<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000081">
<title confidence="0.988428">
Mildly Non-Projective Dependency Structures
</title>
<author confidence="0.882856">
Marco Kuhlmann
</author>
<affiliation confidence="0.7787195">
Programming Systems Lab
Saarland University
</affiliation>
<address confidence="0.459745">
Germany
</address>
<email confidence="0.994207">
kuhlmann@ps.uni-sb.de
</email>
<author confidence="0.987519">
Joakim Nivre
</author>
<affiliation confidence="0.997615">
Växjö University and
Uppsala University
</affiliation>
<address confidence="0.476971">
Sweden
</address>
<email confidence="0.990995">
nivre@msi.vxu.se
</email>
<sectionHeader confidence="0.993608" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99996925">
Syntactic parsing requires a fine balance
between expressivity and complexity, so
that naturally occurring structures can be
accurately parsed without compromising
efficiency. In dependency-based parsing,
several constraints have been proposed that
restrict the class of permissible structures,
such as projectivity, planarity, multi-pla-
narity, well-nestedness, gap degree, and
edge degree. While projectivity is gener-
ally taken to be too restrictive for natural
language syntax, it is not clear which of the
other proposals strikes the best balance be-
tween expressivity and complexity. In this
paper, we review and compare the different
constraints theoretically, and provide an ex-
perimental evaluation using data from two
treebanks, investigating how large a propor-
tion of the structures found in the treebanks
are permitted under different constraints.
The results indicate that a combination of
the well-nestedness constraint and a para-
metric constraint on discontinuity gives a
very good fit with the linguistic data.
</bodyText>
<sectionHeader confidence="0.999128" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999842185185185">
Dependency-based representations have become in-
creasingly popular in syntactic parsing, especially
for languages that exhibit free or flexible word or-
der, such as Czech (Collins et al., 1999), Bulgarian
(Marinov and Nivre, 2005), and Turkish (Eryi˘git
and Oflazer, 2006). Many practical implementa-
tions of dependency parsing are restricted to pro-
jective structures, where the projection of a head
word has to form a continuous substring of the
sentence. While this constraint guarantees good
parsing complexity, it is well-known that certain
syntactic constructions can only be adequately rep-
resented by non-projective dependency structures,
where the projection of a head can be discontinu-
ous. This is especially relevant for languages with
free or flexible word order.
However, recent results in non-projective depen-
dency parsing, especially using data-driven meth-
ods, indicate that most non-projective structures
required for the analysis of natural language are
very nearly projective, differing only minimally
from the best projective approximation (Nivre and
Nilsson, 2005; Hall and Novák, 2005; McDon-
ald and Pereira, 2006). This raises the question
of whether it is possible to characterize a class of
mildly non-projective dependency structures that is
rich enough to account for naturally occurring syn-
tactic constructions, yet restricted enough to enable
efficient parsing.
In this paper, we review a number of propos-
als for classes of dependency structures that lie
between strictly projective and completely unre-
stricted non-projective structures. These classes
have in common that they can be characterized in
terms of properties of the dependency structures
themselves, rather than in terms of grammar for-
malisms that generate the structures. We compare
the proposals from a theoretical point of view, and
evaluate a subset of them empirically by testing
their representational adequacy with respect to two
dependency treebanks: the Prague Dependency
Treebank (PDT) (Hajiˇc et al., 2001), and the Danish
Dependency Treebank (DDT) (Kromann, 2003).
The rest of the paper is structured as follows.
In section 2, we provide a formal definition of de-
pendency structures as a special kind of directed
graphs, and characterize the notion of projectivity.
In section 3, we define and compare five different
constraints on mildly non-projective dependency
structures that can be found in the literature: pla-
narity, multiplanarity, well-nestedness, gap degree,
and edge degree. In section 4, we provide an ex-
perimental evaluation of the notions of planarity,
well-nestedness, gap degree, and edge degree, by
</bodyText>
<page confidence="0.951547">
507
</page>
<note confidence="0.723298">
Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 507–514,
Sydney, July 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.999824">
investigating how large a proportion of the depen-
dency structures found in PDT and DDT are al-
lowed under the different constraints. In section 5,
we present our conclusions and suggestions for fur-
ther research.
</bodyText>
<sectionHeader confidence="0.944826" genericHeader="method">
2 Dependency graphs
</sectionHeader>
<bodyText confidence="0.99879775">
For the purposes of this paper, a dependency graph
is a directed graph on the set of indices correspond-
ing to the tokens of a sentence. We write [n] to refer
to the set of positive integers up to and including n.
</bodyText>
<equation confidence="0.936828666666667">
Definition 1 A dependency graph for a sentence
x = w1, ... , wn is a directed graph1
G = (V ; E), where V = [n] and E C V x V .
</equation>
<bodyText confidence="0.999709666666667">
Throughout this paper, we use standard terminol-
ogy and notation from graph theory to talk about
dependency graphs. In particular, we refer to the
elements of the set V as nodes, and to the elements
of the set E as edges. We write i --&gt; j to mean that
there is an edge from the node i to the node j (i.e.,
(i, j) E E), and i --&gt;* j to mean that the node i
dominates the node j, i.e., that there is a (possibly
empty) path from i to j. For a given node i, the set
of nodes dominated by i is the yield of i. We use
the notation 3r(i) to refer to the projection of i: the
yield of i, arranged in ascending order.
</bodyText>
<subsectionHeader confidence="0.928051">
2.1 Dependency forests
</subsectionHeader>
<bodyText confidence="0.968839142857143">
Most of the literature on dependency grammar and
dependency parsing does not allow arbitrary de-
pendency graphs, but imposes certain structural
constraints on them. In this paper, we restrict our-
selves to dependency graphs that form forests.
Definition 2 A dependency forest is a dependency
graph with two additional properties:
</bodyText>
<listItem confidence="0.825449142857143">
1. it is acyclic (i.e., if i --&gt; j, then not j --&gt;* i);
2. each of its nodes has at most one incoming
edge (i.e., if i --&gt; j, then there is no node k
such that k =A i and k --&gt; j).
Nodes in a forest without an incoming edge are
called roots. A dependency forest with exactly one
root is a dependency tree.
</listItem>
<bodyText confidence="0.99472175">
Figure 1 shows a dependency forest taken from
PDT. It has two roots: node 2 (corresponding to the
complementizer proto) and node 8 (corresponding
to the final punctuation mark).
</bodyText>
<footnote confidence="0.776663">
1We only consider unlabelled dependency graphs.
</footnote>
<figure confidence="0.86111625">
1 2 3 4 5 6 7 8
Neni proto zapotřebi uzavirat nové ndjemni smlouvy .
is-not therefore needed sign new lease contracts .
‘It is therefore not needed to sign new lease contracts.’
</figure>
<figureCaption confidence="0.992997">
Figure 1: Dependency forest for a Czech sentence
from the Prague Dependency Treebank
</figureCaption>
<bodyText confidence="0.99882725">
Some authors extend dependency forests by a
special root node with position 0, and add an edge
(0, i) for every root node i of the remaining graph
(McDonald et al., 2005). This ensures that the ex-
tended graph always is a tree. Although such a
definition can be useful, we do not follow it here,
since it obscures the distinction between projectiv-
ity and planarity to be discussed in section 3.
</bodyText>
<subsectionHeader confidence="0.994785">
2.2 Projectivity
</subsectionHeader>
<bodyText confidence="0.989623357142857">
In contrast to acyclicity and the indegree constraint,
both of which impose restrictions on the depen-
dency relation as such, the projectivity constraint
concerns the interaction between the dependency
relation and the positions of the nodes in the sen-
tence: it says that the nodes in a subtree of a de-
pendency graph must form an interval, where an
interval (with endpoints i and j) is the set
[i, j] := {kEV I i &lt; k and k &lt; j }.
Definition 3 A dependency graph is projective, if
the yields of its nodes are intervals.
Since projectivity requires each node to dominate a
continuous substring of the sentence, it corresponds
to a ban on discontinuous constituents in phrase
structure representations.
Projectivity is an interesting constraint on de-
pendency structures both from a theoretical and
a practical perspective. Dependency grammars
that only allow projective structures are closely
related to context-free grammars (Gaifman, 1965;
Obre¸bski and Grali´nski, 2004); among other things,
they have the same (weak) expressivity. The pro-
jectivity constraint also leads to favourable pars-
ing complexities: chart-based parsing of projective
dependency grammars can be done in cubic time
(Eisner, 1996); hard-wiring projectivity into a de-
terministic dependency parser leads to linear-time
parsing in the worst case (Nivre, 2003).
</bodyText>
<page confidence="0.998079">
508
</page>
<sectionHeader confidence="0.970562" genericHeader="method">
3 Relaxations of projectivity
</sectionHeader>
<bodyText confidence="0.9999047">
While the restriction to projective analyses has a
number of advantages, there is clear evidence that
it cannot be maintained for real-world data (Zeman,
2004; Nivre, 2006). For example, the graph in
Figure 1 is non-projective: the yield of the node 1
(marked by the dashed rectangles) does not form
an interval—the node 2 is ‘missing’. In this sec-
tion, we present several proposals for structural
constraints that relax projectivity, and relate them
to each other.
</bodyText>
<subsectionHeader confidence="0.997876">
3.1 Planarity and multiplanarity
</subsectionHeader>
<bodyText confidence="0.917850615384616">
The notion of planarity appears in work on Link
Grammar (Sleator and Temperley, 1993), where
it is traced back to Mel’ˇcuk (1988). Informally,
a dependency graph is planar, if its edges can be
drawn above the sentence without crossing. We
emphasize the word above, because planarity as
it is understood here does not coincide with the
standard graph-theoretic concept of the same name,
where one would be allowed to also use the area
below the sentence to disentangle the edges.
Figure 2a shows a dependency graph that is pla-
nar but not projective: while there are no crossing
edges, the yield of the node 1 (the set 11, 3}) does
not form an interval.
Using the notation linked(i, j) as an abbrevia-
tion for the statement ‘there is an edge from i to j,
or vice versa’, we formalize planarity as follows:
Definition 4 A dependency graph is planar, if it
does not contain nodes a, b, c, d such that
linked(a, c) A linked(b, d) A a &lt; b &lt; c &lt; d .
Yli-Jyrä (2003) proposes multiplanarity as a gen-
eralization of planarity suitable for modelling de-
pendency analyses, and evaluates it experimentally
using data from DDT.
Definition 5 A dependency graph G = (V ; E) is
m-planar, if it can be split into m planar graphs
</bodyText>
<equation confidence="0.949771">
G1 = (V ; E1), ... , Gm = (V ; Em)
</equation>
<bodyText confidence="0.986990285714286">
such that E = E1U- - -UEm. The planar graphs Gi
are called planes.
As an example of a dependency forest that is 2-
planar but not planar, consider the graph depicted in
Figure 2b. In this graph, the edges (1, 4) and (3, 5)
are crossing. Moving either edge to a separate
graph partitions the original graph into two planes.
</bodyText>
<figure confidence="0.9805625">
1 2 3 1 2 3 4 5
(a) 1-planar (b) 2-planar
</figure>
<figureCaption confidence="0.999626">
Figure 2: Planarity and multi-planarity
</figureCaption>
<subsectionHeader confidence="0.999758">
3.2 Gap degree and well-nestedness
</subsectionHeader>
<bodyText confidence="0.9999209">
Bodirsky et al. (2005) present two structural con-
straints on dependency graphs that characterize
analyses corresponding to derivations in Tree Ad-
joining Grammar: the gap degree restriction and
the well-nestedness constraint.
A gap is a discontinuity in the projection of a
node in a dependency graph (Plátek et al., 2001).
More precisely, let 7ri be the projection of the
node i. Then a gap is a pair (jk, jk+1) of nodes
adjacent in 7ri such that
</bodyText>
<equation confidence="0.996451">
jk+1 — jk &gt; 1.
</equation>
<bodyText confidence="0.997081433333333">
Definition 6 The gap degree of a node i in a de-
pendency graph, gd(i), is the number of gaps in 7ri.
As an example, consider the node labelled i in the
dependency graphs in Figure 3. In Graph 3a, the
projection of i is an interval ((2, 3, 4)), so i has gap
degree 0. In Graph 3b, 7ri = (2, 3, 6) contains a
single gap ((3, 6)), so the gap degree of i is 1. In
the rightmost graph, the gap degree of i is 2, since
7ri = (2, 4, 6) contains two gaps ((2, 4) and (4, 6)).
Definition 7 The gap degree of a dependency
graph G, gd(G), is the maximum among the gap
degrees of its nodes.
Thus, the gap degree of the graphs in Figure 3
is 0, 1 and 2, respectively, since the node i has the
maximum gap degree in all three cases.
The well-nestedness constraint restricts the posi-
tioning of disjoint subtrees in a dependency forest.
Two subtrees are called disjoint, if neither of their
roots dominates the other.
Definition 8 Two subtrees T1, T2 interleave, if
there are nodes l1, r1 E T1 and l2, r2 E T2 such
that l1 &lt; l2 &lt; r1 &lt; r2. A dependency graph is
well-nested, if no two of its disjoint subtrees inter-
leave.
Both Graph 3a and Graph 3b are well-nested.
Graph 3c is not well-nested. To see this, let T1
be the subtree rooted at the node labelled i, and
let T2 be the subtree rooted at j. These subtrees
interleave, as T1 contains the nodes 2 and 4, and T2
contains the nodes 3 and 5.
</bodyText>
<page confidence="0.980951">
509
</page>
<figure confidence="0.991421875">
1 2 i 3 4 5 6
j
1 2 i 3 4 5 6
j
1 2 i 3 4 5 6
j
(a) gd = 0, ed = 0, wnC (b) gd = 1, ed = 1, wnC (c) gd = 2, ed = 1, wn�
-nestedness
</figure>
<subsectionHeader confidence="0.991741">
3.3 Edge degree
</subsectionHeader>
<bodyText confidence="0.94333272">
The notion of edge degree was introduced by Nivre
(2006) in order to allow mildly non-projective struc-
tures while maintaining good parsing efficiency in
data-driven dependency parsing.2
Define the span of an edge (i, j) as the interval
S((i, j)) W= [min(i, j),max(i, j)].
Definition 9 Let G = (V I E) be a dependency
forest, let e = (i, j) be an edge in E, and let Ge
be the subgraph of G that is induced by the nodes
contained in the span of e.
• The degree of an edge e 2 E, ed(e), is the
number of connected components c in Ge
such that the root of c is not dominated by
the head of e.
• The edge degree of G, ed(G), is the maximum
among the degrees of the edges in G.
To illustrate the notion of edge degree, we return
to Figure 3. Graph 3a has edge degree 0: the only
edge that spans more nodes than its head and its de-
pendent is (1, 5), but the root of the connected com-
ponent f2, 3, 4g is dominated by 1. Both Graph 3b
and 3c have edge degree 1: the edge (3, 6) in
Graph 3b and the edges (2, 4), (3, 5) and (4, 6) in
Graph 3c each span a single connected component
that is not dominated by the respective head.
</bodyText>
<sectionHeader confidence="0.975638" genericHeader="method">
3.4 Related work
</sectionHeader>
<bodyText confidence="0.985405884615384">
Apart from proposals for structural constraints re-
laxing projectivity, there are dependency frame-
works that in principle allow unrestricted graphs,
but provide mechanisms to control the actually per-
mitted forms of non-projectivity in the grammar.
The non-projective dependency grammar of Ka-
hane et al. (1998) is based on an operation on de-
pendency trees called lifting: a ‘lift’ of a tree T is
the new tree that is obtained when one replaces one
2We use the term edge degree instead of the original simple
term degree from Nivre (2006) to mark the distinction from
the notion of gap degree.
or more edges (i, k) in T by edges (j, k), where
j !* i. The exact conditions under which a cer-
tain lifting may take place are specified in the rules
of the grammar. A dependency tree is acceptable,
if it can be lifted to form a projective graph.3
A similar design is pursued in Topological De-
pendency Grammar (Duchier and Debusmann,
2001), where a dependency analysis consists of
two, mutually constraining graphs: the ID graph
represents information about immediate domi-
nance, the LP graph models the topological struc-
ture of a sentence. As a principle of the grammar,
the LP graph is required to be a lift of the ID graph;
this lifting can be constrained in the lexicon.
</bodyText>
<sectionHeader confidence="0.604415" genericHeader="method">
3.5 Discussion
</sectionHeader>
<bodyText confidence="0.99993124">
The structural conditions we have presented here
naturally fall into two groups: multiplanarity, gap
degree and edge degree are parametric constraints
with an infinite scale of possible values; planarity
and well-nestedness come as binary constraints.
We discuss these two groups in turn.
Parametric constraints With respect to the
graded constraints, we find that multiplanarity is
different from both gap degree and edge degree
in that it involves a notion of optimization: since
every dependency graph is m-planar for some suf-
ficiently large m (put each edge onto a separate
plane), the interesting question in the context of
multiplanarity is about the minimal values for m
that occur in real-world data. But then, one not
only needs to show that a dependency graph can be
decomposed into m planar graphs, but also that this
decomposition is the one with the smallest number
of planes among all possible decompositions. Up
to now, no tractable algorithm to find the minimal
decomposition has been given, so itis not clear how
to evaluate the significance of the concept as such.
The evaluation presented by Yli-Jyrä (2003) makes
use of additional constraints that are sufficient to
make the decomposition unique.
</bodyText>
<figureCaption confidence="0.960372">
Figure 3: Gap degree, edge degree, and well
</figureCaption>
<footnote confidence="0.9966265">
3We remark that, without restrictions on the lifting, every
non-projective tree has a projective lift.
</footnote>
<page confidence="0.98308">
510
</page>
<figureCaption confidence="0.998444">
Figure 4: Comparing gap degree and edge degree
</figureCaption>
<bodyText confidence="0.997976970588236">
The fundamental difference between gap degree
and edge degree is that the gap degree measures the
number of discontinuities within a subtree, while
the edge degree measures the number of interven-
ing constituents spanned by a single edge. This
difference is illustrated by the graphs displayed in
Figure 4. Graph 4a has gap degree 2 but edge de-
gree 1: the subtree rooted at node 2 (marked by
the solid edges) has two gaps, but each of its edges
only spans one connected component not domi-
nated by 2 (marked by the squares). In contrast,
Graph 4b has gap degree 1 but edge degree 2: the
subtree rooted at node 2 has one gap, but this gap
contains two components not dominated by 2.
Nivre (2006) shows experimentally that limiting
the permissible edge degree to 1 or 2 can reduce the
average parsing time for a deterministic algorithm
from quadratic to linear, while omitting less than
1% of the structures found in DDT and PDT. It
can be expected that constraints on the gap degree
would have very similar effects.
Binary constraints For the two binary con-
straints, we find that well-nestedness subsumes
planarity: a graph that contains interleaving sub-
trees cannot be drawn without crossing edges, so
every planar graph must also be well-nested. To see
that the converse does not hold, consider Graph 3b,
which is well-nested, but not planar.
Since both planarity and well-nestedness are
proper extensions of projectivity, we get the fol-
lowing hierarchy for sets of dependency graphs:
projective C planar C well-nested C unrestricted
The planarity constraint appears like a very natural
one at first sight, as it expresses the intuition that
‘crossing edges are bad’, but still allows a limited
form of non-projectivity. However, many authors
use planarity in conjunction with a special repre-
sentation of the root node: either as an artificial
node at the sentence boundary, as we mentioned in
section 2, or as the target of an infinitely long per-
pendicular edge coming ‘from the outside’, as in
earlier versions of Word Grammar (Hudson, 2003).
In these situations, planarity reduces to projectivity,
so nothing is gained.
Even in cases where planarity is used without a
special representation of the root node, it remains
a peculiar concept. When we compare it with the
notion of gaps, for example, we find that, in a planar
dependency tree, every gap .i; j/ must contain the
root node r, in the sense that i &lt; r &lt; j: if the gap
would only contain non-root nodes k, then the two
paths from r to k and from i to j would cross. This
particular property does not seem to be mirrored in
any linguistic prediction.
In contrast to planarity, well-nestedness is inde-
pendent from both gap degree and edge degree in
the sense that for every d &gt; 0, there are both well-
nested and non-well-nested dependency graphs
with gap degree or edge degree d. All projective de-
pendency graphs (d = 0) are trivially well-nested.
Well-nestedness also brings computational bene-
fits. In particular, chart-based parsers for grammar
formalisms in which derivations obey the well-nest-
edness constraint (such as Tree Adjoining Gram-
mar) are not hampered by the ‘crossing configu-
rations’ to which Satta (1992) attributes the fact
that the universal recognition problem of Linear
Context-Free Rewriting Systems is X30-complete.
</bodyText>
<sectionHeader confidence="0.997411" genericHeader="evaluation">
4 Experimental evaluation
</sectionHeader>
<bodyText confidence="0.999975666666667">
In this section, we present an experimental eval-
uation of planarity, well-nestedness, gap degree,
and edge degree, by examining how large a pro-
portion of the structures found in two dependency
treebanks are allowed under different constraints.
Assuming that the treebank structures are sampled
from naturally occurring structures in natural lan-
guage, this provides an indirect evaluation of the
linguistic adequacy of the different proposals.
</bodyText>
<subsectionHeader confidence="0.988947">
4.1 Experimental setup
</subsectionHeader>
<bodyText confidence="0.999948363636364">
The experiments are based on data from the Prague
Dependency Treebank (PDT) (Hajiˇc et al., 2001)
and the Danish Dependency Treebank (DDT) (Kro-
mann, 2003). PDT contains 1.5M words of news-
paper text, annotated in three layers according to
the theoretical framework of Functional Generative
Description (Böhmová et al., 2003). Our experi-
ments concern only the analytical layer, and are
based on the dedicated training section of the tree-
bank. DDT comprises 100k words of text selected
from the Danish PAROLE corpus, with annotation
</bodyText>
<figure confidence="0.995917727272727">
5
1 2
1 2
4
6
4
5
3
3
(a) gd = 2, ed = 1
(b)gd=1,ed=2
</figure>
<page confidence="0.99207">
511
</page>
<tableCaption confidence="0.999563">
Table 1: Experimental results for DDT and PDT
</tableCaption>
<bodyText confidence="0.796616">
property
all structures
gap degree 0
gap degree 1
gap degree 2
gap degree 3
gap degree 4
edge degree 0
edge degree 1
edge degree 2
edge degree 3
edge degree 4
edge degree 5
edge degree 6
projective
planar
well-nested
</bodyText>
<table confidence="0.990274090909091">
DDT PDT
n = 4393 n = 73088
3732 84.95% 56168 76.85%
654 14.89% 16608 22.72%
7 0.16% 307 0.42%
– – 4 0.01%
– – 1 &lt; 0.01%
3732 84.95% 56168 76.85%
584 13.29% 16585 22.69%
58 1.32% 259 0.35%
17 0.39% 63 0.09%
2 0.05% 10 0.01%
– – 2 &lt; 0.01%
– – 1 &lt; 0.01%
3732 84.95% 56168 76.85%
3796 86.41% 60048 82.16%
4388 99.89% 73010 99.89%
non-projective structures only n = 661 n = 16920
planar
well-nested
64 9.68% 3880 22.93%
656 99.24% 16842 99.54%
</table>
<bodyText confidence="0.98027075">
of primary and secondary dependencies based on
Discontinuous Grammar (Kromann, 2003). Only
primary dependencies are considered in the experi-
ments, which are based on the entire treebank.4
</bodyText>
<subsectionHeader confidence="0.681466">
4.2 Results
</subsectionHeader>
<bodyText confidence="0.968818794871795">
The results of our experiments are given in Table 1.
For the binary constraints (planarity, well-nested-
ness), we simply report the number and percentage
of structures in each data set that satisfy the con-
straint. For the parametric constraints (gap degree,
edge degree), we report the number and percentage
of structures having degree d (d &gt; 0), where de-
gree 0 is equivalent (for both gap degree and edge
degree) to projectivity.
For DDT, we see that about 15% of all analyses
are non-projective. The minimal degree of non-pro-
jectivity required to cover all of the data is 2 in the
case of gap degree and 4 in the case of edge degree.
For both measures, the number of structures drops
quickly as the degree increases. (As an example,
only 7 or 0.17% of the analyses in DDT have gap
4A total number of 17 analyses in DDT were excluded
because they either had more than one root node, or violated
the indegree constraint. (Both cases are annotation errors.)
degree 2.) Regarding the binary constraints, we
find that planarity accounts for slightly more than
the projective structures (86.41% of the data is pla-
nar), while almost all structures in DDT (99.89%)
meet the well-nestedness constraint. The differ-
ence between the two constraints becomes clearer
when we base the figures on the set of non-projec-
tive structures only: out of these, less than 10% are
planar, while more than 99% are well-nested.
For PDT, both the number of non-projective
structures (around 23%) and the minimal degrees
of non-projectivity required to cover the full data
(gap degree 4 and edge degree 6) are higher than in
DDT. The proportion of planar analyses is smaller
than in DDT if we base it on the set of all structures
(82.16%), but significantly larger when based on
the set of non-projective structures only (22.93%).
However, this is still very far from the well-nested-
ness constraint, which has almost perfect coverage
on both data sets.
</bodyText>
<subsectionHeader confidence="0.994388">
4.3 Discussion
</subsectionHeader>
<bodyText confidence="0.999364">
As a general result, our experiments confirm previ-
ous studies on non-projective dependency parsing
(Nivre and Nilsson, 2005; Hall and Novák, 2005;
</bodyText>
<page confidence="0.992092">
512
</page>
<bodyText confidence="0.999560725806452">
McDonald and Pereira, 2006): The phenomenon
of non-projectivity cannot be ignored without also
ignoring a significant portion of real-world data
(around 15% for DDT, and 23% for PDT). At the
same time, already a small step beyond projectivity
accounts for almost all of the structures occurring
in these treebanks.
More specifically, we find that already an edge
degree restriction of d &lt; 1 covers 98.24% of DDT
and 99.54% of PDT, while the same restriction
on the gap degree scale achieves a coverage of
99.84% (DDT) and 99.57% (PDT). Together with
the previous evidence that both measures also have
computational advantages, this provides a strong
indication for the usefulness of these constraints in
the context of non-projective dependency parsing.
When we compare the two graded constraints
to each other, we find that the gap degree measure
partitions the data into less and larger clusters than
the edge degree, which may be an advantage in the
context of using the degree constraints as features
in a data-driven approach towards parsing. How-
ever, our purely quantitative experiments cannot
answer the question, which of the two measures
yields the more informative clusters.
The planarity constraint appears to be of little
use as a generalization of projectivity: enforcing
it excludes more than 75% of the non-projective
data in PDT, and 90% of the data in DDT. The rela-
tively large difference in coverage between the two
treebanks may at least partially be explained with
their different annotation schemes for sentence-fi-
nal punctuation. In DDT, sentence-final punctua-
tion marks are annotated as dependents of the main
verb of a dependency nexus. This, as we have
discussed above, places severe restrictions on per-
mitted forms of non-projectivity in the remaining
sentence, as every discontinuity that includes the
main verb must also include the dependent punctu-
ation marks. On the other hand, in PDT, a sentence-
final punctuation mark is annotated as a separate
root node with no dependents. This scheme does
not restrict the remaining discontinuities at all.
In contrast to planarity, the well-nestedness con-
straint appears to constitute a very attractive exten-
sion of projectivity. For one thing, the almost per-
fect coverage of well-nestedness on DDT and PDT
(99.89%) could by no means be expected on purely
combinatorial grounds—only 7% of all possible
dependency structures for sentences of length 17
(the average sentence length in PDT), and only
slightly more than 5% of all possible dependency
structures for sentences of length 18 (the average
sentence length in DDT) are well-nested.5 More-
over, a cursory inspection of the few problematic
cases in DDT indicates that violations of the well-
nestedness constraint may, at least in part, be due
to properties of the annotation scheme, such as the
analysis of punctuation in quotations. However, a
more detailed analysis of the data from both tree-
banks is needed before any stronger conclusions
can be drawn concerning well-nestedness.
</bodyText>
<sectionHeader confidence="0.998865" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.9999735">
In this paper, we have reviewed a number of pro-
posals for the characterization of mildly non-pro-
jective dependency structures, motivated by the
need to find a better balance between expressivity
and complexity than that offered by either strictly
projective or unrestricted non-projective structures.
Experimental evaluation based on data from two
treebanks shows, that a combination of the well-
nestedness constraint and parametric constraints
on discontinuity (formalized either as gap degree
or edge degree) gives a very good fit with the em-
pirical linguistic data. Important goals for future
work are to widen the empirical basis by inves-
tigating more languages, and to perform a more
detailed analysis of linguistic phenomena that vio-
late certain constraints. Another important line of
research is the integration of these constraints into
parsing algorithms for non-projective dependency
structures, potentially leading to a better trade-off
between accuracy and efficiency than that obtained
with existing methods.
Acknowledgements We thank three anonymous
reviewers of this paper for their comments. The
work of Marco Kuhlmann is funded by the Collab-
orative Research Centre 378 ‘Resource-Adaptive
Cognitive Processes’ of the Deutsche Forschungs-
gemeinschaft. The work of Joakim Nivre is par-
tially supported by the Swedish Research Council.
</bodyText>
<footnote confidence="0.9908245">
5The number of unrestricted dependency trees on n nodes
is given by Sequence A000169, the number of well-nested
dependency trees is given by Sequence A113882 in the On-
Line Encyclopedia of Integer Sequences (Sloane, 2006).
</footnote>
<page confidence="0.997517">
513
</page>
<sectionHeader confidence="0.986851" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999682259259259">
Manuel Bodirsky, Marco Kuhlmann, and Mathias
Möhl. 2005. Well-nested drawings as models of
syntactic structure. In Tenth Conference on For-
mal Grammar and Ninth Meeting on Mathematics
of Language.
Alena Böhmová, Jan Hajiˇc, Eva Hajiˇcová, and Barbora
Hladká. 2003. The Prague Dependency Treebank:
A three-level annotation scenario. In Anne Abeillé,
editor, Treebanks: Building and Using Parsed Cor-
pora, pages 103–127. Kluwer Academic Publishers.
Michael Collins, Jan Hajiˇc, Eric Brill, Lance Ramshaw,
and Christoph Tillmann. 1999. A statistical parser
for Czech. In 37th Annual Meeting of the Associ-
ation for Computational Linguistics (ACL), pages
505–512.
Denys Duchier and Ralph Debusmann. 2001. Topo-
logical dependency trees: A constraint-based ac-
count of linear precedence. In 39th Annual Meet-
ing of the Association for Computational Linguistics
(ACL), pages 180–187.
Jason Eisner. 1996. Three new probabilistic models
for dependency parsing: An exploration. In 16th
International Conference on Computational Linguis-
tics (COLING), pages 340–345.
Gülsen Eryi˘git and Kemal Oflazer. 2006. Statistical
dependency parsing of turkish. In Eleventh Confer-
ence of the European Chapter of the Association for
Computational Linguistics (EACL).
Haim Gaifman. 1965. Dependency systems and
phrase-structure systems. Information and Control,
8:304–337.
Jan Hajiˇc, Barbora Vidova Hladka, Jarmila Panevová,
Eva Hajiˇcová, Petr Sgall, and Petr Pajas. 2001.
Prague Dependency Treebank 1.0. LDC, 2001T10.
Keith Hall and Vaclav Novák. 2005. Corrective mod-
eling for non-projective dependency parsing. In
Ninth International Workshop on Parsing Technolo-
gies (IWPT).
Richard Hudson. 2003. An encyclopedia
of English grammar and Word Grammar.
http://www.phon.ucl.ac.uk/home/dick/enc/intro.htm,
January.
Sylvain Kahane, Alexis Nasr, and Owen Rambow.
1998. Pseudo-projectivity: A polynomially parsable
non-projective dependency grammar. In 36th An-
nual Meeting of the Association for Computational
Linguistics and 18th International Conference on
Computational Linguistics (COLING-ACL), pages
646–652.
Matthias Trautner Kromann. 2003. The Danish De-
pendency Treebank and the DTAG treebank tool. In
Second Workshop on Treebanks and Linguistic The-
ories (TLT), pages 217–220.
Svetoslav Marinov and Joakim Nivre. 2005. A data-
driven parser for Bulgarian. In Fourth Workshop on
Treebanks and Linguistic Theories (TLT), pages 89–
100.
Ryan McDonald and Fernando Pereira. 2006. On-
line learning of approximate dependency parsing al-
gorithms. In Eleventh Conference of the European
Chapter of the Association for Computational Lin-
guistics (EACL).
Ryan McDonald, Fernando Pereira, Kiril Ribarov, and
Jan Hajiˇc. 2005. Non-projective dependency pars-
ing using spanning tree algorithms. In 43rd Annual
Meeting of the Association for Computational Lin-
guistics (ACL).
Igor Mel’ˇcuk. 1988. Dependency Syntax: Theory and
Practice. State University of New York Press, Al-
bany, New York, USA.
Joakim Nivre and Jens Nilsson. 2005. Pseudo-
projective dependency parsing. In 43rd Annual
Meeting of the Association for Computational Lin-
guistics (ACL), pages 99–106.
Joakim Nivre. 2003. An efficient algorithm for pro-
jective dependency parsing. In Eigth International
Workshop on Parsing Technologies (IWPT), pages
149–160.
Joakim Nivre. 2006. Constraints on non-projective de-
pendency parsing. In Eleventh Conference of the
European Chapter of the Association for Computa-
tional Linguistics (EACL).
T. Obre¸bski and F. Grali´nski. 2004. Some notes
on generative capacity of dependency grammar. In
COLING 2004 Workshop on Recent Advances in De-
pendency Grammar Workshop on Recent Advances
in Dependency Grammar.
Martin Plátek, Tomáš Holan, and Vladislav Kuboˇn.
2001. On relax-ability of word order by d-grammars.
In Third International Conference on Discrete Math-
ematics and Theoretical Computer Science.
Giorgio Satta. 1992. Recognition of linear context-
free rewriting systems. In 30th Meeting of the Asso-
ciation for Computational Linguistics (ACL), pages
89–95, Newark, Delaware, USA.
Daniel Sleator and Davy Temperley. 1993. Parsing
English with a link grammar. In Third International
Workshop on Parsing Technologies.
Neil J. A. Sloane. 2006. The on-line encyclopedia
of integer sequences. Published electronically at
http://www.research.att.com/ njas/sequences/.
Anssi Yli-Jyrä. 2003. Multiplanarity – a model for de-
pendency structures in treebanks. In Second Work-
shop on Treebanks and Linguistic Theories (TLT),
pages 189–200.
Daniel Zeman. 2004. Parsing With a Statistical De-
pendency Model. Ph.D. thesis, Charles University,
Prague, Czech Republic.
</reference>
<page confidence="0.997933">
514
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.660446">
<title confidence="0.999908">Mildly Non-Projective Dependency Structures</title>
<author confidence="0.999992">Marco Kuhlmann</author>
<affiliation confidence="0.997746">Programming Systems Lab Saarland University</affiliation>
<address confidence="0.994086">Germany</address>
<email confidence="0.998912">kuhlmann@ps.uni-sb.de</email>
<author confidence="0.836941">Joakim Nivre</author>
<affiliation confidence="0.999968">Växjö University and Uppsala University</affiliation>
<address confidence="0.827656">Sweden</address>
<email confidence="0.963244">nivre@msi.vxu.se</email>
<abstract confidence="0.9997118">Syntactic parsing requires a fine balance between expressivity and complexity, so that naturally occurring structures can be accurately parsed without compromising efficiency. In dependency-based parsing, several constraints have been proposed that restrict the class of permissible structures, such as projectivity, planarity, multi-planarity, well-nestedness, gap degree, and edge degree. While projectivity is generally taken to be too restrictive for natural language syntax, it is not clear which of the other proposals strikes the best balance between expressivity and complexity. In this paper, we review and compare the different constraints theoretically, and provide an experimental evaluation using data from two treebanks, investigating how large a proportion of the structures found in the treebanks are permitted under different constraints. The results indicate that a combination of the well-nestedness constraint and a parametric constraint on discontinuity gives a very good fit with the linguistic data.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Manuel Bodirsky</author>
<author>Marco Kuhlmann</author>
<author>Mathias Möhl</author>
</authors>
<title>Well-nested drawings as models of syntactic structure.</title>
<date>2005</date>
<booktitle>In Tenth Conference on Formal Grammar and Ninth Meeting on Mathematics of Language.</booktitle>
<contexts>
<context position="10329" citStr="Bodirsky et al. (2005)" startWordPosition="1709" endWordPosition="1712">ntally using data from DDT. Definition 5 A dependency graph G = (V ; E) is m-planar, if it can be split into m planar graphs G1 = (V ; E1), ... , Gm = (V ; Em) such that E = E1U- - -UEm. The planar graphs Gi are called planes. As an example of a dependency forest that is 2- planar but not planar, consider the graph depicted in Figure 2b. In this graph, the edges (1, 4) and (3, 5) are crossing. Moving either edge to a separate graph partitions the original graph into two planes. 1 2 3 1 2 3 4 5 (a) 1-planar (b) 2-planar Figure 2: Planarity and multi-planarity 3.2 Gap degree and well-nestedness Bodirsky et al. (2005) present two structural constraints on dependency graphs that characterize analyses corresponding to derivations in Tree Adjoining Grammar: the gap degree restriction and the well-nestedness constraint. A gap is a discontinuity in the projection of a node in a dependency graph (Plátek et al., 2001). More precisely, let 7ri be the projection of the node i. Then a gap is a pair (jk, jk+1) of nodes adjacent in 7ri such that jk+1 — jk &gt; 1. Definition 6 The gap degree of a node i in a dependency graph, gd(i), is the number of gaps in 7ri. As an example, consider the node labelled i in the dependenc</context>
</contexts>
<marker>Bodirsky, Kuhlmann, Möhl, 2005</marker>
<rawString>Manuel Bodirsky, Marco Kuhlmann, and Mathias Möhl. 2005. Well-nested drawings as models of syntactic structure. In Tenth Conference on Formal Grammar and Ninth Meeting on Mathematics of Language.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alena Böhmová</author>
<author>Jan Hajiˇc</author>
<author>Eva Hajiˇcová</author>
<author>Barbora Hladká</author>
</authors>
<title>The Prague Dependency Treebank: A three-level annotation scenario.</title>
<date>2003</date>
<booktitle>Treebanks: Building and Using Parsed Corpora,</booktitle>
<pages>103--127</pages>
<editor>In Anne Abeillé, editor,</editor>
<publisher>Kluwer Academic Publishers.</publisher>
<marker>Böhmová, Hajiˇc, Hajiˇcová, Hladká, 2003</marker>
<rawString>Alena Böhmová, Jan Hajiˇc, Eva Hajiˇcová, and Barbora Hladká. 2003. The Prague Dependency Treebank: A three-level annotation scenario. In Anne Abeillé, editor, Treebanks: Building and Using Parsed Corpora, pages 103–127. Kluwer Academic Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Jan Hajiˇc</author>
<author>Eric Brill</author>
<author>Lance Ramshaw</author>
<author>Christoph Tillmann</author>
</authors>
<title>A statistical parser for Czech.</title>
<date>1999</date>
<booktitle>In 37th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>505--512</pages>
<marker>Collins, Hajiˇc, Brill, Ramshaw, Tillmann, 1999</marker>
<rawString>Michael Collins, Jan Hajiˇc, Eric Brill, Lance Ramshaw, and Christoph Tillmann. 1999. A statistical parser for Czech. In 37th Annual Meeting of the Association for Computational Linguistics (ACL), pages 505–512.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Denys Duchier</author>
<author>Ralph Debusmann</author>
</authors>
<title>Topological dependency trees: A constraint-based account of linear precedence.</title>
<date>2001</date>
<booktitle>In 39th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>180--187</pages>
<contexts>
<context position="14364" citStr="Duchier and Debusmann, 2001" startWordPosition="2513" endWordPosition="2516">(1998) is based on an operation on dependency trees called lifting: a ‘lift’ of a tree T is the new tree that is obtained when one replaces one 2We use the term edge degree instead of the original simple term degree from Nivre (2006) to mark the distinction from the notion of gap degree. or more edges (i, k) in T by edges (j, k), where j !* i. The exact conditions under which a certain lifting may take place are specified in the rules of the grammar. A dependency tree is acceptable, if it can be lifted to form a projective graph.3 A similar design is pursued in Topological Dependency Grammar (Duchier and Debusmann, 2001), where a dependency analysis consists of two, mutually constraining graphs: the ID graph represents information about immediate dominance, the LP graph models the topological structure of a sentence. As a principle of the grammar, the LP graph is required to be a lift of the ID graph; this lifting can be constrained in the lexicon. 3.5 Discussion The structural conditions we have presented here naturally fall into two groups: multiplanarity, gap degree and edge degree are parametric constraints with an infinite scale of possible values; planarity and well-nestedness come as binary constraints</context>
</contexts>
<marker>Duchier, Debusmann, 2001</marker>
<rawString>Denys Duchier and Ralph Debusmann. 2001. Topological dependency trees: A constraint-based account of linear precedence. In 39th Annual Meeting of the Association for Computational Linguistics (ACL), pages 180–187.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Eisner</author>
</authors>
<title>Three new probabilistic models for dependency parsing: An exploration.</title>
<date>1996</date>
<booktitle>In 16th International Conference on Computational Linguistics (COLING),</booktitle>
<pages>340--345</pages>
<contexts>
<context position="7962" citStr="Eisner, 1996" startWordPosition="1289" endWordPosition="1290">ing of the sentence, it corresponds to a ban on discontinuous constituents in phrase structure representations. Projectivity is an interesting constraint on dependency structures both from a theoretical and a practical perspective. Dependency grammars that only allow projective structures are closely related to context-free grammars (Gaifman, 1965; Obre¸bski and Grali´nski, 2004); among other things, they have the same (weak) expressivity. The projectivity constraint also leads to favourable parsing complexities: chart-based parsing of projective dependency grammars can be done in cubic time (Eisner, 1996); hard-wiring projectivity into a deterministic dependency parser leads to linear-time parsing in the worst case (Nivre, 2003). 508 3 Relaxations of projectivity While the restriction to projective analyses has a number of advantages, there is clear evidence that it cannot be maintained for real-world data (Zeman, 2004; Nivre, 2006). For example, the graph in Figure 1 is non-projective: the yield of the node 1 (marked by the dashed rectangles) does not form an interval—the node 2 is ‘missing’. In this section, we present several proposals for structural constraints that relax projectivity, and</context>
</contexts>
<marker>Eisner, 1996</marker>
<rawString>Jason Eisner. 1996. Three new probabilistic models for dependency parsing: An exploration. In 16th International Conference on Computational Linguistics (COLING), pages 340–345.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gülsen Eryi˘git</author>
<author>Kemal Oflazer</author>
</authors>
<title>Statistical dependency parsing of turkish.</title>
<date>2006</date>
<booktitle>In Eleventh Conference of the European Chapter of the Association for Computational Linguistics (EACL).</booktitle>
<marker>Eryi˘git, Oflazer, 2006</marker>
<rawString>Gülsen Eryi˘git and Kemal Oflazer. 2006. Statistical dependency parsing of turkish. In Eleventh Conference of the European Chapter of the Association for Computational Linguistics (EACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Haim Gaifman</author>
</authors>
<title>Dependency systems and phrase-structure systems.</title>
<date>1965</date>
<journal>Information and Control,</journal>
<pages>8--304</pages>
<contexts>
<context position="7698" citStr="Gaifman, 1965" startWordPosition="1251" endWordPosition="1252">rm an interval, where an interval (with endpoints i and j) is the set [i, j] := {kEV I i &lt; k and k &lt; j }. Definition 3 A dependency graph is projective, if the yields of its nodes are intervals. Since projectivity requires each node to dominate a continuous substring of the sentence, it corresponds to a ban on discontinuous constituents in phrase structure representations. Projectivity is an interesting constraint on dependency structures both from a theoretical and a practical perspective. Dependency grammars that only allow projective structures are closely related to context-free grammars (Gaifman, 1965; Obre¸bski and Grali´nski, 2004); among other things, they have the same (weak) expressivity. The projectivity constraint also leads to favourable parsing complexities: chart-based parsing of projective dependency grammars can be done in cubic time (Eisner, 1996); hard-wiring projectivity into a deterministic dependency parser leads to linear-time parsing in the worst case (Nivre, 2003). 508 3 Relaxations of projectivity While the restriction to projective analyses has a number of advantages, there is clear evidence that it cannot be maintained for real-world data (Zeman, 2004; Nivre, 2006). </context>
</contexts>
<marker>Gaifman, 1965</marker>
<rawString>Haim Gaifman. 1965. Dependency systems and phrase-structure systems. Information and Control, 8:304–337.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Hajiˇc</author>
</authors>
<title>Barbora Vidova Hladka, Jarmila Panevová, Eva Hajiˇcová, Petr Sgall, and Petr Pajas.</title>
<date>2001</date>
<marker>Hajiˇc, 2001</marker>
<rawString>Jan Hajiˇc, Barbora Vidova Hladka, Jarmila Panevová, Eva Hajiˇcová, Petr Sgall, and Petr Pajas. 2001. Prague Dependency Treebank 1.0. LDC, 2001T10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Keith Hall</author>
<author>Vaclav Novák</author>
</authors>
<title>Corrective modeling for non-projective dependency parsing.</title>
<date>2005</date>
<booktitle>In Ninth International Workshop on Parsing Technologies (IWPT).</booktitle>
<contexts>
<context position="2357" citStr="Hall and Novák, 2005" startWordPosition="327" endWordPosition="330">antees good parsing complexity, it is well-known that certain syntactic constructions can only be adequately represented by non-projective dependency structures, where the projection of a head can be discontinuous. This is especially relevant for languages with free or flexible word order. However, recent results in non-projective dependency parsing, especially using data-driven methods, indicate that most non-projective structures required for the analysis of natural language are very nearly projective, differing only minimally from the best projective approximation (Nivre and Nilsson, 2005; Hall and Novák, 2005; McDonald and Pereira, 2006). This raises the question of whether it is possible to characterize a class of mildly non-projective dependency structures that is rich enough to account for naturally occurring syntactic constructions, yet restricted enough to enable efficient parsing. In this paper, we review a number of proposals for classes of dependency structures that lie between strictly projective and completely unrestricted non-projective structures. These classes have in common that they can be characterized in terms of properties of the dependency structures themselves, rather than in t</context>
<context position="23490" citStr="Hall and Novák, 2005" startWordPosition="4051" endWordPosition="4054">3%) and the minimal degrees of non-projectivity required to cover the full data (gap degree 4 and edge degree 6) are higher than in DDT. The proportion of planar analyses is smaller than in DDT if we base it on the set of all structures (82.16%), but significantly larger when based on the set of non-projective structures only (22.93%). However, this is still very far from the well-nestedness constraint, which has almost perfect coverage on both data sets. 4.3 Discussion As a general result, our experiments confirm previous studies on non-projective dependency parsing (Nivre and Nilsson, 2005; Hall and Novák, 2005; 512 McDonald and Pereira, 2006): The phenomenon of non-projectivity cannot be ignored without also ignoring a significant portion of real-world data (around 15% for DDT, and 23% for PDT). At the same time, already a small step beyond projectivity accounts for almost all of the structures occurring in these treebanks. More specifically, we find that already an edge degree restriction of d &lt; 1 covers 98.24% of DDT and 99.54% of PDT, while the same restriction on the gap degree scale achieves a coverage of 99.84% (DDT) and 99.57% (PDT). Together with the previous evidence that both measures als</context>
</contexts>
<marker>Hall, Novák, 2005</marker>
<rawString>Keith Hall and Vaclav Novák. 2005. Corrective modeling for non-projective dependency parsing. In Ninth International Workshop on Parsing Technologies (IWPT).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Hudson</author>
</authors>
<title>An encyclopedia of English grammar and Word Grammar.</title>
<date>2003</date>
<location>http://www.phon.ucl.ac.uk/home/dick/enc/intro.htm,</location>
<contexts>
<context position="18171" citStr="Hudson, 2003" startWordPosition="3145" endWordPosition="3146">the following hierarchy for sets of dependency graphs: projective C planar C well-nested C unrestricted The planarity constraint appears like a very natural one at first sight, as it expresses the intuition that ‘crossing edges are bad’, but still allows a limited form of non-projectivity. However, many authors use planarity in conjunction with a special representation of the root node: either as an artificial node at the sentence boundary, as we mentioned in section 2, or as the target of an infinitely long perpendicular edge coming ‘from the outside’, as in earlier versions of Word Grammar (Hudson, 2003). In these situations, planarity reduces to projectivity, so nothing is gained. Even in cases where planarity is used without a special representation of the root node, it remains a peculiar concept. When we compare it with the notion of gaps, for example, we find that, in a planar dependency tree, every gap .i; j/ must contain the root node r, in the sense that i &lt; r &lt; j: if the gap would only contain non-root nodes k, then the two paths from r to k and from i to j would cross. This particular property does not seem to be mirrored in any linguistic prediction. In contrast to planarity, well-n</context>
</contexts>
<marker>Hudson, 2003</marker>
<rawString>Richard Hudson. 2003. An encyclopedia of English grammar and Word Grammar. http://www.phon.ucl.ac.uk/home/dick/enc/intro.htm, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sylvain Kahane</author>
<author>Alexis Nasr</author>
<author>Owen Rambow</author>
</authors>
<title>Pseudo-projectivity: A polynomially parsable non-projective dependency grammar.</title>
<date>1998</date>
<booktitle>In 36th Annual Meeting of the Association for Computational Linguistics and 18th International Conference on Computational Linguistics (COLING-ACL),</booktitle>
<pages>646--652</pages>
<contexts>
<context position="13742" citStr="Kahane et al. (1998)" startWordPosition="2394" endWordPosition="2398">ependent is (1, 5), but the root of the connected component f2, 3, 4g is dominated by 1. Both Graph 3b and 3c have edge degree 1: the edge (3, 6) in Graph 3b and the edges (2, 4), (3, 5) and (4, 6) in Graph 3c each span a single connected component that is not dominated by the respective head. 3.4 Related work Apart from proposals for structural constraints relaxing projectivity, there are dependency frameworks that in principle allow unrestricted graphs, but provide mechanisms to control the actually permitted forms of non-projectivity in the grammar. The non-projective dependency grammar of Kahane et al. (1998) is based on an operation on dependency trees called lifting: a ‘lift’ of a tree T is the new tree that is obtained when one replaces one 2We use the term edge degree instead of the original simple term degree from Nivre (2006) to mark the distinction from the notion of gap degree. or more edges (i, k) in T by edges (j, k), where j !* i. The exact conditions under which a certain lifting may take place are specified in the rules of the grammar. A dependency tree is acceptable, if it can be lifted to form a projective graph.3 A similar design is pursued in Topological Dependency Grammar (Duchie</context>
</contexts>
<marker>Kahane, Nasr, Rambow, 1998</marker>
<rawString>Sylvain Kahane, Alexis Nasr, and Owen Rambow. 1998. Pseudo-projectivity: A polynomially parsable non-projective dependency grammar. In 36th Annual Meeting of the Association for Computational Linguistics and 18th International Conference on Computational Linguistics (COLING-ACL), pages 646–652.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthias Trautner Kromann</author>
</authors>
<title>The Danish Dependency Treebank and the DTAG treebank tool.</title>
<date>2003</date>
<booktitle>In Second Workshop on Treebanks and Linguistic Theories (TLT),</booktitle>
<pages>217--220</pages>
<contexts>
<context position="3316" citStr="Kromann, 2003" startWordPosition="473" endWordPosition="474"> dependency structures that lie between strictly projective and completely unrestricted non-projective structures. These classes have in common that they can be characterized in terms of properties of the dependency structures themselves, rather than in terms of grammar formalisms that generate the structures. We compare the proposals from a theoretical point of view, and evaluate a subset of them empirically by testing their representational adequacy with respect to two dependency treebanks: the Prague Dependency Treebank (PDT) (Hajiˇc et al., 2001), and the Danish Dependency Treebank (DDT) (Kromann, 2003). The rest of the paper is structured as follows. In section 2, we provide a formal definition of dependency structures as a special kind of directed graphs, and characterize the notion of projectivity. In section 3, we define and compare five different constraints on mildly non-projective dependency structures that can be found in the literature: planarity, multiplanarity, well-nestedness, gap degree, and edge degree. In section 4, we provide an experimental evaluation of the notions of planarity, well-nestedness, gap degree, and edge degree, by 507 Proceedings of the COLING/ACL 2006 Main Con</context>
<context position="20069" citStr="Kromann, 2003" startWordPosition="3451" endWordPosition="3453">s section, we present an experimental evaluation of planarity, well-nestedness, gap degree, and edge degree, by examining how large a proportion of the structures found in two dependency treebanks are allowed under different constraints. Assuming that the treebank structures are sampled from naturally occurring structures in natural language, this provides an indirect evaluation of the linguistic adequacy of the different proposals. 4.1 Experimental setup The experiments are based on data from the Prague Dependency Treebank (PDT) (Hajiˇc et al., 2001) and the Danish Dependency Treebank (DDT) (Kromann, 2003). PDT contains 1.5M words of newspaper text, annotated in three layers according to the theoretical framework of Functional Generative Description (Böhmová et al., 2003). Our experiments concern only the analytical layer, and are based on the dedicated training section of the treebank. DDT comprises 100k words of text selected from the Danish PAROLE corpus, with annotation 5 1 2 1 2 4 6 4 5 3 3 (a) gd = 2, ed = 1 (b)gd=1,ed=2 511 Table 1: Experimental results for DDT and PDT property all structures gap degree 0 gap degree 1 gap degree 2 gap degree 3 gap degree 4 edge degree 0 edge degree 1 edg</context>
<context position="21289" citStr="Kromann, 2003" startWordPosition="3682" endWordPosition="3683">ee 2 edge degree 3 edge degree 4 edge degree 5 edge degree 6 projective planar well-nested DDT PDT n = 4393 n = 73088 3732 84.95% 56168 76.85% 654 14.89% 16608 22.72% 7 0.16% 307 0.42% – – 4 0.01% – – 1 &lt; 0.01% 3732 84.95% 56168 76.85% 584 13.29% 16585 22.69% 58 1.32% 259 0.35% 17 0.39% 63 0.09% 2 0.05% 10 0.01% – – 2 &lt; 0.01% – – 1 &lt; 0.01% 3732 84.95% 56168 76.85% 3796 86.41% 60048 82.16% 4388 99.89% 73010 99.89% non-projective structures only n = 661 n = 16920 planar well-nested 64 9.68% 3880 22.93% 656 99.24% 16842 99.54% of primary and secondary dependencies based on Discontinuous Grammar (Kromann, 2003). Only primary dependencies are considered in the experiments, which are based on the entire treebank.4 4.2 Results The results of our experiments are given in Table 1. For the binary constraints (planarity, well-nestedness), we simply report the number and percentage of structures in each data set that satisfy the constraint. For the parametric constraints (gap degree, edge degree), we report the number and percentage of structures having degree d (d &gt; 0), where degree 0 is equivalent (for both gap degree and edge degree) to projectivity. For DDT, we see that about 15% of all analyses are non</context>
</contexts>
<marker>Kromann, 2003</marker>
<rawString>Matthias Trautner Kromann. 2003. The Danish Dependency Treebank and the DTAG treebank tool. In Second Workshop on Treebanks and Linguistic Theories (TLT), pages 217–220.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Svetoslav Marinov</author>
<author>Joakim Nivre</author>
</authors>
<title>A datadriven parser for Bulgarian.</title>
<date>2005</date>
<booktitle>In Fourth Workshop on Treebanks and Linguistic Theories (TLT),</booktitle>
<pages>89--100</pages>
<contexts>
<context position="1485" citStr="Marinov and Nivre, 2005" startWordPosition="201" endWordPosition="204">traints theoretically, and provide an experimental evaluation using data from two treebanks, investigating how large a proportion of the structures found in the treebanks are permitted under different constraints. The results indicate that a combination of the well-nestedness constraint and a parametric constraint on discontinuity gives a very good fit with the linguistic data. 1 Introduction Dependency-based representations have become increasingly popular in syntactic parsing, especially for languages that exhibit free or flexible word order, such as Czech (Collins et al., 1999), Bulgarian (Marinov and Nivre, 2005), and Turkish (Eryi˘git and Oflazer, 2006). Many practical implementations of dependency parsing are restricted to projective structures, where the projection of a head word has to form a continuous substring of the sentence. While this constraint guarantees good parsing complexity, it is well-known that certain syntactic constructions can only be adequately represented by non-projective dependency structures, where the projection of a head can be discontinuous. This is especially relevant for languages with free or flexible word order. However, recent results in non-projective dependency pars</context>
</contexts>
<marker>Marinov, Nivre, 2005</marker>
<rawString>Svetoslav Marinov and Joakim Nivre. 2005. A datadriven parser for Bulgarian. In Fourth Workshop on Treebanks and Linguistic Theories (TLT), pages 89– 100.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Fernando Pereira</author>
</authors>
<title>Online learning of approximate dependency parsing algorithms.</title>
<date>2006</date>
<booktitle>In Eleventh Conference of the European Chapter of the Association for Computational Linguistics (EACL).</booktitle>
<contexts>
<context position="2386" citStr="McDonald and Pereira, 2006" startWordPosition="331" endWordPosition="335">mplexity, it is well-known that certain syntactic constructions can only be adequately represented by non-projective dependency structures, where the projection of a head can be discontinuous. This is especially relevant for languages with free or flexible word order. However, recent results in non-projective dependency parsing, especially using data-driven methods, indicate that most non-projective structures required for the analysis of natural language are very nearly projective, differing only minimally from the best projective approximation (Nivre and Nilsson, 2005; Hall and Novák, 2005; McDonald and Pereira, 2006). This raises the question of whether it is possible to characterize a class of mildly non-projective dependency structures that is rich enough to account for naturally occurring syntactic constructions, yet restricted enough to enable efficient parsing. In this paper, we review a number of proposals for classes of dependency structures that lie between strictly projective and completely unrestricted non-projective structures. These classes have in common that they can be characterized in terms of properties of the dependency structures themselves, rather than in terms of grammar formalisms th</context>
<context position="23523" citStr="McDonald and Pereira, 2006" startWordPosition="4056" endWordPosition="4059">s of non-projectivity required to cover the full data (gap degree 4 and edge degree 6) are higher than in DDT. The proportion of planar analyses is smaller than in DDT if we base it on the set of all structures (82.16%), but significantly larger when based on the set of non-projective structures only (22.93%). However, this is still very far from the well-nestedness constraint, which has almost perfect coverage on both data sets. 4.3 Discussion As a general result, our experiments confirm previous studies on non-projective dependency parsing (Nivre and Nilsson, 2005; Hall and Novák, 2005; 512 McDonald and Pereira, 2006): The phenomenon of non-projectivity cannot be ignored without also ignoring a significant portion of real-world data (around 15% for DDT, and 23% for PDT). At the same time, already a small step beyond projectivity accounts for almost all of the structures occurring in these treebanks. More specifically, we find that already an edge degree restriction of d &lt; 1 covers 98.24% of DDT and 99.54% of PDT, while the same restriction on the gap degree scale achieves a coverage of 99.84% (DDT) and 99.57% (PDT). Together with the previous evidence that both measures also have computational advantages, </context>
</contexts>
<marker>McDonald, Pereira, 2006</marker>
<rawString>Ryan McDonald and Fernando Pereira. 2006. Online learning of approximate dependency parsing algorithms. In Eleventh Conference of the European Chapter of the Association for Computational Linguistics (EACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Fernando Pereira</author>
<author>Kiril Ribarov</author>
<author>Jan Hajiˇc</author>
</authors>
<title>Non-projective dependency parsing using spanning tree algorithms.</title>
<date>2005</date>
<booktitle>In 43rd Annual Meeting of the Association for Computational Linguistics (ACL).</booktitle>
<marker>McDonald, Pereira, Ribarov, Hajiˇc, 2005</marker>
<rawString>Ryan McDonald, Fernando Pereira, Kiril Ribarov, and Jan Hajiˇc. 2005. Non-projective dependency parsing using spanning tree algorithms. In 43rd Annual Meeting of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Igor Mel’ˇcuk</author>
</authors>
<title>Dependency Syntax: Theory and Practice.</title>
<date>1988</date>
<publisher>State University of New York Press,</publisher>
<location>Albany, New York, USA.</location>
<marker>Mel’ˇcuk, 1988</marker>
<rawString>Igor Mel’ˇcuk. 1988. Dependency Syntax: Theory and Practice. State University of New York Press, Albany, New York, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Jens Nilsson</author>
</authors>
<title>Pseudoprojective dependency parsing.</title>
<date>2005</date>
<booktitle>In 43rd Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>99--106</pages>
<contexts>
<context position="2335" citStr="Nivre and Nilsson, 2005" startWordPosition="323" endWordPosition="326">hile this constraint guarantees good parsing complexity, it is well-known that certain syntactic constructions can only be adequately represented by non-projective dependency structures, where the projection of a head can be discontinuous. This is especially relevant for languages with free or flexible word order. However, recent results in non-projective dependency parsing, especially using data-driven methods, indicate that most non-projective structures required for the analysis of natural language are very nearly projective, differing only minimally from the best projective approximation (Nivre and Nilsson, 2005; Hall and Novák, 2005; McDonald and Pereira, 2006). This raises the question of whether it is possible to characterize a class of mildly non-projective dependency structures that is rich enough to account for naturally occurring syntactic constructions, yet restricted enough to enable efficient parsing. In this paper, we review a number of proposals for classes of dependency structures that lie between strictly projective and completely unrestricted non-projective structures. These classes have in common that they can be characterized in terms of properties of the dependency structures themse</context>
<context position="23468" citStr="Nivre and Nilsson, 2005" startWordPosition="4047" endWordPosition="4050">tive structures (around 23%) and the minimal degrees of non-projectivity required to cover the full data (gap degree 4 and edge degree 6) are higher than in DDT. The proportion of planar analyses is smaller than in DDT if we base it on the set of all structures (82.16%), but significantly larger when based on the set of non-projective structures only (22.93%). However, this is still very far from the well-nestedness constraint, which has almost perfect coverage on both data sets. 4.3 Discussion As a general result, our experiments confirm previous studies on non-projective dependency parsing (Nivre and Nilsson, 2005; Hall and Novák, 2005; 512 McDonald and Pereira, 2006): The phenomenon of non-projectivity cannot be ignored without also ignoring a significant portion of real-world data (around 15% for DDT, and 23% for PDT). At the same time, already a small step beyond projectivity accounts for almost all of the structures occurring in these treebanks. More specifically, we find that already an edge degree restriction of d &lt; 1 covers 98.24% of DDT and 99.54% of PDT, while the same restriction on the gap degree scale achieves a coverage of 99.84% (DDT) and 99.57% (PDT). Together with the previous evidence </context>
</contexts>
<marker>Nivre, Nilsson, 2005</marker>
<rawString>Joakim Nivre and Jens Nilsson. 2005. Pseudoprojective dependency parsing. In 43rd Annual Meeting of the Association for Computational Linguistics (ACL), pages 99–106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
</authors>
<title>An efficient algorithm for projective dependency parsing.</title>
<date>2003</date>
<booktitle>In Eigth International Workshop on Parsing Technologies (IWPT),</booktitle>
<pages>149--160</pages>
<contexts>
<context position="8088" citStr="Nivre, 2003" startWordPosition="1307" endWordPosition="1308"> an interesting constraint on dependency structures both from a theoretical and a practical perspective. Dependency grammars that only allow projective structures are closely related to context-free grammars (Gaifman, 1965; Obre¸bski and Grali´nski, 2004); among other things, they have the same (weak) expressivity. The projectivity constraint also leads to favourable parsing complexities: chart-based parsing of projective dependency grammars can be done in cubic time (Eisner, 1996); hard-wiring projectivity into a deterministic dependency parser leads to linear-time parsing in the worst case (Nivre, 2003). 508 3 Relaxations of projectivity While the restriction to projective analyses has a number of advantages, there is clear evidence that it cannot be maintained for real-world data (Zeman, 2004; Nivre, 2006). For example, the graph in Figure 1 is non-projective: the yield of the node 1 (marked by the dashed rectangles) does not form an interval—the node 2 is ‘missing’. In this section, we present several proposals for structural constraints that relax projectivity, and relate them to each other. 3.1 Planarity and multiplanarity The notion of planarity appears in work on Link Grammar (Sleator </context>
</contexts>
<marker>Nivre, 2003</marker>
<rawString>Joakim Nivre. 2003. An efficient algorithm for projective dependency parsing. In Eigth International Workshop on Parsing Technologies (IWPT), pages 149–160.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
</authors>
<title>Constraints on non-projective dependency parsing.</title>
<date>2006</date>
<booktitle>In Eleventh Conference of the European Chapter of the Association for Computational Linguistics (EACL).</booktitle>
<contexts>
<context position="8296" citStr="Nivre, 2006" startWordPosition="1339" endWordPosition="1340">(Gaifman, 1965; Obre¸bski and Grali´nski, 2004); among other things, they have the same (weak) expressivity. The projectivity constraint also leads to favourable parsing complexities: chart-based parsing of projective dependency grammars can be done in cubic time (Eisner, 1996); hard-wiring projectivity into a deterministic dependency parser leads to linear-time parsing in the worst case (Nivre, 2003). 508 3 Relaxations of projectivity While the restriction to projective analyses has a number of advantages, there is clear evidence that it cannot be maintained for real-world data (Zeman, 2004; Nivre, 2006). For example, the graph in Figure 1 is non-projective: the yield of the node 1 (marked by the dashed rectangles) does not form an interval—the node 2 is ‘missing’. In this section, we present several proposals for structural constraints that relax projectivity, and relate them to each other. 3.1 Planarity and multiplanarity The notion of planarity appears in work on Link Grammar (Sleator and Temperley, 1993), where it is traced back to Mel’ˇcuk (1988). Informally, a dependency graph is planar, if its edges can be drawn above the sentence without crossing. We emphasize the word above, because </context>
<context position="12355" citStr="Nivre (2006)" startWordPosition="2129" endWordPosition="2130">T1 and l2, r2 E T2 such that l1 &lt; l2 &lt; r1 &lt; r2. A dependency graph is well-nested, if no two of its disjoint subtrees interleave. Both Graph 3a and Graph 3b are well-nested. Graph 3c is not well-nested. To see this, let T1 be the subtree rooted at the node labelled i, and let T2 be the subtree rooted at j. These subtrees interleave, as T1 contains the nodes 2 and 4, and T2 contains the nodes 3 and 5. 509 1 2 i 3 4 5 6 j 1 2 i 3 4 5 6 j 1 2 i 3 4 5 6 j (a) gd = 0, ed = 0, wnC (b) gd = 1, ed = 1, wnC (c) gd = 2, ed = 1, wn� -nestedness 3.3 Edge degree The notion of edge degree was introduced by Nivre (2006) in order to allow mildly non-projective structures while maintaining good parsing efficiency in data-driven dependency parsing.2 Define the span of an edge (i, j) as the interval S((i, j)) W= [min(i, j),max(i, j)]. Definition 9 Let G = (V I E) be a dependency forest, let e = (i, j) be an edge in E, and let Ge be the subgraph of G that is induced by the nodes contained in the span of e. • The degree of an edge e 2 E, ed(e), is the number of connected components c in Ge such that the root of c is not dominated by the head of e. • The edge degree of G, ed(G), is the maximum among the degrees of </context>
<context position="13969" citStr="Nivre (2006)" startWordPosition="2441" endWordPosition="2442">ted component that is not dominated by the respective head. 3.4 Related work Apart from proposals for structural constraints relaxing projectivity, there are dependency frameworks that in principle allow unrestricted graphs, but provide mechanisms to control the actually permitted forms of non-projectivity in the grammar. The non-projective dependency grammar of Kahane et al. (1998) is based on an operation on dependency trees called lifting: a ‘lift’ of a tree T is the new tree that is obtained when one replaces one 2We use the term edge degree instead of the original simple term degree from Nivre (2006) to mark the distinction from the notion of gap degree. or more edges (i, k) in T by edges (j, k), where j !* i. The exact conditions under which a certain lifting may take place are specified in the rules of the grammar. A dependency tree is acceptable, if it can be lifted to form a projective graph.3 A similar design is pursued in Topological Dependency Grammar (Duchier and Debusmann, 2001), where a dependency analysis consists of two, mutually constraining graphs: the ID graph represents information about immediate dominance, the LP graph models the topological structure of a sentence. As a</context>
<context position="16821" citStr="Nivre (2006)" startWordPosition="2926" endWordPosition="2927">gree measures the number of discontinuities within a subtree, while the edge degree measures the number of intervening constituents spanned by a single edge. This difference is illustrated by the graphs displayed in Figure 4. Graph 4a has gap degree 2 but edge degree 1: the subtree rooted at node 2 (marked by the solid edges) has two gaps, but each of its edges only spans one connected component not dominated by 2 (marked by the squares). In contrast, Graph 4b has gap degree 1 but edge degree 2: the subtree rooted at node 2 has one gap, but this gap contains two components not dominated by 2. Nivre (2006) shows experimentally that limiting the permissible edge degree to 1 or 2 can reduce the average parsing time for a deterministic algorithm from quadratic to linear, while omitting less than 1% of the structures found in DDT and PDT. It can be expected that constraints on the gap degree would have very similar effects. Binary constraints For the two binary constraints, we find that well-nestedness subsumes planarity: a graph that contains interleaving subtrees cannot be drawn without crossing edges, so every planar graph must also be well-nested. To see that the converse does not hold, conside</context>
</contexts>
<marker>Nivre, 2006</marker>
<rawString>Joakim Nivre. 2006. Constraints on non-projective dependency parsing. In Eleventh Conference of the European Chapter of the Association for Computational Linguistics (EACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Obre¸bski</author>
<author>F Grali´nski</author>
</authors>
<title>Some notes on generative capacity of dependency grammar.</title>
<date>2004</date>
<booktitle>In COLING 2004 Workshop on Recent Advances in Dependency Grammar Workshop on Recent Advances in Dependency Grammar.</booktitle>
<marker>Obre¸bski, Grali´nski, 2004</marker>
<rawString>T. Obre¸bski and F. Grali´nski. 2004. Some notes on generative capacity of dependency grammar. In COLING 2004 Workshop on Recent Advances in Dependency Grammar Workshop on Recent Advances in Dependency Grammar.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Plátek</author>
<author>Tomáš Holan</author>
<author>Vladislav Kuboˇn</author>
</authors>
<title>On relax-ability of word order by d-grammars.</title>
<date>2001</date>
<booktitle>In Third International Conference on Discrete Mathematics and Theoretical Computer Science.</booktitle>
<marker>Plátek, Holan, Kuboˇn, 2001</marker>
<rawString>Martin Plátek, Tomáš Holan, and Vladislav Kuboˇn. 2001. On relax-ability of word order by d-grammars. In Third International Conference on Discrete Mathematics and Theoretical Computer Science.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Giorgio Satta</author>
</authors>
<title>Recognition of linear contextfree rewriting systems.</title>
<date>1992</date>
<booktitle>In 30th Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>89--95</pages>
<location>Newark, Delaware, USA.</location>
<contexts>
<context position="19305" citStr="Satta (1992)" startWordPosition="3341" endWordPosition="3342"> to be mirrored in any linguistic prediction. In contrast to planarity, well-nestedness is independent from both gap degree and edge degree in the sense that for every d &gt; 0, there are both wellnested and non-well-nested dependency graphs with gap degree or edge degree d. All projective dependency graphs (d = 0) are trivially well-nested. Well-nestedness also brings computational benefits. In particular, chart-based parsers for grammar formalisms in which derivations obey the well-nestedness constraint (such as Tree Adjoining Grammar) are not hampered by the ‘crossing configurations’ to which Satta (1992) attributes the fact that the universal recognition problem of Linear Context-Free Rewriting Systems is X30-complete. 4 Experimental evaluation In this section, we present an experimental evaluation of planarity, well-nestedness, gap degree, and edge degree, by examining how large a proportion of the structures found in two dependency treebanks are allowed under different constraints. Assuming that the treebank structures are sampled from naturally occurring structures in natural language, this provides an indirect evaluation of the linguistic adequacy of the different proposals. 4.1 Experimen</context>
</contexts>
<marker>Satta, 1992</marker>
<rawString>Giorgio Satta. 1992. Recognition of linear contextfree rewriting systems. In 30th Meeting of the Association for Computational Linguistics (ACL), pages 89–95, Newark, Delaware, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Sleator</author>
<author>Davy Temperley</author>
</authors>
<title>Parsing English with a link grammar.</title>
<date>1993</date>
<booktitle>In Third International Workshop on Parsing Technologies.</booktitle>
<contexts>
<context position="8708" citStr="Sleator and Temperley, 1993" startWordPosition="1404" endWordPosition="1407">e, 2003). 508 3 Relaxations of projectivity While the restriction to projective analyses has a number of advantages, there is clear evidence that it cannot be maintained for real-world data (Zeman, 2004; Nivre, 2006). For example, the graph in Figure 1 is non-projective: the yield of the node 1 (marked by the dashed rectangles) does not form an interval—the node 2 is ‘missing’. In this section, we present several proposals for structural constraints that relax projectivity, and relate them to each other. 3.1 Planarity and multiplanarity The notion of planarity appears in work on Link Grammar (Sleator and Temperley, 1993), where it is traced back to Mel’ˇcuk (1988). Informally, a dependency graph is planar, if its edges can be drawn above the sentence without crossing. We emphasize the word above, because planarity as it is understood here does not coincide with the standard graph-theoretic concept of the same name, where one would be allowed to also use the area below the sentence to disentangle the edges. Figure 2a shows a dependency graph that is planar but not projective: while there are no crossing edges, the yield of the node 1 (the set 11, 3}) does not form an interval. Using the notation linked(i, j) a</context>
</contexts>
<marker>Sleator, Temperley, 1993</marker>
<rawString>Daniel Sleator and Davy Temperley. 1993. Parsing English with a link grammar. In Third International Workshop on Parsing Technologies.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Neil J A Sloane</author>
</authors>
<title>The on-line encyclopedia of integer sequences.</title>
<date>2006</date>
<note>Published electronically at http://www.research.att.com/ njas/sequences/.</note>
<marker>Sloane, 2006</marker>
<rawString>Neil J. A. Sloane. 2006. The on-line encyclopedia of integer sequences. Published electronically at http://www.research.att.com/ njas/sequences/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anssi Yli-Jyrä</author>
</authors>
<title>Multiplanarity – a model for dependency structures in treebanks.</title>
<date>2003</date>
<booktitle>In Second Workshop on Treebanks and Linguistic Theories (TLT),</booktitle>
<pages>189--200</pages>
<contexts>
<context position="9580" citStr="Yli-Jyrä (2003)" startWordPosition="1569" endWordPosition="1570">d graph-theoretic concept of the same name, where one would be allowed to also use the area below the sentence to disentangle the edges. Figure 2a shows a dependency graph that is planar but not projective: while there are no crossing edges, the yield of the node 1 (the set 11, 3}) does not form an interval. Using the notation linked(i, j) as an abbreviation for the statement ‘there is an edge from i to j, or vice versa’, we formalize planarity as follows: Definition 4 A dependency graph is planar, if it does not contain nodes a, b, c, d such that linked(a, c) A linked(b, d) A a &lt; b &lt; c &lt; d . Yli-Jyrä (2003) proposes multiplanarity as a generalization of planarity suitable for modelling dependency analyses, and evaluates it experimentally using data from DDT. Definition 5 A dependency graph G = (V ; E) is m-planar, if it can be split into m planar graphs G1 = (V ; E1), ... , Gm = (V ; Em) such that E = E1U- - -UEm. The planar graphs Gi are called planes. As an example of a dependency forest that is 2- planar but not planar, consider the graph depicted in Figure 2b. In this graph, the edges (1, 4) and (3, 5) are crossing. Moving either edge to a separate graph partitions the original graph into tw</context>
<context position="15840" citStr="Yli-Jyrä (2003)" startWordPosition="2755" endWordPosition="2756">lanar for some sufficiently large m (put each edge onto a separate plane), the interesting question in the context of multiplanarity is about the minimal values for m that occur in real-world data. But then, one not only needs to show that a dependency graph can be decomposed into m planar graphs, but also that this decomposition is the one with the smallest number of planes among all possible decompositions. Up to now, no tractable algorithm to find the minimal decomposition has been given, so itis not clear how to evaluate the significance of the concept as such. The evaluation presented by Yli-Jyrä (2003) makes use of additional constraints that are sufficient to make the decomposition unique. Figure 3: Gap degree, edge degree, and well 3We remark that, without restrictions on the lifting, every non-projective tree has a projective lift. 510 Figure 4: Comparing gap degree and edge degree The fundamental difference between gap degree and edge degree is that the gap degree measures the number of discontinuities within a subtree, while the edge degree measures the number of intervening constituents spanned by a single edge. This difference is illustrated by the graphs displayed in Figure 4. Graph</context>
</contexts>
<marker>Yli-Jyrä, 2003</marker>
<rawString>Anssi Yli-Jyrä. 2003. Multiplanarity – a model for dependency structures in treebanks. In Second Workshop on Treebanks and Linguistic Theories (TLT), pages 189–200.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Zeman</author>
</authors>
<title>Parsing With a Statistical Dependency Model.</title>
<date>2004</date>
<tech>Ph.D. thesis,</tech>
<institution>Charles University,</institution>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="8282" citStr="Zeman, 2004" startWordPosition="1337" endWordPosition="1338">ree grammars (Gaifman, 1965; Obre¸bski and Grali´nski, 2004); among other things, they have the same (weak) expressivity. The projectivity constraint also leads to favourable parsing complexities: chart-based parsing of projective dependency grammars can be done in cubic time (Eisner, 1996); hard-wiring projectivity into a deterministic dependency parser leads to linear-time parsing in the worst case (Nivre, 2003). 508 3 Relaxations of projectivity While the restriction to projective analyses has a number of advantages, there is clear evidence that it cannot be maintained for real-world data (Zeman, 2004; Nivre, 2006). For example, the graph in Figure 1 is non-projective: the yield of the node 1 (marked by the dashed rectangles) does not form an interval—the node 2 is ‘missing’. In this section, we present several proposals for structural constraints that relax projectivity, and relate them to each other. 3.1 Planarity and multiplanarity The notion of planarity appears in work on Link Grammar (Sleator and Temperley, 1993), where it is traced back to Mel’ˇcuk (1988). Informally, a dependency graph is planar, if its edges can be drawn above the sentence without crossing. We emphasize the word a</context>
</contexts>
<marker>Zeman, 2004</marker>
<rawString>Daniel Zeman. 2004. Parsing With a Statistical Dependency Model. Ph.D. thesis, Charles University, Prague, Czech Republic.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>