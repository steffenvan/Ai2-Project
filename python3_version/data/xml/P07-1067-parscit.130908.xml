<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000220">
<title confidence="0.9987935">
Coreference Resolution Using Semantic Relatedness Information from
Automatically Discovered Patterns
</title>
<author confidence="0.997242">
Xiaofeng Yang Jian Su
</author>
<affiliation confidence="0.99471">
Institute for Infocomm Research
</affiliation>
<address confidence="0.966285">
21 Heng Mui Keng Terrace, Singapore, 119613
</address>
<email confidence="0.999074">
{xiaofengy,sujian}@i2r.a-star.edu.sg
</email>
<sectionHeader confidence="0.9986" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999960833333333">
Semantic relatedness is a very important fac-
tor for the coreference resolution task. To
obtain this semantic information, corpus-
based approaches commonly leverage pat-
terns that can express a specific semantic
relation. The patterns, however, are de-
signed manually and thus are not necessar-
ily the most effective ones in terms of ac-
curacy and breadth. To deal with this prob-
lem, in this paper we propose an approach
that can automatically find the effective pat-
terns for coreference resolution. We explore
how to automatically discover and evaluate
patterns, and how to exploit the patterns to
obtain the semantic relatedness information.
The evaluation on ACE data set shows that
the pattern based semantic information is
helpful for coreference resolution.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999962321428571">
Semantic relatedness is a very important factor for
coreference resolution, as noun phrases used to re-
fer to the same entity should have a certain semantic
relation. To obtain this semantic information, previ-
ous work on reference resolution usually leverages
a semantic lexicon like WordNet (Vieira and Poe-
sio, 2000; Harabagiu et al., 2001; Soon et al., 2001;
Ng and Cardie, 2002). However, the drawback of
WordNet is that many expressions (especially for
proper names), word senses and semantic relations
are not available from the database (Vieira and Poe-
sio, 2000). In recent years, increasing interest has
been seen in mining semantic relations from large
text corpora. One common solution is to utilize a
pattern that can represent a specific semantic rela-
tion (e.g., “X such as Y” for is-a relation, and “X
and other Y” for other-relation). Instantiated with
two given noun phrases, the pattern is searched in a
large corpus and the occurrence number is used as
a measure of their semantic relatedness (Markert et
al., 2003; Modjeska et al., 2003; Poesio et al., 2004).
However, in the previous pattern based ap-
proaches, the selection of the patterns to represent a
specific semantic relation is done in an ad hoc way,
usually by linguistic intuition. The manually se-
lected patterns, nevertheless, are not necessarily the
most effective ones for coreference resolution from
the following two concerns:
</bodyText>
<listItem confidence="0.982687">
• Accuracy. Can the patterns (e.g., “X such as
Y”) find as many NP pairs of the specific se-
mantic relation (e.g. is-a) as possible, with a
high precision?
• Breadth. Can the patterns cover a wide variety
of semantic relations, not just is-a, by which
</listItem>
<bodyText confidence="0.9368139">
coreference relationship is realized? For ex-
ample, in some annotation schemes like ACE,
“Beijing:China” are coreferential as the capital
and the country could be used to represent the
government. The pattern for the common “is-
a” relation will fail to identify the NP pairs of
such a “capital-country” relation.
To deal with this problem, in this paper we pro-
pose an approach which can automatically discover
effective patterns to represent the semantic relations
</bodyText>
<page confidence="0.95816">
528
</page>
<note confidence="0.8683155">
Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 528–535,
Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics
</note>
<bodyText confidence="0.4492325">
for coreference resolution. We explore two issues in
our study:
</bodyText>
<listItem confidence="0.946451777777778">
(1) How to automatically acquire and evaluate
the patterns? We utilize a set of coreferential NP
pairs as seeds. For each seed pair, we search a large
corpus for the texts where the two noun phrases co-
occur, and collect the surrounding words as the sur-
face patterns. We evaluate a pattern based on its
commonality or association with the positive seed
pairs.
(2) How to mine the patterns to obtain the seman-
</listItem>
<bodyText confidence="0.96526515">
tic relatedness information for coreference resolu-
tion? We present two strategies to exploit the pat-
terns: choosing the top best patterns as a set of pat-
tern features, or computing the reliability of seman-
tic relatedness as a single feature. In either strategy,
the obtained features are applied to do coreference
resolution in a supervised-learning way.
To our knowledge, our work is the first effort that
systematically explores these issues in the corefer-
ence resolution task. We evaluate our approach on
ACE data set. The experimental results show that
the pattern based semantic relatedness information
is helpful for the coreference resolution.
The remainder of the paper is organized as fol-
lows. Section 2 gives some related work. Section 3
introduces the framework for coreference resolution.
Section 4 presents the model to obtain the pattern-
based semantic relatedness information. Section 5
discusses the experimental results. Finally, Section
6 summarizes the conclusions.
</bodyText>
<sectionHeader confidence="0.999887" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999934903225807">
Earlier work on coreference resolution commonly
relies on semantic lexicons for semantic relatedness
knowledge. In the system by Vieira and Poesio
(2000), for example, WordNet is consulted to obtain
the synonymy, hypernymy and meronymy relations
for resolving the definite anaphora. In (Harabagiu
et al., 2001), the path patterns in WordNet are uti-
lized to compute the semantic consistency between
NPs. Recently, Ponzetto and Strube (2006) suggest
to mine semantic relatedness from Wikipedia, which
can deal with the data sparseness problem suffered
by using WordNet.
Instead of leveraging existing lexicons, many
researchers have investigated corpus-based ap-
proaches to mine semantic relations. Garera and
Yarowsky (2006) propose an unsupervised model
which extracts hypernym relation for resloving def-
inite NPs. Their model assumes that a definite NP
and its hypernym words usually co-occur in texts.
Thus, for a definite-NP anaphor, a preceding NP that
has a high co-occurrence statistics in a large corpus
is preferred for the antecedent.
Bean and Riloff (2004) present a system called
BABAR that uses contextual role knowledge to do
coreference resolution. They apply an IE component
to unannotated texts to generate a set of extraction
caseframes. Each caseframe represents a linguis-
tic expression and a syntactic position, e.g. “mur-
der of &lt;NP&gt;”, “killed &lt;patient&gt;”. From the case-
frames, they derive different types of contextual role
knowledge for resolution, for example, whether an
anaphor and an antecedent candidate can be filled
into co-occurring caseframes, or whether they are
substitutable for each other in their caseframes. Dif-
ferent from their system, our approach aims to find
surface patterns that can directly indicate the coref-
erence relation between two NPs.
Hearst (1998) presents a method to automate the
discovery of WordNet relations, by searching for the
corresponding patterns in large text corpora. She ex-
plores several patterns for the hyponymy relation,
including “X such as Y” “X and/or other Y”, “X
including / especially Y” and so on. The use of
Hearst’s style patterns can be seen for the reference
resolution task. Modjeska et al. (2003) explore the
use of the Web to do the other-anaphora resolution.
In their approach, a pattern “X and other Y” is used.
Given an anaphor and a candidate antecedent, the
pattern is instantiated with the two NPs and forms a
query. The query is submitted to the Google search-
ing engine, and the returned hit number is utilized to
compute the semantic relatedness between the two
NPs. In their work, the semantic information is used
as a feature for the learner. Markert et al. (2003) and
Poesio et al. (2004) adopt a similar strategy for the
bridging anaphora resolution.
In (Hearst, 1998), the author also proposes to dis-
cover new patterns instead of using the manually
designed ones. She employs a bootstrapping algo-
rithm to learn new patterns from the word pairs with
a known relation. Based on Hearst’s work, Pan-
tel and Pennacchiotti (2006) further give a method
</bodyText>
<page confidence="0.997212">
529
</page>
<bodyText confidence="0.99968675">
which measures the reliability of the patterns based
on the strength of association between patterns and
instances, employing the pointwise mutual informa-
tion (PMI).
</bodyText>
<sectionHeader confidence="0.623377" genericHeader="method">
3 Framework of Coreference Resolution
</sectionHeader>
<bodyText confidence="0.998578145833334">
ative instances are added into the original training
instance set for learning, which will generate a clas-
sifier with the capability of not only antecedent iden-
tification, but also non-anaphorically identification.
The new classier is applied to the testing document
to do coreference resolution as usual.
Our coreference resolution system adopts the
common learning-based framework as employed
by Soon et al. (2001) and Ng and Cardie (2002).
In the learning framework, a training or testing
instance has the form of i{NPi, NPj}, in which
NPj is a possible anaphor and NPi is one of its an-
tecedent candidates. An instance is associated with
a vector of features, which is used to describe the
properties of the two noun phrases as well as their
relationships. In our baseline system, we adopt the
common features for coreference resolution such as
lexical property, distance, string-matching, name-
alias, apposition, grammatical role, number/gender
agreement and so on. The same feature set is de-
scribed in (Ng and Cardie, 2002) for reference.
During training, for each encountered anaphor
NPj, one single positive training instance is created
for its closest antecedent. And a group of negative
training instances is created for every intervening
noun phrases between NPj and the antecedent.
Based on the training instances, a binary classifier
can be generated using any discriminative learning
algorithm, like C5 in our study. For resolution, an
input document is processed from the first NP to the
last. For each encountered NPj, a test instance is
formed for each antecedent candidate, NPi1. This
instance is presented to the classifier to determine
the coreference relationship. NPj will be resolved
to the candidate that is classified as positive (if any)
and has the highest confidence value.
In our study, we augment the common framework
by incorporating non-anaphors into training. We fo-
cus on the non-anaphors that the original classifier
fails to identify. Specifically, we apply the learned
classifier to all the non-anaphors in the training doc-
uments. For each non-anaphor that is classified as
positive, a negative instance is created by pairing the
non-anaphor and its false antecedent. These neg-
1For resolution of pronouns, only the preceding NPs in cur-
rent and previous two sentences are considered as antecedent
candidates. For resolution of non-pronouns, all the preceding
non-pronouns are considered.
</bodyText>
<sectionHeader confidence="0.9742" genericHeader="method">
4 Patterned Based Semantic Relatedness
</sectionHeader>
<subsectionHeader confidence="0.999206">
4.1 Acquiring the Patterns
</subsectionHeader>
<bodyText confidence="0.999972763157895">
To derive patterns to indicate a specific semantic re-
lation, a set of seed NP pairs that have the relation of
interest is needed. As described in the previous sec-
tion, we have a set of training instances formed by
NP pairs with known coreference relationships. We
can just use this set of NP pairs as the seeds. That is,
an instance i{NPi, NPj} will become a seed pair
(Ei:Ej) in which NPi corresponds to Ei and NPj
corresponds to Ej. In creating the seed, for a com-
mon noun, only the head word is retained while for
a proper name, the whole string is kept. For ex-
ample, instance i{“Bill Clinton”, “the former pres-
ident”} will be converted to a NP pair (“Bill Clin-
ton”:“president”).
We create the seed pair for every training instance
i{NPi, NPj}, except when (1) NPi or NPj is a
pronoun; or (2) NPi and NPj have the same head
word. We denote S+ and S- the set of seed pairs
derived from the positive and the negative training
instances, respectively. Note that a seed pair may
possibly belong to S+ can S- at the same time.
For each of the seed NP pairs (Ei:Ej), we search
in a large corpus for the strings that match the reg-
ular expression “Ei * * * Ej” or “Ej * * * Ei”,
where * is a wildcard for any word or symbol. The
regular expression is defined as such that all the co-
occurrences of Ei and Ej with at most three words
(or symbols) in between are retrieved.
For each retrieved string, we extract a surface pat-
tern by replacing expression Ei with a mark &lt;#t1#&gt;
and Ej with &lt;#t2#&gt;. If the string is followed by a
symbol, the symbol will be also included in the pat-
tern. This is to create patterns like “X * * * Y [, . ?]”
where Y, with a high possibility, is the head word,
but not a modifier of another noun phrase.
As an example, consider the pair (“Bill Clin-
ton”:“president”). Suppose that two sentences in a
corpus can be matched by the regular expressions:
</bodyText>
<page confidence="0.953658">
530
</page>
<listItem confidence="0.9350972">
(S1) “ Bill Clinton is elected President of the
United States.”
(S2) “The US President, Mr Bill Clinton, to-
day advised India to move towards nuclear non-
proliferation and begin a dialogue with Pakistan to
</listItem>
<bodyText confidence="0.91631275">
”
... .
The patterns to be extracted for (S1) and (S2), re-
spectively, are
</bodyText>
<equation confidence="0.960168">
P1: &lt;#t1#&gt; is elected &lt;#t2#&gt;
P2: &lt;#t2#&gt; , Mr &lt;#t1#&gt; ,
</equation>
<bodyText confidence="0.999903888888889">
We record the number of strings matched by a pat-
tern p instantiated with (Ei:Ej), noted |(Ei, p, Ej)|,
for later use.
For each seed pair, we generate a list of surface
patterns in the above way. We collect all the pat-
terns derived from the positive seed pairs as a set
of reference patterns, which will be scored and used
to evaluate the semantic relatedness for any new NP
pair.
</bodyText>
<subsectionHeader confidence="0.9640695">
4.2 Scoring the Patterns
4.2.1 Frequency
</subsectionHeader>
<bodyText confidence="0.9999831">
One possible scoring scheme is to evaluate a pat-
tern based on its commonality to positive seed pairs.
The intuition here is that the more often a pattern is
seen for the positive seed pairs, the more indicative
the pattern is to find positive coreferential NP pairs.
Based on this idea, we score a pattern by calculating
the number of positive seed pairs whose pattern list
contains the pattern. Formally, supposing the pat-
tern list associated with a seed pair s is PList(s), the
frequency score of a pattern p is defined as
</bodyText>
<equation confidence="0.92376">
Freqency(p) = |{s|s E S+, p E PList(s)} |(1)
</equation>
<sectionHeader confidence="0.370642" genericHeader="method">
4.2.2 Reliability
</sectionHeader>
<bodyText confidence="0.9997125">
Another possible way to evaluate a pattern is
based on its reliability, i.e., the degree that the pat-
tern is associated with the positive coreferential NPs.
In our study, we use pointwise mutual informa-
tion (Cover and Thomas, 1991) to measure associ-
ation strength, which has been proved effective in
the task of semantic relation identification (Pantel
and Pennacchiotti, 2006). Under pointwise mutual
information (PMI), the strength of association be-
tween two events x and y is defined as follows:
</bodyText>
<equation confidence="0.999701666666667">
P (x, y)
pmi(x, y) = log (2)
P(x)P (y)
</equation>
<bodyText confidence="0.841461">
Thus the association between a pattern p and a
positive seed pair s:(Ei:Ej) is:
</bodyText>
<equation confidence="0.740473">
pmi(p, (Ei : Ej)) = log
</equation>
<bodyText confidence="0.998615">
where |(Ei,p,Ej) |is the count of strings matched
by pattern p instantiated with Ei and Ej. Asterisk *
represents a wildcard, that is:
</bodyText>
<equation confidence="0.992102333333333">
|(Ei, *, Ej) |= E |(Ei, p, Ej) |(4)
PEPList(Ei:Ej)
|(*, p, *) |= E |(Ei, p, Ej) |(5)
(Ei:Ej )ES+US−
|(*, *, *) |= E |(Ei, p, Ej) |(6)
(Ei:Ej)ES+US−;PEPlist(Ei:Ej )
</equation>
<bodyText confidence="0.9988905">
The reliability of pattern is the average strength of
association across each positive seed pair:
</bodyText>
<equation confidence="0.999974666666667">
r(p) = usES+ max Pmi
r Pmi(P,s)
|S +  |(7)
</equation>
<bodyText confidence="0.999705333333333">
Here max pmi is used for the normalization pur-
pose, which is the maximum PMI between all pat-
terns and all positive seed pairs.
</bodyText>
<subsectionHeader confidence="0.9751945">
4.3 Exploiting the Patterns
4.3.1 Patterns Features
</subsectionHeader>
<bodyText confidence="0.999956428571429">
One strategy is to directly use the reference pat-
terns as a set of features for classifier learning and
testing. To select the most effective patterns for
the learner, we rank the patterns according to their
scores and then choose the top patterns (first 100 in
our study) as the features.
As mentioned, the frequency score is based on the
commonality of a pattern to the positive seed pairs.
However, if a pattern also occurs frequently for the
negative seed pairs, it should be not deemed a good
feature as it may lead to many false positive pairs
during real resolution. To take this factor into ac-
count, we filter the patterns based on their accuracy,
which is defined as follows:
</bodyText>
<equation confidence="0.9815335">
Accuracy(p) = |{s|s E S+, p E PList(s)} |(8)
|{s|s E S + U S−, p E PList(s)}|
</equation>
<bodyText confidence="0.999854">
A pattern with an accuracy below threshold 0.5 is
eliminated from the reference pattern set. The re-
maining patterns are sorted as normal, from which
the top 100 patterns are selected as features.
</bodyText>
<figure confidence="0.8910206">
|(Ei,p,Ej)|
|(∗,∗,∗)|
|(Ei,∗,Ej) ||(∗,p,∗)|
|(∗,∗,∗) ||(∗,∗,∗)|
(3)
</figure>
<page confidence="0.975668">
531
</page>
<table confidence="0.999861133333333">
R NWire R NPaper BNews
P F P F R P F
Normal Features 54.5 80.3 64.9 56.6 76.0 64.9 52.7 75.3 62.0
+ ”X such as Y” proper names 55.1 79.0 64.9 56.8 76.1 65.0 52.6 75.1 61.9
all types 55.1 78.3 64.7 56.8 74.7 64.4 53.0 74.4 61.9
+ “X and other Y” proper names 54.7 79.9 64.9 56.4 75.9 64.7 52.6 74.9 61.8
all types 54.8 79.8 65.0 56.4 75.9 64.7 52.8 73.3 61.4
+ pattern features (frequency) proper names 58.7 75.8 66.2 57.5 73.9 64.7 54.0 71.1 61.4
all types 59.7 67.3 63.3 57.4 62.4 59.8 55.9 57.7 56.8
+ pattern features (filtered frequency) proper names 57.8 79.1 66.8 56.9 75.1 64.7 54.1 72.4 61.9
all types 58.1 77.4 66.4 56.8 71.2 63.2 55.0 68.1 60.9
+ pattern features (PMI reliability) proper names 58.8 76.9 66.6 58.1 73.8 65.0 54.3 72.0 61.9
all types 59.6 70.4 64.6 58.7 61.6 60.1 56.0 58.8 57.4
+ single reliability feature proper names 57.4 80.8 67.1 56.6 76.2 65.0 54.0 74.7 62.7
all types 57.7 76.4 65.7 56.7 75.9 64.9 55.1 69.5 61.5
</table>
<tableCaption confidence="0.999926">
Table 1: The results of different systems for coreference resolution
</tableCaption>
<bodyText confidence="0.9997099">
Each selected pattern p is used as a single fea-
ture, PFS,. For an instance i{NPZ, NPj}, a list of
patterns is generated for (EZ:Ej) in the same way as
described in Section 4.1. The value of PFS, for the
instance is simply |(EZ, p, Ej)|.
The set of pattern features is used together with
the other normal features to do the learning and test-
ing. Thus, the actual importance of a pattern in
coreference resolution is automatically determined
in a supervised learning way.
</bodyText>
<subsectionHeader confidence="0.715839">
4.3.2 Semantic Relatedness Feature
</subsectionHeader>
<bodyText confidence="0.999926142857143">
Another strategy is to use only one semantic fea-
ture which is able to reflect the reliability that a NP
pair is related in semantics. Intuitively, a NP pair
with strong semantic relatedness should be highly
associated with as many reliable patterns as possi-
ble. Based on this idea, we define the semantic re-
latedness feature (SRel) as follows:
</bodyText>
<equation confidence="0.995383333333333">
SRel(ifNPi, NPj}) _
1000 * E pmi(p, (Ei : Ej)) * r(p) (9)
PEPList(Ei:Ej)
</equation>
<bodyText confidence="0.9998385">
where pmi(p, (EZ:Ej)) is the pointwise mutual in-
formation between pattern p and a NP pair (EZ:Ej),
as defined in Eq. 3. r(p) is the reliability score of p
(Eq. 7). As a relatedness value is always below 1,
we multiple it by 1000 so that the feature value will
be of integer type with a range from 0 to 1000. Note
that among PList(EZ:Ej), only the reference patterns
are involved in the feature computing.
</bodyText>
<sectionHeader confidence="0.998787" genericHeader="evaluation">
5 Experiments and Discussion
</sectionHeader>
<subsectionHeader confidence="0.878224">
5.1 Experimental setup
</subsectionHeader>
<bodyText confidence="0.99999025">
In our study we did evaluation on the ACE-2 V1.0
corpus (NIST, 2003), which contains two data set,
training and devtest, used for training and testing re-
spectively. Each of these sets is further divided by
three domains: newswire (NWire), newspaper (NPa-
per), and broadcast news (BNews).
An input raw text was preprocessed automati-
cally by a pipeline of NLP components, includ-
ing sentence boundary detection, POS-tagging, Text
Chunking and Named-Entity Recognition. Two dif-
ferent classifiers were learned respectively for re-
solving pronouns and non-pronouns. As mentioned,
the pattern based semantic information was only ap-
plied to the non-pronoun resolution. For evaluation,
Vilain et al. (1995)’s scoring algorithm was adopted
to compute the recall and precision of the whole
coreference resolution.
For pattern extraction and feature computing, we
used Wikipedia, a web-based free-content encyclo-
pedia, as the text corpus. We collected the English
Wikipedia database dump in November 2006 (re-
fer to http://download.wikimedia.org/). After all the
hyperlinks and other html tags were removed, the
whole pure text contains about 220 Million words.
</bodyText>
<subsectionHeader confidence="0.905026">
5.2 Results and Discussion
</subsectionHeader>
<bodyText confidence="0.9988748">
Table 1 lists the performance of different coref-
erence resolution systems. The first line of the
table shows the baseline system that uses only
the common features proposed in (Ng and Cardie,
2002). From the table, our baseline system can
</bodyText>
<page confidence="0.993491">
532
</page>
<table confidence="0.999560636363636">
NO Frequency Frequency (Filtered) PMI Reliabilty
1 &lt;#t1&gt; &lt;#t2&gt; &lt;#t2&gt;  ||&lt;#t1&gt;  |&lt;#t1&gt; : &lt;#t2&gt;
2 &lt;#t2&gt; &lt;#t1&gt; &lt;#t1&gt; ) is a &lt;#t2&gt; &lt;#t2&gt; : &lt;#t1&gt;
3 &lt;#t1&gt; , &lt;#t2&gt; &lt;#t1&gt; ) is an &lt;#t2&gt; &lt;#t1&gt; . the &lt;#t2&gt;
4 &lt;#t2&gt; , &lt;#t1&gt; &lt;#t2&gt; ) is an &lt;#t1&gt; &lt;#t2&gt; ( &lt;#t1&gt; )
5 &lt;#t1&gt; . &lt;#t2&gt; &lt;#t2&gt; ) is a &lt;#t1&gt; &lt;#t1&gt; ( &lt;#t2&gt;
6 &lt;#t1&gt; and &lt;#t2&gt; &lt;#t1&gt; or the &lt;#t2&gt; &lt;#t1&gt; ( &lt;#t2&gt; )
7 &lt;#t2&gt; . &lt;#t1&gt; &lt;#t1&gt; (the &lt;#t2&gt; &lt;#t1&gt;   ||&lt;#t2&gt; |
8 &lt;#t1&gt; . the &lt;#t2&gt; &lt;#t1&gt; . during the &lt;#t2&gt; &lt;#t2&gt;   ||&lt;#t1&gt; |
9 &lt;#t2&gt; and &lt;#t1&gt; &lt;#t1&gt;  |&lt;#t2&gt; &lt;#t2&gt; , the &lt;#t1&gt;
10 &lt;#t1&gt; , the &lt;#t2&gt; &lt;#t1&gt; , an &lt;#t2&gt; &lt;#t1&gt; , the &lt;#t2&gt;
11 &lt;#t2&gt; . the &lt;#t1&gt; &lt;#t1&gt; ) was a &lt;#t2&gt; &lt;#t2&gt; ( &lt;#t1&gt;
12 &lt;#t2&gt; , the &lt;#t1&gt; &lt;#t1&gt; in the &lt;#t2&gt; - &lt;#t1&gt; , &lt;#t2&gt;
13 &lt;#t2&gt; &lt;#t1&gt; , &lt;#t1&gt; - &lt;#t2&gt; &lt;#t1&gt; and the &lt;#t2&gt;
14 &lt;#t1&gt; &lt;#t2&gt; , &lt;#t1&gt; ) was an &lt;#t2&gt; &lt;#t1&gt; . &lt;#t2&gt;
15 &lt;#t1&gt; : &lt;#t2&gt; &lt;#t1&gt; ,many &lt;#t2&gt; &lt;#t1&gt; ) is a &lt;#t2&gt;
16 &lt;#t1&gt; &lt;#t2&gt; . &lt;#t2&gt; ) was a &lt;#t1&gt; &lt;#t1&gt; during the &lt;#t2&gt;
17 &lt;#t2&gt; &lt;#t1&gt; . &lt;#t1&gt; ( &lt;#t2&gt; . &lt;#t1&gt; &lt;#t2&gt; .
18 &lt;#t1&gt; ( &lt;#t2&gt; ) &lt;#t2&gt;  |&lt;#t1&gt; &lt;#t1&gt; ) is an &lt;#t2&gt;
19 &lt;#t1&gt; and the &lt;#t2&gt; &lt;#t1&gt; , not the &lt;#t2&gt; &lt;#t2&gt; in &lt;#t1&gt; .
20 &lt;#t2&gt; ( &lt;#t1&gt; ) &lt;#t2&gt; , many &lt;#t1&gt; &lt;#t2&gt; , &lt;#t1&gt;
. . . . . . . . . . . .
</table>
<tableCaption confidence="0.999725">
Table 2: Top patterns chosen under different scoring schemes
</tableCaption>
<bodyText confidence="0.999950904761905">
achieve a good precision (above 75%-80%) with a
recall around 50%-60%. The overall F-measure for
NWire, NPaper and BNews is 64.9%, 64.9% and
62.0% respectively. The results are comparable to
those reported in (Ng, 2005) which uses similar fea-
tures and gets an F-measure of about 62% for the
same data set.
The rest lines of Table 1 are for the systems us-
ing the pattern based information. In all the sys-
tems, we examine the utility of the semantic infor-
mation in resolving different types of NP Pairs: (1)
NP Pairs containing proper names (i.e., Name:Name
or Name:Definites), and (2) NP Pairs of all types.
In Table 1 (Line 2-5), we also list the results of
incorporating two commonly used patterns, “X(s)
such as Y” and “X and other Y(s)”. We can find that
neither of the manually designed patterns has signif-
icant impact on the resolution performance. For all
the domains, the manual patterns just achieve slight
improvement in recall (below 0.6%), indicating that
coverage of the patterns is not broad enough.
</bodyText>
<subsectionHeader confidence="0.655788">
5.2.1 Pattern Features
</subsectionHeader>
<bodyText confidence="0.99641547826087">
In Section 4.3.1 we propose a strategy that di-
rectly uses the patterns as features. Table 2 lists the
top patterns that are sorted based on frequency, fil-
tered frequency (by accuracy), and PMI reliability,
on the NWire domain for illustration.
From the table, evaluated only based on fre-
quency, the top patterns are those that indicate the
appositive structure like “X, an/a/the Y”. However,
if filtered by accuracy, patterns of such a kind will
be removed. Instead, the top patterns with both high
frequency and high accuracy are those for the copula
structure, like “Xis/was/are Y”. Sorted by PMI reli-
ability, patterns for the above two structures can be
seen in the top of the list. These results are consis-
tent with the findings in (Cimiano and Staab, 2004)
that the appositive and copula structures are indica-
tive to find the is-a relation. Also, the two commonly
used patterns “X(s) such as Y” and “X and other
Y(s)” were found in the feature lists (not shown in
the table). Their importance for coreference resolu-
tion will be determined automatically by the learn-
ing algorithm.
An interesting pattern seen in the lists is “X  ||Y |”,
which represents the cases when Y and X appear in
the same of line of a table in Wikipedia. For exam-
ple, the following text
“American  ||United States  |Washington D.C.  |... ”
is found in the table “list of empires”. Thus the pair
“American:United States”, which is deemed coref-
erential in ACE, can be identified by the pattern.
The sixth till the eleventh lines of Table 1 list the
results of the system with pattern features. From the
table, adding the pattern features brings the improve-
ment of the recall against the baseline. Take the sys-
tem based on filtered frequency as an example. We
can observe that the recall increases by up to 3.3%
(for NWire). However, we see the precision drops
(up to 1.2% for NWire) at the same time. Over-
all the system achieves an F-measure better than the
baseline in NWire (1.9%), while equal (f0.2%) in
NPaper and BNews.
Among the three ranking schemes, simply using
frequency leads to the lowest precision. By contrast,
using filtered frequency yields the highest precision
with nevertheless the lowest recall. It is reasonable
since the low accuracy features prone to false posi-
</bodyText>
<page confidence="0.965602">
533
</page>
<equation confidence="0.975348666666667">
NameAlias = 1: ...
NameAlias = 0:
:..Appositive = 1: ...
Appositive = 0:
:..P014 &gt; 0:
:...P003 &lt;= 4: 0 (3)
: P003 &gt; 4: 1 (25)
P014 &lt;= 0:
:..P004 &gt; 0:...
P004 &lt;= 0:
:..P027 &gt; 0: 1 (25/7)
P027 &lt;= 0:
:..P002 &gt; 0: ...
P002 &lt;= 0:
:..P005 &gt; 0: 1 (49/22)
P005 &lt;= 0:
:..String_Match = 1: .
String_Match = 0: .
</equation>
<table confidence="0.992978666666667">
// p002: &lt;t1&gt; ) is a &lt;t2&gt;
// P003: &lt;t1&gt; ) is an &lt;t2&gt;
// P004: &lt;t2&gt; ) is an &lt;t1&gt;
// p005: &lt;t2&gt; ) is a &lt;t1&gt;
// P014: &lt;t1&gt; ) was an &lt;t2&gt;
// p027: &lt;t1&gt; , ( &lt;t2&gt; ,
</table>
<figureCaption confidence="0.827145">
Figure 1: The decision tree (NWire domain) for the
system using pattern features (filtered frequency)
</figureCaption>
<bodyText confidence="0.992067339622642">
(feature String Match records whether the string of anaphor
NP j matches that of a candidate antecedent NP i)
tive NP pairs are eliminated, at the price of recall.
Using PMI Reliability can achieve the highest re-
call with a medium level of precision. However, we
do not find significant difference in the overall F-
measure for all these three schemes. This should be
due to the fact that the pattern features need to be
further chosen by the learning algorithm, and only
those patterns deemed effective by the learner will
really matter in the real resolution.
From the table, the pattern features only work
well for NP pairs containing proper names. Ap-
plied on all types of NP pairs, the pattern features
further boost the recall of the systems, but in the
meanwhile degrade the precision significantly. The
F-measure of the systems is even worse than that
of the baseline. Our error analysis shows that a
non-anaphor is often wrongly resolved to a false an-
tecedent once the two NPs happen to satisfy a pat-
tern feature, which affects precision largely (as an
evidence, the decrease of precision is less significant
when using filtered frequency than using frequency).
Still, these results suggest that we just apply the pat-
tern based semantic information in resolving proper
names which, in fact, is more compelling as the se-
mantic information of common nouns could be more
easily retrieved from WordNet.
We also notice that the patterned based semantic
information seems more effective in the NWire do-
main than the other two. Especially for NPaper, the
improvement in F-measure is less than 0.1% for all
the systems tested. The error analysis indicates it
may be because (1) there are less NP pairs in NPa-
per than in NWire that require the external seman-
tic knowledge for resolution; and (2) For many NP
pairs that require the semantic knowledge, no co-
occurrence can be found in the Wikipedia corpus.
To address this problem, we could resort to the Web
which contains a larger volume of texts and thus
could lead to more informative patterns. We would
like to explore this issue in our future work.
In Figure 1, we plot the decision tree learned
with the pattern features for non-pronoun resolution
(NWire domain, filtered frequency), which visually
illustrates which features are useful in the reference
determination. We can find the pattern features oc-
cur in the top of the decision tree, among the features
for name alias, apposition and string-matching that
are crucial for coreference resolution as reported in
previous work (Soon et al., 2001). Most of the pat-
tern features deemed important by the learner are for
the copula structure.
</bodyText>
<subsectionHeader confidence="0.867359">
5.2.2 Single Semantic Relatedness Feature
</subsectionHeader>
<bodyText confidence="0.999985037037037">
Section 4.3.2 presents another strategy to exploit
the patterns, which uses a single feature to reflect the
semantic relatedness between NP pairs. The last two
lines of Table 1 list the results of such a system.
Observed from the table, the system with the sin-
gle semantic relatedness feature beats those with
other solutions. Compared with the baseline, the
system can get improvement in recall (up to 2.9%
as in NWire), with a similar or even higher preci-
sion. The overall F-measure it produces is 67.1%,
65.0% and 62.7%, better than the baseline in all the
domains. Especially in the NWire domain, we can
see the significant (t-test, p G 0.05) improvement of
2.1% in F-measure. When applied on All-Type NP
pairs, the degrade of performance is less significant
as using pattern features. The resulting performance
is better than the baseline or equal. Compared with
the systems using the pattern features, it can still
achieve a higher precision and F-measure (with a lit-
tle loss in recall) .
There are several reasons why the single seman-
tic relatedness feature (SRel) can perform better than
the set of pattern features. Firstly, the feature value
of SRel takes into consideration the information of
all the patterns, instead of only the selected patterns.
Secondly, since the SRel feature is computed based
on all the patterns, it reduces the risk of false posi-
</bodyText>
<page confidence="0.957543">
534
</page>
<equation confidence="0.9992178">
NameAlias = 1: ...
NameAlias = 0:
:..Appositive = 1: ...
Appositive = 0:
:..SRel &gt; 28:
:..SRel &gt; 47: ...
: SRel &lt;= 47: ...
SRel &lt;= 28:
:..String_Match = 1: ...
String_Match = 0: ...
</equation>
<figureCaption confidence="0.969663">
Figure 2: The decision tree (Nwire) for the system
using the single semantic relatedness feature
</figureCaption>
<bodyText confidence="0.999065769230769">
tive when a NP pair happens to satisfy one or several
pattern features. Lastly, from the point of view of
machine learning, using only one semantic feature,
instead of hundreds of pattern features, can avoid
overfitting and thus benefit the classifier learning.
In Figure 2, we also show the decision tree learned
with the semantic relatedness feature. We observe
that the decision tree is simpler than that with pat-
tern features as depicted in Figure 1. After feature
name-alias and apposite, the classifier checks dif-
ferent ranges of the SRel value and make different
resolution decision accordingly. This figure further
illustrates the importance of the semantic feature.
</bodyText>
<sectionHeader confidence="0.999779" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.97901875">
In this paper we present a pattern based approach to
coreference resolution. Different from the previous
work which utilizes manually designed patterns, our
approach can automatically discover the patterns ef-
fective for the coreference resolution task. In our
study, we explore how to acquire and evaluate pat-
terns, and investigate how to exploit the patterns to
mine semantic relatedness information for corefer-
ence resolution. The evaluation on ACE data set
shows that the patterned based features, when ap-
plied on NP pairs containing proper names, can ef-
fectively help the performance of coreference res-
olution in the recall (up to 4.3%) and the overall
F-measure (up to 2.1%). The results also indicate
that using the single semantic relatedness feature has
more advantages than using a set of pattern features.
For future work, we intend to investigate our
approach in more difficult tasks like the bridging
anaphora resolution, in which the semantic relations
involved are more complicated. Also, we would like
to explore the approach in technical (e.g., biomedi-
cal) domains, where jargons are frequently seen and
the need for external knowledge is more compelling.
Acknowledgements This research is supported by a
Specific Targeted Research Project (STREP) of the European
Union’s 6th Framework Programme within IST call 4, Boot-
strapping Of Ontologies and Terminologies STrategic REsearch
Project (BOOTStrep).
</bodyText>
<sectionHeader confidence="0.995157" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99977484">
D. Bean and E. Riloff. 2004. Unsupervised learning of contex-
tual role knowledge for coreference resolution. In Proceed-
ings ofNAACL, pages 297–304.
P. Cimiano and S. Staab. 2004. Learning by googling.
SIGKDD Explorations Newsletter, 6(2):24–33.
T. Cover and J. Thomas. 1991. Elements of Information The-
ory. Hohn Wiley &amp; Sons.
N. Garera and D. Yarowsky. 2006. Resolving and generating
definite anaphora by modeling hypernymy using unlabeled
corpora. In Proceedings of CoNLL , pages 37–44.
S. Harabagiu, R. Bunescu, and S. Maiorano. 2001. Text knowl-
edge mining for coreference resolution. In Proceedings of
NAACL, pages 55–62.
M. Hearst. 1998. Automated discovery of wordnet relations. In
Christiane Fellbaum, editor, WordNet: An Electronic Lexical
Database and Some of its Applications. MIT Press, Cam-
bridge, MA.
K. Markert, M. Nissim, and N. Modjeska. 2003. Using the
web for nominal anaphora resolution. In Proceedings of the
EACL workshop on Computational Treatment of Anaphora,
pages 39–46.
N. Modjeska, K. Markert, and M. Nissim. 2003. Using the
web in machine learning for other-anaphora resolution. In
Proceedings ofEMNLP, pages 176–183.
V. Ng and C. Cardie. 2002. Improving machine learning ap-
proaches to coreference resolution. In Proceedings of ACL,
pages 104–111, Philadelphia.
V. Ng. 2005. Machine learning for coreference resolution:
From local classification to global ranking. In Proceedings
ofACL, pages 157–164.
P. Pantel and M. Pennacchiotti. 2006. Espresso: Leveraging
generic patterns for automatically harvesting semantic rela-
tions. In Proceedings ofACL, pages 113–1200.
M. Poesio, R. Mehta, A. Maroudas, and J. Hitzeman. 2004.
Learning to resolve bridging references. In Proceedings of
ACL, pages 143–150.
S. Ponzetto and M. Strube. 2006. Exploiting semantic role
labeling, wordnet and wikipedia for coreference resolution.
In Proceedings ofNAACL, pages 192–199.
W. Soon, H. Ng, and D. Lim. 2001. A machine learning ap-
proach to coreference resolution of noun phrases. Computa-
tional Linguistics, 27(4):521–544.
R. Vieira and M. Poesio. 2000. An empirically based system
for processing definite descriptions. Computational Linguis-
tics, 27(4):539–592.
M. Vilain, J. Burger, J. Aberdeen, D. Connolly, and
L. Hirschman. 1995. A model-theoretic coreference scoring
scheme. In Proceedings of the Sixth Message understand-
ing Conference (MUC-6), pages 45–52, San Francisco, CA.
Morgan Kaufmann Publishers.
</reference>
<page confidence="0.998535">
535
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.936378">
<title confidence="0.9916525">Coreference Resolution Using Semantic Relatedness Information from Automatically Discovered Patterns</title>
<author confidence="0.99969">Xiaofeng Yang Jian Su</author>
<affiliation confidence="0.9998">Institute for Infocomm Research</affiliation>
<address confidence="0.96863">21 Heng Mui Keng Terrace, Singapore, 119613</address>
<abstract confidence="0.999035210526316">Semantic relatedness is a very important factor for the coreference resolution task. To obtain this semantic information, corpusbased approaches commonly leverage patterns that can express a specific semantic relation. The patterns, however, are designed manually and thus are not necessarily the most effective ones in terms of accuracy and breadth. To deal with this problem, in this paper we propose an approach that can automatically find the effective patterns for coreference resolution. We explore how to automatically discover and evaluate patterns, and how to exploit the patterns to obtain the semantic relatedness information. The evaluation on ACE data set shows that the pattern based semantic information is helpful for coreference resolution.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>D Bean</author>
<author>E Riloff</author>
</authors>
<title>Unsupervised learning of contextual role knowledge for coreference resolution.</title>
<date>2004</date>
<booktitle>In Proceedings ofNAACL,</booktitle>
<pages>297--304</pages>
<contexts>
<context position="5866" citStr="Bean and Riloff (2004)" startWordPosition="911" endWordPosition="914">gest to mine semantic relatedness from Wikipedia, which can deal with the data sparseness problem suffered by using WordNet. Instead of leveraging existing lexicons, many researchers have investigated corpus-based approaches to mine semantic relations. Garera and Yarowsky (2006) propose an unsupervised model which extracts hypernym relation for resloving definite NPs. Their model assumes that a definite NP and its hypernym words usually co-occur in texts. Thus, for a definite-NP anaphor, a preceding NP that has a high co-occurrence statistics in a large corpus is preferred for the antecedent. Bean and Riloff (2004) present a system called BABAR that uses contextual role knowledge to do coreference resolution. They apply an IE component to unannotated texts to generate a set of extraction caseframes. Each caseframe represents a linguistic expression and a syntactic position, e.g. “murder of &lt;NP&gt;”, “killed &lt;patient&gt;”. From the caseframes, they derive different types of contextual role knowledge for resolution, for example, whether an anaphor and an antecedent candidate can be filled into co-occurring caseframes, or whether they are substitutable for each other in their caseframes. Different from their sys</context>
</contexts>
<marker>Bean, Riloff, 2004</marker>
<rawString>D. Bean and E. Riloff. 2004. Unsupervised learning of contextual role knowledge for coreference resolution. In Proceedings ofNAACL, pages 297–304.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Cimiano</author>
<author>S Staab</author>
</authors>
<title>Learning by googling.</title>
<date>2004</date>
<journal>SIGKDD Explorations Newsletter,</journal>
<volume>6</volume>
<issue>2</issue>
<contexts>
<context position="22834" citStr="Cimiano and Staab, 2004" startWordPosition="3880" endWordPosition="3883">on frequency, filtered frequency (by accuracy), and PMI reliability, on the NWire domain for illustration. From the table, evaluated only based on frequency, the top patterns are those that indicate the appositive structure like “X, an/a/the Y”. However, if filtered by accuracy, patterns of such a kind will be removed. Instead, the top patterns with both high frequency and high accuracy are those for the copula structure, like “Xis/was/are Y”. Sorted by PMI reliability, patterns for the above two structures can be seen in the top of the list. These results are consistent with the findings in (Cimiano and Staab, 2004) that the appositive and copula structures are indicative to find the is-a relation. Also, the two commonly used patterns “X(s) such as Y” and “X and other Y(s)” were found in the feature lists (not shown in the table). Their importance for coreference resolution will be determined automatically by the learning algorithm. An interesting pattern seen in the lists is “X ||Y |”, which represents the cases when Y and X appear in the same of line of a table in Wikipedia. For example, the following text “American ||United States |Washington D.C. |... ” is found in the table “list of empires”. Thus t</context>
</contexts>
<marker>Cimiano, Staab, 2004</marker>
<rawString>P. Cimiano and S. Staab. 2004. Learning by googling. SIGKDD Explorations Newsletter, 6(2):24–33.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Cover</author>
<author>J Thomas</author>
</authors>
<title>Elements of Information Theory.</title>
<date>1991</date>
<publisher>Hohn Wiley &amp; Sons.</publisher>
<contexts>
<context position="13977" citStr="Cover and Thomas, 1991" startWordPosition="2293" endWordPosition="2296">ore indicative the pattern is to find positive coreferential NP pairs. Based on this idea, we score a pattern by calculating the number of positive seed pairs whose pattern list contains the pattern. Formally, supposing the pattern list associated with a seed pair s is PList(s), the frequency score of a pattern p is defined as Freqency(p) = |{s|s E S+, p E PList(s)} |(1) 4.2.2 Reliability Another possible way to evaluate a pattern is based on its reliability, i.e., the degree that the pattern is associated with the positive coreferential NPs. In our study, we use pointwise mutual information (Cover and Thomas, 1991) to measure association strength, which has been proved effective in the task of semantic relation identification (Pantel and Pennacchiotti, 2006). Under pointwise mutual information (PMI), the strength of association between two events x and y is defined as follows: P (x, y) pmi(x, y) = log (2) P(x)P (y) Thus the association between a pattern p and a positive seed pair s:(Ei:Ej) is: pmi(p, (Ei : Ej)) = log where |(Ei,p,Ej) |is the count of strings matched by pattern p instantiated with Ei and Ej. Asterisk * represents a wildcard, that is: |(Ei, *, Ej) |= E |(Ei, p, Ej) |(4) PEPList(Ei:Ej) |(*</context>
</contexts>
<marker>Cover, Thomas, 1991</marker>
<rawString>T. Cover and J. Thomas. 1991. Elements of Information Theory. Hohn Wiley &amp; Sons.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Garera</author>
<author>D Yarowsky</author>
</authors>
<title>Resolving and generating definite anaphora by modeling hypernymy using unlabeled corpora.</title>
<date>2006</date>
<booktitle>In Proceedings of CoNLL ,</booktitle>
<pages>37--44</pages>
<contexts>
<context position="5523" citStr="Garera and Yarowsky (2006)" startWordPosition="856" endWordPosition="859">ness knowledge. In the system by Vieira and Poesio (2000), for example, WordNet is consulted to obtain the synonymy, hypernymy and meronymy relations for resolving the definite anaphora. In (Harabagiu et al., 2001), the path patterns in WordNet are utilized to compute the semantic consistency between NPs. Recently, Ponzetto and Strube (2006) suggest to mine semantic relatedness from Wikipedia, which can deal with the data sparseness problem suffered by using WordNet. Instead of leveraging existing lexicons, many researchers have investigated corpus-based approaches to mine semantic relations. Garera and Yarowsky (2006) propose an unsupervised model which extracts hypernym relation for resloving definite NPs. Their model assumes that a definite NP and its hypernym words usually co-occur in texts. Thus, for a definite-NP anaphor, a preceding NP that has a high co-occurrence statistics in a large corpus is preferred for the antecedent. Bean and Riloff (2004) present a system called BABAR that uses contextual role knowledge to do coreference resolution. They apply an IE component to unannotated texts to generate a set of extraction caseframes. Each caseframe represents a linguistic expression and a syntactic po</context>
</contexts>
<marker>Garera, Yarowsky, 2006</marker>
<rawString>N. Garera and D. Yarowsky. 2006. Resolving and generating definite anaphora by modeling hypernymy using unlabeled corpora. In Proceedings of CoNLL , pages 37–44.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Harabagiu</author>
<author>R Bunescu</author>
<author>S Maiorano</author>
</authors>
<title>Text knowledge mining for coreference resolution.</title>
<date>2001</date>
<booktitle>In Proceedings of NAACL,</booktitle>
<pages>55--62</pages>
<contexts>
<context position="1357" citStr="Harabagiu et al., 2001" startWordPosition="198" endWordPosition="201">on. We explore how to automatically discover and evaluate patterns, and how to exploit the patterns to obtain the semantic relatedness information. The evaluation on ACE data set shows that the pattern based semantic information is helpful for coreference resolution. 1 Introduction Semantic relatedness is a very important factor for coreference resolution, as noun phrases used to refer to the same entity should have a certain semantic relation. To obtain this semantic information, previous work on reference resolution usually leverages a semantic lexicon like WordNet (Vieira and Poesio, 2000; Harabagiu et al., 2001; Soon et al., 2001; Ng and Cardie, 2002). However, the drawback of WordNet is that many expressions (especially for proper names), word senses and semantic relations are not available from the database (Vieira and Poesio, 2000). In recent years, increasing interest has been seen in mining semantic relations from large text corpora. One common solution is to utilize a pattern that can represent a specific semantic relation (e.g., “X such as Y” for is-a relation, and “X and other Y” for other-relation). Instantiated with two given noun phrases, the pattern is searched in a large corpus and the </context>
<context position="5111" citStr="Harabagiu et al., 2001" startWordPosition="797" endWordPosition="800">ized as follows. Section 2 gives some related work. Section 3 introduces the framework for coreference resolution. Section 4 presents the model to obtain the patternbased semantic relatedness information. Section 5 discusses the experimental results. Finally, Section 6 summarizes the conclusions. 2 Related Work Earlier work on coreference resolution commonly relies on semantic lexicons for semantic relatedness knowledge. In the system by Vieira and Poesio (2000), for example, WordNet is consulted to obtain the synonymy, hypernymy and meronymy relations for resolving the definite anaphora. In (Harabagiu et al., 2001), the path patterns in WordNet are utilized to compute the semantic consistency between NPs. Recently, Ponzetto and Strube (2006) suggest to mine semantic relatedness from Wikipedia, which can deal with the data sparseness problem suffered by using WordNet. Instead of leveraging existing lexicons, many researchers have investigated corpus-based approaches to mine semantic relations. Garera and Yarowsky (2006) propose an unsupervised model which extracts hypernym relation for resloving definite NPs. Their model assumes that a definite NP and its hypernym words usually co-occur in texts. Thus, f</context>
</contexts>
<marker>Harabagiu, Bunescu, Maiorano, 2001</marker>
<rawString>S. Harabagiu, R. Bunescu, and S. Maiorano. 2001. Text knowledge mining for coreference resolution. In Proceedings of NAACL, pages 55–62.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Hearst</author>
</authors>
<title>Automated discovery of wordnet relations.</title>
<date>1998</date>
<booktitle>WordNet: An Electronic Lexical Database and Some of its Applications.</booktitle>
<editor>In Christiane Fellbaum, editor,</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="6596" citStr="Hearst (1998)" startWordPosition="1025" endWordPosition="1026">ponent to unannotated texts to generate a set of extraction caseframes. Each caseframe represents a linguistic expression and a syntactic position, e.g. “murder of &lt;NP&gt;”, “killed &lt;patient&gt;”. From the caseframes, they derive different types of contextual role knowledge for resolution, for example, whether an anaphor and an antecedent candidate can be filled into co-occurring caseframes, or whether they are substitutable for each other in their caseframes. Different from their system, our approach aims to find surface patterns that can directly indicate the coreference relation between two NPs. Hearst (1998) presents a method to automate the discovery of WordNet relations, by searching for the corresponding patterns in large text corpora. She explores several patterns for the hyponymy relation, including “X such as Y” “X and/or other Y”, “X including / especially Y” and so on. The use of Hearst’s style patterns can be seen for the reference resolution task. Modjeska et al. (2003) explore the use of the Web to do the other-anaphora resolution. In their approach, a pattern “X and other Y” is used. Given an anaphor and a candidate antecedent, the pattern is instantiated with the two NPs and forms a </context>
</contexts>
<marker>Hearst, 1998</marker>
<rawString>M. Hearst. 1998. Automated discovery of wordnet relations. In Christiane Fellbaum, editor, WordNet: An Electronic Lexical Database and Some of its Applications. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Markert</author>
<author>M Nissim</author>
<author>N Modjeska</author>
</authors>
<title>Using the web for nominal anaphora resolution.</title>
<date>2003</date>
<booktitle>In Proceedings of the EACL workshop on Computational Treatment of Anaphora,</booktitle>
<pages>39--46</pages>
<contexts>
<context position="2047" citStr="Markert et al., 2003" startWordPosition="313" endWordPosition="316">rdNet is that many expressions (especially for proper names), word senses and semantic relations are not available from the database (Vieira and Poesio, 2000). In recent years, increasing interest has been seen in mining semantic relations from large text corpora. One common solution is to utilize a pattern that can represent a specific semantic relation (e.g., “X such as Y” for is-a relation, and “X and other Y” for other-relation). Instantiated with two given noun phrases, the pattern is searched in a large corpus and the occurrence number is used as a measure of their semantic relatedness (Markert et al., 2003; Modjeska et al., 2003; Poesio et al., 2004). However, in the previous pattern based approaches, the selection of the patterns to represent a specific semantic relation is done in an ad hoc way, usually by linguistic intuition. The manually selected patterns, nevertheless, are not necessarily the most effective ones for coreference resolution from the following two concerns: • Accuracy. Can the patterns (e.g., “X such as Y”) find as many NP pairs of the specific semantic relation (e.g. is-a) as possible, with a high precision? • Breadth. Can the patterns cover a wide variety of semantic relat</context>
<context position="7454" citStr="Markert et al. (2003)" startWordPosition="1172" endWordPosition="1175"> including / especially Y” and so on. The use of Hearst’s style patterns can be seen for the reference resolution task. Modjeska et al. (2003) explore the use of the Web to do the other-anaphora resolution. In their approach, a pattern “X and other Y” is used. Given an anaphor and a candidate antecedent, the pattern is instantiated with the two NPs and forms a query. The query is submitted to the Google searching engine, and the returned hit number is utilized to compute the semantic relatedness between the two NPs. In their work, the semantic information is used as a feature for the learner. Markert et al. (2003) and Poesio et al. (2004) adopt a similar strategy for the bridging anaphora resolution. In (Hearst, 1998), the author also proposes to discover new patterns instead of using the manually designed ones. She employs a bootstrapping algorithm to learn new patterns from the word pairs with a known relation. Based on Hearst’s work, Pantel and Pennacchiotti (2006) further give a method 529 which measures the reliability of the patterns based on the strength of association between patterns and instances, employing the pointwise mutual information (PMI). 3 Framework of Coreference Resolution ative in</context>
</contexts>
<marker>Markert, Nissim, Modjeska, 2003</marker>
<rawString>K. Markert, M. Nissim, and N. Modjeska. 2003. Using the web for nominal anaphora resolution. In Proceedings of the EACL workshop on Computational Treatment of Anaphora, pages 39–46.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Modjeska</author>
<author>K Markert</author>
<author>M Nissim</author>
</authors>
<title>Using the web in machine learning for other-anaphora resolution.</title>
<date>2003</date>
<booktitle>In Proceedings ofEMNLP,</booktitle>
<pages>176--183</pages>
<contexts>
<context position="2070" citStr="Modjeska et al., 2003" startWordPosition="317" endWordPosition="320">ressions (especially for proper names), word senses and semantic relations are not available from the database (Vieira and Poesio, 2000). In recent years, increasing interest has been seen in mining semantic relations from large text corpora. One common solution is to utilize a pattern that can represent a specific semantic relation (e.g., “X such as Y” for is-a relation, and “X and other Y” for other-relation). Instantiated with two given noun phrases, the pattern is searched in a large corpus and the occurrence number is used as a measure of their semantic relatedness (Markert et al., 2003; Modjeska et al., 2003; Poesio et al., 2004). However, in the previous pattern based approaches, the selection of the patterns to represent a specific semantic relation is done in an ad hoc way, usually by linguistic intuition. The manually selected patterns, nevertheless, are not necessarily the most effective ones for coreference resolution from the following two concerns: • Accuracy. Can the patterns (e.g., “X such as Y”) find as many NP pairs of the specific semantic relation (e.g. is-a) as possible, with a high precision? • Breadth. Can the patterns cover a wide variety of semantic relations, not just is-a, by</context>
<context position="6975" citStr="Modjeska et al. (2003)" startWordPosition="1087" endWordPosition="1090">urring caseframes, or whether they are substitutable for each other in their caseframes. Different from their system, our approach aims to find surface patterns that can directly indicate the coreference relation between two NPs. Hearst (1998) presents a method to automate the discovery of WordNet relations, by searching for the corresponding patterns in large text corpora. She explores several patterns for the hyponymy relation, including “X such as Y” “X and/or other Y”, “X including / especially Y” and so on. The use of Hearst’s style patterns can be seen for the reference resolution task. Modjeska et al. (2003) explore the use of the Web to do the other-anaphora resolution. In their approach, a pattern “X and other Y” is used. Given an anaphor and a candidate antecedent, the pattern is instantiated with the two NPs and forms a query. The query is submitted to the Google searching engine, and the returned hit number is utilized to compute the semantic relatedness between the two NPs. In their work, the semantic information is used as a feature for the learner. Markert et al. (2003) and Poesio et al. (2004) adopt a similar strategy for the bridging anaphora resolution. In (Hearst, 1998), the author al</context>
</contexts>
<marker>Modjeska, Markert, Nissim, 2003</marker>
<rawString>N. Modjeska, K. Markert, and M. Nissim. 2003. Using the web in machine learning for other-anaphora resolution. In Proceedings ofEMNLP, pages 176–183.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Ng</author>
<author>C Cardie</author>
</authors>
<title>Improving machine learning approaches to coreference resolution.</title>
<date>2002</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>104--111</pages>
<location>Philadelphia.</location>
<contexts>
<context position="1398" citStr="Ng and Cardie, 2002" startWordPosition="206" endWordPosition="209">r and evaluate patterns, and how to exploit the patterns to obtain the semantic relatedness information. The evaluation on ACE data set shows that the pattern based semantic information is helpful for coreference resolution. 1 Introduction Semantic relatedness is a very important factor for coreference resolution, as noun phrases used to refer to the same entity should have a certain semantic relation. To obtain this semantic information, previous work on reference resolution usually leverages a semantic lexicon like WordNet (Vieira and Poesio, 2000; Harabagiu et al., 2001; Soon et al., 2001; Ng and Cardie, 2002). However, the drawback of WordNet is that many expressions (especially for proper names), word senses and semantic relations are not available from the database (Vieira and Poesio, 2000). In recent years, increasing interest has been seen in mining semantic relations from large text corpora. One common solution is to utilize a pattern that can represent a specific semantic relation (e.g., “X such as Y” for is-a relation, and “X and other Y” for other-relation). Instantiated with two given noun phrases, the pattern is searched in a large corpus and the occurrence number is used as a measure of</context>
<context position="8487" citStr="Ng and Cardie (2002)" startWordPosition="1333" endWordPosition="1336">ility of the patterns based on the strength of association between patterns and instances, employing the pointwise mutual information (PMI). 3 Framework of Coreference Resolution ative instances are added into the original training instance set for learning, which will generate a classifier with the capability of not only antecedent identification, but also non-anaphorically identification. The new classier is applied to the testing document to do coreference resolution as usual. Our coreference resolution system adopts the common learning-based framework as employed by Soon et al. (2001) and Ng and Cardie (2002). In the learning framework, a training or testing instance has the form of i{NPi, NPj}, in which NPj is a possible anaphor and NPi is one of its antecedent candidates. An instance is associated with a vector of features, which is used to describe the properties of the two noun phrases as well as their relationships. In our baseline system, we adopt the common features for coreference resolution such as lexical property, distance, string-matching, namealias, apposition, grammatical role, number/gender agreement and so on. The same feature set is described in (Ng and Cardie, 2002) for reference</context>
<context position="19803" citStr="Ng and Cardie, 2002" startWordPosition="3300" endWordPosition="3303">nd precision of the whole coreference resolution. For pattern extraction and feature computing, we used Wikipedia, a web-based free-content encyclopedia, as the text corpus. We collected the English Wikipedia database dump in November 2006 (refer to http://download.wikimedia.org/). After all the hyperlinks and other html tags were removed, the whole pure text contains about 220 Million words. 5.2 Results and Discussion Table 1 lists the performance of different coreference resolution systems. The first line of the table shows the baseline system that uses only the common features proposed in (Ng and Cardie, 2002). From the table, our baseline system can 532 NO Frequency Frequency (Filtered) PMI Reliabilty 1 &lt;#t1&gt; &lt;#t2&gt; &lt;#t2&gt; ||&lt;#t1&gt; |&lt;#t1&gt; : &lt;#t2&gt; 2 &lt;#t2&gt; &lt;#t1&gt; &lt;#t1&gt; ) is a &lt;#t2&gt; &lt;#t2&gt; : &lt;#t1&gt; 3 &lt;#t1&gt; , &lt;#t2&gt; &lt;#t1&gt; ) is an &lt;#t2&gt; &lt;#t1&gt; . the &lt;#t2&gt; 4 &lt;#t2&gt; , &lt;#t1&gt; &lt;#t2&gt; ) is an &lt;#t1&gt; &lt;#t2&gt; ( &lt;#t1&gt; ) 5 &lt;#t1&gt; . &lt;#t2&gt; &lt;#t2&gt; ) is a &lt;#t1&gt; &lt;#t1&gt; ( &lt;#t2&gt; 6 &lt;#t1&gt; and &lt;#t2&gt; &lt;#t1&gt; or the &lt;#t2&gt; &lt;#t1&gt; ( &lt;#t2&gt; ) 7 &lt;#t2&gt; . &lt;#t1&gt; &lt;#t1&gt; (the &lt;#t2&gt; &lt;#t1&gt; ||&lt;#t2&gt; | 8 &lt;#t1&gt; . the &lt;#t2&gt; &lt;#t1&gt; . during the &lt;#t2&gt; &lt;#t2&gt; ||&lt;#t1&gt; | 9 &lt;#t2&gt; and &lt;#t1&gt; &lt;#t1&gt; |&lt;#t2&gt; &lt;#t2&gt; , the &lt;#t1&gt; 10 &lt;#t1&gt; , the &lt;#t2&gt; &lt;#t1&gt; , an &lt;#t2&gt; &lt;#t1&gt; , th</context>
</contexts>
<marker>Ng, Cardie, 2002</marker>
<rawString>V. Ng and C. Cardie. 2002. Improving machine learning approaches to coreference resolution. In Proceedings of ACL, pages 104–111, Philadelphia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Ng</author>
</authors>
<title>Machine learning for coreference resolution: From local classification to global ranking.</title>
<date>2005</date>
<booktitle>In Proceedings ofACL,</booktitle>
<pages>157--164</pages>
<contexts>
<context position="21256" citStr="Ng, 2005" startWordPosition="3610" endWordPosition="3611"> ,many &lt;#t2&gt; &lt;#t1&gt; ) is a &lt;#t2&gt; 16 &lt;#t1&gt; &lt;#t2&gt; . &lt;#t2&gt; ) was a &lt;#t1&gt; &lt;#t1&gt; during the &lt;#t2&gt; 17 &lt;#t2&gt; &lt;#t1&gt; . &lt;#t1&gt; ( &lt;#t2&gt; . &lt;#t1&gt; &lt;#t2&gt; . 18 &lt;#t1&gt; ( &lt;#t2&gt; ) &lt;#t2&gt; |&lt;#t1&gt; &lt;#t1&gt; ) is an &lt;#t2&gt; 19 &lt;#t1&gt; and the &lt;#t2&gt; &lt;#t1&gt; , not the &lt;#t2&gt; &lt;#t2&gt; in &lt;#t1&gt; . 20 &lt;#t2&gt; ( &lt;#t1&gt; ) &lt;#t2&gt; , many &lt;#t1&gt; &lt;#t2&gt; , &lt;#t1&gt; . . . . . . . . . . . . Table 2: Top patterns chosen under different scoring schemes achieve a good precision (above 75%-80%) with a recall around 50%-60%. The overall F-measure for NWire, NPaper and BNews is 64.9%, 64.9% and 62.0% respectively. The results are comparable to those reported in (Ng, 2005) which uses similar features and gets an F-measure of about 62% for the same data set. The rest lines of Table 1 are for the systems using the pattern based information. In all the systems, we examine the utility of the semantic information in resolving different types of NP Pairs: (1) NP Pairs containing proper names (i.e., Name:Name or Name:Definites), and (2) NP Pairs of all types. In Table 1 (Line 2-5), we also list the results of incorporating two commonly used patterns, “X(s) such as Y” and “X and other Y(s)”. We can find that neither of the manually designed patterns has significant imp</context>
</contexts>
<marker>Ng, 2005</marker>
<rawString>V. Ng. 2005. Machine learning for coreference resolution: From local classification to global ranking. In Proceedings ofACL, pages 157–164.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Pantel</author>
<author>M Pennacchiotti</author>
</authors>
<title>Espresso: Leveraging generic patterns for automatically harvesting semantic relations.</title>
<date>2006</date>
<booktitle>In Proceedings ofACL,</booktitle>
<pages>113--1200</pages>
<contexts>
<context position="7815" citStr="Pantel and Pennacchiotti (2006)" startWordPosition="1231" endWordPosition="1235">and forms a query. The query is submitted to the Google searching engine, and the returned hit number is utilized to compute the semantic relatedness between the two NPs. In their work, the semantic information is used as a feature for the learner. Markert et al. (2003) and Poesio et al. (2004) adopt a similar strategy for the bridging anaphora resolution. In (Hearst, 1998), the author also proposes to discover new patterns instead of using the manually designed ones. She employs a bootstrapping algorithm to learn new patterns from the word pairs with a known relation. Based on Hearst’s work, Pantel and Pennacchiotti (2006) further give a method 529 which measures the reliability of the patterns based on the strength of association between patterns and instances, employing the pointwise mutual information (PMI). 3 Framework of Coreference Resolution ative instances are added into the original training instance set for learning, which will generate a classifier with the capability of not only antecedent identification, but also non-anaphorically identification. The new classier is applied to the testing document to do coreference resolution as usual. Our coreference resolution system adopts the common learning-ba</context>
<context position="14123" citStr="Pantel and Pennacchiotti, 2006" startWordPosition="2314" endWordPosition="2317"> positive seed pairs whose pattern list contains the pattern. Formally, supposing the pattern list associated with a seed pair s is PList(s), the frequency score of a pattern p is defined as Freqency(p) = |{s|s E S+, p E PList(s)} |(1) 4.2.2 Reliability Another possible way to evaluate a pattern is based on its reliability, i.e., the degree that the pattern is associated with the positive coreferential NPs. In our study, we use pointwise mutual information (Cover and Thomas, 1991) to measure association strength, which has been proved effective in the task of semantic relation identification (Pantel and Pennacchiotti, 2006). Under pointwise mutual information (PMI), the strength of association between two events x and y is defined as follows: P (x, y) pmi(x, y) = log (2) P(x)P (y) Thus the association between a pattern p and a positive seed pair s:(Ei:Ej) is: pmi(p, (Ei : Ej)) = log where |(Ei,p,Ej) |is the count of strings matched by pattern p instantiated with Ei and Ej. Asterisk * represents a wildcard, that is: |(Ei, *, Ej) |= E |(Ei, p, Ej) |(4) PEPList(Ei:Ej) |(*, p, *) |= E |(Ei, p, Ej) |(5) (Ei:Ej )ES+US− |(*, *, *) |= E |(Ei, p, Ej) |(6) (Ei:Ej)ES+US−;PEPlist(Ei:Ej ) The reliability of pattern is the av</context>
</contexts>
<marker>Pantel, Pennacchiotti, 2006</marker>
<rawString>P. Pantel and M. Pennacchiotti. 2006. Espresso: Leveraging generic patterns for automatically harvesting semantic relations. In Proceedings ofACL, pages 113–1200.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Poesio</author>
<author>R Mehta</author>
<author>A Maroudas</author>
<author>J Hitzeman</author>
</authors>
<title>Learning to resolve bridging references.</title>
<date>2004</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>143--150</pages>
<contexts>
<context position="2092" citStr="Poesio et al., 2004" startWordPosition="321" endWordPosition="324">r proper names), word senses and semantic relations are not available from the database (Vieira and Poesio, 2000). In recent years, increasing interest has been seen in mining semantic relations from large text corpora. One common solution is to utilize a pattern that can represent a specific semantic relation (e.g., “X such as Y” for is-a relation, and “X and other Y” for other-relation). Instantiated with two given noun phrases, the pattern is searched in a large corpus and the occurrence number is used as a measure of their semantic relatedness (Markert et al., 2003; Modjeska et al., 2003; Poesio et al., 2004). However, in the previous pattern based approaches, the selection of the patterns to represent a specific semantic relation is done in an ad hoc way, usually by linguistic intuition. The manually selected patterns, nevertheless, are not necessarily the most effective ones for coreference resolution from the following two concerns: • Accuracy. Can the patterns (e.g., “X such as Y”) find as many NP pairs of the specific semantic relation (e.g. is-a) as possible, with a high precision? • Breadth. Can the patterns cover a wide variety of semantic relations, not just is-a, by which coreference rel</context>
<context position="7479" citStr="Poesio et al. (2004)" startWordPosition="1177" endWordPosition="1180"> and so on. The use of Hearst’s style patterns can be seen for the reference resolution task. Modjeska et al. (2003) explore the use of the Web to do the other-anaphora resolution. In their approach, a pattern “X and other Y” is used. Given an anaphor and a candidate antecedent, the pattern is instantiated with the two NPs and forms a query. The query is submitted to the Google searching engine, and the returned hit number is utilized to compute the semantic relatedness between the two NPs. In their work, the semantic information is used as a feature for the learner. Markert et al. (2003) and Poesio et al. (2004) adopt a similar strategy for the bridging anaphora resolution. In (Hearst, 1998), the author also proposes to discover new patterns instead of using the manually designed ones. She employs a bootstrapping algorithm to learn new patterns from the word pairs with a known relation. Based on Hearst’s work, Pantel and Pennacchiotti (2006) further give a method 529 which measures the reliability of the patterns based on the strength of association between patterns and instances, employing the pointwise mutual information (PMI). 3 Framework of Coreference Resolution ative instances are added into th</context>
</contexts>
<marker>Poesio, Mehta, Maroudas, Hitzeman, 2004</marker>
<rawString>M. Poesio, R. Mehta, A. Maroudas, and J. Hitzeman. 2004. Learning to resolve bridging references. In Proceedings of ACL, pages 143–150.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Ponzetto</author>
<author>M Strube</author>
</authors>
<title>Exploiting semantic role labeling, wordnet and wikipedia for coreference resolution.</title>
<date>2006</date>
<booktitle>In Proceedings ofNAACL,</booktitle>
<pages>192--199</pages>
<contexts>
<context position="5240" citStr="Ponzetto and Strube (2006)" startWordPosition="817" endWordPosition="820">resents the model to obtain the patternbased semantic relatedness information. Section 5 discusses the experimental results. Finally, Section 6 summarizes the conclusions. 2 Related Work Earlier work on coreference resolution commonly relies on semantic lexicons for semantic relatedness knowledge. In the system by Vieira and Poesio (2000), for example, WordNet is consulted to obtain the synonymy, hypernymy and meronymy relations for resolving the definite anaphora. In (Harabagiu et al., 2001), the path patterns in WordNet are utilized to compute the semantic consistency between NPs. Recently, Ponzetto and Strube (2006) suggest to mine semantic relatedness from Wikipedia, which can deal with the data sparseness problem suffered by using WordNet. Instead of leveraging existing lexicons, many researchers have investigated corpus-based approaches to mine semantic relations. Garera and Yarowsky (2006) propose an unsupervised model which extracts hypernym relation for resloving definite NPs. Their model assumes that a definite NP and its hypernym words usually co-occur in texts. Thus, for a definite-NP anaphor, a preceding NP that has a high co-occurrence statistics in a large corpus is preferred for the antecede</context>
</contexts>
<marker>Ponzetto, Strube, 2006</marker>
<rawString>S. Ponzetto and M. Strube. 2006. Exploiting semantic role labeling, wordnet and wikipedia for coreference resolution. In Proceedings ofNAACL, pages 192–199.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Soon</author>
<author>H Ng</author>
<author>D Lim</author>
</authors>
<title>A machine learning approach to coreference resolution of noun phrases.</title>
<date>2001</date>
<journal>Computational Linguistics,</journal>
<volume>27</volume>
<issue>4</issue>
<contexts>
<context position="1376" citStr="Soon et al., 2001" startWordPosition="202" endWordPosition="205">tomatically discover and evaluate patterns, and how to exploit the patterns to obtain the semantic relatedness information. The evaluation on ACE data set shows that the pattern based semantic information is helpful for coreference resolution. 1 Introduction Semantic relatedness is a very important factor for coreference resolution, as noun phrases used to refer to the same entity should have a certain semantic relation. To obtain this semantic information, previous work on reference resolution usually leverages a semantic lexicon like WordNet (Vieira and Poesio, 2000; Harabagiu et al., 2001; Soon et al., 2001; Ng and Cardie, 2002). However, the drawback of WordNet is that many expressions (especially for proper names), word senses and semantic relations are not available from the database (Vieira and Poesio, 2000). In recent years, increasing interest has been seen in mining semantic relations from large text corpora. One common solution is to utilize a pattern that can represent a specific semantic relation (e.g., “X such as Y” for is-a relation, and “X and other Y” for other-relation). Instantiated with two given noun phrases, the pattern is searched in a large corpus and the occurrence number i</context>
<context position="8462" citStr="Soon et al. (2001)" startWordPosition="1328" endWordPosition="1331">ich measures the reliability of the patterns based on the strength of association between patterns and instances, employing the pointwise mutual information (PMI). 3 Framework of Coreference Resolution ative instances are added into the original training instance set for learning, which will generate a classifier with the capability of not only antecedent identification, but also non-anaphorically identification. The new classier is applied to the testing document to do coreference resolution as usual. Our coreference resolution system adopts the common learning-based framework as employed by Soon et al. (2001) and Ng and Cardie (2002). In the learning framework, a training or testing instance has the form of i{NPi, NPj}, in which NPj is a possible anaphor and NPi is one of its antecedent candidates. An instance is associated with a vector of features, which is used to describe the properties of the two noun phrases as well as their relationships. In our baseline system, we adopt the common features for coreference resolution such as lexical property, distance, string-matching, namealias, apposition, grammatical role, number/gender agreement and so on. The same feature set is described in (Ng and Ca</context>
<context position="27447" citStr="Soon et al., 2001" startWordPosition="4695" endWordPosition="4698">ld resort to the Web which contains a larger volume of texts and thus could lead to more informative patterns. We would like to explore this issue in our future work. In Figure 1, we plot the decision tree learned with the pattern features for non-pronoun resolution (NWire domain, filtered frequency), which visually illustrates which features are useful in the reference determination. We can find the pattern features occur in the top of the decision tree, among the features for name alias, apposition and string-matching that are crucial for coreference resolution as reported in previous work (Soon et al., 2001). Most of the pattern features deemed important by the learner are for the copula structure. 5.2.2 Single Semantic Relatedness Feature Section 4.3.2 presents another strategy to exploit the patterns, which uses a single feature to reflect the semantic relatedness between NP pairs. The last two lines of Table 1 list the results of such a system. Observed from the table, the system with the single semantic relatedness feature beats those with other solutions. Compared with the baseline, the system can get improvement in recall (up to 2.9% as in NWire), with a similar or even higher precision. Th</context>
</contexts>
<marker>Soon, Ng, Lim, 2001</marker>
<rawString>W. Soon, H. Ng, and D. Lim. 2001. A machine learning approach to coreference resolution of noun phrases. Computational Linguistics, 27(4):521–544.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Vieira</author>
<author>M Poesio</author>
</authors>
<title>An empirically based system for processing definite descriptions.</title>
<date>2000</date>
<journal>Computational Linguistics,</journal>
<volume>27</volume>
<issue>4</issue>
<contexts>
<context position="1333" citStr="Vieira and Poesio, 2000" startWordPosition="193" endWordPosition="197"> for coreference resolution. We explore how to automatically discover and evaluate patterns, and how to exploit the patterns to obtain the semantic relatedness information. The evaluation on ACE data set shows that the pattern based semantic information is helpful for coreference resolution. 1 Introduction Semantic relatedness is a very important factor for coreference resolution, as noun phrases used to refer to the same entity should have a certain semantic relation. To obtain this semantic information, previous work on reference resolution usually leverages a semantic lexicon like WordNet (Vieira and Poesio, 2000; Harabagiu et al., 2001; Soon et al., 2001; Ng and Cardie, 2002). However, the drawback of WordNet is that many expressions (especially for proper names), word senses and semantic relations are not available from the database (Vieira and Poesio, 2000). In recent years, increasing interest has been seen in mining semantic relations from large text corpora. One common solution is to utilize a pattern that can represent a specific semantic relation (e.g., “X such as Y” for is-a relation, and “X and other Y” for other-relation). Instantiated with two given noun phrases, the pattern is searched in</context>
<context position="4954" citStr="Vieira and Poesio (2000)" startWordPosition="774" endWordPosition="777">perimental results show that the pattern based semantic relatedness information is helpful for the coreference resolution. The remainder of the paper is organized as follows. Section 2 gives some related work. Section 3 introduces the framework for coreference resolution. Section 4 presents the model to obtain the patternbased semantic relatedness information. Section 5 discusses the experimental results. Finally, Section 6 summarizes the conclusions. 2 Related Work Earlier work on coreference resolution commonly relies on semantic lexicons for semantic relatedness knowledge. In the system by Vieira and Poesio (2000), for example, WordNet is consulted to obtain the synonymy, hypernymy and meronymy relations for resolving the definite anaphora. In (Harabagiu et al., 2001), the path patterns in WordNet are utilized to compute the semantic consistency between NPs. Recently, Ponzetto and Strube (2006) suggest to mine semantic relatedness from Wikipedia, which can deal with the data sparseness problem suffered by using WordNet. Instead of leveraging existing lexicons, many researchers have investigated corpus-based approaches to mine semantic relations. Garera and Yarowsky (2006) propose an unsupervised model </context>
</contexts>
<marker>Vieira, Poesio, 2000</marker>
<rawString>R. Vieira and M. Poesio. 2000. An empirically based system for processing definite descriptions. Computational Linguistics, 27(4):539–592.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Vilain</author>
<author>J Burger</author>
<author>J Aberdeen</author>
<author>D Connolly</author>
<author>L Hirschman</author>
</authors>
<title>A model-theoretic coreference scoring scheme.</title>
<date>1995</date>
<booktitle>In Proceedings of the Sixth Message understanding Conference (MUC-6),</booktitle>
<pages>45--52</pages>
<publisher>Morgan Kaufmann Publishers.</publisher>
<location>San Francisco, CA.</location>
<contexts>
<context position="19127" citStr="Vilain et al. (1995)" startWordPosition="3197" endWordPosition="3200"> contains two data set, training and devtest, used for training and testing respectively. Each of these sets is further divided by three domains: newswire (NWire), newspaper (NPaper), and broadcast news (BNews). An input raw text was preprocessed automatically by a pipeline of NLP components, including sentence boundary detection, POS-tagging, Text Chunking and Named-Entity Recognition. Two different classifiers were learned respectively for resolving pronouns and non-pronouns. As mentioned, the pattern based semantic information was only applied to the non-pronoun resolution. For evaluation, Vilain et al. (1995)’s scoring algorithm was adopted to compute the recall and precision of the whole coreference resolution. For pattern extraction and feature computing, we used Wikipedia, a web-based free-content encyclopedia, as the text corpus. We collected the English Wikipedia database dump in November 2006 (refer to http://download.wikimedia.org/). After all the hyperlinks and other html tags were removed, the whole pure text contains about 220 Million words. 5.2 Results and Discussion Table 1 lists the performance of different coreference resolution systems. The first line of the table shows the baseline</context>
</contexts>
<marker>Vilain, Burger, Aberdeen, Connolly, Hirschman, 1995</marker>
<rawString>M. Vilain, J. Burger, J. Aberdeen, D. Connolly, and L. Hirschman. 1995. A model-theoretic coreference scoring scheme. In Proceedings of the Sixth Message understanding Conference (MUC-6), pages 45–52, San Francisco, CA. Morgan Kaufmann Publishers.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>