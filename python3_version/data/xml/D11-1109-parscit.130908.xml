<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000008">
<title confidence="0.99636">
Joint Models for Chinese POS Tagging and Dependency Parsing
</title>
<author confidence="0.993443">
Zhenghua Li†, Min Zhang‡, Wanxiang Che†, Ting Liu†, Wenliang Chen‡ and Haizhou Li‡†Research Center for Social Computing and Information Retrieval
</author>
<affiliation confidence="0.989317">
Harbin Institute of Technology, China
</affiliation>
<email confidence="0.943154">
{lzh,car,tliu}@ir.hit.edu.cn
</email>
<affiliation confidence="0.809279">
‡Institute for Infocomm Research, Singapore
</affiliation>
<email confidence="0.988897">
{mzhang,wechen,hli}@i2r.a-star.edu.sg
</email>
<sectionHeader confidence="0.99726" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99960608">
Part-of-speech (POS) is an indispensable fea-
ture in dependency parsing. Current research
usually models POS tagging and dependency
parsing independently. This may suffer from
error propagation problem. Our experiments
show that parsing accuracy drops by about
6% when using automatic POS tags instead
of gold ones. To solve this issue, this pa-
per proposes a solution by jointly optimiz-
ing POS tagging and dependency parsing in a
unique model. We design several joint models
and their corresponding decoding algorithms
to incorporate different feature sets. We fur-
ther present an effective pruning strategy to re-
duce the search space of candidate POS tags,
leading to significant improvement of parsing
speed. Experimental results on Chinese Penn
Treebank 5 show that our joint models sig-
nificantly improve the state-of-the-art parsing
accuracy by about 1.5%. Detailed analysis
shows that the joint method is able to choose
such POS tags that are more helpful and dis-
criminative from parsing viewpoint. This is
the fundamental reason of parsing accuracy
improvement.
</bodyText>
<sectionHeader confidence="0.999472" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999972760869566">
In dependency parsing, features consisting of part-
of-speech (POS) tags are very effective, since pure
lexical features lead to severe data sparseness prob-
lem. Typically, POS tagging and dependency pars-
ing are modeled in a pipelined way. However, the
pipelined method is prone to error propagation, es-
pecially for Chinese. Due to the lack of morpholog-
ical features, Chinese POS tagging is even harder
than other languages such as English. The state-of-
the-art accuracy of Chinese POS tagging is about
93.5%, which is much lower than that of English
(about 97% (Collins, 2002)). Our experimental re-
sults show that parsing accuracy decreases by about
6% on Chinese when using automatic POS tagging
results instead of gold ones (see Table 3 in Section
5). Recent research on dependency parsing usually
overlooks this issue by simply adopting gold POS
tags for Chinese data (Duan et al., 2007; Zhang and
Clark, 2008b; Huang and Sagae, 2010). In this pa-
per, we address this issue by jointly optimizing POS
tagging and dependency parsing.
Joint modeling has been a popular and effec-
tive approach to simultaneously solve related tasks.
Recently, many successful joint models have been
proposed, such as joint tokenization and POS tag-
ging (Zhang and Clark, 2008a; Jiang et al., 2008;
Kruengkrai et al., 2009), joint lemmatization and
POS tagging (Toutanova and Cherry, 2009), joint
tokenization and parsing (Cohen and Smith, 2007;
Goldberg and Tsarfaty, 2008), joint named en-
tity recognition and parsing (Finkel and Manning,
2009), joint parsing and semantic role labeling
(SRL) (Li et al., 2010), joint word sense disambigua-
tion and SRL (Che and Liu, 2010), joint tokenization
and machine translation (MT) (Dyer, 2009; Xiao et
al., 2010) and joint parsing and MT (Liu and Liu,
2010). Note that the aforementioned “parsing” all
refer to constituent parsing.
As far as we know, there are few successful mod-
els for jointly solving dependency parsing and other
tasks. Being facilitated by Conference on Com-
putational Natural Language Learning (CoNLL)
2008 and 2009 shared tasks, several joint models
of dependency parsing and SRL have been pro-
posed. Nevertheless, the top-ranked systems all
adopt pipelined approaches (Surdeanu et al., 2008;
</bodyText>
<page confidence="0.933896">
1180
</page>
<note confidence="0.9618615">
Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1180–1191,
Edinburgh, Scotland, UK, July 27–31, 2011. c�2011 Association for Computational Linguistics
</note>
<bodyText confidence="0.99455524137931">
Hajiˇc et al., 2009). Theoretically, joint modeling
of POS tagging and dependency parsing should be
helpful to the two individual tasks. On the one hand,
syntactic information can help resolve some POS
ambiguities which are difficult to handle for the se-
quential POS tagging models. On the other hand,
more accurate POS tags should further improve de-
pendency parsing.
For joint POS tagging and dependency parsing,
the major issue is to design effective decoding algo-
rithms to capture rich features and efficiently search
out the optimal results from a huge hypothesis
space.&apos; In this paper, we propose several dynamic
programming (DP) based decoding algorithms for
our joint models by extending existing parsing algo-
rithms. We also present effective pruning techniques
to speed up our decoding algorithms. Experimen-
tal results on Chinese Penn Treebank show that our
joint models can significantly improve the state-of-
the-art parsing accuracy by about 1.5%.
The remainder of this paper is organized as fol-
lows. Section 2 describes the pipelined method, in-
cluding the POS tagging and parsing models. Sec-
tion 3 discusses the joint models and the decod-
ing algorithms, while Section 4 presents the pruning
techniques. Section 5 reports the experimental re-
sults and error analysis. We review previous work
closely related to our method in Section 6, and con-
clude this paper in Section 7.
</bodyText>
<sectionHeader confidence="0.977054" genericHeader="method">
2 The Baseline Pipelined Method
</sectionHeader>
<bodyText confidence="0.989203">
Given an input sentence x = w1...wn, we denote its
POS tag sequence by t = t1...tn, where ti E T, 1 &lt;
i &lt; n, and T is the POS tag set. A dependency tree
is denoted by d = {(h, m) : 0 &lt; h &lt; n, 0 &lt; m &lt;
n}, where (h, m) represents a dependency wh -+
wm whose head word (or father) is wh and modifier
(or child) is wm. w0 is an artificial root token which
is used to simplify the formalization of the problem.
The pipelined method treats POS tagging and de-
pendency parsing as two cascaded problems. First,
&apos;It should be noted that it is straightforward to simultane-
ously do POS tagging and constituent parsing, as POS tags can
be regarded as non-terminals in the constituent structure (Levy
and Manning, 2003). In addition, Rush et al. (2010) describes
an efficient and simple inference algorithm based on dual de-
composition and linear programming relaxation to combine a
lexicalized constituent parser and a trigram POS tagger.
an optimal POS tag sequence t� is determined.
</bodyText>
<equation confidence="0.452553">
Scorepog(x, t)
</equation>
<bodyText confidence="0.9058465">
Then, an optimal dependency tree d is determined
based on x and t.
d = arg max Scoregyn(x, t, d)
d
</bodyText>
<subsectionHeader confidence="0.991013">
2.1 POS Tagging
</subsectionHeader>
<bodyText confidence="0.99908425">
POS tagging is a typical sequence labeling prob-
lem. Many models have been successfully applied
to sequence labeling problems, such as maximum-
entropy (Ratnaparkhi, 1996), conditional random
fields (CRF) (Lafferty et al., 2001) and perceptron
(Collins, 2002). We use perceptron to build our POS
tagging baseline for two reasons. Firstly, as a linear
model, perceptron is simple, fast, and effective. It is
competitive to CRF in tagging accuracy but requires
much less training time (Shen et al., 2007). Sec-
ondly, perceptron has been successfully applied to
dependency parsing as well (Koo and Collins, 2010).
In this paper, perceptron is used in all models includ-
ing the POS tagging model, the dependency parsing
models and the joint models.
In a perceptron, the score of a tag sequence is
</bodyText>
<equation confidence="0.951168">
Scorepog(x,t) = wpog · fpog(x,t)
</equation>
<bodyText confidence="0.999204222222222">
where fpog(x, t) refers to the feature vector and wpog
is the corresponding weight vector.
For POS tagging features, we follow the work of
Zhang and Clark (2008a). Three feature sets are
considered: POS unigram, bigram and trigram fea-
tures. For brevity, we will refer to the three sets as
wi ti, ti−1 ti and ti−2 ti−1 ti.
Given wpog, we adopt the Viterbi algorithm to get
the optimal tagging sequence.
</bodyText>
<subsectionHeader confidence="0.997941">
2.2 Dependency Parsing
</subsectionHeader>
<bodyText confidence="0.999927714285714">
Recently, graph-based dependency parsing has
gained more and more interest due to its state-of-
the-art accuracy. Graph-based dependency parsing
views the problem as finding the highest scoring tree
from a directed graph. Based on dynamic program-
ming decoding, it can efficiently find an optimal tree
in a huge search space. In a graph-based model, the
</bodyText>
<equation confidence="0.9990535">
t� = arg max
t
</equation>
<page confidence="0.910717">
1181
</page>
<bodyText confidence="0.9816115">
score of a dependency tree is factored into scores of
small parts (subtrees).
</bodyText>
<equation confidence="0.982747">
5coresyn(x, t, d) = wsyn · fsyn(x, t, d)
�= 5coresyn(x, t, p)
pCd
</equation>
<bodyText confidence="0.99823375">
where p is a scoring part which contains one or more
dependencies in the dependency tree d. Figure 1
shows different types of scoring parts used in current
graph-based models.
</bodyText>
<figure confidence="0.8397885">
h In h s In g h In
dependency sibling grandparent
g h s In h t s In
grand-sibling tri-sibling
</figure>
<figureCaption confidence="0.997845">
Figure 1: Different types of scoring parts used in current
graph-based models (Koo and Collins, 2010).
</figureCaption>
<bodyText confidence="0.999901625">
Eisner (1996) proposes an O(n3) decoding al-
gorithm for dependency parsing. Based on the al-
gorithm, McDonald et al. (2005) propose the first-
order model, in which the scoring parts only con-
tains dependencies. The second-order model of Mc-
Donald and Pereira (2006) incorporates sibling parts
and also needs O(n3) parsing time. The second-
order model of Carreras (2007) incorporates both
sibling and grandparent parts, and needs O(n4)
parsing time. However, the grandparent parts are
restricted to those composed of outermost grand-
children. Koo and Collins (2010) propose efficient
decoding algorithms of O(n4) for third-order mod-
els. In their paper, they implement two versions
of third-order models, Model 1 and Model 2 ac-
cording to their naming. Model 1 incorporates only
grand-sibling parts, while Model 2 incorporates both
grand-sibling and tri-sibling parts. Their experi-
ments on English and Czech show that Model 1 and
Model 2 obtain nearly the same parsing accuracy.
Therefore, we use Model 1 as our third-order model
in this paper.
We use three versions of graph-based dependency
parsing models.
</bodyText>
<listItem confidence="0.978081857142857">
• The first-order model (O1): the same with Mc-
Donald et al. (2005).
• The second-order model (O2): the same with
Model 1 in Koo and Collins (2010), but without
using grand-sibling features.2
• The third-order model (O3): the same with
Model 1 in Koo and Collins (2010).
</listItem>
<bodyText confidence="0.975551">
We adopt linear models to define the score of a de-
pendency tree. For the third-order model, the score
of a dependency tree is represented as:
</bodyText>
<equation confidence="0.99557475">
�5coresyn(x, t, d) = wdep · fdep(x, t, h,m)
{(h,m)}Cd
+ � wsib · fsib(x, t, h, s, m)
{(h,s)(h,m)}Cd
+ � wgrd · fgrd(x, t, g, h, m)
{(g,h),(h,m)}Cd
+ � wgsib · fgsib(x, t, g, h, s, m)
{(g,h),(h,s),(h,m)}Cd
</equation>
<bodyText confidence="0.9952335">
For the first- and second-order models, the above
formula is modified by deactivating extra parts.
For parsing features, we follow standard prac-
tice for graph-based dependency parsing (McDon-
ald, 2006; Carreras, 2007; Koo and Collins, 2010).
Since these features are highly related with our joint
decoding algorithms, we summarize the features as
follows.
</bodyText>
<listItem confidence="0.98288525">
• Dependency Features, fdep(x, t, h, m)
– Unigram Features: whth dir, wmtm dir
– Bigram Features: whth wmtm dir dist
– In Between Features: th tb tm dir dist
– Surrounding Features:
th−1 th th+1 tm−1 tm tm+1 dir dist
• Sibling Features, fsib(x, t, h, s, m)
wh th ws ts wm tm dir
• Grandparent Features, fgrd(x, t, g, h, m)
wg tg wh th wm tm dir gdir
• Grand-sibling Features, fgsib(x, t, g, h, s, m)
wg tg wh th ws ts wm tm dir gdir
</listItem>
<footnote confidence="0.99650025">
2This second-order model incorporates grandparent features
composed of all grandchildren rather than just outermost ones,
and outperforms the one of Carreras (2007) according to the
results in Koo and Collins (2010).
</footnote>
<page confidence="0.996659">
1182
</page>
<bodyText confidence="0.999985923076923">
where b denotes an index between h and m; dir
and dist are the direction and distance of (h, m);
gdir is the direction of (g, h). We also use back-
off features by generalizing from very specific fea-
tures over word forms, POS tags, directions and dis-
tances to less sparse features over just POS tags or
considering fewer nodes. To avoid producing too
many sparse features, at most two word forms are
used at the same time in sibling, grandparent and
grand-sibling features, while POS tags are used in-
stead for other nodes; meanwhile, at most four POS
tags are considered at the same time for surrounding
features.
</bodyText>
<sectionHeader confidence="0.997837" genericHeader="method">
3 Joint Models
</sectionHeader>
<bodyText confidence="0.999591">
In the joint method, we aim to simultaneously solve
the two problems.
</bodyText>
<equation confidence="0.701933142857143">
(�t, �d) =arg max 5corejoint(x, t, d)
t,d
Under the linear model, the score of a tagged de-
pendency tree is:
5corejoint(x, t, d) = 5corepos(x, t)
+ 5coresyn(x, t, d)
= wpos®syn · fpos®syn(x, t, d)
</equation>
<bodyText confidence="0.999991307692307">
where fpos®syn(.) means the concatenation of fpos(.)
and fsyn(.). Under the joint model, the weights of
POS and syntactic features, wpos®syn, are simulta-
neously learned. We expect that POS and syntactic
features can interact each other to determine an op-
timal joint result.
Similarly to the baseline dependency parsing
models, we define the first-, second-, and third-order
joint models according to the syntactic features con-
tained in fsyn(.).
In the following, we propose two versions of joint
models which can capture different feature sets and
have different complexity.
</bodyText>
<subsectionHeader confidence="0.99609">
3.1 Joint Models of Version 1
</subsectionHeader>
<bodyText confidence="0.9974286">
The crucial problem for the joint method is to de-
sign effective decoding algorithms to capture rich
features and efficiently search out the optimal re-
sults from a huge hypothesis space. Eisner (2000)
describes a preliminary idea to handle polysemy by
extending parsing algorithms. Based on this idea,
we extend decoding algorithms of McDonald et al.
(2005) and Koo and Collins (2010), and propose two
DP based decoding algorithms for our joint models
of version 1.
</bodyText>
<figureCaption confidence="0.9193635">
Figure 2: The DP structures and derivations of the first-
order decoding algorithm of joint models of version 1.
We omit symmetric right-headed versions for brevity.
Trapezoids denote incomplete spans. Triangles denote
complete spans. Solid circles denote POS tags of the cor-
responding indices.
</figureCaption>
<bodyText confidence="0.985221666666666">
The decoding algorithm of O1: As shown in
Figure 2, the first-order joint decoding algorithm
utilizes two types of dynamic programming struc-
tures. (1) Incomplete spans consist of a dependency
and the region between the head and modifier; (2)
Complete spans consist of a headword and its de-
scendants on one side. Each span is recursively cre-
ated by combining two smaller and adjacent spans
in a bottom-up fashion.
The pseudo codes are given in Algorithm 1.
I(i,j)(ti,tj) denotes an incomplete span from i to j
whose boundary POS tags are ti and tj. C(i,j)(ti,tj)
refers to a complete span from i to j whose bound-
ary POS tags are ti and tj. Conversely, I(j,i)(tj,ti)
and C(j,i)(tj,ti) represent spans of the other direction.
Note that in these notations the first argument index
always refers to the head of the span.
Line 6 corresponds to the derivation in Figure 2-
(a). 5corejoint(x, ti, tr, tr+1, tj, p = {(i, j)}) cap-
tures the joint features invented by this combina-
tion, where p = {(i, j)} means that the newly ob-
served scoring part is the dependency (i, j). The
syntactic features, denoted by fsyn(x, ti, tj, i, j), can
only incorporate syntactic unigram and bigram fea-
tures. The surrounding and in between features
are unavailable, because the context POS tags, such
as tb and ti−1, are not contained in the DP struc-
</bodyText>
<equation confidence="0.768366">
i j
r+l j
i r
i j i r r j
</equation>
<page confidence="0.831792">
1183
</page>
<bodyText confidence="0.512456">
Algorithm 1 The first-order joint decoding algorithm of version 1
</bodyText>
<listItem confidence="0.937880083333333">
1: ∀0 ≤ i ≤ n, ti ∈ T C(i,i)(ti,ti) = 0 &lt; initialization
2: for w = 1..n do &lt; span width
3: for i = 0..(n − w) do &lt; span start index
4: j = i + w &lt; span end index
5: for (ti, tj) ∈ T2 do
6: I(i,j)(ti,tj) = maxi&lt;r&lt;j max(tr,tr+1)ET2{C(i,r)(ti,tr) + C(j,r+1)(tj,tr+1) + Scorejoint(x, ti, tr, tr+1, tj, p = {(i, j)})}
7: I(j,i)(tj ,ti) = maxi&lt;r&lt;j max(tr,tr+1)ET2{C(i,r)(ti,tr) + C(j,r+1)(tj ,tr+1) + Scorejoint(x, ti, tr, tr+1, tj, p = {(j, i)})}
8: C(i,j)(ti,tj) = maxi&lt;r&lt;j maxtrET {I(i,r)(ti,tr) + C(r,j)(tr,tj) + Scorejoint(x, ti, tr, tj, p = ∅)}
9: C(j,i)(tj,ti) = maxi&lt;r&lt;j maxtrET {C(r,i)(tr,ti) + I(j,r)(tj,tr) + Scorejoint(x, ti, tr, tj, p = ∅)}
10: end for
11: end for
12: end for
</listItem>
<bodyText confidence="0.9994155">
tures. Therefore, we adopt pseudo surrounding
and in between features by simply fixing the con-
text POS tags as the single most likely ones (Mc-
Donald, 2006). Taking the in between features
as an example, we use ti tb tj dir dist instead,
where
line POS tagger. The POS features, denoted by
fpog(x, ti, tr, tr+1, tj), can only incorporate all POS
unigram and bigram features.3 Similarly, we use
pseudo POS trigram features such as �tr−1 tr tr+1.
Line 8 corresponds to the derivation in Figure 2-
(b). Since this combination invents no scoring part
(p = 0), Scorejoint(x, ti, tr, tj, p = 0) is only com-
posed of POS features.4
Line 7 and Line 9 create spans in the opposite di-
rection, which can be analogously illustrated. The
space and time complexity of the algorithm are re-
spectively O(n2q2) and O(n3q4), where q = |T |.5
The decoding algorithm of O2 &amp; O3: Figure
3 illustrates the second- and third-order decoding
algorithm of joint models of version 1. A new
kind of span, named the sibling span, is used to
capture sibling structures. Furthermore, each span
is augmented with a grandparent-index to capture
both grandparent and grand-sibling structures. It is
straightforward to derive the pseudo codes of the al-
</bodyText>
<construct confidence="0.91470575">
3① wr tr if i ≠ r; ② wr+1 tr+1 if r + 1 ≠ j; ③ tr tr+1
if r ≠ i or r + 1 ≠ j; ④ ti tr if r − 1 = i; ⑤ tr+1 tj if
r + 2 = j. Note that wi ti, wj tj and ti tj (if i = j − 1) are
not incorporated here to avoid double counting.
</construct>
<footnote confidence="0.977140666666667">
4① wr tr if r ≠ j; ② ti tr if i = r−1; ③ tr tj if r+1 = j.
Pseudo trigram features can be added accordingly.
5We can reduce the time complexity to O(n3q3) by strictly
adopting the DP structures in the parsing algorithm of Eisner
(1996). However, that may make the algorithm harder to com-
prehend.
</footnote>
<figureCaption confidence="0.997940625">
Figure 3: The DP structures and derivations of the
second- and third-order joint decoding algorithm of ver-
sion 1. For brevity, we elide the right-headed and right-
grandparented versions. Rectangles represent sibling
spans.
Figure 4: The DP structures and derivations of the first-
order joint decoding algorithm of version 2. We omit the
right-headed version for brevity.
</figureCaption>
<figure confidence="0.932538214285714">
(b)
I
k i i k r i r+l i
8 i i 8 i i i+I i
g i i g i k i k i
$ i i $ i r i r i
(d)
(C)
i i i r r+] i
(a)
i i i r r i
tb is the 1-best tag determined by the base-
1184
4 Pruning Techniques
</figure>
<bodyText confidence="0.9984455">
In this section, we introduce two pruning strategies
to constrain the search space of our models due to
their high complexity.
gorithm from Figure 3. We omit them due to space
limitation. Pseudo surrounding, in between and POS
trigram features are used due to the same reason as
above. The space and time complexity of the algo-
rithm are respectively O(n3q3) and O(n4q5).
</bodyText>
<subsectionHeader confidence="0.995984">
3.2 Joint Models of Version 2
</subsectionHeader>
<bodyText confidence="0.999670777777778">
To further incorporate genuine syntactic surround-
ing and POS trigram features in the DP structures,
we extend the algorithms of joint models of version
1, and propose our joint models of version 2.
The decoding algorithm of O1: Figure 4 illus-
trates the first-order joint decoding algorithm of ver-
sion 2. Compared with the structures in Figure 2,
each span is augmented with the POS tags surround-
ing the boundary indices. These context POS tags
enable Scorejoint(.) in line 6-9 of Algorithm 1 to
capture the syntactic surrounding and POS trigram
features, but also require enumeration of POS tags
over more indices. For brevity, we skip the pseudo
codes which can be easily derived from Algorithm
1. The space and time complexity of the algorithm
are respectively O(n2q6) and O(n3q10).
The decoding algorithm of O2 &amp; O3: Using the
same idea as above, the second- and third-order joint
decoding algorithms of version 2 can be derived
based on Figure 3. Again, we omit both its DP struc-
tures and pseudo codes for the sake of brevity. Its
space and time complexity are respectively O(n3q7)
and O(n4q11).
In between features, which should be regarded as
non-local features in the joint situation, still cannot
be incorporated in our joint models of version 2.
Again, we adopt the pseudo version.
</bodyText>
<subsectionHeader confidence="0.993495">
3.3 Comparison
</subsectionHeader>
<bodyText confidence="0.999962555555556">
Based on the above illustration, we can see that joint
models of version 1 are more efficient with regard
to the number of POS tags for each word, but fail to
incorporate syntactic surrounding features and POS
trigram features in the DP structures. On the con-
trary, joint models of version 2 can incorporate both
aforementioned feature sets, but have higher com-
plexity. These two versions of models will be thor-
oughly compared in the experiments.
</bodyText>
<subsectionHeader confidence="0.973541">
4.1 POS Tag Pruning
</subsectionHeader>
<bodyText confidence="0.999965166666667">
The time complexity of the joint decoding algorithm
is unbearably high with regard to the number of can-
didate POS tags for each word (q = |T |). We
find that it would be extremely time-consuming even
when we only use two most likely POS tags for each
word (q = 2) even for joint models of version 1.
To deal with this problem, we propose a pruning
method that can effectively reduce the POS tag space
based on a probabilistic tagging model.
We adopt a conditional log-linear model (Lafferty
et al., 2001), which defines a conditional distribution
of a POS tag sequence t given x:
</bodyText>
<equation confidence="0.9040965">
ewpos·fpos(x,t)
Et ewpos·fpos(x,t)
</equation>
<bodyText confidence="0.976340833333333">
We use the same feature set fpog defined in Sec-
tion 2.1, and adopt the exponentiated gradient algo-
rithm to learn the weight vector wpog (Collins et al.,
2008).
The marginal probability of tagging a word wi as
t is
</bodyText>
<equation confidence="0.9217875">
P(ti = t|x) = � P(t|x)
t:t[i]=—t
</equation>
<bodyText confidence="0.9773535">
which can be efficiently computed using the
forward-backward algorithm.
We define pmaxi(x) to be the highest marginal
probability of tagging the word wi:
</bodyText>
<equation confidence="0.9973625">
pmaxi(x) = max
tET P(ti = t|x)
</equation>
<bodyText confidence="0.99997">
We then define the allowable candidate POS tags
of the word wi to be
</bodyText>
<equation confidence="0.86537">
Ti(x) = It : t E T ,P(ti = t|x) &gt; At x pmaxi(x)}
</equation>
<bodyText confidence="0.746179333333333">
where At is the pruning threshold. Ti(x) is used to
constrain the POS search space by replacing T in
Algorithm 1.
</bodyText>
<equation confidence="0.991429">
P(t|x) =
</equation>
<page confidence="0.739741">
1185
</page>
<bodyText confidence="0.493125">
proportion of words (%)
</bodyText>
<subsectionHeader confidence="0.959987">
4.2 Dependency Pruning
</subsectionHeader>
<bodyText confidence="0.9999254">
The parsing time grows quickly for the second- and
third-order models (both baseline and joint) when
the input sentence gets longer (O(n4)). Follow-
ing Koo and Collins (2010), we eliminate unlikely
dependencies using a form of coarse-to-fine prun-
ing (Charniak and Johnson, 2005; Petrov and Klein,
2007). On the development set, 68.87% of the de-
pendencies are pruned, while the oracle dependency
accuracy is 99.77%. We use 10-fold cross validation
to do pruning on the training set.
</bodyText>
<sectionHeader confidence="0.999725" genericHeader="method">
5 Experiments
</sectionHeader>
<bodyText confidence="0.999567411764706">
We use the Penn Chinese Treebank 5.1 (CTB5) (Xue
et al., 2005). Following the setup of Duan et al.
(2007), Zhang and Clark (2008b) and Huang and
Sagae (2010), we split CTB5 into training (secs 001-
815 and 1001-1136), development (secs 886-931
and 1148-1151), and test (secs 816-885 and 1137-
1147) sets. We use the head-finding rules of Zhang
and Clark (2008b) to turn the bracketed sentences
into dependency structures.
We use the standard tagging accuracy to evalu-
ate POS tagging. For dependency parsing, we use
word accuracy (also known as dependency accu-
racy), root accuracy and complete match rate (all
excluding punctuation) .
For the averaged training, we train each model for
15 iterations and select the parameters that perform
best on the development set.
</bodyText>
<subsectionHeader confidence="0.977724">
5.1 Results of POS Tag Pruning
</subsectionHeader>
<bodyText confidence="0.9999146">
Figure 5 shows the distribution of words with dif-
ferent number of candidate POS tags and the k-best
oracle tagging accuracy under different At. To avoid
dealing with words that have many candidate POS
tags, we further apply a hard criterion that the decod-
ing algorithms only consider top k candidate POS
tags.
To find the best At, we train and evaluate the
second-order joint model of version 1 on the train-
ing and development sets pruned with different At
(top k = 5). We adopt the second-order joint model
of version 1 because of its efficiency compared with
the third-order models and its capability of captur-
ing rich features compared with the first-order mod-
els. The results are shown in Table 1. The model
</bodyText>
<figure confidence="0.9954405">
100
99
80
70
0.1
0.01
0.001
95
94
93
1 2 3 4 5 &gt;5 1 2 3 4 5 m
number of candidate POS tags k
</figure>
<figureCaption confidence="0.9986185">
Figure 5: Results of POS tag pruning with different prun-
ing threshold At on the development set.
</figureCaption>
<table confidence="0.999129">
At word root compl. acc. speed
0.1 81.53 76.88 30.00 94.17 2.5
0.01 81.83 76.62 30.62 93.16 1.2
0.001 81.73 77.38 30.50 93.41 0.5
</table>
<tableCaption confidence="0.9662842">
Table 1: Performance of the second-order joint model of
version 1 with different pruning threshold At (top k = 5)
on the development set. “Acc.” means the tagging accu-
racy. “Speed” refers to the parsing speed (the number of
sentences processed per second).
</tableCaption>
<bodyText confidence="0.99922965">
with At = 0.1 obtains the highest tagging accuracy,
which is much higher than that of both At = 0.01
and At = 0.001. However, its parsing accuracy
is inferior to the other two. At = 0.01 produces
slightly better parsing accuracy than At = 0.001,
and is twice faster. Finally, we choose At = 0.01
due to the efficiency factor and our priority over the
parsing accuracy.
Then we do experiments to find an optimal top
k. Table 2 shows the results. We decide to choose
k = 3 since it leads to best parsing accuracy.
From Table 1 and 2, we can have an interesting
finding: it seems that the harder we filter the POS
tag space, the higher tagging accuracy we get. In
other words, giving the joint model less flexibility
of choosing POS tags leads to better tagging per-
formance.
Due to time limitation, we do not tune At and k for
other joint models. Instead, we simply adopt At =
0.01 and top k = 3.
</bodyText>
<subsectionHeader confidence="0.997396">
5.2 Final Results
</subsectionHeader>
<bodyText confidence="0.99889275">
Table 3 shows the final results on the test set. We list
a few state-of-the-art results in the bottom. Duan07
refers to the results of Duan et al. (2007). They
enhance the transition-based parsing model with
</bodyText>
<figure confidence="0.9951938125">
100
90
60
50
40
30
20
10
0
k-best oracle tagging accuracy (%)
98
97
96
0.1
0.01
0.001
</figure>
<page confidence="0.973587">
1186
</page>
<table confidence="0.99955116">
Syntactic Metrics Tagging Accuracy Parsing Speed
Sent/Sec
word root compl. all-word known unknown
O3 80.79 75.84 29.11 92.80 93.88 76.80 0.3
Joint Models V2 O2 80.49 75.49 28.24 92.68 93.77 76.27 0.6
O1 77.37 68.64 23.09 92.96 94.05 76.64 2.0
O3 80.69 75.90 29.06 92.89 93.96 76.80 0.5
Joint Models V1 O2 80.74 75.80 28.24 93.08 94.11 77.53 1.7
O1 77.38 69.69 22.62 93.20 94.23 77.76 8.5
O3 79.29 74.65 27.24 2.0
O2 79.03 74.70 27.19 5.8
Auto POS O1 75.68 68.06 21.10 93.51 94.36 80.78 17.4
MSTParser2 77.95 72.04 25.50 4.1
MSTParser1 75.84 68.55 21.36 5.2
MaltParser 75.24 65.92 23.19 2.6
O3 86.00 77.59 34.02 -
O2 86.18 78.58 34.07 -
O1 82.24 70.10 26.02 -
MSTParser2 85.24 77.41 33.19 -
Gold POS MSTParser1 83.04 71.49 27.59 100.0 100.0 100.0
MaltParser 82.62 69.34 29.06 -
H&amp;S10 85.20 78.32 33.72 -
Z&amp;C08 single 84.33 76.73 32.79 -
Z&amp;C08 hybrid 85.77 76.26 34.41 -
Duan07 83.88 73.70 32.70 -
</table>
<tableCaption confidence="0.939114">
Table 3: Final results on the test set. “Gold POS” means that gold POS tags are used as input by the pipelined parsing
models; while “Auto POS” means that the POS tags are generated by the baseline POS tagging model.
</tableCaption>
<table confidence="0.996692">
top k word root compl. acc. speed
2 81.46 76.12 30.50 93.51 2.7
3 82.11 76.75 29.75 93.31 1.7
4 81.75 76.62 30.38 93.25 1.4
5 81.83 76.62 30.62 93.16 1.2
</table>
<tableCaption confidence="0.973273666666667">
Table 2: Performance of the second-order joint model of
version 1 with different top k (At = 0.01) on the devel-
opment set.
</tableCaption>
<bodyText confidence="0.9993737">
the beam search. H&amp;S10 refers to the results of
Huang and Sagae (2010). They greatly expand the
search space of the transition-based model by merg-
ing equivalent states with dynamic programming.
Z&amp;C08 refers to the results of Zhang and Clark
(2008b). They use a hybrid model to combine the
advantages of both graph-based and transition-based
models. We also do experiments with two publicly
available and widely-used parsers, MSTParser6 and
MaltParser7. MSTParser1 refers to the first-order
</bodyText>
<footnote confidence="0.999858">
6http://sourceforge.net/projects/mstparser/
7http://maltparser.org/
</footnote>
<bodyText confidence="0.997669545454546">
graph-based model of McDonald et al. (2005), while
MSTParser2 is the second-order model of McDon-
ald and Pereira (2006). MaltParser is a transition-
based parsing system. It integrates a number of clas-
sification algorithms and transition strategies. We
adopt the support vector machine classifier and the
arc-standard strategy (Nivre, 2008).
We can see that when using gold tags, our
pipelined second- and third-order parsing models
achieve best parsing accuracy, which is even higher
than the hybrid model of Zhang and Clark (2008b).
It is a little surprising that the second-order model
slightly outperforms the third-order one. This may
be possible, since Koo and Collins (2010) shows that
the third-order model outperforms the second-order
one by only 0.32% on English and 0.07% on Czech.
In addition, we only use basic third-order features.
Both joint models of version 1 and 2 can consis-
tently and significantly improve the parsing accu-
racy by about 1.5% for all first-, second- and third-
order cases. Accidentally, the parsing accuracy of
the second-order joint model of version 2 is lower
</bodyText>
<page confidence="0.981683">
1187
</page>
<table confidence="0.999855285714286">
error pattern # error pattern # r
DEC DEG 237 114 NR NN 184 100
NN VV 389 73 NN NR 106 91
DEG DEC 170 39 NN JJ 95 70
VV NN 453 27 VA VV 29 41
P VV 52 24 JJ NN 126 29
P CC 39 13 VV VA 67 10
</table>
<tableCaption confidence="0.9374825">
Table 4: Error analysis of POS tagging. # means the
error number of the corresponding pattern made by the
baseline tagging model. ↓ and ↑ mean the error number
reduced or increased by the joint model.
</tableCaption>
<bodyText confidence="0.999853931034483">
than that of its counterparts by about 0.3%. More
experiments and further analysis may be needed to
find out the reason. The two versions of joint models
performs nearly the same, which indicates that using
pseudo surrounding and POS trigram features may
be sufficient for the joint method on this data set.
In summary, we can conclude that the joint frame-
work is certainly helpful for dependency parsing.
It is clearly shown in Table 3 that the joint
method surprisingly hurts the tagging accuracy,
which diverges from our discussion in Section 1.
Some insights into this issue will be given in Sec-
tion 5.3. Moreover, it seems that the more syntac-
tic features the joint method incorporates (from
O1 to O3), the more the tagging accuracy drops.
We suspect that this is because the joint models are
dominated by the syntactic features. Take the first-
order joint model as an example. The dimension of
the syntactic features fgyn is about 3.5 million, while
that of fpo, is only about 0.5 million. The gap be-
comes much larger for the second- and third-order
cases.
Comparing the parsing speed, we can find that the
pruning of POS tags is very effective. The second-
order joint model of version 1 can parse 1.7 sen-
tences per second, while the pipelined second-order
parsing model can parse 5.8 sentences per second,
which is rather close considering that there is a fac-
tor of q5.
</bodyText>
<subsectionHeader confidence="0.983648">
5.3 Error Analysis
</subsectionHeader>
<bodyText confidence="0.955098811320755">
To find out the impact of our joint models on the
individual tasks, we conduct detailed error analy-
sis through comparing the results of the pipelined
second-order parsing model and the second-order
joint model of version 1.
Impact on POS tagging: Table 4 shows how the
joint model changes the quantity of POS tagging er-
ror patterns compared with the pipelined model. An
error pattern “X → Y” means that the focus word,
whose true tag is ‘X’, is assigned a tag ‘Y’. We
choose these patterns with largest reduction or in-
crease in the error number, and rank them in de-
scending order of the variation.
From the left part of Table 4, we can see that
the joint method is clearly better at resolving tag-
ging ambiguities like {VV, NN} and {DEG, DEC}.&apos;
One common characteristic of these ambiguous
pairs is that the local or even whole syntactic struc-
ture will be destructed if the wrong tag is chosen. In
other words, resolving these ambiguities is critical
and helpful from the parsing viewpoint. From an-
other perspective, the joint model is capable of pre-
ferring the right tag with the help of syntactic struc-
tures, which is impossible for the baseline sequential
labeling model.
In contrast, pairs like {NN, NR}, {VV, VA} and
{NN, JJ} only slightly influence the syntactic struc-
ture when mis-tagged. The joint method performs
worse on these ambiguous pairs, as shown in the
right part of Table 4.
Impact on parsing: Table 5 studies the change of
parsing error rates between the pipelined and joint
model on different POS tag patterns. We present the
most typical and prominent patterns in the table, and
rank them in descending order of X’s frequency of
occurrence. We also show the change of proportion
of different patterns, which is consistent with the re-
sults in Table 4.
From the table, we can see the joint model can
achieve a large error reduction (0.8∼4.0%) for all
the patterns “X → X”. In other words, the joint
model can do better given the correct tags than
the pipelined method.
For all the patterns marked by Q, except for the
ambiguous pair {NN, JJ} (which we find is difficult
to explain even after careful result analysis), the joint
model also reduces the error rates (2.2∼15.4%). As
8DEG and DEC are the two POS tags for the frequently used
auxiliary word “M” (d¯e, of) in Chinese. The associative “M”
is tagged as DEG, such as “XZ*Wfather M RMN/eyes (eyes of
the father)”; while the one in a relative clause is tagged as DEC,
such as “�/he WN/made M AtWprogress (progress that he
made)”.
</bodyText>
<page confidence="0.95833">
1188
</page>
<table confidence="0.9998772">
pattern pipelined joint
prop (%) error (%) prop (%) error (%)
NN → NN 94.6 16.8 -1.1 -1.8
→ VV ♡ 2.9 55.5 -0.5 +15.1
→ NR ♢ 0.8 24.5 +0.7 -2.2
→ JJ ♢ 0.7 17.9 +0.5 +2.1
VV → VV 89.6 34.2 -0.3 –4.0
→ NN ♡ 6.6 66.4 -0.4 +0.7
→ VA ♢ 1.0 38.8 +0.1 -15.4
NR → NR 91.7 15.4 -3.7 -0.8
→ NN ♢ 5.9 21.7 +3.2 -3.7
P → P 92.8 22.6 +3.4 -3.2
→ VV ♡ 3.0 50.0 -1.4 +10.7
→ CC ♡ 2.3 74.4 -0.7 +21.9
JJ → JJ 80.5 11.2 -2.8 -2.0
→ NN ♢ 9.8 18.3 +2.2 +1.8
DEG → DEG 86.5 11.1 +2.8 -3.6
→ DEC ♡ 13.5 61.8 -3.1 +37.4
DEC → DEC 79.7 17.2 +12.1 -4.0
→ DEG ♡ 20.2 56.5 -9.7 +40.2
</table>
<tableCaption confidence="0.94221125">
Table 5: Comparison of parsing error rates on different
POS tag patterns between the pipelined and joint models.
Given a pattern “X → Y”, “prop” means its proportion in
all occurrence of ‘X’ (Count(X-+Y) and “error” refers
</tableCaption>
<figure confidence="0.725514333333333">
Count(X) ),
to its parsing error rate ( Count(wrongly headed X-+Y) ).
Count(X-+Y )
</figure>
<bodyText confidence="0.99513045">
The last two columns give the absolute reduction (-) or
increase (+) in proportion and error rate made by the joint
model. ♡ marks the patterns appearing in the left part of
Table 4, while ♢ marks those in the right part of Table 4.
discussed earlier, these patterns concern ambiguous
tag pairs which usually play similar roles in syn-
tactic structures. This demonstrates that the joint
model can do better on certain tagging error pat-
terns.
For patterns marked by ♡, the error rate of the
joint model usually increases by large margin. How-
ever, the proportion of these patterns is substantially
decreased, since the joint model can better resolve
these ambiguities with the help of syntactic knowl-
edge.
In summary, we can conclude that the joint model
is able to choose such POS tags that are more helpful
and discriminative from parsing viewpoint. This is
the fundamental reason of the parsing performance
improvement.
</bodyText>
<sectionHeader confidence="0.99999" genericHeader="evaluation">
6 Related Work
</sectionHeader>
<bodyText confidence="0.999946842105264">
Theoretically, Eisner (2000) proposes a preliminary
idea of extending the decoding algorithm for de-
pendency parsing to handle polysemy. Here, word
senses can be understood as POS-tagged words.
Koo and Collins (2010) also briefly discuss that their
third-order decoding algorithm can be modified to
handle word senses using the idea of Eisner (2000).
In his PhD thesis, McDonald (2006) extends his
second-order model with the idea of Eisner (2000)
to study the impact of POS tagging errors on pars-
ing accuracy. To make inference tractable, he uses
top 2 candidate POS tags for each word based on
a maximum entropy tagger, and adopts the single
most likely POS tags for the surrounding and in be-
tween features. He conducts primitive experiments
on English Penn Treebank, and shows that parsing
accuracy can be improved from 91.5% to 91.9%.
However, he finds that the model is unbearably time-
consuming.
</bodyText>
<sectionHeader confidence="0.999656" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.999974714285714">
In this paper, we have systematically investigated
the issue of joint POS tagging and dependency pars-
ing. We propose and compare several joint models
and their corresponding decoding algorithms which
can incorporate different feature sets. We also pro-
pose an effective POS tag pruning method which can
greatly improve the decoding efficiency. The experi-
mental results show that our joint models can signif-
icantly improve the state-of-the-art parsing accuracy
by more than 1.5%. Detailed error analysis shows
that the fundamental reason for the parsing accu-
racy improvement is that the joint method is able to
choose POS tags that are helpful and discriminative
from parsing viewpoint.
</bodyText>
<sectionHeader confidence="0.998137" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9994745">
We thank the anonymous reviewers for their helpful
comments. This work was supported by National
Natural Science Foundation of China (NSFC) via
grant 60803093, 60975055, the Natural Scientific
Research Innovation Foundation in Harbin Institute
of Technology (HIT.NSRIF.2009069) and the Fun-
damental Research Funds for the Central Universi-
ties (HIT.KLOF.2010064).
</bodyText>
<sectionHeader confidence="0.988084" genericHeader="references">
References
</sectionHeader>
<bodyText confidence="0.6108305">
Xavier Carreras. 2007. Experiments with a higher-
order projective dependency parser. In Proceedings of
</bodyText>
<page confidence="0.984988">
1189
</page>
<reference confidence="0.999343887850467">
EMNLP/CoNLL, pages 141–150.
Eugene Charniak and Mark Johnson. 2005. Coarse-to-
fine n-best parsing and maxent discriminative rerank-
ing. In Proceedings of ACL-05, pages 173–180.
Wanxiang Che and Ting Liu. 2010. Jointly modeling
wsd and srl with markov logic. In Proceedings of the
23rd International Conference on Computational Lin-
guistics (Coling 2010), pages 161–169.
Shay B. Cohen and Noah A. Smith. 2007. Joint morpho-
logical and syntactic disambiguation. In Proceedings
of EMNLP-CoNLL 2007, pages 208–217.
Michael Collins, Amir Globerson, Terry Koo, Xavier
Carreras, and Peter Bartlett. 2008. Exponentiated
gradient algorithms for conditional random fields and
max-margin markov networks. JMLR, 9:1775–1822.
Michael Collins. 2002. Discriminative training meth-
ods for hidden markov models: Theory and experi-
ments with perceptron algorithms. In Proceedings of
EMNLP 2002.
Xiangyu Duan, Jun Zhao, , and Bo Xu. 2007. Proba-
bilistic models for action-based Chinese dependency
parsing. In Proceedings of ECML/ECPPKDD.
Chris Dyer. 2009. Using a maximum entropy model
to build segmentation lattices for mt. In Proceedings
of Human Language Technologies: The 2009 Annual
Conference of the North American Chapter of the As-
sociation for Computational Linguistics, pages 406–
414.
Jason Eisner. 1996. Three new probabilistic models for
dependency parsing: An exploration. In Proceedings
of COLING 1996, pages 340–345.
Jason Eisner. 2000. Bilexical grammars and their cubic-
time parsing algorithms. In Advances in Probabilistic
and Other Parsing Technologies, pages 29–62.
Jenny Rose Finkel and Christopher D. Manning. 2009.
Joint parsing and named entity recognition. In Pro-
ceedings of Human Language Technologies: The 2009
Annual Conference of the North American Chapter of
the Association for Computational Linguistics, pages
326–334.
Yoav Goldberg and Reut Tsarfaty. 2008. A single gener-
ative model for joint morphological segmentation and
syntactic parsing. In Proceedings of ACL-08: HLT,
pages 371–379, Columbus, Ohio, June. Association
for Computational Linguistics.
Jan Hajiˇc, Massimiliano Ciaramita, Richard Johans-
son, Daisuke Kawahara, Maria Ant`onia Mart´ı, Llu´ıs
M`arquez, Adam Meyers, Joakim Nivre, Sebastian
Pad´o, Jan ˇStˇep´anek, Pavel Straˇn´ak, Mihai Surdeanu,
Nianwen Xue, and Yi Zhang. 2009. The CoNLL-
2009 shared task: Syntactic and semantic dependen-
cies in multiple languages. In Proceedings of CoNLL
2009.
Liang Huang and Kenji Sagae. 2010. Dynamic pro-
gramming for linear-time incremental parsing. In Pro-
ceedings of the 48th Annual Meeting of the Associa-
tion for Computational Linguistics, pages 1077–1086,
Uppsala, Sweden, July. Association for Computational
Linguistics.
Wenbin Jiang, Liang Huang, Qun Liu, and Yajuan L¨u.
2008. A cascaded linear model for joint chinese word
segmentation and part-of-speech tagging. In Proceed-
ings of ACL-08: HLT, pages 897–904.
Terry Koo and Michael Collins. 2010. Efficient third-
order dependency parsers. In Proceedings of the 48th
Annual Meeting of the Association for Computational
Linguistics, pages 1–11, Uppsala, Sweden, July. Asso-
ciation for Computational Linguistics.
Canasai Kruengkrai, Kiyotaka Uchimoto, Jun’ichi
Kazama, Yiou Wang, Kentaro Torisawa, and Hitoshi
Isahara. 2009. An error-driven word-character hy-
brid model for joint chinese word segmentation and
pos tagging. In Proceedings of the Joint Conference
of the 47th Annual Meeting of the ACL and the 4th
International Joint Conference on Natural Language
Processing of the AFNLP, pages 513–521.
John Lafferty, Andrew McCallum, and Fernando Pereira.
2001. Conditional random fields: Probabilistic mod-
els for segmenting and labeling sequence data. In Pro-
ceedings of ICML 2001, pages 282–289.
Roger Levy and Christopher D. Manning. 2003. Is it
harder to parse chinese, or the chinese treebank? In
Proceedings of the 41st Annual Meeting of the Associ-
ation for Computational Linguistics, pages 439–446,
Sapporo, Japan, July. Association for Computational
Linguistics.
Junhui Li, Guodong Zhou, and Hwee Tou Ng. 2010.
Joint syntactic and semantic parsing of chinese. In
Proceedings of the 48th Annual Meeting of the As-
sociation for Computational Linguistics, pages 1108–
1117.
Yang Liu and Qun Liu. 2010. Joint parsing and trans-
lation. In Proceedings of the 23rd International Con-
ference on Computational Linguistics (Coling 2010),
pages 707–715.
Ryan McDonald and Fernando Pereira. 2006. On-
line learning of approximate dependency parsing al-
gorithms. In Proceedings of EACL 2006.
Ryan McDonald, Koby Crammer, and Fernando Pereira.
2005. Online large-margin training of dependency
parsers. In Proceedings of ACL 2005, pages 91–98.
Ryan McDonald. 2006. Discriminative Training and
Spanning Tree Algorithms for Dependency Parsing.
Ph.D. thesis, University of Pennsylvania.
Joakim Nivre. 2008. Algorithms for deterministic in-
cremental dependency parsing. In Computational Lin-
guistics, volume 34, pages 513–553.
</reference>
<page confidence="0.808154">
1190
</page>
<reference confidence="0.999566361702128">
Slav Petrov and Dan Klein. 2007. Improved inference
for unlexicalized parsing. In Proceedings of NAACL
2007.
Adwait Ratnaparkhi. 1996. A maximum entropy model
for part-of-speech tagging. In Proceedings of EMNLP
1996.
Alexander M Rush, David Sontag, Michael Collins, and
Tommi Jaakkola. 2010. On dual decomposition and
linear programming relaxations for natural language
processing. In Proceedings of the 2010 Conference on
Empirical Methods in Natural Language Processing,
pages 1–11.
Libin Shen, Giorgio Satta, and Aravind Joshi. 2007.
Guided learning for bidirectional sequence classifica-
tion. In Proceedings of the 45th Annual Meeting of
the Association of Computational Linguistics, pages
760–767, Prague, Czech Republic, June. Association
for Computational Linguistics.
Mihai Surdeanu, Richard Johansson, Adam Meyers,
Llu´ıs M`arquez, and Joakim Nivre. 2008. The CoNLL-
2008 shared task on joint parsing of syntactic and se-
mantic dependencies. In CoNLL-2008.
Kristina Toutanova and Colin Cherry. 2009. A global
model for joint lemmatization and part-of-speech pre-
diction. In Proceedings of the Joint Conference of the
47th Annual Meeting of the ACL and the 4th Interna-
tional Joint Conference on Natural Language Process-
ing of the AFNLP, pages 486–494.
Xinyan Xiao, Yang Liu, YoungSook Hwang, Qun Liu,
and Shouxun Lin. 2010. Joint tokenization and trans-
lation. In Proceedings of the 23rd International Con-
ference on Computational Linguistics (Coling 2010),
pages 1200–1208.
Nianwen Xue, Fei Xia, Fu-Dong Chiou, and Martha
Palmer. 2005. The Penn Chinese Treebank: Phrase
structure annotation of a large corpus. In Natural Lan-
guage Engineering, volume 11, pages 207–238.
Yue Zhang and Stephen Clark. 2008a. Joint word seg-
mentation and POS tagging using a single perceptron.
In Proceedings of ACL-08: HLT, pages 888–896.
Yue Zhang and Stephen Clark. 2008b. A tale of two
parsers: Investigating and combining graph-based and
transition-based dependency parsing. In Proceedings
of the 2008 Conference on Empirical Methods in Nat-
ural Language Processing, pages 562–571, Honolulu,
Hawaii, October. Association for Computational Lin-
guistics.
</reference>
<page confidence="0.994498">
1191
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.396140">
<title confidence="0.999059">Joint Models for Chinese POS Tagging and Dependency Parsing</title>
<author confidence="0.514776">Min Wanxiang Ting Wenliang Haizhou Center for Social Computing</author>
<author confidence="0.514776">Information</author>
<affiliation confidence="0.916186">Harbin Institute of Technology, for Infocomm Research,</affiliation>
<abstract confidence="0.996184538461538">Part-of-speech (POS) is an indispensable feature in dependency parsing. Current research usually models POS tagging and dependency parsing independently. This may suffer from error propagation problem. Our experiments show that parsing accuracy drops by about 6% when using automatic POS tags instead of gold ones. To solve this issue, this paper proposes a solution by jointly optimizing POS tagging and dependency parsing in a unique model. We design several joint models and their corresponding decoding algorithms to incorporate different feature sets. We further present an effective pruning strategy to reduce the search space of candidate POS tags, leading to significant improvement of parsing speed. Experimental results on Chinese Penn Treebank 5 show that our joint models significantly improve the state-of-the-art parsing accuracy by about 1.5%. Detailed analysis shows that the joint method is able to choose such POS tags that are more helpful and discriminative from parsing viewpoint. This is the fundamental reason of parsing accuracy improvement.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>EMNLPCoNLL</author>
</authors>
<pages>141--150</pages>
<marker>EMNLPCoNLL, </marker>
<rawString>EMNLP/CoNLL, pages 141–150.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
<author>Mark Johnson</author>
</authors>
<title>Coarse-tofine n-best parsing and maxent discriminative reranking.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL-05,</booktitle>
<pages>173--180</pages>
<contexts>
<context position="21694" citStr="Charniak and Johnson, 2005" startWordPosition="3721" endWordPosition="3724">y of tagging the word wi: pmaxi(x) = max tET P(ti = t|x) We then define the allowable candidate POS tags of the word wi to be Ti(x) = It : t E T ,P(ti = t|x) &gt; At x pmaxi(x)} where At is the pruning threshold. Ti(x) is used to constrain the POS search space by replacing T in Algorithm 1. P(t|x) = 1185 proportion of words (%) 4.2 Dependency Pruning The parsing time grows quickly for the second- and third-order models (both baseline and joint) when the input sentence gets longer (O(n4)). Following Koo and Collins (2010), we eliminate unlikely dependencies using a form of coarse-to-fine pruning (Charniak and Johnson, 2005; Petrov and Klein, 2007). On the development set, 68.87% of the dependencies are pruned, while the oracle dependency accuracy is 99.77%. We use 10-fold cross validation to do pruning on the training set. 5 Experiments We use the Penn Chinese Treebank 5.1 (CTB5) (Xue et al., 2005). Following the setup of Duan et al. (2007), Zhang and Clark (2008b) and Huang and Sagae (2010), we split CTB5 into training (secs 001- 815 and 1001-1136), development (secs 886-931 and 1148-1151), and test (secs 816-885 and 1137- 1147) sets. We use the head-finding rules of Zhang and Clark (2008b) to turn the bracket</context>
</contexts>
<marker>Charniak, Johnson, 2005</marker>
<rawString>Eugene Charniak and Mark Johnson. 2005. Coarse-tofine n-best parsing and maxent discriminative reranking. In Proceedings of ACL-05, pages 173–180.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wanxiang Che</author>
<author>Ting Liu</author>
</authors>
<title>Jointly modeling wsd and srl with markov logic.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics (Coling</booktitle>
<pages>161--169</pages>
<contexts>
<context position="3092" citStr="Che and Liu, 2010" startWordPosition="470" endWordPosition="473">. Joint modeling has been a popular and effective approach to simultaneously solve related tasks. Recently, many successful joint models have been proposed, such as joint tokenization and POS tagging (Zhang and Clark, 2008a; Jiang et al., 2008; Kruengkrai et al., 2009), joint lemmatization and POS tagging (Toutanova and Cherry, 2009), joint tokenization and parsing (Cohen and Smith, 2007; Goldberg and Tsarfaty, 2008), joint named entity recognition and parsing (Finkel and Manning, 2009), joint parsing and semantic role labeling (SRL) (Li et al., 2010), joint word sense disambiguation and SRL (Che and Liu, 2010), joint tokenization and machine translation (MT) (Dyer, 2009; Xiao et al., 2010) and joint parsing and MT (Liu and Liu, 2010). Note that the aforementioned “parsing” all refer to constituent parsing. As far as we know, there are few successful models for jointly solving dependency parsing and other tasks. Being facilitated by Conference on Computational Natural Language Learning (CoNLL) 2008 and 2009 shared tasks, several joint models of dependency parsing and SRL have been proposed. Nevertheless, the top-ranked systems all adopt pipelined approaches (Surdeanu et al., 2008; 1180 Proceedings o</context>
</contexts>
<marker>Che, Liu, 2010</marker>
<rawString>Wanxiang Che and Ting Liu. 2010. Jointly modeling wsd and srl with markov logic. In Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 161–169.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shay B Cohen</author>
<author>Noah A Smith</author>
</authors>
<title>Joint morphological and syntactic disambiguation.</title>
<date>2007</date>
<booktitle>In Proceedings of EMNLP-CoNLL</booktitle>
<pages>208--217</pages>
<contexts>
<context position="2864" citStr="Cohen and Smith, 2007" startWordPosition="433" endWordPosition="436">verlooks this issue by simply adopting gold POS tags for Chinese data (Duan et al., 2007; Zhang and Clark, 2008b; Huang and Sagae, 2010). In this paper, we address this issue by jointly optimizing POS tagging and dependency parsing. Joint modeling has been a popular and effective approach to simultaneously solve related tasks. Recently, many successful joint models have been proposed, such as joint tokenization and POS tagging (Zhang and Clark, 2008a; Jiang et al., 2008; Kruengkrai et al., 2009), joint lemmatization and POS tagging (Toutanova and Cherry, 2009), joint tokenization and parsing (Cohen and Smith, 2007; Goldberg and Tsarfaty, 2008), joint named entity recognition and parsing (Finkel and Manning, 2009), joint parsing and semantic role labeling (SRL) (Li et al., 2010), joint word sense disambiguation and SRL (Che and Liu, 2010), joint tokenization and machine translation (MT) (Dyer, 2009; Xiao et al., 2010) and joint parsing and MT (Liu and Liu, 2010). Note that the aforementioned “parsing” all refer to constituent parsing. As far as we know, there are few successful models for jointly solving dependency parsing and other tasks. Being facilitated by Conference on Computational Natural Languag</context>
</contexts>
<marker>Cohen, Smith, 2007</marker>
<rawString>Shay B. Cohen and Noah A. Smith. 2007. Joint morphological and syntactic disambiguation. In Proceedings of EMNLP-CoNLL 2007, pages 208–217.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Amir Globerson</author>
<author>Terry Koo</author>
<author>Xavier Carreras</author>
<author>Peter Bartlett</author>
</authors>
<title>Exponentiated gradient algorithms for conditional random fields and max-margin markov networks.</title>
<date>2008</date>
<journal>JMLR,</journal>
<pages>9--1775</pages>
<contexts>
<context position="20851" citStr="Collins et al., 2008" startWordPosition="3571" endWordPosition="3574"> that it would be extremely time-consuming even when we only use two most likely POS tags for each word (q = 2) even for joint models of version 1. To deal with this problem, we propose a pruning method that can effectively reduce the POS tag space based on a probabilistic tagging model. We adopt a conditional log-linear model (Lafferty et al., 2001), which defines a conditional distribution of a POS tag sequence t given x: ewpos·fpos(x,t) Et ewpos·fpos(x,t) We use the same feature set fpog defined in Section 2.1, and adopt the exponentiated gradient algorithm to learn the weight vector wpog (Collins et al., 2008). The marginal probability of tagging a word wi as t is P(ti = t|x) = � P(t|x) t:t[i]=—t which can be efficiently computed using the forward-backward algorithm. We define pmaxi(x) to be the highest marginal probability of tagging the word wi: pmaxi(x) = max tET P(ti = t|x) We then define the allowable candidate POS tags of the word wi to be Ti(x) = It : t E T ,P(ti = t|x) &gt; At x pmaxi(x)} where At is the pruning threshold. Ti(x) is used to constrain the POS search space by replacing T in Algorithm 1. P(t|x) = 1185 proportion of words (%) 4.2 Dependency Pruning The parsing time grows quickly fo</context>
</contexts>
<marker>Collins, Globerson, Koo, Carreras, Bartlett, 2008</marker>
<rawString>Michael Collins, Amir Globerson, Terry Koo, Xavier Carreras, and Peter Bartlett. 2008. Exponentiated gradient algorithms for conditional random fields and max-margin markov networks. JMLR, 9:1775–1822.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms.</title>
<date>2002</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<contexts>
<context position="2018" citStr="Collins, 2002" startWordPosition="299" endWordPosition="300">ing accuracy improvement. 1 Introduction In dependency parsing, features consisting of partof-speech (POS) tags are very effective, since pure lexical features lead to severe data sparseness problem. Typically, POS tagging and dependency parsing are modeled in a pipelined way. However, the pipelined method is prone to error propagation, especially for Chinese. Due to the lack of morphological features, Chinese POS tagging is even harder than other languages such as English. The state-ofthe-art accuracy of Chinese POS tagging is about 93.5%, which is much lower than that of English (about 97% (Collins, 2002)). Our experimental results show that parsing accuracy decreases by about 6% on Chinese when using automatic POS tagging results instead of gold ones (see Table 3 in Section 5). Recent research on dependency parsing usually overlooks this issue by simply adopting gold POS tags for Chinese data (Duan et al., 2007; Zhang and Clark, 2008b; Huang and Sagae, 2010). In this paper, we address this issue by jointly optimizing POS tagging and dependency parsing. Joint modeling has been a popular and effective approach to simultaneously solve related tasks. Recently, many successful joint models have be</context>
<context position="6647" citStr="Collins, 2002" startWordPosition="1059" endWordPosition="1060">ribes an efficient and simple inference algorithm based on dual decomposition and linear programming relaxation to combine a lexicalized constituent parser and a trigram POS tagger. an optimal POS tag sequence t� is determined. Scorepog(x, t) Then, an optimal dependency tree d is determined based on x and t. d = arg max Scoregyn(x, t, d) d 2.1 POS Tagging POS tagging is a typical sequence labeling problem. Many models have been successfully applied to sequence labeling problems, such as maximumentropy (Ratnaparkhi, 1996), conditional random fields (CRF) (Lafferty et al., 2001) and perceptron (Collins, 2002). We use perceptron to build our POS tagging baseline for two reasons. Firstly, as a linear model, perceptron is simple, fast, and effective. It is competitive to CRF in tagging accuracy but requires much less training time (Shen et al., 2007). Secondly, perceptron has been successfully applied to dependency parsing as well (Koo and Collins, 2010). In this paper, perceptron is used in all models including the POS tagging model, the dependency parsing models and the joint models. In a perceptron, the score of a tag sequence is Scorepog(x,t) = wpog · fpog(x,t) where fpog(x, t) refers to the feat</context>
</contexts>
<marker>Collins, 2002</marker>
<rawString>Michael Collins. 2002. Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms. In Proceedings of EMNLP 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiangyu Duan</author>
<author>Jun Zhao</author>
</authors>
<title>Probabilistic models for action-based Chinese dependency parsing.</title>
<date>2007</date>
<booktitle>In Proceedings of ECML/ECPPKDD.</booktitle>
<marker>Duan, Zhao, 2007</marker>
<rawString>Xiangyu Duan, Jun Zhao, , and Bo Xu. 2007. Probabilistic models for action-based Chinese dependency parsing. In Proceedings of ECML/ECPPKDD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Dyer</author>
</authors>
<title>Using a maximum entropy model to build segmentation lattices for mt.</title>
<date>2009</date>
<booktitle>In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>406--414</pages>
<contexts>
<context position="3153" citStr="Dyer, 2009" startWordPosition="480" endWordPosition="481">neously solve related tasks. Recently, many successful joint models have been proposed, such as joint tokenization and POS tagging (Zhang and Clark, 2008a; Jiang et al., 2008; Kruengkrai et al., 2009), joint lemmatization and POS tagging (Toutanova and Cherry, 2009), joint tokenization and parsing (Cohen and Smith, 2007; Goldberg and Tsarfaty, 2008), joint named entity recognition and parsing (Finkel and Manning, 2009), joint parsing and semantic role labeling (SRL) (Li et al., 2010), joint word sense disambiguation and SRL (Che and Liu, 2010), joint tokenization and machine translation (MT) (Dyer, 2009; Xiao et al., 2010) and joint parsing and MT (Liu and Liu, 2010). Note that the aforementioned “parsing” all refer to constituent parsing. As far as we know, there are few successful models for jointly solving dependency parsing and other tasks. Being facilitated by Conference on Computational Natural Language Learning (CoNLL) 2008 and 2009 shared tasks, several joint models of dependency parsing and SRL have been proposed. Nevertheless, the top-ranked systems all adopt pipelined approaches (Surdeanu et al., 2008; 1180 Proceedings of the 2011 Conference on Empirical Methods in Natural Languag</context>
</contexts>
<marker>Dyer, 2009</marker>
<rawString>Chris Dyer. 2009. Using a maximum entropy model to build segmentation lattices for mt. In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 406– 414.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Eisner</author>
</authors>
<title>Three new probabilistic models for dependency parsing: An exploration.</title>
<date>1996</date>
<booktitle>In Proceedings of COLING</booktitle>
<pages>340--345</pages>
<contexts>
<context position="8538" citStr="Eisner (1996)" startWordPosition="1385" endWordPosition="1386">timal tree in a huge search space. In a graph-based model, the t� = arg max t 1181 score of a dependency tree is factored into scores of small parts (subtrees). 5coresyn(x, t, d) = wsyn · fsyn(x, t, d) �= 5coresyn(x, t, p) pCd where p is a scoring part which contains one or more dependencies in the dependency tree d. Figure 1 shows different types of scoring parts used in current graph-based models. h In h s In g h In dependency sibling grandparent g h s In h t s In grand-sibling tri-sibling Figure 1: Different types of scoring parts used in current graph-based models (Koo and Collins, 2010). Eisner (1996) proposes an O(n3) decoding algorithm for dependency parsing. Based on the algorithm, McDonald et al. (2005) propose the firstorder model, in which the scoring parts only contains dependencies. The second-order model of McDonald and Pereira (2006) incorporates sibling parts and also needs O(n3) parsing time. The secondorder model of Carreras (2007) incorporates both sibling and grandparent parts, and needs O(n4) parsing time. However, the grandparent parts are restricted to those composed of outermost grandchildren. Koo and Collins (2010) propose efficient decoding algorithms of O(n4) for thir</context>
<context position="17289" citStr="Eisner (1996)" startWordPosition="2936" endWordPosition="2937">gmented with a grandparent-index to capture both grandparent and grand-sibling structures. It is straightforward to derive the pseudo codes of the al3 wr tr if i ≠ r;  wr+1 tr+1 if r + 1 ≠ j;  tr tr+1 if r ≠ i or r + 1 ≠ j;  ti tr if r − 1 = i;  tr+1 tj if r + 2 = j. Note that wi ti, wj tj and ti tj (if i = j − 1) are not incorporated here to avoid double counting. 4 wr tr if r ≠ j;  ti tr if i = r−1;  tr tj if r+1 = j. Pseudo trigram features can be added accordingly. 5We can reduce the time complexity to O(n3q3) by strictly adopting the DP structures in the parsing algorithm of Eisner (1996). However, that may make the algorithm harder to comprehend. Figure 3: The DP structures and derivations of the second- and third-order joint decoding algorithm of version 1. For brevity, we elide the right-headed and rightgrandparented versions. Rectangles represent sibling spans. Figure 4: The DP structures and derivations of the firstorder joint decoding algorithm of version 2. We omit the right-headed version for brevity. (b) I k i i k r i r+l i 8 i i 8 i i i+I i g i i g i k i k i $ i i $ i r i r i (d) (C) i i i r r+] i (a) i i i r r i tb is the 1-best tag determined by the base1184 4 Prun</context>
</contexts>
<marker>Eisner, 1996</marker>
<rawString>Jason Eisner. 1996. Three new probabilistic models for dependency parsing: An exploration. In Proceedings of COLING 1996, pages 340–345.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Eisner</author>
</authors>
<title>Bilexical grammars and their cubictime parsing algorithms.</title>
<date>2000</date>
<booktitle>In Advances in Probabilistic and Other Parsing Technologies,</booktitle>
<pages>29--62</pages>
<contexts>
<context position="12948" citStr="Eisner (2000)" startWordPosition="2136" endWordPosition="2137">d syntactic features can interact each other to determine an optimal joint result. Similarly to the baseline dependency parsing models, we define the first-, second-, and third-order joint models according to the syntactic features contained in fsyn(.). In the following, we propose two versions of joint models which can capture different feature sets and have different complexity. 3.1 Joint Models of Version 1 The crucial problem for the joint method is to design effective decoding algorithms to capture rich features and efficiently search out the optimal results from a huge hypothesis space. Eisner (2000) describes a preliminary idea to handle polysemy by extending parsing algorithms. Based on this idea, we extend decoding algorithms of McDonald et al. (2005) and Koo and Collins (2010), and propose two DP based decoding algorithms for our joint models of version 1. Figure 2: The DP structures and derivations of the firstorder decoding algorithm of joint models of version 1. We omit symmetric right-headed versions for brevity. Trapezoids denote incomplete spans. Triangles denote complete spans. Solid circles denote POS tags of the corresponding indices. The decoding algorithm of O1: As shown in</context>
<context position="34375" citStr="Eisner (2000)" startWordPosition="5987" endWordPosition="5988">s. This demonstrates that the joint model can do better on certain tagging error patterns. For patterns marked by ♡, the error rate of the joint model usually increases by large margin. However, the proportion of these patterns is substantially decreased, since the joint model can better resolve these ambiguities with the help of syntactic knowledge. In summary, we can conclude that the joint model is able to choose such POS tags that are more helpful and discriminative from parsing viewpoint. This is the fundamental reason of the parsing performance improvement. 6 Related Work Theoretically, Eisner (2000) proposes a preliminary idea of extending the decoding algorithm for dependency parsing to handle polysemy. Here, word senses can be understood as POS-tagged words. Koo and Collins (2010) also briefly discuss that their third-order decoding algorithm can be modified to handle word senses using the idea of Eisner (2000). In his PhD thesis, McDonald (2006) extends his second-order model with the idea of Eisner (2000) to study the impact of POS tagging errors on parsing accuracy. To make inference tractable, he uses top 2 candidate POS tags for each word based on a maximum entropy tagger, and ado</context>
</contexts>
<marker>Eisner, 2000</marker>
<rawString>Jason Eisner. 2000. Bilexical grammars and their cubictime parsing algorithms. In Advances in Probabilistic and Other Parsing Technologies, pages 29–62.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny Rose Finkel</author>
<author>Christopher D Manning</author>
</authors>
<title>Joint parsing and named entity recognition.</title>
<date>2009</date>
<booktitle>In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>326--334</pages>
<contexts>
<context position="2965" citStr="Finkel and Manning, 2009" startWordPosition="448" endWordPosition="451">nd Clark, 2008b; Huang and Sagae, 2010). In this paper, we address this issue by jointly optimizing POS tagging and dependency parsing. Joint modeling has been a popular and effective approach to simultaneously solve related tasks. Recently, many successful joint models have been proposed, such as joint tokenization and POS tagging (Zhang and Clark, 2008a; Jiang et al., 2008; Kruengkrai et al., 2009), joint lemmatization and POS tagging (Toutanova and Cherry, 2009), joint tokenization and parsing (Cohen and Smith, 2007; Goldberg and Tsarfaty, 2008), joint named entity recognition and parsing (Finkel and Manning, 2009), joint parsing and semantic role labeling (SRL) (Li et al., 2010), joint word sense disambiguation and SRL (Che and Liu, 2010), joint tokenization and machine translation (MT) (Dyer, 2009; Xiao et al., 2010) and joint parsing and MT (Liu and Liu, 2010). Note that the aforementioned “parsing” all refer to constituent parsing. As far as we know, there are few successful models for jointly solving dependency parsing and other tasks. Being facilitated by Conference on Computational Natural Language Learning (CoNLL) 2008 and 2009 shared tasks, several joint models of dependency parsing and SRL hav</context>
</contexts>
<marker>Finkel, Manning, 2009</marker>
<rawString>Jenny Rose Finkel and Christopher D. Manning. 2009. Joint parsing and named entity recognition. In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 326–334.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Goldberg</author>
<author>Reut Tsarfaty</author>
</authors>
<title>A single generative model for joint morphological segmentation and syntactic parsing.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT,</booktitle>
<pages>371--379</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Columbus, Ohio,</location>
<contexts>
<context position="2894" citStr="Goldberg and Tsarfaty, 2008" startWordPosition="437" endWordPosition="440">simply adopting gold POS tags for Chinese data (Duan et al., 2007; Zhang and Clark, 2008b; Huang and Sagae, 2010). In this paper, we address this issue by jointly optimizing POS tagging and dependency parsing. Joint modeling has been a popular and effective approach to simultaneously solve related tasks. Recently, many successful joint models have been proposed, such as joint tokenization and POS tagging (Zhang and Clark, 2008a; Jiang et al., 2008; Kruengkrai et al., 2009), joint lemmatization and POS tagging (Toutanova and Cherry, 2009), joint tokenization and parsing (Cohen and Smith, 2007; Goldberg and Tsarfaty, 2008), joint named entity recognition and parsing (Finkel and Manning, 2009), joint parsing and semantic role labeling (SRL) (Li et al., 2010), joint word sense disambiguation and SRL (Che and Liu, 2010), joint tokenization and machine translation (MT) (Dyer, 2009; Xiao et al., 2010) and joint parsing and MT (Liu and Liu, 2010). Note that the aforementioned “parsing” all refer to constituent parsing. As far as we know, there are few successful models for jointly solving dependency parsing and other tasks. Being facilitated by Conference on Computational Natural Language Learning (CoNLL) 2008 and 20</context>
</contexts>
<marker>Goldberg, Tsarfaty, 2008</marker>
<rawString>Yoav Goldberg and Reut Tsarfaty. 2008. A single generative model for joint morphological segmentation and syntactic parsing. In Proceedings of ACL-08: HLT, pages 371–379, Columbus, Ohio, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Hajiˇc</author>
<author>Massimiliano Ciaramita</author>
<author>Richard Johansson</author>
<author>Daisuke Kawahara</author>
<author>Maria Ant`onia Mart´ı</author>
<author>Llu´ıs M`arquez</author>
<author>Adam Meyers</author>
<author>Joakim Nivre</author>
<author>Sebastian Pad´o</author>
<author>Jan ˇStˇep´anek</author>
<author>Pavel Straˇn´ak</author>
<author>Mihai Surdeanu</author>
<author>Nianwen Xue</author>
<author>Yi Zhang</author>
</authors>
<title>The CoNLL2009 shared task: Syntactic and semantic dependencies in multiple languages.</title>
<date>2009</date>
<booktitle>In Proceedings of CoNLL</booktitle>
<marker>Hajiˇc, Ciaramita, Johansson, Kawahara, Mart´ı, M`arquez, Meyers, Nivre, Pad´o, ˇStˇep´anek, Straˇn´ak, Surdeanu, Xue, Zhang, 2009</marker>
<rawString>Jan Hajiˇc, Massimiliano Ciaramita, Richard Johansson, Daisuke Kawahara, Maria Ant`onia Mart´ı, Llu´ıs M`arquez, Adam Meyers, Joakim Nivre, Sebastian Pad´o, Jan ˇStˇep´anek, Pavel Straˇn´ak, Mihai Surdeanu, Nianwen Xue, and Yi Zhang. 2009. The CoNLL2009 shared task: Syntactic and semantic dependencies in multiple languages. In Proceedings of CoNLL 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Huang</author>
<author>Kenji Sagae</author>
</authors>
<title>Dynamic programming for linear-time incremental parsing.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1077--1086</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Uppsala, Sweden,</location>
<contexts>
<context position="2379" citStr="Huang and Sagae, 2010" startWordPosition="357" endWordPosition="360"> Chinese. Due to the lack of morphological features, Chinese POS tagging is even harder than other languages such as English. The state-ofthe-art accuracy of Chinese POS tagging is about 93.5%, which is much lower than that of English (about 97% (Collins, 2002)). Our experimental results show that parsing accuracy decreases by about 6% on Chinese when using automatic POS tagging results instead of gold ones (see Table 3 in Section 5). Recent research on dependency parsing usually overlooks this issue by simply adopting gold POS tags for Chinese data (Duan et al., 2007; Zhang and Clark, 2008b; Huang and Sagae, 2010). In this paper, we address this issue by jointly optimizing POS tagging and dependency parsing. Joint modeling has been a popular and effective approach to simultaneously solve related tasks. Recently, many successful joint models have been proposed, such as joint tokenization and POS tagging (Zhang and Clark, 2008a; Jiang et al., 2008; Kruengkrai et al., 2009), joint lemmatization and POS tagging (Toutanova and Cherry, 2009), joint tokenization and parsing (Cohen and Smith, 2007; Goldberg and Tsarfaty, 2008), joint named entity recognition and parsing (Finkel and Manning, 2009), joint parsin</context>
<context position="22070" citStr="Huang and Sagae (2010)" startWordPosition="3786" endWordPosition="3789"> for the second- and third-order models (both baseline and joint) when the input sentence gets longer (O(n4)). Following Koo and Collins (2010), we eliminate unlikely dependencies using a form of coarse-to-fine pruning (Charniak and Johnson, 2005; Petrov and Klein, 2007). On the development set, 68.87% of the dependencies are pruned, while the oracle dependency accuracy is 99.77%. We use 10-fold cross validation to do pruning on the training set. 5 Experiments We use the Penn Chinese Treebank 5.1 (CTB5) (Xue et al., 2005). Following the setup of Duan et al. (2007), Zhang and Clark (2008b) and Huang and Sagae (2010), we split CTB5 into training (secs 001- 815 and 1001-1136), development (secs 886-931 and 1148-1151), and test (secs 816-885 and 1137- 1147) sets. We use the head-finding rules of Zhang and Clark (2008b) to turn the bracketed sentences into dependency structures. We use the standard tagging accuracy to evaluate POS tagging. For dependency parsing, we use word accuracy (also known as dependency accuracy), root accuracy and complete match rate (all excluding punctuation) . For the averaged training, we train each model for 15 iterations and select the parameters that perform best on the develop</context>
<context position="26671" citStr="Huang and Sagae (2010)" startWordPosition="4622" endWordPosition="4625">C08 hybrid 85.77 76.26 34.41 - Duan07 83.88 73.70 32.70 - Table 3: Final results on the test set. “Gold POS” means that gold POS tags are used as input by the pipelined parsing models; while “Auto POS” means that the POS tags are generated by the baseline POS tagging model. top k word root compl. acc. speed 2 81.46 76.12 30.50 93.51 2.7 3 82.11 76.75 29.75 93.31 1.7 4 81.75 76.62 30.38 93.25 1.4 5 81.83 76.62 30.62 93.16 1.2 Table 2: Performance of the second-order joint model of version 1 with different top k (At = 0.01) on the development set. the beam search. H&amp;S10 refers to the results of Huang and Sagae (2010). They greatly expand the search space of the transition-based model by merging equivalent states with dynamic programming. Z&amp;C08 refers to the results of Zhang and Clark (2008b). They use a hybrid model to combine the advantages of both graph-based and transition-based models. We also do experiments with two publicly available and widely-used parsers, MSTParser6 and MaltParser7. MSTParser1 refers to the first-order 6http://sourceforge.net/projects/mstparser/ 7http://maltparser.org/ graph-based model of McDonald et al. (2005), while MSTParser2 is the second-order model of McDonald and Pereira </context>
</contexts>
<marker>Huang, Sagae, 2010</marker>
<rawString>Liang Huang and Kenji Sagae. 2010. Dynamic programming for linear-time incremental parsing. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1077–1086, Uppsala, Sweden, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wenbin Jiang</author>
<author>Liang Huang</author>
<author>Qun Liu</author>
<author>Yajuan L¨u</author>
</authors>
<title>A cascaded linear model for joint chinese word segmentation and part-of-speech tagging.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT,</booktitle>
<pages>897--904</pages>
<marker>Jiang, Huang, Liu, L¨u, 2008</marker>
<rawString>Wenbin Jiang, Liang Huang, Qun Liu, and Yajuan L¨u. 2008. A cascaded linear model for joint chinese word segmentation and part-of-speech tagging. In Proceedings of ACL-08: HLT, pages 897–904.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Terry Koo</author>
<author>Michael Collins</author>
</authors>
<title>Efficient thirdorder dependency parsers.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1--11</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Uppsala, Sweden,</location>
<contexts>
<context position="6996" citStr="Koo and Collins, 2010" startWordPosition="1114" endWordPosition="1117"> 2.1 POS Tagging POS tagging is a typical sequence labeling problem. Many models have been successfully applied to sequence labeling problems, such as maximumentropy (Ratnaparkhi, 1996), conditional random fields (CRF) (Lafferty et al., 2001) and perceptron (Collins, 2002). We use perceptron to build our POS tagging baseline for two reasons. Firstly, as a linear model, perceptron is simple, fast, and effective. It is competitive to CRF in tagging accuracy but requires much less training time (Shen et al., 2007). Secondly, perceptron has been successfully applied to dependency parsing as well (Koo and Collins, 2010). In this paper, perceptron is used in all models including the POS tagging model, the dependency parsing models and the joint models. In a perceptron, the score of a tag sequence is Scorepog(x,t) = wpog · fpog(x,t) where fpog(x, t) refers to the feature vector and wpog is the corresponding weight vector. For POS tagging features, we follow the work of Zhang and Clark (2008a). Three feature sets are considered: POS unigram, bigram and trigram features. For brevity, we will refer to the three sets as wi ti, ti−1 ti and ti−2 ti−1 ti. Given wpog, we adopt the Viterbi algorithm to get the optimal </context>
<context position="8523" citStr="Koo and Collins, 2010" startWordPosition="1381" endWordPosition="1384">n efficiently find an optimal tree in a huge search space. In a graph-based model, the t� = arg max t 1181 score of a dependency tree is factored into scores of small parts (subtrees). 5coresyn(x, t, d) = wsyn · fsyn(x, t, d) �= 5coresyn(x, t, p) pCd where p is a scoring part which contains one or more dependencies in the dependency tree d. Figure 1 shows different types of scoring parts used in current graph-based models. h In h s In g h In dependency sibling grandparent g h s In h t s In grand-sibling tri-sibling Figure 1: Different types of scoring parts used in current graph-based models (Koo and Collins, 2010). Eisner (1996) proposes an O(n3) decoding algorithm for dependency parsing. Based on the algorithm, McDonald et al. (2005) propose the firstorder model, in which the scoring parts only contains dependencies. The second-order model of McDonald and Pereira (2006) incorporates sibling parts and also needs O(n3) parsing time. The secondorder model of Carreras (2007) incorporates both sibling and grandparent parts, and needs O(n4) parsing time. However, the grandparent parts are restricted to those composed of outermost grandchildren. Koo and Collins (2010) propose efficient decoding algorithms of</context>
<context position="9770" citStr="Koo and Collins (2010)" startWordPosition="1582" endWordPosition="1585">dels. In their paper, they implement two versions of third-order models, Model 1 and Model 2 according to their naming. Model 1 incorporates only grand-sibling parts, while Model 2 incorporates both grand-sibling and tri-sibling parts. Their experiments on English and Czech show that Model 1 and Model 2 obtain nearly the same parsing accuracy. Therefore, we use Model 1 as our third-order model in this paper. We use three versions of graph-based dependency parsing models. • The first-order model (O1): the same with McDonald et al. (2005). • The second-order model (O2): the same with Model 1 in Koo and Collins (2010), but without using grand-sibling features.2 • The third-order model (O3): the same with Model 1 in Koo and Collins (2010). We adopt linear models to define the score of a dependency tree. For the third-order model, the score of a dependency tree is represented as: �5coresyn(x, t, d) = wdep · fdep(x, t, h,m) {(h,m)}Cd + � wsib · fsib(x, t, h, s, m) {(h,s)(h,m)}Cd + � wgrd · fgrd(x, t, g, h, m) {(g,h),(h,m)}Cd + � wgsib · fgsib(x, t, g, h, s, m) {(g,h),(h,s),(h,m)}Cd For the first- and second-order models, the above formula is modified by deactivating extra parts. For parsing features, we follo</context>
<context position="11244" citStr="Koo and Collins (2010)" startWordPosition="1844" endWordPosition="1847">p(x, t, h, m) – Unigram Features: whth dir, wmtm dir – Bigram Features: whth wmtm dir dist – In Between Features: th tb tm dir dist – Surrounding Features: th−1 th th+1 tm−1 tm tm+1 dir dist • Sibling Features, fsib(x, t, h, s, m) wh th ws ts wm tm dir • Grandparent Features, fgrd(x, t, g, h, m) wg tg wh th wm tm dir gdir • Grand-sibling Features, fgsib(x, t, g, h, s, m) wg tg wh th ws ts wm tm dir gdir 2This second-order model incorporates grandparent features composed of all grandchildren rather than just outermost ones, and outperforms the one of Carreras (2007) according to the results in Koo and Collins (2010). 1182 where b denotes an index between h and m; dir and dist are the direction and distance of (h, m); gdir is the direction of (g, h). We also use backoff features by generalizing from very specific features over word forms, POS tags, directions and distances to less sparse features over just POS tags or considering fewer nodes. To avoid producing too many sparse features, at most two word forms are used at the same time in sibling, grandparent and grand-sibling features, while POS tags are used instead for other nodes; meanwhile, at most four POS tags are considered at the same time for sur</context>
<context position="13132" citStr="Koo and Collins (2010)" startWordPosition="2163" endWordPosition="2166">d-order joint models according to the syntactic features contained in fsyn(.). In the following, we propose two versions of joint models which can capture different feature sets and have different complexity. 3.1 Joint Models of Version 1 The crucial problem for the joint method is to design effective decoding algorithms to capture rich features and efficiently search out the optimal results from a huge hypothesis space. Eisner (2000) describes a preliminary idea to handle polysemy by extending parsing algorithms. Based on this idea, we extend decoding algorithms of McDonald et al. (2005) and Koo and Collins (2010), and propose two DP based decoding algorithms for our joint models of version 1. Figure 2: The DP structures and derivations of the firstorder decoding algorithm of joint models of version 1. We omit symmetric right-headed versions for brevity. Trapezoids denote incomplete spans. Triangles denote complete spans. Solid circles denote POS tags of the corresponding indices. The decoding algorithm of O1: As shown in Figure 2, the first-order joint decoding algorithm utilizes two types of dynamic programming structures. (1) Incomplete spans consist of a dependency and the region between the head a</context>
<context position="21591" citStr="Koo and Collins (2010)" startWordPosition="3706" endWordPosition="3709">uted using the forward-backward algorithm. We define pmaxi(x) to be the highest marginal probability of tagging the word wi: pmaxi(x) = max tET P(ti = t|x) We then define the allowable candidate POS tags of the word wi to be Ti(x) = It : t E T ,P(ti = t|x) &gt; At x pmaxi(x)} where At is the pruning threshold. Ti(x) is used to constrain the POS search space by replacing T in Algorithm 1. P(t|x) = 1185 proportion of words (%) 4.2 Dependency Pruning The parsing time grows quickly for the second- and third-order models (both baseline and joint) when the input sentence gets longer (O(n4)). Following Koo and Collins (2010), we eliminate unlikely dependencies using a form of coarse-to-fine pruning (Charniak and Johnson, 2005; Petrov and Klein, 2007). On the development set, 68.87% of the dependencies are pruned, while the oracle dependency accuracy is 99.77%. We use 10-fold cross validation to do pruning on the training set. 5 Experiments We use the Penn Chinese Treebank 5.1 (CTB5) (Xue et al., 2005). Following the setup of Duan et al. (2007), Zhang and Clark (2008b) and Huang and Sagae (2010), we split CTB5 into training (secs 001- 815 and 1001-1136), development (secs 886-931 and 1148-1151), and test (secs 816</context>
<context position="27837" citStr="Koo and Collins (2010)" startWordPosition="4791" endWordPosition="4794">rser2 is the second-order model of McDonald and Pereira (2006). MaltParser is a transitionbased parsing system. It integrates a number of classification algorithms and transition strategies. We adopt the support vector machine classifier and the arc-standard strategy (Nivre, 2008). We can see that when using gold tags, our pipelined second- and third-order parsing models achieve best parsing accuracy, which is even higher than the hybrid model of Zhang and Clark (2008b). It is a little surprising that the second-order model slightly outperforms the third-order one. This may be possible, since Koo and Collins (2010) shows that the third-order model outperforms the second-order one by only 0.32% on English and 0.07% on Czech. In addition, we only use basic third-order features. Both joint models of version 1 and 2 can consistently and significantly improve the parsing accuracy by about 1.5% for all first-, second- and thirdorder cases. Accidentally, the parsing accuracy of the second-order joint model of version 2 is lower 1187 error pattern # error pattern # r DEC DEG 237 114 NR NN 184 100 NN VV 389 73 NN NR 106 91 DEG DEC 170 39 NN JJ 95 70 VV NN 453 27 VA VV 29 41 P VV 52 24 JJ NN 126 29 P CC 39 13 VV </context>
<context position="34562" citStr="Koo and Collins (2010)" startWordPosition="6014" endWordPosition="6017">margin. However, the proportion of these patterns is substantially decreased, since the joint model can better resolve these ambiguities with the help of syntactic knowledge. In summary, we can conclude that the joint model is able to choose such POS tags that are more helpful and discriminative from parsing viewpoint. This is the fundamental reason of the parsing performance improvement. 6 Related Work Theoretically, Eisner (2000) proposes a preliminary idea of extending the decoding algorithm for dependency parsing to handle polysemy. Here, word senses can be understood as POS-tagged words. Koo and Collins (2010) also briefly discuss that their third-order decoding algorithm can be modified to handle word senses using the idea of Eisner (2000). In his PhD thesis, McDonald (2006) extends his second-order model with the idea of Eisner (2000) to study the impact of POS tagging errors on parsing accuracy. To make inference tractable, he uses top 2 candidate POS tags for each word based on a maximum entropy tagger, and adopts the single most likely POS tags for the surrounding and in between features. He conducts primitive experiments on English Penn Treebank, and shows that parsing accuracy can be improve</context>
</contexts>
<marker>Koo, Collins, 2010</marker>
<rawString>Terry Koo and Michael Collins. 2010. Efficient thirdorder dependency parsers. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1–11, Uppsala, Sweden, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Canasai Kruengkrai</author>
<author>Kiyotaka Uchimoto</author>
<author>Jun’ichi Kazama</author>
<author>Yiou Wang</author>
<author>Kentaro Torisawa</author>
<author>Hitoshi Isahara</author>
</authors>
<title>An error-driven word-character hybrid model for joint chinese word segmentation and pos tagging.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP,</booktitle>
<pages>513--521</pages>
<contexts>
<context position="2743" citStr="Kruengkrai et al., 2009" startWordPosition="416" endWordPosition="419">tomatic POS tagging results instead of gold ones (see Table 3 in Section 5). Recent research on dependency parsing usually overlooks this issue by simply adopting gold POS tags for Chinese data (Duan et al., 2007; Zhang and Clark, 2008b; Huang and Sagae, 2010). In this paper, we address this issue by jointly optimizing POS tagging and dependency parsing. Joint modeling has been a popular and effective approach to simultaneously solve related tasks. Recently, many successful joint models have been proposed, such as joint tokenization and POS tagging (Zhang and Clark, 2008a; Jiang et al., 2008; Kruengkrai et al., 2009), joint lemmatization and POS tagging (Toutanova and Cherry, 2009), joint tokenization and parsing (Cohen and Smith, 2007; Goldberg and Tsarfaty, 2008), joint named entity recognition and parsing (Finkel and Manning, 2009), joint parsing and semantic role labeling (SRL) (Li et al., 2010), joint word sense disambiguation and SRL (Che and Liu, 2010), joint tokenization and machine translation (MT) (Dyer, 2009; Xiao et al., 2010) and joint parsing and MT (Liu and Liu, 2010). Note that the aforementioned “parsing” all refer to constituent parsing. As far as we know, there are few successful models</context>
</contexts>
<marker>Kruengkrai, Uchimoto, Kazama, Wang, Torisawa, Isahara, 2009</marker>
<rawString>Canasai Kruengkrai, Kiyotaka Uchimoto, Jun’ichi Kazama, Yiou Wang, Kentaro Torisawa, and Hitoshi Isahara. 2009. An error-driven word-character hybrid model for joint chinese word segmentation and pos tagging. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP, pages 513–521.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<booktitle>In Proceedings of ICML</booktitle>
<pages>282--289</pages>
<contexts>
<context position="6616" citStr="Lafferty et al., 2001" startWordPosition="1053" endWordPosition="1056">). In addition, Rush et al. (2010) describes an efficient and simple inference algorithm based on dual decomposition and linear programming relaxation to combine a lexicalized constituent parser and a trigram POS tagger. an optimal POS tag sequence t� is determined. Scorepog(x, t) Then, an optimal dependency tree d is determined based on x and t. d = arg max Scoregyn(x, t, d) d 2.1 POS Tagging POS tagging is a typical sequence labeling problem. Many models have been successfully applied to sequence labeling problems, such as maximumentropy (Ratnaparkhi, 1996), conditional random fields (CRF) (Lafferty et al., 2001) and perceptron (Collins, 2002). We use perceptron to build our POS tagging baseline for two reasons. Firstly, as a linear model, perceptron is simple, fast, and effective. It is competitive to CRF in tagging accuracy but requires much less training time (Shen et al., 2007). Secondly, perceptron has been successfully applied to dependency parsing as well (Koo and Collins, 2010). In this paper, perceptron is used in all models including the POS tagging model, the dependency parsing models and the joint models. In a perceptron, the score of a tag sequence is Scorepog(x,t) = wpog · fpog(x,t) wher</context>
<context position="20582" citStr="Lafferty et al., 2001" startWordPosition="3526" endWordPosition="3529">e higher complexity. These two versions of models will be thoroughly compared in the experiments. 4.1 POS Tag Pruning The time complexity of the joint decoding algorithm is unbearably high with regard to the number of candidate POS tags for each word (q = |T |). We find that it would be extremely time-consuming even when we only use two most likely POS tags for each word (q = 2) even for joint models of version 1. To deal with this problem, we propose a pruning method that can effectively reduce the POS tag space based on a probabilistic tagging model. We adopt a conditional log-linear model (Lafferty et al., 2001), which defines a conditional distribution of a POS tag sequence t given x: ewpos·fpos(x,t) Et ewpos·fpos(x,t) We use the same feature set fpog defined in Section 2.1, and adopt the exponentiated gradient algorithm to learn the weight vector wpog (Collins et al., 2008). The marginal probability of tagging a word wi as t is P(ti = t|x) = � P(t|x) t:t[i]=—t which can be efficiently computed using the forward-backward algorithm. We define pmaxi(x) to be the highest marginal probability of tagging the word wi: pmaxi(x) = max tET P(ti = t|x) We then define the allowable candidate POS tags of the wo</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John Lafferty, Andrew McCallum, and Fernando Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In Proceedings of ICML 2001, pages 282–289.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roger Levy</author>
<author>Christopher D Manning</author>
</authors>
<title>Is it harder to parse chinese, or the chinese treebank?</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>439--446</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sapporo, Japan,</location>
<contexts>
<context position="5995" citStr="Levy and Manning, 2003" startWordPosition="953" endWordPosition="956">, where ti E T, 1 &lt; i &lt; n, and T is the POS tag set. A dependency tree is denoted by d = {(h, m) : 0 &lt; h &lt; n, 0 &lt; m &lt; n}, where (h, m) represents a dependency wh -+ wm whose head word (or father) is wh and modifier (or child) is wm. w0 is an artificial root token which is used to simplify the formalization of the problem. The pipelined method treats POS tagging and dependency parsing as two cascaded problems. First, &apos;It should be noted that it is straightforward to simultaneously do POS tagging and constituent parsing, as POS tags can be regarded as non-terminals in the constituent structure (Levy and Manning, 2003). In addition, Rush et al. (2010) describes an efficient and simple inference algorithm based on dual decomposition and linear programming relaxation to combine a lexicalized constituent parser and a trigram POS tagger. an optimal POS tag sequence t� is determined. Scorepog(x, t) Then, an optimal dependency tree d is determined based on x and t. d = arg max Scoregyn(x, t, d) d 2.1 POS Tagging POS tagging is a typical sequence labeling problem. Many models have been successfully applied to sequence labeling problems, such as maximumentropy (Ratnaparkhi, 1996), conditional random fields (CRF) (L</context>
</contexts>
<marker>Levy, Manning, 2003</marker>
<rawString>Roger Levy and Christopher D. Manning. 2003. Is it harder to parse chinese, or the chinese treebank? In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics, pages 439–446, Sapporo, Japan, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Junhui Li</author>
<author>Guodong Zhou</author>
<author>Hwee Tou Ng</author>
</authors>
<title>Joint syntactic and semantic parsing of chinese.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1108--1117</pages>
<contexts>
<context position="3031" citStr="Li et al., 2010" startWordPosition="459" endWordPosition="462">ue by jointly optimizing POS tagging and dependency parsing. Joint modeling has been a popular and effective approach to simultaneously solve related tasks. Recently, many successful joint models have been proposed, such as joint tokenization and POS tagging (Zhang and Clark, 2008a; Jiang et al., 2008; Kruengkrai et al., 2009), joint lemmatization and POS tagging (Toutanova and Cherry, 2009), joint tokenization and parsing (Cohen and Smith, 2007; Goldberg and Tsarfaty, 2008), joint named entity recognition and parsing (Finkel and Manning, 2009), joint parsing and semantic role labeling (SRL) (Li et al., 2010), joint word sense disambiguation and SRL (Che and Liu, 2010), joint tokenization and machine translation (MT) (Dyer, 2009; Xiao et al., 2010) and joint parsing and MT (Liu and Liu, 2010). Note that the aforementioned “parsing” all refer to constituent parsing. As far as we know, there are few successful models for jointly solving dependency parsing and other tasks. Being facilitated by Conference on Computational Natural Language Learning (CoNLL) 2008 and 2009 shared tasks, several joint models of dependency parsing and SRL have been proposed. Nevertheless, the top-ranked systems all adopt pi</context>
</contexts>
<marker>Li, Zhou, Ng, 2010</marker>
<rawString>Junhui Li, Guodong Zhou, and Hwee Tou Ng. 2010. Joint syntactic and semantic parsing of chinese. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1108– 1117.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yang Liu</author>
<author>Qun Liu</author>
</authors>
<title>Joint parsing and translation.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics (Coling</booktitle>
<pages>707--715</pages>
<contexts>
<context position="3218" citStr="Liu and Liu, 2010" startWordPosition="491" endWordPosition="494">int models have been proposed, such as joint tokenization and POS tagging (Zhang and Clark, 2008a; Jiang et al., 2008; Kruengkrai et al., 2009), joint lemmatization and POS tagging (Toutanova and Cherry, 2009), joint tokenization and parsing (Cohen and Smith, 2007; Goldberg and Tsarfaty, 2008), joint named entity recognition and parsing (Finkel and Manning, 2009), joint parsing and semantic role labeling (SRL) (Li et al., 2010), joint word sense disambiguation and SRL (Che and Liu, 2010), joint tokenization and machine translation (MT) (Dyer, 2009; Xiao et al., 2010) and joint parsing and MT (Liu and Liu, 2010). Note that the aforementioned “parsing” all refer to constituent parsing. As far as we know, there are few successful models for jointly solving dependency parsing and other tasks. Being facilitated by Conference on Computational Natural Language Learning (CoNLL) 2008 and 2009 shared tasks, several joint models of dependency parsing and SRL have been proposed. Nevertheless, the top-ranked systems all adopt pipelined approaches (Surdeanu et al., 2008; 1180 Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1180–1191, Edinburgh, Scotland, UK, July 27–3</context>
</contexts>
<marker>Liu, Liu, 2010</marker>
<rawString>Yang Liu and Qun Liu. 2010. Joint parsing and translation. In Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 707–715.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Fernando Pereira</author>
</authors>
<title>Online learning of approximate dependency parsing algorithms.</title>
<date>2006</date>
<booktitle>In Proceedings of EACL</booktitle>
<contexts>
<context position="8785" citStr="McDonald and Pereira (2006)" startWordPosition="1423" endWordPosition="1427">p is a scoring part which contains one or more dependencies in the dependency tree d. Figure 1 shows different types of scoring parts used in current graph-based models. h In h s In g h In dependency sibling grandparent g h s In h t s In grand-sibling tri-sibling Figure 1: Different types of scoring parts used in current graph-based models (Koo and Collins, 2010). Eisner (1996) proposes an O(n3) decoding algorithm for dependency parsing. Based on the algorithm, McDonald et al. (2005) propose the firstorder model, in which the scoring parts only contains dependencies. The second-order model of McDonald and Pereira (2006) incorporates sibling parts and also needs O(n3) parsing time. The secondorder model of Carreras (2007) incorporates both sibling and grandparent parts, and needs O(n4) parsing time. However, the grandparent parts are restricted to those composed of outermost grandchildren. Koo and Collins (2010) propose efficient decoding algorithms of O(n4) for third-order models. In their paper, they implement two versions of third-order models, Model 1 and Model 2 according to their naming. Model 1 incorporates only grand-sibling parts, while Model 2 incorporates both grand-sibling and tri-sibling parts. T</context>
<context position="27277" citStr="McDonald and Pereira (2006)" startWordPosition="4704" endWordPosition="4708">uang and Sagae (2010). They greatly expand the search space of the transition-based model by merging equivalent states with dynamic programming. Z&amp;C08 refers to the results of Zhang and Clark (2008b). They use a hybrid model to combine the advantages of both graph-based and transition-based models. We also do experiments with two publicly available and widely-used parsers, MSTParser6 and MaltParser7. MSTParser1 refers to the first-order 6http://sourceforge.net/projects/mstparser/ 7http://maltparser.org/ graph-based model of McDonald et al. (2005), while MSTParser2 is the second-order model of McDonald and Pereira (2006). MaltParser is a transitionbased parsing system. It integrates a number of classification algorithms and transition strategies. We adopt the support vector machine classifier and the arc-standard strategy (Nivre, 2008). We can see that when using gold tags, our pipelined second- and third-order parsing models achieve best parsing accuracy, which is even higher than the hybrid model of Zhang and Clark (2008b). It is a little surprising that the second-order model slightly outperforms the third-order one. This may be possible, since Koo and Collins (2010) shows that the third-order model outper</context>
</contexts>
<marker>McDonald, Pereira, 2006</marker>
<rawString>Ryan McDonald and Fernando Pereira. 2006. Online learning of approximate dependency parsing algorithms. In Proceedings of EACL 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Koby Crammer</author>
<author>Fernando Pereira</author>
</authors>
<title>Online large-margin training of dependency parsers.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL</booktitle>
<pages>91--98</pages>
<contexts>
<context position="8646" citStr="McDonald et al. (2005)" startWordPosition="1401" endWordPosition="1404">dency tree is factored into scores of small parts (subtrees). 5coresyn(x, t, d) = wsyn · fsyn(x, t, d) �= 5coresyn(x, t, p) pCd where p is a scoring part which contains one or more dependencies in the dependency tree d. Figure 1 shows different types of scoring parts used in current graph-based models. h In h s In g h In dependency sibling grandparent g h s In h t s In grand-sibling tri-sibling Figure 1: Different types of scoring parts used in current graph-based models (Koo and Collins, 2010). Eisner (1996) proposes an O(n3) decoding algorithm for dependency parsing. Based on the algorithm, McDonald et al. (2005) propose the firstorder model, in which the scoring parts only contains dependencies. The second-order model of McDonald and Pereira (2006) incorporates sibling parts and also needs O(n3) parsing time. The secondorder model of Carreras (2007) incorporates both sibling and grandparent parts, and needs O(n4) parsing time. However, the grandparent parts are restricted to those composed of outermost grandchildren. Koo and Collins (2010) propose efficient decoding algorithms of O(n4) for third-order models. In their paper, they implement two versions of third-order models, Model 1 and Model 2 accor</context>
<context position="13105" citStr="McDonald et al. (2005)" startWordPosition="2158" endWordPosition="2161">e first-, second-, and third-order joint models according to the syntactic features contained in fsyn(.). In the following, we propose two versions of joint models which can capture different feature sets and have different complexity. 3.1 Joint Models of Version 1 The crucial problem for the joint method is to design effective decoding algorithms to capture rich features and efficiently search out the optimal results from a huge hypothesis space. Eisner (2000) describes a preliminary idea to handle polysemy by extending parsing algorithms. Based on this idea, we extend decoding algorithms of McDonald et al. (2005) and Koo and Collins (2010), and propose two DP based decoding algorithms for our joint models of version 1. Figure 2: The DP structures and derivations of the firstorder decoding algorithm of joint models of version 1. We omit symmetric right-headed versions for brevity. Trapezoids denote incomplete spans. Triangles denote complete spans. Solid circles denote POS tags of the corresponding indices. The decoding algorithm of O1: As shown in Figure 2, the first-order joint decoding algorithm utilizes two types of dynamic programming structures. (1) Incomplete spans consist of a dependency and th</context>
<context position="27202" citStr="McDonald et al. (2005)" startWordPosition="4693" endWordPosition="4696">the development set. the beam search. H&amp;S10 refers to the results of Huang and Sagae (2010). They greatly expand the search space of the transition-based model by merging equivalent states with dynamic programming. Z&amp;C08 refers to the results of Zhang and Clark (2008b). They use a hybrid model to combine the advantages of both graph-based and transition-based models. We also do experiments with two publicly available and widely-used parsers, MSTParser6 and MaltParser7. MSTParser1 refers to the first-order 6http://sourceforge.net/projects/mstparser/ 7http://maltparser.org/ graph-based model of McDonald et al. (2005), while MSTParser2 is the second-order model of McDonald and Pereira (2006). MaltParser is a transitionbased parsing system. It integrates a number of classification algorithms and transition strategies. We adopt the support vector machine classifier and the arc-standard strategy (Nivre, 2008). We can see that when using gold tags, our pipelined second- and third-order parsing models achieve best parsing accuracy, which is even higher than the hybrid model of Zhang and Clark (2008b). It is a little surprising that the second-order model slightly outperforms the third-order one. This may be pos</context>
</contexts>
<marker>McDonald, Crammer, Pereira, 2005</marker>
<rawString>Ryan McDonald, Koby Crammer, and Fernando Pereira. 2005. Online large-margin training of dependency parsers. In Proceedings of ACL 2005, pages 91–98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
</authors>
<title>Discriminative Training and Spanning Tree Algorithms for Dependency Parsing.</title>
<date>2006</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Pennsylvania.</institution>
<contexts>
<context position="10440" citStr="McDonald, 2006" startWordPosition="1700" endWordPosition="1702">-order model (O3): the same with Model 1 in Koo and Collins (2010). We adopt linear models to define the score of a dependency tree. For the third-order model, the score of a dependency tree is represented as: �5coresyn(x, t, d) = wdep · fdep(x, t, h,m) {(h,m)}Cd + � wsib · fsib(x, t, h, s, m) {(h,s)(h,m)}Cd + � wgrd · fgrd(x, t, g, h, m) {(g,h),(h,m)}Cd + � wgsib · fgsib(x, t, g, h, s, m) {(g,h),(h,s),(h,m)}Cd For the first- and second-order models, the above formula is modified by deactivating extra parts. For parsing features, we follow standard practice for graph-based dependency parsing (McDonald, 2006; Carreras, 2007; Koo and Collins, 2010). Since these features are highly related with our joint decoding algorithms, we summarize the features as follows. • Dependency Features, fdep(x, t, h, m) – Unigram Features: whth dir, wmtm dir – Bigram Features: whth wmtm dir dist – In Between Features: th tb tm dir dist – Surrounding Features: th−1 th th+1 tm−1 tm tm+1 dir dist • Sibling Features, fsib(x, t, h, s, m) wh th ws ts wm tm dir • Grandparent Features, fgrd(x, t, g, h, m) wg tg wh th wm tm dir gdir • Grand-sibling Features, fgsib(x, t, g, h, s, m) wg tg wh th ws ts wm tm dir gdir 2This secon</context>
<context position="15766" citStr="McDonald, 2006" startWordPosition="2632" endWordPosition="2634">1)ET2{C(i,r)(ti,tr) + C(j,r+1)(tj,tr+1) + Scorejoint(x, ti, tr, tr+1, tj, p = {(i, j)})} 7: I(j,i)(tj ,ti) = maxi&lt;r&lt;j max(tr,tr+1)ET2{C(i,r)(ti,tr) + C(j,r+1)(tj ,tr+1) + Scorejoint(x, ti, tr, tr+1, tj, p = {(j, i)})} 8: C(i,j)(ti,tj) = maxi&lt;r&lt;j maxtrET {I(i,r)(ti,tr) + C(r,j)(tr,tj) + Scorejoint(x, ti, tr, tj, p = ∅)} 9: C(j,i)(tj,ti) = maxi&lt;r&lt;j maxtrET {C(r,i)(tr,ti) + I(j,r)(tj,tr) + Scorejoint(x, ti, tr, tj, p = ∅)} 10: end for 11: end for 12: end for tures. Therefore, we adopt pseudo surrounding and in between features by simply fixing the context POS tags as the single most likely ones (McDonald, 2006). Taking the in between features as an example, we use ti tb tj dir dist instead, where line POS tagger. The POS features, denoted by fpog(x, ti, tr, tr+1, tj), can only incorporate all POS unigram and bigram features.3 Similarly, we use pseudo POS trigram features such as �tr−1 tr tr+1. Line 8 corresponds to the derivation in Figure 2- (b). Since this combination invents no scoring part (p = 0), Scorejoint(x, ti, tr, tj, p = 0) is only composed of POS features.4 Line 7 and Line 9 create spans in the opposite direction, which can be analogously illustrated. The space and time complexity of the</context>
<context position="34731" citStr="McDonald (2006)" startWordPosition="6043" endWordPosition="6044">n summary, we can conclude that the joint model is able to choose such POS tags that are more helpful and discriminative from parsing viewpoint. This is the fundamental reason of the parsing performance improvement. 6 Related Work Theoretically, Eisner (2000) proposes a preliminary idea of extending the decoding algorithm for dependency parsing to handle polysemy. Here, word senses can be understood as POS-tagged words. Koo and Collins (2010) also briefly discuss that their third-order decoding algorithm can be modified to handle word senses using the idea of Eisner (2000). In his PhD thesis, McDonald (2006) extends his second-order model with the idea of Eisner (2000) to study the impact of POS tagging errors on parsing accuracy. To make inference tractable, he uses top 2 candidate POS tags for each word based on a maximum entropy tagger, and adopts the single most likely POS tags for the surrounding and in between features. He conducts primitive experiments on English Penn Treebank, and shows that parsing accuracy can be improved from 91.5% to 91.9%. However, he finds that the model is unbearably timeconsuming. 7 Conclusions In this paper, we have systematically investigated the issue of joint </context>
</contexts>
<marker>McDonald, 2006</marker>
<rawString>Ryan McDonald. 2006. Discriminative Training and Spanning Tree Algorithms for Dependency Parsing. Ph.D. thesis, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
</authors>
<title>Algorithms for deterministic incremental dependency parsing.</title>
<date>2008</date>
<booktitle>In Computational Linguistics,</booktitle>
<volume>34</volume>
<pages>513--553</pages>
<contexts>
<context position="27496" citStr="Nivre, 2008" startWordPosition="4738" endWordPosition="4739">e the advantages of both graph-based and transition-based models. We also do experiments with two publicly available and widely-used parsers, MSTParser6 and MaltParser7. MSTParser1 refers to the first-order 6http://sourceforge.net/projects/mstparser/ 7http://maltparser.org/ graph-based model of McDonald et al. (2005), while MSTParser2 is the second-order model of McDonald and Pereira (2006). MaltParser is a transitionbased parsing system. It integrates a number of classification algorithms and transition strategies. We adopt the support vector machine classifier and the arc-standard strategy (Nivre, 2008). We can see that when using gold tags, our pipelined second- and third-order parsing models achieve best parsing accuracy, which is even higher than the hybrid model of Zhang and Clark (2008b). It is a little surprising that the second-order model slightly outperforms the third-order one. This may be possible, since Koo and Collins (2010) shows that the third-order model outperforms the second-order one by only 0.32% on English and 0.07% on Czech. In addition, we only use basic third-order features. Both joint models of version 1 and 2 can consistently and significantly improve the parsing ac</context>
</contexts>
<marker>Nivre, 2008</marker>
<rawString>Joakim Nivre. 2008. Algorithms for deterministic incremental dependency parsing. In Computational Linguistics, volume 34, pages 513–553.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Dan Klein</author>
</authors>
<title>Improved inference for unlexicalized parsing.</title>
<date>2007</date>
<booktitle>In Proceedings of NAACL</booktitle>
<contexts>
<context position="21719" citStr="Petrov and Klein, 2007" startWordPosition="3725" endWordPosition="3728">axi(x) = max tET P(ti = t|x) We then define the allowable candidate POS tags of the word wi to be Ti(x) = It : t E T ,P(ti = t|x) &gt; At x pmaxi(x)} where At is the pruning threshold. Ti(x) is used to constrain the POS search space by replacing T in Algorithm 1. P(t|x) = 1185 proportion of words (%) 4.2 Dependency Pruning The parsing time grows quickly for the second- and third-order models (both baseline and joint) when the input sentence gets longer (O(n4)). Following Koo and Collins (2010), we eliminate unlikely dependencies using a form of coarse-to-fine pruning (Charniak and Johnson, 2005; Petrov and Klein, 2007). On the development set, 68.87% of the dependencies are pruned, while the oracle dependency accuracy is 99.77%. We use 10-fold cross validation to do pruning on the training set. 5 Experiments We use the Penn Chinese Treebank 5.1 (CTB5) (Xue et al., 2005). Following the setup of Duan et al. (2007), Zhang and Clark (2008b) and Huang and Sagae (2010), we split CTB5 into training (secs 001- 815 and 1001-1136), development (secs 886-931 and 1148-1151), and test (secs 816-885 and 1137- 1147) sets. We use the head-finding rules of Zhang and Clark (2008b) to turn the bracketed sentences into depende</context>
</contexts>
<marker>Petrov, Klein, 2007</marker>
<rawString>Slav Petrov and Dan Klein. 2007. Improved inference for unlexicalized parsing. In Proceedings of NAACL 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adwait Ratnaparkhi</author>
</authors>
<title>A maximum entropy model for part-of-speech tagging.</title>
<date>1996</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<contexts>
<context position="6559" citStr="Ratnaparkhi, 1996" startWordPosition="1047" endWordPosition="1048"> in the constituent structure (Levy and Manning, 2003). In addition, Rush et al. (2010) describes an efficient and simple inference algorithm based on dual decomposition and linear programming relaxation to combine a lexicalized constituent parser and a trigram POS tagger. an optimal POS tag sequence t� is determined. Scorepog(x, t) Then, an optimal dependency tree d is determined based on x and t. d = arg max Scoregyn(x, t, d) d 2.1 POS Tagging POS tagging is a typical sequence labeling problem. Many models have been successfully applied to sequence labeling problems, such as maximumentropy (Ratnaparkhi, 1996), conditional random fields (CRF) (Lafferty et al., 2001) and perceptron (Collins, 2002). We use perceptron to build our POS tagging baseline for two reasons. Firstly, as a linear model, perceptron is simple, fast, and effective. It is competitive to CRF in tagging accuracy but requires much less training time (Shen et al., 2007). Secondly, perceptron has been successfully applied to dependency parsing as well (Koo and Collins, 2010). In this paper, perceptron is used in all models including the POS tagging model, the dependency parsing models and the joint models. In a perceptron, the score o</context>
</contexts>
<marker>Ratnaparkhi, 1996</marker>
<rawString>Adwait Ratnaparkhi. 1996. A maximum entropy model for part-of-speech tagging. In Proceedings of EMNLP 1996.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander M Rush</author>
<author>David Sontag</author>
<author>Michael Collins</author>
<author>Tommi Jaakkola</author>
</authors>
<title>On dual decomposition and linear programming relaxations for natural language processing.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1--11</pages>
<contexts>
<context position="6028" citStr="Rush et al. (2010)" startWordPosition="959" endWordPosition="962">e POS tag set. A dependency tree is denoted by d = {(h, m) : 0 &lt; h &lt; n, 0 &lt; m &lt; n}, where (h, m) represents a dependency wh -+ wm whose head word (or father) is wh and modifier (or child) is wm. w0 is an artificial root token which is used to simplify the formalization of the problem. The pipelined method treats POS tagging and dependency parsing as two cascaded problems. First, &apos;It should be noted that it is straightforward to simultaneously do POS tagging and constituent parsing, as POS tags can be regarded as non-terminals in the constituent structure (Levy and Manning, 2003). In addition, Rush et al. (2010) describes an efficient and simple inference algorithm based on dual decomposition and linear programming relaxation to combine a lexicalized constituent parser and a trigram POS tagger. an optimal POS tag sequence t� is determined. Scorepog(x, t) Then, an optimal dependency tree d is determined based on x and t. d = arg max Scoregyn(x, t, d) d 2.1 POS Tagging POS tagging is a typical sequence labeling problem. Many models have been successfully applied to sequence labeling problems, such as maximumentropy (Ratnaparkhi, 1996), conditional random fields (CRF) (Lafferty et al., 2001) and percept</context>
</contexts>
<marker>Rush, Sontag, Collins, Jaakkola, 2010</marker>
<rawString>Alexander M Rush, David Sontag, Michael Collins, and Tommi Jaakkola. 2010. On dual decomposition and linear programming relaxations for natural language processing. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1–11.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Libin Shen</author>
<author>Giorgio Satta</author>
<author>Aravind Joshi</author>
</authors>
<title>Guided learning for bidirectional sequence classification.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>760--767</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="6890" citStr="Shen et al., 2007" startWordPosition="1098" endWordPosition="1101"> t) Then, an optimal dependency tree d is determined based on x and t. d = arg max Scoregyn(x, t, d) d 2.1 POS Tagging POS tagging is a typical sequence labeling problem. Many models have been successfully applied to sequence labeling problems, such as maximumentropy (Ratnaparkhi, 1996), conditional random fields (CRF) (Lafferty et al., 2001) and perceptron (Collins, 2002). We use perceptron to build our POS tagging baseline for two reasons. Firstly, as a linear model, perceptron is simple, fast, and effective. It is competitive to CRF in tagging accuracy but requires much less training time (Shen et al., 2007). Secondly, perceptron has been successfully applied to dependency parsing as well (Koo and Collins, 2010). In this paper, perceptron is used in all models including the POS tagging model, the dependency parsing models and the joint models. In a perceptron, the score of a tag sequence is Scorepog(x,t) = wpog · fpog(x,t) where fpog(x, t) refers to the feature vector and wpog is the corresponding weight vector. For POS tagging features, we follow the work of Zhang and Clark (2008a). Three feature sets are considered: POS unigram, bigram and trigram features. For brevity, we will refer to the thr</context>
</contexts>
<marker>Shen, Satta, Joshi, 2007</marker>
<rawString>Libin Shen, Giorgio Satta, and Aravind Joshi. 2007. Guided learning for bidirectional sequence classification. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 760–767, Prague, Czech Republic, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mihai Surdeanu</author>
<author>Richard Johansson</author>
<author>Adam Meyers</author>
<author>Llu´ıs M`arquez</author>
<author>Joakim Nivre</author>
</authors>
<title>The CoNLL2008 shared task on joint parsing of syntactic and semantic dependencies.</title>
<date>2008</date>
<booktitle>In CoNLL-2008.</booktitle>
<marker>Surdeanu, Johansson, Meyers, M`arquez, Nivre, 2008</marker>
<rawString>Mihai Surdeanu, Richard Johansson, Adam Meyers, Llu´ıs M`arquez, and Joakim Nivre. 2008. The CoNLL2008 shared task on joint parsing of syntactic and semantic dependencies. In CoNLL-2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Colin Cherry</author>
</authors>
<title>A global model for joint lemmatization and part-of-speech prediction.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP,</booktitle>
<pages>486--494</pages>
<contexts>
<context position="2809" citStr="Toutanova and Cherry, 2009" startWordPosition="425" endWordPosition="428">n Section 5). Recent research on dependency parsing usually overlooks this issue by simply adopting gold POS tags for Chinese data (Duan et al., 2007; Zhang and Clark, 2008b; Huang and Sagae, 2010). In this paper, we address this issue by jointly optimizing POS tagging and dependency parsing. Joint modeling has been a popular and effective approach to simultaneously solve related tasks. Recently, many successful joint models have been proposed, such as joint tokenization and POS tagging (Zhang and Clark, 2008a; Jiang et al., 2008; Kruengkrai et al., 2009), joint lemmatization and POS tagging (Toutanova and Cherry, 2009), joint tokenization and parsing (Cohen and Smith, 2007; Goldberg and Tsarfaty, 2008), joint named entity recognition and parsing (Finkel and Manning, 2009), joint parsing and semantic role labeling (SRL) (Li et al., 2010), joint word sense disambiguation and SRL (Che and Liu, 2010), joint tokenization and machine translation (MT) (Dyer, 2009; Xiao et al., 2010) and joint parsing and MT (Liu and Liu, 2010). Note that the aforementioned “parsing” all refer to constituent parsing. As far as we know, there are few successful models for jointly solving dependency parsing and other tasks. Being fac</context>
</contexts>
<marker>Toutanova, Cherry, 2009</marker>
<rawString>Kristina Toutanova and Colin Cherry. 2009. A global model for joint lemmatization and part-of-speech prediction. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP, pages 486–494.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xinyan Xiao</author>
<author>Yang Liu</author>
<author>YoungSook Hwang</author>
<author>Qun Liu</author>
<author>Shouxun Lin</author>
</authors>
<title>Joint tokenization and translation.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics (Coling</booktitle>
<pages>1200--1208</pages>
<contexts>
<context position="3173" citStr="Xiao et al., 2010" startWordPosition="482" endWordPosition="485">e related tasks. Recently, many successful joint models have been proposed, such as joint tokenization and POS tagging (Zhang and Clark, 2008a; Jiang et al., 2008; Kruengkrai et al., 2009), joint lemmatization and POS tagging (Toutanova and Cherry, 2009), joint tokenization and parsing (Cohen and Smith, 2007; Goldberg and Tsarfaty, 2008), joint named entity recognition and parsing (Finkel and Manning, 2009), joint parsing and semantic role labeling (SRL) (Li et al., 2010), joint word sense disambiguation and SRL (Che and Liu, 2010), joint tokenization and machine translation (MT) (Dyer, 2009; Xiao et al., 2010) and joint parsing and MT (Liu and Liu, 2010). Note that the aforementioned “parsing” all refer to constituent parsing. As far as we know, there are few successful models for jointly solving dependency parsing and other tasks. Being facilitated by Conference on Computational Natural Language Learning (CoNLL) 2008 and 2009 shared tasks, several joint models of dependency parsing and SRL have been proposed. Nevertheless, the top-ranked systems all adopt pipelined approaches (Surdeanu et al., 2008; 1180 Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages </context>
</contexts>
<marker>Xiao, Liu, Hwang, Liu, Lin, 2010</marker>
<rawString>Xinyan Xiao, Yang Liu, YoungSook Hwang, Qun Liu, and Shouxun Lin. 2010. Joint tokenization and translation. In Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 1200–1208.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
<author>Fei Xia</author>
<author>Fu-Dong Chiou</author>
<author>Martha Palmer</author>
</authors>
<title>The Penn Chinese Treebank: Phrase structure annotation of a large corpus.</title>
<date>2005</date>
<journal>In Natural Language Engineering,</journal>
<volume>11</volume>
<pages>207--238</pages>
<contexts>
<context position="21975" citStr="Xue et al., 2005" startWordPosition="3769" endWordPosition="3772">(t|x) = 1185 proportion of words (%) 4.2 Dependency Pruning The parsing time grows quickly for the second- and third-order models (both baseline and joint) when the input sentence gets longer (O(n4)). Following Koo and Collins (2010), we eliminate unlikely dependencies using a form of coarse-to-fine pruning (Charniak and Johnson, 2005; Petrov and Klein, 2007). On the development set, 68.87% of the dependencies are pruned, while the oracle dependency accuracy is 99.77%. We use 10-fold cross validation to do pruning on the training set. 5 Experiments We use the Penn Chinese Treebank 5.1 (CTB5) (Xue et al., 2005). Following the setup of Duan et al. (2007), Zhang and Clark (2008b) and Huang and Sagae (2010), we split CTB5 into training (secs 001- 815 and 1001-1136), development (secs 886-931 and 1148-1151), and test (secs 816-885 and 1137- 1147) sets. We use the head-finding rules of Zhang and Clark (2008b) to turn the bracketed sentences into dependency structures. We use the standard tagging accuracy to evaluate POS tagging. For dependency parsing, we use word accuracy (also known as dependency accuracy), root accuracy and complete match rate (all excluding punctuation) . For the averaged training, w</context>
</contexts>
<marker>Xue, Xia, Chiou, Palmer, 2005</marker>
<rawString>Nianwen Xue, Fei Xia, Fu-Dong Chiou, and Martha Palmer. 2005. The Penn Chinese Treebank: Phrase structure annotation of a large corpus. In Natural Language Engineering, volume 11, pages 207–238.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yue Zhang</author>
<author>Stephen Clark</author>
</authors>
<title>Joint word segmentation and POS tagging using a single perceptron.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT,</booktitle>
<pages>888--896</pages>
<contexts>
<context position="2354" citStr="Zhang and Clark, 2008" startWordPosition="353" endWordPosition="356">pagation, especially for Chinese. Due to the lack of morphological features, Chinese POS tagging is even harder than other languages such as English. The state-ofthe-art accuracy of Chinese POS tagging is about 93.5%, which is much lower than that of English (about 97% (Collins, 2002)). Our experimental results show that parsing accuracy decreases by about 6% on Chinese when using automatic POS tagging results instead of gold ones (see Table 3 in Section 5). Recent research on dependency parsing usually overlooks this issue by simply adopting gold POS tags for Chinese data (Duan et al., 2007; Zhang and Clark, 2008b; Huang and Sagae, 2010). In this paper, we address this issue by jointly optimizing POS tagging and dependency parsing. Joint modeling has been a popular and effective approach to simultaneously solve related tasks. Recently, many successful joint models have been proposed, such as joint tokenization and POS tagging (Zhang and Clark, 2008a; Jiang et al., 2008; Kruengkrai et al., 2009), joint lemmatization and POS tagging (Toutanova and Cherry, 2009), joint tokenization and parsing (Cohen and Smith, 2007; Goldberg and Tsarfaty, 2008), joint named entity recognition and parsing (Finkel and Man</context>
<context position="7372" citStr="Zhang and Clark (2008" startWordPosition="1180" endWordPosition="1183">ptron is simple, fast, and effective. It is competitive to CRF in tagging accuracy but requires much less training time (Shen et al., 2007). Secondly, perceptron has been successfully applied to dependency parsing as well (Koo and Collins, 2010). In this paper, perceptron is used in all models including the POS tagging model, the dependency parsing models and the joint models. In a perceptron, the score of a tag sequence is Scorepog(x,t) = wpog · fpog(x,t) where fpog(x, t) refers to the feature vector and wpog is the corresponding weight vector. For POS tagging features, we follow the work of Zhang and Clark (2008a). Three feature sets are considered: POS unigram, bigram and trigram features. For brevity, we will refer to the three sets as wi ti, ti−1 ti and ti−2 ti−1 ti. Given wpog, we adopt the Viterbi algorithm to get the optimal tagging sequence. 2.2 Dependency Parsing Recently, graph-based dependency parsing has gained more and more interest due to its state-ofthe-art accuracy. Graph-based dependency parsing views the problem as finding the highest scoring tree from a directed graph. Based on dynamic programming decoding, it can efficiently find an optimal tree in a huge search space. In a graph-b</context>
<context position="22041" citStr="Zhang and Clark (2008" startWordPosition="3781" endWordPosition="3784">e parsing time grows quickly for the second- and third-order models (both baseline and joint) when the input sentence gets longer (O(n4)). Following Koo and Collins (2010), we eliminate unlikely dependencies using a form of coarse-to-fine pruning (Charniak and Johnson, 2005; Petrov and Klein, 2007). On the development set, 68.87% of the dependencies are pruned, while the oracle dependency accuracy is 99.77%. We use 10-fold cross validation to do pruning on the training set. 5 Experiments We use the Penn Chinese Treebank 5.1 (CTB5) (Xue et al., 2005). Following the setup of Duan et al. (2007), Zhang and Clark (2008b) and Huang and Sagae (2010), we split CTB5 into training (secs 001- 815 and 1001-1136), development (secs 886-931 and 1148-1151), and test (secs 816-885 and 1137- 1147) sets. We use the head-finding rules of Zhang and Clark (2008b) to turn the bracketed sentences into dependency structures. We use the standard tagging accuracy to evaluate POS tagging. For dependency parsing, we use word accuracy (also known as dependency accuracy), root accuracy and complete match rate (all excluding punctuation) . For the averaged training, we train each model for 15 iterations and select the parameters tha</context>
<context position="26847" citStr="Zhang and Clark (2008" startWordPosition="4650" endWordPosition="4653">models; while “Auto POS” means that the POS tags are generated by the baseline POS tagging model. top k word root compl. acc. speed 2 81.46 76.12 30.50 93.51 2.7 3 82.11 76.75 29.75 93.31 1.7 4 81.75 76.62 30.38 93.25 1.4 5 81.83 76.62 30.62 93.16 1.2 Table 2: Performance of the second-order joint model of version 1 with different top k (At = 0.01) on the development set. the beam search. H&amp;S10 refers to the results of Huang and Sagae (2010). They greatly expand the search space of the transition-based model by merging equivalent states with dynamic programming. Z&amp;C08 refers to the results of Zhang and Clark (2008b). They use a hybrid model to combine the advantages of both graph-based and transition-based models. We also do experiments with two publicly available and widely-used parsers, MSTParser6 and MaltParser7. MSTParser1 refers to the first-order 6http://sourceforge.net/projects/mstparser/ 7http://maltparser.org/ graph-based model of McDonald et al. (2005), while MSTParser2 is the second-order model of McDonald and Pereira (2006). MaltParser is a transitionbased parsing system. It integrates a number of classification algorithms and transition strategies. We adopt the support vector machine class</context>
</contexts>
<marker>Zhang, Clark, 2008</marker>
<rawString>Yue Zhang and Stephen Clark. 2008a. Joint word segmentation and POS tagging using a single perceptron. In Proceedings of ACL-08: HLT, pages 888–896.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yue Zhang</author>
<author>Stephen Clark</author>
</authors>
<title>A tale of two parsers: Investigating and combining graph-based and transition-based dependency parsing.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>562--571</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Honolulu, Hawaii,</location>
<contexts>
<context position="2354" citStr="Zhang and Clark, 2008" startWordPosition="353" endWordPosition="356">pagation, especially for Chinese. Due to the lack of morphological features, Chinese POS tagging is even harder than other languages such as English. The state-ofthe-art accuracy of Chinese POS tagging is about 93.5%, which is much lower than that of English (about 97% (Collins, 2002)). Our experimental results show that parsing accuracy decreases by about 6% on Chinese when using automatic POS tagging results instead of gold ones (see Table 3 in Section 5). Recent research on dependency parsing usually overlooks this issue by simply adopting gold POS tags for Chinese data (Duan et al., 2007; Zhang and Clark, 2008b; Huang and Sagae, 2010). In this paper, we address this issue by jointly optimizing POS tagging and dependency parsing. Joint modeling has been a popular and effective approach to simultaneously solve related tasks. Recently, many successful joint models have been proposed, such as joint tokenization and POS tagging (Zhang and Clark, 2008a; Jiang et al., 2008; Kruengkrai et al., 2009), joint lemmatization and POS tagging (Toutanova and Cherry, 2009), joint tokenization and parsing (Cohen and Smith, 2007; Goldberg and Tsarfaty, 2008), joint named entity recognition and parsing (Finkel and Man</context>
<context position="7372" citStr="Zhang and Clark (2008" startWordPosition="1180" endWordPosition="1183">ptron is simple, fast, and effective. It is competitive to CRF in tagging accuracy but requires much less training time (Shen et al., 2007). Secondly, perceptron has been successfully applied to dependency parsing as well (Koo and Collins, 2010). In this paper, perceptron is used in all models including the POS tagging model, the dependency parsing models and the joint models. In a perceptron, the score of a tag sequence is Scorepog(x,t) = wpog · fpog(x,t) where fpog(x, t) refers to the feature vector and wpog is the corresponding weight vector. For POS tagging features, we follow the work of Zhang and Clark (2008a). Three feature sets are considered: POS unigram, bigram and trigram features. For brevity, we will refer to the three sets as wi ti, ti−1 ti and ti−2 ti−1 ti. Given wpog, we adopt the Viterbi algorithm to get the optimal tagging sequence. 2.2 Dependency Parsing Recently, graph-based dependency parsing has gained more and more interest due to its state-ofthe-art accuracy. Graph-based dependency parsing views the problem as finding the highest scoring tree from a directed graph. Based on dynamic programming decoding, it can efficiently find an optimal tree in a huge search space. In a graph-b</context>
<context position="22041" citStr="Zhang and Clark (2008" startWordPosition="3781" endWordPosition="3784">e parsing time grows quickly for the second- and third-order models (both baseline and joint) when the input sentence gets longer (O(n4)). Following Koo and Collins (2010), we eliminate unlikely dependencies using a form of coarse-to-fine pruning (Charniak and Johnson, 2005; Petrov and Klein, 2007). On the development set, 68.87% of the dependencies are pruned, while the oracle dependency accuracy is 99.77%. We use 10-fold cross validation to do pruning on the training set. 5 Experiments We use the Penn Chinese Treebank 5.1 (CTB5) (Xue et al., 2005). Following the setup of Duan et al. (2007), Zhang and Clark (2008b) and Huang and Sagae (2010), we split CTB5 into training (secs 001- 815 and 1001-1136), development (secs 886-931 and 1148-1151), and test (secs 816-885 and 1137- 1147) sets. We use the head-finding rules of Zhang and Clark (2008b) to turn the bracketed sentences into dependency structures. We use the standard tagging accuracy to evaluate POS tagging. For dependency parsing, we use word accuracy (also known as dependency accuracy), root accuracy and complete match rate (all excluding punctuation) . For the averaged training, we train each model for 15 iterations and select the parameters tha</context>
<context position="26847" citStr="Zhang and Clark (2008" startWordPosition="4650" endWordPosition="4653">models; while “Auto POS” means that the POS tags are generated by the baseline POS tagging model. top k word root compl. acc. speed 2 81.46 76.12 30.50 93.51 2.7 3 82.11 76.75 29.75 93.31 1.7 4 81.75 76.62 30.38 93.25 1.4 5 81.83 76.62 30.62 93.16 1.2 Table 2: Performance of the second-order joint model of version 1 with different top k (At = 0.01) on the development set. the beam search. H&amp;S10 refers to the results of Huang and Sagae (2010). They greatly expand the search space of the transition-based model by merging equivalent states with dynamic programming. Z&amp;C08 refers to the results of Zhang and Clark (2008b). They use a hybrid model to combine the advantages of both graph-based and transition-based models. We also do experiments with two publicly available and widely-used parsers, MSTParser6 and MaltParser7. MSTParser1 refers to the first-order 6http://sourceforge.net/projects/mstparser/ 7http://maltparser.org/ graph-based model of McDonald et al. (2005), while MSTParser2 is the second-order model of McDonald and Pereira (2006). MaltParser is a transitionbased parsing system. It integrates a number of classification algorithms and transition strategies. We adopt the support vector machine class</context>
</contexts>
<marker>Zhang, Clark, 2008</marker>
<rawString>Yue Zhang and Stephen Clark. 2008b. A tale of two parsers: Investigating and combining graph-based and transition-based dependency parsing. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 562–571, Honolulu, Hawaii, October. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>