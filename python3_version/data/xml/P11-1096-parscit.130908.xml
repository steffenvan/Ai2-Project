<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000031">
<title confidence="0.757689">
Simple Supervised Document Geolocation with Geodesic Grids
</title>
<author confidence="0.996178">
Benjamin P. Wing
</author>
<affiliation confidence="0.998778">
Department of Linguistics
University of Texas at Austin
</affiliation>
<address confidence="0.673931">
Austin, TX 78712 USA
</address>
<email confidence="0.992191">
ben@benwing.com
</email>
<author confidence="0.996718">
Jason Baldridge
</author>
<affiliation confidence="0.998869">
Department of Linguistics
University of Texas at Austin
</affiliation>
<address confidence="0.677112">
Austin, TX 78712 USA
</address>
<email confidence="0.998292">
jbaldrid@mail.utexas.edu
</email>
<sectionHeader confidence="0.998595" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999930888888889">
We investigate automatic geolocation (i.e.
identification of the location, expressed as
latitude/longitude coordinates) of documents.
Geolocation can be an effective means of sum-
marizing large document collections and it is
an important component of geographic infor-
mation retrieval. We describe several simple
supervised methods for document geolocation
using only the document’s raw text as evi-
dence. All of our methods predict locations
in the context of geodesic grids of varying de-
grees of resolution. We evaluate the methods
on geotagged Wikipedia articles and Twitter
feeds. For Wikipedia, our best method obtains
a median prediction error of just 11.8 kilome-
ters. Twitter geolocation is more challenging:
we obtain a median error of 479 km, an im-
provement on previous results for the dataset.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.991418755102041">
There are a variety of applications that arise from
connecting linguistic content—be it a word, phrase,
document, or entire corpus—to geography. Lei-
dner (2008) provides a systematic overview of
geography-based language applications over the
previous decade, with a special focus on the prob-
lem of toponym resolution—identifying and disam-
biguating the references to locations in texts. Per-
haps the most obvious and far-reaching applica-
tion is geographic information retrieval (Ding et al.,
2000; Martins, 2009; Andogah, 2010), with ap-
plications like MetaCarta’s geographic text search
(Rauch et al., 2003) and NewsStand (Teitler et al.,
2008); these allow users to browse and search for
955
content through a geo-centric interface. The Perseus
project performs automatic toponym resolution on
historical texts in order to display a map with each
text showing the locations that are mentioned (Smith
and Crane, 2001); Google Books also does this
for some books, though the toponyms are identified
and resolved quite crudely. Hao et al (2010) use
a location-based topic model to summarize travel-
ogues, enrich them with automatically chosen im-
ages, and provide travel recommendations. Eisen-
stein et al (2010) investigate questions of dialec-
tal differences and variation in regional interests in
Twitter users using a collection of geotagged tweets.
An intuitive and effective strategy for summa-
rizing geographically-based data is identification of
the location—a specific latitude and longitude—that
forms the primary focus of each document. De-
termining a single location of a document is only
a well-posed problem for certain documents, gen-
erally of fairly small size, but there are a number
of natural situations in which such collections arise.
For example, a great number of articles in Wikipedia
have been manually geotagged; this allows those ar-
ticles to appear in their geographic locations while
geobrowsing in an application like Google Earth.
Overell (2009) investigates the use of Wikipedia
as a source of data for article geolocation, in addition
to article classification by category (location, per-
son, etc.) and toponym resolution. Overell’s main
goal is toponym resolution, for which geolocation
serves as an input feature. For document geoloca-
tion, Overell uses a simple model that makes use
only of the metadata available (article title, incom-
ing and outgoing links, etc.)—the actual article text
</bodyText>
<note confidence="0.9621035">
Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 955–964,
Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics
</note>
<bodyText confidence="0.997247716981132">
is not used at all. However, for many document col- fixed subjects are geotagged with their coordinates.
lections, such metadata is unavailable, especially in Such articles are well-suited as a source of super-
the case of recently digitized historical documents. vised content for document geolocation purposes.
Eisenstein et al. (2010) evaluate their geographic Furthermore, the existence of versions in multiple
topic model by geolocating USA-based Twitter languages means that the techniques in this paper
users based on their tweet content. This is essen- can easily be extended to cover documents written
tially a document geolocation task, where each doc- in many of the world’s most common languages.
ument is a concatenation of all the tweets for a single Wikipedia’s geotagged articles encompass more
user. Their geographic topic model receives super- than just cities, geographic formations and land-
vision from many documents/users and predicts lo- marks. For example, articles for events (like the
cations for unseen documents/users. shooting of JFK) and vehicles (such as the frigate
In this paper, we tackle document geolocation us- USS Constitution) are geotagged. The latter type
ing several simple supervised methods on the textual of article is actually quite challenging to geolocate
content of documents and a geodesic grid as a dis- based on the text content: though the ship is moored
crete representation of the earth’s surface. Our ap- in Boston, most of the page discusses its role in var-
proach is similar to that of Serdyukov et al. (2009), ious battles along the eastern seaboard of the USA.
who geolocate Flickr images using their associated However, such articles make up only a small fraction
textual tags.1 Essentially, the task is cast similarly of the geotagged articles.
to language modeling approaches in information re- For the experiments in this paper, we used a full
trieval (Ponte and Croft, 1998). Discrete cells rep- dump of Wikipedia from September 4, 2010.2 In-
resenting areas on the earth’s surface correspond to cluded in this dump is a total of 10,355,226 articles,
documents (with each cell-document being a con- of which 1,019,490 have been geotagged. Excluding
catenation of all actual documents that are located various types of special-purpose articles used pri-
in that cell); new documents are then geolocated to marily for maintaining the site (specifically, redirect
the most similar cell according to standard measures articles and articles outside the main namespace),
such as Kullback-Leibler divergence (Zhai and Laf- the dump includes 3,431,722 content-bearing arti-
ferty, 2001). Performance is measured both on geo- cles, of which 488,269 are geotagged.
tagged Wikipedia articles (Overell, 2009) and tweets It is necessary to process the raw dump to ob-
(Eisenstein et al., 2010). We obtain high accuracy on tain the plain text, as well as metadata such as geo-
Wikipedia using KL divergence, with a median error tagged coordinates. Extracting the coordinates, for
of just 11.8 kilometers. For the Twitter data set, we example, is not a trivial task, as coordinates can
obtain a median error of 479 km, which improves be specified using multiple templates and in mul-
on the 494 km error of Eisenstein et al. An advan- tiple formats. Automatically-processed versions of
tage of our approach is that it is far simpler, is easy the English-language Wikipedia site are provided by
to implement, and scales straightforwardly to large Metaweb,3 which at first glance promised to signif-
datasets like Wikipedia. icantly simplify the preprocessing. Unfortunately,
these versions still need significant processing and
they incorrectly eliminate some of the important
metadata. In the end, we wrote our own code to
process the raw dump. It should be possible to ex-
tend this code to handle other languages with little
difficulty. See Lieberman and Lin (2009) for more
discussion of a related effort to extract and use the
geotagged articles in Wikipedia.
The entire set of articles was split 80/10/10 in
2 Data
Wikipedia As of April 15, 2011, Wikipedia has
some 18.4 million content-bearing articles in 281
language-specific encyclopedias. Among these, 39
have over 100,000 articles, including 3.61 mil-
lion articles in the English-language edition alone.
Wikipedia articles generally cover a single subject;
in addition, most articles that refer to geographically
</bodyText>
<footnote confidence="0.8040764">
2http://download.wikimedia.org/enwiki/
20100904/pages-articles.xml.bz2
3http://download.freebase.com/wex/
1We became aware of Serdyukov et al. (2009) during the
writing of the camera-ready version of this paper.
</footnote>
<page confidence="0.47352">
956
</page>
<bodyText confidence="0.999966918918919">
round-robin fashion into training, development, and
testing sets after randomizing the order of the arti-
cles, which preserved the proportion of geotagged
articles. Running on the full data set is time-
consuming, so development was done on a subset
of about 80,000 articles (19.9 million tokens) as a
training set and 500 articles as a development set.
Final evaluation was done on the full dataset, which
includes 390,574 training articles (97.2 million to-
kens) and 48,589 test articles. A full run with all the
six strategies described below (three baseline, three
non-baseline) required about 4 months of computing
time and about 10-16 GB of RAM when run on a 64-
bit Intel Xeon E5540 CPU; we completed such jobs
in under two days (wall clock) using the Longhorn
cluster at the Texas Advanced Computing Center.
Geo-tagged Microblog Corpus As a second eval-
uation corpus on a different domain, we use the
corpus of geotagged tweets collected and used by
Eisenstein et al. (2010).4 It contains 380,000 mes-
sages from 9,500 users tweeting within the 48 states
of the continental USA.
We use the train/dev/test splits provided with the
data; for these, the tweets of each user (a feed) have
been concatenated to form a single document, and
the location label associated with each document is
the location of the first tweet by that user. This is
generally a fair assumption as Twitter users typically
tweet within a relatively small region. Given this
setup, we will refer to Twitter users as documents in
what follows; this keeps the terminology consistent
with Wikipedia as well. The training split has 5,685
documents (1.58 million tokens).
Replication Our code (part of the TextGrounder
system), our processed version of Wikipedia, and in-
structions for replicating our experiments are avail-
able on the TextGrounder website.5
</bodyText>
<sectionHeader confidence="0.77015" genericHeader="method">
3 Grid representation for connecting texts
to locations
</sectionHeader>
<bodyText confidence="0.894528666666667">
Geolocation involves identifying some spatial re-
gion with a unit of text—be it a word, phrase, or
document. The earth’s surface is continuous, so a
</bodyText>
<footnote confidence="0.977821">
4http://www.ark.cs.cmu.edu/GeoText/
5http://code.google.com/p/textgrounder/
wiki/WingBaldridge2011
</footnote>
<bodyText confidence="0.9999275625">
natural approach is to predict locations using a con-
tinuous distribution. For example, Eisenstein et al.
(2010) use Gaussian distributions to model the loca-
tions of Twitter users in the United States of Amer-
ica. This appears to work reasonably well for that
restricted region, but is likely to run into problems
when predicting locations for anywhere on earth—
instead, spherical distributions like the von Mises-
Fisher distribution would need to be employed.
We take here the simpler alternative of discretiz-
ing the earth’s surface with a geodesic grid; this al-
lows us to predict locations with a variety of stan-
dard approaches over discrete outcomes. There are
many ways of constructing geodesic grids. Like
Serdyukov et al. (2009), we use the simplest strat-
egy: a grid of square cells of equal degree, such as
1° by 1°. This produces variable-size regions that
shrink latitudinally, becoming progressively smaller
and more elongated the closer they get towards the
poles. Other strategies, such as the quaternary trian-
gular mesh (Dutton, 1996), preserve equal area, but
are considerably more complex to implement. Given
that most of the populated regions of interest for us
are closer to the equator than not and that we use
cells of quite fine granularity (down to 0.05°), the
simple grid system was preferable.
With such a discrete representation of the earth’s
surface, there are four distributions that form the
core of all our geolocation methods. The first is a
standard multinomial distribution over the vocabu-
lary for every cell in the grid. Given a grid G with
cells ci and a vocabulary V with words wj, we have
Bcij = P(wj|ci). The second distribution is the
equivalent distribution for a single test document dk,
i.e. Bdkj = P(wj|dk). The third distribution is the
reverse of the first: for a given word, its distribution
over the earth’s cells, rji = P(ci|wj). The final dis-
tribution is over the cells, -yi = P (ci).
This grid representation ignores all higher level
regions, such as states, countries, rivers, and moun-
tain ranges, but it is consistent with the geocod-
ing in both the Wikipedia and Twitter datasets.
Nonetheless, note that the rji for words referring
to such regions is likely to be much flatter (spread
out) but with most of the mass concentrated in a
set of connected cells. Those for highly focused
point-locations will jam up in a few disconnected
cells—in the extreme case, toponyms like Spring-
</bodyText>
<page confidence="0.986838">
957
</page>
<bodyText confidence="0.999991972222222">
field which are connected to many specific point lo-
cations around the earth.
We use grids with cell sizes of varying granular-
ity dxd for d = 0.1°, 0.5°,1°, 5°,10°. For example,
with d=0.5°, a cell at the equator is roughly 56x55
km and at 45° latitude it is 39x55 km. At this reso-
lution, there are a total of 259,200 cells, of which
35,750 are non-empty when using our Wikipedia
training set. For comparison, at the equator a cell
at d=5° is about 557x553 km (2,592 cells; 1,747
non-empty) and at d=0.1° a cell is about 11.3x10.6
km (6,480,000 cells; 170,005 non-empty).
The geolocation methods predict a cell c� for a
document, and the latitude and longitude of the
degree-midpoint of the cell is used as the predicted
location. Prediction error is the great-circle distance
from these predicted locations to the locations given
by the gold standard. The use of cell midpoints pro-
vides a fair comparison for predictions with differ-
ent cell sizes. This differs from the evaluation met-
rics used by Serdyukov et al. (2009), which are all
computed relative to a given grid size. With their
metrics, results for different granularities cannot be
directly compared because using larger cells means
less ambiguity when choosing c. With our distance-
based evaluation, large cells are penalized by the dis-
tance from the midpoint to the actual location even
when that location is in the same cell. Smaller cells
reduce this penalty and permit the word distributions
θcij to be much more specific for each cell, but they
are harder to predict exactly and suffer more from
sparse word counts compared to courser granular-
ity. For large datasets like Wikipedia, fine-grained
grids work very well, but the trade-off between reso-
lution and sufficient training material shows up more
clearly for the smaller Twitter dataset.
</bodyText>
<sectionHeader confidence="0.9902155" genericHeader="method">
4 Supervised models for document
geolocation
</sectionHeader>
<bodyText confidence="0.9999235">
Our methods use only the text in the documents; pre-
dictions are made based on the distributions θ, κ, and
ρ introduced in the previous section. No use is made
of metadata, such as links/followers and infoboxes.
</bodyText>
<subsectionHeader confidence="0.976845">
4.1 Supervision
</subsectionHeader>
<bodyText confidence="0.947530333333333">
We acquire θ and κ straightforwardly from the train-
ing material. The unsmoothed estimate of word wj’s
probability in a test document dk is:6
</bodyText>
<equation confidence="0.979173333333333">
�θdkj = #(wj,dk) P(1)
#(wl, dk)
wlEV
</equation>
<bodyText confidence="0.99988">
Similarly for a cell ci, we compute the unsmoothed
word distribution by aggregating all of the docu-
ments located within ci:
</bodyText>
<equation confidence="0.992887333333333">
P #(wj, dk)
dkEci
#(wl, dk) (2)
</equation>
<bodyText confidence="0.995604">
We compute the global distribution θDj over the set
of all documents D in the same fashion.
The word distribution of document dk backs off
to the global distribution θDj. The probability mass
αdk reserved for unseen words is determined by the
empirical probability of having seen a word once in
the document, motivated by Good-Turing smooth-
ing. (The cell distributions are treated analogously.)
That is:7
</bodyText>
<equation confidence="0.995892166666667">
θ(�dk) θDj
Dj = 1− P θDl (4)
wlEdk
( θ adk θD�d&apos;k ), if θdkj = 0
d�� (5)
(1−αdk)�θdkj, o.w.
</equation>
<bodyText confidence="0.983230333333333">
The distributions over cells for each word simply
renormalizes the θcij values to achieve aproper dis-
tribution:
</bodyText>
<equation confidence="0.957744333333333">
κji = P θcij
θcij (6)
ciEG
</equation>
<bodyText confidence="0.9893885">
A useful aspect of the κ distributions is that they can
be plotted in a geobrowser using thematic mapping
</bodyText>
<footnote confidence="0.98853275">
6We use #() to indicate the count of an event.
7BD�dk is an adjusted version of BDj that is normalized over
the subset of words not found in document dk. This adjustment
ensures that the entire distribution is properly normalized.
</footnote>
<equation confidence="0.9978216">
�θcij =
P
dkEci
P
wlEV
αdk = (3)
|wj E V s.t. #(wj, dk)=1|
P
#(wj,dk)
wjEV
</equation>
<page confidence="0.978695">
958
</page>
<bodyText confidence="0.99992725">
techniques (Sandvik, 2008) to inspect the spread of
a word over the earth. We used this as a simple way
to verify the basic hypothesis that words that do not
name locations are still useful for geolocation. In-
deed, the Wikipedia distribution for mountain shows
high density over the Rocky Mountains, Smokey
Mountains, the Alps, and other ranges, while beach
has high density in coastal areas. Words without
inherent locational properties also have intuitively
correct distributions: e.g., barbecue has high den-
sity over the south-eastern United States, Texas, Ja-
maica, and Australia, while wine is concentrated in
France, Spain, Italy, Chile, Argentina, California,
South Africa, and Australia.8
Finally, the cell distributions are simply the rela-
tive frequency of the number of documents in each
</bodyText>
<equation confidence="0.764839">
cell: γi = |ci|
|D|.
</equation>
<bodyText confidence="0.999928">
A standard set of stop words are ignored. Also,
all words are lowercased except in the case of the
most-common-toponym baselines, where uppercase
words serve as a fallback in case a toponym cannot
be located in the article.
</bodyText>
<subsectionHeader confidence="0.9123">
4.2 Kullback-Leibler divergence
</subsectionHeader>
<bodyText confidence="0.999879375">
Given the distributions for each cell, θci, in the grid,
we use an information retrieval approach to choose
a location for a test document dk: compute the sim-
ilarity between its word distribution θdk and that of
each cell, and then choose the closest one. Kullback-
Leibler (KL) divergence is a natural choice for this
(Zhai and Lafferty, 2001). For distribution P and Q,
KL divergence is defined as:
</bodyText>
<equation confidence="0.9998005">
P (i)
P(i) log Q(i) (7)
</equation>
<bodyText confidence="0.99996770967742">
This quantity measures how good Q is as an encod-
ing for P – the smaller it is the better. The best cell
ˆcKL is the one which provides the best encoding for
the test document:
the test document is a good encoding for. With
KL(θdk||θci), the log ratio of probabilities for each
word is weighted by the probability of the word in
the test document, ed,j log θdkj
θcij , which means that
the divergence is more sensitive to the document
rather than the overall cell.
As an example for why non-symmetric KL in this
order is appropriate, consider geolocating a page in
a densely geotagged cell, such as the page for the
Washington Monument. The distribution of the cell
containing the monument will represent the words
from many other pages having to do with muse-
ums, US government, corporate buildings, and other
nearby memorials and will have relatively small val-
ues for many of the words that are highly indicative
of the monument’s location. Many of those words
appear only once in the monument’s page, but this
will still be a higher value than for the cell and will
weight the contribution accordingly.
Rather than computing KL(θdk||θci) over the en-
tire vocabulary, we restrict it to only the words in the
document to compute KL more efficiently:
Early experiments showed that it makes no differ-
ence in the outcome to include the rest of the vocab-
ulary. Note that because θci is smoothed, there are
no zeros, so this value is always defined.
</bodyText>
<subsectionHeader confidence="0.994113">
4.3 Naive Bayes
</subsectionHeader>
<bodyText confidence="0.9998936">
Naive Bayes is a natural generative model for the
task of choosing a cell, given the distributions θci
and γ: to generate a document, choose a cell ci ac-
cording to γ and then choose the words in the docu-
ment according to θci:
</bodyText>
<equation confidence="0.945762857142857">
KL(P ||Q) = �
i
� θdkj
KL(θdk||θci) = θdkj log (9)
wj∈Vdk θcij
ˆcKL = arg min KL(θdk||θci) (8) ˆcNB = arg max PNB(ci|dk)
ci∈G ci∈G
</equation>
<bodyText confidence="0.65418625">
The fact that KL is not symmetric is desired here: = arg max P(ci)P(dk|ci)
the other direction, KL(θci||θdk), asks which cell ci∈G
P(dk)
= arg max
</bodyText>
<equation confidence="0.8288486">
ci∈G
�γi
wj∈Vdk
θ#(wj,dk) (10)
cij
</equation>
<footnote confidence="0.889143333333333">
8This also acts as an exploratory tool. For example, due to
a big spike on Cebu Province in the Philippines we learned that
Cebuanos take barbecue very, very seriously.
</footnote>
<page confidence="0.998356">
959
</page>
<bodyText confidence="0.999806666666667">
This method maximizes the combination of the like-
lihood of the document P(dkIci) and the cell prior
probability ryi.
</bodyText>
<subsectionHeader confidence="0.989011">
4.4 Average cell probability
</subsectionHeader>
<bodyText confidence="0.9996458">
For each word, Kji gives the probability of each cell
in the grid. A simple way to compute a distribution
for a document dk is to take a weighted average of
the distributions for all words to compute the aver-
age cell probability (ACP):
</bodyText>
<equation confidence="0.954393">
1: = arg max #(wj,dk)Kji (11)
ciEG wjEVdk
</equation>
<bodyText confidence="0.9999535">
This method, despite its conceptual simplicity,
works well in practice. It could also be easily
modified to use different weights for words, such
as TF/IDF or relative frequency ratios between ge-
olocated documents and non-geolocated documents,
which we intend to try in future work.
</bodyText>
<subsectionHeader confidence="0.980534">
4.5 Baselines
</subsectionHeader>
<bodyText confidence="0.999527111111111">
There are several natural baselines to use for com-
parison against the methods described above.
Random Choose c,.and randomly from a uniform
distribution over the entire grid G.
Cell prior maximum Choose the cell with the
highest prior probability according to ry: ccpm =
arg maxciEG ryi.
Most frequent toponym Identify the most fre-
quent toponym in the article and the geotagged
Wikipedia articles that match it. Then identify
which of those articles has the most incoming links
(a measure of its prominence), and then choose cmft
to be the cell that contains the geotagged location for
that article. This is a strong baseline method, but can
only be used with Wikipedia.
Note that a toponym matches an article (or equiv-
alently, the article is a candidate for the toponym) ei-
ther if the toponym is the same as the article’s title,
</bodyText>
<figure confidence="0.416312">
grid size (degrees)
</figure>
<figureCaption confidence="0.926182">
Figure 1: Plot of grid resolution in degrees versus mean
error for each method on the Wikipedia dev set.
</figureCaption>
<bodyText confidence="0.998388428571429">
or the same as the title after a parenthetical tag or
comma-separated higher-level division is removed.
For example, the toponym Tucson would match ar-
ticles named Tucson, Tucson (city) or Tucson, Ari-
zona. In this fashion, the set of toponyms, and the
list of candidates for each toponym, is generated
from the set of all geotagged Wikipedia articles.
</bodyText>
<sectionHeader confidence="0.999706" genericHeader="method">
5 Experiments
</sectionHeader>
<bodyText confidence="0.999901105263158">
The approaches described in the previous section
are evaluated on both the geotagged Wikipedia and
Twitter datasets. Given a predicted cell c� for a docu-
ment, the prediction error is the great-circle distance
between the true location and the center of c, as de-
scribed in section 3.
Grid resolution and thresholding The major pa-
rameter of all our methods is the grid resolution.
For both Wikipedia and Twitter, preliminary ex-
periments on the development set were run to plot
the prediction error for each method for each level
of resolution, and the optimal resolution for each
method was chosen for obtaining test results. For the
Twitter dataset, an additional parameter is a thresh-
old on the number of feeds each word occurs in: in
the preprocessed splits of Eisenstein et al. (2010), all
vocabulary items that appear in fewer than 40 feeds
are ignored. This thresholding takes away a lot of
very useful material; e.g. in the first feed, it removes
</bodyText>
<figure confidence="0.9717598">
0.1 0.5 1 5 10
mean error (km)
0 200 400 600 800 1000 1200 1400
Most frequent toponym
Avg. cell probability
Naive Bayes
Kullback−Leibler
cACP = arg max
ciEG
= arg max
ciEG
E
wjEVdk
E
clEG
#(wj, dk)Kji
#(wj,dk)Kjl
PACP(ci|dk)
E
wjEVdk
</figure>
<page confidence="0.753315">
960
</page>
<figureCaption confidence="0.997111">
Figure 2: Histograms of distribution of error distances (in
km) for grid size 0.5◦ for each method on the Wikipedia
dev set.
</figureCaption>
<bodyText confidence="0.9997122">
both “kirkland” and “redmond” (towns in the East-
side of Lake Washington near Seattle), very useful
information for geolocating that user. This suggests
that a lower threshold would be better, and this is
borne out by our experiments.
</bodyText>
<figureCaption confidence="0.685338333333333">
Figure 1 graphs the mean error of each method for
different resolutions on the Wikipedia dev set, and
Figure 2 graphs the distribution of error distances
</figureCaption>
<bodyText confidence="0.992183157894737">
for grid size 0.5° for each method on the Wikipedia
dev set. These results indicate that a grid size even
smaller than 0.1° might be beneficial. To test this,
we ran experiments using a grid size of 0.05° and
0.01° using KL divergence. The mean errors on the
dev set increased slightly, from 323 km to 348 and
329 km, respectively, indicating that 0.1° is indeed
the minimum.
For the Twitter dataset, we considered both grid
size and vocabulary threshold. We recomputed the
distributions using several values for both parame-
ters and evaluated on the development set. Table 1
shows mean prediction error using KL divergence,
for various combinations of threshold and grid size.
Similar tables were constructed for the other strate-
gies. Clearly, the larger grid size of 5° is more op-
timal than the 0.1° best for Wikipedia. This is un-
surprising, given the small size of the corpus. Over-
all, there is a less clear trend for the other methods
</bodyText>
<table confidence="0.999674222222222">
Grid size (degrees)
Thr. 0.1 0.5 1 5 10
0 1113.1 996.8 1005.1 969.3 1052.5
2 1018.5 959.5 944.6 911.2 1021.6
3 1027.6 940.8 954.0 913.6 1026.2
5 1011.7 951.0 954.2 892.0 1013.0
10 1011.3 968.8 938.5 929.8 1048.0
20 1032.5 987.3 966.0 940.0 1070.1
40 1080.8 1031.5 998.6 981.8 1127.8
</table>
<tableCaption confidence="0.999485666666667">
Table 1: Mean prediction error (km) on the Twitter dev
set for various combinations of vocabulary threshold (in
feeds) and grid size, using the KL divergence strategy.
</tableCaption>
<bodyText confidence="0.99996315625">
in terms of optimal resolution. Our interpretation
of this is that there is greater sparsity for the Twit-
ter dataset, and thus it is more sensitive to arbitrary
aspects of how different user feeds are captured in
different cells at different granularities.
For the non-baseline strategies, a threshold be-
tween about 2 and 5 was best, although no one value
in this range was clearly better than another.
Results Based on the optimal resolutions for each
method, Table 2 provides the median and mean er-
rors of the methods for both datasets, when run on
the test sets. The results clearly show that KL di-
vergence does the best of all the methods consid-
ered, with Naive Bayes a close second. Prediction
on Wikipedia is very good, with a median value of
11.8 km. Error on Twitter is much higher at 479 km.
Nonetheless, this beats Eisenstein et al.’s (2010) me-
dian results, though our mean is worse at 967. Us-
ing the same threshold of 40 as Eisenstein et al., our
results using KL divergence are slightly worse than
theirs: median error of 516 km and mean of 986 km.
The difference between Wikipedia and Twitter is
unsurprising for several reasons. Wikipedia articles
tend to use a lot of toponyms and words that corre-
late strongly with particular places while many, per-
haps most, tweets discuss quotidian details such as
what the user ate for lunch. Second, Wikipedia arti-
cles are generally longer and thus provide more text
to base predictions on. Finally, there are orders of
magnitude more training examples for Wikipedia,
which allows for greater grid resolution and thus
more precise location predictions.
</bodyText>
<page confidence="0.993381">
961
</page>
<table confidence="0.997845555555556">
Strategy Wikipedia Mean Threshold Twitter Mean
Degree Median Degree Median
Kullback-Leibler 0.1 11.8 221 5 5 479 967
Naive Bayes 0.1 15.5 314 5 5 528 989
Avg. cell probability 0.1 24.1 1421 2 10 659 1184
Most frequent toponym 0.5 136 1927 - - - -
Cell prior maximum 5 2333 4309 N/A 0.1 726 1141
Random 0.1 7259 7192 20 0.1 1217 1588
Eisenstein et al. - - - 40 N/A 494 900
</table>
<tableCaption confidence="0.9924845">
Table 2: Prediction error (km) on the Wikipedia and Twitter test sets for each of the strategies using the optimal grid
resolution and (for Twitter) the optimal threshold, as determined by performance on the corresponding development
sets. Eisenstein et al. (2010) used a fixed Twitter threshold of 40. Threshold makes no difference for cell prior
maximum.
</tableCaption>
<bodyText confidence="0.999841785714286">
Ships One of the most difficult types of Wikipedia
pages to disambiguate are those of ships that either
are stored or had sunk at a particular location. These
articles tend to discuss the exploits of these ships,
not their final resting places. Location error on these
is usually quite large. However, prediction is quite
good for ships that were sunk in particular battles
which are described in detail on the page; examples
are the USS Gambier Bay, USS Hammann (DD-
412), and the HMS Majestic (1895). Another situa-
tion that gives good results is when a ship is retired
in a location where it is a prominent feature and is
thus mentioned in the training set at that location.
An example is the USS Turner Joy, which is in Bre-
merton, Washington and figures prominently in the
page for Bremerton (which is in the training set).
Another interesting aspect of geolocating ship ar-
ticles is that ships tend to end up sunk in remote bat-
tle locations, such that their article is the only one
located in the cell covering the location in the train-
ing set. Ship terminology thus dominates such cells,
with the effect that our models often (incorrectly)
geolocate test articles about other ships to such loca-
tions (and often about ships with similar properties).
This also leads to generally more accurate geoloca-
tion of HMS ships over USS ships; the former seem
to have been sunk in more concentrated regions that
are themselves less spread out globally.
</bodyText>
<sectionHeader confidence="0.99999" genericHeader="method">
6 Related work
</sectionHeader>
<bodyText confidence="0.999982393939394">
Lieberman and Lin (2009) also work with geotagged
Wikipedia articles, but they do in order so to ana-
lyze the likely locations of users who edit such ar-
ticles. Other researchers have investigated the use
of Wikipedia as a source of data for other super-
vised NLP tasks. Mihalcea and colleagues have in-
vestigated the use of Wikipedia in conjunction with
word sense disambiguation (Mihalcea, 2007), key-
word extraction and linking (Mihalcea and Csomai,
2007) and topic identification (Coursey et al., 2009;
Coursey and Mihalcea, 2009). Cucerzan (2007)
used Wikipedia to do named entity disambiguation,
i.e. identification and coreferencing of named enti-
ties by linking them to the Wikipedia article describ-
ing the entity.
Some approaches to document geolocation rely
largely or entirely on non-textual metadata, which
is often unavailable for many corpora of interest,
Nonetheless, our methods could be combined with
such methods when such metadata is available. For
example, given that both Wikipedia and Twitter have
a linked structure between documents, it would be
possible to use the link-based method given in Back-
strom et al. (2010) for predicting the location of
Facebook users based on their friends’ locations. It
is possible that combining their approach with our
text-based approach would provide improvements
for Facebook, Twitter and Wikipedia datasets. For
example, their method performs poorly for users
with few geolocated friends, but results improved
by combining link-based predictions with IP address
predictions. The text written users’ updates could be
an additional aid for locating such users.
</bodyText>
<page confidence="0.958688">
962
</page>
<bodyText confidence="0.9720005625">
7 Conclusion Though we treated the grid resolution as a param-
We have shown that automatic identification of the eter, the grids themselves form a hierarchy of cells
location of a document based only on its text can be containing finer-grained cells. Given this, there are
performed with high accuracy using simple super- a number of obvious ways to combine predictions
vised methods and a discrete grid representation of from different resolutions. For example, given a cell
the earth’s surface. All of our methods are simple of the finest grain, the average cell probability and
to implement, and both training and testing can be naive Bayes models could successively back off to
easily parallelized. Our most effective geolocation the values produced by their coarser-grained con-
strategy finds the grid cell whose word distribution taining cells, and KL divergence could be summed
has the smallest KL divergence from that of the test from finest-to-coarsest grain. Another strategy for
document, and easily beats several effective base- making models less sensitive to grid resolution is to
lines. We predict the location of Wikipedia pages smooth the per-cell word distributions over neigh-
to a median error of 11.8 km and mean error of 221 boring cells; this strategy improved results on Flickr
km. For Twitter, we obtain a median error of 479 photo geolocation for Serdyukov et al. (2009).
km and mean error of 967 km. Using naive Bayes An additional area to explore is to remove the
and a simple averaging of word-level cell distribu- bag-of-words assumption and take into account the
tions also both worked well; however, KL was more ordering between words. This should have a num-
effective, we believe, because it weights the words ber of obvious benefits, among which are sensitivity
in the document most heavily, and thus puts less im- to multi-word toponyms such as New York, colloca-
portance on the less specific word distributions of tions such as London, Ontario or London in Ontario,
each cell. and highly indicative terms such as egg cream that
Though we only use text, link-based predictions are made up of generic constituents.
using the follower graph, as Backstrom et al. (2010) Acknowledgments
do for Facebook, could improve results on the Twit- This research was supported by a grant from the
ter task considered here. It could also help with Morris Memorial Trust Fund of the New York Com-
Wikipedia, especially for buildings: for example, munity Trust and from the Longhorn Innovation
the page for Independence Hall in Philadelphia links Fund for Technology. This paper benefited from re-
to geotagged “friend” pages for Philadelphia, the viewer comments and from discussion in the Natu-
Liberty Bell, and many other nearby locations and ral Language Learning reading group at UT Austin,
buildings. However, we note that we are still pri- with particular thanks to Matt Lease.
marily interested in geolocation with only text be- References
cause there are a great many situations in which such Geoffrey Andogah. 2010. Geographically Constrained
linked structure is unavailable. This is especially Information Retrieval. Ph.D. thesis, University of
true for historical corpora like those made available Groningen, Groningen, Netherlands, May.
by the Perseus project.9 Lars Backstrom, Eric Sun, and Cameron Marlow. 2010.
The task of identifying a single location for an en- Find me if you can: improving geographical prediction
tire document provides a convenient way of evaluat- with social and spatial proximity. In Proceedings of
ing approaches for connecting texts with locations, the 19th international conference on World wide web,
but it is not fully coherent in the context of docu- WWW ’10, pages 61–70, New York, NY, USA. ACM.
ments that cover multiple locations. Nonetheless, Kino Coursey and Rada Mihalcea. 2009. Topic identi-
both the average cell probability and naive Bayes fication using wikipedia graph centrality. In Proceed-
models output a distribution over all cells, which ings ofHuman Language Technologies: The 2009 An-
could be used to assign multiple locations. Further- nual Conference of the North American Chapter of the
more, these cell distributions could additionally be Association for Computational Linguistics, Compan-
used to define a document level prior for resolution ion Volume: Short Papers, NAACL ’09, pages 117–
of individual toponyms.
9www.perseus.tufts.edu/
963
</bodyText>
<reference confidence="0.999730821782178">
120, Morristown, NJ, USA. Association for Computa-
tional Linguistics.
Kino Coursey, Rada Mihalcea, and William Moen. 2009.
Using encyclopedic knowledge for automatic topic
identification. In Proceedings of the Thirteenth Con-
ference on Computational Natural Language Learn-
ing, CoNLL ’09, pages 210–218, Morristown, NJ,
USA. Association for Computational Linguistics.
Silviu Cucerzan. 2007. Large-scale named entity dis-
ambiguation based on Wikipedia data. In Proceedings
of the 2007 Joint Conference on Empirical Methods
in Natural Language Processing and Computational
Natural Language Learning (EMNLP-CoNLL), pages
708–716, Prague, Czech Republic, June. Association
for Computational Linguistics.
Junyan Ding, Luis Gravano, and Narayanan Shivaku-
mar. 2000. Computing geographical scopes of web re-
sources. In Proceedings of the 26th International Con-
ference on Very Large Data Bases, VLDB ’00, pages
545–556, San Francisco, CA, USA. Morgan Kauf-
mann Publishers Inc.
G. Dutton. 1996. Encoding and handling geospatial data
with hierarchical triangular meshes. In M.J. Kraak and
M. Molenaar, editors, Advances in GIS Research II,
pages 505–518, London. Taylor and Francis.
Jacob Eisenstein, Brendan O’Connor, Noah A. Smith,
and Eric P. Xing. 2010. A latent variable model
for geographic lexical variation. In Proceedings of
the 2010 Conference on Empirical Methods in Natural
Language Processing, pages 1277–1287, Cambridge,
MA, October. Association for Computational Linguis-
tics.
Qiang Hao, Rui Cai, Changhu Wang, Rong Xiao, Jiang-
Ming Yang, Yanwei Pang, and Lei Zhang. 2010.
Equip tourists with knowledge mined from travel-
ogues. In Proceedings of the 19th international con-
ference on World wide web, WWW ’10, pages 401–
410, New York, NY, USA. ACM.
Jochen L. Leidner. 2008. Toponym Resolution in Text:
Annotation, Evaluation and Applications of Spatial
Grounding of Place Names. Dissertation.Com, Jan-
uary.
M. D. Lieberman and J. Lin. 2009. You are where you
edit: Locating Wikipedia users through edit histories.
In ICWSM’09: Proceedings of the 3rd International
AAAI Conference on Weblogs and Social Media, pages
106–113, San Jose, CA, May.
Bruno Martins. 2009. Geographically Aware Web Text
Mining. Ph.D. thesis, University of Lisbon.
Rada Mihalcea and Andras Csomai. 2007. Wikify!: link-
ing documents to encyclopedic knowledge. In Pro-
ceedings of the sixteenth ACM conference on Con-
ference on information and knowledge management,
CIKM ’07, pages 233–242, New York, NY, USA.
ACM.
Rada Mihalcea. 2007. Using Wikipedia for Auto-
matic Word Sense Disambiguation. In North Ameri-
can Chapter of the Association for Computational Lin-
guistics (NAACL 2007).
Simon Overell. 2009. Geographic Information Re-
trieval: Classification, Disambiguation and Mod-
elling. Ph.D. thesis, Imperial College London.
Jay M. Ponte and W. Bruce Croft. 1998. A language
modeling approach to information retrieval. In Pro-
ceedings of the 21st annual international ACM SIGIR
conference on Research and development in informa-
tion retrieval, SIGIR ’98, pages 275–281, New York,
NY, USA. ACM.
Erik Rauch, Michael Bukatin, and Kenneth Baker. 2003.
A confidence-based framework for disambiguating ge-
ographic terms. In Proceedings of the HLT-NAACL
2003 workshop on Analysis of geographic references
- Volume 1, HLT-NAACL-GEOREF ’03, pages 50–54,
Stroudsburg, PA, USA. Association for Computational
Linguistics.
Bjorn Sandvik. 2008. Using KML for thematic mapping.
Master’s thesis, The University of Edinburgh.
Pavel Serdyukov, Vanessa Murdock, and Roelof van
Zwol. 2009. Placing flickr photos on a map. In Pro-
ceedings of the 32nd international ACM SIGIR con-
ference on Research and development in information
retrieval, SIGIR ’09, pages 484–491, New York, NY,
USA. ACM.
David A. Smith and Gregory Crane. 2001. Disam-
biguating geographic names in a historical digital li-
brary. In Proceedings of the 5th European Confer-
ence on Research and Advanced Technology for Digi-
talLibraries, ECDL ’01, pages 127–136, London, UK.
Springer-Verlag.
B. E. Teitler, M. D. Lieberman, D. Panozzo, J. Sankara-
narayanan, H. Samet, and J. Sperling. 2008. News-
Stand: A new view on news. In GIS’08: Proceedings
of the 16th ACM SIGSPATIAL International Confer-
ence on Advances in Geographic Information Systems,
pages 144–153, Irvine, CA, November.
Chengxiang Zhai and John Lafferty. 2001. Model-based
feedback in the language modeling approach to infor-
mation retrieval. In Proceedings of the tenth interna-
tional conference on Information and knowledge man-
agement, CIKM ’01, pages 403–410, New York, NY,
USA. ACM.
</reference>
<page confidence="0.998472">
964
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.436176">
<title confidence="0.999907">Simple Supervised Document Geolocation with Geodesic Grids</title>
<author confidence="0.999709">P Benjamin</author>
<affiliation confidence="0.998671">Department of University of Texas at</affiliation>
<address confidence="0.711554">Austin, TX 78712</address>
<email confidence="0.999486">ben@benwing.com</email>
<author confidence="0.996079">Jason</author>
<affiliation confidence="0.9988915">Department of University of Texas at</affiliation>
<address confidence="0.653383">Austin, TX 78712</address>
<email confidence="0.99969">jbaldrid@mail.utexas.edu</email>
<abstract confidence="0.997209947368421">investigate automatic identification of the location, expressed as latitude/longitude coordinates) of documents. Geolocation can be an effective means of summarizing large document collections and it is an important component of geographic information retrieval. We describe several simple supervised methods for document geolocation using only the document’s raw text as evidence. All of our methods predict locations in the context of geodesic grids of varying degrees of resolution. We evaluate the methods on geotagged Wikipedia articles and Twitter feeds. For Wikipedia, our best method obtains a median prediction error of just 11.8 kilometers. Twitter geolocation is more challenging: we obtain a median error of 479 km, an improvement on previous results for the dataset.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>NJ Morristown</author>
<author>USA</author>
</authors>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Morristown, USA, </marker>
<rawString>120, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kino Coursey</author>
<author>Rada Mihalcea</author>
<author>William Moen</author>
</authors>
<title>Using encyclopedic knowledge for automatic topic identification.</title>
<date>2009</date>
<booktitle>In Proceedings of the Thirteenth Conference on Computational Natural Language Learning, CoNLL ’09,</booktitle>
<pages>210--218</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="29455" citStr="Coursey et al., 2009" startWordPosition="4864" endWordPosition="4867">former seem to have been sunk in more concentrated regions that are themselves less spread out globally. 6 Related work Lieberman and Lin (2009) also work with geotagged Wikipedia articles, but they do in order so to analyze the likely locations of users who edit such articles. Other researchers have investigated the use of Wikipedia as a source of data for other supervised NLP tasks. Mihalcea and colleagues have investigated the use of Wikipedia in conjunction with word sense disambiguation (Mihalcea, 2007), keyword extraction and linking (Mihalcea and Csomai, 2007) and topic identification (Coursey et al., 2009; Coursey and Mihalcea, 2009). Cucerzan (2007) used Wikipedia to do named entity disambiguation, i.e. identification and coreferencing of named entities by linking them to the Wikipedia article describing the entity. Some approaches to document geolocation rely largely or entirely on non-textual metadata, which is often unavailable for many corpora of interest, Nonetheless, our methods could be combined with such methods when such metadata is available. For example, given that both Wikipedia and Twitter have a linked structure between documents, it would be possible to use the link-based metho</context>
</contexts>
<marker>Coursey, Mihalcea, Moen, 2009</marker>
<rawString>Kino Coursey, Rada Mihalcea, and William Moen. 2009. Using encyclopedic knowledge for automatic topic identification. In Proceedings of the Thirteenth Conference on Computational Natural Language Learning, CoNLL ’09, pages 210–218, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Silviu Cucerzan</author>
</authors>
<title>Large-scale named entity disambiguation based on Wikipedia data.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL),</booktitle>
<pages>708--716</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="29501" citStr="Cucerzan (2007)" startWordPosition="4872" endWordPosition="4873">regions that are themselves less spread out globally. 6 Related work Lieberman and Lin (2009) also work with geotagged Wikipedia articles, but they do in order so to analyze the likely locations of users who edit such articles. Other researchers have investigated the use of Wikipedia as a source of data for other supervised NLP tasks. Mihalcea and colleagues have investigated the use of Wikipedia in conjunction with word sense disambiguation (Mihalcea, 2007), keyword extraction and linking (Mihalcea and Csomai, 2007) and topic identification (Coursey et al., 2009; Coursey and Mihalcea, 2009). Cucerzan (2007) used Wikipedia to do named entity disambiguation, i.e. identification and coreferencing of named entities by linking them to the Wikipedia article describing the entity. Some approaches to document geolocation rely largely or entirely on non-textual metadata, which is often unavailable for many corpora of interest, Nonetheless, our methods could be combined with such methods when such metadata is available. For example, given that both Wikipedia and Twitter have a linked structure between documents, it would be possible to use the link-based method given in Backstrom et al. (2010) for predict</context>
</contexts>
<marker>Cucerzan, 2007</marker>
<rawString>Silviu Cucerzan. 2007. Large-scale named entity disambiguation based on Wikipedia data. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), pages 708–716, Prague, Czech Republic, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Junyan Ding</author>
<author>Luis Gravano</author>
<author>Narayanan Shivakumar</author>
</authors>
<title>Computing geographical scopes of web resources.</title>
<date>2000</date>
<booktitle>In Proceedings of the 26th International Conference on Very Large Data Bases, VLDB ’00,</booktitle>
<pages>545--556</pages>
<publisher>Morgan Kaufmann Publishers Inc.</publisher>
<location>San Francisco, CA, USA.</location>
<contexts>
<context position="1605" citStr="Ding et al., 2000" startWordPosition="232" endWordPosition="235">is more challenging: we obtain a median error of 479 km, an improvement on previous results for the dataset. 1 Introduction There are a variety of applications that arise from connecting linguistic content—be it a word, phrase, document, or entire corpus—to geography. Leidner (2008) provides a systematic overview of geography-based language applications over the previous decade, with a special focus on the problem of toponym resolution—identifying and disambiguating the references to locations in texts. Perhaps the most obvious and far-reaching application is geographic information retrieval (Ding et al., 2000; Martins, 2009; Andogah, 2010), with applications like MetaCarta’s geographic text search (Rauch et al., 2003) and NewsStand (Teitler et al., 2008); these allow users to browse and search for 955 content through a geo-centric interface. The Perseus project performs automatic toponym resolution on historical texts in order to display a map with each text showing the locations that are mentioned (Smith and Crane, 2001); Google Books also does this for some books, though the toponyms are identified and resolved quite crudely. Hao et al (2010) use a location-based topic model to summarize travelo</context>
</contexts>
<marker>Ding, Gravano, Shivakumar, 2000</marker>
<rawString>Junyan Ding, Luis Gravano, and Narayanan Shivakumar. 2000. Computing geographical scopes of web resources. In Proceedings of the 26th International Conference on Very Large Data Bases, VLDB ’00, pages 545–556, San Francisco, CA, USA. Morgan Kaufmann Publishers Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Dutton</author>
</authors>
<title>Encoding and handling geospatial data with hierarchical triangular meshes.</title>
<date>1996</date>
<booktitle>Advances in GIS Research II,</booktitle>
<pages>505--518</pages>
<editor>In M.J. Kraak and M. Molenaar, editors,</editor>
<publisher>Taylor and Francis.</publisher>
<location>London.</location>
<contexts>
<context position="11502" citStr="Dutton, 1996" startWordPosition="1769" endWordPosition="1770">would need to be employed. We take here the simpler alternative of discretizing the earth’s surface with a geodesic grid; this allows us to predict locations with a variety of standard approaches over discrete outcomes. There are many ways of constructing geodesic grids. Like Serdyukov et al. (2009), we use the simplest strategy: a grid of square cells of equal degree, such as 1° by 1°. This produces variable-size regions that shrink latitudinally, becoming progressively smaller and more elongated the closer they get towards the poles. Other strategies, such as the quaternary triangular mesh (Dutton, 1996), preserve equal area, but are considerably more complex to implement. Given that most of the populated regions of interest for us are closer to the equator than not and that we use cells of quite fine granularity (down to 0.05°), the simple grid system was preferable. With such a discrete representation of the earth’s surface, there are four distributions that form the core of all our geolocation methods. The first is a standard multinomial distribution over the vocabulary for every cell in the grid. Given a grid G with cells ci and a vocabulary V with words wj, we have Bcij = P(wj|ci). The s</context>
</contexts>
<marker>Dutton, 1996</marker>
<rawString>G. Dutton. 1996. Encoding and handling geospatial data with hierarchical triangular meshes. In M.J. Kraak and M. Molenaar, editors, Advances in GIS Research II, pages 505–518, London. Taylor and Francis.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacob Eisenstein</author>
<author>Brendan O’Connor</author>
<author>Noah A Smith</author>
<author>Eric P Xing</author>
</authors>
<title>A latent variable model for geographic lexical variation.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1277--1287</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Cambridge, MA,</location>
<marker>Eisenstein, O’Connor, Smith, Xing, 2010</marker>
<rawString>Jacob Eisenstein, Brendan O’Connor, Noah A. Smith, and Eric P. Xing. 2010. A latent variable model for geographic lexical variation. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1277–1287, Cambridge, MA, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qiang Hao</author>
<author>Rui Cai</author>
<author>Changhu Wang</author>
<author>Rong Xiao</author>
<author>JiangMing Yang</author>
<author>Yanwei Pang</author>
<author>Lei Zhang</author>
</authors>
<title>Equip tourists with knowledge mined from travelogues.</title>
<date>2010</date>
<booktitle>In Proceedings of the 19th international conference on World wide web, WWW ’10,</booktitle>
<pages>401--410</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="2151" citStr="Hao et al (2010)" startWordPosition="318" endWordPosition="321">ing application is geographic information retrieval (Ding et al., 2000; Martins, 2009; Andogah, 2010), with applications like MetaCarta’s geographic text search (Rauch et al., 2003) and NewsStand (Teitler et al., 2008); these allow users to browse and search for 955 content through a geo-centric interface. The Perseus project performs automatic toponym resolution on historical texts in order to display a map with each text showing the locations that are mentioned (Smith and Crane, 2001); Google Books also does this for some books, though the toponyms are identified and resolved quite crudely. Hao et al (2010) use a location-based topic model to summarize travelogues, enrich them with automatically chosen images, and provide travel recommendations. Eisenstein et al (2010) investigate questions of dialectal differences and variation in regional interests in Twitter users using a collection of geotagged tweets. An intuitive and effective strategy for summarizing geographically-based data is identification of the location—a specific latitude and longitude—that forms the primary focus of each document. Determining a single location of a document is only a well-posed problem for certain documents, gener</context>
</contexts>
<marker>Hao, Cai, Wang, Xiao, Yang, Pang, Zhang, 2010</marker>
<rawString>Qiang Hao, Rui Cai, Changhu Wang, Rong Xiao, JiangMing Yang, Yanwei Pang, and Lei Zhang. 2010. Equip tourists with knowledge mined from travelogues. In Proceedings of the 19th international conference on World wide web, WWW ’10, pages 401– 410, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jochen L Leidner</author>
</authors>
<title>Toponym Resolution in Text: Annotation, Evaluation and Applications of Spatial Grounding of Place Names.</title>
<date>2008</date>
<publisher>Dissertation.Com,</publisher>
<contexts>
<context position="1271" citStr="Leidner (2008)" startWordPosition="184" endWordPosition="186">only the document’s raw text as evidence. All of our methods predict locations in the context of geodesic grids of varying degrees of resolution. We evaluate the methods on geotagged Wikipedia articles and Twitter feeds. For Wikipedia, our best method obtains a median prediction error of just 11.8 kilometers. Twitter geolocation is more challenging: we obtain a median error of 479 km, an improvement on previous results for the dataset. 1 Introduction There are a variety of applications that arise from connecting linguistic content—be it a word, phrase, document, or entire corpus—to geography. Leidner (2008) provides a systematic overview of geography-based language applications over the previous decade, with a special focus on the problem of toponym resolution—identifying and disambiguating the references to locations in texts. Perhaps the most obvious and far-reaching application is geographic information retrieval (Ding et al., 2000; Martins, 2009; Andogah, 2010), with applications like MetaCarta’s geographic text search (Rauch et al., 2003) and NewsStand (Teitler et al., 2008); these allow users to browse and search for 955 content through a geo-centric interface. The Perseus project performs</context>
</contexts>
<marker>Leidner, 2008</marker>
<rawString>Jochen L. Leidner. 2008. Toponym Resolution in Text: Annotation, Evaluation and Applications of Spatial Grounding of Place Names. Dissertation.Com, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M D Lieberman</author>
<author>J Lin</author>
</authors>
<title>You are where you edit: Locating Wikipedia users through edit histories.</title>
<date>2009</date>
<booktitle>In ICWSM’09: Proceedings of the 3rd International AAAI Conference on Weblogs and Social Media,</booktitle>
<pages>106--113</pages>
<location>San Jose, CA,</location>
<contexts>
<context position="7608" citStr="Lieberman and Lin (2009)" startWordPosition="1165" endWordPosition="1168">e formats. Automatically-processed versions of tage of our approach is that it is far simpler, is easy the English-language Wikipedia site are provided by to implement, and scales straightforwardly to large Metaweb,3 which at first glance promised to signifdatasets like Wikipedia. icantly simplify the preprocessing. Unfortunately, these versions still need significant processing and they incorrectly eliminate some of the important metadata. In the end, we wrote our own code to process the raw dump. It should be possible to extend this code to handle other languages with little difficulty. See Lieberman and Lin (2009) for more discussion of a related effort to extract and use the geotagged articles in Wikipedia. The entire set of articles was split 80/10/10 in 2 Data Wikipedia As of April 15, 2011, Wikipedia has some 18.4 million content-bearing articles in 281 language-specific encyclopedias. Among these, 39 have over 100,000 articles, including 3.61 million articles in the English-language edition alone. Wikipedia articles generally cover a single subject; in addition, most articles that refer to geographically 2http://download.wikimedia.org/enwiki/ 20100904/pages-articles.xml.bz2 3http://download.freeba</context>
<context position="28979" citStr="Lieberman and Lin (2009)" startWordPosition="4786" endWordPosition="4789">ocating ship articles is that ships tend to end up sunk in remote battle locations, such that their article is the only one located in the cell covering the location in the training set. Ship terminology thus dominates such cells, with the effect that our models often (incorrectly) geolocate test articles about other ships to such locations (and often about ships with similar properties). This also leads to generally more accurate geolocation of HMS ships over USS ships; the former seem to have been sunk in more concentrated regions that are themselves less spread out globally. 6 Related work Lieberman and Lin (2009) also work with geotagged Wikipedia articles, but they do in order so to analyze the likely locations of users who edit such articles. Other researchers have investigated the use of Wikipedia as a source of data for other supervised NLP tasks. Mihalcea and colleagues have investigated the use of Wikipedia in conjunction with word sense disambiguation (Mihalcea, 2007), keyword extraction and linking (Mihalcea and Csomai, 2007) and topic identification (Coursey et al., 2009; Coursey and Mihalcea, 2009). Cucerzan (2007) used Wikipedia to do named entity disambiguation, i.e. identification and cor</context>
</contexts>
<marker>Lieberman, Lin, 2009</marker>
<rawString>M. D. Lieberman and J. Lin. 2009. You are where you edit: Locating Wikipedia users through edit histories. In ICWSM’09: Proceedings of the 3rd International AAAI Conference on Weblogs and Social Media, pages 106–113, San Jose, CA, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bruno Martins</author>
</authors>
<title>Geographically Aware Web Text Mining.</title>
<date>2009</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Lisbon.</institution>
<contexts>
<context position="1620" citStr="Martins, 2009" startWordPosition="236" endWordPosition="237">: we obtain a median error of 479 km, an improvement on previous results for the dataset. 1 Introduction There are a variety of applications that arise from connecting linguistic content—be it a word, phrase, document, or entire corpus—to geography. Leidner (2008) provides a systematic overview of geography-based language applications over the previous decade, with a special focus on the problem of toponym resolution—identifying and disambiguating the references to locations in texts. Perhaps the most obvious and far-reaching application is geographic information retrieval (Ding et al., 2000; Martins, 2009; Andogah, 2010), with applications like MetaCarta’s geographic text search (Rauch et al., 2003) and NewsStand (Teitler et al., 2008); these allow users to browse and search for 955 content through a geo-centric interface. The Perseus project performs automatic toponym resolution on historical texts in order to display a map with each text showing the locations that are mentioned (Smith and Crane, 2001); Google Books also does this for some books, though the toponyms are identified and resolved quite crudely. Hao et al (2010) use a location-based topic model to summarize travelogues, enrich th</context>
</contexts>
<marker>Martins, 2009</marker>
<rawString>Bruno Martins. 2009. Geographically Aware Web Text Mining. Ph.D. thesis, University of Lisbon.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
<author>Andras Csomai</author>
</authors>
<title>Wikify!: linking documents to encyclopedic knowledge.</title>
<date>2007</date>
<booktitle>In Proceedings of the sixteenth ACM conference on Conference on information and knowledge management, CIKM ’07,</booktitle>
<pages>233--242</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="29408" citStr="Mihalcea and Csomai, 2007" startWordPosition="4857" endWordPosition="4860">ccurate geolocation of HMS ships over USS ships; the former seem to have been sunk in more concentrated regions that are themselves less spread out globally. 6 Related work Lieberman and Lin (2009) also work with geotagged Wikipedia articles, but they do in order so to analyze the likely locations of users who edit such articles. Other researchers have investigated the use of Wikipedia as a source of data for other supervised NLP tasks. Mihalcea and colleagues have investigated the use of Wikipedia in conjunction with word sense disambiguation (Mihalcea, 2007), keyword extraction and linking (Mihalcea and Csomai, 2007) and topic identification (Coursey et al., 2009; Coursey and Mihalcea, 2009). Cucerzan (2007) used Wikipedia to do named entity disambiguation, i.e. identification and coreferencing of named entities by linking them to the Wikipedia article describing the entity. Some approaches to document geolocation rely largely or entirely on non-textual metadata, which is often unavailable for many corpora of interest, Nonetheless, our methods could be combined with such methods when such metadata is available. For example, given that both Wikipedia and Twitter have a linked structure between documents, i</context>
</contexts>
<marker>Mihalcea, Csomai, 2007</marker>
<rawString>Rada Mihalcea and Andras Csomai. 2007. Wikify!: linking documents to encyclopedic knowledge. In Proceedings of the sixteenth ACM conference on Conference on information and knowledge management, CIKM ’07, pages 233–242, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
</authors>
<title>Using Wikipedia for Automatic Word Sense Disambiguation.</title>
<date>2007</date>
<booktitle>In North American Chapter of the Association for Computational Linguistics (NAACL</booktitle>
<contexts>
<context position="29348" citStr="Mihalcea, 2007" startWordPosition="4850" endWordPosition="4851"> properties). This also leads to generally more accurate geolocation of HMS ships over USS ships; the former seem to have been sunk in more concentrated regions that are themselves less spread out globally. 6 Related work Lieberman and Lin (2009) also work with geotagged Wikipedia articles, but they do in order so to analyze the likely locations of users who edit such articles. Other researchers have investigated the use of Wikipedia as a source of data for other supervised NLP tasks. Mihalcea and colleagues have investigated the use of Wikipedia in conjunction with word sense disambiguation (Mihalcea, 2007), keyword extraction and linking (Mihalcea and Csomai, 2007) and topic identification (Coursey et al., 2009; Coursey and Mihalcea, 2009). Cucerzan (2007) used Wikipedia to do named entity disambiguation, i.e. identification and coreferencing of named entities by linking them to the Wikipedia article describing the entity. Some approaches to document geolocation rely largely or entirely on non-textual metadata, which is often unavailable for many corpora of interest, Nonetheless, our methods could be combined with such methods when such metadata is available. For example, given that both Wikipe</context>
</contexts>
<marker>Mihalcea, 2007</marker>
<rawString>Rada Mihalcea. 2007. Using Wikipedia for Automatic Word Sense Disambiguation. In North American Chapter of the Association for Computational Linguistics (NAACL 2007).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Simon Overell</author>
</authors>
<title>Geographic Information Retrieval: Classification, Disambiguation and Modelling.</title>
<date>2009</date>
<tech>Ph.D. thesis,</tech>
<institution>Imperial College London.</institution>
<contexts>
<context position="3075" citStr="Overell (2009)" startWordPosition="460" endWordPosition="461">ntuitive and effective strategy for summarizing geographically-based data is identification of the location—a specific latitude and longitude—that forms the primary focus of each document. Determining a single location of a document is only a well-posed problem for certain documents, generally of fairly small size, but there are a number of natural situations in which such collections arise. For example, a great number of articles in Wikipedia have been manually geotagged; this allows those articles to appear in their geographic locations while geobrowsing in an application like Google Earth. Overell (2009) investigates the use of Wikipedia as a source of data for article geolocation, in addition to article classification by category (location, person, etc.) and toponym resolution. Overell’s main goal is toponym resolution, for which geolocation serves as an input feature. For document geolocation, Overell uses a simple model that makes use only of the metadata available (article title, incoming and outgoing links, etc.)—the actual article text Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 955–964, Portland, Oregon, June 19-24, 2011. c�2011 Associ</context>
<context position="6462" citStr="Overell, 2009" startWordPosition="978" endWordPosition="979">ocument being a con- of which 1,019,490 have been geotagged. Excluding catenation of all actual documents that are located various types of special-purpose articles used priin that cell); new documents are then geolocated to marily for maintaining the site (specifically, redirect the most similar cell according to standard measures articles and articles outside the main namespace), such as Kullback-Leibler divergence (Zhai and Laf- the dump includes 3,431,722 content-bearing artiferty, 2001). Performance is measured both on geo- cles, of which 488,269 are geotagged. tagged Wikipedia articles (Overell, 2009) and tweets It is necessary to process the raw dump to ob(Eisenstein et al., 2010). We obtain high accuracy on tain the plain text, as well as metadata such as geoWikipedia using KL divergence, with a median error tagged coordinates. Extracting the coordinates, for of just 11.8 kilometers. For the Twitter data set, we example, is not a trivial task, as coordinates can obtain a median error of 479 km, which improves be specified using multiple templates and in mulon the 494 km error of Eisenstein et al. An advan- tiple formats. Automatically-processed versions of tage of our approach is that it</context>
</contexts>
<marker>Overell, 2009</marker>
<rawString>Simon Overell. 2009. Geographic Information Retrieval: Classification, Disambiguation and Modelling. Ph.D. thesis, Imperial College London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jay M Ponte</author>
<author>W Bruce Croft</author>
</authors>
<title>A language modeling approach to information retrieval.</title>
<date>1998</date>
<booktitle>In Proceedings of the 21st annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’98,</booktitle>
<pages>275--281</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="5646" citStr="Ponte and Croft, 1998" startWordPosition="855" endWordPosition="858">ocuments and a geodesic grid as a dis- based on the text content: though the ship is moored crete representation of the earth’s surface. Our ap- in Boston, most of the page discusses its role in varproach is similar to that of Serdyukov et al. (2009), ious battles along the eastern seaboard of the USA. who geolocate Flickr images using their associated However, such articles make up only a small fraction textual tags.1 Essentially, the task is cast similarly of the geotagged articles. to language modeling approaches in information re- For the experiments in this paper, we used a full trieval (Ponte and Croft, 1998). Discrete cells rep- dump of Wikipedia from September 4, 2010.2 Inresenting areas on the earth’s surface correspond to cluded in this dump is a total of 10,355,226 articles, documents (with each cell-document being a con- of which 1,019,490 have been geotagged. Excluding catenation of all actual documents that are located various types of special-purpose articles used priin that cell); new documents are then geolocated to marily for maintaining the site (specifically, redirect the most similar cell according to standard measures articles and articles outside the main namespace), such as Kullb</context>
</contexts>
<marker>Ponte, Croft, 1998</marker>
<rawString>Jay M. Ponte and W. Bruce Croft. 1998. A language modeling approach to information retrieval. In Proceedings of the 21st annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’98, pages 275–281, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erik Rauch</author>
<author>Michael Bukatin</author>
<author>Kenneth Baker</author>
</authors>
<title>A confidence-based framework for disambiguating geographic terms.</title>
<date>2003</date>
<booktitle>In Proceedings of the HLT-NAACL 2003 workshop on Analysis of geographic references - Volume 1, HLT-NAACL-GEOREF ’03,</booktitle>
<pages>50--54</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="1716" citStr="Rauch et al., 2003" startWordPosition="248" endWordPosition="251">1 Introduction There are a variety of applications that arise from connecting linguistic content—be it a word, phrase, document, or entire corpus—to geography. Leidner (2008) provides a systematic overview of geography-based language applications over the previous decade, with a special focus on the problem of toponym resolution—identifying and disambiguating the references to locations in texts. Perhaps the most obvious and far-reaching application is geographic information retrieval (Ding et al., 2000; Martins, 2009; Andogah, 2010), with applications like MetaCarta’s geographic text search (Rauch et al., 2003) and NewsStand (Teitler et al., 2008); these allow users to browse and search for 955 content through a geo-centric interface. The Perseus project performs automatic toponym resolution on historical texts in order to display a map with each text showing the locations that are mentioned (Smith and Crane, 2001); Google Books also does this for some books, though the toponyms are identified and resolved quite crudely. Hao et al (2010) use a location-based topic model to summarize travelogues, enrich them with automatically chosen images, and provide travel recommendations. Eisenstein et al (2010)</context>
</contexts>
<marker>Rauch, Bukatin, Baker, 2003</marker>
<rawString>Erik Rauch, Michael Bukatin, and Kenneth Baker. 2003. A confidence-based framework for disambiguating geographic terms. In Proceedings of the HLT-NAACL 2003 workshop on Analysis of geographic references - Volume 1, HLT-NAACL-GEOREF ’03, pages 50–54, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bjorn Sandvik</author>
</authors>
<title>Using KML for thematic mapping. Master’s thesis,</title>
<date>2008</date>
<institution>The University of Edinburgh.</institution>
<contexts>
<context position="16382" citStr="Sandvik, 2008" startWordPosition="2610" endWordPosition="2611">j = 0 d�� (5) (1−αdk)�θdkj, o.w. The distributions over cells for each word simply renormalizes the θcij values to achieve aproper distribution: κji = P θcij θcij (6) ciEG A useful aspect of the κ distributions is that they can be plotted in a geobrowser using thematic mapping 6We use #() to indicate the count of an event. 7BD�dk is an adjusted version of BDj that is normalized over the subset of words not found in document dk. This adjustment ensures that the entire distribution is properly normalized. �θcij = P dkEci P wlEV αdk = (3) |wj E V s.t. #(wj, dk)=1| P #(wj,dk) wjEV 958 techniques (Sandvik, 2008) to inspect the spread of a word over the earth. We used this as a simple way to verify the basic hypothesis that words that do not name locations are still useful for geolocation. Indeed, the Wikipedia distribution for mountain shows high density over the Rocky Mountains, Smokey Mountains, the Alps, and other ranges, while beach has high density in coastal areas. Words without inherent locational properties also have intuitively correct distributions: e.g., barbecue has high density over the south-eastern United States, Texas, Jamaica, and Australia, while wine is concentrated in France, Spai</context>
</contexts>
<marker>Sandvik, 2008</marker>
<rawString>Bjorn Sandvik. 2008. Using KML for thematic mapping. Master’s thesis, The University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pavel Serdyukov</author>
<author>Vanessa Murdock</author>
<author>Roelof van Zwol</author>
</authors>
<title>Placing flickr photos on a map.</title>
<date>2009</date>
<booktitle>In Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’09,</booktitle>
<pages>484--491</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<marker>Serdyukov, Murdock, van Zwol, 2009</marker>
<rawString>Pavel Serdyukov, Vanessa Murdock, and Roelof van Zwol. 2009. Placing flickr photos on a map. In Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’09, pages 484–491, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David A Smith</author>
<author>Gregory Crane</author>
</authors>
<title>Disambiguating geographic names in a historical digital library.</title>
<date>2001</date>
<booktitle>In Proceedings of the 5th European Conference on Research and Advanced Technology for DigitalLibraries, ECDL ’01,</booktitle>
<pages>127--136</pages>
<publisher>Springer-Verlag.</publisher>
<location>London, UK.</location>
<contexts>
<context position="2026" citStr="Smith and Crane, 2001" startWordPosition="297" endWordPosition="300">m of toponym resolution—identifying and disambiguating the references to locations in texts. Perhaps the most obvious and far-reaching application is geographic information retrieval (Ding et al., 2000; Martins, 2009; Andogah, 2010), with applications like MetaCarta’s geographic text search (Rauch et al., 2003) and NewsStand (Teitler et al., 2008); these allow users to browse and search for 955 content through a geo-centric interface. The Perseus project performs automatic toponym resolution on historical texts in order to display a map with each text showing the locations that are mentioned (Smith and Crane, 2001); Google Books also does this for some books, though the toponyms are identified and resolved quite crudely. Hao et al (2010) use a location-based topic model to summarize travelogues, enrich them with automatically chosen images, and provide travel recommendations. Eisenstein et al (2010) investigate questions of dialectal differences and variation in regional interests in Twitter users using a collection of geotagged tweets. An intuitive and effective strategy for summarizing geographically-based data is identification of the location—a specific latitude and longitude—that forms the primary </context>
</contexts>
<marker>Smith, Crane, 2001</marker>
<rawString>David A. Smith and Gregory Crane. 2001. Disambiguating geographic names in a historical digital library. In Proceedings of the 5th European Conference on Research and Advanced Technology for DigitalLibraries, ECDL ’01, pages 127–136, London, UK. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B E Teitler</author>
<author>M D Lieberman</author>
<author>D Panozzo</author>
<author>J Sankaranarayanan</author>
<author>H Samet</author>
<author>J Sperling</author>
</authors>
<title>NewsStand: A new view on news.</title>
<date>2008</date>
<booktitle>In GIS’08: Proceedings of the 16th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems,</booktitle>
<pages>144--153</pages>
<location>Irvine, CA,</location>
<contexts>
<context position="1753" citStr="Teitler et al., 2008" startWordPosition="254" endWordPosition="257">of applications that arise from connecting linguistic content—be it a word, phrase, document, or entire corpus—to geography. Leidner (2008) provides a systematic overview of geography-based language applications over the previous decade, with a special focus on the problem of toponym resolution—identifying and disambiguating the references to locations in texts. Perhaps the most obvious and far-reaching application is geographic information retrieval (Ding et al., 2000; Martins, 2009; Andogah, 2010), with applications like MetaCarta’s geographic text search (Rauch et al., 2003) and NewsStand (Teitler et al., 2008); these allow users to browse and search for 955 content through a geo-centric interface. The Perseus project performs automatic toponym resolution on historical texts in order to display a map with each text showing the locations that are mentioned (Smith and Crane, 2001); Google Books also does this for some books, though the toponyms are identified and resolved quite crudely. Hao et al (2010) use a location-based topic model to summarize travelogues, enrich them with automatically chosen images, and provide travel recommendations. Eisenstein et al (2010) investigate questions of dialectal d</context>
</contexts>
<marker>Teitler, Lieberman, Panozzo, Sankaranarayanan, Samet, Sperling, 2008</marker>
<rawString>B. E. Teitler, M. D. Lieberman, D. Panozzo, J. Sankaranarayanan, H. Samet, and J. Sperling. 2008. NewsStand: A new view on news. In GIS’08: Proceedings of the 16th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems, pages 144–153, Irvine, CA, November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chengxiang Zhai</author>
<author>John Lafferty</author>
</authors>
<title>Model-based feedback in the language modeling approach to information retrieval.</title>
<date>2001</date>
<booktitle>In Proceedings of the tenth international conference on Information and knowledge management, CIKM ’01,</booktitle>
<pages>403--410</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="17772" citStr="Zhai and Lafferty, 2001" startWordPosition="2834" endWordPosition="2837">each cell: γi = |ci| |D|. A standard set of stop words are ignored. Also, all words are lowercased except in the case of the most-common-toponym baselines, where uppercase words serve as a fallback in case a toponym cannot be located in the article. 4.2 Kullback-Leibler divergence Given the distributions for each cell, θci, in the grid, we use an information retrieval approach to choose a location for a test document dk: compute the similarity between its word distribution θdk and that of each cell, and then choose the closest one. KullbackLeibler (KL) divergence is a natural choice for this (Zhai and Lafferty, 2001). For distribution P and Q, KL divergence is defined as: P (i) P(i) log Q(i) (7) This quantity measures how good Q is as an encoding for P – the smaller it is the better. The best cell ˆcKL is the one which provides the best encoding for the test document: the test document is a good encoding for. With KL(θdk||θci), the log ratio of probabilities for each word is weighted by the probability of the word in the test document, ed,j log θdkj θcij , which means that the divergence is more sensitive to the document rather than the overall cell. As an example for why non-symmetric KL in this order is</context>
</contexts>
<marker>Zhai, Lafferty, 2001</marker>
<rawString>Chengxiang Zhai and John Lafferty. 2001. Model-based feedback in the language modeling approach to information retrieval. In Proceedings of the tenth international conference on Information and knowledge management, CIKM ’01, pages 403–410, New York, NY, USA. ACM.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>