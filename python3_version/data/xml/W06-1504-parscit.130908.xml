<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.972212">
The weak generative capacity of linear tree-adjoining grammars
</title>
<author confidence="0.997324">
David Chiang*
</author>
<affiliation confidence="0.874519">
Information Sciences Institute
University of Southern California
4676 Admiralty Way, Suite 1001
</affiliation>
<address confidence="0.730395">
Marina del Rey, CA 90292, USA
</address>
<email confidence="0.999292">
chiang@isi.edu
</email>
<sectionHeader confidence="0.999565" genericHeader="abstract">
1 Introduction
</sectionHeader>
<bodyText confidence="0.990234489361702">
Linear tree-adjoining grammars (TAGs), by anal-
ogy with linear context-free grammars, are tree-
adjoining grammars in which at most one sym-
bol in each elementary tree can be rewritten (ad-
joined or substituted at). Uemura et al. (1999),
calling these grammars simple linear TAGs (SL-
TAGs), show that they generate a class of lan-
guages incommensurate with the context-free lan-
guages, and can be recognized in O(n4) time.
Working within the application domain of mod-
eling of RNA secondary structures, they find
that SL-TAGs are too restrictive—they can model
RNA pseudoknots but because they cannot gen-
erate all the context-free languages, they cannot
model even some very simple RNA secondary
structures. Therefore they propose a more power-
ful version of linear TAGs, extended simple linear
TAGs (ESL-TAGs), which generate a class of lan-
guages that include the context-free languages and
can be recognized in O(n5) time.
Satta and Schuler (1998), working within the
application domain of natural language syntax, de-
fine another restriction on TAG which is also rec-
ognizable in O(n5) time. Despite being less pow-
erful than full TAG, it is still able to generate lan-
guages like the copy language {ww} and Dutch
cross-serial dependencies (Joshi, 1985). Kato et
al. (2004) conjecture that this restricted TAG is in
fact equivalent to ESL-TAG.
In this paper we prove their conjecture, and also
prove that adding substitution to ESL-TAG does
not increase its weak generative capacity, whereas
adding substitution to SL-TAG makes it weakly
equivalent to ESL-TAG. Thus these four for-
*This research was primarily carried out while the author
was at the University of Pennsylvania.
malisms converge to the same weak-equivalence
class, the intuition being that the “hardest” oper-
ation in TAG, namely, adjunction of a wrapping
auxiliary tree in the middle of the spine of an-
other wrapping auxiliary tree, is subjected to the
linearity constraint, but most other operations are
unrestricted.&apos; Kato et al. (2004) show that these
formalisms are more powerful than SL-TAG or
general CFG or their union and conjecture, on the
other hand, that they are less powerful than TAG.
We prove this conjecture as well.
</bodyText>
<sectionHeader confidence="0.995973" genericHeader="keywords">
2 Definitions
</sectionHeader>
<bodyText confidence="0.88811452">
We assume a standard definition of TAG, with or
without substitution, in which adjunction is not al-
lowed at foot nodes, and other nodes can have no-
adjunction (NA) constraints, obligatory-adjunction
(OA), or selective-adjunction constraints. We use
the symbols η, η1, η2, etc. to range over nodes of
elementary trees or derived trees, although some-
times we use the label of a node to refer to the
node itself. The spine of an auxiliary tree is the
path from its root node to its foot node, inclusive.
The subtree of a node η is the set of all nodes
dominated by η, including η itself. The segment
of a tree from η1 to η2 (where η1 dominates η2)
is the set of all nodes in the subtree of η1 but not
in the subtree of η2. A segment can be excised,
which means removing the nodes of the segment
and making η2 replace η1 as the child of its parent.
We also assume a standard definition of TAG
derivation trees. We use the symbols h, h1, h2, etc.
to range over nodes of derivation trees. The sub-
&apos;Adjunction at root and foot nodes is another operation
that by itself will not take a formalism beyond context-free
power, a fact which is exploited in Rogers’ regular-form TAG
(Rogers, 1994). But allowing this in a linear TAG would cir-
cumvent the linearity constraint.
</bodyText>
<page confidence="0.977498">
25
</page>
<note confidence="0.585806">
Proceedings of the 8th International Workshop on Tree Adjoining Grammar and Related Formalisms, pages 25–32,
Sydney, July 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.928768625">
derivation of h is the subtree of h in the deriva-
tion tree. When we cut up derivations into sub-
derivations or segments and recombine them, the
edge labels (indicating addresses of adjunctions
and substitutions) stay with the node above, not
the node below.
Now we define various versions of linear TAG.
Definition 1. A right (left) auxiliary tree is one in
which the leftmost (rightmost) frontier node is the
foot node, and the spine contains only the root and
foot nodes. A wrapping auxiliary tree is one which
is neither a left or a right auxiliary tree.
Definition 2. We say that a node of an elementary
tree is active if adjunction is allowed to occur at
it, and that a node is w-active if adjunction of a
wrapping auxiliary tree is allowed to occur at it.
</bodyText>
<listItem confidence="0.70999325">
Definition 3. A Satta-Schuler linear tree-
adjoining grammar (SSL-TAG) is a TAG with
substitution in which:
1. In the spine of each wrapping auxiliary tree,
there is at most one w-active node.
2. In the spine of each left or right auxiliary tree,
there are no w-active nodes, nor are there any
other adjoining constraints.
</listItem>
<bodyText confidence="0.905199285714286">
Definition 4. A simple linear tree-adjoining
grammar (SL-TAG), with or without substitution,
is a TAG, with or without substitution, respec-
tively, in which every initial tree has exactly one
active node, and every auxiliary tree has exactly
one active node on its spine and no active nodes
elsewhere.
Definition 5. An extended simple linear tree-
adjoining grammar (ESL-TAG), with or without
substitution, is a TAG, with or without substitu-
tion, respectively, in which every initial tree has
exactly one active node, and every auxiliary tree
has exactly one active node on its spine and at
most one active node elsewhere.
</bodyText>
<sectionHeader confidence="0.997115" genericHeader="introduction">
3 Properties
</sectionHeader>
<bodyText confidence="0.9768356">
We now review several old results and prove a few
new results relating the weak generative capacity
of these formalisms to one another and to (linear)
CFG and TAG. These results are summarized in
Figure 1.
</bodyText>
<subsectionHeader confidence="0.999013">
3.1 Previous results
</subsectionHeader>
<bodyText confidence="0.561686">
Proposition 1 (Uemura et al. 1999).
</bodyText>
<equation confidence="0.8757875">
Linear CFL C SL-TAL
TAL
SSL-TAL = ESL-TAL = (E)SL-TAL + subst
SL-TAL U CFL
</equation>
<sectionHeader confidence="0.653164" genericHeader="method">
SL-TAL CFL
</sectionHeader>
<subsectionHeader confidence="0.500193">
Linear CFL
</subsectionHeader>
<figureCaption confidence="0.973265">
Figure 1: Summary of results: an edge indicates
that the higher formalism has strictly greater weak
generative capacity than the lower.
</figureCaption>
<figure confidence="0.90097125">
Proposition 2 (Uemura et al. 1999).
CFL C ESL-TAL
Proposition 3 (Kato et al. 2004).
CFL U SL-TAL C ESL-TAL
</figure>
<figureCaption confidence="0.62969">
Proposition 4 (Satta and Schuler 1998; Ue-
mura et al. 1999). SSL-TAG and ESL-TAG can
be parsed in O(n5) time.
</figureCaption>
<subsectionHeader confidence="0.995461">
3.2 Weak equivalence
</subsectionHeader>
<listItem confidence="0.689022166666667">
Proposition 5. The following formalisms are
weakly equivalent:
(i) ESL-TAG
(ii) SL-TAG with substitution
(iii) ESL-TAG with substitution
(iv) SSL-TAG
</listItem>
<bodyText confidence="0.487926">
Proof. We prove this by proving four inclusions.
</bodyText>
<equation confidence="0.8991738">
G(ESL-TAG) C_ G(ESL-TAG+ substitution):
Trivial.
G(ESL-TAG+substitution) C_ G(SSL-TAG):
Trivial.
G(SSL-TAG) C_ G(SL-TAG + substitution): We
</equation>
<bodyText confidence="0.9954815">
deal first with the left and right auxiliary trees, and
then with off-spine adjunction.
First, we eliminate the left and right auxiliary
trees. Since these only insert material to the left or
right of a node, just as in tree-insertion grammars
(TIGs), we may apply the conversion from TIGs to
tree-substitution grammars (Schabes and Waters,
1995), used in the proof of the context-freeness of
</bodyText>
<page confidence="0.989301">
26
</page>
<figure confidence="0.995921818181818">
...
XNA
...
XNA
...
X
⇒
...
X
XNA
RX↓
LX↓ XNA
RX↓
...
...
...
XNA
LX↓ XNA
(Step 1a)
... ... ...
(Step 1b)
X
X∗ Y ⇒
RX
Y RX↓
RX
Y
LX
LX↓ Y
X
LX
Y
Y X∗ ⇒
</figure>
<figureCaption confidence="0.999968">
Figure 2: Elimination of left/right auxiliary trees.
</figureCaption>
<bodyText confidence="0.997762150943396">
TIG.2 (Step 1a) For each active node X that is not
the root of a left or right auxiliary tree, we create
four copies of the containing elementary tree with
X altered in the following ways: first, leave X un-
changed; then, add a copy of X above it, making
both nodes no-adjunction nodes, and add a new
left sister substitution node labeled LX or a new
right sister substitution node labeled RX, or both.
See Figure 2. (Step 1b) For each β that was origi-
nally a left (right) auxiliary tree with root/foot la-
bel X, relabel the root node as LX (RX) and delete
the foot node, and create two copies of the contain-
ing elementary tree, one unchanged, and one with
a new left (right) sister substitution node. See Fig-
ure 2. When the modified β substitutes at one of
the new children of an η, the substitution clearly
results in the same string that would have resulted
from adjoining the original β to η.
This construction might appear incorrect in two
ways. First, the new grammar has trees with both
an LX and an RX node corresponding to the same
original node, which would correspond to adjunc-
tion of two auxiliary trees βL and βR at the same
node X in the original grammar. But this new
derivation generates a string that was generable in
the original grammar, namely by adjoining βL at
2This corresponds to Steps 1–4 of that proof (Schabes and
Waters, 1995, p. 486). Since that proof uses a more relaxed
definition of left and right auxiliary trees, it is probable that
SSL-TAG could also be relaxed in the same way.
X, then adjoining βR at the root of βL, which is
allowed because the definition of SSL-TAG pro-
hibits adjunction constraints at the root of βL.
Thus the first apparent problem is really the so-
lution to the second problem: in the original gram-
mar, a left auxiliary tree βL could adjoin at the root
of a right auxiliary tree βR, which in turn adjoined
at a node η, whereas in the new grammar, βR does
not have an LX substitution node to allow this pos-
sibility. But the same string can be generated by
substituting both trees under η in the new gram-
mar. In the case of a whole chain of adjunctions
of left/right auxiliary trees at the root of left/right
auxiliary trees, we can generate the same string by
rearranging the chain into a chain of left auxiliary
trees and a chain of right auxiliary trees (which is
allowed because adjunction constraints are prohib-
ited at all the roots), and substituting both at η.
(Step 2) Next, we eliminate the case of a wrap-
ping auxiliary tree β that can adjoin at an off-spine
node η. (Step 2a) For each active off-spine node η,
we relabel η with a unique identifier η� and split the
containing elementary tree at η:
</bodyText>
<figure confidence="0.860941666666667">
... ⇒ ...
η� T�↓
... B�
</figure>
<page confidence="0.989365">
27
</page>
<bodyText confidence="0.997871363636364">
(Step 2b) After step 2a has been completed for all
nodes q, we revisit each q, and for every wrapping
Q that could adjoin at q, create a copy of Q with
root relabeled to Tˆη and foot relabeled to Bˆη.
Then the original Q is discarded. Substituting one
of these copies of Q at a Tˆη node and then sub-
stituting a Bˆη tree at the former foot node has the
same effect as adjoining Q at q. Finally, unless q
had an obligatory-adjunction constraint, simulate
the lack of adjunction at q by adding the initial
tree
</bodyText>
<equation confidence="0.822216333333333">
Tˆη
BˆηJ
L(SL-TAG + substitution) C_ L(ESL-TAG): This
</equation>
<bodyText confidence="0.999071">
construction is related to Lang’s normal form
which ensures binary-branching derivation trees
(Lang, 1994), but guarantees that one adjunction
site is on the spine and one is off the spine.
(Step 0a) Ensure that the elementary trees are
binary-branching. (Step 0b) Add a new root and
foot node to every elementary tree:
</bodyText>
<equation confidence="0.942061666666667">
XNA
� X
XNA
</equation>
<bodyText confidence="0.99712232">
If Y has another child, call it Z2; let V2 be a fresh
nonterminal symbol and insert a V2 node above
Z2, and break off the subtree rooted in V2, leav-
ing behind a substitution node. See Figure 3. This
transformation reduces the spine of the auxiliary
tree by one node, and creates two new trees that
satisfy the desired form. We repeat this until the
entire grammar is in the desired form.
(Step 2) Next, we transform the grammar so
that no initial tree has more than one substitution
node, while maintaining the form acquired in step
1. For any initial tree with height greater than three
nodes, we apply the same transformation as in step
1, except that Y is the child of the root node, Z1
is its left child, and Z2 is its other child if it ex-
ists and is not already a substitution node. See Fig-
ure 3. This transformation replaces an initial tree
with at most two shorter initial trees, and one aux-
iliary tree in the desired form. Again we repeat this
until the entire grammar is in the desired form.
(Step 3) Finally, we convert each substitution
node into an adjunction node (Schabes, 1990). For
each substitution node q, let X be the label of q.
Relabel q to SX with obligatory adjunction and
place an empty terminal beneath q.
</bodyText>
<figure confidence="0.7866024">
...
...
� SXOA
XJ
E
</figure>
<bodyText confidence="0.99084925">
For each initial tree with root label X, convert it
into an auxiliary tree by adding a new root node
labeled SX whose children are the old root node
and a new foot node.
</bodyText>
<equation confidence="0.886188733333333">
�
X
X*
Tˆη
BˆηJ
X
SXNA
� X SX*
X
�
X
X*
X
XNA
X*
</equation>
<bodyText confidence="0.9984476">
(Step 1) We transform the grammar so that no
auxiliary tree has more than one substitution node.
For any auxiliary tree with spine longer than four
nodes, we apply the following transformation: tar-
get either the active node or its parent, and call
it Y . Let Z1 be the child that dominates the foot
node; let V1 be a fresh nonterminal symbol and
insert V1 nodes above Y and below Z1, and ex-
cise the segment between the two V nodes, leav-
ing behind an active obligatory-adjunction node.
</bodyText>
<subsectionHeader confidence="0.998451">
3.3 Relation to tree-adjoining languages
</subsectionHeader>
<bodyText confidence="0.734474833333333">
Our second result, also conjectured by Kato et
al., is that the weak equivalence class established
above is a proper subset of TAL.
Proposition 6. The language
L = �ar 1bp 1bp 2cq 1cq 2ar 2ar 3cq 3cq 4bp 3bp 4ar 4�
is in TAL but not ESL-TAL.
</bodyText>
<page confidence="0.995494">
28
</page>
<figure confidence="0.999165912280702">
Z1
...
X*
�
Z2NA
...
X
...
V1
Y
�
V2
Z2NA
X
...
V1OA
...
X*
Z1
V1*
V2
V2
Z2NA
(Step 1)
Z1
V1
X
...
Y
V1NA
Y
... ... ...
X*
X
Y
Z1
... ...
X
V1OA
...
V1NA
Y
Z1 V2
V1* V2
Z2
(Step 2)
Z2
X
V1
Y
�
�
V2
Z1
V1
Z2
... ... ...
</figure>
<figureCaption confidence="0.999651">
Figure 3: Separation of substitution nodes. Some adjunction constraints are omitted to avoid clutter.
</figureCaption>
<equation confidence="0.71612075">
Proof (L E TAL). The language is generated by
the following TAG:
X
E
</equation>
<bodyText confidence="0.997974">
Before proceeding to the other half of the proof,
we define a few useful notions. A marked string
(as in Ogden’s Lemma) over an alphabet E is a
string over E x 10, 11, where a symbol (Q, 1) is
marked and a symbol (Q, 0) is not. Marked strings
over E can be projected into E* in the obvious way
and we will talk about marked strings and their
projections interchangeably.
A decomposed string over E is a sequence
of strings over E, which can be projected into
E* by concatenating their members in order, and
again we will talk about decomposed strings and
their projections interchangeably. In particular,
we will often simply write a decomposed string
(w1, ... , wn) as w1 · · · wn. Moreover, we may use
the symbol wi to refer to the occurrence of the ith
member of the decomposition in w; for example, if
w is a marked string, we may say that a symbol in
wi is marked, or if w is generated by a TAG deriva-
tion, we may say that wi is generated by some set
of nodes in the derivation tree.
The second half of the proof requires a double-
decker pumping lemma.
Condition 1 (cf. Vijay-Shanker (1987), Theo-
rem 4.7). Given a language L and a decom-
posed string x1zx2 E L with some symbols in
z marked, there exists a decomposition of z into
u1v1w1v2u2v3w2v4u3 such that one of the vi con-
tains a mark, and L contains, for all k &gt; 1,
</bodyText>
<equation confidence="0.921196117647059">
x1(u1vk1w1vk2u2vk3w2vk4u3)x2
Condition 2 (cf. Uemura et al. (1999), Lemma
YNA
ZNA
XNA
a1 X
a2 X* a3
a4
XNA
Y
Z
X*
b1 Y
b2 Y* b3
b4 c1 Z
c2 Z* c3
c4
</equation>
<page confidence="0.990622">
29
</page>
<bodyText confidence="0.903028666666667">
1). Given a language L and a decomposed string
x1z1z2x2z3z4x3 E L with some symbols in one of
the zi marked, there exist decompositions of the zi
into uiviwi such that one of the vi contains a mark,
and L contains, for all k &gt; 1,
x1(u1vk1w1)(u2vk2w2)x2(u3vk3w3)(u4vk4w4)x3
</bodyText>
<construct confidence="0.649643">
Lemma 7. If L is an ESL-TAL, then there exists
a constant n such that for any z E L with n sym-
bols marked, Condition 1 holds of E · z · E. More-
over, it holds such that the w1 and w2 it provides
</construct>
<bodyText confidence="0.992829263736264">
can be further decomposed into z1z2 and z3z4, re-
spectively, such that for any marking of n sym-
bols of any of the zj, either Condition 1 holds
of z = x1zjx2 (where x1 and x2 are the sur-
rounding context of zj) or Condition 2 holds of
z = x1z1z2x2z3z4x3 (where x1, x2, and x3 are
the surrounding context of z1z2 and z3z4).
Proof. Since L is an ESL-TAL, it is generated by
some ESL-TAG G. Let k be the number of ele-
mentary trees in G and t be the maximum number
of terminal symbols in any elementary tree of G.
Then set n = 2k+1t.
The first invocation of Condition 1 is the TAG
version of Ogden’s lemma (Hopcroft and Ullman,
1979). To show that it holds, we need to find a
path P in the derivation tree of z that has a cy-
cle that generates at least one marked symbol. De-
fine a branch point to be a node h in the derivation
tree such that the marked nodes generated by the
subderivation of h are not all generated by the sub-
derivation of a single child of h. We seek a P that
has at least k + 1 branch points. Start by adding
the root of the derivation tree to P. Thereafter let
h be the last node in P. If h is a leaf, stop; other-
wise, add to P the child of h whose subderivation
generates the most marked symbols. Note that if
a branch point in P generates m marked symbols,
the next branch point generates at least m�t
2 . Our
choice of n then guarantees that P has at least k+1
branch points, at least two of which must corre-
spond to the same auxiliary tree. Call these nodes
h1 and h2.
These two nodes divide the derivation up into
three phases: first, the derivation segment from the
root to h1, which we call α (because it can be
thought of as the derived initial tree it generates);
then the segment from h1 to h2, which we call β1
(because it can be thought of as the derived aux-
iliary tree it generates); then subderivation of h2,
which we call β2. Note that we can form new valid
derivations of G by repeating β2: that is, in terms
of derivation trees, stacking α on top of one or
more copies of β1, on top of β2—or in terms of
derived trees, repeatedly adjoining β1 into α and
then adjoining β2.
If β2 adjoins into the spine of β1, then let
(u1, u2, u3) be the parts of z generated by α,
(v1, v2, v3, v4) the parts generated by β1, and
(w1, w2) the parts generated by β2 (see Figure 4a).
Then these new derivations generate the strings
u1vk1w1vk2u2vk3w2vk4u3.
But if β2 adjoins at a node to the left of the spine
of β1, then let (u1, v42, u3) be the parts of the z
generated by α, (v1, u2, v41, v43) the parts gener-
ated by β1, and (w1, w2) the parts generated by
β2 (see Figure 4b). Then let v2 = v3 = E and
v4 = v41v42v43; the new derivations will gener-
ate the strings u1vk1w1vk2u2vk3w2vk4u3. The case
where β2 adjoins to the right of the spine.
Now we focus attention on β2. Let S be the
longest path of the derivation of β2 containing
the root of the derivation and auxiliary trees ad-
joined at spine nodes. This S is unique because
each spine can only have one active node. Let h3
be the last node in S, which divides the deriva-
tion of β2 into two phases: the segment from the
root to h3, which we call β21, and the subderiva-
tion of h3, which we call β22. This gives a decom-
position (w1, w2) = (z1z21z22, z31z32z4), where
β22 generates z21 and z32 (see Figure 5). Note
that the derivation nodes in S are the only ones
that can generate symbols in z1, z22, z31, and z4
at once; the other derivation nodes only gener-
ate symbols in a single zi. We let z2 = z21z22
and z3 = z31z32 and hand off the decomposition
(w1, w2) = (z1z2, z3z4) to our adversary, who
may choose a zj and mark n symbols in it.
Then we recapitulate the reasoning above to get
a path P0 starting from the root of the deriva-
tion of β2 and containing at least k + 1 branch
points, two of which correspond to the same aux-
iliary tree. Call these nodes h4 and h5 and the seg-
ment between them β3, and let (v1, v2, v3, v4) now
stand for the parts of (w1, w2) generated by β3.
Once again, we are going to repeat β3 to gener-
ate new derivations, pumping copies of the vi into
(w1, w2). But the location of the vi depends on h5:
if h5 is in S, then the vi will appear inside each of
the zi, satisfying Condition 2. Otherwise, they will
all appear inside zj.
</bodyText>
<page confidence="0.980257">
30
</page>
<figure confidence="0.998801">
α
01
β2
01
α
u1 v1 w1 v2 u2 v3 w2 v4 u3
01
β2
01
α
α
u1 v1 w1 v2 w2 v41 v42 v43 u3
</figure>
<figureCaption confidence="0.9999965">
Figure 4: Anatomy of derived tree in proof of Lemma 7.
Figure 5: Anatomy of β2 in proof of Lemma 7.
</figureCaption>
<figure confidence="0.9955272">
z1 z21 z22 z31 z32 z4
β21
022
β21
�
</figure>
<page confidence="0.999833">
31
</page>
<bodyText confidence="0.997020647058824">
Finally we complete the proof of Proposition 6.
Proof ofProposition 6 (L V ESL-TAL). Suppose
L is an ESL-TAL. Let z be the string obtained by
setting p = q = r = n, and mark the a1s. Then
Lemma 7 must hold. The first invocation of Con-
dition 1 must give a w1 of the form aibn1bn2 cn1 cn2 a2
and a w2 of the form a* 3cn3 cn4 bn3 bn4 a4. Lemma 7
must further decompose w1 into z1z2. Obviously,
either z1 contains all the bjs or z2 contains all
the cjs. Supposing the former, we can obtain a
contradiction by marking the b1s: Condition 2
is impossible because it would give unequal
numbers of b1s and b2s; Condition 1 is impossible
because it would give unequal numbers of b1s and
b3s. On the other hand, if z2 contains all the cjs,
we mark the c1s, and both Conditions are again
rendered impossible.
</bodyText>
<sectionHeader confidence="0.999703" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999976708333334">
The weak equivalence of the previously proposed
ESL-TAG and SSL-TAG, along with the fact that
SL-TAG with substitution and ESL-TAG with
substitution belong to the same class, suggests
that they represent a useful compromise between
CFGs and TAGs. In the two-dimensional language
hierarchy of Rambow and Satta (1999), where the
two dimensions are rank (how many substructures
does a rule combine) and fanout (how many dis-
continuous spans of the input does a substructure
cover), CFGs comprise the fanout-1 grammars and
TAGs are a subset of the the fanout-2 grammars;
both have arbitrary rank, whereas linear CFGs
and linear TAGs are rank-1. The grammars dis-
cussed here are mixed: a rule can combine one
fanout-2 substructure and an arbitrary number of
fanout-1 substructures. A related example would
be a version of synchronous CFG that allows only
one pair of linked nonterminals and any number
of unlinked nonterminals, which could be bitext-
parsed in O(n5) time, whereas inversion transduc-
tion grammar (Wu, 1997) takes O(n6). It may be
of interest to make a more general exploration of
other formalisms that are mixed in this sense.
</bodyText>
<sectionHeader confidence="0.997532" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.98407475">
Thanks to Hiroyuki Seki for discussions that led to
this paper, and to Anoop Sarkar, Giorgio Satta, and
William Schuler. This research was partially sup-
ported by NSF grant ITR EIA-02-05456. S. D. G.
</bodyText>
<sectionHeader confidence="0.994598" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999627511111111">
John E. Hopcroft and Jeffrey D. Ullman. 1979. Intro-
duction to Automata Theory, Languages, and Com-
putation. Addison-Wesley, Reading, MA.
Aravind K. Joshi. 1985. Tree adjoining grammars:
How much context-sensitivity is necessary for as-
signing structural descriptions? In David Dowty,
Lauri Karttunen, and Arnold Zwicky, editors, Nat-
ural Language Parsing, pages 206–250. Cambridge
University Press, Cambridge.
Yuki Kato, Hiroyuki Seki, and Tadao Kasami. 2004.
Subclasses of tree adjoining grammar for RNA sec-
ondary structure. In Proc. Seventh International
Workshop on TAG and Related Formalisms (TAG+),
pages 48–55.
Bernard Lang. 1994. Recognition can be harder than
parsing. Computational Intelligence, 10(4):484–
494. Special Issue on Tree Adjoining Grammars.
Owen Rambow and Giorgio Satta. 1999. Independent
parallelism in finite copying parallel rewriting sys-
tems. Theoretical Computer Science, 223:87–120.
James Rogers. 1994. Capturing CFLs with tree adjoin-
ing grammars. In Proc. 32nd Annual Meeting of the
ACL, pages 155–162.
Giorgio Satta and William Schuler. 1998. Restrictions
on tree adjoining languages. In Proc. COLING-
ACL, pages 1176–1182.
Yves Schabes and Richard C. Waters. 1995. Tree
insertion grammar: a cubic-time parsable formal-
ism that lexicalizes context-free grammar without
changing the trees produced. Computational Lin-
guistics, 21:479–513.
Yves Schabes. 1990. Mathematical and Computa-
tional Aspects ofLexicalized Grammars. Ph.D. the-
sis, University of Pennsylvania. Available as techni-
cal report MS-CIS-90-48.
Yasuo Uemura, Aki Hasegawa, Satoshi Kobayashi, and
Takashi Yokomori. 1999. Tree adjoining grammars
for RNA structure prediction. Theoretical Computer
Science, 210:277–303.
K Vijayashanker. 1987. A study of tree adjoining
grammars. Ph.D. thesis, University of Pennsylva-
nia. Available as technical report MS-CIS-88-03.
Dekai Wu. 1997. Stochastic inversion transduction
grammars and bilingual parsing of parallel corpora.
Computational Linguistics, 23:377–404.
</reference>
<page confidence="0.9993">
32
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.666626">
<title confidence="0.989512">The weak generative capacity of linear tree-adjoining grammars</title>
<affiliation confidence="0.865895">Information Sciences University of Southern</affiliation>
<address confidence="0.9730935">4676 Admiralty Way, Suite Marina del Rey, CA 90292,</address>
<email confidence="0.975605">chiang@isi.edu</email>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>John E Hopcroft</author>
<author>Jeffrey D Ullman</author>
</authors>
<title>Introduction to Automata Theory, Languages, and Computation.</title>
<date>1979</date>
<publisher>Addison-Wesley,</publisher>
<location>Reading, MA.</location>
<contexts>
<context position="16043" citStr="Hopcroft and Ullman, 1979" startWordPosition="2914" endWordPosition="2917">can be further decomposed into z1z2 and z3z4, respectively, such that for any marking of n symbols of any of the zj, either Condition 1 holds of z = x1zjx2 (where x1 and x2 are the surrounding context of zj) or Condition 2 holds of z = x1z1z2x2z3z4x3 (where x1, x2, and x3 are the surrounding context of z1z2 and z3z4). Proof. Since L is an ESL-TAL, it is generated by some ESL-TAG G. Let k be the number of elementary trees in G and t be the maximum number of terminal symbols in any elementary tree of G. Then set n = 2k+1t. The first invocation of Condition 1 is the TAG version of Ogden’s lemma (Hopcroft and Ullman, 1979). To show that it holds, we need to find a path P in the derivation tree of z that has a cycle that generates at least one marked symbol. Define a branch point to be a node h in the derivation tree such that the marked nodes generated by the subderivation of h are not all generated by the subderivation of a single child of h. We seek a P that has at least k + 1 branch points. Start by adding the root of the derivation tree to P. Thereafter let h be the last node in P. If h is a leaf, stop; otherwise, add to P the child of h whose subderivation generates the most marked symbols. Note that if a </context>
</contexts>
<marker>Hopcroft, Ullman, 1979</marker>
<rawString>John E. Hopcroft and Jeffrey D. Ullman. 1979. Introduction to Automata Theory, Languages, and Computation. Addison-Wesley, Reading, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aravind K Joshi</author>
</authors>
<title>Tree adjoining grammars: How much context-sensitivity is necessary for assigning structural descriptions? In</title>
<date>1985</date>
<booktitle>Natural Language Parsing,</booktitle>
<pages>206--250</pages>
<editor>David Dowty, Lauri Karttunen, and Arnold Zwicky, editors,</editor>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge.</location>
<contexts>
<context position="1475" citStr="Joshi, 1985" startWordPosition="229" endWordPosition="230">s, they cannot model even some very simple RNA secondary structures. Therefore they propose a more powerful version of linear TAGs, extended simple linear TAGs (ESL-TAGs), which generate a class of languages that include the context-free languages and can be recognized in O(n5) time. Satta and Schuler (1998), working within the application domain of natural language syntax, define another restriction on TAG which is also recognizable in O(n5) time. Despite being less powerful than full TAG, it is still able to generate languages like the copy language {ww} and Dutch cross-serial dependencies (Joshi, 1985). Kato et al. (2004) conjecture that this restricted TAG is in fact equivalent to ESL-TAG. In this paper we prove their conjecture, and also prove that adding substitution to ESL-TAG does not increase its weak generative capacity, whereas adding substitution to SL-TAG makes it weakly equivalent to ESL-TAG. Thus these four for*This research was primarily carried out while the author was at the University of Pennsylvania. malisms converge to the same weak-equivalence class, the intuition being that the “hardest” operation in TAG, namely, adjunction of a wrapping auxiliary tree in the middle of t</context>
</contexts>
<marker>Joshi, 1985</marker>
<rawString>Aravind K. Joshi. 1985. Tree adjoining grammars: How much context-sensitivity is necessary for assigning structural descriptions? In David Dowty, Lauri Karttunen, and Arnold Zwicky, editors, Natural Language Parsing, pages 206–250. Cambridge University Press, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuki Kato</author>
<author>Hiroyuki Seki</author>
<author>Tadao Kasami</author>
</authors>
<title>Subclasses of tree adjoining grammar for RNA secondary structure.</title>
<date>2004</date>
<booktitle>In Proc. Seventh International Workshop on TAG and Related Formalisms (TAG+),</booktitle>
<pages>48--55</pages>
<contexts>
<context position="1495" citStr="Kato et al. (2004)" startWordPosition="231" endWordPosition="234"> model even some very simple RNA secondary structures. Therefore they propose a more powerful version of linear TAGs, extended simple linear TAGs (ESL-TAGs), which generate a class of languages that include the context-free languages and can be recognized in O(n5) time. Satta and Schuler (1998), working within the application domain of natural language syntax, define another restriction on TAG which is also recognizable in O(n5) time. Despite being less powerful than full TAG, it is still able to generate languages like the copy language {ww} and Dutch cross-serial dependencies (Joshi, 1985). Kato et al. (2004) conjecture that this restricted TAG is in fact equivalent to ESL-TAG. In this paper we prove their conjecture, and also prove that adding substitution to ESL-TAG does not increase its weak generative capacity, whereas adding substitution to SL-TAG makes it weakly equivalent to ESL-TAG. Thus these four for*This research was primarily carried out while the author was at the University of Pennsylvania. malisms converge to the same weak-equivalence class, the intuition being that the “hardest” operation in TAG, namely, adjunction of a wrapping auxiliary tree in the middle of the spine of another </context>
<context position="6167" citStr="Kato et al. 2004" startWordPosition="1032" endWordPosition="1035">ne active node elsewhere. 3 Properties We now review several old results and prove a few new results relating the weak generative capacity of these formalisms to one another and to (linear) CFG and TAG. These results are summarized in Figure 1. 3.1 Previous results Proposition 1 (Uemura et al. 1999). Linear CFL C SL-TAL TAL SSL-TAL = ESL-TAL = (E)SL-TAL + subst SL-TAL U CFL SL-TAL CFL Linear CFL Figure 1: Summary of results: an edge indicates that the higher formalism has strictly greater weak generative capacity than the lower. Proposition 2 (Uemura et al. 1999). CFL C ESL-TAL Proposition 3 (Kato et al. 2004). CFL U SL-TAL C ESL-TAL Proposition 4 (Satta and Schuler 1998; Uemura et al. 1999). SSL-TAG and ESL-TAG can be parsed in O(n5) time. 3.2 Weak equivalence Proposition 5. The following formalisms are weakly equivalent: (i) ESL-TAG (ii) SL-TAG with substitution (iii) ESL-TAG with substitution (iv) SSL-TAG Proof. We prove this by proving four inclusions. G(ESL-TAG) C_ G(ESL-TAG+ substitution): Trivial. G(ESL-TAG+substitution) C_ G(SSL-TAG): Trivial. G(SSL-TAG) C_ G(SL-TAG + substitution): We deal first with the left and right auxiliary trees, and then with off-spine adjunction. First, we eliminat</context>
</contexts>
<marker>Kato, Seki, Kasami, 2004</marker>
<rawString>Yuki Kato, Hiroyuki Seki, and Tadao Kasami. 2004. Subclasses of tree adjoining grammar for RNA secondary structure. In Proc. Seventh International Workshop on TAG and Related Formalisms (TAG+), pages 48–55.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernard Lang</author>
</authors>
<title>Recognition can be harder than parsing.</title>
<date>1994</date>
<journal>Computational Intelligence,</journal>
<volume>10</volume>
<issue>4</issue>
<pages>494</pages>
<note>Special Issue on Tree Adjoining Grammars.</note>
<contexts>
<context position="10618" citStr="Lang, 1994" startWordPosition="1841" endWordPosition="1842">q, we revisit each q, and for every wrapping Q that could adjoin at q, create a copy of Q with root relabeled to Tˆη and foot relabeled to Bˆη. Then the original Q is discarded. Substituting one of these copies of Q at a Tˆη node and then substituting a Bˆη tree at the former foot node has the same effect as adjoining Q at q. Finally, unless q had an obligatory-adjunction constraint, simulate the lack of adjunction at q by adding the initial tree Tˆη BˆηJ L(SL-TAG + substitution) C_ L(ESL-TAG): This construction is related to Lang’s normal form which ensures binary-branching derivation trees (Lang, 1994), but guarantees that one adjunction site is on the spine and one is off the spine. (Step 0a) Ensure that the elementary trees are binary-branching. (Step 0b) Add a new root and foot node to every elementary tree: XNA � X XNA If Y has another child, call it Z2; let V2 be a fresh nonterminal symbol and insert a V2 node above Z2, and break off the subtree rooted in V2, leaving behind a substitution node. See Figure 3. This transformation reduces the spine of the auxiliary tree by one node, and creates two new trees that satisfy the desired form. We repeat this until the entire grammar is in the </context>
</contexts>
<marker>Lang, 1994</marker>
<rawString>Bernard Lang. 1994. Recognition can be harder than parsing. Computational Intelligence, 10(4):484– 494. Special Issue on Tree Adjoining Grammars.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Owen Rambow</author>
<author>Giorgio Satta</author>
</authors>
<title>Independent parallelism in finite copying parallel rewriting systems.</title>
<date>1999</date>
<journal>Theoretical Computer Science,</journal>
<pages>223--87</pages>
<contexts>
<context position="20991" citStr="Rambow and Satta (1999)" startWordPosition="3902" endWordPosition="3905">by marking the b1s: Condition 2 is impossible because it would give unequal numbers of b1s and b2s; Condition 1 is impossible because it would give unequal numbers of b1s and b3s. On the other hand, if z2 contains all the cjs, we mark the c1s, and both Conditions are again rendered impossible. 4 Conclusion The weak equivalence of the previously proposed ESL-TAG and SSL-TAG, along with the fact that SL-TAG with substitution and ESL-TAG with substitution belong to the same class, suggests that they represent a useful compromise between CFGs and TAGs. In the two-dimensional language hierarchy of Rambow and Satta (1999), where the two dimensions are rank (how many substructures does a rule combine) and fanout (how many discontinuous spans of the input does a substructure cover), CFGs comprise the fanout-1 grammars and TAGs are a subset of the the fanout-2 grammars; both have arbitrary rank, whereas linear CFGs and linear TAGs are rank-1. The grammars discussed here are mixed: a rule can combine one fanout-2 substructure and an arbitrary number of fanout-1 substructures. A related example would be a version of synchronous CFG that allows only one pair of linked nonterminals and any number of unlinked nontermi</context>
</contexts>
<marker>Rambow, Satta, 1999</marker>
<rawString>Owen Rambow and Giorgio Satta. 1999. Independent parallelism in finite copying parallel rewriting systems. Theoretical Computer Science, 223:87–120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Rogers</author>
</authors>
<title>Capturing CFLs with tree adjoining grammars.</title>
<date>1994</date>
<booktitle>In Proc. 32nd Annual Meeting of the ACL,</booktitle>
<pages>155--162</pages>
<contexts>
<context position="3615" citStr="Rogers, 1994" startWordPosition="602" endWordPosition="603">uding η itself. The segment of a tree from η1 to η2 (where η1 dominates η2) is the set of all nodes in the subtree of η1 but not in the subtree of η2. A segment can be excised, which means removing the nodes of the segment and making η2 replace η1 as the child of its parent. We also assume a standard definition of TAG derivation trees. We use the symbols h, h1, h2, etc. to range over nodes of derivation trees. The sub&apos;Adjunction at root and foot nodes is another operation that by itself will not take a formalism beyond context-free power, a fact which is exploited in Rogers’ regular-form TAG (Rogers, 1994). But allowing this in a linear TAG would circumvent the linearity constraint. 25 Proceedings of the 8th International Workshop on Tree Adjoining Grammar and Related Formalisms, pages 25–32, Sydney, July 2006. c�2006 Association for Computational Linguistics derivation of h is the subtree of h in the derivation tree. When we cut up derivations into subderivations or segments and recombine them, the edge labels (indicating addresses of adjunctions and substitutions) stay with the node above, not the node below. Now we define various versions of linear TAG. Definition 1. A right (left) auxiliary</context>
</contexts>
<marker>Rogers, 1994</marker>
<rawString>James Rogers. 1994. Capturing CFLs with tree adjoining grammars. In Proc. 32nd Annual Meeting of the ACL, pages 155–162.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Giorgio Satta</author>
<author>William Schuler</author>
</authors>
<title>Restrictions on tree adjoining languages. In</title>
<date>1998</date>
<booktitle>Proc. COLINGACL,</booktitle>
<pages>1176--1182</pages>
<contexts>
<context position="1172" citStr="Satta and Schuler (1998)" startWordPosition="177" endWordPosition="180">s of languages incommensurate with the context-free languages, and can be recognized in O(n4) time. Working within the application domain of modeling of RNA secondary structures, they find that SL-TAGs are too restrictive—they can model RNA pseudoknots but because they cannot generate all the context-free languages, they cannot model even some very simple RNA secondary structures. Therefore they propose a more powerful version of linear TAGs, extended simple linear TAGs (ESL-TAGs), which generate a class of languages that include the context-free languages and can be recognized in O(n5) time. Satta and Schuler (1998), working within the application domain of natural language syntax, define another restriction on TAG which is also recognizable in O(n5) time. Despite being less powerful than full TAG, it is still able to generate languages like the copy language {ww} and Dutch cross-serial dependencies (Joshi, 1985). Kato et al. (2004) conjecture that this restricted TAG is in fact equivalent to ESL-TAG. In this paper we prove their conjecture, and also prove that adding substitution to ESL-TAG does not increase its weak generative capacity, whereas adding substitution to SL-TAG makes it weakly equivalent t</context>
<context position="6229" citStr="Satta and Schuler 1998" startWordPosition="1043" endWordPosition="1046">ral old results and prove a few new results relating the weak generative capacity of these formalisms to one another and to (linear) CFG and TAG. These results are summarized in Figure 1. 3.1 Previous results Proposition 1 (Uemura et al. 1999). Linear CFL C SL-TAL TAL SSL-TAL = ESL-TAL = (E)SL-TAL + subst SL-TAL U CFL SL-TAL CFL Linear CFL Figure 1: Summary of results: an edge indicates that the higher formalism has strictly greater weak generative capacity than the lower. Proposition 2 (Uemura et al. 1999). CFL C ESL-TAL Proposition 3 (Kato et al. 2004). CFL U SL-TAL C ESL-TAL Proposition 4 (Satta and Schuler 1998; Uemura et al. 1999). SSL-TAG and ESL-TAG can be parsed in O(n5) time. 3.2 Weak equivalence Proposition 5. The following formalisms are weakly equivalent: (i) ESL-TAG (ii) SL-TAG with substitution (iii) ESL-TAG with substitution (iv) SSL-TAG Proof. We prove this by proving four inclusions. G(ESL-TAG) C_ G(ESL-TAG+ substitution): Trivial. G(ESL-TAG+substitution) C_ G(SSL-TAG): Trivial. G(SSL-TAG) C_ G(SL-TAG + substitution): We deal first with the left and right auxiliary trees, and then with off-spine adjunction. First, we eliminate the left and right auxiliary trees. Since these only insert </context>
</contexts>
<marker>Satta, Schuler, 1998</marker>
<rawString>Giorgio Satta and William Schuler. 1998. Restrictions on tree adjoining languages. In Proc. COLINGACL, pages 1176–1182.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yves Schabes</author>
<author>Richard C Waters</author>
</authors>
<title>Tree insertion grammar: a cubic-time parsable formalism that lexicalizes context-free grammar without changing the trees produced.</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<pages>21--479</pages>
<contexts>
<context position="7007" citStr="Schabes and Waters, 1995" startWordPosition="1159" endWordPosition="1162">t: (i) ESL-TAG (ii) SL-TAG with substitution (iii) ESL-TAG with substitution (iv) SSL-TAG Proof. We prove this by proving four inclusions. G(ESL-TAG) C_ G(ESL-TAG+ substitution): Trivial. G(ESL-TAG+substitution) C_ G(SSL-TAG): Trivial. G(SSL-TAG) C_ G(SL-TAG + substitution): We deal first with the left and right auxiliary trees, and then with off-spine adjunction. First, we eliminate the left and right auxiliary trees. Since these only insert material to the left or right of a node, just as in tree-insertion grammars (TIGs), we may apply the conversion from TIGs to tree-substitution grammars (Schabes and Waters, 1995), used in the proof of the context-freeness of 26 ... XNA ... XNA ... X ⇒ ... X XNA RX↓ LX↓ XNA RX↓ ... ... ... XNA LX↓ XNA (Step 1a) ... ... ... (Step 1b) X X∗ Y ⇒ RX Y RX↓ RX Y LX LX↓ Y X LX Y Y X∗ ⇒ Figure 2: Elimination of left/right auxiliary trees. TIG.2 (Step 1a) For each active node X that is not the root of a left or right auxiliary tree, we create four copies of the containing elementary tree with X altered in the following ways: first, leave X unchanged; then, add a copy of X above it, making both nodes no-adjunction nodes, and add a new left sister substitution node labeled LX or a</context>
<context position="8613" citStr="Schabes and Waters, 1995" startWordPosition="1469" endWordPosition="1472">fied β substitutes at one of the new children of an η, the substitution clearly results in the same string that would have resulted from adjoining the original β to η. This construction might appear incorrect in two ways. First, the new grammar has trees with both an LX and an RX node corresponding to the same original node, which would correspond to adjunction of two auxiliary trees βL and βR at the same node X in the original grammar. But this new derivation generates a string that was generable in the original grammar, namely by adjoining βL at 2This corresponds to Steps 1–4 of that proof (Schabes and Waters, 1995, p. 486). Since that proof uses a more relaxed definition of left and right auxiliary trees, it is probable that SSL-TAG could also be relaxed in the same way. X, then adjoining βR at the root of βL, which is allowed because the definition of SSL-TAG prohibits adjunction constraints at the root of βL. Thus the first apparent problem is really the solution to the second problem: in the original grammar, a left auxiliary tree βL could adjoin at the root of a right auxiliary tree βR, which in turn adjoined at a node η, whereas in the new grammar, βR does not have an LX substitution node to allow</context>
</contexts>
<marker>Schabes, Waters, 1995</marker>
<rawString>Yves Schabes and Richard C. Waters. 1995. Tree insertion grammar: a cubic-time parsable formalism that lexicalizes context-free grammar without changing the trees produced. Computational Linguistics, 21:479–513.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yves Schabes</author>
</authors>
<title>Mathematical and Computational Aspects ofLexicalized Grammars.</title>
<date>1990</date>
<tech>Ph.D. thesis,</tech>
<pages>90--48</pages>
<institution>University of Pennsylvania.</institution>
<note>Available as technical report</note>
<contexts>
<context position="11936" citStr="Schabes, 1990" startWordPosition="2086" endWordPosition="2087">tion node, while maintaining the form acquired in step 1. For any initial tree with height greater than three nodes, we apply the same transformation as in step 1, except that Y is the child of the root node, Z1 is its left child, and Z2 is its other child if it exists and is not already a substitution node. See Figure 3. This transformation replaces an initial tree with at most two shorter initial trees, and one auxiliary tree in the desired form. Again we repeat this until the entire grammar is in the desired form. (Step 3) Finally, we convert each substitution node into an adjunction node (Schabes, 1990). For each substitution node q, let X be the label of q. Relabel q to SX with obligatory adjunction and place an empty terminal beneath q. ... ... � SXOA XJ E For each initial tree with root label X, convert it into an auxiliary tree by adding a new root node labeled SX whose children are the old root node and a new foot node. � X X* Tˆη BˆηJ X SXNA � X SX* X � X X* X XNA X* (Step 1) We transform the grammar so that no auxiliary tree has more than one substitution node. For any auxiliary tree with spine longer than four nodes, we apply the following transformation: target either the active nod</context>
</contexts>
<marker>Schabes, 1990</marker>
<rawString>Yves Schabes. 1990. Mathematical and Computational Aspects ofLexicalized Grammars. Ph.D. thesis, University of Pennsylvania. Available as technical report MS-CIS-90-48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yasuo Uemura</author>
<author>Aki Hasegawa</author>
<author>Satoshi Kobayashi</author>
<author>Takashi Yokomori</author>
</authors>
<title>Tree adjoining grammars for RNA structure prediction.</title>
<date>1999</date>
<journal>Theoretical Computer Science,</journal>
<pages>210--277</pages>
<contexts>
<context position="5850" citStr="Uemura et al. 1999" startWordPosition="977" endWordPosition="980">o active nodes elsewhere. Definition 5. An extended simple linear treeadjoining grammar (ESL-TAG), with or without substitution, is a TAG, with or without substitution, respectively, in which every initial tree has exactly one active node, and every auxiliary tree has exactly one active node on its spine and at most one active node elsewhere. 3 Properties We now review several old results and prove a few new results relating the weak generative capacity of these formalisms to one another and to (linear) CFG and TAG. These results are summarized in Figure 1. 3.1 Previous results Proposition 1 (Uemura et al. 1999). Linear CFL C SL-TAL TAL SSL-TAL = ESL-TAL = (E)SL-TAL + subst SL-TAL U CFL SL-TAL CFL Linear CFL Figure 1: Summary of results: an edge indicates that the higher formalism has strictly greater weak generative capacity than the lower. Proposition 2 (Uemura et al. 1999). CFL C ESL-TAL Proposition 3 (Kato et al. 2004). CFL U SL-TAL C ESL-TAL Proposition 4 (Satta and Schuler 1998; Uemura et al. 1999). SSL-TAG and ESL-TAG can be parsed in O(n5) time. 3.2 Weak equivalence Proposition 5. The following formalisms are weakly equivalent: (i) ESL-TAG (ii) SL-TAG with substitution (iii) ESL-TAG with subs</context>
<context position="14865" citStr="Uemura et al. (1999)" startWordPosition="2669" endWordPosition="2672">decomposition in w; for example, if w is a marked string, we may say that a symbol in wi is marked, or if w is generated by a TAG derivation, we may say that wi is generated by some set of nodes in the derivation tree. The second half of the proof requires a doubledecker pumping lemma. Condition 1 (cf. Vijay-Shanker (1987), Theorem 4.7). Given a language L and a decomposed string x1zx2 E L with some symbols in z marked, there exists a decomposition of z into u1v1w1v2u2v3w2v4u3 such that one of the vi contains a mark, and L contains, for all k &gt; 1, x1(u1vk1w1vk2u2vk3w2vk4u3)x2 Condition 2 (cf. Uemura et al. (1999), Lemma YNA ZNA XNA a1 X a2 X* a3 a4 XNA Y Z X* b1 Y b2 Y* b3 b4 c1 Z c2 Z* c3 c4 29 1). Given a language L and a decomposed string x1z1z2x2z3z4x3 E L with some symbols in one of the zi marked, there exist decompositions of the zi into uiviwi such that one of the vi contains a mark, and L contains, for all k &gt; 1, x1(u1vk1w1)(u2vk2w2)x2(u3vk3w3)(u4vk4w4)x3 Lemma 7. If L is an ESL-TAL, then there exists a constant n such that for any z E L with n symbols marked, Condition 1 holds of E · z · E. Moreover, it holds such that the w1 and w2 it provides can be further decomposed into z1z2 and z3z4, re</context>
</contexts>
<marker>Uemura, Hasegawa, Kobayashi, Yokomori, 1999</marker>
<rawString>Yasuo Uemura, Aki Hasegawa, Satoshi Kobayashi, and Takashi Yokomori. 1999. Tree adjoining grammars for RNA structure prediction. Theoretical Computer Science, 210:277–303.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Vijayashanker</author>
</authors>
<title>A study of tree adjoining grammars.</title>
<date>1987</date>
<tech>Ph.D. thesis,</tech>
<pages>88--03</pages>
<institution>University of Pennsylvania.</institution>
<note>Available as technical report</note>
<marker>Vijayashanker, 1987</marker>
<rawString>K Vijayashanker. 1987. A study of tree adjoining grammars. Ph.D. thesis, University of Pennsylvania. Available as technical report MS-CIS-88-03.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
</authors>
<title>Stochastic inversion transduction grammars and bilingual parsing of parallel corpora.</title>
<date>1997</date>
<journal>Computational Linguistics,</journal>
<pages>23--377</pages>
<marker>Wu, 1997</marker>
<rawString>Dekai Wu. 1997. Stochastic inversion transduction grammars and bilingual parsing of parallel corpora. Computational Linguistics, 23:377–404.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>