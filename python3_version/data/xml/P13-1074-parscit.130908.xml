<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000009">
<title confidence="0.998367">
Punctuation Prediction with Transition-based Parsing
</title>
<author confidence="0.999597">
Dongdong Zhang1, Shuangzhi Wu2, Nan Yang3, Mu Li1
</author>
<affiliation confidence="0.988908666666667">
1Microsoft Research Asia, Beijing, China
2Harbin Institute of Technology, Harbin, China
3University of Science and Technology of China, Hefei, China
</affiliation>
<email confidence="0.997286">
{dozhang,v-shuawu,v-nayang,muli}@microsoft.com
</email>
<sectionHeader confidence="0.994756" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999375882352941">
Punctuations are not available in automatic
speech recognition outputs, which could cre-
ate barriers to many subsequent text pro-
cessing tasks. This paper proposes a novel
method to predict punctuation symbols for the
stream of words in transcribed speech texts.
Our method jointly performs parsing and
punctuation prediction by integrating a rich set
of syntactic features when processing words
from left to right. It can exploit a global view
to capture long-range dependencies for punc-
tuation prediction with linear complexity. The
experimental results on the test data sets of
IWSLT and TDT4 show that our method can
achieve high-level performance in punctuation
prediction over the stream of words in tran-
scribed speech text.
</bodyText>
<sectionHeader confidence="0.998786" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999960318181818">
Standard automatic speech recognizers output un-
structured streams of words. They neither perform
a proper segmentation of the output into sentences,
nor predict punctuation symbols. The unavailable
punctuations and sentence boundaries in tran-
scribed speech texts create barriers to many sub-
sequent processing tasks, such as summarization,
information extraction, question answering and
machine translation. Thus, the segmentation of
long texts is necessary in many real applications.
For example, in speech-to-speech translation,
continuously transcribed speech texts need to be
segmented before being fed into subsequent ma-
chine translation systems (Takezawa et al., 1998;
Nakamura, 2009). This is because current ma-
chine translation (MT) systems perform the trans-
lation at the sentence level, where various models
used in MT are trained over segmented sentences
and many algorithms inside MT have an exponen-
tial complexity with regard to the length of inputs.
The punctuation prediction problem has at-
tracted research interest in both the speech pro-
cessing community and the natural language pro-
cessing community. Most previous work primar-
ily exploits local features in their statistical mod-
els such as lexicons, prosodic cues and hidden
event language model (HELM) (Liu et al., 2005;
Matusov et al., 2006; Huang and Zweig, 2002;
Stolcke and Shriberg, 1996). The word-level mod-
els integrating local features have narrow views
about the input and could not achieve satisfied
performance due to the limited context infor-
mation access (Favre et al., 2008). Naturally,
global contexts are required to model the punctu-
ation prediction, especially for long-range de-
pendencies. For instance, in English question sen-
tences, the ending question mark is long-range de-
pendent on the initial phrases (Lu and Ng, 2010),
such as “could you” in Figure 1. There has been
some work trying to incorporate syntactic features
to broaden the view of hypotheses in the punctua-
tion prediction models (Roark et al., 2006; Favre
et al., 2008). In their methods, the punctuation
prediction is treated as a separated post-procedure
of parsing, which may suffer from the problem of
error propagation. In addition, these approaches
are not able to incrementally process inputs and
are not efficient for very long inputs, especially in
the cases of long transcribed speech texts from
presentations where the number of streaming
words could be larger than hundreds or thousands.
In this paper, we propose jointly performing
punctuation prediction and transition-based de-
pendency parsing over transcribed speech text.
When the transition-based parsing consumes the
stream of words left to right with the shift-reduce
decoding algorithm, punctuation symbols are pre-
dicted for each word based on the contexts of the
parsing tree. Two models are proposed to cause
the punctuation prediction to interact with the
transition actions in parsing. One is to conduct
transition actions of parsing followed by punctua-
tion predictions in a cascaded way. The other is to
associate the conventional transition actions of
parsing with punctuation perditions, so that pre-
dicted punctuations are directly inferred from the
</bodyText>
<page confidence="0.990935">
752
</page>
<figure confidence="0.961036666666667">
anyway you may find your favorite if you go through the menu so could you tell me your choice
(a). The transcribed speech text without punctuations
advcl
(b). Transition-based parsing trees and predicted punctuations over transcribed text
anyway, you may find your favorite if you go through the menu. so, could you tell me your choice?
(c). Two segmentations are formed when inserting the predicted punctuation symbols into the transcribed text
</figure>
<figureCaption confidence="0.982758">
Figure 1. An example of punctuation prediction.
</figureCaption>
<figure confidence="0.954511">
mark pobj
advmod dobj
advmod
dobj
nsubj
aux
poss
aux
nsubj prep det nsubj iobj poss
anyway you may find your favorite if you go through the menu so could you tell me your choice
, N N N N N N N N N N . , N N N N N ?
</figure>
<bodyText confidence="0.993757794871795">
parsing tree. Our models have linear complexity
and are capable of handling streams of words with
any length. In addition, the computation of models
use a rich set of syntactic features, which can im-
prove the complicated punctuation predictions
from a global view, especially for the long range
dependencies.
Figure 1 shows an example of how parsing
helps punctuation prediction over the transcribed
speech text. As illustrated in Figure 1(b), two
commas are predicted when their preceding words
act as the adverbial modifiers (advmod) during
parsing. The period after the word “menu” is pre-
dicted when the parsing of an adverbial clause
modifier (advcl) is completed. The question mark
at the end of the input is determined when a direct
object modifier (dobj) is identified, together with
the long range clue that the auxiliary word occurs
before the nominal subject (nsubj). Eventually,
two segmentations are formed according to the
punctuation prediction results, shown in Figure
1(c).
The training data used for our models is adapted
from Treebank data by excluding all punctuations
but keeping the punctuation contexts, so that it can
simulate the unavailable annotated transcribed
speech texts. In decoding, beam search is used to
get optimal punctuation prediction results. We
conduct experiments on both IWSLT data and
TDT4 test data sets. The experimental results
show that our method can achieve higher perfor-
mance than the CRF-based baseline method.
The paper is structured as follows: Section 2
conducts a survey of related work. The transition-
based dependency parsing is introduced in Section
3. We explain our approach to predicting punctu-
ations for transcribed speech texts in Section 4.
Section 5 gives the results of our experiment. The
conclusion and future work are given in Section 6.
</bodyText>
<sectionHeader confidence="0.999716" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999815481481482">
Sentence boundary detection and punctuation pre-
diction have been extensively studied in the
speech processing field and have attracted re-
search interest in the natural language processing
field as well. Most previous work exploits local
features for the task. Kim and Woodland (2001),
Huang and Zweig (2002), Christensen et al.
(2001), and Liu et al. (2005) integrate both pro-
sodic features (pitch, pause duration, etc.) and lex-
ical features (words, n-grams, etc.) to predict
punctuation symbols during speech recognition,
where Huang and Zweig (2002) uses a maximum
entropy model, Christensen et al. (2001) focus on
finite state and multi-layer perceptron methods,
and Liu et al. (2005) uses conditional random
fields. However, in some scenarios the prosodic
cues are not available due to inaccessible original
raw speech waveforms. Matusov et al. (2006) in-
tegrate segmentation features into the log-linear
model in the statistical machine translation (SMT)
framework to improve the translation perfor-
mance when translating transcribed speech texts.
Lu and Ng (2010) uses dynamic conditional ran-
dom fields to perform both sentence boundary and
sentence type prediction. They achieved promis-
ing results on both English and Chinese tran-
scribed speech texts. The above work only ex-
</bodyText>
<page confidence="0.998064">
753
</page>
<bodyText confidence="0.99985736">
ploits local features, so they were limited to cap-
turing long range dependencies for punctuation
prediction.
It is natural to incorporate global knowledge,
such as syntactic information, to improve punctu-
ation prediction performance. Roark et al. (2006)
use a rich set of non-local features including par-
ser scores to re-rank full segmentations. Favre et
al. (2008) integrate syntactic information from a
PCFG parser into a log-linear and combine it with
local features for sentence segmentation. The
punctuation prediction in these works is per-
formed as a post-procedure step of parsing, where
a parse tree needs to be built in advance. As their
parsing over the stream of words in transcribed
speech text is exponentially complex, their ap-
proaches are only feasible for short input pro-
cessing. Unlike these works, we incorporate punc-
tuation prediction into the parsing which process
left to right input without length limitations.
Numerous dependency parsing algorithms
have been proposed in the natural language pro-
cessing community, including transition-based
and graph-based dependency parsing. Compared
to graph-based parsing, transition-based parsing
can offer linear time complexity and easily lever-
age non-local features in the models (Yamada and
Matsumoto, 2003; Nivre et al., 2006b; Zhang and
Clark, 2008; Huang and Sagae, 2010). Starting
with the work from (Zhang and Nivre, 2011), in
this paper we extend transition-based dependency
parsing from the sentence-level to the stream of
words and integrate the parsing with punctuation
prediction.
Joint POS tagging and transition-based de-
pendency parsing are studied in (Hatori et al.,
2011; Bohnet and Nivre, 2012). The improve-
ments are reported with the joint model compared
to the pipeline model for Chinese and other richly
inflected languages, which shows that it also
makes sense to jointly perform punctuation pre-
diction and parsing, although these two tasks of
POS tagging and punctuation prediction are dif-
ferent in two ways: 1). The former usually works
on a well-formed single sentence while the latter
needs to process multiple sentences that are very
lengthy. 2). POS tags are must-have features to
parsing while punctuations are not. The parsing
quality in the former is more sensitive to the per-
formance of the entire task than in the latter.
</bodyText>
<sectionHeader confidence="0.861182" genericHeader="method">
3 Transition-based dependency parsing
</sectionHeader>
<bodyText confidence="0.997831916666667">
In a typical transition-based dependency parsing
process, the shift-reduce decoding algorithm is
applied and a queue and stack are maintained
(Zhang and Nivre, 2011). The queue stores the
stream of transcribed speech words, the front of
which is indexed as the current word. The stack
stores the unfinished words which may be linked
with the current word or a future word in the
queue. When words in the queue are consumed
from left to right, a set of transition actions is ap-
plied to build a parse tree. There are four kinds of
transition actions conducted in the parsing process
(Zhang and Nivre, 2011), as described in Table 1.
Action Description
Shift Fetches the current word from the
queue and pushes it to the stack
Reduce Pops the stack
LeftArc Adds a dependency link from the cur-
rent word to the stack top, and pops the
stack
RightArc Adds a dependency link from the stack
top to the current word, takes away the
current word from the queue and
pushes it to the stack
</bodyText>
<tableCaption confidence="0.970714">
Table 1. Action types in transition-based parsing
</tableCaption>
<bodyText confidence="0.999985888888889">
The choice of each transition action during the
parsing is scored by a linear model that can be
trained over a rich set of non-local features ex-
tracted from the contexts of the stack, the queue
and the set of dependency labels. As described in
(Zhang and Nivre, 2011), the feature templates
could be defined over the lexicons, POS-tags and
the combinations with syntactic information.
In parsing, beam search is performed to search
the optimal sequence of transition actions, from
which a parse tree is formed (Zhang and Clark,
2008). As each word must be pushed to the stack
once and popped off once, the number of actions
needed to parse a sentence is always 2n, where n
is the length of the sentence. Thus, transition-
based parsing has a linear complexity with the
length of input and naturally it can be extended to
process the stream of words.
</bodyText>
<sectionHeader confidence="0.984611" genericHeader="method">
4 Our method
</sectionHeader>
<subsectionHeader confidence="0.859255">
4.1 Model
</subsectionHeader>
<bodyText confidence="0.999702857142857">
In the task of punctuation prediction, we are given
a stream of words from an automatic transcription
of speech text, denoted by 𝑤1𝑛 : = 𝑤1, 𝑤2,... , 𝑤𝑛.
We are asked to output a sequence of punctuation
symbols 𝑆1𝑛: = 𝑠1, 𝑠2, ... , 𝑠𝑛 where 𝑠𝑖 is attached
to 𝑤𝑖 to form a sentence like Figure 1(c). If there
are no ambiguities, 𝑆1 𝑛 is also abbreviated as 𝑆,
</bodyText>
<page confidence="0.992659">
754
</page>
<bodyText confidence="0.986374">
similarly for 𝑤1𝑛 as 𝑤. We model the search of the
best sequence of predicted punctuation symbols
𝑆∗ as:
</bodyText>
<equation confidence="0.934235">
𝑆∗ = argmaxS𝑃(𝑆1𝑛 |𝑤1𝑛) (1)
</equation>
<bodyText confidence="0.9999065">
We introduce the transition-based parsing tree
𝑇 to guide the punctuation prediction in Model (2),
where parsing trees are constructed over the tran-
scribed text while containing no punctuations.
</bodyText>
<equation confidence="0.997391">
𝑆∗ = argmax𝑆 ∑ 𝑃(𝑇|𝑤1 𝑛) × 𝑃(𝑆1 𝑛|𝑇, 𝑤1 𝑛) (2)
𝑇
</equation>
<bodyText confidence="0.99972575">
Rather than enumerate all possible parsing trees,
we jointly optimize the punctuation prediction
model and the transition-based parsing model
with the form:
</bodyText>
<equation confidence="0.976379666666667">
(𝑆∗,𝑇∗) = argmax(𝑆,𝑇)𝑃(𝑇|𝑤1𝑛) ×
𝑃(𝑆1 𝑛|𝑇,𝑤1𝑛) (3)
Let 𝑇1𝑖 be the constructed partial tree when 𝑤1𝑖
is consumed from the queue. We decompose the
Model (3) into:
(𝑆∗, 𝑇∗) =
argmax(𝑆,𝑇) ∏ 𝑃(𝑇1
𝑛 𝑖|𝑇1 𝑖−1, 𝑤1 𝑖) × 𝑃(𝑠𝑖|𝑇1 𝑖, 𝑤1 𝑖)
𝑖=1
</equation>
<bodyText confidence="0.999372">
It is noted that a partial parsing tree uniquely
corresponds to a sequence of transition actions,
and vice versa. Suppose 𝑇1𝑖 corresponds to the ac-
tion sequence 𝐴1𝑖 and let 𝑎𝑖 denote the last action
in 𝐴1𝑖. As the current word 𝑤𝑖 can only be con-
sumed from the queue by either Shift or RightArc
according to Table 1, we have 𝑎𝑖 ∈
{𝑆ℎ𝑖𝑓𝑡, 𝑅𝑖𝑔ℎ𝑡𝐴𝑟𝑐} . Thus, we synchronize the
punctuation prediction with the application of
Shift and RightArc during the parsing, which is ex-
plained by Model (5).
</bodyText>
<equation confidence="0.9377075">
𝑛
(𝑆∗, 𝑇∗) = argmax(𝑆,𝑇) ∏ 𝑃(𝑇1𝑖, 𝐴1 𝑖 |𝑇1 𝑖−1, 𝑤1 𝑖)
𝑖=1
× 𝑃(𝑠𝑖 |𝑎𝑖, 𝑇1𝑖, 𝑤1𝑖)
</equation>
<bodyText confidence="0.99941775">
The model is further refined by reducing the
computation scope. When a full-stop punctuation
is determined (i.e., a segmentation is formed), we
discard the previous contexts and restart a new
</bodyText>
<footnote confidence="0.4032555">
1 Specially, 𝑏𝑖 is equal to 1 if there are no previous full-stop
punctuations.
</footnote>
<bodyText confidence="0.9915999">
procedure for both parsing and punctuation pre-
diction over the rest of words in the stream. In this
way we are theoretically able to handle the unlim-
ited stream of words without needing to always
keep the entire context history of streaming words.
Let 𝑏𝑖 be the position index of last full-stop punc-
tuation1 before 𝑖, 𝑇𝑏𝑖 𝑖 and 𝐴𝑏𝑖
𝑖 the partial tree and
corresponding action sequence over the words
𝑤𝑏𝑖
</bodyText>
<equation confidence="0.957096272727273">
𝑖 , Model (5) can be rewritten by:
(𝑆∗, 𝑇∗) =
argmax(𝑆,𝑇) ∏ 𝑃(𝑇𝑏𝑖
𝑛 𝑖 , 𝐴𝑏𝑖
𝑖 |𝑇𝑏𝑖
𝑖−1, 𝑤𝑏𝑖
𝑖 ) ×
𝑖=1
𝑃(𝑠𝑖 |𝑎𝑖, 𝑇𝑏𝑖
𝑖 , 𝑤𝑏𝑖
𝑖 ) (6)
</equation>
<bodyText confidence="0.99968">
With different computation of Model (6), we
induce two joint models for punctuation predic-
tion: the cascaded punctuation prediction model
and the unified punctuation prediction model.
</bodyText>
<sectionHeader confidence="0.670246" genericHeader="method">
4.2 Cascaded punctuation prediction model
(CPP)
</sectionHeader>
<bodyText confidence="0.945681678571429">
In Model (6), the computation of two sub-models
is independent. The first sub-model is computed
based on the context of words and partial trees
without any punctuation knowledge, while the
computation of the second sub-model is condi-
tional on the context from the partially built pars-
ing tree 𝑇𝑏𝑖 𝑖 and the transition action. As the words
in the stream are consumed, each computation of
transition actions is followed by a computation of
punctuation prediction. Thus, the two sub-models
are computed in a cascaded way, until the optimal
parsing tree and optimal punctuation symbols are
generated. We call this model the cascaded punc-
tuation prediction model (CPP).
4.3 Unified punctuation prediction model
(UPP)
In Model (6), if the punctuation symbols can be
deterministically inferred from the partial tree,
𝑃 (𝑠𝑖 |𝑎𝑖, 𝑇𝑏𝑖
𝑖, 𝑤𝑏𝑖
𝑖 ) can be omitted because it is al-
ways 1. Similar to the idea of joint POS tagging
and parsing (Hatori et al., 2011; Bohnet and Nivre,
2012), we propose attaching the punctuation pre-
diction onto the parsing tree by embedding 𝑠𝑖 into
𝑎𝑖. Thus, we extend the conventional transition
actions illustrated in Table 1 to a new set of tran-
sition actions for the parsing, denoted by 𝐴̂ :
</bodyText>
<page confidence="0.937615">
755
</page>
<equation confidence="0.570291">
A� _ {LeftArc, Reduce) U {Shift(s)Is E Q)
U {RightArc(s)ls E Q)
</equation>
<bodyText confidence="0.999057875">
where Q is the set of punctuation symbols to be
predicted, s is a punctuation symbol belonging to
Q, Shift(s) is an action that attaches s to the current
word on the basis of original Shift action in pars-
ing, RightArc(s) attaches s to the current word on
the basis of original RightArc action.
With the redefined transition action set A , the
computation of Model (6) is reformulated as:
</bodyText>
<equation confidence="0.9903045">
(S*, T*) _
argmax(s,T) nn 1 P (Ttip, Abp I Tb 1,A bp 1, wbp) (7)
</equation>
<bodyText confidence="0.92125">
Here, the computation of parsing tree and punc-
tuation prediction is unified into one model where
the sequence of transition action outputs uniquely
determines the punctuations attached to the words.
We refer to it as the unified punctuation predic-
tion model (UPP).
(a). Parsing tree and attached punctuation symbols
</bodyText>
<keyword confidence="0.275726">
Shift(,), Shift(N), Shift(N), LeftArc, LeftArc, LeftArc,
Shift(N), RightArc(?), Reduce, Reduce
</keyword>
<figure confidence="0.575236">
(b). The corresponding sequence of transition actions
</figure>
<figureCaption confidence="0.893670625">
Figure 2. An example of punctuation prediction
using the UPP model, where N is a null type punc-
tuation symbol denoting no need to attach any
punctuation to the word.
Figure 2 illustrates an example how the UPP
model works. Given an input “so could you tell
me”, the optimal sequence of transition actions in
Figure 2(b) is calculated based on the UPP model
</figureCaption>
<bodyText confidence="0.973950714285714">
to produce the parsing tree in Figure 2(a). Accord-
ing to the sequence of actions, we can determine
the sequence of predicted punctuation symbols
like “,NNN?” that have been attached to the words
shown in Figure 2(a). The final segmentation with
the predicted punctuation insertion could be “so,
could you tell me?”.
</bodyText>
<subsectionHeader confidence="0.999665">
4.4 Model training and decoding
</subsectionHeader>
<bodyText confidence="0.992763666666667">
In practice, the sub-models in Model (6) and (7)
with the form of P (Y IX) is computed with a linear
model Score (Y, X) as
</bodyText>
<equation confidence="0.9682385">
I
Score (Y,X) _ 0(Y,X) -A
</equation>
<bodyText confidence="0.984425">
where 0 (Y, X) is the feature vector extracted
</bodyText>
<equation confidence="0.545329">
I
</equation>
<bodyText confidence="0.9996735">
from the output Y and the context X, and A is the
weight vector. For the features of the models, we
incorporate the bag of words and POS tags as well
as tree-based features shown in Table 2, which are
the same as those defined in (Zhang and Nivre,
2011).
</bodyText>
<equation confidence="0.999065222222222">
ws; w0; w1; w2; ps; p0; p1; p2; wsps; w0p0; w1p1;
w2p2; wspsw0p0; wspsw0; wspsp0; wsw0p0;
psw0p0; wsw0; psp0; p0p1; psp0p1; p0p1p2;
pshpsp0; pspslp0; pspsrp0; psp0p0l; wsd; psd; w0d;
p0d; wsw0d; psp0d; wsvl; psvl; wsvr; psvr; w0vl;
p0vl; wsh; psh; ts; w0l; p0l; t0l; w0r; p0r; t0r; w1l;
p1l; t1l; wsh2; psh2; tsh; wsl2; psl2; tsl2; wsr2; psr2;
tsr2; w0l2; p0l2; t0l2; pspslpsl2; pspsrpsr2; pspshpsh2;
p0p0lp0l2; wsTl; psTl; wsTr; psTr; w0Tl; p0Tl;
</equation>
<bodyText confidence="0.981669038461538">
Table 2. (a) Features of the bag of words and POS
tags. (b). Tree-based features. w—word; p—POS
tag; d—distance between ws and w0; v—number of
modifiers; t—dependency label; T—set of depend-
ency labels; s, 0, 1 and 2 index the stack top and
three front items in the queue respectively; h—head;
l—left/leftmost; r—right/rightmost; h2—head of a
head; l2—second leftmost; r2—second rightmost.
The training data for both the CPP and UPP
models need to contain parsing trees and punctu-
ation information. Due to the absence of annota-
tion over transcribed speech data, we adapt the
Treebank data for the purpose of model training.
To do this, we remove all types of syntactic infor-
mation related to punctuation symbols from the
raw Treebank data, but record what punctuation
symbols are attached to the words. We normalize
various punctuation symbols into two types: Mid-
dle-paused punctuation (M) and Full-stop punctu-
ation (F). Plus null type (N), there are three kinds
of punctuation symbols attached to the words. Ta-
ble 3 illustrates the normalizations of punctuation
symbols. In the experiments, we did not further
distinguish the type among full-stop punctuation
because the question mark and the exclamation
mark have very low frequency in Treebank data.
</bodyText>
<figure confidence="0.9712596">
advmod
aux
nsubj iobj
so could you tell me
, I I I ?
</figure>
<page confidence="0.996652">
756
</page>
<bodyText confidence="0.998431">
But our CPP and UPP models are both independ-
ent regarding the number of punctuation types to
be predicted.
</bodyText>
<table confidence="0.998729111111111">
Punctuations Normalization
Period, question mark, Full-stop punctuation
exclamation mark (F)
Comma, Colon, semi- Middle-paused punctu-
colon ation (M)
Multiple Punctuations Full-stop punctuation
(e.g., !!!!?) (F)
Quotations, brackets, Null (N)
etc.
</table>
<tableCaption confidence="0.74639">
Table 3. Punctuation normalization in training
data
</tableCaption>
<bodyText confidence="0.999760785714286">
As the feature templates are the same for the
model training of both CPP and UPP, the training
instances of CPP and UPP have the same contexts
but with different outputs. Similar to work in
(Zhang and Clark, 2008; Zhang and Nivre, 2011),
we train CPP and UPP by generalized perceptron
(Collins, 2002).
In decoding, beam search is performed to get
the optimal sequence of transition actions in CPP
and UPP, and the optimal punctuation symbols in
CPP. To ensure each segment decided by a full-
stop punctuation corresponds to a single parsing
tree, two constraints are applied in decoding for
the pruning of deficient search paths.
</bodyText>
<listItem confidence="0.9945755">
(1) Proceeding-constraint: If the partial pars-
ing result is not a single tree, the full-stop
punctuation prediction in CPP cannot be
performed. In UPP, if Shift(F) or
RightArc(F) fail to result in a single parsing
tree, they cannot be performed as well.
(2) Succeeding-constraint: If the full-stop
punctuation is predicted in CPP, or Shift(F)
and RightArc(F) are performed in UPP, the
following transition actions must be a se-
quence of Reduce actions until the stack
becomes empty.
</listItem>
<sectionHeader confidence="0.998924" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<subsectionHeader confidence="0.994398">
5.1 Experimental setup
</subsectionHeader>
<bodyText confidence="0.9999488">
Our training data of transition-based dependency
trees are converted from phrasal structure trees in
English Web Treebank (LDC2012T13) and the
English portion of OntoNotes 4.0 (LDC2011T03)
by the Stanford Conversion toolkit (Marneffe et
al., 2006). It contains around 1.5M words in total
and consist of various genres including weblogs,
web texts, newsgroups, email, reviews, question-
answer sessions, newswires, broadcast news and
broadcast conversations. To simulate the tran-
scribed speech text, all words in dependency trees
are lowercased and punctuations are excluded be-
fore model training. In addition, every ten depend-
ency trees are concatenated sequentially to simu-
late a parsing result of a stream of words in the
model training.
There are two test data sets used in our experi-
ments. One is the English corpus of the IWSLT09
evaluation campaign (Paul, 2009) that is the con-
versional speech text. The other is a subset of the
TDT4 English data (LDC2005T16) which con-
sists of 200 hours of closed-captioned broadcast
news.
In the decoding, the beam size of both the tran-
sition-based parsing and punctuation prediction is
set to 5. The part-of-speech tagger is our re-imple-
mentation of the work in (Collins, 2002).
The evaluation metrics of our experiments are
precision (prec.), recall (rec.) and F1-measure
(F1).
For the comparison, we also implement a base-
line method based on the CRF model. It incorpo-
rates the features of bag of words and POS tags
shown in Table 2(a), which are commonly used in
previous related work.
</bodyText>
<subsectionHeader confidence="0.998875">
5.2 Experimental results
</subsectionHeader>
<bodyText confidence="0.999984714285714">
We test the performance of our method on both
the correctly recognized texts and automatically
recognized texts. The former data is used to eval-
uate the capability of punctuation prediction of
our algorithm regardless of the noises from speech
data, as our model training data come from formal
text instead of transcribed speech data. The usage
of the latter test data set aims to evaluate the ef-
fectiveness of our method in real applications
where lots of substantial recognition errors could
be contained. In addition, we also evaluate the
quality of our transition-based parsing, as its per-
formance could have a big influence on the quality
of punctuation prediction.
</bodyText>
<subsectionHeader confidence="0.648771">
5.2.1 Performance on correctly recognized
text
</subsectionHeader>
<bodyText confidence="0.99982875">
The evaluation of our method on correctly recog-
nized text uses 10% of IWSLT09 training set,
which consists of 19,972 sentences from BTEC
(Basic Travel Expression Corpus) and 10,061 sen-
tences from CT (Challenge Task). The average in-
put length is about 10 words and each input con-
tains 1.3 sentences on average. The evaluation re-
sults are presented in Table 4.
</bodyText>
<page confidence="0.992577">
757
</page>
<table confidence="0.999759083333333">
Measure Middle- Full-stop Mixed
Paused
Baseline prec. 33.2% 81.5% 78.8%
(CRF)
rec. 25.9% 83.8% 80.7%
F1 29.1% 82.6% 79.8%
CPP prec. 51% 89% 89.6%
rec. 50.3% 93.1% 92.7%
F1 50.6% 91% 91.1%
UPP prec. 52.6% 93.2% 92%
rec. 59.7% 91.3% 92.3%
F1 55.9% 92.2% 92.2%
</table>
<tableCaption confidence="0.9772625">
Table 4. Punctuation prediction performance on
correctly recognized text
</tableCaption>
<bodyText confidence="0.999851884615384">
We achieved good performance on full-stop
punctuation compared to the baseline, which
shows our method can efficiently process sen-
tence segmentation because each segment is de-
cided by the structure of a single parsing tree. In
addition, the global syntactic knowledge used in
our work help capture long range dependencies of
punctuations. The performance of middle-paused
punctuation prediction is fairly low between all
methods, which shows predicting middle-paused
punctuations is a difficult task. This is because the
usage of middle-paused punctuations is very flex-
ible, especially in conversional data. The last col-
umn in Table 4 presents the performance of the
pure segmentation task where the middle-paused
and full-stop punctuations are mixed and not dis-
tinguished. The performance of our method is
much higher than that of the baseline, which
shows our method is good at segmentation. We
also note that UPP yields slightly better perfor-
mance than CPP on full-stop and mixed punctua-
tion prediction, and much better performance on
middle-paused punctuation prediction. This could
be because the interaction of parsing and punctu-
ation prediction is closer together in UPP than in
CPP.
</bodyText>
<subsectionHeader confidence="0.7013605">
5.2.2 Performance on automatically recog-
nized text
</subsectionHeader>
<bodyText confidence="0.999835916666667">
Table 5 shows the experimental results of punctu-
ation prediction on automatically recognized text
from TDT4 data that is recognized using SRI’s
English broadcast news ASR system where the
word error rate is estimated to be 18%. As the an-
notation of middle-paused punctuations in TDT4
is not available, we can only evaluate the perfor-
mance of full-stop punctuation prediction (i.e., de-
tecting sentence boundaries). Thus, we merge
every three sentences into one single input before
performing full-stop prediction. The average input
length is about 43 words.
</bodyText>
<table confidence="0.9990903">
Measure Full-stop
Baseline prec. 37.7%
(CRF) rec. 60.7%
F1 46.5%
prec. 63%
CPP rec. 58.6%
F1 60.2%
prec. 73.9%
UPP rec. 51.6%
F1 60.7%
</table>
<tableCaption confidence="0.957823">
Table 5. Punctuation prediction performance on
automatically recognized text
</tableCaption>
<bodyText confidence="0.972736085714286">
Generally, the performance shown in Table 5 is
not as high as that in Table 4. This is because the
speech recognition error from ASR systems de-
grades the capability of model prediction. Another
reason might be that the domain and style of our
training data mismatch those of TDT4 data. The
baseline gets a little higher recall than our method,
which shows the baseline method tends to make
aggressive segmentation decisions. However,
both precision and F1 score of our method are
much higher than the baseline. CPP has higher re-
call than UPP, but with lower precision and F1
score. This is in line with Table 4, which consist-
ently illustrates CPP can get higher recall on full-
stop punctuation prediction for both correctly rec-
ognized and automatically recognized texts.
5.2.3 Performance of transition-based pars-
ing
Performance of parsing affects the quality of
punctuation prediction in our work. In this section,
we separately evaluate the performance of our
transition-based parser over various domains in-
cluding the Wall Street Journal (WSJ), weblogs,
newsgroups, answers, email messages and re-
views. We divided annotated Treebank data into
three data sets: 90% for model training, 5% for the
development set and 5% for the test set. The accu-
racy of our POS-tagger achieves 96.71%. The
beam size in the decoding of both our POS-tag-
ging and parsing is set to 5. Table 6 presents the
results of our experiments on the measures of
UAS and LAS, where the overall accuracy is ob-
tained from a general model which is trained over
the combination of the training data from all do-
mains.
</bodyText>
<page confidence="0.993367">
758
</page>
<bodyText confidence="0.999833619047619">
We first evaluate the performance of our transi-
tion-based parsing over texts containing punctua-
tions (TCP). The evaluation results show that our
transition-based parser achieves state-of-the-art
performance levels, referring to the best depend-
ency parsing results reported in the shared task of
SANCL 2012 workshop2, although they cannot be
compared directly due to the different training
data and test data sets used in the experiments.
Secondly, we evaluate our parsing model in CPP
over the texts without punctuations (TOP). Sur-
prisingly, the performance over TOP is better than
that over TCP. The reason could be that we
cleaned out data noises caused by punctuations
when preparing TOP data. These results illustrate
that the performance of transition-based parsing in
our method does not degrade after being inte-
grated with punctuation prediction. As a by-prod-
uct of the punctuation prediction task, the outputs
of parsing trees can benefit the subsequent text
processing tasks.
</bodyText>
<table confidence="0.9998344">
Data sets UAS LAS
Texts con- WSJ 92.6% 90.3%
taining punc-
tuations
(TCP)
Weblogs 90.7% 88.2%
Answers 89.4% 85.7%
Newsgroups 90.1% 87.6%
Reviews 90.9% 88.4%
Email Messages 89.6% 87.1%
Overall 90.5% 88%
Texts with- WSJ 92.6% 91.1%
out punctua-
tions (TOP)
Weblogs 92.5% 91.1%
Answers 95% 94%
Newsgroups 92.6% 91.2%
Reviews 92.6% 91.2%
Email Messages 92.9% 91.7%
Overall 92.6% 91.2%
</table>
<tableCaption confidence="0.970198333333333">
Table 6. The performance of our transition-based
parser on written texts. UAS=unlabeled attach-
ment score; LAS=labeled attachment score
</tableCaption>
<sectionHeader confidence="0.993318" genericHeader="conclusions">
6 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999897857142857">
In this paper, we proposed a novel method for
punctuation prediction of transcribed speech texts.
Our approach jointly performs parsing and punc-
tuation prediction by integrating a rich set of syn-
tactic features. It can not only yield parse trees, but
also determine sentence boundaries and predict
punctuation symbols from a global view of the in-
</bodyText>
<footnote confidence="0.5212615">
2 https://sites.google.com/site/sancl2012/home/shared-
task/results
</footnote>
<bodyText confidence="0.999880111111111">
puts. The proposed algorithm has linear complex-
ity in the size of input, which can efficiently pro-
cess the stream of words from a purely text pro-
cessing perspective without the dependences on
either the ASR systems or subsequent tasks. The
experimental results show that our approach out-
performs the CRF-based method on both the cor-
rectly recognized and automatically recognized
texts. In addition, the performance of the parsing
over the stream of transcribed words is state-of-
the-art, which can benefit many subsequent text
processing tasks.
In future work, we will try our method on other
languages such as Chinese and Japanese, where
Treebank data is available. We would also like to
test the MT performance over transcribed speech
texts with punctuation symbols inserted based on
our method proposed in this paper.
</bodyText>
<sectionHeader confidence="0.999201" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999929111111111">
B. Bohnet and J. Nivre. 2012. A transition-based sys-
tem for joint part-of-speech tagging and labeled
non-projective dependency parsing. In Proc.
EMNLP-CoNLL 2012.
H. Christensen, Y. Gotoh, and S. Renals. 2001. Punc-
tuation annotation using statistical prosody models.
In Proc. of ISCA Workshop on Prosody in Speech
Recognition and Understanding.
M. Collins. 2002. Discriminative training methods for
hidden Markov models: Theory and experiments
with perceptron algorithms. In Proc. EMNLP’02,
pages 1-8.
B. Favre, R. Grishman, D. Hillard, H. Ji, D. Hakkani-
Tur, and M. Ostendorf. 2008. Punctuating speech
for information extraction. In Proc. of ICASSP’08.
B. Favre, D. HakkaniTur, S. Petrov and D. Klein. 2008.
Efficient sentence segmentation using syntactic fea-
tures. In Spoken Language Technologies (SLT).
A. Gravano, M. Jansche, and M. Bacchiani. 2009. Re-
storing punctuation and capitalization in transcribed
speech. In Proc. of ICASSP’09.
J. Hatori, T. Matsuzaki, Y. Miyao and J. Tsujii. 2011.
Incremental joint POS tagging and dependency
parsing in Chinese. In Proc. Of IJCNLP’11.
J. Huang and G. Zweig. 2002. Maximum entropy
model for punctuation annotation from speech. In
Proc. Of ICSLP’02.
</reference>
<page confidence="0.984852">
759
</page>
<reference confidence="0.999502826923077">
J.H. Kim and P.C. Woodland. 2001. The use of pros-
ody in a combined system for punctuation genera-
tion and speech recognition. In Proc. of Eu-
roSpeech’01.
Y. Liu, A. Stolcke, E. Shriberg, and M. Harper. 2005.
Using conditional random fields for sentence
boundary detection in speech. In Proc. of ACL’05.
W. Lu and H.T. Ng. 2010. Better Punctuation Predic-
tion with Dynamic Conditional Random Fields. In
Proc. Of EMNLP’10. Pages 177-186.
M. Marneffe, B. MacCartney, C.D. Maning. 2006.
Generating Typed Dependency Parses from Phrase
Structure Parses. In Proc. LREC’06.
E. Matusov, A. Mauser, and H. Ney. 2006. Automatic
sentence segmentation and punctuation prediction
for spoken language translation. In Proc. of
IWSLT’06.
S. Nakamura. 2009. Overcoming the language barrier
with speech translation technology. In Science &amp;
Technology Trends - Quarterly Review. No. 31.
April 2009.
J. Nivre. 2003. An efficient algorithm for projective de-
pendency parsing. In Proceedings of IWPT, pages
149–160, Nancy, France.
J. Nivre and M. Scholz. 2004. Deterministic depend-
ency parsing of English text. In Proc. COLING’04.
M. Paul. 2009. Overview of the IWSLT 2009 Evalua-
tion Campaign. In Proceedings of IWSLT’09.
B. Roark, Y. Liu, M. Harper, R. Stewart, M. Lease, M.
Snover, I. Shafran, B. Dorr, J. Hale, A. Krasnyan-
skaya, and L. Yung. 2006. Reranking for sentence
boundary detection in conversational speech. In
Proc. ICASSP, 2006.
A. Stolcke and E. Shriberg, “Automatic linguistic seg-
mentation of conversational speech,” Proc. ICSLP,
vol. 2, 1996.
A. Stolcke, E. Shriberg, R. Bates, M. Ostendorf, D.
Hakkani, M. Plauche, G. Tur, and Y. Lu. 1998. Au-
tomatic detection of sentence boundaries and disflu-
encies based on recognized words. In Proc. of
ICSLP’ 98.
Takezawa, T. Morimoto, T. Sagisaka, Y. Campbell, N.
Iida, H. Sugaya, F. Yokoo, A. Yamamoto, Seiichi.
1998. A Japanese-to-English speech translation sys-
tem: ATR-MATRIX. In Proc. ICSLP’98.
Y. Zhang and J. Nivre. 2011. Transition-based De-
pendency Parsing with Rich Non-local Features. In
Proc. of ACL’11, pages 188-193.
Y. Zhang and S. Clark. A Tale of Two Parsers: inves-
tigating and combing graph-based and transition-
based dependency parsing using beam-search. 2008.
In Proc. of EMNLP’08, pages 562-571.
</reference>
<page confidence="0.996414">
760
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.676611">
<title confidence="0.999956">Punctuation Prediction with Transition-based Parsing</title>
<author confidence="0.999737">Shuangzhi Nan Mu</author>
<affiliation confidence="0.877662333333333">Research Asia, Beijing, Institute of Technology, Harbin, China of Science and Technology of China, Hefei, China</affiliation>
<email confidence="0.99973">dozhang@microsoft.com</email>
<email confidence="0.99973">v-shuawu@microsoft.com</email>
<email confidence="0.99973">v-nayang@microsoft.com</email>
<email confidence="0.99973">muli@microsoft.com</email>
<abstract confidence="0.998058888888889">Punctuations are not available in automatic speech recognition outputs, which could create barriers to many subsequent text processing tasks. This paper proposes a novel method to predict punctuation symbols for the stream of words in transcribed speech texts. Our method jointly performs parsing and punctuation prediction by integrating a rich set of syntactic features when processing words from left to right. It can exploit a global view to capture long-range dependencies for punctuation prediction with linear complexity. The experimental results on the test data sets of IWSLT and TDT4 show that our method can achieve high-level performance in punctuation prediction over the stream of words in transcribed speech text.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>B Bohnet</author>
<author>J Nivre</author>
</authors>
<title>A transition-based system for joint part-of-speech tagging and labeled non-projective dependency parsing.</title>
<date>2012</date>
<booktitle>In Proc. EMNLP-CoNLL</booktitle>
<contexts>
<context position="9721" citStr="Bohnet and Nivre, 2012" startWordPosition="1501" endWordPosition="1504">sition-based and graph-based dependency parsing. Compared to graph-based parsing, transition-based parsing can offer linear time complexity and easily leverage non-local features in the models (Yamada and Matsumoto, 2003; Nivre et al., 2006b; Zhang and Clark, 2008; Huang and Sagae, 2010). Starting with the work from (Zhang and Nivre, 2011), in this paper we extend transition-based dependency parsing from the sentence-level to the stream of words and integrate the parsing with punctuation prediction. Joint POS tagging and transition-based dependency parsing are studied in (Hatori et al., 2011; Bohnet and Nivre, 2012). The improvements are reported with the joint model compared to the pipeline model for Chinese and other richly inflected languages, which shows that it also makes sense to jointly perform punctuation prediction and parsing, although these two tasks of POS tagging and punctuation prediction are different in two ways: 1). The former usually works on a well-formed single sentence while the latter needs to process multiple sentences that are very lengthy. 2). POS tags are must-have features to parsing while punctuations are not. The parsing quality in the former is more sensitive to the performa</context>
<context position="16013" citStr="Bohnet and Nivre, 2012" startWordPosition="2605" endWordPosition="2608">am are consumed, each computation of transition actions is followed by a computation of punctuation prediction. Thus, the two sub-models are computed in a cascaded way, until the optimal parsing tree and optimal punctuation symbols are generated. We call this model the cascaded punctuation prediction model (CPP). 4.3 Unified punctuation prediction model (UPP) In Model (6), if the punctuation symbols can be deterministically inferred from the partial tree, 𝑃 (𝑠𝑖 |𝑎𝑖, 𝑇𝑏𝑖 𝑖, 𝑤𝑏𝑖 𝑖 ) can be omitted because it is always 1. Similar to the idea of joint POS tagging and parsing (Hatori et al., 2011; Bohnet and Nivre, 2012), we propose attaching the punctuation prediction onto the parsing tree by embedding 𝑠𝑖 into 𝑎𝑖. Thus, we extend the conventional transition actions illustrated in Table 1 to a new set of transition actions for the parsing, denoted by 𝐴̂ : 755 A� _ {LeftArc, Reduce) U {Shift(s)Is E Q) U {RightArc(s)ls E Q) where Q is the set of punctuation symbols to be predicted, s is a punctuation symbol belonging to Q, Shift(s) is an action that attaches s to the current word on the basis of original Shift action in parsing, RightArc(s) attaches s to the current word on the basis of original RightArc action</context>
</contexts>
<marker>Bohnet, Nivre, 2012</marker>
<rawString>B. Bohnet and J. Nivre. 2012. A transition-based system for joint part-of-speech tagging and labeled non-projective dependency parsing. In Proc. EMNLP-CoNLL 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Christensen</author>
<author>Y Gotoh</author>
<author>S Renals</author>
</authors>
<title>Punctuation annotation using statistical prosody models.</title>
<date>2001</date>
<booktitle>In Proc. of ISCA Workshop on Prosody in Speech Recognition and Understanding.</booktitle>
<contexts>
<context position="7098" citStr="Christensen et al. (2001)" startWordPosition="1103" endWordPosition="1106">elated work. The transitionbased dependency parsing is introduced in Section 3. We explain our approach to predicting punctuations for transcribed speech texts in Section 4. Section 5 gives the results of our experiment. The conclusion and future work are given in Section 6. 2 Related Work Sentence boundary detection and punctuation prediction have been extensively studied in the speech processing field and have attracted research interest in the natural language processing field as well. Most previous work exploits local features for the task. Kim and Woodland (2001), Huang and Zweig (2002), Christensen et al. (2001), and Liu et al. (2005) integrate both prosodic features (pitch, pause duration, etc.) and lexical features (words, n-grams, etc.) to predict punctuation symbols during speech recognition, where Huang and Zweig (2002) uses a maximum entropy model, Christensen et al. (2001) focus on finite state and multi-layer perceptron methods, and Liu et al. (2005) uses conditional random fields. However, in some scenarios the prosodic cues are not available due to inaccessible original raw speech waveforms. Matusov et al. (2006) integrate segmentation features into the log-linear model in the statistical m</context>
</contexts>
<marker>Christensen, Gotoh, Renals, 2001</marker>
<rawString>H. Christensen, Y. Gotoh, and S. Renals. 2001. Punctuation annotation using statistical prosody models. In Proc. of ISCA Workshop on Prosody in Speech Recognition and Understanding.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
</authors>
<title>Discriminative training methods for hidden Markov models: Theory and experiments with perceptron algorithms.</title>
<date>2002</date>
<booktitle>In Proc. EMNLP’02,</booktitle>
<pages>1--8</pages>
<contexts>
<context position="20860" citStr="Collins, 2002" startWordPosition="3424" endWordPosition="3425"> be predicted. Punctuations Normalization Period, question mark, Full-stop punctuation exclamation mark (F) Comma, Colon, semi- Middle-paused punctucolon ation (M) Multiple Punctuations Full-stop punctuation (e.g., !!!!?) (F) Quotations, brackets, Null (N) etc. Table 3. Punctuation normalization in training data As the feature templates are the same for the model training of both CPP and UPP, the training instances of CPP and UPP have the same contexts but with different outputs. Similar to work in (Zhang and Clark, 2008; Zhang and Nivre, 2011), we train CPP and UPP by generalized perceptron (Collins, 2002). In decoding, beam search is performed to get the optimal sequence of transition actions in CPP and UPP, and the optimal punctuation symbols in CPP. To ensure each segment decided by a fullstop punctuation corresponds to a single parsing tree, two constraints are applied in decoding for the pruning of deficient search paths. (1) Proceeding-constraint: If the partial parsing result is not a single tree, the full-stop punctuation prediction in CPP cannot be performed. In UPP, if Shift(F) or RightArc(F) fail to result in a single parsing tree, they cannot be performed as well. (2) Succeeding-con</context>
<context position="22924" citStr="Collins, 2002" startWordPosition="3753" endWordPosition="3754">ion, every ten dependency trees are concatenated sequentially to simulate a parsing result of a stream of words in the model training. There are two test data sets used in our experiments. One is the English corpus of the IWSLT09 evaluation campaign (Paul, 2009) that is the conversional speech text. The other is a subset of the TDT4 English data (LDC2005T16) which consists of 200 hours of closed-captioned broadcast news. In the decoding, the beam size of both the transition-based parsing and punctuation prediction is set to 5. The part-of-speech tagger is our re-implementation of the work in (Collins, 2002). The evaluation metrics of our experiments are precision (prec.), recall (rec.) and F1-measure (F1). For the comparison, we also implement a baseline method based on the CRF model. It incorporates the features of bag of words and POS tags shown in Table 2(a), which are commonly used in previous related work. 5.2 Experimental results We test the performance of our method on both the correctly recognized texts and automatically recognized texts. The former data is used to evaluate the capability of punctuation prediction of our algorithm regardless of the noises from speech data, as our model t</context>
</contexts>
<marker>Collins, 2002</marker>
<rawString>M. Collins. 2002. Discriminative training methods for hidden Markov models: Theory and experiments with perceptron algorithms. In Proc. EMNLP’02, pages 1-8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Favre</author>
<author>R Grishman</author>
<author>D Hillard</author>
<author>H Ji</author>
<author>D HakkaniTur</author>
<author>M Ostendorf</author>
</authors>
<title>Punctuating speech for information extraction.</title>
<date>2008</date>
<booktitle>In Proc. of ICASSP’08.</booktitle>
<contexts>
<context position="2606" citStr="Favre et al., 2008" startWordPosition="379" endWordPosition="382">d to the length of inputs. The punctuation prediction problem has attracted research interest in both the speech processing community and the natural language processing community. Most previous work primarily exploits local features in their statistical models such as lexicons, prosodic cues and hidden event language model (HELM) (Liu et al., 2005; Matusov et al., 2006; Huang and Zweig, 2002; Stolcke and Shriberg, 1996). The word-level models integrating local features have narrow views about the input and could not achieve satisfied performance due to the limited context information access (Favre et al., 2008). Naturally, global contexts are required to model the punctuation prediction, especially for long-range dependencies. For instance, in English question sentences, the ending question mark is long-range dependent on the initial phrases (Lu and Ng, 2010), such as “could you” in Figure 1. There has been some work trying to incorporate syntactic features to broaden the view of hypotheses in the punctuation prediction models (Roark et al., 2006; Favre et al., 2008). In their methods, the punctuation prediction is treated as a separated post-procedure of parsing, which may suffer from the problem o</context>
<context position="8412" citStr="Favre et al. (2008)" startWordPosition="1304" endWordPosition="1307">scribed speech texts. Lu and Ng (2010) uses dynamic conditional random fields to perform both sentence boundary and sentence type prediction. They achieved promising results on both English and Chinese transcribed speech texts. The above work only ex753 ploits local features, so they were limited to capturing long range dependencies for punctuation prediction. It is natural to incorporate global knowledge, such as syntactic information, to improve punctuation prediction performance. Roark et al. (2006) use a rich set of non-local features including parser scores to re-rank full segmentations. Favre et al. (2008) integrate syntactic information from a PCFG parser into a log-linear and combine it with local features for sentence segmentation. The punctuation prediction in these works is performed as a post-procedure step of parsing, where a parse tree needs to be built in advance. As their parsing over the stream of words in transcribed speech text is exponentially complex, their approaches are only feasible for short input processing. Unlike these works, we incorporate punctuation prediction into the parsing which process left to right input without length limitations. Numerous dependency parsing algo</context>
</contexts>
<marker>Favre, Grishman, Hillard, Ji, HakkaniTur, Ostendorf, 2008</marker>
<rawString>B. Favre, R. Grishman, D. Hillard, H. Ji, D. HakkaniTur, and M. Ostendorf. 2008. Punctuating speech for information extraction. In Proc. of ICASSP’08.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Favre</author>
<author>D HakkaniTur</author>
<author>S Petrov</author>
<author>D Klein</author>
</authors>
<title>Efficient sentence segmentation using syntactic features.</title>
<date>2008</date>
<booktitle>In Spoken Language Technologies (SLT).</booktitle>
<contexts>
<context position="2606" citStr="Favre et al., 2008" startWordPosition="379" endWordPosition="382">d to the length of inputs. The punctuation prediction problem has attracted research interest in both the speech processing community and the natural language processing community. Most previous work primarily exploits local features in their statistical models such as lexicons, prosodic cues and hidden event language model (HELM) (Liu et al., 2005; Matusov et al., 2006; Huang and Zweig, 2002; Stolcke and Shriberg, 1996). The word-level models integrating local features have narrow views about the input and could not achieve satisfied performance due to the limited context information access (Favre et al., 2008). Naturally, global contexts are required to model the punctuation prediction, especially for long-range dependencies. For instance, in English question sentences, the ending question mark is long-range dependent on the initial phrases (Lu and Ng, 2010), such as “could you” in Figure 1. There has been some work trying to incorporate syntactic features to broaden the view of hypotheses in the punctuation prediction models (Roark et al., 2006; Favre et al., 2008). In their methods, the punctuation prediction is treated as a separated post-procedure of parsing, which may suffer from the problem o</context>
<context position="8412" citStr="Favre et al. (2008)" startWordPosition="1304" endWordPosition="1307">scribed speech texts. Lu and Ng (2010) uses dynamic conditional random fields to perform both sentence boundary and sentence type prediction. They achieved promising results on both English and Chinese transcribed speech texts. The above work only ex753 ploits local features, so they were limited to capturing long range dependencies for punctuation prediction. It is natural to incorporate global knowledge, such as syntactic information, to improve punctuation prediction performance. Roark et al. (2006) use a rich set of non-local features including parser scores to re-rank full segmentations. Favre et al. (2008) integrate syntactic information from a PCFG parser into a log-linear and combine it with local features for sentence segmentation. The punctuation prediction in these works is performed as a post-procedure step of parsing, where a parse tree needs to be built in advance. As their parsing over the stream of words in transcribed speech text is exponentially complex, their approaches are only feasible for short input processing. Unlike these works, we incorporate punctuation prediction into the parsing which process left to right input without length limitations. Numerous dependency parsing algo</context>
</contexts>
<marker>Favre, HakkaniTur, Petrov, Klein, 2008</marker>
<rawString>B. Favre, D. HakkaniTur, S. Petrov and D. Klein. 2008. Efficient sentence segmentation using syntactic features. In Spoken Language Technologies (SLT).</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Gravano</author>
<author>M Jansche</author>
<author>M Bacchiani</author>
</authors>
<title>Restoring punctuation and capitalization in transcribed speech.</title>
<date>2009</date>
<booktitle>In Proc. of ICASSP’09.</booktitle>
<marker>Gravano, Jansche, Bacchiani, 2009</marker>
<rawString>A. Gravano, M. Jansche, and M. Bacchiani. 2009. Restoring punctuation and capitalization in transcribed speech. In Proc. of ICASSP’09.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hatori</author>
<author>T Matsuzaki</author>
<author>Y Miyao</author>
<author>J Tsujii</author>
</authors>
<title>Incremental joint POS tagging and dependency parsing in Chinese.</title>
<date>2011</date>
<booktitle>In Proc. Of IJCNLP’11.</booktitle>
<contexts>
<context position="9696" citStr="Hatori et al., 2011" startWordPosition="1497" endWordPosition="1500">unity, including transition-based and graph-based dependency parsing. Compared to graph-based parsing, transition-based parsing can offer linear time complexity and easily leverage non-local features in the models (Yamada and Matsumoto, 2003; Nivre et al., 2006b; Zhang and Clark, 2008; Huang and Sagae, 2010). Starting with the work from (Zhang and Nivre, 2011), in this paper we extend transition-based dependency parsing from the sentence-level to the stream of words and integrate the parsing with punctuation prediction. Joint POS tagging and transition-based dependency parsing are studied in (Hatori et al., 2011; Bohnet and Nivre, 2012). The improvements are reported with the joint model compared to the pipeline model for Chinese and other richly inflected languages, which shows that it also makes sense to jointly perform punctuation prediction and parsing, although these two tasks of POS tagging and punctuation prediction are different in two ways: 1). The former usually works on a well-formed single sentence while the latter needs to process multiple sentences that are very lengthy. 2). POS tags are must-have features to parsing while punctuations are not. The parsing quality in the former is more </context>
<context position="15988" citStr="Hatori et al., 2011" startWordPosition="2601" endWordPosition="2604">the words in the stream are consumed, each computation of transition actions is followed by a computation of punctuation prediction. Thus, the two sub-models are computed in a cascaded way, until the optimal parsing tree and optimal punctuation symbols are generated. We call this model the cascaded punctuation prediction model (CPP). 4.3 Unified punctuation prediction model (UPP) In Model (6), if the punctuation symbols can be deterministically inferred from the partial tree, 𝑃 (𝑠𝑖 |𝑎𝑖, 𝑇𝑏𝑖 𝑖, 𝑤𝑏𝑖 𝑖 ) can be omitted because it is always 1. Similar to the idea of joint POS tagging and parsing (Hatori et al., 2011; Bohnet and Nivre, 2012), we propose attaching the punctuation prediction onto the parsing tree by embedding 𝑠𝑖 into 𝑎𝑖. Thus, we extend the conventional transition actions illustrated in Table 1 to a new set of transition actions for the parsing, denoted by 𝐴̂ : 755 A� _ {LeftArc, Reduce) U {Shift(s)Is E Q) U {RightArc(s)ls E Q) where Q is the set of punctuation symbols to be predicted, s is a punctuation symbol belonging to Q, Shift(s) is an action that attaches s to the current word on the basis of original Shift action in parsing, RightArc(s) attaches s to the current word on the basis of</context>
</contexts>
<marker>Hatori, Matsuzaki, Miyao, Tsujii, 2011</marker>
<rawString>J. Hatori, T. Matsuzaki, Y. Miyao and J. Tsujii. 2011. Incremental joint POS tagging and dependency parsing in Chinese. In Proc. Of IJCNLP’11.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Huang</author>
<author>G Zweig</author>
</authors>
<title>Maximum entropy model for punctuation annotation from speech.</title>
<date>2002</date>
<booktitle>In Proc. Of ICSLP’02.</booktitle>
<contexts>
<context position="2382" citStr="Huang and Zweig, 2002" startWordPosition="344" endWordPosition="347">rrent machine translation (MT) systems perform the translation at the sentence level, where various models used in MT are trained over segmented sentences and many algorithms inside MT have an exponential complexity with regard to the length of inputs. The punctuation prediction problem has attracted research interest in both the speech processing community and the natural language processing community. Most previous work primarily exploits local features in their statistical models such as lexicons, prosodic cues and hidden event language model (HELM) (Liu et al., 2005; Matusov et al., 2006; Huang and Zweig, 2002; Stolcke and Shriberg, 1996). The word-level models integrating local features have narrow views about the input and could not achieve satisfied performance due to the limited context information access (Favre et al., 2008). Naturally, global contexts are required to model the punctuation prediction, especially for long-range dependencies. For instance, in English question sentences, the ending question mark is long-range dependent on the initial phrases (Lu and Ng, 2010), such as “could you” in Figure 1. There has been some work trying to incorporate syntactic features to broaden the view of</context>
<context position="7071" citStr="Huang and Zweig (2002)" startWordPosition="1099" endWordPosition="1102">2 conducts a survey of related work. The transitionbased dependency parsing is introduced in Section 3. We explain our approach to predicting punctuations for transcribed speech texts in Section 4. Section 5 gives the results of our experiment. The conclusion and future work are given in Section 6. 2 Related Work Sentence boundary detection and punctuation prediction have been extensively studied in the speech processing field and have attracted research interest in the natural language processing field as well. Most previous work exploits local features for the task. Kim and Woodland (2001), Huang and Zweig (2002), Christensen et al. (2001), and Liu et al. (2005) integrate both prosodic features (pitch, pause duration, etc.) and lexical features (words, n-grams, etc.) to predict punctuation symbols during speech recognition, where Huang and Zweig (2002) uses a maximum entropy model, Christensen et al. (2001) focus on finite state and multi-layer perceptron methods, and Liu et al. (2005) uses conditional random fields. However, in some scenarios the prosodic cues are not available due to inaccessible original raw speech waveforms. Matusov et al. (2006) integrate segmentation features into the log-linear</context>
</contexts>
<marker>Huang, Zweig, 2002</marker>
<rawString>J. Huang and G. Zweig. 2002. Maximum entropy model for punctuation annotation from speech. In Proc. Of ICSLP’02.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J H Kim</author>
<author>P C Woodland</author>
</authors>
<title>The use of prosody in a combined system for punctuation generation and speech recognition.</title>
<date>2001</date>
<booktitle>In Proc. of EuroSpeech’01.</booktitle>
<contexts>
<context position="7047" citStr="Kim and Woodland (2001)" startWordPosition="1095" endWordPosition="1098">ured as follows: Section 2 conducts a survey of related work. The transitionbased dependency parsing is introduced in Section 3. We explain our approach to predicting punctuations for transcribed speech texts in Section 4. Section 5 gives the results of our experiment. The conclusion and future work are given in Section 6. 2 Related Work Sentence boundary detection and punctuation prediction have been extensively studied in the speech processing field and have attracted research interest in the natural language processing field as well. Most previous work exploits local features for the task. Kim and Woodland (2001), Huang and Zweig (2002), Christensen et al. (2001), and Liu et al. (2005) integrate both prosodic features (pitch, pause duration, etc.) and lexical features (words, n-grams, etc.) to predict punctuation symbols during speech recognition, where Huang and Zweig (2002) uses a maximum entropy model, Christensen et al. (2001) focus on finite state and multi-layer perceptron methods, and Liu et al. (2005) uses conditional random fields. However, in some scenarios the prosodic cues are not available due to inaccessible original raw speech waveforms. Matusov et al. (2006) integrate segmentation feat</context>
</contexts>
<marker>Kim, Woodland, 2001</marker>
<rawString>J.H. Kim and P.C. Woodland. 2001. The use of prosody in a combined system for punctuation generation and speech recognition. In Proc. of EuroSpeech’01.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Liu</author>
<author>A Stolcke</author>
<author>E Shriberg</author>
<author>M Harper</author>
</authors>
<title>Using conditional random fields for sentence boundary detection in speech.</title>
<date>2005</date>
<booktitle>In Proc. of ACL’05.</booktitle>
<contexts>
<context position="2337" citStr="Liu et al., 2005" startWordPosition="336" endWordPosition="339">998; Nakamura, 2009). This is because current machine translation (MT) systems perform the translation at the sentence level, where various models used in MT are trained over segmented sentences and many algorithms inside MT have an exponential complexity with regard to the length of inputs. The punctuation prediction problem has attracted research interest in both the speech processing community and the natural language processing community. Most previous work primarily exploits local features in their statistical models such as lexicons, prosodic cues and hidden event language model (HELM) (Liu et al., 2005; Matusov et al., 2006; Huang and Zweig, 2002; Stolcke and Shriberg, 1996). The word-level models integrating local features have narrow views about the input and could not achieve satisfied performance due to the limited context information access (Favre et al., 2008). Naturally, global contexts are required to model the punctuation prediction, especially for long-range dependencies. For instance, in English question sentences, the ending question mark is long-range dependent on the initial phrases (Lu and Ng, 2010), such as “could you” in Figure 1. There has been some work trying to incorpor</context>
<context position="7121" citStr="Liu et al. (2005)" startWordPosition="1108" endWordPosition="1111">d dependency parsing is introduced in Section 3. We explain our approach to predicting punctuations for transcribed speech texts in Section 4. Section 5 gives the results of our experiment. The conclusion and future work are given in Section 6. 2 Related Work Sentence boundary detection and punctuation prediction have been extensively studied in the speech processing field and have attracted research interest in the natural language processing field as well. Most previous work exploits local features for the task. Kim and Woodland (2001), Huang and Zweig (2002), Christensen et al. (2001), and Liu et al. (2005) integrate both prosodic features (pitch, pause duration, etc.) and lexical features (words, n-grams, etc.) to predict punctuation symbols during speech recognition, where Huang and Zweig (2002) uses a maximum entropy model, Christensen et al. (2001) focus on finite state and multi-layer perceptron methods, and Liu et al. (2005) uses conditional random fields. However, in some scenarios the prosodic cues are not available due to inaccessible original raw speech waveforms. Matusov et al. (2006) integrate segmentation features into the log-linear model in the statistical machine translation (SMT</context>
</contexts>
<marker>Liu, Stolcke, Shriberg, Harper, 2005</marker>
<rawString>Y. Liu, A. Stolcke, E. Shriberg, and M. Harper. 2005. Using conditional random fields for sentence boundary detection in speech. In Proc. of ACL’05.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Lu</author>
<author>H T Ng</author>
</authors>
<title>Better Punctuation Prediction with Dynamic Conditional Random Fields.</title>
<date>2010</date>
<booktitle>In Proc. Of EMNLP’10.</booktitle>
<pages>177--186</pages>
<contexts>
<context position="2859" citStr="Lu and Ng, 2010" startWordPosition="418" endWordPosition="421">odels such as lexicons, prosodic cues and hidden event language model (HELM) (Liu et al., 2005; Matusov et al., 2006; Huang and Zweig, 2002; Stolcke and Shriberg, 1996). The word-level models integrating local features have narrow views about the input and could not achieve satisfied performance due to the limited context information access (Favre et al., 2008). Naturally, global contexts are required to model the punctuation prediction, especially for long-range dependencies. For instance, in English question sentences, the ending question mark is long-range dependent on the initial phrases (Lu and Ng, 2010), such as “could you” in Figure 1. There has been some work trying to incorporate syntactic features to broaden the view of hypotheses in the punctuation prediction models (Roark et al., 2006; Favre et al., 2008). In their methods, the punctuation prediction is treated as a separated post-procedure of parsing, which may suffer from the problem of error propagation. In addition, these approaches are not able to incrementally process inputs and are not efficient for very long inputs, especially in the cases of long transcribed speech texts from presentations where the number of streaming words c</context>
<context position="7831" citStr="Lu and Ng (2010)" startWordPosition="1213" endWordPosition="1216">-grams, etc.) to predict punctuation symbols during speech recognition, where Huang and Zweig (2002) uses a maximum entropy model, Christensen et al. (2001) focus on finite state and multi-layer perceptron methods, and Liu et al. (2005) uses conditional random fields. However, in some scenarios the prosodic cues are not available due to inaccessible original raw speech waveforms. Matusov et al. (2006) integrate segmentation features into the log-linear model in the statistical machine translation (SMT) framework to improve the translation performance when translating transcribed speech texts. Lu and Ng (2010) uses dynamic conditional random fields to perform both sentence boundary and sentence type prediction. They achieved promising results on both English and Chinese transcribed speech texts. The above work only ex753 ploits local features, so they were limited to capturing long range dependencies for punctuation prediction. It is natural to incorporate global knowledge, such as syntactic information, to improve punctuation prediction performance. Roark et al. (2006) use a rich set of non-local features including parser scores to re-rank full segmentations. Favre et al. (2008) integrate syntacti</context>
</contexts>
<marker>Lu, Ng, 2010</marker>
<rawString>W. Lu and H.T. Ng. 2010. Better Punctuation Prediction with Dynamic Conditional Random Fields. In Proc. Of EMNLP’10. Pages 177-186.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Marneffe</author>
<author>B MacCartney</author>
<author>C D Maning</author>
</authors>
<title>Generating Typed Dependency Parses from Phrase Structure Parses. In</title>
<date>2006</date>
<booktitle>Proc. LREC’06.</booktitle>
<contexts>
<context position="21954" citStr="Marneffe et al., 2006" startWordPosition="3593" endWordPosition="3596">In UPP, if Shift(F) or RightArc(F) fail to result in a single parsing tree, they cannot be performed as well. (2) Succeeding-constraint: If the full-stop punctuation is predicted in CPP, or Shift(F) and RightArc(F) are performed in UPP, the following transition actions must be a sequence of Reduce actions until the stack becomes empty. 5 Experiments 5.1 Experimental setup Our training data of transition-based dependency trees are converted from phrasal structure trees in English Web Treebank (LDC2012T13) and the English portion of OntoNotes 4.0 (LDC2011T03) by the Stanford Conversion toolkit (Marneffe et al., 2006). It contains around 1.5M words in total and consist of various genres including weblogs, web texts, newsgroups, email, reviews, questionanswer sessions, newswires, broadcast news and broadcast conversations. To simulate the transcribed speech text, all words in dependency trees are lowercased and punctuations are excluded before model training. In addition, every ten dependency trees are concatenated sequentially to simulate a parsing result of a stream of words in the model training. There are two test data sets used in our experiments. One is the English corpus of the IWSLT09 evaluation cam</context>
</contexts>
<marker>Marneffe, MacCartney, Maning, 2006</marker>
<rawString>M. Marneffe, B. MacCartney, C.D. Maning. 2006. Generating Typed Dependency Parses from Phrase Structure Parses. In Proc. LREC’06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Matusov</author>
<author>A Mauser</author>
<author>H Ney</author>
</authors>
<title>Automatic sentence segmentation and punctuation prediction for spoken language translation.</title>
<date>2006</date>
<booktitle>In Proc. of IWSLT’06.</booktitle>
<contexts>
<context position="2359" citStr="Matusov et al., 2006" startWordPosition="340" endWordPosition="343">9). This is because current machine translation (MT) systems perform the translation at the sentence level, where various models used in MT are trained over segmented sentences and many algorithms inside MT have an exponential complexity with regard to the length of inputs. The punctuation prediction problem has attracted research interest in both the speech processing community and the natural language processing community. Most previous work primarily exploits local features in their statistical models such as lexicons, prosodic cues and hidden event language model (HELM) (Liu et al., 2005; Matusov et al., 2006; Huang and Zweig, 2002; Stolcke and Shriberg, 1996). The word-level models integrating local features have narrow views about the input and could not achieve satisfied performance due to the limited context information access (Favre et al., 2008). Naturally, global contexts are required to model the punctuation prediction, especially for long-range dependencies. For instance, in English question sentences, the ending question mark is long-range dependent on the initial phrases (Lu and Ng, 2010), such as “could you” in Figure 1. There has been some work trying to incorporate syntactic features</context>
<context position="7619" citStr="Matusov et al. (2006)" startWordPosition="1183" endWordPosition="1186">al features for the task. Kim and Woodland (2001), Huang and Zweig (2002), Christensen et al. (2001), and Liu et al. (2005) integrate both prosodic features (pitch, pause duration, etc.) and lexical features (words, n-grams, etc.) to predict punctuation symbols during speech recognition, where Huang and Zweig (2002) uses a maximum entropy model, Christensen et al. (2001) focus on finite state and multi-layer perceptron methods, and Liu et al. (2005) uses conditional random fields. However, in some scenarios the prosodic cues are not available due to inaccessible original raw speech waveforms. Matusov et al. (2006) integrate segmentation features into the log-linear model in the statistical machine translation (SMT) framework to improve the translation performance when translating transcribed speech texts. Lu and Ng (2010) uses dynamic conditional random fields to perform both sentence boundary and sentence type prediction. They achieved promising results on both English and Chinese transcribed speech texts. The above work only ex753 ploits local features, so they were limited to capturing long range dependencies for punctuation prediction. It is natural to incorporate global knowledge, such as syntacti</context>
</contexts>
<marker>Matusov, Mauser, Ney, 2006</marker>
<rawString>E. Matusov, A. Mauser, and H. Ney. 2006. Automatic sentence segmentation and punctuation prediction for spoken language translation. In Proc. of IWSLT’06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Nakamura</author>
</authors>
<title>Overcoming the language barrier with speech translation technology.</title>
<date>2009</date>
<booktitle>In Science &amp; Technology Trends - Quarterly Review. No. 31.</booktitle>
<contexts>
<context position="1741" citStr="Nakamura, 2009" startWordPosition="242" endWordPosition="243">. They neither perform a proper segmentation of the output into sentences, nor predict punctuation symbols. The unavailable punctuations and sentence boundaries in transcribed speech texts create barriers to many subsequent processing tasks, such as summarization, information extraction, question answering and machine translation. Thus, the segmentation of long texts is necessary in many real applications. For example, in speech-to-speech translation, continuously transcribed speech texts need to be segmented before being fed into subsequent machine translation systems (Takezawa et al., 1998; Nakamura, 2009). This is because current machine translation (MT) systems perform the translation at the sentence level, where various models used in MT are trained over segmented sentences and many algorithms inside MT have an exponential complexity with regard to the length of inputs. The punctuation prediction problem has attracted research interest in both the speech processing community and the natural language processing community. Most previous work primarily exploits local features in their statistical models such as lexicons, prosodic cues and hidden event language model (HELM) (Liu et al., 2005; Ma</context>
</contexts>
<marker>Nakamura, 2009</marker>
<rawString>S. Nakamura. 2009. Overcoming the language barrier with speech translation technology. In Science &amp; Technology Trends - Quarterly Review. No. 31. April 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Nivre</author>
</authors>
<title>An efficient algorithm for projective dependency parsing.</title>
<date>2003</date>
<booktitle>In Proceedings of IWPT,</booktitle>
<pages>149--160</pages>
<location>Nancy, France.</location>
<marker>Nivre, 2003</marker>
<rawString>J. Nivre. 2003. An efficient algorithm for projective dependency parsing. In Proceedings of IWPT, pages 149–160, Nancy, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Nivre</author>
<author>M Scholz</author>
</authors>
<title>Deterministic dependency parsing of English text.</title>
<date>2004</date>
<booktitle>In Proc. COLING’04.</booktitle>
<marker>Nivre, Scholz, 2004</marker>
<rawString>J. Nivre and M. Scholz. 2004. Deterministic dependency parsing of English text. In Proc. COLING’04.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Paul</author>
</authors>
<title>Overview of the IWSLT</title>
<date>2009</date>
<booktitle>In Proceedings of IWSLT’09.</booktitle>
<contexts>
<context position="22572" citStr="Paul, 2009" startWordPosition="3693" endWordPosition="3694">ntains around 1.5M words in total and consist of various genres including weblogs, web texts, newsgroups, email, reviews, questionanswer sessions, newswires, broadcast news and broadcast conversations. To simulate the transcribed speech text, all words in dependency trees are lowercased and punctuations are excluded before model training. In addition, every ten dependency trees are concatenated sequentially to simulate a parsing result of a stream of words in the model training. There are two test data sets used in our experiments. One is the English corpus of the IWSLT09 evaluation campaign (Paul, 2009) that is the conversional speech text. The other is a subset of the TDT4 English data (LDC2005T16) which consists of 200 hours of closed-captioned broadcast news. In the decoding, the beam size of both the transition-based parsing and punctuation prediction is set to 5. The part-of-speech tagger is our re-implementation of the work in (Collins, 2002). The evaluation metrics of our experiments are precision (prec.), recall (rec.) and F1-measure (F1). For the comparison, we also implement a baseline method based on the CRF model. It incorporates the features of bag of words and POS tags shown in</context>
</contexts>
<marker>Paul, 2009</marker>
<rawString>M. Paul. 2009. Overview of the IWSLT 2009 Evaluation Campaign. In Proceedings of IWSLT’09.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Roark</author>
<author>Y Liu</author>
<author>M Harper</author>
<author>R Stewart</author>
<author>M Lease</author>
<author>M Snover</author>
<author>I Shafran</author>
<author>B Dorr</author>
<author>J Hale</author>
<author>A Krasnyanskaya</author>
<author>L Yung</author>
</authors>
<title>Reranking for sentence boundary detection in conversational speech.</title>
<date>2006</date>
<booktitle>In Proc. ICASSP,</booktitle>
<contexts>
<context position="3050" citStr="Roark et al., 2006" startWordPosition="451" endWordPosition="454">ls integrating local features have narrow views about the input and could not achieve satisfied performance due to the limited context information access (Favre et al., 2008). Naturally, global contexts are required to model the punctuation prediction, especially for long-range dependencies. For instance, in English question sentences, the ending question mark is long-range dependent on the initial phrases (Lu and Ng, 2010), such as “could you” in Figure 1. There has been some work trying to incorporate syntactic features to broaden the view of hypotheses in the punctuation prediction models (Roark et al., 2006; Favre et al., 2008). In their methods, the punctuation prediction is treated as a separated post-procedure of parsing, which may suffer from the problem of error propagation. In addition, these approaches are not able to incrementally process inputs and are not efficient for very long inputs, especially in the cases of long transcribed speech texts from presentations where the number of streaming words could be larger than hundreds or thousands. In this paper, we propose jointly performing punctuation prediction and transition-based dependency parsing over transcribed speech text. When the t</context>
<context position="8300" citStr="Roark et al. (2006)" startWordPosition="1285" endWordPosition="1288">the statistical machine translation (SMT) framework to improve the translation performance when translating transcribed speech texts. Lu and Ng (2010) uses dynamic conditional random fields to perform both sentence boundary and sentence type prediction. They achieved promising results on both English and Chinese transcribed speech texts. The above work only ex753 ploits local features, so they were limited to capturing long range dependencies for punctuation prediction. It is natural to incorporate global knowledge, such as syntactic information, to improve punctuation prediction performance. Roark et al. (2006) use a rich set of non-local features including parser scores to re-rank full segmentations. Favre et al. (2008) integrate syntactic information from a PCFG parser into a log-linear and combine it with local features for sentence segmentation. The punctuation prediction in these works is performed as a post-procedure step of parsing, where a parse tree needs to be built in advance. As their parsing over the stream of words in transcribed speech text is exponentially complex, their approaches are only feasible for short input processing. Unlike these works, we incorporate punctuation prediction</context>
</contexts>
<marker>Roark, Liu, Harper, Stewart, Lease, Snover, Shafran, Dorr, Hale, Krasnyanskaya, Yung, 2006</marker>
<rawString>B. Roark, Y. Liu, M. Harper, R. Stewart, M. Lease, M. Snover, I. Shafran, B. Dorr, J. Hale, A. Krasnyanskaya, and L. Yung. 2006. Reranking for sentence boundary detection in conversational speech. In Proc. ICASSP, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Stolcke</author>
<author>E Shriberg</author>
</authors>
<title>Automatic linguistic segmentation of conversational speech,”</title>
<date>1996</date>
<booktitle>Proc. ICSLP,</booktitle>
<volume>2</volume>
<contexts>
<context position="2411" citStr="Stolcke and Shriberg, 1996" startWordPosition="348" endWordPosition="351">on (MT) systems perform the translation at the sentence level, where various models used in MT are trained over segmented sentences and many algorithms inside MT have an exponential complexity with regard to the length of inputs. The punctuation prediction problem has attracted research interest in both the speech processing community and the natural language processing community. Most previous work primarily exploits local features in their statistical models such as lexicons, prosodic cues and hidden event language model (HELM) (Liu et al., 2005; Matusov et al., 2006; Huang and Zweig, 2002; Stolcke and Shriberg, 1996). The word-level models integrating local features have narrow views about the input and could not achieve satisfied performance due to the limited context information access (Favre et al., 2008). Naturally, global contexts are required to model the punctuation prediction, especially for long-range dependencies. For instance, in English question sentences, the ending question mark is long-range dependent on the initial phrases (Lu and Ng, 2010), such as “could you” in Figure 1. There has been some work trying to incorporate syntactic features to broaden the view of hypotheses in the punctuatio</context>
</contexts>
<marker>Stolcke, Shriberg, 1996</marker>
<rawString>A. Stolcke and E. Shriberg, “Automatic linguistic segmentation of conversational speech,” Proc. ICSLP, vol. 2, 1996.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Stolcke</author>
<author>E Shriberg</author>
<author>R Bates</author>
<author>M Ostendorf</author>
<author>D Hakkani</author>
<author>M Plauche</author>
<author>G Tur</author>
<author>Y Lu</author>
</authors>
<title>Automatic detection of sentence boundaries and disfluencies based on recognized words.</title>
<date>1998</date>
<booktitle>In Proc. of ICSLP’ 98.</booktitle>
<marker>Stolcke, Shriberg, Bates, Ostendorf, Hakkani, Plauche, Tur, Lu, 1998</marker>
<rawString>A. Stolcke, E. Shriberg, R. Bates, M. Ostendorf, D. Hakkani, M. Plauche, G. Tur, and Y. Lu. 1998. Automatic detection of sentence boundaries and disfluencies based on recognized words. In Proc. of ICSLP’ 98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Morimoto Takezawa</author>
<author>T Sagisaka</author>
<author>Y Campbell</author>
<author>N Iida</author>
<author>H Sugaya</author>
<author>F Yokoo</author>
<author>A Yamamoto</author>
<author>Seiichi</author>
</authors>
<title>A Japanese-to-English speech translation system: ATR-MATRIX.</title>
<date>1998</date>
<booktitle>In Proc. ICSLP’98.</booktitle>
<contexts>
<context position="1724" citStr="Takezawa et al., 1998" startWordPosition="238" endWordPosition="241">ctured streams of words. They neither perform a proper segmentation of the output into sentences, nor predict punctuation symbols. The unavailable punctuations and sentence boundaries in transcribed speech texts create barriers to many subsequent processing tasks, such as summarization, information extraction, question answering and machine translation. Thus, the segmentation of long texts is necessary in many real applications. For example, in speech-to-speech translation, continuously transcribed speech texts need to be segmented before being fed into subsequent machine translation systems (Takezawa et al., 1998; Nakamura, 2009). This is because current machine translation (MT) systems perform the translation at the sentence level, where various models used in MT are trained over segmented sentences and many algorithms inside MT have an exponential complexity with regard to the length of inputs. The punctuation prediction problem has attracted research interest in both the speech processing community and the natural language processing community. Most previous work primarily exploits local features in their statistical models such as lexicons, prosodic cues and hidden event language model (HELM) (Liu</context>
</contexts>
<marker>Takezawa, Sagisaka, Campbell, Iida, Sugaya, Yokoo, Yamamoto, Seiichi, 1998</marker>
<rawString>Takezawa, T. Morimoto, T. Sagisaka, Y. Campbell, N. Iida, H. Sugaya, F. Yokoo, A. Yamamoto, Seiichi. 1998. A Japanese-to-English speech translation system: ATR-MATRIX. In Proc. ICSLP’98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Zhang</author>
<author>J Nivre</author>
</authors>
<title>Transition-based Dependency Parsing with Rich Non-local Features.</title>
<date>2011</date>
<booktitle>In Proc. of ACL’11,</booktitle>
<pages>188--193</pages>
<contexts>
<context position="9439" citStr="Zhang and Nivre, 2011" startWordPosition="1459" endWordPosition="1462">r short input processing. Unlike these works, we incorporate punctuation prediction into the parsing which process left to right input without length limitations. Numerous dependency parsing algorithms have been proposed in the natural language processing community, including transition-based and graph-based dependency parsing. Compared to graph-based parsing, transition-based parsing can offer linear time complexity and easily leverage non-local features in the models (Yamada and Matsumoto, 2003; Nivre et al., 2006b; Zhang and Clark, 2008; Huang and Sagae, 2010). Starting with the work from (Zhang and Nivre, 2011), in this paper we extend transition-based dependency parsing from the sentence-level to the stream of words and integrate the parsing with punctuation prediction. Joint POS tagging and transition-based dependency parsing are studied in (Hatori et al., 2011; Bohnet and Nivre, 2012). The improvements are reported with the joint model compared to the pipeline model for Chinese and other richly inflected languages, which shows that it also makes sense to jointly perform punctuation prediction and parsing, although these two tasks of POS tagging and punctuation prediction are different in two ways</context>
<context position="11006" citStr="Zhang and Nivre, 2011" startWordPosition="1716" endWordPosition="1719">ependency parsing In a typical transition-based dependency parsing process, the shift-reduce decoding algorithm is applied and a queue and stack are maintained (Zhang and Nivre, 2011). The queue stores the stream of transcribed speech words, the front of which is indexed as the current word. The stack stores the unfinished words which may be linked with the current word or a future word in the queue. When words in the queue are consumed from left to right, a set of transition actions is applied to build a parse tree. There are four kinds of transition actions conducted in the parsing process (Zhang and Nivre, 2011), as described in Table 1. Action Description Shift Fetches the current word from the queue and pushes it to the stack Reduce Pops the stack LeftArc Adds a dependency link from the current word to the stack top, and pops the stack RightArc Adds a dependency link from the stack top to the current word, takes away the current word from the queue and pushes it to the stack Table 1. Action types in transition-based parsing The choice of each transition action during the parsing is scored by a linear model that can be trained over a rich set of non-local features extracted from the contexts of the </context>
<context position="18395" citStr="Zhang and Nivre, 2011" startWordPosition="3025" endWordPosition="3028">ched to the words shown in Figure 2(a). The final segmentation with the predicted punctuation insertion could be “so, could you tell me?”. 4.4 Model training and decoding In practice, the sub-models in Model (6) and (7) with the form of P (Y IX) is computed with a linear model Score (Y, X) as I Score (Y,X) _ 0(Y,X) -A where 0 (Y, X) is the feature vector extracted I from the output Y and the context X, and A is the weight vector. For the features of the models, we incorporate the bag of words and POS tags as well as tree-based features shown in Table 2, which are the same as those defined in (Zhang and Nivre, 2011). ws; w0; w1; w2; ps; p0; p1; p2; wsps; w0p0; w1p1; w2p2; wspsw0p0; wspsw0; wspsp0; wsw0p0; psw0p0; wsw0; psp0; p0p1; psp0p1; p0p1p2; pshpsp0; pspslp0; pspsrp0; psp0p0l; wsd; psd; w0d; p0d; wsw0d; psp0d; wsvl; psvl; wsvr; psvr; w0vl; p0vl; wsh; psh; ts; w0l; p0l; t0l; w0r; p0r; t0r; w1l; p1l; t1l; wsh2; psh2; tsh; wsl2; psl2; tsl2; wsr2; psr2; tsr2; w0l2; p0l2; t0l2; pspslpsl2; pspsrpsr2; pspshpsh2; p0p0lp0l2; wsTl; psTl; wsTr; psTr; w0Tl; p0Tl; Table 2. (a) Features of the bag of words and POS tags. (b). Tree-based features. w—word; p—POS tag; d—distance between ws and w0; v—number of modifie</context>
<context position="20796" citStr="Zhang and Nivre, 2011" startWordPosition="3412" endWordPosition="3415">models are both independent regarding the number of punctuation types to be predicted. Punctuations Normalization Period, question mark, Full-stop punctuation exclamation mark (F) Comma, Colon, semi- Middle-paused punctucolon ation (M) Multiple Punctuations Full-stop punctuation (e.g., !!!!?) (F) Quotations, brackets, Null (N) etc. Table 3. Punctuation normalization in training data As the feature templates are the same for the model training of both CPP and UPP, the training instances of CPP and UPP have the same contexts but with different outputs. Similar to work in (Zhang and Clark, 2008; Zhang and Nivre, 2011), we train CPP and UPP by generalized perceptron (Collins, 2002). In decoding, beam search is performed to get the optimal sequence of transition actions in CPP and UPP, and the optimal punctuation symbols in CPP. To ensure each segment decided by a fullstop punctuation corresponds to a single parsing tree, two constraints are applied in decoding for the pruning of deficient search paths. (1) Proceeding-constraint: If the partial parsing result is not a single tree, the full-stop punctuation prediction in CPP cannot be performed. In UPP, if Shift(F) or RightArc(F) fail to result in a single pa</context>
</contexts>
<marker>Zhang, Nivre, 2011</marker>
<rawString>Y. Zhang and J. Nivre. 2011. Transition-based Dependency Parsing with Rich Non-local Features. In Proc. of ACL’11, pages 188-193.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Zhang</author>
<author>S Clark</author>
</authors>
<title>A Tale of Two Parsers: investigating and combing graph-based and transitionbased dependency parsing using beam-search.</title>
<date>2008</date>
<booktitle>In Proc. of EMNLP’08,</booktitle>
<pages>562--571</pages>
<contexts>
<context position="9362" citStr="Zhang and Clark, 2008" startWordPosition="1446" endWordPosition="1449"> speech text is exponentially complex, their approaches are only feasible for short input processing. Unlike these works, we incorporate punctuation prediction into the parsing which process left to right input without length limitations. Numerous dependency parsing algorithms have been proposed in the natural language processing community, including transition-based and graph-based dependency parsing. Compared to graph-based parsing, transition-based parsing can offer linear time complexity and easily leverage non-local features in the models (Yamada and Matsumoto, 2003; Nivre et al., 2006b; Zhang and Clark, 2008; Huang and Sagae, 2010). Starting with the work from (Zhang and Nivre, 2011), in this paper we extend transition-based dependency parsing from the sentence-level to the stream of words and integrate the parsing with punctuation prediction. Joint POS tagging and transition-based dependency parsing are studied in (Hatori et al., 2011; Bohnet and Nivre, 2012). The improvements are reported with the joint model compared to the pipeline model for Chinese and other richly inflected languages, which shows that it also makes sense to jointly perform punctuation prediction and parsing, although these </context>
<context position="11962" citStr="Zhang and Clark, 2008" startWordPosition="1883" endWordPosition="1886">m the queue and pushes it to the stack Table 1. Action types in transition-based parsing The choice of each transition action during the parsing is scored by a linear model that can be trained over a rich set of non-local features extracted from the contexts of the stack, the queue and the set of dependency labels. As described in (Zhang and Nivre, 2011), the feature templates could be defined over the lexicons, POS-tags and the combinations with syntactic information. In parsing, beam search is performed to search the optimal sequence of transition actions, from which a parse tree is formed (Zhang and Clark, 2008). As each word must be pushed to the stack once and popped off once, the number of actions needed to parse a sentence is always 2n, where n is the length of the sentence. Thus, transitionbased parsing has a linear complexity with the length of input and naturally it can be extended to process the stream of words. 4 Our method 4.1 Model In the task of punctuation prediction, we are given a stream of words from an automatic transcription of speech text, denoted by 𝑤1𝑛 : = 𝑤1, 𝑤2,... , 𝑤𝑛. We are asked to output a sequence of punctuation symbols 𝑆1𝑛: = 𝑠1, 𝑠2, ... , 𝑠𝑛 where 𝑠𝑖 is attached to 𝑤𝑖 </context>
<context position="20772" citStr="Zhang and Clark, 2008" startWordPosition="3408" endWordPosition="3411">56 But our CPP and UPP models are both independent regarding the number of punctuation types to be predicted. Punctuations Normalization Period, question mark, Full-stop punctuation exclamation mark (F) Comma, Colon, semi- Middle-paused punctucolon ation (M) Multiple Punctuations Full-stop punctuation (e.g., !!!!?) (F) Quotations, brackets, Null (N) etc. Table 3. Punctuation normalization in training data As the feature templates are the same for the model training of both CPP and UPP, the training instances of CPP and UPP have the same contexts but with different outputs. Similar to work in (Zhang and Clark, 2008; Zhang and Nivre, 2011), we train CPP and UPP by generalized perceptron (Collins, 2002). In decoding, beam search is performed to get the optimal sequence of transition actions in CPP and UPP, and the optimal punctuation symbols in CPP. To ensure each segment decided by a fullstop punctuation corresponds to a single parsing tree, two constraints are applied in decoding for the pruning of deficient search paths. (1) Proceeding-constraint: If the partial parsing result is not a single tree, the full-stop punctuation prediction in CPP cannot be performed. In UPP, if Shift(F) or RightArc(F) fail </context>
</contexts>
<marker>Zhang, Clark, 2008</marker>
<rawString>Y. Zhang and S. Clark. A Tale of Two Parsers: investigating and combing graph-based and transitionbased dependency parsing using beam-search. 2008. In Proc. of EMNLP’08, pages 562-571.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>