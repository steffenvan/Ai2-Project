<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.006262">
<note confidence="0.713209">
Proceedings of EACL &apos;99
</note>
<title confidence="0.999326">
A Flexible Architecture for Reference Resolution
</title>
<author confidence="0.99496">
Donna K Byron and Joel R. Tetreault
</author>
<affiliation confidence="0.920121666666667">
Department of Computer Science
University of Rochester
Rochester NY 14627, U.S.A.
</affiliation>
<email confidence="0.996289">
dbyron/tetreaul@cs.rochester.edu
</email>
<sectionHeader confidence="0.995849" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999794583333333">
This paper describes an architecture
for performing anaphora resolution in
a flexible way. Systems which con-
form to these guidelines are well-
encapsulated and portable, and can
be used to compare anaphora resolu-
tion techniques for new language un-
derstanding applications. Our im-
plementation of the architecture in
a pronoun resolution testing platform
demonstrates the flexibility of the ap-
proach.
</bodyText>
<sectionHeader confidence="0.998994" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998996442307692">
When building natural language understand-
ing systems, choosing the best technique for
anaphora resolution is a challenging task. The
system builder must decide whether to adopt an
existing technique or design a new approach.
A huge variety of techniques are described in
the literature, many of them achieving high suc-
cess rates on their own evaluation texts (cf.
Hobbs 1986; Strube 1998; Mitkov 1998). Each
technique makes different assumptions about the
data available to reference resolution, for ex-
ample, some assume perfect parses, others as-
sume only POS-tagged input, some assume se-
mantic information is available, etc. The chances
are high that no published technique will ex-
actly match the data available to a particular sys-
tem&apos;s reference resolution component, so it may
The authors thank James Allen for help on this project, as
well as the anonymous reviewers for helpful comments on
the paper. This material is based on work supported by
USAF/Rome Labs contract F30602-95-1-0025, ONR grant
N00014-95-1-1088, and Columbia Univ. grant OPG:1307.
not be apparent which method will work best.
Choosing a technique is especially problematic
for designers of dialogue systems trying to pre-
dict how anaphora resolution techniques devel-
oped for written monologue will perform when
adapted for spoken dialogue. In an ideal world,
the system designer would implement and com-
pare many techniques on the input data available
in his system. As a good software engineer, he
would also ensure that any pronoun resolution
code he implements can be ported to future ap-
plications or different language domains without
modification.
The architecture described in this paper was
designed to provide just that functionality.
Anaphora resolution code developed within the
architecture is encapsulated to ensure portabil-
ity across parsers, language genres and domains.
Using these architectural guidelines, a testbed
system for comparing pronoun resolution tech-
niques has been developed at the University of
Rochester. The testbed provides a highly config-
urable environment which uses the same pronoun
resolution code regardless of the parser front-end
and language type under analysis. It can be used,
inter alia, to compare anaphora resolution tech-
niques for a given application, to compare new
techniques to published baselines, or to compare
a particular technique&apos;s performance across lan-
guage types.
</bodyText>
<sectionHeader confidence="0.983086" genericHeader="method">
2 The Architecture
</sectionHeader>
<subsectionHeader confidence="0.99347">
2.1 Encapsulation of layers
</subsectionHeader>
<bodyText confidence="0.766008333333333">
Figure 1 depicts the organization of the architec-
ture. Each of the three layers have different re-
sponsibilities:
</bodyText>
<page confidence="0.993415">
229
</page>
<figure confidence="0.533243">
Proceedings of EACL &apos;99
</figure>
<figureCaption confidence="0.7862165">
Figure 1: Reference Resolution Architecture
Layer 1: Supervisor layer controls which Translation and Anaphora resolution modules are active for the current test.
</figureCaption>
<figure confidence="0.98627272972973">
Translator 1:
Treebank Translator 2:
TRAINS93
Translator 3:
Other domain
Discourse
Structure
analysis
Layer 2: Translation layer turns input text
into standard format for discourse referents.
Interface to
surrounding
system
Discourse
Context:
contains
discourse
referent tokens
in a standard
format
Hobbs naive
algorithm
Temporal anaphora
resolution
Layer 3: Anaphora Resolution posts results
of its analysis back to the discourse context.
Indefinite NP
Analysis: new
discourse referent?
Coreference
analysis for
definite NPs
Semantic type matching
for pronouns
Gender/number
agreement for
pronouns
</figure>
<listItem confidence="0.9711862">
• Layer 1: The supervisor controls which
modules in Layers 2 and 3 execute. In our
implementation, the supervisor sets a run-
time switch for each module in layer 2 and
3, and the first instruction of each of those
modules checks its runtime flag to see if it is
active for the current experiment.
• Layer 2: Translation reads the input text
and creates the main data structure used
for reference resolution, called the discourse
context (DC). The DC consists of discourse
entities (DEs) introduced in the text, some of
which are anaphoric. This layer contains all
syntactic and semantic analysis components
and all interaction with the surrounding sys-
tem, such as access to a gender database or
a lexicon for semantic restrictions. All fea-
tures that need to be available to reference
resolution are posted to the DC. This layer
is also responsible for deciding which input
constituents create DEs.
• Layer 3: Anaphora resolution contains a
variety of functions for resolving different
types of anaphora. Responsibilities of this
layer include determining what anaphoric
</listItem>
<bodyText confidence="0.9789693125">
phenomena are to be resolved in the current
experiment, determining what anaphora res-
olution technique(s) will be used, and de-
termining what updates to make to the DC.
Even though the modules are independent of
the input format, they are still somewhat de-
pendent on the availability of DE features.
If a feature needed by a particular resolution
module was not created in a particular ex-
periment, the module must either do without
it or give up and exit. This layer&apos;s output is
an updated DC with anaphoric elements re-
solved to their referents. If labeled training
data is available, this layer is also responsi-
ble for calculating the accuracy of anaphora
resolution.
</bodyText>
<subsectionHeader confidence="0.999371">
2.2 Benefits of this design
</subsectionHeader>
<bodyText confidence="0.9999345">
This strict delineation of responsibilities between
layers provides the following advantages:
</bodyText>
<listItem confidence="0.9989303">
• Once a translation layer is written for a
specific type of input, all the implemented
anaphora resolution techniques are immedi-
ately available and can be compared.
• Different models of DC construction can be
compared using the same underlying refer-
ence resolution modules.
• It is simple to activate or deactivate each
component of the system for a particular ex-
periment.
</listItem>
<sectionHeader confidence="0.992255" genericHeader="method">
3 Implementation
</sectionHeader>
<bodyText confidence="0.9996132">
We used this architecture to implement a testing
platform for pronoun resolution. Several experi-
ments were run to demonstrate the flexibility of
the architecture. The purpose of this paper is not
to compare the pronoun resolution results for the
techniques we implemented, so pronoun resolu-
tion accuracy of particular techniques will not be
discussed here.&apos; Instead, our implementation is
described to provide some examples of how the
architecture can be put to use.
</bodyText>
<subsectionHeader confidence="0.995214">
3.1 Supervisor layer
</subsectionHeader>
<bodyText confidence="0.9913198">
The supervisor layer controls which modules
within layers 2 and 3 execute for a particular ex-
periment. We created two different supervisor
&apos;See (Byron and Allen, 1999; Tetreault, 1999) for results
of pronoun resolution experiments run within the testbed.
</bodyText>
<page confidence="0.98692">
230
</page>
<bodyText confidence="0.964568333333334">
Proceedings of EACL &apos;99
modules in the testbed. One of them simply reads
a configuration file with runtime flags hard-coded
by the user. This allows the user to explicitly con-
trol which parts of the system execute, and will be
used when a final reference resolution techniques
is chosen for integration into the TRIPS system
parser (Ferguson and Allen, 1998).
The second supervisor layer was coded as a ge-
netic algorithm (Byron and Allen, 1999). In this
module, the selection of translation layer modules
to execute was hard-coded for the evaluation cor-
pus, but pronoun resolution modules and meth-
ods for combining their results were activated and
de-activated by the genetic algorithm. Using pro-
noun resolution accuracy as the fitness function,
the algorithm learned an optimal combination of
pronoun resolution modules.
</bodyText>
<subsectionHeader confidence="0.99954">
3.2 Translation layer
</subsectionHeader>
<bodyText confidence="0.999948733333334">
Translation layer modules are responsible for all
syntactic and semantic analysis of the input text.
There are a number of design features that must
be controlled in this layer, such as how the dis-
course structure affects antecedent accessibility
and which surface constituents trigger DEs. All
these design decisions should be implemented as
independent modules so that they can be turned
on or off for particular experiments.
Our experiments created translation modules
for two evaluation corpora: written news sto-
ries from the Penn Treebank corpus (Marcus et
al., 1993) and spoken task-oriented dialogues
from the TRAINS93 corpus (Heeman and Allen,
1995). The input format and features added onto
DEs from these two corpora are very different,
but by encapsulating the translation layer, the
same pronoun resolution code can be used for
both domains. In both of our experiments only
simple noun phrases in the surface form triggered
DEs.
Treebank texts contain complete structural
parsers, POS tags, and annotation of the
antecedents of definite pronouns (added by
Ge et al. 1998). Because of the thorough syntac-
tic information, DEs can be attributed with ex-
plicit phrase structure information. This corpus
contains unconstrained news stories, so semantic
type information is not available. The Treebank
translator module adds the following features to
</bodyText>
<listItem confidence="0.972640090909091">
each DE:
1. Whether its surface constituent is contained
in reported speech;
2. A list of parent nodes containing its surface
constituent in the parse tree. Each node&apos;s
unique identifier encodes the phrase type
(i.e. VB, NP, ADJP);
3. Whether the surface constituent is in the sec-
ond half of a compound sentence;
4. The referent&apos;s animacy and gender from a
hand-coded agreement-feature database.
</listItem>
<bodyText confidence="0.995721090909091">
A second translation module was created for a
selection of TRAINS 93 dialogue transcripts. The
input was POS-tagged words with no structural
analysis. Other information, such as basic punc-
tuation and whether each pronoun was in a main
or subordinate clause, had previously been hand-
annotated onto the transcripts. We also created an
interface to the semantic type hierarchy within the
Trains system and added semantic information to
the DEs.
Common DE attributes for both corpora:
</bodyText>
<listItem confidence="0.9984021">
1. Plural or singular numeric agreement;
2. Whether the entity is contained in the subject
of the matrix clause;
3. Linear position of the surface constituent;
4. Whether its surface constituent is definite or
indefinite;
5. Whether its surface constituent is contained
in quoted speech;
6. For pronoun DEs, the id of the correct an-
tecedent (used for evaluation).
</listItem>
<subsectionHeader confidence="0.997463">
3.3 Anaphora resolution layer
</subsectionHeader>
<bodyText confidence="0.997277333333333">
Modules within this layer can be coded to resolve
a variety of anaphoric phenomena in a variety of
ways. For example, a particular experiment may
be concerned only with resolving pronouns or it
might also require determination of coreference
between definite noun phrases. This layer is rem-
iniscent of the independent anaphora resolution
modules in the Lucy system (Rich and LuperFoy,
1988), except that modules in that system were
not designed to be easily turned on or off.
For our testbed, we implemented a variety of
pronoun resolution techniques. Each technique
</bodyText>
<page confidence="0.99398">
231
</page>
<table confidence="0.995436785714286">
Proceedings of EACL &apos;99
Pronoun resolution module Activated for Activated for
Treebank TRAINS93
Baseline most-recent technique that chooses closest entity to the left of the pronoun X X
Hobbs naive algorithm X
Choose most recent entity that matches sub-categorization restrictions on the verb X
Strube&apos;s s-list algorithm (Strube, 1998) X X
Boost salience for the first entity in each sentence X X
Decrease salience for entities in prepositional phrases or relative clauses X
Increase the salience for non-subject entities for demonstrative pronoun resolution (Schiffman, 1985) X
Decrease salience for indefinite entities X X
Decrease salience for entities in reported speech X
Increase the salience of entities in the subject of the previous sentence X X
Increase the salience of entities whose surface form is pronominal X X
</table>
<tableCaption confidence="0.999818">
Table 1: Pronoun resolution modules used in our experiments
</tableCaption>
<bodyText confidence="0.999531294117647">
can run in isolation or with the addition of meta-
modules that combine the output of multiple tech-
niques. We implemented meta-modules to in-
terface to the genetic algorithm driver and to
combine different salience factors into an over-
all score (similar to (Carbonell and Brown, 1988;
Mitkov, 1998)). Table 1 describes the pronoun
resolution techniques implemented at this point,
and shows whether they are activated for the
Treebank and the TRAINS93 experiments. Al-
though each module could run for both experi-
ments without error, if the features a particular
module uses in the DE were not available, we
simply de-activated the module. When we mi-
grate the TRIPS system to a new domain this
year, all these pronoun resolution methods will be
available for comparison.
</bodyText>
<sectionHeader confidence="0.999089" genericHeader="method">
4 Summary
</sectionHeader>
<bodyText confidence="0.999929555555556">
This paper has described a framework for ref-
erence resolution that separates details of the
syntactic/semantic interpretation process from
anaphora resolution in a plug-and-play architec-
ture. The approach is not revolutionary, it sim-
ply demonstrates how to apply known software
engineering techniques to the reference resolu-
tion component of a natural language understand-
ing system. The framework enables compari-
son of baseline techniques across corpora and al-
lows for easy modification of an implemented
system when the sources of information available
to anaphora resolution change. The architecture
facilitates experimentation on different mixtures
of discourse context and anaphora resolution al-
gorithms. Modules written within this framework
are portable across domains and language gen-
res.
</bodyText>
<sectionHeader confidence="0.999428" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998819525">
Donna K. Byron and James F. Allen. 1999. A genetic
algorithms approach to pronoun resolution. Techni-
cal Report 713, Department of Computer Science,
University of Rochester.
Jaime G. Carbonell and R.D. Brown. 1988. Anaphora
resolution: a multy-strategy approach. In COL-
ING &apos;88, pages 96-101.
George Ferguson and James F. Allen. 1998. Trips:
An intelligent integrated problem-solving assistant.
In Proceedings of AAAI &apos;98.
Niyu Ge, John Hale, and Eugene Charniak. 1998. A
statistical approach to anaphora resolution. In Pro-
ceedings of the Sixth Workshop on Very Large Cor-
pora.
Peter A. Heeman and James F. Allen. 1995. The
Trains spoken dialog corpus. CD-ROM, Linguis-
tics Data Consortium.
Jerry Hobbs. 1986. Resolving pronoun reference. In
Readings in Natural Language Processing. Morgan
Kaufmann.
Mitchell P. Marcus, Beatrice Santorini, and Mary Ann
Marcinkiewicz. 1993. Building a large annotated
corpus of english: The Penn Treebank. Computa-
tional Linguistics, I 9(2): 313-330.
Ruslan Mitkov. 1998. Robust pronoun resolution with
limited knowledge. In Proceedings of ACL &apos;98,
pages 869-875.
Elaine Rich and Susann LuperFoy. 1988. An archi-
tecture for anaphora resolution. In Conference on
Applied NLP, pages 18-24.
Rebecca Schiffman. 1985. Discourse constraints on
&apos;it&apos; and &apos;that&apos;: A study of language use in career-
counseling interviews. Ph.D. thesis, University of
Chicago.
Michael Strube. 1998. Never look back: An alterna-
tive to centering. In Proceedings of ACL &apos;98, pages
1251-1257.
Joel R. Tetreault. 1999. Analysis of syntax-based
pronoun resolution methods. In Proceedings of
ACL &apos;99.
</reference>
<page confidence="0.994783">
232
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.341185">
<note confidence="0.505052">Proceedings of EACL &apos;99</note>
<title confidence="0.999605">A Flexible Architecture for Reference Resolution</title>
<author confidence="0.999813">K Byron R Tetreault</author>
<affiliation confidence="0.999914">Department of Computer Science University of Rochester</affiliation>
<address confidence="0.999353">Rochester NY 14627, U.S.A.</address>
<email confidence="0.999858">dbyron/tetreaul@cs.rochester.edu</email>
<abstract confidence="0.974984923076923">This paper describes an architecture for performing anaphora resolution in a flexible way. Systems which conform to these guidelines are wellencapsulated and portable, and can be used to compare anaphora resolutechniques for new language unapplications. Our plementation of the architecture in a pronoun resolution testing platform demonstrates the flexibility of the approach.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Donna K Byron</author>
<author>James F Allen</author>
</authors>
<title>A genetic algorithms approach to pronoun resolution.</title>
<date>1999</date>
<tech>Technical Report 713,</tech>
<institution>Department of Computer Science, University of Rochester.</institution>
<contexts>
<context position="6893" citStr="Byron and Allen, 1999" startWordPosition="1059" endWordPosition="1062">ement a testing platform for pronoun resolution. Several experiments were run to demonstrate the flexibility of the architecture. The purpose of this paper is not to compare the pronoun resolution results for the techniques we implemented, so pronoun resolution accuracy of particular techniques will not be discussed here.&apos; Instead, our implementation is described to provide some examples of how the architecture can be put to use. 3.1 Supervisor layer The supervisor layer controls which modules within layers 2 and 3 execute for a particular experiment. We created two different supervisor &apos;See (Byron and Allen, 1999; Tetreault, 1999) for results of pronoun resolution experiments run within the testbed. 230 Proceedings of EACL &apos;99 modules in the testbed. One of them simply reads a configuration file with runtime flags hard-coded by the user. This allows the user to explicitly control which parts of the system execute, and will be used when a final reference resolution techniques is chosen for integration into the TRIPS system parser (Ferguson and Allen, 1998). The second supervisor layer was coded as a genetic algorithm (Byron and Allen, 1999). In this module, the selection of translation layer modules to</context>
</contexts>
<marker>Byron, Allen, 1999</marker>
<rawString>Donna K. Byron and James F. Allen. 1999. A genetic algorithms approach to pronoun resolution. Technical Report 713, Department of Computer Science, University of Rochester.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jaime G Carbonell</author>
<author>R D Brown</author>
</authors>
<title>Anaphora resolution: a multy-strategy approach.</title>
<date>1988</date>
<booktitle>In COLING &apos;88,</booktitle>
<pages>96--101</pages>
<contexts>
<context position="12194" citStr="Carbonell and Brown, 1988" startWordPosition="1893" endWordPosition="1896">ronoun resolution (Schiffman, 1985) X Decrease salience for indefinite entities X X Decrease salience for entities in reported speech X Increase the salience of entities in the subject of the previous sentence X X Increase the salience of entities whose surface form is pronominal X X Table 1: Pronoun resolution modules used in our experiments can run in isolation or with the addition of metamodules that combine the output of multiple techniques. We implemented meta-modules to interface to the genetic algorithm driver and to combine different salience factors into an overall score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)). Table 1 describes the pronoun resolution techniques implemented at this point, and shows whether they are activated for the Treebank and the TRAINS93 experiments. Although each module could run for both experiments without error, if the features a particular module uses in the DE were not available, we simply de-activated the module. When we migrate the TRIPS system to a new domain this year, all these pronoun resolution methods will be available for comparison. 4 Summary This paper has described a framework for reference resolution that separates details of the syntactic/sem</context>
</contexts>
<marker>Carbonell, Brown, 1988</marker>
<rawString>Jaime G. Carbonell and R.D. Brown. 1988. Anaphora resolution: a multy-strategy approach. In COLING &apos;88, pages 96-101.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Ferguson</author>
<author>James F Allen</author>
</authors>
<title>Trips: An intelligent integrated problem-solving assistant.</title>
<date>1998</date>
<booktitle>In Proceedings of AAAI &apos;98.</booktitle>
<contexts>
<context position="7344" citStr="Ferguson and Allen, 1998" startWordPosition="1132" endWordPosition="1135">r layer The supervisor layer controls which modules within layers 2 and 3 execute for a particular experiment. We created two different supervisor &apos;See (Byron and Allen, 1999; Tetreault, 1999) for results of pronoun resolution experiments run within the testbed. 230 Proceedings of EACL &apos;99 modules in the testbed. One of them simply reads a configuration file with runtime flags hard-coded by the user. This allows the user to explicitly control which parts of the system execute, and will be used when a final reference resolution techniques is chosen for integration into the TRIPS system parser (Ferguson and Allen, 1998). The second supervisor layer was coded as a genetic algorithm (Byron and Allen, 1999). In this module, the selection of translation layer modules to execute was hard-coded for the evaluation corpus, but pronoun resolution modules and methods for combining their results were activated and de-activated by the genetic algorithm. Using pronoun resolution accuracy as the fitness function, the algorithm learned an optimal combination of pronoun resolution modules. 3.2 Translation layer Translation layer modules are responsible for all syntactic and semantic analysis of the input text. There are a n</context>
</contexts>
<marker>Ferguson, Allen, 1998</marker>
<rawString>George Ferguson and James F. Allen. 1998. Trips: An intelligent integrated problem-solving assistant. In Proceedings of AAAI &apos;98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Niyu Ge</author>
<author>John Hale</author>
<author>Eugene Charniak</author>
</authors>
<title>A statistical approach to anaphora resolution.</title>
<date>1998</date>
<booktitle>In Proceedings of the Sixth Workshop on Very Large Corpora.</booktitle>
<contexts>
<context position="8913" citStr="Ge et al. 1998" startWordPosition="1376" endWordPosition="1379">les for two evaluation corpora: written news stories from the Penn Treebank corpus (Marcus et al., 1993) and spoken task-oriented dialogues from the TRAINS93 corpus (Heeman and Allen, 1995). The input format and features added onto DEs from these two corpora are very different, but by encapsulating the translation layer, the same pronoun resolution code can be used for both domains. In both of our experiments only simple noun phrases in the surface form triggered DEs. Treebank texts contain complete structural parsers, POS tags, and annotation of the antecedents of definite pronouns (added by Ge et al. 1998). Because of the thorough syntactic information, DEs can be attributed with explicit phrase structure information. This corpus contains unconstrained news stories, so semantic type information is not available. The Treebank translator module adds the following features to each DE: 1. Whether its surface constituent is contained in reported speech; 2. A list of parent nodes containing its surface constituent in the parse tree. Each node&apos;s unique identifier encodes the phrase type (i.e. VB, NP, ADJP); 3. Whether the surface constituent is in the second half of a compound sentence; 4. The referen</context>
</contexts>
<marker>Ge, Hale, Charniak, 1998</marker>
<rawString>Niyu Ge, John Hale, and Eugene Charniak. 1998. A statistical approach to anaphora resolution. In Proceedings of the Sixth Workshop on Very Large Corpora.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter A Heeman</author>
<author>James F Allen</author>
</authors>
<title>The Trains spoken dialog corpus.</title>
<date>1995</date>
<journal>CD-ROM, Linguistics Data Consortium.</journal>
<contexts>
<context position="8487" citStr="Heeman and Allen, 1995" startWordPosition="1307" endWordPosition="1310">onsible for all syntactic and semantic analysis of the input text. There are a number of design features that must be controlled in this layer, such as how the discourse structure affects antecedent accessibility and which surface constituents trigger DEs. All these design decisions should be implemented as independent modules so that they can be turned on or off for particular experiments. Our experiments created translation modules for two evaluation corpora: written news stories from the Penn Treebank corpus (Marcus et al., 1993) and spoken task-oriented dialogues from the TRAINS93 corpus (Heeman and Allen, 1995). The input format and features added onto DEs from these two corpora are very different, but by encapsulating the translation layer, the same pronoun resolution code can be used for both domains. In both of our experiments only simple noun phrases in the surface form triggered DEs. Treebank texts contain complete structural parsers, POS tags, and annotation of the antecedents of definite pronouns (added by Ge et al. 1998). Because of the thorough syntactic information, DEs can be attributed with explicit phrase structure information. This corpus contains unconstrained news stories, so semanti</context>
</contexts>
<marker>Heeman, Allen, 1995</marker>
<rawString>Peter A. Heeman and James F. Allen. 1995. The Trains spoken dialog corpus. CD-ROM, Linguistics Data Consortium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry Hobbs</author>
</authors>
<title>Resolving pronoun reference.</title>
<date>1986</date>
<booktitle>In Readings in Natural Language Processing.</booktitle>
<publisher>Morgan Kaufmann.</publisher>
<contexts>
<context position="1019" citStr="Hobbs 1986" startWordPosition="150" endWordPosition="151">be used to compare anaphora resolution techniques for new language understanding applications. Our implementation of the architecture in a pronoun resolution testing platform demonstrates the flexibility of the approach. 1 Introduction When building natural language understanding systems, choosing the best technique for anaphora resolution is a challenging task. The system builder must decide whether to adopt an existing technique or design a new approach. A huge variety of techniques are described in the literature, many of them achieving high success rates on their own evaluation texts (cf. Hobbs 1986; Strube 1998; Mitkov 1998). Each technique makes different assumptions about the data available to reference resolution, for example, some assume perfect parses, others assume only POS-tagged input, some assume semantic information is available, etc. The chances are high that no published technique will exactly match the data available to a particular system&apos;s reference resolution component, so it may The authors thank James Allen for help on this project, as well as the anonymous reviewers for helpful comments on the paper. This material is based on work supported by USAF/Rome Labs contract </context>
</contexts>
<marker>Hobbs, 1986</marker>
<rawString>Jerry Hobbs. 1986. Resolving pronoun reference. In Readings in Natural Language Processing. Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Beatrice Santorini</author>
<author>Mary Ann Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of english: The Penn Treebank. Computational Linguistics,</title>
<date>1993</date>
<journal>I</journal>
<volume>9</volume>
<issue>2</issue>
<pages>313--330</pages>
<contexts>
<context position="8402" citStr="Marcus et al., 1993" startWordPosition="1295" endWordPosition="1298">onoun resolution modules. 3.2 Translation layer Translation layer modules are responsible for all syntactic and semantic analysis of the input text. There are a number of design features that must be controlled in this layer, such as how the discourse structure affects antecedent accessibility and which surface constituents trigger DEs. All these design decisions should be implemented as independent modules so that they can be turned on or off for particular experiments. Our experiments created translation modules for two evaluation corpora: written news stories from the Penn Treebank corpus (Marcus et al., 1993) and spoken task-oriented dialogues from the TRAINS93 corpus (Heeman and Allen, 1995). The input format and features added onto DEs from these two corpora are very different, but by encapsulating the translation layer, the same pronoun resolution code can be used for both domains. In both of our experiments only simple noun phrases in the surface form triggered DEs. Treebank texts contain complete structural parsers, POS tags, and annotation of the antecedents of definite pronouns (added by Ge et al. 1998). Because of the thorough syntactic information, DEs can be attributed with explicit phra</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>Mitchell P. Marcus, Beatrice Santorini, and Mary Ann Marcinkiewicz. 1993. Building a large annotated corpus of english: The Penn Treebank. Computational Linguistics, I 9(2): 313-330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ruslan Mitkov</author>
</authors>
<title>Robust pronoun resolution with limited knowledge.</title>
<date>1998</date>
<booktitle>In Proceedings of ACL &apos;98,</booktitle>
<pages>869--875</pages>
<contexts>
<context position="1046" citStr="Mitkov 1998" startWordPosition="154" endWordPosition="155">ra resolution techniques for new language understanding applications. Our implementation of the architecture in a pronoun resolution testing platform demonstrates the flexibility of the approach. 1 Introduction When building natural language understanding systems, choosing the best technique for anaphora resolution is a challenging task. The system builder must decide whether to adopt an existing technique or design a new approach. A huge variety of techniques are described in the literature, many of them achieving high success rates on their own evaluation texts (cf. Hobbs 1986; Strube 1998; Mitkov 1998). Each technique makes different assumptions about the data available to reference resolution, for example, some assume perfect parses, others assume only POS-tagged input, some assume semantic information is available, etc. The chances are high that no published technique will exactly match the data available to a particular system&apos;s reference resolution component, so it may The authors thank James Allen for help on this project, as well as the anonymous reviewers for helpful comments on the paper. This material is based on work supported by USAF/Rome Labs contract F30602-95-1-0025, ONR grant</context>
<context position="12209" citStr="Mitkov, 1998" startWordPosition="1897" endWordPosition="1898">n, 1985) X Decrease salience for indefinite entities X X Decrease salience for entities in reported speech X Increase the salience of entities in the subject of the previous sentence X X Increase the salience of entities whose surface form is pronominal X X Table 1: Pronoun resolution modules used in our experiments can run in isolation or with the addition of metamodules that combine the output of multiple techniques. We implemented meta-modules to interface to the genetic algorithm driver and to combine different salience factors into an overall score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)). Table 1 describes the pronoun resolution techniques implemented at this point, and shows whether they are activated for the Treebank and the TRAINS93 experiments. Although each module could run for both experiments without error, if the features a particular module uses in the DE were not available, we simply de-activated the module. When we migrate the TRIPS system to a new domain this year, all these pronoun resolution methods will be available for comparison. 4 Summary This paper has described a framework for reference resolution that separates details of the syntactic/semantic interpret</context>
</contexts>
<marker>Mitkov, 1998</marker>
<rawString>Ruslan Mitkov. 1998. Robust pronoun resolution with limited knowledge. In Proceedings of ACL &apos;98, pages 869-875.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elaine Rich</author>
<author>Susann LuperFoy</author>
</authors>
<title>An architecture for anaphora resolution.</title>
<date>1988</date>
<booktitle>In Conference on Applied NLP,</booktitle>
<pages>18--24</pages>
<contexts>
<context position="10847" citStr="Rich and LuperFoy, 1988" startWordPosition="1680" endWordPosition="1683">4. Whether its surface constituent is definite or indefinite; 5. Whether its surface constituent is contained in quoted speech; 6. For pronoun DEs, the id of the correct antecedent (used for evaluation). 3.3 Anaphora resolution layer Modules within this layer can be coded to resolve a variety of anaphoric phenomena in a variety of ways. For example, a particular experiment may be concerned only with resolving pronouns or it might also require determination of coreference between definite noun phrases. This layer is reminiscent of the independent anaphora resolution modules in the Lucy system (Rich and LuperFoy, 1988), except that modules in that system were not designed to be easily turned on or off. For our testbed, we implemented a variety of pronoun resolution techniques. Each technique 231 Proceedings of EACL &apos;99 Pronoun resolution module Activated for Activated for Treebank TRAINS93 Baseline most-recent technique that chooses closest entity to the left of the pronoun X X Hobbs naive algorithm X Choose most recent entity that matches sub-categorization restrictions on the verb X Strube&apos;s s-list algorithm (Strube, 1998) X X Boost salience for the first entity in each sentence X X Decrease salience for </context>
</contexts>
<marker>Rich, LuperFoy, 1988</marker>
<rawString>Elaine Rich and Susann LuperFoy. 1988. An architecture for anaphora resolution. In Conference on Applied NLP, pages 18-24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rebecca Schiffman</author>
</authors>
<title>Discourse constraints on &apos;it&apos; and &apos;that&apos;: A study of language use in careercounseling interviews.</title>
<date>1985</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Chicago.</institution>
<contexts>
<context position="11604" citStr="Schiffman, 1985" startWordPosition="1797" endWordPosition="1798">solution techniques. Each technique 231 Proceedings of EACL &apos;99 Pronoun resolution module Activated for Activated for Treebank TRAINS93 Baseline most-recent technique that chooses closest entity to the left of the pronoun X X Hobbs naive algorithm X Choose most recent entity that matches sub-categorization restrictions on the verb X Strube&apos;s s-list algorithm (Strube, 1998) X X Boost salience for the first entity in each sentence X X Decrease salience for entities in prepositional phrases or relative clauses X Increase the salience for non-subject entities for demonstrative pronoun resolution (Schiffman, 1985) X Decrease salience for indefinite entities X X Decrease salience for entities in reported speech X Increase the salience of entities in the subject of the previous sentence X X Increase the salience of entities whose surface form is pronominal X X Table 1: Pronoun resolution modules used in our experiments can run in isolation or with the addition of metamodules that combine the output of multiple techniques. We implemented meta-modules to interface to the genetic algorithm driver and to combine different salience factors into an overall score (similar to (Carbonell and Brown, 1988; Mitkov, </context>
</contexts>
<marker>Schiffman, 1985</marker>
<rawString>Rebecca Schiffman. 1985. Discourse constraints on &apos;it&apos; and &apos;that&apos;: A study of language use in careercounseling interviews. Ph.D. thesis, University of Chicago.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Strube</author>
</authors>
<title>Never look back: An alternative to centering.</title>
<date>1998</date>
<booktitle>In Proceedings of ACL &apos;98,</booktitle>
<pages>1251--1257</pages>
<contexts>
<context position="1032" citStr="Strube 1998" startWordPosition="152" endWordPosition="153">ompare anaphora resolution techniques for new language understanding applications. Our implementation of the architecture in a pronoun resolution testing platform demonstrates the flexibility of the approach. 1 Introduction When building natural language understanding systems, choosing the best technique for anaphora resolution is a challenging task. The system builder must decide whether to adopt an existing technique or design a new approach. A huge variety of techniques are described in the literature, many of them achieving high success rates on their own evaluation texts (cf. Hobbs 1986; Strube 1998; Mitkov 1998). Each technique makes different assumptions about the data available to reference resolution, for example, some assume perfect parses, others assume only POS-tagged input, some assume semantic information is available, etc. The chances are high that no published technique will exactly match the data available to a particular system&apos;s reference resolution component, so it may The authors thank James Allen for help on this project, as well as the anonymous reviewers for helpful comments on the paper. This material is based on work supported by USAF/Rome Labs contract F30602-95-1-0</context>
<context position="11363" citStr="Strube, 1998" startWordPosition="1761" endWordPosition="1762">scent of the independent anaphora resolution modules in the Lucy system (Rich and LuperFoy, 1988), except that modules in that system were not designed to be easily turned on or off. For our testbed, we implemented a variety of pronoun resolution techniques. Each technique 231 Proceedings of EACL &apos;99 Pronoun resolution module Activated for Activated for Treebank TRAINS93 Baseline most-recent technique that chooses closest entity to the left of the pronoun X X Hobbs naive algorithm X Choose most recent entity that matches sub-categorization restrictions on the verb X Strube&apos;s s-list algorithm (Strube, 1998) X X Boost salience for the first entity in each sentence X X Decrease salience for entities in prepositional phrases or relative clauses X Increase the salience for non-subject entities for demonstrative pronoun resolution (Schiffman, 1985) X Decrease salience for indefinite entities X X Decrease salience for entities in reported speech X Increase the salience of entities in the subject of the previous sentence X X Increase the salience of entities whose surface form is pronominal X X Table 1: Pronoun resolution modules used in our experiments can run in isolation or with the addition of meta</context>
</contexts>
<marker>Strube, 1998</marker>
<rawString>Michael Strube. 1998. Never look back: An alternative to centering. In Proceedings of ACL &apos;98, pages 1251-1257.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joel R Tetreault</author>
</authors>
<title>Analysis of syntax-based pronoun resolution methods.</title>
<date>1999</date>
<booktitle>In Proceedings of ACL &apos;99.</booktitle>
<contexts>
<context position="6911" citStr="Tetreault, 1999" startWordPosition="1063" endWordPosition="1064">m for pronoun resolution. Several experiments were run to demonstrate the flexibility of the architecture. The purpose of this paper is not to compare the pronoun resolution results for the techniques we implemented, so pronoun resolution accuracy of particular techniques will not be discussed here.&apos; Instead, our implementation is described to provide some examples of how the architecture can be put to use. 3.1 Supervisor layer The supervisor layer controls which modules within layers 2 and 3 execute for a particular experiment. We created two different supervisor &apos;See (Byron and Allen, 1999; Tetreault, 1999) for results of pronoun resolution experiments run within the testbed. 230 Proceedings of EACL &apos;99 modules in the testbed. One of them simply reads a configuration file with runtime flags hard-coded by the user. This allows the user to explicitly control which parts of the system execute, and will be used when a final reference resolution techniques is chosen for integration into the TRIPS system parser (Ferguson and Allen, 1998). The second supervisor layer was coded as a genetic algorithm (Byron and Allen, 1999). In this module, the selection of translation layer modules to execute was hard-</context>
</contexts>
<marker>Tetreault, 1999</marker>
<rawString>Joel R. Tetreault. 1999. Analysis of syntax-based pronoun resolution methods. In Proceedings of ACL &apos;99.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>