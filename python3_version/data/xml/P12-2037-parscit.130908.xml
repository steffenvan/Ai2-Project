<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000179">
<title confidence="0.997821">
Automatically Mining Question Reformulation Patterns from
Search Log Data
</title>
<author confidence="0.998479">
Xiaobing Xue∗ Yu Tao∗
</author>
<affiliation confidence="0.992898">
Univ. of Massachusetts, Amherst Univ. of Science and Technology of China
</affiliation>
<email confidence="0.988859">
xuexb@cs.umass.edu v-yutao@microsoft.com
</email>
<author confidence="0.99886">
Daxin Jiang Hang Li
</author>
<affiliation confidence="0.98018">
Microsoft Research Asia
</affiliation>
<email confidence="0.998725">
{djiang,hangli}@microsoft.com
</email>
<sectionHeader confidence="0.998602" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998946538461538">
Natural language questions have become pop-
ular in web search. However, various ques-
tions can be formulated to convey the same
information need, which poses a great chal-
lenge to search systems. In this paper, we au-
tomatically mined 5w1h question reformula-
tion patterns from large scale search log data.
The question reformulations generated from
these patterns are further incorporated into the
retrieval model. Experiments show that us-
ing question reformulation patterns can sig-
nificantly improve the search performance of
natural language questions.
</bodyText>
<sectionHeader confidence="0.999516" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999605625">
More and more web users tend to use natural lan-
guage questions as queries for web search. Some
commercial natural language search engines such as
InQuira and Ask have also been developed to answer
this type of queries. One major challenge is that var-
ious questions can be formulated for the same infor-
mation need. Table 1 shows some alternative expres-
sions for the question “how far is it from Boston to
Seattle”. It is difficult for search systems to achieve
satisfactory retrieval performance without consider-
ing these alternative expressions.
In this paper, we propose a method of automat-
ically mining 5w1h question1 reformulation pat-
terns to improve the search relevance of 5w1h ques-
tions. Question reformulations represent the alter-
native expressions for 5w1h questions. A question
</bodyText>
<note confidence="0.734063666666667">
∗Contribution during internship at Microsoft Research Asia
15w1h questions start with “Who”, “What”, “Where”,
“When”, “Why” and “How”.
</note>
<tableCaption confidence="0.8018235">
Table 1: Alternative expressions for the original question
Original Question:
how far is it from Boston to Seattle
Alternative Expressions:
</tableCaption>
<note confidence="0.52359125">
how many miles is it from Boston to Seattle
distance from Boston to Seattle
Boston to Seattle
how long does it take to drive from Boston to Seattle
</note>
<bodyText confidence="0.999963692307692">
reformulation pattern generalizes a set of similar
question reformulations that share the same struc-
ture. For example, users may ask similar questions
“how far is it from X1 to X2” where X1 and X2
represent some other cities besides Boston and Seat-
tle. Then, similar question reformulations as in Ta-
ble 1 will be generated with the city names changed.
These patterns increase the coverage of the system
by handling the queries that did not appear before
but share similar structures as previous queries.
Using reformulation patterns as the key concept,
we propose a question reformulation framework.
First, we mine the question reformulation patterns
from search logs that record users’ reformulation
behavior. Second, given a new question, we use
the most relevant reformulation patterns to generate
question reformulations and each of the reformula-
tions is associated with its probability. Third, the
original question and these question reformulations
are then combined together for retrieval.
The contributions of this paper are summarized as
two folds. First, we propose a simple yet effective
approach to automatically mine 5w1h question re-
formulation patterns. Second, we conduct compre-
hensive studies in improving the search performance
of 5w1h questions using the mined patterns.
</bodyText>
<page confidence="0.981052">
187
</page>
<note confidence="0.851253">
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 187–192,
Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics
</note>
<figure confidence="0.528541">
ffline Phase
</figure>
<figureCaption confidence="0.999486">
Figure 1: The framework of reformulating questions.
</figureCaption>
<sectionHeader confidence="0.999716" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999886310344828">
In the Natural Language Processing (NLP) area, dif-
ferent expressions that convey the same meaning
are referred as paraphrases (Lin and Pantel, 2001;
Barzilay and McKeown, 2001; Pang et al., 2003;
Pas¸ca and Dienes, 2005; Bannard and Callison-
Burch, 2005; Bhagat and Ravichandran, 2008;
Callison-Burch, 2008; Zhao et al., 2008). Para-
phrases have been studied in a variety of NLP appli-
cations such as machine translation (Kauchak and
Barzilay, 2006; Callison-Burch et al., 2006), ques-
tion answering (Ravichandran and Hovy, 2002) and
document summarization (McKeown et al., 2002).
Yet, little research has considered improving web
search performance using paraphrases.
Query logs have become an important resource
for many NLP applications such as class and at-
tribute extraction (Pas¸ca and Van Durme, 2008),
paraphrasing (Zhao et al., 2010) and language mod-
eling (Huang et al., 2010). Little research has been
conducted to automatically mine 5w1h question re-
formulation patterns from query logs.
Recently, query reformulation (Boldi et al., 2009;
Jansen et al., 2009) has been studied in web search.
Different techniques have been developed for query
segmentation (Bergsma and Wang, 2007; Tan and
Peng, 2008) and query substitution (Jones et al.,
2006; Wang and Zhai, 2008). Yet, most previous
research focused on keyword queries without con-
sidering 5w1h questions.
</bodyText>
<sectionHeader confidence="0.900328" genericHeader="method">
3 Mining Question Reformulation
</sectionHeader>
<subsectionHeader confidence="0.843242">
Patterns for Web Search
</subsectionHeader>
<bodyText confidence="0.9875825">
Our framework consists of three major components,
which is illustrated in Fig. 1.
</bodyText>
<tableCaption confidence="0.968478">
Table 2: Question reformulation patterns generated for
the query pair (“how far is it from Boston to Seattle”
,“distance from Boston to Seattle”).
</tableCaption>
<note confidence="0.94565525">
S1 = {Boston}:(“how far is it from X1 to Seattle”
,“distance from X1 to Seattle”)
S2 = {Seattle}:(“how far is it from Boston to X1”
,“distance from Boston to X1”)
</note>
<bodyText confidence="0.4582125">
S3 = {Boston, Seattle}:(“how far is it from X1 to X2”
,“distance from X1 to X2”)
</bodyText>
<subsectionHeader confidence="0.999617">
3.1 Generating Reformulation Patterns
</subsectionHeader>
<bodyText confidence="0.99988875">
From the search log, we extract all successive query
pairs issued by the same user within a certain time
period where the first query is a 5w1h question. In
such query pair, the second query is considered as
a question reformulation. Our method takes these
query pairs, i.e. Set = {(q,qr)}, as the input and
outputs a pattern base consisting of 5w1h question
reformulation patterns, i.e. P = {(p, pr)}). Specif-
ically, for each query pair (q, qr), we first collect all
common words between q and qr except for stop-
words ST2, where CW = {w|w ∈ q, w ∈ q′, w ∈�
ST}. For any non-empty subset Si of CW, the
words in Si are replaced as slots in q and qr to con-
struct a reformulation pattern. Table 2 shows exam-
ples of question reformulation patterns. Finally, the
patterns observed in many different query pairs are
kept. In other words, we rely on the frequency of a
pattern to filter noisy patterns. Generating patterns
using more NLP features such as the parsing infor-
mation will be studied in the future work.
</bodyText>
<subsectionHeader confidence="0.99962">
3.2 Generating Question Reformulations
</subsectionHeader>
<bodyText confidence="0.995949066666667">
We describe how to generate a set of question refor-
mulations {qnew
r } for an unseen question qnew.
First, we search P = {(p, pr)} to find all ques-
tion reformulation patterns where p matches qnew.
Then, we pick the best question pattern p* accord-
ing to the number of prefix words and the total num-
ber of words in a pattern. We select the pattern that
has the most prefix words, since this pattern is more
likely to have the same information as qnew. If sev-
eral patterns have the same number of prefix words,
we use the total number of words to break the tie.
After picking the best question pattern p*, we fur-
ther rank all question reformulation patterns con-
taining p*, i.e. (p*, pr), according to Eq. 1.
</bodyText>
<footnote confidence="0.8332615">
2Stopwords refer to the function words that have little mean-
ing by themselves, such as “the”, “a”, “an”, “that” and “those”.
</footnote>
<figure confidence="0.999186363636364">
New Question
qnew
Set (q,qr)
nline Phase
Search
Log
Generating
Question
Reformulations
Generating
Reformulation
Patterns
Question
Reformulation
qr new
Retrieval
Model
P (p,pr)
Pattern
Base
Retrieved
Documents
</figure>
<page confidence="0.977134">
188
</page>
<tableCaption confidence="0.999614">
Table 3: Examples of the question reformulations and their corresponding reformulation patterns
</tableCaption>
<bodyText confidence="0.662466333333333">
qnew: how good is the eden pure air system qnew: how to market a restaurant
p⋆: how good is the X p⋆: how to market a X
qnew pr qnew pr
r r
eden pure air system X marketing a restaurant marketing a X
eden pure air system review X review how to promote a restaurant how to promote a X
eden pure air system reviews X reviews how to sell a restaurant how to sell a X
rate the eden pure air system rate the X how to advertise a restaurant how to advertise a X
reviews on the eden pure air system reviews on the X restaurant marketing X marketing
</bodyText>
<equation confidence="0.998074">
P(pr|p⋆) = f(p⋆, pr) (1)
E&amp;quot; f(p⋆, p′r)
</equation>
<bodyText confidence="0.926178285714286">
Finally, we generate k question reformulations
qnew
r by applying the top k question reformulation
patterns containing p⋆. The probability P(pr|p⋆) as-
sociated with the pattern (p⋆, pr) is assigned to the
corresponding question reformulation qnew
r.
</bodyText>
<subsectionHeader confidence="0.938289">
3.3 Retrieval Model
</subsectionHeader>
<bodyText confidence="0.99387775">
Given the original question qnew and k question re-
formulations {qnew
r }, the query distribution model
(Xue and Croft, 2010) (denoted as QDist) is adopted
to combine qnew and {qnew
r } using their associated
probabilities. The retrieval score of the document D,
i.e. score(qnew, D), is calculated as follows:
</bodyText>
<equation confidence="0.999595">
score(qnew, D) = A log P(qnew|D)
k
+(1 − A) P(pri|p⋆) log P(qnew ri|D) (2)
i=1
</equation>
<bodyText confidence="0.999083">
In Eq. 2, A is a parameter that indicates the prob-
ability assigned to the original query. P(pri|p⋆) is
the probability assigned to qnew
ri . P(qnew|D) and
P(q′|D) are calculated using the language model
(Ponte and Croft, 1998; Zhai and Lafferty, 2001).
</bodyText>
<sectionHeader confidence="0.999818" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999960444444444">
A large scale search log from a commercial search
engine (2011.1-2011.6) is used in experiments.
From the search log, we extract all successive query
pairs issued by the same user within 30 minutes
(Boldi et al., 2008)3 where the first query is a 5w1h
question. Finally, we extracted 6,680,278 question
reformulation patterns.
For the retrieval experiments, we randomly sam-
ple 10,000 natural language questions as queries
</bodyText>
<footnote confidence="0.7671025">
3In web search, queries issued within 30 minutes are usually
considered having the same information need.
</footnote>
<tableCaption confidence="0.985339">
Table 4: Retrieval Performance of using question refor-
mulations. ⋆ denotes significantly different with Orig.
</tableCaption>
<table confidence="0.996253">
NDCG@1 NDCG@3 NDCG@5
Orig 0.2946 0.2923 0.2991
QDist 0.3032⋆ 0.2991⋆ 0.3067⋆
</table>
<bodyText confidence="0.99912">
from the search log before 2011. For each question,
we generate the top ten questions reformulations.
The Indri toolkit4 is used to implement the language
model. A web collection from a commercial search
engine is used for retrieval experiments. For each
question, the relevance judgments are provided by
human annotators. The standard NDCG@k is used
to measure performance.
</bodyText>
<subsectionHeader confidence="0.99826">
4.1 Examples and Performance
</subsectionHeader>
<bodyText confidence="0.999887133333334">
Table 3 shows examples of the generated questions
reformulations. Several interesting expressions are
generated to reformulate the original question.
We compare the retrieval performance of using
the question reformulations (QDist) with the perfor-
mance of using the original question (Orig) in Table
4. The parameter A of QDist is decided using ten-
fold cross validation. Two sided t-test are conducted
to measure significance.
Table 4 shows that using the question reformula-
tions can significantly improve the retrieval perfor-
mance of natural language questions. Note that, con-
sidering the scale of experiments (10,000 queries),
around 3% improvement with respect to NDCG is a
very interesting result for web search.
</bodyText>
<subsectionHeader confidence="0.994383">
4.2 Analysis
</subsectionHeader>
<bodyText confidence="0.9997646">
In this subsection, we analyze the results to better
understand the effect of question reformulations.
First, we report the performance of always pick-
ing the best question reformulation for each query
(denoted as Upper) in Table 5, which provides an
</bodyText>
<footnote confidence="0.972022">
4www.lemurproject.org/
</footnote>
<page confidence="0.999017">
189
</page>
<tableCaption confidence="0.999595">
Table 5: Performance of the upper bound.
</tableCaption>
<table confidence="0.99983175">
NDCG@1 NDCG@3 NDCG@5
Orig 0.2946 0.2923 0.2991
QDist 0.3032 0.2991 0.3067
Upper 0.3826 0.3588 0.3584
</table>
<tableCaption confidence="0.832227">
Table 6: Best reformulation within different positions.
</tableCaption>
<bodyText confidence="0.972661439024391">
top 1 within top 2 within top 3
49.2% 64.7% 75.4%
upper bound for the performance of the question re-
formulation. Table 5 shows that if we were able
to always picking the best question reformulation,
the performance of Orig could be improved by
around 30% (from 0.2926 to 0.3826 with respect to
NDCG@1). It indicates that we do generate some
high quality question reformulations.
Table 6 further reports the percent of those 10,000
queries where the best question reformulation can be
observed in the top 1 position, within the top 2 posi-
tions and within the top 3 positions, respectively.
Table 6 shows that for most queries, our method
successfully ranks the best reformulation within the
top 3 positions.
Second, we study the effect of different types
of question reformulations. We roughly divide the
question reformulations generated by our method
into five categories as shown in Table 7. For each
category, we report the percent of reformulations
which performance is bigger/smaller/equal with re-
spect to the original question.
Table 7 shows that the “more specific” reformula-
tions and the “equivalent” reformulations are more
likely to improve the original question. Reformu-
lations that make “morphological change” do not
have much effect on improving the original ques-
tion. “More general” and “not relevant” reformu-
lations usually decrease the performance.
Third, we conduct the error analysis on the ques-
tion reformulations that decrease the performance
of the original question. Three typical types of er-
rors are observed. First, some important words are
removed from the original question. For example,
“what is the role of corporate executives” is reformu-
lated as “corporate executives”. Second, the refor-
mulation is too specific. For example, “how to effec-
tively organize your classroom” is reformulated as
“how to effectively organize your elementary class-
room”. Third, some reformulations entirely change
</bodyText>
<tableCaption confidence="0.99607">
Table 7: Analysis of different types of reformulations.
</tableCaption>
<table confidence="0.999949166666667">
Type increase decrease same
Morphological change 11% 10% 79%
Equivalent meaning 32% 30% 38%
More specific/Add words 45% 39% 16%
More general/Remove words 38% 48% 14%
Not relevant 14% 72% 14%
</table>
<tableCaption confidence="0.9872695">
Table 8: Retrieval Performance of other query processing
techniques.
</tableCaption>
<table confidence="0.9985766">
NDCG@1 NDCG@3 NDCG@5
ORIG 0.2720 0.2937 0.3151
NoStop 0.2697 0.2893 0.3112
DropOne 0.2630 0.2888 0.3102
QDist 0.2978 0.3052 0.3250
</table>
<bodyText confidence="0.999809">
the meaning of the original question. For example,
“what is the adjective of anxiously” is reformulated
as “what is the noun of anxiously”.
Fourth, we compare our question reformulation
method with two long query processing techniques,
i.e. NoStop (Huston and Croft, 2010) and DropOne
(Balasubramanian et al., 2010). NoStop removes all
stopwords in the query and DropOne learns to drop
a single word from the query. The same query set as
Balasubramanian et al. (2010) is used. Table 8 re-
ports the retrieval performance of different methods.
Table 8 shows that both NoStop and DropOne per-
form worse than using the original question, which
indicates that the general techniques developed for
long queries are not appropriate for natural language
questions. On the other hand, our proposed method
outperforms all the baselines.
</bodyText>
<sectionHeader confidence="0.99648" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999170444444444">
Improving the search relevance of natural language
questions poses a great challenge for search systems.
We propose to automatically mine 5w1h question re-
formulation patterns from search log data. The ef-
fectiveness of the extracted patterns has been shown
on web search. These patterns are potentially useful
for many other applications, which will be studied in
the future work. How to automatically classify the
extracted patterns is also an interesting future issue.
</bodyText>
<sectionHeader confidence="0.991712" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.998905">
We would like to thank W. Bruce Croft for his sug-
gestions and discussions.
</bodyText>
<page confidence="0.997462">
190
</page>
<sectionHeader confidence="0.984387" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999236211538461">
N. Balasubramanian, G. Kumaran, and V.R. Carvalho.
2010. Exploring reductions for long web queries. In
Proceeding of the 33rd international ACM SIGIR con-
ference on Research and development in information
retrieval, pages 571–578. ACM.
C. Bannard and C. Callison-Burch. 2005. Paraphras-
ing with bilingual parallel corpora. In Proceedings of
the 43rd Annual Meeting on Association for Compu-
tational Linguistics, pages 597–604. Association for
Computational Linguistics.
R. Barzilay and K.R. McKeown. 2001. Extracting para-
phrases from a parallel corpus. In Proceedings of
the 39th Annual Meeting on Association for Computa-
tional Linguistics, pages 50–57. Association for Com-
putational Linguistics.
S. Bergsma and Q. I. Wang. 2007. Learning noun
phrase query segmentation. In EMNLP-CoNLL07,
pages 819–826, Prague.
R. Bhagat and D. Ravichandran. 2008. Large scale ac-
quisition of paraphrases for learning surface patterns.
Proceedings of ACL-08: HLT, pages 674–682.
Paolo Boldi, Francesco Bonchi, Carlos Castillo, Deb-
ora Donato, Aristides Gionis, and Sebastiano Vigna.
2008. The query-flow graph: model and applications.
In CIKM08, pages 609–618.
P. Boldi, F. Bonchi, C. Castillo, and S. Vigna. 2009.
From “Dango” to “Japanese Cakes”: Query refor-
mulation models and patterns. In Web Intelligence
and Intelligent Agent Technologies, 2009. WI-IAT’09.
IEEE/WIC/ACM International Joint Conferences on,
volume 1, pages 183–190. IEEE.
C. Callison-Burch, P. Koehn, and M. Osborne. 2006.
Improved statistical machine translation using para-
phrases. In Proceedings of the main conference on
Human Language Technology Conference of the North
American Chapter of the Association of Computa-
tional Linguistics, pages 17–24. Association for Com-
putational Linguistics.
C. Callison-Burch. 2008. Syntactic constraints on para-
phrases extracted from parallel corpora. In Proceed-
ings of the Conference on Empirical Methods in Natu-
ral Language Processing, pages 196–205. Association
for Computational Linguistics.
Jian Huang, Jianfeng Gao, Jiangbo Miao, Xiaolong Li,
Kuansan Wang, Fritz Behr, and C. Lee Giles. 2010.
Exploring web scale language models for search query
processing. In WWW10, pages 451–460, New York,
NY, USA. ACM.
S. Huston and W.B. Croft. 2010. Evaluating ver-
bose query processing techniques. In Proceeding
of the 33rd international ACM SIGIR conference on
Research and development in information retrieval,
pages 291–298. ACM.
B.J. Jansen, D.L. Booth, and A. Spink. 2009. Patterns
of query reformulation during web searching. Journal
of the American Society for Information Science and
Technology, 60(7):1358–1371.
R. Jones, B. Rey, O. Madani, and W. Greiner. 2006. Gen-
erating query substitutions. In WWW06, pages 387–
396, Ediburgh, Scotland.
D. Kauchak and R. Barzilay. 2006. Paraphrasing for
automatic evaluation.
D.-K. Lin and P. Pantel. 2001. Discovery of inference
rules for question answering. Natural Language Pro-
cessing, 7(4):343–360.
K.R. McKeown, R. Barzilay, D. Evans, V. Hatzi-
vassiloglou, J.L. Klavans, A. Nenkova, C. Sable,
B. Schiffman, and S. Sigelman. 2002. Tracking and
summarizing news on a daily basis with columbia’s
newsblaster. In Proceedings of the second interna-
tional conference on Human Language Technology
Research, pages 280–285. Morgan Kaufmann Publish-
ers Inc.
B. Pang, K. Knight, and D. Marcu. 2003. Syntax-based
alignment of multiple translations: Extracting para-
phrases and generating new sentences. In Proceedings
of the 2003 Conference of the North American Chap-
ter of the Association for Computational Linguistics on
Human Language Technology-Volume 1, pages 102–
109. Association for Computational Linguistics.
M. Pas¸ca and P. Dienes. 2005. Aligning needles in a
haystack: Paraphrase acquisition across the web. Nat-
ural Language Processing–IJCNLP 2005, pages 119–
130.
M. Pas¸ca and B. Van Durme. 2008. Weakly-supervised
acquisition of open-domain classes and class attributes
from web documents and query logs. In Proceed-
ings of the 46th Annual Meeting of the Association for
Computational Linguistics (ACL-08), pages 19–27.
J. M. Ponte and W. B. Croft. 1998. A language modeling
approach to information retrieval. In SIGIR98, pages
275–281, Melbourne, Australia.
D. Ravichandran and E. Hovy. 2002. Learning sur-
face text patterns for a question answering system. In
ACL02, pages 41–47.
B. Tan and F. Peng. 2008. Unsupervised query
segmentation using generative language models and
Wikipedia. In WWW08, pages 347–356, Bei-
jing,China.
X. Wang and C. Zhai. 2008. Mining term association
patterns from search logs for effective query reformu-
lation. In CIKM08, pages 479–488, Napa Valley, CA.
X. Xue and W. B. Croft. 2010. Representing queries
as distributions. In SIGIR10 Workshop on Query Rep-
</reference>
<page confidence="0.979989">
191
</page>
<reference confidence="0.997792066666667">
resentation and Understanding, pages 9–12, Geneva,
Switzerland.
C. Zhai and J. Lafferty. 2001. A study of smoothing
methods for language models applied to ad hoc infor-
mation retrieval. In SIGIR01, pages 334–342, New
Orleans, LA.
S. Zhao, H. Wang, T. Liu, and S. Li. 2008. Pivot ap-
proach for extracting paraphrase patterns from bilin-
gual corpora. Proceedings of ACL-08: HLT, pages
780–788.
S. Zhao, H. Wang, and T. Liu. 2010. Paraphrasing with
search engine query logs. In Proceedings of the 23rd
International Conference on Computational Linguis-
tics, pages 1317–1325. Association for Computational
Linguistics.
</reference>
<page confidence="0.998171">
192
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.495294">
<title confidence="0.957675">Automatically Mining Question Reformulation Patterns from</title>
<author confidence="0.51754">Search Log Data</author>
<affiliation confidence="0.999027">Univ. of Massachusetts, Amherst Univ. of Science and Technology of China</affiliation>
<email confidence="0.995185">xuexb@cs.umass.eduv-yutao@microsoft.com</email>
<author confidence="0.99485">Daxin Jiang Hang Li</author>
<affiliation confidence="0.998368">Microsoft Research Asia</affiliation>
<abstract confidence="0.999679357142857">Natural language questions have become popular in web search. However, various questions can be formulated to convey the same information need, which poses a great challenge to search systems. In this paper, we aumined question reformulapatterns large scale search log data. The question reformulations generated from these patterns are further incorporated into the retrieval model. Experiments show that using question reformulation patterns can significantly improve the search performance of natural language questions.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>N Balasubramanian</author>
<author>G Kumaran</author>
<author>V R Carvalho</author>
</authors>
<title>Exploring reductions for long web queries.</title>
<date>2010</date>
<booktitle>In Proceeding of the 33rd international ACM SIGIR conference on Research and development in information retrieval,</booktitle>
<pages>571--578</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="14263" citStr="Balasubramanian et al., 2010" startWordPosition="2269" endWordPosition="2272">ng 32% 30% 38% More specific/Add words 45% 39% 16% More general/Remove words 38% 48% 14% Not relevant 14% 72% 14% Table 8: Retrieval Performance of other query processing techniques. NDCG@1 NDCG@3 NDCG@5 ORIG 0.2720 0.2937 0.3151 NoStop 0.2697 0.2893 0.3112 DropOne 0.2630 0.2888 0.3102 QDist 0.2978 0.3052 0.3250 the meaning of the original question. For example, “what is the adjective of anxiously” is reformulated as “what is the noun of anxiously”. Fourth, we compare our question reformulation method with two long query processing techniques, i.e. NoStop (Huston and Croft, 2010) and DropOne (Balasubramanian et al., 2010). NoStop removes all stopwords in the query and DropOne learns to drop a single word from the query. The same query set as Balasubramanian et al. (2010) is used. Table 8 reports the retrieval performance of different methods. Table 8 shows that both NoStop and DropOne perform worse than using the original question, which indicates that the general techniques developed for long queries are not appropriate for natural language questions. On the other hand, our proposed method outperforms all the baselines. 5 Conclusion Improving the search relevance of natural language questions poses a great ch</context>
</contexts>
<marker>Balasubramanian, Kumaran, Carvalho, 2010</marker>
<rawString>N. Balasubramanian, G. Kumaran, and V.R. Carvalho. 2010. Exploring reductions for long web queries. In Proceeding of the 33rd international ACM SIGIR conference on Research and development in information retrieval, pages 571–578. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Bannard</author>
<author>C Callison-Burch</author>
</authors>
<title>Paraphrasing with bilingual parallel corpora.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>597--604</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Bannard, Callison-Burch, 2005</marker>
<rawString>C. Bannard and C. Callison-Burch. 2005. Paraphrasing with bilingual parallel corpora. In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, pages 597–604. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Barzilay</author>
<author>K R McKeown</author>
</authors>
<title>Extracting paraphrases from a parallel corpus.</title>
<date>2001</date>
<booktitle>In Proceedings of the 39th Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>50--57</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="3811" citStr="Barzilay and McKeown, 2001" startWordPosition="572" endWordPosition="575">atically mine 5w1h question reformulation patterns. Second, we conduct comprehensive studies in improving the search performance of 5w1h questions using the mined patterns. 187 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 187–192, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics ffline Phase Figure 1: The framework of reformulating questions. 2 Related Work In the Natural Language Processing (NLP) area, different expressions that convey the same meaning are referred as paraphrases (Lin and Pantel, 2001; Barzilay and McKeown, 2001; Pang et al., 2003; Pas¸ca and Dienes, 2005; Bannard and CallisonBurch, 2005; Bhagat and Ravichandran, 2008; Callison-Burch, 2008; Zhao et al., 2008). Paraphrases have been studied in a variety of NLP applications such as machine translation (Kauchak and Barzilay, 2006; Callison-Burch et al., 2006), question answering (Ravichandran and Hovy, 2002) and document summarization (McKeown et al., 2002). Yet, little research has considered improving web search performance using paraphrases. Query logs have become an important resource for many NLP applications such as class and attribute extraction </context>
</contexts>
<marker>Barzilay, McKeown, 2001</marker>
<rawString>R. Barzilay and K.R. McKeown. 2001. Extracting paraphrases from a parallel corpus. In Proceedings of the 39th Annual Meeting on Association for Computational Linguistics, pages 50–57. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Bergsma</author>
<author>Q I Wang</author>
</authors>
<title>Learning noun phrase query segmentation.</title>
<date>2007</date>
<booktitle>In EMNLP-CoNLL07,</booktitle>
<pages>819--826</pages>
<location>Prague.</location>
<contexts>
<context position="4820" citStr="Bergsma and Wang, 2007" startWordPosition="725" endWordPosition="728">et al., 2002). Yet, little research has considered improving web search performance using paraphrases. Query logs have become an important resource for many NLP applications such as class and attribute extraction (Pas¸ca and Van Durme, 2008), paraphrasing (Zhao et al., 2010) and language modeling (Huang et al., 2010). Little research has been conducted to automatically mine 5w1h question reformulation patterns from query logs. Recently, query reformulation (Boldi et al., 2009; Jansen et al., 2009) has been studied in web search. Different techniques have been developed for query segmentation (Bergsma and Wang, 2007; Tan and Peng, 2008) and query substitution (Jones et al., 2006; Wang and Zhai, 2008). Yet, most previous research focused on keyword queries without considering 5w1h questions. 3 Mining Question Reformulation Patterns for Web Search Our framework consists of three major components, which is illustrated in Fig. 1. Table 2: Question reformulation patterns generated for the query pair (“how far is it from Boston to Seattle” ,“distance from Boston to Seattle”). S1 = {Boston}:(“how far is it from X1 to Seattle” ,“distance from X1 to Seattle”) S2 = {Seattle}:(“how far is it from Boston to X1” ,“di</context>
</contexts>
<marker>Bergsma, Wang, 2007</marker>
<rawString>S. Bergsma and Q. I. Wang. 2007. Learning noun phrase query segmentation. In EMNLP-CoNLL07, pages 819–826, Prague.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Bhagat</author>
<author>D Ravichandran</author>
</authors>
<title>Large scale acquisition of paraphrases for learning surface patterns.</title>
<date>2008</date>
<booktitle>Proceedings of ACL-08: HLT,</booktitle>
<pages>674--682</pages>
<contexts>
<context position="3919" citStr="Bhagat and Ravichandran, 2008" startWordPosition="589" endWordPosition="592"> the search performance of 5w1h questions using the mined patterns. 187 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 187–192, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics ffline Phase Figure 1: The framework of reformulating questions. 2 Related Work In the Natural Language Processing (NLP) area, different expressions that convey the same meaning are referred as paraphrases (Lin and Pantel, 2001; Barzilay and McKeown, 2001; Pang et al., 2003; Pas¸ca and Dienes, 2005; Bannard and CallisonBurch, 2005; Bhagat and Ravichandran, 2008; Callison-Burch, 2008; Zhao et al., 2008). Paraphrases have been studied in a variety of NLP applications such as machine translation (Kauchak and Barzilay, 2006; Callison-Burch et al., 2006), question answering (Ravichandran and Hovy, 2002) and document summarization (McKeown et al., 2002). Yet, little research has considered improving web search performance using paraphrases. Query logs have become an important resource for many NLP applications such as class and attribute extraction (Pas¸ca and Van Durme, 2008), paraphrasing (Zhao et al., 2010) and language modeling (Huang et al., 2010). L</context>
</contexts>
<marker>Bhagat, Ravichandran, 2008</marker>
<rawString>R. Bhagat and D. Ravichandran. 2008. Large scale acquisition of paraphrases for learning surface patterns. Proceedings of ACL-08: HLT, pages 674–682.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paolo Boldi</author>
<author>Francesco Bonchi</author>
<author>Carlos Castillo</author>
<author>Debora Donato</author>
<author>Aristides Gionis</author>
<author>Sebastiano Vigna</author>
</authors>
<title>The query-flow graph: model and applications. In</title>
<date>2008</date>
<booktitle>CIKM08,</booktitle>
<pages>609--618</pages>
<contexts>
<context position="9475" citStr="Boldi et al., 2008" startWordPosition="1538" endWordPosition="1541">ment D, i.e. score(qnew, D), is calculated as follows: score(qnew, D) = A log P(qnew|D) k +(1 − A) P(pri|p⋆) log P(qnew ri|D) (2) i=1 In Eq. 2, A is a parameter that indicates the probability assigned to the original query. P(pri|p⋆) is the probability assigned to qnew ri . P(qnew|D) and P(q′|D) are calculated using the language model (Ponte and Croft, 1998; Zhai and Lafferty, 2001). 4 Experiments A large scale search log from a commercial search engine (2011.1-2011.6) is used in experiments. From the search log, we extract all successive query pairs issued by the same user within 30 minutes (Boldi et al., 2008)3 where the first query is a 5w1h question. Finally, we extracted 6,680,278 question reformulation patterns. For the retrieval experiments, we randomly sample 10,000 natural language questions as queries 3In web search, queries issued within 30 minutes are usually considered having the same information need. Table 4: Retrieval Performance of using question reformulations. ⋆ denotes significantly different with Orig. NDCG@1 NDCG@3 NDCG@5 Orig 0.2946 0.2923 0.2991 QDist 0.3032⋆ 0.2991⋆ 0.3067⋆ from the search log before 2011. For each question, we generate the top ten questions reformulations. T</context>
</contexts>
<marker>Boldi, Bonchi, Castillo, Donato, Gionis, Vigna, 2008</marker>
<rawString>Paolo Boldi, Francesco Bonchi, Carlos Castillo, Debora Donato, Aristides Gionis, and Sebastiano Vigna. 2008. The query-flow graph: model and applications. In CIKM08, pages 609–618.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Boldi</author>
<author>F Bonchi</author>
<author>C Castillo</author>
<author>S Vigna</author>
</authors>
<title>From “Dango” to “Japanese Cakes”: Query reformulation models and patterns.</title>
<date>2009</date>
<booktitle>In Web Intelligence and Intelligent Agent Technologies, 2009. WI-IAT’09. IEEE/WIC/ACM International Joint Conferences on,</booktitle>
<volume>1</volume>
<pages>183--190</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="4678" citStr="Boldi et al., 2009" startWordPosition="703" endWordPosition="706">ak and Barzilay, 2006; Callison-Burch et al., 2006), question answering (Ravichandran and Hovy, 2002) and document summarization (McKeown et al., 2002). Yet, little research has considered improving web search performance using paraphrases. Query logs have become an important resource for many NLP applications such as class and attribute extraction (Pas¸ca and Van Durme, 2008), paraphrasing (Zhao et al., 2010) and language modeling (Huang et al., 2010). Little research has been conducted to automatically mine 5w1h question reformulation patterns from query logs. Recently, query reformulation (Boldi et al., 2009; Jansen et al., 2009) has been studied in web search. Different techniques have been developed for query segmentation (Bergsma and Wang, 2007; Tan and Peng, 2008) and query substitution (Jones et al., 2006; Wang and Zhai, 2008). Yet, most previous research focused on keyword queries without considering 5w1h questions. 3 Mining Question Reformulation Patterns for Web Search Our framework consists of three major components, which is illustrated in Fig. 1. Table 2: Question reformulation patterns generated for the query pair (“how far is it from Boston to Seattle” ,“distance from Boston to Seatt</context>
</contexts>
<marker>Boldi, Bonchi, Castillo, Vigna, 2009</marker>
<rawString>P. Boldi, F. Bonchi, C. Castillo, and S. Vigna. 2009. From “Dango” to “Japanese Cakes”: Query reformulation models and patterns. In Web Intelligence and Intelligent Agent Technologies, 2009. WI-IAT’09. IEEE/WIC/ACM International Joint Conferences on, volume 1, pages 183–190. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Callison-Burch</author>
<author>P Koehn</author>
<author>M Osborne</author>
</authors>
<title>Improved statistical machine translation using paraphrases.</title>
<date>2006</date>
<booktitle>In Proceedings of the main conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics,</booktitle>
<pages>17--24</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="4111" citStr="Callison-Burch et al., 2006" startWordPosition="619" endWordPosition="622"> Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics ffline Phase Figure 1: The framework of reformulating questions. 2 Related Work In the Natural Language Processing (NLP) area, different expressions that convey the same meaning are referred as paraphrases (Lin and Pantel, 2001; Barzilay and McKeown, 2001; Pang et al., 2003; Pas¸ca and Dienes, 2005; Bannard and CallisonBurch, 2005; Bhagat and Ravichandran, 2008; Callison-Burch, 2008; Zhao et al., 2008). Paraphrases have been studied in a variety of NLP applications such as machine translation (Kauchak and Barzilay, 2006; Callison-Burch et al., 2006), question answering (Ravichandran and Hovy, 2002) and document summarization (McKeown et al., 2002). Yet, little research has considered improving web search performance using paraphrases. Query logs have become an important resource for many NLP applications such as class and attribute extraction (Pas¸ca and Van Durme, 2008), paraphrasing (Zhao et al., 2010) and language modeling (Huang et al., 2010). Little research has been conducted to automatically mine 5w1h question reformulation patterns from query logs. Recently, query reformulation (Boldi et al., 2009; Jansen et al., 2009) has been s</context>
</contexts>
<marker>Callison-Burch, Koehn, Osborne, 2006</marker>
<rawString>C. Callison-Burch, P. Koehn, and M. Osborne. 2006. Improved statistical machine translation using paraphrases. In Proceedings of the main conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics, pages 17–24. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Callison-Burch</author>
</authors>
<title>Syntactic constraints on paraphrases extracted from parallel corpora.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>196--205</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="3941" citStr="Callison-Burch, 2008" startWordPosition="593" endWordPosition="594"> questions using the mined patterns. 187 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 187–192, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics ffline Phase Figure 1: The framework of reformulating questions. 2 Related Work In the Natural Language Processing (NLP) area, different expressions that convey the same meaning are referred as paraphrases (Lin and Pantel, 2001; Barzilay and McKeown, 2001; Pang et al., 2003; Pas¸ca and Dienes, 2005; Bannard and CallisonBurch, 2005; Bhagat and Ravichandran, 2008; Callison-Burch, 2008; Zhao et al., 2008). Paraphrases have been studied in a variety of NLP applications such as machine translation (Kauchak and Barzilay, 2006; Callison-Burch et al., 2006), question answering (Ravichandran and Hovy, 2002) and document summarization (McKeown et al., 2002). Yet, little research has considered improving web search performance using paraphrases. Query logs have become an important resource for many NLP applications such as class and attribute extraction (Pas¸ca and Van Durme, 2008), paraphrasing (Zhao et al., 2010) and language modeling (Huang et al., 2010). Little research has bee</context>
</contexts>
<marker>Callison-Burch, 2008</marker>
<rawString>C. Callison-Burch. 2008. Syntactic constraints on paraphrases extracted from parallel corpora. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 196–205. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jian Huang</author>
<author>Jianfeng Gao</author>
<author>Jiangbo Miao</author>
<author>Xiaolong Li</author>
<author>Kuansan Wang</author>
<author>Fritz Behr</author>
<author>C Lee Giles</author>
</authors>
<title>Exploring web scale language models for search query processing.</title>
<date>2010</date>
<booktitle>In WWW10,</booktitle>
<pages>451--460</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="4516" citStr="Huang et al., 2010" startWordPosition="680" endWordPosition="683">and Ravichandran, 2008; Callison-Burch, 2008; Zhao et al., 2008). Paraphrases have been studied in a variety of NLP applications such as machine translation (Kauchak and Barzilay, 2006; Callison-Burch et al., 2006), question answering (Ravichandran and Hovy, 2002) and document summarization (McKeown et al., 2002). Yet, little research has considered improving web search performance using paraphrases. Query logs have become an important resource for many NLP applications such as class and attribute extraction (Pas¸ca and Van Durme, 2008), paraphrasing (Zhao et al., 2010) and language modeling (Huang et al., 2010). Little research has been conducted to automatically mine 5w1h question reformulation patterns from query logs. Recently, query reformulation (Boldi et al., 2009; Jansen et al., 2009) has been studied in web search. Different techniques have been developed for query segmentation (Bergsma and Wang, 2007; Tan and Peng, 2008) and query substitution (Jones et al., 2006; Wang and Zhai, 2008). Yet, most previous research focused on keyword queries without considering 5w1h questions. 3 Mining Question Reformulation Patterns for Web Search Our framework consists of three major components, which is il</context>
</contexts>
<marker>Huang, Gao, Miao, Li, Wang, Behr, Giles, 2010</marker>
<rawString>Jian Huang, Jianfeng Gao, Jiangbo Miao, Xiaolong Li, Kuansan Wang, Fritz Behr, and C. Lee Giles. 2010. Exploring web scale language models for search query processing. In WWW10, pages 451–460, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Huston</author>
<author>W B Croft</author>
</authors>
<title>Evaluating verbose query processing techniques.</title>
<date>2010</date>
<booktitle>In Proceeding of the 33rd international ACM SIGIR conference on Research and development in information retrieval,</booktitle>
<pages>291--298</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="14220" citStr="Huston and Croft, 2010" startWordPosition="2263" endWordPosition="2266">l change 11% 10% 79% Equivalent meaning 32% 30% 38% More specific/Add words 45% 39% 16% More general/Remove words 38% 48% 14% Not relevant 14% 72% 14% Table 8: Retrieval Performance of other query processing techniques. NDCG@1 NDCG@3 NDCG@5 ORIG 0.2720 0.2937 0.3151 NoStop 0.2697 0.2893 0.3112 DropOne 0.2630 0.2888 0.3102 QDist 0.2978 0.3052 0.3250 the meaning of the original question. For example, “what is the adjective of anxiously” is reformulated as “what is the noun of anxiously”. Fourth, we compare our question reformulation method with two long query processing techniques, i.e. NoStop (Huston and Croft, 2010) and DropOne (Balasubramanian et al., 2010). NoStop removes all stopwords in the query and DropOne learns to drop a single word from the query. The same query set as Balasubramanian et al. (2010) is used. Table 8 reports the retrieval performance of different methods. Table 8 shows that both NoStop and DropOne perform worse than using the original question, which indicates that the general techniques developed for long queries are not appropriate for natural language questions. On the other hand, our proposed method outperforms all the baselines. 5 Conclusion Improving the search relevance of </context>
</contexts>
<marker>Huston, Croft, 2010</marker>
<rawString>S. Huston and W.B. Croft. 2010. Evaluating verbose query processing techniques. In Proceeding of the 33rd international ACM SIGIR conference on Research and development in information retrieval, pages 291–298. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B J Jansen</author>
<author>D L Booth</author>
<author>A Spink</author>
</authors>
<title>Patterns of query reformulation during web searching.</title>
<date>2009</date>
<journal>Journal of the American Society for Information Science and Technology,</journal>
<volume>60</volume>
<issue>7</issue>
<contexts>
<context position="4700" citStr="Jansen et al., 2009" startWordPosition="707" endWordPosition="710">6; Callison-Burch et al., 2006), question answering (Ravichandran and Hovy, 2002) and document summarization (McKeown et al., 2002). Yet, little research has considered improving web search performance using paraphrases. Query logs have become an important resource for many NLP applications such as class and attribute extraction (Pas¸ca and Van Durme, 2008), paraphrasing (Zhao et al., 2010) and language modeling (Huang et al., 2010). Little research has been conducted to automatically mine 5w1h question reformulation patterns from query logs. Recently, query reformulation (Boldi et al., 2009; Jansen et al., 2009) has been studied in web search. Different techniques have been developed for query segmentation (Bergsma and Wang, 2007; Tan and Peng, 2008) and query substitution (Jones et al., 2006; Wang and Zhai, 2008). Yet, most previous research focused on keyword queries without considering 5w1h questions. 3 Mining Question Reformulation Patterns for Web Search Our framework consists of three major components, which is illustrated in Fig. 1. Table 2: Question reformulation patterns generated for the query pair (“how far is it from Boston to Seattle” ,“distance from Boston to Seattle”). S1 = {Boston}:(“</context>
</contexts>
<marker>Jansen, Booth, Spink, 2009</marker>
<rawString>B.J. Jansen, D.L. Booth, and A. Spink. 2009. Patterns of query reformulation during web searching. Journal of the American Society for Information Science and Technology, 60(7):1358–1371.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Jones</author>
<author>B Rey</author>
<author>O Madani</author>
<author>W Greiner</author>
</authors>
<title>Generating query substitutions.</title>
<date>2006</date>
<booktitle>In WWW06,</booktitle>
<pages>387--396</pages>
<location>Ediburgh, Scotland.</location>
<contexts>
<context position="4884" citStr="Jones et al., 2006" startWordPosition="736" endWordPosition="739">rch performance using paraphrases. Query logs have become an important resource for many NLP applications such as class and attribute extraction (Pas¸ca and Van Durme, 2008), paraphrasing (Zhao et al., 2010) and language modeling (Huang et al., 2010). Little research has been conducted to automatically mine 5w1h question reformulation patterns from query logs. Recently, query reformulation (Boldi et al., 2009; Jansen et al., 2009) has been studied in web search. Different techniques have been developed for query segmentation (Bergsma and Wang, 2007; Tan and Peng, 2008) and query substitution (Jones et al., 2006; Wang and Zhai, 2008). Yet, most previous research focused on keyword queries without considering 5w1h questions. 3 Mining Question Reformulation Patterns for Web Search Our framework consists of three major components, which is illustrated in Fig. 1. Table 2: Question reformulation patterns generated for the query pair (“how far is it from Boston to Seattle” ,“distance from Boston to Seattle”). S1 = {Boston}:(“how far is it from X1 to Seattle” ,“distance from X1 to Seattle”) S2 = {Seattle}:(“how far is it from Boston to X1” ,“distance from Boston to X1”) S3 = {Boston, Seattle}:(“how far is i</context>
</contexts>
<marker>Jones, Rey, Madani, Greiner, 2006</marker>
<rawString>R. Jones, B. Rey, O. Madani, and W. Greiner. 2006. Generating query substitutions. In WWW06, pages 387– 396, Ediburgh, Scotland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Kauchak</author>
<author>R Barzilay</author>
</authors>
<title>Paraphrasing for automatic evaluation.</title>
<date>2006</date>
<contexts>
<context position="4081" citStr="Kauchak and Barzilay, 2006" startWordPosition="615" endWordPosition="618">s 187–192, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics ffline Phase Figure 1: The framework of reformulating questions. 2 Related Work In the Natural Language Processing (NLP) area, different expressions that convey the same meaning are referred as paraphrases (Lin and Pantel, 2001; Barzilay and McKeown, 2001; Pang et al., 2003; Pas¸ca and Dienes, 2005; Bannard and CallisonBurch, 2005; Bhagat and Ravichandran, 2008; Callison-Burch, 2008; Zhao et al., 2008). Paraphrases have been studied in a variety of NLP applications such as machine translation (Kauchak and Barzilay, 2006; Callison-Burch et al., 2006), question answering (Ravichandran and Hovy, 2002) and document summarization (McKeown et al., 2002). Yet, little research has considered improving web search performance using paraphrases. Query logs have become an important resource for many NLP applications such as class and attribute extraction (Pas¸ca and Van Durme, 2008), paraphrasing (Zhao et al., 2010) and language modeling (Huang et al., 2010). Little research has been conducted to automatically mine 5w1h question reformulation patterns from query logs. Recently, query reformulation (Boldi et al., 2009; J</context>
</contexts>
<marker>Kauchak, Barzilay, 2006</marker>
<rawString>D. Kauchak and R. Barzilay. 2006. Paraphrasing for automatic evaluation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D-K Lin</author>
<author>P Pantel</author>
</authors>
<title>Discovery of inference rules for question answering.</title>
<date>2001</date>
<journal>Natural Language Processing,</journal>
<volume>7</volume>
<issue>4</issue>
<contexts>
<context position="3783" citStr="Lin and Pantel, 2001" startWordPosition="568" endWordPosition="571">tive approach to automatically mine 5w1h question reformulation patterns. Second, we conduct comprehensive studies in improving the search performance of 5w1h questions using the mined patterns. 187 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 187–192, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics ffline Phase Figure 1: The framework of reformulating questions. 2 Related Work In the Natural Language Processing (NLP) area, different expressions that convey the same meaning are referred as paraphrases (Lin and Pantel, 2001; Barzilay and McKeown, 2001; Pang et al., 2003; Pas¸ca and Dienes, 2005; Bannard and CallisonBurch, 2005; Bhagat and Ravichandran, 2008; Callison-Burch, 2008; Zhao et al., 2008). Paraphrases have been studied in a variety of NLP applications such as machine translation (Kauchak and Barzilay, 2006; Callison-Burch et al., 2006), question answering (Ravichandran and Hovy, 2002) and document summarization (McKeown et al., 2002). Yet, little research has considered improving web search performance using paraphrases. Query logs have become an important resource for many NLP applications such as cla</context>
</contexts>
<marker>Lin, Pantel, 2001</marker>
<rawString>D.-K. Lin and P. Pantel. 2001. Discovery of inference rules for question answering. Natural Language Processing, 7(4):343–360.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K R McKeown</author>
<author>R Barzilay</author>
<author>D Evans</author>
<author>V Hatzivassiloglou</author>
<author>J L Klavans</author>
<author>A Nenkova</author>
<author>C Sable</author>
<author>B Schiffman</author>
<author>S Sigelman</author>
</authors>
<title>Tracking and summarizing news on a daily basis with columbia’s newsblaster.</title>
<date>2002</date>
<booktitle>In Proceedings of the second international conference on Human Language Technology Research,</booktitle>
<pages>280--285</pages>
<publisher>Morgan Kaufmann Publishers Inc.</publisher>
<contexts>
<context position="4211" citStr="McKeown et al., 2002" startWordPosition="633" endWordPosition="636">rk of reformulating questions. 2 Related Work In the Natural Language Processing (NLP) area, different expressions that convey the same meaning are referred as paraphrases (Lin and Pantel, 2001; Barzilay and McKeown, 2001; Pang et al., 2003; Pas¸ca and Dienes, 2005; Bannard and CallisonBurch, 2005; Bhagat and Ravichandran, 2008; Callison-Burch, 2008; Zhao et al., 2008). Paraphrases have been studied in a variety of NLP applications such as machine translation (Kauchak and Barzilay, 2006; Callison-Burch et al., 2006), question answering (Ravichandran and Hovy, 2002) and document summarization (McKeown et al., 2002). Yet, little research has considered improving web search performance using paraphrases. Query logs have become an important resource for many NLP applications such as class and attribute extraction (Pas¸ca and Van Durme, 2008), paraphrasing (Zhao et al., 2010) and language modeling (Huang et al., 2010). Little research has been conducted to automatically mine 5w1h question reformulation patterns from query logs. Recently, query reformulation (Boldi et al., 2009; Jansen et al., 2009) has been studied in web search. Different techniques have been developed for query segmentation (Bergsma and W</context>
</contexts>
<marker>McKeown, Barzilay, Evans, Hatzivassiloglou, Klavans, Nenkova, Sable, Schiffman, Sigelman, 2002</marker>
<rawString>K.R. McKeown, R. Barzilay, D. Evans, V. Hatzivassiloglou, J.L. Klavans, A. Nenkova, C. Sable, B. Schiffman, and S. Sigelman. 2002. Tracking and summarizing news on a daily basis with columbia’s newsblaster. In Proceedings of the second international conference on Human Language Technology Research, pages 280–285. Morgan Kaufmann Publishers Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Pang</author>
<author>K Knight</author>
<author>D Marcu</author>
</authors>
<title>Syntax-based alignment of multiple translations: Extracting paraphrases and generating new sentences.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology-Volume 1,</booktitle>
<pages>102--109</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="3830" citStr="Pang et al., 2003" startWordPosition="576" endWordPosition="579">reformulation patterns. Second, we conduct comprehensive studies in improving the search performance of 5w1h questions using the mined patterns. 187 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 187–192, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics ffline Phase Figure 1: The framework of reformulating questions. 2 Related Work In the Natural Language Processing (NLP) area, different expressions that convey the same meaning are referred as paraphrases (Lin and Pantel, 2001; Barzilay and McKeown, 2001; Pang et al., 2003; Pas¸ca and Dienes, 2005; Bannard and CallisonBurch, 2005; Bhagat and Ravichandran, 2008; Callison-Burch, 2008; Zhao et al., 2008). Paraphrases have been studied in a variety of NLP applications such as machine translation (Kauchak and Barzilay, 2006; Callison-Burch et al., 2006), question answering (Ravichandran and Hovy, 2002) and document summarization (McKeown et al., 2002). Yet, little research has considered improving web search performance using paraphrases. Query logs have become an important resource for many NLP applications such as class and attribute extraction (Pas¸ca and Van Dur</context>
</contexts>
<marker>Pang, Knight, Marcu, 2003</marker>
<rawString>B. Pang, K. Knight, and D. Marcu. 2003. Syntax-based alignment of multiple translations: Extracting paraphrases and generating new sentences. In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology-Volume 1, pages 102– 109. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Pas¸ca</author>
<author>P Dienes</author>
</authors>
<title>Aligning needles in a haystack: Paraphrase acquisition across the web. Natural Language Processing–IJCNLP</title>
<date>2005</date>
<pages>119--130</pages>
<marker>Pas¸ca, Dienes, 2005</marker>
<rawString>M. Pas¸ca and P. Dienes. 2005. Aligning needles in a haystack: Paraphrase acquisition across the web. Natural Language Processing–IJCNLP 2005, pages 119– 130.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Pas¸ca</author>
<author>B Van Durme</author>
</authors>
<title>Weakly-supervised acquisition of open-domain classes and class attributes from web documents and query logs.</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics (ACL-08),</booktitle>
<pages>pages</pages>
<marker>Pas¸ca, Van Durme, 2008</marker>
<rawString>M. Pas¸ca and B. Van Durme. 2008. Weakly-supervised acquisition of open-domain classes and class attributes from web documents and query logs. In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics (ACL-08), pages 19–27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J M Ponte</author>
<author>W B Croft</author>
</authors>
<title>A language modeling approach to information retrieval.</title>
<date>1998</date>
<booktitle>In SIGIR98,</booktitle>
<pages>275--281</pages>
<location>Melbourne, Australia.</location>
<contexts>
<context position="9215" citStr="Ponte and Croft, 1998" startWordPosition="1495" endWordPosition="1498">l Model Given the original question qnew and k question reformulations {qnew r }, the query distribution model (Xue and Croft, 2010) (denoted as QDist) is adopted to combine qnew and {qnew r } using their associated probabilities. The retrieval score of the document D, i.e. score(qnew, D), is calculated as follows: score(qnew, D) = A log P(qnew|D) k +(1 − A) P(pri|p⋆) log P(qnew ri|D) (2) i=1 In Eq. 2, A is a parameter that indicates the probability assigned to the original query. P(pri|p⋆) is the probability assigned to qnew ri . P(qnew|D) and P(q′|D) are calculated using the language model (Ponte and Croft, 1998; Zhai and Lafferty, 2001). 4 Experiments A large scale search log from a commercial search engine (2011.1-2011.6) is used in experiments. From the search log, we extract all successive query pairs issued by the same user within 30 minutes (Boldi et al., 2008)3 where the first query is a 5w1h question. Finally, we extracted 6,680,278 question reformulation patterns. For the retrieval experiments, we randomly sample 10,000 natural language questions as queries 3In web search, queries issued within 30 minutes are usually considered having the same information need. Table 4: Retrieval Performance</context>
</contexts>
<marker>Ponte, Croft, 1998</marker>
<rawString>J. M. Ponte and W. B. Croft. 1998. A language modeling approach to information retrieval. In SIGIR98, pages 275–281, Melbourne, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Ravichandran</author>
<author>E Hovy</author>
</authors>
<title>Learning surface text patterns for a question answering system.</title>
<date>2002</date>
<booktitle>In ACL02,</booktitle>
<pages>41--47</pages>
<contexts>
<context position="4161" citStr="Ravichandran and Hovy, 2002" startWordPosition="626" endWordPosition="629">putational Linguistics ffline Phase Figure 1: The framework of reformulating questions. 2 Related Work In the Natural Language Processing (NLP) area, different expressions that convey the same meaning are referred as paraphrases (Lin and Pantel, 2001; Barzilay and McKeown, 2001; Pang et al., 2003; Pas¸ca and Dienes, 2005; Bannard and CallisonBurch, 2005; Bhagat and Ravichandran, 2008; Callison-Burch, 2008; Zhao et al., 2008). Paraphrases have been studied in a variety of NLP applications such as machine translation (Kauchak and Barzilay, 2006; Callison-Burch et al., 2006), question answering (Ravichandran and Hovy, 2002) and document summarization (McKeown et al., 2002). Yet, little research has considered improving web search performance using paraphrases. Query logs have become an important resource for many NLP applications such as class and attribute extraction (Pas¸ca and Van Durme, 2008), paraphrasing (Zhao et al., 2010) and language modeling (Huang et al., 2010). Little research has been conducted to automatically mine 5w1h question reformulation patterns from query logs. Recently, query reformulation (Boldi et al., 2009; Jansen et al., 2009) has been studied in web search. Different techniques have be</context>
</contexts>
<marker>Ravichandran, Hovy, 2002</marker>
<rawString>D. Ravichandran and E. Hovy. 2002. Learning surface text patterns for a question answering system. In ACL02, pages 41–47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Tan</author>
<author>F Peng</author>
</authors>
<title>Unsupervised query segmentation using generative language models and Wikipedia.</title>
<date>2008</date>
<booktitle>In WWW08,</booktitle>
<pages>347--356</pages>
<location>Beijing,China.</location>
<contexts>
<context position="4841" citStr="Tan and Peng, 2008" startWordPosition="729" endWordPosition="732">le research has considered improving web search performance using paraphrases. Query logs have become an important resource for many NLP applications such as class and attribute extraction (Pas¸ca and Van Durme, 2008), paraphrasing (Zhao et al., 2010) and language modeling (Huang et al., 2010). Little research has been conducted to automatically mine 5w1h question reformulation patterns from query logs. Recently, query reformulation (Boldi et al., 2009; Jansen et al., 2009) has been studied in web search. Different techniques have been developed for query segmentation (Bergsma and Wang, 2007; Tan and Peng, 2008) and query substitution (Jones et al., 2006; Wang and Zhai, 2008). Yet, most previous research focused on keyword queries without considering 5w1h questions. 3 Mining Question Reformulation Patterns for Web Search Our framework consists of three major components, which is illustrated in Fig. 1. Table 2: Question reformulation patterns generated for the query pair (“how far is it from Boston to Seattle” ,“distance from Boston to Seattle”). S1 = {Boston}:(“how far is it from X1 to Seattle” ,“distance from X1 to Seattle”) S2 = {Seattle}:(“how far is it from Boston to X1” ,“distance from Boston to</context>
</contexts>
<marker>Tan, Peng, 2008</marker>
<rawString>B. Tan and F. Peng. 2008. Unsupervised query segmentation using generative language models and Wikipedia. In WWW08, pages 347–356, Beijing,China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Wang</author>
<author>C Zhai</author>
</authors>
<title>Mining term association patterns from search logs for effective query reformulation.</title>
<date>2008</date>
<booktitle>In CIKM08,</booktitle>
<pages>479--488</pages>
<location>Napa Valley, CA.</location>
<contexts>
<context position="4906" citStr="Wang and Zhai, 2008" startWordPosition="740" endWordPosition="743">g paraphrases. Query logs have become an important resource for many NLP applications such as class and attribute extraction (Pas¸ca and Van Durme, 2008), paraphrasing (Zhao et al., 2010) and language modeling (Huang et al., 2010). Little research has been conducted to automatically mine 5w1h question reformulation patterns from query logs. Recently, query reformulation (Boldi et al., 2009; Jansen et al., 2009) has been studied in web search. Different techniques have been developed for query segmentation (Bergsma and Wang, 2007; Tan and Peng, 2008) and query substitution (Jones et al., 2006; Wang and Zhai, 2008). Yet, most previous research focused on keyword queries without considering 5w1h questions. 3 Mining Question Reformulation Patterns for Web Search Our framework consists of three major components, which is illustrated in Fig. 1. Table 2: Question reformulation patterns generated for the query pair (“how far is it from Boston to Seattle” ,“distance from Boston to Seattle”). S1 = {Boston}:(“how far is it from X1 to Seattle” ,“distance from X1 to Seattle”) S2 = {Seattle}:(“how far is it from Boston to X1” ,“distance from Boston to X1”) S3 = {Boston, Seattle}:(“how far is it from X1 to X2” ,“dis</context>
</contexts>
<marker>Wang, Zhai, 2008</marker>
<rawString>X. Wang and C. Zhai. 2008. Mining term association patterns from search logs for effective query reformulation. In CIKM08, pages 479–488, Napa Valley, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Xue</author>
<author>W B Croft</author>
</authors>
<title>Representing queries as distributions.</title>
<date>2010</date>
<booktitle>In SIGIR10 Workshop on Query Representation and Understanding,</booktitle>
<pages>9--12</pages>
<location>Geneva, Switzerland.</location>
<contexts>
<context position="8726" citStr="Xue and Croft, 2010" startWordPosition="1410" endWordPosition="1413"> sell a X rate the eden pure air system rate the X how to advertise a restaurant how to advertise a X reviews on the eden pure air system reviews on the X restaurant marketing X marketing P(pr|p⋆) = f(p⋆, pr) (1) E&amp;quot; f(p⋆, p′r) Finally, we generate k question reformulations qnew r by applying the top k question reformulation patterns containing p⋆. The probability P(pr|p⋆) associated with the pattern (p⋆, pr) is assigned to the corresponding question reformulation qnew r. 3.3 Retrieval Model Given the original question qnew and k question reformulations {qnew r }, the query distribution model (Xue and Croft, 2010) (denoted as QDist) is adopted to combine qnew and {qnew r } using their associated probabilities. The retrieval score of the document D, i.e. score(qnew, D), is calculated as follows: score(qnew, D) = A log P(qnew|D) k +(1 − A) P(pri|p⋆) log P(qnew ri|D) (2) i=1 In Eq. 2, A is a parameter that indicates the probability assigned to the original query. P(pri|p⋆) is the probability assigned to qnew ri . P(qnew|D) and P(q′|D) are calculated using the language model (Ponte and Croft, 1998; Zhai and Lafferty, 2001). 4 Experiments A large scale search log from a commercial search engine (2011.1-2011</context>
</contexts>
<marker>Xue, Croft, 2010</marker>
<rawString>X. Xue and W. B. Croft. 2010. Representing queries as distributions. In SIGIR10 Workshop on Query Representation and Understanding, pages 9–12, Geneva, Switzerland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Zhai</author>
<author>J Lafferty</author>
</authors>
<title>A study of smoothing methods for language models applied to ad hoc information retrieval.</title>
<date>2001</date>
<booktitle>In SIGIR01,</booktitle>
<pages>334--342</pages>
<location>New Orleans, LA.</location>
<contexts>
<context position="9241" citStr="Zhai and Lafferty, 2001" startWordPosition="1499" endWordPosition="1502">nal question qnew and k question reformulations {qnew r }, the query distribution model (Xue and Croft, 2010) (denoted as QDist) is adopted to combine qnew and {qnew r } using their associated probabilities. The retrieval score of the document D, i.e. score(qnew, D), is calculated as follows: score(qnew, D) = A log P(qnew|D) k +(1 − A) P(pri|p⋆) log P(qnew ri|D) (2) i=1 In Eq. 2, A is a parameter that indicates the probability assigned to the original query. P(pri|p⋆) is the probability assigned to qnew ri . P(qnew|D) and P(q′|D) are calculated using the language model (Ponte and Croft, 1998; Zhai and Lafferty, 2001). 4 Experiments A large scale search log from a commercial search engine (2011.1-2011.6) is used in experiments. From the search log, we extract all successive query pairs issued by the same user within 30 minutes (Boldi et al., 2008)3 where the first query is a 5w1h question. Finally, we extracted 6,680,278 question reformulation patterns. For the retrieval experiments, we randomly sample 10,000 natural language questions as queries 3In web search, queries issued within 30 minutes are usually considered having the same information need. Table 4: Retrieval Performance of using question reformu</context>
</contexts>
<marker>Zhai, Lafferty, 2001</marker>
<rawString>C. Zhai and J. Lafferty. 2001. A study of smoothing methods for language models applied to ad hoc information retrieval. In SIGIR01, pages 334–342, New Orleans, LA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Zhao</author>
<author>H Wang</author>
<author>T Liu</author>
<author>S Li</author>
</authors>
<title>Pivot approach for extracting paraphrase patterns from bilingual corpora.</title>
<date>2008</date>
<booktitle>Proceedings of ACL-08: HLT,</booktitle>
<pages>780--788</pages>
<contexts>
<context position="3961" citStr="Zhao et al., 2008" startWordPosition="595" endWordPosition="598">ined patterns. 187 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 187–192, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics ffline Phase Figure 1: The framework of reformulating questions. 2 Related Work In the Natural Language Processing (NLP) area, different expressions that convey the same meaning are referred as paraphrases (Lin and Pantel, 2001; Barzilay and McKeown, 2001; Pang et al., 2003; Pas¸ca and Dienes, 2005; Bannard and CallisonBurch, 2005; Bhagat and Ravichandran, 2008; Callison-Burch, 2008; Zhao et al., 2008). Paraphrases have been studied in a variety of NLP applications such as machine translation (Kauchak and Barzilay, 2006; Callison-Burch et al., 2006), question answering (Ravichandran and Hovy, 2002) and document summarization (McKeown et al., 2002). Yet, little research has considered improving web search performance using paraphrases. Query logs have become an important resource for many NLP applications such as class and attribute extraction (Pas¸ca and Van Durme, 2008), paraphrasing (Zhao et al., 2010) and language modeling (Huang et al., 2010). Little research has been conducted to autom</context>
</contexts>
<marker>Zhao, Wang, Liu, Li, 2008</marker>
<rawString>S. Zhao, H. Wang, T. Liu, and S. Li. 2008. Pivot approach for extracting paraphrase patterns from bilingual corpora. Proceedings of ACL-08: HLT, pages 780–788.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Zhao</author>
<author>H Wang</author>
<author>T Liu</author>
</authors>
<title>Paraphrasing with search engine query logs.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics,</booktitle>
<pages>1317--1325</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="4473" citStr="Zhao et al., 2010" startWordPosition="672" endWordPosition="675">; Bannard and CallisonBurch, 2005; Bhagat and Ravichandran, 2008; Callison-Burch, 2008; Zhao et al., 2008). Paraphrases have been studied in a variety of NLP applications such as machine translation (Kauchak and Barzilay, 2006; Callison-Burch et al., 2006), question answering (Ravichandran and Hovy, 2002) and document summarization (McKeown et al., 2002). Yet, little research has considered improving web search performance using paraphrases. Query logs have become an important resource for many NLP applications such as class and attribute extraction (Pas¸ca and Van Durme, 2008), paraphrasing (Zhao et al., 2010) and language modeling (Huang et al., 2010). Little research has been conducted to automatically mine 5w1h question reformulation patterns from query logs. Recently, query reformulation (Boldi et al., 2009; Jansen et al., 2009) has been studied in web search. Different techniques have been developed for query segmentation (Bergsma and Wang, 2007; Tan and Peng, 2008) and query substitution (Jones et al., 2006; Wang and Zhai, 2008). Yet, most previous research focused on keyword queries without considering 5w1h questions. 3 Mining Question Reformulation Patterns for Web Search Our framework cons</context>
</contexts>
<marker>Zhao, Wang, Liu, 2010</marker>
<rawString>S. Zhao, H. Wang, and T. Liu. 2010. Paraphrasing with search engine query logs. In Proceedings of the 23rd International Conference on Computational Linguistics, pages 1317–1325. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>