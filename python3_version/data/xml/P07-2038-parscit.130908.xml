<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.005926">
<title confidence="0.986054">
Empirical Measurements of Lexical Similarity in Noun Phrase Conjuncts
</title>
<author confidence="0.987944">
Deirdre Hogan*
</author>
<affiliation confidence="0.988113">
Department of Computer Science
Trinity College Dublin
</affiliation>
<address confidence="0.758364">
Dublin 2, Ireland
</address>
<email confidence="0.997286">
dhogan@computing.dcu.ie
</email>
<sectionHeader confidence="0.995616" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999468">
The ability to detect similarity in conjunct
heads is potentially a useful tool in help-
ing to disambiguate coordination structures
- a difficult task for parsers. We propose a
distributional measure of similarity designed
for such a task. We then compare several dif-
ferent measures of word similarity by testing
whether they can empirically detect similar-
ity in the head nouns of noun phrase con-
juncts in the Wall Street Journal (WSJ) tree-
bank. We demonstrate that several measures
of word similarity can successfully detect
conjunct head similarity and suggest that the
measure proposed in this paper is the most
appropriate for this task.
</bodyText>
<sectionHeader confidence="0.999127" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999399692307692">
Some noun pairs are more likely to be conjoined
than others. Take the follow two alternate brack-
etings: 1. busloads of ((executives) and (their
spouses)) and 2. ((busloads of executives) and
(their spouses)). The two head nouns coordinated
in 1 are executives and spouses, and (incorrectly)
in 2: busloads and spouses. Clearly, the former
pair of head nouns is more likely and, for the pur-
pose of discrimination, a parsing model would ben-
efit if it could learn that executives and spouses
is a more likely combination than busloads and
spouses. If nouns co-occurring in coordination pat-
terns are often semantically similar, and if a simi-
</bodyText>
<note confidence="0.27623">
* Now at the National Centre for Language Technology,
Dublin City University, Ireland.
</note>
<bodyText confidence="0.9719992">
larity measure could be defined so that, for exam-
ple: sim(executives, spouses) &gt; sim(busloads, spouses)
then it is potentially useful for coordination disam-
biguation.
The idea that nouns co-occurring in conjunc-
tions tend to be semantically related has been noted
in (Riloff and Shepherd, 1997) and used effec-
tively to automatically cluster semantically similar
words (Roark and Charniak, 1998; Caraballo, 1999;
Widdows and Dorow, 2002). The tendency for con-
joined nouns to be semantically similar has also
been exploited for coordinate noun phrase disam-
biguation by Resnik (1999) who employed a mea-
sure of similarity based on WordNet to measure
which were the head nouns being conjoined in cer-
tain types of coordinate noun phrase.
In this paper we look at different measures of
word similarity in order to discover whether they can
detect empirically a tendency for conjoined nouns to
be more similar than nouns which co-occur but are
not conjoined. In Section 2 we introduce a measure
of word similarity based on word vectors and in Sec-
tion 3 we briefly describe some WordNet similarity
measures which, in addition to our word vector mea-
sure, will be tested in the experiments of Section 4.
</bodyText>
<sectionHeader confidence="0.6181435" genericHeader="method">
2 Similarity based on Coordination
Co-occurrences
</sectionHeader>
<bodyText confidence="0.999962166666667">
The potential usefulness of a similarity measure de-
pends on the particular application. An obvious
place to start, when looking at similarity functions
for measuring the type of semantic similarity com-
mon for coordinate nouns, is a similarity function
based on distributional similarity with context de-
</bodyText>
<page confidence="0.986144">
149
</page>
<bodyText confidence="0.956326050847457">
Proceedings of the ACL 2007 Demo and Poster Sessions, pages 149–152,
Prague, June 2007. c�2007 Association for Computational Linguistics
fined in terms of coordination patterns. Our mea- by the information content of their lowest com-
sure of similarity is based on noun co-occurrence mon subsumer in the is-a hierarchy of WordNet.
information, extracted from conjunctions and lists. Both Jiang and Conrath (1997) and Lin (1998) pro-
We collected co-occurrence data on 82, 579 distinct pose extentions of Resnik’s measure. Leacock and
word types from the BNC and the WSJ treebank. Chodorow (1998)’s measure takes into account the
We extracted all noun pairs from the BNC which path length between two concepts, which is scaled
occurred in a pattern of the form: noun cc noun1, by the depth of the hierarchy in which they re-
as well as lists of any number of nouns separated by side. In (Hirst and St-Onge, 1998) similarity is
commas and ending in cc noun. Each noun in the list based on path length as well as the number of
is linked with every other noun in the list. Thus for changes in the direction in the path. In (Banerjee and
a list: n1, n2, and n3, there will be co-occurrences Pedersen, 2003) semantic relatedness between two
between words n1 and n2, between n1 and n3 and concepts is based on the number of shared words
between n2 and n3. To the BNC data we added all in their WordNet definitions (glosses). The gloss
head noun pairs from the WSJ (sections 02 to 21) of a particular concept is extended to include the
that occurred together in a coordinate noun phrase.2 glosses of other concepts to which it is related in the
From the co-occurrence data we constructed word WordNet hierarchy. Finally, Patwardhan and Peder-
vectors. Every dimension of a word vector repre- son (2006) build on previous work on second-order
sents another word type and the values of the com- co-occurrence vectors (Sch¨utze, 1998) by construct-
ponents of the vector, the term weights, are derived ing second-order co-occurrence vectors from Word-
from the coordinate word co-occurrence counts. We Net glosses, where, as in (Banerjee and Pedersen,
used dampened co-occurrence counts, of the form: 2003), the gloss of a concept is extended so that it
1 + log(count), as the term weights for the word includes the gloss of concepts to which it is directly
vectors. To measure the similarity of two words, w1 related in WordNet.
and w2, we calculate the cosine of the angle between 4 Experiments
the two word vectors, w1 and 192. We selected two sets of data from sections 00, 01,
3 WordNet-Based Similarity Measures 22 and 24 of the WSJ treebank. The first consists
We also examine the following measures of seman- of all nouns pairs which make up the head words
tic similarity which are WordNet-based.3 Wu and of two conjuncts in coordinate noun phrases (again
Palmer (1994) propose a measure of similarity of not including coordinate NPBs). We found 601 such
two concepts c1 and c2 based on the depth of con- coordinate noun pairs. The second data set consists
cepts in the WordNet hierarchy. Similarity is mea- of 601 word pairs which were selected at random
sured from the depth of the most specific node dom- from all head-modifier pairs where both head and
inating both c1 and c2, (their lowest common sub- modifier words are nouns and are not coordinated.
sumer), and normalised by the depths of c1 and We tested the 9 different measures of word similar-
c2. In (Resnik, 1995) concepts in WordNet are ity just described on each data set in order to see if
augmented by corpus statistics and an information- a significant difference could be detected between
theoretic measure of semantic similarity is calcu- the similarity scores for the coordinate words sam-
lated. Similarity of two concepts is measured ple and non-coordinate words sample.
Initially both the coordinate and non-coordinate
pair samples each contained 601 word pairs. How-
ever, before running the experiments we removed
all pairs where the words in the pair were identical.
This is because identical words occur more often in
coordinate head words than in other lexical depen-
dencies (there were 43 pairs with identical words in
the coordination set, compared to 3 such pairs in the
1It would be preferable to ensure that the pairs extracted are
unambiguously conjoined heads. We leave this to future work.
2We did not include coordinate head nouns from base noun
phrases (NPB) (i.e. noun phrases that do not dominate other
noun phrases) because the underspecified annotation of NPBs
in the WSJ means that the conjoined head nouns can not always
be easily identified.
3All of the WordNet-based similarity measure ex-
periments, as well as a random similarity measure,
were carried out with the WordNet::Similarity package,
http://search.cpan.org/dist/WordNet-Similarity.
</bodyText>
<table confidence="0.981361333333333">
150
SimTest ncoord xcoord SDcoord nnonCoord xnonCoord SDnonCoord 95% CI p-value
coordDistrib 503 0.11 0.13 485 0.06 0.09 [0.04 0.07] 0.000
(Resnik, 1995) 444 3.19 2.33 396 2.43 2.10 [0.46 1.06] 0.000
(Lin, 1998) 444 0.27 0.26 396 0.19 0.22 [0.04 0.11] 0.000
(Jiang and Conrath, 1997) 444 0.13 0.65 395 0.07 0.08 [-0.01 0.11] 0.083
(Wu and Palmer, 1994) 444 0.63 0.19 396 0.55 0.19 [0.06 0.11] 0.000
(Leacock and Chodorow, 1998) 444 1.72 0.51 396 1.52 0.47 [0.13 0.27] 0.000
(Hirst and St-Onge, 1998) 459 1.599 2.03 447 1.09 1.87 [0.25 0.76] 0.000
(Banerjee and Pedersen, 2003) 451 114.12 317.18 436 82.20 168.21 [-1.08 64.92] 0.058
(Patwardhan and Pedersen, 2006) 459 0.67 0.18 447 0.66 0.2 [-0.02 0.03] 0.545
random 483 0.89 0.17 447 0.88 0.18 [-0.02 0.02] 0.859
</table>
<tableCaption confidence="0.999675">
Table 1: Summary statistics for 9 different word similarity measures (plus one random measure):ncoord
</tableCaption>
<bodyText confidence="0.999264653846154">
and nnonCoord are the sample sizes for the coordinate and non-coordinate noun pairs samples, respectively;
xcoord, SDcoord and xnonCoord, SDnonCoord are the sample means and standard deviations for the two sets.
The 95% CI column shows the 95% confidence interval for the difference between the two sample means.
The p-value is for a Welch two sample two-sided t-test. coordDistrib is the measure introduced in Section 2.
non-coordination set). If we had not removed them,
a statistically significant difference between the sim-
ilarity scores of the pairs in the two sets could be
found simply by using a measure which, say, gave
one score for identical words and another (lower)
score for all non-identical word pairs.
Results for all similarity measure tests on the data
sets described above are displayed in Table 1. In one
final experiment we used a random measure of sim-
ilarity. For each experiment we produced two sam-
ples, one consisting of the similarity scores given by
the similarity measure for the coordinate noun pairs,
and another set of similarity scores generated for the
non-coordinate pairs. The sample sizes, means, and
standard deviations for each experiment are shown
in the table. Note that the variation in the sample
size is due to coverage: the different measures did
not produce a score for all word pairs. Also dis-
played in Table 1 are the results of statistical signif-
icance tests based on the Welsh two sample t-test.
A 95% confidence interval for the difference of the
sample means is shown along with the p-value.
</bodyText>
<sectionHeader confidence="0.999299" genericHeader="conclusions">
5 Discussion
</sectionHeader>
<bodyText confidence="0.999966697674419">
For all but three of the experiments (excluding the
random measure), the difference between the mean
similarity measures is statistically significant. Inter-
estingly, the three tests where no significant differ-
ence was measured between the scores on the co-
ordination set and the non-coordination set (Jiang
and Conrath, 1997; Banerjee and Pedersen, 2003;
Patwardhan and Pedersen, 2006) were the three
top scoring measures in (Patwardhan and Pedersen,
2006), where a subset of six of the above WordNet-
based experiments were compared and the measures
evaluated against human relatedness judgements and
in a word sense disambiguation task. In another
comparative study (Budanitsky and Hirst, 2002) of
five of the above WordNet-based measures, evalu-
ated as part of a real-word spelling correction sys-
tem, Jiang and Conrath (1997)’s similarity score per-
formed best. Although performing relatively well
under other evaluation criteria, these three measures
seem less suited to measuring the kind of similar-
ity occurring in coordinate noun pairs. One possi-
ble explanation for the unsuitability of the measures
of (Patwardhan and Pedersen, 2006) for the coordi-
nate similarity task could be based on how context
is defined when building context vectors. Context
for an instance of the the word w is taken to be the
words that surround w in the corpus within a given
number of positions, where the corpus is taken as all
the glosses in WordNet. Words that form part of col-
locations such as disk drives or taskforce would then
tend to have very similar contexts, and thus such
word pairs, from non-coordinate modifier-head re-
lations, could be given too high a similarity score.
Although the difference between the mean simi-
larity scores seems rather slight in all experiments,
it is worth noting that not all coordinate head
words are semantically related. To take a cou-
ple of examples from the coordinate word pair set:
work/harmony extracted from hard work and har-
mony, and power/clause extracted from executive
power and the appropriations clause. We would
not expect these word pairs to get a high similar-
ity score. On the other hand, it is also possible that
</bodyText>
<page confidence="0.996673">
151
</page>
<bodyText confidence="0.998736933333333">
some of the examples of non-coordinate dependen-
cies involve semantically similar words. For exam-
ple, nouns in lists are often semantically similar, and
we did not exclude nouns extracted from lists from
the non-coordinate test set.
Although not all coordinate noun pairs are se-
mantically similar, it seems clear, on inspection of
the two sets of data, that they are more likely to be
semantically similar than modifier-head word pairs,
and the tests carried out for most of the measures
of semantic similarity detect a significant difference
between the similarity scores assigned to coordinate
pairs and those assigned to non-coordinate pairs.
It is not possible to judge, based on the signifi-
cance tests alone, which might be the most useful
measure for the purpose of disambiguation. How-
ever, in terms of coverage, the distributional mea-
sure introduced in Section 2 clearly performs best4.
This measure of distributional similarity is perhaps
more suited to the task of coordination disambigua-
tion because it directly measures the type of simi-
larity that occurs between coordinate nouns. That
is, the distributional similarity measure presented in
Section 2 defines two words as similar if they occur
in coordination patterns with a similar set of words
and with similar distributions. Whether the words
are semantically similar becomes irrelevant. A mea-
sure of semantic similarity, on the other hand, might
find words similar which are quite unlikely to ap-
pear in coordination patterns. For example, Ceder-
berg and Widdows (2003) note that words appearing
in coordination patterns tend to be on the same onto-
logical level: ‘fruit and vegetables’ is quite likely to
occur, whereas ‘fruit and apples’ is an unlikely co-
occurrence. A WordNet-based measure of semantic
similarity, however, might give a high score to both
of the noun pairs.
In the future we intend to use the similarity mea-
sure outlined in Section 2 in a lexicalised parser to
help resolve coordinate noun phrase ambiguities.
Acknowledgements Thanks to the TCD Broad
Curriculum Fellowship and to the SFI Research
Grant 04/BR/CS370 for funding this research.
Thanks also to P´adraig Cunningham, Saturnino Luz
and Jennifer Foster for helpful discussions.
</bodyText>
<footnote confidence="0.985243">
4Somewhat unsurprisingly given it is part trained on data
from the same domain.
</footnote>
<sectionHeader confidence="0.792393" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.96911586">
Satanjeev Banerjee and Ted Pedersen. 2003 Extended Gloss
Overlaps as a Measure of Semantic Relatedness. In Pro-
ceeding of the 18th IJCAI.
Alexander Budanitsky and Graeme Hirst. 2002 Semantic Dis-
tance in WordNet: An experimental, application-oriented
Evaluation of Five Measures In Proceedings of the 3rd CI-
CLING.
Sharon Caraballo. 1999 Automatic construction of a
hypernym-labeled noun hierarchy from text In Proceedings
of the 37th ACL.
Scott Cederberg and Dominic Widdows. 2003. Using LSA
and Noun Coordination Information to Improve the Preci-
sion and Recall of Automatic Hyponymy Extraction. In Pro-
ceedings of the 7th CoNLL.
G. Hirst and D. St-Onge 1998. Lexical Chains as repre-
sentations of context for the detection and correction of
malapropisms. WordNet: An electronic lexical database.
MIT Press.
J. Jiang and D. Conrath. 1997. Semantic similarity based on
corpus statistics and lexical taxonomy. In Proceedings of
the ROCLING.
C. Leacock and M. Chodorow. 1998. Combining local context
and WordNet similarity for word sense identification. Word-
Net: An electronic lexical database. MIT Press.
D. Lin. 1998. An information-theoretic definition of similarity.
In Proceedings of the 15th ICML.
Siddharth Patwardhan and Ted Pedersen. 2006. Using
WordNet-based Context Vectors to Estimate the Semantic
Relatedness of Concepts. In Proceedings ofMaking Sense of
Sense - Bringing Computational Linguistics and Psycholin-
guistics Together, EACL.
Philip Resnik. 1995. Using Information Content to Evaluate
Semantic Similarity. In Proceedings ofIJCAI.
Philip Resnik. 1999. Semantic Similarity in a Taxonomy: An
Information-Based Measure and its Application to Problems
of Ambiguity in Natural Language. In Journal of Artificial
Intelligence Research, 11:95-130.
Ellen Riloff and Jessica Shepherd 1997. A Corpus-based Ap-
proach for Building Semantic Lexicon. In Proceedings of
the 2nd EMNLP.
Brian Roark and Eugene Charniak 1998. Noun-phrase Co-
occurrence Statistics for Semi-automatic semantic lexicon
construction. In Proceedings of the COLING-ACL.
Hinrich Sch¨utze. 1998. Automatic Word Sense Discrimination.
Computational Linguistics, 24(1):97-123.
Dominic Widdows and Beate Dorow. 2002. A Graph Model
for Unsupervised Lexical Acquisition. In Proceedings of the
19th COLING.
Zhibiao Wu and Martha Palmer. 1994. Verb Semantics and
Lexical Selection. In Proceedings of the ACL.
</reference>
<page confidence="0.998118">
152
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.883095">
<title confidence="0.909074">Empirical Measurements of Lexical Similarity in Noun Phrase Conjuncts</title>
<affiliation confidence="0.99653">Department of Computer Science Trinity College Dublin</affiliation>
<address confidence="0.998761">Dublin 2, Ireland</address>
<email confidence="0.992538">dhogan@computing.dcu.ie</email>
<abstract confidence="0.9991598125">The ability to detect similarity in conjunct heads is potentially a useful tool in helping to disambiguate coordination structures a difficult task for parsers. We propose a distributional measure of similarity designed for such a task. We then compare several different measures of word similarity by testing whether they can empirically detect similarity in the head nouns of noun phrase conjuncts in the Wall Street Journal (WSJ) treebank. We demonstrate that several measures of word similarity can successfully detect conjunct head similarity and suggest that the measure proposed in this paper is the most appropriate for this task.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Satanjeev Banerjee</author>
<author>Ted Pedersen</author>
</authors>
<title>Extended Gloss Overlaps as a Measure of Semantic Relatedness.</title>
<date>2003</date>
<booktitle>In Proceeding of the 18th IJCAI.</booktitle>
<contexts>
<context position="8513" citStr="Banerjee and Pedersen, 2003" startWordPosition="1398" endWordPosition="1401">ge, http://search.cpan.org/dist/WordNet-Similarity. 150 SimTest ncoord xcoord SDcoord nnonCoord xnonCoord SDnonCoord 95% CI p-value coordDistrib 503 0.11 0.13 485 0.06 0.09 [0.04 0.07] 0.000 (Resnik, 1995) 444 3.19 2.33 396 2.43 2.10 [0.46 1.06] 0.000 (Lin, 1998) 444 0.27 0.26 396 0.19 0.22 [0.04 0.11] 0.000 (Jiang and Conrath, 1997) 444 0.13 0.65 395 0.07 0.08 [-0.01 0.11] 0.083 (Wu and Palmer, 1994) 444 0.63 0.19 396 0.55 0.19 [0.06 0.11] 0.000 (Leacock and Chodorow, 1998) 444 1.72 0.51 396 1.52 0.47 [0.13 0.27] 0.000 (Hirst and St-Onge, 1998) 459 1.599 2.03 447 1.09 1.87 [0.25 0.76] 0.000 (Banerjee and Pedersen, 2003) 451 114.12 317.18 436 82.20 168.21 [-1.08 64.92] 0.058 (Patwardhan and Pedersen, 2006) 459 0.67 0.18 447 0.66 0.2 [-0.02 0.03] 0.545 random 483 0.89 0.17 447 0.88 0.18 [-0.02 0.02] 0.859 Table 1: Summary statistics for 9 different word similarity measures (plus one random measure):ncoord and nnonCoord are the sample sizes for the coordinate and non-coordinate noun pairs samples, respectively; xcoord, SDcoord and xnonCoord, SDnonCoord are the sample means and standard deviations for the two sets. The 95% CI column shows the 95% confidence interval for the difference between the two sample mean</context>
<context position="10711" citStr="Banerjee and Pedersen, 2003" startWordPosition="1755" endWordPosition="1758">sures did not produce a score for all word pairs. Also displayed in Table 1 are the results of statistical significance tests based on the Welsh two sample t-test. A 95% confidence interval for the difference of the sample means is shown along with the p-value. 5 Discussion For all but three of the experiments (excluding the random measure), the difference between the mean similarity measures is statistically significant. Interestingly, the three tests where no significant difference was measured between the scores on the coordination set and the non-coordination set (Jiang and Conrath, 1997; Banerjee and Pedersen, 2003; Patwardhan and Pedersen, 2006) were the three top scoring measures in (Patwardhan and Pedersen, 2006), where a subset of six of the above WordNetbased experiments were compared and the measures evaluated against human relatedness judgements and in a word sense disambiguation task. In another comparative study (Budanitsky and Hirst, 2002) of five of the above WordNet-based measures, evaluated as part of a real-word spelling correction system, Jiang and Conrath (1997)’s similarity score performed best. Although performing relatively well under other evaluation criteria, these three measures se</context>
</contexts>
<marker>Banerjee, Pedersen, 2003</marker>
<rawString>Satanjeev Banerjee and Ted Pedersen. 2003 Extended Gloss Overlaps as a Measure of Semantic Relatedness. In Proceeding of the 18th IJCAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Budanitsky</author>
<author>Graeme Hirst</author>
</authors>
<title>Semantic Distance in WordNet: An experimental, application-oriented Evaluation of Five Measures</title>
<date>2002</date>
<booktitle>In Proceedings of the 3rd CICLING.</booktitle>
<contexts>
<context position="11052" citStr="Budanitsky and Hirst, 2002" startWordPosition="1806" endWordPosition="1809">), the difference between the mean similarity measures is statistically significant. Interestingly, the three tests where no significant difference was measured between the scores on the coordination set and the non-coordination set (Jiang and Conrath, 1997; Banerjee and Pedersen, 2003; Patwardhan and Pedersen, 2006) were the three top scoring measures in (Patwardhan and Pedersen, 2006), where a subset of six of the above WordNetbased experiments were compared and the measures evaluated against human relatedness judgements and in a word sense disambiguation task. In another comparative study (Budanitsky and Hirst, 2002) of five of the above WordNet-based measures, evaluated as part of a real-word spelling correction system, Jiang and Conrath (1997)’s similarity score performed best. Although performing relatively well under other evaluation criteria, these three measures seem less suited to measuring the kind of similarity occurring in coordinate noun pairs. One possible explanation for the unsuitability of the measures of (Patwardhan and Pedersen, 2006) for the coordinate similarity task could be based on how context is defined when building context vectors. Context for an instance of the the word w is take</context>
</contexts>
<marker>Budanitsky, Hirst, 2002</marker>
<rawString>Alexander Budanitsky and Graeme Hirst. 2002 Semantic Distance in WordNet: An experimental, application-oriented Evaluation of Five Measures In Proceedings of the 3rd CICLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sharon Caraballo</author>
</authors>
<title>Automatic construction of a hypernym-labeled noun hierarchy from text</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th ACL.</booktitle>
<contexts>
<context position="1979" citStr="Caraballo, 1999" startWordPosition="307" endWordPosition="308">than busloads and spouses. If nouns co-occurring in coordination patterns are often semantically similar, and if a simi* Now at the National Centre for Language Technology, Dublin City University, Ireland. larity measure could be defined so that, for example: sim(executives, spouses) &gt; sim(busloads, spouses) then it is potentially useful for coordination disambiguation. The idea that nouns co-occurring in conjunctions tend to be semantically related has been noted in (Riloff and Shepherd, 1997) and used effectively to automatically cluster semantically similar words (Roark and Charniak, 1998; Caraballo, 1999; Widdows and Dorow, 2002). The tendency for conjoined nouns to be semantically similar has also been exploited for coordinate noun phrase disambiguation by Resnik (1999) who employed a measure of similarity based on WordNet to measure which were the head nouns being conjoined in certain types of coordinate noun phrase. In this paper we look at different measures of word similarity in order to discover whether they can detect empirically a tendency for conjoined nouns to be more similar than nouns which co-occur but are not conjoined. In Section 2 we introduce a measure of word similarity base</context>
</contexts>
<marker>Caraballo, 1999</marker>
<rawString>Sharon Caraballo. 1999 Automatic construction of a hypernym-labeled noun hierarchy from text In Proceedings of the 37th ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott Cederberg</author>
<author>Dominic Widdows</author>
</authors>
<title>Using LSA and Noun Coordination Information to Improve the Precision and Recall of Automatic Hyponymy Extraction.</title>
<date>2003</date>
<booktitle>In Proceedings of the 7th CoNLL.</booktitle>
<contexts>
<context position="14047" citStr="Cederberg and Widdows (2003)" startWordPosition="2294" endWordPosition="2298">e of distributional similarity is perhaps more suited to the task of coordination disambiguation because it directly measures the type of similarity that occurs between coordinate nouns. That is, the distributional similarity measure presented in Section 2 defines two words as similar if they occur in coordination patterns with a similar set of words and with similar distributions. Whether the words are semantically similar becomes irrelevant. A measure of semantic similarity, on the other hand, might find words similar which are quite unlikely to appear in coordination patterns. For example, Cederberg and Widdows (2003) note that words appearing in coordination patterns tend to be on the same ontological level: ‘fruit and vegetables’ is quite likely to occur, whereas ‘fruit and apples’ is an unlikely cooccurrence. A WordNet-based measure of semantic similarity, however, might give a high score to both of the noun pairs. In the future we intend to use the similarity measure outlined in Section 2 in a lexicalised parser to help resolve coordinate noun phrase ambiguities. Acknowledgements Thanks to the TCD Broad Curriculum Fellowship and to the SFI Research Grant 04/BR/CS370 for funding this research. Thanks al</context>
</contexts>
<marker>Cederberg, Widdows, 2003</marker>
<rawString>Scott Cederberg and Dominic Widdows. 2003. Using LSA and Noun Coordination Information to Improve the Precision and Recall of Automatic Hyponymy Extraction. In Proceedings of the 7th CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Hirst</author>
<author>D St-Onge</author>
</authors>
<title>Lexical Chains as representations of context for the detection and correction of malapropisms. WordNet: An electronic lexical database.</title>
<date>1998</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="4024" citStr="Hirst and St-Onge, 1998" startWordPosition="644" endWordPosition="647"> mon subsumer in the is-a hierarchy of WordNet. information, extracted from conjunctions and lists. Both Jiang and Conrath (1997) and Lin (1998) proWe collected co-occurrence data on 82, 579 distinct pose extentions of Resnik’s measure. Leacock and word types from the BNC and the WSJ treebank. Chodorow (1998)’s measure takes into account the We extracted all noun pairs from the BNC which path length between two concepts, which is scaled occurred in a pattern of the form: noun cc noun1, by the depth of the hierarchy in which they reas well as lists of any number of nouns separated by side. In (Hirst and St-Onge, 1998) similarity is commas and ending in cc noun. Each noun in the list based on path length as well as the number of is linked with every other noun in the list. Thus for changes in the direction in the path. In (Banerjee and a list: n1, n2, and n3, there will be co-occurrences Pedersen, 2003) semantic relatedness between two between words n1 and n2, between n1 and n3 and concepts is based on the number of shared words between n2 and n3. To the BNC data we added all in their WordNet definitions (glosses). The gloss head noun pairs from the WSJ (sections 02 to 21) of a particular concept is extende</context>
<context position="8436" citStr="Hirst and St-Onge, 1998" startWordPosition="1385" endWordPosition="1388">m similarity measure, were carried out with the WordNet::Similarity package, http://search.cpan.org/dist/WordNet-Similarity. 150 SimTest ncoord xcoord SDcoord nnonCoord xnonCoord SDnonCoord 95% CI p-value coordDistrib 503 0.11 0.13 485 0.06 0.09 [0.04 0.07] 0.000 (Resnik, 1995) 444 3.19 2.33 396 2.43 2.10 [0.46 1.06] 0.000 (Lin, 1998) 444 0.27 0.26 396 0.19 0.22 [0.04 0.11] 0.000 (Jiang and Conrath, 1997) 444 0.13 0.65 395 0.07 0.08 [-0.01 0.11] 0.083 (Wu and Palmer, 1994) 444 0.63 0.19 396 0.55 0.19 [0.06 0.11] 0.000 (Leacock and Chodorow, 1998) 444 1.72 0.51 396 1.52 0.47 [0.13 0.27] 0.000 (Hirst and St-Onge, 1998) 459 1.599 2.03 447 1.09 1.87 [0.25 0.76] 0.000 (Banerjee and Pedersen, 2003) 451 114.12 317.18 436 82.20 168.21 [-1.08 64.92] 0.058 (Patwardhan and Pedersen, 2006) 459 0.67 0.18 447 0.66 0.2 [-0.02 0.03] 0.545 random 483 0.89 0.17 447 0.88 0.18 [-0.02 0.02] 0.859 Table 1: Summary statistics for 9 different word similarity measures (plus one random measure):ncoord and nnonCoord are the sample sizes for the coordinate and non-coordinate noun pairs samples, respectively; xcoord, SDcoord and xnonCoord, SDnonCoord are the sample means and standard deviations for the two sets. The 95% CI column sho</context>
</contexts>
<marker>Hirst, St-Onge, 1998</marker>
<rawString>G. Hirst and D. St-Onge 1998. Lexical Chains as representations of context for the detection and correction of malapropisms. WordNet: An electronic lexical database. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Jiang</author>
<author>D Conrath</author>
</authors>
<title>Semantic similarity based on corpus statistics and lexical taxonomy.</title>
<date>1997</date>
<booktitle>In Proceedings of the ROCLING.</booktitle>
<contexts>
<context position="3529" citStr="Jiang and Conrath (1997)" startWordPosition="555" endWordPosition="558">vious place to start, when looking at similarity functions for measuring the type of semantic similarity common for coordinate nouns, is a similarity function based on distributional similarity with context de149 Proceedings of the ACL 2007 Demo and Poster Sessions, pages 149–152, Prague, June 2007. c�2007 Association for Computational Linguistics fined in terms of coordination patterns. Our mea- by the information content of their lowest comsure of similarity is based on noun co-occurrence mon subsumer in the is-a hierarchy of WordNet. information, extracted from conjunctions and lists. Both Jiang and Conrath (1997) and Lin (1998) proWe collected co-occurrence data on 82, 579 distinct pose extentions of Resnik’s measure. Leacock and word types from the BNC and the WSJ treebank. Chodorow (1998)’s measure takes into account the We extracted all noun pairs from the BNC which path length between two concepts, which is scaled occurred in a pattern of the form: noun cc noun1, by the depth of the hierarchy in which they reas well as lists of any number of nouns separated by side. In (Hirst and St-Onge, 1998) similarity is commas and ending in cc noun. Each noun in the list based on path length as well as the nu</context>
<context position="8220" citStr="Jiang and Conrath, 1997" startWordPosition="1346" endWordPosition="1349"> phrases) because the underspecified annotation of NPBs in the WSJ means that the conjoined head nouns can not always be easily identified. 3All of the WordNet-based similarity measure experiments, as well as a random similarity measure, were carried out with the WordNet::Similarity package, http://search.cpan.org/dist/WordNet-Similarity. 150 SimTest ncoord xcoord SDcoord nnonCoord xnonCoord SDnonCoord 95% CI p-value coordDistrib 503 0.11 0.13 485 0.06 0.09 [0.04 0.07] 0.000 (Resnik, 1995) 444 3.19 2.33 396 2.43 2.10 [0.46 1.06] 0.000 (Lin, 1998) 444 0.27 0.26 396 0.19 0.22 [0.04 0.11] 0.000 (Jiang and Conrath, 1997) 444 0.13 0.65 395 0.07 0.08 [-0.01 0.11] 0.083 (Wu and Palmer, 1994) 444 0.63 0.19 396 0.55 0.19 [0.06 0.11] 0.000 (Leacock and Chodorow, 1998) 444 1.72 0.51 396 1.52 0.47 [0.13 0.27] 0.000 (Hirst and St-Onge, 1998) 459 1.599 2.03 447 1.09 1.87 [0.25 0.76] 0.000 (Banerjee and Pedersen, 2003) 451 114.12 317.18 436 82.20 168.21 [-1.08 64.92] 0.058 (Patwardhan and Pedersen, 2006) 459 0.67 0.18 447 0.66 0.2 [-0.02 0.03] 0.545 random 483 0.89 0.17 447 0.88 0.18 [-0.02 0.02] 0.859 Table 1: Summary statistics for 9 different word similarity measures (plus one random measure):ncoord and nnonCoord are</context>
<context position="10682" citStr="Jiang and Conrath, 1997" startWordPosition="1751" endWordPosition="1754">verage: the different measures did not produce a score for all word pairs. Also displayed in Table 1 are the results of statistical significance tests based on the Welsh two sample t-test. A 95% confidence interval for the difference of the sample means is shown along with the p-value. 5 Discussion For all but three of the experiments (excluding the random measure), the difference between the mean similarity measures is statistically significant. Interestingly, the three tests where no significant difference was measured between the scores on the coordination set and the non-coordination set (Jiang and Conrath, 1997; Banerjee and Pedersen, 2003; Patwardhan and Pedersen, 2006) were the three top scoring measures in (Patwardhan and Pedersen, 2006), where a subset of six of the above WordNetbased experiments were compared and the measures evaluated against human relatedness judgements and in a word sense disambiguation task. In another comparative study (Budanitsky and Hirst, 2002) of five of the above WordNet-based measures, evaluated as part of a real-word spelling correction system, Jiang and Conrath (1997)’s similarity score performed best. Although performing relatively well under other evaluation crit</context>
</contexts>
<marker>Jiang, Conrath, 1997</marker>
<rawString>J. Jiang and D. Conrath. 1997. Semantic similarity based on corpus statistics and lexical taxonomy. In Proceedings of the ROCLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Leacock</author>
<author>M Chodorow</author>
</authors>
<title>Combining local context and WordNet similarity for word sense identification. WordNet: An electronic lexical database.</title>
<date>1998</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="8364" citStr="Leacock and Chodorow, 1998" startWordPosition="1372" endWordPosition="1375">All of the WordNet-based similarity measure experiments, as well as a random similarity measure, were carried out with the WordNet::Similarity package, http://search.cpan.org/dist/WordNet-Similarity. 150 SimTest ncoord xcoord SDcoord nnonCoord xnonCoord SDnonCoord 95% CI p-value coordDistrib 503 0.11 0.13 485 0.06 0.09 [0.04 0.07] 0.000 (Resnik, 1995) 444 3.19 2.33 396 2.43 2.10 [0.46 1.06] 0.000 (Lin, 1998) 444 0.27 0.26 396 0.19 0.22 [0.04 0.11] 0.000 (Jiang and Conrath, 1997) 444 0.13 0.65 395 0.07 0.08 [-0.01 0.11] 0.083 (Wu and Palmer, 1994) 444 0.63 0.19 396 0.55 0.19 [0.06 0.11] 0.000 (Leacock and Chodorow, 1998) 444 1.72 0.51 396 1.52 0.47 [0.13 0.27] 0.000 (Hirst and St-Onge, 1998) 459 1.599 2.03 447 1.09 1.87 [0.25 0.76] 0.000 (Banerjee and Pedersen, 2003) 451 114.12 317.18 436 82.20 168.21 [-1.08 64.92] 0.058 (Patwardhan and Pedersen, 2006) 459 0.67 0.18 447 0.66 0.2 [-0.02 0.03] 0.545 random 483 0.89 0.17 447 0.88 0.18 [-0.02 0.02] 0.859 Table 1: Summary statistics for 9 different word similarity measures (plus one random measure):ncoord and nnonCoord are the sample sizes for the coordinate and non-coordinate noun pairs samples, respectively; xcoord, SDcoord and xnonCoord, SDnonCoord are the samp</context>
</contexts>
<marker>Leacock, Chodorow, 1998</marker>
<rawString>C. Leacock and M. Chodorow. 1998. Combining local context and WordNet similarity for word sense identification. WordNet: An electronic lexical database. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lin</author>
</authors>
<title>An information-theoretic definition of similarity.</title>
<date>1998</date>
<booktitle>In Proceedings of the 15th ICML.</booktitle>
<contexts>
<context position="3544" citStr="Lin (1998)" startWordPosition="560" endWordPosition="561">oking at similarity functions for measuring the type of semantic similarity common for coordinate nouns, is a similarity function based on distributional similarity with context de149 Proceedings of the ACL 2007 Demo and Poster Sessions, pages 149–152, Prague, June 2007. c�2007 Association for Computational Linguistics fined in terms of coordination patterns. Our mea- by the information content of their lowest comsure of similarity is based on noun co-occurrence mon subsumer in the is-a hierarchy of WordNet. information, extracted from conjunctions and lists. Both Jiang and Conrath (1997) and Lin (1998) proWe collected co-occurrence data on 82, 579 distinct pose extentions of Resnik’s measure. Leacock and word types from the BNC and the WSJ treebank. Chodorow (1998)’s measure takes into account the We extracted all noun pairs from the BNC which path length between two concepts, which is scaled occurred in a pattern of the form: noun cc noun1, by the depth of the hierarchy in which they reas well as lists of any number of nouns separated by side. In (Hirst and St-Onge, 1998) similarity is commas and ending in cc noun. Each noun in the list based on path length as well as the number of is link</context>
<context position="8148" citStr="Lin, 1998" startWordPosition="1335" endWordPosition="1336">s (NPB) (i.e. noun phrases that do not dominate other noun phrases) because the underspecified annotation of NPBs in the WSJ means that the conjoined head nouns can not always be easily identified. 3All of the WordNet-based similarity measure experiments, as well as a random similarity measure, were carried out with the WordNet::Similarity package, http://search.cpan.org/dist/WordNet-Similarity. 150 SimTest ncoord xcoord SDcoord nnonCoord xnonCoord SDnonCoord 95% CI p-value coordDistrib 503 0.11 0.13 485 0.06 0.09 [0.04 0.07] 0.000 (Resnik, 1995) 444 3.19 2.33 396 2.43 2.10 [0.46 1.06] 0.000 (Lin, 1998) 444 0.27 0.26 396 0.19 0.22 [0.04 0.11] 0.000 (Jiang and Conrath, 1997) 444 0.13 0.65 395 0.07 0.08 [-0.01 0.11] 0.083 (Wu and Palmer, 1994) 444 0.63 0.19 396 0.55 0.19 [0.06 0.11] 0.000 (Leacock and Chodorow, 1998) 444 1.72 0.51 396 1.52 0.47 [0.13 0.27] 0.000 (Hirst and St-Onge, 1998) 459 1.599 2.03 447 1.09 1.87 [0.25 0.76] 0.000 (Banerjee and Pedersen, 2003) 451 114.12 317.18 436 82.20 168.21 [-1.08 64.92] 0.058 (Patwardhan and Pedersen, 2006) 459 0.67 0.18 447 0.66 0.2 [-0.02 0.03] 0.545 random 483 0.89 0.17 447 0.88 0.18 [-0.02 0.02] 0.859 Table 1: Summary statistics for 9 different wor</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>D. Lin. 1998. An information-theoretic definition of similarity. In Proceedings of the 15th ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Siddharth Patwardhan</author>
<author>Ted Pedersen</author>
</authors>
<title>Using WordNet-based Context Vectors to Estimate the Semantic Relatedness of Concepts.</title>
<date>2006</date>
<booktitle>In Proceedings ofMaking Sense of Sense - Bringing Computational Linguistics and Psycholinguistics Together, EACL.</booktitle>
<contexts>
<context position="8600" citStr="Patwardhan and Pedersen, 2006" startWordPosition="1411" endWordPosition="1414"> nnonCoord xnonCoord SDnonCoord 95% CI p-value coordDistrib 503 0.11 0.13 485 0.06 0.09 [0.04 0.07] 0.000 (Resnik, 1995) 444 3.19 2.33 396 2.43 2.10 [0.46 1.06] 0.000 (Lin, 1998) 444 0.27 0.26 396 0.19 0.22 [0.04 0.11] 0.000 (Jiang and Conrath, 1997) 444 0.13 0.65 395 0.07 0.08 [-0.01 0.11] 0.083 (Wu and Palmer, 1994) 444 0.63 0.19 396 0.55 0.19 [0.06 0.11] 0.000 (Leacock and Chodorow, 1998) 444 1.72 0.51 396 1.52 0.47 [0.13 0.27] 0.000 (Hirst and St-Onge, 1998) 459 1.599 2.03 447 1.09 1.87 [0.25 0.76] 0.000 (Banerjee and Pedersen, 2003) 451 114.12 317.18 436 82.20 168.21 [-1.08 64.92] 0.058 (Patwardhan and Pedersen, 2006) 459 0.67 0.18 447 0.66 0.2 [-0.02 0.03] 0.545 random 483 0.89 0.17 447 0.88 0.18 [-0.02 0.02] 0.859 Table 1: Summary statistics for 9 different word similarity measures (plus one random measure):ncoord and nnonCoord are the sample sizes for the coordinate and non-coordinate noun pairs samples, respectively; xcoord, SDcoord and xnonCoord, SDnonCoord are the sample means and standard deviations for the two sets. The 95% CI column shows the 95% confidence interval for the difference between the two sample means. The p-value is for a Welch two sample two-sided t-test. coordDistrib is the measure </context>
<context position="10743" citStr="Patwardhan and Pedersen, 2006" startWordPosition="1759" endWordPosition="1762"> for all word pairs. Also displayed in Table 1 are the results of statistical significance tests based on the Welsh two sample t-test. A 95% confidence interval for the difference of the sample means is shown along with the p-value. 5 Discussion For all but three of the experiments (excluding the random measure), the difference between the mean similarity measures is statistically significant. Interestingly, the three tests where no significant difference was measured between the scores on the coordination set and the non-coordination set (Jiang and Conrath, 1997; Banerjee and Pedersen, 2003; Patwardhan and Pedersen, 2006) were the three top scoring measures in (Patwardhan and Pedersen, 2006), where a subset of six of the above WordNetbased experiments were compared and the measures evaluated against human relatedness judgements and in a word sense disambiguation task. In another comparative study (Budanitsky and Hirst, 2002) of five of the above WordNet-based measures, evaluated as part of a real-word spelling correction system, Jiang and Conrath (1997)’s similarity score performed best. Although performing relatively well under other evaluation criteria, these three measures seem less suited to measuring the </context>
</contexts>
<marker>Patwardhan, Pedersen, 2006</marker>
<rawString>Siddharth Patwardhan and Ted Pedersen. 2006. Using WordNet-based Context Vectors to Estimate the Semantic Relatedness of Concepts. In Proceedings ofMaking Sense of Sense - Bringing Computational Linguistics and Psycholinguistics Together, EACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
</authors>
<title>Using Information Content to Evaluate Semantic Similarity.</title>
<date>1995</date>
<booktitle>In Proceedings ofIJCAI.</booktitle>
<contexts>
<context position="6579" citStr="Resnik, 1995" startWordPosition="1091" endWordPosition="1092"> (1994) propose a measure of similarity of not including coordinate NPBs). We found 601 such two concepts c1 and c2 based on the depth of con- coordinate noun pairs. The second data set consists cepts in the WordNet hierarchy. Similarity is mea- of 601 word pairs which were selected at random sured from the depth of the most specific node dom- from all head-modifier pairs where both head and inating both c1 and c2, (their lowest common sub- modifier words are nouns and are not coordinated. sumer), and normalised by the depths of c1 and We tested the 9 different measures of word similarc2. In (Resnik, 1995) concepts in WordNet are ity just described on each data set in order to see if augmented by corpus statistics and an information- a significant difference could be detected between theoretic measure of semantic similarity is calcu- the similarity scores for the coordinate words samlated. Similarity of two concepts is measured ple and non-coordinate words sample. Initially both the coordinate and non-coordinate pair samples each contained 601 word pairs. However, before running the experiments we removed all pairs where the words in the pair were identical. This is because identical words occu</context>
<context position="8090" citStr="Resnik, 1995" startWordPosition="1324" endWordPosition="1325">e did not include coordinate head nouns from base noun phrases (NPB) (i.e. noun phrases that do not dominate other noun phrases) because the underspecified annotation of NPBs in the WSJ means that the conjoined head nouns can not always be easily identified. 3All of the WordNet-based similarity measure experiments, as well as a random similarity measure, were carried out with the WordNet::Similarity package, http://search.cpan.org/dist/WordNet-Similarity. 150 SimTest ncoord xcoord SDcoord nnonCoord xnonCoord SDnonCoord 95% CI p-value coordDistrib 503 0.11 0.13 485 0.06 0.09 [0.04 0.07] 0.000 (Resnik, 1995) 444 3.19 2.33 396 2.43 2.10 [0.46 1.06] 0.000 (Lin, 1998) 444 0.27 0.26 396 0.19 0.22 [0.04 0.11] 0.000 (Jiang and Conrath, 1997) 444 0.13 0.65 395 0.07 0.08 [-0.01 0.11] 0.083 (Wu and Palmer, 1994) 444 0.63 0.19 396 0.55 0.19 [0.06 0.11] 0.000 (Leacock and Chodorow, 1998) 444 1.72 0.51 396 1.52 0.47 [0.13 0.27] 0.000 (Hirst and St-Onge, 1998) 459 1.599 2.03 447 1.09 1.87 [0.25 0.76] 0.000 (Banerjee and Pedersen, 2003) 451 114.12 317.18 436 82.20 168.21 [-1.08 64.92] 0.058 (Patwardhan and Pedersen, 2006) 459 0.67 0.18 447 0.66 0.2 [-0.02 0.03] 0.545 random 483 0.89 0.17 447 0.88 0.18 [-0.02 0</context>
</contexts>
<marker>Resnik, 1995</marker>
<rawString>Philip Resnik. 1995. Using Information Content to Evaluate Semantic Similarity. In Proceedings ofIJCAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
</authors>
<title>Semantic Similarity in a Taxonomy: An Information-Based Measure and its Application to Problems of Ambiguity in Natural Language.</title>
<date>1999</date>
<journal>In Journal of Artificial Intelligence Research,</journal>
<pages>11--95</pages>
<contexts>
<context position="2149" citStr="Resnik (1999)" startWordPosition="334" endWordPosition="335"> Dublin City University, Ireland. larity measure could be defined so that, for example: sim(executives, spouses) &gt; sim(busloads, spouses) then it is potentially useful for coordination disambiguation. The idea that nouns co-occurring in conjunctions tend to be semantically related has been noted in (Riloff and Shepherd, 1997) and used effectively to automatically cluster semantically similar words (Roark and Charniak, 1998; Caraballo, 1999; Widdows and Dorow, 2002). The tendency for conjoined nouns to be semantically similar has also been exploited for coordinate noun phrase disambiguation by Resnik (1999) who employed a measure of similarity based on WordNet to measure which were the head nouns being conjoined in certain types of coordinate noun phrase. In this paper we look at different measures of word similarity in order to discover whether they can detect empirically a tendency for conjoined nouns to be more similar than nouns which co-occur but are not conjoined. In Section 2 we introduce a measure of word similarity based on word vectors and in Section 3 we briefly describe some WordNet similarity measures which, in addition to our word vector measure, will be tested in the experiments o</context>
</contexts>
<marker>Resnik, 1999</marker>
<rawString>Philip Resnik. 1999. Semantic Similarity in a Taxonomy: An Information-Based Measure and its Application to Problems of Ambiguity in Natural Language. In Journal of Artificial Intelligence Research, 11:95-130.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen Riloff</author>
<author>Jessica Shepherd</author>
</authors>
<title>A Corpus-based Approach for Building Semantic Lexicon.</title>
<date>1997</date>
<booktitle>In Proceedings of the 2nd EMNLP.</booktitle>
<contexts>
<context position="1863" citStr="Riloff and Shepherd, 1997" startWordPosition="289" endWordPosition="292">se of discrimination, a parsing model would benefit if it could learn that executives and spouses is a more likely combination than busloads and spouses. If nouns co-occurring in coordination patterns are often semantically similar, and if a simi* Now at the National Centre for Language Technology, Dublin City University, Ireland. larity measure could be defined so that, for example: sim(executives, spouses) &gt; sim(busloads, spouses) then it is potentially useful for coordination disambiguation. The idea that nouns co-occurring in conjunctions tend to be semantically related has been noted in (Riloff and Shepherd, 1997) and used effectively to automatically cluster semantically similar words (Roark and Charniak, 1998; Caraballo, 1999; Widdows and Dorow, 2002). The tendency for conjoined nouns to be semantically similar has also been exploited for coordinate noun phrase disambiguation by Resnik (1999) who employed a measure of similarity based on WordNet to measure which were the head nouns being conjoined in certain types of coordinate noun phrase. In this paper we look at different measures of word similarity in order to discover whether they can detect empirically a tendency for conjoined nouns to be more </context>
</contexts>
<marker>Riloff, Shepherd, 1997</marker>
<rawString>Ellen Riloff and Jessica Shepherd 1997. A Corpus-based Approach for Building Semantic Lexicon. In Proceedings of the 2nd EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brian Roark</author>
<author>Eugene Charniak</author>
</authors>
<title>Noun-phrase Cooccurrence Statistics for Semi-automatic semantic lexicon construction.</title>
<date>1998</date>
<booktitle>In Proceedings of the COLING-ACL.</booktitle>
<contexts>
<context position="1962" citStr="Roark and Charniak, 1998" startWordPosition="303" endWordPosition="306">a more likely combination than busloads and spouses. If nouns co-occurring in coordination patterns are often semantically similar, and if a simi* Now at the National Centre for Language Technology, Dublin City University, Ireland. larity measure could be defined so that, for example: sim(executives, spouses) &gt; sim(busloads, spouses) then it is potentially useful for coordination disambiguation. The idea that nouns co-occurring in conjunctions tend to be semantically related has been noted in (Riloff and Shepherd, 1997) and used effectively to automatically cluster semantically similar words (Roark and Charniak, 1998; Caraballo, 1999; Widdows and Dorow, 2002). The tendency for conjoined nouns to be semantically similar has also been exploited for coordinate noun phrase disambiguation by Resnik (1999) who employed a measure of similarity based on WordNet to measure which were the head nouns being conjoined in certain types of coordinate noun phrase. In this paper we look at different measures of word similarity in order to discover whether they can detect empirically a tendency for conjoined nouns to be more similar than nouns which co-occur but are not conjoined. In Section 2 we introduce a measure of wor</context>
</contexts>
<marker>Roark, Charniak, 1998</marker>
<rawString>Brian Roark and Eugene Charniak 1998. Noun-phrase Cooccurrence Statistics for Semi-automatic semantic lexicon construction. In Proceedings of the COLING-ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hinrich Sch¨utze</author>
</authors>
<title>Automatic Word Sense Discrimination.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<pages>24--1</pages>
<marker>Sch¨utze, 1998</marker>
<rawString>Hinrich Sch¨utze. 1998. Automatic Word Sense Discrimination. Computational Linguistics, 24(1):97-123.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dominic Widdows</author>
<author>Beate Dorow</author>
</authors>
<title>A Graph Model for Unsupervised Lexical Acquisition.</title>
<date>2002</date>
<booktitle>In Proceedings of the 19th COLING.</booktitle>
<contexts>
<context position="2005" citStr="Widdows and Dorow, 2002" startWordPosition="309" endWordPosition="312"> spouses. If nouns co-occurring in coordination patterns are often semantically similar, and if a simi* Now at the National Centre for Language Technology, Dublin City University, Ireland. larity measure could be defined so that, for example: sim(executives, spouses) &gt; sim(busloads, spouses) then it is potentially useful for coordination disambiguation. The idea that nouns co-occurring in conjunctions tend to be semantically related has been noted in (Riloff and Shepherd, 1997) and used effectively to automatically cluster semantically similar words (Roark and Charniak, 1998; Caraballo, 1999; Widdows and Dorow, 2002). The tendency for conjoined nouns to be semantically similar has also been exploited for coordinate noun phrase disambiguation by Resnik (1999) who employed a measure of similarity based on WordNet to measure which were the head nouns being conjoined in certain types of coordinate noun phrase. In this paper we look at different measures of word similarity in order to discover whether they can detect empirically a tendency for conjoined nouns to be more similar than nouns which co-occur but are not conjoined. In Section 2 we introduce a measure of word similarity based on word vectors and in S</context>
</contexts>
<marker>Widdows, Dorow, 2002</marker>
<rawString>Dominic Widdows and Beate Dorow. 2002. A Graph Model for Unsupervised Lexical Acquisition. In Proceedings of the 19th COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhibiao Wu</author>
<author>Martha Palmer</author>
</authors>
<title>Verb Semantics and Lexical Selection.</title>
<date>1994</date>
<booktitle>In Proceedings of the ACL.</booktitle>
<contexts>
<context position="8289" citStr="Wu and Palmer, 1994" startWordPosition="1359" endWordPosition="1362">that the conjoined head nouns can not always be easily identified. 3All of the WordNet-based similarity measure experiments, as well as a random similarity measure, were carried out with the WordNet::Similarity package, http://search.cpan.org/dist/WordNet-Similarity. 150 SimTest ncoord xcoord SDcoord nnonCoord xnonCoord SDnonCoord 95% CI p-value coordDistrib 503 0.11 0.13 485 0.06 0.09 [0.04 0.07] 0.000 (Resnik, 1995) 444 3.19 2.33 396 2.43 2.10 [0.46 1.06] 0.000 (Lin, 1998) 444 0.27 0.26 396 0.19 0.22 [0.04 0.11] 0.000 (Jiang and Conrath, 1997) 444 0.13 0.65 395 0.07 0.08 [-0.01 0.11] 0.083 (Wu and Palmer, 1994) 444 0.63 0.19 396 0.55 0.19 [0.06 0.11] 0.000 (Leacock and Chodorow, 1998) 444 1.72 0.51 396 1.52 0.47 [0.13 0.27] 0.000 (Hirst and St-Onge, 1998) 459 1.599 2.03 447 1.09 1.87 [0.25 0.76] 0.000 (Banerjee and Pedersen, 2003) 451 114.12 317.18 436 82.20 168.21 [-1.08 64.92] 0.058 (Patwardhan and Pedersen, 2006) 459 0.67 0.18 447 0.66 0.2 [-0.02 0.03] 0.545 random 483 0.89 0.17 447 0.88 0.18 [-0.02 0.02] 0.859 Table 1: Summary statistics for 9 different word similarity measures (plus one random measure):ncoord and nnonCoord are the sample sizes for the coordinate and non-coordinate noun pairs sa</context>
</contexts>
<marker>Wu, Palmer, 1994</marker>
<rawString>Zhibiao Wu and Martha Palmer. 1994. Verb Semantics and Lexical Selection. In Proceedings of the ACL.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>