<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000069">
<title confidence="0.999534">
A Latent Variable Model for Viewpoint Discovery from
Threaded Forum Posts
</title>
<author confidence="0.99606">
Minghui Qiu
</author>
<affiliation confidence="0.88606">
School of Information Systems
Singapore Management University
</affiliation>
<address confidence="0.819595">
Singapore
</address>
<email confidence="0.997609">
minghui.qiu.2010@smu.edu.sg
</email>
<author confidence="0.99569">
Jing Jiang
</author>
<affiliation confidence="0.885168">
School of Information Systems
Singapore Management University
</affiliation>
<address confidence="0.819108">
Singapore
</address>
<email confidence="0.997387">
jingjiang@smu.edu.sg
</email>
<sectionHeader confidence="0.995598" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999503941176471">
Threaded discussion forums provide an im-
portant social media platform. Its rich user
generated content has served as an important
source of public feedback. To automatically
discover the viewpoints or stances on hot is-
sues from forum threads is an important and
useful task. In this paper, we propose a novel
latent variable model for viewpoint discov-
ery from threaded forum posts. Our model is
a principled generative latent variable model
which captures three important factors: view-
point specific topic preference, user identity
and user interactions. Evaluation results show
that our model clearly outperforms a number
of baseline models in terms of both clustering
posts based on viewpoints and clustering users
with different viewpoints.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999708714285714">
Threaded discussion forums provide an important
social media platform that allows netizens to express
their opinions, to ask for advice, and to form on-
line communities. In particular, responses to major
sociopolitical events and issues can often be found
in discussion forums, which serve as an impor-
tant source of public feedback. In such discussion
threads, we often observe heated debates over a con-
troversial issue, with different sides defending their
viewpoints with different arguments. For example,
after the presidential debate between Barack Obama
and Mitt Romney, there were heated discussions in
online forums like CreateDebate1 where some peo-
ple expressed their support for Obama while some
</bodyText>
<footnote confidence="0.930414">
1http://www.createdebate.com/
</footnote>
<bodyText confidence="0.999715029411765">
others have their opposition to him. For a user who
is not closely following an event or issue, instead of
going through all the existing posts in a long thread,
she may want to quickly get an overview of the ma-
jor viewpoints and arguments given by the different
sides. For policy makers who want to obtain pub-
lic feedback on social issues from social media, it is
also desirable to automatically summarize the view-
points on an issue from relevant threads. In this pa-
per, we study the problem of modeling and discov-
ering different viewpoints in forum threads.
Recently there has been some work on finding
contrastive viewpoints from text. The model pro-
posed by Paul et al. (2010) assumes viewpoints and
topics are orthogonal dimensions. Another model
proposed by Fang et al. (2012) assumes that docu-
ments are already grouped by viewpoints and it fo-
cus on identifying contrastive viewpoint words un-
der the same topic. However, these existing stud-
ies are not based on interdependent documents like
threaded forum posts. As a result, at least two im-
portant characteristics of threaded forum data are not
considered in these models. (1) User identity: The
user or publisher of each forum post is known, and
a user may publish several posts in the same thread.
Since the same user’s opinion on an issue usually re-
mains unchanged, posts published by the same user
are likely to contain the same viewpoint. (2) User
interactions. A thread is like a conversation, where
users not only directly comment on the issue under
discussion but also comment on each other’s posts.
Users having different viewpoints may express their
disagreement or even attack each other while users
having the same viewpoint often support each other.
</bodyText>
<page confidence="0.954703">
1031
</page>
<note confidence="0.469656">
Proceedings of NAACL-HLT 2013, pages 1031–1040,
Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.999574882352941">
The interaction expressions in forum posts may help
us infer the relation between two users and subse-
quently infer the viewpoints of the corresponding
posts.
In this paper, we propose a novel latent variable
model for viewpoint discovery from threaded forum
posts. Our model is based on the following obser-
vations: First, posts with different viewpoints tend
to focus on different topics. To illustrate this point,
we first apply the Latent Dirichlet Allocation (LDA)
model (Blei et al., 2003) on a thread about “will
you vote Obama” and obtain a set of topics. This
thread comes from a data set that has each user’s
viewpoint annotated. Using the ground truth view-
point labels, we group all posts published by users
with viewpoint 1 (or viewpoint 2) and compute the
topic proportions. The two topic distributions are
shown in Figure 1. We can see that indeed the two
viewpoints each have some dominating topics. Our
second observations is that the same user tends to
hold the same viewpoint. In our model, we use a
user-level viewpoint distribution to capture this ob-
servation, and the experiments show that it works
better than assuming a global viewpoint distribution.
Third, users with the same viewpoint are likely to
have positive interactions while users with different
viewpoints tend to have negative interactions. Using
a sentiment lexicon, we can first predict the polarity
of interaction expressions. We then propose a novel
way to incorporate this information into the latent
variable model. In summary, we capture the three
observations above in a principled generative latent
variable model. We present the details of our model
in Section 3.
</bodyText>
<figureCaption confidence="0.987457666666667">
Figure 1: Topic distributions of two viewpoints for the
thread “will you vote Obama?” The dotted line is the
average topic probability.
</figureCaption>
<bodyText confidence="0.999987176470588">
We use two tasks to evaluate our model. In the
first task, we evaluate how well posts with differ-
ent viewpoints are separated. In the second task, we
evaluate how well our model is able to group users
with different viewpoints. For both tasks, we com-
pare our model with an existing model as well as
a few degenerate versions of our model. The re-
sults show that our model can clearly outperform the
baselines in terms of three evaluation metrics. The
experiments are presented in Section 5.
The contributions of our work are threefold: (1)
We identify the importance of using user interac-
tions to help infer viewpoints in forum posts. (2) We
propose a principled latent variable model to jointly
model topics, viewpoints and user interactions. (3)
We empirically verify the validity of the three as-
sumptions in our model using real data sets.
</bodyText>
<sectionHeader confidence="0.999782" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999818774193548">
There are a few different lines of work that are re-
lated to our work. For discovering different view-
points from general text, Paul et al. (2010) used the
model proposed by Paul and Girju (2010) to jointly
model topics and viewpoints. They assume these
two concepts are orthogonal and they do not con-
sider user identity. In comparison, our model has
the notion of topics and viewpoints, but we explicitly
model the dependency of topics on viewpoints, i.e.
we assume each viewpoint has a topic distribution.
We also consider author identities as an important
factor of our model. Fang et al. (2012) proposed a
model that also combines topics and viewpoints. But
they assume that documents are already grouped by
viewpoints, which is not the case for forum posts.
Therefore, their model cannot be directly applied to
forum posts.
There has also been some work on finding view-
points from social media. Somasundaran and Wiebe
(2010) studied how to identify stances in online de-
bates. They used a supervised approach for classi-
fying stances in ideological debates. In comparison,
our model is an unsupervised method. The same au-
thors proposed an unsupervised method which relies
on associations of aspects with topics indicative of
stances mined from the Web for the task (Somasun-
daran and Wiebe, 2009). In contrast, our model is
also an unsupervised one but we do not rely on any
external knowledge.
Part of our work is related to detecting agree-
ment/disagreement from text. For this task, nor-
</bodyText>
<page confidence="0.993537">
1032
</page>
<bodyText confidence="0.999317962962963">
mally supervised methods are used (Galley et al.,
2004; Abbott et al., 2011), which require sufficient
labeled training data. In our work, since we deal
with different languages, we use a lexicon-based
approach that does not need training data. Re-
cently, Mukherjee and Liu (2012) proposed an un-
supervised model to extract different types of ex-
pressions including agreement/disagreement expres-
sions. However, our focus is not to detect agree-
ment/disagreement expressions but to model the
interplay between agreement/disagreement expres-
sions and viewpoints. The work by Mukherjee and
Liu (2012) can potentially be combined with our
model.
Another line of related work is subgroup detec-
tion, which aims to separate users holding different
viewpoints. This problem has recently been stud-
ied by Abu-Jbara and Radev (2012), Dasigi et al.
(2012), Abu-Jbara et al. (2012) and Hassan et al.
(2012), where a clustering based approach is used.
Lu et al. (2012) studied both textual content and
social interactions to find opposing network from
online forums. In our experiments we show that
our model can also be used for subgroup detection,
but meanwhile we also directly identify viewpoints,
which is not the goal of existing work on subgroup
finding or opposing network extraction.
</bodyText>
<sectionHeader confidence="0.999132" genericHeader="method">
3 Model
</sectionHeader>
<subsectionHeader confidence="0.99974">
3.1 Motivation
</subsectionHeader>
<bodyText confidence="0.992837153846154">
Before we formally present our latent variable
model for viewpoint discovery, let us first look at the
assumptions we would like to capture in the model.
Viewpoint-based topic distribution: The first as-
sumption we have is that different viewpoints tend
to touch upon different topics. This is because to
support a viewpoint, users need to provide evidence
and arguments, and for different viewpoints the ar-
guments are likely different. To capture this assump-
tion, in our model, we let each viewpoint have its
own distribution of topics. Given the viewpoint of
a post, the hidden topic of each word in the post is
chosen according to the corresponding topic distri-
bution associated with that viewpoint.
User identify: The second assumption we have
is that the same user tends to talk from the same
viewpoint, although there are also users who do not
clearly have a viewpoint. In our model, we assume
that there is a user-level viewpoint distribution. For
each post by a user, its viewpoint is drawn from the
corresponding viewpoint distribution.
User interaction: An important difference between
threaded forum posts and regular document collec-
tions such as news articles is that posts in the same
thread form a tree structure via the “reply-to” re-
lations. Many reply posts start with an expression
that comments on a previous post or directly ad-
dresses another user. These interaction expressions
may carry positive or negative sentiment, indicating
an agreement or a disagreement. For example, Ta-
ble 1 shows the interaction expressions from a few
sample posts with words such as “correct,” “agree,”
and “delusional,” implying the polarity of the inter-
action expressions. The polarity of these interaction
expressions can help us infer whether two posts or
two users hold the same viewpoint or not. In our
model, we assume that the polarity of each interac-
tion expression can be detected. Details of how we
perform this detection are in Section 3.4.
</bodyText>
<figure confidence="0.2984855">
Post
+ You are correct. Obama got into office w/ everything � � �
I agree with your post Dan. Obama is so � � �
Most of your post is delusional, especially the part � � �
�
Are you freaking nutz? Palin is a BIMBO!
</figure>
<tableCaption confidence="0.9532835">
Table 1: Sample posts with positive (+) and negative(−)
interactions.
</tableCaption>
<bodyText confidence="0.9999838">
While the way to capture the first two assump-
tions discussed above is fairly standard, modeling
user interactions is something new. In our model,
we assume that the polarity of an interaction expres-
sion is generated based on the viewpoint of the cur-
rent post and the viewpoint of post(s) that the current
post replies to. The intuition is that if the viewpoints
are the same, we are more likely to see a positive in-
teraction whereas if the viewpoints are different we
are more likely to see a negative interaction.
</bodyText>
<subsectionHeader confidence="0.999758">
3.2 Model description
</subsectionHeader>
<bodyText confidence="0.985061">
We use the following notation to represent our data.
We consider a set of forum posts published by U dif-
ferent users on the same event or issue, where user
u (1 &lt; u &lt; U) has published Nu posts. Let wu,n,l
(1 &lt; l &lt; Lu,n ) denote the l-th word in the n-th
post by user u, where Lu,n is the number of words
</bodyText>
<page confidence="0.949863">
1033
</page>
<bodyText confidence="0.999909384615385">
in the n-th post by user u. wu,n,l is represented by
an index between 1 and V where V is the vocabu-
lary size. Furthermore, we assume that some of the
posts have user interaction expressions, where the
polarity of the expression is known. Without loss of
generality, let su,n E 10, 11 denote the polarity of
the interaction expression of the n-th post by user
u. In addition, for each post that has an interaction
expression, we assume we also know the previous
post(s) it replies to. (In the case when the current
post replies to a user, we assume all that user’s ex-
isting posts are being replied to.) We refer to these
posts as the parent posts of the current post.
We assume that there are T topics where each
topic is essentially a word distribution, denoted as
0t. We also assume that there are Y different view-
points expressed in the collection of posts. For most
controversial issues, Y can be set to 2. Each view-
point y has a topic distribution By over the T top-
ics. While these T topics are meant to capture the
topical differences between viewpoints, since these
viewpoints are all about the same issue, there are
also some words commonly used by different view-
points. We therefore introduce a background topic
0B to capture these words. Finally, each user u has
a distribution over the Y viewpoints, denoted as (pu.
</bodyText>
<figureCaption confidence="0.648168">
Figure 2: Plate notation of the Joint Viewpoint-Topic
</figureCaption>
<bodyText confidence="0.9856445">
Model with User Interaction (JVTM-UI). The dotted cir-
cle for Y means the variables represented by Y are not
new variables but a subset of the y variables.
Figure 2 shows the plate notation of the complete
model. We assume the following generation process
in our model. When user u generates her n-th post,
she first samples a viewpoint from (pu. Let this view-
point be represented by a hidden variable yu,n. For
the l-th word in this post, she first samples an in-
dicator variable xu,n,l from a Bernoulli distribution
parameterized by 7r. If xu,n,l = 0, then she draws
wu,n,l from 0B. Otherwise, she first samples a topic,
denoted as zu,n,l, according to Byu,n, and then draws
wu,n,l from 0zu,n,l.
Furthermore, if this post is a reply to a previous
post or another user, she may first comment on the
parent post(s). The polarity of the interaction ex-
pression in the post is dependent on the viewpoint
yu,n and the viewpoints of the previous post(s). Let
us use Yu,n to denote the set of y variables associ-
ated with the parent posts of the current post. The
user draws su,n according to following distribution:
</bodyText>
<equation confidence="0.9978648">
r
y�∈Yu,n I(yu,n == y0) + δ
p(su,n = 1|yu,n, Yu,n, δ) = ,
|Yu,n |+ 2δ
p(su,n = 0|yu,n, Yu,n, δ) = 1 − p(su,n = 1|yu,n, Yu,n, δ), (1)
</equation>
<bodyText confidence="0.99989625">
where l[(·) is 1 if the statement inside is true and 0
otherwise, and S &gt; 0 is a smoothing parameter.
Finally, we assume that 0B, 0t, (pu, By and 7r all
have some uniform Dirichlet priors.
</bodyText>
<subsectionHeader confidence="0.961728">
3.3 Inference
</subsectionHeader>
<bodyText confidence="0.986158166666667">
We use collapsed Gibbs sampling to estimate the
model parameters. In the initialization stage of
Gibbs sampling, for a reply post to a recipient, we
initialize its corresponding reply polarity s accord-
ing to all the labeled polarity of interaction words.
Specifically, if the majority of labeled interaction
words are positive, we set s = 1, otherwise we set
s = 0.
Let Y denote the set of all y variables, and
Y¬(u,n) denote Y excluding yu,n. Similar notation
is used for the other variables. We sample yu,n using
the following formula.
</bodyText>
<equation confidence="0.996060444444444">
p(yu,n = k|Y¬(u,n), Z, S, X, α, η, δ)
∝ p(yu,n = k, Y¬(u,n)|α) p(Z|yu,n = k, Y¬(u,n), X, η)
p(Y¬(u,n)|α) p(Z¬(u,n)|Y¬(u,n), X¬(u,n), η)
·p(S|yu,n = k, Y¬(u,n), δ)
r1t 1r1Ct
a-o −1(Ck,¬(u,n) + η + a)
C,(,,n−1 (·)
r1b=0 (Ck,¬(u,n) + Tη + b)
·p(S|yu,n = k, Y¬(u,n), δ). (2)
</equation>
<bodyText confidence="0.998659666666667">
Here all Cs are counters. Cku,¬n is the number of
times we observe the viewpoint k from u’s posts,
excluding the n-th post, based on Y¬(u,n). Ctu,n is
</bodyText>
<equation confidence="0.6904304">
Ck
u ¬n + α
C(·)
u,¬n + Y α
=
</equation>
<page confidence="0.935932">
1034
</page>
<bodyText confidence="0.966413769230769">
the number of times we observe topic t from user
u’s n-th post, based on Zu,n. And Ctk,¬(u,n) is the
number of times we observe topic t associated with
viewpoint k, excluding user u’s n-th post. Note that
we need X to know which words are assigned to
the background topic so we can exclude them for
Ctu,n and Ctk,¬(u,n). C(·)
u,¬n is the number of times we
observe any viewpoint from u’s posts, excluding the
n-th post. C(·)
u,n and C(·) are defined similarly.
k,¬(u,n)
The last term is further expanded as follows:
</bodyText>
<equation confidence="0.9957345">
p(S|yu,n = k, Y-(u,n), δ) = p(su,n|yu,n = k, Yu,n, δ)
·p(S-(u,n)|yu,n = k, Y-(u,n), δ). (3)
</equation>
<bodyText confidence="0.99682525">
Here p(su,n|yu,n = k, Yu,n, S) is computed ac-
cording to Eqn. (1). For the latter term, we need to
consider posts which reply to user u’s n-th post be-
cause the value of yu,n affects these posts.
</bodyText>
<equation confidence="0.99754">
p(S-(u,n)|yu,n = k, Y-(u,n), δ)
p(su0,n0|yu0,n0, Yu0,n0, δ). (4)
(u0,n0):yu,nEYu0,n0
</equation>
<bodyText confidence="0.999727125">
Next, we show how we jointly sample xu,n,l
and zu,n,l. We jointly sample them because when
xu,n,l = 0, zu,n,l does not need a value. We have the
following formulas:
Here again the Cs are counters defined in similar
ways as before. For example, C1 ¬(u,n,l) is the num-
ber of times we observe 1 assigned to an x variable,
excluding xu,n,l.
</bodyText>
<subsectionHeader confidence="0.981839">
3.4 Interaction polarity prediction
</subsectionHeader>
<bodyText confidence="0.99997896969697">
The problem of detecting agreement and disagree-
ment from forum posts is relatively new. One pos-
sible solution is to use supervised learning, which
requires training data (Galley et al., 2004; Abbott et
al., 2011; Andreas et al., 2012). However, training
data are also likely domain and language dependent,
which makes them hard for re-use. For our task, we
take a simpler approach and use a sentiment lexicon
together with some heuristics to predict the polar-
ity of interaction expressions. Specifically, we first
identify interaction sentences following the strate-
gies from Hassan et al. (2012). We assume sentences
containing mentions of the recipient of a post are in-
teraction sentences. Next, we consider words within
a text window of 8 words surrounding these men-
tions. We then use a subjectivity lexicon to label
these words. To form an English lexicon, we com-
bine three popular lexicons: the sentiment lexicon
used by Hu and Liu (2004), Multi-Perspective Ques-
tion Answering Subjectivity Lexicon by Wilson et
al. (2005) and SentiWordNet by Baccianella et al.
(2010). Since we also work with a Chinese data set,
to form the Chinese sentiment lexicon, we use opin-
ion words from HowNet2 and NTUSD by Ku et al.
(2007). To predict the polarity of an interaction ex-
pression, we simply check whether there are more
positive sentiment words or more negative sentiment
words in the expression, and label the interaction ex-
pression accordingly.
We would like to stress that since this interaction
classification step is independent of the latent vari-
able model, we can always apply a more accurate
method, but this is not the focus of this work.
</bodyText>
<sectionHeader confidence="0.999534" genericHeader="method">
4 Models for Comparison
</sectionHeader>
<bodyText confidence="0.99974425">
In our experiments, we compare our model,
Joint Viewpoint-Topic Model with User Interaction
(JVTM-UI), with the following baseline models.
JVTM: The model is shown in Figure 3(a), a variant
of JVTM-UI that does not consider user interaction.
Through comparison with it, we can check the effect
of modeling user interactions.
JVTM-G: We consider JVTM-G in Figure 3(b), a
variant of JVTM which assumes a global viewpoint
distribution. Comparison with it allows us to check
the usefulness of user identity in the task.
UIM: The third model we consider is a User Interac-
tion Model (UIM) in Figure 3(c), where we rely on
only the users’ interactions to infer the viewpoints.
We use it to check how well viewpoints can be dis-
covered from only user interaction expressions.
</bodyText>
<footnote confidence="0.541636">
2http://www.keenage.com/html/e_index.html
</footnote>
<equation confidence="0.998902625">
∝
p(xu,n,l = 1, zu,n,l = t|X¬(u,n,l), Z¬(u,n,l), Y, W, γ, η, β, βB)
M C1 + γ
¬(u,n,l)
t η
Cyu,n,l,¬(u,n,l) +
C(·) + Tη
yu,n,l,¬(u,n,l)
, (5)
C(·)
t,¬(u,n,l) + V β
wu,n,l
Ct,¬(u,n,l) + β
C(·)
¬(u,n,l) + 2γ
p(xu,n,l = 0|X¬(u,n,l), Z¬(u,n,l), Y, W, γ, η, β, βB)
C0¬(u,n,l) + γ
M
. () B (6)
CB ¬(u,n,l) + vβ
CB,¬(u,n,l) + βB
wu,n,l
(·)
C(u,n,l) + 2γ
</equation>
<page confidence="0.983624">
1035
</page>
<figureCaption confidence="0.9978175">
Figure 3: (a) JVTM: Joint Viewpoint-Topic Model. (b) JVTM-G: JVTM with a global viewpoint distribution. (c)
UIM: User-Interaction Model.
</figureCaption>
<bodyText confidence="0.99993325">
TAM: The last model we consider is the one by Paul
et al. (2010). As TAM is applied at document collec-
tions, we first concatenate all the posts by the same
user into a pseudo document and then apply TAM.
</bodyText>
<sectionHeader confidence="0.994448" genericHeader="evaluation">
5 Experiments and Analysis
</sectionHeader>
<bodyText confidence="0.9902565">
In this section, we evaluate our model with a set of
baseline models using two data sets.
</bodyText>
<table confidence="0.999274571428571">
Name Issue #Posts #Users
EDS1 Vote for Obama 2599 197
EDS2 Arizona Immigration Law 738 59
EDS3 Tax Cuts 276 26
CDS1 Tencent and Qihoo dispute 30137 2507
CDS2 Fang Zhouzi questions Han Han 76934 1769
CDS3 Liu Xiang in London Olympics 29486 2774
</table>
<tableCaption confidence="0.999399">
Table 2: Some statistics of the data set.
</tableCaption>
<subsectionHeader confidence="0.996487">
5.1 Data Sets and Experimental Settings
</subsectionHeader>
<bodyText confidence="0.999994777777778">
We focus our work on finding users’ viewpoints on
a controversial issue, where we assume that there
are two contradictory viewpoints. We use two data
sets on controversial issues. The first data set comes
from Abu-Jbara et al. (2012) and Hassan et al.
(2012). This data set originally was used for finding
subgroups of users, so the annotations were done at
user level, i.e. for each user there is a label indicat-
ing which subgroup he/she belongs to. We use the
top-3 mostly discussed threads with two subgroups
for our study.
In reality, controversial issues are often discussed
across threads. We thus constructed another large
data set which contains more than one thread for
each issue. We chose three hot issues from one of
the most popular Chinese online forums — TianYa
Club3. The three issues are “Fang Zhouzi questions
Han Han”4, “Tencent and Qihoo dispute”5, and “Liu
Xiang in London Olympics”6. All these issues trig-
gered heated discussions on the forum and we found
that most of the users were divided into two different
groups.
We crawled the data set using the TianYa API7.
The API allows users to issue queries and get threads
most related to the queries. For each issue, we used
entities involved in the event as queries and obtained
750 threads for each query. We then extracted all the
posts in the threads. As there are users who posted
irrelevant posts in the forum, we then filtered out
those users who did not mention the entities or had
fewer than 4 posts.
We refer to the first set of data in English as EDS1,
EDS2 and EDS3, and the second set of data in Chi-
nese as CDS1, CDS2 and CDS3. Some statistics of
the resulting data set are shown in Table 2.
For all the models, we set Y = 2. We set T = 10
for the English data sets and T = 40 for the Chinese
data sets. We run 400 iterations of Gibbs sampling
as burn-in iterations and then take 100 samples with
a gap of 5 to obtain our final results. We empirically
set Q = 0.01, QB = 0.1, ry = 10 and 6 = 0.1 for our
model on all the data sets. α and q are set through
grid search where they take values in 10.01, 0.001}.
For each data set, we choose the best setting for each
model and report the corresponding results.
</bodyText>
<footnote confidence="0.999892">
3http://en.wikipedia.org/wiki/Tianya_Club
4http://en.wikipedia.org/wiki/Fang_Zhouzi
5http://en.wikipedia.org/wiki/360_v._Tencent
6http://en.wikipedia.org/wiki/Liu_Xiang
7http://open.tianya.cn/index.php
</footnote>
<page confidence="0.992576">
1036
</page>
<subsectionHeader confidence="0.998876">
5.2 Identification of viewpoints
</subsectionHeader>
<bodyText confidence="0.999989130434783">
We first evaluate the models on the task of identi-
fying viewpoints. For fair comparison, each model
will output a viewpoint label for each post. For
JVTM-UI, JVTM, JVTM-G and UIM, after we learn
the model, each post will directly have a viewpoint
assignment. For TAM we cannot directly get each
post’s viewpoint as the model assumes a document-
level viewpoint distribution. To estimate each post’s
viewpoint in this model, we use viewpoint assign-
ment at the word level learnt from the model. Then
for each post, we label its viewpoint as the viewpoint
that has the majority count in the post.
Ideally, we would like to manually label all the
posts to obtain the ground truth for evaluation. Since
there are too many posts, we only labeled a sample
of them. For each issue, we randomly selected 150
posts to label their viewpoints. For each post, we
asked two different annotators to label its viewpoint.
We made sure that the annotators understand the is-
sue and the two major viewpoints before they anno-
tated the posts. Specifically, as the Chinese data sets
are about some controversial issues around the enti-
ties involved, we then defined two major viewpoints
as support and not support the entity who initiated
the event. The entities of data set CDS1, CDS2 and
CDS3 are Fang Zhouzi, Tencent and Liu Xiang re-
spectively. For each given post, the annotators were
asked to judge whether the post has expressed view-
points and if so, what is its corresponding view-
point. We measure the agreement score using Co-
hen’s kappa coefficient. The lowest agreement score
for an issue is 0.61 in the data set, showing good
agreement. We then used the set of posts that were
labeled with the same viewpoint by the two annota-
tors as our evaluation data for all the models.
Since our task is essentially a clustering problem,
we use purity and entropy to measure the perfor-
mance (Manning et al., 2008). Furthermore, we also
use accuracy where we choose the better alignment
of clusters with ground truth class labels and com-
pute the percentage of posts that are “classified” cor-
rectly. For purity and accuracy, the higher the mea-
sure is the better the performance. For entropy, the
lower the measure is the better the performance.
We give an overview of the all the averaged model
results on the data sets in Figure 4. We observed that
</bodyText>
<subsubsectionHeader confidence="0.621615">
Purity Entropy Accuracy
</subsubsectionHeader>
<figureCaption confidence="0.9995375">
Figure 4: Averaged results of the models in identification
of viewpoints.
</figureCaption>
<bodyText confidence="0.9997622">
UIM performs relatively better than other methods
except our model. This shows user interactions are
important features to identify post viewpoints. Over-
all, our model has a better performance as it is with
higher purity and accuracy, and lower entropy.
</bodyText>
<table confidence="0.999681368421052">
JVTM-UI UIM JVTM TAM JVTM-G
P 0.77 0.74 0.64 0.65 0.63
EDS1 E 0.72 0.76 0.90 0.92 0.94
A 0.77 0.74 0.61 0.60 0.57
P 0.82 0.78 0.68 0.65 0.64
EDS2 E 0.69 0.73 0.79 0.86 0.90
A 0.81 0.78 0.68 0.68 0.65
P 0.79 0.73 0.65 0.64 0.62
EDS3 E 0.67 0.79 0.88 0.89 0.87
A 0.79 0.73 0.65 0.64 0.62
P 0.87 0.83 0.83 0.82 0.82
CDS1 E 0.61 0.64 0.65 0.66 0.64
A 0.60 0.58 0.59 0.58 0.57
P 0.71 0.65 0.61 0.63 0.60
CDS2 E 0.80 0.85 0.92 0.95 0.96
A 0.71 0.65 0.61 0.61 0.59
P 0.78 0.78 0.78 0.78 0.78
CDS3 E 0.73 0.75 0.70 0.72 0.73
A 0.67 0.59 0.67 0.66 0.63
</table>
<tableCaption confidence="0.976536">
Table 3: Results on viewpoint identification on the all
data sets.
</tableCaption>
<bodyText confidence="0.99854825">
Table 3 shows the detailed results on the data
sets. We perform the 2-tailed paired t-test as used
by Abu-Jbara et al. (2012) on the results. All the re-
sult differences are at 10% significance level if not
with further clarification. First, JVTM has a better
performance over JVTM-G, which shows it is im-
portant to consider user identity in the task. Sec-
ond, JVTM and TAM have similar performance on
</bodyText>
<figure confidence="0.992322555555556">
1.0
0.8
0.6
0.4
JVTM-G
TAM
JVTM
UIM
JVTM-UI
</figure>
<page confidence="0.993604">
1037
</page>
<bodyText confidence="0.99995752631579">
EDS1 and CDS2, but JVTM has a relatively bet-
ter performance on EDS2, EDS3, CDS1 and CDS3.
This shows it is helpful to consider each viewpoint’s
topic preference. Although as studied by Paul et
al. (2010), by only using unigram features, TAM
may not be able to cluster viewpoints accurately,
our study shows that the results can be improved
when adding each viewpoint’s topic focus. Third,
UIM has relatively better performance than the other
models, which demonstrates that user interactions
alone can do a decent job in inferring viewpoints. Fi-
nally, our proposed model has the best performance
across the board in terms of all three evaluation met-
rics. Note that, our proposed model significantly
outperforms other methods at 5% significance level
except at 10% significance level over JVTM model.
This shows by jointly modeling topics, viewpoints
and user interactions, our model can better identify
posts with different viewpoints.
</bodyText>
<subsectionHeader confidence="0.999644">
5.3 Identification of user groups
</subsectionHeader>
<bodyText confidence="0.999957814814815">
We also use another task to evaluate our model.
The task here is finding each user’s viewpoint and
subsequently grouping users by their viewpoints.
This task has been studied by Abu-Jbara and Radev
(2012), Dasigi et al. (2012), Abu-Jbara et al. (2012)
and Hassan et al. (2012). For the English data set,
the user-level group labels are provided by the orig-
inal data set. For the Chinese data set, we randomly
selected 150 users for each issue and manually la-
beled them according to their viewpoints as reflected
by their posts. If a user’s posts do not clearly suggest
a viewpoint, we label her as neutral. Again we asked
two human judges to do annotation. The agreement
scores are above 0.70 for all issues, showing sub-
stantial agreement. This score is higher than view-
point identification, which suggests that it is easier
to judge a user’s viewpoint than a single post’s view-
point. We use the set of users who have got the same
labels by the two human judges for our experiments.
Similarly we compute purity, entropy and accuracy
to evaluate the clustering results.
Figure 5 shows the averaged results of all the
models. Similar to previous experiment, our model
has a better performance compared to the competing
models.
The results on the each data set are shown in Ta-
ble 4. The tables show that similar trends can be
</bodyText>
<subsubsectionHeader confidence="0.707085">
Purity Entropy Accuracy
</subsubsectionHeader>
<figureCaption confidence="0.954845">
Figure 5: Averaged results of the models in identification
of user groups.
</figureCaption>
<table confidence="0.999898421052632">
JVTM-UI UIM JVTM TAM JVTM-G
P 0.67 0.67 0.67 0.67 0.67
EDS1 E 0.85 0.88 0.89 0.89 0.91
A 0.63 0.59 0.58 0.59 0.57
P 0.77 0.77 0.77 0.77 0.77
EDS2 E 0.72 0.76 0.74 0.75 0.76
A 0.62 0.59 0.60 0.58 0.59
P 0.68 0.63 0.61 0.61 0.58
EDS3 E 0.90 0.92 0.95 0.96 0.97
A 0.68 0.63 0.61 0.58 0.57
P 0.64 0.60 0.61 0.61 0.60
CDS1 E 0.91 0.97 0.96 0.96 0.97
A 0.61 0.55 0.55 0.56 0.53
P 0.69 0.69 0.69 0.69 0.69
CDS2 E 0.83 0.89 0.85 0.89 0.89
A 0.62 0.57 0.56 0.58 0.54
P 0.67 0.63 0.64 0.60 0.60
CDS3 E 0.89 0.91 0.92 0.93 0.96
A 0.64 0.62 0.60 0.56 0.54
</table>
<tableCaption confidence="0.9963185">
Table 4: Results on identification of user groups on the
all the data sets.
</tableCaption>
<bodyText confidence="0.999534363636364">
observed for the task of user group identification.
We also perform the 2-tailed paired t-test on the re-
sults. We find our model significantly outperforms
other models in terms of accuracy at 5% significance
level, and purity and entropy at 10% significance
level. Overall speaking, our joint model performed
the best among all the models for this task for all
three metrics. This shows that it is important to con-
sider the topical preference of individual viewpoint,
user’s identify as well as the interactions between
users.
</bodyText>
<figure confidence="0.995336777777778">
1.0
0.8
0.6
0.4
JVTM-G
TAM
JVTM
UIM
JVTM-UI
</figure>
<page confidence="0.656543">
1038
</page>
<figureCaption confidence="0.9891914">
Figure 6: The user interaction network in a discussion
thread about “will you vote obama.” Green (left) and
white (right) nodes represent users with two different
viewpoints. Red (thin) and blue(thick) edges represent
negative and positive interactions.
</figureCaption>
<subsectionHeader confidence="0.697712">
5.4 User interaction network
</subsectionHeader>
<bodyText confidence="0.999964842105263">
To gain some direct insight into our results, we show
the user interaction network from one thread in Fig-
ure 6. Here each node denotes a user, and its color
denotes the predicted viewpoint of that user. A link
between a pair of users means these users have in-
teractions and the interaction types have a dominant
polarity. The polarities of these links are predicted
using the interaction expressions and a sentiment
lexicon, whereas the viewpoints of different users
are learned by JVTM-UI, making use of the inter-
action polarities. The figure shows that clearly there
are mostly positive interactions between users with
the same viewpoint and mostly negative interactions
between users with different viewpoints. Note that,
our method to identify user interaction polarity is
rule-based. As this step serves as a preprocessing
step for our latent variable model, we can always
use a more accurate method to improve the perfor-
mances.
</bodyText>
<sectionHeader confidence="0.999249" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999994407407407">
In this work, we proposed a novel latent variable
model for viewpoint discovery from threaded forum
posts. Our model is based on the three important fac-
tors: viewpoint specific topic preference, user iden-
tity and user interactions. Our proposed model cap-
tures these observations in a principled way. In par-
ticular, to incorporate the user interaction informa-
tion, we proposed a novel generative process. Em-
pirical evaluation on the real forum data sets showed
that our model could cluster both posts and users
with different viewpoints more accurately than the
baseline models we consider. To the best of our
knowledge, our work is the first to incorporate user
interaction polarity into a generative model to dis-
cover viewpoints.
In this work, we only considered unigrams. As
some previous work has shown, more complex lexi-
cal units such as n-grams (Mukherjee and Liu, 2012)
and dependency triplets (Paul et al., 2010) may im-
prove the performance of topic models. We will con-
sider these strategies in our future work. Currently
we use a simple heuristic-based classifier to predict
interaction polarity. In our further work, we plan
to consider more accurate methods using deeper lin-
guistic analysis. We did not study how to summarize
the discovered viewpoints in this work, which is also
something we will look into in our future work.
</bodyText>
<sectionHeader confidence="0.998929" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999995666666667">
We thank the reviewers for their valuable comments
on this work. We also thank Shuang Xia for his help
on processing and labeling the data sets.
</bodyText>
<sectionHeader confidence="0.999111" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999752703703704">
Rob Abbott, Marilyn Walker, Pranav Anand, Jean E.
Fox Tree, Robeson Bowmani, and Joseph King. 2011.
How can you say such things?!?: Recognizing dis-
agreement in informal political argument. In Proceed-
ings of the Workshop on Language in Social Media
(LSM 2011), pages 2–11.
Amjad Abu-Jbara and Dragomir R. Radev. 2012. Sub-
group detector: A system for detecting subgroups in
online discussions. In ACL (System Demonstrations),
pages 133–138.
Amjad Abu-Jbara, Pradeep Dasigi, Mona Diab, and
Dragomir R. Radev. 2012. Subgroup detection in
ideological discussions. In Proceedings of ACL 2012,
pages 399–409.
Jacob Andreas, Sara Rosenthal, and Kathleen McKe-
own. 2012. Annotating agreement and disagreement
in threaded discussion. In Proceedings of LREC’12.
Stefano Baccianella, Andrea Esuli, and Fabrizio Sebas-
tiani. 2010. Sentiwordnet 3.0: An enhanced lexical
resource for sentiment analysis and opinion mining. In
LREC.
David M. Blei, Andrew Y. Ng, and Michael I. Jordan.
2003. Latent dirichlet allocation. J. Mach. Learn.
Res., 3:993–1022.
Pradeep Dasigi, Weiwei Guo, and Mona T. Diab. 2012.
Genre independent subgroup detection in online dis-
cussion threads: A study of implicit attitude using
</reference>
<page confidence="0.871881">
1039
</page>
<reference confidence="0.999877694915254">
textual latent semantics. In Proceedings of the 50th
Annual Meeting of the Association for Computational
Linguistics, pages 65–69.
Yi Fang, Luo Si, Naveen Somasundaram, and Zhengtao
Yu. 2012. Mining contrastive opinions on political
texts using cross-perspective topic model. In WSDM,
pages 63–72.
Michel Galley, Kathleen McKeown, Julia Hirschberg,
and Elizabeth Shriberg. 2004. Identifying agreement
and disagreement in conversational speech: Use of
bayesian networks to model pragmatic dependencies.
In Proceedings of ACL’04, Main Volume, pages 669–
676.
Ahmed Hassan, Amjad Abu-Jbara, and Dragomir Radev.
2012. Detecting subgroups in online discussions by
modeling positive and negative relations among par-
ticipants. In Proceedings of the 2012 EMNLP, pages
59–70.
Minqing Hu and Bing Liu. 2004. Mining and summariz-
ing customer reviews. In Proceedings of the 10th ACM
SIGKDD international conference on Knowledge dis-
covery and data mining, pages 168–177.
Lun-wei Ku, Yong-sheng Lo, and Hsin-hsi Chen. 2007.
Using polarity scores of words for sentence-level opin-
ion extraction. In Proc. of the NTCIR-6 Workshop
Meeting, pages 316–322.
Yue Lu, Hongning Wang, ChengXiang Zhai, and Dan
Roth. 2012. Unsupervised discovery of opposing
opinion networks from forum discussions. In Pro-
ceedings of the 21st ACM international conference on
Information and knowledge management, CIKM ’12,
pages 1642–1646, New York, NY, USA. ACM.
Christopher D. Manning, Prabhakar Raghavan, and Hin-
rich Schtze. 2008. Introduction to Information Re-
trieval. Cambridge University Press, July.
Arjun Mukherjee and Bing Liu. 2012. Modeling review
comments. In Proceedings of the 50th Annual Meet-
ing of the Association for Computational Linguistics,
pages 320–329.
Michael J. Paul and Roxana Girju. 2010. A two-
dimensional topic-aspect model for discovering multi-
faceted topics. In AAAI.
Michael J. Paul, ChengXiang Zhai, and Roxana Girju.
2010. Summarizing contrastive viewpoints in opin-
ionated text. In EMNLP, pages 66–76.
Swapna Somasundaran and Janyce Wiebe. 2009. Rec-
ognizing stances in online debates. In Proceedings
of the Joint Conference of the 47th Annual Meeting
of the ACL and the 4th International Joint Conference
on Natural Language Processing of the AFNLP, pages
226–234.
Swapna Somasundaran and Janyce Wiebe. 2010. Recog-
nizing stances in ideological on-line debates. In Pro-
ceedings of the NAACL HLT 2010 Workshop on Com-
putational Approaches to Analysis and Generation of
Emotion in Text, pages 116–124.
Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.
2005. Recognizing contextual polarity in phrase-level
sentiment analysis. In HLT/EMNLP.
</reference>
<page confidence="0.98694">
1040
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.369628">
<title confidence="0.9916215">A Latent Variable Model for Viewpoint Discovery Threaded Forum Posts</title>
<author confidence="0.980871">Minghui</author>
<affiliation confidence="0.9834165">School of Information Singapore Management</affiliation>
<email confidence="0.682117">minghui.qiu.2010@smu.edu.sg</email>
<author confidence="0.662744">Jing</author>
<affiliation confidence="0.9162545">School of Information Singapore Management</affiliation>
<email confidence="0.938832">jingjiang@smu.edu.sg</email>
<abstract confidence="0.999496444444445">Threaded discussion forums provide an important social media platform. Its rich user generated content has served as an important source of public feedback. To automatically discover the viewpoints or stances on hot issues from forum threads is an important and useful task. In this paper, we propose a novel latent variable model for viewpoint discovery from threaded forum posts. Our model is a principled generative latent variable model which captures three important factors: viewpoint specific topic preference, user identity and user interactions. Evaluation results show that our model clearly outperforms a number of baseline models in terms of both clustering posts based on viewpoints and clustering users with different viewpoints.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Rob Abbott</author>
<author>Marilyn Walker</author>
<author>Pranav Anand</author>
<author>Jean E Fox Tree</author>
<author>Robeson Bowmani</author>
<author>Joseph King</author>
</authors>
<title>How can you say such things?!?: Recognizing disagreement in informal political argument.</title>
<date>2011</date>
<booktitle>In Proceedings of the Workshop on Language in Social Media (LSM</booktitle>
<pages>2--11</pages>
<contexts>
<context position="7866" citStr="Abbott et al., 2011" startWordPosition="1269" endWordPosition="1272">fy stances in online debates. They used a supervised approach for classifying stances in ideological debates. In comparison, our model is an unsupervised method. The same authors proposed an unsupervised method which relies on associations of aspects with topics indicative of stances mined from the Web for the task (Somasundaran and Wiebe, 2009). In contrast, our model is also an unsupervised one but we do not rely on any external knowledge. Part of our work is related to detecting agreement/disagreement from text. For this task, nor1032 mally supervised methods are used (Galley et al., 2004; Abbott et al., 2011), which require sufficient labeled training data. In our work, since we deal with different languages, we use a lexicon-based approach that does not need training data. Recently, Mukherjee and Liu (2012) proposed an unsupervised model to extract different types of expressions including agreement/disagreement expressions. However, our focus is not to detect agreement/disagreement expressions but to model the interplay between agreement/disagreement expressions and viewpoints. The work by Mukherjee and Liu (2012) can potentially be combined with our model. Another line of related work is subgrou</context>
<context position="17457" citStr="Abbott et al., 2011" startWordPosition="2955" endWordPosition="2958">u0,n0, δ). (4) (u0,n0):yu,nEYu0,n0 Next, we show how we jointly sample xu,n,l and zu,n,l. We jointly sample them because when xu,n,l = 0, zu,n,l does not need a value. We have the following formulas: Here again the Cs are counters defined in similar ways as before. For example, C1 ¬(u,n,l) is the number of times we observe 1 assigned to an x variable, excluding xu,n,l. 3.4 Interaction polarity prediction The problem of detecting agreement and disagreement from forum posts is relatively new. One possible solution is to use supervised learning, which requires training data (Galley et al., 2004; Abbott et al., 2011; Andreas et al., 2012). However, training data are also likely domain and language dependent, which makes them hard for re-use. For our task, we take a simpler approach and use a sentiment lexicon together with some heuristics to predict the polarity of interaction expressions. Specifically, we first identify interaction sentences following the strategies from Hassan et al. (2012). We assume sentences containing mentions of the recipient of a post are interaction sentences. Next, we consider words within a text window of 8 words surrounding these mentions. We then use a subjectivity lexicon t</context>
</contexts>
<marker>Abbott, Walker, Anand, Tree, Bowmani, King, 2011</marker>
<rawString>Rob Abbott, Marilyn Walker, Pranav Anand, Jean E. Fox Tree, Robeson Bowmani, and Joseph King. 2011. How can you say such things?!?: Recognizing disagreement in informal political argument. In Proceedings of the Workshop on Language in Social Media (LSM 2011), pages 2–11.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amjad Abu-Jbara</author>
<author>Dragomir R Radev</author>
</authors>
<title>Subgroup detector: A system for detecting subgroups in online discussions.</title>
<date>2012</date>
<booktitle>In ACL (System Demonstrations),</booktitle>
<pages>133--138</pages>
<contexts>
<context position="8606" citStr="Abu-Jbara and Radev (2012)" startWordPosition="1381" endWordPosition="1384">xicon-based approach that does not need training data. Recently, Mukherjee and Liu (2012) proposed an unsupervised model to extract different types of expressions including agreement/disagreement expressions. However, our focus is not to detect agreement/disagreement expressions but to model the interplay between agreement/disagreement expressions and viewpoints. The work by Mukherjee and Liu (2012) can potentially be combined with our model. Another line of related work is subgroup detection, which aims to separate users holding different viewpoints. This problem has recently been studied by Abu-Jbara and Radev (2012), Dasigi et al. (2012), Abu-Jbara et al. (2012) and Hassan et al. (2012), where a clustering based approach is used. Lu et al. (2012) studied both textual content and social interactions to find opposing network from online forums. In our experiments we show that our model can also be used for subgroup detection, but meanwhile we also directly identify viewpoints, which is not the goal of existing work on subgroup finding or opposing network extraction. 3 Model 3.1 Motivation Before we formally present our latent variable model for viewpoint discovery, let us first look at the assumptions we w</context>
<context position="28193" citStr="Abu-Jbara and Radev (2012)" startWordPosition="4810" endWordPosition="4813">ly, our proposed model has the best performance across the board in terms of all three evaluation metrics. Note that, our proposed model significantly outperforms other methods at 5% significance level except at 10% significance level over JVTM model. This shows by jointly modeling topics, viewpoints and user interactions, our model can better identify posts with different viewpoints. 5.3 Identification of user groups We also use another task to evaluate our model. The task here is finding each user’s viewpoint and subsequently grouping users by their viewpoints. This task has been studied by Abu-Jbara and Radev (2012), Dasigi et al. (2012), Abu-Jbara et al. (2012) and Hassan et al. (2012). For the English data set, the user-level group labels are provided by the original data set. For the Chinese data set, we randomly selected 150 users for each issue and manually labeled them according to their viewpoints as reflected by their posts. If a user’s posts do not clearly suggest a viewpoint, we label her as neutral. Again we asked two human judges to do annotation. The agreement scores are above 0.70 for all issues, showing substantial agreement. This score is higher than viewpoint identification, which sugges</context>
</contexts>
<marker>Abu-Jbara, Radev, 2012</marker>
<rawString>Amjad Abu-Jbara and Dragomir R. Radev. 2012. Subgroup detector: A system for detecting subgroups in online discussions. In ACL (System Demonstrations), pages 133–138.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amjad Abu-Jbara</author>
<author>Pradeep Dasigi</author>
<author>Mona Diab</author>
<author>Dragomir R Radev</author>
</authors>
<title>Subgroup detection in ideological discussions.</title>
<date>2012</date>
<booktitle>In Proceedings of ACL 2012,</booktitle>
<pages>399--409</pages>
<contexts>
<context position="8653" citStr="Abu-Jbara et al. (2012)" startWordPosition="1389" endWordPosition="1392">ata. Recently, Mukherjee and Liu (2012) proposed an unsupervised model to extract different types of expressions including agreement/disagreement expressions. However, our focus is not to detect agreement/disagreement expressions but to model the interplay between agreement/disagreement expressions and viewpoints. The work by Mukherjee and Liu (2012) can potentially be combined with our model. Another line of related work is subgroup detection, which aims to separate users holding different viewpoints. This problem has recently been studied by Abu-Jbara and Radev (2012), Dasigi et al. (2012), Abu-Jbara et al. (2012) and Hassan et al. (2012), where a clustering based approach is used. Lu et al. (2012) studied both textual content and social interactions to find opposing network from online forums. In our experiments we show that our model can also be used for subgroup detection, but meanwhile we also directly identify viewpoints, which is not the goal of existing work on subgroup finding or opposing network extraction. 3 Model 3.1 Motivation Before we formally present our latent variable model for viewpoint discovery, let us first look at the assumptions we would like to capture in the model. Viewpoint-ba</context>
<context position="21089" citStr="Abu-Jbara et al. (2012)" startWordPosition="3574" endWordPosition="3577">te our model with a set of baseline models using two data sets. Name Issue #Posts #Users EDS1 Vote for Obama 2599 197 EDS2 Arizona Immigration Law 738 59 EDS3 Tax Cuts 276 26 CDS1 Tencent and Qihoo dispute 30137 2507 CDS2 Fang Zhouzi questions Han Han 76934 1769 CDS3 Liu Xiang in London Olympics 29486 2774 Table 2: Some statistics of the data set. 5.1 Data Sets and Experimental Settings We focus our work on finding users’ viewpoints on a controversial issue, where we assume that there are two contradictory viewpoints. We use two data sets on controversial issues. The first data set comes from Abu-Jbara et al. (2012) and Hassan et al. (2012). This data set originally was used for finding subgroups of users, so the annotations were done at user level, i.e. for each user there is a label indicating which subgroup he/she belongs to. We use the top-3 mostly discussed threads with two subgroups for our study. In reality, controversial issues are often discussed across threads. We thus constructed another large data set which contains more than one thread for each issue. We chose three hot issues from one of the most popular Chinese online forums — TianYa Club3. The three issues are “Fang Zhouzi questions Han H</context>
<context position="26695" citStr="Abu-Jbara et al. (2012)" startWordPosition="4564" endWordPosition="4567"> P 0.82 0.78 0.68 0.65 0.64 EDS2 E 0.69 0.73 0.79 0.86 0.90 A 0.81 0.78 0.68 0.68 0.65 P 0.79 0.73 0.65 0.64 0.62 EDS3 E 0.67 0.79 0.88 0.89 0.87 A 0.79 0.73 0.65 0.64 0.62 P 0.87 0.83 0.83 0.82 0.82 CDS1 E 0.61 0.64 0.65 0.66 0.64 A 0.60 0.58 0.59 0.58 0.57 P 0.71 0.65 0.61 0.63 0.60 CDS2 E 0.80 0.85 0.92 0.95 0.96 A 0.71 0.65 0.61 0.61 0.59 P 0.78 0.78 0.78 0.78 0.78 CDS3 E 0.73 0.75 0.70 0.72 0.73 A 0.67 0.59 0.67 0.66 0.63 Table 3: Results on viewpoint identification on the all data sets. Table 3 shows the detailed results on the data sets. We perform the 2-tailed paired t-test as used by Abu-Jbara et al. (2012) on the results. All the result differences are at 10% significance level if not with further clarification. First, JVTM has a better performance over JVTM-G, which shows it is important to consider user identity in the task. Second, JVTM and TAM have similar performance on 1.0 0.8 0.6 0.4 JVTM-G TAM JVTM UIM JVTM-UI 1037 EDS1 and CDS2, but JVTM has a relatively better performance on EDS2, EDS3, CDS1 and CDS3. This shows it is helpful to consider each viewpoint’s topic preference. Although as studied by Paul et al. (2010), by only using unigram features, TAM may not be able to cluster viewpoin</context>
<context position="28240" citStr="Abu-Jbara et al. (2012)" startWordPosition="4818" endWordPosition="4821">ross the board in terms of all three evaluation metrics. Note that, our proposed model significantly outperforms other methods at 5% significance level except at 10% significance level over JVTM model. This shows by jointly modeling topics, viewpoints and user interactions, our model can better identify posts with different viewpoints. 5.3 Identification of user groups We also use another task to evaluate our model. The task here is finding each user’s viewpoint and subsequently grouping users by their viewpoints. This task has been studied by Abu-Jbara and Radev (2012), Dasigi et al. (2012), Abu-Jbara et al. (2012) and Hassan et al. (2012). For the English data set, the user-level group labels are provided by the original data set. For the Chinese data set, we randomly selected 150 users for each issue and manually labeled them according to their viewpoints as reflected by their posts. If a user’s posts do not clearly suggest a viewpoint, we label her as neutral. Again we asked two human judges to do annotation. The agreement scores are above 0.70 for all issues, showing substantial agreement. This score is higher than viewpoint identification, which suggests that it is easier to judge a user’s viewpoin</context>
</contexts>
<marker>Abu-Jbara, Dasigi, Diab, Radev, 2012</marker>
<rawString>Amjad Abu-Jbara, Pradeep Dasigi, Mona Diab, and Dragomir R. Radev. 2012. Subgroup detection in ideological discussions. In Proceedings of ACL 2012, pages 399–409.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacob Andreas</author>
<author>Sara Rosenthal</author>
<author>Kathleen McKeown</author>
</authors>
<title>Annotating agreement and disagreement in threaded discussion.</title>
<date>2012</date>
<booktitle>In Proceedings of LREC’12.</booktitle>
<contexts>
<context position="17480" citStr="Andreas et al., 2012" startWordPosition="2959" endWordPosition="2962">):yu,nEYu0,n0 Next, we show how we jointly sample xu,n,l and zu,n,l. We jointly sample them because when xu,n,l = 0, zu,n,l does not need a value. We have the following formulas: Here again the Cs are counters defined in similar ways as before. For example, C1 ¬(u,n,l) is the number of times we observe 1 assigned to an x variable, excluding xu,n,l. 3.4 Interaction polarity prediction The problem of detecting agreement and disagreement from forum posts is relatively new. One possible solution is to use supervised learning, which requires training data (Galley et al., 2004; Abbott et al., 2011; Andreas et al., 2012). However, training data are also likely domain and language dependent, which makes them hard for re-use. For our task, we take a simpler approach and use a sentiment lexicon together with some heuristics to predict the polarity of interaction expressions. Specifically, we first identify interaction sentences following the strategies from Hassan et al. (2012). We assume sentences containing mentions of the recipient of a post are interaction sentences. Next, we consider words within a text window of 8 words surrounding these mentions. We then use a subjectivity lexicon to label these words. To</context>
</contexts>
<marker>Andreas, Rosenthal, McKeown, 2012</marker>
<rawString>Jacob Andreas, Sara Rosenthal, and Kathleen McKeown. 2012. Annotating agreement and disagreement in threaded discussion. In Proceedings of LREC’12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefano Baccianella</author>
<author>Andrea Esuli</author>
<author>Fabrizio Sebastiani</author>
</authors>
<title>Sentiwordnet 3.0: An enhanced lexical resource for sentiment analysis and opinion mining.</title>
<date>2010</date>
<booktitle>In LREC.</booktitle>
<contexts>
<context position="18317" citStr="Baccianella et al. (2010)" startWordPosition="3093" endWordPosition="3096">ict the polarity of interaction expressions. Specifically, we first identify interaction sentences following the strategies from Hassan et al. (2012). We assume sentences containing mentions of the recipient of a post are interaction sentences. Next, we consider words within a text window of 8 words surrounding these mentions. We then use a subjectivity lexicon to label these words. To form an English lexicon, we combine three popular lexicons: the sentiment lexicon used by Hu and Liu (2004), Multi-Perspective Question Answering Subjectivity Lexicon by Wilson et al. (2005) and SentiWordNet by Baccianella et al. (2010). Since we also work with a Chinese data set, to form the Chinese sentiment lexicon, we use opinion words from HowNet2 and NTUSD by Ku et al. (2007). To predict the polarity of an interaction expression, we simply check whether there are more positive sentiment words or more negative sentiment words in the expression, and label the interaction expression accordingly. We would like to stress that since this interaction classification step is independent of the latent variable model, we can always apply a more accurate method, but this is not the focus of this work. 4 Models for Comparison In ou</context>
</contexts>
<marker>Baccianella, Esuli, Sebastiani, 2010</marker>
<rawString>Stefano Baccianella, Andrea Esuli, and Fabrizio Sebastiani. 2010. Sentiwordnet 3.0: An enhanced lexical resource for sentiment analysis and opinion mining. In LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Blei</author>
<author>Andrew Y Ng</author>
<author>Michael I Jordan</author>
</authors>
<title>Latent dirichlet allocation.</title>
<date>2003</date>
<journal>J. Mach. Learn. Res.,</journal>
<pages>3--993</pages>
<contexts>
<context position="4140" citStr="Blei et al., 2003" startWordPosition="642" endWordPosition="645">dings of NAACL-HLT 2013, pages 1031–1040, Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics The interaction expressions in forum posts may help us infer the relation between two users and subsequently infer the viewpoints of the corresponding posts. In this paper, we propose a novel latent variable model for viewpoint discovery from threaded forum posts. Our model is based on the following observations: First, posts with different viewpoints tend to focus on different topics. To illustrate this point, we first apply the Latent Dirichlet Allocation (LDA) model (Blei et al., 2003) on a thread about “will you vote Obama” and obtain a set of topics. This thread comes from a data set that has each user’s viewpoint annotated. Using the ground truth viewpoint labels, we group all posts published by users with viewpoint 1 (or viewpoint 2) and compute the topic proportions. The two topic distributions are shown in Figure 1. We can see that indeed the two viewpoints each have some dominating topics. Our second observations is that the same user tends to hold the same viewpoint. In our model, we use a user-level viewpoint distribution to capture this observation, and the experi</context>
</contexts>
<marker>Blei, Ng, Jordan, 2003</marker>
<rawString>David M. Blei, Andrew Y. Ng, and Michael I. Jordan. 2003. Latent dirichlet allocation. J. Mach. Learn. Res., 3:993–1022.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pradeep Dasigi</author>
<author>Weiwei Guo</author>
<author>Mona T Diab</author>
</authors>
<title>Genre independent subgroup detection in online discussion threads: A study of implicit attitude using textual latent semantics.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>65--69</pages>
<contexts>
<context position="8628" citStr="Dasigi et al. (2012)" startWordPosition="1385" endWordPosition="1388">es not need training data. Recently, Mukherjee and Liu (2012) proposed an unsupervised model to extract different types of expressions including agreement/disagreement expressions. However, our focus is not to detect agreement/disagreement expressions but to model the interplay between agreement/disagreement expressions and viewpoints. The work by Mukherjee and Liu (2012) can potentially be combined with our model. Another line of related work is subgroup detection, which aims to separate users holding different viewpoints. This problem has recently been studied by Abu-Jbara and Radev (2012), Dasigi et al. (2012), Abu-Jbara et al. (2012) and Hassan et al. (2012), where a clustering based approach is used. Lu et al. (2012) studied both textual content and social interactions to find opposing network from online forums. In our experiments we show that our model can also be used for subgroup detection, but meanwhile we also directly identify viewpoints, which is not the goal of existing work on subgroup finding or opposing network extraction. 3 Model 3.1 Motivation Before we formally present our latent variable model for viewpoint discovery, let us first look at the assumptions we would like to capture i</context>
<context position="28215" citStr="Dasigi et al. (2012)" startWordPosition="4814" endWordPosition="4817">he best performance across the board in terms of all three evaluation metrics. Note that, our proposed model significantly outperforms other methods at 5% significance level except at 10% significance level over JVTM model. This shows by jointly modeling topics, viewpoints and user interactions, our model can better identify posts with different viewpoints. 5.3 Identification of user groups We also use another task to evaluate our model. The task here is finding each user’s viewpoint and subsequently grouping users by their viewpoints. This task has been studied by Abu-Jbara and Radev (2012), Dasigi et al. (2012), Abu-Jbara et al. (2012) and Hassan et al. (2012). For the English data set, the user-level group labels are provided by the original data set. For the Chinese data set, we randomly selected 150 users for each issue and manually labeled them according to their viewpoints as reflected by their posts. If a user’s posts do not clearly suggest a viewpoint, we label her as neutral. Again we asked two human judges to do annotation. The agreement scores are above 0.70 for all issues, showing substantial agreement. This score is higher than viewpoint identification, which suggests that it is easier t</context>
</contexts>
<marker>Dasigi, Guo, Diab, 2012</marker>
<rawString>Pradeep Dasigi, Weiwei Guo, and Mona T. Diab. 2012. Genre independent subgroup detection in online discussion threads: A study of implicit attitude using textual latent semantics. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 65–69.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yi Fang</author>
<author>Luo Si</author>
<author>Naveen Somasundaram</author>
<author>Zhengtao Yu</author>
</authors>
<title>Mining contrastive opinions on political texts using cross-perspective topic model.</title>
<date>2012</date>
<booktitle>In WSDM,</booktitle>
<pages>63--72</pages>
<contexts>
<context position="2573" citStr="Fang et al. (2012)" startWordPosition="390" endWordPosition="393">he may want to quickly get an overview of the major viewpoints and arguments given by the different sides. For policy makers who want to obtain public feedback on social issues from social media, it is also desirable to automatically summarize the viewpoints on an issue from relevant threads. In this paper, we study the problem of modeling and discovering different viewpoints in forum threads. Recently there has been some work on finding contrastive viewpoints from text. The model proposed by Paul et al. (2010) assumes viewpoints and topics are orthogonal dimensions. Another model proposed by Fang et al. (2012) assumes that documents are already grouped by viewpoints and it focus on identifying contrastive viewpoint words under the same topic. However, these existing studies are not based on interdependent documents like threaded forum posts. As a result, at least two important characteristics of threaded forum data are not considered in these models. (1) User identity: The user or publisher of each forum post is known, and a user may publish several posts in the same thread. Since the same user’s opinion on an issue usually remains unchanged, posts published by the same user are likely to contain t</context>
<context position="6893" citStr="Fang et al. (2012)" startWordPosition="1107" endWordPosition="1110"> sets. 2 Related Work There are a few different lines of work that are related to our work. For discovering different viewpoints from general text, Paul et al. (2010) used the model proposed by Paul and Girju (2010) to jointly model topics and viewpoints. They assume these two concepts are orthogonal and they do not consider user identity. In comparison, our model has the notion of topics and viewpoints, but we explicitly model the dependency of topics on viewpoints, i.e. we assume each viewpoint has a topic distribution. We also consider author identities as an important factor of our model. Fang et al. (2012) proposed a model that also combines topics and viewpoints. But they assume that documents are already grouped by viewpoints, which is not the case for forum posts. Therefore, their model cannot be directly applied to forum posts. There has also been some work on finding viewpoints from social media. Somasundaran and Wiebe (2010) studied how to identify stances in online debates. They used a supervised approach for classifying stances in ideological debates. In comparison, our model is an unsupervised method. The same authors proposed an unsupervised method which relies on associations of aspe</context>
</contexts>
<marker>Fang, Si, Somasundaram, Yu, 2012</marker>
<rawString>Yi Fang, Luo Si, Naveen Somasundaram, and Zhengtao Yu. 2012. Mining contrastive opinions on political texts using cross-perspective topic model. In WSDM, pages 63–72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Galley</author>
<author>Kathleen McKeown</author>
<author>Julia Hirschberg</author>
<author>Elizabeth Shriberg</author>
</authors>
<title>Identifying agreement and disagreement in conversational speech: Use of bayesian networks to model pragmatic dependencies.</title>
<date>2004</date>
<booktitle>In Proceedings of ACL’04, Main Volume,</booktitle>
<pages>669--676</pages>
<contexts>
<context position="7844" citStr="Galley et al., 2004" startWordPosition="1265" endWordPosition="1268">studied how to identify stances in online debates. They used a supervised approach for classifying stances in ideological debates. In comparison, our model is an unsupervised method. The same authors proposed an unsupervised method which relies on associations of aspects with topics indicative of stances mined from the Web for the task (Somasundaran and Wiebe, 2009). In contrast, our model is also an unsupervised one but we do not rely on any external knowledge. Part of our work is related to detecting agreement/disagreement from text. For this task, nor1032 mally supervised methods are used (Galley et al., 2004; Abbott et al., 2011), which require sufficient labeled training data. In our work, since we deal with different languages, we use a lexicon-based approach that does not need training data. Recently, Mukherjee and Liu (2012) proposed an unsupervised model to extract different types of expressions including agreement/disagreement expressions. However, our focus is not to detect agreement/disagreement expressions but to model the interplay between agreement/disagreement expressions and viewpoints. The work by Mukherjee and Liu (2012) can potentially be combined with our model. Another line of r</context>
<context position="17436" citStr="Galley et al., 2004" startWordPosition="2951" endWordPosition="2954">δ) p(su0,n0|yu0,n0, Yu0,n0, δ). (4) (u0,n0):yu,nEYu0,n0 Next, we show how we jointly sample xu,n,l and zu,n,l. We jointly sample them because when xu,n,l = 0, zu,n,l does not need a value. We have the following formulas: Here again the Cs are counters defined in similar ways as before. For example, C1 ¬(u,n,l) is the number of times we observe 1 assigned to an x variable, excluding xu,n,l. 3.4 Interaction polarity prediction The problem of detecting agreement and disagreement from forum posts is relatively new. One possible solution is to use supervised learning, which requires training data (Galley et al., 2004; Abbott et al., 2011; Andreas et al., 2012). However, training data are also likely domain and language dependent, which makes them hard for re-use. For our task, we take a simpler approach and use a sentiment lexicon together with some heuristics to predict the polarity of interaction expressions. Specifically, we first identify interaction sentences following the strategies from Hassan et al. (2012). We assume sentences containing mentions of the recipient of a post are interaction sentences. Next, we consider words within a text window of 8 words surrounding these mentions. We then use a s</context>
</contexts>
<marker>Galley, McKeown, Hirschberg, Shriberg, 2004</marker>
<rawString>Michel Galley, Kathleen McKeown, Julia Hirschberg, and Elizabeth Shriberg. 2004. Identifying agreement and disagreement in conversational speech: Use of bayesian networks to model pragmatic dependencies. In Proceedings of ACL’04, Main Volume, pages 669– 676.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ahmed Hassan</author>
<author>Amjad Abu-Jbara</author>
<author>Dragomir Radev</author>
</authors>
<title>Detecting subgroups in online discussions by modeling positive and negative relations among participants.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 EMNLP,</booktitle>
<pages>59--70</pages>
<contexts>
<context position="8678" citStr="Hassan et al. (2012)" startWordPosition="1394" endWordPosition="1397"> Liu (2012) proposed an unsupervised model to extract different types of expressions including agreement/disagreement expressions. However, our focus is not to detect agreement/disagreement expressions but to model the interplay between agreement/disagreement expressions and viewpoints. The work by Mukherjee and Liu (2012) can potentially be combined with our model. Another line of related work is subgroup detection, which aims to separate users holding different viewpoints. This problem has recently been studied by Abu-Jbara and Radev (2012), Dasigi et al. (2012), Abu-Jbara et al. (2012) and Hassan et al. (2012), where a clustering based approach is used. Lu et al. (2012) studied both textual content and social interactions to find opposing network from online forums. In our experiments we show that our model can also be used for subgroup detection, but meanwhile we also directly identify viewpoints, which is not the goal of existing work on subgroup finding or opposing network extraction. 3 Model 3.1 Motivation Before we formally present our latent variable model for viewpoint discovery, let us first look at the assumptions we would like to capture in the model. Viewpoint-based topic distribution: T</context>
<context position="17841" citStr="Hassan et al. (2012)" startWordPosition="3015" endWordPosition="3018">tion polarity prediction The problem of detecting agreement and disagreement from forum posts is relatively new. One possible solution is to use supervised learning, which requires training data (Galley et al., 2004; Abbott et al., 2011; Andreas et al., 2012). However, training data are also likely domain and language dependent, which makes them hard for re-use. For our task, we take a simpler approach and use a sentiment lexicon together with some heuristics to predict the polarity of interaction expressions. Specifically, we first identify interaction sentences following the strategies from Hassan et al. (2012). We assume sentences containing mentions of the recipient of a post are interaction sentences. Next, we consider words within a text window of 8 words surrounding these mentions. We then use a subjectivity lexicon to label these words. To form an English lexicon, we combine three popular lexicons: the sentiment lexicon used by Hu and Liu (2004), Multi-Perspective Question Answering Subjectivity Lexicon by Wilson et al. (2005) and SentiWordNet by Baccianella et al. (2010). Since we also work with a Chinese data set, to form the Chinese sentiment lexicon, we use opinion words from HowNet2 and N</context>
<context position="21114" citStr="Hassan et al. (2012)" startWordPosition="3579" endWordPosition="3582">aseline models using two data sets. Name Issue #Posts #Users EDS1 Vote for Obama 2599 197 EDS2 Arizona Immigration Law 738 59 EDS3 Tax Cuts 276 26 CDS1 Tencent and Qihoo dispute 30137 2507 CDS2 Fang Zhouzi questions Han Han 76934 1769 CDS3 Liu Xiang in London Olympics 29486 2774 Table 2: Some statistics of the data set. 5.1 Data Sets and Experimental Settings We focus our work on finding users’ viewpoints on a controversial issue, where we assume that there are two contradictory viewpoints. We use two data sets on controversial issues. The first data set comes from Abu-Jbara et al. (2012) and Hassan et al. (2012). This data set originally was used for finding subgroups of users, so the annotations were done at user level, i.e. for each user there is a label indicating which subgroup he/she belongs to. We use the top-3 mostly discussed threads with two subgroups for our study. In reality, controversial issues are often discussed across threads. We thus constructed another large data set which contains more than one thread for each issue. We chose three hot issues from one of the most popular Chinese online forums — TianYa Club3. The three issues are “Fang Zhouzi questions Han Han”4, “Tencent and Qihoo </context>
<context position="28265" citStr="Hassan et al. (2012)" startWordPosition="4823" endWordPosition="4826">ll three evaluation metrics. Note that, our proposed model significantly outperforms other methods at 5% significance level except at 10% significance level over JVTM model. This shows by jointly modeling topics, viewpoints and user interactions, our model can better identify posts with different viewpoints. 5.3 Identification of user groups We also use another task to evaluate our model. The task here is finding each user’s viewpoint and subsequently grouping users by their viewpoints. This task has been studied by Abu-Jbara and Radev (2012), Dasigi et al. (2012), Abu-Jbara et al. (2012) and Hassan et al. (2012). For the English data set, the user-level group labels are provided by the original data set. For the Chinese data set, we randomly selected 150 users for each issue and manually labeled them according to their viewpoints as reflected by their posts. If a user’s posts do not clearly suggest a viewpoint, we label her as neutral. Again we asked two human judges to do annotation. The agreement scores are above 0.70 for all issues, showing substantial agreement. This score is higher than viewpoint identification, which suggests that it is easier to judge a user’s viewpoint than a single post’s vi</context>
</contexts>
<marker>Hassan, Abu-Jbara, Radev, 2012</marker>
<rawString>Ahmed Hassan, Amjad Abu-Jbara, and Dragomir Radev. 2012. Detecting subgroups in online discussions by modeling positive and negative relations among participants. In Proceedings of the 2012 EMNLP, pages 59–70.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minqing Hu</author>
<author>Bing Liu</author>
</authors>
<title>Mining and summarizing customer reviews.</title>
<date>2004</date>
<booktitle>In Proceedings of the 10th ACM SIGKDD international conference on Knowledge discovery and data mining,</booktitle>
<pages>168--177</pages>
<contexts>
<context position="18188" citStr="Hu and Liu (2004)" startWordPosition="3075" endWordPosition="3078">rd for re-use. For our task, we take a simpler approach and use a sentiment lexicon together with some heuristics to predict the polarity of interaction expressions. Specifically, we first identify interaction sentences following the strategies from Hassan et al. (2012). We assume sentences containing mentions of the recipient of a post are interaction sentences. Next, we consider words within a text window of 8 words surrounding these mentions. We then use a subjectivity lexicon to label these words. To form an English lexicon, we combine three popular lexicons: the sentiment lexicon used by Hu and Liu (2004), Multi-Perspective Question Answering Subjectivity Lexicon by Wilson et al. (2005) and SentiWordNet by Baccianella et al. (2010). Since we also work with a Chinese data set, to form the Chinese sentiment lexicon, we use opinion words from HowNet2 and NTUSD by Ku et al. (2007). To predict the polarity of an interaction expression, we simply check whether there are more positive sentiment words or more negative sentiment words in the expression, and label the interaction expression accordingly. We would like to stress that since this interaction classification step is independent of the latent </context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>Minqing Hu and Bing Liu. 2004. Mining and summarizing customer reviews. In Proceedings of the 10th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 168–177.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lun-wei Ku</author>
<author>Yong-sheng Lo</author>
<author>Hsin-hsi Chen</author>
</authors>
<title>Using polarity scores of words for sentence-level opinion extraction.</title>
<date>2007</date>
<booktitle>In Proc. of the NTCIR-6 Workshop Meeting,</booktitle>
<pages>316--322</pages>
<contexts>
<context position="18465" citStr="Ku et al. (2007)" startWordPosition="3122" endWordPosition="3125">ume sentences containing mentions of the recipient of a post are interaction sentences. Next, we consider words within a text window of 8 words surrounding these mentions. We then use a subjectivity lexicon to label these words. To form an English lexicon, we combine three popular lexicons: the sentiment lexicon used by Hu and Liu (2004), Multi-Perspective Question Answering Subjectivity Lexicon by Wilson et al. (2005) and SentiWordNet by Baccianella et al. (2010). Since we also work with a Chinese data set, to form the Chinese sentiment lexicon, we use opinion words from HowNet2 and NTUSD by Ku et al. (2007). To predict the polarity of an interaction expression, we simply check whether there are more positive sentiment words or more negative sentiment words in the expression, and label the interaction expression accordingly. We would like to stress that since this interaction classification step is independent of the latent variable model, we can always apply a more accurate method, but this is not the focus of this work. 4 Models for Comparison In our experiments, we compare our model, Joint Viewpoint-Topic Model with User Interaction (JVTM-UI), with the following baseline models. JVTM: The mode</context>
</contexts>
<marker>Ku, Lo, Chen, 2007</marker>
<rawString>Lun-wei Ku, Yong-sheng Lo, and Hsin-hsi Chen. 2007. Using polarity scores of words for sentence-level opinion extraction. In Proc. of the NTCIR-6 Workshop Meeting, pages 316–322.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yue Lu</author>
<author>Hongning Wang</author>
<author>ChengXiang Zhai</author>
<author>Dan Roth</author>
</authors>
<title>Unsupervised discovery of opposing opinion networks from forum discussions.</title>
<date>2012</date>
<booktitle>In Proceedings of the 21st ACM international conference on Information and knowledge management, CIKM ’12,</booktitle>
<pages>1642--1646</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="8739" citStr="Lu et al. (2012)" startWordPosition="1405" endWordPosition="1408">ypes of expressions including agreement/disagreement expressions. However, our focus is not to detect agreement/disagreement expressions but to model the interplay between agreement/disagreement expressions and viewpoints. The work by Mukherjee and Liu (2012) can potentially be combined with our model. Another line of related work is subgroup detection, which aims to separate users holding different viewpoints. This problem has recently been studied by Abu-Jbara and Radev (2012), Dasigi et al. (2012), Abu-Jbara et al. (2012) and Hassan et al. (2012), where a clustering based approach is used. Lu et al. (2012) studied both textual content and social interactions to find opposing network from online forums. In our experiments we show that our model can also be used for subgroup detection, but meanwhile we also directly identify viewpoints, which is not the goal of existing work on subgroup finding or opposing network extraction. 3 Model 3.1 Motivation Before we formally present our latent variable model for viewpoint discovery, let us first look at the assumptions we would like to capture in the model. Viewpoint-based topic distribution: The first assumption we have is that different viewpoints tend</context>
</contexts>
<marker>Lu, Wang, Zhai, Roth, 2012</marker>
<rawString>Yue Lu, Hongning Wang, ChengXiang Zhai, and Dan Roth. 2012. Unsupervised discovery of opposing opinion networks from forum discussions. In Proceedings of the 21st ACM international conference on Information and knowledge management, CIKM ’12, pages 1642–1646, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher D Manning</author>
<author>Prabhakar Raghavan</author>
<author>Hinrich Schtze</author>
</authors>
<title>Introduction to Information Retrieval.</title>
<date>2008</date>
<publisher>Cambridge University Press,</publisher>
<contexts>
<context position="25172" citStr="Manning et al., 2008" startWordPosition="4281" endWordPosition="4284">CDS3 are Fang Zhouzi, Tencent and Liu Xiang respectively. For each given post, the annotators were asked to judge whether the post has expressed viewpoints and if so, what is its corresponding viewpoint. We measure the agreement score using Cohen’s kappa coefficient. The lowest agreement score for an issue is 0.61 in the data set, showing good agreement. We then used the set of posts that were labeled with the same viewpoint by the two annotators as our evaluation data for all the models. Since our task is essentially a clustering problem, we use purity and entropy to measure the performance (Manning et al., 2008). Furthermore, we also use accuracy where we choose the better alignment of clusters with ground truth class labels and compute the percentage of posts that are “classified” correctly. For purity and accuracy, the higher the measure is the better the performance. For entropy, the lower the measure is the better the performance. We give an overview of the all the averaged model results on the data sets in Figure 4. We observed that Purity Entropy Accuracy Figure 4: Averaged results of the models in identification of viewpoints. UIM performs relatively better than other methods except our model.</context>
</contexts>
<marker>Manning, Raghavan, Schtze, 2008</marker>
<rawString>Christopher D. Manning, Prabhakar Raghavan, and Hinrich Schtze. 2008. Introduction to Information Retrieval. Cambridge University Press, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arjun Mukherjee</author>
<author>Bing Liu</author>
</authors>
<title>Modeling review comments.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>320--329</pages>
<contexts>
<context position="8069" citStr="Mukherjee and Liu (2012)" startWordPosition="1301" endWordPosition="1304">ised method which relies on associations of aspects with topics indicative of stances mined from the Web for the task (Somasundaran and Wiebe, 2009). In contrast, our model is also an unsupervised one but we do not rely on any external knowledge. Part of our work is related to detecting agreement/disagreement from text. For this task, nor1032 mally supervised methods are used (Galley et al., 2004; Abbott et al., 2011), which require sufficient labeled training data. In our work, since we deal with different languages, we use a lexicon-based approach that does not need training data. Recently, Mukherjee and Liu (2012) proposed an unsupervised model to extract different types of expressions including agreement/disagreement expressions. However, our focus is not to detect agreement/disagreement expressions but to model the interplay between agreement/disagreement expressions and viewpoints. The work by Mukherjee and Liu (2012) can potentially be combined with our model. Another line of related work is subgroup detection, which aims to separate users holding different viewpoints. This problem has recently been studied by Abu-Jbara and Radev (2012), Dasigi et al. (2012), Abu-Jbara et al. (2012) and Hassan et a</context>
<context position="32712" citStr="Mukherjee and Liu, 2012" startWordPosition="5589" endWordPosition="5592">captures these observations in a principled way. In particular, to incorporate the user interaction information, we proposed a novel generative process. Empirical evaluation on the real forum data sets showed that our model could cluster both posts and users with different viewpoints more accurately than the baseline models we consider. To the best of our knowledge, our work is the first to incorporate user interaction polarity into a generative model to discover viewpoints. In this work, we only considered unigrams. As some previous work has shown, more complex lexical units such as n-grams (Mukherjee and Liu, 2012) and dependency triplets (Paul et al., 2010) may improve the performance of topic models. We will consider these strategies in our future work. Currently we use a simple heuristic-based classifier to predict interaction polarity. In our further work, we plan to consider more accurate methods using deeper linguistic analysis. We did not study how to summarize the discovered viewpoints in this work, which is also something we will look into in our future work. Acknowledgments We thank the reviewers for their valuable comments on this work. We also thank Shuang Xia for his help on processing and </context>
</contexts>
<marker>Mukherjee, Liu, 2012</marker>
<rawString>Arjun Mukherjee and Bing Liu. 2012. Modeling review comments. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 320–329.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael J Paul</author>
<author>Roxana Girju</author>
</authors>
<title>A twodimensional topic-aspect model for discovering multifaceted topics.</title>
<date>2010</date>
<booktitle>In AAAI.</booktitle>
<contexts>
<context position="6490" citStr="Paul and Girju (2010)" startWordPosition="1040" endWordPosition="1043">luation metrics. The experiments are presented in Section 5. The contributions of our work are threefold: (1) We identify the importance of using user interactions to help infer viewpoints in forum posts. (2) We propose a principled latent variable model to jointly model topics, viewpoints and user interactions. (3) We empirically verify the validity of the three assumptions in our model using real data sets. 2 Related Work There are a few different lines of work that are related to our work. For discovering different viewpoints from general text, Paul et al. (2010) used the model proposed by Paul and Girju (2010) to jointly model topics and viewpoints. They assume these two concepts are orthogonal and they do not consider user identity. In comparison, our model has the notion of topics and viewpoints, but we explicitly model the dependency of topics on viewpoints, i.e. we assume each viewpoint has a topic distribution. We also consider author identities as an important factor of our model. Fang et al. (2012) proposed a model that also combines topics and viewpoints. But they assume that documents are already grouped by viewpoints, which is not the case for forum posts. Therefore, their model cannot be</context>
</contexts>
<marker>Paul, Girju, 2010</marker>
<rawString>Michael J. Paul and Roxana Girju. 2010. A twodimensional topic-aspect model for discovering multifaceted topics. In AAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael J Paul</author>
<author>ChengXiang Zhai</author>
<author>Roxana Girju</author>
</authors>
<title>Summarizing contrastive viewpoints in opinionated text.</title>
<date>2010</date>
<booktitle>In EMNLP,</booktitle>
<pages>66--76</pages>
<contexts>
<context position="2471" citStr="Paul et al. (2010)" startWordPosition="375" endWordPosition="378">osely following an event or issue, instead of going through all the existing posts in a long thread, she may want to quickly get an overview of the major viewpoints and arguments given by the different sides. For policy makers who want to obtain public feedback on social issues from social media, it is also desirable to automatically summarize the viewpoints on an issue from relevant threads. In this paper, we study the problem of modeling and discovering different viewpoints in forum threads. Recently there has been some work on finding contrastive viewpoints from text. The model proposed by Paul et al. (2010) assumes viewpoints and topics are orthogonal dimensions. Another model proposed by Fang et al. (2012) assumes that documents are already grouped by viewpoints and it focus on identifying contrastive viewpoint words under the same topic. However, these existing studies are not based on interdependent documents like threaded forum posts. As a result, at least two important characteristics of threaded forum data are not considered in these models. (1) User identity: The user or publisher of each forum post is known, and a user may publish several posts in the same thread. Since the same user’s o</context>
<context position="6441" citStr="Paul et al. (2010)" startWordPosition="1031" endWordPosition="1034">outperform the baselines in terms of three evaluation metrics. The experiments are presented in Section 5. The contributions of our work are threefold: (1) We identify the importance of using user interactions to help infer viewpoints in forum posts. (2) We propose a principled latent variable model to jointly model topics, viewpoints and user interactions. (3) We empirically verify the validity of the three assumptions in our model using real data sets. 2 Related Work There are a few different lines of work that are related to our work. For discovering different viewpoints from general text, Paul et al. (2010) used the model proposed by Paul and Girju (2010) to jointly model topics and viewpoints. They assume these two concepts are orthogonal and they do not consider user identity. In comparison, our model has the notion of topics and viewpoints, but we explicitly model the dependency of topics on viewpoints, i.e. we assume each viewpoint has a topic distribution. We also consider author identities as an important factor of our model. Fang et al. (2012) proposed a model that also combines topics and viewpoints. But they assume that documents are already grouped by viewpoints, which is not the case </context>
<context position="20273" citStr="Paul et al. (2010)" startWordPosition="3430" endWordPosition="3433">nteraction expressions. 2http://www.keenage.com/html/e_index.html ∝ p(xu,n,l = 1, zu,n,l = t|X¬(u,n,l), Z¬(u,n,l), Y, W, γ, η, β, βB) M C1 + γ ¬(u,n,l) t η Cyu,n,l,¬(u,n,l) + C(·) + Tη yu,n,l,¬(u,n,l) , (5) C(·) t,¬(u,n,l) + V β wu,n,l Ct,¬(u,n,l) + β C(·) ¬(u,n,l) + 2γ p(xu,n,l = 0|X¬(u,n,l), Z¬(u,n,l), Y, W, γ, η, β, βB) C0¬(u,n,l) + γ M . () B (6) CB ¬(u,n,l) + vβ CB,¬(u,n,l) + βB wu,n,l (·) C(u,n,l) + 2γ 1035 Figure 3: (a) JVTM: Joint Viewpoint-Topic Model. (b) JVTM-G: JVTM with a global viewpoint distribution. (c) UIM: User-Interaction Model. TAM: The last model we consider is the one by Paul et al. (2010). As TAM is applied at document collections, we first concatenate all the posts by the same user into a pseudo document and then apply TAM. 5 Experiments and Analysis In this section, we evaluate our model with a set of baseline models using two data sets. Name Issue #Posts #Users EDS1 Vote for Obama 2599 197 EDS2 Arizona Immigration Law 738 59 EDS3 Tax Cuts 276 26 CDS1 Tencent and Qihoo dispute 30137 2507 CDS2 Fang Zhouzi questions Han Han 76934 1769 CDS3 Liu Xiang in London Olympics 29486 2774 Table 2: Some statistics of the data set. 5.1 Data Sets and Experimental Settings We focus our work</context>
<context position="27222" citStr="Paul et al. (2010)" startWordPosition="4658" endWordPosition="4661"> on the data sets. We perform the 2-tailed paired t-test as used by Abu-Jbara et al. (2012) on the results. All the result differences are at 10% significance level if not with further clarification. First, JVTM has a better performance over JVTM-G, which shows it is important to consider user identity in the task. Second, JVTM and TAM have similar performance on 1.0 0.8 0.6 0.4 JVTM-G TAM JVTM UIM JVTM-UI 1037 EDS1 and CDS2, but JVTM has a relatively better performance on EDS2, EDS3, CDS1 and CDS3. This shows it is helpful to consider each viewpoint’s topic preference. Although as studied by Paul et al. (2010), by only using unigram features, TAM may not be able to cluster viewpoints accurately, our study shows that the results can be improved when adding each viewpoint’s topic focus. Third, UIM has relatively better performance than the other models, which demonstrates that user interactions alone can do a decent job in inferring viewpoints. Finally, our proposed model has the best performance across the board in terms of all three evaluation metrics. Note that, our proposed model significantly outperforms other methods at 5% significance level except at 10% significance level over JVTM model. Thi</context>
</contexts>
<marker>Paul, Zhai, Girju, 2010</marker>
<rawString>Michael J. Paul, ChengXiang Zhai, and Roxana Girju. 2010. Summarizing contrastive viewpoints in opinionated text. In EMNLP, pages 66–76.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Swapna Somasundaran</author>
<author>Janyce Wiebe</author>
</authors>
<title>Recognizing stances in online debates.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP,</booktitle>
<pages>226--234</pages>
<contexts>
<context position="7593" citStr="Somasundaran and Wiebe, 2009" startWordPosition="1220" endWordPosition="1224">sume that documents are already grouped by viewpoints, which is not the case for forum posts. Therefore, their model cannot be directly applied to forum posts. There has also been some work on finding viewpoints from social media. Somasundaran and Wiebe (2010) studied how to identify stances in online debates. They used a supervised approach for classifying stances in ideological debates. In comparison, our model is an unsupervised method. The same authors proposed an unsupervised method which relies on associations of aspects with topics indicative of stances mined from the Web for the task (Somasundaran and Wiebe, 2009). In contrast, our model is also an unsupervised one but we do not rely on any external knowledge. Part of our work is related to detecting agreement/disagreement from text. For this task, nor1032 mally supervised methods are used (Galley et al., 2004; Abbott et al., 2011), which require sufficient labeled training data. In our work, since we deal with different languages, we use a lexicon-based approach that does not need training data. Recently, Mukherjee and Liu (2012) proposed an unsupervised model to extract different types of expressions including agreement/disagreement expressions. Howe</context>
</contexts>
<marker>Somasundaran, Wiebe, 2009</marker>
<rawString>Swapna Somasundaran and Janyce Wiebe. 2009. Recognizing stances in online debates. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP, pages 226–234.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Swapna Somasundaran</author>
<author>Janyce Wiebe</author>
</authors>
<title>Recognizing stances in ideological on-line debates.</title>
<date>2010</date>
<booktitle>In Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text,</booktitle>
<pages>116--124</pages>
<contexts>
<context position="7224" citStr="Somasundaran and Wiebe (2010)" startWordPosition="1161" endWordPosition="1164">nsider user identity. In comparison, our model has the notion of topics and viewpoints, but we explicitly model the dependency of topics on viewpoints, i.e. we assume each viewpoint has a topic distribution. We also consider author identities as an important factor of our model. Fang et al. (2012) proposed a model that also combines topics and viewpoints. But they assume that documents are already grouped by viewpoints, which is not the case for forum posts. Therefore, their model cannot be directly applied to forum posts. There has also been some work on finding viewpoints from social media. Somasundaran and Wiebe (2010) studied how to identify stances in online debates. They used a supervised approach for classifying stances in ideological debates. In comparison, our model is an unsupervised method. The same authors proposed an unsupervised method which relies on associations of aspects with topics indicative of stances mined from the Web for the task (Somasundaran and Wiebe, 2009). In contrast, our model is also an unsupervised one but we do not rely on any external knowledge. Part of our work is related to detecting agreement/disagreement from text. For this task, nor1032 mally supervised methods are used </context>
</contexts>
<marker>Somasundaran, Wiebe, 2010</marker>
<rawString>Swapna Somasundaran and Janyce Wiebe. 2010. Recognizing stances in ideological on-line debates. In Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text, pages 116–124.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Wilson</author>
<author>Janyce Wiebe</author>
<author>Paul Hoffmann</author>
</authors>
<title>Recognizing contextual polarity in phrase-level sentiment analysis.</title>
<date>2005</date>
<booktitle>In HLT/EMNLP.</booktitle>
<contexts>
<context position="18271" citStr="Wilson et al. (2005)" startWordPosition="3086" endWordPosition="3089">con together with some heuristics to predict the polarity of interaction expressions. Specifically, we first identify interaction sentences following the strategies from Hassan et al. (2012). We assume sentences containing mentions of the recipient of a post are interaction sentences. Next, we consider words within a text window of 8 words surrounding these mentions. We then use a subjectivity lexicon to label these words. To form an English lexicon, we combine three popular lexicons: the sentiment lexicon used by Hu and Liu (2004), Multi-Perspective Question Answering Subjectivity Lexicon by Wilson et al. (2005) and SentiWordNet by Baccianella et al. (2010). Since we also work with a Chinese data set, to form the Chinese sentiment lexicon, we use opinion words from HowNet2 and NTUSD by Ku et al. (2007). To predict the polarity of an interaction expression, we simply check whether there are more positive sentiment words or more negative sentiment words in the expression, and label the interaction expression accordingly. We would like to stress that since this interaction classification step is independent of the latent variable model, we can always apply a more accurate method, but this is not the foc</context>
</contexts>
<marker>Wilson, Wiebe, Hoffmann, 2005</marker>
<rawString>Theresa Wilson, Janyce Wiebe, and Paul Hoffmann. 2005. Recognizing contextual polarity in phrase-level sentiment analysis. In HLT/EMNLP.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>