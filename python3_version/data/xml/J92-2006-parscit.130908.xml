<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002224">
<note confidence="0.648943">
Letters to the Editor
</note>
<bodyText confidence="0.975798151515152">
I do not believe that Geoffrey Pullum, in his attack on my Antilinguistics (Computational
Linguistics, 17(2), 240) is trying to protect his livelihood. I hardly think he is in any
danger there. But I do think he is protecting the intellectual pride of himself and his
colleagues. That is reasonable and to be expected. What is not reasonable is that in
doing this he does not report, let alone try to answer, a single one of my general
arguments or, with one possible exception, any of my specific points. His method
of review is to mock remarks that he has stripped of all their reasoned context, and
to scorn conclusions without even hinting at the existence of the large amounts of
evidence I present in justification. (Luckily for my confidence there have been other
reviewers who have shown greater appreciation of my rational powers.)
Most serious of all Pullum&apos;s mistakes is perhaps that several of his complaints
are based on the very assumptions that I question in the book. His talk of Quirk&apos;s
&amp;quot;monumental descriptive work on modern English&amp;quot; without mentioning any part of
my case against it is one example. His contempt for my failure to master primary
sources is another. I should probably have emphasized my argument about this more.
But it is there, on pages 2, 195n, and 258. It is surely significant that Pullum uses
p. 195n, not to explain my position, but to attack the book&apos;s poor production.
He is quite right to criticize the mistakes in names (I apologize to the people con-
cerned), the faulty index, and missing arrows. It was careless; I should have checked
the proofs better. Pullum is careless himself. He misquotes a sentence from p. 56; and
in the index it is only the proper names that have two figures too high (and from
p. 170, not p. 180 as he states)—all the other entries are correct.
In the only case where Pullum really attempts a proper discussion of the material
to show that &amp;quot;when by chance Gethin gets hold of the linguistic ball for a moment
he unfailingly drops it&amp;quot;) his criticism is typical of the barren formality that I com-
plain of: I should have located the ambiguity of Flying planes can be dangerous in the
transitive/intransitive contrast in fly, not in -ing. He thus abandons reality, the words
actually used, for the sake of an abstraction. And I am not simply insisting on a princi-
ple here, for in the process Pullum gets it wrong. The transitive/intransitive difference
in the meanings of -ing is not the crucial one, and may not be there at all, as can be
seen in, for example, The burning sun. . /Burning wood (is wasteful), where (burn)ing is
transitive in both cases, but has different meanings. At the same time I cannot think
of any sentence where there would be any transitive/intransitive confusion through
the use of an infinitive, indicative, or imperative. Can Pullum?
It is sadly revealing that he suspects that my attack on Quirk&apos;s grammar is prompted
by a desire to settle scores with prestigious linguists at British universities. I have no
scores to settle with anyone. Is he so used to academic in-fighting that he cannot be-
lieve that I have no personal quarrel, only a general quarrel with the attitudes and
assumptions, purposes and pretentions, methods and thinking, of academic social &apos;sci-
ence&apos;?
I am impatient because while social &apos;scientists&apos; claim authority, they have failed, I
believe, to deliver real results, and yet at the same time exercise intellectual dominance
over the rest of the community. I repeat something I say in my book. If academic
experts think their work has any importance, that it can affect people&apos;s lives in any way,
C) 1992 Association for Computational Linguistics
Computational Linguistics Volume 18, Number 2
they have a duty to debate their work and ideas with any nonexpert members of the
public that are interested. There would be a great many more people actively interested
than there are now if they were not normally cowed by the sort of attitude displayed
by Pullum in his review. I anticipated what is happening. It&apos;s fine for academics to
savage each other. But immediately somebody attacks them from outside they close
ranks.
If this letter is published I hope he will have the courage to respond with a
serious attempt to rebut in a reasoned way at least some of my broader propositions:
linguistic analysis serves no useful purpose; there is really no such thing as structure
(as opposed to practical logic) in language; linguistics has not improved the learning
of foreign languages; thought is essentially independent of language but is in practice
corrupted by it; etc.
But if Pullum has real courage he will seek a much wider forum than this journal,
a forum where he should discuss these matters without being assured of the sympathy
of virtually all his &apos;insider&apos; readers as he can be here. If he can persuade a more general
journal, or a newspaper, to publish his opinions on these matters (and to explain to
use why computational linguistics is important), I shall be happy to respond. It might
also induce both of us to be a little more temperate.
Amorey Gethin
Cambridge, England
</bodyText>
<subsectionHeader confidence="0.881955">
What is Semantic Structures About?
</subsectionHeader>
<bodyText confidence="0.999648148148148">
It is not clear how useful it is to reply to Yorick Wilks&apos;s dismissive review of my
Semantic Structures (SS) (Computational Linguistics 18:1, March 1992). Nevertheless, I
will attempt to say briefly how I think Wilks has misconstrued the enterprise.
Wilks describes SS as &amp;quot;a large project to construct semantic or conceptual expres-
sions of word meaning on which inference can be done.&amp;quot; A substantial part of his
criticism flows from the book&apos;s failing to meet this description in a way that sat-
isfies him (about which more in a moment). But constructing formalized semantic
expressions for words is only one of the goals of the book. The general goal is &amp;quot;the
characterization of the mental resources that make possible human knowledge and ex-
perience of the world&amp;quot; (p. 8). More precisely, &amp;quot;What are the innate units and principles
of organization that make human lexical and sentential concepts both possible in all
their variety and also learnable on the basis of some realistic combination of linguistic
and nonlinguistic experience?&amp;quot; (p. 11). In addition to conceptual structures being an
interface between language and inference, they can be compared with &amp;quot;conceptual
structures derived from sensory modalities&amp;quot; (p. 11). In short, I conceive of the inquiry
as thoroughly psychological, and not just a technical work on &amp;quot;handcrafting lexical
codings,&amp;quot; as Wilks puts it.
SS itself spends only one chapter on philosophical and psychological foundations
before moving on to technical details of formulating the relation between lexical struc-
ture, syntactic structure, and conceptual structure. As the text makes clear, the reason
for this is that I have written two previous books dealing in much more detail with
philosophical and psychological foundations: Semantics and Cognition (Cambridge, MA:
The MIT Press, 1983) and Consciousness and the Computational Mind (Cambridge, MA:
The MIT Press, 1987). The first chapter of SS is a precis of the positions developed
and defended in this previous work.
One of Wilks&apos;s main complaints about SS is that it does not make sufficient mention
of the AT and CL literature on lexical and conceptual semantics. Indeed, he insinuates
</bodyText>
<page confidence="0.980644">
240
</page>
<note confidence="0.808802">
Letters to the Editor
</note>
<bodyText confidence="0.9971908">
that if I had paid attention to this literature, I would have seen that my approach was
pointless, since everyone in AT and CL gave it up long ago.
I have two responses to this criticism. The first is that life is short, and one has to
choose what to read out of an inexhaustible literature in many fields. One is always
at one&apos;s peril at having missed something important. If I have missed something
important, I am ready to accept responsibility for it and try to do better next time.&apos; This
work merited citation in the section on aspectual structure on p. 28, and I apologize
to James for the omission. On the other hand, I did read a fair amount of the AT and
CL literature during the seventies and early eighties, when it appeared to be similar
to what I was doing; there are not a few references to this literature in Semantics and
</bodyText>
<subsubsectionHeader confidence="0.478528">
Cognition.2
</subsubsectionHeader>
<bodyText confidence="0.99997625">
However, I felt at the time that the empirical justifications of most AI-CL work
were insufficient: it was too often difficult to say why one particular solution was
better than any other, and which decisions about representation were being made on
a principled basis. I therefore decided that, while the AI-CL tradition might produce
interesting simulations of limited aspects of language understanding, it was not going
to teach me much about the overall nature of human language, and so I abandoned
contact. (In a sense I feel vindicated by Wilks&apos;s saying that no one does this sort of
work anymore: he is telling me that I was right in thinking it wouldn&apos;t work.)
SS, by contrast with much of the AI-CL tradition, attempts to justify every step
of formalization and to distinguish between essential and inessential aspects of the
formalism. It appeals to a wide range of linguistic data, not just the fixed given corpus
of many Al implementations. Like other work in the linguistic tradition, it is deeply
concerned with accounting for what does not happen—hence its preoccupation with
constraining the theory so as to explain the ungrammaticality of sentences that are in
principle plausible. Wilks, however, seems to project onto the book his own goals for
linguistic analysis, and apparently does not recognize the difference in methodology
as flowing from a different outlook. As a result, he sees nothing but a lot of effort
spent on what seem to him insignificant details.
But many of the seemingly insignificant details offer a great deal to our under-
standing of the organization of language. SS spends considerable effort showing how
to simplify lexical entries of verbs and prepositions so as to account for the range of
syntactic frames in which they can and cannot occur, as well as for the differences in
meaning they carry in different frames. In addition, important classes of lexical items
are unified. For example, causative verbs, treated in almost everyone&apos;s theory as ex-
pressing a conceptual primitive CAUSE, are shown to form a natural class along with
verbs of helping, permitting, trying, resisting, and entailing. In the process of treating
these relations formally, the alleged primitive CAUSE dissolves into a combination of
more general predicates and features. Finally, three chapters of the book are devoted
</bodyText>
<footnote confidence="0.946861615384615">
1 Wilks takes me to task for not citing my Brandeis colleague James Pustejovsky; he refers to a book
allegedly published in 1991 that actually was completed only at the end of 1991 and is still not
published. In fact, the only work of Pustejovsky&apos;s that was in citable form in 1989, when SS was
completed, was his work on event structure, which finally achieved real publication in Cognition in late
1991.
2 In particular, Wilks heaps scorn on my brief mention of &amp;quot;preference rules&amp;quot; in SS, citing the AI—CL
tradition as knowing better. However, as SS states, there is much more extensive discussion of
preference rules in Semantics and Cognition, and also in my book with Fred Lerdahl, A Generative Theory
of Tonal Music (Cambridge, MA: The MIT Press, 1983). SS moreover observes (p. 284) that the
conceptual indeterminacies expressed by preference rules &amp;quot;play a relatively minor role in the relation
between conceptual structure and syntax.... This is why the present work, concerned most directly
with the syntax—semantics correspondence, has not made much reference to formal devices such as
preference rules, graded conditions, and 3D model stereotypes.&amp;quot;
</footnote>
<page confidence="0.988771">
241
</page>
<note confidence="0.635997">
Computational Linguistics Volume 18, Number 2
</note>
<bodyText confidence="0.97690085106383">
to analysis of syntactic adjuncts that carry thematic roles, such as the with of cover
with a cloth (which proves not to be an instrumental), four different varieties of for,
depictive and resultative predication, and the curious construction occurring in Bill
belched his way out of the restaurant. If one&apos;s concerns are at the level of &amp;quot;handcrafting
lexical entries,&amp;quot; these issues are perhaps not of great importance. But from the point
of view of linguistics, these case studies establish important boundary conditions on
the expressive capacity of human grammars; they show us the microstructure of lan-
guage at a higher degree of resolution than was previously possible, a degree that was
certainly not attained by the AI–CL approaches of the 1970s.
Now, it is no surprise that the linguistic and computational enterprises should
converge on certain basic elements of formalism. Everyone finds it convenient to use
capitalized English words to stand for meanings of things they don&apos;t yet know how
to formalize, e.g., IN, FOR, WITH, MOUTH, CAUSE. Everyone needs a means to ex-
press how characters play roles in events; constituent structure notation and function-
argument notation are among the most natural ways to represent these relations. The
fact that everyone uses these notations tends to mask the differences in goals to which
the notations are being applied. However, what distinguishes one theory from another
is how one goes beyond these obvious points: when one can find a further decomposi-
tion of a word or a phrase (as happens frequently in SS, for example with causatives),
what is it like? What is the repertoire of constituent types and function types out of
which concepts are built? How are these mapped productively into linguistic expres-
sions? If one is a theoretical linguist or psycholinguist, one may further ask: Is this
repertoire psychologically and biologically plausible? Does it make learning possible
for the child? And so forth.
Alternatively, if one is a computational linguist, the goals may include questions
such as: Can this theory be built into an operating computer program? Can it yield
a system of automatic concept construction from text? And so forth. There are two
possible ways these latter goals might be related to the linguist&apos;s. First, the two sets of
goals might be orthogonal, yielding different and unrelated solutions, in which case
there is not too much point in paying attention to each other&apos;s work. Alternatively,
it might just be that the best (or only) way to make a computer process and acquire
language is essentially to do it the way people do it, In this case it makes sense
for computational linguists not to treat the results of linguistic theory as &amp;quot;imaginary
procedures&amp;quot; and &amp;quot;fantasy encodings&amp;quot; (to use Wilks&apos;s terms), but as a more careful
approch to common problems. That doesn&apos;t mean linguists are always right—there
are plenty of wheels being spun in linguistics, for sure—but the goals, results, and
difficulties recognized by linguists maybe ought to get a little more respect. Under
such conditions, when computational linguists are testing theories that linguists can
regard as linguistically plausible, it is by all means worthwhile as well for linguists to
reciprocate.
Ray Jackendoff
Brandeis University, Waltham, MA 02254-9110
I wish to reply to Vitale&apos;s recent article in CL 17:3, which describes the fairly well-
established method of name pronunciation that is currently used in a number of speech
synthesizers including the ones at DEC, Bellcore, and AT&amp;T Bell Laboratories. It is
not entirely clear why it would be appropriate to discuss this topic in Computational
Linguistics given that the method has been fairly well-established for many years.
</bodyText>
<page confidence="0.990057">
242
</page>
<note confidence="0.609726">
Letters to the Editor
</note>
<bodyText confidence="0.999717916666667">
Nevertheless on page 259, Vitale suggests that the discussion is appropriate because
previous researchers have failed to disclose the details of the method:
&amp;quot;It should be stressed that there have been other attempts to imple-
ment similar algorithms, although few descriptions of such implemen-
tations are available.&amp;quot;
It seems to me that there are plenty of adequate descriptions in the literature includ-
ing Church (1985, p. 252). I believe that this description is more than adequate for
someone skilled in the art as evidenced by the fact that it has since been replicated
in several different places, and has been described in at least one review article on
speech synthesis (Klatt 1987, p. 773). In fact, the details of the method have been fully
disclosed in sufficient detail to satisfy the United States Patent Office (Church 1989). In
short, I don&apos;t know what more I could have done to disclose the details of my work.
</bodyText>
<sectionHeader confidence="0.536332" genericHeader="abstract">
Ken Church
AT&amp;T Bell Laboratories
References
</sectionHeader>
<reference confidence="0.998344333333333">
Church, K. (1985). &amp;quot;Stress assignment in letter to sound rules for speech synthesis,&amp;quot;
Association for Computational Linguistics.
Klatt, D. (1987). &amp;quot;Review of test-to-speech conversion for English,&amp;quot; I. Acoust. Soc. Am. 82(3),
737-793.
Church, K. (1989). &amp;quot;Text analysis system with letter sequence recognition and speech stress
assignment arrangement,&amp;quot; United States Patent 4,829,580.
</reference>
<page confidence="0.999047">
243
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.048773">
<title confidence="0.628711">Letters to the Editor</title>
<abstract confidence="0.988394671875">do not believe that Geoffrey Pullum, in his attack on my (Computational 240) is trying to protect his livelihood. I hardly think he is in any danger there. But I do think he is protecting the intellectual pride of himself and his colleagues. That is reasonable and to be expected. What is not reasonable is that in doing this he does not report, let alone try to answer, a single one of my general arguments or, with one possible exception, any of my specific points. His method of review is to mock remarks that he has stripped of all their reasoned context, and to scorn conclusions without even hinting at the existence of the large amounts of evidence I present in justification. (Luckily for my confidence there have been other reviewers who have shown greater appreciation of my rational powers.) Most serious of all Pullum&apos;s mistakes is perhaps that several of his complaints are based on the very assumptions that I question in the book. His talk of Quirk&apos;s &amp;quot;monumental descriptive work on modern English&amp;quot; without mentioning any part of my case against it is one example. His contempt for my failure to master primary sources is another. I should probably have emphasized my argument about this more. But it is there, on pages 2, 195n, and 258. It is surely significant that Pullum uses p. 195n, not to explain my position, but to attack the book&apos;s poor production. He is quite right to criticize the mistakes in names (I apologize to the people concerned), the faulty index, and missing arrows. It was careless; I should have checked the proofs better. Pullum is careless himself. He misquotes a sentence from p. 56; and in the index it is only the proper names that have two figures too high (and from p. 170, not p. 180 as he states)—all the other entries are correct. In the only case where Pullum really attempts a proper discussion of the material to show that &amp;quot;when by chance Gethin gets hold of the linguistic ball for a moment he unfailingly drops it&amp;quot;) his criticism is typical of the barren formality that I comof: I should have located the ambiguity of planes can be dangerous the contrast in fly, not in thus abandons reality, the words actually used, for the sake of an abstraction. And I am not simply insisting on a principle here, for in the process Pullum gets it wrong. The transitive/intransitive difference the meanings of not the crucial one, and may not be there at all, as can be in, for example, burning sun. . /Burning wood (is wasteful), transitive in both cases, but has different meanings. At the same time I cannot think of any sentence where there would be any transitive/intransitive confusion through the use of an infinitive, indicative, or imperative. Can Pullum? It is sadly revealing that he suspects that my attack on Quirk&apos;s grammar is prompted by a desire to settle scores with prestigious linguists at British universities. I have no scores to settle with anyone. Is he so used to academic in-fighting that he cannot believe that I have no personal quarrel, only a general quarrel with the attitudes and assumptions, purposes and pretentions, methods and thinking, of academic social &apos;science&apos;? I am impatient because while social &apos;scientists&apos; claim authority, they have failed, I believe, to deliver real results, and yet at the same time exercise intellectual dominance over the rest of the community. I repeat something I say in my book. If academic experts think their work has any importance, that it can affect people&apos;s lives in any way, C) 1992 Association for Computational Linguistics Computational Linguistics Volume 18, Number 2 they have a duty to debate their work and ideas with any nonexpert members of the public that are interested. There would be a great many more people actively interested than there are now if they were not normally cowed by the sort of attitude displayed by Pullum in his review. I anticipated what is happening. It&apos;s fine for academics to savage each other. But immediately somebody attacks them from outside they close ranks. If this letter is published I hope he will have the courage to respond with a serious attempt to rebut in a reasoned way at least some of my broader propositions: linguistic analysis serves no useful purpose; there is really no such thing as structure (as opposed to practical logic) in language; linguistics has not improved the learning of foreign languages; thought is essentially independent of language but is in practice corrupted by it; etc. But if Pullum has real courage he will seek a much wider forum than this journal, a forum where he should discuss these matters without being assured of the sympathy of virtually all his &apos;insider&apos; readers as he can be here. If he can persuade a more general journal, or a newspaper, to publish his opinions on these matters (and to explain to use why computational linguistics is important), I shall be happy to respond. It might also induce both of us to be a little more temperate.</abstract>
<affiliation confidence="0.507237">Amorey Gethin</affiliation>
<address confidence="0.989401">Cambridge, England</address>
<abstract confidence="0.995777471544715">is Structures It is not clear how useful it is to reply to Yorick Wilks&apos;s dismissive review of my Structures (SS) (Computational Linguistics March 1992). Nevertheless, I attempt to say how I think Wilks has misconstrued the Wilks describes SS as &amp;quot;a large project to construct semantic or conceptual expressions of word meaning on which inference can be done.&amp;quot; A substantial part of his criticism flows from the book&apos;s failing to meet this description in a way that satisfies him (about which more in a moment). But constructing formalized semantic expressions for words is only one of the goals of the book. The general goal is &amp;quot;the characterization of the mental resources that make possible human knowledge and experience of the world&amp;quot; (p. 8). More precisely, &amp;quot;What are the innate units and principles of organization that make human lexical and sentential concepts both possible in all their variety and also learnable on the basis of some realistic combination of linguistic and nonlinguistic experience?&amp;quot; (p. 11). In addition to conceptual structures being an interface between language and inference, they can be compared with &amp;quot;conceptual structures derived from sensory modalities&amp;quot; (p. 11). In short, I conceive of the inquiry as thoroughly psychological, and not just a technical work on &amp;quot;handcrafting lexical codings,&amp;quot; as Wilks puts it. SS itself spends only one chapter on philosophical and psychological foundations before moving on to technical details of formulating the relation between lexical structure, syntactic structure, and conceptual structure. As the text makes clear, the reason for this is that I have written two previous books dealing in much more detail with and psychological foundations: and Cognition MA: MIT Press, 1983) and and the Computational Mind MA: The MIT Press, 1987). The first chapter of SS is a precis of the positions developed and defended in this previous work. One of Wilks&apos;s main complaints about SS is that it does not make sufficient mention of the AT and CL literature on lexical and conceptual semantics. Indeed, he insinuates 240 Letters to the Editor that if I had paid attention to this literature, I would have seen that my approach was pointless, since everyone in AT and CL gave it up long ago. I have two responses to this criticism. The first is that life is short, and one has to choose what to read out of an inexhaustible literature in many fields. One is always at one&apos;s peril at having missed something important. If I have missed something important, I am ready to accept responsibility for it and try to do better next time.&apos; This work merited citation in the section on aspectual structure on p. 28, and I apologize to James for the omission. On the other hand, I did read a fair amount of the AT and CL literature during the seventies and early eighties, when it appeared to be similar what I was doing; there are not a few references to this literature in and However, I felt at the time that the empirical justifications of most AI-CL work were insufficient: it was too often difficult to say why one particular solution was better than any other, and which decisions about representation were being made on a principled basis. I therefore decided that, while the AI-CL tradition might produce interesting simulations of limited aspects of language understanding, it was not going to teach me much about the overall nature of human language, and so I abandoned contact. (In a sense I feel vindicated by Wilks&apos;s saying that no one does this sort of anymore: he is telling I was right in thinking it wouldn&apos;t work.) SS, by contrast with much of the AI-CL tradition, attempts to justify every step of formalization and to distinguish between essential and inessential aspects of the formalism. It appeals to a wide range of linguistic data, not just the fixed given corpus of many Al implementations. Like other work in the linguistic tradition, it is deeply concerned with accounting for what does not happen—hence its preoccupation with constraining the theory so as to explain the ungrammaticality of sentences that are in principle plausible. Wilks, however, seems to project onto the book his own goals for linguistic analysis, and apparently does not recognize the difference in methodology as flowing from a different outlook. As a result, he sees nothing but a lot of effort spent on what seem to him insignificant details. But many of the seemingly insignificant details offer a great deal to our understanding of the organization of language. SS spends considerable effort showing how to simplify lexical entries of verbs and prepositions so as to account for the range of syntactic frames in which they can and cannot occur, as well as for the differences in meaning they carry in different frames. In addition, important classes of lexical items are unified. For example, causative verbs, treated in almost everyone&apos;s theory as expressing a conceptual primitive CAUSE, are shown to form a natural class along with verbs of helping, permitting, trying, resisting, and entailing. In the process of treating these relations formally, the alleged primitive CAUSE dissolves into a combination of more general predicates and features. Finally, three chapters of the book are devoted 1 Wilks takes me to task for not citing my Brandeis colleague James Pustejovsky; he refers to a book allegedly published in 1991 that actually was completed only at the end of 1991 and is still not published. In fact, the only work of Pustejovsky&apos;s that was in citable form in 1989, when SS was was his work on event structure, which finally achieved real publication in late 1991. 2 In particular, Wilks heaps scorn on my brief mention of &amp;quot;preference rules&amp;quot; in SS, citing the AI—CL as knowing better. However, as there is much more extensive discussion of rules in and Cognition, also in my book with Fred Lerdahl, Generative Theory Tonal Music MA: The MIT Press, 1983). observes (p. 284) that the conceptual indeterminacies expressed by preference rules &amp;quot;play a relatively minor role in the relation structure and syntax.... This is why the present work, concerned most directly with the syntax—semantics correspondence, has not made much reference to formal devices such as preference rules, graded conditions, and 3D model stereotypes.&amp;quot; 241 Computational Linguistics Volume 18, Number 2 analysis of syntactic adjuncts that carry thematic roles, such as the a cloth proves not to be an instrumental), four different varieties of and resultative predication, and the curious construction occurring in his way out of the restaurant. one&apos;s concerns are at the level of &amp;quot;handcrafting lexical entries,&amp;quot; these issues are perhaps not of great importance. But from the point of view of linguistics, these case studies establish important boundary conditions on the expressive capacity of human grammars; they show us the microstructure of language at a higher degree of resolution than was previously possible, a degree that was certainly not attained by the AI–CL approaches of the 1970s. Now, it is no surprise that the linguistic and computational enterprises should converge on certain basic elements of formalism. Everyone finds it convenient to use capitalized English words to stand for meanings of things they don&apos;t yet know how to formalize, e.g., IN, FOR, WITH, MOUTH, CAUSE. Everyone needs a means to express how characters play roles in events; constituent structure notation and functionargument notation are among the most natural ways to represent these relations. The fact that everyone uses these notations tends to mask the differences in goals to which the notations are being applied. However, what distinguishes one theory from another how one goes beyond these obvious points: when one a further decomposition of a word or a phrase (as happens frequently in SS, for example with causatives), what is it like? What is the repertoire of constituent types and function types out of which concepts are built? How are these mapped productively into linguistic expressions? If one is a theoretical linguist or psycholinguist, one may further ask: Is this repertoire psychologically and biologically plausible? Does it make learning possible for the child? And so forth. Alternatively, if one is a computational linguist, the goals may include questions such as: Can this theory be built into an operating computer program? Can it yield system of automatic concept construction text? And so There are two possible ways these latter goals might be related to the linguist&apos;s. First, the two sets of goals might be orthogonal, yielding different and unrelated solutions, in which case there is not too much point in paying attention to each other&apos;s work. Alternatively, it might just be that the best (or only) way to make a computer process and acquire language is essentially to do it the way people do it, In this case it makes sense for computational linguists not to treat the results of linguistic theory as &amp;quot;imaginary procedures&amp;quot; and &amp;quot;fantasy encodings&amp;quot; (to use Wilks&apos;s terms), but as a more careful approch to common problems. That doesn&apos;t mean linguists are always right—there are plenty of wheels being spun in linguistics, for sure—but the goals, results, and difficulties recognized by linguists maybe ought to get a little more respect. Under such conditions, when computational linguists are testing theories that linguists can regard as linguistically plausible, it is by all means worthwhile as well for linguists to reciprocate.</abstract>
<author confidence="0.969242">Ray Jackendoff</author>
<address confidence="0.774146">Brandeis University, Waltham, MA 02254-9110</address>
<abstract confidence="0.988820842105263">I wish to reply to Vitale&apos;s recent article in CL 17:3, which describes the fairly wellestablished method of name pronunciation that is currently used in a number of speech synthesizers including the ones at DEC, Bellcore, and AT&amp;T Bell Laboratories. It is entirely clear why it would be appropriate to discuss this topic in that the method has been fairly well-established for many years. 242 Letters to the Editor Nevertheless on page 259, Vitale suggests that the discussion is appropriate because previous researchers have failed to disclose the details of the method: &amp;quot;It should be stressed that there have been other attempts to implement similar algorithms, although few descriptions of such implementations are available.&amp;quot; It seems to me that there are plenty of adequate descriptions in the literature including Church (1985, p. 252). I believe that this description is more than adequate for someone skilled in the art as evidenced by the fact that it has since been replicated in several different places, and has been described in at least one review article on speech synthesis (Klatt 1987, p. 773). In fact, the details of the method have been fully disclosed in sufficient detail to satisfy the United States Patent Office (Church 1989). In short, I don&apos;t know what more I could have done to disclose the details of my work.</abstract>
<author confidence="0.996555">Ken Church</author>
<affiliation confidence="0.997018">AT&amp;T Bell Laboratories</affiliation>
<note confidence="0.91776025">References Church, K. (1985). &amp;quot;Stress assignment in letter to sound rules for speech synthesis,&amp;quot; Association for Computational Linguistics. D. (1987). &amp;quot;Review of test-to-speech conversion for English,&amp;quot; I. Soc. Am. 737-793. Church, K. (1989). &amp;quot;Text analysis system with letter sequence recognition and speech stress assignment arrangement,&amp;quot; United States Patent 4,829,580. 243</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>K Church</author>
</authors>
<title>Stress assignment in letter to sound rules for speech synthesis,&amp;quot; Association for Computational Linguistics.</title>
<date>1985</date>
<marker>Church, 1985</marker>
<rawString>Church, K. (1985). &amp;quot;Stress assignment in letter to sound rules for speech synthesis,&amp;quot; Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Klatt</author>
</authors>
<title>Review of test-to-speech conversion for English,&amp;quot;</title>
<date>1987</date>
<journal>I. Acoust. Soc. Am.</journal>
<volume>82</volume>
<issue>3</issue>
<pages>737--793</pages>
<marker>Klatt, 1987</marker>
<rawString>Klatt, D. (1987). &amp;quot;Review of test-to-speech conversion for English,&amp;quot; I. Acoust. Soc. Am. 82(3), 737-793.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Church</author>
</authors>
<title>Text analysis system with letter sequence recognition and speech stress assignment arrangement,&amp;quot; United States Patent 4,829,580.</title>
<date>1989</date>
<marker>Church, 1989</marker>
<rawString>Church, K. (1989). &amp;quot;Text analysis system with letter sequence recognition and speech stress assignment arrangement,&amp;quot; United States Patent 4,829,580.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>