<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.039264">
<title confidence="0.990933">
Exploration of Term Dependence in Sentence Retrieval
</title>
<author confidence="0.997615">
Keke Cai, Jiajun Bu, Chun Chen, Kangmiao Liu
</author>
<affiliation confidence="0.8465725">
College of Computer Science, Zhejiang University
Hangzhou, 310027, China
</affiliation>
<email confidence="0.997065">
{caikeke,bjj,chenc,lkm}@zju.edu.cn
</email>
<sectionHeader confidence="0.995621" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999889846153846">
This paper focuses on the exploration of
term dependence in the application of
sentence retrieval. The adjacent terms ap-
pearing in query are assumed to be related
with each other. These assumed depend-
ences among query terms will be further
validated for each sentence and sentences,
which present strong syntactic relation-
ship among query terms, are considered
more relevant. Experimental results have
fully demonstrated the promising of the
proposed models in improving sentence
retrieval effectiveness.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999932368421053">
Sentence retrieval is to retrieve sentences in re-
sponse to certain requirements. It has been widely
applied in many tasks, such as passage retrieval
(Salton et al, 1994), document summarization
(Daumé and Marcu, 2006), question answering
(Li, 2003) and novelty detection (Li and Croft
2005). A lot of different approaches have been
proposed for this service, but most of them are
based on term matching. Compared with docu-
ment, sentence always consists of fewer terms.
Limited information contained in sentence makes
it quite difficult to implement such term based
matching approaches.
Term dependence, which means that the pres-
ence or absence of one set of terms provides in-
formation about the probabilities of the presence
or absence of another set of terms, has been
widely accepted in recent studies of information
retrieval. Taking into account the limited infor-
</bodyText>
<page confidence="0.993514">
97
</page>
<bodyText confidence="0.998978346153846">
mation about term distribution in sentence, the
necessary of incorporating term dependence into
sentence retrieval is clear.
Two kinds of dependence can be considered in
the service of sentence retrieval. The first one
occurs among query or sentence terms and an-
other one occurs between query and sentence
terms. This paper mainly focuses on the first kind
of dependence and correspondingly proposes a
new sentence retrieval model (TDSR). In general,
TDSR model can be achieved through the follow-
ing two steps:
The first step is to simulate the dependences
among query terms and then represent query as a
set of term combinations, terms of each of which
are considered to be dependent with each other.
The second step is to measure the relevance of
each sentence by considering the syntactic rela-
tionship of terms in each term combination
formed above and then sort sentences according
to their relevance to the given query.
The remainder is structured as follows: Section
2 introduces some related studies. Section 3 de-
scribes the proposed sentence retrieval model. In
Section 4, the experimental results are presented
and section 5 concludes the paper.
</bodyText>
<sectionHeader confidence="0.999361" genericHeader="introduction">
2 Related Works
</sectionHeader>
<bodyText confidence="0.99269028125">
Sentence retrieval is always treated as a special
type of document retrieval (Larkey et al, 2002;
Schiffman, 2002; Zhang et al, 2003). Weight
function, such as tfidf algorithm, is used to con-
struct the weighted term vectors of query and
sentence. Similarity of these two vectors is then
used as the evidence of sentence relevance. In
fact, document retrieval differs from sentence
retrieval in many ways. Thus, traditional docu-
Proceedings of the ACL 2007 Demo and Poster Sessions, pages 97–100,
Prague, June 2007. c�2007 Association for Computational Linguistics
ment retrieval approaches, when implemented in
the service of sentence retrieval, cannot achieve
the expected retrieval performance.
Some systems try to utilize linguistic or other
features of sentences to facilitate the detection of
sentence relevance. In the study of White (2005),
factors used for ranking sentences include the
position of sentence in the source document, the
words contained in sentence and the number of
query terms contained in sentence. In another
study (Collins-Thompson et al., 2002), semantic
and lexical features are extracted from the initial
retrieved sentences to filter out possible non-
relevant sentences. Li and Croft (2005) chooses
to describe a query by patterns that include both
query words and required answer types. These
patterns are then used to retrieve sentences.
Term dependence also has been tried in some
sentence retrieval models. Most of these ap-
proaches realize it by referring to query expan-
sion or relevance feedback. Terms that are se-
mantically equivalent to the query terms or co-
occurred with the query terms frequently can be
selected as expanded terms (Schiffman, 2002).
Moreover, query also can be expanded by using
concept groups (Ohgaya et al., 2003). Sentences
are then ranked by the cosine similarity between
the expanded query vector and sentence vector.
In (Zhang et al., 2003), blind relevance feedback
and automatic sentence categorization based
Support Vector Machine (SVM) are combined
together to finish the task of sentence retrieval. In
recent study, a translation model is proposed for
monolingual sentence retrieval (Murdock and
Croft, 2005). The basic idea is to use explicit re-
lationships between terms to evaluate the transla-
tion probability between query and sentence. Al-
though the translation makes an effective utiliza-
tion of term relationships in the service of sen-
tence retrieval, the most difficulty is how to con-
struct the parallel corpus used for term translation.
Studies above have shown the positive effects
of term dependence on sentence retrieval. How-
ever, it is considered that for the special task of
sentence retrieval the potentialities of term de-
pendence have not been fully explored. Sentence,
being an integrated information unit, always has
special syntactic structure. This kind of informa-
tion is considered quite important to sentence
relevance. How to incorporate this kind of infor-
mation with information about dependences in
query to realize the most efficient sentence re-
trieval is the main objective of this paper.
</bodyText>
<sectionHeader confidence="0.998319" genericHeader="method">
3 TDSR Model
</sectionHeader>
<bodyText confidence="0.999996333333333">
As discussed above, the implementation of TDSR
model consists of two steps. The following will
give the detail description of each step.
</bodyText>
<subsectionHeader confidence="0.999319">
3.1 Term Dependences in Query
</subsectionHeader>
<bodyText confidence="0.999913333333333">
Past studies have shown the importance of de-
pendences among query terms and different ap-
proaches have been proposed to define the styles
of term dependence in query. In this paper, the
assumption of term dependence starts by consid-
ering the possible syntactic relationships of terms.
For that the syntactic relationships can happen
among any set of query terms, hence the assump-
tion of dependence occurring among any query
terms is considered more reasonable.
The dependences among all query terms will
be defined in this paper. Based on this definition,
the given query Q can be represented as: Q =
{TS1, TS2, ..., TSn}, each item of which contains
one or more query terms. These assumed depend-
ences will be further evaluated in each retrieved
sentence and then used to define the relevance of
sentence
</bodyText>
<subsectionHeader confidence="0.999764">
3.2 Identification of Sentence Relevance
</subsectionHeader>
<bodyText confidence="0.999978523809524">
Term dependences defined above provide struc-
ture basis for sentence relevance estimate. How-
ever, their effects to sentence relevance identifi-
cation are finally decided by the definition of sen-
tence feature function. Sentence feature function
is used to estimate the importance of the esti-
mated dependences and then decides the rele-
vance of each retrieved sentence.
In this paper, feature function is defined from
the perspective of syntactic relationship of terms
in sentence. The specific dependency grammar is
used to describe such relationship in the form of
dependency parse tree. A dependency syntactic
relationship is an asymmetric relationship be-
tween a word called governor and another word
called modifier. In this paper, MINIPAR is
adopted as the dependency parser. An example of
a dependency parse tree parsed by MINIPAR is
shown in Figure 1, in which nodes are labeled by
part of speeches and edges are labeled by relation
types.
</bodyText>
<page confidence="0.973331">
98
</page>
<figureCaption confidence="0.986063">
Figure 1. Dependency parse tree of sentence “Ev-
erest is the highest mountain”.
</figureCaption>
<bodyText confidence="0.999944882352941">
As we know, terms within a sentence can be
described by certain syntactic relationship (direct
or indirect). Moreover, different syntactic rela-
tionships describe different degrees of associa-
tions. Given a query, the relevance of each sen-
tence is considered different if query terms pre-
sent different forms of syntactic relationships.
This paper makes an investigation of syntactic
relationships among terms and then proposes a
novel feature function.
To evaluate the syntactic relationship of terms,
the concept of association strength should be de-
fined to each TSi EQ with respect to each sen-
tence S. It describes the association of terms in
TSi. The more closely they are related, the higher
the value is. In this paper, the association strength
of TSi is valued from two aspects:
</bodyText>
<listItem confidence="0.9089942">
• Size of TSi. Sentences containing more
query terms are considered more relevant.
• Distance of TSi. In the context of depend-
ency parse tree, the link between two terms
means their direct syntactic relationship. For
</listItem>
<bodyText confidence="0.9263238">
terms with no direct linkage, their syntactic rela-
tionship can be described by the path between
their corresponding nodes in tree. For example, in
Figure 1 the syntactic relationship between terms
“Everest” and “mountain” can be described by
the path:
This paper uses term distance to evaluate terms
syntactic relationship. Given two terms A and B,
their distance distance(A, B) is defined as the
number of linkages between A and B with no
consideration of direction. Furthermore, for the
term set C, their distance is defined as:
where N is the number of term pairs of C.
Given the term set TSi, the association strength
of TSi in sentence S is defined as:
</bodyText>
<equation confidence="0.9982495">
1
AS(TSi,S) = α S(TSi) * fl D(TSi) (2)
</equation>
<bodyText confidence="0.999695">
where S(TSi) is the size of term set TSi and pa-
rameters α and β are valued between 0 and 1 and
used to control the influence of each component
on the computation of AS(TSi).
Based on the definition of association strength,
the feature function of S can be further defined as:
</bodyText>
<equation confidence="0.963028">
) (3)
</equation>
<bodyText confidence="0.992520333333333">
Taking the maximum association strength to
evaluate sentence relevance conforms to the Dis-
junctive Relevance Decision principle (Kong et
al., 2004). Based on the feature function defined
above, sentences can be finally ranked according
to the obtained maximum association strength.
</bodyText>
<sectionHeader confidence="0.999736" genericHeader="evaluation">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999814684210526">
In this paper, the proposed method is evaluated
on the data collection used in TREC novelty track
2003 and 2004 with the topics N1-N50 and N51-
N100. Only the title portion of these TREC topics
is considered.
To measure the performance of the suggested
retrieval model, three traditional sentence re-
trieval models are also performed, i.e., TFIDF
model (TFIDF), Okapi model (OKAPI) and KL-
divergence model with Dirichlet smoothing
(KLD). The result of TFIDF provides the base-
line from which to compare other retrieval mod-
els.
Table 1 shows the non-interpolated average
precision of each different retrieval models. The
value in parentheses is the improvement over the
baseline method. As shown in the table, TDSR
model outperforms TFIDF model obviously. The
improvements are respectively 15.3% and 10.2%.
</bodyText>
<table confidence="0.9918234">
N1-N50 N51-N100
TFIDF 0.308 0.215
OKAPI 0.239 (-22.4) 0.165 (-23.3%)
KLD 0.281 (-8.8) 0.204 (-5.1%)
TDSR 0.355 (15.3%) 0.237 (10.2%)
</table>
<tableCaption confidence="0.9954335">
Table 1. Average precision of each different re-
trieval models
</tableCaption>
<figure confidence="0.830884222222222">
subj
Everest (N) mountain (N)
Everest (N)
s pred
Be (VBE)
the (Det) highest (A)
det mod
s pred
Everest Be mountain
D(C)= 1N* Y_distance(qi,qj
j
C
girq
E
) (1)
F(S, Q) max AS ( TS i , S
=
TSiEQ
</figure>
<page confidence="0.985238">
99
</page>
<bodyText confidence="0.9908425">
Figure 2 and Figure 3 further depict the preci-
sion recall curve of each retrieval model when
implemented on different query sets. The im-
provements of the proposed retrieval model indi-
cated in these figures are clear. TDSR outper-
forms other retrieval models at any recall point.
</bodyText>
<figureCaption confidence="0.9972665">
Figure 2. Precision-Recall Curve of Each Re-
trieval Model (N1-N50)
Figure 3. Precision-Recall Curve of Each Re-
trieval Model (N51-N100)
</figureCaption>
<sectionHeader confidence="0.99911" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999949444444444">
This paper presents a novel approach for sentence
retrieval. Given a sentence, its relevance is meas-
ured by the degree of its support to the depend-
ences between query terms. Term dependence,
which has been widely considered in the studies
of document retrieval, is the basis of this retrieval
model. Experimental results show the promising
of the proposed models in improving sentence
retrieval performance.
</bodyText>
<sectionHeader confidence="0.998959" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.996707929824561">
Barry Schiffman. 2002. Experiments in Novelty De-
tection at Columbia University. In Proceedings of
the 11th Text REtrieval Conference, pages 188-196.
Gerard Salton, James Allan, and Chris Buckley. 1994.
Automatic structuring and retrieval of large text
files. Communication of the ACM, 37(2): 97-108.
Hal Daumé III and Daniel Marcu. 2006. Bayesian
query-focused summarization. In Proceedings of
the 21st International Conference on Computa-
tional Linguistics and the 44th annual meeting of
the ACL, pages 305-312, Sydney, Australia.
Kevyn Collins-Thompson, Paul Ogilvie, Yi Zhang,
and Jamie Callan. 2002. Information filtering, Nov-
elty detection, and named-page finding. In Proceed-
ings of the 11th Text REtrieval Conference, Na-
tional Institute of Standards and Technology.
Leah S. Larkey, James Allan, Margaret E. Connell,
Alvaro Bolivar, and Courtney Wade. 2002. UMass
at TREC 2002: Cross Language and Novelty
Tracks. In Proceeding of the Eleventh Text Re-
trieval Conference, pages 721–732, Gaithersburg,
Maryland.
Min Zhang, Chuan Lin, Yiqun Liu, Le Zhao, Liang
Ma, and Shaoping Ma. 2003. THUIR at TREC
2003: Novelty, Robust, Web and HARD. In Pro-
ceedings of 12th Text Retrieval Conference, pages
137-148.
Ryen W. White, Joemon M. Jose, and Ian Ruthven.
2005. Using top-ranking sentences to facilitate ef-
fective information access. Journal of the American
Society for Information Science and Technology,
56(10): 1113-1125.
Ryosuke Ohgaya, Akiyoshi Shimmura, Tomohiro Ta-
kagi, and Akiko N. Aizawa. 2003. Meiji University
web and novelty track experiments at TREC 2003.
In Proceedings of the Twelfth Text Retrieval Con-
ference.
Vanessa Murdock and W. Bruce Croft. 2005. A trans-
lation Model for Sentence retrieval. HLT/EMNLP.
In Proceedings of the Conference on Human Lan-
guage Technologies and Empirical Methods in
Natural Language Processing, pages 684-691.
Xiaoyan Li. 2003. Syntactic Features in Question An-
swering. In Proceedings of the 26th Annual Inter-
national ACM SIGIR Conference on Research and
Development in Information Retrieval, pages 455-
456, Toronto, Canada.
Xiaoyan Li and W. Bruce Croft. 2005. Novelty detec-
tion based on sentence level patterns. In Proceed-
ings of ACM Fourteenth Conference on Information
and Knowledge Management (CIKM), pages 744-
751, Bremen, Germany.
Y.K. Kong, R.W.P. Luk, W. Lam, K.S. Ho and F.L.
Chung. 2004. Passage-based retrieval based on pa-
rameterized fuzzy operators, ACM SIGIR Workshop
on Mathematical/Formal Methods for Information
Retrieval.
</reference>
<figure confidence="0.999865692307692">
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
Recall
1
0.8
TFIDF
OKAPI
KL
TDSR
Precision
0.6
0.4
0.2
0
1
0.8
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
Recall
TFIDF
OKAPI
KL
TDSR
Precision
0.6
0.4
0.2
0
</figure>
<page confidence="0.65041">
100
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.899812">
<title confidence="0.969795">Exploration of Term Dependence in Sentence Retrieval</title>
<author confidence="0.944185">Keke Cai</author>
<author confidence="0.944185">Jiajun Bu</author>
<author confidence="0.944185">Chun Chen</author>
<author confidence="0.944185">Kangmiao Liu</author>
<affiliation confidence="0.999984">College of Computer Science, Zhejiang University</affiliation>
<address confidence="0.999928">Hangzhou, 310027, China</address>
<email confidence="0.987666">caikeke@zju.edu.cn</email>
<email confidence="0.987666">bjj@zju.edu.cn</email>
<email confidence="0.987666">chenc@zju.edu.cn</email>
<email confidence="0.987666">lkm@zju.edu.cn</email>
<abstract confidence="0.997875785714285">This paper focuses on the exploration of term dependence in the application of sentence retrieval. The adjacent terms appearing in query are assumed to be related with each other. These assumed dependences among query terms will be further validated for each sentence and sentences, which present strong syntactic relationship among query terms, are considered more relevant. Experimental results have fully demonstrated the promising of the proposed models in improving sentence retrieval effectiveness.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Barry Schiffman</author>
</authors>
<title>Experiments in Novelty Detection at Columbia University.</title>
<date>2002</date>
<booktitle>In Proceedings of the 11th Text REtrieval Conference,</booktitle>
<pages>188--196</pages>
<contexts>
<context position="2889" citStr="Schiffman, 2002" startWordPosition="448" endWordPosition="449">to be dependent with each other. The second step is to measure the relevance of each sentence by considering the syntactic relationship of terms in each term combination formed above and then sort sentences according to their relevance to the given query. The remainder is structured as follows: Section 2 introduces some related studies. Section 3 describes the proposed sentence retrieval model. In Section 4, the experimental results are presented and section 5 concludes the paper. 2 Related Works Sentence retrieval is always treated as a special type of document retrieval (Larkey et al, 2002; Schiffman, 2002; Zhang et al, 2003). Weight function, such as tfidf algorithm, is used to construct the weighted term vectors of query and sentence. Similarity of these two vectors is then used as the evidence of sentence relevance. In fact, document retrieval differs from sentence retrieval in many ways. Thus, traditional docuProceedings of the ACL 2007 Demo and Poster Sessions, pages 97–100, Prague, June 2007. c�2007 Association for Computational Linguistics ment retrieval approaches, when implemented in the service of sentence retrieval, cannot achieve the expected retrieval performance. Some systems try </context>
<context position="4463" citStr="Schiffman, 2002" startWordPosition="693" endWordPosition="694">), semantic and lexical features are extracted from the initial retrieved sentences to filter out possible nonrelevant sentences. Li and Croft (2005) chooses to describe a query by patterns that include both query words and required answer types. These patterns are then used to retrieve sentences. Term dependence also has been tried in some sentence retrieval models. Most of these approaches realize it by referring to query expansion or relevance feedback. Terms that are semantically equivalent to the query terms or cooccurred with the query terms frequently can be selected as expanded terms (Schiffman, 2002). Moreover, query also can be expanded by using concept groups (Ohgaya et al., 2003). Sentences are then ranked by the cosine similarity between the expanded query vector and sentence vector. In (Zhang et al., 2003), blind relevance feedback and automatic sentence categorization based Support Vector Machine (SVM) are combined together to finish the task of sentence retrieval. In recent study, a translation model is proposed for monolingual sentence retrieval (Murdock and Croft, 2005). The basic idea is to use explicit relationships between terms to evaluate the translation probability between </context>
</contexts>
<marker>Schiffman, 2002</marker>
<rawString>Barry Schiffman. 2002. Experiments in Novelty Detection at Columbia University. In Proceedings of the 11th Text REtrieval Conference, pages 188-196.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerard Salton</author>
<author>James Allan</author>
<author>Chris Buckley</author>
</authors>
<title>Automatic structuring and retrieval of large text files.</title>
<date>1994</date>
<journal>Communication of the ACM,</journal>
<volume>37</volume>
<issue>2</issue>
<pages>97--108</pages>
<contexts>
<context position="904" citStr="Salton et al, 1994" startWordPosition="127" endWordPosition="130">ation of sentence retrieval. The adjacent terms appearing in query are assumed to be related with each other. These assumed dependences among query terms will be further validated for each sentence and sentences, which present strong syntactic relationship among query terms, are considered more relevant. Experimental results have fully demonstrated the promising of the proposed models in improving sentence retrieval effectiveness. 1 Introduction Sentence retrieval is to retrieve sentences in response to certain requirements. It has been widely applied in many tasks, such as passage retrieval (Salton et al, 1994), document summarization (Daumé and Marcu, 2006), question answering (Li, 2003) and novelty detection (Li and Croft 2005). A lot of different approaches have been proposed for this service, but most of them are based on term matching. Compared with document, sentence always consists of fewer terms. Limited information contained in sentence makes it quite difficult to implement such term based matching approaches. Term dependence, which means that the presence or absence of one set of terms provides information about the probabilities of the presence or absence of another set of terms, has been</context>
</contexts>
<marker>Salton, Allan, Buckley, 1994</marker>
<rawString>Gerard Salton, James Allan, and Chris Buckley. 1994. Automatic structuring and retrieval of large text files. Communication of the ACM, 37(2): 97-108.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hal Daumé</author>
<author>Daniel Marcu</author>
</authors>
<title>Bayesian query-focused summarization.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the ACL,</booktitle>
<pages>305--312</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="952" citStr="Daumé and Marcu, 2006" startWordPosition="133" endWordPosition="136">ms appearing in query are assumed to be related with each other. These assumed dependences among query terms will be further validated for each sentence and sentences, which present strong syntactic relationship among query terms, are considered more relevant. Experimental results have fully demonstrated the promising of the proposed models in improving sentence retrieval effectiveness. 1 Introduction Sentence retrieval is to retrieve sentences in response to certain requirements. It has been widely applied in many tasks, such as passage retrieval (Salton et al, 1994), document summarization (Daumé and Marcu, 2006), question answering (Li, 2003) and novelty detection (Li and Croft 2005). A lot of different approaches have been proposed for this service, but most of them are based on term matching. Compared with document, sentence always consists of fewer terms. Limited information contained in sentence makes it quite difficult to implement such term based matching approaches. Term dependence, which means that the presence or absence of one set of terms provides information about the probabilities of the presence or absence of another set of terms, has been widely accepted in recent studies of informatio</context>
</contexts>
<marker>Daumé, Marcu, 2006</marker>
<rawString>Hal Daumé III and Daniel Marcu. 2006. Bayesian query-focused summarization. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the ACL, pages 305-312, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevyn Collins-Thompson</author>
<author>Paul Ogilvie</author>
<author>Yi Zhang</author>
<author>Jamie Callan</author>
</authors>
<title>Information filtering, Novelty detection, and named-page finding.</title>
<date>2002</date>
<booktitle>In Proceedings of the 11th Text REtrieval Conference, National Institute of Standards and Technology.</booktitle>
<contexts>
<context position="3848" citStr="Collins-Thompson et al., 2002" startWordPosition="592" endWordPosition="595">the ACL 2007 Demo and Poster Sessions, pages 97–100, Prague, June 2007. c�2007 Association for Computational Linguistics ment retrieval approaches, when implemented in the service of sentence retrieval, cannot achieve the expected retrieval performance. Some systems try to utilize linguistic or other features of sentences to facilitate the detection of sentence relevance. In the study of White (2005), factors used for ranking sentences include the position of sentence in the source document, the words contained in sentence and the number of query terms contained in sentence. In another study (Collins-Thompson et al., 2002), semantic and lexical features are extracted from the initial retrieved sentences to filter out possible nonrelevant sentences. Li and Croft (2005) chooses to describe a query by patterns that include both query words and required answer types. These patterns are then used to retrieve sentences. Term dependence also has been tried in some sentence retrieval models. Most of these approaches realize it by referring to query expansion or relevance feedback. Terms that are semantically equivalent to the query terms or cooccurred with the query terms frequently can be selected as expanded terms (S</context>
</contexts>
<marker>Collins-Thompson, Ogilvie, Zhang, Callan, 2002</marker>
<rawString>Kevyn Collins-Thompson, Paul Ogilvie, Yi Zhang, and Jamie Callan. 2002. Information filtering, Novelty detection, and named-page finding. In Proceedings of the 11th Text REtrieval Conference, National Institute of Standards and Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leah S Larkey</author>
<author>James Allan</author>
<author>Margaret E Connell</author>
<author>Alvaro Bolivar</author>
<author>Courtney Wade</author>
</authors>
<title>UMass at TREC 2002: Cross Language and Novelty Tracks.</title>
<date>2002</date>
<booktitle>In Proceeding of the Eleventh Text Retrieval Conference,</booktitle>
<pages>721--732</pages>
<location>Gaithersburg, Maryland.</location>
<contexts>
<context position="2872" citStr="Larkey et al, 2002" startWordPosition="444" endWordPosition="447">hich are considered to be dependent with each other. The second step is to measure the relevance of each sentence by considering the syntactic relationship of terms in each term combination formed above and then sort sentences according to their relevance to the given query. The remainder is structured as follows: Section 2 introduces some related studies. Section 3 describes the proposed sentence retrieval model. In Section 4, the experimental results are presented and section 5 concludes the paper. 2 Related Works Sentence retrieval is always treated as a special type of document retrieval (Larkey et al, 2002; Schiffman, 2002; Zhang et al, 2003). Weight function, such as tfidf algorithm, is used to construct the weighted term vectors of query and sentence. Similarity of these two vectors is then used as the evidence of sentence relevance. In fact, document retrieval differs from sentence retrieval in many ways. Thus, traditional docuProceedings of the ACL 2007 Demo and Poster Sessions, pages 97–100, Prague, June 2007. c�2007 Association for Computational Linguistics ment retrieval approaches, when implemented in the service of sentence retrieval, cannot achieve the expected retrieval performance. </context>
</contexts>
<marker>Larkey, Allan, Connell, Bolivar, Wade, 2002</marker>
<rawString>Leah S. Larkey, James Allan, Margaret E. Connell, Alvaro Bolivar, and Courtney Wade. 2002. UMass at TREC 2002: Cross Language and Novelty Tracks. In Proceeding of the Eleventh Text Retrieval Conference, pages 721–732, Gaithersburg, Maryland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Min Zhang</author>
<author>Chuan Lin</author>
<author>Yiqun Liu</author>
<author>Liang Ma Le Zhao</author>
<author>Shaoping Ma</author>
</authors>
<title>Novelty, Robust, Web and HARD.</title>
<date>2003</date>
<booktitle>In Proceedings of 12th Text Retrieval Conference,</booktitle>
<tech>THUIR at TREC</tech>
<pages>137--148</pages>
<marker>Zhang, Lin, Liu, Le Zhao, Ma, 2003</marker>
<rawString>Min Zhang, Chuan Lin, Yiqun Liu, Le Zhao, Liang Ma, and Shaoping Ma. 2003. THUIR at TREC 2003: Novelty, Robust, Web and HARD. In Proceedings of 12th Text Retrieval Conference, pages 137-148.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryen W White</author>
<author>Joemon M Jose</author>
<author>Ian Ruthven</author>
</authors>
<title>Using top-ranking sentences to facilitate effective information access.</title>
<date>2005</date>
<journal>Journal of the American Society for Information Science and Technology,</journal>
<volume>56</volume>
<issue>10</issue>
<pages>1113--1125</pages>
<marker>White, Jose, Ruthven, 2005</marker>
<rawString>Ryen W. White, Joemon M. Jose, and Ian Ruthven. 2005. Using top-ranking sentences to facilitate effective information access. Journal of the American Society for Information Science and Technology, 56(10): 1113-1125.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryosuke Ohgaya</author>
<author>Akiyoshi Shimmura</author>
<author>Tomohiro Takagi</author>
<author>Akiko N Aizawa</author>
</authors>
<title>Meiji University web and novelty track experiments at TREC</title>
<date>2003</date>
<booktitle>In Proceedings of the Twelfth Text Retrieval Conference.</booktitle>
<contexts>
<context position="4547" citStr="Ohgaya et al., 2003" startWordPosition="705" endWordPosition="708">ces to filter out possible nonrelevant sentences. Li and Croft (2005) chooses to describe a query by patterns that include both query words and required answer types. These patterns are then used to retrieve sentences. Term dependence also has been tried in some sentence retrieval models. Most of these approaches realize it by referring to query expansion or relevance feedback. Terms that are semantically equivalent to the query terms or cooccurred with the query terms frequently can be selected as expanded terms (Schiffman, 2002). Moreover, query also can be expanded by using concept groups (Ohgaya et al., 2003). Sentences are then ranked by the cosine similarity between the expanded query vector and sentence vector. In (Zhang et al., 2003), blind relevance feedback and automatic sentence categorization based Support Vector Machine (SVM) are combined together to finish the task of sentence retrieval. In recent study, a translation model is proposed for monolingual sentence retrieval (Murdock and Croft, 2005). The basic idea is to use explicit relationships between terms to evaluate the translation probability between query and sentence. Although the translation makes an effective utilization of term </context>
</contexts>
<marker>Ohgaya, Shimmura, Takagi, Aizawa, 2003</marker>
<rawString>Ryosuke Ohgaya, Akiyoshi Shimmura, Tomohiro Takagi, and Akiko N. Aizawa. 2003. Meiji University web and novelty track experiments at TREC 2003. In Proceedings of the Twelfth Text Retrieval Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vanessa Murdock</author>
<author>W Bruce Croft</author>
</authors>
<title>A translation Model for Sentence retrieval. HLT/EMNLP.</title>
<date>2005</date>
<booktitle>In Proceedings of the Conference on Human Language Technologies and Empirical Methods in Natural Language Processing,</booktitle>
<pages>684--691</pages>
<contexts>
<context position="4951" citStr="Murdock and Croft, 2005" startWordPosition="764" endWordPosition="767">ntically equivalent to the query terms or cooccurred with the query terms frequently can be selected as expanded terms (Schiffman, 2002). Moreover, query also can be expanded by using concept groups (Ohgaya et al., 2003). Sentences are then ranked by the cosine similarity between the expanded query vector and sentence vector. In (Zhang et al., 2003), blind relevance feedback and automatic sentence categorization based Support Vector Machine (SVM) are combined together to finish the task of sentence retrieval. In recent study, a translation model is proposed for monolingual sentence retrieval (Murdock and Croft, 2005). The basic idea is to use explicit relationships between terms to evaluate the translation probability between query and sentence. Although the translation makes an effective utilization of term relationships in the service of sentence retrieval, the most difficulty is how to construct the parallel corpus used for term translation. Studies above have shown the positive effects of term dependence on sentence retrieval. However, it is considered that for the special task of sentence retrieval the potentialities of term dependence have not been fully explored. Sentence, being an integrated infor</context>
</contexts>
<marker>Murdock, Croft, 2005</marker>
<rawString>Vanessa Murdock and W. Bruce Croft. 2005. A translation Model for Sentence retrieval. HLT/EMNLP. In Proceedings of the Conference on Human Language Technologies and Empirical Methods in Natural Language Processing, pages 684-691.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaoyan Li</author>
</authors>
<title>Syntactic Features in Question Answering.</title>
<date>2003</date>
<booktitle>In Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,</booktitle>
<pages>455--456</pages>
<location>Toronto, Canada.</location>
<contexts>
<context position="983" citStr="Li, 2003" startWordPosition="139" endWordPosition="140">ted with each other. These assumed dependences among query terms will be further validated for each sentence and sentences, which present strong syntactic relationship among query terms, are considered more relevant. Experimental results have fully demonstrated the promising of the proposed models in improving sentence retrieval effectiveness. 1 Introduction Sentence retrieval is to retrieve sentences in response to certain requirements. It has been widely applied in many tasks, such as passage retrieval (Salton et al, 1994), document summarization (Daumé and Marcu, 2006), question answering (Li, 2003) and novelty detection (Li and Croft 2005). A lot of different approaches have been proposed for this service, but most of them are based on term matching. Compared with document, sentence always consists of fewer terms. Limited information contained in sentence makes it quite difficult to implement such term based matching approaches. Term dependence, which means that the presence or absence of one set of terms provides information about the probabilities of the presence or absence of another set of terms, has been widely accepted in recent studies of information retrieval. Taking into accoun</context>
</contexts>
<marker>Li, 2003</marker>
<rawString>Xiaoyan Li. 2003. Syntactic Features in Question Answering. In Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 455-456, Toronto, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaoyan Li</author>
<author>W Bruce Croft</author>
</authors>
<title>Novelty detection based on sentence level patterns.</title>
<date>2005</date>
<booktitle>In Proceedings of ACM Fourteenth Conference on Information and Knowledge Management (CIKM),</booktitle>
<pages>744--751</pages>
<location>Bremen, Germany.</location>
<contexts>
<context position="1025" citStr="Li and Croft 2005" startWordPosition="144" endWordPosition="147">d dependences among query terms will be further validated for each sentence and sentences, which present strong syntactic relationship among query terms, are considered more relevant. Experimental results have fully demonstrated the promising of the proposed models in improving sentence retrieval effectiveness. 1 Introduction Sentence retrieval is to retrieve sentences in response to certain requirements. It has been widely applied in many tasks, such as passage retrieval (Salton et al, 1994), document summarization (Daumé and Marcu, 2006), question answering (Li, 2003) and novelty detection (Li and Croft 2005). A lot of different approaches have been proposed for this service, but most of them are based on term matching. Compared with document, sentence always consists of fewer terms. Limited information contained in sentence makes it quite difficult to implement such term based matching approaches. Term dependence, which means that the presence or absence of one set of terms provides information about the probabilities of the presence or absence of another set of terms, has been widely accepted in recent studies of information retrieval. Taking into account the limited infor97 mation about term di</context>
<context position="3996" citStr="Li and Croft (2005)" startWordPosition="614" endWordPosition="617">ented in the service of sentence retrieval, cannot achieve the expected retrieval performance. Some systems try to utilize linguistic or other features of sentences to facilitate the detection of sentence relevance. In the study of White (2005), factors used for ranking sentences include the position of sentence in the source document, the words contained in sentence and the number of query terms contained in sentence. In another study (Collins-Thompson et al., 2002), semantic and lexical features are extracted from the initial retrieved sentences to filter out possible nonrelevant sentences. Li and Croft (2005) chooses to describe a query by patterns that include both query words and required answer types. These patterns are then used to retrieve sentences. Term dependence also has been tried in some sentence retrieval models. Most of these approaches realize it by referring to query expansion or relevance feedback. Terms that are semantically equivalent to the query terms or cooccurred with the query terms frequently can be selected as expanded terms (Schiffman, 2002). Moreover, query also can be expanded by using concept groups (Ohgaya et al., 2003). Sentences are then ranked by the cosine similar</context>
</contexts>
<marker>Li, Croft, 2005</marker>
<rawString>Xiaoyan Li and W. Bruce Croft. 2005. Novelty detection based on sentence level patterns. In Proceedings of ACM Fourteenth Conference on Information and Knowledge Management (CIKM), pages 744-751, Bremen, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y K Kong</author>
<author>R W P Luk</author>
<author>W Lam</author>
<author>K S Ho</author>
<author>F L Chung</author>
</authors>
<title>Passage-based retrieval based on parameterized fuzzy operators,</title>
<date>2004</date>
<booktitle>ACM SIGIR Workshop on Mathematical/Formal Methods for Information Retrieval.</booktitle>
<contexts>
<context position="10031" citStr="Kong et al., 2004" startWordPosition="1601" endWordPosition="1604">istance is defined as: where N is the number of term pairs of C. Given the term set TSi, the association strength of TSi in sentence S is defined as: 1 AS(TSi,S) = α S(TSi) * fl D(TSi) (2) where S(TSi) is the size of term set TSi and parameters α and β are valued between 0 and 1 and used to control the influence of each component on the computation of AS(TSi). Based on the definition of association strength, the feature function of S can be further defined as: ) (3) Taking the maximum association strength to evaluate sentence relevance conforms to the Disjunctive Relevance Decision principle (Kong et al., 2004). Based on the feature function defined above, sentences can be finally ranked according to the obtained maximum association strength. 4 Experiments In this paper, the proposed method is evaluated on the data collection used in TREC novelty track 2003 and 2004 with the topics N1-N50 and N51- N100. Only the title portion of these TREC topics is considered. To measure the performance of the suggested retrieval model, three traditional sentence retrieval models are also performed, i.e., TFIDF model (TFIDF), Okapi model (OKAPI) and KLdivergence model with Dirichlet smoothing (KLD). The result of T</context>
</contexts>
<marker>Kong, Luk, Lam, Ho, Chung, 2004</marker>
<rawString>Y.K. Kong, R.W.P. Luk, W. Lam, K.S. Ho and F.L. Chung. 2004. Passage-based retrieval based on parameterized fuzzy operators, ACM SIGIR Workshop on Mathematical/Formal Methods for Information Retrieval.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>