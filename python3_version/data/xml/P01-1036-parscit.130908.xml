<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000012">
<title confidence="0.915597">
Topic-focus and salience*
</title>
<author confidence="0.799764">
Eva Hajičova
</author>
<affiliation confidence="0.630412">
Faculty of Mathematics and Physics
Charles University
</affiliation>
<address confidence="0.592007">
Malostransk6 nam. 25
118 00 Praha, Czech Republic
</address>
<email confidence="0.992541">
hajicova@ufal.mff.cuni.cz
</email>
<note confidence="0.68711325">
Petr Sgall
Faculty of Mathematics and Physics
Charles University
Malostransk6 nam. 25
</note>
<address confidence="0.673102">
118 00 Praha, Czech Republic
</address>
<email confidence="0.995993">
sgall@ufal.mff.cuni.cz
</email>
<sectionHeader confidence="0.993049" genericHeader="abstract">
1 Objectives and Motivation
</sectionHeader>
<bodyText confidence="0.999960534883721">
Most of the current work on corpus annotation is
concentrated on morphemics, lexical semantics
and sentence structure. However, it becomes
more and more obvious that attention should and
can be also paid to phenomena that reflect the
links between a sentence and its context, i.e. the
discourse anchoring of utterances. If conceived
in this way, an annotated corpus can be used as a
resource for linguistic research not only within
the limits of the sentence, but also with regard to
discourse patterns. Thus, the applications of the
research to issues of information retrieval and
extraction may be made more effective; also
applications in new domains become feasible, be
it to serve for inner linguistic (and literary) aims,
such as text segmentation, specification of topics
of parts of a discourse, or for other disciplines.
These considerations have been a motivation
for the tectogrammatical (i.e. underlying, see
below) tagging done within the Prague
Dependency Treebank (PDT) to contain also
attributes concerning certain contextual features,
i.e. the contextual anchoring of word tokens and
their relationships to their coreferential
antecedents.
Along with this enrichment in the
intersentential aspect, we do not neglect to pay
attention to intrasentential issues, i.e. to sentence
structure, which displays its own features
oriented towards the contextual potential of the
sentence, namely its topic-focus articulation
(TFA).
In the present paper, we give first an outline
of the annotation scenario of the PDT (Section
2), concentrating then on the use of one of the
PDT attributes for the specification of the Topic
and the Focus (the &apos;information structure&apos;) of the
sentence (Section 3). In Section 4. we present
certain heuristics that partly are based on TFA
and that allow for the specification of the
degrees of salience in a discourse. The
application of these heuristics is illustrated in
Section 5.
</bodyText>
<sectionHeader confidence="0.9801395" genericHeader="keywords">
2 Outline of the Prague Dependency
Treebank
</sectionHeader>
<bodyText confidence="0.998376666666667">
The Prague Dependency Treebank (PDT) is
being built on the basis of the Czech National
Corpus (CNC), which grows rapidly in the range
of hundreds of millions of word occurrences in
journalistic and fiction texts. The PDT scenario
comprises three layers of annotation:
</bodyText>
<listItem confidence="0.974783444444444">
(i) the morphemic (POS) layer with about
2000 tags for the highly inflectional Czech
language; the whole CNC has been tagged by a
stochastic tagger (Haji6 and Hladka 1997;1998,
B6hmova and Haji6ova 1999, Hladka 2000)
with a success rate of 95%; the tagger is based
on a fully automatic morphemic analysis of
Czech (Haji6 in press);
(ii) a layer of &apos;analytic&apos; (&amp;quot;surface&amp;quot;) syntax
(see Haji6 1998): cca 100 000 Czech sentences,
i.e. samples of texts (each randomly chosen
sample consisting of 50 sentences of a coherent
text), taken from CNC, have been assigned
dependency tree structures; every word (as well
as every punctuation mark) has a node of its
own, the label of which specifies its analytic
function, i.e. Subj, Pred, Obj, Adv, different
kinds of function words, etc. (total of 40 values);
</listItem>
<footnote confidence="0.547656">
*Acknowledgement: The work reported on in this paper has been carried out under the projects GACR 405/96/K214 and
MSMT LN00A063.
</footnote>
<bodyText confidence="0.997622925925926">
no nodes are added that are not in the surface
shape of the sentence (except for the root of the
tree, carrying the identification number of the
sentence); the sentences from CNC are
preprocessed by a dependency-based
modification of Collins et al.&apos;s (1999) automatic
parser (with a success rate of about 80%),
followed by a manual tagging procedure that is
supported by a special user-friendly software
tool that enables the annotators to work with
(i.e. modify) the automatically derived graphic
representations of the trees;
(iii) the tectogrammatical (underlying)
syntactic layer: tectogrammatical tree structures
(TGTSs) are being assigned to a subset of the set
tagged according to (ii); by now, the
experimental phase has resulted in 20 samples of
50 sentences each; the TGTSs, based on
dependency syntax, are much simpler than
structural trees based on constituency
(minimalist or other), displaying a much lower
number of nodes and a more perspicuous
patterning; their basic characteristics are as
follows (a more detailed characterization of
tectogrammatics and motivating discussion,
which cannot be reproduced here, can be found
in Sgall et al. 1986; Hajičova et al. 1998):
</bodyText>
<listItem confidence="0.9967519375">
(a) only autosemantic (lexical) words have
nodes of their own; function words, as far as
semantically relevant, are reflected by parts of
complex node labels (with the exception of
coordinating conjunctions);
(b) nodes are added in case of deletions on
the surface level;
(c) the condition of projectivity is met (i.e. no
crossing of edges is allowed);
(d) tectogrammatical functions (&apos;functors&apos;)
such as Actor/Bearer, Patient, Addressee,
Origin, Effect, different kinds of Circumstantials
are assigned;
(e) basic features of TFA are introduced;
(f) elementary coreference links (both
grammatical and textual) are indicated.
</listItem>
<bodyText confidence="0.994928222222222">
Thus, a TGTS node label consists of the
lexical value of the word, of its &apos;(morphological)
grammatemes&apos; (i.e. the values of morphological
categories), its &apos;functors&apos; (with a more subtle
differentiation of syntactic relations by means of
&apos;syntactic grammatemes&apos; (e.g. &apos;in&apos;, &apos;at&apos;, &apos;on&apos;,
&apos;under&apos;), of the attribute of Contextual
Boundness (see below), and of values
concerning intersentential links (see below).
</bodyText>
<sectionHeader confidence="0.8212415" genericHeader="method">
3 From Contextual Boundness to the
Topic and the Focus of the Sentence
</sectionHeader>
<bodyText confidence="0.999873258064516">
The dependency based TGTSs in PDT allow for
a highly perspicuous notation of sentence
structure, including an economical
representation of TFA, understood as one of the
main aspects of (underlying) sentence structure
along with all other kinds of semantically
relevant information expressed by grammatical
means. TFA is accounted for by one of the
following three values of a specific TFA
attribute assigned to every lexical
(autosemantic) occurrence: t for &apos;contextually
bound&apos; (prototypically in Topic), c for
&apos;contrastive (part of) Topic&apos;, or f (`non-bound&apos;,
typically in Focus). The opposition of contextual
boundness is understood as the linguistically
structured counterpart of the distinction between
&amp;quot;given&amp;quot; and &amp;quot;new&amp;quot; information, rather than in a
straightforward etymological way (see Sgall,
Hajičova and Panevova 1986, Ch. 3). Our
approach to TFA, which uses such operational
criteria of empirical adequateness as the
question test (with the item corresponding to a
question word prototypically constituting the
focus of the answer), represents an elaboration
of older ideas, discussed especially in Czech
linguistics since V. Mathesius and J. Firbas, in
the sense of an explicit treatment meeting the
methodological requirements of formal syntax.
The following rules determine the
appurtenance of a lexical occurrence to the
Topic (T) or to the Focus (F) of the sentence:
</bodyText>
<listItem confidence="0.874228125">
(a) the main verb (V) and any of its direct
dependents belong to F iff they carry index f;
(b) every item i that does not depend directly
on V and is subordinated to an element of F
different from V, belongs to F (where
&amp;quot;subordinated to&amp;quot; is defined as the irreflexive
transitive closure of &amp;quot;depend on&amp;quot;);
(c) iff V and all items kj directly depending on it
</listItem>
<bodyText confidence="0.9958976">
carry index t, then those items kj to which some
items lm carrying f are subordinated are called
&apos;proxy foci&apos; and the items lm together with all
items subordinated to one of them belong to F,
where 1 ≤ j,m;
</bodyText>
<listItem confidence="0.9976065">
(d) every item not belonging to F according
to (a) - (c) belongs to T.
</listItem>
<bodyText confidence="0.995319956521739">
To illustrate how this approach makes it
possible to analyze also complex sentences as
for their TFA patterns, with neither T nor F
corresponding to a single constitutent, let us
present the following example, in which (1&apos;) is a
highly simplified linearized TGTS of (1); every
dependent item is enclosed in a pair of
parentheses; for the sake of transparency,
syntactic subscripts of the parentheses are left
out here, as well as subscripts indicating
morphological values, with the exception of the
two which correspond to function words, i.e.
Temp and Necess(ity); Fig. 1. presents the
respective tree structure, in which three parts of
each node label are specified, namely the lexical
value, the syntactic function (with ACT for
Actor/Bearer, RSTR for Restrictive, MANN for
Manner, and OBJ for Objective), and the TFA
value:
(1) teske radiokomunikace musi v tomto
roce rychle splatit dluh televiznim divakum.
This year, Czech Radiocommunications have
quickly to pay their debt to the TV viewers.
</bodyText>
<equation confidence="0.910349833333333">
(1&apos;) ((teskLf) radiokomunikace.t) ((tomto.t)
Czech Radiocommunications this
roce.Temp.t) splatit.Necess.f (rychle.f)
in-year must-pay quickly
(dluh.f ((televiznim.f) divakum.f))
debt TV viewers
</equation>
<figureCaption confidence="0.949301">
Figure 1.
</figureCaption>
<sectionHeader confidence="0.962602" genericHeader="method">
4 Degrees of Salience in a Discourse
</sectionHeader>
<bodyText confidence="0.99951226">
During the development of a discourse, in the
prototypical case, a new discourse referent
emerges as corresponding to a lexical
occurrence that carries the index f; its further
occurrences in the discourse carry t and are
primarily guided by the scale of their degrees of
salience. This scale, which was discussed by
Hajicova and Vrbova (1982), has to be reflected
in a description of the semantico-pragmatic
layer of the discourse. In this sense our approach
can be viewed as pointing to a useful enrichment
of the existing theories of discourse
representation (cf. also Kruijffova 1998,
Krahmer 1998; Krahmer and Theune 1999).
In the annotation system of PDT, not only
values of attributes concerning sentence
structure are assigned, but also values of
attributes for coreferential links in the discourse,
which capture certain features typical for the
linking of sentences to each other and to the
context of situation and allow for a tentative
characterization of the discourse pattern in what
concerns the development of salience degrees
during the discourse.
The following attributes of this kind are
applied within a selected part of PDT, called
&apos;model collection&apos; (for the time being, essentially
only pronouns such as &apos;on&apos; (he), including its
zero form, or &apos;ten&apos; (this) are handled in this way):
COREF: the lexical value of the antecedent,
CORNUM: the serial number of the antecedent,
CORSNT: if the antecedent in the same
sentence: NIL, if not: PREVi for the i-th
preceding sentence.
An additional attribute, ANTEC, with its
value equal to the functor of the antecedent, is
used with the so-called grammatical coreference
(relative clauses, pronouns such as &apos;se&apos; (-self),
the relation of control).
On the basis of these attributes (and of further
judgments, concerning especially associative
links between word occurrences), it is possible
to study the referential identity of different word
tokens in the flow of the discourse, and thus also
the development of salience degrees.
The following basic rules determining the
degrees of salience (in a preliminary
formulation) have been designed, with x(r)
indicating that the referent r has the salience
degree x, and 1 &lt; m,n:
</bodyText>
<listItem confidence="0.983547333333333">
(i) if r is expressed by a weak pronoun (or
zero) in a sentence, it retains its salience degree
after this sentence is uttered: n(r) --&gt; n(r);
(ii) if r is expressed by a noun (group)
carrying f, then n(r) --&gt; 0(r);
(iii) if r is expressed by a noun (group)
carrying t or c, then n(r) --&gt; 1(r);
(iv) if n(r) --&gt; m(r) in sentence S, then
m+2(q) obtains for every referent q that is not
</listItem>
<bodyText confidence="0.99935324">
itself referred to in S, but is immediately
associated with the item r present here1;
(v) if r neither is included in S, nor refers to
an associated object, then n(r) --&gt; n+2(r).
These rules, which have been checked with
several pieces of English and Czech texts,
capture such points as e.g. the fact that in the
third utterance of Jim met Martin. He
immediately started to speak of the old school in
Sussex. Jim invited him for lunch the weak
pronoun in object can only refer to Martin,
whose image has become the most salient
referent by being mentioned in the second
utterance; on the other hand, the use of such a
pronoun also in the subject (in He invited him
for lunch) would make the reference unclear.
Since the only fixed point is that of maximal
salience, our rules technically determine the
degree of salience reduction (indicating 0 as the
maximal salience). Whenever an entity has a
salience distinctly higher than all competing
entities which can be referred to by the given
expression, this expression may be used as
giving the addressee a sufficiently clear
indication of the reference specification.2
</bodyText>
<sectionHeader confidence="0.999216" genericHeader="method">
5 Illustrations
</sectionHeader>
<bodyText confidence="0.998001929824562">
The development of salience degrees during a
discourse, as far as determined by these rules,
may be illustrated on the basis of five sentence
tokens (utterances) from PDT, starting from (1),
which constitute a segment of a newspaper text
(we indicate the numerical values of salience
reduction for every noun token that is a referring
expression). We present here - similarly as with
(1&apos;) in Section 3 above - highly simplified
representations of these sentences, with
parentheses for every dependent member and
the symbols t, c, and f for contextual boundness;
1 Only immediate associative links are taken into account
for the time being, such as those between (Czech) crown
and money, or between TV or (its) signal and (its) viewer.
2 These tentative rules, which have been presented at
several occasions (starting with Hajicova and Vrbova
1982) for the aims of a further discussion, still wait for a
systematic testing and evaluation, as well as for
enrichments and more precise formulations. These issues
may find new opportunities now, when e.g. a comparison
with the centering theory gets possible and when a large set
of annotated examples from continuous texts in PDT is
available. An automatic derivation of such features can
only be looked for after the lexical units included get a very
complex and subtle semantic classification.
numbers of the degrees of salience (more
precisely, of salince reduction) for every
referring expression are inserted in the sentences
themselves. This example should enable the
reader to check (at least in certain aspects) the
general function of the procedure we use, as
well as the degree of its empirical adequacy in
the points it covers, and also our consistence in
assigning the indices. We are aware of the
preliminary character of our analysis, which
may and should be enriched in several respects
(not to cover only noun groups, to account for
possible episodic text segments, for oral speech
with the sentence prosody, for cases of
deictically, rather than anaphorically
conditioned salience, etc.).
We do not reflect several peripheral points,
such as the differences between surface word
order and the scale of CD (underlying WO),
mainly caused by the fact that a dependent often
precedes its head word on the surface (in
morphemics), although if the dependent has f
(as e.g. rychle (quickly) has in (1)), then it
follows its head under CD (with the exceptions
of focus sensitive particles, cf. Hajicova, Partee
and Sgall 1998); our translations are literal.
(1) Ceske radiokomunikace.1 musi v tomto
roce.1 rychle splatit dluh.0 televiznim
divakum.0
In this year, Czech Radiocommunications
have quickly to pay their debt to the TV viewers.
</bodyText>
<equation confidence="0.883185888888889">
(1&apos;) ((teskM) radiokomunikace.t) ((tomto.t)
Czech Radiocommunications this
roce.Temp.t) splatit.Necess.f (rychle.f)
in-year must-pay quickly
(dluh.f ((televiznim.f) divakum.f))
debt TV viewers
(2) Jejich.1 vysilace.1 dosud pokryvaji
signalem.0 programu.0 ft1 2.0 mene nez-
polovinu.0 uzemi.0 republiky.0.
</equation>
<construct confidence="0.603946">
Their transmitters hitherto cover by-signal
of-the-program ČT2 less than a-half of-the-
territory of-the-Republic.
</construct>
<listItem confidence="0.4305805">
(2&apos;) ((jejich.t) vysilace.t) (dosud.t) pokryvaji.f
(signalem.f (programu.f (ftt (2.f)))) ((mene.f
(nez-polovinu.f)) uzemi.f (republiky.t))
(3) Na moravsko-slovenskem pomezi.1 je
</listItem>
<bodyText confidence="0.520603">
nada mist.0, kde nezachyti ani prvni program.0
Ceske televize.1.
On the-Moravian-Slovakian borderline
there-is a-number of-places where (they) do-not-
get even the-first program of-Czech Television.
</bodyText>
<equation confidence="0.77958575">
(3&apos;) ((na-moravsko-slovensk6m.t) pomezi.t)
je.f (rada.f (mist.f ((kde.t) (oni.t) (ne.f) zachyti.f
((ani.f) (prvni.f) program.t ((teskLt)
televize.t)))))
</equation>
<listItem confidence="0.878692454545455">
(4) Do rozdeleni.1 federace.1 totiz signal.1
zajisfovaly vysila6e.0 v SR.0.
Until the-division of-the-federation as-a-
matter-of-fact the-signal.Accusative provided
transmitters.Nominative in S(lovac)R(epublic).
(4&apos;) (do-rozdeleni.t (federace.t)) (totiz.t)
(signal.t) zajisfovaly.t (vysila6e.f (v-SR.f)).
(5) teska televize zada urychlenou vystavbu
novych vysila6u.
Czech Television requires quick construction
of-new transmitters.
</listItem>
<equation confidence="0.79638">
(5&apos;) ((teska.t) televize.t) zada.f
((urychlenou.f) vystavbu.f ((novych.f)
vysila6u.t))
</equation>
<bodyText confidence="0.99981196">
The development of salience reduction of the
referents most frequently mentioned in (1) - (5)
is characterized in Tab. 1, which includes
numbers of salience reduction degrees and of
those rules from Section 3 that are the main
sources of the degrees. Two further remarks
may be added, concerning details of our analysis
that have not been discussed above and may not
be directly found in the previous publications we
refer to: (a) a noun group consisting of a head
with t or c and of one or more adjuncts with f
constitutes a referring expression as a whole, in
the prototypical case, and gets degree 0, if it
occurs in F; this concerns e.g. the group vysilafre
v SR (`transmitters in the Slovac Republic&apos;) in
sentence (4), or ČT 2 (CTV 2) in (2); here 2 is
treated as an adjunct of CT; (b) the difference
between the degrees 0 and 1 is not sufficient for
a safe choice of reference, so that, e.g., the
reference of the pronoun jejich (their) after (1)
by itself is indistinct, and only inferencing helps
to establish that Česke radiokomunikace (Czech
Radiocommunications) are referred to (viewers
normally do not have transmitters at their
diposal).
</bodyText>
<table confidence="0.995452333333333">
after (1) (2) (3) (4) (5)
CRC 1 1 3 5 7
(iii) (iii) (iv) (v) (v)
CTV 3 1 1 2 1
(iv) (iii) (iii) (iv) (iii)
CTV1 2 2 0 2 3
(iv) (iv) (ii) (iv) (iv)
CTV2 2 0 2 2 3
(iv) (ii) (iv) (iv) (iv)
viewer 0 2 2 3 3
(ii) (iv) (i) (iv) (iv)
sig. 3 0 2 1 3
(iv) (ii) (iv) (iii) (iv)
CR 3 1 3 3 3
(iv) (iii) (iv) (iv) (iv)
CSF - - 3 1 3
(iv) (iii) (v)
terr. 3 0 2 2 4
(iv) (ii) (iv) (iv) (v)
tr. - 1 2 0 0
(iii) (iv) (ii) (ii)
</table>
<tableCaption confidence="0.999581">
Table 1.
</tableCaption>
<figure confidence="0.656959714285714">
Abbreviations:
CRC - Czech Radio(tele)communications
CTV - Czech TV
CR - Czech Republic
CSF - (CS) Federation
CTV1(2) - 1st (2nd) program of CTV
tr. - transmitter
</figure>
<figureCaption confidence="0.8017085">
terr. - territory of CR
sig. - signal of CTV
</figureCaption>
<bodyText confidence="0.983426821428571">
Even with this short piece of discourse, its
segmentation is reflected, if its first subsegment,
discussed up to now (sentences (1) - (5)), is
compared with its continuation, i.e. sentences
(6) - (9), given below. While the first segment
deals primarily with CTV and its signal (cf. the
relatively high salience of CTV, CTV1, CTV2,
RC, signal and viewer in most parts of the
segment), sentences (6) — (9) are devoted to
financial issues, as can be seen from the
following facts: (a) money gets degree 0 after
(6), in which it functions as its focus proper (the
most dynamic item), (b) Czech crown gets
degree 1 after (7), in which it is an embedded
part of the focus, and (c) the group financial
coverage gets degree 1 in sentence (8).
The continuation is presented here without
the TGTSs:
(6) Nage spole6nost maze ukol splnit, ale
chybeji nam penize.
Our company can the-task.Accusative fulfil, but
is-lacking us.Dative the-money.Nominative.
(7) Letos by vystavba technick6ho zařizeni v
sedmi lokalitach stala 120 mili6nů korun, ale
mů�eme uvolnit jen 80 mili6nů.
This-year, would the-construction of-technical
equipment in seven localities cost 120 million
crowns, but we-can spend only 80 million.
</bodyText>
<listItem confidence="0.569387">
(8) Proto o finančnim zabezpečeni jedname
s Českou televizi, uvadi ekonomicky ředitel
</listItem>
<bodyText confidence="0.627870583333333">
Českych radiotelekomunikaci Miroslav Cuřin.
Therefore about (its) financial coverage we-
discuss with Czech Television, states the-
economic director of-Czech
Radiotelcommunications M. C.
(9) Dalsich 62 mili6nů korun si vyzada
vystavba vysilačů a převaděčů signalu v
pohraniči.
Further 62 million crowns.Accusative Refl. will-
require the-construction.Nominative of-
transmitters and transferrers of-the-signal in the-
border-area.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999996952380952">
We are aware that, along with the rules
characterized above, there are other factors that
have to be investigated, which are important for
different kinds of discourses. This concerns
various aspects of the discourse situation, of
domain knowledge, of specific textual patterns
(with episodes, poetic effects, and so on).
Factors of these and further kinds can be studied
on the basis of the salience degrees, which are
typical for basic discourse situations.
In any case, we may conclude that it is useful
for a theory of discourse semantics to reflect the
degrees of salience. This makes it possible to
distinguish the reference potential of referring
expressions and thus the connectedness of the
discourse. Discourse analysis of this kind may
also be useful for application domains such as
text segmentation (in accordance with topics of
individual segments), or data mining (specifying
texts in which a given topic is actually treated,
rather than being just occasionally mentioned).
</bodyText>
<sectionHeader confidence="0.999477" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9987134">
B6hmova A. and E. Hajičova (1999). The Prague
Dependency Tree Bank I: How much of the
underlying syntactic structure can be tagged
automatically? The Prague Bulletin of
Mathematical Linguistics 71, 5-12.
Collins M., Hajič J., Brill E., Ramshaw L. and C.
Tillmann (1999). A statistical parser for Czech. In:
Proceedings of 37th Annual Meeting of ACL,
Cambridge, Mass.: M.I.T. Press, 505-512.
Hajič J. (1998). Building a syntactically annotated
corpus: The Prague Dependency Treebank. In:
Issues of Valency and Meaning. Studies in Honour
of Jarmila Panevova, ed. by E. Hajičova, 106-132.
Prague: Karolinum.
Hajič J. (in press). Disambiguation of rich inflection
(Computational morphology of Czech).
Prague:Karolinum.
Hajič J. and Hladka B. (1997). Probabilistic and rule-
based tagger of an inflective language - a
comparison. In Proceedings of the Fifth
Conference on Applied Natural Language
Processing, Washington, D.C., 111-118.
Hajič J. and Hladka B. (1998). Czech language
processing - POS tagging. In: Proceedings of the
First International Conference on Language
Resources &amp; Evaluation, Granada.
Hajičova E., Partee B. and P. Sgall (1998): Topic-
focus articulation, tripartite structures, and
semantic content. Amsterdam:Kluwer
Hajičova E. and J. Vrbova (1982). On the role of the
hierarchy of activation in the process of natural
language understanding. In: COLING 82. Ed. by J.
Horecky. Amsterdam: North Holland, 107-113.
Krahmer E. (1998), Presupposition and anaphora.
CSLI Lecture Notes 89. CSLI, Stanford, CA.
Krahmer E. and M. Theune (1999), Efficient
generation of descriptions in context. In: R. Kibble
and K. van Deemter (eds.), Proceedings of the
workshop The Generation of Nominal Expression,
associated with the 11th European Summer School
in Logic, Language and Information.
Kruijff-Korbayova I. (1998): The dynamic potential
of topic and focus: A Praguian approach to
Discourse Representation Theory. Prague: Charles
University, Faculty of Mathematics and Physics,
Ph.D. dissertation.
Sgall P., Hajičova E. and J. Panevova (1986): The
Meaning of the Sentence in Its Semantic and
Pragmatic Aspects, ed. by J. L. Mey,
Dordrecht:Reidel - Prague: Academia.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000184">
<title confidence="0.4551455">and Faculty of Mathematics and Physics</title>
<affiliation confidence="0.998205">Charles University</affiliation>
<address confidence="0.9967795">Malostransk6 nam. 25 118 00 Praha, Czech Republic</address>
<email confidence="0.982549">hajicova@ufal.mff.cuni.cz</email>
<author confidence="0.997266">Petr Sgall</author>
<affiliation confidence="0.995929">Faculty of Mathematics and Physics Charles University</affiliation>
<address confidence="0.991799">Malostransk6 nam. 25 118 00 Praha, Czech Republic</address>
<abstract confidence="0.995827613053612">sgall@ufal.mff.cuni.cz and Motivation Most of the current work on corpus annotation is concentrated on morphemics, lexical semantics and sentence structure. However, it becomes more and more obvious that attention should and can be also paid to phenomena that reflect the links between a sentence and its context, i.e. the discourse anchoring of utterances. If conceived in this way, an annotated corpus can be used as a resource for linguistic research not only within the limits of the sentence, but also with regard to discourse patterns. Thus, the applications of the research to issues of information retrieval and extraction may be made more effective; also applications in new domains become feasible, be it to serve for inner linguistic (and literary) aims, such as text segmentation, specification of topics of parts of a discourse, or for other disciplines. These considerations have been a motivation for the tectogrammatical (i.e. underlying, see below) tagging done within the Prague Dependency Treebank (PDT) to contain also attributes concerning certain contextual features, i.e. the contextual anchoring of word tokens and their relationships to their coreferential antecedents. Along with this enrichment in the intersentential aspect, we do not neglect to pay attention to intrasentential issues, i.e. to sentence structure, which displays its own features oriented towards the contextual potential of the sentence, namely its topic-focus articulation (TFA). In the present paper, we give first an outline of the annotation scenario of the PDT (Section 2), concentrating then on the use of one of the PDT attributes for the specification of the Topic and the Focus (the &apos;information structure&apos;) of the sentence (Section 3). In Section 4. we present certain heuristics that partly are based on TFA and that allow for the specification of the degrees of salience in a discourse. The application of these heuristics is illustrated in Section 5. 2 Outline of the Prague Dependency Treebank The Prague Dependency Treebank (PDT) is being built on the basis of the Czech National Corpus (CNC), which grows rapidly in the range of hundreds of millions of word occurrences in journalistic and fiction texts. The PDT scenario comprises three layers of annotation: (i) the morphemic (POS) layer with about 2000 tags for the highly inflectional Czech language; the whole CNC has been tagged by a tagger Hladka 1997;1998, and 1999, Hladka 2000) with a success rate of 95%; the tagger is based on a fully automatic morphemic analysis of press); (ii) a layer of &apos;analytic&apos; (&amp;quot;surface&amp;quot;) syntax cca 100 000 Czech sentences, i.e. samples of texts (each randomly chosen sample consisting of 50 sentences of a coherent text), taken from CNC, have been assigned dependency tree structures; every word (as well as every punctuation mark) has a node of its own, the label of which specifies its analytic function, i.e. Subj, Pred, Obj, Adv, different kinds of function words, etc. (total of 40 values); The work reported on in this paper has been carried out under the projects GACR 405/96/K214 and MSMT LN00A063. no nodes are added that are not in the surface shape of the sentence (except for the root of the tree, carrying the identification number of the sentence); the sentences from CNC are preprocessed by a dependency-based modification of Collins et al.&apos;s (1999) automatic parser (with a success rate of about 80%), followed by a manual tagging procedure that is supported by a special user-friendly software tool that enables the annotators to work with (i.e. modify) the automatically derived graphic representations of the trees; (iii) the tectogrammatical (underlying) syntactic layer: tectogrammatical tree structures (TGTSs) are being assigned to a subset of the set tagged according to (ii); by now, the experimental phase has resulted in 20 samples of 50 sentences each; the TGTSs, based on dependency syntax, are much simpler than structural trees based on constituency (minimalist or other), displaying a much lower number of nodes and a more perspicuous patterning; their basic characteristics are as follows (a more detailed characterization of tectogrammatics and motivating discussion, which cannot be reproduced here, can be found Sgall et al. 1986; et al. 1998): (a) only autosemantic (lexical) words have nodes of their own; function words, as far as semantically relevant, are reflected by parts of complex node labels (with the exception of coordinating conjunctions); (b) nodes are added in case of deletions on the surface level; (c) the condition of projectivity is met (i.e. no crossing of edges is allowed); (d) tectogrammatical functions (&apos;functors&apos;) such as Actor/Bearer, Patient, Addressee, Origin, Effect, different kinds of Circumstantials are assigned; (e) basic features of TFA are introduced; (f) elementary coreference links (both grammatical and textual) are indicated. Thus, a TGTS node label consists of the lexical value of the word, of its &apos;(morphological) grammatemes&apos; (i.e. the values of morphological categories), its &apos;functors&apos; (with a more subtle differentiation of syntactic relations by means of &apos;syntactic grammatemes&apos; (e.g. &apos;in&apos;, &apos;at&apos;, &apos;on&apos;, &apos;under&apos;), of the attribute of Contextual Boundness (see below), and of values concerning intersentential links (see below). 3 From Contextual Boundness to the Topic and the Focus of the Sentence The dependency based TGTSs in PDT allow for a highly perspicuous notation of sentence structure, including an economical representation of TFA, understood as one of the main aspects of (underlying) sentence structure along with all other kinds of semantically relevant information expressed by grammatical means. TFA is accounted for by one of the following three values of a specific TFA attribute assigned to every lexical (autosemantic) occurrence: t for &apos;contextually bound&apos; (prototypically in Topic), c for &apos;contrastive (part of) Topic&apos;, or f (`non-bound&apos;, typically in Focus). The opposition of contextual boundness is understood as the linguistically structured counterpart of the distinction between &amp;quot;given&amp;quot; and &amp;quot;new&amp;quot; information, rather than in a straightforward etymological way (see Sgall, and Panevova 1986, Ch. 3). Our approach to TFA, which uses such operational criteria of empirical adequateness as the question test (with the item corresponding to a question word prototypically constituting the focus of the answer), represents an elaboration of older ideas, discussed especially in Czech linguistics since V. Mathesius and J. Firbas, in the sense of an explicit treatment meeting the methodological requirements of formal syntax. The following rules determine the appurtenance of a lexical occurrence to the Topic (T) or to the Focus (F) of the sentence: (a) the main verb (V) and any of its direct dependents belong to F iff they carry index f; (b) every item i that does not depend directly on V and is subordinated to an element of F different from V, belongs to F (where &amp;quot;subordinated to&amp;quot; is defined as the irreflexive transitive closure of &amp;quot;depend on&amp;quot;); iff V and all items depending on it index t, then those items which some carrying f are subordinated are called foci&apos; and the items together with all items subordinated to one of them belong to F, 1 (d) every item not belonging to F according to (a) - (c) belongs to T. To illustrate how this approach makes it possible to analyze also complex sentences as for their TFA patterns, with neither T nor F corresponding to a single constitutent, let us present the following example, in which (1&apos;) is a highly simplified linearized TGTS of (1); every dependent item is enclosed in a pair of parentheses; for the sake of transparency, syntactic subscripts of the parentheses are left out here, as well as subscripts indicating morphological values, with the exception of the two which correspond to function words, i.e. Temp and Necess(ity); Fig. 1. presents the respective tree structure, in which three parts of each node label are specified, namely the lexical value, the syntactic function (with ACT for Actor/Bearer, RSTR for Restrictive, MANN for Manner, and OBJ for Objective), and the TFA value: radiokomunikace musi v tomto rychle splatit dluh televiznim This year, Czech Radiocommunications have quickly to pay their debt to the TV viewers. radiokomunikace.t) ((tomto.t) Czech Radiocommunications this roce.Temp.t) splatit.Necess.f (rychle.f) in-year must-pay quickly ((televiznim.f) debt TV viewers Figure 1. 4 Degrees of Salience in a Discourse During the development of a discourse, in the prototypical case, a new discourse referent emerges as corresponding to a lexical occurrence that carries the index f; its further occurrences in the discourse carry t and are primarily guided by the scale of their degrees of salience. This scale, which was discussed by and Vrbova (1982), has to be reflected in a description of the semantico-pragmatic layer of the discourse. In this sense our approach can be viewed as pointing to a useful enrichment of the existing theories of discourse representation (cf. also Kruijffova 1998, Krahmer 1998; Krahmer and Theune 1999). In the annotation system of PDT, not only values of attributes concerning sentence structure are assigned, but also values of attributes for coreferential links in the discourse, which capture certain features typical for the linking of sentences to each other and to the context of situation and allow for a tentative characterization of the discourse pattern in what concerns the development of salience degrees during the discourse. The following attributes of this kind are applied within a selected part of PDT, called &apos;model collection&apos; (for the time being, essentially only pronouns such as &apos;on&apos; (he), including its zero form, or &apos;ten&apos; (this) are handled in this way): COREF: the lexical value of the antecedent, CORNUM: the serial number of the antecedent, CORSNT: if the antecedent in the same sentence: NIL, if not: PREVi for the i-th preceding sentence. An additional attribute, ANTEC, with its value equal to the functor of the antecedent, is used with the so-called grammatical coreference (relative clauses, pronouns such as &apos;se&apos; (-self), the relation of control). On the basis of these attributes (and of further judgments, concerning especially associative links between word occurrences), it is possible to study the referential identity of different word tokens in the flow of the discourse, and thus also the development of salience degrees. The following basic rules determining the degrees of salience (in a preliminary formulation) have been designed, with x(r) indicating that the referent r has the salience x, and 1 (i) if r is expressed by a weak pronoun (or zero) in a sentence, it retains its salience degree after this sentence is uttered: n(r) --&gt; n(r); (ii) if r is expressed by a noun (group) carrying f, then n(r) --&gt; 0(r); (iii) if r is expressed by a noun (group) carrying t or c, then n(r) --&gt; 1(r); (iv) if n(r) --&gt; m(r) in sentence S, then m+2(q) obtains for every referent q that is not itself referred to in S, but is immediately with the item r present (v) if r neither is included in S, nor refers to an associated object, then n(r) --&gt; n+2(r). These rules, which have been checked with several pieces of English and Czech texts, capture such points as e.g. the fact that in the utterance of met Martin. He immediately started to speak of the old school in Jim invited him for lunch weak pronoun in object can only refer to Martin, whose image has become the most salient referent by being mentioned in the second utterance; on the other hand, the use of such a also in the subject (in invited him would make the reference unclear. Since the only fixed point is that of maximal salience, our rules technically determine the degree of salience reduction (indicating 0 as the maximal salience). Whenever an entity has a salience distinctly higher than all competing entities which can be referred to by the given expression, this expression may be used as giving the addressee a sufficiently clear of the reference 5 Illustrations The development of salience degrees during a discourse, as far as determined by these rules, may be illustrated on the basis of five sentence tokens (utterances) from PDT, starting from (1), which constitute a segment of a newspaper text (we indicate the numerical values of salience reduction for every noun token that is a referring expression). We present here similarly as with (1&apos;) in Section 3 above highly simplified representations of these sentences, with parentheses for every dependent member and the symbols t, c, and f for contextual boundness; immediate associative links are taken into account the time being, such as those between or between tentative rules, which have been presented at occasions (starting with and Vrbova 1982) for the aims of a further discussion, still wait for a systematic testing and evaluation, as well as for enrichments and more precise formulations. These issues may find new opportunities now, when e.g. a comparison with the centering theory gets possible and when a large set of annotated examples from continuous texts in PDT is available. An automatic derivation of such features can only be looked for after the lexical units included get a very complex and subtle semantic classification. numbers of the degrees of salience (more precisely, of salince reduction) for every referring expression are inserted in the sentences themselves. This example should enable the reader to check (at least in certain aspects) the general function of the procedure we use, as well as the degree of its empirical adequacy in the points it covers, and also our consistence in assigning the indices. We are aware of the preliminary character of our analysis, which may and should be enriched in several respects (not to cover only noun groups, to account for possible episodic text segments, for oral speech with the sentence prosody, for cases of deictically, rather than anaphorically conditioned salience, etc.). We do not reflect several peripheral points, such as the differences between surface word order and the scale of CD (underlying WO), mainly caused by the fact that a dependent often precedes its head word on the surface (in morphemics), although if the dependent has f e.g. has in (1)), then it follows its head under CD (with the exceptions focus sensitive particles, cf. Partee and Sgall 1998); our translations are literal. radiokomunikace.1 musi v tomto roce.1 rychle splatit dluh.0 televiznim In this year, Czech Radiocommunications have quickly to pay their debt to the TV viewers. radiokomunikace.t) ((tomto.t) Czech Radiocommunications this roce.Temp.t) splatit.Necess.f (rychle.f) in-year must-pay quickly ((televiznim.f) debt TV viewers Jejich.1 dosud pokryvaji programu.0 2.0 nezpolovinu.0 uzemi.0 republiky.0. Their transmitters hitherto cover by-signal less than a-half of-theterritory of-the-Republic. ((jejich.t) (dosud.t) pokryvaji.f (programu.f (2.f)))) (nez-polovinu.f)) uzemi.f (republiky.t)) (3) Na moravsko-slovenskem pomezi.1 je mist.0, kde nezachyti ani prvni program.0 televize.1. On the-Moravian-Slovakian borderline there-is a-number of-places where (they) do-notget even the-first program of-Czech Television. (3&apos;) ((na-moravsko-slovensk6m.t) pomezi.t) (mist.f ((kde.t) (oni.t) (ne.f) zachyti.f (prvni.f) program.t televize.t))))) Do federace.1 totiz signal.1 v SR.0. Until the-division of-the-federation as-amatter-of-fact the-signal.Accusative provided transmitters.Nominative in S(lovac)R(epublic). (federace.t)) (totiz.t) (v-SR.f)). televize zada urychlenou vystavbu Czech Television requires quick construction of-new transmitters. televize.t) zada.f ((urychlenou.f) vystavbu.f ((novych.f) The development of salience reduction of the referents most frequently mentioned in (1) - (5) is characterized in Tab. 1, which includes numbers of salience reduction degrees and of those rules from Section 3 that are the main sources of the degrees. Two further remarks may be added, concerning details of our analysis that have not been discussed above and may not be directly found in the previous publications we refer to: (a) a noun group consisting of a head with t or c and of one or more adjuncts with f constitutes a referring expression as a whole, in the prototypical case, and gets degree 0, if it in F; this concerns e.g. the group SR in the Slovac Republic&apos;) in (4), or 2 in (2); here as an adjunct of (b) the difference between the degrees 0 and 1 is not sufficient for a safe choice of reference, so that, e.g., the of the pronoun after (1) by itself is indistinct, and only inferencing helps establish that radiokomunikace are referred to (viewers normally do not have transmitters at their diposal). after (2) (3) (4) (5) CRC 1 1 3 (iv) 5 7 (iii) (iii) (v) (v) CTV 3 1 1 2 (iv) 1 (iv) (iii) (iii) (iii) 2 (iv) 2 0 (ii) 2 (iv) 3 (iv) (iv) CTV2 2 (iv) 0 (ii) 2 2 (iv) 3 (iv) (iv) viewer 0 (ii) 2 2 (i) 3 (iv) 3 (iv) (iv) sig. 3 (iv) 0 2 (iv) 1 3 (iv) (ii) (iii) CR 3 (iv) 1 3 3 3 (iv) (iii) (iv) (iv) CSF - - 3 (iv) 1 3 (iii) (v) terr. 3 (iv) 0 2 (iv) 2 4 (ii) (iv) (v) tr. - 1 2 0 (ii) 0 (ii) (iii) (iv) Table 1.</abstract>
<title confidence="0.7517342">Abbreviations: CRC - Czech Radio(tele)communications CTV - Czech TV CR - Czech Republic CSF - (CS) Federation</title>
<abstract confidence="0.995609776119403">CTV1(2) - 1st (2nd) program of CTV tr. transmitter terr. territory of CR sig. signal of CTV Even with this short piece of discourse, its segmentation is reflected, if its first subsegment, discussed up to now (sentences (1) - (5)), is compared with its continuation, i.e. sentences (6) - (9), given below. While the first segment deals primarily with CTV and its signal (cf. the high salience of CTV2, signal most parts of the segment), sentences (6) — (9) are devoted to financial issues, as can be seen from the facts: (a) degree 0 after (6), in which it functions as its focus proper (the dynamic item), (b) crown degree 1 after (7), in which it is an embedded of the focus, and (c) the group degree 1 in sentence (8). The continuation is presented here without the TGTSs: Nage ukol splnit, ale nam penize. Our company can the-task.Accusative fulfil, but is-lacking us.Dative the-money.Nominative. Letos by vystavba technick6ho v lokalitach stala 120 ale uvolnit jen 80 This-year, would the-construction of-technical equipment in seven localities cost 120 million crowns, but we-can spend only 80 million. Proto o jedname televizi, uvadi ekonomicky radiotelekomunikaci Miroslav Therefore about (its) financial coverage wediscuss with Czech Television, states theeconomic director of-Czech Radiotelcommunications M. C. Dalsich 62 si vyzada v Further 62 million crowns.Accusative Refl. willrequire the-construction.Nominative oftransmitters and transferrers of-the-signal in theborder-area. 6 Conclusions We are aware that, along with the rules characterized above, there are other factors that have to be investigated, which are important for different kinds of discourses. This concerns various aspects of the discourse situation, of domain knowledge, of specific textual patterns (with episodes, poetic effects, and so on). Factors of these and further kinds can be studied on the basis of the salience degrees, which are typical for basic discourse situations. In any case, we may conclude that it is useful for a theory of discourse semantics to reflect the degrees of salience. This makes it possible to distinguish the reference potential of referring expressions and thus the connectedness of the discourse. Discourse analysis of this kind may also be useful for application domains such as text segmentation (in accordance with topics of individual segments), or data mining (specifying texts in which a given topic is actually treated, rather than being just occasionally mentioned).</abstract>
<note confidence="0.780563648648649">References A. and E. (1999). The Prague Dependency Tree Bank I: How much of the underlying syntactic structure can be tagged automatically? The Prague Bulletin of Mathematical Linguistics 71, 5-12. M., Brill E., Ramshaw L. and C. Tillmann (1999). A statistical parser for Czech. In: Proceedings of 37th Annual Meeting of ACL, Cambridge, Mass.: M.I.T. Press, 505-512. (1998). Building a syntactically annotated corpus: The Prague Dependency Treebank. In: Issues of Valency and Meaning. Studies in Honour Jarmila Panevova, ed. by E. 106-132. Prague: Karolinum. (in press). Disambiguation of rich inflection (Computational morphology of Czech). Prague:Karolinum. and Hladka B. (1997). Probabilistic and rulebased tagger of an inflective language a comparison. In Proceedings of the Fifth Conference on Applied Natural Language Processing, Washington, D.C., 111-118. and Hladka B. (1998). Czech language processing - POS tagging. In: Proceedings of the First International Conference on Language Resources &amp; Evaluation, Granada. E., Partee B. and P. Sgall (1998): Topicfocus articulation, tripartite structures, and semantic content. Amsterdam:Kluwer E. and J. Vrbova (1982). On the role of the hierarchy of activation in the process of natural understanding. In: Ed. by J. Horecky. Amsterdam: North Holland, 107-113. Krahmer E. (1998), Presupposition and anaphora. CSLI Lecture Notes 89. CSLI, Stanford, CA. Krahmer E. and M. Theune (1999), Efficient</note>
<abstract confidence="0.918587142857143">generation of descriptions in context. In: R. Kibble and K. van Deemter (eds.), Proceedings of the workshop The Generation of Nominal Expression, associated with the 11th European Summer School in Logic, Language and Information. Kruijff-Korbayova I. (1998): The dynamic potential of topic and focus: A Praguian approach to</abstract>
<affiliation confidence="0.9218905">Discourse Representation Theory. Prague: Charles University, Faculty of Mathematics and Physics,</affiliation>
<keyword confidence="0.475116">Ph.D. dissertation.</keyword>
<note confidence="0.373592">P., E. and J. Panevova (1986): The Meaning of the Sentence in Its Semantic and Pragmatic Aspects, ed. by J. L. Mey, Dordrecht:Reidel - Prague: Academia.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A B6hmova</author>
<author>E Hajičova</author>
</authors>
<title>The Prague Dependency Tree Bank I: How much of the underlying syntactic structure can be tagged automatically? The Prague Bulletin of</title>
<date>1999</date>
<journal>Mathematical Linguistics</journal>
<volume>71</volume>
<pages>5--12</pages>
<marker>B6hmova, Hajičova, 1999</marker>
<rawString>B6hmova A. and E. Hajičova (1999). The Prague Dependency Tree Bank I: How much of the underlying syntactic structure can be tagged automatically? The Prague Bulletin of Mathematical Linguistics 71, 5-12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
<author>J Hajič</author>
<author>E Brill</author>
<author>L Ramshaw</author>
<author>C Tillmann</author>
</authors>
<title>A statistical parser for Czech. In:</title>
<date>1999</date>
<booktitle>Proceedings of 37th Annual Meeting of ACL,</booktitle>
<pages>505--512</pages>
<publisher>M.I.T. Press,</publisher>
<location>Cambridge, Mass.:</location>
<marker>Collins, Hajič, Brill, Ramshaw, Tillmann, 1999</marker>
<rawString>Collins M., Hajič J., Brill E., Ramshaw L. and C. Tillmann (1999). A statistical parser for Czech. In: Proceedings of 37th Annual Meeting of ACL, Cambridge, Mass.: M.I.T. Press, 505-512.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hajič</author>
</authors>
<title>Building a syntactically annotated corpus: The Prague Dependency Treebank. In:</title>
<date>1998</date>
<booktitle>Issues of Valency and Meaning. Studies in Honour of Jarmila Panevova,</booktitle>
<pages>106--132</pages>
<editor>ed. by E. Hajičova,</editor>
<publisher>Karolinum.</publisher>
<location>Prague:</location>
<marker>Hajič, 1998</marker>
<rawString>Hajič J. (1998). Building a syntactically annotated corpus: The Prague Dependency Treebank. In: Issues of Valency and Meaning. Studies in Honour of Jarmila Panevova, ed. by E. Hajičova, 106-132. Prague: Karolinum.</rawString>
</citation>
<citation valid="false">
<authors>
<author>J Hajič</author>
</authors>
<title>(in press). Disambiguation of rich inflection (Computational morphology of Czech).</title>
<publisher>Prague:Karolinum.</publisher>
<marker>Hajič, </marker>
<rawString>Hajič J. (in press). Disambiguation of rich inflection (Computational morphology of Czech). Prague:Karolinum.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hajič</author>
<author>B Hladka</author>
</authors>
<title>Probabilistic and rulebased tagger of an inflective language - a comparison.</title>
<date>1997</date>
<booktitle>In Proceedings of the Fifth Conference on Applied Natural Language Processing,</booktitle>
<pages>111--118</pages>
<location>Washington, D.C.,</location>
<marker>Hajič, Hladka, 1997</marker>
<rawString>Hajič J. and Hladka B. (1997). Probabilistic and rulebased tagger of an inflective language - a comparison. In Proceedings of the Fifth Conference on Applied Natural Language Processing, Washington, D.C., 111-118.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hajič</author>
<author>B Hladka</author>
</authors>
<title>Czech language processing - POS tagging. In:</title>
<date>1998</date>
<booktitle>Proceedings of the First International Conference on Language Resources &amp; Evaluation,</booktitle>
<location>Granada.</location>
<marker>Hajič, Hladka, 1998</marker>
<rawString>Hajič J. and Hladka B. (1998). Czech language processing - POS tagging. In: Proceedings of the First International Conference on Language Resources &amp; Evaluation, Granada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Hajičova</author>
<author>B Partee</author>
<author>P Sgall</author>
</authors>
<title>Topicfocus articulation, tripartite structures, and semantic content.</title>
<date>1998</date>
<publisher>Amsterdam:Kluwer</publisher>
<contexts>
<context position="4680" citStr="Hajičova et al. 1998" startWordPosition="724" endWordPosition="727">ing) syntactic layer: tectogrammatical tree structures (TGTSs) are being assigned to a subset of the set tagged according to (ii); by now, the experimental phase has resulted in 20 samples of 50 sentences each; the TGTSs, based on dependency syntax, are much simpler than structural trees based on constituency (minimalist or other), displaying a much lower number of nodes and a more perspicuous patterning; their basic characteristics are as follows (a more detailed characterization of tectogrammatics and motivating discussion, which cannot be reproduced here, can be found in Sgall et al. 1986; Hajičova et al. 1998): (a) only autosemantic (lexical) words have nodes of their own; function words, as far as semantically relevant, are reflected by parts of complex node labels (with the exception of coordinating conjunctions); (b) nodes are added in case of deletions on the surface level; (c) the condition of projectivity is met (i.e. no crossing of edges is allowed); (d) tectogrammatical functions (&apos;functors&apos;) such as Actor/Bearer, Patient, Addressee, Origin, Effect, different kinds of Circumstantials are assigned; (e) basic features of TFA are introduced; (f) elementary coreference links (both grammatical a</context>
</contexts>
<marker>Hajičova, Partee, Sgall, 1998</marker>
<rawString>Hajičova E., Partee B. and P. Sgall (1998): Topicfocus articulation, tripartite structures, and semantic content. Amsterdam:Kluwer</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Hajičova</author>
<author>J Vrbova</author>
</authors>
<title>On the role of the hierarchy of activation in the process of natural language understanding. In:</title>
<date>1982</date>
<booktitle>COLING 82. Ed. by J. Horecky.</booktitle>
<pages>107--113</pages>
<location>Amsterdam: North Holland,</location>
<marker>Hajičova, Vrbova, 1982</marker>
<rawString>Hajičova E. and J. Vrbova (1982). On the role of the hierarchy of activation in the process of natural language understanding. In: COLING 82. Ed. by J. Horecky. Amsterdam: North Holland, 107-113.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Krahmer</author>
</authors>
<title>Presupposition and anaphora.</title>
<date>1998</date>
<journal>CSLI Lecture Notes</journal>
<volume>89</volume>
<publisher>CSLI,</publisher>
<location>Stanford, CA.</location>
<contexts>
<context position="9646" citStr="Krahmer 1998" startWordPosition="1501" endWordPosition="1502"> Discourse During the development of a discourse, in the prototypical case, a new discourse referent emerges as corresponding to a lexical occurrence that carries the index f; its further occurrences in the discourse carry t and are primarily guided by the scale of their degrees of salience. This scale, which was discussed by Hajicova and Vrbova (1982), has to be reflected in a description of the semantico-pragmatic layer of the discourse. In this sense our approach can be viewed as pointing to a useful enrichment of the existing theories of discourse representation (cf. also Kruijffova 1998, Krahmer 1998; Krahmer and Theune 1999). In the annotation system of PDT, not only values of attributes concerning sentence structure are assigned, but also values of attributes for coreferential links in the discourse, which capture certain features typical for the linking of sentences to each other and to the context of situation and allow for a tentative characterization of the discourse pattern in what concerns the development of salience degrees during the discourse. The following attributes of this kind are applied within a selected part of PDT, called &apos;model collection&apos; (for the time being, essentia</context>
</contexts>
<marker>Krahmer, 1998</marker>
<rawString>Krahmer E. (1998), Presupposition and anaphora. CSLI Lecture Notes 89. CSLI, Stanford, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Krahmer</author>
<author>M Theune</author>
</authors>
<title>Efficient generation of descriptions in context. In:</title>
<date>1999</date>
<booktitle>Proceedings of the workshop The Generation of Nominal Expression, associated with the 11th European Summer School in Logic, Language and Information.</booktitle>
<editor>R. Kibble and K. van Deemter (eds.),</editor>
<contexts>
<context position="9672" citStr="Krahmer and Theune 1999" startWordPosition="1503" endWordPosition="1506">ing the development of a discourse, in the prototypical case, a new discourse referent emerges as corresponding to a lexical occurrence that carries the index f; its further occurrences in the discourse carry t and are primarily guided by the scale of their degrees of salience. This scale, which was discussed by Hajicova and Vrbova (1982), has to be reflected in a description of the semantico-pragmatic layer of the discourse. In this sense our approach can be viewed as pointing to a useful enrichment of the existing theories of discourse representation (cf. also Kruijffova 1998, Krahmer 1998; Krahmer and Theune 1999). In the annotation system of PDT, not only values of attributes concerning sentence structure are assigned, but also values of attributes for coreferential links in the discourse, which capture certain features typical for the linking of sentences to each other and to the context of situation and allow for a tentative characterization of the discourse pattern in what concerns the development of salience degrees during the discourse. The following attributes of this kind are applied within a selected part of PDT, called &apos;model collection&apos; (for the time being, essentially only pronouns such as </context>
</contexts>
<marker>Krahmer, Theune, 1999</marker>
<rawString>Krahmer E. and M. Theune (1999), Efficient generation of descriptions in context. In: R. Kibble and K. van Deemter (eds.), Proceedings of the workshop The Generation of Nominal Expression, associated with the 11th European Summer School in Logic, Language and Information.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Kruijff-Korbayova</author>
</authors>
<title>The dynamic potential of topic and focus: A Praguian approach to Discourse Representation Theory.</title>
<date>1998</date>
<institution>Charles University, Faculty of Mathematics and Physics,</institution>
<location>Prague:</location>
<note>Ph.D. dissertation.</note>
<marker>Kruijff-Korbayova, 1998</marker>
<rawString>Kruijff-Korbayova I. (1998): The dynamic potential of topic and focus: A Praguian approach to Discourse Representation Theory. Prague: Charles University, Faculty of Mathematics and Physics, Ph.D. dissertation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Sgall</author>
<author>E Hajičova</author>
<author>J Panevova</author>
</authors>
<date>1986</date>
<booktitle>The Meaning of the Sentence in Its Semantic and Pragmatic Aspects,</booktitle>
<editor>ed. by J. L. Mey, Dordrecht:Reidel - Prague:</editor>
<publisher>Academia.</publisher>
<contexts>
<context position="4657" citStr="Sgall et al. 1986" startWordPosition="720" endWordPosition="723">rammatical (underlying) syntactic layer: tectogrammatical tree structures (TGTSs) are being assigned to a subset of the set tagged according to (ii); by now, the experimental phase has resulted in 20 samples of 50 sentences each; the TGTSs, based on dependency syntax, are much simpler than structural trees based on constituency (minimalist or other), displaying a much lower number of nodes and a more perspicuous patterning; their basic characteristics are as follows (a more detailed characterization of tectogrammatics and motivating discussion, which cannot be reproduced here, can be found in Sgall et al. 1986; Hajičova et al. 1998): (a) only autosemantic (lexical) words have nodes of their own; function words, as far as semantically relevant, are reflected by parts of complex node labels (with the exception of coordinating conjunctions); (b) nodes are added in case of deletions on the surface level; (c) the condition of projectivity is met (i.e. no crossing of edges is allowed); (d) tectogrammatical functions (&apos;functors&apos;) such as Actor/Bearer, Patient, Addressee, Origin, Effect, different kinds of Circumstantials are assigned; (e) basic features of TFA are introduced; (f) elementary coreference li</context>
</contexts>
<marker>Sgall, Hajičova, Panevova, 1986</marker>
<rawString>Sgall P., Hajičova E. and J. Panevova (1986): The Meaning of the Sentence in Its Semantic and Pragmatic Aspects, ed. by J. L. Mey, Dordrecht:Reidel - Prague: Academia.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>