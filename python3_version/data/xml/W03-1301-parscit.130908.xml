<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000049">
<title confidence="0.951522">
Gene Name Extraction Using FlyBase Resources
</title>
<author confidence="0.363944">
Alex Morgan The MITRE Corporation Alexander Yeh
</author>
<address confidence="0.403341">
amorgan@mitre.org 202 Burlington Road asy@mitre.org
Lynette Hirschman Bedford, MA 01730-1420 Marc Colosimo
</address>
<email confidence="0.972242">
lynette@mitre.org mcolosim@brandeis.edu
</email>
<sectionHeader confidence="0.99701" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998383961538462">
Machine-learning based entity extraction re-
quires a large corpus of annotated training to
achieve acceptable results. However, the cost
of expert annotation of relevant data, coupled
with issues of inter-annotator variability,
makes it expensive and time-consuming to
create the necessary corpora. We report here
on a simple method for the automatic creation
of large quantities of imperfect training data
for a biological entity (gene or protein) extrac-
tion system. We used resources available in
the FlyBase model organism database; these
resources include a curated lists of genes and
the articles from which the entries were
drawn, together a synonym lexicon. We ap-
plied simple pattern matching to identify gene
names in the associated abstracts and filtered
these entities using the list of curated entries
for the article. This process created a data set
that could be used to train a simple Hidden
Markov Model (HMM) entity tagger. The re-
sults from the HMM tagger were comparable
to those reported by other groups (F-measure
of 0.75). This method has the advantage of be-
ing rapidly transferable to new domains that
have similar existing resources.
</bodyText>
<sectionHeader confidence="0.996244" genericHeader="method">
1 Introduction: Biological Databases
</sectionHeader>
<bodyText confidence="0.9990142">
There is currently an information explosion in
biomedical research. The growth of literature is
roughly exponential, as can be seen in Figure 1
which shows the number of literature references in
FlyBase1 organized by date of publication over a
</bodyText>
<footnote confidence="0.936327">
1 FlyBase is a database that focuses on research in the genetics
and molecular biology of the fruit fly (Drosophila melangas-
</footnote>
<bodyText confidence="0.948042421052632">
hundred year span.2 This growth of literature
makes it daunting for researchers to keep track of
the information, even in very small subfields of
biology.
Increasingly, biological databases serve to collect
and organize published experimental results. A
wide range of biological databases exist, including
model organism databases (e.g., for mouse3 and
yeast4) as well as various protein databases (e.g.,
Protein Information Resource5 (PIR) or SWISS-
PROT6 and interaction databases such as the
Biomolecular Interaction Network Database7
(BIND). These databases are created by a process
of curation, which is done by Ph.D. biologists who
read the published literature to cull experimental
findings and relations. These facts are organized
into a set of structured fields of a database and
tor), a model organism for genetics research:
http://www.flybase.org.
</bodyText>
<footnote confidence="0.99131025">
2 Of course most of these early references in FlyBase are not
in electronic form. The FlyBase database has been in existence
since 1993.
3 http://www.informatics.jax.org/
4 http://genome-www.stanford.edu/Saccharomyces/
5 http://pir.georgetown.edu/pirwww/pirhome3.shtml
6 http://us.expasy.org/sprot/
7 http://www.bind.ca/
</footnote>
<figureCaption confidence="0.999856">
Figure 1: FlyBase References, 1900-2000
</figureCaption>
<bodyText confidence="0.9998148">
linked to the source of information (the journal
article). As a result, curation is a time-consuming
and expensive process; database curators are in-
creasingly eager to adopt text mining and natural
language processing techniques to make curation
faster and more consistent. As a result, there has
been growing interest in the application of entity
extraction and text classification techniques to the
problem of biological database curation [Hirsch-
man02].
</bodyText>
<sectionHeader confidence="0.995026" genericHeader="method">
2 Entity Extraction Methods
</sectionHeader>
<bodyText confidence="0.992436661538462">
There are two approaches to entity extraction. The
first requires manual or heuristic creation of rules
to identify the names mentioned in text; the second
uses machine learning to create the rules that drive
the entity tagging. Heuristic systems require expert
developers to create the rules, and these rules must
be manually changed to handle new domains. Ma-
chine-learning based systems are dependent on
large quantities of tagged data, consisting of both
positive and negative examples.8 Figure 2 shows
results from the IdentiFinder system [Bikel99] il-
lustrating that performance increases roughly with
the log of quantity of training data. Given the ex-
pense of manual annotation of large quantities of
data, the challenge for the machine learning ap-
proach is to find ways of creating sufficient quanti-
ties of training data cheaply.
Overall, hand-crafted systems seem to outper-
form learning-based systems for biology. How-
8 For negative examples, the &amp;quot;closed world&amp;quot; assumption gen-
erally is taken to apply: if an entity is not tagged, it is assumed
to be a negative example.
ever, it is clear that the quantities of training have
been small, relative to the results reported for en-
tity extraction in e.g., newswire [Hirschman03].
There are several published sets of performance
results for automatic named biological entity ex-
traction systems. The system of Collier et al. [Col-
lier00] uses a hidden Markov model to achieve an
F-measure9 of 0.73 when trained on a corpus of
29,940 words of text from 100 MEDLINE ab-
stracts. Contrast this with Figure 2, which reports
results using over 600,000 words of training data,
and an F-measure of 0.95 for English newswire
entity extraction (and 0.91 for Spanish).
Krauthammer et al. [Krauthammer00] have taken a
somewhat different approach which encodes char-
acters as 4-tuples of DNA bases; they then use
BLAST together with a lexicon of gene names to
search for &apos;gene name homologies&apos;. They report an
F-measure of 0.75 without the use of a large set of
rules or annotated training data.
The PASTA system [Gaizauskas03] uses a combi-
nation of heuristic and machine-learned rules to
achieve a higher F-measure over a larger number
of classes: F-measure of 0.83 for the task of identi-
fying 12 classes of entities involved in the descrip-
tion of roles of residues in protein molecules.
Because they used heuristic rules, they were able
to get these results with a relatively small training
corpus of 52 MEDLINE abstracts (roughly 12,000
words).
These results suggest that machine learning meth-
ods will not be able to compete with heuristic rules
until there is a way to generate large quantities of
annotated training data. Biology has the advantage
that there are rich resources available, such as lexi-
cons, ontologies and hand-curated databases.
What is missing is a way to convert these into
training corpora for text mining and natural lan-
guage processing. Craven and Kumlien [Cra-
ven99] developed an innovative approach that used
fields in a biological database to locate abstracts
which mention physiological localization of pro-
teins. Then via a simple pattern matching algo-
</bodyText>
<footnote confidence="0.5981275">
Manning D, Schutze H. Foundations of Statistical Natural
Language Processing, 2002: p 269.
</footnote>
<figureCaption confidence="0.705711666666667">
Figure 2: Performance of BBN&apos;s IdentiFinder named entity
recognition system relative to the amount of training data, from
[Bikel99]
</figureCaption>
<page confidence="0.776831">
9
</page>
<listItem confidence="0.50985">
• Recall)
</listItem>
<equation confidence="0.574393285714286">
=
F
(Precision Recall)
+
2 Precision
•
(
</equation>
<bodyText confidence="0.999919454545455">
rithm, they identified those sentences where the
relation was mentioned and matched these with
entries in the Yeast Protein Database (YPD). In
this way, they were able to automatically create an
annotated gold standard, consisting of sentences
paired with the curated relations derived from
those sentences. They then used these for training
and testing a machine-learning based system. This
approach inspired our interest in using existing
resources to create an annotated corpus automati-
cally.
</bodyText>
<sectionHeader confidence="0.955119" genericHeader="method">
3 FlyBase: Organization and Resources
</sectionHeader>
<bodyText confidence="0.999956339622642">
We focused on FlyBase because we had access to
FlyBase resources from our work in the creation of
the KDD 2002 Cup Challenge Task 1 [Yeh03].
Through this work, we had become familiar with
the multi-stage process of curation. An early task
in the curation pipeline is to determine, for a given
article, whether there are experimental results that
need to be added to the database. This was the task
used as the basis for the KDD text data mining
&amp;quot;challenge evaluation&amp;quot;. A later task in the pipeline
creates a list of the Drosophila genes discussed in
each curated article. This is the task we focus on in
this paper.
An example of a FlyBase entry can be seen in Fig-
ure 3 which shows part of the record for the gene
Toll. Under Molecular Function and Biological
Process we see that the gene is responsible for en-
coding a transmembrane receptor protein involved
in antimicrobial humoral response (part of the
innate immune system of the fly). We see further
that “Tl” and “CG5490” are synonymous for Toll
(top of the entry next to Symbol), and the link
Synonyms leads to a long synonym list which in-
cludes: “Fs(1)Tl”, “dToll”, “CT17414”, “Toll-1”,
“Fs(3)Tl”, “mat(3)9”, “mel(3)10”, and “mel(3)9”.
Many of these facts about Toll are linked to a par-
ticular literature reference in the database. For ex-
ample, following the link for Transcripts will lead
to a page with links to the abstract of a paper by
Tauszig et al. [Tauszig00] which reports on ex-
periments which measured the lengths of RNA
transcribed from the Toll gene.
For FlyBase, Drosophila genes are the key bio-
logical entities; each entity (e.g., gene) is associ-
ated with a unique identifier for the underlying
physical entity. If there were a one-to-one relation-
ship between gene name and unique identifier, the
gene identification task would be straightforward.
However, both polysemy and synonymy occur fre-
quently in the naming of biological entities, and
the gene names of Drosophila are considered to be
particularly problematic because of creative nam-
ing conventions10. For example, “18 wheeler”,
“batman”, and “rutabaga” are all Drosophila gene
names. A single entity (as represented by a unique
identifier) may have a number of names like Toll
or even ATPα, which has 38 synonyms listed in
FlyBase.
We obtained a copy of part the FlyBase database,11
including the lists of genes discussed in each paper
examined by the curators. Using the BioPython12
modules, we were able to obtain MEDLINE ab-
stracts for 15,144 for these papers. We decided to
</bodyText>
<footnote confidence="0.992181571428571">
10 At the other end of the spectrum is the yeast nomenclature
which is strictly controlled – see &lt;http://genome-
www.stanford.edu/Saccharomyces/gene_guidelines.shtml&gt; for
nomenclature conventions.
11 Special thanks to William Gelbart, David Emmert, Beverly
Matthews, Leyla Bayraktaroglu, and Don Gilbert.
12 http://www.biopython.org/
</footnote>
<subsectionHeader confidence="0.3947">
3.1 Resources
</subsectionHeader>
<figureCaption confidence="0.997964">
Figure 3: FlyBase entry for Toll
</figureCaption>
<bodyText confidence="0.999981333333333">
set aside the same articles used in the KDD Cup
Challenge [Yeh03] for evaluation purposes. This
left a training set of 14,033 abstracts, consisting of
a total of 2,664,324 lexemes identified by our
tokenizer.
It was only with some reluctance that we decided
to focus on journal abstracts. From our earlier
work, we recognized that the majority of the in-
formation entered into FlyBase is missing from the
abstracts and can be found only in the full text of
the article [Hirschman03]. However, due to copy-
right restrictions, there is a paucity of freely avail-
able full text for journal articles. What articles are
available in electronic form vary in their format-
ting, which can cause considerable difficulty in
automatic processing. MEDLINE abstracts have a
uniform format and are readily available. Many
other experiments have been performed on
MEDLINE abstracts for similar reasons.
We also created a synonym lexicon from FlyBase.
We found 35,971 genes with associated ‘gene
symbols’ (e.g. Tl is the gene symbol for Toll) and
48,434 synonyms; therefore, each gene has an av-
erage of 2.3 alternate naming forms, including the
gene symbol. The lexicon also allowed us to asso-
ciate each gene with one a unique FlyBase gene
identifier, providing &amp;quot;term normalization.&amp;quot;
</bodyText>
<sectionHeader confidence="0.999847" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999860235294118">
For purposes of evaluation, our task was the identi-
fication of mentions of Drosophila genes in the
text of abstracts. We also included mentions of
protein or transcript where the associated gene
shared the same name. This occurs when, for ex-
ample, the gene name appears as a pre-nominal
modifier, as in &amp;quot;the zygotic Toll protein&amp;quot;. We did
not include mentions of protein complexes because
these are created out of multiple polypeptide
chains with multiple genes (e.g., hemoglobin). We
also did not include families of proteins or genes
(e.g. lectin), particular alleles of a gene, genes
which are not part of the natural Drosophila ge-
nome such as reporter genes (e.g. LacZ), and the
names of genes from other organisms (e.g. sonic
hedgehog, the mammalian gene homologous to the
Drosophila hedgehog gene).13
</bodyText>
<subsectionHeader confidence="0.985414">
4.1 Background
</subsectionHeader>
<bodyText confidence="0.99983298">
Our initial experiment [Hirschman03] had looked
at creating a gene name finder by simple pattern
matching, using the extensive FlyBase list of genes
and their synonyms and identifying each mention
which occurred in the lexicon with the appropriate
unique identifier. This yielded spectacularly poor
results: recall14 on the full papers was quite high
(84%), but precision was 2%! For abstracts, the
recall was predictably lower (31%) and precision
remained low at 7%. Our analysis showed that
polysemy (described in Section 5) and the large
intersection of gene names with common English
words caused most of the performance problems.
In the initial run, where a name was ambiguous,
we recorded all gene identifiers; this raised recall
but lowered precision. After removing all the
names which were ambiguous for a gene, precision
climbed to 5% for full papers and 17% in abstracts,
with a corresponding drop in recall (77% for full
papers, 28% for abstracts). We also tried a few
simple filters, such as ignoring all terms three
characters or less in length, but the best precision
we could achieve was 29% in abstracts, certainly
unacceptable.
We were, however, encouraged by the relatively
high recall in full papers. Analysis showed that
many of the missing names were contained only in
figures or tables that had not been downloaded.
While these were counted as recall errors when
compared to the FlyBase curation, there were, in
fact, no mentions of these genes in the text that had
been downloaded for this experiment. Similarly,
for abstracts, while the recall appeared low com-
pared to the complete set of genes discussed in the
full paper, these genes were simply not mentioned
in the abstract. So from an information extraction
13 There are no curated lists of complexes or families in Fly-
Base, so we did not train a tagger for these tasks. In our man-
ual curation, we did create separate tags for complexes and
families, since we believe that these will be important for fu-
ture tasks.
14 Note that these measures of recall and precision are based
on the list of unique Drosophila genes curated in a paper. This
is quite different from recall and precision measuring the men-
tions of gene names in a paper. We used the measure of
unique genes in a paper because this allowed us to take advan-
tage of the existing FlyBase expert curated resources.
point of view, the simple pattern matching
achieved a very high recall for genes mentioned in
the text being processed.
</bodyText>
<subsectionHeader confidence="0.982524">
4.2 Generating Noisy Training Data
</subsectionHeader>
<bodyText confidence="0.999977307692308">
The initial experiment demonstrated that exact
match using rich lexical resources was not useful
on its own. However, we realized that we could
use the lists of curated genes from FlyBase to con-
strain the possible matches within an abstract – that
is, to &amp;quot;license&amp;quot; the tagging of only those genes
known to occur in the curated full article. Our
hope was that this filtered data would provide large
quantities of cheap but imperfect or noisy training
data.
Our next experiment focused on generating this
large but noisy training corpus. We used our inter-
nal tokenizer, punctoker, originally designed for
use with newswire data. There were some errors in
tokenization, since biological terms have a very
different morphology from newswire– see
[Cohen02] for an interesting discussion of tokeni-
zation issues. Among the problems in tokenization
were uses of &amp;quot;-&amp;quot; instead of white space, or &amp;quot;/&amp;quot; to
separate recombinant genes. However, an informal
examination of errors did not show tokenization
errors to be a significant contributor to the overall
performance of the entity extraction system.
To perform the pattern matching, we created a suf-
fix tree of all the synonyms known to FlyBase for
those genes. This was important, since many bio-
logical entity names are multi-word terms. We
then used longest-extent pattern matching to find
candidate mentions in the abstract of the paper.
The system tagged only terms licensed by the as-
sociated list of genes for the abstract, assigning the
appropriate unique gene identifier. Even with the
FlyBase filtering, this method resulted in some
errors. For example, an examination of an abstract
describing the gene to revealed the unsurprising
result that all the uses of the word &amp;quot;to&amp;quot; did not refer
to the gene. However, the aim was to create data
of sufficient quantity to lessen the effects of this
noise.
</bodyText>
<subsectionHeader confidence="0.984165">
4.3 Evaluation
</subsectionHeader>
<bodyText confidence="0.999140476190476">
In order to measure performance, we created a
small doubly annotated test corpus. We selected a
sample of 86 abstracts and had two annotators
mark these abstracts for gene name mentions as
previously described. Mentions of families and
foreign genes were also identified with different
tags during this process, but not evaluated. One
curator was a professional researcher in biology
with experience as a model organism genome da-
tabase curator (Colosimo). This set of annotations
was taken as the &amp;quot;gold-standard&amp;quot;. The second an-
notator was the system developer with no particu-
lar annotation experience (Morgan). With two
annotators, we were able to measure inter-
annotator agreement (F-measure of 0.87). We also
measured the quality of the automatically created
training data by using the lexical pattern matching
procedure with filtering to generate annotations for
86 abstracts in the test set. The F-measure was
0.83, when compared against the gold standard,
shown in Table 1 below.
</bodyText>
<table confidence="0.999302333333333">
F-measure Precision Recall
Training Data 0.83 0.78 0.88
Quality
Inter- 0.87 0.83 0.91
annotator
Agreement
</table>
<tableCaption confidence="0.99992">
Table 1: Training data quality and inter-annotator agreement
</tableCaption>
<subsectionHeader confidence="0.995937">
4.4 HMM Tagging With Noisy Training Data
</subsectionHeader>
<bodyText confidence="0.999935375">
We now had a large quantity of noisy training data
that we could use to train a statistical tagger. This
methodology is illustrated in Figure 4. We chose
the HMM-based trainable entity tagger phrag15
[Palmer99] to extract the names in text. We
trained phrag on different amounts of training data
and measured performance. Our evaluation metric
was the standard metric used in named entity
</bodyText>
<figureCaption confidence="0.999581">
Figure 4: Schematic of Methodology
</figureCaption>
<figure confidence="0.910805521739131">
15 Phrag is available for download at
http://www.openchannelfoundation.org/projects/Qanda
Abstracts
from
PubMed
Lexicon
FlyBase
Large Quantity
of Noisy
Training Data
Text automatically tagged using
FlyBase references and a lexicon is
used to train up a tagger capable of
tagging gene names in new text,
including gene names never observed
before.
Start End
Other1 Other2
Gene1 Gene2
Trainable
Tagger
Genes Tagged
Plain Text
</figure>
<bodyText confidence="0.999974567567567">
evaluation, requiring the matching of a name&apos;s ex-
tent and tag (except that for our experiment, we
were only concerned with one tag, Drosophila
gene). Extent matching meant exact matching of
gene name boundaries at the level of tokens: Ex-
actly matching boundaries were considered a hit.
Inexact answers are considered a miss. For exam-
ple, a multiword gene name such as &amp;quot;fas receptor&amp;quot;,
which has been tagged for &amp;quot;fas&amp;quot; but not for &amp;quot;recep-
tor&amp;quot; would constitute a miss (recall error) and a
false alarm (precision error).
Table 2 shows the performance of the basic system
as a function of the amount of training data. As
with Figure 2, we see there is a diminishing return
as the amount of training data is increased. At 2.6
million words or training data, phrag achieved an
entity identification F-measure of 73%. We then
made a simple modification of the algorithm to
correct for variations in orthography due to capi-
talization and representation of Greek letters: we
simply expanded the search for letters such as &amp;quot;∆&amp;quot;
to include &amp;quot;Delta&amp;quot; and &amp;quot;delta&amp;quot;. By expanding the
matching of terms using the orthographical and
case variants, performance of phrag improved
slightly, shown in Table 3, improving our best
performance to an F-measure of 75%.
Figure 5 shows these results in a graphical form.
Two things are apparent from this graph. Based on
the results shown in Figure 2, we might expect the
performance to be linear with the logarithm of the
amount of training data, and in this case there is a
rough fit with a correlation coefficient of .88. The
other result which stands out is that there is con-
siderable variation in the performance when train-
ed on different training sets of the same size. We
believe that this is due to the very limited amount
of testing data.
</bodyText>
<sectionHeader confidence="0.998228" genericHeader="method">
5 Error Analysis
</sectionHeader>
<bodyText confidence="0.919290925925926">
We have identified three types of polysemy in
Drosophila gene names in FlyBase. In some cases,
one name (e.g., “Clock”) can refer to two distinct
genes: period or Clock. The term with the most
polysemy is “P450” which is a family of genes and
is listed as a synonym for 20 different genes in
FlyBase. In addition, the same term is often used
interchangeably to refer to the gene, RNA tran-
script, or the protein. [Hazivassloglou01] presents
interesting results that demonstrate that experts
only agree 78% of the time on whether a particular
mention refers to a gene or a protein.16 The most
problematic type of polysemy occurs because
many Drosophila gene names are also regular Eng-
lish words such as &amp;quot;white&amp;quot;, “cycle”, and &amp;quot;bizarre&amp;quot;.
There are some particularly troublesome examples
that occur because of frequent use of short forms
(abbreviations) of gene names, e.g., &amp;quot;we&amp;quot;, &amp;quot;a&amp;quot;,
&amp;quot;not”, and even “and” each occur as gene names.
These short forms are often abbreviations for the
full gene name. For example, the gene symbol of
the gene takeout is &amp;quot;to&amp;quot;, and the symbol for the
16 The entity tagging task for FlyBase was defined to extract
gene-or-protein names; however, in cases where the article
talks only about the protein and not about the gene, the protein
name may not appear on the list of curated genes for the arti-
cle, leading to apparent false positives in tagging.
</bodyText>
<figureCaption confidence="0.992813333333333">
Figure 5: Performance as a function of the amount of train-
ing data. The line is a least-squares logarithmic fit with an
R2 value of .8814.
</figureCaption>
<figure confidence="0.896507272727273">
F-measure
0.78
0.76
0.74
0.72
0.68
0.66
0.64
0.62
0.7
100000 1000000 10000000
</figure>
<table confidence="0.987367375">
Training Data (# of Lexemes)
No Orthographic Correction
Training Data F-measure Precision Recall
531522 0.62 0.73 0.54
529760 0.64 0.75 0.56
1342039 0.72 0.80 0.65
2664324 0.73 0.79 0.67
Table 2: Performance as a function of training data
Orthographic Correction
Training Data F-measure Precision Recall
531522 0.65 0.76 0.56
529760 0.66 0.74 0.59
522825 0.67 0.76 0.59
1322285 0.72 0.77 0.67
1342039 0.75 0.80 0.70
2664324 0.75 0.78 0.71
</table>
<tableCaption confidence="0.99253">
Table 3: Improved performance with orthographical correction
</tableCaption>
<bodyText confidence="0.992106548387097">
for Greek letters and case folding for term matching in training
data
gene wee is &amp;quot;we&amp;quot;. It may be that more sophisti-
cated handling of abbreviations can address some
of these issues.
An error analysis looking at the results of our sta-
tistical tagger demonstrated some unusual behav-
ior. Because our gene name tagger phrag uses a
first order Markov model, it relies on local context
and occasionally makes errors such as not tagging
all of the occurrences of the term &amp;quot;rutabaga&amp;quot; in an
abstract about rutabaga as gene names. This cer-
tainly opens up the opportunity for some sort of
post processing step to resolve these problems.
The fact that phrag uses this local context can
sometimes be a strength, enabling it to identify
gene names it has never seen. We estimated the
ability of the system to identify new terms as gene
names by substituting strings unknown to phrag in
place of all the occurrences of gene names in the
evaluation data. The performance of the system at
correctly identifying terms it had never observed
gave a precision of 68%, a recall of 22% and an F-
measure of 33%. This result is relatively encour-
aging, compared with the 3.3% precision and 4.4%
recall for novel gene names reported by Krau-
thammer. Recognizing novel names is important
because the nomenclature of biological entities is
constantly changing and entity tagging systems
should to be able to rapidly adapt and recognize
new terms.
</bodyText>
<sectionHeader confidence="0.99842" genericHeader="conclusions">
6 Conclusion and Future Directions
</sectionHeader>
<bodyText confidence="0.999990333333334">
We have demonstrated that we can automatically
produce large quantities of relatively high quality
training data; these data were good enough to train
an HMM-based tagger to identify gene mentions
with an F-measure of 75% (precision of 78% and
recall of 71%), evaluated on our small develop-
ment test set of 86 abstracts. This compares fa-
vorably with other reported results as described in
Section 2, and as discussed below, we believe that
we can improve upon these results in various ways.
These results are still considerably below the re-
sults from [Gaizauskas03] and may be too low to
be useful as a building block for further automated
processing, such as relation extraction. However,
in the absence of any shared benchmark evaluation
sets, cross-system performance cannot be evalu-
ated since the task definition and evaluation cor-
pora differ from system to system.
We plan to take this work in several directions.
First, we believe that we can improve the quality of
the underlying automatically generated data, and
with this, the quality of the entity tagging. There
are several things that could be improved.
A morphological analyzer trained for biological
text would eliminate some of the tokenization er-
rors and perhaps capture some of the underlying
regularities, such as addition of Greek letters or
numbers (with or without preceding hyphen) to
specify sub-types within a gene family. There can
also be considerable semantic content in gene
names and their formatting. For example, many
Drosophila genes are differentiated from the genes
of other organisms by prepending a &amp;quot;d&amp;quot; or &amp;quot;D&amp;quot;,
such as &amp;quot;dToll&amp;quot;. Gene names can also be explicit
descriptions of their chromosomal location or even
function (e.g. Dopamine receptor).
The problem of matching abbreviations has been
tackled by a number of researchers [e.g. Puste-
jovsky02 and Liu03]. As was mentioned above, it
seems that ambiguity for &amp;quot;short forms&amp;quot; of gene
names could be partially resolved by detecting lo-
cal definitions for abbreviations. It should also be
possible to apply part of speech tagging and corpus
statistics to avoid mis-tagging of common words,
such as “to” or “and”.
In the longer term, this methodology provides an
opportunity to go beyond gene name tagging for
Drosophila. It can be extended to other domains
that have comparable resources (e.g. other model
organism genome databases, other biological enti-
ties), and entity tagging itself provides the founda-
tion for more complex tasks, such as relation
extraction (e.g. using the BIND database) or attrib-
ute extraction (e.g. using FlyBase to identify at-
tributes such as RNA transcript length, associated
with protein coding genes).
Second, the existence of a synonym lexicon with
unique identifiers provides data for term normali-
zation, a task of potentially greater utility to biolo-
gists than the tagging of every mention in an
article. There are currently few corpora with anno-
tated term normalization; using the methodology
outlined here makes it possible to produce large
quantities of normalized data. The identification
and characterization of abbreviations and other
transformations would be particularly important in
normalization.
By exploiting the rich set of biological resources
that already exist, it should be possible to generate
many kinds of corpora useful for training high-
quality information extraction and text mining
components.
</bodyText>
<sectionHeader confidence="0.999186" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999817403846154">
Bikel D, Schwartz R, Weischedel R. An Algorithm that
Learns What&apos;s in a Name. Machine Learning, Special
Issue on Natural Language Learning 34 (1999):211-31.
Cohen KB, Dolbey A, Hunter L. “Contrast and variabil-
ity in gene names.” Proceedings of the workshop on
natural language processing in the biomedical domain,
Association for Computational Linguistics, 2002
Collier N, Nobata C, Tsujii J. “Extracting the Names of
Genes and Gene Products with a Hidden Markov
Model.” Proceedings of COLING &apos;2000 (2000): 201-07.
Craven M, Kumlien J. “Constructing Biological Knowl-
edge Bases by Extracting Information from Text
Sources.” Proceedings of the Seventh International
Conference on Intelligent Systems for Molecular Biol-
ogy 1999: 77-86.
Gaizauskas R, Demetriou G, Artymiuk PJ, Willett P.
“Protein Structures and Information Extraction from
Biological Texts: The PASTA System.” Bioinformatics.
19 (2003): 135-43.
Hatzivassiloglou V, Duboue P, Rzhetsky A. “Disam-
biguating Proteins, Genes, and RNA in Text: A Ma-
chine Learning Approach.” Bioinformatics 2001: 97-
106.
Hirschman L, Park J, Tsujii J, Wong L, Wu C. &amp;quot;Accom-
plishments and Challenges in Literature Data Mining
for Biology,&amp;quot; Bioinformatics 17 (2002):1553-61.
Hirschman L, Morgan A, Yeh A. “Rutabaga by Any
Other Name: Extracting Biological Names.&amp;quot; Accepted,
Journal of Biomedical Informatics, Spring 2003.
Krauthammer M, Rzhetsky A, Morosov P, Friedman C.
“Using BLAST for Identifying Gene and Protein Names
in Journal Articles.” Gene 259 (2000): 245-52.
Liu H, Friedman C. “Mining Terminological Knowl-
edge in Large Biomedical Corpora.” Proceedings of the
Pacific Symposium on Biocomputing. 2003.
Palmer D, Burger J, and Ostendorf M. &amp;quot;Information
Extraction from Broadcast News Speech Data.&amp;quot; Pro-
ceedings of the DARPA Broadcast News and Under-
standing Workshop, 1999.
Pustejovsky J, Castaño J, Saurí R, Rumshisky A, Zhang
J, Luo W. “Medstract: Creating Large-scale Information
Servers for Biomedical Libraries.” Proceedings of the
ACL 2002 Workshop on Natural Language Processing
in the Biomedical Domain. 2002.
Tauszig et al. “Toll-related receptors and the control of
antimicrobial peptide expression in Drosophila.” Pro-
ceedings of the National Academy of Sciences 97
(2000): 10520-5.
Yeh A., Hirschman L, Morgan A. &amp;quot;Evaluation of Text
Data Mining for Database Curation: Lessons Learned
from the KDD Challenge Cup.&amp;quot; Accepted, Intelligent
Systems in Molecular Biology, Brisbane, June 2003.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.534550">
<title confidence="0.999628">Gene Name Extraction Using FlyBase Resources</title>
<author confidence="0.748945333333333">Morgan MITRE Corporation Yeh Burlington Road Hirschman MA</author>
<email confidence="0.992698">lynette@mitre.orgmcolosim@brandeis.edu</email>
<abstract confidence="0.999907407407407">Machine-learning based entity extraction requires a large corpus of annotated training to achieve acceptable results. However, the cost of expert annotation of relevant data, coupled with issues of inter-annotator variability, makes it expensive and time-consuming to create the necessary corpora. We report here on a simple method for the automatic creation of large quantities of imperfect training data for a biological entity (gene or protein) extraction system. We used resources available in the FlyBase model organism database; these resources include a curated lists of genes and the articles from which the entries were drawn, together a synonym lexicon. We applied simple pattern matching to identify gene names in the associated abstracts and filtered these entities using the list of curated entries for the article. This process created a data set that could be used to train a simple Hidden Markov Model (HMM) entity tagger. The results from the HMM tagger were comparable to those reported by other groups (F-measure of 0.75). This method has the advantage of being rapidly transferable to new domains that have similar existing resources.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>D Bikel</author>
<author>R Schwartz</author>
<author>R Weischedel</author>
</authors>
<title>An Algorithm that Learns What&apos;s in a Name.</title>
<journal>Machine Learning, Special Issue on Natural Language Learning</journal>
<volume>34</volume>
<pages>1999--211</pages>
<marker>Bikel, Schwartz, Weischedel, </marker>
<rawString>Bikel D, Schwartz R, Weischedel R. An Algorithm that Learns What&apos;s in a Name. Machine Learning, Special Issue on Natural Language Learning 34 (1999):211-31.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cohen KB</author>
<author>A Dolbey</author>
<author>L Hunter</author>
</authors>
<title>Contrast and variability in gene names.”</title>
<date>2002</date>
<booktitle>Proceedings of the workshop on natural language processing in the biomedical domain, Association for Computational Linguistics,</booktitle>
<marker>KB, Dolbey, Hunter, 2002</marker>
<rawString>Cohen KB, Dolbey A, Hunter L. “Contrast and variability in gene names.” Proceedings of the workshop on natural language processing in the biomedical domain, Association for Computational Linguistics, 2002</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Collier</author>
<author>C Nobata</author>
<author>J Tsujii</author>
</authors>
<title>Extracting the Names of Genes and Gene Products with a Hidden Markov Model.”</title>
<date>2000</date>
<booktitle>Proceedings of COLING</booktitle>
<pages>201--07</pages>
<marker>Collier, Nobata, Tsujii, 2000</marker>
<rawString>Collier N, Nobata C, Tsujii J. “Extracting the Names of Genes and Gene Products with a Hidden Markov Model.” Proceedings of COLING &apos;2000 (2000): 201-07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Craven</author>
<author>J Kumlien</author>
</authors>
<title>Constructing Biological Knowledge Bases by Extracting Information from Text Sources.”</title>
<date>1999</date>
<booktitle>Proceedings of the Seventh International Conference on Intelligent Systems for Molecular Biology</booktitle>
<pages>77--86</pages>
<marker>Craven, Kumlien, 1999</marker>
<rawString>Craven M, Kumlien J. “Constructing Biological Knowledge Bases by Extracting Information from Text Sources.” Proceedings of the Seventh International Conference on Intelligent Systems for Molecular Biology 1999: 77-86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Gaizauskas</author>
<author>G Demetriou</author>
<author>Artymiuk PJ</author>
<author>P Willett</author>
</authors>
<title>Protein Structures and Information Extraction from Biological Texts: The PASTA System.” Bioinformatics.</title>
<date>2003</date>
<volume>19</volume>
<pages>135--43</pages>
<marker>Gaizauskas, Demetriou, PJ, Willett, 2003</marker>
<rawString>Gaizauskas R, Demetriou G, Artymiuk PJ, Willett P. “Protein Structures and Information Extraction from Biological Texts: The PASTA System.” Bioinformatics. 19 (2003): 135-43.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Hatzivassiloglou</author>
<author>P Duboue</author>
<author>A Rzhetsky</author>
</authors>
<title>Disambiguating Proteins, Genes, and RNA in Text: A Machine Learning Approach.” Bioinformatics</title>
<date>2001</date>
<pages>97--106</pages>
<marker>Hatzivassiloglou, Duboue, Rzhetsky, 2001</marker>
<rawString>Hatzivassiloglou V, Duboue P, Rzhetsky A. “Disambiguating Proteins, Genes, and RNA in Text: A Machine Learning Approach.” Bioinformatics 2001: 97-106.</rawString>
</citation>
<citation valid="false">
<authors>
<author>L Hirschman</author>
<author>J Park</author>
<author>J Tsujii</author>
<author>L Wong</author>
<author>C Wu</author>
</authors>
<title>Accomplishments and Challenges in Literature Data Mining for Biology,&amp;quot;</title>
<journal>Bioinformatics</journal>
<volume>17</volume>
<pages>2002--1553</pages>
<marker>Hirschman, Park, Tsujii, Wong, Wu, </marker>
<rawString>Hirschman L, Park J, Tsujii J, Wong L, Wu C. &amp;quot;Accomplishments and Challenges in Literature Data Mining for Biology,&amp;quot; Bioinformatics 17 (2002):1553-61.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Hirschman</author>
<author>A Morgan</author>
<author>A Yeh</author>
</authors>
<title>Rutabaga by Any Other Name: Extracting Biological Names.&amp;quot; Accepted,</title>
<date>2003</date>
<journal>Journal of Biomedical Informatics, Spring</journal>
<marker>Hirschman, Morgan, Yeh, 2003</marker>
<rawString>Hirschman L, Morgan A, Yeh A. “Rutabaga by Any Other Name: Extracting Biological Names.&amp;quot; Accepted, Journal of Biomedical Informatics, Spring 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Krauthammer</author>
<author>A Rzhetsky</author>
<author>P Morosov</author>
<author>C Friedman</author>
</authors>
<title>Using BLAST for Identifying Gene and Protein Names in</title>
<date>2000</date>
<journal>Journal Articles.” Gene</journal>
<volume>259</volume>
<pages>245--52</pages>
<marker>Krauthammer, Rzhetsky, Morosov, Friedman, 2000</marker>
<rawString>Krauthammer M, Rzhetsky A, Morosov P, Friedman C. “Using BLAST for Identifying Gene and Protein Names in Journal Articles.” Gene 259 (2000): 245-52.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Liu</author>
<author>C Friedman</author>
</authors>
<title>Mining Terminological Knowledge</title>
<date>2003</date>
<booktitle>in Large Biomedical Corpora.” Proceedings of the Pacific Symposium on Biocomputing.</booktitle>
<marker>Liu, Friedman, 2003</marker>
<rawString>Liu H, Friedman C. “Mining Terminological Knowledge in Large Biomedical Corpora.” Proceedings of the Pacific Symposium on Biocomputing. 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Palmer</author>
<author>J Burger</author>
<author>M Ostendorf</author>
</authors>
<title>Information Extraction from Broadcast News Speech Data.&amp;quot;</title>
<date>1999</date>
<booktitle>Proceedings of the DARPA Broadcast News and Understanding Workshop,</booktitle>
<marker>Palmer, Burger, Ostendorf, 1999</marker>
<rawString>Palmer D, Burger J, and Ostendorf M. &amp;quot;Information Extraction from Broadcast News Speech Data.&amp;quot; Proceedings of the DARPA Broadcast News and Understanding Workshop, 1999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Pustejovsky</author>
<author>J Castaño</author>
<author>R Saurí</author>
<author>A Rumshisky</author>
<author>J Zhang</author>
<author>W Luo</author>
</authors>
<title>Medstract: Creating Large-scale Information Servers for Biomedical Libraries.”</title>
<date>2002</date>
<booktitle>Proceedings of the ACL 2002 Workshop on Natural Language Processing in the Biomedical Domain.</booktitle>
<marker>Pustejovsky, Castaño, Saurí, Rumshisky, Zhang, Luo, 2002</marker>
<rawString>Pustejovsky J, Castaño J, Saurí R, Rumshisky A, Zhang J, Luo W. “Medstract: Creating Large-scale Information Servers for Biomedical Libraries.” Proceedings of the ACL 2002 Workshop on Natural Language Processing in the Biomedical Domain. 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tauszig</author>
</authors>
<title>Toll-related receptors and the control of antimicrobial peptide expression</title>
<date>2000</date>
<booktitle>in Drosophila.” Proceedings of the National Academy of Sciences</booktitle>
<volume>97</volume>
<pages>10520--5</pages>
<marker>Tauszig, 2000</marker>
<rawString>Tauszig et al. “Toll-related receptors and the control of antimicrobial peptide expression in Drosophila.” Proceedings of the National Academy of Sciences 97 (2000): 10520-5.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Yeh</author>
<author>L Hirschman</author>
<author>A Morgan</author>
</authors>
<title>Evaluation of Text Data Mining for Database Curation: Lessons Learned from the KDD Challenge Cup.&amp;quot; Accepted, Intelligent Systems in Molecular Biology,</title>
<date>2003</date>
<location>Brisbane,</location>
<marker>Yeh, Hirschman, Morgan, 2003</marker>
<rawString>Yeh A., Hirschman L, Morgan A. &amp;quot;Evaluation of Text Data Mining for Database Curation: Lessons Learned from the KDD Challenge Cup.&amp;quot; Accepted, Intelligent Systems in Molecular Biology, Brisbane, June 2003.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>