<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.011796">
<title confidence="0.9952905">
A Summariser based on Human Memory Limitations and
Lexical Competition
</title>
<author confidence="0.996457">
Yimai Fang
</author>
<affiliation confidence="0.991424">
Computer Laboratory
University of Cambridge
</affiliation>
<address confidence="0.956828">
15 JJ Thomson Avenue, CB3 0FD, UK
</address>
<email confidence="0.99732">
Yimai.Fang@cl.cam.ac.uk
</email>
<author confidence="0.994489">
Simone Teufel
</author>
<affiliation confidence="0.99109">
Computer Laboratory
University of Cambridge
</affiliation>
<address confidence="0.957123">
15 JJ Thomson Avenue, CB3 0FD, UK
</address>
<email confidence="0.997921">
Simone.Teufel@cl.cam.ac.uk
</email>
<sectionHeader confidence="0.993821" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999847176470588">
Kintsch and van Dijk proposed a model
of human comprehension and summarisa-
tion which is based on the idea of pro-
cessing propositions on a sentence-by-
sentence basis, detecting argument over-
lap, and creating a summary on the basis
of the best connected propositions. We
present an implementation of that model,
which gets around the problem of identi-
fying concepts in text by applying coref-
erence resolution, named entity detection,
and semantic similarity detection, imple-
mented as a two-step competition. We
evaluate the resulting summariser against
two commonly used extractive summaris-
ers using ROUGE, with encouraging re-
sults.
</bodyText>
<sectionHeader confidence="0.99899" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999823272727273">
Kintsch and van Dijk (1978) (henceforth KvD)
present a model of human comprehension and
memory retention which is based on research in ar-
tificial intelligence, experimental psychology and
discourse linguistics. It models the processing of
incoming text or speech by human memory lim-
itations, and makes verifiable predictions about
which propositions in a text will be recalled by
subjects later. It has been very influential, particu-
larly in the 1980 and 1990s in educational (Palin-
scar and Brown, 1984; King, 1992) and cognitive
(Paivio, 1990) psychology, and is still today used
as a theoretical model of reading and comprehen-
sion (Baddeley, 2007; Zwaan, 2003; DeLong et
al., 2005; Smith, 2004). It has also been used for
improving education, particularly for the produc-
tion of better instructional text (Britton and Gul-
goz, 1991; Pressley, 2006), and for teaching hu-
mans how to read for deep comprehension (Coiro
and Dobler, 2007; Duke and Pearson, 2002; Koda,
2005; Driscoll, 2005) and to summarise (Hidi,
1986; Brown et al., 1983).
In the summarisation community, the model has
been commended for its elegant and explana-
tory “deep” treatment of the summarisation pro-
cess (Lehnert, 1981; Sp¨arck Jones, 1993; Endres-
Niggemeyer, 1998), but has not lead to any prac-
tical prototypes, mainly due the impossibility of
implementing the knowledge- and inference-based
aspects the model relies on.
We present here an implementation of the model,
which attempts to circumvent some of these prob-
lems by the application of distributional seman-
tics, and by modelling the construction of the co-
herence tree as a double competition (firstly of
concept partners for word forms, secondly of at-
tachment sites for propositions).
In the KvD model, a text (e.g. Figure 1) is con-
verted into propositions (see Table 1) which have
one functor and one or more arguments. The func-
tor can be taken either from a fixed list of gram-
matical relations (e.g. IS A; AT; BETWEEN; OR)
or an open class-set of so-called concepts, (e.g.
BLOODY; TEACH). Arguments can be concepts
or proposition numbers. Proposition numbers ex-
press embedded semantic structures (e.g. #9 in
Table 1). Kintsch et al. (1979) assumed that this
tranformation is performed manually; they were
able to train humans to do so consistently.
A series of violent, bloody encounters between police
and Black Panther members punctuated the early sum-
mer days of 1969. Soon after, a group of black students
I teach at California State College, Los Angeles, who
were members of the Panther Party, began to complain
of continuous harassment by law enforcement officers.
</bodyText>
<figureCaption confidence="0.7717025">
Figure 1: First two sentences from the example
paragraph Bumperstickers by KvD (1978).
</figureCaption>
<page confidence="0.925575">
732
</page>
<note confidence="0.997503">
Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 732–741,
Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics
</note>
<figure confidence="0.976538416666667">
No. Proposition
Cycle 1
1 SERIES (ENCOUNTER)
2 VIOLENT (ENCOUNTER)
3 BLOODY (ENCOUNTER)
4 BETWEEN (ENCOUNTER, POLICE, BLACK PAN-
THER)
5 TIME: IN (ENCOUNTER, SUMMER)
6 EARLY (SUMMER)
7 TIME: IN (SUMMER, 1969)
Cycle 2
8 SOON (#9)
9 AFTER (#4, #16)
10 GROUP (STUDENT)
11 BLACK (STUDENT)
12 TEACH (SPEAKER, STUDENT)
13 LOCATION: AT (#12, CAL STATE COLLEGE)
14 LOCATION: AT (CAL STATE COLLEGE, LOS
ANGELES)
15 IS A (STUDENT, BLACK PANTHER)
16 BEGIN (#17)
17 COMPLAIN (STUDENT, #19)
18 CONTINUOUS (#19)
19 HARASS (POLICE, STUDENT)
</figure>
<tableCaption confidence="0.946122">
Table 1: Propositions for Figure 1.
</tableCaption>
<bodyText confidence="0.999878119047619">
The KvD algorithm is manually simulated in their
work, but is described in a mechanistic manner
that should in principle lend itself to implemen-
tation, once propositions are created. Propositions
form a tree where a proposition is attached to an-
other proposition with which they share at least
one argument; attachment higher in the tree is pre-
ferred. The tree is built incrementally; blocks of
propositions, each of which roughly correspond-
ing to one sentence, are processed in cycles. Af-
ter each cycle, a process of “forgetting” is sim-
ulated by copying only the most salient proposi-
tions to the short-term memory (STM). This se-
lection is performed by the so-called leading edge
strategy (LES), which prefers propositions that
are attached more recently and those attached at
higher positions. This algorithms mirrors van
Dijk’s (1977) model of textual coherence.
When choosing an attachment site for proposition,
arguments which are currently in STM are pre-
ferred. A resource-consuming search in long-term
memory (LTM) is only triggered if a proposition
cannot be attached in STM; in that case a bridging
proposition is reintroduced into the tree.
The KvD model can be used to explain human re-
call of stories, and can also to create a summary of
a text. The most natural way for a human to sum-
marise from scratch is to replace propositions with
so-called macropropositions, and the KvD model
prefers this style of summary creation. An exam-
ple for macroproposition is a statement that gen-
eralises over other propositions. This results in a
more abstract version of the text. However if for
any reason it is not possible to create macropropo-
sitions (for instance due to lack of deep knowledge
representation), a summary can also be created in
a simpler way based only on the propositions con-
tained in the text. In that case, the selection cri-
terion is the number of cycles a proposition has
remained in STM.
There are three main stumbling blocks in the way
of an implementation of the KvD model:
</bodyText>
<listItem confidence="0.99309275">
1. The automatic creation of propositions from
text, and of summary text from summary
propositions;
2. The automatic creation of concepts from
words (including coreference resolution);
3. The creation of macropropositions, which
would require sophisticated knowledge rep-
resentation and reasoning.
</listItem>
<bodyText confidence="0.85024">
We present a fully automatic version of the KvD
model based on the following assumptions:
</bodyText>
<listItem confidence="0.99606996">
1. Current parser technology allows us to recon-
struct the compositional semantics of the text
well enough to make the KvD model opera-
tional, both in terms of creating propositions
from text, and in terms of creating reasonably
understandable output text from propositions
(even if not fully grammatical).
2. We model the lexical variation of how a con-
cept is expressed in a text probabilistically
by semantic similarity and coreference reso-
lution. This creates a competition between
plausible expressions for argument overlap.
3. Our core algorithm is modelled as two com-
petitions: (a) the competition between con-
cept matches as mentioned in the point
above; and (b) the competition between pos-
sible positions in a tree where a proposition
could attach.
4. We also observed that KvD’s method of
choosing the tree root in the first processing
cycle, and to never change it afterwards un-
less texts are truly incoherent (resorting to
multiple trees), is too limiting, in particu-
lar in combination with their LES. Texts can
have topic changes and still be perfectly co-
</listItem>
<page confidence="0.99815">
733
</page>
<bodyText confidence="0.999924625">
herent, particularly if they are longer and less
linearly structured than the examples used
by KvD. We therefore experiment with more
flexible root choice strategies.
We have nothing to say on the third and biggest
obstacle, the creation of macropropositions. Nev-
ertheless, the experiments presented here test
whether our hypotheses 1 – 4 are strong enough
to provide our summariser with useful informa-
tion concerning the discourse structure of the texts.
We test this by comparing its performance to that
of two current state-of-the-art summarisers, which
instead rely on the sole use of lexical informa-
tion. A psychologically-motivated summariser
such as ours should be evaluated by compari-
son to abstractive, i.e., reformulated human sum-
maries, rather than by comparison to extractive
summaries. We do so using ROUGE, an evalu-
ation framework that supports such comparisons
(Lin and Hovy, 2003).
The structure of the paper is as follows. In the
next section, we will detail our implementation of
the KvD model, with particular emphasis on the
creation of propositions, probabilistic concepts,
proposition attachment, and root choice. In Sec-
tion 4, we will present experiments comparing our
summariser against two research extractive sum-
marisers, MEAD and LexRank. We also test how
our inventions including similarity-based concept
matching and root choice strategy contribute to
performance. We compare to related work in Sec-
tion 3, and draw our conclusions in Section 5.
</bodyText>
<sectionHeader confidence="0.902467" genericHeader="introduction">
2 Our implementation of KvD
</sectionHeader>
<bodyText confidence="0.999602666666667">
Figure 2 shows the structure of our summariser.
The Proposition Creation module transforms sur-
face text to propositions with the aid of a grammat-
ical parser. Recall that in the original KvD model
(shown as “Human (KvD)”), propositions are gen-
erated manually. Apart from such, our implemen-
tation follows the KvD algorithm as closely as
possible. The core of this algorithm is the Mem-
ory Retention Cycle in the centre of the figure.
A cycle begins with the detection of coherence be-
tween the new propositions and the current STM
content. This results in a hierarchy of all so-far
processed propositions called the Coherence Tree.
Propositions are attached to the tree by a variety of
strategies, as explained in Subsection 2.2.
</bodyText>
<figureCaption confidence="0.996446">
Figure 2: Framework of the summariser.
</figureCaption>
<bodyText confidence="0.999990578947368">
At the end of each cycle, important propositions
(IPs) are selected by the Selector, stored in STM,
and thus retained for the next cycle, where they are
available for new incoming propositions to attach
to. The selector is a full implementation of KvD’s
LES, which also updates the recency of proposi-
tions reinstantiated from the LTM.1 Less impor-
tant propositions leave the cycle and go into the
LTM, which is conceptually a secondary reposi-
tory of propositions to provide the “missing links”
when no coherence between the STM and the in-
coming propositions can be established.
After the text is consumed, a propositional repre-
sentation of the summary is created by recalling
the propositions that were retained in STM most
frequently. The summary text is then either cre-
ated manually (in the KvD model), or in our im-
plementation, as a prototype, automatically by ex-
tracting words from the parser’s dependencies.
</bodyText>
<subsectionHeader confidence="0.999285">
2.1 Proposition builder
</subsectionHeader>
<bodyText confidence="0.999986666666667">
We aim to create propositions of comparable se-
mantic weight to each other. This is a consequence
of our decision to recast KvD as a competition
model (as will become clear in subsection 2.2),
because by defining propositions as blocks of ar-
guments they should contain a similar number of
</bodyText>
<footnote confidence="0.934834333333333">
1KvD implied this in the last cycle of the Bumperstick-
ers paragraph, by placing the two reinstantiated propositions
below #37, though they are older than #37.
</footnote>
<figure confidence="0.998380956521739">
Proposition Creation
Memory Retention Cycle
Proposition to text
Dependencies
Proposition
Builder
IPs in STM
Coherence
Detector
Extractor
Input: Full text
Parser
Each sentence
Output: Summary text
Summary propositions
Most frequent ones
Propositions
Human (KvD)
Human (KvD)
Coherence
Tree
Selector
LTM
</figure>
<page confidence="0.99206">
734
</page>
<bodyText confidence="0.999946568181818">
meaningful arguments to ensure similar potential
for overlap.
To achieve suitable granularity of propositions,
we aggregate information spread out over several
grammatical dependencies, and exclude semanti-
cally empty words from participating in argument
overlap. We use Stanford Parser (Klein and Man-
ning, 2003), and aggregate subjects and comple-
ments of a predicate into a single proposition. Ac-
tive and passive voices are unified; clauses are
treated as embedded propositions; controlling sub-
jects of open clausal complements are recovered.
Some predicates are not verbs, but nominalised
verbs or coordination. For instance, KvD model
the phrase “ encounters between police and Black
Panther Party members ” as BETWEEN (EN-
COUNTER, POLICE, BLACK PANTHER). Produc-
ing such a proposition instead of two separate
ones BETWEEN (ENCOUNTER, POLICE) and BE-
TWEEN (ENCOUNTER, BLACK PANTHER) is ad-
vantageous, because this single proposition pro-
vides a strong connection between POLICE and
BLACK PANTHER which cannot be derived from
other dependencies.
However we lack a subcategorisation lexicon that
provides information about how many arguments
a preposition like “between” takes. Therefore we
scan conjoined prepositional phrases, aggregate
the objects, and attach them to the governors of the
prepositional phrases. In this example, the result-
ing preposition is ENCOUNTER (POLICE, MEM-
BER). The word “between” is excluded because it
is semantically empty and may interfere with over-
lap detection.
We take care to detect and exclude semantically
empty material. For instance, the empty semantic
heads in noun phrases such as “a series of” and “a
group of” are detected using a list of of 21 words
we collected, and treated by redirecting the depen-
dencies involving the empty heads to the corre-
sponding content heads. In this treatment, the rela-
tion between an empty head and its content head is
not entirely erased, but encoded as a general mod-
ifier relation.
</bodyText>
<subsectionHeader confidence="0.996034">
2.2 Probabilistic concept matching
</subsectionHeader>
<bodyText confidence="0.999934612903226">
The notion of argument overlap in KvD’s model
is sophisticated in that it “knows” which surface
expressions (pronouns, synonyms, etc) in text re-
fer to the same concept. Concept mapping is the
task of forming equivalence classes of surface ex-
pressions; each concept then corresponds to one
such equivalence class. The KvD model, because
it simulates concept mapping and proposition at-
tachment in parallel, conceals some of the choices
that a fully automatic model has to make.
Given current technology, concept mapping can
only be performed probabilistically. We use the
Stanford coreference resolution, named-entity de-
tection (to extend coreference detection to non-
same-head references, e.g. mapping “the tech
giant” to “Apple Inc.”2); and to find synonymy
or at least semantic relatedness, we use a well-
known measure of semantic similarity, namely
Lin’s Dependency-Based Thesaurus (Lin, 1998).
We are not committed to this particular measure,
but it empirically performed best out of the 11 we
tried; especially it outperformed WordNet path-
based measures. Note however that only the 200
most similar words for each word are provided by
this tool. The similarity measure is normalised by
relative ranking to provide the probability that an
expression refers to the same concept as another
expression. We use WordNet (Miller, 1995) for
derivationally related forms (to solve e.g. nomi-
nalisation). This establishes the first competition,
the one between concept matches.
</bodyText>
<figure confidence="0.38290375">
law enforce-
ment officers
members of the
Panther Party
</figure>
<figureCaption confidence="0.999989">
Figure 3: KvD’s concept matching.
Figure 4: Probabilistic concept matching.
</figureCaption>
<bodyText confidence="0.9999476">
Modelling concepts probabilistically has its impli-
cation for the next task: finding the best attach-
ment site for a proposition. Let us explain this with
an example. Notice that in the example text in Fig-
ure 1, “police” (from #4, in the first sentence) and
</bodyText>
<footnote confidence="0.948471333333333">
2A WordNet synset is defined for each named-entity type;
here “giant” is connected to its hypernym “organization” via
“enterprise”.
</footnote>
<figure confidence="0.996689555555555">
police
0.99 0.67
0
0
law enforce-
ment officers
Black Pan-
ther members
0.01
1 1
0.33
members of the
Panther Party
1 1
police
1 1
Black Pan-
ther members
</figure>
<page confidence="0.991811">
735
</page>
<bodyText confidence="0.999956325581396">
“law enforcement officer” (from #19, in the sec-
ond sentence) refer to the same concept POLICE.
Figure 3 illustrates how this is handled in KvD’s
model, where intelligent concept matching estab-
lishes with 100% certainty that the two strings re-
fer to the same concept. Certainty about the ar-
gument overlap then enables them to later attach
#19 to #4. In their model it is important whether
a matching proposition is found in STM or LTM:
If the only proposition that mentions “police” (#4)
is no longer in STM when the proposition contain-
ing “law enforcement officer” (#19) is processed,
and for any reason the other arguments in #19 (i.e.
STUDENT) cannot find overlaps either, KvD find
no concept match in STM and know therefore,
again with full certainty, that an LTM search must
be triggered3, which in this case leads to the suc-
cessful recall of #19 for #4 to attach to.
Figure 4 illustrates the corresponding situation in
our model, where #4 with “police” is in LTM, the
probability of a concept match between “law en-
forcement officer” and “police” is 66.7%, whereas
that of a match with “members”, which is in STM,
is 33.3%. The probabilistic concept matching can-
not provide enough certainty to single out #4 be-
cause of full argument overlap. The probabilities
of concept match have to act as a much weaker
filter in our model, and all previous propositions
have to be considered as potential landing sites
for #19. In particular, we do not know whether
a concept match within STM is “good enough”,
or whether a LTM search is needed. There is, in
this case, a competition between a weak match in
STM (the direct vicinity) and a strong match in
LTM (further away), which will hopefully result
in a successful match between “police” and “law
enforcement officer”. In other words, we always
have to search for matches in both repositories.
After obtaining the graph of interrelated expres-
sions, the competition between landing sites for
each proposition takes place, whereby higher po-
sitions are preferred. This double competition is a
core aspect of our model.
</bodyText>
<subsectionHeader confidence="0.999556">
2.3 Choice of root
</subsectionHeader>
<bodyText confidence="0.9996995">
The KvD model almost always maintains the root
determined in the first cycle (either by overlap
</bodyText>
<footnote confidence="0.708692666666667">
3KvD only mentioned retrieving embedded propositions
as LTM search rarely happens, but the goal is the same as
here: to establish overlap.
</footnote>
<bodyText confidence="0.99991215625">
with title concepts or by coverage of the main
clause of the first sentence). The model intro-
duces multiple roots if a text is totally incoher-
ent, namely when propositions cannot be attached
anywhere and therefore a forest of disjoint trees
has to be developed. This strategy does not gen-
eralise well to longer texts with topic changes,
for example newspaper texts with anecdotal leads.
Although these texts are perfectly coherent, KvD
cannot treat them appropriately.4
Our more flexible rooting strategy is run once
in each cycle, assessing whether any of the cur-
rent root’s children in the working memory would
make a better root. In case of a root change, the
edge between the old and the new root is reversed,
and the old root becomes a child of the new root.
Then we perform the same strategy on the new tree
until no root change is needed.
We denote the current root as i, and a new root
candidate (a child of i) j. J is the set of descen-
dants of j (inclusive of j), and I the set of all nodes
V excluding J, i.e. I = V \ J. Then nodes in J
will be promoted after the root change, while those
in I will go one level deeper. Since edge weights,
i.e. attachment strengths, are asymmetric, we de-
note the weight for j being a child of i as wi,j, and
wj,i for the reversed attachment. Each node v also
carries a weight xv = mv · adv, where mv is a
memory status factor (e.g. mv = 1 if v is in STM,
0.5 if otherwise), 0 &lt; a ≤ 1 is an attenuation fac-
tor, and dv is depth of v in the tree. To decide, we
evaluate
</bodyText>
<equation confidence="0.995968">
�s = wj,i �xv − wi,j xv (1)
v∈J v∈I
</equation>
<bodyText confidence="0.998595444444445">
If s &gt; 0, the root change is permitted.5 This evalu-
ation makes root change easier if the edge in ques-
tion favours i being a child of j, or there are more
important nodes that can benefit from the change,
and vice versa.
An example of such a root change taken from the
Bumperstickers is given in Figure 5 (refer to Ta-
ble 1 for proposition contents). As the central
topic of the text changes from the encounters to
</bodyText>
<footnote confidence="0.924581833333333">
4In our scenario the situation can barely ever arise where
absolutely no proposition attachment is possible, as the prob-
abilistic concept mapping is usually able suggest some con-
cept match, albeit with small probability.
5In case when multiple candidates are permitted, the one
with the highest s is chosen.
</footnote>
<page confidence="0.998094">
736
</page>
<bodyText confidence="0.99957275">
that the identity of Panther Party members are ac-
tually the author’s students, the summariser recog-
nises this change after reading one more sentence,
by flipping the edge connecting #3 and #14.
</bodyText>
<figureCaption confidence="0.980229">
Figure 5: Tree before and after a root change.
</figureCaption>
<sectionHeader confidence="0.999607" genericHeader="related work">
3 Related Work
</sectionHeader>
<bodyText confidence="0.999988230769231">
One of the dilemmas in summarisation research is
how “deep”, i.e. semantics-oriented, a summariser
should be. Shallow analysis of lexical similarity
between sentences and/or the keywords contained
in sentences has lead to summarisers that are ro-
bust and perform very well for most texts (Radev
et al., 2004; Dorr and Zajic, 2003; Carbonell and
Goldstein, 1998). The methods applied include a
random-surfer model (Mihalcea and Tarau, 2004;
Radev, 2004), a model of attraction and repul-
sion of similar summary sentences (Carbonell and
Goldstein, 1998). There are statistical models of
sentence shortening (Knight and Marcu, 2002).
While much work in summarisation has concen-
trated on multi-document summarisation, where
the main challenge is the detection of redundant
information, the summariser presented here is a
single-document summariser.
However, researchers have been attracted by
deeper, more symbolic and thus more explana-
tory summarisation models that use semantic rep-
resentations of some form (Radev and McKe-
own, 1998) and often rely on explicit discourse
modelling (Lehnert, 1981; Kintsch and van Dijk,
1978; Cohen, 1984). The problem with template-
based summarisers is that they tend to be domain-
dependent; the problem with discourse structure-
based summarisers is in general that they require
knowledge modelling and reasoning far beyond
the capability of today’s state of the art in arti-
ficial intelligence. Rhetorical Structure Theory
(Mann and Thompson, 1987) provides a domain-
independent framework that takes local discourse
structure into account, which has lead to a suc-
cessful prototype summariser (Marcu, 2000). This
summarisation strategy does not however look at
the lexical content of the propositions or clause-
like units it connects, only at the way how the con-
nection is performed.
The summariser presented here is a hybrid: its
core algorithm is symbolic, but its limited powers
of generalisation come from a semantic similarity
metric that is defined via distributionally derived
probabilities. Because its core processing is sym-
bolic and based on a simple semantic representa-
tion, it is possible to derive an explanation based
on the coherence tree and the propositions selected
from it. There are some similarities to the idea of
summarisation via lexical chains (Barzilay and El-
hadad, 1997), as both methods trace concepts (as
representatives of topics) across a document. The
KvD model arguably uses more informative mean-
ing units, as it is based on the combination of con-
cepts within propositions, rather than on concept
repetition alone.
A different, related stream of research looked
at the automatic detection of coherence in text.
Graesser et al (2004) present a coherence checker
based on over 200 coherence metrics, including
argument overlap as in KvD. Barzilay and Lap-
ata (2008) use a profiling of texts akin to Centering
theory to rank texts according to their coherence.
It would be interesting to combine their notion of
entity-based coherence with KvD’s notion of ar-
gument overlap.
</bodyText>
<sectionHeader confidence="0.99965" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999676">
We now perform two experiments. The first tests
the contribution of our concept matcher and root
change strategy on a small document set we have
collected, and compares against two research sum-
marisers. In the second experiment, we test the
performance of our summariser on a much larger
and standard dataset.
We will use the intrinsic evaluation strategy of
comparison to a gold standard. Human judge-
ments would be the most credible, but as a cheap
alternative, we use ROUGE-L (Lin, 2004), which
has been shown to correlate well to human judge-
ments. For each sentence, ROUGE-L treats it as a
sequence of words, and finds the longest common
subsequences (LCSs) with any sentence in a gold
standard summary. The score is defined as the F-
measure of the precision and recall of the LCSs.
</bodyText>
<figure confidence="0.992478181818182">
3 2
4
14 16
17
18
14
16
17
18
3 2
4
</figure>
<page confidence="0.989426">
737
</page>
<bodyText confidence="0.997703949152542">
The next question is how the gold standard sum-
maries used in ROUGE are defined. Because our
summariser is deep and has a fine granularity, it
should be compared against human-written sum-
maries on a variety of texts.
For the first experiment, we have collected from
volunteers 8 human abstractive summaries for
each of the 4 short scientific articles or stories
we found in Kintsch and Vipond (1979) (average
length: 120 words), and 4 for each of 2 longer po-
litical news texts (average length: 523 words). The
volunteers were instructed to condense the text to
1/3 of its length for the short texts, and to 100
words for the longer ones. They were also in-
structed not to paraphrase, but to use the words in
the text as much as possible. This was because no
summariser in this experiment has a paraphrasing
ability. Nevertheless, not all subjects followed this
instruction strictly.
For the second experiment, we use the DUC 2002
dataset (Over and Liggett, 2002). There are 827
texts from news media, of a variety of topics and
lengths, among which our script is able to extract
titles and contents of 822 documents. We use the
provided single document abstractive summaries,
which are of 100 words in length each, as gold
standard summaries. A few of the documents are
selected in multiple clusters and therefore have
multiple summaries; all of them are used in evalu-
ation.
We compare our summariser against a baseline
constructed with the first n words from the origi-
nal text, where n is the summary length as defined
above, and two summarisers: MEAD (Radev et
al., 2004) is a research summariser which uses a
centroid-based paradigm and is known to perform
generally well over a range of texts. LexRank
(Radev, 2004) uses lexically derived similarities in
its similarity graph of sentences, sharing the same
idea of sentence similarity with MEAD. Note that
both summarisers are extractive.
We illustrate what our summaries look like in Ta-
ble 2, where we asked the summariser to give us
summaries as close to 20 and 50 word summaries
as possible, with Table 3 showing the underlying
propositions. In contrast, MEAD can only extract
sentences as-is (thus not as flexible in length), and
does not have meaning blocks like our proposi-
tions.
Encounters between police and Black Panther members.
Students to complain of harassment. Automobiles Panther
Party signs glued to bumpers.
Bloody encounters between police and Black Panther
members punctuated the summer days of 1969. Students
to complain of continuous harassment by law enforcement
officers. They receiving many traffic citations. Automo-
biles with Panther Party signs glued to their bumpers. I to
determine whether we were hearing the voice of paranoia
or reality.
</bodyText>
<tableCaption confidence="0.946713625">
Table 2: Summaries produced by our summariser.
3 encounters (between: police; between: Black Pan-
ther members)
16 to complain (students; of: harassment)
34 with: Panther Party signs (automobiles)
35 glued (#34; to: bumpers)
Table 3: Summary propositions for the first sum-
mary above.
</tableCaption>
<bodyText confidence="0.999862583333333">
We create summaries for all three summarisers
following this procedure: We provide sentence-
split texts and their headlines (not needed by
LexRank), and run the summarisers in such a way
as to produce a summary of the same length as
stipulated for the standard summaries. Our sum-
mariser controls word count precisely; we require
MEAD to produce summaries close to the length
(allowing variations), and for LexRank we allow
it to go beyond the limit by less than one sentence
and then discard the exceeding part in the sentence
with the lowest salience.
The results of Experiment 1 are summarised in Ta-
ble 4. As is well-known from similar experiments,
it is hard beating the first n baseline due to the fact
that journalistic style (in the long texts) already
puts a summary of each text first. It is slightly
surprising that this effect also holds for the short
texts (literary style). It is of note that our KvD
summariser beats both MEAD and LexRank on
this dataset, which is shelved away during devel-
opment, with statistical significance on the long
texts: the 95%-confidence interval of ours is 0.403
– 0.432, and that of MEAD is 0.370 – 0.411.
</bodyText>
<table confidence="0.999629625">
Long Texts Short Texts
Ours 0.418 0.333
Ours – without similarity 0.396 0.271
Ours – without word info 0.319 0.185
Ours – without root change 0.388 0.348
MEAD 0.391 0.343
LexRank 0.378 0.326
First n words 0.460 0.368
</table>
<tableCaption confidence="0.995486">
Table 4: ROUGE-L F-measures for Experiment 1.
</tableCaption>
<page confidence="0.928633">
738
</page>
<table confidence="0.99996575">
Precision Recall F-measure
Our summariser 0.361 0.332 0.344
MEAD 0.366 0.355 0.358
First n words 0.403 0.395 0.399
</table>
<tableCaption confidence="0.998219">
Table 5: ROUGE-L scores for Experiment 2.
</tableCaption>
<bodyText confidence="0.999952771428571">
We test whether concept matching is beneficial
by switching off similarity derived from distribu-
tional semantics, or switching off all “word infor-
mation” which includes distributional semantics,
lemmatisation, and coreference detection, i.e. to
consider matching only for the same word. Per-
formance deteriorates when concept matching is
switched off, substantially if all word information
is off. This confirms our hypothesis that one of
the cornerstones of KvD, concept matching, can
be at least partially simulated using today’s distri-
butional semantics methods. As for root change,
turning it off seems to hurt performance on the
longer texts, but not so on the shorter ones, which
matches our speculation that root change is useful
for longer texts, which have some focus shifts.
The result of Experiment 2 is shown in Table 5.
This experiment on a large dataset demonstrates
that our summariser performs in the ballpark of
typical results of extractive summarisers, although
it is still statistically a little worse than the state-of-
the-art MEAD (whose F-measure 95%-confidence
interval is 0.349 – 0.367). Our summariser is
good at precision because many summaries pro-
duced have not used up the 100-word limit, mak-
ing the average summary length smaller than that
of MEAD’s. This indicates that our summariser
might be good at very short summaries, or we
could improve the memory selection to allow for
a more diversified important proposition set. Con-
sidering this, and the fact that we have many pa-
rameters not tuned for the task, and we have not
utilised the structural / positional features (whose
importance is shown in the first-n baseline), the
result is still encouraging.
</bodyText>
<sectionHeader confidence="0.999634" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.99999502">
We present here a first prototype of the feasibility
of basing a summarisation algorithm on Kintsch
and van Dijk’s (1978) model. Our implemen-
tation successfully creates flexible-length sum-
maries, highly compressed if desired, and provides
some explanation for why certain meaning units
appear in the summary. We have avoided some of
the hardest aspects of KvD’s model, which have to
do with the generation of macropropositions and
with keeping closer track of larger discourse struc-
tures, but we show that some core aspects of the
model can be approximated with today’s parsing
and lexical semantics technology. Although the
output summaries are not yet in all cases grammat-
ical, we show that our system performs compara-
bly with extractive state-of-the-art summarisers.
During the implementation, we had to solve sev-
eral practical problems that the KvD did not give
enough procedural detail about, or skipped over
in their manual simulation. For instance, we have
turned the distinction between LTM and STM to
two parallel salience levels from KvD’s two dis-
joint stages, formalised the tree building process
and improved KvD’s root choice strategy.
The KvD model does not keep track of unique
events, but would profit from doing so, for in-
stance in texts where more than one event of the
same type is referred to. It has no explicit model
of time, but would profit from one. It does not
even use information about which entities in a text
form the same concept or individual, for selecting
all information about that concept into the sum-
mary. There are also many interesting ways how
the memory cycle could be modified by giving
more weight to particular events, concepts and in-
dividuals.
On the implementational side, much remains to
be tried. Anything that improves the proposition
builder should bear direct fruit in the quality of
the summaries. The limitations of our proposi-
tion builder come from the limitations of parsing
technology as well as the fact that semantics is not
entirely determined by syntax. For instance, we
noticed some problems caused by incorrect prepo-
sitional phrase attachment. A better coreference
system would also improve this summariser im-
mensely, reducing much uncertainty in the con-
cept matching. The deep nature of the summariser
also enables natural language generation to im-
prove the readability of our textual summary.
</bodyText>
<sectionHeader confidence="0.973365" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.8709325">
Joint scholarship from the Cambridge Common-
wealth, European &amp; International Trust and the
China Scholarship Council is gratefully acknowl-
edged.
</bodyText>
<page confidence="0.997776">
739
</page>
<sectionHeader confidence="0.990192" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998534654205607">
A Baddeley. 2007. Working memory, thought, and ac-
tion. Oxford University Press.
Regina Barzilay and Michael Elhadad. 1997. Us-
ing lexical chains for text summarization. In Inderjeet
Mani and Mark T. Maybury, editors, Proceedings of the
ACL/EACL-97 Workshop on Intelligent Scalable Text
Summarization.
Regina Barzilay and Mirella Lapata. 2008. Modeling
local coherence: An entity-based approach. Computa-
tional Linguistics, 34(1):1–34.
BK Britton and S Gulgoz. 1991. Using kintsch’s
computational model to improve instructional text: Ef-
fects of repairing inference calls on recall and cognitive
structures. Journal of Educational Psychology.
Ann L. Brown, Jeanne D. Day, and Jones R. S. 1983.
The development of plans for summarizing text. Child
development. was in press in 1983.
Jaime Carbonell and Jade Goldstein. 1998. The use
of MMR, diversity-based reranking for reordering doc-
uments and producing summaries. In Proceedings of
the 21th (SIGIR-98), pages 335–336, Melbourne, Aus-
tralia.
Robin Cohen. 1984. A computational theory of the
function of clue words in argument understanding. In
Proceedings of the 10th (COLING-84), pages 251–255.
J Coiro and E Dobler. 2007. Exploring the online
reading comprehension strategies used by sixthgrade
skilled readers to search for and locate information on
the internet. Reading research quarterly.
KA DeLong, TP Urbach, and M Kutas. 2005. Prob-
abilistic word pre-activation during language compre-
hension inferred from electrical brain activity. Nature
neuroscience.
Bonnie Dorr and David Zajic. 2003. Hedge trimmer:
A parse-and-trim approach to headline generation. In
in Proceedings of Workshop on Automatic Summariza-
tion, pages 1–8.
MP Driscoll. 2005. Psychology of learning for instruc-
tion. Allyn and Bacon.
NK Duke and PD Pearson. 2002. Effective practices
for developing reading comprehension. In Alan E.
Farstrup and S. Jay Samuels, editors, What research
has to say about reading instruction.
Brigitte Endres-Niggemeyer. 1998. Summarizing In-
formation. Springer-Verlag, New York, NY.
Arthur C. Graesser, Danielle S. McNamara, Max M.
Louwerse, and Zhiqiang Cai. 2004. Coh-metrix:
Analysis of text on cohesion and language. Behav-
ior Research Methods, Instruments, &amp; Computers,
36(2):193–202.
V Anderson Hidi. 1986. Producing written sum-
maries: Task demands, cognitive operations, and impli-
cations for instruction. Review of educational research.
A King. 1992. Comparison of self-questioning, sum-
marizing, and notetaking-review as strategies for learn-
ing from lectures. American Educational Research
Journal.
Walter Kintsch and Teun A. van Dijk. 1978. Toward a
model of text comprehension and production. Psycho-
logical review, 85(5):363–394.
Walter Kintsch and Douglas Vipond. 1979. Read-
ing comprehension and readability in educational prac-
tice and psychological theory. In Lars-G¨oran Nilsson,
editor, Perspectives on Memory Research: Essays in
Honor of Uppsala’s 500th Anniversary, pages 329–
365. Erlbaum Associates.
Dan Klein and Christopher D Manning. 2003. Ac-
curate unlexicalized parsing. In Proceedings of the
41st Annual Meeting on Association for Computational
Linguistics-Volume 1, pages 423–430. Association for
Computational Linguistics.
Kevin Knight and Daniel Marcu. 2002. Summariza-
tion beyond sentence extraction: A probabilistic ap-
proach to sentence compression. Artificial Intelligence,
139(1).
Keiko Koda. 2005. Insights into second language
reading: A cross-linguistic approach. Cambridge Uni-
veristy Press.
Wendy G Lehnert. 1981. Plot units and narrative sum-
marization. Cognitive Science, 5(4):293–331.
Chin-Yew Lin and Eduard Hovy. 2003. Automatic
evaluation of summaries using n-gram co-occurrence
statistics. In Proceedings of the 2003 Conference of the
North American Chapter of the Association for Compu-
tational Linguistics on Human Language Technology-
Volume 1, pages 71–78. Association for Computational
Linguistics.
Dekang Lin. 1998. Automatic retrieval and clustering
of similar words. In Proceedings of the 17th interna-
tional conference on Computational linguistics-Volume
2, pages 768–774. Association for Computational Lin-
guistics.
Chin-Yew Lin. 2004. ROUGE: A package for auto-
matic evaluation of summaries. In Text Summarization
Branches Out: Proceedings of the ACL-04 Workshop,
pages 74–81.
William C. Mann and Sandra A. Thompson. 1987.
Rhetorical Structure Theory: Description and construc-
tion of text structures. In Gerard Kempen, editor, Natu-
ral Language Generation: New Results in Artificial In-
telligence, Psychology, and Linguistics, pages 85–95.
Marinus Nijhoff Publishers, Dordrecht, NL.
Daniel Marcu. 2000. The Theory and Practice of Dis-
course Parsing and Summarization. MIT Press.
R Mihalcea and P Tarau. 2004. Textrank: Bringing
order into texts. In Proceedings of the EMLNP.
George A Miller. 1995. Wordnet: a lexical database
</reference>
<page confidence="0.960816">
740
</page>
<reference confidence="0.99736375">
for english. Communications of the ACM, 38(11):39–
41.
Paul Over and W Liggett. 2002. Introduction to
duc: An intrinsic evaluation of generic news text sum-
marization systems. In Proc. DUC. http://www-
nlpir.nist.gov/projects/duc/guidelines/2002.html.
A Paivio. 1990. Mental representations. Oxford Sci-
ence Publications.
Aannemarie Sullivan Palinscar and Ann L. Brown.
1984. Reciprocal teaching of comprehension-fostering
and comprehension-monitoring activities. Cognition
and Instruction, 1:117–175.
Michael Pressley. 2006. Reading instruction that
works: The case for balanced teaching. Guildford
Press.
Dragomir R. Radev and Kathleen R. McKeown. 1998.
Generating natural language summaries from multiple
on-line sources. 24(3):469–500.
Dragomir Radev, Timothy Allison, Sasha Blair-
Goldensohn, John Blitzer, Arda Celebi, Stanko Dim-
itrov, Elliott Drabek, Ali Hakim, Wai Lam, Danyu Liu,
Jahna Otterbacher, Hong Qi, Horacio Saggion, Simone
Teufel, Michael Topper, Adam Winkel, and Zhu Zhang.
2004. Mead – a platform for multidocument multilin-
gual text summarization. In Proceedings of LREC-04.
Dragomir R. Radev. 2004. Lexrank: Graph-based lex-
ical centrality as salience in text summarization. Jour-
nal of Artificial Intelligence Research.
F Smith. 2004. Understanding reading: A psy-
cholinguistic analysis of reading and learning to read.
Lawrence Erlbaum.
Karen Sp¨arck Jones. 1993. What might be in a sum-
mary? Technical report, Computer Laboratory, Uni-
versity of Cambridge.
Teun A. van Dijk. 1977. Text and Context: Explo-
rations in the Semantics and Pragmatics of Discourse.
Longman, London, UK.
RA Zwaan. 2003. The immersed experiencer: Toward
an embodied theory of language comprehension. Psy-
chology of learning and motivation.
</reference>
<page confidence="0.997807">
741
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.204404">
<title confidence="0.9983285">A Summariser based on Human Memory Limitations Lexical Competition</title>
<author confidence="0.970128">Yimai</author>
<affiliation confidence="0.991042">Computer University of</affiliation>
<address confidence="0.48935">15 JJ Thomson Avenue, CB3 0FD,</address>
<email confidence="0.88547">Yimai.Fang@cl.cam.ac.uk</email>
<author confidence="0.97138">Simone</author>
<affiliation confidence="0.98584">Computer University of</affiliation>
<address confidence="0.544536">15 JJ Thomson Avenue, CB3 0FD,</address>
<email confidence="0.970765">Simone.Teufel@cl.cam.ac.uk</email>
<abstract confidence="0.994136333333333">Kintsch and van Dijk proposed a model of human comprehension and summarisation which is based on the idea of processing propositions on a sentence-bysentence basis, detecting argument overlap, and creating a summary on the basis of the best connected propositions. We present an implementation of that model, which gets around the problem of identifying concepts in text by applying coreference resolution, named entity detection, and semantic similarity detection, implemented as a two-step competition. We evaluate the resulting summariser against two commonly used extractive summarisers using ROUGE, with encouraging results.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Baddeley</author>
</authors>
<title>Working memory, thought, and action.</title>
<date>2007</date>
<publisher>Oxford University Press.</publisher>
<contexts>
<context position="1605" citStr="Baddeley, 2007" startWordPosition="241" endWordPosition="242">forth KvD) present a model of human comprehension and memory retention which is based on research in artificial intelligence, experimental psychology and discourse linguistics. It models the processing of incoming text or speech by human memory limitations, and makes verifiable predictions about which propositions in a text will be recalled by subjects later. It has been very influential, particularly in the 1980 and 1990s in educational (Palinscar and Brown, 1984; King, 1992) and cognitive (Paivio, 1990) psychology, and is still today used as a theoretical model of reading and comprehension (Baddeley, 2007; Zwaan, 2003; DeLong et al., 2005; Smith, 2004). It has also been used for improving education, particularly for the production of better instructional text (Britton and Gulgoz, 1991; Pressley, 2006), and for teaching humans how to read for deep comprehension (Coiro and Dobler, 2007; Duke and Pearson, 2002; Koda, 2005; Driscoll, 2005) and to summarise (Hidi, 1986; Brown et al., 1983). In the summarisation community, the model has been commended for its elegant and explanatory “deep” treatment of the summarisation process (Lehnert, 1981; Sp¨arck Jones, 1993; EndresNiggemeyer, 1998), but has no</context>
</contexts>
<marker>Baddeley, 2007</marker>
<rawString>A Baddeley. 2007. Working memory, thought, and action. Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Michael Elhadad</author>
</authors>
<title>Using lexical chains for text summarization.</title>
<date>1997</date>
<booktitle>In Inderjeet Mani and</booktitle>
<editor>Mark T. Maybury, editors,</editor>
<contexts>
<context position="23115" citStr="Barzilay and Elhadad, 1997" startWordPosition="3766" endWordPosition="3770">cal content of the propositions or clauselike units it connects, only at the way how the connection is performed. The summariser presented here is a hybrid: its core algorithm is symbolic, but its limited powers of generalisation come from a semantic similarity metric that is defined via distributionally derived probabilities. Because its core processing is symbolic and based on a simple semantic representation, it is possible to derive an explanation based on the coherence tree and the propositions selected from it. There are some similarities to the idea of summarisation via lexical chains (Barzilay and Elhadad, 1997), as both methods trace concepts (as representatives of topics) across a document. The KvD model arguably uses more informative meaning units, as it is based on the combination of concepts within propositions, rather than on concept repetition alone. A different, related stream of research looked at the automatic detection of coherence in text. Graesser et al (2004) present a coherence checker based on over 200 coherence metrics, including argument overlap as in KvD. Barzilay and Lapata (2008) use a profiling of texts akin to Centering theory to rank texts according to their coherence. It woul</context>
</contexts>
<marker>Barzilay, Elhadad, 1997</marker>
<rawString>Regina Barzilay and Michael Elhadad. 1997. Using lexical chains for text summarization. In Inderjeet Mani and Mark T. Maybury, editors, Proceedings of the ACL/EACL-97 Workshop on Intelligent Scalable Text Summarization.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Mirella Lapata</author>
</authors>
<title>Modeling local coherence: An entity-based approach.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>1</issue>
<contexts>
<context position="23613" citStr="Barzilay and Lapata (2008)" startWordPosition="3846" endWordPosition="3850">tions selected from it. There are some similarities to the idea of summarisation via lexical chains (Barzilay and Elhadad, 1997), as both methods trace concepts (as representatives of topics) across a document. The KvD model arguably uses more informative meaning units, as it is based on the combination of concepts within propositions, rather than on concept repetition alone. A different, related stream of research looked at the automatic detection of coherence in text. Graesser et al (2004) present a coherence checker based on over 200 coherence metrics, including argument overlap as in KvD. Barzilay and Lapata (2008) use a profiling of texts akin to Centering theory to rank texts according to their coherence. It would be interesting to combine their notion of entity-based coherence with KvD’s notion of argument overlap. 4 Experiments We now perform two experiments. The first tests the contribution of our concept matcher and root change strategy on a small document set we have collected, and compares against two research summarisers. In the second experiment, we test the performance of our summariser on a much larger and standard dataset. We will use the intrinsic evaluation strategy of comparison to a gol</context>
</contexts>
<marker>Barzilay, Lapata, 2008</marker>
<rawString>Regina Barzilay and Mirella Lapata. 2008. Modeling local coherence: An entity-based approach. Computational Linguistics, 34(1):1–34.</rawString>
</citation>
<citation valid="true">
<authors>
<author>BK Britton</author>
<author>S Gulgoz</author>
</authors>
<title>Using kintsch’s computational model to improve instructional text: Effects of repairing inference calls on recall and cognitive structures.</title>
<date>1991</date>
<journal>Journal of Educational Psychology.</journal>
<contexts>
<context position="1788" citStr="Britton and Gulgoz, 1991" startWordPosition="268" endWordPosition="272">cs. It models the processing of incoming text or speech by human memory limitations, and makes verifiable predictions about which propositions in a text will be recalled by subjects later. It has been very influential, particularly in the 1980 and 1990s in educational (Palinscar and Brown, 1984; King, 1992) and cognitive (Paivio, 1990) psychology, and is still today used as a theoretical model of reading and comprehension (Baddeley, 2007; Zwaan, 2003; DeLong et al., 2005; Smith, 2004). It has also been used for improving education, particularly for the production of better instructional text (Britton and Gulgoz, 1991; Pressley, 2006), and for teaching humans how to read for deep comprehension (Coiro and Dobler, 2007; Duke and Pearson, 2002; Koda, 2005; Driscoll, 2005) and to summarise (Hidi, 1986; Brown et al., 1983). In the summarisation community, the model has been commended for its elegant and explanatory “deep” treatment of the summarisation process (Lehnert, 1981; Sp¨arck Jones, 1993; EndresNiggemeyer, 1998), but has not lead to any practical prototypes, mainly due the impossibility of implementing the knowledge- and inference-based aspects the model relies on. We present here an implementation of t</context>
</contexts>
<marker>Britton, Gulgoz, 1991</marker>
<rawString>BK Britton and S Gulgoz. 1991. Using kintsch’s computational model to improve instructional text: Effects of repairing inference calls on recall and cognitive structures. Journal of Educational Psychology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann L Brown</author>
<author>Jeanne D Day</author>
<author>R S Jones</author>
</authors>
<title>The development of plans for summarizing text. Child development. was in press in</title>
<date>1983</date>
<contexts>
<context position="1992" citStr="Brown et al., 1983" startWordPosition="303" endWordPosition="306">luential, particularly in the 1980 and 1990s in educational (Palinscar and Brown, 1984; King, 1992) and cognitive (Paivio, 1990) psychology, and is still today used as a theoretical model of reading and comprehension (Baddeley, 2007; Zwaan, 2003; DeLong et al., 2005; Smith, 2004). It has also been used for improving education, particularly for the production of better instructional text (Britton and Gulgoz, 1991; Pressley, 2006), and for teaching humans how to read for deep comprehension (Coiro and Dobler, 2007; Duke and Pearson, 2002; Koda, 2005; Driscoll, 2005) and to summarise (Hidi, 1986; Brown et al., 1983). In the summarisation community, the model has been commended for its elegant and explanatory “deep” treatment of the summarisation process (Lehnert, 1981; Sp¨arck Jones, 1993; EndresNiggemeyer, 1998), but has not lead to any practical prototypes, mainly due the impossibility of implementing the knowledge- and inference-based aspects the model relies on. We present here an implementation of the model, which attempts to circumvent some of these problems by the application of distributional semantics, and by modelling the construction of the coherence tree as a double competition (firstly of co</context>
</contexts>
<marker>Brown, Day, Jones, 1983</marker>
<rawString>Ann L. Brown, Jeanne D. Day, and Jones R. S. 1983. The development of plans for summarizing text. Child development. was in press in 1983.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jaime Carbonell</author>
<author>Jade Goldstein</author>
</authors>
<title>The use of MMR, diversity-based reranking for reordering documents and producing summaries.</title>
<date>1998</date>
<booktitle>In Proceedings of the 21th (SIGIR-98),</booktitle>
<pages>335--336</pages>
<location>Melbourne, Australia.</location>
<contexts>
<context position="21156" citStr="Carbonell and Goldstein, 1998" startWordPosition="3468" endWordPosition="3471">s chosen. 736 that the identity of Panther Party members are actually the author’s students, the summariser recognises this change after reading one more sentence, by flipping the edge connecting #3 and #14. Figure 5: Tree before and after a root change. 3 Related Work One of the dilemmas in summarisation research is how “deep”, i.e. semantics-oriented, a summariser should be. Shallow analysis of lexical similarity between sentences and/or the keywords contained in sentences has lead to summarisers that are robust and perform very well for most texts (Radev et al., 2004; Dorr and Zajic, 2003; Carbonell and Goldstein, 1998). The methods applied include a random-surfer model (Mihalcea and Tarau, 2004; Radev, 2004), a model of attraction and repulsion of similar summary sentences (Carbonell and Goldstein, 1998). There are statistical models of sentence shortening (Knight and Marcu, 2002). While much work in summarisation has concentrated on multi-document summarisation, where the main challenge is the detection of redundant information, the summariser presented here is a single-document summariser. However, researchers have been attracted by deeper, more symbolic and thus more explanatory summarisation models that</context>
</contexts>
<marker>Carbonell, Goldstein, 1998</marker>
<rawString>Jaime Carbonell and Jade Goldstein. 1998. The use of MMR, diversity-based reranking for reordering documents and producing summaries. In Proceedings of the 21th (SIGIR-98), pages 335–336, Melbourne, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robin Cohen</author>
</authors>
<title>A computational theory of the function of clue words in argument understanding.</title>
<date>1984</date>
<booktitle>In Proceedings of the 10th (COLING-84),</booktitle>
<pages>251--255</pages>
<contexts>
<context position="21928" citStr="Cohen, 1984" startWordPosition="3583" endWordPosition="3584">arbonell and Goldstein, 1998). There are statistical models of sentence shortening (Knight and Marcu, 2002). While much work in summarisation has concentrated on multi-document summarisation, where the main challenge is the detection of redundant information, the summariser presented here is a single-document summariser. However, researchers have been attracted by deeper, more symbolic and thus more explanatory summarisation models that use semantic representations of some form (Radev and McKeown, 1998) and often rely on explicit discourse modelling (Lehnert, 1981; Kintsch and van Dijk, 1978; Cohen, 1984). The problem with templatebased summarisers is that they tend to be domaindependent; the problem with discourse structurebased summarisers is in general that they require knowledge modelling and reasoning far beyond the capability of today’s state of the art in artificial intelligence. Rhetorical Structure Theory (Mann and Thompson, 1987) provides a domainindependent framework that takes local discourse structure into account, which has lead to a successful prototype summariser (Marcu, 2000). This summarisation strategy does not however look at the lexical content of the propositions or claus</context>
</contexts>
<marker>Cohen, 1984</marker>
<rawString>Robin Cohen. 1984. A computational theory of the function of clue words in argument understanding. In Proceedings of the 10th (COLING-84), pages 251–255.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Coiro</author>
<author>E Dobler</author>
</authors>
<title>Exploring the online reading comprehension strategies used by sixthgrade skilled readers to search for and locate information on the internet. Reading research quarterly.</title>
<date>2007</date>
<contexts>
<context position="1889" citStr="Coiro and Dobler, 2007" startWordPosition="286" endWordPosition="289">le predictions about which propositions in a text will be recalled by subjects later. It has been very influential, particularly in the 1980 and 1990s in educational (Palinscar and Brown, 1984; King, 1992) and cognitive (Paivio, 1990) psychology, and is still today used as a theoretical model of reading and comprehension (Baddeley, 2007; Zwaan, 2003; DeLong et al., 2005; Smith, 2004). It has also been used for improving education, particularly for the production of better instructional text (Britton and Gulgoz, 1991; Pressley, 2006), and for teaching humans how to read for deep comprehension (Coiro and Dobler, 2007; Duke and Pearson, 2002; Koda, 2005; Driscoll, 2005) and to summarise (Hidi, 1986; Brown et al., 1983). In the summarisation community, the model has been commended for its elegant and explanatory “deep” treatment of the summarisation process (Lehnert, 1981; Sp¨arck Jones, 1993; EndresNiggemeyer, 1998), but has not lead to any practical prototypes, mainly due the impossibility of implementing the knowledge- and inference-based aspects the model relies on. We present here an implementation of the model, which attempts to circumvent some of these problems by the application of distributional se</context>
</contexts>
<marker>Coiro, Dobler, 2007</marker>
<rawString>J Coiro and E Dobler. 2007. Exploring the online reading comprehension strategies used by sixthgrade skilled readers to search for and locate information on the internet. Reading research quarterly.</rawString>
</citation>
<citation valid="true">
<authors>
<author>KA DeLong</author>
<author>TP Urbach</author>
<author>M Kutas</author>
</authors>
<title>Probabilistic word pre-activation during language comprehension inferred from electrical brain activity. Nature neuroscience.</title>
<date>2005</date>
<contexts>
<context position="1639" citStr="DeLong et al., 2005" startWordPosition="245" endWordPosition="248"> human comprehension and memory retention which is based on research in artificial intelligence, experimental psychology and discourse linguistics. It models the processing of incoming text or speech by human memory limitations, and makes verifiable predictions about which propositions in a text will be recalled by subjects later. It has been very influential, particularly in the 1980 and 1990s in educational (Palinscar and Brown, 1984; King, 1992) and cognitive (Paivio, 1990) psychology, and is still today used as a theoretical model of reading and comprehension (Baddeley, 2007; Zwaan, 2003; DeLong et al., 2005; Smith, 2004). It has also been used for improving education, particularly for the production of better instructional text (Britton and Gulgoz, 1991; Pressley, 2006), and for teaching humans how to read for deep comprehension (Coiro and Dobler, 2007; Duke and Pearson, 2002; Koda, 2005; Driscoll, 2005) and to summarise (Hidi, 1986; Brown et al., 1983). In the summarisation community, the model has been commended for its elegant and explanatory “deep” treatment of the summarisation process (Lehnert, 1981; Sp¨arck Jones, 1993; EndresNiggemeyer, 1998), but has not lead to any practical prototypes</context>
</contexts>
<marker>DeLong, Urbach, Kutas, 2005</marker>
<rawString>KA DeLong, TP Urbach, and M Kutas. 2005. Probabilistic word pre-activation during language comprehension inferred from electrical brain activity. Nature neuroscience.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonnie Dorr</author>
<author>David Zajic</author>
</authors>
<title>Hedge trimmer: A parse-and-trim approach to headline generation.</title>
<date>2003</date>
<booktitle>In in Proceedings of Workshop on Automatic Summarization,</booktitle>
<pages>1--8</pages>
<contexts>
<context position="21124" citStr="Dorr and Zajic, 2003" startWordPosition="3464" endWordPosition="3467">e with the highest s is chosen. 736 that the identity of Panther Party members are actually the author’s students, the summariser recognises this change after reading one more sentence, by flipping the edge connecting #3 and #14. Figure 5: Tree before and after a root change. 3 Related Work One of the dilemmas in summarisation research is how “deep”, i.e. semantics-oriented, a summariser should be. Shallow analysis of lexical similarity between sentences and/or the keywords contained in sentences has lead to summarisers that are robust and perform very well for most texts (Radev et al., 2004; Dorr and Zajic, 2003; Carbonell and Goldstein, 1998). The methods applied include a random-surfer model (Mihalcea and Tarau, 2004; Radev, 2004), a model of attraction and repulsion of similar summary sentences (Carbonell and Goldstein, 1998). There are statistical models of sentence shortening (Knight and Marcu, 2002). While much work in summarisation has concentrated on multi-document summarisation, where the main challenge is the detection of redundant information, the summariser presented here is a single-document summariser. However, researchers have been attracted by deeper, more symbolic and thus more expla</context>
</contexts>
<marker>Dorr, Zajic, 2003</marker>
<rawString>Bonnie Dorr and David Zajic. 2003. Hedge trimmer: A parse-and-trim approach to headline generation. In in Proceedings of Workshop on Automatic Summarization, pages 1–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>MP Driscoll</author>
</authors>
<title>Psychology of learning for instruction. Allyn and Bacon.</title>
<date>2005</date>
<contexts>
<context position="1942" citStr="Driscoll, 2005" startWordPosition="296" endWordPosition="297">called by subjects later. It has been very influential, particularly in the 1980 and 1990s in educational (Palinscar and Brown, 1984; King, 1992) and cognitive (Paivio, 1990) psychology, and is still today used as a theoretical model of reading and comprehension (Baddeley, 2007; Zwaan, 2003; DeLong et al., 2005; Smith, 2004). It has also been used for improving education, particularly for the production of better instructional text (Britton and Gulgoz, 1991; Pressley, 2006), and for teaching humans how to read for deep comprehension (Coiro and Dobler, 2007; Duke and Pearson, 2002; Koda, 2005; Driscoll, 2005) and to summarise (Hidi, 1986; Brown et al., 1983). In the summarisation community, the model has been commended for its elegant and explanatory “deep” treatment of the summarisation process (Lehnert, 1981; Sp¨arck Jones, 1993; EndresNiggemeyer, 1998), but has not lead to any practical prototypes, mainly due the impossibility of implementing the knowledge- and inference-based aspects the model relies on. We present here an implementation of the model, which attempts to circumvent some of these problems by the application of distributional semantics, and by modelling the construction of the coh</context>
</contexts>
<marker>Driscoll, 2005</marker>
<rawString>MP Driscoll. 2005. Psychology of learning for instruction. Allyn and Bacon.</rawString>
</citation>
<citation valid="true">
<authors>
<author>NK Duke</author>
<author>PD Pearson</author>
</authors>
<title>Effective practices for developing reading comprehension.</title>
<date>2002</date>
<editor>In Alan E. Farstrup and S. Jay Samuels, editors,</editor>
<contexts>
<context position="1913" citStr="Duke and Pearson, 2002" startWordPosition="290" endWordPosition="293">ch propositions in a text will be recalled by subjects later. It has been very influential, particularly in the 1980 and 1990s in educational (Palinscar and Brown, 1984; King, 1992) and cognitive (Paivio, 1990) psychology, and is still today used as a theoretical model of reading and comprehension (Baddeley, 2007; Zwaan, 2003; DeLong et al., 2005; Smith, 2004). It has also been used for improving education, particularly for the production of better instructional text (Britton and Gulgoz, 1991; Pressley, 2006), and for teaching humans how to read for deep comprehension (Coiro and Dobler, 2007; Duke and Pearson, 2002; Koda, 2005; Driscoll, 2005) and to summarise (Hidi, 1986; Brown et al., 1983). In the summarisation community, the model has been commended for its elegant and explanatory “deep” treatment of the summarisation process (Lehnert, 1981; Sp¨arck Jones, 1993; EndresNiggemeyer, 1998), but has not lead to any practical prototypes, mainly due the impossibility of implementing the knowledge- and inference-based aspects the model relies on. We present here an implementation of the model, which attempts to circumvent some of these problems by the application of distributional semantics, and by modellin</context>
</contexts>
<marker>Duke, Pearson, 2002</marker>
<rawString>NK Duke and PD Pearson. 2002. Effective practices for developing reading comprehension. In Alan E. Farstrup and S. Jay Samuels, editors, What research has to say about reading instruction.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brigitte Endres-Niggemeyer</author>
</authors>
<title>Summarizing Information.</title>
<date>1998</date>
<publisher>Springer-Verlag,</publisher>
<location>New York, NY.</location>
<marker>Endres-Niggemeyer, 1998</marker>
<rawString>Brigitte Endres-Niggemeyer. 1998. Summarizing Information. Springer-Verlag, New York, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arthur C Graesser</author>
<author>Danielle S McNamara</author>
<author>Max M Louwerse</author>
<author>Zhiqiang Cai</author>
</authors>
<title>Coh-metrix: Analysis of text on cohesion and language.</title>
<date>2004</date>
<journal>Behavior Research Methods, Instruments, &amp; Computers,</journal>
<volume>36</volume>
<issue>2</issue>
<contexts>
<context position="23483" citStr="Graesser et al (2004)" startWordPosition="3826" endWordPosition="3829">ased on a simple semantic representation, it is possible to derive an explanation based on the coherence tree and the propositions selected from it. There are some similarities to the idea of summarisation via lexical chains (Barzilay and Elhadad, 1997), as both methods trace concepts (as representatives of topics) across a document. The KvD model arguably uses more informative meaning units, as it is based on the combination of concepts within propositions, rather than on concept repetition alone. A different, related stream of research looked at the automatic detection of coherence in text. Graesser et al (2004) present a coherence checker based on over 200 coherence metrics, including argument overlap as in KvD. Barzilay and Lapata (2008) use a profiling of texts akin to Centering theory to rank texts according to their coherence. It would be interesting to combine their notion of entity-based coherence with KvD’s notion of argument overlap. 4 Experiments We now perform two experiments. The first tests the contribution of our concept matcher and root change strategy on a small document set we have collected, and compares against two research summarisers. In the second experiment, we test the perform</context>
</contexts>
<marker>Graesser, McNamara, Louwerse, Cai, 2004</marker>
<rawString>Arthur C. Graesser, Danielle S. McNamara, Max M. Louwerse, and Zhiqiang Cai. 2004. Coh-metrix: Analysis of text on cohesion and language. Behavior Research Methods, Instruments, &amp; Computers, 36(2):193–202.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Anderson Hidi</author>
</authors>
<title>Producing written summaries: Task demands, cognitive operations, and implications for instruction. Review of educational research.</title>
<date>1986</date>
<contexts>
<context position="1971" citStr="Hidi, 1986" startWordPosition="301" endWordPosition="302">een very influential, particularly in the 1980 and 1990s in educational (Palinscar and Brown, 1984; King, 1992) and cognitive (Paivio, 1990) psychology, and is still today used as a theoretical model of reading and comprehension (Baddeley, 2007; Zwaan, 2003; DeLong et al., 2005; Smith, 2004). It has also been used for improving education, particularly for the production of better instructional text (Britton and Gulgoz, 1991; Pressley, 2006), and for teaching humans how to read for deep comprehension (Coiro and Dobler, 2007; Duke and Pearson, 2002; Koda, 2005; Driscoll, 2005) and to summarise (Hidi, 1986; Brown et al., 1983). In the summarisation community, the model has been commended for its elegant and explanatory “deep” treatment of the summarisation process (Lehnert, 1981; Sp¨arck Jones, 1993; EndresNiggemeyer, 1998), but has not lead to any practical prototypes, mainly due the impossibility of implementing the knowledge- and inference-based aspects the model relies on. We present here an implementation of the model, which attempts to circumvent some of these problems by the application of distributional semantics, and by modelling the construction of the coherence tree as a double compe</context>
</contexts>
<marker>Hidi, 1986</marker>
<rawString>V Anderson Hidi. 1986. Producing written summaries: Task demands, cognitive operations, and implications for instruction. Review of educational research.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A King</author>
</authors>
<title>Comparison of self-questioning, summarizing, and notetaking-review as strategies for learning from lectures.</title>
<date>1992</date>
<journal>American Educational Research Journal.</journal>
<contexts>
<context position="1472" citStr="King, 1992" startWordPosition="220" endWordPosition="221"> two commonly used extractive summarisers using ROUGE, with encouraging results. 1 Introduction Kintsch and van Dijk (1978) (henceforth KvD) present a model of human comprehension and memory retention which is based on research in artificial intelligence, experimental psychology and discourse linguistics. It models the processing of incoming text or speech by human memory limitations, and makes verifiable predictions about which propositions in a text will be recalled by subjects later. It has been very influential, particularly in the 1980 and 1990s in educational (Palinscar and Brown, 1984; King, 1992) and cognitive (Paivio, 1990) psychology, and is still today used as a theoretical model of reading and comprehension (Baddeley, 2007; Zwaan, 2003; DeLong et al., 2005; Smith, 2004). It has also been used for improving education, particularly for the production of better instructional text (Britton and Gulgoz, 1991; Pressley, 2006), and for teaching humans how to read for deep comprehension (Coiro and Dobler, 2007; Duke and Pearson, 2002; Koda, 2005; Driscoll, 2005) and to summarise (Hidi, 1986; Brown et al., 1983). In the summarisation community, the model has been commended for its elegant a</context>
</contexts>
<marker>King, 1992</marker>
<rawString>A King. 1992. Comparison of self-questioning, summarizing, and notetaking-review as strategies for learning from lectures. American Educational Research Journal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Walter Kintsch</author>
<author>Teun A van Dijk</author>
</authors>
<title>Toward a model of text comprehension and production. Psychological review,</title>
<date>1978</date>
<pages>85--5</pages>
<marker>Kintsch, van Dijk, 1978</marker>
<rawString>Walter Kintsch and Teun A. van Dijk. 1978. Toward a model of text comprehension and production. Psychological review, 85(5):363–394.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Walter Kintsch</author>
<author>Douglas Vipond</author>
</authors>
<title>Reading comprehension and readability in educational practice and psychological theory.</title>
<date>1979</date>
<booktitle>Perspectives on Memory Research: Essays in Honor of Uppsala’s 500th Anniversary,</booktitle>
<pages>329--365</pages>
<editor>In Lars-G¨oran Nilsson, editor,</editor>
<publisher>Erlbaum Associates.</publisher>
<contexts>
<context position="25058" citStr="Kintsch and Vipond (1979)" startWordPosition="4101" endWordPosition="4104">nce of words, and finds the longest common subsequences (LCSs) with any sentence in a gold standard summary. The score is defined as the Fmeasure of the precision and recall of the LCSs. 3 2 4 14 16 17 18 14 16 17 18 3 2 4 737 The next question is how the gold standard summaries used in ROUGE are defined. Because our summariser is deep and has a fine granularity, it should be compared against human-written summaries on a variety of texts. For the first experiment, we have collected from volunteers 8 human abstractive summaries for each of the 4 short scientific articles or stories we found in Kintsch and Vipond (1979) (average length: 120 words), and 4 for each of 2 longer political news texts (average length: 523 words). The volunteers were instructed to condense the text to 1/3 of its length for the short texts, and to 100 words for the longer ones. They were also instructed not to paraphrase, but to use the words in the text as much as possible. This was because no summariser in this experiment has a paraphrasing ability. Nevertheless, not all subjects followed this instruction strictly. For the second experiment, we use the DUC 2002 dataset (Over and Liggett, 2002). There are 827 texts from news media,</context>
</contexts>
<marker>Kintsch, Vipond, 1979</marker>
<rawString>Walter Kintsch and Douglas Vipond. 1979. Reading comprehension and readability in educational practice and psychological theory. In Lars-G¨oran Nilsson, editor, Perspectives on Memory Research: Essays in Honor of Uppsala’s 500th Anniversary, pages 329– 365. Erlbaum Associates.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Accurate unlexicalized parsing.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics-Volume 1,</booktitle>
<pages>423--430</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="12137" citStr="Klein and Manning, 2003" startWordPosition="1932" endWordPosition="1936">an #37. Proposition Creation Memory Retention Cycle Proposition to text Dependencies Proposition Builder IPs in STM Coherence Detector Extractor Input: Full text Parser Each sentence Output: Summary text Summary propositions Most frequent ones Propositions Human (KvD) Human (KvD) Coherence Tree Selector LTM 734 meaningful arguments to ensure similar potential for overlap. To achieve suitable granularity of propositions, we aggregate information spread out over several grammatical dependencies, and exclude semantically empty words from participating in argument overlap. We use Stanford Parser (Klein and Manning, 2003), and aggregate subjects and complements of a predicate into a single proposition. Active and passive voices are unified; clauses are treated as embedded propositions; controlling subjects of open clausal complements are recovered. Some predicates are not verbs, but nominalised verbs or coordination. For instance, KvD model the phrase “ encounters between police and Black Panther Party members ” as BETWEEN (ENCOUNTER, POLICE, BLACK PANTHER). Producing such a proposition instead of two separate ones BETWEEN (ENCOUNTER, POLICE) and BETWEEN (ENCOUNTER, BLACK PANTHER) is advantageous, because this</context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Dan Klein and Christopher D Manning. 2003. Accurate unlexicalized parsing. In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics-Volume 1, pages 423–430. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
</authors>
<title>Summarization beyond sentence extraction: A probabilistic approach to sentence compression.</title>
<date>2002</date>
<journal>Artificial Intelligence,</journal>
<volume>139</volume>
<issue>1</issue>
<contexts>
<context position="21423" citStr="Knight and Marcu, 2002" startWordPosition="3507" endWordPosition="3510">of the dilemmas in summarisation research is how “deep”, i.e. semantics-oriented, a summariser should be. Shallow analysis of lexical similarity between sentences and/or the keywords contained in sentences has lead to summarisers that are robust and perform very well for most texts (Radev et al., 2004; Dorr and Zajic, 2003; Carbonell and Goldstein, 1998). The methods applied include a random-surfer model (Mihalcea and Tarau, 2004; Radev, 2004), a model of attraction and repulsion of similar summary sentences (Carbonell and Goldstein, 1998). There are statistical models of sentence shortening (Knight and Marcu, 2002). While much work in summarisation has concentrated on multi-document summarisation, where the main challenge is the detection of redundant information, the summariser presented here is a single-document summariser. However, researchers have been attracted by deeper, more symbolic and thus more explanatory summarisation models that use semantic representations of some form (Radev and McKeown, 1998) and often rely on explicit discourse modelling (Lehnert, 1981; Kintsch and van Dijk, 1978; Cohen, 1984). The problem with templatebased summarisers is that they tend to be domaindependent; the probl</context>
</contexts>
<marker>Knight, Marcu, 2002</marker>
<rawString>Kevin Knight and Daniel Marcu. 2002. Summarization beyond sentence extraction: A probabilistic approach to sentence compression. Artificial Intelligence, 139(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Keiko Koda</author>
</authors>
<title>Insights into second language reading: A cross-linguistic approach.</title>
<date>2005</date>
<publisher>Cambridge Univeristy Press.</publisher>
<contexts>
<context position="1925" citStr="Koda, 2005" startWordPosition="294" endWordPosition="295">t will be recalled by subjects later. It has been very influential, particularly in the 1980 and 1990s in educational (Palinscar and Brown, 1984; King, 1992) and cognitive (Paivio, 1990) psychology, and is still today used as a theoretical model of reading and comprehension (Baddeley, 2007; Zwaan, 2003; DeLong et al., 2005; Smith, 2004). It has also been used for improving education, particularly for the production of better instructional text (Britton and Gulgoz, 1991; Pressley, 2006), and for teaching humans how to read for deep comprehension (Coiro and Dobler, 2007; Duke and Pearson, 2002; Koda, 2005; Driscoll, 2005) and to summarise (Hidi, 1986; Brown et al., 1983). In the summarisation community, the model has been commended for its elegant and explanatory “deep” treatment of the summarisation process (Lehnert, 1981; Sp¨arck Jones, 1993; EndresNiggemeyer, 1998), but has not lead to any practical prototypes, mainly due the impossibility of implementing the knowledge- and inference-based aspects the model relies on. We present here an implementation of the model, which attempts to circumvent some of these problems by the application of distributional semantics, and by modelling the constr</context>
</contexts>
<marker>Koda, 2005</marker>
<rawString>Keiko Koda. 2005. Insights into second language reading: A cross-linguistic approach. Cambridge Univeristy Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wendy G Lehnert</author>
</authors>
<title>Plot units and narrative summarization.</title>
<date>1981</date>
<journal>Cognitive Science,</journal>
<volume>5</volume>
<issue>4</issue>
<contexts>
<context position="2147" citStr="Lehnert, 1981" startWordPosition="329" endWordPosition="330">sed as a theoretical model of reading and comprehension (Baddeley, 2007; Zwaan, 2003; DeLong et al., 2005; Smith, 2004). It has also been used for improving education, particularly for the production of better instructional text (Britton and Gulgoz, 1991; Pressley, 2006), and for teaching humans how to read for deep comprehension (Coiro and Dobler, 2007; Duke and Pearson, 2002; Koda, 2005; Driscoll, 2005) and to summarise (Hidi, 1986; Brown et al., 1983). In the summarisation community, the model has been commended for its elegant and explanatory “deep” treatment of the summarisation process (Lehnert, 1981; Sp¨arck Jones, 1993; EndresNiggemeyer, 1998), but has not lead to any practical prototypes, mainly due the impossibility of implementing the knowledge- and inference-based aspects the model relies on. We present here an implementation of the model, which attempts to circumvent some of these problems by the application of distributional semantics, and by modelling the construction of the coherence tree as a double competition (firstly of concept partners for word forms, secondly of attachment sites for propositions). In the KvD model, a text (e.g. Figure 1) is converted into propositions (see</context>
<context position="21886" citStr="Lehnert, 1981" startWordPosition="3576" endWordPosition="3577">d repulsion of similar summary sentences (Carbonell and Goldstein, 1998). There are statistical models of sentence shortening (Knight and Marcu, 2002). While much work in summarisation has concentrated on multi-document summarisation, where the main challenge is the detection of redundant information, the summariser presented here is a single-document summariser. However, researchers have been attracted by deeper, more symbolic and thus more explanatory summarisation models that use semantic representations of some form (Radev and McKeown, 1998) and often rely on explicit discourse modelling (Lehnert, 1981; Kintsch and van Dijk, 1978; Cohen, 1984). The problem with templatebased summarisers is that they tend to be domaindependent; the problem with discourse structurebased summarisers is in general that they require knowledge modelling and reasoning far beyond the capability of today’s state of the art in artificial intelligence. Rhetorical Structure Theory (Mann and Thompson, 1987) provides a domainindependent framework that takes local discourse structure into account, which has lead to a successful prototype summariser (Marcu, 2000). This summarisation strategy does not however look at the le</context>
</contexts>
<marker>Lehnert, 1981</marker>
<rawString>Wendy G Lehnert. 1981. Plot units and narrative summarization. Cognitive Science, 5(4):293–331.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chin-Yew Lin</author>
<author>Eduard Hovy</author>
</authors>
<title>Automatic evaluation of summaries using n-gram co-occurrence statistics.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language TechnologyVolume 1,</booktitle>
<pages>71--78</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="8767" citStr="Lin and Hovy, 2003" startWordPosition="1398" endWordPosition="1401"> experiments presented here test whether our hypotheses 1 – 4 are strong enough to provide our summariser with useful information concerning the discourse structure of the texts. We test this by comparing its performance to that of two current state-of-the-art summarisers, which instead rely on the sole use of lexical information. A psychologically-motivated summariser such as ours should be evaluated by comparison to abstractive, i.e., reformulated human summaries, rather than by comparison to extractive summaries. We do so using ROUGE, an evaluation framework that supports such comparisons (Lin and Hovy, 2003). The structure of the paper is as follows. In the next section, we will detail our implementation of the KvD model, with particular emphasis on the creation of propositions, probabilistic concepts, proposition attachment, and root choice. In Section 4, we will present experiments comparing our summariser against two research extractive summarisers, MEAD and LexRank. We also test how our inventions including similarity-based concept matching and root choice strategy contribute to performance. We compare to related work in Section 3, and draw our conclusions in Section 5. 2 Our implementation o</context>
</contexts>
<marker>Lin, Hovy, 2003</marker>
<rawString>Chin-Yew Lin and Eduard Hovy. 2003. Automatic evaluation of summaries using n-gram co-occurrence statistics. In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language TechnologyVolume 1, pages 71–78. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Automatic retrieval and clustering of similar words.</title>
<date>1998</date>
<booktitle>In Proceedings of the 17th international conference on Computational linguistics-Volume 2,</booktitle>
<pages>768--774</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="14706" citStr="Lin, 1998" startWordPosition="2334" endWordPosition="2335">o one such equivalence class. The KvD model, because it simulates concept mapping and proposition attachment in parallel, conceals some of the choices that a fully automatic model has to make. Given current technology, concept mapping can only be performed probabilistically. We use the Stanford coreference resolution, named-entity detection (to extend coreference detection to nonsame-head references, e.g. mapping “the tech giant” to “Apple Inc.”2); and to find synonymy or at least semantic relatedness, we use a wellknown measure of semantic similarity, namely Lin’s Dependency-Based Thesaurus (Lin, 1998). We are not committed to this particular measure, but it empirically performed best out of the 11 we tried; especially it outperformed WordNet pathbased measures. Note however that only the 200 most similar words for each word are provided by this tool. The similarity measure is normalised by relative ranking to provide the probability that an expression refers to the same concept as another expression. We use WordNet (Miller, 1995) for derivationally related forms (to solve e.g. nominalisation). This establishes the first competition, the one between concept matches. law enforcement officers</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>Dekang Lin. 1998. Automatic retrieval and clustering of similar words. In Proceedings of the 17th international conference on Computational linguistics-Volume 2, pages 768–774. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chin-Yew Lin</author>
</authors>
<title>ROUGE: A package for automatic evaluation of summaries.</title>
<date>2004</date>
<booktitle>In Text Summarization Branches Out: Proceedings of the ACL-04 Workshop,</booktitle>
<pages>74--81</pages>
<contexts>
<context position="24324" citStr="Lin, 2004" startWordPosition="3967" endWordPosition="3968">ld be interesting to combine their notion of entity-based coherence with KvD’s notion of argument overlap. 4 Experiments We now perform two experiments. The first tests the contribution of our concept matcher and root change strategy on a small document set we have collected, and compares against two research summarisers. In the second experiment, we test the performance of our summariser on a much larger and standard dataset. We will use the intrinsic evaluation strategy of comparison to a gold standard. Human judgements would be the most credible, but as a cheap alternative, we use ROUGE-L (Lin, 2004), which has been shown to correlate well to human judgements. For each sentence, ROUGE-L treats it as a sequence of words, and finds the longest common subsequences (LCSs) with any sentence in a gold standard summary. The score is defined as the Fmeasure of the precision and recall of the LCSs. 3 2 4 14 16 17 18 14 16 17 18 3 2 4 737 The next question is how the gold standard summaries used in ROUGE are defined. Because our summariser is deep and has a fine granularity, it should be compared against human-written summaries on a variety of texts. For the first experiment, we have collected from</context>
</contexts>
<marker>Lin, 2004</marker>
<rawString>Chin-Yew Lin. 2004. ROUGE: A package for automatic evaluation of summaries. In Text Summarization Branches Out: Proceedings of the ACL-04 Workshop, pages 74–81.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William C Mann</author>
<author>Sandra A Thompson</author>
</authors>
<title>Rhetorical Structure Theory: Description and construction of text structures.</title>
<date>1987</date>
<booktitle>Natural Language Generation: New Results in Artificial Intelligence, Psychology, and Linguistics,</booktitle>
<pages>85--95</pages>
<editor>In Gerard Kempen, editor,</editor>
<publisher>Marinus Nijhoff Publishers,</publisher>
<location>Dordrecht, NL.</location>
<contexts>
<context position="22269" citStr="Mann and Thompson, 1987" startWordPosition="3633" endWordPosition="3636">r, researchers have been attracted by deeper, more symbolic and thus more explanatory summarisation models that use semantic representations of some form (Radev and McKeown, 1998) and often rely on explicit discourse modelling (Lehnert, 1981; Kintsch and van Dijk, 1978; Cohen, 1984). The problem with templatebased summarisers is that they tend to be domaindependent; the problem with discourse structurebased summarisers is in general that they require knowledge modelling and reasoning far beyond the capability of today’s state of the art in artificial intelligence. Rhetorical Structure Theory (Mann and Thompson, 1987) provides a domainindependent framework that takes local discourse structure into account, which has lead to a successful prototype summariser (Marcu, 2000). This summarisation strategy does not however look at the lexical content of the propositions or clauselike units it connects, only at the way how the connection is performed. The summariser presented here is a hybrid: its core algorithm is symbolic, but its limited powers of generalisation come from a semantic similarity metric that is defined via distributionally derived probabilities. Because its core processing is symbolic and based on</context>
</contexts>
<marker>Mann, Thompson, 1987</marker>
<rawString>William C. Mann and Sandra A. Thompson. 1987. Rhetorical Structure Theory: Description and construction of text structures. In Gerard Kempen, editor, Natural Language Generation: New Results in Artificial Intelligence, Psychology, and Linguistics, pages 85–95. Marinus Nijhoff Publishers, Dordrecht, NL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Marcu</author>
</authors>
<title>The Theory and Practice of Discourse Parsing and Summarization.</title>
<date>2000</date>
<booktitle>In Proceedings of the EMLNP.</booktitle>
<publisher>MIT</publisher>
<contexts>
<context position="22425" citStr="Marcu, 2000" startWordPosition="3658" endWordPosition="3659">eown, 1998) and often rely on explicit discourse modelling (Lehnert, 1981; Kintsch and van Dijk, 1978; Cohen, 1984). The problem with templatebased summarisers is that they tend to be domaindependent; the problem with discourse structurebased summarisers is in general that they require knowledge modelling and reasoning far beyond the capability of today’s state of the art in artificial intelligence. Rhetorical Structure Theory (Mann and Thompson, 1987) provides a domainindependent framework that takes local discourse structure into account, which has lead to a successful prototype summariser (Marcu, 2000). This summarisation strategy does not however look at the lexical content of the propositions or clauselike units it connects, only at the way how the connection is performed. The summariser presented here is a hybrid: its core algorithm is symbolic, but its limited powers of generalisation come from a semantic similarity metric that is defined via distributionally derived probabilities. Because its core processing is symbolic and based on a simple semantic representation, it is possible to derive an explanation based on the coherence tree and the propositions selected from it. There are some</context>
</contexts>
<marker>Marcu, 2000</marker>
<rawString>Daniel Marcu. 2000. The Theory and Practice of Discourse Parsing and Summarization. MIT Press. R Mihalcea and P Tarau. 2004. Textrank: Bringing order into texts. In Proceedings of the EMLNP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
</authors>
<title>Wordnet: a lexical database for english.</title>
<date>1995</date>
<journal>Communications of the ACM,</journal>
<volume>38</volume>
<issue>11</issue>
<pages>41</pages>
<contexts>
<context position="15143" citStr="Miller, 1995" startWordPosition="2405" endWordPosition="2406">to “Apple Inc.”2); and to find synonymy or at least semantic relatedness, we use a wellknown measure of semantic similarity, namely Lin’s Dependency-Based Thesaurus (Lin, 1998). We are not committed to this particular measure, but it empirically performed best out of the 11 we tried; especially it outperformed WordNet pathbased measures. Note however that only the 200 most similar words for each word are provided by this tool. The similarity measure is normalised by relative ranking to provide the probability that an expression refers to the same concept as another expression. We use WordNet (Miller, 1995) for derivationally related forms (to solve e.g. nominalisation). This establishes the first competition, the one between concept matches. law enforcement officers members of the Panther Party Figure 3: KvD’s concept matching. Figure 4: Probabilistic concept matching. Modelling concepts probabilistically has its implication for the next task: finding the best attachment site for a proposition. Let us explain this with an example. Notice that in the example text in Figure 1, “police” (from #4, in the first sentence) and 2A WordNet synset is defined for each named-entity type; here “giant” is co</context>
</contexts>
<marker>Miller, 1995</marker>
<rawString>George A Miller. 1995. Wordnet: a lexical database for english. Communications of the ACM, 38(11):39– 41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Over</author>
<author>W Liggett</author>
</authors>
<title>Introduction to duc: An intrinsic evaluation of generic news text summarization systems.</title>
<date>2002</date>
<booktitle>In Proc. DUC. http://wwwnlpir.nist.gov/projects/duc/guidelines/2002.html.</booktitle>
<contexts>
<context position="25620" citStr="Over and Liggett, 2002" startWordPosition="4199" endWordPosition="4202">fic articles or stories we found in Kintsch and Vipond (1979) (average length: 120 words), and 4 for each of 2 longer political news texts (average length: 523 words). The volunteers were instructed to condense the text to 1/3 of its length for the short texts, and to 100 words for the longer ones. They were also instructed not to paraphrase, but to use the words in the text as much as possible. This was because no summariser in this experiment has a paraphrasing ability. Nevertheless, not all subjects followed this instruction strictly. For the second experiment, we use the DUC 2002 dataset (Over and Liggett, 2002). There are 827 texts from news media, of a variety of topics and lengths, among which our script is able to extract titles and contents of 822 documents. We use the provided single document abstractive summaries, which are of 100 words in length each, as gold standard summaries. A few of the documents are selected in multiple clusters and therefore have multiple summaries; all of them are used in evaluation. We compare our summariser against a baseline constructed with the first n words from the original text, where n is the summary length as defined above, and two summarisers: MEAD (Radev et</context>
</contexts>
<marker>Over, Liggett, 2002</marker>
<rawString>Paul Over and W Liggett. 2002. Introduction to duc: An intrinsic evaluation of generic news text summarization systems. In Proc. DUC. http://wwwnlpir.nist.gov/projects/duc/guidelines/2002.html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Paivio</author>
</authors>
<title>Mental representations.</title>
<date>1990</date>
<publisher>Oxford Science Publications.</publisher>
<contexts>
<context position="1501" citStr="Paivio, 1990" startWordPosition="224" endWordPosition="225">ve summarisers using ROUGE, with encouraging results. 1 Introduction Kintsch and van Dijk (1978) (henceforth KvD) present a model of human comprehension and memory retention which is based on research in artificial intelligence, experimental psychology and discourse linguistics. It models the processing of incoming text or speech by human memory limitations, and makes verifiable predictions about which propositions in a text will be recalled by subjects later. It has been very influential, particularly in the 1980 and 1990s in educational (Palinscar and Brown, 1984; King, 1992) and cognitive (Paivio, 1990) psychology, and is still today used as a theoretical model of reading and comprehension (Baddeley, 2007; Zwaan, 2003; DeLong et al., 2005; Smith, 2004). It has also been used for improving education, particularly for the production of better instructional text (Britton and Gulgoz, 1991; Pressley, 2006), and for teaching humans how to read for deep comprehension (Coiro and Dobler, 2007; Duke and Pearson, 2002; Koda, 2005; Driscoll, 2005) and to summarise (Hidi, 1986; Brown et al., 1983). In the summarisation community, the model has been commended for its elegant and explanatory “deep” treatme</context>
</contexts>
<marker>Paivio, 1990</marker>
<rawString>A Paivio. 1990. Mental representations. Oxford Science Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aannemarie Sullivan Palinscar</author>
<author>Ann L Brown</author>
</authors>
<title>Reciprocal teaching of comprehension-fostering and comprehension-monitoring activities. Cognition and Instruction,</title>
<date>1984</date>
<pages>1--117</pages>
<contexts>
<context position="1459" citStr="Palinscar and Brown, 1984" startWordPosition="215" endWordPosition="219">esulting summariser against two commonly used extractive summarisers using ROUGE, with encouraging results. 1 Introduction Kintsch and van Dijk (1978) (henceforth KvD) present a model of human comprehension and memory retention which is based on research in artificial intelligence, experimental psychology and discourse linguistics. It models the processing of incoming text or speech by human memory limitations, and makes verifiable predictions about which propositions in a text will be recalled by subjects later. It has been very influential, particularly in the 1980 and 1990s in educational (Palinscar and Brown, 1984; King, 1992) and cognitive (Paivio, 1990) psychology, and is still today used as a theoretical model of reading and comprehension (Baddeley, 2007; Zwaan, 2003; DeLong et al., 2005; Smith, 2004). It has also been used for improving education, particularly for the production of better instructional text (Britton and Gulgoz, 1991; Pressley, 2006), and for teaching humans how to read for deep comprehension (Coiro and Dobler, 2007; Duke and Pearson, 2002; Koda, 2005; Driscoll, 2005) and to summarise (Hidi, 1986; Brown et al., 1983). In the summarisation community, the model has been commended for </context>
</contexts>
<marker>Palinscar, Brown, 1984</marker>
<rawString>Aannemarie Sullivan Palinscar and Ann L. Brown. 1984. Reciprocal teaching of comprehension-fostering and comprehension-monitoring activities. Cognition and Instruction, 1:117–175.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Pressley</author>
</authors>
<title>Reading instruction that works: The case for balanced teaching.</title>
<date>2006</date>
<publisher>Guildford Press.</publisher>
<contexts>
<context position="1805" citStr="Pressley, 2006" startWordPosition="273" endWordPosition="274">ng of incoming text or speech by human memory limitations, and makes verifiable predictions about which propositions in a text will be recalled by subjects later. It has been very influential, particularly in the 1980 and 1990s in educational (Palinscar and Brown, 1984; King, 1992) and cognitive (Paivio, 1990) psychology, and is still today used as a theoretical model of reading and comprehension (Baddeley, 2007; Zwaan, 2003; DeLong et al., 2005; Smith, 2004). It has also been used for improving education, particularly for the production of better instructional text (Britton and Gulgoz, 1991; Pressley, 2006), and for teaching humans how to read for deep comprehension (Coiro and Dobler, 2007; Duke and Pearson, 2002; Koda, 2005; Driscoll, 2005) and to summarise (Hidi, 1986; Brown et al., 1983). In the summarisation community, the model has been commended for its elegant and explanatory “deep” treatment of the summarisation process (Lehnert, 1981; Sp¨arck Jones, 1993; EndresNiggemeyer, 1998), but has not lead to any practical prototypes, mainly due the impossibility of implementing the knowledge- and inference-based aspects the model relies on. We present here an implementation of the model, which a</context>
</contexts>
<marker>Pressley, 2006</marker>
<rawString>Michael Pressley. 2006. Reading instruction that works: The case for balanced teaching. Guildford Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dragomir R Radev</author>
<author>Kathleen R McKeown</author>
</authors>
<title>Generating natural language summaries from multiple on-line sources.</title>
<date>1998</date>
<pages>24--3</pages>
<contexts>
<context position="21824" citStr="Radev and McKeown, 1998" startWordPosition="3564" endWordPosition="3568">r model (Mihalcea and Tarau, 2004; Radev, 2004), a model of attraction and repulsion of similar summary sentences (Carbonell and Goldstein, 1998). There are statistical models of sentence shortening (Knight and Marcu, 2002). While much work in summarisation has concentrated on multi-document summarisation, where the main challenge is the detection of redundant information, the summariser presented here is a single-document summariser. However, researchers have been attracted by deeper, more symbolic and thus more explanatory summarisation models that use semantic representations of some form (Radev and McKeown, 1998) and often rely on explicit discourse modelling (Lehnert, 1981; Kintsch and van Dijk, 1978; Cohen, 1984). The problem with templatebased summarisers is that they tend to be domaindependent; the problem with discourse structurebased summarisers is in general that they require knowledge modelling and reasoning far beyond the capability of today’s state of the art in artificial intelligence. Rhetorical Structure Theory (Mann and Thompson, 1987) provides a domainindependent framework that takes local discourse structure into account, which has lead to a successful prototype summariser (Marcu, 2000</context>
</contexts>
<marker>Radev, McKeown, 1998</marker>
<rawString>Dragomir R. Radev and Kathleen R. McKeown. 1998. Generating natural language summaries from multiple on-line sources. 24(3):469–500.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dragomir Radev</author>
<author>Timothy Allison</author>
<author>Sasha BlairGoldensohn</author>
<author>John Blitzer</author>
<author>Arda Celebi</author>
<author>Stanko Dimitrov</author>
<author>Elliott Drabek</author>
<author>Ali Hakim</author>
<author>Wai Lam</author>
<author>Danyu Liu</author>
<author>Jahna Otterbacher</author>
<author>Hong Qi</author>
<author>Horacio Saggion</author>
<author>Simone Teufel</author>
<author>Michael Topper</author>
<author>Adam Winkel</author>
<author>Zhu Zhang</author>
</authors>
<title>Mead – a platform for multidocument multilingual text summarization.</title>
<date>2004</date>
<booktitle>In Proceedings of LREC-04.</booktitle>
<contexts>
<context position="21102" citStr="Radev et al., 2004" startWordPosition="3460" endWordPosition="3463">re permitted, the one with the highest s is chosen. 736 that the identity of Panther Party members are actually the author’s students, the summariser recognises this change after reading one more sentence, by flipping the edge connecting #3 and #14. Figure 5: Tree before and after a root change. 3 Related Work One of the dilemmas in summarisation research is how “deep”, i.e. semantics-oriented, a summariser should be. Shallow analysis of lexical similarity between sentences and/or the keywords contained in sentences has lead to summarisers that are robust and perform very well for most texts (Radev et al., 2004; Dorr and Zajic, 2003; Carbonell and Goldstein, 1998). The methods applied include a random-surfer model (Mihalcea and Tarau, 2004; Radev, 2004), a model of attraction and repulsion of similar summary sentences (Carbonell and Goldstein, 1998). There are statistical models of sentence shortening (Knight and Marcu, 2002). While much work in summarisation has concentrated on multi-document summarisation, where the main challenge is the detection of redundant information, the summariser presented here is a single-document summariser. However, researchers have been attracted by deeper, more symbol</context>
<context position="26231" citStr="Radev et al., 2004" startWordPosition="4305" endWordPosition="4308">t, 2002). There are 827 texts from news media, of a variety of topics and lengths, among which our script is able to extract titles and contents of 822 documents. We use the provided single document abstractive summaries, which are of 100 words in length each, as gold standard summaries. A few of the documents are selected in multiple clusters and therefore have multiple summaries; all of them are used in evaluation. We compare our summariser against a baseline constructed with the first n words from the original text, where n is the summary length as defined above, and two summarisers: MEAD (Radev et al., 2004) is a research summariser which uses a centroid-based paradigm and is known to perform generally well over a range of texts. LexRank (Radev, 2004) uses lexically derived similarities in its similarity graph of sentences, sharing the same idea of sentence similarity with MEAD. Note that both summarisers are extractive. We illustrate what our summaries look like in Table 2, where we asked the summariser to give us summaries as close to 20 and 50 word summaries as possible, with Table 3 showing the underlying propositions. In contrast, MEAD can only extract sentences as-is (thus not as flexible i</context>
</contexts>
<marker>Radev, Allison, BlairGoldensohn, Blitzer, Celebi, Dimitrov, Drabek, Hakim, Lam, Liu, Otterbacher, Qi, Saggion, Teufel, Topper, Winkel, Zhang, 2004</marker>
<rawString>Dragomir Radev, Timothy Allison, Sasha BlairGoldensohn, John Blitzer, Arda Celebi, Stanko Dimitrov, Elliott Drabek, Ali Hakim, Wai Lam, Danyu Liu, Jahna Otterbacher, Hong Qi, Horacio Saggion, Simone Teufel, Michael Topper, Adam Winkel, and Zhu Zhang. 2004. Mead – a platform for multidocument multilingual text summarization. In Proceedings of LREC-04.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dragomir R Radev</author>
</authors>
<title>Lexrank: Graph-based lexical centrality as salience in text summarization.</title>
<date>2004</date>
<journal>Journal of Artificial Intelligence Research.</journal>
<contexts>
<context position="21247" citStr="Radev, 2004" startWordPosition="3483" endWordPosition="3484">ecognises this change after reading one more sentence, by flipping the edge connecting #3 and #14. Figure 5: Tree before and after a root change. 3 Related Work One of the dilemmas in summarisation research is how “deep”, i.e. semantics-oriented, a summariser should be. Shallow analysis of lexical similarity between sentences and/or the keywords contained in sentences has lead to summarisers that are robust and perform very well for most texts (Radev et al., 2004; Dorr and Zajic, 2003; Carbonell and Goldstein, 1998). The methods applied include a random-surfer model (Mihalcea and Tarau, 2004; Radev, 2004), a model of attraction and repulsion of similar summary sentences (Carbonell and Goldstein, 1998). There are statistical models of sentence shortening (Knight and Marcu, 2002). While much work in summarisation has concentrated on multi-document summarisation, where the main challenge is the detection of redundant information, the summariser presented here is a single-document summariser. However, researchers have been attracted by deeper, more symbolic and thus more explanatory summarisation models that use semantic representations of some form (Radev and McKeown, 1998) and often rely on expl</context>
<context position="26377" citStr="Radev, 2004" startWordPosition="4331" endWordPosition="4332">ocuments. We use the provided single document abstractive summaries, which are of 100 words in length each, as gold standard summaries. A few of the documents are selected in multiple clusters and therefore have multiple summaries; all of them are used in evaluation. We compare our summariser against a baseline constructed with the first n words from the original text, where n is the summary length as defined above, and two summarisers: MEAD (Radev et al., 2004) is a research summariser which uses a centroid-based paradigm and is known to perform generally well over a range of texts. LexRank (Radev, 2004) uses lexically derived similarities in its similarity graph of sentences, sharing the same idea of sentence similarity with MEAD. Note that both summarisers are extractive. We illustrate what our summaries look like in Table 2, where we asked the summariser to give us summaries as close to 20 and 50 word summaries as possible, with Table 3 showing the underlying propositions. In contrast, MEAD can only extract sentences as-is (thus not as flexible in length), and does not have meaning blocks like our propositions. Encounters between police and Black Panther members. Students to complain of ha</context>
</contexts>
<marker>Radev, 2004</marker>
<rawString>Dragomir R. Radev. 2004. Lexrank: Graph-based lexical centrality as salience in text summarization. Journal of Artificial Intelligence Research.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Smith</author>
</authors>
<title>Understanding reading: A psycholinguistic analysis of reading and learning to read. Lawrence Erlbaum.</title>
<date>2004</date>
<contexts>
<context position="1653" citStr="Smith, 2004" startWordPosition="249" endWordPosition="250">and memory retention which is based on research in artificial intelligence, experimental psychology and discourse linguistics. It models the processing of incoming text or speech by human memory limitations, and makes verifiable predictions about which propositions in a text will be recalled by subjects later. It has been very influential, particularly in the 1980 and 1990s in educational (Palinscar and Brown, 1984; King, 1992) and cognitive (Paivio, 1990) psychology, and is still today used as a theoretical model of reading and comprehension (Baddeley, 2007; Zwaan, 2003; DeLong et al., 2005; Smith, 2004). It has also been used for improving education, particularly for the production of better instructional text (Britton and Gulgoz, 1991; Pressley, 2006), and for teaching humans how to read for deep comprehension (Coiro and Dobler, 2007; Duke and Pearson, 2002; Koda, 2005; Driscoll, 2005) and to summarise (Hidi, 1986; Brown et al., 1983). In the summarisation community, the model has been commended for its elegant and explanatory “deep” treatment of the summarisation process (Lehnert, 1981; Sp¨arck Jones, 1993; EndresNiggemeyer, 1998), but has not lead to any practical prototypes, mainly due t</context>
</contexts>
<marker>Smith, 2004</marker>
<rawString>F Smith. 2004. Understanding reading: A psycholinguistic analysis of reading and learning to read. Lawrence Erlbaum.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karen Sp¨arck Jones</author>
</authors>
<title>What might be in a summary?</title>
<date>1993</date>
<tech>Technical report,</tech>
<institution>Computer Laboratory, University of Cambridge.</institution>
<contexts>
<context position="2168" citStr="Jones, 1993" startWordPosition="332" endWordPosition="333">del of reading and comprehension (Baddeley, 2007; Zwaan, 2003; DeLong et al., 2005; Smith, 2004). It has also been used for improving education, particularly for the production of better instructional text (Britton and Gulgoz, 1991; Pressley, 2006), and for teaching humans how to read for deep comprehension (Coiro and Dobler, 2007; Duke and Pearson, 2002; Koda, 2005; Driscoll, 2005) and to summarise (Hidi, 1986; Brown et al., 1983). In the summarisation community, the model has been commended for its elegant and explanatory “deep” treatment of the summarisation process (Lehnert, 1981; Sp¨arck Jones, 1993; EndresNiggemeyer, 1998), but has not lead to any practical prototypes, mainly due the impossibility of implementing the knowledge- and inference-based aspects the model relies on. We present here an implementation of the model, which attempts to circumvent some of these problems by the application of distributional semantics, and by modelling the construction of the coherence tree as a double competition (firstly of concept partners for word forms, secondly of attachment sites for propositions). In the KvD model, a text (e.g. Figure 1) is converted into propositions (see Table 1) which have </context>
</contexts>
<marker>Jones, 1993</marker>
<rawString>Karen Sp¨arck Jones. 1993. What might be in a summary? Technical report, Computer Laboratory, University of Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Teun A van Dijk</author>
</authors>
<date>1977</date>
<booktitle>Text and Context: Explorations in the Semantics and Pragmatics of Discourse.</booktitle>
<location>Longman, London, UK.</location>
<marker>van Dijk, 1977</marker>
<rawString>Teun A. van Dijk. 1977. Text and Context: Explorations in the Semantics and Pragmatics of Discourse. Longman, London, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>RA Zwaan</author>
</authors>
<title>The immersed experiencer: Toward an embodied theory of language comprehension. Psychology of learning and motivation.</title>
<date>2003</date>
<contexts>
<context position="1618" citStr="Zwaan, 2003" startWordPosition="243" endWordPosition="244">nt a model of human comprehension and memory retention which is based on research in artificial intelligence, experimental psychology and discourse linguistics. It models the processing of incoming text or speech by human memory limitations, and makes verifiable predictions about which propositions in a text will be recalled by subjects later. It has been very influential, particularly in the 1980 and 1990s in educational (Palinscar and Brown, 1984; King, 1992) and cognitive (Paivio, 1990) psychology, and is still today used as a theoretical model of reading and comprehension (Baddeley, 2007; Zwaan, 2003; DeLong et al., 2005; Smith, 2004). It has also been used for improving education, particularly for the production of better instructional text (Britton and Gulgoz, 1991; Pressley, 2006), and for teaching humans how to read for deep comprehension (Coiro and Dobler, 2007; Duke and Pearson, 2002; Koda, 2005; Driscoll, 2005) and to summarise (Hidi, 1986; Brown et al., 1983). In the summarisation community, the model has been commended for its elegant and explanatory “deep” treatment of the summarisation process (Lehnert, 1981; Sp¨arck Jones, 1993; EndresNiggemeyer, 1998), but has not lead to any</context>
</contexts>
<marker>Zwaan, 2003</marker>
<rawString>RA Zwaan. 2003. The immersed experiencer: Toward an embodied theory of language comprehension. Psychology of learning and motivation.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>