<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.015950">
<title confidence="0.7546805">
Book Reviews
Spoken Natural Language Dialogue Systems: A Practical Approach
</title>
<author confidence="0.716275">
Ronnie W. Smith and D. Richard Hipp
</author>
<affiliation confidence="0.773488">
(East Carolina University and Hipp, Wyrick and Company, Inc.)
</affiliation>
<address confidence="0.756405">
New York: Oxford University Press,
1994, xiv+299 pp; hardbound, ISBN
</address>
<figure confidence="0.60564575">
0-19-509187-6, $49.95
Reviewed by
David R. Traum
Universite de Geneve
</figure>
<bodyText confidence="0.999602647058824">
This book gives a detailed yet readable account of the design, implementation, testing,
and analysis of a spoken task-oriented dialogue system. Although there is a thorough
reporting of related work, the plural in the main title is a bit misleading, as the book
focuses on only one system, built by the authors at Duke University. The subtitle is
well warranted, as Smith and Hipp put a premium on achieving useful interaction
rather than adherence to any particular psychological or linguistic theory of language
processing.
The writing is generally clear, even when discussing details of the sometimes
complex algorithms. The index is also very helpful. In addition, for those who want
more specifics, an appendix gives instructions for electronically obtaining the dialogue
system code and transcripts of user interactions with the system. The code is also
commented with pointers to aspects of the book, including sections, figures, and pages.
Smith and Hipp carefully point out not only the successes of their system, but also its
shortcomings and some prospects for improvement.
Smith and Hipp do a good job of describing and analyzing related work and
comparing it to their own system. Chapter 2, in particular, reviews foundational work
on dialogue processing. The main focus is on work in the subareas of speech act
processing, user modeling, use of expectations, and mixed initiative. Also included are
several other proposals for integrated dialogue models. The highlight of the chapter
is a comparison of 26 other dialogue systems, mostly from the 1980&apos;s, listing the
application domain and output modality, as well as the types of processing performed
and how the systems were evaluated. Other related work is introduced as appropriate
in subsequent chapters. The authors are perhaps not quite as successful in recasting the
innovations from their own implementation in a more general conceptual framework
that could be useful for designers of systems with very different architectures.
A task-oriented spoken language dialogue system is a large piece of software,
requiring successful integration of a number of heterogeneous subcomponents to per-
form at least the following functions: speech recognition, language understanding,
dialogue reasoning, task reasoning, language generation, and speech generation. The
thrust of the authors&apos; work is on the language-understanding and dialogue-reasoning
components, as well as the overall architecture that ties these subsystems together.
These aspects are also presented more briefly by Smith, Hipp, and Biermann (1995),
who also include a more detailed discussion of the relationship to Grosz and Sidner&apos;s
(1986) theory of discourse structure.
</bodyText>
<subsectionHeader confidence="0.974194">
Book Reviews
</subsectionHeader>
<bodyText confidence="0.999987568627451">
The authors&apos; system used independent components for speech recognition (speaker-
dependent connected speech) and output, while the main dialogue processing took
place on a Sun 4 workstation, running Prolog and C. The system understood a vocab-
ulary of 125 words, and used 560 grammar rules. Users of the system were instructed
to perform single-sentence utterances of 3-6 words in length, waiting for system re-
sponse before uttering a new sentence. Normal response time for the whole system
was 6-8 seconds for utterances of this length. All the words were correctly recog-
nized in only 50% of 2,840 utterances, although the error-correcting parser managed
to achieve the correct meaning in 81% of the utterances.
As this book demonstrates, a task-oriented dialogue system must be more than
just an interface or front-end. For coherent dialogue, it is crucial that there be close
cooperation between the task and language-reasoning modules. In order to interpret
utterances in context, respond appropriately, and track user focus, the dialogue system
must have some idea of what the task reasoner is doing, at least at an abstract level.
The authors adopt a strong hypothesis here that dialogue structure is task structure,
following the intentional discourse structure of Grosz and Sidner (1986). Each task step
is related to a (potential) subdialogue, and expectations and meaning interpretation
are always computed relative to the focused or likely subdialogues.
The domain processor uses Prolog-style theorem-proving on a set of plan libraries
in the form of circuit-diagnosis proofs. The authors connect task reasoning to language
by what they call the Missing Axiom Theory. Some of the axioms in the diagnosis
proofs refer to knowledge of states of the world or the performance of actions. When
these axioms are missing (i.e., the system knows that they would help in the proof,
but can&apos;t prove them), actions or observations must be performed. In particular, since
this system has no way to directly sense or act upon the elements of the circuit, it
must use language to instruct the user to perform the desired actions. Thus, language
is viewed as a way of providing missing axioms for the circuit diagnosis.
Being embedded within an interactive dialogue system provides constraints on the
domain task reasoning itself. In particular, the system must be able to reason about
action and plans from both directions: from world-state to best-solution path—in order
to output requests for action and observation to the user, and from arbitrary action or
observation and world-state to likely plan step—for interpreting user utterances in con-
text. As well, the system reasoning must be prompt (for quick response, maintaining
fluid interactivity) and interruptible—full proofs must be interspersed with actions and
observations. For this purpose, the authors have implemented a modified Prolog sys-
tem that allows a user (or, in this case, the dialogue system) access to an ongoing proof,
with the ability to notice and provide missing axioms, or modify the proving process.
The system starts the process of understanding user inputs by reasoning about
context before actually interpreting the language input; the system calculates a set of
expectations of what the user will say in the current circumstance. There are a number
of possible user responses at any given point, and the authors classify the expectations
into those coming from the task processor (e.g., descriptions of a component) or the
dialogue controller (descriptions of subgoals or reference to ancestor subdialogues),
and in each of these categories, whether they are specifically about the situation or
task itself, or merely related.
These expectations are ordered and weighted as to likelihood and used to help
disambiguate parses, as well as provide necessary contextual information for providing
full interpretations of pronouns, elided material, and short answers such as &amp;quot;yes.&amp;quot;
Some of the expectations will have variables included (e.g., for a numerical value
when expecting the report of a measurement). These underspecified expectations are
unified with similar forms that result from parsing the user&apos;s input. When completely
</bodyText>
<page confidence="0.993158">
431
</page>
<note confidence="0.618205">
Computational Linguistics Volume 22, Number 3
</note>
<bodyText confidence="0.999810941176471">
unexpected inputs occur that the system cannot relate to the current task structure, it
tries to teach the user how to perform the current goal (making the assumption that
the user utterance was a misunderstood attempt to discuss this goal).
The main input to the parser is a lattice of the word possibilities produced by
the speech recognizer. Also provided is the set of expectations calculated by the di-
alogue module. The parser computes the most likely parses using an n3m dynamic
programming algorithm (where n is the size of the input string, and m is the size of the
grammar), assigning a cost function based on string distance between the actual input
and the right-hand side of a grammar rule. The least expensive parses are compared to
the expectations produced by the dialogue system, for final selection of the interpreta-
tion. For the dialogues collected in their experiments, the authors determined that the
dialogue expectations help only to disambiguate parses with equal cost. Thus, in fact,
the way expectations are used turns out to be equivalent to the &amp;quot;traditional&amp;quot; pipe-lined
processing model, in which context is consulted after producing an initial parse. What
is interesting, though, is the authors&apos; practical approach, which determined this fact
empirically by examining the performance on the actual input.
Another important aspect of dialogue is the degree of initiative taken by the
system (Whittaker and Stenton 1988). This amounts to a determination of which par-
ticipant will guide the direction of the dialogue and to what degree. Smith and Hipp
include four levels of initiative, ranging from directive, where user focus is ignored in
formulating the computer&apos;s dialogue goals, to passive, where the computer will only
process and confirm understanding of the user&apos;s utterance and provide information
only in response to direct questions. In the intermediate levels, the system will try
to find a common relationship between the user&apos;s focus and its own goal. Although
there is some flexibility allowed (the system will try to take more control when it sus-
pects that the user does not know what to do next), generally the initiative level must
be preset for each dialogue. The system was tested in both declarative and directive
modes (after an initial training session in directive mode), with results showing both
shorter dialogues in the declarative mode, as well as more users stating that the system
had too much control when in directive mode. The authors provide a detailed analysis
of the numbers of utterances and completion times for subjects using the directive or
declarative styles.
Smith and Hipp also include a chapter on verifying potentially mistaken inputs as
an adjunct to the error-tolerant processing. Although this was added after the exper-
iments were carried out, there is some analysis of the collected dialogues to see how
the system would have performed with such strategies. One of the major problems is
deciding when and when not to verify; too much verification results in an unwieldy
system, while too little can result in a higher rate of misinterpretations. Smith and Hipp
propose several measures for confidence in an interpretation, relating to the cost of the
parse (amount of errors), the distance of the result from expectations, and the relative
ambiguity (closeness of the best parse to other possible parses). Several estimate func-
tions are proposed on the basis of combinations of these measures and are compared
as to how they would have performed in the corpus from the experiments. When
the confidence drops below a threshold, then a verification is performed. Assuming
that the verification subdialogues would eventually produce the correct answer, they
calculate that engaging in the verification procedures would raise the percentage of
correct interpretations from 83% to 97%.
In general, Smith and Hipp&apos;s system emphasizes the task-related intentional struc-
ture too much at the expense of the linguistic or social structure. Both are important
for fluent dialogues. While it is certainly interesting to see how far an approach based
solely on task structure can get, there are some issues that would need expanding in
</bodyText>
<page confidence="0.995736">
432
</page>
<subsectionHeader confidence="0.926847">
Book Reviews
</subsectionHeader>
<bodyText confidence="0.999930742857143">
a more general system. For example, the way that pronoun resolution is performed
is by matching the input to the lowest-cost expectation. The pronoun is then identi-
fied as the corresponding object in the expectation. While this will work well for many
cases, it may have problems if an unexpected utterance is made about a focused object.
In this case, traditional pronoun resolution techniques (e.g., centering [Grosz, Joshi,
and Weinstein 1995] or focus-matching [Grosz 1977]) would find the referent, while
presumably Smith and Hipp&apos;s approach would not be able to match the unexpected
input at all. Also, while the dialogue model allows for clarification subdialogues, it
does not encode many general non-task-related patterns of linguistic interaction such
as the linguistic expectations used by McRoy and Hirst (1995).
While the dialogue system is fairly successful at interacting with a user to fix the
circuits, there are still some aspects of the interaction that diverge from natural dia-
logue. First, a rigid turn-taking system was imposed, which allowed the user to only
say a single sentence before waiting for a system response. While this kind of limi-
tation is fairly standard for written dialogue systems involved in query-answering, it
detracts from the flexibility of spoken dialogue by not allowing followup elaborations,
clarifications, or shifts in initiative. Secondly, the &apos;directive&apos; initiative level is too inflex-
ible. When the system is in control, it tends to just repeat the previous query if it gets a
reply that it cannot understand as directly satisfying it, while ignoring the reply itself.
A real dialogue participant should respond to what was said, if even just to rephrase
the request or chastise the other for going off topic. This kind of repetition in the face of
noncompliance is also likely to be misinterpreted by the user (Suchman 1987). Finally,
the experimental set-up allowed the experimenter to intervene in specified ways to
counteract specific system limitations, such as words not in the vocabulary, occasional
slow system response time, or deviating from the strict single-sentence turn-taking
conventions.
Although some of the specific devices employed in this system will not be used in
future dialogue systems, due to, for example, rapid developments in speech process-
ing technology, this book and the system described will continue to be interesting for
the practical approach to dialogue, and the careful analysis of the interactions of spe-
cific dialogue phenomena. In particular, the method of general, parameterized system
design, with parameters set by analyzing performance on a particular corpus, should
allow general dialogue architectures to be customized to particular domains. This sys-
tem also serves, for the present, as a demonstration that building such a system is
possible even with off-the-shelf technology and limited resources.
</bodyText>
<sectionHeader confidence="0.973684" genericHeader="abstract">
References
</sectionHeader>
<reference confidence="0.9955986875">
Grosz, Barbara J. 1977. The representation
and use of focus in a system for
understanding dialogues. In Proceedings of
the 5th International Joint Conference on
Artificial Intelligence, Cambridge, MA,
pages 67-76.
Grosz, Barbara J., Aravind K. Joshi, and Scott
Weinstein. 1995. Centering: A framework
for modelling the local coherence of
discourse. Computational Linguistics,
21(2):203-226.
Grosz, Barbara J. and Candace L. Sidner.
1986. Attention, intention, and the
structure of discourse. Computational
Linguistics, 12(3):175-204.
McRoy, Susan W. and Graeme Hirst. 1995.
The repair of speech act
misunderstandings by abductive
inference. Computational Linguistics,
21(4):435-478.
Smith, Ronnie W., D. Richard Hipp, and
Alan W. Biermann. 1995. An architecture
for voice dialogue systems based on
Prolog-style theorem proving.
Computational Linguistics, 21(3):281-320.
Suchman, Lucy A. 1987. Plans and Situated
Actions. Cambridge University Press.
Whittaker, Steve and Phil Stenton. 1988.
Cues and control in expert—client
dialogues. In Proceedings of the 26th Annual
Meeting of the Association for Computational
Linguistics, Buffalo, pages 123-130.
</reference>
<page confidence="0.995621">
433
</page>
<reference confidence="0.750186666666667">
Computational Linguistics Volume 22, Number 3
David R. Traum is a post-doctoral researcher in the educational technologies group (TECFA) of
the Psychology and Education Department at the University of Geneva. He received his Ph.D.
in Computer Science from the University of Rochester, while working on dialogue management
issues in the TRAINS natural language system. Traum&apos;s address is: TECFA, FPSE, Universite
de Geneve, 9 route de Drize, Bat D, CH-1227 Carouge, Switzerland;
</reference>
<email confidence="0.764237">
e-mail: David.Traum@tecfa.unige.ch
</email>
<page confidence="0.998599">
434
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.001158">
<title confidence="0.9762115">Book Reviews Spoken Natural Language Dialogue Systems: A Practical Approach</title>
<author confidence="0.999968">Ronnie W Smith</author>
<author confidence="0.999968">D Richard Hipp</author>
<affiliation confidence="0.984367">(East Carolina University and Hipp, Wyrick and Company, Inc.) New York: Oxford University Press,</affiliation>
<address confidence="0.99559">1994, xiv+299 pp; hardbound, ISBN</address>
<phone confidence="0.474827">0-19-509187-6, $49.95</phone>
<title confidence="0.517345">Reviewed by</title>
<author confidence="0.998684">David R Traum</author>
<affiliation confidence="0.606812">Universite de Geneve</affiliation>
<abstract confidence="0.995467827777778">This book gives a detailed yet readable account of the design, implementation, testing, and analysis of a spoken task-oriented dialogue system. Although there is a thorough reporting of related work, the plural in the main title is a bit misleading, as the book focuses on only one system, built by the authors at Duke University. The subtitle is well warranted, as Smith and Hipp put a premium on achieving useful interaction rather than adherence to any particular psychological or linguistic theory of language processing. The writing is generally clear, even when discussing details of the sometimes complex algorithms. The index is also very helpful. In addition, for those who want more specifics, an appendix gives instructions for electronically obtaining the dialogue system code and transcripts of user interactions with the system. The code is also commented with pointers to aspects of the book, including sections, figures, and pages. Smith and Hipp carefully point out not only the successes of their system, but also its shortcomings and some prospects for improvement. Smith and Hipp do a good job of describing and analyzing related work and comparing it to their own system. Chapter 2, in particular, reviews foundational work on dialogue processing. The main focus is on work in the subareas of speech act processing, user modeling, use of expectations, and mixed initiative. Also included are several other proposals for integrated dialogue models. The highlight of the chapter is a comparison of 26 other dialogue systems, mostly from the 1980&apos;s, listing the application domain and output modality, as well as the types of processing performed and how the systems were evaluated. Other related work is introduced as appropriate in subsequent chapters. The authors are perhaps not quite as successful in recasting the innovations from their own implementation in a more general conceptual framework that could be useful for designers of systems with very different architectures. A task-oriented spoken language dialogue system is a large piece of software, requiring successful integration of a number of heterogeneous subcomponents to perform at least the following functions: speech recognition, language understanding, dialogue reasoning, task reasoning, language generation, and speech generation. The thrust of the authors&apos; work is on the language-understanding and dialogue-reasoning components, as well as the overall architecture that ties these subsystems together. These aspects are also presented more briefly by Smith, Hipp, and Biermann (1995), who also include a more detailed discussion of the relationship to Grosz and Sidner&apos;s (1986) theory of discourse structure. Book Reviews The authors&apos; system used independent components for speech recognition (speakerdependent connected speech) and output, while the main dialogue processing took place on a Sun 4 workstation, running Prolog and C. The system understood a vocabulary of 125 words, and used 560 grammar rules. Users of the system were instructed to perform single-sentence utterances of 3-6 words in length, waiting for system response before uttering a new sentence. Normal response time for the whole system was 6-8 seconds for utterances of this length. All the words were correctly recognized in only 50% of 2,840 utterances, although the error-correcting parser managed to achieve the correct meaning in 81% of the utterances. As this book demonstrates, a task-oriented dialogue system must be more than just an interface or front-end. For coherent dialogue, it is crucial that there be close cooperation between the task and language-reasoning modules. In order to interpret utterances in context, respond appropriately, and track user focus, the dialogue system must have some idea of what the task reasoner is doing, at least at an abstract level. authors adopt a strong hypothesis here that dialogue structure structure, following the intentional discourse structure of Grosz and Sidner (1986). Each task step is related to a (potential) subdialogue, and expectations and meaning interpretation are always computed relative to the focused or likely subdialogues. The domain processor uses Prolog-style theorem-proving on a set of plan libraries in the form of circuit-diagnosis proofs. The authors connect task reasoning to language what they call the Axiom Theory. of the axioms in the diagnosis proofs refer to knowledge of states of the world or the performance of actions. When axioms are the system knows that they would help in the proof, but can&apos;t prove them), actions or observations must be performed. In particular, since this system has no way to directly sense or act upon the elements of the circuit, it must use language to instruct the user to perform the desired actions. Thus, language is viewed as a way of providing missing axioms for the circuit diagnosis. Being embedded within an interactive dialogue system provides constraints on the domain task reasoning itself. In particular, the system must be able to reason about action and plans from both directions: from world-state to best-solution path—in order to output requests for action and observation to the user, and from arbitrary action or observation and world-state to likely plan step—for interpreting user utterances in context. As well, the system reasoning must be prompt (for quick response, maintaining fluid interactivity) and interruptible—full proofs must be interspersed with actions and observations. For this purpose, the authors have implemented a modified Prolog system that allows a user (or, in this case, the dialogue system) access to an ongoing proof, with the ability to notice and provide missing axioms, or modify the proving process. The system starts the process of understanding user inputs by reasoning about context before actually interpreting the language input; the system calculates a set of what the user will say in the current circumstance. There are a number of possible user responses at any given point, and the authors classify the expectations into those coming from the task processor (e.g., descriptions of a component) or the dialogue controller (descriptions of subgoals or reference to ancestor subdialogues), and in each of these categories, whether they are specifically about the situation or task itself, or merely related. These expectations are ordered and weighted as to likelihood and used to help disambiguate parses, as well as provide necessary contextual information for providing full interpretations of pronouns, elided material, and short answers such as &amp;quot;yes.&amp;quot; Some of the expectations will have variables included (e.g., for a numerical value when expecting the report of a measurement). These underspecified expectations are unified with similar forms that result from parsing the user&apos;s input. When completely 431 Computational Linguistics Volume 22, Number 3 unexpected inputs occur that the system cannot relate to the current task structure, it tries to teach the user how to perform the current goal (making the assumption that the user utterance was a misunderstood attempt to discuss this goal). The main input to the parser is a lattice of the word possibilities produced by the speech recognizer. Also provided is the set of expectations calculated by the dimodule. The parser computes the most likely parses using an dynamic algorithm (where the size of the input string, and m is the size of the grammar), assigning a cost function based on string distance between the actual input and the right-hand side of a grammar rule. The least expensive parses are compared to the expectations produced by the dialogue system, for final selection of the interpretation. For the dialogues collected in their experiments, the authors determined that the dialogue expectations help only to disambiguate parses with equal cost. Thus, in fact, the way expectations are used turns out to be equivalent to the &amp;quot;traditional&amp;quot; pipe-lined processing model, in which context is consulted after producing an initial parse. What is interesting, though, is the authors&apos; practical approach, which determined this fact empirically by examining the performance on the actual input. important aspect of dialogue is the degree of by the system (Whittaker and Stenton 1988). This amounts to a determination of which participant will guide the direction of the dialogue and to what degree. Smith and Hipp four levels of initiative, ranging from user focus is ignored in the computer&apos;s dialogue goals, to the computer will only process and confirm understanding of the user&apos;s utterance and provide information only in response to direct questions. In the intermediate levels, the system will try to find a common relationship between the user&apos;s focus and its own goal. Although there is some flexibility allowed (the system will try to take more control when it suspects that the user does not know what to do next), generally the initiative level must be preset for each dialogue. The system was tested in both declarative and directive (after an initial training session directive mode), with results showing both shorter dialogues in the declarative mode, as well as more users stating that the system had too much control when in directive mode. The authors provide a detailed analysis of the numbers of utterances and completion times for subjects using the directive or declarative styles. Smith and Hipp also include a chapter on verifying potentially mistaken inputs as an adjunct to the error-tolerant processing. Although this was added after the experiments were carried out, there is some analysis of the collected dialogues to see how the system would have performed with such strategies. One of the major problems is deciding when and when not to verify; too much verification results in an unwieldy system, while too little can result in a higher rate of misinterpretations. Smith and Hipp propose several measures for confidence in an interpretation, relating to the cost of the parse (amount of errors), the distance of the result from expectations, and the relative ambiguity (closeness of the best parse to other possible parses). Several estimate functions are proposed on the basis of combinations of these measures and are compared as to how they would have performed in the corpus from the experiments. When the confidence drops below a threshold, then a verification is performed. Assuming that the verification subdialogues would eventually produce the correct answer, they calculate that engaging in the verification procedures would raise the percentage of interpretations from to 97%. Smith and Hipp&apos;s system emphasizes the task-related structoo much at the expense of the Both are important for fluent dialogues. While it is certainly interesting to see how far an approach based solely on task structure can get, there are some issues that would need expanding in 432 Book Reviews a more general system. For example, the way that pronoun resolution is performed is by matching the input to the lowest-cost expectation. The pronoun is then identified as the corresponding object in the expectation. While this will work well for many cases, it may have problems if an unexpected utterance is made about a focused object. In this case, traditional pronoun resolution techniques (e.g., centering [Grosz, Joshi, and Weinstein 1995] or focus-matching [Grosz 1977]) would find the referent, while presumably Smith and Hipp&apos;s approach would not be able to match the unexpected input at all. Also, while the dialogue model allows for clarification subdialogues, it does not encode many general non-task-related patterns of linguistic interaction such as the linguistic expectations used by McRoy and Hirst (1995). While the dialogue system is fairly successful at interacting with a user to fix the circuits, there are still some aspects of the interaction that diverge from natural dialogue. First, a rigid turn-taking system was imposed, which allowed the user to only say a single sentence before waiting for a system response. While this kind of limitation is fairly standard for written dialogue systems involved in query-answering, it detracts from the flexibility of spoken dialogue by not allowing followup elaborations, or shifts in initiative. Secondly, the &apos;directive&apos; initiative level is inflexible. When the system is in control, it tends to just repeat the previous query if it gets a reply that it cannot understand as directly satisfying it, while ignoring the reply itself. A real dialogue participant should respond to what was said, if even just to rephrase the request or chastise the other for going off topic. This kind of repetition in the face of noncompliance is also likely to be misinterpreted by the user (Suchman 1987). Finally, the experimental set-up allowed the experimenter to intervene in specified ways to counteract specific system limitations, such as words not in the vocabulary, occasional slow system response time, or deviating from the strict single-sentence turn-taking conventions. Although some of the specific devices employed in this system will not be used in future dialogue systems, due to, for example, rapid developments in speech processing technology, this book and the system described will continue to be interesting for the practical approach to dialogue, and the careful analysis of the interactions of specific dialogue phenomena. In particular, the method of general, parameterized system design, with parameters set by analyzing performance on a particular corpus, should general dialogue architectures to be customized to particular domains. This sysalso serves, the present, as a demonstration that building such a system is possible even with off-the-shelf technology and limited resources. References Grosz, Barbara J. 1977. The representation and use of focus in a system for dialogues. In of</abstract>
<note confidence="0.653825566666667">the 5th International Joint Conference on Intelligence, MA, pages 67-76. Grosz, Barbara J., Aravind K. Joshi, and Scott Weinstein. 1995. Centering: A framework for modelling the local coherence of Linguistics, 21(2):203-226. Grosz, Barbara J. and Candace L. Sidner. 1986. Attention, intention, and the of discourse. McRoy, Susan W. and Graeme Hirst. 1995. The repair of speech act misunderstandings by abductive Linguistics, 21(4):435-478. Smith, Ronnie W., D. Richard Hipp, and Alan W. Biermann. 1995. An architecture for voice dialogue systems based on Prolog-style theorem proving. Linguistics, Lucy A. 1987. and Situated University Press. Whittaker, Steve and Phil Stenton. 1988. Cues and control in expert—client In of the 26th Annual Meeting of the Association for Computational pages 123-130. 433 Computational Linguistics Volume 22, Number 3</note>
<abstract confidence="0.8705705">R. Traum a post-doctoral researcher in the educational technologies group (TECFA) of the Psychology and Education Department at the University of Geneva. He received his Ph.D. in Computer Science from the University of Rochester, while working on dialogue management issues in the TRAINS natural language system. Traum&apos;s address is: TECFA, FPSE, Universite</abstract>
<address confidence="0.874418">de Geneve, 9 route de Drize, Bat D, CH-1227 Carouge, Switzerland;</address>
<email confidence="0.967319">e-mail:David.Traum@tecfa.unige.ch</email>
<address confidence="0.505215">434</address>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Barbara J Grosz</author>
</authors>
<title>The representation and use of focus in a system for understanding dialogues.</title>
<date>1977</date>
<booktitle>In Proceedings of the 5th International Joint Conference on Artificial Intelligence,</booktitle>
<pages>67--76</pages>
<location>Cambridge, MA,</location>
<contexts>
<context position="11976" citStr="Grosz 1977" startWordPosition="1872" endWordPosition="1873">o see how far an approach based solely on task structure can get, there are some issues that would need expanding in 432 Book Reviews a more general system. For example, the way that pronoun resolution is performed is by matching the input to the lowest-cost expectation. The pronoun is then identified as the corresponding object in the expectation. While this will work well for many cases, it may have problems if an unexpected utterance is made about a focused object. In this case, traditional pronoun resolution techniques (e.g., centering [Grosz, Joshi, and Weinstein 1995] or focus-matching [Grosz 1977]) would find the referent, while presumably Smith and Hipp&apos;s approach would not be able to match the unexpected input at all. Also, while the dialogue model allows for clarification subdialogues, it does not encode many general non-task-related patterns of linguistic interaction such as the linguistic expectations used by McRoy and Hirst (1995). While the dialogue system is fairly successful at interacting with a user to fix the circuits, there are still some aspects of the interaction that diverge from natural dialogue. First, a rigid turn-taking system was imposed, which allowed the user to</context>
</contexts>
<marker>Grosz, 1977</marker>
<rawString>Grosz, Barbara J. 1977. The representation and use of focus in a system for understanding dialogues. In Proceedings of the 5th International Joint Conference on Artificial Intelligence, Cambridge, MA, pages 67-76.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara J Grosz</author>
<author>Aravind K Joshi</author>
<author>Scott Weinstein</author>
</authors>
<title>Centering: A framework for modelling the local coherence of discourse.</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<pages>21--2</pages>
<marker>Grosz, Joshi, Weinstein, 1995</marker>
<rawString>Grosz, Barbara J., Aravind K. Joshi, and Scott Weinstein. 1995. Centering: A framework for modelling the local coherence of discourse. Computational Linguistics, 21(2):203-226.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara J Grosz</author>
<author>Candace L Sidner</author>
</authors>
<title>Attention, intention, and the structure of discourse.</title>
<date>1986</date>
<journal>Computational Linguistics,</journal>
<pages>12--3</pages>
<contexts>
<context position="4321" citStr="Grosz and Sidner (1986)" startWordPosition="658" endWordPosition="661">orrect meaning in 81% of the utterances. As this book demonstrates, a task-oriented dialogue system must be more than just an interface or front-end. For coherent dialogue, it is crucial that there be close cooperation between the task and language-reasoning modules. In order to interpret utterances in context, respond appropriately, and track user focus, the dialogue system must have some idea of what the task reasoner is doing, at least at an abstract level. The authors adopt a strong hypothesis here that dialogue structure is task structure, following the intentional discourse structure of Grosz and Sidner (1986). Each task step is related to a (potential) subdialogue, and expectations and meaning interpretation are always computed relative to the focused or likely subdialogues. The domain processor uses Prolog-style theorem-proving on a set of plan libraries in the form of circuit-diagnosis proofs. The authors connect task reasoning to language by what they call the Missing Axiom Theory. Some of the axioms in the diagnosis proofs refer to knowledge of states of the world or the performance of actions. When these axioms are missing (i.e., the system knows that they would help in the proof, but can&apos;t p</context>
</contexts>
<marker>Grosz, Sidner, 1986</marker>
<rawString>Grosz, Barbara J. and Candace L. Sidner. 1986. Attention, intention, and the structure of discourse. Computational Linguistics, 12(3):175-204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Susan W McRoy</author>
<author>Graeme Hirst</author>
</authors>
<title>The repair of speech act misunderstandings by abductive inference.</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<pages>21--4</pages>
<contexts>
<context position="12323" citStr="McRoy and Hirst (1995)" startWordPosition="1922" endWordPosition="1925">he expectation. While this will work well for many cases, it may have problems if an unexpected utterance is made about a focused object. In this case, traditional pronoun resolution techniques (e.g., centering [Grosz, Joshi, and Weinstein 1995] or focus-matching [Grosz 1977]) would find the referent, while presumably Smith and Hipp&apos;s approach would not be able to match the unexpected input at all. Also, while the dialogue model allows for clarification subdialogues, it does not encode many general non-task-related patterns of linguistic interaction such as the linguistic expectations used by McRoy and Hirst (1995). While the dialogue system is fairly successful at interacting with a user to fix the circuits, there are still some aspects of the interaction that diverge from natural dialogue. First, a rigid turn-taking system was imposed, which allowed the user to only say a single sentence before waiting for a system response. While this kind of limitation is fairly standard for written dialogue systems involved in query-answering, it detracts from the flexibility of spoken dialogue by not allowing followup elaborations, clarifications, or shifts in initiative. Secondly, the &apos;directive&apos; initiative level</context>
</contexts>
<marker>McRoy, Hirst, 1995</marker>
<rawString>McRoy, Susan W. and Graeme Hirst. 1995. The repair of speech act misunderstandings by abductive inference. Computational Linguistics, 21(4):435-478.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronnie W Smith</author>
<author>D Richard Hipp</author>
<author>Alan W Biermann</author>
</authors>
<title>An architecture for voice dialogue systems based on Prolog-style theorem proving.</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<pages>21--3</pages>
<marker>Smith, Hipp, Biermann, 1995</marker>
<rawString>Smith, Ronnie W., D. Richard Hipp, and Alan W. Biermann. 1995. An architecture for voice dialogue systems based on Prolog-style theorem proving. Computational Linguistics, 21(3):281-320.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lucy A Suchman</author>
</authors>
<title>Plans and Situated Actions.</title>
<date>1987</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="13378" citStr="Suchman 1987" startWordPosition="2097" endWordPosition="2098"> the flexibility of spoken dialogue by not allowing followup elaborations, clarifications, or shifts in initiative. Secondly, the &apos;directive&apos; initiative level is too inflexible. When the system is in control, it tends to just repeat the previous query if it gets a reply that it cannot understand as directly satisfying it, while ignoring the reply itself. A real dialogue participant should respond to what was said, if even just to rephrase the request or chastise the other for going off topic. This kind of repetition in the face of noncompliance is also likely to be misinterpreted by the user (Suchman 1987). Finally, the experimental set-up allowed the experimenter to intervene in specified ways to counteract specific system limitations, such as words not in the vocabulary, occasional slow system response time, or deviating from the strict single-sentence turn-taking conventions. Although some of the specific devices employed in this system will not be used in future dialogue systems, due to, for example, rapid developments in speech processing technology, this book and the system described will continue to be interesting for the practical approach to dialogue, and the careful analysis of the in</context>
</contexts>
<marker>Suchman, 1987</marker>
<rawString>Suchman, Lucy A. 1987. Plans and Situated Actions. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steve Whittaker</author>
<author>Phil Stenton</author>
</authors>
<title>Cues and control in expert—client dialogues.</title>
<date>1988</date>
<booktitle>In Proceedings of the 26th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>123--130</pages>
<location>Buffalo,</location>
<contexts>
<context position="8730" citStr="Whittaker and Stenton 1988" startWordPosition="1350" endWordPosition="1353">the interpretation. For the dialogues collected in their experiments, the authors determined that the dialogue expectations help only to disambiguate parses with equal cost. Thus, in fact, the way expectations are used turns out to be equivalent to the &amp;quot;traditional&amp;quot; pipe-lined processing model, in which context is consulted after producing an initial parse. What is interesting, though, is the authors&apos; practical approach, which determined this fact empirically by examining the performance on the actual input. Another important aspect of dialogue is the degree of initiative taken by the system (Whittaker and Stenton 1988). This amounts to a determination of which participant will guide the direction of the dialogue and to what degree. Smith and Hipp include four levels of initiative, ranging from directive, where user focus is ignored in formulating the computer&apos;s dialogue goals, to passive, where the computer will only process and confirm understanding of the user&apos;s utterance and provide information only in response to direct questions. In the intermediate levels, the system will try to find a common relationship between the user&apos;s focus and its own goal. Although there is some flexibility allowed (the system</context>
</contexts>
<marker>Whittaker, Stenton, 1988</marker>
<rawString>Whittaker, Steve and Phil Stenton. 1988. Cues and control in expert—client dialogues. In Proceedings of the 26th Annual Meeting of the Association for Computational Linguistics, Buffalo, pages 123-130.</rawString>
</citation>
<citation valid="false">
<authors>
<author>R David</author>
</authors>
<title>Traum is a post-doctoral researcher in the educational technologies group (TECFA) of the Psychology and Education Department at the University of Geneva. He received his Ph.D.</title>
<date>1227</date>
<booktitle>in Computer Science from the University of Rochester, while working on dialogue management issues in the TRAINS natural language system. Traum&apos;s address is: TECFA, FPSE, Universite de Geneve,</booktitle>
<volume>22</volume>
<institution>Computational Linguistics</institution>
<location>Carouge, Switzerland;</location>
<marker>David, 1227</marker>
<rawString>Computational Linguistics Volume 22, Number 3 David R. Traum is a post-doctoral researcher in the educational technologies group (TECFA) of the Psychology and Education Department at the University of Geneva. He received his Ph.D. in Computer Science from the University of Rochester, while working on dialogue management issues in the TRAINS natural language system. Traum&apos;s address is: TECFA, FPSE, Universite de Geneve, 9 route de Drize, Bat D, CH-1227 Carouge, Switzerland;</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>