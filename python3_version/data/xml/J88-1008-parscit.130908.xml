<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.008924">
<figure confidence="0.438127444444444">
Book Reviews Parsing Natural Language
PARSING NATURAL LANGUAGE
King, Margaret (editor)
London: Academic Press, 1983 [second printing,
1986], x+308 pp.
Hardbound, ISBN 0-12-408280-7, $21.00, £12.60
Reviewed by
Klaus Schubert
BSO/Research
</figure>
<bodyText confidence="0.999944">
This book falls into three parts, an introductory, a
syntactic, and a semantic one. In a rapidly developing
branch of applied science like parsing, it is not at all
surprising that the authors have more to say about the
fundamentals than about syntactic applications, and
more about syntax than about semantics. This is so at
least if measured by the number of articles: five intro-
ductory, four syntactic, and three semantic contribu-
tions.
Especially the first part appears to be well edited, so
that the five articles form a readable and worthwhile
whole. Starting from Anne De Roeck&apos;s definitions of
parsing, recognizing, grammar, and various parsing
strategies, the introduction proceeds to presentations of
a procedural parsing system (by Margaret King) and a
declarative parsing system (by Michael Rosner). Special
attention is paid to different versions of transition
networks (by Roderick Johnson) and to charts (by
Giovanni Varile) as a powerful data structure for partial
parsing results, applicable in parsers of various types.
In the syntactic part, Geoffrey Sampson discusses a
deterministic parser for which psychological validity is
claimed. Eugene Charniak&apos;s parser for both grammati-
cal and ill-formed utterances has a similar orientation,
although Charniak admits that psychological validity
has not been attained. His parser is special, as com-
pared to other systems, because it assigns a grammati-
cality figure rather than providing a yes/no judgement
on the correctness of a sentence. In his second contri-
bution, Sampson discusses (and discards) many argu-
ments against context-free grammars, suggesting that
they can be made powerful enough for describing hu-
man languages. Steve Pulman presents an implementa-
tion of Chomsky&apos;s (1981: 55ff) trace theory for long-
distance dependencies and similar notorious problems.
Psychological validity is again at issue when semantic
parsing is taken up. Graeme Ritchie especially focuses
on the problems of local decidability of semantic
choices, taking as proven by psychology that humans
understand much in a word-by-word way. He admits
that a computer system that would perform a semantic
analysis in this fashion has not been devised yet. Yorick
Wilks discusses deep and superficial methods of seman-
tic analysing, arriving at the conclusion that the differ-
ences are not as significant as had been supposed.
Steven Small describes in much detail a semantic word-
</bodyText>
<subsectionHeader confidence="0.792248">
Computational Linguistics, Volume 14, Number 1, Winter 1988
</subsectionHeader>
<bodyText confidence="0.999929609756098">
expert parser used for determining the meaning of
words in a given context.
The articles come from a tutorial held at Lugano in
1981. Reviewing them today, it may be interesting to
ask how the book can be assessed now, in view of these
six years&apos; developments. Much could be said; I choose
three observations.
First, it strikes me to what extent Augmented Tran-
sition Networks seem, at that time, to have been the
most well-known parsing formalism, referred to by
almost every author. The Lugano tutorial was held at a
time when two powerful competitors of ATNs were
being brought to a wider public&apos;s attention, but proba-
bly had not been recognized as such: Definite Clause
Grammar (Pereira and Warren 1980) and Lexical-Func-
tional Grammar (Kaplan and Bresnan 1982). Another
development has a forerunner in this book: Sampson&apos;s
&amp;quot;context-free parsing&amp;quot; is based on work by Gerald
Gazdar and others that later was to become known as
Generalized Phrase Structure Grammar (Gazdar, et al,
1985). (On all these formalisms cf. Schubert 1987:
211ff.)
Second, for all the authors the most natural language
seems to be English. I have found only four or five
sample sentences from other languages. This is a severe
shortcoming in a book where keywords such as &amp;quot;psy-
chological validity&amp;quot; and &amp;quot;syntactic universals&amp;quot; are
used. I feel that computational linguistics has become
slightly more international since then, but wide-scoped
publications are still rare.
Third, there is a certain lack of alternative thinking in
another respect. There are two approaches for analys-
ing grammatical systems, both feasible to parsing: the
constituency and the dependency approaches (Schubert
1987: 17ff). On the syntactic level, this book is entirely
constituency-minded, although an introductory series of
articles would be an appropriate place for at least
mentioning that one has made a deliberate choice by
presenting only one of the two approaches. Dependency
syntax seems to have spread and gained ground in
computational applications since 1981.
</bodyText>
<sectionHeader confidence="0.986378" genericHeader="references">
REFERENCES
</sectionHeader>
<bodyText confidence="0.4598549375">
Chomsky, Noam. 1981 Lectures on government and binding. Dor-
drecht: Foris.
Gazdar, G.; Klein, E.; Pullum, G.; Sag, I. 1985 Generalized phrase
structure grammar. Oxford: Blackwell.
Kaplan, Ronald M. and Bresnan, Joan. 1982 Lexical-Functional
grammar: A formal system for grammatical representation. In
Bresnan, J., Ed., The mental representation of grammatical
relations. Cambridge [USA]: MIT Press.
Pereira, Fernando C. N. and Warren, David H. D. 1980 Definite
clause grammars for language analysis—a survey of the formalism
and a comparison with augmented transition networks. Artificial
Intelligence, 13: 231-278.
Schubert, Klaus. 1987 Metataxis. Contrastive dependency syntax for
machine translation. Dordrecht and Providence: Foris.
Klaus Schubert holds a doctoral degree in General, Scandinavian, and
Slavic Linguistics from the University of Kiel (Federal Republic of
</bodyText>
<page confidence="0.970481">
55
</page>
<note confidence="0.335679">
Book Reviews Machine Translation: Theoretical and Methodological Issues
</note>
<bodyText confidence="0.9966794">
Germany). Since 1985 he has been with the DLT machine translation
project at the BSO software house in Utrecht (The Netherlands),
where he is responsible for the overall linguistic system design.
Schubert&apos;s address is: BSO/Research, Postbus 8348, NL-3503 RH
Utrecht, The Netherlands. E-mail: schubert@dltl.uucp.
</bodyText>
<sectionHeader confidence="0.994808666666667" genericHeader="method">
MACHINE TRANSLATION: THEORETICAL AND
METHODOLOGICAL ISSUES (STUDIES IN NATURAL
LANGUAGE PROCESSING)
</sectionHeader>
<subsectionHeader confidence="0.983225">
Nirenburg, Sergei (editor)
</subsectionHeader>
<bodyText confidence="0.994240922330097">
Cambridge, England: Cambridge University Press,
1987, xv +350 pp
Hardbound, ISBN 0-521-33125-0, $49.50; Paperback,
ISBN 0-521-33696-1, $17.95 [20% discount to ACL
members]
Reviewed by
Harold Somers
UMIST
This title in the ACL-sponsored &amp;quot;Studies in Natural
Language Processing&amp;quot; series is a collection of seven-
teen papers on Machine Translation (MT). Twelve of
the papers are revised versions of presentations at the
1985 Colgate conference, and four of the papers are
completely original. The appearance of this book is
further evidence of the massive renaissance of MT,
along with which comes the serious risk of surfeit of
books and articles covering the same material. It is
important, therefore, that publications in this field have
something new to offer the experienced reader. Hap-
pily, this is the case with Nirenburg&apos;s collection, since
most of the papers either focus on theoretical and
experimental approaches to the problem, or else ad-
dress some of the less commonly considered aspects of
MT. Notable in this respect are Weischedel and Ram-
shaw&apos;s discussion of ill-formed input, McDonald on
generation, and Walker&apos;s description of tools for ex-
tracting information from large databases.
Like the book itself, the remainder of this review is
divided into six parts, as reflected in the section titles.
1. The state of the art
The editor&apos;s introduction is a rather heterogeneous
collection of introductory thoughts. First, some of the
flavor of MT is presented through the discussion of the
types of knowledge involved in an MT system and the
ways in which problems can be addressed, notably by
restricting the input, or by involving the human in the
translation process. The final section of this chapter
gives a useful overview and summary of the remainder
of the book. Tucker&apos;s contribution is a revised version
of his 1984 ARIST article, and concerns strategies for
MT together with brief sections on sublanguage and
evaluation. Various MT systems are reviewed: these
are divided into the &amp;quot;operational&amp;quot; systems SYSTRAN,
SPANAM, TAUM-METEO, and METAL, and exper-
imental projects EUROTRA, Mu, SUSY, DLT, and
TRANSLATOR. Most of these will be familiar names,
except perhaps the last two: TRANSLATOR is Tucker
and Nirenburg&apos;s own system, while DLT is a project
under way in Utrecht, which envisages the use of
Esperanto as an interlingua. Tucker is justly critical of
this project, and one wonders why it merits two pages of
discussion when other more worthy systems are not
mentioned.
2. MT and linguistic theory
Raskin discusses the relationship between linguistics
and NLP. He begins with a catalog of the various
elements of linguistics and gives examples of problems
in each domain which are relevant to NLP. He says that
linguistic treatments are never complete; furthermore,
they are rarely available in a coherent form acceptable
for immediate implementation. Therefore, NLP pro-
jects must have linguists on their staff who know about,
and can gain access to, linguistic materials. But theo-
retical linguistic work is not always useful for NLP, as
we are shown (pp. 52-3) in an interesting point-by-point
analysis of the different needs of theoretical linguistics
and NLP.
Kittredge&apos;s excellent contribution is on the signifi-
cance of sublanguage for MT. &amp;quot;Sublanguage&amp;quot; is defined
informally as a linguistic system used in a particular
domain of discourse, and is characterized by specific
recurring structures and vocabulary. Although a sub-
language is a proper subset of some natural language, it
will not necessarily be a subset of the general variety of
that language. For example, the English of weather
bulletins (as in METEO) has sentence patterns which
are not generally found in standard English (e.g., omit-
ted articles and lack of tensed verbs):
In a sublanguage, the rules for constructing sen-
tences may be quite different from (and even con-
trary to) the rules for sentences in the &apos;standard&apos;
language. (p. 63)
The main attraction of a given sublanguage for the
purposes of MT is the extent to which it can be
described by a significantly smaller grammar than that
required for the full general language, and the extent to
which lexical ambiguities are reduced by the exclusion
of non-domain-relevant alternatives. Some sublan-
guages are not so &amp;quot;well-behaved&amp;quot; in this respect,
permitting &amp;quot;seepage&amp;quot; from general language (p. 63).
Kittredge next considers the choice of sublanguages
as suitable candidates for MT, noting that not all
sublanguages are necessarily good in this respect. This
was the experience of the TAUM-AVIATION project,
where some of the characteristics of the aircraft hydrau-
lics manual sublanguage were particularly unsuitable for
MT (e.g., complex NPs). Finally, he offers some guides
to estimating the suitability of candidate sublanguages
for MT. These include comparing vocabulary size in
texts of different lengths: a vocabulary growth curve
which tends to flatten is a good indicator of a con-
strained vocabulary. Estimating the computational trac-
tability of the grammar is more difficult. Kittredge gives
</bodyText>
<page confidence="0.964174">
56 Computational Linguistics, Volume 14, Number 1, Winter 1988
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.293213">
<title confidence="0.9617005">Book Reviews Parsing Natural Language PARSING NATURAL LANGUAGE</title>
<author confidence="0.919385">Margaret King</author>
<note confidence="0.9833855">London: Academic Press, 1983 [second printing, 1986], x+308 pp. Hardbound, ISBN 0-12-408280-7, $21.00, £12.60 Reviewed by</note>
<author confidence="0.983558">Klaus Schubert</author>
<abstract confidence="0.973119230769231">BSO/Research This book falls into three parts, an introductory, a syntactic, and a semantic one. In a rapidly developing branch of applied science like parsing, it is not at all surprising that the authors have more to say about the fundamentals than about syntactic applications, and more about syntax than about semantics. This is so at least if measured by the number of articles: five introductory, four syntactic, and three semantic contributions. Especially the first part appears to be well edited, so that the five articles form a readable and worthwhile whole. Starting from Anne De Roeck&apos;s definitions of</abstract>
<intro confidence="0.5204">parsing, recognizing, grammar, and various parsing</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
</citationList>
</algorithm>
</algorithms>