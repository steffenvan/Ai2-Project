<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003134">
<title confidence="0.990082">
Phrase Training Based Adaptation for Statistical Machine Translation
</title>
<author confidence="0.991037">
Saab Mansour and Hermann Ney
</author>
<affiliation confidence="0.991414666666667">
Human Language Technology and Pattern Recognition
Computer Science Department
RWTH Aachen University, Aachen, Germany
</affiliation>
<email confidence="0.998011">
{mansour,ney}@cs.rwth-aachen.de
</email>
<sectionHeader confidence="0.998592" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998005">
We present a novel approach for translation
model (TM) adaptation using phrase train-
ing. The proposed adaptation procedure is ini-
tialized with a standard general-domain TM,
which is then used to perform phrase training
on a smaller in-domain set. This way, we bias
the probabilities of the general TM towards
the in-domain distribution. Experimental re-
sults on two different lectures translation tasks
show significant improvements of the adapted
systems over the general ones. Additionally,
we compare our results to mixture modeling,
where we report gains when using the sug-
gested phrase training adaptation method.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999976480769231">
The task of domain-adaptation attempts to exploit
data mainly drawn from one domain (e.g. news,
parliamentary discussion) to maximize the perfor-
mance on the test domain (e.g. lectures, web fo-
rums). In this work, we focus on translation model
(TM) adaptation. A prominent approach in recent
work is weighting at different levels of granularity.
Foster and Kuhn (2007) perform weighting at the
corpus level, where different corpora receive differ-
ent weights and are then combined using mixture
modeling. A finer grained weighting is that of Mat-
soukas et al. (2009), who weight each sentence in the
bitexts using features of meta-information and opti-
mize a mapping from the feature vectors to weights
using a translation quality measure.
In this work, we propose to perform TM adapta-
tion using phrase training. We start from a general-
domain phrase table and adapt the probabilities by
training on an in-domain data. Thus, we achieve
direct phrase probabilities adaptation as opposed to
weighting. Foster et al. (2010) perform weighting
at the phrase level, assigning each phrase pair a
weight according to its relevance to the test domain.
They compare phrase weighting to a “flat” model,
where the weight directly approximates the phrase
probability. In their experiments, the weighting
method performs better than the flat model, there-
fore, they conclude that retaining the original rela-
tive frequency probabilities of the TM is important
for good performance. The “flat” model of Foster
et al. (2010) is similar to our work. We differ in
the following points: (i) we use the same procedure
to perform the phrase training based adaptation and
the search thus avoiding inconsistencies between the
two; (ii) we do not directly interpolate the original
statistics with the new ones, but use a training pro-
cedure to manipulate the original statistics. We per-
form experiments on the publicly available IWSLT
TED task, on both Arabic-to-English and German-
to-English lectures translation tracks. We compare
our suggested phrase training adaptation method to
a variety of baselines and show its effectiveness. Fi-
nally, we experiment with mixture modeling based
adaptation. We compare mixture modeling to our
adaptation method, and apply our method within a
mixture modeling framework.
In Section 2, we present the phrase training
method and explain how it is utilized for adaptation.
Experimental setup including corpora statistics and
the SMT system are described in Section 3. Sec-
tion 4 summarizes the phrase training adaptation re-
sults ending with a comparison to mixture modeling.
</bodyText>
<page confidence="0.988792">
649
</page>
<subsectionHeader confidence="0.167143">
Proceedings of NAACL-HLT 2013, pages 649–654,
</subsectionHeader>
<bodyText confidence="0.35254">
Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics
</bodyText>
<sectionHeader confidence="0.930002" genericHeader="method">
2 Phrase Training
</sectionHeader>
<bodyText confidence="0.99999416">
The standard phrase extraction procedure in SMT
consists of two phases: (i) word-alignment training
(e.g., IBM alignment models), (ii) heuristic phrase
extraction and relative frequency based phrase trans-
lation probability estimation. In this work, we utilize
phrase training for the task of adaptation. We use
the forced alignment (FA) method (Wuebker et al.,
2010) to perform the phrase alignment training and
probability estimation. We perform phrase training
by running a normal SMT decoder on the training
data and constrain the translation to the given target
instance. Using n-best possible phrase segmentation
for each training instance, the phrase probabilities
are re-estimated over the output. Leaving-one-out is
used during the forced alignment procedure phase to
avoid over-fitting (Wuebker et al., 2010).
In the standard phrase training procedure, we
are given a training set y, from which an initial
heuristics-based phrase table p0i is generated. FA
training is then done over the training set y using the
phrases and probabilities in p0i (possibly updated by
the leaving-one-out method). Finally, re-estimation
of the phrase probabilities is done over the decoder
output, generating the FA phrase table p1. We ex-
plain next how to utilize FA training for adaptation.
</bodyText>
<subsectionHeader confidence="0.985219">
2.1 Adaptation
</subsectionHeader>
<bodyText confidence="0.999962909090909">
In this work, we utilize phrase training for the task
of adaptation. The main idea is to generate the initial
phrase table required for FA using a general-domain
training data y&apos;, thus resulting in p0i,, and perform
the FA training over yIN, the in-domain training
data (instead of y&apos; in the standard procedure). This
way, we bias the probabilities of p0i, towards the in-
domain distribution. We denote this new procedure
by Y’-FA-IN. This differs from the standard IN-FA-
IN by that we have more phrase pairs to use for FA.
Thus, we obtain phrase pairs relevant to IN in ad-
dition to “general” phrase pairs which were not ex-
tracted from IN, perhaps due to faulty word align-
ments. The probabilities of the general phrase table
will be tailored towards IN. In practice, we usually
have in-domain IN and other-domain OD data. We
denote by ALL the concatenation of IN and OD. To
adapt the ALL phrase table, we perform the FA pro-
cedure ALL-FA-IN. We also utilize leaving-one-out
to avoid over-fitting.
Another procedure we experimented with is
adapting the OD phrase table using FA over IN,
without leaving-one-out. We denote it by OD-FA0-
IN. In this FA scenario, we do not use leaving-one-
out as IN is not contained in OD, therefore, over-
fitting will not occur. By this procedure, we train
phrases from OD that are relevant for both OD and
IN, while the probabilities will be tailored to IN. In
this case, we do not expect improvements over the
IN based phrase table, but, improvements over OD
and reduction in the phrase table size.
We compare our suggested FA based adaptation
to the standard FA procedure.
</bodyText>
<sectionHeader confidence="0.997782" genericHeader="method">
3 Experimental Setup
</sectionHeader>
<subsectionHeader confidence="0.997591">
3.1 Training Corpora
</subsectionHeader>
<bodyText confidence="0.999953518518518">
To evaluate the introduced methods experimentally,
we use the IWSLT 2011 TED Arabic-to-English and
German-to-English translation tasks. The IWSLT
2011 evaluation campaign focuses on the transla-
tion of TED talks, a collection of lectures on a
variety of topics ranging from science to culture.
For Arabic-to-English, the bilingual data consists
of roughly 100K sentences of in-domain TED talks
data and 8M sentences of “other”-domain United
Nations (UN) data. For the German-to-English task,
the data consists of 130K TED sentences and 2.1M
sentences of “other”-domain data assembled from
the news-commentary and the europarl corpora. For
language model training purposes, we use an addi-
tional 1.4 billion words (supplied as part of the cam-
paign monolingual training data).
The bilingual training and test data for the Arabic-
to-English and German-to-English tasks are sum-
marized in Table 11. The English data was tok-
enized and lowercased while the Arabic data was
tokenized and segmented using MADA v3.1 (Roth
et al., 2008) with the ATB scheme. The German
source is decompounded (Koehn and Knight, 2003)
and part-of-speech-based long-range verb reorder-
ing rules (Popovi´c and Ney, 2006) are applied.
From Table 1, we note that using the general
data considerably reduces the number of out-of-
</bodyText>
<footnote confidence="0.985523666666667">
1For a list of the IWSLT TED 2011 training cor-
pora, see http://www.iwslt2011.org/doku.php?
id=06_evaluation
</footnote>
<page confidence="0.988963">
650
</page>
<table confidence="0.946275461538462">
Set Sen Tok OOV/IN OOV/ALL
German-to-English
IN 130K 2.5M
OD 2.1M 55M
dev 883 20K 398 (2.0%) 215 (1.1%)
test 1565 32K 483 (1.5%) 227 (0.7%)
eval 1436 27K 490 (1.8%) 271 (1.0%)
Arabic-to-English
IN 90K 1.6M
OD 7.9M 228M
dev 934 19K 408 (2.2%) 184 (1.0%)
test 1664 31K 495 (1.6%) 228 (0.8%)
eval 1450 27K 513 (1.9%) 163 (0.6%)
</table>
<tableCaption confidence="0.984854">
Table 1: IWSLT 2011 TED bilingual corpora statistics:
</tableCaption>
<figureCaption confidence="0.6426606">
the number of tokens is given for the source side. OOV/X
denotes the number of OOV words in relation to corpus
X (the percentage is given in parentheses). IN is the TED
in-domain data, OD denotes other-domain data, ALL de-
notes the concatenation of IN and OD.
</figureCaption>
<bodyText confidence="0.999912333333333">
vocabulary (OOV) words. This comes with the price
of increasing the size of the training data by a factor
of more than 20. A simple concatenation of the cor-
pora might mask the phrase probabilities obtained
from the in-domain corpus, causing a deterioration
in performance. One way to avoid this contamina-
tion is by filtering the general corpus, but this dis-
cards phrase translations completely from the phrase
model. A more principled way is by adapting the
phrase probabilities of the full system to the domain
being tackled. We perform this by phrase training
the full phrase table over the in-domain training set.
</bodyText>
<subsectionHeader confidence="0.99954">
3.2 Translation System
</subsectionHeader>
<bodyText confidence="0.999979545454545">
The baseline system is built using the open-source
SMT toolkit Jane 2.0, which provides a state-of-
the-art phrase-based SMT system (Wuebker et al.,
2012a). In addition to the phrase based decoder,
Jane 2.0 implements the forced alignment procedure
used in this work for the purpose of adaptation. We
use the standard set of models with phrase transla-
tion probabilities for source-to-target and target-to-
source directions, smoothing with lexical weights,
a word and phrase penalty, distance-based reorder-
ing and an n-gram target language model. The SMT
systems are tuned on the dev (dev2010) development
set with minimum error rate training (Och, 2003) us-
ing BLEU (Papineni et al., 2002) accuracy measure
as the optimization criterion. We test the perfor-
mance of our system on the test (tst2010) and eval
(tst2011) sets using the BLEU and translation edit
rate (TER) (Snover et al., 2006) measures. We use
TER as an additional measure to verify the consis-
tency of our improvements and avoid over-tuning.
The Arabic-English results are case sensitive while
the German-English results are case insensitive.
</bodyText>
<sectionHeader confidence="0.999973" genericHeader="evaluation">
4 Results
</sectionHeader>
<bodyText confidence="0.999818857142857">
For TM training, we define three different sets: in-
domain (IN) which is the TED corpus, other-domain
(OD) which consists of the UN corpus for Arabic-
English and a concatenation of news-commentary
and europarl for German-English, and ALL which
consists of the concatenation of IN and OD. We ex-
periment with the following extraction methods:
</bodyText>
<listItem confidence="0.993974333333333">
• Heuristics: standard phrase extraction using
word-alignment training and heuristic phrase
extraction over the word alignment. The ex-
traction is performed for the three different
training data, IN, OD and ALL.
• FA standard: standard FA phrase training
where the same training set is used for initial
phrase table generation as well as the FA pro-
cedure. We perform the training on the three
different training sets and denote the resulting
systems by IN-FA, OD-FA and ALL-FA.
• FA adaptation: FA based adaptation phrase
</listItem>
<bodyText confidence="0.8095586">
training, where the initial table is generated
from some general data and the FA training is
performed on the IN data to achieve adapta-
tion. We perform two experiments, OD-FAo-
IN without leaving-one-out and ALL-FA-IN
with leaving-one-out.
The results of the various experiments over both
Arabic-English and German-English tasks are sum-
marized in Table 2. The usefulness of the OD
data differs between the Arabic-to-English and the
German-to-English translation tasks. For Arabic-to-
English, the OD system is 2.5%-4.3% BLEU worse
than the IN system, whereas for the German-to-
English task the differences between IN and OD are
smaller and range from 0.9% to 1.6% BLEU. The
</bodyText>
<page confidence="0.992799">
651
</page>
<figure confidence="0.945069909090909">
Phrase training
method
System Rules
number
dev
BLEU TER
test
BLEU TER
eval
BLEU TER
Arabic-to-English
</figure>
<table confidence="0.998682">
IN 1.1M 27.2 54.1 25.3 57.1 24.3 59.9
Heuristics OD 36.3M 24.7 57.7 21.2 62.6 21.0 64.7
ALL 36.9M 27.1 54.8 24.4 58.6 23.8 61.1
IN-FA 1.0M 27.0 54.4 25.0 57.5 23.8 60.3
FA standard OD-FA 1.8M 24.5 57.7 21.0 62.4 21.2 64.3
ALL-FA 2.0M 27.2 54.2 24.5 58.1 23.8 60.6
OD-FAo-IN 0.3M 25.8 55.8 23.6 59.4 22.7 61.7
FA adaptation ALL-FA-IN 0.5M 27.7 53.7 25.3 56.9 24.7 59.3
German-to-English
IN 1.3M 31.0 48.9 29.3 51.0 32.7 46.8
Heuristics OD 7.3M 29.8 49.2 27.7 51.5 31.8 47.5
ALL 7.8M 31.2 48.3 29.5 50.5 33.6 46.1
IN-FA 0.5M 31.6 48.2 29.7 50.5 33.3 46.4
FA standard OD-FA 3.0M 29.1 51.0 27.6 53.0 30.7 49.6
ALL-FA 3.2M 31.4 48.3 29.4 50.8 33.6 46.2
OD-FAO-IN 0.9M 31.2 48.7 29.1 50.9 32.7 46.9
FA adaptation ALL-FA-IN 0.9M 31.8 47.4 29.7 49.7 33.6 45.5
</table>
<tableCaption confidence="0.96052">
Table 2: TED 2011 translation results. BLEU and TER are given in percentages. IN denotes the TED lectures in-
domain corpus, OD denotes the other-domain corpus, ALL is the concatenation of IN and OD. FAO denotes forced
alignment training without leaving-one-out (otherwise, leaving-one-out is used).
</tableCaption>
<bodyText confidence="0.998537511627907">
inferior performance of the OD system can be re-
lated to noisy data or bigger discrepancy between
the OD data domain distribution and the IN distri-
bution. The ALL system performs according to the
usefulness of the OD training set, where for Arabic-
to-English we observe deterioration in performance
for all test sets and up-to -0.9% BLEU on the test
set. On the other hand, for German-to-English, the
ALL system is improving over IN where the biggest
improvement is observed on the eval set with +0.9%
BLEU improvement.
The standard FA procedure achieves mixed re-
sults, where IN-FA deteriorates the results over the
IN counterpart for Arabic-English, while improving
for German-English. ALL-FA performs comparably
to the ALL system on both tasks, while reducing the
phrase table size considerably. The OD-FA system
deteriorates the results in comparison to the OD sys-
tem in most cases, which is expected as training over
the OD set fits the phrase model on the OD domain,
making it perform worse on IN. (Wuebker et al.,
2012b) also report mixed results with FA training.
The FA adaptation results are summarized in the
last block of the experiments. The OD-FAO-IN im-
proves over the OD system, which means that the
training procedure was able to modify the OD prob-
abilities to perform well on the IN data. On the
German-to-English task, the OD-FAO-IN performs
comparably to the IN system, whereas for Arabic-
to-English OD-FAO-IN was able to close around half
of the gap between OD and IN.
The FA adapted ALL system (ALL-FA-IN) per-
forms best in our experiments, improving on both
BLEU and TER measures. In comparison to the
best heuristics system (IN for Arabic-English and
ALL for German-English), +0.4% BLEU and -0.6%
TER improvements are observed on the eval set for
Arabic-English. For German-English, the biggest
improvements are observed on TER with -0.8% on
test and -0.5% on eval. The results suggest that ALL-
FA-IN is able to learn more useful phrases than the
IN system and adjust the ALL phrase probabilities
towards the in-domain distribution.
</bodyText>
<page confidence="0.993296">
652
</page>
<figure confidence="0.579131375">
System
BLEU TER
Arabic-to-English
Heuristicsbest 27.2 54.1 25.3 57.1
IN,OD 28.2 53.1 25.5 56.8
IN,OD-FAo-IN 28.4 52.9 25.7 56.5
German-to-English
Heuristicsbest 31.2 48.3
</figure>
<bodyText confidence="0.997644375">
better and +0.8% TER worse than ALL-FA-IN. We
hypothesize that for Arabic-to-English interpolation
is important due to the larger size of the OD data,
where it could reduce the masking of the IN training
data by the much larger OD data. Nevertheless,
as mentioned previously, using phrase training
adapted phrase table in a mixture setup consistently
improves over using heuristically extracted tables.
</bodyText>
<figure confidence="0.995390454545454">
dev
BLEU TER
test
29.5 50.5
IN,OD
IN,OD-FAo-IN
31.6 48.2
31.8 47.8
29.9 50.5
30.0 50.0
5 Conclusions
</figure>
<tableCaption confidence="0.96860625">
Table 3: TED 2011 mixture modeling results.
Heuristicsbest is the best heuristics based system, IN for
Arabic-English and ALL for German-English. X,Y de-
notes linear interpolation between X and Y phrase tables.
</tableCaption>
<subsectionHeader confidence="0.99679">
4.1 Mixture Modeling
</subsectionHeader>
<bodyText confidence="0.999981051724138">
In this section, we compare our method to mixture
modeling based adaptation, in addition to applying
mixture modeling on top of our method. We focus
on linear interpolation (Foster and Kuhn, 2007) of
the in-domain (IN) and other-domain phrase tables,
where we vary the latter between the heuristically
extracted phrase table (OD) and the FA adapted one
(OD-FAO-IN). The interpolation weight is uniform
for the interpolated phrase tables (0.5). The results
of mixture modeling are summarized in Table 3. In
this table, we include the best heuristics based sys-
tem (Heuristicsbest) from Table 2 as a reference sys-
tem. The results on the eval set are omitted as they
show similar tendencies to the test set results.
Linear interpolation of IN and OD (IN,OD) is per-
forming well in our experiments, with big improve-
ments over the dev set, +1.0% BLEU for Arabic-to-
English and +0.4% BLEU for German-to-English.
On the test set, we observe smaller improvements.
Interpolating IN with the phrase training adapted
system OD-FAO-IN (IN,OD-FAO-IN) achieves ad-
ditional gains over the IN,OD system, the biggest
are observed on TER for German-to-English, with
-0.4% and -0.5% improvements on the dev and test
sets correspondingly.
Comparing heuristics based interpolation
(IN,OD) to our best phrase training adapted system
(ALL-FA-IN) shows mixed results. For Arabic-to-
English, the systems are comparable, while for the
German-to-English test set, IN,OD is +0.2% BLEU
In this work, we propose a phrase training procedure
for adaptation. The phrase training is implemented
using the FA method. First, we extract a standard
phrase table using the whole available training data.
Using this table, we initialize the FA procedure and
perform training on the in-domain set.
Experiments are done on the Arabic-to-English
and German-to-English TED lectures translation
tasks. We show that the suggested procedure is im-
proving over unadapted baselines. On the Arabic-
to-English task, the FA adapted system is +0.9%
BLEU better than the full unadapted counterpart on
both test sets. Unlike the Arabic-to-English setup,
the German-to-English OD data is helpful and pro-
duces a strong unadapted baseline in concatenation
with IN. In this case, the FA adapted system achieves
BLEU improvements mainly on the development set
with +0.6% BLEU, on the test and eval sets, im-
provements of -0.8% and -0.6% TER are observed
correspondingly. As a side effect of the FA training
process, the size of the adapted phrase table is less
than 10% of the size of the full table.
Finally, we experimented with mixture model-
ing where improvements are observed over the un-
adapted baselines. The results show that using our
phrase training adapted OD table yields better per-
formance than using the heuristically extracted OD
in a mixture framework.
</bodyText>
<sectionHeader confidence="0.998815" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.995872833333333">
This material is based upon work supported by the
DARPA BOLT project under Contract No. HR0011-
12-C-0015. Any opinions, findings and conclusions
or recommendations expressed in this material are
those of the authors and do not necessarily reflect
the views of DARPA.
</bodyText>
<page confidence="0.999122">
653
</page>
<sectionHeader confidence="0.996368" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999925">
George Foster and Roland Kuhn. 2007. Mixture-model
adaptation for SMT. In Proceedings of the Second
Workshop on Statistical Machine Translation, pages
128–135, Prague, Czech Republic, June. Association
for Computational Linguistics.
George Foster, Cyril Goutte, and Roland Kuhn. 2010.
Discriminative instance weighting for domain adapta-
tion in statistical machine translation. In Proceedings
of the 2010 Conference on Empirical Methods in Natu-
ral Language Processing, pages 451–459, Cambridge,
MA, October. Association for Computational Linguis-
tics.
Philipp Koehn and Kevin Knight. 2003. Empirical Meth-
ods for Compound Splitting. In Proc. 10th Conf. of the
Europ. Chapter of the Assoc. for Computational Lin-
guistics (EACL), pages 347–354, Budapest, Hungary,
April.
Spyros Matsoukas, Antti-Veikko I. Rosti, and Bing
Zhang. 2009. Discriminative corpus weight estima-
tion for machine translation. In Proceedings of the
2009 Conference on Empirical Methods in Natural
Language Processing, pages 708–717, Singapore, Au-
gust. Association for Computational Linguistics.
Franz J. Och. 2003. Minimum Error Rate Training in
Statistical Machine Translation. In Proceedings of the
41th Annual Meeting of the Association for Compu-
tational Linguistics, pages 160–167, Sapporo, Japan,
July.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a Method for Automatic Eval-
uation of Machine Translation. In Proceedings of the
41st Annual Meeting of the Association for Computa-
tional Linguistics, pages 311–318, Philadelphia, Penn-
sylvania, USA, July.
M. Popovi´c and H. Ney. 2006. POS-based Word Re-
orderings for Statistical Machine Translation. In In-
ternational Conference on Language Resources and
Evaluation, pages 1278–1283.
Ryan Roth, Owen Rambow, Nizar Habash, Mona Diab,
and Cynthia Rudin. 2008. Arabic morphological tag-
ging, diacritization, and lemmatization using lexeme
models and feature ranking. In Proceedings of ACL-
08: HLT, Short Papers, pages 117–120, Columbus,
Ohio, June. Association for Computational Linguis-
tics.
Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-
nea Micciulla, and John Makhoul. 2006. A Study
of Translation Edit Rate with Targeted Human Anno-
tation. In Proceedings of the 7th Conference of the
Association for Machine Translation in the Americas,
pages 223–231, Cambridge, Massachusetts, USA, Au-
gust.
Joern Wuebker, Arne Mauser, and Hermann Ney. 2010.
Training phrase translation models with leaving-one-
out. In Proceedings of the 48th Annual Meeting of the
Assoc. for Computational Linguistics, pages 475–484,
Uppsala, Sweden, July.
Joern Wuebker, Matthias Huck, Stephan Peitz, Malte
Nuhn, Markus Freitag, Jan-Thorsten Peter, Saab Man-
sour, and Hermann Ney. 2012a. Jane 2: Open
source phrase-based and hierarchical statistical ma-
chine translation. In International Conference on
Computational Linguistics, Mumbai, India, Decem-
ber.
Joern Wuebker, Mei-Yuh Hwang, and Chris Quirk.
2012b. Leave-one-out phrase model training for large-
scale deployment. In NAACL 2012 Seventh Work-
shop on Statistical Machine Translation, pages 460–
467, Montreal, Canada, June. Association for Compu-
tational Linguistics.
</reference>
<page confidence="0.999026">
654
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.275047">
<title confidence="0.769309">Phrase Training Based Adaptation for Statistical Machine Translation Mansour</title>
<author confidence="0.496625">Human Language Technology</author>
<author confidence="0.496625">Pattern</author>
<affiliation confidence="0.961747">Computer Science RWTH Aachen University, Aachen,</affiliation>
<abstract confidence="0.996413933333333">We present a novel approach for translation model (TM) adaptation using phrase training. The proposed adaptation procedure is initialized with a standard general-domain TM, which is then used to perform phrase training on a smaller in-domain set. This way, we bias the probabilities of the general TM towards the in-domain distribution. Experimental results on two different lectures translation tasks show significant improvements of the adapted systems over the general ones. Additionally, we compare our results to mixture modeling, where we report gains when using the suggested phrase training adaptation method.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>George Foster</author>
<author>Roland Kuhn</author>
</authors>
<title>Mixture-model adaptation for SMT.</title>
<date>2007</date>
<booktitle>In Proceedings of the Second Workshop on Statistical Machine Translation,</booktitle>
<pages>128--135</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="1256" citStr="Foster and Kuhn (2007)" startWordPosition="179" endWordPosition="182">ctures translation tasks show significant improvements of the adapted systems over the general ones. Additionally, we compare our results to mixture modeling, where we report gains when using the suggested phrase training adaptation method. 1 Introduction The task of domain-adaptation attempts to exploit data mainly drawn from one domain (e.g. news, parliamentary discussion) to maximize the performance on the test domain (e.g. lectures, web forums). In this work, we focus on translation model (TM) adaptation. A prominent approach in recent work is weighting at different levels of granularity. Foster and Kuhn (2007) perform weighting at the corpus level, where different corpora receive different weights and are then combined using mixture modeling. A finer grained weighting is that of Matsoukas et al. (2009), who weight each sentence in the bitexts using features of meta-information and optimize a mapping from the feature vectors to weights using a translation quality measure. In this work, we propose to perform TM adaptation using phrase training. We start from a generaldomain phrase table and adapt the probabilities by training on an in-domain data. Thus, we achieve direct phrase probabilities adaptati</context>
<context position="16193" citStr="Foster and Kuhn, 2007" startWordPosition="2601" endWordPosition="2604">ase table in a mixture setup consistently improves over using heuristically extracted tables. dev BLEU TER test 29.5 50.5 IN,OD IN,OD-FAo-IN 31.6 48.2 31.8 47.8 29.9 50.5 30.0 50.0 5 Conclusions Table 3: TED 2011 mixture modeling results. Heuristicsbest is the best heuristics based system, IN for Arabic-English and ALL for German-English. X,Y denotes linear interpolation between X and Y phrase tables. 4.1 Mixture Modeling In this section, we compare our method to mixture modeling based adaptation, in addition to applying mixture modeling on top of our method. We focus on linear interpolation (Foster and Kuhn, 2007) of the in-domain (IN) and other-domain phrase tables, where we vary the latter between the heuristically extracted phrase table (OD) and the FA adapted one (OD-FAO-IN). The interpolation weight is uniform for the interpolated phrase tables (0.5). The results of mixture modeling are summarized in Table 3. In this table, we include the best heuristics based system (Heuristicsbest) from Table 2 as a reference system. The results on the eval set are omitted as they show similar tendencies to the test set results. Linear interpolation of IN and OD (IN,OD) is performing well in our experiments, wit</context>
</contexts>
<marker>Foster, Kuhn, 2007</marker>
<rawString>George Foster and Roland Kuhn. 2007. Mixture-model adaptation for SMT. In Proceedings of the Second Workshop on Statistical Machine Translation, pages 128–135, Prague, Czech Republic, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Foster</author>
<author>Cyril Goutte</author>
<author>Roland Kuhn</author>
</authors>
<title>Discriminative instance weighting for domain adaptation in statistical machine translation.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>451--459</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Cambridge, MA,</location>
<contexts>
<context position="1904" citStr="Foster et al. (2010)" startWordPosition="284" endWordPosition="287">rpus level, where different corpora receive different weights and are then combined using mixture modeling. A finer grained weighting is that of Matsoukas et al. (2009), who weight each sentence in the bitexts using features of meta-information and optimize a mapping from the feature vectors to weights using a translation quality measure. In this work, we propose to perform TM adaptation using phrase training. We start from a generaldomain phrase table and adapt the probabilities by training on an in-domain data. Thus, we achieve direct phrase probabilities adaptation as opposed to weighting. Foster et al. (2010) perform weighting at the phrase level, assigning each phrase pair a weight according to its relevance to the test domain. They compare phrase weighting to a “flat” model, where the weight directly approximates the phrase probability. In their experiments, the weighting method performs better than the flat model, therefore, they conclude that retaining the original relative frequency probabilities of the TM is important for good performance. The “flat” model of Foster et al. (2010) is similar to our work. We differ in the following points: (i) we use the same procedure to perform the phrase tr</context>
</contexts>
<marker>Foster, Goutte, Kuhn, 2010</marker>
<rawString>George Foster, Cyril Goutte, and Roland Kuhn. 2010. Discriminative instance weighting for domain adaptation in statistical machine translation. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 451–459, Cambridge, MA, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Kevin Knight</author>
</authors>
<title>Empirical Methods for Compound Splitting. In</title>
<date>2003</date>
<booktitle>Proc. 10th Conf. of the Europ. Chapter of the Assoc. for Computational Linguistics (EACL),</booktitle>
<pages>347--354</pages>
<location>Budapest, Hungary,</location>
<contexts>
<context position="7661" citStr="Koehn and Knight, 2003" startWordPosition="1201" endWordPosition="1204">glish task, the data consists of 130K TED sentences and 2.1M sentences of “other”-domain data assembled from the news-commentary and the europarl corpora. For language model training purposes, we use an additional 1.4 billion words (supplied as part of the campaign monolingual training data). The bilingual training and test data for the Arabicto-English and German-to-English tasks are summarized in Table 11. The English data was tokenized and lowercased while the Arabic data was tokenized and segmented using MADA v3.1 (Roth et al., 2008) with the ATB scheme. The German source is decompounded (Koehn and Knight, 2003) and part-of-speech-based long-range verb reordering rules (Popovi´c and Ney, 2006) are applied. From Table 1, we note that using the general data considerably reduces the number of out-of1For a list of the IWSLT TED 2011 training corpora, see http://www.iwslt2011.org/doku.php? id=06_evaluation 650 Set Sen Tok OOV/IN OOV/ALL German-to-English IN 130K 2.5M OD 2.1M 55M dev 883 20K 398 (2.0%) 215 (1.1%) test 1565 32K 483 (1.5%) 227 (0.7%) eval 1436 27K 490 (1.8%) 271 (1.0%) Arabic-to-English IN 90K 1.6M OD 7.9M 228M dev 934 19K 408 (2.2%) 184 (1.0%) test 1664 31K 495 (1.6%) 228 (0.8%) eval 1450 2</context>
</contexts>
<marker>Koehn, Knight, 2003</marker>
<rawString>Philipp Koehn and Kevin Knight. 2003. Empirical Methods for Compound Splitting. In Proc. 10th Conf. of the Europ. Chapter of the Assoc. for Computational Linguistics (EACL), pages 347–354, Budapest, Hungary, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Spyros Matsoukas</author>
<author>Antti-Veikko I Rosti</author>
<author>Bing Zhang</author>
</authors>
<title>Discriminative corpus weight estimation for machine translation.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>708--717</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="1452" citStr="Matsoukas et al. (2009)" startWordPosition="210" endWordPosition="214"> suggested phrase training adaptation method. 1 Introduction The task of domain-adaptation attempts to exploit data mainly drawn from one domain (e.g. news, parliamentary discussion) to maximize the performance on the test domain (e.g. lectures, web forums). In this work, we focus on translation model (TM) adaptation. A prominent approach in recent work is weighting at different levels of granularity. Foster and Kuhn (2007) perform weighting at the corpus level, where different corpora receive different weights and are then combined using mixture modeling. A finer grained weighting is that of Matsoukas et al. (2009), who weight each sentence in the bitexts using features of meta-information and optimize a mapping from the feature vectors to weights using a translation quality measure. In this work, we propose to perform TM adaptation using phrase training. We start from a generaldomain phrase table and adapt the probabilities by training on an in-domain data. Thus, we achieve direct phrase probabilities adaptation as opposed to weighting. Foster et al. (2010) perform weighting at the phrase level, assigning each phrase pair a weight according to its relevance to the test domain. They compare phrase weigh</context>
</contexts>
<marker>Matsoukas, Rosti, Zhang, 2009</marker>
<rawString>Spyros Matsoukas, Antti-Veikko I. Rosti, and Bing Zhang. 2009. Discriminative corpus weight estimation for machine translation. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 708–717, Singapore, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz J Och</author>
</authors>
<title>Minimum Error Rate Training in Statistical Machine Translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>160--167</pages>
<location>Sapporo, Japan,</location>
<contexts>
<context position="9889" citStr="Och, 2003" startWordPosition="1570" endWordPosition="1571">pen-source SMT toolkit Jane 2.0, which provides a state-ofthe-art phrase-based SMT system (Wuebker et al., 2012a). In addition to the phrase based decoder, Jane 2.0 implements the forced alignment procedure used in this work for the purpose of adaptation. We use the standard set of models with phrase translation probabilities for source-to-target and target-tosource directions, smoothing with lexical weights, a word and phrase penalty, distance-based reordering and an n-gram target language model. The SMT systems are tuned on the dev (dev2010) development set with minimum error rate training (Och, 2003) using BLEU (Papineni et al., 2002) accuracy measure as the optimization criterion. We test the performance of our system on the test (tst2010) and eval (tst2011) sets using the BLEU and translation edit rate (TER) (Snover et al., 2006) measures. We use TER as an additional measure to verify the consistency of our improvements and avoid over-tuning. The Arabic-English results are case sensitive while the German-English results are case insensitive. 4 Results For TM training, we define three different sets: indomain (IN) which is the TED corpus, other-domain (OD) which consists of the UN corpus</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz J. Och. 2003. Minimum Error Rate Training in Statistical Machine Translation. In Proceedings of the 41th Annual Meeting of the Association for Computational Linguistics, pages 160–167, Sapporo, Japan, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>Bleu: a Method for Automatic Evaluation of Machine Translation.</title>
<date>2002</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>311--318</pages>
<location>Philadelphia, Pennsylvania, USA,</location>
<contexts>
<context position="9924" citStr="Papineni et al., 2002" startWordPosition="1575" endWordPosition="1578">Jane 2.0, which provides a state-ofthe-art phrase-based SMT system (Wuebker et al., 2012a). In addition to the phrase based decoder, Jane 2.0 implements the forced alignment procedure used in this work for the purpose of adaptation. We use the standard set of models with phrase translation probabilities for source-to-target and target-tosource directions, smoothing with lexical weights, a word and phrase penalty, distance-based reordering and an n-gram target language model. The SMT systems are tuned on the dev (dev2010) development set with minimum error rate training (Och, 2003) using BLEU (Papineni et al., 2002) accuracy measure as the optimization criterion. We test the performance of our system on the test (tst2010) and eval (tst2011) sets using the BLEU and translation edit rate (TER) (Snover et al., 2006) measures. We use TER as an additional measure to verify the consistency of our improvements and avoid over-tuning. The Arabic-English results are case sensitive while the German-English results are case insensitive. 4 Results For TM training, we define three different sets: indomain (IN) which is the TED corpus, other-domain (OD) which consists of the UN corpus for ArabicEnglish and a concatenat</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. Bleu: a Method for Automatic Evaluation of Machine Translation. In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics, pages 311–318, Philadelphia, Pennsylvania, USA, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Popovi´c</author>
<author>H Ney</author>
</authors>
<title>POS-based Word Reorderings for Statistical Machine Translation.</title>
<date>2006</date>
<booktitle>In International Conference on Language Resources and Evaluation,</booktitle>
<pages>1278--1283</pages>
<marker>Popovi´c, Ney, 2006</marker>
<rawString>M. Popovi´c and H. Ney. 2006. POS-based Word Reorderings for Statistical Machine Translation. In International Conference on Language Resources and Evaluation, pages 1278–1283.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan Roth</author>
<author>Owen Rambow</author>
<author>Nizar Habash</author>
<author>Mona Diab</author>
<author>Cynthia Rudin</author>
</authors>
<title>Arabic morphological tagging, diacritization, and lemmatization using lexeme models and feature ranking.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL08: HLT, Short Papers,</booktitle>
<pages>117--120</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Columbus, Ohio,</location>
<contexts>
<context position="7581" citStr="Roth et al., 2008" startWordPosition="1188" endWordPosition="1191"> sentences of “other”-domain United Nations (UN) data. For the German-to-English task, the data consists of 130K TED sentences and 2.1M sentences of “other”-domain data assembled from the news-commentary and the europarl corpora. For language model training purposes, we use an additional 1.4 billion words (supplied as part of the campaign monolingual training data). The bilingual training and test data for the Arabicto-English and German-to-English tasks are summarized in Table 11. The English data was tokenized and lowercased while the Arabic data was tokenized and segmented using MADA v3.1 (Roth et al., 2008) with the ATB scheme. The German source is decompounded (Koehn and Knight, 2003) and part-of-speech-based long-range verb reordering rules (Popovi´c and Ney, 2006) are applied. From Table 1, we note that using the general data considerably reduces the number of out-of1For a list of the IWSLT TED 2011 training corpora, see http://www.iwslt2011.org/doku.php? id=06_evaluation 650 Set Sen Tok OOV/IN OOV/ALL German-to-English IN 130K 2.5M OD 2.1M 55M dev 883 20K 398 (2.0%) 215 (1.1%) test 1565 32K 483 (1.5%) 227 (0.7%) eval 1436 27K 490 (1.8%) 271 (1.0%) Arabic-to-English IN 90K 1.6M OD 7.9M 228M d</context>
</contexts>
<marker>Roth, Rambow, Habash, Diab, Rudin, 2008</marker>
<rawString>Ryan Roth, Owen Rambow, Nizar Habash, Mona Diab, and Cynthia Rudin. 2008. Arabic morphological tagging, diacritization, and lemmatization using lexeme models and feature ranking. In Proceedings of ACL08: HLT, Short Papers, pages 117–120, Columbus, Ohio, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Snover</author>
<author>Bonnie Dorr</author>
<author>Richard Schwartz</author>
<author>Linnea Micciulla</author>
<author>John Makhoul</author>
</authors>
<title>A Study of Translation Edit Rate with Targeted Human Annotation.</title>
<date>2006</date>
<booktitle>In Proceedings of the 7th Conference of the Association for Machine Translation in the Americas,</booktitle>
<pages>223--231</pages>
<location>Cambridge, Massachusetts, USA,</location>
<contexts>
<context position="10125" citStr="Snover et al., 2006" startWordPosition="1609" endWordPosition="1612">or the purpose of adaptation. We use the standard set of models with phrase translation probabilities for source-to-target and target-tosource directions, smoothing with lexical weights, a word and phrase penalty, distance-based reordering and an n-gram target language model. The SMT systems are tuned on the dev (dev2010) development set with minimum error rate training (Och, 2003) using BLEU (Papineni et al., 2002) accuracy measure as the optimization criterion. We test the performance of our system on the test (tst2010) and eval (tst2011) sets using the BLEU and translation edit rate (TER) (Snover et al., 2006) measures. We use TER as an additional measure to verify the consistency of our improvements and avoid over-tuning. The Arabic-English results are case sensitive while the German-English results are case insensitive. 4 Results For TM training, we define three different sets: indomain (IN) which is the TED corpus, other-domain (OD) which consists of the UN corpus for ArabicEnglish and a concatenation of news-commentary and europarl for German-English, and ALL which consists of the concatenation of IN and OD. We experiment with the following extraction methods: • Heuristics: standard phrase extr</context>
</contexts>
<marker>Snover, Dorr, Schwartz, Micciulla, Makhoul, 2006</marker>
<rawString>Matthew Snover, Bonnie Dorr, Richard Schwartz, Linnea Micciulla, and John Makhoul. 2006. A Study of Translation Edit Rate with Targeted Human Annotation. In Proceedings of the 7th Conference of the Association for Machine Translation in the Americas, pages 223–231, Cambridge, Massachusetts, USA, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joern Wuebker</author>
<author>Arne Mauser</author>
<author>Hermann Ney</author>
</authors>
<title>Training phrase translation models with leaving-oneout.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Assoc. for Computational Linguistics,</booktitle>
<pages>475--484</pages>
<location>Uppsala, Sweden,</location>
<contexts>
<context position="3983" citStr="Wuebker et al., 2010" startWordPosition="602" endWordPosition="605">ction 4 summarizes the phrase training adaptation results ending with a comparison to mixture modeling. 649 Proceedings of NAACL-HLT 2013, pages 649–654, Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics 2 Phrase Training The standard phrase extraction procedure in SMT consists of two phases: (i) word-alignment training (e.g., IBM alignment models), (ii) heuristic phrase extraction and relative frequency based phrase translation probability estimation. In this work, we utilize phrase training for the task of adaptation. We use the forced alignment (FA) method (Wuebker et al., 2010) to perform the phrase alignment training and probability estimation. We perform phrase training by running a normal SMT decoder on the training data and constrain the translation to the given target instance. Using n-best possible phrase segmentation for each training instance, the phrase probabilities are re-estimated over the output. Leaving-one-out is used during the forced alignment procedure phase to avoid over-fitting (Wuebker et al., 2010). In the standard phrase training procedure, we are given a training set y, from which an initial heuristics-based phrase table p0i is generated. FA </context>
</contexts>
<marker>Wuebker, Mauser, Ney, 2010</marker>
<rawString>Joern Wuebker, Arne Mauser, and Hermann Ney. 2010. Training phrase translation models with leaving-oneout. In Proceedings of the 48th Annual Meeting of the Assoc. for Computational Linguistics, pages 475–484, Uppsala, Sweden, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joern Wuebker</author>
<author>Matthias Huck</author>
<author>Stephan Peitz</author>
<author>Malte Nuhn</author>
<author>Markus Freitag</author>
<author>Jan-Thorsten Peter</author>
<author>Saab Mansour</author>
<author>Hermann Ney</author>
</authors>
<title>2: Open source phrase-based and hierarchical statistical machine translation.</title>
<date>2012</date>
<booktitle>In International Conference on Computational Linguistics,</booktitle>
<location>Mumbai, India,</location>
<contexts>
<context position="9390" citStr="Wuebker et al., 2012" startWordPosition="1491" endWordPosition="1494"> the phrase probabilities obtained from the in-domain corpus, causing a deterioration in performance. One way to avoid this contamination is by filtering the general corpus, but this discards phrase translations completely from the phrase model. A more principled way is by adapting the phrase probabilities of the full system to the domain being tackled. We perform this by phrase training the full phrase table over the in-domain training set. 3.2 Translation System The baseline system is built using the open-source SMT toolkit Jane 2.0, which provides a state-ofthe-art phrase-based SMT system (Wuebker et al., 2012a). In addition to the phrase based decoder, Jane 2.0 implements the forced alignment procedure used in this work for the purpose of adaptation. We use the standard set of models with phrase translation probabilities for source-to-target and target-tosource directions, smoothing with lexical weights, a word and phrase penalty, distance-based reordering and an n-gram target language model. The SMT systems are tuned on the dev (dev2010) development set with minimum error rate training (Och, 2003) using BLEU (Papineni et al., 2002) accuracy measure as the optimization criterion. We test the perfo</context>
<context position="14059" citStr="Wuebker et al., 2012" startWordPosition="2260" endWordPosition="2263"> system is improving over IN where the biggest improvement is observed on the eval set with +0.9% BLEU improvement. The standard FA procedure achieves mixed results, where IN-FA deteriorates the results over the IN counterpart for Arabic-English, while improving for German-English. ALL-FA performs comparably to the ALL system on both tasks, while reducing the phrase table size considerably. The OD-FA system deteriorates the results in comparison to the OD system in most cases, which is expected as training over the OD set fits the phrase model on the OD domain, making it perform worse on IN. (Wuebker et al., 2012b) also report mixed results with FA training. The FA adaptation results are summarized in the last block of the experiments. The OD-FAO-IN improves over the OD system, which means that the training procedure was able to modify the OD probabilities to perform well on the IN data. On the German-to-English task, the OD-FAO-IN performs comparably to the IN system, whereas for Arabicto-English OD-FAO-IN was able to close around half of the gap between OD and IN. The FA adapted ALL system (ALL-FA-IN) performs best in our experiments, improving on both BLEU and TER measures. In comparison to the bes</context>
</contexts>
<marker>Wuebker, Huck, Peitz, Nuhn, Freitag, Peter, Mansour, Ney, 2012</marker>
<rawString>Joern Wuebker, Matthias Huck, Stephan Peitz, Malte Nuhn, Markus Freitag, Jan-Thorsten Peter, Saab Mansour, and Hermann Ney. 2012a. Jane 2: Open source phrase-based and hierarchical statistical machine translation. In International Conference on Computational Linguistics, Mumbai, India, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joern Wuebker</author>
<author>Mei-Yuh Hwang</author>
<author>Chris Quirk</author>
</authors>
<title>Leave-one-out phrase model training for largescale deployment.</title>
<date>2012</date>
<booktitle>In NAACL 2012 Seventh Workshop on Statistical Machine Translation,</booktitle>
<pages>460--467</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Montreal, Canada,</location>
<contexts>
<context position="9390" citStr="Wuebker et al., 2012" startWordPosition="1491" endWordPosition="1494"> the phrase probabilities obtained from the in-domain corpus, causing a deterioration in performance. One way to avoid this contamination is by filtering the general corpus, but this discards phrase translations completely from the phrase model. A more principled way is by adapting the phrase probabilities of the full system to the domain being tackled. We perform this by phrase training the full phrase table over the in-domain training set. 3.2 Translation System The baseline system is built using the open-source SMT toolkit Jane 2.0, which provides a state-ofthe-art phrase-based SMT system (Wuebker et al., 2012a). In addition to the phrase based decoder, Jane 2.0 implements the forced alignment procedure used in this work for the purpose of adaptation. We use the standard set of models with phrase translation probabilities for source-to-target and target-tosource directions, smoothing with lexical weights, a word and phrase penalty, distance-based reordering and an n-gram target language model. The SMT systems are tuned on the dev (dev2010) development set with minimum error rate training (Och, 2003) using BLEU (Papineni et al., 2002) accuracy measure as the optimization criterion. We test the perfo</context>
<context position="14059" citStr="Wuebker et al., 2012" startWordPosition="2260" endWordPosition="2263"> system is improving over IN where the biggest improvement is observed on the eval set with +0.9% BLEU improvement. The standard FA procedure achieves mixed results, where IN-FA deteriorates the results over the IN counterpart for Arabic-English, while improving for German-English. ALL-FA performs comparably to the ALL system on both tasks, while reducing the phrase table size considerably. The OD-FA system deteriorates the results in comparison to the OD system in most cases, which is expected as training over the OD set fits the phrase model on the OD domain, making it perform worse on IN. (Wuebker et al., 2012b) also report mixed results with FA training. The FA adaptation results are summarized in the last block of the experiments. The OD-FAO-IN improves over the OD system, which means that the training procedure was able to modify the OD probabilities to perform well on the IN data. On the German-to-English task, the OD-FAO-IN performs comparably to the IN system, whereas for Arabicto-English OD-FAO-IN was able to close around half of the gap between OD and IN. The FA adapted ALL system (ALL-FA-IN) performs best in our experiments, improving on both BLEU and TER measures. In comparison to the bes</context>
</contexts>
<marker>Wuebker, Hwang, Quirk, 2012</marker>
<rawString>Joern Wuebker, Mei-Yuh Hwang, and Chris Quirk. 2012b. Leave-one-out phrase model training for largescale deployment. In NAACL 2012 Seventh Workshop on Statistical Machine Translation, pages 460– 467, Montreal, Canada, June. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>