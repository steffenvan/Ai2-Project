<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002212">
<title confidence="0.957126">
The ACL Anthology Searchbench
</title>
<author confidence="0.958868">
Ulrich Sch¨afer Bernd Kiefer Christian Spurk J¨org Steffen Rui Wang
</author>
<affiliation confidence="0.775591">
Language Technology Lab
German Research Center for Artificial Intelligence (DFKI)
</affiliation>
<address confidence="0.749492">
D-66123 Saarbr¨ucken, Germany
</address>
<email confidence="0.9379345">
{ulrich.schaefer,kiefer,cspurk,steffen,wang.rui}@dfki.de
http://www.dfki.de/lt
</email>
<sectionHeader confidence="0.993298" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999731047619047">
We describe a novel application for structured
search in scientific digital libraries. The ACL
Anthology Searchbench is meant to become a
publicly available research tool to query the
content of the ACL Anthology. The applica-
tion provides search in both its bibliographic
metadata and semantically analyzed full tex-
tual content. By combining these two features,
very efficient and focused queries are possi-
ble. At the same time, the application serves
as a showcase for the recent progress in nat-
ural language processing (NLP) research and
language technology. The system currently
indexes the textual content of 7,500 anthol-
ogy papers from 2002–2009 with predicate-
argument-like semantic structures. It also
provides useful search filters based on bib-
liographic metadata. It will be extended to
provide the full anthology content and en-
hanced functionality based on further NLP
techniques.
</bodyText>
<sectionHeader confidence="0.990804" genericHeader="categories and subject descriptors">
1 Introduction and Motivation
</sectionHeader>
<bodyText confidence="0.9998655">
Scientists in all disciplines nowadays are faced with
a flood of new publications every day. In addi-
tion, more and more publications from the past be-
come digitally available and thus even increase the
amount. Finding relevant information and avoiding
duplication of work have become urgent issues to be
addressed by the scientific community.
The organization and preservation of scientific
knowledge in scientific publications, vulgo text doc-
uments, thwarts these efforts. From a viewpoint of
a computer scientist, scientific papers are just ‘un-
structured information’. At least in our own sci-
entific community, Computational Linguistics, it is
generally assumed that NLP could help to support
search in such document collections.
The ACL Anthology1 is a comprehensive elec-
tronic collection of scientific papers in our own field
(Bird et al., 2008). It is updated regularly with
new publications, but also older papers have been
scanned and are made available electronically.
We have implemented the ACL Anthology
Searchbench2 for two reasons: Our first aim is to
provide a more targeted search facility in this col-
lection than standard web search on the anthology
website. In this sense, the Searchbench is meant to
become a service to our own community.
Our second motivation is to use the developed
system as a showcase for the progress that has been
made over the last years in precision-oriented deep
linguistic parsing in terms of both efficiency and
coverage, specifically in the context of the DELPH-
IN community3. Our system also uses further NLP
techniques such as unsupervised term extraction,
named entity recognition and part-of-speech (PoS)
tagging.
By automatically precomputing normalized se-
mantic representations (predicate-argument struc-
ture) of each sentence in the anthology, the search
space is structured and allows to find equivalent or
related predicates even if they are expressed differ-
</bodyText>
<footnote confidence="0.99767925">
1http://www.aclweb.org/anthology
2http://aclasb.dfki.de
3http://www.delph-in.net – DELPH-IN stands for
DEep Linguistic Processing with HPSG INitiative.
</footnote>
<page confidence="0.982169">
7
</page>
<note confidence="0.3166575">
Proceedings of the ACL-HLT 2011 System Demonstrations, pages 7–13,
Portland, Oregon, USA, 21 June 2011. c�2011 Association for Computational Linguistics
</note>
<bodyText confidence="0.999933882352941">
ently, e.g. in passive constructions, using synonyms,
etc. By storing the semantic sentence structure along
with the original text in a structured full-text search
engine, it can be guaranteed that recall cannot fall
behind the baseline of a fulltext search.
In addition, the Searchbench also provides de-
tailed bibliographic metadata for filtering as well as
autosuggest texts for input fields computed from the
corpus – two further key features one can expect
from such systems today, nevertheless very impor-
tant for efficient search in digital libraries.
We describe the offline preprocessing and deep
parsing approach in Section 2. Section 3 concen-
trates on the generation of the semantic search in-
dex. In Section 4, we describe the search interface.
We conclude in Section 5 and present an outlook to
future extensions.
</bodyText>
<sectionHeader confidence="0.888435" genericHeader="method">
2 Parsing the ACL Anthology
</sectionHeader>
<bodyText confidence="0.999951173076923">
The basis of the search index for the ACL Anthol-
ogy are its original PDF documents, currently 8,200
from the years 2002 through 2009. To overcome
quality problems in text extraction from PDF, we
use a commercial PDF extractor based on OCR tech-
niques. This approach guarantees uniform and high-
quality textual representations even from older pa-
pers in the anthology (before 2000) which mostly
were scanned from printed paper versions.
The general idea of the semantics-oriented ac-
cess to scholarly paper content is to parse each sen-
tence they contain with the open-source HPSG (Pol-
lard and Sag, 1994) grammar for English (ERG;
Flickinger (2002)) and then distill and index seman-
tically structured representations for search.
To make the deep parser robust, it is embedded
in a NLP workflow. The coverage (percentage of
full deeply parsed sentences) on the anthology cor-
pus could be increased from 65 % to now more
than 85 % through careful combination of several
robustness techniques; for example: (1) chart prun-
ing, directed search during parsing to increase per-
formance, and also coverage for longer sentences
(Cramer and Zhang, 2010); (2) chart mapping, a
novel method for integrating preprocessing informa-
tion in exactly the way the deep grammar expects
it (Adolphs et al., 2008); (3) new version of the
ERG with better handling of open word classes; (4)
more fine-grained named entity recognition, includ-
ing recognition of citation patterns; (5) new, better
suited parse ranking model (WeScience; Flickinger
et al. (2010)). Because of limited space, we will fo-
cus on (1) and (2) below. A more detailed descrip-
tion and further results are available in (Sch¨afer and
Kiefer, 2011).
Except for a small part of the named entity recog-
nition components (citations, some terminology)
and the parse ranking model, there are no further
adaptations to genre or domain of the text corpus.
This implies that the NLP workflow could be easily
and modularly adapted to other (scientific or non-
scientific) domains—mainly thanks to the generic
and comprehensive language modelling in the ERG.
The NLP preprocessing component workflow is
implemented using the Heart of Gold NLP mid-
dleware architecture (Sch¨afer, 2006). It starts
with sentence boundary detection (SBR) and regu-
lar expression-based tokenization using its built-in
component JTok, followed by the trigram-based PoS
tagger TnT (Brants, 2000) trained on the Penn Tree-
bank (Marcus et al., 1993) and the named entity rec-
ognizer SProUT (Dro˙zd˙zy´nski et al., 2004).
</bodyText>
<subsectionHeader confidence="0.99901">
2.1 Precise Preprocessing Integration with
Chart Mapping
</subsectionHeader>
<bodyText confidence="0.9999065">
Tagger output is combined with information from
the named entity recognizer, e.g. delivering hypo-
thetical information on citation expressions. The
combined result is delivered as input to the deep
parser PET (Callmeier, 2000) running the ERG.
Here, citations, for example, can be treated as either
persons, locations or appositions.
Concerning punctuation, the ERG can make use
of information on opening and closing quotation
marks. Such information is often not explicit in the
input text, e.g. when, as in our setup, gained through
OCR which does not distinguish between ‘ and ’ or “
and ”. However, a tokenizer can often guess (recon-
struct) leftness and rightness correctly. This infor-
mation, passed to the deep parser via chart mapping,
helps it to disambiguate.
</bodyText>
<subsectionHeader confidence="0.932111">
2.2 Increased Processing Speed and Coverage
through Chart Pruning
</subsectionHeader>
<bodyText confidence="0.999616">
In addition to a well-established discriminative max-
imum entropy model for post-analysis parse selec-
</bodyText>
<page confidence="0.987918">
8
</page>
<bodyText confidence="0.999994380952381">
tion, we use an additional generative model as de-
scribed in Cramer and Zhang (2010) to restrict the
search space during parsing. This restriction in-
creases efficiency, but also coverage, because the
parse time was restricted to at most 60 CPU seconds
on a standard PC, and more sentences could now be
parsed within these bounds. A 4 GB limit for main
memory consumption was far beyond what was ever
needed. We saw a small but negligible decrease in
parsing accuracy, 5.4 % best parses were not found
due to the pruning of important chart edges.
Ninomiya et al. (2006) did a very thorough com-
parison of different performance optimization strate-
gies, and among those also a local pruning strategy
similar to the one used here. There is an important
difference between the systems, in that theirs works
on a reduced context-free backbone first and recon-
structs the results with the full grammar, while PET
uses the HPSG grammar directly, with subsumption
packing and partial unpacking to achieve a similar
effect as the packed chart of a context-free parser.
</bodyText>
<figure confidence="0.584057">
sentence length −&gt;
</figure>
<figureCaption confidence="0.9955905">
Figure 1: Distribution of sentence length and mean parse
times for mild pruning
</figureCaption>
<bodyText confidence="0.9998018">
tences has a length of at most 60 words4. The parse
times only grow mildly due to the many optimiza-
tion techniques in the original system, and also the
new chart pruning method. The sentence length dis-
tribution has been integrated into Figure 1 to show
that the predominant part of our real-world corpus
can be processed using this information-rich method
with very low parse times (overall average parse
time &lt; 2 s per sentence).
The large amount of short inputs is at first surpris-
ing, even more so that most of these inputs can not
be parsed. Most of these inputs are non-sentences
such as headings, enumerations, footnotes, table cell
content. There are several alternatives to deal with
such input, one to identify and handle them in a pre-
processing step, another to use a special root con-
dition in the deep analysis component that is able
to combine phrases with well-defined properties for
inputs where no spanning result could be found.
We employed the second method, which has the
advantage that it handles a larger range of phenom-
ena in a homogeneous way. Figure 2 shows the
change in percentage of unparsed and timed out in-
puts for the mild pruning method with and without
the root condition combining fragments.
</bodyText>
<figure confidence="0.970081413793103">
0 20 40 60 80 100
80
70
60
50
40
30
20
10
0
sentences x 1000
mean parse time (CPU s)
0 20 40 60 80 100
100
90
80
70
60
50
40
30
20
10
0
strict
strict timeout
strict+fragments
strict+fragments timeout
sentence length −&gt;
</figure>
<bodyText confidence="0.988952666666667">
In total, we parsed 1,537,801 sentences, of which
57,832 (3.8 %) could not be parsed because of lexi-
con errors. Most of them were caused by OCR ar-
tifacts resulting in unexpected punctuation character
combinations. These can be identified and will be
deleted in the future.
</bodyText>
<figureCaption confidence="0.687023714285714">
Figure 1 displays the average parse time of pro-
cessing with a mild chart pruning setting, together
with the mean quadratic error. In addition, it con-
tains the distribution of input sentences over sen-
tence length. Obviously, the vast majority of sen-
Figure 2: Unparsed and timed out sentences with and
without fragment combination
</figureCaption>
<bodyText confidence="0.9541498">
Figure 2 shows that this changes the curve for un-
parsed sentences towards more expected character-
istics and removes the uncommonly high percent-
age of short sentences for which no parse can be
computed. Together with the parses for fragmented
</bodyText>
<footnote confidence="0.512371333333333">
4It has to be pointed out that extremely long sentences also
may be non-sentences resulting from PDF extraction errors,
missing punctuation etc. No manual correction took place.
</footnote>
<page confidence="0.989382">
9
</page>
<figureCaption confidence="0.998764">
Figure 3: Multiple semantic tuples may be generated for a sentence
</figureCaption>
<bodyText confidence="0.9995164">
input, we get a recall (sentences with at least one
parse) over the whole corpus of 85.9% (1,321,336
sentences), without a significant change for any of
the other measures, and with potential for further im-
provement.
</bodyText>
<sectionHeader confidence="0.989759" genericHeader="method">
3 Semantic Triple Extraction with DMRS
</sectionHeader>
<bodyText confidence="0.999981542372882">
In contrast to shallow parsers, the ERG not only
handles detailed syntactic analyses of phrases, com-
pounds, coordination, negation and other linguistic
phenomena that are important for extracting seman-
tic relations, but also generates a formal semantic
representation of the meaning of the input sentence
in the Minimal Recursion Semantics (MRS) repre-
sentation format (Copestake et al., 2005). It consists
of elementary predications for each word and larger
constituents, connected via argument positions and
variables, from which predicate-argument structure
can be extracted.
MRS representations resulting from deep parsing
are still relatively close to linguistic structures and
contain more detailed information than a user would
like to query and search for. Therefore, an additional
extraction and abstraction step is performed before
storing semantic structures in the search index.
Firstly, MRS is converted to DMRS (Copes-
take, 2009), a dependency-style version of MRS
that eases extraction of predicate-argument struc-
ture using the implementation in LKB (Copestake,
2002). The representation format we devised for the
search index we call semantic tuples, in fact quintu-
ples &lt;subject, predicate, first object, second object,
adjuncts&gt;; example in Figure 3. The basic extrac-
tion algorithm consists of the following three steps:
(1) calculate the closure for each elementary pred-
ication based on the EQ (variable equivalence) re-
lation, and group the predicates and entities in each
closure respectively; (2) extract the relations of the
groups, which results in a graph as a whole; (3) re-
cursively traverse the graph, form one semantic tu-
ple for each predicate, and fill in the corresponding
information under its scope, i.e. subject, object, etc.
In the example shown in Figure 3, entity groups
like ‘our systems’, ‘the baseline’, and ‘good perfor-
mance on the SRL task’, as well as predicate groups
‘beating’ and ‘achieved’ are formed at the first step.
In the second step, the graph structure is extracted,
i.e., the relation between the groups. Finally, two
semantic tuples are filled in with both the predicates
and the corresponding information. Notice that the
modifier(s) of the entity belong to the same entity
group, but the modifier(s) of the predicate will be
put into the Adjuncts slot. Similarly, the coordina-
tion of the entities will be put into one entity group,
while the coordination of predicates will form mul-
tiple semantic tuples.
Since we are extracting predicate-argument struc-
ture, syntactic variations such as passive construc-
tions and relative clauses will be all ‘normalized’
into the same form. Consequently, ‘the book which
I read’, ‘I read the book’, and ‘the book was read
by me’ will form the exact same semantic tuple &lt;I,
read, the book, N/A, N/A&gt;. The resulting tuple
structures along with their associated text are stored
in an Apache Solr/Lucene5 server which receives
queries from the Searchbench user interface.
</bodyText>
<sectionHeader confidence="0.945165" genericHeader="method">
4 Searchbench User Interface
</sectionHeader>
<bodyText confidence="0.997697875">
The Searchbench user interface (UI) is a web appli-
cation running in every modern, JavaScript-enabled
web browser. As can be seen in Figure 4, the UI
is divided into three parts: (1) a sidebar on the left
(Filters View), where different filters can be set that
constrain the list of found documents; (2) a list of
found documents matching the currently set filters
in the upper right part of the UI (Results View); (3)
</bodyText>
<footnote confidence="0.981683">
5http://lucene.apache.org/solr
</footnote>
<page confidence="0.9969">
10
</page>
<figureCaption confidence="0.99967">
Figure 4: Searchbench user interface with different filters set and currently looking at the debug menu for a sentence.
</figureCaption>
<bodyText confidence="0.970733844444444">
the Document View in the lower right part of the UI
with different views of the current document.
A focus in the design of the UI has been to al-
low the user to very quickly browse the papers of the
ACL Anthology and then to find small sets of rele-
vant documents based on metadata and content. This
is mainly achieved by these techniques: (i) changes
in the collection of filters automatically update the
Results View; (ii) metadata and searchable content
from both the Results View and the Document View
can easily be used with a single click as new filters;
(iii) filters can easily be removed with a single click;
(iv) manually entering filter items is assisted by sen-
sible autosuggestions computed from the corpus; (v)
accidental filter changes can easily be corrected by
going back in the browser history.
The following kinds of filters are supported:
Statements (filter by semantic statements, i.e., the
actual content of sentences, see Section 4.1), Key-
words (filter by simple keywords with a full-text
search), Topics (filter by topics of the articles that
were extracted with an extended approach of the un-
supervised term extractor of Frantzi et al. (1998)),
Publication (filter by publication title/event), Au-
thors (filter by author names), Year (filter by pub-
lication year), Affiliations (filter by affiliation or-
ganizations), Affiliation Sites (filter by affiliation
cities and countries)6. Found papers always match
all currently set filters. For each filter type multi-
ple different filter items can be set; one could search
for papers written jointly by people from different
research institutes on a certain topic, for example.
Matches of the statements filter and the keywords
filter are highlighted in document snippets for each
paper in the Results View and in the currently se-
lected paper of the Document View.
Besides a header displaying the metadata of the
currently selected paper (including the automatically
extracted topics on the right), the Document View
provides three subviews of the selected paper: (1)
the Document Content View is a raw list of the sen-
tences of the paper and provides different kinds of
interaction with these sentences; (2) the PDF View
shows the original PDF version of the paper; (3) the
Citations View provides citation information includ-
</bodyText>
<footnote confidence="0.790395">
6Affiliations have been added using the ACL Anthology
Network data (Radev et al., 2009).
</footnote>
<page confidence="0.9992">
11
</page>
<bodyText confidence="0.998800125">
ing link to the ACL Anthology Network (Radev et
al., 2009).
Figure 4 shows the search result for a query com-
bining a statement (‘obtain improvements’), a topic
‘dependency parsing’ and the publication year 2008.
As can be seen in the Results View, six papers
match these filters; sentences with semantically sim-
ilar predicates and passive voice are found, too.
</bodyText>
<subsectionHeader confidence="0.997929">
4.1 Semantic Search
</subsectionHeader>
<bodyText confidence="0.999915875">
The main feature which distinguishes the ACL An-
thology Searchbench from other search applications
for scientific papers is the semantic search in paper
content. This enables the search for (semantic) state-
ments in the paper content as opposed to searching
for keywords in the plain text. Our use of the term
“statement” is loosely along the lines of the same
term used in logic. Very simple sentences often
bear a single statement only, while more complex
sentences (especially when having multiple clauses)
contain multiple statements. Each of the semantic
tuples extracted from the papers of the ACL Anthol-
ogy (cf. Section 3) corresponds to a statement.
The Statements filter is responsible for the seman-
tic search. Statements used in filters may be under-
specified, e.g., one may search for statements with a
certain semantic subject but with arbitrary semantic
predicates and objects. There are two ways in which
a new statement filter can be set: (1) entering a state-
ment manually; (2) clicking a sentence in the Doc-
ument Content View and choosing the statements of
this sentence that shall be set as new statement fil-
ters (cf. Figure 5), i.e. it is possible to formulate and
refine queries ‘by example’.
</bodyText>
<figureCaption confidence="0.964089666666667">
Figure 5: Dialog for choosing statements to be used as
new filters (for sentence “Our systems achieved good per-
formance on the SRL task, easily beating the baseline.”).
</figureCaption>
<bodyText confidence="0.999725476190476">
Throughout the user interface, no distinction is
made between the different kinds of semantic ob-
jects and adjuncts so as to make it easy also for
non-linguists to use the search and to be more ro-
bust against bad analyses of the parser. Therefore,
the different semantic parts of a statement are high-
lighted in three different colors only, depending on
whether a part is the semantic subject, the semantic
predicate or anything else (object/adjunct).
In order to disengage even further from the con-
crete wording and make the semantic search even
more ‘meaning-based’, we additionally search for
synonyms of the semantic predicates in statement
filters. These synonyms have been computed as an
intersection of the most frequent verbs (semantic
predicates) in the anthology corpus with WordNet
synsets (Fellbaum, 1998), the main reason being re-
duction of the number of meanings irrelevant for the
domain. This relatively simple approach could of
course be improved, e.g. by active learning from
user clicks in search results etc.
</bodyText>
<sectionHeader confidence="0.983946" genericHeader="conclusions">
5 Summary and Outlook
</sectionHeader>
<bodyText confidence="0.999489615384615">
We have described the ACL Anthology Search-
bench, a novel search application for scientific dig-
ital libraries. The system is fully implemented and
indexes 7,500 papers of the 8,200 parsed ones. For
the other 700, bibliographic metadata was missing.
These and the remaining 10,000 papers are currently
being processed and will be added to the search in-
dex. The goal of the Searchbench is both to serve
as a showcase for benefits and improvement of NLP
for text search and at the same time provide a use-
ful tool for researchers in Computational Linguis-
tics. We believe that the tool by now already sup-
ports targeted search in a large collection of digital
research papers better than standard web search en-
gines. An evaluation comparing Searchbench query
results with web search is in progress.
Optionally, the Searchbench runs in a linguistic
debug mode providing NLP output a typical user
would not need. These analyses are accessible from
a context menu on each sentence (cf. Figure 4). Both
a tabular view of the semantic tuples of a sentence
(cf. Figure 3) and different kinds of information re-
lated to the parsing of the sentence (including the
MRS and a parse tree) can be displayed.
Future work, for which we are urgently seek-
ing funding, could include integration of further
</bodyText>
<page confidence="0.995733">
12
</page>
<bodyText confidence="0.99987525">
NLP-based features such as coreference resolution
or question answering, as well as citation classifi-
cation and graphical navigation along the ideas in
Sch¨afer and Kasterka (2010).
</bodyText>
<sectionHeader confidence="0.995491" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999643692307692">
We are indebted to Peter Adolphs, Bart Cramer, Dan
Flickinger, Stephan Oepen, Yi Zhang for their sup-
port with ERG and PET extensions such as chart
mapping and chart pruning. Melanie Reiplinger,
Benjamin Weitz and Leonie Gr¨on helped with pre-
processing. We also thank the anonymous review-
ers for their encouraging comments. The work de-
scribed in this paper has been carried out in the
context of the project TAKE (Technologies for Ad-
vanced Knowledge Extraction), funded under con-
tract 01IW08003 by the German Federal Ministry
of Education and Research, and in the context of the
world-wide DELPH-IN consortium.
</bodyText>
<sectionHeader confidence="0.998112" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999879963414634">
Peter Adolphs, Stephan Oepen, Ulrich Callmeier,
Berthold Crysmann, Daniel Flickinger, and Bernd
Kiefer. 2008. Some fine points of hybrid natural lan-
guage parsing. In Proceedings of LREC-2008, pages
1380–1387, Marrakesh, Morocco.
Steven Bird, Robert Dale, Bonnie Dorr, Bryan Gibson,
Mark Joseph, Min-Yen Kan, Dongwon Lee, Brett
Powley, Dragomir Radev, and Yee Fan Tan. 2008. The
ACL anthology reference corpus: A reference dataset
for bibliographic research. In Proceedings of LREC-
2008, pages 1755–1759, Marrakesh, Morocco.
Torsten Brants. 2000. TnT – a statistical part-of-speech
tagger. In Proc. ofANLP, pages 224–231, Seattle, WA.
Ulrich Callmeier. 2000. PET – A platform for experi-
mentation with efficient HPSG processing techniques.
Natural Language Engineering, 6(1):99–108.
Ann Copestake, Dan Flickinger, Ivan A. Sag, and Carl
Pollard. 2005. Minimal recursion semantics: an in-
troduction. Research on Language and Computation,
3(2–3):281–332.
Ann Copestake. 2002. Implementing Typed Feature
Structure Grammars. CSLI publications, Stanford.
Ann Copestake. 2009. Slacker semantics: why superfi-
ciality, dependency and avoidance of commitment can
be the right way to go. In Proc. of EACL, pages 1–9.
Bart Cramer and Yi Zhang. 2010. Constraining robust
constructions for broad-coverage parsing with preci-
sion grammars. In Proceedings of COLING-2010,
pages 223–231, Beijing, China.
Witold Dro˙zd˙zy´nski, Hans-Ulrich Krieger, Jakub Pisko-
rski, Ulrich Sch¨afer, and Feiyu Xu. 2004. Shallow
processing with unification and typed feature struc-
tures – foundations and applications. K¨unstliche In-
telligenz, 2004(1):17–23.
Christiane Fellbaum, editor. 1998. WordNet, An Elec-
tronic Lexical Database. MIT Press.
Dan Flickinger, Stephan Oepen, and Gisle Ytrestøl.
2010. WikiWoods: Syntacto-semantic annotation for
English Wikipedia. In Proceedings of LREC-2010,
pages 1665–1671.
Dan Flickinger. 2002. On building a more efficient
grammar by exploiting types. In Dan Flickinger,
Stephan Oepen, Hans Uszkoreit, and Jun’ichi Tsujii,
editors, Collaborative Language Engineering. A Case
Study in Efficient Grammar-based Processing, pages
1–17. CSLI Publications, Stanford, CA.
Katerina T. Frantzi, Sophia Ananiadou, and Jun’ichi Tsu-
jii. 1998. The C-value/NC-value method of automatic
recognition for multi-word terms. In Proceedings of
ECDL, pages 585–604.
Mitchell P. Marcus, Beatrice Santorini, and Mary Ann
Marcinkiewicz. 1993. Building a large annotated cor-
pus of English. The Penn Treebank. Computational
Linguistics, 19:313–330.
Takashi Ninomiya, Yoshimasa Tsuruoka, Yusuke Miyao,
Kenjiro Taura, and Jun’ichi Tsujii. 2006. Fast and
scalable HPSG parsing. Traitement automatique des
langues (TAL), 46(2).
Carl Pollard and Ivan A. Sag. 1994. Head-Driven Phrase
Structure Grammar. Studies in Contemporary Lin-
guistics. University of Chicago Press, Chicago.
Dragomir R. Radev, Pradeep Muthukrishnan, and Va-
hed Qazvinian. 2009. The ACL anthology network
corpus. In Proceedings of the ACL-2009 Workshop
on Natural Language Processing and Information Re-
trieval for Digital Libraries, Singapore.
Ulrich Sch¨afer and Uwe Kasterka. 2010. Scientific
authoring support: A tool to navigate in typed cita-
tion graphs. In Proceedings of the NAACL-HLT 2010
Workshop on Computational Linguistics and Writing,
pages 7–14, Los Angeles, CA.
Ulrich Sch¨afer and Bernd Kiefer. 2011. Advances in
deep parsing of scholarly paper content. In Raffaella
Bernardi, Sally Chambers, Bj¨orn Gottfried, Fr´ed´erique
Segond, and Ilya Zaihrayeu, editors, Advanced Lan-
guage Technologies for Digital Libraries, LNCS Hot
Topics Series. Springer. to appear.
Ulrich Sch¨afer. 2006. Middleware for creating and
combining multi-dimensional NLP markup. In Pro-
ceedings of the EACL-2006 Workshop on Multi-
dimensional Markup in Natural Language Processing,
pages 81–84, Trento, Italy.
</reference>
<page confidence="0.999468">
13
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.665876">
<title confidence="0.999051">The ACL Anthology Searchbench</title>
<author confidence="0.999937">Ulrich Sch¨afer Bernd Kiefer Christian Spurk J¨org Steffen Rui</author>
<affiliation confidence="0.9373715">Language Technology German Research Center for Artificial Intelligence</affiliation>
<address confidence="0.777768">D-66123 Saarbr¨ucken,</address>
<web confidence="0.934405">http://www.dfki.de/lt</web>
<abstract confidence="0.997441454545455">We describe a novel application for structured search in scientific digital libraries. The ACL Anthology Searchbench is meant to become a publicly available research tool to query the content of the ACL Anthology. The application provides search in both its bibliographic metadata and semantically analyzed full textual content. By combining these two features, very efficient and focused queries are possible. At the same time, the application serves as a showcase for the recent progress in natural language processing (NLP) research and language technology. The system currently indexes the textual content of 7,500 anthology papers from 2002–2009 with predicateargument-like semantic structures. It also provides useful search filters based on bibliographic metadata. It will be extended to provide the full anthology content and enhanced functionality based on further NLP techniques.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Peter Adolphs</author>
<author>Stephan Oepen</author>
<author>Ulrich Callmeier</author>
<author>Berthold Crysmann</author>
<author>Daniel Flickinger</author>
<author>Bernd Kiefer</author>
</authors>
<title>Some fine points of hybrid natural language parsing.</title>
<date>2008</date>
<booktitle>In Proceedings of LREC-2008,</booktitle>
<pages>1380--1387</pages>
<location>Marrakesh, Morocco.</location>
<contexts>
<context position="5570" citStr="Adolphs et al., 2008" startWordPosition="841" endWordPosition="844">and index semantically structured representations for search. To make the deep parser robust, it is embedded in a NLP workflow. The coverage (percentage of full deeply parsed sentences) on the anthology corpus could be increased from 65 % to now more than 85 % through careful combination of several robustness techniques; for example: (1) chart pruning, directed search during parsing to increase performance, and also coverage for longer sentences (Cramer and Zhang, 2010); (2) chart mapping, a novel method for integrating preprocessing information in exactly the way the deep grammar expects it (Adolphs et al., 2008); (3) new version of the ERG with better handling of open word classes; (4) more fine-grained named entity recognition, including recognition of citation patterns; (5) new, better suited parse ranking model (WeScience; Flickinger et al. (2010)). Because of limited space, we will focus on (1) and (2) below. A more detailed description and further results are available in (Sch¨afer and Kiefer, 2011). Except for a small part of the named entity recognition components (citations, some terminology) and the parse ranking model, there are no further adaptations to genre or domain of the text corpus. </context>
</contexts>
<marker>Adolphs, Oepen, Callmeier, Crysmann, Flickinger, Kiefer, 2008</marker>
<rawString>Peter Adolphs, Stephan Oepen, Ulrich Callmeier, Berthold Crysmann, Daniel Flickinger, and Bernd Kiefer. 2008. Some fine points of hybrid natural language parsing. In Proceedings of LREC-2008, pages 1380–1387, Marrakesh, Morocco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steven Bird</author>
<author>Robert Dale</author>
<author>Bonnie Dorr</author>
<author>Bryan Gibson</author>
<author>Mark Joseph</author>
<author>Min-Yen Kan</author>
<author>Dongwon Lee</author>
<author>Brett Powley</author>
<author>Dragomir Radev</author>
<author>Yee Fan Tan</author>
</authors>
<title>The ACL anthology reference corpus: A reference dataset for bibliographic research.</title>
<date>2008</date>
<booktitle>In Proceedings of LREC2008,</booktitle>
<pages>1755--1759</pages>
<location>Marrakesh, Morocco.</location>
<contexts>
<context position="2066" citStr="Bird et al., 2008" startWordPosition="296" endWordPosition="299">rmation and avoiding duplication of work have become urgent issues to be addressed by the scientific community. The organization and preservation of scientific knowledge in scientific publications, vulgo text documents, thwarts these efforts. From a viewpoint of a computer scientist, scientific papers are just ‘unstructured information’. At least in our own scientific community, Computational Linguistics, it is generally assumed that NLP could help to support search in such document collections. The ACL Anthology1 is a comprehensive electronic collection of scientific papers in our own field (Bird et al., 2008). It is updated regularly with new publications, but also older papers have been scanned and are made available electronically. We have implemented the ACL Anthology Searchbench2 for two reasons: Our first aim is to provide a more targeted search facility in this collection than standard web search on the anthology website. In this sense, the Searchbench is meant to become a service to our own community. Our second motivation is to use the developed system as a showcase for the progress that has been made over the last years in precision-oriented deep linguistic parsing in terms of both effici</context>
</contexts>
<marker>Bird, Dale, Dorr, Gibson, Joseph, Kan, Lee, Powley, Radev, Tan, 2008</marker>
<rawString>Steven Bird, Robert Dale, Bonnie Dorr, Bryan Gibson, Mark Joseph, Min-Yen Kan, Dongwon Lee, Brett Powley, Dragomir Radev, and Yee Fan Tan. 2008. The ACL anthology reference corpus: A reference dataset for bibliographic research. In Proceedings of LREC2008, pages 1755–1759, Marrakesh, Morocco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Torsten Brants</author>
</authors>
<title>TnT – a statistical part-of-speech tagger.</title>
<date>2000</date>
<booktitle>In Proc. ofANLP,</booktitle>
<pages>224--231</pages>
<location>Seattle, WA.</location>
<contexts>
<context position="6679" citStr="Brants, 2000" startWordPosition="1015" endWordPosition="1016">y) and the parse ranking model, there are no further adaptations to genre or domain of the text corpus. This implies that the NLP workflow could be easily and modularly adapted to other (scientific or nonscientific) domains—mainly thanks to the generic and comprehensive language modelling in the ERG. The NLP preprocessing component workflow is implemented using the Heart of Gold NLP middleware architecture (Sch¨afer, 2006). It starts with sentence boundary detection (SBR) and regular expression-based tokenization using its built-in component JTok, followed by the trigram-based PoS tagger TnT (Brants, 2000) trained on the Penn Treebank (Marcus et al., 1993) and the named entity recognizer SProUT (Dro˙zd˙zy´nski et al., 2004). 2.1 Precise Preprocessing Integration with Chart Mapping Tagger output is combined with information from the named entity recognizer, e.g. delivering hypothetical information on citation expressions. The combined result is delivered as input to the deep parser PET (Callmeier, 2000) running the ERG. Here, citations, for example, can be treated as either persons, locations or appositions. Concerning punctuation, the ERG can make use of information on opening and closing quota</context>
</contexts>
<marker>Brants, 2000</marker>
<rawString>Torsten Brants. 2000. TnT – a statistical part-of-speech tagger. In Proc. ofANLP, pages 224–231, Seattle, WA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ulrich Callmeier</author>
</authors>
<title>PET – A platform for experimentation with efficient HPSG processing techniques.</title>
<date>2000</date>
<journal>Natural Language Engineering,</journal>
<volume>6</volume>
<issue>1</issue>
<contexts>
<context position="7083" citStr="Callmeier, 2000" startWordPosition="1076" endWordPosition="1077">itecture (Sch¨afer, 2006). It starts with sentence boundary detection (SBR) and regular expression-based tokenization using its built-in component JTok, followed by the trigram-based PoS tagger TnT (Brants, 2000) trained on the Penn Treebank (Marcus et al., 1993) and the named entity recognizer SProUT (Dro˙zd˙zy´nski et al., 2004). 2.1 Precise Preprocessing Integration with Chart Mapping Tagger output is combined with information from the named entity recognizer, e.g. delivering hypothetical information on citation expressions. The combined result is delivered as input to the deep parser PET (Callmeier, 2000) running the ERG. Here, citations, for example, can be treated as either persons, locations or appositions. Concerning punctuation, the ERG can make use of information on opening and closing quotation marks. Such information is often not explicit in the input text, e.g. when, as in our setup, gained through OCR which does not distinguish between ‘ and ’ or “ and ”. However, a tokenizer can often guess (reconstruct) leftness and rightness correctly. This information, passed to the deep parser via chart mapping, helps it to disambiguate. 2.2 Increased Processing Speed and Coverage through Chart </context>
</contexts>
<marker>Callmeier, 2000</marker>
<rawString>Ulrich Callmeier. 2000. PET – A platform for experimentation with efficient HPSG processing techniques. Natural Language Engineering, 6(1):99–108.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann Copestake</author>
<author>Dan Flickinger</author>
<author>Ivan A Sag</author>
<author>Carl Pollard</author>
</authors>
<title>Minimal recursion semantics: an introduction.</title>
<date>2005</date>
<booktitle>Research on Language and Computation,</booktitle>
<pages>3--2</pages>
<contexts>
<context position="12130" citStr="Copestake et al., 2005" startWordPosition="1922" endWordPosition="1925">entences with at least one parse) over the whole corpus of 85.9% (1,321,336 sentences), without a significant change for any of the other measures, and with potential for further improvement. 3 Semantic Triple Extraction with DMRS In contrast to shallow parsers, the ERG not only handles detailed syntactic analyses of phrases, compounds, coordination, negation and other linguistic phenomena that are important for extracting semantic relations, but also generates a formal semantic representation of the meaning of the input sentence in the Minimal Recursion Semantics (MRS) representation format (Copestake et al., 2005). It consists of elementary predications for each word and larger constituents, connected via argument positions and variables, from which predicate-argument structure can be extracted. MRS representations resulting from deep parsing are still relatively close to linguistic structures and contain more detailed information than a user would like to query and search for. Therefore, an additional extraction and abstraction step is performed before storing semantic structures in the search index. Firstly, MRS is converted to DMRS (Copestake, 2009), a dependency-style version of MRS that eases extr</context>
</contexts>
<marker>Copestake, Flickinger, Sag, Pollard, 2005</marker>
<rawString>Ann Copestake, Dan Flickinger, Ivan A. Sag, and Carl Pollard. 2005. Minimal recursion semantics: an introduction. Research on Language and Computation, 3(2–3):281–332.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann Copestake</author>
</authors>
<title>Implementing Typed Feature Structure Grammars. CSLI publications,</title>
<date>2002</date>
<location>Stanford.</location>
<contexts>
<context position="12818" citStr="Copestake, 2002" startWordPosition="2021" endWordPosition="2022">tuents, connected via argument positions and variables, from which predicate-argument structure can be extracted. MRS representations resulting from deep parsing are still relatively close to linguistic structures and contain more detailed information than a user would like to query and search for. Therefore, an additional extraction and abstraction step is performed before storing semantic structures in the search index. Firstly, MRS is converted to DMRS (Copestake, 2009), a dependency-style version of MRS that eases extraction of predicate-argument structure using the implementation in LKB (Copestake, 2002). The representation format we devised for the search index we call semantic tuples, in fact quintuples &lt;subject, predicate, first object, second object, adjuncts&gt;; example in Figure 3. The basic extraction algorithm consists of the following three steps: (1) calculate the closure for each elementary predication based on the EQ (variable equivalence) relation, and group the predicates and entities in each closure respectively; (2) extract the relations of the groups, which results in a graph as a whole; (3) recursively traverse the graph, form one semantic tuple for each predicate, and fill in</context>
</contexts>
<marker>Copestake, 2002</marker>
<rawString>Ann Copestake. 2002. Implementing Typed Feature Structure Grammars. CSLI publications, Stanford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann Copestake</author>
</authors>
<title>Slacker semantics: why superficiality, dependency and avoidance of commitment can be the right way to go.</title>
<date>2009</date>
<booktitle>In Proc. of EACL,</booktitle>
<pages>1--9</pages>
<contexts>
<context position="12679" citStr="Copestake, 2009" startWordPosition="2001" endWordPosition="2003">sion Semantics (MRS) representation format (Copestake et al., 2005). It consists of elementary predications for each word and larger constituents, connected via argument positions and variables, from which predicate-argument structure can be extracted. MRS representations resulting from deep parsing are still relatively close to linguistic structures and contain more detailed information than a user would like to query and search for. Therefore, an additional extraction and abstraction step is performed before storing semantic structures in the search index. Firstly, MRS is converted to DMRS (Copestake, 2009), a dependency-style version of MRS that eases extraction of predicate-argument structure using the implementation in LKB (Copestake, 2002). The representation format we devised for the search index we call semantic tuples, in fact quintuples &lt;subject, predicate, first object, second object, adjuncts&gt;; example in Figure 3. The basic extraction algorithm consists of the following three steps: (1) calculate the closure for each elementary predication based on the EQ (variable equivalence) relation, and group the predicates and entities in each closure respectively; (2) extract the relations of t</context>
</contexts>
<marker>Copestake, 2009</marker>
<rawString>Ann Copestake. 2009. Slacker semantics: why superficiality, dependency and avoidance of commitment can be the right way to go. In Proc. of EACL, pages 1–9.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bart Cramer</author>
<author>Yi Zhang</author>
</authors>
<title>Constraining robust constructions for broad-coverage parsing with precision grammars.</title>
<date>2010</date>
<booktitle>In Proceedings of COLING-2010,</booktitle>
<pages>223--231</pages>
<location>Beijing, China.</location>
<contexts>
<context position="5423" citStr="Cramer and Zhang, 2010" startWordPosition="817" endWordPosition="820"> to parse each sentence they contain with the open-source HPSG (Pollard and Sag, 1994) grammar for English (ERG; Flickinger (2002)) and then distill and index semantically structured representations for search. To make the deep parser robust, it is embedded in a NLP workflow. The coverage (percentage of full deeply parsed sentences) on the anthology corpus could be increased from 65 % to now more than 85 % through careful combination of several robustness techniques; for example: (1) chart pruning, directed search during parsing to increase performance, and also coverage for longer sentences (Cramer and Zhang, 2010); (2) chart mapping, a novel method for integrating preprocessing information in exactly the way the deep grammar expects it (Adolphs et al., 2008); (3) new version of the ERG with better handling of open word classes; (4) more fine-grained named entity recognition, including recognition of citation patterns; (5) new, better suited parse ranking model (WeScience; Flickinger et al. (2010)). Because of limited space, we will focus on (1) and (2) below. A more detailed description and further results are available in (Sch¨afer and Kiefer, 2011). Except for a small part of the named entity recogni</context>
<context position="7876" citStr="Cramer and Zhang (2010)" startWordPosition="1202" endWordPosition="1205"> opening and closing quotation marks. Such information is often not explicit in the input text, e.g. when, as in our setup, gained through OCR which does not distinguish between ‘ and ’ or “ and ”. However, a tokenizer can often guess (reconstruct) leftness and rightness correctly. This information, passed to the deep parser via chart mapping, helps it to disambiguate. 2.2 Increased Processing Speed and Coverage through Chart Pruning In addition to a well-established discriminative maximum entropy model for post-analysis parse selec8 tion, we use an additional generative model as described in Cramer and Zhang (2010) to restrict the search space during parsing. This restriction increases efficiency, but also coverage, because the parse time was restricted to at most 60 CPU seconds on a standard PC, and more sentences could now be parsed within these bounds. A 4 GB limit for main memory consumption was far beyond what was ever needed. We saw a small but negligible decrease in parsing accuracy, 5.4 % best parses were not found due to the pruning of important chart edges. Ninomiya et al. (2006) did a very thorough comparison of different performance optimization strategies, and among those also a local pruni</context>
</contexts>
<marker>Cramer, Zhang, 2010</marker>
<rawString>Bart Cramer and Yi Zhang. 2010. Constraining robust constructions for broad-coverage parsing with precision grammars. In Proceedings of COLING-2010, pages 223–231, Beijing, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Witold Dro˙zd˙zy´nski</author>
<author>Hans-Ulrich Krieger</author>
<author>Jakub Piskorski</author>
<author>Ulrich Sch¨afer</author>
<author>Feiyu Xu</author>
</authors>
<title>Shallow processing with unification and typed feature structures – foundations and applications. K¨unstliche Intelligenz,</title>
<date>2004</date>
<marker>Dro˙zd˙zy´nski, Krieger, Piskorski, Sch¨afer, Xu, 2004</marker>
<rawString>Witold Dro˙zd˙zy´nski, Hans-Ulrich Krieger, Jakub Piskorski, Ulrich Sch¨afer, and Feiyu Xu. 2004. Shallow processing with unification and typed feature structures – foundations and applications. K¨unstliche Intelligenz, 2004(1):17–23.</rawString>
</citation>
<citation valid="true">
<title>WordNet, An Electronic Lexical Database.</title>
<date>1998</date>
<editor>Christiane Fellbaum, editor.</editor>
<publisher>MIT Press.</publisher>
<contexts>
<context position="16459" citStr="(1998)" startWordPosition="2623" endWordPosition="2623"> (iii) filters can easily be removed with a single click; (iv) manually entering filter items is assisted by sensible autosuggestions computed from the corpus; (v) accidental filter changes can easily be corrected by going back in the browser history. The following kinds of filters are supported: Statements (filter by semantic statements, i.e., the actual content of sentences, see Section 4.1), Keywords (filter by simple keywords with a full-text search), Topics (filter by topics of the articles that were extracted with an extended approach of the unsupervised term extractor of Frantzi et al. (1998)), Publication (filter by publication title/event), Authors (filter by author names), Year (filter by publication year), Affiliations (filter by affiliation organizations), Affiliation Sites (filter by affiliation cities and countries)6. Found papers always match all currently set filters. For each filter type multiple different filter items can be set; one could search for papers written jointly by people from different research institutes on a certain topic, for example. Matches of the statements filter and the keywords filter are highlighted in document snippets for each paper in the Result</context>
</contexts>
<marker>1998</marker>
<rawString>Christiane Fellbaum, editor. 1998. WordNet, An Electronic Lexical Database. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Flickinger</author>
<author>Stephan Oepen</author>
<author>Gisle Ytrestøl</author>
</authors>
<title>WikiWoods: Syntacto-semantic annotation for English Wikipedia.</title>
<date>2010</date>
<booktitle>In Proceedings of LREC-2010,</booktitle>
<pages>1665--1671</pages>
<contexts>
<context position="5813" citStr="Flickinger et al. (2010)" startWordPosition="878" endWordPosition="881">o now more than 85 % through careful combination of several robustness techniques; for example: (1) chart pruning, directed search during parsing to increase performance, and also coverage for longer sentences (Cramer and Zhang, 2010); (2) chart mapping, a novel method for integrating preprocessing information in exactly the way the deep grammar expects it (Adolphs et al., 2008); (3) new version of the ERG with better handling of open word classes; (4) more fine-grained named entity recognition, including recognition of citation patterns; (5) new, better suited parse ranking model (WeScience; Flickinger et al. (2010)). Because of limited space, we will focus on (1) and (2) below. A more detailed description and further results are available in (Sch¨afer and Kiefer, 2011). Except for a small part of the named entity recognition components (citations, some terminology) and the parse ranking model, there are no further adaptations to genre or domain of the text corpus. This implies that the NLP workflow could be easily and modularly adapted to other (scientific or nonscientific) domains—mainly thanks to the generic and comprehensive language modelling in the ERG. The NLP preprocessing component workflow is i</context>
</contexts>
<marker>Flickinger, Oepen, Ytrestøl, 2010</marker>
<rawString>Dan Flickinger, Stephan Oepen, and Gisle Ytrestøl. 2010. WikiWoods: Syntacto-semantic annotation for English Wikipedia. In Proceedings of LREC-2010, pages 1665–1671.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Flickinger</author>
</authors>
<title>On building a more efficient grammar by exploiting types.</title>
<date>2002</date>
<booktitle>Collaborative Language Engineering. A Case Study in Efficient Grammar-based Processing,</booktitle>
<pages>1--17</pages>
<editor>In Dan Flickinger, Stephan Oepen, Hans Uszkoreit, and Jun’ichi Tsujii, editors,</editor>
<publisher>CSLI Publications,</publisher>
<location>Stanford, CA.</location>
<contexts>
<context position="4930" citStr="Flickinger (2002)" startWordPosition="739" endWordPosition="740">ndex for the ACL Anthology are its original PDF documents, currently 8,200 from the years 2002 through 2009. To overcome quality problems in text extraction from PDF, we use a commercial PDF extractor based on OCR techniques. This approach guarantees uniform and highquality textual representations even from older papers in the anthology (before 2000) which mostly were scanned from printed paper versions. The general idea of the semantics-oriented access to scholarly paper content is to parse each sentence they contain with the open-source HPSG (Pollard and Sag, 1994) grammar for English (ERG; Flickinger (2002)) and then distill and index semantically structured representations for search. To make the deep parser robust, it is embedded in a NLP workflow. The coverage (percentage of full deeply parsed sentences) on the anthology corpus could be increased from 65 % to now more than 85 % through careful combination of several robustness techniques; for example: (1) chart pruning, directed search during parsing to increase performance, and also coverage for longer sentences (Cramer and Zhang, 2010); (2) chart mapping, a novel method for integrating preprocessing information in exactly the way the deep g</context>
</contexts>
<marker>Flickinger, 2002</marker>
<rawString>Dan Flickinger. 2002. On building a more efficient grammar by exploiting types. In Dan Flickinger, Stephan Oepen, Hans Uszkoreit, and Jun’ichi Tsujii, editors, Collaborative Language Engineering. A Case Study in Efficient Grammar-based Processing, pages 1–17. CSLI Publications, Stanford, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katerina T Frantzi</author>
<author>Sophia Ananiadou</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>The C-value/NC-value method of automatic recognition for multi-word terms.</title>
<date>1998</date>
<booktitle>In Proceedings of ECDL,</booktitle>
<pages>585--604</pages>
<contexts>
<context position="16459" citStr="Frantzi et al. (1998)" startWordPosition="2620" endWordPosition="2623">as new filters; (iii) filters can easily be removed with a single click; (iv) manually entering filter items is assisted by sensible autosuggestions computed from the corpus; (v) accidental filter changes can easily be corrected by going back in the browser history. The following kinds of filters are supported: Statements (filter by semantic statements, i.e., the actual content of sentences, see Section 4.1), Keywords (filter by simple keywords with a full-text search), Topics (filter by topics of the articles that were extracted with an extended approach of the unsupervised term extractor of Frantzi et al. (1998)), Publication (filter by publication title/event), Authors (filter by author names), Year (filter by publication year), Affiliations (filter by affiliation organizations), Affiliation Sites (filter by affiliation cities and countries)6. Found papers always match all currently set filters. For each filter type multiple different filter items can be set; one could search for papers written jointly by people from different research institutes on a certain topic, for example. Matches of the statements filter and the keywords filter are highlighted in document snippets for each paper in the Result</context>
</contexts>
<marker>Frantzi, Ananiadou, Tsujii, 1998</marker>
<rawString>Katerina T. Frantzi, Sophia Ananiadou, and Jun’ichi Tsujii. 1998. The C-value/NC-value method of automatic recognition for multi-word terms. In Proceedings of ECDL, pages 585–604.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Beatrice Santorini</author>
<author>Mary Ann Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of English. The Penn Treebank. Computational Linguistics,</title>
<date>1993</date>
<contexts>
<context position="6730" citStr="Marcus et al., 1993" startWordPosition="1023" endWordPosition="1026"> further adaptations to genre or domain of the text corpus. This implies that the NLP workflow could be easily and modularly adapted to other (scientific or nonscientific) domains—mainly thanks to the generic and comprehensive language modelling in the ERG. The NLP preprocessing component workflow is implemented using the Heart of Gold NLP middleware architecture (Sch¨afer, 2006). It starts with sentence boundary detection (SBR) and regular expression-based tokenization using its built-in component JTok, followed by the trigram-based PoS tagger TnT (Brants, 2000) trained on the Penn Treebank (Marcus et al., 1993) and the named entity recognizer SProUT (Dro˙zd˙zy´nski et al., 2004). 2.1 Precise Preprocessing Integration with Chart Mapping Tagger output is combined with information from the named entity recognizer, e.g. delivering hypothetical information on citation expressions. The combined result is delivered as input to the deep parser PET (Callmeier, 2000) running the ERG. Here, citations, for example, can be treated as either persons, locations or appositions. Concerning punctuation, the ERG can make use of information on opening and closing quotation marks. Such information is often not explicit </context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>Mitchell P. Marcus, Beatrice Santorini, and Mary Ann Marcinkiewicz. 1993. Building a large annotated corpus of English. The Penn Treebank. Computational Linguistics, 19:313–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Takashi Ninomiya</author>
</authors>
<title>Yoshimasa Tsuruoka, Yusuke Miyao, Kenjiro Taura, and Jun’ichi Tsujii.</title>
<date>2006</date>
<booktitle>Fast and scalable HPSG parsing. Traitement automatique des langues (TAL),</booktitle>
<volume>46</volume>
<issue>2</issue>
<marker>Ninomiya, 2006</marker>
<rawString>Takashi Ninomiya, Yoshimasa Tsuruoka, Yusuke Miyao, Kenjiro Taura, and Jun’ichi Tsujii. 2006. Fast and scalable HPSG parsing. Traitement automatique des langues (TAL), 46(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carl Pollard</author>
<author>Ivan A Sag</author>
</authors>
<title>Head-Driven Phrase Structure Grammar. Studies in Contemporary Linguistics.</title>
<date>1994</date>
<publisher>University of Chicago Press,</publisher>
<location>Chicago.</location>
<contexts>
<context position="4886" citStr="Pollard and Sag, 1994" startWordPosition="730" endWordPosition="734">rsing the ACL Anthology The basis of the search index for the ACL Anthology are its original PDF documents, currently 8,200 from the years 2002 through 2009. To overcome quality problems in text extraction from PDF, we use a commercial PDF extractor based on OCR techniques. This approach guarantees uniform and highquality textual representations even from older papers in the anthology (before 2000) which mostly were scanned from printed paper versions. The general idea of the semantics-oriented access to scholarly paper content is to parse each sentence they contain with the open-source HPSG (Pollard and Sag, 1994) grammar for English (ERG; Flickinger (2002)) and then distill and index semantically structured representations for search. To make the deep parser robust, it is embedded in a NLP workflow. The coverage (percentage of full deeply parsed sentences) on the anthology corpus could be increased from 65 % to now more than 85 % through careful combination of several robustness techniques; for example: (1) chart pruning, directed search during parsing to increase performance, and also coverage for longer sentences (Cramer and Zhang, 2010); (2) chart mapping, a novel method for integrating preprocessi</context>
</contexts>
<marker>Pollard, Sag, 1994</marker>
<rawString>Carl Pollard and Ivan A. Sag. 1994. Head-Driven Phrase Structure Grammar. Studies in Contemporary Linguistics. University of Chicago Press, Chicago.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dragomir R Radev</author>
<author>Pradeep Muthukrishnan</author>
<author>Vahed Qazvinian</author>
</authors>
<title>The ACL anthology network corpus.</title>
<date>2009</date>
<booktitle>In Proceedings of the ACL-2009 Workshop on Natural Language Processing and Information Retrieval for Digital Libraries,</booktitle>
<location>Singapore.</location>
<contexts>
<context position="17671" citStr="Radev et al., 2009" startWordPosition="2810" endWordPosition="2813"> Results View and in the currently selected paper of the Document View. Besides a header displaying the metadata of the currently selected paper (including the automatically extracted topics on the right), the Document View provides three subviews of the selected paper: (1) the Document Content View is a raw list of the sentences of the paper and provides different kinds of interaction with these sentences; (2) the PDF View shows the original PDF version of the paper; (3) the Citations View provides citation information includ6Affiliations have been added using the ACL Anthology Network data (Radev et al., 2009). 11 ing link to the ACL Anthology Network (Radev et al., 2009). Figure 4 shows the search result for a query combining a statement (‘obtain improvements’), a topic ‘dependency parsing’ and the publication year 2008. As can be seen in the Results View, six papers match these filters; sentences with semantically similar predicates and passive voice are found, too. 4.1 Semantic Search The main feature which distinguishes the ACL Anthology Searchbench from other search applications for scientific papers is the semantic search in paper content. This enables the search for (semantic) statements in </context>
</contexts>
<marker>Radev, Muthukrishnan, Qazvinian, 2009</marker>
<rawString>Dragomir R. Radev, Pradeep Muthukrishnan, and Vahed Qazvinian. 2009. The ACL anthology network corpus. In Proceedings of the ACL-2009 Workshop on Natural Language Processing and Information Retrieval for Digital Libraries, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ulrich Sch¨afer</author>
<author>Uwe Kasterka</author>
</authors>
<title>Scientific authoring support: A tool to navigate in typed citation graphs.</title>
<date>2010</date>
<booktitle>In Proceedings of the NAACL-HLT 2010 Workshop on Computational Linguistics and Writing,</booktitle>
<pages>7--14</pages>
<location>Los Angeles, CA.</location>
<marker>Sch¨afer, Kasterka, 2010</marker>
<rawString>Ulrich Sch¨afer and Uwe Kasterka. 2010. Scientific authoring support: A tool to navigate in typed citation graphs. In Proceedings of the NAACL-HLT 2010 Workshop on Computational Linguistics and Writing, pages 7–14, Los Angeles, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ulrich Sch¨afer</author>
<author>Bernd Kiefer</author>
</authors>
<title>Advances in deep parsing of scholarly paper content.</title>
<date>2011</date>
<booktitle>Advanced Language Technologies for Digital Libraries, LNCS Hot Topics Series.</booktitle>
<editor>In Raffaella Bernardi, Sally Chambers, Bj¨orn Gottfried, Fr´ed´erique Segond, and Ilya Zaihrayeu, editors,</editor>
<publisher>Springer.</publisher>
<note>to appear.</note>
<marker>Sch¨afer, Kiefer, 2011</marker>
<rawString>Ulrich Sch¨afer and Bernd Kiefer. 2011. Advances in deep parsing of scholarly paper content. In Raffaella Bernardi, Sally Chambers, Bj¨orn Gottfried, Fr´ed´erique Segond, and Ilya Zaihrayeu, editors, Advanced Language Technologies for Digital Libraries, LNCS Hot Topics Series. Springer. to appear.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ulrich Sch¨afer</author>
</authors>
<title>Middleware for creating and combining multi-dimensional NLP markup.</title>
<date>2006</date>
<booktitle>In Proceedings of the EACL-2006 Workshop on Multidimensional Markup in Natural Language Processing,</booktitle>
<pages>81--84</pages>
<location>Trento, Italy.</location>
<marker>Sch¨afer, 2006</marker>
<rawString>Ulrich Sch¨afer. 2006. Middleware for creating and combining multi-dimensional NLP markup. In Proceedings of the EACL-2006 Workshop on Multidimensional Markup in Natural Language Processing, pages 81–84, Trento, Italy.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>