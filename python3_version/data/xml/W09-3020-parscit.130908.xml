<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.028099">
<title confidence="0.995117">
Using Parallel Propbanks to enhance Word-alignments
</title>
<author confidence="0.993521">
Jinho D. Choi Martha Palmer Nianwen Xue
</author>
<affiliation confidence="0.948586">
Dept. of Computer Science Dept. of Linguistics Dept. of Computer Science
Univ. of Colorado at Boulder Univ. of Colorado at Boulder Brandeis University
</affiliation>
<email confidence="0.994049">
choijd@colorado.edu mpalmer@colorado.edu xuen@brandeis.edu
</email>
<sectionHeader confidence="0.997415" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9949753">
This short paper describes the use of the
linguistic annotation available in paral-
lel PropBanks (Chinese and English) for
the enhancement of automatically derived
word alignments. Specifically, we sug-
gest ways to refine and expand word
alignments for verb-predicates by using
predicate-argument structures. Evalua-
tions demonstrate improved alignment ac-
curacies that vary by corpus type.
</bodyText>
<sectionHeader confidence="0.999392" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.997640115384616">
Since verbs tend to be the roots of dependency re-
lations in a sentence (Palmer et al., 2005), when it
comes down to translations, finding correct map-
pings between verbs in a source and a target lan-
guage is very important. Many machine transla-
tion systems (Fraser and Marcu, 2007) use word-
alignment tools such as GIZA++ (Och and Ney,
2003) to retrieve word mappings between a source
and a target language. Although GIZA++ gives
well-structured alignments, it has limitations in
several ways. First, it is hard to verify if align-
ments generated by GIZA++ are correct. Second,
GIZA++ may not find alignments for low-frequent
words. Third, GIZA++ does not account for any
semantic information.
In this paper, we suggest a couple of ways to
enhance word-alignments for predicating expres-
sions such as verbs1. We restricted the source
and the target language to Chinese and English,
respectively. The goal is to use the linguistic
annotation available in parallel PropBanks (Xue
and Palmer, 2009) to refine and expand automatic
word-alignments. First, we check if the alignment
for each Chinese predicate, generated by GIZA++,
is also a predicate in English (Section 3). If it is,
we verify if the alignment is correct by matching
</bodyText>
<footnote confidence="0.717562">
1Throughout the paper, all predicates refer to verbs.
</footnote>
<bodyText confidence="0.999287666666667">
their arguments (Section 4.1). If it is not, we find
an English predicate that has the maximum argu-
ment matching with the Chinese predicate (Sec-
tion 4.2). Finally, we evaluate the potential of the
enhanced word-alignments for providing a signif-
icant improvement over the GIZA++ baseline.
</bodyText>
<sectionHeader confidence="0.993388" genericHeader="method">
2 Parallel Corpus
</sectionHeader>
<bodyText confidence="0.999975533333333">
We used the ‘English Chinese Translation Tree-
bank’ (ECTB), a parallel English-Chinese cor-
pus. In addition to the treebank syntactic struc-
ture, the corpus has also been annotated with
semantic role labels in the standard PropBank
style of Arg0, Arg1, etc., based on verb specific
frame file definitions (Xue and Palmer, 2009).
The corpus is divided into two parts: the Xin-
hua Chinese newswire with literal English trans-
lations (4,363 parallel sentences) and the Sino-
rama Chinese news magazine with non-literal En-
glish translations (12,600 parallel sentences). We
experimented with the two parts separately to
see how literal and non-literal translations affect
word-alignments.
</bodyText>
<sectionHeader confidence="0.980328" genericHeader="method">
3 Predicate Matching
</sectionHeader>
<bodyText confidence="0.999526333333333">
For preprocessing, we ran GIZA++ on ECTB to
get word-alignments between Chinese and En-
glish. Then, for each Chinese predicate, we
checked if it is aligned to an English predicate by
using the gold-standard parallel Propbanks. Ta-
ble 1 shows how many Chinese predicates were
aligned to what kind of English words.
Only (45.3%-Xinhua, 19.1%-Sinorama) of Chi-
nese predicates were aligned to words that are
predicates in English. It is true that not all Chi-
nese verbs are supposed to be translated to verbs
in English, but that does not account for the num-
bers in Table 1. We therefore assume that there
are opportunities to enhance word-alignments for
Chinese and English predicates.
</bodyText>
<page confidence="0.973372">
121
</page>
<note confidence="0.9761605">
Proceedings of the Third Linguistic Annotation Workshop, ACL-IJCNLP 2009, pages 121–124,
Suntec, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP
</note>
<table confidence="0.998065">
Alignment Xinhua Sinorama
Ch.pred → En.pred 5,842 7,643
Ch.pred → En.be 386 1,229
Ch.pred → En.else 2,489 8,726
Ch.pred → En.none 4,178 22,488
Total 12,895 40,086
</table>
<tableCaption confidence="0.743599">
Table 1: Results of predicate matching (Ch: Chi-
nese, En: English, pred: predicates, be: be-verbs,
else: non-verbs, none: no word). The numbers in-
dicate the amount of verb-tokens, not verb-types.
</tableCaption>
<sectionHeader confidence="0.969377" genericHeader="method">
4 Argument Matching
</sectionHeader>
<bodyText confidence="0.999966222222222">
For Chinese predicates aligned to English predi-
cates, we can verify the alignments by ‘Top-down
argument matching’: given Chinese and English
predicates that are aligned, check if their argu-
ments are also aligned (arguments are found from
parallel Propbanks). The intuition is that if the
predicates are correctly aligned across the lan-
guages, their arguments should be aligned as well.
For Chinese predicates not aligned to any En-
glish words, we can find their potential English
alignments by ‘Bottom-up argument matching’:
given a set of arguments for a such Chinese predi-
cate, find some English predicate whose set of ar-
guments has the most words aligned to words in
the Chinese arguments. If the words in the argu-
ments are mostly aligned (above a certain thresh-
old) across the languages, we suspect that the
predicates should be aligned as well.
</bodyText>
<subsectionHeader confidence="0.998289">
4.1 Top-down Argument Matching (T-D)
</subsectionHeader>
<bodyText confidence="0.998490882352941">
Given a Chinese predicate pc aligned to an English
predicate pe, let Sc and Se be a set of arguments
for pc and pe, respectively. For each cai ∈ Sc, we
match it with some eaj ∈ Se that has the most
words aligned to words in cai. If such eaj ex-
ists, we count the number of aligned words, say
|cai ∩ eaj|; otherwise, the count is 0. Once the
matchings are done, we average the proportions
of the counts and if the average is above a certain
threshold, we consider the alignment is correct.
Let us look at the example in Table 2. Af-
ter the preprocessing, a Chinese predicate ‘ikAt’
is aligned to an English predicate ‘set up’ by
GIZA++. ‘ikA’ has two arguments, Ch.Arg0 and
Ch.Arg1, retrieved from the Chinese Propbank.
For each Chinese argument, we search for some
argument of ‘set’ (from the English Propbank) that
</bodyText>
<listItem confidence="0.949904666666667">
– Chinese Sentence –
: NHt l A i�_(L- M$ ikA tVQ ^ itI t_19F 1H&amp;quot;Pc
- Predicate: ik_[..01 → setup
- Ch.Arg0: M$ → those municipalities
- Ch.Arg1: t VQ ^ itl tz(F aHIPC
→ fourteen border economic cooperation zones
– English Sentence –
: At the same time it also sanctioned those municipalities
to set up fourteen border economic cooperation zones
- Predicate: set.03 (set up)
- En.Arg0: those municipalities
- En.Arg1: fourteen border economic cooperation zones
</listItem>
<tableCaption confidence="0.981133">
Table 2: Parallel sentences labelled with their se-
mantic roles
</tableCaption>
<bodyText confidence="0.999353941176471">
has the most words aligned. For instance, words
in Ch.Arg0, ‘i�_(Lt M$’, are aligned to ‘those
municipalities’ by GIZA++ so Ch.Arg0 finds
En.Arg0 as the one maximizes word-interscetions
(similar for Ch.Arg1 and En.Arg1). In this case,
the argument matchings for all pairs of arguments
are 100%, so we consider the alignment is correct.
Table 3 shows the average argument matching
scores for all pairs of Chinese and English predi-
cates. For each pair of predicates, ‘macro-average’
measures the proportion of word-intersections for
each pair of Chinese and English arguments (with
the most words aligned) and averages the pro-
portions whereas ‘micro-average’ counts word-
intersections for all pairs of arguments (each pair
with the most words aligned) and divides it by the
total number of words in Chinese arguments.
</bodyText>
<listItem confidence="0.999915">
• Sc = a set of Chinese arguments, cai ∈ Sc
• Se = a set of English arguments, eaj ∈ Se
• Macro average argument matching score
</listItem>
<equation confidence="0.982779333333333">
= 1 argmax ( |cai ∩ eaj|)
c
|S |�( |cai |)
</equation>
<listItem confidence="0.917176333333333">
• Micro average argument matching score
E∀ca, argmax(|cai ∩ eaj|)
=
</listItem>
<table confidence="0.998872333333333">
Xinhua Sinorama
Macro Avg. 80.55% 53.56%
Micro Avg. 83.91% 52.62%
</table>
<tableCaption confidence="0.984492">
Table 3: Average argument matching scores for
top-down argument matching
</tableCaption>
<figure confidence="0.6935855">
E
∀ca, |cai|
</figure>
<page confidence="0.97867">
122
</page>
<bodyText confidence="0.9998936">
It is not surprising that Xinhua’s scores are
higher because the English sentences in Xinhua
are more literally translated than ones in Sinorama
so that it is easier to find correct alignments in Xin-
hua.
</bodyText>
<subsectionHeader confidence="0.996643">
4.2 Bottom-Up Argument Matching (B-U)
</subsectionHeader>
<bodyText confidence="0.998418933333333">
A large portion of Chinese predicates are aligned
to no English words. For such Chinese predicate,
say p,, we check to see if there exists an English
predicate within the parallel sentence, say pe, that
is not aligned to any Chinese word and gives the
maximum micro-average score (Section 4.1) com-
pare to all other predicates in the English sen-
tence. If the micro-average score is above a certain
threshold, we align p, to pe.
The thresholds we used are 0.7 and 0.8. Thresh-
olds below 0.7 assumes too many alignments that
are incorrect and ones above 0.8 assumes too few
alignments to be useful. Table 4 shows the average
argument matching scores for alignments found by
bottom-up argument matching.
</bodyText>
<table confidence="0.9978965">
Xinhua Sinorama
Thresh. 0.7 0.8 0.7 0.8
Macro 80.74 83.99 77.70 82.86
Micro 82.63 86.46 79.45 85.07
</table>
<tableCaption confidence="0.9982065">
Table 4: Average argument matching scores in
percentile for bottom-up argument matching
</tableCaption>
<sectionHeader confidence="0.997943" genericHeader="evaluation">
5 Evaluations
</sectionHeader>
<bodyText confidence="0.9999815">
Evaluations are done by a Chinese-English bilin-
gual. We used a different English-Chinese paral-
lel corpus for evaluations. There are 100 paral-
lel sentences, 365 Chinese verb-tokens, and 273
Chinese verb-types in the corpus. We tested
word-alignments, refined and expanded by our ap-
proaches, on verb-types rather than verb-tokens
to avoid over-emphasizing multiple appearances
of a single type. Furthermore, we tested word-
alignments from Xinhua and Sinorama separately
to see how literal and non-literal translations affect
the outcomes.
</bodyText>
<subsectionHeader confidence="0.970871">
5.1 Refining word-alignment
</subsectionHeader>
<bodyText confidence="0.999968733333333">
We used three kinds of measurements for compar-
isons: term coverage, term expansion, and align-
ment accuracy. ‘Term coverage’ shows how many
source terms (Chinese verb-types) are covered by
word-alignments found in each corpus. Out of
273 Chinese verb-types in the test corpus, (79-
Xinhua, 129-Sinorama) were covered by word-
alignments generated by GIZA++. ‘Term expan-
sion’ shows how many target terms (English verb-
types) are suggested for each of the covered source
terms. There are on average (1.77-Xinhua, 2.29-
Sinorama) English verb-types suggested for each
covered Chinese verb-type. ‘Alignment accuracy’
shows how many of the suggested target terms are
correct. Among the suggested English verb-types,
(83.35%-Xinhua, 57.76%-Sinorama) were correct
on average.
The goal is to improve the alignment accu-
racy with minimum reduction of the term cov-
erage and expansion. To accomplish the goal,
we set a threshold for the T-D’s macro-average
score: for Chinese predicates aligned to English
predicates, we kept only alignments whose macro-
average scores meet or exceed a certain threshold.
The thresholds we chose are 0.4 and 0.5; lower
thresholds did not have much effect and higher
thresholds threw out too many alignments. Table 5
shows the results of three measurements with re-
spect to the thresholds (Note that all these align-
ments were generated by GIZA++).
</bodyText>
<table confidence="0.998386">
Xinhua Sinorama
TH TC ATE AAA TC ATE AAA
0.0 79 1.77 83.35 129 2.29 57.76
0.4 76 1.72 83.54 93 1.8 65.88
0.5 76 1.68 83.71 62 1.58 78.09
</table>
<tableCaption confidence="0.754615">
Table 5: Results for alignment refinement (TH:
threshold, TC: term coverage, ATE: average term
expansion, AAA: average alignment accuracy in
</tableCaption>
<bodyText confidence="0.976504875">
percentage). The highest score for each measure-
ment is marked as bold.
As you can see, thresholds did not have much
effect on alignments found in Xinhua. This is
understandable because the translations in Xin-
hua are so literal that it was relatively easy for
GIZA++ to find correct alignments; in other
words, the alignments generated by GIZA++ were
already very accurate. However, for alignments
found in Sinorama, the average alignment accu-
racy increases radically as the threshold increases.
This implies that it is possible to refine word-
alignments found in a corpus containing many
non-literal translations by using T-D.
Notice that the term coverage for Sinorama de-
creases as the threshold increases. Considering
</bodyText>
<page confidence="0.997596">
123
</page>
<bodyText confidence="0.999260333333333">
how much improvement it made for the average
alignment accuracy, we suspect that it filtered out
mostly ones that were incorrect alignments.
</bodyText>
<subsectionHeader confidence="0.992293">
5.2 Expanding word-alignment
</subsectionHeader>
<bodyText confidence="0.999731933333333">
We used B-U to expand word-alignments for Chi-
nese predicates aligned to no English words. We
decided not to expand alignments for Chinese
predicates aligned to non-verb English words be-
cause GIZA++ generated alignments are more ac-
curate than ones found by B-U in general.
There are (22-Xinhua, 20-Sinorama) additional
verb-types covered by the expanded-alignments.
Note that these alignments are already filtered by
the micro-average score (Section 4.2). To refine
the alignments even more, we set a threshold on
the macro-average score as well. The thresholds
we used for the macro-average score are 0.6 and
0.7. Table 6 shows the results of the expanded-
alignments found in Xinhua and Sinorama.
</bodyText>
<table confidence="0.9984611">
Mac - 0.7 Mac - 0.8
TC ATE AAA TC ATE AAA
Mic Xinhua
0.0 22 4.27 50.38 20 3.35 57.50
0.6 21 3.9 54.76 18 3.39 63.89
0.7 19 3.47 55.26 17 3.12 61.76
Mic Sinorama
0.0 37 3.59 18.01 29 3.14 14.95
0.6 31 3.06 15.11 27 2.93 14.46
0.7 21 2.81 11.99 25 2.6 11.82
</table>
<tableCaption confidence="0.878464">
Table 6: Results for expanded-alignments found in
</tableCaption>
<bodyText confidence="0.965840111111111">
Xinhua and Sinorama (Mac: threshold on macro-
average score, Mic: threshold on micro-average
score)
The average alignment accuracy for Xinhua is
encouraging; it shows that B-U can expand word-
alignments for a corpus with literal translations.
The average alignment accuracy for Sinorama is
surprisingly low; it shows that B-U cannot func-
tion effectively given non-literal translations.
</bodyText>
<sectionHeader confidence="0.998117" genericHeader="conclusions">
6 Summary and Future Works
</sectionHeader>
<bodyText confidence="0.999975">
We have demonstrated the potential for using par-
allel Propbanks to improve statistical verb transla-
tions from Chinese to English. Our B-U approach
shows promise for expanding the term-coverage
of GIZA++ alignments that are based on literal
translations. In contrast, our T-D is most effec-
tive with non-literal translations for verifying the
alignment accuracy, which has been proven diffi-
cult for GIZA++.
This is still a preliminary work but in the fu-
ture, we will try to enhance word-alignments
by using automatically labelled Propbanks, Nom-
banks (Meyers et al., 2004), Named-entity tag-
ging, and test the enhancement on bigger corpora.
Furthermore, we will also evaluate the integration
of our enhanced alignments with statistical ma-
chine translation systems.
</bodyText>
<sectionHeader confidence="0.999075" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.890778111111111">
Special thanks to Daniel Gildea, Ding Liu
(University of Rochester) who provided word-
alignments, Wei Wang (Information Sciences In-
stitute at University of Southern California) who
provided the test-corpus, and Hua Zhong (Uni-
versity of Colorado at Boulder) who performed
the evaluations. We gratefully acknowledge
the support of the National Science Foundation
Grants IIS-0325646, Domain Independent Seman-
tic Parsing, CISE-CRI-0551615, Towards a Com-
prehensive Linguistic Annotation, and a grant
from the Defense Advanced Research Projects
Agency (DARPA/IPTO) under the GALE pro-
gram, DARPA/CMO Contract No. HR0011-06-
C-0022, subcontract from BBN, Inc. Any contents
expressed in this material are those of the authors
and do not necessarily reflect the views of the Na-
tional Science Foundation.
</bodyText>
<sectionHeader confidence="0.995579" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999659888888889">
Alexander Fraser and Daniel Marcu. 2007. Measuring
word alignment quality for statistical machine trans-
lation. Computational Linguistics, 33(3):293–303.
A. Meyers, R. Reeves, C. Macleod, R. Szekely,
V. Zielinska, B. Young, and R. Grishman. 2004.
The nombank project: An interim report. In HLT-
NAACL 2004 Workshop: Frontiers in Corpus Anno-
tation, pages 24–31.
Franz Josef Och and Hermann Ney. 2003. A sys-
tematic comparison of various statistical alignment
models. Computational Linguistics, 29(1):19–51.
Martha Palmer, Daniel Gildea, and Paul Kingsbury.
2005. The proposition bank: An annotated cor-
pus of semantic roles. Computational Linguistics,
31(1):71–106.
Nianwen Xue and Martha Palmer. 2009. Adding se-
mantic roles to the chinese treebank. Natural Lan-
guage Engineering, 15(1):143–172.
</reference>
<page confidence="0.998311">
124
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.969492">
<title confidence="0.999984">Using Parallel Propbanks to enhance Word-alignments</title>
<author confidence="0.999525">Jinho D Choi Martha Palmer Nianwen Xue</author>
<affiliation confidence="0.9995115">Dept. of Computer Science Dept. of Linguistics Dept. of Computer Science Univ. of Colorado at Boulder Univ. of Colorado at Boulder Brandeis</affiliation>
<email confidence="0.998676">choijd@colorado.edumpalmer@colorado.eduxuen@brandeis.edu</email>
<abstract confidence="0.997429454545455">This short paper describes the use of the linguistic annotation available in parallel PropBanks (Chinese and English) for the enhancement of automatically derived word alignments. Specifically, we suggest ways to refine and expand word alignments for verb-predicates by using predicate-argument structures. Evaluations demonstrate improved alignment accuracies that vary by corpus type.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Alexander Fraser</author>
<author>Daniel Marcu</author>
</authors>
<title>Measuring word alignment quality for statistical machine translation.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>3</issue>
<contexts>
<context position="992" citStr="Fraser and Marcu, 2007" startWordPosition="143" endWordPosition="146">ation available in parallel PropBanks (Chinese and English) for the enhancement of automatically derived word alignments. Specifically, we suggest ways to refine and expand word alignments for verb-predicates by using predicate-argument structures. Evaluations demonstrate improved alignment accuracies that vary by corpus type. 1 Introduction Since verbs tend to be the roots of dependency relations in a sentence (Palmer et al., 2005), when it comes down to translations, finding correct mappings between verbs in a source and a target language is very important. Many machine translation systems (Fraser and Marcu, 2007) use wordalignment tools such as GIZA++ (Och and Ney, 2003) to retrieve word mappings between a source and a target language. Although GIZA++ gives well-structured alignments, it has limitations in several ways. First, it is hard to verify if alignments generated by GIZA++ are correct. Second, GIZA++ may not find alignments for low-frequent words. Third, GIZA++ does not account for any semantic information. In this paper, we suggest a couple of ways to enhance word-alignments for predicating expressions such as verbs1. We restricted the source and the target language to Chinese and English, re</context>
</contexts>
<marker>Fraser, Marcu, 2007</marker>
<rawString>Alexander Fraser and Daniel Marcu. 2007. Measuring word alignment quality for statistical machine translation. Computational Linguistics, 33(3):293–303.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Meyers</author>
<author>R Reeves</author>
<author>C Macleod</author>
<author>R Szekely</author>
<author>V Zielinska</author>
<author>B Young</author>
<author>R Grishman</author>
</authors>
<title>The nombank project: An interim report.</title>
<date>2004</date>
<booktitle>In HLTNAACL 2004 Workshop: Frontiers in Corpus Annotation,</booktitle>
<pages>24--31</pages>
<contexts>
<context position="13858" citStr="Meyers et al., 2004" startWordPosition="2239" endWordPosition="2242">n-literal translations. 6 Summary and Future Works We have demonstrated the potential for using parallel Propbanks to improve statistical verb translations from Chinese to English. Our B-U approach shows promise for expanding the term-coverage of GIZA++ alignments that are based on literal translations. In contrast, our T-D is most effective with non-literal translations for verifying the alignment accuracy, which has been proven difficult for GIZA++. This is still a preliminary work but in the future, we will try to enhance word-alignments by using automatically labelled Propbanks, Nombanks (Meyers et al., 2004), Named-entity tagging, and test the enhancement on bigger corpora. Furthermore, we will also evaluate the integration of our enhanced alignments with statistical machine translation systems. Acknowledgments Special thanks to Daniel Gildea, Ding Liu (University of Rochester) who provided wordalignments, Wei Wang (Information Sciences Institute at University of Southern California) who provided the test-corpus, and Hua Zhong (University of Colorado at Boulder) who performed the evaluations. We gratefully acknowledge the support of the National Science Foundation Grants IIS-0325646, Domain Indep</context>
</contexts>
<marker>Meyers, Reeves, Macleod, Szekely, Zielinska, Young, Grishman, 2004</marker>
<rawString>A. Meyers, R. Reeves, C. Macleod, R. Szekely, V. Zielinska, B. Young, and R. Grishman. 2004. The nombank project: An interim report. In HLTNAACL 2004 Workshop: Frontiers in Corpus Annotation, pages 24–31.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="1051" citStr="Och and Ney, 2003" startWordPosition="154" endWordPosition="157">the enhancement of automatically derived word alignments. Specifically, we suggest ways to refine and expand word alignments for verb-predicates by using predicate-argument structures. Evaluations demonstrate improved alignment accuracies that vary by corpus type. 1 Introduction Since verbs tend to be the roots of dependency relations in a sentence (Palmer et al., 2005), when it comes down to translations, finding correct mappings between verbs in a source and a target language is very important. Many machine translation systems (Fraser and Marcu, 2007) use wordalignment tools such as GIZA++ (Och and Ney, 2003) to retrieve word mappings between a source and a target language. Although GIZA++ gives well-structured alignments, it has limitations in several ways. First, it is hard to verify if alignments generated by GIZA++ are correct. Second, GIZA++ may not find alignments for low-frequent words. Third, GIZA++ does not account for any semantic information. In this paper, we suggest a couple of ways to enhance word-alignments for predicating expressions such as verbs1. We restricted the source and the target language to Chinese and English, respectively. The goal is to use the linguistic annotation av</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martha Palmer</author>
<author>Daniel Gildea</author>
<author>Paul Kingsbury</author>
</authors>
<title>The proposition bank: An annotated corpus of semantic roles.</title>
<date>2005</date>
<journal>Computational Linguistics,</journal>
<volume>31</volume>
<issue>1</issue>
<contexts>
<context position="805" citStr="Palmer et al., 2005" startWordPosition="111" endWordPosition="114"> Boulder Univ. of Colorado at Boulder Brandeis University choijd@colorado.edu mpalmer@colorado.edu xuen@brandeis.edu Abstract This short paper describes the use of the linguistic annotation available in parallel PropBanks (Chinese and English) for the enhancement of automatically derived word alignments. Specifically, we suggest ways to refine and expand word alignments for verb-predicates by using predicate-argument structures. Evaluations demonstrate improved alignment accuracies that vary by corpus type. 1 Introduction Since verbs tend to be the roots of dependency relations in a sentence (Palmer et al., 2005), when it comes down to translations, finding correct mappings between verbs in a source and a target language is very important. Many machine translation systems (Fraser and Marcu, 2007) use wordalignment tools such as GIZA++ (Och and Ney, 2003) to retrieve word mappings between a source and a target language. Although GIZA++ gives well-structured alignments, it has limitations in several ways. First, it is hard to verify if alignments generated by GIZA++ are correct. Second, GIZA++ may not find alignments for low-frequent words. Third, GIZA++ does not account for any semantic information. In</context>
</contexts>
<marker>Palmer, Gildea, Kingsbury, 2005</marker>
<rawString>Martha Palmer, Daniel Gildea, and Paul Kingsbury. 2005. The proposition bank: An annotated corpus of semantic roles. Computational Linguistics, 31(1):71–106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
<author>Martha Palmer</author>
</authors>
<title>Adding semantic roles to the chinese treebank.</title>
<date>2009</date>
<journal>Natural Language Engineering,</journal>
<volume>15</volume>
<issue>1</issue>
<contexts>
<context position="1703" citStr="Xue and Palmer, 2009" startWordPosition="256" endWordPosition="259">een a source and a target language. Although GIZA++ gives well-structured alignments, it has limitations in several ways. First, it is hard to verify if alignments generated by GIZA++ are correct. Second, GIZA++ may not find alignments for low-frequent words. Third, GIZA++ does not account for any semantic information. In this paper, we suggest a couple of ways to enhance word-alignments for predicating expressions such as verbs1. We restricted the source and the target language to Chinese and English, respectively. The goal is to use the linguistic annotation available in parallel PropBanks (Xue and Palmer, 2009) to refine and expand automatic word-alignments. First, we check if the alignment for each Chinese predicate, generated by GIZA++, is also a predicate in English (Section 3). If it is, we verify if the alignment is correct by matching 1Throughout the paper, all predicates refer to verbs. their arguments (Section 4.1). If it is not, we find an English predicate that has the maximum argument matching with the Chinese predicate (Section 4.2). Finally, we evaluate the potential of the enhanced word-alignments for providing a significant improvement over the GIZA++ baseline. 2 Parallel Corpus We us</context>
</contexts>
<marker>Xue, Palmer, 2009</marker>
<rawString>Nianwen Xue and Martha Palmer. 2009. Adding semantic roles to the chinese treebank. Natural Language Engineering, 15(1):143–172.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>