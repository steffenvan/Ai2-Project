<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001786">
<title confidence="0.9988285">
The Automatic Generation of Formal Annotations in a Multimedia
Indexing and Searching Environment
</title>
<author confidence="0.945404">
Thierry Declerck
</author>
<affiliation confidence="0.828617">
DFKI GmbH
</affiliation>
<address confidence="0.867884333333333">
Stuhlsatzenhausweg 3
D-66123 Saarbruecken
Germany
</address>
<email confidence="0.992725">
declerck@dfki.de
</email>
<author confidence="0.85224">
Peter Wittenburg
</author>
<affiliation confidence="0.781751">
MPI for Psycholinguistics
</affiliation>
<address confidence="0.919692666666667">
Wundtlaan 1, PB 310
NL-6500 AH Nijmegen
The Netherlands
</address>
<email confidence="0.982196">
Peter.Wittenburg@mpi.nl
</email>
<author confidence="0.81757">
Hamish Cunningham
</author>
<affiliation confidence="0.994172">
Dept. of Computer Science
University of Sheffield
</affiliation>
<address confidence="0.962460333333333">
Regent Court, 211 Portobello
GB-Sheffield S1 4DP
Great Britain
</address>
<email confidence="0.999375">
hamish@dcs.shef.ac.uk
</email>
<sectionHeader confidence="0.995644" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999954294117647">
We describe in this paper the MU-
MIS Project (Multimedia Indexing and
Searching Environment)1, which is
concerned with the development and in-
tegration of base technologies, demon-
strated within a laboratory prototype, to
support automated multimedia index-
ing and to facilitate search and retrieval
from multimedia databases. We stress
the role linguistically motivated annota-
tions, coupled with domain-specific in-
formation, can play within this environ-
ment. The project will demonstrate that
innovative technology components can
operate on multilingual, multisource,
and multimedia information and create
a meaningful and queryable database.
</bodyText>
<sectionHeader confidence="0.999132" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999258818181818">
MUMIS develops and integrates basic technolo-
gies, which will be demonstrated within a labora-
tory prototype, for the automatic indexing of mul-
timedia programme material. Various technology
components operating offline will generate for-
mal annotations of events in the data material pro-
cessed. These formal annotations will form the
basis for the integral online part of the MUMIS
project, consisting of a user interface allowing the
querying of videos. The indexing of the video ma-
terial with relevant events will be done along the
</bodyText>
<footnote confidence="0.999417">
1MUMIS is an on-going EU-funded project within the
Information Society Program (IST) of the European Union,
section Human Language Technology (HLT). See for more
information http://parlevink.cs.utwente.nl/projects/mumis/.
</footnote>
<bodyText confidence="0.958015690476191">
line of time codes extracted from the various doc-
uments.
For this purpose the project makes use of data
from different media sources (textual documents,
radio and television broadcasts) in different lan-
guages (Dutch, English and German) to build a
specialized set of lexicons and an ontology for
the selected domain (soccer). It also digitizes
non-text data and applies speech recognition tech-
niques to extract text for the purpose of annota-
tion.
The core linguistic processing for the anno-
tation of the multimedia material consists of
advanced information extraction techniques for
identifying, collecting and normalizing signifi-
cant text elements (such as the names of players
in a team, goals scored, time points or sequences
etc.) which are critical for the appropriate anno-
tation of the multimedia material in the case of
soccer.
Due to the fact that the project is accessing and
processing distinct media in distinct languages,
there is a need for a novel type of merging tool in
order to combine the semantically related annota-
tions generated from those different data sources,
and to detect inconsistencies and/or redundancies
within the combined annotations. The merged an-
notations will be stored in a database, where they
will be combined with relevant metadata.2
Finally the project will develop a user interface
to enable professional users to query the database,
by selecting from menus based on structured an-
2We see in this process of merging extracted informa-
tions and their combination with metadata a fruitful base for
the identification and classification of content or knowledge
from distinct types of documents.
notations and metadata, and to view video frag-
ments retrieved to satisfy the query, offering thus
a tool to formulate queries about multimedia pro-
grammes and directly get interactive access to the
multimedia contents. This tool constitutes the on-
line component of the MUMIS environment.
</bodyText>
<sectionHeader confidence="0.320441" genericHeader="method">
2 State of the Art
</sectionHeader>
<bodyText confidence="0.999554947368421">
MUMIS differs in many significant ways from ex-
isting technologies and already achieved or ad-
vanced projects3. Most closely related to the the-
matic focus of MUMIS are the HLT projects Pop-
Eye [POP] and OLIVE [OLI]. Pop-Eye used sub-
titles to index video streams and offered time-
stamped texts to satisfy a user query, on request
displaying a storyboard or video fragment corre-
sponding to the text hit. OLIVE used automatic
speech recognition to generate transcriptions of
the sound tracks of news reports, which were then
indexed and used in ways similar to the Pop-Eye
project; both projects used fuzzy matching IR al-
gorithms to search and retrieve text, offering lim-
ited multilingual access to texts. Instead of using
IR methods to index and search the transcriptions,
MUMIS will create formal annotations to the in-
formation, and will fuse information annotations
from different media sources. The fusion result
is then used to direct retrieval, through interface
techniques such as pop-up menus, keyword lists,
and so on. Search takes the user direct to the sto-
ryboard and video clippings.
The Informedia project at Carnegie-Mellon-
University [INF] has a similar conceptual base-
line to MUMIS. The innovative contribution of
MUMIS is that it uses a variety of multilingual
information sources and fuses them on the ba-
sis of formal domain-specific annotations. Where
Informedia primarily focuses on special applica-
tions, MUMIS aims at the advancement and in-
tegratibility of HLT-enhanced modules to enable
information filtering beyond the textual domain.
Therefore, MUMIS can be seen as complemen-
tary to Informedia with extensions typical for Eu-
rope.
The THISL project [THI] is about spoken doc-
ument retrieval, i.e., automatic speech recognition
</bodyText>
<footnote confidence="0.994198333333333">
3We are aware of more related on-going projects, at least
within the IST program, but we can not compare those to
MUMIS now, since we still lack first reports.
</footnote>
<bodyText confidence="0.99975372972973">
is used to auto-transcribe news reports and then
information retrieval is carried out on this infor-
mation. One main focus of THISL is to improve
speech recognition. Compared to MUMIS it lacks
the strong language processing aspects, the fusion
of multilingual sources, and the multimedia deliv-
ery.
Columbia university is running a project [COL]
to use textual annotations of video streams to in-
dicate moments of interest, in order to limit the
scope of the video processing task which requires
extreme CPU capacities. So the focus is on find-
ing strategies to limit video processing. The Uni-
versity of Massachusetts (Amherst) is also run-
ning projects about video indexing [UMA], but
these focus on the combination of text and im-
ages. Associated text is used to facilitate indexing
of video content. Both projects are funded under
the NSF Stimulate programme [NSF].
Much work has been done on video and im-
age processing (Virage [VIR], the EUROMEDIA
project [EUR], Surfimage [SUR], the ISIS project
[ISI], IBM&apos;s Media Miner, projects funded under
the NSF Stimulate program [NSF], and many oth-
ers). Although this technology in general is in its
infancy, there is reliable technology to indicate,
for example, scene changes using very low-level
cues and to extract key frames at those instances
to form a storyboard for easy video access. Some
institutions are running projects to detect subtitles
in the video scene and create a textual annotation.
This task is very difficult, given a sequence of real
scenes with moving backgrounds and so on. Even
more ambitious tasks such as finding real patterns
in real movies (tracing the course of the ball in a
soccer match, for example) are still far from being
achieved.4
</bodyText>
<sectionHeader confidence="0.9892145" genericHeader="method">
3 Formal Annotations for the Soccer
Domain
</sectionHeader>
<bodyText confidence="0.996593">
Soccer has been chosen as the domain to test and
apply the algorithms to be developed. There are a
number of reasons for this choice: availability of
people willing to help in analyzing user require-
ments, existence of many information sources in
</bodyText>
<footnote confidence="0.9656235">
4The URLs of the projects mentionned above are given
in the bibliography at the end of this paper.
</footnote>
<bodyText confidence="0.999928595238096">
several languages5, and great economic and pub-
lic interest. The prototype will also be tested by
TV professionals and sport journalists, who will
report on its practicability for the creation and
management of their programme and information
material.
The principles and methods derived from this
domain can be applied to other as well. This has
been shown already in the context of text-based
Information Extraction (IE), for which method-
ologies for a fast adaptation to new domains
have been developed (see the MUC conferences
and (Neumann et al., 2000)). And generally
speaking the use of IE for automatic annotation
of multimedia document has the advantage of
providing, besides the results of the (shallow)
syntactic processing, accurate semantic (or con-
tent/conceptual) information (and thus potential
annotation) for specific predefined domains, since
a mapping from the linguistically analyzed rele-
vant text parts can be mapped onto an unambigu-
ous conceptual description6. Thus in a sense it
can be assumed that IE is supporting the word
sense disambiguation task.
It is also commonly assumed (see among oth-
ers (Cunningham, 1999)) that IE occupies an in-
termediate place between Information Retrieval
(with few linguistic knowledge involved) and
Text Understanding (involving the full deep lin-
guistic analysis and being still not realized for the
time being.). IE being robust but offering only a
partial (but mostly accurate) syntactic and content
analysis, it can be said that this language technol-
ogy is actually filling the gap between available
low-level annotated/indexed documents and cor-
pora and the desirable full content annotation of
those documents and corpora. This is the reason
why MUMIS has chosen this technology for pro-
viding automatic annotation (at distinct linguistic
and domain-specific levels) of multimedia mate-
rial, allowing thus to add queryable “content in-
formation” to this material.7
</bodyText>
<footnote confidence="0.985492111111111">
5We would like to thank at this place the various institu-
tions making available various textual, audio and video data.
6This topic has already been object of a workshop dis-
cussing the relations between IE and Corpus Linguistics
(McNaught, 2000).
7MUMIS was not explicitly designed for supporting
knowledge management tasks, but we assume that the mean-
ingful organization of domain-specific multimedia material
proposed by the project can be adapted to the organization of
</footnote>
<sectionHeader confidence="0.90949" genericHeader="method">
4 The Multimedia Material in MUMIS
</sectionHeader>
<bodyText confidence="0.999619923076923">
The MUMIS project is about automatic index-
ing of videos of soccer matches with formal an-
notations and querying that information to get
immediate access to interesting video fragments.
For this purpose the project chose the European
Football Championships 2000 in Belgium and the
Netherlands as its main database. A major project
goal is to merge the formal annotations extracted
from textual and audio material (including the au-
dio part of videos) on the EURO 2000 in three
languages: English, German, Dutch. The mate-
rial MUMIS has to process can be classified in
the following way:
</bodyText>
<listItem confidence="0.999608636363637">
1. Reports from Newspapers (reports about
specific games, general reports) which is
classified as free texts (FrT)
2. Tickers, close captions, Action-Databases
which are classified as semi-formal texts
(SFT)
3. Formal descriptions about specific games
which are classified as formal texts (FoT)
4. Audio material recorded from radio and TV
broadcasts
5. Video material recorded from TV broadcasts
</listItem>
<bodyText confidence="0.9984553">
1-4 will be used for automatically generating
formal annotations in order to index 5. MUMIS
is investigating the precise contribution of each
source of information for the overall goal of the
project.
Since the information contained in formal texts
can be considered as a database of true facts, they
play an important role within MUMIS. But never-
theless they contain only few information about a
game: the goals, the substitutions and some other
few events (penalties, yellow and red cards). So
there are only few time points available for in-
dexing videos. Semi-formal texts (SFT), like live
tickers on the web, are offering much more time
points sequences, related with a higher diversity
the distributed information of an enterprise and thus support
the sharing and access to companies expertise and know-
how.
of events (goals scenes, fouls etc,) and seem to of-
fer the best textual source for our purposes. Nev-
ertheless the quality of the texts of online tick-
ers is often quite poor. Free texts, like newspa-
pers articles, have a high quality but the extrac-
tion of time points and their associated events in
text is more difficult. Those texts also offer more
background information which might be interest-
ing for the users (age of the players, the clubs they
are normally playing for, etc.). Figures 1 and 2 in
section 8 show examples of (German) formal and
semi-formal texts on one and the same game.
</bodyText>
<sectionHeader confidence="0.886076" genericHeader="method">
5 Processing Steps in MUMIS
</sectionHeader>
<subsectionHeader confidence="0.834307">
5.1 Media Pre-Processing
</subsectionHeader>
<bodyText confidence="0.999979779661017">
Media material has been delivered in various
formats (AudioDAT, AudioCassettes, Hi-8 video
cassettes, DV video cassettes etc) and qualities.
All audio signals (also those which are part of
the video recordings) are digitized and stored in
an audio archive. Audio digitization is done with
20 kHz sample frequency, the format generated is
according to the de-facto wav standard. For dig-
itization any available tool can be used such as
SoundForge.
Video information (including the audio compo-
nent) of selected games have been digitized into
MPEG1 streams first. Later it will be encoded in
MPEG2 streams. While the quality of MPEG1 is
certainly not satisfying to the end-user, its band-
width and CPU requirements are moderate for
current computer and network technology. The
mean bit rate for MPEG1 streams is about 1.5
Mbps. Current state-of-the-art computers can ren-
der MPEG1 streams in real time and many net-
work connections (Intranet and even Internet) can
support MPEG1. MPEG2 is specified for about 3
to 5 Mbps. Currently the top-end personal com-
puters can render MPEG2, but MPEG2 is not yet
supported for the most relevant player APIs such
as JavaMediaFramework or Quicktime. When
this support is given the MUMIS project will also
offer MPEG2 quality.
For all separate audio recordings as for ex-
ample from radio stations it has to be checked
whether the time base is synchronous to that one
of the corresponding video recordings. In case of
larger deviations a time base correction factor has
to be estimated and stored for later use. Given that
the annotations cannot be created with too high
accuracy a certain time base deviation will be ac-
cepted. For part of the audio signals manual tran-
scriptions have to be generated to train the speech
recognizers. These transcripts will be delivered in
XML-structured files.
Since keyframes will be needed in the user in-
terface, the MUMIS project will develop software
that easily can generate such keyframes around a
set of pre-defined time marks. Time marks will
be the result of information extraction processes,
since the corresponding formal annotations is re-
ferring to to specific moments in time. The soft-
ware to be written has to extract the set of time
marks from the XML-structured formal annota-
tion file and extract a set of keyframes from the
MPEG streams around those time marks. A set of
keyframes will be extracted around the indicated
moments in time, since the estimated times will
not be exact and since the video scenes at such
decisive moments are changing rapidly. There
is a chance to miss the interesting scene by us-
ing keyframes and just see for example specta-
tors. Taking a number of keyframes increases the
chance to grab meaningful frames.
</bodyText>
<subsectionHeader confidence="0.8154135">
5.2 Multilingual Automatic Speech
Recognition
</subsectionHeader>
<bodyText confidence="0.999966344827586">
Domain specific language models will be trained.
The training can be bootstrapped from written re-
ports of soccer matches, but substantial amounts
of transcribed recordings of commentaries on
matches are also required. Novel techniques
will be developed to interpolate the base-line lan-
guage models of the Automatic Speech Recogni-
tion (ASR) systems and the domain specific mod-
els. Moreover, techniques must be developed to
adapt the vocabularies and the language models
to reflect the specific conditions of a match (e.g.,
the names players have to be added to the vocabu-
lary, with the proper bias in the language model).
In addition, the acoustic models must be adapted
to cope with the background noise present in most
recordings.
Automatic speech recognition of the sound
tracks of television and (especially) radio pro-
grammes will make use of closed caption subtitle
texts and information extracted from formal texts
to help in finding interesting sequences and auto-
matically transcribing them. Further, the domain
lexicons will help with keyword and topic spot-
ting. Around such text islands ASR will be used
to transcribe the spoken soundtrack. The ASR
system will then be enriched with lexica contain-
ing more keywords, to increase the number of se-
quence types that can be identified and automati-
cally transcribed.
</bodyText>
<subsectionHeader confidence="0.994574">
5.3 Multilingual Domain Lexicon Building
</subsectionHeader>
<bodyText confidence="0.999947545454546">
All the collected textual data for the soccer do-
main are used for building the multilingual do-
main lexicons. This data can be in XML, HTML,
plain text format, etc. A number of automatic
processes are used for the lexicon building, first
on a monolingual and secondly on a multilin-
gual level. Manual browsing and editing is tak-
ing place, mainly in order to provide the semantic
links to the terms, but also for the fine-tuning of
the lexicon according to the domain knowledge.
Domain lexicons are built for four lan-
guages, namely English, German, Dutch and
Swedish. The lexicons will be delivered in a
fully structured, XML-compliant, TMX-format
(Translation Memory eXchange format). For
more information about the TMX format see
http://www.lisa.org/tmx/tmx.htm.
We will also investigate how far
EUROWORDNET resources (see
http://www.hum.uva.nl/ ewn/) can be of use
for the organization of the domain-specific
terminology.
</bodyText>
<subsectionHeader confidence="0.905055">
5.4 Building of Domain Ontology and Event
Table
</subsectionHeader>
<bodyText confidence="0.943063076923077">
The project is currently building an ontology for
the soccer domain, taking into consideration the
requirements of the information extraction and
merging components, as well as users require-
ments. The ontology will be delivered in an XML
format&apos;.
&apos;There are still on-going discussions within the
project consortium wrt the best possible encoding for-
mat for the domain ontology, the alternative being
reduced probably to RDFS, OIL and IFF, see respec-
tively, and among others, http://www.w3.org/TR/rdf-
schema/, http://www.oasis-open.org/cover/oil.html and
http://www.ontologos.org/IFF/The%20IFF%20Language.
html
In parallel to building the ontology an event ta-
ble is being described. It contains the major event
types that can occur in soccer games and their
attributes. This content of the table is matching
with the content of the ontology. The event ta-
ble is a flat structure and guides the information
extraction processes to generate the formal event
annotations. The formal event annotations build
the basis for answering user queries. The event
table is specified as an XML schema to constrain
the possibilities of annotation to what has been
agreed within the project consortium.
</bodyText>
<subsectionHeader confidence="0.991242">
5.5 Generation of Formal Annotations
</subsectionHeader>
<bodyText confidence="0.999992787878788">
The formal annotations are generated by the IE
technology and are reflecting the typical output of
IE systems, i.e.instantiated domain-specific tem-
plates or event tables. The slots to be filled by
the systems are basically entities (player, teams
etc.), relations (player of, opponents etc.) and
events (goal, substitution etc.), which are all de-
rived from the current version of the domain on-
tology and can be queried for in the online com-
ponent of the MUMIS prototype. All the tem-
plates associated with an event are including a
time slot to be filled if the corresponding informa-
tion is available in a least one of the sources con-
sulted during the IE procedure. This time infor-
mation is necessary for the indexing of the video
material.
The IE systems are applying to distinct sources
(FoT, FrT etc.) but they are not concerned with
achieving consistency in the IE result on distinct
sources about the same event (game): this is the
task of the merging tools, described below.
Since the distinct textual sources are differ-
ently structured, from “formal” to “free” texts, the
IE systems involved have adopted a modular ap-
proach: regular expressions for the detection of
Named Entities in the case of formal texts, full
shallow parsing for the free texts. On the base of
the factual information extracted from the formal
texts, the IE systems are also building dynamic
databases on certain entities (like name and age
of the players, the clubs they are normally playing
for, etc.) or certain metadata (final score), which
can be used at the next level of processing.
</bodyText>
<subsectionHeader confidence="0.971688">
5.6 The Merging Tool
</subsectionHeader>
<bodyText confidence="0.99999515">
The distinct formal annotations generated are
passed to a merging component, which is respon-
sible for avoiding both inconsistencies and redun-
dancies in the annotations generated on one event
(in our case a soccer game).
In a sense one can consider this merging
component as an extension of the so-called co-
reference task of IE systems to a cross-document
(and cross-lingual) reference resolution task. The
database generated during the IE process will help
here for operating reference resolution for more
“verbose” types of texts, which in the context
of soccer are quite “poetic” with respect to the
naming of agents (the “Kaiser” for Beckenbauer,
the “Bomber” for Mueller etc...), which would
be quite difficult to achieve within the sole refer-
ential information available within the boundary
of one document. The project will also investi-
gate here the use of inferential mechanisms for
supporting reference resolution. So for example,
“knowing” from the formal texts the final score
of a game and the names of the scorers, follow-
ing formulation can be resolved form this kind
of formulation in a free text (in any language):
“With his decisive goal, the “Bomber” gave the
victory to his team.”, whereas the special nam-
ing “Bomber” can be further added to the entry
“Mueller”
The merging tools used in MUMIS will also
take into consideration some general representa-
tion of the domain-knowledge in order to filter out
some annotations generated in the former phases.
The use of general representations9 (like domain
frames), combined with inference mechanisms,
might also support a better sequential organiza-
tion of some event templates in larger scenarios.
It will also allow to induce some events which
are not explicitly mentioned in the sources under
consideration (or which the IE systems might not
have detected).
</bodyText>
<subsectionHeader confidence="0.984533">
5.7 User Interface Building
</subsectionHeader>
<bodyText confidence="0.975441">
The user first will interact with a web-portal to
start a MUMIS query session. An applet will be
</bodyText>
<footnote confidence="0.83143825">
9Like for example the Type Description Language
(TDL), a formalism supporting all kind of operations on
(typed) features as well as multiple inheritance, see (Krieger
and Schaefer, 1994).
</footnote>
<bodyText confidence="0.999837">
down-line loaded in case of showing the MUMIS
demonstration. This applet mainly offers a query
interface. The user then will enter a query that
either refers to metadata, formal annotations, or
both. The MUMIS on-line system will search
for all formal annotations that meet the criteria
of the query. In doing so it will find the appro-
priate meta-information and/or moments in some
media recording. In case of meta-information it
will simply offer the information in scrollable text
widgets. This will be done in a structured way
such that different type of information can eas-
ily be detected by the user. In case that scenes of
games are the result of queries about formal anno-
tations the user interface will first present selected
video keyframes as thumbnails with a direct indi-
cation of the corresponding metadata.
The user can then ask for more metadata
about the corresponding game or for more media
data. It has still to be decided within the project
whether several layers of media data zooming in
and out are useful to satisfy the user or whether
the step directly to the corresponding video frag-
ment is offered. All can be invoked by simple
user interactions such as clicking on the presented
screen object. Playing the media means playing
the video and corresponding audio fragment in
streaming mode requested from a media server.
</bodyText>
<sectionHeader confidence="0.995938" genericHeader="method">
6 Standards for Multimedia Content
</sectionHeader>
<bodyText confidence="0.999877666666667">
MUMIS is looking for a compliance with exist-
ing standards in the context of the processing of
multimedia content on the computer and so will
adhere to emerging standards such as MPEG4,
which defines how different media objects will be
decoded and integrated at the receiving station,
and MPEG7, which is about defining standards
for annotations which can be seen as multime-
dia objects. Further, MUMIS will also maintain
awareness of international discussions and devel-
opments in the aerea of multimedia streaming
(RTP, RTSP, JMF...), and will follow the discus-
sions within the W3C consortium and the EBU
which are also about standardizing descriptions of
media content.
</bodyText>
<subsectionHeader confidence="0.632812">
7 Role of MUMIS for the Annotation of
Multimedia Content
</subsectionHeader>
<bodyText confidence="0.999734604651163">
To conclude, we would like to list the points
where we think MUMIS will, directly or indi-
rectly, contribute to extract and access multimedia
content:
uses multimedia (MM) and multilingual in-
formation sources;
carries out multimedia indexing by applying
information extraction to a well-delineated
domain and using already existing informa-
tion as constraints;
uses and extends advanced language tech-
nology to automatically create formal anno-
tations for MM content;
merges information from many sources
to improve the quality of the annotation
database;
application of IE to the output of ASR and
the combination of this with already existing
knowledge;
definition of a complex information annota-
tion structure, which is stored in a standard
document type definition (DTD);
integration of new methods into a query in-
terface which is guided by domain knowl-
edge (ontology and multilingual lexica).
So in a sense MUMIS is contributing in defin-
ing semantic structures of multimedia contents,
at the level proposed by domain-specific IE anal-
ysis. The full machinery of IE, combined with
ASR (and in the future with Image Analysis)
can be used for multimedia contents development
and so efficiently support cross-media (and cross-
lingual) information retrieval and effective navi-
gation within multimedia information interfaces.
There seems thus that this technolgy can play a
highly relevant role for the purposes of knowl-
edge detection and management. This is prob-
ably specially valid for the merging component,
which is eliminating redundancies in the annota-
tions generated from sets of documents and estab-
lishing complex reference resolutions, thus sim-
plyfying the access to content (and knowledge)
distributed over multiple documents and media.
</bodyText>
<sectionHeader confidence="0.990135" genericHeader="conclusions">
References
</sectionHeader>
<reference confidence="0.994834061728395">
Doug E. Appelt. 1999. An introduction to information
extraction. AI Communications, 12.
Steven Bird and Mark Liberman. 2001. A formal
framework for linguistic annotation. Speech Com-
munication.
K. Bontcheva, H. Brugman, A. Russel, P. Wittenburg,
and H. Cunningham. 2000. An Experiment in
Unifying Audio-Visual and Textual Infrastructures
for Language Processing R&amp;D. In Proceedings of
the Workshop on Using Toolsets and Architectures
To Build NLP Systems at COLING-2000, Luxem-
bourg. http://gate.ac.uk/.
Daan Broeder, Hamish Cunningham, Nancy Ide,
David Roy, Henry Thompson, and Peter Witten-
burg, editors. 2000. Meta-Descriptions and An-
notation Schemes for Multimodal/Multimedia Lan-
gauge Resources LREC-2000.
H. Brugman, K. Bontcheva, P. Wittenburg, and
H. Cunningham. 1999. Integrating Multimedia and
Textual Software Architectures for Language Tech-
nology. Technical report mpi-tg-99-1, Max-Planck
Institute for Psycholinguistics, Nijmegen, Nethed-
lands.
Hamish Cunningham. 1999. An introduction to infor-
mation extraction. Research memo CS - 99 - 07.
Thierry Declerck and G. Neumann. 2000. Using a pa-
rameterisable and domain-adaptive information ex-
traction system for annotating large-scale corpora?
In Proceedings of the Workshop Information Ex-
traction meets Corpus Linguistics, LREC-2000.
Kevin Humphreys, R. Gaizauskas, S. Azzam,
C. Huyck, B. Mitchell, H. Cunningham, and
Y. Wilks. 1998. University of sheffield:
Description of the lasie-ii system as used for
muc-7. In SAIC, editor, Proceedings of the
7th Message Understanding Conference, MUC-7,
http://www.muc.saic.com/. SAIC Information Ex-
traction.
Christopher Kennedy and B. Boguraev. 1996.
Anaphora for everyone: Pronominal anaphora res-
olution without a parser. In Proceedings of the
16th International Conference on Computational
Linguistics, COLING-96, pages 113–118, Copen-
hagen.
Hans-Ulrich Krieger and U. Schaefer. 1994.
a type description language for constraint-based
grammars. In Proceedings of the 15th Interna-
tional Conference on Computational Linguistics,
COLING-94, pages 893–899.
Shalom Lappin and H-H. Shih. 1996. A generalized
algorithm for ellipsis resolution. In Proceedings
of the 16th International Conference on Compu-
tational Linguistics, COLING-96, pages 687–692,
Copenhagen.
John McNaught, editor. 2000. Information Extraction
meets Corpus Linguistics, LREC-2000.
Ruslan Mitkov. 1998. Robust pronoun resolution with
limited knowledge. In Proceedings of the 17th In-
ternational Conference on Computational Linguis-
tics, COLING-98, pages 869–875, Montreal.
MUC, editor. 1995. Sixth Message Understanding
Conference (MUC-6). Morgan Kaufmann.
MUC, editor. 1998. Seventh Message Understanding
Conference (MUC-7), http://www.muc.saic.com/.
SAIC Information Extraction.
Guenter Neumann, R. Backofen, J. Baur, M. Becker,
and C. Braun. 1997. An information extrac-
tion core system for real world german text pro-
cessing. In Proceedings of the 5th Conference on
Applied Natural Language Processing, ANLP-97,
pages 209–216.
Guenter Neumann, C. Braun, and J. Piskorski. 2000.
A divide-and-conquer strategy for shallow parsing
of german free texts. In Proceedings of the 6th Con-
ference on Applied Natural Language Processing,
ANLP-00.
Jakub Piskorski and G. Neumann. 2000. An intel-
ligent text extraction and navigation system. In
Proceedings of the 6th Conference on Recherche
d&apos;Information Assist´ee par Ordinateur, RIAO-2000.
Project URLs:
</reference>
<footnote confidence="0.936593">
node1.html
THI: http://www.dcs.shef.ac.uk/research/
groups/spandh/projects/thisl
UMA: http://ciir.cs.umass.edu/research/
UNL: http://www.ias.unu.edu/research_prog/
science_technology/
universalnetwork_language.html
VIR: http://www.virage.com/
</footnote>
<sectionHeader confidence="0.968651" genericHeader="references">
8 Annex
</sectionHeader>
<reference confidence="0.995312125">
England - Deutschland 1:0 (0:0)
England: Seaman (2,5) - G. Neville (3,5), Keown (3), Camp-
bell (2), P. Neville (4,5) - Ince (3,5), Wise (5) - Beckham (4),
Scholes (3) - Shearer (3), Owen (5) - Trainer: Keegan
Deutschland: Kahn (2) - Matthaeus (3) - Babbel (3,5),
Nowotny (2,5) - Deisler (3), Hamann (2,5), Jeremies (3,5),
Ziege (3,5) - Scholl (5) - Jancker (4), Kirsten (5) - Trainer:
Ribbeck
Eingewechselt: 61. Gerrard fuer Owen, 72. Barmby fuer
Scholes - 70. Rink fuer Kirsten, 72. Ballack fuer Deisler,
78. Bode fuer Jeremies
Tore: 1:0 Shearer (53., Kopfball, Vorarbeit Beckham)
Schiedsrichter: Collina, Pierluigi (Viareggio), Note 2 - bis
auf eine falsche Abseits-Entscheidung souveraen und sicher
Zuschauer: 30000 (ausverkauft)
Gelbe Karten: Beckham - Babbel, Jeremies
</reference>
<figureCaption confidence="0.941515">
Figure 1: Example of a so-called formal text,
where one can see that only 5 distinct time points
can be extracted, concerning the player subsitu-
tions (“Eingewechselt”) and one goal (“Tore”).
</figureCaption>
<reference confidence="0.99813796969697">
Gruppe A: England - Deutschland 1:0 (0:0)
7. Ein Freistoss von Christian Ziege aus 25 Metern geht ue-
ber das Tor.
12. Ziege flankt per Freistoss in den Strafraum und Jeremies
versucht es per Kofball, verfehlt den Kasten jedoch deutlich.
16. Scholes flankt gefaehrlich von der Torauslinie in
den Fuenfmeterraum, doch Ziege hat aufgepasst und kann
klaeren.
18. Hamann versucht es mit einem Distanzschuss aus 20
Metern, aber Seaman ist auf dem Posten.
23. Scholl mit einer Riesenchance: Nach Zuspiel von
Hamann rennt er in den englischen Strafraum, wird jedoch
gleich von drei Seiten bedraengt und kommt nur zu einem
unplazierten Schuss, den Seaman sicher abfangen kann.
27. Jancker spielt auf Ziege, dessen Schuss von der
Strafraumgrenze kann von Seaman abgefangen werden.
35. Michael Owen kommt nach Flanke von Philip Neville
voellig frei vor dem deutschen Tor zum Kopfball, doch Kahn
kann zum ersten Mal sein Koennen unter Beweis stellen und
rettet auf der Linie.
43. Kahn zum zweiten: Beckham flankt auf Scholes, der
zieht ab in den rechten Winkel, aber der deutsche Keeper
verhindert erneut die englische Fuehrung.
47. Christian Zieges Freistoss aus 20 Metern geht einen hal-
ben Meter ueber das Tor.
53. Beckham flankt per Freistoss an der deutschen Abwehr
vorbei auf den Kopf von Alan Shearer, der voellig freiste-
hend zum 1:0 fuer die Englaender verwandelt.
58. Scholl wird von Matthaeus bedient, aber sein Schuss
geht aus halbrechter Position um Zentimeter am Tor vorbei.
65. Seaman kann nach einem Eckball vor Kirsten klaeren,
der Nachschuss von Jancker geht knapp am Tor vorbei.
Riesenmoeglichkeit fuer die DFB-Elf.
</reference>
<figureCaption confidence="0.824185333333333">
Figure 2: Example of a so-called semi-formal
text, where one can see that here more time points
are available, and that those can be complemen-
tary to the time points to be extracted from formal
texts. So, already at this level, a unification or
merging of extracted time points is necessary.
</figureCaption>
<figure confidence="0.995732533333333">
sumDemo
EUR: http://www.foyer.de/euromedia/
GDA: http://www.csl.sony.co.jp/person/
nagao/gda/
INF: http://www.informedia.cs.cmu.edu/
ISI: http://www.wins.uva.nl/research/
isis/isisNS.html
ISLE: http://www.ilc.pi.cnr.it/EAGLES/
ISLE_Home_Page.htm
NSF: http://www.nsf.gov./od/lpa/news/press/
pr9714.htm
OLI: http://twentyone.tpd.tno.nl/olive
POP: http://twentyone.tpd.tno.nl/popeye
SUR:
COL:
</figure>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.040438">
<title confidence="0.99848">The Automatic Generation of Formal Annotations in a Indexing and Searching Environment</title>
<author confidence="0.779851">Thierry</author>
<affiliation confidence="0.66749">DFKI Stuhlsatzenhausweg</affiliation>
<address confidence="0.817224">D-66123</address>
<email confidence="0.982723">declerck@dfki.de</email>
<author confidence="0.950182">Peter</author>
<affiliation confidence="0.909723">MPI for</affiliation>
<address confidence="0.6438715">Wundtlaan 1, PB NL-6500 AH</address>
<title confidence="0.842023">The Peter.Wittenburg@mpi.nl</title>
<author confidence="0.897739">Hamish</author>
<affiliation confidence="0.995815">Dept. of Computer University of</affiliation>
<address confidence="0.5562725">Regent Court, 211 GB-Sheffield S1</address>
<author confidence="0.956577">Great Britain</author>
<email confidence="0.993427">hamish@dcs.shef.ac.uk</email>
<abstract confidence="0.999247555555556">We describe in this paper the MU- MIS Project (Multimedia Indexing and which is concerned with the development and integration of base technologies, demonstrated within a laboratory prototype, to support automated multimedia indexing and to facilitate search and retrieval from multimedia databases. We stress the role linguistically motivated annotations, coupled with domain-specific information, can play within this environment. The project will demonstrate that innovative technology components can operate on multilingual, multisource, and multimedia information and create a meaningful and queryable database.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Doug E Appelt</author>
</authors>
<title>An introduction to information extraction.</title>
<date>1999</date>
<journal>AI Communications,</journal>
<volume>12</volume>
<marker>Appelt, 1999</marker>
<rawString>Doug E. Appelt. 1999. An introduction to information extraction. AI Communications, 12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steven Bird</author>
<author>Mark Liberman</author>
</authors>
<title>A formal framework for linguistic annotation. Speech Communication.</title>
<date>2001</date>
<marker>Bird, Liberman, 2001</marker>
<rawString>Steven Bird and Mark Liberman. 2001. A formal framework for linguistic annotation. Speech Communication.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Bontcheva</author>
<author>H Brugman</author>
<author>A Russel</author>
<author>P Wittenburg</author>
<author>H Cunningham</author>
</authors>
<title>An Experiment in Unifying Audio-Visual and Textual Infrastructures for Language Processing R&amp;D.</title>
<date>2000</date>
<booktitle>In Proceedings of the Workshop on Using Toolsets and Architectures To Build NLP Systems at COLING-2000,</booktitle>
<location>Luxembourg. http://gate.ac.uk/.</location>
<marker>Bontcheva, Brugman, Russel, Wittenburg, Cunningham, 2000</marker>
<rawString>K. Bontcheva, H. Brugman, A. Russel, P. Wittenburg, and H. Cunningham. 2000. An Experiment in Unifying Audio-Visual and Textual Infrastructures for Language Processing R&amp;D. In Proceedings of the Workshop on Using Toolsets and Architectures To Build NLP Systems at COLING-2000, Luxembourg. http://gate.ac.uk/.</rawString>
</citation>
<citation valid="true">
<date>2000</date>
<booktitle>Meta-Descriptions and Annotation Schemes for Multimodal/Multimedia Langauge Resources LREC-2000.</booktitle>
<editor>Daan Broeder, Hamish Cunningham, Nancy Ide, David Roy, Henry Thompson, and Peter Wittenburg, editors.</editor>
<marker>2000</marker>
<rawString>Daan Broeder, Hamish Cunningham, Nancy Ide, David Roy, Henry Thompson, and Peter Wittenburg, editors. 2000. Meta-Descriptions and Annotation Schemes for Multimodal/Multimedia Langauge Resources LREC-2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Brugman</author>
<author>K Bontcheva</author>
<author>P Wittenburg</author>
<author>H Cunningham</author>
</authors>
<title>Integrating Multimedia and Textual Software Architectures for Language Technology.</title>
<date>1999</date>
<tech>Technical report mpi-tg-99-1,</tech>
<institution>Max-Planck Institute for Psycholinguistics,</institution>
<location>Nijmegen, Nethedlands.</location>
<marker>Brugman, Bontcheva, Wittenburg, Cunningham, 1999</marker>
<rawString>H. Brugman, K. Bontcheva, P. Wittenburg, and H. Cunningham. 1999. Integrating Multimedia and Textual Software Architectures for Language Technology. Technical report mpi-tg-99-1, Max-Planck Institute for Psycholinguistics, Nijmegen, Nethedlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hamish Cunningham</author>
</authors>
<title>An introduction to information extraction.</title>
<date>1999</date>
<journal>Research memo CS - 99 -</journal>
<volume>07</volume>
<contexts>
<context position="8960" citStr="Cunningham, 1999" startWordPosition="1397" endWordPosition="1398">ferences and (Neumann et al., 2000)). And generally speaking the use of IE for automatic annotation of multimedia document has the advantage of providing, besides the results of the (shallow) syntactic processing, accurate semantic (or content/conceptual) information (and thus potential annotation) for specific predefined domains, since a mapping from the linguistically analyzed relevant text parts can be mapped onto an unambiguous conceptual description6. Thus in a sense it can be assumed that IE is supporting the word sense disambiguation task. It is also commonly assumed (see among others (Cunningham, 1999)) that IE occupies an intermediate place between Information Retrieval (with few linguistic knowledge involved) and Text Understanding (involving the full deep linguistic analysis and being still not realized for the time being.). IE being robust but offering only a partial (but mostly accurate) syntactic and content analysis, it can be said that this language technology is actually filling the gap between available low-level annotated/indexed documents and corpora and the desirable full content annotation of those documents and corpora. This is the reason why MUMIS has chosen this technology </context>
</contexts>
<marker>Cunningham, 1999</marker>
<rawString>Hamish Cunningham. 1999. An introduction to information extraction. Research memo CS - 99 - 07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thierry Declerck</author>
<author>G Neumann</author>
</authors>
<title>Using a parameterisable and domain-adaptive information extraction system for annotating large-scale corpora?</title>
<date>2000</date>
<booktitle>In Proceedings of the Workshop Information Extraction meets Corpus Linguistics, LREC-2000.</booktitle>
<marker>Declerck, Neumann, 2000</marker>
<rawString>Thierry Declerck and G. Neumann. 2000. Using a parameterisable and domain-adaptive information extraction system for annotating large-scale corpora? In Proceedings of the Workshop Information Extraction meets Corpus Linguistics, LREC-2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Humphreys</author>
<author>R Gaizauskas</author>
<author>S Azzam</author>
<author>C Huyck</author>
<author>B Mitchell</author>
<author>H Cunningham</author>
<author>Y Wilks</author>
</authors>
<title>University of sheffield: Description of the lasie-ii system as used for muc-7.</title>
<date>1998</date>
<booktitle>Proceedings of the 7th Message Understanding Conference, MUC-7, http://www.muc.saic.com/. SAIC Information Extraction.</booktitle>
<editor>In SAIC, editor,</editor>
<marker>Humphreys, Gaizauskas, Azzam, Huyck, Mitchell, Cunningham, Wilks, 1998</marker>
<rawString>Kevin Humphreys, R. Gaizauskas, S. Azzam, C. Huyck, B. Mitchell, H. Cunningham, and Y. Wilks. 1998. University of sheffield: Description of the lasie-ii system as used for muc-7. In SAIC, editor, Proceedings of the 7th Message Understanding Conference, MUC-7, http://www.muc.saic.com/. SAIC Information Extraction.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher Kennedy</author>
<author>B Boguraev</author>
</authors>
<title>Anaphora for everyone: Pronominal anaphora resolution without a parser.</title>
<date>1996</date>
<booktitle>In Proceedings of the 16th International Conference on Computational Linguistics, COLING-96,</booktitle>
<pages>113--118</pages>
<location>Copenhagen.</location>
<marker>Kennedy, Boguraev, 1996</marker>
<rawString>Christopher Kennedy and B. Boguraev. 1996. Anaphora for everyone: Pronominal anaphora resolution without a parser. In Proceedings of the 16th International Conference on Computational Linguistics, COLING-96, pages 113–118, Copenhagen.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hans-Ulrich Krieger</author>
<author>U Schaefer</author>
</authors>
<title>a type description language for constraint-based grammars.</title>
<date>1994</date>
<booktitle>In Proceedings of the 15th International Conference on Computational Linguistics, COLING-94,</booktitle>
<pages>893--899</pages>
<contexts>
<context position="22720" citStr="Krieger and Schaefer, 1994" startWordPosition="3610" endWordPosition="3613">like domain frames), combined with inference mechanisms, might also support a better sequential organization of some event templates in larger scenarios. It will also allow to induce some events which are not explicitly mentioned in the sources under consideration (or which the IE systems might not have detected). 5.7 User Interface Building The user first will interact with a web-portal to start a MUMIS query session. An applet will be 9Like for example the Type Description Language (TDL), a formalism supporting all kind of operations on (typed) features as well as multiple inheritance, see (Krieger and Schaefer, 1994). down-line loaded in case of showing the MUMIS demonstration. This applet mainly offers a query interface. The user then will enter a query that either refers to metadata, formal annotations, or both. The MUMIS on-line system will search for all formal annotations that meet the criteria of the query. In doing so it will find the appropriate meta-information and/or moments in some media recording. In case of meta-information it will simply offer the information in scrollable text widgets. This will be done in a structured way such that different type of information can easily be detected by th</context>
</contexts>
<marker>Krieger, Schaefer, 1994</marker>
<rawString>Hans-Ulrich Krieger and U. Schaefer. 1994. a type description language for constraint-based grammars. In Proceedings of the 15th International Conference on Computational Linguistics, COLING-94, pages 893–899.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shalom Lappin</author>
<author>H-H Shih</author>
</authors>
<title>A generalized algorithm for ellipsis resolution.</title>
<date>1996</date>
<booktitle>In Proceedings of the 16th International Conference on Computational Linguistics, COLING-96,</booktitle>
<pages>687--692</pages>
<location>Copenhagen.</location>
<marker>Lappin, Shih, 1996</marker>
<rawString>Shalom Lappin and H-H. Shih. 1996. A generalized algorithm for ellipsis resolution. In Proceedings of the 16th International Conference on Computational Linguistics, COLING-96, pages 687–692, Copenhagen.</rawString>
</citation>
<citation valid="true">
<date>2000</date>
<booktitle>Information Extraction meets Corpus Linguistics, LREC-2000.</booktitle>
<editor>John McNaught, editor.</editor>
<marker>2000</marker>
<rawString>John McNaught, editor. 2000. Information Extraction meets Corpus Linguistics, LREC-2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ruslan Mitkov</author>
</authors>
<title>Robust pronoun resolution with limited knowledge.</title>
<date>1998</date>
<booktitle>In Proceedings of the 17th International Conference on Computational Linguistics, COLING-98,</booktitle>
<pages>869--875</pages>
<location>Montreal.</location>
<marker>Mitkov, 1998</marker>
<rawString>Ruslan Mitkov. 1998. Robust pronoun resolution with limited knowledge. In Proceedings of the 17th International Conference on Computational Linguistics, COLING-98, pages 869–875, Montreal.</rawString>
</citation>
<citation valid="true">
<date>1995</date>
<booktitle>Sixth Message Understanding Conference (MUC-6).</booktitle>
<editor>MUC, editor.</editor>
<publisher>Morgan Kaufmann.</publisher>
<marker>1995</marker>
<rawString>MUC, editor. 1995. Sixth Message Understanding Conference (MUC-6). Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>editor MUC</author>
</authors>
<date>1998</date>
<booktitle>Seventh Message Understanding Conference (MUC-7), http://www.muc.saic.com/. SAIC Information Extraction.</booktitle>
<marker>MUC, 1998</marker>
<rawString>MUC, editor. 1998. Seventh Message Understanding Conference (MUC-7), http://www.muc.saic.com/. SAIC Information Extraction.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guenter Neumann</author>
<author>R Backofen</author>
<author>J Baur</author>
<author>M Becker</author>
<author>C Braun</author>
</authors>
<title>An information extraction core system for real world german text processing.</title>
<date>1997</date>
<booktitle>In Proceedings of the 5th Conference on Applied Natural Language Processing, ANLP-97,</booktitle>
<pages>209--216</pages>
<marker>Neumann, Backofen, Baur, Becker, Braun, 1997</marker>
<rawString>Guenter Neumann, R. Backofen, J. Baur, M. Becker, and C. Braun. 1997. An information extraction core system for real world german text processing. In Proceedings of the 5th Conference on Applied Natural Language Processing, ANLP-97, pages 209–216.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guenter Neumann</author>
<author>C Braun</author>
<author>J Piskorski</author>
</authors>
<title>A divide-and-conquer strategy for shallow parsing of german free texts.</title>
<date>2000</date>
<booktitle>In Proceedings of the 6th Conference on Applied Natural Language Processing, ANLP-00.</booktitle>
<contexts>
<context position="8378" citStr="Neumann et al., 2000" startWordPosition="1307" endWordPosition="1310">ned above are given in the bibliography at the end of this paper. several languages5, and great economic and public interest. The prototype will also be tested by TV professionals and sport journalists, who will report on its practicability for the creation and management of their programme and information material. The principles and methods derived from this domain can be applied to other as well. This has been shown already in the context of text-based Information Extraction (IE), for which methodologies for a fast adaptation to new domains have been developed (see the MUC conferences and (Neumann et al., 2000)). And generally speaking the use of IE for automatic annotation of multimedia document has the advantage of providing, besides the results of the (shallow) syntactic processing, accurate semantic (or content/conceptual) information (and thus potential annotation) for specific predefined domains, since a mapping from the linguistically analyzed relevant text parts can be mapped onto an unambiguous conceptual description6. Thus in a sense it can be assumed that IE is supporting the word sense disambiguation task. It is also commonly assumed (see among others (Cunningham, 1999)) that IE occupies</context>
</contexts>
<marker>Neumann, Braun, Piskorski, 2000</marker>
<rawString>Guenter Neumann, C. Braun, and J. Piskorski. 2000. A divide-and-conquer strategy for shallow parsing of german free texts. In Proceedings of the 6th Conference on Applied Natural Language Processing, ANLP-00.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jakub Piskorski</author>
<author>G Neumann</author>
</authors>
<title>An intelligent text extraction and navigation system.</title>
<date>2000</date>
<booktitle>In Proceedings of the 6th Conference on Recherche d&apos;Information Assist´ee par Ordinateur, RIAO-2000. Project URLs: England - Deutschland</booktitle>
<volume>1</volume>
<pages>0--0</pages>
<marker>Piskorski, Neumann, 2000</marker>
<rawString>Jakub Piskorski and G. Neumann. 2000. An intelligent text extraction and navigation system. In Proceedings of the 6th Conference on Recherche d&apos;Information Assist´ee par Ordinateur, RIAO-2000. Project URLs: England - Deutschland 1:0 (0:0)</rawString>
</citation>
<citation valid="false">
<authors>
<author>G Neville</author>
</authors>
<title>Neville (4,5) - Ince (3,5), Wise (5) - Beckham (4), Scholes (3) - Shearer (3), Owen (5) - Trainer: Keegan Deutschland: Kahn (2) -</title>
<journal>Matthaeus</journal>
<volume>3</volume>
<note>Babbel (3,5), Nowotny (2,5) - Deisler (3), Hamann (2,5), Jeremies (3,5), Ziege (3,5) - Scholl (5) - Jancker (4), Kirsten (5) - Trainer: Ribbeck</note>
<marker>Neville, </marker>
<rawString>England: Seaman (2,5) - G. Neville (3,5), Keown (3), Campbell (2), P. Neville (4,5) - Ince (3,5), Wise (5) - Beckham (4), Scholes (3) - Shearer (3), Owen (5) - Trainer: Keegan Deutschland: Kahn (2) - Matthaeus (3) - Babbel (3,5), Nowotny (2,5) - Deisler (3), Hamann (2,5), Jeremies (3,5), Ziege (3,5) - Scholl (5) - Jancker (4), Kirsten (5) - Trainer: Ribbeck</rawString>
</citation>
<citation valid="false">
<authors>
<author>Eingewechselt</author>
</authors>
<title>Gerrard fuer Owen, 72. Barmby fuer</title>
<booktitle>Scholes - 70. Rink fuer Kirsten, 72. Ballack fuer Deisler, 78. Bode fuer Jeremies</booktitle>
<marker>Eingewechselt, </marker>
<rawString>Eingewechselt: 61. Gerrard fuer Owen, 72. Barmby fuer Scholes - 70. Rink fuer Kirsten, 72. Ballack fuer Deisler, 78. Bode fuer Jeremies</rawString>
</citation>
<citation valid="false">
<title>Vorarbeit Beckham) Schiedsrichter: Collina, Pierluigi (Viareggio), Note 2 - bis auf eine falsche Abseits-Entscheidung souveraen und sicher Zuschauer: 30000 (ausverkauft) Gelbe Karten: Beckham - Babbel, Jeremies Gruppe A: England -</title>
<journal>Deutschland</journal>
<volume>0</volume>
<issue>0</issue>
<marker></marker>
<rawString>Tore: 1:0 Shearer (53., Kopfball, Vorarbeit Beckham) Schiedsrichter: Collina, Pierluigi (Viareggio), Note 2 - bis auf eine falsche Abseits-Entscheidung souveraen und sicher Zuschauer: 30000 (ausverkauft) Gelbe Karten: Beckham - Babbel, Jeremies Gruppe A: England - Deutschland 1:0 (0:0) 7. Ein Freistoss von Christian Ziege aus 25 Metern geht ueber das Tor.</rawString>
</citation>
<citation valid="false">
<title>Ziege flankt per Freistoss in den Strafraum und Jeremies versucht es per Kofball, verfehlt den Kasten jedoch deutlich. 16. Scholes flankt gefaehrlich von der Torauslinie in den Fuenfmeterraum, doch Ziege hat aufgepasst und kann klaeren.</title>
<marker></marker>
<rawString>12. Ziege flankt per Freistoss in den Strafraum und Jeremies versucht es per Kofball, verfehlt den Kasten jedoch deutlich. 16. Scholes flankt gefaehrlich von der Torauslinie in den Fuenfmeterraum, doch Ziege hat aufgepasst und kann klaeren.</rawString>
</citation>
<citation valid="false">
<title>Hamann versucht es mit einem Distanzschuss aus 20 Metern, aber Seaman ist auf dem Posten. 23. Scholl mit einer Riesenchance: Nach Zuspiel von Hamann rennt er in den englischen Strafraum, wird jedoch gleich von drei Seiten bedraengt und kommt nur zu einem unplazierten Schuss, den Seaman sicher abfangen kann.</title>
<marker></marker>
<rawString>18. Hamann versucht es mit einem Distanzschuss aus 20 Metern, aber Seaman ist auf dem Posten. 23. Scholl mit einer Riesenchance: Nach Zuspiel von Hamann rennt er in den englischen Strafraum, wird jedoch gleich von drei Seiten bedraengt und kommt nur zu einem unplazierten Schuss, den Seaman sicher abfangen kann.</rawString>
</citation>
<citation valid="false">
<title>Jancker spielt auf Ziege, dessen Schuss von der Strafraumgrenze kann von Seaman abgefangen werden.</title>
<marker></marker>
<rawString>27. Jancker spielt auf Ziege, dessen Schuss von der Strafraumgrenze kann von Seaman abgefangen werden.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Michael</author>
</authors>
<title>Owen kommt nach Flanke von Philip Neville voellig frei vor dem deutschen Tor zum Kopfball, doch Kahn kann zum ersten Mal sein Koennen unter Beweis stellen und rettet auf der Linie.</title>
<marker>Michael, </marker>
<rawString>35. Michael Owen kommt nach Flanke von Philip Neville voellig frei vor dem deutschen Tor zum Kopfball, doch Kahn kann zum ersten Mal sein Koennen unter Beweis stellen und rettet auf der Linie.</rawString>
</citation>
<citation valid="false">
<title>Kahn zum zweiten: Beckham flankt auf Scholes, der zieht ab in den rechten Winkel, aber der deutsche Keeper verhindert erneut die englische Fuehrung. 47. Christian Zieges Freistoss aus 20 Metern geht einen halben Meter ueber das Tor.</title>
<marker></marker>
<rawString>43. Kahn zum zweiten: Beckham flankt auf Scholes, der zieht ab in den rechten Winkel, aber der deutsche Keeper verhindert erneut die englische Fuehrung. 47. Christian Zieges Freistoss aus 20 Metern geht einen halben Meter ueber das Tor.</rawString>
</citation>
<citation valid="false">
<title>Beckham flankt per Freistoss an der deutschen Abwehr vorbei auf den Kopf von Alan Shearer, der voellig freistehend zum 1:0 fuer die Englaender verwandelt. 58. Scholl wird von Matthaeus bedient, aber sein Schuss geht aus halbrechter Position um Zentimeter am Tor vorbei. 65. Seaman kann nach einem Eckball vor Kirsten klaeren, der Nachschuss von Jancker geht knapp am Tor vorbei. Riesenmoeglichkeit fuer die DFB-Elf.</title>
<marker></marker>
<rawString>53. Beckham flankt per Freistoss an der deutschen Abwehr vorbei auf den Kopf von Alan Shearer, der voellig freistehend zum 1:0 fuer die Englaender verwandelt. 58. Scholl wird von Matthaeus bedient, aber sein Schuss geht aus halbrechter Position um Zentimeter am Tor vorbei. 65. Seaman kann nach einem Eckball vor Kirsten klaeren, der Nachschuss von Jancker geht knapp am Tor vorbei. Riesenmoeglichkeit fuer die DFB-Elf.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>