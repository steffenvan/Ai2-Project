<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.977624">
A Block-Based Robust Dependency Parser for Unrestricted
Chinese Text&apos;
</title>
<author confidence="0.998398">
Ming Zhou
</author>
<affiliation confidence="0.912501">
Microsoft Research China,
Sigma Centre, 49#, Zhichun Road,
100080, Beijing, China
</affiliation>
<email confidence="0.991176">
mingzhou@microsoft.com
</email>
<sectionHeader confidence="0.986799" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999752181818182">
Although substantial efforts have been made
to parse Chinese, very few have been
practically used due to incapability of
handling unrestricted texts. This paper
realizes a practical system for Chinese
parsing by using a hybrid model of phrase
structure partial parsing and dependency
parsing. This system showed good
performance and high robustness in parsing
unrestricted texts and has been applied in a
successful machine translation product.
</bodyText>
<sectionHeader confidence="0.834349" genericHeader="introduction">
Introduction
</sectionHeader>
<bodyText confidence="0.99991472972973">
Substantial efforts have been made to parse
western languages such as English, and many
powerful computational models have been
proposed (Gazdar, et al, 1987, Tomita, M, 1986).
However, very limited work has been done with
Chinese. This is mainly due to the fact that the
structure of the Chinese language is quite
different from English. Therefore the
computational model in processing English may
not be directly applied to the Chinese language.
Lin-Shan Lee et al (1991) proposed a Chinese
natural language processing system with special
consideration of some typical phenomena of
Chinese. Jinye Thou et al (1986) presented a
deterministic Chinese parsing methodology
using formal semantics to combine syntactic and
semantic analysis. However, most of the
proposed approaches were realized on
small-scale lexicon and rule base (usually
thousands words and tens or hundreds rules). It
is still an open issue whether these models will
work on real texts containing various
ungrammatical phenomena. A parser capable of
handling real text should have not only large
lexicon and big rule base, but also high
robustness in coping with different kinds of
ungrammatical phenomena. Therefore, it is
important to design a grammar scheme which
not only is capable of representing the unique
grammar structures which are different with
English, but also qualified of handling
unrestricted text.
Phrase structure scheme is usually used in
English parsing models to represent sentence
structures, but it is not convenient and not strong
enough to express Chinese sentence by phrase
structure in some occasions. For examples:
</bodyText>
<figure confidence="0.588795">
Sentence-1 WI-Mt a
Rif] it it ri.Vgl
</figure>
<figureCaption confidence="0.800122">
Fig. 1 phrase structure
Fig.2 dependency structure
</figureCaption>
<footnote confidence="0.446061">
I This work was mainly done while the author visited Kodensha Ltd, Japan during 1996-1999
</footnote>
<page confidence="0.994858">
78
</page>
<bodyText confidence="0.975883807692308">
Sentence-1 is a pivot sentence(*i§), i.e.,
&amp;quot;M,&amp;quot; is not only the object of &amp;quot;iii&amp;quot; but also
the subject of &amp;quot; 114&amp;quot; . But this phrase structure
cannot indicate the relations clearly as shown in
Fig. 1. However, the grammar structure is
clarified if it is represented in dependency
structure (Fig. 2). Therefore, it is believed that
dependency grammar scheme is more suitable
than phrase structure to represent Chinese
structures (Thou, Huang, 1994). However,
traditional Dependency grammar realizes the
dependency relations between any of two
specific words, then numerous word based
dependency knowledge should be constructed,
this is a time-consuming task. Fortunately,
knowledge for phrase structure parsing has been
accumulated for Chinese for many years and it
should be re-used to compensate the lack of
knowledge of word-based dependency parsing.
Therefore, to combine the advantages of phrase
structure parsing and dependency parsing, we
propose a new parsing strategy, called
&amp;quot;block-based dependency parsing&amp;quot;.
A &amp;quot;block&amp;quot; means a basic component of
sentence, for example, there are six blocks for
sentence 1:
</bodyText>
<equation confidence="0.4930955">
fain][1111[At][4][4ffil[.
Another example:
Sentence 2: iiir_b.ltirl-Mttn±VIRJ*4
mocksVFX.±.] [Rim [Atinvin
</equation>
<bodyText confidence="0.986012782608696">
[n4 [—tallit][.
A block represents an information unit in
communications. For example, in
Chinese-Japanese machine translation,
translations of the members within a block in a
Chinese sentence usually are in a same blocks in
the Japanese translation. Furthermore, it is clear
to represent block with phrase structure, while it
is rather complicated with dependency structure.
This block-based dependency parsing process
works like follows. For an input sentence, basic
components of sentence, i.e., &amp;quot;blocks&amp;quot; are first
identified by an ATN-like partial parsing
procedure, which produces a clear skeleton of
the sentence structure. In our phrase structure
analysis, we don&apos;t try to deduce the whole
sentence into root S, instead, we only try to get
the components, namely blocks. This partial
parsing strategy guarantees high robustness.
Then dependency parsing is applied in order to
build dependency relations among blocks. The
dependency parsing skips ungrammatical
portions it encounters. This strategy confmes
ungrammatical portion and avoids errors to be
propagated globally. By partial parsing and skip
strategy, this parser can handle long,
complicated, or even faulty sentences. The
experiments show that this parser is very robust
and powerful. A parser constructed based on this
approach has been developed, with 220,000
words, 5,000 part-of-speech tagging rules, over
1,000 block parsing rules and 300 dependency
parsing rules. This parser has been applied in a
Chinese-Japanese machine translation product
(Zhou, 1999). To the author&apos;s knowledge, this
parser is one of the largest scale Chinese parser
ever implemented in the world.
The outline of this paper is as follows. In
section 1, we present our special solution to
part-of-speech tagging which significantly
affects the Chinese parsing. Section 2 describes
in details the block-based dependency parsing
approach. We then explain the dependency
parsing algorithm in section 3. The experiment
and its analysis are given in section 4. The
conclusion is given in section 5.
</bodyText>
<sectionHeader confidence="0.679498" genericHeader="method">
1 Rule-based part-of-speech tagging
</sectionHeader>
<bodyText confidence="0.999935428571428">
The Chinese language has many special
syntactic phenomena substantially different from
English (Chao, 1981; Huang, 1982, Wu and Hou,
1982). One of the biggest problems is that there
is no morphological change for a verb, whether
the verb functions as the predicate, subject,
object, or modifier of a noun. For instance:
</bodyText>
<equation confidence="0.95774975">
([11&amp;quot;
vtikm Np)
fiff53faki z`r OH-F*Int
([MONTFAvi NP)
</equation>
<bodyText confidence="0.969115">
Chinese linguistics literature insists that those
words are verbs, and should be marked as
regardless of what context they are in. In this
sense, there will be phrase structure rules for
noun phrase like:
NP-&gt;N+V
NP-&gt;V+N
</bodyText>
<page confidence="0.908901">
79
</page>
<figure confidence="0.403974625">
I. X(NIR)+g)3(VINIFIA)+ X(V*)-&gt;MMF)+ X00
2. ot+giv/INIFIA)+X(aA-)-&gt;rei+gt(N)i- X(N)
3. (19+g)7(VINIFIA)+ X(vN)-&gt;fitli-gt(A)+ X(N)
4. VE+-gt(VINIFIA) + X(-V)-&gt;E/E+gt(V)
However, there must be some rules for VP, S
like:
S-&gt;N+V
VP-&gt;V+N
</figure>
<bodyText confidence="0.971031666666667">
Therefore the conflict of rules becomes very
serious. It means that part-of-speech information
in Chinese is too weak to support Chinese
syntactical analysis. To solve this problem, we
propose that in the part-of-speech tagging stage,
the real grammar features of this kind of words
are determined directly as N, instead of V. To do
this, we describe all possible word category
information for a word in the lexicon, for
example:
j, V/ N/F/A
IN: verb; N: noun; F: adverb; A: adjective
A set of rules with comprehensive context
constraints is designed to determine the specific
part-of-speech of a word in a context. For
example:
X(NIR): a word X, whose word category may
includes N,R, or others.
</bodyText>
<equation confidence="0.95317725">
R: Pronoun;
* : any part-of-speeches;
V* having V category;
—V having no V category;
</equation>
<bodyText confidence="0.9995529">
It is ideal if we have a large corpus which has
been tagged with thins kind of word category
information, so that we can obtain tagging rules
or obtained n-gram model by training. However,
at present, we can&apos;t find a Chinese corpus tagged
with this kind of part-of-speech information as
the training data. We had to write the
part-of-speech disambiguation rules manually.
Currently, over 5,000 linguistics rules have been
designed.
</bodyText>
<sectionHeader confidence="0.658107" genericHeader="method">
2 Block-based Chinese dependency analysis
</sectionHeader>
<bodyText confidence="0.999782689655172">
As indicated in Fig. 3, block-based dependency
analysis consists of four modules, i.e., word
segmentation, part-of-speech tagging, block
analysis and dependency analysis. A
bi-directional heuristic longest matching method
is applied to decide the optimal word sequence.
A set of manually compiled linguistic rules is
applied to decide the optimal word category
sequence. In a partial parsing process, first, local
structures (such as duplication, prefix and suffix)
are identified by a set of word formation rules,
and proper names are identified by a set of
construction rules. This kind of local structures
are called meta-blocks. Then frame structures
(DP), which have paired starting word and
ending word , such as &amp;quot;E&amp;quot;&amp;quot;.&amp;quot;Ht&amp;quot;,&amp;quot;
&amp;quot; &amp;quot; etc are identified, but its internal
structure analysis is delayed. Then ATN network
is used to identify the basic blocks, called
level-1 blocks (these blocks don&apos;t contain IP, LP
and DP). Then we use a set of heuristic rules to
identify the boundaries of IP and LP. Then ATN
network will use again to identify the
complicated blocks, called level-2 blocks, which
may contain LP, DP, IP as its components. Then
a sequence of blocks obtained is then transported
to dependency parser, which will generate
dependency relations among blocks. After that,
we will recursively parse the internal parts of IP,
</bodyText>
<figure confidence="0.999228333333333">
Chinese
Sentences
word part-of-
segment speech
-ation tagging
Dependency
tree
Block depend-
identifica- ency
tion parsing
A
Dependency
rule
Lexicon Tagging
rules
</figure>
<figureCaption confidence="0.975781">
Fig. 3 Configuration of the block-based dependency parser
</figureCaption>
<page confidence="0.979216">
80
</page>
<bodyText confidence="0.97325525">
LP and DP to get its inner blocks and
dependency relations.
We define 11 kinds of blocks as explained
below.
</bodyText>
<table confidence="0.999821375">
NP Noun phrase a nt 44
UP Digital phrase 14560,Ef-=ff
UG Digital-classifier Efi.,7:--h*
phrase
NTL Phrase expressing E-1-lig, 60 &apos;NI
the period of time
NTP Phrase expressing --)I.AiL*E.A
the exact time
AP Adjective phrase X ElfjQt-
FP Adverb phrase Mffi,jVit (44-33 &apos;AZ)
VP Verb phrase
IP Preposition phrase AMR*
LP Post-position -IIr
phrase
DP Frame structure )§!e.Ti-atfl.111C511,f117
Ilgift&amp;ffl
</table>
<tableCaption confidence="0.999533">
Table 1 Blocks defined in the system
</tableCaption>
<bodyText confidence="0.996557857142857">
Except PP, LP and DP, each kind of block is
defined by a set of rules in the form of phrase
structure rule. All of these rules combined with
syntactic and semantic constraints are
implemented as an ATN network (Allen, 1995).
We also define 17 kinds of dependency
relations for Chinese as shown in table 2.
</bodyText>
<table confidence="0.809629285714286">
1 SUB Subject(1)
2 OBJ1 Indirect-objectrOJV AZ.)
3 OBJ2 Direct object(Att A-4)
4 COMP Complement(4M)
4 NUM Amount()
5 TOP Topic()
6 ADVN Near adverbs ( Mnt4)
7 ADVF Far adverbs (1t-Mil4. 1tj1IL iE
AM1&apos;44XW:i )
8 QT miscellaneous before verbs (4-igZia
(14J Pi *Aft)
10 HT miscellaneous after verbs(MislZgin
KJ galAft)
11 PUNC Punctuation mark(1j)
12 PIVT Pivot(AM)
13 SOC Pivot-complement(IM4FiN)
14 VAA Series of verbs after( A katiti4J4/0
15 VAB Series of verbs before( PI Tratitmf)
16 G fiElfAitHIMAA
17 LOG Logical relation between sentences(iff
-as OA)
</table>
<tableCaption confidence="0.985917">
Table 2 Dependency relations used in the system
</tableCaption>
<bodyText confidence="0.9154378">
For an Input: S= w2,—,wn the expected
parse result includes two parts as described
below:
@ T : a set of sub-trees, each sub-tree
represents a block.
</bodyText>
<equation confidence="0.763273">
T={ ,T2,T3 in }
</equation>
<bodyText confidence="0.808892">
0 D: a set of 3-tuple in the form of {governor,
dependant, dependency-relation}, which
represents dependency relations between blocks.
</bodyText>
<construct confidence="0.631047666666667">
D={&lt; goN,dep,re1q&gt;,&lt;gov2,dep2,rela2&gt;,...
Algorithm 1: The block-based parsing
algorithm
</construct>
<listItem confidence="0.971205142857143">
1) Identification DP by matching the starting word
and ending word;
2) Identification of meta-blocks by bottom-up
analysis;
3) Identification of NP, UP, UG, NTL, NTP, AP,
FP, VP of level 1 by bottom-up analysis;
4) Identification LP, PP by looking for left
boundary for LP and right boundary for IP, by
using a set of Chinese linguistic rules;
5) Identification of NP, UP, UG, NTL, NTP, AP,
FP, VP of level 2 by bottom-up analysis;
6) Dependency parsing with the blocks identified;
7) For blocks LP, DP and LP, recursively do 1
thorough 6.
</listItem>
<bodyText confidence="0.90620175">
In the following, we will illustrate the parsing
process with an example.
Sentence 3: &amp;--1-7-T&amp;TiMI-taktilli.K*:
itt-.A.kAA.t12*-73K-Alrig•E.
</bodyText>
<listItem confidence="0.957469">
(1) Word Segmentation &amp; Part-of-speech
tagging
</listItem>
<table confidence="0.329653333333333">
/VT V/T wom Ar/rgi Nat 11c13/1,
Ang* N/ILA Nai% V/ESN/zt-F N/A-K L/
Fam A/0 P/
</table>
<listItem confidence="0.936462571428571">
(2) Meta-blocks identification
Mit VPF F/501&amp;quot; V/]VP
(3) Frame structure identification
[ l/rP /.IN A/3g* N/.t.-Ak NaMi WE&apos;S N/zt
-FN/31E% L/]DP
(4) Block identification
blockl: [/50-1- V/T Frst-r- W]VP
</listItem>
<page confidence="0.985093">
81
</page>
<figure confidence="0.981157875">
b1ock2IOR Mfg&apos; N/]NP
block3: 1/41/1N MEV] N/Wrtaf V/E
eN4C-F N/313a L/DP
block4: [0* VIM A/]AP
block5: Pf]
(5)Predicate Identification
Block4 is determined as the predicate.
(6) Dependency parsing
</figure>
<figureCaption confidence="0.493967">
(block2, blockl, OBJ1)
(block3, block4, ADVF)
(block&apos;, block4, SUB)
(block5, bolck4, PUNC)
</figureCaption>
<bodyText confidence="0.990533066666667">
(7)Repeat the above parsing process to
analyze the internal structure of DP, IP and
LP
Analyze block3 recursively (The detailed
process is omitted).
Lots of efforts have been made to parse
languages into phrase structure, and many
powerful computational models have been
proposed (Gazdar, eta!, 1987, Tomita, M, 1986).
We build up an ATN like network to identify
these blocks. Since the ATN approaches can be
found in the literatures (Allen, 1995), we will
not describe this algorithm in details here. In the
next section, we will focus on a new efficient
algorithm for Chinese dependency parsing.
</bodyText>
<sectionHeader confidence="0.973905" genericHeader="method">
3 Dependency analysis
</sectionHeader>
<subsectionHeader confidence="0.838254">
Text For an Input: S=blockl,block2,---,block„,
</subsectionHeader>
<bodyText confidence="0.9979724">
the dependency parsing will generate a set of
3-tuple in the form of {governor, dependant,
dependency-relation}, which represents
dependency relations between blocks in the
given sentence.
</bodyText>
<equation confidence="0.5661615">
{‹ govi,dep,,rela, &gt;,
&lt; gov2,dep2,rela2&gt;,...&lt;
</equation>
<listItem confidence="0.915980333333333">
Algorithm 2: The dependency parsing
1) Count the number of block qualifying of
acting as a predicate, denoted as s. These kind of
blocks are called &amp;quot;predicate candidates&amp;quot;.
2) Decide the predicate from these s blocks,
denoted as block,
3) If s=0, return; //need not analysis;
4) For any case of S, S=1,2,... (S&gt;0), do
dependency parsing respectively;
</listItem>
<bodyText confidence="0.960193583333333">
A sentence may contain s predicate candidates.
For each case, we defined a detailed analysis
algorithm. Up to now, the parser is designed to
have ability to treat with sentences containing up
to 7 predicate candidates. In case a sentence has
more than 7 predicate candidates, it will be
partitioned into two parts, and then doing
analysis in turn.
Suppose the predicate block is block„ the
number of &amp;quot;predicate candidates&amp;quot; is denoted as s.
We explain the dependency parsing by the
following two simple cases.
</bodyText>
<listItem confidence="0.889673423076923">
Case 1: s=1
• For all Nockk before block, , builds
dependency relations of
( biockk ,block, ,SUB),( biOCkk ,block, ,ADV),
( biOCkk ,block, ,G), ( biOCkk , block,,TOP);
• For all blockk after block, ,builds
dependency relations of
( biockk , block, ,COMP),( biOCkk ,block, ,OBJ
1), ( block, ,block, ,m2), etc.
Case 2: s=2, Let&apos;s say the another predicate
candidate is block y
• For all block before block, ,builds
dependency relations of
( biockk ,block, ,SUB), ( biOCkk ,block, ,ADV),
(blockk,block, ,G), ( block, ,block, ,TOP);
• For all block, after Nock/ ,builds
dependency relations of
( block, • blocks ,COMP),
Moak block.
,OBJ1),
( biOCkk , blocks ,OBJ2), etc.
• For blocks between block, and blocky,
Conducts detailed analysis based on the
verb categories of block, and blocks
• Determines the dependency relation
between block, and blocky
</listItem>
<page confidence="0.998864">
82
</page>
<sectionHeader confidence="0.998194" genericHeader="evaluation">
4 Experiments
</sectionHeader>
<bodyText confidence="0.99965425">
A parsing system was implemented and
extensive experiments have been performed.
The system is written in C and tested on
Pentium PC. A total of over 1,000 phrase
structure rules and over 3,00 dependency rules
were used for block-based parsing. We built a
large lexicon of 220,000 word entries, with word
category information and necessary syntactical
and semantic features. This approach has been
incorporated as Chinese parsing model in a
successful commercial Chinese-Japanese
machine translation system J-Beijing (Thou,
1999).
This system accepts Chinese text and output
the parsing result for each sentence. Each input
sentence is defined as a word string ending with
period, comma, question mark, semicolon,
exclamation mark.
We evaluated the parsing result with two
corpus: @ &amp;quot;primary school textbook of
Singapore&amp;quot;(CIII±A4N*W*), a corpus consists
of single sentences of modem Chinese,
including 1842 sentences, which not only covers
most Chinese sentence types, but also includes
various of morphological phenomena, such as
word duplication, affix, suffix, etc. 0 Some
news articles collected from People&apos;s
Daily(1998,1999,2000). The sentences are real
text, so there are lots of unknown words (mainly
proper nouns), long sentences, complicated
sentences, ellipsis, etc. The evaluation results are
listed in table 3.
</bodyText>
<table confidence="0.9997474">
Test #sentence Average Analysis
corpus sentence precision
length
(words)
Primary 1842 7.34 90.4%
school
textbook,
Singapore
People&apos;s 1400 14.52 67.7%
Daily
</table>
<tableCaption confidence="0.998653">
Table 3 Evaluation result
</tableCaption>
<bodyText confidence="0.999859857142857">
Although this model has produced
satisfactory initial results, some natural
difficulties for the Chinese language still remain,
such that further improvement is highly desired.
Through mistake analysis, we found that some
of main issues affecting the system performance
seriously, as is listed below.
</bodyText>
<figure confidence="0.959157555555555">
1) Word segmentation
• V.NE
/AMA/g VE/#31ELEit/. /
/A4&gt;M5./8git/*/V_EA/0 /
&amp;quot;=431E&amp;quot; can not only function as single word, but
also function as two words with totally different
meaning.
2) Part-of-speech tagging
(l,a,R)(2,71-,D(3sF,R) (4, ,I) (5, RR N) (6,&apos;13fit
(7,ffi,E) (8,1g,V) (9,0t,E) (/0,8?O,F) (11.
(12,,V,P) (13,051,N) (14,RI,V,C)
(15„ ,P)
3) Compound noun
• 3fi&apos;f&apos;ff
ittirJ/EVAff
• ii3Fi.71R
/ilifI/Ea/Eff/i1V./00c/
/1E/iltfeM/i/g./113/,/
</figure>
<bodyText confidence="0.983496">
Since compound nouns cannot exhaustively
numerated, errors will be inevitable.
</bodyText>
<listItem confidence="0.8004555">
4) Identification of proper noun
(1,iI)X,N) (2, rig V,V,P) (3. -AA) (4..AN)
31,V,C) (6,ffk,N) (7,an,N) (8,8-itN)
5) Syntactical ambiguity
</listItem>
<equation confidence="0.947488">
(1,tiff,V,P) (3,M111,N) (4,-ftft,N)
fa,V.C) (6,0,A,D) (6,45,N) (7,ALA) (84AMN)
(9,ta,A)(10,f9M,N) (11, ,P)
</equation>
<bodyText confidence="0.816566666666667">
For pattern of &amp;quot;V+A+N&amp;quot;, there are usually
two kinds of reduction methods:
[W+Mvp+N] OW/01R
[V+[A+1•1]np] ojegig
All of these problems need further
improvements in the future.
</bodyText>
<sectionHeader confidence="0.523116" genericHeader="conclusions">
Conclusion
</sectionHeader>
<bodyText confidence="0.999897666666667">
In this paper, a practical Chinese parser is
presented. The block-based dependency parsing
strategy is a novel integration of phrase structure
partial approach and dependency parsing
approach. The partial parsing approach and
dependency parsing approach can cope with
</bodyText>
<page confidence="0.995217">
83
</page>
<bodyText confidence="0.999940363636364">
ungrammatical or faulty, or complicated
sentences, therefore making the system highly
robust. Furthermore, our top-down strategy of
identifying the Chinese special structures such
as frame structures, preposition structures,
post-preposition structures produces a simplified
sentence skeleton, thereby improving the
efficiency of parsing.
Although this model has shown satisfactory
initial results, some natural difficulties for the
Chinese language still remain, and further work
will be needed. We currently determine the word
category by a set of linguistics rules compiled by
human which limits the precision of
identification precision. Therefore, other
approaches such as statistical approach or some
kind of hybrid approach will be adopted in the
future. In addition, new methods in handling
ambiguous word segmentation, proper noun and
compound noun identification, block analysis,
predicate identification and dependency analysis
will be studied.
</bodyText>
<sectionHeader confidence="0.983355" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9999035">
Our thanks go to Dr. Kai-Fu Lee and Prof.
Changning Huang of Microsoft Research China
for their valuable suggestions. Also thanks all
the members of Chinese-Japanese MT group of
Kodensha for their great efforts in testing the
parsing system and improving the dictionary.
</bodyText>
<sectionHeader confidence="0.99574" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999553428571428">
Gazdar, G.,Franz.,A., Osborne, K., and Evans, R.
(1987), Natural Language Processing in the
1980s.&amp;quot;, CSLI, Stanford University.
Tomita, M. (1986). Efficient Parsing for Natural
Language: A Fast Algorithm for Practical Systems,
Boston: Kluwer.
Jinye Zhou, Shi-lcuo Chang (1986), A Methodology
for Deterministic Chinese Parsing, Computer
Processing of Chinese &amp; Oriental Languages, Vol.
2, No. 3 May 1986.
Lin-Shan Lee, Lee-Feng Chien, Longj-ji Lin, James
Huang, K.-J. Chen (1991), An Efficient Natural
Language Processing System Specially Designed
for the Chinese Language, Computational
Linguistics, Vol.17, No. 4, 1991
M. Thou (1999), J-Beijing Chinese-Japanese
Machine Translation System, Proceedings of JSCL,
312-319, Beijing, 1-3, Nov, 1999
Jingcun Wu, Xuechao Hou, Modern Chinese
Syntactical Analysis, Beijing University Press,
1982.
Zhengsheng Luo, Changjian Sun, Cai Sun (1995), An
Approach to the Recognition of predicated in the
automatic analysis of Chinese sentence patterns,
Advances and applications on Computational
Linguistics, Tsinghua University Press
Chao, Y.R. (1968). A Grammar of Spoken Chinese,
Berkeley, CA: University of California Press
M. Thou, C.N.Huang, (1994) An Efficient Syntactic
Tagging Toll for Corpora. Proc. COLING 94,
Kyoto, pp. 945-955.
Huang, J. (1982). Logical relations in Chinese and
the theory of grammar, Doctoral dissertation,
Massachusetts Institute of Technology, Cambridge,
MA.
</reference>
<page confidence="0.999227">
84
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.579869">
<title confidence="0.866214">A Block-Based Robust Dependency Parser for Chinese Text&apos; Ming</title>
<affiliation confidence="0.994001">Microsoft Research</affiliation>
<address confidence="0.9871215">Sigma Centre, 49#, Zhichun 100080, Beijing,</address>
<email confidence="0.999928">mingzhou@microsoft.com</email>
<abstract confidence="0.999441083333333">Although substantial efforts have been made to parse Chinese, very few have been practically used due to incapability of handling unrestricted texts. This paper realizes a practical system for Chinese parsing by using a hybrid model of phrase structure partial parsing and dependency parsing. This system showed good performance and high robustness in parsing unrestricted texts and has been applied in a successful machine translation product.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>G Gazdar</author>
<author>A Franz</author>
<author>K Osborne</author>
<author>R Evans</author>
</authors>
<title>Natural Language Processing in the 1980s.&amp;quot;, CSLI,</title>
<date>1987</date>
<institution>Stanford University.</institution>
<contexts>
<context position="809" citStr="Gazdar, et al, 1987" startWordPosition="111" endWordPosition="114">act Although substantial efforts have been made to parse Chinese, very few have been practically used due to incapability of handling unrestricted texts. This paper realizes a practical system for Chinese parsing by using a hybrid model of phrase structure partial parsing and dependency parsing. This system showed good performance and high robustness in parsing unrestricted texts and has been applied in a successful machine translation product. Introduction Substantial efforts have been made to parse western languages such as English, and many powerful computational models have been proposed (Gazdar, et al, 1987, Tomita, M, 1986). However, very limited work has been done with Chinese. This is mainly due to the fact that the structure of the Chinese language is quite different from English. Therefore the computational model in processing English may not be directly applied to the Chinese language. Lin-Shan Lee et al (1991) proposed a Chinese natural language processing system with special consideration of some typical phenomena of Chinese. Jinye Thou et al (1986) presented a deterministic Chinese parsing methodology using formal semantics to combine syntactic and semantic analysis. However, most of th</context>
</contexts>
<marker>Gazdar, Franz, Osborne, Evans, 1987</marker>
<rawString>Gazdar, G.,Franz.,A., Osborne, K., and Evans, R. (1987), Natural Language Processing in the 1980s.&amp;quot;, CSLI, Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Tomita</author>
</authors>
<title>Efficient Parsing for Natural Language: A Fast Algorithm for Practical Systems,</title>
<date>1986</date>
<publisher>Kluwer.</publisher>
<location>Boston:</location>
<marker>Tomita, 1986</marker>
<rawString>Tomita, M. (1986). Efficient Parsing for Natural Language: A Fast Algorithm for Practical Systems, Boston: Kluwer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jinye Zhou</author>
</authors>
<title>Shi-lcuo Chang</title>
<date>1986</date>
<journal>Computer Processing of Chinese &amp; Oriental Languages,</journal>
<volume>2</volume>
<marker>Zhou, 1986</marker>
<rawString>Jinye Zhou, Shi-lcuo Chang (1986), A Methodology for Deterministic Chinese Parsing, Computer Processing of Chinese &amp; Oriental Languages, Vol. 2, No. 3 May 1986.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lin-Shan Lee</author>
<author>Lee-Feng Chien</author>
<author>Longj-ji Lin</author>
<author>James Huang</author>
<author>K-J Chen</author>
</authors>
<title>An Efficient Natural Language Processing System Specially Designed for the Chinese Language,</title>
<date>1991</date>
<journal>Computational Linguistics,</journal>
<volume>17</volume>
<contexts>
<context position="1125" citStr="Lee et al (1991)" startWordPosition="163" endWordPosition="166">d performance and high robustness in parsing unrestricted texts and has been applied in a successful machine translation product. Introduction Substantial efforts have been made to parse western languages such as English, and many powerful computational models have been proposed (Gazdar, et al, 1987, Tomita, M, 1986). However, very limited work has been done with Chinese. This is mainly due to the fact that the structure of the Chinese language is quite different from English. Therefore the computational model in processing English may not be directly applied to the Chinese language. Lin-Shan Lee et al (1991) proposed a Chinese natural language processing system with special consideration of some typical phenomena of Chinese. Jinye Thou et al (1986) presented a deterministic Chinese parsing methodology using formal semantics to combine syntactic and semantic analysis. However, most of the proposed approaches were realized on small-scale lexicon and rule base (usually thousands words and tens or hundreds rules). It is still an open issue whether these models will work on real texts containing various ungrammatical phenomena. A parser capable of handling real text should have not only large lexicon </context>
</contexts>
<marker>Lee, Chien, Lin, Huang, Chen, 1991</marker>
<rawString>Lin-Shan Lee, Lee-Feng Chien, Longj-ji Lin, James Huang, K.-J. Chen (1991), An Efficient Natural Language Processing System Specially Designed for the Chinese Language, Computational Linguistics, Vol.17, No. 4, 1991</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Thou</author>
</authors>
<title>J-Beijing Chinese-Japanese Machine Translation System,</title>
<date>1999</date>
<booktitle>Proceedings of JSCL,</booktitle>
<pages>312--319</pages>
<location>Beijing,</location>
<contexts>
<context position="15679" citStr="Thou, 1999" startWordPosition="2425" endWordPosition="2426">ks • Determines the dependency relation between block, and blocky 82 4 Experiments A parsing system was implemented and extensive experiments have been performed. The system is written in C and tested on Pentium PC. A total of over 1,000 phrase structure rules and over 3,00 dependency rules were used for block-based parsing. We built a large lexicon of 220,000 word entries, with word category information and necessary syntactical and semantic features. This approach has been incorporated as Chinese parsing model in a successful commercial Chinese-Japanese machine translation system J-Beijing (Thou, 1999). This system accepts Chinese text and output the parsing result for each sentence. Each input sentence is defined as a word string ending with period, comma, question mark, semicolon, exclamation mark. We evaluated the parsing result with two corpus: @ &amp;quot;primary school textbook of Singapore&amp;quot;(CIII±A4N*W*), a corpus consists of single sentences of modem Chinese, including 1842 sentences, which not only covers most Chinese sentence types, but also includes various of morphological phenomena, such as word duplication, affix, suffix, etc. 0 Some news articles collected from People&apos;s Daily(1998,1999</context>
</contexts>
<marker>Thou, 1999</marker>
<rawString>M. Thou (1999), J-Beijing Chinese-Japanese Machine Translation System, Proceedings of JSCL, 312-319, Beijing, 1-3, Nov, 1999</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jingcun Wu</author>
</authors>
<title>Xuechao Hou, Modern Chinese Syntactical Analysis,</title>
<date>1982</date>
<publisher>University Press,</publisher>
<location>Beijing</location>
<marker>Wu, 1982</marker>
<rawString>Jingcun Wu, Xuechao Hou, Modern Chinese Syntactical Analysis, Beijing University Press, 1982.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhengsheng Luo</author>
</authors>
<title>Changjian Sun, Cai Sun</title>
<date>1995</date>
<publisher>University Press</publisher>
<marker>Luo, 1995</marker>
<rawString>Zhengsheng Luo, Changjian Sun, Cai Sun (1995), An Approach to the Recognition of predicated in the automatic analysis of Chinese sentence patterns, Advances and applications on Computational Linguistics, Tsinghua University Press</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y R Chao</author>
</authors>
<title>A Grammar of Spoken Chinese,</title>
<date>1968</date>
<booktitle>Proc. COLING 94, Kyoto,</booktitle>
<pages>945--955</pages>
<institution>University of California Press</institution>
<location>Berkeley, CA:</location>
<marker>Chao, 1968</marker>
<rawString>Chao, Y.R. (1968). A Grammar of Spoken Chinese, Berkeley, CA: University of California Press M. Thou, C.N.Huang, (1994) An Efficient Syntactic Tagging Toll for Corpora. Proc. COLING 94, Kyoto, pp. 945-955.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Huang</author>
</authors>
<title>Logical relations in Chinese and the theory of grammar, Doctoral dissertation,</title>
<date>1982</date>
<institution>Massachusetts Institute of Technology,</institution>
<location>Cambridge, MA.</location>
<contexts>
<context position="5859" citStr="Huang, 1982" startWordPosition="869" endWordPosition="870"> largest scale Chinese parser ever implemented in the world. The outline of this paper is as follows. In section 1, we present our special solution to part-of-speech tagging which significantly affects the Chinese parsing. Section 2 describes in details the block-based dependency parsing approach. We then explain the dependency parsing algorithm in section 3. The experiment and its analysis are given in section 4. The conclusion is given in section 5. 1 Rule-based part-of-speech tagging The Chinese language has many special syntactic phenomena substantially different from English (Chao, 1981; Huang, 1982, Wu and Hou, 1982). One of the biggest problems is that there is no morphological change for a verb, whether the verb functions as the predicate, subject, object, or modifier of a noun. For instance: ([11&amp;quot; vtikm Np) fiff53faki z`r OH-F*Int ([MONTFAvi NP) Chinese linguistics literature insists that those words are verbs, and should be marked as regardless of what context they are in. In this sense, there will be phrase structure rules for noun phrase like: NP-&gt;N+V NP-&gt;V+N 79 I. X(NIR)+g)3(VINIFIA)+ X(V*)-&gt;MMF)+ X00 2. ot+giv/INIFIA)+X(aA-)-&gt;rei+gt(N)i- X(N) 3. (19+g)7(VINIFIA)+ X(vN)-&gt;fitli-gt</context>
</contexts>
<marker>Huang, 1982</marker>
<rawString>Huang, J. (1982). Logical relations in Chinese and the theory of grammar, Doctoral dissertation, Massachusetts Institute of Technology, Cambridge, MA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>