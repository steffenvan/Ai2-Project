<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000006">
<title confidence="0.853333">
Incremental Query Generation
</title>
<author confidence="0.287395">
Claire Gardent
</author>
<affiliation confidence="0.124247">
CNRS/LORIA
</affiliation>
<address confidence="0.556244">
Nancy, France
</address>
<email confidence="0.789528">
claire.gardent@loria.fr
</email>
<author confidence="0.990594">
Laura Perez-Beltrachini
</author>
<affiliation confidence="0.847842333333333">
Faculty of Computer Science
Free University of Bozen-Bolzano
Bozen-Bolzano, Italy
</affiliation>
<email confidence="0.995042">
laura.perez@loria.fr
</email>
<author confidence="0.996523">
Enrico Franconi
</author>
<affiliation confidence="0.847817">
Faculty of Computer Science
Free University of Bozen-Bolzano
Bozen-Bolzano, Italy
</affiliation>
<email confidence="0.993422">
franconi@inf.unibz.it
</email>
<sectionHeader confidence="0.993775" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999891294117647">
We present a natural language genera-
tion system which supports the incremen-
tal specification of ontology-based queries
in natural language. Our contribution is
two fold. First, we introduce a chart
based surface realisation algorithm which
supports the kind of incremental process-
ing required by ontology-based querying.
Crucially, this algorithm avoids confusing
the end user by preserving a consistent
ordering of the query elements through-
out the incremental query formulation pro-
cess. Second, we show that grammar
based surface realisation better supports
the generation of fluent, natural sounding
queries than previous template-based ap-
proaches.
</bodyText>
<sectionHeader confidence="0.99899" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.989110903846154">
Previous research has shown that formal ontolo-
gies could be used as a means not only to provide
a uniform and flexible approach to integrating and
describing heterogeneous data sources, but also to
support the final user in querying them, thus im-
proving the usability of the integrated system. To
support the wide access to these data sources, it is
crucial to develop efficient and user-friendly ways
to query them (Wache et al., 2001).
In this paper, we present a Natural Language
(NL) interface of an ontology-based query tool,
called Quelo1, which allows the end user to for-
mulate a query without any knowledge either of
the formal languages used to specify ontologies, or
of the content of the ontology being used. Follow-
ing the conceptual authoring approach described
in (Tennant et al., 1983; Hallett et al., 2007), this
interface masks the composition of a formal query
1krdbapp.inf.unibz.it:8080/quelo
as the composition of an English text describ-
ing the equivalent information needs using natu-
ral language generation techniques. The natural
language generation system that we propose for
Quelo’s NL interface departs from similar work
(Hallett et al., 2007; Franconi et al., 2010a; Fran-
coni et al., 2011b; Franconi et al., 2010b; Franconi
et al., 2011a) in that it makes use of standard gram-
mar based surface realisation techniques. Our con-
tribution is two fold. First, we introduce a chart
based surface realisation algorithm which supports
the kind of incremental processing required by on-
tology driven query formulation. Crucially, this
algorithm avoids confusing the end user by pre-
serving a consistent ordering of the query ele-
ments throughout the incremental query formu-
lation process. Second, we show that grammar
based surface realisation better supports the gener-
ation of fluent, natural sounding queries than pre-
vious template-based approaches.
The paper is structured as follows. Section 2
discusses related work and situates our approach.
Section 3 describes the task being addressed
namely, ontology driven query formulation. It in-
troduces the input being handled, the constraints
under which generation operates and the opera-
tions the user may perform to build her query.
In Section 4, we present the generation algo-
rithm used to support the verbalisation of possi-
ble queries. Section 5 reports on an evaluation of
the system with respect to fluency, clarity, cover-
age and incrementality. Section 6 concludes with
pointers for further research.
</bodyText>
<sectionHeader confidence="0.999852" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.992247">
Our approach is related to two main strands of
work: incremental generation and conceptual au-
thoring.
Incremental Generation (Oh and Rudnicky,
2000) used an n-gram language model to stochas-
</bodyText>
<page confidence="0.987737">
183
</page>
<note confidence="0.9929755">
Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 183–191,
Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.99935662195122">
tically generate system turns. The language model
is trained on a dialog corpus manually annotated
with word and utterance classes. The generation
engine uses the appropriate language model for
the utterance class and generates word sequences
randomly according to the language model distri-
bution. The generated word sequences are then
ranked using a scoring mechanism and only the
best-scored utterance is kept. The system is incre-
mental is that each word class to be verbalised can
yield a new set of utterance candidates. However
it supports only addition not revisions. Moreover
it requires domain specific training data and man-
ual annotation while the approach we propose is
unsupervised and generic to any ontology.
(Dethlefs et al., 2013) use Conditional Random
Fields to find the best surface realisation from a
semantic tree. They show that the resulting sys-
tem is able to modify generation results on the fly
when new or updated input is provided by the dia-
log manager. While their approach is fast to ex-
ecute, it is limited to a restricted set of domain
specific attributes; requires a training corpus of
example sentences to define the space of possi-
ble surface realisations; and is based on a large
set (800 rules) of domain specific rules extracted
semi-automatically from the training corpus. In
contrast, we use a general, small size grammar
(around 50 rules) and a lexicon which is automat-
ically derived from the input ontologies. The re-
sulting system requires no training and thus can
be applied to any ontology with any given signa-
ture of concepts and relations. Another difference
between the two approaches concerns revisions:
while our approach supports revisions anywhere
in the input, the CRF approach proposed by (Deth-
lefs et al., 2013) only supports revisions occurring
at the end of the generated string.
There is also much work (Schlangen and
Skantze, 2009; Schlangen et al., 2009) in the do-
main of spoken dialog systems geared at mod-
elling the incremental nature of dialog and in par-
ticular, at developing dialog systems where pro-
cessing starts before the input is complete. In these
approaches, the focus is on developing efficient ar-
chitectures which support the timely interleaving
of parsing and generation. Instead, our aim is to
develop a principled approach to the incremental
generation of a user query which supports revision
and additions at arbitrary points of the query being
built; generates natural sounding text; and maxi-
mally preserves the linear order of the query.
Conceptual authoring Our proposal is closely
related to the conceptual authoring approach de-
scribed in (Hallett et al., 2007). In this approach,
a text generated from a knowledge base, describes
in natural language the knowledge encoded so far,
and the options for extending it. Starting with an
initial very general query (e.g., all things), the user
can formulate a query by choosing between these
options. Similarly, (Franconi et al., 2010a; Fran-
coni et al., 2011b; Franconi et al., 2010b; Fran-
coni et al., 2011a) describes a conceptual author-
ing approach to querying semantic data where in
addition , logical inference is used to semantically
constrain the possible completions/revisions dis-
played to the user.
Our approach departs from this work in that it
makes use of standard grammars and algorithms.
While previous work was based on procedures and
templates, we rely on a Feature-Based Tree Ad-
joining Grammar to capture the link between text
and semantics required by conceptual authoring;
and we adapt a chart based algorithm to support
the addition, the revision and the substitution of
input material. To avoid confusing the user, we
additionally introduce a scoring function which
helps preserve the linear order of the NL query.
The generation system we present is in fact inte-
grated in the Quelo interface developed by (Fran-
coni et al., 2011a) and compared with their previ-
ous template-based approach.
</bodyText>
<sectionHeader confidence="0.806252" genericHeader="method">
3 Incremental Generation of Candidate
Query Extensions
</sectionHeader>
<bodyText confidence="0.999899411764706">
The generation task we address is the following.
Given a knowledge base K, some initial formal
query q and a focus point p in that query, the rea-
soning services supported by Quelo’s query logic
framework (see (Guagliardo, 2009)) will compute
a set of new queries rev(q) formed by adding,
deleting and revising the current query q at point
p. The task of the generator is then to produce
a natural language sentence for each new formal
query q′ ∈ rev(q) which results from this revision
process. In other words, each time the user refines
a query q to produce a new query q′, the system
computes all revisions rev(q) of q′ that are com-
patible with the underlying knowledge base using
a reasoner. Each of these possible revisions is then
input to the generator and the resulting revised NL
queries are displayed to the user. In what follows,
</bodyText>
<page confidence="0.998031">
184
</page>
<bodyText confidence="0.990213181818182">
we assume that formal queries are represented us-
ing Description Logics (Baader, 2003).
The following examples show a possible se-
quence of NL queries, their corresponding DL rep-
resentation and the operations provided by Quelo
that can be performed on a query (bold face is used
to indicate the point in the query at which the next
revision takes place). For instance, the query in
(1c) results from adding the concept Young to the
query underlying (1b) at the point highlighted by
man.
</bodyText>
<listItem confidence="0.955475235294118">
(1) a. I am looking for something (initial query)
T
b. I am looking for a man (substitute con-
cept)
Man
c. I am looking for a young man (add com-
patible concept)
Man n Young
d. I am looking for a young man who is
married to a person (add relation)
Man n Young n IisMarried.(Person)
e. I am looking for a young married man
(substitute selection)
MarriedMan n Young
f. I am looking for a married man (delete
concept)
MarriedMan
</listItem>
<sectionHeader confidence="0.976168" genericHeader="method">
4 Generating Queries
</sectionHeader>
<bodyText confidence="0.994680944444445">
Generation of KB queries differs from standard
natural language generation algorithms in two
main ways. First it should support the revi-
sions, deletions and additions required by incre-
mental processing. Second, to avoid confusing
the user, the revisions (modifications, extensions,
deletions) performed by the user should have a
minimal effect on the linear order of the NL query.
That is the generator is not free to produce any NL
variant verbalising the query but should produce
a verbalisation that is linearly as close as possi-
ble, modulo the revision applied by the user, to the
query before revisions. Thus for instance, given
the DL query (2) and assuming a linearisation of
that formula that matches the linear order it is pre-
sented in (see Section 4.2.1 below for a definition
of the linearisation of DL formulae), sentence (2b)
will be preferred over (2c).
</bodyText>
<listItem confidence="0.942262">
(2) a. Car n IrunOn.(Diesel) n
IequippedW ith.(AirCond)
b. A car which runs on Diesel and is
equipped with air conditioning
c. A car which is equipped with air condi-
tioning and runs on Diesel
</listItem>
<bodyText confidence="0.9999526">
In what follows, we describe the generation al-
gorithm used to verbalise possible extensions of
user queries as proposed by the Quelo tool. We
start by introducing and motivating the underlying
formal language supported by Quelo and the input
to the generator. We then describe the overall ar-
chitecture of our generator. Finally, we present the
incremental surface realisation algorithm support-
ing the verbalisation of the possible query exten-
sions.
</bodyText>
<subsectionHeader confidence="0.978343">
4.1 The Input Language
</subsectionHeader>
<bodyText confidence="0.9999579">
Following (Franconi et al., 2010a; Franconi et al.,
2011b; Franconi et al., 2010b; Franconi et al.,
2011a) we assume a formal language for queries
that targets the querying of various knowledge and
data bases independent of their specification lan-
guage. To this end, it uses a minimal query lan-
guage L that is shared by most knowledge repre-
sentation languages and is supported by Descrip-
tion Logic (DL) reasoners namely, the language of
tree shaped conjunctive DL queries. Let R be a
set of relations and C be a set of concepts, then the
language of tree-shaped conjunctive DL queries is
defined as follows: 5 ::= C  |IR.(5)  |5 n 5
where R E R, C E C, n denotes conjunction and
I is the existential quantifier.
A tree shaped conjunctive DL query can be rep-
resented as a tree where nodes are associated with
a set of concept names (node labels) and edges are
labelled with a relation name (edge labels). Figure
1 shows some example query trees.
</bodyText>
<subsectionHeader confidence="0.993925">
4.2 NLG architecture
</subsectionHeader>
<bodyText confidence="0.999985818181818">
Our generator takes as input two L formula: the
formula representing the current query q and the
formula representing a possible revision r (addi-
tion/deletion/modification) of q. Given this in-
put, the system architecture follows a traditional
pipeline sequencing a document planner which (i)
linearises the input query and (ii) partition the in-
put into sentence size chunks; a surface realiser
mapping each sentence size L formula into a sen-
tence; and a referring expression generator verbal-
ising NPs.
</bodyText>
<subsubsectionHeader confidence="0.896342">
4.2.1 Document Planning
</subsubsectionHeader>
<bodyText confidence="0.997555">
The document planning module linearises the in-
put query and segments the resulting linearised
</bodyText>
<page confidence="0.986477">
185
</page>
<figure confidence="0.999971333333333">
(b)
(c)
(d)
X {Man}
{Man}
livesIn
{House}
X
w
(a)
{Man}
livesIn
{House}
ownedBy
{RichPerson}
X
w
Z
{Man}
livesIn
{House,
Beautiful}
ownedBy
{RichPerson}
X
w
Z
✬
X
{Person}
ownedBy
✫
(e)
✩
{Man}
marriedTo livesIn
{House,
Beautiful}
Y w
Z
{RichPerson}
j
</figure>
<figureCaption confidence="0.999997">
Figure 1: Example of query tree and incremental query construction.
</figureCaption>
<bodyText confidence="0.986824142857143">
query into sentence size chunks.
Query Linearisation Among the different
strategies investigated in (Dongilli, 2008) to
find a good order for the content contained in a
query tree the depth-first planning, i.e. depth-first
traversal of the query tree, was found to be the
most appropriate one. Partly because it is obtained
straightforward from the query tree but mostly
due to the fact that it minimizes the changes in the
text plan that are required by incremental query
modifications. Thus, (Franconi et al., 2010a)
defines a query linearisation as a strict total order2
on the query tree that satisfies the following
conditions:
</bodyText>
<listItem confidence="0.995356166666666">
• all labels associated with the edge’s leaving
node precede the edge label
• the edge label is followed by at least one label
associated with the edge’s arriving node
• between any two labels of a node there can
only be (distinct) labels of the same node
</listItem>
<bodyText confidence="0.992192333333333">
The specific linearisation adopted in Quelo is
defined by the depth-first traversal strategy of the
query tree and a total order on the children which
is based on the query operations. That is, the la-
bels of a node are ordered according to the se-
quence applications of the add compatible
concept operation. The children of a node are
inversely ordered according to the sequence of ap-
plications of the add relation operation.
According to this linearisation definition, for
the query tree (e) in Figure 1 the following linear
order is produced:
</bodyText>
<footnote confidence="0.6479612">
(3) a. Man marriedTo Person livesIn House
Beautiful ownedBy RichPeron
2A strict total order can be obtained by fixing an order in
the children nodes and traversing the tree according to some
tree traversal strategy.
</footnote>
<bodyText confidence="0.998627166666667">
Query Segmentation Given a linearised query
q, the document planner uses some heuristics
based on the number and the types of rela-
tions/concepts present in q to output a sequence
of sub-formulae each of which will be verbalised
as a sentence.
</bodyText>
<sectionHeader confidence="0.7937415" genericHeader="method">
4.2.2 Incremental Surface Realisation and
Linearisation Constraints
</sectionHeader>
<bodyText confidence="0.999178483870968">
We now describe the main module of the generator
namely the surface realiser which supports both
the incremental refinement of a query and a min-
imal modification of the linear order between in-
crements. This surface realiser is caracterised by
the following three main features.
Grammar-Based We use a symbolic, grammar-
based approach rather than a statistical one for two
reasons. First, there is no training corpus available
that would consist of knowledge base queries and
their increments. Second, the approach must be
portable and should apply to any knowledge base
independent of the domain it covers and indepen-
dent of the presence of a training corpus. By com-
bining a lexicon automatically extracted from the
ontology with a small grammar tailored to produce
natural sounding queries, we provide a generator
which can effectively apply to any ontology with-
out requiring the construction of a training corpus.
Chart-Based A chart-based architecture en-
hances efficiency by avoiding the recomputation
of intermediate structures while allowing for a
natural implementation of the revisions (addition,
deletion, substitution) operations required by the
incremental formulation of user queries. We show
how the chart can be used to implement these op-
erations.
Beam search. As already mentioned, for er-
gonomic reasons, the linear order of the gener-
ated NL query should be minimally disturbed dur-
ing query formulation. The generation system
</bodyText>
<page confidence="0.995058">
186
</page>
<bodyText confidence="0.981129088235294">
should also be sufficiently fast to support a timely
Man/Machine interaction. We use beam search
and a customised scoring function both to preserve
linear order and to support efficiency.
We now introduce each of these components in
more details.
Feature-Based Tree Adjoining Grammar
A tree adjoining grammar (TAG) is a tuple
(Σ, N, I, A, 5) with Σ a set of terminals, N a set
of non-terminals, I a finite set of initial trees, A a
finite set of auxiliary trees, and 5 a distinguished
non-terminal (5 E N). Initial trees are trees
whose leaves are labeled with substitution nodes
(marked with a down-arrow) or with terminal
categories3. Auxiliary trees are distinguished by
a foot node (marked with a star) whose category
must be the same as that of the root node.
Two tree-composition operations are used to
combine trees: substitution and adjunction. Sub-
stitution inserts a tree onto a substitution node of
some other tree while adjunction inserts an aux-
iliary tree into a tree. In a Feature-Based Lexi-
calised TAG (FB-LTAG), tree nodes are further-
more decorated with two feature structures which
are unified during derivation; and each tree is an-
chored with a lexical item. Figure 2 shows an ex-
ample toy FB-LTAG with unification semantics.
The dotted arrows indicate possible tree combina-
tions (substitution for John, adjunction for often).
As the trees are combined, the semantics is the
union of their semantics modulo unification. Thus
given the grammar and the derivation shown, the
semantics of John often runs is as shown namely,
named(j john), run(a,j), often(a).
</bodyText>
<equation confidence="0.912555">
lv:run(a,j)
l1:named(j john), lv:run(a,j), lv:often(a)
</equation>
<figureCaption confidence="0.838181666666667">
Figure 2: Derivation and Semantics for “John often runs”
Chart-Based Surface Realisation Given an
FB-LTAG G of the type described above, sen-
tences can be generated from semantic formulae
by (i) selecting all trees in G whose semantics sub-
sumes part of the input formula and (ii) combining
</figureCaption>
<footnote confidence="0.8837825">
3For a more detailed introduction to TAG and FB-LTAG,
see (Vijay-Shanker and Joshi, 1988).
</footnote>
<bodyText confidence="0.999338733333333">
these trees using the FB-LTAG combining opera-
tions namely substitution and adjunction. Thus for
instance, in Figure 2, given the semantics l1:named(j
john), lv:run(a,j), lv:often(a), the three trees shown are
selected. When combined they produce a com-
plete phrase structure tree whose yield (John runs
often) is the generated sentence.
Following (Gardent and Perez-Beltrachini,
2011), we implement an Earley style generation
algorithm for FB-LTAG which makes use of the
fact that the derivation trees of an FB-LTAG are
context free and that an FB-LTAG can be con-
verted to a a Feature-Based Regular Tree Gram-
mar (FB-RTG) describing the derivation trees of
this FB-LTAG4.
On the one hand, this Earley algorithm en-
hances efficiency in that (i) it avoids recomput-
ing intermediate structures by storing them and
(ii) it packs locally equivalent structures into a
single representative (the most general one). Lo-
cally equivalent structures are taken to be partial
derivation trees with identical semantic coverage
and similar combinatorics (same number and type
of substitution and adjunction requirements).
On the other hand, it naturally supports the
range of revisions required for the incremental for-
mulation of ontology-based queries. Let C be the
current chart i.e., the chart built when generating a
NL query from the formal query. Then additions,
revisions and deletion can be handled as follows.
</bodyText>
<listItem confidence="0.979340352941176">
• Add concept or property X: the grammar
units selected by X are added to the agenda5
and tried for combinations with the elements
of C.
• Substitute selection X with Y : all chart items
derived from a grammar unit selected by an
element of X are removed from the chart.
Conversely, all chart items derived from a
grammar unit selected by an element of Y are
added to the agenda. All items in the agenda
are then processed until generation halts.
• Delete selection X: all chart items derived
from a grammar unit selected by an element
of X are removed from the chart. Intermedi-
ate structures that had previously used X are
moved to the agenda and the agenda is pro-
cessed until generation halts.
</listItem>
<footnote confidence="0.921313">
4For more details on this algorithm, we refer the reader to
(Gardent and Perez-Beltrachini, 2010).
5The agenda is a book keeping device which stores all
items that needs to be processed i.e., which need to be tried
for combination with elements in the chart.
</footnote>
<figure confidence="0.662878181818182">
Sb
I
�Ic VPba
1 Va
runs
VPx
often VP*x
lo:often(x)
NPj
John
l1:john(j)
</figure>
<page confidence="0.984107">
187
</page>
<bodyText confidence="0.99858125">
Beam Search To enhance efficiency and favor
those structures which best preserve the word or-
der while covering maximal input, we base our
beam search on a scoring function combining lin-
ear order and semantic coverage information. This
works as follows. First, we associate each literal
in the input query with its positional information
e.g.,
</bodyText>
<equation confidence="0.953062">
(4) a. man(x)[0] marriedTo(x y)[1]
person(y)[2] livesIn(x w)[3]
house(w)[4]
</equation>
<bodyText confidence="0.99636175">
This positional information is copied over to
each FB-LTAG tree selected by a given literal and
is then used to compute a word order cost (Cwo)
for each derived tree as follows:
</bodyText>
<equation confidence="0.997256">
Cwo(ti+j) = Cwo(ti) + Cwo(tj) + Cwo(ti + tj)
</equation>
<bodyText confidence="0.999942294117647">
That is the cost of a tree ti+j obtained by com-
bining ti and tj is the sum of the cost of each
of these trees plus the cost incurred by combin-
ing these two trees. We define this latter cost to
be proportional to the distance separating the ac-
tual position (api) of the tree (ti) being substi-
tuted/adjoined in from its required position (rpi).
If ti is substituted/adjoined at position n to the
right (left) of the anchor of a tree tj with posi-
tion pj, then the actual position of ti is pj + n
(pj − n) and the cost of combining ti with tj is
 |pj + n − rpi  |/α ( |pj − n − rpi  |/α) where
we empirically determined α to be 1006.
Finally, the total score of a tree reflects the rela-
tion between the cost of the built tree, i.e. its word
order cost, and its semantic coverage, i.e. nb. of
literals from the input semantics:
</bodyText>
<equation confidence="0.9773418">
�
−(|literals |− 1) Cwo(ti) = 0
S(ti) =
Cwo(ti)/(|literals|−
1) otherwise
</equation>
<bodyText confidence="0.904547">
6In the current implementation we assume that n = 1.
Furthermore, as ti might be a derived tree we also add to
Cwo(ti + tj) the cost computed on each tree tk used in the
derivation of ti with respect to tj.
</bodyText>
<subsectionHeader confidence="0.749">
4.2.3 Referring Expression Generation
</subsectionHeader>
<bodyText confidence="0.999992875">
The referring expression (RE) module takes as
input the sequence of phrase structure trees out-
put by the surface realiser and uses heuristics to
decide for each NP whether it should be ver-
balised as a pronoun, a definite or an indefinite
NP. These heuristics are based on the linear order
and morpho-syntactic information contained in the
phrase structure trees of the generated sentences.
</bodyText>
<sectionHeader confidence="0.964545" genericHeader="evaluation">
5 Experiments and evaluation
</sectionHeader>
<bodyText confidence="0.995827">
We conducted evaluation experiments designed to
address the following questions:
</bodyText>
<listItem confidence="0.994797416666667">
• Does the scoring mechanism appropriately
capture the ordering constraints on the gen-
erated queries ? That is, does it ensure that
the generated queries respect the strict total
order of the query tree linearisation ?
• Does our grammar based approach produce
more fluent and less ambiguous NL query
than the initial template based approach cur-
rently used by Quelo ?
• Does the automatic extraction of lexicons
from ontology support generic coverage of
arbitrary ontologies ?
</listItem>
<bodyText confidence="0.999097333333333">
We start by describing the grammar used. We
then report on the results obtained for each of these
evaluation points.
</bodyText>
<subsectionHeader confidence="0.992545">
5.1 Grammar and Lexicon
</subsectionHeader>
<bodyText confidence="0.999493269230769">
The total score is defined by cases. Those trees
with Cwo = 0 get a negative value according to
their input coverage (i.e. those that cover a larger
subset of the input semantics are favored as the
trees in the agenda are ordered by increasing total
score). Conversely, those trees with Cwo &gt; 0 get
a score that is the word order cost proportional to
the covered input.
In effect, this scoring mechanism favors trees
with low word order cost and large semantic cov-
erage. The beam search will select those trees with
lowest score.
We specify an FB-LTAG with unification seman-
tics which covers a set of basic constructions used
to formulate queries namely, active and passive
transitive verbs, adjectives, prepositional phrases,
relative and elliptical clauses, gerund and partici-
ple modifiers. The resulting grammar consists of
53 FB-LTAG pairs of syntactic trees and semantic
schema.
To ensure the appropriate syntax/semantic in-
terface, we make explicit the arguments of a
relation using the variables associated with the
nodes of the query tree. Thus for instance,
given the rightmost query tree shown in Figure
1, the flat semantics input to surface realisation is
</bodyText>
<construct confidence="0.6819605">
{Man(x), Person(y), House(w), Beautiful(w), RichPerson(z),
marriedTo(x,y), livesIn(x,w), ownedBy(w,z)}.
</construct>
<bodyText confidence="0.9973206">
For each ontology, a lexicon mapping con-
cepts and relations to FB-LTAG trees is automat-
ically derived from the ontology using (Trevisan,
2010)’s approach. We specify for each experiment
below, the size of the extracted lexicon.
</bodyText>
<page confidence="0.995513">
188
</page>
<subsectionHeader confidence="0.996584">
5.2 Linearisation
</subsectionHeader>
<bodyText confidence="0.999983166666667">
In this first experiment, we manually examined
whether the incremental algorithm we propose
supports the generation of NL queries whose word
order matches the linearisation of the input query
tree.
We created four series of queries such that each
serie is a sequence q1 ... qn where qi+1 is an in-
crement of qi. That is, qi+1 is derived from qi
by adding, removing or substituting to qi a con-
cept or a relation. The series were devised so as to
encompass the whole range of possible operations
at different points of the preceding query (e.g., at
the last node/edge or on some node/edge occur-
ring further to the left of the previous query); and
include 14 revisions on 4 initial queries.
For all queries, the word order of the best NL
query produced by the generator was found to
match the linearisation of the DL query.
</bodyText>
<subsectionHeader confidence="0.990051">
5.3 Fluency and Clarity
</subsectionHeader>
<bodyText confidence="0.982972730769231">
Following the so-called consensus model (Power
and Third, 2010), the current, template based ver-
sion of Quelo generates one clause per relation7.
Thus for instance, template-based Quelo will gen-
erate (5a) while our grammar based approach sup-
ports the generation of arguably more fluent sen-
tences such as (5b).
(5) a. I am looking for a car. Its make should
be a Land Rover. The body style of the
car should be an off-road car. The exterior
color of the car should be beige.
b. I am looking for car whose make is a Land
Rover, whose body style is an off-road car
and whose exterior color is beige.
We ran two experiments designed to assess how
fluency impacts users. The first experiment aims
to assess how Quelo template based queries are
perceived by the users in terms of clarity and flu-
ency, the second aims to compare these template
based queries with the queries produced by our
grammar-based approach.
Assessing Quelo template-based queries Us-
ing the Quelo interface, we generated a set of
41 queries chosen to capture different combina-
tions of concepts and relations. Eight persons
(four native speakers of English, four with C2
</bodyText>
<footnote confidence="0.9044115">
7This is modulo aggregation of relations. Thus two sub-
ject sharing relations may be realised in the same clause.
</footnote>
<bodyText confidence="0.999836941176471">
level of competence for foreign learners of En-
glish) were then asked to classify (a binary choice)
each query in terms of clarity and fluency. Fol-
lowing (Kow and Belz, 2012), we take Fluency
to be a single quality criterion intended to cap-
ture language quality as distinct from its meaning,
i.e. how well a piece of text reads. In contrast,
Clarity/ambiguity refers to ease of understanding
(Is the sentence easy to understand?). Taking the
average of the majority vote, we found that the
judges evaluated the queries as non fluent in 50%
of the cases and as unclear in 10% of the cases.
In other words, template based queries were found
to be disfluent about half of the time and unclear
to a lesser extent. The major observation made by
most of the participants was that the generated text
is too repetitive and lacks aggregation.
</bodyText>
<figureCaption confidence="0.999053">
Figure 3: Online Evaluation.
</figureCaption>
<bodyText confidence="0.999655611111111">
Comparing template- and grammar-based
queries In this second experiment, we asked 10
persons (all proficient in the English language) to
compare pairs of NL queries where one query is
produced using templates and the other using our
grammar-based generation algorithm. The evalu-
ation was done online using the LG-Eval toolkit
(Kow and Belz, 2012) and geared to collect rel-
ative quality judgements using visual analogue
scales. After logging in, judges were given a de-
scription of the task. The sentence pairs were dis-
played as shown in Figure 3 with one sentence to
the left and the other to the right. The judges were
instructed to move the slider to the left to favor
the sentence shown on the left side of the screen;
and to the right to favor the sentence appearing to
the right. Not moving the slider means that both
sentences rank equally. To avoid creating a bias,
</bodyText>
<page confidence="0.996821">
189
</page>
<bodyText confidence="0.999923130434783">
the sentences from both systems were equally dis-
tributed to both sides of the screen.
For this experiment, we used 14 queries built
from two ontologies, an ontology on cars and the
other on universities. The extracted lexicons for
each of these ontology contained 465 and 297 en-
tries respectively.
The results indicate that the queries generated
by the grammar based approach are perceived as
more fluent than those produced by the template
based approach (19.76 points in average for the
grammar based approach against 7.20 for the tem-
plate based approach). Furthermore, although the
template based queries are perceived as clearer
(8.57 for Quelo, 6.87 for our approach), the dif-
ference is not statistically significant (p &lt; 0.5).
Overall thus, the grammar based approach appears
to produce verbalisations that are better accepted
by the users. Concerning clarity, we observed that
longer sentences let through by document plan-
ning were often deemed unclear. In future work,
we plan to improve clarity by better integrating
document planning and sentence realisation.
</bodyText>
<subsectionHeader confidence="0.94025">
5.4 Coverage
</subsectionHeader>
<bodyText confidence="0.999972676470588">
One motivation for the symbolic based approach
was the lack of training corpus and the need for
portability: the query interface should be usable
independently of the underlying ontology and of
the existence of a training corpus. To support
coverage, we combined the grammar based ap-
proach with a lexicon which is automatically ex-
tracted from the ontology using the methodology
described in (Trevisan, 2010). When tested on
a corpus of 200 ontologies, this approach was
shown to be able to provide appropriate verbalisa-
tion templates for about 85% of the relation iden-
tifiers present in these ontologies. 12 000 relation
identifiers were extracted from the 200 ontologies
and 13 syntactic templates were found to be suf-
ficient to verbalise these relation identifiers (see
(Trevisan, 2010) for more details on this evalua-
tion).
That is, in general, the extracted lexicons permit
covering about 85% of the ontological data. In ad-
dition, we evaluated the coverage of our approach
by running the generator on 40 queries generated
from five distinct ontologies. The domains ob-
served are cinema, wines, human abilities, dis-
abilities, and assistive devices, e-commerce on the
Web, and a fishery database for observations about
an aquatic resource. The extracted lexicons con-
tained in average 453 lexical entries and the cov-
erage (proportion of DL queries for which the gen-
erator produced a NL query) was 87%.
Fuller coverage could be obtained by manually
adding lexical entries, or by developing new ways
of inducing lexical entries from ontologies (c.f.
e.g. (Walter et al., 2013)).
</bodyText>
<sectionHeader confidence="0.999173" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999975411764706">
Conceptual authoring (CA) allows the user to
query a knowledge base without having any
knowledge either of the formal representation lan-
guage used to specify that knowledge base or of
the content of the knowledge base. Although this
approach builds on a tight integration between
syntax and semantics and requires an efficient pro-
cessing of revisions, existing CA tools predomi-
nantly make use of ad hoc generation algorithms
and restricted computational grammars (e.g., Def-
inite Clause Grammars or templates). In this pa-
per, we have shown that FB-LTAG and chart based
surface realisation provide a natural framework in
which to implement conceptual authoring. In par-
ticular, we show that the chart based approach nat-
urally supports the definition of an incremental al-
gorithm for query verbalisation; and that the added
fluency provided by the grammar based approach
potentially provides for query interfaces that are
better accepted by the human evaluators.
In the future, we would like to investigate the
interaction between context, document structuring
and surface realisation. In our experiments we
found out that this interaction strongly impacts flu-
ency whereby for instance, a complex sentence
might be perceived as more fluent than several
clauses but a too long sentence will be perceived
as difficult to read (non fluent). Using data that
can now be collected using our grammar based
approach to query verbalisation and generalising
over FB-LTAG tree names rather than lemmas or
POS tags, we plan to explore how e.g., Conditional
Random Fields can be used to model these inter-
actions.
</bodyText>
<sectionHeader confidence="0.998843" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9999852">
We would like to thank Marco Trevisan, Paolo
Guagliardo and Alexandre Denis for facilitating
the access to the libraries they developed and to
Natalia Korchagina and the judges who partici-
pated in the evaluation experiments.
</bodyText>
<page confidence="0.996077">
190
</page>
<sectionHeader confidence="0.99588" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999926479591837">
Franz Baader. 2003. The description logic handbook:
theory, implementation, and applications. Cam-
bridge university press.
Nina Dethlefs, Helen Hastie, Heriberto Cuay´ahuitl, and
Oliver Lemon. 2013. Conditional Random Fields
for Responsive Surface Realisation using Global
Features. Proceedings ofACL, Sofia, Bulgaria.
Paolo Dongilli. 2008. Natural language rendering of a
conjunctive query. KRDB Research Centre Techni-
cal Report No. KRDB08-3). Bozen, IT: Free Univer-
sity of Bozen-Bolzano, 2:5.
E. Franconi, P. Guagliardo, and M. Trevisan. 2010a.
An intelligent query interface based on ontology
navigation. In Workshop on Visual Interfaces to the
Social and Semantic Web, VISSW, volume 10. Cite-
seer.
E. Franconi, P. Guagliardo, and M. Trevisan. 2010b.
Quelo: a NL-based intelligent query interface. In
Pre-Proceedings of the Second Workshop on Con-
trolled Natural Languages, volume 622.
E. Franconi, P. Guagliardo, S. Tessaris, and M. Tre-
visan. 2011a. A natural language ontology-driven
query interface. In 9th International Conference on
Terminology and Artificial Intelligence, page 43.
E. Franconi, P. Guagliardo, M. Trevisan, and S. Tes-
saris. 2011b. Quelo: an Ontology-Driven Query
Interface. In Description Logics.
C. Gardent and L. Perez-Beltrachini. 2010. RTG based
Surface Realisation for TAG. In COLING’10, Bei-
jing, China.
B. Gottesman Gardent, C. and L. Perez-Beltrachini.
2011. Using regular tree grammar to enhance sur-
face realisation. Natural Language Engineering,
17:185–201. Special Issue on Finite State Methods
and Models in Natural Language Processing.
Paolo Guagliardo. 2009. Theoretical foundations of
an ontology-based visual tool for query formulation
support. Technical report, KRDB Research Centre,
Free University of Bozen-Bolzano, October.
C. Hallett, D. Scott, and R. Power. 2007. Composing
questions through conceptual authoring. Computa-
tional Linguistics, 33(1):105–133.
Eric Kow and Anja Belz. 2012. LG-Eval: A Toolkit
for Creating Online Language Evaluation Experi-
ments. In LREC, pages 4033–4037.
Alice H Oh and Alexander I Rudnicky. 2000. Stochas-
tic language generation for spoken dialogue sys-
tems. In Proceedings of the 2000 ANLP/NAACL
Workshop on Conversational systems-Volume 3,
pages 27–32. Association for Computational Lin-
guistics.
R. Power and A. Third. 2010. Expressing owl ax-
ioms by english sentences: dubious in theory, fea-
sible in practice. In Proceedings of the 23rd Inter-
national Conference on Computational Linguistics:
Posters, pages 1006–1013. Association for Compu-
tational Linguistics.
David Schlangen and Gabriel Skantze. 2009. A gen-
eral, abstract model of incremental dialogue pro-
cessing. In Proceedings of the 12th Conference of
the European Chapter of the Association for Com-
putational Linguistics, pages 710–718. Association
for Computational Linguistics.
David Schlangen, Timo Baumann, and Michaela At-
terer. 2009. Incremental reference resolution: The
task, metrics for evaluation, and a bayesian filtering
model that is sensitive to disfluencies. In Proceed-
ings of the SIGDIAL 2009 Conference: The 10th An-
nual Meeting of the Special Interest Group on Dis-
course and Dialogue, pages 30–37. Association for
Computational Linguistics.
H. R Tennant, K. M Ross, R. M Saenz, C. W Thomp-
son, and J. R Miller. 1983. Menu-based natural lan-
guage understanding. In Proceedings of the 21st an-
nual meeting on Association for Computational Lin-
guistics, pages 151–158. Association for Computa-
tional Linguistics.
Marco Trevisan. 2010. A Portable Menuguided Nat-
ural Language Interface to Knowledge Bases for
Querytool. Ph.D. thesis, Masters thesis, Free Uni-
versity of Bozen-Bolzano (Italy) and University of
Groningen (Netherlands).
K. Vijay-Shanker and A. Joshi. 1988. Feature based
tags. In Proceedings of the 12th International Con-
ference of the Association for Computational Lin-
guistics, pages 573–577, Budapest.
Holger Wache, Thomas Voegele, Ubbo Visser, Heiner
Stuckenschmidt, Gerhard Schuster, Holger Neu-
mann, and Sebastian H¨ubner. 2001. Ontology-
based integration of information-a survey of existing
approaches. In IJCAI-01 workshop: ontologies and
information sharing, volume 2001, pages 108–117.
Citeseer.
Sebastian Walter, Christina Unger, and Philipp Cimi-
ano. 2013. A corpus-based approach for the induc-
tion of ontology lexica. In Natural Language Pro-
cessing and Information Systems, pages 102–113.
Springer.
</reference>
<page confidence="0.998472">
191
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.214974">
<title confidence="0.999321">Incremental Query Generation</title>
<author confidence="0.7476255">Claire Nancy</author>
<author confidence="0.7476255">France</author>
<email confidence="0.968444">claire.gardent@loria.fr</email>
<author confidence="0.630881">Laura</author>
<affiliation confidence="0.9939685">Faculty of Computer Free University of</affiliation>
<address confidence="0.965856">Bozen-Bolzano, Italy</address>
<email confidence="0.995665">laura.perez@loria.fr</email>
<author confidence="0.828261">Enrico</author>
<affiliation confidence="0.995327">Faculty of Computer Free University of</affiliation>
<address confidence="0.953935">Bozen-Bolzano, Italy</address>
<email confidence="0.999438">franconi@inf.unibz.it</email>
<abstract confidence="0.991479888888889">We present a natural language generation system which supports the incremental specification of ontology-based queries in natural language. Our contribution is two fold. First, we introduce a chart based surface realisation algorithm which supports the kind of incremental processing required by ontology-based querying. Crucially, this algorithm avoids confusing the end user by preserving a consistent ordering of the query elements throughout the incremental query formulation process. Second, we show that grammar based surface realisation better supports the generation of fluent, natural sounding queries than previous template-based approaches.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Franz Baader</author>
</authors>
<title>The description logic handbook: theory, implementation, and applications. Cambridge university press.</title>
<date>2003</date>
<contexts>
<context position="8817" citStr="Baader, 2003" startWordPosition="1388" endWordPosition="1389">rrent query q at point p. The task of the generator is then to produce a natural language sentence for each new formal query q′ ∈ rev(q) which results from this revision process. In other words, each time the user refines a query q to produce a new query q′, the system computes all revisions rev(q) of q′ that are compatible with the underlying knowledge base using a reasoner. Each of these possible revisions is then input to the generator and the resulting revised NL queries are displayed to the user. In what follows, 184 we assume that formal queries are represented using Description Logics (Baader, 2003). The following examples show a possible sequence of NL queries, their corresponding DL representation and the operations provided by Quelo that can be performed on a query (bold face is used to indicate the point in the query at which the next revision takes place). For instance, the query in (1c) results from adding the concept Young to the query underlying (1b) at the point highlighted by man. (1) a. I am looking for something (initial query) T b. I am looking for a man (substitute concept) Man c. I am looking for a young man (add compatible concept) Man n Young d. I am looking for a young </context>
</contexts>
<marker>Baader, 2003</marker>
<rawString>Franz Baader. 2003. The description logic handbook: theory, implementation, and applications. Cambridge university press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nina Dethlefs</author>
<author>Helen Hastie</author>
<author>Heriberto Cuay´ahuitl</author>
<author>Oliver Lemon</author>
</authors>
<title>Conditional Random Fields for Responsive Surface Realisation using Global Features.</title>
<date>2013</date>
<booktitle>Proceedings ofACL,</booktitle>
<location>Sofia, Bulgaria.</location>
<marker>Dethlefs, Hastie, Cuay´ahuitl, Lemon, 2013</marker>
<rawString>Nina Dethlefs, Helen Hastie, Heriberto Cuay´ahuitl, and Oliver Lemon. 2013. Conditional Random Fields for Responsive Surface Realisation using Global Features. Proceedings ofACL, Sofia, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paolo Dongilli</author>
</authors>
<title>Natural language rendering of a conjunctive query. KRDB Research Centre</title>
<date>2008</date>
<tech>Technical Report No. KRDB08-3). Bozen, IT:</tech>
<pages>2--5</pages>
<institution>Free University of Bozen-Bolzano,</institution>
<contexts>
<context position="13218" citStr="Dongilli, 2008" startWordPosition="2134" endWordPosition="2135">e; and a referring expression generator verbalising NPs. 4.2.1 Document Planning The document planning module linearises the input query and segments the resulting linearised 185 (b) (c) (d) X {Man} {Man} livesIn {House} X w (a) {Man} livesIn {House} ownedBy {RichPerson} X w Z {Man} livesIn {House, Beautiful} ownedBy {RichPerson} X w Z ✬ X {Person} ownedBy ✫ (e) ✩ {Man} marriedTo livesIn {House, Beautiful} Y w Z {RichPerson} j Figure 1: Example of query tree and incremental query construction. query into sentence size chunks. Query Linearisation Among the different strategies investigated in (Dongilli, 2008) to find a good order for the content contained in a query tree the depth-first planning, i.e. depth-first traversal of the query tree, was found to be the most appropriate one. Partly because it is obtained straightforward from the query tree but mostly due to the fact that it minimizes the changes in the text plan that are required by incremental query modifications. Thus, (Franconi et al., 2010a) defines a query linearisation as a strict total order2 on the query tree that satisfies the following conditions: • all labels associated with the edge’s leaving node precede the edge label • the e</context>
</contexts>
<marker>Dongilli, 2008</marker>
<rawString>Paolo Dongilli. 2008. Natural language rendering of a conjunctive query. KRDB Research Centre Technical Report No. KRDB08-3). Bozen, IT: Free University of Bozen-Bolzano, 2:5.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Franconi</author>
<author>P Guagliardo</author>
<author>M Trevisan</author>
</authors>
<title>An intelligent query interface based on ontology navigation.</title>
<date>2010</date>
<booktitle>In Workshop on Visual Interfaces to the Social and Semantic Web, VISSW,</booktitle>
<volume>10</volume>
<publisher>Citeseer.</publisher>
<contexts>
<context position="2205" citStr="Franconi et al., 2010" startWordPosition="318" endWordPosition="321">ser to formulate a query without any knowledge either of the formal languages used to specify ontologies, or of the content of the ontology being used. Following the conceptual authoring approach described in (Tennant et al., 1983; Hallett et al., 2007), this interface masks the composition of a formal query 1krdbapp.inf.unibz.it:8080/quelo as the composition of an English text describing the equivalent information needs using natural language generation techniques. The natural language generation system that we propose for Quelo’s NL interface departs from similar work (Hallett et al., 2007; Franconi et al., 2010a; Franconi et al., 2011b; Franconi et al., 2010b; Franconi et al., 2011a) in that it makes use of standard grammar based surface realisation techniques. Our contribution is two fold. First, we introduce a chart based surface realisation algorithm which supports the kind of incremental processing required by ontology driven query formulation. Crucially, this algorithm avoids confusing the end user by preserving a consistent ordering of the query elements throughout the incremental query formulation process. Second, we show that grammar based surface realisation better supports the generation o</context>
<context position="6858" citStr="Franconi et al., 2010" startWordPosition="1058" endWordPosition="1061"> query which supports revision and additions at arbitrary points of the query being built; generates natural sounding text; and maximally preserves the linear order of the query. Conceptual authoring Our proposal is closely related to the conceptual authoring approach described in (Hallett et al., 2007). In this approach, a text generated from a knowledge base, describes in natural language the knowledge encoded so far, and the options for extending it. Starting with an initial very general query (e.g., all things), the user can formulate a query by choosing between these options. Similarly, (Franconi et al., 2010a; Franconi et al., 2011b; Franconi et al., 2010b; Franconi et al., 2011a) describes a conceptual authoring approach to querying semantic data where in addition , logical inference is used to semantically constrain the possible completions/revisions displayed to the user. Our approach departs from this work in that it makes use of standard grammars and algorithms. While previous work was based on procedures and templates, we rely on a Feature-Based Tree Adjoining Grammar to capture the link between text and semantics required by conceptual authoring; and we adapt a chart based algorithm to sup</context>
<context position="11226" citStr="Franconi et al., 2010" startWordPosition="1798" endWordPosition="1801"> on Diesel and is equipped with air conditioning c. A car which is equipped with air conditioning and runs on Diesel In what follows, we describe the generation algorithm used to verbalise possible extensions of user queries as proposed by the Quelo tool. We start by introducing and motivating the underlying formal language supported by Quelo and the input to the generator. We then describe the overall architecture of our generator. Finally, we present the incremental surface realisation algorithm supporting the verbalisation of the possible query extensions. 4.1 The Input Language Following (Franconi et al., 2010a; Franconi et al., 2011b; Franconi et al., 2010b; Franconi et al., 2011a) we assume a formal language for queries that targets the querying of various knowledge and data bases independent of their specification language. To this end, it uses a minimal query language L that is shared by most knowledge representation languages and is supported by Description Logic (DL) reasoners namely, the language of tree shaped conjunctive DL queries. Let R be a set of relations and C be a set of concepts, then the language of tree-shaped conjunctive DL queries is defined as follows: 5 ::= C |IR.(5) |5 n 5 w</context>
<context position="13618" citStr="Franconi et al., 2010" startWordPosition="2200" endWordPosition="2203">use, Beautiful} Y w Z {RichPerson} j Figure 1: Example of query tree and incremental query construction. query into sentence size chunks. Query Linearisation Among the different strategies investigated in (Dongilli, 2008) to find a good order for the content contained in a query tree the depth-first planning, i.e. depth-first traversal of the query tree, was found to be the most appropriate one. Partly because it is obtained straightforward from the query tree but mostly due to the fact that it minimizes the changes in the text plan that are required by incremental query modifications. Thus, (Franconi et al., 2010a) defines a query linearisation as a strict total order2 on the query tree that satisfies the following conditions: • all labels associated with the edge’s leaving node precede the edge label • the edge label is followed by at least one label associated with the edge’s arriving node • between any two labels of a node there can only be (distinct) labels of the same node The specific linearisation adopted in Quelo is defined by the depth-first traversal strategy of the query tree and a total order on the children which is based on the query operations. That is, the labels of a node are ordered </context>
</contexts>
<marker>Franconi, Guagliardo, Trevisan, 2010</marker>
<rawString>E. Franconi, P. Guagliardo, and M. Trevisan. 2010a. An intelligent query interface based on ontology navigation. In Workshop on Visual Interfaces to the Social and Semantic Web, VISSW, volume 10. Citeseer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Franconi</author>
<author>P Guagliardo</author>
<author>M Trevisan</author>
</authors>
<title>Quelo: a NL-based intelligent query interface.</title>
<date>2010</date>
<booktitle>In Pre-Proceedings of the Second Workshop on Controlled Natural Languages,</booktitle>
<volume>volume</volume>
<pages>622</pages>
<contexts>
<context position="2205" citStr="Franconi et al., 2010" startWordPosition="318" endWordPosition="321">ser to formulate a query without any knowledge either of the formal languages used to specify ontologies, or of the content of the ontology being used. Following the conceptual authoring approach described in (Tennant et al., 1983; Hallett et al., 2007), this interface masks the composition of a formal query 1krdbapp.inf.unibz.it:8080/quelo as the composition of an English text describing the equivalent information needs using natural language generation techniques. The natural language generation system that we propose for Quelo’s NL interface departs from similar work (Hallett et al., 2007; Franconi et al., 2010a; Franconi et al., 2011b; Franconi et al., 2010b; Franconi et al., 2011a) in that it makes use of standard grammar based surface realisation techniques. Our contribution is two fold. First, we introduce a chart based surface realisation algorithm which supports the kind of incremental processing required by ontology driven query formulation. Crucially, this algorithm avoids confusing the end user by preserving a consistent ordering of the query elements throughout the incremental query formulation process. Second, we show that grammar based surface realisation better supports the generation o</context>
<context position="6858" citStr="Franconi et al., 2010" startWordPosition="1058" endWordPosition="1061"> query which supports revision and additions at arbitrary points of the query being built; generates natural sounding text; and maximally preserves the linear order of the query. Conceptual authoring Our proposal is closely related to the conceptual authoring approach described in (Hallett et al., 2007). In this approach, a text generated from a knowledge base, describes in natural language the knowledge encoded so far, and the options for extending it. Starting with an initial very general query (e.g., all things), the user can formulate a query by choosing between these options. Similarly, (Franconi et al., 2010a; Franconi et al., 2011b; Franconi et al., 2010b; Franconi et al., 2011a) describes a conceptual authoring approach to querying semantic data where in addition , logical inference is used to semantically constrain the possible completions/revisions displayed to the user. Our approach departs from this work in that it makes use of standard grammars and algorithms. While previous work was based on procedures and templates, we rely on a Feature-Based Tree Adjoining Grammar to capture the link between text and semantics required by conceptual authoring; and we adapt a chart based algorithm to sup</context>
<context position="11226" citStr="Franconi et al., 2010" startWordPosition="1798" endWordPosition="1801"> on Diesel and is equipped with air conditioning c. A car which is equipped with air conditioning and runs on Diesel In what follows, we describe the generation algorithm used to verbalise possible extensions of user queries as proposed by the Quelo tool. We start by introducing and motivating the underlying formal language supported by Quelo and the input to the generator. We then describe the overall architecture of our generator. Finally, we present the incremental surface realisation algorithm supporting the verbalisation of the possible query extensions. 4.1 The Input Language Following (Franconi et al., 2010a; Franconi et al., 2011b; Franconi et al., 2010b; Franconi et al., 2011a) we assume a formal language for queries that targets the querying of various knowledge and data bases independent of their specification language. To this end, it uses a minimal query language L that is shared by most knowledge representation languages and is supported by Description Logic (DL) reasoners namely, the language of tree shaped conjunctive DL queries. Let R be a set of relations and C be a set of concepts, then the language of tree-shaped conjunctive DL queries is defined as follows: 5 ::= C |IR.(5) |5 n 5 w</context>
<context position="13618" citStr="Franconi et al., 2010" startWordPosition="2200" endWordPosition="2203">use, Beautiful} Y w Z {RichPerson} j Figure 1: Example of query tree and incremental query construction. query into sentence size chunks. Query Linearisation Among the different strategies investigated in (Dongilli, 2008) to find a good order for the content contained in a query tree the depth-first planning, i.e. depth-first traversal of the query tree, was found to be the most appropriate one. Partly because it is obtained straightforward from the query tree but mostly due to the fact that it minimizes the changes in the text plan that are required by incremental query modifications. Thus, (Franconi et al., 2010a) defines a query linearisation as a strict total order2 on the query tree that satisfies the following conditions: • all labels associated with the edge’s leaving node precede the edge label • the edge label is followed by at least one label associated with the edge’s arriving node • between any two labels of a node there can only be (distinct) labels of the same node The specific linearisation adopted in Quelo is defined by the depth-first traversal strategy of the query tree and a total order on the children which is based on the query operations. That is, the labels of a node are ordered </context>
</contexts>
<marker>Franconi, Guagliardo, Trevisan, 2010</marker>
<rawString>E. Franconi, P. Guagliardo, and M. Trevisan. 2010b. Quelo: a NL-based intelligent query interface. In Pre-Proceedings of the Second Workshop on Controlled Natural Languages, volume 622.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Franconi</author>
<author>P Guagliardo</author>
<author>S Tessaris</author>
<author>M Trevisan</author>
</authors>
<title>A natural language ontology-driven query interface.</title>
<date>2011</date>
<booktitle>In 9th International Conference on Terminology and Artificial Intelligence,</booktitle>
<pages>43</pages>
<contexts>
<context position="2229" citStr="Franconi et al., 2011" startWordPosition="322" endWordPosition="326"> without any knowledge either of the formal languages used to specify ontologies, or of the content of the ontology being used. Following the conceptual authoring approach described in (Tennant et al., 1983; Hallett et al., 2007), this interface masks the composition of a formal query 1krdbapp.inf.unibz.it:8080/quelo as the composition of an English text describing the equivalent information needs using natural language generation techniques. The natural language generation system that we propose for Quelo’s NL interface departs from similar work (Hallett et al., 2007; Franconi et al., 2010a; Franconi et al., 2011b; Franconi et al., 2010b; Franconi et al., 2011a) in that it makes use of standard grammar based surface realisation techniques. Our contribution is two fold. First, we introduce a chart based surface realisation algorithm which supports the kind of incremental processing required by ontology driven query formulation. Crucially, this algorithm avoids confusing the end user by preserving a consistent ordering of the query elements throughout the incremental query formulation process. Second, we show that grammar based surface realisation better supports the generation of fluent, natural soundi</context>
<context position="6882" citStr="Franconi et al., 2011" startWordPosition="1062" endWordPosition="1066">vision and additions at arbitrary points of the query being built; generates natural sounding text; and maximally preserves the linear order of the query. Conceptual authoring Our proposal is closely related to the conceptual authoring approach described in (Hallett et al., 2007). In this approach, a text generated from a knowledge base, describes in natural language the knowledge encoded so far, and the options for extending it. Starting with an initial very general query (e.g., all things), the user can formulate a query by choosing between these options. Similarly, (Franconi et al., 2010a; Franconi et al., 2011b; Franconi et al., 2010b; Franconi et al., 2011a) describes a conceptual authoring approach to querying semantic data where in addition , logical inference is used to semantically constrain the possible completions/revisions displayed to the user. Our approach departs from this work in that it makes use of standard grammars and algorithms. While previous work was based on procedures and templates, we rely on a Feature-Based Tree Adjoining Grammar to capture the link between text and semantics required by conceptual authoring; and we adapt a chart based algorithm to support the addition, the r</context>
<context position="11250" citStr="Franconi et al., 2011" startWordPosition="1802" endWordPosition="1805">ed with air conditioning c. A car which is equipped with air conditioning and runs on Diesel In what follows, we describe the generation algorithm used to verbalise possible extensions of user queries as proposed by the Quelo tool. We start by introducing and motivating the underlying formal language supported by Quelo and the input to the generator. We then describe the overall architecture of our generator. Finally, we present the incremental surface realisation algorithm supporting the verbalisation of the possible query extensions. 4.1 The Input Language Following (Franconi et al., 2010a; Franconi et al., 2011b; Franconi et al., 2010b; Franconi et al., 2011a) we assume a formal language for queries that targets the querying of various knowledge and data bases independent of their specification language. To this end, it uses a minimal query language L that is shared by most knowledge representation languages and is supported by Description Logic (DL) reasoners namely, the language of tree shaped conjunctive DL queries. Let R be a set of relations and C be a set of concepts, then the language of tree-shaped conjunctive DL queries is defined as follows: 5 ::= C |IR.(5) |5 n 5 where R E R, C E C, n den</context>
</contexts>
<marker>Franconi, Guagliardo, Tessaris, Trevisan, 2011</marker>
<rawString>E. Franconi, P. Guagliardo, S. Tessaris, and M. Trevisan. 2011a. A natural language ontology-driven query interface. In 9th International Conference on Terminology and Artificial Intelligence, page 43.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Franconi</author>
<author>P Guagliardo</author>
<author>M Trevisan</author>
<author>S Tessaris</author>
</authors>
<title>Quelo: an Ontology-Driven Query Interface. In Description Logics.</title>
<date>2011</date>
<contexts>
<context position="2229" citStr="Franconi et al., 2011" startWordPosition="322" endWordPosition="326"> without any knowledge either of the formal languages used to specify ontologies, or of the content of the ontology being used. Following the conceptual authoring approach described in (Tennant et al., 1983; Hallett et al., 2007), this interface masks the composition of a formal query 1krdbapp.inf.unibz.it:8080/quelo as the composition of an English text describing the equivalent information needs using natural language generation techniques. The natural language generation system that we propose for Quelo’s NL interface departs from similar work (Hallett et al., 2007; Franconi et al., 2010a; Franconi et al., 2011b; Franconi et al., 2010b; Franconi et al., 2011a) in that it makes use of standard grammar based surface realisation techniques. Our contribution is two fold. First, we introduce a chart based surface realisation algorithm which supports the kind of incremental processing required by ontology driven query formulation. Crucially, this algorithm avoids confusing the end user by preserving a consistent ordering of the query elements throughout the incremental query formulation process. Second, we show that grammar based surface realisation better supports the generation of fluent, natural soundi</context>
<context position="6882" citStr="Franconi et al., 2011" startWordPosition="1062" endWordPosition="1066">vision and additions at arbitrary points of the query being built; generates natural sounding text; and maximally preserves the linear order of the query. Conceptual authoring Our proposal is closely related to the conceptual authoring approach described in (Hallett et al., 2007). In this approach, a text generated from a knowledge base, describes in natural language the knowledge encoded so far, and the options for extending it. Starting with an initial very general query (e.g., all things), the user can formulate a query by choosing between these options. Similarly, (Franconi et al., 2010a; Franconi et al., 2011b; Franconi et al., 2010b; Franconi et al., 2011a) describes a conceptual authoring approach to querying semantic data where in addition , logical inference is used to semantically constrain the possible completions/revisions displayed to the user. Our approach departs from this work in that it makes use of standard grammars and algorithms. While previous work was based on procedures and templates, we rely on a Feature-Based Tree Adjoining Grammar to capture the link between text and semantics required by conceptual authoring; and we adapt a chart based algorithm to support the addition, the r</context>
<context position="11250" citStr="Franconi et al., 2011" startWordPosition="1802" endWordPosition="1805">ed with air conditioning c. A car which is equipped with air conditioning and runs on Diesel In what follows, we describe the generation algorithm used to verbalise possible extensions of user queries as proposed by the Quelo tool. We start by introducing and motivating the underlying formal language supported by Quelo and the input to the generator. We then describe the overall architecture of our generator. Finally, we present the incremental surface realisation algorithm supporting the verbalisation of the possible query extensions. 4.1 The Input Language Following (Franconi et al., 2010a; Franconi et al., 2011b; Franconi et al., 2010b; Franconi et al., 2011a) we assume a formal language for queries that targets the querying of various knowledge and data bases independent of their specification language. To this end, it uses a minimal query language L that is shared by most knowledge representation languages and is supported by Description Logic (DL) reasoners namely, the language of tree shaped conjunctive DL queries. Let R be a set of relations and C be a set of concepts, then the language of tree-shaped conjunctive DL queries is defined as follows: 5 ::= C |IR.(5) |5 n 5 where R E R, C E C, n den</context>
</contexts>
<marker>Franconi, Guagliardo, Trevisan, Tessaris, 2011</marker>
<rawString>E. Franconi, P. Guagliardo, M. Trevisan, and S. Tessaris. 2011b. Quelo: an Ontology-Driven Query Interface. In Description Logics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Gardent</author>
<author>L Perez-Beltrachini</author>
</authors>
<title>RTG based Surface Realisation for TAG.</title>
<date>2010</date>
<booktitle>In COLING’10,</booktitle>
<location>Beijing, China.</location>
<contexts>
<context position="20705" citStr="Gardent and Perez-Beltrachini, 2010" startWordPosition="3353" endWordPosition="3356">on X with Y : all chart items derived from a grammar unit selected by an element of X are removed from the chart. Conversely, all chart items derived from a grammar unit selected by an element of Y are added to the agenda. All items in the agenda are then processed until generation halts. • Delete selection X: all chart items derived from a grammar unit selected by an element of X are removed from the chart. Intermediate structures that had previously used X are moved to the agenda and the agenda is processed until generation halts. 4For more details on this algorithm, we refer the reader to (Gardent and Perez-Beltrachini, 2010). 5The agenda is a book keeping device which stores all items that needs to be processed i.e., which need to be tried for combination with elements in the chart. Sb I �Ic VPba 1 Va runs VPx often VP*x lo:often(x) NPj John l1:john(j) 187 Beam Search To enhance efficiency and favor those structures which best preserve the word order while covering maximal input, we base our beam search on a scoring function combining linear order and semantic coverage information. This works as follows. First, we associate each literal in the input query with its positional information e.g., (4) a. man(x)[0] mar</context>
</contexts>
<marker>Gardent, Perez-Beltrachini, 2010</marker>
<rawString>C. Gardent and L. Perez-Beltrachini. 2010. RTG based Surface Realisation for TAG. In COLING’10, Beijing, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Gottesman Gardent</author>
<author>C</author>
<author>L Perez-Beltrachini</author>
</authors>
<title>Using regular tree grammar to enhance surface realisation.</title>
<date>2011</date>
<journal>Natural Language Engineering,</journal>
<booktitle>Special Issue on Finite State Methods and Models in Natural Language Processing.</booktitle>
<pages>17--185</pages>
<marker>Gardent, C, Perez-Beltrachini, 2011</marker>
<rawString>B. Gottesman Gardent, C. and L. Perez-Beltrachini. 2011. Using regular tree grammar to enhance surface realisation. Natural Language Engineering, 17:185–201. Special Issue on Finite State Methods and Models in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paolo Guagliardo</author>
</authors>
<title>Theoretical foundations of an ontology-based visual tool for query formulation support.</title>
<date>2009</date>
<tech>Technical report,</tech>
<institution>KRDB Research Centre, Free University of Bozen-Bolzano,</institution>
<contexts>
<context position="8115" citStr="Guagliardo, 2009" startWordPosition="1264" endWordPosition="1265">substitution of input material. To avoid confusing the user, we additionally introduce a scoring function which helps preserve the linear order of the NL query. The generation system we present is in fact integrated in the Quelo interface developed by (Franconi et al., 2011a) and compared with their previous template-based approach. 3 Incremental Generation of Candidate Query Extensions The generation task we address is the following. Given a knowledge base K, some initial formal query q and a focus point p in that query, the reasoning services supported by Quelo’s query logic framework (see (Guagliardo, 2009)) will compute a set of new queries rev(q) formed by adding, deleting and revising the current query q at point p. The task of the generator is then to produce a natural language sentence for each new formal query q′ ∈ rev(q) which results from this revision process. In other words, each time the user refines a query q to produce a new query q′, the system computes all revisions rev(q) of q′ that are compatible with the underlying knowledge base using a reasoner. Each of these possible revisions is then input to the generator and the resulting revised NL queries are displayed to the user. In w</context>
</contexts>
<marker>Guagliardo, 2009</marker>
<rawString>Paolo Guagliardo. 2009. Theoretical foundations of an ontology-based visual tool for query formulation support. Technical report, KRDB Research Centre, Free University of Bozen-Bolzano, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Hallett</author>
<author>D Scott</author>
<author>R Power</author>
</authors>
<title>Composing questions through conceptual authoring.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>1</issue>
<contexts>
<context position="1837" citStr="Hallett et al., 2007" startWordPosition="265" endWordPosition="268">pport the final user in querying them, thus improving the usability of the integrated system. To support the wide access to these data sources, it is crucial to develop efficient and user-friendly ways to query them (Wache et al., 2001). In this paper, we present a Natural Language (NL) interface of an ontology-based query tool, called Quelo1, which allows the end user to formulate a query without any knowledge either of the formal languages used to specify ontologies, or of the content of the ontology being used. Following the conceptual authoring approach described in (Tennant et al., 1983; Hallett et al., 2007), this interface masks the composition of a formal query 1krdbapp.inf.unibz.it:8080/quelo as the composition of an English text describing the equivalent information needs using natural language generation techniques. The natural language generation system that we propose for Quelo’s NL interface departs from similar work (Hallett et al., 2007; Franconi et al., 2010a; Franconi et al., 2011b; Franconi et al., 2010b; Franconi et al., 2011a) in that it makes use of standard grammar based surface realisation techniques. Our contribution is two fold. First, we introduce a chart based surface realis</context>
<context position="6541" citStr="Hallett et al., 2007" startWordPosition="1007" endWordPosition="1010">lar, at developing dialog systems where processing starts before the input is complete. In these approaches, the focus is on developing efficient architectures which support the timely interleaving of parsing and generation. Instead, our aim is to develop a principled approach to the incremental generation of a user query which supports revision and additions at arbitrary points of the query being built; generates natural sounding text; and maximally preserves the linear order of the query. Conceptual authoring Our proposal is closely related to the conceptual authoring approach described in (Hallett et al., 2007). In this approach, a text generated from a knowledge base, describes in natural language the knowledge encoded so far, and the options for extending it. Starting with an initial very general query (e.g., all things), the user can formulate a query by choosing between these options. Similarly, (Franconi et al., 2010a; Franconi et al., 2011b; Franconi et al., 2010b; Franconi et al., 2011a) describes a conceptual authoring approach to querying semantic data where in addition , logical inference is used to semantically constrain the possible completions/revisions displayed to the user. Our approa</context>
</contexts>
<marker>Hallett, Scott, Power, 2007</marker>
<rawString>C. Hallett, D. Scott, and R. Power. 2007. Composing questions through conceptual authoring. Computational Linguistics, 33(1):105–133.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Kow</author>
<author>Anja Belz</author>
</authors>
<title>LG-Eval: A Toolkit for Creating Online Language Evaluation Experiments. In</title>
<date>2012</date>
<booktitle>LREC,</booktitle>
<pages>4033--4037</pages>
<contexts>
<context position="27628" citStr="Kow and Belz, 2012" startWordPosition="4542" endWordPosition="4545">nd aims to compare these template based queries with the queries produced by our grammar-based approach. Assessing Quelo template-based queries Using the Quelo interface, we generated a set of 41 queries chosen to capture different combinations of concepts and relations. Eight persons (four native speakers of English, four with C2 7This is modulo aggregation of relations. Thus two subject sharing relations may be realised in the same clause. level of competence for foreign learners of English) were then asked to classify (a binary choice) each query in terms of clarity and fluency. Following (Kow and Belz, 2012), we take Fluency to be a single quality criterion intended to capture language quality as distinct from its meaning, i.e. how well a piece of text reads. In contrast, Clarity/ambiguity refers to ease of understanding (Is the sentence easy to understand?). Taking the average of the majority vote, we found that the judges evaluated the queries as non fluent in 50% of the cases and as unclear in 10% of the cases. In other words, template based queries were found to be disfluent about half of the time and unclear to a lesser extent. The major observation made by most of the participants was that </context>
</contexts>
<marker>Kow, Belz, 2012</marker>
<rawString>Eric Kow and Anja Belz. 2012. LG-Eval: A Toolkit for Creating Online Language Evaluation Experiments. In LREC, pages 4033–4037.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alice H Oh</author>
<author>Alexander I Rudnicky</author>
</authors>
<title>Stochastic language generation for spoken dialogue systems.</title>
<date>2000</date>
<booktitle>In Proceedings of the 2000 ANLP/NAACL Workshop on Conversational systems-Volume 3,</booktitle>
<pages>27--32</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="3648" citStr="Oh and Rudnicky, 2000" startWordPosition="543" endWordPosition="546">ly, ontology driven query formulation. It introduces the input being handled, the constraints under which generation operates and the operations the user may perform to build her query. In Section 4, we present the generation algorithm used to support the verbalisation of possible queries. Section 5 reports on an evaluation of the system with respect to fluency, clarity, coverage and incrementality. Section 6 concludes with pointers for further research. 2 Related Work Our approach is related to two main strands of work: incremental generation and conceptual authoring. Incremental Generation (Oh and Rudnicky, 2000) used an n-gram language model to stochas183 Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 183–191, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics tically generate system turns. The language model is trained on a dialog corpus manually annotated with word and utterance classes. The generation engine uses the appropriate language model for the utterance class and generates word sequences randomly according to the language model distribution. The generated word sequences are then ranked u</context>
</contexts>
<marker>Oh, Rudnicky, 2000</marker>
<rawString>Alice H Oh and Alexander I Rudnicky. 2000. Stochastic language generation for spoken dialogue systems. In Proceedings of the 2000 ANLP/NAACL Workshop on Conversational systems-Volume 3, pages 27–32. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Power</author>
<author>A Third</author>
</authors>
<title>Expressing owl axioms by english sentences: dubious in theory, feasible in practice.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics: Posters,</booktitle>
<pages>1006--1013</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="26269" citStr="Power and Third, 2010" startWordPosition="4305" endWordPosition="4308">+1 is an increment of qi. That is, qi+1 is derived from qi by adding, removing or substituting to qi a concept or a relation. The series were devised so as to encompass the whole range of possible operations at different points of the preceding query (e.g., at the last node/edge or on some node/edge occurring further to the left of the previous query); and include 14 revisions on 4 initial queries. For all queries, the word order of the best NL query produced by the generator was found to match the linearisation of the DL query. 5.3 Fluency and Clarity Following the so-called consensus model (Power and Third, 2010), the current, template based version of Quelo generates one clause per relation7. Thus for instance, template-based Quelo will generate (5a) while our grammar based approach supports the generation of arguably more fluent sentences such as (5b). (5) a. I am looking for a car. Its make should be a Land Rover. The body style of the car should be an off-road car. The exterior color of the car should be beige. b. I am looking for car whose make is a Land Rover, whose body style is an off-road car and whose exterior color is beige. We ran two experiments designed to assess how fluency impacts user</context>
</contexts>
<marker>Power, Third, 2010</marker>
<rawString>R. Power and A. Third. 2010. Expressing owl axioms by english sentences: dubious in theory, feasible in practice. In Proceedings of the 23rd International Conference on Computational Linguistics: Posters, pages 1006–1013. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Schlangen</author>
<author>Gabriel Skantze</author>
</authors>
<title>A general, abstract model of incremental dialogue processing.</title>
<date>2009</date>
<booktitle>In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>710--718</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="5788" citStr="Schlangen and Skantze, 2009" startWordPosition="886" endWordPosition="889">acted semi-automatically from the training corpus. In contrast, we use a general, small size grammar (around 50 rules) and a lexicon which is automatically derived from the input ontologies. The resulting system requires no training and thus can be applied to any ontology with any given signature of concepts and relations. Another difference between the two approaches concerns revisions: while our approach supports revisions anywhere in the input, the CRF approach proposed by (Dethlefs et al., 2013) only supports revisions occurring at the end of the generated string. There is also much work (Schlangen and Skantze, 2009; Schlangen et al., 2009) in the domain of spoken dialog systems geared at modelling the incremental nature of dialog and in particular, at developing dialog systems where processing starts before the input is complete. In these approaches, the focus is on developing efficient architectures which support the timely interleaving of parsing and generation. Instead, our aim is to develop a principled approach to the incremental generation of a user query which supports revision and additions at arbitrary points of the query being built; generates natural sounding text; and maximally preserves the</context>
</contexts>
<marker>Schlangen, Skantze, 2009</marker>
<rawString>David Schlangen and Gabriel Skantze. 2009. A general, abstract model of incremental dialogue processing. In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics, pages 710–718. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Schlangen</author>
<author>Timo Baumann</author>
<author>Michaela Atterer</author>
</authors>
<title>Incremental reference resolution: The task, metrics for evaluation, and a bayesian filtering model that is sensitive to disfluencies.</title>
<date>2009</date>
<booktitle>In Proceedings of the SIGDIAL 2009 Conference: The 10th Annual Meeting of the Special Interest Group on Discourse and Dialogue,</booktitle>
<pages>30--37</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="5813" citStr="Schlangen et al., 2009" startWordPosition="890" endWordPosition="893"> the training corpus. In contrast, we use a general, small size grammar (around 50 rules) and a lexicon which is automatically derived from the input ontologies. The resulting system requires no training and thus can be applied to any ontology with any given signature of concepts and relations. Another difference between the two approaches concerns revisions: while our approach supports revisions anywhere in the input, the CRF approach proposed by (Dethlefs et al., 2013) only supports revisions occurring at the end of the generated string. There is also much work (Schlangen and Skantze, 2009; Schlangen et al., 2009) in the domain of spoken dialog systems geared at modelling the incremental nature of dialog and in particular, at developing dialog systems where processing starts before the input is complete. In these approaches, the focus is on developing efficient architectures which support the timely interleaving of parsing and generation. Instead, our aim is to develop a principled approach to the incremental generation of a user query which supports revision and additions at arbitrary points of the query being built; generates natural sounding text; and maximally preserves the linear order of the quer</context>
</contexts>
<marker>Schlangen, Baumann, Atterer, 2009</marker>
<rawString>David Schlangen, Timo Baumann, and Michaela Atterer. 2009. Incremental reference resolution: The task, metrics for evaluation, and a bayesian filtering model that is sensitive to disfluencies. In Proceedings of the SIGDIAL 2009 Conference: The 10th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 30–37. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H R Tennant</author>
<author>K M Ross</author>
<author>R M Saenz</author>
<author>C W Thompson</author>
<author>J R Miller</author>
</authors>
<title>Menu-based natural language understanding.</title>
<date>1983</date>
<booktitle>In Proceedings of the 21st annual meeting on Association for Computational Linguistics,</booktitle>
<pages>151--158</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="1814" citStr="Tennant et al., 1983" startWordPosition="261" endWordPosition="264">ources, but also to support the final user in querying them, thus improving the usability of the integrated system. To support the wide access to these data sources, it is crucial to develop efficient and user-friendly ways to query them (Wache et al., 2001). In this paper, we present a Natural Language (NL) interface of an ontology-based query tool, called Quelo1, which allows the end user to formulate a query without any knowledge either of the formal languages used to specify ontologies, or of the content of the ontology being used. Following the conceptual authoring approach described in (Tennant et al., 1983; Hallett et al., 2007), this interface masks the composition of a formal query 1krdbapp.inf.unibz.it:8080/quelo as the composition of an English text describing the equivalent information needs using natural language generation techniques. The natural language generation system that we propose for Quelo’s NL interface departs from similar work (Hallett et al., 2007; Franconi et al., 2010a; Franconi et al., 2011b; Franconi et al., 2010b; Franconi et al., 2011a) in that it makes use of standard grammar based surface realisation techniques. Our contribution is two fold. First, we introduce a cha</context>
</contexts>
<marker>Tennant, Ross, Saenz, Thompson, Miller, 1983</marker>
<rawString>H. R Tennant, K. M Ross, R. M Saenz, C. W Thompson, and J. R Miller. 1983. Menu-based natural language understanding. In Proceedings of the 21st annual meeting on Association for Computational Linguistics, pages 151–158. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Trevisan</author>
</authors>
<title>A Portable Menuguided Natural Language Interface to Knowledge Bases for Querytool.</title>
<date>2010</date>
<tech>Ph.D. thesis,</tech>
<institution>Masters thesis, Free University of Bozen-Bolzano (Italy) and University of Groningen (Netherlands).</institution>
<contexts>
<context position="25254" citStr="Trevisan, 2010" startWordPosition="4131" endWordPosition="4132">esulting grammar consists of 53 FB-LTAG pairs of syntactic trees and semantic schema. To ensure the appropriate syntax/semantic interface, we make explicit the arguments of a relation using the variables associated with the nodes of the query tree. Thus for instance, given the rightmost query tree shown in Figure 1, the flat semantics input to surface realisation is {Man(x), Person(y), House(w), Beautiful(w), RichPerson(z), marriedTo(x,y), livesIn(x,w), ownedBy(w,z)}. For each ontology, a lexicon mapping concepts and relations to FB-LTAG trees is automatically derived from the ontology using (Trevisan, 2010)’s approach. We specify for each experiment below, the size of the extracted lexicon. 188 5.2 Linearisation In this first experiment, we manually examined whether the incremental algorithm we propose supports the generation of NL queries whose word order matches the linearisation of the input query tree. We created four series of queries such that each serie is a sequence q1 ... qn where qi+1 is an increment of qi. That is, qi+1 is derived from qi by adding, removing or substituting to qi a concept or a relation. The series were devised so as to encompass the whole range of possible operations</context>
<context position="30683" citStr="Trevisan, 2010" startWordPosition="5051" endWordPosition="5052">ved that longer sentences let through by document planning were often deemed unclear. In future work, we plan to improve clarity by better integrating document planning and sentence realisation. 5.4 Coverage One motivation for the symbolic based approach was the lack of training corpus and the need for portability: the query interface should be usable independently of the underlying ontology and of the existence of a training corpus. To support coverage, we combined the grammar based approach with a lexicon which is automatically extracted from the ontology using the methodology described in (Trevisan, 2010). When tested on a corpus of 200 ontologies, this approach was shown to be able to provide appropriate verbalisation templates for about 85% of the relation identifiers present in these ontologies. 12 000 relation identifiers were extracted from the 200 ontologies and 13 syntactic templates were found to be sufficient to verbalise these relation identifiers (see (Trevisan, 2010) for more details on this evaluation). That is, in general, the extracted lexicons permit covering about 85% of the ontological data. In addition, we evaluated the coverage of our approach by running the generator on 40</context>
</contexts>
<marker>Trevisan, 2010</marker>
<rawString>Marco Trevisan. 2010. A Portable Menuguided Natural Language Interface to Knowledge Bases for Querytool. Ph.D. thesis, Masters thesis, Free University of Bozen-Bolzano (Italy) and University of Groningen (Netherlands).</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Vijay-Shanker</author>
<author>A Joshi</author>
</authors>
<title>Feature based tags.</title>
<date>1988</date>
<booktitle>In Proceedings of the 12th International Conference of the Association for Computational Linguistics,</booktitle>
<pages>573--577</pages>
<location>Budapest.</location>
<contexts>
<context position="18511" citStr="Vijay-Shanker and Joshi, 1988" startWordPosition="2993" endWordPosition="2996">mantics is the union of their semantics modulo unification. Thus given the grammar and the derivation shown, the semantics of John often runs is as shown namely, named(j john), run(a,j), often(a). lv:run(a,j) l1:named(j john), lv:run(a,j), lv:often(a) Figure 2: Derivation and Semantics for “John often runs” Chart-Based Surface Realisation Given an FB-LTAG G of the type described above, sentences can be generated from semantic formulae by (i) selecting all trees in G whose semantics subsumes part of the input formula and (ii) combining 3For a more detailed introduction to TAG and FB-LTAG, see (Vijay-Shanker and Joshi, 1988). these trees using the FB-LTAG combining operations namely substitution and adjunction. Thus for instance, in Figure 2, given the semantics l1:named(j john), lv:run(a,j), lv:often(a), the three trees shown are selected. When combined they produce a complete phrase structure tree whose yield (John runs often) is the generated sentence. Following (Gardent and Perez-Beltrachini, 2011), we implement an Earley style generation algorithm for FB-LTAG which makes use of the fact that the derivation trees of an FB-LTAG are context free and that an FB-LTAG can be converted to a a Feature-Based Regular </context>
</contexts>
<marker>Vijay-Shanker, Joshi, 1988</marker>
<rawString>K. Vijay-Shanker and A. Joshi. 1988. Feature based tags. In Proceedings of the 12th International Conference of the Association for Computational Linguistics, pages 573–577, Budapest.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Holger Wache</author>
<author>Thomas Voegele</author>
<author>Ubbo Visser</author>
<author>Heiner Stuckenschmidt</author>
<author>Gerhard Schuster</author>
<author>Holger Neumann</author>
<author>Sebastian H¨ubner</author>
</authors>
<title>Ontologybased integration of information-a survey of existing approaches.</title>
<date>2001</date>
<booktitle>In IJCAI-01 workshop: ontologies and information sharing,</booktitle>
<volume>volume</volume>
<pages>108--117</pages>
<publisher>Citeseer.</publisher>
<marker>Wache, Voegele, Visser, Stuckenschmidt, Schuster, Neumann, H¨ubner, 2001</marker>
<rawString>Holger Wache, Thomas Voegele, Ubbo Visser, Heiner Stuckenschmidt, Gerhard Schuster, Holger Neumann, and Sebastian H¨ubner. 2001. Ontologybased integration of information-a survey of existing approaches. In IJCAI-01 workshop: ontologies and information sharing, volume 2001, pages 108–117. Citeseer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Walter</author>
<author>Christina Unger</author>
<author>Philipp Cimiano</author>
</authors>
<title>A corpus-based approach for the induction of ontology lexica.</title>
<date>2013</date>
<booktitle>In Natural Language Processing and Information Systems,</booktitle>
<pages>102--113</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="31850" citStr="Walter et al., 2013" startWordPosition="5238" endWordPosition="5241">verage of our approach by running the generator on 40 queries generated from five distinct ontologies. The domains observed are cinema, wines, human abilities, disabilities, and assistive devices, e-commerce on the Web, and a fishery database for observations about an aquatic resource. The extracted lexicons contained in average 453 lexical entries and the coverage (proportion of DL queries for which the generator produced a NL query) was 87%. Fuller coverage could be obtained by manually adding lexical entries, or by developing new ways of inducing lexical entries from ontologies (c.f. e.g. (Walter et al., 2013)). 6 Conclusion Conceptual authoring (CA) allows the user to query a knowledge base without having any knowledge either of the formal representation language used to specify that knowledge base or of the content of the knowledge base. Although this approach builds on a tight integration between syntax and semantics and requires an efficient processing of revisions, existing CA tools predominantly make use of ad hoc generation algorithms and restricted computational grammars (e.g., Definite Clause Grammars or templates). In this paper, we have shown that FB-LTAG and chart based surface realisat</context>
</contexts>
<marker>Walter, Unger, Cimiano, 2013</marker>
<rawString>Sebastian Walter, Christina Unger, and Philipp Cimiano. 2013. A corpus-based approach for the induction of ontology lexica. In Natural Language Processing and Information Systems, pages 102–113. Springer.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>