<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000060">
<title confidence="0.999256">
Adaptive Clustering for Coreference Resolution with Deterministic Rules
and Web-Based Language Models
</title>
<author confidence="0.985497">
Razvan C. Bunescu
</author>
<affiliation confidence="0.996105">
School of EECS
Ohio University
</affiliation>
<address confidence="0.940192">
Athens, OH 45701, USA
</address>
<email confidence="0.998977">
bunescu@ohio.edu
</email>
<sectionHeader confidence="0.996661" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999811529411765">
We present a novel adaptive clustering model
for coreference resolution in which the expert
rules of a state of the art deterministic sys-
tem are used as features over pairs of clus-
ters. A significant advantage of the new ap-
proach is that the expert rules can be eas-
ily augmented with new semantic features.
We demonstrate this advantage by incorporat-
ing semantic compatibility features for neutral
pronouns computed from web n-gram statis-
tics. Experimental results show that the com-
bination of the new features with the expert
rules in the adaptive clustering approach re-
sults in an overall performance improvement,
and over 5% improvement in Fl measure for
the target pronouns when evaluated on the
ACE 2004 newswire corpus.
</bodyText>
<sectionHeader confidence="0.998777" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999939875">
Coreference resolution is the task of clustering a
sequence of textual entity mentions into a set of
maximal non-overlapping clusters, such that men-
tions in a cluster refer to the same discourse entity.
Coreference resolution is an important subtask in
a wide array of natural language processing prob-
lems, among them information extraction, question
answering, and machine translation. The availabil-
ity of corpora annotated with coreference relations
has led to the development of a diverse set of super-
vised learning approaches for coreference. While
learning models enjoy a largely undisputed role in
many NLP applications, deterministic models based
on rich sets of expert rules for coreference have been
shown recently to achieve performance rivaling, if
not exceeding, the performance of state of the art
machine learning approaches (Haghighi and Klein,
2009; Raghunathan et al., 2010). In particular, the
top performing system in the CoNLL 2011 shared
task (Pradhan et al., 2011) is a multi-pass system that
applies tiers of deterministic coreference sieves from
highest to lowest precision (Lee et al., 2011). The
PRECISECONSTRUCTS sieve, for example, creates
coreference links between mentions that are found
to match patterns of apposition, predicate nomina-
tives, acronyms, demonyms, or relative pronouns.
This is a high precision sieve, correspondingly it is
among the first sieves to be applied. The PRONOUN-
MATCH sieve links an anaphoric pronoun with the
first antecedent mention that agrees in number and
gender with the pronoun, based on an ordering of the
antecedents that uses syntactic rules to model dis-
course salience. This is the last sieve to be applied,
due to its lower overall precision, as estimated on
development data. While very successful, this de-
terministic multi-pass sieve approach to coreference
can nevertheless be quite unwieldy when one seeks
to integrate new sources of knowledge in order to
improve the resolution performance. Pronoun reso-
lution, for example, was shown by Yang et al. (2005)
to benefit from semantic compatibility information
extracted from search engine statistics. The seman-
tic compatibility between candidate antecedents and
the pronoun context induces a new ordering between
the antecedents. One possibility for using compat-
ibility scores in the deterministic system is to ig-
nore the salience-based ordering and replace it with
the new compatibility-based ordering. The draw-
</bodyText>
<page confidence="0.992708">
11
</page>
<note confidence="0.9726185">
First Joint Conference on Lexical and Computational Semantics (*SEM), pages 11–19,
Montr´eal, Canada, June 7-8, 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.999878461538462">
back of this simple approach is that now discourse
salience, an important signal in pronoun resolution,
is completely ignored. Ideally, we would want to
use both discourse salience and semantic compat-
ibility when ranking the candidate antecedents of
the pronoun, something that can be achieved natu-
rally in a discriminative learning approach that uses
the two rankings as different, but overlapping, fea-
tures. Consequently, we propose an adaptive cluster-
ing model for coreference in which the expert rules
are successfully supplemented by semantic compat-
ibility features obtained from limited history web n-
gram statistics.
</bodyText>
<sectionHeader confidence="0.993604" genericHeader="introduction">
2 A Coreference Resolution Algorithm
</sectionHeader>
<bodyText confidence="0.973514681818182">
From a machine learning perspective, the determin-
istic system of Lee et al. (2011) represents a trove
of coreference resolution features. Since the de-
terministic sieves use not only information about a
pair of mentions, but also the clusters to which they
have been assigned so far, a learning model that uti-
lized the sieves as features would need to be able
to work with features defined on pairs of clusters.
We therefore chose to model coreference resolu-
tion as the greedy clustering process shown in Algo-
rithm 1. The algorithm starts by initializing the clus-
tering C with a set of singleton clusters. Then, as
long as the clustering contains more than one clus-
ter, it repeatedly finds the highest scoring pair of
clusters hCi, Cji. If the score passes the threshold
τ = f(∅, ∅), the clusters Ci, Cj are joined into one
cluster and the process continues with another high-
est scoring pair of clusters.
Algorithm 1 CLUSTER(X,f)
Input: A set of mentions X = {x1, x2, ..., xn};
Ameasure f(Ci,Cj) = wTb(Ci,Cj).
Output: A greedy agglomerative clustering of X.
</bodyText>
<listItem confidence="0.9800188">
1: for i = 1 to n do
2: Ci ← {xi}
3: C ← {Ci}1&lt;i&lt;n
4: hCi, Cji ← argmax f(p)
PEP(C)
5: while |C |&gt; 1 and f(Ci, Cj) &gt; τ do
6: replace Ci, Cj in C with Ci ∪ Cj
7: hCi, Cji ← argmax f(p)
PEP(C)
8: return C
</listItem>
<bodyText confidence="0.999081">
The scoring function f(Ci, Cj) is a linearly
weighted combination of features 4b(Ci, Cj) ex-
tracted from the cluster pair, parametrized by a
weight vector w. The function P takes a cluster-
ing C as argument and returns a set of cluster pairs
hCi, Cji as follows:
</bodyText>
<equation confidence="0.980385">
P(C)={hCi,Cji  |Ci, Cj ∈C, Ci6=Cj}∪{h∅,∅i}
</equation>
<bodyText confidence="0.9531446">
P(C) contains a special cluster pair h∅, ∅i, where
4b(∅, ∅) is defined to contain a binary feature
uniquely associated with this empty pair. Its cor-
responding weight is learned together with all other
weights and will effectively function as a clustering
threshold τ = f(∅, ∅).
Algorithm 2 TRAIN(C,T)
Input: A dataset of training clusterings C;
The number of training epochs T.
Output: The averaged parameters w.
</bodyText>
<listItem confidence="0.9886348">
1: w ← 0
2: for t = 1 to T do
3: for all C ∈ C do
4: w ← UPDATE(C,w)
5: return w
</listItem>
<bodyText confidence="0.968715">
Algorithm 3 UPDATE(C,w)
Input: A gold clustering C = {C1, C2,..., Cm};
The current parameters w.
Output: The updated parameters w.
</bodyText>
<equation confidence="0.7042795">
1: X ← C1 ∪ C2 ∪ ... ∪ Cm = {x1, x2,..., xn}
2: for i = 1 to n do
3: Ci ← {xi}
4: C ← { 0i}1&lt;i&lt;n
5: while  |C |&gt; 1 do
6: h�Ci, �Cji = argmax wT b(p)
PEP(C)
�Ck, Cl|C) &gt;
g(
Ok,
</equation>
<listItem confidence="0.976671">
10: w ← w + 4b(
11: if h Ci, Cji = h∅, ∅i then
12: return w
13: replace Ci, Cj in C� with Ci ∪ Cj
14: return w
</listItem>
<equation confidence="0.962180727272727">
7: B ← {h
Ck, �Cli ∈ P(
�Ci,�Cj|C)}
8: if B =6 ∅ then
�C)  |g(
9: h
�Cli = argmax
PEB
wT b(p)
�Ck,
Cl) − q&apos;(Ci, Cj)
</equation>
<page confidence="0.918587">
12
</page>
<bodyText confidence="0.999955774193548">
Algorithms 2 and 3 show an incremental learning
model for the weight vector w that is parametrized
with the number of training epochs T and a set of
training clusterings C in which each clustering con-
tains the true coreference clusters from one docu-
ment. Algorithm 2 repeatedly uses all true cluster-
ings to update the current weight vector and instead
of the last computed weights it returns an averaged
weight vector to control for overfitting, as originally
proposed by Freund and Schapire (1999). The core
of the learning model is in the update procedure
shown in Algorithm 3. Like the greedy clustering of
Algorithm 1, it starts with an initial system cluster-
ing Cˆ that contains all singleton clusters. At every
step in the iteration (lines 5–13), it joins the high-
est scoring pair of clusters hˆCi, ˆCji, computed ac-
cording to the current parameters. The iteration ends
when either the empty pair obtains the highest score
or everything has been joined into only one cluster.
The weight update logic is implemented in lines 7–
10: if a more accurate pair h ˆCk, ˆCli can be found,
the highest scoring such pair is used in the percep-
tron update in line 10. If multiple cluster pairs obtain
the maximum score in lines 6 and 9, the algorithm
selects one of them at random. This is useful es-
pecially in the beginning, when the weight vector is
zero and consequently all cluster pairs have the same
score of 0. We define the goodness g(ˆCk, ˆCl |C) of a
proposed pair h Ck, Cli with respect to the true clus-
tering C as the accuracy of the coreference pairs that
would be created if ˆCk and ˆCl were joined:
</bodyText>
<equation confidence="0.999169">
�{(x, y)∈ ˆCk× ˆCl  |∃Ci∈C : x,y∈Ci} ���
|ˆCk |·  |ˆCl|
(1)
</equation>
<bodyText confidence="0.999840583333333">
It can be shown that this definition of the goodness
function selects a cluster pair (lines 7–9) that, when
joined, results in a clustering with a better pairwise
accuracy. Therefore, the algorithm can be seen as
trying to fit the training data by searching for param-
eters that greedily maximize the clustering accuracy,
while overfitting is kept under control by comput-
ing an averaged version of the parameters. We have
chosen to use a perceptron update for simplicity, but
the algorithm can be easily instantiated to accommo-
date other types of incremental updates, e.g. MIRA
(Crammer and Singer, 2003).
</bodyText>
<sectionHeader confidence="0.944912" genericHeader="method">
3 Expert Rules as Features
</sectionHeader>
<bodyText confidence="0.9999298">
With the exception of mention detection which is
run separately, all the remaining 12 sieves men-
tioned in (Lee et al., 2011) are used as Boolean fea-
tures defined on cluster pairs, i.e. if any of the men-
tion pairs in the cluster pair hˆCi, ˆCji were linked
by sieve k, then the corresponding sieve feature
ˆCi, ˆCj) = 1. We used the implementation from
the Stanford CoreNLP package1 for all sieves, with a
modification for the PRONOUNMATCH sieve which
was split into 3 different sieves as follows:
</bodyText>
<listItem confidence="0.961085714285714">
• ITPRONOUNMATCH: this sieve finds an-
tecedents only for neutral pronouns it.
• ITSPRONOUNMATCH: this sieve finds an-
tecedents only for neutral possessive pronouns
its.
• OTHERPRONOUNMATCH: this is a catch-all
sieve for the remaining pronouns.
</listItem>
<bodyText confidence="0.999973928571428">
This 3-way split was performed in order to enable
the combination of the discourse salience features
captured by the pronoun sieves with the semantic
compatibility features for neutral pronouns that will
be introduced in the next section. The OTHER-
PRONOUNMATCH sieve works exactly as the orig-
inal PRONOUNMATCH: for a given non-neutral pro-
noun, it searches in the current sentence and the pre-
vious 3 sentences for the first mention that agrees in
gender and number with the pronoun. The candi-
date antecedents for the pronoun are ordered based
on a notion of discourse salience that favors syntac-
tic salience and document proximity (Raghunathan
et al., 2010).
</bodyText>
<sectionHeader confidence="0.984722" genericHeader="method">
4 Discourse Salience Features
</sectionHeader>
<bodyText confidence="0.9998878">
The IT/SPRONOUNMATCH sieves use the same im-
plementation for finding the first matching candi-
date antecedent as the original PRONOUNMATCH.
However, unlike OTHERPRONOUNMATCH and the
other sieves that generate Boolean features, the neu-
tral pronoun sieves are used to generate real valued
features. If the neutral pronoun is the leftmost men-
tion in the cluster ˆCj from a cluster pair h ˆCi, ˆCji,
the corresponding normalized feature is computed
as follows:
</bodyText>
<footnote confidence="0.64595">
1http://nlp.stanford.edu/software/corenlp.shtml
</footnote>
<equation confidence="0.963827">
g(·) =
Φk(
</equation>
<page confidence="0.940692">
13
</page>
<bodyText confidence="0.777669125">
1. Let Sj = (S�j , S2j , ..., Snj ) be the sequence
of candidate mentions that precede the neutral
pronoun and agree in gender and number with
it, ordered from most salient to least salient.
2. Compute the maximum and minimum seman-
tic similarity between the pronoun context and
any mention that precedes the pronoun and is
in agreement with it:
</bodyText>
<listItem confidence="0.9975412">
2. Let Ai C ˆCi be the set of mentions in the clus-
ter ˆCi that appear before the pronoun and agree
with it.
3. For each mention m E Ai, find its rank in the
sequence Sj:
</listItem>
<figure confidence="0.862791">
rank(m, Sj) = k &lt; ---&gt;m = Skj (2)
Mall = max comp(m, cj)
mESi comp(m, cj)
mall = min
mESi
3. Compute the semantic compatibility feature as
follows:
Ψit/s( ˆCi, ˆCj) = Mj − mall (4)
Mall − mall
4. Find the minimum rank across all the mentions
in Ai and compute the feature as follows:
</figure>
<equation confidence="0.9144045">
Φit/s(
ˆCi, ˆCj) = mEAi
( ���
min rank(m, Sj)
</equation>
<bodyText confidence="0.829201">
To avoid numerical instability, if the over-
all maximum and minimum similarities are
very close (Mall − mall &lt; 1e−4) we set
Ψit/s( ˆCi, ˆCj) = 1.
</bodyText>
<equation confidence="0.926078">
(3)
If Ai is empty, set Φit/s( ˆCi, ˆCj) = 0.
</equation>
<bodyText confidence="0.999972125">
The discourse salience feature described above is by
definition normalized in the interval [0, 1]. It takes
the maximum value of 1 when the most salient men-
tion in the discourse at the current position agrees
with the pronoun and also belongs to the candidate
cluster. The feature is 0 when the candidate cluster
does not contain any mention that agrees in gender
and number with the pronoun.
</bodyText>
<sectionHeader confidence="0.984444" genericHeader="method">
5 Semantic Compatibility Features
</sectionHeader>
<bodyText confidence="0.890305">
Each of the two types of neutral pronouns is associ-
ated with a new feature that computes the semantic
compatibility between the syntactic head of a candi-
date antecedent and the context of the neutral pro-
noun. If the neutral pronoun is the leftmost mention
in the cluster ˆCj from a cluster pair ( ˆCi, ˆCj) and cj
is the pronoun context, then the new normalized fea-
tures Ψit/s(ˆCi, ˆCj) are computed as follows:
1. Compute the maximum semantic similarity be-
tween the pronoun context and any mention in
ˆCi that precedes the pronoun and is in agree-
ment with it:
</bodyText>
<equation confidence="0.9417445">
Mj = max
mEAi comp(m, cj)
</equation>
<bodyText confidence="0.999896454545455">
Like the salience feature Φit/s, the semantic com-
patibility feature Ψit/s is normalized in the interval
[0, 1]. Its definition assumes that we can compute
comp(m, cj), the semantic compatibility between a
candidate antecedent mention m and the pronoun
context cj. For the possessive pronoun its, we ex-
tract the syntactic head h of the mention m and re-
place the pronoun with the mention head h in the
possessive context. We use the resulting possessive
pronoun context pcj(h) to define the semantic com-
patibility as the following conditional probability:
</bodyText>
<equation confidence="0.995432">
comp(m, cj) = log P(pcj(h)|h) (5)
= log P(pcj(h)) − log P(h)
</equation>
<bodyText confidence="0.999922571428571">
To compute the n-gram probabilities P(pcj(h)) and
P(h) in Equation 6, we use the language mod-
els provided by the Microsoft Web N-Gram Cor-
pus (Wang et al., 2010), as described in the next sec-
tion.
Figure 1 shows an example of a possessive neu-
tral pronoun context, together with the set of can-
didate antecedents that agree in number and gender
with the pronoun, from the current and previous 3
sentences. Each candidate antecedent is given an in-
dex that reflects its ranking in the discourse salience
based ordering. We see that discourse salience does
not help here, as the most salient mention is not
the correct antecedent. The figure also shows the
</bodyText>
<page confidence="0.995501">
14
</page>
<bodyText confidence="0.993331">
In 1946, the nine justices dismissed a case[7] involving
the apportionment[8] of congressional districts. That
view[6] would slowly change. In 1962, the court[3]
abandoned its[5] caution[4]. Finding remedies to the
unequal distribution[1] of political power[2] was indeed
within its constitutional authority.
</bodyText>
<figure confidence="0.997769">
[3] P(court’s constitutional authority court)
,: exp(−5.91)
[5] P(court’s constitutional authority court) (*)
,: exp(−5.91)
[7] P(case’s constitutional authority case)
,: exp(−8.32)
[2] P(power’s constitutional authority power)
,: exp(−9.30)
[8] P(app-nt’s constitutional authority app-nt)
,: exp(−9.32)
[4] P(caution’s constitutional authority caution)
,: exp(−9.39)
[1] P(dist-ion’s constitutional authority dist-ion)
,: exp(−9.40)
[6] P(view’s constitutional authority view)
,: exp(−9.69)
</figure>
<figureCaption confidence="0.999981">
Figure 1: Possessive neutral pronoun example.
</figureCaption>
<bodyText confidence="0.988398375">
The letter[5] appears to be an attempt[6] to calm the
concerns of the current American administration[7]. “I
confirm my commitment[1] to the points made therein,”
Aristide said in the letter[2], “confident that they will
help strengthen the ties between our two nations where
democracy[3] and peace[4] will flourish.” Since 1994,
when it sent 20,000 troops to restore Aristide to power,
the administration ...
</bodyText>
<figure confidence="0.997552428571429">
[7] P(administration sent troops administration)
,: exp(−6.00)
[2] P(letter sent troops letter)
,: exp(−6.57)
[5] P(letter sent troops letter)
,: exp(−6.57)
[4] P(peace sent troops peace)
,: exp(−7.92)
[6] P(attempt sent troops attempt)
,: exp(−8.26)
[3] P(democracy sent troops democracy)
,: exp(−8.30)
[1] P(commitment sent troops commitment)
,: exp(−8.62)
</figure>
<figureCaption confidence="0.99935">
Figure 2: Neutral pronoun example.
</figureCaption>
<bodyText confidence="0.995880642857143">
compatibility score computed for each candidate an-
tecedent, using the formula described above. In this
example, when ranking the candidate antecedents
based on their compatibility scores, the top ranked
mention is the correct antecedent, whereas the most
salient mention is down in the list.
When the set of candidate mentions contains pro-
nouns, we require that they are resolved to a nominal
or named mention, and use the head of this mention
to instantiate the possessive context. This is the case
of the pronominal mention [5] in Figure 1, which
we assumed was already resolved to the noun court
(even if the pronoun [5] were resolved to an incor-
rect mention, the noun court would still be ranked
first due to mention [3]). This partial ordering be-
tween coreference decisions is satisfied automati-
cally by setting the semantic compatibility feature
Cj) = 0 whenever the antecedent cluster
Ci contains only pronouns.
A similar feature is introduced for all neutral
pronouns it appearing in subject-verb-object triples.
The new pronoun context pcj(h) is obtained by
replacing the pronoun it in the subject-verb-object
context cj with the head h of the candidate an-
tecedent mention. Figure 2 shows a neutral pro-
noun context, together with the set of candidate an-
tecedents that agree in number and gender with the
pronoun, from an abridged version of the original
current and previous 3 sentences. Each candidate
antecedent is given an index that reflects its ranking
in the discourse salience based ordering. Discourse
salience does not help here, as the most salient men-
tion is not the correct antecedent. The figure shows
the compatibility score computed for each candidate
antecedent, using Equation 6. In this example, the
top ranked mention in the compatibility based order-
ing is the correct antecedent, whereas the most most
salient mention is at the bottom of the list.
To summarize, in the last two sections we de-
scribed two special features for neutral pronouns:
the discourse salience feature 4bit/s and the seman-
tic compatibility feature &apos;Pit/s. The two real-valued
</bodyText>
<figure confidence="0.529201">
oil
IFit/s(
</figure>
<page confidence="0.947399">
15
</page>
<table confidence="0.995827666666667">
Candidate mentions Original context N-gram context
capital, store, GE, side, offer with its corporate tentacles reaching GE’s corporate tentacles
AOL, Microsoft, Yahoo, product its substantial customer base AOL’s customer base
regime, Serbia, state, EU, embargo meets its international obligations Serbia’s international obligations
company, secret, internet, FBI it was investigating the incident FBI was investigating the incident
goal, team, realm, NHL, victory something it has not experienced since NHL has experienced
Onvia, line, Nasdaq, rating said Tuesday it will cut jobs Onvia will cut jobs
coalition, government, Italy but it has had more direct exposure Italy has had direct exposure
Pinochet, arrest, Chile, court while it studied a judge ’s explanation court studied the explanation
</table>
<tableCaption confidence="0.999714">
Table 1: N-gram generation examples.
</tableCaption>
<bodyText confidence="0.92172025">
features are computed at the level of cluster pairs as
described in Equations 3 and 4. Their computation
relies on the mention level rank (Equation 2) and se-
mantic compatibility (Equation 6) respectively.
</bodyText>
<sectionHeader confidence="0.988335" genericHeader="method">
6 Web-based Language Models
</sectionHeader>
<bodyText confidence="0.999890714285714">
We used the Microsoft Web N-Gram Corpus2 to
compute the pronoun context probability P(pcj(h))
and the candidate head probability P(h). This
corpus provides smoothed back-off language mod-
els that are computed dynamically from N-gram
statistics using the CALM algorithm (Wang and Li,
2009). The N-grams are collected from the tok-
enized versions of the billions of web pages indexed
by the Bing search engine. Separate models have
been created for the document body, the document
title and the anchor text. In our experiments, we
used the April 2010 version of the document body
language models. The number of words in the pro-
noun context and the antecedent head determine the
order of the language models used for estimating the
conditional probabilities. For example, to estimate
P(administration sent troops I administration), we
used a trigram model for the context probability
P(administration sent troops) and a unigram model
for the head probability P(administration). Since
the maximum order of the N-grams available in the
Microsoft corpus is 5, we designed the context and
head extraction rules to return N-grams with size
at most 5. Table 1 shows a number of examples
of N-grams generated from the original contexts, in
which the pronoun was replaced with the correct an-
tecedent. To get a sense of the utility of each con-
text in matching the right antecedent, the table also
</bodyText>
<footnote confidence="0.912211">
2http://web-ngram.research.microsoft.com
</footnote>
<bodyText confidence="0.999353347826087">
shows a sample of candidate antecedents.
For possessive contexts, the N-gram extraction
rules use the head of the NP context and its clos-
est premodifier whenever available. Using the pre-
modifier was meant to increase the discriminative
power of the context. For the subject-verb-object
N-grams, we used the verb at the same tense as in
the original context, which made it necessary to also
include the auxiliary verbs, as shown in lines 4–7 in
the table. Furthermore, in order to keep the gener-
ated N-grams within the maximum size of 5, we did
not include modifiers for the subject or object nouns,
as illustrated in the last line of the table. Some of
the examples in the table also illustrate the limits of
the context-based semantic compatibility feature. In
the second example, all three company names are
equally good matches for the possessive context. In
these situations, we expect the discourse salience
feature to provide the additional information neces-
sary for extracting the correct antecedent. This com-
bination of discourse salience with semantic com-
patibility features is done in the adaptive clustering
algorithm introduced in Section 2.
</bodyText>
<sectionHeader confidence="0.97274" genericHeader="evaluation">
7 Experimental Results
</sectionHeader>
<bodyText confidence="0.999946272727273">
We compare our adaptive clustering (AC) approach
with the state of the art deterministic sieves (DT)
system of Lee et al. (2011) on the newswire portion
of the ACE-2004 dataset. The newswire section of
the corpus contains 128 documents annotated with
gold mentions and coreference information, where
coreference is marked only between mentions that
belong to one of seven semantic classes: person, or-
ganization, location, geo-political entity, facility, ve-
hicle, and weapon. This set of documents has been
used before to evaluate coreference resolution sys-
</bodyText>
<page confidence="0.992375">
16
</page>
<table confidence="0.999777142857143">
System Mentions P R F1
DT Gold, all 88.1 73.3 80.0
AC Gold, all 88.7 73.5 80.4
DT Gold, neutral 82.5 51.5 63.4
AC Gold, neutral 83.0 52.1 64.0
DT Auto, neutral 84.4 34.9 49.3
AC Auto, neutral 86.1 40.0 54.6
</table>
<tableCaption confidence="0.999465">
Table 2: B3 comparative results on ACE 2004.
</tableCaption>
<bodyText confidence="0.999748129411765">
tems in (Poon and Domingos, 2008; Haghighi and
Klein, 2009; Raghunathan et al., 2010), with the best
results so far obtained by the deterministic sieve sys-
tem of Lee at al. (2011). There are 11,398 annotated
gold mentions, out of which 135 are possessive neu-
tral pronouns its and 88 are neutral pronouns it in
a subject-verb-object triple. Given the very small
number of neutral pronouns, in order to obtain re-
liable estimates for the model parameters we tested
the adaptive clustering algorithm in a 16 fold cross-
validation scenario. Thus, the set of 128 documents
was split into 16 folds, where each fold contains 120
documents for training and 8 documents for testing.
The final results were pooled together from the 16
disjoint test sets. During training, the AC’s update
procedure was run for 10 epochs. Since the AC al-
gorithm does not need to tune any hyper parameters,
there was no need for development data.
Table 2 shows the results obtained by the two sys-
tems on the newswire corpus under three evaluation
scenarios. We use the B3 version of the precision
(P), recall (R), and F1 measure, computed either on
all mention pairs (all) or only on links that contain at
least one neutral pronoun (neutral) marked as a men-
tion in ACE. Furthermore, we report results on gold
mentions (Gold) as well as on mentions extracted
automatically (Auto). Since the number of neutral
pronouns marked as gold mentions is small com-
pared to the total number of mentions, the impact
on the overall performance shown in the first two
rows is small. However, when looking at corefer-
ence links that contain at least one neutral pronoun,
the improvement becomes substantial. AC increases
F1 with 5.3% when the mentions are extracted auto-
matically during testing, a setting that reflects a more
realistic use of the system. We have also evaluated
the AC approach in the Gold setting using only the
original DT sieves as features, obtaining an F1 of
80.3% for all mentions and 63.4% – same as DT –
for neutral pronouns.
By matching the performance of the DT system in
the first two rows of the table, the AC system proves
that it can successfully learn the relative importance
of the deterministic sieves, which in (Raghunathan
et al., 2010) and (Lee et al., 2011) have been manu-
ally ordered using a separate development dataset.
Furthermore, in the DT system the sieves are ap-
plied on mentions in their textual order, whereas the
adaptive clustering algorithm AC does not assume
a predefined ordering among coreference resolution
decisions. Thus, the algorithm has the capability to
make the first clustering decisions in any section of
the document in which the coreference decisions are
potentially easier to make. We have run experiments
in which the AC system was augmented with a fea-
ture that computed the normalized distance between
a cluster and the beginning of the document, but this
did not lead to an improvement in the results, lend-
ing further credence to the hypothesis that a strictly
left to right ordering of the coreference decisions is
not necessary, at least with the current features.
The same behavior, albeit with smaller increases
in performance, was observed when the DT and AC
approaches were compared on the newswire section
of the development dataset used in the CoNLL 2011
shared task (Pradhan et al., 2011). For these exper-
iments, the AC system was trained on all 128 docu-
ments from the newswire portion of ACE 2004. On
gold mentions, the DT and AC systems obtained a
very similar performance. When evaluated only on
links that contain at least one neutral pronoun, in a
setting where the mentions were automatically de-
tected, the AC approach improved the F1 measure
over the DT system from 58.6% to 59.1%. One rea-
son for the smaller increase in performance in the
CoNLL experiments could be given by the different
annotation schemes used in the two datasets. Com-
pared to ACE, the CoNLL dataset does not include
coreference links for appositives, predicate nomi-
nals or relative pronouns. The different annotation
schemes may have led to mismatches in the training
and test data for the AC system, which was trained
on ACE and tested on CoNLL. While we tried to
control for these conditions during the evaluation
of the AC system, it is conceivable that the differ-
</bodyText>
<page confidence="0.994316">
17
</page>
<table confidence="0.998821">
System Mentions P R F1
DT Auto, its 86.0 46.9 60.7
AC Auto, its 91.7 47.5 62.6
</table>
<tableCaption confidence="0.999796">
Table 3: B3 comparative results on CoNLL 2011.
</tableCaption>
<bodyText confidence="0.99644975">
ences in annotation still had some effect on the per-
formance of the AC approach. Another cause for
the smaller increase in performance was that the
pronominal contexts were less discriminative in the
CoNLL data, especially for the neutral pronoun it.
When evaluated only on links that contained at least
one possessive neutral pronoun its, the improvement
in F1 increased at 1.9%, as shown in Table 3.
</bodyText>
<sectionHeader confidence="0.999909" genericHeader="related work">
8 Related Work
</sectionHeader>
<bodyText confidence="0.999420163636364">
Closest to our clustering approach from Section 2
is the error-driven first-order probabilistic model of
Culotta et al. (2007). Among significant differences
we mention that our model is non-probabilistic, sim-
pler and easier to understand and implement. Fur-
thermore, the update step does not stop after the
first clustering error, instead the algorithm learns and
uses a clustering threshold r to determine when to
stop during training and testing. This required the
design of a method to order cluster pairs in which the
clusters may not be consistent with the true coref-
erence chains, which led to the introduction of the
goodness function in Equation 1 as a new scoring
measure for cluster pairs. The strategy of contin-
uing the clustering during training as long as a an
adaptive threshold is met better matches the training
with the testing, and was observed to lead to better
performance. The cluster ranking model of Rahman
and Ng (2009) proceeds in a left-to-right fashion and
adds the current discourse old mention to the highest
scoring preceding cluster. Compared to it, our adap-
tive clustering approach is less constrained: it uses
only a weak, partial ordering between coreference
decisions, and does not require a singleton cluster at
every clustering step. This allows clustering to start
in any section of the document where coreference
decisions are easier to make, and thus create accu-
rate clusters earlier in the process.
The use of semantic knowledge for coreference
resolution has been studied before in a number of
works, among them (Ponzetto and Strube, 2006),
(Bengtson and Roth, 2008), (Lee et al., 2011), and
(Rahman and Ng, 2011). The focus in these studies
has been on the semantic similarity between a men-
tion and a candidate antecedent, or the parallelism
between the semantic role structures in which the
two appear. One of the earliest methods for using
predicate-argument frequencies in pronoun resolu-
tion is that of Dagan and Itai (1990). Closer to our
use of semantic compatibility features for pronouns
are the approaches of Kehler et al. (2004) and Yang
et al. (2005). The last work showed that pronoun
resolution can be improved by incorporating seman-
tic compatibility features derived from search engine
statistics in the twin-candidate model. In our ap-
proach, we use web-based language models to com-
pute semantic compatibility features for neutral pro-
nouns and show that they can improve performance
over a state-of-the-art coreference resolution system.
The use of language models instead of search engine
statistics is more practical, as they eliminate the la-
tency involved in using search engine queries. Web-
based language models can be built on readily avail-
able web N-gram corpora, such as Google’s Web 1T
5-gram Corpus (Brants and Franz, 2006).
</bodyText>
<sectionHeader confidence="0.994822" genericHeader="conclusions">
9 Conclusion
</sectionHeader>
<bodyText confidence="0.9999674">
We described a novel adaptive clustering method
for coreference resolution and showed that it can
not only learn the relative importance of the origi-
nal expert rules of Lee et al. (2011), but also ex-
tend them effectively with new semantic compati-
bility features. Experimental results show that the
new method improves the performance of the state
of the art deterministic system and obtains a sub-
stantial improvement for neutral pronouns when the
mentions are extracted automatically.
</bodyText>
<sectionHeader confidence="0.99698" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999977333333333">
We would like to thank the anonymous reviewers for
their helpful suggestions. This work was supported
by grant IIS-1018590 from the NSF. Any opinions,
findings, and conclusions or recommendations ex-
pressed in this material are those of the author and
do not necessarily reflect the views of the NSF.
</bodyText>
<page confidence="0.998774">
18
</page>
<sectionHeader confidence="0.993886" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99977309375">
Eric Bengtson and Dan Roth. 2008. Understanding the
value of features for coreference resolution. In Pro-
ceedings of the Conference on Empirical Methods in
Natural Language Processing, pages 294–303, Hon-
olulu, Hawaii, October. Association for Computational
Linguistics.
Thorsten Brants and Alex Franz. 2006. Web 1t 5-gram
version 1.
Koby Crammer and Yoram Singer. 2003. Ultraconser-
vative online algorithms for multiclass problems. J.
Mach. Learn. Res., 3:951–991.
Aron Culotta, Michael Wick, and Andrew McCallum.
2007. First-order probabilistic models for coreference
resolution. In Human Language Technologies 2007:
The Conference of the North American Chapter of the
Association for Computational Linguistics; Proceed-
ings of the Main Conference, pages 81–88, Rochester,
New York, April. Association for Computational Lin-
guistics.
Ido Dagan and Alon Itai. 1990. Automatic processing
of large corpora for the resolution of anaphora refer-
ences. In Proceedings of the 13th conference on Com-
putational linguistics - Volume 3, COLING’90, pages
330–332.
Yoav Freund and Robert E. Schapire. 1999. Large mar-
gin classification using the perceptron algorithm. Ma-
chine Learning, 37:277–296.
Aria Haghighi and Dan Klein. 2009. Simple coreference
resolution with rich syntactic and semantic features.
In Proceedings of the 2009 Conference on Empiri-
cal Methods in Natural Language Processing, pages
1152–1161, Singapore, August.
Andrew Kehler, Douglas Appelt, Lara Taylor, and Alek-
sandr Simma. 2004. The (non)utility of predicate-
argument frequencies for pronoun interpretation. In
HLT-NAACL 2004: Main Proceedings, pages 289–
296, Boston, Massachusetts, USA. Association for
Computational Linguistics.
Heeyoung Lee, Yves Peirsman, Angel Chang, Nathanael
Chambers, Mihai Surdeanu, and Dan Jurafsky. 2011.
Stanford’s multi-pass sieve coreference resolution sys-
tem at the conll-2011 shared task. In Proceedings of
the Fifteenth Conference on Computational Natural
Language Learning: Shared Task, pages 28–34.
Simone Paolo Ponzetto and Michael Strube. 2006. Ex-
ploiting semantic role labeling, wordnet and wikipedia
for coreference resolution. In Proceedings of the Hu-
man Language Technology Conference of the North
American Chapter of the Association of Computa-
tional Linguistics, pages 192–199.
Hoifung Poon and Pedro Domingos. 2008. Joint un-
supervised coreference resolution with markov logic.
In Proceedings of the 2008 Conference on Empirical
Methods in Natural Language Processing, Honolulu,
Hawaii, October.
Sameer Pradhan, Lance Ramshaw, Mitchell Marcus,
Martha Palmer, Ralph Weischedel, and Nianwen Xue.
2011. Conll-2011 shared task: modeling unrestricted
coreference in ontonotes. In Proceedings of the Fif-
teenth Conference on Computational Natural Lan-
guage Learning: Shared Task, pages 1–27.
Karthik Raghunathan, Heeyoung Lee, Sudarshan Ran-
garajan, Nate Chambers, Mihai Surdeanu, Dan Juraf-
sky, and Christopher D. Manning. 2010. A multi-pass
sieve for coreference resolution. In Proceedings of
the 2010 Conference on Empirical Methods in Natural
Language Processing (EMNLP’10), pages 492–501.
Altaf Rahman and Vincent Ng. 2009. Supervised mod-
els for coreference resolution. In Proceedings of the
2009 Conference on Empirical Methods in Natural
Language Processing, pages 968–977, Singapore, Au-
gust. Association for Computational Linguistics.
Altaf Rahman and Vincent Ng. 2011. Coreference res-
olution with world knowledge. In Proceedings of the
49th Annual Meeting of the Association for Compu-
tational Linguistics: Human Language Technologies,
pages 814–824, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Kuansan Wang and Xiaolong Li. 2009. Efficacy of a con-
stantly adaptive language modeling technique for web-
scale applications. In Proceedings of the 2009 IEEE
International Conference on Acoustics, Speech and
Signal Processing, ICASSP ’09, pages 4733–4736,
Washington, DC, USA. IEEE Computer Society.
Kuansan Wang, Christopher Thrasher, Evelyne Viegas,
Xiaolong Li, and Bo-june (Paul) Hsu. 2010. An
overview of microsoft web n-gram corpus and appli-
cations. In Proceedings of the NAACL HLT 2010
Demonstration Session, HLT-DEMO ’10, pages 45–
48, Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.
Xiaofeng Yang, Jian Su, and Chew Lim Tan. 2005. Im-
proving pronoun resolution using statistics-based se-
mantic compatibility information. In Proceedings of
the 43rd Annual Meeting on Association for Computa-
tional Linguistics, pages 165–172.
</reference>
<page confidence="0.999329">
19
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.925211">
<title confidence="0.9994485">Adaptive Clustering for Coreference Resolution with Deterministic and Web-Based Language Models</title>
<author confidence="0.999885">Razvan C Bunescu</author>
<affiliation confidence="0.9999595">School of EECS Ohio University</affiliation>
<address confidence="0.989906">Athens, OH 45701,</address>
<email confidence="0.999832">bunescu@ohio.edu</email>
<abstract confidence="0.9953285">We present a novel adaptive clustering model for coreference resolution in which the expert rules of a state of the art deterministic system are used as features over pairs of clusters. A significant advantage of the new approach is that the expert rules can be easily augmented with new semantic features. We demonstrate this advantage by incorporating semantic compatibility features for neutral pronouns computed from web n-gram statistics. Experimental results show that the combination of the new features with the expert rules in the adaptive clustering approach results in an overall performance improvement, over 5% improvement in for the target pronouns when evaluated on the ACE 2004 newswire corpus.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eric Bengtson</author>
<author>Dan Roth</author>
</authors>
<title>Understanding the value of features for coreference resolution.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>294--303</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Honolulu, Hawaii,</location>
<contexts>
<context position="29009" citStr="Bengtson and Roth, 2008" startWordPosition="4825" endWordPosition="4828">adds the current discourse old mention to the highest scoring preceding cluster. Compared to it, our adaptive clustering approach is less constrained: it uses only a weak, partial ordering between coreference decisions, and does not require a singleton cluster at every clustering step. This allows clustering to start in any section of the document where coreference decisions are easier to make, and thus create accurate clusters earlier in the process. The use of semantic knowledge for coreference resolution has been studied before in a number of works, among them (Ponzetto and Strube, 2006), (Bengtson and Roth, 2008), (Lee et al., 2011), and (Rahman and Ng, 2011). The focus in these studies has been on the semantic similarity between a mention and a candidate antecedent, or the parallelism between the semantic role structures in which the two appear. One of the earliest methods for using predicate-argument frequencies in pronoun resolution is that of Dagan and Itai (1990). Closer to our use of semantic compatibility features for pronouns are the approaches of Kehler et al. (2004) and Yang et al. (2005). The last work showed that pronoun resolution can be improved by incorporating semantic compatibility fe</context>
</contexts>
<marker>Bengtson, Roth, 2008</marker>
<rawString>Eric Bengtson and Dan Roth. 2008. Understanding the value of features for coreference resolution. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 294–303, Honolulu, Hawaii, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Brants</author>
<author>Alex Franz</author>
</authors>
<title>Web 1t 5-gram version 1.</title>
<date>2006</date>
<contexts>
<context position="30189" citStr="Brants and Franz, 2006" startWordPosition="5016" endWordPosition="5019"> by incorporating semantic compatibility features derived from search engine statistics in the twin-candidate model. In our approach, we use web-based language models to compute semantic compatibility features for neutral pronouns and show that they can improve performance over a state-of-the-art coreference resolution system. The use of language models instead of search engine statistics is more practical, as they eliminate the latency involved in using search engine queries. Webbased language models can be built on readily available web N-gram corpora, such as Google’s Web 1T 5-gram Corpus (Brants and Franz, 2006). 9 Conclusion We described a novel adaptive clustering method for coreference resolution and showed that it can not only learn the relative importance of the original expert rules of Lee et al. (2011), but also extend them effectively with new semantic compatibility features. Experimental results show that the new method improves the performance of the state of the art deterministic system and obtains a substantial improvement for neutral pronouns when the mentions are extracted automatically. Acknowledgments We would like to thank the anonymous reviewers for their helpful suggestions. This w</context>
</contexts>
<marker>Brants, Franz, 2006</marker>
<rawString>Thorsten Brants and Alex Franz. 2006. Web 1t 5-gram version 1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Koby Crammer</author>
<author>Yoram Singer</author>
</authors>
<title>Ultraconservative online algorithms for multiclass problems.</title>
<date>2003</date>
<journal>J. Mach. Learn. Res.,</journal>
<pages>3--951</pages>
<contexts>
<context position="9064" citStr="Crammer and Singer, 2003" startWordPosition="1551" endWordPosition="1554">��� |ˆCk |· |ˆCl| (1) It can be shown that this definition of the goodness function selects a cluster pair (lines 7–9) that, when joined, results in a clustering with a better pairwise accuracy. Therefore, the algorithm can be seen as trying to fit the training data by searching for parameters that greedily maximize the clustering accuracy, while overfitting is kept under control by computing an averaged version of the parameters. We have chosen to use a perceptron update for simplicity, but the algorithm can be easily instantiated to accommodate other types of incremental updates, e.g. MIRA (Crammer and Singer, 2003). 3 Expert Rules as Features With the exception of mention detection which is run separately, all the remaining 12 sieves mentioned in (Lee et al., 2011) are used as Boolean features defined on cluster pairs, i.e. if any of the mention pairs in the cluster pair hˆCi, ˆCji were linked by sieve k, then the corresponding sieve feature ˆCi, ˆCj) = 1. We used the implementation from the Stanford CoreNLP package1 for all sieves, with a modification for the PRONOUNMATCH sieve which was split into 3 different sieves as follows: • ITPRONOUNMATCH: this sieve finds antecedents only for neutral pronouns i</context>
</contexts>
<marker>Crammer, Singer, 2003</marker>
<rawString>Koby Crammer and Yoram Singer. 2003. Ultraconservative online algorithms for multiclass problems. J. Mach. Learn. Res., 3:951–991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aron Culotta</author>
<author>Michael Wick</author>
<author>Andrew McCallum</author>
</authors>
<title>First-order probabilistic models for coreference resolution.</title>
<date>2007</date>
<booktitle>In Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference,</booktitle>
<pages>81--88</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Rochester, New York,</location>
<contexts>
<context position="27527" citStr="Culotta et al. (2007)" startWordPosition="4583" endWordPosition="4586">.7 AC Auto, its 91.7 47.5 62.6 Table 3: B3 comparative results on CoNLL 2011. ences in annotation still had some effect on the performance of the AC approach. Another cause for the smaller increase in performance was that the pronominal contexts were less discriminative in the CoNLL data, especially for the neutral pronoun it. When evaluated only on links that contained at least one possessive neutral pronoun its, the improvement in F1 increased at 1.9%, as shown in Table 3. 8 Related Work Closest to our clustering approach from Section 2 is the error-driven first-order probabilistic model of Culotta et al. (2007). Among significant differences we mention that our model is non-probabilistic, simpler and easier to understand and implement. Furthermore, the update step does not stop after the first clustering error, instead the algorithm learns and uses a clustering threshold r to determine when to stop during training and testing. This required the design of a method to order cluster pairs in which the clusters may not be consistent with the true coreference chains, which led to the introduction of the goodness function in Equation 1 as a new scoring measure for cluster pairs. The strategy of continuing</context>
</contexts>
<marker>Culotta, Wick, McCallum, 2007</marker>
<rawString>Aron Culotta, Michael Wick, and Andrew McCallum. 2007. First-order probabilistic models for coreference resolution. In Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference, pages 81–88, Rochester, New York, April. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Alon Itai</author>
</authors>
<title>Automatic processing of large corpora for the resolution of anaphora references.</title>
<date>1990</date>
<booktitle>In Proceedings of the 13th conference on Computational linguistics -</booktitle>
<volume>3</volume>
<pages>330--332</pages>
<contexts>
<context position="29371" citStr="Dagan and Itai (1990)" startWordPosition="4886" endWordPosition="4889">ce decisions are easier to make, and thus create accurate clusters earlier in the process. The use of semantic knowledge for coreference resolution has been studied before in a number of works, among them (Ponzetto and Strube, 2006), (Bengtson and Roth, 2008), (Lee et al., 2011), and (Rahman and Ng, 2011). The focus in these studies has been on the semantic similarity between a mention and a candidate antecedent, or the parallelism between the semantic role structures in which the two appear. One of the earliest methods for using predicate-argument frequencies in pronoun resolution is that of Dagan and Itai (1990). Closer to our use of semantic compatibility features for pronouns are the approaches of Kehler et al. (2004) and Yang et al. (2005). The last work showed that pronoun resolution can be improved by incorporating semantic compatibility features derived from search engine statistics in the twin-candidate model. In our approach, we use web-based language models to compute semantic compatibility features for neutral pronouns and show that they can improve performance over a state-of-the-art coreference resolution system. The use of language models instead of search engine statistics is more pract</context>
</contexts>
<marker>Dagan, Itai, 1990</marker>
<rawString>Ido Dagan and Alon Itai. 1990. Automatic processing of large corpora for the resolution of anaphora references. In Proceedings of the 13th conference on Computational linguistics - Volume 3, COLING’90, pages 330–332.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Freund</author>
<author>Robert E Schapire</author>
</authors>
<title>Large margin classification using the perceptron algorithm.</title>
<date>1999</date>
<booktitle>Machine Learning,</booktitle>
<pages>37--277</pages>
<contexts>
<context position="7293" citStr="Freund and Schapire (1999)" startWordPosition="1236" endWordPosition="1239"> return w 7: B ← {h Ck, �Cli ∈ P( �Ci,�Cj|C)} 8: if B =6 ∅ then �C) |g( 9: h �Cli = argmax PEB wT b(p) �Ck, Cl) − q&apos;(Ci, Cj) 12 Algorithms 2 and 3 show an incremental learning model for the weight vector w that is parametrized with the number of training epochs T and a set of training clusterings C in which each clustering contains the true coreference clusters from one document. Algorithm 2 repeatedly uses all true clusterings to update the current weight vector and instead of the last computed weights it returns an averaged weight vector to control for overfitting, as originally proposed by Freund and Schapire (1999). The core of the learning model is in the update procedure shown in Algorithm 3. Like the greedy clustering of Algorithm 1, it starts with an initial system clustering Cˆ that contains all singleton clusters. At every step in the iteration (lines 5–13), it joins the highest scoring pair of clusters hˆCi, ˆCji, computed according to the current parameters. The iteration ends when either the empty pair obtains the highest score or everything has been joined into only one cluster. The weight update logic is implemented in lines 7– 10: if a more accurate pair h ˆCk, ˆCli can be found, the highest</context>
</contexts>
<marker>Freund, Schapire, 1999</marker>
<rawString>Yoav Freund and Robert E. Schapire. 1999. Large margin classification using the perceptron algorithm. Machine Learning, 37:277–296.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aria Haghighi</author>
<author>Dan Klein</author>
</authors>
<title>Simple coreference resolution with rich syntactic and semantic features.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1152--1161</pages>
<location>Singapore,</location>
<contexts>
<context position="1804" citStr="Haghighi and Klein, 2009" startWordPosition="275" endWordPosition="278">t subtask in a wide array of natural language processing problems, among them information extraction, question answering, and machine translation. The availability of corpora annotated with coreference relations has led to the development of a diverse set of supervised learning approaches for coreference. While learning models enjoy a largely undisputed role in many NLP applications, deterministic models based on rich sets of expert rules for coreference have been shown recently to achieve performance rivaling, if not exceeding, the performance of state of the art machine learning approaches (Haghighi and Klein, 2009; Raghunathan et al., 2010). In particular, the top performing system in the CoNLL 2011 shared task (Pradhan et al., 2011) is a multi-pass system that applies tiers of deterministic coreference sieves from highest to lowest precision (Lee et al., 2011). The PRECISECONSTRUCTS sieve, for example, creates coreference links between mentions that are found to match patterns of apposition, predicate nominatives, acronyms, demonyms, or relative pronouns. This is a high precision sieve, correspondingly it is among the first sieves to be applied. The PRONOUNMATCH sieve links an anaphoric pronoun with t</context>
<context position="22637" citStr="Haghighi and Klein, 2009" startWordPosition="3748" endWordPosition="3751"> with gold mentions and coreference information, where coreference is marked only between mentions that belong to one of seven semantic classes: person, organization, location, geo-political entity, facility, vehicle, and weapon. This set of documents has been used before to evaluate coreference resolution sys16 System Mentions P R F1 DT Gold, all 88.1 73.3 80.0 AC Gold, all 88.7 73.5 80.4 DT Gold, neutral 82.5 51.5 63.4 AC Gold, neutral 83.0 52.1 64.0 DT Auto, neutral 84.4 34.9 49.3 AC Auto, neutral 86.1 40.0 54.6 Table 2: B3 comparative results on ACE 2004. tems in (Poon and Domingos, 2008; Haghighi and Klein, 2009; Raghunathan et al., 2010), with the best results so far obtained by the deterministic sieve system of Lee at al. (2011). There are 11,398 annotated gold mentions, out of which 135 are possessive neutral pronouns its and 88 are neutral pronouns it in a subject-verb-object triple. Given the very small number of neutral pronouns, in order to obtain reliable estimates for the model parameters we tested the adaptive clustering algorithm in a 16 fold crossvalidation scenario. Thus, the set of 128 documents was split into 16 folds, where each fold contains 120 documents for training and 8 documents</context>
</contexts>
<marker>Haghighi, Klein, 2009</marker>
<rawString>Aria Haghighi and Dan Klein. 2009. Simple coreference resolution with rich syntactic and semantic features. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1152–1161, Singapore, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Kehler</author>
<author>Douglas Appelt</author>
<author>Lara Taylor</author>
<author>Aleksandr Simma</author>
</authors>
<title>The (non)utility of predicateargument frequencies for pronoun interpretation.</title>
<date>2004</date>
<booktitle>In HLT-NAACL 2004: Main Proceedings,</booktitle>
<pages>289--296</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Boston, Massachusetts, USA.</location>
<contexts>
<context position="29481" citStr="Kehler et al. (2004)" startWordPosition="4904" endWordPosition="4907">knowledge for coreference resolution has been studied before in a number of works, among them (Ponzetto and Strube, 2006), (Bengtson and Roth, 2008), (Lee et al., 2011), and (Rahman and Ng, 2011). The focus in these studies has been on the semantic similarity between a mention and a candidate antecedent, or the parallelism between the semantic role structures in which the two appear. One of the earliest methods for using predicate-argument frequencies in pronoun resolution is that of Dagan and Itai (1990). Closer to our use of semantic compatibility features for pronouns are the approaches of Kehler et al. (2004) and Yang et al. (2005). The last work showed that pronoun resolution can be improved by incorporating semantic compatibility features derived from search engine statistics in the twin-candidate model. In our approach, we use web-based language models to compute semantic compatibility features for neutral pronouns and show that they can improve performance over a state-of-the-art coreference resolution system. The use of language models instead of search engine statistics is more practical, as they eliminate the latency involved in using search engine queries. Webbased language models can be b</context>
</contexts>
<marker>Kehler, Appelt, Taylor, Simma, 2004</marker>
<rawString>Andrew Kehler, Douglas Appelt, Lara Taylor, and Aleksandr Simma. 2004. The (non)utility of predicateargument frequencies for pronoun interpretation. In HLT-NAACL 2004: Main Proceedings, pages 289– 296, Boston, Massachusetts, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heeyoung Lee</author>
<author>Yves Peirsman</author>
<author>Angel Chang</author>
<author>Nathanael Chambers</author>
<author>Mihai Surdeanu</author>
<author>Dan Jurafsky</author>
</authors>
<title>Stanford’s multi-pass sieve coreference resolution system at the conll-2011 shared task.</title>
<date>2011</date>
<booktitle>In Proceedings of the Fifteenth Conference on Computational Natural Language Learning: Shared Task,</booktitle>
<pages>28--34</pages>
<contexts>
<context position="2056" citStr="Lee et al., 2011" startWordPosition="315" endWordPosition="318">supervised learning approaches for coreference. While learning models enjoy a largely undisputed role in many NLP applications, deterministic models based on rich sets of expert rules for coreference have been shown recently to achieve performance rivaling, if not exceeding, the performance of state of the art machine learning approaches (Haghighi and Klein, 2009; Raghunathan et al., 2010). In particular, the top performing system in the CoNLL 2011 shared task (Pradhan et al., 2011) is a multi-pass system that applies tiers of deterministic coreference sieves from highest to lowest precision (Lee et al., 2011). The PRECISECONSTRUCTS sieve, for example, creates coreference links between mentions that are found to match patterns of apposition, predicate nominatives, acronyms, demonyms, or relative pronouns. This is a high precision sieve, correspondingly it is among the first sieves to be applied. The PRONOUNMATCH sieve links an anaphoric pronoun with the first antecedent mention that agrees in number and gender with the pronoun, based on an ordering of the antecedents that uses syntactic rules to model discourse salience. This is the last sieve to be applied, due to its lower overall precision, as e</context>
<context position="4285" citStr="Lee et al. (2011)" startWordPosition="650" endWordPosition="653">. Ideally, we would want to use both discourse salience and semantic compatibility when ranking the candidate antecedents of the pronoun, something that can be achieved naturally in a discriminative learning approach that uses the two rankings as different, but overlapping, features. Consequently, we propose an adaptive clustering model for coreference in which the expert rules are successfully supplemented by semantic compatibility features obtained from limited history web ngram statistics. 2 A Coreference Resolution Algorithm From a machine learning perspective, the deterministic system of Lee et al. (2011) represents a trove of coreference resolution features. Since the deterministic sieves use not only information about a pair of mentions, but also the clusters to which they have been assigned so far, a learning model that utilized the sieves as features would need to be able to work with features defined on pairs of clusters. We therefore chose to model coreference resolution as the greedy clustering process shown in Algorithm 1. The algorithm starts by initializing the clustering C with a set of singleton clusters. Then, as long as the clustering contains more than one cluster, it repeatedly</context>
<context position="9217" citStr="Lee et al., 2011" startWordPosition="1578" endWordPosition="1581"> with a better pairwise accuracy. Therefore, the algorithm can be seen as trying to fit the training data by searching for parameters that greedily maximize the clustering accuracy, while overfitting is kept under control by computing an averaged version of the parameters. We have chosen to use a perceptron update for simplicity, but the algorithm can be easily instantiated to accommodate other types of incremental updates, e.g. MIRA (Crammer and Singer, 2003). 3 Expert Rules as Features With the exception of mention detection which is run separately, all the remaining 12 sieves mentioned in (Lee et al., 2011) are used as Boolean features defined on cluster pairs, i.e. if any of the mention pairs in the cluster pair hˆCi, ˆCji were linked by sieve k, then the corresponding sieve feature ˆCi, ˆCj) = 1. We used the implementation from the Stanford CoreNLP package1 for all sieves, with a modification for the PRONOUNMATCH sieve which was split into 3 different sieves as follows: • ITPRONOUNMATCH: this sieve finds antecedents only for neutral pronouns it. • ITSPRONOUNMATCH: this sieve finds antecedents only for neutral possessive pronouns its. • OTHERPRONOUNMATCH: this is a catch-all sieve for the remai</context>
<context position="21896" citStr="Lee et al. (2011)" startWordPosition="3625" endWordPosition="3628">strate the limits of the context-based semantic compatibility feature. In the second example, all three company names are equally good matches for the possessive context. In these situations, we expect the discourse salience feature to provide the additional information necessary for extracting the correct antecedent. This combination of discourse salience with semantic compatibility features is done in the adaptive clustering algorithm introduced in Section 2. 7 Experimental Results We compare our adaptive clustering (AC) approach with the state of the art deterministic sieves (DT) system of Lee et al. (2011) on the newswire portion of the ACE-2004 dataset. The newswire section of the corpus contains 128 documents annotated with gold mentions and coreference information, where coreference is marked only between mentions that belong to one of seven semantic classes: person, organization, location, geo-political entity, facility, vehicle, and weapon. This set of documents has been used before to evaluate coreference resolution sys16 System Mentions P R F1 DT Gold, all 88.1 73.3 80.0 AC Gold, all 88.7 73.5 80.4 DT Gold, neutral 82.5 51.5 63.4 AC Gold, neutral 83.0 52.1 64.0 DT Auto, neutral 84.4 34.9</context>
<context position="24826" citStr="Lee et al., 2011" startWordPosition="4127" endWordPosition="4130">rovement becomes substantial. AC increases F1 with 5.3% when the mentions are extracted automatically during testing, a setting that reflects a more realistic use of the system. We have also evaluated the AC approach in the Gold setting using only the original DT sieves as features, obtaining an F1 of 80.3% for all mentions and 63.4% – same as DT – for neutral pronouns. By matching the performance of the DT system in the first two rows of the table, the AC system proves that it can successfully learn the relative importance of the deterministic sieves, which in (Raghunathan et al., 2010) and (Lee et al., 2011) have been manually ordered using a separate development dataset. Furthermore, in the DT system the sieves are applied on mentions in their textual order, whereas the adaptive clustering algorithm AC does not assume a predefined ordering among coreference resolution decisions. Thus, the algorithm has the capability to make the first clustering decisions in any section of the document in which the coreference decisions are potentially easier to make. We have run experiments in which the AC system was augmented with a feature that computed the normalized distance between a cluster and the beginn</context>
<context position="29029" citStr="Lee et al., 2011" startWordPosition="4829" endWordPosition="4832">old mention to the highest scoring preceding cluster. Compared to it, our adaptive clustering approach is less constrained: it uses only a weak, partial ordering between coreference decisions, and does not require a singleton cluster at every clustering step. This allows clustering to start in any section of the document where coreference decisions are easier to make, and thus create accurate clusters earlier in the process. The use of semantic knowledge for coreference resolution has been studied before in a number of works, among them (Ponzetto and Strube, 2006), (Bengtson and Roth, 2008), (Lee et al., 2011), and (Rahman and Ng, 2011). The focus in these studies has been on the semantic similarity between a mention and a candidate antecedent, or the parallelism between the semantic role structures in which the two appear. One of the earliest methods for using predicate-argument frequencies in pronoun resolution is that of Dagan and Itai (1990). Closer to our use of semantic compatibility features for pronouns are the approaches of Kehler et al. (2004) and Yang et al. (2005). The last work showed that pronoun resolution can be improved by incorporating semantic compatibility features derived from </context>
<context position="30390" citStr="Lee et al. (2011)" startWordPosition="5050" endWordPosition="5053">es for neutral pronouns and show that they can improve performance over a state-of-the-art coreference resolution system. The use of language models instead of search engine statistics is more practical, as they eliminate the latency involved in using search engine queries. Webbased language models can be built on readily available web N-gram corpora, such as Google’s Web 1T 5-gram Corpus (Brants and Franz, 2006). 9 Conclusion We described a novel adaptive clustering method for coreference resolution and showed that it can not only learn the relative importance of the original expert rules of Lee et al. (2011), but also extend them effectively with new semantic compatibility features. Experimental results show that the new method improves the performance of the state of the art deterministic system and obtains a substantial improvement for neutral pronouns when the mentions are extracted automatically. Acknowledgments We would like to thank the anonymous reviewers for their helpful suggestions. This work was supported by grant IIS-1018590 from the NSF. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author and do not necessarily reflect the vie</context>
</contexts>
<marker>Lee, Peirsman, Chang, Chambers, Surdeanu, Jurafsky, 2011</marker>
<rawString>Heeyoung Lee, Yves Peirsman, Angel Chang, Nathanael Chambers, Mihai Surdeanu, and Dan Jurafsky. 2011. Stanford’s multi-pass sieve coreference resolution system at the conll-2011 shared task. In Proceedings of the Fifteenth Conference on Computational Natural Language Learning: Shared Task, pages 28–34.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Simone Paolo Ponzetto</author>
<author>Michael Strube</author>
</authors>
<title>Exploiting semantic role labeling, wordnet and wikipedia for coreference resolution.</title>
<date>2006</date>
<booktitle>In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics,</booktitle>
<pages>192--199</pages>
<contexts>
<context position="28982" citStr="Ponzetto and Strube, 2006" startWordPosition="4821" endWordPosition="4824"> a left-to-right fashion and adds the current discourse old mention to the highest scoring preceding cluster. Compared to it, our adaptive clustering approach is less constrained: it uses only a weak, partial ordering between coreference decisions, and does not require a singleton cluster at every clustering step. This allows clustering to start in any section of the document where coreference decisions are easier to make, and thus create accurate clusters earlier in the process. The use of semantic knowledge for coreference resolution has been studied before in a number of works, among them (Ponzetto and Strube, 2006), (Bengtson and Roth, 2008), (Lee et al., 2011), and (Rahman and Ng, 2011). The focus in these studies has been on the semantic similarity between a mention and a candidate antecedent, or the parallelism between the semantic role structures in which the two appear. One of the earliest methods for using predicate-argument frequencies in pronoun resolution is that of Dagan and Itai (1990). Closer to our use of semantic compatibility features for pronouns are the approaches of Kehler et al. (2004) and Yang et al. (2005). The last work showed that pronoun resolution can be improved by incorporatin</context>
</contexts>
<marker>Ponzetto, Strube, 2006</marker>
<rawString>Simone Paolo Ponzetto and Michael Strube. 2006. Exploiting semantic role labeling, wordnet and wikipedia for coreference resolution. In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics, pages 192–199.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hoifung Poon</author>
<author>Pedro Domingos</author>
</authors>
<title>Joint unsupervised coreference resolution with markov logic.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<location>Honolulu, Hawaii,</location>
<contexts>
<context position="22611" citStr="Poon and Domingos, 2008" startWordPosition="3744" endWordPosition="3747">s 128 documents annotated with gold mentions and coreference information, where coreference is marked only between mentions that belong to one of seven semantic classes: person, organization, location, geo-political entity, facility, vehicle, and weapon. This set of documents has been used before to evaluate coreference resolution sys16 System Mentions P R F1 DT Gold, all 88.1 73.3 80.0 AC Gold, all 88.7 73.5 80.4 DT Gold, neutral 82.5 51.5 63.4 AC Gold, neutral 83.0 52.1 64.0 DT Auto, neutral 84.4 34.9 49.3 AC Auto, neutral 86.1 40.0 54.6 Table 2: B3 comparative results on ACE 2004. tems in (Poon and Domingos, 2008; Haghighi and Klein, 2009; Raghunathan et al., 2010), with the best results so far obtained by the deterministic sieve system of Lee at al. (2011). There are 11,398 annotated gold mentions, out of which 135 are possessive neutral pronouns its and 88 are neutral pronouns it in a subject-verb-object triple. Given the very small number of neutral pronouns, in order to obtain reliable estimates for the model parameters we tested the adaptive clustering algorithm in a 16 fold crossvalidation scenario. Thus, the set of 128 documents was split into 16 folds, where each fold contains 120 documents fo</context>
</contexts>
<marker>Poon, Domingos, 2008</marker>
<rawString>Hoifung Poon and Pedro Domingos. 2008. Joint unsupervised coreference resolution with markov logic. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, Honolulu, Hawaii, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sameer Pradhan</author>
<author>Lance Ramshaw</author>
<author>Mitchell Marcus</author>
<author>Martha Palmer</author>
<author>Ralph Weischedel</author>
<author>Nianwen Xue</author>
</authors>
<title>Conll-2011 shared task: modeling unrestricted coreference in ontonotes.</title>
<date>2011</date>
<booktitle>In Proceedings of the Fifteenth Conference on Computational Natural Language Learning: Shared Task,</booktitle>
<pages>1--27</pages>
<contexts>
<context position="1926" citStr="Pradhan et al., 2011" startWordPosition="295" endWordPosition="298"> machine translation. The availability of corpora annotated with coreference relations has led to the development of a diverse set of supervised learning approaches for coreference. While learning models enjoy a largely undisputed role in many NLP applications, deterministic models based on rich sets of expert rules for coreference have been shown recently to achieve performance rivaling, if not exceeding, the performance of state of the art machine learning approaches (Haghighi and Klein, 2009; Raghunathan et al., 2010). In particular, the top performing system in the CoNLL 2011 shared task (Pradhan et al., 2011) is a multi-pass system that applies tiers of deterministic coreference sieves from highest to lowest precision (Lee et al., 2011). The PRECISECONSTRUCTS sieve, for example, creates coreference links between mentions that are found to match patterns of apposition, predicate nominatives, acronyms, demonyms, or relative pronouns. This is a high precision sieve, correspondingly it is among the first sieves to be applied. The PRONOUNMATCH sieve links an anaphoric pronoun with the first antecedent mention that agrees in number and gender with the pronoun, based on an ordering of the antecedents tha</context>
<context position="25898" citStr="Pradhan et al., 2011" startWordPosition="4302" endWordPosition="4305">e. We have run experiments in which the AC system was augmented with a feature that computed the normalized distance between a cluster and the beginning of the document, but this did not lead to an improvement in the results, lending further credence to the hypothesis that a strictly left to right ordering of the coreference decisions is not necessary, at least with the current features. The same behavior, albeit with smaller increases in performance, was observed when the DT and AC approaches were compared on the newswire section of the development dataset used in the CoNLL 2011 shared task (Pradhan et al., 2011). For these experiments, the AC system was trained on all 128 documents from the newswire portion of ACE 2004. On gold mentions, the DT and AC systems obtained a very similar performance. When evaluated only on links that contain at least one neutral pronoun, in a setting where the mentions were automatically detected, the AC approach improved the F1 measure over the DT system from 58.6% to 59.1%. One reason for the smaller increase in performance in the CoNLL experiments could be given by the different annotation schemes used in the two datasets. Compared to ACE, the CoNLL dataset does not in</context>
</contexts>
<marker>Pradhan, Ramshaw, Marcus, Palmer, Weischedel, Xue, 2011</marker>
<rawString>Sameer Pradhan, Lance Ramshaw, Mitchell Marcus, Martha Palmer, Ralph Weischedel, and Nianwen Xue. 2011. Conll-2011 shared task: modeling unrestricted coreference in ontonotes. In Proceedings of the Fifteenth Conference on Computational Natural Language Learning: Shared Task, pages 1–27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karthik Raghunathan</author>
<author>Heeyoung Lee</author>
<author>Sudarshan Rangarajan</author>
<author>Nate Chambers</author>
<author>Mihai Surdeanu</author>
<author>Dan Jurafsky</author>
<author>Christopher D Manning</author>
</authors>
<title>A multi-pass sieve for coreference resolution.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing (EMNLP’10),</booktitle>
<pages>492--501</pages>
<contexts>
<context position="1831" citStr="Raghunathan et al., 2010" startWordPosition="279" endWordPosition="282">of natural language processing problems, among them information extraction, question answering, and machine translation. The availability of corpora annotated with coreference relations has led to the development of a diverse set of supervised learning approaches for coreference. While learning models enjoy a largely undisputed role in many NLP applications, deterministic models based on rich sets of expert rules for coreference have been shown recently to achieve performance rivaling, if not exceeding, the performance of state of the art machine learning approaches (Haghighi and Klein, 2009; Raghunathan et al., 2010). In particular, the top performing system in the CoNLL 2011 shared task (Pradhan et al., 2011) is a multi-pass system that applies tiers of deterministic coreference sieves from highest to lowest precision (Lee et al., 2011). The PRECISECONSTRUCTS sieve, for example, creates coreference links between mentions that are found to match patterns of apposition, predicate nominatives, acronyms, demonyms, or relative pronouns. This is a high precision sieve, correspondingly it is among the first sieves to be applied. The PRONOUNMATCH sieve links an anaphoric pronoun with the first antecedent mention</context>
<context position="10488" citStr="Raghunathan et al., 2010" startWordPosition="1787" endWordPosition="1790">in order to enable the combination of the discourse salience features captured by the pronoun sieves with the semantic compatibility features for neutral pronouns that will be introduced in the next section. The OTHERPRONOUNMATCH sieve works exactly as the original PRONOUNMATCH: for a given non-neutral pronoun, it searches in the current sentence and the previous 3 sentences for the first mention that agrees in gender and number with the pronoun. The candidate antecedents for the pronoun are ordered based on a notion of discourse salience that favors syntactic salience and document proximity (Raghunathan et al., 2010). 4 Discourse Salience Features The IT/SPRONOUNMATCH sieves use the same implementation for finding the first matching candidate antecedent as the original PRONOUNMATCH. However, unlike OTHERPRONOUNMATCH and the other sieves that generate Boolean features, the neutral pronoun sieves are used to generate real valued features. If the neutral pronoun is the leftmost mention in the cluster ˆCj from a cluster pair h ˆCi, ˆCji, the corresponding normalized feature is computed as follows: 1http://nlp.stanford.edu/software/corenlp.shtml g(·) = Φk( 13 1. Let Sj = (S�j , S2j , ..., Snj ) be the sequence</context>
<context position="22664" citStr="Raghunathan et al., 2010" startWordPosition="3752" endWordPosition="3755">reference information, where coreference is marked only between mentions that belong to one of seven semantic classes: person, organization, location, geo-political entity, facility, vehicle, and weapon. This set of documents has been used before to evaluate coreference resolution sys16 System Mentions P R F1 DT Gold, all 88.1 73.3 80.0 AC Gold, all 88.7 73.5 80.4 DT Gold, neutral 82.5 51.5 63.4 AC Gold, neutral 83.0 52.1 64.0 DT Auto, neutral 84.4 34.9 49.3 AC Auto, neutral 86.1 40.0 54.6 Table 2: B3 comparative results on ACE 2004. tems in (Poon and Domingos, 2008; Haghighi and Klein, 2009; Raghunathan et al., 2010), with the best results so far obtained by the deterministic sieve system of Lee at al. (2011). There are 11,398 annotated gold mentions, out of which 135 are possessive neutral pronouns its and 88 are neutral pronouns it in a subject-verb-object triple. Given the very small number of neutral pronouns, in order to obtain reliable estimates for the model parameters we tested the adaptive clustering algorithm in a 16 fold crossvalidation scenario. Thus, the set of 128 documents was split into 16 folds, where each fold contains 120 documents for training and 8 documents for testing. The final res</context>
<context position="24803" citStr="Raghunathan et al., 2010" startWordPosition="4122" endWordPosition="4125">st one neutral pronoun, the improvement becomes substantial. AC increases F1 with 5.3% when the mentions are extracted automatically during testing, a setting that reflects a more realistic use of the system. We have also evaluated the AC approach in the Gold setting using only the original DT sieves as features, obtaining an F1 of 80.3% for all mentions and 63.4% – same as DT – for neutral pronouns. By matching the performance of the DT system in the first two rows of the table, the AC system proves that it can successfully learn the relative importance of the deterministic sieves, which in (Raghunathan et al., 2010) and (Lee et al., 2011) have been manually ordered using a separate development dataset. Furthermore, in the DT system the sieves are applied on mentions in their textual order, whereas the adaptive clustering algorithm AC does not assume a predefined ordering among coreference resolution decisions. Thus, the algorithm has the capability to make the first clustering decisions in any section of the document in which the coreference decisions are potentially easier to make. We have run experiments in which the AC system was augmented with a feature that computed the normalized distance between a</context>
</contexts>
<marker>Raghunathan, Lee, Rangarajan, Chambers, Surdeanu, Jurafsky, Manning, 2010</marker>
<rawString>Karthik Raghunathan, Heeyoung Lee, Sudarshan Rangarajan, Nate Chambers, Mihai Surdeanu, Dan Jurafsky, and Christopher D. Manning. 2010. A multi-pass sieve for coreference resolution. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing (EMNLP’10), pages 492–501.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Altaf Rahman</author>
<author>Vincent Ng</author>
</authors>
<title>Supervised models for coreference resolution.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>968--977</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="28344" citStr="Rahman and Ng (2009)" startWordPosition="4720" endWordPosition="4723"> error, instead the algorithm learns and uses a clustering threshold r to determine when to stop during training and testing. This required the design of a method to order cluster pairs in which the clusters may not be consistent with the true coreference chains, which led to the introduction of the goodness function in Equation 1 as a new scoring measure for cluster pairs. The strategy of continuing the clustering during training as long as a an adaptive threshold is met better matches the training with the testing, and was observed to lead to better performance. The cluster ranking model of Rahman and Ng (2009) proceeds in a left-to-right fashion and adds the current discourse old mention to the highest scoring preceding cluster. Compared to it, our adaptive clustering approach is less constrained: it uses only a weak, partial ordering between coreference decisions, and does not require a singleton cluster at every clustering step. This allows clustering to start in any section of the document where coreference decisions are easier to make, and thus create accurate clusters earlier in the process. The use of semantic knowledge for coreference resolution has been studied before in a number of works, </context>
</contexts>
<marker>Rahman, Ng, 2009</marker>
<rawString>Altaf Rahman and Vincent Ng. 2009. Supervised models for coreference resolution. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 968–977, Singapore, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Altaf Rahman</author>
<author>Vincent Ng</author>
</authors>
<title>Coreference resolution with world knowledge.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>814--824</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="29056" citStr="Rahman and Ng, 2011" startWordPosition="4834" endWordPosition="4837">st scoring preceding cluster. Compared to it, our adaptive clustering approach is less constrained: it uses only a weak, partial ordering between coreference decisions, and does not require a singleton cluster at every clustering step. This allows clustering to start in any section of the document where coreference decisions are easier to make, and thus create accurate clusters earlier in the process. The use of semantic knowledge for coreference resolution has been studied before in a number of works, among them (Ponzetto and Strube, 2006), (Bengtson and Roth, 2008), (Lee et al., 2011), and (Rahman and Ng, 2011). The focus in these studies has been on the semantic similarity between a mention and a candidate antecedent, or the parallelism between the semantic role structures in which the two appear. One of the earliest methods for using predicate-argument frequencies in pronoun resolution is that of Dagan and Itai (1990). Closer to our use of semantic compatibility features for pronouns are the approaches of Kehler et al. (2004) and Yang et al. (2005). The last work showed that pronoun resolution can be improved by incorporating semantic compatibility features derived from search engine statistics in</context>
</contexts>
<marker>Rahman, Ng, 2011</marker>
<rawString>Altaf Rahman and Vincent Ng. 2011. Coreference resolution with world knowledge. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 814–824, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kuansan Wang</author>
<author>Xiaolong Li</author>
</authors>
<title>Efficacy of a constantly adaptive language modeling technique for webscale applications.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP ’09,</booktitle>
<pages>4733--4736</pages>
<publisher>IEEE Computer Society.</publisher>
<location>Washington, DC, USA.</location>
<contexts>
<context position="19454" citStr="Wang and Li, 2009" startWordPosition="3230" endWordPosition="3233">studied a judge ’s explanation court studied the explanation Table 1: N-gram generation examples. features are computed at the level of cluster pairs as described in Equations 3 and 4. Their computation relies on the mention level rank (Equation 2) and semantic compatibility (Equation 6) respectively. 6 Web-based Language Models We used the Microsoft Web N-Gram Corpus2 to compute the pronoun context probability P(pcj(h)) and the candidate head probability P(h). This corpus provides smoothed back-off language models that are computed dynamically from N-gram statistics using the CALM algorithm (Wang and Li, 2009). The N-grams are collected from the tokenized versions of the billions of web pages indexed by the Bing search engine. Separate models have been created for the document body, the document title and the anchor text. In our experiments, we used the April 2010 version of the document body language models. The number of words in the pronoun context and the antecedent head determine the order of the language models used for estimating the conditional probabilities. For example, to estimate P(administration sent troops I administration), we used a trigram model for the context probability P(admini</context>
</contexts>
<marker>Wang, Li, 2009</marker>
<rawString>Kuansan Wang and Xiaolong Li. 2009. Efficacy of a constantly adaptive language modeling technique for webscale applications. In Proceedings of the 2009 IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP ’09, pages 4733–4736, Washington, DC, USA. IEEE Computer Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kuansan Wang</author>
<author>Christopher Thrasher</author>
<author>Evelyne Viegas</author>
<author>Xiaolong Li</author>
<author>Bo-june Hsu</author>
</authors>
<title>An overview of microsoft web n-gram corpus and applications.</title>
<date>2010</date>
<booktitle>In Proceedings of the NAACL HLT 2010 Demonstration Session, HLT-DEMO ’10,</booktitle>
<pages>45--48</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="13862" citStr="Wang et al., 2010" startWordPosition="2383" endWordPosition="2386">mp(m, cj), the semantic compatibility between a candidate antecedent mention m and the pronoun context cj. For the possessive pronoun its, we extract the syntactic head h of the mention m and replace the pronoun with the mention head h in the possessive context. We use the resulting possessive pronoun context pcj(h) to define the semantic compatibility as the following conditional probability: comp(m, cj) = log P(pcj(h)|h) (5) = log P(pcj(h)) − log P(h) To compute the n-gram probabilities P(pcj(h)) and P(h) in Equation 6, we use the language models provided by the Microsoft Web N-Gram Corpus (Wang et al., 2010), as described in the next section. Figure 1 shows an example of a possessive neutral pronoun context, together with the set of candidate antecedents that agree in number and gender with the pronoun, from the current and previous 3 sentences. Each candidate antecedent is given an index that reflects its ranking in the discourse salience based ordering. We see that discourse salience does not help here, as the most salient mention is not the correct antecedent. The figure also shows the 14 In 1946, the nine justices dismissed a case[7] involving the apportionment[8] of congressional districts. </context>
</contexts>
<marker>Wang, Thrasher, Viegas, Li, Hsu, 2010</marker>
<rawString>Kuansan Wang, Christopher Thrasher, Evelyne Viegas, Xiaolong Li, and Bo-june (Paul) Hsu. 2010. An overview of microsoft web n-gram corpus and applications. In Proceedings of the NAACL HLT 2010 Demonstration Session, HLT-DEMO ’10, pages 45– 48, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaofeng Yang</author>
<author>Jian Su</author>
<author>Chew Lim Tan</author>
</authors>
<title>Improving pronoun resolution using statistics-based semantic compatibility information.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>165--172</pages>
<contexts>
<context position="2969" citStr="Yang et al. (2005)" startWordPosition="458" endWordPosition="461"> PRONOUNMATCH sieve links an anaphoric pronoun with the first antecedent mention that agrees in number and gender with the pronoun, based on an ordering of the antecedents that uses syntactic rules to model discourse salience. This is the last sieve to be applied, due to its lower overall precision, as estimated on development data. While very successful, this deterministic multi-pass sieve approach to coreference can nevertheless be quite unwieldy when one seeks to integrate new sources of knowledge in order to improve the resolution performance. Pronoun resolution, for example, was shown by Yang et al. (2005) to benefit from semantic compatibility information extracted from search engine statistics. The semantic compatibility between candidate antecedents and the pronoun context induces a new ordering between the antecedents. One possibility for using compatibility scores in the deterministic system is to ignore the salience-based ordering and replace it with the new compatibility-based ordering. The draw11 First Joint Conference on Lexical and Computational Semantics (*SEM), pages 11–19, Montr´eal, Canada, June 7-8, 2012. c�2012 Association for Computational Linguistics back of this simple approa</context>
<context position="29504" citStr="Yang et al. (2005)" startWordPosition="4909" endWordPosition="4912"> resolution has been studied before in a number of works, among them (Ponzetto and Strube, 2006), (Bengtson and Roth, 2008), (Lee et al., 2011), and (Rahman and Ng, 2011). The focus in these studies has been on the semantic similarity between a mention and a candidate antecedent, or the parallelism between the semantic role structures in which the two appear. One of the earliest methods for using predicate-argument frequencies in pronoun resolution is that of Dagan and Itai (1990). Closer to our use of semantic compatibility features for pronouns are the approaches of Kehler et al. (2004) and Yang et al. (2005). The last work showed that pronoun resolution can be improved by incorporating semantic compatibility features derived from search engine statistics in the twin-candidate model. In our approach, we use web-based language models to compute semantic compatibility features for neutral pronouns and show that they can improve performance over a state-of-the-art coreference resolution system. The use of language models instead of search engine statistics is more practical, as they eliminate the latency involved in using search engine queries. Webbased language models can be built on readily availab</context>
</contexts>
<marker>Yang, Su, Tan, 2005</marker>
<rawString>Xiaofeng Yang, Jian Su, and Chew Lim Tan. 2005. Improving pronoun resolution using statistics-based semantic compatibility information. In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, pages 165–172.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>