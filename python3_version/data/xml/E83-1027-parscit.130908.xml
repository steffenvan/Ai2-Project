<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.89943">
SYSTEMIC GRAMMAR IN COMPUTATION:
THE NIGEL CASE
</title>
<author confidence="0.832188">
Christian M.I.M. Matthiessen,
</author>
<affiliation confidence="0.879251">
USC/Information Sciences Institute
</affiliation>
<sectionHeader confidence="0.999569" genericHeader="abstract">
1 INTRODUCTION
</sectionHeader>
<bodyText confidence="0.914801547169811">
Computational linguistics needs grammars for several different
tasks such as comprehension of text, machine translation, and
text generation.1 Clearly, any approach to grammar2 has
potentially something to offer computational linguistics, say for
parsing or text generation (and. by the same token, there is a
potential benefit from an application within computational
linguistics for each approach, cf. [Fawcett 80]). However, it is
equally clear that some approaches have much more to offer than
others. Here I will take a look at Systemic Linguistics3 in the
service of computational linguistics tasks, concentrating on a
1This research was supported by the Air Force Office of Scientific Research
Contract No. F49620-79.C.0181. The views and conclusions contained in this
document are those of the authors and should not be interpreted as necessarily
representing the official policies or endorsements, either expressed or implied, of
the Air Force Office of Scientific Research of the U.S. Government. I am very
grateful to William Mann for many helpful comments on various versions of this
paper; much of the discussion builds on work by him. tam also deeply indebted to
Michael A.K. Halliday; I have profited from and drawn heavily on his insights about
English grammar and semantics and the systemic framework. I am solely
responsible for all errors.
2There are now in the early 80s a great number of grammatical mechanisms
around witness for example the 1979 Milwaukee conference on current
alternative approaches to syntax where around fourteen alternatives were
presented (see [Moravcsik &amp; Wirth 801). a collection which is only a sample,
leaving out many current approaches. The term grammar is used in its traditional
sense in systemic linguistics: it subsumes both syntax and morphology. This use
contrasts with the more recent one where grammar subsumes semantics, syntax,
morphology, and phonology.
3There are few grammatical mechanisms that have been developed within a
framework with as impressive a tradition as Systemic Linguistics and with as wide a
scope. The systemic framework is not just a non.transformational alternative to
Chomsky&apos;s transformational grammar. It is different from Chomskyan work at the
level of framework, not only at -the level of mechanism and notation. Systemic
linguists ask questions like &amp;quot;How does communication succeed?&amp;quot;, &amp;quot;What are the
relations between context and language use?&amp;quot;, &amp;quot;What can a speaker of English do
grammatically to achieve a particular purpose?&amp;quot;. &amp;quot;What are the options for
expressing grammatically a particular range of meanings?&apos;, &amp;quot;What functions does
language serve?&amp;quot; and so on. These are questions that are crucial to the success
of for example a text generation system. One consequence of questions of this
type has been in Systemic Linguistics that text as a communicative unit is taken to
be the basic linguistic unit rather than the sentences that are used to express texts,
see (Hasan 78) and [Hasan 79). Obviously, this view has far-reaching effects on
the onception of grammar. The systemic conception of language draws on
continental European work, the British tradition started by Firth, and American
anthropological linguistics. It has much to offer at a time when communication is
beginning to assert itself as a central organizing notion in linguistic research
instead of the much more limited notion of (primarily syntactic) competence that
received so much attention for a long time in the 60s. but began to lose its
apparent attractiveness in the 70s. For discussion of systemic grammar, see e.g.
[Halliday 69]. [Halliday 76a), [Hudson 76]. [Davey 79], [Berry 77]. [Fawcett 80], and
[Matthiessen 83].
large computational systemic grammar for text generation (Nigel)
that is currently being developed.
</bodyText>
<subsectionHeader confidence="0.986594">
1.1 What can systemic linguistics offer?
</subsectionHeader>
<bodyText confidence="0.999666789473684">
The question I will try to answer in this paper is what systemic
linguistics can offer computational linguistics. Since the answer is,
I think, far too long for a short discussion, I will let a more specific
question represent the general question here: What can systemic
linguistic accounts of grammar and semantics offer computational
linguistics in the area of text generation? This question excludes
for example the use of systemic grammar in parsing -- see
[Winograd • 72] and the large systemic body of work on
discourse organization (see in particular [Halliday &amp; Hasan 76],
[Hasan 78], [Hasan 79]. [Halliday &amp; Hasan 80], [Martin 83], and
[Butler 83]).
The text generation task raises a number of demands on the
grammatical component. Very roughly and generally stated, they
amount to generating in conformity with diverse needs, such as
the need for denotational appropriateness and the need for fluent
text. There is no published general solution to the problem of
cosntrolling the grammar to generate in conformity with diverse
needs. The discussion here continues and elaborates parts of
[Matthiessen 81].
</bodyText>
<subsectionHeader confidence="0.973955">
1.2 Systemic functionalism as a contribution
</subsectionHeader>
<bodyText confidence="0.9997639">
A cornerstone in systemic linguistics as developed by M.A.K.
Halliday and others is systemic functionalism.4 Grammar is to be
investigated and interpreted in terms of the purposes it fulfills. Its
organization is a function of these higher-level considerations.
Apart from guiding research in systemic linguistics, this
functionalism has been important in the design of systemic
grammar. I will identify two design properties characteristic of
systemic grammars that make them well suited to deal with the
demands, better than grammars that are not designed to reflect
the functionalism that the two properties stem from. The two
</bodyText>
<footnote confidence="0.9945184">
4There are also strictly formal considerations having to do with the notation
used. These have been more central in work on e.g. Lexical Functional Grammar,
Functional Unification Grammar, and Generalized Phrase Structure Grammar. The
results may or may not generalize to Systemic Grammar; that is a matter for future
discussion.
</footnote>
<page confidence="0.998337">
155
</page>
<bodyText confidence="0.999968615384615">
properties have to do with the organization of grammar and with
the process of sentence generation; they constitute factorings of
the sentence generation task. One is a factoring into a process of
controlled choice and a process of structure specification as a
consequence of choices made. This factoring is due to the need
to represent the organization of grammar in its role as a resource
for communicative needs. The other is a factoring of the
grammatical resources into domains that serve different purposes
(what will be called the meta-functional factoring). I will use Nigel
to illustrate how they work and what their value is in text
generation systems. I will also present a completely new addition
to systemic grammar, the so-called chooser framework, developed
in the context of the text generation task.5
</bodyText>
<subsectionHeader confidence="0.999581">
1.3 Organization of the discussion
</subsectionHeader>
<bodyText confidence="0.998982125">
First, I will sketch the steps in the process of text generation so
that the role grammar has to play can be identified (section 2). The
rest of the paper illustrates how systemic functionalism enables
grammar to cope with tasks its role in the text generation process
entails. I will use the generation of a particular text realized by a
single sentence, Had Sir Christopher Wren been going to build a
cathedral ever since his youth?, as a way of illustrating and
organizing the discussion.
</bodyText>
<sectionHeader confidence="0.997133" genericHeader="method">
2 THE TEXT GENERATION PROCESS
</sectionHeader>
<bodyText confidence="0.9412767">
In this presentation of text generation. I will follow an expository
design by William Mann (see [Mann 83]). The model of text
generation he gives an overview of is called Penman. It has been
designed for monologue only, without for example any facilities for
comprehension. However, although Penman cannot take part in a
conversation, I will present an example that corresponds to a turn
in a dialogue; Penman will be assigned the task of asking a
question in this illustration. The reason for doing this is purely
illustrative; the task of asking a question is a concise way of
bringing out a number of features of the grammar.
Assume that a need for a text has arisen. In a conversation
about Sir Christopher Wren. the need arises to know whether
there was a plan for him to build a cathedral sometime after the
Functionalism in linguistics will hopefully be reconciled with goal reasoning as
it has developed in computational linguistics and Al. The term function has two
related meanings in current linguistics, in addition to its strictly mathematical
sense. One is &amp;quot;meta-f unction,&amp;quot; which can be defined as the purpose or goal
-- effect considerations that defines a particular component of the grammar. The
second meaning of function is what Halliday has called &amp;quot;micro-function&amp;quot;. This type
is the one that figures in traditional grammar subject, object, etc. -- and more
</bodyText>
<listItem confidence="0.872991888888889">
• ntly in for example Relational Grammar, Case Grammar, and Lexical
Functional Grammar Conceptually. micro-functions are very much like roles or
slots used in semantic nets. (Micro vs. macro is here simply a distinction between
small and big; meta means that the functions are on another plane, not part of the
structure. In this way it is the same &amp;quot;meta&amp;quot; we find in for example &amp;quot;meta-
language&amp;quot;) For an interesting discussion of the development of meta-functions
and micro-functions out of a set of macro-functions in early child language. see
[Halliday 75]. For some discussion of functional grammar, see e.g. (Halliday 69],
[Halliday 74], [Fawcett 80], and [Dik 78].
</listItem>
<bodyText confidence="0.899453666666666">
time when he was still a youngster. The task of the text generator
is to satisfy this need. (As we will see, one way of meeting this
need is to ask Had Sir Christopher Wren been going to build a
cathedral ever since his youth?) Three processes, Acquisition,
Planning, and Sentence generation, work in text generation
towards meeting the need.
</bodyText>
<subsectionHeader confidence="0.998072">
2.1 Steps in the text generation process
</subsectionHeader>
<bodyText confidence="0.99998119047619">
Given the need for text, the text generator identifies the goals
that the text should pursue and acquires the information
necessary to pursue it. This process is supported by a knowledge
base. The goal is roughly that the addressee recognize that the
information desired has been requested; in this case, we want to
find out whether Sir Chris had been going to build a cathedral or
not.
Next. there is a process of text planning. In response to the goal
for the text and the information acquired, a plan to achieve the
goal is created. The planning process uses a rhetoric of text
organization to create the text plan.
The plan consists of (among other things) conceptual loci (at
least one), each of which corresponds roughly to, an independent
clause.5 In the present example, a text with one such locus is
planned, a locus we can call CATHEDRAL BUILDING. It is up to
sentence generation to realize this plan, i.e., to find a wording
for it. The process of sentence generation does this, relying on
grammar as its resource. The remainder of the paper deals with
this part of the text generation process. The grammar I will draw
on for the rest of the discussion is the Nigel grammar, the systemic
text generation grammar mentioned earlier.7
</bodyText>
<subsectionHeader confidence="0.9941">
2.2 The task for sentence generation
</subsectionHeader>
<bodyText confidence="0.9490616">
The sentence generation process can start when there is a fully
specified local plan for CATHEDRAL-BUILDING in the text plan for
an independent clause. Such a plan includes among other things:
- A pointer to the process aspect of CATHEDRAL.
BUILDING, called BUILDING in our example.
</bodyText>
<listItem confidence="0.9988416">
• A specification of the local speech act, here called
BUILDING-OUESTION; see the discussion of Mood
below.
• A plan for temporal relations; cf. the discussion of
Tense below.
</listItem>
<footnote confidence="0.947994">
6A traditional distinction between clause and sentence is maintained in systemic
linguistics. A sentence can be defined simply as a complex of clauses, related by
coordination or subordination.
7Although the text generation process can conveniently be factored into the
three subprocesses identified above, these subprocesses are not necessarily
serially arranged. There is one additional process, a process of improvement. For
instance, the quality of the Output of sentence generation is evaluated and then.
based on this evaluation, changes in the plan are proposed.
</footnote>
<page confidence="0.998527">
156
</page>
<bodyText confidence="0.99980032">
- Possibly a specification of a specific conceptual
context, defined temporally, spatially, in terms of
purpose, or in some other way, to be indicated as a
part of the organization of the text in terms of
conceptual contexts. There is no such specification
for the present example.
Possibly a specification of a conjunctive relation (like
contrast, enumeration, temporal sequence,
disjunction, and cause) to be expressed. There is no
such specification for the present example.
A list such as this represents expressive demands, all of which
the grammar of the sentence generation process has to cope with,
but it imposes no structuring or factoring of this process. The task
of the grammar and its semantics is to impose an organization of
and find a wording for the material relevant to the local plan.
Consequently, it is quite helpful if the grammar of the sentence
generation process is organized in such a way that the process
can be decomposed into manageable subprocesses.
In what follows, I shall show how there is a natural factoring of
the sentence generation process that derives from the systemic
organization of a grammar. As we will see, this factoring is due to
the research programme (a consequence of systemic
functionalism) in systemic linguistics to uncover the functional
organization of grammar and semantics and to reflect it in
systemic notation.
</bodyText>
<sectionHeader confidence="0.9994895" genericHeader="method">
3 SYSTEMIC FACTORING OF SENTENCE
GENERATION
</sectionHeader>
<bodyText confidence="0.999781875">
The design of systemic grammar is the result of a long-term
effort to create a grammatical framework that reflects the
functional organization of grammar. The important point to note
here is that the organization of systemic grammar leads naturally
to a factoring of the sentence generation process. In other words,
the systemic factoring of the sentence generation process is due
to the organization of systemic grammar.
There are two simultaneous factorings that cross-cut:
</bodyText>
<listItem confidence="0.9831818">
1. The process of structure building is factored into two
processes, each of which with its own notation: The
process of choosing among grammatical alternatives
(section 4.1) and the process of realizing, or re-
expressing, a particular choice as a specification of a
fragment of grammatical structure (section 4.2).
2. The statements of grammatical choice, realizations of
choice, and resulting structure are factored into three
fairly independent processes: an ideational process
of representing the speaker&apos;s experience, an
interpersonal process of specifying the interaction
between speaker and hearer (in terms of speech act
and role assignments), and a textual process of
enabling the two other &apos;processes. This is the meta-
functional factoring; cf. section 5.
</listItem>
<bodyText confidence="0.999955333333333">
The meta-functional factoring is possible because of the
notations developed for choice and realization of choice into
structure as a configuration of functions. Features originating in
different meta-functions can be used to co-classify a grammatical
unit and functions from different meta-functions can be conflated
so that they apply to the same constituent in a structure.
</bodyText>
<sectionHeader confidence="0.9999165" genericHeader="method">
4 FACTORING INTO CHOICE AND
REALIZATION
</sectionHeader>
<subsectionHeader confidence="0.997023">
4.1 The process of choosing
</subsectionHeader>
<bodyText confidence="0.999917333333333">
The separation of statements of grammatical choice alternatives
from structure specifications allows the grammar to have choice
as its central organizing principle. The systemic network notation
has been developed to make statements of minimal grammatical
choice points and statements about the inter-dependencies
among these choice points possible. The process of choice is
itself factored into two parts: (i) Grammatical choice: the
statement of what the grammatical choice points and their
interdependencies are the systemic network notation just
mentioned -- and (ii) Semantic choice: statements about how to
select among the options of the grammatical choice points -- a
chooser semantics.
</bodyText>
<subsubsectionHeader confidence="0.732651">
4.1.1 Grammatical choice
</subsubsectionHeader>
<bodyText confidence="0.999947529411765">
Each choice point is represented by a system. A system is a
disjunction of two or more options (represented by grammatical
features like Declarative Past and Passive).8 It has an entry
condition, which is the condition under which the choice is
available. As long as the condition has not been satisfied, no
choice can be made. The condition is a Boolean combination of
features (without negation, though) minimally a single feature.
When the entry condition is satisfied. one of the feature options
must be chosen. An example of a system is given below in Figure
1
Together the systems of the grammar constitute a network of
systems: The features that are the output of one system are part
of the entry conditions of other systems. The network as a whole
represents the entire scope of the process of grammatical
selection; the individual systems represent the decomposition of
this process into minimal choice points. Below. in Figure 2, the
network fragment for mood is presented; see section 6.
</bodyText>
<subsectionHeader confidence="0.728365">
4.1.2 Semantic choice
</subsectionHeader>
<bodyText confidence="0.974490555555556">
The process of purposefully choosing among the feature options
of a system is represented by a chooser or choice expert. The
grammar supplies us with linguistically justified control points, the
sIn systemic grammar, a distinction is usually (and always in work by Halliday)
maintained between features and functions like SUBJECT, ACTOR, and THEME.
Features are the building blocks of the paradigmatic organization of grammar, te,
of grammar as choice. Functions are the building blocks of the syntagmatic
organization, i.e.. of grammatical structure. The distinction is not maintained in
Martin Kay&apos;s Functional Unification Grammar (Cf. [Kay 79]).
</bodyText>
<page confidence="0.988921">
157
</page>
<bodyText confidence="0.999982333333333">
systems. Each system is assigned a chooser, which is a procedure
composed of one or more steps leading to the determination of
which grammatical feature to choose.
Where is the information relevant to the determination of which
option should be chosen located? As we have seen, in addition to
the grammar component, our text generation system has a
knowledge base and a text plan for the text to be generated.
We can call these components and other possible sources of
knowledge the environment of the grammar component. It is
from this environment that a chooser demands the information it
needs in order to be able to choose one of the features of its
systems. It demands this information by presenting formal
inquiries to the environment.9 An inquiry is asked of one or more
parameters. The parameters are variables like PROCESS, GOAL,
TEmPoo, and POLARITY for which conceptual values are identified
in the generation of every grammatical unit. As we will see
presently in section 4.2, grammatical structure is a specification of
grammatical functions and the variables correspond to those
grammatical functions. The conceptual values are called hubs;
they are concepts from which other concepts can be accessed.
For instance, once a concept for a particular action has been
identified, the participants in the action can be identified through
the action concept. The inquiries are the only interaction between
the choosers and the environment.
</bodyText>
<subsectionHeader confidence="0.998789">
4.2 The realization process
</subsectionHeader>
<bodyText confidence="0.962987">
There is a separate notation for the realization process.
Grammatical structure is defined in terms of relations that can
hold between grammatical functions; grammatical structure is a
configuration of functions like SUBJECT, PROCESS, ACTOR, and
THEME. The relations (conflation, expansion, ordering; see below)
are introduced by realization statements. In the realization
process, a function structure is specified step by step: A small
number of realization operators operate on one grammatical
function, a combination of grammatical functions.19 or a
grammatical function and a set of features.&amp;quot; A realization
statements consisting of an operator and one or more operands is
associated with a particular grammatical feature in a system; when
that feature is chosen. the realization statement can be activated.
9These formal inquiries have informal versions that are informal questions in
English used for purposes of discussion and presentation.
1°The realization operations include Insert, which inserts a function into the
structure being built, Expand, which specifies a constituency relation between a
function and one or more daughters, Order, which order two grammatical
functions, and Conflate, which states that two functions, say SUBJECT and AGENT,
describe the same constituent. Two functions are not ordered until it is clear that
the ordering imposed is the final one. There is thus no need for movement
:formations. In fact, there are no transformations at all: A realization is only
stated at a point where it is clear that it represents the final state.
This latter category of realization operator serves to state how the functionally
defined constituents of a particular structure, say clause structure or prepositional
phrase structure, are to be expressed grammatically or lexically. We will meet the
operator Classify which associates a lexical feature with a function: this feature is a
constraint on what lexical items can realize the constituent that the function
defines.
Among the important properties of the realization process, we
find:
• The specification of structural presence (the insertion
of a function into the structure being built) and the
specification of constituency relations are separate
from ordering specifications. For example, the
specifications of the presence of FINITE, the finite
verbal element of a clause, and suBJECT are separate
from specifications of their ordering. Either can be
specified to follow the other and there is no need for a
transformation to invert an original ordering. This
follows the general tendency in the grammar towards
factoring the realization (i.e., structure building)
process into functionally motivated steps. It is typically
the case that the presence of a function and its
ordering with respect to other functions serve two
different purposes.
There is a &amp;quot;unification&amp;quot; operator on functions, called
Conflate, that enables the grammar to reconcile
function structure fragments that are contributions
from areas of the grammar serving different purposes.
For example, suaJECT is conflated with different
functions depending on the voice of the clause
ACTOR, GOAL, RECIPIENT, etc..
Collections of features that determine how each
constituent of e.g. cfause structure is further specified
can be built up step by step. The features are
associated with functions. Whenever two functions
are declared to describe the same constituent, i.e.,
are conflated, their feature collections are merged.
For instance, the auxiliary had has that form in our
example because it serves both the function TENP00
which constrains it to be a past form and the function
TEMPO, which constrains it to be a form of the auxiliary
have.
Now I will show in some more detail how the sentence
generation process is organized. I will use the example already
introduced and structure the discussion around the meta.
functional factoring of sentence generation. We will see examples
of all the characteristics of the choice process and the realization
process identified above.
</bodyText>
<sectionHeader confidence="0.999891" genericHeader="method">
5 META-FUNCTIONAL FACTORING
</sectionHeader>
<bodyText confidence="0.99906975">
To see how the multi-functional factoring works, we will return to
our CATHEDRAL-BUILDING example and look at it first in an
interpersonal perspective, then in an ideational perspective, and
finally in a textual perspective. Different perspectives draw on
different types of information in the environment. The final
wording the grammar will give us is Had Sir Christopher Wren
been going to build a cathedral ever since his youth?. We will
consider the three meta-functions identified above; each
corresponds to a different &amp;quot;event&amp;quot;. There is the textual event
itself, the event or process of creating a text for the addressee that
enables the speaker to achieve his goals (the textual meta.
function). In addition, we have (i) the speech event, an act of
</bodyText>
<page confidence="0.993159">
158
</page>
<bodyText confidence="0.99920225">
speaking involving speaker and addressee (the interpersonal
meta-function), and (ii) an event in the speaker&apos;s experience (real
or imagined, recalled or projected) (s)he wants to represent (the
ideational meta-function).12
</bodyText>
<subsectionHeader confidence="0.823571">
5.1 Interpersonal choices
</subsectionHeader>
<bodyText confidence="0.999987733333333">
When they explore the part of the grammar that deals with the
clause as interaction between speaker and hearer, choosers ask
questions that have to do with some aspect of the speech act,
such as: (i) Mood, i.e., a classification of the speech act: Is the
speech act (BUILDING-QUESTION) a command? Is the speech act
a question? I will use the mood area below to show in more detail
how the grammar works; see section 6. (ii) Identity of
speaker/hearer: What is the identity of the hearer? Is the hearer
included in the proposition? Here there is no involvement of
speaker/hearer. (iii) The polarity of the speech act: Is the speech
act a positive assertion or a denial? For polarity in our example,
see section 6.4. (iv) The sincerity of the act: Is the assurance of
the speaker&apos;s sincerity to be expressed? Is a request for the
hearer&apos;s sincerity to be expressed? Here we do not have a
specification of a marking of sincerity.
</bodyText>
<subsectionHeader confidence="0.982485">
5.2 Ideational choices
</subsectionHeader>
<bodyText confidence="0.999378875">
Second, consider the exploration of the clause as a
representation of our experience. Chooser questions here
concern the structure and character of the conceptual situation
we are to represent. (i) Transitivity, i.e., the organization of our
experience as a process with one or more participants and
possibly attendant circumstances: Here we choose to represent
CATHEDRAL-BUILDING as an external process where one entity
(SIR CHRIS) causes the building process. which effects, i.e.,
brings into existence, another entity (CATHEDRAL).
The function structure generated by realization statements that
re-express our choices as structure has as functional constituents
ACTOR, PROCESS, and GOAL, all of which carry hub associations.
ACTOR is associated with SIR CHRIS, PROCESS with BUILDING,
and GOAL with CATHEDRAL. In the final wording of the clause, Sir
Christopher Wren is the ACTOR of the clause, built the PROCESS,
and this cathedral is the GOAL.
concepts, SIR CHRIS associated with ACTOR and CATHEDRAL
with Pom., which is conceptually closer the the topic of the
paragraph being created? Is the causer of the event to be
mentioned? In our example, the concept WREN is the paragraph
topic and we get an active clause with a conflation of ACTOR and
SUBJECT, i.e., ACTOR/SUBJECT.
(ii) Theme: For a particular ideational function, we ask if it serve
as a conceptual context for the rest of the clause? For example, it
is determined that CATHEDRAL is not to serve this function.
Similarly, for interpersonal functions. Here, the conceptual context
in relation to which the remainder is interpreted is FINITE, an
indication that the clause expresses a question about polarity.
The different strands of functional reasoning hinted at above are
unified into one structure as I will show below in section 8.
Meanwhile, mood and tense will serve as representatives of the
full range of choices sketched in this section.
</bodyText>
<sectionHeader confidence="0.999697" genericHeader="method">
6 INTERPERSONAL CHOICES: MOOD
</sectionHeader>
<bodyText confidence="0.999804333333333">
Mood is the interpersonal part of clause grammar that expresses
the role the speaker adopts and the role (s)he gives to the
addressee in terms of speech act. I will present the choice
organization of mood first, then the structural effects of different
Choices. and finally I will show how mood selections can be
controlled.
</bodyText>
<subsectionHeader confidence="0.975797">
6.1 Mood choices
</subsectionHeader>
<bodyText confidence="0.999949">
In English there is a grammatical choice for clauses between
imperative ones and indicative ones. This choice of the mood of a
clause is represented by the mood system; the two options that
constitute the choice are represented by the features Imperative
and Indicative. Only clauses with a finite verb select for mood;
infinitival and gerundial ones do not. This fact is captured through
the entry condition of the system, which says that if the clause is
Finite, the mood system can be entered. A diagrammatic
representation of the system is given in Figure 1.
</bodyText>
<sectionHeader confidence="0.689453" genericHeader="method">
-- Indicative
</sectionHeader>
<bodyText confidence="0.487047090909091">
. (ii) Tense, i.e., the organization of our experience in terms of Finite --i)
time relations: How is the event from our experience (here the Imperative
CATHEDRAL-BUILDING event) to be related temporally to the
speech event? This intricate question will be further examined in
section 7 below.
5.3 Textual choices KEY TO GRAPHIC NOTATION
Finally, let us look at the clause as a message, the textual Entry condition: &amp;quot;Finite&amp;quot;
perspective. (i) Voice: Of two particular ideationally identified Feature options: &amp;quot;Indicative&amp;quot; and
&amp;quot;Indicative&amp;quot;
12These two events may overlap in various wayS. of course, as in so.called
performative sentences. Figure 1: The mood system in English
</bodyText>
<page confidence="0.997964">
159
</page>
<bodyText confidence="0.999953416666667">
The feature Indicative is the entry condition to the system of
IndicativeMood where the options are Declarative and
Interrooative. There is an additional step. The feature
interrogative is the input to the system InterrogativeType where
the options are WhInterrociative and Polarity-Interrooative. This
network is represented diagrammatically in Figure 2. The boxes
under the features in the diagram contain realization statements.
Our example can be represented as a path through the network
for mood. The features Indicative, Interrogative, and
Polarity-Interrogative are selected in that order. Each feature has
structural consequences; the functional structure is built step by
step.
</bodyText>
<subsectionHeader confidence="0.944974">
6.2 Realizations and the structure of mood
</subsectionHeader>
<bodyText confidence="0.999425">
The structural realization of mood is in the m000 constituent, a
function which embodies the mood or speechact aspect of the
clause. The internal structure of m000 expresses the mood
selection of the clause.13 The two principal daughters are
SUBJECT and FINITE, the finite verbal element of the clause. In
</bodyText>
<figure confidence="0.730888">
4
;38
</figure>
<figureCaption confidence="0.524509333333333">
13Indicative clauses typically have a SUBJECT in English. whereas imperative
ones do not. Consequently, there is a realization statement which says &amp;quot;Insert
SUBJECT&amp;quot; if the clause is Indicative. This means that the grammatical function
SUBJECT is inserted into the grammatical structure being built. There is no need to
delete SUBJECT in imperative clauses; the function is never inserted unless it is
actually expressed.
</figureCaption>
<bodyText confidence="0.80159325">
Declarative clauses, SUBJECT precedes FINITE; in
Polarity-Interrogative clauses, FINITE precedes SUBJECT, as in our
example.
In our example, the mood structure will be as diagrammed in
</bodyText>
<figureCaption confidence="0.6862595">
Figure 3. The constituent organization is the result of the
application of (Expand m000 SUBJECT) and (Expand mow FINITE).
</figureCaption>
<figure confidence="0.905358">
MOOD
FINITE SUBJECT
Had Sir Christopher
</figure>
<figureCaption confidence="0.927531">
Figure 3: Mood structure in polarity interrogative
6.3 Semantic mood choices
</figureCaption>
<bodyText confidence="0.988565034482759">
Each system in the mood network is controlled by a chooser.
For instance, the mood chooser of the mood system in Figure
1 above, asks questions that identify information about the speech
act of the clause to be generated. Basically, if the intention is to
command, the chooser chooses the feature Imperative otherwise
the feature Indicative.
For our mood system the chooser interaction with the
environment proceeds as follows:
ENVIRONMENT CHOOSER
Is the illocutionary point of
the surface level speech act
represented by BUILDING-QUESTION
(MOOD) a command, i.e. a
request by the speaker of an
action by the
hearer?
It is not a command.
Then I choose feature Indicative.
This is of course an informal dramatized representation of what
goes on, but the dialogue illustrates the interaction between
environment and chooser: The chooser presents a inquiry to the
environment, the environment responds, and the chooser chooses
a feature in conformity with the response.
The inquiry above requests a classification of a hub, called
BUILDING-QUESTION in the example. The BUILDING-QUESTION
hub is associated with the grammatical (micro-)function m000.
Two additional inquiries establish that BUILDING-QUESTION
should be expressed by an Interrogative clause and that this is a
Polarity- Interrogative.
</bodyText>
<figure confidence="0.9940214">
zE
1
.13
3
X
</figure>
<figureCaption confidence="0.99943">
Figure 2: The grammar of mood: network representation
</figureCaption>
<page confidence="0.984349">
160
</page>
<subsectionHeader confidence="0.933936">
6.4 A note on polarity
</subsectionHeader>
<bodyText confidence="0.998044">
The choice of mood determines how we choose polarity in
English. In Polaritv-interrogativE clauses, the choice between
Positive, as in Had Sir Christopher Wren been going to build a
,Cathedral, and Negative, as in Hadn&apos;t Sir Christopher Wren been
going to build a cathedral?, is a choice that has to do with the bias
in the reader&apos;s assumptions about which situation (s)he thinks
obtains.
In our example, an unbiased question is intended and Positive is
chosen. The realization of the choice is that the function FINITE is
prohibited from being realized by a verb with the feature negative;
it is outclassified for that feature: (Outclassify FINITE negative).
We can symbolize this by associating &amp;quot;.negative&amp;quot; with FINITE.
Notice that this realization constitutes a constraint on how the
constituent described by FINITE can be expressed. As we will see
in section 7, other constraints on the constituent come from
another part of the grammar (the functions TEMPO° and TEMPO).
</bodyText>
<sectionHeader confidence="0.995937" genericHeader="method">
7 IDEATIONAL CHOICES: TENSE
</sectionHeader>
<bodyText confidence="0.999861090909091">
Independent of and parallel with the grammar of mood is the
grammar of tense. The two parts of the grammar originate from
two different meta-functions, the interpersonal one and the
ideational one.14
[Halliday 76b]). It is possible to iterate over tense options just as it
is possible to iterate over tense operators in some tense logics.
(Cf. will have been going to leave and FPFp where p is a
proposition and F and P are tense operators.) The iteration
defines tenses of different orders, starting. with first order (or
primary) tense, then second order tense, third order tense, and so
on.
</bodyText>
<subsectionHeader confidence="0.9959">
7.2 Tense choosers
</subsectionHeader>
<bodyText confidence="0.999782923076923">
Each selection of Past Present or Future corresponds to a
specification of a precedence relation between two times, Tx and
T0. These times are concepts in Nigel&apos;s environment. The task of
each tense chooser is to establish what the current times to be
related are, i.e., a current T and T pair, and what relationship
obtains between them. This exploration proceeds in a step by
step fashion, guided by the grammar.
In our example, there are four times: the time of speaking, called
NOW, a time prior to that which falls within the period of Sir Chris&apos;s
life under discussion, call it MATURE-TIME, a time prior to that
which falls within the period of his youth, call it YOUTH-T1ME, and
the time of the building of a cathedral, call it BUILDING-TIME. The
temporal relations are represented in Figure 4.
</bodyText>
<equation confidence="0.574235">
NOW
MATURE-TIME
YOUTH-TIME
</equation>
<subsectionHeader confidence="0.918898">
7.1 Grammar of tense
</subsectionHeader>
<bodyText confidence="0.974746590909091">
In English Indicative clauses (cf. the previous section), if they are
non-modal, there is always a specification of at least one relation
of precedence between two times, one of which is the time of
speaking. This is the system of primary tense, whose options are
Past vs. Present vs. Future. The realizations of these features are
stated in terms of the tense function TEMPO°. If Past is chosen, the
realization is (Classify TEMPO° past); if Future is chosen, the
realization is (Classify TEmP00 will). In the latter case, TEMPO° is a
separate constituent, as in will build; in the former case TEmPoo is
fused. i.e. conflated, with whatever verbal function follows to the
right when Future is chosen as in built. In English, the primary
present tense is morphologically unmarked.
It is possible to generate a More elaborate temporal verbal
structure, with more than one tense function:
TEMPO, TEMPO1 TEMPO2
will have ( jump )ed
This is possible because the grammar of tense does not just
contain the system of primary tense, but also, in principle,
indefinitely many systems of secondary tense (see especially
14Note, however, that the full resources of tense are only at work in Indicative
clauses, For example, we cannot cm English) request of an addressee the past
execution of an action.
</bodyText>
<figure confidence="0.594113">
BUILDING-TIME
</figure>
<figureCaption confidence="0.995262">
Figure 4: Temporal relations
</figureCaption>
<bodyText confidence="0.870501">
ihe tense functions receive hub associations. First, TEmPoo and
.TEMPO, are identified as NOW and MATURE-TIME respectively,
then the following dialogue ensues:
ENVIRONMENT CHOOSER
</bodyText>
<sectionHeader confidence="0.777368666666667" genericHeader="method">
Does MATURE-TIME
(TEMP01) precede
NOW (TEMP00)?
</sectionHeader>
<bodyText confidence="0.901088222222222">
Yes, it does.
Then I choose Past.
This procedure illustrates the selection of primary or first order
tense. This type of activity is repeated for the pair MATURE-TIME
(TEMPO) and YOUTH-TIME (TEmPo2) where the choice is a second
order Past and for the pair YOUTH-TIME (TEmPo2) and BUILDING.
TIME (TEmPo3) where the choice is a third order Future. As a
result, we get three orders of tense, (i), (ii), and (iii), the
realizations of which are:
</bodyText>
<page confidence="0.986858">
161
</page>
<figure confidence="0.6805082">
(i) Past (Classify TEMPO° past)
(ii) Past (Classify TEMPO, have)
(Classify TEMPO3 enparticiple)
(iii) Future (Classify TEMPO, be going)
(Classify TEMPO3 to-infinitive)
</figure>
<bodyText confidence="0.997259875">
To sum up: Both the process of choosing tense and the process
of specifying a tense structure are factored into steps that
correspond to minimal temporal relations. The tense functions are
ordered as a collection of tense functions: the sequence is iconic
with the order of tense; increase in order of tense corresponds to
the left to right sequence of tense functions. Since there are no
more tense selections and no voice auxiliary, TEMPO3 is conflated
with PROCESS: (Conflate TEMPO3 PROCESS) is activated.
</bodyText>
<sectionHeader confidence="0.9999745" genericHeader="method">
8 RECONCILIATION OF THE META-
FUNCTIONS: STRUCTURAL RESULT
</sectionHeader>
<subsectionHeader confidence="0.925759">
8.1 Conflation of FINITE and -rEmPO,
</subsectionHeader>
<bodyText confidence="0.994547">
The two function structure fragments we have generated are
(mom FINITE SUBJECT) and TEMP00/TEmPO1 TEMPO. TEMPO3.
Typically FINITE and TEMPO° conflate and the two fragments
combine into the structure in Figure 5. Similarly, as already
indicated, we have a conflation of TEMPO3 with PROCESS. The latter
function is a transitivity function and carries feature information
about the transitivity type of the verb (i.e, constrains build in
transitivity), symbolized by the feature transitive. Each one of the
functions carries constraining feature information.
As the figure indicates, there are two consequences of the
conflation of FINITE with TEMP00:
1. Feature constraints derived from independent choices
are merged and co-constrain the final expression. In
other words, for polarity reasons. had appears as had
rather than hadn&apos;t, and for tense reasons, it appears in
this form rather than for example has, have, will, or
was.
2. The final sequence is a result of two independent
ordering specifications. viz, the mood specification
that FINITE comes before SUBJECT and the tense
specification of the ordering of tense auxiliaries. In
other words, as a tense auxiliary, had precedes been
going to build, and as the finite element of the clause,
it precedes the subject.
</bodyText>
<subsectionHeader confidence="0.761449">
8.2 Other contributions to resultant clause structure
</subsectionHeader>
<bodyText confidence="0.9591296">
Other aspects of the final structure come from transitivity, voice,
theme etc. (as we have seen in section 5):
- From transitivity we get ACTOR, PROCESS, and GOAL
with feature specifications.
From voice we get the conflation of SUBJECT with
</bodyText>
<listItem confidence="0.848868">
• ACTOR.
</listItem>
<bodyText confidence="0.998413857142857">
From theme we get the conflation of THEME with
To sum up: Depending on the perspective we lay on the clause,
the phrase Sir Christopher Wren will be SUBJECT (interpersonal
perspective) or ACTOR (ideational perspective). We say that these
functions are conflated (symbolized SUBJECT/ACTOR). The
conflation is the result of bringing independent lines of reasoning
together. It is an operation that can only be performed on
functions, not on categories like NP, N. and VP. The resultant
structure is given in Figure 6 (associated features are left out).
Note that had, Sir Chris. etc. are not the result of equally many
functions. Some constituent play a role only in one component
(e.g. tense: be going) whereas others realized more than one
function (Sir Chris, for example).
One important property of these conflations is that they could
have been otherwise, if the choosers had received different
resbonses from the environment and thus had made different
choices. For instance, we could have SUBJECT/GOAL and get the
clause Had a cathedral been going to be built by Sir Christopher
Wren. Or, with a MODAL displacing TEmP00 in the conflation with
FINITE: MODAL/FINITE followed by TEMPo0 as in may have (instead
of had).
</bodyText>
<figure confidence="0.785918181818182">
FINITE SUBJ ECT
-negative
TEMPOO/
past
TEMPO1
have
TEMPO2 TEMPO3
be going to-infinitive
PROCESS
transitiVe
had Sir Chris been going to build
</figure>
<figureCaption confidence="0.999199">
Figure 5: Mood and tense structures combined
</figureCaption>
<page confidence="0.839737">
162
</page>
<figure confidence="0.8765705">
Had Sir Chris I been going I to build a cathedral
FINITE I SUBJECT
TEMPOO
TEMPO1 TEMPO2 TEMPO3
ACTOR PROCESS GOAL
THEME
</figure>
<figureCaption confidence="0.999251">
Figure 6: Clause structure
</figureCaption>
<subsectionHeader confidence="0.749811">
8.3 A note on the development of the function constituents
</subsectionHeader>
<bodyText confidence="0.999943142857143">
The structure presented above represents clause structure; the
terminal functions are functions of the clause. It is the solution to
the problems that the clause has evolved to solve. For the
development of each constituent, we have to go to go either to
lexicon or (back) to grammar. The verbal have lexical features
associated with them and these features serve as constraints on
what lexical items can be used. The ACTOR constituent and the
GOAL constituent have to go through another round of
development in the grammar, in the nominal group part of the
grammar. Although I have not shown them, features are also
associated with these two constituents. These features are
grammatical and will serve as constraints on choices in the
nominal group part of the network. This process is discussed in
e.g. [Matthiessen 83].
</bodyText>
<sectionHeader confidence="0.998943" genericHeader="conclusions">
9 CONCLUSION
</sectionHeader>
<bodyText confidence="0.999985714285714">
The first concise presentation of systemic suggestions was
published when what came to be called ACL was being formed.
Now, roughly twenty years later, with the first meeting of the
European chapter of ACL we can look back on substantial
achievements in both computational linguistics and systemic
linguistics, some of them in co-operation.
However, the most exciting developments are current and
future. We can see the most ambitious applications of systemic
linguistics to computational tasks to date. And we can see the
growing interest in text generation. a task in the context of which
systemic linguistics seems to have much to offer.
Here I have• pointed to some properties and designs that come
from the systemic tradition and which I think are of interest for the
text generation task. Systemic linguists have done and are still
doing pioneer work on text organization, turning up insights that
will most certainly be important to the design of text generators.
However, here.] have concentrated on contributions in the area of
grammar and choosers for grammar with a view to showing how
they help us fulfill the demands place on a grammar in a text
generator. I have focused on the factoring of the sentence
generation process that systemic grammar supports.
</bodyText>
<sectionHeader confidence="0.99919" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999185567567567">
[Berry 77] Berry, M., Introduction to Systemic Linguistics, B. T.
Batsford, Ltd., London, 1977.
[Butler 83] Butler, C., &amp;quot;Discourse Systems and Structures and
their Place within an Overall Systemic Model,&amp;quot; in Benson,
J. &amp; Greaves, W. (ed.), Systemic Perspectives on Discourse:
Selected Theoretical Papers from the 9th International
Systemic Workshop, Ablex, 1983.
[Davey 79] Davey, A., Discourse Production, Edinburgh University
Press, Edinburgh, 1979.
[Dik 78] Dik, S., Functional Grammar, North Holland, 1978.
[Fawcett 80] Fawcett, R. P., Exeter Linguistic Studies. Volume 3:
Cognitive Linguistics and Social Interaction, Julius Groos
Verlag Heidelberg and Exeter University, 1980.
[Halliday 69] Halliday, M.A.K., &amp;quot;Options and functions in the
English clause,&amp;quot; Brno Studies in English 8. 1969, 81-88.
[Halliday 74] M.A.K. Halliday, &amp;quot;The place of &apos;Functional Sentence
Perspective&apos; in the system of linguistic description,&amp;quot; in
F. Danes (ed.), Papers on Functional Sentence Perspective,
Academia, 1974.
[Halliday 75] M.A.K. Halliday, Learning How to Mean, Edward
Arnold, 1975.
[Halliday 76a] Halliday, M. A. K., System and Function in
Language, Oxford University Press, London, 1976.
[Halliday 76b] Halliday, M.A.K., &amp;quot;The English verbal group,&amp;quot; in
Kress, G. (ed.), Halliday: System and Function in Language,
Oxford University Press, 1976. Originally circulated in 1966
[Halliday &amp; Hasan 76] Halliday, M. A. K., and R. Hasan, Cohesion
in English, Longman, London, 1976. English Language
Series, Title No. 9.
[Halliday &amp; Hasan 80] Halliday, M.A.K. &amp; Hasan, R., Text and
context, Sofia, 1980.
[Hasan 78] R. Hasan, &amp;quot;Text in the Systemic-Functional Model,&amp;quot; in
W. Dressler (ed.), Current Trends in Text Linguistics, de
Gruyter, 1978.
[Hasan 79] R. Hasan, &amp;quot;On the Notion of Text,&amp;quot; in J. Petoefi (ed.),
Text vs. Sentence (Papers in Text Linguistics, volume 20),
Helmut Buske Verlag. 1979.
</reference>
<page confidence="0.988473">
163
</page>
<reference confidence="0.99976184">
[Hudson 76] Hudson, R. A., Arguments for a Non-
Transformational Grammar, University of Chicago Press,
Chicago, 1976.
[Kay 79] Kay, M., Functional Grammar, 1979. Xerox Parc, Palo
Alto
[Mann 83] Mann, William C., An Overview of the Penman Text
Generation System, USC Information Sciences Institute,
Marina del Rey, CA 90291., Technical Report RR-83-114,
1983. To appear in the 1983 AAAI Proceedings.
[Martin 83] Martin, J., &amp;quot;Process and Text: Two Aspects of Human
Semiosis,&amp;quot; in Benson, J. &amp; Greaves, W. (ed.), Systemic
Perspectives on Discourse: Selected Theoretical Papers from
the 9th International Systemic Workshop, Ablex, 1983.
[Matthiessen 81] Matthiessen, C. M. I. M., &amp;quot;A grammar and a
lexicon for aAext-production system,&amp;quot; in The Nineteenth
Annual Meeting of the Association for Computational
Linguistics, Sperry Univac, 1981.
[Matthiessen 83] Matthiessen, C., &amp;quot;The systemic framework in
text generation: Nigel,&amp;quot; in W. Greaves &amp; J. Benson (eds.),
Systemic Perspectives on Discourse, Ablex, 1983.
[Moravcsik &amp; Wirth 80] E. Moravcsik &amp; J. Wirth (eds.), Syntax and
Semantics, volume 13: Current Approaches to Syntax,
Academic Press, 1980.
[Winograd 72] T. Winograd, Understanding Natural Language,
Academic Press, 1972.
</reference>
<page confidence="0.998523">
164
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.855521">
<title confidence="0.979102">SYSTEMIC GRAMMAR IN COMPUTATION: THE NIGEL CASE</title>
<author confidence="0.999401">Christian M I M Matthiessen</author>
<affiliation confidence="0.891902">USC/Information Sciences Institute</affiliation>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M Berry</author>
</authors>
<title>Introduction to Systemic Linguistics,</title>
<date>1977</date>
<journal>B. T. Batsford,</journal>
<location>Ltd., London,</location>
<marker>[Berry 77]</marker>
<rawString>Berry, M., Introduction to Systemic Linguistics, B. T. Batsford, Ltd., London, 1977.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Butler</author>
</authors>
<title>Discourse Systems and Structures and their Place within an Overall Systemic Model,&amp;quot;</title>
<date>1983</date>
<booktitle>Systemic Perspectives on Discourse: Selected Theoretical Papers from the 9th International Systemic Workshop, Ablex,</booktitle>
<editor>in Benson, J. &amp; Greaves, W. (ed.),</editor>
<marker>[Butler 83]</marker>
<rawString>Butler, C., &amp;quot;Discourse Systems and Structures and their Place within an Overall Systemic Model,&amp;quot; in Benson, J. &amp; Greaves, W. (ed.), Systemic Perspectives on Discourse: Selected Theoretical Papers from the 9th International Systemic Workshop, Ablex, 1983.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Davey</author>
</authors>
<title>Discourse Production,</title>
<date>1979</date>
<publisher>University Press,</publisher>
<location>Edinburgh</location>
<marker>[Davey 79]</marker>
<rawString>Davey, A., Discourse Production, Edinburgh University Press, Edinburgh, 1979.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Dik</author>
</authors>
<title>Functional Grammar,</title>
<date>1978</date>
<location>North Holland,</location>
<marker>[Dik 78]</marker>
<rawString>Dik, S., Functional Grammar, North Holland, 1978.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R P Fawcett</author>
</authors>
<title>Exeter Linguistic Studies. Volume 3: Cognitive Linguistics and Social Interaction,</title>
<date>1980</date>
<institution>Julius Groos Verlag Heidelberg and Exeter University,</institution>
<marker>[Fawcett 80]</marker>
<rawString>Fawcett, R. P., Exeter Linguistic Studies. Volume 3: Cognitive Linguistics and Social Interaction, Julius Groos Verlag Heidelberg and Exeter University, 1980.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A K Halliday</author>
</authors>
<title>Options and functions in the English clause,&amp;quot;</title>
<date>1969</date>
<journal>Brno Studies in English</journal>
<volume>8</volume>
<pages>81--88</pages>
<marker>[Halliday 69]</marker>
<rawString>Halliday, M.A.K., &amp;quot;Options and functions in the English clause,&amp;quot; Brno Studies in English 8. 1969, 81-88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A K Halliday</author>
</authors>
<title>The place of &apos;Functional Sentence Perspective&apos; in the system of linguistic description,&amp;quot;</title>
<date>1974</date>
<booktitle>Papers on Functional Sentence Perspective, Academia,</booktitle>
<editor>in F. Danes (ed.),</editor>
<marker>[Halliday 74]</marker>
<rawString>M.A.K. Halliday, &amp;quot;The place of &apos;Functional Sentence Perspective&apos; in the system of linguistic description,&amp;quot; in F. Danes (ed.), Papers on Functional Sentence Perspective, Academia, 1974.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A K Halliday</author>
</authors>
<title>Learning How to Mean,</title>
<date>1975</date>
<location>Edward Arnold,</location>
<marker>[Halliday 75]</marker>
<rawString>M.A.K. Halliday, Learning How to Mean, Edward Arnold, 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A K Halliday</author>
</authors>
<title>System and Function in Language,</title>
<date>1976</date>
<publisher>University Press,</publisher>
<location>Oxford</location>
<marker>[Halliday 76a]</marker>
<rawString>Halliday, M. A. K., System and Function in Language, Oxford University Press, London, 1976.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A K Halliday</author>
</authors>
<title>The English verbal group,&amp;quot;</title>
<date>1976</date>
<booktitle>Halliday: System and Function in Language,</booktitle>
<editor>in Kress, G. (ed.),</editor>
<publisher>University Press,</publisher>
<location>Oxford</location>
<note>Originally circulated in</note>
<marker>[Halliday 76b]</marker>
<rawString>Halliday, M.A.K., &amp;quot;The English verbal group,&amp;quot; in Kress, G. (ed.), Halliday: System and Function in Language, Oxford University Press, 1976. Originally circulated in 1966</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A K Halliday</author>
<author>R Hasan</author>
</authors>
<title>Cohesion in English,</title>
<date>1976</date>
<journal>English Language Series, Title</journal>
<volume>9</volume>
<location>Longman, London,</location>
<marker>[Halliday &amp; Hasan 76]</marker>
<rawString>Halliday, M. A. K., and R. Hasan, Cohesion in English, Longman, London, 1976. English Language Series, Title No. 9.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A K Halliday</author>
<author>R Hasan</author>
<author>Text</author>
<author>Sofia context</author>
</authors>
<date>1980</date>
<marker>[Halliday &amp; Hasan 80]</marker>
<rawString>Halliday, M.A.K. &amp; Hasan, R., Text and context, Sofia, 1980.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Hasan</author>
</authors>
<title>Text in the Systemic-Functional Model,&amp;quot;</title>
<date>1978</date>
<booktitle>Current Trends in Text Linguistics, de Gruyter,</booktitle>
<editor>in W. Dressler (ed.),</editor>
<marker>[Hasan 78]</marker>
<rawString>R. Hasan, &amp;quot;Text in the Systemic-Functional Model,&amp;quot; in W. Dressler (ed.), Current Trends in Text Linguistics, de Gruyter, 1978.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Hasan</author>
</authors>
<title>On the Notion of Text,&amp;quot;</title>
<date>1979</date>
<booktitle>Text vs. Sentence (Papers in Text Linguistics, volume 20), Helmut Buske Verlag.</booktitle>
<editor>in J. Petoefi (ed.),</editor>
<marker>[Hasan 79]</marker>
<rawString>R. Hasan, &amp;quot;On the Notion of Text,&amp;quot; in J. Petoefi (ed.), Text vs. Sentence (Papers in Text Linguistics, volume 20), Helmut Buske Verlag. 1979.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R A Hudson</author>
</authors>
<title>Arguments for a NonTransformational Grammar,</title>
<date>1976</date>
<publisher>University of Chicago Press,</publisher>
<location>Chicago,</location>
<marker>[Hudson 76]</marker>
<rawString>Hudson, R. A., Arguments for a NonTransformational Grammar, University of Chicago Press, Chicago, 1976.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kay</author>
<author>Functional Grammar</author>
</authors>
<title>Xerox Parc,</title>
<date>1979</date>
<location>Palo Alto</location>
<marker>[Kay 79]</marker>
<rawString>Kay, M., Functional Grammar, 1979. Xerox Parc, Palo Alto</rawString>
</citation>
<citation valid="true">
<authors>
<author>William C Mann</author>
</authors>
<title>An Overview of the Penman Text Generation System, USC Information Sciences Institute,</title>
<date>1983</date>
<tech>CA 90291., Technical Report RR-83-114,</tech>
<publisher>AAAI Proceedings.</publisher>
<location>Marina</location>
<note>To appear in the</note>
<marker>[Mann 83]</marker>
<rawString>Mann, William C., An Overview of the Penman Text Generation System, USC Information Sciences Institute, Marina del Rey, CA 90291., Technical Report RR-83-114, 1983. To appear in the 1983 AAAI Proceedings.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Martin</author>
</authors>
<title>Process and Text: Two Aspects of Human Semiosis,&amp;quot;</title>
<date>1983</date>
<booktitle>Systemic Perspectives on Discourse: Selected Theoretical Papers from the 9th International Systemic Workshop, Ablex,</booktitle>
<editor>in Benson, J. &amp; Greaves, W. (ed.),</editor>
<marker>[Martin 83]</marker>
<rawString>Martin, J., &amp;quot;Process and Text: Two Aspects of Human Semiosis,&amp;quot; in Benson, J. &amp; Greaves, W. (ed.), Systemic Perspectives on Discourse: Selected Theoretical Papers from the 9th International Systemic Workshop, Ablex, 1983.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C M I M Matthiessen</author>
</authors>
<title>A grammar and a lexicon for aAext-production system,&amp;quot;</title>
<date>1981</date>
<booktitle>in The Nineteenth Annual Meeting of the Association for Computational Linguistics, Sperry Univac,</booktitle>
<marker>[Matthiessen 81]</marker>
<rawString>Matthiessen, C. M. I. M., &amp;quot;A grammar and a lexicon for aAext-production system,&amp;quot; in The Nineteenth Annual Meeting of the Association for Computational Linguistics, Sperry Univac, 1981.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Matthiessen</author>
</authors>
<title>The systemic framework in text generation: Nigel,&amp;quot;</title>
<date>1983</date>
<booktitle>Systemic Perspectives on Discourse, Ablex,</booktitle>
<editor>in W. Greaves &amp; J. Benson (eds.),</editor>
<marker>[Matthiessen 83]</marker>
<rawString>Matthiessen, C., &amp;quot;The systemic framework in text generation: Nigel,&amp;quot; in W. Greaves &amp; J. Benson (eds.), Systemic Perspectives on Discourse, Ablex, 1983.</rawString>
</citation>
<citation valid="true">
<date>1980</date>
<booktitle>Syntax and Semantics, volume 13: Current Approaches to Syntax,</booktitle>
<editor>E. Moravcsik &amp; J. Wirth (eds.),</editor>
<publisher>Academic Press,</publisher>
<marker>[Moravcsik &amp; Wirth 80]</marker>
<rawString>E. Moravcsik &amp; J. Wirth (eds.), Syntax and Semantics, volume 13: Current Approaches to Syntax, Academic Press, 1980.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Winograd</author>
</authors>
<title>Understanding Natural Language,</title>
<date>1972</date>
<publisher>Academic Press,</publisher>
<marker>[Winograd 72]</marker>
<rawString>T. Winograd, Understanding Natural Language, Academic Press, 1972.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>