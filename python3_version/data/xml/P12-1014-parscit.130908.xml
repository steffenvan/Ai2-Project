<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.986187">
Learning High-Level Planning from Text
</title>
<author confidence="0.998558">
S.R.K. Branavan, Nate Kushman, Tao Lei, Regina Barzilay
</author>
<affiliation confidence="0.99856">
Computer Science and Artificial Intelligence Laboratory
Massachusetts Institute of Technology
</affiliation>
<email confidence="0.974058">
{branavan, nkushman, taolei, regina}@csail.mit.edu
</email>
<sectionHeader confidence="0.997221" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99924724">
Comprehending action preconditions and ef-
fects is an essential step in modeling the dy-
namics of the world. In this paper, we ex-
press the semantics of precondition relations
extracted from text in terms of planning oper-
ations. The challenge of modeling this con-
nection is to ground language at the level of
relations. This type of grounding enables us to
create high-level plans based on language ab-
stractions. Our model jointly learns to predict
precondition relations from text and to per-
form high-level planning guided by those rela-
tions. We implement this idea in the reinforce-
ment learning framework using feedback au-
tomatically obtained from plan execution at-
tempts. When applied to a complex virtual
world and text describing that world, our rela-
tion extraction technique performs on par with
a supervised baseline, yielding an F-measure
of 66% compared to the baseline’s 65%. Ad-
ditionally, we show that a high-level planner
utilizing these extracted relations significantly
outperforms a strong, text unaware baseline
– successfully completing 80% of planning
tasks as compared to 69% for the baseline.1
</bodyText>
<sectionHeader confidence="0.999472" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999815">
Understanding action preconditions and effects is a
basic step in modeling the dynamics of the world.
For example, having seeds is a precondition for
growing wheat. Not surprisingly, preconditions have
been extensively explored in various sub-fields of
AI. However, existing work on action models has
largely focused on tasks and techniques specific to
individual sub-fields with little or no interconnection
between them. In NLP, precondition relations have
been studied in terms of the linguistic mechanisms
</bodyText>
<footnote confidence="0.9985645">
1The code, data and experimental setup for this work are
available at http://groups.csail.mit.edu/rbg/code/planning
</footnote>
<figureCaption confidence="0.610034333333333">
A pickaxe, which is used to harvest stone, can be
made from wood.
Low Level Actions for: wood —* pickaxe —* stone
step 1: move from (0,0) to (2,0)
step 2: chop tree at: (2,0)
step 3: get wood at: (2,0)
step 4: craft plank from wood
step 5: craft stick from plank
step 6: craft pickaxe from plank and stick
</figureCaption>
<figure confidence="0.433700666666667">
� � �
step N-1: pickup tool: pickaxe
step N: harvest stone with pickaxe at: (5,5)
</figure>
<figureCaption confidence="0.9973195">
Figure 1: Text description of preconditions and effects
(a), and the low-level actions connecting them (b).
</figureCaption>
<bodyText confidence="0.999906391304348">
that realize them, while in classical planning, these
relations are viewed as a part of world dynamics.
In this paper, we bring these two parallel views to-
gether, grounding the linguistic realization of these
relations in the semantics of planning operations.
The challenge and opportunity of this fusion
comes from the mismatch between the abstractions
of human language and the granularity of planning
primitives. Consider, for example, text describing a
virtual world such as Minecraft2 and a formal de-
scription of that world using planning primitives.
Due to the mismatch in granularity, even the simple
relations between wood, pickaxe and stone described
in the sentence in Figure 1a results in dozens of low-
level planning actions in the world, as can be seen
in Figure 1b. While the text provides a high-level
description of world dynamics, it does not provide
sufficient details for successful plan execution. On
the other hand, planning with low-level actions does
not suffer from this limitation, but is computation-
ally intractable for even moderately complex tasks.
As a consequence, in many practical domains, plan-
ning algorithms rely on manually-crafted high-level
</bodyText>
<footnote confidence="0.9657">
2http://www.minecraft.net/
</footnote>
<page confidence="0.925035">
126
</page>
<note confidence="0.9872585">
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 126–135,
Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.970846457627119">
abstractions to make search tractable (Ghallab et al.,
2004; Lekav´y and N´avrat, 2007).
The central idea of our work is to express the se-
mantics of precondition relations extracted from text
in terms of planning operations. For instance, the
precondition relation between pickaxe and stone de-
scribed in the sentence in Figure 1a indicates that
plans which involve obtaining stone will likely need
to first obtain a pickaxe. The novel challenge of this
view is to model grounding at the level of relations,
in contrast to prior work which focused on object-
level grounding. We build on the intuition that the
validity of precondition relations extracted from text
can be informed by the execution of a low-level
planner.3 This feedback can enable us to learn these
relations without annotations. Moreover, we can use
the learned relations to guide a high level planner
and ultimately improve planning performance.
We implement these ideas in the reinforcement
learning framework, wherein our model jointly
learns to predict precondition relations from text and
to perform high-level planning guided by those rela-
tions. For a given planning task and a set of can-
didate relations, our model repeatedly predicts a se-
quence of subgoals where each subgoal specifies an
attribute of the world that must be made true. It
then asks the low-level planner to find a plan be-
tween each consecutive pair of subgoals in the se-
quence. The observed feedback – whether the low-
level planner succeeded or failed at each step – is
utilized to update the policy for both text analysis
and high-level planning.
We evaluate our algorithm in the Minecraft virtual
world, using a large collection of user-generated on-
line documents as our source of textual information.
Our results demonstrate the strength of our relation
extraction technique – while using planning feed-
back as its only source of supervision, it achieves
a precondition relation extraction accuracy on par
with that of a supervised SVM baseline. Specifi-
cally, it yields an F-score of 66% compared to the
65% of the baseline. In addition, we show that
these extracted relations can be used to improve the
performance of a high-level planner. As baselines
3If a planner can find a plan to successfully obtain stone
after obtaining a pickaxe, then a pickaxe is likely a precondition
for stone. Conversely, if a planner obtains stone without first
obtaining a pickaxe, then it is likely not a precondition.
for this evaluation, we employ the Metric-FF plan-
ner (Hoffmann and Nebel, 2001),4 as well as a text-
unaware variant of our model. Our results show that
our text-driven high-level planner significantly out-
performs all baselines in terms of completed plan-
ning tasks – it successfully solves 80% as compared
to 41% for the Metric-FF planner and 69% for the
text unaware variant of our model. In fact, the per-
formance of our method approaches that of an ora-
cle planner which uses manually-annotated precon-
ditions.
</bodyText>
<sectionHeader confidence="0.999932" genericHeader="introduction">
2 Related Work
</sectionHeader>
<subsectionHeader confidence="0.659079">
Extracting Event Semantics from Text The task
</subsectionHeader>
<bodyText confidence="0.995383967741935">
of extracting preconditions and effects has previ-
ously been addressed in the context of lexical se-
mantics (Sil et al., 2010; Sil and Yates, 2011).
These approaches combine large-scale distributional
techniques with supervised learning to identify de-
sired semantic relations in text. Such combined ap-
proaches have also been shown to be effective for
identifying other relationships between events, such
as causality (Girju and Moldovan, 2002; Chang and
Choi, 2006; Blanco et al., 2008; Beamer and Girju,
2009; Do et al., 2011).
Similar to these methods, our algorithm capital-
izes on surface linguistic cues to learn preconditions
from text. However, our only source of supervision
is the feedback provided by the planning task which
utilizes the predictions. Additionally, we not only
identify these relations in text, but also show they
are valuable in performing an external task.
Learning Semantics via Language Grounding
Our work fits into the broad area of grounded lan-
guage acquisition, where the goal is to learn linguis-
tic analysis from a situated context (Oates, 2001;
Siskind, 2001; Yu and Ballard, 2004; Fleischman
and Roy, 2005; Mooney, 2008a; Mooney, 2008b;
Branavan et al., 2009; Liang et al., 2009; Vogel
and Jurafsky, 2010). Within this line of work, we
are most closely related to the reinforcement learn-
ing approaches that learn language by interacting
with an external environment (Branavan et al., 2009;
Branavan et al., 2010; Vogel and Jurafsky, 2010;
Branavan et al., 2011).
</bodyText>
<footnote confidence="0.999813">
4The state-of-the-art baseline used in the 2008 International
Planning Competition. http://ipc.informatik.uni-freiburg.de/
</footnote>
<page confidence="0.993132">
127
</page>
<figure confidence="0.851034">
Text (input):
A pickaxe, which is used to harvest stone,
can be made from wood.
Precondition Relations:
</figure>
<figureCaption confidence="0.995354">
Figure 2: A high-level plan showing two subgoals in
a precondition relation. The corresponding sentence is
shown above.
</figureCaption>
<bodyText confidence="0.999677870967742">
The key distinction of our work is the use of
grounding to learn abstract pragmatic relations, i.e.
to learn linguistic patterns that describe relationships
between objects in the world. This supplements pre-
vious work which grounds words to objects in the
world (Branavan et al., 2009; Vogel and Jurafsky,
2010). Another important difference of our setup
is the way the textual information is utilized in the
situated context. Instead of getting step-by-step in-
structions from the text, our model uses text that de-
scribes general knowledge about the domain struc-
ture. From this text, it extracts relations between
objects in the world which hold independently of
any given task. Task-specific solutions are then con-
structed by a planner that relies on these relations to
perform effective high-level planning.
Hierarchical Planning It is widely accepted that
high-level plans that factorize a planning prob-
lem can greatly reduce the corresponding search
space (Newell et al., 1959; Bacchus and Yang,
1994). Previous work in planning has studied
the theoretical properties of valid abstractions and
proposed a number of techniques for generating
them (Jonsson and Barto, 2005; Wolfe and Barto,
2005; Mehta et al., 2008; Barry et al., 2011). In gen-
eral, these techniques use static analysis of the low-
level domain to induce effective high-level abstrac-
tions. In contrast, our focus is on learning the ab-
straction from natural language. Thus our technique
is complementary to past work, and can benefit from
human knowledge about the domain structure.
</bodyText>
<sectionHeader confidence="0.979404" genericHeader="method">
3 Problem Formulation
</sectionHeader>
<bodyText confidence="0.999989925">
Our task is two-fold. First, given a text document
describing an environment, we wish to extract a set
of precondition/effect relations implied by the text.
Second, we wish to use these induced relations to
determine an action sequence for completing a given
task in the environment.
We formalize our task as illustrated in Figure 2.
As input, we are given a world defined by the tuple
(S, A, T), where S is the set of possible world states,
A is the set of possible actions and T is a determin-
istic state transition function. Executing action a in
state s causes a transition to a new state s&apos; according
to T(s&apos;  |s, a). States are represented using proposi-
tional logic predicates xi E X, where each state is
simply a set of such predicates, i.e. s C X.
The objective of the text analysis part of our task
is to automatically extract a set of valid precondi-
tion/effect relationships from a given document d.
Given our definition of the world state, precondi-
tions and effects are merely single term predicates,
xi, in this world state. We assume that we are given
a seed mapping between a predicate xi, and the
word types in the document that reference it (see
Table 3 for examples). Thus, for each predicate
pair (xk, xi), we want to utilize the text to predict
whether xk is a precondition for xi; i.e., xk —* xi.
For example, from the text in Figure 2, we want to
predict that possessing a pickaxe is a precondition
for possessing stone. Note that this relation implies
the reverse as well, i.e. x1 can be interpreted as the
effect of an action sequence performed on state xk.
Each planning goal g E G is defined by a starting
state so, and a final goal state sf. This goal state is
represented by a set of predicates which need to be
made true. In the planning part of our task our objec-
tive is to find a sequence of actions at that connect so
to sf. Finally, we assume document d does not con-
tain step-by-step instructions for any individual task,
but instead describes general facts about the given
world that are useful for a wide variety of tasks.
</bodyText>
<sectionHeader confidence="0.995956" genericHeader="method">
4 Model
</sectionHeader>
<bodyText confidence="0.9999895">
The key idea behind our model is to leverage textual
descriptions of preconditions and effects to guide the
construction of high level plans. We define a high-
level plan as a sequence of subgoals, where each
</bodyText>
<figure confidence="0.998671727272727">
wood pickaxe
Plan Subgoal Sequence:
pickaxe stone
stone
(goal)
pickaxe
(subgoal 2)
wood
(subgoal 1)
initial
state
</figure>
<page confidence="0.979395">
128
</page>
<bodyText confidence="0.998443444444444">
subgoal is represented by a single-term predicate,
xi, that needs to be set in the corresponding world
state – e.g. have(wheat)=true. Thus the set of
possible subgoals is defined by the set of all possi-
ble single-term predicates in the domain. In contrast
to low-level plans, the transition between these sub-
goals can involve multiple low-level actions. Our al-
gorithm for textually informed high-level planning
operates in four steps:
</bodyText>
<listItem confidence="0.962309357142857">
1. Use text to predict the preconditions of each
subgoal. These predictions are for the entire
domain and are not goal specific.
2. Given a planning goal and the induced pre-
conditions, predict a subgoal sequence that
achieves the given goal.
3. Execute the predicted sequence by giving each
pair of consecutive subgoals to a low-level
planner. This planner, treated as a black-box,
computes the low-level plan actions necessary
to transition from one subgoal to the next.
4. Update the model parameters, using the low-
level planner’s success or failure as the source
of supervision.
</listItem>
<bodyText confidence="0.998831294117647">
We formally define these steps below.
Modeling Precondition Relations Given a docu-
ment d, and a set of subgoal pairs (xi, xj), we want
to predict whether subgoal xi is a precondition for
xj. We assume that precondition relations are gener-
ally described within single sentences. We first use
our seed grounding in a preprocessing step where
we extract all predicate pairs where both predicates
are mentioned in the same sentence. We call this set
the Candidate Relations. Note that this set will con-
tain many invalid relations since co-occurrence in a
sentence does not necessarily imply a valid precon-
dition relation.5 Thus for each sentence, ~wk, asso-
ciated with a given Candidate Relation, xi -* xj,
our task is to predict whether the sentence indicates
the relation. We model this decision via a log linear
distribution as follows:
</bodyText>
<equation confidence="0.961394">
p(xi -* xj  |~wk, qk; θc) « eθ�-φ�(xi,xj,~wk,qk), (1)
</equation>
<bodyText confidence="0.9940975">
where θc is the vector of model parameters. We
compute the feature function φc using the seed
</bodyText>
<footnote confidence="0.675706">
5In our dataset only 11% of Candidate Relations are valid.
</footnote>
<bodyText confidence="0.339240666666667">
Input: A document d, Set of planning tasks G,
Set of candidate precondition relations Call,
Reward function r(), Number of iterations T
</bodyText>
<figure confidence="0.751325304347826">
Initialization:Model parameters θx = 0 and θ, = 0.
for i = 1 ··· T do
Sample valid preconditions:
C + _0
foreach (xi, xj) E Call do
foreach Sentence ~wk containing xi and xj do
v — p(xi -* xj  |~wk, qk; θ.)
if v = 1 then C = C U (xi,xj)
end
end
Predict subgoal sequences for each task g.
foreach g E G do
Sample subgoal sequence x~ as follows:
fort = 1··· n do
Sample next subgoal:
xt — p(x  |xt−1,s&amp;quot;sf,C;θx)
Construct low-level subtask from xt−1 to xt
Execute low-level planner on subtask
end
Update subgoal prediction model using Eqn. 2
end
Update text precondition model using Eqn. 3
end
</figure>
<figureCaption confidence="0.6894135">
Algorithm 1: A policy gradient algorithm for pa-
rameter estimation in our model.
</figureCaption>
<bodyText confidence="0.998306583333333">
grounding, the sentence ~wk, and a given dependency
parse qk of the sentence. Given these per-sentence
decisions, we predict the set of all valid precondi-
tion relations, C, in a deterministic fashion. We do
this by considering a precondition xi -* xj as valid
if it is predicted to be valid by at least one sentence.
Modeling Subgoal Sequences Given a planning
goal g, defined by initial and final goal states sg 0 and
sgf, our task is to predict a sequence of subgoals x~
which will achieve the goal. We condition this de-
cision on our predicted set of valid preconditions C,
by modeling the distribution over sequences x~ as:
</bodyText>
<equation confidence="0.972118333333333">
n
p(~x  |sg�,sgf,C;θx) = H p(xt  |xt-1, sg�, sgf, C; θx),
t=1
</equation>
<bodyText confidence="0.979322">
,s f,C)os θx φx(xt,xt−1,sop(xt  |xt-i, s, A, C; OX) « e .
f
Here we assume that subgoal sequences are Marko-
vian in nature and model individual subgoal predic-
tions using a log-linear model. Note that in con-
</bodyText>
<page confidence="0.994418">
129
</page>
<bodyText confidence="0.99988475">
trast to Equation 1 where the predictions are goal-
agnostic, these predictions are goal-specific. As be-
fore, θx is the vector of model parameters, and φx is
the feature function. Additionally, we assume a spe-
cial stop symbol, x0, which indicates the end of the
subgoal sequence.
Parameter Update Parameter updates in our model
are done via reinforcement learning. Specifically,
once the model has predicted a subgoal sequence for
a given goal, the sequence is given to the low-level
planner for execution. The success or failure of this
execution is used to compute the reward signal r for
parameter estimation. This predict-execute-update
cycle is repeated until convergence. We assume that
our reward signal r strongly correlates with the cor-
rectness of model predictions. Therefore, during
learning, we need to find the model parameters that
maximize expected future reward (Sutton and Barto,
1998). We perform this maximization via stochastic
gradient ascent, using the standard policy gradient
algorithm (Williams, 1992; Sutton et al., 2000).
We perform two separate policy gradient updates,
one for each model component. The objective of the
text component of our model is purely to predict the
validity of preconditions. Therefore, subgoal pairs
(xk, xl), where xl is reachable from xk, are given
positive reward. The corresponding parameter up-
date, with learning rate αc, takes the following form:
</bodyText>
<equation confidence="0.993887">
�Dθc +— αc r φc(xi, xj, ~wk, qk) −
Ep(x,,1—&apos;x,1|·) [φc(xi1, xj1, ~wk, qk)] J . (2)
</equation>
<bodyText confidence="0.999947">
The objective of the planning component of our
model is to predict subgoal sequences that success-
fully achieve the given planning goals. Thus we di-
rectly use plan-success as a binary reward signal,
which is applied to each subgoal decision in a se-
quence. This results in the following update:
</bodyText>
<equation confidence="0.98671675">
�φx(xt, xt−1, sg 0, sg f, C) −
h i �
Ep(x1 φx(x� t, xt−1, sg 0, sg f, C) , (3)
t|·)
</equation>
<bodyText confidence="0.9988005">
where t indexes into the subgoal sequence and αx is
the learning rate.
</bodyText>
<figureCaption confidence="0.996396">
Figure 3: Example of the precondition dependencies
present in the Minecraft domain.
</figureCaption>
<table confidence="0.9999096">
Domain #Objects #Pred Types #Actions
Parking 49 5 4
Floortile 61 10 7
Barman 40 15 12
Minecraft 108 16 68
</table>
<tableCaption confidence="0.90995125">
Table 1: A comparison of complexity between Minecraft
and some domains used in the IPC-2011 sequential satis-
ficing track. In the Minecraft domain, the number of ob-
jects, predicate types, and actions is significantly larger.
</tableCaption>
<sectionHeader confidence="0.99812" genericHeader="method">
5 Applying the Model
</sectionHeader>
<bodyText confidence="0.99987924">
We apply our method to Minecraft, a grid-based vir-
tual world. Each grid location represents a tile of ei-
ther land or water and may also contain resources.
Users can freely move around the world, harvest
resources and craft various tools and objects from
these resources. The dynamics of the world require
certain resources or tools as prerequisites for per-
forming a given action, as can be seen in Figure 3.
For example, a user must first craft a bucket before
they can collect milk.
Defining the Domain In order to execute a tradi-
tional planner on the Minecraft domain, we define
the domain using the Planning Domain Definition
Language (PDDL) (Fox and Long, 2003). This is the
standard task definition language used in the Inter-
national Planning Competitions (IPC).6 We define
as predicates all aspects of the game state – for ex-
ample, the location of resources in the world, the re-
sources and objects possessed by the player, and the
player’s location. Our subgoals xi and our task goals
sg f map directly to these predicates. This results in
a domain with significantly greater complexity than
those solvable by traditional low-level planners. Ta-
ble 1 compares the complexity of our domain with
some typical planning domains used in the IPC.
</bodyText>
<footnote confidence="0.585352">
6http://ipc.icaps-conference.org/
</footnote>
<figure confidence="0.976769076923077">
fence
wood
plank
stick
bone meal
seeds string wool
fishing rod
shears iron door bucket
fish
iron
milk
XDθx +— αx r
t
</figure>
<page confidence="0.985793">
130
</page>
<bodyText confidence="0.9998365">
Low-level Planner As our low-level planner we
employ Metric-FF (Hoffmann and Nebel, 2001),
the state-of-the-art baseline used in the 2008 In-
ternational Planning Competition. Metric-FF is a
forward-chaining heuristic state space planner. Its
main heuristic is to simplify the task by ignoring op-
erator delete lists. The number of actions in the so-
lution for this simplified task is then used as the goal
distance estimate for various search strategies.
Features The two components of our model lever-
age different types of information, and as a result,
they each use distinct sets of features. The text com-
ponent features 0, are computed over sentences and
their dependency parses. The Stanford parser (de
Marneffe et al., 2006) was used to generate the de-
pendency parse information for each sentence. Ex-
amples of these features appear in Table 2. The se-
quence prediction component takes as input both the
preconditions induced by the text component as well
as the planning state and the previous subgoal. Thus
0,, contains features which check whether two sub-
goals are connected via an induced precondition re-
lation, in addition to features which are simply the
Cartesian product of domain predicates.
</bodyText>
<sectionHeader confidence="0.998724" genericHeader="method">
6 Experimental Setup
</sectionHeader>
<bodyText confidence="0.99970045">
Datasets As the text description of our virtual world,
we use documents from the Minecraft Wiki,7 the
most popular information source about the game.
Our manually constructed seed grounding of pred-
icates contains 74 entries, examples of which can be
seen in Table 3. We use this seed grounding to iden-
tify a set of 242 sentences that reference predicates
in the Minecraft domain. This results in a set of
694 Candidate Relations. We also manually anno-
tated the relations expressed in the text, identifying
94 of the Candidate Relations as valid. Our corpus
contains 979 unique word types and is composed of
sentences with an average length of 20 words.
We test our system on a set of 98 problems that
involve collecting resources and constructing ob-
jects in the Minecraft domain – for example, fish-
ing, cooking and making furniture. To assess the
complexity of these tasks, we manually constructed
high-level plans for these goals and solved them us-
ing the Metric-FF planner. On average, the execu-
</bodyText>
<footnote confidence="0.989125">
7http://www.minecraftwiki.net/wiki/Minecraft Wiki/
</footnote>
<table confidence="0.9458328">
Words
Dependency Types
Dependency Type x Direction
Word x Dependency Type
Word x Dependency Type x Direction
</table>
<tableCaption confidence="0.9990812">
Table 2: Example text features. A subgoal pair (xi, xj)
is first mapped to word tokens using a small grounding
table. Words and dependencies are extracted along paths
between mapped target words. These are combined with
path directions to generate the text features.
</tableCaption>
<table confidence="0.999601">
Domain Predicate Noun Phrases
have(plank) wooden plank, wood plank
have(stone) stone, cobblestone
have(iron) iron ingot
</table>
<tableCaption confidence="0.839681333333333">
Table 3: Examples in our seed grounding table. Each
predicate is mapped to one or more noun phrases that de-
scribe it in the text.
</tableCaption>
<bodyText confidence="0.999907111111111">
tion of the sequence of low-level plans takes 35 ac-
tions, with 3 actions for the shortest plan and 123
actions for the longest. The average branching fac-
tor is 9.7, leading to an average search space of more
than 1034 possible action sequences. For evaluation
purposes we manually identify a set of Gold Rela-
tions consisting of all precondition relations that are
valid in this domain, including those not discussed
in the text.
Evaluation Metrics We use our manual annotations
to evaluate the type-level accuracy of relation extrac-
tion. To evaluate our high-level planner, we use the
standard measure adopted by the IPC. This evalu-
ation measure simply assesses whether the planner
completes a task within a predefined time.
Baselines To evaluate the performance of our rela-
tion extraction, we compare against an SVM classi-
fier8 trained on the Gold Relations. We test the SVM
baseline in a leave-one-out fashion.
To evaluate the performance of our text-aware
high-level planner, we compare against five base-
lines. The first two baselines – FF and No Text –
do not use any textual information. The FF base-
line directly runs the Metric-FF planner on the given
task, while the No Text baseline is a variant of our
model that learns to plan in the reinforcement learn-
ing framework. It uses the same state-level features
</bodyText>
<footnote confidence="0.760534">
8SVMlight (Joachims, 1999) with default parameters.
</footnote>
<page confidence="0.986151">
131
</page>
<figure confidence="0.790997857142857">
Sticks are the only building material required to craft a
Seeds for growing
wheat can be obtained by breaking
✘
fence or
tall grass
ladder.
</figure>
<figureCaption confidence="0.9431055">
Figure 4: Examples of precondition relations predicted by our model from text. Check marks (✓) indicate correct
predictions, while a cross (X) marks the incorrect one – in this case, a valid relation that was predicted as invalid by
our model. Note that each pair of highlighted noun phrases in a sentence is a Candidate Relation, and pairs that are
not connected by an arrow were correctly predicted to be invalid by our model.
Figure 5: The performance of our model and a supervised
SVM baseline on the precondition prediction task. Also
</figureCaption>
<bodyText confidence="0.982740192307692">
shown is the F-Score of the full set of Candidate Rela-
tions which is used unmodified by All Text, and is given as
input to our model. Our model’s F-score, averaged over
200 trials, is shown with respect to learning iterations.
as our model, but does not have access to text.
The All Text baseline has access to the full set of
694 Candidate Relations. During learning, our full
model refines this set of relations, while in contrast
the All Text baseline always uses the full set.
The two remaining baselines constitute the upper
bound on the performance of our model. The first,
Manual Text, is a variant of our model which directly
uses the links derived from manual annotations of
preconditions in text. The second, Gold, has access
to the Gold Relations. Note that the connections
available to Manual Text are a subset of the Gold
links, because the text does not specify all relations.
Experimental Details All experimental results are
averaged over 200 independent runs for both our
model as well as the baselines. Each of these tri-
als is run for 200 learning iterations with a max-
imum subgoal sequence length of 10. To find a
low-level plan between each consecutive pair of sub-
goals, our high-level planner internally uses Metric-
FF. We give Metric-FF a one-minute timeout to find
such a low-level plan. To ensure that the comparison
</bodyText>
<table confidence="0.998828571428572">
Method %Plans
FF 40.8
No text 69.4
All text 75.5
Full model 80.2
Manual text 84.7
Gold connection 87.1
</table>
<tableCaption confidence="0.997597666666667">
Table 4: Percentage of tasks solved successfully by our
model and the baselines. All performance differences be-
tween methods are statistically significant at p &lt; .01.
</tableCaption>
<bodyText confidence="0.999853">
between the high-level planners and the FF baseline
is fair, the FF baseline is allowed a runtime of 2,000
minutes. This is an upper bound on the time that our
high-level planner can take over the 200 learning it-
erations, with subgoal sequences of length at most
10 and a one minute timeout. Lastly, during learning
we initialize all parameters to zero, use a fixed learn-
ing rate of 0.0001, and encourage our model to ex-
plore the state space by using the standard c-greedy
exploration strategy (Sutton and Barto, 1998).
</bodyText>
<sectionHeader confidence="0.999837" genericHeader="evaluation">
7 Results
</sectionHeader>
<bodyText confidence="0.9997974">
Relation Extraction Figure 5 shows the perfor-
mance of our method on identifying preconditions
in text. We also show the performance of the super-
vised SVM baseline. As can be seen, after 200 learn-
ing iterations, our model achieves an F-Measure of
66%, equal to the supervised baseline. These results
support our hypothesis that planning feedback is a
powerful source of supervision for analyzing a given
text corpus. Figure 4 shows some examples of sen-
tences and the corresponding extracted relations.
Planning Performance As shown in Table 4 our
text-enriched planning model outperforms the text-
free baselines by more than 10%. Moreover, the
performance improvement of our model over the All
Text baseline demonstrates that the accuracy of the
</bodyText>
<figure confidence="0.558905">
50 100 150 200
132
Hard
Easy
0% 20% 40% 60% 80% 100%
</figure>
<bodyText confidence="0.995586">
path has word &amp;quot;use&amp;quot;
path has word &amp;quot;fill&amp;quot;
path has dependency type &amp;quot;dobj&amp;quot;
path has dependency type &amp;quot;xsubj&amp;quot;
path has word &amp;quot;craft&amp;quot;
path has word &amp;quot;craft&amp;quot;
path has dependency type &amp;quot;partmod&amp;quot;
path has word &amp;quot;equals&amp;quot;
path has word &amp;quot;use&amp;quot;
path has dependency type &amp;quot;xsubj&amp;quot;
</bodyText>
<figure confidence="0.9986252">
95%
48%
31%
64%
94%
91%
59%
71%
89%
88%
Gold
Manual text
Full model
All text
No text
</figure>
<figureCaption confidence="0.998379">
Figure 6: Percentage of problems solved by various mod-
els on Easy and Hard problem sets.
</figureCaption>
<bodyText confidence="0.982832967741936">
extracted text relations does indeed impact planning
performance. A similar conclusion can be reached
by comparing the performance of our model and the
Manual Text baseline.
The difference in performance of 2.35% between
Manual Text and Gold shows the importance of the
precondition information that is missing from the
text. Note that Gold itself does not complete all
tasks – this is largely because the Markov assump-
tion made by our model does not hold for all tasks.9
Figure 6 breaks down the results based on the dif-
ficulty of the corresponding planning task. We mea-
sure problem complexity in terms of the low-level
steps needed to implement a manually constructed
high-level plan. Based on this measure, we divide
the problems into two sets. As can be seen, all of
the high-level planners solve almost all of the easy
problems. However, performance varies greatly on
the more challenging tasks, directly correlating with
planner sophistication. On these tasks our model
outperforms the No Text baseline by 28% and the
All Text baseline by 11%.
Feature Analysis Figure 7 shows the top five pos-
itive features for our model and the SVM baseline.
Both models picked up on the words that indicate
precondition relations in this domain. For instance,
the word use often occurs in sentences that describe
the resources required to make an object, such as
“bricks are items used to craft brick blocks”. In ad-
dition to lexical features, dependency information is
also given high weight by both learners. An example
</bodyText>
<footnote confidence="0.9432345">
9When a given task has two non-trivial preconditions, our
model will choose to satisfy one of the two first, and the Markov
assumption blinds it to the remaining precondition, preventing
it from determining that it must still satisfy the other.
</footnote>
<figureCaption confidence="0.985702">
Figure 7: The top five positive features on words and
dependency types learned by our model (above) and by
SVM (below) for precondition prediction.
</figureCaption>
<bodyText confidence="0.9991415">
of this is a feature that checks for the direct object
dependency type. This analysis is consistent with
prior work on event semantics which shows lexico-
syntactic features are effective cues for learning text
relations (Blanco et al., 2008; Beamer and Girju,
2009; Do et al., 2011).
</bodyText>
<sectionHeader confidence="0.999158" genericHeader="conclusions">
8 Conclusions
</sectionHeader>
<bodyText confidence="0.9999715">
In this paper, we presented a novel technique for in-
ducing precondition relations from text by ground-
ing them in the semantics of planning operations.
While using planning feedback as its only source
of supervision, our method for relation extraction
achieves a performance on par with that of a su-
pervised baseline. Furthermore, relation grounding
provides a new view on classical planning problems
which enables us to create high-level plans based on
language abstractions. We show that building high-
level plans in this manner significantly outperforms
traditional techniques in terms of task completion.
</bodyText>
<sectionHeader confidence="0.998137" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99994775">
The authors acknowledge the support of the
NSF (CAREER grant IIS-0448168, grant IIS-
0835652), the DARPA Machine Reading Program
(FA8750-09-C-0172, PO#4910018860), and Batelle
(PO#300662). Thanks to Amir Globerson, Tommi
Jaakkola, Leslie Kaelbling, George Konidaris, Dy-
lan Hadfield-Menell, Stefanie Tellex, the MIT NLP
group, and the ACL reviewers for their suggestions
and comments. Any opinions, findings, conclu-
sions, or recommendations expressed in this paper
are those of the authors, and do not necessarily re-
flect the views of the funding organizations.
</bodyText>
<page confidence="0.998799">
133
</page>
<sectionHeader confidence="0.996217" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999691428571428">
Fahiem Bacchus and Qiang Yang. 1994. Downward
refinement and the efficiency of hierarchical problem
solving. Artificial Intell., 71(1):43–100.
Jennifer L. Barry, Leslie Pack Kaelbling, and Toms
Lozano-Prez. 2011. DetH*: Approximate hierarchi-
cal solution of large markov decision processes. In
IJCAI’11, pages 1928–1935.
Brandon Beamer and Roxana Girju. 2009. Using a bi-
gram event model to predict causal potential. In Pro-
ceedings of CICLing, pages 430–441.
Eduardo Blanco, Nuria Castell, and Dan Moldovan.
2008. Causal relation extraction. In Proceedings of
the LREC’08.
S.R.K Branavan, Harr Chen, Luke Zettlemoyer, and
Regina Barzilay. 2009. Reinforcement learning for
mapping instructions to actions. In Proceedings of
ACL, pages 82–90.
S.R.K Branavan, Luke Zettlemoyer, and Regina Barzilay.
2010. Reading between the lines: Learning to map
high-level instructions to commands. In Proceedings
of ACL, pages 1268–1277.
S. R. K. Branavan, David Silver, and Regina Barzilay.
2011. Learning to win by reading manuals in a monte-
carlo framework. In Proceedings of ACL, pages 268–
277.
Du-Seong Chang and Key-Sun Choi. 2006. Incremen-
tal cue phrase learning and bootstrapping method for
causality extraction using cue phrase and word pair
probabilities. Inf. Process. Manage., 42(3):662–678.
Marie-Catherine de Marneffe, Bill MacCartney, and
Christopher D. Manning. 2006. Generating typed
dependency parses from phrase structure parses. In
LREC 2006.
Q. Do, Y. Chan, and D. Roth. 2011. Minimally super-
vised event causality identification. In EMNLP, 7.
Michael Fleischman and Deb Roy. 2005. Intentional
context in situated natural language learning. In Pro-
ceedings of CoNLL, pages 104–111.
Maria Fox and Derek Long. 2003. Pddl2.1: An ex-
tension to pddl for expressing temporal planning do-
mains. Journal of Artificial Intelligence Research,
20:2003.
Malik Ghallab, Dana S. Nau, and Paolo Traverso. 2004.
Automated Planning: theory and practice. Morgan
Kaufmann.
Roxana Girju and Dan I. Moldovan. 2002. Text mining
for causal relations. In Proceedigns of FLAIRS, pages
360–364.
J¨org Hoffmann and Bernhard Nebel. 2001. The FF plan-
ning system: Fast plan generation through heuristic
search. JAIR, 14:253–302.
Thorsten Joachims. 1999. Advances in kernel meth-
ods. chapter Making large-scale support vector ma-
chine learning practical, pages 169–184. MIT Press.
Anders Jonsson and Andrew Barto. 2005. A causal
approach to hierarchical decomposition of factored
mdps. In Advances in Neural Information Processing
Systems, 13:10541060, page 22. Press.
Mari´an Lekav´y and Pavol N´avrat. 2007. Expressivity
of strips-like and htn-like planning. Lecture Notes in
Artificial Intelligence, 4496:121–130.
Percy Liang, Michael I. Jordan, and Dan Klein. 2009.
Learning semantic correspondences with less supervi-
sion. In Proceedings of ACL, pages 91–99.
Neville Mehta, Soumya Ray, Prasad Tadepalli, and
Thomas Dietterich. 2008. Automatic discovery and
transfer of maxq hierarchies. In Proceedings of the
25th international conference on Machine learning,
ICML ’08, pages 648–655.
Raymond J. Mooney. 2008a. Learning language from its
perceptual context. In Proceedings of ECML/PKDD.
Raymond J. Mooney. 2008b. Learning to connect lan-
guage and perception. In Proceedings of AAAI, pages
1598–1601.
A. Newell, J.C. Shaw, and H.A. Simon. 1959. The pro-
cesses of creative thinking. Paper P-1320. Rand Cor-
poration.
James Timothy Oates. 2001. Grounding knowledge
in sensors: Unsupervised learning for language and
planning. Ph.D. thesis, University of Massachusetts
Amherst.
Avirup Sil and Alexander Yates. 2011. Extract-
ing STRIPS representations of actions and events.
In Recent Advances in Natural Language Learning
(RANLP).
Avirup Sil, Fei Huang, and Alexander Yates. 2010. Ex-
tracting action and event semantics from web text. In
AAAI 2010 Fall Symposium on Commonsense Knowl-
edge (CSK).
Jeffrey Mark Siskind. 2001. Grounding the lexical se-
mantics of verbs in visual perception using force dy-
namics and event logic. Journal of Artificial Intelli-
gence Research, 15:31–90.
Richard S. Sutton and Andrew G. Barto. 1998. Rein-
forcement Learning: An Introduction. The MIT Press.
Richard S. Sutton, David McAllester, Satinder Singh, and
Yishay Mansour. 2000. Policy gradient methods for
reinforcement learning with function approximation.
In Advances in NIPS, pages 1057–1063.
Adam Vogel and Daniel Jurafsky. 2010. Learning to
follow navigational directions. In Proceedings of the
ACL, pages 806–814.
Ronald J Williams. 1992. Simple statistical gradient-
following algorithms for connectionist reinforcement
learning. Machine Learning, 8.
</reference>
<page confidence="0.98621">
134
</page>
<reference confidence="0.998467625">
Alicia P. Wolfe and Andrew G. Barto. 2005. Identify-
ing useful subgoals in reinforcement learning by local
graph partitioning. In In Proceedings of the Twenty-
Second International Conference on Machine Learn-
ing, pages 816–823.
Chen Yu and Dana H. Ballard. 2004. On the integration
of grounding language and learning objects. In Pro-
ceedings of AAAI, pages 488–493.
</reference>
<page confidence="0.99879">
135
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.457626">
<title confidence="0.999927">Learning High-Level Planning from Text</title>
<author confidence="0.99134">S R K Branavan</author>
<author confidence="0.99134">Nate Kushman</author>
<author confidence="0.99134">Tao Lei</author>
<author confidence="0.99134">Regina</author>
<affiliation confidence="0.976541">Computer Science and Artificial Intelligence Massachusetts Institute of</affiliation>
<email confidence="0.836521">nkushman,taolei,</email>
<abstract confidence="0.982851153846154">Comprehending action preconditions and effects is an essential step in modeling the dynamics of the world. In this paper, we express the semantics of precondition relations extracted from text in terms of planning operations. The challenge of modeling this connection is to ground language at the level of relations. This type of grounding enables us to create high-level plans based on language abstractions. Our model jointly learns to predict precondition relations from text and to perform high-level planning guided by those relations. We implement this idea in the reinforcement learning framework using feedback automatically obtained from plan execution attempts. When applied to a complex virtual world and text describing that world, our relation extraction technique performs on par with a supervised baseline, yielding an F-measure of 66% compared to the baseline’s 65%. Additionally, we show that a high-level planner utilizing these extracted relations significantly outperforms a strong, text unaware baseline – successfully completing 80% of planning as compared to 69% for the</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Fahiem Bacchus</author>
<author>Qiang Yang</author>
</authors>
<title>Downward refinement and the efficiency of hierarchical problem solving.</title>
<date>1994</date>
<journal>Artificial Intell.,</journal>
<volume>71</volume>
<issue>1</issue>
<contexts>
<context position="9766" citStr="Bacchus and Yang, 1994" startWordPosition="1535" endWordPosition="1538">rmation is utilized in the situated context. Instead of getting step-by-step instructions from the text, our model uses text that describes general knowledge about the domain structure. From this text, it extracts relations between objects in the world which hold independently of any given task. Task-specific solutions are then constructed by a planner that relies on these relations to perform effective high-level planning. Hierarchical Planning It is widely accepted that high-level plans that factorize a planning problem can greatly reduce the corresponding search space (Newell et al., 1959; Bacchus and Yang, 1994). Previous work in planning has studied the theoretical properties of valid abstractions and proposed a number of techniques for generating them (Jonsson and Barto, 2005; Wolfe and Barto, 2005; Mehta et al., 2008; Barry et al., 2011). In general, these techniques use static analysis of the lowlevel domain to induce effective high-level abstractions. In contrast, our focus is on learning the abstraction from natural language. Thus our technique is complementary to past work, and can benefit from human knowledge about the domain structure. 3 Problem Formulation Our task is two-fold. First, given</context>
</contexts>
<marker>Bacchus, Yang, 1994</marker>
<rawString>Fahiem Bacchus and Qiang Yang. 1994. Downward refinement and the efficiency of hierarchical problem solving. Artificial Intell., 71(1):43–100.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jennifer L Barry</author>
<author>Leslie Pack Kaelbling</author>
<author>Toms Lozano-Prez</author>
</authors>
<title>DetH*: Approximate hierarchical solution of large markov decision processes.</title>
<date>2011</date>
<booktitle>In IJCAI’11,</booktitle>
<pages>1928--1935</pages>
<contexts>
<context position="9999" citStr="Barry et al., 2011" startWordPosition="1572" endWordPosition="1575">ts in the world which hold independently of any given task. Task-specific solutions are then constructed by a planner that relies on these relations to perform effective high-level planning. Hierarchical Planning It is widely accepted that high-level plans that factorize a planning problem can greatly reduce the corresponding search space (Newell et al., 1959; Bacchus and Yang, 1994). Previous work in planning has studied the theoretical properties of valid abstractions and proposed a number of techniques for generating them (Jonsson and Barto, 2005; Wolfe and Barto, 2005; Mehta et al., 2008; Barry et al., 2011). In general, these techniques use static analysis of the lowlevel domain to induce effective high-level abstractions. In contrast, our focus is on learning the abstraction from natural language. Thus our technique is complementary to past work, and can benefit from human knowledge about the domain structure. 3 Problem Formulation Our task is two-fold. First, given a text document describing an environment, we wish to extract a set of precondition/effect relations implied by the text. Second, we wish to use these induced relations to determine an action sequence for completing a given task in </context>
</contexts>
<marker>Barry, Kaelbling, Lozano-Prez, 2011</marker>
<rawString>Jennifer L. Barry, Leslie Pack Kaelbling, and Toms Lozano-Prez. 2011. DetH*: Approximate hierarchical solution of large markov decision processes. In IJCAI’11, pages 1928–1935.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brandon Beamer</author>
<author>Roxana Girju</author>
</authors>
<title>Using a bigram event model to predict causal potential.</title>
<date>2009</date>
<booktitle>In Proceedings of CICLing,</booktitle>
<pages>430--441</pages>
<contexts>
<context position="7421" citStr="Beamer and Girju, 2009" startWordPosition="1172" endWordPosition="1175"> planner which uses manually-annotated preconditions. 2 Related Work Extracting Event Semantics from Text The task of extracting preconditions and effects has previously been addressed in the context of lexical semantics (Sil et al., 2010; Sil and Yates, 2011). These approaches combine large-scale distributional techniques with supervised learning to identify desired semantic relations in text. Such combined approaches have also been shown to be effective for identifying other relationships between events, such as causality (Girju and Moldovan, 2002; Chang and Choi, 2006; Blanco et al., 2008; Beamer and Girju, 2009; Do et al., 2011). Similar to these methods, our algorithm capitalizes on surface linguistic cues to learn preconditions from text. However, our only source of supervision is the feedback provided by the planning task which utilizes the predictions. Additionally, we not only identify these relations in text, but also show they are valuable in performing an external task. Learning Semantics via Language Grounding Our work fits into the broad area of grounded language acquisition, where the goal is to learn linguistic analysis from a situated context (Oates, 2001; Siskind, 2001; Yu and Ballard,</context>
<context position="30738" citStr="Beamer and Girju, 2009" startWordPosition="5093" endWordPosition="5096">vial preconditions, our model will choose to satisfy one of the two first, and the Markov assumption blinds it to the remaining precondition, preventing it from determining that it must still satisfy the other. Figure 7: The top five positive features on words and dependency types learned by our model (above) and by SVM (below) for precondition prediction. of this is a feature that checks for the direct object dependency type. This analysis is consistent with prior work on event semantics which shows lexicosyntactic features are effective cues for learning text relations (Blanco et al., 2008; Beamer and Girju, 2009; Do et al., 2011). 8 Conclusions In this paper, we presented a novel technique for inducing precondition relations from text by grounding them in the semantics of planning operations. While using planning feedback as its only source of supervision, our method for relation extraction achieves a performance on par with that of a supervised baseline. Furthermore, relation grounding provides a new view on classical planning problems which enables us to create high-level plans based on language abstractions. We show that building highlevel plans in this manner significantly outperforms traditional</context>
</contexts>
<marker>Beamer, Girju, 2009</marker>
<rawString>Brandon Beamer and Roxana Girju. 2009. Using a bigram event model to predict causal potential. In Proceedings of CICLing, pages 430–441.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eduardo Blanco</author>
<author>Nuria Castell</author>
<author>Dan Moldovan</author>
</authors>
<title>Causal relation extraction.</title>
<date>2008</date>
<booktitle>In Proceedings of the LREC’08.</booktitle>
<contexts>
<context position="7397" citStr="Blanco et al., 2008" startWordPosition="1168" endWordPosition="1171">hes that of an oracle planner which uses manually-annotated preconditions. 2 Related Work Extracting Event Semantics from Text The task of extracting preconditions and effects has previously been addressed in the context of lexical semantics (Sil et al., 2010; Sil and Yates, 2011). These approaches combine large-scale distributional techniques with supervised learning to identify desired semantic relations in text. Such combined approaches have also been shown to be effective for identifying other relationships between events, such as causality (Girju and Moldovan, 2002; Chang and Choi, 2006; Blanco et al., 2008; Beamer and Girju, 2009; Do et al., 2011). Similar to these methods, our algorithm capitalizes on surface linguistic cues to learn preconditions from text. However, our only source of supervision is the feedback provided by the planning task which utilizes the predictions. Additionally, we not only identify these relations in text, but also show they are valuable in performing an external task. Learning Semantics via Language Grounding Our work fits into the broad area of grounded language acquisition, where the goal is to learn linguistic analysis from a situated context (Oates, 2001; Siskin</context>
<context position="30714" citStr="Blanco et al., 2008" startWordPosition="5089" endWordPosition="5092"> task has two non-trivial preconditions, our model will choose to satisfy one of the two first, and the Markov assumption blinds it to the remaining precondition, preventing it from determining that it must still satisfy the other. Figure 7: The top five positive features on words and dependency types learned by our model (above) and by SVM (below) for precondition prediction. of this is a feature that checks for the direct object dependency type. This analysis is consistent with prior work on event semantics which shows lexicosyntactic features are effective cues for learning text relations (Blanco et al., 2008; Beamer and Girju, 2009; Do et al., 2011). 8 Conclusions In this paper, we presented a novel technique for inducing precondition relations from text by grounding them in the semantics of planning operations. While using planning feedback as its only source of supervision, our method for relation extraction achieves a performance on par with that of a supervised baseline. Furthermore, relation grounding provides a new view on classical planning problems which enables us to create high-level plans based on language abstractions. We show that building highlevel plans in this manner significantly</context>
</contexts>
<marker>Blanco, Castell, Moldovan, 2008</marker>
<rawString>Eduardo Blanco, Nuria Castell, and Dan Moldovan. 2008. Causal relation extraction. In Proceedings of the LREC’08.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S R K Branavan</author>
<author>Harr Chen</author>
<author>Luke Zettlemoyer</author>
<author>Regina Barzilay</author>
</authors>
<title>Reinforcement learning for mapping instructions to actions.</title>
<date>2009</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>82--90</pages>
<contexts>
<context position="8105" citStr="Branavan et al., 2009" startWordPosition="1281" endWordPosition="1284">italizes on surface linguistic cues to learn preconditions from text. However, our only source of supervision is the feedback provided by the planning task which utilizes the predictions. Additionally, we not only identify these relations in text, but also show they are valuable in performing an external task. Learning Semantics via Language Grounding Our work fits into the broad area of grounded language acquisition, where the goal is to learn linguistic analysis from a situated context (Oates, 2001; Siskind, 2001; Yu and Ballard, 2004; Fleischman and Roy, 2005; Mooney, 2008a; Mooney, 2008b; Branavan et al., 2009; Liang et al., 2009; Vogel and Jurafsky, 2010). Within this line of work, we are most closely related to the reinforcement learning approaches that learn language by interacting with an external environment (Branavan et al., 2009; Branavan et al., 2010; Vogel and Jurafsky, 2010; Branavan et al., 2011). 4The state-of-the-art baseline used in the 2008 International Planning Competition. http://ipc.informatik.uni-freiburg.de/ 127 Text (input): A pickaxe, which is used to harvest stone, can be made from wood. Precondition Relations: Figure 2: A high-level plan showing two subgoals in a preconditi</context>
</contexts>
<marker>Branavan, Chen, Zettlemoyer, Barzilay, 2009</marker>
<rawString>S.R.K Branavan, Harr Chen, Luke Zettlemoyer, and Regina Barzilay. 2009. Reinforcement learning for mapping instructions to actions. In Proceedings of ACL, pages 82–90.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S R K Branavan</author>
<author>Luke Zettlemoyer</author>
<author>Regina Barzilay</author>
</authors>
<title>Reading between the lines: Learning to map high-level instructions to commands.</title>
<date>2010</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>1268--1277</pages>
<contexts>
<context position="8358" citStr="Branavan et al., 2010" startWordPosition="1322" endWordPosition="1325">lso show they are valuable in performing an external task. Learning Semantics via Language Grounding Our work fits into the broad area of grounded language acquisition, where the goal is to learn linguistic analysis from a situated context (Oates, 2001; Siskind, 2001; Yu and Ballard, 2004; Fleischman and Roy, 2005; Mooney, 2008a; Mooney, 2008b; Branavan et al., 2009; Liang et al., 2009; Vogel and Jurafsky, 2010). Within this line of work, we are most closely related to the reinforcement learning approaches that learn language by interacting with an external environment (Branavan et al., 2009; Branavan et al., 2010; Vogel and Jurafsky, 2010; Branavan et al., 2011). 4The state-of-the-art baseline used in the 2008 International Planning Competition. http://ipc.informatik.uni-freiburg.de/ 127 Text (input): A pickaxe, which is used to harvest stone, can be made from wood. Precondition Relations: Figure 2: A high-level plan showing two subgoals in a precondition relation. The corresponding sentence is shown above. The key distinction of our work is the use of grounding to learn abstract pragmatic relations, i.e. to learn linguistic patterns that describe relationships between objects in the world. This suppl</context>
</contexts>
<marker>Branavan, Zettlemoyer, Barzilay, 2010</marker>
<rawString>S.R.K Branavan, Luke Zettlemoyer, and Regina Barzilay. 2010. Reading between the lines: Learning to map high-level instructions to commands. In Proceedings of ACL, pages 1268–1277.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S R K Branavan</author>
<author>David Silver</author>
<author>Regina Barzilay</author>
</authors>
<title>Learning to win by reading manuals in a montecarlo framework.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>268--277</pages>
<contexts>
<context position="8408" citStr="Branavan et al., 2011" startWordPosition="1330" endWordPosition="1333">nal task. Learning Semantics via Language Grounding Our work fits into the broad area of grounded language acquisition, where the goal is to learn linguistic analysis from a situated context (Oates, 2001; Siskind, 2001; Yu and Ballard, 2004; Fleischman and Roy, 2005; Mooney, 2008a; Mooney, 2008b; Branavan et al., 2009; Liang et al., 2009; Vogel and Jurafsky, 2010). Within this line of work, we are most closely related to the reinforcement learning approaches that learn language by interacting with an external environment (Branavan et al., 2009; Branavan et al., 2010; Vogel and Jurafsky, 2010; Branavan et al., 2011). 4The state-of-the-art baseline used in the 2008 International Planning Competition. http://ipc.informatik.uni-freiburg.de/ 127 Text (input): A pickaxe, which is used to harvest stone, can be made from wood. Precondition Relations: Figure 2: A high-level plan showing two subgoals in a precondition relation. The corresponding sentence is shown above. The key distinction of our work is the use of grounding to learn abstract pragmatic relations, i.e. to learn linguistic patterns that describe relationships between objects in the world. This supplements previous work which grounds words to object</context>
</contexts>
<marker>Branavan, Silver, Barzilay, 2011</marker>
<rawString>S. R. K. Branavan, David Silver, and Regina Barzilay. 2011. Learning to win by reading manuals in a montecarlo framework. In Proceedings of ACL, pages 268– 277.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Du-Seong Chang</author>
<author>Key-Sun Choi</author>
</authors>
<title>Incremental cue phrase learning and bootstrapping method for causality extraction using cue phrase and word pair probabilities.</title>
<date>2006</date>
<journal>Inf. Process. Manage.,</journal>
<volume>42</volume>
<issue>3</issue>
<contexts>
<context position="7376" citStr="Chang and Choi, 2006" startWordPosition="1164" endWordPosition="1167"> of our method approaches that of an oracle planner which uses manually-annotated preconditions. 2 Related Work Extracting Event Semantics from Text The task of extracting preconditions and effects has previously been addressed in the context of lexical semantics (Sil et al., 2010; Sil and Yates, 2011). These approaches combine large-scale distributional techniques with supervised learning to identify desired semantic relations in text. Such combined approaches have also been shown to be effective for identifying other relationships between events, such as causality (Girju and Moldovan, 2002; Chang and Choi, 2006; Blanco et al., 2008; Beamer and Girju, 2009; Do et al., 2011). Similar to these methods, our algorithm capitalizes on surface linguistic cues to learn preconditions from text. However, our only source of supervision is the feedback provided by the planning task which utilizes the predictions. Additionally, we not only identify these relations in text, but also show they are valuable in performing an external task. Learning Semantics via Language Grounding Our work fits into the broad area of grounded language acquisition, where the goal is to learn linguistic analysis from a situated context</context>
</contexts>
<marker>Chang, Choi, 2006</marker>
<rawString>Du-Seong Chang and Key-Sun Choi. 2006. Incremental cue phrase learning and bootstrapping method for causality extraction using cue phrase and word pair probabilities. Inf. Process. Manage., 42(3):662–678.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine de Marneffe</author>
<author>Bill MacCartney</author>
<author>Christopher D Manning</author>
</authors>
<title>Generating typed dependency parses from phrase structure parses.</title>
<date>2006</date>
<booktitle>In LREC</booktitle>
<marker>de Marneffe, MacCartney, Manning, 2006</marker>
<rawString>Marie-Catherine de Marneffe, Bill MacCartney, and Christopher D. Manning. 2006. Generating typed dependency parses from phrase structure parses. In LREC 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Q Do</author>
<author>Y Chan</author>
<author>D Roth</author>
</authors>
<title>Minimally supervised event causality identification.</title>
<date>2011</date>
<booktitle>In EMNLP, 7.</booktitle>
<contexts>
<context position="7439" citStr="Do et al., 2011" startWordPosition="1176" endWordPosition="1179">ally-annotated preconditions. 2 Related Work Extracting Event Semantics from Text The task of extracting preconditions and effects has previously been addressed in the context of lexical semantics (Sil et al., 2010; Sil and Yates, 2011). These approaches combine large-scale distributional techniques with supervised learning to identify desired semantic relations in text. Such combined approaches have also been shown to be effective for identifying other relationships between events, such as causality (Girju and Moldovan, 2002; Chang and Choi, 2006; Blanco et al., 2008; Beamer and Girju, 2009; Do et al., 2011). Similar to these methods, our algorithm capitalizes on surface linguistic cues to learn preconditions from text. However, our only source of supervision is the feedback provided by the planning task which utilizes the predictions. Additionally, we not only identify these relations in text, but also show they are valuable in performing an external task. Learning Semantics via Language Grounding Our work fits into the broad area of grounded language acquisition, where the goal is to learn linguistic analysis from a situated context (Oates, 2001; Siskind, 2001; Yu and Ballard, 2004; Fleischman </context>
<context position="30756" citStr="Do et al., 2011" startWordPosition="5097" endWordPosition="5100">model will choose to satisfy one of the two first, and the Markov assumption blinds it to the remaining precondition, preventing it from determining that it must still satisfy the other. Figure 7: The top five positive features on words and dependency types learned by our model (above) and by SVM (below) for precondition prediction. of this is a feature that checks for the direct object dependency type. This analysis is consistent with prior work on event semantics which shows lexicosyntactic features are effective cues for learning text relations (Blanco et al., 2008; Beamer and Girju, 2009; Do et al., 2011). 8 Conclusions In this paper, we presented a novel technique for inducing precondition relations from text by grounding them in the semantics of planning operations. While using planning feedback as its only source of supervision, our method for relation extraction achieves a performance on par with that of a supervised baseline. Furthermore, relation grounding provides a new view on classical planning problems which enables us to create high-level plans based on language abstractions. We show that building highlevel plans in this manner significantly outperforms traditional techniques in ter</context>
</contexts>
<marker>Do, Chan, Roth, 2011</marker>
<rawString>Q. Do, Y. Chan, and D. Roth. 2011. Minimally supervised event causality identification. In EMNLP, 7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Fleischman</author>
<author>Deb Roy</author>
</authors>
<title>Intentional context in situated natural language learning.</title>
<date>2005</date>
<booktitle>In Proceedings of CoNLL,</booktitle>
<pages>104--111</pages>
<contexts>
<context position="8052" citStr="Fleischman and Roy, 2005" startWordPosition="1273" endWordPosition="1276"> al., 2011). Similar to these methods, our algorithm capitalizes on surface linguistic cues to learn preconditions from text. However, our only source of supervision is the feedback provided by the planning task which utilizes the predictions. Additionally, we not only identify these relations in text, but also show they are valuable in performing an external task. Learning Semantics via Language Grounding Our work fits into the broad area of grounded language acquisition, where the goal is to learn linguistic analysis from a situated context (Oates, 2001; Siskind, 2001; Yu and Ballard, 2004; Fleischman and Roy, 2005; Mooney, 2008a; Mooney, 2008b; Branavan et al., 2009; Liang et al., 2009; Vogel and Jurafsky, 2010). Within this line of work, we are most closely related to the reinforcement learning approaches that learn language by interacting with an external environment (Branavan et al., 2009; Branavan et al., 2010; Vogel and Jurafsky, 2010; Branavan et al., 2011). 4The state-of-the-art baseline used in the 2008 International Planning Competition. http://ipc.informatik.uni-freiburg.de/ 127 Text (input): A pickaxe, which is used to harvest stone, can be made from wood. Precondition Relations: Figure 2: A</context>
</contexts>
<marker>Fleischman, Roy, 2005</marker>
<rawString>Michael Fleischman and Deb Roy. 2005. Intentional context in situated natural language learning. In Proceedings of CoNLL, pages 104–111.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maria Fox</author>
<author>Derek Long</author>
</authors>
<title>Pddl2.1: An extension to pddl for expressing temporal planning domains.</title>
<date>2003</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<pages>20--2003</pages>
<contexts>
<context position="19514" citStr="Fox and Long, 2003" startWordPosition="3218" endWordPosition="3221"> virtual world. Each grid location represents a tile of either land or water and may also contain resources. Users can freely move around the world, harvest resources and craft various tools and objects from these resources. The dynamics of the world require certain resources or tools as prerequisites for performing a given action, as can be seen in Figure 3. For example, a user must first craft a bucket before they can collect milk. Defining the Domain In order to execute a traditional planner on the Minecraft domain, we define the domain using the Planning Domain Definition Language (PDDL) (Fox and Long, 2003). This is the standard task definition language used in the International Planning Competitions (IPC).6 We define as predicates all aspects of the game state – for example, the location of resources in the world, the resources and objects possessed by the player, and the player’s location. Our subgoals xi and our task goals sg f map directly to these predicates. This results in a domain with significantly greater complexity than those solvable by traditional low-level planners. Table 1 compares the complexity of our domain with some typical planning domains used in the IPC. 6http://ipc.icaps-c</context>
</contexts>
<marker>Fox, Long, 2003</marker>
<rawString>Maria Fox and Derek Long. 2003. Pddl2.1: An extension to pddl for expressing temporal planning domains. Journal of Artificial Intelligence Research, 20:2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Malik Ghallab</author>
<author>Dana S Nau</author>
<author>Paolo Traverso</author>
</authors>
<title>Automated Planning: theory and practice.</title>
<date>2004</date>
<publisher>Morgan Kaufmann.</publisher>
<contexts>
<context position="3958" citStr="Ghallab et al., 2004" startWordPosition="605" endWordPosition="608">mics, it does not provide sufficient details for successful plan execution. On the other hand, planning with low-level actions does not suffer from this limitation, but is computationally intractable for even moderately complex tasks. As a consequence, in many practical domains, planning algorithms rely on manually-crafted high-level 2http://www.minecraft.net/ 126 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 126–135, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics abstractions to make search tractable (Ghallab et al., 2004; Lekav´y and N´avrat, 2007). The central idea of our work is to express the semantics of precondition relations extracted from text in terms of planning operations. For instance, the precondition relation between pickaxe and stone described in the sentence in Figure 1a indicates that plans which involve obtaining stone will likely need to first obtain a pickaxe. The novel challenge of this view is to model grounding at the level of relations, in contrast to prior work which focused on objectlevel grounding. We build on the intuition that the validity of precondition relations extracted from t</context>
</contexts>
<marker>Ghallab, Nau, Traverso, 2004</marker>
<rawString>Malik Ghallab, Dana S. Nau, and Paolo Traverso. 2004. Automated Planning: theory and practice. Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roxana Girju</author>
<author>Dan I Moldovan</author>
</authors>
<title>Text mining for causal relations.</title>
<date>2002</date>
<booktitle>In Proceedigns of FLAIRS,</booktitle>
<pages>360--364</pages>
<contexts>
<context position="7354" citStr="Girju and Moldovan, 2002" startWordPosition="1160" endWordPosition="1163">. In fact, the performance of our method approaches that of an oracle planner which uses manually-annotated preconditions. 2 Related Work Extracting Event Semantics from Text The task of extracting preconditions and effects has previously been addressed in the context of lexical semantics (Sil et al., 2010; Sil and Yates, 2011). These approaches combine large-scale distributional techniques with supervised learning to identify desired semantic relations in text. Such combined approaches have also been shown to be effective for identifying other relationships between events, such as causality (Girju and Moldovan, 2002; Chang and Choi, 2006; Blanco et al., 2008; Beamer and Girju, 2009; Do et al., 2011). Similar to these methods, our algorithm capitalizes on surface linguistic cues to learn preconditions from text. However, our only source of supervision is the feedback provided by the planning task which utilizes the predictions. Additionally, we not only identify these relations in text, but also show they are valuable in performing an external task. Learning Semantics via Language Grounding Our work fits into the broad area of grounded language acquisition, where the goal is to learn linguistic analysis f</context>
</contexts>
<marker>Girju, Moldovan, 2002</marker>
<rawString>Roxana Girju and Dan I. Moldovan. 2002. Text mining for causal relations. In Proceedigns of FLAIRS, pages 360–364.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J¨org Hoffmann</author>
<author>Bernhard Nebel</author>
</authors>
<title>The FF planning system: Fast plan generation through heuristic search.</title>
<date>2001</date>
<journal>JAIR,</journal>
<pages>14--253</pages>
<contexts>
<context position="6423" citStr="Hoffmann and Nebel, 2001" startWordPosition="1011" endWordPosition="1014">precondition relation extraction accuracy on par with that of a supervised SVM baseline. Specifically, it yields an F-score of 66% compared to the 65% of the baseline. In addition, we show that these extracted relations can be used to improve the performance of a high-level planner. As baselines 3If a planner can find a plan to successfully obtain stone after obtaining a pickaxe, then a pickaxe is likely a precondition for stone. Conversely, if a planner obtains stone without first obtaining a pickaxe, then it is likely not a precondition. for this evaluation, we employ the Metric-FF planner (Hoffmann and Nebel, 2001),4 as well as a textunaware variant of our model. Our results show that our text-driven high-level planner significantly outperforms all baselines in terms of completed planning tasks – it successfully solves 80% as compared to 41% for the Metric-FF planner and 69% for the text unaware variant of our model. In fact, the performance of our method approaches that of an oracle planner which uses manually-annotated preconditions. 2 Related Work Extracting Event Semantics from Text The task of extracting preconditions and effects has previously been addressed in the context of lexical semantics (Si</context>
<context position="20339" citStr="Hoffmann and Nebel, 2001" startWordPosition="3353" endWordPosition="3356">n the world, the resources and objects possessed by the player, and the player’s location. Our subgoals xi and our task goals sg f map directly to these predicates. This results in a domain with significantly greater complexity than those solvable by traditional low-level planners. Table 1 compares the complexity of our domain with some typical planning domains used in the IPC. 6http://ipc.icaps-conference.org/ fence wood plank stick bone meal seeds string wool fishing rod shears iron door bucket fish iron milk XDθx +— αx r t 130 Low-level Planner As our low-level planner we employ Metric-FF (Hoffmann and Nebel, 2001), the state-of-the-art baseline used in the 2008 International Planning Competition. Metric-FF is a forward-chaining heuristic state space planner. Its main heuristic is to simplify the task by ignoring operator delete lists. The number of actions in the solution for this simplified task is then used as the goal distance estimate for various search strategies. Features The two components of our model leverage different types of information, and as a result, they each use distinct sets of features. The text component features 0, are computed over sentences and their dependency parses. The Stanf</context>
</contexts>
<marker>Hoffmann, Nebel, 2001</marker>
<rawString>J¨org Hoffmann and Bernhard Nebel. 2001. The FF planning system: Fast plan generation through heuristic search. JAIR, 14:253–302.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
</authors>
<title>Advances in kernel methods. chapter Making large-scale support vector machine learning practical,</title>
<date>1999</date>
<pages>169--184</pages>
<publisher>MIT Press.</publisher>
<contexts>
<context position="24488" citStr="Joachims, 1999" startWordPosition="4035" endWordPosition="4036">selines To evaluate the performance of our relation extraction, we compare against an SVM classifier8 trained on the Gold Relations. We test the SVM baseline in a leave-one-out fashion. To evaluate the performance of our text-aware high-level planner, we compare against five baselines. The first two baselines – FF and No Text – do not use any textual information. The FF baseline directly runs the Metric-FF planner on the given task, while the No Text baseline is a variant of our model that learns to plan in the reinforcement learning framework. It uses the same state-level features 8SVMlight (Joachims, 1999) with default parameters. 131 Sticks are the only building material required to craft a Seeds for growing wheat can be obtained by breaking ✘ fence or tall grass ladder. Figure 4: Examples of precondition relations predicted by our model from text. Check marks (✓) indicate correct predictions, while a cross (X) marks the incorrect one – in this case, a valid relation that was predicted as invalid by our model. Note that each pair of highlighted noun phrases in a sentence is a Candidate Relation, and pairs that are not connected by an arrow were correctly predicted to be invalid by our model. F</context>
</contexts>
<marker>Joachims, 1999</marker>
<rawString>Thorsten Joachims. 1999. Advances in kernel methods. chapter Making large-scale support vector machine learning practical, pages 169–184. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anders Jonsson</author>
<author>Andrew Barto</author>
</authors>
<title>A causal approach to hierarchical decomposition of factored mdps.</title>
<date>2005</date>
<booktitle>In Advances in Neural Information Processing Systems,</booktitle>
<pages>13--10541060</pages>
<publisher>Press.</publisher>
<contexts>
<context position="9935" citStr="Jonsson and Barto, 2005" startWordPosition="1560" endWordPosition="1563">omain structure. From this text, it extracts relations between objects in the world which hold independently of any given task. Task-specific solutions are then constructed by a planner that relies on these relations to perform effective high-level planning. Hierarchical Planning It is widely accepted that high-level plans that factorize a planning problem can greatly reduce the corresponding search space (Newell et al., 1959; Bacchus and Yang, 1994). Previous work in planning has studied the theoretical properties of valid abstractions and proposed a number of techniques for generating them (Jonsson and Barto, 2005; Wolfe and Barto, 2005; Mehta et al., 2008; Barry et al., 2011). In general, these techniques use static analysis of the lowlevel domain to induce effective high-level abstractions. In contrast, our focus is on learning the abstraction from natural language. Thus our technique is complementary to past work, and can benefit from human knowledge about the domain structure. 3 Problem Formulation Our task is two-fold. First, given a text document describing an environment, we wish to extract a set of precondition/effect relations implied by the text. Second, we wish to use these induced relations</context>
</contexts>
<marker>Jonsson, Barto, 2005</marker>
<rawString>Anders Jonsson and Andrew Barto. 2005. A causal approach to hierarchical decomposition of factored mdps. In Advances in Neural Information Processing Systems, 13:10541060, page 22. Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mari´an Lekav´y</author>
<author>Pavol N´avrat</author>
</authors>
<title>Expressivity of strips-like and htn-like planning.</title>
<date>2007</date>
<journal>Lecture Notes in Artificial Intelligence,</journal>
<pages>4496--121</pages>
<marker>Lekav´y, N´avrat, 2007</marker>
<rawString>Mari´an Lekav´y and Pavol N´avrat. 2007. Expressivity of strips-like and htn-like planning. Lecture Notes in Artificial Intelligence, 4496:121–130.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Percy Liang</author>
<author>Michael I Jordan</author>
<author>Dan Klein</author>
</authors>
<title>Learning semantic correspondences with less supervision.</title>
<date>2009</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>91--99</pages>
<contexts>
<context position="8125" citStr="Liang et al., 2009" startWordPosition="1285" endWordPosition="1288">guistic cues to learn preconditions from text. However, our only source of supervision is the feedback provided by the planning task which utilizes the predictions. Additionally, we not only identify these relations in text, but also show they are valuable in performing an external task. Learning Semantics via Language Grounding Our work fits into the broad area of grounded language acquisition, where the goal is to learn linguistic analysis from a situated context (Oates, 2001; Siskind, 2001; Yu and Ballard, 2004; Fleischman and Roy, 2005; Mooney, 2008a; Mooney, 2008b; Branavan et al., 2009; Liang et al., 2009; Vogel and Jurafsky, 2010). Within this line of work, we are most closely related to the reinforcement learning approaches that learn language by interacting with an external environment (Branavan et al., 2009; Branavan et al., 2010; Vogel and Jurafsky, 2010; Branavan et al., 2011). 4The state-of-the-art baseline used in the 2008 International Planning Competition. http://ipc.informatik.uni-freiburg.de/ 127 Text (input): A pickaxe, which is used to harvest stone, can be made from wood. Precondition Relations: Figure 2: A high-level plan showing two subgoals in a precondition relation. The cor</context>
</contexts>
<marker>Liang, Jordan, Klein, 2009</marker>
<rawString>Percy Liang, Michael I. Jordan, and Dan Klein. 2009. Learning semantic correspondences with less supervision. In Proceedings of ACL, pages 91–99.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Neville Mehta</author>
<author>Soumya Ray</author>
<author>Prasad Tadepalli</author>
<author>Thomas Dietterich</author>
</authors>
<title>Automatic discovery and transfer of maxq hierarchies.</title>
<date>2008</date>
<booktitle>In Proceedings of the 25th international conference on Machine learning, ICML ’08,</booktitle>
<pages>648--655</pages>
<contexts>
<context position="9978" citStr="Mehta et al., 2008" startWordPosition="1568" endWordPosition="1571">ations between objects in the world which hold independently of any given task. Task-specific solutions are then constructed by a planner that relies on these relations to perform effective high-level planning. Hierarchical Planning It is widely accepted that high-level plans that factorize a planning problem can greatly reduce the corresponding search space (Newell et al., 1959; Bacchus and Yang, 1994). Previous work in planning has studied the theoretical properties of valid abstractions and proposed a number of techniques for generating them (Jonsson and Barto, 2005; Wolfe and Barto, 2005; Mehta et al., 2008; Barry et al., 2011). In general, these techniques use static analysis of the lowlevel domain to induce effective high-level abstractions. In contrast, our focus is on learning the abstraction from natural language. Thus our technique is complementary to past work, and can benefit from human knowledge about the domain structure. 3 Problem Formulation Our task is two-fold. First, given a text document describing an environment, we wish to extract a set of precondition/effect relations implied by the text. Second, we wish to use these induced relations to determine an action sequence for comple</context>
</contexts>
<marker>Mehta, Ray, Tadepalli, Dietterich, 2008</marker>
<rawString>Neville Mehta, Soumya Ray, Prasad Tadepalli, and Thomas Dietterich. 2008. Automatic discovery and transfer of maxq hierarchies. In Proceedings of the 25th international conference on Machine learning, ICML ’08, pages 648–655.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Raymond J Mooney</author>
</authors>
<title>Learning language from its perceptual context.</title>
<date>2008</date>
<booktitle>In Proceedings of ECML/PKDD.</booktitle>
<contexts>
<context position="8066" citStr="Mooney, 2008" startWordPosition="1277" endWordPosition="1278">ese methods, our algorithm capitalizes on surface linguistic cues to learn preconditions from text. However, our only source of supervision is the feedback provided by the planning task which utilizes the predictions. Additionally, we not only identify these relations in text, but also show they are valuable in performing an external task. Learning Semantics via Language Grounding Our work fits into the broad area of grounded language acquisition, where the goal is to learn linguistic analysis from a situated context (Oates, 2001; Siskind, 2001; Yu and Ballard, 2004; Fleischman and Roy, 2005; Mooney, 2008a; Mooney, 2008b; Branavan et al., 2009; Liang et al., 2009; Vogel and Jurafsky, 2010). Within this line of work, we are most closely related to the reinforcement learning approaches that learn language by interacting with an external environment (Branavan et al., 2009; Branavan et al., 2010; Vogel and Jurafsky, 2010; Branavan et al., 2011). 4The state-of-the-art baseline used in the 2008 International Planning Competition. http://ipc.informatik.uni-freiburg.de/ 127 Text (input): A pickaxe, which is used to harvest stone, can be made from wood. Precondition Relations: Figure 2: A high-level pl</context>
</contexts>
<marker>Mooney, 2008</marker>
<rawString>Raymond J. Mooney. 2008a. Learning language from its perceptual context. In Proceedings of ECML/PKDD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Raymond J Mooney</author>
</authors>
<title>Learning to connect language and perception.</title>
<date>2008</date>
<booktitle>In Proceedings of AAAI,</booktitle>
<pages>1598--1601</pages>
<contexts>
<context position="8066" citStr="Mooney, 2008" startWordPosition="1277" endWordPosition="1278">ese methods, our algorithm capitalizes on surface linguistic cues to learn preconditions from text. However, our only source of supervision is the feedback provided by the planning task which utilizes the predictions. Additionally, we not only identify these relations in text, but also show they are valuable in performing an external task. Learning Semantics via Language Grounding Our work fits into the broad area of grounded language acquisition, where the goal is to learn linguistic analysis from a situated context (Oates, 2001; Siskind, 2001; Yu and Ballard, 2004; Fleischman and Roy, 2005; Mooney, 2008a; Mooney, 2008b; Branavan et al., 2009; Liang et al., 2009; Vogel and Jurafsky, 2010). Within this line of work, we are most closely related to the reinforcement learning approaches that learn language by interacting with an external environment (Branavan et al., 2009; Branavan et al., 2010; Vogel and Jurafsky, 2010; Branavan et al., 2011). 4The state-of-the-art baseline used in the 2008 International Planning Competition. http://ipc.informatik.uni-freiburg.de/ 127 Text (input): A pickaxe, which is used to harvest stone, can be made from wood. Precondition Relations: Figure 2: A high-level pl</context>
</contexts>
<marker>Mooney, 2008</marker>
<rawString>Raymond J. Mooney. 2008b. Learning to connect language and perception. In Proceedings of AAAI, pages 1598–1601.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Newell</author>
<author>J C Shaw</author>
<author>H A Simon</author>
</authors>
<title>The processes of creative thinking. Paper P-1320.</title>
<date>1959</date>
<publisher>Rand Corporation.</publisher>
<contexts>
<context position="9741" citStr="Newell et al., 1959" startWordPosition="1531" endWordPosition="1534"> way the textual information is utilized in the situated context. Instead of getting step-by-step instructions from the text, our model uses text that describes general knowledge about the domain structure. From this text, it extracts relations between objects in the world which hold independently of any given task. Task-specific solutions are then constructed by a planner that relies on these relations to perform effective high-level planning. Hierarchical Planning It is widely accepted that high-level plans that factorize a planning problem can greatly reduce the corresponding search space (Newell et al., 1959; Bacchus and Yang, 1994). Previous work in planning has studied the theoretical properties of valid abstractions and proposed a number of techniques for generating them (Jonsson and Barto, 2005; Wolfe and Barto, 2005; Mehta et al., 2008; Barry et al., 2011). In general, these techniques use static analysis of the lowlevel domain to induce effective high-level abstractions. In contrast, our focus is on learning the abstraction from natural language. Thus our technique is complementary to past work, and can benefit from human knowledge about the domain structure. 3 Problem Formulation Our task </context>
</contexts>
<marker>Newell, Shaw, Simon, 1959</marker>
<rawString>A. Newell, J.C. Shaw, and H.A. Simon. 1959. The processes of creative thinking. Paper P-1320. Rand Corporation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Timothy Oates</author>
</authors>
<title>Grounding knowledge in sensors: Unsupervised learning for language and planning.</title>
<date>2001</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Massachusetts Amherst.</institution>
<contexts>
<context position="7989" citStr="Oates, 2001" startWordPosition="1265" endWordPosition="1266">Blanco et al., 2008; Beamer and Girju, 2009; Do et al., 2011). Similar to these methods, our algorithm capitalizes on surface linguistic cues to learn preconditions from text. However, our only source of supervision is the feedback provided by the planning task which utilizes the predictions. Additionally, we not only identify these relations in text, but also show they are valuable in performing an external task. Learning Semantics via Language Grounding Our work fits into the broad area of grounded language acquisition, where the goal is to learn linguistic analysis from a situated context (Oates, 2001; Siskind, 2001; Yu and Ballard, 2004; Fleischman and Roy, 2005; Mooney, 2008a; Mooney, 2008b; Branavan et al., 2009; Liang et al., 2009; Vogel and Jurafsky, 2010). Within this line of work, we are most closely related to the reinforcement learning approaches that learn language by interacting with an external environment (Branavan et al., 2009; Branavan et al., 2010; Vogel and Jurafsky, 2010; Branavan et al., 2011). 4The state-of-the-art baseline used in the 2008 International Planning Competition. http://ipc.informatik.uni-freiburg.de/ 127 Text (input): A pickaxe, which is used to harvest st</context>
</contexts>
<marker>Oates, 2001</marker>
<rawString>James Timothy Oates. 2001. Grounding knowledge in sensors: Unsupervised learning for language and planning. Ph.D. thesis, University of Massachusetts Amherst.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Avirup Sil</author>
<author>Alexander Yates</author>
</authors>
<title>Extracting STRIPS representations of actions and events.</title>
<date>2011</date>
<booktitle>In Recent Advances in Natural Language Learning (RANLP).</booktitle>
<contexts>
<context position="7059" citStr="Sil and Yates, 2011" startWordPosition="1119" endWordPosition="1122">textunaware variant of our model. Our results show that our text-driven high-level planner significantly outperforms all baselines in terms of completed planning tasks – it successfully solves 80% as compared to 41% for the Metric-FF planner and 69% for the text unaware variant of our model. In fact, the performance of our method approaches that of an oracle planner which uses manually-annotated preconditions. 2 Related Work Extracting Event Semantics from Text The task of extracting preconditions and effects has previously been addressed in the context of lexical semantics (Sil et al., 2010; Sil and Yates, 2011). These approaches combine large-scale distributional techniques with supervised learning to identify desired semantic relations in text. Such combined approaches have also been shown to be effective for identifying other relationships between events, such as causality (Girju and Moldovan, 2002; Chang and Choi, 2006; Blanco et al., 2008; Beamer and Girju, 2009; Do et al., 2011). Similar to these methods, our algorithm capitalizes on surface linguistic cues to learn preconditions from text. However, our only source of supervision is the feedback provided by the planning task which utilizes the </context>
</contexts>
<marker>Sil, Yates, 2011</marker>
<rawString>Avirup Sil and Alexander Yates. 2011. Extracting STRIPS representations of actions and events. In Recent Advances in Natural Language Learning (RANLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Avirup Sil</author>
<author>Fei Huang</author>
<author>Alexander Yates</author>
</authors>
<title>Extracting action and event semantics from web text.</title>
<date>2010</date>
<booktitle>In AAAI 2010 Fall Symposium on Commonsense Knowledge (CSK).</booktitle>
<contexts>
<context position="7037" citStr="Sil et al., 2010" startWordPosition="1115" endWordPosition="1118">1),4 as well as a textunaware variant of our model. Our results show that our text-driven high-level planner significantly outperforms all baselines in terms of completed planning tasks – it successfully solves 80% as compared to 41% for the Metric-FF planner and 69% for the text unaware variant of our model. In fact, the performance of our method approaches that of an oracle planner which uses manually-annotated preconditions. 2 Related Work Extracting Event Semantics from Text The task of extracting preconditions and effects has previously been addressed in the context of lexical semantics (Sil et al., 2010; Sil and Yates, 2011). These approaches combine large-scale distributional techniques with supervised learning to identify desired semantic relations in text. Such combined approaches have also been shown to be effective for identifying other relationships between events, such as causality (Girju and Moldovan, 2002; Chang and Choi, 2006; Blanco et al., 2008; Beamer and Girju, 2009; Do et al., 2011). Similar to these methods, our algorithm capitalizes on surface linguistic cues to learn preconditions from text. However, our only source of supervision is the feedback provided by the planning ta</context>
</contexts>
<marker>Sil, Huang, Yates, 2010</marker>
<rawString>Avirup Sil, Fei Huang, and Alexander Yates. 2010. Extracting action and event semantics from web text. In AAAI 2010 Fall Symposium on Commonsense Knowledge (CSK).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeffrey Mark Siskind</author>
</authors>
<title>Grounding the lexical semantics of verbs in visual perception using force dynamics and event logic.</title>
<date>2001</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<pages>15--31</pages>
<contexts>
<context position="8004" citStr="Siskind, 2001" startWordPosition="1267" endWordPosition="1268">, 2008; Beamer and Girju, 2009; Do et al., 2011). Similar to these methods, our algorithm capitalizes on surface linguistic cues to learn preconditions from text. However, our only source of supervision is the feedback provided by the planning task which utilizes the predictions. Additionally, we not only identify these relations in text, but also show they are valuable in performing an external task. Learning Semantics via Language Grounding Our work fits into the broad area of grounded language acquisition, where the goal is to learn linguistic analysis from a situated context (Oates, 2001; Siskind, 2001; Yu and Ballard, 2004; Fleischman and Roy, 2005; Mooney, 2008a; Mooney, 2008b; Branavan et al., 2009; Liang et al., 2009; Vogel and Jurafsky, 2010). Within this line of work, we are most closely related to the reinforcement learning approaches that learn language by interacting with an external environment (Branavan et al., 2009; Branavan et al., 2010; Vogel and Jurafsky, 2010; Branavan et al., 2011). 4The state-of-the-art baseline used in the 2008 International Planning Competition. http://ipc.informatik.uni-freiburg.de/ 127 Text (input): A pickaxe, which is used to harvest stone, can be mad</context>
</contexts>
<marker>Siskind, 2001</marker>
<rawString>Jeffrey Mark Siskind. 2001. Grounding the lexical semantics of verbs in visual perception using force dynamics and event logic. Journal of Artificial Intelligence Research, 15:31–90.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard S Sutton</author>
<author>Andrew G Barto</author>
</authors>
<title>Reinforcement Learning: An Introduction.</title>
<date>1998</date>
<publisher>The MIT Press.</publisher>
<contexts>
<context position="17378" citStr="Sutton and Barto, 1998" startWordPosition="2851" endWordPosition="2854"> Parameter Update Parameter updates in our model are done via reinforcement learning. Specifically, once the model has predicted a subgoal sequence for a given goal, the sequence is given to the low-level planner for execution. The success or failure of this execution is used to compute the reward signal r for parameter estimation. This predict-execute-update cycle is repeated until convergence. We assume that our reward signal r strongly correlates with the correctness of model predictions. Therefore, during learning, we need to find the model parameters that maximize expected future reward (Sutton and Barto, 1998). We perform this maximization via stochastic gradient ascent, using the standard policy gradient algorithm (Williams, 1992; Sutton et al., 2000). We perform two separate policy gradient updates, one for each model component. The objective of the text component of our model is purely to predict the validity of preconditions. Therefore, subgoal pairs (xk, xl), where xl is reachable from xk, are given positive reward. The corresponding parameter update, with learning rate αc, takes the following form: �Dθc +— αc r φc(xi, xj, ~wk, qk) − Ep(x,,1—&apos;x,1|·) [φc(xi1, xj1, ~wk, qk)] J . (2) The objectiv</context>
<context position="27326" citStr="Sutton and Barto, 1998" startWordPosition="4522" endWordPosition="4525">and the baselines. All performance differences between methods are statistically significant at p &lt; .01. between the high-level planners and the FF baseline is fair, the FF baseline is allowed a runtime of 2,000 minutes. This is an upper bound on the time that our high-level planner can take over the 200 learning iterations, with subgoal sequences of length at most 10 and a one minute timeout. Lastly, during learning we initialize all parameters to zero, use a fixed learning rate of 0.0001, and encourage our model to explore the state space by using the standard c-greedy exploration strategy (Sutton and Barto, 1998). 7 Results Relation Extraction Figure 5 shows the performance of our method on identifying preconditions in text. We also show the performance of the supervised SVM baseline. As can be seen, after 200 learning iterations, our model achieves an F-Measure of 66%, equal to the supervised baseline. These results support our hypothesis that planning feedback is a powerful source of supervision for analyzing a given text corpus. Figure 4 shows some examples of sentences and the corresponding extracted relations. Planning Performance As shown in Table 4 our text-enriched planning model outperforms t</context>
</contexts>
<marker>Sutton, Barto, 1998</marker>
<rawString>Richard S. Sutton and Andrew G. Barto. 1998. Reinforcement Learning: An Introduction. The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard S Sutton</author>
<author>David McAllester</author>
<author>Satinder Singh</author>
<author>Yishay Mansour</author>
</authors>
<title>Policy gradient methods for reinforcement learning with function approximation.</title>
<date>2000</date>
<booktitle>In Advances in NIPS,</booktitle>
<pages>1057--1063</pages>
<contexts>
<context position="17523" citStr="Sutton et al., 2000" startWordPosition="2871" endWordPosition="2874">for a given goal, the sequence is given to the low-level planner for execution. The success or failure of this execution is used to compute the reward signal r for parameter estimation. This predict-execute-update cycle is repeated until convergence. We assume that our reward signal r strongly correlates with the correctness of model predictions. Therefore, during learning, we need to find the model parameters that maximize expected future reward (Sutton and Barto, 1998). We perform this maximization via stochastic gradient ascent, using the standard policy gradient algorithm (Williams, 1992; Sutton et al., 2000). We perform two separate policy gradient updates, one for each model component. The objective of the text component of our model is purely to predict the validity of preconditions. Therefore, subgoal pairs (xk, xl), where xl is reachable from xk, are given positive reward. The corresponding parameter update, with learning rate αc, takes the following form: �Dθc +— αc r φc(xi, xj, ~wk, qk) − Ep(x,,1—&apos;x,1|·) [φc(xi1, xj1, ~wk, qk)] J . (2) The objective of the planning component of our model is to predict subgoal sequences that successfully achieve the given planning goals. Thus we directly use</context>
</contexts>
<marker>Sutton, McAllester, Singh, Mansour, 2000</marker>
<rawString>Richard S. Sutton, David McAllester, Satinder Singh, and Yishay Mansour. 2000. Policy gradient methods for reinforcement learning with function approximation. In Advances in NIPS, pages 1057–1063.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Vogel</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Learning to follow navigational directions.</title>
<date>2010</date>
<booktitle>In Proceedings of the ACL,</booktitle>
<pages>806--814</pages>
<contexts>
<context position="8152" citStr="Vogel and Jurafsky, 2010" startWordPosition="1289" endWordPosition="1292">n preconditions from text. However, our only source of supervision is the feedback provided by the planning task which utilizes the predictions. Additionally, we not only identify these relations in text, but also show they are valuable in performing an external task. Learning Semantics via Language Grounding Our work fits into the broad area of grounded language acquisition, where the goal is to learn linguistic analysis from a situated context (Oates, 2001; Siskind, 2001; Yu and Ballard, 2004; Fleischman and Roy, 2005; Mooney, 2008a; Mooney, 2008b; Branavan et al., 2009; Liang et al., 2009; Vogel and Jurafsky, 2010). Within this line of work, we are most closely related to the reinforcement learning approaches that learn language by interacting with an external environment (Branavan et al., 2009; Branavan et al., 2010; Vogel and Jurafsky, 2010; Branavan et al., 2011). 4The state-of-the-art baseline used in the 2008 International Planning Competition. http://ipc.informatik.uni-freiburg.de/ 127 Text (input): A pickaxe, which is used to harvest stone, can be made from wood. Precondition Relations: Figure 2: A high-level plan showing two subgoals in a precondition relation. The corresponding sentence is show</context>
</contexts>
<marker>Vogel, Jurafsky, 2010</marker>
<rawString>Adam Vogel and Daniel Jurafsky. 2010. Learning to follow navigational directions. In Proceedings of the ACL, pages 806–814.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronald J Williams</author>
</authors>
<title>Simple statistical gradientfollowing algorithms for connectionist reinforcement learning.</title>
<date>1992</date>
<booktitle>Machine Learning,</booktitle>
<volume>8</volume>
<contexts>
<context position="17501" citStr="Williams, 1992" startWordPosition="2869" endWordPosition="2870">ubgoal sequence for a given goal, the sequence is given to the low-level planner for execution. The success or failure of this execution is used to compute the reward signal r for parameter estimation. This predict-execute-update cycle is repeated until convergence. We assume that our reward signal r strongly correlates with the correctness of model predictions. Therefore, during learning, we need to find the model parameters that maximize expected future reward (Sutton and Barto, 1998). We perform this maximization via stochastic gradient ascent, using the standard policy gradient algorithm (Williams, 1992; Sutton et al., 2000). We perform two separate policy gradient updates, one for each model component. The objective of the text component of our model is purely to predict the validity of preconditions. Therefore, subgoal pairs (xk, xl), where xl is reachable from xk, are given positive reward. The corresponding parameter update, with learning rate αc, takes the following form: �Dθc +— αc r φc(xi, xj, ~wk, qk) − Ep(x,,1—&apos;x,1|·) [φc(xi1, xj1, ~wk, qk)] J . (2) The objective of the planning component of our model is to predict subgoal sequences that successfully achieve the given planning goals</context>
</contexts>
<marker>Williams, 1992</marker>
<rawString>Ronald J Williams. 1992. Simple statistical gradientfollowing algorithms for connectionist reinforcement learning. Machine Learning, 8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alicia P Wolfe</author>
<author>Andrew G Barto</author>
</authors>
<title>Identifying useful subgoals in reinforcement learning by local graph partitioning. In</title>
<date>2005</date>
<booktitle>In Proceedings of the TwentySecond International Conference on Machine Learning,</booktitle>
<pages>816--823</pages>
<contexts>
<context position="9958" citStr="Wolfe and Barto, 2005" startWordPosition="1564" endWordPosition="1567">s text, it extracts relations between objects in the world which hold independently of any given task. Task-specific solutions are then constructed by a planner that relies on these relations to perform effective high-level planning. Hierarchical Planning It is widely accepted that high-level plans that factorize a planning problem can greatly reduce the corresponding search space (Newell et al., 1959; Bacchus and Yang, 1994). Previous work in planning has studied the theoretical properties of valid abstractions and proposed a number of techniques for generating them (Jonsson and Barto, 2005; Wolfe and Barto, 2005; Mehta et al., 2008; Barry et al., 2011). In general, these techniques use static analysis of the lowlevel domain to induce effective high-level abstractions. In contrast, our focus is on learning the abstraction from natural language. Thus our technique is complementary to past work, and can benefit from human knowledge about the domain structure. 3 Problem Formulation Our task is two-fold. First, given a text document describing an environment, we wish to extract a set of precondition/effect relations implied by the text. Second, we wish to use these induced relations to determine an action</context>
</contexts>
<marker>Wolfe, Barto, 2005</marker>
<rawString>Alicia P. Wolfe and Andrew G. Barto. 2005. Identifying useful subgoals in reinforcement learning by local graph partitioning. In In Proceedings of the TwentySecond International Conference on Machine Learning, pages 816–823.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chen Yu</author>
<author>Dana H Ballard</author>
</authors>
<title>On the integration of grounding language and learning objects.</title>
<date>2004</date>
<booktitle>In Proceedings of AAAI,</booktitle>
<pages>488--493</pages>
<contexts>
<context position="8026" citStr="Yu and Ballard, 2004" startWordPosition="1269" endWordPosition="1272">and Girju, 2009; Do et al., 2011). Similar to these methods, our algorithm capitalizes on surface linguistic cues to learn preconditions from text. However, our only source of supervision is the feedback provided by the planning task which utilizes the predictions. Additionally, we not only identify these relations in text, but also show they are valuable in performing an external task. Learning Semantics via Language Grounding Our work fits into the broad area of grounded language acquisition, where the goal is to learn linguistic analysis from a situated context (Oates, 2001; Siskind, 2001; Yu and Ballard, 2004; Fleischman and Roy, 2005; Mooney, 2008a; Mooney, 2008b; Branavan et al., 2009; Liang et al., 2009; Vogel and Jurafsky, 2010). Within this line of work, we are most closely related to the reinforcement learning approaches that learn language by interacting with an external environment (Branavan et al., 2009; Branavan et al., 2010; Vogel and Jurafsky, 2010; Branavan et al., 2011). 4The state-of-the-art baseline used in the 2008 International Planning Competition. http://ipc.informatik.uni-freiburg.de/ 127 Text (input): A pickaxe, which is used to harvest stone, can be made from wood. Precondit</context>
</contexts>
<marker>Yu, Ballard, 2004</marker>
<rawString>Chen Yu and Dana H. Ballard. 2004. On the integration of grounding language and learning objects. In Proceedings of AAAI, pages 488–493.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>