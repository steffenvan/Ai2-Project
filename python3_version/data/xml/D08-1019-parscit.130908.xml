<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000026">
<note confidence="0.6494256">
Sentence Fusion via Dependency Graph Compression
Katja Filippova and Michael Strube
EML Research gGmbH
Schloss-Wolfsbrunnenweg 33
69118 Heidelberg, Germany
</note>
<bodyText confidence="0.963179592592593">
http://www.eml-research.de/nlp
not yet available (see e.g. Hovy (2003, p.589)). Sen-
tence fusion (Barzilay &amp; McKeown, 2005), where a
new sentence is generated from a group of related
sentences and where complete semantic and con-
ceptual representation is not required, can be seen
as a middle-ground between extractive and abstrac-
tive summarization. Our work regards a corpus of
biographies in German where multiple documents
about the same person should be merged into a sin-
gle one. An example of a fused sentence (3) with the
source sentences (1,2) is given below:
Kopenhagen
Copenhagen
Abstract
We present a novel unsupervised sentence fu-
sion method which we apply to a corpus of bi-
ographies in German. Given a group of related
sentences, we align their dependency trees and
build a dependency graph. Using integer lin-
ear programming we compress this graph to
a new tree, which we then linearize. We use
GermaNet and Wikipedia for checking seman-
tic compatibility of co-arguments. In an eval-
uation with human judges our method out-
performs the fusion approach of Barzilay &amp;
McKeown (2005) with respect to readability.
</bodyText>
<figure confidence="0.964390583333333">
(1) Bohr
Bohr
studierte
studied
Universit¨at
University
an
at
der
the
1 Introduction und erlangte dort seine Doktorw¨urde.
and got there his PhD
</figure>
<bodyText confidence="0.968446828571429">
Automatic text summarization is a rapidly develop-
ing field in computational linguistics. Summariza-
tion systems can be classified as either extractive or
abstractive ones (Sp¨arck Jones, 1999). To date, most
systems are extractive: sentences are selected from
one or several documents and then ordered. This
method exhibits problems, because input sentences
very often overlap and complement each other at the
same time. As a result there is a trade-off between
non-redundancy and completeness of the output. Al-
though the need for abstractive approaches has been
recognized before (e.g. McKeown et al. (1999)), so
far almost all attempts to get closer to abstractive
summarization using scalable, statistical techniques
have been limited to sentence compression.
The main reason why there is little progress on ab-
stractive summarization is that this task seems to re-
quire a conceptual representation of the text which is
’Bohr studied at the University of Copenhagen
and got his PhD there’
Physik
physics
Kopenhagen.
Copenhagen
’After school he studied physics and mathemat-
ics at the University of Copenhagen’
Physik
physics
Kopenhagen
Copenhagen
Doktorw¨urde.
PhD
’After school Bohr studied physics and mathe-
matics at the University of Copenhagen and got
his PhD there’
</bodyText>
<figure confidence="0.987848740740741">
(2) Nach dem
After the
Abitur
school
studierte er
studied he
und
and
Mathematik an der Universit¨at
mathematics at the University
(3) Nach dem
After the
Abitur
school
studierte Bohr
studied Bohr
und
and
Mathematik an der Universit¨at
mathematics at the University
und erlangte
and got
dort
there
seine
his
177
</figure>
<note confidence="0.9790555">
Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 177–185,
Honolulu, October 2008.c�2008 Association for Computational Linguistics
</note>
<bodyText confidence="0.999149236842106">
Having both (1) and (2) in a summary would make
it redundant. Selecting only one of them would not
give all the information from the input. (3), fused
from both (1) and (2), conveys the necessary infor-
mation without being redundant and is more appro-
priate for a summary.
To this end, we present a novel sentence fusion
method based on dependency structure alignment
and semantically and syntactically informed phrase
aggregation and pruning. We address the problem in
an unsupervised manner and use integer linear pro-
gramming (ILP) to find a globally optimal solution.
We argue that our method has three important advan-
tages compared to existing methods. First, we ad-
dress the grammaticality issue empirically by means
of knowledge obtained from an automatically parsed
corpus. We do not require such resources as subcat-
egorization lexicons or hand-crafted rules, but de-
cide to retain a dependency based on its syntactic
importance score. The second point concerns inte-
grating semantics. Being definitely important, ”this
source of information remains relatively unused in
work on aggregation1 within NLG” (Reiter &amp; Dale,
2000, p.141). To our knowledge, in the text-to-text
generation field, we are the first to use semantic in-
formation not only for alignment but also for aggre-
gation in that we check coarguments’ compatibility.
Apart from that, our method is not limited to sen-
tence fusion and can be easily applied to sentence
compression. In Filippova &amp; Strube (2008) we com-
press English sentences with the same approach and
achieve state-of-the-art performance.
The paper is organized as follows: Section 2 gives
an overview of related work and Section 3 presents
our data. Section 4 introduces our method and Sec-
tion 5 describes the experiments and discusses the
results of the evaluation. The conclusions follow in
the final section.
</bodyText>
<sectionHeader confidence="0.999346" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.997302479166667">
Most studies on text-to-text generation concern sen-
tence compression where the input consists of ex-
actly one sentence (Jing, 2001; Hori &amp; Furui, 2004;
Clarke &amp; Lapata, 2008, inter alia). In such set-
ting, redundancy, incompleteness and compatibility
1We follow Barzilay &amp; McKeown (2005) and refer to aggre-
gation within text-to-text generation as sentence fusion.
issues do not arise. Apart from that, there is no
obvious way of how existing sentence compression
methods can be adapted to sentence fusion.
Barzilay &amp; McKeown (2005) present a sentence
fusion method for multi-document news summariza-
tion which crucially relies on the assumption that in-
formation appearing in many sources is important.
Consequently, their method produces an intersec-
tion of input sentences by, first, finding the centroid
of the input, second, augmenting it with informa-
tion from other sentences and, finally, pruning a pre-
defined set of constituents (e.g. PPs). The resulting
structure is not necessarily a tree and allows for ex-
traction of several trees, each of which can be lin-
earized in many ways.
Marsi &amp; Krahmer (2005) extend the approach of
Barzilay &amp; McKeown to do not only intersection
but also union fusion. Like Barzilay &amp; McKeown
(2005), they find the best linearization with a lan-
guage model which, as they point out, often pro-
duces inadequate rankings being unable to deal with
word order, agreement and subcategorization con-
straints. In our work we aim at producing a valid
dependency tree structure so that most grammatical-
ity issues are resolved before the linearization stage.
Wan et al. (2007) introduce a global revision
method of how a novel sentence can be generated
from a set of input words. They formulate the prob-
lem as a search for a maximum spanning tree which
is incrementally constructed by connecting words or
phrases with dependency relations. The grammat-
icality issue is addressed by a number of hard con-
straints. As Wan et al. point out, one of the problems
with their method is that the output built up from
dependencies found in a corpus might have a mean-
ing different from the intended one. Since we build
our trees from the input dependencies, this problem
does not arise with our method. Apart from that, in
our opinion, the optimization formulation we adopt
is more appropriate as it allows to integrate many
constraints without complex rescoring rules.
</bodyText>
<sectionHeader confidence="0.995237" genericHeader="method">
3 Data
</sectionHeader>
<bodyText confidence="0.999728">
The comparable corpus we work with is a collection
of about 400 biographies in German gathered from
</bodyText>
<page confidence="0.856471">
178
</page>
<bodyText confidence="0.999900764705882">
the Internet2. These biographies describe 140 differ-
ent people, and the number of articles for one person
ranges from 2 to 4, being 3 on average. Despite ob-
vious similarities between articles about one person,
neither identical content nor identical ordering of in-
formation can be expected.
Fully automatic preprocessing in our system com-
prises the following steps: sentence boundaries are
identified with a Perl CPAN module3. Then the
sentences are split into tokens and the TnT tagger
(Brants, 2000) and the TreeTagger (Schmid, 1997)
are used for tagging and lemmatization respectively.
Finally, the biographies are parsed with the CDG de-
pendency parser (Foth &amp; Menzel, 2006). We also
identify references to the biographee (pronominal as
well as proper names) and temporal expressions (ab-
solute and relative) with a few rules.
</bodyText>
<sectionHeader confidence="0.991453" genericHeader="method">
4 Our Method
</sectionHeader>
<bodyText confidence="0.999571625">
Groups of related sentences serve as input to a sen-
tence fusion system and thus need to be identified
first (4.1). Then the dependency trees of the sen-
tences are modified (4.2) and aligned (4.3). Syntac-
tic importance (4.4) and word informativeness (4.5)
scores are used to extract a new dependency tree
from a graph of aligned trees (4.6). Finally, the tree
is linearized (4.7).
</bodyText>
<subsectionHeader confidence="0.998034">
4.1 Sentence Alignment
</subsectionHeader>
<bodyText confidence="0.920977272727273">
Sentence alignment for comparable corpora requires
methods different from those used in machine trans-
lation for parallel corpora. For example, given two
biographies of a person, one of them may follow the
timeline from birth to death whereas the other may
group events thematically or tell only about the sci-
entific contribution of the person. Thus one can-
not assume that the sentence order or the content
is the same in two biographies. Shallow methods
like word or bigram overlap, (weighted) cosine or
Jaccard similarity are appealing as they are cheap
and robust. In particular, Nelken &amp; Schieber (2006)
2http://de.wikipedia.org, http://home.
datacomm.ch/biografien, http://biographie.
net/de, http://www.weltchronik.de/ws/bio/
main.htm, http://www.brockhaus-suche.de/
suche
3http://search.cpan.org/-holsten/
Lingua-DE-Sentence-0.07/Sentence.pm
demonstrate the efficacy of a sentence-based tf*idf
score when applied to comparable corpora. Follow-
ing them, we define the similarity of two sentences
</bodyText>
<equation confidence="0.893431">
sim(s1, s2) as
Et wS1(t) · wS2(t) (1)
t w2S1(t) Et w2S2(t)
</equation>
<bodyText confidence="0.9275845">
where S is the set of all lemmas but stop-words from
s, and wS(t) is the weight of the term t:
</bodyText>
<equation confidence="0.9724965">
wS(t) = S(t) 1 (2)
Nt
</equation>
<bodyText confidence="0.999970909090909">
where S(t) is the indicator function of S, Nt is the
number of sentences in the biographies of one per-
son which contain t. We enhance the similarity mea-
sure by looking up synonymy in GermaNet (Lem-
nitzer &amp; Kunze, 2002).
We discard identical or nearly identical sen-
tences (sim(s1, s2) &gt; 0.8) and greedily build
sentence clusters using a hierarchical groupwise-
average technique. As a result, one sentence may
belong to one cluster at most. These sentence clus-
ters serve as input to the fusion algorithm.
</bodyText>
<subsectionHeader confidence="0.992913">
4.2 Dependency Tree Modification
</subsectionHeader>
<bodyText confidence="0.9998042">
We apply a set of transformations to a dependency
tree to emphasize its important properties and elim-
inate unimportant ones. These transformations are
necessary for the compression stage. An example of
a dependency tree and its modifed version are given
in Fig. 1.
PREP preposition nodes (an, in) are removed and
placed as labels on the edges to the respective
nouns;
CONJ a chain of conjuncts (Mathematik und
Physik) is split and each node is attached to the
parent node (studierte) provided they are not
verbs;
APP a chain of words analyzed as appositions by
CDG (Niels Bohr) is collapsed into one node;
FUNC function words like determiners (der), aux-
iliary verbs or negative particles are removed
from the tree and memorized with their lexical
heads (memorizing negative particles preserves
negation in the output);
</bodyText>
<figure confidence="0.9878893125">
S1 · S2
|S1|· |S2|
179
studierte
subj obja pp
Mathematik
pp
an in
pn
kon
und
Physik
pn
Uni
det
der
Bohr
cj
Kopenhagen
root
s
studierte
Mathematik
Kopenhagen
subj
in
obja
bio
an
obja
Physik Uni
(a) Dependency tree (b) Modified tree
</figure>
<figureCaption confidence="0.989154">
Figure 1: The dependency tree of the sentence Bohr studierte Mathematik und Physik an der Uni in Kopenhagen
(Bohr studied mathematics and physics at university in Copenhagen) as produced by the parser (a) and after all
transformations applied (b)
</figureCaption>
<bodyText confidence="0.99722">
ROOT every dependency tree gets an explicit root
which is connected to every verb node;
BIO all occurrences of the biographee (Niels Bohr)
are replaced with the bio tag.
</bodyText>
<subsectionHeader confidence="0.996956">
4.3 Node Alignment
</subsectionHeader>
<bodyText confidence="0.99986">
Once we have a group of two to four strongly related
sentences and their transformed dependency trees,
we aim at finding the best node alignment. We use
a simple, fast and transparent method and align any
two words provided that they
</bodyText>
<listItem confidence="0.998915">
1. are content words;
2. have the same part-of-speech;
3. have identical lemmas or are synonyms.
</listItem>
<bodyText confidence="0.999896235294118">
In case of multiple possibilities, which are extremely
rare in our data, the choice is made randomly. By
merging all aligned nodes we get a dependency
graph which consists of all dependencies from the
input trees. In case it contains a cycle, one of the
alignments from the cycle is eliminated.
We prefer this very simple method to bottom-up
ones (Barzilay &amp; McKeown, 2005; Marsi &amp; Krah-
mer, 2005) for two main reasons. Pursuing local
subtree alignments, bottom-up methods may leave
identical words unaligned and thus prohibit fusion
of complementary information. On the other hand,
they may force alignment of two unrelated words if
the subtrees they root are largely aligned. Although
in some cases it helps discover paraphrases, it con-
siderably increases chances of generating ungram-
matical output which we want to avoid at any cost.
</bodyText>
<subsectionHeader confidence="0.99036">
4.4 Syntactic Importance Score
</subsectionHeader>
<bodyText confidence="0.999930333333333">
Given a dependency graph we want to get a new de-
pendency tree from it. Intuitively, we want to re-
tain obligatory dependencies (e.g. subject) while re-
moving less important ones (e.g. adv). When de-
ciding on pruning an argument, previous approaches
either used a set of hand-crafted rules (e.g. Barzilay
&amp; McKeown (2005)), or utilized a subcategorization
lexicon (e.g. Jing (2001)). The hand-crafted rules
are often too general to ensure a grammatical argu-
ment structure for different verbs (e.g. PPs can be
pruned). Subcategorization lexicons are not readily
available for many languages and cover only verbs.
E.g. they do not tell that the noun son is very of-
ten modified by a PP using the preposition of, as in
the son of Niels Bohr, and that the NP without a PP
modifier may appear incomplete.
To overcome these problems, we decide on prun-
ing an edge by estimating the conditional proba-
bility of its label given its head, P(l|h)4. For ex-
ample, P(subj|studieren) – the probability of the
label subject given the verb study – is higher than
P(inlstudieren), and therefore the subject will be
preserved whereas the prepositional label and thus
the whole PP can be pruned, if needed. Table 1
presents the probabilities of several labels given that
the head is studieren and shows that some preposi-
tions are more important than other ones. Note that
if we did not apply the PREP modification we would
be unable to distinguish between different prepo-
sitions and could only calculate P(pplstudieren)
</bodyText>
<footnote confidence="0.666564">
4The probabilities are calculated from a corpus of approx.
3,000 biographies from Wikipedia which we annotated auto-
matically as described in Section 3.
</footnote>
<page confidence="0.572416">
180
</page>
<bodyText confidence="0.516633333333333">
which would not be very informative.
in an
0.44 0.42
</bodyText>
<tableCaption confidence="0.996405">
Table 1: Probabilities of subj, obja(ccusative), in, at, af-
ter, with, to given the verb studieren (study)
</tableCaption>
<subsectionHeader confidence="0.920121">
4.5 Word Informativeness Score
</subsectionHeader>
<bodyText confidence="0.996806333333333">
We also want to retain informative words in the out-
put tree. There are many ways in which word im-
portance can be defined. Here, we use a formula
introduced by Clarke &amp; Lapata (2008) which is a
modification of the significance score of Hori &amp; Fu-
rui (2004):
</bodyText>
<equation confidence="0.973274">
l FA
I(wi) = N · fi log (3)
Fi
</equation>
<bodyText confidence="0.99994">
wi is the topic word (either noun or verb), fi is the
frequency of wi in the aligned biographies, Fi is the
frequency of wi in the corpus, and FA is the sum
of frequencies of all topic words in the corpus. l is
the number of clause nodes above w and N is the
maximum level of embedding of the sentence which
w belongs to. By defining word importance differ-
ently, e.g. as relatedness of a word to the topic, we
could apply our method to topic-based summariza-
tion (Krahmer et al., 2008).
</bodyText>
<subsectionHeader confidence="0.985873">
4.6 New Sentence Generation
</subsectionHeader>
<bodyText confidence="0.94676">
We formulate the task of getting a tree from a depen-
dency graph as an optimization problem and solve
it with ILP5. In order to decide which edges of the
graph to remove, for each directed dependency edge
from head h to word w we introduce a binary vari-
able xlh,w, where l stands for the label of the edge:
(
</bodyText>
<equation confidence="0.985357">
l = 1 if the dependency is preserved
xh,w (4)
0 otherwise
</equation>
<bodyText confidence="0.981656266666667">
The goal is to find a subtree of the graph which
gets the highest score of the objective function (5) to
which both the probability of dependencies (P(l|h) )
and the importance of dependent words (I(w)) con-
tribute:
5We use lp solve in our implementation http://
sourceforge.net/projects/lpsolve.
The objective function is subject to four types of
constraints presented below (W stands for the set of
graph nodes minus root, i.e. the set of words).
STRUCTURAL constraints allow to get a tree from
the graph: (6) ensures that each word has one head
at most. (7) ensures connectivity in the tree. (8) is
optional and restricts the size of the resulting tree to
α words (α = min(0.6 · |W |,10)).
</bodyText>
<equation confidence="0.9880645">
∀w ∈ W, X xlh,w ≤ 1 (6)
h,l
Xxlh,w ≤ α (8)
x
</equation>
<bodyText confidence="0.999784">
SYNTACTIC constraints ensure the syntactic validity
of the output tree and explicitly state which argu-
ments should be preserved. We have only one syn-
tactic constraint which guarantees that a subordinat-
ing conjunction (sc) is preserved (9) if and only if the
clause it belongs to serves as a subordinate clause
(sub) in the output.
</bodyText>
<equation confidence="0.936432666666667">
∀xsc
w,u, X xsub h,w − xsc w,u = 0 (9)
h,l
</equation>
<bodyText confidence="0.9998044375">
SEMANTIC constraints restrict coordination to se-
mantically compatible elements. The idea behind
these constraints is the following (see Fig. 2). It
can be that one sentence says He studied math and
another one He studied physics, so the output may
unite the two words under coordination: He studied
math and physics. But if the input sentences are He
studied physics and He studied sciences, then one
should not unite both, because sciences is the gen-
eralization of physics. Neither should one unite two
unrelated words: He studied with pleasure and He
studied with Bohr cannot be fused into He studied
with pleasure and Bohr.
To formalize these intuitions we define two func-
tions hm(w,u) and rel(w,u): hm(w,u) is a binary func-
tion, whereas rel(w,u) returns a value from [0, 1]. We
</bodyText>
<figure confidence="0.997629764705882">
subj
obja
nach
mit
0.88
0.74
0.09
0.02
0.01
X X xlw,u ≥ 0 (7)
∀w ∈ W, l 1
h,l xh w −
|W |u,l
X xlh,w · P(l|h) · I(w) (5)
f(X) =
zu x
181
</figure>
<figureCaption confidence="0.953005">
Figure 2: Graph obtained from sentences He studied sci-
ences with pleasure and He studied math and physics with
Bohr
</figureCaption>
<bodyText confidence="0.9944825">
also introduce additional variables ylw,u (represented
by dashed lines in Fig. 2):
</bodyText>
<equation confidence="0.9885995">
l—�1 if 1h,l : xlhw = 1 ∧ xlh
yw,u u = 1
— (10)
0 otherwise
</equation>
<bodyText confidence="0.999720076923077">
For two edges sharing a head and having identical
labels to be retained we check in GermaNet and
in the taxonomy derived from Wikipedia (Kassner
et al., 2008) that their dependents are not in the
hyponymy or meronymy relation (11). We prohibit
verb coordination unless it is found in one of the
input sentences. If the dependents are nouns, we
also check that their semantic relatedness as mea-
sured with WikiRelate! (Strube &amp; Ponzetto, 2006)
is above a certain threshold (12). We empirically
determined the value of Q = 0.36 by calculating an
average similarity of coordinated nouns in the cor-
pus.
</bodyText>
<equation confidence="0.9970485">
bylw,u, hm(w, u) - ylw,u = 0 (11)
bylw,u, (rel(w, u) − 0) - ylw,u &gt; 0 (12)
</equation>
<listItem confidence="0.997395625">
(11) prohibits thatphysics (or math) and sciences ap-
pear together since, according to GermaNet, physics
(Physik) is a hyponym of science (Wissenschaft).
(12) blocks taking both pleasure (Freude) and Bohr
because rel(Freude,Bohr) = 0.17. math and physics
are neither in ISA, nor part-of relation and are suffi-
ciently related (rel(Mathematik, Physik) = 0.67) to
become conjuncts.
</listItem>
<bodyText confidence="0.9990945">
META constraints (equations (13) and (14)) guar-
antee that ylw,u = xlh,w x xlh,u i.e. they ensure that
the semantic constraints are applied only if both the
labels from h to w and from h to u are preserved.
</bodyText>
<equation confidence="0.988639333333333">
bylw,u,xlh,w + xlh,u &gt; 2yl (13)
w,u
bylw,u,1 − xlh,w + 1 − xlh,u &gt; 1 − ylw,u (14)
</equation>
<subsectionHeader confidence="0.917827">
4.7 Linearization
</subsectionHeader>
<bodyText confidence="0.999983473684211">
The “overgenerate-and-rank” approach to statisti-
cal surface realization is very common (Langk-
ilde &amp; Knight, 1998). Unfortunately, in its sim-
plest and most popular version, it ignores syntac-
tical constraints and may produce ungrammatical
output. For example, an inviolable rule of Ger-
man grammar states that the finite verb must be in
the second position in the main clause. Since it is
hard to enforce such rules with an ngram language
model, syntax-informed linearization methods have
been developed for German (Ringger et al., 2004;
Filippova &amp; Strube, 2007). We apply our recent
method to order constituents and, using the CMU
toolkit (Clarkson &amp; Rosenfeld, 1997), build a tri-
gram language model from Wikipedia (approx. 1GB
plain text) to find the best word order within con-
stituents. Some constraints on word order are in-
ferred from the input. Only interclause punctuation
is generated.
</bodyText>
<sectionHeader confidence="0.977573" genericHeader="evaluation">
5 Experiments and Evaluation
</sectionHeader>
<bodyText confidence="0.9999795">
We choose Barzilay &amp; McKeown’s system as a non-
trivial baseline since, to our knowledge, there is no
other system which outperforms theirs (Sec. 5.1). It
is important for us to evaluate the fusion part of our
system, so the input and the linearization module of
our method and the baseline are identical. We are
also interested in how many errors are due to the lin-
earization module and thus define the readability up-
per bound (Sec. 5.2). We further present and discuss
the experiments (Sec. 5.3 and 5.5).
</bodyText>
<subsectionHeader confidence="0.979155">
5.1 Baseline
</subsectionHeader>
<bodyText confidence="0.999865857142857">
The algorithm of Barzilay &amp; McKeown (2005) pro-
ceeds as follows: Given a group of related sentences,
a dependency tree is built for each sentence. These
trees are modified so that grammatical features are
eliminated from the representation and memorized;
noun phrases are flattened to facilitate alignment.
A locally optimal pairwise alignment of modified
</bodyText>
<figure confidence="0.9766764375">
math
physics
Bohr
bio
pleasure
root
s
studied
with
subj
with
obja
obja
sciences
obja
182
</figure>
<bodyText confidence="0.999695875">
dependency trees is recursively found with Word-
Net and a paraphrase lexicon. From the alignment
costs the centroid of the group is identified. Then
this tree is augmented with information from other
trees given that it appears in at least half of the sen-
tences from this group. A rule-based pruning mod-
ule prunes optional constituents, such as PPs or rel-
ative clauses. The linearization of the resulting tree
(or graph) is done with a trigram language model.
To adapt this system to German, we use the Ger-
maNet API (Gurevych &amp; Niederlich, 2005) instead
of WordNet. We do not use a paraphrase lexicon,
because there is no comparable corpus of sufficient
size available for German. We readjust the align-
ment parameters of the system to prevent dissimi-
lar nodes from being aligned. The input to the al-
gorithm is generated as described in Sec. 4.1. The
linearization is done as described in Sec. 4.7. In
cases when there is a graph to linearize, all possible
trees covering the maximum number of nodes are
extracted from it and linearized. The most probable
string is selected as the final output with a language
model. For the rest of the reimplementation we fol-
low the algorithm as presented.
</bodyText>
<subsectionHeader confidence="0.999753">
5.2 Readability Upper Bound
</subsectionHeader>
<bodyText confidence="0.999994166666667">
To find the upper bound on readability, we select one
sentence from the input randomly, parse it and lin-
earize the dependency tree as described in Sec. 4.7.
This way we obtain a sentence which may differ in
form from the input sentences but whose content is
identical to one of them.
</bodyText>
<subsectionHeader confidence="0.98079">
5.3 Experiments
</subsectionHeader>
<bodyText confidence="0.99982125">
It is notoriously difficult to evaluate generation and
summarization systems as there are many dimen-
sions in which the quality of the output can be as-
sessed. The goal of our present evaluation is in the
first place to check whether our method is able to
produce sensible output.
We evaluated the three systems (GRAPH-
COMPRESSION, BARZILAY &amp; MCKEOWN and
READABILITY UB) with 50 native German speakers
on 120 fused sentences generated from 40 randomly
drawn related sentences groups (3 x 40). In an
online experiment, the participants were asked to
read a fused sentence preceded by the input and
to rate its readability (read) and informativity in
respect to the input (inf) on a five point scale. The
experiment was designed so that every participant
rated 40 sentences in total. No participant saw
two sentences generated from the same input. The
results are presented in Table 2. len is an average
length in words of the output.
</bodyText>
<table confidence="0.99658875">
read inf len
READABILITY UB 4.0 3.5 12.9
BARZILAY &amp; MCKEOWN 3.1 3.0 15.5
GRAPH-COMPRESSION 3.7 3.1 13.0
</table>
<tableCaption confidence="0.9862085">
Table 2: Average readability and informativity on a five
point scale, average length in words
</tableCaption>
<subsectionHeader confidence="0.960862">
5.4 Error Analysis
</subsectionHeader>
<bodyText confidence="0.999930580645161">
The main disadvantage of our method, as well as
other methods designed to work on syntactic struc-
tures, is that it requires a very accurate parser. In
some cases, errors in the preprocessing made ex-
tracting a valid dependency tree impossible. The
poor rating of READABILITY UB also shows that er-
rors of the parser and of the linearization module af-
fect the output considerably.
Although the semantic constraints ruled out
many anomalous combinations, the limited cover-
age of GermaNet and the taxonomy derived from
Wikipedia was the reason for some semantic oddi-
ties in the sentences generated by our method. For
example, it generated phrases like aus England und
Großbritannien (from England and Great Britain).
A larger taxonomy would presumably increase the
recall of the semantic constraints which proved help-
ful. Such errors were not observed in the output of
the baseline because it does not fuse within NPs.
Both the baseline and our method made subcate-
gorization errors, although these are more common
for the baseline which aligns not only synonyms
but also verbs which share some arguments. Also,
the baseline pruned some PPs necessary for a sen-
tence to be complete. For example, it pruned an
der Atombombe (on the atom bomb) and generated
an incomplete sentence Er arbeitete (He worked).
For the baseline, alignment of flattened NPs instead
of words caused generating very wordy and redun-
dant sentences when the input parse trees were in-
correct. In other cases, our method made mistakes
</bodyText>
<page confidence="0.855018">
183
</page>
<bodyText confidence="0.9998758">
in linearizing constituents because it had to rely on a
language model whereas the baseline used unmod-
ified constituents from the input. Absense of intra-
clause commas caused a drop in readability in some
otherwise grammatical sentences.
</bodyText>
<subsectionHeader confidence="0.654876">
5.5 Discussion
</subsectionHeader>
<bodyText confidence="0.999994263157895">
A paired t-test revealed significant differences be-
tween the readability ratings of the three systems
(p = 0.01) but found no significant differences be-
tween the informativity scores of our system and the
baseline. Some participants reported informativity
hard to estimate and to be assessable for grammat-
ical sentences only. The higher readability rating
of our method supports our claim that the method
based on syntactic importance score and global con-
straints generates more grammatical sentences than
existing systems. An important advantage of our
method is that it addresses the subcategorization is-
sue directly without shifting the burden of selecting
the right arguments to the linearization module. The
dependency structure it outputs is a tree and not a
graph as it may happen with the method of Barzi-
lay &amp; McKeown (2005). Moreover, our method can
distinguish between more and less obligatory argu-
ments. For example, it knows that at is more impor-
tant than to for study whereas for go it is the other
way round. Unlike our differentiated approach, the
baseline rule states that PPs can generally be pruned.
Since the baseline generates a new sentence by
modifying the tree of an input sentence, in some
cases it outputs a compression of this sentence. Un-
like this, our method is not based on an input tree
and generates a new sentence without being biased
to any of the input sentences.
Our method can also be applied to non-trivial sen-
tence compression, whereas the baseline and similar
methods, such as Marsi &amp; Krahmer (2005), would
then boil down to a few very general pruning rules.
We tested our method on the English compression
corpus6 and evaluated the compressions automati-
cally the same way as Clarke &amp; Lapata (2008) did.
The results (Filippova &amp; Strube, 2008) were as good
as or significantly better than the state-of-the-art, de-
pending on the choice of dependency parser.
</bodyText>
<footnote confidence="0.9031995">
6The corpus is available from http://homepages.
inf.ed.ac.uk/s0460084/data.
</footnote>
<sectionHeader confidence="0.997006" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999984833333333">
We presented a novel sentence fusion method which
formulates the fusion task as an optimization prob-
lem. It is unsupervised and finds a globally optimal
solution taking semantics, syntax and word informa-
tiveness into account. The method does not require
hand-crafted rules or lexicons to generate grammat-
ical output but relies on the syntactic importance
score calculated from an automatically parsed cor-
pus. An experiment with native speakers demon-
strated that our method generates more grammatical
sentences than existing systems.
There are several directions to explore in the fu-
ture. Recently query-based sentence fusion has been
shown to be a better defined task than generic sen-
tence fusion (Krahmer et al., 2008). By modify-
ing the word informativeness score, e.g. by giving
higher scores to words semantically related to the
query, one could force our system to retain words
relevant to the query in the output. To generate co-
herent texts we plan to move beyond sentence gen-
eration and add discourse constraints to our system.
Acknowledgements: This work has been funded
by the Klaus Tschira Foundation, Heidelberg, Ger-
many. The first author has been supported by a KTF
grant (09.009.2004). Part of the data has been used
with a permission of Bibliographisches Institut &amp; F.
A. Brockhaus AG, Mannheim, Germany. We would
like to thank the participants in our online evalua-
tion. We are also grateful to Regina Barzilay and the
three reviewers for their helpful comments.
</bodyText>
<sectionHeader confidence="0.989931" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998987266666667">
Barzilay, Regina &amp; Kathleen R. McKeown (2005). Sen-
tence fusion for multidocument news summarization.
Computational Linguistics, 31(3):297–327.
Brants, Thorsten (2000). TnT – A statistical Part-of-
Speech tagger. In Proceedings of the 6th Confer-
ence on Applied Natural Language Processing, Seat-
tle, Wash., 29 April – 4 May 2000, pp. 224–231.
Clarke, James &amp; Mirella Lapata (2008). Global inference
for sentence compression: An integer linear program-
ming approach. Journal of Artificial Intelligence Re-
search, 31:399–429.
Clarkson, Philip &amp; Ronald Rosenfeld (1997). Statis-
tical language modeling using the CMU-Cambridge
toolkit. In Proceedings of the 5th European Con-
ference on Speech Communication and Technology,
</reference>
<page confidence="0.662877">
184
</page>
<reference confidence="0.999027161904762">
Rhodes, Greece, 22-25 September 1997, pp. 2707–
2710.
Filippova, Katja &amp; Michael Strube (2007). Generating
constituent order in German clauses. In Proceedings of
the 45th Annual Meeting of the Association for Com-
putational Linguistics, Prague, Czech Republic, 23–30
June 2007, pp. 320–327.
Filippova, Katja &amp; Michael Strube (2008). Dependency
tree based sentence compression. In Proceedings of
the 5th International Conference on Natural Language
Generation, Salt Fork, Ohio, 12–14 June 2008, pp. 25–
32.
Foth, Kilian &amp; Wolfgang Menzel (2006). Hybrid pars-
ing: Using probabilistic models as predictors for a
symbolic parser. In Proceedings of the 21st Interna-
tional Conference on Computational Linguistics and
44th Annual Meeting of the Association for Computa-
tional Linguistics, Sydney, Australia, 17–21 July 2006,
pp. 321–327.
Gurevych, Iryna &amp; Hendrik Niederlich (2005). Access-
ing GermaNet data and computing semantic related-
ness. In Companion Volume to the Proceedings of the
43rd Annual Meeting of the Association for Compu-
tational Linguistics, Ann Arbor, Mich., 25–30 June
2005, pp. 5–8.
Hori, Chiori &amp; Sadaoki Furui (2004). Speech summa-
rization: An approach through word extraction and a
method for evaluation. IEEE Transactions on Infor-
mation and Systems, E87-D(1):15–25.
Hovy, Eduard (2003). Text summarization. In Ruslan
Mitkov (Ed.), The Oxford Handbook of Computational
Linguistics, pp. 583–598. Oxford, U.K.: Oxford Uni-
versity Press.
Jing, Hongyan (2001). Cut-and-Paste Text Summariza-
tion, (Ph.D. thesis). Computer Science Department,
Columbia University, New York, N.Y.
Kassner, Laura, Vivi Nastase &amp; Michael Strube (2008).
Acquiring a taxonomy from the German Wikipedia.
In Proceedings of the 6th International Conference on
Language Resources and Evaluation, Marrakech, Mo-
rocco, 26 May – 1 June 2008.
Krahmer, Emiel, Erwin Marsi &amp; Paul van Pelt (2008).
Query-based sentence fusion is better defined and
leads to more preferred results than generic sentence
fusion. In Companion Volume to the Proceedings of
the 46th Annual Meeting of the Association for Com-
putational Linguistics, Columbus, Ohio, 15–20 June
2008, pp. 193–196.
Langkilde, Irene &amp; Kevin Knight (1998). Generation
that exploits corpus-based statistical knowledge. In
Proceedings of the 17th International Conference on
Computational Linguistics and 36th Annual Meet-
ing of the Association for Computational Linguistics,
Montr´eal, Qu´ebec, Canada, 10–14 August 1998, pp.
704–710.
Lemnitzer, Lothar &amp; Claudia Kunze (2002). GermaNet
– representation, visualization, application. In Pro-
ceedings of the 3rd International Conference on Lan-
guage Resources and Evaluation, Las Palmas, Canary
Islands, Spain, 29–31 May 2002, pp. 1485–1491.
Marsi, Erwin &amp; Emiel Krahmer (2005). Explorations in
sentence fusion. In Proceedings of the European Work-
shop on Natural Language Generation, Aberdeen,
Scotland, 8–10 August, 2005, pp. 109–117.
McKeown, Kathleen R., Judith L. Klavans, Vassileios
Hatzivassiloglou, Regina Barzilay &amp; Eleazar Eskin
(1999). Towards multidocument summarization by re-
formulation: Progress and prospects. In Proceedings
of the 16th National Conference on Artificial Intelli-
gence, Orlando, Flo., 18–22 July 1999, pp. 453–460.
Nelken, Rani &amp; Stuart Schieber (2006). Towards robust
context-sensitive sentence alignment for monolingual
corpora. In Proceedings of the 11th Conference of
the European Chapter of the Association for Compu-
tational Linguistics, Trento, Italy, 3–7 April 2006, pp.
161–168.
Reiter, Ehud &amp; Robert Dale (2000). Building Natu-
ral Language Generation Systems. Cambridge, U.K.:
Cambridge University Press.
Ringger, Eric, Michael Gamon, Robert C. Moore, David
Rojas, Martine Smets &amp; Simon Corston-Oliver (2004).
Linguistically informed statistical models of con-
stituent structure for ordering in sentence realization.
In Proceedings of the 20th International Conference
on Computational Linguistics, Geneva, Switzerland,
23–27 August 2004, pp. 673–679.
Schmid, Helmut (1997). Probabilistic Part-of-Speech
tagging using decision trees. In Daniel Jones &amp; Harold
Somers (Eds.), New Methods in Language Processing,
pp. 154–164. London, U.K.: UCL Press.
Sp¨arck Jones, Karen (1999). Automatic summarizing:
Factors and directions. In Inderjeet Mani &amp; Mark T.
Maybury (Eds.), Advances in Automatic Text Summa-
rization, pp. 1–12. Cambridge, Mass.: MIT Press.
Strube, Michael &amp; Simone Paolo Ponzetto (2006).
WikiRelate! Computing semantic relatedness using
Wikipedia. In Proceedings of the 21st National Con-
ference on Artificial Intelligence, Boston, Mass., 16–
20 July 2006, pp. 1419–1424.
Wan, Stephen, Robert Dale, Mark Dras &amp; Cecile Paris
(2007). Global revision in summarization: Generating
novel sentences with Prim’s algorithm. In Proceedings
of the 10th Conference of the Pacific Association for
Computational Linguistics, Melbourne, Australia, 19–
21 September, 2007, pp. 226–235.
</reference>
<page confidence="0.941693">
185
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.049200">
<title confidence="0.999561">Sentence Fusion via Dependency Graph Compression</title>
<author confidence="0.836833">Filippova</author>
<affiliation confidence="0.827909">EML Research Schloss-Wolfsbrunnenweg</affiliation>
<address confidence="0.998878">69118 Heidelberg, Germany</address>
<web confidence="0.862485">http://www.eml-research.de/nlp</web>
<abstract confidence="0.981316818181818">not yet available (see e.g. Hovy (2003, p.589)). Sentence fusion (Barzilay &amp; McKeown, 2005), where a new sentence is generated from a group of related sentences and where complete semantic and conceptual representation is not required, can be seen as a middle-ground between extractive and abstractive summarization. Our work regards a corpus of biographies in German where multiple documents about the same person should be merged into a single one. An example of a fused sentence (3) with the source sentences (1,2) is given below:</abstract>
<note confidence="0.553797">Kopenhagen Copenhagen</note>
<abstract confidence="0.991027294117647">We present a novel unsupervised sentence fusion method which we apply to a corpus of biographies in German. Given a group of related sentences, we align their dependency trees and build a dependency graph. Using integer linear programming we compress this graph to a new tree, which we then linearize. We use GermaNet and Wikipedia for checking semantic compatibility of co-arguments. In an evaluation with human judges our method outperforms the fusion approach of Barzilay &amp; McKeown (2005) with respect to readability. (1) Bohr Bohr studierte studied</abstract>
<affiliation confidence="0.7841505">Universit¨at University</affiliation>
<abstract confidence="0.886413666666667">an at der</abstract>
<intro confidence="0.573205">the</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Kathleen R McKeown</author>
</authors>
<title>Sentence fusion for multidocument news summarization.</title>
<date>2005</date>
<journal>Computational Linguistics,</journal>
<volume>31</volume>
<issue>3</issue>
<contexts>
<context position="1243" citStr="Barzilay &amp; McKeown (2005)" startWordPosition="192" endWordPosition="195"> into a single one. An example of a fused sentence (3) with the source sentences (1,2) is given below: Kopenhagen Copenhagen Abstract We present a novel unsupervised sentence fusion method which we apply to a corpus of biographies in German. Given a group of related sentences, we align their dependency trees and build a dependency graph. Using integer linear programming we compress this graph to a new tree, which we then linearize. We use GermaNet and Wikipedia for checking semantic compatibility of co-arguments. In an evaluation with human judges our method outperforms the fusion approach of Barzilay &amp; McKeown (2005) with respect to readability. (1) Bohr Bohr studierte studied Universit¨at University an at der the 1 Introduction und erlangte dort seine Doktorw¨urde. and got there his PhD Automatic text summarization is a rapidly developing field in computational linguistics. Summarization systems can be classified as either extractive or abstractive ones (Sp¨arck Jones, 1999). To date, most systems are extractive: sentences are selected from one or several documents and then ordered. This method exhibits problems, because input sentences very often overlap and complement each other at the same time. As a </context>
<context position="5314" citStr="Barzilay &amp; McKeown (2005)" startWordPosition="828" endWordPosition="831">approach and achieve state-of-the-art performance. The paper is organized as follows: Section 2 gives an overview of related work and Section 3 presents our data. Section 4 introduces our method and Section 5 describes the experiments and discusses the results of the evaluation. The conclusions follow in the final section. 2 Related Work Most studies on text-to-text generation concern sentence compression where the input consists of exactly one sentence (Jing, 2001; Hori &amp; Furui, 2004; Clarke &amp; Lapata, 2008, inter alia). In such setting, redundancy, incompleteness and compatibility 1We follow Barzilay &amp; McKeown (2005) and refer to aggregation within text-to-text generation as sentence fusion. issues do not arise. Apart from that, there is no obvious way of how existing sentence compression methods can be adapted to sentence fusion. Barzilay &amp; McKeown (2005) present a sentence fusion method for multi-document news summarization which crucially relies on the assumption that information appearing in many sources is important. Consequently, their method produces an intersection of input sentences by, first, finding the centroid of the input, second, augmenting it with information from other sentences and, fina</context>
<context position="12658" citStr="Barzilay &amp; McKeown, 2005" startWordPosition="2030" endWordPosition="2033">ormed dependency trees, we aim at finding the best node alignment. We use a simple, fast and transparent method and align any two words provided that they 1. are content words; 2. have the same part-of-speech; 3. have identical lemmas or are synonyms. In case of multiple possibilities, which are extremely rare in our data, the choice is made randomly. By merging all aligned nodes we get a dependency graph which consists of all dependencies from the input trees. In case it contains a cycle, one of the alignments from the cycle is eliminated. We prefer this very simple method to bottom-up ones (Barzilay &amp; McKeown, 2005; Marsi &amp; Krahmer, 2005) for two main reasons. Pursuing local subtree alignments, bottom-up methods may leave identical words unaligned and thus prohibit fusion of complementary information. On the other hand, they may force alignment of two unrelated words if the subtrees they root are largely aligned. Although in some cases it helps discover paraphrases, it considerably increases chances of generating ungrammatical output which we want to avoid at any cost. 4.4 Syntactic Importance Score Given a dependency graph we want to get a new dependency tree from it. Intuitively, we want to retain obl</context>
<context position="21286" citStr="Barzilay &amp; McKeown (2005)" startWordPosition="3543" endWordPosition="3546">terclause punctuation is generated. 5 Experiments and Evaluation We choose Barzilay &amp; McKeown’s system as a nontrivial baseline since, to our knowledge, there is no other system which outperforms theirs (Sec. 5.1). It is important for us to evaluate the fusion part of our system, so the input and the linearization module of our method and the baseline are identical. We are also interested in how many errors are due to the linearization module and thus define the readability upper bound (Sec. 5.2). We further present and discuss the experiments (Sec. 5.3 and 5.5). 5.1 Baseline The algorithm of Barzilay &amp; McKeown (2005) proceeds as follows: Given a group of related sentences, a dependency tree is built for each sentence. These trees are modified so that grammatical features are eliminated from the representation and memorized; noun phrases are flattened to facilitate alignment. A locally optimal pairwise alignment of modified math physics Bohr bio pleasure root s studied with subj with obja obja sciences obja 182 dependency trees is recursively found with WordNet and a paraphrase lexicon. From the alignment costs the centroid of the group is identified. Then this tree is augmented with information from other</context>
<context position="26939" citStr="Barzilay &amp; McKeown (2005)" startWordPosition="4482" endWordPosition="4486">seline. Some participants reported informativity hard to estimate and to be assessable for grammatical sentences only. The higher readability rating of our method supports our claim that the method based on syntactic importance score and global constraints generates more grammatical sentences than existing systems. An important advantage of our method is that it addresses the subcategorization issue directly without shifting the burden of selecting the right arguments to the linearization module. The dependency structure it outputs is a tree and not a graph as it may happen with the method of Barzilay &amp; McKeown (2005). Moreover, our method can distinguish between more and less obligatory arguments. For example, it knows that at is more important than to for study whereas for go it is the other way round. Unlike our differentiated approach, the baseline rule states that PPs can generally be pruned. Since the baseline generates a new sentence by modifying the tree of an input sentence, in some cases it outputs a compression of this sentence. Unlike this, our method is not based on an input tree and generates a new sentence without being biased to any of the input sentences. Our method can also be applied to </context>
</contexts>
<marker>Barzilay, McKeown, 2005</marker>
<rawString>Barzilay, Regina &amp; Kathleen R. McKeown (2005). Sentence fusion for multidocument news summarization. Computational Linguistics, 31(3):297–327.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Brants</author>
</authors>
<title>TnT – A statistical Part-ofSpeech tagger.</title>
<date>2000</date>
<booktitle>In Proceedings of the 6th Conference on Applied Natural Language Processing,</booktitle>
<volume>4</volume>
<pages>224--231</pages>
<location>Seattle, Wash.,</location>
<contexts>
<context position="8016" citStr="Brants, 2000" startWordPosition="1277" endWordPosition="1278"> 3 Data The comparable corpus we work with is a collection of about 400 biographies in German gathered from 178 the Internet2. These biographies describe 140 different people, and the number of articles for one person ranges from 2 to 4, being 3 on average. Despite obvious similarities between articles about one person, neither identical content nor identical ordering of information can be expected. Fully automatic preprocessing in our system comprises the following steps: sentence boundaries are identified with a Perl CPAN module3. Then the sentences are split into tokens and the TnT tagger (Brants, 2000) and the TreeTagger (Schmid, 1997) are used for tagging and lemmatization respectively. Finally, the biographies are parsed with the CDG dependency parser (Foth &amp; Menzel, 2006). We also identify references to the biographee (pronominal as well as proper names) and temporal expressions (absolute and relative) with a few rules. 4 Our Method Groups of related sentences serve as input to a sentence fusion system and thus need to be identified first (4.1). Then the dependency trees of the sentences are modified (4.2) and aligned (4.3). Syntactic importance (4.4) and word informativeness (4.5) score</context>
</contexts>
<marker>Brants, 2000</marker>
<rawString>Brants, Thorsten (2000). TnT – A statistical Part-ofSpeech tagger. In Proceedings of the 6th Conference on Applied Natural Language Processing, Seattle, Wash., 29 April – 4 May 2000, pp. 224–231.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Clarke</author>
<author>Mirella Lapata</author>
</authors>
<title>Global inference for sentence compression: An integer linear programming approach.</title>
<date>2008</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<pages>31--399</pages>
<contexts>
<context position="5201" citStr="Clarke &amp; Lapata, 2008" startWordPosition="812" endWordPosition="815">ly applied to sentence compression. In Filippova &amp; Strube (2008) we compress English sentences with the same approach and achieve state-of-the-art performance. The paper is organized as follows: Section 2 gives an overview of related work and Section 3 presents our data. Section 4 introduces our method and Section 5 describes the experiments and discusses the results of the evaluation. The conclusions follow in the final section. 2 Related Work Most studies on text-to-text generation concern sentence compression where the input consists of exactly one sentence (Jing, 2001; Hori &amp; Furui, 2004; Clarke &amp; Lapata, 2008, inter alia). In such setting, redundancy, incompleteness and compatibility 1We follow Barzilay &amp; McKeown (2005) and refer to aggregation within text-to-text generation as sentence fusion. issues do not arise. Apart from that, there is no obvious way of how existing sentence compression methods can be adapted to sentence fusion. Barzilay &amp; McKeown (2005) present a sentence fusion method for multi-document news summarization which crucially relies on the assumption that information appearing in many sources is important. Consequently, their method produces an intersection of input sentences by</context>
<context position="15174" citStr="Clarke &amp; Lapata (2008)" startWordPosition="2449" endWordPosition="2452"> unable to distinguish between different prepositions and could only calculate P(pplstudieren) 4The probabilities are calculated from a corpus of approx. 3,000 biographies from Wikipedia which we annotated automatically as described in Section 3. 180 which would not be very informative. in an 0.44 0.42 Table 1: Probabilities of subj, obja(ccusative), in, at, after, with, to given the verb studieren (study) 4.5 Word Informativeness Score We also want to retain informative words in the output tree. There are many ways in which word importance can be defined. Here, we use a formula introduced by Clarke &amp; Lapata (2008) which is a modification of the significance score of Hori &amp; Furui (2004): l FA I(wi) = N · fi log (3) Fi wi is the topic word (either noun or verb), fi is the frequency of wi in the aligned biographies, Fi is the frequency of wi in the corpus, and FA is the sum of frequencies of all topic words in the corpus. l is the number of clause nodes above w and N is the maximum level of embedding of the sentence which w belongs to. By defining word importance differently, e.g. as relatedness of a word to the topic, we could apply our method to topic-based summarization (Krahmer et al., 2008). 4.6 New </context>
<context position="27844" citStr="Clarke &amp; Lapata (2008)" startWordPosition="4640" endWordPosition="4643">d. Since the baseline generates a new sentence by modifying the tree of an input sentence, in some cases it outputs a compression of this sentence. Unlike this, our method is not based on an input tree and generates a new sentence without being biased to any of the input sentences. Our method can also be applied to non-trivial sentence compression, whereas the baseline and similar methods, such as Marsi &amp; Krahmer (2005), would then boil down to a few very general pruning rules. We tested our method on the English compression corpus6 and evaluated the compressions automatically the same way as Clarke &amp; Lapata (2008) did. The results (Filippova &amp; Strube, 2008) were as good as or significantly better than the state-of-the-art, depending on the choice of dependency parser. 6The corpus is available from http://homepages. inf.ed.ac.uk/s0460084/data. 6 Conclusions We presented a novel sentence fusion method which formulates the fusion task as an optimization problem. It is unsupervised and finds a globally optimal solution taking semantics, syntax and word informativeness into account. The method does not require hand-crafted rules or lexicons to generate grammatical output but relies on the syntactic importan</context>
</contexts>
<marker>Clarke, Lapata, 2008</marker>
<rawString>Clarke, James &amp; Mirella Lapata (2008). Global inference for sentence compression: An integer linear programming approach. Journal of Artificial Intelligence Research, 31:399–429.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Clarkson</author>
<author>Ronald Rosenfeld</author>
</authors>
<title>Statistical language modeling using the CMU-Cambridge toolkit.</title>
<date>1997</date>
<booktitle>In Proceedings of the 5th European Conference on Speech Communication and Technology,</booktitle>
<contexts>
<context position="20472" citStr="Clarkson &amp; Rosenfeld, 1997" startWordPosition="3404" endWordPosition="3407"> statistical surface realization is very common (Langkilde &amp; Knight, 1998). Unfortunately, in its simplest and most popular version, it ignores syntactical constraints and may produce ungrammatical output. For example, an inviolable rule of German grammar states that the finite verb must be in the second position in the main clause. Since it is hard to enforce such rules with an ngram language model, syntax-informed linearization methods have been developed for German (Ringger et al., 2004; Filippova &amp; Strube, 2007). We apply our recent method to order constituents and, using the CMU toolkit (Clarkson &amp; Rosenfeld, 1997), build a trigram language model from Wikipedia (approx. 1GB plain text) to find the best word order within constituents. Some constraints on word order are inferred from the input. Only interclause punctuation is generated. 5 Experiments and Evaluation We choose Barzilay &amp; McKeown’s system as a nontrivial baseline since, to our knowledge, there is no other system which outperforms theirs (Sec. 5.1). It is important for us to evaluate the fusion part of our system, so the input and the linearization module of our method and the baseline are identical. We are also interested in how many errors </context>
</contexts>
<marker>Clarkson, Rosenfeld, 1997</marker>
<rawString>Clarkson, Philip &amp; Ronald Rosenfeld (1997). Statistical language modeling using the CMU-Cambridge toolkit. In Proceedings of the 5th European Conference on Speech Communication and Technology,</rawString>
</citation>
<citation valid="true">
<authors>
<author>Greece Rhodes</author>
</authors>
<date>1997</date>
<pages>2707--2710</pages>
<marker>Rhodes, 1997</marker>
<rawString>Rhodes, Greece, 22-25 September 1997, pp. 2707– 2710.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katja Filippova</author>
<author>Michael Strube</author>
</authors>
<title>Generating constituent order in German clauses.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>320--327</pages>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="20366" citStr="Filippova &amp; Strube, 2007" startWordPosition="3387" endWordPosition="3390"> bylw,u,1 − xlh,w + 1 − xlh,u &gt; 1 − ylw,u (14) 4.7 Linearization The “overgenerate-and-rank” approach to statistical surface realization is very common (Langkilde &amp; Knight, 1998). Unfortunately, in its simplest and most popular version, it ignores syntactical constraints and may produce ungrammatical output. For example, an inviolable rule of German grammar states that the finite verb must be in the second position in the main clause. Since it is hard to enforce such rules with an ngram language model, syntax-informed linearization methods have been developed for German (Ringger et al., 2004; Filippova &amp; Strube, 2007). We apply our recent method to order constituents and, using the CMU toolkit (Clarkson &amp; Rosenfeld, 1997), build a trigram language model from Wikipedia (approx. 1GB plain text) to find the best word order within constituents. Some constraints on word order are inferred from the input. Only interclause punctuation is generated. 5 Experiments and Evaluation We choose Barzilay &amp; McKeown’s system as a nontrivial baseline since, to our knowledge, there is no other system which outperforms theirs (Sec. 5.1). It is important for us to evaluate the fusion part of our system, so the input and the lin</context>
</contexts>
<marker>Filippova, Strube, 2007</marker>
<rawString>Filippova, Katja &amp; Michael Strube (2007). Generating constituent order in German clauses. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics, Prague, Czech Republic, 23–30 June 2007, pp. 320–327.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katja Filippova</author>
<author>Michael Strube</author>
</authors>
<title>Dependency tree based sentence compression.</title>
<date>2008</date>
<booktitle>In Proceedings of the 5th International Conference on Natural Language Generation,</booktitle>
<pages>25--32</pages>
<location>Salt Fork, Ohio,</location>
<contexts>
<context position="4644" citStr="Filippova &amp; Strube (2008)" startWordPosition="722" endWordPosition="725">nd-crafted rules, but decide to retain a dependency based on its syntactic importance score. The second point concerns integrating semantics. Being definitely important, ”this source of information remains relatively unused in work on aggregation1 within NLG” (Reiter &amp; Dale, 2000, p.141). To our knowledge, in the text-to-text generation field, we are the first to use semantic information not only for alignment but also for aggregation in that we check coarguments’ compatibility. Apart from that, our method is not limited to sentence fusion and can be easily applied to sentence compression. In Filippova &amp; Strube (2008) we compress English sentences with the same approach and achieve state-of-the-art performance. The paper is organized as follows: Section 2 gives an overview of related work and Section 3 presents our data. Section 4 introduces our method and Section 5 describes the experiments and discusses the results of the evaluation. The conclusions follow in the final section. 2 Related Work Most studies on text-to-text generation concern sentence compression where the input consists of exactly one sentence (Jing, 2001; Hori &amp; Furui, 2004; Clarke &amp; Lapata, 2008, inter alia). In such setting, redundancy,</context>
<context position="27888" citStr="Filippova &amp; Strube, 2008" startWordPosition="4647" endWordPosition="4650">tence by modifying the tree of an input sentence, in some cases it outputs a compression of this sentence. Unlike this, our method is not based on an input tree and generates a new sentence without being biased to any of the input sentences. Our method can also be applied to non-trivial sentence compression, whereas the baseline and similar methods, such as Marsi &amp; Krahmer (2005), would then boil down to a few very general pruning rules. We tested our method on the English compression corpus6 and evaluated the compressions automatically the same way as Clarke &amp; Lapata (2008) did. The results (Filippova &amp; Strube, 2008) were as good as or significantly better than the state-of-the-art, depending on the choice of dependency parser. 6The corpus is available from http://homepages. inf.ed.ac.uk/s0460084/data. 6 Conclusions We presented a novel sentence fusion method which formulates the fusion task as an optimization problem. It is unsupervised and finds a globally optimal solution taking semantics, syntax and word informativeness into account. The method does not require hand-crafted rules or lexicons to generate grammatical output but relies on the syntactic importance score calculated from an automatically pa</context>
</contexts>
<marker>Filippova, Strube, 2008</marker>
<rawString>Filippova, Katja &amp; Michael Strube (2008). Dependency tree based sentence compression. In Proceedings of the 5th International Conference on Natural Language Generation, Salt Fork, Ohio, 12–14 June 2008, pp. 25– 32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kilian Foth</author>
<author>Wolfgang Menzel</author>
</authors>
<title>Hybrid parsing: Using probabilistic models as predictors for a symbolic parser.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>321--327</pages>
<location>Sydney, Australia,</location>
<contexts>
<context position="8192" citStr="Foth &amp; Menzel, 2006" startWordPosition="1302" endWordPosition="1305">eople, and the number of articles for one person ranges from 2 to 4, being 3 on average. Despite obvious similarities between articles about one person, neither identical content nor identical ordering of information can be expected. Fully automatic preprocessing in our system comprises the following steps: sentence boundaries are identified with a Perl CPAN module3. Then the sentences are split into tokens and the TnT tagger (Brants, 2000) and the TreeTagger (Schmid, 1997) are used for tagging and lemmatization respectively. Finally, the biographies are parsed with the CDG dependency parser (Foth &amp; Menzel, 2006). We also identify references to the biographee (pronominal as well as proper names) and temporal expressions (absolute and relative) with a few rules. 4 Our Method Groups of related sentences serve as input to a sentence fusion system and thus need to be identified first (4.1). Then the dependency trees of the sentences are modified (4.2) and aligned (4.3). Syntactic importance (4.4) and word informativeness (4.5) scores are used to extract a new dependency tree from a graph of aligned trees (4.6). Finally, the tree is linearized (4.7). 4.1 Sentence Alignment Sentence alignment for comparable</context>
</contexts>
<marker>Foth, Menzel, 2006</marker>
<rawString>Foth, Kilian &amp; Wolfgang Menzel (2006). Hybrid parsing: Using probabilistic models as predictors for a symbolic parser. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, Sydney, Australia, 17–21 July 2006, pp. 321–327.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Iryna Gurevych</author>
<author>Hendrik Niederlich</author>
</authors>
<title>Accessing GermaNet data and computing semantic relatedness.</title>
<date>2005</date>
<booktitle>In Companion Volume to the Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>5--8</pages>
<location>Ann Arbor, Mich.,</location>
<contexts>
<context position="22232" citStr="Gurevych &amp; Niederlich, 2005" startWordPosition="3700" endWordPosition="3703">physics Bohr bio pleasure root s studied with subj with obja obja sciences obja 182 dependency trees is recursively found with WordNet and a paraphrase lexicon. From the alignment costs the centroid of the group is identified. Then this tree is augmented with information from other trees given that it appears in at least half of the sentences from this group. A rule-based pruning module prunes optional constituents, such as PPs or relative clauses. The linearization of the resulting tree (or graph) is done with a trigram language model. To adapt this system to German, we use the GermaNet API (Gurevych &amp; Niederlich, 2005) instead of WordNet. We do not use a paraphrase lexicon, because there is no comparable corpus of sufficient size available for German. We readjust the alignment parameters of the system to prevent dissimilar nodes from being aligned. The input to the algorithm is generated as described in Sec. 4.1. The linearization is done as described in Sec. 4.7. In cases when there is a graph to linearize, all possible trees covering the maximum number of nodes are extracted from it and linearized. The most probable string is selected as the final output with a language model. For the rest of the reimplem</context>
</contexts>
<marker>Gurevych, Niederlich, 2005</marker>
<rawString>Gurevych, Iryna &amp; Hendrik Niederlich (2005). Accessing GermaNet data and computing semantic relatedness. In Companion Volume to the Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics, Ann Arbor, Mich., 25–30 June 2005, pp. 5–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chiori Hori</author>
<author>Sadaoki Furui</author>
</authors>
<title>Speech summarization: An approach through word extraction and a method for evaluation.</title>
<date>2004</date>
<journal>IEEE Transactions on Information and Systems,</journal>
<pages>87--1</pages>
<contexts>
<context position="5178" citStr="Hori &amp; Furui, 2004" startWordPosition="808" endWordPosition="811">sion and can be easily applied to sentence compression. In Filippova &amp; Strube (2008) we compress English sentences with the same approach and achieve state-of-the-art performance. The paper is organized as follows: Section 2 gives an overview of related work and Section 3 presents our data. Section 4 introduces our method and Section 5 describes the experiments and discusses the results of the evaluation. The conclusions follow in the final section. 2 Related Work Most studies on text-to-text generation concern sentence compression where the input consists of exactly one sentence (Jing, 2001; Hori &amp; Furui, 2004; Clarke &amp; Lapata, 2008, inter alia). In such setting, redundancy, incompleteness and compatibility 1We follow Barzilay &amp; McKeown (2005) and refer to aggregation within text-to-text generation as sentence fusion. issues do not arise. Apart from that, there is no obvious way of how existing sentence compression methods can be adapted to sentence fusion. Barzilay &amp; McKeown (2005) present a sentence fusion method for multi-document news summarization which crucially relies on the assumption that information appearing in many sources is important. Consequently, their method produces an intersectio</context>
<context position="15247" citStr="Hori &amp; Furui (2004)" startWordPosition="2462" endWordPosition="2466">te P(pplstudieren) 4The probabilities are calculated from a corpus of approx. 3,000 biographies from Wikipedia which we annotated automatically as described in Section 3. 180 which would not be very informative. in an 0.44 0.42 Table 1: Probabilities of subj, obja(ccusative), in, at, after, with, to given the verb studieren (study) 4.5 Word Informativeness Score We also want to retain informative words in the output tree. There are many ways in which word importance can be defined. Here, we use a formula introduced by Clarke &amp; Lapata (2008) which is a modification of the significance score of Hori &amp; Furui (2004): l FA I(wi) = N · fi log (3) Fi wi is the topic word (either noun or verb), fi is the frequency of wi in the aligned biographies, Fi is the frequency of wi in the corpus, and FA is the sum of frequencies of all topic words in the corpus. l is the number of clause nodes above w and N is the maximum level of embedding of the sentence which w belongs to. By defining word importance differently, e.g. as relatedness of a word to the topic, we could apply our method to topic-based summarization (Krahmer et al., 2008). 4.6 New Sentence Generation We formulate the task of getting a tree from a depend</context>
</contexts>
<marker>Hori, Furui, 2004</marker>
<rawString>Hori, Chiori &amp; Sadaoki Furui (2004). Speech summarization: An approach through word extraction and a method for evaluation. IEEE Transactions on Information and Systems, E87-D(1):15–25.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eduard Hovy</author>
</authors>
<title>Text summarization.</title>
<date>2003</date>
<booktitle>In Ruslan Mitkov (Ed.), The Oxford Handbook of Computational Linguistics,</booktitle>
<pages>583--598</pages>
<publisher>Oxford University Press.</publisher>
<location>Oxford, U.K.:</location>
<marker>Hovy, 2003</marker>
<rawString>Hovy, Eduard (2003). Text summarization. In Ruslan Mitkov (Ed.), The Oxford Handbook of Computational Linguistics, pp. 583–598. Oxford, U.K.: Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hongyan Jing</author>
</authors>
<title>Cut-and-Paste Text Summarization,</title>
<date>2001</date>
<tech>(Ph.D. thesis).</tech>
<institution>Computer Science Department, Columbia University,</institution>
<location>New York, N.Y.</location>
<contexts>
<context position="5158" citStr="Jing, 2001" startWordPosition="806" endWordPosition="807"> sentence fusion and can be easily applied to sentence compression. In Filippova &amp; Strube (2008) we compress English sentences with the same approach and achieve state-of-the-art performance. The paper is organized as follows: Section 2 gives an overview of related work and Section 3 presents our data. Section 4 introduces our method and Section 5 describes the experiments and discusses the results of the evaluation. The conclusions follow in the final section. 2 Related Work Most studies on text-to-text generation concern sentence compression where the input consists of exactly one sentence (Jing, 2001; Hori &amp; Furui, 2004; Clarke &amp; Lapata, 2008, inter alia). In such setting, redundancy, incompleteness and compatibility 1We follow Barzilay &amp; McKeown (2005) and refer to aggregation within text-to-text generation as sentence fusion. issues do not arise. Apart from that, there is no obvious way of how existing sentence compression methods can be adapted to sentence fusion. Barzilay &amp; McKeown (2005) present a sentence fusion method for multi-document news summarization which crucially relies on the assumption that information appearing in many sources is important. Consequently, their method pro</context>
<context position="13530" citStr="Jing (2001)" startWordPosition="2171" endWordPosition="2172">the subtrees they root are largely aligned. Although in some cases it helps discover paraphrases, it considerably increases chances of generating ungrammatical output which we want to avoid at any cost. 4.4 Syntactic Importance Score Given a dependency graph we want to get a new dependency tree from it. Intuitively, we want to retain obligatory dependencies (e.g. subject) while removing less important ones (e.g. adv). When deciding on pruning an argument, previous approaches either used a set of hand-crafted rules (e.g. Barzilay &amp; McKeown (2005)), or utilized a subcategorization lexicon (e.g. Jing (2001)). The hand-crafted rules are often too general to ensure a grammatical argument structure for different verbs (e.g. PPs can be pruned). Subcategorization lexicons are not readily available for many languages and cover only verbs. E.g. they do not tell that the noun son is very often modified by a PP using the preposition of, as in the son of Niels Bohr, and that the NP without a PP modifier may appear incomplete. To overcome these problems, we decide on pruning an edge by estimating the conditional probability of its label given its head, P(l|h)4. For example, P(subj|studieren) – the probabil</context>
</contexts>
<marker>Jing, 2001</marker>
<rawString>Jing, Hongyan (2001). Cut-and-Paste Text Summarization, (Ph.D. thesis). Computer Science Department, Columbia University, New York, N.Y.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Laura Kassner</author>
<author>Vivi Nastase</author>
<author>Michael Strube</author>
</authors>
<title>Acquiring a taxonomy from the German Wikipedia.</title>
<date>2008</date>
<booktitle>In Proceedings of the 6th International Conference on Language Resources and Evaluation,</booktitle>
<volume>1</volume>
<location>Marrakech,</location>
<contexts>
<context position="18607" citStr="Kassner et al., 2008" startWordPosition="3091" endWordPosition="3094"> binary function, whereas rel(w,u) returns a value from [0, 1]. We subj obja nach mit 0.88 0.74 0.09 0.02 0.01 X X xlw,u ≥ 0 (7) ∀w ∈ W, l 1 h,l xh w − |W |u,l X xlh,w · P(l|h) · I(w) (5) f(X) = zu x 181 Figure 2: Graph obtained from sentences He studied sciences with pleasure and He studied math and physics with Bohr also introduce additional variables ylw,u (represented by dashed lines in Fig. 2): l—�1 if 1h,l : xlhw = 1 ∧ xlh yw,u u = 1 — (10) 0 otherwise For two edges sharing a head and having identical labels to be retained we check in GermaNet and in the taxonomy derived from Wikipedia (Kassner et al., 2008) that their dependents are not in the hyponymy or meronymy relation (11). We prohibit verb coordination unless it is found in one of the input sentences. If the dependents are nouns, we also check that their semantic relatedness as measured with WikiRelate! (Strube &amp; Ponzetto, 2006) is above a certain threshold (12). We empirically determined the value of Q = 0.36 by calculating an average similarity of coordinated nouns in the corpus. bylw,u, hm(w, u) - ylw,u = 0 (11) bylw,u, (rel(w, u) − 0) - ylw,u &gt; 0 (12) (11) prohibits thatphysics (or math) and sciences appear together since, according to</context>
</contexts>
<marker>Kassner, Nastase, Strube, 2008</marker>
<rawString>Kassner, Laura, Vivi Nastase &amp; Michael Strube (2008). Acquiring a taxonomy from the German Wikipedia. In Proceedings of the 6th International Conference on Language Resources and Evaluation, Marrakech, Morocco, 26 May – 1 June 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emiel Krahmer</author>
<author>Erwin Marsi</author>
<author>Paul van Pelt</author>
</authors>
<title>Query-based sentence fusion is better defined and leads to more preferred results than generic sentence fusion.</title>
<date>2008</date>
<booktitle>In Companion Volume to the Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>193--196</pages>
<location>Columbus, Ohio,</location>
<marker>Krahmer, Marsi, van Pelt, 2008</marker>
<rawString>Krahmer, Emiel, Erwin Marsi &amp; Paul van Pelt (2008). Query-based sentence fusion is better defined and leads to more preferred results than generic sentence fusion. In Companion Volume to the Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics, Columbus, Ohio, 15–20 June 2008, pp. 193–196.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Irene Langkilde</author>
<author>Kevin Knight</author>
</authors>
<title>Generation that exploits corpus-based statistical knowledge.</title>
<date>1998</date>
<booktitle>In Proceedings of the 17th International Conference on Computational Linguistics and 36th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>704--710</pages>
<location>Montr´eal, Qu´ebec, Canada, 10–14</location>
<contexts>
<context position="19919" citStr="Langkilde &amp; Knight, 1998" startWordPosition="3314" endWordPosition="3318">both pleasure (Freude) and Bohr because rel(Freude,Bohr) = 0.17. math and physics are neither in ISA, nor part-of relation and are sufficiently related (rel(Mathematik, Physik) = 0.67) to become conjuncts. META constraints (equations (13) and (14)) guarantee that ylw,u = xlh,w x xlh,u i.e. they ensure that the semantic constraints are applied only if both the labels from h to w and from h to u are preserved. bylw,u,xlh,w + xlh,u &gt; 2yl (13) w,u bylw,u,1 − xlh,w + 1 − xlh,u &gt; 1 − ylw,u (14) 4.7 Linearization The “overgenerate-and-rank” approach to statistical surface realization is very common (Langkilde &amp; Knight, 1998). Unfortunately, in its simplest and most popular version, it ignores syntactical constraints and may produce ungrammatical output. For example, an inviolable rule of German grammar states that the finite verb must be in the second position in the main clause. Since it is hard to enforce such rules with an ngram language model, syntax-informed linearization methods have been developed for German (Ringger et al., 2004; Filippova &amp; Strube, 2007). We apply our recent method to order constituents and, using the CMU toolkit (Clarkson &amp; Rosenfeld, 1997), build a trigram language model from Wikipedia</context>
</contexts>
<marker>Langkilde, Knight, 1998</marker>
<rawString>Langkilde, Irene &amp; Kevin Knight (1998). Generation that exploits corpus-based statistical knowledge. In Proceedings of the 17th International Conference on Computational Linguistics and 36th Annual Meeting of the Association for Computational Linguistics, Montr´eal, Qu´ebec, Canada, 10–14 August 1998, pp. 704–710.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lothar Lemnitzer</author>
<author>Claudia Kunze</author>
</authors>
<title>GermaNet – representation, visualization, application.</title>
<date>2002</date>
<booktitle>In Proceedings of the 3rd International Conference on Language Resources and Evaluation, Las Palmas, Canary Islands,</booktitle>
<pages>1485--1491</pages>
<contexts>
<context position="10152" citStr="Lemnitzer &amp; Kunze, 2002" startWordPosition="1609" endWordPosition="1613">e/ suche 3http://search.cpan.org/-holsten/ Lingua-DE-Sentence-0.07/Sentence.pm demonstrate the efficacy of a sentence-based tf*idf score when applied to comparable corpora. Following them, we define the similarity of two sentences sim(s1, s2) as Et wS1(t) · wS2(t) (1) t w2S1(t) Et w2S2(t) where S is the set of all lemmas but stop-words from s, and wS(t) is the weight of the term t: wS(t) = S(t) 1 (2) Nt where S(t) is the indicator function of S, Nt is the number of sentences in the biographies of one person which contain t. We enhance the similarity measure by looking up synonymy in GermaNet (Lemnitzer &amp; Kunze, 2002). We discard identical or nearly identical sentences (sim(s1, s2) &gt; 0.8) and greedily build sentence clusters using a hierarchical groupwiseaverage technique. As a result, one sentence may belong to one cluster at most. These sentence clusters serve as input to the fusion algorithm. 4.2 Dependency Tree Modification We apply a set of transformations to a dependency tree to emphasize its important properties and eliminate unimportant ones. These transformations are necessary for the compression stage. An example of a dependency tree and its modifed version are given in Fig. 1. PREP preposition n</context>
</contexts>
<marker>Lemnitzer, Kunze, 2002</marker>
<rawString>Lemnitzer, Lothar &amp; Claudia Kunze (2002). GermaNet – representation, visualization, application. In Proceedings of the 3rd International Conference on Language Resources and Evaluation, Las Palmas, Canary Islands, Spain, 29–31 May 2002, pp. 1485–1491.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erwin Marsi</author>
<author>Emiel Krahmer</author>
</authors>
<title>Explorations in sentence fusion.</title>
<date>2005</date>
<booktitle>In Proceedings of the European Workshop on Natural Language Generation,</booktitle>
<pages>109--117</pages>
<location>Aberdeen, Scotland, 8–10</location>
<contexts>
<context position="6134" citStr="Marsi &amp; Krahmer (2005)" startWordPosition="960" endWordPosition="963"> to sentence fusion. Barzilay &amp; McKeown (2005) present a sentence fusion method for multi-document news summarization which crucially relies on the assumption that information appearing in many sources is important. Consequently, their method produces an intersection of input sentences by, first, finding the centroid of the input, second, augmenting it with information from other sentences and, finally, pruning a predefined set of constituents (e.g. PPs). The resulting structure is not necessarily a tree and allows for extraction of several trees, each of which can be linearized in many ways. Marsi &amp; Krahmer (2005) extend the approach of Barzilay &amp; McKeown to do not only intersection but also union fusion. Like Barzilay &amp; McKeown (2005), they find the best linearization with a language model which, as they point out, often produces inadequate rankings being unable to deal with word order, agreement and subcategorization constraints. In our work we aim at producing a valid dependency tree structure so that most grammaticality issues are resolved before the linearization stage. Wan et al. (2007) introduce a global revision method of how a novel sentence can be generated from a set of input words. They for</context>
<context position="12682" citStr="Marsi &amp; Krahmer, 2005" startWordPosition="2034" endWordPosition="2038"> aim at finding the best node alignment. We use a simple, fast and transparent method and align any two words provided that they 1. are content words; 2. have the same part-of-speech; 3. have identical lemmas or are synonyms. In case of multiple possibilities, which are extremely rare in our data, the choice is made randomly. By merging all aligned nodes we get a dependency graph which consists of all dependencies from the input trees. In case it contains a cycle, one of the alignments from the cycle is eliminated. We prefer this very simple method to bottom-up ones (Barzilay &amp; McKeown, 2005; Marsi &amp; Krahmer, 2005) for two main reasons. Pursuing local subtree alignments, bottom-up methods may leave identical words unaligned and thus prohibit fusion of complementary information. On the other hand, they may force alignment of two unrelated words if the subtrees they root are largely aligned. Although in some cases it helps discover paraphrases, it considerably increases chances of generating ungrammatical output which we want to avoid at any cost. 4.4 Syntactic Importance Score Given a dependency graph we want to get a new dependency tree from it. Intuitively, we want to retain obligatory dependencies (e.</context>
<context position="27645" citStr="Marsi &amp; Krahmer (2005)" startWordPosition="4606" endWordPosition="4609">or example, it knows that at is more important than to for study whereas for go it is the other way round. Unlike our differentiated approach, the baseline rule states that PPs can generally be pruned. Since the baseline generates a new sentence by modifying the tree of an input sentence, in some cases it outputs a compression of this sentence. Unlike this, our method is not based on an input tree and generates a new sentence without being biased to any of the input sentences. Our method can also be applied to non-trivial sentence compression, whereas the baseline and similar methods, such as Marsi &amp; Krahmer (2005), would then boil down to a few very general pruning rules. We tested our method on the English compression corpus6 and evaluated the compressions automatically the same way as Clarke &amp; Lapata (2008) did. The results (Filippova &amp; Strube, 2008) were as good as or significantly better than the state-of-the-art, depending on the choice of dependency parser. 6The corpus is available from http://homepages. inf.ed.ac.uk/s0460084/data. 6 Conclusions We presented a novel sentence fusion method which formulates the fusion task as an optimization problem. It is unsupervised and finds a globally optimal </context>
</contexts>
<marker>Marsi, Krahmer, 2005</marker>
<rawString>Marsi, Erwin &amp; Emiel Krahmer (2005). Explorations in sentence fusion. In Proceedings of the European Workshop on Natural Language Generation, Aberdeen, Scotland, 8–10 August, 2005, pp. 109–117.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kathleen R McKeown</author>
<author>Judith L Klavans</author>
</authors>
<title>Vassileios Hatzivassiloglou, Regina Barzilay &amp; Eleazar Eskin</title>
<date>1999</date>
<booktitle>In Proceedings of the 16th National Conference on Artificial Intelligence,</booktitle>
<pages>453--460</pages>
<location>Orlando, Flo.,</location>
<marker>McKeown, Klavans, 1999</marker>
<rawString>McKeown, Kathleen R., Judith L. Klavans, Vassileios Hatzivassiloglou, Regina Barzilay &amp; Eleazar Eskin (1999). Towards multidocument summarization by reformulation: Progress and prospects. In Proceedings of the 16th National Conference on Artificial Intelligence, Orlando, Flo., 18–22 July 1999, pp. 453–460.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rani Nelken</author>
<author>Stuart Schieber</author>
</authors>
<title>Towards robust context-sensitive sentence alignment for monolingual corpora.</title>
<date>2006</date>
<booktitle>In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>161--168</pages>
<location>Trento,</location>
<contexts>
<context position="9365" citStr="Nelken &amp; Schieber (2006)" startWordPosition="1496" endWordPosition="1499">entence Alignment Sentence alignment for comparable corpora requires methods different from those used in machine translation for parallel corpora. For example, given two biographies of a person, one of them may follow the timeline from birth to death whereas the other may group events thematically or tell only about the scientific contribution of the person. Thus one cannot assume that the sentence order or the content is the same in two biographies. Shallow methods like word or bigram overlap, (weighted) cosine or Jaccard similarity are appealing as they are cheap and robust. In particular, Nelken &amp; Schieber (2006) 2http://de.wikipedia.org, http://home. datacomm.ch/biografien, http://biographie. net/de, http://www.weltchronik.de/ws/bio/ main.htm, http://www.brockhaus-suche.de/ suche 3http://search.cpan.org/-holsten/ Lingua-DE-Sentence-0.07/Sentence.pm demonstrate the efficacy of a sentence-based tf*idf score when applied to comparable corpora. Following them, we define the similarity of two sentences sim(s1, s2) as Et wS1(t) · wS2(t) (1) t w2S1(t) Et w2S2(t) where S is the set of all lemmas but stop-words from s, and wS(t) is the weight of the term t: wS(t) = S(t) 1 (2) Nt where S(t) is the indicator fu</context>
</contexts>
<marker>Nelken, Schieber, 2006</marker>
<rawString>Nelken, Rani &amp; Stuart Schieber (2006). Towards robust context-sensitive sentence alignment for monolingual corpora. In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics, Trento, Italy, 3–7 April 2006, pp. 161–168.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ehud Reiter</author>
<author>Robert Dale</author>
</authors>
<title>Building Natural Language Generation Systems.</title>
<date>2000</date>
<publisher>Cambridge University Press.</publisher>
<location>Cambridge, U.K.:</location>
<contexts>
<context position="4299" citStr="Reiter &amp; Dale, 2000" startWordPosition="664" endWordPosition="667">linear programming (ILP) to find a globally optimal solution. We argue that our method has three important advantages compared to existing methods. First, we address the grammaticality issue empirically by means of knowledge obtained from an automatically parsed corpus. We do not require such resources as subcategorization lexicons or hand-crafted rules, but decide to retain a dependency based on its syntactic importance score. The second point concerns integrating semantics. Being definitely important, ”this source of information remains relatively unused in work on aggregation1 within NLG” (Reiter &amp; Dale, 2000, p.141). To our knowledge, in the text-to-text generation field, we are the first to use semantic information not only for alignment but also for aggregation in that we check coarguments’ compatibility. Apart from that, our method is not limited to sentence fusion and can be easily applied to sentence compression. In Filippova &amp; Strube (2008) we compress English sentences with the same approach and achieve state-of-the-art performance. The paper is organized as follows: Section 2 gives an overview of related work and Section 3 presents our data. Section 4 introduces our method and Section 5 d</context>
</contexts>
<marker>Reiter, Dale, 2000</marker>
<rawString>Reiter, Ehud &amp; Robert Dale (2000). Building Natural Language Generation Systems. Cambridge, U.K.: Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Ringger</author>
<author>Michael Gamon</author>
<author>Robert C Moore</author>
<author>David Rojas</author>
</authors>
<title>Martine Smets &amp; Simon Corston-Oliver</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th International Conference on Computational Linguistics,</booktitle>
<pages>673--679</pages>
<location>Geneva,</location>
<contexts>
<context position="20339" citStr="Ringger et al., 2004" startWordPosition="3383" endWordPosition="3386">+ xlh,u &gt; 2yl (13) w,u bylw,u,1 − xlh,w + 1 − xlh,u &gt; 1 − ylw,u (14) 4.7 Linearization The “overgenerate-and-rank” approach to statistical surface realization is very common (Langkilde &amp; Knight, 1998). Unfortunately, in its simplest and most popular version, it ignores syntactical constraints and may produce ungrammatical output. For example, an inviolable rule of German grammar states that the finite verb must be in the second position in the main clause. Since it is hard to enforce such rules with an ngram language model, syntax-informed linearization methods have been developed for German (Ringger et al., 2004; Filippova &amp; Strube, 2007). We apply our recent method to order constituents and, using the CMU toolkit (Clarkson &amp; Rosenfeld, 1997), build a trigram language model from Wikipedia (approx. 1GB plain text) to find the best word order within constituents. Some constraints on word order are inferred from the input. Only interclause punctuation is generated. 5 Experiments and Evaluation We choose Barzilay &amp; McKeown’s system as a nontrivial baseline since, to our knowledge, there is no other system which outperforms theirs (Sec. 5.1). It is important for us to evaluate the fusion part of our syste</context>
</contexts>
<marker>Ringger, Gamon, Moore, Rojas, 2004</marker>
<rawString>Ringger, Eric, Michael Gamon, Robert C. Moore, David Rojas, Martine Smets &amp; Simon Corston-Oliver (2004). Linguistically informed statistical models of constituent structure for ordering in sentence realization. In Proceedings of the 20th International Conference on Computational Linguistics, Geneva, Switzerland, 23–27 August 2004, pp. 673–679.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
</authors>
<title>Probabilistic Part-of-Speech tagging using decision trees.</title>
<date>1997</date>
<booktitle>In Daniel Jones &amp; Harold Somers (Eds.), New Methods in Language Processing,</booktitle>
<pages>154--164</pages>
<publisher>UCL Press.</publisher>
<location>London, U.K.:</location>
<contexts>
<context position="8050" citStr="Schmid, 1997" startWordPosition="1282" endWordPosition="1283">ork with is a collection of about 400 biographies in German gathered from 178 the Internet2. These biographies describe 140 different people, and the number of articles for one person ranges from 2 to 4, being 3 on average. Despite obvious similarities between articles about one person, neither identical content nor identical ordering of information can be expected. Fully automatic preprocessing in our system comprises the following steps: sentence boundaries are identified with a Perl CPAN module3. Then the sentences are split into tokens and the TnT tagger (Brants, 2000) and the TreeTagger (Schmid, 1997) are used for tagging and lemmatization respectively. Finally, the biographies are parsed with the CDG dependency parser (Foth &amp; Menzel, 2006). We also identify references to the biographee (pronominal as well as proper names) and temporal expressions (absolute and relative) with a few rules. 4 Our Method Groups of related sentences serve as input to a sentence fusion system and thus need to be identified first (4.1). Then the dependency trees of the sentences are modified (4.2) and aligned (4.3). Syntactic importance (4.4) and word informativeness (4.5) scores are used to extract a new depend</context>
</contexts>
<marker>Schmid, 1997</marker>
<rawString>Schmid, Helmut (1997). Probabilistic Part-of-Speech tagging using decision trees. In Daniel Jones &amp; Harold Somers (Eds.), New Methods in Language Processing, pp. 154–164. London, U.K.: UCL Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sp¨arck Jones</author>
<author>Karen</author>
</authors>
<title>Automatic summarizing: Factors and directions.</title>
<date>1999</date>
<booktitle>In Inderjeet Mani &amp; Mark T. Maybury (Eds.), Advances in Automatic Text Summarization,</booktitle>
<pages>1--12</pages>
<publisher>MIT Press.</publisher>
<location>Cambridge, Mass.:</location>
<marker>Jones, Karen, 1999</marker>
<rawString>Sp¨arck Jones, Karen (1999). Automatic summarizing: Factors and directions. In Inderjeet Mani &amp; Mark T. Maybury (Eds.), Advances in Automatic Text Summarization, pp. 1–12. Cambridge, Mass.: MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Strube</author>
<author>Simone Paolo Ponzetto</author>
</authors>
<title>WikiRelate! Computing semantic relatedness using Wikipedia.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st National Conference on Artificial Intelligence,</booktitle>
<volume>16</volume>
<pages>1419--1424</pages>
<location>Boston, Mass.,</location>
<contexts>
<context position="18890" citStr="Strube &amp; Ponzetto, 2006" startWordPosition="3138" endWordPosition="3141">d He studied math and physics with Bohr also introduce additional variables ylw,u (represented by dashed lines in Fig. 2): l—�1 if 1h,l : xlhw = 1 ∧ xlh yw,u u = 1 — (10) 0 otherwise For two edges sharing a head and having identical labels to be retained we check in GermaNet and in the taxonomy derived from Wikipedia (Kassner et al., 2008) that their dependents are not in the hyponymy or meronymy relation (11). We prohibit verb coordination unless it is found in one of the input sentences. If the dependents are nouns, we also check that their semantic relatedness as measured with WikiRelate! (Strube &amp; Ponzetto, 2006) is above a certain threshold (12). We empirically determined the value of Q = 0.36 by calculating an average similarity of coordinated nouns in the corpus. bylw,u, hm(w, u) - ylw,u = 0 (11) bylw,u, (rel(w, u) − 0) - ylw,u &gt; 0 (12) (11) prohibits thatphysics (or math) and sciences appear together since, according to GermaNet, physics (Physik) is a hyponym of science (Wissenschaft). (12) blocks taking both pleasure (Freude) and Bohr because rel(Freude,Bohr) = 0.17. math and physics are neither in ISA, nor part-of relation and are sufficiently related (rel(Mathematik, Physik) = 0.67) to become c</context>
</contexts>
<marker>Strube, Ponzetto, 2006</marker>
<rawString>Strube, Michael &amp; Simone Paolo Ponzetto (2006). WikiRelate! Computing semantic relatedness using Wikipedia. In Proceedings of the 21st National Conference on Artificial Intelligence, Boston, Mass., 16– 20 July 2006, pp. 1419–1424.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Wan</author>
<author>Robert Dale</author>
<author>Mark Dras</author>
<author>Cecile Paris</author>
</authors>
<title>Global revision in summarization: Generating novel sentences with Prim’s algorithm.</title>
<date>2007</date>
<booktitle>In Proceedings of the 10th Conference of the Pacific Association for Computational Linguistics,</booktitle>
<pages>21</pages>
<location>Melbourne, Australia,</location>
<contexts>
<context position="6622" citStr="Wan et al. (2007)" startWordPosition="1041" endWordPosition="1044">cessarily a tree and allows for extraction of several trees, each of which can be linearized in many ways. Marsi &amp; Krahmer (2005) extend the approach of Barzilay &amp; McKeown to do not only intersection but also union fusion. Like Barzilay &amp; McKeown (2005), they find the best linearization with a language model which, as they point out, often produces inadequate rankings being unable to deal with word order, agreement and subcategorization constraints. In our work we aim at producing a valid dependency tree structure so that most grammaticality issues are resolved before the linearization stage. Wan et al. (2007) introduce a global revision method of how a novel sentence can be generated from a set of input words. They formulate the problem as a search for a maximum spanning tree which is incrementally constructed by connecting words or phrases with dependency relations. The grammaticality issue is addressed by a number of hard constraints. As Wan et al. point out, one of the problems with their method is that the output built up from dependencies found in a corpus might have a meaning different from the intended one. Since we build our trees from the input dependencies, this problem does not arise wi</context>
</contexts>
<marker>Wan, Dale, Dras, Paris, 2007</marker>
<rawString>Wan, Stephen, Robert Dale, Mark Dras &amp; Cecile Paris (2007). Global revision in summarization: Generating novel sentences with Prim’s algorithm. In Proceedings of the 10th Conference of the Pacific Association for Computational Linguistics, Melbourne, Australia, 19– 21 September, 2007, pp. 226–235.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>