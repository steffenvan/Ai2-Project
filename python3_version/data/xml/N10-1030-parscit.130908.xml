<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001395">
<title confidence="0.987735">
Improving Semantic Role Labeling with Word Sense
</title>
<author confidence="0.997444">
Wanxiang Che, Ting Liu and Yongqiang Li
</author>
<affiliation confidence="0.99627875">
Research Center for Information Retrieval
MOE-Microsoft Key Laboratory of Natural Language Processing and Speech
School of Computer Science and Technology
Harbin Institute of Technology, China, 150001
</affiliation>
<email confidence="0.994816">
{car, tliu, yqli}@ir.hit.edu.cn
</email>
<sectionHeader confidence="0.993871" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999313454545455">
Semantic role labeling (SRL) not only needs
lexical and syntactic information, but also
needs word sense information. However, be-
cause of the lack of corpus annotated with
both word senses and semantic roles, there is
few research on using word sense for SRL.
The release of OntoNotes provides an oppor-
tunity for us to study how to use word sense
for SRL. In this paper, we present some novel
word sense features for SRL and find that they
can improve the performance significantly.
</bodyText>
<sectionHeader confidence="0.998797" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999914785714286">
Semantic role labeling (SRL) is a kind of shallow
sentence-level semantic analysis and is becoming a
hot task in natural language processing. SRL aims at
identifying the relations between the predicates in a
sentence and their associated arguments. At present,
the main stream researches are focusing on feature
engineering or combination of multiple results.
Word senses are important information for rec-
ognizing semantic roles. For example, if we know
“cat” is an “agent” of the predicate “eat” in a
sentence, we can guess that “dog” can also be
an “agent” of “eat”. Word sense has been suc-
cessfully used in many natural language process-
ing tasks, such as machine translation (Chan et al.,
2007; Carpuat and Wu, 2007). CoNLL 2008 shared
task (Surdeanu et al., 2008) first introduced the pred-
icate classification task, which can be regarded as
the predicate sense disambiguation. Meza-Ruiz and
Riedel (2009) has shown that the predicate sense can
improve the final SRL performance. However, there
is few discussion about the concrete influence of all
word senses, i.e. the words besides predicates. The
major reason is lacking the corpus, which is both an-
notated with all word senses and semantic roles.
The release of OntoNotes corpus provides an op-
portunity for us to verify whether all word senses
can help SRL. OntoNotes is a large corpus annotated
with constituency trees (based on Penn Treebank),
predicate argument structures (based on Penn Prop-
Bank) and word senses. It has been used in some
natural language processing tasks, such as joint pars-
ing and named entity recognition (Finkel and Man-
ning, 2009) and word sense disambiguation (Zhong
et al., 2008).
In this paper, we regard the word sense informa-
tion as additional SRL features. We compare three
categories of word sense features (subtree-word re-
lated sense, predicate sense, and sense path) and find
that the subtree-word related sense feature is ineffec-
tive, however, the predicate sense and the sense path
features can improve the SRL performance signifi-
cantly.
</bodyText>
<sectionHeader confidence="0.977883" genericHeader="method">
2 Data Preparation
</sectionHeader>
<bodyText confidence="0.994831352941177">
In our experiments, we use the OntoNotes Release
2.01 corpus (Hovy et al., 2006). The OntoNotes
project leaders describe it as “a large, multilingual
richly-annotated corpus constructed at 90% inter-
nanotator agreement.” The corpus has been an-
notated with multiple levels of annotation, includ-
ing constituency trees, predicate argument struc-
ture, word senses, co-reference, and named entities.
For this work, we focus on the constituency trees,
word senses, and predicate argument structures. The
corpus has English and Chinese portions, and we
just use the English portion, which has been split
into seven sections: ABC, CNN, MNB, NBC, PRI,
VOA, and WSJ. These sections represent a mix of
speech and newswire data.
Because we used SRL system based on depen-
dence syntactic trees, we convert the constituency
</bodyText>
<footnote confidence="0.614732">
lhttp://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?
catalogId=LDC2008T04
</footnote>
<page confidence="0.954194">
246
</page>
<subsubsectionHeader confidence="0.564598">
Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 246–249,
</subsubsectionHeader>
<subsectionHeader confidence="0.271395">
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</subsectionHeader>
<bodyText confidence="0.999251857142857">
trees into dependence trees with an Constituent-to-
Dependency Conversion Tool2. In addition, we also
convert the OntoNotes sense of each polysemant
into WordNet sense using sense inventory file pro-
vided by OntoNotes 2.0. For an OntoNotes sense
with more than one WordNet sense, we simply use
the foremost (more popular) one.
</bodyText>
<sectionHeader confidence="0.969793" genericHeader="method">
3 Semantic Role Labeling System
</sectionHeader>
<bodyText confidence="0.999971384615385">
Our baseline is a state-of-the-art SRL system based
on dependency syntactic tree (Che et al., 2009). A
maximum entropy (Berger et al., 1996) classifier is
used to predict the probabilities of a word in the
sentence to be each semantic role. A virtual role
“NULL” (presenting none of roles is assigned) is
added to the roles set, so it does not need seman-
tic role identification stage anymore. For a predi-
cate, two classifiers (one for noun predicates, and
the other for verb predicates) predict probabilities of
each word in a sentence to be each semantic role (in-
cluding virtual role “NULL”). The features used in
this stage are listed in Table 1.
</bodyText>
<subsectionHeader confidence="0.709312">
Feature Description
</subsectionHeader>
<bodyText confidence="0.9747221875">
FirstwordLemma The lemma of the first word in a
subtree
HeadwordLemma The lemma of the head word in
a subtree
HeadwordPOS The POS of the head word in a
subtree
LastwordLemma The lemma of the last word in a
subtree
POSPath The POS path from a word to a
predicate
PathLength The length of a path
Position The relative position of a word
with a predicate
PredicateLemma The lemma of a predicate
RelationPath The dependency relation path
from a word to a predicate
</bodyText>
<tableCaption confidence="0.997102">
Table 1: Features that are used in SRL.
</tableCaption>
<sectionHeader confidence="0.853231" genericHeader="method">
4 Word Sense for Semantic Role Labeling
</sectionHeader>
<bodyText confidence="0.999265666666667">
From Table 1, we can see that there are lots of lemma
or POS related features. However, the lemma fea-
ture is very sparse and may result in data sparseness
</bodyText>
<footnote confidence="0.939089">
2http://nlp.cs.lth.se/software/treebank converter/
</footnote>
<bodyText confidence="0.999653444444444">
problem. As for the POS, it represents the syntactic
information, but is not enough to distinguish differ-
ent semantic roles. Therefore, we need a kind of new
feature, which is general than the lemma and special
than the POS.
The word sense just satisfies the requirement.
Thus, we will add some new features related with
word sense for SRL. Generally, the original features
can be classified into three categories:
</bodyText>
<listItem confidence="0.999634333333333">
1. Subtree-word related: FirstwordLemma, Last-
wordLemma, HeadwordLemma, and Head-
wordPOS
2. Predicate related: PredicateLemma
3. Word and predicate related: POSPath, Rela-
tionPath, PathLenght, and Position
</listItem>
<bodyText confidence="0.998026">
Correspondingly, we add three categories of word
sense features by replacing Lemma or POS into
Sense, i.e.
</bodyText>
<listItem confidence="0.935746846153846">
1. Subtree-word related sense: FirstwordSense,
LastwordSense, and HeadwordSense
2. Predicate related sense: PredicateSense
3. Word and predicate related sense: SensePath
Three strategies are designed to adopt these
senses:
1. Lemma+Sense: It is the original word
sense representation in OntoNotes, such as
“dog.n.1”. In fact, This is a specialization of
the lemma.
2. Hypernym(n): It is the hypernym of a word
sense, e.g. the hypernym of “dog.n.1” is “ca-
nine.n.1”. The n means the level of the hy-
pernym. With the increasing of n, the sense
becomes more and more general. In theory,
however, this strategy may result in inconsis-
tent sense, e.g. word “dog” and “canine” have
different hypernyms. The same problem occurs
with Basic Concepts method (Izquierdo et al.,
2007).
3. Root Hyper(n): In order to extract more con-
sistent sense, we use the hypernym of a word
sense counting from the root of a sense tree,
e.g. the root hypernym of “dog.n.1” is “en-
tity.n.1”. The n means the level of the root hy-
pernym. With the increasing of n, the sense
</listItem>
<page confidence="0.968261">
247
</page>
<table confidence="0.999580888888889">
Subtree-word Predicate Sense
related sense sense path
Lemma+Sense 85.34% 86.16% 85.69%
1 85.41% 86.12% 85.74%
Hypernym(n) 2 85.48% 86.10% 85.74%
3 85.38% 86.10% 85.69%
1 85.35% 86.07% 85.96%
Root Hyper(n) 2 85.45% 86.13% 85.86%
3 85.46% 86.05% 85.91%
</table>
<bodyText confidence="0.9966375">
becomes more and more special. Thus, word
“dog” and “canine” have the same Root Hyper:
“entity”, “physical entity”, and “object” with n
= 1, 2, and 3 respectively.
</bodyText>
<sectionHeader confidence="0.999015" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<bodyText confidence="0.999464">
We will do our experiments on seven of the
OntoNotes English datasets described in Section 2.
For each dataset, we aimed for roughly a 60% train
/ 20% development / 20% test split. See Table 2
for the detailed statistics. In order to examine the
influence of word senses in isolation, we use the hu-
man annotated POS, parse trees, and word senses
provided by OntoNotes. The lemma of each word is
extracted using WordNet tool.
</bodyText>
<subsectionHeader confidence="0.565746">
Training Developing Testing
</subsectionHeader>
<equation confidence="0.963364727272727">
669 163 138
ABC
(0001-0040) (0041-0054) (0057-0069)
1,691 964 1,146
CNN
(0001-0234) (0235-0331) (0333-0437)
381 130 125
MNB
(0001-0015) (0016-0020) (0021-0025)
351 129 86
NBC
(0001-0025) (0026-0032) (0033-0039)
1,205 384 387
PRI
(0001-0067) (0068-0090) (0091-0112)
1,238 325 331
VOA
(0001-0159) (0160-0212) (0213-0264)
8,592 2,552 3,432
WSJ
(0020-1446) (1447-1705) (1730-2454)
All 14,127 4,647 5,645
</equation>
<tableCaption confidence="0.99170025">
Table 2: Training, developing and testing set sizes for the
seven datasets in sentences. The file ranges (in parenthe-
sis) refer to the numbers within the names of the original
OntoNotes files.
</tableCaption>
<bodyText confidence="0.9918066">
The baseline SRL system without sense informa-
tion is trained with all the training corpus as de-
scribed in Section 3. Its performance on the devel-
opment data is F1 = 85.48%.
Table 3 shows the performance (F1) comparison
on the development data among different sense ex-
tracting strategies with different feature categories.
The numbers are the parameter n used in Hypernym
and Root Hyper strategies.
From Table 3, we can find that:
</bodyText>
<listItem confidence="0.774966">
1. Both of the predicate sense feature and the
sense path feature can improve the performance. For
</listItem>
<tableCaption confidence="0.995359666666667">
Table 3: The performance comparison on the devel-
opment data among different sense extracting strategies
with different feature categories.
</tableCaption>
<bodyText confidence="0.998272575757576">
the predicate sense feature, we arrive at the same
conclusion with Meza-Ruiz and Riedel (2009). As
for the sense path feature, it is more special than the
POS, therefore, it can enhance the precision.
2. The subtree-word related sense is almost use-
less. The reason is that the original lemma and POS
features have been able to describe the subtree-word
related information. This kind of sense features is
just reduplicate.
3. For different sense feature categories
(columns), the performance is not very seriously af-
fected by different sense extracting strategies (rows).
That is to say, once the sense of a word is disam-
biguated, the sense expressing form is not important
for SRL.
In order to further improve the performance,
we add the predicate sense and the sense path
features simultaneously. Here, we select the
Lemma+Sense strategy for the predicate sense and
the Root Hyper(1) strategy for the sense path. The
final performance achieves F1 = 86.44%, which is
about 1% higher than the baseline (F1 = 85.48%).
Finally, we compare the baseline (without sense)
result with the word sense result on the test data. In
order to see the contribution of correct word senses,
we introduce a simple sense determining strategy,
which use the first (the most popular) WordNet sense
for each word. The final detailed comparison results
are listed in Table 4.
Averagely, both of the methods with the first sense
and the correct sense can perform better than the
baseline. However, the improvement of the method
with the first sense is not significant (x2-test3 with
</bodyText>
<footnote confidence="0.96952">
3http://graphpad.com/quickcalcs/chisquared1.cfm
</footnote>
<page confidence="0.983508">
248
</page>
<table confidence="0.999757469387755">
Precision Recall F1
86.25 83.01 84.60
84.91 81.71 83.28
87.13 83.40 85.22
86.67 79.97 83.19
86.94 80.73 83.72
87.75 80.64 84.05
85.29 81.69 83.45
85.04 81.85 83.41
86.96 82.47 84.66
84.49 76.42 80.26
84.53 76.63 80.38
86.20 77.44 81.58
86.48 82.29 84.34
86.82 83.10 84.92
87.45 83.14 85.24
89.87 86.65 88.23
90.01 86.60 88.27
91.35 87.10 89.18
88.38 82.93 85.57
88.72 83.29 85.92
89.25 84.00 86.54
87.85 82.46 85.07
88.11 82.85 85.40
88.84 83.37 86.02
w/o sense
ABC first sense
word sense
w/o sense
CNN first sense
word sense
w/o sense
MNB first sense
word sense
w/o sense
NBC first sense
word sense
w/o sense
PRI first sense
word sense
w/o sense
VOA first sense
word sense
w/o sense
WSJ first sense
word sense
w/o sense
Avg first sense
word sense
</table>
<tableCaption confidence="0.70689">
Table 4: The testing performance comparison among
the baseline without (w/o) sense information, the method
with the first sense, and the method with the correct word
sense.
</tableCaption>
<bodyText confidence="0.999911333333333">
p &lt; 0.01). Especially, for some sections, such as
ABC and MNB, it is harmful to the performance. In
contrast, the correct word sense can improve the per-
formance significantly (x2-test with p &lt; 0.01)and
consistently. These can further prove that the word
sense can enhance the semantic role labeling.
</bodyText>
<sectionHeader confidence="0.999249" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.99995325">
This is the first effort to adopt the word sense
features into semantic role labeling. Experiments
show that the subtree-word related sense features
are ineffective, but the predicate sense and the sense
path features can improve the performance signifi-
cantly. In the future, we will use an automatic word
sense disambiguation (WSD) system to obtain word
senses and study the function of WSD for SRL.
</bodyText>
<sectionHeader confidence="0.995557" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.978754857142857">
This work was supported by National Natural
Science Foundation of China (NSFC) via grant
60803093, 60975055, the “863” National High-
Tech Research and Development of China via grant
2008AA01Z144, and Natural Scientific Research
Innovation Foundation in Harbin Institute of Tech-
nology (HIT.NSRIF.2009069).
</bodyText>
<sectionHeader confidence="0.997465" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999907951219512">
Adam L. Berger, Stephen A. Della Pietra, and Vincent
J. Della Pietra. 1996. A maximum entropy approach
to natural language processing. Computational Lin-
guistics, 22.
Marine Carpuat and Dekai Wu. 2007. Improving statisti-
cal machine translation using word sense disambigua-
tion. In Proceedings of EMNLP/CoNLL-2007, pages
61–72, Prague, Czech Republic, June.
Yee Seng Chan, Hwee Tou Ng, and David Chiang. 2007.
Word sense disambiguation improves statistical ma-
chine translation. In Proceedings of ACL-2007, pages
33–40, Prague, Czech Republic, June.
Wanxiang Che, Zhenghua Li, Yongqiang Li, Yuhang
Guo, Bing Qin, and Ting Liu. 2009. Multilingual
dependency-based syntactic and semantic parsing. In
Proceedings of CoNLL-2009, pages 49–54, Boulder,
Colorado, June.
Jenny Rose Finkel and Christopher D. Manning. 2009.
Joint parsing and named entity recognition. In Pro-
ceedings of NAACL/HLT-2009, pages 326–334, Boul-
der, Colorado, June.
Eduard Hovy, Mitchell Marcus, Martha Palmer, Lance
Ramshaw, and Ralph Weischedel. 2006. Ontonotes:
The 90% solution. In Proceedings of NAACL/HLT-
2006, pages 57–60, New York City, USA, June.
Rub´en Izquierdo, Armando Su´arez, and German Rigau.
2007. Exploring the automatic selection of basic level
concepts. In Proceedings of RANLP-2007.
Ivan Meza-Ruiz and Sebastian Riedel. 2009. Jointly
identifying predicates, arguments and senses using
markov logic. In Proceedings of NAACL/HLT-2009,
pages 155–163, Boulder, Colorado, June.
Mihai Surdeanu, Richard Johansson, Adam Meyers,
Lluis M`arquez, and Joakim Nivre. 2008. The conll
2008 shared task on joint parsing of syntactic and se-
mantic dependencies. In Proceedings of CoNLL-2008,
pages 159–177, Manchester, England, August.
Zhi Zhong, Hwee Tou Ng, and Yee Seng Chan. 2008.
Word sense disambiguation using OntoNotes: An em-
pirical study. In Proceedings of EMNLP-2008, pages
1002–1010, Honolulu, Hawaii, October.
</reference>
<page confidence="0.998915">
249
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.911102">
<title confidence="0.969620333333333">Improving Semantic Role Labeling with Word Sense Wanxiang Che, Ting Liu and Yongqiang Research Center for Information</title>
<author confidence="0.952249">MOE-Microsoft Key Laboratory of Natural Language Processing</author>
<affiliation confidence="0.998821">School of Computer Science and Harbin Institute of Technology, China,</affiliation>
<email confidence="0.991948">tliu,</email>
<abstract confidence="0.999733083333333">Semantic role labeling (SRL) not only needs lexical and syntactic information, but also needs word sense information. However, because of the lack of corpus annotated with both word senses and semantic roles, there is few research on using word sense for SRL. The release of OntoNotes provides an opportunity for us to study how to use word sense for SRL. In this paper, we present some novel word sense features for SRL and find that they can improve the performance significantly.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Adam L Berger</author>
<author>Stephen A Della Pietra</author>
<author>Vincent J Della Pietra</author>
</authors>
<title>A maximum entropy approach to natural language processing.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<volume>22</volume>
<contexts>
<context position="4458" citStr="Berger et al., 1996" startWordPosition="692" endWordPosition="695">can Chapter of the ACL, pages 246–249, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics trees into dependence trees with an Constituent-toDependency Conversion Tool2. In addition, we also convert the OntoNotes sense of each polysemant into WordNet sense using sense inventory file provided by OntoNotes 2.0. For an OntoNotes sense with more than one WordNet sense, we simply use the foremost (more popular) one. 3 Semantic Role Labeling System Our baseline is a state-of-the-art SRL system based on dependency syntactic tree (Che et al., 2009). A maximum entropy (Berger et al., 1996) classifier is used to predict the probabilities of a word in the sentence to be each semantic role. A virtual role “NULL” (presenting none of roles is assigned) is added to the roles set, so it does not need semantic role identification stage anymore. For a predicate, two classifiers (one for noun predicates, and the other for verb predicates) predict probabilities of each word in a sentence to be each semantic role (including virtual role “NULL”). The features used in this stage are listed in Table 1. Feature Description FirstwordLemma The lemma of the first word in a subtree HeadwordLemma T</context>
</contexts>
<marker>Berger, Pietra, Pietra, 1996</marker>
<rawString>Adam L. Berger, Stephen A. Della Pietra, and Vincent J. Della Pietra. 1996. A maximum entropy approach to natural language processing. Computational Linguistics, 22.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marine Carpuat</author>
<author>Dekai Wu</author>
</authors>
<title>Improving statistical machine translation using word sense disambiguation.</title>
<date>2007</date>
<booktitle>In Proceedings of EMNLP/CoNLL-2007,</booktitle>
<pages>61--72</pages>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="1548" citStr="Carpuat and Wu, 2007" startWordPosition="243" endWordPosition="246"> a hot task in natural language processing. SRL aims at identifying the relations between the predicates in a sentence and their associated arguments. At present, the main stream researches are focusing on feature engineering or combination of multiple results. Word senses are important information for recognizing semantic roles. For example, if we know “cat” is an “agent” of the predicate “eat” in a sentence, we can guess that “dog” can also be an “agent” of “eat”. Word sense has been successfully used in many natural language processing tasks, such as machine translation (Chan et al., 2007; Carpuat and Wu, 2007). CoNLL 2008 shared task (Surdeanu et al., 2008) first introduced the predicate classification task, which can be regarded as the predicate sense disambiguation. Meza-Ruiz and Riedel (2009) has shown that the predicate sense can improve the final SRL performance. However, there is few discussion about the concrete influence of all word senses, i.e. the words besides predicates. The major reason is lacking the corpus, which is both annotated with all word senses and semantic roles. The release of OntoNotes corpus provides an opportunity for us to verify whether all word senses can help SRL. Ont</context>
</contexts>
<marker>Carpuat, Wu, 2007</marker>
<rawString>Marine Carpuat and Dekai Wu. 2007. Improving statistical machine translation using word sense disambiguation. In Proceedings of EMNLP/CoNLL-2007, pages 61–72, Prague, Czech Republic, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yee Seng Chan</author>
<author>Hwee Tou Ng</author>
<author>David Chiang</author>
</authors>
<title>Word sense disambiguation improves statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of ACL-2007,</booktitle>
<pages>33--40</pages>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="1525" citStr="Chan et al., 2007" startWordPosition="239" endWordPosition="242">sis and is becoming a hot task in natural language processing. SRL aims at identifying the relations between the predicates in a sentence and their associated arguments. At present, the main stream researches are focusing on feature engineering or combination of multiple results. Word senses are important information for recognizing semantic roles. For example, if we know “cat” is an “agent” of the predicate “eat” in a sentence, we can guess that “dog” can also be an “agent” of “eat”. Word sense has been successfully used in many natural language processing tasks, such as machine translation (Chan et al., 2007; Carpuat and Wu, 2007). CoNLL 2008 shared task (Surdeanu et al., 2008) first introduced the predicate classification task, which can be regarded as the predicate sense disambiguation. Meza-Ruiz and Riedel (2009) has shown that the predicate sense can improve the final SRL performance. However, there is few discussion about the concrete influence of all word senses, i.e. the words besides predicates. The major reason is lacking the corpus, which is both annotated with all word senses and semantic roles. The release of OntoNotes corpus provides an opportunity for us to verify whether all word s</context>
</contexts>
<marker>Chan, Ng, Chiang, 2007</marker>
<rawString>Yee Seng Chan, Hwee Tou Ng, and David Chiang. 2007. Word sense disambiguation improves statistical machine translation. In Proceedings of ACL-2007, pages 33–40, Prague, Czech Republic, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wanxiang Che</author>
<author>Zhenghua Li</author>
<author>Yongqiang Li</author>
<author>Yuhang Guo</author>
<author>Bing Qin</author>
<author>Ting Liu</author>
</authors>
<title>Multilingual dependency-based syntactic and semantic parsing.</title>
<date>2009</date>
<booktitle>In Proceedings of CoNLL-2009,</booktitle>
<pages>49--54</pages>
<location>Boulder, Colorado,</location>
<contexts>
<context position="4417" citStr="Che et al., 2009" startWordPosition="685" endWordPosition="688">0 Annual Conference of the North American Chapter of the ACL, pages 246–249, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics trees into dependence trees with an Constituent-toDependency Conversion Tool2. In addition, we also convert the OntoNotes sense of each polysemant into WordNet sense using sense inventory file provided by OntoNotes 2.0. For an OntoNotes sense with more than one WordNet sense, we simply use the foremost (more popular) one. 3 Semantic Role Labeling System Our baseline is a state-of-the-art SRL system based on dependency syntactic tree (Che et al., 2009). A maximum entropy (Berger et al., 1996) classifier is used to predict the probabilities of a word in the sentence to be each semantic role. A virtual role “NULL” (presenting none of roles is assigned) is added to the roles set, so it does not need semantic role identification stage anymore. For a predicate, two classifiers (one for noun predicates, and the other for verb predicates) predict probabilities of each word in a sentence to be each semantic role (including virtual role “NULL”). The features used in this stage are listed in Table 1. Feature Description FirstwordLemma The lemma of th</context>
</contexts>
<marker>Che, Li, Li, Guo, Qin, Liu, 2009</marker>
<rawString>Wanxiang Che, Zhenghua Li, Yongqiang Li, Yuhang Guo, Bing Qin, and Ting Liu. 2009. Multilingual dependency-based syntactic and semantic parsing. In Proceedings of CoNLL-2009, pages 49–54, Boulder, Colorado, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny Rose Finkel</author>
<author>Christopher D Manning</author>
</authors>
<title>Joint parsing and named entity recognition.</title>
<date>2009</date>
<booktitle>In Proceedings of NAACL/HLT-2009,</booktitle>
<pages>326--334</pages>
<location>Boulder, Colorado,</location>
<contexts>
<context position="2442" citStr="Finkel and Manning, 2009" startWordPosition="387" endWordPosition="391">er, there is few discussion about the concrete influence of all word senses, i.e. the words besides predicates. The major reason is lacking the corpus, which is both annotated with all word senses and semantic roles. The release of OntoNotes corpus provides an opportunity for us to verify whether all word senses can help SRL. OntoNotes is a large corpus annotated with constituency trees (based on Penn Treebank), predicate argument structures (based on Penn PropBank) and word senses. It has been used in some natural language processing tasks, such as joint parsing and named entity recognition (Finkel and Manning, 2009) and word sense disambiguation (Zhong et al., 2008). In this paper, we regard the word sense information as additional SRL features. We compare three categories of word sense features (subtree-word related sense, predicate sense, and sense path) and find that the subtree-word related sense feature is ineffective, however, the predicate sense and the sense path features can improve the SRL performance significantly. 2 Data Preparation In our experiments, we use the OntoNotes Release 2.01 corpus (Hovy et al., 2006). The OntoNotes project leaders describe it as “a large, multilingual richly-annot</context>
</contexts>
<marker>Finkel, Manning, 2009</marker>
<rawString>Jenny Rose Finkel and Christopher D. Manning. 2009. Joint parsing and named entity recognition. In Proceedings of NAACL/HLT-2009, pages 326–334, Boulder, Colorado, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eduard Hovy</author>
<author>Mitchell Marcus</author>
<author>Martha Palmer</author>
<author>Lance Ramshaw</author>
<author>Ralph Weischedel</author>
</authors>
<title>Ontonotes: The 90% solution.</title>
<date>2006</date>
<booktitle>In Proceedings of NAACL/HLT2006,</booktitle>
<pages>57--60</pages>
<location>New York City, USA,</location>
<contexts>
<context position="2960" citStr="Hovy et al., 2006" startWordPosition="471" endWordPosition="474">uage processing tasks, such as joint parsing and named entity recognition (Finkel and Manning, 2009) and word sense disambiguation (Zhong et al., 2008). In this paper, we regard the word sense information as additional SRL features. We compare three categories of word sense features (subtree-word related sense, predicate sense, and sense path) and find that the subtree-word related sense feature is ineffective, however, the predicate sense and the sense path features can improve the SRL performance significantly. 2 Data Preparation In our experiments, we use the OntoNotes Release 2.01 corpus (Hovy et al., 2006). The OntoNotes project leaders describe it as “a large, multilingual richly-annotated corpus constructed at 90% internanotator agreement.” The corpus has been annotated with multiple levels of annotation, including constituency trees, predicate argument structure, word senses, co-reference, and named entities. For this work, we focus on the constituency trees, word senses, and predicate argument structures. The corpus has English and Chinese portions, and we just use the English portion, which has been split into seven sections: ABC, CNN, MNB, NBC, PRI, VOA, and WSJ. These sections represent </context>
</contexts>
<marker>Hovy, Marcus, Palmer, Ramshaw, Weischedel, 2006</marker>
<rawString>Eduard Hovy, Mitchell Marcus, Martha Palmer, Lance Ramshaw, and Ralph Weischedel. 2006. Ontonotes: The 90% solution. In Proceedings of NAACL/HLT2006, pages 57–60, New York City, USA, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rub´en Izquierdo</author>
<author>Armando Su´arez</author>
<author>German Rigau</author>
</authors>
<title>Exploring the automatic selection of basic level concepts.</title>
<date>2007</date>
<booktitle>In Proceedings of RANLP-2007.</booktitle>
<marker>Izquierdo, Su´arez, Rigau, 2007</marker>
<rawString>Rub´en Izquierdo, Armando Su´arez, and German Rigau. 2007. Exploring the automatic selection of basic level concepts. In Proceedings of RANLP-2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Meza-Ruiz</author>
<author>Sebastian Riedel</author>
</authors>
<title>Jointly identifying predicates, arguments and senses using markov logic.</title>
<date>2009</date>
<booktitle>In Proceedings of NAACL/HLT-2009,</booktitle>
<pages>155--163</pages>
<location>Boulder, Colorado,</location>
<contexts>
<context position="1737" citStr="Meza-Ruiz and Riedel (2009)" startWordPosition="271" endWordPosition="274">arches are focusing on feature engineering or combination of multiple results. Word senses are important information for recognizing semantic roles. For example, if we know “cat” is an “agent” of the predicate “eat” in a sentence, we can guess that “dog” can also be an “agent” of “eat”. Word sense has been successfully used in many natural language processing tasks, such as machine translation (Chan et al., 2007; Carpuat and Wu, 2007). CoNLL 2008 shared task (Surdeanu et al., 2008) first introduced the predicate classification task, which can be regarded as the predicate sense disambiguation. Meza-Ruiz and Riedel (2009) has shown that the predicate sense can improve the final SRL performance. However, there is few discussion about the concrete influence of all word senses, i.e. the words besides predicates. The major reason is lacking the corpus, which is both annotated with all word senses and semantic roles. The release of OntoNotes corpus provides an opportunity for us to verify whether all word senses can help SRL. OntoNotes is a large corpus annotated with constituency trees (based on Penn Treebank), predicate argument structures (based on Penn PropBank) and word senses. It has been used in some natural</context>
<context position="9741" citStr="Meza-Ruiz and Riedel (2009)" startWordPosition="1556" endWordPosition="1559"> the development data is F1 = 85.48%. Table 3 shows the performance (F1) comparison on the development data among different sense extracting strategies with different feature categories. The numbers are the parameter n used in Hypernym and Root Hyper strategies. From Table 3, we can find that: 1. Both of the predicate sense feature and the sense path feature can improve the performance. For Table 3: The performance comparison on the development data among different sense extracting strategies with different feature categories. the predicate sense feature, we arrive at the same conclusion with Meza-Ruiz and Riedel (2009). As for the sense path feature, it is more special than the POS, therefore, it can enhance the precision. 2. The subtree-word related sense is almost useless. The reason is that the original lemma and POS features have been able to describe the subtree-word related information. This kind of sense features is just reduplicate. 3. For different sense feature categories (columns), the performance is not very seriously affected by different sense extracting strategies (rows). That is to say, once the sense of a word is disambiguated, the sense expressing form is not important for SRL. In order to</context>
</contexts>
<marker>Meza-Ruiz, Riedel, 2009</marker>
<rawString>Ivan Meza-Ruiz and Sebastian Riedel. 2009. Jointly identifying predicates, arguments and senses using markov logic. In Proceedings of NAACL/HLT-2009, pages 155–163, Boulder, Colorado, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mihai Surdeanu</author>
<author>Richard Johansson</author>
<author>Adam Meyers</author>
<author>Lluis M`arquez</author>
<author>Joakim Nivre</author>
</authors>
<title>The conll 2008 shared task on joint parsing of syntactic and semantic dependencies.</title>
<date>2008</date>
<booktitle>In Proceedings of CoNLL-2008,</booktitle>
<pages>159--177</pages>
<location>Manchester, England,</location>
<marker>Surdeanu, Johansson, Meyers, M`arquez, Nivre, 2008</marker>
<rawString>Mihai Surdeanu, Richard Johansson, Adam Meyers, Lluis M`arquez, and Joakim Nivre. 2008. The conll 2008 shared task on joint parsing of syntactic and semantic dependencies. In Proceedings of CoNLL-2008, pages 159–177, Manchester, England, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhi Zhong</author>
<author>Hwee Tou Ng</author>
<author>Yee Seng Chan</author>
</authors>
<title>Word sense disambiguation using OntoNotes: An empirical study.</title>
<date>2008</date>
<booktitle>In Proceedings of EMNLP-2008,</booktitle>
<pages>1002--1010</pages>
<location>Honolulu, Hawaii,</location>
<contexts>
<context position="2493" citStr="Zhong et al., 2008" startWordPosition="396" endWordPosition="399">of all word senses, i.e. the words besides predicates. The major reason is lacking the corpus, which is both annotated with all word senses and semantic roles. The release of OntoNotes corpus provides an opportunity for us to verify whether all word senses can help SRL. OntoNotes is a large corpus annotated with constituency trees (based on Penn Treebank), predicate argument structures (based on Penn PropBank) and word senses. It has been used in some natural language processing tasks, such as joint parsing and named entity recognition (Finkel and Manning, 2009) and word sense disambiguation (Zhong et al., 2008). In this paper, we regard the word sense information as additional SRL features. We compare three categories of word sense features (subtree-word related sense, predicate sense, and sense path) and find that the subtree-word related sense feature is ineffective, however, the predicate sense and the sense path features can improve the SRL performance significantly. 2 Data Preparation In our experiments, we use the OntoNotes Release 2.01 corpus (Hovy et al., 2006). The OntoNotes project leaders describe it as “a large, multilingual richly-annotated corpus constructed at 90% internanotator agree</context>
</contexts>
<marker>Zhong, Ng, Chan, 2008</marker>
<rawString>Zhi Zhong, Hwee Tou Ng, and Yee Seng Chan. 2008. Word sense disambiguation using OntoNotes: An empirical study. In Proceedings of EMNLP-2008, pages 1002–1010, Honolulu, Hawaii, October.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>