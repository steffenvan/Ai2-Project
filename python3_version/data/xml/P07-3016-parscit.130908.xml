<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000728">
<title confidence="0.975699">
Clustering Hungarian Verbs on the Basis of Complementation Patterns
</title>
<author confidence="0.996343">
Kata G´abor
</author>
<affiliation confidence="0.837639">
Dept. of Language Technology
Linguistics Institute, HAS
</affiliation>
<address confidence="0.63089">
1399 Budapest, P. O. Box 701/518
Hungary
</address>
<email confidence="0.996902">
gkata@nytud.hu
</email>
<author confidence="0.987185">
Enik˝o H´eja
</author>
<affiliation confidence="0.834887">
Dept. of Language Technology
Linguistics Institute, HAS
</affiliation>
<address confidence="0.6316005">
1399 Budapest, P. O. Box 701/518
Hungary
</address>
<email confidence="0.998014">
eheja@nytud.hu
</email>
<sectionHeader confidence="0.995626" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999936533333333">
Our paper reports an attempt to apply an un-
supervised clustering algorithm to a Hun-
garian treebank in order to obtain seman-
tic verb classes. Starting from the hypo-
thesis that semantic metapredicates underlie
verbs’ syntactic realization, we investigate
how one can obtain semantically motivated
verb classes by automatic means. The 150
most frequent Hungarian verbs were clus-
tered on the basis of their complementation
patterns, yielding a set of basic classes and
hints about the features that determine ver-
bal subcategorization. The resulting classes
serve as a basis for the subsequent analysis
of their alternation behavior.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999891163265307">
For over a decade, automatic construction of wide-
coverage structured lexicons has been in the center
of interest in the natural language processing com-
munity. On the one hand, structured lexical data-
bases are easier to handle and to expand because
they allow making generalizations over classes of
words. On the other hand, interest in the automatic
acquisition of lexical information from corpora is
due to the fact that manual construction of such re-
sources is time-consuming, and the resulting data-
base is difficult to update. Most of the work in
the field of acquisition of verbal lexical properties
aims at learning subcategorization frames from cor-
pora e.g. (Pereira et al., 1993; Briscoe and Car-
roll, 1997; Sass, 2006). However, semantic group-
ing of verbs on the basis of their syntactic distribu-
tion or other quantifiable features has also gained at-
tention (Schulte im Walde, 2000; Schulte im Walde
and Brew, 2002; Merlo and Stevenson, 2001; Dorr
and Jones, 1996). The goal of these investigations is
either the validation of verb classes based on (Levin,
1993), or finding algorithms for the categorization of
new verbs.
Unlike these projects, we report an attempt to
cluster verbs on the basis of their syntactic proper-
ties with the further goal of identifying the seman-
tic classes relevant for the description of Hungarian
verbs’ alternation behavior. The theoretical ground-
ing of our clustering attempts is provided by the
so-called Semantic Base Hypothesis (Levin, 1993;
Koenig et al., 2003). It is founded on the observation
that semantically similar verbs tend to occur in simi-
lar syntactic contexts, leading to the assumption that
verbal semantics determines argument structure and
the surface realization of arguments. While in Eng-
lish semantic argument roles are mapped to confi-
gurational positions in the tree structure, Hungarian
codes complement structure in its highly rich nom-
inal inflection system. Therefore, we start from the
examination of case-marked NPs in the context of
verbs.
The experiment discussed in this paper is the first
stage of an ongoing project for finding the semantic
verb classes which are syntactically relevant in Hun-
garian. As we do not have presuppositions about
which classes have to be used, we chose an unsu-
pervised clustering method described in (Schulte
im Walde, 2000). The 150 most frequent Hunga-
rian verbs were categorized according to their comp-
</bodyText>
<page confidence="0.984847">
91
</page>
<bodyText confidence="0.8722946">
Proceedings of the ACL 2007 Student Research Workshop, pages 91–96,
Prague, June 2007. c�2007 Association for Computational Linguistics
lementation structures in a syntactically annotated
corpus, the Szeged Treebank (Csendes et al., 2005).
We are seeking the answer to two questions:
</bodyText>
<listItem confidence="0.9917254">
1. Are the resulting clusters semantically coherent
(thus reinforcing the Semantic Base Hypothe-
sis)?
2. If so, what are the alternations responsible for
their similar behavior?
</listItem>
<bodyText confidence="0.9980375">
The subsequent sections present the input features
[2] and the clustering methods [3], followed by the
presentation of our results [4]. Problematic issues
raised by the evaluation are discussed in [5]. Future
work is outlined in [6]. The paper ends with the con-
clusions [7].
</bodyText>
<sectionHeader confidence="0.980428" genericHeader="method">
2 Feature Space
</sectionHeader>
<bodyText confidence="0.999932717948718">
As currently available Hungarian parsers (Babarczy
et al., 2005; G´abor and H´eja, 2005) cannot be used
satisfactorily for extracting verbal argument struc-
tures from corpora, the first experiment was carried
out using a manually annotated Hungarian corpus,
the Szeged Treebank. Texts of the corpus come from
different topic areas such as business news, daily
news, fiction, law, and compositions of students. It
currently comprises 1.2 million words with POS tag-
ging and syntactic annotation which extends to top-
level sentence constituents but does not differentiate
between complements and adjuncts.
When applying a classification or clustering algo-
rithm to a corpus, a crucial question is which quan-
tifiable features reflect the most precisely the lin-
guistic properties underlying word classes. (Brent,
1993) uses regular patterns. (Schulte im Walde,
2000; Schulte im Walde and Brew, 2002; Briscoe
and Carroll, 1997) use subcategorization frame
frequencies obtained from parsed corpora, poten-
tially completed by semantic selection information.
(Merlo and Stevenson, 2001) approximates diathesis
alternations by hand-selected grammatical features.
While this method has the advantage of working on
POS-tagged, unparsed corpora, it is costly with res-
pect to time and linguistic expertise. To overcome
this drawback, (Joanis and Stevenson, 2003) de-
velop a general feature space for supervised verb
classification. (Stevenson and Joanis, 2003) inves-
tigate the applicability of this general feature space
to unsupervised verb clustering tasks. As unsuper-
vised methods are more sensitive to noisy features,
the key issue is to filter out the large number of
probably irrelevant features. They propose a semi-
supervised feature selection method which outper-
forms both hand-selection of features and usage of
the full feature set.
As in our experiment we do not have a pre-defined
set of semantic classes, we need to apply unsu-
pervised methods. Neither have we manually de-
fined grammatical cues, not knowing which alter-
nations should be approximated. Hence, similarly
to (Schulte im Walde, 2000), we represent verbs by
their subcategorization frames.
In accordance with the annotation of the treebank,
we included both complements and adjuncts in sub-
categorization patterns. It is important to note, how-
ever, that not only practical considerations lead us
to this decision. First, there are no reliable syntactic
tests for differentiating complements from adjuncts.
This is due to the fact that Hungarian is a highly in-
flective, non-configurational language, where con-
stituent order does not reveal dependency relations.
Indeed, complements and adjuncts of verbs tend to
mingle. In parallel, Hungarian presents a very rich
nominal inflection system: there are 19 case suf-
fixes, and most of them can correspond to more than
one syntactic function, depending on the verb class
they occur with. Second, we believe that adjuncts
can be at least as revealing of verbal meaning as
complements are: many of them are not productive
(in the sense that they cannot be added to any verb),
they can only appear with predicates the meaning of
which is compatible with the semantic role of the ad-
junct. For these considerations we chose to include
both complements and adjuncts in subcategorization
patterns.
Subcategorization frames to be extracted from
the treebank are composed of case-marked NPs
and infinitives that belong to a children node of
the verb’s maximal projection. As Hungarian is a
non-configurational language, this operation simply
yields a non-ordered list of the verb’s syntactic de-
pendents. There was no upper bound on the num-
ber of syntactic dependents to be included in the
frame. Frame types were obtained from individual
frames by omitting lexical information as well as
every piece of morphosyntactic description except
</bodyText>
<page confidence="0.977582">
92
</page>
<bodyText confidence="0.9998205">
for the POS tag and the case suffix. The generaliza-
tion yielded 839 frame types altogether.1
</bodyText>
<sectionHeader confidence="0.998934" genericHeader="method">
3 Clustering Methods
</sectionHeader>
<bodyText confidence="0.999670555555556">
In accordance with our goal to set up a basis for
a semantic classification, we chose to perform the
first clustering trial on the 150 most frequent verbs
in the Szeged Treebank. The representation of verbs
and the clustering process were carried out based on
(Schulte im Walde, 2000). The data to be compared
were the maximum likelihood estimates of the pro-
bability distribution of verbs over the possible frame
types:
</bodyText>
<equation confidence="0.9981115">
p(t|v) = f(v, t) (1)
f(v)
</equation>
<bodyText confidence="0.999426833333333">
with f(v) being the frequency of the verb, and
f(v, t) being the frequency of the verb in the frame.
These values have been calculated for each of the
150 verbs and 839 frame types.
Probability distributions were compared using re-
lative entropy as a distance measure:
</bodyText>
<equation confidence="0.988914">
D(xlly) =
</equation>
<bodyText confidence="0.99966575">
Due to the large number of subcategorization
frame types, verbs’ representation comprise a lot of
zero probability figures. Using relative entropy as
a distance measure compels us to apply a smoothing
technique to be able to deal with these figures. How-
ever, we do not want to lose the information coded
in zero frequencies - namely, the presumable incom-
patibility of the verb with certain semantic roles as-
sociated with specific case suffixes. Since we work
with the 150 most frequent verbs, we wish to use
a method which is apt to reflect that a gap in the
case of a high-frequency lemma is more likely to be
an impossible event than in the case of a relatively
less frequent lemma (where it might as well be acci-
dental). That is why we have chosen the smoothing
technique below:
</bodyText>
<equation confidence="0.995388">
0,001 if
fe = f (v)
fc(t, v) = 0
</equation>
<footnote confidence="0.855801">
1The order in which syntactic dependents appear in the sen-
tence was not taken into account.
</footnote>
<bodyText confidence="0.9989555">
where fe is the estimated and f, is the observed fre-
quency.
Two alternative bottom-up clustering algorithms
were then applied to the data:
</bodyText>
<listItem confidence="0.772197647058823">
1. First we employed an agglomerative clustering
method, starting from 150 singleton clusters.
At every iteration we merged the two most sim-
ilar clusters and re-counted the distance mea-
sures. The problem with this approach, as
Schulte im Walde notes on her experiment, is
that verbs tend to gather in a small number of
big classes after a few iterations. To avoid this,
we followed her in setting to four the maximum
number of elements occuring in a cluster. This
method - and the size of the corpus - allowed
us to categorize 120 out of 150 verbs into 38
clusters, as going on with the process would
have led us to considerably less coherent clus-
ters. However, the results confronted us with
the chaining effect, i.e. some of the clusters
had a relatively big distance between their least
similar members.
2. In the second experiment we put a restriction
on the distance between each pair of verbs be-
longing to the same cluster. That is, in order for
a new verb to be added to a cluster, its distance
from all of the current cluster members had to
be smaller than the maximum distance stated
based on test runs. In this experiment we could
categorize 71 verbs into 23 clusters. The con-
venience of this method over the first one is its
ability to produce popular yet coherent clusters,
which is a particularly valuable feature given
that our goal at this stage is to establish basic
verb classes for Hungarian. However, we are
also planning to run a top-down clustering al-
gorithm on the data to get a probably more pre-
cise overview of their structure.
</listItem>
<sectionHeader confidence="0.999924" genericHeader="method">
4 Results
</sectionHeader>
<bodyText confidence="0.998758">
With both methods we describe in Section 3, a big
part of the verbs showed a tendency to gather to-
gether in a few but popular clusters, while the rest
of them were typically paired with their nearest
synonym (e.g.: z´ar (close) with v´egez (finish) or
antonym (e.g.: ¨ul (sit) with ´all (stand)). Naturally,
</bodyText>
<figure confidence="0.535096285714286">
xi
xi · log
yi
n
i=1
(2)
(3)
</figure>
<page confidence="0.981212">
93
</page>
<bodyText confidence="0.954849732142857">
method 1 (i.e. placing an upper limit on the num-
ber of verbs within a cluster) produced more clus-
ters and gave more valuable results on the least fre-
quent verbs. On the other hand, method 2 (i.e. plac-
ing an upper limit on the distance between each pair
of verbs within the class) is more efficient for iden-
tifying basic verb classes with a lot of members.
Given our objective to provide a Levin-type classi-
fication for Hungarian, we need to examine whether
the clusters are semantically coherent, and if so,
what kind of semantic properties are shared among
class members. The three most popular verb clusters
were investigated first, because they contain many
of the most frequent verbs and yet are characterized
by strong inter-cluster coherence due to the method
used. The three clusters absorbed one third of the 71
categorized verbs. The clusters are the following:
C-1 VERBS OF BEING: marad (remain), van (be),
lesz (become), nincs (not being)
C-2 MODALS: megpr´ob´al (try out), pr´ob´al (try),
szokik (used to), szeret (like), akar (want),
elkezd (start), fog (will), k´ıv´an (wish), kell
(must)
C-3 MOVEMENT VERBS: indul (leave), j¨on (come),
elindul (depart), megy (go), kimegy (go out),
elmegy (go away)
Verb clusters C-1 and C-3 exhibit intuitively
strong semantic coherence, whereas C-2 is best de-
fined along syntactic lines as ’modals’. A subclass
of C-2 is composed of verbs which express some
mental attitude towards undertaking an action, e.g.
(szeret (like), akar (want), k´ıv´an (wish)), but for the
rest of the verbs it is hard to capture shared meaning
components.
It can be said in general about the clusters ob-
tained that many of them can be anchored to ge-
neral semantic metapredicates or one of the argu-
ments’ semantic role, e.g.: CHANGE OF STATE
VERBS (er˝os¨odik (get stronger), gyeng¨ul (intransi-
tive weaken), emelkedik (intransitive rise)), verbs
with a beneficiary role (biztos´ıt (guarantee), ad
(give), ny´ujt (provide), k´esz´ıt(make)), VERBS OF
ABILITY (siker¨ul (succeed), lehet (be possible), tud
(be able, can)). Some clusters seem to result from a
tighter semantic relation, e.g. VERBS OF APPEA-
RANCE or VERBS OF JUDGEMENT were put to-
gether. In other cases the relation is broader as verbs
belonging to the class seem to share only aspectual
characteristics, e.g. AGENTIVE VERBS OF CONTI-
NUOS ACTIVITIES (¨ul (be sitting), ´all (be standing),
lakik (live somewhere), dolgozik (work)). At the
other end of the scale we find one group of verbs
which ’accidentally’ share the same syntactic pat-
terns without being semantically related (foglalkozik
(deal with sg), tal´alkozik (meet sy), rendelkezik (dis-
pose of sg)).
</bodyText>
<sectionHeader confidence="0.993151" genericHeader="evaluation">
5 Evaluation and Discussion
</sectionHeader>
<bodyText confidence="0.999987">
As (Schulte im Walde, 2007) notes, there is no
widely accepted practice of evaluating semantic
verb classes. She divides the methods into two major
classes. The first type of methods assess whether the
resulting clusters are coherent enough, i. e. elements
belonging to the same cluster are closer to each other
than to elements outside the class, according to an
independent similarity/distance measure. However,
relying on such a method would not help us eva-
luating the semantic coherence of our classes. The
second type of methods use gold standards. Widely
accepted gold standards in this field are Levin’s verb
classes or verbal WordNets. As we do not dispose
of a Hungarian equivalent of Levin’s classification
– that is exactly why we experiment with automatic
clustering – we cannot use it directly.
We also run across difficulties when considering
Hungarian verbal WordNet (Kuti et al., 2005) as the
standard for evaluation. Mapping verb clusters to
the net would require to state semantic relatedness
in terms of WordNet-type hierarchy relations. How-
ever, if we try to capture the distance between verbal
meanings by the number of intermediary nodes in
the WordNet, we face the problem that the semantic
distance between mother-children nodes is not uni-
form.
As our work is about obtaining a Levin-type verb
classification, it could be an obvious choice to eva-
luate semantic classes by collecting alternations spe-
cific to the given class. Hungarian language hardly
lends itself to this method because of its peculiar
syntactic features. The large number of subcatego-
rization frames and the optionality of most comple-
ments and adjuncts yield too much possible alterna-
</bodyText>
<page confidence="0.997548">
94
</page>
<table confidence="0.9657084">
acc ins abl ela
marad - com cause material
van - com cause material
lesz - com cause material
nincs - com cause material
</table>
<tableCaption confidence="0.678727">
Table 2: The semantic roles of cases beside C-1 verb
cluster
</tableCaption>
<table confidence="0.99954">
acc ins abl ela
indul - ins/com source source
j¨on - ins/com source source
elindul - ins/com source source
megy - ins/com source source
kimegy - ins/com source source
elmegy - ins/com source source
</table>
<tableCaption confidence="0.9113395">
Table 1: The semantic roles of cases beside C-3 verb
cluster
</tableCaption>
<bodyText confidence="0.998066235294118">
tions. Hence, we decided to narrow down the scope
of investigation. We start from verb clusters and the
meaning components their members share. Then we
attempt to discover which semantic roles can be li-
cenced by these meaning components. If verbs in
the same cluster agree both in being compatible with
the same semantic roles and in the syntactic encod-
ing of these roles, we consider that they form a cor-
rect cluster.
To put it somewhat more formally, we represent
verb classes by matrices with a) nominal case suf-
fixes in columns and b) individual verb lemmata in
rows. The first step of the evaluation process is to fill
in the cells with the semantic roles the given suffix
can code in the context of the verb. We consider the
clusters correct, if the corresponding matrices meet
two requirements:
</bodyText>
<listItem confidence="0.986726333333333">
1. They have to be specific to the cluster.
2. Cells in the same column have to contain the
same semantic role.
</listItem>
<bodyText confidence="0.986251818181818">
Tables 1. and 2. illustrate coherent and distinctive
case matrices2.
According to Table 1. ablative case, just as e-
lative, codes a physical source in the environment
of movement verbs. Both cases having the same
semantic role, the decision between them is deter-
mined by the semantics of the corresponding NP.
These cases code an other semantic role – cause –
in the case of verbs of existence (Table 2).
It is important to note that we do not dispose of a
preliminary list of semantic roles. To avoid arbitrary
</bodyText>
<footnote confidence="0.56414375">
2Com is for comitative – approximately encoding the mean-
ing ’together with’ , ins is for the instrument of the described
event, source denotes a starting point in the space, cause refers
to entity which evoked the eventuality described by the verb.
</footnote>
<bodyText confidence="0.990237666666667">
or vague role specifications, we need more than one
persons to fill in the cells, based on example sen-
tences.
</bodyText>
<sectionHeader confidence="0.9999" genericHeader="evaluation">
6 Future Work
</sectionHeader>
<bodyText confidence="0.999995115384616">
There are two major directions regarding our fu-
ture work. With respect to the automatic cluster-
ing process, we have the intention of widening the
scope of the grammatical features to be compared
by enriching subcategorization frames by other mor-
phological properties. We are also planning to test
top-down clustering methods such as the one de-
scribed in (Pereira et al., 1993). On the long run, it
will be inevitable to make experiments on larger cor-
pora. The obvious choice is the 180 million words
Hungarian National Corpus (V´aradi, 2002). It is a
POS-tagged corpus but does not contain any syntac-
tic annotation; hence its use would require at least
some partial parsing such as NP analysis to be em-
ployable for our purposes. The other future direc-
tion concerns evaluation and linguistic analysis of
verb clusters. We define well-founded verb classes
on the basis of semantic role matrices. These se-
mantic roles can be filled in a sentence by case-
marked NPs. Therefore, evaluation of automatically
obtained clusters presupposes the definition of such
matrices, which is our major linguistic task in the
future. When we have the supposed matrices at our
disposal, we can start evaluating the clusters via ex-
ample sentences which illustrate case suffix alterna-
tions or roles characteristic to specific classes.
</bodyText>
<sectionHeader confidence="0.999505" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.99765175">
The experiment of clustering the 150 most frequent
Hungarian verbs is the first step towards finding the
semantic verb classes underlying verbs’ syntactic
distribution. As we did not have presuppositions
</bodyText>
<page confidence="0.996136">
95
</page>
<bodyText confidence="0.999987285714286">
about the relevant classes, neither any gold standard
for automatic evaluation, the results have to serve
as input for a detailed linguistic analysis to find out
at what extent they are usable for the syntactic des-
cription of Hungarian. However, as demonstrated
in Section 4, the verb clusters we got show surpris-
ingly transparent semantic coherence. These results,
obtained from a corpus which is by several orders of
magnitude smaller than what is usual for such pur-
poses, is a reinforcement of the usability of the Se-
mantic Base Hypothesis for language analysis. Our
further work will emphasize both the refinement of
the clustering methods and the linguistic interpre-
tation of the resulting classes.
</bodyText>
<sectionHeader confidence="0.998706" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.990279321428572">
Anna Babarczy, B´alint G´abor, G´abor Hamp, Andr´as
K´arp´ati, Andr´as Rung and Istv´an Szakad´at. 2005.
Hunpars: mondattani elemz˝o alkalmaz´as [Hunpars: A
rule-based sentence parser for Hungarian]. Proceed-
ings of the 3th Hungarian Conference of Computa-
tional Linguistics (MSZNY05), pages 20-28, Szeged,
Hungary.
Michael R. Brent. 1993. From grammar to lexicon: un-
supervised learning of lexical syntax. Computational
Linguistics, 19(2):243–262, MIT Press, Cambridge,
MA, USA.
Ted Briscoe and John Carroll. 1997. Automatic Extrac-
tion of Subcategorization from Corpora. Proceedings
of the 5th Conference on Applied Natural Language
Processing (ANLP-97), pages 356–363, Washington,
DC, USA.
D´ora Csendes, J´anos Csirik, Tibor Gyim´othy and Andr´as
Kocsor. 2005. The Szeged Treebank. LNCS series
Vol. 3658, 123-131.
Bonnie J. Dorr and Doug Jones. 1996. Role of Word
Sense Disambiguation in Lexical Acquisition: Predict-
ing Semantics from Syntactic Cues. Proceedings of
the 14th International Conference on Computational
Linguistics (COLING-96), pages 322–327, Kopen-
hagen, Denmark.
Kata G´abor and Enik˝o H´eja. 2005. Vonzatok ´es sza-
bad hat´aroz´ok szab´alyalap´u kezel´ese [A Rule-based
Analysis of Complements and Adjuncts]. Proceedings
of the 3th Hungarian Conference of Computational
Linguistics (MSZNY05), pages 245-256, Szeged, Hun-
gary.
Eric Joanis and Suzanne Stevenson. 2003. A general
feature space for automatic verb classification. Pro-
ceedings of the 10th Conference of the EACL (EACL
2003), pages 163–170, Budapest, Hungary.
Jean-Pierre Koenig, Gail Mauner and Breton Bienvenue.
2003. Arguments for Adjuncts. Cognition, 89, 67-
103.
Judit Kuti, P´eter Vajda and K´aroly Varasdi. 2005.
Javaslat a magyar igei WordNet kialakit´as´ara [Pro-
posal for Developing the Hungarian WordNet of
Verbs]. Proceedings of the 3th Hungarian Conference
of Computational Linguistics (MSZNY05), pages 79–
87, Szeged, Hungary.
Beth Levin. 1993. English Verb Classes And Alterna-
tions: A Preliminary Investigation. Chicago Univer-
sity Press.
Paola Merlo and Suzanne Stevenson. 2001. Automatic
Verb Classification Based on Statistical Distributions
of Argument Structure. Computational Linguistics,
27(3), pages 373-408.
Fernando C. N. Pereira, Naftali Tishby and Lillan Lee.
1993. Distributional Clustering of English Words.
31st Annual Meeting of the ACL, pages 183-190,
Columbus, Ohio, USA.
B´alint Sass. 2006. Igei vonzatkeretek az MNSZ tagmon-
dataiban [Exploring Verb Frames in the Hungarian Na-
tional Corpus]. Proceedings of the 4th Hungarian
Conference of Computational Linguistics (MSZNY06),
pages 15–22, Szeged, Hungary.
Sabine Schulte im Walde. 2000. Clustering Verbs Se-
mantically According to their Alternation Behaviour.
Proceedings of the 18th International Conference on
Computational Linguistics (COLING-00), pages 747–
753, Saarbr¨ucken, Germany.
Sabine Schulte im Walde and Chris Brew. 2002. Induc-
ing German Semantic Verb Classes from Purely Syn-
tactic Subcategorisation Information. Proceedings of
the 40th Annual Meeting of the Association for Com-
putational Linguistics, pages 223-230, Philadelphia,
PA.
Sabine Schulte im Walde. to appear. The Induction of
Verb Frames and Verb Classes from Corpora. Corpus
Linguistics. An International Handbook., Anke L¨ude-
ling and Merja Kyt¨o (eds). Mouton de Gruyter, Berlin.
Suzanne Stevenson and Eric Joanis. 2003. Semi-
supervised Verb Class Discovery Using Noisy Fea-
tures. Proceedings of the 7th Conference on Computa-
tional Natural Language Learning (CoNLL-03), pages
71-78, Edmonton, Canada.
Tam´as V´aradi. 2002. The Hungarian National Corpus.
Proceedings of the Third International Conference on
Language Resources and Evaluation, pages 385–389,
Las Palmas, Spain.
</reference>
<page confidence="0.998456">
96
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.107102">
<title confidence="0.999885">Clustering Hungarian Verbs on the Basis of Complementation Patterns</title>
<author confidence="0.999976">Kata G´abor</author>
<affiliation confidence="0.922699">Dept. of Language Technology Linguistics Institute, HAS</affiliation>
<address confidence="0.999514">1399 Budapest, P. O. Box 701/518</address>
<affiliation confidence="0.428849">Hungary</affiliation>
<email confidence="0.990606">gkata@nytud.hu</email>
<author confidence="0.881484">Enik˝o H´eja</author>
<affiliation confidence="0.922684">Dept. of Language Technology Linguistics Institute, HAS</affiliation>
<address confidence="0.99953">1399 Budapest, P. O. Box 701/518</address>
<affiliation confidence="0.405873">Hungary</affiliation>
<email confidence="0.995218">eheja@nytud.hu</email>
<abstract confidence="0.9994634375">Our paper reports an attempt to apply an unsupervised clustering algorithm to a Hungarian treebank in order to obtain semantic verb classes. Starting from the hypothesis that semantic metapredicates underlie verbs’ syntactic realization, we investigate how one can obtain semantically motivated verb classes by automatic means. The 150 most frequent Hungarian verbs were clustered on the basis of their complementation patterns, yielding a set of basic classes and hints about the features that determine verbal subcategorization. The resulting classes serve as a basis for the subsequent analysis of their alternation behavior.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Anna Babarczy</author>
<author>B´alint G´abor</author>
<author>G´abor Hamp</author>
<author>Andr´as K´arp´ati</author>
<author>Andr´as Rung</author>
<author>Istv´an Szakad´at</author>
</authors>
<title>Hunpars: mondattani elemz˝o alkalmaz´as [Hunpars: A rule-based sentence parser for Hungarian].</title>
<date>2005</date>
<booktitle>Proceedings of the 3th Hungarian Conference of Computational Linguistics (MSZNY05),</booktitle>
<pages>20--28</pages>
<location>Szeged, Hungary.</location>
<marker>Babarczy, G´abor, Hamp, K´arp´ati, Rung, Szakad´at, 2005</marker>
<rawString>Anna Babarczy, B´alint G´abor, G´abor Hamp, Andr´as K´arp´ati, Andr´as Rung and Istv´an Szakad´at. 2005. Hunpars: mondattani elemz˝o alkalmaz´as [Hunpars: A rule-based sentence parser for Hungarian]. Proceedings of the 3th Hungarian Conference of Computational Linguistics (MSZNY05), pages 20-28, Szeged, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael R Brent</author>
</authors>
<title>From grammar to lexicon: unsupervised learning of lexical syntax.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA, USA.</location>
<contexts>
<context position="4939" citStr="Brent, 1993" startWordPosition="764" endWordPosition="765">s carried out using a manually annotated Hungarian corpus, the Szeged Treebank. Texts of the corpus come from different topic areas such as business news, daily news, fiction, law, and compositions of students. It currently comprises 1.2 million words with POS tagging and syntactic annotation which extends to toplevel sentence constituents but does not differentiate between complements and adjuncts. When applying a classification or clustering algorithm to a corpus, a crucial question is which quantifiable features reflect the most precisely the linguistic properties underlying word classes. (Brent, 1993) uses regular patterns. (Schulte im Walde, 2000; Schulte im Walde and Brew, 2002; Briscoe and Carroll, 1997) use subcategorization frame frequencies obtained from parsed corpora, potentially completed by semantic selection information. (Merlo and Stevenson, 2001) approximates diathesis alternations by hand-selected grammatical features. While this method has the advantage of working on POS-tagged, unparsed corpora, it is costly with respect to time and linguistic expertise. To overcome this drawback, (Joanis and Stevenson, 2003) develop a general feature space for supervised verb classificatio</context>
</contexts>
<marker>Brent, 1993</marker>
<rawString>Michael R. Brent. 1993. From grammar to lexicon: unsupervised learning of lexical syntax. Computational Linguistics, 19(2):243–262, MIT Press, Cambridge, MA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Briscoe</author>
<author>John Carroll</author>
</authors>
<title>Automatic Extraction of Subcategorization from Corpora.</title>
<date>1997</date>
<booktitle>Proceedings of the 5th Conference on Applied Natural Language Processing (ANLP-97),</booktitle>
<pages>356--363</pages>
<location>Washington, DC, USA.</location>
<contexts>
<context position="1682" citStr="Briscoe and Carroll, 1997" startWordPosition="255" endWordPosition="259">in the center of interest in the natural language processing community. On the one hand, structured lexical databases are easier to handle and to expand because they allow making generalizations over classes of words. On the other hand, interest in the automatic acquisition of lexical information from corpora is due to the fact that manual construction of such resources is time-consuming, and the resulting database is difficult to update. Most of the work in the field of acquisition of verbal lexical properties aims at learning subcategorization frames from corpora e.g. (Pereira et al., 1993; Briscoe and Carroll, 1997; Sass, 2006). However, semantic grouping of verbs on the basis of their syntactic distribution or other quantifiable features has also gained attention (Schulte im Walde, 2000; Schulte im Walde and Brew, 2002; Merlo and Stevenson, 2001; Dorr and Jones, 1996). The goal of these investigations is either the validation of verb classes based on (Levin, 1993), or finding algorithms for the categorization of new verbs. Unlike these projects, we report an attempt to cluster verbs on the basis of their syntactic properties with the further goal of identifying the semantic classes relevant for the des</context>
<context position="5047" citStr="Briscoe and Carroll, 1997" startWordPosition="779" endWordPosition="782">orpus come from different topic areas such as business news, daily news, fiction, law, and compositions of students. It currently comprises 1.2 million words with POS tagging and syntactic annotation which extends to toplevel sentence constituents but does not differentiate between complements and adjuncts. When applying a classification or clustering algorithm to a corpus, a crucial question is which quantifiable features reflect the most precisely the linguistic properties underlying word classes. (Brent, 1993) uses regular patterns. (Schulte im Walde, 2000; Schulte im Walde and Brew, 2002; Briscoe and Carroll, 1997) use subcategorization frame frequencies obtained from parsed corpora, potentially completed by semantic selection information. (Merlo and Stevenson, 2001) approximates diathesis alternations by hand-selected grammatical features. While this method has the advantage of working on POS-tagged, unparsed corpora, it is costly with respect to time and linguistic expertise. To overcome this drawback, (Joanis and Stevenson, 2003) develop a general feature space for supervised verb classification. (Stevenson and Joanis, 2003) investigate the applicability of this general feature space to unsupervised </context>
</contexts>
<marker>Briscoe, Carroll, 1997</marker>
<rawString>Ted Briscoe and John Carroll. 1997. Automatic Extraction of Subcategorization from Corpora. Proceedings of the 5th Conference on Applied Natural Language Processing (ANLP-97), pages 356–363, Washington, DC, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D´ora Csendes</author>
<author>J´anos Csirik</author>
<author>Tibor Gyim´othy</author>
<author>Andr´as Kocsor</author>
</authors>
<date>2005</date>
<booktitle>The Szeged Treebank. LNCS series</booktitle>
<volume>3658</volume>
<pages>123--131</pages>
<marker>Csendes, Csirik, Gyim´othy, Kocsor, 2005</marker>
<rawString>D´ora Csendes, J´anos Csirik, Tibor Gyim´othy and Andr´as Kocsor. 2005. The Szeged Treebank. LNCS series Vol. 3658, 123-131.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonnie J Dorr</author>
<author>Doug Jones</author>
</authors>
<title>Role of Word Sense Disambiguation in Lexical Acquisition: Predicting Semantics from Syntactic Cues.</title>
<date>1996</date>
<booktitle>Proceedings of the 14th International Conference on Computational Linguistics (COLING-96),</booktitle>
<pages>322--327</pages>
<location>Kopenhagen, Denmark.</location>
<contexts>
<context position="1941" citStr="Dorr and Jones, 1996" startWordPosition="299" endWordPosition="302">acquisition of lexical information from corpora is due to the fact that manual construction of such resources is time-consuming, and the resulting database is difficult to update. Most of the work in the field of acquisition of verbal lexical properties aims at learning subcategorization frames from corpora e.g. (Pereira et al., 1993; Briscoe and Carroll, 1997; Sass, 2006). However, semantic grouping of verbs on the basis of their syntactic distribution or other quantifiable features has also gained attention (Schulte im Walde, 2000; Schulte im Walde and Brew, 2002; Merlo and Stevenson, 2001; Dorr and Jones, 1996). The goal of these investigations is either the validation of verb classes based on (Levin, 1993), or finding algorithms for the categorization of new verbs. Unlike these projects, we report an attempt to cluster verbs on the basis of their syntactic properties with the further goal of identifying the semantic classes relevant for the description of Hungarian verbs’ alternation behavior. The theoretical grounding of our clustering attempts is provided by the so-called Semantic Base Hypothesis (Levin, 1993; Koenig et al., 2003). It is founded on the observation that semantically similar verbs </context>
</contexts>
<marker>Dorr, Jones, 1996</marker>
<rawString>Bonnie J. Dorr and Doug Jones. 1996. Role of Word Sense Disambiguation in Lexical Acquisition: Predicting Semantics from Syntactic Cues. Proceedings of the 14th International Conference on Computational Linguistics (COLING-96), pages 322–327, Kopenhagen, Denmark.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kata G´abor</author>
<author>Enik˝o H´eja</author>
</authors>
<title>Vonzatok ´es szabad hat´aroz´ok szab´alyalap´u kezel´ese [A Rule-based Analysis of Complements and Adjuncts].</title>
<date>2005</date>
<booktitle>Proceedings of the 3th Hungarian Conference of Computational Linguistics (MSZNY05),</booktitle>
<pages>245--256</pages>
<location>Szeged, Hungary.</location>
<marker>G´abor, H´eja, 2005</marker>
<rawString>Kata G´abor and Enik˝o H´eja. 2005. Vonzatok ´es szabad hat´aroz´ok szab´alyalap´u kezel´ese [A Rule-based Analysis of Complements and Adjuncts]. Proceedings of the 3th Hungarian Conference of Computational Linguistics (MSZNY05), pages 245-256, Szeged, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Joanis</author>
<author>Suzanne Stevenson</author>
</authors>
<title>A general feature space for automatic verb classification.</title>
<date>2003</date>
<booktitle>Proceedings of the 10th Conference of the EACL (EACL</booktitle>
<pages>163--170</pages>
<location>Budapest, Hungary.</location>
<contexts>
<context position="5473" citStr="Joanis and Stevenson, 2003" startWordPosition="836" endWordPosition="839">s reflect the most precisely the linguistic properties underlying word classes. (Brent, 1993) uses regular patterns. (Schulte im Walde, 2000; Schulte im Walde and Brew, 2002; Briscoe and Carroll, 1997) use subcategorization frame frequencies obtained from parsed corpora, potentially completed by semantic selection information. (Merlo and Stevenson, 2001) approximates diathesis alternations by hand-selected grammatical features. While this method has the advantage of working on POS-tagged, unparsed corpora, it is costly with respect to time and linguistic expertise. To overcome this drawback, (Joanis and Stevenson, 2003) develop a general feature space for supervised verb classification. (Stevenson and Joanis, 2003) investigate the applicability of this general feature space to unsupervised verb clustering tasks. As unsupervised methods are more sensitive to noisy features, the key issue is to filter out the large number of probably irrelevant features. They propose a semisupervised feature selection method which outperforms both hand-selection of features and usage of the full feature set. As in our experiment we do not have a pre-defined set of semantic classes, we need to apply unsupervised methods. Neithe</context>
</contexts>
<marker>Joanis, Stevenson, 2003</marker>
<rawString>Eric Joanis and Suzanne Stevenson. 2003. A general feature space for automatic verb classification. Proceedings of the 10th Conference of the EACL (EACL 2003), pages 163–170, Budapest, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean-Pierre Koenig</author>
<author>Gail Mauner</author>
<author>Breton Bienvenue</author>
</authors>
<title>Arguments for Adjuncts.</title>
<date>2003</date>
<journal>Cognition,</journal>
<volume>89</volume>
<pages>67--103</pages>
<contexts>
<context position="2474" citStr="Koenig et al., 2003" startWordPosition="383" endWordPosition="386">2000; Schulte im Walde and Brew, 2002; Merlo and Stevenson, 2001; Dorr and Jones, 1996). The goal of these investigations is either the validation of verb classes based on (Levin, 1993), or finding algorithms for the categorization of new verbs. Unlike these projects, we report an attempt to cluster verbs on the basis of their syntactic properties with the further goal of identifying the semantic classes relevant for the description of Hungarian verbs’ alternation behavior. The theoretical grounding of our clustering attempts is provided by the so-called Semantic Base Hypothesis (Levin, 1993; Koenig et al., 2003). It is founded on the observation that semantically similar verbs tend to occur in similar syntactic contexts, leading to the assumption that verbal semantics determines argument structure and the surface realization of arguments. While in English semantic argument roles are mapped to configurational positions in the tree structure, Hungarian codes complement structure in its highly rich nominal inflection system. Therefore, we start from the examination of case-marked NPs in the context of verbs. The experiment discussed in this paper is the first stage of an ongoing project for finding the </context>
</contexts>
<marker>Koenig, Mauner, Bienvenue, 2003</marker>
<rawString>Jean-Pierre Koenig, Gail Mauner and Breton Bienvenue. 2003. Arguments for Adjuncts. Cognition, 89, 67-103.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Judit Kuti</author>
<author>P´eter Vajda</author>
<author>K´aroly Varasdi</author>
</authors>
<title>Javaslat a magyar igei WordNet kialakit´as´ara [Proposal for Developing the Hungarian WordNet of Verbs].</title>
<date>2005</date>
<booktitle>Proceedings of the 3th Hungarian Conference of Computational Linguistics (MSZNY05),</booktitle>
<pages>79--87</pages>
<location>Szeged, Hungary.</location>
<contexts>
<context position="15321" citStr="Kuti et al., 2005" startWordPosition="2482" endWordPosition="2485">ter are closer to each other than to elements outside the class, according to an independent similarity/distance measure. However, relying on such a method would not help us evaluating the semantic coherence of our classes. The second type of methods use gold standards. Widely accepted gold standards in this field are Levin’s verb classes or verbal WordNets. As we do not dispose of a Hungarian equivalent of Levin’s classification – that is exactly why we experiment with automatic clustering – we cannot use it directly. We also run across difficulties when considering Hungarian verbal WordNet (Kuti et al., 2005) as the standard for evaluation. Mapping verb clusters to the net would require to state semantic relatedness in terms of WordNet-type hierarchy relations. However, if we try to capture the distance between verbal meanings by the number of intermediary nodes in the WordNet, we face the problem that the semantic distance between mother-children nodes is not uniform. As our work is about obtaining a Levin-type verb classification, it could be an obvious choice to evaluate semantic classes by collecting alternations specific to the given class. Hungarian language hardly lends itself to this metho</context>
</contexts>
<marker>Kuti, Vajda, Varasdi, 2005</marker>
<rawString>Judit Kuti, P´eter Vajda and K´aroly Varasdi. 2005. Javaslat a magyar igei WordNet kialakit´as´ara [Proposal for Developing the Hungarian WordNet of Verbs]. Proceedings of the 3th Hungarian Conference of Computational Linguistics (MSZNY05), pages 79– 87, Szeged, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beth Levin</author>
</authors>
<title>English Verb Classes And Alternations: A Preliminary Investigation.</title>
<date>1993</date>
<publisher>Chicago University Press.</publisher>
<contexts>
<context position="2039" citStr="Levin, 1993" startWordPosition="317" endWordPosition="318">es is time-consuming, and the resulting database is difficult to update. Most of the work in the field of acquisition of verbal lexical properties aims at learning subcategorization frames from corpora e.g. (Pereira et al., 1993; Briscoe and Carroll, 1997; Sass, 2006). However, semantic grouping of verbs on the basis of their syntactic distribution or other quantifiable features has also gained attention (Schulte im Walde, 2000; Schulte im Walde and Brew, 2002; Merlo and Stevenson, 2001; Dorr and Jones, 1996). The goal of these investigations is either the validation of verb classes based on (Levin, 1993), or finding algorithms for the categorization of new verbs. Unlike these projects, we report an attempt to cluster verbs on the basis of their syntactic properties with the further goal of identifying the semantic classes relevant for the description of Hungarian verbs’ alternation behavior. The theoretical grounding of our clustering attempts is provided by the so-called Semantic Base Hypothesis (Levin, 1993; Koenig et al., 2003). It is founded on the observation that semantically similar verbs tend to occur in similar syntactic contexts, leading to the assumption that verbal semantics deter</context>
</contexts>
<marker>Levin, 1993</marker>
<rawString>Beth Levin. 1993. English Verb Classes And Alternations: A Preliminary Investigation. Chicago University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paola Merlo</author>
<author>Suzanne Stevenson</author>
</authors>
<title>Automatic Verb Classification Based on</title>
<date>2001</date>
<journal>Statistical Distributions of Argument Structure. Computational Linguistics,</journal>
<volume>27</volume>
<issue>3</issue>
<pages>373--408</pages>
<contexts>
<context position="1918" citStr="Merlo and Stevenson, 2001" startWordPosition="295" endWordPosition="298"> interest in the automatic acquisition of lexical information from corpora is due to the fact that manual construction of such resources is time-consuming, and the resulting database is difficult to update. Most of the work in the field of acquisition of verbal lexical properties aims at learning subcategorization frames from corpora e.g. (Pereira et al., 1993; Briscoe and Carroll, 1997; Sass, 2006). However, semantic grouping of verbs on the basis of their syntactic distribution or other quantifiable features has also gained attention (Schulte im Walde, 2000; Schulte im Walde and Brew, 2002; Merlo and Stevenson, 2001; Dorr and Jones, 1996). The goal of these investigations is either the validation of verb classes based on (Levin, 1993), or finding algorithms for the categorization of new verbs. Unlike these projects, we report an attempt to cluster verbs on the basis of their syntactic properties with the further goal of identifying the semantic classes relevant for the description of Hungarian verbs’ alternation behavior. The theoretical grounding of our clustering attempts is provided by the so-called Semantic Base Hypothesis (Levin, 1993; Koenig et al., 2003). It is founded on the observation that sema</context>
<context position="5202" citStr="Merlo and Stevenson, 2001" startWordPosition="798" endWordPosition="801">ds with POS tagging and syntactic annotation which extends to toplevel sentence constituents but does not differentiate between complements and adjuncts. When applying a classification or clustering algorithm to a corpus, a crucial question is which quantifiable features reflect the most precisely the linguistic properties underlying word classes. (Brent, 1993) uses regular patterns. (Schulte im Walde, 2000; Schulte im Walde and Brew, 2002; Briscoe and Carroll, 1997) use subcategorization frame frequencies obtained from parsed corpora, potentially completed by semantic selection information. (Merlo and Stevenson, 2001) approximates diathesis alternations by hand-selected grammatical features. While this method has the advantage of working on POS-tagged, unparsed corpora, it is costly with respect to time and linguistic expertise. To overcome this drawback, (Joanis and Stevenson, 2003) develop a general feature space for supervised verb classification. (Stevenson and Joanis, 2003) investigate the applicability of this general feature space to unsupervised verb clustering tasks. As unsupervised methods are more sensitive to noisy features, the key issue is to filter out the large number of probably irrelevant</context>
</contexts>
<marker>Merlo, Stevenson, 2001</marker>
<rawString>Paola Merlo and Suzanne Stevenson. 2001. Automatic Verb Classification Based on Statistical Distributions of Argument Structure. Computational Linguistics, 27(3), pages 373-408.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernando C N Pereira</author>
<author>Naftali Tishby</author>
<author>Lillan Lee</author>
</authors>
<date>1993</date>
<booktitle>Distributional Clustering of English Words. 31st Annual Meeting of the ACL,</booktitle>
<pages>183--190</pages>
<location>Columbus, Ohio, USA.</location>
<contexts>
<context position="1655" citStr="Pereira et al., 1993" startWordPosition="251" endWordPosition="254">red lexicons has been in the center of interest in the natural language processing community. On the one hand, structured lexical databases are easier to handle and to expand because they allow making generalizations over classes of words. On the other hand, interest in the automatic acquisition of lexical information from corpora is due to the fact that manual construction of such resources is time-consuming, and the resulting database is difficult to update. Most of the work in the field of acquisition of verbal lexical properties aims at learning subcategorization frames from corpora e.g. (Pereira et al., 1993; Briscoe and Carroll, 1997; Sass, 2006). However, semantic grouping of verbs on the basis of their syntactic distribution or other quantifiable features has also gained attention (Schulte im Walde, 2000; Schulte im Walde and Brew, 2002; Merlo and Stevenson, 2001; Dorr and Jones, 1996). The goal of these investigations is either the validation of verb classes based on (Levin, 1993), or finding algorithms for the categorization of new verbs. Unlike these projects, we report an attempt to cluster verbs on the basis of their syntactic properties with the further goal of identifying the semantic c</context>
<context position="18714" citStr="Pereira et al., 1993" startWordPosition="3066" endWordPosition="3069">source denotes a starting point in the space, cause refers to entity which evoked the eventuality described by the verb. or vague role specifications, we need more than one persons to fill in the cells, based on example sentences. 6 Future Work There are two major directions regarding our future work. With respect to the automatic clustering process, we have the intention of widening the scope of the grammatical features to be compared by enriching subcategorization frames by other morphological properties. We are also planning to test top-down clustering methods such as the one described in (Pereira et al., 1993). On the long run, it will be inevitable to make experiments on larger corpora. The obvious choice is the 180 million words Hungarian National Corpus (V´aradi, 2002). It is a POS-tagged corpus but does not contain any syntactic annotation; hence its use would require at least some partial parsing such as NP analysis to be employable for our purposes. The other future direction concerns evaluation and linguistic analysis of verb clusters. We define well-founded verb classes on the basis of semantic role matrices. These semantic roles can be filled in a sentence by casemarked NPs. Therefore, eva</context>
</contexts>
<marker>Pereira, Tishby, Lee, 1993</marker>
<rawString>Fernando C. N. Pereira, Naftali Tishby and Lillan Lee. 1993. Distributional Clustering of English Words. 31st Annual Meeting of the ACL, pages 183-190, Columbus, Ohio, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B´alint Sass</author>
</authors>
<title>Igei vonzatkeretek az MNSZ tagmondataiban [Exploring Verb Frames in the Hungarian National Corpus].</title>
<date>2006</date>
<booktitle>Proceedings of the 4th Hungarian Conference of Computational Linguistics (MSZNY06),</booktitle>
<pages>15--22</pages>
<location>Szeged, Hungary.</location>
<contexts>
<context position="1695" citStr="Sass, 2006" startWordPosition="260" endWordPosition="261">n the natural language processing community. On the one hand, structured lexical databases are easier to handle and to expand because they allow making generalizations over classes of words. On the other hand, interest in the automatic acquisition of lexical information from corpora is due to the fact that manual construction of such resources is time-consuming, and the resulting database is difficult to update. Most of the work in the field of acquisition of verbal lexical properties aims at learning subcategorization frames from corpora e.g. (Pereira et al., 1993; Briscoe and Carroll, 1997; Sass, 2006). However, semantic grouping of verbs on the basis of their syntactic distribution or other quantifiable features has also gained attention (Schulte im Walde, 2000; Schulte im Walde and Brew, 2002; Merlo and Stevenson, 2001; Dorr and Jones, 1996). The goal of these investigations is either the validation of verb classes based on (Levin, 1993), or finding algorithms for the categorization of new verbs. Unlike these projects, we report an attempt to cluster verbs on the basis of their syntactic properties with the further goal of identifying the semantic classes relevant for the description of H</context>
</contexts>
<marker>Sass, 2006</marker>
<rawString>B´alint Sass. 2006. Igei vonzatkeretek az MNSZ tagmondataiban [Exploring Verb Frames in the Hungarian National Corpus]. Proceedings of the 4th Hungarian Conference of Computational Linguistics (MSZNY06), pages 15–22, Szeged, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Schulte im Walde</author>
</authors>
<title>Clustering Verbs Semantically According to their Alternation Behaviour.</title>
<date>2000</date>
<booktitle>Proceedings of the 18th International Conference on Computational Linguistics (COLING-00),</booktitle>
<pages>747--753</pages>
<location>Saarbr¨ucken, Germany.</location>
<contexts>
<context position="1858" citStr="Walde, 2000" startWordPosition="287" endWordPosition="288">ions over classes of words. On the other hand, interest in the automatic acquisition of lexical information from corpora is due to the fact that manual construction of such resources is time-consuming, and the resulting database is difficult to update. Most of the work in the field of acquisition of verbal lexical properties aims at learning subcategorization frames from corpora e.g. (Pereira et al., 1993; Briscoe and Carroll, 1997; Sass, 2006). However, semantic grouping of verbs on the basis of their syntactic distribution or other quantifiable features has also gained attention (Schulte im Walde, 2000; Schulte im Walde and Brew, 2002; Merlo and Stevenson, 2001; Dorr and Jones, 1996). The goal of these investigations is either the validation of verb classes based on (Levin, 1993), or finding algorithms for the categorization of new verbs. Unlike these projects, we report an attempt to cluster verbs on the basis of their syntactic properties with the further goal of identifying the semantic classes relevant for the description of Hungarian verbs’ alternation behavior. The theoretical grounding of our clustering attempts is provided by the so-called Semantic Base Hypothesis (Levin, 1993; Koen</context>
<context position="3294" citStr="Walde, 2000" startWordPosition="515" endWordPosition="516">alization of arguments. While in English semantic argument roles are mapped to configurational positions in the tree structure, Hungarian codes complement structure in its highly rich nominal inflection system. Therefore, we start from the examination of case-marked NPs in the context of verbs. The experiment discussed in this paper is the first stage of an ongoing project for finding the semantic verb classes which are syntactically relevant in Hungarian. As we do not have presuppositions about which classes have to be used, we chose an unsupervised clustering method described in (Schulte im Walde, 2000). The 150 most frequent Hungarian verbs were categorized according to their comp91 Proceedings of the ACL 2007 Student Research Workshop, pages 91–96, Prague, June 2007. c�2007 Association for Computational Linguistics lementation structures in a syntactically annotated corpus, the Szeged Treebank (Csendes et al., 2005). We are seeking the answer to two questions: 1. Are the resulting clusters semantically coherent (thus reinforcing the Semantic Base Hypothesis)? 2. If so, what are the alternations responsible for their similar behavior? The subsequent sections present the input features [2] a</context>
<context position="4986" citStr="Walde, 2000" startWordPosition="771" endWordPosition="772">an corpus, the Szeged Treebank. Texts of the corpus come from different topic areas such as business news, daily news, fiction, law, and compositions of students. It currently comprises 1.2 million words with POS tagging and syntactic annotation which extends to toplevel sentence constituents but does not differentiate between complements and adjuncts. When applying a classification or clustering algorithm to a corpus, a crucial question is which quantifiable features reflect the most precisely the linguistic properties underlying word classes. (Brent, 1993) uses regular patterns. (Schulte im Walde, 2000; Schulte im Walde and Brew, 2002; Briscoe and Carroll, 1997) use subcategorization frame frequencies obtained from parsed corpora, potentially completed by semantic selection information. (Merlo and Stevenson, 2001) approximates diathesis alternations by hand-selected grammatical features. While this method has the advantage of working on POS-tagged, unparsed corpora, it is costly with respect to time and linguistic expertise. To overcome this drawback, (Joanis and Stevenson, 2003) develop a general feature space for supervised verb classification. (Stevenson and Joanis, 2003) investigate the</context>
<context position="6217" citStr="Walde, 2000" startWordPosition="956" endWordPosition="957">his general feature space to unsupervised verb clustering tasks. As unsupervised methods are more sensitive to noisy features, the key issue is to filter out the large number of probably irrelevant features. They propose a semisupervised feature selection method which outperforms both hand-selection of features and usage of the full feature set. As in our experiment we do not have a pre-defined set of semantic classes, we need to apply unsupervised methods. Neither have we manually defined grammatical cues, not knowing which alternations should be approximated. Hence, similarly to (Schulte im Walde, 2000), we represent verbs by their subcategorization frames. In accordance with the annotation of the treebank, we included both complements and adjuncts in subcategorization patterns. It is important to note, however, that not only practical considerations lead us to this decision. First, there are no reliable syntactic tests for differentiating complements from adjuncts. This is due to the fact that Hungarian is a highly inflective, non-configurational language, where constituent order does not reveal dependency relations. Indeed, complements and adjuncts of verbs tend to mingle. In parallel, Hun</context>
<context position="8356" citStr="Walde, 2000" startWordPosition="1299" endWordPosition="1300">d on the number of syntactic dependents to be included in the frame. Frame types were obtained from individual frames by omitting lexical information as well as every piece of morphosyntactic description except 92 for the POS tag and the case suffix. The generalization yielded 839 frame types altogether.1 3 Clustering Methods In accordance with our goal to set up a basis for a semantic classification, we chose to perform the first clustering trial on the 150 most frequent verbs in the Szeged Treebank. The representation of verbs and the clustering process were carried out based on (Schulte im Walde, 2000). The data to be compared were the maximum likelihood estimates of the probability distribution of verbs over the possible frame types: p(t|v) = f(v, t) (1) f(v) with f(v) being the frequency of the verb, and f(v, t) being the frequency of the verb in the frame. These values have been calculated for each of the 150 verbs and 839 frame types. Probability distributions were compared using relative entropy as a distance measure: D(xlly) = Due to the large number of subcategorization frame types, verbs’ representation comprise a lot of zero probability figures. Using relative entropy as a distance</context>
</contexts>
<marker>Walde, 2000</marker>
<rawString>Sabine Schulte im Walde. 2000. Clustering Verbs Semantically According to their Alternation Behaviour. Proceedings of the 18th International Conference on Computational Linguistics (COLING-00), pages 747– 753, Saarbr¨ucken, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Schulte im Walde</author>
<author>Chris Brew</author>
</authors>
<title>Inducing German Semantic Verb Classes from Purely Syntactic Subcategorisation Information.</title>
<date>2002</date>
<booktitle>Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>223--230</pages>
<location>Philadelphia, PA.</location>
<contexts>
<context position="1891" citStr="Walde and Brew, 2002" startWordPosition="291" endWordPosition="294">ds. On the other hand, interest in the automatic acquisition of lexical information from corpora is due to the fact that manual construction of such resources is time-consuming, and the resulting database is difficult to update. Most of the work in the field of acquisition of verbal lexical properties aims at learning subcategorization frames from corpora e.g. (Pereira et al., 1993; Briscoe and Carroll, 1997; Sass, 2006). However, semantic grouping of verbs on the basis of their syntactic distribution or other quantifiable features has also gained attention (Schulte im Walde, 2000; Schulte im Walde and Brew, 2002; Merlo and Stevenson, 2001; Dorr and Jones, 1996). The goal of these investigations is either the validation of verb classes based on (Levin, 1993), or finding algorithms for the categorization of new verbs. Unlike these projects, we report an attempt to cluster verbs on the basis of their syntactic properties with the further goal of identifying the semantic classes relevant for the description of Hungarian verbs’ alternation behavior. The theoretical grounding of our clustering attempts is provided by the so-called Semantic Base Hypothesis (Levin, 1993; Koenig et al., 2003). It is founded o</context>
<context position="5019" citStr="Walde and Brew, 2002" startWordPosition="775" endWordPosition="778">eebank. Texts of the corpus come from different topic areas such as business news, daily news, fiction, law, and compositions of students. It currently comprises 1.2 million words with POS tagging and syntactic annotation which extends to toplevel sentence constituents but does not differentiate between complements and adjuncts. When applying a classification or clustering algorithm to a corpus, a crucial question is which quantifiable features reflect the most precisely the linguistic properties underlying word classes. (Brent, 1993) uses regular patterns. (Schulte im Walde, 2000; Schulte im Walde and Brew, 2002; Briscoe and Carroll, 1997) use subcategorization frame frequencies obtained from parsed corpora, potentially completed by semantic selection information. (Merlo and Stevenson, 2001) approximates diathesis alternations by hand-selected grammatical features. While this method has the advantage of working on POS-tagged, unparsed corpora, it is costly with respect to time and linguistic expertise. To overcome this drawback, (Joanis and Stevenson, 2003) develop a general feature space for supervised verb classification. (Stevenson and Joanis, 2003) investigate the applicability of this general fe</context>
</contexts>
<marker>Walde, Brew, 2002</marker>
<rawString>Sabine Schulte im Walde and Chris Brew. 2002. Inducing German Semantic Verb Classes from Purely Syntactic Subcategorisation Information. Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 223-230, Philadelphia, PA.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Sabine Schulte im Walde</author>
</authors>
<title>to appear. The Induction of Verb Frames and Verb Classes from Corpora. Corpus Linguistics. An International Handbook., Anke L¨udeling and Merja Kyt¨o (eds). Mouton de Gruyter,</title>
<location>Berlin.</location>
<marker>Walde, </marker>
<rawString>Sabine Schulte im Walde. to appear. The Induction of Verb Frames and Verb Classes from Corpora. Corpus Linguistics. An International Handbook., Anke L¨udeling and Merja Kyt¨o (eds). Mouton de Gruyter, Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Suzanne Stevenson</author>
<author>Eric Joanis</author>
</authors>
<title>Semisupervised Verb Class Discovery Using Noisy Features.</title>
<date>2003</date>
<booktitle>Proceedings of the 7th Conference on Computational Natural Language Learning (CoNLL-03),</booktitle>
<pages>71--78</pages>
<location>Edmonton, Canada.</location>
<contexts>
<context position="5570" citStr="Stevenson and Joanis, 2003" startWordPosition="850" endWordPosition="853">s regular patterns. (Schulte im Walde, 2000; Schulte im Walde and Brew, 2002; Briscoe and Carroll, 1997) use subcategorization frame frequencies obtained from parsed corpora, potentially completed by semantic selection information. (Merlo and Stevenson, 2001) approximates diathesis alternations by hand-selected grammatical features. While this method has the advantage of working on POS-tagged, unparsed corpora, it is costly with respect to time and linguistic expertise. To overcome this drawback, (Joanis and Stevenson, 2003) develop a general feature space for supervised verb classification. (Stevenson and Joanis, 2003) investigate the applicability of this general feature space to unsupervised verb clustering tasks. As unsupervised methods are more sensitive to noisy features, the key issue is to filter out the large number of probably irrelevant features. They propose a semisupervised feature selection method which outperforms both hand-selection of features and usage of the full feature set. As in our experiment we do not have a pre-defined set of semantic classes, we need to apply unsupervised methods. Neither have we manually defined grammatical cues, not knowing which alternations should be approximate</context>
</contexts>
<marker>Stevenson, Joanis, 2003</marker>
<rawString>Suzanne Stevenson and Eric Joanis. 2003. Semisupervised Verb Class Discovery Using Noisy Features. Proceedings of the 7th Conference on Computational Natural Language Learning (CoNLL-03), pages 71-78, Edmonton, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tam´as V´aradi</author>
</authors>
<title>The Hungarian National Corpus.</title>
<date>2002</date>
<booktitle>Proceedings of the Third International Conference on Language Resources and Evaluation,</booktitle>
<pages>385--389</pages>
<location>Las Palmas,</location>
<marker>V´aradi, 2002</marker>
<rawString>Tam´as V´aradi. 2002. The Hungarian National Corpus. Proceedings of the Third International Conference on Language Resources and Evaluation, pages 385–389, Las Palmas, Spain.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>