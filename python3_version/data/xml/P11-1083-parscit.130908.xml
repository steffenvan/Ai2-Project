<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000005">
<note confidence="0.79144">
How to train your multi bottom-up tree transducer
</note>
<author confidence="0.869565">
Andreas Maletti
</author>
<affiliation confidence="0.875193">
Universit¨at Stuttgart, Institute for Natural Language Processing
</affiliation>
<address confidence="0.709642">
Azenbergstraße 12, 70174 Stuttgart, Germany
</address>
<email confidence="0.991835">
andreas.maletti@ims.uni-stuttgart.de
</email>
<sectionHeader confidence="0.99439" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.989219818181818">
The local multi bottom-up tree transducer is
introduced and related to the (non-contiguous)
synchronous tree sequence substitution gram-
mar. It is then shown how to obtain a weighted
local multi bottom-up tree transducer from
a bilingual and biparsed corpus. Finally,
the problem of non-preservation of regular-
ity is addressed. Three properties that ensure
preservation are introduced, and it is discussed
how to adjust the rule extraction process such
that they are automatically fulfilled.
</bodyText>
<sectionHeader confidence="0.998396" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999968473684211">
A (formal) translation model is at the core of ev-
ery machine translation system. Predominantly, sta-
tistical processes are used to instantiate the for-
mal model and derive a specific translation device.
Brown et al. (1990) discuss automatically trainable
translation models in their seminal paper. However,
the IBM models of Brown et al. (1993) are string-
based in the sense that they base the translation de-
cision on the words and their surrounding context.
Contrary, in the field of syntax-based machine trans-
lation, the translation models have full access to the
syntax of the sentences and can base their decision
on it. A good exposition to both fields is presented
in (Knight, 2007).
In this paper, we deal exclusively with syntax-
based translation models such as synchronous tree
substitution grammars (STSG), multi bottom-up tree
transducers (MBOT), and synchronous tree-sequence
substitution grammars (STSSG). Chiang (2006)
gives a good introduction to STSG, which originate
from the syntax-directed translation schemes of Aho
and Ullman (1972). Roughly speaking, an STSG
has rules in which two linked nonterminals are re-
placed (at the same time) by two corresponding trees
containing terminal and nonterminal symbols. In
addition, the nonterminals in the two replacement
trees are linked, which creates new linked nontermi-
nals to which further rules can be applied. Hence-
forth, we refer to these two trees as input and output
tree. MBOT have been introduced in (Arnold and
Dauchet, 1982; Lilin, 1981) and are slightly more
expressive than STSG. Roughly speaking, they al-
low one replacement input tree and several output
trees in a single rule. This change and the pres-
ence of states yields many algorithmically advanta-
geous properties such as closure under composition,
efficient binarization, and efficient input and output
restriction [see (Maletti, 2010)]. Finally, STSSG,
which have been derived from rational tree rela-
tions (Raoult, 1997), have been discussed by Zhang
et al. (2008a), Zhang et al. (2008b), and Sun et al.
(2009). They are even more expressive than the lo-
cal variant of the multi bottom-up tree transducer
(LMBOT) that we introduce here and can have sev-
eral input and output trees in a single rule.
In this contribution, we restrict MBOT to a form
that is particularly relevant in machine translation.
We drop the general state behavior of MBOT and re-
place it by the common locality tests that are also
present in STSG, STSSG, and STAG (Shieber and
Schabes, 1990; Shieber, 2007). The obtained device
is the local MBOT (LMBOT).
Maletti (2010) argued the algorithmical advan-
tages of MBOT over STSG and proposed MBOT as
an implementation alternative for STSG. In partic-
ular, the training procedure would train STSG; i.e.,
it would not utilize the additional expressive power
</bodyText>
<page confidence="0.981613">
825
</page>
<note confidence="0.979525">
Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 825–834,
Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics
</note>
<bodyText confidence="0.999743631578948">
of MBOT. However, Zhang et al. (2008b) and Sun
et al. (2009) demonstrate that the additional expres-
sivity gained from non-contiguous rules greatly im-
proves the translation quality. In this contribution
we address this separation and investigate a training
procedure for LMBOT that allows non-contiguous
fragments while preserving the algorithmic advan-
tages of MBOT. To this end, we introduce a rule ex-
traction and weight training method for LMBOT that
is based on the corresponding procedures for STSG
and STSSG. However, general LMBOT can be too
expressive in the sense that they allow translations
that do not preserve regularity. Preservation of reg-
ularity is an important property for efficient repre-
sentations and efficient algorithms [see (May et al.,
2010)]. Consequently, we present 3 properties that
ensure that an LMBOT preserves regularity. In addi-
tion, we shortly discuss how these properties could
be enforced in the rule extraction procedure.
</bodyText>
<sectionHeader confidence="0.978132" genericHeader="introduction">
2 Notation
</sectionHeader>
<bodyText confidence="0.9981944">
The set of nonnegative integers is N. We write [k]
for the set {i  |1 ≤ i ≤ k}. We treat functions as
special relations. For every relation R ⊆ A × B and
5 ⊆ A, we write
inductively defined by pos(t) = {E}∪pos(t), where
</bodyText>
<equation confidence="0.980374">
pos(t) = U {ip  |p ∈ pos(ti)} .
1≤i≤|t|
</equation>
<bodyText confidence="0.999956875">
Note that this yields an undesirable difference be-
tween pos(t) and pos(t), but it will always be clear
from the context whether we refer to a single tree or
a sequence. Note that positions are ordered via the
(standard) lexicographic ordering. Let t ∈ TΣ and
p ∈ pos(t). The label of t at position p is t(p), and
the subtree rooted at position p is t|p. Formally, they
are defined by
</bodyText>
<equation confidence="0.908743333333333">
t(p) =t(p) otherwise
� Q if p = E t(ip) = ti(p)
t|p I
_ It if p = E
Sl t|p otherwise t Zp - _
ti|p
</equation>
<bodyText confidence="0.98947975">
for all t = Q(t) and 1 ≤ i ≤ |t|. As demonstrated,
these notions are also used for sequences. A posi-
tion p ∈ pos(t) is a leaf (in t) if p1 ∈� pos(t). Given
a subset NT ⊆ Σ, we let
↓NT(t) = {p ∈ pos(t)  |t(p) ∈ NT, p leaf in t} .
Later NT will be the set of nonterminals, so that
the elements of ↓NT(t) will be the leaf nonterminals
of t. We extend the notion to sequences t by
</bodyText>
<equation confidence="0.999688">
R(5) = {b ∈ B  |∃a ∈ 5: (a, b) ∈ R} ↓NT(t) = U {ip  |p ∈ ↓NT(ti)} .
R−1 = {(b, a)  |(a, b) ∈ R} , 1≤i≤|t|
</equation>
<bodyText confidence="0.995171857142857">
where R−1 is called the inverse of R.
Given an alphabet Σ, the set of all words (or se-
quences) over Σ is Σ∗, of which the empty word is E.
The concatenation of two words u and w is simply
denoted by the juxtaposition uw. The length of a
word w = Q1 · · · Qk with Qi ∈ Σ for all i ∈ [k]
is |w |= k. Given 1 ≤ i ≤ j ≤ k, the (i, j)-
span w[i, j] of w is QiQi+1 ··· Qj.
The set TΣ of all Σ-trees is the smallest set T
such that Q(t) ∈ T for all Q ∈ Σ and t ∈ T∗.
We generally use bold-face characters (like t) for
sequences, and we refer to their elements using sub-
scripts (like ti). Consequently, a tree t consists of
a labeled root node Q followed by a sequence t of
its children. To improve readability we sometimes
write a sequence t1 · · · tk as t1, ... , tk.
The positions pos(t) ⊆ N∗ of a tree t = Q(t) are
We also need a substitution that replaces sub-
trees. Let p1, ... , pn ∈ pos(t) be pairwise in-
comparable positions and t1, ... , tn ∈ TΣ. Then
t[pi ← ti  |1 ≤ i ≤ n] denotes the tree that is ob-
tained from t by replacing (in parallel) the subtrees
at pi by ti for every i ∈ [k].
Finally, let us recall regular tree languages. A fi-
nite tree automaton M is a tuple (Q, Σ, 6, F) such
that Q is a finite set, 6 ⊆_ Q∗ × Σ × Q is a fi-
nite relation, and F ⊆ Q We extend 6 to a map-
ping 6: TΣ → 2(Q by
</bodyText>
<equation confidence="0.894874">
6(Q(t)) = {q  |(q, Q, q) ∈ 6, ∀i ∈ [ |t |]: qi ∈ 6(ti)}
for every Q ∈ Σ and t ∈ T∗Σ. The finite tree automa-
ton M recognizes the tree language
L(M) = {t ∈ TΣ  |6(t) ∩ F =6 ∅} .
</equation>
<bodyText confidence="0.996936">
A tree language L ⊆ TΣ is regular if there exists a
finite tree automaton M such that L = L(M).
</bodyText>
<page confidence="0.996599">
826
</page>
<figure confidence="0.99894488">
NP-OBJ
VP
VBD
signed
PP
1
→
PV
twlY
,
NP
DET-NN
AltwqyE
PP
S
VP
NP-SBJ
1
VP
2
→
1
PV
NP-OBJ
NP-SBJ
</figure>
<figureCaption confidence="0.999843">
Figure 1: Sample LMBOT rules.
</figureCaption>
<sectionHeader confidence="0.991962" genericHeader="method">
3 The model
</sectionHeader>
<bodyText confidence="0.957797073529412">
In this section, we recall particular multi bottom-
up tree transducers, which have been introduced
by Arnold and Dauchet (1982) and Lilin (1981). A
detailed (and English) presentation of the general
model can be found in Engelfriet et al. (2009) and
Maletti (2010). Using the nomenclature of Engel-
friet et al. (2009), we recall a variant of linear and
nondeleting extended multi bottom-up tree transduc-
ers (MBOT) here. Occasionally, we will refer to gen-
eral MBOT, which differ from the local variant dis-
cussed here because they have explicit states.
Throughout the article, we assume sets E and A
of input and output symbols, respectively. More-
over, let NT ⊆ E ∪ A be the set of designated non-
terminal symbols. Finally, we avoid weights in the
formal development to keep it simple. It is straight-
forward to add weights to our model.
Essentially, the model works on pairs ht, ui
consisting of an input tree t ∈ TE and a se-
quence u ∈ To of output trees. Each such pair is
called a pre-translation and the rank rk(ht, ui) the
pre-translation ht, ui is |u|. In other words, the rank
of a pre-translation equals the number of output trees
stored in it. Given a pre-translation ht, ui ∈ TE×To
and i ∈ [k], we call ui the ith translation of t. An
alignment for the pre-translation ht, ui is an injec-
tive mapping ψ: ↓NT(u) → ↓NT(t) × N such that
(p, j) ∈ ψ(↓NT(u)) for every (p, i) ∈ ψ(↓NT(u))
and j ∈ [i]. In other words, an alignment should re-
quest each translation of a particular subtree at most
once and if it requests the ith translation, then it
should also request all previous translations.
Definition 1 A local multi bottom-up tree trans-
ducer (LMBOT) is a finite set R of rules such that ev-
ery rule, written l →,p r, contains a pre-translation
hl, ri and an alignment ψ for it.
The component l is the left-hand side, r is
the right-hand side, and ψ is the alignment of a
rule l →,p r ∈ R. The rules of an LMBOT are similar
to the rules of an STSG (synchronous tree substitu-
tion grammar) of Eisner (2003) and Shieber (2004),
but right-hand sides of LMBOT contain a sequence
of trees instead of just a single tree as in an STSG. In
addition, the alignments in an STSG rule are bijec-
tive between leaf nonterminals, whereas our model
permits multiple alignments to a single leaf nonter-
minal in the left-hand side. A model that is even
more powerful than LMBOT is the non-contiguous
version of STSSG (synchronous tree-sequence sub-
stitution grammar) of Zhang et al. (2008a), Zhang
et al. (2008b), and Sun et al. (2009), which al-
lows sequences of trees on both sides of rules [see
also (Raoult, 1997)]. Figure 1 displays sample rules
of an LMBOT using a graphical representation of the
trees and the alignment.
Next, we define the semantics of an LMBOT R.
To avoid difficulties1, we explicitly exclude rules
like l →,p r where l ∈ NT or r ∈ NT*; i.e.,
rules where the left- or right-hand side are only
leaf nonterminals. We first define the traditional
bottom-up semantics. Let ρ = l →,p r ∈ R be a
rule and p ∈ ↓NT(l). The p-rank rk(ρ, p) of ρ is
rk(ρ, p) = |{i ∈ N  |(p, i) ∈ ψ(↓NT(r))}|.
Definition 2 The set τ(R) of pre-translations of an
LMBOT R is inductively defined to be the smallest
set such that: If ρ = l →,p r ∈ R is a rule,
htp, upi ∈ τ(R) is a pre-translation of R for every
p ∈ ↓NT(l), and
</bodyText>
<listItem confidence="0.999788">
• rk(ρ, p) = rk(htp, upi),
• l(p) = tp(ε), and
</listItem>
<bodyText confidence="0.382553">
1Actually, difficulties arise only in the weighted setting.
</bodyText>
<page confidence="0.94325">
827
</page>
<figure confidence="0.99991865">
VP
NP-OBJ
PP
E
NP
NN-PROP
SrbyA
PREP
NP
En NN-PROP
SrbyA
DPREP
En
VBD
signed
PP
NP
NNP
Serbia
DPV
twlY
NP
, DET-NN
AltwqyE
PP
E
IN
for
VP
NP-OBJ
. . .
PV
twlY
PP
PP
NP
D
E
PREP
NP
NNP
Serbia
En
IN
for
S
... VP
VBD
signed
DET-NN
AltwqyE
NP
NN-PROP
SrbyA
PP
NP
NNP
Serbia
IN
for
</figure>
<figureCaption confidence="0.9982705">
Figure 2: Top left: (a) Initial pre-translation; Top right: (b) Pre-translation obtained from the left rule of Fig. 1 and (a);
Bottom: (c) Pre-translation obtained from the right rule of Fig. 1 and (b).
</figureCaption>
<listItem confidence="0.9763515">
• r(p0) = up00(i) with ψ(p0) = (p00, i)
for every p0 E INT(r), then (t, u) E τ(R) where
• t = l[p - tp I p E INT(l)]and
• u = r[p0 - (up00)i I p0 E ψ−1(p00, i)].
</listItem>
<bodyText confidence="0.998804678571429">
In plain words, each nonterminal leaf p in the
left-hand side of a rule ρ can be replaced by the
input tree t of a pre-translation (t, u) whose root
is labeled by the same nonterminal. In addition,
the rank rk(ρ, p) of the replaced nonterminal should
match the rank rk((t, u)) of the pre-translation and
the nonterminals in the right-hand side that are
aligned to p should be replaced by the translation
that the alignment requests, provided that the non-
terminal matches with the root symbol of the re-
quested translation. The main benefit of the bottom-
up semantics is that it works exclusively on pre-
translations. The process is illustrated in Figure 2.
Using the classical bottom-up semantics, we sim-
ply obtain the following theorem by Maletti (2010)
because the MBOT constructed there is in fact an
LMBOT.
Theorem 3 For every STSG, an equivalent LMBOT
can be constructed in linear time, which in turn
yields a particular MBOT in linear time.
Finally, we want to relate LMBOT to the STSSG
of Sun et al. (2009). To this end, we also introduce
the top-down semantics for LMBOT. As expected,
both semantics coincide. The top-down semantics is
introduced using rule compositions, which will play
an important rule later on.
Definition 4 The set Rk of k-fold composed rules is
inductively defined as follows:
</bodyText>
<listItem confidence="0.972790666666667">
• R1 = R and
• ` —ϕ s E Rk+1 for all ρ = l —ψ r E R and
ρp = lp —ψP rp E Rk such that
</listItem>
<equation confidence="0.98637">
– rk(ρ, p) = rk((lp, rp)),
– l(p) = lp(ε), and
– r(p0) = rp00(i) with ψ(p0) = (p00, i)
for every p E INT(l) and p0 E INT(r) where
– ` = l[p lp I p E INT(l)],
– s = r[p0 - (rp00)i I p0 E ψ−1(p00, i)], and
– ϕ(p0p) = p00ψp00(ip) for all positions
p0 E ψ−1(p00, i) and ip E INT(rp00).
</equation>
<bodyText confidence="0.964178">
The rule closure R≤∞ of R is R≤∞ = Si≥1 Ri. The
top-down pre-translation of R is
</bodyText>
<equation confidence="0.983092">
τt(R) = {(l,r) I l —ψ r E R≤∞, INT(l) = 0} .
</equation>
<page confidence="0.99066">
828
</page>
<figureCaption confidence="0.999843">
Figure 3: Composed rule.
</figureCaption>
<bodyText confidence="0.993245421052631">
The composition of the rules, which is illus-
trated in Figure 3, in the second item of Defini-
tion 4 could also be represented as ρ(ρ1,...,ρk)
where ρ1, ... , ρk is an enumeration of the rules
{ρp  |p ∈ ↓NT(l)} used in the item. The follow-
ing theorem is easy to prove.
Theorem 5 The bottom-up and top-down semantics
coincide; i.e., τ(R) = τt(R).
Chiang (2005) and Graehl et al. (2008) argue that
STSG have sufficient expressive power for syntax-
based machine translation, but Zhang et al. (2008a)
show that the additional expressive power of tree-
sequences helps the translation process. This is
mostly due to the fact that smaller (and less specific)
rules can be extracted from bi-parsed word-aligned
training data. A detailed overview that focusses on
STSG is presented by Knight (2007).
Theorem 6 For every LMBOT, an equivalent STSSG
can be constructed in linear time.
</bodyText>
<sectionHeader confidence="0.906119" genericHeader="method">
4 Rule extraction and training
</sectionHeader>
<bodyText confidence="0.961326028571429">
In this section, we will show how to automatically
obtain an LMBOT from a bi-parsed, word-aligned
parallel corpus. Essentially, the process has two
steps: rule extraction and training. In the rule ex-
traction step, an (unweighted) LMBOT is extracted
from the corpus. The rule weights are then set in the
training procedure.
The two main inspirations for our rule extraction
are the corresponding procedures for STSG (Galley
et al., 2004; Graehl et al., 2008) and for STSSG (Sun
et al., 2009). STSG are always contiguous in both
the left- and right-hand side, which means that they
(completely) cover a single span of input or output
words. On the contrary, STSSG rules can be non-
contiguous on both sides, but the extraction proce-
dure of Sun et al. (2009) only extracts rules that are
contiguous on the left- or right-hand side. We can
adjust its 1�t phase that extracts rules with (poten-
tially) non-contiguous right-hand sides. The adjust-
ment is necessary because LMBOT rules cannot have
(contiguous) tree sequences in their left-hand sides.
Overall, the rule extraction process is sketched in
Algorithm 1.
Algorithm 1 Rule extraction for LMBOT
Require: word-aligned tree pair (t, u)
Return: LMBOT rules R such that (t, u) ∈ τ(R)
while there exists a maximal non-leaf node
p ∈ pos(t) and minimal p1, ... , pk ∈ pos(u)
such that t|p and (u|p1, ... , u|pJ have a con-
sistent alignment (i.e., no alignments from
within t|p to a leaf outside (u|p1, . . . , u|pJ and
vice versa)
do
2: add rule ρ = t|p →ψ (up1, ... , upJ to R
with the nonterminal alignments ψ
</bodyText>
<listItem confidence="0.9636774">
// excise rule ρ from (t,u)
4: t ← t[p ← t(p)]
u ← u[pi ← u(pi)  |i ∈ {1, ... , k}]
6: establish alignments according to position
end while
</listItem>
<bodyText confidence="0.999869052631579">
The requirement that we can only have one in-
put tree in LMBOT rules indeed might cause the ex-
traction of bigger and less useful rules (when com-
pared to the corresponding STSSG rules) as demon-
strated in (Sun et al., 2009). However, the stricter
rule shape preserves the good algorithmic proper-
ties of LMBOT. The more powerful STSSG rules can
cause nonclosure under composition (Raoult, 1997;
Radmacher, 2008) and parsing to be less efficient.
Figure 4 shows an example of biparsed aligned
parallel text. According to the method of Galley et
al. (2004) we can extract the (minimal) STSG rule
displayed in Figure 5. Using the more liberal format
of LMBOT rules, we can decompose the STSG rule of
Figure 5 further into the rules displayed in Figure 1.
The method of Sun et al. (2009) would also extract
the rule displayed in Figure 6.
Let us reconsider Figures 1 and 2. Let ρ1 be
the top left rule of Figure 2 and ρ2 and ρ3 be the
</bodyText>
<figure confidence="0.995336657894737">
X
→
X
2
1
a
X
X
X
X
,
X
2
X
→ a X
1
a
X
X
b
,
X
X
→
X
2
X
a X
1
b
b
X
X
,
X
b
X
X
</figure>
<page confidence="0.735328">
829
</page>
<figureCaption confidence="0.998752">
Figure 4: Biparsed aligned parallel text.
</figureCaption>
<figure confidence="0.999887975">
twlY
NP
PP
NP
NP
PV
NP-SBJ
NP-OBJ
NP-SBJ
VP
S
NNP
Voislav
VBD
signed
PP
NP
NNP
Serbia
NML
IN
for
SrbyA
AlywgwslAfy
fwyslAf
En
DET-ADJ
NN-PROP
DET-NN
PREP
NP
DET-NN
VP
AltwqyE
NN-PROP
Alr}ys
JJ
Yugoslav
NNP
President
</figure>
<figureCaption confidence="0.999968">
Figure 5: Minimal STSG rule.
</figureCaption>
<bodyText confidence="0.9996047">
left and right rule of Figure 1, respectively. We
can represent the lower pre-translation of Figure 2
by p3(· · · , p2(p1)), where p2(p1) represents the up-
per right pre-translation of Figure 2. If we name
all rules of R, then we can represent each pre-
translation of T(R) symbolically by a tree contain-
ing rule names. Such trees containing rule names
are often called derivation trees. Overall, we obtain
the following result, for which details can be found
in (Arnold and Dauchet, 1982).
</bodyText>
<construct confidence="0.681074333333333">
Theorem 7 The set D(R) is a regular tree language
for every LMBOT R, and the set of derivations is also
regular for every MBOT.
</construct>
<figureCaption confidence="0.998763">
Figure 6: Sample STSSG rule.
</figureCaption>
<bodyText confidence="0.999980363636364">
Moreover, using the input and output product con-
structions of Maletti (2010) we obtain that even the
set Dt,u(R) of derivations for a specific input tree t
and output tree u is regular. Since Dt,u(R) is reg-
ular, we can compute the inside and outside weight
of each (weighted) rule of R following the method
of Graehl et al. (2008). Similarly, we can adjust
the training procedure of Graehl et al. (2008), which
yields that we can automatically obtain a weighted
LMBOT from a bi-parsed parallel corpus. Details on
the run-time can be found in (Graehl et al., 2008).
</bodyText>
<sectionHeader confidence="0.853272" genericHeader="method">
5 Preservation of regularity
</sectionHeader>
<bodyText confidence="0.999799">
Clearly, LMBOT are not symmetric. Although, the
backwards application of an LMBOT preserves regu-
larity, this property does not hold for forward appli-
cation. We will focus on forward application here.
Given a set T of pre-translations and a tree language
</bodyText>
<figure confidence="0.99700135483871">
VP
NP-SBJ
1
signed
VBD
S
VP
PP
1
�
twlY
PV
DET-NN
AltwqyE
NP
NP-OBJ
PP
NP-SBJ
VBD
signed
NP
, DET-NN ,
AltwqyE
PREP
En
,
IN
for
PV
�
twlY
</figure>
<page confidence="0.910092">
830
</page>
<equation confidence="0.983619">
L C TE, we let
Tc(L) = {uz I (u1, ... , uk) E T (L), i E [k]} ,
</equation>
<bodyText confidence="0.965359258426966">
which collects all translations of input trees in L.
We say that T preserves regularity if Tc(L) is regu-
lar for every regular tree language L C TE. Corre-
spondingly, an LMBOT R preserves regularity if its
set T(R) of pre-translations preserves regularity.
As mentioned, an LMBOT does not necessarily
preserve regularity. The rules of an LMBOT have
only alignments between the left-hand side (input
tree) and the right-hand side (output tree), which are
also called inter-tree alignments. However, several
alignments to a single nonterminal in the left-hand
side can transitively relate two different nontermi-
nals in the output side and thus simulate an intra-
tree alignment. For example, the right rule of Fig-
ure 1 relates a ‘PV’ and an ‘NP-OBJ’ node to a sin-
gle ‘VP’ node in the left-hand side. This could lead
to an intra-tree alignment (synchronization) between
the ‘PV’ and ‘NP-OBJ’ nodes in the right-hand side.
Figure 7 displays the rules R of an LMBOT
that does not preserve regularity. This can easily
be seen on the leaf (word) languages because the
LMBOT can translate the word x to any element
of L = {wcwc I w E {a, b}*}. Clearly, this word
language L is not context-free. Since the leaf lan-
guage of every regular tree language is context-free
and regular tree languages are closed under inter-
section (needed to single out the translations that
have the symbol Y at the root), this also proves that
T(R)c(TE) is not regular. Since TE is regular, this
proves that the LMBOT does not preserve regularity.
Preservation of regularity is an important property
for a number of translation model manipulations.
For example, the bucket-brigade and the on-the-fly
method for the efficient inference described in (May
et al., 2010) essentially build on it. Moreover, a reg-
ular tree grammar (i.e., a representation of a regular
tree language) is an efficient representation. More
complex representations such as context-free tree
grammars [see, e.g., (Fujiyoshi, 2004)] have worse
algorithmic properties (e.g., more complex parsing
and problematic intersection).
In this section, we investigate three syntactic re-
strictions on the set R of rules that guarantees that
the obtained LMBOT preserves regularity. Then we
shortly discuss how to adjust the rule extraction al-
gorithm, so that the extracted rules automatically
have these property. First, we quickly recall the no-
tion of composed rules from Definition 4 because
it will play an essential role in all three properties.
Figure 3 shows a composition of two rules from Fig-
ure 7. Mind that R2 might not contain all rules of R,
but it contains all those without leaf nonterminals.
Definition 8 An LMBOT R is finitely collapsing if
thereisn E Nsuchthato: INT(r) — INT(l)x{1}
for every rule l —*,p r E Rn.
The following statement follows from a more gen-
eral result of Raoult (1997), which we will introduce
with our second property.
Theorem 9 Every finitely collapsing LMBOT pre-
serves regularity.
Often the simple condition ‘finitely collapsing’ is
fulfilled after rule extraction. In addition, it is au-
tomatically fulfilled in an LMBOT that was obtained
from an STSG using Theorem 3. It can also be en-
sured in the rule extraction process by introducing
collapsing points for output symbols that can appear
recursively in the corpus. For example, we could en-
force that all extracted rules for clause-level output
symbols (assuming that there is no recursion not in-
volving a clause-level output symbols) should have
only 1 output tree in the right-hand side.
However, ‘finitely collapsing’ is a rather strict
property. Finitely collapsing LMBOT have only
slightly more expressive power than STSG. In fact,
they could be called STSG with input desynchro-
nization. This is due to the fact that the alignment
in composed rules establishes an injective relation
between leaf nonterminals (as in an STSG), but it
need not be bijective. Consequently, there can be
leaf nonterminals in the left-hand side that have no
aligned leaf nonterminal in the right-hand side. In
this sense, those leaf nonterminals are desynchro-
nized. This feature is illustrated in Figure 8 and
such an LMBOT can compute the transformation
{(t, a) I t E TE}, which cannot be computed by an
STSG (assuming that TE is suitably rich). Thus STSG
with input desynchronization are more expressive
than STSG, but they still compute a class of trans-
formations that is not closed under composition.
</bodyText>
<page confidence="0.989172">
831
</page>
<figure confidence="0.999089256410257">
1
X
X
—*
b
X
,
X
X
X
b
2
Y
Y
—*
1
X
X
2
X
X —*
x
X
X
X
—*
,
X
a
X
a
1
X
2
X
X
c
,
c
</figure>
<figureCaption confidence="0.961036">
Figure 7: Output subtree synchronization (intra-tree).
</figureCaption>
<figure confidence="0.9977530625">
X
Y
t3
X
X
X
X
a
��—*
—* a
...
X
Y
t1 t2
Z
t1 t2 t3
</figure>
<figureCaption confidence="0.999866">
Figure 8: Finitely collapsing LMBOT.
</figureCaption>
<bodyText confidence="0.948241967741935">
Theorem 10 For every STSG, we can construct an
equivalent finitely collapsing LMBOT in linear time.
Moreover, finitely collapsing LMBOT are strictly
more expressive than STSG.
Next, we investigate a weaker property by Raoult
(1997) that still ensures preservation of regularity.
Definition 11 An LMBOT R has finite synchroniza-
tion if there is n E N such that for every rule
l —*,p r E Rn and p E INT(l) there exists i E N
with 0−1({p} x N) C {iw I w E N*}.
In plain terms, multiple alignments to a single leaf
nonterminal at p in the left-hand side are allowed,
but all leaf nonterminals of the right-hand side that
are aligned to p must be in the same tree. Clearly,
an LMBOT with finite synchronization is finitely col-
lapsing. Raoult (1997) investigated this restriction
in the context of rational tree relations, which are a
generalization of our LMBOT. Raoult (1997) shows
that finite synchronization can be decided. The next
theorem follows from the results of Raoult (1997).
Theorem 12 Every LMBOT with finite synchroniza-
tion preserves regularity.
MBOT can compute arbitrary compositions of
STSG (Maletti, 2010). However, this no longer re-
mains true for MBOT (or LMBOT) with finite syn-
chronization.2 In Figure 9 we illustrate a transla-
tion that can be computed by a composition of two
STSG, but that cannot be computed by an MBOT
(or LMBOT) with finite synchronization. Intuitively,
when processing the chain of ‘X’s of the transforma-
tion depicted in Figure 9, the first and second suc-
</bodyText>
<footnote confidence="0.989553">
2This assumes a straightforward generalization of the ‘finite
synchronization’ property for MBOT.
</footnote>
<note confidence="0.372204">
—*
</note>
<figureCaption confidence="0.9992">
Figure 9: Transformation that cannot be computed by an
MBOT with finite synchronization.
</figureCaption>
<bodyText confidence="0.9588495">
cessor of the ‘Z’-node at the root on the output side
must be aligned to the ‘X’-chain. This is necessary
because those two mentioned subtrees must repro-
duce t1 and t2 from the end of the ‘X’-chain. We
omit the formal proof here, but obtain the following
statement.
Theorem 13 For every STSG, we can construct an
equivalent LMBOT with finite synchronization in lin-
ear time. LMBOT and MBOT with finite synchroniza-
tion are strictly more expressive than STSG and com-
pute classes that are not closed under composition.
Again, it is straightforward to adjust the rule ex-
traction algorithm by the introduction of synchro-
nization points (for example, for clause level output
symbols). We can simply require that rules extracted
for those selected output symbols fulfill the condi-
tion mentioned in Definition 11.
Finally, we introduce an even weaker version.
</bodyText>
<construct confidence="0.638084">
Definition 14 An LMBOT R is copy-free if there is
n E N such that for every rule l —*,p r E Rn and
p E INT(l) we have (i) 0−1({p} x N) C N, or
(ii) 0−1({p} x N) C {iw I w E N*} for an i E N.
</construct>
<bodyText confidence="0.999804">
Intuitively, a copy-free LMBOT has rules whose
right hand sides may use all leaf nonterminals that
are aligned to a given leaf nonterminal in the left-
hand side directly at the root (of one of the trees
</bodyText>
<page confidence="0.993087">
832
</page>
<figureCaption confidence="0.993653">
Figure 10: Composed rule that is not copy-free.
</figureCaption>
<bodyText confidence="0.985074636363636">
in the right-hand side forest) or group all those leaf
nonterminals in a single tree in the forest. Clearly,
the LMBOT of Figure 7 is not copy-free because the
second rule composes with itself (see Figure 10) to
a rule that does not fulfill the copy-free condition.
Theorem 15 Every copy-free LMBOT preserves
regularity.
Proof sketch: Let n be the integer of Defini-
tion 14. We replace the LMBOT with rules R by the
equivalent LMBOT M with rules Rn. Then all rules
have the form required in Definition 14. Moreover,
let L C_ TE be a regular tree language. Then we
can construct the input product of T(M) with L. In
this way, we obtain an MBOT M&apos;, whose rules still
fulfill the requirements (adapted for MBOT) of Defi-
nition 14 because the input product does not change
the structure of the rules (it only modifies the state
behavior). Consequently, we only need to show that
the range of the MBOT M&apos; is regular. This can be
achieved using a decomposition into a relabeling,
which clearly preserves regularity, and a determinis-
tic finite-copying top-down tree transducer (Engel-
</bodyText>
<figureCaption confidence="0.8686395">
friet et al., 1980; Engelfriet, 1982). ❑
Figure 11 shows some relevant rules of a copy-
free LMBOT that computes the transformation of
Figure 9. Clearly, copy-free LMBOT are more gen-
</figureCaption>
<bodyText confidence="0.916660375">
eral than LMBOT with finite synchronization, so we
again can obtain copy-free LMBOT from STSG. In
addition, we can adjust the rule extraction process
using synchronization points as for LMBOT with fi-
nite synchronization using the restrictions of Defini-
tion 14.
Theorem 16 For every STSG, we can construct
an equivalent copy-free LMBOT in linear time.
</bodyText>
<figureCaption confidence="0.6386475">
Figure 11: Copy-free LMBOT for the transformation
of Figure 9.
Copy-free LMBOT are strictly more expressive than
LMBOT with finite synchronization.
</figureCaption>
<sectionHeader confidence="0.989638" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999990692307692">
We have introduced a simple restriction of multi
bottom-up tree transducers. It abstracts from the
general state behavior of the general model and
only uses the locality tests that are also present in
STSG, STSSG, and STAG. Next, we introduced a
rule extraction procedure and a corresponding rule
weight training procedure for our LMBOT. However,
LMBOT allow translations that do not preserve reg-
ularity, which is an important property for efficient
algorithms. We presented 3 properties that ensure
that regularity is preserved. In addition, we shortly
discussed how these properties could be enforced in
the presented rule extraction procedure.
</bodyText>
<sectionHeader confidence="0.996177" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.996871714285714">
The author gratefully acknowledges the support by
KEVIN KNIGHT, who provided the inspiration and
the data. JONATHAN MAY helped in many fruitful
discussions.
The author was financially supported by
the German Research Foundation (DFG) grant
MA / 4959 / 1-1.
</bodyText>
<figure confidence="0.999449543478261">
...
�
X
,
X
a ...
X
a ...
X
X
a
X
1
2
a
X
X
X
a X
X
a X
Y
Z
X
2
1
S
�
S
S
S
(�
1
2
X
X
S
X
Y
1
S
2
(S
, S
S
, S
</figure>
<page confidence="0.99634">
833
</page>
<sectionHeader confidence="0.993069" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999903722222222">
Alfred V. Aho and Jeffrey D. Ullman. 1972. The Theory
of Parsing, Translation, and Compiling. Prentice Hall.
Andr´e Arnold and Max Dauchet. 1982. Morphismes
et bimorphismes d’arbres. Theoret. Comput. Sci.,
20(1):33–93.
Peter F. Brown, John Cocke, Stephen A. Della Pietra,
Vincent J. Della Pietra, Fredrick Jelinek, John D. Laf-
ferty, Robert L. Mercer, and Paul S. Roossin. 1990. A
statistical approach to machine translation. Computa-
tional Linguistics, 16(2):79–85.
Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della
Pietra, and Robert L. Mercer. 1993. Mathematics of
statistical machine translation: Parameter estimation.
Computational Linguistics, 19(2):263–311.
David Chiang. 2005. A hierarchical phrase-based model
for statistical machine translation. In Proc. ACL, pages
263–270. Association for Computational Linguistics.
David Chiang. 2006. An introduction to synchronous
grammars. In Proc. ACL. Association for Computa-
tional Linguistics. Part of a tutorial given with Kevin
Knight.
Jason Eisner. 2003. Simpler and more general mini-
mization for weighted finite-state automata. In Proc.
NAACL, pages 64–71. Association for Computational
Linguistics.
Joost Engelfriet, Grzegorz Rozenberg, and Giora Slutzki.
1980. Tree transducers, L systems, and two-way ma-
chines. J. Comput. System Sci., 20(2):150–202.
Joost Engelfriet, Eric Lilin, and Andreas Maletti. 2009.
Composition and decomposition of extended multi
bottom-up tree transducers. Acta Inform., 46(8):561–
590.
Joost Engelfriet. 1982. The copying power of one-state
tree transducers. J. Comput. System Sci., 25(3):418–
435.
Akio Fujiyoshi. 2004. Restrictions on monadic context-
free tree grammars. In Proc. CoLing, pages 78–84.
Association for Computational Linguistics.
Michel Galley, Mark Hopkins, Kevin Knight, and Daniel
Marcu. 2004. What’s in a translation rule? In Proc.
HLT-NAACL, pages 273–280. Association for Compu-
tational Linguistics.
Jonathan Graehl, Kevin Knight, and Jonathan May. 2008.
Training tree transducers. Computational Linguistics,
34(3):391–427.
Kevin Knight. 2007. Capturing practical natu-
ral language transformations. Machine Translation,
21(2):121–133.
Eric Lilin. 1981. Propri´et´es de clˆoture d’une ex-
tension de transducteurs d’arbres d´eterministes. In
Proc. CAAP, volume 112 of LNCS, pages 280–289.
Springer.
Andreas Maletti. 2010. Why synchronous tree substi-
tution grammars? In Proc. NAACL, pages 876–884.
Association for Computational Linguistics.
Jonathan May, Kevin Knight, and Heiko Vogler. 2010.
Efficient inference through cascades of weighted tree
transducers. In Proc. ACL, pages 1058–1066. Associ-
ation for Computational Linguistics.
Frank G. Radmacher. 2008. An automata theoretic ap-
proach to rational tree relations. In Proc. SOFSEM,
volume 4910 of LNCS, pages 424–435. Springer.
Jean-Claude Raoult. 1997. Rational tree relations. Bull.
Belg. Math. Soc. Simon Stevin, 4(1):149–176.
Stuart M. Shieber and Yves Schabes. 1990. Synchronous
tree-adjoining grammars. In Proc. CoLing, volume 3,
pages 253–258. Association for Computational Lin-
guistics.
Stuart M. Shieber. 2004. Synchronous grammars as tree
transducers. In Proc. TAG+7, pages 88–95, Vancou-
ver, BC, Canada. Simon Fraser University.
Stuart M. Shieber. 2007. Probabilistic synchronous tree-
adjoining grammars for machine translation: The ar-
gument from bilingual dictionaries. In Proc. SSST,
pages 88–95. Association for Computational Linguis-
tics.
Jun Sun, Min Zhang, and Chew Lim Tan. 2009. A non-
contiguous tree sequence alignment-based model for
statistical machine translation. In Proc. ACL, pages
914–922. Association for Computational Linguistics.
Min Zhang, Hongfei Jiang, Aiti Aw, Haizhou Li,
Chew Lim Tan, and Sheng Li. 2008a. A tree se-
quence alignment-based tree-to-tree translation model.
In Proc. ACL, pages 559–567. Association for Compu-
tational Linguistics.
Min Zhang, Hongfei Jiang, Haizhou Li, Aiti Aw, and
Sheng Li. 2008b. Grammar comparison study for
translational equivalence modeling and statistical ma-
chine translation. In Proc. CoLing, pages 1097–1104.
Association for Computational Linguistics.
</reference>
<page confidence="0.998708">
834
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.880426">
<title confidence="0.99794">How to train your multi bottom-up tree transducer</title>
<author confidence="0.979337">Andreas</author>
<affiliation confidence="0.985976">Universit¨at Stuttgart, Institute for Natural Language</affiliation>
<address confidence="0.911112">Azenbergstraße 12, 70174 Stuttgart,</address>
<email confidence="0.996987">andreas.maletti@ims.uni-stuttgart.de</email>
<abstract confidence="0.9987325">The local multi bottom-up tree transducer is introduced and related to the (non-contiguous) synchronous tree sequence substitution grammar. It is then shown how to obtain a weighted local multi bottom-up tree transducer from a bilingual and biparsed corpus. Finally, the problem of non-preservation of regularity is addressed. Three properties that ensure preservation are introduced, and it is discussed how to adjust the rule extraction process such that they are automatically fulfilled.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Alfred V Aho</author>
<author>Jeffrey D Ullman</author>
</authors>
<date>1972</date>
<booktitle>The Theory of Parsing, Translation, and Compiling.</booktitle>
<publisher>Prentice Hall.</publisher>
<contexts>
<context position="1777" citStr="Aho and Ullman (1972)" startWordPosition="257" endWordPosition="260"> their surrounding context. Contrary, in the field of syntax-based machine translation, the translation models have full access to the syntax of the sentences and can base their decision on it. A good exposition to both fields is presented in (Knight, 2007). In this paper, we deal exclusively with syntaxbased translation models such as synchronous tree substitution grammars (STSG), multi bottom-up tree transducers (MBOT), and synchronous tree-sequence substitution grammars (STSSG). Chiang (2006) gives a good introduction to STSG, which originate from the syntax-directed translation schemes of Aho and Ullman (1972). Roughly speaking, an STSG has rules in which two linked nonterminals are replaced (at the same time) by two corresponding trees containing terminal and nonterminal symbols. In addition, the nonterminals in the two replacement trees are linked, which creates new linked nonterminals to which further rules can be applied. Henceforth, we refer to these two trees as input and output tree. MBOT have been introduced in (Arnold and Dauchet, 1982; Lilin, 1981) and are slightly more expressive than STSG. Roughly speaking, they allow one replacement input tree and several output trees in a single rule.</context>
</contexts>
<marker>Aho, Ullman, 1972</marker>
<rawString>Alfred V. Aho and Jeffrey D. Ullman. 1972. The Theory of Parsing, Translation, and Compiling. Prentice Hall.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andr´e Arnold</author>
<author>Max Dauchet</author>
</authors>
<title>Morphismes et bimorphismes d’arbres.</title>
<date>1982</date>
<journal>Theoret. Comput. Sci.,</journal>
<volume>20</volume>
<issue>1</issue>
<contexts>
<context position="2220" citStr="Arnold and Dauchet, 1982" startWordPosition="330" endWordPosition="333">s tree-sequence substitution grammars (STSSG). Chiang (2006) gives a good introduction to STSG, which originate from the syntax-directed translation schemes of Aho and Ullman (1972). Roughly speaking, an STSG has rules in which two linked nonterminals are replaced (at the same time) by two corresponding trees containing terminal and nonterminal symbols. In addition, the nonterminals in the two replacement trees are linked, which creates new linked nonterminals to which further rules can be applied. Henceforth, we refer to these two trees as input and output tree. MBOT have been introduced in (Arnold and Dauchet, 1982; Lilin, 1981) and are slightly more expressive than STSG. Roughly speaking, they allow one replacement input tree and several output trees in a single rule. This change and the presence of states yields many algorithmically advantageous properties such as closure under composition, efficient binarization, and efficient input and output restriction [see (Maletti, 2010)]. Finally, STSSG, which have been derived from rational tree relations (Raoult, 1997), have been discussed by Zhang et al. (2008a), Zhang et al. (2008b), and Sun et al. (2009). They are even more expressive than the local varian</context>
<context position="7749" citStr="Arnold and Dauchet (1982)" startWordPosition="1411" endWordPosition="1414"> Q∗ × Σ × Q is a finite relation, and F ⊆ Q We extend 6 to a mapping 6: TΣ → 2(Q by 6(Q(t)) = {q |(q, Q, q) ∈ 6, ∀i ∈ [ |t |]: qi ∈ 6(ti)} for every Q ∈ Σ and t ∈ T∗Σ. The finite tree automaton M recognizes the tree language L(M) = {t ∈ TΣ |6(t) ∩ F =6 ∅} . A tree language L ⊆ TΣ is regular if there exists a finite tree automaton M such that L = L(M). 826 NP-OBJ VP VBD signed PP 1 → PV twlY , NP DET-NN AltwqyE PP S VP NP-SBJ 1 VP 2 → 1 PV NP-OBJ NP-SBJ Figure 1: Sample LMBOT rules. 3 The model In this section, we recall particular multi bottomup tree transducers, which have been introduced by Arnold and Dauchet (1982) and Lilin (1981). A detailed (and English) presentation of the general model can be found in Engelfriet et al. (2009) and Maletti (2010). Using the nomenclature of Engelfriet et al. (2009), we recall a variant of linear and nondeleting extended multi bottom-up tree transducers (MBOT) here. Occasionally, we will refer to general MBOT, which differ from the local variant discussed here because they have explicit states. Throughout the article, we assume sets E and A of input and output symbols, respectively. Moreover, let NT ⊆ E ∪ A be the set of designated nonterminal symbols. Finally, we avoi</context>
<context position="17880" citStr="Arnold and Dauchet, 1982" startWordPosition="3329" endWordPosition="3332">wgwslAfy fwyslAf En DET-ADJ NN-PROP DET-NN PREP NP DET-NN VP AltwqyE NN-PROP Alr}ys JJ Yugoslav NNP President Figure 5: Minimal STSG rule. left and right rule of Figure 1, respectively. We can represent the lower pre-translation of Figure 2 by p3(· · · , p2(p1)), where p2(p1) represents the upper right pre-translation of Figure 2. If we name all rules of R, then we can represent each pretranslation of T(R) symbolically by a tree containing rule names. Such trees containing rule names are often called derivation trees. Overall, we obtain the following result, for which details can be found in (Arnold and Dauchet, 1982). Theorem 7 The set D(R) is a regular tree language for every LMBOT R, and the set of derivations is also regular for every MBOT. Figure 6: Sample STSSG rule. Moreover, using the input and output product constructions of Maletti (2010) we obtain that even the set Dt,u(R) of derivations for a specific input tree t and output tree u is regular. Since Dt,u(R) is regular, we can compute the inside and outside weight of each (weighted) rule of R following the method of Graehl et al. (2008). Similarly, we can adjust the training procedure of Graehl et al. (2008), which yields that we can automatical</context>
</contexts>
<marker>Arnold, Dauchet, 1982</marker>
<rawString>Andr´e Arnold and Max Dauchet. 1982. Morphismes et bimorphismes d’arbres. Theoret. Comput. Sci., 20(1):33–93.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>John Cocke</author>
<author>Stephen A Della Pietra</author>
<author>Vincent J Della Pietra</author>
<author>Fredrick Jelinek</author>
<author>John D Lafferty</author>
<author>Robert L Mercer</author>
<author>Paul S Roossin</author>
</authors>
<title>A statistical approach to machine translation.</title>
<date>1990</date>
<journal>Computational Linguistics,</journal>
<volume>16</volume>
<issue>2</issue>
<contexts>
<context position="948" citStr="Brown et al. (1990)" startWordPosition="131" endWordPosition="134">e sequence substitution grammar. It is then shown how to obtain a weighted local multi bottom-up tree transducer from a bilingual and biparsed corpus. Finally, the problem of non-preservation of regularity is addressed. Three properties that ensure preservation are introduced, and it is discussed how to adjust the rule extraction process such that they are automatically fulfilled. 1 Introduction A (formal) translation model is at the core of every machine translation system. Predominantly, statistical processes are used to instantiate the formal model and derive a specific translation device. Brown et al. (1990) discuss automatically trainable translation models in their seminal paper. However, the IBM models of Brown et al. (1993) are stringbased in the sense that they base the translation decision on the words and their surrounding context. Contrary, in the field of syntax-based machine translation, the translation models have full access to the syntax of the sentences and can base their decision on it. A good exposition to both fields is presented in (Knight, 2007). In this paper, we deal exclusively with syntaxbased translation models such as synchronous tree substitution grammars (STSG), multi b</context>
</contexts>
<marker>Brown, Cocke, Pietra, Pietra, Jelinek, Lafferty, Mercer, Roossin, 1990</marker>
<rawString>Peter F. Brown, John Cocke, Stephen A. Della Pietra, Vincent J. Della Pietra, Fredrick Jelinek, John D. Lafferty, Robert L. Mercer, and Paul S. Roossin. 1990. A statistical approach to machine translation. Computational Linguistics, 16(2):79–85.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Stephen A Della Pietra</author>
<author>Vincent J Della Pietra</author>
<author>Robert L Mercer</author>
</authors>
<title>Mathematics of statistical machine translation: Parameter estimation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="1070" citStr="Brown et al. (1993)" startWordPosition="149" endWordPosition="152">lingual and biparsed corpus. Finally, the problem of non-preservation of regularity is addressed. Three properties that ensure preservation are introduced, and it is discussed how to adjust the rule extraction process such that they are automatically fulfilled. 1 Introduction A (formal) translation model is at the core of every machine translation system. Predominantly, statistical processes are used to instantiate the formal model and derive a specific translation device. Brown et al. (1990) discuss automatically trainable translation models in their seminal paper. However, the IBM models of Brown et al. (1993) are stringbased in the sense that they base the translation decision on the words and their surrounding context. Contrary, in the field of syntax-based machine translation, the translation models have full access to the syntax of the sentences and can base their decision on it. A good exposition to both fields is presented in (Knight, 2007). In this paper, we deal exclusively with syntaxbased translation models such as synchronous tree substitution grammars (STSG), multi bottom-up tree transducers (MBOT), and synchronous tree-sequence substitution grammars (STSSG). Chiang (2006) gives a good </context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della Pietra, and Robert L. Mercer. 1993. Mathematics of statistical machine translation: Parameter estimation. Computational Linguistics, 19(2):263–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>A hierarchical phrase-based model for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>263--270</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="13859" citStr="Chiang (2005)" startWordPosition="2593" endWordPosition="2594"> p0 E ψ−1(p00, i)], and – ϕ(p0p) = p00ψp00(ip) for all positions p0 E ψ−1(p00, i) and ip E INT(rp00). The rule closure R≤∞ of R is R≤∞ = Si≥1 Ri. The top-down pre-translation of R is τt(R) = {(l,r) I l —ψ r E R≤∞, INT(l) = 0} . 828 Figure 3: Composed rule. The composition of the rules, which is illustrated in Figure 3, in the second item of Definition 4 could also be represented as ρ(ρ1,...,ρk) where ρ1, ... , ρk is an enumeration of the rules {ρp |p ∈ ↓NT(l)} used in the item. The following theorem is easy to prove. Theorem 5 The bottom-up and top-down semantics coincide; i.e., τ(R) = τt(R). Chiang (2005) and Graehl et al. (2008) argue that STSG have sufficient expressive power for syntaxbased machine translation, but Zhang et al. (2008a) show that the additional expressive power of treesequences helps the translation process. This is mostly due to the fact that smaller (and less specific) rules can be extracted from bi-parsed word-aligned training data. A detailed overview that focusses on STSG is presented by Knight (2007). Theorem 6 For every LMBOT, an equivalent STSSG can be constructed in linear time. 4 Rule extraction and training In this section, we will show how to automatically obtain</context>
</contexts>
<marker>Chiang, 2005</marker>
<rawString>David Chiang. 2005. A hierarchical phrase-based model for statistical machine translation. In Proc. ACL, pages 263–270. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>An introduction to synchronous grammars.</title>
<date>2006</date>
<booktitle>In Proc. ACL.</booktitle>
<publisher>Association</publisher>
<contexts>
<context position="1656" citStr="Chiang (2006)" startWordPosition="241" endWordPosition="242">dels of Brown et al. (1993) are stringbased in the sense that they base the translation decision on the words and their surrounding context. Contrary, in the field of syntax-based machine translation, the translation models have full access to the syntax of the sentences and can base their decision on it. A good exposition to both fields is presented in (Knight, 2007). In this paper, we deal exclusively with syntaxbased translation models such as synchronous tree substitution grammars (STSG), multi bottom-up tree transducers (MBOT), and synchronous tree-sequence substitution grammars (STSSG). Chiang (2006) gives a good introduction to STSG, which originate from the syntax-directed translation schemes of Aho and Ullman (1972). Roughly speaking, an STSG has rules in which two linked nonterminals are replaced (at the same time) by two corresponding trees containing terminal and nonterminal symbols. In addition, the nonterminals in the two replacement trees are linked, which creates new linked nonterminals to which further rules can be applied. Henceforth, we refer to these two trees as input and output tree. MBOT have been introduced in (Arnold and Dauchet, 1982; Lilin, 1981) and are slightly more</context>
</contexts>
<marker>Chiang, 2006</marker>
<rawString>David Chiang. 2006. An introduction to synchronous grammars. In Proc. ACL. Association for Computational Linguistics. Part of a tutorial given with Kevin Knight.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Eisner</author>
</authors>
<title>Simpler and more general minimization for weighted finite-state automata.</title>
<date>2003</date>
<booktitle>In Proc. NAACL,</booktitle>
<pages>64--71</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="9627" citStr="Eisner (2003)" startWordPosition="1765" endWordPosition="1766">∈ [i]. In other words, an alignment should request each translation of a particular subtree at most once and if it requests the ith translation, then it should also request all previous translations. Definition 1 A local multi bottom-up tree transducer (LMBOT) is a finite set R of rules such that every rule, written l →,p r, contains a pre-translation hl, ri and an alignment ψ for it. The component l is the left-hand side, r is the right-hand side, and ψ is the alignment of a rule l →,p r ∈ R. The rules of an LMBOT are similar to the rules of an STSG (synchronous tree substitution grammar) of Eisner (2003) and Shieber (2004), but right-hand sides of LMBOT contain a sequence of trees instead of just a single tree as in an STSG. In addition, the alignments in an STSG rule are bijective between leaf nonterminals, whereas our model permits multiple alignments to a single leaf nonterminal in the left-hand side. A model that is even more powerful than LMBOT is the non-contiguous version of STSSG (synchronous tree-sequence substitution grammar) of Zhang et al. (2008a), Zhang et al. (2008b), and Sun et al. (2009), which allows sequences of trees on both sides of rules [see also (Raoult, 1997)]. Figure </context>
</contexts>
<marker>Eisner, 2003</marker>
<rawString>Jason Eisner. 2003. Simpler and more general minimization for weighted finite-state automata. In Proc. NAACL, pages 64–71. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joost Engelfriet</author>
<author>Grzegorz Rozenberg</author>
<author>Giora Slutzki</author>
</authors>
<title>Tree transducers, L systems, and two-way machines.</title>
<date>1980</date>
<journal>J. Comput. System Sci.,</journal>
<volume>20</volume>
<issue>2</issue>
<contexts>
<context position="27799" citStr="Engelfriet et al., 1980" startWordPosition="5065" endWordPosition="5069">the form required in Definition 14. Moreover, let L C_ TE be a regular tree language. Then we can construct the input product of T(M) with L. In this way, we obtain an MBOT M&apos;, whose rules still fulfill the requirements (adapted for MBOT) of Definition 14 because the input product does not change the structure of the rules (it only modifies the state behavior). Consequently, we only need to show that the range of the MBOT M&apos; is regular. This can be achieved using a decomposition into a relabeling, which clearly preserves regularity, and a deterministic finite-copying top-down tree transducer (Engelfriet et al., 1980; Engelfriet, 1982). ❑ Figure 11 shows some relevant rules of a copyfree LMBOT that computes the transformation of Figure 9. Clearly, copy-free LMBOT are more general than LMBOT with finite synchronization, so we again can obtain copy-free LMBOT from STSG. In addition, we can adjust the rule extraction process using synchronization points as for LMBOT with finite synchronization using the restrictions of Definition 14. Theorem 16 For every STSG, we can construct an equivalent copy-free LMBOT in linear time. Figure 11: Copy-free LMBOT for the transformation of Figure 9. Copy-free LMBOT are stri</context>
</contexts>
<marker>Engelfriet, Rozenberg, Slutzki, 1980</marker>
<rawString>Joost Engelfriet, Grzegorz Rozenberg, and Giora Slutzki. 1980. Tree transducers, L systems, and two-way machines. J. Comput. System Sci., 20(2):150–202.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joost Engelfriet</author>
<author>Eric Lilin</author>
<author>Andreas Maletti</author>
</authors>
<title>Composition and decomposition of extended multi bottom-up tree transducers.</title>
<date>2009</date>
<journal>Acta Inform.,</journal>
<volume>46</volume>
<issue>8</issue>
<pages>590</pages>
<contexts>
<context position="7867" citStr="Engelfriet et al. (2009)" startWordPosition="1431" endWordPosition="1434"> |t |]: qi ∈ 6(ti)} for every Q ∈ Σ and t ∈ T∗Σ. The finite tree automaton M recognizes the tree language L(M) = {t ∈ TΣ |6(t) ∩ F =6 ∅} . A tree language L ⊆ TΣ is regular if there exists a finite tree automaton M such that L = L(M). 826 NP-OBJ VP VBD signed PP 1 → PV twlY , NP DET-NN AltwqyE PP S VP NP-SBJ 1 VP 2 → 1 PV NP-OBJ NP-SBJ Figure 1: Sample LMBOT rules. 3 The model In this section, we recall particular multi bottomup tree transducers, which have been introduced by Arnold and Dauchet (1982) and Lilin (1981). A detailed (and English) presentation of the general model can be found in Engelfriet et al. (2009) and Maletti (2010). Using the nomenclature of Engelfriet et al. (2009), we recall a variant of linear and nondeleting extended multi bottom-up tree transducers (MBOT) here. Occasionally, we will refer to general MBOT, which differ from the local variant discussed here because they have explicit states. Throughout the article, we assume sets E and A of input and output symbols, respectively. Moreover, let NT ⊆ E ∪ A be the set of designated nonterminal symbols. Finally, we avoid weights in the formal development to keep it simple. It is straightforward to add weights to our model. Essentially,</context>
</contexts>
<marker>Engelfriet, Lilin, Maletti, 2009</marker>
<rawString>Joost Engelfriet, Eric Lilin, and Andreas Maletti. 2009. Composition and decomposition of extended multi bottom-up tree transducers. Acta Inform., 46(8):561– 590.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joost Engelfriet</author>
</authors>
<title>The copying power of one-state tree transducers.</title>
<date>1982</date>
<journal>J. Comput. System Sci.,</journal>
<volume>25</volume>
<issue>3</issue>
<pages>435</pages>
<contexts>
<context position="27818" citStr="Engelfriet, 1982" startWordPosition="5070" endWordPosition="5071">nition 14. Moreover, let L C_ TE be a regular tree language. Then we can construct the input product of T(M) with L. In this way, we obtain an MBOT M&apos;, whose rules still fulfill the requirements (adapted for MBOT) of Definition 14 because the input product does not change the structure of the rules (it only modifies the state behavior). Consequently, we only need to show that the range of the MBOT M&apos; is regular. This can be achieved using a decomposition into a relabeling, which clearly preserves regularity, and a deterministic finite-copying top-down tree transducer (Engelfriet et al., 1980; Engelfriet, 1982). ❑ Figure 11 shows some relevant rules of a copyfree LMBOT that computes the transformation of Figure 9. Clearly, copy-free LMBOT are more general than LMBOT with finite synchronization, so we again can obtain copy-free LMBOT from STSG. In addition, we can adjust the rule extraction process using synchronization points as for LMBOT with finite synchronization using the restrictions of Definition 14. Theorem 16 For every STSG, we can construct an equivalent copy-free LMBOT in linear time. Figure 11: Copy-free LMBOT for the transformation of Figure 9. Copy-free LMBOT are strictly more expressiv</context>
</contexts>
<marker>Engelfriet, 1982</marker>
<rawString>Joost Engelfriet. 1982. The copying power of one-state tree transducers. J. Comput. System Sci., 25(3):418– 435.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Akio Fujiyoshi</author>
</authors>
<title>Restrictions on monadic contextfree tree grammars.</title>
<date>2004</date>
<booktitle>In Proc. CoLing,</booktitle>
<pages>78--84</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="21060" citStr="Fujiyoshi, 2004" startWordPosition="3884" endWordPosition="3885">hat have the symbol Y at the root), this also proves that T(R)c(TE) is not regular. Since TE is regular, this proves that the LMBOT does not preserve regularity. Preservation of regularity is an important property for a number of translation model manipulations. For example, the bucket-brigade and the on-the-fly method for the efficient inference described in (May et al., 2010) essentially build on it. Moreover, a regular tree grammar (i.e., a representation of a regular tree language) is an efficient representation. More complex representations such as context-free tree grammars [see, e.g., (Fujiyoshi, 2004)] have worse algorithmic properties (e.g., more complex parsing and problematic intersection). In this section, we investigate three syntactic restrictions on the set R of rules that guarantees that the obtained LMBOT preserves regularity. Then we shortly discuss how to adjust the rule extraction algorithm, so that the extracted rules automatically have these property. First, we quickly recall the notion of composed rules from Definition 4 because it will play an essential role in all three properties. Figure 3 shows a composition of two rules from Figure 7. Mind that R2 might not contain all </context>
</contexts>
<marker>Fujiyoshi, 2004</marker>
<rawString>Akio Fujiyoshi. 2004. Restrictions on monadic contextfree tree grammars. In Proc. CoLing, pages 78–84. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Galley</author>
<author>Mark Hopkins</author>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
</authors>
<title>What’s in a translation rule? In</title>
<date>2004</date>
<booktitle>Proc. HLT-NAACL,</booktitle>
<pages>273--280</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="14837" citStr="Galley et al., 2004" startWordPosition="2748" endWordPosition="2751">detailed overview that focusses on STSG is presented by Knight (2007). Theorem 6 For every LMBOT, an equivalent STSSG can be constructed in linear time. 4 Rule extraction and training In this section, we will show how to automatically obtain an LMBOT from a bi-parsed, word-aligned parallel corpus. Essentially, the process has two steps: rule extraction and training. In the rule extraction step, an (unweighted) LMBOT is extracted from the corpus. The rule weights are then set in the training procedure. The two main inspirations for our rule extraction are the corresponding procedures for STSG (Galley et al., 2004; Graehl et al., 2008) and for STSSG (Sun et al., 2009). STSG are always contiguous in both the left- and right-hand side, which means that they (completely) cover a single span of input or output words. On the contrary, STSSG rules can be noncontiguous on both sides, but the extraction procedure of Sun et al. (2009) only extracts rules that are contiguous on the left- or right-hand side. We can adjust its 1�t phase that extracts rules with (potentially) non-contiguous right-hand sides. The adjustment is necessary because LMBOT rules cannot have (contiguous) tree sequences in their left-hand s</context>
<context position="16644" citStr="Galley et al. (2004)" startWordPosition="3076" endWordPosition="3079">{1, ... , k}] 6: establish alignments according to position end while The requirement that we can only have one input tree in LMBOT rules indeed might cause the extraction of bigger and less useful rules (when compared to the corresponding STSSG rules) as demonstrated in (Sun et al., 2009). However, the stricter rule shape preserves the good algorithmic properties of LMBOT. The more powerful STSSG rules can cause nonclosure under composition (Raoult, 1997; Radmacher, 2008) and parsing to be less efficient. Figure 4 shows an example of biparsed aligned parallel text. According to the method of Galley et al. (2004) we can extract the (minimal) STSG rule displayed in Figure 5. Using the more liberal format of LMBOT rules, we can decompose the STSG rule of Figure 5 further into the rules displayed in Figure 1. The method of Sun et al. (2009) would also extract the rule displayed in Figure 6. Let us reconsider Figures 1 and 2. Let ρ1 be the top left rule of Figure 2 and ρ2 and ρ3 be the X → X 2 1 a X X X X , X 2 X → a X 1 a X X b , X X → X 2 X a X 1 b b X X , X b X X 829 Figure 4: Biparsed aligned parallel text. twlY NP PP NP NP PV NP-SBJ NP-OBJ NP-SBJ VP S NNP Voislav VBD signed PP NP NNP Serbia NML IN fo</context>
</contexts>
<marker>Galley, Hopkins, Knight, Marcu, 2004</marker>
<rawString>Michel Galley, Mark Hopkins, Kevin Knight, and Daniel Marcu. 2004. What’s in a translation rule? In Proc. HLT-NAACL, pages 273–280. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan Graehl</author>
<author>Kevin Knight</author>
<author>Jonathan May</author>
</authors>
<title>Training tree transducers.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>3</issue>
<contexts>
<context position="13884" citStr="Graehl et al. (2008)" startWordPosition="2596" endWordPosition="2599">, and – ϕ(p0p) = p00ψp00(ip) for all positions p0 E ψ−1(p00, i) and ip E INT(rp00). The rule closure R≤∞ of R is R≤∞ = Si≥1 Ri. The top-down pre-translation of R is τt(R) = {(l,r) I l —ψ r E R≤∞, INT(l) = 0} . 828 Figure 3: Composed rule. The composition of the rules, which is illustrated in Figure 3, in the second item of Definition 4 could also be represented as ρ(ρ1,...,ρk) where ρ1, ... , ρk is an enumeration of the rules {ρp |p ∈ ↓NT(l)} used in the item. The following theorem is easy to prove. Theorem 5 The bottom-up and top-down semantics coincide; i.e., τ(R) = τt(R). Chiang (2005) and Graehl et al. (2008) argue that STSG have sufficient expressive power for syntaxbased machine translation, but Zhang et al. (2008a) show that the additional expressive power of treesequences helps the translation process. This is mostly due to the fact that smaller (and less specific) rules can be extracted from bi-parsed word-aligned training data. A detailed overview that focusses on STSG is presented by Knight (2007). Theorem 6 For every LMBOT, an equivalent STSSG can be constructed in linear time. 4 Rule extraction and training In this section, we will show how to automatically obtain an LMBOT from a bi-parse</context>
<context position="18369" citStr="Graehl et al. (2008)" startWordPosition="3419" endWordPosition="3422">ften called derivation trees. Overall, we obtain the following result, for which details can be found in (Arnold and Dauchet, 1982). Theorem 7 The set D(R) is a regular tree language for every LMBOT R, and the set of derivations is also regular for every MBOT. Figure 6: Sample STSSG rule. Moreover, using the input and output product constructions of Maletti (2010) we obtain that even the set Dt,u(R) of derivations for a specific input tree t and output tree u is regular. Since Dt,u(R) is regular, we can compute the inside and outside weight of each (weighted) rule of R following the method of Graehl et al. (2008). Similarly, we can adjust the training procedure of Graehl et al. (2008), which yields that we can automatically obtain a weighted LMBOT from a bi-parsed parallel corpus. Details on the run-time can be found in (Graehl et al., 2008). 5 Preservation of regularity Clearly, LMBOT are not symmetric. Although, the backwards application of an LMBOT preserves regularity, this property does not hold for forward application. We will focus on forward application here. Given a set T of pre-translations and a tree language VP NP-SBJ 1 signed VBD S VP PP 1 � twlY PV DET-NN AltwqyE NP NP-OBJ PP NP-SBJ VBD </context>
</contexts>
<marker>Graehl, Knight, May, 2008</marker>
<rawString>Jonathan Graehl, Kevin Knight, and Jonathan May. 2008. Training tree transducers. Computational Linguistics, 34(3):391–427.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Knight</author>
</authors>
<title>Capturing practical natural language transformations.</title>
<date>2007</date>
<journal>Machine Translation,</journal>
<volume>21</volume>
<issue>2</issue>
<contexts>
<context position="1413" citStr="Knight, 2007" startWordPosition="210" endWordPosition="211"> system. Predominantly, statistical processes are used to instantiate the formal model and derive a specific translation device. Brown et al. (1990) discuss automatically trainable translation models in their seminal paper. However, the IBM models of Brown et al. (1993) are stringbased in the sense that they base the translation decision on the words and their surrounding context. Contrary, in the field of syntax-based machine translation, the translation models have full access to the syntax of the sentences and can base their decision on it. A good exposition to both fields is presented in (Knight, 2007). In this paper, we deal exclusively with syntaxbased translation models such as synchronous tree substitution grammars (STSG), multi bottom-up tree transducers (MBOT), and synchronous tree-sequence substitution grammars (STSSG). Chiang (2006) gives a good introduction to STSG, which originate from the syntax-directed translation schemes of Aho and Ullman (1972). Roughly speaking, an STSG has rules in which two linked nonterminals are replaced (at the same time) by two corresponding trees containing terminal and nonterminal symbols. In addition, the nonterminals in the two replacement trees ar</context>
<context position="14287" citStr="Knight (2007)" startWordPosition="2661" endWordPosition="2662">ration of the rules {ρp |p ∈ ↓NT(l)} used in the item. The following theorem is easy to prove. Theorem 5 The bottom-up and top-down semantics coincide; i.e., τ(R) = τt(R). Chiang (2005) and Graehl et al. (2008) argue that STSG have sufficient expressive power for syntaxbased machine translation, but Zhang et al. (2008a) show that the additional expressive power of treesequences helps the translation process. This is mostly due to the fact that smaller (and less specific) rules can be extracted from bi-parsed word-aligned training data. A detailed overview that focusses on STSG is presented by Knight (2007). Theorem 6 For every LMBOT, an equivalent STSSG can be constructed in linear time. 4 Rule extraction and training In this section, we will show how to automatically obtain an LMBOT from a bi-parsed, word-aligned parallel corpus. Essentially, the process has two steps: rule extraction and training. In the rule extraction step, an (unweighted) LMBOT is extracted from the corpus. The rule weights are then set in the training procedure. The two main inspirations for our rule extraction are the corresponding procedures for STSG (Galley et al., 2004; Graehl et al., 2008) and for STSSG (Sun et al., </context>
</contexts>
<marker>Knight, 2007</marker>
<rawString>Kevin Knight. 2007. Capturing practical natural language transformations. Machine Translation, 21(2):121–133.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Lilin</author>
</authors>
<title>Propri´et´es de clˆoture d’une extension de transducteurs d’arbres d´eterministes.</title>
<date>1981</date>
<booktitle>In Proc. CAAP,</booktitle>
<volume>112</volume>
<pages>280--289</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="2234" citStr="Lilin, 1981" startWordPosition="334" endWordPosition="335">on grammars (STSSG). Chiang (2006) gives a good introduction to STSG, which originate from the syntax-directed translation schemes of Aho and Ullman (1972). Roughly speaking, an STSG has rules in which two linked nonterminals are replaced (at the same time) by two corresponding trees containing terminal and nonterminal symbols. In addition, the nonterminals in the two replacement trees are linked, which creates new linked nonterminals to which further rules can be applied. Henceforth, we refer to these two trees as input and output tree. MBOT have been introduced in (Arnold and Dauchet, 1982; Lilin, 1981) and are slightly more expressive than STSG. Roughly speaking, they allow one replacement input tree and several output trees in a single rule. This change and the presence of states yields many algorithmically advantageous properties such as closure under composition, efficient binarization, and efficient input and output restriction [see (Maletti, 2010)]. Finally, STSSG, which have been derived from rational tree relations (Raoult, 1997), have been discussed by Zhang et al. (2008a), Zhang et al. (2008b), and Sun et al. (2009). They are even more expressive than the local variant of the multi</context>
<context position="7766" citStr="Lilin (1981)" startWordPosition="1416" endWordPosition="1417">on, and F ⊆ Q We extend 6 to a mapping 6: TΣ → 2(Q by 6(Q(t)) = {q |(q, Q, q) ∈ 6, ∀i ∈ [ |t |]: qi ∈ 6(ti)} for every Q ∈ Σ and t ∈ T∗Σ. The finite tree automaton M recognizes the tree language L(M) = {t ∈ TΣ |6(t) ∩ F =6 ∅} . A tree language L ⊆ TΣ is regular if there exists a finite tree automaton M such that L = L(M). 826 NP-OBJ VP VBD signed PP 1 → PV twlY , NP DET-NN AltwqyE PP S VP NP-SBJ 1 VP 2 → 1 PV NP-OBJ NP-SBJ Figure 1: Sample LMBOT rules. 3 The model In this section, we recall particular multi bottomup tree transducers, which have been introduced by Arnold and Dauchet (1982) and Lilin (1981). A detailed (and English) presentation of the general model can be found in Engelfriet et al. (2009) and Maletti (2010). Using the nomenclature of Engelfriet et al. (2009), we recall a variant of linear and nondeleting extended multi bottom-up tree transducers (MBOT) here. Occasionally, we will refer to general MBOT, which differ from the local variant discussed here because they have explicit states. Throughout the article, we assume sets E and A of input and output symbols, respectively. Moreover, let NT ⊆ E ∪ A be the set of designated nonterminal symbols. Finally, we avoid weights in the </context>
</contexts>
<marker>Lilin, 1981</marker>
<rawString>Eric Lilin. 1981. Propri´et´es de clˆoture d’une extension de transducteurs d’arbres d´eterministes. In Proc. CAAP, volume 112 of LNCS, pages 280–289. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Maletti</author>
</authors>
<title>Why synchronous tree substitution grammars?</title>
<date>2010</date>
<booktitle>In Proc. NAACL,</booktitle>
<pages>876--884</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2591" citStr="Maletti, 2010" startWordPosition="388" endWordPosition="389">nals in the two replacement trees are linked, which creates new linked nonterminals to which further rules can be applied. Henceforth, we refer to these two trees as input and output tree. MBOT have been introduced in (Arnold and Dauchet, 1982; Lilin, 1981) and are slightly more expressive than STSG. Roughly speaking, they allow one replacement input tree and several output trees in a single rule. This change and the presence of states yields many algorithmically advantageous properties such as closure under composition, efficient binarization, and efficient input and output restriction [see (Maletti, 2010)]. Finally, STSSG, which have been derived from rational tree relations (Raoult, 1997), have been discussed by Zhang et al. (2008a), Zhang et al. (2008b), and Sun et al. (2009). They are even more expressive than the local variant of the multi bottom-up tree transducer (LMBOT) that we introduce here and can have several input and output trees in a single rule. In this contribution, we restrict MBOT to a form that is particularly relevant in machine translation. We drop the general state behavior of MBOT and replace it by the common locality tests that are also present in STSG, STSSG, and STAG </context>
<context position="7886" citStr="Maletti (2010)" startWordPosition="1436" endWordPosition="1437"> Q ∈ Σ and t ∈ T∗Σ. The finite tree automaton M recognizes the tree language L(M) = {t ∈ TΣ |6(t) ∩ F =6 ∅} . A tree language L ⊆ TΣ is regular if there exists a finite tree automaton M such that L = L(M). 826 NP-OBJ VP VBD signed PP 1 → PV twlY , NP DET-NN AltwqyE PP S VP NP-SBJ 1 VP 2 → 1 PV NP-OBJ NP-SBJ Figure 1: Sample LMBOT rules. 3 The model In this section, we recall particular multi bottomup tree transducers, which have been introduced by Arnold and Dauchet (1982) and Lilin (1981). A detailed (and English) presentation of the general model can be found in Engelfriet et al. (2009) and Maletti (2010). Using the nomenclature of Engelfriet et al. (2009), we recall a variant of linear and nondeleting extended multi bottom-up tree transducers (MBOT) here. Occasionally, we will refer to general MBOT, which differ from the local variant discussed here because they have explicit states. Throughout the article, we assume sets E and A of input and output symbols, respectively. Moreover, let NT ⊆ E ∪ A be the set of designated nonterminal symbols. Finally, we avoid weights in the formal development to keep it simple. It is straightforward to add weights to our model. Essentially, the model works on</context>
<context position="12426" citStr="Maletti (2010)" startWordPosition="2301" endWordPosition="2302"> whose root is labeled by the same nonterminal. In addition, the rank rk(ρ, p) of the replaced nonterminal should match the rank rk((t, u)) of the pre-translation and the nonterminals in the right-hand side that are aligned to p should be replaced by the translation that the alignment requests, provided that the nonterminal matches with the root symbol of the requested translation. The main benefit of the bottomup semantics is that it works exclusively on pretranslations. The process is illustrated in Figure 2. Using the classical bottom-up semantics, we simply obtain the following theorem by Maletti (2010) because the MBOT constructed there is in fact an LMBOT. Theorem 3 For every STSG, an equivalent LMBOT can be constructed in linear time, which in turn yields a particular MBOT in linear time. Finally, we want to relate LMBOT to the STSSG of Sun et al. (2009). To this end, we also introduce the top-down semantics for LMBOT. As expected, both semantics coincide. The top-down semantics is introduced using rule compositions, which will play an important rule later on. Definition 4 The set Rk of k-fold composed rules is inductively defined as follows: • R1 = R and • ` —ϕ s E Rk+1 for all ρ = l —ψ </context>
<context position="18115" citStr="Maletti (2010)" startWordPosition="3373" endWordPosition="3374">(· · · , p2(p1)), where p2(p1) represents the upper right pre-translation of Figure 2. If we name all rules of R, then we can represent each pretranslation of T(R) symbolically by a tree containing rule names. Such trees containing rule names are often called derivation trees. Overall, we obtain the following result, for which details can be found in (Arnold and Dauchet, 1982). Theorem 7 The set D(R) is a regular tree language for every LMBOT R, and the set of derivations is also regular for every MBOT. Figure 6: Sample STSSG rule. Moreover, using the input and output product constructions of Maletti (2010) we obtain that even the set Dt,u(R) of derivations for a specific input tree t and output tree u is regular. Since Dt,u(R) is regular, we can compute the inside and outside weight of each (weighted) rule of R following the method of Graehl et al. (2008). Similarly, we can adjust the training procedure of Graehl et al. (2008), which yields that we can automatically obtain a weighted LMBOT from a bi-parsed parallel corpus. Details on the run-time can be found in (Graehl et al., 2008). 5 Preservation of regularity Clearly, LMBOT are not symmetric. Although, the backwards application of an LMBOT </context>
<context position="24847" citStr="Maletti, 2010" startWordPosition="4546" endWordPosition="4547">e leaf nonterminal at p in the left-hand side are allowed, but all leaf nonterminals of the right-hand side that are aligned to p must be in the same tree. Clearly, an LMBOT with finite synchronization is finitely collapsing. Raoult (1997) investigated this restriction in the context of rational tree relations, which are a generalization of our LMBOT. Raoult (1997) shows that finite synchronization can be decided. The next theorem follows from the results of Raoult (1997). Theorem 12 Every LMBOT with finite synchronization preserves regularity. MBOT can compute arbitrary compositions of STSG (Maletti, 2010). However, this no longer remains true for MBOT (or LMBOT) with finite synchronization.2 In Figure 9 we illustrate a translation that can be computed by a composition of two STSG, but that cannot be computed by an MBOT (or LMBOT) with finite synchronization. Intuitively, when processing the chain of ‘X’s of the transformation depicted in Figure 9, the first and second suc2This assumes a straightforward generalization of the ‘finite synchronization’ property for MBOT. —* Figure 9: Transformation that cannot be computed by an MBOT with finite synchronization. cessor of the ‘Z’-node at the root o</context>
</contexts>
<marker>Maletti, 2010</marker>
<rawString>Andreas Maletti. 2010. Why synchronous tree substitution grammars? In Proc. NAACL, pages 876–884. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan May</author>
<author>Kevin Knight</author>
<author>Heiko Vogler</author>
</authors>
<title>Efficient inference through cascades of weighted tree transducers.</title>
<date>2010</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>1058--1066</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="4483" citStr="May et al., 2010" startWordPosition="688" endWordPosition="691"> improves the translation quality. In this contribution we address this separation and investigate a training procedure for LMBOT that allows non-contiguous fragments while preserving the algorithmic advantages of MBOT. To this end, we introduce a rule extraction and weight training method for LMBOT that is based on the corresponding procedures for STSG and STSSG. However, general LMBOT can be too expressive in the sense that they allow translations that do not preserve regularity. Preservation of regularity is an important property for efficient representations and efficient algorithms [see (May et al., 2010)]. Consequently, we present 3 properties that ensure that an LMBOT preserves regularity. In addition, we shortly discuss how these properties could be enforced in the rule extraction procedure. 2 Notation The set of nonnegative integers is N. We write [k] for the set {i |1 ≤ i ≤ k}. We treat functions as special relations. For every relation R ⊆ A × B and 5 ⊆ A, we write inductively defined by pos(t) = {E}∪pos(t), where pos(t) = U {ip |p ∈ pos(ti)} . 1≤i≤|t| Note that this yields an undesirable difference between pos(t) and pos(t), but it will always be clear from the context whether we refer </context>
<context position="20824" citStr="May et al., 2010" startWordPosition="3848" endWordPosition="3851">c I w E {a, b}*}. Clearly, this word language L is not context-free. Since the leaf language of every regular tree language is context-free and regular tree languages are closed under intersection (needed to single out the translations that have the symbol Y at the root), this also proves that T(R)c(TE) is not regular. Since TE is regular, this proves that the LMBOT does not preserve regularity. Preservation of regularity is an important property for a number of translation model manipulations. For example, the bucket-brigade and the on-the-fly method for the efficient inference described in (May et al., 2010) essentially build on it. Moreover, a regular tree grammar (i.e., a representation of a regular tree language) is an efficient representation. More complex representations such as context-free tree grammars [see, e.g., (Fujiyoshi, 2004)] have worse algorithmic properties (e.g., more complex parsing and problematic intersection). In this section, we investigate three syntactic restrictions on the set R of rules that guarantees that the obtained LMBOT preserves regularity. Then we shortly discuss how to adjust the rule extraction algorithm, so that the extracted rules automatically have these pr</context>
</contexts>
<marker>May, Knight, Vogler, 2010</marker>
<rawString>Jonathan May, Kevin Knight, and Heiko Vogler. 2010. Efficient inference through cascades of weighted tree transducers. In Proc. ACL, pages 1058–1066. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank G Radmacher</author>
</authors>
<title>An automata theoretic approach to rational tree relations.</title>
<date>2008</date>
<booktitle>In Proc. SOFSEM,</booktitle>
<volume>4910</volume>
<pages>424--435</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="16501" citStr="Radmacher, 2008" startWordPosition="3053" endWordPosition="3054">ule ρ = t|p →ψ (up1, ... , upJ to R with the nonterminal alignments ψ // excise rule ρ from (t,u) 4: t ← t[p ← t(p)] u ← u[pi ← u(pi) |i ∈ {1, ... , k}] 6: establish alignments according to position end while The requirement that we can only have one input tree in LMBOT rules indeed might cause the extraction of bigger and less useful rules (when compared to the corresponding STSSG rules) as demonstrated in (Sun et al., 2009). However, the stricter rule shape preserves the good algorithmic properties of LMBOT. The more powerful STSSG rules can cause nonclosure under composition (Raoult, 1997; Radmacher, 2008) and parsing to be less efficient. Figure 4 shows an example of biparsed aligned parallel text. According to the method of Galley et al. (2004) we can extract the (minimal) STSG rule displayed in Figure 5. Using the more liberal format of LMBOT rules, we can decompose the STSG rule of Figure 5 further into the rules displayed in Figure 1. The method of Sun et al. (2009) would also extract the rule displayed in Figure 6. Let us reconsider Figures 1 and 2. Let ρ1 be the top left rule of Figure 2 and ρ2 and ρ3 be the X → X 2 1 a X X X X , X 2 X → a X 1 a X X b , X X → X 2 X a X 1 b b X X , X b X </context>
</contexts>
<marker>Radmacher, 2008</marker>
<rawString>Frank G. Radmacher. 2008. An automata theoretic approach to rational tree relations. In Proc. SOFSEM, volume 4910 of LNCS, pages 424–435. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean-Claude Raoult</author>
</authors>
<title>Rational tree relations.</title>
<date>1997</date>
<journal>Bull. Belg. Math. Soc. Simon Stevin,</journal>
<volume>4</volume>
<issue>1</issue>
<contexts>
<context position="2677" citStr="Raoult, 1997" startWordPosition="401" endWordPosition="402">which further rules can be applied. Henceforth, we refer to these two trees as input and output tree. MBOT have been introduced in (Arnold and Dauchet, 1982; Lilin, 1981) and are slightly more expressive than STSG. Roughly speaking, they allow one replacement input tree and several output trees in a single rule. This change and the presence of states yields many algorithmically advantageous properties such as closure under composition, efficient binarization, and efficient input and output restriction [see (Maletti, 2010)]. Finally, STSSG, which have been derived from rational tree relations (Raoult, 1997), have been discussed by Zhang et al. (2008a), Zhang et al. (2008b), and Sun et al. (2009). They are even more expressive than the local variant of the multi bottom-up tree transducer (LMBOT) that we introduce here and can have several input and output trees in a single rule. In this contribution, we restrict MBOT to a form that is particularly relevant in machine translation. We drop the general state behavior of MBOT and replace it by the common locality tests that are also present in STSG, STSSG, and STAG (Shieber and Schabes, 1990; Shieber, 2007). The obtained device is the local MBOT (LMB</context>
<context position="10217" citStr="Raoult, 1997" startWordPosition="1867" endWordPosition="1868">ammar) of Eisner (2003) and Shieber (2004), but right-hand sides of LMBOT contain a sequence of trees instead of just a single tree as in an STSG. In addition, the alignments in an STSG rule are bijective between leaf nonterminals, whereas our model permits multiple alignments to a single leaf nonterminal in the left-hand side. A model that is even more powerful than LMBOT is the non-contiguous version of STSSG (synchronous tree-sequence substitution grammar) of Zhang et al. (2008a), Zhang et al. (2008b), and Sun et al. (2009), which allows sequences of trees on both sides of rules [see also (Raoult, 1997)]. Figure 1 displays sample rules of an LMBOT using a graphical representation of the trees and the alignment. Next, we define the semantics of an LMBOT R. To avoid difficulties1, we explicitly exclude rules like l →,p r where l ∈ NT or r ∈ NT*; i.e., rules where the left- or right-hand side are only leaf nonterminals. We first define the traditional bottom-up semantics. Let ρ = l →,p r ∈ R be a rule and p ∈ ↓NT(l). The p-rank rk(ρ, p) of ρ is rk(ρ, p) = |{i ∈ N |(p, i) ∈ ψ(↓NT(r))}|. Definition 2 The set τ(R) of pre-translations of an LMBOT R is inductively defined to be the smallest set such</context>
<context position="16483" citStr="Raoult, 1997" startWordPosition="3051" endWordPosition="3052">a) do 2: add rule ρ = t|p →ψ (up1, ... , upJ to R with the nonterminal alignments ψ // excise rule ρ from (t,u) 4: t ← t[p ← t(p)] u ← u[pi ← u(pi) |i ∈ {1, ... , k}] 6: establish alignments according to position end while The requirement that we can only have one input tree in LMBOT rules indeed might cause the extraction of bigger and less useful rules (when compared to the corresponding STSSG rules) as demonstrated in (Sun et al., 2009). However, the stricter rule shape preserves the good algorithmic properties of LMBOT. The more powerful STSSG rules can cause nonclosure under composition (Raoult, 1997; Radmacher, 2008) and parsing to be less efficient. Figure 4 shows an example of biparsed aligned parallel text. According to the method of Galley et al. (2004) we can extract the (minimal) STSG rule displayed in Figure 5. Using the more liberal format of LMBOT rules, we can decompose the STSG rule of Figure 5 further into the rules displayed in Figure 1. The method of Sun et al. (2009) would also extract the rule displayed in Figure 6. Let us reconsider Figures 1 and 2. Let ρ1 be the top left rule of Figure 2 and ρ2 and ρ3 be the X → X 2 1 a X X X X , X 2 X → a X 1 a X X b , X X → X 2 X a X </context>
<context position="21923" citStr="Raoult (1997)" startWordPosition="4029" endWordPosition="4030">ortly discuss how to adjust the rule extraction algorithm, so that the extracted rules automatically have these property. First, we quickly recall the notion of composed rules from Definition 4 because it will play an essential role in all three properties. Figure 3 shows a composition of two rules from Figure 7. Mind that R2 might not contain all rules of R, but it contains all those without leaf nonterminals. Definition 8 An LMBOT R is finitely collapsing if thereisn E Nsuchthato: INT(r) — INT(l)x{1} for every rule l —*,p r E Rn. The following statement follows from a more general result of Raoult (1997), which we will introduce with our second property. Theorem 9 Every finitely collapsing LMBOT preserves regularity. Often the simple condition ‘finitely collapsing’ is fulfilled after rule extraction. In addition, it is automatically fulfilled in an LMBOT that was obtained from an STSG using Theorem 3. It can also be ensured in the rule extraction process by introducing collapsing points for output symbols that can appear recursively in the corpus. For example, we could enforce that all extracted rules for clause-level output symbols (assuming that there is no recursion not involving a clause-</context>
<context position="23961" citStr="Raoult (1997)" startWordPosition="4392" endWordPosition="4393">G with input desynchronization are more expressive than STSG, but they still compute a class of transformations that is not closed under composition. 831 1 X X —* b X , X X X b 2 Y Y —* 1 X X 2 X X —* x X X X —* , X a X a 1 X 2 X X c , c Figure 7: Output subtree synchronization (intra-tree). X Y t3 X X X X a ��—* —* a ... X Y t1 t2 Z t1 t2 t3 Figure 8: Finitely collapsing LMBOT. Theorem 10 For every STSG, we can construct an equivalent finitely collapsing LMBOT in linear time. Moreover, finitely collapsing LMBOT are strictly more expressive than STSG. Next, we investigate a weaker property by Raoult (1997) that still ensures preservation of regularity. Definition 11 An LMBOT R has finite synchronization if there is n E N such that for every rule l —*,p r E Rn and p E INT(l) there exists i E N with 0−1({p} x N) C {iw I w E N*}. In plain terms, multiple alignments to a single leaf nonterminal at p in the left-hand side are allowed, but all leaf nonterminals of the right-hand side that are aligned to p must be in the same tree. Clearly, an LMBOT with finite synchronization is finitely collapsing. Raoult (1997) investigated this restriction in the context of rational tree relations, which are a gen</context>
</contexts>
<marker>Raoult, 1997</marker>
<rawString>Jean-Claude Raoult. 1997. Rational tree relations. Bull. Belg. Math. Soc. Simon Stevin, 4(1):149–176.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart M Shieber</author>
<author>Yves Schabes</author>
</authors>
<title>Synchronous tree-adjoining grammars.</title>
<date>1990</date>
<booktitle>In Proc. CoLing,</booktitle>
<volume>3</volume>
<pages>253--258</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="3217" citStr="Shieber and Schabes, 1990" startWordPosition="496" endWordPosition="499">. Finally, STSSG, which have been derived from rational tree relations (Raoult, 1997), have been discussed by Zhang et al. (2008a), Zhang et al. (2008b), and Sun et al. (2009). They are even more expressive than the local variant of the multi bottom-up tree transducer (LMBOT) that we introduce here and can have several input and output trees in a single rule. In this contribution, we restrict MBOT to a form that is particularly relevant in machine translation. We drop the general state behavior of MBOT and replace it by the common locality tests that are also present in STSG, STSSG, and STAG (Shieber and Schabes, 1990; Shieber, 2007). The obtained device is the local MBOT (LMBOT). Maletti (2010) argued the algorithmical advantages of MBOT over STSG and proposed MBOT as an implementation alternative for STSG. In particular, the training procedure would train STSG; i.e., it would not utilize the additional expressive power 825 Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 825–834, Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics of MBOT. However, Zhang et al. (2008b) and Sun et al. (2009) demonstrate that the additional expr</context>
</contexts>
<marker>Shieber, Schabes, 1990</marker>
<rawString>Stuart M. Shieber and Yves Schabes. 1990. Synchronous tree-adjoining grammars. In Proc. CoLing, volume 3, pages 253–258. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart M Shieber</author>
</authors>
<title>Synchronous grammars as tree transducers.</title>
<date>2004</date>
<booktitle>In Proc. TAG+7,</booktitle>
<pages>88--95</pages>
<publisher>Simon Fraser University.</publisher>
<location>Vancouver, BC, Canada.</location>
<contexts>
<context position="9646" citStr="Shieber (2004)" startWordPosition="1768" endWordPosition="1769">rds, an alignment should request each translation of a particular subtree at most once and if it requests the ith translation, then it should also request all previous translations. Definition 1 A local multi bottom-up tree transducer (LMBOT) is a finite set R of rules such that every rule, written l →,p r, contains a pre-translation hl, ri and an alignment ψ for it. The component l is the left-hand side, r is the right-hand side, and ψ is the alignment of a rule l →,p r ∈ R. The rules of an LMBOT are similar to the rules of an STSG (synchronous tree substitution grammar) of Eisner (2003) and Shieber (2004), but right-hand sides of LMBOT contain a sequence of trees instead of just a single tree as in an STSG. In addition, the alignments in an STSG rule are bijective between leaf nonterminals, whereas our model permits multiple alignments to a single leaf nonterminal in the left-hand side. A model that is even more powerful than LMBOT is the non-contiguous version of STSSG (synchronous tree-sequence substitution grammar) of Zhang et al. (2008a), Zhang et al. (2008b), and Sun et al. (2009), which allows sequences of trees on both sides of rules [see also (Raoult, 1997)]. Figure 1 displays sample r</context>
</contexts>
<marker>Shieber, 2004</marker>
<rawString>Stuart M. Shieber. 2004. Synchronous grammars as tree transducers. In Proc. TAG+7, pages 88–95, Vancouver, BC, Canada. Simon Fraser University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart M Shieber</author>
</authors>
<title>Probabilistic synchronous treeadjoining grammars for machine translation: The argument from bilingual dictionaries.</title>
<date>2007</date>
<booktitle>In Proc. SSST,</booktitle>
<pages>88--95</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="3233" citStr="Shieber, 2007" startWordPosition="500" endWordPosition="501">e been derived from rational tree relations (Raoult, 1997), have been discussed by Zhang et al. (2008a), Zhang et al. (2008b), and Sun et al. (2009). They are even more expressive than the local variant of the multi bottom-up tree transducer (LMBOT) that we introduce here and can have several input and output trees in a single rule. In this contribution, we restrict MBOT to a form that is particularly relevant in machine translation. We drop the general state behavior of MBOT and replace it by the common locality tests that are also present in STSG, STSSG, and STAG (Shieber and Schabes, 1990; Shieber, 2007). The obtained device is the local MBOT (LMBOT). Maletti (2010) argued the algorithmical advantages of MBOT over STSG and proposed MBOT as an implementation alternative for STSG. In particular, the training procedure would train STSG; i.e., it would not utilize the additional expressive power 825 Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 825–834, Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics of MBOT. However, Zhang et al. (2008b) and Sun et al. (2009) demonstrate that the additional expressivity gained </context>
</contexts>
<marker>Shieber, 2007</marker>
<rawString>Stuart M. Shieber. 2007. Probabilistic synchronous treeadjoining grammars for machine translation: The argument from bilingual dictionaries. In Proc. SSST, pages 88–95. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun Sun</author>
<author>Min Zhang</author>
<author>Chew Lim Tan</author>
</authors>
<title>A noncontiguous tree sequence alignment-based model for statistical machine translation.</title>
<date>2009</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>914--922</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2767" citStr="Sun et al. (2009)" startWordPosition="416" endWordPosition="419">nd output tree. MBOT have been introduced in (Arnold and Dauchet, 1982; Lilin, 1981) and are slightly more expressive than STSG. Roughly speaking, they allow one replacement input tree and several output trees in a single rule. This change and the presence of states yields many algorithmically advantageous properties such as closure under composition, efficient binarization, and efficient input and output restriction [see (Maletti, 2010)]. Finally, STSSG, which have been derived from rational tree relations (Raoult, 1997), have been discussed by Zhang et al. (2008a), Zhang et al. (2008b), and Sun et al. (2009). They are even more expressive than the local variant of the multi bottom-up tree transducer (LMBOT) that we introduce here and can have several input and output trees in a single rule. In this contribution, we restrict MBOT to a form that is particularly relevant in machine translation. We drop the general state behavior of MBOT and replace it by the common locality tests that are also present in STSG, STSSG, and STAG (Shieber and Schabes, 1990; Shieber, 2007). The obtained device is the local MBOT (LMBOT). Maletti (2010) argued the algorithmical advantages of MBOT over STSG and proposed MBO</context>
<context position="10136" citStr="Sun et al. (2009)" startWordPosition="1850" endWordPosition="1853">les of an LMBOT are similar to the rules of an STSG (synchronous tree substitution grammar) of Eisner (2003) and Shieber (2004), but right-hand sides of LMBOT contain a sequence of trees instead of just a single tree as in an STSG. In addition, the alignments in an STSG rule are bijective between leaf nonterminals, whereas our model permits multiple alignments to a single leaf nonterminal in the left-hand side. A model that is even more powerful than LMBOT is the non-contiguous version of STSSG (synchronous tree-sequence substitution grammar) of Zhang et al. (2008a), Zhang et al. (2008b), and Sun et al. (2009), which allows sequences of trees on both sides of rules [see also (Raoult, 1997)]. Figure 1 displays sample rules of an LMBOT using a graphical representation of the trees and the alignment. Next, we define the semantics of an LMBOT R. To avoid difficulties1, we explicitly exclude rules like l →,p r where l ∈ NT or r ∈ NT*; i.e., rules where the left- or right-hand side are only leaf nonterminals. We first define the traditional bottom-up semantics. Let ρ = l →,p r ∈ R be a rule and p ∈ ↓NT(l). The p-rank rk(ρ, p) of ρ is rk(ρ, p) = |{i ∈ N |(p, i) ∈ ψ(↓NT(r))}|. Definition 2 The set τ(R) of </context>
<context position="12685" citStr="Sun et al. (2009)" startWordPosition="2347" endWordPosition="2350">ranslation that the alignment requests, provided that the nonterminal matches with the root symbol of the requested translation. The main benefit of the bottomup semantics is that it works exclusively on pretranslations. The process is illustrated in Figure 2. Using the classical bottom-up semantics, we simply obtain the following theorem by Maletti (2010) because the MBOT constructed there is in fact an LMBOT. Theorem 3 For every STSG, an equivalent LMBOT can be constructed in linear time, which in turn yields a particular MBOT in linear time. Finally, we want to relate LMBOT to the STSSG of Sun et al. (2009). To this end, we also introduce the top-down semantics for LMBOT. As expected, both semantics coincide. The top-down semantics is introduced using rule compositions, which will play an important rule later on. Definition 4 The set Rk of k-fold composed rules is inductively defined as follows: • R1 = R and • ` —ϕ s E Rk+1 for all ρ = l —ψ r E R and ρp = lp —ψP rp E Rk such that – rk(ρ, p) = rk((lp, rp)), – l(p) = lp(ε), and – r(p0) = rp00(i) with ψ(p0) = (p00, i) for every p E INT(l) and p0 E INT(r) where – ` = l[p lp I p E INT(l)], – s = r[p0 - (rp00)i I p0 E ψ−1(p00, i)], and – ϕ(p0p) = p00ψ</context>
<context position="14892" citStr="Sun et al., 2009" startWordPosition="2759" endWordPosition="2762">night (2007). Theorem 6 For every LMBOT, an equivalent STSSG can be constructed in linear time. 4 Rule extraction and training In this section, we will show how to automatically obtain an LMBOT from a bi-parsed, word-aligned parallel corpus. Essentially, the process has two steps: rule extraction and training. In the rule extraction step, an (unweighted) LMBOT is extracted from the corpus. The rule weights are then set in the training procedure. The two main inspirations for our rule extraction are the corresponding procedures for STSG (Galley et al., 2004; Graehl et al., 2008) and for STSSG (Sun et al., 2009). STSG are always contiguous in both the left- and right-hand side, which means that they (completely) cover a single span of input or output words. On the contrary, STSSG rules can be noncontiguous on both sides, but the extraction procedure of Sun et al. (2009) only extracts rules that are contiguous on the left- or right-hand side. We can adjust its 1�t phase that extracts rules with (potentially) non-contiguous right-hand sides. The adjustment is necessary because LMBOT rules cannot have (contiguous) tree sequences in their left-hand sides. Overall, the rule extraction process is sketched </context>
<context position="16314" citStr="Sun et al., 2009" startWordPosition="3024" endWordPosition="3027">p1, ... , pk ∈ pos(u) such that t|p and (u|p1, ... , u|pJ have a consistent alignment (i.e., no alignments from within t|p to a leaf outside (u|p1, . . . , u|pJ and vice versa) do 2: add rule ρ = t|p →ψ (up1, ... , upJ to R with the nonterminal alignments ψ // excise rule ρ from (t,u) 4: t ← t[p ← t(p)] u ← u[pi ← u(pi) |i ∈ {1, ... , k}] 6: establish alignments according to position end while The requirement that we can only have one input tree in LMBOT rules indeed might cause the extraction of bigger and less useful rules (when compared to the corresponding STSSG rules) as demonstrated in (Sun et al., 2009). However, the stricter rule shape preserves the good algorithmic properties of LMBOT. The more powerful STSSG rules can cause nonclosure under composition (Raoult, 1997; Radmacher, 2008) and parsing to be less efficient. Figure 4 shows an example of biparsed aligned parallel text. According to the method of Galley et al. (2004) we can extract the (minimal) STSG rule displayed in Figure 5. Using the more liberal format of LMBOT rules, we can decompose the STSG rule of Figure 5 further into the rules displayed in Figure 1. The method of Sun et al. (2009) would also extract the rule displayed in</context>
</contexts>
<marker>Sun, Zhang, Tan, 2009</marker>
<rawString>Jun Sun, Min Zhang, and Chew Lim Tan. 2009. A noncontiguous tree sequence alignment-based model for statistical machine translation. In Proc. ACL, pages 914–922. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Min Zhang</author>
<author>Hongfei Jiang</author>
<author>Aiti Aw</author>
<author>Haizhou Li</author>
<author>Chew Lim Tan</author>
<author>Sheng Li</author>
</authors>
<title>A tree sequence alignment-based tree-to-tree translation model.</title>
<date>2008</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>559--567</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2720" citStr="Zhang et al. (2008" startWordPosition="407" endWordPosition="410">nceforth, we refer to these two trees as input and output tree. MBOT have been introduced in (Arnold and Dauchet, 1982; Lilin, 1981) and are slightly more expressive than STSG. Roughly speaking, they allow one replacement input tree and several output trees in a single rule. This change and the presence of states yields many algorithmically advantageous properties such as closure under composition, efficient binarization, and efficient input and output restriction [see (Maletti, 2010)]. Finally, STSSG, which have been derived from rational tree relations (Raoult, 1997), have been discussed by Zhang et al. (2008a), Zhang et al. (2008b), and Sun et al. (2009). They are even more expressive than the local variant of the multi bottom-up tree transducer (LMBOT) that we introduce here and can have several input and output trees in a single rule. In this contribution, we restrict MBOT to a form that is particularly relevant in machine translation. We drop the general state behavior of MBOT and replace it by the common locality tests that are also present in STSG, STSSG, and STAG (Shieber and Schabes, 1990; Shieber, 2007). The obtained device is the local MBOT (LMBOT). Maletti (2010) argued the algorithmica</context>
<context position="10089" citStr="Zhang et al. (2008" startWordPosition="1841" endWordPosition="1844">ψ is the alignment of a rule l →,p r ∈ R. The rules of an LMBOT are similar to the rules of an STSG (synchronous tree substitution grammar) of Eisner (2003) and Shieber (2004), but right-hand sides of LMBOT contain a sequence of trees instead of just a single tree as in an STSG. In addition, the alignments in an STSG rule are bijective between leaf nonterminals, whereas our model permits multiple alignments to a single leaf nonterminal in the left-hand side. A model that is even more powerful than LMBOT is the non-contiguous version of STSSG (synchronous tree-sequence substitution grammar) of Zhang et al. (2008a), Zhang et al. (2008b), and Sun et al. (2009), which allows sequences of trees on both sides of rules [see also (Raoult, 1997)]. Figure 1 displays sample rules of an LMBOT using a graphical representation of the trees and the alignment. Next, we define the semantics of an LMBOT R. To avoid difficulties1, we explicitly exclude rules like l →,p r where l ∈ NT or r ∈ NT*; i.e., rules where the left- or right-hand side are only leaf nonterminals. We first define the traditional bottom-up semantics. Let ρ = l →,p r ∈ R be a rule and p ∈ ↓NT(l). The p-rank rk(ρ, p) of ρ is rk(ρ, p) = |{i ∈ N |(p, </context>
<context position="13993" citStr="Zhang et al. (2008" startWordPosition="2613" endWordPosition="2616">s R≤∞ = Si≥1 Ri. The top-down pre-translation of R is τt(R) = {(l,r) I l —ψ r E R≤∞, INT(l) = 0} . 828 Figure 3: Composed rule. The composition of the rules, which is illustrated in Figure 3, in the second item of Definition 4 could also be represented as ρ(ρ1,...,ρk) where ρ1, ... , ρk is an enumeration of the rules {ρp |p ∈ ↓NT(l)} used in the item. The following theorem is easy to prove. Theorem 5 The bottom-up and top-down semantics coincide; i.e., τ(R) = τt(R). Chiang (2005) and Graehl et al. (2008) argue that STSG have sufficient expressive power for syntaxbased machine translation, but Zhang et al. (2008a) show that the additional expressive power of treesequences helps the translation process. This is mostly due to the fact that smaller (and less specific) rules can be extracted from bi-parsed word-aligned training data. A detailed overview that focusses on STSG is presented by Knight (2007). Theorem 6 For every LMBOT, an equivalent STSSG can be constructed in linear time. 4 Rule extraction and training In this section, we will show how to automatically obtain an LMBOT from a bi-parsed, word-aligned parallel corpus. Essentially, the process has two steps: rule extraction and training. In the</context>
</contexts>
<marker>Zhang, Jiang, Aw, Li, Tan, Li, 2008</marker>
<rawString>Min Zhang, Hongfei Jiang, Aiti Aw, Haizhou Li, Chew Lim Tan, and Sheng Li. 2008a. A tree sequence alignment-based tree-to-tree translation model. In Proc. ACL, pages 559–567. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Min Zhang</author>
<author>Hongfei Jiang</author>
<author>Haizhou Li</author>
<author>Aiti Aw</author>
<author>Sheng Li</author>
</authors>
<title>Grammar comparison study for translational equivalence modeling and statistical machine translation.</title>
<date>2008</date>
<booktitle>In Proc. CoLing,</booktitle>
<pages>1097--1104</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2720" citStr="Zhang et al. (2008" startWordPosition="407" endWordPosition="410">nceforth, we refer to these two trees as input and output tree. MBOT have been introduced in (Arnold and Dauchet, 1982; Lilin, 1981) and are slightly more expressive than STSG. Roughly speaking, they allow one replacement input tree and several output trees in a single rule. This change and the presence of states yields many algorithmically advantageous properties such as closure under composition, efficient binarization, and efficient input and output restriction [see (Maletti, 2010)]. Finally, STSSG, which have been derived from rational tree relations (Raoult, 1997), have been discussed by Zhang et al. (2008a), Zhang et al. (2008b), and Sun et al. (2009). They are even more expressive than the local variant of the multi bottom-up tree transducer (LMBOT) that we introduce here and can have several input and output trees in a single rule. In this contribution, we restrict MBOT to a form that is particularly relevant in machine translation. We drop the general state behavior of MBOT and replace it by the common locality tests that are also present in STSG, STSSG, and STAG (Shieber and Schabes, 1990; Shieber, 2007). The obtained device is the local MBOT (LMBOT). Maletti (2010) argued the algorithmica</context>
<context position="10089" citStr="Zhang et al. (2008" startWordPosition="1841" endWordPosition="1844">ψ is the alignment of a rule l →,p r ∈ R. The rules of an LMBOT are similar to the rules of an STSG (synchronous tree substitution grammar) of Eisner (2003) and Shieber (2004), but right-hand sides of LMBOT contain a sequence of trees instead of just a single tree as in an STSG. In addition, the alignments in an STSG rule are bijective between leaf nonterminals, whereas our model permits multiple alignments to a single leaf nonterminal in the left-hand side. A model that is even more powerful than LMBOT is the non-contiguous version of STSSG (synchronous tree-sequence substitution grammar) of Zhang et al. (2008a), Zhang et al. (2008b), and Sun et al. (2009), which allows sequences of trees on both sides of rules [see also (Raoult, 1997)]. Figure 1 displays sample rules of an LMBOT using a graphical representation of the trees and the alignment. Next, we define the semantics of an LMBOT R. To avoid difficulties1, we explicitly exclude rules like l →,p r where l ∈ NT or r ∈ NT*; i.e., rules where the left- or right-hand side are only leaf nonterminals. We first define the traditional bottom-up semantics. Let ρ = l →,p r ∈ R be a rule and p ∈ ↓NT(l). The p-rank rk(ρ, p) of ρ is rk(ρ, p) = |{i ∈ N |(p, </context>
<context position="13993" citStr="Zhang et al. (2008" startWordPosition="2613" endWordPosition="2616">s R≤∞ = Si≥1 Ri. The top-down pre-translation of R is τt(R) = {(l,r) I l —ψ r E R≤∞, INT(l) = 0} . 828 Figure 3: Composed rule. The composition of the rules, which is illustrated in Figure 3, in the second item of Definition 4 could also be represented as ρ(ρ1,...,ρk) where ρ1, ... , ρk is an enumeration of the rules {ρp |p ∈ ↓NT(l)} used in the item. The following theorem is easy to prove. Theorem 5 The bottom-up and top-down semantics coincide; i.e., τ(R) = τt(R). Chiang (2005) and Graehl et al. (2008) argue that STSG have sufficient expressive power for syntaxbased machine translation, but Zhang et al. (2008a) show that the additional expressive power of treesequences helps the translation process. This is mostly due to the fact that smaller (and less specific) rules can be extracted from bi-parsed word-aligned training data. A detailed overview that focusses on STSG is presented by Knight (2007). Theorem 6 For every LMBOT, an equivalent STSSG can be constructed in linear time. 4 Rule extraction and training In this section, we will show how to automatically obtain an LMBOT from a bi-parsed, word-aligned parallel corpus. Essentially, the process has two steps: rule extraction and training. In the</context>
</contexts>
<marker>Zhang, Jiang, Li, Aw, Li, 2008</marker>
<rawString>Min Zhang, Hongfei Jiang, Haizhou Li, Aiti Aw, and Sheng Li. 2008b. Grammar comparison study for translational equivalence modeling and statistical machine translation. In Proc. CoLing, pages 1097–1104. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>