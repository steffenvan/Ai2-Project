<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003229">
<title confidence="0.982137">
Natural Language Access to Software Applications
</title>
<author confidence="0.85164">
Paul Schmidt
</author>
<affiliation confidence="0.836439">
University of Mainz, An der Hochschule 2,
</affiliation>
<note confidence="0.672520923076923">
D-76711 Germersheim
schmidtp@usun2.fask.tmi-mainz.de
Marius Groenendijk, Peter Phelan, Henrik Schulz
Anite Systems, 13, rue Robert Stumper
L-2557 Luxembourg
{marius;peter;henrik}@anite-systems.lu
Sibylle Rieder, Axel Theofilidis
IA!, Martin-Luther-Str. 14
D-66111 Saarbrucken
{sibylle;axel}@iai.uni-sb.de
Thierry Deelerek
Deutsches Forschungszentrum fur KI
D-66123 Saarbrticken
</note>
<email confidence="0.923674">
declerck@dfid.uni-sb.de
</email>
<author confidence="0.992911">
Andrew Bredenkamp
</author>
<affiliation confidence="0.99971">
University of Essex, Wivenhoe Park, Colchester, C04 3SQ
</affiliation>
<email confidence="0.993364">
andrewb@essex.ac.uk
</email>
<sectionHeader confidence="0.993633" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.995563833333333">
This paper reports on the ESPRIT project
MELISSA (Methods and Tools for Natural-
Language Interfacing with Standard Software
Applications)&apos;. MELISSA aims at developing
the technology and tools enabling end users to
interface with computer applications, using natu-
ral-language (NL), and to obtain a pre-
competitive product validated in selected end-
user applications. This paper gives an overview
of the approach to solving (NL) interfacing
problem and outlines some of the methods and
software components developed in the project.
</bodyText>
<sectionHeader confidence="0.954249" genericHeader="introduction">
Introduction
</sectionHeader>
<bodyText confidence="0.99886655">
The major goal of MELISSA is to provide the
technology and tools enabling software develop-
ers to provide a Natural Language (NL) interface
for new products, as well as for legacy applica-
tions. The project is based on the conviction that
NL is the most user friendly interface for specific
software applications and for a specific kind of
users. NL is &apos;generic&apos; requiring little or no train-
ing. Integrated with speech recognition and speech
generation the NL interface is optimally conven-
ient and allows for easy access to software systems
by all kinds of (non-expert) users as well as for
users with specific disabilities (e.g. visual, motor).
MELISSA will deliver three main components: a
core of linguistic processing machinery and ge-
neric linguistic resources for Spanish, English and
German; a set of methods and tools for acquiring
and representing the knowledge about the host
application and specific linguistic resources re-
quired for this application; a set of methods and
</bodyText>
<note confidence="0.94676375">
I This project is sponsored by the Commission of the EU under
ESPRIT-22252. Project partners are Software AG, Espana, SEMA,
France/Spain, Anite-Systems, Luxembourg, IA!, Germany, ONCE,
Spain and the City of Cologne.
</note>
<bodyText confidence="0.9982028">
tools for integrating the MELISSA core, the appli-
cation knowledge, and the host application using
the CORBA interoperability standard. The overall
architecture of a MELISSA-based NL interface
consists of the following software modules:
</bodyText>
<listItem confidence="0.999025315789474">
• Speech Recognition Module (SRM), which is
a commercial product, providing a continuous
speech interface for the other NL modules
• Linguistic Processing Module (LPM) consisting
of the linguistic processing machinery and the
linguistic resources
• Semantic Analysis Module (SAM) interpreting
LPM output using application knowledge
• Function Generator Module (FGM) converting
SAM output into executable function calls
• Application Knowledge Repository (AKR) con-
taining all the relevant application specific
knowledge being used by SAM and FGM
• Front-End Module (FEM) responsible for in-
voking requested operations in the application
• Controller Module (CTR) co-ordinating the co-
operation between the previous modules
• End-User Interface (EUI) in which the user types
or dictates his NL queries to target application
</listItem>
<bodyText confidence="0.993629714285714">
The focus of MELISSA is on understanding NL.
In that, MELISSA addresses problems from
knowledge representation and linguistic process-
ing. In the following we concentrate on the design
and the interrelation of the linguistic and knowl-
edge-based modules (SRM, LPM, SAM, AKR).
The MELISSA tools are designed to be generic
such that they support development of NL inter-
faces for a broad range of software applications.
This requires an application independent encoding
of linguistic resources, and an elaborate
modularization scheme supporting flexible con-
figuration of these resources for different software
applications.
</bodyText>
<page confidence="0.978822">
1193
</page>
<bodyText confidence="0.999926">
Furthermore, successful NL interface must meet
with user acceptance requirements regarding re-
sponse time. This poses a major challenge on the
deployment of sophisticated, competence-grammar
based NLP technologies as envisaged in
MELISSA. One aspect of ensuring efficient per-
formance of a NL interface consists in limiting its
capabilities in terms of linguistic coverage. To
avoid false (positive or negative) expectations such
restrictions must be obvious to the user. In addi-
tion, any restriction in terms of linguistic resources
must warrant naturalness of expression.
</bodyText>
<sectionHeader confidence="0.779955" genericHeader="method">
1 The Speech Recognition Module
</sectionHeader>
<bodyText confidence="0.999938611111111">
Speech is the most natural form of communication
for people and is felt to greatly extend the range of
potential applications suitable for an NL interface.
MELISSA currently adopts a &apos;black-box&apos; approach
to speech recognition, viz., speech is just an alter-
native to a keyboard. The results of speech recog-
nition are stored and can be retrieved by sending a
request to the component. The speech component
itself can be controlled by voice commands. Be-
fore using the SRM, speakers have to &apos;train&apos; it in
order to adjust the general voice model to the spe-
cific speaker&apos;s voice characteristics.
The speech interface sends recognized utterances
as strings to other MELISSA components, but is
not able to interact on a higher level with those
components. In a subsequent phase the feedback
and co-operation between the MELISSA core
components and the SRM will be addressed.
</bodyText>
<sectionHeader confidence="0.908162" genericHeader="method">
2 The Linguistic Processing Module
</sectionHeader>
<bodyText confidence="0.999929121212121">
The core of the LPM is based on the Advanced
Language Engineering Platform (ALEP), the EU
Commission&apos;s standard NLP development platform
[Simpkins 94]. ALEP provides the functionality
for efficient NLP: a &apos;lean&apos; linguistic formalism
(with term unification) providing typed feature
structures (TFSs), an efficient head scheme based
parser, rule indexation mechanisms, a number of
devices supporting modularization and configura-
tion of linguistic resources, e.g. an interface format
supporting information flow from SGML-encoded
data structures to TFSs (thus enabling straightfor-
ward integration of &apos;low-level&apos; processing with
deep linguistic analysis), the refinement facility
allowing for separating parsing and &apos;semantic
decoration&apos;, and the specifier mechanism allowing
for multi-dimensional partitioning of linguistic
resources into specialized sub-modules.
For the first time ALEP is used in an industrial
context. In the first place, core components of
ALEP (parser, feature interpreter, linguistic for-
malism) are used as the basis of the MELISSA
LPM. In the second place, ALEP is used as the
development platform for the MELISSA lingware.
The coverage of the linguistic resources for the
first MELISSA prototype was determined by a
thorough user needs analysis. The application dealt
with was an administrative purchase and acquisi-
tion handling system at the Spanish organization of
blind people, ONCE.
The following is an outline of solutions realized in
the LPM for text handling, linguistic analysis and
semantic representation.
</bodyText>
<subsectionHeader confidence="0.992452">
2.1 Text Handling
</subsectionHeader>
<bodyText confidence="0.999948333333334">
The TH modules for MELISSA (treating phenom-
ena like dates, measures, codes (pro-nr. 123/98-al -
T4), abbreviations, but also multiple word units
and fixed phrases come as independent Perl pre-
processors for pattern recognition, resulting in a
drastic improvement of efficiency and a dramatic
expansion of coverage.
Within the general mark up strategy for words a
module has been added which allows the treatment
of specific sequences of words building units.
Once those patterns have been recognized and
concatenated into one single unit, it is easy to con-
vert them to some code required by the applica-
tion. Precisely this latter information is then deliv-
ered to the grammar for further processing. For
one application in MELISSA it is, for example,
required to recognize distinct types of proposals
and to convert them into numeric codes (e.g.
`ordenes de viaje&apos; into the number &apos;2019&apos;)
The TH components allow for an expansion of the
coverage of the NLP components. Experiments
have already been made in integrating simple
POS-tagging components and in passing this in-
formation to the ALEP system [Declerck &amp; Maas
971 Unknown words predictable for their syntactic
behaviour can be identified, marked and repre-
sented by a single default lexical entry in the
ALEP lexicon. In one practical experiment, this
meant the deletion of thousands of lexical entries.
The default mechanism in ALEP works as follows,
during parsing ALEP applies the result of lexical
look-up to each of the terminal nodes; if this fails
then ALEP will look at lexical entries which con-
tain a default specifier to see whether any of them
matches (typically these are underspecifed for
string value, but fully specified for syntactic cate-
gory etc.). Clearly without valency information
such an approach is limited (but nevertheless use-
ful). Future work will focus on the (semi)-
</bodyText>
<page confidence="0.979746">
1194
</page>
<bodyText confidence="0.999729">
automatic identification of this information in the
pre-processing.
The modular design of the TH components (dis-
tinction of application specific TH phenomena and
general ones) allows for a controlled extension to
other languages and other applications.
</bodyText>
<subsectionHeader confidence="0.998873">
2.2 Linguistic Analysis
</subsectionHeader>
<bodyText confidence="0.999980804878049">
Based on experiences from previous projects
[Schmidt et al. 96], mainstream linguistic concepts
such as HPSG are adopted and combined with
strategies from the &apos;lean formalism paradigm&apos;.
For MELISSA, a major issue is to design linguistic
resources which are transparent, flexible and easily
adaptable to specific applications. In order to
minimize configuration and extension costs, ling-
ware for different languages is designed according
to the same strategies, guaranteeing maximal uni-
formity. This is realized in semantics. All language
modules use the same type and feature system.
Macros provide an important means of supporting
modularity and transparency. They are extensively
used for encoding lexical entries as well as struc-
tural rules. Structural macros mostly encode
HPSG-like ID schemes spelled out in category-
specific grammar rules. Structural macros are
largely language-independent, but also lexical
macros will be &apos;standardized&apos; in order to support
transparency and easy maintenance.
The second major issue in linguistic analysis is
efficiency of linguistic processing. Efficiency is
achieved e.g. by exploiting the lingware partition-
ing mechanisms of ALEP. Specifier feature struc-
tures encode which subpart of the lingware a rule
belongs to. Thus for each processing step, only the
appropriate subset of rules is activated.
Efficient processing of NL input is also supported
by separation of the &apos;analysis&apos; stage and one or
several `refmement&apos; stages. During the analysis
stage, a structural representation of the NL input is
built by a cf. grammar, while the refinement
stage(s) enriches the representation with additional
information. Currently, this is implemented as a
two-step approach, where the analysis stage com-
putes purely syntactic information, and the refine-
ment adds semantic information (keeping syntactic
and semantic ambiguities separate). In the future
we will use further refinement steps for adding
application-specific linguistic information.
</bodyText>
<subsectionHeader confidence="0.993762">
2.3 Semantic Representation
</subsectionHeader>
<bodyText confidence="0.999693222222222">
During linguistic analysis, compositional semantic
representations are simultaneously encoded by
recursive embedding of semantic feature structures
as well as by a number of features encoding dis-
tinct types of semantic facts (e.g. predications,
argument relations) in terms of a unique wrapper
data type, so called `sf-terms&apos; (SFs). Links be-
tween semantic facts are established through vari-
able sharings as (2) shows:
</bodyText>
<listItem confidence="0.9222495">
(1) Elaborate new proposal
(2) t_sem:{
</listItem>
<equation confidence="0.997821">
indx =&gt; sf(indx(event,E)),
pred =&gt; sf(pred(elaborate,E,A,B)),
arg2 =&gt; t_sem:(
arg =&gt; sf(arg(theme,E,B)),
pred =&gt; sf(pred(proposal,B)),
mods =&gt; [ t sem:(
mod =&gt; sf(mod(guality,B,M)),
pred =&gt; sf(pred(new,M))) ] 11
</equation>
<bodyText confidence="0.999910466666667">
The flat list of all SFs representing the meaning of
an NL input expression is the input data structure
for the SAM.
Besides predicate argument structure and modifi-
cation, the semantic model includes functional
semantic information (negation, determination,
quantification, tense and aspect) and lexical se-
mantics. The SF-encoding scheme carries over to
these facets of semantic information as well.
Special data types which are recognized and
marked up during TH and which typically corre-
spond to basic data types in the application func-
tionality model, are diacritically encoded by the
special wrapper-type &apos;type&apos;, as illustrated in (4) for
an instance of a code expression:
</bodyText>
<listItem confidence="0.8672035">
(3) proposal of type 2019
(4) t_sem:(
</listItem>
<equation confidence="0.979447">
pred =&gt; sf(pred(proposal,P)),
mods =&gt; t sem{
mod =&gt; sf(mod(concern,P,M)).
pred =&gt; sf(type(proptype(2019),M))1 ])
</equation>
<sectionHeader confidence="0.813658" genericHeader="method">
3 Modelling of Application Knowledge
</sectionHeader>
<bodyText confidence="0.999861">
Two distinct but related models of the host appli-
cation are required within MELISSA. On the one
hand, MELISSA has to understand which (if any)
function the user is trying to execute. On the other
hand, MELISSA needs to know whether such a
functional request can be executed at that instant.
The basic ontological assumption underpinning
each model is that any application comprises a
number of functions, each of which requires zero
or more parameters.
</bodyText>
<subsectionHeader confidence="0.969638">
3.1 The SAM Model
</subsectionHeader>
<bodyText confidence="0.9999805">
The output of the LPM is basically application
independent. The SAM has to interpret the seman-
tic output of the LPM in terms of a specific appli-
cation. Fragments of NL are inherently ambiguous.
Thus, in general, this LPM output will consist of a
number of possible interpretations. The goal of the
SAM is to identify a unique function call for the
specific application. This is achieved by a (do-
</bodyText>
<page confidence="0.982891">
1195
</page>
<bodyText confidence="0.99953225">
main-independent) matching process, which at-
tempts to unify each of the LPM results with one
or more so-called mapping rules. Heuristic criteria,
embodied within the SAM algorithm, enable the
best interpretation to be identified. An example
criterion is the principle of &apos;Maximal Consump-
tion&apos;, by which rules matching a greater proportion
of the SFs in an LPM result are preferred.
Analysis of the multiple, application-independent
semantic interpretations depends on the matching
procedure performed by the SAM, and on the
mapping rules. (5) is a mapping rule:
</bodyText>
<equation confidence="0.989486222222222">
(5) rule(elaborate(3), -- (a)
[elaborate, elaboration, make, create,
creation, introduce], (b)
[arg(agent, elaborate, _ ),
arg(theme, elaborate, proposal),
mod(concern, proposal,
type(proptype(PropType)))1, (c)
[new_proposal_type(
proptype(PropType))]). (d)
</equation>
<bodyText confidence="0.999877315789474">
Each mapping rule consists of an identifier (a), a
list of normalised function-word synonyms (b), a
list of SFs (c), and finally, a simple term repre-
senting the application function to be called, to-
gether with its parameters (d).
The SAM receives a list of SF lists from the LPM.
Each list is considered in turn, and the best inter-
pretation sought for each. All of the individual
&apos;best results&apos; are assessed, and the overall best
result returned. This overall best is passed on to the
FGM, which can either execute, or start a dialogue.
The SFs embody structural semantic information,
but also very important constraint information,
derived from the text-handling. Thus in the exam-
ple rule above, it can clearly be seen that the value
of &apos;PropType&apos; must already have been identified
(i.e. during text handling) as being of the type
&apos;proptype&apos;. In particular cases this allows for dis-
ambiguation.
</bodyText>
<subsectionHeader confidence="0.999619">
3.2 The Application State Model
</subsectionHeader>
<bodyText confidence="0.999764790697674">
It is obvious that NL interfaces have to respond in
a manner as intelligent as possible. Clearly, certain
functions can only be called if the application is in
a certain state (e.g. it is a precondition of the func-
tion call &apos;print_file&apos; that the relevant file exists and
is printable). These &apos;application states&apos; provide a
means for assessing whether or not a function call
is currently permitted.
A standard application can reasonably be described
as a deterministic finite state automaton. A state
can only be changed by the execution of one of the
functions of the application. This allows for mod-
elling an application in a monotonic fashion and
thus calls for a representation in terms of the
predicate calculus. From amongst a number of
alternatives, the New Event Calculus (NEC) was
chosen [Saciri &amp; Kowalski 95] as an appropriately
powerful formalism for supporting this state mod-
elling. NEC allows for the representation of
events, preconditions, postconditions and time
intervals between events. NEC is appropriate for
modelling concurrent, event-driven transitions
between states. However, for single-user applica-
tions, without concurrent functionality, a much
simpler formalism, such as, for example, STRIPS-
like operators, will be perfectly adequate.
In terms of implementation methodology, the work
to be done is to specify the application specific
predicates. The state model of the application
contains as components a set of functions which
comprise the application, a set of preconditions
that must be fulfilled in order to allow the execu-
tion of each function, and a set of consequences
that results from the execution of a function.
Both preconditions and consequences are com-
posed of a subset of the set of propositions which
comprise the current application state. There exists
a set of relations between the components: A
function must fulfil preconditions and produces a
set of consequences. The set of preconditions is-
composed-of facts. The same holds for the set of
consequences and the application state. (6) gives a
summary for a simple text editor. (&apos;F&apos; = some file).
</bodyText>
<listItem confidence="0.966317">
(6) Preconditions:
</listItem>
<bodyText confidence="0.989828730769231">
create(F),[not(exists(F))1).
open(F),[exists(F),not(open(F))]).
close(F),[exists(F),open(F)]).
delete(F),[exists(F)]).
edit(F),[exists(F),open(F)]).
save(F),[exists(F),open(F),modified(F)]).
spell_check(F),[exists(F),open(F)]).
a) Postconditions: Facts to be added
add(create(F),[exists(F)]).
add(open(F),[open(F))).
add(close(F),[]).
add(delete(F),[]).
add(edit(F),[modified(F))).
add(save(F),(saved(F)]).
add(spell_check(F),[modified(F)]).
b) Postconditions: Facts to be deleted
del(create(F),[]).
del(open(F),[]).
del(close(F),[open(F)]).
del(delete(F),[exists(F)]).
del(edit(F),[]).
del(save(F),[modified(F)]).
del(spell_check(F),[]).
A simple planner can be used to generate remedial
suggestion to the user, in cases where the desired
function is currently disabled.
</bodyText>
<sectionHeader confidence="0.999404" genericHeader="method">
4 Adopted Solutions
</sectionHeader>
<subsectionHeader confidence="0.986069">
4.1 Standardisation and Methodologies
</subsectionHeader>
<bodyText confidence="0.9997525">
Throughout the design phase of the project an
object oriented approach has been followed using
</bodyText>
<page confidence="0.976699">
1196
</page>
<bodyText confidence="0.9999646875">
the Unified Modelling Language [Booch et al. 97]
as a suitable notation. It is equally foreseen to
actually propose an extension to this standard no-
tation with linguistic and knowledge related as-
pects. This activity covers part of the &apos;Methodol-
ogy and Standards&apos; aspects of the project.
Other activities related to this aspect are concerned
with &apos;knowledge engineering&apos;, &apos;knowledge mod-
elling&apos;, and &apos;language engineering&apos; (e.g. linguistic
coverage analysis). Methodologies are being de-
veloped that define the steps (and how to carry
them out) from a systematic application analysis (a
kind of reverse-engineering) to the implementation
of a usable (logical and physical) model of the
application. This model can be directly exploited
by the MELISSA software components.
</bodyText>
<subsectionHeader confidence="0.649826">
4.2 Interoperability
</subsectionHeader>
<bodyText confidence="0.999985958333333">
As stated in the introduction, CORBA [Ben-Natan
1995] is used as the interoperability standard in
order for the different components to co-operate.
The component approach, together with CORBA,
allows a very flexible (e.g. distributed) deployment
of the MELISSA system. CORBA allows software
components to invoke methods (functionality) in
remote objects (applications) regardless of the
machine and architecture the called objects reside
on. This is particularly relevant for calling func-
tions in the &apos;hosting&apos; application. The NL input
processing by the MELISSA core components
(themselves communicating through CORBA)
must eventually lead to the invoking of some
function in the targeted application. In many cases
this can be achieved through CORBA
interoperability techniques (e.g. object wrapping).
This approach will enable developers to provide
existing (legacy) applications with an NL interface
without having to re-implement or reverse engi-
neer such applications. New applications, devel-
oped with components and distributed processing
in mind, can integrate MELISSA components with
little development effort.
</bodyText>
<subsectionHeader confidence="0.988271">
4.3 Design and Implementation
</subsectionHeader>
<bodyText confidence="0.999947722222222">
The software design of all components has fol-
lowed the object-oriented paradigm. The SRM for
example is implemented based on a hierarchical
collection of classes. These classes cover for in-
stances software structures focused on speech
recognition and distributed computing using
CORBA. In particular the speech recognition
classes were implemented to be independent of
various speech recognition programming inter-
faces, and are expandable. Vocabularies, diction-
aries and user specific settings are handled by
specific classes to support the main speech appli-
cation class. Commands can easily be mapped to
the desired functionality. Speech recognition re-
sults are stored in conjunction with scores, con-
firmed words and their alternatives. Other
MELISSA components can access these results
through CORBA calls.
</bodyText>
<sectionHeader confidence="0.99972" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.9997683">
MELISSA represents a unique combination of
high quality NLP and state-of-the-art software- and
knowledge-engineering techniques. It potentially
provides a solution to the problem of re-using
legacy applications. The project realizes a system-
atic approach to solving the problems of NL inter-
facing: define a methodology, provide tools and
apply them to build NL interfaces. The production
of the first working prototype has proven the
soundness of the concept.
MELISSA addresses a highly relevant area wrt.
future developments in human-computer interac-
tion, providing users with an intuitive way of ac-
cessing the functionalities of computers.
Future work will focus on refinement of method-
ologies, production of knowledge acquisition tools,
improvement and extension of the SAM function-
ality, robustness and extension of the LPM output.
Contonuous user assessment will guide the devel-
opment.
</bodyText>
<sectionHeader confidence="0.999535" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997968523809524">
[Ben-Natan 1995] Ben-Natan, Ron (1995) CORBA : A
guide to common object request broker architecture.
McGraw-Hill, ISBN 0-07-005427-4
[Booch et al. 97] Booch, G., Rumbaugh, J., Jacobson, I.
(1997) The Unified Modelling Language User Guide.
Addison Wesley, est. publication December 1997.
[Declerck &amp; Maas 97] Declerck, T. and Maas, H.D.
(1997) The Integration of a Part-of-Speech Tagger
into the ALEP Platform. In: Proceedings of the 3rd
ALEP User Group Workshop, Saarbrucken 1997.
[Sadri &amp; Kowalski 95] Sadri, F. and Kowalski, R,
(1995) Variants of the Event Calculus. Technical
Note, Imperial College, London.
[Schmidt et al. 96] Schmidt, P., Theofilidis, A., Rieder,
S., Declerck T. (1996) Lean Formalisms, Linguistic
Theory, and Applications. Grammar Development in
ALEP. In: Proceedings of the 16th COLING, Copen-
hagen 1996.
[Simpkins 94] Simpkins, N.K. (1994) Linguistic Devel-
opment and Processing. ALEP-2 User Guide. CEC,
Luxembourg
</reference>
<page confidence="0.995115">
1197
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.044007">
<title confidence="0.999878">Natural Language Access to Software Applications</title>
<author confidence="0.999987">Paul Schmidt</author>
<affiliation confidence="0.99988">University of Mainz, An der Hochschule 2,</affiliation>
<address confidence="0.996694">D-76711 Germersheim</address>
<email confidence="0.990579">schmidtp@usun2.fask.tmi-mainz.de</email>
<author confidence="0.998453">Marius Groenendijk</author>
<author confidence="0.998453">Peter Phelan</author>
<author confidence="0.998453">Henrik Schulz</author>
<affiliation confidence="0.485399">Anite Systems, 13, rue Robert Stumper</affiliation>
<address confidence="0.72801">L-2557 Luxembourg</address>
<email confidence="0.975208">{marius;peter;henrik}@anite-systems.lu</email>
<author confidence="0.813696">Sibylle Rieder</author>
<author confidence="0.813696">Axel Theofilidis</author>
<affiliation confidence="0.38467">IA!, Martin-Luther-Str. 14</affiliation>
<address confidence="0.54233">D-66111 Saarbrucken</address>
<email confidence="0.947562">{sibylle;axel}@iai.uni-sb.de</email>
<author confidence="0.911409">Thierry Deelerek</author>
<affiliation confidence="0.895372">Deutsches Forschungszentrum fur KI</affiliation>
<address confidence="0.819231">D-66123 Saarbrticken</address>
<email confidence="0.984724">declerck@dfid.uni-sb.de</email>
<author confidence="0.99884">Andrew Bredenkamp</author>
<affiliation confidence="0.970306">University of Essex, Wivenhoe Park, Colchester, C04 3SQ</affiliation>
<email confidence="0.988705">andrewb@essex.ac.uk</email>
<abstract confidence="0.907496923076923">This paper reports on the ESPRIT project MELISSA (Methods and Tools for Natural- Language Interfacing with Standard Software Applications)&apos;. MELISSA aims at developing the technology and tools enabling end users to interface with computer applications, using natural-language (NL), and to obtain a precompetitive product validated in selected enduser applications. This paper gives an overview of the approach to solving (NL) interfacing problem and outlines some of the methods and software components developed in the project.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Ron Ben-Natan</author>
</authors>
<title>CORBA : A guide to common object request broker architecture.</title>
<date>1995</date>
<journal>McGraw-Hill, ISBN</journal>
<pages>0--07</pages>
<marker>[Ben-Natan 1995]</marker>
<rawString>Ben-Natan, Ron (1995) CORBA : A guide to common object request broker architecture. McGraw-Hill, ISBN 0-07-005427-4</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Booch</author>
<author>J Rumbaugh</author>
<author>I Jacobson</author>
</authors>
<title>The Unified Modelling Language User Guide.</title>
<date>1997</date>
<pages>publication</pages>
<publisher>Addison Wesley,</publisher>
<location>est.</location>
<marker>[Booch et al. 97]</marker>
<rawString>Booch, G., Rumbaugh, J., Jacobson, I. (1997) The Unified Modelling Language User Guide. Addison Wesley, est. publication December 1997.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Declerck</author>
<author>H D Maas</author>
</authors>
<title>The Integration of a Part-of-Speech Tagger into the ALEP Platform. In:</title>
<date>1997</date>
<booktitle>Proceedings of the 3rd ALEP User Group Workshop,</booktitle>
<location>Saarbrucken</location>
<marker>[Declerck &amp; Maas 97]</marker>
<rawString>Declerck, T. and Maas, H.D. (1997) The Integration of a Part-of-Speech Tagger into the ALEP Platform. In: Proceedings of the 3rd ALEP User Group Workshop, Saarbrucken 1997.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Sadri</author>
<author>R Kowalski</author>
</authors>
<title>Variants of the Event Calculus. Technical Note,</title>
<date>1995</date>
<location>Imperial College, London.</location>
<marker>[Sadri &amp; Kowalski 95]</marker>
<rawString>Sadri, F. and Kowalski, R, (1995) Variants of the Event Calculus. Technical Note, Imperial College, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Schmidt</author>
<author>A Theofilidis</author>
<author>S Rieder</author>
<author>T Declerck</author>
</authors>
<title>Lean Formalisms, Linguistic Theory, and Applications. Grammar Development in ALEP. In:</title>
<date>1996</date>
<booktitle>Proceedings of the 16th COLING,</booktitle>
<location>Copenhagen</location>
<marker>[Schmidt et al. 96]</marker>
<rawString>Schmidt, P., Theofilidis, A., Rieder, S., Declerck T. (1996) Lean Formalisms, Linguistic Theory, and Applications. Grammar Development in ALEP. In: Proceedings of the 16th COLING, Copenhagen 1996.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N K Simpkins</author>
</authors>
<date>1994</date>
<booktitle>Linguistic Development and Processing. ALEP-2 User Guide. CEC,</booktitle>
<location>Luxembourg</location>
<marker>[Simpkins 94]</marker>
<rawString>Simpkins, N.K. (1994) Linguistic Development and Processing. ALEP-2 User Guide. CEC, Luxembourg</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>