<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000518">
<title confidence="0.995492">
Accurate Learning for Chinese Function Tags from Minimal Features
</title>
<author confidence="0.997712">
Caixia Yuan1,2, Fuji Ren1,2 and Xiaojie Wang2
</author>
<affiliation confidence="0.9778175">
1The University of Tokushima, Tokushima, Japan
2Beijing University of Posts and Telecommunications, Beijing, China
</affiliation>
<email confidence="0.9874615">
{yuancai,ren}@is.tokushima-u.ac.jp
xjwang@bupt.edu.cn
</email>
<sectionHeader confidence="0.997271" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99990872">
Data-driven function tag assignment has
been studied for English using Penn Tree-
bank data. In this paper, we address
the question of whether such method can
be applied to other languages and Tree-
bank resources. In addition to simply
extend previous method from English to
Chinese, we also proposed an effective
way to recognize function tags directly
from lexical information, which is eas-
ily scalable for languages that lack suf-
ficient parsing resources or have inher-
ent linguistic challenges for parsing. We
investigated a supervised sequence learn-
ing method to automatically recognize
function tags, which achieves an F-score
of 0.938 on gold-standard POS (Part-of-
Speech) tagged Chinese text – a statisti-
cally significant improvement over exist-
ing Chinese function label assignment sys-
tems. Results show that a small number
of linguistically motivated lexical features
are sufficient to achieve comparable per-
formance to systems using sophisticated
parse trees.
</bodyText>
<sectionHeader confidence="0.999472" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999261454545455">
Function tags, such as subject, object, time, loca-
tion, etc. are conceptually appealing by encoding
an event in the format of “who did what to whom,
where, when”, which provides useful semantic in-
formation of the sentences. Lexical semantic re-
sources such as Penn Treebank (Marcus et al.,
1994) have been annotated with phrase tree struc-
tures and function tags. Figure 1 shows the parse
tree with function tags for a sample sentence form
the Penn Chinese Treebank 5.01 (Xue et al., 2000)
(file 0043.fid).
</bodyText>
<footnote confidence="0.9776165">
1released by Linguistic Data Consortium (LDC) catalog
NO. LDC2005T01
</footnote>
<figureCaption confidence="0.916025">
Figure 1: Simplified parse tree with function tags
(in black bold) for example sentence.
</figureCaption>
<bodyText confidence="0.999948814814815">
When dealing with the task of function tag
assignment (or function labeling thereafter), one
basic question that must be addressed is what
features can be extracted in practice for distin-
guishing different function tag types. In answer-
ing this question, several pieces of work (Blaheta
and Charniak, 2000; Blaheta, 2004; Merlo and
Musillo, 2005; Gildea and Palmer, 2002) have
already been proposed. (Blaheta and Charniak,
2000; Blaheta, 2004) described a statistical sys-
tem trained on the data of Penn Treebank to au-
tomatically assign function tags for English text.
The system first passed sentences through an au-
tomatic parser, then extracted features from the
parse trees and predicted the most plausible func-
tion label of constituent from these features. Not-
ing that parsing errors are difficult or even impos-
sible to recover at function tag recognition stage,
the alternative approaches are obtained by assign-
ing function tags at the same time as producing
parse trees (Merlo and Musillo, 2005), through
learning deeper syntactic properties such as finer-
grained labels, features from the nodes to the left
of the current node.
Through all that research, however, success-
fully addressing function labeling requires accu-
rate parsing model and training data, and the re-
</bodyText>
<page confidence="0.98483">
54
</page>
<note confidence="0.996994">
Proceedings of the ACL-IJCNLP 2009 Student Research Workshop, pages 54–62,
Suntec, Singapore, 4 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.999965666666667">
sults of them show that the performance ceil-
ing of function labeling is limited by the parsers
they used. Given the imperfection of existing
automatic parsers, which are far from producing
gold-standard results, function tags output by such
models cannot be satisfactory for practical use.
The limitation is even more pertinent for the lan-
guages that do not have sophisticated parsing re-
sources, or languages that have inherent linguistic
challenges for parsing (like Chinese). It is there-
fore worthwhile to investigate alternatives to func-
tion labeling for languages under the parsing bot-
tleneck, both in terms of features used and effec-
tive learning algorithms.
In current study, we focused on the use of
parser-independent features for function labeling.
Specifically, our proposal is to classify function
types directly from lexical features like words and
their POS tags and the surface sentence informa-
tion like the word position. The hypothesis that
underlies our proposal is that lexical features are
informative for different function types, and cap-
ture fundamental properties of the semantics that
sometimes can not be concluded from the glance
of parse structure. Such cases come when distin-
guishing phrases of the same structure that differ
by just one word – for instance, telling “ M
(in Shanghai)”, which is locative, from “ t�
(in May)”, which is temporal.
At a high level, we can say that class-based dif-
ferences in function labels are reflected in statistics
over the lexical features in large-scale annotated
corpus, and that such knowledge can be encoded
by learning algorithms. By exploiting lexical in-
formation collected from Penn Chinese Treebank
(CTB) (Xue et al., 2000), we investigate a super-
vised sequence learning model to test our core hy-
pothesis – that function tags could be guessed pre-
cisely through informative lexical features and ef-
fective learning methods. At the end of this pa-
per, we extend previous function labeling meth-
ods from English to Chinese. The result proves, at
least for Chinese language, our proposed method
outperforms previous ones that utilize sophisti-
cated parse trees.
In section 2 we will introduce the CTB re-
sources and function tags used in our study. In
section 3, we will describe the sequence learn-
ing algorithm in the framework of maximum mar-
gin learning, showing how to approximate func-
tion tagging by simple lexical statistics. Section 4
</bodyText>
<tableCaption confidence="0.897185666666667">
Table 1: Complete set of function labels in Chi-
nese Treebank and function labels used in our sys-
tem (selected labels).
</tableCaption>
<table confidence="0.997449357142857">
type labels in CTB selected labels
clause types IMP imperative
Q question
(function/form) ADV adverbial √
discrepancies
grammatical roles EXT extent √
FOC focus √
IO indirect object √
OBJ direct object √
PRD predicate √
SBJ subject √
TPC topic √
adverbials BNF beneficiary √
CND condition √
DIR direction √
IJ interjective √
LGS logic subject √
LOC locative √
MNR manner √
PRP purpose/reason √
TMP temporal √
VOC vocative √
miscellaneous APP appositive
HLN headline
PN proper names
SHORT short form
TTL title
WH wh-phrase
</table>
<bodyText confidence="0.967792666666667">
gives a detailed discussion of our experiment and
comparison with pieces of related work. Some fi-
nal remarks will be given in Section 5.
</bodyText>
<sectionHeader confidence="0.971769" genericHeader="method">
2 Chinese Function Tags
</sectionHeader>
<bodyText confidence="0.977572136363636">
The label such as subject, object, time, location,
etc. are named as function tags2 in Penn Chi-
nese Treebank (Xue et al., 2000), a complete list
of which is shown in Table 1. Among the 5 cat-
egories, grammatical roles such as SBJ, OBJ are
useful in recovering predicate-argument structure,
while adverbials are actually semantically oriented
labels (though not true for all cases, see (Merlo
and Palmer, 2006)) that carry semantic role infor-
mation.
As for the task of function parsing, it is reason-
able to ignore the IMP and Q in Table 1 since they
do not form natural syntactic or semantic classes.
In addition, we regard the miscellaneous labels as
an “O” label (out of any function chunks) like la-
beling constituents that do not bear any function
2The annotation guidelines of Penn Chinese Treebank talk
of function tags. We will use the term function labels and
function tags identically, and hence make no distinction be-
tween function labeling and function tagging throughout this
paper. Also, the term function chunk signifies a sequence of
words that are decorated with the same function label.
</bodyText>
<page confidence="0.997639">
55
</page>
<bodyText confidence="0.999787680851064">
tags. Punctuation marks like comma, semi-colon
and period that separate sentences are also denoted
as “O”. But the punctuation that appear within one
sentence like double quotes are denoted with the
same function labels with the content they quote.
In the annotation guidelines of CTB (Xue et al.,
2000), the function tag “PRD” is assigned to non-
verbal predicate. Since VP (verb phrase) is always
predicate, “PRD” is assumed and no function tag
is attached to it. We make a slight modification to
such standard by calling this kind of VP “verbal
predicates”, and assigning them with function la-
bel “TAR (target verb)”, which is grouped into the
same grammar roles type with “PRD”.
To a large extent, PP (preposition phrase) al-
ways plays a functional role in sentence, like “PP-
MNR” in Figure 1. But there are many such PPs
bare of any function type in CTB resources. Like
in the sentence “�t-t`&apos;-fillM*ik 25% (increase
by 25% over the same period of last year)”, “�L-t
�fillM (over the same period of last year)” is la-
beled as “PP” in CTB without any function labels
attached, thus losing to describe the relationship
with the predicate “W[k (increases)”. In order to
capture various relationships related to the predi-
cate, we assign function label “ADT (adjunct)” for
this scenario, and merge it with other adverbials
to form adverbials category. There are 1,415 such
cases in CTB resources, which account for a large
proportion of adverbials types.
After the modifications discussed above, in our
final system we use 20 function labels3 (18 origi-
nal CTB labels shown in Table 2 and two newly
added labels) that are grouped into two types:
grammatical roles and adverbials.
We calculate the frequency (the number of times
each tag occurs) and average length (the average
number of words each tag covers) of each func-
tion category in our selected sentences, which are
listed in Table 2. As can be seen, the frequency of
adverbials is much smaller than that of grammati-
cal roles. Furthermore, the average length of most
adverbials are somewhat larger than 4. Such data
distribution is likely to be one cause of the lower
identification accuracy of adverbials as we will see
in the experiments.
From the layer of function labeling, sentences
</bodyText>
<footnote confidence="0.5704758">
3ADV includes ADV and ADVP in CTB recourses,
grouped into adverbials. In function labeling level, EXT that
signifies degree, amount of the predicates should be grouped
into adverbials like in the work of (Blaheta and Charniak,
2000) and (Merlo and Musillo, 2005).
</footnote>
<tableCaption confidence="0.944505">
Table 2: Categories of function tags with their rel-
ative frequencies and average length.
</tableCaption>
<table confidence="0.999539636363636">
Function Labels Frequency Average Length
grammatical roles 99507 2.62
FOC 133 1.89
IO 126 1.26
OBJ 25834 4.15
PRD 4428 5.20
SBJ 23809 3.02
TPC 676 3.51
TAR 44501 1.25
adverbials 33287 2.11
ADT 1415 4.51
ADV 21891 1.32
BNF 465 4.66
CND 68 3.15
DIR 1558 4.68
EXT 1048 1.99
IJ 1 1.00
LGS 204 5.42
LOC 2051 4.27
MNR 1053 4.48
PRP 224 4.91
TMP 3309 2.25
</table>
<bodyText confidence="0.9992356">
in CTB are described with the structure of “SV”
which indicates a sentence is basically composed
of “subject + verb”. But in order to identify objects
and complements of predicates, we express sen-
tence by “SVO” framework in our system, which
regards sentence as a structure of “subject + verb +
object”. The structure transformation is obtained
through a preprocessing procedure, by upgrading
OBJs and complements (EXT, DIR, etc.) which
are under VP in layered brackets.
</bodyText>
<sectionHeader confidence="0.946928" genericHeader="method">
3 Learning Function Labels
</sectionHeader>
<bodyText confidence="0.999894555555556">
Function labeling deals with the problem of pre-
dicting a sequence of function tags y = y1, ..., yT,
from a given sequence of input words x =
x1, ..., xT, where yi E E. Therefore the function
labeling task can be formulated as a stream of se-
quence learning problem. The general approach
is to learn a w-parameterized mapping function
F : X×Y → R based on training sample of input-
output pairs and to maximize F(x, y; w) over the
response variable to make a prediction.
There has been several algorithms for label-
ing sequence data including hidden Markov model
(Rabiner, 1989), maximum entropy Markov model
(Mccallum et al., 2000), conditional random fields
(Lafferty et al., 2001) and hidden Markov support
vector machine (HM-SVM) (Altun et al., 2003;
Tsochantaridis et al., 2004), among which HM-
SVM shows notable advantages by its learning
</bodyText>
<page confidence="0.980617">
56
</page>
<bodyText confidence="0.9999608">
non-linear discriminant functions via kernel func-
tion, the properties inherited from support vec-
tor machines (SVMs). Furthermore, HM-SVM
retains some of the key advantages of Markov
model, namely the Markov chain dependency
structure between labels and an efficient dynamic
programming formulation.
In this paper we investigate the application of
the HM-SVM model to Chinese function labeling
task. In order to keep the completeness of paper,
we here address briefly the HM-SVM algorithm,
more details of which could be founded in (Altun
et al., 2003; Tsochantaridis et al., 2004), then we
will concentrate on the techniques of applying it to
our specific task.
</bodyText>
<subsectionHeader confidence="0.993813">
3.1 Learning Model
</subsectionHeader>
<bodyText confidence="0.9895475">
The framework from which HM-SVM are derived
is a maximum margin formulation for joint fea-
ture functions in kernel learning setting. Given n
labeled examples (x1, y1), ..., (xn, yn), the notion
of a separation margin proposed in standard SVMs
is generalized by defining the margin of a train-
ing example with respect to a discriminant func-
tion F(x, y; w), as:
</bodyText>
<equation confidence="0.7849065">
γi = F(xi, yi; w) − max F(xi, y; w). (1)
y/∈yi
</equation>
<bodyText confidence="0.9446845">
Then the maximum margin problem can be de-
fined as finding a weight vector w that maxi-
mizes miniγi. By fixing the functional margin
(maxiγi ≥ 1) like in the standard setting of SVMs
with binary labels, we get the following hard-
margin optimization problem with a quadratic ob-
jective:
2||w||2,
</bodyText>
<equation confidence="0.997186">
1 (2)
with constraints,
F(xi, yi; w) − F(xi, y; w) ≥ 1,∀ni=1, ∀y7yi.
</equation>
<bodyText confidence="0.999322166666667">
In the particular setting of SVM, F is as-
sumed to be linear in some combined feature
representation of inputs and outputs Φ(x, y), i.e.
F(x, y; w) = hw, Φ(x, y)i. Φ(x, y) can be
specified by extracting features from an obser-
vation/label sequence pair (x, y). Inspired by
HMMs, we propose to define two types of fea-
tures, interactions between neighboring labels
along the chain as well as interactions between at-
tributes of the observation vectors and a specific
label. For instance, in our function labeling task,
we might think of a label-label feature of the form
</bodyText>
<equation confidence="0.961046">
α(yt−1, yt) = [[yt−1 = SBJ ∧ yt = TAR]], (3)
</equation>
<bodyText confidence="0.8362185">
that equals 1 if a SBJ is followed by a TAR. Anal-
ogously, a label-observation feature may be
</bodyText>
<equation confidence="0.949854">
β(xt, yt) = [[yt = SBJ ∧ xt is a noun]], (4)
</equation>
<bodyText confidence="0.996730333333333">
which equals 1 if x at position t is a noun and la-
beled as SBJ. The described feature map exhibits
a first-order Markov property and as a result, de-
coding can be performed by a Viterbi algorithm in
O(T|Σ|2).
All the features extracted at location t are sim-
ply stacked together to form Φ(x, y; t). Finally,
this feature map is extended to sequences (x, y) of
length T in an additive manner as
</bodyText>
<equation confidence="0.993559">
T
Φ(x, y) = E Φ(x, y; t). (5)
t=1
</equation>
<subsectionHeader confidence="0.909869">
3.2 Features
</subsectionHeader>
<bodyText confidence="0.999641222222222">
It deserves to note that features in HM-SVM
model can be easily changeable regardless of de-
pendency among them. In this prospect, features
are very far from independent can be cooperated
in the model.
By observing the particular property of function
structure in Chinese sentences, we design several
sets of label-observation features which are inde-
pendent of parse trees, namely:
Words and POS tags: The lexical context is ex-
tremely important in function labeling, as indi-
cated by their importance in related task of phrase
chunking. Due to long-distance dependency of
function structure, intuitively, more wider con-
text window will bring more accurate prediction.
However, the wider context window is more likely
to bring sparseness problem of features and in-
crease computation cost. So there should be a
proper compromise among them. In our experi-
ment, we start from a context of [-2, +2] and then
expand it to [-4, 4], that is, four words (and POS
tags) around the word in question, which is closest
to the average length of most function types shown
in Table 2.
Bi-gram of POS tags: Apart from POS tags them-
selves, we also try on the bi-gram of POS tags. We
regard POS tag sequence as an analog to function
</bodyText>
<equation confidence="0.694212">
min
w
</equation>
<page confidence="0.974391">
57
</page>
<bodyText confidence="0.999816948717949">
chains, which reveals somewhat the dependent re-
lations among words.
Verbs: Function labels like subject and object
specify the relations between verb and its argu-
ments. As observed in English verbs (Levin,
1993), each class of verb is associated with a set
of syntactic frames. Similar criteria can also be
found in Chinese. In this sense, we can rely on
the surface verb for distinguishing argument roles
syntactically. Besides the verbs themselves, we
also take into account the special words sharing
common property with verbs in Chinese language,
which are active voice “4U(BA)” and passive voice
“*(BEI)”. The verb we refer here is supposed to
be the last verb if it happens in a consecutive verb
sequence, thus actually not the head verb of sen-
tence.
POS tags of verbs: according to CTB annota-
tion guideline, verbs are labeled with four kinds
of POS tags (VA, VC, VE, VV), along with BA
(for “4U”), LB and SB (for “R”). This feature
somewhat notifies the coarse class of verbs talked
in (Levin, 1993) and is taken into account as fea-
ture candidates.
Position indicators: It is interesting to notice that
whether the constituent to be labeled occurs before
or after the verb is highly correlated with gram-
matical function, since subjects will generally ap-
pear before a verb, and objects after, at least for
Chinese language. This feature may overcome the
lack of syntactic structure that could be read from
the parse tree.
In our experiment, all feature candidates are in-
troduced to the training instances incrementally by
a feature inducing procedure, then we use a gain-
driven method to decide whether a feature should
be reserved or deleted according to the increase or
decrease of the predication accuracy. The proce-
dure are described in Figure 2.
</bodyText>
<figureCaption confidence="0.900817">
Figure 2: Pseudo-code of feature introducing pro-
cedure.
</figureCaption>
<bodyText confidence="0.498674">
1: initialize feature superset C={all feature candidates},
feature set c is empty
</bodyText>
<listItem confidence="0.903831111111111">
2: repeat
3: for each feature ci E C do
4: construct training instances using ci U c
experiment on k-fold cross-validation data
5: if accuracy increases then
ci → c
6: end if
7: end for
8: until all features in C are traversed
</listItem>
<sectionHeader confidence="0.978037" genericHeader="evaluation">
4 Experiment and Discussion
</sectionHeader>
<bodyText confidence="0.99997145">
In this section, we turn to our computational ex-
periments that investigate whether the statistical
indicators of lexical properties that we have devel-
oped can in fact be used to classify function labels,
and demonstrate which kind of feature contributes
most in identifying function types, at least for Chi-
nese text.
As in the work of (Ramshaw and Marcus,
1995), each word or punctuation mark within a
sentence is labeled with “IOB” tag together with
its function type. The three tags are sufficient for
encoding all constituents since there are no over-
laps among different function chunks. The func-
tion tags in this paper are limited to 20 types, re-
sulting in a total of |Σ |= 41 different outputs.
We use three measures to evaluate the model
performance: precision, which is the percentage
of detected chunks that are correct; recall, which
is the percentage of chunks in the data that are
found by the tagger; and F-score which is equal to
2xprecisionxrecall/(precision+recall). Un-
der the “IOB” tagging scheme, a function chunk
is only counted as correct when its boundaries and
its type are both identified correctly. Furthermore,
sentence accuracy is used in order to observe the
prediction correctness of sentences, which is de-
fined as the percentage of sentences within which
all the constituents are assigned with correct tags.
As in the work of (Blaheta and Charniak, 2000)
and (Merlo and Musillo, 2005), to avoid calcu-
lating excessively optimistic values, constituents
bearing the “O” label are not counted in for com-
puting overall precision, recall and F-score.
We derived 18,782 sentences from CTB 5.0
with about 497 thousands of words (including
punctuation marks). On average, each sentence
contains 26.5 words with 2.4 verbs. We followed
5-fold cross-validation method in our experiment.
The numbers reported are the averages of the re-
sults across the five test sets.
</bodyText>
<subsectionHeader confidence="0.972806">
4.1 Evaluation of Different Features and
Models
</subsectionHeader>
<bodyText confidence="0.999978714285714">
In pilot experiments on a subset of the features,
we provide a comparison of HM-SVM with other
two learning models, maximum entropy (Max-
Ent) model (Berger et al., 1996) and SVM model
(Kudo, 2001), to test the effectiveness of HM-
SVM on function labeling task, as well as the
generality of our hypothesis on different learning
</bodyText>
<page confidence="0.999534">
58
</page>
<tableCaption confidence="0.997331">
Table 3: Features used in each experiment round.
</tableCaption>
<table confidence="0.891257142857143">
FT1 word &amp; POS tags within [-2,+2]
FT2 word &amp; POS tags within [-3,+3]
FT3 word &amp; POS tags within [-4,+4]
FT4 FT3 plus POS bigrams within [-4, +4]
FT5 FT4 plus verbs
FT6 FT5 plus POS tags of verbs
FT7 FT6 plus position indicators
</table>
<bodyText confidence="0.951301541666667">
models.
In our experiment, SVMs and HM-SVM train-
ing are carried out with SVMstruct packages4. The
multi-class SVMs model is realized by extend-
ing binary SVMs using pairwise strategy. We
used a first-order of transition and emission depen-
dency in HM-SVM. Both SVMs and HM-SVM
are trained with the linear kernel function and the
soft margin parameter c is set to be 1. The MaxEnt
model is implemented based on Zhang’s MaxEnt
toolkit5 and L-BFGS (Nocedal, 1999) method to
perform parameter estimation.
Figure 3: Sentence accuracy achieved by different
models using different feature combinations.
We use sentence accuracy to compare perfor-
mances of three models with different feature
combinations shown in Table 3. The learning
curves in Figure 3 illustrate feature combination
FT7 gains the best results for all three models
we considered. As we have expected, the perfor-
mance improves as the context window expanded
from 2 to 4 (from FT1 to FT3 in Figure 3). The
sentence accuracy increases significantly when the
features include verbs and position indicators, giv-
</bodyText>
<footnote confidence="0.989435333333333">
4http://svmlight.joachims.org/s vm multiclass.html
5http://homepages.inf.ed.ac.uk/s0450736/maxent toolkit.
html
</footnote>
<bodyText confidence="0.999518142857143">
ing some indication of the complexity of the struc-
ture intervening between focus word and the verb.
However, at a high level, we can simply say that
any further information would help for identifying
function types, so we believe that the features we
deliberated on currently are by no means the solely
optimal feature set.
As observed in Figure 3, the structural sequence
model HM-SVM outperforms multi-class SVMs,
meanwhile, they both perform slightly better than
MaxEnt model, demonstrating the benefit of max-
imum margin based approach. In the experiment
below, we will use feature FT7 and HM-SVM
model to illustrate our method.
</bodyText>
<subsectionHeader confidence="0.870302">
4.2 Results with Gold-standard POS Tags
</subsectionHeader>
<bodyText confidence="0.999445142857143">
By using gold-standard POS tags, this experiment
is to view the performance of two types of func-
tion labels - grammatical roles and adverbials, and
fine-grained function types belonging to them. We
cite the average precision, recall and F-score of
5-fold cross validation data output by HM-SVM
model to discuss this facet.
</bodyText>
<tableCaption confidence="0.897140333333333">
Table 4: Average performance for individual cat-
egories, using HM-SVM model with feature FT7
and gold-standard POS tags.
</tableCaption>
<table confidence="0.999939">
Precision Recall F-score
Overall 0.934 0.942 0.938
grammatical roles 0.949 0.960 0.955
FOC 0.385 0.185 0.250
IO 0.857 0.286 0.429
OBJ 0.960 0.980 0.970
PRD 0.985 0.988 0.987
SBJ 0.869 0.912 0.890
TPC 0.292 0.051 0.087
TAR 0.986 0.990 0.990
adverbials 0.887 0.887 0.887
ADT 0.690 0.663 0.676
ADV 0.956 0.955 0.956
BNF 0.729 0.869 0.793
CND 0.000 0.000 0.000
DIR 0.741 0.812 0.775
EXT 0.899 0.820 0.857
LGS 0.563 0.659 0.607
LOC 0.712 0.721 0.716
MNR 0.736 0.783 0.759
PRP 0.656 0.404 0.500
TMP 0.821 0.808 0.814
</table>
<tableCaption confidence="0.766421666666667">
Table 4 details the results of individual function
types. On the whole, grammatical roles outper-
form adverbials. It seems to reflect the fact that
</tableCaption>
<page confidence="0.998612">
59
</page>
<bodyText confidence="0.999793738095238">
syntactic constituents can often be guessed based
on POS tags and high-frequency lexical words,
largely avoiding sparse-data problems. This is ev-
ident particularly for “OBJ” that reaches aggres-
sively 0.970 in F-score. One exception is “TPC”,
whose precision and recall draws to the lowest
among grammatical roles. In CTB resources,
“TPC” marks elements that appear before the sub-
ject in a declarative sentence, and, it always consti-
tutes a noun phrase together with the subject of the
sentence. As an illustrating example, in the sen-
tence “X 4a (The industrial
structure of Tianjin and Taiwan is similar)”, “X
�aM (Tianjin and Taiwan)” is labeled with
“TPC”, while “Y&apos;_N &apos;MPYJ (The industrial struc-
ture)” with “SBJ”. In such settings, it is difficult to
distinguish between them even for human beings.
Overall, there are three possible explanations
for the lower F-score of adverbials. One is that
tags characterized by much more semantic infor-
mation always have flexible syntactic construc-
tions and diverse positions in sentence, which
makes it difficult to capture their uniform char-
acteristics. Second one is likely that the long-
distance dependency and sparseness problem de-
grade the performance of adverbials greatly. This
can be viewed from the statistics in Table 2, where
most of the adverbials are longer than 4, while the
frequency of them is significantly lower than that
of grammatical roles. The third possible explana-
tion is that there is vagueness among different ad-
verbials. An instance to state such case is the dis-
pute between “ADV” and “MNR” like the phrase
“M46C*_f )WMXA (with the deepening of re-
form and opening-up)”, which are assigned with
“ADV” and “MNR” in two totally the same con-
texts in our training data. Noting that word se-
quences for some semantic labels carry several
limited formations (e.g., most of “DIR” is prepo-
sition phrase beginning with “from, to”), we will
try some linguistically informed heuristics to de-
tect such patterns in future work.
</bodyText>
<subsectionHeader confidence="0.98825">
4.3 Results with Automatically Assigned POS
Tags
</subsectionHeader>
<bodyText confidence="0.983183875">
Parallel to experiments on text with gold-standard
POS tags, we also present results on automatically
POS-tagged text to quantify the effect of POS ac-
curacy on the system performance. We adopt auto-
matic POS tagger of (Qin et al., 2008), which got
the first place in the forth SIGHAN Chinese POS
tagging bakeoff on CTB open test, to assign POS
tags for our data. Following the approach of (Qin
et al., 2008), we train the automatic POS tagger
which gets an average accuracy of 96.18% in our
5-fold cross-validation data. Function tagger takes
raw text as input, then completes POS tagging and
function labeling in a cascaded way. As shown in
Table 5, the F-score of AutoPOS is slightly lower
than that of GoldPOS. However, the small gap is
still within our first expectation.
</bodyText>
<tableCaption confidence="0.9772658">
Table 5: Performance separated for grammatical
roles and adverbials, of our models GoldPOS (us-
ing gold-standard POS tags), GoldPARSE (using
gold-standard parse trees), AutoPOS (using auto-
matically labeled POS tags).
</tableCaption>
<table confidence="0.9727344">
grammatical roles adverbials
P R F P R F
GoldPOS 0.949 0.960 0.955 0.887 0.887 0.887
AutoPOS 0.921 0.948 0.934 0.872 0.867 0.869
GoldPARSE 0.936 0.967 0.951 0.911 0.884 0.897
</table>
<subsectionHeader confidence="0.974552">
4.4 Results with Gold-standard Parser
</subsectionHeader>
<bodyText confidence="0.999848214285714">
A thoroughly different way for function labeling
is deriving function labels together with parsing.
The work of (Blaheta and Charniak, 2000; Bla-
heta, 2004; Merlo and Musillo, 2005) has ap-
proved its effectiveness in English text. Among
them, the work of Merlo and Musillo (Merlo and
Musillo, 2005) achieved a state-of-the-art F1 score
for English function labeling (0.964 for grammat-
ical roles and 0.863 for adverbials). In order to ad-
dress the question of whether such method can be
successfully applied to Chinese text and whether
the simple method we proposed is better than or
at least equivalent to it, we used features collected
from hand-crafted parse trees in CTB resources,
and did a separate experiment on the same text.
The features we used are borrowed from feature
trees described in (Blaheta and Charniak, 2000).
A trivial difference is that in our system the head
for prepositional phrases is defined as the preposi-
tions themselves (not the head of object of preposi-
tional phrases (Blaheta and Charniak, 2000)), be-
cause we think that the preposition itself is a more
distinctive attribute for different semantic mean-
ings.
Results in Table 5 show that the parser tree
doesn’t help a lot in Chinese function labeling.
One reason for this may be sparseness problem of
parse tree features – For instance, in one of the 5-
</bodyText>
<page confidence="0.994657">
60
</page>
<bodyText confidence="0.999993228571429">
fold data, 34% of syntactic paths in test instances
are unseen in training data. For sentences with
the average length of more than 40 words, this
sparseness becomes even severe. Another possi-
ble reason is that some functional chunks are more
local and less prone to structured parse trees, as
observed in examples listed at the beginning of
the paper. In Table 5, although the performance
of adverbials grows really huge when using fea-
tures from the gold-standard parse trees, the per-
formance of grammatical roles drops as introduc-
ing such features. As mentioned above, in fact
even the simple position feature can give a better
explanation to word’s grammatical role than com-
plicated syntactic path.
Although the experimental setup is strictly not
the same for the present paper and (Blaheta
and Charniak, 2000; Blaheta, 2004; Merlo and
Musillo, 2005), we observe that the proposed
method yields better results with deliberately de-
signed but simple features at lexical level, while
attempts in (Blaheta and Charniak, 2000; Blaheta,
2004; Merlo and Musillo, 2005) optimized func-
tion labeling together with parsing, which is a
more complex task and difficult to realize for lan-
guages that lack sufficient parse resources.
The work of (Blaheta and Charniak, 2000; Bla-
heta, 2004; Merlo and Musillo, 2005) reveal that
the performance of parser used sets upper bound
on the performance of function labeling. However,
the best Chinese parser ever reported (Wang et al.,
2006) achieves 0.882 F-score for sentences with
less than 40 words, we therefore conclude that the
way using auto-parser for Chinese function label-
ing is not the optimal choice.
</bodyText>
<subsectionHeader confidence="0.815391">
4.5 Error Analysis
</subsectionHeader>
<bodyText confidence="0.998822823529412">
In the course of our experiment, we wanted to at-
tain some understanding of what sort of errors the
system was making. While still working on the
gold-standard POS-tagged text, we randomly took
one output from the 5-fold cross-validation tests
and examined each error. But when observing the
1,550 wrongly labeled function chunks (26,593 in
total), we can distinguish three types of errors.
The first and widest category of errors are
caused when the lexical construction of the chunk
is similar to other chunk types. A typical example
is “PRP (purpose)” and “BNF (beneficiary)”, both
of which are mostly prepositional phrases begin-
ning with “t, tT(for, in order to)”.
The second type of errors are found when the
chunk is too long, like more than 8 words. Nor-
mally it is not easy to eliminate this kind of errors
through local lexical features. In Chinese, the long
chunks are mainly composed of “M (DE)” struc-
ture that can be translated into attributive clause
in English. The “M (DE)” structures are usually
nested component and used as a modifier of noun
phrases, thus this kind of errors can be partly re-
solved by accurately recognition of such structure.
The third type of errors concern the sentence
with some special structure, like intransitive sen-
tence, elliptical sentence (left out of subject or ob-
ject), and so on. The errors of “IO” with wrong
tag “OBJ”, and errors of “EXT” with wrong tag
“OBJ” fall into the third categories. It is interest-
ing to notice that, when using GoldPARSE (see
Table 5), suggesting that features from the trees
are helpful when disambiguating function labels
that related with sentence structures.
</bodyText>
<sectionHeader confidence="0.998277" genericHeader="conclusions">
5 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.99996844">
We have presented the first experimental results on
Chinese function labeling using Chinese Treebank
resources, and shown that Chinese function la-
beling can be reached with considerable accuracy
given a small number of lexical features. Even
though our experiments using hand-crafted parse
trees yield promising initial results, this method
will be hampered when using fully automatic
parser due to the imperfection of Chinese parser,
which is our core motivation to assign function la-
bels by exploiting the underlining lexical insights
instead of parse trees. Experimental results sug-
gest that our method for Chinese function label-
ing is comparable with the English state-of-the-art
work that utilizes complicated parse trees.
We believe that we have not settled on an “opti-
mal” set of features for Chinese function labeling,
hence, more language-specific customization is
necessary in the future work. Although there have
been speculations and trails on things that func-
tion labels might help with, it remains to be im-
portant to discover how function labels contribute
to other NLP applications, such as the Japanese-
Chinese machine translation system we have been
working on.
</bodyText>
<sectionHeader confidence="0.99959" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.986551">
Altun, Y., Tsochantaridis, I., Hofmann, T. 2003. Hid-
den Markov Support Vector Machines. In: Pro-
</reference>
<page confidence="0.983431">
61
</page>
<reference confidence="0.999797075268818">
ceedings of ICML 2003, pages 172-188, Washing-
ton, DC, USA.
Berger, A., Pietra, D. S., Pietra, D. V. 1996. A Max-
imum Entropy Approach to Natural Language Pro-
cessing. Computational Linguistics, 22(1):39-71.
Blaheta, D. 2004. Function Tagging. Ph.D. thesis, De-
partment of Computer Science, Brown University.
Blaheta, D., Charniak, E. 2000. Assigning Function
Tags to Parsed Text. In: Proceedings of the 1st
NAACL, pages 234-240, Seattle, Washington.
Chrupala, G., Stroppa, N., Genabith, J., Dinu, G. 2007.
Better Training for Function Labeling. In: Proceed-
ings of RANLP2007, Borovets, Bulgaria.
Gildea, D., Palmer, M. 2002. The Necessity of Parsing
for Predicate Argument Recognition. In: Proceed-
ings of the 40th ACL, pages 239-246, Philadelphia,
USA.
Iida, R., Komachi, M., Inui, K., Matsumoto, Y. 2007.
Annotating a Japanese Text Corpus with Predicate-
argument and Coreference Relations. In: Proceed-
ings of ACL workshop on the linguistic annotation,
pages 132-139, Prague, Czech Republic.
Jijkoun, V., Rijke D. M. 2004. Enriching the Out-
put of a Parser Using Memory-based Learning.
In: Proceedings of the 42nd ACL, pages 311-318,
Barcelona, Spain.
Kiss, T., Strunk, J. 2006. Unsupervised Multilingual
Sentence Boundary Detection. Computational Lin-
guistics, 32(4):485-525.
Kudo, T., Matsumoto, Y. 2001. Chunking with
Support Vector Machines. In: Proceedings of the
NAACL 2001, pages 1-8, Pittsburgh, USA.
Nocedal, J., Wright, S. J. 1999. Numerical Optimiza-
tion. Springer.
Lafferty, J., McCallum, A., Pereira, F. 2001. Condi-
tional Random Fields: Probabilistic Models for Seg-
menting and Labeling Sequence Data. In: Proceed-
ings of ICML 2001, pages 282-289, Williamstown,
USA.
Levin, B. 1993. English Verb Classes and Alterna-
tions: A preliminary Investigation. The University
of Chicago Press, USA.
Marcus, M., Kim, G., Marcinkiewicz, A. M., Macin-
tyre, R., Bies, A., Ferguson, M., Katz, K., Schas-
berger, B. 1994. The Penn Treebank: Annotating
Predicate Argument Structure. In: Proceedings of
ARPA Human Language Technology Workshop, San
Francisco, USA.
Mccallum, A., Freitag, D., Pereira, F. 2000. Maximum
Entropy Markov Models for Information Extraction
and Segmentation. In: Proceedings of ICML 2000,
pages 591-598, Stanford University, USA.
Merlo, P., Ferrer, E. E. 2006. The Notion of Argument
in Prepositional Phrase Attachment. Computational
Linguistics, 32(3):341-378.
Merlo, P., Musillo, G. 2005. Accurate Function Pars-
ing. In: Proceedings of EMNLP 2005, pages 620-
627, Vancouver, Canada.
Qin, Y., Yuan, C., Sun, J., Wang, X. 2008. BUPT
Systems in the SIGHAN Bakeoff 2007. In: Pro-
ceedings of the Sixth SIGHAN Workshop on Chinese
Language Processing, pages 94-97, Hyderabad, In-
dia.
Rabiner, L. 1989. A Tutorial on Hidden Markov Mod-
els and Selected Applications in Speech Recogni-
tion. In: Proceedings of the IEEE, 77(2):257-286.
Ramshaw, L., Marcus, M. 1995. Text Chunking Using
Transformation Based Learning. In: Proceedings of
ACL Third Workshop on Very Large Corpora, pages
82-94, Cambridge MA, USA.
Swier, R., Stevenson, S. 2004. Unsupervised Semantic
Role Labelling. In: Proceedings of EMNLP-2004,
pages 95-102, Barcelona, Spain.
Tsochantaridis, T., Hofmann, T., Joachims, T., Altun,
Y. 2004. Support Vector Machine Learning for
Interdependent and Structured Output Spaces. In:
Proceedings of ICML 2004, pages 823-830, Banff,
Canada.
Wang, M., Sagae, K., Mitamura, T. 2006. A Fast,
Accurate Deterministic Parser for Chinese. In: Pro-
ceedings of the 44th ACL, pages 425-432, Sydney,
Australia.
Xue, N., Xia, F., Huang, S., Kroch, T. 2000. The
Bracketing Guidelines for the Chinese Treebank.
IRCS Tech., rep., University of Pennsylvania.
Zhao, Y., Zhou, Q. 2006. A SVM-based Model for
Chinese Functional Chunk Parsing. In: Proceed-
ings of the Fifth SIGHAN Workshop on Chinese Lan-
guage Processing, pages 94-10, Sydney, Australia1.
Zhou, Q., Zhan, W., Ren, H. 2001. Building a Large-
scale Chinese Chunkbank (in Chinese). In: Pro-
ceedings of the 6th Joint Conference of Computa-
tional Linguistics of China, Taiyuan, China.
</reference>
<page confidence="0.999187">
62
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.739988">
<title confidence="0.998467">Accurate Learning for Chinese Function Tags from Minimal Features</title>
<author confidence="0.898378">Fuji</author>
<author confidence="0.898378">Xiaojie</author>
<affiliation confidence="0.930109">University of Tokushima, Tokushima, Japan University of Posts and Telecommunications, Beijing, China</affiliation>
<email confidence="0.969823">xjwang@bupt.edu.cn</email>
<abstract confidence="0.999529615384615">Data-driven function tag assignment has been studied for English using Penn Treebank data. In this paper, we address the question of whether such method can be applied to other languages and Treebank resources. In addition to simply extend previous method from English to Chinese, we also proposed an effective way to recognize function tags directly from lexical information, which is easily scalable for languages that lack sufficient parsing resources or have inherent linguistic challenges for parsing. We investigated a supervised sequence learning method to automatically recognize function tags, which achieves an F-score of 0.938 on gold-standard POS (Part-of- Speech) tagged Chinese text – a statistically significant improvement over existing Chinese function label assignment systems. Results show that a small number of linguistically motivated lexical features are sufficient to achieve comparable performance to systems using sophisticated parse trees.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Y Altun</author>
<author>I Tsochantaridis</author>
<author>T Hofmann</author>
</authors>
<title>Hidden Markov Support Vector Machines. In:</title>
<date>2003</date>
<booktitle>Proceedings of ICML 2003,</booktitle>
<pages>172--188</pages>
<location>Washington, DC, USA.</location>
<contexts>
<context position="11833" citStr="Altun et al., 2003" startWordPosition="1932" endWordPosition="1935"> words x = x1, ..., xT, where yi E E. Therefore the function labeling task can be formulated as a stream of sequence learning problem. The general approach is to learn a w-parameterized mapping function F : X×Y → R based on training sample of inputoutput pairs and to maximize F(x, y; w) over the response variable to make a prediction. There has been several algorithms for labeling sequence data including hidden Markov model (Rabiner, 1989), maximum entropy Markov model (Mccallum et al., 2000), conditional random fields (Lafferty et al., 2001) and hidden Markov support vector machine (HM-SVM) (Altun et al., 2003; Tsochantaridis et al., 2004), among which HMSVM shows notable advantages by its learning 56 non-linear discriminant functions via kernel function, the properties inherited from support vector machines (SVMs). Furthermore, HM-SVM retains some of the key advantages of Markov model, namely the Markov chain dependency structure between labels and an efficient dynamic programming formulation. In this paper we investigate the application of the HM-SVM model to Chinese function labeling task. In order to keep the completeness of paper, we here address briefly the HM-SVM algorithm, more details of w</context>
</contexts>
<marker>Altun, Tsochantaridis, Hofmann, 2003</marker>
<rawString>Altun, Y., Tsochantaridis, I., Hofmann, T. 2003. Hidden Markov Support Vector Machines. In: Proceedings of ICML 2003, pages 172-188, Washington, DC, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Berger</author>
<author>D S Pietra</author>
<author>D V Pietra</author>
</authors>
<title>A Maximum Entropy Approach to Natural Language Processing.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<pages>22--1</pages>
<contexts>
<context position="20030" citStr="Berger et al., 1996" startWordPosition="3336" endWordPosition="3339">bearing the “O” label are not counted in for computing overall precision, recall and F-score. We derived 18,782 sentences from CTB 5.0 with about 497 thousands of words (including punctuation marks). On average, each sentence contains 26.5 words with 2.4 verbs. We followed 5-fold cross-validation method in our experiment. The numbers reported are the averages of the results across the five test sets. 4.1 Evaluation of Different Features and Models In pilot experiments on a subset of the features, we provide a comparison of HM-SVM with other two learning models, maximum entropy (MaxEnt) model (Berger et al., 1996) and SVM model (Kudo, 2001), to test the effectiveness of HMSVM on function labeling task, as well as the generality of our hypothesis on different learning 58 Table 3: Features used in each experiment round. FT1 word &amp; POS tags within [-2,+2] FT2 word &amp; POS tags within [-3,+3] FT3 word &amp; POS tags within [-4,+4] FT4 FT3 plus POS bigrams within [-4, +4] FT5 FT4 plus verbs FT6 FT5 plus POS tags of verbs FT7 FT6 plus position indicators models. In our experiment, SVMs and HM-SVM training are carried out with SVMstruct packages4. The multi-class SVMs model is realized by extending binary SVMs usin</context>
</contexts>
<marker>Berger, Pietra, Pietra, 1996</marker>
<rawString>Berger, A., Pietra, D. S., Pietra, D. V. 1996. A Maximum Entropy Approach to Natural Language Processing. Computational Linguistics, 22(1):39-71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Blaheta</author>
</authors>
<title>Function Tagging.</title>
<date>2004</date>
<tech>Ph.D. thesis,</tech>
<institution>Department of Computer Science, Brown University.</institution>
<contexts>
<context position="2252" citStr="Blaheta, 2004" startWordPosition="338" endWordPosition="339">1 shows the parse tree with function tags for a sample sentence form the Penn Chinese Treebank 5.01 (Xue et al., 2000) (file 0043.fid). 1released by Linguistic Data Consortium (LDC) catalog NO. LDC2005T01 Figure 1: Simplified parse tree with function tags (in black bold) for example sentence. When dealing with the task of function tag assignment (or function labeling thereafter), one basic question that must be addressed is what features can be extracted in practice for distinguishing different function tag types. In answering this question, several pieces of work (Blaheta and Charniak, 2000; Blaheta, 2004; Merlo and Musillo, 2005; Gildea and Palmer, 2002) have already been proposed. (Blaheta and Charniak, 2000; Blaheta, 2004) described a statistical system trained on the data of Penn Treebank to automatically assign function tags for English text. The system first passed sentences through an automatic parser, then extracted features from the parse trees and predicted the most plausible function label of constituent from these features. Noting that parsing errors are difficult or even impossible to recover at function tag recognition stage, the alternative approaches are obtained by assigning f</context>
<context position="26810" citStr="Blaheta, 2004" startWordPosition="4439" endWordPosition="4441">within our first expectation. Table 5: Performance separated for grammatical roles and adverbials, of our models GoldPOS (using gold-standard POS tags), GoldPARSE (using gold-standard parse trees), AutoPOS (using automatically labeled POS tags). grammatical roles adverbials P R F P R F GoldPOS 0.949 0.960 0.955 0.887 0.887 0.887 AutoPOS 0.921 0.948 0.934 0.872 0.867 0.869 GoldPARSE 0.936 0.967 0.951 0.911 0.884 0.897 4.4 Results with Gold-standard Parser A thoroughly different way for function labeling is deriving function labels together with parsing. The work of (Blaheta and Charniak, 2000; Blaheta, 2004; Merlo and Musillo, 2005) has approved its effectiveness in English text. Among them, the work of Merlo and Musillo (Merlo and Musillo, 2005) achieved a state-of-the-art F1 score for English function labeling (0.964 for grammatical roles and 0.863 for adverbials). In order to address the question of whether such method can be successfully applied to Chinese text and whether the simple method we proposed is better than or at least equivalent to it, we used features collected from hand-crafted parse trees in CTB resources, and did a separate experiment on the same text. The features we used are</context>
<context position="28818" citStr="Blaheta, 2004" startWordPosition="4776" endWordPosition="4777">e functional chunks are more local and less prone to structured parse trees, as observed in examples listed at the beginning of the paper. In Table 5, although the performance of adverbials grows really huge when using features from the gold-standard parse trees, the performance of grammatical roles drops as introducing such features. As mentioned above, in fact even the simple position feature can give a better explanation to word’s grammatical role than complicated syntactic path. Although the experimental setup is strictly not the same for the present paper and (Blaheta and Charniak, 2000; Blaheta, 2004; Merlo and Musillo, 2005), we observe that the proposed method yields better results with deliberately designed but simple features at lexical level, while attempts in (Blaheta and Charniak, 2000; Blaheta, 2004; Merlo and Musillo, 2005) optimized function labeling together with parsing, which is a more complex task and difficult to realize for languages that lack sufficient parse resources. The work of (Blaheta and Charniak, 2000; Blaheta, 2004; Merlo and Musillo, 2005) reveal that the performance of parser used sets upper bound on the performance of function labeling. However, the best Chine</context>
</contexts>
<marker>Blaheta, 2004</marker>
<rawString>Blaheta, D. 2004. Function Tagging. Ph.D. thesis, Department of Computer Science, Brown University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Blaheta</author>
<author>E Charniak</author>
</authors>
<title>Assigning Function Tags to Parsed Text. In:</title>
<date>2000</date>
<booktitle>Proceedings of the 1st NAACL,</booktitle>
<pages>234--240</pages>
<location>Seattle, Washington.</location>
<contexts>
<context position="2237" citStr="Blaheta and Charniak, 2000" startWordPosition="334" endWordPosition="337">s and function tags. Figure 1 shows the parse tree with function tags for a sample sentence form the Penn Chinese Treebank 5.01 (Xue et al., 2000) (file 0043.fid). 1released by Linguistic Data Consortium (LDC) catalog NO. LDC2005T01 Figure 1: Simplified parse tree with function tags (in black bold) for example sentence. When dealing with the task of function tag assignment (or function labeling thereafter), one basic question that must be addressed is what features can be extracted in practice for distinguishing different function tag types. In answering this question, several pieces of work (Blaheta and Charniak, 2000; Blaheta, 2004; Merlo and Musillo, 2005; Gildea and Palmer, 2002) have already been proposed. (Blaheta and Charniak, 2000; Blaheta, 2004) described a statistical system trained on the data of Penn Treebank to automatically assign function tags for English text. The system first passed sentences through an automatic parser, then extracted features from the parse trees and predicted the most plausible function label of constituent from these features. Noting that parsing errors are difficult or even impossible to recover at function tag recognition stage, the alternative approaches are obtained</context>
<context position="10117" citStr="Blaheta and Charniak, 2000" startWordPosition="1634" endWordPosition="1637">d sentences, which are listed in Table 2. As can be seen, the frequency of adverbials is much smaller than that of grammatical roles. Furthermore, the average length of most adverbials are somewhat larger than 4. Such data distribution is likely to be one cause of the lower identification accuracy of adverbials as we will see in the experiments. From the layer of function labeling, sentences 3ADV includes ADV and ADVP in CTB recourses, grouped into adverbials. In function labeling level, EXT that signifies degree, amount of the predicates should be grouped into adverbials like in the work of (Blaheta and Charniak, 2000) and (Merlo and Musillo, 2005). Table 2: Categories of function tags with their relative frequencies and average length. Function Labels Frequency Average Length grammatical roles 99507 2.62 FOC 133 1.89 IO 126 1.26 OBJ 25834 4.15 PRD 4428 5.20 SBJ 23809 3.02 TPC 676 3.51 TAR 44501 1.25 adverbials 33287 2.11 ADT 1415 4.51 ADV 21891 1.32 BNF 465 4.66 CND 68 3.15 DIR 1558 4.68 EXT 1048 1.99 IJ 1 1.00 LGS 204 5.42 LOC 2051 4.27 MNR 1053 4.48 PRP 224 4.91 TMP 3309 2.25 in CTB are described with the structure of “SV” which indicates a sentence is basically composed of “subject + verb”. But in order</context>
<context position="19313" citStr="Blaheta and Charniak, 2000" startWordPosition="3222" endWordPosition="3225">: precision, which is the percentage of detected chunks that are correct; recall, which is the percentage of chunks in the data that are found by the tagger; and F-score which is equal to 2xprecisionxrecall/(precision+recall). Under the “IOB” tagging scheme, a function chunk is only counted as correct when its boundaries and its type are both identified correctly. Furthermore, sentence accuracy is used in order to observe the prediction correctness of sentences, which is defined as the percentage of sentences within which all the constituents are assigned with correct tags. As in the work of (Blaheta and Charniak, 2000) and (Merlo and Musillo, 2005), to avoid calculating excessively optimistic values, constituents bearing the “O” label are not counted in for computing overall precision, recall and F-score. We derived 18,782 sentences from CTB 5.0 with about 497 thousands of words (including punctuation marks). On average, each sentence contains 26.5 words with 2.4 verbs. We followed 5-fold cross-validation method in our experiment. The numbers reported are the averages of the results across the five test sets. 4.1 Evaluation of Different Features and Models In pilot experiments on a subset of the features, w</context>
<context position="26795" citStr="Blaheta and Charniak, 2000" startWordPosition="4435" endWordPosition="4438">ver, the small gap is still within our first expectation. Table 5: Performance separated for grammatical roles and adverbials, of our models GoldPOS (using gold-standard POS tags), GoldPARSE (using gold-standard parse trees), AutoPOS (using automatically labeled POS tags). grammatical roles adverbials P R F P R F GoldPOS 0.949 0.960 0.955 0.887 0.887 0.887 AutoPOS 0.921 0.948 0.934 0.872 0.867 0.869 GoldPARSE 0.936 0.967 0.951 0.911 0.884 0.897 4.4 Results with Gold-standard Parser A thoroughly different way for function labeling is deriving function labels together with parsing. The work of (Blaheta and Charniak, 2000; Blaheta, 2004; Merlo and Musillo, 2005) has approved its effectiveness in English text. Among them, the work of Merlo and Musillo (Merlo and Musillo, 2005) achieved a state-of-the-art F1 score for English function labeling (0.964 for grammatical roles and 0.863 for adverbials). In order to address the question of whether such method can be successfully applied to Chinese text and whether the simple method we proposed is better than or at least equivalent to it, we used features collected from hand-crafted parse trees in CTB resources, and did a separate experiment on the same text. The featu</context>
<context position="28803" citStr="Blaheta and Charniak, 2000" startWordPosition="4772" endWordPosition="4775"> possible reason is that some functional chunks are more local and less prone to structured parse trees, as observed in examples listed at the beginning of the paper. In Table 5, although the performance of adverbials grows really huge when using features from the gold-standard parse trees, the performance of grammatical roles drops as introducing such features. As mentioned above, in fact even the simple position feature can give a better explanation to word’s grammatical role than complicated syntactic path. Although the experimental setup is strictly not the same for the present paper and (Blaheta and Charniak, 2000; Blaheta, 2004; Merlo and Musillo, 2005), we observe that the proposed method yields better results with deliberately designed but simple features at lexical level, while attempts in (Blaheta and Charniak, 2000; Blaheta, 2004; Merlo and Musillo, 2005) optimized function labeling together with parsing, which is a more complex task and difficult to realize for languages that lack sufficient parse resources. The work of (Blaheta and Charniak, 2000; Blaheta, 2004; Merlo and Musillo, 2005) reveal that the performance of parser used sets upper bound on the performance of function labeling. However,</context>
</contexts>
<marker>Blaheta, Charniak, 2000</marker>
<rawString>Blaheta, D., Charniak, E. 2000. Assigning Function Tags to Parsed Text. In: Proceedings of the 1st NAACL, pages 234-240, Seattle, Washington.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Chrupala</author>
<author>N Stroppa</author>
<author>J Genabith</author>
<author>G Dinu</author>
</authors>
<title>Better Training for Function Labeling. In:</title>
<date>2007</date>
<booktitle>Proceedings of RANLP2007, Borovets,</booktitle>
<marker>Chrupala, Stroppa, Genabith, Dinu, 2007</marker>
<rawString>Chrupala, G., Stroppa, N., Genabith, J., Dinu, G. 2007. Better Training for Function Labeling. In: Proceedings of RANLP2007, Borovets, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Gildea</author>
<author>M Palmer</author>
</authors>
<title>The Necessity of Parsing for Predicate Argument Recognition. In:</title>
<date>2002</date>
<booktitle>Proceedings of the 40th ACL,</booktitle>
<pages>239--246</pages>
<location>Philadelphia, USA.</location>
<contexts>
<context position="2303" citStr="Gildea and Palmer, 2002" startWordPosition="344" endWordPosition="347">s for a sample sentence form the Penn Chinese Treebank 5.01 (Xue et al., 2000) (file 0043.fid). 1released by Linguistic Data Consortium (LDC) catalog NO. LDC2005T01 Figure 1: Simplified parse tree with function tags (in black bold) for example sentence. When dealing with the task of function tag assignment (or function labeling thereafter), one basic question that must be addressed is what features can be extracted in practice for distinguishing different function tag types. In answering this question, several pieces of work (Blaheta and Charniak, 2000; Blaheta, 2004; Merlo and Musillo, 2005; Gildea and Palmer, 2002) have already been proposed. (Blaheta and Charniak, 2000; Blaheta, 2004) described a statistical system trained on the data of Penn Treebank to automatically assign function tags for English text. The system first passed sentences through an automatic parser, then extracted features from the parse trees and predicted the most plausible function label of constituent from these features. Noting that parsing errors are difficult or even impossible to recover at function tag recognition stage, the alternative approaches are obtained by assigning function tags at the same time as producing parse tr</context>
</contexts>
<marker>Gildea, Palmer, 2002</marker>
<rawString>Gildea, D., Palmer, M. 2002. The Necessity of Parsing for Predicate Argument Recognition. In: Proceedings of the 40th ACL, pages 239-246, Philadelphia, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Iida</author>
<author>M Komachi</author>
<author>K Inui</author>
<author>Y Matsumoto</author>
</authors>
<title>Annotating a Japanese Text Corpus with Predicateargument and Coreference Relations. In:</title>
<date>2007</date>
<booktitle>Proceedings of ACL workshop on the linguistic annotation,</booktitle>
<pages>132--139</pages>
<location>Prague, Czech Republic.</location>
<marker>Iida, Komachi, Inui, Matsumoto, 2007</marker>
<rawString>Iida, R., Komachi, M., Inui, K., Matsumoto, Y. 2007. Annotating a Japanese Text Corpus with Predicateargument and Coreference Relations. In: Proceedings of ACL workshop on the linguistic annotation, pages 132-139, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Jijkoun</author>
<author>D M Rijke</author>
</authors>
<title>Enriching the Output of a Parser Using Memory-based Learning. In:</title>
<date>2004</date>
<booktitle>Proceedings of the 42nd ACL,</booktitle>
<pages>311--318</pages>
<location>Barcelona,</location>
<marker>Jijkoun, Rijke, 2004</marker>
<rawString>Jijkoun, V., Rijke D. M. 2004. Enriching the Output of a Parser Using Memory-based Learning. In: Proceedings of the 42nd ACL, pages 311-318, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Kiss</author>
<author>J Strunk</author>
</authors>
<title>Unsupervised Multilingual Sentence Boundary Detection.</title>
<date>2006</date>
<journal>Computational Linguistics,</journal>
<pages>32--4</pages>
<marker>Kiss, Strunk, 2006</marker>
<rawString>Kiss, T., Strunk, J. 2006. Unsupervised Multilingual Sentence Boundary Detection. Computational Linguistics, 32(4):485-525.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Kudo</author>
<author>Y Matsumoto</author>
</authors>
<title>Chunking with Support Vector Machines. In:</title>
<date>2001</date>
<booktitle>Proceedings of the NAACL</booktitle>
<pages>1--8</pages>
<location>Pittsburgh, USA.</location>
<marker>Kudo, Matsumoto, 2001</marker>
<rawString>Kudo, T., Matsumoto, Y. 2001. Chunking with Support Vector Machines. In: Proceedings of the NAACL 2001, pages 1-8, Pittsburgh, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Nocedal</author>
<author>S J Wright</author>
</authors>
<title>Numerical Optimization.</title>
<date>1999</date>
<publisher>Springer.</publisher>
<marker>Nocedal, Wright, 1999</marker>
<rawString>Nocedal, J., Wright, S. J. 1999. Numerical Optimization. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lafferty</author>
<author>A McCallum</author>
<author>F Pereira</author>
</authors>
<title>Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data. In:</title>
<date>2001</date>
<booktitle>Proceedings of ICML</booktitle>
<pages>282--289</pages>
<location>Williamstown, USA.</location>
<contexts>
<context position="11763" citStr="Lafferty et al., 2001" startWordPosition="1921" endWordPosition="1924"> sequence of function tags y = y1, ..., yT, from a given sequence of input words x = x1, ..., xT, where yi E E. Therefore the function labeling task can be formulated as a stream of sequence learning problem. The general approach is to learn a w-parameterized mapping function F : X×Y → R based on training sample of inputoutput pairs and to maximize F(x, y; w) over the response variable to make a prediction. There has been several algorithms for labeling sequence data including hidden Markov model (Rabiner, 1989), maximum entropy Markov model (Mccallum et al., 2000), conditional random fields (Lafferty et al., 2001) and hidden Markov support vector machine (HM-SVM) (Altun et al., 2003; Tsochantaridis et al., 2004), among which HMSVM shows notable advantages by its learning 56 non-linear discriminant functions via kernel function, the properties inherited from support vector machines (SVMs). Furthermore, HM-SVM retains some of the key advantages of Markov model, namely the Markov chain dependency structure between labels and an efficient dynamic programming formulation. In this paper we investigate the application of the HM-SVM model to Chinese function labeling task. In order to keep the completeness of </context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>Lafferty, J., McCallum, A., Pereira, F. 2001. Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data. In: Proceedings of ICML 2001, pages 282-289, Williamstown, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Levin</author>
</authors>
<title>English Verb Classes and Alternations: A preliminary Investigation.</title>
<date>1993</date>
<publisher>The University of Chicago Press, USA.</publisher>
<contexts>
<context position="15993" citStr="Levin, 1993" startWordPosition="2663" endWordPosition="2664">mise among them. In our experiment, we start from a context of [-2, +2] and then expand it to [-4, 4], that is, four words (and POS tags) around the word in question, which is closest to the average length of most function types shown in Table 2. Bi-gram of POS tags: Apart from POS tags themselves, we also try on the bi-gram of POS tags. We regard POS tag sequence as an analog to function min w 57 chains, which reveals somewhat the dependent relations among words. Verbs: Function labels like subject and object specify the relations between verb and its arguments. As observed in English verbs (Levin, 1993), each class of verb is associated with a set of syntactic frames. Similar criteria can also be found in Chinese. In this sense, we can rely on the surface verb for distinguishing argument roles syntactically. Besides the verbs themselves, we also take into account the special words sharing common property with verbs in Chinese language, which are active voice “4U(BA)” and passive voice “*(BEI)”. The verb we refer here is supposed to be the last verb if it happens in a consecutive verb sequence, thus actually not the head verb of sentence. POS tags of verbs: according to CTB annotation guideli</context>
</contexts>
<marker>Levin, 1993</marker>
<rawString>Levin, B. 1993. English Verb Classes and Alternations: A preliminary Investigation. The University of Chicago Press, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Marcus</author>
<author>G Kim</author>
<author>A M Marcinkiewicz</author>
<author>R Macintyre</author>
<author>A Bies</author>
<author>M Ferguson</author>
<author>K Katz</author>
<author>B Schasberger</author>
</authors>
<title>The Penn Treebank: Annotating Predicate Argument Structure. In:</title>
<date>1994</date>
<booktitle>Proceedings of ARPA Human Language Technology Workshop,</booktitle>
<location>San Francisco, USA.</location>
<contexts>
<context position="1564" citStr="Marcus et al., 1994" startWordPosition="227" endWordPosition="230"> POS (Part-ofSpeech) tagged Chinese text – a statistically significant improvement over existing Chinese function label assignment systems. Results show that a small number of linguistically motivated lexical features are sufficient to achieve comparable performance to systems using sophisticated parse trees. 1 Introduction Function tags, such as subject, object, time, location, etc. are conceptually appealing by encoding an event in the format of “who did what to whom, where, when”, which provides useful semantic information of the sentences. Lexical semantic resources such as Penn Treebank (Marcus et al., 1994) have been annotated with phrase tree structures and function tags. Figure 1 shows the parse tree with function tags for a sample sentence form the Penn Chinese Treebank 5.01 (Xue et al., 2000) (file 0043.fid). 1released by Linguistic Data Consortium (LDC) catalog NO. LDC2005T01 Figure 1: Simplified parse tree with function tags (in black bold) for example sentence. When dealing with the task of function tag assignment (or function labeling thereafter), one basic question that must be addressed is what features can be extracted in practice for distinguishing different function tag types. In an</context>
</contexts>
<marker>Marcus, Kim, Marcinkiewicz, Macintyre, Bies, Ferguson, Katz, Schasberger, 1994</marker>
<rawString>Marcus, M., Kim, G., Marcinkiewicz, A. M., Macintyre, R., Bies, A., Ferguson, M., Katz, K., Schasberger, B. 1994. The Penn Treebank: Annotating Predicate Argument Structure. In: Proceedings of ARPA Human Language Technology Workshop, San Francisco, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Mccallum</author>
<author>D Freitag</author>
<author>F Pereira</author>
</authors>
<title>Maximum Entropy Markov Models for Information Extraction and Segmentation. In:</title>
<date>2000</date>
<booktitle>Proceedings of ICML 2000,</booktitle>
<pages>591--598</pages>
<institution>Stanford University, USA.</institution>
<contexts>
<context position="11712" citStr="Mccallum et al., 2000" startWordPosition="1914" endWordPosition="1917">ion labeling deals with the problem of predicting a sequence of function tags y = y1, ..., yT, from a given sequence of input words x = x1, ..., xT, where yi E E. Therefore the function labeling task can be formulated as a stream of sequence learning problem. The general approach is to learn a w-parameterized mapping function F : X×Y → R based on training sample of inputoutput pairs and to maximize F(x, y; w) over the response variable to make a prediction. There has been several algorithms for labeling sequence data including hidden Markov model (Rabiner, 1989), maximum entropy Markov model (Mccallum et al., 2000), conditional random fields (Lafferty et al., 2001) and hidden Markov support vector machine (HM-SVM) (Altun et al., 2003; Tsochantaridis et al., 2004), among which HMSVM shows notable advantages by its learning 56 non-linear discriminant functions via kernel function, the properties inherited from support vector machines (SVMs). Furthermore, HM-SVM retains some of the key advantages of Markov model, namely the Markov chain dependency structure between labels and an efficient dynamic programming formulation. In this paper we investigate the application of the HM-SVM model to Chinese function l</context>
</contexts>
<marker>Mccallum, Freitag, Pereira, 2000</marker>
<rawString>Mccallum, A., Freitag, D., Pereira, F. 2000. Maximum Entropy Markov Models for Information Extraction and Segmentation. In: Proceedings of ICML 2000, pages 591-598, Stanford University, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Merlo</author>
<author>E E Ferrer</author>
</authors>
<date>2006</date>
<booktitle>The Notion of Argument in Prepositional Phrase Attachment. Computational Linguistics,</booktitle>
<pages>32--3</pages>
<marker>Merlo, Ferrer, 2006</marker>
<rawString>Merlo, P., Ferrer, E. E. 2006. The Notion of Argument in Prepositional Phrase Attachment. Computational Linguistics, 32(3):341-378.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Merlo</author>
<author>G Musillo</author>
</authors>
<title>Accurate Function Parsing. In:</title>
<date>2005</date>
<booktitle>Proceedings of EMNLP 2005,</booktitle>
<pages>620--627</pages>
<location>Vancouver, Canada.</location>
<contexts>
<context position="2277" citStr="Merlo and Musillo, 2005" startWordPosition="340" endWordPosition="343">se tree with function tags for a sample sentence form the Penn Chinese Treebank 5.01 (Xue et al., 2000) (file 0043.fid). 1released by Linguistic Data Consortium (LDC) catalog NO. LDC2005T01 Figure 1: Simplified parse tree with function tags (in black bold) for example sentence. When dealing with the task of function tag assignment (or function labeling thereafter), one basic question that must be addressed is what features can be extracted in practice for distinguishing different function tag types. In answering this question, several pieces of work (Blaheta and Charniak, 2000; Blaheta, 2004; Merlo and Musillo, 2005; Gildea and Palmer, 2002) have already been proposed. (Blaheta and Charniak, 2000; Blaheta, 2004) described a statistical system trained on the data of Penn Treebank to automatically assign function tags for English text. The system first passed sentences through an automatic parser, then extracted features from the parse trees and predicted the most plausible function label of constituent from these features. Noting that parsing errors are difficult or even impossible to recover at function tag recognition stage, the alternative approaches are obtained by assigning function tags at the same </context>
<context position="10147" citStr="Merlo and Musillo, 2005" startWordPosition="1639" endWordPosition="1642">Table 2. As can be seen, the frequency of adverbials is much smaller than that of grammatical roles. Furthermore, the average length of most adverbials are somewhat larger than 4. Such data distribution is likely to be one cause of the lower identification accuracy of adverbials as we will see in the experiments. From the layer of function labeling, sentences 3ADV includes ADV and ADVP in CTB recourses, grouped into adverbials. In function labeling level, EXT that signifies degree, amount of the predicates should be grouped into adverbials like in the work of (Blaheta and Charniak, 2000) and (Merlo and Musillo, 2005). Table 2: Categories of function tags with their relative frequencies and average length. Function Labels Frequency Average Length grammatical roles 99507 2.62 FOC 133 1.89 IO 126 1.26 OBJ 25834 4.15 PRD 4428 5.20 SBJ 23809 3.02 TPC 676 3.51 TAR 44501 1.25 adverbials 33287 2.11 ADT 1415 4.51 ADV 21891 1.32 BNF 465 4.66 CND 68 3.15 DIR 1558 4.68 EXT 1048 1.99 IJ 1 1.00 LGS 204 5.42 LOC 2051 4.27 MNR 1053 4.48 PRP 224 4.91 TMP 3309 2.25 in CTB are described with the structure of “SV” which indicates a sentence is basically composed of “subject + verb”. But in order to identify objects and compl</context>
<context position="19343" citStr="Merlo and Musillo, 2005" startWordPosition="3227" endWordPosition="3230">age of detected chunks that are correct; recall, which is the percentage of chunks in the data that are found by the tagger; and F-score which is equal to 2xprecisionxrecall/(precision+recall). Under the “IOB” tagging scheme, a function chunk is only counted as correct when its boundaries and its type are both identified correctly. Furthermore, sentence accuracy is used in order to observe the prediction correctness of sentences, which is defined as the percentage of sentences within which all the constituents are assigned with correct tags. As in the work of (Blaheta and Charniak, 2000) and (Merlo and Musillo, 2005), to avoid calculating excessively optimistic values, constituents bearing the “O” label are not counted in for computing overall precision, recall and F-score. We derived 18,782 sentences from CTB 5.0 with about 497 thousands of words (including punctuation marks). On average, each sentence contains 26.5 words with 2.4 verbs. We followed 5-fold cross-validation method in our experiment. The numbers reported are the averages of the results across the five test sets. 4.1 Evaluation of Different Features and Models In pilot experiments on a subset of the features, we provide a comparison of HM-S</context>
<context position="26836" citStr="Merlo and Musillo, 2005" startWordPosition="4442" endWordPosition="4445">t expectation. Table 5: Performance separated for grammatical roles and adverbials, of our models GoldPOS (using gold-standard POS tags), GoldPARSE (using gold-standard parse trees), AutoPOS (using automatically labeled POS tags). grammatical roles adverbials P R F P R F GoldPOS 0.949 0.960 0.955 0.887 0.887 0.887 AutoPOS 0.921 0.948 0.934 0.872 0.867 0.869 GoldPARSE 0.936 0.967 0.951 0.911 0.884 0.897 4.4 Results with Gold-standard Parser A thoroughly different way for function labeling is deriving function labels together with parsing. The work of (Blaheta and Charniak, 2000; Blaheta, 2004; Merlo and Musillo, 2005) has approved its effectiveness in English text. Among them, the work of Merlo and Musillo (Merlo and Musillo, 2005) achieved a state-of-the-art F1 score for English function labeling (0.964 for grammatical roles and 0.863 for adverbials). In order to address the question of whether such method can be successfully applied to Chinese text and whether the simple method we proposed is better than or at least equivalent to it, we used features collected from hand-crafted parse trees in CTB resources, and did a separate experiment on the same text. The features we used are borrowed from feature tre</context>
<context position="28844" citStr="Merlo and Musillo, 2005" startWordPosition="4778" endWordPosition="4781">unks are more local and less prone to structured parse trees, as observed in examples listed at the beginning of the paper. In Table 5, although the performance of adverbials grows really huge when using features from the gold-standard parse trees, the performance of grammatical roles drops as introducing such features. As mentioned above, in fact even the simple position feature can give a better explanation to word’s grammatical role than complicated syntactic path. Although the experimental setup is strictly not the same for the present paper and (Blaheta and Charniak, 2000; Blaheta, 2004; Merlo and Musillo, 2005), we observe that the proposed method yields better results with deliberately designed but simple features at lexical level, while attempts in (Blaheta and Charniak, 2000; Blaheta, 2004; Merlo and Musillo, 2005) optimized function labeling together with parsing, which is a more complex task and difficult to realize for languages that lack sufficient parse resources. The work of (Blaheta and Charniak, 2000; Blaheta, 2004; Merlo and Musillo, 2005) reveal that the performance of parser used sets upper bound on the performance of function labeling. However, the best Chinese parser ever reported (W</context>
</contexts>
<marker>Merlo, Musillo, 2005</marker>
<rawString>Merlo, P., Musillo, G. 2005. Accurate Function Parsing. In: Proceedings of EMNLP 2005, pages 620-627, Vancouver, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Qin</author>
<author>C Yuan</author>
<author>J Sun</author>
<author>X Wang</author>
</authors>
<date>2008</date>
<booktitle>BUPT Systems in the SIGHAN Bakeoff 2007. In: Proceedings of the Sixth SIGHAN Workshop on Chinese Language Processing,</booktitle>
<pages>94--97</pages>
<location>Hyderabad, India.</location>
<contexts>
<context position="25687" citStr="Qin et al., 2008" startWordPosition="4255" endWordPosition="4258">assigned with “ADV” and “MNR” in two totally the same contexts in our training data. Noting that word sequences for some semantic labels carry several limited formations (e.g., most of “DIR” is preposition phrase beginning with “from, to”), we will try some linguistically informed heuristics to detect such patterns in future work. 4.3 Results with Automatically Assigned POS Tags Parallel to experiments on text with gold-standard POS tags, we also present results on automatically POS-tagged text to quantify the effect of POS accuracy on the system performance. We adopt automatic POS tagger of (Qin et al., 2008), which got the first place in the forth SIGHAN Chinese POS tagging bakeoff on CTB open test, to assign POS tags for our data. Following the approach of (Qin et al., 2008), we train the automatic POS tagger which gets an average accuracy of 96.18% in our 5-fold cross-validation data. Function tagger takes raw text as input, then completes POS tagging and function labeling in a cascaded way. As shown in Table 5, the F-score of AutoPOS is slightly lower than that of GoldPOS. However, the small gap is still within our first expectation. Table 5: Performance separated for grammatical roles and adv</context>
</contexts>
<marker>Qin, Yuan, Sun, Wang, 2008</marker>
<rawString>Qin, Y., Yuan, C., Sun, J., Wang, X. 2008. BUPT Systems in the SIGHAN Bakeoff 2007. In: Proceedings of the Sixth SIGHAN Workshop on Chinese Language Processing, pages 94-97, Hyderabad, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Rabiner</author>
</authors>
<title>A Tutorial on Hidden Markov Models and Selected Applications in Speech Recognition. In:</title>
<date>1989</date>
<booktitle>Proceedings of the IEEE,</booktitle>
<pages>77--2</pages>
<contexts>
<context position="11658" citStr="Rabiner, 1989" startWordPosition="1908" endWordPosition="1909">red brackets. 3 Learning Function Labels Function labeling deals with the problem of predicting a sequence of function tags y = y1, ..., yT, from a given sequence of input words x = x1, ..., xT, where yi E E. Therefore the function labeling task can be formulated as a stream of sequence learning problem. The general approach is to learn a w-parameterized mapping function F : X×Y → R based on training sample of inputoutput pairs and to maximize F(x, y; w) over the response variable to make a prediction. There has been several algorithms for labeling sequence data including hidden Markov model (Rabiner, 1989), maximum entropy Markov model (Mccallum et al., 2000), conditional random fields (Lafferty et al., 2001) and hidden Markov support vector machine (HM-SVM) (Altun et al., 2003; Tsochantaridis et al., 2004), among which HMSVM shows notable advantages by its learning 56 non-linear discriminant functions via kernel function, the properties inherited from support vector machines (SVMs). Furthermore, HM-SVM retains some of the key advantages of Markov model, namely the Markov chain dependency structure between labels and an efficient dynamic programming formulation. In this paper we investigate the</context>
</contexts>
<marker>Rabiner, 1989</marker>
<rawString>Rabiner, L. 1989. A Tutorial on Hidden Markov Models and Selected Applications in Speech Recognition. In: Proceedings of the IEEE, 77(2):257-286.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Ramshaw</author>
<author>M Marcus</author>
</authors>
<title>Text Chunking Using Transformation Based Learning. In:</title>
<date>1995</date>
<booktitle>Proceedings of ACL Third Workshop on Very Large Corpora,</booktitle>
<pages>82--94</pages>
<location>Cambridge MA, USA.</location>
<contexts>
<context position="18292" citStr="Ramshaw and Marcus, 1995" startWordPosition="3053" endWordPosition="3056">is empty 2: repeat 3: for each feature ci E C do 4: construct training instances using ci U c experiment on k-fold cross-validation data 5: if accuracy increases then ci → c 6: end if 7: end for 8: until all features in C are traversed 4 Experiment and Discussion In this section, we turn to our computational experiments that investigate whether the statistical indicators of lexical properties that we have developed can in fact be used to classify function labels, and demonstrate which kind of feature contributes most in identifying function types, at least for Chinese text. As in the work of (Ramshaw and Marcus, 1995), each word or punctuation mark within a sentence is labeled with “IOB” tag together with its function type. The three tags are sufficient for encoding all constituents since there are no overlaps among different function chunks. The function tags in this paper are limited to 20 types, resulting in a total of |Σ |= 41 different outputs. We use three measures to evaluate the model performance: precision, which is the percentage of detected chunks that are correct; recall, which is the percentage of chunks in the data that are found by the tagger; and F-score which is equal to 2xprecisionxrecall</context>
</contexts>
<marker>Ramshaw, Marcus, 1995</marker>
<rawString>Ramshaw, L., Marcus, M. 1995. Text Chunking Using Transformation Based Learning. In: Proceedings of ACL Third Workshop on Very Large Corpora, pages 82-94, Cambridge MA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Swier</author>
<author>S Stevenson</author>
</authors>
<title>Unsupervised Semantic Role Labelling. In:</title>
<date>2004</date>
<booktitle>Proceedings of EMNLP-2004,</booktitle>
<pages>95--102</pages>
<location>Barcelona,</location>
<marker>Swier, Stevenson, 2004</marker>
<rawString>Swier, R., Stevenson, S. 2004. Unsupervised Semantic Role Labelling. In: Proceedings of EMNLP-2004, pages 95-102, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Tsochantaridis</author>
<author>T Hofmann</author>
<author>T Joachims</author>
<author>Y Altun</author>
</authors>
<title>Support Vector Machine Learning for Interdependent and Structured Output Spaces. In:</title>
<date>2004</date>
<booktitle>Proceedings of ICML 2004,</booktitle>
<pages>823--830</pages>
<location>Banff, Canada.</location>
<contexts>
<context position="11863" citStr="Tsochantaridis et al., 2004" startWordPosition="1936" endWordPosition="1939">xT, where yi E E. Therefore the function labeling task can be formulated as a stream of sequence learning problem. The general approach is to learn a w-parameterized mapping function F : X×Y → R based on training sample of inputoutput pairs and to maximize F(x, y; w) over the response variable to make a prediction. There has been several algorithms for labeling sequence data including hidden Markov model (Rabiner, 1989), maximum entropy Markov model (Mccallum et al., 2000), conditional random fields (Lafferty et al., 2001) and hidden Markov support vector machine (HM-SVM) (Altun et al., 2003; Tsochantaridis et al., 2004), among which HMSVM shows notable advantages by its learning 56 non-linear discriminant functions via kernel function, the properties inherited from support vector machines (SVMs). Furthermore, HM-SVM retains some of the key advantages of Markov model, namely the Markov chain dependency structure between labels and an efficient dynamic programming formulation. In this paper we investigate the application of the HM-SVM model to Chinese function labeling task. In order to keep the completeness of paper, we here address briefly the HM-SVM algorithm, more details of which could be founded in (Altu</context>
</contexts>
<marker>Tsochantaridis, Hofmann, Joachims, Altun, 2004</marker>
<rawString>Tsochantaridis, T., Hofmann, T., Joachims, T., Altun, Y. 2004. Support Vector Machine Learning for Interdependent and Structured Output Spaces. In: Proceedings of ICML 2004, pages 823-830, Banff, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Wang</author>
<author>K Sagae</author>
<author>T Mitamura</author>
</authors>
<title>A Fast, Accurate Deterministic Parser for Chinese. In:</title>
<date>2006</date>
<booktitle>Proceedings of the 44th ACL,</booktitle>
<pages>425--432</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="29461" citStr="Wang et al., 2006" startWordPosition="4876" endWordPosition="4879">), we observe that the proposed method yields better results with deliberately designed but simple features at lexical level, while attempts in (Blaheta and Charniak, 2000; Blaheta, 2004; Merlo and Musillo, 2005) optimized function labeling together with parsing, which is a more complex task and difficult to realize for languages that lack sufficient parse resources. The work of (Blaheta and Charniak, 2000; Blaheta, 2004; Merlo and Musillo, 2005) reveal that the performance of parser used sets upper bound on the performance of function labeling. However, the best Chinese parser ever reported (Wang et al., 2006) achieves 0.882 F-score for sentences with less than 40 words, we therefore conclude that the way using auto-parser for Chinese function labeling is not the optimal choice. 4.5 Error Analysis In the course of our experiment, we wanted to attain some understanding of what sort of errors the system was making. While still working on the gold-standard POS-tagged text, we randomly took one output from the 5-fold cross-validation tests and examined each error. But when observing the 1,550 wrongly labeled function chunks (26,593 in total), we can distinguish three types of errors. The first and wide</context>
</contexts>
<marker>Wang, Sagae, Mitamura, 2006</marker>
<rawString>Wang, M., Sagae, K., Mitamura, T. 2006. A Fast, Accurate Deterministic Parser for Chinese. In: Proceedings of the 44th ACL, pages 425-432, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Xue</author>
<author>F Xia</author>
<author>S Huang</author>
<author>T Kroch</author>
</authors>
<title>The Bracketing Guidelines for the Chinese Treebank.</title>
<date>2000</date>
<tech>IRCS Tech., rep.,</tech>
<institution>University of Pennsylvania.</institution>
<contexts>
<context position="1757" citStr="Xue et al., 2000" startWordPosition="261" endWordPosition="264">ated lexical features are sufficient to achieve comparable performance to systems using sophisticated parse trees. 1 Introduction Function tags, such as subject, object, time, location, etc. are conceptually appealing by encoding an event in the format of “who did what to whom, where, when”, which provides useful semantic information of the sentences. Lexical semantic resources such as Penn Treebank (Marcus et al., 1994) have been annotated with phrase tree structures and function tags. Figure 1 shows the parse tree with function tags for a sample sentence form the Penn Chinese Treebank 5.01 (Xue et al., 2000) (file 0043.fid). 1released by Linguistic Data Consortium (LDC) catalog NO. LDC2005T01 Figure 1: Simplified parse tree with function tags (in black bold) for example sentence. When dealing with the task of function tag assignment (or function labeling thereafter), one basic question that must be addressed is what features can be extracted in practice for distinguishing different function tag types. In answering this question, several pieces of work (Blaheta and Charniak, 2000; Blaheta, 2004; Merlo and Musillo, 2005; Gildea and Palmer, 2002) have already been proposed. (Blaheta and Charniak, 20</context>
<context position="5031" citStr="Xue et al., 2000" startWordPosition="776" endWordPosition="779">operties of the semantics that sometimes can not be concluded from the glance of parse structure. Such cases come when distinguishing phrases of the same structure that differ by just one word – for instance, telling “ M (in Shanghai)”, which is locative, from “ t� (in May)”, which is temporal. At a high level, we can say that class-based differences in function labels are reflected in statistics over the lexical features in large-scale annotated corpus, and that such knowledge can be encoded by learning algorithms. By exploiting lexical information collected from Penn Chinese Treebank (CTB) (Xue et al., 2000), we investigate a supervised sequence learning model to test our core hypothesis – that function tags could be guessed precisely through informative lexical features and effective learning methods. At the end of this paper, we extend previous function labeling methods from English to Chinese. The result proves, at least for Chinese language, our proposed method outperforms previous ones that utilize sophisticated parse trees. In section 2 we will introduce the CTB resources and function tags used in our study. In section 3, we will describe the sequence learning algorithm in the framework of </context>
<context position="6669" citStr="Xue et al., 2000" startWordPosition="1056" endWordPosition="1059">t object √ PRD predicate √ SBJ subject √ TPC topic √ adverbials BNF beneficiary √ CND condition √ DIR direction √ IJ interjective √ LGS logic subject √ LOC locative √ MNR manner √ PRP purpose/reason √ TMP temporal √ VOC vocative √ miscellaneous APP appositive HLN headline PN proper names SHORT short form TTL title WH wh-phrase gives a detailed discussion of our experiment and comparison with pieces of related work. Some final remarks will be given in Section 5. 2 Chinese Function Tags The label such as subject, object, time, location, etc. are named as function tags2 in Penn Chinese Treebank (Xue et al., 2000), a complete list of which is shown in Table 1. Among the 5 categories, grammatical roles such as SBJ, OBJ are useful in recovering predicate-argument structure, while adverbials are actually semantically oriented labels (though not true for all cases, see (Merlo and Palmer, 2006)) that carry semantic role information. As for the task of function parsing, it is reasonable to ignore the IMP and Q in Table 1 since they do not form natural syntactic or semantic classes. In addition, we regard the miscellaneous labels as an “O” label (out of any function chunks) like labeling constituents that do </context>
<context position="7949" citStr="Xue et al., 2000" startWordPosition="1268" endWordPosition="1271">e Treebank talk of function tags. We will use the term function labels and function tags identically, and hence make no distinction between function labeling and function tagging throughout this paper. Also, the term function chunk signifies a sequence of words that are decorated with the same function label. 55 tags. Punctuation marks like comma, semi-colon and period that separate sentences are also denoted as “O”. But the punctuation that appear within one sentence like double quotes are denoted with the same function labels with the content they quote. In the annotation guidelines of CTB (Xue et al., 2000), the function tag “PRD” is assigned to nonverbal predicate. Since VP (verb phrase) is always predicate, “PRD” is assumed and no function tag is attached to it. We make a slight modification to such standard by calling this kind of VP “verbal predicates”, and assigning them with function label “TAR (target verb)”, which is grouped into the same grammar roles type with “PRD”. To a large extent, PP (preposition phrase) always plays a functional role in sentence, like “PPMNR” in Figure 1. But there are many such PPs bare of any function type in CTB resources. Like in the sentence “�t-t`&apos;-fillM*ik</context>
</contexts>
<marker>Xue, Xia, Huang, Kroch, 2000</marker>
<rawString>Xue, N., Xia, F., Huang, S., Kroch, T. 2000. The Bracketing Guidelines for the Chinese Treebank. IRCS Tech., rep., University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Zhao</author>
<author>Q Zhou</author>
</authors>
<title>A SVM-based Model for Chinese Functional Chunk Parsing. In:</title>
<date>2006</date>
<booktitle>Proceedings of the Fifth SIGHAN Workshop on Chinese Language Processing,</booktitle>
<pages>94--10</pages>
<location>Sydney, Australia1.</location>
<marker>Zhao, Zhou, 2006</marker>
<rawString>Zhao, Y., Zhou, Q. 2006. A SVM-based Model for Chinese Functional Chunk Parsing. In: Proceedings of the Fifth SIGHAN Workshop on Chinese Language Processing, pages 94-10, Sydney, Australia1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Q Zhou</author>
<author>W Zhan</author>
<author>H Ren</author>
</authors>
<title>Building a Largescale Chinese Chunkbank (in Chinese). In:</title>
<date>2001</date>
<booktitle>Proceedings of the 6th Joint Conference of Computational Linguistics of China,</booktitle>
<location>Taiyuan, China.</location>
<marker>Zhou, Zhan, Ren, 2001</marker>
<rawString>Zhou, Q., Zhan, W., Ren, H. 2001. Building a Largescale Chinese Chunkbank (in Chinese). In: Proceedings of the 6th Joint Conference of Computational Linguistics of China, Taiyuan, China.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>