<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000017">
<figure confidence="0.8309319">
Book Reviews Text Coherence in Translation
TEXT COHERENCE IN TRANSLATION
Bart Papegaaij and Klaus Schubert
(BSO/Research, Utrecht)
Dordrecht: Foris Publications, 1988, 211 pp.
(Distributed language translation 3)
ISBN 90-6765-360-8, Dfl 110.- (hb); ISBN 90-6765-
361-6, Dfl 52.- (sb)
Reviewed by
Chrysanne DiMarco
</figure>
<affiliation confidence="0.468738">
University of Toronto
</affiliation>
<bodyText confidence="0.999899114754098">
Machine translation (MT) has focused on the problems
of syntax and semantics at the sentence level, but the
real goal of MT is to translate texts, a fact that has been
generally overlooked. There is a crucial difference
between a text and a set of unrelated sentences, and in
MT, one must avoid destroying the former by translat-
ing it into the latter. It is the coherence of text in
particular that Papegaaij and Schubert address. They
aim to examine the role of text phenomena in machine
translation, to assess the feasibility of a number of
suggested models of text coherence for MT, and to
propose solutions.
The book consists of three chapters: introductory
material, a chapter on the clues and devices of text
coherence, and a chapter on text coherence in transla-
tion.
The introductory chapter (11 pages) summarizes the
main approaches to text linguistics, reviews the Distrib-
uted Language Translation project (with which the
authors are associated), and introduces the relevant
terminology. Chapter 2 (139 pages) is the background
chapter for understanding the techniques that can be
used to render text coherent. It begins with a study of
the kinds of decisions involved in a sample translation,
and then surveys the maintenance of text coherence
through deictic reference, word disambiguation (by
means of a shared context), thematic progression, the
structure-building properties of verbs, and, on a higher
level, rhetorical patterns. This review of diverse devices
for text coherence is illustrated by showing how they
contribute to the coherence of a sample text. This
chapter covers essentially the same ground as Halliday
and Hasan (1976), but in less detail and with a slant to
translation.
In Chapter 3 (41 pages), the authors follow up on this
review to consider text coherence from the standpoint
of translation. A systematic summary of the coherence
devices discussed earlier is given, grouped under the
headings: coherence of entities, coherence of focus, and
coherence of events. This chapter also focuses more
explicitly on the question of how to maintain text
coherence in a MT system.
The strength (and the bulk) of the book is the quite
thorough discussion of the text coherence devices that
are relevant in MT. A reader unfamiliar with the prob-
lem of maintaining coherence in translation will receive
a useful tutorial in the possible approaches. However, it
should be noted that, as the authors themselves point
out, &amp;quot;the reader [may be] somewhat unsatisfied and
[have] a feeling of having been offered just another
series of sample analyses and just another, sketchy,
model of text structure. This may appear to be so, at
least to a casual reader. . . [However], it has . . . been
our aim to make some steps towards (preliminary)
implementation possible right now, although we are
aware of the fact that much more research of both a
fundamental and an application-oriented nature remains
to be done&amp;quot; (p. 198). The book will therefore be of
interest to readers who want an introduction to a
difficult problem in MT but who recognize that, as of
now, solutions remain preliminary and still theoretical.
</bodyText>
<sectionHeader confidence="0.891306" genericHeader="abstract">
REFERENCE
</sectionHeader>
<bodyText confidence="0.508227">
Halliday, M.A.K. and Hasan, Rugaiya 1976 Cohesion in English.
London: Longman.
</bodyText>
<construct confidence="0.588463833333333">
Chrysanne DiMarco is a doctoral student in the natural
language understanding group, University of Toronto. Her
thesis research is in stylistics in machine translation. DiMar-
co&apos;s address is: Department of Computer Science, University
of Toronto, Toronto, Ontario, Canada M5S 1A4. E-mail:
cdi@ai.toronto.edu
</construct>
<sectionHeader confidence="0.9853005" genericHeader="method">
WORD EXPERT SEMANTICS: AN INTERLINGUAL
KNOWLEDGE-BASED APPROACH
</sectionHeader>
<bodyText confidence="0.7620222">
Bart C. Papegaaij, Victor Sadler, and A.P.M. Toon
Witkam (eds.)
(BSO/Research, Utrecht)
Dordrecht: Foris Publications, 1986, ix + 254 pp.
(Distributed language translation 1)
</bodyText>
<figure confidence="0.53891025">
ISBN 90-6765-261-X, $29 / Dfl 57.- (sb); ISBN 90-
6765-262-3, $59 / Dfl 120.- (hb)
Reviewed by
Jonathan Slocum
</figure>
<subsectionHeader confidence="0.573501">
Symantec Corporation
</subsectionHeader>
<bodyText confidence="0.956856340909091">
This book describes the Dutch firm BSO&apos;s machine
translation system DLT at a very early stage in its
development. The book is organized into four parts,
each with its separate set of chapters. Part I is an
introduction to the problems of NLP in general, and MT
in particular, for the neophyte. Part II describes the
&amp;quot;Semantic Word Expert System&amp;quot; in some (not exhaus-
tive) detail, describing its workings primarily in the
future tense. Part III describes the &amp;quot;Semantic Work
Bench&amp;quot; development tool that is being developed for
development of the DLT lexicons. Part IV discusses
&amp;quot;Future Developments&amp;quot; in DLT, all the way up to
&amp;quot;The Ultimate Aim,&amp;quot; which turns out (p. 207) to be a
system for multidirectional machine translation, multi-
lingual information retrieval and document indexing,
Computational Linguistics, Volume 15, Number 3, September 1989 207
Book Reviews Word Expert Semantics: An Interlingual Knowledge-Based Approach
automatic abstracting and summarizing, and the provi-
sion of an NL interface in the language of the user&apos;s
choice. Who in the field does not share this ultimate
goal? My chief complaint is that the great bulk of the
description of DLT is in the future tense. This is not, of
course, a complaint that can be lodged against this
book/system alone.
Content Summary. Part I constitutes a review of MT
and the problem of ambiguity in NLP. Chapter 1
discusses NLP (needed for &amp;quot;user-friendly front-ends&amp;quot;)
and MT (needed to overcome the growing language
barrier), offering Bar-Hillel&apos;s famous pair of &amp;quot;pen&amp;quot;
sentences as an illustration of how computers are rigid,
while natural language is supple and complex. Chapter
2 explores lexical ambiguity—polysemy—contrasting
the &amp;quot;determinism&amp;quot; of mathematics/logic with the &amp;quot;non-
determinism&amp;quot; of natural language in order to demon-
strate the need for knowledge of the world to cope with
the creativity of language. Just how this works is never
quite explained.
Chapter 3 offers a brief historical survey of NLP,
touching upon Warren Weaver&apos;s seminal memo, word-
for-word MT (citing Oettinger), strictly-syntactic ap-
proaches (citing Chomsky, somewhat out of place),
closed worlds (Woods&apos;s LUNAR and Winograd&apos;s
SHRDLU), selection restrictions (Kelly and Stone,
Cullingford and Onyshkevych), case grammar (Fill-
</bodyText>
<listItem confidence="0.9833765">
• more), scripts and plans (Schank and Abelson), prefer-
ence semantics (Wilks), and word experts (Small).
</listItem>
<bodyText confidence="0.998652779069768">
Chapter 4 talks about MT and NL understanding today,
in terms of semantic primitives, a knowledge bank (as
opposed to a program), sublanguage and limited do-
mains, semantic networks, frames, and inferencing/
reasoning through &amp;quot;non-monotonous [sic] logic.&amp;quot;
Chapter 5 emphasizes the importance of dictionaries,
implying (falsely) that large lexicons entail a move to
word grammars stored as a lexical knowledge bank (the
natural follow-up to global syntax rules, which in turn
succeeded &amp;quot;word lists&amp;quot;). It draws a parallel between
this development and innovations in theoretical lexicog-
raphy leading to increased &amp;quot;precision and clarity.&amp;quot;
Chapter 6 laments the problem of fragmented research
brought about by concentration on mono-theoretical
approaches, and calls for a combination of strategies to
effect the integration required to solve the NLP puzzle.
Part II is entitled &amp;quot;The Semantic Word Expert
System,&amp;quot; and sets about describing the DLT system
(more accurately, proposal). Briefly characterized,
DLT is intended to provide multidirectional translation
by capturing and parsing text at creation—as the user
types it in—and engaging him/her in a multiple-choice
&amp;quot;disambiguation dialogue&amp;quot; at sentence boundaries in
order to resolve any ambiguities in the analysis. Once
the meaning of the sentence has been identified and
expressed in the interlingua, which happens to be (a
customized version of) Esperanto, translation into any
supported target language can be done fully automati-
cally, with no recourse to the writer or a translator.
Indeed., it is anticipated that a producer&apos;s text will be
disseminated in Esperanto interlingual form only, and
translated upon demand by the consumer&apos;s worksta-
tion.
Chapter 1 explains that parsing is performed by first
computing all possible syntactic analyses without refer-
ence to semantics, then filtering the analyses semanti-
cally to produce a graded list of possible interpretations
of each content word and attachment. In the disambig-
uation dialogue, the typist is queried about each ambi-
guity (with possible readings listed in decreasing order
of likelihood, according to DLT&apos;s rule base), and must
respond by identifying (by number or mouse click) the
intended reading. It explains that analysis (apparently,
including semantic filtering) is performed as one types,
so that the dialog can commence immediately upon
completing the sentence. Something (unimplemented)
called &amp;quot;macrocontext semantics&amp;quot; relates the sentence
being typed with any previous input, for anaphoric
reference and polysemy resolution: this is another name
for discourse analysis.
Chapter 2 presents &amp;quot;The Structure of the Lexical
Knowledge Bank&amp;quot;. SWESIL by name (Semantic Word
Expert System for the Intermediate Language), this is a
system with. &amp;quot;three major parts: two bi-lingual word
lists—SL-to-IL [Source Language to InterLingua] and
IL-to-TL [InterLingua to Target Language]—and the
central IL knowledge bank [in Esperanto].&amp;quot; According
to the figure caption on the same page (85), the three
parts are &amp;quot;an TL-to-IL dictionary, an IL-to-SL dictio-
nary, and the central Knowledge Bank, entirely in IL&amp;quot;
[sic]. Presumably the text governs, and the figure cap-
tion is wrong—especially since the diagram agrees with
the textual description, which also makes more sense.
But to compound the confusion, the next section,
describing the &amp;quot;SL to IL&amp;quot; module, talks about its
&amp;quot;listing TL words with their IL counterparts&amp;quot; (p. 86).
These and many other pieces of evidence (e.g., the
initial identification of the acronym SWESIL, back on
page 82, as &amp;quot;the Semantic Word Expert Module . . .&amp;quot;
[sic], or the definition of &amp;quot;bibliographical references&amp;quot;
(p. 103) as &amp;quot;names of famous . . . persons&amp;quot; [sic]) lead
one to guess that—as with texts to be composed in the
DLT system—the first draft of this book may have been
the final one. At the very least, it is unclear what role
the editors played in its composition and publication.
Later, this chapter takes pride in showing how the
Interlingua replaces multiple world models, one per
human language, with a single model based on Espe-
ranto. Lost on the writers, seemingly, is the concept
that languages might embody culturally distinct world
models, with obvious advantages to be obtained by
somewhat more direct translation between &amp;quot;similar&amp;quot;
languages—especially those somewhat removed from
Esperanto&apos;s Western European outlook. (Japanese (p.
90) is one of the &amp;quot;world model&amp;quot; host languages replaced
by Esperanto.) More charitably, and probably more
</bodyText>
<page confidence="0.921129">
208 Computational Linguistics, Volume 15, Number 3, September 1989
</page>
<note confidence="0.524302">
Book Reviews Word Expert Semantics: An Interlingual Knowledge-Based Approach
</note>
<bodyText confidence="0.998634652173913">
accurately, they are aware of this critical philosophical
issue, but fail to acknowledge it as they ought.
The next section delves into the advantages of lexical
taxonomies, which provide structure to the world model
and, through property inheritance, concision as well.
Here and elsewhere, the work of Amsler and Calzolari
is summarized and cited; some of their ideas are
adopted into SWESIL. Since most of the detail pre-
sented here is derived from these and other works, I will
not summarize it.
Chapter 3 deals with &amp;quot;Disambiguation with SWE-
SIL&amp;quot; in depth. The fact that this is the only segment of
the book that goes into really substantial detail argues
for the conclusion that this is the only functioning
component of DLT. Certainly the level of detail far
exceeds anything else in the book; so much so, indeed,
that it seems out of place. I infer that much of this
material was written very late—immediately before
publication?—since the textual errors are, if anything,
even more obvious (e.g., a number of what seem to be
references to figures appear as
Chapter 4 covers &amp;quot;The Disambiguation Dialogue.&amp;quot; It
justifies this approach to MT on the grounds that:
</bodyText>
<listItem confidence="0.986410166666667">
1. &amp;quot;[MT with pre/post-editing] would distract the
user who wants to communicate something away
[sic] from the immediate task&amp;quot; (p. 129); and
2. &amp;quot;The editor [translator?] has to consult the writer
about the correct interpretation of the text&amp;quot; (p.
130).
</listItem>
<bodyText confidence="0.981782416666667">
That interruptions for dialogue disambiguation after
each sentence, in order for DLT to consult the writer
about his intent, might also lead to considerable delays,
seems to elude the authors entirely. This, despite the
fact that they decry &amp;quot;annoying the user with frequent
interruptions that interfere with the task of writing&amp;quot; (p.
131). The remainder of the chapter, which relates the
results of some laboratory simulation experiments, ar-
gues to this reviewer that these delays are likely to be
substantial and frustrating.
In Part III, Chapter 1 opens by dismissing claims
based on small prototypes:
</bodyText>
<listItem confidence="0.997420571428571">
1. &amp;quot;There is no guarantee that the worked-out exam-
ples are representative&amp;quot;;
2. &amp;quot;A small vocabulary. . . [often allows] . . . con-
trol over all possible contexts&amp;quot;; and
3. &amp;quot;Very detailed dictionary entries . . . [in a large
system] . . . can become prohibitively expensive&amp;quot;
(pp. 144-5).
</listItem>
<bodyText confidence="0.985530865671642">
This reviewer is in full sympathy with such objec-
tions. The chapter continues by encouraging reality
checks (bravo!) using the Melby Test—which, upon
reading its description, I recognize to be an old, well-
known (if too seldom practiced) test regimen in MT
circles. But never mind. DLT&apos;s benchmark against such
a test is described in Chapter 3. Or, rather, the tiny
existing subset of SWESIL and the variation on the
Melby Test described in Chapter 2 are used to conduct
an experiment. The writers find the test results to be
(need I say it?) encouraging. As for the real test,
Chapter 4 (&amp;quot;Melby Test Results&amp;quot;) informs us that &amp;quot;the
databases and software [are] still in preparation. [Thus]
. . . no actual results of the test can be presented here&amp;quot;
(p. 191). One may be forgiven for imagining a much-
delayed delivery date due to problems not reported.
Part IV, &amp;quot;Future Developments,&amp;quot; discusses aspects
of &amp;quot;[future] Computerized Lexicography&amp;quot; (Chapter 1),
&amp;quot;[future] Macrocontext and Discourse Analysis&amp;quot;
(Chapter 2), and &amp;quot;The [future] Self-Improving System&amp;quot;
(Chapter 3). It is in Chapter 1 where &amp;quot;The Ultimate
Aim—The General-Purpose IL Knowledge Bank,&amp;quot;
which is the heart of DLT, has its possibilities laid out:
translation, information retrieval, indexing, abstracting,
summarizing, etc. In Chapter 2, discourse analysis is
revisited (cf. Part II, Chapter 1). In Chapter 3, &amp;quot;The
Self-Improving System&amp;quot; is presented. This is a full-
blown artificial intelligence that, among other things,
learns from its experience. It &amp;quot;will probably be pre-
ceded by several years of DLT operation on a large
corpus of suitable informative texts&amp;quot; (p. 219). To be
sure.
Critique. In a number of ways this book would be
useful to members of the general public interested in
learning something about NLP; about MT, which is
implied to be a focus of attention, much less is actually
said. The level of detail—except in Part II, Chapter 3,
and probably Part III, Chapter 3—is just about right.
Yet even to this audience, a number of glaring problems
make their presence known. First of all there is the
typography. This book was photo-reproduced from an
original printed on a dot-matrix printer, with fixed pitch.
Then there is the matter of filling: it was poorly done
(probably manually), with mistakes. There is no justifi-
cation. It is not an attractive package: one has to want
to read it.
Second, there are the textual problems, some of
which were commented on earlier (e.g., missing figure
[?] references). Certain errors are attributable to the fact
that the writers are apparently not native English speak-
ers; I forgive all these, as I hope they would my Dutch,
were I to attempt writing it. But typographical errors,
misspellings, and grammatical errors (frequently num-
ber agreement) abound. This is especially ironic when
one notes that the writers envisage a DLT system that
incorporates a number of text processing aids, of which
they mention spelling and grammar checkers/correc-
tors; these tools have been available on the open market
for years, and in research labs for longer. There are
references to figures that seem not to exist. These are
the kinds of problems that editors are supposed to
catch. One gathers the impression that this book was
assembled (in part from existing texts?) in a great
hurry—or at least at a time when the writers were very
much concerned with other matters. Since it would
appear that their intended audience includes NLP re-
searchers (else why all the details about disambiguation
Computational Linguistics, Volume 15, Number 3, September 1989 209
Book Reviews Knowledge Systems and Prolog: A Logical Approach to Expert Systems and Natural Language Processing
with SWESIL?), it might have been better to wait until
more care could be taken.
Although the title leads one to assume the authors
will concern themselves with &amp;quot;word experts,&amp;quot; which
usually implies lexical procedures in Small&apos;s sense (they
cite him several times), it turns out that nothing in DLT
can be construed as such. The dictionary entries are
intended to be numerous, but the authors themselves
proscribe large entries (p. 145), or even ones wherein
procedures appear (&amp;quot;There is no level of abstraction
within the LKB in which meaning can be viewed as
separate from words&amp;quot; (p. 118), and other pro-modu-
larity arguments). DLT&apos;s semantic rules seem much
more akin to Wilks&apos;s preference semantics than to
Small&apos;s word expert procedures; and syntactic parsing
in DLT, it turns out, is based on dependency grammar
(p. 105) and is quite independent of any semantic
processing.
More serious are certain scientific and technical
claims that are un(der)supported. Here, of course, one
tends to leave the realm of reviewing the book and move
on to critiquing the work behind it. As this may not be
in the purview of a book review proper, I will constrain
myself to two points. First, the &amp;quot;lexical taxonomy&amp;quot;
issue, for all the attention paid to it, is glossed over. In
particular, while the authors promote the &amp;quot;good&amp;quot; re-
sults, identification of noun and verb hierarchies,
achieved by Calzolari and Amsler, they fail to mention
the problems that Amsler, at least, brings up: the noun
hierarchies tend to attach themselves to the verb hier-
archies eventually (which seems to violate a structural
assumption built into DLT) and, worse, hierarchies
seem quite inappropriate for any other part of speech
(e.g., adjectives and adverbs).
Second, it is perhaps most unfortunate that the
writers, who discount results reported on the basis of
small prototypes (Part III, Chapter 1), are reduced to
just such claims themselves—testing but seven phrases
(p. 172) and one single sentence (p. 176) using a system
with a &amp;quot;Semantic Dictionary [that] contains some 800
headwords&amp;quot; (p. 205). True, such a vocabulary is an
order of magnitude larger than that found in most
academic AI/NLP systems; but it is still an order of
magnitude below the 10,000 that the authors themselves
think reasonable (p. 145)—which is in turn one or two
orders of magnitude below that probably required for
such uses as they anticipate for DLT, if claims like
those of Walker and Amsler (based on several months
of New York Times text) are to be believed. Regardless,
the trivial number of test cases put to SWESIL prove
absolutely nothing, notwithstanding statements like
&amp;quot;some interesting successes have already been
achieved&amp;quot; (p. 205). (I grade SWESIL at 79% on the
7-phrase test (p. 172). At least they are honest: many
AI/NLP reports neglect to mention errors at all, and
fewer yet quantify anything.)
In short, the authors are inconsistent about the
evaluation of other NLP systems against their own, and
too much of this• book talks about DLT in the future
tense (again, not problems unique to this book). It was
written too early, and apparently in too great a hurry.
For the most part, it is interesting reading for the
uninformed; there is no news for the professional. But
for this I could have liked it, whether or not I agree with
their approach.
</bodyText>
<reference confidence="0.963057285714286">
Jonathan Slocum is staff scientist at Symantec, a software
firm that includes Al applications—notably Q&amp;A, a file man-
agement system with a natural language interface—among its
offerings. Previously, Dr. Slocum directed the successful
METAL machine translation project at the University of
Texas. Slocum&apos;s address is: Symantec, 1302 Darter Lane,
Austin, TX 78746. E-mail: slocum@cs.utexas.edu
</reference>
<sectionHeader confidence="0.749352" genericHeader="method">
KNOWLEDGE SYSTEMS AND PROLOG: A LOGICAL
APPROACH TO EXPERT SYSTEMS AND NATURAL
LANGUAGE PROCESSING
</sectionHeader>
<reference confidence="0.9308855">
Adrian Walker (ed.); Michael McCord, John F. Sowa,
and Walter G. Wilson
(IBM T.J. Watson Research Center and IBM Systems
Research Institute)
Reading, MA: Addison-Wesley, corrected reprinting,
March 1987, xii + 475 pp.
ISBN 0-201-09044-9, $35.50 (hb)
Reviewed by
Stan C. Kwasny
Washington University
</reference>
<bodyText confidence="0.999968346153846">
Books written by committees—where everyone writes a
chapter--usually suffer from problems of readability,
continuity, and stylistic variations that are difficult for a
reader to overcome. Such were my expectations in
reviewing this book. To the credit of the committee that
produced it, none of these expectations were met. On
the contrary, I found this book to be among the very
best Prolog-based descriptions of expert systems, nat-
ural language processing, and knowledge systems.
The book takes a formal, logical approach to its
subject. Every opportunity is taken to demonstrate in
concise terms the relationship of Prolog with logic. Too
many Prolog textbooks fail to point out connections
with classical logic where possible. They approach
Prolog as a conventional programming language. An
important and obvious aspect of Prolog is thus missed:
that Prolog, since it is based on logic, permits relatively
easy translation from logical form to program. More-
over, given the close relationship between logical form
and program, various mixtures of declarative and pro-
cedural styles can be incorporated into problem solu-
tions. To emphasize one to the exclusion of the other
does not tell the whole story.
This book does tell the whole story, and gives the
reader a good sense of Prolog&apos;s flexibility in addressing
difficult issues across a spectrum of problems. Care-
</bodyText>
<page confidence="0.97971">
210 Computational Linguistics, Volume 15, Number 3, September 1989
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.230783">
<title confidence="0.996382">Book Reviews Text Coherence in Translation TEXT COHERENCE IN TRANSLATION</title>
<author confidence="0.997553">Bart Papegaaij</author>
<author confidence="0.997553">Klaus Schubert</author>
<note confidence="0.815882833333333">(BSO/Research, Utrecht) Dordrecht: Foris Publications, 1988, 211 pp. (Distributed language translation 3) ISBN 90-6765-360-8, Dfl 110.- (hb); ISBN 90-6765- 361-6, Dfl 52.- (sb) Reviewed by</note>
<author confidence="0.948546">Chrysanne DiMarco</author>
<affiliation confidence="0.99687">University of Toronto</affiliation>
<abstract confidence="0.994169344827586">Machine translation (MT) has focused on the problems of syntax and semantics at the sentence level, but the real goal of MT is to translate texts, a fact that has been generally overlooked. There is a crucial difference between a text and a set of unrelated sentences, and in MT, one must avoid destroying the former by translating it into the latter. It is the coherence of text in particular that Papegaaij and Schubert address. They aim to examine the role of text phenomena in machine translation, to assess the feasibility of a number of suggested models of text coherence for MT, and to propose solutions. The book consists of three chapters: introductory material, a chapter on the clues and devices of text coherence, and a chapter on text coherence in translation. The introductory chapter (11 pages) summarizes the main approaches to text linguistics, reviews the Distributed Language Translation project (with which the authors are associated), and introduces the relevant terminology. Chapter 2 (139 pages) is the background chapter for understanding the techniques that can be used to render text coherent. It begins with a study of the kinds of decisions involved in a sample translation, and then surveys the maintenance of text coherence through deictic reference, word disambiguation (by means of a shared context), thematic progression, the structure-building properties of verbs, and, on a higher level, rhetorical patterns. This review of diverse devices for text coherence is illustrated by showing how they contribute to the coherence of a sample text. This chapter covers essentially the same ground as Halliday and Hasan (1976), but in less detail and with a slant to translation. In Chapter 3 (41 pages), the authors follow up on this review to consider text coherence from the standpoint of translation. A systematic summary of the coherence devices discussed earlier is given, grouped under the headings: coherence of entities, coherence of focus, and coherence of events. This chapter also focuses more explicitly on the question of how to maintain text coherence in a MT system. The strength (and the bulk) of the book is the quite thorough discussion of the text coherence devices that are relevant in MT. A reader unfamiliar with the probof maintaining coherence in translation receive useful tutorial in the possible approaches. it be noted that, as the authors themselves &amp;quot;the reader [may be] somewhat unsatisfied a feeling of having been offered just series of sample analyses and just another, sketchy, of text structure. This may appear to be at to a casual reader. . . [However], it has . . . our aim to make some steps towards (preliminary) possible right now, although we of the fact that much more research of both fundamental and an application-oriented nature remains be done&amp;quot; (p. 198). The book will therefore be</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>Jonathan</author>
</authors>
<title>Slocum is staff scientist at Symantec, a software firm that includes Al applications—notably Q&amp;A, a file management system with a natural language interface—among its offerings. Previously, Dr. Slocum directed the successful METAL machine translation project at the University of Texas. Slocum&apos;s address is: Symantec,</title>
<pages>78746</pages>
<location>1302 Darter Lane, Austin, TX</location>
<note>E-mail: slocum@cs.utexas.edu</note>
<marker>Jonathan, </marker>
<rawString>Jonathan Slocum is staff scientist at Symantec, a software firm that includes Al applications—notably Q&amp;A, a file management system with a natural language interface—among its offerings. Previously, Dr. Slocum directed the successful METAL machine translation project at the University of Texas. Slocum&apos;s address is: Symantec, 1302 Darter Lane, Austin, TX 78746. E-mail: slocum@cs.utexas.edu</rawString>
</citation>
<citation valid="false">
<authors>
<author>Michael McCord</author>
<author>John F Sowa</author>
<author>G Walter</author>
</authors>
<booktitle>Research Center and IBM Systems Research Institute</booktitle>
<editor>Wilson (IBM T.J. Watson</editor>
<marker>McCord, Sowa, Walter, </marker>
<rawString>Adrian Walker (ed.); Michael McCord, John F. Sowa, and Walter G. Wilson (IBM T.J. Watson Research Center and IBM Systems Research Institute)</rawString>
</citation>
<citation valid="true">
<authors>
<author>MA Reading</author>
</authors>
<title>Addison-Wesley, corrected reprinting,</title>
<date>1987</date>
<journal>xii +</journal>
<volume>475</volume>
<pages>pp.</pages>
<marker>Reading, 1987</marker>
<rawString>Reading, MA: Addison-Wesley, corrected reprinting, March 1987, xii + 475 pp.</rawString>
</citation>
<citation valid="false">
<authors>
<author>ISBN</author>
</authors>
<title>35.50 (hb) Reviewed by Stan C.</title>
<publisher>Kwasny</publisher>
<marker>ISBN, </marker>
<rawString>ISBN 0-201-09044-9, $35.50 (hb) Reviewed by Stan C. Kwasny</rawString>
</citation>
<citation valid="false">
<institution>Washington University</institution>
<marker></marker>
<rawString>Washington University</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>