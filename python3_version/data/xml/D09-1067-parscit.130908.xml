<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000156">
<title confidence="0.8718895">
Improving Verb Clustering with Automatically Acquired Selectional
Preferences
</title>
<author confidence="0.987848">
Lin Sun and Anna Korhonen
</author>
<affiliation confidence="0.998633">
University of Cambridge, Computer Laboratory
</affiliation>
<address confidence="0.815945">
15 JJ Thomson Avenue, Cambridge CB3 0GD, UK
</address>
<email confidence="0.995616">
ls418,alk23@cl.cam.ac.uk
</email>
<sectionHeader confidence="0.994699" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999866277777778">
In previous research in automatic verb
classification, syntactic features have
proved the most useful features, although
manual classifications rely heavily on se-
mantic features. We show, in contrast
with previous work, that considerable ad-
ditional improvement can be obtained by
using semantic features in automatic clas-
sification: verb selectional preferences ac-
quired from corpus data using a fully unsu-
pervised method. We report these promis-
ing results using a new framework for
verb clustering which incorporates a re-
cent subcategorization acquisition system,
rich syntactic-semantic feature sets, and
a variation of spectral clustering which
performs particularly well in high dimen-
sional feature space.
</bodyText>
<sectionHeader confidence="0.998784" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99967975">
Verb classifications have attracted a great deal
of interest in natural language processing (NLP).
They have proved useful for various important
NLP tasks and applications, including e.g. parsing,
word sense disambiguation, semantic role label-
ing, information extraction, question-answering,
and machine translation (Swier and Stevenson,
2004; Dang, 2004; Shi and Mihalcea, 2005; Za-
pirain et al., 2008).
Verb classes are useful because they offer a
powerful tool for generalization and abstraction
which can be beneficial when faced e.g. with the
problem of data sparsity. Particularly useful can
be classes which capture generalizations over a
range of (cross-)linguistic properties, such as the
ones proposed by Levin (1993). Being defined in
terms of similar meaning and (morpho-)syntactic
behaviour of words, Levin style classes gener-
ally incorporate a wider range of properties than
e.g. classes defined solely on semantic grounds
(Miller, 1995).
In recent years, a variety of approaches have
been proposed for automatic induction of verb
classes from corpus data (Schulte im Walde, 2006;
Joanis et al., 2008; Sun et al., 2008; Li and Brew,
2008; Korhonen et al., 2008; O´ S´eaghdha and
Copestake, 2008; Vlachos et al., 2009). This work
opens up the opportunity of learning and tuning
classifications tailored to the application and do-
main in question. Although manual classification
may always yields higher accuracy, automatic verb
classification is cost-effective and gathers statisti-
cal information as a side-effect of the acquisition
process which is difficult for humans to gather but
can be highly useful for NLP applications.
To date, both supervised and unsupervised ma-
chine learning (ML) methods have been proposed
for verb classification and used to classify a vari-
ety of features extracted from raw, tagged and/or
parsed corpus data. The best performing features
on cross-domain verb classification have been syn-
tactic in nature (e.g. syntactic slots, subcategoriza-
tion frames (SCFs)). Disappointingly, semantic
features have not yielded significant additional im-
provement, although they play a key role in man-
ual and theoretical work on verb classification and
could thus be expected to offer a considerable con-
tribution to classification performance.
Since the accuracy of automatic verb classifi-
cation shows room for improvement, we further
investigate the potential of semantic features –
verb selectional preferences (SPs) – for the task.
We introduce a novel approach to verb cluster-
ing which involves the use of (i) a recent subcate-
gorization frame (SCF) acquisition system (Preiss
et al., 2007) which produces rich lexical, SCF and
syntactic data, (ii) novel syntactic-semantic fea-
ture sets extracted from this data which incorpo-
rate a variety of linguistic information, including
SPs, and (iii) a new variation of spectral cluster-
</bodyText>
<page confidence="0.968452">
638
</page>
<note confidence="0.996611">
Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 638–647,
Singapore, 6-7 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.999813">
ing based on the MNCut algorithm (Meila and Shi,
2001) which is well-suited for dealing with the re-
sulting, high dimensional feature space.
Using this approach, we show on two well-
established test sets that automatically acquired
SPs can be highly useful for verb clustering. They
yield high performance when used in combination
with syntactic features. We obtain our promis-
ing results using a fully unsupervised approach
to SP acquisition which differs from previous
approaches in that it does not exploit WordNet
(Miller, 1995) or other lexical resources. It is
based on clustering argument head data in the
grammatical relations associated with verbs.
We describe our features in section 2 and the
clustering methods in section 3. Experimental
evaluation and results are reported in sections 4
and 5, respectively. Section 6 provides discus-
sion and describes related work, and section 7 con-
cludes.
</bodyText>
<sectionHeader confidence="0.998989" genericHeader="introduction">
2 Features
</sectionHeader>
<bodyText confidence="0.999920392857143">
Our target classification is the taxonomy of Levin
(1993) where verbs taking similar diathesis al-
ternations are assumed to share meaning compo-
nents and are organized into semantically coherent
classes. The main feature of this classification is a
diathesis alternation which manifests at the level
of syntax in alternating sets of SCF (e.g. in the
causative/inchoative alternation an NP frame alter-
nates with an intransitive frame: Tony broke the
window ↔ The window broke).
Since automatic detection of diathesis alterna-
tions is very challenging (McCarthy, 2001), most
work on automatic classification has exploited the
fact that similar alternations tend to result in sim-
ilar SCFs. The research reported so far1 has used
mainly syntactic features for classification, rang-
ing from shallow syntactic slots (e.g. NPs preced-
ing or following the verb) to SCFs. Some re-
searchers have discovered that supplementing ba-
sic syntactic features with information about ad-
juncts, co-occurrences, tense, and/or voice of the
verb have resulted in better performance.
However, additional information about seman-
tic SPs of verbs has not yielded considerable im-
provement on verb classification although SPs can
be strong indicators of diathesis alternations (Mc-
Carthy, 2001) and although fairly precise semantic
descriptions, including information about verb se-
</bodyText>
<footnote confidence="0.530081">
1See section 6 for discussion on previous work.
</footnote>
<bodyText confidence="0.999802352941177">
lectional restrictions, can be assigned to the major-
ity of Levin classes, as demonstrated by VerbNet
(Kipper-Schuler, 2005).
SP acquisition from undisambiguated corpus
data is arguably challenging (Brockmann and La-
pata, 2003; Erk, 2007; Bergsma et al., 2008). It is
especially challenging in the context of verb clas-
sification where SP models are needed for specific
syntactic slots for which the data may be sparse,
and the resulting feature vectors integrating both
syntactic and semantic features may be high di-
mensional. However, we wanted to investigate
whether better results could be obtained if the fea-
tures were optimised for richness, the feature ex-
traction for accuracy, and a clustering method ca-
pable of dealing with the resulting high dimen-
sional feature space was employed.
</bodyText>
<subsectionHeader confidence="0.989637">
2.1 Feature extraction
</subsectionHeader>
<bodyText confidence="0.999991928571428">
We adopted a recent SCF acquisition system which
has proved more accurate than previous compa-
rable systems2 but which has not been employed
for verb clustering before: the system of Preiss
et al. (2007). This system tags, lemmatizes and
parses corpus data using the current version of the
RASP (Robust Accurate Statistical Parsing) toolkit
(Briscoe et al., 2006), and on the basis of resulting
grammatical relations (GRs) assigns each occur-
rence of a verb to one of 168 verbal SCFs classes3.
The system provides a filter which can be used
to remove adjuncts from the resulting lexicon.
We do not employ this filter since adjuncts have
proved informative for verb classification (Sun
et al., 2008; Joanis et al., 2008). However, we
do frequency-based thresholding to minimise the
noise (e.g. erroneous scfs) and sparse data in verb
classification and to ensure that only features sup-
ported by several verbs are used in classification:
we only consider SCFs and GRs which have fre-
quency larger than 40 with 5 or more verbs4.
The system produces a rich lexicon which in-
cludes raw and processed input sentences and pro-
vides a variety of material for verb clustering, in-
cluding e.g. (statistical) information related to the
part-of-speech (POS) tags, GRs, SCFs, argument
heads, and adjuncts of verbs. Using this mate-
rial, we constructed a wide range of feature sets
</bodyText>
<footnote confidence="0.9826036">
2See Preiss et al. (2007) for the details of evaluation.
3We used an implementation of the SCF classifier pro-
vided by Paula Buttery.
4These and other threshold values mentioned in this paper
were determined empirically on corpus data.
</footnote>
<page confidence="0.998611">
639
</page>
<bodyText confidence="0.998867714285714">
for experimentation, both shallow and deep syn-
tactic and semantic features. As described below,
some of the feature types have been employed in
previous works and some are novel.
F8: Basic SCF feature corresponding to F4 but ex-
tracted from the VALEX lexicon (Korhonen
et al., 2006)5.
</bodyText>
<subsectionHeader confidence="0.999552">
2.2 Feature sets
</subsectionHeader>
<bodyText confidence="0.99624525">
The first feature set F1 includes information
about the lexical context (co-occurrences) of verbs
which has proved useful for supervised verb clas-
sification (Li and Brew, 2008):
</bodyText>
<listItem confidence="0.9942165">
F1: Co-occurrence (CO): We adopt the best
method of Li and Brew (2008) where collo-
cations are extracted from the four words im-
mediately preceding and following a lemma-
tized verb. Stop words are removed prior to
extraction, and the 600 most frequent result-
ing COs are kept.
F2-F3 provide information about lexical prefer-
ences of verbs in argument head positions of spe-
cific GRs associated with the verb:
F2: Prepositional preference (PP): the type and
frequency of prepositions in the indirect ob-
ject relation.
F3: Lexical preference (LP): the type and fre-
quency of nouns and prepositions in the sub-
ject, object, and indirect object relation.
</listItem>
<bodyText confidence="0.989383428571429">
All the other feature sets include information
about SCFs which have been widely employed in
verb classification, e.g. (Schulte im Walde, 2006;
Sun et al., 2008; Li and Brew, 2008; Korhonen
et al., 2008). F4-F7 include basic SCF information
and/or refine it with additional information which
has proved useful in previous works:
</bodyText>
<listItem confidence="0.872910777777778">
F4: SCFs and relative frequencies with verbs.
SCFs abstract over particles and prepositions.
F5: F4 with COs (F1). The SCF and CO feature
vectors are concatenated.
F6: F4 with the tense of the verb. The frequency
of verbal POS tags is calculated specific to
each SCF.
F7: F4 with PPs (F2). This feature parameterizes
SCFs for prepositions.
</listItem>
<bodyText confidence="0.914949444444444">
The following 9 feature sets are novel. They
build on F7, refining it further. F9-F11 refine F7
with information about LPs:
F9: F7 with F3 (subject only)
F10: F7 with F3 (object only)
F11: F7 with F3 (subject, object, indirect object)
F12-17 refine F7 with SPs. We adopt a fully un-
supervised approach to SP acquisition. We acquire
the SPs by
</bodyText>
<listItem confidence="0.746303777777778">
1. taking the GR relations (subject, object, indi-
rect object) associated with verbs,
2. extracting all the argument heads in these re-
lations which occur with frequency &gt; 20 with
more than 3 verbs, and
3. clustering the resulting N most frequent ar-
gument heads into M classes using the spec-
tral clustering method described in the fol-
lowing section.
</listItem>
<bodyText confidence="0.940096894736842">
We tried the N settings {200, 500} and the M
settings {10, 20, 30, 80}. The best settings N =
200, M = 20 and N = 500, M = 30 are reported
in this paper. We enforce the features to be shared
by all the potential members of a verb class. The
expected class size is approximately N/K, and we
allow for 10% outliers (the features occurring less
than (N/K) x 0.9 verbs are thus removed).
The resulting SPs are combined with SCFs in a
similar fashion as LPs are combined with SCFs in
F9-F11:
F12-F14: as F9-F11 but SPs (20 clusters from 200
argument heads) are used instead of LPs
F15-F17: as F9-F11 but SPs (30 clusters from 500
argument heads) are used instead of LPs
5This feature was included to enable comparing the con-
tribution of the recent SCF system to that of an older, com-
parable system which was used for constructing the VALEX
lexicon.
</bodyText>
<page confidence="0.995836">
640
</page>
<sectionHeader confidence="0.999499" genericHeader="method">
3 Clustering methods
</sectionHeader>
<bodyText confidence="0.999882081081081">
We use two clustering methods: (i) pairwise clus-
tering (PC) which obtained the best performance
in comparison with several other methods in re-
cent work on biomedical verb clustering (Korho-
nen et al., 2008), and (ii) a method which is
new to the task (and to the best of our knowl-
edge, to NLP): a variation of spectral clustering
which exploits the MNCut algorithm (Meila and
Shi, 2001) (SPEC). Spectral clustering has been
shown to be effective for high dimensional and
non-convex data in NLP (Chen et al., 2006) and
it has been applied to German verb clustering by
Brew and Schulte im Walde (2002). However, pre-
vious work has used Ng et al. (2002)’s algorithm,
while we adopt the MNCut algorithm. The lat-
ter has shown a wider applicability (von Luxburg,
2007; Verma and Meila, 2003) and it can be justi-
fied from the random walk view, which has a clear
probabilistic interpretation.
Clustering groups a given set of items (verbs in
our experiment) V = {vn}Nn=1 into a disjoint par-
tition of K classes I = {Ik}Kk=1. Both our algo-
rithms take a similarity matrix as input. We con-
struct this from the skew divergence (Lee, 2001).
The skew divergence between two feature vectors
v and v&apos; is dskew(v, v&apos;) = D(v&apos;||a·v +(1−a)·v&apos;)
where D is the KL-divergence. v is smoothed
with v&apos;. The level of smoothing is controlled by
a whose value is set to a value close to 1 (e.g.
0.9999). We symmetrize the skew divergence
as follows: d(v, v&apos;)sskew = 12(dskew(v, v&apos;) +
dskew(v&apos;,v)).
SPEC is typically used with the Radial Basis
Function (RBF) kernel. We adopt a new kernel
similar to the symmetrized KL divergence kernel
(Moreno et al., 2004) which avoids the need for
scale parameter estimation.
</bodyText>
<equation confidence="0.669262">
w(v, v&apos;) = exp(−dsskew(v, v&apos;))
</equation>
<bodyText confidence="0.7041825">
The similarity matrix W is constructed where
Wij = w(vi, vj).
</bodyText>
<subsectionHeader confidence="0.859278">
Pairwise clustering
</subsectionHeader>
<bodyText confidence="0.99976675">
PC (Puzicha et al., 2000) is a method where a cost
criterion guides the search for a suitable partition.
This criterion is realized through a cost function of
the similarity matrix W and partition I:
</bodyText>
<equation confidence="0.997705666666667">
H = − E�n-+j · Avgsimj,
L{a,b∈Aj} w(a,b)
Avgsimj = nj·(nj−1)
</equation>
<bodyText confidence="0.9989245">
where nj is the size of the jth cluster and Avgsimj
is the average similarity between cluster members.
</bodyText>
<subsectionHeader confidence="0.934671">
Spectral clustering
</subsectionHeader>
<bodyText confidence="0.999725625">
In SPEC, the similarities Wij are viewed as the
weight on the edges ij of a graph G over V . The
similarity matrix W is thus the adjacency matrix
for G. The degree of a vertex i is di = EN j=1 wij.
A cut between two partitions A and A&apos; is defined
to be Cut(A, A&apos;) = EmEA,nEA&apos; Wmn.
In MNCut algorithm, the similarity matrix W is
transformed to a stochastic matrix P.
</bodyText>
<equation confidence="0.999889">
P = D−1W (1)
</equation>
<bodyText confidence="0.983299857142857">
The degree matrix D is a diagonal matrix where
Dii = di.
It was shown by Meila and Shi (2001) that if P
has the K leading eigenvectors that are piecewise
constant6 with respect to a partition I* and their
eigenvalues are not zero, then I* minimizes the
multiway normalized cut(MNCut):
</bodyText>
<equation confidence="0.973003">
MNCut (I) = K − K Cut(Ik,Ik)
( ) �k=1 Cut(Ik,I)
</equation>
<bodyText confidence="0.999375">
Pmn can be interpreted as the transition probabil-
ity between vertices m, n. The criterion can thus
be expressed as MNCut(I) = EKk=1(1 − P(Ik →
Ik|Ik)) (Meila, 2001), which is the sum of transi-
tion probabilities across different clusters. The cri-
terion finds the partition where the random walks
are most likely to happen within the same cluster.
In practice, the K leading eigenvectors of P is
not piecewise constant. But we can extract the
partition by finding the approximately equal ele-
ments in the eigenvectors using a clustering algo-
rithm like K-means.
The numerator of MNCut is similar to the cost
function of PC. The main differences between the
two algorithms are: 1) MNCut takes into account
of the cross cluster similarity, while PC does not.
2) PC optimizes the cost function using determin-
istic annealing, whereas SPEC uses eigensystem
decomposition.
The spectral clustering algorithm is based on the
Multicut algorithm (Meila and Shi, 2001).
</bodyText>
<construct confidence="0.38537">
6The eigenvector v is piecewise constant with respect to I
if v(i) = v(j)∀i, j ∈ Ik and k ∈ 1, 2...K
</construct>
<page confidence="0.991255">
641
</page>
<listItem confidence="0.925745">
Input: Dataset S, Number of clusters K
1. Compute similarity matrix W and Degree ma-
trix D
2. Construct stochastic matrix P using equation
1
3. Compute the eigenvalues and eigenvectors
{λn, xn}Nn=1 of P, where λn ≥ λn+1, form a
matrix X = [x2,. . . , xk] by stacking the eigen-
vectors in columns.
4. Form a matrix Y from X by normalizing the
2
row sums to have norm 1: Yij = Xij/(�j X2 ij)1
5. Consider the row of Y to be the transformed
feature vectors for each verb and cluster them
into clusters C1 ... Ck using K-means clustering
algorithm.
Output: Clusters C1 ... Ck
</listItem>
<sectionHeader confidence="0.993402" genericHeader="method">
4 Experimental evaluation
</sectionHeader>
<subsectionHeader confidence="0.998823">
4.1 Test sets
</subsectionHeader>
<bodyText confidence="0.993208333333333">
We employed two test sets which have been used
to evaluate previous work on English verb classi-
fication:
T1 The test set of Joanis et al. (2008) provides
a classification of 835 verbs into 15 (some
coarse, some fine-grained) Levin classes. 11
tests are provided for 2-14 way classifica-
tions. We employ the 14 way classifica-
tion because this corresponds the closest to
our target (Levin’s fine-grained) classifica-
tion7. We select 586 verbs according to Joa-
nis et al.’s selection criteria, resulting in 10-
120 verbs per class. We restrict the class
imbalance to 1:1.5.8. This yields 205 verbs
(10-15 verbs per class) which is similar to
the sub-set of T1 employed by Stevenson and
Joanis (2003).
T2 The test set of Sun et al. (2008) classifies 204
verbs to 17 fine-grained Levin classes, so that
each class has 12 member verbs.
Table 1 shows the classes in T1 and T2.
</bodyText>
<subsectionHeader confidence="0.994527">
4.2 Data processing
</subsectionHeader>
<bodyText confidence="0.989157333333333">
For each verb in T1 and T2, we extracted all
the occurrences (up to 10,000) from the raw cor-
pus data gathered originally for constructing the
7However, the correspondence is not perfect with half
of the classes including two or more Levin’s fine-grained
classes.
8Otherwise, in the case of a large class imbalance the eval-
uation measure would be dominated by the classes with large
population.
</bodyText>
<table confidence="0.999698272727273">
T1 T2
Object Drop 26.{1,3,7} Remove 10.1
Recipient 13.{1,3} Send 11.1
Admire 31.2 Get 13.5.1
Amuse 31.1 Hit 18.1
Run 51.3.2 Amalgamate 22.2
Sound 43.2 Characterize 29.2
Light &amp; 43.{1,4} Peer 30.3
Substance 10.6 Amuse 31.1
Cheat 10.{5,1} Correspond 36.1
Steal 10.4.{1,2} Manner 37.3
Remove 9.7 of speaking 37.7
Wipe 9.8 Say 40.2
Spray / Load 9.1-6 Nonverbal 43.1
Fill 45.1-4 expression 45.4
Putting Light 47.3
Change of State Other change 51.3.2
of state 9.1
Mode with
Motion
Run
Put
</table>
<tableCaption confidence="0.993039">
Table 1: Levin classes in T1 and T2
</tableCaption>
<table confidence="0.999857894736842">
T1 T2
total avg total avg
CO F1 1328 764 743 382
LP (p) F2 61 37 55 25
LP (all) F3 2521 526 1481 295
SCF F4 88 46 86 38
SCF+CO F5 1466 833 856 422
SCF+POS F6 319 114 299 87
SCF+P F7 282 96 273 76
SCF (V) F8 - - 92 45
SCF+LP(s) F9 1747 324 1474 225
SCF+LP (o) F10 2817 424 2319 279
SCF+LP (all) F11 4250 649 3515 426
SCF+SP20 (s) F12 821 235 690 145
SCF+SP20(o) F13 792 218 706 135
SCF+SP20(all) F14 1333 357 1200 231
SCF+SP30 (s) F15 977 274 903 202
SCF+SP30(o) F16 1026 273 1012 205
SCF+SP30(all) F17 1720 451 1640 330
</table>
<tableCaption confidence="0.991364">
Table 2: (i) The total number of features and (ii)
</tableCaption>
<bodyText confidence="0.9910824375">
the average per verb for all the feature sets
VALEX lexicon (Korhonen et al., 2006). The data
was gathered from five corpora, including e.g. the
British National Corpus (Leech, 1992) and the
North American News Text Corpus (Graff, 1995).
The average frequency of verbs in T1 was 1448
and T2 2166, showing that T1 is a more sparse
data set.
The data was first processed using the feature
extraction module. Table 2 shows (i) the total
number of features in each feature set and (ii) the
average per verb in the resulting lexicons for T1
and T2.
We normalized the feature vectors by the sum
of the feature values before applying the clustering
techniques. Since both clustering algorithms have
</bodyText>
<page confidence="0.993486">
642
</page>
<bodyText confidence="0.9999772">
an element of randomness, we run them multiple
times. The step 5 of SPEC (K-means) was run for
50 times. The result that minimizes the distortion
(the distances to cluster centroid) is reported. PC
was run 20 times, and the results are averaged.
</bodyText>
<subsectionHeader confidence="0.997034">
4.3 Evaluation measures
</subsectionHeader>
<bodyText confidence="0.9999775">
To facilitate meaningful comparisons, we em-
ploy the same measures for evaluation as previ-
ously employed e.g. by Korhonen et al. (2008); O´
S´eaghdha and Copestake (2008).
The first measure is modified purity (mPUR) –
a global measure which evaluates the mean preci-
sion of clusters. Each cluster is associated with its
prevalent class. The number of verbs in a cluster
K that take this class is denoted by nprevalent(K).
Verbs that do not take it are considered as errors.
Clusters where nprevalent(K) = 1 are disregarded
as not to introduce a bias towards singletons:
</bodyText>
<equation confidence="0.982876">
mPUR = Enprevalent(ki)&gt;2 nprevalent(ki)
</equation>
<bodyText confidence="0.9470025">
number of verbs
The second measure is weighted class accuracy
(ACC): the proportion of members of dominant
clusters DOM-CLUSTi within all classes ci.
</bodyText>
<equation confidence="0.982625333333333">
EC
i=1 verbs in DOM-CLUSTi
ACC =
</equation>
<bodyText confidence="0.67164">
number of verbs
mPUR and ACC can be seen as a measure of pre-
cision(P) and recall(R) respectively. We calculate
F measure as the harmonic mean of P and R:
</bodyText>
<equation confidence="0.9894628">
2 · mPUR · ACC
F =
mPUR + ACC
The random baseline(BL) is calculated as follows:
BL = 1/number of classes
</equation>
<sectionHeader confidence="0.999954" genericHeader="evaluation">
5 Results
</sectionHeader>
<subsectionHeader confidence="0.999726">
5.1 Quantitative evaluation
</subsectionHeader>
<bodyText confidence="0.999960285714286">
Table 3 includes the F-measure results for all the
feature sets when the two methods (PC and SPEC)
are used to cluster verbs in the test sets T1 and T2,
respectively. A number of tendencies can be ob-
served in the results. Firstly, the results for T2 are
clearly better than those for T1. Including a higher
number of verbs lower in frequency from classes
of variable granularity, T1 is probably a more chal-
lenging test set than T2. T2 is controlled for the
number and frequency of verbs to facilitate cross-
class comparisons. While this may contribute to
better results, T2 is a more accurate test set for us
in the sense that it offers a better correspondence
with our target (fine-grained Levin) classes.
</bodyText>
<table confidence="0.9992913">
T1 T2
PC SPEC PC SPEC
BL 7.14 7.14 5.88 5.88
CO F1 15.62 33.85 17.86 40.94
LP (p) F2 40.40 38.97 50.98 49.02
LP (all) F3 42.94 47.50 41.08 74.55
SCF F4 34.22 36.16 52.33 57.78
SCF+CO F5 26.43 28.70 19.52 29.10
SCF+POS F6 36.14 34.75 44.44 46.70
SCF+P F7 43.57 43.85 63.40 63.28
SCF (V) F8 - - 34.08 38.30
SCF+LP (s) F9 47.72 56.09 65.94 71.65
SCF+LP (o) F10 43.09 48.43 57.11 73.97
SCF+LP (all) F11 45.87 54.63 56.30 72.97
SCF+SP20 (s) F12 46.67 57.75 39.52 71.67
SCF+SP20 (o) F13 44.95 51.70 40.76 70.78
SCF+SP20(all) F14 48.19 55.12 39.68 73.09
SCF+SP30 (s) F15 45.89 56.10 64.44 80.35
SCF+SP30 (o) F16 42.01 48.74 52.75 70.52
SCF+SP30(all) F17 46.66 52.68 51.07 68.67
</table>
<tableCaption confidence="0.999962">
Table 3: Results on testsets T1 and T2
</tableCaption>
<bodyText confidence="0.999919411764706">
Secondly, the difference between the two clus-
tering methods is clear: the new SPEC outperforms
PC on both test sets and across all the feature sets.
The performance of the two methods is still fairly
similar with the more basic, less sparse feature sets
(F1-F2, F4, F6-7) but when the more sophisticated
feature sets are used (F3, F5, F9-F17) SPEC per-
forms considerably better. This demonstrates that
it is clearly a better suited method for high dimen-
sional feature sets.
Comparing the feature sets, the simple co-
occurrence based F1 performs clearly better than
the random baseline. F2 and F3 which exploit lex-
ical data in the argument head positions of GRs
prove significantly better than F1. F3 yields sur-
prisingly good results on T2: it is the second best
feature set on this test set. Also on T1, F3 per-
forms better than the SCF-based feature sets F4-
F7. This demonstrates the usefulness of lexical
data when obtained from argument positions in
relevant GRs.
Our basic SCF feature set F4 performs consid-
erably better than the comparable feature set F8
obtained from the VALEX lexicon. The difference
is 19.50 in F-measure. As both lexicons were ex-
tracted from the same corpus data, the improve-
ment can be attributed to improved parser and SCF
acquisition performance (Preiss et al., 2007).
F5-F7 refine the basic SCF feature set F4 fur-
ther. F5 which combines a SCF with CO in-
formation proved the best feature set in the su-
pervised verb classification experiment of Li and
Brew (2008). In our experiment, F5 produces sub-
stantially lower result than CO and SCF alone (i.e.
</bodyText>
<page confidence="0.998587">
643
</page>
<bodyText confidence="0.999963531914894">
F1 and F4). However, our corpus is smaller (Li
and Brew used the large Gigaword corpus), our
SCFs are different, and our approach is unsuper-
vised, making meaningful comparisons difficult.
F6 combines F4 with information about verb
tense. This was not helpful: F6 produces worse re-
sults than F4. F7, on the other hand, yields better
results than F4 on both test sets. This demonstrates
what the previous research has shown: SCF per-
form better when parameterized for prepositions.
Looking at our novel feature sets F9-F17, F9-
F11 combine the most accurate SCF feature set
F4 with the LP-based features F2-F3. Although
the feature space gets more sparse, all the feature
sets outperform F2-F3 on T1. On T2, F3 per-
forms exceptionally well, and thus yields a better
result than F9-F11, but F9-F11 nevertheless per-
form clearly better than the best SCF-based feature
set F4 alone. The differences among F9, F10 and
F11 are small on T2, but on T1 F9 yields the best
performance. It could be that F9 works the best
for the more sparse T1 because it suffers the least
from data sparsity (it uses LPs only for the subject
relation).
F12-F17 replace the LPs in F9-F11 by semantic
SPs. When only 20 clusters are used as SP models
and acquired from the smaller sample of (200) ar-
gument heads (F12-F14), SPs do not perform bet-
ter than LPs on T2. A small improvement can be
observed on T1, especially with F12 which uses
only the subject data (yielding the best F measure
on T1: 57.75%). However, when 30 more fine-
grained clusters are acquired from a bigger sample
of (500) argument heads (F15-F17), lower results
can be seen on T1. On T2, on the other hand, F15
yields dramatic improvement and we get the best
performance for this test set: 80.35% F-measure.
The fact that no improvement is observed when
using F16 and F17 on T2 could be explained by
the fact that SPs are stronger for the subject posi-
tion which also suffers less from the sparse data
problem than e.g. i. object position. The fact that
no improvement is observed on T1 is likely to be
due to the fact that verbs have strong SPs only at
the finer-grained level of Levin classification. Re-
call that in T1, as many as half of the classes are
coarser-grained.
</bodyText>
<subsectionHeader confidence="0.999526">
5.2 Qualitative evaluation
</subsectionHeader>
<bodyText confidence="0.993983">
The best performing feature sets on both T1 and
T2 were thus our new SP-based feature sets. We
conducted qualitative analysis of the best 30 SP
</bodyText>
<table confidence="0.9926757">
Human mother, wife, parent, girl, child
Role patient, student, user, worker, teacher
Body-part neck, shoulder, back, knee, corner
Authority committee, police, court, council, board
Organization society, firm, union, bank, institution
Money cash, currency, pound, dollar, fund
Amount proportion, value, size, speed, degree
Time minute, moment, night, hour, year
Path street, track, road, stair, route
Building office, shop, hotel, hospital, house
Region site, field, area, land, island
Technology system, model, facility, engine, machine
Task operation, test, study, analysis, duty
Arrangement agreement, policy, term, rule, procedure
Matter aspect, subject, issue, question, case
Problem difficulty, challenge, loss, pressure, fear
Idea argument, concept, idea, theory, belief
Power control, lead, influence, confidence, ability
Form colour, style, pattern, shape, design
Item letter, book, goods, flower, card
</table>
<tableCaption confidence="0.8677335">
Table 4: Cluster analysis: 20 clusters, their SP la-
bels, and prototypical member nouns
</tableCaption>
<bodyText confidence="0.99975490625">
clusters in the T2 data created using SPEC to find
out whether these clusters were really semantic in
nature, i.e. captured semantically meaningful pref-
erences. As no gold standard specific to our verb
classification task was available, we did manual
cluster analysis using VerbNet (VN) as aid. In VN,
Levin classes are assigned with semantic descrip-
tions: the arguments of SCFs involved in diathesis
alternations are labeled with thematic roles some
of which are labeled with selectional restrictions.
From the 30 thematic role types in VN, as many
as 20 are associated with the 17 Levin classes in
T2. The most frequent role in T2 is agent, fol-
lowed by theme, location, patient, recipient, and
source. From the 36 possible selectional restric-
tion types, 7 appear in T2; the most frequent ones
being +animate and +organization, followed by
+concrete, +location, and +communication.
As SP clusters capture selectional preferences
rather than restrictions, we examined manu-
ally whether the 30 clusters (i) capture seman-
tically meaningful classes, and whether they (ii)
are plausible given the VN semantic descrip-
tions/restrictions for the classes in T2.
The analysis revealed that all the 30 clusters had
a predominant, semantically motivated SP sup-
ported by the majority of the member nouns. Al-
though many clusters could be further divided into
more specific SPs (and despite the fact that some
nouns were clearly misclassified), we were able to
assign each cluster a descriptive label characteriz-
ing the predominant SP. Table 4 shows 15 sam-
</bodyText>
<page confidence="0.997726">
644
</page>
<bodyText confidence="0.999925314285714">
ple clusters, the SP labels assigned to them, and a
number of example nouns in these clusters.
When comparing each SP cluster against the
VN semantic descriptions/restrictions for T2, we
found that each predominant SP was plausible.
Also, the SPs frequent in our data were also fre-
quent among the 17 classes according to VN. For
example, the many SP clusters labeled as arrange-
ments, issues, ideas and other abstract concepts
were also frequent in T2, e.g. among COMMUNI-
CATION (37), CHARACTERISE (29.2), AMALGA-
MATE (22.2) and other classes.
This analysis showed that the SP models which
performed well in verb clustering were semanti-
cally meaningful for our task. An independent
evaluation using one of the standard datasets avail-
able for SP acquisition research (Brockmann and
Lapata, 2003) is of course needed to determine
how well the acquisition method performs in com-
parison with other existing methods.
Finally, we evaluated the quality of the verb
clusters created using the SP-based features. We
found that some of the errors were similar to those
seen on T2 when using syntactic features: errors
due to polysemy and syntactic idiosyncracy. How-
ever, a new error type clearly due to the SP-based
feature was detected. A small number of classes
got confused because of strong similar SPs in the
subject (agent) position. For example, some PEER
(30.3) verbs (e.g. look, peer) were found in the
same cluster with SAY (37.7) verbs (e.g. shout,
yell) – an error which purely syntactic features do
not produce. Such errors were not numerous and
could be addressed by developing more balanced
SP models across different GRs.
</bodyText>
<sectionHeader confidence="0.982722" genericHeader="discussions">
6 Discussion and related work
</sectionHeader>
<bodyText confidence="0.9998014">
Although features incorporating semantic infor-
mation about verb SPs make theoretical sense they
have not proved equally promising in previous ex-
periments which have compared them against syn-
tactic features in verb classification. Joanis et al.
(2008) incorporated an ’animacy’ feature (a kind
of a ’SP’) which was determined by classifying
e.g. pronouns and proper names in data to this sin-
gle SP class. A small improvement was obtained
when this feature was used in conjunction with
syntactic features in supervised classification.
Joanis (2002) and Schulte im Walde (2006) ex-
perimented with more conventional SPs with syn-
tactic features in English and German verb clas-
sification, respectively. They employing top level
</bodyText>
<note confidence="0.9958416">
Method Result
T1 Li et al. 2008 supervised 66.3
Joanis et al. 2008 supervised 58.4
Stevenson et al. 2003 semi-supervised 29
unsupervised 31
SPEC unsupervised 57.55
T2 Sun et al. 2008 supervised 62.50
unsupervised 51.6
O´ S´eaghdha et al. 2008 supervised 67.3
SPEC unsupervised 80.35
</note>
<tableCaption confidence="0.996996">
Table 5: Previous verb classification results
</tableCaption>
<bodyText confidence="0.999916341463415">
WordNet (Miller, 1995) and Germanet (Kunze and
Lemnitzer, 2002) classes as SP models. Joanis
(2002) obtained no improvement over syntactic
features, whereas Schulte im Walde (2006) ob-
tained insignificant improvement.
Korhonen et al. (2008) combined SPs with SCFs
when clustering biomedical verbs. The SPs were
acquired automatically from syntactic slots of
SCFs (not from GRs as in our experiment) using
PC clustering. A small improvement was obtained
using LPs extracted from the same syntactic slots,
but the SP clusters offered no improvement. Re-
cently, Schulte im Walde et al. (2008) proposed an
interesting SP acquisition method which involves
combining EM training and the MDL principle for
an verb classification incorporating SPs. However,
no comparison against purely syntactic features is
provided.
In our experiment, we obtained a considerable
improvement over syntactic features, despite using
a fully unsupervised approach to both verb clus-
tering and SP acquisition. In addition to the rich,
syntactic-semantic feature sets, our good results
can be attributed to the clustering technique capa-
ble of dealing with them. The potential of spectral
clustering for the task was recognised earlier by
Brew and Schulte im Walde (2002). Although a
different version of the algorithm was employed
and applied to German (rather than to English),
and although no SP features were used, these ear-
lier experiments did demonstrate the ability of the
method to perform well in high dimensional fea-
ture space.
To get an idea of how our performance com-
pares with that of related approaches, we exam-
ined recent works on verb classification (super-
vised and unsupervised) which were evaluated on
same test sets using comparable evaluation mea-
sures. These works are summarized in table 5.
ACC and F-measure are shown for T1 and T2, re-
spectively.
</bodyText>
<page confidence="0.997383">
645
</page>
<bodyText confidence="0.999963205882353">
On T1, the best performing supervised method
reported so far is that of Li and Brew (2008). Li
and Brew used Bayesian Multinomial Regression
for classification. A range of feature sets integrat-
ing COs, SCFs and/or LPs were evaluated. The
combination of COs and SCFs gave the best result,
shown in the table. Joanis et al. (2008) report the
second best supervised result on T1, using Support
Vector Machines for classification and features de-
rived from linguistic analysis: syntactic slots, slot
overlaps, tense, voice, aspect, and animacy of NPs.
Stevenson and Joanis (2003) report a semi- and
unsupervised experiment on T1. A feature set sim-
ilar to that of Joanis et al. (2008) was employed
(features were selected in a semi-supervised fash-
ion) and hierarchical clustering was used.
Our unsupervised method SPEC performs sub-
stantially better than the unsupervised method of
Stevenson et al. and nearly as well as the super-
vised approach of Joanis et al. (2008) (note, how-
ever, that the different experiments involved differ-
ent sub-sets of T1 so are not entirely comparable).
On T2, the best performing supervised method
so far is that of O´ S´eaghdha and Copestake (2008)
which employs a distributional kernel method to
classify SCF features parameterized for preposi-
tions in the automatically acquired VALEX lexicon.
Using exactly the same data and feature set, Sun
et al. (2008) obtain a slightly lower result when us-
ing a supervised method (Gaussian) and a notably
lower result when using an unsupervised method
(PC clustering). Our method performs consider-
ably better and also outperforms the supervised
method of O´ S´eaghdha and Copestake (2008).
</bodyText>
<sectionHeader confidence="0.990009" genericHeader="conclusions">
7 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999988526315789">
We introduced a new approach to verb cluster-
ing which involves the use of (i) rich lexical, SCF
and GR data produced by a recent SCF system, (ii)
novel syntactic-semantic feature sets which com-
bine a variety of linguistic information, and (iii) a
new variation of spectral clustering which is par-
ticularly suited for dealing with the resulting, high
dimensional feature space. Using this approach,
we showed on two well-established test sets that
automatically acquired SPs can be highly useful
for verb clustering. This result contrasts with most
previous works but is in line with theoretical work
on verb classification which relies not only on syn-
tactic but also on semantic features (Levin, 1993).
In addition to the ideas mentioned earlier, our
future plans include looking into optimal ways
of acquiring SPs for verb classification. Consid-
erable research has been done on SP acquisition
most of which has involved collecting argument
headwords from data and generalizing to Word-
Net classes. Brockmann and Lapata (2003) have
showed that WordNet-based approaches do not
always outperform simple frequency-based mod-
els, and a number of techniques have been re-
cently proposed which may offer ideas for refin-
ing our current unsupervised approach (Erk, 2007;
Bergsma et al., 2008). The number and type (and
combination) of GRs for which SPs can be reliably
acquired, especially when the data is sparse, re-
quires also further investigation.
In addition, we plan to investigate other po-
tentially useful features for verb classification
(e.g. named entities and preposition classes) and
explore semi-automatic ML technology and active
learning for guiding the classification. Finally, we
plan to conduct a bigger experiment with a larger
number of verbs, and conduct evaluation in the
context of practical application tasks.
</bodyText>
<sectionHeader confidence="0.997237" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999949571428571">
Our work was funded by the Dorothy Hodgkin
Postgraduate Award, the Royal Society Univer-
sity Research Fellowship, and the EPSRC grant
EP/F030061/1, UK. We would like to thank Paula
Buttery for letting us use her implementation of
the SCF classifier and Yuval Krymolowski for the
support he provided for feature extraction.
</bodyText>
<sectionHeader confidence="0.998985" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999882681818182">
Shane Bergsma, Dekang Lin, and Randy Goebel. Dis-
criminative learning of selectional preference from
unlabeled text. In Proc. of EMNLP, 2008.
Chris Brew and Sabine Schulte im Walde. Spectral
clustering for german verbs. In Proc. of EMNLP,
2002.
Ted Briscoe, John Carroll, and Rebecca Watson. The
second release of the rasp system. In Proc. of the
COLING/ACL on Interactive presentation sessions,
2006.
Carsten Brockmann and Mirella Lapata. Evaluating
and combining approaches to selectional preference
acquisition. In Proc. of EACL, 2003.
Jinxiu Chen, Dong-Hong Ji, Chew Lim Tan, and
Zheng-Yu Niu. Unsupervised relation disambigua-
tion using spectral clustering. In Proc. of COL-
ING/ACL, 2006.
Hoa Trang Dang. Investigations into the Role of Lexi-
cal Semantics in Word Sense Disambiguation. PhD
thesis, CIS, University of Pennsylvania, 2004.
Katrin Erk. A simple, similarity-based model for selec-
tional preferences. In Proc. of ACL, 2007.
</reference>
<page confidence="0.986905">
646
</page>
<reference confidence="0.999921373626373">
David Graff. North american news text corpus. Lin-
guistic Data Consortium, 1995.
Eric Joanis. Automatic Verb Classification Using a
General Feature Space. Master’s thesis, University
of Toronto, 2002.
Eric Joanis, Suzanne Stevenson, and David James. A
general feature space for automatic verb classifica-
tion. Natural Language Engineering, 2008.
Karin Kipper-Schuler. VerbNet: A broad-coverage,
comprehensive verb lexicon. 2005.
Anna Korhonen, Yuval Krymolowski, and Ted Briscoe.
A large subcategorization lexicon for natural lan-
guage processing applications. In Proc. of the 5th
LREC, 2006.
Anna Korhonen, Yuval Krymolowski, and Nigel Col-
lier. The Choice of Features for Classification of
Verbs in Biomedical Texts. In Proc. of COLING,
2008.
Claudia Kunze and Lothar Lemnitzer. GermaNet-
representation, visualization, application. In Proc.
of LREC, 2002.
Lillian. Lee. On the effectiveness of the skew diver-
gence for statistical language analysis. In Artificial
Intelligence and Statistics, 2001.
Geoffrey Leech. 100 million words of english: the
british national corpus. Language Research, 1992.
Beth. Levin. English verb classes and alternations: A
preliminary investigation. Chicago, IL, 1993.
Jianguo Li and Chris Brew. Which Are the Best Fea-
tures for Automatic Verb Classification. In Proc. of
ACL, 2008.
Diana McCarthy. Lexical Acquisition at the Syntax-
Semantics Interface: Diathesis Alternations, Sub-
categorization Frames and Selectional Preferences.
PhD thesis, University of Sussex, UK, 2001.
Marina. Meila. The multicut lemma. Technical report,
University of Washington, 2001.
Marina Meila and Jianbo Shi. A random walks view of
spectral segmentation. AISTATS, 2001.
George A. Miller. WordNet: a lexical database for En-
glish. Communications of the ACM, 1995.
Pedro J. Moreno, Purdy P. Ho, and Nuno Vasconce-
los. A Kullback-Leibler divergence based kernel for
SVM classification in multimedia applications. In
Proc. of NIPS, 2004.
Andrew Y. Ng, Michael Jordan, and Yair Weiss. On
spectral clustering: Analysis and an algorithm. In
Proc. of NIPS, 2002.
Diarmuid O´ S´eaghdha and Ann Copestake. Semantic
classification with distributional kernels. In Proc. of
COLING, 2008.
Judita Preiss, Ted Briscoe, and Anna Korhonen. A sys-
tem for large-scale acquisition of verbal, nominal
and adjectival subcategorization frames from cor-
pora. In Proc. of ACL, 2007.
Jan Puzicha, Thomas Hofmann, and Joachim M. Buh-
mann. A theory of proximity based clustering:
Structure detection by optimization. Pattern Recog-
nition, 2000.
Sabine Schulte im Walde. Experiments on the auto-
matic induction of german semantic verb classes.
Computational Linguistics, 2006.
Sabine Schulte im Walde, Christian Hying, Christian
Scheible, and Helmut Schmid. Combining EM
Training and the MDL Principle for an Automatic
Verb Classification incorporating Selectional Pref-
erences. In Proc. of ACL, pages 496–504, 2008.
Lei Shi and Rada Mihalcea. Putting pieces together:
Combining FrameNet, VerbNet and WordNet for ro-
bust semantic parsing. In Proc. of CICLING, 2005.
Suzanne Stevenson and Eric Joanis. Semi-supervised
verb class discovery using noisy features. In Proc.
of HLT-NAACL 2003, pages 71–78, 2003.
Lin Sun, Anna Korhonen, and Yuval Krymolowski.
Verb class discovery from rich syntactic data. Lec-
ture Notes in Computer Science, 4919:16, 2008.
Robert Swier and Suzanne Stevenson. Unsupervised
semantic role labelling. In Proc. of EMNLP, 2004.
Deepak Verma and Marina Meila. Comparison of spec-
tral clustering methods. Advances in Neural Infor-
mation Processing Systems (NIPS 15), 2003.
Andreas Vlachos, Anna Korhonen, and Zoubin
Ghahramani. Unsupervised and constrained dirich-
let process mixture models for verb clustering. In
Proc. of the Workshop on Geometrical Models of
Natural Language Semantics, 2009.
Ulrike von Luxburg. A tutorial on spectral clustering.
Statistics and Computing, 2007.
Be˜nat Zapirain, Eneko Agirre, and Llu´ıs M`arquez. Ro-
bustness and generalization of role sets: PropBank
vs. VerbNet. In Proc. of ACL, 2008.
</reference>
<page confidence="0.998191">
647
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.626120">
<title confidence="0.998709">Improving Verb Clustering with Automatically Acquired Selectional Preferences</title>
<author confidence="0.998159">Lin Sun</author>
<author confidence="0.998159">Anna</author>
<affiliation confidence="0.973424">University of Cambridge, Computer</affiliation>
<address confidence="0.639185">15 JJ Thomson Avenue, Cambridge CB3 0GD,</address>
<email confidence="0.994103">ls418,alk23@cl.cam.ac.uk</email>
<abstract confidence="0.999227631578947">In previous research in automatic verb classification, syntactic features have proved the most useful features, although manual classifications rely heavily on semantic features. We show, in contrast with previous work, that considerable additional improvement can be obtained by using semantic features in automatic classification: verb selectional preferences acquired from corpus data using a fully unsupervised method. We report these promising results using a new framework for verb clustering which incorporates a recent subcategorization acquisition system, rich syntactic-semantic feature sets, and a variation of spectral clustering which performs particularly well in high dimensional feature space.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Shane Bergsma</author>
<author>Dekang Lin</author>
<author>Randy Goebel</author>
</authors>
<title>Discriminative learning of selectional preference from unlabeled text.</title>
<date>2008</date>
<booktitle>In Proc. of EMNLP,</booktitle>
<contexts>
<context position="6526" citStr="Bergsma et al., 2008" startWordPosition="976" endWordPosition="979"> in better performance. However, additional information about semantic SPs of verbs has not yielded considerable improvement on verb classification although SPs can be strong indicators of diathesis alternations (McCarthy, 2001) and although fairly precise semantic descriptions, including information about verb se1See section 6 for discussion on previous work. lectional restrictions, can be assigned to the majority of Levin classes, as demonstrated by VerbNet (Kipper-Schuler, 2005). SP acquisition from undisambiguated corpus data is arguably challenging (Brockmann and Lapata, 2003; Erk, 2007; Bergsma et al., 2008). It is especially challenging in the context of verb classification where SP models are needed for specific syntactic slots for which the data may be sparse, and the resulting feature vectors integrating both syntactic and semantic features may be high dimensional. However, we wanted to investigate whether better results could be obtained if the features were optimised for richness, the feature extraction for accuracy, and a clustering method capable of dealing with the resulting high dimensional feature space was employed. 2.1 Feature extraction We adopted a recent SCF acquisition system whi</context>
<context position="36444" citStr="Bergsma et al., 2008" startWordPosition="6037" endWordPosition="6040">t also on semantic features (Levin, 1993). In addition to the ideas mentioned earlier, our future plans include looking into optimal ways of acquiring SPs for verb classification. Considerable research has been done on SP acquisition most of which has involved collecting argument headwords from data and generalizing to WordNet classes. Brockmann and Lapata (2003) have showed that WordNet-based approaches do not always outperform simple frequency-based models, and a number of techniques have been recently proposed which may offer ideas for refining our current unsupervised approach (Erk, 2007; Bergsma et al., 2008). The number and type (and combination) of GRs for which SPs can be reliably acquired, especially when the data is sparse, requires also further investigation. In addition, we plan to investigate other potentially useful features for verb classification (e.g. named entities and preposition classes) and explore semi-automatic ML technology and active learning for guiding the classification. Finally, we plan to conduct a bigger experiment with a larger number of verbs, and conduct evaluation in the context of practical application tasks. Acknowledgments Our work was funded by the Dorothy Hodgkin</context>
</contexts>
<marker>Bergsma, Lin, Goebel, 2008</marker>
<rawString>Shane Bergsma, Dekang Lin, and Randy Goebel. Discriminative learning of selectional preference from unlabeled text. In Proc. of EMNLP, 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Brew</author>
<author>Sabine Schulte im Walde</author>
</authors>
<title>Spectral clustering for german verbs.</title>
<date>2002</date>
<booktitle>In Proc. of EMNLP,</booktitle>
<marker>Brew, Walde, 2002</marker>
<rawString>Chris Brew and Sabine Schulte im Walde. Spectral clustering for german verbs. In Proc. of EMNLP, 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Briscoe</author>
<author>John Carroll</author>
<author>Rebecca Watson</author>
</authors>
<title>The second release of the rasp system.</title>
<date>2006</date>
<booktitle>In Proc. of the COLING/ACL on Interactive presentation sessions,</booktitle>
<contexts>
<context position="7442" citStr="Briscoe et al., 2006" startWordPosition="1123" endWordPosition="1126">igate whether better results could be obtained if the features were optimised for richness, the feature extraction for accuracy, and a clustering method capable of dealing with the resulting high dimensional feature space was employed. 2.1 Feature extraction We adopted a recent SCF acquisition system which has proved more accurate than previous comparable systems2 but which has not been employed for verb clustering before: the system of Preiss et al. (2007). This system tags, lemmatizes and parses corpus data using the current version of the RASP (Robust Accurate Statistical Parsing) toolkit (Briscoe et al., 2006), and on the basis of resulting grammatical relations (GRs) assigns each occurrence of a verb to one of 168 verbal SCFs classes3. The system provides a filter which can be used to remove adjuncts from the resulting lexicon. We do not employ this filter since adjuncts have proved informative for verb classification (Sun et al., 2008; Joanis et al., 2008). However, we do frequency-based thresholding to minimise the noise (e.g. erroneous scfs) and sparse data in verb classification and to ensure that only features supported by several verbs are used in classification: we only consider SCFs and GR</context>
</contexts>
<marker>Briscoe, Carroll, Watson, 2006</marker>
<rawString>Ted Briscoe, John Carroll, and Rebecca Watson. The second release of the rasp system. In Proc. of the COLING/ACL on Interactive presentation sessions, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carsten Brockmann</author>
<author>Mirella Lapata</author>
</authors>
<title>Evaluating and combining approaches to selectional preference acquisition.</title>
<date>2003</date>
<booktitle>In Proc. of EACL,</booktitle>
<contexts>
<context position="6492" citStr="Brockmann and Lapata, 2003" startWordPosition="969" endWordPosition="973"> and/or voice of the verb have resulted in better performance. However, additional information about semantic SPs of verbs has not yielded considerable improvement on verb classification although SPs can be strong indicators of diathesis alternations (McCarthy, 2001) and although fairly precise semantic descriptions, including information about verb se1See section 6 for discussion on previous work. lectional restrictions, can be assigned to the majority of Levin classes, as demonstrated by VerbNet (Kipper-Schuler, 2005). SP acquisition from undisambiguated corpus data is arguably challenging (Brockmann and Lapata, 2003; Erk, 2007; Bergsma et al., 2008). It is especially challenging in the context of verb classification where SP models are needed for specific syntactic slots for which the data may be sparse, and the resulting feature vectors integrating both syntactic and semantic features may be high dimensional. However, we wanted to investigate whether better results could be obtained if the features were optimised for richness, the feature extraction for accuracy, and a clustering method capable of dealing with the resulting high dimensional feature space was employed. 2.1 Feature extraction We adopted a</context>
<context position="29725" citStr="Brockmann and Lapata, 2003" startWordPosition="4966" endWordPosition="4969">estrictions for T2, we found that each predominant SP was plausible. Also, the SPs frequent in our data were also frequent among the 17 classes according to VN. For example, the many SP clusters labeled as arrangements, issues, ideas and other abstract concepts were also frequent in T2, e.g. among COMMUNICATION (37), CHARACTERISE (29.2), AMALGAMATE (22.2) and other classes. This analysis showed that the SP models which performed well in verb clustering were semantically meaningful for our task. An independent evaluation using one of the standard datasets available for SP acquisition research (Brockmann and Lapata, 2003) is of course needed to determine how well the acquisition method performs in comparison with other existing methods. Finally, we evaluated the quality of the verb clusters created using the SP-based features. We found that some of the errors were similar to those seen on T2 when using syntactic features: errors due to polysemy and syntactic idiosyncracy. However, a new error type clearly due to the SP-based feature was detected. A small number of classes got confused because of strong similar SPs in the subject (agent) position. For example, some PEER (30.3) verbs (e.g. look, peer) were found</context>
<context position="36188" citStr="Brockmann and Lapata (2003)" startWordPosition="5997" endWordPosition="6000">we showed on two well-established test sets that automatically acquired SPs can be highly useful for verb clustering. This result contrasts with most previous works but is in line with theoretical work on verb classification which relies not only on syntactic but also on semantic features (Levin, 1993). In addition to the ideas mentioned earlier, our future plans include looking into optimal ways of acquiring SPs for verb classification. Considerable research has been done on SP acquisition most of which has involved collecting argument headwords from data and generalizing to WordNet classes. Brockmann and Lapata (2003) have showed that WordNet-based approaches do not always outperform simple frequency-based models, and a number of techniques have been recently proposed which may offer ideas for refining our current unsupervised approach (Erk, 2007; Bergsma et al., 2008). The number and type (and combination) of GRs for which SPs can be reliably acquired, especially when the data is sparse, requires also further investigation. In addition, we plan to investigate other potentially useful features for verb classification (e.g. named entities and preposition classes) and explore semi-automatic ML technology and</context>
</contexts>
<marker>Brockmann, Lapata, 2003</marker>
<rawString>Carsten Brockmann and Mirella Lapata. Evaluating and combining approaches to selectional preference acquisition. In Proc. of EACL, 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jinxiu Chen</author>
<author>Dong-Hong Ji</author>
<author>Chew Lim Tan</author>
<author>Zheng-Yu Niu</author>
</authors>
<title>Unsupervised relation disambiguation using spectral clustering.</title>
<date>2006</date>
<booktitle>In Proc. of COLING/ACL,</booktitle>
<contexts>
<context position="12541" citStr="Chen et al., 2006" startWordPosition="1995" endWordPosition="1998">f an older, comparable system which was used for constructing the VALEX lexicon. 640 3 Clustering methods We use two clustering methods: (i) pairwise clustering (PC) which obtained the best performance in comparison with several other methods in recent work on biomedical verb clustering (Korhonen et al., 2008), and (ii) a method which is new to the task (and to the best of our knowledge, to NLP): a variation of spectral clustering which exploits the MNCut algorithm (Meila and Shi, 2001) (SPEC). Spectral clustering has been shown to be effective for high dimensional and non-convex data in NLP (Chen et al., 2006) and it has been applied to German verb clustering by Brew and Schulte im Walde (2002). However, previous work has used Ng et al. (2002)’s algorithm, while we adopt the MNCut algorithm. The latter has shown a wider applicability (von Luxburg, 2007; Verma and Meila, 2003) and it can be justified from the random walk view, which has a clear probabilistic interpretation. Clustering groups a given set of items (verbs in our experiment) V = {vn}Nn=1 into a disjoint partition of K classes I = {Ik}Kk=1. Both our algorithms take a similarity matrix as input. We construct this from the skew divergence </context>
</contexts>
<marker>Chen, Ji, Tan, Niu, 2006</marker>
<rawString>Jinxiu Chen, Dong-Hong Ji, Chew Lim Tan, and Zheng-Yu Niu. Unsupervised relation disambiguation using spectral clustering. In Proc. of COLING/ACL, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hoa Trang Dang</author>
</authors>
<title>Investigations into the Role of Lexical Semantics in Word Sense Disambiguation.</title>
<date>2004</date>
<tech>PhD thesis,</tech>
<institution>CIS, University of Pennsylvania,</institution>
<contexts>
<context position="1306" citStr="Dang, 2004" startWordPosition="177" endWordPosition="178">framework for verb clustering which incorporates a recent subcategorization acquisition system, rich syntactic-semantic feature sets, and a variation of spectral clustering which performs particularly well in high dimensional feature space. 1 Introduction Verb classifications have attracted a great deal of interest in natural language processing (NLP). They have proved useful for various important NLP tasks and applications, including e.g. parsing, word sense disambiguation, semantic role labeling, information extraction, question-answering, and machine translation (Swier and Stevenson, 2004; Dang, 2004; Shi and Mihalcea, 2005; Zapirain et al., 2008). Verb classes are useful because they offer a powerful tool for generalization and abstraction which can be beneficial when faced e.g. with the problem of data sparsity. Particularly useful can be classes which capture generalizations over a range of (cross-)linguistic properties, such as the ones proposed by Levin (1993). Being defined in terms of similar meaning and (morpho-)syntactic behaviour of words, Levin style classes generally incorporate a wider range of properties than e.g. classes defined solely on semantic grounds (Miller, 1995). In</context>
</contexts>
<marker>Dang, 2004</marker>
<rawString>Hoa Trang Dang. Investigations into the Role of Lexical Semantics in Word Sense Disambiguation. PhD thesis, CIS, University of Pennsylvania, 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katrin Erk</author>
</authors>
<title>A simple, similarity-based model for selectional preferences.</title>
<date>2007</date>
<booktitle>In Proc. of ACL,</booktitle>
<contexts>
<context position="6503" citStr="Erk, 2007" startWordPosition="974" endWordPosition="975">ve resulted in better performance. However, additional information about semantic SPs of verbs has not yielded considerable improvement on verb classification although SPs can be strong indicators of diathesis alternations (McCarthy, 2001) and although fairly precise semantic descriptions, including information about verb se1See section 6 for discussion on previous work. lectional restrictions, can be assigned to the majority of Levin classes, as demonstrated by VerbNet (Kipper-Schuler, 2005). SP acquisition from undisambiguated corpus data is arguably challenging (Brockmann and Lapata, 2003; Erk, 2007; Bergsma et al., 2008). It is especially challenging in the context of verb classification where SP models are needed for specific syntactic slots for which the data may be sparse, and the resulting feature vectors integrating both syntactic and semantic features may be high dimensional. However, we wanted to investigate whether better results could be obtained if the features were optimised for richness, the feature extraction for accuracy, and a clustering method capable of dealing with the resulting high dimensional feature space was employed. 2.1 Feature extraction We adopted a recent SCF</context>
<context position="36421" citStr="Erk, 2007" startWordPosition="6035" endWordPosition="6036">yntactic but also on semantic features (Levin, 1993). In addition to the ideas mentioned earlier, our future plans include looking into optimal ways of acquiring SPs for verb classification. Considerable research has been done on SP acquisition most of which has involved collecting argument headwords from data and generalizing to WordNet classes. Brockmann and Lapata (2003) have showed that WordNet-based approaches do not always outperform simple frequency-based models, and a number of techniques have been recently proposed which may offer ideas for refining our current unsupervised approach (Erk, 2007; Bergsma et al., 2008). The number and type (and combination) of GRs for which SPs can be reliably acquired, especially when the data is sparse, requires also further investigation. In addition, we plan to investigate other potentially useful features for verb classification (e.g. named entities and preposition classes) and explore semi-automatic ML technology and active learning for guiding the classification. Finally, we plan to conduct a bigger experiment with a larger number of verbs, and conduct evaluation in the context of practical application tasks. Acknowledgments Our work was funded</context>
</contexts>
<marker>Erk, 2007</marker>
<rawString>Katrin Erk. A simple, similarity-based model for selectional preferences. In Proc. of ACL, 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Graff</author>
</authors>
<title>North american news text corpus. Linguistic Data Consortium,</title>
<date>1995</date>
<contexts>
<context position="19195" citStr="Graff, 1995" startWordPosition="3195" endWordPosition="3196"> SCF (V) F8 - - 92 45 SCF+LP(s) F9 1747 324 1474 225 SCF+LP (o) F10 2817 424 2319 279 SCF+LP (all) F11 4250 649 3515 426 SCF+SP20 (s) F12 821 235 690 145 SCF+SP20(o) F13 792 218 706 135 SCF+SP20(all) F14 1333 357 1200 231 SCF+SP30 (s) F15 977 274 903 202 SCF+SP30(o) F16 1026 273 1012 205 SCF+SP30(all) F17 1720 451 1640 330 Table 2: (i) The total number of features and (ii) the average per verb for all the feature sets VALEX lexicon (Korhonen et al., 2006). The data was gathered from five corpora, including e.g. the British National Corpus (Leech, 1992) and the North American News Text Corpus (Graff, 1995). The average frequency of verbs in T1 was 1448 and T2 2166, showing that T1 is a more sparse data set. The data was first processed using the feature extraction module. Table 2 shows (i) the total number of features in each feature set and (ii) the average per verb in the resulting lexicons for T1 and T2. We normalized the feature vectors by the sum of the feature values before applying the clustering techniques. Since both clustering algorithms have 642 an element of randomness, we run them multiple times. The step 5 of SPEC (K-means) was run for 50 times. The result that minimizes the disto</context>
</contexts>
<marker>Graff, 1995</marker>
<rawString>David Graff. North american news text corpus. Linguistic Data Consortium, 1995.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Joanis</author>
</authors>
<title>Automatic Verb Classification Using a General Feature Space. Master’s thesis,</title>
<date>2002</date>
<institution>University of Toronto,</institution>
<contexts>
<context position="31135" citStr="Joanis (2002)" startWordPosition="5196" endWordPosition="5197">nced SP models across different GRs. 6 Discussion and related work Although features incorporating semantic information about verb SPs make theoretical sense they have not proved equally promising in previous experiments which have compared them against syntactic features in verb classification. Joanis et al. (2008) incorporated an ’animacy’ feature (a kind of a ’SP’) which was determined by classifying e.g. pronouns and proper names in data to this single SP class. A small improvement was obtained when this feature was used in conjunction with syntactic features in supervised classification. Joanis (2002) and Schulte im Walde (2006) experimented with more conventional SPs with syntactic features in English and German verb classification, respectively. They employing top level Method Result T1 Li et al. 2008 supervised 66.3 Joanis et al. 2008 supervised 58.4 Stevenson et al. 2003 semi-supervised 29 unsupervised 31 SPEC unsupervised 57.55 T2 Sun et al. 2008 supervised 62.50 unsupervised 51.6 O´ S´eaghdha et al. 2008 supervised 67.3 SPEC unsupervised 80.35 Table 5: Previous verb classification results WordNet (Miller, 1995) and Germanet (Kunze and Lemnitzer, 2002) classes as SP models. Joanis (20</context>
</contexts>
<marker>Joanis, 2002</marker>
<rawString>Eric Joanis. Automatic Verb Classification Using a General Feature Space. Master’s thesis, University of Toronto, 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Joanis</author>
<author>Suzanne Stevenson</author>
<author>David James</author>
</authors>
<title>A general feature space for automatic verb classification. Natural Language Engineering,</title>
<date>2008</date>
<contexts>
<context position="2065" citStr="Joanis et al., 2008" startWordPosition="293" endWordPosition="296">ion which can be beneficial when faced e.g. with the problem of data sparsity. Particularly useful can be classes which capture generalizations over a range of (cross-)linguistic properties, such as the ones proposed by Levin (1993). Being defined in terms of similar meaning and (morpho-)syntactic behaviour of words, Levin style classes generally incorporate a wider range of properties than e.g. classes defined solely on semantic grounds (Miller, 1995). In recent years, a variety of approaches have been proposed for automatic induction of verb classes from corpus data (Schulte im Walde, 2006; Joanis et al., 2008; Sun et al., 2008; Li and Brew, 2008; Korhonen et al., 2008; O´ S´eaghdha and Copestake, 2008; Vlachos et al., 2009). This work opens up the opportunity of learning and tuning classifications tailored to the application and domain in question. Although manual classification may always yields higher accuracy, automatic verb classification is cost-effective and gathers statistical information as a side-effect of the acquisition process which is difficult for humans to gather but can be highly useful for NLP applications. To date, both supervised and unsupervised machine learning (ML) methods ha</context>
<context position="7797" citStr="Joanis et al., 2008" startWordPosition="1184" endWordPosition="1187">e systems2 but which has not been employed for verb clustering before: the system of Preiss et al. (2007). This system tags, lemmatizes and parses corpus data using the current version of the RASP (Robust Accurate Statistical Parsing) toolkit (Briscoe et al., 2006), and on the basis of resulting grammatical relations (GRs) assigns each occurrence of a verb to one of 168 verbal SCFs classes3. The system provides a filter which can be used to remove adjuncts from the resulting lexicon. We do not employ this filter since adjuncts have proved informative for verb classification (Sun et al., 2008; Joanis et al., 2008). However, we do frequency-based thresholding to minimise the noise (e.g. erroneous scfs) and sparse data in verb classification and to ensure that only features supported by several verbs are used in classification: we only consider SCFs and GRs which have frequency larger than 40 with 5 or more verbs4. The system produces a rich lexicon which includes raw and processed input sentences and provides a variety of material for verb clustering, including e.g. (statistical) information related to the part-of-speech (POS) tags, GRs, SCFs, argument heads, and adjuncts of verbs. Using this material, </context>
<context position="16732" citStr="Joanis et al. (2008)" startWordPosition="2748" endWordPosition="2751">ion 1 3. Compute the eigenvalues and eigenvectors {λn, xn}Nn=1 of P, where λn ≥ λn+1, form a matrix X = [x2,. . . , xk] by stacking the eigenvectors in columns. 4. Form a matrix Y from X by normalizing the 2 row sums to have norm 1: Yij = Xij/(�j X2 ij)1 5. Consider the row of Y to be the transformed feature vectors for each verb and cluster them into clusters C1 ... Ck using K-means clustering algorithm. Output: Clusters C1 ... Ck 4 Experimental evaluation 4.1 Test sets We employed two test sets which have been used to evaluate previous work on English verb classification: T1 The test set of Joanis et al. (2008) provides a classification of 835 verbs into 15 (some coarse, some fine-grained) Levin classes. 11 tests are provided for 2-14 way classifications. We employ the 14 way classification because this corresponds the closest to our target (Levin’s fine-grained) classification7. We select 586 verbs according to Joanis et al.’s selection criteria, resulting in 10- 120 verbs per class. We restrict the class imbalance to 1:1.5.8. This yields 205 verbs (10-15 verbs per class) which is similar to the sub-set of T1 employed by Stevenson and Joanis (2003). T2 The test set of Sun et al. (2008) classifies 2</context>
<context position="30839" citStr="Joanis et al. (2008)" startWordPosition="5147" endWordPosition="5150">ilar SPs in the subject (agent) position. For example, some PEER (30.3) verbs (e.g. look, peer) were found in the same cluster with SAY (37.7) verbs (e.g. shout, yell) – an error which purely syntactic features do not produce. Such errors were not numerous and could be addressed by developing more balanced SP models across different GRs. 6 Discussion and related work Although features incorporating semantic information about verb SPs make theoretical sense they have not proved equally promising in previous experiments which have compared them against syntactic features in verb classification. Joanis et al. (2008) incorporated an ’animacy’ feature (a kind of a ’SP’) which was determined by classifying e.g. pronouns and proper names in data to this single SP class. A small improvement was obtained when this feature was used in conjunction with syntactic features in supervised classification. Joanis (2002) and Schulte im Walde (2006) experimented with more conventional SPs with syntactic features in English and German verb classification, respectively. They employing top level Method Result T1 Li et al. 2008 supervised 66.3 Joanis et al. 2008 supervised 58.4 Stevenson et al. 2003 semi-supervised 29 unsup</context>
<context position="33808" citStr="Joanis et al. (2008)" startWordPosition="5618" endWordPosition="5621">res with that of related approaches, we examined recent works on verb classification (supervised and unsupervised) which were evaluated on same test sets using comparable evaluation measures. These works are summarized in table 5. ACC and F-measure are shown for T1 and T2, respectively. 645 On T1, the best performing supervised method reported so far is that of Li and Brew (2008). Li and Brew used Bayesian Multinomial Regression for classification. A range of feature sets integrating COs, SCFs and/or LPs were evaluated. The combination of COs and SCFs gave the best result, shown in the table. Joanis et al. (2008) report the second best supervised result on T1, using Support Vector Machines for classification and features derived from linguistic analysis: syntactic slots, slot overlaps, tense, voice, aspect, and animacy of NPs. Stevenson and Joanis (2003) report a semi- and unsupervised experiment on T1. A feature set similar to that of Joanis et al. (2008) was employed (features were selected in a semi-supervised fashion) and hierarchical clustering was used. Our unsupervised method SPEC performs substantially better than the unsupervised method of Stevenson et al. and nearly as well as the supervised</context>
</contexts>
<marker>Joanis, Stevenson, James, 2008</marker>
<rawString>Eric Joanis, Suzanne Stevenson, and David James. A general feature space for automatic verb classification. Natural Language Engineering, 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karin Kipper-Schuler</author>
</authors>
<title>VerbNet: A broad-coverage, comprehensive verb lexicon.</title>
<date>2005</date>
<contexts>
<context position="6391" citStr="Kipper-Schuler, 2005" startWordPosition="958" endWordPosition="959">t supplementing basic syntactic features with information about adjuncts, co-occurrences, tense, and/or voice of the verb have resulted in better performance. However, additional information about semantic SPs of verbs has not yielded considerable improvement on verb classification although SPs can be strong indicators of diathesis alternations (McCarthy, 2001) and although fairly precise semantic descriptions, including information about verb se1See section 6 for discussion on previous work. lectional restrictions, can be assigned to the majority of Levin classes, as demonstrated by VerbNet (Kipper-Schuler, 2005). SP acquisition from undisambiguated corpus data is arguably challenging (Brockmann and Lapata, 2003; Erk, 2007; Bergsma et al., 2008). It is especially challenging in the context of verb classification where SP models are needed for specific syntactic slots for which the data may be sparse, and the resulting feature vectors integrating both syntactic and semantic features may be high dimensional. However, we wanted to investigate whether better results could be obtained if the features were optimised for richness, the feature extraction for accuracy, and a clustering method capable of dealin</context>
</contexts>
<marker>Kipper-Schuler, 2005</marker>
<rawString>Karin Kipper-Schuler. VerbNet: A broad-coverage, comprehensive verb lexicon. 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anna Korhonen</author>
<author>Yuval Krymolowski</author>
<author>Ted Briscoe</author>
</authors>
<title>A large subcategorization lexicon for natural language processing applications.</title>
<date>2006</date>
<booktitle>In Proc. of the 5th LREC,</booktitle>
<contexts>
<context position="8961" citStr="Korhonen et al., 2006" startWordPosition="1376" endWordPosition="1379">gument heads, and adjuncts of verbs. Using this material, we constructed a wide range of feature sets 2See Preiss et al. (2007) for the details of evaluation. 3We used an implementation of the SCF classifier provided by Paula Buttery. 4These and other threshold values mentioned in this paper were determined empirically on corpus data. 639 for experimentation, both shallow and deep syntactic and semantic features. As described below, some of the feature types have been employed in previous works and some are novel. F8: Basic SCF feature corresponding to F4 but extracted from the VALEX lexicon (Korhonen et al., 2006)5. 2.2 Feature sets The first feature set F1 includes information about the lexical context (co-occurrences) of verbs which has proved useful for supervised verb classification (Li and Brew, 2008): F1: Co-occurrence (CO): We adopt the best method of Li and Brew (2008) where collocations are extracted from the four words immediately preceding and following a lemmatized verb. Stop words are removed prior to extraction, and the 600 most frequent resulting COs are kept. F2-F3 provide information about lexical preferences of verbs in argument head positions of specific GRs associated with the verb:</context>
<context position="19042" citStr="Korhonen et al., 2006" startWordPosition="3169" endWordPosition="3172">1328 764 743 382 LP (p) F2 61 37 55 25 LP (all) F3 2521 526 1481 295 SCF F4 88 46 86 38 SCF+CO F5 1466 833 856 422 SCF+POS F6 319 114 299 87 SCF+P F7 282 96 273 76 SCF (V) F8 - - 92 45 SCF+LP(s) F9 1747 324 1474 225 SCF+LP (o) F10 2817 424 2319 279 SCF+LP (all) F11 4250 649 3515 426 SCF+SP20 (s) F12 821 235 690 145 SCF+SP20(o) F13 792 218 706 135 SCF+SP20(all) F14 1333 357 1200 231 SCF+SP30 (s) F15 977 274 903 202 SCF+SP30(o) F16 1026 273 1012 205 SCF+SP30(all) F17 1720 451 1640 330 Table 2: (i) The total number of features and (ii) the average per verb for all the feature sets VALEX lexicon (Korhonen et al., 2006). The data was gathered from five corpora, including e.g. the British National Corpus (Leech, 1992) and the North American News Text Corpus (Graff, 1995). The average frequency of verbs in T1 was 1448 and T2 2166, showing that T1 is a more sparse data set. The data was first processed using the feature extraction module. Table 2 shows (i) the total number of features in each feature set and (ii) the average per verb in the resulting lexicons for T1 and T2. We normalized the feature vectors by the sum of the feature values before applying the clustering techniques. Since both clustering algorit</context>
</contexts>
<marker>Korhonen, Krymolowski, Briscoe, 2006</marker>
<rawString>Anna Korhonen, Yuval Krymolowski, and Ted Briscoe. A large subcategorization lexicon for natural language processing applications. In Proc. of the 5th LREC, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anna Korhonen</author>
<author>Yuval Krymolowski</author>
<author>Nigel Collier</author>
</authors>
<title>The Choice of Features for Classification of Verbs in Biomedical Texts.</title>
<date>2008</date>
<booktitle>In Proc. of COLING,</booktitle>
<contexts>
<context position="2125" citStr="Korhonen et al., 2008" startWordPosition="305" endWordPosition="308">em of data sparsity. Particularly useful can be classes which capture generalizations over a range of (cross-)linguistic properties, such as the ones proposed by Levin (1993). Being defined in terms of similar meaning and (morpho-)syntactic behaviour of words, Levin style classes generally incorporate a wider range of properties than e.g. classes defined solely on semantic grounds (Miller, 1995). In recent years, a variety of approaches have been proposed for automatic induction of verb classes from corpus data (Schulte im Walde, 2006; Joanis et al., 2008; Sun et al., 2008; Li and Brew, 2008; Korhonen et al., 2008; O´ S´eaghdha and Copestake, 2008; Vlachos et al., 2009). This work opens up the opportunity of learning and tuning classifications tailored to the application and domain in question. Although manual classification may always yields higher accuracy, automatic verb classification is cost-effective and gathers statistical information as a side-effect of the acquisition process which is difficult for humans to gather but can be highly useful for NLP applications. To date, both supervised and unsupervised machine learning (ML) methods have been proposed for verb classification and used to classif</context>
<context position="10004" citStr="Korhonen et al., 2008" startWordPosition="1547" endWordPosition="1550">and the 600 most frequent resulting COs are kept. F2-F3 provide information about lexical preferences of verbs in argument head positions of specific GRs associated with the verb: F2: Prepositional preference (PP): the type and frequency of prepositions in the indirect object relation. F3: Lexical preference (LP): the type and frequency of nouns and prepositions in the subject, object, and indirect object relation. All the other feature sets include information about SCFs which have been widely employed in verb classification, e.g. (Schulte im Walde, 2006; Sun et al., 2008; Li and Brew, 2008; Korhonen et al., 2008). F4-F7 include basic SCF information and/or refine it with additional information which has proved useful in previous works: F4: SCFs and relative frequencies with verbs. SCFs abstract over particles and prepositions. F5: F4 with COs (F1). The SCF and CO feature vectors are concatenated. F6: F4 with the tense of the verb. The frequency of verbal POS tags is calculated specific to each SCF. F7: F4 with PPs (F2). This feature parameterizes SCFs for prepositions. The following 9 feature sets are novel. They build on F7, refining it further. F9-F11 refine F7 with information about LPs: F9: F7 wit</context>
<context position="12234" citStr="Korhonen et al., 2008" startWordPosition="1939" endWordPosition="1943"> are combined with SCFs in F9-F11: F12-F14: as F9-F11 but SPs (20 clusters from 200 argument heads) are used instead of LPs F15-F17: as F9-F11 but SPs (30 clusters from 500 argument heads) are used instead of LPs 5This feature was included to enable comparing the contribution of the recent SCF system to that of an older, comparable system which was used for constructing the VALEX lexicon. 640 3 Clustering methods We use two clustering methods: (i) pairwise clustering (PC) which obtained the best performance in comparison with several other methods in recent work on biomedical verb clustering (Korhonen et al., 2008), and (ii) a method which is new to the task (and to the best of our knowledge, to NLP): a variation of spectral clustering which exploits the MNCut algorithm (Meila and Shi, 2001) (SPEC). Spectral clustering has been shown to be effective for high dimensional and non-convex data in NLP (Chen et al., 2006) and it has been applied to German verb clustering by Brew and Schulte im Walde (2002). However, previous work has used Ng et al. (2002)’s algorithm, while we adopt the MNCut algorithm. The latter has shown a wider applicability (von Luxburg, 2007; Verma and Meila, 2003) and it can be justifi</context>
<context position="20059" citStr="Korhonen et al. (2008)" startWordPosition="3342" endWordPosition="3345">ii) the average per verb in the resulting lexicons for T1 and T2. We normalized the feature vectors by the sum of the feature values before applying the clustering techniques. Since both clustering algorithms have 642 an element of randomness, we run them multiple times. The step 5 of SPEC (K-means) was run for 50 times. The result that minimizes the distortion (the distances to cluster centroid) is reported. PC was run 20 times, and the results are averaged. 4.3 Evaluation measures To facilitate meaningful comparisons, we employ the same measures for evaluation as previously employed e.g. by Korhonen et al. (2008); O´ S´eaghdha and Copestake (2008). The first measure is modified purity (mPUR) – a global measure which evaluates the mean precision of clusters. Each cluster is associated with its prevalent class. The number of verbs in a cluster K that take this class is denoted by nprevalent(K). Verbs that do not take it are considered as errors. Clusters where nprevalent(K) = 1 are disregarded as not to introduce a bias towards singletons: mPUR = Enprevalent(ki)&gt;2 nprevalent(ki) number of verbs The second measure is weighted class accuracy (ACC): the proportion of members of dominant clusters DOM-CLUSTi</context>
<context position="31878" citStr="Korhonen et al. (2008)" startWordPosition="5306" endWordPosition="5309">lassification, respectively. They employing top level Method Result T1 Li et al. 2008 supervised 66.3 Joanis et al. 2008 supervised 58.4 Stevenson et al. 2003 semi-supervised 29 unsupervised 31 SPEC unsupervised 57.55 T2 Sun et al. 2008 supervised 62.50 unsupervised 51.6 O´ S´eaghdha et al. 2008 supervised 67.3 SPEC unsupervised 80.35 Table 5: Previous verb classification results WordNet (Miller, 1995) and Germanet (Kunze and Lemnitzer, 2002) classes as SP models. Joanis (2002) obtained no improvement over syntactic features, whereas Schulte im Walde (2006) obtained insignificant improvement. Korhonen et al. (2008) combined SPs with SCFs when clustering biomedical verbs. The SPs were acquired automatically from syntactic slots of SCFs (not from GRs as in our experiment) using PC clustering. A small improvement was obtained using LPs extracted from the same syntactic slots, but the SP clusters offered no improvement. Recently, Schulte im Walde et al. (2008) proposed an interesting SP acquisition method which involves combining EM training and the MDL principle for an verb classification incorporating SPs. However, no comparison against purely syntactic features is provided. In our experiment, we obtained</context>
</contexts>
<marker>Korhonen, Krymolowski, Collier, 2008</marker>
<rawString>Anna Korhonen, Yuval Krymolowski, and Nigel Collier. The Choice of Features for Classification of Verbs in Biomedical Texts. In Proc. of COLING, 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claudia Kunze</author>
<author>Lothar Lemnitzer</author>
</authors>
<title>GermaNetrepresentation, visualization, application.</title>
<date>2002</date>
<booktitle>In Proc. of LREC,</booktitle>
<contexts>
<context position="31702" citStr="Kunze and Lemnitzer, 2002" startWordPosition="5281" endWordPosition="5284">tactic features in supervised classification. Joanis (2002) and Schulte im Walde (2006) experimented with more conventional SPs with syntactic features in English and German verb classification, respectively. They employing top level Method Result T1 Li et al. 2008 supervised 66.3 Joanis et al. 2008 supervised 58.4 Stevenson et al. 2003 semi-supervised 29 unsupervised 31 SPEC unsupervised 57.55 T2 Sun et al. 2008 supervised 62.50 unsupervised 51.6 O´ S´eaghdha et al. 2008 supervised 67.3 SPEC unsupervised 80.35 Table 5: Previous verb classification results WordNet (Miller, 1995) and Germanet (Kunze and Lemnitzer, 2002) classes as SP models. Joanis (2002) obtained no improvement over syntactic features, whereas Schulte im Walde (2006) obtained insignificant improvement. Korhonen et al. (2008) combined SPs with SCFs when clustering biomedical verbs. The SPs were acquired automatically from syntactic slots of SCFs (not from GRs as in our experiment) using PC clustering. A small improvement was obtained using LPs extracted from the same syntactic slots, but the SP clusters offered no improvement. Recently, Schulte im Walde et al. (2008) proposed an interesting SP acquisition method which involves combining EM t</context>
</contexts>
<marker>Kunze, Lemnitzer, 2002</marker>
<rawString>Claudia Kunze and Lothar Lemnitzer. GermaNetrepresentation, visualization, application. In Proc. of LREC, 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lee</author>
</authors>
<title>On the effectiveness of the skew divergence for statistical language analysis.</title>
<date>2001</date>
<booktitle>In Artificial Intelligence and Statistics,</booktitle>
<contexts>
<context position="13152" citStr="Lee, 2001" startWordPosition="2107" endWordPosition="2108">and it has been applied to German verb clustering by Brew and Schulte im Walde (2002). However, previous work has used Ng et al. (2002)’s algorithm, while we adopt the MNCut algorithm. The latter has shown a wider applicability (von Luxburg, 2007; Verma and Meila, 2003) and it can be justified from the random walk view, which has a clear probabilistic interpretation. Clustering groups a given set of items (verbs in our experiment) V = {vn}Nn=1 into a disjoint partition of K classes I = {Ik}Kk=1. Both our algorithms take a similarity matrix as input. We construct this from the skew divergence (Lee, 2001). The skew divergence between two feature vectors v and v&apos; is dskew(v, v&apos;) = D(v&apos;||a·v +(1−a)·v&apos;) where D is the KL-divergence. v is smoothed with v&apos;. The level of smoothing is controlled by a whose value is set to a value close to 1 (e.g. 0.9999). We symmetrize the skew divergence as follows: d(v, v&apos;)sskew = 12(dskew(v, v&apos;) + dskew(v&apos;,v)). SPEC is typically used with the Radial Basis Function (RBF) kernel. We adopt a new kernel similar to the symmetrized KL divergence kernel (Moreno et al., 2004) which avoids the need for scale parameter estimation. w(v, v&apos;) = exp(−dsskew(v, v&apos;)) The similari</context>
</contexts>
<marker>Lee, 2001</marker>
<rawString>Lillian. Lee. On the effectiveness of the skew divergence for statistical language analysis. In Artificial Intelligence and Statistics, 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Geoffrey Leech</author>
</authors>
<title>100 million words of english: the british national corpus. Language Research,</title>
<date>1992</date>
<contexts>
<context position="19141" citStr="Leech, 1992" startWordPosition="3186" endWordPosition="3187">6 422 SCF+POS F6 319 114 299 87 SCF+P F7 282 96 273 76 SCF (V) F8 - - 92 45 SCF+LP(s) F9 1747 324 1474 225 SCF+LP (o) F10 2817 424 2319 279 SCF+LP (all) F11 4250 649 3515 426 SCF+SP20 (s) F12 821 235 690 145 SCF+SP20(o) F13 792 218 706 135 SCF+SP20(all) F14 1333 357 1200 231 SCF+SP30 (s) F15 977 274 903 202 SCF+SP30(o) F16 1026 273 1012 205 SCF+SP30(all) F17 1720 451 1640 330 Table 2: (i) The total number of features and (ii) the average per verb for all the feature sets VALEX lexicon (Korhonen et al., 2006). The data was gathered from five corpora, including e.g. the British National Corpus (Leech, 1992) and the North American News Text Corpus (Graff, 1995). The average frequency of verbs in T1 was 1448 and T2 2166, showing that T1 is a more sparse data set. The data was first processed using the feature extraction module. Table 2 shows (i) the total number of features in each feature set and (ii) the average per verb in the resulting lexicons for T1 and T2. We normalized the feature vectors by the sum of the feature values before applying the clustering techniques. Since both clustering algorithms have 642 an element of randomness, we run them multiple times. The step 5 of SPEC (K-means) was</context>
</contexts>
<marker>Leech, 1992</marker>
<rawString>Geoffrey Leech. 100 million words of english: the british national corpus. Language Research, 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Levin</author>
</authors>
<title>English verb classes and alternations: A preliminary investigation.</title>
<date>1993</date>
<location>Chicago, IL,</location>
<contexts>
<context position="1678" citStr="Levin (1993)" startWordPosition="235" endWordPosition="236">d useful for various important NLP tasks and applications, including e.g. parsing, word sense disambiguation, semantic role labeling, information extraction, question-answering, and machine translation (Swier and Stevenson, 2004; Dang, 2004; Shi and Mihalcea, 2005; Zapirain et al., 2008). Verb classes are useful because they offer a powerful tool for generalization and abstraction which can be beneficial when faced e.g. with the problem of data sparsity. Particularly useful can be classes which capture generalizations over a range of (cross-)linguistic properties, such as the ones proposed by Levin (1993). Being defined in terms of similar meaning and (morpho-)syntactic behaviour of words, Levin style classes generally incorporate a wider range of properties than e.g. classes defined solely on semantic grounds (Miller, 1995). In recent years, a variety of approaches have been proposed for automatic induction of verb classes from corpus data (Schulte im Walde, 2006; Joanis et al., 2008; Sun et al., 2008; Li and Brew, 2008; Korhonen et al., 2008; O´ S´eaghdha and Copestake, 2008; Vlachos et al., 2009). This work opens up the opportunity of learning and tuning classifications tailored to the appl</context>
<context position="4933" citStr="Levin (1993)" startWordPosition="739" endWordPosition="740">obtain our promising results using a fully unsupervised approach to SP acquisition which differs from previous approaches in that it does not exploit WordNet (Miller, 1995) or other lexical resources. It is based on clustering argument head data in the grammatical relations associated with verbs. We describe our features in section 2 and the clustering methods in section 3. Experimental evaluation and results are reported in sections 4 and 5, respectively. Section 6 provides discussion and describes related work, and section 7 concludes. 2 Features Our target classification is the taxonomy of Levin (1993) where verbs taking similar diathesis alternations are assumed to share meaning components and are organized into semantically coherent classes. The main feature of this classification is a diathesis alternation which manifests at the level of syntax in alternating sets of SCF (e.g. in the causative/inchoative alternation an NP frame alternates with an intransitive frame: Tony broke the window ↔ The window broke). Since automatic detection of diathesis alternations is very challenging (McCarthy, 2001), most work on automatic classification has exploited the fact that similar alternations tend </context>
<context position="35864" citStr="Levin, 1993" startWordPosition="5949" endWordPosition="5950">l, SCF and GR data produced by a recent SCF system, (ii) novel syntactic-semantic feature sets which combine a variety of linguistic information, and (iii) a new variation of spectral clustering which is particularly suited for dealing with the resulting, high dimensional feature space. Using this approach, we showed on two well-established test sets that automatically acquired SPs can be highly useful for verb clustering. This result contrasts with most previous works but is in line with theoretical work on verb classification which relies not only on syntactic but also on semantic features (Levin, 1993). In addition to the ideas mentioned earlier, our future plans include looking into optimal ways of acquiring SPs for verb classification. Considerable research has been done on SP acquisition most of which has involved collecting argument headwords from data and generalizing to WordNet classes. Brockmann and Lapata (2003) have showed that WordNet-based approaches do not always outperform simple frequency-based models, and a number of techniques have been recently proposed which may offer ideas for refining our current unsupervised approach (Erk, 2007; Bergsma et al., 2008). The number and typ</context>
</contexts>
<marker>Levin, 1993</marker>
<rawString>Beth. Levin. English verb classes and alternations: A preliminary investigation. Chicago, IL, 1993.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jianguo Li</author>
<author>Chris Brew</author>
</authors>
<title>Which Are the Best Features for Automatic Verb Classification.</title>
<date>2008</date>
<booktitle>In Proc. of ACL,</booktitle>
<contexts>
<context position="2102" citStr="Li and Brew, 2008" startWordPosition="301" endWordPosition="304">e.g. with the problem of data sparsity. Particularly useful can be classes which capture generalizations over a range of (cross-)linguistic properties, such as the ones proposed by Levin (1993). Being defined in terms of similar meaning and (morpho-)syntactic behaviour of words, Levin style classes generally incorporate a wider range of properties than e.g. classes defined solely on semantic grounds (Miller, 1995). In recent years, a variety of approaches have been proposed for automatic induction of verb classes from corpus data (Schulte im Walde, 2006; Joanis et al., 2008; Sun et al., 2008; Li and Brew, 2008; Korhonen et al., 2008; O´ S´eaghdha and Copestake, 2008; Vlachos et al., 2009). This work opens up the opportunity of learning and tuning classifications tailored to the application and domain in question. Although manual classification may always yields higher accuracy, automatic verb classification is cost-effective and gathers statistical information as a side-effect of the acquisition process which is difficult for humans to gather but can be highly useful for NLP applications. To date, both supervised and unsupervised machine learning (ML) methods have been proposed for verb classificat</context>
<context position="9157" citStr="Li and Brew, 2008" startWordPosition="1406" endWordPosition="1409">ssifier provided by Paula Buttery. 4These and other threshold values mentioned in this paper were determined empirically on corpus data. 639 for experimentation, both shallow and deep syntactic and semantic features. As described below, some of the feature types have been employed in previous works and some are novel. F8: Basic SCF feature corresponding to F4 but extracted from the VALEX lexicon (Korhonen et al., 2006)5. 2.2 Feature sets The first feature set F1 includes information about the lexical context (co-occurrences) of verbs which has proved useful for supervised verb classification (Li and Brew, 2008): F1: Co-occurrence (CO): We adopt the best method of Li and Brew (2008) where collocations are extracted from the four words immediately preceding and following a lemmatized verb. Stop words are removed prior to extraction, and the 600 most frequent resulting COs are kept. F2-F3 provide information about lexical preferences of verbs in argument head positions of specific GRs associated with the verb: F2: Prepositional preference (PP): the type and frequency of prepositions in the indirect object relation. F3: Lexical preference (LP): the type and frequency of nouns and prepositions in the sub</context>
<context position="23918" citStr="Li and Brew (2008)" startWordPosition="4018" endWordPosition="4021">strates the usefulness of lexical data when obtained from argument positions in relevant GRs. Our basic SCF feature set F4 performs considerably better than the comparable feature set F8 obtained from the VALEX lexicon. The difference is 19.50 in F-measure. As both lexicons were extracted from the same corpus data, the improvement can be attributed to improved parser and SCF acquisition performance (Preiss et al., 2007). F5-F7 refine the basic SCF feature set F4 further. F5 which combines a SCF with CO information proved the best feature set in the supervised verb classification experiment of Li and Brew (2008). In our experiment, F5 produces substantially lower result than CO and SCF alone (i.e. 643 F1 and F4). However, our corpus is smaller (Li and Brew used the large Gigaword corpus), our SCFs are different, and our approach is unsupervised, making meaningful comparisons difficult. F6 combines F4 with information about verb tense. This was not helpful: F6 produces worse results than F4. F7, on the other hand, yields better results than F4 on both test sets. This demonstrates what the previous research has shown: SCF perform better when parameterized for prepositions. Looking at our novel feature </context>
<context position="33570" citStr="Li and Brew (2008)" startWordPosition="5578" endWordPosition="5581">o German (rather than to English), and although no SP features were used, these earlier experiments did demonstrate the ability of the method to perform well in high dimensional feature space. To get an idea of how our performance compares with that of related approaches, we examined recent works on verb classification (supervised and unsupervised) which were evaluated on same test sets using comparable evaluation measures. These works are summarized in table 5. ACC and F-measure are shown for T1 and T2, respectively. 645 On T1, the best performing supervised method reported so far is that of Li and Brew (2008). Li and Brew used Bayesian Multinomial Regression for classification. A range of feature sets integrating COs, SCFs and/or LPs were evaluated. The combination of COs and SCFs gave the best result, shown in the table. Joanis et al. (2008) report the second best supervised result on T1, using Support Vector Machines for classification and features derived from linguistic analysis: syntactic slots, slot overlaps, tense, voice, aspect, and animacy of NPs. Stevenson and Joanis (2003) report a semi- and unsupervised experiment on T1. A feature set similar to that of Joanis et al. (2008) was employe</context>
</contexts>
<marker>Li, Brew, 2008</marker>
<rawString>Jianguo Li and Chris Brew. Which Are the Best Features for Automatic Verb Classification. In Proc. of ACL, 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana McCarthy</author>
</authors>
<title>Lexical Acquisition at the SyntaxSemantics Interface: Diathesis Alternations, Subcategorization Frames and Selectional Preferences.</title>
<date>2001</date>
<tech>PhD thesis,</tech>
<institution>University of Sussex,</institution>
<location>UK,</location>
<contexts>
<context position="5439" citStr="McCarthy, 2001" startWordPosition="816" endWordPosition="817">s related work, and section 7 concludes. 2 Features Our target classification is the taxonomy of Levin (1993) where verbs taking similar diathesis alternations are assumed to share meaning components and are organized into semantically coherent classes. The main feature of this classification is a diathesis alternation which manifests at the level of syntax in alternating sets of SCF (e.g. in the causative/inchoative alternation an NP frame alternates with an intransitive frame: Tony broke the window ↔ The window broke). Since automatic detection of diathesis alternations is very challenging (McCarthy, 2001), most work on automatic classification has exploited the fact that similar alternations tend to result in similar SCFs. The research reported so far1 has used mainly syntactic features for classification, ranging from shallow syntactic slots (e.g. NPs preceding or following the verb) to SCFs. Some researchers have discovered that supplementing basic syntactic features with information about adjuncts, co-occurrences, tense, and/or voice of the verb have resulted in better performance. However, additional information about semantic SPs of verbs has not yielded considerable improvement on verb c</context>
</contexts>
<marker>McCarthy, 2001</marker>
<rawString>Diana McCarthy. Lexical Acquisition at the SyntaxSemantics Interface: Diathesis Alternations, Subcategorization Frames and Selectional Preferences. PhD thesis, University of Sussex, UK, 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Meila</author>
</authors>
<title>The multicut lemma.</title>
<date>2001</date>
<tech>Technical report,</tech>
<institution>University of Washington,</institution>
<contexts>
<context position="15082" citStr="Meila, 2001" startWordPosition="2456" endWordPosition="2457">= EmEA,nEA&apos; Wmn. In MNCut algorithm, the similarity matrix W is transformed to a stochastic matrix P. P = D−1W (1) The degree matrix D is a diagonal matrix where Dii = di. It was shown by Meila and Shi (2001) that if P has the K leading eigenvectors that are piecewise constant6 with respect to a partition I* and their eigenvalues are not zero, then I* minimizes the multiway normalized cut(MNCut): MNCut (I) = K − K Cut(Ik,Ik) ( ) �k=1 Cut(Ik,I) Pmn can be interpreted as the transition probability between vertices m, n. The criterion can thus be expressed as MNCut(I) = EKk=1(1 − P(Ik → Ik|Ik)) (Meila, 2001), which is the sum of transition probabilities across different clusters. The criterion finds the partition where the random walks are most likely to happen within the same cluster. In practice, the K leading eigenvectors of P is not piecewise constant. But we can extract the partition by finding the approximately equal elements in the eigenvectors using a clustering algorithm like K-means. The numerator of MNCut is similar to the cost function of PC. The main differences between the two algorithms are: 1) MNCut takes into account of the cross cluster similarity, while PC does not. 2) PC optim</context>
</contexts>
<marker>Meila, 2001</marker>
<rawString>Marina. Meila. The multicut lemma. Technical report, University of Washington, 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marina Meila</author>
<author>Jianbo Shi</author>
</authors>
<title>A random walks view of spectral segmentation.</title>
<date>2001</date>
<publisher>AISTATS,</publisher>
<contexts>
<context position="4018" citStr="Meila and Shi, 2001" startWordPosition="593" endWordPosition="596"> for the task. We introduce a novel approach to verb clustering which involves the use of (i) a recent subcategorization frame (SCF) acquisition system (Preiss et al., 2007) which produces rich lexical, SCF and syntactic data, (ii) novel syntactic-semantic feature sets extracted from this data which incorporate a variety of linguistic information, including SPs, and (iii) a new variation of spectral cluster638 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 638–647, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP ing based on the MNCut algorithm (Meila and Shi, 2001) which is well-suited for dealing with the resulting, high dimensional feature space. Using this approach, we show on two wellestablished test sets that automatically acquired SPs can be highly useful for verb clustering. They yield high performance when used in combination with syntactic features. We obtain our promising results using a fully unsupervised approach to SP acquisition which differs from previous approaches in that it does not exploit WordNet (Miller, 1995) or other lexical resources. It is based on clustering argument head data in the grammatical relations associated with verbs.</context>
<context position="12414" citStr="Meila and Shi, 2001" startWordPosition="1974" endWordPosition="1977">heads) are used instead of LPs 5This feature was included to enable comparing the contribution of the recent SCF system to that of an older, comparable system which was used for constructing the VALEX lexicon. 640 3 Clustering methods We use two clustering methods: (i) pairwise clustering (PC) which obtained the best performance in comparison with several other methods in recent work on biomedical verb clustering (Korhonen et al., 2008), and (ii) a method which is new to the task (and to the best of our knowledge, to NLP): a variation of spectral clustering which exploits the MNCut algorithm (Meila and Shi, 2001) (SPEC). Spectral clustering has been shown to be effective for high dimensional and non-convex data in NLP (Chen et al., 2006) and it has been applied to German verb clustering by Brew and Schulte im Walde (2002). However, previous work has used Ng et al. (2002)’s algorithm, while we adopt the MNCut algorithm. The latter has shown a wider applicability (von Luxburg, 2007; Verma and Meila, 2003) and it can be justified from the random walk view, which has a clear probabilistic interpretation. Clustering groups a given set of items (verbs in our experiment) V = {vn}Nn=1 into a disjoint partitio</context>
<context position="14678" citStr="Meila and Shi (2001)" startWordPosition="2383" endWordPosition="2386">a,b) Avgsimj = nj·(nj−1) where nj is the size of the jth cluster and Avgsimj is the average similarity between cluster members. Spectral clustering In SPEC, the similarities Wij are viewed as the weight on the edges ij of a graph G over V . The similarity matrix W is thus the adjacency matrix for G. The degree of a vertex i is di = EN j=1 wij. A cut between two partitions A and A&apos; is defined to be Cut(A, A&apos;) = EmEA,nEA&apos; Wmn. In MNCut algorithm, the similarity matrix W is transformed to a stochastic matrix P. P = D−1W (1) The degree matrix D is a diagonal matrix where Dii = di. It was shown by Meila and Shi (2001) that if P has the K leading eigenvectors that are piecewise constant6 with respect to a partition I* and their eigenvalues are not zero, then I* minimizes the multiway normalized cut(MNCut): MNCut (I) = K − K Cut(Ik,Ik) ( ) �k=1 Cut(Ik,I) Pmn can be interpreted as the transition probability between vertices m, n. The criterion can thus be expressed as MNCut(I) = EKk=1(1 − P(Ik → Ik|Ik)) (Meila, 2001), which is the sum of transition probabilities across different clusters. The criterion finds the partition where the random walks are most likely to happen within the same cluster. In practice, t</context>
</contexts>
<marker>Meila, Shi, 2001</marker>
<rawString>Marina Meila and Jianbo Shi. A random walks view of spectral segmentation. AISTATS, 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
</authors>
<title>WordNet: a lexical database for English.</title>
<date>1995</date>
<journal>Communications of the ACM,</journal>
<contexts>
<context position="1902" citStr="Miller, 1995" startWordPosition="268" endWordPosition="269"> 2004; Dang, 2004; Shi and Mihalcea, 2005; Zapirain et al., 2008). Verb classes are useful because they offer a powerful tool for generalization and abstraction which can be beneficial when faced e.g. with the problem of data sparsity. Particularly useful can be classes which capture generalizations over a range of (cross-)linguistic properties, such as the ones proposed by Levin (1993). Being defined in terms of similar meaning and (morpho-)syntactic behaviour of words, Levin style classes generally incorporate a wider range of properties than e.g. classes defined solely on semantic grounds (Miller, 1995). In recent years, a variety of approaches have been proposed for automatic induction of verb classes from corpus data (Schulte im Walde, 2006; Joanis et al., 2008; Sun et al., 2008; Li and Brew, 2008; Korhonen et al., 2008; O´ S´eaghdha and Copestake, 2008; Vlachos et al., 2009). This work opens up the opportunity of learning and tuning classifications tailored to the application and domain in question. Although manual classification may always yields higher accuracy, automatic verb classification is cost-effective and gathers statistical information as a side-effect of the acquisition proces</context>
<context position="4493" citStr="Miller, 1995" startWordPosition="669" endWordPosition="670">anguage Processing, pages 638–647, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP ing based on the MNCut algorithm (Meila and Shi, 2001) which is well-suited for dealing with the resulting, high dimensional feature space. Using this approach, we show on two wellestablished test sets that automatically acquired SPs can be highly useful for verb clustering. They yield high performance when used in combination with syntactic features. We obtain our promising results using a fully unsupervised approach to SP acquisition which differs from previous approaches in that it does not exploit WordNet (Miller, 1995) or other lexical resources. It is based on clustering argument head data in the grammatical relations associated with verbs. We describe our features in section 2 and the clustering methods in section 3. Experimental evaluation and results are reported in sections 4 and 5, respectively. Section 6 provides discussion and describes related work, and section 7 concludes. 2 Features Our target classification is the taxonomy of Levin (1993) where verbs taking similar diathesis alternations are assumed to share meaning components and are organized into semantically coherent classes. The main featur</context>
<context position="31661" citStr="Miller, 1995" startWordPosition="5277" endWordPosition="5278">used in conjunction with syntactic features in supervised classification. Joanis (2002) and Schulte im Walde (2006) experimented with more conventional SPs with syntactic features in English and German verb classification, respectively. They employing top level Method Result T1 Li et al. 2008 supervised 66.3 Joanis et al. 2008 supervised 58.4 Stevenson et al. 2003 semi-supervised 29 unsupervised 31 SPEC unsupervised 57.55 T2 Sun et al. 2008 supervised 62.50 unsupervised 51.6 O´ S´eaghdha et al. 2008 supervised 67.3 SPEC unsupervised 80.35 Table 5: Previous verb classification results WordNet (Miller, 1995) and Germanet (Kunze and Lemnitzer, 2002) classes as SP models. Joanis (2002) obtained no improvement over syntactic features, whereas Schulte im Walde (2006) obtained insignificant improvement. Korhonen et al. (2008) combined SPs with SCFs when clustering biomedical verbs. The SPs were acquired automatically from syntactic slots of SCFs (not from GRs as in our experiment) using PC clustering. A small improvement was obtained using LPs extracted from the same syntactic slots, but the SP clusters offered no improvement. Recently, Schulte im Walde et al. (2008) proposed an interesting SP acquisi</context>
</contexts>
<marker>Miller, 1995</marker>
<rawString>George A. Miller. WordNet: a lexical database for English. Communications of the ACM, 1995.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pedro J Moreno</author>
<author>Purdy P Ho</author>
<author>Nuno Vasconcelos</author>
</authors>
<title>A Kullback-Leibler divergence based kernel for SVM classification in multimedia applications.</title>
<date>2004</date>
<booktitle>In Proc. of NIPS,</booktitle>
<contexts>
<context position="13654" citStr="Moreno et al., 2004" startWordPosition="2192" endWordPosition="2195">Ik}Kk=1. Both our algorithms take a similarity matrix as input. We construct this from the skew divergence (Lee, 2001). The skew divergence between two feature vectors v and v&apos; is dskew(v, v&apos;) = D(v&apos;||a·v +(1−a)·v&apos;) where D is the KL-divergence. v is smoothed with v&apos;. The level of smoothing is controlled by a whose value is set to a value close to 1 (e.g. 0.9999). We symmetrize the skew divergence as follows: d(v, v&apos;)sskew = 12(dskew(v, v&apos;) + dskew(v&apos;,v)). SPEC is typically used with the Radial Basis Function (RBF) kernel. We adopt a new kernel similar to the symmetrized KL divergence kernel (Moreno et al., 2004) which avoids the need for scale parameter estimation. w(v, v&apos;) = exp(−dsskew(v, v&apos;)) The similarity matrix W is constructed where Wij = w(vi, vj). Pairwise clustering PC (Puzicha et al., 2000) is a method where a cost criterion guides the search for a suitable partition. This criterion is realized through a cost function of the similarity matrix W and partition I: H = − E�n-+j · Avgsimj, L{a,b∈Aj} w(a,b) Avgsimj = nj·(nj−1) where nj is the size of the jth cluster and Avgsimj is the average similarity between cluster members. Spectral clustering In SPEC, the similarities Wij are viewed as the </context>
</contexts>
<marker>Moreno, Ho, Vasconcelos, 2004</marker>
<rawString>Pedro J. Moreno, Purdy P. Ho, and Nuno Vasconcelos. A Kullback-Leibler divergence based kernel for SVM classification in multimedia applications. In Proc. of NIPS, 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Y Ng</author>
<author>Michael Jordan</author>
<author>Yair Weiss</author>
</authors>
<title>On spectral clustering: Analysis and an algorithm.</title>
<date>2002</date>
<booktitle>In Proc. of NIPS,</booktitle>
<contexts>
<context position="12677" citStr="Ng et al. (2002)" startWordPosition="2021" endWordPosition="2024">i) pairwise clustering (PC) which obtained the best performance in comparison with several other methods in recent work on biomedical verb clustering (Korhonen et al., 2008), and (ii) a method which is new to the task (and to the best of our knowledge, to NLP): a variation of spectral clustering which exploits the MNCut algorithm (Meila and Shi, 2001) (SPEC). Spectral clustering has been shown to be effective for high dimensional and non-convex data in NLP (Chen et al., 2006) and it has been applied to German verb clustering by Brew and Schulte im Walde (2002). However, previous work has used Ng et al. (2002)’s algorithm, while we adopt the MNCut algorithm. The latter has shown a wider applicability (von Luxburg, 2007; Verma and Meila, 2003) and it can be justified from the random walk view, which has a clear probabilistic interpretation. Clustering groups a given set of items (verbs in our experiment) V = {vn}Nn=1 into a disjoint partition of K classes I = {Ik}Kk=1. Both our algorithms take a similarity matrix as input. We construct this from the skew divergence (Lee, 2001). The skew divergence between two feature vectors v and v&apos; is dskew(v, v&apos;) = D(v&apos;||a·v +(1−a)·v&apos;) where D is the KL-divergenc</context>
</contexts>
<marker>Ng, Jordan, Weiss, 2002</marker>
<rawString>Andrew Y. Ng, Michael Jordan, and Yair Weiss. On spectral clustering: Analysis and an algorithm. In Proc. of NIPS, 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diarmuid O´ S´eaghdha</author>
<author>Ann Copestake</author>
</authors>
<title>Semantic classification with distributional kernels.</title>
<date>2008</date>
<booktitle>In Proc. of COLING,</booktitle>
<marker>S´eaghdha, Copestake, 2008</marker>
<rawString>Diarmuid O´ S´eaghdha and Ann Copestake. Semantic classification with distributional kernels. In Proc. of COLING, 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Judita Preiss</author>
<author>Ted Briscoe</author>
<author>Anna Korhonen</author>
</authors>
<title>A system for large-scale acquisition of verbal, nominal and adjectival subcategorization frames from corpora.</title>
<date>2007</date>
<booktitle>In Proc. of ACL,</booktitle>
<contexts>
<context position="3571" citStr="Preiss et al., 2007" startWordPosition="524" endWordPosition="527">)). Disappointingly, semantic features have not yielded significant additional improvement, although they play a key role in manual and theoretical work on verb classification and could thus be expected to offer a considerable contribution to classification performance. Since the accuracy of automatic verb classification shows room for improvement, we further investigate the potential of semantic features – verb selectional preferences (SPs) – for the task. We introduce a novel approach to verb clustering which involves the use of (i) a recent subcategorization frame (SCF) acquisition system (Preiss et al., 2007) which produces rich lexical, SCF and syntactic data, (ii) novel syntactic-semantic feature sets extracted from this data which incorporate a variety of linguistic information, including SPs, and (iii) a new variation of spectral cluster638 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 638–647, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP ing based on the MNCut algorithm (Meila and Shi, 2001) which is well-suited for dealing with the resulting, high dimensional feature space. Using this approach, we show on two wellestablished test sets that </context>
<context position="7282" citStr="Preiss et al. (2007)" startWordPosition="1099" endWordPosition="1102">he data may be sparse, and the resulting feature vectors integrating both syntactic and semantic features may be high dimensional. However, we wanted to investigate whether better results could be obtained if the features were optimised for richness, the feature extraction for accuracy, and a clustering method capable of dealing with the resulting high dimensional feature space was employed. 2.1 Feature extraction We adopted a recent SCF acquisition system which has proved more accurate than previous comparable systems2 but which has not been employed for verb clustering before: the system of Preiss et al. (2007). This system tags, lemmatizes and parses corpus data using the current version of the RASP (Robust Accurate Statistical Parsing) toolkit (Briscoe et al., 2006), and on the basis of resulting grammatical relations (GRs) assigns each occurrence of a verb to one of 168 verbal SCFs classes3. The system provides a filter which can be used to remove adjuncts from the resulting lexicon. We do not employ this filter since adjuncts have proved informative for verb classification (Sun et al., 2008; Joanis et al., 2008). However, we do frequency-based thresholding to minimise the noise (e.g. erroneous s</context>
<context position="23723" citStr="Preiss et al., 2007" startWordPosition="3982" endWordPosition="3985">ntly better than F1. F3 yields surprisingly good results on T2: it is the second best feature set on this test set. Also on T1, F3 performs better than the SCF-based feature sets F4- F7. This demonstrates the usefulness of lexical data when obtained from argument positions in relevant GRs. Our basic SCF feature set F4 performs considerably better than the comparable feature set F8 obtained from the VALEX lexicon. The difference is 19.50 in F-measure. As both lexicons were extracted from the same corpus data, the improvement can be attributed to improved parser and SCF acquisition performance (Preiss et al., 2007). F5-F7 refine the basic SCF feature set F4 further. F5 which combines a SCF with CO information proved the best feature set in the supervised verb classification experiment of Li and Brew (2008). In our experiment, F5 produces substantially lower result than CO and SCF alone (i.e. 643 F1 and F4). However, our corpus is smaller (Li and Brew used the large Gigaword corpus), our SCFs are different, and our approach is unsupervised, making meaningful comparisons difficult. F6 combines F4 with information about verb tense. This was not helpful: F6 produces worse results than F4. F7, on the other h</context>
</contexts>
<marker>Preiss, Briscoe, Korhonen, 2007</marker>
<rawString>Judita Preiss, Ted Briscoe, and Anna Korhonen. A system for large-scale acquisition of verbal, nominal and adjectival subcategorization frames from corpora. In Proc. of ACL, 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Puzicha</author>
<author>Thomas Hofmann</author>
<author>Joachim M Buhmann</author>
</authors>
<title>A theory of proximity based clustering: Structure detection by optimization. Pattern Recognition,</title>
<date>2000</date>
<contexts>
<context position="13847" citStr="Puzicha et al., 2000" startWordPosition="2223" endWordPosition="2226"> = D(v&apos;||a·v +(1−a)·v&apos;) where D is the KL-divergence. v is smoothed with v&apos;. The level of smoothing is controlled by a whose value is set to a value close to 1 (e.g. 0.9999). We symmetrize the skew divergence as follows: d(v, v&apos;)sskew = 12(dskew(v, v&apos;) + dskew(v&apos;,v)). SPEC is typically used with the Radial Basis Function (RBF) kernel. We adopt a new kernel similar to the symmetrized KL divergence kernel (Moreno et al., 2004) which avoids the need for scale parameter estimation. w(v, v&apos;) = exp(−dsskew(v, v&apos;)) The similarity matrix W is constructed where Wij = w(vi, vj). Pairwise clustering PC (Puzicha et al., 2000) is a method where a cost criterion guides the search for a suitable partition. This criterion is realized through a cost function of the similarity matrix W and partition I: H = − E�n-+j · Avgsimj, L{a,b∈Aj} w(a,b) Avgsimj = nj·(nj−1) where nj is the size of the jth cluster and Avgsimj is the average similarity between cluster members. Spectral clustering In SPEC, the similarities Wij are viewed as the weight on the edges ij of a graph G over V . The similarity matrix W is thus the adjacency matrix for G. The degree of a vertex i is di = EN j=1 wij. A cut between two partitions A and A&apos; is de</context>
</contexts>
<marker>Puzicha, Hofmann, Buhmann, 2000</marker>
<rawString>Jan Puzicha, Thomas Hofmann, and Joachim M. Buhmann. A theory of proximity based clustering: Structure detection by optimization. Pattern Recognition, 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Schulte im Walde</author>
</authors>
<title>Experiments on the automatic induction of german semantic verb classes. Computational Linguistics,</title>
<date>2006</date>
<contexts>
<context position="2044" citStr="Walde, 2006" startWordPosition="291" endWordPosition="292"> and abstraction which can be beneficial when faced e.g. with the problem of data sparsity. Particularly useful can be classes which capture generalizations over a range of (cross-)linguistic properties, such as the ones proposed by Levin (1993). Being defined in terms of similar meaning and (morpho-)syntactic behaviour of words, Levin style classes generally incorporate a wider range of properties than e.g. classes defined solely on semantic grounds (Miller, 1995). In recent years, a variety of approaches have been proposed for automatic induction of verb classes from corpus data (Schulte im Walde, 2006; Joanis et al., 2008; Sun et al., 2008; Li and Brew, 2008; Korhonen et al., 2008; O´ S´eaghdha and Copestake, 2008; Vlachos et al., 2009). This work opens up the opportunity of learning and tuning classifications tailored to the application and domain in question. Although manual classification may always yields higher accuracy, automatic verb classification is cost-effective and gathers statistical information as a side-effect of the acquisition process which is difficult for humans to gather but can be highly useful for NLP applications. To date, both supervised and unsupervised machine lea</context>
<context position="9943" citStr="Walde, 2006" startWordPosition="1537" endWordPosition="1538">verb. Stop words are removed prior to extraction, and the 600 most frequent resulting COs are kept. F2-F3 provide information about lexical preferences of verbs in argument head positions of specific GRs associated with the verb: F2: Prepositional preference (PP): the type and frequency of prepositions in the indirect object relation. F3: Lexical preference (LP): the type and frequency of nouns and prepositions in the subject, object, and indirect object relation. All the other feature sets include information about SCFs which have been widely employed in verb classification, e.g. (Schulte im Walde, 2006; Sun et al., 2008; Li and Brew, 2008; Korhonen et al., 2008). F4-F7 include basic SCF information and/or refine it with additional information which has proved useful in previous works: F4: SCFs and relative frequencies with verbs. SCFs abstract over particles and prepositions. F5: F4 with COs (F1). The SCF and CO feature vectors are concatenated. F6: F4 with the tense of the verb. The frequency of verbal POS tags is calculated specific to each SCF. F7: F4 with PPs (F2). This feature parameterizes SCFs for prepositions. The following 9 feature sets are novel. They build on F7, refining it fur</context>
<context position="31163" citStr="Walde (2006)" startWordPosition="5201" endWordPosition="5202">nt GRs. 6 Discussion and related work Although features incorporating semantic information about verb SPs make theoretical sense they have not proved equally promising in previous experiments which have compared them against syntactic features in verb classification. Joanis et al. (2008) incorporated an ’animacy’ feature (a kind of a ’SP’) which was determined by classifying e.g. pronouns and proper names in data to this single SP class. A small improvement was obtained when this feature was used in conjunction with syntactic features in supervised classification. Joanis (2002) and Schulte im Walde (2006) experimented with more conventional SPs with syntactic features in English and German verb classification, respectively. They employing top level Method Result T1 Li et al. 2008 supervised 66.3 Joanis et al. 2008 supervised 58.4 Stevenson et al. 2003 semi-supervised 29 unsupervised 31 SPEC unsupervised 57.55 T2 Sun et al. 2008 supervised 62.50 unsupervised 51.6 O´ S´eaghdha et al. 2008 supervised 67.3 SPEC unsupervised 80.35 Table 5: Previous verb classification results WordNet (Miller, 1995) and Germanet (Kunze and Lemnitzer, 2002) classes as SP models. Joanis (2002) obtained no improvement </context>
</contexts>
<marker>Walde, 2006</marker>
<rawString>Sabine Schulte im Walde. Experiments on the automatic induction of german semantic verb classes. Computational Linguistics, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Schulte im Walde</author>
<author>Christian Hying</author>
<author>Christian Scheible</author>
<author>Helmut Schmid</author>
</authors>
<title>Combining EM Training and the MDL Principle for an Automatic Verb Classification incorporating Selectional Preferences.</title>
<date>2008</date>
<booktitle>In Proc. of ACL,</booktitle>
<pages>496--504</pages>
<contexts>
<context position="32226" citStr="Walde et al. (2008)" startWordPosition="5362" endWordPosition="5365">ous verb classification results WordNet (Miller, 1995) and Germanet (Kunze and Lemnitzer, 2002) classes as SP models. Joanis (2002) obtained no improvement over syntactic features, whereas Schulte im Walde (2006) obtained insignificant improvement. Korhonen et al. (2008) combined SPs with SCFs when clustering biomedical verbs. The SPs were acquired automatically from syntactic slots of SCFs (not from GRs as in our experiment) using PC clustering. A small improvement was obtained using LPs extracted from the same syntactic slots, but the SP clusters offered no improvement. Recently, Schulte im Walde et al. (2008) proposed an interesting SP acquisition method which involves combining EM training and the MDL principle for an verb classification incorporating SPs. However, no comparison against purely syntactic features is provided. In our experiment, we obtained a considerable improvement over syntactic features, despite using a fully unsupervised approach to both verb clustering and SP acquisition. In addition to the rich, syntactic-semantic feature sets, our good results can be attributed to the clustering technique capable of dealing with them. The potential of spectral clustering for the task was re</context>
</contexts>
<marker>Walde, Hying, Scheible, Schmid, 2008</marker>
<rawString>Sabine Schulte im Walde, Christian Hying, Christian Scheible, and Helmut Schmid. Combining EM Training and the MDL Principle for an Automatic Verb Classification incorporating Selectional Preferences. In Proc. of ACL, pages 496–504, 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lei Shi</author>
<author>Rada Mihalcea</author>
</authors>
<title>Putting pieces together: Combining FrameNet, VerbNet and WordNet for robust semantic parsing.</title>
<date>2005</date>
<booktitle>In Proc. of CICLING,</booktitle>
<contexts>
<context position="1330" citStr="Shi and Mihalcea, 2005" startWordPosition="179" endWordPosition="182">r verb clustering which incorporates a recent subcategorization acquisition system, rich syntactic-semantic feature sets, and a variation of spectral clustering which performs particularly well in high dimensional feature space. 1 Introduction Verb classifications have attracted a great deal of interest in natural language processing (NLP). They have proved useful for various important NLP tasks and applications, including e.g. parsing, word sense disambiguation, semantic role labeling, information extraction, question-answering, and machine translation (Swier and Stevenson, 2004; Dang, 2004; Shi and Mihalcea, 2005; Zapirain et al., 2008). Verb classes are useful because they offer a powerful tool for generalization and abstraction which can be beneficial when faced e.g. with the problem of data sparsity. Particularly useful can be classes which capture generalizations over a range of (cross-)linguistic properties, such as the ones proposed by Levin (1993). Being defined in terms of similar meaning and (morpho-)syntactic behaviour of words, Levin style classes generally incorporate a wider range of properties than e.g. classes defined solely on semantic grounds (Miller, 1995). In recent years, a variety</context>
</contexts>
<marker>Shi, Mihalcea, 2005</marker>
<rawString>Lei Shi and Rada Mihalcea. Putting pieces together: Combining FrameNet, VerbNet and WordNet for robust semantic parsing. In Proc. of CICLING, 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Suzanne Stevenson</author>
<author>Eric Joanis</author>
</authors>
<title>Semi-supervised verb class discovery using noisy features.</title>
<date>2003</date>
<booktitle>In Proc. of HLT-NAACL</booktitle>
<pages>71--78</pages>
<contexts>
<context position="17281" citStr="Stevenson and Joanis (2003)" startWordPosition="2838" endWordPosition="2841">s work on English verb classification: T1 The test set of Joanis et al. (2008) provides a classification of 835 verbs into 15 (some coarse, some fine-grained) Levin classes. 11 tests are provided for 2-14 way classifications. We employ the 14 way classification because this corresponds the closest to our target (Levin’s fine-grained) classification7. We select 586 verbs according to Joanis et al.’s selection criteria, resulting in 10- 120 verbs per class. We restrict the class imbalance to 1:1.5.8. This yields 205 verbs (10-15 verbs per class) which is similar to the sub-set of T1 employed by Stevenson and Joanis (2003). T2 The test set of Sun et al. (2008) classifies 204 verbs to 17 fine-grained Levin classes, so that each class has 12 member verbs. Table 1 shows the classes in T1 and T2. 4.2 Data processing For each verb in T1 and T2, we extracted all the occurrences (up to 10,000) from the raw corpus data gathered originally for constructing the 7However, the correspondence is not perfect with half of the classes including two or more Levin’s fine-grained classes. 8Otherwise, in the case of a large class imbalance the evaluation measure would be dominated by the classes with large population. T1 T2 Object</context>
<context position="34054" citStr="Stevenson and Joanis (2003)" startWordPosition="5654" endWordPosition="5657">F-measure are shown for T1 and T2, respectively. 645 On T1, the best performing supervised method reported so far is that of Li and Brew (2008). Li and Brew used Bayesian Multinomial Regression for classification. A range of feature sets integrating COs, SCFs and/or LPs were evaluated. The combination of COs and SCFs gave the best result, shown in the table. Joanis et al. (2008) report the second best supervised result on T1, using Support Vector Machines for classification and features derived from linguistic analysis: syntactic slots, slot overlaps, tense, voice, aspect, and animacy of NPs. Stevenson and Joanis (2003) report a semi- and unsupervised experiment on T1. A feature set similar to that of Joanis et al. (2008) was employed (features were selected in a semi-supervised fashion) and hierarchical clustering was used. Our unsupervised method SPEC performs substantially better than the unsupervised method of Stevenson et al. and nearly as well as the supervised approach of Joanis et al. (2008) (note, however, that the different experiments involved different sub-sets of T1 so are not entirely comparable). On T2, the best performing supervised method so far is that of O´ S´eaghdha and Copestake (2008) w</context>
</contexts>
<marker>Stevenson, Joanis, 2003</marker>
<rawString>Suzanne Stevenson and Eric Joanis. Semi-supervised verb class discovery using noisy features. In Proc. of HLT-NAACL 2003, pages 71–78, 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lin Sun</author>
<author>Anna Korhonen</author>
<author>Yuval Krymolowski</author>
</authors>
<title>Verb class discovery from rich syntactic data.</title>
<date>2008</date>
<journal>Lecture Notes in Computer Science,</journal>
<volume>4919</volume>
<contexts>
<context position="2083" citStr="Sun et al., 2008" startWordPosition="297" endWordPosition="300">ficial when faced e.g. with the problem of data sparsity. Particularly useful can be classes which capture generalizations over a range of (cross-)linguistic properties, such as the ones proposed by Levin (1993). Being defined in terms of similar meaning and (morpho-)syntactic behaviour of words, Levin style classes generally incorporate a wider range of properties than e.g. classes defined solely on semantic grounds (Miller, 1995). In recent years, a variety of approaches have been proposed for automatic induction of verb classes from corpus data (Schulte im Walde, 2006; Joanis et al., 2008; Sun et al., 2008; Li and Brew, 2008; Korhonen et al., 2008; O´ S´eaghdha and Copestake, 2008; Vlachos et al., 2009). This work opens up the opportunity of learning and tuning classifications tailored to the application and domain in question. Although manual classification may always yields higher accuracy, automatic verb classification is cost-effective and gathers statistical information as a side-effect of the acquisition process which is difficult for humans to gather but can be highly useful for NLP applications. To date, both supervised and unsupervised machine learning (ML) methods have been proposed f</context>
<context position="7775" citStr="Sun et al., 2008" startWordPosition="1180" endWordPosition="1183">previous comparable systems2 but which has not been employed for verb clustering before: the system of Preiss et al. (2007). This system tags, lemmatizes and parses corpus data using the current version of the RASP (Robust Accurate Statistical Parsing) toolkit (Briscoe et al., 2006), and on the basis of resulting grammatical relations (GRs) assigns each occurrence of a verb to one of 168 verbal SCFs classes3. The system provides a filter which can be used to remove adjuncts from the resulting lexicon. We do not employ this filter since adjuncts have proved informative for verb classification (Sun et al., 2008; Joanis et al., 2008). However, we do frequency-based thresholding to minimise the noise (e.g. erroneous scfs) and sparse data in verb classification and to ensure that only features supported by several verbs are used in classification: we only consider SCFs and GRs which have frequency larger than 40 with 5 or more verbs4. The system produces a rich lexicon which includes raw and processed input sentences and provides a variety of material for verb clustering, including e.g. (statistical) information related to the part-of-speech (POS) tags, GRs, SCFs, argument heads, and adjuncts of verbs.</context>
<context position="9961" citStr="Sun et al., 2008" startWordPosition="1539" endWordPosition="1542">rds are removed prior to extraction, and the 600 most frequent resulting COs are kept. F2-F3 provide information about lexical preferences of verbs in argument head positions of specific GRs associated with the verb: F2: Prepositional preference (PP): the type and frequency of prepositions in the indirect object relation. F3: Lexical preference (LP): the type and frequency of nouns and prepositions in the subject, object, and indirect object relation. All the other feature sets include information about SCFs which have been widely employed in verb classification, e.g. (Schulte im Walde, 2006; Sun et al., 2008; Li and Brew, 2008; Korhonen et al., 2008). F4-F7 include basic SCF information and/or refine it with additional information which has proved useful in previous works: F4: SCFs and relative frequencies with verbs. SCFs abstract over particles and prepositions. F5: F4 with COs (F1). The SCF and CO feature vectors are concatenated. F6: F4 with the tense of the verb. The frequency of verbal POS tags is calculated specific to each SCF. F7: F4 with PPs (F2). This feature parameterizes SCFs for prepositions. The following 9 feature sets are novel. They build on F7, refining it further. F9-F11 refin</context>
<context position="17319" citStr="Sun et al. (2008)" startWordPosition="2847" endWordPosition="2850">st set of Joanis et al. (2008) provides a classification of 835 verbs into 15 (some coarse, some fine-grained) Levin classes. 11 tests are provided for 2-14 way classifications. We employ the 14 way classification because this corresponds the closest to our target (Levin’s fine-grained) classification7. We select 586 verbs according to Joanis et al.’s selection criteria, resulting in 10- 120 verbs per class. We restrict the class imbalance to 1:1.5.8. This yields 205 verbs (10-15 verbs per class) which is similar to the sub-set of T1 employed by Stevenson and Joanis (2003). T2 The test set of Sun et al. (2008) classifies 204 verbs to 17 fine-grained Levin classes, so that each class has 12 member verbs. Table 1 shows the classes in T1 and T2. 4.2 Data processing For each verb in T1 and T2, we extracted all the occurrences (up to 10,000) from the raw corpus data gathered originally for constructing the 7However, the correspondence is not perfect with half of the classes including two or more Levin’s fine-grained classes. 8Otherwise, in the case of a large class imbalance the evaluation measure would be dominated by the classes with large population. T1 T2 Object Drop 26.{1,3,7} Remove 10.1 Recipient</context>
<context position="31492" citStr="Sun et al. 2008" startWordPosition="5252" endWordPosition="5255">kind of a ’SP’) which was determined by classifying e.g. pronouns and proper names in data to this single SP class. A small improvement was obtained when this feature was used in conjunction with syntactic features in supervised classification. Joanis (2002) and Schulte im Walde (2006) experimented with more conventional SPs with syntactic features in English and German verb classification, respectively. They employing top level Method Result T1 Li et al. 2008 supervised 66.3 Joanis et al. 2008 supervised 58.4 Stevenson et al. 2003 semi-supervised 29 unsupervised 31 SPEC unsupervised 57.55 T2 Sun et al. 2008 supervised 62.50 unsupervised 51.6 O´ S´eaghdha et al. 2008 supervised 67.3 SPEC unsupervised 80.35 Table 5: Previous verb classification results WordNet (Miller, 1995) and Germanet (Kunze and Lemnitzer, 2002) classes as SP models. Joanis (2002) obtained no improvement over syntactic features, whereas Schulte im Walde (2006) obtained insignificant improvement. Korhonen et al. (2008) combined SPs with SCFs when clustering biomedical verbs. The SPs were acquired automatically from syntactic slots of SCFs (not from GRs as in our experiment) using PC clustering. A small improvement was obtained u</context>
<context position="34861" citStr="Sun et al. (2008)" startWordPosition="5786" endWordPosition="5789">lustering was used. Our unsupervised method SPEC performs substantially better than the unsupervised method of Stevenson et al. and nearly as well as the supervised approach of Joanis et al. (2008) (note, however, that the different experiments involved different sub-sets of T1 so are not entirely comparable). On T2, the best performing supervised method so far is that of O´ S´eaghdha and Copestake (2008) which employs a distributional kernel method to classify SCF features parameterized for prepositions in the automatically acquired VALEX lexicon. Using exactly the same data and feature set, Sun et al. (2008) obtain a slightly lower result when using a supervised method (Gaussian) and a notably lower result when using an unsupervised method (PC clustering). Our method performs considerably better and also outperforms the supervised method of O´ S´eaghdha and Copestake (2008). 7 Conclusion and Future Work We introduced a new approach to verb clustering which involves the use of (i) rich lexical, SCF and GR data produced by a recent SCF system, (ii) novel syntactic-semantic feature sets which combine a variety of linguistic information, and (iii) a new variation of spectral clustering which is parti</context>
</contexts>
<marker>Sun, Korhonen, Krymolowski, 2008</marker>
<rawString>Lin Sun, Anna Korhonen, and Yuval Krymolowski. Verb class discovery from rich syntactic data. Lecture Notes in Computer Science, 4919:16, 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Swier</author>
<author>Suzanne Stevenson</author>
</authors>
<title>Unsupervised semantic role labelling.</title>
<date>2004</date>
<booktitle>In Proc. of EMNLP,</booktitle>
<contexts>
<context position="1294" citStr="Swier and Stevenson, 2004" startWordPosition="173" endWordPosition="176">mising results using a new framework for verb clustering which incorporates a recent subcategorization acquisition system, rich syntactic-semantic feature sets, and a variation of spectral clustering which performs particularly well in high dimensional feature space. 1 Introduction Verb classifications have attracted a great deal of interest in natural language processing (NLP). They have proved useful for various important NLP tasks and applications, including e.g. parsing, word sense disambiguation, semantic role labeling, information extraction, question-answering, and machine translation (Swier and Stevenson, 2004; Dang, 2004; Shi and Mihalcea, 2005; Zapirain et al., 2008). Verb classes are useful because they offer a powerful tool for generalization and abstraction which can be beneficial when faced e.g. with the problem of data sparsity. Particularly useful can be classes which capture generalizations over a range of (cross-)linguistic properties, such as the ones proposed by Levin (1993). Being defined in terms of similar meaning and (morpho-)syntactic behaviour of words, Levin style classes generally incorporate a wider range of properties than e.g. classes defined solely on semantic grounds (Mille</context>
</contexts>
<marker>Swier, Stevenson, 2004</marker>
<rawString>Robert Swier and Suzanne Stevenson. Unsupervised semantic role labelling. In Proc. of EMNLP, 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Deepak Verma</author>
<author>Marina Meila</author>
</authors>
<title>Comparison of spectral clustering methods.</title>
<date>2003</date>
<booktitle>Advances in Neural Information Processing Systems (NIPS 15),</booktitle>
<contexts>
<context position="12812" citStr="Verma and Meila, 2003" startWordPosition="2043" endWordPosition="2046">ical verb clustering (Korhonen et al., 2008), and (ii) a method which is new to the task (and to the best of our knowledge, to NLP): a variation of spectral clustering which exploits the MNCut algorithm (Meila and Shi, 2001) (SPEC). Spectral clustering has been shown to be effective for high dimensional and non-convex data in NLP (Chen et al., 2006) and it has been applied to German verb clustering by Brew and Schulte im Walde (2002). However, previous work has used Ng et al. (2002)’s algorithm, while we adopt the MNCut algorithm. The latter has shown a wider applicability (von Luxburg, 2007; Verma and Meila, 2003) and it can be justified from the random walk view, which has a clear probabilistic interpretation. Clustering groups a given set of items (verbs in our experiment) V = {vn}Nn=1 into a disjoint partition of K classes I = {Ik}Kk=1. Both our algorithms take a similarity matrix as input. We construct this from the skew divergence (Lee, 2001). The skew divergence between two feature vectors v and v&apos; is dskew(v, v&apos;) = D(v&apos;||a·v +(1−a)·v&apos;) where D is the KL-divergence. v is smoothed with v&apos;. The level of smoothing is controlled by a whose value is set to a value close to 1 (e.g. 0.9999). We symmetri</context>
</contexts>
<marker>Verma, Meila, 2003</marker>
<rawString>Deepak Verma and Marina Meila. Comparison of spectral clustering methods. Advances in Neural Information Processing Systems (NIPS 15), 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Vlachos</author>
<author>Anna Korhonen</author>
<author>Zoubin Ghahramani</author>
</authors>
<title>Unsupervised and constrained dirichlet process mixture models for verb clustering.</title>
<date>2009</date>
<booktitle>In Proc. of the Workshop on Geometrical Models of Natural Language Semantics,</booktitle>
<contexts>
<context position="2182" citStr="Vlachos et al., 2009" startWordPosition="314" endWordPosition="317">hich capture generalizations over a range of (cross-)linguistic properties, such as the ones proposed by Levin (1993). Being defined in terms of similar meaning and (morpho-)syntactic behaviour of words, Levin style classes generally incorporate a wider range of properties than e.g. classes defined solely on semantic grounds (Miller, 1995). In recent years, a variety of approaches have been proposed for automatic induction of verb classes from corpus data (Schulte im Walde, 2006; Joanis et al., 2008; Sun et al., 2008; Li and Brew, 2008; Korhonen et al., 2008; O´ S´eaghdha and Copestake, 2008; Vlachos et al., 2009). This work opens up the opportunity of learning and tuning classifications tailored to the application and domain in question. Although manual classification may always yields higher accuracy, automatic verb classification is cost-effective and gathers statistical information as a side-effect of the acquisition process which is difficult for humans to gather but can be highly useful for NLP applications. To date, both supervised and unsupervised machine learning (ML) methods have been proposed for verb classification and used to classify a variety of features extracted from raw, tagged and/or</context>
</contexts>
<marker>Vlachos, Korhonen, Ghahramani, 2009</marker>
<rawString>Andreas Vlachos, Anna Korhonen, and Zoubin Ghahramani. Unsupervised and constrained dirichlet process mixture models for verb clustering. In Proc. of the Workshop on Geometrical Models of Natural Language Semantics, 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ulrike von Luxburg</author>
</authors>
<title>A tutorial on spectral clustering. Statistics and Computing,</title>
<date>2007</date>
<marker>von Luxburg, 2007</marker>
<rawString>Ulrike von Luxburg. A tutorial on spectral clustering. Statistics and Computing, 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Be˜nat Zapirain</author>
</authors>
<title>Eneko Agirre, and Llu´ıs M`arquez. Robustness and generalization of role sets: PropBank vs. VerbNet.</title>
<date>2008</date>
<booktitle>In Proc. of ACL,</booktitle>
<marker>Zapirain, 2008</marker>
<rawString>Be˜nat Zapirain, Eneko Agirre, and Llu´ıs M`arquez. Robustness and generalization of role sets: PropBank vs. VerbNet. In Proc. of ACL, 2008.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>