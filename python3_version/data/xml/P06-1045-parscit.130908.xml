<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000007">
<title confidence="0.9987355">
Selection of Effective Contextual Information
for Automatic Synonym Acquisition
</title>
<author confidence="0.997415">
Masato Hagiwara, Yasuhiro Ogawa, and Katsuhiko Toyama
</author>
<affiliation confidence="0.851159666666667">
Graduate School of Information Science,
Nagoya University
Furo-cho, Chikusa-ku, Nagoya, JAPAN 464-8603
</affiliation>
<email confidence="0.995587">
{hagiwara, yasuhiro, toyama}@kl.i.is.nagoya-u.ac.jp
</email>
<sectionHeader confidence="0.993874" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999799916666667">
Various methods have been proposed for
automatic synonym acquisition, as syn-
onyms are one of the most fundamen-
tal lexical knowledge. Whereas many
methods are based on contextual clues
of words, little attention has been paid
to what kind of categories of contex-
tual information are useful for the pur-
pose. This study has experimentally inves-
tigated the impact of contextual informa-
tion selection, by extracting three kinds of
word relationships from corpora: depen-
dency, sentence co-occurrence, and prox-
imity. The evaluation result shows that
while dependency and proximity perform
relatively well by themselves, combina-
tion of two or more kinds of contextual in-
formation gives more stable performance.
We’ve further investigated useful selection
of dependency relations and modification
categories, and it is found that modifi-
cation has the greatest contribution, even
greater than the widely adopted subject-
object combination.
</bodyText>
<sectionHeader confidence="0.999134" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999045833333334">
Lexical knowledge is one of the most important re-
sources in natural language applications, making it
almost indispensable for higher levels of syntacti-
cal and semantic processing. Among many kinds
of lexical relations, synonyms are especially use-
ful ones, having broad range of applications such
as query expansion technique in information re-
trieval and automatic thesaurus construction.
Various methods (Hindle, 1990; Lin, 1998;
Hagiwara et al., 2005) have been proposed for syn-
onym acquisition. Most of the acquisition meth-
ods are based on distributional hypothesis (Har-
ris, 1985), which states that semantically similar
words share similar contexts, and it has been ex-
perimentally shown considerably plausible.
However, whereas many methods which adopt
the hypothesis are based on contextual clues con-
cerning words, and there has been much consid-
eration on the language models such as Latent
Semantic Indexing (Deerwester et al., 1990) and
Probabilistic LSI (Hofmann, 1999) and synonym
acquisition method, almost no attention has been
paid to what kind of categories of contextual infor-
mation, or their combinations, are useful for word
featuring in terms of synonym acquisition.
For example, Hindle (1990) used co-
occurrences between verbs and their subjects
and objects, and proposed a similarity metric
based on mutual information, but no exploration
concerning the effectiveness of other kinds of
word relationship is provided, although it is
extendable to any kinds of contextual information.
Lin (1998) also proposed an information theory-
based similarity metric, using a broad-coverage
parser and extracting wider range of grammatical
relationship including modifications, but he didn’t
further investigate what kind of relationships
actually had important contributions to acquisi-
tion, either. The selection of useful contextual
information is considered to have a critical impact
on the performance of synonym acquisition. This
is an independent problem from the choice of
language model or acquisition method, and should
therefore be examined by itself.
The purpose of this study is to experimen-
tally investigate the impact of contextual infor-
mation selection for automatic synonym acqui-
sition. Because nouns are the main target of
</bodyText>
<page confidence="0.989227">
353
</page>
<note confidence="0.532712">
Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 353–360,
Sydney, July 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.999871909090909">
synonym acquisition, here we limit the target of
acquisition to nouns, and firstly extract the co-
occurrences between nouns and three categories of
contextual information — dependency, sentence
co-occurrence, and proximity — from each of
three different corpora, and the performance of
individual categories and their combinations are
evaluated. Since dependency and modification re-
lations are considered to have greater contribu-
tions in contextual information and in the depen-
dency category, respectively, these categories are
then broken down into smaller categories to ex-
amine the individual significance.
Because the consideration on the language
model and acquisition methods is not the scope of
the current study, widely used vector space model
(VSM), tf·idf weighting scheme, and cosine mea-
sure are adopted for similarity calculation. The re-
sult is evaluated using two automatic evaluation
methods we proposed and implemented: discrimi-
nation rate and correlation coefficient based on the
existing thesaurus WordNet.
This paper is organized as follows: in Section
2, three kinds of contextual information we use
are described, and the following Section 3 explains
the synonym acquisition method. In Section 4 the
evaluation method we employed is detailed, which
consists of the calculation methods of reference
similarity, discrimination rate, and correlation co-
efficient. Section 5 provides the experimental con-
ditions and results of contextual information se-
lection, followed by dependency and modification
selection. Section 6 concludes this paper.
</bodyText>
<sectionHeader confidence="0.985766" genericHeader="method">
2 Contextual Information
</sectionHeader>
<bodyText confidence="0.9999082">
In this study, we focused on three kinds of con-
textual information: dependency between words,
sentence co-occurrence, and proximity, that is, co-
occurrence with other words in a window, details
of which are provided the following sections.
</bodyText>
<subsectionHeader confidence="0.914987">
2.1 Dependency
</subsectionHeader>
<bodyText confidence="0.999904111111111">
The first category of the contextual information we
employed is the dependency between words in a
sentence, which we suppose is most commonly
used for synonym acquisition as the context of
words. The dependency here includes predicate-
argument structure such as subjects and objects
of verbs, and modifications of nouns. As the ex-
traction of accurate and comprehensive grammat-
ical relations is in itself a difficult task, the so-
</bodyText>
<figure confidence="0.783085">
dependent
obj
</figure>
<figureCaption confidence="0.953873">
Figure 1: Hierarchy of grammatical relations and
groups
</figureCaption>
<bodyText confidence="0.999132086956522">
phisticated parser RASP Toolkit (Briscoe and Car-
roll, 2002) was utilized to extract this kind of
word relations. RASP analyzes input sentences
and provides wide variety of grammatical infor-
mation such as POS tags, dependency structure,
and parsed trees as output, among which we paid
attention to dependency structure called grammat-
ical relations (GRs) (Briscoe et al., 2002).
GRs represent relationship among two or more
words and are specified by the labels, which con-
struct the hierarchy shown in Figure 1. In this hier-
archy, the upper levels correspond to more general
relations whereas the lower levels to more specific
ones. Although the most general relationship in
GRs is “dependent”, more specific labels are as-
signed whenever possible. The representation of
the contextual information using GRs is as fol-
lows. Take the following sentence for example:
Shipments have been relatively level
since January, the Commerce Depart-
ment noted.
RASP outputs the extracted GRs as n-ary rela-
tions as follows:
</bodyText>
<equation confidence="0.93687725">
(ncsubj note Department obj)
(ncsubj be Shipment _)
(xcomp _ be level)
(mod _ level relatively)
(aux _ be have)
(ncmod since be January)
(mod _ Department note)
(ncmod _Department Commerce)
</equation>
<figure confidence="0.9479915">
mod
arg_mod arg aux conj
mod
ncmod xmod cmod detmod
subj_or_dobj
comp
obj clausal
subj
ncsubj xsubj csubj
xcompccomp
dobj obj2 iobj
subj
</figure>
<page confidence="0.983009">
354
</page>
<equation confidence="0.6021215">
(detmod _ Department the)
(ncmod _be Department)
</equation>
<bodyText confidence="0.999737272727273">
While most of GRs extracted by RASP are bi-
nary relations of head and dependent, there are
some relations that contain additional slot or ex-
tra information regarding the relations, as shown
“ncsubj” and “ncmod” in the above example. To
obtain the final representation that we require for
synonym acquisition, that is, the co-occurrence
between words and their contexts, these relation-
ships must be converted to binary relations, i.e.,
co-occurrence. We consider the concatenation of
all the rest of the target word as context:
</bodyText>
<figure confidence="0.959093625">
Department ncsubj:note:*:obj
shipment ncsubj:be:*:_
January ncmod:since:be:*
Department mod:_:*:note
Department ncmod:_:*:Commerce
Commerce ncmod:_:Department:*
Department detmod:_:*:the
Department ncmod:_:be:*
</figure>
<bodyText confidence="0.99793975">
The slot for the target word is replaced by “*” in
the context. Note that only the contexts for nouns
are extracted because our purpose here is the auto-
matic extraction of synonymous nouns.
</bodyText>
<subsectionHeader confidence="0.997952">
2.2 Sentence Co-occurrence
</subsectionHeader>
<bodyText confidence="0.999555727272727">
As the second category of contextual information,
we used the sentence co-occurrence, i.e., which
sentence words appear in. Using this context is,
in other words, essentially the same as featuring
words with the sentences in which they occur.
Treating single sentences as documents, this fea-
turing corresponds to exploiting transposed term-
document matrix in the information retrieval con-
text, and the underlying assumption is that words
that commonly appear in the similar documents or
sentences are considered semantically similar.
</bodyText>
<subsectionHeader confidence="0.997821">
2.3 Proximity
</subsectionHeader>
<bodyText confidence="0.999996923076923">
The third category of contextual information,
proximity, utilizes tokens that appear in the vicin-
ity of the target word in a sentence. The basic as-
sumption here is that the more similar the distri-
bution of proceeding and succeeding words of the
target words are, the more similar meaning these
two words possess, and its effectiveness has been
previously shown (Macro Baroni and Sabrina Bisi,
2004). To capture the word proximity, we consider
a window with a certain radius, and treat the la-
bel of the word and its position within the window
as context. The contexts for the previous example
sentence, when the window radius is 3, are then:
</bodyText>
<figure confidence="0.993819142857143">
shipment R1:have
shipment R2:be
shipment R3:relatively
January L1:since
January L2:level
January L3:relatively
January R1:,
January R2:the
January R3:Commerce
Commerce L1:the
Commerce L2:,
Commerce L3:January
Commerce R1:Department
...
</figure>
<bodyText confidence="0.996581666666667">
Note that the proximity includes tokens such as
punctuation marks as context, because we suppose
they offer useful contextual information as well.
</bodyText>
<sectionHeader confidence="0.991325" genericHeader="method">
3 Synonym Acquisition Method
</sectionHeader>
<bodyText confidence="0.959235625">
The purpose of the current study is to investigate
the impact of the contextual information selection,
not the language model itself, we employed one
of the most commonly used method: vector space
model (VSM) and tf·idf weighting scheme. In this
framework, each word is represented as a vector
in a vector space, whose dimensions correspond
to contexts. The elements of the vectors given by
tf·idf are the co-occurrence frequencies of words
and contexts, weighted by normalized idf. That
is, denoting the number of distinct words and con-
texts as N and M, respectively,
wi = t[tf(wi, ci) · idf(ci) ... tf(wi, cM) · idf(cM)],
(1)
where tf(wi, cj) is the co-occurrence frequency of
word wi and context cj. idf(cj) is given by
</bodyText>
<equation confidence="0.998294">
log(N/df(cj))
idf(cj) = maxk log(N/df(vk)), (2)
</equation>
<bodyText confidence="0.999865125">
where df(cj) is the number of distinct words that
co-occur with context cj.
Although VSM and tf·idf are naive and simple
compared to other language models like LSI and
PLSI, they have been shown effective enough for
the purpose (Hagiwara et al., 2005). The similar-
ity between two words are then calculated as the
cosine value of two corresponding vectors.
</bodyText>
<sectionHeader confidence="0.998417" genericHeader="method">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.999960666666667">
This section describes the evaluation methods we
employed for automatic synonym acquisition. The
evaluation is to measure how similar the obtained
similarities are to the “true” similarities. We firstly
prepared the reference similarities from the exist-
ing thesaurus WordNet as described in Section 4.1,
</bodyText>
<page confidence="0.994722">
355
</page>
<bodyText confidence="0.99991625">
and by comparing the reference and obtained sim-
ilarities, two evaluation measures, discrimination
rate and correlation coefficient, are calculated au-
tomatically as described in Sections 4.2 and 4.3.
</bodyText>
<subsectionHeader confidence="0.9762275">
4.1 Reference similarity calculation using
WordNet
</subsectionHeader>
<bodyText confidence="0.9999475">
As the basis for automatic evaluation methods, the
reference similarity, which is the answer value that
similarity of a certain pair of words “should take,”
is required. We obtained the reference similarity
using the calculation based on thesaurus tree struc-
ture (Nagao, 1996). This calculation method re-
quires no other resources such as corpus, thus it is
simple to implement and widely used.
The similarity between word sense wi and word
sense vj is obtained using tree structure as follows.
Let the depth1 of node wi be di, the depth of node
vj be dj, and the maximum depth of the common
ancestors of both nodes be ddca. The similarity
between wi and vj is then calculated as
</bodyText>
<equation confidence="0.98833">
2 ·sim(wi, vj) = di d cdj
a, (3)
</equation>
<bodyText confidence="0.999765833333333">
which takes the value between 0.0 and 1.0.
Figure 2 shows the example of calculating the
similarity between the word senses “hill” and
“coast.” The number on the side of each word
sense represents the word’s depth. From this tree
structure, the similarity is obtained:
</bodyText>
<equation confidence="0.853294">
2 · 3
sim(“hill”, “coast”) = 5 + 5 =0.6. (4)
</equation>
<bodyText confidence="0.971391714285714">
The similarity between word w with senses
w1, ..., wr,, and word v with senses v1, ..., vin is de-
fined as the maximum similarity between all the
pairs of word senses:
sim(w, v) = max sim(wi, vj), (5)
i,j
whose idea came from Lin’s method (Lin, 1998).
</bodyText>
<subsectionHeader confidence="0.989832">
4.2 Discrimination Rate
</subsectionHeader>
<bodyText confidence="0.99998925">
The following two sections describe two evalua-
tion measures based on the reference similarity.
The first one is discrimination rate (DR). DR, orig-
inally proposed by Kojima et al. (2004), is the rate
</bodyText>
<footnote confidence="0.92966275">
1To be precise, the structure of WordNet, where some
word senses have more than one parent, isn’t a tree but a
DAG. The depth of a node is, therefore, defined here as the
“maximum distance” from the root node.
</footnote>
<figure confidence="0.9273595">
entity 0
inanimate-object 1
natural-object 2
geological-formation 3
4 natural-elevation
coast 5
</figure>
<figureCaption confidence="0.993893">
Figure 2: Example of automatic similarity calcu-
lation based on tree structure
</figureCaption>
<table confidence="0.9762028">
highly related unrelated
(answer, reply) (animal, coffee)
(phone, telephone) (him, technology)
(sign, signal) (track, vote)
(concern, worry) (path, youth)
</table>
<figureCaption confidence="0.972858">
Figure 3: Test-sets for discrimination rate calcula-
tion.
</figureCaption>
<bodyText confidence="0.999530208333333">
(percentage) of pairs (w1, w2) whose degree of as-
sociation between two words w1, w2 is success-
fully discriminated by the similarity derived by
the method under evaluation. Kojima et al. dealt
with three-level discrimination of a pair of words,
that is, highly related (synonyms or nearly syn-
onymous), moderately related (a certain degree of
association), and unrelated (irrelevant). However,
we omitted the moderately related level and lim-
ited the discrimination to two-level: high or none,
because of the difficulty of preparing a test set that
consists of moderately related pairs.
The calculation of DR follows these steps: first,
two test sets, one of which consists of highly re-
lated word pairs and the other of unrelated ones,
are prepared, as shown in Figure 3. The similar-
ity between w1 and w2 is then calculated for each
pair (w1, w2) in both test sets via the method un-
der evaluation, and the pair is labeled highly re-
lated when similarity exceeds a given threshold t
and unrelated when the similarity is lower than t.
The number of pairs labeled highly related in the
highly related test set and unrelated in the unre-
lated test set are denoted na and nb, respectively.
</bodyText>
<figure confidence="0.957423">
...
5 hill
shore 4
</figure>
<page confidence="0.941606">
356
</page>
<bodyText confidence="0.483188">
DR is then given by:
</bodyText>
<equation confidence="0.959932333333333">
1 ( na�
+ nb, (6)
2 Na Nb
</equation>
<bodyText confidence="0.999908384615385">
where Na and Nb are the numbers of pairs in
highly related and unrelated test sets, respectively.
Since DR changes depending on threshold t, max-
imum value is adopted by varying t.
We used the reference similarity to create these
two test sets. Firstly, Np = 100, 000 pairs of
words are randomly created using the target vo-
cabulary set for synonym acquisition. Proper
nouns are omitted from the choice here because
of their high ambiguity. The two testsets are then
created extracting n = 2, 000 most related (with
high reference similarity) and unrelated (with low
reference similarity) pairs.
</bodyText>
<subsectionHeader confidence="0.998114">
4.3 Correlation coefficient
</subsectionHeader>
<bodyText confidence="0.999575230769231">
The second evaluation measure is correlation co-
efficient (CC) between the obtained similarity and
the reference similarity. The higher CC value is,
the more similar the obtained similarities are to
WordNet, thus more accurate the synonym acqui-
sition result is.
The value of CC is calculated as follows. Let
the set of the sample pairs be Ps, the sequence of
the reference similarities calculated for the pairs
in Ps be r = (r1, r2, ..., rn), the corresponding
sequence of the target similarity to be evaluated
be r = (s1, s2, ..., sn), respectively. Correlation
coefficient ρ is then defined by:
</bodyText>
<equation confidence="0.936498">
1 �n i=1(ri − �r)(si − �s)
n
σrσs
</equation>
<bodyText confidence="0.999953428571429">
where f, 9, σr, and σs represent the average of r
and s and the standard deviation of r and s, re-
spectively. The set of the sample pairs Ps is cre-
ated in a similar way to the preparation of highly
related test set used in DR calculation, except that
we employed Np = 4, 000, n = 2, 000 to avoid
extreme nonuniformity.
</bodyText>
<sectionHeader confidence="0.999711" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<bodyText confidence="0.9999365">
Now we desribe the experimental conditions and
results of contextual information selection.
</bodyText>
<subsectionHeader confidence="0.961404">
5.1 Condition
</subsectionHeader>
<bodyText confidence="0.99792708">
We used the following three corpora for the ex-
periment: (1) Wall Street Journal (WSJ) corpus
(approx. 68,000 sentences, 1.4 million tokens),
(2) Brown Corpus (BROWN) (approx. 60,000
sentences, 1.3 million tokens), both of which are
contained in Treebank 3 (Marcus, 1994), and (3)
written sentences in WordBank (WB) (approx.
190,000 sentences, 3.5 million words) (Hyper-
Collins, 2002). No additional annotation such as
POS tags provided for Treebank was used, which
means that we gave the plain texts stripped off any
additional information to RASP as input.
To distinguish nouns, using POS tags annotated
by RASP, any words with POS tags APP, ND, NN,
NP, PN, PP were labeled as nouns. The window
radius for proximity is set to 3. We also set a
threshold tf on occurrence frequency in order to
filter out any words or contexts with low frequency
and to reduce computational cost. More specifi-
cally, any words w such that &amp; tf(w, c) &lt; tf and
any contexts c such that Ew tf(w, c) &lt; tf were
removed from the co-occurrence data. tf was set
to tf = 5 for WSJ and BROWN, and tf = 10 for
WB in Sections 5.2 and 5.3, and tf = 2 for WSJ
and BROWN and tf = 5 for WB in Section 5.4.
</bodyText>
<subsectionHeader confidence="0.994309">
5.2 Contextual Information Selection
</subsectionHeader>
<bodyText confidence="0.99999252173913">
In this section, we experimented to discover what
kind of contextual information extracted in Sec-
tion 2 is useful for synonym extraction. The per-
formances, i.e. DR and CC are evaluated for each
of the three categories and their combinations.
The evaluation result for three corpora is shown
in Figure 4. Notice that the range and scale of the
vertical axes of the graphs vary according to cor-
pus. The result shows that dependency and prox-
imity perform relatively well alone, while sen-
tence co-occurrence has almost no contributions
to performance. However, when combined with
other kinds of context information, every category,
even sentence co-occurrence, serves to “stabilize”
the overall performance, although in some cases
combination itself decreases individual measures
slightly. It is no surprise that the combination of all
categories achieves the best performance. There-
fore, in choosing combination of different kinds of
context information, one should take into consid-
eration the economical efficiency and trade-offbe-
tween computational complexity and overall per-
formance stability.
</bodyText>
<subsectionHeader confidence="0.991509">
5.3 Dependency Selection
</subsectionHeader>
<bodyText confidence="0.999924">
We then focused on the contribution of individual
categories of dependency relation, i.e. groups of
grammatical relations. The following four groups
</bodyText>
<equation confidence="0.9094545">
ρ=
, (7)
</equation>
<page confidence="0.940348">
357
</page>
<figure confidence="0.999832890410959">
(3) WB
sent
prox
dep
prox
all
dep sent prox dep
sent
sent
prox
dep sent prox dep
sent
(2) BROWN
dep
prox
all
sent
prox
dep
prox
all
dep sent prox dep
sent
coelati coefficien cUIIUIauuu lti IUHLffiien coelati —amu•coefficien
...4.
ino
te ()a
68.5%
68.0%
67.5%
67.0%
66.5%
66.0%
65.5%
65.0%
DR
= 52.8%
CC
= -0.0029
sent:
DR
CC
(1) WSJ
sent:
DR
= 52.2%
CC
= 0.0066
DR
CC
69.0%
68.5%
68.0%
67.5%
67.0%
66.5%
66.0%
65.5%
65.0%
DR
= 53.8%
CC
= 0.060
sent:
DR
CC
69.0%
68.5%
68.0%
67.5%
67.0%
66.5%
66.0%
</figure>
<figureCaption confidence="0.460554">
inao ate ()a
ino te ()a
</figureCaption>
<bodyText confidence="0.930222777777778">
of GRs are considered for comparison conve-
nience: (1) subj group (“subj”, “ncsubj”, “xsubj”,
0.13 and “csubj”), (2) obj group (“obj”, “dobj”, “obj2”,
and “iobj”), (3) mod group (“mod”, “ncmod”,
“xmod”, “cmod”, and “detmod”), and (4) etc
group (others), as shown in the circles in Figure
1. This is because distinction between relations
0.11at&apos; in a group is sometimes unclear, and is consid-
2. to strongly depend on the parser implemen-
</bodyText>
<equation confidence="0.50443">
0.10CD
</equation>
<bodyText confidence="0.968751117647059">
tation. The final target is seven kinds of combina-
tions of the above four groups: subj, obj, mod, etc,
subj+obj, subj+obj+mod, and all.
0.09 The two evaluation measures are similarly cal-
culated for each group and combination, and
shown in Figure 5. Although subjects, objects, coefficien
and their combination are widely used contextual
0.15 information, the performances for subj and obj
categories, as well as their combination subj+obj,
0 were relatively poor. On the contrary, the re-
sult clearly shows the importance of modification,
which alone is even better than widely adopted
0.14tsubj+obj. The “stabilization effect” of combina-
tions observed in the previous experiment is also
confirmed here as well.
Because the size of the co-occurrence data
varies from one category to another, we conducted
another experiment to verify that the superiority
of the modification category is simply due to the
difference in the quality (content) of the group,
0.19 not the quantity (size). We randomly extracted
100,000 pairs from each of mod and subj+obj cat-
egories to cancel out the quantity difference and
9 compared the performance by calculating aver-
0.18cp. aged DR and CC of ten trials. The result showed
that, while the overall performances substantially
53 decreased due to the size reduction, the relation
2.
0.17oe&apos;a between groups was preserved before and after the
extraction throughout all of the three corpora, al-
though the detailed result is not shown due to the
0.16 space limitation. This means that what essentially
contributes to the performance is not the size of
the modification category but its content.
</bodyText>
<figure confidence="0.990733833333333">
0.12
0.13
s
0
0
non coetncient
</figure>
<figureCaption confidence="0.719082">
Figure 4: Contextual information selection perfor-
mances
Discrimination rate (DR) and correlation coefficient (CC)
for (1) Wall Street Journal corpus, (2) Brown Corpus, and
(3) WordBank.
</figureCaption>
<subsectionHeader confidence="0.998035">
5.4 Modification Selection
</subsectionHeader>
<bodyText confidence="0.998929142857143">
As the previous experiment shows that modifica-
tions have the biggest significance of all the depen-
dency relationship, we further investigated what
kind of modifications is useful for the purpose. To
do this, we broke down the mod group into these
five categories according to modifying word’s cat-
egory: (1) detmod, when the GR label is “det-
</bodyText>
<page confidence="0.990618">
358
</page>
<figure confidence="0.999805680473373">
detmod
ncmod-j
etc all
ncmod-n
ncmod-p
detmod
ncmod-j
etc all
ncmod-n
ncmod-p
(1) WSJ
DR
CC
CC
= -0.018
(2) BROWN
DR
CC
66.0%
64.0%
62.0%
60.0%
58.0%
56.0%
54.0%
52.0%
50.0%
DR
CC
66.0%
64.0%
62.0%
60.0%
58.0%
56.0%
54.0%
52.0%
50.0%
67.0%
65.0%
63.0%
61.0%
59.0%
57.0%
subj
obj
mod
subj obj mod etc subj
obj
(1) WSJ
all
DR
CC
subj
obj
mod
all
subj obj mod etc subj
obj
DR
CC
(2) BROWN
DR
CC
minin
te ()
mination ate ()a
minin te ()
68.0%
66.0%
64.0%
62.0%
60.0%
58.0%
56.0%
54.0%
68.0%
66.0%
64.0%
62.0%
60.0%
58.0%
56.0%
54.0%
70.0%
68.0%
66.0%
64.0%
62.0%
60.0%
58.0%
56.0%
54.0%
mination
ate (DR)a
minaion ate ()a
.i:
minaion ate ()a
0.14
0.12
0.10
0.08
0.06
0.04
0.02
0.00
0.16
0.14
0.12
0.10
0.08
0.06
0.04
0.02
0.00
0.20
0.18
0.16
0.14
0.12
0.10
0.08
0.06
0.04
Lavu
colati officien corlati officien colati officien
0.02
0.00
coelatioLivu coefficien corelatio —coefficien colati officien
0.12
0.10
0.08
0.06
0.04
0.02
0.00
0.14
0.12
0.10
0.08
0.06
0.04
0.02
0.00
0.18
0.16
0.14
0.12
0.10
0.08
0.06
0.04
subj obj mod etc subj
subj obj mod etc subj subj all detmod ncmod-j etc all
subj
all
detmod
ncmod-j
etc all
obj
obj
obj obj ncmod-n ncmod-p
ncmod-n
ncmod-p
mod
mod
(3) WB
(3) WB (3) WB
(3) WB
</figure>
<figureCaption confidence="0.999936666666667">
Figure 5: Dependency selection performances
Figure 5: Dependency selection performances Figure 6: Modification selection performances
Figure 6: Modification selection performances
</figureCaption>
<bodyText confidence="0.731536666666667">
Discrimination rate (DR) and correlation coefficient (CC)
Discrimination rate (DR) and correlation coefficient (CC) Discrimination rate (DR) and correlation coefficient (CC)
Discrimination rate (DR) and correlation coefficient (CC)
for (1) Wall Street Journal corpus, (2) Brown Corpus, and
for (1) Wall Street Journal corpus, (2) Brown Corpus, and for (1) Wall Street Journal corpus, (2) Brown Corpus, and
for (1) Wall Street Journal corpus, (2) Brown Corpus, and
</bodyText>
<listItem confidence="0.899818666666667">
(3) WordBank.
(3) WordBank.
(3) WordBank. (3) WordBank.
</listItem>
<page confidence="0.998028">
359
</page>
<bodyText confidence="0.99999205">
mod”, i.e., the modifying word is a determiner, (2)
ncmod-n, when the GR label is “ncmod” and the
modifying word is a noun, (3) ncmod-j, when the
GR label is “ncmod” and the modifying word is an
adjective or number, (4) ncmod-p, when the GR
label is “ncmod” and the modification is through a
preposition (e.g. “state” and “affairs” in “state of
affairs”), and (5) etc (others).
The performances for each modification cate-
gory are evaluated and shown in Figure 6. Al-
though some individual modification categories
such as detmod and ncmod-j outperform other cat-
egories in some cases, the overall observation is
that all the modification categories contribute to
synonym acquisition to some extent, and the ef-
fect of individual categories are accumulative. We
therefore conclude that the main contributing fac-
tor on utilizing modification relationship in syn-
onym acquisition isn’t the type of modification,
but the diversity of the relations.
</bodyText>
<sectionHeader confidence="0.999506" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999993482758621">
In this study, we experimentally investigated the
impact of contextual information selection, by ex-
tracting three kinds of contextual information —
dependency, sentence co-occurrence, and proxim-
ity — from three different corpora. The acqui-
sition result was evaluated using two evaluation
measures, DR and CC using the existing thesaurus
WordNet. We showed that while dependency and
proximity perform relatively well by themselves,
combination of two or more kinds of contextual
information, even with the poorly performing sen-
tence co-occurrence, gives more stable result. The
selection should be chosen considering the trade-
off between computational complexity and overall
performance stability. We also showed that modi-
fication has the greatest contribution to the acqui-
sition of all the dependency relations, even greater
than the widely adopted subject-object combina-
tion. It is also shown that all the modification cate-
gories contribute to the acquisition to some extent.
Because we limited the target to nouns, the re-
sult might be specific to nouns, but the same exper-
imental framework is applicable to any other cate-
gories of words. Although the result also shows
the possibility that the bigger the corpus is, the
better the performance will be, the contents and
size of the corpora we used are diverse, so their
relationship, including the effect of the window ra-
dius, should be examined as the future work.
</bodyText>
<sectionHeader confidence="0.996175" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998290679245283">
Marco Baroni and Sabrina Bisi 2004. Using cooccur-
rence statistics and the web to discover synonyms
in a technical language. Proc. of the Fourth Interna-
tional Conference on Language Resources and Eval-
uation (LREC 2004).
Ted Briscoe and John Carroll. 2002. Robust Accu-
rate Statistical Annotation of General Text. Proc. of
the Third International Conference on Language Re-
sources and Evaluation (LREC 2002), 1499–1504.
Ted Briscoe, John Carroll, Jonathan Graham and Ann
Copestake 2002. Relational evaluation schemes.
Proc. of the Beyond PARSEVAL Workshop at the
Third International Conference on Language Re-
sources and Evaluation, 4–8.
Scott Deerwester, et al. 1990. Indexing by Latent Se-
mantic Analysis. Journal of the American Society
for Information Science, 41(6):391–407.
Christiane Fellbaum. 1998. WordNet: an electronic
lexical database. MIT Press.
Masato Hagiwara, Yasuhiro Ogawa, Katsuhiko
Toyama. 2005. PLSI Utilization for Automatic
Thesaurus Construction. Proc. of The Second In-
ternational Joint Conference on Natural Language
Processing (IJCNLP-05), 334–345.
Zellig Harris. 1985. Distributional Structure. Jerrold
J. Katz (ed.) The Philosophy of Linguistics. Oxford
University Press. 26–47.
Donald Hindle. 1990. Noun classification from
predicate-argument structures. Proc. of the 28th An-
nual Meeting of the ACL, 268–275.
Thomas Hofmann. 1999. Probabilistic Latent Seman-
tic Indexing. Proc. of the 22nd International Con-
ference on Research and Development in Informa-
tion Retrieval (SIGIR ’99), 50–57.
Kazuhide Kojima, Hirokazu Watabe, and Tsukasa
Kawaoka. 2004. Existence and Application of
Common Threshold of the Degree of Association.
Proc. of the Forum on Information Technology
(FIT2004) F-003.
Collins. 2002. Collins Cobuild Mld Major New Edi-
tion CD-ROM. HarperCollins Publishers.
Dekang Lin. 1998. Automatic retrieval and clustering
of similar words. Proc. of the 36th Annual Meet-
ing of the Association for Computational Linguis-
tics and 17th International Conference on Compu-
tational linguistics (COLING-ACL ’98), 786–774.
Mitchell P. Marcus, Beatrice Santorini, and Mary Ann
Marcinkiewicz. 1994. Building a large annotated
corpus of English: The Penn treebank. Computa-
tional Linguistics, 19(2):313–330.
Makoto Nagao (ed.). 1996. Shizengengoshori.
The Iwanami Software Science Series 15, Iwanami
Shoten Publishers.
</reference>
<page confidence="0.998212">
360
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.854802">
<title confidence="0.9996795">Selection of Effective Contextual Information for Automatic Synonym Acquisition</title>
<author confidence="0.997255">Masato Hagiwara</author>
<author confidence="0.997255">Yasuhiro Ogawa</author>
<author confidence="0.997255">Katsuhiko Toyama</author>
<affiliation confidence="0.999876">Graduate School of Information Science, Nagoya University</affiliation>
<address confidence="0.996734">Furo-cho, Chikusa-ku, Nagoya, JAPAN 464-8603</address>
<email confidence="0.990067">yasuhiro,</email>
<abstract confidence="0.99472912">Various methods have been proposed for automatic synonym acquisition, as synonyms are one of the most fundamental lexical knowledge. Whereas many methods are based on contextual clues of words, little attention has been paid to what kind of categories of contextual information are useful for the purpose. This study has experimentally investigated the impact of contextual information selection, by extracting three kinds of word relationships from corpora: dependency, sentence co-occurrence, and proximity. The evaluation result shows that while dependency and proximity perform relatively well by themselves, combination of two or more kinds of contextual information gives more stable performance. We’ve further investigated useful selection of dependency relations and modification categories, and it is found that modification has the greatest contribution, even greater than the widely adopted subjectobject combination.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Marco Baroni</author>
<author>Sabrina Bisi</author>
</authors>
<title>Using cooccurrence statistics and the web to discover synonyms in a technical language.</title>
<date>2004</date>
<booktitle>Proc. of the Fourth International Conference on Language Resources and Evaluation (LREC</booktitle>
<marker>Baroni, Bisi, 2004</marker>
<rawString>Marco Baroni and Sabrina Bisi 2004. Using cooccurrence statistics and the web to discover synonyms in a technical language. Proc. of the Fourth International Conference on Language Resources and Evaluation (LREC 2004).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Briscoe</author>
<author>John Carroll</author>
</authors>
<title>Robust Accurate Statistical Annotation of General Text.</title>
<date>2002</date>
<booktitle>Proc. of the Third International Conference on Language Resources and Evaluation (LREC</booktitle>
<pages>1499--1504</pages>
<contexts>
<context position="6078" citStr="Briscoe and Carroll, 2002" startWordPosition="888" endWordPosition="892"> details of which are provided the following sections. 2.1 Dependency The first category of the contextual information we employed is the dependency between words in a sentence, which we suppose is most commonly used for synonym acquisition as the context of words. The dependency here includes predicateargument structure such as subjects and objects of verbs, and modifications of nouns. As the extraction of accurate and comprehensive grammatical relations is in itself a difficult task, the sodependent obj Figure 1: Hierarchy of grammatical relations and groups phisticated parser RASP Toolkit (Briscoe and Carroll, 2002) was utilized to extract this kind of word relations. RASP analyzes input sentences and provides wide variety of grammatical information such as POS tags, dependency structure, and parsed trees as output, among which we paid attention to dependency structure called grammatical relations (GRs) (Briscoe et al., 2002). GRs represent relationship among two or more words and are specified by the labels, which construct the hierarchy shown in Figure 1. In this hierarchy, the upper levels correspond to more general relations whereas the lower levels to more specific ones. Although the most general re</context>
</contexts>
<marker>Briscoe, Carroll, 2002</marker>
<rawString>Ted Briscoe and John Carroll. 2002. Robust Accurate Statistical Annotation of General Text. Proc. of the Third International Conference on Language Resources and Evaluation (LREC 2002), 1499–1504.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Briscoe</author>
<author>John Carroll</author>
<author>Jonathan Graham</author>
<author>Ann Copestake</author>
</authors>
<title>Relational evaluation schemes.</title>
<date>2002</date>
<booktitle>Proc. of the Beyond PARSEVAL Workshop at the Third International Conference on Language Resources and Evaluation,</booktitle>
<volume>4</volume>
<contexts>
<context position="6394" citStr="Briscoe et al., 2002" startWordPosition="938" endWordPosition="941">e such as subjects and objects of verbs, and modifications of nouns. As the extraction of accurate and comprehensive grammatical relations is in itself a difficult task, the sodependent obj Figure 1: Hierarchy of grammatical relations and groups phisticated parser RASP Toolkit (Briscoe and Carroll, 2002) was utilized to extract this kind of word relations. RASP analyzes input sentences and provides wide variety of grammatical information such as POS tags, dependency structure, and parsed trees as output, among which we paid attention to dependency structure called grammatical relations (GRs) (Briscoe et al., 2002). GRs represent relationship among two or more words and are specified by the labels, which construct the hierarchy shown in Figure 1. In this hierarchy, the upper levels correspond to more general relations whereas the lower levels to more specific ones. Although the most general relationship in GRs is “dependent”, more specific labels are assigned whenever possible. The representation of the contextual information using GRs is as follows. Take the following sentence for example: Shipments have been relatively level since January, the Commerce Department noted. RASP outputs the extracted GRs </context>
</contexts>
<marker>Briscoe, Carroll, Graham, Copestake, 2002</marker>
<rawString>Ted Briscoe, John Carroll, Jonathan Graham and Ann Copestake 2002. Relational evaluation schemes. Proc. of the Beyond PARSEVAL Workshop at the Third International Conference on Language Resources and Evaluation, 4–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott Deerwester</author>
</authors>
<title>Indexing by Latent Semantic Analysis.</title>
<date>1990</date>
<journal>Journal of the American Society for Information Science,</journal>
<volume>41</volume>
<issue>6</issue>
<marker>Deerwester, 1990</marker>
<rawString>Scott Deerwester, et al. 1990. Indexing by Latent Semantic Analysis. Journal of the American Society for Information Science, 41(6):391–407.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christiane Fellbaum</author>
</authors>
<title>WordNet: an electronic lexical database.</title>
<date>1998</date>
<publisher>MIT Press.</publisher>
<marker>Fellbaum, 1998</marker>
<rawString>Christiane Fellbaum. 1998. WordNet: an electronic lexical database. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Masato Hagiwara</author>
</authors>
<title>Yasuhiro Ogawa, Katsuhiko Toyama.</title>
<date>2005</date>
<booktitle>Proc. of The Second International Joint Conference on Natural Language Processing (IJCNLP-05),</booktitle>
<pages>334--345</pages>
<marker>Hagiwara, 2005</marker>
<rawString>Masato Hagiwara, Yasuhiro Ogawa, Katsuhiko Toyama. 2005. PLSI Utilization for Automatic Thesaurus Construction. Proc. of The Second International Joint Conference on Natural Language Processing (IJCNLP-05), 334–345.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zellig Harris</author>
</authors>
<date>1985</date>
<booktitle>The Philosophy of Linguistics.</booktitle>
<pages>26--47</pages>
<editor>Distributional Structure. Jerrold J. Katz (ed.)</editor>
<publisher>Oxford University Press.</publisher>
<contexts>
<context position="1824" citStr="Harris, 1985" startWordPosition="259" endWordPosition="261">ct combination. 1 Introduction Lexical knowledge is one of the most important resources in natural language applications, making it almost indispensable for higher levels of syntactical and semantic processing. Among many kinds of lexical relations, synonyms are especially useful ones, having broad range of applications such as query expansion technique in information retrieval and automatic thesaurus construction. Various methods (Hindle, 1990; Lin, 1998; Hagiwara et al., 2005) have been proposed for synonym acquisition. Most of the acquisition methods are based on distributional hypothesis (Harris, 1985), which states that semantically similar words share similar contexts, and it has been experimentally shown considerably plausible. However, whereas many methods which adopt the hypothesis are based on contextual clues concerning words, and there has been much consideration on the language models such as Latent Semantic Indexing (Deerwester et al., 1990) and Probabilistic LSI (Hofmann, 1999) and synonym acquisition method, almost no attention has been paid to what kind of categories of contextual information, or their combinations, are useful for word featuring in terms of synonym acquisition.</context>
</contexts>
<marker>Harris, 1985</marker>
<rawString>Zellig Harris. 1985. Distributional Structure. Jerrold J. Katz (ed.) The Philosophy of Linguistics. Oxford University Press. 26–47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donald Hindle</author>
</authors>
<title>Noun classification from predicate-argument structures.</title>
<date>1990</date>
<booktitle>Proc. of the 28th Annual Meeting of the ACL,</booktitle>
<pages>268--275</pages>
<contexts>
<context position="1659" citStr="Hindle, 1990" startWordPosition="233" endWordPosition="234"> dependency relations and modification categories, and it is found that modification has the greatest contribution, even greater than the widely adopted subjectobject combination. 1 Introduction Lexical knowledge is one of the most important resources in natural language applications, making it almost indispensable for higher levels of syntactical and semantic processing. Among many kinds of lexical relations, synonyms are especially useful ones, having broad range of applications such as query expansion technique in information retrieval and automatic thesaurus construction. Various methods (Hindle, 1990; Lin, 1998; Hagiwara et al., 2005) have been proposed for synonym acquisition. Most of the acquisition methods are based on distributional hypothesis (Harris, 1985), which states that semantically similar words share similar contexts, and it has been experimentally shown considerably plausible. However, whereas many methods which adopt the hypothesis are based on contextual clues concerning words, and there has been much consideration on the language models such as Latent Semantic Indexing (Deerwester et al., 1990) and Probabilistic LSI (Hofmann, 1999) and synonym acquisition method, almost n</context>
</contexts>
<marker>Hindle, 1990</marker>
<rawString>Donald Hindle. 1990. Noun classification from predicate-argument structures. Proc. of the 28th Annual Meeting of the ACL, 268–275.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Hofmann</author>
</authors>
<title>Probabilistic Latent Semantic Indexing.</title>
<date>1999</date>
<booktitle>Proc. of the 22nd International Conference on Research and Development in Information Retrieval (SIGIR ’99),</booktitle>
<pages>50--57</pages>
<contexts>
<context position="2218" citStr="Hofmann, 1999" startWordPosition="319" endWordPosition="320">c thesaurus construction. Various methods (Hindle, 1990; Lin, 1998; Hagiwara et al., 2005) have been proposed for synonym acquisition. Most of the acquisition methods are based on distributional hypothesis (Harris, 1985), which states that semantically similar words share similar contexts, and it has been experimentally shown considerably plausible. However, whereas many methods which adopt the hypothesis are based on contextual clues concerning words, and there has been much consideration on the language models such as Latent Semantic Indexing (Deerwester et al., 1990) and Probabilistic LSI (Hofmann, 1999) and synonym acquisition method, almost no attention has been paid to what kind of categories of contextual information, or their combinations, are useful for word featuring in terms of synonym acquisition. For example, Hindle (1990) used cooccurrences between verbs and their subjects and objects, and proposed a similarity metric based on mutual information, but no exploration concerning the effectiveness of other kinds of word relationship is provided, although it is extendable to any kinds of contextual information. Lin (1998) also proposed an information theorybased similarity metric, using</context>
</contexts>
<marker>Hofmann, 1999</marker>
<rawString>Thomas Hofmann. 1999. Probabilistic Latent Semantic Indexing. Proc. of the 22nd International Conference on Research and Development in Information Retrieval (SIGIR ’99), 50–57.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kazuhide Kojima</author>
<author>Hirokazu Watabe</author>
<author>Tsukasa Kawaoka</author>
</authors>
<date>2004</date>
<booktitle>Existence and Application of Common Threshold of the Degree of Association. Proc. of the Forum on Information Technology (FIT2004) F-003.</booktitle>
<contexts>
<context position="13143" citStr="Kojima et al. (2004)" startWordPosition="2015" endWordPosition="2018"> on the side of each word sense represents the word’s depth. From this tree structure, the similarity is obtained: 2 · 3 sim(“hill”, “coast”) = 5 + 5 =0.6. (4) The similarity between word w with senses w1, ..., wr,, and word v with senses v1, ..., vin is defined as the maximum similarity between all the pairs of word senses: sim(w, v) = max sim(wi, vj), (5) i,j whose idea came from Lin’s method (Lin, 1998). 4.2 Discrimination Rate The following two sections describe two evaluation measures based on the reference similarity. The first one is discrimination rate (DR). DR, originally proposed by Kojima et al. (2004), is the rate 1To be precise, the structure of WordNet, where some word senses have more than one parent, isn’t a tree but a DAG. The depth of a node is, therefore, defined here as the “maximum distance” from the root node. entity 0 inanimate-object 1 natural-object 2 geological-formation 3 4 natural-elevation coast 5 Figure 2: Example of automatic similarity calculation based on tree structure highly related unrelated (answer, reply) (animal, coffee) (phone, telephone) (him, technology) (sign, signal) (track, vote) (concern, worry) (path, youth) Figure 3: Test-sets for discrimination rate cal</context>
</contexts>
<marker>Kojima, Watabe, Kawaoka, 2004</marker>
<rawString>Kazuhide Kojima, Hirokazu Watabe, and Tsukasa Kawaoka. 2004. Existence and Application of Common Threshold of the Degree of Association. Proc. of the Forum on Information Technology (FIT2004) F-003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Collins</author>
</authors>
<title>Collins Cobuild Mld Major New Edition CD-ROM.</title>
<date>2002</date>
<publisher>HarperCollins Publishers.</publisher>
<contexts>
<context position="17075" citStr="Collins, 2002" startWordPosition="2682" endWordPosition="2684">est set used in DR calculation, except that we employed Np = 4, 000, n = 2, 000 to avoid extreme nonuniformity. 5 Experiments Now we desribe the experimental conditions and results of contextual information selection. 5.1 Condition We used the following three corpora for the experiment: (1) Wall Street Journal (WSJ) corpus (approx. 68,000 sentences, 1.4 million tokens), (2) Brown Corpus (BROWN) (approx. 60,000 sentences, 1.3 million tokens), both of which are contained in Treebank 3 (Marcus, 1994), and (3) written sentences in WordBank (WB) (approx. 190,000 sentences, 3.5 million words) (HyperCollins, 2002). No additional annotation such as POS tags provided for Treebank was used, which means that we gave the plain texts stripped off any additional information to RASP as input. To distinguish nouns, using POS tags annotated by RASP, any words with POS tags APP, ND, NN, NP, PN, PP were labeled as nouns. The window radius for proximity is set to 3. We also set a threshold tf on occurrence frequency in order to filter out any words or contexts with low frequency and to reduce computational cost. More specifically, any words w such that &amp; tf(w, c) &lt; tf and any contexts c such that Ew tf(w, c) &lt; tf w</context>
</contexts>
<marker>Collins, 2002</marker>
<rawString>Collins. 2002. Collins Cobuild Mld Major New Edition CD-ROM. HarperCollins Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Automatic retrieval and clustering of similar words.</title>
<date>1998</date>
<booktitle>Proc. of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational linguistics (COLING-ACL ’98),</booktitle>
<pages>786--774</pages>
<contexts>
<context position="1670" citStr="Lin, 1998" startWordPosition="235" endWordPosition="236">lations and modification categories, and it is found that modification has the greatest contribution, even greater than the widely adopted subjectobject combination. 1 Introduction Lexical knowledge is one of the most important resources in natural language applications, making it almost indispensable for higher levels of syntactical and semantic processing. Among many kinds of lexical relations, synonyms are especially useful ones, having broad range of applications such as query expansion technique in information retrieval and automatic thesaurus construction. Various methods (Hindle, 1990; Lin, 1998; Hagiwara et al., 2005) have been proposed for synonym acquisition. Most of the acquisition methods are based on distributional hypothesis (Harris, 1985), which states that semantically similar words share similar contexts, and it has been experimentally shown considerably plausible. However, whereas many methods which adopt the hypothesis are based on contextual clues concerning words, and there has been much consideration on the language models such as Latent Semantic Indexing (Deerwester et al., 1990) and Probabilistic LSI (Hofmann, 1999) and synonym acquisition method, almost no attention</context>
<context position="12932" citStr="Lin, 1998" startWordPosition="1984" endWordPosition="1985">calculated as 2 ·sim(wi, vj) = di d cdj a, (3) which takes the value between 0.0 and 1.0. Figure 2 shows the example of calculating the similarity between the word senses “hill” and “coast.” The number on the side of each word sense represents the word’s depth. From this tree structure, the similarity is obtained: 2 · 3 sim(“hill”, “coast”) = 5 + 5 =0.6. (4) The similarity between word w with senses w1, ..., wr,, and word v with senses v1, ..., vin is defined as the maximum similarity between all the pairs of word senses: sim(w, v) = max sim(wi, vj), (5) i,j whose idea came from Lin’s method (Lin, 1998). 4.2 Discrimination Rate The following two sections describe two evaluation measures based on the reference similarity. The first one is discrimination rate (DR). DR, originally proposed by Kojima et al. (2004), is the rate 1To be precise, the structure of WordNet, where some word senses have more than one parent, isn’t a tree but a DAG. The depth of a node is, therefore, defined here as the “maximum distance” from the root node. entity 0 inanimate-object 1 natural-object 2 geological-formation 3 4 natural-elevation coast 5 Figure 2: Example of automatic similarity calculation based on tree s</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>Dekang Lin. 1998. Automatic retrieval and clustering of similar words. Proc. of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational linguistics (COLING-ACL ’98), 786–774.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Beatrice Santorini</author>
<author>Mary Ann Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of English: The Penn treebank.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<marker>Marcus, Santorini, Marcinkiewicz, 1994</marker>
<rawString>Mitchell P. Marcus, Beatrice Santorini, and Mary Ann Marcinkiewicz. 1994. Building a large annotated corpus of English: The Penn treebank. Computational Linguistics, 19(2):313–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Makoto Nagao</author>
</authors>
<date>1996</date>
<booktitle>Shizengengoshori. The Iwanami Software Science Series 15, Iwanami Shoten</booktitle>
<publisher>Publishers.</publisher>
<contexts>
<context position="11933" citStr="Nagao, 1996" startWordPosition="1796" endWordPosition="1797">nce similarities from the existing thesaurus WordNet as described in Section 4.1, 355 and by comparing the reference and obtained similarities, two evaluation measures, discrimination rate and correlation coefficient, are calculated automatically as described in Sections 4.2 and 4.3. 4.1 Reference similarity calculation using WordNet As the basis for automatic evaluation methods, the reference similarity, which is the answer value that similarity of a certain pair of words “should take,” is required. We obtained the reference similarity using the calculation based on thesaurus tree structure (Nagao, 1996). This calculation method requires no other resources such as corpus, thus it is simple to implement and widely used. The similarity between word sense wi and word sense vj is obtained using tree structure as follows. Let the depth1 of node wi be di, the depth of node vj be dj, and the maximum depth of the common ancestors of both nodes be ddca. The similarity between wi and vj is then calculated as 2 ·sim(wi, vj) = di d cdj a, (3) which takes the value between 0.0 and 1.0. Figure 2 shows the example of calculating the similarity between the word senses “hill” and “coast.” The number on the si</context>
</contexts>
<marker>Nagao, 1996</marker>
<rawString>Makoto Nagao (ed.). 1996. Shizengengoshori. The Iwanami Software Science Series 15, Iwanami Shoten Publishers.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>