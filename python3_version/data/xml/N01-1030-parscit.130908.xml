<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000415">
<title confidence="0.435045">
Do CFG-Based Language Models Need Agreement Constraints?
</title>
<author confidence="0.517209">
Manny Rayner Beth Ann Hockey Johan Boye
Genevieve Gorrell John Dowding
</author>
<affiliation confidence="0.388173">
netdecisions RIACS, Mail Stop 19-39 Telia Research
</affiliation>
<address confidence="0.8684695">
Wellington House, East Road NASA Ames Research Center S-123 86 Farsta
Cambridge CB1 1BH, UK Moffett Field, CA 94035-1000 Sweden
</address>
<table confidence="0.7685114">
manny.raynerOnetdecisions.co.uk bahockeyOriacs.edu johan.boyeOtrab.se
genevieve.gorrell jdowdingOriacs.edu
Onetdecisions.co.uk
November 8, 2000
Paper ID: NAACL-2001-0090
</table>
<keyword confidence="0.942179666666667">
Keywords: speech recognition, language modelling, context-free grammars, grammatical
agreement, mixed-initiative systems
Contact Author: Manny Rayner (for correspondence)
</keyword>
<sectionHeader confidence="0.8455925" genericHeader="abstract">
Under consideration for other conferences (specify)? No submissions to other conferences
Abstract
</sectionHeader>
<bodyText confidence="0.957054777777778">
Many people are now routinely building grammar-based language models for interactive
spoken language applications; these language models are typically ad hoc semantic
grammars which ignore many standard linguistic constraints, in particular grammatical
agreement. We describe a series of experiments in which we took three CFG-based
language models from non-trivial implemented systems, and in each case contrasted the
performance of a version which included agreement constraints against a version which
ignored them. Our findings suggest that inclusion of agreement constraints significantly
improves performance in terms of both word error rate and semantic error rate.
Do CFG-Based Language Models Need Agreement Constraints?
</bodyText>
<sectionHeader confidence="0.602457" genericHeader="introduction">
Abstract
</sectionHeader>
<bodyText confidence="0.999773875">
Many people are now routinely building grammar-based language models for interactive
spoken language applications; these language models are typically ad hoc semantic gram-
mars which ignore many standard linguistic constraints, in particular grammatical agree-
ment. We describe a series of experiments in which we took three CFG-based language
models from non-trivial implemented systems, and in each case contrasted the perfor-
mance of a version which included agreement constraints against a version which ignored
them. Our findings suggest that inclusion of agreement constraints significantly improves
performance in terms of both word error rate and semantic error rate.
</bodyText>
<sectionHeader confidence="0.998516" genericHeader="method">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999962092307692">
A key problem in building interactive spoken
language systems is constructing a language
model to guide speech recognition. There are
two main approaches: statistical language mod-
els, and grammar-based language models. The
basic idea of the statistical approach is to train
the language model (most often some kind of
N-gram grammar) from a domain corpus; if a
sufficiently large corpus is available, experience
shows that this method can yield excellent re-
sults (Cohen et al., 1995; Ward and Issar, 1995).
In contrast, the grammar-based approach cre-
ates the language model directly in the form of
a (most often hand-coded) grammar.
For the last decade researchers have paid
more attention to the statistical alternative,
and there are many theoretically attractive rea-
sons for preferring it (Mori and Kuhn, 1991;
Rosenfeld and Huang, 1992). However, within
the last two years commercial speech technol-
ogy has adopted the grammar-based approach
(VoiceXML Forum, 2000; W3C, 2000; Nu-
ance Communications, 2000; SpeechWorks In-
ternational, 2000; Tellme, 2000; BeVocal, 2000;
HeyAnita, 2000). This focus on grammar-based
methods is motivated by important practical
and theoretical considerations. Most obviously,
the large quantity of corpus data needed to train
a statistical language model is hardly ever avail-
able; creating it, by Wizard of Oz simulation or
similar methods, is prohibitively expensive. It is
also frequently the case that the language model
changes dynamically with the state of the in-
teraction in some way that is easiest to specify
in terms of rules rather than statistical regu-
larities. For example, the dialogue may concern
choice from some continually changing set of ob-
jects; the appropriate language model will have
to take account of what those objects currently
are, and how they can be referred to.
Another factor that must be considered is the
type of dialogue strategy the system employs.
Language modelling is both more critical and
more difficult in mixed initiative and user ini-
tiative systems. With these dialogue strategies,
the user has a much wider range of potential
utterances than with system initiative. This
makes the recognition problem harder and the
language model larger.
In what follows, we will be mainly concerned
with systems that use a CFG-based language
model and a mixed initiative dialogue strategy.
Since these systems need to be able to respond
to a fairly free range of user input, construct-
ing the language model is usually a non-trivial
task. If it is too constrained, the system will
reject many of the user&apos;s utterances; if it is too
loose, the system will make too many recogni-
tion errors.
One way to build grammar-based language
models is just to apply the techniques devel-
oped for building other types of grammars, in
particular those used for parsing and genera-
tion. Unfortunately, it is non-trivial to trans-
form a grammar written in a high-level linguis-
</bodyText>
<page confidence="0.966235">
1
</page>
<bodyText confidence="0.99997556626506">
tic formalism into a useful CFG-based language
model. In fact, the only really successful piece
of work we are aware of that has taken this
path is the approach pioneered by the Gem-
ini (Dowding et al., 1993; Moore, 1999) and
CommandTalk (Moore et al., 1997; Stent et
al., 1999) projects at SRI. Although the idea
is promising, it is still not clear that it scales up
well to large grammars (Rayner et al., 2000b).
Rather than use the type of methods de-
veloped under Gemini, most people have in-
stead adopted a simpler and more pragmatic
approach. Grammars are developed in an ad
hoc way directly in CFG, and without reference
to linguistic principles. However dubious this
may be from a theoretical point of view, experi-
ence shows that useful grammars can be quickly
developed even for quite complex domains.
In the current paper, we present an empirical
study which contrasts linguistically motivated
and ad hoc approaches to language model con-
struction. In order to be able to make clear
comparisons, we focus specifically on the sin-
gle topic of grammatical agreement. This is
a phenomenon that relevant at least to some
extent in nearly all domains, and is easy to
model in high-level grammatical frameworks.
In contrast, modelling agreement directly in
CFG is rather painful, and as far as we can
tell most commercially deployed speech appli-
cations choose not to do so.
There are only two important examples of
agreement in English: between subject and verb
in clauses, and between determiner and noun
in NPs. In contrast, agreement is a central
phenomenon in many languages like French,
Spanish, Italian, German, Swedish, Russian and
Greek. For example, in French there is agree-
ment between subject and verb and determiner
and noun as in English, and also (among other
things) agreement between nouns and adjec-
tives, subjects and past participles, and sub-
jects and some adverbials. Note that differ-
ent inflected forms of a word can often sound
fairly different. For example, in Swedish the
plural form of an adjective normally adds an
&amp;quot;a&amp;quot;: thus &amp;quot;rod&amp;quot; (&amp;quot;red&amp;quot;, singular) is a mono-
syllable, while &amp;quot;roda&amp;quot; (&amp;quot;red&amp;quot;, plural) is a disyl-
lable. In French, the feminine form of an ad-
jective adds an &amp;quot;e&amp;quot;, which again can affect the
pronunciation. For example &amp;quot;vert&amp;quot; (&amp;quot;green&amp;quot;,
masculine) doesn&apos;t sound the &amp;quot;t&amp;quot;, but &amp;quot;verte&amp;quot;
(&amp;quot;green&amp;quot;, feminine) does sound the &amp;quot;t&amp;quot;.
The rest of the paper is structured as fol-
lows. In Section 2, we describe three imple-
mented systems, two for English and one for
Swedish, which all use mixed-initiative strate-
gies and CFG-based language models. The lan-
guage models for two of these systems were de-
veloped directly in CFG using ad hoc methods,
and in particular ignoring grammatical agree-
ment. The third system was developed in a
high-level formalism and then compiled down
to CFG; this grammar used a principled lin-
guistic approach, which in particular took care-
ful account of agreement. For each system, we
constructed a second version of the language
model, which embodied the converse approach
to agreement. Thus for the ad hoc systems we
constructed versions of the grammars modified
to include all relevant agreement constraints,
and for the theoretically motivated system we
constructed a simplified version of the language
model in which all the agreement constraints
had been removed.
For each of the three systems, we collected
and transcribed a sizeable corpus of recorded
utterances. Section 3 describes experiments in
which the performance of the different versions
of each language model were evaluated empiri-
cally on the domain corpora. The final section
discusses the significance of these results and
concludes.
</bodyText>
<sectionHeader confidence="0.576921" genericHeader="method">
2 Base systems
</sectionHeader>
<bodyText confidence="0.941643777777778">
We carried out experiments on the following
three systems:
On/Off House An ad hoc system for English
in a home automation domain.
Advanced House An ad hoc system for
Swedish, also in a home automation do-
main.
Simulated Personal Satellite Assistant A
linguistically motivated system for English
</bodyText>
<page confidence="0.964858">
2
</page>
<bodyText confidence="0.984457">
in a robotics domain.
In the rest of the section, we describe the sys-
tems and their language models in more detail.
</bodyText>
<subsectionHeader confidence="0.969837">
2.1 On/Off House
</subsectionHeader>
<bodyText confidence="0.99993012195122">
The On/Off House (00H) system is imple-
mented using the Nuance Toolkit (Nuance Com-
munications, 2000), and offers English spoken
language control, via telephone, of about 20 de-
vices in a simulated home. Device states can
only be &amp;quot;on&amp;quot; or &amp;quot;off&amp;quot;. The dialogue manager is
implemented in Visual C++ using the Nuance
DialogueBuilder API. The mode of operation
is primarily user-initiative. The system offers
coverage of a fairly broad range of language,
including commands (&amp;quot;Turn on the heater&amp;quot;,
&amp;quot;Turn off the light in the bathroom&amp;quot;), sev-
eral types of questions (&amp;quot;Is the heater switched
on?&amp;quot;; &amp;quot;What is there in the kitchen?&amp;quot;; &amp;quot;Where
is the washing machine?&amp;quot;; &amp;quot;Could you tell me
which lights are on?&amp;quot;), universal quantifica-
tion (&amp;quot;Switch off everything in the bathroom&amp;quot;),
conjunction (&amp;quot;Are the hall and kitchen lights
switched on?&amp;quot;; &amp;quot;Switch off the radio, TV and
computer&amp;quot;), ellipsis (&amp;quot;Turn on the cooker&amp;quot;...
&amp;quot;now the microwave&amp;quot;) and pronouns (&amp;quot;Switch
off the stereo and the hi-fl&amp;quot;... &amp;quot;switch them on
again&amp;quot;). The system has been tuned over four
or five iterations of user testing, and performs
well enough to have been successfully demon-
strated in public on several occasions. All spo-
ken utterances input to the system during devel-
opment, testing and demos have been recorded
and transcribed, resulting in a speech corpus of
3975 sentences.
The main focus of interest for the purposes of
the present paper is the grammar. It contains
346 context-free rules; of these, 113 are &amp;quot;lexi-
cal&amp;quot; (i.e. have only terminal symbols on their
right-hand sides), while the remaining 233 are
&amp;quot;grammatical&amp;quot; (i.e. contain at least one non-
terminal on the right-hand side).
The grammar is implemented in Nuance
Toolkit Grammar Specification Language (GSL;
(Nuance Communications, 1999)), and directly
encodes a simple slot-value semantics, using
</bodyText>
<figure confidence="0.931613888888889">
a set of 15 slots. These include slots for
Command
CommandIntro CommandBody
1 -----i------,
could_you Switch OnlOff Device
switch on Devicel
Spec DeviceN
1 1
the cooker
</figure>
<figureCaption confidence="0.983932">
Figure 1: Parse tree for &amp;quot;could you switch on
the cooker&amp;quot;
</figureCaption>
<bodyText confidence="0.999748952380953">
the type of utterance (command/query), the
type of device (light/heater/TV/...), the loca-
tion (kitchen/bedroom/bathroom/...), the po-
larity (on/off), and the quantifier (existen-
tial/universal). Because of the quantifier slot,
determiners ( &amp;quot;a&amp;quot; / &amp;quot;the&amp;quot; / &amp;quot;all the&amp;quot; /...) can af-
fect the semantic value of an utterance; this is
necessary in order, for example, to distinguish
&amp;quot;switch on the light&amp;quot; from &amp;quot;switch on all the
lights&amp;quot;.
To give the flavour of the grammar, Figure 1
presents a slightly simplified derivation of the
utterance &amp;quot;could you switch on the cooker&amp;quot;.
This yields the semantic representation
&lt;operation command&gt; &lt;onoff on&gt;
&lt;devicel cooker&gt; &lt;specl existential&gt;
The grammar fails to enforce agreement in num-
ber between subject and verb, or head noun and
determiner; thus for example it will accept sen-
tences such as &amp;quot;*are any light switched on?&amp;quot; or
&amp;quot;*switch off all the heater&amp;quot;.
</bodyText>
<subsectionHeader confidence="0.999459">
2.2 Advanced House
</subsectionHeader>
<bodyText confidence="0.9999014">
Advanced House (AH) is essentially an ex-
tended Swedish version of the 00H system
described in the preceding section. It is im-
plemented using the same platforms (Nuance
Toolkit and the DialogueBuilder API), and of-
fers all the functionality provided by 00H.
Apart from the change of language, there are
two important enhancements. Firstly, AH sup-
ports interfaces to devices whose state can be
represented as a scalar variable, such as dim-
</bodyText>
<page confidence="0.993547">
3
</page>
<bodyText confidence="0.989364410526316">
mer switches and temperature sensors. Sec-
ondly, the devices in question are real as op-
posed to simulated; they are controlled via a
Java servlet interface to a LonWorks device net-
work (Echelon Corporation, 2000). AH is cur-
rently in an initial testing phase, and has not
yet been as thoroughly debugged as 00H. All
utterances input to the system during develop-
ment and testing have been recorded and tran-
scribed, yielding a corpus which at the time of
writing contains 1039 sentences.
As above, our main interest is in the gram-
mar. Coverage is analogous to that of the
00H system, with additional constructions to
cover control and querying of scalar devices, e.g.
&amp;quot;Sank lampan i koket till femtio procent&amp;quot; (Dim
the light in the kitchen to 50 percent); Ytterli-
gare tio procent (another ten percent); &amp;quot;Hur
meinga grader dr det i kylskapet?&amp;quot; (How many
degrees is it in the fridge?) The grammar con-
tains a total of 448 context-free productions,
of which 192 are lexical and 256 non-lexical.
It also resembles the 00H grammar in that
it fails to enforce any kind of agreement con-
straints. In Swedish, the types of agreement
relevant to this domain are between subject
and adjective and between determiner and head
noun; agreement is with respect to both number
(singular/plural) and gender (common/neuter).
Swedish also marks nouns for definiteness, and
certain grammatical contexts require specifi-
cally definite or indefinite nouns; the AH gram-
mar fails to model any of the constraints asso-
ciated with definiteness. Finally, the infinitive
and imperative forms of Swedish verbs are in
general distinct; the grammar once again treats
them interchangeably.
The following sentences exemplify common
types of utterance incorrectly accepted by the
grammar: *stang av lampa (switch off light-
INDEF = switch off the light); *dr lampan
tant (is light-DEF-COMMON lit-NEUTER =
is the light switched on?); *firms det nagon ele-
ment i koket (is there any-COMMON radiator-
NEUTER in kitchen-DEF = is there any ra-
diator in the kitchen?); *sanka belysningen till
halften (lower-INF lighting-DEF to half-DEF =
dim the lighting to a half).
2.3 Simulated Personal Satellite
Assistant
The Personal Satellite Assistant (PSA; (NASA
Ames Research Center, 2000)) is a small robot
currently being developed at NASA Ames Re-
search Center, designed for use in micrograv-
ity and targeted for deployment on the Interna-
tional Space Station. Because of the mobility
of the robot and the problems of microgravity,
English spoken language dialogue is favored as
its primary interface mode. The PSA simulator
(Rayner et al., 2000a) was constructed to aid
in development and testing of the spoken dia-
logue interface. The simulated robot can be in-
structed to move around a diagram of the space
shuttle and measure environmental factors such
as temperature and carbon dioxide. There are
also doors in the simulation that can be opened
and closed, and fans that can be turned on and
off via spoken commands. The system is imple-
mented as a suite of about 20 agents running un-
der the Open Agent Architecture (OAA; (Mar-
tin et al., 1998)), and runs on a high-end SUN
workstation; it is a mature prototype, which has
been publicly demonstrated on numerous occa-
sions. The tests described below were carried
out on a transcribed corpus of 6261 utterances,
collected according to a well-defined protocol
described in (James et al., 2000).
Speech recognition in the simulated PSA is
once again performed using the Nuance Toolkit,
together with a CFG language model. In con-
trast to the two previous systems, the PSA&apos;s
language model is compiled from a linguistically
motivated general unification grammar for En-
glish, using the SRI Gemini compiler (Moore,
1999). The unification grammar formalism pro-
vides an extremely compact description of a
broad range of linguistic constructions; it cur-
rently contains 60 rules and 327 lexical entries,
but after compilation expands these to over
10 000 CFG rules. Coverage includes commands
(&amp;quot;Go to flight deck&amp;quot;; &amp;quot;Turn on the fan at stor-
age lockers&amp;quot;), WH- and Y-N questions (&amp;quot;What
is the pressure at pilot&apos;s seat?&amp;quot;; &amp;quot;Is the radiation
level increasing?&amp;quot;), past tense and reference to
past times (&amp;quot;What was the carbon dioxide level
</bodyText>
<page confidence="0.995018">
4
</page>
<bodyText confidence="0.99996575">
at crew hatch at fifteen oh five?&amp;quot;), numbered
objects (&amp;quot;Start scenario three&amp;quot;), conjunction of
both NPs and clauses (&amp;quot;Measure pressure at
crew hatch and flight deck&amp;quot;; &amp;quot;Go to crew hatch
and switch on the fan&amp;quot;), ellipsis (&amp;quot;Measure pres-
sure&amp;quot;... &amp;quot;how about temperature&amp;quot;), and use of
pronouns (&amp;quot;Open the crew hatch&amp;quot;... &amp;quot;close it&amp;quot;).
The CFG language model produced by Gem-
ini compilation is only used for recognition.
Parsing as such is performed on the recognised
string, using the Gemini parser, and produces
a semantic representation in a version of Quasi
Logical Form (van Eijck and Moore, 1992). The
unification grammar, and issues relating to its
compilation to CFG form, are described in de-
tail in (Rayner et al., 2000b).
</bodyText>
<sectionHeader confidence="0.998559" genericHeader="evaluation">
3 Experiments
</sectionHeader>
<bodyText confidence="0.999982310344827">
In order to carry out the experiments described
here, we constructed alternate versions of each
of the three systems described above. For
the ad hoc 00H and AH systems, we manu-
ally constructed new versions of the CFG lan-
guage models modified to include agreement
constraints. The new versions of the grammars
were substantially larger, as shown in Table 1;
the worst problem, however, was that many
rules from the original grammar had to be du-
plicated in two or more slightly differing forms,
greatly complicating the task of future grammar
maintenance. In contrast, it was extremely easy
to build a version of the PSA unification gram-
mar in which the agreement constraints had
been removed; this only involved editing out a
handful of feature specifications. We were not
able to measure directly the number of context-
free productions in the two versions of the PSA
grammar, but the size of the generated Nuance
grammar decreased from 31K lines of code to
24K, a difference in size comparable with that
observed in the English 00H system.
Our basic plan was to measure performance
of each grammar on its appropriate corpus using
the Nuance batchrec tool, which returns infor-
mation about word error rate (WER), sentence
error rate (SER), and semantic error rate (Sem).
For the 00H and AH systems, we use the stan-
</bodyText>
<table confidence="0.98503025">
English 0011 Swedish All
Non-lex Lex Non-lex Lex
No Agr. 233 113 256 192
Agr. 390 114 326 235
</table>
<tableCaption confidence="0.834293666666667">
Table 1: Numbers of non-lexical and lexical
CFG rules for the two versions of the 00H and
AH systems
</tableCaption>
<bodyText confidence="0.999508710526316">
dard Nuance definition of semantic error rate as
being the proportion of utterances which receive
an incorrect slot-level representation. Since the
PSA grammar returns strings rather than se-
mantic representations, we measured semantic
error rate for it on the QLF representations pro-
duced by the subsequent parsing stage, using a
specially constructed tool. We set the Nuance
recognition parameters to maximize the propor-
tion of utterances which produced a recognition
result: with normal settings, sentences outside
grammar coverage are most frequently rejected.
In this way, we maximize the return of informa-
tion on the out-of-coverage portion of the cor-
pus.
Since performance on in-grammar and out-
of-grammar sentences is still very different, it
makes sense to consider them separately. We
have two grammars for each corpus, a tight
grammar implementing agreement constraints
and a loose grammar failing to do so. This
naturally splits each corpus into the following
four pieces: a) utterances inside coverage of
both grammars (both); b) utterances inside the
coverage of the loose grammar, but not of the
tight grammar (loose-only); c) utterances in-
side the coverage of the tight grammar, but not
of the loose grammar (tight-only); d) utter-
ances inside coverage of neither grammar (nei-
ther). Table 2 shows the relevant breakdown
for each of our three corpora.
In the context of an interactive spoken lan-
guage system, the in-coverage part of the cor-
pus is the practically interesting one. Ta-
bles 3 presents performance figures for the por-
tion of each corpus that is within coverage of
both grammars. In terms of word error rate,
the grammar which enforces agreement con-
</bodyText>
<page confidence="0.991208">
5
</page>
<table confidence="0.999913722222222">
0011 Words Sentences
Both grammars 16067 3511
Neither grammar 2161 437
Loose gram. only 205 27
Tight gram. only 0 0
Total 18433 3975
All Words Sentences
Both grammars 2535 691
Neither grammar 1482 345
Loose gram. only 5 3
Tight gram. only 0 0
Total 4022 1039
PSA Words Sentences
Both grammars 23051 5676
Neither grammar 3937 585
Loose gram. only 10 2
Tight gram. only 0 0
Total 26998 6263
</table>
<tableCaption confidence="0.998977">
Table 2: Sizes of sub-corpora for the systems
</tableCaption>
<bodyText confidence="0.999426454545455">
straints scores significantly better in the two En-
glish language systems (relative improvements
of 17% for 00H and 16.5% for PSA), a differ-
ence which increases to a striking 46% for the
Swedish language system. In view of the fact
that agreement is considerably more important
in Swedish than in English, this disparity is not
surprising.
A similar pattern is displayed in the sentence
error rate figures, with relative improvements
of about 20% for the two English systems, and
</bodyText>
<table confidence="0.999708777777778">
0011 WER SER Sem.
No Agr. 10.86% 25.06% 14.64%
Agr. 9.01% 19.71% 10.17%
All WER SER Sem.
No Agr. 12.47% 24.89% 12.74%
Agr. 6.71% 10.85% 10.27%
PSA WER SER Sem.
No Agr. 13.73% 29.03% 27.63%
Agr. 11.47% 23.24% 22.11%
</table>
<tableCaption confidence="0.985494">
Table 3: Error rates for both versions of the
systems on utterances within coverage of both
grammars
</tableCaption>
<table confidence="0.999911">
0011 WER SER Sem.
No Agr. 58.72% 95.19% n/a
Agr. 58.54% 95.19% n/a
All WER SER Sem.
No Agr. 68.56% 98.84% n/a
Agr. 66.80% 98.55% n/a
PSA WER SER Sem.
No Agr. 52.78% 95.90% n/a
Agr. 53.49% 95.04% n/a
</table>
<tableCaption confidence="0.936754666666667">
Table 4: Error rates for both versions of the
systems on utterances within coverage of neither
grammar
</tableCaption>
<table confidence="0.999748666666667">
WER SER Sem.
No Agr. 14.15% 74.07% 22.22%
Agr. 20.98% 100.00% 40.74%
</table>
<tableCaption confidence="0.857099666666667">
Table 5: Error rates for both versions of the
00H system on utterances within coverage of
loose grammar only
</tableCaption>
<bodyText confidence="0.99960488">
56% for the Swedish one. For completeness, we
also present in Table 4 results for utterances
outside coverage of either grammar; these dis-
play little interesting variation. Finally, Table 5
gives the results for the 27 00H utterances
inside coverage of the loose but not the tight
grammar. Unsurprisingly, the loose grammar
performs much better on this set.
The most critical measure of performance for
systems of this kind is the semantic error rate,
which is only meaningful for the in-coverage
portion of the corpus. At first sight, the figures
in Table 3 also appear to show a marked im-
provement in favour of the tight grammar, with
proportional reductions of 31% for 00H, 20%
for AH, and 20% for PSA. We were somewhat
surprised to see 00H scoring so much better
than the other two systems, and carried out a
detailed item-by-item comparison of the 00H
data. This revealed that a substantial propor-
tion of the 00H improvement was essentially
spurious; for technical reasons relating to the
way in which NP conjunction was modelled,
many sentences where the tight grammar won
were examples like
</bodyText>
<page confidence="0.998544">
6
</page>
<bodyText confidence="0.999384282051282">
switch on the light and the TV
where the loose grammar incorrectly recognised
switch on the light and TV
Although this technically counts as a reduction
of the semantic error rate, it is obviously of lit-
tle practical importance. After eliminating all
examples of the above type, we were left with
a residue of 47 utterances where one grammar
was right and the other wrong; of these, the
tight grammar was correct in 37 cases and the
loose one in the remaining 10. A more realis-
tic estimate of the absolute reduction in seman-
tic error rate for the 00H system as a result
of correctly modelling agreement would thus be
(37— 10)/3511, or 0.7%, giving a relative reduc-
tion of about 5%. Although undramatic, this
margin is significant at the 0.05% level accord-
ing to the McNemar sign test (McNemar, 1947).
The following examples show typical instances
of the tight grammar (T) outscoring the loose
one (L).
T: turn them off
L: is them off
T: put the computer on
L: are the computer on
T: what is switched on in the
kitchen
L: what fridge are in the kitchen
We carried out a similar item-by-item com-
parison of the tight and loose grammars for the
Swedish AH system. This time, there were 20
utterances for which the result in one grammar
was clearly correct results and the other clearly
incorrect, dividing 19-1 in favour of the tight
grammar. The revised estimate of reduction
in semantic error rate is thus (19 — 1)/691 =
2.6% absolute, or a more substantial 20% rela-
tive. This result is also significant at the 0.05%
level according to the McNemar test.
</bodyText>
<sectionHeader confidence="0.942818" genericHeader="conclusions">
4 Conclusions and further directions
</sectionHeader>
<bodyText confidence="0.999960372549019">
When we began work on the experiments de-
scribed here, we felt that there were two com-
peting positions concerning the question of
whether or not it was important to include
agreement constraints in CFG-based language
models. From a research-oriented theoretical
standpoint, we believed that it would be im-
possible to ignore a linguistic phenomenon as
central as grammatical agreement without in-
curring some significant penalty. Practical im-
plementation experience however pointed in the
opposite direction: most commercial systems
fail to take account of agreement, and achieve
adequate performance using mostly semantic
and domain constraints.
With the results in front of us, we think that
both sides can lay some claim to being right.
There is indeed a very significant improvement
in performance when agreement constraints are
added to a grammar. However, this improve-
ment is manifested most strongly at the surface
level, as measured by WER and SER. Although
the difference is still strongly significant at the
level of semantic representation, the absolute in-
crease in semantic accuracy is fairly small. A
practical system builder can reasonably wonder
whether these gains are enough to motivate the
considerable extra implementation burden cre-
ated by adding agreement to a hand-coded CFG
language model. If the CFG model is compiled
from a high-level description, however, there is
little additional work to be done, and it is obvi-
ously desirable to include agreement constraints
in the grammar. This can be interpreted as an
argument in favour of using high-level linguis-
tic descriptions as opposed to hand-coded CFG
models.
Looking further ahead, it is also important to
remember that grammatical agreement is only
one of a large range of linguistic phenomena
currently ignored by most practical implemen-
tors. It is unclear to us how large the cumu-
lative effect may become when detailed mod-
elling of many such phenomena is added to an
atheoretical coarse-grained language model, and
it is seems plausible that it could be consid-
erably greater than that produced by the sin-
gle phenomenon we have investigated here. It
is feasible to investigate these questions em-
pirically by modifying large-scale linguistically
motivated systems like the PSA grammar de-
</bodyText>
<page confidence="0.997677">
7
</page>
<bodyText confidence="0.9442965">
scribed in this paper; we hope to present further
results in due course.
NASA Ames Research Center, 2000. Per-
sonal Satellite Assistant (PSA) Project.
http://ic.arc.nasa.gov/ic/psa/. As of 6 November
2000.
</bodyText>
<sectionHeader confidence="0.965754" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999860197674419">
BeVocal, 2000. Be Vocal.
http://www.bevocal.com/index.html. As of
6 November 2000.
M. Cohen, Z. Rivlin, and H. Bratt. 1995. Speech
recognition in the ATIS domain using multiple
knowledge sources. In Proceedings of the Spoken
Language Systems Technology Workshop, pages
257-260.
J. Dowding, M. Gawron, D. Appelt, L. Cherny,
R. Moore, and D. Moran. 1993. Gemini: A
natural language system for spoken language un-
derstanding. In Proceedings of the Thirty-First
Annual Meeting of the Association for Computa-
tional Linguistics.
Echelon Corporation, 2000. L 0 N-
WORKS CORE TECHNOLOGY.
http://www.echelon.com/Products/Core/.
As of 6 November 2000.
HeyAnita, 2000. HeyAnita.
http://heyanita.com/html/main/index.html.
As of 6 November 2000.
F. James, M. Rayner, and B.A. Hockey. 2000. Ac-
curacy, coverage, and speed: What do they mean
to users? In CHI 2000 Workshop on Natural-
Language Interaction.
D. Martin, A. Cheyer, and D. Moran. 1998. Build-
ing distributed software systems with the open
agent architecture. In Proceedings of the Third
International Conference on the Practical Appli-
cation of Intelligent Agents and Multi-Agent Tech-
nology, Blackpool, Lancashire, UK.
Q. McNemar. 1947. Note on the sampling error of
the difference between correlated proportions or
percentages. Psychometrika, 12(2):153-157.
R. Moore, J. Dowding, H. Bratt, J. Gawron,
Y. Gorfu, and A. Cheyer. 1997. CommandTalk:
A spoken-language interface for battlefield simu-
lations. In Proceedings of the Fifth Conference on
Applied Natural Language Processing, pages 1-7.
R. Moore. 1999. Using natural language
knowledge sources in speech recognition. In
Keith Ponting, editor, Speech Pattern Processing.
Springer-Verlag.
R. De Mori and R. Kuhn. 1991. Some results on
stochastic language modelling. In Speech and Nat-
ural Language Workshop, pages 225-230.
Nuance Communications, 1999. Nuance Speech
Recognition System Developer&apos;s Manual version
6.2. 1380 Willow Road, Menlo Park, CA 94025.
Nuance Communications, 2000. Nuance Home.
http://www.nuance.com. As of 6 November 2000.
M. Rayner, B.A. Hockey, and F. James. 2000a.
A compact architecture for dialogue management
based on scripts and meta-outputs. In Pro-
ceedings of Applied Natural Language Processing
(ANLP).
M. Rayner, B.A. Hockey, F. James, E.O. Bratt,
S. Goldwater„ and J.M. Gawron. 2000b. Com-
piling language models from a linguistically mo-
tivated unification grammar. In Proceedings of
COLING 2000.
R. Rosenfeld and X. Huang. 1992. Improvements
in stochastic language modeling. In Speech and
Natural Language Workshop, pages 107-111.
SpeechWorks International, 2000. Speech Works In-
ternational. http://www.speechworks.com. As of
6 November 2000.
A. Stent, J. Dowding, J. Gawron, E. Bratt, and
R. Moore. 1999. The CommandTalk spoken
dialogue system. In Proceedings of the Thirty-
Seventh Annual Meeting of the Association for
Computational Linguistics, pages 183-190.
Tellme, 2000. Tellme. http://www.tellme.com/. As
of 6 November 2000.
J. van Eijck and R. Moore. 1992. Semantic rules
for English. In H. Alshawi, editor, The Core Lan-
guage Engine. MIT Press.
VoiceXML Forum, 2000. VoiceXML Forum.
http://www.voicexml.org/index.html. As of 6
November 2000.
W3C, 2000. Speech Recognition Grammar Specifica-
tion. http://www.w3.org/TR/grammar-spec. As
of 6 November 2000.
W. Ward and S. Issar. 1995. The cmu atis system.
In Spoken Language System Technology Work-
shop, pages 249-251.
</reference>
<page confidence="0.998489">
8
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.140956">
<title confidence="0.996647">Do CFG-Based Language Models Need Agreement Constraints?</title>
<author confidence="0.9971545">Manny Rayner Beth Ann Hockey Johan Boye Genevieve Gorrell John Dowding</author>
<affiliation confidence="0.849517">netdecisions RIACS, Mail Stop 19-39 Telia Research</affiliation>
<address confidence="0.9393665">Wellington House, East Road NASA Ames Research Center S-123 86 Farsta Cambridge CB1 1BH, UK Moffett Field, CA 94035-1000 Sweden</address>
<email confidence="0.611910333333333">manny.raynerOnetdecisions.co.ukbahockeyOriacs.edujohan.boyeOtrab.segenevieve.gorrellOnetdecisions.co.uk</email>
<date confidence="0.648709">November 8, 2000</date>
<abstract confidence="0.968252782608696">recognition, language modelling, context-free grammars, grammatical agreement, mixed-initiative systems Author: Rayner (for correspondence) consideration for other conferences (specify)? submissions to other conferences Abstract Many people are now routinely building grammar-based language models for interactive language applications; these language models are typically hoc grammars which ignore many standard linguistic constraints, in particular grammatical agreement. We describe a series of experiments in which we took three CFG-based language models from non-trivial implemented systems, and in each case contrasted the performance of a version which included agreement constraints against a version which ignored them. Our findings suggest that inclusion of agreement constraints significantly improves performance in terms of both word error rate and semantic error rate. Do CFG-Based Language Models Need Agreement Constraints? Abstract Many people are now routinely building grammar-based language models for interactive language applications; these language models are typically hoc grammars which ignore many standard linguistic constraints, in particular grammatical agreement. We describe a series of experiments in which we took three CFG-based language models from non-trivial implemented systems, and in each case contrasted the performance of a version which included agreement constraints against a version which ignored them. Our findings suggest that inclusion of agreement constraints significantly improves performance in terms of both word error rate and semantic error rate.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>BeVocal</author>
</authors>
<title>Be Vocal. http://www.bevocal.com/index.html.</title>
<date>2000</date>
<journal>As of</journal>
<volume>6</volume>
<contexts>
<context position="3241" citStr="BeVocal, 2000" startWordPosition="447" endWordPosition="448">results (Cohen et al., 1995; Ward and Issar, 1995). In contrast, the grammar-based approach creates the language model directly in the form of a (most often hand-coded) grammar. For the last decade researchers have paid more attention to the statistical alternative, and there are many theoretically attractive reasons for preferring it (Mori and Kuhn, 1991; Rosenfeld and Huang, 1992). However, within the last two years commercial speech technology has adopted the grammar-based approach (VoiceXML Forum, 2000; W3C, 2000; Nuance Communications, 2000; SpeechWorks International, 2000; Tellme, 2000; BeVocal, 2000; HeyAnita, 2000). This focus on grammar-based methods is motivated by important practical and theoretical considerations. Most obviously, the large quantity of corpus data needed to train a statistical language model is hardly ever available; creating it, by Wizard of Oz simulation or similar methods, is prohibitively expensive. It is also frequently the case that the language model changes dynamically with the state of the interaction in some way that is easiest to specify in terms of rules rather than statistical regularities. For example, the dialogue may concern choice from some continual</context>
</contexts>
<marker>BeVocal, 2000</marker>
<rawString>BeVocal, 2000. Be Vocal. http://www.bevocal.com/index.html. As of 6 November 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Cohen</author>
<author>Z Rivlin</author>
<author>H Bratt</author>
</authors>
<title>Speech recognition in the ATIS domain using multiple knowledge sources.</title>
<date>1995</date>
<booktitle>In Proceedings of the Spoken Language Systems Technology Workshop,</booktitle>
<pages>257--260</pages>
<contexts>
<context position="2655" citStr="Cohen et al., 1995" startWordPosition="357" endWordPosition="360">on of agreement constraints significantly improves performance in terms of both word error rate and semantic error rate. 1 Introduction A key problem in building interactive spoken language systems is constructing a language model to guide speech recognition. There are two main approaches: statistical language models, and grammar-based language models. The basic idea of the statistical approach is to train the language model (most often some kind of N-gram grammar) from a domain corpus; if a sufficiently large corpus is available, experience shows that this method can yield excellent results (Cohen et al., 1995; Ward and Issar, 1995). In contrast, the grammar-based approach creates the language model directly in the form of a (most often hand-coded) grammar. For the last decade researchers have paid more attention to the statistical alternative, and there are many theoretically attractive reasons for preferring it (Mori and Kuhn, 1991; Rosenfeld and Huang, 1992). However, within the last two years commercial speech technology has adopted the grammar-based approach (VoiceXML Forum, 2000; W3C, 2000; Nuance Communications, 2000; SpeechWorks International, 2000; Tellme, 2000; BeVocal, 2000; HeyAnita, 20</context>
</contexts>
<marker>Cohen, Rivlin, Bratt, 1995</marker>
<rawString>M. Cohen, Z. Rivlin, and H. Bratt. 1995. Speech recognition in the ATIS domain using multiple knowledge sources. In Proceedings of the Spoken Language Systems Technology Workshop, pages 257-260.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Dowding</author>
<author>M Gawron</author>
<author>D Appelt</author>
<author>L Cherny</author>
<author>R Moore</author>
<author>D Moran</author>
</authors>
<title>Gemini: A natural language system for spoken language understanding.</title>
<date>1993</date>
<booktitle>In Proceedings of the Thirty-First Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="5296" citStr="Dowding et al., 1993" startWordPosition="787" endWordPosition="790"> is too constrained, the system will reject many of the user&apos;s utterances; if it is too loose, the system will make too many recognition errors. One way to build grammar-based language models is just to apply the techniques developed for building other types of grammars, in particular those used for parsing and generation. Unfortunately, it is non-trivial to transform a grammar written in a high-level linguis1 tic formalism into a useful CFG-based language model. In fact, the only really successful piece of work we are aware of that has taken this path is the approach pioneered by the Gemini (Dowding et al., 1993; Moore, 1999) and CommandTalk (Moore et al., 1997; Stent et al., 1999) projects at SRI. Although the idea is promising, it is still not clear that it scales up well to large grammars (Rayner et al., 2000b). Rather than use the type of methods developed under Gemini, most people have instead adopted a simpler and more pragmatic approach. Grammars are developed in an ad hoc way directly in CFG, and without reference to linguistic principles. However dubious this may be from a theoretical point of view, experience shows that useful grammars can be quickly developed even for quite complex domains</context>
</contexts>
<marker>Dowding, Gawron, Appelt, Cherny, Moore, Moran, 1993</marker>
<rawString>J. Dowding, M. Gawron, D. Appelt, L. Cherny, R. Moore, and D. Moran. 1993. Gemini: A natural language system for spoken language understanding. In Proceedings of the Thirty-First Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="false">
<date>2000</date>
<institution>Echelon Corporation,</institution>
<note>L 0 N-</note>
<marker>2000</marker>
<rawString>Echelon Corporation, 2000. L 0 N-</rawString>
</citation>
<citation valid="true">
<authors>
<author>http www echelon comProductsCore</author>
</authors>
<date>2000</date>
<journal>As of</journal>
<volume>6</volume>
<marker>comProductsCore, 2000</marker>
<rawString>WORKS CORE TECHNOLOGY. http://www.echelon.com/Products/Core/. As of 6 November 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>HeyAnita</author>
</authors>
<date>2000</date>
<journal>HeyAnita. http://heyanita.com/html/main/index.html. As of</journal>
<volume>6</volume>
<contexts>
<context position="3258" citStr="HeyAnita, 2000" startWordPosition="449" endWordPosition="450">et al., 1995; Ward and Issar, 1995). In contrast, the grammar-based approach creates the language model directly in the form of a (most often hand-coded) grammar. For the last decade researchers have paid more attention to the statistical alternative, and there are many theoretically attractive reasons for preferring it (Mori and Kuhn, 1991; Rosenfeld and Huang, 1992). However, within the last two years commercial speech technology has adopted the grammar-based approach (VoiceXML Forum, 2000; W3C, 2000; Nuance Communications, 2000; SpeechWorks International, 2000; Tellme, 2000; BeVocal, 2000; HeyAnita, 2000). This focus on grammar-based methods is motivated by important practical and theoretical considerations. Most obviously, the large quantity of corpus data needed to train a statistical language model is hardly ever available; creating it, by Wizard of Oz simulation or similar methods, is prohibitively expensive. It is also frequently the case that the language model changes dynamically with the state of the interaction in some way that is easiest to specify in terms of rules rather than statistical regularities. For example, the dialogue may concern choice from some continually changing set o</context>
</contexts>
<marker>HeyAnita, 2000</marker>
<rawString>HeyAnita, 2000. HeyAnita. http://heyanita.com/html/main/index.html. As of 6 November 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F James</author>
<author>M Rayner</author>
<author>B A Hockey</author>
</authors>
<title>Accuracy, coverage, and speed: What do they mean to users?</title>
<date>2000</date>
<booktitle>In CHI 2000 Workshop on NaturalLanguage Interaction.</booktitle>
<contexts>
<context position="15953" citStr="James et al., 2000" startWordPosition="2529" endWordPosition="2532">asure environmental factors such as temperature and carbon dioxide. There are also doors in the simulation that can be opened and closed, and fans that can be turned on and off via spoken commands. The system is implemented as a suite of about 20 agents running under the Open Agent Architecture (OAA; (Martin et al., 1998)), and runs on a high-end SUN workstation; it is a mature prototype, which has been publicly demonstrated on numerous occasions. The tests described below were carried out on a transcribed corpus of 6261 utterances, collected according to a well-defined protocol described in (James et al., 2000). Speech recognition in the simulated PSA is once again performed using the Nuance Toolkit, together with a CFG language model. In contrast to the two previous systems, the PSA&apos;s language model is compiled from a linguistically motivated general unification grammar for English, using the SRI Gemini compiler (Moore, 1999). The unification grammar formalism provides an extremely compact description of a broad range of linguistic constructions; it currently contains 60 rules and 327 lexical entries, but after compilation expands these to over 10 000 CFG rules. Coverage includes commands (&amp;quot;Go to f</context>
</contexts>
<marker>James, Rayner, Hockey, 2000</marker>
<rawString>F. James, M. Rayner, and B.A. Hockey. 2000. Accuracy, coverage, and speed: What do they mean to users? In CHI 2000 Workshop on NaturalLanguage Interaction.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Martin</author>
<author>A Cheyer</author>
<author>D Moran</author>
</authors>
<title>Building distributed software systems with the open agent architecture.</title>
<date>1998</date>
<booktitle>In Proceedings of the Third International Conference on the Practical Application of Intelligent Agents and Multi-Agent Technology,</booktitle>
<location>Blackpool, Lancashire, UK.</location>
<contexts>
<context position="15657" citStr="Martin et al., 1998" startWordPosition="2481" endWordPosition="2485">avity, English spoken language dialogue is favored as its primary interface mode. The PSA simulator (Rayner et al., 2000a) was constructed to aid in development and testing of the spoken dialogue interface. The simulated robot can be instructed to move around a diagram of the space shuttle and measure environmental factors such as temperature and carbon dioxide. There are also doors in the simulation that can be opened and closed, and fans that can be turned on and off via spoken commands. The system is implemented as a suite of about 20 agents running under the Open Agent Architecture (OAA; (Martin et al., 1998)), and runs on a high-end SUN workstation; it is a mature prototype, which has been publicly demonstrated on numerous occasions. The tests described below were carried out on a transcribed corpus of 6261 utterances, collected according to a well-defined protocol described in (James et al., 2000). Speech recognition in the simulated PSA is once again performed using the Nuance Toolkit, together with a CFG language model. In contrast to the two previous systems, the PSA&apos;s language model is compiled from a linguistically motivated general unification grammar for English, using the SRI Gemini comp</context>
</contexts>
<marker>Martin, Cheyer, Moran, 1998</marker>
<rawString>D. Martin, A. Cheyer, and D. Moran. 1998. Building distributed software systems with the open agent architecture. In Proceedings of the Third International Conference on the Practical Application of Intelligent Agents and Multi-Agent Technology, Blackpool, Lancashire, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Q McNemar</author>
</authors>
<title>Note on the sampling error of the difference between correlated proportions or percentages.</title>
<date>1947</date>
<journal>Psychometrika,</journal>
<pages>12--2</pages>
<contexts>
<context position="24310" citStr="McNemar, 1947" startWordPosition="3944" endWordPosition="3945">s obviously of little practical importance. After eliminating all examples of the above type, we were left with a residue of 47 utterances where one grammar was right and the other wrong; of these, the tight grammar was correct in 37 cases and the loose one in the remaining 10. A more realistic estimate of the absolute reduction in semantic error rate for the 00H system as a result of correctly modelling agreement would thus be (37— 10)/3511, or 0.7%, giving a relative reduction of about 5%. Although undramatic, this margin is significant at the 0.05% level according to the McNemar sign test (McNemar, 1947). The following examples show typical instances of the tight grammar (T) outscoring the loose one (L). T: turn them off L: is them off T: put the computer on L: are the computer on T: what is switched on in the kitchen L: what fridge are in the kitchen We carried out a similar item-by-item comparison of the tight and loose grammars for the Swedish AH system. This time, there were 20 utterances for which the result in one grammar was clearly correct results and the other clearly incorrect, dividing 19-1 in favour of the tight grammar. The revised estimate of reduction in semantic error rate is </context>
</contexts>
<marker>McNemar, 1947</marker>
<rawString>Q. McNemar. 1947. Note on the sampling error of the difference between correlated proportions or percentages. Psychometrika, 12(2):153-157.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Moore</author>
<author>J Dowding</author>
<author>H Bratt</author>
<author>J Gawron</author>
<author>Y Gorfu</author>
<author>A Cheyer</author>
</authors>
<title>CommandTalk: A spoken-language interface for battlefield simulations.</title>
<date>1997</date>
<booktitle>In Proceedings of the Fifth Conference on Applied Natural Language Processing,</booktitle>
<pages>1--7</pages>
<contexts>
<context position="5346" citStr="Moore et al., 1997" startWordPosition="795" endWordPosition="798">the user&apos;s utterances; if it is too loose, the system will make too many recognition errors. One way to build grammar-based language models is just to apply the techniques developed for building other types of grammars, in particular those used for parsing and generation. Unfortunately, it is non-trivial to transform a grammar written in a high-level linguis1 tic formalism into a useful CFG-based language model. In fact, the only really successful piece of work we are aware of that has taken this path is the approach pioneered by the Gemini (Dowding et al., 1993; Moore, 1999) and CommandTalk (Moore et al., 1997; Stent et al., 1999) projects at SRI. Although the idea is promising, it is still not clear that it scales up well to large grammars (Rayner et al., 2000b). Rather than use the type of methods developed under Gemini, most people have instead adopted a simpler and more pragmatic approach. Grammars are developed in an ad hoc way directly in CFG, and without reference to linguistic principles. However dubious this may be from a theoretical point of view, experience shows that useful grammars can be quickly developed even for quite complex domains. In the current paper, we present an empirical st</context>
</contexts>
<marker>Moore, Dowding, Bratt, Gawron, Gorfu, Cheyer, 1997</marker>
<rawString>R. Moore, J. Dowding, H. Bratt, J. Gawron, Y. Gorfu, and A. Cheyer. 1997. CommandTalk: A spoken-language interface for battlefield simulations. In Proceedings of the Fifth Conference on Applied Natural Language Processing, pages 1-7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Moore</author>
</authors>
<title>Using natural language knowledge sources in speech recognition.</title>
<date>1999</date>
<booktitle>In Keith Ponting, editor, Speech Pattern Processing.</booktitle>
<publisher>Springer-Verlag.</publisher>
<contexts>
<context position="5310" citStr="Moore, 1999" startWordPosition="791" endWordPosition="792">he system will reject many of the user&apos;s utterances; if it is too loose, the system will make too many recognition errors. One way to build grammar-based language models is just to apply the techniques developed for building other types of grammars, in particular those used for parsing and generation. Unfortunately, it is non-trivial to transform a grammar written in a high-level linguis1 tic formalism into a useful CFG-based language model. In fact, the only really successful piece of work we are aware of that has taken this path is the approach pioneered by the Gemini (Dowding et al., 1993; Moore, 1999) and CommandTalk (Moore et al., 1997; Stent et al., 1999) projects at SRI. Although the idea is promising, it is still not clear that it scales up well to large grammars (Rayner et al., 2000b). Rather than use the type of methods developed under Gemini, most people have instead adopted a simpler and more pragmatic approach. Grammars are developed in an ad hoc way directly in CFG, and without reference to linguistic principles. However dubious this may be from a theoretical point of view, experience shows that useful grammars can be quickly developed even for quite complex domains. In the curre</context>
<context position="16275" citStr="Moore, 1999" startWordPosition="2582" endWordPosition="2583"> runs on a high-end SUN workstation; it is a mature prototype, which has been publicly demonstrated on numerous occasions. The tests described below were carried out on a transcribed corpus of 6261 utterances, collected according to a well-defined protocol described in (James et al., 2000). Speech recognition in the simulated PSA is once again performed using the Nuance Toolkit, together with a CFG language model. In contrast to the two previous systems, the PSA&apos;s language model is compiled from a linguistically motivated general unification grammar for English, using the SRI Gemini compiler (Moore, 1999). The unification grammar formalism provides an extremely compact description of a broad range of linguistic constructions; it currently contains 60 rules and 327 lexical entries, but after compilation expands these to over 10 000 CFG rules. Coverage includes commands (&amp;quot;Go to flight deck&amp;quot;; &amp;quot;Turn on the fan at storage lockers&amp;quot;), WH- and Y-N questions (&amp;quot;What is the pressure at pilot&apos;s seat?&amp;quot;; &amp;quot;Is the radiation level increasing?&amp;quot;), past tense and reference to past times (&amp;quot;What was the carbon dioxide level 4 at crew hatch at fifteen oh five?&amp;quot;), numbered objects (&amp;quot;Start scenario three&amp;quot;), conjunctio</context>
</contexts>
<marker>Moore, 1999</marker>
<rawString>R. Moore. 1999. Using natural language knowledge sources in speech recognition. In Keith Ponting, editor, Speech Pattern Processing. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R De Mori</author>
<author>R Kuhn</author>
</authors>
<title>Some results on stochastic language modelling.</title>
<date>1991</date>
<booktitle>In Speech and Natural Language Workshop,</booktitle>
<pages>225--230</pages>
<marker>De Mori, Kuhn, 1991</marker>
<rawString>R. De Mori and R. Kuhn. 1991. Some results on stochastic language modelling. In Speech and Natural Language Workshop, pages 225-230.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nuance Communications</author>
</authors>
<title>Nuance Speech Recognition System Developer&apos;s Manual version 6.2. 1380 Willow Road,</title>
<date>1999</date>
<pages>94025</pages>
<location>Menlo Park, CA</location>
<contexts>
<context position="10936" citStr="Communications, 1999" startWordPosition="1711" endWordPosition="1712">d in public on several occasions. All spoken utterances input to the system during development, testing and demos have been recorded and transcribed, resulting in a speech corpus of 3975 sentences. The main focus of interest for the purposes of the present paper is the grammar. It contains 346 context-free rules; of these, 113 are &amp;quot;lexical&amp;quot; (i.e. have only terminal symbols on their right-hand sides), while the remaining 233 are &amp;quot;grammatical&amp;quot; (i.e. contain at least one nonterminal on the right-hand side). The grammar is implemented in Nuance Toolkit Grammar Specification Language (GSL; (Nuance Communications, 1999)), and directly encodes a simple slot-value semantics, using a set of 15 slots. These include slots for Command CommandIntro CommandBody 1 -----i------, could_you Switch OnlOff Device switch on Devicel Spec DeviceN 1 1 the cooker Figure 1: Parse tree for &amp;quot;could you switch on the cooker&amp;quot; the type of utterance (command/query), the type of device (light/heater/TV/...), the location (kitchen/bedroom/bathroom/...), the polarity (on/off), and the quantifier (existential/universal). Because of the quantifier slot, determiners ( &amp;quot;a&amp;quot; / &amp;quot;the&amp;quot; / &amp;quot;all the&amp;quot; /...) can affect the semantic value of an utteran</context>
</contexts>
<marker>Communications, 1999</marker>
<rawString>Nuance Communications, 1999. Nuance Speech Recognition System Developer&apos;s Manual version 6.2. 1380 Willow Road, Menlo Park, CA 94025.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nuance Communications</author>
</authors>
<title>Nuance Home. http://www.nuance.com.</title>
<date>2000</date>
<journal>As of</journal>
<volume>6</volume>
<contexts>
<context position="3179" citStr="Communications, 2000" startWordPosition="439" endWordPosition="440"> is available, experience shows that this method can yield excellent results (Cohen et al., 1995; Ward and Issar, 1995). In contrast, the grammar-based approach creates the language model directly in the form of a (most often hand-coded) grammar. For the last decade researchers have paid more attention to the statistical alternative, and there are many theoretically attractive reasons for preferring it (Mori and Kuhn, 1991; Rosenfeld and Huang, 1992). However, within the last two years commercial speech technology has adopted the grammar-based approach (VoiceXML Forum, 2000; W3C, 2000; Nuance Communications, 2000; SpeechWorks International, 2000; Tellme, 2000; BeVocal, 2000; HeyAnita, 2000). This focus on grammar-based methods is motivated by important practical and theoretical considerations. Most obviously, the large quantity of corpus data needed to train a statistical language model is hardly ever available; creating it, by Wizard of Oz simulation or similar methods, is prohibitively expensive. It is also frequently the case that the language model changes dynamically with the state of the interaction in some way that is easiest to specify in terms of rules rather than statistical regularities. Fo</context>
<context position="9280" citStr="Communications, 2000" startWordPosition="1445" endWordPosition="1447"> The final section discusses the significance of these results and concludes. 2 Base systems We carried out experiments on the following three systems: On/Off House An ad hoc system for English in a home automation domain. Advanced House An ad hoc system for Swedish, also in a home automation domain. Simulated Personal Satellite Assistant A linguistically motivated system for English 2 in a robotics domain. In the rest of the section, we describe the systems and their language models in more detail. 2.1 On/Off House The On/Off House (00H) system is implemented using the Nuance Toolkit (Nuance Communications, 2000), and offers English spoken language control, via telephone, of about 20 devices in a simulated home. Device states can only be &amp;quot;on&amp;quot; or &amp;quot;off&amp;quot;. The dialogue manager is implemented in Visual C++ using the Nuance DialogueBuilder API. The mode of operation is primarily user-initiative. The system offers coverage of a fairly broad range of language, including commands (&amp;quot;Turn on the heater&amp;quot;, &amp;quot;Turn off the light in the bathroom&amp;quot;), several types of questions (&amp;quot;Is the heater switched on?&amp;quot;; &amp;quot;What is there in the kitchen?&amp;quot;; &amp;quot;Where is the washing machine?&amp;quot;; &amp;quot;Could you tell me which lights are on?&amp;quot;), unive</context>
</contexts>
<marker>Communications, 2000</marker>
<rawString>Nuance Communications, 2000. Nuance Home. http://www.nuance.com. As of 6 November 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Rayner</author>
<author>B A Hockey</author>
<author>F James</author>
</authors>
<title>A compact architecture for dialogue management based on scripts and meta-outputs.</title>
<date>2000</date>
<booktitle>In Proceedings of Applied Natural Language Processing (ANLP).</booktitle>
<contexts>
<context position="5500" citStr="Rayner et al., 2000" startWordPosition="824" endWordPosition="827">ply the techniques developed for building other types of grammars, in particular those used for parsing and generation. Unfortunately, it is non-trivial to transform a grammar written in a high-level linguis1 tic formalism into a useful CFG-based language model. In fact, the only really successful piece of work we are aware of that has taken this path is the approach pioneered by the Gemini (Dowding et al., 1993; Moore, 1999) and CommandTalk (Moore et al., 1997; Stent et al., 1999) projects at SRI. Although the idea is promising, it is still not clear that it scales up well to large grammars (Rayner et al., 2000b). Rather than use the type of methods developed under Gemini, most people have instead adopted a simpler and more pragmatic approach. Grammars are developed in an ad hoc way directly in CFG, and without reference to linguistic principles. However dubious this may be from a theoretical point of view, experience shows that useful grammars can be quickly developed even for quite complex domains. In the current paper, we present an empirical study which contrasts linguistically motivated and ad hoc approaches to language model construction. In order to be able to make clear comparisons, we focus</context>
<context position="15157" citStr="Rayner et al., 2000" startWordPosition="2392" endWordPosition="2395">en-DEF = is there any radiator in the kitchen?); *sanka belysningen till halften (lower-INF lighting-DEF to half-DEF = dim the lighting to a half). 2.3 Simulated Personal Satellite Assistant The Personal Satellite Assistant (PSA; (NASA Ames Research Center, 2000)) is a small robot currently being developed at NASA Ames Research Center, designed for use in microgravity and targeted for deployment on the International Space Station. Because of the mobility of the robot and the problems of microgravity, English spoken language dialogue is favored as its primary interface mode. The PSA simulator (Rayner et al., 2000a) was constructed to aid in development and testing of the spoken dialogue interface. The simulated robot can be instructed to move around a diagram of the space shuttle and measure environmental factors such as temperature and carbon dioxide. There are also doors in the simulation that can be opened and closed, and fans that can be turned on and off via spoken commands. The system is implemented as a suite of about 20 agents running under the Open Agent Architecture (OAA; (Martin et al., 1998)), and runs on a high-end SUN workstation; it is a mature prototype, which has been publicly demonst</context>
<context position="17503" citStr="Rayner et al., 2000" startWordPosition="2781" endWordPosition="2784"> NPs and clauses (&amp;quot;Measure pressure at crew hatch and flight deck&amp;quot;; &amp;quot;Go to crew hatch and switch on the fan&amp;quot;), ellipsis (&amp;quot;Measure pressure&amp;quot;... &amp;quot;how about temperature&amp;quot;), and use of pronouns (&amp;quot;Open the crew hatch&amp;quot;... &amp;quot;close it&amp;quot;). The CFG language model produced by Gemini compilation is only used for recognition. Parsing as such is performed on the recognised string, using the Gemini parser, and produces a semantic representation in a version of Quasi Logical Form (van Eijck and Moore, 1992). The unification grammar, and issues relating to its compilation to CFG form, are described in detail in (Rayner et al., 2000b). 3 Experiments In order to carry out the experiments described here, we constructed alternate versions of each of the three systems described above. For the ad hoc 00H and AH systems, we manually constructed new versions of the CFG language models modified to include agreement constraints. The new versions of the grammars were substantially larger, as shown in Table 1; the worst problem, however, was that many rules from the original grammar had to be duplicated in two or more slightly differing forms, greatly complicating the task of future grammar maintenance. In contrast, it was extremel</context>
</contexts>
<marker>Rayner, Hockey, James, 2000</marker>
<rawString>M. Rayner, B.A. Hockey, and F. James. 2000a. A compact architecture for dialogue management based on scripts and meta-outputs. In Proceedings of Applied Natural Language Processing (ANLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Rayner</author>
<author>B A Hockey</author>
<author>F James</author>
<author>E O Bratt</author>
<author>S Goldwater„</author>
<author>J M Gawron</author>
</authors>
<title>Compiling language models from a linguistically motivated unification grammar.</title>
<date>2000</date>
<booktitle>In Proceedings of COLING</booktitle>
<marker>Rayner, Hockey, James, Bratt, Goldwater„, Gawron, 2000</marker>
<rawString>M. Rayner, B.A. Hockey, F. James, E.O. Bratt, S. Goldwater„ and J.M. Gawron. 2000b. Compiling language models from a linguistically motivated unification grammar. In Proceedings of COLING 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Rosenfeld</author>
<author>X Huang</author>
</authors>
<title>Improvements in stochastic language modeling.</title>
<date>1992</date>
<booktitle>In Speech and Natural Language Workshop,</booktitle>
<pages>107--111</pages>
<contexts>
<context position="3013" citStr="Rosenfeld and Huang, 1992" startWordPosition="413" endWordPosition="416">els. The basic idea of the statistical approach is to train the language model (most often some kind of N-gram grammar) from a domain corpus; if a sufficiently large corpus is available, experience shows that this method can yield excellent results (Cohen et al., 1995; Ward and Issar, 1995). In contrast, the grammar-based approach creates the language model directly in the form of a (most often hand-coded) grammar. For the last decade researchers have paid more attention to the statistical alternative, and there are many theoretically attractive reasons for preferring it (Mori and Kuhn, 1991; Rosenfeld and Huang, 1992). However, within the last two years commercial speech technology has adopted the grammar-based approach (VoiceXML Forum, 2000; W3C, 2000; Nuance Communications, 2000; SpeechWorks International, 2000; Tellme, 2000; BeVocal, 2000; HeyAnita, 2000). This focus on grammar-based methods is motivated by important practical and theoretical considerations. Most obviously, the large quantity of corpus data needed to train a statistical language model is hardly ever available; creating it, by Wizard of Oz simulation or similar methods, is prohibitively expensive. It is also frequently the case that the </context>
</contexts>
<marker>Rosenfeld, Huang, 1992</marker>
<rawString>R. Rosenfeld and X. Huang. 1992. Improvements in stochastic language modeling. In Speech and Natural Language Workshop, pages 107-111.</rawString>
</citation>
<citation valid="true">
<authors>
<author>SpeechWorks International</author>
</authors>
<title>Speech Works International. http://www.speechworks.com.</title>
<date>2000</date>
<journal>As of</journal>
<volume>6</volume>
<contexts>
<context position="3212" citStr="International, 2000" startWordPosition="442" endWordPosition="444">at this method can yield excellent results (Cohen et al., 1995; Ward and Issar, 1995). In contrast, the grammar-based approach creates the language model directly in the form of a (most often hand-coded) grammar. For the last decade researchers have paid more attention to the statistical alternative, and there are many theoretically attractive reasons for preferring it (Mori and Kuhn, 1991; Rosenfeld and Huang, 1992). However, within the last two years commercial speech technology has adopted the grammar-based approach (VoiceXML Forum, 2000; W3C, 2000; Nuance Communications, 2000; SpeechWorks International, 2000; Tellme, 2000; BeVocal, 2000; HeyAnita, 2000). This focus on grammar-based methods is motivated by important practical and theoretical considerations. Most obviously, the large quantity of corpus data needed to train a statistical language model is hardly ever available; creating it, by Wizard of Oz simulation or similar methods, is prohibitively expensive. It is also frequently the case that the language model changes dynamically with the state of the interaction in some way that is easiest to specify in terms of rules rather than statistical regularities. For example, the dialogue may conce</context>
</contexts>
<marker>International, 2000</marker>
<rawString>SpeechWorks International, 2000. Speech Works International. http://www.speechworks.com. As of 6 November 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Stent</author>
<author>J Dowding</author>
<author>J Gawron</author>
<author>E Bratt</author>
<author>R Moore</author>
</authors>
<title>The CommandTalk spoken dialogue system.</title>
<date>1999</date>
<booktitle>In Proceedings of the ThirtySeventh Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>183--190</pages>
<contexts>
<context position="5367" citStr="Stent et al., 1999" startWordPosition="799" endWordPosition="802">s; if it is too loose, the system will make too many recognition errors. One way to build grammar-based language models is just to apply the techniques developed for building other types of grammars, in particular those used for parsing and generation. Unfortunately, it is non-trivial to transform a grammar written in a high-level linguis1 tic formalism into a useful CFG-based language model. In fact, the only really successful piece of work we are aware of that has taken this path is the approach pioneered by the Gemini (Dowding et al., 1993; Moore, 1999) and CommandTalk (Moore et al., 1997; Stent et al., 1999) projects at SRI. Although the idea is promising, it is still not clear that it scales up well to large grammars (Rayner et al., 2000b). Rather than use the type of methods developed under Gemini, most people have instead adopted a simpler and more pragmatic approach. Grammars are developed in an ad hoc way directly in CFG, and without reference to linguistic principles. However dubious this may be from a theoretical point of view, experience shows that useful grammars can be quickly developed even for quite complex domains. In the current paper, we present an empirical study which contrasts l</context>
</contexts>
<marker>Stent, Dowding, Gawron, Bratt, Moore, 1999</marker>
<rawString>A. Stent, J. Dowding, J. Gawron, E. Bratt, and R. Moore. 1999. The CommandTalk spoken dialogue system. In Proceedings of the ThirtySeventh Annual Meeting of the Association for Computational Linguistics, pages 183-190.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tellme</author>
</authors>
<date>2000</date>
<journal>Tellme. http://www.tellme.com/. As of</journal>
<volume>6</volume>
<contexts>
<context position="3226" citStr="Tellme, 2000" startWordPosition="445" endWordPosition="446">eld excellent results (Cohen et al., 1995; Ward and Issar, 1995). In contrast, the grammar-based approach creates the language model directly in the form of a (most often hand-coded) grammar. For the last decade researchers have paid more attention to the statistical alternative, and there are many theoretically attractive reasons for preferring it (Mori and Kuhn, 1991; Rosenfeld and Huang, 1992). However, within the last two years commercial speech technology has adopted the grammar-based approach (VoiceXML Forum, 2000; W3C, 2000; Nuance Communications, 2000; SpeechWorks International, 2000; Tellme, 2000; BeVocal, 2000; HeyAnita, 2000). This focus on grammar-based methods is motivated by important practical and theoretical considerations. Most obviously, the large quantity of corpus data needed to train a statistical language model is hardly ever available; creating it, by Wizard of Oz simulation or similar methods, is prohibitively expensive. It is also frequently the case that the language model changes dynamically with the state of the interaction in some way that is easiest to specify in terms of rules rather than statistical regularities. For example, the dialogue may concern choice from</context>
</contexts>
<marker>Tellme, 2000</marker>
<rawString>Tellme, 2000. Tellme. http://www.tellme.com/. As of 6 November 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J van Eijck</author>
<author>R Moore</author>
</authors>
<title>Semantic rules for English.</title>
<date>1992</date>
<booktitle>The Core Language Engine.</booktitle>
<editor>In H. Alshawi, editor,</editor>
<publisher>MIT Press.</publisher>
<marker>van Eijck, Moore, 1992</marker>
<rawString>J. van Eijck and R. Moore. 1992. Semantic rules for English. In H. Alshawi, editor, The Core Language Engine. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>VoiceXML Forum</author>
</authors>
<title>VoiceXML Forum. http://www.voicexml.org/index.html.</title>
<date>2000</date>
<journal>As of</journal>
<volume>6</volume>
<contexts>
<context position="3139" citStr="Forum, 2000" startWordPosition="433" endWordPosition="434"> if a sufficiently large corpus is available, experience shows that this method can yield excellent results (Cohen et al., 1995; Ward and Issar, 1995). In contrast, the grammar-based approach creates the language model directly in the form of a (most often hand-coded) grammar. For the last decade researchers have paid more attention to the statistical alternative, and there are many theoretically attractive reasons for preferring it (Mori and Kuhn, 1991; Rosenfeld and Huang, 1992). However, within the last two years commercial speech technology has adopted the grammar-based approach (VoiceXML Forum, 2000; W3C, 2000; Nuance Communications, 2000; SpeechWorks International, 2000; Tellme, 2000; BeVocal, 2000; HeyAnita, 2000). This focus on grammar-based methods is motivated by important practical and theoretical considerations. Most obviously, the large quantity of corpus data needed to train a statistical language model is hardly ever available; creating it, by Wizard of Oz simulation or similar methods, is prohibitively expensive. It is also frequently the case that the language model changes dynamically with the state of the interaction in some way that is easiest to specify in terms of rules </context>
</contexts>
<marker>Forum, 2000</marker>
<rawString>VoiceXML Forum, 2000. VoiceXML Forum. http://www.voicexml.org/index.html. As of 6 November 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W3C</author>
</authors>
<title>Speech Recognition Grammar Specification.</title>
<date>2000</date>
<booktitle>http://www.w3.org/TR/grammar-spec. As of 6</booktitle>
<marker>W3C, 2000</marker>
<rawString>W3C, 2000. Speech Recognition Grammar Specification. http://www.w3.org/TR/grammar-spec. As of 6 November 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Ward</author>
<author>S Issar</author>
</authors>
<title>The cmu atis system.</title>
<date>1995</date>
<booktitle>In Spoken Language System Technology Workshop,</booktitle>
<pages>249--251</pages>
<contexts>
<context position="2678" citStr="Ward and Issar, 1995" startWordPosition="361" endWordPosition="364">traints significantly improves performance in terms of both word error rate and semantic error rate. 1 Introduction A key problem in building interactive spoken language systems is constructing a language model to guide speech recognition. There are two main approaches: statistical language models, and grammar-based language models. The basic idea of the statistical approach is to train the language model (most often some kind of N-gram grammar) from a domain corpus; if a sufficiently large corpus is available, experience shows that this method can yield excellent results (Cohen et al., 1995; Ward and Issar, 1995). In contrast, the grammar-based approach creates the language model directly in the form of a (most often hand-coded) grammar. For the last decade researchers have paid more attention to the statistical alternative, and there are many theoretically attractive reasons for preferring it (Mori and Kuhn, 1991; Rosenfeld and Huang, 1992). However, within the last two years commercial speech technology has adopted the grammar-based approach (VoiceXML Forum, 2000; W3C, 2000; Nuance Communications, 2000; SpeechWorks International, 2000; Tellme, 2000; BeVocal, 2000; HeyAnita, 2000). This focus on gram</context>
</contexts>
<marker>Ward, Issar, 1995</marker>
<rawString>W. Ward and S. Issar. 1995. The cmu atis system. In Spoken Language System Technology Workshop, pages 249-251.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>