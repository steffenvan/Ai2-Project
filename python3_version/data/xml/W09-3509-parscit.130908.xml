<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.012563">
<title confidence="0.9971755">
Testing and Performance Evaluation of Machine Transliteration System
for Tamil Language
</title>
<author confidence="0.953481">
Kommaluri Vijayanand1, 2; Inampudi Ramesh Babu1, 3, Poonguzhali Sandiran1, 2
</author>
<listItem confidence="0.518332">
(1) Department of Computer Science and Engineering,
(2) Pondicherry University, Puducherry - 605 014, India.
(3) Acharya Nagarjuna University, Nagarjuna Nagar - 522 510, India.
</listItem>
<email confidence="0.983185">
kvixs@yahoo.co.in, rinampudi@yahoo.com, poon 8724@yahoo.com
</email>
<sectionHeader confidence="0.99353" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999728461538462">
Machine Translation (MT) is a science fic-
tion that was converted into reality with
the enormous contributions from the MT
research community. We cannot expect
any text without Named Entities (NE).
Such NEs are crucial in deciding the qua-
lity of MT. NEs are to be recognized from
the text and transliterated accordingly into
the target language in order to ensure the
quality of MT. In the present paper we
present various technical issues encounte-
red during handling the shared task of NE
transliteration for Tamil.
</bodyText>
<sectionHeader confidence="0.998798" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.970821655172414">
Out of several underlying issues relating to Ma-
chine Translation (MT) against the dependence
on the human editors, Named Entity Recognition
(NER) play a pivotal role. When a MT system is
developed and executed, majority of the initial test
cases are bound to fail, when the system attempt
to translate the names, acronyms etc. Special at-
tention is required to handle such cases where in
NER and transliteration task play a pivot role (Vi-
jayanand and Subramanian, 2006).
We had participated in the shared task towards
the languages English to Tamil, English to Hindi
and English to Kannada after receiving the refe-
rence corpora which consists of 1000 names for
each language pair (Li et al., 2009b). Though we
committed responsibility for the three language
pairs viz., English to Tamil, English to Kannada
and English to Hindi, we mainly concentrated on
the English to Tamil language pair. The Tamil Ma-
chine Transliteration System shall be available for
demonstration during the workshop.
(Research Scholar at Acharya Nagarjuna University, In-
dia and Visiting Scholar of Universit´e Joseph Fourier (Gre-
noble 1), Grenoble, France.
The present transliteration system is implemen-
ted using JDK 1.6.0 for transliterating the Named
Entities in Tamil language from the source names
in English. The character combination in English
such as A, Aa, I, ee, u, oo, ai, o, ou, forms vo-
wels in Tamil. Similarly the characters k, ng, ch, t,
etc., form consonants and the characters ka, nga,
cha etc., form compound characters. One single
character in English produce different pronuncia-
tions and for each pronunciation, there exists a se-
parate character. For example in the words Ma-
dura and Ramya the sound of a is different when
a is suffixed with r and y. Similarly, the cha-
racter n has different pronunciations depending
upon the suffix. For example in the words San-
chit, Pannu, Nandini, Jahangir the character n has
different pronunciations depending upon the suf-
fix. We need to identify and consider these crite-
ria when we transliterate the words from the lan-
guages English to Tamil. Thus the present system
takes into account all such cases and generate the
possible transliterations for the data given by the
shared task (Li et al., 2009a).
The paper is organized in such a way that, we
enumerate various rules that are formulated and
deployed in favor of segmentation are explained
with suitable examples in section 2. The technical
details regarding the system design is presented in
the section 3. The results generated by the system
and the evaluation of the transliterations that are
carried out using different kinds of data are explai-
ned in the section 4, followed by the section 5 that
concludes the papers with the overall remarks and
future work.
</bodyText>
<sectionHeader confidence="0.922087" genericHeader="method">
2 Segmentation Rules
</sectionHeader>
<bodyText confidence="0.998905">
Every word is a combination of characters and
transforms its sound based on the characters that
surrounds it as described in the previous section.
During transliteration it is quite important to iden-
tify the break points with in the word to pronounce
</bodyText>
<page confidence="0.993853">
48
</page>
<note confidence="0.98378">
Proceedings of the 2009 Named Entities Workshop, ACL-IJCNLP 2009, pages 48–51,
Suntec, Singapore, 7 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.9996315">
the given word correctly. Towards enforcing such
constraint we had devised and employed various
rules towards segmentation based on the phonetic
conversions. They are enumerated as follows :
</bodyText>
<listItem confidence="0.94905525">
1. If the second index to the current index of the
word is a, e, I or u, then it is considered to be
one individual segment.
2. If the second index to the current index of the
word is h and the third index to the current
index of the word is a, e, I, o or u, then it is
considered as one segment.
3. If the second and third index to the current
index of the word is a, e, I, o or u and if it is
same character i.e., aa,ee, oo, then it is consi-
dered as one segment.
4. If the second index to the current index of the
word is a, o and the third index to the current
index of the word is e or u, then it is conside-
red as one segment.
5. If the second and third index to the current
index of the word does not satisfy any of the
above four conditions then the current index
of the word is considered to be as one seg-
ment.
</listItem>
<bodyText confidence="0.979491875">
Based on these rules the partition algorithm was
sketched and implemented in favor of partitioning
the word. The partitioning algorithm is applied
only for the named entities and explained with the
following example.
Let us consider a word Chandrachur, the
present system navigate through five steps for seg-
menting this word as listed below :
1. The word is fragmented as Cha  |ndrachur
Initially the system parse from the initial cha-
racter c and checks the second index. It re-
cognizes that the second index is h. Then it
reads the third index according to the rule
number 2. It then recognizes that the third in-
dex is a. So the system partitions up to that
third index and consider it as one segment.
</bodyText>
<listItem confidence="0.90323">
2. Further segmentation: Cha  |n  |drachur
</listItem>
<bodyText confidence="0.970356">
Now the system starts from the fourth index
and consider that index as the current index.
It continues checking the fifth index. As it
does not satisfy any of the rules, it partitions
the fourth index from the source word and
consider it as one segment.
</bodyText>
<listItem confidence="0.982785">
3. Cha  |n  |d  |rachur
</listItem>
<bodyText confidence="0.999034857142857">
In the third step checking starts from the fifth
index and now it is considered to be the cur-
rent index. Then it checks the sixth index.
Since, it does not satisfy any of the rules,
the system partitions the fifth index from the
source name and it is considered as one seg-
ment.
</bodyText>
<listItem confidence="0.974353">
4. Cha  |n  |d  |ra  |chur
</listItem>
<bodyText confidence="0.998921125">
Now the system starts from the sixth index
and consider this to be the current index. It
checks the seventh index, after recognizing
the presence of a, then it checks whether the
eighth index is a, e or u, as per the rule 3 and
rule 4. As it does not satisfy with those rules,
the system partitions from sixth index to se-
venth index as one segment.
</bodyText>
<listItem confidence="0.974959">
5. Cha  |n  |d  |ra  |chu  |r
</listItem>
<bodyText confidence="0.992810916666667">
Finally checking starts from the eighth index
which is treated as the current index and the
system checks the ninth index. The ninth in-
dex consists of h. Thus, checks the tenth in-
dex for the presence of a, e, I, o or u accor-
ding to the rule 2 and satisfies with that rule.
Thus, the system partitions from eighth index
to tenth index as one segment and the ele-
venth index become one segment.
Similarly, for the word Manikkam the system
applies the partitioning algorithm and segment the
word as shown below:
</bodyText>
<listItem confidence="0.99989975">
1. Ma  |nikkam
2. Ma  |ni  |kkam
3. Ma  |ni  |k  |kam
4. Ma  |ni  |k  |ka  |m
</listItem>
<sectionHeader confidence="0.988745" genericHeader="method">
3 The System Design
</sectionHeader>
<bodyText confidence="0.999975642857143">
The system was designed in such a way that
it produces four to six transliterations for a given
word in English. We stored all the possible com-
binations of characters in English and its corres-
ponding Tamil characters in a database and crea-
ted an interface to read the test file. The system
is facilitated to browse the test file using the file
handling technique which was designed applying
the logical concepts. Consonants in English when
combined with vowels in English to form com-
pound words in Tamil. Compound words have
many forms for a single combination.
The present system extract the source names
and store them in an array list. These source names
</bodyText>
<page confidence="0.998754">
49
</page>
<bodyText confidence="0.999991366666667">
are retrieved from an array list sequentially and
stored in a string variable for further processing.
The value of the string is parsed character wise
and check for the existence of a vowel or h, in the
next two positions to its index i.e., for each cha-
racter the next two characters are checked, if there
exists vowels or h, then these characters are extrac-
ted up to that index and stored in another string
variable. Other wise only that variable is stored
and compared with the database that contain Ta-
mil characters, for each combination of characters
that are present in English. Thereafter each index
in an array list of each transliteration will be com-
bined with each index in another array list of trans-
literated letter combination, stored in another va-
riable. This process will continue until the system
encounter the end of each array list. After getting
all the combinations, these combinations are sto-
red in an array list and it is written to the file.
It is to be noted that only one source name is
assigned to the string variable at a time. After get-
ting the target name of that source name, the next
source name is retrieved from an array list. Af-
ter retrieving the source name it is passed to the
next module for segmentation. The segments for-
med are stored in an array list. Then these target
characters for each segment is retrieved from the
database and stored in a separate list. There after
the values in an array list are merged appropriately
and stored in an array list.
</bodyText>
<sectionHeader confidence="0.999604" genericHeader="evaluation">
4 Results and Evaluation
</sectionHeader>
<bodyText confidence="0.999796571428571">
This section describes briefly about the results
and evaluation conducted and present the results.
We had employed various techniques and algo-
rithms as explained in previous sections, to select
the appropriate transliterated word that matches
the source name from the n-best candidate list
using six metrics.
</bodyText>
<subsectionHeader confidence="0.838789">
4.1 Results
</subsectionHeader>
<bodyText confidence="0.999465523809524">
The result file consists of source name with its
ID and the ranked list of target names. The target
names are generated along with the source names,
after being processed by the system. The source
names are the names given in the test file. The
target names are the names that are generated by
the system. The target names are ranked accor-
ding to their ID’s. The target names are Unicode
characters in Tamil. After applying various tech-
niques we produce the result file. It is worth stat-
ting that the result file is generated in the XML
format using UTF-8 encoding schema.
The present system transliterates for 1000
source names and generates up to six best candi-
date lists (Target names). We conducted testing for
the given data towards transliterations. The first
transliteration present in the four best candidate
lists are considered to be the correct hit. The eva-
luation is carried out using Python. These six me-
trics are implemented in python. The metrics are
as follows :
</bodyText>
<listItem confidence="0.991813833333333">
1. Word Accuracy in Top-1 (ACC)
2. Mean F-Score
3. Mean Reciprocal Rank (MRR)
4. MAP ref
5. MAP 10
6. MAP sys
</listItem>
<bodyText confidence="0.998266">
MAP refers to the Mean Average Precision. Py-
thon is preferred because it is an excellent pro-
gramming language, easy to understand, dynamic
and truly object oriented.
</bodyText>
<subsectionHeader confidence="0.986175">
4.2 Evaluation
</subsectionHeader>
<bodyText confidence="0.999955470588235">
The Result file and the Test file in XML format
and the python script developed with six metrics
reads the above mentioned files. Execution of the
script requires Python interpreter. The Result file
is the one generated by the Transliteration System
and the test file is created manually with a single
transliteration for each source name and testing is
conducted. As part of the shared task (Kumaran
and Kellner, 2007) evaluation was done by run-
ning the system and thus 6 metrics are displayed
as output, with each metric given the value 0 or 1.
These metrics declare the performance of the sys-
tem. The max-candidates argument in the script is
assigned 10 (max-candidates=10). It is also chan-
ged according to target names provided. The out-
put of the evaluation of our Transliteration System
are as follows :
</bodyText>
<listItem confidence="0.853783625">
1. Word Accuracy in Top-1 (ACC) : The ACC
of our system is 0.403974,
2. Mean F-Score : The Mean F-Score of our
system is 0.865840.
3. MRR = The Mean Reciprocal rank of our
system is 0.449227.
4. MAP ref : The MAP ref of the system is
0.390545.
</listItem>
<page confidence="0.930495">
50
</page>
<listItem confidence="0.776866">
5. MAP 10 : The MAP 10 value of the system
is 0.240066.
6. MAP sys : The MAP sys of the system is
0.369840.
</listItem>
<bodyText confidence="0.9663675">
The output that was generated by our system is
presented in appendix.
</bodyText>
<sectionHeader confidence="0.999378" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999991923076923">
After working with the experiment that was car-
ried out for evaluating the metrics, we conclude
that the accuracy in top-1 score of our system is
0.061. The reason could be that the accurate trans-
literation is not generated in the top scored transli-
teration. We could improve the performance of the
present system by involving all the possible trans-
literations. With the initial test results are very low
when compared to Urdu to Hindi transliteration
system (M. G. et al., 2008), yields 97.12% and
Hindi to Urdu delivers 97.88% of accuracy and
NER system favor of the Bengali language which
had demonstrated the evaluation results with a
precision of 80.12% (Ekbal and Bandyopadhyay,
2008).
After participating in the shared task we had
tested the transliteration system thoroughly by
applying various techniques as explained in the
present paper. So far we had carried out the transli-
teration for six named entity candidates. In future
we would like to extend the task for translitera-
tion candidates unto twenty. Thus the named entity
transliteration task that is being carried out would
be a solution for the long standing research pro-
blem in handling the named entities that is quite
common in speech and text machine translation.
</bodyText>
<sectionHeader confidence="0.998361" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999879142857143">
I am thankful to the anonymous referees for
their valuable advices towards improving this pa-
per. I am thankful to my students Kanickairaj Ca-
roline, Dhivya Moorthy and Kothandapani Selvi
for rendering their service and cooperation in ful-
filling this task. I extend my gratitude to all the
elders for their support and encouragement.
</bodyText>
<sectionHeader confidence="0.999467" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.996958806451613">
Asif Ekbal and Sivaji Bandyopadhyay. 2008. Named
entity recognition using support vector machine : A
language independent approach. International Jour-
nal of Computer Systems Science and Engineering,
4(2) :155–170.
FIG. 1 – Screenshot of Evaluation Result.
A. Kumaran and Tobias Kellner. 2007. A generic fra-
mework for machine transliteration. In 30th Annual
ACM SIGIR Conference, Amsterdam.
Hauzhou Li, A Kumaran, Vladimir Pervouchine, and
Min Zhang. 2009a. Report on news 2009 ma-
chine transliteration shared task. In Proceedings
of the ACL-IJCNLP 2009 Named Entities Workshop
(NEWS 2009), Singapore.
Hauzhou Li, A Kumaran, Min Zhang, and Vladimir
Pervouchine. 2009b. White paper of news 2009
machine transliteration shared task. In Proceedings
of the ACL-IJCNLP 2009 Named Entities Workshop
(NEWS 2009), Singapore.
Abbas Malik M. G., Christian Boitet, and Pushpak
Bhattacharyya. 2008. Hindi urdu machine translite-
ration using finite state transducers. In Proceedings
of the 22nd International Conference on Computa-
tional Linguistics (COLING 2008), Manchester.
Kommaluri Vijayanand and Ramalingam Subrama-
nian. 2006. Anuvadini : An automatic example-
based machine translation system for bengali into
assamese and oriya. In Proceedings of the First Na-
tional Symposium on Modeling and Shallow Parsing
of Indian Languages (MSPIL-06), IIT Bombay, In-
dia.
</reference>
<page confidence="0.999086">
51
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.570891">
<title confidence="0.999603">Testing and Performance Evaluation of Machine Transliteration for Tamil Language</title>
<author confidence="0.996509">Inampudi Ramesh Poonguzhali</author>
<affiliation confidence="0.979738">(1) Department of Computer Science and Engineering,</affiliation>
<address confidence="0.978994">(2) Pondicherry University, Puducherry - 605 014, India.</address>
<phone confidence="0.702906">(3) Acharya Nagarjuna University, Nagarjuna Nagar - 522 510,</phone>
<email confidence="0.97908">kvixs@yahoo.co.in,rinampudi@yahoo.com,poon8724@yahoo.com</email>
<abstract confidence="0.988186">Machine Translation (MT) is a science fiction that was converted into reality with the enormous contributions from the MT research community. We cannot expect any text without Named Entities (NE). Such NEs are crucial in deciding the quality of MT. NEs are to be recognized from the text and transliterated accordingly into the target language in order to ensure the quality of MT. In the present paper we present various technical issues encountered during handling the shared task of NE transliteration for Tamil.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Asif Ekbal</author>
<author>Sivaji Bandyopadhyay</author>
</authors>
<title>Named entity recognition using support vector machine : A language independent approach.</title>
<date>2008</date>
<journal>International Journal of Computer Systems Science and Engineering,</journal>
<booktitle>155–170. FIG. 1 – Screenshot of Evaluation Result.</booktitle>
<volume>4</volume>
<issue>2</issue>
<contexts>
<context position="13103" citStr="Ekbal and Bandyopadhyay, 2008" startWordPosition="2297" endWordPosition="2300">evaluating the metrics, we conclude that the accuracy in top-1 score of our system is 0.061. The reason could be that the accurate transliteration is not generated in the top scored transliteration. We could improve the performance of the present system by involving all the possible transliterations. With the initial test results are very low when compared to Urdu to Hindi transliteration system (M. G. et al., 2008), yields 97.12% and Hindi to Urdu delivers 97.88% of accuracy and NER system favor of the Bengali language which had demonstrated the evaluation results with a precision of 80.12% (Ekbal and Bandyopadhyay, 2008). After participating in the shared task we had tested the transliteration system thoroughly by applying various techniques as explained in the present paper. So far we had carried out the transliteration for six named entity candidates. In future we would like to extend the task for transliteration candidates unto twenty. Thus the named entity transliteration task that is being carried out would be a solution for the long standing research problem in handling the named entities that is quite common in speech and text machine translation. Acknowledgments I am thankful to the anonymous referees</context>
</contexts>
<marker>Ekbal, Bandyopadhyay, 2008</marker>
<rawString>Asif Ekbal and Sivaji Bandyopadhyay. 2008. Named entity recognition using support vector machine : A language independent approach. International Journal of Computer Systems Science and Engineering, 4(2) :155–170. FIG. 1 – Screenshot of Evaluation Result.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kumaran</author>
<author>Tobias Kellner</author>
</authors>
<title>A generic framework for machine transliteration.</title>
<date>2007</date>
<booktitle>In 30th Annual ACM SIGIR Conference,</booktitle>
<location>Amsterdam.</location>
<contexts>
<context position="11585" citStr="Kumaran and Kellner, 2007" startWordPosition="2024" endWordPosition="2027"> ref 5. MAP 10 6. MAP sys MAP refers to the Mean Average Precision. Python is preferred because it is an excellent programming language, easy to understand, dynamic and truly object oriented. 4.2 Evaluation The Result file and the Test file in XML format and the python script developed with six metrics reads the above mentioned files. Execution of the script requires Python interpreter. The Result file is the one generated by the Transliteration System and the test file is created manually with a single transliteration for each source name and testing is conducted. As part of the shared task (Kumaran and Kellner, 2007) evaluation was done by running the system and thus 6 metrics are displayed as output, with each metric given the value 0 or 1. These metrics declare the performance of the system. The max-candidates argument in the script is assigned 10 (max-candidates=10). It is also changed according to target names provided. The output of the evaluation of our Transliteration System are as follows : 1. Word Accuracy in Top-1 (ACC) : The ACC of our system is 0.403974, 2. Mean F-Score : The Mean F-Score of our system is 0.865840. 3. MRR = The Mean Reciprocal rank of our system is 0.449227. 4. MAP ref : The M</context>
</contexts>
<marker>Kumaran, Kellner, 2007</marker>
<rawString>A. Kumaran and Tobias Kellner. 2007. A generic framework for machine transliteration. In 30th Annual ACM SIGIR Conference, Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hauzhou Li</author>
<author>A Kumaran</author>
<author>Vladimir Pervouchine</author>
<author>Min Zhang</author>
</authors>
<title>Report on news 2009 machine transliteration shared task.</title>
<date>2009</date>
<booktitle>In Proceedings of the ACL-IJCNLP 2009 Named Entities Workshop (NEWS</booktitle>
<contexts>
<context position="1637" citStr="Li et al., 2009" startWordPosition="252" endWordPosition="255">e dependence on the human editors, Named Entity Recognition (NER) play a pivotal role. When a MT system is developed and executed, majority of the initial test cases are bound to fail, when the system attempt to translate the names, acronyms etc. Special attention is required to handle such cases where in NER and transliteration task play a pivot role (Vijayanand and Subramanian, 2006). We had participated in the shared task towards the languages English to Tamil, English to Hindi and English to Kannada after receiving the reference corpora which consists of 1000 names for each language pair (Li et al., 2009b). Though we committed responsibility for the three language pairs viz., English to Tamil, English to Kannada and English to Hindi, we mainly concentrated on the English to Tamil language pair. The Tamil Machine Transliteration System shall be available for demonstration during the workshop. (Research Scholar at Acharya Nagarjuna University, India and Visiting Scholar of Universit´e Joseph Fourier (Grenoble 1), Grenoble, France. The present transliteration system is implemented using JDK 1.6.0 for transliterating the Named Entities in Tamil language from the source names in English. The chara</context>
<context position="3170" citStr="Li et al., 2009" startWordPosition="504" endWordPosition="507">sts a separate character. For example in the words Madura and Ramya the sound of a is different when a is suffixed with r and y. Similarly, the character n has different pronunciations depending upon the suffix. For example in the words Sanchit, Pannu, Nandini, Jahangir the character n has different pronunciations depending upon the suffix. We need to identify and consider these criteria when we transliterate the words from the languages English to Tamil. Thus the present system takes into account all such cases and generate the possible transliterations for the data given by the shared task (Li et al., 2009a). The paper is organized in such a way that, we enumerate various rules that are formulated and deployed in favor of segmentation are explained with suitable examples in section 2. The technical details regarding the system design is presented in the section 3. The results generated by the system and the evaluation of the transliterations that are carried out using different kinds of data are explained in the section 4, followed by the section 5 that concludes the papers with the overall remarks and future work. 2 Segmentation Rules Every word is a combination of characters and transforms it</context>
</contexts>
<marker>Li, Kumaran, Pervouchine, Zhang, 2009</marker>
<rawString>Hauzhou Li, A Kumaran, Vladimir Pervouchine, and Min Zhang. 2009a. Report on news 2009 machine transliteration shared task. In Proceedings of the ACL-IJCNLP 2009 Named Entities Workshop (NEWS 2009), Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hauzhou Li</author>
<author>A Kumaran</author>
<author>Min Zhang</author>
<author>Vladimir Pervouchine</author>
</authors>
<title>White paper of news 2009 machine transliteration shared task.</title>
<date>2009</date>
<booktitle>In Proceedings of the ACL-IJCNLP 2009 Named Entities Workshop (NEWS</booktitle>
<contexts>
<context position="1637" citStr="Li et al., 2009" startWordPosition="252" endWordPosition="255">e dependence on the human editors, Named Entity Recognition (NER) play a pivotal role. When a MT system is developed and executed, majority of the initial test cases are bound to fail, when the system attempt to translate the names, acronyms etc. Special attention is required to handle such cases where in NER and transliteration task play a pivot role (Vijayanand and Subramanian, 2006). We had participated in the shared task towards the languages English to Tamil, English to Hindi and English to Kannada after receiving the reference corpora which consists of 1000 names for each language pair (Li et al., 2009b). Though we committed responsibility for the three language pairs viz., English to Tamil, English to Kannada and English to Hindi, we mainly concentrated on the English to Tamil language pair. The Tamil Machine Transliteration System shall be available for demonstration during the workshop. (Research Scholar at Acharya Nagarjuna University, India and Visiting Scholar of Universit´e Joseph Fourier (Grenoble 1), Grenoble, France. The present transliteration system is implemented using JDK 1.6.0 for transliterating the Named Entities in Tamil language from the source names in English. The chara</context>
<context position="3170" citStr="Li et al., 2009" startWordPosition="504" endWordPosition="507">sts a separate character. For example in the words Madura and Ramya the sound of a is different when a is suffixed with r and y. Similarly, the character n has different pronunciations depending upon the suffix. For example in the words Sanchit, Pannu, Nandini, Jahangir the character n has different pronunciations depending upon the suffix. We need to identify and consider these criteria when we transliterate the words from the languages English to Tamil. Thus the present system takes into account all such cases and generate the possible transliterations for the data given by the shared task (Li et al., 2009a). The paper is organized in such a way that, we enumerate various rules that are formulated and deployed in favor of segmentation are explained with suitable examples in section 2. The technical details regarding the system design is presented in the section 3. The results generated by the system and the evaluation of the transliterations that are carried out using different kinds of data are explained in the section 4, followed by the section 5 that concludes the papers with the overall remarks and future work. 2 Segmentation Rules Every word is a combination of characters and transforms it</context>
</contexts>
<marker>Li, Kumaran, Zhang, Pervouchine, 2009</marker>
<rawString>Hauzhou Li, A Kumaran, Min Zhang, and Vladimir Pervouchine. 2009b. White paper of news 2009 machine transliteration shared task. In Proceedings of the ACL-IJCNLP 2009 Named Entities Workshop (NEWS 2009), Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Abbas Malik M G</author>
<author>Christian Boitet</author>
<author>Pushpak Bhattacharyya</author>
</authors>
<title>Hindi urdu machine transliteration using finite state transducers.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics (COLING 2008),</booktitle>
<location>Manchester.</location>
<marker>G, Boitet, Bhattacharyya, 2008</marker>
<rawString>Abbas Malik M. G., Christian Boitet, and Pushpak Bhattacharyya. 2008. Hindi urdu machine transliteration using finite state transducers. In Proceedings of the 22nd International Conference on Computational Linguistics (COLING 2008), Manchester.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kommaluri Vijayanand</author>
<author>Ramalingam Subramanian</author>
</authors>
<title>Anuvadini : An automatic examplebased machine translation system for bengali into assamese and oriya.</title>
<date>2006</date>
<booktitle>In Proceedings of the First National Symposium on Modeling and Shallow Parsing of Indian Languages (MSPIL-06), IIT</booktitle>
<location>Bombay, India.</location>
<contexts>
<context position="1410" citStr="Vijayanand and Subramanian, 2006" startWordPosition="212" endWordPosition="216"> quality of MT. In the present paper we present various technical issues encountered during handling the shared task of NE transliteration for Tamil. 1 Introduction Out of several underlying issues relating to Machine Translation (MT) against the dependence on the human editors, Named Entity Recognition (NER) play a pivotal role. When a MT system is developed and executed, majority of the initial test cases are bound to fail, when the system attempt to translate the names, acronyms etc. Special attention is required to handle such cases where in NER and transliteration task play a pivot role (Vijayanand and Subramanian, 2006). We had participated in the shared task towards the languages English to Tamil, English to Hindi and English to Kannada after receiving the reference corpora which consists of 1000 names for each language pair (Li et al., 2009b). Though we committed responsibility for the three language pairs viz., English to Tamil, English to Kannada and English to Hindi, we mainly concentrated on the English to Tamil language pair. The Tamil Machine Transliteration System shall be available for demonstration during the workshop. (Research Scholar at Acharya Nagarjuna University, India and Visiting Scholar o</context>
</contexts>
<marker>Vijayanand, Subramanian, 2006</marker>
<rawString>Kommaluri Vijayanand and Ramalingam Subramanian. 2006. Anuvadini : An automatic examplebased machine translation system for bengali into assamese and oriya. In Proceedings of the First National Symposium on Modeling and Shallow Parsing of Indian Languages (MSPIL-06), IIT Bombay, India.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>