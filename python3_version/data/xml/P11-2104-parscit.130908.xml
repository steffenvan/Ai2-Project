<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.007459">
<title confidence="0.995748">
Identifying the Semantic Orientation of Foreign Words
</title>
<author confidence="0.953966">
Ahmed Hassan
</author>
<affiliation confidence="0.9504735">
EECS Department
University of Michigan
</affiliation>
<address confidence="0.953806">
Ann Arbor, MI
</address>
<email confidence="0.996617">
hassanam@umich.edu
</email>
<author confidence="0.958321">
Rahul Jha
</author>
<affiliation confidence="0.943542">
EECS Department
University of Michigan
</affiliation>
<address confidence="0.95188">
Ann Arbor, MI
</address>
<email confidence="0.998889">
rahuljha@umich.edu
</email>
<author confidence="0.821514">
Amjad Abu-Jbara
</author>
<affiliation confidence="0.8927715">
EECS Department
University of Michigan
</affiliation>
<address confidence="0.952073">
Ann Arbor, MI
</address>
<email confidence="0.996428">
amjbara@umich.edu
</email>
<author confidence="0.959724">
Dragomir Radev
</author>
<affiliation confidence="0.9596385">
EECS Department and School of Information
University of Michigan
</affiliation>
<address confidence="0.952204">
Ann Arbor, MI
</address>
<email confidence="0.999409">
radev@umich.edu
</email>
<sectionHeader confidence="0.995651" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999868">
We present a method for identifying the pos-
itive or negative semantic orientation of for-
eign words. Identifying the semantic orienta-
tion of words has numerous applications in the
areas of text classification, analysis of prod-
uct review, analysis of responses to surveys,
and mining online discussions. Identifying
the semantic orientation of English words has
been extensively studied in literature. Most of
this work assumes the existence of resources
(e.g. Wordnet, seeds, etc) that do not exist
in foreign languages. In this work, we de-
scribe a method based on constructing a mul-
tilingual network connecting English and for-
eign words. We use this network to iden-
tify the semantic orientation of foreign words
based on connection between words in the
same language as well as multilingual connec-
tions. The method is experimentally tested us-
ing a manually labeled set of positive and neg-
ative words and has shown very promising re-
sults.
</bodyText>
<sectionHeader confidence="0.999337" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999689975609756">
A great body of research work has focused on iden-
tifying the semantic orientation of words. Word po-
larity is a very important feature that has been used
in several applications. For example, the problem
of mining product reputation from Web reviews has
been extensively studied (Turney, 2002; Morinaga
et al., 2002; Nasukawa and Yi, 2003; Popescu and
Etzioni, 2005; Banea et al., 2008). This is a very
important task given the huge amount of product re-
views written on the Web and the difficulty of man-
ually handling them. Another interesting applica-
tion is mining attitude in discussions (Hassan et al.,
2010), where the attitude of participants in a discus-
sion is inferred using the text they exchange.
Due to its importance, several researchers have
addressed the problem of identifying the semantic
orientation of individual words. This work has al-
most exclusively focused on English. Most of this
work used several language dependent resources.
For example Turney and Littman (2003) use the en-
tire English Web corpus by submitting queries con-
sisting of the given word and a set of seeds to a
search engine. In addition, several other methods
have used Wordnet (Miller, 1995) for connecting se-
mantically related words (Kamps et al., 2004; Taka-
mura et al., 2005; Hassan and Radev, 2010).
When we try to apply those methods to other lan-
guages, we run into the problem of the lack of re-
sources in other languages when compared to En-
glish. For example, the General Inquirer lexicon
(Stone et al., 1966) has thousands of English words
labeled with semantic orientation. Most of the lit-
erature has used it as a source of labeled seeds or
for evaluation. Such lexicons are not readily avail-
able in other languages. Another source that has
been widely used for this task is Wordnet (Miller,
1995). Even though other Wordnets have been built
for other languages, their coverage is very limited
when compared to the English Wordnet.
In this work, we present a method for predicting
the semantic orientation of foreign words. The pro-
</bodyText>
<page confidence="0.969646">
592
</page>
<note confidence="0.5850515">
Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 592–597,
Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics
</note>
<bodyText confidence="0.975913128440367">
section, we survey several methods that addressed
this problem.
The work of Hatzivassiloglou and McKeown
(1997) is among the earliest efforts that addressed
this problem. They proposed a method for identify-
ing the polarity of adjectives. Their method is based
on extracting all conjunctions of adjectives from a
given corpus and then they classify each conjunc-
tive expression as either the same orientation such
as “simple and well-received” or different orienta-
tion such as “simplistic but well-received”. Words
are clustered into two sets and the cluster with the
higher average word frequency is classified as posi-
tive.
Turney and Littman (2003) identify word polar-
ity by looking at its statistical association with a set
of positive/negative seed words. They use two sta-
tistical measures for estimating association: Point-
wise Mutual Information (PMI) and Latent Seman-
tic Analysis (LSA). Co-occurrence statistics are col-
lected by submitting queries to a search engine. The
number of hits for positive seeds, negative seeds,
positives seeds near the given word, and negative
seeds near the given word are used to estimate the
association of the given word to the positive/negative
seeds.
Wordnet (Miller, 1995), thesaurus and co-
occurrence statistics have been widely used to mea-
sure word relatedness by several semantic orienta-
tion prediction methods. Kamps et al. (2004) use the
length of the shortest-path in Wordnet connecting
any given word to positive/negative seeds to iden-
tify word polarity. Hu and Liu (2004) use Word-
net synonyms and antonyms to bootstrap from words
with known polarity to words with unknown polar-
ity. They assign any given word the label of its syn-
onyms or the opposite label of its antonyms if any of
them are known.
Kanayama and Nasukawa (2006) used syntactic
features and context coherency, defined as the ten-
dency for same polarities to appear successively,
to acquire polar atoms. Takamura et al. (2005)
proposed using spin models for extracting seman-
tic orientation of words. They construct a network
of words using gloss definitions, thesaurus and co-
occurrence statistics. They regard each word as an
electron. Each electron has a spin and each spin has
a direction taking one of two values: up or down.
Figure 1: Sparse Foreign Networks are connected to
Dense English Networks. Dashed nodes represent la-
beled positive and negative seeds.
posed method is based on creating a multilingual
network of words that represents both English and
foreign words. The network has English-English
connections, as well as foreign-foreign connections
and English-foreign connections. This allows us to
benefit from the richness of the resources built for
the English language and in the meantime utilize
resources specific to foreign languages. Figure 1
shows a multilingual network where a sparse foreign
network and a dense English network are connected.
We then define a random walk model over the multi-
lingual network and predict the semantic orientation
of any given word by comparing the mean hitting
time of a random walk starting from it to a positive
and a negative set of seed English words.
We use both Arabic and Hindi for experiments.
We compare the performance of several methods us-
ing the foreign language resources only and the mul-
tilingual network that has both English and foreign
words. We show that bootstrapping from languages
with dense resources such as English is useful for
improving the performance on other languages with
limited resources.
The rest of the paper is structured as follows. In
section 2, we review some of the related prior work.
We define our problem and explain our approach in
Section 3. Results and discussion are presented in
Section 4. We conclude in Section 5.
2 Related Work
The problem of identifying the polarity of individual
words is a well-studied problem that attracted sev-
eral research efforts in the past few years. In this
593
Two neighboring spins tend to have the same orien-
tation from an energetic point of view. Their hypoth-
esis is that as neighboring electrons tend to have the
same spin direction, neighboring words tend to have
similar polarity. Hassan and Radev (2010) use a ran-
dom walk model defined over a word relatedness
graph to classify words as either positive or negative.
Words are connected based on Wordnet relations as
well as co-occurrence statistics. They measure the
random walk mean hitting time of the given word to
the positive set and the negative set. They show that
their method outperforms other related methods and
that it is more immune to noisy word connections.
Identifying the semantic orientation of individ-
ual words is closely related to subjectivity analy-
sis. Subjectivity analysis focused on identifying
text that presents opinion as opposed to objective
text that presents factual information (Wiebe, 2000).
Some approaches to subjectivity analysis disregard
the context phrases and words appear in (Wiebe,
2000; Hatzivassiloglou and Wiebe, 2000; Banea
et al., 2008), while others take it into considera-
tion (Riloff and Wiebe, 2003; Yu and Hatzivas-
siloglou, 2003; Nasukawa and Yi, 2003; Popescu
and Etzioni, 2005).
</bodyText>
<sectionHeader confidence="0.998469" genericHeader="introduction">
3 Approach
</sectionHeader>
<bodyText confidence="0.999984117647059">
The general goal of this work is to mine the seman-
tic orientation of foreign words. We do this by cre-
ating a multilingual network of words. In this net-
work two words are connected if we believe that they
are semantically related. The network has English-
English, English-Foreign and Foreign-Foreign con-
nections. Some of the English words will be used as
seeds for which we know the semantic orientation.
Given such a network, we will measure the mean
hitting time in a random walk starting at any given
word to the positive set of seeds and the negative set
of seeds. Positive words will be more likely to hit the
positive set faster than hitting the negative set and
vice versa. In the rest of this section, we define how
the multilingual word network is built and describe
an algorithm for predicting the semantic orientation
of any given word.
</bodyText>
<subsectionHeader confidence="0.997597">
3.1 Multilingual Word Network
</subsectionHeader>
<bodyText confidence="0.999974655172413">
We build a network G(V, E) where V = Ven U Vf,
is the union of a set of English and foreign words.
E is a set of edges connecting nodes in V . There
are three types of connections: English-English con-
nections, Foreign-Foreign connections and English-
Foreign connections.
For the English-English connections, we use
Wordnet (Miller, 1995). Wordnet is a large lexical
database of English. Words are grouped in synsets
to express distinct concepts. We add a link between
two words if they occur in the same Wordnet synset.
We also add a link between two words if they have a
hypernym or a similar-to relation.
Foreign-Foreign connections are created in a sim-
ilar way to the English connections. Some other lan-
guages have lexical resources based on the design of
the Princeton English Wordnet. For example: Euro
Wordnet (EWN) (Vossen, 1997), Arabic Wordnet
(AWN) (Elkateb, 2006; Black and Fellbaum, 2006;
Elkateb and Fellbaum, 2006) and the Hindi Word-
net (Narayan et al., 2002; S. Jha, 2001). We also use
co-occurrence statistics similar to the work of Hatzi-
vassiloglou and McKeown (1997).
Finally, to connect foreign words to English
words, we use a foreign to English dictionary. For
every word in a list of foreign words, we look up
its meaning in a dictionary and add an edge between
the foreign word and every other English word that
appeared as a possible meaning for it.
</bodyText>
<subsectionHeader confidence="0.99903">
3.2 Semantic Orientation Prediction
</subsectionHeader>
<bodyText confidence="0.999993285714286">
We use the multilingual network we described above
to predict the semantic orientation of words based
on the mean hitting time to two sets of positive and
negative seeds. Given the graph G(V, E), we de-
scribed in the previous section, we define the transi-
tion probability from node i to node j by normaliz-
ing the weights of the edges out from i:
</bodyText>
<equation confidence="0.995672">
P(j|i) = Wij/ � WZk (1)
k
</equation>
<bodyText confidence="0.9999466">
The mean hitting time h(i|j) is the average num-
ber of steps a random walker, starting at i, will take
to enter state j for the first time (Norris, 1997). Let
the average number of steps that a random walker
starting at some node i will need to enter a state
</bodyText>
<page confidence="0.992113">
594
</page>
<bodyText confidence="0.984349541666667">
k E S be h(i|S). It can be formally defined as:
ise
(2)
where pij is the transition probability between
node i and node j.
Given two lists of seed English words with known
polarity, we define two sets of nodes S+ and S−
representing those seeds. For any given word w, we
calculate the mean hitting time between w and the
two seed sets h(w|S+) and h(w|S−). If h(w|S+)
is greater than h(w|S−), the word is classified as
negative, otherwise it is classified as positive. We
used the list of labeled seeds from (Hatzivassiloglou
and McKeown, 1997) and (Stone et al., 1966). Sev-
eral other similarity measures may be used to predict
whether a given word is closer to the positive seeds
list or the negative seeds list (e.g. average shortest
path length (Kamps et al., 2004)). However hit-
ting time has been shown to be more efficient and
more accurate (Hassan and Radev, 2010) because it
measures connectivity rather than distance. For ex-
ample, the length of the shortest path between the
words “good” and “bad” is only 5 (Kamps et al.,
2004).
</bodyText>
<sectionHeader confidence="0.998785" genericHeader="background">
4 Experiments
</sectionHeader>
<subsectionHeader confidence="0.985842">
4.1 Data
</subsectionHeader>
<bodyText confidence="0.999873777777778">
We used Wordnet (Miller, 1995) as a source of syn-
onyms and hypernyms for linking English words in
the word relatedness graph. We used two foreign
languages for our experiments Arabic and Hindi.
Both languages have a Wordnet that was constructed
based on the design the Princeton English Wordnet.
Arabic Wordnet (AWN) (Elkateb, 2006; Black and
Fellbaum, 2006; Elkateb and Fellbaum, 2006) has
17561 unique words and 7822 synsets. The Hindi
Wordnet (Narayan et al., 2002; S. Jha, 2001) has
56,928 unique words and 26,208 synsets.
In addition, we used three lexicons with words la-
beled as either positive or negative. For English, we
used the General Inquirer lexicon (Stone et al., 1966)
as a source of seed labeled words. The lexicon con-
tains 4206 words, 1915 of which are positive and
2291 are negative. For Arabic and Hindi we con-
structed a labeled set of 300 words for each language
</bodyText>
<figure confidence="0.469496">
Arabic Hindi
</figure>
<figureCaption confidence="0.99809">
Figure 2: Accuracy of the proposed method and baselines
for both Arabic and Hindi.
</figureCaption>
<bodyText confidence="0.9990535">
for use in evaluation. Those sets were labeled by two
native speakers of each language. We also used an
Arabic-English and a Hindi-English dictionaries to
generate Foreign-English links.
</bodyText>
<subsectionHeader confidence="0.919403">
4.2 Results and Discussion
</subsectionHeader>
<bodyText confidence="0.999974428571429">
We performed experiments on the data described in
the previous section. We compare our results to
two baselines. The first is the SO-PMI method de-
scribed in (Turney and Littman, 2003). This method
is based on finding the semantic association of any
given word to a set of positive and a set of negative
words. It can be calculated as follows:
</bodyText>
<equation confidence="0.933640333333333">
hitsw,pos x hitsneg
SO-PMI(w) = log (3)
hitsw,neg x hitspos
</equation>
<bodyText confidence="0.9999760625">
where w is a word with unknown polarity,
hitsw,pos is the number of hits returned by a com-
mercial search engine when the search query is the
given word and the disjunction of all positive seed
words. hitspos is the number of hits when we
search for the disjunction of all positive seed words.
hitsw,neg and hitsneg are defined similarly. We used
7 positive and 7 negative seeds as described in (Tur-
ney and Littman, 2003).
The second baseline constructs a network of for-
eign words only as described earlier. It uses mean
hitting time to find the semantic association of any
given word. We used 10 fold cross validation for this
experiment. We will refer to this system as HT-FR.
Finally, we build a multilingual network and use
the hitting time as before to predict semantic orien-
</bodyText>
<figure confidence="0.991787533333333">
SO-PMI HT-FR HT-FR+EN
�
h(i|S) = 0 i E S
EjEV pij x h(j|S) + 1 otherw
100
90
80
70
60
50
40
30
20
10
0
</figure>
<page confidence="0.870232">
595
</page>
<figureCaption confidence="0.8649398">
tation. We used the English words from (Stone et Intelligence Advanced Research Projects Activity
al., 1966) as seeds and the labeled foreign words (IARPA), through the U.S. Army Research Lab. All
for evaluation. We will refer to this system as statements of fact, opinion or conclusions contained
HT-FR + EN. herein are those of the authors and should not be
Figure 2 compares the accuracy of the three meth- construed as representing the ofcial views or poli-
</figureCaption>
<bodyText confidence="0.9837647">
ods for Arabic and Hindi. We notice that the cies of IARPA, the ODNI or the U.S. Government.
SO-PMI and the hitting time based methods per- References
form poorly on both Arabic and Hindi. This is Carmen Banea, Rada Mihalcea, and Janyce Wiebe.
clearly evident when we consider that the accuracy 2008. A bootstrapping method for building subjec-
of the two systems on English was 83% and 93% re- tivity lexicons for languages with scarce resources. In
spectively (Turney and Littman, 2003; Hassan and LREC’08.
Radev, 2010). This supports our hypothesis that Elkateb S. Rodriguez H Alkhalifa M. Vossen P. Pease A.
state of the art methods, designed for English, per- Black, W. and C. Fellbaum. 2006. Introducing the
form poorly on foreign languages due to the limited arabic wordnet project. In Third International Word-
amount of resources available in foreign languages Net Conference.
compared to English. The figure also shows that the Black. W. Rodriguez H Alkhalifa M. Vossen P. Pease A.
proposed method, which combines resources from Elkateb, S. and C. Fellbaum. 2006. Building a word-
both English and foreign languages, performs sig- net for arabic. In Fifth International Conference on
nificantly better. Finally, we studied how much im- Language Resources and Evaluation.
provement is achieved by including links between Black W. Vossen P. Farwell D. Rodrguez H. Pease A.
foreign words from global Wordnets. We found out Alkhalifa M. Elkateb, S. 2006. Arabic wordnet and
that it improves the performance by 2.5% and 4% the challenges of arabic. In Arabic NLP/MT Confer-
for Arabic and Hindi respectively. ence.
5 Conclusions Ahmed Hassan and Dragomir Radev. 2010. Identifying
We addressed the problem of predicting the seman- text polarity using random walks. In ACL’10.
tic orientation of foreign words. All previous work Ahmed Hassan, Vahed Qazvinian, and Dragomir Radev.
on this task has almost exclusively focused on En- 2010. What’s with the attitude?: identifying sentences
glish. Applying off-the-shelf methods developed for with attitude in online discussions. In Proceedings of
English to other languages does not work well be- the 2010 Conference on Empirical Methods in Natural
cause of the limited amount of resources available Language Processing, pages 1245–1255.
in foreign languages compared to English. We pro- Vasileios Hatzivassiloglou and Kathleen R. McKeown.
posed a method based on the construction of a multi- 1997. Predicting the semantic orientation of adjec-
lingual network that uses both language specific re- tives. In EACL’97, pages 174–181.
sources as well as the rich semantic relations avail- Vasileios Hatzivassiloglou and Janyce Wiebe. 2000. Ef-
able in English. We then use a model that computes fects of adjective orientation and gradability on sen-
the mean hitting time to a set of positive and neg- tence subjectivity. In COLING, pages 299–305.
ative seed words to predict whether a given word Minqing Hu and Bing Liu. 2004. Mining and summariz-
has a positive or a negative semantic orientation. ing customer reviews. In KDD’04, pages 168–177.
We showed that the proposed method can predict Jaap Kamps, Maarten Marx, Robert J. Mokken, and
semantic orientation with high accuracy. We also Maarten De Rijke. 2004. Using wordnet to measure
showed that it outperforms state of the art methods semantic orientations of adjectives. In National Insti-
limited to using language specific resources. tute for, pages 1115–1118.
Acknowledgments Hiroshi Kanayama and Tetsuya Nasukawa. 2006. Fully
This research was funded in part by the Office automatic lexicon expansion for domain-oriented sen-
of the Director of National Intelligence (ODNI), timent analysis. In EMNLP’06, pages 355–363.
</bodyText>
<reference confidence="0.96026572">
596 George A. Miller. 1995. Wordnet: a lexical database for
english. Commun. ACM, 38(11):39–41.
Satoshi Morinaga, Kenji Yamanishi, Kenji Tateishi, and
Toshikazu Fukushima. 2002. Mining product reputa-
tions on the web. In KDD’02, pages 341–349.
Dipak Narayan, Debasri Chakrabarti, Prabhakar Pande,
and P. Bhattacharyya. 2002. An experience in build-
ing the indo wordnet - a wordnet for hindi. In First
International Conference on Global WordNet.
Tetsuya Nasukawa and Jeonghee Yi. 2003. Sentiment
analysis: capturing favorability using natural language
processing. In K-CAP ’03: Proceedings of the 2nd
international conference on Knowledge capture, pages
70–77.
J. Norris. 1997. Markov chains. Cambridge University
Press.
Ana-Maria Popescu and Oren Etzioni. 2005. Extracting
product features and opinions from reviews. In HLT-
EMNLP’05, pages 339–346.
Ellen Riloff and Janyce Wiebe. 2003. Learning
extraction patterns for subjective expressions. In
EMNLP’03, pages 105–112.
P. Pande P. Bhattacharyya S. Jha, D. Narayan. 2001. A
wordnet for hindi. In International Workshop on Lexi-
cal Resources in Natural Language Processing.
Philip Stone, Dexter Dunphy, Marchall Smith, and Daniel
Ogilvie. 1966. The general inquirer: A computer ap-
proach to content analysis. The MIT Press.
Hiroya Takamura, Takashi Inui, and Manabu Okumura.
2005. Extracting semantic orientations of words using
spin model. In ACL’05, pages 133–140.
Peter Turney and Michael Littman. 2003. Measuring
praise and criticism: Inference of semantic orientation
from association. ACM Transactions on Information
Systems, 21:315–346.
Peter D. Turney. 2002. Thumbs up or thumbs down?:
semantic orientation applied to unsupervised classifi-
cation of reviews. In ACL’02, pages 417–424.
P. Vossen. 1997. Eurowordnet: a multilingual database
for information retrieval. In DELOS workshop on
Cross-language Information Retrieval.
Janyce Wiebe. 2000. Learning subjective adjectives
from corpora. In Proceedings of the Seventeenth
National Conference on Artificial Intelligence and
Twelfth Conference on Innovative Applications of Ar-
tificial Intelligence, pages 735–740.
Hong Yu and Vasileios Hatzivassiloglou. 2003. Towards
answering opinion questions: separating facts from
opinions and identifying the polarity of opinion sen-
tences. In EMNLP’03, pages 129–136.
</reference>
<page confidence="0.997583">
597
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.024678">
<title confidence="0.999771">Identifying the Semantic Orientation of Foreign Words</title>
<author confidence="0.97131">Ahmed</author>
<affiliation confidence="0.990755">EECS University of</affiliation>
<author confidence="0.608391">Ann Arbor</author>
<email confidence="0.999563">hassanam@umich.edu</email>
<author confidence="0.630876">Rahul</author>
<affiliation confidence="0.9854135">EECS University of</affiliation>
<author confidence="0.620529">Ann Arbor</author>
<email confidence="0.999189">rahuljha@umich.edu</email>
<author confidence="0.54179">Amjad</author>
<affiliation confidence="0.946781">EECS University of</affiliation>
<author confidence="0.705231">Ann Arbor</author>
<email confidence="0.99908">amjbara@umich.edu</email>
<author confidence="0.53599">Dragomir</author>
<affiliation confidence="0.9847215">EECS Department and School of University of</affiliation>
<author confidence="0.622773">Ann Arbor</author>
<email confidence="0.999762">radev@umich.edu</email>
<abstract confidence="0.99539152173913">We present a method for identifying the positive or negative semantic orientation of foreign words. Identifying the semantic orientation of words has numerous applications in the areas of text classification, analysis of product review, analysis of responses to surveys, and mining online discussions. Identifying the semantic orientation of English words has been extensively studied in literature. Most of this work assumes the existence of resources (e.g. Wordnet, seeds, etc) that do not exist in foreign languages. In this work, we describe a method based on constructing a multilingual network connecting English and foreign words. We use this network to identify the semantic orientation of foreign words based on connection between words in the same language as well as multilingual connections. The method is experimentally tested using a manually labeled set of positive and negative words and has shown very promising results.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
</citationList>
</algorithm>
</algorithms>