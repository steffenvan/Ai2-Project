<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000331">
<title confidence="0.998322">
Lexicalization in Crosslinguistic Probabilistic Parsing:
The Case of French
</title>
<author confidence="0.98891">
Abhishek Arun and Frank Keller
</author>
<affiliation confidence="0.869018">
School of Informatics, University of Edinburgh
2 Buccleuch Place, Edinburgh EH8 9LW, UK
</affiliation>
<email confidence="0.980976">
a.arun@sms.ed.ac.uk,keller@inf.ed.ac.uk
</email>
<sectionHeader confidence="0.997187" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999970833333333">
This paper presents the first probabilistic
parsing results for French, using the re-
cently released French Treebank. We start
with an unlexicalized PCFG as a base-
line model, which is enriched to the level
of Collins’ Model 2 by adding lexical-
ization and subcategorization. The lexi-
calized sister-head model and a bigram
model are also tested, to deal with the flat-
ness of the French Treebank. The bigram
model achieves the best performance:
81% constituency F-score and 84% de-
pendency accuracy. All lexicalized mod-
els outperform the unlexicalized baseline,
consistent with probabilistic parsing re-
sults for English, but contrary to results
for German, where lexicalization has only
a limited effect on parsing performance.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999991059701493">
This paper brings together two strands of research
that have recently emerged in the field of probabilis-
tic parsing: crosslinguistic parsing and lexicalized
parsing. Interest in parsing models for languages
other than English has been growing, starting with
work on Czech (Collins et al., 1999) and Chinese
(Bikel and Chiang, 2000; Levy and Manning, 2003).
Probabilistic parsing for German has also been ex-
plored by a range of authors (Dubey and Keller,
2003; Schiehlen, 2004). In general, these authors
have found that existing lexicalized parsing models
for English (e.g., Collins 1997) do not straightfor-
wardly generalize to new languages; this typically
manifests itself in a severe reduction in parsing per-
formance compared to the results for English.
A second recent strand in parsing research has
dealt with the role of lexicalization. The conven-
tional wisdom since Magerman (1995) has been that
lexicalization substantially improves performance
compared to an unlexicalized baseline model (e.g., a
probabilistic context-free grammar, PCFG). How-
ever, this has been challenged by Klein and Man-
ning (2003), who demonstrate that an unlexicalized
model can achieve a performance close to the state
of the art for lexicalized models. Furthermore, Bikel
(2004) provides evidence that lexical information
(in the form of bi-lexical dependencies) only makes
a small contribution to the performance of parsing
models such as Collins’s (1997).
The only previous authors that have directly ad-
dressed the role of lexicalization in crosslinguistic
parsing are Dubey and Keller (2003). They show
that standard lexicalized models fail to outperform
an unlexicalized baseline (a vanilla PCFG) on Ne-
gra, a German treebank (Skut et al., 1997). They
attribute this result to two facts: (a) The Negra an-
notation assumes very flat trees, which means that
Collins-style head-lexicalization fails to pick up the
relevant information from non-head nodes. (b) Ger-
man allows flexible word order, which means that
standard parsing models based on context free gram-
mars perform poorly, as they fail to generalize over
different positions of the same constituent.
As it stands, Dubey and Keller’s (2003) work does
not tell us whether treebank flatness or word order
flexibility is responsible for their results: for English,
the annotation scheme is non-flat, and the word or-
der is non-flexible; lexicalization improves perfor-
mance. For German, the annotation scheme is flat
and the word order is flexible; lexicalization fails to
improve performance. The present paper provides
the missing piece of evidence by applying proba-
bilistic parsing models to French, a language with
non-flexible word order (like English), but with a
treebank with a flat annotation scheme (like Ger-
man). Our results show that French patterns with En-
glish: a large increase of parsing performance can be
obtained by using a lexicalized model. We conclude
that the failure to find a sizable effect of lexicaliza-
tion in German can be attributed to the word order
flexibility of that language, rather than to the flatness
of the annotation in the German treebank.
The paper is organized as follows: In Section 2,
we give an overview of the French Treebank we use
for our experiments. Section 3 discusses its anno-
tation scheme and introduces a set of tree transfor-
mations that we apply. Section 4 describes the pars-
</bodyText>
<page confidence="0.984152">
306
</page>
<note confidence="0.9942795">
Proceedings of the 43rd Annual Meeting of the ACL, pages 306–313,
Ann Arbor, June 2005. c�2005 Association for Computational Linguistics
</note>
<figure confidence="0.9936294">
&lt;NP&gt;
&lt;w lemma=&amp;quot;eux&amp;quot; ei=&amp;quot;PROmp&amp;quot;
ee=&amp;quot;PRO-3mp&amp;quot; cat=&amp;quot;PRO&amp;quot;
subcat=&amp;quot;3mp&amp;quot;&gt;eux&lt;/w&gt;
&lt;/NP&gt;
</figure>
<figureCaption confidence="0.743259333333333">
Figure 1: Word-level annotation in the French Tree-
bank: eux ‘they’ (cat: POS tag, subcat: subcate-
gory, ei, ee: inflection)
</figureCaption>
<bodyText confidence="0.980603333333333">
ing models, followed by the results for the unlexi-
calized baseline model in Section 6 and for a range
of lexicalized models in Section 5. Finally, Section 7
provides a crosslinguistic comparison involving data
sets of the same size extracted from the French, En-
glish, and German treebanks.
</bodyText>
<sectionHeader confidence="0.982436" genericHeader="introduction">
2 The French Treebank
</sectionHeader>
<subsectionHeader confidence="0.995568">
2.1 Annotation Scheme
</subsectionHeader>
<bodyText confidence="0.999461666666667">
The French Treebank (FTB; Abeill´e et al. 2000) con-
sists of 20,648 sentences extracted from the daily
newspaper Le Monde, covering a variety of authors
and domains (economy, literature, politics, etc.).&apos;
The corpus is formatted in XML and has a rich mor-
phosyntactic tagset that includes part-of-speech tag,
‘subcategorization’ (e.g., possessive or cardinal), in-
flection (e.g., masculine singular), and lemma in-
formation. Compared to the Penn Treebank (PTB;
Marcus et al. 1993), the POS tagset of the French
Treebank is smaller (13 tags vs. 36 tags): all punc-
tuation marks are represented as the single PONCT
tag, there are no separate tags for modal verbs, wh-
words, and possessives. Also verbs, adverbs and
prepositions are more coarsely defined. On the other
hand, a separate clitic tag (CL) for weak pronouns is
introduced. An example for the word-level annota-
tion in the FTB is given in Figure 1
The phrasal annotation of the FTB differs from
that for the Penn Treebank in several aspects. There
is no verb phrase: only the verbal nucleus (VN) is
annotated. A VN comprises the verb and any clitics,
auxiliaries, adverbs, and negation associated with it.
This results in a flat syntactic structure, as in (1).
</bodyText>
<listItem confidence="0.960335">
(1) (VN (V sont) (ADV syst´ematiquement) (V
arrˆet´es)) ‘are systematically arrested’
</listItem>
<bodyText confidence="0.917976625">
The noun phrases (NPs) in the FTB are also flat; a
noun is grouped together with any associated deter-
miners and prenominal adjectives, as in example (2).
Note that postnominal adjectives, however, are ad-
joined to the NP in an adjectival phrase (AP).
&apos;The French Treebank was developed at Universit´e Paris 7.
A license can be obtained by emailing Anne Abeill´e (abeille@
linguist.jussieu.fr).
</bodyText>
<figure confidence="0.6518424">
&lt;w compound=&amp;quot;yes&amp;quot; lemma=&amp;quot;d’entre&amp;quot;
ei=&amp;quot;P&amp;quot; ee=&amp;quot;P&amp;quot; cat=&amp;quot;P&amp;quot;&gt;
&lt;w catint=&amp;quot;P&amp;quot;&gt;d’&lt;/w&gt;
&lt;w catint=&amp;quot;P&amp;quot;&gt;entre&lt;/w&gt;
&lt;/w&gt;
</figure>
<figureCaption confidence="0.779177">
Figure 2: Annotation of compounds in the French
Treebank: d’entre ‘between’ (catint: compound-
internal POS tag)
</figureCaption>
<bodyText confidence="0.968121944444444">
(2) (NP (D des) (A petits) (N mots) (AP (ADV tr`es)
(A gentils))) ‘small, very gentle words’
Unlike the PTB, the FTB annotates coordinated
phrases with the syntactic tag COORD (see the left
panel of Figure 3 for an example).
The treatment of compounds is also different in
the FTB. Compounds in French can comprise words
which do not exist otherwise (e.g., insu in the com-
pound preposition a� l’insu de ‘unbeknownst to’) or
can exhibit sequences of tags otherwise ungrammat-
ical (e.g., a� la va vite ‘in a hurry’: Prep + Det +
finite verb + adverb). To account for these proper-
ties, compounds receive a two-level annotation in
the FTB: a subordinate level is added for the con-
stituent parts of the compound (both levels use the
same POS tagset). An example is given in Figure 2.
Finally, the FTB differs from the PTB in that it
does not use any empty categories.
</bodyText>
<subsectionHeader confidence="0.999283">
2.2 Data Sets
</subsectionHeader>
<bodyText confidence="0.99998296">
The version of the FTB made available to us (ver-
sion 1.4, May 2004) contains numerous errors. Two
main classes of inaccuracies were found in the data:
(a) The word is present but morphosyntactic tags
are missing; 101 such cases exist. (b) The tag in-
formation for a word (or a part of a compound) is
present but the word (or compound part) itself is
missing. There were 16,490 instances of this error
in the dataset.
Initially we attempted to correct the errors, but
this proved too time consuming, and we often found
that the errors cannot be corrected without access to
the raw corpus, which we did not have. We therefore
decided to remove all sentences with errors, which
lead to a reduced dataset of 10,552 sentences.
The remaining data set (222,569 words at an av-
erage sentence length of 21.1 words) was split into
a training set, a development set (used to test the
parsing models and to tune their parameters), and a
test set, unseen during development. The training set
consisted of the first 8,552 sentences in the corpus,
with the following 1000 sentences serving as the de-
velopment set and the final 1000 sentences forming
the test set. All results reported in this paper were
obtained on the test set, unless stated otherwise.
</bodyText>
<page confidence="0.956212">
307
</page>
<equation confidence="0.992102333333333">
XP
X COORD
C XP
X
XP
X C XP
X
XP
X C X
</equation>
<sectionHeader confidence="0.989765" genericHeader="method">
3 Tree Transformations
</sectionHeader>
<bodyText confidence="0.999936625">
We created a number of different datasets from the
FTB, applying various tree transformation to deal
with the peculiarities of the FTB annotation scheme.
As a first step, the XML formatted FTB data was
converted to PTB-style bracketed expressions. Only
the POS tag was kept and the rest of the morphologi-
cal information for each terminal was discarded. For
example, the NP in Figure 1 was transformed to:
</bodyText>
<listItem confidence="0.914615">
(3) (NP (PRO eux))
</listItem>
<bodyText confidence="0.9998431875">
In order to make our results comparable to re-
sults from the literature, we also transformed the
annotation of punctuation. In the FTB, all punc-
tuations is tagged uniformly as PONCT. We re-
assigned the POS for punctuation using the PTB
tagset, which differentiates between commas, peri-
ods, brackets, etc.
Compounds have internal structure in the FTB
(see Section 2.1). We created two separate data sets
by applying two alternative tree transformation to
make FTB compounds more similar to compounds
in other annotation schemes. The first was collaps-
ing the compound by concatenating the compound
parts using an underscore and picking up the cat
information supplied at the compound level. For ex-
ample, the compound in Figure 2 results in:
</bodyText>
<listItem confidence="0.811941">
(4) (P d’ entre)
</listItem>
<bodyText confidence="0.999926090909091">
This approach is similar to the treatment of com-
pounds in the German Negra treebank (used by
Dubey and Keller 2003), where compounds are not
given any internal structure (compounds are mostly
spelled without spaces or apostrophes in German).
The second approach is expanding the compound.
Here, the compound parts are treated as individual
words with their own POS (from the catint tag),
and the suffix Cmp is appended the POS of the com-
pound, effectively expanding the tagset.2 Now Fig-
ure 2 yields:
</bodyText>
<listItem confidence="0.834134">
(5) (PCmp (P d’) (P entre)).
</listItem>
<bodyText confidence="0.999949888888889">
This approach is similar to the treatment of com-
pounds in the PTB (except hat the PTB does not use
a separate tag for the mother category). We found
that in the FTB the POS tag of the compound part
is sometimes missing (i.e., the value of catint is
blank). In cases like this, the missing catint was
substituted with the cat tag of the compound. This
heuristic produces the correct POS for the subparts
of the compound most of the time.
</bodyText>
<footnote confidence="0.504356">
2An alternative would be to retain the cat tag of the com-
pound. The effect of this decision needs to be investigated in
future work.
</footnote>
<figureCaption confidence="0.867704333333333">
Figure 3: Coordination in the FTB: before (left) and
after transformation (middle); coordination in the
PTB (right)
</figureCaption>
<bodyText confidence="0.999972076923077">
As mentioned previously, coordinate structures
have their own constituent label COORD in the
FTB annotation. Existing parsing models (e.g., the
Collins models) have coordination-specific rules,
presupposing that coordination is marked up in PTB
format. We therefore created additional datasets
where a transformation is applied that raises coor-
dination. This is illustrated in Figure 3. Note that
in the FTB annotation scheme, a coordinating con-
junction is always followed by a syntactic category.
Hence the resulting tree, though flatter, is still not
fully compatible with the PTB treatment of coordi-
nation.
</bodyText>
<sectionHeader confidence="0.998176" genericHeader="method">
4 Probabilistic Parsing Models
</sectionHeader>
<subsectionHeader confidence="0.999627">
4.1 Probabilistic Context-Free Grammars
</subsectionHeader>
<bodyText confidence="0.999982666666667">
The aim of this paper is to further explore the
crosslinguistic role of lexicalization by applying lex-
icalized parsing models to the French Treebank pars-
ing accuracy. Following Dubey and Keller (2003),
we use a standard unlexicalized PCFG as our base-
line. In such a model, each context-free rule RHS —*
LHS is annotated with an expansion probability
P(RHS|LHS). The probabilities for all the rules with
the same left-hand side have to sum up to one and
the probability of a parse tree T is defined as the
product of the probabilities of each rule applied in
the generation of T.
</bodyText>
<subsectionHeader confidence="0.998702">
4.2 Collins’ Head-Lexicalized Models
</subsectionHeader>
<bodyText confidence="0.999912125">
A number of lexicalized models can then be applied
to the FTB, comparing their performance to the un-
lexicalized baseline. We start with Collins’ Model 1,
which lexicalizes a PCFG by associating a word w
and a POS tag t with each non-terminal X in the
tree. Thus, a non-terminal is written as X(x) where
x = (w�t) and X is constituent label. Each rule now
has the form:
</bodyText>
<equation confidence="0.953994">
(1) P(h) —* Ln(ln)...L1(l1)H(h)R1(r1)...Rm(rm)
</equation>
<bodyText confidence="0.99888975">
Here, H is the head-daughter of the phrase, which
inherits the head-word h from its parent P. L1 ...Ln
and R1 ...Rn are the left and right sisters ofH. Either
n or m may be zero, and n = m for unary rules.
</bodyText>
<page confidence="0.994588">
308
</page>
<bodyText confidence="0.999964375">
The addition of lexical heads leads to an enor-
mous number of potential rules, making direct esti-
mation of P(RHS|LHS) infeasible because of sparse
data. Therefore, the generation of the RHS of a rule
given the LHS is decomposed into three steps: first
the head is generated, then the left and right sisters
are generated by independent 0th-order Markov pro-
cesses. The probability of a rule is thus defined as:
</bodyText>
<equation confidence="0.9962765">
P(RHS|LHS) =
P(Ln(Zn) ... \L1(l717)H(h), (R1 ((r1) ... Rm (rm()  |\P(h))
= Ph(H|P,h) x\llmilPr(R(i(r\i)|P,h,H,d(i))
x IIn+1i=1Pl(Li(li)IP,h,H,d(l))
</equation>
<bodyText confidence="0.998696769230769">
Here, Ph is the probability of generating the head, Pl
and Pr are the probabilities of generating the left and
right sister respectively. Lm+1(lm+1) and Rm+1(rm+1)
are defined as stop categories which indicate when to
stop generating sisters. d(i) is a distance measure, a
function of the length of the surface string between
the head and the previously generated sister.
Collins’ Model 2 further refines the initial model
by incorporating the complement/adjunct distinction
and subcategorization frames. The generative pro-
cess is enhanced to include a probabilistic choice of
left and right subcategorization frames. The proba-
bility of a rule is now:
</bodyText>
<equation confidence="0.9991142">
Ph(H|P,h) xPlc(LC|P,H,h) xPrc(RC|P,H,h)
xIIm+1
i=1 Pr(Ri(ri)|P,h,H,d(i),RC)
xIIn+1
i=1 Pl(Li(li)|P,h,H,d(i),LC)
</equation>
<bodyText confidence="0.999950333333333">
Here, LC and RC are left and right subcat frames,
multisets specifying the complements that the head
requires in its left or right sister. The subcat re-
quirements are added to the conditioning context. As
complements are generated, they are removed from
the appropriate subcat multiset.
</bodyText>
<sectionHeader confidence="0.993709" genericHeader="method">
5 Experiment 1: Unlexicalized Model
</sectionHeader>
<subsectionHeader confidence="0.982343">
5.1 Method
</subsectionHeader>
<bodyText confidence="0.999697642857143">
This experiment was designed to compare the per-
formance of the unlexicalized baseline model on
four different datasets, created by the tree trans-
formations described in Section 3: compounds
expanded (Exp), compounds contracted (Cont),
compounds expanded with coordination raised
(Exp+CR), and compounds contracted with coordi-
nation raised (Cont+CR).
We used BitPar (Schmid, 2004) for our unlexi-
calized experiments. BitPar is a parser based on a
bit-vector implementation of the CKY algorithm. A
grammar and lexicon were read off our training set,
along with rule frequencies and frequencies for lex-
ical items, based on which BitPar computes the rule
</bodyText>
<table confidence="0.9996948">
Model LR LP CBs 0CB &lt;2CB Tag Cov
Exp 59.97 58.64 1.74 39.05 73.23 91.00 99.20
Exp+CR 60.75 60.57 1.57 40.77 75.03 91.08 99.09
Cont 64.19 64.61 1.50 46.74 76.80 93.30 98.48
Cont+CR 66.11 65.55 1.39 46.99 78.95 93.22 97.94
</table>
<tableCaption confidence="0.992464">
Table 1: Results for unlexicalized models (sentences
</tableCaption>
<bodyText confidence="0.983628">
&lt;40 words); each model performed its own POS
tagging.
probabilities using maximum likelihood estimation.
A frequency distribution for POS tags was also read
off the training set; this distribution is used by BitPar
to tag unknown words in the test data.
All models were evaluated using standard Par-
seval measures of labeled recall (LR), labeled pre-
cision (LP), average crossing brackets (CBs), zero
crossling brackets (0CB), and two or less crossing
brackets (&lt;2CB). We also report tagging accuracy
(Tag), and coverage (Cov).
</bodyText>
<sectionHeader confidence="0.510584" genericHeader="method">
5.2 Results
</sectionHeader>
<bodyText confidence="0.9998389375">
The results for the unlexicalized model are shown in
Table 1 for sentences of length &lt;40 words. We find
that contracting compounds increases parsing per-
formance substantially compared to expanding com-
pounds, raising labeled recall from around 60% to
around 64% and labeled precision from around 59%
to around 65%. The results show that raising co-
ordination is also beneficial; it increases precision
and recall by 1–2%, both for expanded and for non-
expanded compounds.
Note that these results were obtained by uni-
formly applying coordination raising during evalu-
ation, so as to make all models comparable. For the
Exp and Cont models, the parsed output and the gold
standard files were first converted by raising coordi-
nation and then the evaluation was performed.
</bodyText>
<subsectionHeader confidence="0.928817">
5.3 Discussion
</subsectionHeader>
<bodyText confidence="0.999886466666667">
The disappointing performance obtained for the ex-
panded compound models can be partly attributed
to the increase in the number of grammar rules
(11,704 expanded vs. 10,299 contracted) and POS
tags (24 expanded vs. 11 contracted) associated with
that transformation.
However, a more important point observation is
that the two compound models do not yield compa-
rable results, since an expanded compound has more
brackets than a contracted one. We attempted to ad-
dress this problem by collapsing the compounds for
evaluation purposes (as described in Section 3). For
example, (5) would be contracted to (4). However,
this approach only works if we are certain that the
model is tagging the right words as compounds. Un-
</bodyText>
<page confidence="0.995986">
309
</page>
<bodyText confidence="0.962038">
fortunately, this is rarely the case. For example, the
model outputs:
</bodyText>
<listItem confidence="0.799774">
(6) (NCmp (N jours) (N commerc¸ants))
</listItem>
<bodyText confidence="0.9997886">
But in the gold standard file, jours and commerc¸ants
are two distinct NPs. Collapsing the compounds
therefore leads to length mismatches in the test data.
This problem occurs frequently in the test set, so that
such an evaluation becomes pointless.
</bodyText>
<sectionHeader confidence="0.994006" genericHeader="method">
6 Experiment 2: Lexicalized Models
</sectionHeader>
<subsectionHeader confidence="0.994144">
6.1 Method
</subsectionHeader>
<bodyText confidence="0.999974325">
Parsing We now compare a series of lexicalized
parsing models against the unlexicalized baseline es-
tablished in the previous experiment. Our is was to
test if French behaves like English in that lexicaliza-
tion improves parsing performance, or like German,
in that lexicalization has only a small effect on pars-
ing performance.
The lexicalized parsing experiments were run us-
ing Dan Bikel’s probabilistic parsing engine (Bikel,
2002) which in addition to replicating the models
described by Collins (1997) also provides a con-
venient interface to develop corresponding parsing
models for other languages.
Lexicalization requires that each rule in a gram-
mar has one of the categories on its right hand side
annotated as the head. These head rules were con-
structed based on the FTB annotation guidelines
(provided along with the dataset), as well as by us-
ing heuristics, and were optimized on the develop-
ment set. Collins’ Model 2 incorporates a comple-
ment/adjunct distinction and probabilities over sub-
categorization frames. Complements were marked
in the training phase based on argument identifica-
tion rules, tuned on the development set.
Part of speech tags are generated along with
the words in the models; parsing and tagging are
fully integrated. To achieve this, Bikel’s parser
requires a mapping of lexical items to ortho-
graphic/morphological word feature vectors. The
features implemented (capitalization, hyphenation,
inflection, derivation, and compound) were again
optimized on the development set.
Like BitPar, Bikel’s parser implements a prob-
abilistic version of the CKY algorithm. As with
normal CKY, even though the model is defined in
a top-down, generative manner, decoding proceeds
bottom-up. To speed up decoding, the algorithm im-
plements beam search. Collins uses a beam width of
104, while we found that a width of 105 gave us the
best coverage vs. parsing speed trade-off.
</bodyText>
<table confidence="0.980829285714286">
Label FTB PTB Negra Label FTB PTB Negra
SENT 5.84 2.22 4.55 VPpart 2.51 – –
Ssub 4.41 – – VN 1.76 – –
Sint 3.44 – – PP 2.10 2.03 3.08
Srel 3.92 – – NP 2.45 2.20 3.08
VP – 2.32 2.59 AdvP 2.24 – 2.08
VPinf 3.07 – – AP 1.34 – 2.22
</table>
<tableCaption confidence="0.854069">
Table 2: Average number of daughter nodes per con-
stituents in three treebanks
</tableCaption>
<bodyText confidence="0.998637137931034">
Flatness As already pointed out in Section 2.1,
the FTB uses a flat annotation scheme. This can
be quantified by computing the average number of
daughters for each syntactic category in the FTB,
and comparing them with the figures available for
PTB and Negra (Dubey and Keller, 2003). This is
done in Table 2. The absence of sentence-internal
VPs explains the very high level of flatness for the
sentential category SENT (5.84 daughters), com-
pared to the PTB (2.44), and even to Negra, which is
also very flat (4.55 daughters). The other sentential
categories Ssub (subordinate clauses), Srel (relative
clause), and Sint (interrogative clause) are also very
flat. Note that the FTB uses VP nodes only for non-
finite subordinate clauses: VPinf (infinitival clause)
and VPpart (participle clause); these categories are
roughly comparable in flatness to the VP category
in the PTB and Negra. For NP, PPs, APs, and AdvPs
the FTB is roughly as flat as the PTB, and somewhat
less flat than Negra.
Sister-Head Model To cope with the flatness of
the FTB, we implemented three additional parsing
models. First, we implemented Dubey and Keller’s
(2003) sister-head model, which extends Collins’
base NP model to all syntactic categories. This
means that the probability function Pr in equation (2)
is no longer conditioned on the head but instead on
its previous sister, yielding the following definition
for Pr (and by analogy Pl):
</bodyText>
<listItem confidence="0.654795">
(4) Pr(Ri(ri)|P,Ri−1(ri−1),d(i))
</listItem>
<bodyText confidence="0.99559375">
Dubey and Keller (2003) argue that this implicitly
adds binary branching to the grammar, and therefore
provides a way of dealing with flat annotation (in
Negra and in the FTB, see Table 2).
Bigram Model This model, inspired by the ap-
proach of Collins et al. (1999) for parsing the Prague
Dependency Treebank, builds on Collins’ Model 2
by implementing a 1st order Markov assumption for
the generation of sister non-terminals. The latter are
now conditioned, not only on their head, but also on
the previous sister. The probability function for Pr
(and by analogy Pl) is now:
</bodyText>
<page confidence="0.720016">
(5) Pr(Ri(ri)|P,h,H,d(i),Ri−1,RC)
310
</page>
<table confidence="0.999716833333333">
Model LR LP CBs 0CB &lt;2CB Tag Cov
Model 1 80.35 79.99 0.78 65.22 89.46 96.86 99.68
Model 2 80.49 79.98 0.77 64.85 90.10 96.83 99.68
SisterHead 80.47 80.56 0.78 64.96 89.34 96.85 99.57
Bigram 81.15 80.84 0.74 65.21 90.51 96.82 99.46
BigramFlat 80.30 80.05 0.77 64.78 89.13 96.71 99.57
</table>
<tableCaption confidence="0.985977">
Table 3: Results for lexicalized models (sentences
</tableCaption>
<bodyText confidence="0.9773915">
≤40 words); each model performed its own POS
tagging; all lexicalized models used the Cont+CR
data set
The intuition behind this approach is that the model
will learn that the stop symbol is more likely to fol-
low phrases with many sisters. Finally, we also ex-
perimented with a third model (BigramFlat) that ap-
plies the bigram model only for categories with high
degrees of flatness (SENT, Srel, Ssub, Sint, VPinf,
and VPpart).
</bodyText>
<subsectionHeader confidence="0.888455">
6.2 Results
</subsectionHeader>
<bodyText confidence="0.999902205882353">
Constituency Evaluation The lexicalized models
were tested on the Cont+CR data set, i.e., com-
pounds were contracted and coordination was raised
(this is the configuration that gave the best perfor-
mance in Experiment 1).
Table 3 shows that all lexicalized models achieve
a performance of around 80% recall and precision,
i.e., they outperform the best unlexicalized model by
at least 14% (see Table 1). This is consistent with
what has been reported for English on the PTB.
Collins’ Model 2, which adds the comple-
ment/adjunct distinction and subcategorization
frames achieved only a very small improvement
over Collins’ Model 1, which was not statistically
significant using a χ2 test. It might well be that
the annotation scheme of the FTB does not lend
itself particularly well to the demands of Model 2.
Moreover, as Collins (1997) mentions, some of
the benefits of Model 2 are already captured by
inclusion of the distance measure.
A further small improvement was achieved us-
ing Dubey and Keller’s (2003) sister-head model;
however, again the difference did not reach sta-
tistical significance. The bigram model, however,
yielded a statistically significant improvement over
Collins’ Model 1 (recall χ2 = 3.91, df = 1, p:5.048;
precision χ2 = 3.97, df = 1, p:5 .046). This is con-
sistent with the findings of Collins et al. (1999)
for Czech, where the bigram model upped depen-
dency accuracy by about 0.9%, as well as for En-
glish where Charniak (2000) reports an increase
in F-score of approximately 0.3%. The BigramFlat
model, which applies the bigram model to only those
labels which have a high degree of flatness, performs
</bodyText>
<table confidence="0.999653375">
Model LR LP CBs 0CB &lt;2CB Tag Cov
Exp+CR 65.50 64.76 1.49 42.36 77.48 100.0 97.83
Cont+CR 69.35 67.93 1.34 47.43 80.25 100.0 96.97
Model1 81.51 81.43 0.78 64.60 89.25 98.54 99.78
Model2 81.69 81.59 0.78 63.84 89.69 98.55 99.78
SisterHead 81.08 81.56 0.79 64.35 89.57 98.51 99.57
Bigram 81.78 81.91 0.78 64.96 89.12 98.81 99.67
BigramFlat 81.14 81.19 0.81 63.37 88.80 98.80 99.67
</table>
<tableCaption confidence="0.99116375">
Table 4: Results for lexicalized and unlexical-
ized models (sentences ≤40 words) with correct
POS tags supplied; all lexicalized models used the
Cont+CR data set
</tableCaption>
<bodyText confidence="0.997573162162162">
at roughly the same level as Model 1.
The models in Tables 1 and 3 implemented their
own POS tagging. Tagging accuracy was 91–93%
for BitPar (unlexicalized models) and around 96%
for the word-feature enhanced tagging model of the
Bikel parser (lexicalized models). POS tags are an
important cue for parsing. To gain an upper bound
on the performance of the parsing models, we reran
the experiments by providing the correct POS tag
for the words in the test set. While BitPar always
uses the tags provided, the Bikel parser only uses
them for words whose frequency is less than the un-
known word threshold. As Table 4 shows, perfect
tagging increased parsing performance in the lexi-
calized models by around 3%. This shows that the
poor POS tagging performed by BitPar is one of the
reasons of the poor performance of the lexicalized
models. The impact of perfect tagging is less dras-
tic on the lexicalized models (around 1% increase).
However, our main finding, viz., that lexicalized
models outperform unlexicalized models consider-
able on the FTB, remains valid, even with perfect
tagging.3
Dependency Evaluation We also evaluated our
models using dependency measures, which have
been argued to be more annotation-neutral than
Parseval. Lin (1995) notes that labeled bracketing
scores are more susceptible to cascading errors,
where one incorrect attachment decision causes the
scoring algorithm to count more than one error.
The gold standard and parsed trees were con-
verted into dependency trees using the algorithm de-
scribed by Lin (1995). Dependency accuracy is de-
fined as the ratio of correct dependencies over the to-
tal number of dependencies in a sentence. (Note that
this is an unlabeled dependency measure.) Depen-
dency accuracy and constituency F-score are shown
</bodyText>
<footnote confidence="0.9971542">
3It is important to note that the Collins model has a range
of other features that set it apart from a standard unlexicalized
PCFG (notably Markovization), as discussed in Section 4.2. It
is therefore likely that the gain in performance is not attributable
to lexicalization alone.
</footnote>
<page confidence="0.991892">
311
</page>
<table confidence="0.9984978">
Model Dependency F-score
Cont+CR 73.09 65.83
Model 2 83.96 80.23
SisterHead 84.00 80.51
Bigram 84.20 80.99
</table>
<tableCaption confidence="0.977911">
Table 5: Dependency vs. constituency scores for lex-
icalized and unlexicalized models
</tableCaption>
<bodyText confidence="0.99972425">
in Table 5 for the most relevant FTB models. (F-
score is computed as the geometric mean of labeled
recall and precision.)
Numerically, dependency accuracies are higher
than constituency F-scores across the board. How-
ever, the effect of lexicalization is the same on both
measures: for the FTB, a gain of 11% in dependency
accuracy is observed for the lexicalized model.
</bodyText>
<sectionHeader confidence="0.9989545" genericHeader="method">
7 Experiment 3: Crosslinguistic
Comparison
</sectionHeader>
<bodyText confidence="0.999983833333333">
The results reported in Experiments 1 and 2 shed
some light on the role of lexicalization for parsing
French, but they are not strictly comparable to the
results that have been reported for other languages.
This is because the treebanks available for different
languages typically vary considerably in size: our
FTB training set was about 8,500 sentences large,
while the standard training set for the PTB is about
40,000 sentences in size, and the Negra training set
used by Dubey and Keller (2003) comprises about
18,600 sentences. This means that the differences in
the effect of lexicalization that we observe could be
simply due to the size of the training set: lexicalized
models are more susceptible to data sparseness than
unlexicalized ones.
We therefore conducted another experiment in
which we applied Collins’ Model 2 to subsets of
the PTB that were comparable in size to our FTB
data sets. We combined sections 02–05 and 08 of
the PTB (8,345 sentences in total) to form the train-
ing set, and the first 1,000 sentences of section 23
to form our test set. As a baseline model, we also
run an unlexicalized PCFG on the same data sets.
For comparison with Negra, we also include the re-
sults of Dubey and Keller (2003): they report the
performance of Collins’ Model 1 on a data set of
9,301 sentences and a test set of 1,000 sentences,
which are comparable in size to our FTB data sets.4
The results of the crosslinguistic comparison are
shown in Table 6.5 We conclude that the effect of
</bodyText>
<footnote confidence="0.999183">
4Dubey and Keller (2003) report only F-scores for the re-
duced data set (see their Figure 1); the other scores were pro-
vided by Amit Dubey. No results for Model 2 are available.
5For this experiments, the same POS tagging model was ap-
plied to the PTB and the FTB data, which is why the FTB fig-
</footnote>
<table confidence="0.996819142857143">
Corpus Model LR LP CBs 0CB &lt;2CB
FTB Cont+CR 66.11 65.55 1.39 46.99 78.95
Model 2 79.20 78.58 0.83 63.33 89.23
PTB Unlex 72.79 75.23 2.54 31.56 58.98
Model 2 86.43 86.79 1.17 57.80 82.44
Negra Unlex 69.64 67.27 1.12 54.21 82.84
Model 1 68.33 67.32 0.83 60.43 88.78
</table>
<tableCaption confidence="0.926643">
Table 6: The effect of lexicalization on different cor-
pora for training sets of comparable size (sentences
≤40 words)
</tableCaption>
<bodyText confidence="0.998858">
lexicalization is stable even if the size of the train-
ing set is held constant across languages: For the
FTB we find that lexicalization increases F-score by
around 13%. Also for the PTB, we find an effect of
lexicalization of about 14%. For the German Negra
treebank, however, the performance of the lexical-
ized and the unlexicalized model are almost indis-
tinguishable. (This is true for Collins’ Model 1; note
that Dubey and Keller (2003) do report a small im-
provement for the lexicalized sister-head model.)
</bodyText>
<sectionHeader confidence="0.999972" genericHeader="related work">
8 Related Work
</sectionHeader>
<bodyText confidence="0.999971">
We are not aware of any previous attempts to build
a probabilistic, treebank-trained parser for French.
However, there is work on chunking for French. The
group who built the French Treebank (Abeill´e et al.,
2000) used a rule-based chunker to automatically
annotate the corpus with syntactic structures, which
were then manually corrected. They report an un-
labeled recall/precision of 94.3/94.2% for opening
brackets and 92.2/91.4% for closing brackets, and a
label accuracy of 95.6%. This result is not compara-
ble to our results for full parsing.
Giguet and Vergne (1997) present use a memory-
based learner to predict chunks and dependencies
between chunks. The system is evaluated on texts
from Le Monde (different from the FTB texts). Re-
sults are only reported for verb-object dependencies,
for which recall/precision is 94.04/96.39%. Again,
these results are not comparable to ours, which were
obtained using a different corpus, a different depen-
dency scheme, and for a full set of dependencies.
</bodyText>
<sectionHeader confidence="0.998512" genericHeader="conclusions">
9 Conclusions
</sectionHeader>
<bodyText confidence="0.98870175">
In this paper, we provided the first probabilis-
tic, treebank-trained parser for French. In Exper-
iment 1, we established an unlexicalized baseline
model, which yielded a labeled precision and re-
call of about 66%. We experimented with a num-
ber of tree transformation that take account of the
peculiarities of the annotation of the French Tree-
ures are slightly lower than in Table 3.
</bodyText>
<page confidence="0.995444">
312
</page>
<bodyText confidence="0.999975056603774">
bank; the best performance was obtained by rais-
ing coordination and contracting compounds (which
have internal structure in the FTB). In Experiment 2,
we explored a range of lexicalized parsing models,
and found that lexicalization improved parsing per-
formance by up to 15%: Collins’ Models 1 and 2
performed at around 80% LR and LP. No signifi-
cant improvement could be achieved by switching to
Dubey and Keller’s (2003) sister-head model, which
has been claimed to be particularly suitable for tree-
banks with flat annotation, such as the FTB. A small
but significant improvement (to 81% LR and LP)
was obtained by a bigram model that combines fea-
tures of the sister-head model and Collins’ model.
These results have important implications for
crosslinguistic parsing research, as they allow us
to tease apart language-specific and annotation-
specific effects. Previous work for English (e.g.,
Magerman, 1995; Collins, 1997) has shown that lex-
icalization leads to a sizable improvement in pars-
ing performance. English is a language with non-
flexible word order and with a treebank with a non-
flat annotation scheme (see Table 2). Research on
German (Dubey and Keller, 2003) showed that lex-
icalization leads to no sizable improvement in pars-
ing performance for this language. German has a
flexible word order and a flat treebank annotation,
both of which could be responsible for this counter-
intuitive effect. The results for French presented in
this paper provide the missing piece of evidence:
they show that French behaves like English in that
it shows a large effect of lexicalization. Like En-
glish, French is a language with non-flexible word
order, but like the German Treebank, the French
Treebank has a flat annotation. We conclude that
Dubey and Keller’s (2003) results for German can be
attributed to a language-specific factor (viz., flexible
word order) rather than to an annotation-specific fac-
tor (viz., flat annotation). We confirmed this claim in
Experiment 3 by showing that the effects of lexical-
ization observed for English, French, and German
are preserved if the size of the training set is kept
constant across languages.
An interesting prediction follows from the claim
that word order flexibility, rather than flatness of
annotation, is crucial for lexicalization. A language
which has a flexible word order (like German), but
a non-flat treebank (like English) should show no
effect of lexicalization, i.e., lexicalized models are
predicted not to outperform unlexicalized ones. In
future work, we plan to test this prediction for Ko-
rean, a flexible word order language whose treebank
(Penn Korean Treebank) has a non-flat annotation.
</bodyText>
<sectionHeader confidence="0.998467" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999887044117647">
Abeill´e, Anne, Lionel Clement, and Alexandra Kinyon. 2000.
Building a treebank for French. In Proceedings of the 2nd In-
ternational Conference on Language Resources and Evalu-
ation. Athens.
Bikel, Daniel M. 2002. Design of a multi-lingual, parallel-
processing statistical parsing engine. In Proceedings of the
2nd International Conference on Human Language Technol-
ogy Research. Morgan Kaufmann, San Francisco.
Bikel, Daniel M. 2004. A distributional analysis of a lexicalized
statistical parsing model. In Dekang Lin and Dekai Wu, ed-
itors, Proceedings of the Conference on Empirical Methods
in Natural Language Processing. Barcelona, pages 182–189.
Bikel, Daniel M. and David Chiang. 2000. Two statistical pars-
ing models applied to the Chinese treebank. In Proceedings
of the 2nd ACL Workshop on Chinese Language Processing.
Hong Kong.
Charniak, Eugene. 2000. A maximum-entropy-inspired parser.
In Proceedings of the 1st Conference of the North American
Chapter of the Association for Computational Linguistics.
Seattle, WA, pages 132–139.
Collins, Michael. 1997. Three generative, lexicalised models
for statistical parsing. In Proceedings of the 35th Annual
Meeting of the Association for Computational Linguistics
and the 8th Conference of the European Chapter of the Asso-
ciation for Computational Linguistics. Madrid, pages 16–23.
Collins, Michael, Jan Hajiˇc, Lance Ramshaw, and Christoph
Tillmann. 1999. A statistical parser for Czech. In Pro-
ceedings of the 37th Annual Meeting of the Association for
Computational Linguistics. University of Maryland, College
Park.
Dubey, Amit and Frank Keller. 2003. Probabilistic parsing for
German using sister-head dependencies. In Proceedings of
the 41st Annual Meeting of the Association for Computa-
tional Linguistics. Sapporo, pages 96–103.
Giguet, Emmanuel and Jacques Vergne. 1997. From part-of-
speech tagging to memory-based deep syntactic analysis. In
Proceedings of the International Workshop on Parsing Tech-
nologies. Boston, pages 77–88.
Klein, Dan and Christopher Manning. 2003. Accurate unlexi-
calized parsing. In Proceedings of the 41st Annual Meeting
of the Association for Computational Linguistics. Sapporo.
Levy, Roger and Christopher Manning. 2003. Is it harder to
parse Chinese, or the Chinese treebank? In Proceedings of
the 41st Annual Meeting of the Association for Computa-
tional Linguistics. Sapporo.
Lin, Dekang. 1995. A dependency-based method for evaluating
broad-coverage parsers. In Proceedings of the International
Joint Conference on Artificial Intelligence. Montreal, pages
1420–1425.
Magerman, David. 1995. Statistical decision-tree models for
parsing. In Proceedings of the 33rd Annual Meeting of the
Association for Computational Linguistics. Cambridge, MA,
pages 276–283.
Marcus, Mitchell P., Beatrice Santorini, and Mary Ann
Marcinkiewicz. 1993. Building a large annotated corpus
of English: The Penn Treebank. Computational Linguistics
19(2):313–330.
Schiehlen, Michael. 2004. Annotation strategies for probabilis-
tic parsing in German. In Proceedings of the 20th Interna-
tional Conference on Computational Linguistics. Geneva.
Schmid, Helmut. 2004. Efficient parsing of highly ambiguous
context-free grammars with bit vectors. In Proceedings of
the 20th International Conference on Computational Lin-
guistics. Geneva.
Skut, Wojciech, Brigitte Krenn, Thorsten Brants, and Hans
Uszkoreit. 1997. An annotation scheme for free word order
languages. In Proceedings of the 5th Conference on Applied
Natural Language Processing. Washington, DC.
</reference>
<page confidence="0.999514">
313
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.692432">
<title confidence="0.997178">Lexicalization in Crosslinguistic Probabilistic Parsing: The Case of French</title>
<author confidence="0.742022">Arun Keller</author>
<affiliation confidence="0.999895">School of Informatics, University of Edinburgh</affiliation>
<address confidence="0.964704">2 Buccleuch Place, Edinburgh EH8 9LW, UK</address>
<abstract confidence="0.997840578947368">This paper presents the first probabilistic parsing results for French, using the recently released French Treebank. We start with an unlexicalized PCFG as a baseline model, which is enriched to the level of Collins’ Model 2 by adding lexicalization and subcategorization. The lexicalized sister-head model and a bigram model are also tested, to deal with the flatness of the French Treebank. The bigram model achieves the best performance: 81% constituency F-score and 84% dependency accuracy. All lexicalized models outperform the unlexicalized baseline, consistent with probabilistic parsing results for English, but contrary to results for German, where lexicalization has only a limited effect on parsing performance.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Anne Abeill´e</author>
<author>Lionel Clement</author>
<author>Alexandra Kinyon</author>
</authors>
<title>Building a treebank for French.</title>
<date>2000</date>
<booktitle>In Proceedings of the 2nd International Conference on Language Resources and Evaluation.</booktitle>
<location>Athens.</location>
<marker>Abeill´e, Clement, Kinyon, 2000</marker>
<rawString>Abeill´e, Anne, Lionel Clement, and Alexandra Kinyon. 2000. Building a treebank for French. In Proceedings of the 2nd International Conference on Language Resources and Evaluation. Athens.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel M Bikel</author>
</authors>
<title>Design of a multi-lingual, parallelprocessing statistical parsing engine.</title>
<date>2002</date>
<booktitle>In Proceedings of the 2nd International Conference on Human Language Technology Research.</booktitle>
<publisher>Morgan Kaufmann,</publisher>
<location>San Francisco.</location>
<contexts>
<context position="18884" citStr="Bikel, 2002" startWordPosition="3054" endWordPosition="3055"> to length mismatches in the test data. This problem occurs frequently in the test set, so that such an evaluation becomes pointless. 6 Experiment 2: Lexicalized Models 6.1 Method Parsing We now compare a series of lexicalized parsing models against the unlexicalized baseline established in the previous experiment. Our is was to test if French behaves like English in that lexicalization improves parsing performance, or like German, in that lexicalization has only a small effect on parsing performance. The lexicalized parsing experiments were run using Dan Bikel’s probabilistic parsing engine (Bikel, 2002) which in addition to replicating the models described by Collins (1997) also provides a convenient interface to develop corresponding parsing models for other languages. Lexicalization requires that each rule in a grammar has one of the categories on its right hand side annotated as the head. These head rules were constructed based on the FTB annotation guidelines (provided along with the dataset), as well as by using heuristics, and were optimized on the development set. Collins’ Model 2 incorporates a complement/adjunct distinction and probabilities over subcategorization frames. Complement</context>
</contexts>
<marker>Bikel, 2002</marker>
<rawString>Bikel, Daniel M. 2002. Design of a multi-lingual, parallelprocessing statistical parsing engine. In Proceedings of the 2nd International Conference on Human Language Technology Research. Morgan Kaufmann, San Francisco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel M Bikel</author>
</authors>
<title>A distributional analysis of a lexicalized statistical parsing model.</title>
<date>2004</date>
<booktitle>In Dekang Lin and Dekai Wu, editors, Proceedings of the Conference on Empirical Methods in Natural Language Processing.</booktitle>
<pages>182--189</pages>
<location>Barcelona,</location>
<contexts>
<context position="2243" citStr="Bikel (2004)" startWordPosition="334" endWordPosition="335">ypically manifests itself in a severe reduction in parsing performance compared to the results for English. A second recent strand in parsing research has dealt with the role of lexicalization. The conventional wisdom since Magerman (1995) has been that lexicalization substantially improves performance compared to an unlexicalized baseline model (e.g., a probabilistic context-free grammar, PCFG). However, this has been challenged by Klein and Manning (2003), who demonstrate that an unlexicalized model can achieve a performance close to the state of the art for lexicalized models. Furthermore, Bikel (2004) provides evidence that lexical information (in the form of bi-lexical dependencies) only makes a small contribution to the performance of parsing models such as Collins’s (1997). The only previous authors that have directly addressed the role of lexicalization in crosslinguistic parsing are Dubey and Keller (2003). They show that standard lexicalized models fail to outperform an unlexicalized baseline (a vanilla PCFG) on Negra, a German treebank (Skut et al., 1997). They attribute this result to two facts: (a) The Negra annotation assumes very flat trees, which means that Collins-style head-l</context>
</contexts>
<marker>Bikel, 2004</marker>
<rawString>Bikel, Daniel M. 2004. A distributional analysis of a lexicalized statistical parsing model. In Dekang Lin and Dekai Wu, editors, Proceedings of the Conference on Empirical Methods in Natural Language Processing. Barcelona, pages 182–189.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel M Bikel</author>
<author>David Chiang</author>
</authors>
<title>Two statistical parsing models applied to the Chinese treebank.</title>
<date>2000</date>
<booktitle>In Proceedings of the 2nd ACL Workshop on Chinese Language Processing. Hong Kong.</booktitle>
<contexts>
<context position="1312" citStr="Bikel and Chiang, 2000" startWordPosition="191" endWordPosition="194">onstituency F-score and 84% dependency accuracy. All lexicalized models outperform the unlexicalized baseline, consistent with probabilistic parsing results for English, but contrary to results for German, where lexicalization has only a limited effect on parsing performance. 1 Introduction This paper brings together two strands of research that have recently emerged in the field of probabilistic parsing: crosslinguistic parsing and lexicalized parsing. Interest in parsing models for languages other than English has been growing, starting with work on Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000; Levy and Manning, 2003). Probabilistic parsing for German has also been explored by a range of authors (Dubey and Keller, 2003; Schiehlen, 2004). In general, these authors have found that existing lexicalized parsing models for English (e.g., Collins 1997) do not straightforwardly generalize to new languages; this typically manifests itself in a severe reduction in parsing performance compared to the results for English. A second recent strand in parsing research has dealt with the role of lexicalization. The conventional wisdom since Magerman (1995) has been that lexicalization substantiall</context>
</contexts>
<marker>Bikel, Chiang, 2000</marker>
<rawString>Bikel, Daniel M. and David Chiang. 2000. Two statistical parsing models applied to the Chinese treebank. In Proceedings of the 2nd ACL Workshop on Chinese Language Processing. Hong Kong.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
</authors>
<title>A maximum-entropy-inspired parser.</title>
<date>2000</date>
<booktitle>In Proceedings of the 1st Conference of the North American Chapter of the Association for Computational Linguistics.</booktitle>
<pages>132--139</pages>
<location>Seattle, WA,</location>
<contexts>
<context position="24943" citStr="Charniak (2000)" startWordPosition="4060" endWordPosition="4061">ntions, some of the benefits of Model 2 are already captured by inclusion of the distance measure. A further small improvement was achieved using Dubey and Keller’s (2003) sister-head model; however, again the difference did not reach statistical significance. The bigram model, however, yielded a statistically significant improvement over Collins’ Model 1 (recall χ2 = 3.91, df = 1, p:5.048; precision χ2 = 3.97, df = 1, p:5 .046). This is consistent with the findings of Collins et al. (1999) for Czech, where the bigram model upped dependency accuracy by about 0.9%, as well as for English where Charniak (2000) reports an increase in F-score of approximately 0.3%. The BigramFlat model, which applies the bigram model to only those labels which have a high degree of flatness, performs Model LR LP CBs 0CB &lt;2CB Tag Cov Exp+CR 65.50 64.76 1.49 42.36 77.48 100.0 97.83 Cont+CR 69.35 67.93 1.34 47.43 80.25 100.0 96.97 Model1 81.51 81.43 0.78 64.60 89.25 98.54 99.78 Model2 81.69 81.59 0.78 63.84 89.69 98.55 99.78 SisterHead 81.08 81.56 0.79 64.35 89.57 98.51 99.57 Bigram 81.78 81.91 0.78 64.96 89.12 98.81 99.67 BigramFlat 81.14 81.19 0.81 63.37 88.80 98.80 99.67 Table 4: Results for lexicalized and unlexical</context>
</contexts>
<marker>Charniak, 2000</marker>
<rawString>Charniak, Eugene. 2000. A maximum-entropy-inspired parser. In Proceedings of the 1st Conference of the North American Chapter of the Association for Computational Linguistics. Seattle, WA, pages 132–139.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Three generative, lexicalised models for statistical parsing.</title>
<date>1997</date>
<booktitle>In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics and the 8th Conference of the European Chapter of the Association for Computational Linguistics.</booktitle>
<pages>16--23</pages>
<location>Madrid,</location>
<contexts>
<context position="1570" citStr="Collins 1997" startWordPosition="233" endWordPosition="234">formance. 1 Introduction This paper brings together two strands of research that have recently emerged in the field of probabilistic parsing: crosslinguistic parsing and lexicalized parsing. Interest in parsing models for languages other than English has been growing, starting with work on Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000; Levy and Manning, 2003). Probabilistic parsing for German has also been explored by a range of authors (Dubey and Keller, 2003; Schiehlen, 2004). In general, these authors have found that existing lexicalized parsing models for English (e.g., Collins 1997) do not straightforwardly generalize to new languages; this typically manifests itself in a severe reduction in parsing performance compared to the results for English. A second recent strand in parsing research has dealt with the role of lexicalization. The conventional wisdom since Magerman (1995) has been that lexicalization substantially improves performance compared to an unlexicalized baseline model (e.g., a probabilistic context-free grammar, PCFG). However, this has been challenged by Klein and Manning (2003), who demonstrate that an unlexicalized model can achieve a performance close </context>
<context position="18956" citStr="Collins (1997)" startWordPosition="3065" endWordPosition="3066"> in the test set, so that such an evaluation becomes pointless. 6 Experiment 2: Lexicalized Models 6.1 Method Parsing We now compare a series of lexicalized parsing models against the unlexicalized baseline established in the previous experiment. Our is was to test if French behaves like English in that lexicalization improves parsing performance, or like German, in that lexicalization has only a small effect on parsing performance. The lexicalized parsing experiments were run using Dan Bikel’s probabilistic parsing engine (Bikel, 2002) which in addition to replicating the models described by Collins (1997) also provides a convenient interface to develop corresponding parsing models for other languages. Lexicalization requires that each rule in a grammar has one of the categories on its right hand side annotated as the head. These head rules were constructed based on the FTB annotation guidelines (provided along with the dataset), as well as by using heuristics, and were optimized on the development set. Collins’ Model 2 incorporates a complement/adjunct distinction and probabilities over subcategorization frames. Complements were marked in the training phase based on argument identification rul</context>
<context position="24325" citStr="Collins (1997)" startWordPosition="3955" endWordPosition="3956"> Table 3 shows that all lexicalized models achieve a performance of around 80% recall and precision, i.e., they outperform the best unlexicalized model by at least 14% (see Table 1). This is consistent with what has been reported for English on the PTB. Collins’ Model 2, which adds the complement/adjunct distinction and subcategorization frames achieved only a very small improvement over Collins’ Model 1, which was not statistically significant using a χ2 test. It might well be that the annotation scheme of the FTB does not lend itself particularly well to the demands of Model 2. Moreover, as Collins (1997) mentions, some of the benefits of Model 2 are already captured by inclusion of the distance measure. A further small improvement was achieved using Dubey and Keller’s (2003) sister-head model; however, again the difference did not reach statistical significance. The bigram model, however, yielded a statistically significant improvement over Collins’ Model 1 (recall χ2 = 3.91, df = 1, p:5.048; precision χ2 = 3.97, df = 1, p:5 .046). This is consistent with the findings of Collins et al. (1999) for Czech, where the bigram model upped dependency accuracy by about 0.9%, as well as for English whe</context>
<context position="33337" citStr="Collins, 1997" startWordPosition="5450" endWordPosition="5451">at around 80% LR and LP. No significant improvement could be achieved by switching to Dubey and Keller’s (2003) sister-head model, which has been claimed to be particularly suitable for treebanks with flat annotation, such as the FTB. A small but significant improvement (to 81% LR and LP) was obtained by a bigram model that combines features of the sister-head model and Collins’ model. These results have important implications for crosslinguistic parsing research, as they allow us to tease apart language-specific and annotationspecific effects. Previous work for English (e.g., Magerman, 1995; Collins, 1997) has shown that lexicalization leads to a sizable improvement in parsing performance. English is a language with nonflexible word order and with a treebank with a nonflat annotation scheme (see Table 2). Research on German (Dubey and Keller, 2003) showed that lexicalization leads to no sizable improvement in parsing performance for this language. German has a flexible word order and a flat treebank annotation, both of which could be responsible for this counterintuitive effect. The results for French presented in this paper provide the missing piece of evidence: they show that French behaves l</context>
</contexts>
<marker>Collins, 1997</marker>
<rawString>Collins, Michael. 1997. Three generative, lexicalised models for statistical parsing. In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics and the 8th Conference of the European Chapter of the Association for Computational Linguistics. Madrid, pages 16–23.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Jan Hajiˇc</author>
<author>Lance Ramshaw</author>
<author>Christoph Tillmann</author>
</authors>
<title>A statistical parser for Czech.</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th Annual Meeting of the Association</booktitle>
<institution>for Computational Linguistics. University of Maryland, College Park.</institution>
<marker>Collins, Hajiˇc, Ramshaw, Tillmann, 1999</marker>
<rawString>Collins, Michael, Jan Hajiˇc, Lance Ramshaw, and Christoph Tillmann. 1999. A statistical parser for Czech. In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics. University of Maryland, College Park.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amit Dubey</author>
<author>Frank Keller</author>
</authors>
<title>Probabilistic parsing for German using sister-head dependencies.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics. Sapporo,</booktitle>
<pages>96--103</pages>
<contexts>
<context position="1440" citStr="Dubey and Keller, 2003" startWordPosition="213" endWordPosition="216">robabilistic parsing results for English, but contrary to results for German, where lexicalization has only a limited effect on parsing performance. 1 Introduction This paper brings together two strands of research that have recently emerged in the field of probabilistic parsing: crosslinguistic parsing and lexicalized parsing. Interest in parsing models for languages other than English has been growing, starting with work on Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000; Levy and Manning, 2003). Probabilistic parsing for German has also been explored by a range of authors (Dubey and Keller, 2003; Schiehlen, 2004). In general, these authors have found that existing lexicalized parsing models for English (e.g., Collins 1997) do not straightforwardly generalize to new languages; this typically manifests itself in a severe reduction in parsing performance compared to the results for English. A second recent strand in parsing research has dealt with the role of lexicalization. The conventional wisdom since Magerman (1995) has been that lexicalization substantially improves performance compared to an unlexicalized baseline model (e.g., a probabilistic context-free grammar, PCFG). However, </context>
<context position="10409" citStr="Dubey and Keller 2003" startWordPosition="1687" endWordPosition="1690"> differentiates between commas, periods, brackets, etc. Compounds have internal structure in the FTB (see Section 2.1). We created two separate data sets by applying two alternative tree transformation to make FTB compounds more similar to compounds in other annotation schemes. The first was collapsing the compound by concatenating the compound parts using an underscore and picking up the cat information supplied at the compound level. For example, the compound in Figure 2 results in: (4) (P d’ entre) This approach is similar to the treatment of compounds in the German Negra treebank (used by Dubey and Keller 2003), where compounds are not given any internal structure (compounds are mostly spelled without spaces or apostrophes in German). The second approach is expanding the compound. Here, the compound parts are treated as individual words with their own POS (from the catint tag), and the suffix Cmp is appended the POS of the compound, effectively expanding the tagset.2 Now Figure 2 yields: (5) (PCmp (P d’) (P entre)). This approach is similar to the treatment of compounds in the PTB (except hat the PTB does not use a separate tag for the mother category). We found that in the FTB the POS tag of the co</context>
<context position="12390" citStr="Dubey and Keller (2003)" startWordPosition="2010" endWordPosition="2013">erefore created additional datasets where a transformation is applied that raises coordination. This is illustrated in Figure 3. Note that in the FTB annotation scheme, a coordinating conjunction is always followed by a syntactic category. Hence the resulting tree, though flatter, is still not fully compatible with the PTB treatment of coordination. 4 Probabilistic Parsing Models 4.1 Probabilistic Context-Free Grammars The aim of this paper is to further explore the crosslinguistic role of lexicalization by applying lexicalized parsing models to the French Treebank parsing accuracy. Following Dubey and Keller (2003), we use a standard unlexicalized PCFG as our baseline. In such a model, each context-free rule RHS —* LHS is annotated with an expansion probability P(RHS|LHS). The probabilities for all the rules with the same left-hand side have to sum up to one and the probability of a parse tree T is defined as the product of the probabilities of each rule applied in the generation of T. 4.2 Collins’ Head-Lexicalized Models A number of lexicalized models can then be applied to the FTB, comparing their performance to the unlexicalized baseline. We start with Collins’ Model 1, which lexicalizes a PCFG by as</context>
<context position="20934" citStr="Dubey and Keller, 2003" startWordPosition="3398" endWordPosition="3401">rage vs. parsing speed trade-off. Label FTB PTB Negra Label FTB PTB Negra SENT 5.84 2.22 4.55 VPpart 2.51 – – Ssub 4.41 – – VN 1.76 – – Sint 3.44 – – PP 2.10 2.03 3.08 Srel 3.92 – – NP 2.45 2.20 3.08 VP – 2.32 2.59 AdvP 2.24 – 2.08 VPinf 3.07 – – AP 1.34 – 2.22 Table 2: Average number of daughter nodes per constituents in three treebanks Flatness As already pointed out in Section 2.1, the FTB uses a flat annotation scheme. This can be quantified by computing the average number of daughters for each syntactic category in the FTB, and comparing them with the figures available for PTB and Negra (Dubey and Keller, 2003). This is done in Table 2. The absence of sentence-internal VPs explains the very high level of flatness for the sentential category SENT (5.84 daughters), compared to the PTB (2.44), and even to Negra, which is also very flat (4.55 daughters). The other sentential categories Ssub (subordinate clauses), Srel (relative clause), and Sint (interrogative clause) are also very flat. Note that the FTB uses VP nodes only for nonfinite subordinate clauses: VPinf (infinitival clause) and VPpart (participle clause); these categories are roughly comparable in flatness to the VP category in the PTB and Ne</context>
<context position="28818" citStr="Dubey and Keller (2003)" startWordPosition="4687" endWordPosition="4690">FTB, a gain of 11% in dependency accuracy is observed for the lexicalized model. 7 Experiment 3: Crosslinguistic Comparison The results reported in Experiments 1 and 2 shed some light on the role of lexicalization for parsing French, but they are not strictly comparable to the results that have been reported for other languages. This is because the treebanks available for different languages typically vary considerably in size: our FTB training set was about 8,500 sentences large, while the standard training set for the PTB is about 40,000 sentences in size, and the Negra training set used by Dubey and Keller (2003) comprises about 18,600 sentences. This means that the differences in the effect of lexicalization that we observe could be simply due to the size of the training set: lexicalized models are more susceptible to data sparseness than unlexicalized ones. We therefore conducted another experiment in which we applied Collins’ Model 2 to subsets of the PTB that were comparable in size to our FTB data sets. We combined sections 02–05 and 08 of the PTB (8,345 sentences in total) to form the training set, and the first 1,000 sentences of section 23 to form our test set. As a baseline model, we also run</context>
<context position="30929" citStr="Dubey and Keller (2003)" startWordPosition="5064" endWordPosition="5067">9.64 67.27 1.12 54.21 82.84 Model 1 68.33 67.32 0.83 60.43 88.78 Table 6: The effect of lexicalization on different corpora for training sets of comparable size (sentences ≤40 words) lexicalization is stable even if the size of the training set is held constant across languages: For the FTB we find that lexicalization increases F-score by around 13%. Also for the PTB, we find an effect of lexicalization of about 14%. For the German Negra treebank, however, the performance of the lexicalized and the unlexicalized model are almost indistinguishable. (This is true for Collins’ Model 1; note that Dubey and Keller (2003) do report a small improvement for the lexicalized sister-head model.) 8 Related Work We are not aware of any previous attempts to build a probabilistic, treebank-trained parser for French. However, there is work on chunking for French. The group who built the French Treebank (Abeill´e et al., 2000) used a rule-based chunker to automatically annotate the corpus with syntactic structures, which were then manually corrected. They report an unlabeled recall/precision of 94.3/94.2% for opening brackets and 92.2/91.4% for closing brackets, and a label accuracy of 95.6%. This result is not comparabl</context>
<context position="33584" citStr="Dubey and Keller, 2003" startWordPosition="5491" endWordPosition="5494">mall but significant improvement (to 81% LR and LP) was obtained by a bigram model that combines features of the sister-head model and Collins’ model. These results have important implications for crosslinguistic parsing research, as they allow us to tease apart language-specific and annotationspecific effects. Previous work for English (e.g., Magerman, 1995; Collins, 1997) has shown that lexicalization leads to a sizable improvement in parsing performance. English is a language with nonflexible word order and with a treebank with a nonflat annotation scheme (see Table 2). Research on German (Dubey and Keller, 2003) showed that lexicalization leads to no sizable improvement in parsing performance for this language. German has a flexible word order and a flat treebank annotation, both of which could be responsible for this counterintuitive effect. The results for French presented in this paper provide the missing piece of evidence: they show that French behaves like English in that it shows a large effect of lexicalization. Like English, French is a language with non-flexible word order, but like the German Treebank, the French Treebank has a flat annotation. We conclude that Dubey and Keller’s (2003) res</context>
</contexts>
<marker>Dubey, Keller, 2003</marker>
<rawString>Dubey, Amit and Frank Keller. 2003. Probabilistic parsing for German using sister-head dependencies. In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics. Sapporo, pages 96–103.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emmanuel Giguet</author>
<author>Jacques Vergne</author>
</authors>
<title>From part-ofspeech tagging to memory-based deep syntactic analysis.</title>
<date>1997</date>
<booktitle>In Proceedings of the International Workshop on Parsing Technologies.</booktitle>
<pages>77--88</pages>
<location>Boston,</location>
<contexts>
<context position="31588" citStr="Giguet and Vergne (1997)" startWordPosition="5168" endWordPosition="5171">the lexicalized sister-head model.) 8 Related Work We are not aware of any previous attempts to build a probabilistic, treebank-trained parser for French. However, there is work on chunking for French. The group who built the French Treebank (Abeill´e et al., 2000) used a rule-based chunker to automatically annotate the corpus with syntactic structures, which were then manually corrected. They report an unlabeled recall/precision of 94.3/94.2% for opening brackets and 92.2/91.4% for closing brackets, and a label accuracy of 95.6%. This result is not comparable to our results for full parsing. Giguet and Vergne (1997) present use a memorybased learner to predict chunks and dependencies between chunks. The system is evaluated on texts from Le Monde (different from the FTB texts). Results are only reported for verb-object dependencies, for which recall/precision is 94.04/96.39%. Again, these results are not comparable to ours, which were obtained using a different corpus, a different dependency scheme, and for a full set of dependencies. 9 Conclusions In this paper, we provided the first probabilistic, treebank-trained parser for French. In Experiment 1, we established an unlexicalized baseline model, which </context>
</contexts>
<marker>Giguet, Vergne, 1997</marker>
<rawString>Giguet, Emmanuel and Jacques Vergne. 1997. From part-ofspeech tagging to memory-based deep syntactic analysis. In Proceedings of the International Workshop on Parsing Technologies. Boston, pages 77–88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher Manning</author>
</authors>
<title>Accurate unlexicalized parsing.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics.</booktitle>
<location>Sapporo.</location>
<contexts>
<context position="2092" citStr="Klein and Manning (2003)" startWordPosition="308" endWordPosition="312">al, these authors have found that existing lexicalized parsing models for English (e.g., Collins 1997) do not straightforwardly generalize to new languages; this typically manifests itself in a severe reduction in parsing performance compared to the results for English. A second recent strand in parsing research has dealt with the role of lexicalization. The conventional wisdom since Magerman (1995) has been that lexicalization substantially improves performance compared to an unlexicalized baseline model (e.g., a probabilistic context-free grammar, PCFG). However, this has been challenged by Klein and Manning (2003), who demonstrate that an unlexicalized model can achieve a performance close to the state of the art for lexicalized models. Furthermore, Bikel (2004) provides evidence that lexical information (in the form of bi-lexical dependencies) only makes a small contribution to the performance of parsing models such as Collins’s (1997). The only previous authors that have directly addressed the role of lexicalization in crosslinguistic parsing are Dubey and Keller (2003). They show that standard lexicalized models fail to outperform an unlexicalized baseline (a vanilla PCFG) on Negra, a German treeban</context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Klein, Dan and Christopher Manning. 2003. Accurate unlexicalized parsing. In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics. Sapporo.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roger Levy</author>
<author>Christopher Manning</author>
</authors>
<title>Is it harder to parse Chinese, or the Chinese treebank?</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics.</booktitle>
<location>Sapporo.</location>
<contexts>
<context position="1337" citStr="Levy and Manning, 2003" startWordPosition="195" endWordPosition="198">84% dependency accuracy. All lexicalized models outperform the unlexicalized baseline, consistent with probabilistic parsing results for English, but contrary to results for German, where lexicalization has only a limited effect on parsing performance. 1 Introduction This paper brings together two strands of research that have recently emerged in the field of probabilistic parsing: crosslinguistic parsing and lexicalized parsing. Interest in parsing models for languages other than English has been growing, starting with work on Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000; Levy and Manning, 2003). Probabilistic parsing for German has also been explored by a range of authors (Dubey and Keller, 2003; Schiehlen, 2004). In general, these authors have found that existing lexicalized parsing models for English (e.g., Collins 1997) do not straightforwardly generalize to new languages; this typically manifests itself in a severe reduction in parsing performance compared to the results for English. A second recent strand in parsing research has dealt with the role of lexicalization. The conventional wisdom since Magerman (1995) has been that lexicalization substantially improves performance co</context>
</contexts>
<marker>Levy, Manning, 2003</marker>
<rawString>Levy, Roger and Christopher Manning. 2003. Is it harder to parse Chinese, or the Chinese treebank? In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics. Sapporo.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>A dependency-based method for evaluating broad-coverage parsers.</title>
<date>1995</date>
<booktitle>In Proceedings of the International Joint Conference on Artificial Intelligence.</booktitle>
<pages>1420--1425</pages>
<location>Montreal,</location>
<contexts>
<context position="26904" citStr="Lin (1995)" startWordPosition="4382" endWordPosition="4383">ng increased parsing performance in the lexicalized models by around 3%. This shows that the poor POS tagging performed by BitPar is one of the reasons of the poor performance of the lexicalized models. The impact of perfect tagging is less drastic on the lexicalized models (around 1% increase). However, our main finding, viz., that lexicalized models outperform unlexicalized models considerable on the FTB, remains valid, even with perfect tagging.3 Dependency Evaluation We also evaluated our models using dependency measures, which have been argued to be more annotation-neutral than Parseval. Lin (1995) notes that labeled bracketing scores are more susceptible to cascading errors, where one incorrect attachment decision causes the scoring algorithm to count more than one error. The gold standard and parsed trees were converted into dependency trees using the algorithm described by Lin (1995). Dependency accuracy is defined as the ratio of correct dependencies over the total number of dependencies in a sentence. (Note that this is an unlabeled dependency measure.) Dependency accuracy and constituency F-score are shown 3It is important to note that the Collins model has a range of other featur</context>
</contexts>
<marker>Lin, 1995</marker>
<rawString>Lin, Dekang. 1995. A dependency-based method for evaluating broad-coverage parsers. In Proceedings of the International Joint Conference on Artificial Intelligence. Montreal, pages 1420–1425.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Magerman</author>
</authors>
<title>Statistical decision-tree models for parsing.</title>
<date>1995</date>
<booktitle>In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics.</booktitle>
<pages>276--283</pages>
<location>Cambridge, MA,</location>
<contexts>
<context position="1870" citStr="Magerman (1995)" startWordPosition="280" endWordPosition="281">Collins et al., 1999) and Chinese (Bikel and Chiang, 2000; Levy and Manning, 2003). Probabilistic parsing for German has also been explored by a range of authors (Dubey and Keller, 2003; Schiehlen, 2004). In general, these authors have found that existing lexicalized parsing models for English (e.g., Collins 1997) do not straightforwardly generalize to new languages; this typically manifests itself in a severe reduction in parsing performance compared to the results for English. A second recent strand in parsing research has dealt with the role of lexicalization. The conventional wisdom since Magerman (1995) has been that lexicalization substantially improves performance compared to an unlexicalized baseline model (e.g., a probabilistic context-free grammar, PCFG). However, this has been challenged by Klein and Manning (2003), who demonstrate that an unlexicalized model can achieve a performance close to the state of the art for lexicalized models. Furthermore, Bikel (2004) provides evidence that lexical information (in the form of bi-lexical dependencies) only makes a small contribution to the performance of parsing models such as Collins’s (1997). The only previous authors that have directly ad</context>
<context position="33321" citStr="Magerman, 1995" startWordPosition="5448" endWordPosition="5449">and 2 performed at around 80% LR and LP. No significant improvement could be achieved by switching to Dubey and Keller’s (2003) sister-head model, which has been claimed to be particularly suitable for treebanks with flat annotation, such as the FTB. A small but significant improvement (to 81% LR and LP) was obtained by a bigram model that combines features of the sister-head model and Collins’ model. These results have important implications for crosslinguistic parsing research, as they allow us to tease apart language-specific and annotationspecific effects. Previous work for English (e.g., Magerman, 1995; Collins, 1997) has shown that lexicalization leads to a sizable improvement in parsing performance. English is a language with nonflexible word order and with a treebank with a nonflat annotation scheme (see Table 2). Research on German (Dubey and Keller, 2003) showed that lexicalization leads to no sizable improvement in parsing performance for this language. German has a flexible word order and a flat treebank annotation, both of which could be responsible for this counterintuitive effect. The results for French presented in this paper provide the missing piece of evidence: they show that </context>
</contexts>
<marker>Magerman, 1995</marker>
<rawString>Magerman, David. 1995. Statistical decision-tree models for parsing. In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics. Cambridge, MA, pages 276–283.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Beatrice Santorini</author>
<author>Mary Ann Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of English: The Penn Treebank.</title>
<date>1993</date>
<journal>Computational Linguistics</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="5503" citStr="Marcus et al. 1993" startWordPosition="847" endWordPosition="850">son involving data sets of the same size extracted from the French, English, and German treebanks. 2 The French Treebank 2.1 Annotation Scheme The French Treebank (FTB; Abeill´e et al. 2000) consists of 20,648 sentences extracted from the daily newspaper Le Monde, covering a variety of authors and domains (economy, literature, politics, etc.).&apos; The corpus is formatted in XML and has a rich morphosyntactic tagset that includes part-of-speech tag, ‘subcategorization’ (e.g., possessive or cardinal), inflection (e.g., masculine singular), and lemma information. Compared to the Penn Treebank (PTB; Marcus et al. 1993), the POS tagset of the French Treebank is smaller (13 tags vs. 36 tags): all punctuation marks are represented as the single PONCT tag, there are no separate tags for modal verbs, whwords, and possessives. Also verbs, adverbs and prepositions are more coarsely defined. On the other hand, a separate clitic tag (CL) for weak pronouns is introduced. An example for the word-level annotation in the FTB is given in Figure 1 The phrasal annotation of the FTB differs from that for the Penn Treebank in several aspects. There is no verb phrase: only the verbal nucleus (VN) is annotated. A VN comprises </context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>Marcus, Mitchell P., Beatrice Santorini, and Mary Ann Marcinkiewicz. 1993. Building a large annotated corpus of English: The Penn Treebank. Computational Linguistics 19(2):313–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Schiehlen</author>
</authors>
<title>Annotation strategies for probabilistic parsing in German.</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th International Conference on Computational Linguistics.</booktitle>
<location>Geneva.</location>
<contexts>
<context position="1458" citStr="Schiehlen, 2004" startWordPosition="217" endWordPosition="218">ults for English, but contrary to results for German, where lexicalization has only a limited effect on parsing performance. 1 Introduction This paper brings together two strands of research that have recently emerged in the field of probabilistic parsing: crosslinguistic parsing and lexicalized parsing. Interest in parsing models for languages other than English has been growing, starting with work on Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000; Levy and Manning, 2003). Probabilistic parsing for German has also been explored by a range of authors (Dubey and Keller, 2003; Schiehlen, 2004). In general, these authors have found that existing lexicalized parsing models for English (e.g., Collins 1997) do not straightforwardly generalize to new languages; this typically manifests itself in a severe reduction in parsing performance compared to the results for English. A second recent strand in parsing research has dealt with the role of lexicalization. The conventional wisdom since Magerman (1995) has been that lexicalization substantially improves performance compared to an unlexicalized baseline model (e.g., a probabilistic context-free grammar, PCFG). However, this has been chal</context>
</contexts>
<marker>Schiehlen, 2004</marker>
<rawString>Schiehlen, Michael. 2004. Annotation strategies for probabilistic parsing in German. In Proceedings of the 20th International Conference on Computational Linguistics. Geneva.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
</authors>
<title>Efficient parsing of highly ambiguous context-free grammars with bit vectors.</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th International Conference on Computational Linguistics.</booktitle>
<location>Geneva.</location>
<contexts>
<context position="15465" citStr="Schmid, 2004" startWordPosition="2504" endWordPosition="2505"> requires in its left or right sister. The subcat requirements are added to the conditioning context. As complements are generated, they are removed from the appropriate subcat multiset. 5 Experiment 1: Unlexicalized Model 5.1 Method This experiment was designed to compare the performance of the unlexicalized baseline model on four different datasets, created by the tree transformations described in Section 3: compounds expanded (Exp), compounds contracted (Cont), compounds expanded with coordination raised (Exp+CR), and compounds contracted with coordination raised (Cont+CR). We used BitPar (Schmid, 2004) for our unlexicalized experiments. BitPar is a parser based on a bit-vector implementation of the CKY algorithm. A grammar and lexicon were read off our training set, along with rule frequencies and frequencies for lexical items, based on which BitPar computes the rule Model LR LP CBs 0CB &lt;2CB Tag Cov Exp 59.97 58.64 1.74 39.05 73.23 91.00 99.20 Exp+CR 60.75 60.57 1.57 40.77 75.03 91.08 99.09 Cont 64.19 64.61 1.50 46.74 76.80 93.30 98.48 Cont+CR 66.11 65.55 1.39 46.99 78.95 93.22 97.94 Table 1: Results for unlexicalized models (sentences &lt;40 words); each model performed its own POS tagging. p</context>
</contexts>
<marker>Schmid, 2004</marker>
<rawString>Schmid, Helmut. 2004. Efficient parsing of highly ambiguous context-free grammars with bit vectors. In Proceedings of the 20th International Conference on Computational Linguistics. Geneva.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wojciech Skut</author>
<author>Brigitte Krenn</author>
<author>Thorsten Brants</author>
<author>Hans Uszkoreit</author>
</authors>
<title>An annotation scheme for free word order languages.</title>
<date>1997</date>
<booktitle>In Proceedings of the 5th Conference on Applied Natural Language Processing.</booktitle>
<location>Washington, DC.</location>
<contexts>
<context position="2713" citStr="Skut et al., 1997" startWordPosition="404" endWordPosition="407">ho demonstrate that an unlexicalized model can achieve a performance close to the state of the art for lexicalized models. Furthermore, Bikel (2004) provides evidence that lexical information (in the form of bi-lexical dependencies) only makes a small contribution to the performance of parsing models such as Collins’s (1997). The only previous authors that have directly addressed the role of lexicalization in crosslinguistic parsing are Dubey and Keller (2003). They show that standard lexicalized models fail to outperform an unlexicalized baseline (a vanilla PCFG) on Negra, a German treebank (Skut et al., 1997). They attribute this result to two facts: (a) The Negra annotation assumes very flat trees, which means that Collins-style head-lexicalization fails to pick up the relevant information from non-head nodes. (b) German allows flexible word order, which means that standard parsing models based on context free grammars perform poorly, as they fail to generalize over different positions of the same constituent. As it stands, Dubey and Keller’s (2003) work does not tell us whether treebank flatness or word order flexibility is responsible for their results: for English, the annotation scheme is non</context>
</contexts>
<marker>Skut, Krenn, Brants, Uszkoreit, 1997</marker>
<rawString>Skut, Wojciech, Brigitte Krenn, Thorsten Brants, and Hans Uszkoreit. 1997. An annotation scheme for free word order languages. In Proceedings of the 5th Conference on Applied Natural Language Processing. Washington, DC.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>