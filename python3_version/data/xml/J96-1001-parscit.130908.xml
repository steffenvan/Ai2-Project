<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9544525">
Translating Collocations for Bilingual
Lexicons: A Statistical Approach
</title>
<author confidence="0.999258">
Frank Smadja* Kathleen R. McKeownt
</author>
<affiliation confidence="0.991771">
NetPatrol Consulting Columbia University
</affiliation>
<author confidence="0.945035">
Vasileios Ha tzivassiloglout
</author>
<affiliation confidence="0.937825">
Columbia University
</affiliation>
<bodyText confidence="0.9825895">
Collocations are notoriously difficult for non-native speakers to translate, primarily because they
are opaque and cannot be translated on a word-by-word basis. We describe a program named
Champollion which, given a pair of parallel corpora in two different languages and a list of
collocations in one of them, automatically produces their translations. Our goal is to provide a tool
for compiling bilingual lexical information above the word level in multiple languages, for different
domains. The algorithm we use is based on statistical methods and produces p-word translations of
n-word collocations in which n and p need not be the same. For example, Champollion translates
make . . . decision, employment equity, and stock market into prendre . . . decision, equite
en matiere d&apos;emploi, and bourse respectively. Testing Champollion on three years&apos; worth of
the Hansards corpus yielded the French translations of 300 collocations for each year, evaluated at
73% accuracy on average. In this paper, we describe the statistical measures used, the algorithm,
and the implementation of Champollion, presenting our results and evaluation.
</bodyText>
<sectionHeader confidence="0.992137" genericHeader="abstract">
1. Introduction
</sectionHeader>
<bodyText confidence="0.998564625">
Hieroglyphics remained undeciphered for centuries until the discovery of the Rosetta
stone in the beginning of the 19th century in Rosetta, Egypt. The Rosetta stone is a
tablet of black basalt containing parallel inscriptions in three different scripts: Greek
and two forms of ancient Egyptian writings (demotic and hieroglyphics). Jean-Francois
Champollion, a linguist and Egyptologist, made the assumption that these inscriptions
were parallel and managed after several years of research to decipher the hieroglyphic
inscriptions. He used his work on the Rosetta stone as a basis from which to produce
the first comprehensive hieroglyphics dictionary (Budge 1989).
In this paper, we describe a modern version of a similar approach: given a large
corpus in two languages, our system produces translations of common word pairs
and phrases that can form the basis of a bilingual lexicon. Our focus is on the use of
statistical methods for the translation of multiword expressions, such as collocations
which are often idiomatic in nature. Published translations of such collocations are not
readily available, even for languages such as French and English, despite the fact that
collocations have been recognized as one of the main obstacles to second language
acquisition (Leed and Nakhimovsky 1979).
</bodyText>
<note confidence="0.318692">
* The work reported in this paper was done while the author was at Columbia University. His current
</note>
<affiliation confidence="0.8522255">
address is NetPatrol Consulting, Tel Maneh 6, Haifa 34363, Israel. E-mail: smadj a@netvision . net .
t Department of Computer Science, 450 Computer Science Building, Columbia University, New York, NY
</affiliation>
<page confidence="0.411139">
10027, USA. E-mail: kathy@cs. columbia. edu, vh@cs.columbia.edu.
</page>
<note confidence="0.8567035">
C) 1996 Association for Computational Linguistics
Computational Linguistics Volume 22, Number 1
</note>
<bodyText confidence="0.999982209302325">
We have developed a program named Champollion1 , which, given a sentence-
aligned parallel bilingual corpus, translates collocations (or individual words) in the
source language into collocations (or individual words) in the target language. The
aligned corpus is used as a reference, or database corpus, and represents Champol-
lion&apos; s knowledge of both languages. Champollion uses statistical methods to incremen-
tally construct the collocation translation, adding one word at a time. As a correlation
measure, Champollion uses the Dice coefficient (Dice 1945; Sorensen 1948) commonly
used in information retrieval (Salton and McGill 1983; Frakes and Baeza-Yates 1992).
For a given source language collocation, Champollion identifies individual words in the
target language that are highly correlated with the source collocation, thus producing
a set of words in the target language. These words are then combined in a systematic,
iterative manner to produce a translation of the source language collocation. Cham-
pollion considers all pairs of these words and identifies any that are highly correlated
with the source collocation. Next, triplets are produced by adding a highly correlated
word to a highly correlated pair, and the triplets that are highly correlated with the
source language collocation are passed to the next stage. This process is repeated until
no more highly correlated combinations of words can be found. Champollion selects
the group of words with the highest cardinality and correlation factor as the target
collocation. Finally, it produces the correct word ordering of the target collocation by
examining samples in the corpus. If word order is variable in the target collocation,
Champollion labels it flexible (for example, to take steps to can appear as took immediate
steps to, steps were taken to, etc.); otherwise, the correct word order is reported and the
collocation is labeled rigid.
To evaluate Champollion, we used a collocation compiler, XTRACT (Smadja 1993),
to automatically produce several lists of source (English) collocations. These source
collocations contain both flexible word pairs, which can be separated by an arbitrary
number of words, and fixed constituents, such as compound noun phrases. Using
XTRACT on three parts of the English data in the Hansards corpus, each representing
one year&apos;s worth of data, we extracted three sets of collocations, each consisting of
300 randomly selected collocations occurring with medium frequency. We then ran
Champollion on each of these sets, using three separate database corpora of varying
size, also taken from the Hansards corpus. We asked several people fluent in both
French and English to judge the results, and the accuracy of Champollion was found to
range from 65% to 78%. In our discussion of results, we show how problems for the
lower score can be alleviated by increasing the size of the database corpus.
In the following sections, we first present a review of related work in statistical
natural language processing dealing with bilingual data. Our algorithm depends on
using a measure of correlation to find words that are highly correlated across lan-
guages. We describe the measure that we use and then provide a detailed description
of the algorithm, following this with a theoretical analysis of the performance of our al-
gorithm. Next, we turn to a description of the results and evaluation. Finally, we show
how the results can be used for a variety of applications, closing with a discussion of
the limitations of our approach and of future work.
</bodyText>
<footnote confidence="0.709987">
1 None of the authors is affiliated with Boitet&apos;s research center on machine translation in Grenoble,
France, which is also named &amp;quot;Champollion&amp;quot;.
</footnote>
<page confidence="0.907189">
2
</page>
<note confidence="0.825808">
Smadja, McKeown, and Hatzivassiloglou Translating Collocations for Bilingual Lexicons
</note>
<sectionHeader confidence="0.99846" genericHeader="related work">
2. Related Work
</sectionHeader>
<bodyText confidence="0.999971795918367">
The recent availability of large amounts of bilingual data has attracted interest in
several areas, including sentence alignment (Gale and Church 1991b; Brown, Lai, and
Mercer 1991; Simard, Foster and Isabelle 1992; Gale and Church 1993; Chen 1993), word
alignment (Gale and Church 1991a; Brown et al. 1993; Dagan, Church, and Gale 1993;
Fung and McKeown 1994; Fung 1995b), alignment of groups of words (Smadja 1992;
Kupiec 1993; van der Eijk 1993), and statistical translation (Brown et al. 1993). Of these,
aligning groups of words is most similar to the work reported here, although, as we
shall show, we consider a greater variety of groups than is typical in other research.
In this section, we describe work on sentence and word alignment and statistical
translation, showing how these goals differ from our own, and then describe work
on aligning groups of words. Note that there is additional research using statistical
approaches to bilingual problems, but it is less related to ours, addressing, for example,
word sense disambiguation in the source language by statistically examining context
(e.g., collocations) in the source language, thus allowing appropriate word selection
in the target language. (Brown et al. 1991; Dagan, Itai, and Schwall 1991; Dagan and
Itai 1994).
Our use of bilingual corpora assumes a prealigned corpus. Thus, we draw on work
done at AT&amp;T Bell Laboratories by Gale and Church (1991a, 1991b, 1993) and at IBM
by Brown, Lai, and Mercer (1991) on bilingual sentence alignment. Sentence alignment
programs take a paired bilingual corpus as input and determine which sentences in
the target language translate which sentences in the source language. Both the AT&amp;T
and the IBM groups use purely statistical techniques based on sentence length to
identify sentence pairing in corpora such as the Hansards. The AT&amp;T group (Gale and
Church 1993) defines sentence length by the number of characters in the sentences,
while the IBM group (Brown, Lai, and Mercer 1991) defines sentence length by the
number of words in the sentence. Both approaches achieve similar results and have
been influential in much of the research on statistical natural language processing,
including ours. It has been noted in more recent work that length-based alignment
programs such as these are problematic for many cases of real world parallel data, such
as OCR (Optical Character Recognition) input, in which periods may not be noticeable
(Church 1993), or languages where insertions or deletions are common (Shemtov 1993;
Fung and McKeown 1994). These algorithms were adequate for our purposes, but
could be replaced by algorithms more appropriate for noisy input corpora, if necessary
Sentence alignment techniques are generally used as a preprocessing stage, before
the main processing component that proposes actual translations, whether of words,
phrases, or full text, and they are used this way in our work as well.
Translation can be approached using statistical techniques alone. Brown et al. (1990,
1993) use a stochastic language model based on techniques used in speech recognition,
combined with translation probabilities compiled on the aligned corpus, to do sentence
translation. Their system, Candide, uses little linguistic and no semantic information
and currently produces good quality translations for short sentences containing high
frequency vocabulary as measured by individual human evaluators (see Berger et al.
[19941 for information on recent results). While they also align groups of words across
languages in the process of translation, they are careful to point out that such groups
may or may not occur at constituent breaks in the sentence. In contrast, our work aims
at identifying syntactically and semantically meaningful units, which may be either
constituents or flexible word pairs separated by intervening words, and provides the
translation of these units for use in a variety of bilingual applications. Thus, the goals
of our research are somewhat different.
</bodyText>
<page confidence="0.997564">
3
</page>
<note confidence="0.872721">
Computational Linguistics Volume 22, Number 1
</note>
<bodyText confidence="0.99865262745098">
Kupiec (1993) describes a technique for finding noun phrase correspondences in
bilingual corpora using several stages. First, as for Champollion, the bilingual corpus
must be aligned by sentences. Then, each corpus is separately run through a part-
of-speech tagger and noun phrase recognizer. Finally, noun phrases are mapped to
each other using an iterative re-estimation algorithm. Evaluation was done on the 100
highest-ranking correspondences produced by the program, yielding 90% accuracy.
Evaluation has not been completed for the remaining correspondences-4900 distinct
English noun phrases. The author indicates that the technique has several limitations,
due in part to the compounded error rates of the taggers and noun phrase recognizers.
Van der Eijk (1993) uses a similar approach for translating terms. His work is based
on the assumption that terms are noun phrases and thus, like Kupiec, uses sentence
alignment, tagging, and a noun phrase recognizer. His work differs in the correlation
measure he uses: he compares local frequency of the term (i.e., frequency in sentences
containing the term) to global frequency (i.e., frequency in the full corpus), decreasing
the resulting score by a weight representing the distance between the actual position of
the target term and its expected position in the corpus; this weight is small if the target
term is exactly aligned with the source term and larger as the distance increases. His
evaluation shows 68% precision and 64% recall. We suspect that the lower precision
is due in part to the fact that van der Eijk evaluated all translations produced by the
program while Kupiec only evaluated the top 2%. Note that the greatest difference
between these two approaches and ours is that van der Eijk and Kupiec only handle
noun phrases whereas collocations have been shown to include parts of noun phrases,
categories other than noun phrases (e.g., verb phrases), as well as flexible phrases that
involve words separated by an arbitrary number of other words (e.g., to take . . . steps,
to demonstrate . . . support). In this work, as in earlier work (Smadja 1992), we address
the full range of collocations including both flexible and rigid collocations for a variety
of syntactic categories.
Another approach, begun more recently than our work, is taken by Dagan and
Church (1994), who use statistical methods to translate technical terminology. Like
van der Eijk and Kupiec, they preprocess their corpora by tagging and by identifying
noun phrases. However, they use a word alignment program as opposed to sentence
alignment and they include single words as candidates for technical terms. One of the
major differences between their work and ours is that, like van der Eijk and Kupiec,
they only handle translation of uninterrupted sequences of words; they do not handle
the broader class of flexible collocations. Their system, Termight, first extracts candidate
technical terms, presenting them to a terminologist for filtering. Then, Termight iden-
tifies candidate translations for each occurrence of a source term by using the word
alignment to find the first and last target positions aligned with any words of the source
terms. All candidate translations for a given source term are sorted by frequency and
presented to the user, along with a concordance. Because Termight does not use ad-
ditional correlation statistics, relying instead only on the word alignment, it will find
translations for infrequent terms; none of the other approaches, including Champol-
lion, can make this claim. Accuracy, however, is considerably lower; the most frequent
translation for a term is correct only 40% of the time (compare with Champollion&apos;s
73% accuracy). Since Termight is fully integrated within a translator&apos;s editor (another
unique feature) and is used as an aid for human translators, it gets around the problem
of accuracy by presenting the sorted list of translations to the translator for a choice.
In all cases, the correct translation was found in this list and translators were able to
speed up both the task of identifying technical terminology and translating terms.
Other recent related work aims at using statistical techniques to produce trans-
lations of single words (Fung and McKeown 1994; Wu and Xia 1994; Fung 1995b)
</bodyText>
<page confidence="0.997145">
4
</page>
<note confidence="0.92276">
Smadja, McKeown, and Hatzivassiloglou Translating Collocations for Bilingual Lexicons
</note>
<bodyText confidence="0.999977833333333">
as opposed to collocations or phrases. Wu and Xia (1994) employed an estimation-
maximization technique to find the optimal word alignment from previously sentence-
aligned clean parallel corpora2, with additional significance filtering. The work by Fung
and McKeown (1994) and Fung (1995b) is notable for its use of techniques suitable to
Asian/Romance language pairs as well as Romance language pairs. Given that Asian
languages differ considerably in structure from Romance languages, statistical meth-
ods that were previously proposed for pairs of European languages do not work well
for these pairs. Fung and McKeown&apos;s work also focuses on word alignment from noisy
parallel corpora, where there are no clear sentence boundaries or perfect translations.
Work on the translation of single words into multiword sequences that integrates
techniques for machine-readable dictionaries with statistical corpus analysis (Klavans
and Tzoukermann 1990; Klavans and Tzoukermann in press) is also relevant. While
this work focuses on a smaller set of words for translation (movement verbs), it pro-
vides a sophisticated approach using multiple knowledge sources to address both
one-to-many word translations and the problem of sense disambiguation. Given only
one word in the source, their system, BICORD, uses the corpus to extend dictionary
definitions and provide translations that are appropriate for a given sense but do not
occur in the dictionary, producing a bilingual lexicon of movement verbs as output.
</bodyText>
<sectionHeader confidence="0.752876" genericHeader="method">
3. Collocations and Machine Translation
</sectionHeader>
<bodyText confidence="0.966566214285714">
Collocations, commonly occurring word pairs and phrases, are a notorious source of
difficulty for non-native speakers of a language (Leed and Nakhimovsky 1979; Benson
1985; Benson, Benson, and Ilson 1986). This is because they cannot be translated on a
word-by-word basis. Instead, a speaker must be aware of the meaning of the phrase
as a whole in the source language and know the common phrase typically used in
the target language. While collocations are not predictable on the basis of syntactic or
semantic rules, they can be observed in language and thus must be learned through
repeated usage. For example, in American English one says set the table while in British
English the phrase lay the table is used. These are expressions that have evolved over
time. It is not the meaning of the words lay and set that determines the use of one or
the other in the full phrase. Here, the verb functions as a support verb; it derives its
meaning in good part from the object in this context and not from its own semantic
features. In addition, such collocations are flexible. The constraint is between the verb
and its object and any number of words may occur between these two elements (e.g.,
You will be setting a gorgeously decorated and lavishly appointed table designed for a king).
Collocations also include rigid groups of words that do not change from one context
to another, such as compounds, as in Canadian Charter of Rights and Freedoms.
To understand the difficulties that collocations pose for translation, consider sen-
tences (le) and (10 in Figure 1. Although these sentences are relatively simple, au-
tomatically translating (le) as (10 involves several problems. Inability to translate on
a word-by-word basis is due in part to the presence of collocations. For example,
the English collocation to demonstrate support is translated as prouver son adhesion. This
translation uses words that do not correspond to individual words in the source; the
English translation of prouver is prove and son adhe&apos;sion translates as one&apos;s adhesion. As a
phrase, however, prouver son adhesion carries the same meaning as the source phrase.
Other groups of words in (1e) cause similar problems, including to take steps to, provi-
2 These corpora had little noise. Most sentences neatly corresponded to translations in the paired corpus,
with few extraneous sentences.
</bodyText>
<page confidence="0.988493">
5
</page>
<note confidence="0.858797">
Computational Linguistics Volume 22, Number 1
</note>
<bodyText confidence="0.8916345">
(1e) &amp;quot;Mr. Speaker, our Government has demonstrated its support for
these important principles by taking steps to enforce the provi-
sions of the Charter more vigorously.&amp;quot;
(10 &amp;quot;Monsieur le Président, notre gouvernement a prouve son adhesion
ces importants principes en prenant des mesures pour appliquer
plus systematiquement les preceptes de la Charte.&amp;quot;
</bodyText>
<figureCaption confidence="0.675377">
Figure 1
Example pair of matched sentences from the Hansards corpus.
</figureCaption>
<bodyText confidence="0.99808872">
sions of the Charter, and to enforce provisions. These groups are identified as collocations
for a variety of reasons. For example, to take steps is a collocation because to take is
used here as a support verb for the noun steps. The agent our government doesn&apos;t actu-
ally physically take anything; rather, it has begun the process of enforcement through
small, concrete actions. While the French translation en prenant des mesures does use
the French for take, the object is the translation of a word that does not appear in the
source, measures. These are flexible collocations exhibiting variations in word order.
On the other hand, the compound provisions of the Charter is very commonly used as a
whole in a much more rigid way.
This example also illustrates that collocations are domain dependent, often form-
ing part of a sublanguage. For example, Mr. Speaker is the proper way to refer to
the Speaker of the House in the Canadian Parliament when speaking English. The
French equivalent, Monsieur le Président, is not the literal translation but instead uses
the translation of the term President. While this is an appropriate translation for the
Canadian Parliament, in different contexts another translation would be better. Note
that these problems are quite similar to the difficulties in translating technical termi-
nology, which also is usually part of a particular technical sublanguage (Dagan and
Church 1994). The ability to automatically acquire collocation translations is thus a
definite advantage for sublanguage translation. When moving to a new domain and
sublanguage, translations that are appropriate can be acquired by running Champollion
on a new corpus from that domain.
Since in some instances parts of a sentence can be translated on a word-by-word
basis, a translator must know when a full phrase or pair of words must be consid-
ered for translation and when a word-by-word technique will suffice. Two tasks must
therefore be considered:
</bodyText>
<listItem confidence="0.999770333333333">
1. Identify collocations, or phrases which cannot be translated on a
word-by-word basis, in the source language.
2. Provide adequate translation for these collocations.
</listItem>
<bodyText confidence="0.9674355">
For both tasks, general knowledge of the two languages is not sufficient. It is also
necessary to know the expressions used in the sublanguage, since we have seen that
idiomatic phrases often have different translations in a restricted sublanguage than in
general usage. In order to produce a fluent translation of a full sentence, it is necessary
to know the specific translation for each of the source collocations.
We use XTRACT (Smadja and McKeown 1990; Smadja 1991a; Smadja 1993), a
</bodyText>
<page confidence="0.998319">
6
</page>
<note confidence="0.652476">
Smadja, McKeown, and Hatzivassiloglou Translating Collocations for Bilingual Lexicons
</note>
<bodyText confidence="0.999967625">
tool we developed previously, to identify collocations in the source language (task
1). XTRACT works in three stages. In the first stage, word pairs that co-occur with
significant frequency are identified. These words can be separated by up to four inter-
vening words and thus constitute flexible collocations. In the second stage, XTRACT
identifies combinations of word pairs from stage one with other words and phrases,
producing compounds and idiomatic templates (i.e., phrases with one or more holes
to be filled by specific syntactic types). In the final stage, XTRACT filters any pairs that
do not consistently occur in the same syntactic relation, using a parsed version of the
corpus. This tool has been used in several projects at Columbia University and has
been distributed to a number of research and commercial sites worldwide.
XTRACT has been developed and tested on English-only input. For optimal per-
formance, XTRACT itself relies on other tools, such as a part-of-speech tagger and a
robust parser. Although such tools are becoming more widely available in many lan-
guages, they are still hard to find. We have thus assumed in Champollion that these
tools were only available in one of the two languages; namely, English, termed the
source language throughout the paper.
</bodyText>
<sectionHeader confidence="0.964079" genericHeader="method">
4. The Similarity Measure
</sectionHeader>
<bodyText confidence="0.9999631875">
To rank the proposed translations so that the best one is selected, Champollion uses a
quantitative measure of correlation between the source collocation and its complete
or partial translations. This measure is also used to reduce the search space to a
manageable size, by filtering out partial translations that are not highly correlated
with the source collocation. In this section, we discuss the properties of similarity
measures that are appropriate for our application. We explain why the Dice coefficient
meets these criteria and why this measure is more appropriate than another frequently
used measure—mutual information.
Our approach is based on the assumption that each collocation is unambiguous in
the source language and has a unique translation in the target language (at least in a
clear majority of the cases). In this way, we can ignore the context of the collocations
and their translations, and base our decisions only on the patterns of co-occurrence of
each collocation and its candidate translations across the entire corpus. This approach
is quite different from those adopted for the translation of single words (Klavans
and Tzoukermann 1990; Dorr 1992; Klavans and Tzoukermann 1996), since for single
words polysemy cannot be ignored; indeed, the problem of sense disambiguation has
been linked to the problem of translating ambiguous words (Brown et al. 1991; Dagan,
Itai, and Schwa11 1991; Dagan and Itai 1994). The assumption of a single meaning per
collocation was based on our previous experience with English collocations (Smadja
1993), is supported for less opaque collocations by the fact that their constituent words
tend to have a single sense when they appear in the collocation (Yarowsky 1993), and
was verified during our evaluation of Champollion (Section 7).
We construct a mathematical model of the events we want to correlate, namely, the
appearance of any word or group of words in the sentences of our corpus, as follows:
To each group of words G, in either the source or the target language, we map a binary
random variable XG that takes the value &amp;quot;1&amp;quot; if G appears in a particular sentence and
&amp;quot;0&amp;quot; if not. Then, the corpus of paired sentences comprising our database represents
a collection of samples for the various random variables X for the various groups of
words. Each new sentence in the corpus provides a new independent sample for every
variable XG. For example, if G is unemployment rate and the words unemployment rate
appear only in the fifth and fifty-fifth sentences of our corpus (not necessarily in that
order and perhaps with other words intervening), then in our sample collection, XG
</bodyText>
<page confidence="0.998041">
7
</page>
<note confidence="0.423547">
Computational Linguistics Volume 22, Number 1
</note>
<bodyText confidence="0.9994755">
takes the value &amp;quot;1&amp;quot; for the fifth and fifty-fifth sentences and &amp;quot;0&amp;quot; for all other sentences
in the corpus. Furthermore, for the measurement of correlation between a word group
G in the source language and another word group H in the target language, we map the
paired sentences in our corpus to a collection of paired samples for the random variables
XG and XH. This modeling process allows us to use correlation metrics between paired
samples of random variables (XG and Xx) to measure the correlation between word
groups (G and H) across languages.
There are several ways to measure the correlation of two such random variables.
One measure frequently used in information retrieval is the Dice coefficient (Dice 1945;
Sorensen 1948; Salton and McGill 1983; Frakes and Baeza-Yates 1992). It is defined as
</bodyText>
<equation confidence="0.981213">
,„ 2 . p(X=1, Y=1) (1)
Dice(X, I) =p(X =1) + p(Y =1)
</equation>
<bodyText confidence="0.999987666666667">
where p(X, Y), p(X), and p(Y) are the joint and marginal probability mass functions
of the variables X and Y, respectively. Using maximum likelihood estimates for the
probabilities in the above equation, we have
</bodyText>
<equation confidence="0.988116">
Dice(X,Y) = 2 fxy fx fy
</equation>
<bodyText confidence="0.997596714285714">
where fx, fy, and fxy are the absolute frequencies of appearance of &amp;quot;1&amp;quot;s for the variables
X, Y, and both X and Y together, respectively.
On the other hand, in computational linguistics, information-theoretic measures
such as mutual information are widely used (e.g., Bahl et al. 1986; Church and Hanks
1990; Church et al. 1991; Dagan, Marcus, and Markovitch 1993; Su, Wu, and Chang
1994). In information theory, the mutual information I(X, Y) between two binary ran-
dom variables X and Y is defined as
</bodyText>
<equation confidence="0.999440333333333">
p(X=x,Y =y) log P(X=x&apos;Y =Y)
/(X, Y) = E
xE{0,1}yE{0,1} P(X=X)p(Y= y)
</equation>
<bodyText confidence="0.997979">
However, in computational linguistics, the term mutual information has been used
most of the time to describe only a part of the above sum, namely the term from the
X =1, Y =1 case (unweighted by the joint probability p(X = 1, Y = 1)) . In other words,
this alternative measure of mutual information, which we will refer to as specific
mutual information S/(X, Y), is
</bodyText>
<equation confidence="0.996049">
p(X= 1, Y=1)
S/(X, Y) = log p(X=1)p(Y =1)
</equation>
<bodyText confidence="0.9990834">
The quantity /(X, Y) is the average of SI(X, Y) taken over the four combinations of
values of X and Y according to the joint probability distribution p(X, Y), so sometimes
the term average mutual information is used for /(X, Y).
Average mutual information expresses the difference between the entropy (infor-
mation) of one of the variables and the conditional entropy of that variable given the
other variable (Cover and Thomas 1991). Thus, average mutual information measures
the reduction in the uncertainty about the value of one variable that knowledge of
the value of the other variable provides, averaged over all possible values of the two
variables. Equivalently, average mutual information is &amp;quot;the information about X con-
tained in Y&amp;quot; (Papoulis 1984, 518) (or the information about Y contained in X). Specific
</bodyText>
<page confidence="0.991543">
8
</page>
<note confidence="0.648193">
Smadja, McKeown, and Hatzivassiloglou Translating Collocations for Bilingual Lexicons
</note>
<bodyText confidence="0.999918857142857">
mutual information represents the log-likelihood ratio of the joint probability of see-
ing a &amp;quot;1&amp;quot; in both variables over the probability that such an event would have if the
two variables were independent, and thus provides a measure of the departure from
independence.
The Dice coefficient, on the other hand, combines the conditional probabilities
p(X==1 I Y=1) and p(Y=1 I X=1) with equal weights in a single number. This can
be shown by replacing p(X=1, Y=1) on the right side of equation (1):3
</bodyText>
<equation confidence="0.999524363636364">
Dice(X,Y) = 2 p(X=1, Y =1)
p(X=1) + p(Y =1)
2
p(X=1) p(Y=1)
p(X=1,Y=1) p(X=1,Y=1)
2
p(X=1) p(Y=1)
p(Y=1 I X=1)p(X=1) + p(X=1 Y=1)p(Y=1)
2
1 1
p(Y=1 I X=1) p(X=1 I Y=1)
</equation>
<bodyText confidence="0.9999706">
As is evident from the above equation, the Dice coefficient depends only on the
conditional probabilities of seeing a &amp;quot;1&amp;quot; for one of the variables after seeing a &amp;quot;1&amp;quot; for
the other variable, and not on the marginal probabilities of &amp;quot;1&amp;quot;s for the two variables.
In contrast, both the average and the specific mutual information depend on both the
conditional and the marginal probabilities. For S/(X, Y) in particular, we have
</bodyText>
<equation confidence="0.9994375">
p(X=1,Y=1) (2)
SI(X,Y) --= log p(X=1)p(Y =1)
- log p(X=1 Y=1)p(Y=1)
p(X=1)p(Y=1)
log p(X=1 I Y=1)
p(X=1)
- log p(Y=1 I X=1)
p(Y=1)
</equation>
<bodyText confidence="0.9763732">
To select among the three measures, we first observe that for our application,
1-1 matches (paired samples where both X and Y are 1) are significant while 0-0
matches (samples where both X and Y are 0) are not. These two types of matches
correspond to the cases where either both word groups of interest appear in a pair of
aligned sentences or neither word group does. Seeing the two word groups in aligned
</bodyText>
<footnote confidence="0.700238857142857">
3 In the remainder of this discussion, we assume that p(X =1, Y =1) is not zero. This is a justified
assumption for our model, since we cannot say that two words or word groups will not occur in the
same sentence or in a sentence and its translation; such an event may well happen by chance, or
because the words or word groups are parts of different syntactic constituents, even for unrelated
words and word groups. The above assumption guarantees that all three measures are always
well-defined; in particular, it guarantees that the marginal probabilities p(X=1) and p(Y =1) and the
conditional probabilities p(X=1 I Y=1) and p(Y=1 I X=1) are all nonzero.
</footnote>
<page confidence="0.981847">
9
</page>
<note confidence="0.410143">
Computational Linguistics Volume 22, Number 1
</note>
<bodyText confidence="0.999502583333334">
sentences (a 1-1 match) certainly contributes to their association and increases our
belief that one is the translation of the other. Similarly, seeing only one of them (a 1-0
or 0-1 mismatch) decreases our belief in their association. But, given the many possible
groups of words that can appear in each sentence, the fact that neither of two groups
of words appears in a pair of aligned sentences does not offer any information about
their similarity. Even when the word groups have been observed relatively few times
(together or separately), seeing additional sentences containing none of the groups of
words we are interested in should not affect our estimate of their similarity.
In other words, in our case, X and Y are highly asymmetric; a &amp;quot;1&amp;quot; value (and a 1-1
match) is much more informative than a &amp;quot;0&amp;quot; value (or 0-0 match). Therefore, we should
select a similarity measure that is based only on 1-1 matches and mismatches. 0-0
matches should be completely ignored; otherwise, they would dominate the similarity
measure, given the overall relatively low frequency of any particular word or word
group in our corpus.
The Dice coefficient satisfies the above requirement of asymmetry: adding 0-0
matches does not change any of the absolute frequencies fxY, fx, and fy, and so does
not affect Dice(X,Y). On the other hand, average mutual information depends only
on the distribution of X and Y and not on the actual values of the random variables.
In fact, I(X, Y) is a completely symmetric measure. If the variables X and Y are trans-
formed so that every &amp;quot;1&amp;quot; is replaced with a &amp;quot;0&amp;quot; and vice versa, the average mutual
information between X and Y remains the same. This is appropriate in the context
of communications for which mutual information was originally developed (Shannon
1948), where the ones and zeros encode two different states with no special preference
for either of them. But in the context of translation, exchanging the &amp;quot;1&amp;quot;s and &amp;quot;0&amp;quot;s is
equivalent to considering a word or word group to be present when it was absent
and vice versa, thus converting all 1-1 matches to 0-0 matches and all 0-0 matches to
1-1 matches. As explained above, such a change should not be considered similarity
preserving, since 1-1 matches are much more significant than 0-0 ones.
As a concrete example, consider a corpus of 100 matched sentences, where each of
the word groups associated with X and Y appears five times. Furthermore, suppose
that the two groups appear twice in a pair of aligned sentences and each word group
also appears three times by itself. This situation is depicted in the column labeled
&amp;quot;Original Variables&amp;quot; in Table 1. Since each word group appears two times with the
other group and three times by itself, we would normally consider the source and
target groups somewhat similar but not strongly related. And indeed, the value of the
Dice coefficient (254 = 0.4) intuitively corresponds to that assessment of similarity.4
Now, suppose that the &amp;quot;0&amp;quot;s and &amp;quot;1&amp;quot;s in X and Y are exchanged, so that the situation is
now described by the last column of Table 1. The transformed variables now indicate
that out of 100 sentences, the two word groups appear together 92 times, while each
appears by itself three times and there are two sentences that contain none of the
groups. We would consider such evidence to strongly indicate very high similarity
between the two groups, and indeed the Dice coefficient of the transformed variables
is now 4115 = 0.9684. However, the average mutual information of the variables
would remain the same.
Specific mutual information falls somewhere in between the Dice coefficient and
average mutual information: it is not completely symmetric but neither does it ig-
nore 0-0 matches. This measure is very sensitive to the marginal probabilities (relative
frequencies) of the &amp;quot;1&amp;quot;s in the two variables, tending to give higher values as these
</bodyText>
<footnote confidence="0.625668">
4 Recall that the Dice coefficient is always between 0 and 1.
</footnote>
<page confidence="0.998252">
10
</page>
<note confidence="0.901711">
Smadja, McKeown, and Hatzivassiloglou Translating Collocations for Bilingual Lexicons
</note>
<tableCaption confidence="0.910501">
Table 1
Example values of Dice(X,Y), I(X, Y), and SI(X, Y) after interchanging O&apos;s and l&apos;s.
</tableCaption>
<table confidence="0.99873625">
Original Variables Transformed Variables
1-1 matches 2 92
0-0 matches 92 2
1-0 and 0-1 mismatches 6 6
Total 100 100
Dice coefficient 0.4000 0.9684
Average mutual information (bits) 0.0457 0.0457
Specific mutual information (bits) 3.0000 0.0277
</table>
<bodyText confidence="0.999820583333333">
probabilities decrease. Adding 0-0 matches lowers the relative frequencies of &amp;quot;1&amp;quot;s,
and therefore always increases the estimate of SI(X, Y). Furthermore, as the marginal
probabilities of the two word groups become very small, SI(X, Y) tends to infinity,
independently of the distribution of matches (including 1-1 and 0-0 ones) and mis-
matches, as long as the joint probability of 1-1 matches is not zero. By taking the limit
of SI(X, Y) for p(X =1) —+0 or p(Y =1) —+0 in equation (2) we can easily verify that
this happens even if the conditional probabilities p(X =1 I Y=1) and p(Y = 1 I X = 1)
remain constant, a fact that should indicate a constant degree of relatedness between
the two variables. Neither of these problems occurs with the Dice coefficient, exactly
because that measure combines the conditional probabilities of &amp;quot;1&amp;quot;s in both directions
without looking at the marginal distributions of the two variables. In fact, in cases
such as the examples of Table 1, where p(X = 1 I Y = 1) = p(Y = 1 I X = 1), the Dice
coefficient becomes equal to these conditional probabilities.
The dependence of SI(X, Y) on the marginal probabilities of &amp;quot;1&amp;quot;s shows that using
it would make rare word groups look more similar than they really are. For our
example in Table 1, the specific mutual information is SI(X, Y) = log 0.05o.o20.05 = log 8 =
3 bits for the original variables, but SI(X&apos;, Y&apos;) = log 0.95%920,95 = log 1.019391 = 0.027707
bits for the transformed variables. Note, however, that the change is in the opposite
direction from the appropriate one; that is, the new variables are deemed far less
similar than the old ones. This can be attributed to the fact that the number of &amp;quot;1&amp;quot;s in
the original variables is far smaller.
SI(X,Y) also suffers disproportionately from estimation errors when the observed
counts of &amp;quot;1&amp;quot;s are very small. While all similarity measures will be inaccurate when
the data is sparse, the results produced by specific mutual information can be more
misleading than the results of other measures, because SI is not bounded. This is not
a problem for our application, as Champollion applies absolute frequency thresholds to
avoid considering very rare words and word groups; but it indicates another potential
problem with the use of SI to measure similarity.
Finally, another criterion for selecting a similarity measure is its suitability for
testing for a particular outcome, where outcome is determined by the application. In
our case, we need a clear-cut test to decide when two events are correlated. Both for
mutual information and the Dice coefficient, this involves comparison with an exper-
imentally determined threshold. Although the two measures are similar in that they
compare the joint probability p(X=1,Y =1) with the marginal probabilities, they have
different asymptotic behaviors. This was demonstrated in the previous paragraphs for
the cases of small and decreasing relative frequencies. Here we examine two more
</bodyText>
<page confidence="0.98919">
11
</page>
<note confidence="0.353655">
Computational Linguistics Volume 22, Number 1
</note>
<bodyText confidence="0.616398">
cases associated with specific tests. We consider the two extreme cases, where
</bodyText>
<listItem confidence="0.982741">
• The two events are perfectly independent. In this case,
p(X=x, Y=y) = p(X= x)p(Y =y).
• The two events are perfectly correlated in the positive direction: each
word group appears every time (and only when) the other appears in
the corresponding sentence. Then
</listItem>
<equation confidence="0.811363666666667">
p(X=x,Y=y) ifxy
= 0
p(X=x) = p(Y =y) if x = y
</equation>
<bodyText confidence="0.898125625">
In the first case, both average and specific mutual information are equal to 0 since
log p51c-x)xptyYy)) = log 1 = 0 for all x and y, and are thus easily testable, whereas the
Dice coefficient is equal to 2xp(r)(cx-1)1±))V-.01)) and is thus a function of the individual fre-
quencies of the two word groups. In this case, the test is easier to decide using mutual
information. In the second case, the results are reversed; specific mutual information
is equal to log pP((xtil))2 = log(p(X = 1)), and it can be shown that the average mutual
information becomes equal to the entropy H(X) of X (or Y). Both of these measures
depend on the individual probabilities (or relative frequencies) of the word groups,
</bodyText>
<equation confidence="0.65921">
( 2 xi xp=( ) 1)
</equation>
<bodyText confidence="0.998891166666667">
whereas the Dice coefficient is equal to px p) 1. In this case, the test is easier
to decide using the Dice coefficient. Since we are looking for a way to identify posi-
tively correlated events we must be able to easily test the second case, while testing
the first case is not relevant. Specific mutual information is a good measure of inde-
pendence (which it was designed to measure), but good measures of independence
are not necessarily good measures of similarity.
The above arguments all support the use of the Dice coefficient over either average
or specific mutual information. We have confirmed the theoretically expected behavior
of the similarity measures through testing. In our early work on Champollion (Smadja
1992), we used specific mutual information (SI) as a correlation metric. After carefully
studying the errors produced, we suspected that the Dice measure would produce
better results for our task, according to the arguments given above.
Consider the example given in Table 2. In the table, the second column represents
candidate French word pairs for translating the single word today. The third column
gives the frequency of the word today in a subset of the Hansards containing 182,584
sentences. The fourth column gives the frequency of each French word pair in the
French counterpart of the same corpus, and the fifth column gives the frequency of
appearance of today and each French word pair in matched sentences. Finally, the
sixth and seventh columns give the similarity scores for today and each French word
pair computed according to the Dice measure or specific mutual information (in bits)
respectively. Of the four candidates, aujourd hui (shown in bold) is the only correct
translation.&apos; We see from the table that the specific mutual information scores fail to
identify aujourd hui as the best candidate—it is only ranked fourth. Furthermore, the
four SI scores are very similar, thus not clearly differentiating the results. In contrast,
</bodyText>
<footnote confidence="0.8257975">
5 Note that the correct translation is really a single word in contemporary French. Aujourd&apos;hui has
evolved from a collocation (au jour d&apos;hui) which has become so rigid that it is now considered a single
word. Hui can still appear on its own, but aujourd is not a French word, so Champollion&apos;s French
tokenizer erroneously considered the apostrophe character as a word separator in this case. Champollion
will correct this error by putting aujourd and hui back together and identifying them as a rigid
collocation.
</footnote>
<page confidence="0.996625">
12
</page>
<note confidence="0.912688">
Smadja, McKeown, and Hatzivassiloglou Translating Collocations for Bilingual Lexicons
</note>
<tableCaption confidence="0.8765925">
Table 2
Dice versus specific mutual information scores for the English word today. The correct
translation is shown in bold.
French (Y)
debat aujourd
debat hui
senat hui
aujourd hui
</tableCaption>
<table confidence="0.909806714285714">
fx fY fxy Dice(X,Y) SI(X, Y)
3121 143 130 0.08 5.73
3121 143 130 0.08 5.73
3121 52 46 0.03 5.69
3121 2874 2408 0.80 5.62
English (X)
today
</table>
<bodyText confidence="0.997602333333333">
the Dice coefficient clearly identifies aujourd hui as the group of words most similar to
today, which is what we want.
After implementing Champollion, we attempted to generalize these results and con-
firm our theoretical argumentation by performing an experiment to compare SI and
the Dice coefficient in the context of Champollion. We selected a set of 45 collocations
with mid-range frequency identified by XTRACT and we ran Champollion on them
using sample training corpora (databases). For each run of Champollion, and for each
input collocation, we took the final set of candidate translations of different lengths
produced by Champollion (with the intermediate stages driven by the Dice coefficient)
and compared the results obtained using both the Dice coefficient and SI at the last
stage for selecting the proposed translation. The 45 collocations were randomly se-
lected from a larger set of 300 collocations so that the Dice coefficient&apos;s performance
on them is representative (i.e., approximately 70% of them are translated correctly by
Champollion when the Dice measure is used), and the correct translation is always in-
cluded in the final set of candidate translations. In this way, the number of erroneous
decisions made when SI is used at the final pass is a lower bound on the number of
errors that would have been made if SI had also been used in the intermediate stages.
We compared the results and found that out of the 45 source collocations,
</bodyText>
<listItem confidence="0.9982114">
• 2 were not frequent enough in the database to produce any candidate
translations.
• Using the Dice coefficient, 36 were correctly translated and 7 were
incorrectly translated.
• Using SI, 26 were correctly translated and 17 incorrectly.6
</listItem>
<bodyText confidence="0.998704625">
Table 3 summarizes these results and shows the breakdown across categories. In
the table, the numbers of collocations correctly and incorrectly translated when the
Dice coefficient is used are shown in the second and third rows respectively. For
both cases, the second column indicates the number of collocations that were correctly
translated with SI and the third column indicates the number of these collocations that
were incorrectly translated with SI. The last column and the last row show the total
number of collocations correctly and incorrectly translated when the Dice coefficient
or SI is used respectively. From the table we see that every time SI produced good
</bodyText>
<footnote confidence="0.950161333333333">
6 In this section, incorrect translations are those judged as incorrect by the authors. We did not
distinguish between errors due to XTRACT (identifying an invalid English collocation) or Champollion
(providing a wrong translation for a valid collocation).
</footnote>
<page confidence="0.996749">
13
</page>
<note confidence="0.415405">
Computational Linguistics Volume 22, Number 1
</note>
<tableCaption confidence="0.993149">
Table 3
</tableCaption>
<table confidence="0.974111166666667">
Comparison of Dice and SI scores on a small set of
examples.
SI Correct SI Incorrect Total
Dice Correct 26 10 36
Dice Incorrect 0 7 7
Total 26 17 43
</table>
<tableCaption confidence="0.998806">
Table 4
</tableCaption>
<figure confidence="0.90464652631579">
Dice versus specific mutual information scores on two example English collocations. The
correct translation for each source collocation is shown in bold.
English (X) French (Y)
cartes
cartes credit
cartes credit taux
cartes credit taux paient
positive
affirmative action positive action
positive action sociale
fx ft fxy Dice(X,Y) SI(X,Y)
69 89 54 0.68 2.68
69 57 52 0.83 2.86
69 23 22 0.48 2.88
69 2 2 0.06 2.90
116 89 73 0.71 2.59
116 75 73 0.76 2.66
116 2 2 0.03 2.68
credit cards
</figure>
<bodyText confidence="0.95171595">
results, the Dice coefficient also produced good results; there were no cases for which
SI produced a correct result while the Dice coefficient produced an incorrect one. In
addition, we see that out of the 17 incorrect results produced by SI, the Dice coefficient
corrected 10. Although based on only a few cases, this experiment confirms that the
Dice coefficient outperforms SI in the context of Champollion.
Table 4 gives concrete examples from this experiment in which the Dice coefficient
outperforms specific mutual information. The table has a format similar to that of
Table 2. X represents an English collocation (credit card or affirmative action), and Y
represents candidate translations in French (for the credit cards example: cartes, cartes
credit, cartes credit taux, and cartes credit taux paient). The correct translations are again
shown in bold. The third and fourth columns give the independent frequencies of
each word group, while the fifth column gives the number of times that both groups
appear in matched sentences. The two subsequent columns give the similarity values
computed according to the Dice coefficient and specific mutual information (in bits).
The corpus used for these examples contained 54,944 sentences in each language. We
see from Table 4 that, as for the today example in Table 2, the SI scores are very close
to each other and fail to select the correct candidate whereas the Dice scores cover a
wider range and clearly peak for the correct translation.
In conclusion, both theoretical arguments and experimental results support the
choice of the Dice coefficient over average or specific mutual information for our
</bodyText>
<page confidence="0.981387">
14
</page>
<note confidence="0.509483">
Smadja, McKeown, and Hatzivassiloglou Translating Collocations for Bilingual Lexicons
</note>
<listItem confidence="0.822296666666667">
application.&apos; Consequently, we have used the Dice coefficient as the similarity measure
in Champollion.
5. Champollion: The Algorithm and the Implementation
</listItem>
<bodyText confidence="0.949475239130434">
Champollion translates single words or collocations in one language into collocations
(including single word translations) in a second language using the aligned corpus as a
reference database. Before running Champollion there are two steps that must be carried
out: source and target language sentences of the database corpus must be aligned and
a list of collocations to be translated must be provided in the source language. For our
experiments, we used corpora that had been aligned by Gale and Church&apos;s sentence
alignment program (Gale and Church 1991b) as our input data.8 Since our intent in
this paper is to evaluate Champollion, we tried not to introduce errors into the training
data; for this purpose, we kept only the 1-1 alignments. Indeed, more complex sentence
alignments tend to have a much higher alignment error rate (Gale and Church 1991b).
By doing so, we lost an estimated 10% of the text (Brown, Lai, and Mercer 1991), which
was not problematic since we had enough data. In the future, we plan to design more
flexible techniques that would work from a loosely aligned corpus (see Section 9).
To compile collocations, we used XTRACT on the English version of the Hansards.
Some of the collocations retrieved are shown in Table 5. Collocations labeled &amp;quot;fixed,&amp;quot;
such as International Human Rights Covenants, are rigid compounds. Collocations labeled
&amp;quot;flexible&amp;quot; are pairs of words that can be separated by intervening words or occur in
reverse order, possibly with different inflected forms.
Given a source English collocation, Champollion first identifies in the database
corpus all the sentences containing the source collocation. It then attempts to find all
words that can be part of the translation of the collocation, producing all words that
are highly correlated with the source collocation as a whole. Once this set of words is
identified, Champollion iteratively combines these words in groups, so that each group
is in turn highly correlated with the source collocation. Finally, Champollion produces
as the translation the largest group of words having a high correlation with the source
collocation.
More precisely, for a given source collocation, Champollion initially identifies a set
S of k words that are highly correlated with the source collocation. This operation is
described in detail in Section 5.1 below. Champollion assumes that the target colloca-
tion is a combination of some subset of these words. Its search space at this point
thus consists of the powerset P(S) of S containing 2k elements. Instead of computing
a correlation factor for each of the 2&amp;quot; elements with the source collocation, Champollion
searches a part of this space in an iterative manner. Champollion first forms all pairs
of words in S, evaluates the correlation between each pair and the source collocation
using the Dice coefficient, and keeps only those pairs that score above some thresh-
old. Subsequently, it constructs the three-word elements of P (S) containing one of
7 The choice of the Dice coefficient is not crucial; for example, using the Jaccard coefficient or any other
similarity measure that is monotonically related to the Dice coefficient would be equivalent. What is
important is that the selected measure satisfy the conditions of asymmetry insensitivity to marginal
word probabilities, and convenience in testing for correlation. There are many other possible measures
of association, and the general points made in this section may apply to them insofar as they also
exhibit the properties we discussed. For example, the normalized chi-square measure (02) used in Gale
and Church (1991a) shares some of the important properties of average mutual information (for
example, it is completely symmetric with respect to 1-1 and 0-0 matches).
8 We are thankful to Ken Church and the AT&amp;T Bell Laboratories for providing us with a prealigned
Hansards corpus.
</bodyText>
<figure confidence="0.463858962962963">
Computational Linguistics Volume 22, Number 1
Table 5
Some collocations identified by XTRACT.
Collocation Type
Canadian Charter of Rights and Freedoms rigid
Canadian Human Rights Commission rigid
enforce provisions flexible
enforce vigorously flexible
express hope flexible
gays and lesbians rigid
health and safety problems rigid
health and safety rights rigid
health equipment rigid
health hazards rigid
health legislation rigid
health services rigid
human rights rigid
income tax return rigid
International Human Rights Covenants rigid
make progress flexible
Minister of National Health and Welfare rigid
Nova Scotia rigid
Smoking Control Act rigid
take effect flexible
take initiative flexible
take steps flexible
unemployment rate rigid
</figure>
<bodyText confidence="0.992519681818182">
these highly correlated pairs plus a member of S. measures their correlation with the
source collocation, and keeps the triplets that score above the threshold. This process
is repeated until, for some value n &lt; k, no n-word element of 2(S) scores above the
threshold. Then Champollion selects the best translation among the top candidates in
each group of i words, 1 &lt;i &lt; n — 1, and determines whether the selected translation
is a single word, a flexible collocation, or a rigid collocation. For rigid collocations,
Champollion also reports the (fixed) order in which the words in the translation appear
in the corpus.
Champollion operates in four consecutive stages. Each of these stages corresponds
to one step of the algorithm, with the exception of the main iteration stage, which
covers steps 2 to 4 of the algorithm. An additional preprocessing stage where indexing
structures are created for fast access to the corpus is required when the corpus database
is changed. We describe the algorithm below, alternating each step with a description
of what is produced at that step, using the example given in Figure 2. This figure shows
information exactly as Champollion produces it. We have added italicized comments
explaining the various components of the output. The output includes the various
potential candidate translations, of incrementally larger lengths, and the final selected
translation having the best score. Note that Champollion correctly determines the word
order in the French translation, which is the opposite of the word order in the English
collocation.
Stage 1—Step 1: Initialization of the work space. Starting with a source language word
group (possibly a single word) W, Champollion identifies all words in the target Ian-
</bodyText>
<note confidence="0.622792">
Smadja, McKeown, and Hatzivassiloglou Translating Collocations for Bilingual Lexicons
</note>
<table confidence="0.966964275862069">
SOURCE COLLOCATION:
official, 492
languages, 266
The numbers indicate the frequencies of the input words in the English corpus.
NUMBER OF SENTENCES IN COMMON: 167
The words appear together in 167 English sentences.
Champollion now gives all the candidate final translations; that is, the best translations at each
stage of the iteration process. The best single word translation is thus (officielles), the best pair
(officielles, langues, the best translation with 8 words (suivantes, doug, deposer, lewis, petitions,
honneur, officielles, langues). The word groups are treated as sets, with no ordering. The numbers are
the associated similarity score (using the Dice coefficient) for the best translation at each iteration and
the number of candidate translations that passed the threshold among the word groups considered
at that iteration. There are thus 11 single words that pass the thresholds at the first iteration, 35
pairs of words, and so on.
CANDIDATE TRANSLATIONS:
officielles, 0.94 out of 11
officielles langues, 0.95 out of 35
honneur officielles langues, 0.45 out of 61
deposer honneur officielles langues, 0.36 out of 71
deposer petitions honneur officielles langues, 0.34 out of 56
deposer lewis petitions honneur officielles langues, 0.32 out of 28
doug deposer lewis petitions honneur officielles langues, 0.32 out of 8
suivantes doug deposer lewis petitions honneur officielles langues, 0.20 out of 1
Champollion then selects the optimal translation, which is the translation with the highest simi-
larity score. In this case the result is correct.
SELECTED TRANSLATION:
officielles langues 0.951070
An example sentence in French where the selected translation is used is also shown.
EXAMPLE SENTENCE:
</table>
<bodyText confidence="0.517428888888889">
Le depute n&apos; ignore pas que le gouvernement compte presenter, avant la fin de l&apos;
armee, un projet de revision de la Loi sur les langues officielles.
Finally, additional information concerning word order is computed and presented. For a rigid
collocation such as this one, Champollion will print for all words in the selected translation except
the first one their distance from the first word. In our example, the second word (langues) appears
in most cases one word before officielles, to form the compound langues officielles. Note that
this information is added during postprocessing after the translation has been selected, and takes
very little time to compute because of the indexing. In this case, it took a few seconds to compute
this information.
</bodyText>
<figure confidence="0.52037">
WORD ORDER:
officielles
langues: selected position: —1
</figure>
<figureCaption confidence="0.7884605">
Figure 2
Sample output of Champollion.
</figureCaption>
<bodyText confidence="0.903178">
guage that satisfy the following two conditions:
</bodyText>
<listItem confidence="0.6228344">
1. The value of the Dice coefficient between the word and the source
collocation W is at least Td, where Td is an empirically chosen threshold,
and
2. The word appears in the target language opposite the source collocation
at least T1 times, where 7.1 is another empirically chosen threshold.
</listItem>
<page confidence="0.991986">
17
</page>
<note confidence="0.618502">
Computational Linguistics Volume 22, Number 1
</note>
<bodyText confidence="0.999573102040816">
Words that pass these tests are collected in a set S. from which the final translation
will eventually be produced. When given official languages as input (see Figure 2),
this step produces a set S with the following eleven words: suivantes, doug, deposer,
suprematie, lewis, petitions, honneur, programme, mixte, officielles, and langues.
The Dice threshold Td (currently set at 0.10) is the major criterion that Champollion
uses to decide which words or partial collocations should be kept as candidates for the
final translation of the source collocation. In Section 6 we explain why this incremental
filtering process is necessary and we show that it does not significantly degrade the
quality of Champ°llion&apos;s output. To our surprise, we found that the filtering process
may even increase the quality of the proposed translation.
The absolute frequency threshold Tf (currently set at 5) also helps limit the size
of S, by rejecting words that appear too few times opposite the source collocation.
Its most important function, however, is to remove from consideration words that
appear too few times for our statistical methods to be meaningful. Applying the Dice
measure (or any other statistical similarity measure) to very sparse data can produce
misleading results, so we use Tf as a guide for the applicability of our method to low
frequency words.
It is possible to modify the thresholds Td and Tf according to properties of the
database corpus and the collocations that are translated. Such an approach would use
lower values of the thresholds, especially of Tf, for smaller corpora or less frequent
collocations. In that case, a separate estimation phase is needed to automatically de-
termine the values of the thresholds. The alternative we currently support is to allow
the user to replace the default thresholds during the execution of Champollion with
values that are more appropriate for the corpus at hand.
After all words have been collected in S, the initial set of possible translations P
is set equal to S, and Champollion proceeds with the next stage.
Stage 2—Step 2: Scoring of possible translations. In this step, Champollion examines all
members of the set P of possible translations. For each member x of P, Champollion
computes the Dice coefficient between the source language collocation W and x. If the
Dice coefficient is below the threshold Td, X is discarded from further consideration;
otherwise, x is saved in a set P&apos;.
When given official languages as input, the first iteration of Step 2 simply sets P&apos;
to P, the second iteration selects 35 word pairs out of the possible 110 candidates,
the third iteration selects 61 word triplets, and so on until the final (ninth) iteration
when none of the three elements of P passes the threshold Td and thus P&apos; has no
elements.
Stage 2—Step 3: Identifying the locally best translation. Once the set of surviving transla-
tions P&apos; has been computed, Champollion checks if it is empty. If it is, there cannot be
any more translations to be considered, so Champollion proceeds to Step 5. If P&apos; is not
empty, Champollion locates the translation that looks locally the best; that is, among
all members of P&apos; analyzed at this iteration, the translation that has the highest Dice
coefficient value with the source collocation. This translation is saved in a table C of
candidate final translations, along with its length in words and its similarity score.
Champollion then continues with the next step.
The first iteration of Step 3 on our example collocation would select the word
officielles (among the 11 words in S) as the first candidate translation, with a score of
0.94. On the second iteration, the word pair (officielles, langues) is selected (out of 35
pairs that pass the threshold) with a score of 0.95. On the third run, the word triplet
(honneur, officielles, langues), is selected (out of 61 triplets) with a score of 0.45. On the
</bodyText>
<page confidence="0.992842">
18
</page>
<note confidence="0.806079">
Smadja, McKeown, and Hatzivassiloglou Translating Collocations for Bilingual Lexicons
</note>
<bodyText confidence="0.999623139534883">
eighth iteration of Step 3, P&apos; has only one element, the 8-tuple (suivantes, doug, deposer,
lewis, petitions, honneur, officielles, langues) with a score of 0.20. Finally, on the ninth
iteration of Step 3, P&apos; is empty and Champollion goes to Step 5.
Stage 2—Step 4: Updating the set of possible translations. Champollion updates the set of
possible translations by setting P equal to the Cartesian product of the surviving trans-
lations P&apos; and the collection of words S (i.e., those related to the source collocation).9
Control then returns to the start of Step 2.
In our example, during the first run of Step 4, a set of word pairs would be
produced, including, for example, (suivantes, doug), (deposer, lewis), (petitions, honneur),
and (officielles, langues). Some of the word triplets formed during the second iteration
of Step 4 on our example starting from the word pair (officielles, longues) are (officielles,
langues, suivantes), (officielles, langues, doug), (officielles, langues, lewis), and (officielles,
langues, honneur). Similarly, on the third run of Step 4 quadruplets are formed such
as (officielles, langues, suivantes, lewis). Finally, on the eighth iteration of this step, three
9-tuples are formed, including, for example, (suivantes, doug, deposer, lewis, petitions,
honneur, officielles, langues, mixte), and are passed on to Step 2; note that none of them
will pass the Dice threshold at the next iteration of Step 2.
Stage 3—Step 5: Identifying the globally best translation. If the list of candidate final trans-
lations C is empty, Champollion has failed to locate a target language translation of
the source collocation and stops, reporting this. Otherwise, the entry with the highest
Dice coefficient with the source collocation is selected as the translation. In the case of
ties, the longer of the tied collocations is selected. Note that because of the way table
C is maintained, the word group selected in this way is guaranteed to correspond
to a global maximum (among all word groups considered) of the similarity measure.
We are planning to experiment with a more sophisticated technique for selecting the
globally best translation, giving more weight to the collocation length so that longer
word groups are considered better choices.
If the final translation contains just one word, Champollion reports the result and
halts. Otherwise, the following step is executed.
Step 5 in our example selects the pair (officielles, langues) with a score of 0.951070
as the best candidate and continues with the following step.
Stage 4—Step 6: Determination of word ordering. Once a multiword translation has been
selected, Champollion examines all the sentences containing the selected translation to
determine whether the collocation is flexible (i.e., word order is not fixed) or rigid.
Champollion looks at all the sentences containing the target language collocation and
determines if the words involved are used consistently (i.e., in at least 60% of the cases)
in the same order and at the same distance from one another. If the collocation is found
to be rigid, the word order and the interword distances are also reported. Note that
although this is a postprocessing stage, it does not require any sentence of the corpus
to be reread, since the necessary information has already been precomputed.
For the official languages example, Champollion determines that langues appears be-
fore officielles with no intervening words and produces the rigid collocation langues
officielles. See Figure 2 on page 17 for more details.
</bodyText>
<footnote confidence="0.936327">
9 Actually, a somewhat smaller subset of the Cartesian product is formed, since translations with
repeated words are eliminated from consideration. Such word groups very rarely correspond to a valid
collocation.
</footnote>
<page confidence="0.991576">
19
</page>
<note confidence="0.575173">
Computational Linguistics Volume 22, Number 1
</note>
<subsectionHeader confidence="0.954404">
5.1 Computational and Implementation Features
</subsectionHeader>
<bodyText confidence="0.999944153846154">
Considering the size of the corpora that must be handled by Champollion, special care
has been taken to minimize the number of disk accesses made during processing. We
have experimented on up to two full years of the Hansards corpus, amounting to
some 640,000 sentences in each language or about 220 megabytes of uncompressed
text. With corpora of this magnitude, Champollion takes between one and two minutes
to translate a collocation, thus enabling its practical use as a bilingual lexicography
tool.
To achieve efficient processing of the corpus database, Champollion is implemented
in two phases: the preparation phase and the actual translation phase. The preparation
phase reads in the database corpus and indexes it for fast future access using a com-
mercial B-tree package (Informix 1990). Each word in the original corpus is associated
with a set of pointers to all the sentences containing it and to the positions of the word
in each of these sentences. The frequency of each word (in sentences) is also computed
at this stage. Thus, all the necessary information is collected from the corpus database
at this preprocessing phase with only one pass over the corpus file. At the translation
phase, only the indices are accessed.
For the translation phase, we developed an algorithm that avoids computing the
Dice coefficient for French words when the result must necessarily fall below the
threshold. Using the index file on the English part of the corpus, we collect all French
sentences that match the source collocation, and produce a list of all words that appear
in these sentences, together with their frequency (in sentences) in this subset of the
French corpus. This operation takes only a few seconds to perform, and yields a list
of a few thousand French words. The list also contains the local frequency of these
words (i.e., frequency within this subset of the French corpus), and is sorted by this
frequency in decreasing order. We start from the top of this list and work our way
downwards until we find a word that fails either of the following tests:
</bodyText>
<listItem confidence="0.871581">
1. The word&apos;s local frequency is lower than the threshold Tf.
2. The word&apos;s local frequency is so low that we know it would be
impossible for the Dice coefficient between it and the source collocation
to be higher than the threshold Td.
</listItem>
<bodyText confidence="0.99994605882353">
Once a word fails one of the above tests, we are guaranteed that all subsequent
words in the list (with lower local frequencies) will also fail the same test. By applying
these two tests and removing all closed-class words from the list, we greatly reduce
the number of words that must be considered. In practice, about 90-98% of the words
in the list fail to meet the two tests above, so we dramatically reduce our search space
without having to perform any relatively expensive operations. For the remaining
words in the list, we need to compute their Dice coefficient value so as to select the
best-ranking one-word translation of the source collocation.
The first of the above tests is rather obviously valid and easy to apply. For the
second test, we compute an upper bound for the Dice coefficient between the word
under consideration and the source collocation. Let X and Y stand for the source
collocation and the French word under consideration, respectively, at some step of the
loop through the word list. At this point, we know the global frequency of the source
collocation (fx) and the local frequency of the candidate translation word (fxy), but
not the global frequency of the candidate word (fy). We need all these three quantities
to compute the Dice coefficient, but while fx is computed once for all Y, and it is
very efficient to compute fx y at the same time as the set of sentences matching X is
</bodyText>
<page confidence="0.9544">
20
</page>
<note confidence="0.780948">
Smadja, McKeown, and Hatzivassiloglou Translating Collocations for Bilingual Lexicons
</note>
<bodyText confidence="0.995714166666667">
identified, it is more costly to find fy even if a special access structure is maintained. So,
we first check whether there is any possibility that this word correlates with the source
collocation highly enough to pass the Dice threshold by assuming temporarily that the
word does not appear at all outside the sentences matching the source collocation. By
setting fy=fxy, we can efficiently compute the Dice coefficient between X and Y under
this assumption:
</bodyText>
<equation confidence="0.466104">
2 fxY 2 fxr
Dicea(X, fx fy fx + fxY
</equation>
<bodyText confidence="0.999402636363636">
Of course, this assumption most likely won&apos;t be true. But since we know that
fxY &lt; fy, it follows that Dicea(X,Y) is never less than the true value of the Dice co-
efficient between X and Y.1° Comparing Dicea(X,Y) with the Dice threshold Td will
only filter out words that are guaranteed not to have a high enough Dice coefficient
value independently of their overall frequency fy; thus, this is the most efficient pro-
cess for this task that also guarantees correctness.&apos; Another possible implementation
involves representing the words as integers using hashing. Then it would be possible
to compute fy and the Dice coefficient in linear time. Our method, in comparison,
takes 0(n log n) time to sort n candidates by their local frequency fxy, but it retrieves
the frequency fy and computes the Dice coefficient for a much smaller percentage of
them.
</bodyText>
<subsectionHeader confidence="0.852535">
6. Analysis of Champollion&apos;s Heuristic Filtering Stage
</subsectionHeader>
<bodyText confidence="0.999349157894737">
In this section, we analyze the generative capacity of our algorithm. In particular, we
compare it to the obvious method of exhaustively generating and testing all possible
groups of k words, with k varying from 1 to some maximum length of the translation in.
Our concern is whether our algorithm will actually generate all valid translations—
those with final Dice coefficient above the threshold—while it is clear that the exhaus-
tive algorithm would.&apos; Does the filtering process we use sometimes cause our algo-
rithm to omit a valid translation? In other words, is there a possibility that a group
of words has high similarity with the source collocation (above the threshold) and at
the same time one or more of its subgroups have similarity below the threshold? In
the worst case, as we show below, the answer to this question is affirmative. How-
ever, if only very few translations are missed in practice, the algorithm is indeed a
good choice. In this section, we first show why the filtering we use is necessary and
how it can miss valid translations, and then present the results of Monte Carlo sim-
ulation experiments (Rubenstein 1981) showing that with appropriate selection of the
threshold, the algorithm misses very few translations, that this rate of failure can be
reduced even more by using different thresholds at each level, and that the missed
translations are in general the less interesting ones, so that the rejection of some of the
valid (according to the Dice coefficient) translations most likely leads to an increase of
Champollion&apos;s performance.
</bodyText>
<footnote confidence="0.966529">
10 And actually is a tight upper bound, realized when fx..),y=i = 0.
11 Heuristic filtering of words with low local frequency may be more or less efficient, depending on the
word, but a higher percentage of discarded words will come at the cost of inadvertently throwing out
some valid words.
12 In this section we refer to missed valid translations or failures, using these terms to describe
candidate translations that are above the Dice threshold but are nevertheless rejected due to the
non-exhaustive algorithm we use. These candidate translations are not necessarily correct translations
from a performance perspective.
</footnote>
<page confidence="0.998281">
21
</page>
<note confidence="0.575126">
Computational Linguistics Volume 22, Number 1
</note>
<subsectionHeader confidence="0.905518">
6.1 Why is Filtering Necessary?
</subsectionHeader>
<bodyText confidence="0.99994325">
The exhaustive algorithm described above suffers from two disadvantages: First, the
only guaranteed correct value of m is the number of words Q in the target language
that have been selected in Stage 1 as viable candidate translations and pass the Dice
coefficient test as single words (see Section 5.1). This set of words typically contains
100-120 words, so enumerating all its subsets is impractical. But even if we artificially
impose some lower ceiling for m—say three times the length of the source language
collocation—we run into the second, and more severe, problem of the exhaustive
approach. We need to consider
</bodyText>
<equation confidence="0.989191">
(Ic) + (Q2) + (in&apos;)
</equation>
<bodyText confidence="0.99978105">
candidate translations. With typical values of Q = 110 and m = 10, which we ob-
served in our corpus, the above formula evaluates to 5.2. 1013, or more than 50 trillion
candidate translations. Clearly, we need to reduce this number to a more practical
value.
Our algorithm achieves this reduction by filtering out groups of words not having
a high similarity with the source collocation, assuming that such groups will not be
part of the translation. Let ri (i &gt; 2) be the fraction of proposed translations with i
words which pass the threshold Td. Let 131 be the number of translations with i words
that are examined by Champollion, and Si the number of these translations that actually
survive the thresholds and will be used to generate the candidate translations with i +1
words. Clearly, Si =-- P1 Q, P2 = (?), and Si = ri • P, for i &gt; 2. During the generation
of the candidate translations of length i + 1 (i &gt; 2), each of the Si translations of
length i can combine with Q - i single words that are sufficiently correlated with the
source language collocation, generating Q - i possible translations of length i +1, since
Champollion does not consider translations that include repeated words. However, there
are up to i + 1 different ways that the same set of i +1 words can be generated in this
manner; for example, (ABC) can be generated by adding C to (AB), adding B to (AC),
or adding A to (BC). When the set of translations of length i has been filtered, it is
possible that not all of the i + 1 ways to generate a given translation of length i + 1
are available. In general, we have
</bodyText>
<equation confidence="0.892868642857143">
si•Q. &lt; Pi+i &lt; Si • (Q — i)
+ —
Solving the recurrences specifying the upper and lower bounds together with the
equations S, = r,P, for i &gt; 2 and the boundary conditions Si = P1 = Q and P2 = (?),
we get, for the lower bound (i &gt; 3),
Pi &gt; (ri_1ri_2• fir (Q 2)(Q - 3) (Q - i 1)
j=2
• • r2) .P2. (Q +
3 4 i
Q(Q - 1) (Q - 2)(Q - 3)
2 3•4 i
Q!
i!(Q = (1-1 ri)
j=2 j=2
</equation>
<page confidence="0.98986">
22
</page>
<note confidence="0.808539">
Smadja, McKeown, and Hatzivassiloglou Translating Collocations for Bilingual Lexicons
</note>
<bodyText confidence="0.972439647058823">
and with a similar derivation, for the upper bound (i &gt; 3),
.Pi &lt; Hi) 2(Q 01
The sums of the bounds on the values Pi for i = 3 to m, plus the value P1 + P2 =
Q + (?), give upper and lower bounds on the total number of candidate translations
generated and examined by Champollion. When the r,&apos;s are high, the actual number of
candidate translations will be close to the lower bound. On the other hand, low val-
ues for the ri&apos;s (i.e., a low threshold Td) will result in the actual number of candidate
translations being close to the upper bound. To estimate the average number of candi-
date translations examined, we make the simplifying assumption that the decisions to
reject each candidate translation with i words are made independently with constant
probability ri. Under these assumptions, the probability of generating a particular
candidate translation with i words is the same for all translations with length i; the
same applies to the probability Ai that a translation with i words is included in the
set of translations of length i that will generate the candidate translations of length
i + 1. Clearly, A1 =- yi = = 1 and Ai = rai for i &gt; 2. For a particular translation with
i &gt; 3 words to be generated, at least one of its i subsets with i — 1 words must have
survived the threshold. With our assumptions, we have
</bodyText>
<equation confidence="0.766994">
-yi = 1 — (1 —
</equation>
<bodyText confidence="0.999938625">
From this recurrence equation and the boundary conditions given above we can
compute the values of and A, for all i. Then the expected (average) number of
candidate translations with i &gt; 3 words examined by Champollion will be
and the sum of these terms for i = 3 to m, plus the terms Q and (?), gives the total
complexity of our algorithm. In Table 6 we show the number of candidate transla-
tions examined by the exhaustive algorithm and the corresponding best-, worst-, and
average-case behavior of Champollion for several values of Q and m, using empirical
estimates of the ri&apos;s.
</bodyText>
<subsectionHeader confidence="0.999935">
6.2 Effects of the Filtering Process
</subsectionHeader>
<bodyText confidence="0.999977785714286">
We showed above that filtering is necessary to bring the number of proposed transla-
tions down to manageable levels. For any corpus of reasonable size, we can find cases
where a valid translation is missed because a part of it does not pass the threshold. Let
N be the size of the corpus in terms of matched sentences. Separate the N sentences
into eight categories, depending on whether each of the source collocation (X) and the
partial translations (i.e., A and B) appear in it. Let the counts of these sentences be
11ABx, nAB)--c, •, nag, where a bar indicates that the corresponding term is absent.
We can then find values of the n. &apos;s that cause the algorithm to miss a valid translation
as long as the corpus contains a modest number of sentences. This happens when one
or more of the parts of the final translation appear frequently in the corpus but not
together with the other parts or the source collocation. This phenomenon occurs even
if we are allowed to vary the Dice thresholds at each stage of the algorithm. With our
current constant Dice threshold Td = 0.1, we may miss a valid translation as long as
the corpus contains at least 20 sentences.
</bodyText>
<page confidence="0.997239">
23
</page>
<note confidence="0.536878">
Computational Linguistics Volume 22, Number 1
</note>
<tableCaption confidence="0.986289">
Table 6
</tableCaption>
<table confidence="0.938237785714286">
Candidate translations examined by the exact and approximate algorithms for representative
word set sizes and translation lengths.
Words Maximum Exhaustive Champollion&apos;s algorithm
translation algorithm
length
Best Worst Average
50 5 2.37• 106 2,884 14,302 13,558
10 1.34 • 1010 2,888 15,870 15,032
75 5 1.85. 107 9,696 75,331 71,129
10 9.74 . 1011 9,748 96,346 90,880
100 5 7.94 . 107 24,820 259,873 244,950
10 1.94 • 1013 25,127 391,895 369,070
150 5 6.12 • 108 104,331 1,589,228 1,496,041
10 1.26• 1015 108,057 3,391,110 3,190,075
</table>
<bodyText confidence="0.990696">
While our algorithm will necessarily miss some valid translations, this is a worst
case scenario. To study the average-case behavior of our algorithm, we simulated
its performance with randomly selected points with integer non-negative coordinates
</bodyText>
<equation confidence="0.8858295">
(n ABX n ABX nAsx, nAFnAtoc, n 11Apx) from the hyperplane defined by the equation
n ABX + nABX 4- n ABX n ABX n ABX nABX nAr3x = No
</equation>
<bodyText confidence="0.973618772727273">
where No is the number of &amp;quot;interesting&amp;quot; sentences in the corpus for the translation
under consideration, that is, the number of sentences that contain at least one of X,
A, or B.13 Sampling from this six-dimensional polytope in seven-dimensional space is
not easy. We accomplish it by constructing a mapping from the uniform distribution
to each allowed value for the n...&apos;s, using combinatorial methods. For example, for
No = 50, there are 3,478,761 different points with 11ABx = 0 but only one with nABX = 50.
Using the above method, we sampled 20,000 points for each of several values for
No (N0 = 50, 100, 500, and 1000). The results of the simulation were very similar for the
different values of No, with no apparent pattern emerging as No increased. Therefore,
in the following we give averages over the values of No tried.
We first measured the percentage of missed valid translations when either A or B,
or both, do not pass the threshold but AB should, for different values of the threshold
parameter (solid line in Figure 3). We observed that for low values of the threshold,
less than 1% of the valid translations are missed; for example, for the threshold value
of 0.10 we currently use, the error rate is 0.74%. However, as the threshold increases,
the rate of failure can become unacceptable.
A higher value for the threshold has two advantages: First, it offers higher se-
lectivity, allowing fewer false positives (proposed translations that are not considered
13 Note that the number of sentences that do not contain any of X, A, or B does not enter any of the Dice
coefficients computed by Champollion and consequently does not affect the algorithm&apos;s decisions. As
discussed in Section 4, this gives a definite advantage to the Dice method over other measures of
similarity.
</bodyText>
<page confidence="0.995881">
24
</page>
<figure confidence="0.9273832">
Smadja, McKeown, and Hatzivassiloglou Translating Collocations for Bilingual Lexicons
a=1
o -
a=4/5/-
............
7.. .. ....................
•••••••••,...,1=ng=-=‘=.= ....... ...... .... ................
a=1/2
0.05 0.20 0.40 0.60 0.80 0.95
Final threshold
</figure>
<figureCaption confidence="0.934984">
Figure 3
</figureCaption>
<bodyText confidence="0.986486333333333">
Failure rate of the translation algorithm with constant and increasing thresholds. The case
a = 1 (solid line) represents the basic algorithm with no threshold changes.
accurate by the human judges). Second, it speeds up the execution of the algorithm, as
all fractions r!&apos;s decrease and the overall number of candidate translations is reduced.
However, as Figure 3 shows, high values of the threshold parameter cause the algo-
rithm to miss a significant percentage of valid translations. Intuitively, we expect this
problem to be alleviated if a higher threshold value is used for the final admittance
of a translation, but a lower threshold is used internally when the subparts of the
translation are considered. Our second simulation experiment tested this expectation
for various values of the final threshold using a lower initial threshold equal to a
constant a &lt; 1 times the final threshold. The results are represented by the remaining
curves of Figure 3. Surprisingly, we found that with moderate values of a (close to
1) this method gives a very low failure rate even for high final threshold values, and
is preferable to using a constant but lower threshold just to reduce the failure rate.
For example, running the algorithm at an initial threshold of 0.3 and a final threshold
of 0.6 gives a failure rate of 0.45%, much less than the failure rate of 6.59% which
corresponds to a constant threshold of 0.3 for both stages.&apos;
The above analyses show that the algorithm fails quite rarely when the threshold
is low, and its performance can be improved with a sequence of increasing thresholds.
We also studied cases where the algorithm does fail. For this purpose, we stratified
14 The curves in Figure 3 become noticeably less smooth for values of the final threshold that are greater
than 0.8. This happens for all settings of a in Figure 3. This apparently different behavior for high
threshold values can be traced to sampling issues. Since few of the 20,000 points in each sample meet
the criterion of having Dice(AB, X) greater or equal to the threshold for high final threshold values, the
estimate of the percentage of failures is more susceptible to random variation in such cases.
Furthermore, since the same sample (for a given No) is used for all values of a, any such random
variation due to small sample size will be replicated in all curves of Figure 3.
</bodyText>
<page confidence="0.998253">
25
</page>
<figureCaption confidence="0.678197666666667">
Figure 4
Failure rate of the translation algorithm according to the Dice coefficient between the partial
translations.
</figureCaption>
<bodyText confidence="0.999955928571429">
our samples into five groups, based on the Dice coefficient between the two parts A
and B (which does not directly enter the computations of the algorithm). Figure 4
shows the failure rate for the groups of low (0 to 0.2), middle (0.4 to 0.6), and high (0.8
to 1) Dice(A,B) values, using the same threshold at both levels. We observe that the
algorithm tends to fail much less frequently when the two parts of the final translation
are strongly related. But this is desirable behavior, since a strong correlation between
the two subparts of the word group indicates that it is indeed a collocation in the target
language. Therefore, failures of the algorithm act, to some extent, as an (unintentional)
filter, rejecting uninteresting translations that would otherwise have been accepted by
the exhaustive method. Table 7 shows sample results from the simulation experiments,
summarizing Figures 3 and 4 for several representative cases. The first column gives
the threshold used at the second level, while the second through fourth columns show
failure rates for various values of a. For example, the second column shows failure
rates when the same threshold is used for both levels.
</bodyText>
<sectionHeader confidence="0.96872" genericHeader="method">
7. Results and Evaluation
</sectionHeader>
<bodyText confidence="0.921603857142857">
We evaluated Champollion in several separate trials, varying the collocations provided
as input and the database corpora used as reference. We used three different sets
of collocations as input, each taken from a different year of the English half of the
Hansards corpus!&apos; We tested these collocations on database corpora of varying size
15 We limited the evaluation of Champollion to three types of collocations, Noun-Noun (Chamber of
Commerce), Verb-Noun (express hope), and Adjective-Noun (annual deficit) obtained using the first two
stages of XTRACT.
</bodyText>
<figure confidence="0.9947473">
Volume 22, Number 1
Computational Linguistics
0.05
0.20
0.40 0.60
Threshold
0
0
0.60
0.95
</figure>
<page confidence="0.992123">
26
</page>
<note confidence="0.950224">
Smadja, McKeown, and Hatzivassiloglou Translating Collocations for Bilingual Lexicons
</note>
<tableCaption confidence="0.998223">
Table 7
</tableCaption>
<table confidence="0.951290375">
Failure rate of several variants of the translation algorithm for representative thresholds.
Final a = 1 a = 3/4 a = 1/2 Low Dice(A, B) High Dice(A, B)
threshold (a = 1) (a = 1)
0.05 0.39% 0.05% 0.02% 1.80% 0.02%
0.10 0.89% 0.21% 0.04% 4.99% 0.11%
0.20 2.88% 0.70% 0.13% 25.26% 0.27%
0.40 12.42% 2.29% 0.26% 96.33% 2.08%
0.80 67.11% 10.79% 1.17% 100.00% 31.83%
</table>
<tableCaption confidence="0.999043">
Table 8
</tableCaption>
<figure confidence="0.8855558125">
Some translations produced by Champollion.
English Collocation French Translation Found by Champollion
additional costs
affirmative action
apartheid ... South Africa
collective agreement
demonstrate support
employment equity
free trade
freer trade
head office
health insurance
make ... decision
take ... steps
cotits supplementaires
action positive
</figure>
<figureCaption confidence="0.7521368">
apartheid ... afrique sud
convention collective
prouver ... adhesion
equite matiere emploi
libre-echange
liberalisation ... echanges
siege social
assurance-maladie
prendre decision
prendre mesures
</figureCaption>
<bodyText confidence="0.999852625">
and year, taken from the aligned Hansards. Table 8 illustrates the range of translations
which Champollion produces. Flexible collocations are shown with ellipsis points (... )
indicating where additional, variable words could appear. These examples show cases
where a two word collocation is translated as one word (e.g., health insurance), a two
word collocation is translated as three words (e.g., employment equity), and how words
can be inverted in the translation (e.g., additional costs). In this section, we discuss the
design of the separate tests and our evaluation methodology, and present the results
of our evaluation.
</bodyText>
<subsectionHeader confidence="0.999499">
7.1 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.999985583333333">
We carried out three tests with Champollion using two database corpora and three
sets of source collocations. The first database corpus (DB1) consists of 8 months of
Hansards aligned data taken from 1986 (16 megabytes, 3.5 million words) and the
second database corpus (DB2) consists of all of the 1986 and 1987 transcripts of the
Canadian Parliament (a total of approximately 45 megabytes and 8.5 million words).
For the first corpus (DB1), we ran XTRACT and obtained a set of approximately 3,000
collocations from which we randomly selected a subset of 300 for manual evaluation
purposes. The 300 collocations were selected from among the collocations of mid-range
frequency—collocations appearing more than 10 times in the corpus. We call this first
set of source collocations Cl. The second set (C2) is a set of 300 collocations similarly
selected from the set of approximately 5,000 collocations identified by XTRACT on all
data from 1987. The third set of collocations (C3) consists of 300 collocations selected
</bodyText>
<page confidence="0.994828">
27
</page>
<note confidence="0.714713">
Computational Linguistics Volume 22, Number 1
</note>
<bodyText confidence="0.999098121212121">
from the set of approximately 5,000 collocations identified by XTRACT on all data from
1988. We used DB1 with both Cl (experiment 1) and C2 (experiment 2) and we used
DB2 with C3 (experiment 3).
We asked three fluent bilingual speakers to evaluate the results for the different
experiments. The evaluators first examined the source collocation, validating that it in-
deed was a word group exhibiting semantic coherence. Source collocations that seemed
incorrect (i.e., mistakenly identified as collocations by XTRACT) were removed from
further consideration. The evaluators then classified the translations of the remaining
collocations as either correct or incorrect. In this way, we decoupled the evaluation of
Champollion from the errors made by XTRACT.
It is clear that our classification scheme is not perfect because some cases are
difficult to judge. The judges were not especially familiar with the institutionalized
differences between Canadian French and continental French (which is the form of
French they speak). For example, without knowledge of Canadian French, it is difficult
to judge if the translation of affirmative action is action positive since this term is not used
in other forms of French.
One of the biggest problems for the evaluators was scoring translations of colloca-
tions with prepositions and articles. Champollion does not translate closed-class words
such as prepositions and articles. Their frequency is so high in comparison to open-
class words that including them in the candidate translations causes problems with
the correlation metric. Evaluators generally counted a translation as incorrect if it did
not contain a preposition or article when it should have. There is one exception to this
general rule: When the translation should have included one closed-class word, it was
obvious what that word should be, it occurred in one empty slot in the phrase, and
Champollion produced a rigid collocation with an empty slot at that position; and with
the correct open-class words, they judged the translation correct. It is exactly in these
cases that the closed-class word could easily be filled in when examining samples in the
corpus to determine word ordering. Since the collocation is rigid, the same preposition
or article occurs in most cases, so it could be extracted from the samples along with
word ordering. For example, when judging the translation of assistance program into
programme X aide the judges knew that the missing word (X) was d&apos; even without look-
ing at the corpus. In Section 9, we describe a later version of Champollion in which we
added the capability to identify these types of closed-class words during the last stage.
</bodyText>
<subsectionHeader confidence="0.999915">
7.2 Evaluation Results
</subsectionHeader>
<bodyText confidence="0.999916384615385">
The results of the evaluation experiments are given in Table 9. The first column de-
scribes the experiment, the second column gives the percentage of XTRACT errors,
and the next two columns give the percentages of incorrect and correct translations
of source collocations in comparison to the total number of collocations. Since our
previous work shows that XTRACT has a rate of accuracy of 80% (Smadja 1991b), it
is reasonable to expect a certain number of errors in the input to Champollion, but
these should not contribute to the evaluation of Champollion. Consequently, we have
included in the last column of the table the percentage of correct translations produced
by Champollion in comparison to the total number of valid collocations supplied to it;
namely, the percentage of Champ°llion&apos;s correct translations if XTRACT&apos;S errors are fil-
tered from the input. This quantity is equal to the ratio of the fourth column over the
sum of the third and fourth columns.&apos;
The accuracy figures shown in Table 9 are computed by averaging the scores
</bodyText>
<footnote confidence="0.6926005">
16 The results in the table were computed with higher precision intermediate figures; the figures shown
have been rounded to integers.
</footnote>
<page confidence="0.995285">
28
</page>
<note confidence="0.966747">
Smadja, McKeown, and Hatzivassiloglou Translating Collocations for Bilingual Lexicons
</note>
<tableCaption confidence="0.998267">
Table 9
</tableCaption>
<table confidence="0.9877653">
Results of our evaluations.
Experiment Invalid Source Valid Source Collocations Champollion&apos;s
Collocations Precision
(XTRACT errors)
Incorrect Correct
Translations Translations
Cl /DB1 11% 19% 70% 78%
C2/DB1 11% 31% 58% 65%
C3/DB2 10% 23% 66% 74%
Average 11% 24% 65% 73%
</table>
<bodyText confidence="0.9998576">
of the three individual judges. However, we noted that the scores of the individual
evaluators never varied by more than 2%, thus showing high agreement between the
judges.&apos; Such results indicate that, in general, there is a single correct answer in each
case, verifying the hypothesis of a unique translation per collocation independently of
context, which we postulated in Section 4. They also indicate that it is generally easy
for the evaluators to identify this unique correct answer.
When there is not a single correct answer, or when it is not easy for the evaluators
to identify the correct answer, it is prudent to guard against the introduction of (usually
pro-system) bias by asking the evaluators to produce their answers independently of
the system&apos;s output, as we have argued elsewhere (Hatzivassiloglou and McKeown
1993; Hatzivassiloglou in press). However, for the problem at hand, the uniqueness
and accessibility of the correct answer greatly alleviates&apos; the danger of introducing
bias by letting the evaluators grade the translations produced by Champollion. Since
the latter method makes more efficient use of the judges, we decided to adopt it for
our evaluation.
Among the three experiments described above, our best results are obtained when
the database corpus is also used as the corpus from which XTRACT identifies the source
language collocations (experiment Cl /DB1). In this case, not counting XTRACT errors,
accuracy is rated at 78%. It should be noted that the thresholds used by Champol-
lion were determined by experimenting on a separate data set. Since determining the
thresholds is the only training required for our statistical method, using the same cor-
pus as both the database and the source of input collocations is not a case of testing
on the training data.
The second experiment yielded the lowest results because many input collocations
simply did not appear often enough in the database corpus. However, we suspected
that this could be corrected by using a larger database corpus!&apos; Thus, for our third
experiment, we used DB2, which contained two years of the Hansards (1986 and 1987),
and drew our input collocations from yet a different year (1988). Evaluation on this
third experiment raised the accuracy to nearly as high as the first experiment, yielding
74%.
</bodyText>
<footnote confidence="0.9783428">
17 It should be noted that the judges worked independently of each other without conferring.
18 Another factor that could affect the performance of Champollion in this case is that we use the same
frequency and Dice thresholds independently of the size of the corpus. As we noted in Section 5,
adjusting the values of these thresholds when a new database corpus is employed may result in
improved performance.
</footnote>
<page confidence="0.996258">
29
</page>
<note confidence="0.6552">
Computational Linguistics Volume 22, Number 1
</note>
<sectionHeader confidence="0.602123" genericHeader="method">
8. Applications
</sectionHeader>
<bodyText confidence="0.999915795918368">
A bilingual lexicon of collocations has a variety of potential uses. The most obvious
are machine translation and machine-assisted human translation, but other multilin-
gual applications, including information retrieval, summarization, and computational
lexicography, also require access to bilingual lexicons.
While some researchers are attempting machine translation through purely sta-
tistical techniques, the more common approach is to use some hybrid of interlingual
and transfer techniques. These symbolic machine translation systems must have ac-
cess to a bilingual lexicon and the ability to construct one semi-automatically would
ease the development of such systems. Champollion is particularly promising for this
purpose for two reasons. First, it constructs translations for multiword collocations.
Collocations are known to be opaque; that is, their meaning often derives from the
combination of the words and not from the meaning of the individual words them-
selves. As a result, translation of collocations cannot be done on a word-by-word basis,
and some representation of collocations in both languages is needed if the system is to
translate fluently. Second, collocations are domain dependent. Particularly in techni-
cal domains, the collocations differ from those in general use. Accordingly, the ability
to automatically discover collocations for a given domain by using a new corpus as
input to Champollion would ease the work required to transfer an MT system to a new
domain.
Multilingual systems are now being developed in addition to pure machine trans-
lation systems. These systems also need access to bilingual phrases. We are currently
developing a multilingual summarization system, in which we will use the results
from Champollion. An early version of this system (McKeown and Radev 1995) pro-
duces short summaries of multiple news articles covering the same event using as
input the templates produced by information extraction systems developed under the
ARPA message understanding program. Since some information extraction systems,
such as General Electric&apos;s NLToolset (Jacobs and Rau 1990), already produce similar
representations for Japanese and English news articles, the addition of an English
summary generator will automatically allow for English summarization of Japanese.
In addition, we are planning to add a second language for the summaries. While the
output is not a direct translation of input articles, collocations that appear frequently
in the news articles will also appear in summaries. Thus, a list of bilingual collocations
would be useful for the summarization process.
Information retrieval is another prospective application. As shown in Maarek and
Smadja (1989) and more recently in Broglio et al. (1995), the precision of information
retrieval systems can be improved through the use of collocations in addition to the
more traditional single word indexing units. A collocation gives the context in which
a given word was used, which will help retrieve documents using the word with
the same sense and thus improve precision. The well-known New Mexico example in
information retrieval describes an oft-encountered problem when single word searches
are employed: searching for new and Mexico independently will retrieve a multitude of
documents that do not relate to New Mexico. Automatically identifying and explicitly
using collocations such as New Mexico at search or indexing time can help solve this
problem. We have licensed XTRACT to several sites that are using it to improve the
accuracy of their retrieval or text categorization systems.
A bilingual list of collocations could be used for the development of a multilingual
information retrieval system. In cases where the database of texts includes documents
written in multiple languages, the search query need only be expressed in one lan-
guage. The bilingual collocations could be used to translate the query (particularly
</bodyText>
<page confidence="0.993133">
30
</page>
<note confidence="0.856336">
Smadja, McKeown, and Hatzivassiloglou Translating Collocations for Bilingual Lexicons
</note>
<bodyText confidence="0.999852071428571">
given that it may consist of collocations in addition to single words) from the input
language to other languages in the database.
Another potential application, as demonstrated by Dagan and Church (1994), is
machine-aided human translation. For this scenario, when a translator begins work
on a collocation inside a translation editor, the translation produced by Champollion
could be provided as a prompt giving the translator the opportunity to approve it.
In such cases, it may be useful to provide the top several translations produced by
Champollion allowing the translator to choose the best, as Dagan and Church do.
Finally, Champollion could also be used for computer-assisted lexicography. Since
its output includes the translation of 1 to n word phrases, Champollion could be used
to automatically translate lexicons. While it could not translate sentences that are often
used in dictionaries as examples, it could be used for translation of both individual
words and phrases. In this way, a list of translated words could be produced auto-
matically from a monolingual dictionary and filtered by a lexicographer.
</bodyText>
<sectionHeader confidence="0.96915" genericHeader="method">
9. Future Work
</sectionHeader>
<bodyText confidence="0.996983866666667">
Champollion is one of the first attempts at translating lexical constructions using sta-
tistical techniques and our work has several limitations, which will be addressed in
future work. In this section we describe some of them and we give possible directions
for future research.
Translating closed class words. In the experiments described in this paper, Champol-
lion produced only partial collocations in the target language, because we eliminated
closed-class words from our indices. There are two reasons for eliminating such words.
First, they are very frequent and appear in almost any context, so that using them
would blur our statistics. The second reason is one of time and space efficiency: since
these words appear in many sentences in the corpus database, it is economical to re-
move them from the indices. However, this causes Champollion to produce only partial
collocations, for example, to cause havoc gets translated as semer[0], desarrois[2]. The po-
sition numbers indicate that a word is missing between the two French words. This
word is the article le, and the full collocation is semer le desarrois. We implemented an
extension that checks the positions around the words of a rigid collocation.&amp;quot; Note that
for flexible collocations the words can occur in any order, separated by any number
of words, and therefore it is difficult to check whether the same close class word is
consistently used. Our extension checks one word to the left and to the right of the
collocation, plus any gaps between words. If the same preposition or article is found
to occur in the same position in 90% of the sentences in which the rigid collocation
occurs, it is added to the output. Note that if Champollion were to be used as part of
machine-assisted human translation, another option would be to produce a ranked
list of several prepositions or articles that are used in the corpus and let the translator
choose the best option.
This extension improves the fluency of the translations tremendously. For example,
employment equity is translated as equite en matiere d&apos; emploi with prepositions in place of
the empty slots shown in Table 8 on page 27. Table 10 shows a variety of translations
produced by this extension. While we have not yet completed a full evaluation of
these results, preliminary work using the evaluation of only one judge suggests that
our results improve substantially.
</bodyText>
<page confidence="0.7846325">
19 This extension was implemented by Ofer Wainberg, an MS student at Columbia University.
31
</page>
<note confidence="0.613135">
Computational Linguistics Volume 22, Number 1
</note>
<tableCaption confidence="0.99454">
Table 10
</tableCaption>
<table confidence="0.903655444444444">
Some translations with closed class words produced by Champollion.
English Collocation French Translation Found by Champollion
amount of money
capital gains
consumer protection
dispute settlement mechanism
drug abuse
employment equity
environmental protection
federal sales tax
somme d&apos; argent
gains en capital
la protection des consommateurs
mecanisme de reglement des differends
abus des drogues
equite en matiere d&apos;emploi
protection de l&apos; environnement
taxe de vente federale
</table>
<bodyText confidence="0.990147294117647">
Tools for the target language. Tools in French, such as a morphological analyzer, a tagger,
a list of acronyms, a robust parser, and various lists of tagged words, would be most
helpful and would allow us to improve our results. For example, a tagger for French
would allow us to run XTRACT on the French part of the corpus, and thus to translate
from either French or English as input. In addition, running XTRACT on the French part
of the corpus would allow for independent confirmation of the proposed translations,
which should be French collocations. Similarly, a morphological analyzer would allow
us to produce richer results, since several forms of the same word would be conflated,
increasing both the expected and the actual frequencies of the co-occurrence events;
this has been found empirically to have a positive effect in overall performance in
other problems (Hatzivassiloglou in press). Note that ignoring inflectional distinctions
can sometimes have a detrimental effect if only particular forms of a word participate
in a given collocation. Consequently, it might be beneficial to take into account both
the distribution of the base form and the differences between the distributions of the
various inflected forms.
In the current implementation of Champollion, we were restricted to using tools for
only one of the two languages, since at the time of implementation tools for French
were not readily available. However, from the above discussion it is clear that certain
tools would improve the system&apos;s performance.
Separating corpus-dependent translations from general ones. Champollion identifies trans-
lations for the source collocations using the aligned corpora database as its entire
knowledge of the two languages. Consequently, sometimes the results are specific to
the domain and seem peculiar when viewed in a more general context. For example,
we have already mentioned that Mr. Speaker was translated as Monsieur le Président,
which is obviously only valid for this domain. Canadian family is another example; it
is often translated as famille (the Canadian qualifier is dropped in the French version).
This is an important feature of the system, since in this way the sublanguage of the
domain is employed for the translation. However, many of the collocations that Cham-
pollion identifies are general, domain-independent ones. Champollion cannot make any
distinction between domain-specific and general collocations. What is clearly needed
is a way to determine the generality of each produced translation, as many transla-
tions found by Champollion are of general use and could be directly applied to other
domains. This may be possible by intersecting the output of Champollion on corpora
from many different domains.
</bodyText>
<page confidence="0.995134">
32
</page>
<note confidence="0.835373">
Smadja, McKeown, and Hatzivassiloglou Translating Collocations for Bilingual Lexicons
</note>
<bodyText confidence="0.998696416666667">
Handling low frequency collocations. The statistics we used do not produce good results
when the frequencies are low. This shows up clearly when our evaluation results on the
first two experiments are compared. Running the collocation set C2 over the database
DB1 produced our worst results, and this can be attributed to the low frequency
in DBI of many collocations in C2. Recall that C2 was extracted from a different
(and larger) corpus from DBI. This problem is due not only to the frequencies of
the source collocations or of the words involved but also to the frequencies of their
&amp;quot;official&amp;quot; translations. Indeed, while most collocations exhibit unique senses in a given
domain, sometimes a source collocation appearing multiple times in the corpus is not
consistently translated into the same target collocation in the database. This sampling
problem, which generally affects all statistical approaches, was not addressed in the
paper. We reduced the effects of low frequencies by purposefully limiting ourselves
to source collocations of frequencies higher than 10, containing individual words with
frequencies higher than 15.
Analysis of the effects of our thresholds. Various thresholds are used in Champollion&apos;s algo-
rithm to reduce the search space. A threshold too low would significantly slow down
the search as, according to Zipf&apos;s law (Zipf 1949), the number of terms occurring n
times in a general English corpus is a decreasing function of n2. Unfortunately, some-
times this filtering step causes Champollion to miss a valid translation. For example,
one of the incorrect translations made by Champollion is that important factor was trans-
lated into facteur (factor) alone instead of the proper translation facteur important. The
error is due to the fact that the French word important did not pass the first step of
the algorithm as its Dice coefficient with important factor was too low. Important occurs
a total of 858 times in the French part of the corpus and only 8 times in the right
context, whereas a minimum of 10 appearances is required to pass this step.
Although the theoretical analysis and simulation experiments of Section 6.2 show
that such cases of missing the correct translation are rare, more work needs to be
done in quantifying this phenomenon. In particular, experiments with actual corpus
data should supplement the theoretical results (based on uniform distributions). Fur-
thermore, more experimentation with the values of the thresholds needs to be done,
to locate the optimum trade-off point between efficiency and accuracy. An additional
direction for future experiments is to vary the thresholds (and especially the frequency
threshold Tf) according to the size of the database corpus and the frequency of the
collocation being translated.
Incorporating the length of the translation into the score. Currently our scoring method only
uses the lengths of candidate translations to break a tie in the similarity measure. It
seems, however, that longer translations should get a &amp;quot;bonus.&amp;quot; For example, using our
scoring technique the correlation of the collocation official languages with the French
word officielles is equal to 0.94 and the correlation with the French collocation langues
officielles is 0.95. Our scoring only uses the relative frequencies of the events without
taking into account that some of these events are composed of multiple single events.
We plan to refine our scoring method so that the length (number of words involved)
of the events is taken into account.
Using nonparallel corpora. Champollion requires an aligned bilingual corpus as input.
However, finding bilingual corpora can be problematic in some domains. Although
organizations such as the United Nations, the European Community, and governments
of countries with several official languages are big producers, such corpora are still
difficult to obtain for research purposes. While aligned bilingual corpora will become
</bodyText>
<page confidence="0.99574">
33
</page>
<note confidence="0.691732">
Computational Linguistics Volume 22, Number 1
</note>
<bodyText confidence="0.9999822">
more available in the future, it would be helpful if we could relax the constraint
for aligned data. Bilingual corpora in the same domain, which are not necessarily
translations of each other, are more easily available. For example, news agencies such
as the Associated Press and Reuters publish in several languages. News stories often
relate similar facts but they are not direct translations of one another. Even though
the stories probably use equivalent terminology, totally different techniques would
be necessary to be able to use such &amp;quot;nonalignable&amp;quot; corpora as databases. Ultimately,
such techniques would be more useful than those currently used, because they would
be able to extract knowledge from noisy data. While this is definitely a large research
problem, our research team at Columbia University has begun work in this area (Fung
and McKeown 1994) that shows promise for noisy parallel corpora (in which the
target corpus may contain either additional or deleted paragraphs and where the
languages themselves do not involve neat sentence-by-sentence translations). Bilingual
word correspondences extracted from nonparallel corpora with techniques such as
those proposed by Fung (1995a) also look promising.
</bodyText>
<sectionHeader confidence="0.957185" genericHeader="conclusions">
10. Conclusion
</sectionHeader>
<bodyText confidence="0.999860363636364">
We have presented a method for translating collocations, implemented in Champollion.
The ability to provide translations for collocations is important for three main reasons.
First, because they are opaque constructions, they cannot be translated on a word-by-
word basis. Instead, translations must be provided for the phrase as a whole. Second,
collocations are domain dependent. Each domain includes a variety of phrases that
have specific meanings and translations that apply only in the given domain. Finally,
a quick look at a bilingual dictionary, even for two widely studied languages such
as English and French, shows that correspondences between collocations in two lan-
guages are largely unexplored. Thus, the ability to compile a set of translations for a
new domain automatically will ultimately increase the portability of machine transla-
tion systems. By applying Champollion to a corpus in a new domain, translations for
the domain-specific collocations can be automatically compiled and inaccurate results
filtered by a native speaker of the target language.
The output of our system is a bilingual list of collocations that can be used in
a variety of multilingual applications. It is directly applicable to machine translation
systems that use a transfer approach, since such systems rely on correspondences be-
tween words and phrases of the source and target languages. For interlingua systems,
identification of collocations and their translations provide a means of augmenting
the interlingua. Since such phrases cannot be translated compositionally, they indi-
cate where concepts representing such phrases must be added to the interlingua. Such
bilingual phrases are also useful for other multilingual tasks, including information
retrieval of multilingual documents given a phrase in one language, summarization
in one language of texts in another, and multilingual generation.
Finally, we have carried out three evaluations of the system on three separate years
of the Hansards corpus. These evaluations indicate that Champollion has a high rate of
accuracy: in the best case, 78% of the French translations of valid English collocations
were judged to be good. This is a good score in comparison with evaluations carried
out on full machine translation systems. We conjecture that by using statistical tech-
niques to translate a particular type of construction, known to be easily observable in
language, we can achieve better results than by applying the same technique to all
constructions uniformly.
Our work is part of a paradigm of research that focuses on the development of tools
using statistical analysis of text corpora. This line of research aims at producing tools
</bodyText>
<page confidence="0.99284">
34
</page>
<note confidence="0.834427">
Smadja, McKeown, and Hatzivassiloglou Translating Collocations for Bilingual Lexicons
</note>
<bodyText confidence="0.99992475">
that satisfactorily handle relatively simple tasks. These tools can then be used by other
systems to address more complex tasks. For example, previous work has addressed
low-level tasks such as tagging a free-style corpus with part-of-speech information
(Church 1988), aligning a bilingual corpus (Gale and Church 1991b; Brown, Lai, and
Mercer 1991), and producing a list of collocations (Smadja 1993). While each of these
tools is based on simple statistics and tackles elementary tasks, we have demonstrated
with our work on Champollion that by combining them, one can reach new levels of
complexity in the automatic treatment of natural languages.
</bodyText>
<sectionHeader confidence="0.98351" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.988323045454546">
This work was supported jointly by the
Advanced Research Projects Agency and
the Office of Naval Research under grant
N00014-89—J-1782, by the Office of Naval
Research under grant N00014-95-1-0745, by
the National Science Foundation under
grant GER-90-24069, and by the New York
State Science and Technology Foundation
under grants NYSSTF—CAT(91)-053 and
NYSSTF—CAT(94)-013. We wish to thank
Pascale Fung and Dragomir Radev for
serving as evaluators, Thanasis Tsantilas for
discussions relating to the average-case
complexity of Champollion, and the
anonymous reviewers for providing useful
comments on an earlier version of the
paper. We also thank Ofer Wainberg for his
excellent work on improving the efficiency
of Champollion and for adding the
preposition extension, and Ken Church and
AT&amp;T Bell Laboratories for providing us
with a prealigned Hansards corpus.
</bodyText>
<sectionHeader confidence="0.992085" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999406256756757">
Bahl, Lalit R.; Brown, Peter F.; de Souza,
Peter V.; and Mercer, Robert L. (1986).
Maximum Mutual Information of Hidden
Markov Model Parameters for Speech
Recognition. In Proceedings, International
Conference on Acoustics, Speech, and Signal
Processing (ICASSP-86), Tokyo, Japan, 1:
49-52, IEEE Acoustics, Speech and Signal
Processing Society, Institute of Electronics
and Communication Engineers of Japan,
and Acoustical Society of Japan.
Benson, Morton (1985). &amp;quot;Collocations and
Idioms.&amp;quot; In Dictionaries, Lexicography, and
Language Learning, edited by Robert Ilson.
Pergamon Institute of English, Oxford,
England, 61-68.
Benson, Morton; Benson, Evelyn; and Ilson,
Robert. (1986). The BBI Combinatory
Dictionary of English: A Guide to Word
Combinations. John Benjamins, Amsterdam
and Philadelphia.
Berger, Adam L.; Brown, Peter F.; Della
Pietra, Stephen A.; Della Pietra, Vincent J.;
Gillet, John R.; Lafferty, John D.; Mercer,
Robert L.; Printz, Harry; and Ureg, Lubog.
(1994). The Candide System for Machine
Translation. In Proceedings, ARPA Workshop
on Human Language Technology, Plainsboro,
New Jersey, 157-162. ARPA Software and
Intelligent Systems Technology Office,
Morgan Kaufmann, San Francisco,
California.
Broglio, John; Callan, James P.; Croft,
W. Bruce; and Nachbar, Daniel W. (1995).
Document Retrieval and Routing Using
the INQUERY System. In Proceedings,
Third Text Retrieval Conference (TREC-3),
Gaithersburg, Maryland, 29-39. National
Institute of Standards and Technology
(NIST).
Brown, Peter E; Cocke, John; Della Pietra,
Stephen A.; Della Pietra, Vincent J.;
Jelinek, Fredrick; Lafferty, John D.;
Mercer, Robert L.; and Roosin, Paul S.
(1990). A Statistical Approach to Machine
Translation. Computational Linguistics,
16(2): 79-85.
Brown, Peter F.; Lai, Jennifer C.; and Mercer,
Robert L. (1991). Aligning Sentences in
Parallel Corpora. In Proceedings, 29th
Annual Meeting of the ACL, Berkeley,
California, 169-184. Association for
Computational Linguistics.
Brown, Peter F.; Della Pietra, Stephen A.;
Della Pietra, Vincent J.; and Mercer,
Robert L. (1991). Word-Sense
Disambiguation Using Statistical
Methods. In Proceedings, 29th Annual
Meeting of the ACL, Berkeley, California,
264-270. Association for Computational
Linguistics.
Brown, Peter E; Della Pietra, Stephen A.;
Della Pietra, Vincent J.; and Mercer,
Robert L. (1993). The Mathematics of
Statistical Machine Translation: Parameter
Estimation. Computational Linguistics,
19(2): 263-311.
Budge, E. A. Wallis. (1989). The Rosetta Stone.
Dover Publications, New York.
(Originally published as The Rosetta Stone
in the British Museum, Religious Tract
Society, London, 1929.)
Chen, Stanley F. (1993). Aligning Sentences
in Bilingual Corpora Using Lexical
</reference>
<page confidence="0.994808">
35
</page>
<note confidence="0.662452">
Computational Linguistics Volume 22, Number 1
</note>
<reference confidence="0.99948425409836">
Information. In Proceedings, 31st Annual
Meeting of the ACL, Columbus, Ohio, 9-16.
Association for Computational
Linguistics.
Church, Kenneth W. (1988). A Stochastic
Parts Program and Noun Phrase Parser
for Unrestricted Text. In Proceedings,
Second Conference on Applied Natural
Language Processing (ANLP-88), Austin,
Texas, 136-143. Association for
Computational Linguistics.
Church, Kenneth W. (1993). Char_align: A
Program for Aligning Parallel Texts at the
Character Level. In Proceedings, 31st
Annual Meeting of the ACL, Columbus,
Ohio, 1-8. Association for Computational
Linguistics.
Church, Kenneth W.; Gale, William A.;
Hanks, Patrick; and Hindle, Donald.
(1991). Using Statistics in Lexical
Analysis. In Lexical Acquisition: Using
On-line Resources to Build a Lexicon, edited
by Uri Zernik. Lawrence Erlbaum,
Hillsdale, New Jersey, 115-165.
Church, Kenneth W. and Hanks, Patrick.
(1990). Word Association Norms, Mutual
Information, and Lexicography.
Computational Linguistics, 16(1): 22-29.
Cover, Thomas M. and Thomas, Joy A.
(1991). Elements of Information Theory.
Wiley, New York.
Dagan, Ido and Church, Kenneth W. (1994).
Termight: Identifying and Translating
Technical Terminology. In Proceedings,
Fourth Conference on Applied Natural
Language Processing (ANLP-94), Stuttgart,
Germany, 34-40. Association for
Computational Linguistics.
Dagan, Ido; Church, Kenneth W.; and Gale,
William A. (1993). Robust Bilingual Word
Alignment for Machine-Aided
Translation. In Proceedings, Workshop on
Very Large Corpora: Academic and Industrial
Perspectives, Columbus, Ohio, 1-8.
Association for Computational
Linguistics.
Dagan, Ido and Itai, Alon. (1994). Word
Sense Disambiguation Using a Second
Language Monolingual Corpus.
Computational Linguistics, 20(4): 563-596.
Dagan, Ido; Itai, Alon; and Schwall, Ulrike.
(1991). Two Languages Are More
Informative Than One. In Proceedings, 29th
Annual Meeting of the ACL, Berkeley,
California, 130-137. Association for
Computational Linguistics.
Dagan, Ido; Marcus, Shaul; and Markovitch,
Shaul. (1993). Contextual Word Similarity
and Estimation from Sparse Data. In
Proceedings, 31st Annual Meeting of the ACL,
Columbus, Ohio, 164-171. Association for
Computational Linguistics.
Dice, Lee R. (1945). Measures of the
Amount of Ecologic Association between
Species. Journal of Ecology, 26: 297-302.
Dorr, Bonnie J. (1992). The Use of Lexical
Semantics in Interlingual Machine
Translation. Machine Translation, 7(3):
135-193.
van der Eijk, Pim. (1993). Automating the
Acquisition of Bilingual Terminology. In
Proceedings, Sixth Conference of the European
Chapter of the Association for Computational
Linguistics, Utrecht, The Netherlands,
113-119. Association for Computational
Linguistics.
Frakes, William B. and Baeza-Yates, Ricardo,
eds. (1992). Information Retrieval: Data
Structures and Algorithms. Prentice Hall,
Englewood Cliffs, New Jersey.
Fung, Pascale. (1995a). Compiling Bilingual
Lexicon Entries from a Non-Parallel
English-Chinese Corpus. In Proceedings,
Third Annual Workshop on Very Large
Corpora, Boston, Massachusetts, 173-183.
Fung, Pascale. (1995b). A Pattern Matching
Method for Finding Noun and Proper
Noun Translations from Noisy Parallel
Corpora. In Proceedings, 33rd Annual
Meeting of the ACL, Boston, Massachusetts,
236-243. Association for Computational
Linguistics.
Fung, Pascale and McKeown, Kathleen R.
(1994). Aligning Noisy Parallel Corpora
Across Language Groups: Word Pair
Feature Matching by Dynamic Time
Warping. In Proceedings, First Conference of
the Association for Machine Translation in the
Americas (ANITA), Columbia, Maryland,
81-88.
Gale, William A. and Church, Kenneth W.
(1991a). Identifying Word
Correspondences in Parallel Texts. In
Proceedings, DARPA Speech and Natural
Language Workshop, Pacific Grove,
California, 152-157. Morgan Kaufmann,
San Mateo, California.
Gale, William A. and Church, Kenneth W.
(1991b). A Program for Aligning
Sentences in Bilingual Corpora. In
Proceedings, 29th Annual Meeting of the ACL,
Berkeley, California, 177-184. Association
for Computational Linguistics.
Gale, William A. and Church, Kenneth W.
(1993). A Program for Aligning Sentences
in Bilingual Corpora. Computational
Linguistics, 19(1): 75-102.
Hatzivassiloglou, Vasileios. (in press). &amp;quot;Do
We Need Linguistics When We Have
Statistics? A Comparative Analysis of the
Contributions of Linguistic Cues to a
Statistical Word Grouping System.&amp;quot; In The
</reference>
<page confidence="0.967253">
36
</page>
<note confidence="0.686078">
Smadja, McKeown, and Hatzivassiloglou Translating Collocations for Bilingual Lexicons
</note>
<reference confidence="0.999785155737705">
Balancing Act: Combining Symbolic and
Statistical Approaches to Language, edited by
Judith L. Klavans and Philip Resnik. MIT
Press, Cambridge, Massachusetts.
Hatzivassiloglou, Vasileios and McKeown,
Kathleen R. (1993). Towards the
Automatic Identification of Adjectival
Scales: Clustering Adjectives According to
Meaning. In Proceedings, 31st Annual
Meeting of the ACL, Columbus, Ohio,
172-182. Association for Computational
Linguistics.
Informix. (1990). C-ISAM Programmer&apos;s
Manual. Informix Software, Inc., Menlo
Park, California.
Jacobs, Paul S. and Rau, Lisa F. (1990). The
GE NLToolset: A Software Foundation for
Intelligent Text Processing. In Proceedings,
13th International Conference on
Computational Linguistics (COLING-90),
edited by Hans Karlgren, Helsinki,
Finland, 3: 373-377.
Klavans, Judith L. and Tzoukermann,
Evelyne. (1990). The BICORD System:
Combining Lexical Information from
Bilingual Corpora and Machine Readable
Dictionaries. In Proceedings, 13th
International Conference on Computational
Linguistics (COLING-90), edited by Hans
Karlgren, Helsinki, Finland, 3: 174-179.
Klavans, Judith L. and Tzoukermann,
Evelyne. (1996). Combining Corpus and
Machine-Readable Dictionary Data for
Building Bilingual Lexicons. Machine
Translation, 10(2).
Kupiec, Julian M. (1993). An Algorithm for
Finding Noun Phrase Correspondences in
Bilingual Corpora. In Proceedings, 31st
Annual Meeting of the ACL, Columbus,
Ohio, 17-22. Association for
Computational Linguistics.
Leed, Richard L. and Nakhimovsky,
Alexander D. (1979). Lexical Functions
and Language Learning. Slavic and East
European Journal, 23(1): 104-113.
Maarek, Yoelle and Smadja, Frank. (1989).
Full Text Indexing Based on Lexical
Relations. An Application: Software
Libraries. In Proceedings, 12th Annual
International ACM SIGIR Conference on
Research and Development in Information
Retrieval, edited by Nicholas J. Belkin and
C. J. van Rijsbergen, Cambridge,
Massachusetts, 198-206.
McKeown, Kathleen R. and Radev,
Dragomir. (1995). Generating Summaries
of Multiple News Articles. In Proceedings,
18th Annual International ACM SIGIR
Conference on Research and Development in
Information Retrieval, edited by Edward A.
Fox, Peter Ingwersen, and Raya Fidel,
Seattle, Washington, 74-82.
Papoulis, Athanasios. (1984). Probability,
Random Variables, and Stochastic Processes.
McGraw-Hill, New York, 2nd edition.
Rubinstein, Reuven Y. (1981). Simulation and
the Monte Carlo Method. Wiley, New York.
Salton, Gerard and McGill, Michael J.
(1983). Introduction to Modern Information
Retrieval. McGraw-Hill, New York.
Shannon, Claude E. (1948). A Mathematical
Theory of Communication. Bell System
Technical Journal, 27: 379-423 and 623-656.
Shemtov, Hadar. (1993). Text Alignment in a
Tool for Translating Revised Documents.
In Proceedings, Sixth Conference of the
European Chapter of the Association for
Computational Linguistics, Utrecht, The
Netherlands, 449-453. Association for
Computational Linguistics.
Simard, Michel; Foster, George F.; and
Isabelle, Pierre. (1992). Using Cognates to
Align Sentences in Bilingual Corpora. In
Proceedings, Fourth International Conference
on Theoretical and Methodological Issues in
Machine Translation (TMI-92), Montreal,
Canada, 67-81.
Smadja, Frank. (1991a). Extracting
Collocations from Text. An Application:
Language Generation. Doctoral dissertation,
Department of Computer Science,
Columbia University, New York.
Smadja, Frank. (1991b). From N-grams to
Collocations: An Evaluation of Xtract. In
Proceedings, 29th Annual Meeting of the ACL,
Berkeley, California, 279-284. Association
for Computational Linguistics.
Smadja, Frank. (1992). How to Compile a
Bilingual Collocational Lexicon
Automatically. In Proceedings, AAAI-92
Workshop on Statistically-Based NLP
Techniques, Sari Jose, California, 65-71.
American Association for Artificial
Intelligence.
Smadja, Frank. (1993). Retrieving
Collocations From Text: Xtract.
Computational Linguistics, 19(1): 143-177.
Smadja, Frank and McKeown, Kathleen R.
(1990). Automatically Extracting and
Representing Collocations for Language
Generation. In Proceedings, 28th Annual
Meeting of the ACL, Pittsburgh,
Pennsylvania, 252-259. Association for
Computational Linguistics.
SOrensen, Thorvald J. (1948). A Method of
Establishing Groups of Equal Amplitude
in Plant Sociology Based on Similarity of
Species Content and its Application to
Analysis of the Vegetation of Danish
Commons. Biologiske Skrifter, 5(4): 1-34.
Su, Keh-Yih; Wu, Ming-Wen; and Chang,
Jing-Shin. (1994). A Corpus-based
</reference>
<page confidence="0.98321">
37
</page>
<note confidence="0.338461">
Computational Linguistics Volume 22, Number 1
</note>
<reference confidence="0.9939055">
Approach to Automatic Compound
Extraction. In Proceedings, 32nd Annual
Meeting of the ACL, Las Cruces, New
Mexico, 242-247. Association for
Computational Linguistics.
Wu, Dekai and Xia, Xuanyuin. (1994).
Learning an English-Chinese Lexicon
from a Parallel Corpus. In Proceedings,
First Conference of the Association for
Machine Translation in the Americas (AMTA),
Columbia, Maryland, 206-213.
Yarowsky, David. (1993). One Sense Per
Collocation. In Proceedings, ARPA
Workshop on Human Language Technology,
Plainsboro, New Jersey, 266-271. ARPA
Software and Intelligent Systems
Technology Office, Morgan Kaufmann,
San Francisco, California.
Zipf, George K. (1949). Human Behavior and
the Principle of Least Effort: An Introduction
to Human Ecology. Addison-Wesley,
Reading, Massachusetts.
</reference>
<page confidence="0.999346">
38
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.812474">
<title confidence="0.999693">Translating Collocations for Bilingual Lexicons: A Statistical Approach</title>
<author confidence="0.999894">Frank Smadja Kathleen R McKeownt</author>
<affiliation confidence="0.997048">NetPatrol Consulting Columbia University</affiliation>
<author confidence="0.89801">Vasileios Ha tzivassiloglout</author>
<affiliation confidence="0.99998">Columbia University</affiliation>
<abstract confidence="0.991070333333333">Collocations are notoriously difficult for non-native speakers to translate, primarily because they are opaque and cannot be translated on a word-by-word basis. We describe a program named given a pair of parallel corpora in two different languages and a list of collocations in one of them, automatically produces their translations. Our goal is to provide a tool for compiling bilingual lexical information above the word level in multiple languages, for different domains. The algorithm we use is based on statistical methods and produces p-word translations of collocations in which not be the same. For example, . . . decision, employment equity, market . . . decision, equite matiere d&apos;emploi, Testing three years&apos; worth of the Hansards corpus yielded the French translations of 300 collocations for each year, evaluated at 73% accuracy on average. In this paper, we describe the statistical measures used, the algorithm, the implementation of our results and evaluation.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>Lalit R Bahl</author>
<author>Peter F Brown</author>
<author>Peter V de Souza</author>
<author>Robert L Mercer</author>
</authors>
<title>Maximum Mutual Information of Hidden Markov Model Parameters for Speech Recognition.</title>
<date>1986</date>
<booktitle>In Proceedings, International Conference on Acoustics, Speech, and Signal Processing (ICASSP-86),</booktitle>
<volume>1</volume>
<pages>49--52</pages>
<location>Tokyo,</location>
<marker>Bahl, Brown, de Souza, Mercer, 1986</marker>
<rawString>Bahl, Lalit R.; Brown, Peter F.; de Souza, Peter V.; and Mercer, Robert L. (1986). Maximum Mutual Information of Hidden Markov Model Parameters for Speech Recognition. In Proceedings, International Conference on Acoustics, Speech, and Signal Processing (ICASSP-86), Tokyo, Japan, 1: 49-52, IEEE Acoustics, Speech and Signal Processing Society, Institute of Electronics and Communication Engineers of Japan, and Acoustical Society of Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Morton Benson</author>
</authors>
<title>Collocations and Idioms.&amp;quot; In Dictionaries, Lexicography, and Language Learning, edited by Robert Ilson. Pergamon Institute of English,</title>
<date>1985</date>
<pages>61--68</pages>
<location>Oxford, England,</location>
<contexts>
<context position="17072" citStr="Benson 1985" startWordPosition="2631" endWordPosition="2632">cated approach using multiple knowledge sources to address both one-to-many word translations and the problem of sense disambiguation. Given only one word in the source, their system, BICORD, uses the corpus to extend dictionary definitions and provide translations that are appropriate for a given sense but do not occur in the dictionary, producing a bilingual lexicon of movement verbs as output. 3. Collocations and Machine Translation Collocations, commonly occurring word pairs and phrases, are a notorious source of difficulty for non-native speakers of a language (Leed and Nakhimovsky 1979; Benson 1985; Benson, Benson, and Ilson 1986). This is because they cannot be translated on a word-by-word basis. Instead, a speaker must be aware of the meaning of the phrase as a whole in the source language and know the common phrase typically used in the target language. While collocations are not predictable on the basis of syntactic or semantic rules, they can be observed in language and thus must be learned through repeated usage. For example, in American English one says set the table while in British English the phrase lay the table is used. These are expressions that have evolved over time. It i</context>
</contexts>
<marker>Benson, 1985</marker>
<rawString>Benson, Morton (1985). &amp;quot;Collocations and Idioms.&amp;quot; In Dictionaries, Lexicography, and Language Learning, edited by Robert Ilson. Pergamon Institute of English, Oxford, England, 61-68.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Morton Benson</author>
<author>Evelyn Benson</author>
<author>Robert Ilson</author>
</authors>
<title>The BBI Combinatory Dictionary of English: A Guide to Word Combinations. John Benjamins,</title>
<date>1986</date>
<location>Amsterdam and Philadelphia.</location>
<marker>Benson, Benson, Ilson, 1986</marker>
<rawString>Benson, Morton; Benson, Evelyn; and Ilson, Robert. (1986). The BBI Combinatory Dictionary of English: A Guide to Word Combinations. John Benjamins, Amsterdam and Philadelphia.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Adam L Berger</author>
<author>Peter F Brown</author>
<author>Della Pietra</author>
<author>A Stephen</author>
<author>Della Pietra</author>
<author>J Vincent</author>
<author>John R Gillet</author>
<author>John D Lafferty</author>
<author>Robert L Mercer</author>
<author>Harry Printz</author>
<author>Lubog Ureg</author>
</authors>
<title>The Candide System for Machine Translation.</title>
<date>1994</date>
<booktitle>In Proceedings, ARPA Workshop on Human Language Technology,</booktitle>
<publisher>Morgan Kaufmann,</publisher>
<location>Plainsboro, New Jersey,</location>
<marker>Berger, Brown, Pietra, Stephen, Pietra, Vincent, Gillet, Lafferty, Mercer, Printz, Ureg, 1994</marker>
<rawString>Berger, Adam L.; Brown, Peter F.; Della Pietra, Stephen A.; Della Pietra, Vincent J.; Gillet, John R.; Lafferty, John D.; Mercer, Robert L.; Printz, Harry; and Ureg, Lubog. (1994). The Candide System for Machine Translation. In Proceedings, ARPA Workshop on Human Language Technology, Plainsboro, New Jersey, 157-162. ARPA Software and Intelligent Systems Technology Office, Morgan Kaufmann, San Francisco, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Broglio</author>
<author>James P Callan</author>
<author>W Bruce Croft</author>
<author>Daniel W Nachbar</author>
</authors>
<title>Document Retrieval and Routing Using the INQUERY System. In</title>
<date>1995</date>
<booktitle>Proceedings, Third Text Retrieval Conference (TREC-3),</booktitle>
<location>Gaithersburg, Maryland,</location>
<contexts>
<context position="98933" citStr="Broglio et al. (1995)" startWordPosition="16021" endWordPosition="16024">similar representations for Japanese and English news articles, the addition of an English summary generator will automatically allow for English summarization of Japanese. In addition, we are planning to add a second language for the summaries. While the output is not a direct translation of input articles, collocations that appear frequently in the news articles will also appear in summaries. Thus, a list of bilingual collocations would be useful for the summarization process. Information retrieval is another prospective application. As shown in Maarek and Smadja (1989) and more recently in Broglio et al. (1995), the precision of information retrieval systems can be improved through the use of collocations in addition to the more traditional single word indexing units. A collocation gives the context in which a given word was used, which will help retrieve documents using the word with the same sense and thus improve precision. The well-known New Mexico example in information retrieval describes an oft-encountered problem when single word searches are employed: searching for new and Mexico independently will retrieve a multitude of documents that do not relate to New Mexico. Automatically identifying</context>
</contexts>
<marker>Broglio, Callan, Croft, Nachbar, 1995</marker>
<rawString>Broglio, John; Callan, James P.; Croft, W. Bruce; and Nachbar, Daniel W. (1995). Document Retrieval and Routing Using the INQUERY System. In Proceedings, Third Text Retrieval Conference (TREC-3), Gaithersburg, Maryland, 29-39. National Institute of Standards and Technology (NIST).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter E Brown</author>
<author>John Cocke</author>
<author>Della Pietra</author>
<author>A Stephen</author>
<author>Della Pietra</author>
<author>J Vincent</author>
<author>Fredrick Jelinek</author>
<author>John D Lafferty</author>
<author>Robert L Mercer</author>
<author>Paul S Roosin</author>
</authors>
<title>A Statistical Approach to Machine Translation.</title>
<date>1990</date>
<journal>Computational Linguistics,</journal>
<volume>16</volume>
<issue>2</issue>
<pages>79--85</pages>
<contexts>
<context position="9937" citStr="Brown et al. (1990" startWordPosition="1528" endWordPosition="1531">on) input, in which periods may not be noticeable (Church 1993), or languages where insertions or deletions are common (Shemtov 1993; Fung and McKeown 1994). These algorithms were adequate for our purposes, but could be replaced by algorithms more appropriate for noisy input corpora, if necessary Sentence alignment techniques are generally used as a preprocessing stage, before the main processing component that proposes actual translations, whether of words, phrases, or full text, and they are used this way in our work as well. Translation can be approached using statistical techniques alone. Brown et al. (1990, 1993) use a stochastic language model based on techniques used in speech recognition, combined with translation probabilities compiled on the aligned corpus, to do sentence translation. Their system, Candide, uses little linguistic and no semantic information and currently produces good quality translations for short sentences containing high frequency vocabulary as measured by individual human evaluators (see Berger et al. [19941 for information on recent results). While they also align groups of words across languages in the process of translation, they are careful to point out that such g</context>
</contexts>
<marker>Brown, Cocke, Pietra, Stephen, Pietra, Vincent, Jelinek, Lafferty, Mercer, Roosin, 1990</marker>
<rawString>Brown, Peter E; Cocke, John; Della Pietra, Stephen A.; Della Pietra, Vincent J.; Jelinek, Fredrick; Lafferty, John D.; Mercer, Robert L.; and Roosin, Paul S. (1990). A Statistical Approach to Machine Translation. Computational Linguistics, 16(2): 79-85.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Jennifer C Lai</author>
<author>Robert L Mercer</author>
</authors>
<title>Aligning Sentences in Parallel Corpora.</title>
<date>1991</date>
<booktitle>In Proceedings, 29th Annual Meeting of the ACL,</booktitle>
<pages>169--184</pages>
<institution>Association for Computational Linguistics.</institution>
<location>Berkeley, California,</location>
<contexts>
<context position="8150" citStr="Brown et al. 1991" startWordPosition="1246" endWordPosition="1249">er a greater variety of groups than is typical in other research. In this section, we describe work on sentence and word alignment and statistical translation, showing how these goals differ from our own, and then describe work on aligning groups of words. Note that there is additional research using statistical approaches to bilingual problems, but it is less related to ours, addressing, for example, word sense disambiguation in the source language by statistically examining context (e.g., collocations) in the source language, thus allowing appropriate word selection in the target language. (Brown et al. 1991; Dagan, Itai, and Schwall 1991; Dagan and Itai 1994). Our use of bilingual corpora assumes a prealigned corpus. Thus, we draw on work done at AT&amp;T Bell Laboratories by Gale and Church (1991a, 1991b, 1993) and at IBM by Brown, Lai, and Mercer (1991) on bilingual sentence alignment. Sentence alignment programs take a paired bilingual corpus as input and determine which sentences in the target language translate which sentences in the source language. Both the AT&amp;T and the IBM groups use purely statistical techniques based on sentence length to identify sentence pairing in corpora such as the Ha</context>
<context position="25142" citStr="Brown et al. 1991" startWordPosition="3921" endWordPosition="3924">arget language (at least in a clear majority of the cases). In this way, we can ignore the context of the collocations and their translations, and base our decisions only on the patterns of co-occurrence of each collocation and its candidate translations across the entire corpus. This approach is quite different from those adopted for the translation of single words (Klavans and Tzoukermann 1990; Dorr 1992; Klavans and Tzoukermann 1996), since for single words polysemy cannot be ignored; indeed, the problem of sense disambiguation has been linked to the problem of translating ambiguous words (Brown et al. 1991; Dagan, Itai, and Schwa11 1991; Dagan and Itai 1994). The assumption of a single meaning per collocation was based on our previous experience with English collocations (Smadja 1993), is supported for less opaque collocations by the fact that their constituent words tend to have a single sense when they appear in the collocation (Yarowsky 1993), and was verified during our evaluation of Champollion (Section 7). We construct a mathematical model of the events we want to correlate, namely, the appearance of any word or group of words in the sentences of our corpus, as follows: To each group of w</context>
</contexts>
<marker>Brown, Lai, Mercer, 1991</marker>
<rawString>Brown, Peter F.; Lai, Jennifer C.; and Mercer, Robert L. (1991). Aligning Sentences in Parallel Corpora. In Proceedings, 29th Annual Meeting of the ACL, Berkeley, California, 169-184. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Della Pietra</author>
<author>A Stephen</author>
<author>Della Pietra</author>
<author>J Vincent</author>
<author>Robert L Mercer</author>
</authors>
<title>Word-Sense Disambiguation Using Statistical Methods.</title>
<date>1991</date>
<booktitle>In Proceedings, 29th Annual Meeting of the ACL,</booktitle>
<pages>264--270</pages>
<institution>Association for Computational Linguistics.</institution>
<location>Berkeley, California,</location>
<contexts>
<context position="8150" citStr="Brown et al. 1991" startWordPosition="1246" endWordPosition="1249">er a greater variety of groups than is typical in other research. In this section, we describe work on sentence and word alignment and statistical translation, showing how these goals differ from our own, and then describe work on aligning groups of words. Note that there is additional research using statistical approaches to bilingual problems, but it is less related to ours, addressing, for example, word sense disambiguation in the source language by statistically examining context (e.g., collocations) in the source language, thus allowing appropriate word selection in the target language. (Brown et al. 1991; Dagan, Itai, and Schwall 1991; Dagan and Itai 1994). Our use of bilingual corpora assumes a prealigned corpus. Thus, we draw on work done at AT&amp;T Bell Laboratories by Gale and Church (1991a, 1991b, 1993) and at IBM by Brown, Lai, and Mercer (1991) on bilingual sentence alignment. Sentence alignment programs take a paired bilingual corpus as input and determine which sentences in the target language translate which sentences in the source language. Both the AT&amp;T and the IBM groups use purely statistical techniques based on sentence length to identify sentence pairing in corpora such as the Ha</context>
<context position="25142" citStr="Brown et al. 1991" startWordPosition="3921" endWordPosition="3924">arget language (at least in a clear majority of the cases). In this way, we can ignore the context of the collocations and their translations, and base our decisions only on the patterns of co-occurrence of each collocation and its candidate translations across the entire corpus. This approach is quite different from those adopted for the translation of single words (Klavans and Tzoukermann 1990; Dorr 1992; Klavans and Tzoukermann 1996), since for single words polysemy cannot be ignored; indeed, the problem of sense disambiguation has been linked to the problem of translating ambiguous words (Brown et al. 1991; Dagan, Itai, and Schwa11 1991; Dagan and Itai 1994). The assumption of a single meaning per collocation was based on our previous experience with English collocations (Smadja 1993), is supported for less opaque collocations by the fact that their constituent words tend to have a single sense when they appear in the collocation (Yarowsky 1993), and was verified during our evaluation of Champollion (Section 7). We construct a mathematical model of the events we want to correlate, namely, the appearance of any word or group of words in the sentences of our corpus, as follows: To each group of w</context>
</contexts>
<marker>Brown, Pietra, Stephen, Pietra, Vincent, Mercer, 1991</marker>
<rawString>Brown, Peter F.; Della Pietra, Stephen A.; Della Pietra, Vincent J.; and Mercer, Robert L. (1991). Word-Sense Disambiguation Using Statistical Methods. In Proceedings, 29th Annual Meeting of the ACL, Berkeley, California, 264-270. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter E Brown</author>
<author>Della Pietra</author>
<author>A Stephen</author>
<author>Della Pietra</author>
<author>J Vincent</author>
<author>Robert L Mercer</author>
</authors>
<title>The Mathematics of Statistical Machine Translation: Parameter Estimation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<pages>263--311</pages>
<contexts>
<context position="7225" citStr="Brown et al. 1993" startWordPosition="1100" endWordPosition="1103">ussion of the limitations of our approach and of future work. 1 None of the authors is affiliated with Boitet&apos;s research center on machine translation in Grenoble, France, which is also named &amp;quot;Champollion&amp;quot;. 2 Smadja, McKeown, and Hatzivassiloglou Translating Collocations for Bilingual Lexicons 2. Related Work The recent availability of large amounts of bilingual data has attracted interest in several areas, including sentence alignment (Gale and Church 1991b; Brown, Lai, and Mercer 1991; Simard, Foster and Isabelle 1992; Gale and Church 1993; Chen 1993), word alignment (Gale and Church 1991a; Brown et al. 1993; Dagan, Church, and Gale 1993; Fung and McKeown 1994; Fung 1995b), alignment of groups of words (Smadja 1992; Kupiec 1993; van der Eijk 1993), and statistical translation (Brown et al. 1993). Of these, aligning groups of words is most similar to the work reported here, although, as we shall show, we consider a greater variety of groups than is typical in other research. In this section, we describe work on sentence and word alignment and statistical translation, showing how these goals differ from our own, and then describe work on aligning groups of words. Note that there is additional resea</context>
</contexts>
<marker>Brown, Pietra, Stephen, Pietra, Vincent, Mercer, 1993</marker>
<rawString>Brown, Peter E; Della Pietra, Stephen A.; Della Pietra, Vincent J.; and Mercer, Robert L. (1993). The Mathematics of Statistical Machine Translation: Parameter Estimation. Computational Linguistics, 19(2): 263-311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E A Wallis Budge</author>
</authors>
<title>The Rosetta Stone.</title>
<date>1989</date>
<publisher>Dover Publications,</publisher>
<location>New York.</location>
<contexts>
<context position="2017" citStr="Budge 1989" startWordPosition="293" endWordPosition="294">l the discovery of the Rosetta stone in the beginning of the 19th century in Rosetta, Egypt. The Rosetta stone is a tablet of black basalt containing parallel inscriptions in three different scripts: Greek and two forms of ancient Egyptian writings (demotic and hieroglyphics). Jean-Francois Champollion, a linguist and Egyptologist, made the assumption that these inscriptions were parallel and managed after several years of research to decipher the hieroglyphic inscriptions. He used his work on the Rosetta stone as a basis from which to produce the first comprehensive hieroglyphics dictionary (Budge 1989). In this paper, we describe a modern version of a similar approach: given a large corpus in two languages, our system produces translations of common word pairs and phrases that can form the basis of a bilingual lexicon. Our focus is on the use of statistical methods for the translation of multiword expressions, such as collocations which are often idiomatic in nature. Published translations of such collocations are not readily available, even for languages such as French and English, despite the fact that collocations have been recognized as one of the main obstacles to second language acqui</context>
</contexts>
<marker>Budge, 1989</marker>
<rawString>Budge, E. A. Wallis. (1989). The Rosetta Stone. Dover Publications, New York. (Originally published as The Rosetta Stone in the British Museum, Religious Tract Society, London, 1929.)</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stanley F Chen</author>
</authors>
<title>Aligning Sentences in Bilingual Corpora Using Lexical Information.</title>
<date>1993</date>
<booktitle>In Proceedings, 31st Annual Meeting of the ACL,</booktitle>
<pages>9--16</pages>
<institution>Association for Computational Linguistics.</institution>
<location>Columbus, Ohio,</location>
<contexts>
<context position="7167" citStr="Chen 1993" startWordPosition="1092" endWordPosition="1093"> for a variety of applications, closing with a discussion of the limitations of our approach and of future work. 1 None of the authors is affiliated with Boitet&apos;s research center on machine translation in Grenoble, France, which is also named &amp;quot;Champollion&amp;quot;. 2 Smadja, McKeown, and Hatzivassiloglou Translating Collocations for Bilingual Lexicons 2. Related Work The recent availability of large amounts of bilingual data has attracted interest in several areas, including sentence alignment (Gale and Church 1991b; Brown, Lai, and Mercer 1991; Simard, Foster and Isabelle 1992; Gale and Church 1993; Chen 1993), word alignment (Gale and Church 1991a; Brown et al. 1993; Dagan, Church, and Gale 1993; Fung and McKeown 1994; Fung 1995b), alignment of groups of words (Smadja 1992; Kupiec 1993; van der Eijk 1993), and statistical translation (Brown et al. 1993). Of these, aligning groups of words is most similar to the work reported here, although, as we shall show, we consider a greater variety of groups than is typical in other research. In this section, we describe work on sentence and word alignment and statistical translation, showing how these goals differ from our own, and then describe work on ali</context>
</contexts>
<marker>Chen, 1993</marker>
<rawString>Chen, Stanley F. (1993). Aligning Sentences in Bilingual Corpora Using Lexical Information. In Proceedings, 31st Annual Meeting of the ACL, Columbus, Ohio, 9-16. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth W Church</author>
</authors>
<title>A Stochastic Parts Program and Noun Phrase Parser for Unrestricted Text. In</title>
<date>1988</date>
<booktitle>Proceedings, Second Conference on Applied Natural Language Processing (ANLP-88),</booktitle>
<pages>136--143</pages>
<institution>Association for Computational Linguistics.</institution>
<location>Austin, Texas,</location>
<contexts>
<context position="115496" citStr="Church 1988" startWordPosition="18589" endWordPosition="18590">etter results than by applying the same technique to all constructions uniformly. Our work is part of a paradigm of research that focuses on the development of tools using statistical analysis of text corpora. This line of research aims at producing tools 34 Smadja, McKeown, and Hatzivassiloglou Translating Collocations for Bilingual Lexicons that satisfactorily handle relatively simple tasks. These tools can then be used by other systems to address more complex tasks. For example, previous work has addressed low-level tasks such as tagging a free-style corpus with part-of-speech information (Church 1988), aligning a bilingual corpus (Gale and Church 1991b; Brown, Lai, and Mercer 1991), and producing a list of collocations (Smadja 1993). While each of these tools is based on simple statistics and tackles elementary tasks, we have demonstrated with our work on Champollion that by combining them, one can reach new levels of complexity in the automatic treatment of natural languages. Acknowledgments This work was supported jointly by the Advanced Research Projects Agency and the Office of Naval Research under grant N00014-89—J-1782, by the Office of Naval Research under grant N00014-95-1-0745, by</context>
</contexts>
<marker>Church, 1988</marker>
<rawString>Church, Kenneth W. (1988). A Stochastic Parts Program and Noun Phrase Parser for Unrestricted Text. In Proceedings, Second Conference on Applied Natural Language Processing (ANLP-88), Austin, Texas, 136-143. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth W Church</author>
</authors>
<title>Char_align: A Program for Aligning Parallel Texts at the Character Level.</title>
<date>1993</date>
<booktitle>In Proceedings, 31st Annual Meeting of the ACL,</booktitle>
<location>Columbus, Ohio,</location>
<contexts>
<context position="7155" citStr="Church 1993" startWordPosition="1090" endWordPosition="1091">s can be used for a variety of applications, closing with a discussion of the limitations of our approach and of future work. 1 None of the authors is affiliated with Boitet&apos;s research center on machine translation in Grenoble, France, which is also named &amp;quot;Champollion&amp;quot;. 2 Smadja, McKeown, and Hatzivassiloglou Translating Collocations for Bilingual Lexicons 2. Related Work The recent availability of large amounts of bilingual data has attracted interest in several areas, including sentence alignment (Gale and Church 1991b; Brown, Lai, and Mercer 1991; Simard, Foster and Isabelle 1992; Gale and Church 1993; Chen 1993), word alignment (Gale and Church 1991a; Brown et al. 1993; Dagan, Church, and Gale 1993; Fung and McKeown 1994; Fung 1995b), alignment of groups of words (Smadja 1992; Kupiec 1993; van der Eijk 1993), and statistical translation (Brown et al. 1993). Of these, aligning groups of words is most similar to the work reported here, although, as we shall show, we consider a greater variety of groups than is typical in other research. In this section, we describe work on sentence and word alignment and statistical translation, showing how these goals differ from our own, and then describe</context>
<context position="8795" citStr="Church 1993" startWordPosition="1353" endWordPosition="1354">Dagan and Itai 1994). Our use of bilingual corpora assumes a prealigned corpus. Thus, we draw on work done at AT&amp;T Bell Laboratories by Gale and Church (1991a, 1991b, 1993) and at IBM by Brown, Lai, and Mercer (1991) on bilingual sentence alignment. Sentence alignment programs take a paired bilingual corpus as input and determine which sentences in the target language translate which sentences in the source language. Both the AT&amp;T and the IBM groups use purely statistical techniques based on sentence length to identify sentence pairing in corpora such as the Hansards. The AT&amp;T group (Gale and Church 1993) defines sentence length by the number of characters in the sentences, while the IBM group (Brown, Lai, and Mercer 1991) defines sentence length by the number of words in the sentence. Both approaches achieve similar results and have been influential in much of the research on statistical natural language processing, including ours. It has been noted in more recent work that length-based alignment programs such as these are problematic for many cases of real world parallel data, such as OCR (Optical Character Recognition) input, in which periods may not be noticeable (Church 1993), or language</context>
</contexts>
<marker>Church, 1993</marker>
<rawString>Church, Kenneth W. (1993). Char_align: A Program for Aligning Parallel Texts at the Character Level. In Proceedings, 31st Annual Meeting of the ACL, Columbus, Ohio, 1-8. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth W Church</author>
<author>William A Gale</author>
<author>Patrick Hanks</author>
<author>Donald Hindle</author>
</authors>
<title>Using Statistics in Lexical Analysis. In Lexical Acquisition: Using On-line Resources to Build a Lexicon, edited by Uri Zernik. Lawrence Erlbaum,</title>
<date>1991</date>
<pages>115--165</pages>
<location>Hillsdale, New Jersey,</location>
<contexts>
<context position="27876" citStr="Church et al. 1991" startWordPosition="4382" endWordPosition="4385">s ,„ 2 . p(X=1, Y=1) (1) Dice(X, I) =p(X =1) + p(Y =1) where p(X, Y), p(X), and p(Y) are the joint and marginal probability mass functions of the variables X and Y, respectively. Using maximum likelihood estimates for the probabilities in the above equation, we have Dice(X,Y) = 2 fxy fx fy where fx, fy, and fxy are the absolute frequencies of appearance of &amp;quot;1&amp;quot;s for the variables X, Y, and both X and Y together, respectively. On the other hand, in computational linguistics, information-theoretic measures such as mutual information are widely used (e.g., Bahl et al. 1986; Church and Hanks 1990; Church et al. 1991; Dagan, Marcus, and Markovitch 1993; Su, Wu, and Chang 1994). In information theory, the mutual information I(X, Y) between two binary random variables X and Y is defined as p(X=x,Y =y) log P(X=x&apos;Y =Y) /(X, Y) = E xE{0,1}yE{0,1} P(X=X)p(Y= y) However, in computational linguistics, the term mutual information has been used most of the time to describe only a part of the above sum, namely the term from the X =1, Y =1 case (unweighted by the joint probability p(X = 1, Y = 1)) . In other words, this alternative measure of mutual information, which we will refer to as specific mutual information S</context>
</contexts>
<marker>Church, Gale, Hanks, Hindle, 1991</marker>
<rawString>Church, Kenneth W.; Gale, William A.; Hanks, Patrick; and Hindle, Donald. (1991). Using Statistics in Lexical Analysis. In Lexical Acquisition: Using On-line Resources to Build a Lexicon, edited by Uri Zernik. Lawrence Erlbaum, Hillsdale, New Jersey, 115-165.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth W Church</author>
<author>Patrick Hanks</author>
</authors>
<date>1990</date>
<journal>Word Association Norms, Mutual Information, and Lexicography. Computational Linguistics,</journal>
<volume>16</volume>
<issue>1</issue>
<pages>22--29</pages>
<contexts>
<context position="27856" citStr="Church and Hanks 1990" startWordPosition="4378" endWordPosition="4381"> 1992). It is defined as ,„ 2 . p(X=1, Y=1) (1) Dice(X, I) =p(X =1) + p(Y =1) where p(X, Y), p(X), and p(Y) are the joint and marginal probability mass functions of the variables X and Y, respectively. Using maximum likelihood estimates for the probabilities in the above equation, we have Dice(X,Y) = 2 fxy fx fy where fx, fy, and fxy are the absolute frequencies of appearance of &amp;quot;1&amp;quot;s for the variables X, Y, and both X and Y together, respectively. On the other hand, in computational linguistics, information-theoretic measures such as mutual information are widely used (e.g., Bahl et al. 1986; Church and Hanks 1990; Church et al. 1991; Dagan, Marcus, and Markovitch 1993; Su, Wu, and Chang 1994). In information theory, the mutual information I(X, Y) between two binary random variables X and Y is defined as p(X=x,Y =y) log P(X=x&apos;Y =Y) /(X, Y) = E xE{0,1}yE{0,1} P(X=X)p(Y= y) However, in computational linguistics, the term mutual information has been used most of the time to describe only a part of the above sum, namely the term from the X =1, Y =1 case (unweighted by the joint probability p(X = 1, Y = 1)) . In other words, this alternative measure of mutual information, which we will refer to as specific </context>
</contexts>
<marker>Church, Hanks, 1990</marker>
<rawString>Church, Kenneth W. and Hanks, Patrick. (1990). Word Association Norms, Mutual Information, and Lexicography. Computational Linguistics, 16(1): 22-29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas M Cover</author>
<author>Joy A Thomas</author>
</authors>
<title>Elements of Information Theory.</title>
<date>1991</date>
<publisher>Wiley,</publisher>
<location>New York.</location>
<contexts>
<context position="28962" citStr="Cover and Thomas 1991" startWordPosition="4572" endWordPosition="4575">X = 1, Y = 1)) . In other words, this alternative measure of mutual information, which we will refer to as specific mutual information S/(X, Y), is p(X= 1, Y=1) S/(X, Y) = log p(X=1)p(Y =1) The quantity /(X, Y) is the average of SI(X, Y) taken over the four combinations of values of X and Y according to the joint probability distribution p(X, Y), so sometimes the term average mutual information is used for /(X, Y). Average mutual information expresses the difference between the entropy (information) of one of the variables and the conditional entropy of that variable given the other variable (Cover and Thomas 1991). Thus, average mutual information measures the reduction in the uncertainty about the value of one variable that knowledge of the value of the other variable provides, averaged over all possible values of the two variables. Equivalently, average mutual information is &amp;quot;the information about X contained in Y&amp;quot; (Papoulis 1984, 518) (or the information about Y contained in X). Specific 8 Smadja, McKeown, and Hatzivassiloglou Translating Collocations for Bilingual Lexicons mutual information represents the log-likelihood ratio of the joint probability of seeing a &amp;quot;1&amp;quot; in both variables over the prob</context>
</contexts>
<marker>Cover, Thomas, 1991</marker>
<rawString>Cover, Thomas M. and Thomas, Joy A. (1991). Elements of Information Theory. Wiley, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Kenneth W Church</author>
</authors>
<title>Termight: Identifying and Translating Technical Terminology. In</title>
<date>1994</date>
<booktitle>Proceedings, Fourth Conference on Applied Natural Language Processing (ANLP-94),</booktitle>
<pages>34--40</pages>
<institution>Association for Computational Linguistics.</institution>
<location>Stuttgart,</location>
<contexts>
<context position="13320" citStr="Dagan and Church (1994)" startWordPosition="2057" endWordPosition="2060">approaches and ours is that van der Eijk and Kupiec only handle noun phrases whereas collocations have been shown to include parts of noun phrases, categories other than noun phrases (e.g., verb phrases), as well as flexible phrases that involve words separated by an arbitrary number of other words (e.g., to take . . . steps, to demonstrate . . . support). In this work, as in earlier work (Smadja 1992), we address the full range of collocations including both flexible and rigid collocations for a variety of syntactic categories. Another approach, begun more recently than our work, is taken by Dagan and Church (1994), who use statistical methods to translate technical terminology. Like van der Eijk and Kupiec, they preprocess their corpora by tagging and by identifying noun phrases. However, they use a word alignment program as opposed to sentence alignment and they include single words as candidates for technical terms. One of the major differences between their work and ours is that, like van der Eijk and Kupiec, they only handle translation of uninterrupted sequences of words; they do not handle the broader class of flexible collocations. Their system, Termight, first extracts candidate technical terms</context>
<context position="21156" citStr="Dagan and Church 1994" startWordPosition="3294" endWordPosition="3297">nt, often forming part of a sublanguage. For example, Mr. Speaker is the proper way to refer to the Speaker of the House in the Canadian Parliament when speaking English. The French equivalent, Monsieur le Président, is not the literal translation but instead uses the translation of the term President. While this is an appropriate translation for the Canadian Parliament, in different contexts another translation would be better. Note that these problems are quite similar to the difficulties in translating technical terminology, which also is usually part of a particular technical sublanguage (Dagan and Church 1994). The ability to automatically acquire collocation translations is thus a definite advantage for sublanguage translation. When moving to a new domain and sublanguage, translations that are appropriate can be acquired by running Champollion on a new corpus from that domain. Since in some instances parts of a sentence can be translated on a word-by-word basis, a translator must know when a full phrase or pair of words must be considered for translation and when a word-by-word technique will suffice. Two tasks must therefore be considered: 1. Identify collocations, or phrases which cannot be tran</context>
<context position="100407" citStr="Dagan and Church (1994)" startWordPosition="16246" endWordPosition="16249">gual list of collocations could be used for the development of a multilingual information retrieval system. In cases where the database of texts includes documents written in multiple languages, the search query need only be expressed in one language. The bilingual collocations could be used to translate the query (particularly 30 Smadja, McKeown, and Hatzivassiloglou Translating Collocations for Bilingual Lexicons given that it may consist of collocations in addition to single words) from the input language to other languages in the database. Another potential application, as demonstrated by Dagan and Church (1994), is machine-aided human translation. For this scenario, when a translator begins work on a collocation inside a translation editor, the translation produced by Champollion could be provided as a prompt giving the translator the opportunity to approve it. In such cases, it may be useful to provide the top several translations produced by Champollion allowing the translator to choose the best, as Dagan and Church do. Finally, Champollion could also be used for computer-assisted lexicography. Since its output includes the translation of 1 to n word phrases, Champollion could be used to automatic</context>
</contexts>
<marker>Dagan, Church, 1994</marker>
<rawString>Dagan, Ido and Church, Kenneth W. (1994). Termight: Identifying and Translating Technical Terminology. In Proceedings, Fourth Conference on Applied Natural Language Processing (ANLP-94), Stuttgart, Germany, 34-40. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Kenneth W Church</author>
<author>William A Gale</author>
</authors>
<title>Robust Bilingual Word Alignment for Machine-Aided Translation. In</title>
<date>1993</date>
<booktitle>Proceedings, Workshop on Very Large Corpora: Academic and Industrial Perspectives,</booktitle>
<location>Columbus, Ohio,</location>
<marker>Dagan, Church, Gale, 1993</marker>
<rawString>Dagan, Ido; Church, Kenneth W.; and Gale, William A. (1993). Robust Bilingual Word Alignment for Machine-Aided Translation. In Proceedings, Workshop on Very Large Corpora: Academic and Industrial Perspectives, Columbus, Ohio, 1-8. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Alon Itai</author>
</authors>
<title>Word Sense Disambiguation Using a Second Language Monolingual Corpus.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<volume>20</volume>
<issue>4</issue>
<pages>563--596</pages>
<contexts>
<context position="8203" citStr="Dagan and Itai 1994" startWordPosition="1255" endWordPosition="1258">other research. In this section, we describe work on sentence and word alignment and statistical translation, showing how these goals differ from our own, and then describe work on aligning groups of words. Note that there is additional research using statistical approaches to bilingual problems, but it is less related to ours, addressing, for example, word sense disambiguation in the source language by statistically examining context (e.g., collocations) in the source language, thus allowing appropriate word selection in the target language. (Brown et al. 1991; Dagan, Itai, and Schwall 1991; Dagan and Itai 1994). Our use of bilingual corpora assumes a prealigned corpus. Thus, we draw on work done at AT&amp;T Bell Laboratories by Gale and Church (1991a, 1991b, 1993) and at IBM by Brown, Lai, and Mercer (1991) on bilingual sentence alignment. Sentence alignment programs take a paired bilingual corpus as input and determine which sentences in the target language translate which sentences in the source language. Both the AT&amp;T and the IBM groups use purely statistical techniques based on sentence length to identify sentence pairing in corpora such as the Hansards. The AT&amp;T group (Gale and Church 1993) defines</context>
<context position="25195" citStr="Dagan and Itai 1994" startWordPosition="3930" endWordPosition="3933">e cases). In this way, we can ignore the context of the collocations and their translations, and base our decisions only on the patterns of co-occurrence of each collocation and its candidate translations across the entire corpus. This approach is quite different from those adopted for the translation of single words (Klavans and Tzoukermann 1990; Dorr 1992; Klavans and Tzoukermann 1996), since for single words polysemy cannot be ignored; indeed, the problem of sense disambiguation has been linked to the problem of translating ambiguous words (Brown et al. 1991; Dagan, Itai, and Schwa11 1991; Dagan and Itai 1994). The assumption of a single meaning per collocation was based on our previous experience with English collocations (Smadja 1993), is supported for less opaque collocations by the fact that their constituent words tend to have a single sense when they appear in the collocation (Yarowsky 1993), and was verified during our evaluation of Champollion (Section 7). We construct a mathematical model of the events we want to correlate, namely, the appearance of any word or group of words in the sentences of our corpus, as follows: To each group of words G, in either the source or the target language, </context>
</contexts>
<marker>Dagan, Itai, 1994</marker>
<rawString>Dagan, Ido and Itai, Alon. (1994). Word Sense Disambiguation Using a Second Language Monolingual Corpus. Computational Linguistics, 20(4): 563-596.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Alon Itai</author>
<author>Ulrike Schwall</author>
</authors>
<title>Two Languages Are More Informative Than One.</title>
<date>1991</date>
<booktitle>In Proceedings, 29th Annual Meeting of the ACL,</booktitle>
<pages>130--137</pages>
<institution>Association for Computational Linguistics.</institution>
<location>Berkeley, California,</location>
<marker>Dagan, Itai, Schwall, 1991</marker>
<rawString>Dagan, Ido; Itai, Alon; and Schwall, Ulrike. (1991). Two Languages Are More Informative Than One. In Proceedings, 29th Annual Meeting of the ACL, Berkeley, California, 130-137. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Shaul Marcus</author>
<author>Shaul Markovitch</author>
</authors>
<title>Contextual Word Similarity and Estimation from Sparse Data.</title>
<date>1993</date>
<booktitle>In Proceedings, 31st Annual Meeting of the ACL,</booktitle>
<pages>164--171</pages>
<institution>Association for Computational Linguistics.</institution>
<location>Columbus, Ohio,</location>
<marker>Dagan, Marcus, Markovitch, 1993</marker>
<rawString>Dagan, Ido; Marcus, Shaul; and Markovitch, Shaul. (1993). Contextual Word Similarity and Estimation from Sparse Data. In Proceedings, 31st Annual Meeting of the ACL, Columbus, Ohio, 164-171. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lee R Dice</author>
</authors>
<title>Measures of the Amount of Ecologic Association between Species.</title>
<date>1945</date>
<journal>Journal of Ecology,</journal>
<volume>26</volume>
<pages>297--302</pages>
<contexts>
<context position="3670" citStr="Dice 1945" startWordPosition="543" endWordPosition="544">istics Computational Linguistics Volume 22, Number 1 We have developed a program named Champollion1 , which, given a sentencealigned parallel bilingual corpus, translates collocations (or individual words) in the source language into collocations (or individual words) in the target language. The aligned corpus is used as a reference, or database corpus, and represents Champollion&apos; s knowledge of both languages. Champollion uses statistical methods to incrementally construct the collocation translation, adding one word at a time. As a correlation measure, Champollion uses the Dice coefficient (Dice 1945; Sorensen 1948) commonly used in information retrieval (Salton and McGill 1983; Frakes and Baeza-Yates 1992). For a given source language collocation, Champollion identifies individual words in the target language that are highly correlated with the source collocation, thus producing a set of words in the target language. These words are then combined in a systematic, iterative manner to produce a translation of the source language collocation. Champollion considers all pairs of these words and identifies any that are highly correlated with the source collocation. Next, triplets are produced </context>
<context position="27172" citStr="Dice 1945" startWordPosition="4263" endWordPosition="4264">rthermore, for the measurement of correlation between a word group G in the source language and another word group H in the target language, we map the paired sentences in our corpus to a collection of paired samples for the random variables XG and XH. This modeling process allows us to use correlation metrics between paired samples of random variables (XG and Xx) to measure the correlation between word groups (G and H) across languages. There are several ways to measure the correlation of two such random variables. One measure frequently used in information retrieval is the Dice coefficient (Dice 1945; Sorensen 1948; Salton and McGill 1983; Frakes and Baeza-Yates 1992). It is defined as ,„ 2 . p(X=1, Y=1) (1) Dice(X, I) =p(X =1) + p(Y =1) where p(X, Y), p(X), and p(Y) are the joint and marginal probability mass functions of the variables X and Y, respectively. Using maximum likelihood estimates for the probabilities in the above equation, we have Dice(X,Y) = 2 fxy fx fy where fx, fy, and fxy are the absolute frequencies of appearance of &amp;quot;1&amp;quot;s for the variables X, Y, and both X and Y together, respectively. On the other hand, in computational linguistics, information-theoretic measures such </context>
</contexts>
<marker>Dice, 1945</marker>
<rawString>Dice, Lee R. (1945). Measures of the Amount of Ecologic Association between Species. Journal of Ecology, 26: 297-302.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonnie J Dorr</author>
</authors>
<title>The Use of Lexical Semantics in Interlingual Machine Translation.</title>
<date>1992</date>
<journal>Machine Translation,</journal>
<volume>7</volume>
<issue>3</issue>
<pages>135--193</pages>
<contexts>
<context position="24934" citStr="Dorr 1992" startWordPosition="3891" endWordPosition="3892">riate than another frequently used measure—mutual information. Our approach is based on the assumption that each collocation is unambiguous in the source language and has a unique translation in the target language (at least in a clear majority of the cases). In this way, we can ignore the context of the collocations and their translations, and base our decisions only on the patterns of co-occurrence of each collocation and its candidate translations across the entire corpus. This approach is quite different from those adopted for the translation of single words (Klavans and Tzoukermann 1990; Dorr 1992; Klavans and Tzoukermann 1996), since for single words polysemy cannot be ignored; indeed, the problem of sense disambiguation has been linked to the problem of translating ambiguous words (Brown et al. 1991; Dagan, Itai, and Schwa11 1991; Dagan and Itai 1994). The assumption of a single meaning per collocation was based on our previous experience with English collocations (Smadja 1993), is supported for less opaque collocations by the fact that their constituent words tend to have a single sense when they appear in the collocation (Yarowsky 1993), and was verified during our evaluation of Ch</context>
</contexts>
<marker>Dorr, 1992</marker>
<rawString>Dorr, Bonnie J. (1992). The Use of Lexical Semantics in Interlingual Machine Translation. Machine Translation, 7(3): 135-193.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pim van der Eijk</author>
</authors>
<title>Automating the Acquisition of Bilingual Terminology.</title>
<date>1993</date>
<booktitle>In Proceedings, Sixth Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<location>Utrecht, The</location>
<marker>van der Eijk, 1993</marker>
<rawString>van der Eijk, Pim. (1993). Automating the Acquisition of Bilingual Terminology. In Proceedings, Sixth Conference of the European Chapter of the Association for Computational Linguistics, Utrecht, The Netherlands, 113-119. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<title>Information Retrieval: Data Structures and Algorithms.</title>
<date>1992</date>
<editor>Frakes, William B. and Baeza-Yates, Ricardo, eds.</editor>
<publisher>Prentice Hall,</publisher>
<location>Englewood Cliffs, New Jersey.</location>
<marker>1992</marker>
<rawString>Frakes, William B. and Baeza-Yates, Ricardo, eds. (1992). Information Retrieval: Data Structures and Algorithms. Prentice Hall, Englewood Cliffs, New Jersey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pascale Fung</author>
</authors>
<title>Compiling Bilingual Lexicon Entries from a Non-Parallel English-Chinese Corpus.</title>
<date>1995</date>
<booktitle>In Proceedings, Third Annual Workshop on Very Large Corpora,</booktitle>
<pages>173--183</pages>
<location>Boston, Massachusetts,</location>
<contexts>
<context position="7289" citStr="Fung 1995" startWordPosition="1113" endWordPosition="1114">the authors is affiliated with Boitet&apos;s research center on machine translation in Grenoble, France, which is also named &amp;quot;Champollion&amp;quot;. 2 Smadja, McKeown, and Hatzivassiloglou Translating Collocations for Bilingual Lexicons 2. Related Work The recent availability of large amounts of bilingual data has attracted interest in several areas, including sentence alignment (Gale and Church 1991b; Brown, Lai, and Mercer 1991; Simard, Foster and Isabelle 1992; Gale and Church 1993; Chen 1993), word alignment (Gale and Church 1991a; Brown et al. 1993; Dagan, Church, and Gale 1993; Fung and McKeown 1994; Fung 1995b), alignment of groups of words (Smadja 1992; Kupiec 1993; van der Eijk 1993), and statistical translation (Brown et al. 1993). Of these, aligning groups of words is most similar to the work reported here, although, as we shall show, we consider a greater variety of groups than is typical in other research. In this section, we describe work on sentence and word alignment and statistical translation, showing how these goals differ from our own, and then describe work on aligning groups of words. Note that there is additional research using statistical approaches to bilingual problems, but it i</context>
<context position="15268" citStr="Fung 1995" startWordPosition="2367" endWordPosition="2368">th Champollion&apos;s 73% accuracy). Since Termight is fully integrated within a translator&apos;s editor (another unique feature) and is used as an aid for human translators, it gets around the problem of accuracy by presenting the sorted list of translations to the translator for a choice. In all cases, the correct translation was found in this list and translators were able to speed up both the task of identifying technical terminology and translating terms. Other recent related work aims at using statistical techniques to produce translations of single words (Fung and McKeown 1994; Wu and Xia 1994; Fung 1995b) 4 Smadja, McKeown, and Hatzivassiloglou Translating Collocations for Bilingual Lexicons as opposed to collocations or phrases. Wu and Xia (1994) employed an estimationmaximization technique to find the optimal word alignment from previously sentencealigned clean parallel corpora2, with additional significance filtering. The work by Fung and McKeown (1994) and Fung (1995b) is notable for its use of techniques suitable to Asian/Romance language pairs as well as Romance language pairs. Given that Asian languages differ considerably in structure from Romance languages, statistical methods that </context>
<context position="112405" citStr="Fung (1995" startWordPosition="18123" endWordPosition="18124">, such techniques would be more useful than those currently used, because they would be able to extract knowledge from noisy data. While this is definitely a large research problem, our research team at Columbia University has begun work in this area (Fung and McKeown 1994) that shows promise for noisy parallel corpora (in which the target corpus may contain either additional or deleted paragraphs and where the languages themselves do not involve neat sentence-by-sentence translations). Bilingual word correspondences extracted from nonparallel corpora with techniques such as those proposed by Fung (1995a) also look promising. 10. Conclusion We have presented a method for translating collocations, implemented in Champollion. The ability to provide translations for collocations is important for three main reasons. First, because they are opaque constructions, they cannot be translated on a word-byword basis. Instead, translations must be provided for the phrase as a whole. Second, collocations are domain dependent. Each domain includes a variety of phrases that have specific meanings and translations that apply only in the given domain. Finally, a quick look at a bilingual dictionary, even for</context>
</contexts>
<marker>Fung, 1995</marker>
<rawString>Fung, Pascale. (1995a). Compiling Bilingual Lexicon Entries from a Non-Parallel English-Chinese Corpus. In Proceedings, Third Annual Workshop on Very Large Corpora, Boston, Massachusetts, 173-183.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pascale Fung</author>
</authors>
<title>A Pattern Matching Method for Finding Noun and Proper Noun Translations from Noisy Parallel Corpora.</title>
<date>1995</date>
<booktitle>In Proceedings, 33rd Annual Meeting of the ACL,</booktitle>
<pages>236--243</pages>
<institution>Association for Computational Linguistics.</institution>
<location>Boston, Massachusetts,</location>
<contexts>
<context position="7289" citStr="Fung 1995" startWordPosition="1113" endWordPosition="1114">the authors is affiliated with Boitet&apos;s research center on machine translation in Grenoble, France, which is also named &amp;quot;Champollion&amp;quot;. 2 Smadja, McKeown, and Hatzivassiloglou Translating Collocations for Bilingual Lexicons 2. Related Work The recent availability of large amounts of bilingual data has attracted interest in several areas, including sentence alignment (Gale and Church 1991b; Brown, Lai, and Mercer 1991; Simard, Foster and Isabelle 1992; Gale and Church 1993; Chen 1993), word alignment (Gale and Church 1991a; Brown et al. 1993; Dagan, Church, and Gale 1993; Fung and McKeown 1994; Fung 1995b), alignment of groups of words (Smadja 1992; Kupiec 1993; van der Eijk 1993), and statistical translation (Brown et al. 1993). Of these, aligning groups of words is most similar to the work reported here, although, as we shall show, we consider a greater variety of groups than is typical in other research. In this section, we describe work on sentence and word alignment and statistical translation, showing how these goals differ from our own, and then describe work on aligning groups of words. Note that there is additional research using statistical approaches to bilingual problems, but it i</context>
<context position="15268" citStr="Fung 1995" startWordPosition="2367" endWordPosition="2368">th Champollion&apos;s 73% accuracy). Since Termight is fully integrated within a translator&apos;s editor (another unique feature) and is used as an aid for human translators, it gets around the problem of accuracy by presenting the sorted list of translations to the translator for a choice. In all cases, the correct translation was found in this list and translators were able to speed up both the task of identifying technical terminology and translating terms. Other recent related work aims at using statistical techniques to produce translations of single words (Fung and McKeown 1994; Wu and Xia 1994; Fung 1995b) 4 Smadja, McKeown, and Hatzivassiloglou Translating Collocations for Bilingual Lexicons as opposed to collocations or phrases. Wu and Xia (1994) employed an estimationmaximization technique to find the optimal word alignment from previously sentencealigned clean parallel corpora2, with additional significance filtering. The work by Fung and McKeown (1994) and Fung (1995b) is notable for its use of techniques suitable to Asian/Romance language pairs as well as Romance language pairs. Given that Asian languages differ considerably in structure from Romance languages, statistical methods that </context>
<context position="112405" citStr="Fung (1995" startWordPosition="18123" endWordPosition="18124">, such techniques would be more useful than those currently used, because they would be able to extract knowledge from noisy data. While this is definitely a large research problem, our research team at Columbia University has begun work in this area (Fung and McKeown 1994) that shows promise for noisy parallel corpora (in which the target corpus may contain either additional or deleted paragraphs and where the languages themselves do not involve neat sentence-by-sentence translations). Bilingual word correspondences extracted from nonparallel corpora with techniques such as those proposed by Fung (1995a) also look promising. 10. Conclusion We have presented a method for translating collocations, implemented in Champollion. The ability to provide translations for collocations is important for three main reasons. First, because they are opaque constructions, they cannot be translated on a word-byword basis. Instead, translations must be provided for the phrase as a whole. Second, collocations are domain dependent. Each domain includes a variety of phrases that have specific meanings and translations that apply only in the given domain. Finally, a quick look at a bilingual dictionary, even for</context>
</contexts>
<marker>Fung, 1995</marker>
<rawString>Fung, Pascale. (1995b). A Pattern Matching Method for Finding Noun and Proper Noun Translations from Noisy Parallel Corpora. In Proceedings, 33rd Annual Meeting of the ACL, Boston, Massachusetts, 236-243. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pascale Fung</author>
<author>Kathleen R McKeown</author>
</authors>
<title>Aligning Noisy Parallel Corpora Across Language Groups: Word Pair Feature Matching by Dynamic Time Warping.</title>
<date>1994</date>
<booktitle>In Proceedings, First Conference of the Association for Machine Translation in the Americas (ANITA),</booktitle>
<pages>81--88</pages>
<location>Columbia, Maryland,</location>
<contexts>
<context position="7278" citStr="Fung and McKeown 1994" startWordPosition="1109" endWordPosition="1112">future work. 1 None of the authors is affiliated with Boitet&apos;s research center on machine translation in Grenoble, France, which is also named &amp;quot;Champollion&amp;quot;. 2 Smadja, McKeown, and Hatzivassiloglou Translating Collocations for Bilingual Lexicons 2. Related Work The recent availability of large amounts of bilingual data has attracted interest in several areas, including sentence alignment (Gale and Church 1991b; Brown, Lai, and Mercer 1991; Simard, Foster and Isabelle 1992; Gale and Church 1993; Chen 1993), word alignment (Gale and Church 1991a; Brown et al. 1993; Dagan, Church, and Gale 1993; Fung and McKeown 1994; Fung 1995b), alignment of groups of words (Smadja 1992; Kupiec 1993; van der Eijk 1993), and statistical translation (Brown et al. 1993). Of these, aligning groups of words is most similar to the work reported here, although, as we shall show, we consider a greater variety of groups than is typical in other research. In this section, we describe work on sentence and word alignment and statistical translation, showing how these goals differ from our own, and then describe work on aligning groups of words. Note that there is additional research using statistical approaches to bilingual problem</context>
<context position="9475" citStr="Fung and McKeown 1994" startWordPosition="1458" endWordPosition="1461">e sentences, while the IBM group (Brown, Lai, and Mercer 1991) defines sentence length by the number of words in the sentence. Both approaches achieve similar results and have been influential in much of the research on statistical natural language processing, including ours. It has been noted in more recent work that length-based alignment programs such as these are problematic for many cases of real world parallel data, such as OCR (Optical Character Recognition) input, in which periods may not be noticeable (Church 1993), or languages where insertions or deletions are common (Shemtov 1993; Fung and McKeown 1994). These algorithms were adequate for our purposes, but could be replaced by algorithms more appropriate for noisy input corpora, if necessary Sentence alignment techniques are generally used as a preprocessing stage, before the main processing component that proposes actual translations, whether of words, phrases, or full text, and they are used this way in our work as well. Translation can be approached using statistical techniques alone. Brown et al. (1990, 1993) use a stochastic language model based on techniques used in speech recognition, combined with translation probabilities compiled o</context>
<context position="15240" citStr="Fung and McKeown 1994" startWordPosition="2359" endWordPosition="2362">correct only 40% of the time (compare with Champollion&apos;s 73% accuracy). Since Termight is fully integrated within a translator&apos;s editor (another unique feature) and is used as an aid for human translators, it gets around the problem of accuracy by presenting the sorted list of translations to the translator for a choice. In all cases, the correct translation was found in this list and translators were able to speed up both the task of identifying technical terminology and translating terms. Other recent related work aims at using statistical techniques to produce translations of single words (Fung and McKeown 1994; Wu and Xia 1994; Fung 1995b) 4 Smadja, McKeown, and Hatzivassiloglou Translating Collocations for Bilingual Lexicons as opposed to collocations or phrases. Wu and Xia (1994) employed an estimationmaximization technique to find the optimal word alignment from previously sentencealigned clean parallel corpora2, with additional significance filtering. The work by Fung and McKeown (1994) and Fung (1995b) is notable for its use of techniques suitable to Asian/Romance language pairs as well as Romance language pairs. Given that Asian languages differ considerably in structure from Romance language</context>
<context position="112069" citStr="Fung and McKeown 1994" startWordPosition="18075" endWordPosition="18078">cies such as the Associated Press and Reuters publish in several languages. News stories often relate similar facts but they are not direct translations of one another. Even though the stories probably use equivalent terminology, totally different techniques would be necessary to be able to use such &amp;quot;nonalignable&amp;quot; corpora as databases. Ultimately, such techniques would be more useful than those currently used, because they would be able to extract knowledge from noisy data. While this is definitely a large research problem, our research team at Columbia University has begun work in this area (Fung and McKeown 1994) that shows promise for noisy parallel corpora (in which the target corpus may contain either additional or deleted paragraphs and where the languages themselves do not involve neat sentence-by-sentence translations). Bilingual word correspondences extracted from nonparallel corpora with techniques such as those proposed by Fung (1995a) also look promising. 10. Conclusion We have presented a method for translating collocations, implemented in Champollion. The ability to provide translations for collocations is important for three main reasons. First, because they are opaque constructions, they</context>
</contexts>
<marker>Fung, McKeown, 1994</marker>
<rawString>Fung, Pascale and McKeown, Kathleen R. (1994). Aligning Noisy Parallel Corpora Across Language Groups: Word Pair Feature Matching by Dynamic Time Warping. In Proceedings, First Conference of the Association for Machine Translation in the Americas (ANITA), Columbia, Maryland, 81-88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William A Gale</author>
<author>Kenneth W Church</author>
</authors>
<title>Identifying Word Correspondences in Parallel Texts.</title>
<date>1991</date>
<booktitle>In Proceedings, DARPA Speech and Natural Language Workshop,</booktitle>
<pages>152--157</pages>
<publisher>Morgan Kaufmann,</publisher>
<location>Pacific Grove, California,</location>
<contexts>
<context position="7069" citStr="Gale and Church 1991" startWordPosition="1074" endWordPosition="1077">. Next, we turn to a description of the results and evaluation. Finally, we show how the results can be used for a variety of applications, closing with a discussion of the limitations of our approach and of future work. 1 None of the authors is affiliated with Boitet&apos;s research center on machine translation in Grenoble, France, which is also named &amp;quot;Champollion&amp;quot;. 2 Smadja, McKeown, and Hatzivassiloglou Translating Collocations for Bilingual Lexicons 2. Related Work The recent availability of large amounts of bilingual data has attracted interest in several areas, including sentence alignment (Gale and Church 1991b; Brown, Lai, and Mercer 1991; Simard, Foster and Isabelle 1992; Gale and Church 1993; Chen 1993), word alignment (Gale and Church 1991a; Brown et al. 1993; Dagan, Church, and Gale 1993; Fung and McKeown 1994; Fung 1995b), alignment of groups of words (Smadja 1992; Kupiec 1993; van der Eijk 1993), and statistical translation (Brown et al. 1993). Of these, aligning groups of words is most similar to the work reported here, although, as we shall show, we consider a greater variety of groups than is typical in other research. In this section, we describe work on sentence and word alignment and s</context>
<context position="8340" citStr="Gale and Church (1991" startWordPosition="1279" endWordPosition="1282">ffer from our own, and then describe work on aligning groups of words. Note that there is additional research using statistical approaches to bilingual problems, but it is less related to ours, addressing, for example, word sense disambiguation in the source language by statistically examining context (e.g., collocations) in the source language, thus allowing appropriate word selection in the target language. (Brown et al. 1991; Dagan, Itai, and Schwall 1991; Dagan and Itai 1994). Our use of bilingual corpora assumes a prealigned corpus. Thus, we draw on work done at AT&amp;T Bell Laboratories by Gale and Church (1991a, 1991b, 1993) and at IBM by Brown, Lai, and Mercer (1991) on bilingual sentence alignment. Sentence alignment programs take a paired bilingual corpus as input and determine which sentences in the target language translate which sentences in the source language. Both the AT&amp;T and the IBM groups use purely statistical techniques based on sentence length to identify sentence pairing in corpora such as the Hansards. The AT&amp;T group (Gale and Church 1993) defines sentence length by the number of characters in the sentences, while the IBM group (Brown, Lai, and Mercer 1991) defines sentence length </context>
<context position="48970" citStr="Gale and Church 1991" startWordPosition="7880" endWordPosition="7883">ampollion. 5. Champollion: The Algorithm and the Implementation Champollion translates single words or collocations in one language into collocations (including single word translations) in a second language using the aligned corpus as a reference database. Before running Champollion there are two steps that must be carried out: source and target language sentences of the database corpus must be aligned and a list of collocations to be translated must be provided in the source language. For our experiments, we used corpora that had been aligned by Gale and Church&apos;s sentence alignment program (Gale and Church 1991b) as our input data.8 Since our intent in this paper is to evaluate Champollion, we tried not to introduce errors into the training data; for this purpose, we kept only the 1-1 alignments. Indeed, more complex sentence alignments tend to have a much higher alignment error rate (Gale and Church 1991b). By doing so, we lost an estimated 10% of the text (Brown, Lai, and Mercer 1991), which was not problematic since we had enough data. In the future, we plan to design more flexible techniques that would work from a loosely aligned corpus (see Section 9). To compile collocations, we used XTRACT on</context>
<context position="52036" citStr="Gale and Church (1991" startWordPosition="8370" endWordPosition="8373">e of the Dice coefficient is not crucial; for example, using the Jaccard coefficient or any other similarity measure that is monotonically related to the Dice coefficient would be equivalent. What is important is that the selected measure satisfy the conditions of asymmetry insensitivity to marginal word probabilities, and convenience in testing for correlation. There are many other possible measures of association, and the general points made in this section may apply to them insofar as they also exhibit the properties we discussed. For example, the normalized chi-square measure (02) used in Gale and Church (1991a) shares some of the important properties of average mutual information (for example, it is completely symmetric with respect to 1-1 and 0-0 matches). 8 We are thankful to Ken Church and the AT&amp;T Bell Laboratories for providing us with a prealigned Hansards corpus. Computational Linguistics Volume 22, Number 1 Table 5 Some collocations identified by XTRACT. Collocation Type Canadian Charter of Rights and Freedoms rigid Canadian Human Rights Commission rigid enforce provisions flexible enforce vigorously flexible express hope flexible gays and lesbians rigid health and safety problems rigid he</context>
<context position="115547" citStr="Gale and Church 1991" startWordPosition="18595" endWordPosition="18598">hnique to all constructions uniformly. Our work is part of a paradigm of research that focuses on the development of tools using statistical analysis of text corpora. This line of research aims at producing tools 34 Smadja, McKeown, and Hatzivassiloglou Translating Collocations for Bilingual Lexicons that satisfactorily handle relatively simple tasks. These tools can then be used by other systems to address more complex tasks. For example, previous work has addressed low-level tasks such as tagging a free-style corpus with part-of-speech information (Church 1988), aligning a bilingual corpus (Gale and Church 1991b; Brown, Lai, and Mercer 1991), and producing a list of collocations (Smadja 1993). While each of these tools is based on simple statistics and tackles elementary tasks, we have demonstrated with our work on Champollion that by combining them, one can reach new levels of complexity in the automatic treatment of natural languages. Acknowledgments This work was supported jointly by the Advanced Research Projects Agency and the Office of Naval Research under grant N00014-89—J-1782, by the Office of Naval Research under grant N00014-95-1-0745, by the National Science Foundation under grant GER-90</context>
</contexts>
<marker>Gale, Church, 1991</marker>
<rawString>Gale, William A. and Church, Kenneth W. (1991a). Identifying Word Correspondences in Parallel Texts. In Proceedings, DARPA Speech and Natural Language Workshop, Pacific Grove, California, 152-157. Morgan Kaufmann, San Mateo, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William A Gale</author>
<author>Kenneth W Church</author>
</authors>
<title>A Program for Aligning Sentences in Bilingual Corpora.</title>
<date>1991</date>
<booktitle>In Proceedings, 29th Annual Meeting of the ACL,</booktitle>
<pages>177--184</pages>
<institution>Association for Computational Linguistics.</institution>
<location>Berkeley, California,</location>
<contexts>
<context position="7069" citStr="Gale and Church 1991" startWordPosition="1074" endWordPosition="1077">. Next, we turn to a description of the results and evaluation. Finally, we show how the results can be used for a variety of applications, closing with a discussion of the limitations of our approach and of future work. 1 None of the authors is affiliated with Boitet&apos;s research center on machine translation in Grenoble, France, which is also named &amp;quot;Champollion&amp;quot;. 2 Smadja, McKeown, and Hatzivassiloglou Translating Collocations for Bilingual Lexicons 2. Related Work The recent availability of large amounts of bilingual data has attracted interest in several areas, including sentence alignment (Gale and Church 1991b; Brown, Lai, and Mercer 1991; Simard, Foster and Isabelle 1992; Gale and Church 1993; Chen 1993), word alignment (Gale and Church 1991a; Brown et al. 1993; Dagan, Church, and Gale 1993; Fung and McKeown 1994; Fung 1995b), alignment of groups of words (Smadja 1992; Kupiec 1993; van der Eijk 1993), and statistical translation (Brown et al. 1993). Of these, aligning groups of words is most similar to the work reported here, although, as we shall show, we consider a greater variety of groups than is typical in other research. In this section, we describe work on sentence and word alignment and s</context>
<context position="8340" citStr="Gale and Church (1991" startWordPosition="1279" endWordPosition="1282">ffer from our own, and then describe work on aligning groups of words. Note that there is additional research using statistical approaches to bilingual problems, but it is less related to ours, addressing, for example, word sense disambiguation in the source language by statistically examining context (e.g., collocations) in the source language, thus allowing appropriate word selection in the target language. (Brown et al. 1991; Dagan, Itai, and Schwall 1991; Dagan and Itai 1994). Our use of bilingual corpora assumes a prealigned corpus. Thus, we draw on work done at AT&amp;T Bell Laboratories by Gale and Church (1991a, 1991b, 1993) and at IBM by Brown, Lai, and Mercer (1991) on bilingual sentence alignment. Sentence alignment programs take a paired bilingual corpus as input and determine which sentences in the target language translate which sentences in the source language. Both the AT&amp;T and the IBM groups use purely statistical techniques based on sentence length to identify sentence pairing in corpora such as the Hansards. The AT&amp;T group (Gale and Church 1993) defines sentence length by the number of characters in the sentences, while the IBM group (Brown, Lai, and Mercer 1991) defines sentence length </context>
<context position="48970" citStr="Gale and Church 1991" startWordPosition="7880" endWordPosition="7883">ampollion. 5. Champollion: The Algorithm and the Implementation Champollion translates single words or collocations in one language into collocations (including single word translations) in a second language using the aligned corpus as a reference database. Before running Champollion there are two steps that must be carried out: source and target language sentences of the database corpus must be aligned and a list of collocations to be translated must be provided in the source language. For our experiments, we used corpora that had been aligned by Gale and Church&apos;s sentence alignment program (Gale and Church 1991b) as our input data.8 Since our intent in this paper is to evaluate Champollion, we tried not to introduce errors into the training data; for this purpose, we kept only the 1-1 alignments. Indeed, more complex sentence alignments tend to have a much higher alignment error rate (Gale and Church 1991b). By doing so, we lost an estimated 10% of the text (Brown, Lai, and Mercer 1991), which was not problematic since we had enough data. In the future, we plan to design more flexible techniques that would work from a loosely aligned corpus (see Section 9). To compile collocations, we used XTRACT on</context>
<context position="52036" citStr="Gale and Church (1991" startWordPosition="8370" endWordPosition="8373">e of the Dice coefficient is not crucial; for example, using the Jaccard coefficient or any other similarity measure that is monotonically related to the Dice coefficient would be equivalent. What is important is that the selected measure satisfy the conditions of asymmetry insensitivity to marginal word probabilities, and convenience in testing for correlation. There are many other possible measures of association, and the general points made in this section may apply to them insofar as they also exhibit the properties we discussed. For example, the normalized chi-square measure (02) used in Gale and Church (1991a) shares some of the important properties of average mutual information (for example, it is completely symmetric with respect to 1-1 and 0-0 matches). 8 We are thankful to Ken Church and the AT&amp;T Bell Laboratories for providing us with a prealigned Hansards corpus. Computational Linguistics Volume 22, Number 1 Table 5 Some collocations identified by XTRACT. Collocation Type Canadian Charter of Rights and Freedoms rigid Canadian Human Rights Commission rigid enforce provisions flexible enforce vigorously flexible express hope flexible gays and lesbians rigid health and safety problems rigid he</context>
<context position="115547" citStr="Gale and Church 1991" startWordPosition="18595" endWordPosition="18598">hnique to all constructions uniformly. Our work is part of a paradigm of research that focuses on the development of tools using statistical analysis of text corpora. This line of research aims at producing tools 34 Smadja, McKeown, and Hatzivassiloglou Translating Collocations for Bilingual Lexicons that satisfactorily handle relatively simple tasks. These tools can then be used by other systems to address more complex tasks. For example, previous work has addressed low-level tasks such as tagging a free-style corpus with part-of-speech information (Church 1988), aligning a bilingual corpus (Gale and Church 1991b; Brown, Lai, and Mercer 1991), and producing a list of collocations (Smadja 1993). While each of these tools is based on simple statistics and tackles elementary tasks, we have demonstrated with our work on Champollion that by combining them, one can reach new levels of complexity in the automatic treatment of natural languages. Acknowledgments This work was supported jointly by the Advanced Research Projects Agency and the Office of Naval Research under grant N00014-89—J-1782, by the Office of Naval Research under grant N00014-95-1-0745, by the National Science Foundation under grant GER-90</context>
</contexts>
<marker>Gale, Church, 1991</marker>
<rawString>Gale, William A. and Church, Kenneth W. (1991b). A Program for Aligning Sentences in Bilingual Corpora. In Proceedings, 29th Annual Meeting of the ACL, Berkeley, California, 177-184. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William A Gale</author>
<author>Kenneth W Church</author>
</authors>
<title>A Program for Aligning Sentences in Bilingual Corpora.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>1</issue>
<pages>75--102</pages>
<contexts>
<context position="7155" citStr="Gale and Church 1993" startWordPosition="1088" endWordPosition="1091">he results can be used for a variety of applications, closing with a discussion of the limitations of our approach and of future work. 1 None of the authors is affiliated with Boitet&apos;s research center on machine translation in Grenoble, France, which is also named &amp;quot;Champollion&amp;quot;. 2 Smadja, McKeown, and Hatzivassiloglou Translating Collocations for Bilingual Lexicons 2. Related Work The recent availability of large amounts of bilingual data has attracted interest in several areas, including sentence alignment (Gale and Church 1991b; Brown, Lai, and Mercer 1991; Simard, Foster and Isabelle 1992; Gale and Church 1993; Chen 1993), word alignment (Gale and Church 1991a; Brown et al. 1993; Dagan, Church, and Gale 1993; Fung and McKeown 1994; Fung 1995b), alignment of groups of words (Smadja 1992; Kupiec 1993; van der Eijk 1993), and statistical translation (Brown et al. 1993). Of these, aligning groups of words is most similar to the work reported here, although, as we shall show, we consider a greater variety of groups than is typical in other research. In this section, we describe work on sentence and word alignment and statistical translation, showing how these goals differ from our own, and then describe</context>
<context position="8795" citStr="Gale and Church 1993" startWordPosition="1351" endWordPosition="1354">ll 1991; Dagan and Itai 1994). Our use of bilingual corpora assumes a prealigned corpus. Thus, we draw on work done at AT&amp;T Bell Laboratories by Gale and Church (1991a, 1991b, 1993) and at IBM by Brown, Lai, and Mercer (1991) on bilingual sentence alignment. Sentence alignment programs take a paired bilingual corpus as input and determine which sentences in the target language translate which sentences in the source language. Both the AT&amp;T and the IBM groups use purely statistical techniques based on sentence length to identify sentence pairing in corpora such as the Hansards. The AT&amp;T group (Gale and Church 1993) defines sentence length by the number of characters in the sentences, while the IBM group (Brown, Lai, and Mercer 1991) defines sentence length by the number of words in the sentence. Both approaches achieve similar results and have been influential in much of the research on statistical natural language processing, including ours. It has been noted in more recent work that length-based alignment programs such as these are problematic for many cases of real world parallel data, such as OCR (Optical Character Recognition) input, in which periods may not be noticeable (Church 1993), or language</context>
</contexts>
<marker>Gale, Church, 1993</marker>
<rawString>Gale, William A. and Church, Kenneth W. (1993). A Program for Aligning Sentences in Bilingual Corpora. Computational Linguistics, 19(1): 75-102.</rawString>
</citation>
<citation valid="false">
<title>Do We Need Linguistics When We Have Statistics? A Comparative Analysis of the Contributions of Linguistic Cues to a Statistical Word Grouping System.&amp;quot;</title>
<booktitle>In The Balancing Act: Combining Symbolic and Statistical Approaches</booktitle>
<publisher>MIT Press,</publisher>
<location>Cambridge, Massachusetts.</location>
<note>to Language, edited by</note>
<marker></marker>
<rawString>Hatzivassiloglou, Vasileios. (in press). &amp;quot;Do We Need Linguistics When We Have Statistics? A Comparative Analysis of the Contributions of Linguistic Cues to a Statistical Word Grouping System.&amp;quot; In The Balancing Act: Combining Symbolic and Statistical Approaches to Language, edited by Judith L. Klavans and Philip Resnik. MIT Press, Cambridge, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vasileios Hatzivassiloglou</author>
<author>Kathleen R McKeown</author>
</authors>
<title>Towards the Automatic Identification of Adjectival Scales: Clustering Adjectives According to Meaning.</title>
<date>1993</date>
<booktitle>In Proceedings, 31st Annual Meeting of the ACL,</booktitle>
<pages>172--182</pages>
<institution>Association for Computational Linguistics.</institution>
<location>Columbus, Ohio,</location>
<contexts>
<context position="94226" citStr="Hatzivassiloglou and McKeown 1993" startWordPosition="15298" endWordPosition="15301"> in general, there is a single correct answer in each case, verifying the hypothesis of a unique translation per collocation independently of context, which we postulated in Section 4. They also indicate that it is generally easy for the evaluators to identify this unique correct answer. When there is not a single correct answer, or when it is not easy for the evaluators to identify the correct answer, it is prudent to guard against the introduction of (usually pro-system) bias by asking the evaluators to produce their answers independently of the system&apos;s output, as we have argued elsewhere (Hatzivassiloglou and McKeown 1993; Hatzivassiloglou in press). However, for the problem at hand, the uniqueness and accessibility of the correct answer greatly alleviates&apos; the danger of introducing bias by letting the evaluators grade the translations produced by Champollion. Since the latter method makes more efficient use of the judges, we decided to adopt it for our evaluation. Among the three experiments described above, our best results are obtained when the database corpus is also used as the corpus from which XTRACT identifies the source language collocations (experiment Cl /DB1). In this case, not counting XTRACT erro</context>
</contexts>
<marker>Hatzivassiloglou, McKeown, 1993</marker>
<rawString>Hatzivassiloglou, Vasileios and McKeown, Kathleen R. (1993). Towards the Automatic Identification of Adjectival Scales: Clustering Adjectives According to Meaning. In Proceedings, 31st Annual Meeting of the ACL, Columbus, Ohio, 172-182. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Informix</author>
</authors>
<date>1990</date>
<journal>C-ISAM Programmer&apos;s Manual. Informix Software, Inc.,</journal>
<location>Menlo Park, California.</location>
<contexts>
<context position="66503" citStr="Informix 1990" startWordPosition="10657" endWordPosition="10658">ted on up to two full years of the Hansards corpus, amounting to some 640,000 sentences in each language or about 220 megabytes of uncompressed text. With corpora of this magnitude, Champollion takes between one and two minutes to translate a collocation, thus enabling its practical use as a bilingual lexicography tool. To achieve efficient processing of the corpus database, Champollion is implemented in two phases: the preparation phase and the actual translation phase. The preparation phase reads in the database corpus and indexes it for fast future access using a commercial B-tree package (Informix 1990). Each word in the original corpus is associated with a set of pointers to all the sentences containing it and to the positions of the word in each of these sentences. The frequency of each word (in sentences) is also computed at this stage. Thus, all the necessary information is collected from the corpus database at this preprocessing phase with only one pass over the corpus file. At the translation phase, only the indices are accessed. For the translation phase, we developed an algorithm that avoids computing the Dice coefficient for French words when the result must necessarily fall below t</context>
</contexts>
<marker>Informix, 1990</marker>
<rawString>Informix. (1990). C-ISAM Programmer&apos;s Manual. Informix Software, Inc., Menlo Park, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul S Jacobs</author>
<author>Lisa F Rau</author>
</authors>
<title>The GE NLToolset: A Software Foundation for Intelligent Text Processing.</title>
<date>1990</date>
<booktitle>In Proceedings, 13th International Conference on Computational Linguistics (COLING-90), edited by Hans Karlgren,</booktitle>
<volume>3</volume>
<pages>373--377</pages>
<location>Helsinki,</location>
<contexts>
<context position="98294" citStr="Jacobs and Rau 1990" startWordPosition="15925" endWordPosition="15928">ilingual systems are now being developed in addition to pure machine translation systems. These systems also need access to bilingual phrases. We are currently developing a multilingual summarization system, in which we will use the results from Champollion. An early version of this system (McKeown and Radev 1995) produces short summaries of multiple news articles covering the same event using as input the templates produced by information extraction systems developed under the ARPA message understanding program. Since some information extraction systems, such as General Electric&apos;s NLToolset (Jacobs and Rau 1990), already produce similar representations for Japanese and English news articles, the addition of an English summary generator will automatically allow for English summarization of Japanese. In addition, we are planning to add a second language for the summaries. While the output is not a direct translation of input articles, collocations that appear frequently in the news articles will also appear in summaries. Thus, a list of bilingual collocations would be useful for the summarization process. Information retrieval is another prospective application. As shown in Maarek and Smadja (1989) and</context>
</contexts>
<marker>Jacobs, Rau, 1990</marker>
<rawString>Jacobs, Paul S. and Rau, Lisa F. (1990). The GE NLToolset: A Software Foundation for Intelligent Text Processing. In Proceedings, 13th International Conference on Computational Linguistics (COLING-90), edited by Hans Karlgren, Helsinki, Finland, 3: 373-377.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Judith L Klavans</author>
<author>Evelyne Tzoukermann</author>
</authors>
<title>The BICORD System: Combining Lexical Information from Bilingual Corpora and Machine Readable Dictionaries.</title>
<date>1990</date>
<booktitle>In Proceedings, 13th International Conference on Computational Linguistics (COLING-90), edited by Hans Karlgren,</booktitle>
<volume>3</volume>
<pages>174--179</pages>
<location>Helsinki,</location>
<contexts>
<context position="16301" citStr="Klavans and Tzoukermann 1990" startWordPosition="2512" endWordPosition="2515">echniques suitable to Asian/Romance language pairs as well as Romance language pairs. Given that Asian languages differ considerably in structure from Romance languages, statistical methods that were previously proposed for pairs of European languages do not work well for these pairs. Fung and McKeown&apos;s work also focuses on word alignment from noisy parallel corpora, where there are no clear sentence boundaries or perfect translations. Work on the translation of single words into multiword sequences that integrates techniques for machine-readable dictionaries with statistical corpus analysis (Klavans and Tzoukermann 1990; Klavans and Tzoukermann in press) is also relevant. While this work focuses on a smaller set of words for translation (movement verbs), it provides a sophisticated approach using multiple knowledge sources to address both one-to-many word translations and the problem of sense disambiguation. Given only one word in the source, their system, BICORD, uses the corpus to extend dictionary definitions and provide translations that are appropriate for a given sense but do not occur in the dictionary, producing a bilingual lexicon of movement verbs as output. 3. Collocations and Machine Translation </context>
<context position="24923" citStr="Klavans and Tzoukermann 1990" startWordPosition="3887" endWordPosition="3890">hy this measure is more appropriate than another frequently used measure—mutual information. Our approach is based on the assumption that each collocation is unambiguous in the source language and has a unique translation in the target language (at least in a clear majority of the cases). In this way, we can ignore the context of the collocations and their translations, and base our decisions only on the patterns of co-occurrence of each collocation and its candidate translations across the entire corpus. This approach is quite different from those adopted for the translation of single words (Klavans and Tzoukermann 1990; Dorr 1992; Klavans and Tzoukermann 1996), since for single words polysemy cannot be ignored; indeed, the problem of sense disambiguation has been linked to the problem of translating ambiguous words (Brown et al. 1991; Dagan, Itai, and Schwa11 1991; Dagan and Itai 1994). The assumption of a single meaning per collocation was based on our previous experience with English collocations (Smadja 1993), is supported for less opaque collocations by the fact that their constituent words tend to have a single sense when they appear in the collocation (Yarowsky 1993), and was verified during our evalu</context>
</contexts>
<marker>Klavans, Tzoukermann, 1990</marker>
<rawString>Klavans, Judith L. and Tzoukermann, Evelyne. (1990). The BICORD System: Combining Lexical Information from Bilingual Corpora and Machine Readable Dictionaries. In Proceedings, 13th International Conference on Computational Linguistics (COLING-90), edited by Hans Karlgren, Helsinki, Finland, 3: 174-179.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Judith L Klavans</author>
<author>Evelyne Tzoukermann</author>
</authors>
<title>Combining Corpus and Machine-Readable Dictionary Data for Building Bilingual Lexicons.</title>
<date>1996</date>
<journal>Machine Translation,</journal>
<volume>10</volume>
<issue>2</issue>
<contexts>
<context position="24965" citStr="Klavans and Tzoukermann 1996" startWordPosition="3893" endWordPosition="3896">another frequently used measure—mutual information. Our approach is based on the assumption that each collocation is unambiguous in the source language and has a unique translation in the target language (at least in a clear majority of the cases). In this way, we can ignore the context of the collocations and their translations, and base our decisions only on the patterns of co-occurrence of each collocation and its candidate translations across the entire corpus. This approach is quite different from those adopted for the translation of single words (Klavans and Tzoukermann 1990; Dorr 1992; Klavans and Tzoukermann 1996), since for single words polysemy cannot be ignored; indeed, the problem of sense disambiguation has been linked to the problem of translating ambiguous words (Brown et al. 1991; Dagan, Itai, and Schwa11 1991; Dagan and Itai 1994). The assumption of a single meaning per collocation was based on our previous experience with English collocations (Smadja 1993), is supported for less opaque collocations by the fact that their constituent words tend to have a single sense when they appear in the collocation (Yarowsky 1993), and was verified during our evaluation of Champollion (Section 7). We const</context>
</contexts>
<marker>Klavans, Tzoukermann, 1996</marker>
<rawString>Klavans, Judith L. and Tzoukermann, Evelyne. (1996). Combining Corpus and Machine-Readable Dictionary Data for Building Bilingual Lexicons. Machine Translation, 10(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julian M Kupiec</author>
</authors>
<title>An Algorithm for Finding Noun Phrase Correspondences in Bilingual Corpora.</title>
<date>1993</date>
<booktitle>In Proceedings, 31st Annual Meeting of the ACL,</booktitle>
<pages>17--22</pages>
<institution>Association for Computational Linguistics.</institution>
<location>Columbus, Ohio,</location>
<contexts>
<context position="7347" citStr="Kupiec 1993" startWordPosition="1122" endWordPosition="1123">on machine translation in Grenoble, France, which is also named &amp;quot;Champollion&amp;quot;. 2 Smadja, McKeown, and Hatzivassiloglou Translating Collocations for Bilingual Lexicons 2. Related Work The recent availability of large amounts of bilingual data has attracted interest in several areas, including sentence alignment (Gale and Church 1991b; Brown, Lai, and Mercer 1991; Simard, Foster and Isabelle 1992; Gale and Church 1993; Chen 1993), word alignment (Gale and Church 1991a; Brown et al. 1993; Dagan, Church, and Gale 1993; Fung and McKeown 1994; Fung 1995b), alignment of groups of words (Smadja 1992; Kupiec 1993; van der Eijk 1993), and statistical translation (Brown et al. 1993). Of these, aligning groups of words is most similar to the work reported here, although, as we shall show, we consider a greater variety of groups than is typical in other research. In this section, we describe work on sentence and word alignment and statistical translation, showing how these goals differ from our own, and then describe work on aligning groups of words. Note that there is additional research using statistical approaches to bilingual problems, but it is less related to ours, addressing, for example, word sens</context>
<context position="10991" citStr="Kupiec (1993)" startWordPosition="1687" endWordPosition="1688">information on recent results). While they also align groups of words across languages in the process of translation, they are careful to point out that such groups may or may not occur at constituent breaks in the sentence. In contrast, our work aims at identifying syntactically and semantically meaningful units, which may be either constituents or flexible word pairs separated by intervening words, and provides the translation of these units for use in a variety of bilingual applications. Thus, the goals of our research are somewhat different. 3 Computational Linguistics Volume 22, Number 1 Kupiec (1993) describes a technique for finding noun phrase correspondences in bilingual corpora using several stages. First, as for Champollion, the bilingual corpus must be aligned by sentences. Then, each corpus is separately run through a partof-speech tagger and noun phrase recognizer. Finally, noun phrases are mapped to each other using an iterative re-estimation algorithm. Evaluation was done on the 100 highest-ranking correspondences produced by the program, yielding 90% accuracy. Evaluation has not been completed for the remaining correspondences-4900 distinct English noun phrases. The author indi</context>
</contexts>
<marker>Kupiec, 1993</marker>
<rawString>Kupiec, Julian M. (1993). An Algorithm for Finding Noun Phrase Correspondences in Bilingual Corpora. In Proceedings, 31st Annual Meeting of the ACL, Columbus, Ohio, 17-22. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard L Leed</author>
<author>Alexander D Nakhimovsky</author>
</authors>
<title>Lexical Functions and Language Learning.</title>
<date>1979</date>
<journal>Slavic and East European Journal,</journal>
<volume>23</volume>
<issue>1</issue>
<pages>104--113</pages>
<contexts>
<context position="2651" citStr="Leed and Nakhimovsky 1979" startWordPosition="392" endWordPosition="395">s paper, we describe a modern version of a similar approach: given a large corpus in two languages, our system produces translations of common word pairs and phrases that can form the basis of a bilingual lexicon. Our focus is on the use of statistical methods for the translation of multiword expressions, such as collocations which are often idiomatic in nature. Published translations of such collocations are not readily available, even for languages such as French and English, despite the fact that collocations have been recognized as one of the main obstacles to second language acquisition (Leed and Nakhimovsky 1979). * The work reported in this paper was done while the author was at Columbia University. His current address is NetPatrol Consulting, Tel Maneh 6, Haifa 34363, Israel. E-mail: smadj a@netvision . net . t Department of Computer Science, 450 Computer Science Building, Columbia University, New York, NY 10027, USA. E-mail: kathy@cs. columbia. edu, vh@cs.columbia.edu. C) 1996 Association for Computational Linguistics Computational Linguistics Volume 22, Number 1 We have developed a program named Champollion1 , which, given a sentencealigned parallel bilingual corpus, translates collocations (or in</context>
<context position="17059" citStr="Leed and Nakhimovsky 1979" startWordPosition="2627" endWordPosition="2630">bs), it provides a sophisticated approach using multiple knowledge sources to address both one-to-many word translations and the problem of sense disambiguation. Given only one word in the source, their system, BICORD, uses the corpus to extend dictionary definitions and provide translations that are appropriate for a given sense but do not occur in the dictionary, producing a bilingual lexicon of movement verbs as output. 3. Collocations and Machine Translation Collocations, commonly occurring word pairs and phrases, are a notorious source of difficulty for non-native speakers of a language (Leed and Nakhimovsky 1979; Benson 1985; Benson, Benson, and Ilson 1986). This is because they cannot be translated on a word-by-word basis. Instead, a speaker must be aware of the meaning of the phrase as a whole in the source language and know the common phrase typically used in the target language. While collocations are not predictable on the basis of syntactic or semantic rules, they can be observed in language and thus must be learned through repeated usage. For example, in American English one says set the table while in British English the phrase lay the table is used. These are expressions that have evolved ov</context>
</contexts>
<marker>Leed, Nakhimovsky, 1979</marker>
<rawString>Leed, Richard L. and Nakhimovsky, Alexander D. (1979). Lexical Functions and Language Learning. Slavic and East European Journal, 23(1): 104-113.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoelle Maarek</author>
<author>Frank Smadja</author>
</authors>
<title>Full Text Indexing Based on Lexical Relations. An Application: Software Libraries.</title>
<date>1989</date>
<booktitle>In Proceedings, 12th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,</booktitle>
<location>Cambridge, Massachusetts,</location>
<note>edited by</note>
<contexts>
<context position="98890" citStr="Maarek and Smadja (1989)" startWordPosition="16013" endWordPosition="16016">oolset (Jacobs and Rau 1990), already produce similar representations for Japanese and English news articles, the addition of an English summary generator will automatically allow for English summarization of Japanese. In addition, we are planning to add a second language for the summaries. While the output is not a direct translation of input articles, collocations that appear frequently in the news articles will also appear in summaries. Thus, a list of bilingual collocations would be useful for the summarization process. Information retrieval is another prospective application. As shown in Maarek and Smadja (1989) and more recently in Broglio et al. (1995), the precision of information retrieval systems can be improved through the use of collocations in addition to the more traditional single word indexing units. A collocation gives the context in which a given word was used, which will help retrieve documents using the word with the same sense and thus improve precision. The well-known New Mexico example in information retrieval describes an oft-encountered problem when single word searches are employed: searching for new and Mexico independently will retrieve a multitude of documents that do not rela</context>
</contexts>
<marker>Maarek, Smadja, 1989</marker>
<rawString>Maarek, Yoelle and Smadja, Frank. (1989). Full Text Indexing Based on Lexical Relations. An Application: Software Libraries. In Proceedings, 12th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, edited by Nicholas J. Belkin and C. J. van Rijsbergen, Cambridge, Massachusetts, 198-206.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kathleen R McKeown</author>
<author>Dragomir Radev</author>
</authors>
<title>Generating Summaries of Multiple News Articles.</title>
<date>1995</date>
<booktitle>In Proceedings, 18th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, edited by</booktitle>
<pages>74--82</pages>
<location>Seattle, Washington,</location>
<contexts>
<context position="97989" citStr="McKeown and Radev 1995" startWordPosition="15882" endWordPosition="15885">domain dependent. Particularly in technical domains, the collocations differ from those in general use. Accordingly, the ability to automatically discover collocations for a given domain by using a new corpus as input to Champollion would ease the work required to transfer an MT system to a new domain. Multilingual systems are now being developed in addition to pure machine translation systems. These systems also need access to bilingual phrases. We are currently developing a multilingual summarization system, in which we will use the results from Champollion. An early version of this system (McKeown and Radev 1995) produces short summaries of multiple news articles covering the same event using as input the templates produced by information extraction systems developed under the ARPA message understanding program. Since some information extraction systems, such as General Electric&apos;s NLToolset (Jacobs and Rau 1990), already produce similar representations for Japanese and English news articles, the addition of an English summary generator will automatically allow for English summarization of Japanese. In addition, we are planning to add a second language for the summaries. While the output is not a direc</context>
</contexts>
<marker>McKeown, Radev, 1995</marker>
<rawString>McKeown, Kathleen R. and Radev, Dragomir. (1995). Generating Summaries of Multiple News Articles. In Proceedings, 18th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, edited by Edward A. Fox, Peter Ingwersen, and Raya Fidel, Seattle, Washington, 74-82.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Athanasios Papoulis</author>
</authors>
<title>Probability, Random Variables, and Stochastic Processes.</title>
<date>1984</date>
<publisher>McGraw-Hill,</publisher>
<location>New York,</location>
<note>2nd edition.</note>
<contexts>
<context position="29286" citStr="Papoulis 1984" startWordPosition="4624" endWordPosition="4625">bution p(X, Y), so sometimes the term average mutual information is used for /(X, Y). Average mutual information expresses the difference between the entropy (information) of one of the variables and the conditional entropy of that variable given the other variable (Cover and Thomas 1991). Thus, average mutual information measures the reduction in the uncertainty about the value of one variable that knowledge of the value of the other variable provides, averaged over all possible values of the two variables. Equivalently, average mutual information is &amp;quot;the information about X contained in Y&amp;quot; (Papoulis 1984, 518) (or the information about Y contained in X). Specific 8 Smadja, McKeown, and Hatzivassiloglou Translating Collocations for Bilingual Lexicons mutual information represents the log-likelihood ratio of the joint probability of seeing a &amp;quot;1&amp;quot; in both variables over the probability that such an event would have if the two variables were independent, and thus provides a measure of the departure from independence. The Dice coefficient, on the other hand, combines the conditional probabilities p(X==1 I Y=1) and p(Y=1 I X=1) with equal weights in a single number. This can be shown by replacing p(</context>
</contexts>
<marker>Papoulis, 1984</marker>
<rawString>Papoulis, Athanasios. (1984). Probability, Random Variables, and Stochastic Processes. McGraw-Hill, New York, 2nd edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reuven Y Rubinstein</author>
</authors>
<title>Simulation and the Monte Carlo Method.</title>
<date>1981</date>
<publisher>Wiley,</publisher>
<location>New York.</location>
<marker>Rubinstein, 1981</marker>
<rawString>Rubinstein, Reuven Y. (1981). Simulation and the Monte Carlo Method. Wiley, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerard Salton</author>
<author>Michael J McGill</author>
</authors>
<title>Introduction to Modern Information Retrieval.</title>
<date>1983</date>
<publisher>McGraw-Hill,</publisher>
<location>New York.</location>
<contexts>
<context position="3749" citStr="Salton and McGill 1983" startWordPosition="552" endWordPosition="555">oped a program named Champollion1 , which, given a sentencealigned parallel bilingual corpus, translates collocations (or individual words) in the source language into collocations (or individual words) in the target language. The aligned corpus is used as a reference, or database corpus, and represents Champollion&apos; s knowledge of both languages. Champollion uses statistical methods to incrementally construct the collocation translation, adding one word at a time. As a correlation measure, Champollion uses the Dice coefficient (Dice 1945; Sorensen 1948) commonly used in information retrieval (Salton and McGill 1983; Frakes and Baeza-Yates 1992). For a given source language collocation, Champollion identifies individual words in the target language that are highly correlated with the source collocation, thus producing a set of words in the target language. These words are then combined in a systematic, iterative manner to produce a translation of the source language collocation. Champollion considers all pairs of these words and identifies any that are highly correlated with the source collocation. Next, triplets are produced by adding a highly correlated word to a highly correlated pair, and the triplet</context>
<context position="27211" citStr="Salton and McGill 1983" startWordPosition="4267" endWordPosition="4270">ment of correlation between a word group G in the source language and another word group H in the target language, we map the paired sentences in our corpus to a collection of paired samples for the random variables XG and XH. This modeling process allows us to use correlation metrics between paired samples of random variables (XG and Xx) to measure the correlation between word groups (G and H) across languages. There are several ways to measure the correlation of two such random variables. One measure frequently used in information retrieval is the Dice coefficient (Dice 1945; Sorensen 1948; Salton and McGill 1983; Frakes and Baeza-Yates 1992). It is defined as ,„ 2 . p(X=1, Y=1) (1) Dice(X, I) =p(X =1) + p(Y =1) where p(X, Y), p(X), and p(Y) are the joint and marginal probability mass functions of the variables X and Y, respectively. Using maximum likelihood estimates for the probabilities in the above equation, we have Dice(X,Y) = 2 fxy fx fy where fx, fy, and fxy are the absolute frequencies of appearance of &amp;quot;1&amp;quot;s for the variables X, Y, and both X and Y together, respectively. On the other hand, in computational linguistics, information-theoretic measures such as mutual information are widely used (</context>
</contexts>
<marker>Salton, McGill, 1983</marker>
<rawString>Salton, Gerard and McGill, Michael J. (1983). Introduction to Modern Information Retrieval. McGraw-Hill, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claude E Shannon</author>
</authors>
<title>A Mathematical Theory of Communication.</title>
<date>1948</date>
<journal>Bell System Technical Journal,</journal>
<volume>27</volume>
<pages>379--423</pages>
<contexts>
<context position="33560" citStr="Shannon 1948" startWordPosition="5350" endWordPosition="5351"> of asymmetry: adding 0-0 matches does not change any of the absolute frequencies fxY, fx, and fy, and so does not affect Dice(X,Y). On the other hand, average mutual information depends only on the distribution of X and Y and not on the actual values of the random variables. In fact, I(X, Y) is a completely symmetric measure. If the variables X and Y are transformed so that every &amp;quot;1&amp;quot; is replaced with a &amp;quot;0&amp;quot; and vice versa, the average mutual information between X and Y remains the same. This is appropriate in the context of communications for which mutual information was originally developed (Shannon 1948), where the ones and zeros encode two different states with no special preference for either of them. But in the context of translation, exchanging the &amp;quot;1&amp;quot;s and &amp;quot;0&amp;quot;s is equivalent to considering a word or word group to be present when it was absent and vice versa, thus converting all 1-1 matches to 0-0 matches and all 0-0 matches to 1-1 matches. As explained above, such a change should not be considered similarity preserving, since 1-1 matches are much more significant than 0-0 ones. As a concrete example, consider a corpus of 100 matched sentences, where each of the word groups associated wit</context>
</contexts>
<marker>Shannon, 1948</marker>
<rawString>Shannon, Claude E. (1948). A Mathematical Theory of Communication. Bell System Technical Journal, 27: 379-423 and 623-656.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hadar Shemtov</author>
</authors>
<title>Text Alignment in a Tool for Translating Revised Documents.</title>
<date>1993</date>
<booktitle>In Proceedings, Sixth Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>449--453</pages>
<institution>Association for Computational Linguistics.</institution>
<location>Utrecht, The</location>
<contexts>
<context position="9451" citStr="Shemtov 1993" startWordPosition="1456" endWordPosition="1457">aracters in the sentences, while the IBM group (Brown, Lai, and Mercer 1991) defines sentence length by the number of words in the sentence. Both approaches achieve similar results and have been influential in much of the research on statistical natural language processing, including ours. It has been noted in more recent work that length-based alignment programs such as these are problematic for many cases of real world parallel data, such as OCR (Optical Character Recognition) input, in which periods may not be noticeable (Church 1993), or languages where insertions or deletions are common (Shemtov 1993; Fung and McKeown 1994). These algorithms were adequate for our purposes, but could be replaced by algorithms more appropriate for noisy input corpora, if necessary Sentence alignment techniques are generally used as a preprocessing stage, before the main processing component that proposes actual translations, whether of words, phrases, or full text, and they are used this way in our work as well. Translation can be approached using statistical techniques alone. Brown et al. (1990, 1993) use a stochastic language model based on techniques used in speech recognition, combined with translation </context>
</contexts>
<marker>Shemtov, 1993</marker>
<rawString>Shemtov, Hadar. (1993). Text Alignment in a Tool for Translating Revised Documents. In Proceedings, Sixth Conference of the European Chapter of the Association for Computational Linguistics, Utrecht, The Netherlands, 449-453. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Simard</author>
<author>George F Foster</author>
<author>Pierre Isabelle</author>
</authors>
<title>Using Cognates to Align Sentences in Bilingual Corpora. In</title>
<date>1992</date>
<booktitle>Proceedings, Fourth International Conference on Theoretical and Methodological Issues in Machine Translation (TMI-92),</booktitle>
<pages>67--81</pages>
<location>Montreal, Canada,</location>
<marker>Simard, Foster, Isabelle, 1992</marker>
<rawString>Simard, Michel; Foster, George F.; and Isabelle, Pierre. (1992). Using Cognates to Align Sentences in Bilingual Corpora. In Proceedings, Fourth International Conference on Theoretical and Methodological Issues in Machine Translation (TMI-92), Montreal, Canada, 67-81.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank Smadja</author>
</authors>
<title>Extracting Collocations from Text. An Application: Language Generation. Doctoral dissertation,</title>
<date>1991</date>
<institution>Department of Computer Science, Columbia University,</institution>
<location>New York.</location>
<contexts>
<context position="22337" citStr="Smadja 1991" startWordPosition="3483" endWordPosition="3484">r phrases which cannot be translated on a word-by-word basis, in the source language. 2. Provide adequate translation for these collocations. For both tasks, general knowledge of the two languages is not sufficient. It is also necessary to know the expressions used in the sublanguage, since we have seen that idiomatic phrases often have different translations in a restricted sublanguage than in general usage. In order to produce a fluent translation of a full sentence, it is necessary to know the specific translation for each of the source collocations. We use XTRACT (Smadja and McKeown 1990; Smadja 1991a; Smadja 1993), a 6 Smadja, McKeown, and Hatzivassiloglou Translating Collocations for Bilingual Lexicons tool we developed previously, to identify collocations in the source language (task 1). XTRACT works in three stages. In the first stage, word pairs that co-occur with significant frequency are identified. These words can be separated by up to four intervening words and thus constitute flexible collocations. In the second stage, XTRACT identifies combinations of word pairs from stage one with other words and phrases, producing compounds and idiomatic templates (i.e., phrases with one or m</context>
<context position="92250" citStr="Smadja 1991" startWordPosition="14988" endWordPosition="14989">looking at the corpus. In Section 9, we describe a later version of Champollion in which we added the capability to identify these types of closed-class words during the last stage. 7.2 Evaluation Results The results of the evaluation experiments are given in Table 9. The first column describes the experiment, the second column gives the percentage of XTRACT errors, and the next two columns give the percentages of incorrect and correct translations of source collocations in comparison to the total number of collocations. Since our previous work shows that XTRACT has a rate of accuracy of 80% (Smadja 1991b), it is reasonable to expect a certain number of errors in the input to Champollion, but these should not contribute to the evaluation of Champollion. Consequently, we have included in the last column of the table the percentage of correct translations produced by Champollion in comparison to the total number of valid collocations supplied to it; namely, the percentage of Champ°llion&apos;s correct translations if XTRACT&apos;S errors are filtered from the input. This quantity is equal to the ratio of the fourth column over the sum of the third and fourth columns.&apos; The accuracy figures shown in Table </context>
</contexts>
<marker>Smadja, 1991</marker>
<rawString>Smadja, Frank. (1991a). Extracting Collocations from Text. An Application: Language Generation. Doctoral dissertation, Department of Computer Science, Columbia University, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank Smadja</author>
</authors>
<title>From N-grams to Collocations: An Evaluation of Xtract.</title>
<date>1991</date>
<booktitle>In Proceedings, 29th Annual Meeting of the ACL,</booktitle>
<pages>279--284</pages>
<institution>Association for Computational Linguistics.</institution>
<location>Berkeley, California,</location>
<contexts>
<context position="22337" citStr="Smadja 1991" startWordPosition="3483" endWordPosition="3484">r phrases which cannot be translated on a word-by-word basis, in the source language. 2. Provide adequate translation for these collocations. For both tasks, general knowledge of the two languages is not sufficient. It is also necessary to know the expressions used in the sublanguage, since we have seen that idiomatic phrases often have different translations in a restricted sublanguage than in general usage. In order to produce a fluent translation of a full sentence, it is necessary to know the specific translation for each of the source collocations. We use XTRACT (Smadja and McKeown 1990; Smadja 1991a; Smadja 1993), a 6 Smadja, McKeown, and Hatzivassiloglou Translating Collocations for Bilingual Lexicons tool we developed previously, to identify collocations in the source language (task 1). XTRACT works in three stages. In the first stage, word pairs that co-occur with significant frequency are identified. These words can be separated by up to four intervening words and thus constitute flexible collocations. In the second stage, XTRACT identifies combinations of word pairs from stage one with other words and phrases, producing compounds and idiomatic templates (i.e., phrases with one or m</context>
<context position="92250" citStr="Smadja 1991" startWordPosition="14988" endWordPosition="14989">looking at the corpus. In Section 9, we describe a later version of Champollion in which we added the capability to identify these types of closed-class words during the last stage. 7.2 Evaluation Results The results of the evaluation experiments are given in Table 9. The first column describes the experiment, the second column gives the percentage of XTRACT errors, and the next two columns give the percentages of incorrect and correct translations of source collocations in comparison to the total number of collocations. Since our previous work shows that XTRACT has a rate of accuracy of 80% (Smadja 1991b), it is reasonable to expect a certain number of errors in the input to Champollion, but these should not contribute to the evaluation of Champollion. Consequently, we have included in the last column of the table the percentage of correct translations produced by Champollion in comparison to the total number of valid collocations supplied to it; namely, the percentage of Champ°llion&apos;s correct translations if XTRACT&apos;S errors are filtered from the input. This quantity is equal to the ratio of the fourth column over the sum of the third and fourth columns.&apos; The accuracy figures shown in Table </context>
</contexts>
<marker>Smadja, 1991</marker>
<rawString>Smadja, Frank. (1991b). From N-grams to Collocations: An Evaluation of Xtract. In Proceedings, 29th Annual Meeting of the ACL, Berkeley, California, 279-284. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank Smadja</author>
</authors>
<title>How to Compile a Bilingual Collocational Lexicon Automatically.</title>
<date>1992</date>
<journal>Artificial Intelligence.</journal>
<booktitle>In Proceedings, AAAI-92 Workshop on Statistically-Based NLP Techniques,</booktitle>
<pages>65--71</pages>
<publisher>American Association for</publisher>
<location>Sari Jose, California,</location>
<contexts>
<context position="7334" citStr="Smadja 1992" startWordPosition="1120" endWordPosition="1121">earch center on machine translation in Grenoble, France, which is also named &amp;quot;Champollion&amp;quot;. 2 Smadja, McKeown, and Hatzivassiloglou Translating Collocations for Bilingual Lexicons 2. Related Work The recent availability of large amounts of bilingual data has attracted interest in several areas, including sentence alignment (Gale and Church 1991b; Brown, Lai, and Mercer 1991; Simard, Foster and Isabelle 1992; Gale and Church 1993; Chen 1993), word alignment (Gale and Church 1991a; Brown et al. 1993; Dagan, Church, and Gale 1993; Fung and McKeown 1994; Fung 1995b), alignment of groups of words (Smadja 1992; Kupiec 1993; van der Eijk 1993), and statistical translation (Brown et al. 1993). Of these, aligning groups of words is most similar to the work reported here, although, as we shall show, we consider a greater variety of groups than is typical in other research. In this section, we describe work on sentence and word alignment and statistical translation, showing how these goals differ from our own, and then describe work on aligning groups of words. Note that there is additional research using statistical approaches to bilingual problems, but it is less related to ours, addressing, for examp</context>
<context position="13102" citStr="Smadja 1992" startWordPosition="2025" endWordPosition="2026">he lower precision is due in part to the fact that van der Eijk evaluated all translations produced by the program while Kupiec only evaluated the top 2%. Note that the greatest difference between these two approaches and ours is that van der Eijk and Kupiec only handle noun phrases whereas collocations have been shown to include parts of noun phrases, categories other than noun phrases (e.g., verb phrases), as well as flexible phrases that involve words separated by an arbitrary number of other words (e.g., to take . . . steps, to demonstrate . . . support). In this work, as in earlier work (Smadja 1992), we address the full range of collocations including both flexible and rigid collocations for a variety of syntactic categories. Another approach, begun more recently than our work, is taken by Dagan and Church (1994), who use statistical methods to translate technical terminology. Like van der Eijk and Kupiec, they preprocess their corpora by tagging and by identifying noun phrases. However, they use a word alignment program as opposed to sentence alignment and they include single words as candidates for technical terms. One of the major differences between their work and ours is that, like </context>
<context position="40999" citStr="Smadja 1992" startWordPosition="6595" endWordPosition="6596">ent. Since we are looking for a way to identify positively correlated events we must be able to easily test the second case, while testing the first case is not relevant. Specific mutual information is a good measure of independence (which it was designed to measure), but good measures of independence are not necessarily good measures of similarity. The above arguments all support the use of the Dice coefficient over either average or specific mutual information. We have confirmed the theoretically expected behavior of the similarity measures through testing. In our early work on Champollion (Smadja 1992), we used specific mutual information (SI) as a correlation metric. After carefully studying the errors produced, we suspected that the Dice measure would produce better results for our task, according to the arguments given above. Consider the example given in Table 2. In the table, the second column represents candidate French word pairs for translating the single word today. The third column gives the frequency of the word today in a subset of the Hansards containing 182,584 sentences. The fourth column gives the frequency of each French word pair in the French counterpart of the same corpu</context>
</contexts>
<marker>Smadja, 1992</marker>
<rawString>Smadja, Frank. (1992). How to Compile a Bilingual Collocational Lexicon Automatically. In Proceedings, AAAI-92 Workshop on Statistically-Based NLP Techniques, Sari Jose, California, 65-71. American Association for Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank Smadja</author>
</authors>
<title>Retrieving Collocations From Text: Xtract.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>1</issue>
<pages>143--177</pages>
<contexts>
<context position="5108" citStr="Smadja 1993" startWordPosition="765" endWordPosition="766">lated combinations of words can be found. Champollion selects the group of words with the highest cardinality and correlation factor as the target collocation. Finally, it produces the correct word ordering of the target collocation by examining samples in the corpus. If word order is variable in the target collocation, Champollion labels it flexible (for example, to take steps to can appear as took immediate steps to, steps were taken to, etc.); otherwise, the correct word order is reported and the collocation is labeled rigid. To evaluate Champollion, we used a collocation compiler, XTRACT (Smadja 1993), to automatically produce several lists of source (English) collocations. These source collocations contain both flexible word pairs, which can be separated by an arbitrary number of words, and fixed constituents, such as compound noun phrases. Using XTRACT on three parts of the English data in the Hansards corpus, each representing one year&apos;s worth of data, we extracted three sets of collocations, each consisting of 300 randomly selected collocations occurring with medium frequency. We then ran Champollion on each of these sets, using three separate database corpora of varying size, also tak</context>
<context position="22352" citStr="Smadja 1993" startWordPosition="3485" endWordPosition="3486">h cannot be translated on a word-by-word basis, in the source language. 2. Provide adequate translation for these collocations. For both tasks, general knowledge of the two languages is not sufficient. It is also necessary to know the expressions used in the sublanguage, since we have seen that idiomatic phrases often have different translations in a restricted sublanguage than in general usage. In order to produce a fluent translation of a full sentence, it is necessary to know the specific translation for each of the source collocations. We use XTRACT (Smadja and McKeown 1990; Smadja 1991a; Smadja 1993), a 6 Smadja, McKeown, and Hatzivassiloglou Translating Collocations for Bilingual Lexicons tool we developed previously, to identify collocations in the source language (task 1). XTRACT works in three stages. In the first stage, word pairs that co-occur with significant frequency are identified. These words can be separated by up to four intervening words and thus constitute flexible collocations. In the second stage, XTRACT identifies combinations of word pairs from stage one with other words and phrases, producing compounds and idiomatic templates (i.e., phrases with one or more holes to be</context>
<context position="25324" citStr="Smadja 1993" startWordPosition="3951" endWordPosition="3952">of co-occurrence of each collocation and its candidate translations across the entire corpus. This approach is quite different from those adopted for the translation of single words (Klavans and Tzoukermann 1990; Dorr 1992; Klavans and Tzoukermann 1996), since for single words polysemy cannot be ignored; indeed, the problem of sense disambiguation has been linked to the problem of translating ambiguous words (Brown et al. 1991; Dagan, Itai, and Schwa11 1991; Dagan and Itai 1994). The assumption of a single meaning per collocation was based on our previous experience with English collocations (Smadja 1993), is supported for less opaque collocations by the fact that their constituent words tend to have a single sense when they appear in the collocation (Yarowsky 1993), and was verified during our evaluation of Champollion (Section 7). We construct a mathematical model of the events we want to correlate, namely, the appearance of any word or group of words in the sentences of our corpus, as follows: To each group of words G, in either the source or the target language, we map a binary random variable XG that takes the value &amp;quot;1&amp;quot; if G appears in a particular sentence and &amp;quot;0&amp;quot; if not. Then, the corpu</context>
<context position="115630" citStr="Smadja 1993" startWordPosition="18610" endWordPosition="18611">ses on the development of tools using statistical analysis of text corpora. This line of research aims at producing tools 34 Smadja, McKeown, and Hatzivassiloglou Translating Collocations for Bilingual Lexicons that satisfactorily handle relatively simple tasks. These tools can then be used by other systems to address more complex tasks. For example, previous work has addressed low-level tasks such as tagging a free-style corpus with part-of-speech information (Church 1988), aligning a bilingual corpus (Gale and Church 1991b; Brown, Lai, and Mercer 1991), and producing a list of collocations (Smadja 1993). While each of these tools is based on simple statistics and tackles elementary tasks, we have demonstrated with our work on Champollion that by combining them, one can reach new levels of complexity in the automatic treatment of natural languages. Acknowledgments This work was supported jointly by the Advanced Research Projects Agency and the Office of Naval Research under grant N00014-89—J-1782, by the Office of Naval Research under grant N00014-95-1-0745, by the National Science Foundation under grant GER-90-24069, and by the New York State Science and Technology Foundation under grants NY</context>
</contexts>
<marker>Smadja, 1993</marker>
<rawString>Smadja, Frank. (1993). Retrieving Collocations From Text: Xtract. Computational Linguistics, 19(1): 143-177.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank Smadja</author>
<author>Kathleen R McKeown</author>
</authors>
<title>Automatically Extracting and Representing Collocations for Language Generation.</title>
<date>1990</date>
<booktitle>In Proceedings, 28th Annual Meeting of the ACL,</booktitle>
<pages>252--259</pages>
<institution>Association for Computational Linguistics.</institution>
<location>Pittsburgh, Pennsylvania,</location>
<contexts>
<context position="22324" citStr="Smadja and McKeown 1990" startWordPosition="3479" endWordPosition="3482"> Identify collocations, or phrases which cannot be translated on a word-by-word basis, in the source language. 2. Provide adequate translation for these collocations. For both tasks, general knowledge of the two languages is not sufficient. It is also necessary to know the expressions used in the sublanguage, since we have seen that idiomatic phrases often have different translations in a restricted sublanguage than in general usage. In order to produce a fluent translation of a full sentence, it is necessary to know the specific translation for each of the source collocations. We use XTRACT (Smadja and McKeown 1990; Smadja 1991a; Smadja 1993), a 6 Smadja, McKeown, and Hatzivassiloglou Translating Collocations for Bilingual Lexicons tool we developed previously, to identify collocations in the source language (task 1). XTRACT works in three stages. In the first stage, word pairs that co-occur with significant frequency are identified. These words can be separated by up to four intervening words and thus constitute flexible collocations. In the second stage, XTRACT identifies combinations of word pairs from stage one with other words and phrases, producing compounds and idiomatic templates (i.e., phrases </context>
</contexts>
<marker>Smadja, McKeown, 1990</marker>
<rawString>Smadja, Frank and McKeown, Kathleen R. (1990). Automatically Extracting and Representing Collocations for Language Generation. In Proceedings, 28th Annual Meeting of the ACL, Pittsburgh, Pennsylvania, 252-259. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorvald J SOrensen</author>
</authors>
<title>A Method of Establishing Groups of Equal Amplitude in Plant Sociology Based on Similarity of Species Content and its Application to Analysis of the Vegetation of Danish Commons.</title>
<date>1948</date>
<journal>Biologiske Skrifter,</journal>
<volume>5</volume>
<issue>4</issue>
<pages>1--34</pages>
<marker>SOrensen, 1948</marker>
<rawString>SOrensen, Thorvald J. (1948). A Method of Establishing Groups of Equal Amplitude in Plant Sociology Based on Similarity of Species Content and its Application to Analysis of the Vegetation of Danish Commons. Biologiske Skrifter, 5(4): 1-34.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Keh-Yih Su</author>
<author>Ming-Wen Wu</author>
<author>Jing-Shin Chang</author>
</authors>
<title>A Corpus-based Approach to Automatic Compound Extraction.</title>
<date>1994</date>
<booktitle>In Proceedings, 32nd Annual Meeting of the ACL, Las</booktitle>
<pages>242--247</pages>
<institution>Association for Computational Linguistics.</institution>
<location>Cruces, New</location>
<marker>Su, Wu, Chang, 1994</marker>
<rawString>Su, Keh-Yih; Wu, Ming-Wen; and Chang, Jing-Shin. (1994). A Corpus-based Approach to Automatic Compound Extraction. In Proceedings, 32nd Annual Meeting of the ACL, Las Cruces, New Mexico, 242-247. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
<author>Xuanyuin Xia</author>
</authors>
<title>Learning an English-Chinese Lexicon from a Parallel Corpus. In</title>
<date>1994</date>
<booktitle>Proceedings, First Conference of the Association for Machine Translation in the Americas (AMTA),</booktitle>
<pages>206--213</pages>
<location>Columbia, Maryland,</location>
<contexts>
<context position="15257" citStr="Wu and Xia 1994" startWordPosition="2363" endWordPosition="2366"> time (compare with Champollion&apos;s 73% accuracy). Since Termight is fully integrated within a translator&apos;s editor (another unique feature) and is used as an aid for human translators, it gets around the problem of accuracy by presenting the sorted list of translations to the translator for a choice. In all cases, the correct translation was found in this list and translators were able to speed up both the task of identifying technical terminology and translating terms. Other recent related work aims at using statistical techniques to produce translations of single words (Fung and McKeown 1994; Wu and Xia 1994; Fung 1995b) 4 Smadja, McKeown, and Hatzivassiloglou Translating Collocations for Bilingual Lexicons as opposed to collocations or phrases. Wu and Xia (1994) employed an estimationmaximization technique to find the optimal word alignment from previously sentencealigned clean parallel corpora2, with additional significance filtering. The work by Fung and McKeown (1994) and Fung (1995b) is notable for its use of techniques suitable to Asian/Romance language pairs as well as Romance language pairs. Given that Asian languages differ considerably in structure from Romance languages, statistical me</context>
</contexts>
<marker>Wu, Xia, 1994</marker>
<rawString>Wu, Dekai and Xia, Xuanyuin. (1994). Learning an English-Chinese Lexicon from a Parallel Corpus. In Proceedings, First Conference of the Association for Machine Translation in the Americas (AMTA), Columbia, Maryland, 206-213.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
</authors>
<title>One Sense Per Collocation.</title>
<date>1993</date>
<booktitle>In Proceedings, ARPA Workshop on Human Language Technology,</booktitle>
<publisher>Morgan Kaufmann,</publisher>
<location>Plainsboro, New Jersey,</location>
<contexts>
<context position="25488" citStr="Yarowsky 1993" startWordPosition="3978" endWordPosition="3979">ion of single words (Klavans and Tzoukermann 1990; Dorr 1992; Klavans and Tzoukermann 1996), since for single words polysemy cannot be ignored; indeed, the problem of sense disambiguation has been linked to the problem of translating ambiguous words (Brown et al. 1991; Dagan, Itai, and Schwa11 1991; Dagan and Itai 1994). The assumption of a single meaning per collocation was based on our previous experience with English collocations (Smadja 1993), is supported for less opaque collocations by the fact that their constituent words tend to have a single sense when they appear in the collocation (Yarowsky 1993), and was verified during our evaluation of Champollion (Section 7). We construct a mathematical model of the events we want to correlate, namely, the appearance of any word or group of words in the sentences of our corpus, as follows: To each group of words G, in either the source or the target language, we map a binary random variable XG that takes the value &amp;quot;1&amp;quot; if G appears in a particular sentence and &amp;quot;0&amp;quot; if not. Then, the corpus of paired sentences comprising our database represents a collection of samples for the various random variables X for the various groups of words. Each new senten</context>
</contexts>
<marker>Yarowsky, 1993</marker>
<rawString>Yarowsky, David. (1993). One Sense Per Collocation. In Proceedings, ARPA Workshop on Human Language Technology, Plainsboro, New Jersey, 266-271. ARPA Software and Intelligent Systems Technology Office, Morgan Kaufmann, San Francisco, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George K Zipf</author>
</authors>
<title>Human Behavior and the Principle of Least Effort: An Introduction to Human Ecology.</title>
<date>1949</date>
<publisher>Addison-Wesley,</publisher>
<location>Reading, Massachusetts.</location>
<contexts>
<context position="108568" citStr="Zipf 1949" startWordPosition="17530" endWordPosition="17531">pus is not consistently translated into the same target collocation in the database. This sampling problem, which generally affects all statistical approaches, was not addressed in the paper. We reduced the effects of low frequencies by purposefully limiting ourselves to source collocations of frequencies higher than 10, containing individual words with frequencies higher than 15. Analysis of the effects of our thresholds. Various thresholds are used in Champollion&apos;s algorithm to reduce the search space. A threshold too low would significantly slow down the search as, according to Zipf&apos;s law (Zipf 1949), the number of terms occurring n times in a general English corpus is a decreasing function of n2. Unfortunately, sometimes this filtering step causes Champollion to miss a valid translation. For example, one of the incorrect translations made by Champollion is that important factor was translated into facteur (factor) alone instead of the proper translation facteur important. The error is due to the fact that the French word important did not pass the first step of the algorithm as its Dice coefficient with important factor was too low. Important occurs a total of 858 times in the French par</context>
</contexts>
<marker>Zipf, 1949</marker>
<rawString>Zipf, George K. (1949). Human Behavior and the Principle of Least Effort: An Introduction to Human Ecology. Addison-Wesley, Reading, Massachusetts.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>