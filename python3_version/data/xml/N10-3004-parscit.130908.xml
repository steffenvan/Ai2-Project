<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.015995">
<title confidence="0.990673">
Extrinsic Parse Selection
</title>
<author confidence="0.996373">
David Goss-Grubbs
</author>
<affiliation confidence="0.9960675">
University of Washington
Department of Linguistics
</affiliation>
<address confidence="0.96183">
Box 354340
Seattle, WA 98195-4340, USA
</address>
<email confidence="0.990392">
davidgg@u.washington.edu
</email>
<sectionHeader confidence="0.995384" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99942225">
This paper reports on one aspect of Locutus, a
natural language interface to databases
(NLIDB) which uses the output of a high-
precision broad-coverage grammar to build
semantic representations and ultimately SQL
queries. Rather than selecting just a subset of
the parses provided by the grammar to use in
further processing, Locutus uses all of them. If
the meaning of a parse does not conform to
the semantic domain of the database, no query
is built for it. Thus, intended parses are chosen
extrinsically. The parser gives an average of
3.01 parses to the sentences in the
GEOQUERY250 corpus. Locutus generates an
average of 1.02 queries per sentence for this
corpus, all of them correct.
</bodyText>
<sectionHeader confidence="0.99913" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999948">
Natural language sentences are typically more am-
biguous than the people who utter them or perceive
them are aware of. People are very good at using
context and world knowledge to unconsciously
disambiguate them. High-precision, broad-
coverage grammars, however, often assign every
legitimate analysis to a given sentence, even when
only one of them reflects the sentence’s intended
meaning. It is thus important for natural language
processing applications that use these analyses to
be able to reliably select the intended parse. It is
typical for such applications to choose the best
parse up front and pass just that one on to further
</bodyText>
<page confidence="0.987996">
19
</page>
<bodyText confidence="0.999924333333333">
processing. For some applications, however, it is
possible, and indeed preferable, to pass all the
parses on and let downstream processing decide
which parses to use.
This paper describes such an application. Locu-
tus (Goss-Grubbs to appear), a natural language
interface to relational databases (NLIDB), creates
semantic representations for the parses assigned by
a high-precision broad-coverage grammar, and
from those creates SQL queries. It does not include
a step where one or more “best” parses are selected
for further processing. Queries are built for all
parses for which it is possible to do so. For a stan-
dard corpus of NLIDB training sentences, it is able
to generate the correct query whenever a suitable
analysis is given by the parser. In the rare case
where it generates two queries, both queries are
equally correct.
</bodyText>
<sectionHeader confidence="0.949897" genericHeader="method">
2 Parse Selection
</sectionHeader>
<bodyText confidence="0.999889615384615">
Parse selection for probabilistic grammars involves
simply finding the most probable parse, or top-N
most probable parses, and can be done using effi-
cient algorithms, (e.g. Klein and Manning, 2003).
Things are different for high-precision, hand-
coded grammars, such as the LinGO English Re-
source Grammar, ERG (Flickinger, 2000), a Head-
Driven Phrase Structure Grammar implementation
of English; and Xerox’s English grammar (Butt, et
al., 2002), a Lexical Functional Grammar
implementation. These grammars do not define a
probability distribution over parses. Rather, they
assign to each string all of its grammatically valid
</bodyText>
<subsectionHeader confidence="0.4977605">
Proceedings of the NAACL HLT 2010 Student Research Workshop, pages 19–22,
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</subsectionHeader>
<bodyText confidence="0.999902129032258">
parses. Techniques for deciding between parses
produced by these kinds of grammars include us-
ing sortal constraints on arguments of semantic
relations (Müller and Kasper, 2000); and
annotating individual grammatical rules with
weights (Kiefer, et al., 1999). More recently, the
development of rich treebanks such as the LinGO
Redwoods (Oepen, et al., 2004) which stores all
analyses of a sentence, along with an indication of
which is the preferred one, makes it possible to
train maximum entropy models for parse selection,
(e.g. Toutanova, et al., 2002).
For at least the NLIDB task, however, selection
of the best parse is not an end in itself. Rather,
what is necessary is to generate the intended data-
base query. Indeed, two or more distinct syntactic
parses may all lead to the same (intended) query. If
the NLIDB identifies this query correctly, it has
achieved its goal without, strictly speaking, having
selected the best parse.
Furthermore, eliminating any grammatically va-
lid parse without subjecting it to further processing
risks missing the intended query. For these rea-
sons, Locutus does no intrinsic parse selection.
Rather, it tries to build a query for all valid parses.
The semantic constraints of the database domain
limit well-formed semantic representations to those
that make sense in that domain, so that a grammat-
ically valid parse may not receive a legitimate se-
mantic representation, and thus not receive a
database query.
</bodyText>
<sectionHeader confidence="0.996472" genericHeader="method">
3 Locutus
</sectionHeader>
<bodyText confidence="0.99645225">
Locutus is an NLIDB which is designed to be port-
able with respect to source language and grammat-
ical formalism. It can take as input the syntactic
analyses produced by any sufficiently sophisticated
grammar/parser. The implementation reported on
in this paper consumes the f-structures produced
by the Xerox English grammar.
Locutus is also portable with respect to database
domain. The projection of semantic structures from
the syntactic analyses provided by the parser is
guided by a semantic description of the database
domain together with a set of constraints called
sign templates linking syntactic patterns with se-
mantic patterns.
High precision (building only correct queries) is
maintained in a number of ways:
</bodyText>
<listItem confidence="0.994293285714286">
• High-precision syntactic grammars are used.
• The projection of semantic structures from
syntactic structures is resource-sensitive. Every
element of the syntactic structure must be refe-
renced just once by the sign template that li-
censes the corresponding semantic structure.
• The semantic description of the database do-
</listItem>
<bodyText confidence="0.960462333333333">
main defines a network of semantic relation-
ships and their arguments, along with
constraints regarding which arguments are
compatible with one another. In this way, se-
mantic structures which would otherwise be
generated can be ruled out.
</bodyText>
<subsectionHeader confidence="0.999898">
3.1 Processing Pipeline
</subsectionHeader>
<bodyText confidence="0.9997366">
The processing of a sentence by Locutus proceeds
in the following way. The string of words is passed
to the XLE parser, which returns a contextualized
feature structure from which individual parses are
extracted. An example parse appears in Figure 1.
</bodyText>
<figure confidence="0.9794403">
[ PRED border
SUBJ [ PRED state
NTYPE [ NSYN common ]
SPEC [ DET [ PRED which
NTYPE [ NSYN ... ]
PRON-TYPE int ] ]
CASE nom
NUM pl
PERS 3 ]
OBJ [ PRED delaware
NTYPE [ NSYN proper ]
CASE obl
NUM sg
PERS 3 ]
PRON-INT [...]
FOCUS-INT [...]
TNS-ASP [...]
CLAUSE-TYPE int
PASSIVE -
VTYPE main ]
</figure>
<figureCaption confidence="0.998328">
Figure 1: parse for “Which states border delaware?”
</figureCaption>
<bodyText confidence="0.925544">
Locutus interprets this syntactic analysis into a set
of semantic representations called Semantic Mo-
bile Structures, an example of which appears in an
abbreviated form in Figure 2.
</bodyText>
<equation confidence="0.595895666666667">
x0 DefQuant: [ &gt; [1]]
r0 Border:STATE1
STATE2: x1 DefQuant: [1]
</equation>
<footnote confidence="0.453463666666667">
r1 StateName:STATE
NAME: [delaware]
r2 State:STATE
</footnote>
<figureCaption confidence="0.909321">
Figure 2: SMS for &amp;quot;Which states border delaware?&amp;quot;
</figureCaption>
<page confidence="0.961651">
20
</page>
<bodyText confidence="0.999714666666667">
Finally, this representation is translated into an
SQL query, as shown in Figure 3, which is sent to
the database, and the answer is shown.
</bodyText>
<figure confidence="0.599092">
select t1.Name
from border, state t1, state t2
where border.State1 = t1.Name and
border.State2 = t2.Name and
t2.Name = &apos;delaware&apos;
</figure>
<figureCaption confidence="0.994292">
Figure 3: query for “Which states border Delaware?”
</figureCaption>
<subsectionHeader confidence="0.994051">
3.2 Efficiency
</subsectionHeader>
<bodyText confidence="0.999203642857143">
There is a bit of time savings in not having an
intrinsic parse-selection step. These savings are
counterbalanced by the extra time it takes to interp-
ret parses that would have otherwise been excluded
by such a step. However, a certain amount of syn-
tactic structure is shared among the various parses
of a syntactically ambiguous sentence. Locutus
recognizes when a piece of syntactic structure has
already been interpreted, and reuses that interpreta-
tion in every parse in which it appears. In this way
Locutus minimizes the extra time taken to process
multiple parses. At any rate, processing speed does
not appear to be a problem at this point in the de-
velopment of Locutus.
</bodyText>
<subsectionHeader confidence="0.940368">
3.3 Further Work
</subsectionHeader>
<bodyText confidence="0.999991">
Although Locutus has a wide range of functionali-
ty, it is still a work in progress. The format for au-
thoring sign templates is rather complex, and
customizing Locutus for a given database can be
time-consuming. I anticipate an authoring tool
which makes much of the customization process
automatic, and hides much of the complexity of the
rest of the process from the author, but such a tool
has yet to be implemented.
</bodyText>
<sectionHeader confidence="0.998976" genericHeader="method">
4 Experiment
</sectionHeader>
<bodyText confidence="0.987300846153846">
To test the coverage and precision of Locutus, I
have customized it to answer questions from the
GEOQUERY 250 corpus (Mooney, 1996), which
consists of a database of geographical information
paired with 250 English sentences requesting in-
formation from that database. 25 of these sentences
are held out for the purposes of another study, and
I have not examined the behavior of Locutus with
respect to these sentences. I ran the other 225 sen-
tences through Locutus, keeping track of which
sentences Locutus built at least one query for. For
each of those sentences, I also tracked the follow-
ing:
</bodyText>
<listItem confidence="0.9998555">
• How many syntactic parses were generated by
the grammar
• How many queries were produced
• How many of those queries were correct
</listItem>
<bodyText confidence="0.99985825">
The XLE Engine includes a facility to do stochas-
tic disambiguation (Kaplan, et al. 2004), and the
English grammar I used comes with a property
weights file of the kind required by the disambigu-
ation process. I ran the sentences through Locutus
using just the single best parse returned by that
process, keeping track of how many queries were
produced.
</bodyText>
<sectionHeader confidence="0.999888" genericHeader="evaluation">
5 Results
</sectionHeader>
<bodyText confidence="0.999873058823529">
223 of the 225 sentences (99.1%) are assigned at
least one query. For the other two sentences, no
analysis returned by the parser reflect the intended
meaning of the sentence. The average number of
parses for these sentences is 3.01, with 158 sen-
tences given at least two parses, and 84 sentences
given at least three. Some sentences were given as
many as 20 parses.
Figure 4 contains the graph of the number of
parses by the average number of queries assigned
to sentences with that many parses. Note that the
number of queries per sentence is not correlated
with the number of parses assigned by the gram-
mar. The sentences that were assigned more than
one query were each assigned either one or two
parses. All the sentences with more syntactic
parses were assigned a single query each.
</bodyText>
<figureCaption confidence="0.994695">
Figure 4: Average queries by ambiguity level
</figureCaption>
<bodyText confidence="0.994331666666667">
Of the 223 sentences that were assigned a query,
219 of them were assigned exactly one query.
Every query was correct in the sense that it accu-
</bodyText>
<figure confidence="0.9659829">
1.04
1.03
1.02
1.01
1
0.99
0.98
Avg Queries
1 3 5 7 9 11 13 15 17 19
# of Parses
</figure>
<page confidence="0.998631">
21
</page>
<bodyText confidence="0.998466333333333">
rately reflected a reasonable interpretation of the
sentence. Four sentences were each assigned two
queries. They are given in (1)-(4).
</bodyText>
<listItem confidence="0.99966025">
(1) How many people live in Washington?
(2) How many people live in New York?
(3) What is the length of the Colorado river?
(4) What is the length of the Mississippi river?
</listItem>
<bodyText confidence="0.9999135">
It is appropriate that each of these sentences gets
two queries. For (1)-(2), the GEOQUERY 250 data-
base contains cities, their populations, states and
their populations; “Washington” and “New York”
are both names of cities and states that appear in
the database. For (3)-(4), one interpretation is to
return the length of the river mentioned in the sen-
tence. The other possibility is to return all the riv-
ers that are the same lengths as the ones
mentioned. For instance, in the GEOQUERY data-
base, the Colorado and Arkansas rivers are both
2333 km long. One valid answer to (3) is the num-
ber “2333”. The other valid answer is the list of
rivers “Arkansas” and “Colorado”. To give any of
these sentences only a single query would be to
miss a reasonable interpretation.
Table 1 summarizes the results when only a sin-
gle parse for each sentence, chosen stochastically
using the property weights file provided with the
XLE English grammar, is sent to Locutus. The
parse is considered correct if it leads to a correct
query.
</bodyText>
<table confidence="0.642421">
# of sents avg. parses % correct
&gt; 1 parse 223 3.01 54%
&gt; 2 parses 158 3.84 35%
</table>
<tableCaption confidence="0.92743">
Table 1
</tableCaption>
<bodyText confidence="0.99892425">
Although performance is better than chance, it is
clearly less successful than when Locutus is al-
lowed to use every parse, in which case a correct
query is always constructed.
</bodyText>
<sectionHeader confidence="0.999485" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999969461538462">
For natural language processing applications that
take the results of a high-precision syntactic parser
and pass them along to further processing, select-
ing the correct parse is not an end in itself. It is
only useful insofar as it improves the final result.
For applications such as NLIDBs, which are
provided with a precise semantic framework within
which sentences may be interpreted, it is better to
pass along the full set of grammatically valid
parses than to select beforehand a limited subset of
those parses. Using this technique, Locutus
achieves 100% correctness on the sentences for
which it builds a query.
</bodyText>
<sectionHeader confidence="0.998512" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999595795454546">
Butt, Miriam, Helge Dyvik, Tracy Holloway King,
Hiroshi Masuichi, and Christian Rohrer. &amp;quot;The
Parallel Grammar Project.&amp;quot; Proceedings of
COLING2002 Workshop on Grammar Engineering
and Evaluation. 2002.
Flickinger, Dan. &amp;quot;On building a more efficient
grammar by exploiting types.&amp;quot; Natural Language
Engineering 6, no. 1 (2000): 15-28.
Goss-Grubbs, David. &amp;quot;Deep Processing for a Portable
Natural Language Interface to Databases.&amp;quot;
dissertation, University of Washington. to appear.
Kaplan, Ron, Stefan Riezler, Trace King, John
Maxwell, Alexander Vasserman, and Richard
Crouch. &amp;quot;Speed and Accuracy in Shallow and Deep
Stochastic Parsing.&amp;quot; Proceedings of the Human
Language Technology Conference and the 4th
Annual Meeting of the North American Chapter of
the Association for Computational Linguistics
(HLT-NAACL&apos;04). Boston, MA, 2004.
Kiefer, Bernd, Hans-Ulrich Krieger, John Carroll, and
Rob Malouf. &amp;quot;A Bag of Useful Techniques for
Efficient and Robust Parsing.&amp;quot; Proceedings of the
37th Meeting of the Association for Computational
Linguistics. College Park, MD, 1999. 473-480.
Klein, Dan, and Christopher D. Manning. &amp;quot;A*
Parsing: Fast Exact Viterbi Parse Selection.&amp;quot;
Proceedings of HLT-NAACL 2003. 2003. 40-47.
Mooney, Raymond. Geoquery Data. 1996.
http://www.cs.utexas.edu/users/ml/nldata/geoquery.
html (accessed February 13, 2010).
Müller, Stefan, and Walter Kasper. &amp;quot;HPSG Analysis
of German.&amp;quot; In Verbmobil. Foundations of Speech-
to-Speech Translation, edited by Wolfgang
Wahlster, 238-253. Berlin: Springer, 2000.
Oepen, Stephan, Dan Flickinger, Kristina Toutanova,
and Christopher D. Manning. &amp;quot;LinGO Redwoods:
A Rich and Dynamic Treebank for HPSG.&amp;quot;
Research on Language and Computation (Springer)
2 (2004): 575-596.
Toutanova, Kristina, Christopher D. Manning, Stuart
Shieber, Dan Flickinger, and Stephan Oepen.
&amp;quot;Parse disambiguation for a rich HPSG grammar.&amp;quot;
Proceedings of the First Workshop on Treebanks
and Linguistic Theories. 2002. 253-263.
</reference>
<page confidence="0.999027">
22
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.795863">
<title confidence="0.999916">Extrinsic Parse Selection</title>
<author confidence="0.986613">David</author>
<affiliation confidence="0.99875">University of Department of</affiliation>
<address confidence="0.934129">Box Seattle, WA 98195-4340,</address>
<email confidence="0.999908">davidgg@u.washington.edu</email>
<abstract confidence="0.995618235294118">This paper reports on one aspect of Locutus, a natural language interface to databases (NLIDB) which uses the output of a highprecision broad-coverage grammar to build semantic representations and ultimately SQL queries. Rather than selecting just a subset of the parses provided by the grammar to use in further processing, Locutus uses all of them. If the meaning of a parse does not conform to the semantic domain of the database, no query is built for it. Thus, intended parses are chosen extrinsically. The parser gives an average of 3.01 parses to the sentences in the corpus. Locutus generates an average of 1.02 queries per sentence for this corpus, all of them correct.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Miriam Butt</author>
<author>Helge Dyvik</author>
<author>Tracy Holloway King</author>
<author>Hiroshi Masuichi</author>
<author>Christian Rohrer</author>
</authors>
<title>The Parallel Grammar Project.&amp;quot;</title>
<date>2002</date>
<booktitle>Proceedings of COLING2002 Workshop on Grammar Engineering and Evaluation.</booktitle>
<contexts>
<context position="2806" citStr="Butt, et al., 2002" startWordPosition="438" endWordPosition="441">erate the correct query whenever a suitable analysis is given by the parser. In the rare case where it generates two queries, both queries are equally correct. 2 Parse Selection Parse selection for probabilistic grammars involves simply finding the most probable parse, or top-N most probable parses, and can be done using efficient algorithms, (e.g. Klein and Manning, 2003). Things are different for high-precision, handcoded grammars, such as the LinGO English Resource Grammar, ERG (Flickinger, 2000), a HeadDriven Phrase Structure Grammar implementation of English; and Xerox’s English grammar (Butt, et al., 2002), a Lexical Functional Grammar implementation. These grammars do not define a probability distribution over parses. Rather, they assign to each string all of its grammatically valid Proceedings of the NAACL HLT 2010 Student Research Workshop, pages 19–22, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics parses. Techniques for deciding between parses produced by these kinds of grammars include using sortal constraints on arguments of semantic relations (Müller and Kasper, 2000); and annotating individual grammatical rules with weights (Kiefer, et al., 1999). </context>
</contexts>
<marker>Butt, Dyvik, King, Masuichi, Rohrer, 2002</marker>
<rawString>Butt, Miriam, Helge Dyvik, Tracy Holloway King, Hiroshi Masuichi, and Christian Rohrer. &amp;quot;The Parallel Grammar Project.&amp;quot; Proceedings of COLING2002 Workshop on Grammar Engineering and Evaluation. 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Flickinger</author>
</authors>
<title>On building a more efficient grammar by exploiting types.&amp;quot;</title>
<date>2000</date>
<journal>Natural Language Engineering</journal>
<volume>6</volume>
<pages>15--28</pages>
<contexts>
<context position="2691" citStr="Flickinger, 2000" startWordPosition="423" endWordPosition="424">ll parses for which it is possible to do so. For a standard corpus of NLIDB training sentences, it is able to generate the correct query whenever a suitable analysis is given by the parser. In the rare case where it generates two queries, both queries are equally correct. 2 Parse Selection Parse selection for probabilistic grammars involves simply finding the most probable parse, or top-N most probable parses, and can be done using efficient algorithms, (e.g. Klein and Manning, 2003). Things are different for high-precision, handcoded grammars, such as the LinGO English Resource Grammar, ERG (Flickinger, 2000), a HeadDriven Phrase Structure Grammar implementation of English; and Xerox’s English grammar (Butt, et al., 2002), a Lexical Functional Grammar implementation. These grammars do not define a probability distribution over parses. Rather, they assign to each string all of its grammatically valid Proceedings of the NAACL HLT 2010 Student Research Workshop, pages 19–22, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics parses. Techniques for deciding between parses produced by these kinds of grammars include using sortal constraints on arguments of semantic rel</context>
</contexts>
<marker>Flickinger, 2000</marker>
<rawString>Flickinger, Dan. &amp;quot;On building a more efficient grammar by exploiting types.&amp;quot; Natural Language Engineering 6, no. 1 (2000): 15-28.</rawString>
</citation>
<citation valid="false">
<authors>
<author>David Goss-Grubbs</author>
</authors>
<title>Deep Processing for a Portable Natural Language Interface to Databases.&amp;quot; dissertation,</title>
<institution>University of Washington.</institution>
<note>to appear.</note>
<marker>Goss-Grubbs, </marker>
<rawString>Goss-Grubbs, David. &amp;quot;Deep Processing for a Portable Natural Language Interface to Databases.&amp;quot; dissertation, University of Washington. to appear.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Ron Kaplan</author>
<author>Stefan Riezler</author>
<author>Trace King</author>
<author>John Maxwell</author>
</authors>
<title>Alexander Vasserman,</title>
<location>and Richard</location>
<marker>Kaplan, Riezler, King, Maxwell, </marker>
<rawString>Kaplan, Ron, Stefan Riezler, Trace King, John Maxwell, Alexander Vasserman, and Richard</rawString>
</citation>
<citation valid="true">
<authors>
<author>Crouch</author>
</authors>
<title>Speed and Accuracy in Shallow and Deep Stochastic Parsing.&amp;quot;</title>
<date>2004</date>
<booktitle>Proceedings of the Human Language Technology Conference and the 4th Annual Meeting of the North American Chapter of the Association for Computational Linguistics (HLT-NAACL&apos;04).</booktitle>
<location>Boston, MA,</location>
<marker>Crouch, 2004</marker>
<rawString>Crouch. &amp;quot;Speed and Accuracy in Shallow and Deep Stochastic Parsing.&amp;quot; Proceedings of the Human Language Technology Conference and the 4th Annual Meeting of the North American Chapter of the Association for Computational Linguistics (HLT-NAACL&apos;04). Boston, MA, 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernd Kiefer</author>
<author>Hans-Ulrich Krieger</author>
<author>John Carroll</author>
<author>Rob Malouf</author>
</authors>
<title>A Bag of Useful Techniques for Efficient and Robust Parsing.&amp;quot;</title>
<date>1999</date>
<booktitle>Proceedings of the 37th Meeting of the Association for Computational Linguistics.</booktitle>
<pages>473--480</pages>
<location>College Park, MD,</location>
<contexts>
<context position="3404" citStr="Kiefer, et al., 1999" startWordPosition="522" endWordPosition="525">ar (Butt, et al., 2002), a Lexical Functional Grammar implementation. These grammars do not define a probability distribution over parses. Rather, they assign to each string all of its grammatically valid Proceedings of the NAACL HLT 2010 Student Research Workshop, pages 19–22, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics parses. Techniques for deciding between parses produced by these kinds of grammars include using sortal constraints on arguments of semantic relations (Müller and Kasper, 2000); and annotating individual grammatical rules with weights (Kiefer, et al., 1999). More recently, the development of rich treebanks such as the LinGO Redwoods (Oepen, et al., 2004) which stores all analyses of a sentence, along with an indication of which is the preferred one, makes it possible to train maximum entropy models for parse selection, (e.g. Toutanova, et al., 2002). For at least the NLIDB task, however, selection of the best parse is not an end in itself. Rather, what is necessary is to generate the intended database query. Indeed, two or more distinct syntactic parses may all lead to the same (intended) query. If the NLIDB identifies this query correctly, it h</context>
</contexts>
<marker>Kiefer, Krieger, Carroll, Malouf, 1999</marker>
<rawString>Kiefer, Bernd, Hans-Ulrich Krieger, John Carroll, and Rob Malouf. &amp;quot;A Bag of Useful Techniques for Efficient and Robust Parsing.&amp;quot; Proceedings of the 37th Meeting of the Association for Computational Linguistics. College Park, MD, 1999. 473-480.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>A* Parsing: Fast Exact Viterbi Parse Selection.&amp;quot;</title>
<date>2003</date>
<booktitle>Proceedings of HLT-NAACL</booktitle>
<pages>40--47</pages>
<contexts>
<context position="2562" citStr="Klein and Manning, 2003" startWordPosition="402" endWordPosition="405">tes SQL queries. It does not include a step where one or more “best” parses are selected for further processing. Queries are built for all parses for which it is possible to do so. For a standard corpus of NLIDB training sentences, it is able to generate the correct query whenever a suitable analysis is given by the parser. In the rare case where it generates two queries, both queries are equally correct. 2 Parse Selection Parse selection for probabilistic grammars involves simply finding the most probable parse, or top-N most probable parses, and can be done using efficient algorithms, (e.g. Klein and Manning, 2003). Things are different for high-precision, handcoded grammars, such as the LinGO English Resource Grammar, ERG (Flickinger, 2000), a HeadDriven Phrase Structure Grammar implementation of English; and Xerox’s English grammar (Butt, et al., 2002), a Lexical Functional Grammar implementation. These grammars do not define a probability distribution over parses. Rather, they assign to each string all of its grammatically valid Proceedings of the NAACL HLT 2010 Student Research Workshop, pages 19–22, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics parses. Techniq</context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Klein, Dan, and Christopher D. Manning. &amp;quot;A* Parsing: Fast Exact Viterbi Parse Selection.&amp;quot; Proceedings of HLT-NAACL 2003. 2003. 40-47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Raymond Mooney</author>
</authors>
<title>Geoquery Data.</title>
<date>1996</date>
<note>http://www.cs.utexas.edu/users/ml/nldata/geoquery. html (accessed</note>
<contexts>
<context position="8451" citStr="Mooney, 1996" startWordPosition="1355" endWordPosition="1356">t in the development of Locutus. 3.3 Further Work Although Locutus has a wide range of functionality, it is still a work in progress. The format for authoring sign templates is rather complex, and customizing Locutus for a given database can be time-consuming. I anticipate an authoring tool which makes much of the customization process automatic, and hides much of the complexity of the rest of the process from the author, but such a tool has yet to be implemented. 4 Experiment To test the coverage and precision of Locutus, I have customized it to answer questions from the GEOQUERY 250 corpus (Mooney, 1996), which consists of a database of geographical information paired with 250 English sentences requesting information from that database. 25 of these sentences are held out for the purposes of another study, and I have not examined the behavior of Locutus with respect to these sentences. I ran the other 225 sentences through Locutus, keeping track of which sentences Locutus built at least one query for. For each of those sentences, I also tracked the following: • How many syntactic parses were generated by the grammar • How many queries were produced • How many of those queries were correct The </context>
</contexts>
<marker>Mooney, 1996</marker>
<rawString>Mooney, Raymond. Geoquery Data. 1996. http://www.cs.utexas.edu/users/ml/nldata/geoquery. html (accessed February 13, 2010).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Müller</author>
<author>Walter Kasper</author>
</authors>
<title>HPSG Analysis of German.&amp;quot; In Verbmobil. Foundations of Speechto-Speech Translation, edited by Wolfgang Wahlster,</title>
<date>2000</date>
<pages>238--253</pages>
<publisher>Springer,</publisher>
<location>Berlin:</location>
<contexts>
<context position="3323" citStr="Müller and Kasper, 2000" startWordPosition="511" endWordPosition="514">Driven Phrase Structure Grammar implementation of English; and Xerox’s English grammar (Butt, et al., 2002), a Lexical Functional Grammar implementation. These grammars do not define a probability distribution over parses. Rather, they assign to each string all of its grammatically valid Proceedings of the NAACL HLT 2010 Student Research Workshop, pages 19–22, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics parses. Techniques for deciding between parses produced by these kinds of grammars include using sortal constraints on arguments of semantic relations (Müller and Kasper, 2000); and annotating individual grammatical rules with weights (Kiefer, et al., 1999). More recently, the development of rich treebanks such as the LinGO Redwoods (Oepen, et al., 2004) which stores all analyses of a sentence, along with an indication of which is the preferred one, makes it possible to train maximum entropy models for parse selection, (e.g. Toutanova, et al., 2002). For at least the NLIDB task, however, selection of the best parse is not an end in itself. Rather, what is necessary is to generate the intended database query. Indeed, two or more distinct syntactic parses may all lead</context>
</contexts>
<marker>Müller, Kasper, 2000</marker>
<rawString>Müller, Stefan, and Walter Kasper. &amp;quot;HPSG Analysis of German.&amp;quot; In Verbmobil. Foundations of Speechto-Speech Translation, edited by Wolfgang Wahlster, 238-253. Berlin: Springer, 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Oepen</author>
<author>Dan Flickinger</author>
<author>Kristina Toutanova</author>
<author>Christopher D Manning</author>
</authors>
<title>LinGO Redwoods: A Rich and Dynamic Treebank for HPSG.&amp;quot;</title>
<date>2004</date>
<journal>Research on Language and Computation (Springer)</journal>
<volume>2</volume>
<pages>575--596</pages>
<contexts>
<context position="3503" citStr="Oepen, et al., 2004" startWordPosition="538" endWordPosition="541"> probability distribution over parses. Rather, they assign to each string all of its grammatically valid Proceedings of the NAACL HLT 2010 Student Research Workshop, pages 19–22, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics parses. Techniques for deciding between parses produced by these kinds of grammars include using sortal constraints on arguments of semantic relations (Müller and Kasper, 2000); and annotating individual grammatical rules with weights (Kiefer, et al., 1999). More recently, the development of rich treebanks such as the LinGO Redwoods (Oepen, et al., 2004) which stores all analyses of a sentence, along with an indication of which is the preferred one, makes it possible to train maximum entropy models for parse selection, (e.g. Toutanova, et al., 2002). For at least the NLIDB task, however, selection of the best parse is not an end in itself. Rather, what is necessary is to generate the intended database query. Indeed, two or more distinct syntactic parses may all lead to the same (intended) query. If the NLIDB identifies this query correctly, it has achieved its goal without, strictly speaking, having selected the best parse. Furthermore, elimi</context>
</contexts>
<marker>Oepen, Flickinger, Toutanova, Manning, 2004</marker>
<rawString>Oepen, Stephan, Dan Flickinger, Kristina Toutanova, and Christopher D. Manning. &amp;quot;LinGO Redwoods: A Rich and Dynamic Treebank for HPSG.&amp;quot; Research on Language and Computation (Springer) 2 (2004): 575-596.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Christopher D Manning</author>
<author>Stuart Shieber</author>
<author>Dan Flickinger</author>
<author>Stephan Oepen</author>
</authors>
<title>Parse disambiguation for a rich HPSG grammar.&amp;quot;</title>
<date>2002</date>
<booktitle>Proceedings of the First Workshop on Treebanks and Linguistic Theories.</booktitle>
<pages>253--263</pages>
<contexts>
<context position="3702" citStr="Toutanova, et al., 2002" startWordPosition="571" endWordPosition="574">ifornia, June 2010. c�2010 Association for Computational Linguistics parses. Techniques for deciding between parses produced by these kinds of grammars include using sortal constraints on arguments of semantic relations (Müller and Kasper, 2000); and annotating individual grammatical rules with weights (Kiefer, et al., 1999). More recently, the development of rich treebanks such as the LinGO Redwoods (Oepen, et al., 2004) which stores all analyses of a sentence, along with an indication of which is the preferred one, makes it possible to train maximum entropy models for parse selection, (e.g. Toutanova, et al., 2002). For at least the NLIDB task, however, selection of the best parse is not an end in itself. Rather, what is necessary is to generate the intended database query. Indeed, two or more distinct syntactic parses may all lead to the same (intended) query. If the NLIDB identifies this query correctly, it has achieved its goal without, strictly speaking, having selected the best parse. Furthermore, eliminating any grammatically valid parse without subjecting it to further processing risks missing the intended query. For these reasons, Locutus does no intrinsic parse selection. Rather, it tries to bu</context>
</contexts>
<marker>Toutanova, Manning, Shieber, Flickinger, Oepen, 2002</marker>
<rawString>Toutanova, Kristina, Christopher D. Manning, Stuart Shieber, Dan Flickinger, and Stephan Oepen. &amp;quot;Parse disambiguation for a rich HPSG grammar.&amp;quot; Proceedings of the First Workshop on Treebanks and Linguistic Theories. 2002. 253-263.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>