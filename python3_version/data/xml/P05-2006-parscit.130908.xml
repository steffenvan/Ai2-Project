<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000081">
<title confidence="0.9821455">
Automatic Discovery of Intentions in Text and its Application to Question
Answering
</title>
<author confidence="0.992936">
Marta Tatu
</author>
<affiliation confidence="0.995573">
Human Language Technology Research Institute
Department of Computer Science
University of Texas at Dallas
</affiliation>
<address confidence="0.589438">
Richardson, TX 75080, USA
</address>
<email confidence="0.999241">
marta@hlt.utdallas.edu
</email>
<sectionHeader confidence="0.995649" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999882">
Semantic relations between text concepts
denote the core elements of lexical se-
mantics. This paper presents a model for
the automatic detection of INTENTION se-
mantic relation. Our approach first identi-
fies the syntactic patterns that encode in-
tentions, then we select syntactic and se-
mantic features for a SVM learning classi-
fier. In conclusion, we discuss the appli-
cation of INTENTION relations to Q&amp;A.
</bodyText>
<sectionHeader confidence="0.99964" genericHeader="keywords">
1 Introduction
</sectionHeader>
<subsectionHeader confidence="0.998061">
1.1 Problem description
</subsectionHeader>
<bodyText confidence="0.99962">
Intentions comprise of semantic relationships that
express a human’s goal-oriented private states of
mind, including intents, objectives, aims, and pur-
poses. As a relation, it encodes information that
might not be explicitly stated in text and its detec-
tion might require inferences and human judgment.
The answer to the question What was Putin trying
to achieve by increasing military cooperation with
North Korea? is found in the sentence Putin is at-
tempting to restore Russia’s influence in the East
Asian region. Extracting the exact answer to restore
Russia’s influence in the East Asian region becomes
easier if this is recognized as Putin’s intention which
matches the question’s expected answer.
In this paper, we describe a method that identi-
fies intentions in domain independent texts. We em-
ployed two machine learning algorithms to create
models that locate intentions in a given paragraph
using a set of six syntactic and semantic features.
</bodyText>
<page confidence="0.997673">
31
</page>
<subsectionHeader confidence="0.671971">
1.2 Motivation
</subsectionHeader>
<bodyText confidence="0.991647727272727">
The current state-of-the-art NLP systems cannot ex-
tract intentions from open text and, as we saw in the
example, their detection benefits Question Answer-
ing. An intention is the answer to general questions
like What is the goal ofX?, What does Xplan to do?,
or What does X aim for? The INTENTION seman-
tic relation is one of the most challenging relations
because text fragments may convey unstated inten-
tions. These are most pervasive in dialogues, com-
munication specific to humans. For example, in the
following conversation, the vendor infers the client’s
unstated intention of buying the cups.
Customer: Where do you have the $1 cups?
Salesman: How many do you want?
Intentions are closely related to other semantic re-
lations such as beliefs, motives, desires, or plans.
In the above example, the context tells us that this
takes place in a superstore, well-known as a place
where people buy things from. The clerk’s an-
swer emerges from our common beliefs and back-
ground knowledge as well as from his desire to
help a customer. Intentions are the framework for
plans. Many philosophers and artificial intelligence
researchers studied the intentions as parts of coor-
dinating plans (Bratman, 1987; Pollack, 1990) be-
cause people establish plans for future times.
In this paper, we regard intentions as expres-
sions of a particular action that shall take place in
the future, in which the speaker is some sort of
agent (Anscombe, 1957). For example, the sentence
Mary is going to buy a TV set shows Mary’s in-
tention. Anscombe (1957) considers intentions as
a subclass of predictions, besides commands and
</bodyText>
<note confidence="0.387987">
Proceedings of the ACL Student Research Workshop, pages 31–36,
</note>
<page confidence="0.394249">
Ann Arbor, Michigan, June 2005. c�2005 Association for Computational Linguistics
</page>
<bodyText confidence="0.998007">
prophecies. John is going to be sick is usually a
prophecy, John, go for a walk! is an order, and John
plans to take a walk expresses an intention.
</bodyText>
<subsectionHeader confidence="0.905261">
1.3 Previous work
</subsectionHeader>
<bodyText confidence="0.999979545454545">
Various methodologies have been proposed and used
over the years for the task of extracting semantic
relations from text. Purely probabilistic models,
empirical methods, or hand-coded constraints were
some of the approaches that do not use machine
learning algorithms. Later on, methods that use de-
cision tree, neural networks, memory-based learn-
ing, or support vector machines were introduced.
Currently, there is also a increased interest in shal-
low semantic parsing of open texts and automatic la-
beling of semantic roles. Wiebe et al. (2004) focused
on the detection of subjective language such as opin-
ions, evaluations, or emotions in text. Using clues
of subjectivity (low-frequency words, collocations),
they identify opinion piece texts such as editorials,
letters to the editor, or arts and leisure reviews.
There exists an immense literature in philoso-
phy about the different types of intentions and their
characteristics. Bratman (1987) tries to find the re-
lationship between the two distinct phenomena of
doing something intentionally and intending to do
something. Numerous philosophical studies dis-
cuss how intentions relate to other psychological
concepts, such as, beliefs, desires, hopes, or ex-
pectations (Audi, 1973; Bratman, 1981; Bratman,
1987). Intentions are consistent with the person’s
beliefs, and, unlike ordinary desires, require con-
sistency (Bratman, 1987). They can generate rea-
sons for or against future intentions (Bratman, 1981;
Bratman, 1987). As plan elements, intentions re-
quire a certain stability. Their side effects need not
be intended, even if they were taken into considera-
tion in the first place1 (Bratman, 1990).
</bodyText>
<sectionHeader confidence="0.838555" genericHeader="introduction">
2 Syntax and Semantics of Intention
</sectionHeader>
<subsectionHeader confidence="0.991564">
2.1 Syntactic patterns
</subsectionHeader>
<bodyText confidence="0.9998185">
Because, in all the cases that we encountered, inten-
tions were conveyed by phrases, we took a closer
look at how intentions can be expressed in the writ-
ten text. For our investigations, we chose the Sem-
</bodyText>
<footnote confidence="0.9728265">
1Due to space limitations, we couldn’t include detailed ex-
amples. Please see the cited articles for examples.
</footnote>
<bodyText confidence="0.962659714285714">
Cor text collection (Miller et al., 1993), a subset of
the Brown corpus manually tagged with WordNet
senses (37,176 sentences in 352 newspaper articles).
After manually classifying the first 2,700 sentences
from SemCor into sentences that contain or not in-
tentions, only 46 examples were identified. The
syntactic patterns listed in Table 1 cover 95.65% of
them. Because the first pattern comprises more than
half of the studied examples, our algorithm focuses
on detecting intentions encoded by to .
We note that this pattern is ambiguous and may con-
vey other semantics. For instance, Mary began to
play with the dog, He told her to meet you are en-
coded by our pattern, but do not express intentions.
Pattern Example Frequency
to plan to go for a walk 27 (58.69)
NN to VB strivings to give up drink 6 (13.04)
VB PP VP He resigned so that he can work 5 (10.87)
for the school campaign
goal/purpose is to VB his goal is to leave the country 4 (8.69)
ADJ to VB eager to end a pitching slump 2 (4.34)
</bodyText>
<tableCaption confidence="0.991761">
Table 1: INTENTION syntactic patterns
</tableCaption>
<subsectionHeader confidence="0.99862">
2.2 Semantics of intentions
</subsectionHeader>
<bodyText confidence="0.9955034">
From the semantic point of view, an intention may
be very specific, it may contain a future time or a
location (John intends to meet Mary today), but ev-
ery intention must specify a future action. Hence,
we propose the following representation for the IN-
TENTION semantic relation: INT( ) where
is the event denoting the intention, denotes the
person that has the intention and is the intended
action or event. If the intention is more specific
then we will identify instances of other semantic re-
</bodyText>
<equation confidence="0.6677045">
lations2. INT
THEME
</equation>
<bodyText confidence="0.9937305">
TIME represents a more specific intention.
The semantics of the INTENTION relation allows
the derivation of inference rules which show that IN-
TENTION dominates other semantic relations such as
PURPOSE, ENTAIL, or ISA. For example, if a person
intends to perform action and this action has
a purpose , then we can say that intends to do
3. Formally, we can express the above relations
</bodyText>
<footnote confidence="0.9995168">
2The list of semantic relations that can specialize an INT
includes THEME, LOCATION, TEMPORAL, MANNER, INSTRU-
MENT, SOURCE, MEANS, and FREQUENCY. Their arguments
are , the intention verb, and a corresponding .
3Similar statements can be made for the ENTAIL and ISA
</footnote>
<page confidence="0.997954">
32
</page>
<figure confidence="0.611219833333333">
with the following set of implications4:
INT PURPOSE INT
INT ENTAIL INT
INT IS-A INT
INT PURPOSE INT
INT CAUSE INT
</figure>
<bodyText confidence="0.999754736842105">
The first three implications formalize the above
inference rules. If John intends to start his car to
go to the park, then John intends to go to the park.
Similarly, if John intends to buy a car, then we can
say that he intends to pay for it. The sentences John
intends to go to the park. He’s starting his car right
now express John’s intention to go to the park ( ).
The purpose of starting the car ( ) is to go to the
park. We cannot say that John intends to start his
car. This is just an intentional action done to achieve
his objective. The fifth rule tries to eliminate the ef-
fects ( ) of an intention ( ) from being considered
as intentions or objectives. If John intends to swim
in the pool ( ) even if he knows that he is going to
catch a cold ( ) because the water is too cold, we
cannot say that John intends to catch a cold.5 The
traditional relational properties (reflexivity, symme-
try, or transitivity) do not hold for the INTENTION
semantic relation.
</bodyText>
<sectionHeader confidence="0.998163" genericHeader="method">
3 Learning Model
</sectionHeader>
<subsectionHeader confidence="0.986762">
3.1 Experimental data
</subsectionHeader>
<bodyText confidence="0.999711818181818">
We applied the most frequent syntactic pattern that
expresses intentions in text ( to ) on the
first 10,000 sentences of the SemCor2.0 collection
and we extracted 1,873 sentences. These sentences
contain 115 intentions (manually identified by a
graduate student, not the author). The data consist-
ing of these positives and 258 arbitrarily selected
negative examples, was randomly divided into a
training set that contains 80% of the examples and
a test set with the remaining 20% instances. The
statistics are shown in Table 2.
</bodyText>
<table confidence="0.989362">
Intentions Non-Intentions Total
Training 92 208 300
Testing 23 50 73
</table>
<tableCaption confidence="0.994538">
Table 2: Experiments Data Division
</tableCaption>
<footnote confidence="0.541317666666667">
semantic relations.
4 and represent different intentions of the same person.
5A more detailed example can be found in (Bratman, 1990).
</footnote>
<subsectionHeader confidence="0.853521">
3.2 Features for intention
</subsectionHeader>
<bodyText confidence="0.993839978260869">
After analyzing our training data, we pinpointed a
set of features to help us identify the intentions en-
coded by the pattern to . The WordNet
senses needed to extract the semantic features were
taken from SemCor. We will use Mary intends to
revise the paper to show each feature’s value.
The semantic class of the the verb’s agent
or specializations of it. Intentions and objectives
are specific to humans. Thus, the semantic class of
the agent bears a high importance. We used
an in-house semantic parser to retrieve the AGENT
of the verb. The feature’s value is its WordNet
semantic class. Mary names a person. Thus, the
semantic class that we are seeking is entity#1.
We chose this semantic generalization because
nouns and verbs belong to open part-of-speech
classes. There can be an enormous number of pos-
sibilities and any models built using them as fea-
ture values will not be able to generalize beyond the
training examples. Therefore, we introduce a bias
in our learning framework based on the assumption:
noun and verb concepts will semantically behave
as the concepts that subsume them in the WordNet
structures. But, by generalizing concepts, we lose
some of their semantic properties. Hence, we spe-
cialize the semantic class of a concept by re-
placing it with its immediate hyponym ( ) that sub-
sumes . We can further increase the semantic level
by specializing . We note that the number of values
is still finite even though we specialized the general
concepts. As the specialization level increases, there
will be words that cannot be further specialized
(entity#1 cannot be specialized even once). In such
cases, we add to the set of feature values.
The semantic class of the verb or its spe-
cializations. The intention phrase is subordinated
to a verb ( ). The semantic class of this verb is
the system’s second feature. In our example,
(intend#1) semantic class is wish#3.
The semantic class of the verb’s agent, if
this agent differs from the verb’s agent; other-
wise, a common value (equal) is given. We identify
the AGENT of the verb. The specializations of
its semantic class will be used if the top noun proves
to be too general. In the sample sentence, the agent
of revise is Mary. We can have a different agent for
</bodyText>
<page confidence="0.98707">
33
</page>
<bodyText confidence="0.92091">
Semantic Semantic class of the verb (%)
class of
the ’s
agent
no specialization level of specialization level of specialization
Semantic class of the verb Semantic class of the verb Semantic class of the verb
no spec. level level no spec. level level no spec. level level
no spec. 87.67 80.82 87.67 90.41 87.67 87.67 86.30 83.56 84.93
level 89.04 82.19 87.67 87.67 89.04 87.67 87.67 86.30 84.93
level 87.67 83.56 87.67 90.41 90.41 89.04 89.04 87.67 86.30
</bodyText>
<tableCaption confidence="0.981868">
Table 3: Accuracy of models using the specialization level for the agent semantic class
</tableCaption>
<bodyText confidence="0.980965878787879">
the verb (Mary intends John to revise the pa-
per). Let’s assume that Mary is John’s supervisor
and she can make him revise the document. The sen-
tence expresses Mary’s intention of persuading John
to revise the paper, but this objective is not encoded
by the pattern we considered.
The semantic class of the verb or its spe-
cializations. The verb expresses the future ac-
tion or behavior that the agent intends. We extract
this feature using WordNet hierarchies. Revise#] be-
longs to the act#] semantic class.
A flag indicating if the verb has an affir-
mative or a negative form. We want to differen-
tiate between sentences like John wants to go for a
walk and John doesn’t want to go for a walk. The
first sentence expresses John’s intention, while, in
the second one, no intention can be identified.
The type of the analyzed sentence. This feature
is primarily concerned with questions. A question
like Where do you plan to go for a walk? indicates
the intention of going for a walk, unlike the question
Do you plan to go for a walk? which might express
an intention if the answer is “yes”. This feature’s
values are the wh-words that begin a question or n/a
for the other types of English sentences.
We did not analyze the affirmative versus the neg-
ative form of the verb because it does not affect
the objective attribute of the intention. The sentence
John intends not to go for a walk expresses a nega-
tive intention. This sentence is much stronger than
John doesn’t intend to go for a walk. In the former
context, John has set a goal for himself , while in the
second sentence, the objective does not exist.
</bodyText>
<sectionHeader confidence="0.996975" genericHeader="method">
4 Experimental Results
</sectionHeader>
<subsectionHeader confidence="0.997699">
4.1 Impact of specialization
</subsectionHeader>
<bodyText confidence="0.999438">
The first experiment was performed using the LIB-
SVm package and the WordNet semantic classes.
</bodyText>
<footnote confidence="0.740197">
6http://www.csie.ntu.edu.tw/˜cjlin/libsvm/index.html
</footnote>
<bodyText confidence="0.999917555555556">
These features yield an accuracy of 87.67%. Try-
ing to improve the performance, we specialized the
semantic classes. When the ’s agent semantic
class was specialized, the accuracy remained con-
stant. If we replace the ’s semantic class with
its direct hyponyms, the accuracy drops 5.48%. But,
the specialization of the agent’s semantic class
brings an improvement of 1.37% and the special-
ization of the ’s class produces an increase in
accuracy of 2.74%. Given this fluctuation in per-
formance, we performed 81 different experiments
which create SVm models using the same training
data annotated with more general or more specific
feature values. For each feature, we analyzed the
first two semantic specialization levels.
From our experiments, we noticed that the spe-
cialization of the ’s agent semantic class does
not influence the performance. Out of the 27 ex-
periment triplets in which this specialization level
changes, in only 4, it influences the result and, in
3 of them, the accuracy increases with the special-
ization level. Thus, our third feature is the second
specialization level of the ’s agent class. Ta-
ble 3 shows the results obtained when the values of
the radial kernel parameters were chosen to optimize
the 5-fold-cross-validation on the training data. The
best models are described in Table 4.
</bodyText>
<subsectionHeader confidence="0.997524">
Model Level of specialization for the features
</subsectionHeader>
<bodyText confidence="0.979199833333333">
A semantic class of the agent, level of specialization for
the ’s semantic class, and semantic class of the verb
B semantic level for the agent class, level of the
’s semantic class, and the semantic class of the verb
C level of the agent’s semantic class and
specialization levels for the and semantic classes
</bodyText>
<tableCaption confidence="0.986266">
Table 4: The best three intention classifiers
</tableCaption>
<subsectionHeader confidence="0.998921">
4.2 Learning curves
</subsectionHeader>
<bodyText confidence="0.999448333333333">
We further analyzed our data and models and tried
to see how many training examples are needed to
reach 90.41% accuracy. We varied the training data
</bodyText>
<page confidence="0.99628">
34
</page>
<table confidence="0.961407">
Semantic class of the Semantic class of the Semantic class of the Semantic class of the verb Sentence
’s agent verb ’s agent verb form type
Model A 2.74 16.44 1.37 0 2.74 4.11
Model B 2.74 15.07 1.37 0 4.11 2.74
Model C 1.37 16.44 4.11 0 4.11 2.74
</table>
<tableCaption confidence="0.999874">
Table 5: The improvement (%) brought by each feature to the three best SVM models
</tableCaption>
<bodyText confidence="0.998789454545455">
size and validated the new models using our previ-
ous test set. Figure 1 shows the performance varia-
tion of three models that use feature sets identical in
terms of specialization levels to the ones of the A, B,
and C classifiers. All three models exhibit a similar
behavior with respect to the change in the training
set size. Therefore, our features create a stable al-
gorithm. The highest accuracy models use all 300
training examples. Thus, we did not reach the satu-
ration point, but, considering the performance curve,
this point is not very far.
</bodyText>
<figure confidence="0.8543105">
50 100 150 200 250 300
Number of training examples
</figure>
<figureCaption confidence="0.999437">
Figure 1: Testing set is constant
</figureCaption>
<subsectionHeader confidence="0.957739">
4.3 Feature impact on the SVM models
</subsectionHeader>
<bodyText confidence="0.999974571428572">
All our previous experiments used the entire set of
features. Now, we investigate the relative contribu-
tion of each feature. We performed experiments that
use only five out of the six features. In Table 5, we
list the accuracy increase that is gained by the inclu-
sion of each feature. The most influential attribute is
the verb’s semantic class or its specializations.
The intention’s description verb does not influence
the classification result. Because intentions consist
of a future action and verbs express actions, there
are very few verbs, such as dream or snore (invol-
untary actions) that cannot occupy the verb’s
position. The syntactic features bring an average in-
crease in accuracy of 3.50%.
</bodyText>
<subsectionHeader confidence="0.999697">
4.4 Impact of word sense disambiguation
</subsectionHeader>
<bodyText confidence="0.979964125">
Perfect word sense disambiguation might be a too
strong assumption. In this section, we examine the
effects of weaker disambiguation. Table 6 shows the
accuracies of the best three models when each con-
cept is tagged with its first WordNet sense (No WSn)
and when the senses are given by an in-house WSn
system with an accuracy of 69% computed on the
SemCor data (Automatic WSn).
</bodyText>
<table confidence="0.998725">
No WSn Automatic WSn Gold WSn
Model A 72.60 79.45 90.41
Model B 73.97 79.45 90.41
Model C 72.60 80.82 90.41
</table>
<tableCaption confidence="0.96693">
Table 6: Best models performance (%)
</tableCaption>
<subsectionHeader confidence="0.896202">
4.5 C5 results
</subsectionHeader>
<bodyText confidence="0.999987444444445">
After examining the SVM results, we applied the C5
machine learning algorithm (Quinlan, 2004) to the
same training data annotated with the same feature
set, in a similar manner. Again, we specialized the
four semantic classes, independently, and tested the
decision trees against the testing data. Table 7 shows
their accuracy. The highest values were obtained for
the first level of specialization of the verb se-
mantic class. The specialization levels of the other
semantic classes do not influence the accuracy of
the decision trees. The most tested attribute is the
verb. This further substantiates our observa-
tion, made during our SVM models analysis, that this
feature has the greatest importance in the intention
classification process. Our error analysis of the C5
results indicates that, because of the relatively small
numbers of training instances, C5 ignores some of
the features and makes wrong decisions.
</bodyText>
<sectionHeader confidence="0.974959" genericHeader="method">
5 Application to Question Answering
</sectionHeader>
<bodyText confidence="0.784921666666667">
Questions involving intentions cannot be answered
only by keyword-based or simple surface-level
matching techniques. Table 8 lists two questions for
</bodyText>
<figure confidence="0.994826916666666">
SVM model accuracy
100
90
80
70
60
50
40
30
Model A
Model B
Model C
</figure>
<page confidence="0.989397">
35
</page>
<table confidence="0.999809846153846">
: What was Putin trying to achieve by increasing military cooperation with North Korea?
: Putin &amp; INT &amp; ANS &amp; MANNER &amp; increase &amp; military &amp; cooperation &amp; with
&amp; North Korea
: Putin is attempting [to restore Russia’s influence in the East Asian region][INT]. The report said, the possibility remains that Russia could
increase military cooperation with North Korea based on their treaty.
: Putin &amp; INT &amp; restore &amp; Russia &amp; ’s &amp; influence &amp; LOCATION &amp; East &amp;
Asian &amp; region &amp; report &amp; say &amp; possibility &amp; remains &amp; increase &amp;
military &amp; cooperation &amp; with &amp; North Korea &amp; base &amp; treaty
: From where does al Qaeda intend [to purchase weapons of mass destruction][INT]?
: alQaeda &amp; INT &amp; ANS &amp; LOCATION &amp; purchase &amp; weapons of mass destruction
: It is known that Osama bin Laden’s al Qaeda network has tried [to buy ingredients for weapons of mass destruction in Russia][INT].
: Osama bin Laden &amp;’s &amp; al Qaeda &amp; network &amp; IS-A &amp; INT &amp; buy &amp;
ingredient &amp; PURPOSE &amp; weapons of mass destruction &amp; LOCATION &amp; Russia
</table>
<tableCaption confidence="0.999387">
Table 8: Question and answer pair examples
</tableCaption>
<bodyText confidence="0.961783166666667">
Semantic class of Semantic class of the verb
the ’s agent
no spec. level level
no spec. 79.45 87.67 84.93
level 68.49 87.67 84.93
level 79.45 87.67 84.93
</bodyText>
<tableCaption confidence="0.944887">
Table 7: C5 models accuracy (%)
</tableCaption>
<bodyText confidence="0.99997455">
which finding the correct answer primarily depends
on the discovery of the INTENTION relation.
The answer type for the question is the IN-
TENTION argument itself. The question processing
module will detect that the answer being sought is
Putin’s intention. The semantic relations module
processes ’s text and discovers the INTENTION
relation. The question is searching for the intent of
Putin with regards to North Korea and the answer
text reveals Putin’s intention to restore Russia’s in-
fluence in the area. Question is searching for a
location as its answer type and the correct answer is
one which involves al Qaeda intending to purchase
weapons of mass destruction. The candidate answer
text ( ) reveals the organization’s past intent to buy
(synonym with purchase) weapons in Russia. Be-
cause the two intentions have the same agent, future
action and theme, the two semantically enhanced
logic forms can now be unified and we can pin down
the location of the intent (Russia).
</bodyText>
<sectionHeader confidence="0.99981" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.99993075">
We proposed a method to detect the INTENT rela-
tion encoded by the sentence-level pattern to
with a 90.41% accuracy. We plan to investi-
gate the other INTENTION patterns as well as other
semantic relations such as MOTIVE, IMPLICATION,
or MEANING which, currently, cannot be identified
by the state-of-the-art NLP systems. These relation-
ships need to be analyzed to provide a complete cov-
erage of the underlying semantics of text documents.
We intend to incorporate our INTENTION detection
module into a Question Answering system and show
its impact.
</bodyText>
<sectionHeader confidence="0.99944" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99984056">
Anscombe, G.E.M. 1957. Intention. Cornell University
Press, Ithaca, New York.
Audi, Robert. 1973. Intending. The Journal of Philoso-
phy, 70(13):387–403.
Bratman, Michael E. 1981. Intention and means-end
reasoning. The Philosophical Review, 90(2):252–265.
Bratman, Michael E. 1987. Intention, Plans, and Prac-
tical Reason. Harvard University Press, Cambridge,
Massachusetts.
Bratman, Michael E. 1990. What is intention? In Inten-
tions in Communication. MIT Press.
Miller, George A., Claudia Leacock, Randee Tengi, and
Ross T. Bunker. 1993. A semantic concordance. In
Proceedings of the ARPA Human Language Technol-
ogy Workshop
Miller, George A. 1995. Wordnet: A lexical database.
Communication of the ACM, 38(11):39–41.
Pollack, Martha E. 1990. Plans as complex mental atti-
tudes. In Intentions in Communication. MIT Press.
Quinlan, Ross. 2004. Data Mining Tools See5 and C5.0.
http://www.rulequest.com/see5-info.html
Wiebe, Janyce M., Theresa Wilson, Rebecca F. Bruce,
Matthew Bell, and Melanie Martin. 2004. Learn-
ing subjective language. Computational Linguistics,
30(3):277–308.
</reference>
<page confidence="0.99894">
36
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.668977">
<title confidence="0.998612">Automatic Discovery of Intentions in Text and its Application to Question Answering</title>
<author confidence="0.999936">Marta Tatu</author>
<affiliation confidence="0.99807">Human Language Technology Research Institute Department of Computer Science University of Texas at Dallas</affiliation>
<address confidence="0.979687">Richardson, TX 75080, USA</address>
<email confidence="0.999496">marta@hlt.utdallas.edu</email>
<abstract confidence="0.970193">Semantic relations between text concepts denote the core elements of lexical semantics. This paper presents a model for automatic detection of semantic relation. Our approach first identifies the syntactic patterns that encode intentions, then we select syntactic and sefeatures for a classifier. In conclusion, we discuss the appliof to Q&amp;A.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>G E M Anscombe</author>
</authors>
<title>Intention.</title>
<date>1957</date>
<publisher>Cornell University Press,</publisher>
<location>Ithaca, New York.</location>
<contexts>
<context position="3106" citStr="Anscombe, 1957" startWordPosition="494" endWordPosition="495">hat this takes place in a superstore, well-known as a place where people buy things from. The clerk’s answer emerges from our common beliefs and background knowledge as well as from his desire to help a customer. Intentions are the framework for plans. Many philosophers and artificial intelligence researchers studied the intentions as parts of coordinating plans (Bratman, 1987; Pollack, 1990) because people establish plans for future times. In this paper, we regard intentions as expressions of a particular action that shall take place in the future, in which the speaker is some sort of agent (Anscombe, 1957). For example, the sentence Mary is going to buy a TV set shows Mary’s intention. Anscombe (1957) considers intentions as a subclass of predictions, besides commands and Proceedings of the ACL Student Research Workshop, pages 31–36, Ann Arbor, Michigan, June 2005. c�2005 Association for Computational Linguistics prophecies. John is going to be sick is usually a prophecy, John, go for a walk! is an order, and John plans to take a walk expresses an intention. 1.3 Previous work Various methodologies have been proposed and used over the years for the task of extracting semantic relations from text</context>
</contexts>
<marker>Anscombe, 1957</marker>
<rawString>Anscombe, G.E.M. 1957. Intention. Cornell University Press, Ithaca, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Audi</author>
</authors>
<date>1973</date>
<journal>Intending. The Journal of Philosophy,</journal>
<volume>70</volume>
<issue>13</issue>
<contexts>
<context position="4818" citStr="Audi, 1973" startWordPosition="758" endWordPosition="759">, or emotions in text. Using clues of subjectivity (low-frequency words, collocations), they identify opinion piece texts such as editorials, letters to the editor, or arts and leisure reviews. There exists an immense literature in philosophy about the different types of intentions and their characteristics. Bratman (1987) tries to find the relationship between the two distinct phenomena of doing something intentionally and intending to do something. Numerous philosophical studies discuss how intentions relate to other psychological concepts, such as, beliefs, desires, hopes, or expectations (Audi, 1973; Bratman, 1981; Bratman, 1987). Intentions are consistent with the person’s beliefs, and, unlike ordinary desires, require consistency (Bratman, 1987). They can generate reasons for or against future intentions (Bratman, 1981; Bratman, 1987). As plan elements, intentions require a certain stability. Their side effects need not be intended, even if they were taken into consideration in the first place1 (Bratman, 1990). 2 Syntax and Semantics of Intention 2.1 Syntactic patterns Because, in all the cases that we encountered, intentions were conveyed by phrases, we took a closer look at how inten</context>
</contexts>
<marker>Audi, 1973</marker>
<rawString>Audi, Robert. 1973. Intending. The Journal of Philosophy, 70(13):387–403.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael E Bratman</author>
</authors>
<title>Intention and means-end reasoning.</title>
<date>1981</date>
<journal>The Philosophical Review,</journal>
<volume>90</volume>
<issue>2</issue>
<contexts>
<context position="4833" citStr="Bratman, 1981" startWordPosition="760" endWordPosition="761">s in text. Using clues of subjectivity (low-frequency words, collocations), they identify opinion piece texts such as editorials, letters to the editor, or arts and leisure reviews. There exists an immense literature in philosophy about the different types of intentions and their characteristics. Bratman (1987) tries to find the relationship between the two distinct phenomena of doing something intentionally and intending to do something. Numerous philosophical studies discuss how intentions relate to other psychological concepts, such as, beliefs, desires, hopes, or expectations (Audi, 1973; Bratman, 1981; Bratman, 1987). Intentions are consistent with the person’s beliefs, and, unlike ordinary desires, require consistency (Bratman, 1987). They can generate reasons for or against future intentions (Bratman, 1981; Bratman, 1987). As plan elements, intentions require a certain stability. Their side effects need not be intended, even if they were taken into consideration in the first place1 (Bratman, 1990). 2 Syntax and Semantics of Intention 2.1 Syntactic patterns Because, in all the cases that we encountered, intentions were conveyed by phrases, we took a closer look at how intentions can be ex</context>
</contexts>
<marker>Bratman, 1981</marker>
<rawString>Bratman, Michael E. 1981. Intention and means-end reasoning. The Philosophical Review, 90(2):252–265.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael E Bratman</author>
</authors>
<title>Intention, Plans, and Practical Reason.</title>
<date>1987</date>
<publisher>Harvard University Press,</publisher>
<location>Cambridge, Massachusetts.</location>
<contexts>
<context position="2870" citStr="Bratman, 1987" startWordPosition="453" endWordPosition="454">ng the cups. Customer: Where do you have the $1 cups? Salesman: How many do you want? Intentions are closely related to other semantic relations such as beliefs, motives, desires, or plans. In the above example, the context tells us that this takes place in a superstore, well-known as a place where people buy things from. The clerk’s answer emerges from our common beliefs and background knowledge as well as from his desire to help a customer. Intentions are the framework for plans. Many philosophers and artificial intelligence researchers studied the intentions as parts of coordinating plans (Bratman, 1987; Pollack, 1990) because people establish plans for future times. In this paper, we regard intentions as expressions of a particular action that shall take place in the future, in which the speaker is some sort of agent (Anscombe, 1957). For example, the sentence Mary is going to buy a TV set shows Mary’s intention. Anscombe (1957) considers intentions as a subclass of predictions, besides commands and Proceedings of the ACL Student Research Workshop, pages 31–36, Ann Arbor, Michigan, June 2005. c�2005 Association for Computational Linguistics prophecies. John is going to be sick is usually a </context>
<context position="4532" citStr="Bratman (1987)" startWordPosition="716" endWordPosition="717">ry-based learning, or support vector machines were introduced. Currently, there is also a increased interest in shallow semantic parsing of open texts and automatic labeling of semantic roles. Wiebe et al. (2004) focused on the detection of subjective language such as opinions, evaluations, or emotions in text. Using clues of subjectivity (low-frequency words, collocations), they identify opinion piece texts such as editorials, letters to the editor, or arts and leisure reviews. There exists an immense literature in philosophy about the different types of intentions and their characteristics. Bratman (1987) tries to find the relationship between the two distinct phenomena of doing something intentionally and intending to do something. Numerous philosophical studies discuss how intentions relate to other psychological concepts, such as, beliefs, desires, hopes, or expectations (Audi, 1973; Bratman, 1981; Bratman, 1987). Intentions are consistent with the person’s beliefs, and, unlike ordinary desires, require consistency (Bratman, 1987). They can generate reasons for or against future intentions (Bratman, 1981; Bratman, 1987). As plan elements, intentions require a certain stability. Their side e</context>
</contexts>
<marker>Bratman, 1987</marker>
<rawString>Bratman, Michael E. 1987. Intention, Plans, and Practical Reason. Harvard University Press, Cambridge, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael E Bratman</author>
</authors>
<title>What is intention?</title>
<date>1990</date>
<booktitle>In Intentions in Communication.</booktitle>
<publisher>MIT Press.</publisher>
<contexts>
<context position="5239" citStr="Bratman, 1990" startWordPosition="822" endWordPosition="823">onally and intending to do something. Numerous philosophical studies discuss how intentions relate to other psychological concepts, such as, beliefs, desires, hopes, or expectations (Audi, 1973; Bratman, 1981; Bratman, 1987). Intentions are consistent with the person’s beliefs, and, unlike ordinary desires, require consistency (Bratman, 1987). They can generate reasons for or against future intentions (Bratman, 1981; Bratman, 1987). As plan elements, intentions require a certain stability. Their side effects need not be intended, even if they were taken into consideration in the first place1 (Bratman, 1990). 2 Syntax and Semantics of Intention 2.1 Syntactic patterns Because, in all the cases that we encountered, intentions were conveyed by phrases, we took a closer look at how intentions can be expressed in the written text. For our investigations, we chose the Sem1Due to space limitations, we couldn’t include detailed examples. Please see the cited articles for examples. Cor text collection (Miller et al., 1993), a subset of the Brown corpus manually tagged with WordNet senses (37,176 sentences in 352 newspaper articles). After manually classifying the first 2,700 sentences from SemCor into sen</context>
<context position="9728" citStr="Bratman, 1990" startWordPosition="1608" endWordPosition="1609">e extracted 1,873 sentences. These sentences contain 115 intentions (manually identified by a graduate student, not the author). The data consisting of these positives and 258 arbitrarily selected negative examples, was randomly divided into a training set that contains 80% of the examples and a test set with the remaining 20% instances. The statistics are shown in Table 2. Intentions Non-Intentions Total Training 92 208 300 Testing 23 50 73 Table 2: Experiments Data Division semantic relations. 4 and represent different intentions of the same person. 5A more detailed example can be found in (Bratman, 1990). 3.2 Features for intention After analyzing our training data, we pinpointed a set of features to help us identify the intentions encoded by the pattern to . The WordNet senses needed to extract the semantic features were taken from SemCor. We will use Mary intends to revise the paper to show each feature’s value. The semantic class of the the verb’s agent or specializations of it. Intentions and objectives are specific to humans. Thus, the semantic class of the agent bears a high importance. We used an in-house semantic parser to retrieve the AGENT of the verb. The feature’s value is its Wor</context>
</contexts>
<marker>Bratman, 1990</marker>
<rawString>Bratman, Michael E. 1990. What is intention? In Intentions in Communication. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
<author>Claudia Leacock</author>
<author>Randee Tengi</author>
<author>Ross T Bunker</author>
</authors>
<title>A semantic concordance.</title>
<date>1993</date>
<booktitle>In Proceedings of the ARPA Human Language Technology Workshop</booktitle>
<contexts>
<context position="5653" citStr="Miller et al., 1993" startWordPosition="890" endWordPosition="893">atman, 1981; Bratman, 1987). As plan elements, intentions require a certain stability. Their side effects need not be intended, even if they were taken into consideration in the first place1 (Bratman, 1990). 2 Syntax and Semantics of Intention 2.1 Syntactic patterns Because, in all the cases that we encountered, intentions were conveyed by phrases, we took a closer look at how intentions can be expressed in the written text. For our investigations, we chose the Sem1Due to space limitations, we couldn’t include detailed examples. Please see the cited articles for examples. Cor text collection (Miller et al., 1993), a subset of the Brown corpus manually tagged with WordNet senses (37,176 sentences in 352 newspaper articles). After manually classifying the first 2,700 sentences from SemCor into sentences that contain or not intentions, only 46 examples were identified. The syntactic patterns listed in Table 1 cover 95.65% of them. Because the first pattern comprises more than half of the studied examples, our algorithm focuses on detecting intentions encoded by to . We note that this pattern is ambiguous and may convey other semantics. For instance, Mary began to play with the dog, He told her to meet yo</context>
</contexts>
<marker>Miller, Leacock, Tengi, Bunker, 1993</marker>
<rawString>Miller, George A., Claudia Leacock, Randee Tengi, and Ross T. Bunker. 1993. A semantic concordance. In Proceedings of the ARPA Human Language Technology Workshop</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
</authors>
<title>Wordnet: A lexical database.</title>
<date>1995</date>
<journal>Communication of the ACM,</journal>
<volume>38</volume>
<issue>11</issue>
<marker>Miller, 1995</marker>
<rawString>Miller, George A. 1995. Wordnet: A lexical database. Communication of the ACM, 38(11):39–41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martha E Pollack</author>
</authors>
<title>Plans as complex mental attitudes.</title>
<date>1990</date>
<booktitle>In Intentions in Communication.</booktitle>
<publisher>MIT Press.</publisher>
<contexts>
<context position="2886" citStr="Pollack, 1990" startWordPosition="455" endWordPosition="456">stomer: Where do you have the $1 cups? Salesman: How many do you want? Intentions are closely related to other semantic relations such as beliefs, motives, desires, or plans. In the above example, the context tells us that this takes place in a superstore, well-known as a place where people buy things from. The clerk’s answer emerges from our common beliefs and background knowledge as well as from his desire to help a customer. Intentions are the framework for plans. Many philosophers and artificial intelligence researchers studied the intentions as parts of coordinating plans (Bratman, 1987; Pollack, 1990) because people establish plans for future times. In this paper, we regard intentions as expressions of a particular action that shall take place in the future, in which the speaker is some sort of agent (Anscombe, 1957). For example, the sentence Mary is going to buy a TV set shows Mary’s intention. Anscombe (1957) considers intentions as a subclass of predictions, besides commands and Proceedings of the ACL Student Research Workshop, pages 31–36, Ann Arbor, Michigan, June 2005. c�2005 Association for Computational Linguistics prophecies. John is going to be sick is usually a prophecy, John, </context>
</contexts>
<marker>Pollack, 1990</marker>
<rawString>Pollack, Martha E. 1990. Plans as complex mental attitudes. In Intentions in Communication. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ross Quinlan</author>
</authors>
<date>2004</date>
<booktitle>Data Mining Tools See5 and C5.0. http://www.rulequest.com/see5-info.html</booktitle>
<contexts>
<context position="18609" citStr="Quinlan, 2004" startWordPosition="3131" endWordPosition="3132"> disambiguation might be a too strong assumption. In this section, we examine the effects of weaker disambiguation. Table 6 shows the accuracies of the best three models when each concept is tagged with its first WordNet sense (No WSn) and when the senses are given by an in-house WSn system with an accuracy of 69% computed on the SemCor data (Automatic WSn). No WSn Automatic WSn Gold WSn Model A 72.60 79.45 90.41 Model B 73.97 79.45 90.41 Model C 72.60 80.82 90.41 Table 6: Best models performance (%) 4.5 C5 results After examining the SVM results, we applied the C5 machine learning algorithm (Quinlan, 2004) to the same training data annotated with the same feature set, in a similar manner. Again, we specialized the four semantic classes, independently, and tested the decision trees against the testing data. Table 7 shows their accuracy. The highest values were obtained for the first level of specialization of the verb semantic class. The specialization levels of the other semantic classes do not influence the accuracy of the decision trees. The most tested attribute is the verb. This further substantiates our observation, made during our SVM models analysis, that this feature has the greatest im</context>
</contexts>
<marker>Quinlan, 2004</marker>
<rawString>Quinlan, Ross. 2004. Data Mining Tools See5 and C5.0. http://www.rulequest.com/see5-info.html</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janyce M Wiebe</author>
<author>Theresa Wilson</author>
<author>Rebecca F Bruce</author>
<author>Matthew Bell</author>
<author>Melanie Martin</author>
</authors>
<title>Learning subjective language.</title>
<date>2004</date>
<journal>Computational Linguistics,</journal>
<volume>30</volume>
<issue>3</issue>
<contexts>
<context position="4130" citStr="Wiebe et al. (2004)" startWordPosition="655" endWordPosition="658">r, and John plans to take a walk expresses an intention. 1.3 Previous work Various methodologies have been proposed and used over the years for the task of extracting semantic relations from text. Purely probabilistic models, empirical methods, or hand-coded constraints were some of the approaches that do not use machine learning algorithms. Later on, methods that use decision tree, neural networks, memory-based learning, or support vector machines were introduced. Currently, there is also a increased interest in shallow semantic parsing of open texts and automatic labeling of semantic roles. Wiebe et al. (2004) focused on the detection of subjective language such as opinions, evaluations, or emotions in text. Using clues of subjectivity (low-frequency words, collocations), they identify opinion piece texts such as editorials, letters to the editor, or arts and leisure reviews. There exists an immense literature in philosophy about the different types of intentions and their characteristics. Bratman (1987) tries to find the relationship between the two distinct phenomena of doing something intentionally and intending to do something. Numerous philosophical studies discuss how intentions relate to oth</context>
</contexts>
<marker>Wiebe, Wilson, Bruce, Bell, Martin, 2004</marker>
<rawString>Wiebe, Janyce M., Theresa Wilson, Rebecca F. Bruce, Matthew Bell, and Melanie Martin. 2004. Learning subjective language. Computational Linguistics, 30(3):277–308.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>