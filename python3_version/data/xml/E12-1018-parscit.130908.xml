<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001979">
<title confidence="0.998782">
Tree Representations in Probabilistic Models for Extended Named
Entities Detection
</title>
<author confidence="0.897707">
Marco Dinarelli Sophie Rosset
</author>
<affiliation confidence="0.8788325">
LIMSI-CNRS LIMSI-CNRS
Orsay, France Orsay, France
</affiliation>
<email confidence="0.997489">
marcod@limsi.fr rosset@limsi.fr
</email>
<sectionHeader confidence="0.998659" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.994534647058824">
In this paper we deal with Named En-
tity Recognition (NER) on transcriptions of
French broadcast data. Two aspects make
the task more difficult with respect to previ-
ous NER tasks: i) named entities annotated
used in this work have a tree structure, thus
the task cannot be tackled as a sequence la-
belling task; ii) the data used are more noisy
than data used for previous NER tasks. We
approach the task in two steps, involving
Conditional Random Fields and Probabilis-
tic Context-Free Grammars, integrated in a
single parsing algorithm. We analyse the
effect of using several tree representations.
Our system outperforms the best system of
the evaluation campaign by a significant
margin.
</bodyText>
<sectionHeader confidence="0.999514" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999834888888889">
Named Entity Recognition is a traditinal task of
the Natural Language Processing domain. The
task aims at mapping words in a text into seman-
tic classes, such like persons, organizations or lo-
calizations. While at first the NER task was quite
simple, involving a limited number of classes (Gr-
ishman and Sundheim, 1996), along the years
the task complexity increased as more complex
class taxonomies were defined (Sekine and No-
bata, 2004). The interest in the task is related to
its use in complex frameworks for (semantic) con-
tent extraction, such like Relation Extraction ap-
plications (Doddington et al., 2004).
This work presents research on a Named Entity
Recognition task defined with a new set of named
entities. The characteristic of such set is in that
named entities have a tree structure. As conce-
quence the task cannot be tackled as a sequence
labelling approach. Additionally, the use of noisy
data like transcriptions of French broadcast data,
makes the task very challenging for traditional
NLP solutions. To deal with such problems, we
adopt a two-steps approach, the first being real-
ized with Conditional Random Fields (CRF) (Laf-
ferty et al., 2001), the second with a Probabilistic
Context-Free Grammar (PCFG) (Johnson, 1998).
The motivations behind that are:
</bodyText>
<listItem confidence="0.908250565217391">
• Since the named entities have a tree struc-
ture, it is reasonable to use a solution com-
ing from syntactic parsing. However pre-
liminary experiments using such approaches
gave poor results.
• Despite the tree-structure of the entities,
trees are not as complex as syntactic trees,
thus, before designing an ad-hoc solution for
the task, which require a remarkable effort
and yet it doesn’t guarantee better perfor-
mances, we designed a solution providing
good results and which required a limited de-
velopment effort.
• Conditional Random Fields are models ro-
bust to noisy data, like automatic transcrip-
tions of ASR systems (Hahn et al., 2010),
thus it is the best choice to deal with tran-
scriptions of broadcast data. Once words
have been annotated with basic entity con-
stituents, the tree structure of named entities
is simple enough to be reconstructed with
relatively simple model like PCFG (Johnson,
1998).
</listItem>
<bodyText confidence="0.993222">
The two models are integrated in a single pars-
ing algorithm. We analyze the effect of the use of
</bodyText>
<page confidence="0.975986">
174
</page>
<note confidence="0.9924425">
Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 174–184,
Avignon, France, April 23 - 27 2012. c�2012 Association for Computational Linguistics
</note>
<figure confidence="0.985189333333333">
S
amount
object
time.date.rel
amount
org.adm
</figure>
<figureCaption confidence="0.9617045">
Figure 1: Examples of structured named entities annotated on the
data used in this work
</figureCaption>
<figure confidence="0.994664923076923">
demonym
kind
loc.adm.town name time-modifier
val kind name
val object
Zahra
Abouch
Conseil de Gouvernement
irakien
func.coll
pers.ind
name.firstname.last
org.adm
</figure>
<bodyText confidence="0.994384263157895">
several tree representations, which result in differ-
ent parsing models with different performances.
We provide a detailed evaluation of our mod-
els. Results can be compared with those obtained
in the evaluation campaign where the same data
were used. Our system outperforms the best sys-
tem of the evaluation campaign by a significant
margin.
The rest of the paper is structured as follows: in
the next section we introduce the extended named
entities used in this work, in section 3 we describe
our two-steps algorithm for parsing entity trees,
in section 4 we detail the second step of our ap-
proach based on syntactic parsing approaches, in
particular we describe the different tree represen-
tations used in this work to encode entity trees
in parsing models. In section 6 we describe and
comment experiments, and finally, in section 7,
we draw some conclusions.
</bodyText>
<sectionHeader confidence="0.993262" genericHeader="introduction">
2 Extended Named Entities
</sectionHeader>
<bodyText confidence="0.902442">
The most important aspect of the NER task we
investigated is provided by the tree structure of
named entities. Examples of such entities are
given in figure 1 and 2, where words have been re-
move for readability issues and are: (“90 persons
are still present at Atambua. It’s there that 3 employ-
ees of the High Conseil of United Nations for refugees
have been killed yesterday morning”):
90 personnes toujours pr´esentes a`
Atambua c’ est l`a qu’ hier matin ont
´et´e tu´es 3 employ´es du haut commis-
sariat des Nations unies aux r´efugi´es ,
le HCR
Words realizing entities in figure 2 are in bold,
and they correspond to the tree leaves in the
picture. As we see in the figures, entities
can have complex structures. Beyond the use
of subtypes, like individual in person (to give
pers.ind), or administrative in organization
(to give org.adm), entities with more specific con-
tent can be constituents of more general enti-
ties to form tree structures, like name.first and
</bodyText>
<figureCaption confidence="0.956770333333333">
Figure 2: An example of named entity tree corresponding to en-
tities of a whole sentence. Tree leaves, corresponding to sentence
words have been removed to keep readability
</figureCaption>
<table confidence="0.9993305">
Quaero training dev
# sentences 43,251 112
words entities words entities
# tokens 1,251,432 245,880 2,659 570
# vocabulary 39,631 134 891 30
# components – 133662 – 971
# components dict. – 28 – 18
# OOV rate [%] – – 17.15 0
</table>
<tableCaption confidence="0.9644945">
Table 1: Statistics on the training and development sets of the
Quaero corpus
</tableCaption>
<bodyText confidence="0.97090852">
name.last for pers.ind or val (for value) and ob-
ject for amount.
These named entities have been annotated on
transcriptions of French broadcast news coming
from several radio channels. The transcriptions
constitute a corpus that has been split into train-
ing, development and evaluation sets.The evalu-
ation set, in particular, is composed of two set
of data, Broadcast News (BN in the table) and
Broadcast Conversations (BC in the table). The
evaluation of the models presented in this work
is performed on the merge of the two data types.
Some statistics of the corpus are reported in ta-
ble 1 and 2. This set of named entities has been
defined in order to provide more fine semantic in-
formation for entities found in the data, e.g. a
person is better specified by first and last name,
and is fully described in (Grouin, 2011) . In or-
der to avoid confusion, entities that can be associ-
ated directly to words, like name.first, name.last,
val and object, are called entity constituents, com-
ponents or entity pre-terminals (as they are pre-
terminals nodes in the trees). The other entities,
like pers.ind or amount, are called entities or non-
terminal entities, depending on the context.
</bodyText>
<sectionHeader confidence="0.939881" genericHeader="method">
3 Models Cascade for Extended Named
Entities
</sectionHeader>
<bodyText confidence="0.989718666666667">
Since the task of Named Entity Recognition pre-
sented here cannot be modeled as sequence la-
belling and, as mentioned previously, an approach
</bodyText>
<page confidence="0.997597">
175
</page>
<table confidence="0.999293375">
Quaero test BN test BC
#sentences 1704 3933
words entities words entities
#tokens 32945 2762 69414 2769
# vocabulary – 28 – 28
# components – 4128 – 4017
# components dict. 3.63 21 3.84 20
# OOV rate [%] 0 0
</table>
<tableCaption confidence="0.9576475">
Table 2: Statistics on the test set of the Quaero corpus, divided in
Broadcast News (BN) and Broadcast Conversations (BC)
</tableCaption>
<subsectionHeader confidence="0.999184">
3.1 Conditional Random Fields
</subsectionHeader>
<bodyText confidence="0.999939272727273">
CRFs are particularly suitable for sequence la-
belling tasks (Lafferty et al., 2001). Beyond the
possibility to include a huge number of features
using the same framework as Maximum Entropy
models (Berger et al., 1996), CRF models en-
code global conditional probabilities normalized
at sentence level.
Given a sequence of N words W1N =
w1, ..., wN and its corresponding components se-
quence EN1 = e1, ..., eN, CRF trains the condi-
tional probabilities
</bodyText>
<equation confidence="0.986495">
P(EN1|W1N) =
</equation>
<figureCaption confidence="0.956069666666667">
Figure 3: Processing schema of the two-steps approach proposed 1 N exp M �
in this work: CRF plus PCFG Z ri E n+2
λm · hm(en−1, en, wn−2) (1)
</figureCaption>
<bodyText confidence="0.998212722222222">
coming from syntactic parsing to perform named
entity annotation in “one-shot” is not robust on
the data used in this work, we adopt a two-steps.
The first is designed to be robust to noisy data and
is used to annotate entity components, while the
second is used to parse complete entity trees and
is based on a relatively simple model. Since we
are dealing with noisy data, the hardest part of the
task is indeed to annotate components on words.
On the other hand, since entity trees are relatively
simple, at least much simpler than syntactic trees,
once entity components have been annotated in a
first step, for the second step, a complex model is
not required, which would also make the process-
ing slower. Taking all these issues into account,
the two steps of our system for tree-structured
named entity recognition are performed as fol-
lows:
</bodyText>
<listItem confidence="0.992722166666667">
1. A CRF model (Lafferty et al., 2001) is used
to annotate components on words.
2. A PCFG model (Johnson, 1998) is used
to parse complete entity trees upon compo-
nents, i.e. using components annotated by
CRF as starting point.
</listItem>
<bodyText confidence="0.993816272727273">
This processing schema is depicted in figure 3.
Conditional Random Fields are described shortly
in the next subsection. PCFG models, constituting
the main part of this work together with the analy-
sis over tree representations, is described more in
details in the next sections.
where λm are the training parameters.
hm(en−1, en, wn+2
n−2) are the feature functions
capturing dependencies of entities and words. Z
is the partition function:
</bodyText>
<equation confidence="0.9835265">
H(˜en−1, ˜en, wn+2
n−2) (2)
</equation>
<bodyText confidence="0.906194307692308">
which ensures that probabilities sum up to one.
�en−1 and �en are components for previous and cur-
rent words, H(En−1, �en, wn+2
n−2) is an abbreviation
for EMm=1 λm · hm(en−1, en, wn+2
n−2), i.e. the set
of active feature functions at current position in
the sequence.
In the last few years different CRF implemen-
tations have been realized. The implementation
we refer in this work is the one described in
(Lavergne et al., 2010), which optimize the fol-
lowing objective function:
</bodyText>
<equation confidence="0.968666">
−log(P(EN1|W1N))+ρ1kλk1+ ρ2 2 kλk2 (3)
2
</equation>
<bodyText confidence="0.99996925">
IIλII1 and IIλII2 2 are the l1 and l2 regulariz-
ers (Riezler and Vasserman, 2004), and together
in a linear combination implement the elastic net
regularizer (Zou and Hastie, 2005). As mentioned
in (Lavergne et al., 2010), this kind of regulariz-
ers are very effective for feature selection at train-
ing time, which is a very good point when dealing
with noisy data and big set of features.
</bodyText>
<equation confidence="0.917332166666667">
N
ri
n=1
Z =L
˜eN
1
</equation>
<page confidence="0.993869">
176
</page>
<sectionHeader confidence="0.995994" genericHeader="method">
4 Models for Parsing Trees
</sectionHeader>
<bodyText confidence="0.999868166666667">
The models used in this work for parsing en-
tity trees refer to the models described in (John-
son, 1998), in (Charniak, 1997; Caraballo and
Charniak, 1997) and (Charniak et al., 1998), and
which constitutes the basis of the maximum en-
tropy model for parsing described in (Charniak,
2000). A similar lexicalized model has been pro-
posed also by Collins (Collins, 1997). All these
models are based on a PCFG trained from data
and used in a chart parsing algorithm to find the
best parse for the given input. The PCFG model
of (Johnson, 1998) is made of rules of the form:
</bodyText>
<listItem confidence="0.999421">
• XZ ⇒ X3Xk
• XZ ⇒ w
</listItem>
<bodyText confidence="0.999338333333333">
where X are non-terminal entities and w are
terminal symbols (words in our case).1 The prob-
ability associated to these rules are:
</bodyText>
<equation confidence="0.9998736">
P(Xi ==&gt; Xj,Xk) (4)
P(Xi)
P(Xi � w)
pi —w = (5)
P(Xi)
</equation>
<bodyText confidence="0.998735777777778">
The models described in (Charniak, 1997;
Caraballo and Charniak, 1997) encode probabil-
ities involving more information, such as head
words. In order to have a PCFG model made of
rules with their associated probabilities, we ex-
tract rules from the entity trees of our corpus. This
processing is straightforward, for example from
the tree depicted in figure 2, the following rules
are extracted:
</bodyText>
<equation confidence="0.982237666666667">
S ⇒ amount loc.adm.town time.dat.rel amount
amount ⇒ val object
time.date.rel ⇒ name time-modifier
object ⇒ func.coll
func.coll ⇒ kind org.adm
org.adm ⇒ name
</equation>
<bodyText confidence="0.914908666666667">
Using counts of these rules we then compute
maximum likelihood probabilities of the Right
Hand Side (RHS) of the rule given its Left Hand
Side (LHS). Also binarization of rules, applied to
1These rules are actually in Chomsky Normal Form, i.e.
unary or binary rules only. A PCFG, in general, can have any
rule, however, the algorithm we are discussing convert the
PCFG rules into Chomsky Normal Form, thus for simplicity
we provide directly such formulation.
</bodyText>
<figureCaption confidence="0.9982855">
Figure 4: Baseline tree representations used in the PCFG parsing
model
Figure 5: Filler-parent tree representations used in the PCFG pars-
ing model
</figureCaption>
<bodyText confidence="0.995137666666667">
have all rules in the form of 4 and 5, is straight-
forward and can be done with simple algorithms
not discussed here.
</bodyText>
<subsectionHeader confidence="0.9691175">
4.1 Tree Representations for Extended
Named Entities
</subsectionHeader>
<bodyText confidence="0.999867">
As discussed in (Johnson, 1998), an important
point for a parsing algorithm is the representation
of trees being parsed. Changing the tree represen-
tation can change significantly the performances
of the parser. Since there is a large difference be-
tween entity trees used in this work and syntac-
tic trees, from both meaning and structure point
of view, it is worth performing an analysis with
the aim of finding the most suitable representa-
tion for our task. In order to perform this analy-
sis, we start from a named entity annotated on the
words de notre president, M. Nicolas Sarkozy(of
our president, Mr. Nicolas Sarkozy). The corre-
sponding named entity is shown in figure 4. As
decided in the annotation guidelines, fillers can be
part of a named entity. This can happen for com-
plex named entities involving several words. The
representation shown in figure 4 is the default rep-
resentation and will be referred to as baseline. A
problem created by this representation is the fact
that fillers are present also outside entities. Fillers
of named entities should be, in principle, distin-
guished from any other filler, since they may be
informative to discriminate entities.
Following this intuition, we designed two dif-
ferent representations where entity fillers are con-
</bodyText>
<equation confidence="0.851555">
pi—.j,k =
</equation>
<page confidence="0.976689">
177
</page>
<figureCaption confidence="0.998749">
Figure 6: Parent-context tree representations used in the PCFG
parsing model
Figure 7: Parent-node tree representations used in the PCFG pars-
ing model
</figureCaption>
<bodyText confidence="0.999558147058823">
textualized so that to be distinguished from the
other fillers. In the first representation we give to
the filler the same label of the parent node, while
in the second representation we use a concatena-
tion of the filler and the label of the parent node.
These two representations are shown in figure 5
and 6, respectively. The first one will be referred
to as iller-parent, while the second will be re-
ferred as parent-context. A problem that may be
introduced by the first representation is that some
entities that originally were used only for non-
terminal entities will appear also as components,
i.e. entities annotated on words. This may intro-
duce some ambiguity.
Another possible contextualization can be to
annotate each node with the label of the parent
node. This representation is shown in figure 7
and will be referred to as parent-node. Intuitively,
this representation is effective since entities an-
notated directly on words provide also the en-
tity of the parent node. However this representa-
tion increases drastically the number of entities,
in particular the number of components, which
in our case are the set of labels to be learned by
the CRF model. For the same reason this repre-
sentation produces more rigid models, since label
sequences vary widely and thus is not likely to
match sequences not seen in the training data.
Finally, another interesting tree representation
is a variation of the parent-node tree, where en-
tity fillers are only distinguished from fillers not
in an entity, using the label ne-iller, but they are
not contextualized with entity information. This
representation is shown in figure 8 and it will be
</bodyText>
<figureCaption confidence="0.969556">
Figure 8: Parent-node-filler tree representations used in the PCFG
parsing model
</figureCaption>
<bodyText confidence="0.999923181818182">
referred to as parent-node-iller. This representa-
tion is a good trade-off between contextual infor-
mation and rigidity, by still representing entities
as concatenation of labels, while using a common
special label for entity fillers. This allows to keep
lower the number of entities annotated on words,
i.e. components.
Using different tree representations affects both
the structure and the performance of the parsing
model. The structure is described in the next sec-
tion, the performance in the evaluation section.
</bodyText>
<subsectionHeader confidence="0.99877">
4.2 Structure of the Model
</subsectionHeader>
<bodyText confidence="0.999853333333333">
Lexicalized models for syntactic parsing de-
scribed in (Charniak, 2000; Charniak et al., 1998)
and (Collins, 1997), integrate more information
than what is used in equations 4 and 5. Consider-
ing a particular node in the entity tree, not includ-
ing terminals, the information used is:
</bodyText>
<listItem confidence="0.999938833333333">
• s: the head word of the node, i.e. the most
important word of the chunk covered by the
current node
• h: the head word of the parent node
• t: the entity tag of the current node
• l: the entity tag of the parent node
</listItem>
<bodyText confidence="0.999996363636364">
The head word of the parent node is defined
percolating head words from children nodes to
parent nodes, giving the priority to verbs. They
can be found using automatic approaches based
on words and entity tag co-occurrence or mutual
information. Using this information, the model
described in (Charniak et al., 1998) is P(s|h, t, l).
This model being conditioned on several pieces
of information, it can be affected by data sparsity
problems. Thus, the model is actually approxi-
mated as an interpolation of probabilities:
</bodyText>
<equation confidence="0.999880333333333">
P(s|h, t, l) =
λ,P(s|h, t, l) + λ2P(s|ch, t, l)+
λsP(s|t, l) + λ4P(s|t) (6)
</equation>
<page confidence="0.965036">
178
</page>
<bodyText confidence="0.998616885714286">
where AZ, i = 1, ..., 4, are parameters of the
model to be tuned, and ch is the cluster of head
words for a given entity tag t. With such model,
when not all pieces of information are available to
estimate reliably the probability with more con-
ditioning, the model can still provide a proba-
bility with terms conditioned with less informa-
tion. The use of head words and their percola-
tion over the tree is called lexicalization. The
goal of tree lexicalization is to add lexical infor-
mation all over the tree. This way the probabil-
ity of all rules can be conditioned also on lexi-
cal information, allowing to define the probabili-
ties P(s|h, t, l) and P(s|ch, t, l). Tree lexicaliza-
tion reflects the characteristics of syntactic pars-
ing, for which the models described in (Charniak,
2000; Charniak et al., 1998) and (Collins, 1997)
were defined. Head words are very informative
since they constitute keywords instantiating la-
bels, regardless if they are syntactic constituents
or named entities. However, for named entity
recognition it doesn’t make sense to give prior-
ity to verbs when percolating head words over the
tree, even more because head words of named en-
tities are most of the time nouns. Moreover, it
doesn’t make sense to give priority to the head
word of a particular entity with respect to the oth-
ers, all entities in a sentence have the same im-
portance. Intuitively, lexicalization of entity trees
is not straightforward as lexicalization of syntac-
tic trees. At the same time, using not lexicalized
trees doesn’t make sense with models like 6, since
all the terms involve lexical information. Instead,
we can use the model of (Johnson, 1998), which
define the probability of a tree T as:
</bodyText>
<equation confidence="0.983957">
P(r) = � P(X —, α)CT (X-α) (7)
X-.α
</equation>
<bodyText confidence="0.999646428571428">
here the RHS of rules has been generalized with
α, representing RHS of both unary and binary
rules 4 and 5. Cr(X —* α) is the number of times
the rule X —* α appears in the tree T. The model
7 is instantiated when using tree representations
shown in Fig. 4, 5 and 6. When using representa-
tions given in Fig. 7 and 8, the model is:
</bodyText>
<equation confidence="0.996002">
P(r|l) (8)
</equation>
<bodyText confidence="0.999949821428571">
where l is the entity label of the parent node.
Although non-lexicalized models like 7 and 8
have shown less effective for syntactic parsing
than their lexicalized couter-parts, there are evi-
dences showing that they can be effective in our
task. With reference to figure 4, considering the
entity pers.ind instantiated by Nicolas Sarkozy,
our algorithm detects first name.first for Nicolas
and name.last for Sarkozy using the CRF model.
As mentioned earlier, once the CRF model has de-
tected components, since entity trees have not a
complex structure with respect to syntactic trees,
even a simple model like the one in equation 7
or 8 is effective for entity tree parsing. For ex-
ample, once name.first and name.last have been
detected by CRF, pers.ind is the only entity hav-
ing name.first and name.last as children. Am-
biguities, like for example for kind or qualifier,
which can appear in many entities, can affect the
model 7, but they are overcome by the model 8,
taking the entity tag of the parent node into ac-
count. Moreover, the use of CRF allows to in-
clude in the model much more features than the
lexicalized model in equation 6. Using features
like word prefixes (P), suffixes (S), capitalization
(C), morpho-syntactic features (MS) and other
features indicated as F2, the CRF model encodes
the conditional probability:
</bodyText>
<equation confidence="0.723428">
P(t|w, P, S, C, MS, F) (9)
</equation>
<bodyText confidence="0.999969142857143">
where w is an input word and t is the corre-
sponding component.
The probability of the CRF model, used in the
first step to tag input words with components,
is combined with the probability of the PCFG
model, used to parse entity trees starting from
components. Thus the structure of our model is:
</bodyText>
<equation confidence="0.995873">
P(t|w, P, S, C, MS, F) · P(r) (10)
or
P(t|w, P, S, C, MS, F) · P(r|l) (11)
</equation>
<bodyText confidence="0.9981206">
depending if we are using the tree representa-
tion given in figure 4, 5 and 6 or in figure 7 and 8,
respectively. A scale factor could be used to com-
bine the two scores, but this is optional as CRFs
can provide normalized posterior probabilities.
</bodyText>
<footnote confidence="0.873231">
2The set of features used in the CRF model will be de-
scribed in more details in the evaluation section.
</footnote>
<page confidence="0.998824">
179
</page>
<sectionHeader confidence="0.999934" genericHeader="method">
5 Related Work
</sectionHeader>
<bodyText confidence="0.999987181818182">
While the models used for named entity detection
and the set of named entities defined along the
years have been discussed in the introduction and
in section 2, since CRFs and models for parsing
constitute the main issue in our work, we discuss
some important models here.
Beyond the models for parsing discussed in
section 4, together with motivations for using or
not in our work, another important model for syn-
tactic parsing has been proposed in (Ratnaparkhi,
1999). Such model is made of four Maximum
Entropy models used in cascade for parsing at
different stages. Also this model makes use of
head words, like those described in section 4, thus
the same considerations hold, moreover it seems
quite complex for real applications, as it involves
the use of four different models together. The
models described in (Johnson, 1998), (Charniak,
1997; Caraballo and Charniak, 1997), (Charniak
et al., 1998), (Charniak, 2000), (Collins, 1997)
and (Ratnaparkhi, 1999), constitute the main in-
dividual models proposed for constituent-based
syntactic parsing. Later other approaches based
on models combination have been proposed, like
e.g. the reranking approach described in (Collins
and Koo, 2005), among many, and also evolutions
or improvements of these models.
More recently, approaches based on log-linear
models have been proposed (Clark and Curran,
2007; Finkel et al., 2008) for parsing, called also
“Tree CRF&apos;, using also different training criteria
(Auli and Lopez, 2011). Using such models in our
work has basically two problems: one related to
scaling issues, since our data present a large num-
ber of labels, which makes CRF training problem-
atic, even more when using “Tree CRF&apos;; another
problem is related to the difference between syn-
tactic parsing and named entity detection tasks,
as mentioned in sub-section 4.2. Adapting “Tree
CRF&apos; to our task is thus a quite complex work, it
constitutes an entire work by itself, we leave it as
feature work.
Concerning linear-chain CRF models, the
one we use is a state-of-the-art implementation
(Lavergne et al., 2010), as it implements the
most effective optimization algorithms as well as
state-of-the-art regularizers (see sub-section 3.1).
Some improvement of linear-chain CRF have
been proposed, trying to integrate higher order
target-side features (Tang et al., 2006). An inte-
gration of the same kind of features has been tried
also in the model used in this work, without giv-
ing significant improvements, but making model
training much harder. Thus, this direction has not
been further investigated.
</bodyText>
<sectionHeader confidence="0.99891" genericHeader="evaluation">
6 Evaluation
</sectionHeader>
<bodyText confidence="0.9998504">
In this section we describe experiments performed
to evaluate our models. We first describe the set-
tings used for the two models involved in the en-
tity tree parsing, and then describe and comment
the results obtained on the test corpus.
</bodyText>
<subsectionHeader confidence="0.992297">
6.1 Settings
</subsectionHeader>
<bodyText confidence="0.999987444444444">
The CRF implementation used in this work is de-
scribed in (Lavergne et al., 2010), named wapiti.3
We didn’t optimize parameters p1 and p2 of the
elastic net (see section 3.1), although this im-
proves significantly the performances and leads
to more compact models, default values lead in
most cases to very accurate models. We used a
wide set of features in CRF models, in a window
of [−2, +2] around the target word:
</bodyText>
<listItem confidence="0.9790628">
• A set of standard features like word prefixes
and suffixes of length from 1 to 6, plus some
Yes/No features like Does the word start with
capital letter?, etc.
• Morpho-syntactic features extracted from
the output of the tool tagger (Allauzen and
Bonneau-Maynard, 2008)
• Features extracted from the output of the se-
mantic analyzer (Rosset et al., (2009)) pro-
vided by the tool WMatch (Galibert, 2009).
</listItem>
<bodyText confidence="0.999670636363636">
This analysis morpho-syntactic information as
well as semantic information at the same level
of named entities. Using two different sets of
morpho-syntactic features results in more effec-
tive models, as they create a kind of agreement
for a given word in case of match. Concerning
the PCFG model, grammars, tree binarization and
the different tree representations are created with
our own scripts, while entity tree parsing is per-
formed with the chart parsing algorithm described
in (Johnson, 1998).4
</bodyText>
<footnote confidence="0.979622333333333">
3available at http://wapiti.limsi.fr
4available at http://web.science.mq.edu.au/
˜mjohnson/Software.htm
</footnote>
<page confidence="0.976834">
180
</page>
<table confidence="0.999424">
CRF PCFG
Model # features # labels # rules
baseline 3,041,797 55 29,611
filler-parent 3,637,990 112 29,611
parent-context 3,605,019 120 29,611
parent-node 3,718,089 441 31,110
parent-node-filler 3,723,964 378 31,110
</table>
<tableCaption confidence="0.996075">
Table 3: Statistics showing the characteristics of the different
models used in this work
</tableCaption>
<subsectionHeader confidence="0.999043">
6.2 Evaluation Metrics
</subsectionHeader>
<bodyText confidence="0.999993">
All results are expressed in terms of Slot Error
Rate (SER) (Makhoul et al., 1999) which has a
similar definition of word error rate for ASR sys-
tems, with the difference that substitution errors
are split in three types: i) correct entity type with
wrong segmentation; ii) wrong entity type with
correct segmentation; iii) wrong entity type with
wrong segmentation; here, i) and ii) are given half
points, while iii), as well as insertion and deletion
errors, are given full points. Moreover, results are
given using the well known F1 measure, defined
as a function of precision and recall.
</bodyText>
<subsectionHeader confidence="0.896364">
6.3 Results
</subsectionHeader>
<bodyText confidence="0.9997605">
In this section we provide evaluations of the mod-
els described in this work, based on combination
of CRF and PCFG and using different tree repre-
sentations of named entity trees.
</bodyText>
<subsectionHeader confidence="0.979967">
6.3.1 Model Statistics
</subsectionHeader>
<bodyText confidence="0.999929523809524">
As a first evaluation, we describe some statis-
tics computed from the CRF and PCFG models
using the tree representations. Such statistics pro-
vide interesting clues of how difficult is learning
the task and which performance we can expect
from the model. Statistics for this evaluation are
presented in table 3. Rows corresponds to the dif-
ferent tree representations described in this work,
while in the columns we show the number of fea-
tures and labels for the CRF models (# features
and # labels), and the number of rules for PCFG
models (# rules).
As we can see from the table, the number
of rules is the same for the tree representations
baseline, filler-parent and parent-context, and
for the representations parent-node and parent-
node-filler. This is the consequence of the con-
textualization applied by the latter representa-
tions, i.e. parent-node and parent-node-filler
create several different labels depending from
the context, thus the corresponding grammar
</bodyText>
<table confidence="0.997691142857143">
DEV TEST
Model SER F1 SER F1
baseline 20.0% 73.4% 14.2% 79.4%
filler-parent 16.2% 77.8% 12.5% 81.2%
parent-context 15.2% 78.6% 11.9% 81.4%
parent-node 6.6% 96.7% 5.9% 96.7%
parent-node-filler 6.8% 95.9% 5.7% 96.8%
</table>
<tableCaption confidence="0.9274925">
Table 4: Results computed from oracle predictions obtained with
the different models presented in this work
</tableCaption>
<table confidence="0.999935571428571">
DEV TEST
Model SER F1 SER F1
baseline 33.5% 72.5% 33.4% 72.8%
filler-parent 31.3% 74.4% 33.4% 72.7%
parent-context 30.9% 74.6% 33.3% 72.8%
parent-node 31.2% 77.8% 31.4% 79.5%
parent-node-filler 28.7% 78.9% 30.2% 80.3%
</table>
<tableCaption confidence="0.9660675">
Table 5: Results obtained with our combined algorithm based on
CRF and PCFG
</tableCaption>
<bodyText confidence="0.999861727272727">
will have more rules. For example, the rule
pers.ind ==&gt;. name.first name.last can
appear as it is or contextualized with func.ind,
like in figure 8. In contrast the other tree repre-
sentations modify only fillers, thus the number of
rules is not affected.
Concerning CRF models, as shown in table 3,
the use of the different tree representations results
in an increasing number of labels to be learned by
CRF. This aspect is quite critical in CRF learn-
ing, as training time is exponential in the number
of labels. Indeed, the most complex models, ob-
tained with parent-node and parent-node-filler
tree representations, took roughly 8 days for train-
ing. Additionally, increasing the number of labels
can create data sparseness problems, however this
problem doesn’t seem to arise in our case since,
apart the baseline model which has quite less fea-
tures, all the others have approximately the same
number of features, meaning that there are actu-
ally enough data to learn the models, regardless
the number of labels.
</bodyText>
<subsectionHeader confidence="0.994441">
6.3.2 Evaluations of Tree Representations
</subsectionHeader>
<bodyText confidence="0.999318272727273">
In this section we evaluate the models in terms
of the evaluation metrics described in previous
section, Slot Error Rate (SER) and F1 measure.
In order to evaluate PCFG models alone, we
performed entity tree parsing using as input ref-
erence transcriptions, i.e. manual transcriptions
and reference component annotations taken from
development and test sets. This can be consid-
ered a kind of oracle evaluations and provides us
an upper bound of the performance of the PCFG
models. Results for this evaluation are reported in
</bodyText>
<page confidence="0.991965">
181
</page>
<table confidence="0.998546666666667">
Participant SER
P1 48.9
P2 41.0
parent-context 33.3
parent-node 31.4
parent-node-filler 30.2
</table>
<tableCaption confidence="0.9552205">
Table 6: Results obtained with our combined algorithm based on
CRF and PCFG
</tableCaption>
<bodyText confidence="0.99641141025641">
table 4. As it can be intuitively expected, adding
more contextualization in the trees results in more
accurate models, the simplest model, baseline,
has the worst oracle performance, filler-parent
and parent-context models, adding similar con-
textualization information, have very similar ora-
cle performances. Same line of reasoning applies
to models parent-node and parent-node-filler,
which also add similar contextualization and have
very similar oracle predictions. These last two
models have also the best absolute oracle perfor-
mances. However, adding more contextualization
in the trees results also in more rigid models, the
fact that models are robust on reference transcrip-
tions and based on reference component annota-
tions, doesn’t imply a proportional robustness on
component sequences generated by CRF models.
This intuition is confirmed from results re-
ported in table 5, where a real evaluation of our
models is reported, using this time CRF out-
put components as input to PCFG models, to
parse entity trees. The results reported in ta-
ble 5 show in particular that models using base-
line, filler-parent and parent-context tree repre-
sentations have similar performances, especially
on test set. Models characterized by parent-node
and parent-node-filler tree representations have
indeed the best performances, although the gain
with respect to the other models is not as much
as it could be expected given the difference in
the oracle performances discussed above. In par-
ticular the best absolute performance is obtained
with the model parent-node-filler. As we men-
tioned in subsection 4.1, this model represents the
best trade-off between rigidity and accuracy using
the same label for all entity fillers, but still distin-
guishing between fillers found in entity structures
and other fillers found in words not instantiating
any entity.
</bodyText>
<subsectionHeader confidence="0.910424">
6.3.3 Comparison with Official Results
</subsectionHeader>
<bodyText confidence="0.999986380952381">
As a final evaluation of our models, we pro-
vide a comparison of official results obtained at
the 2011 evaluation campaign of extended named
entity recognition (Galibert et al., 2011; 2) Re-
sults are reported in table 6, where the other two
participants to the campaign are indicated as P1
and P2. These two participants P1 and P2, used
a system based on CRF, and rules for deep syn-
tactic analysis, respectively. In particular, P2 ob-
tained superior performances in previous evalua-
tion campaign on named entity recognition. The
system we proposed at the evaluation campaign
used a parent-context tree representation. The
results obtained at the evaluation campaign are
in the first three lines of Table 6. We compare
such results with those obtained with the parent-
node and parent-node-filler tree representations,
reported in the last two rows of the same table. As
we can see, the new tree representations described
in this work allow to achieve the best absolute per-
formances.
</bodyText>
<sectionHeader confidence="0.999658" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.999649391304348">
In this paper we have presented a Named Entity
Recognition system dealing with extended named
entities with a tree structure. Given such represen-
tation of named entities, the task cannot be mod-
eled as a sequence labelling approach. We thus
proposed a two-steps system based on CRF and
PCFG. CRF annotate entity components directly
on words, while PCFG apply parsing techniques
to predict the whole entity tree. We motivated
our choice by showing that it is not effective to
apply techniques used widely for syntactic pars-
ing, like for example tree lexicalization. We pre-
sented an analysis of different tree representations
for PCFG, which affect significantly parsing per-
formances.
We provided and discussed a detailed evalua-
tion of all the models obtained by combining CRF
and PCFG with the different tree representation
proposed. Our combined models result in better
performances with respect to other models pro-
posed at the official evaluation campaign, as well
as our previous model used also at the evaluation
campaign.
</bodyText>
<sectionHeader confidence="0.998812" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.996993666666667">
This work has been funded by the project Quaero,
under the program Oseo, French State agency for
innovation.
</bodyText>
<page confidence="0.996544">
182
</page>
<sectionHeader confidence="0.996189" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999680044642857">
Ralph Grishman and Beth Sundheim. 1996. Mes-
sage Understanding Conference-6: a brief history.
In Proceedings of the 16th conference on Com-
putational linguistics - Volume 1, pages 466–471,
Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.
Satoshi Sekine and Chikashi Nobata. 2004. Defini-
tion, Dictionaries and Tagger for Extended Named
Entity Hierarchy. In Proceedings of LREC.
G. Doddington, A. Mitchell, M. Przybocki,
L. Ramshaw, S. Strassel, and R. Weischedel.
2004. The Automatic Content Extraction (ACE)
Program–Tasks, Data, and Evaluation. Proceedings
of LREC 2004, pages 837–840.
Cyril Grouin, Sophie Rosset, Pierre Zweigenbaum,
Karn Fort, Olivier Galibert, Ludovic Quintard.
2011. Proposal for an extension or traditional
named entities: From guidelines to evaluation, an
overview. In Proceedings of the Linguistic Annota-
tion Workshop (LAW).
J. Lafferty, A. McCallum, and F. Pereira. 2001. Con-
ditional random fields: Probabilistic models for
segmenting and labeling sequence data. In Pro-
ceedings of the Eighteenth International Confer-
ence on Machine Learning (ICML), pages 282–289,
Williamstown, MA, USA, June.
Mark Johnson. 1998. Pcfg models of linguistic
tree representations. Computational Linguistics,
24:613–632.
Stefan Hahn, Marco Dinarelli, Christian Raymond,
Fabrice Lef`evre, Patrick Lehen, Renato De Mori,
Alessandro Moschitti, Hermann Ney, and Giuseppe
Riccardi. 2010. Comparing stochastic approaches
to spoken language understanding in multiple lan-
guages. IEEE Transactions on Audio, Speech and
Language Processing (TASLP), 99.
Adam L. Berger, Stephen A. Della Pietra, and Vin-
cent J. Della Pietra. 1996. A maximum entropy
approach to natural language processing. COMPU-
TATIONAL LINGUISTICS, 22:39–71.
Thomas Lavergne, Olivier Capp´e, and Franc¸ois Yvon.
2010. Practical very large scale CRFs. In Proceed-
ings the 48th Annual Meeting of the Association for
Computational Linguistics (ACL), pages 504–513.
Association for Computational Linguistics, July.
Stefan Riezler and Alexander Vasserman. 2004. In-
cremental feature selection and l1 regularization
for relaxed maximum-entropy modeling. In Pro-
ceedings of the International Conference on Em-
pirical Methods for Natural Language Processing
(EMNLP).
Hui Zou and Trevor Hastie. 2005. Regularization and
variable selection via the Elastic Net. Journal of the
Royal Statistical Society B, 67:301–320.
Eugene Charniak. 1997. Statistical parsing with
a context-free grammar and word statistics. In
Proceedings of the fourteenth national conference
on artificial intelligence and ninth conference on
Innovative applications of artificial intelligence,
AAAI’97/IAAI’97, pages 598–603. AAAI Press.
Eugene Charniak. 2000. A maximum-entropy-
inspired parser. In Proceedings of the 1st North
American chapter of the Association for Computa-
tional Linguistics conference, pages 132–139, San
Francisco, CA, USA. Morgan Kaufmann Publish-
ers Inc.
Sharon A. Caraballo and Eugene Charniak. 1997.
New figures of merit for best-first probabilistic chart
parsing. Computational Linguistics, 24:275–298.
Michael Collins. 1997. Three generative, lexicalised
models for statistical parsing. In Proceedings of the
35th Annual Meeting of the Association for Com-
putational Linguistics and Eighth Conference of the
European Chapter of the Association for Computa-
tional Linguistics, ACL ’98, pages 16–23, Strouds-
burg, PA, USA. Association for Computational Lin-
guistics.
Eugene Charniak, Sharon Goldwater, and Mark John-
son. 1998. Edge-based best-first chart parsing. In
In Proceedings of the Sixth Workshop on Very Large
Corpora, pages 127–133. Morgan Kaufmann.
Alexandre Allauzen and H´el´ene Bonneau-Maynard.
2008. Training and evaluation of pos taggers on the
french multitag corpus. In Proceedings of the Sixth
International Language Resources and Evaluation
(LREC’08), Marrakech, Morocco, may.
Olivier Galibert. 2009. Approches et m´ethodologies
pour la r´eponse automatique a` des questions
adapt´ees a` un cadre interactif en domaine ouvert.
Ph.D. thesis, Universit´e Paris Sud, Orsay.
Rosset Sophie, Galibert Olivier, Bernard Guillaume,
Bilinski Eric, and Adda Gilles. The LIMSI mul-
tilingual, multitask QAst system. In Proceed-
ings of the 9th Cross-language evaluation forum
conference on Evaluating systems for multilin-
gual and multimodal information access, CLEF’08,
pages 480–487, Berlin, Heidelberg, 2009. Springer-
Verlag.
Azeddine Zidouni, Sophie Rosset, and Herv´e Glotin.
2010. Efficient combined approach for named en-
tity recognition in spoken language. In Proceedings
of the International Conference of the Speech Com-
munication Assosiation (Interspeech), Makuhari,
Japan
John Makhoul, Francis Kubala, Richard Schwartz,
and Ralph Weischedel. 1999. Performance mea-
sures for information extraction. In Proceedings of
DARPA Broadcast News Workshop, pages 249–252.
Adwait Ratnaparkhi. 1999. Learning to Parse Natural
Language with Maximum Entropy Models. Journal
of Machine Learning, vol. 34, issue 1-3, pages 151–
175.
</reference>
<page confidence="0.990009">
183
</page>
<reference confidence="0.999805">
Michael Collins and Terry Koo. 2005. Discriminative
Re-ranking for Natural Language Parsing. Journal
of Machine Learning, vol. 31, issue 1, pages 25–70.
Clark, Stephen and Curran, James R. 2007. Wide-
Coverage Efficient Statistical Parsing with CCG and
Log-Linear Models. Journal of Computational Lin-
guistics, vol. 33, issue 4, pages 493–552.
Finkel, Jenny R. and Kleeman, Alex and Manning,
Christopher D. 2008. Efficient, Feature-based,
Conditional Random Field Parsing. Proceedings
of the Association for Computational Linguistics,
pages 959–967, Columbus, Ohio.
Michael Auli and Adam Lopez 2011. Training a Log-
Linear Parser with Loss Functions via Softmax-
Margin. Proceedings of Empirical Methods for
Natural Language Processing, pages 333–343, Ed-
inburgh, U.K.
Tang, Jie and Hong, MingCai and Li, Juan-Zi and
Liang, Bangyong. 2006. Tree-Structured Con-
ditional Random Fields for Semantic Annotation.
Proceedgins of the International Semantic Web
Conference, pages 640–653, Edited by Springer.
Olivier Galibert; Sophie Rosset; Cyril Grouin; Pierre
Zweigenbaum; Ludovic Quintard. 2011. Struc-
tured and Extended Named Entity Evaluation in Au-
tomatic Speech Transcriptions. IJCNLP 2011.
Marco Dinarelli, Sophie Rosset. Models Cascade for
Tree-Structured Named Entity Detection IJCNLP
2011.
</reference>
<page confidence="0.998698">
184
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.772931">
<title confidence="0.9996265">Tree Representations in Probabilistic Models for Extended Entities Detection</title>
<author confidence="0.999497">Marco Dinarelli Sophie Rosset</author>
<affiliation confidence="0.998576">LIMSI-CNRS LIMSI-CNRS</affiliation>
<address confidence="0.88644">Orsay, France Orsay, France</address>
<email confidence="0.963176">marcod@limsi.frrosset@limsi.fr</email>
<abstract confidence="0.994554388888889">In this paper we deal with Named Entity Recognition (NER) on transcriptions of French broadcast data. Two aspects make the task more difficult with respect to previous NER tasks: i) named entities annotated used in this work have a tree structure, thus the task cannot be tackled as a sequence labelling task; ii) the data used are more noisy than data used for previous NER tasks. We approach the task in two steps, involving Conditional Random Fields and Probabilistic Context-Free Grammars, integrated in a single parsing algorithm. We analyse the effect of using several tree representations. Our system outperforms the best system of the evaluation campaign by a significant margin.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Ralph Grishman</author>
<author>Beth Sundheim</author>
</authors>
<title>Message Understanding Conference-6: a brief history.</title>
<date>1996</date>
<booktitle>In Proceedings of the 16th conference on Computational linguistics -</booktitle>
<volume>1</volume>
<pages>466--471</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="1224" citStr="Grishman and Sundheim, 1996" startWordPosition="187" endWordPosition="191">h the task in two steps, involving Conditional Random Fields and Probabilistic Context-Free Grammars, integrated in a single parsing algorithm. We analyse the effect of using several tree representations. Our system outperforms the best system of the evaluation campaign by a significant margin. 1 Introduction Named Entity Recognition is a traditinal task of the Natural Language Processing domain. The task aims at mapping words in a text into semantic classes, such like persons, organizations or localizations. While at first the NER task was quite simple, involving a limited number of classes (Grishman and Sundheim, 1996), along the years the task complexity increased as more complex class taxonomies were defined (Sekine and Nobata, 2004). The interest in the task is related to its use in complex frameworks for (semantic) content extraction, such like Relation Extraction applications (Doddington et al., 2004). This work presents research on a Named Entity Recognition task defined with a new set of named entities. The characteristic of such set is in that named entities have a tree structure. As concequence the task cannot be tackled as a sequence labelling approach. Additionally, the use of noisy data like tra</context>
</contexts>
<marker>Grishman, Sundheim, 1996</marker>
<rawString>Ralph Grishman and Beth Sundheim. 1996. Message Understanding Conference-6: a brief history. In Proceedings of the 16th conference on Computational linguistics - Volume 1, pages 466–471, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Satoshi Sekine</author>
<author>Chikashi Nobata</author>
</authors>
<title>Definition, Dictionaries and Tagger for Extended Named Entity Hierarchy.</title>
<date>2004</date>
<booktitle>In Proceedings of LREC.</booktitle>
<contexts>
<context position="1343" citStr="Sekine and Nobata, 2004" startWordPosition="206" endWordPosition="210">e parsing algorithm. We analyse the effect of using several tree representations. Our system outperforms the best system of the evaluation campaign by a significant margin. 1 Introduction Named Entity Recognition is a traditinal task of the Natural Language Processing domain. The task aims at mapping words in a text into semantic classes, such like persons, organizations or localizations. While at first the NER task was quite simple, involving a limited number of classes (Grishman and Sundheim, 1996), along the years the task complexity increased as more complex class taxonomies were defined (Sekine and Nobata, 2004). The interest in the task is related to its use in complex frameworks for (semantic) content extraction, such like Relation Extraction applications (Doddington et al., 2004). This work presents research on a Named Entity Recognition task defined with a new set of named entities. The characteristic of such set is in that named entities have a tree structure. As concequence the task cannot be tackled as a sequence labelling approach. Additionally, the use of noisy data like transcriptions of French broadcast data, makes the task very challenging for traditional NLP solutions. To deal with such </context>
</contexts>
<marker>Sekine, Nobata, 2004</marker>
<rawString>Satoshi Sekine and Chikashi Nobata. 2004. Definition, Dictionaries and Tagger for Extended Named Entity Hierarchy. In Proceedings of LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Doddington</author>
<author>A Mitchell</author>
<author>M Przybocki</author>
<author>L Ramshaw</author>
<author>S Strassel</author>
<author>R Weischedel</author>
</authors>
<title>The Automatic Content Extraction (ACE) Program–Tasks, Data, and Evaluation.</title>
<date>2004</date>
<booktitle>Proceedings of LREC</booktitle>
<pages>837--840</pages>
<contexts>
<context position="1517" citStr="Doddington et al., 2004" startWordPosition="235" endWordPosition="238"> Introduction Named Entity Recognition is a traditinal task of the Natural Language Processing domain. The task aims at mapping words in a text into semantic classes, such like persons, organizations or localizations. While at first the NER task was quite simple, involving a limited number of classes (Grishman and Sundheim, 1996), along the years the task complexity increased as more complex class taxonomies were defined (Sekine and Nobata, 2004). The interest in the task is related to its use in complex frameworks for (semantic) content extraction, such like Relation Extraction applications (Doddington et al., 2004). This work presents research on a Named Entity Recognition task defined with a new set of named entities. The characteristic of such set is in that named entities have a tree structure. As concequence the task cannot be tackled as a sequence labelling approach. Additionally, the use of noisy data like transcriptions of French broadcast data, makes the task very challenging for traditional NLP solutions. To deal with such problems, we adopt a two-steps approach, the first being realized with Conditional Random Fields (CRF) (Lafferty et al., 2001), the second with a Probabilistic Context-Free G</context>
</contexts>
<marker>Doddington, Mitchell, Przybocki, Ramshaw, Strassel, Weischedel, 2004</marker>
<rawString>G. Doddington, A. Mitchell, M. Przybocki, L. Ramshaw, S. Strassel, and R. Weischedel. 2004. The Automatic Content Extraction (ACE) Program–Tasks, Data, and Evaluation. Proceedings of LREC 2004, pages 837–840.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cyril Grouin</author>
<author>Sophie Rosset</author>
<author>Pierre Zweigenbaum</author>
<author>Karn Fort</author>
<author>Olivier Galibert</author>
<author>Ludovic Quintard</author>
</authors>
<title>Proposal for an extension or traditional named entities: From guidelines to evaluation, an overview.</title>
<date>2011</date>
<booktitle>In Proceedings of the Linguistic Annotation Workshop</booktitle>
<publisher>(LAW).</publisher>
<marker>Grouin, Rosset, Zweigenbaum, Fort, Galibert, Quintard, 2011</marker>
<rawString>Cyril Grouin, Sophie Rosset, Pierre Zweigenbaum, Karn Fort, Olivier Galibert, Ludovic Quintard. 2011. Proposal for an extension or traditional named entities: From guidelines to evaluation, an overview. In Proceedings of the Linguistic Annotation Workshop (LAW).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lafferty</author>
<author>A McCallum</author>
<author>F Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<booktitle>In Proceedings of the Eighteenth International Conference on Machine Learning (ICML),</booktitle>
<pages>282--289</pages>
<location>Williamstown, MA, USA,</location>
<contexts>
<context position="2069" citStr="Lafferty et al., 2001" startWordPosition="325" endWordPosition="329">, such like Relation Extraction applications (Doddington et al., 2004). This work presents research on a Named Entity Recognition task defined with a new set of named entities. The characteristic of such set is in that named entities have a tree structure. As concequence the task cannot be tackled as a sequence labelling approach. Additionally, the use of noisy data like transcriptions of French broadcast data, makes the task very challenging for traditional NLP solutions. To deal with such problems, we adopt a two-steps approach, the first being realized with Conditional Random Fields (CRF) (Lafferty et al., 2001), the second with a Probabilistic Context-Free Grammar (PCFG) (Johnson, 1998). The motivations behind that are: • Since the named entities have a tree structure, it is reasonable to use a solution coming from syntactic parsing. However preliminary experiments using such approaches gave poor results. • Despite the tree-structure of the entities, trees are not as complex as syntactic trees, thus, before designing an ad-hoc solution for the task, which require a remarkable effort and yet it doesn’t guarantee better performances, we designed a solution providing good results and which required a l</context>
<context position="7843" citStr="Lafferty et al., 2001" startWordPosition="1291" endWordPosition="1294">ascade for Extended Named Entities Since the task of Named Entity Recognition presented here cannot be modeled as sequence labelling and, as mentioned previously, an approach 175 Quaero test BN test BC #sentences 1704 3933 words entities words entities #tokens 32945 2762 69414 2769 # vocabulary – 28 – 28 # components – 4128 – 4017 # components dict. 3.63 21 3.84 20 # OOV rate [%] 0 0 Table 2: Statistics on the test set of the Quaero corpus, divided in Broadcast News (BN) and Broadcast Conversations (BC) 3.1 Conditional Random Fields CRFs are particularly suitable for sequence labelling tasks (Lafferty et al., 2001). Beyond the possibility to include a huge number of features using the same framework as Maximum Entropy models (Berger et al., 1996), CRF models encode global conditional probabilities normalized at sentence level. Given a sequence of N words W1N = w1, ..., wN and its corresponding components sequence EN1 = e1, ..., eN, CRF trains the conditional probabilities P(EN1|W1N) = Figure 3: Processing schema of the two-steps approach proposed 1 N exp M � in this work: CRF plus PCFG Z ri E n+2 λm · hm(en−1, en, wn−2) (1) coming from syntactic parsing to perform named entity annotation in “one-shot” i</context>
<context position="9249" citStr="Lafferty et al., 2001" startWordPosition="1539" endWordPosition="1542">o parse complete entity trees and is based on a relatively simple model. Since we are dealing with noisy data, the hardest part of the task is indeed to annotate components on words. On the other hand, since entity trees are relatively simple, at least much simpler than syntactic trees, once entity components have been annotated in a first step, for the second step, a complex model is not required, which would also make the processing slower. Taking all these issues into account, the two steps of our system for tree-structured named entity recognition are performed as follows: 1. A CRF model (Lafferty et al., 2001) is used to annotate components on words. 2. A PCFG model (Johnson, 1998) is used to parse complete entity trees upon components, i.e. using components annotated by CRF as starting point. This processing schema is depicted in figure 3. Conditional Random Fields are described shortly in the next subsection. PCFG models, constituting the main part of this work together with the analysis over tree representations, is described more in details in the next sections. where λm are the training parameters. hm(en−1, en, wn+2 n−2) are the feature functions capturing dependencies of entities and words. Z</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>J. Lafferty, A. McCallum, and F. Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In Proceedings of the Eighteenth International Conference on Machine Learning (ICML), pages 282–289, Williamstown, MA, USA, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Johnson</author>
</authors>
<title>Pcfg models of linguistic tree representations.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<pages>24--613</pages>
<contexts>
<context position="2146" citStr="Johnson, 1998" startWordPosition="338" endWordPosition="339">sents research on a Named Entity Recognition task defined with a new set of named entities. The characteristic of such set is in that named entities have a tree structure. As concequence the task cannot be tackled as a sequence labelling approach. Additionally, the use of noisy data like transcriptions of French broadcast data, makes the task very challenging for traditional NLP solutions. To deal with such problems, we adopt a two-steps approach, the first being realized with Conditional Random Fields (CRF) (Lafferty et al., 2001), the second with a Probabilistic Context-Free Grammar (PCFG) (Johnson, 1998). The motivations behind that are: • Since the named entities have a tree structure, it is reasonable to use a solution coming from syntactic parsing. However preliminary experiments using such approaches gave poor results. • Despite the tree-structure of the entities, trees are not as complex as syntactic trees, thus, before designing an ad-hoc solution for the task, which require a remarkable effort and yet it doesn’t guarantee better performances, we designed a solution providing good results and which required a limited development effort. • Conditional Random Fields are models robust to n</context>
<context position="9322" citStr="Johnson, 1998" startWordPosition="1554" endWordPosition="1555"> are dealing with noisy data, the hardest part of the task is indeed to annotate components on words. On the other hand, since entity trees are relatively simple, at least much simpler than syntactic trees, once entity components have been annotated in a first step, for the second step, a complex model is not required, which would also make the processing slower. Taking all these issues into account, the two steps of our system for tree-structured named entity recognition are performed as follows: 1. A CRF model (Lafferty et al., 2001) is used to annotate components on words. 2. A PCFG model (Johnson, 1998) is used to parse complete entity trees upon components, i.e. using components annotated by CRF as starting point. This processing schema is depicted in figure 3. Conditional Random Fields are described shortly in the next subsection. PCFG models, constituting the main part of this work together with the analysis over tree representations, is described more in details in the next sections. where λm are the training parameters. hm(en−1, en, wn+2 n−2) are the feature functions capturing dependencies of entities and words. Z is the partition function: H(˜en−1, ˜en, wn+2 n−2) (2) which ensures tha</context>
<context position="10966" citStr="Johnson, 1998" startWordPosition="1835" endWordPosition="1837">e following objective function: −log(P(EN1|W1N))+ρ1kλk1+ ρ2 2 kλk2 (3) 2 IIλII1 and IIλII2 2 are the l1 and l2 regularizers (Riezler and Vasserman, 2004), and together in a linear combination implement the elastic net regularizer (Zou and Hastie, 2005). As mentioned in (Lavergne et al., 2010), this kind of regularizers are very effective for feature selection at training time, which is a very good point when dealing with noisy data and big set of features. N ri n=1 Z =L ˜eN 1 176 4 Models for Parsing Trees The models used in this work for parsing entity trees refer to the models described in (Johnson, 1998), in (Charniak, 1997; Caraballo and Charniak, 1997) and (Charniak et al., 1998), and which constitutes the basis of the maximum entropy model for parsing described in (Charniak, 2000). A similar lexicalized model has been proposed also by Collins (Collins, 1997). All these models are based on a PCFG trained from data and used in a chart parsing algorithm to find the best parse for the given input. The PCFG model of (Johnson, 1998) is made of rules of the form: • XZ ⇒ X3Xk • XZ ⇒ w where X are non-terminal entities and w are terminal symbols (words in our case).1 The probability associated to t</context>
<context position="12995" citStr="Johnson, 1998" startWordPosition="2182" endWordPosition="2183">se rules are actually in Chomsky Normal Form, i.e. unary or binary rules only. A PCFG, in general, can have any rule, however, the algorithm we are discussing convert the PCFG rules into Chomsky Normal Form, thus for simplicity we provide directly such formulation. Figure 4: Baseline tree representations used in the PCFG parsing model Figure 5: Filler-parent tree representations used in the PCFG parsing model have all rules in the form of 4 and 5, is straightforward and can be done with simple algorithms not discussed here. 4.1 Tree Representations for Extended Named Entities As discussed in (Johnson, 1998), an important point for a parsing algorithm is the representation of trees being parsed. Changing the tree representation can change significantly the performances of the parser. Since there is a large difference between entity trees used in this work and syntactic trees, from both meaning and structure point of view, it is worth performing an analysis with the aim of finding the most suitable representation for our task. In order to perform this analysis, we start from a named entity annotated on the words de notre president, M. Nicolas Sarkozy(of our president, Mr. Nicolas Sarkozy). The cor</context>
<context position="19424" citStr="Johnson, 1998" startWordPosition="3262" endWordPosition="3263">t make sense to give priority to verbs when percolating head words over the tree, even more because head words of named entities are most of the time nouns. Moreover, it doesn’t make sense to give priority to the head word of a particular entity with respect to the others, all entities in a sentence have the same importance. Intuitively, lexicalization of entity trees is not straightforward as lexicalization of syntactic trees. At the same time, using not lexicalized trees doesn’t make sense with models like 6, since all the terms involve lexical information. Instead, we can use the model of (Johnson, 1998), which define the probability of a tree T as: P(r) = � P(X —, α)CT (X-α) (7) X-.α here the RHS of rules has been generalized with α, representing RHS of both unary and binary rules 4 and 5. Cr(X —* α) is the number of times the rule X —* α appears in the tree T. The model 7 is instantiated when using tree representations shown in Fig. 4, 5 and 6. When using representations given in Fig. 7 and 8, the model is: P(r|l) (8) where l is the entity label of the parent node. Although non-lexicalized models like 7 and 8 have shown less effective for syntactic parsing than their lexicalized couter-part</context>
<context position="22780" citStr="Johnson, 1998" startWordPosition="3861" endWordPosition="3862">e in our work, we discuss some important models here. Beyond the models for parsing discussed in section 4, together with motivations for using or not in our work, another important model for syntactic parsing has been proposed in (Ratnaparkhi, 1999). Such model is made of four Maximum Entropy models used in cascade for parsing at different stages. Also this model makes use of head words, like those described in section 4, thus the same considerations hold, moreover it seems quite complex for real applications, as it involves the use of four different models together. The models described in (Johnson, 1998), (Charniak, 1997; Caraballo and Charniak, 1997), (Charniak et al., 1998), (Charniak, 2000), (Collins, 1997) and (Ratnaparkhi, 1999), constitute the main individual models proposed for constituent-based syntactic parsing. Later other approaches based on models combination have been proposed, like e.g. the reranking approach described in (Collins and Koo, 2005), among many, and also evolutions or improvements of these models. More recently, approaches based on log-linear models have been proposed (Clark and Curran, 2007; Finkel et al., 2008) for parsing, called also “Tree CRF&apos;, using also diffe</context>
<context position="26088" citStr="Johnson, 1998" startWordPosition="4391" endWordPosition="4392">cted from the output of the semantic analyzer (Rosset et al., (2009)) provided by the tool WMatch (Galibert, 2009). This analysis morpho-syntactic information as well as semantic information at the same level of named entities. Using two different sets of morpho-syntactic features results in more effective models, as they create a kind of agreement for a given word in case of match. Concerning the PCFG model, grammars, tree binarization and the different tree representations are created with our own scripts, while entity tree parsing is performed with the chart parsing algorithm described in (Johnson, 1998).4 3available at http://wapiti.limsi.fr 4available at http://web.science.mq.edu.au/ ˜mjohnson/Software.htm 180 CRF PCFG Model # features # labels # rules baseline 3,041,797 55 29,611 filler-parent 3,637,990 112 29,611 parent-context 3,605,019 120 29,611 parent-node 3,718,089 441 31,110 parent-node-filler 3,723,964 378 31,110 Table 3: Statistics showing the characteristics of the different models used in this work 6.2 Evaluation Metrics All results are expressed in terms of Slot Error Rate (SER) (Makhoul et al., 1999) which has a similar definition of word error rate for ASR systems, with the d</context>
</contexts>
<marker>Johnson, 1998</marker>
<rawString>Mark Johnson. 1998. Pcfg models of linguistic tree representations. Computational Linguistics, 24:613–632.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Hahn</author>
<author>Marco Dinarelli</author>
<author>Christian Raymond</author>
<author>Fabrice Lef`evre</author>
<author>Patrick Lehen</author>
<author>Renato De Mori</author>
<author>Alessandro Moschitti</author>
<author>Hermann Ney</author>
<author>Giuseppe Riccardi</author>
</authors>
<title>Comparing stochastic approaches to spoken language understanding in multiple languages.</title>
<date>2010</date>
<journal>IEEE Transactions on Audio, Speech and Language Processing (TASLP),</journal>
<volume>99</volume>
<marker>Hahn, Dinarelli, Raymond, Lef`evre, Lehen, De Mori, Moschitti, Ney, Riccardi, 2010</marker>
<rawString>Stefan Hahn, Marco Dinarelli, Christian Raymond, Fabrice Lef`evre, Patrick Lehen, Renato De Mori, Alessandro Moschitti, Hermann Ney, and Giuseppe Riccardi. 2010. Comparing stochastic approaches to spoken language understanding in multiple languages. IEEE Transactions on Audio, Speech and Language Processing (TASLP), 99.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam L Berger</author>
<author>Stephen A Della Pietra</author>
<author>Vincent J Della Pietra</author>
</authors>
<title>A maximum entropy approach to natural language processing.</title>
<date>1996</date>
<booktitle>COMPUTATIONAL LINGUISTICS,</booktitle>
<pages>22--39</pages>
<contexts>
<context position="7977" citStr="Berger et al., 1996" startWordPosition="1313" endWordPosition="1316">, as mentioned previously, an approach 175 Quaero test BN test BC #sentences 1704 3933 words entities words entities #tokens 32945 2762 69414 2769 # vocabulary – 28 – 28 # components – 4128 – 4017 # components dict. 3.63 21 3.84 20 # OOV rate [%] 0 0 Table 2: Statistics on the test set of the Quaero corpus, divided in Broadcast News (BN) and Broadcast Conversations (BC) 3.1 Conditional Random Fields CRFs are particularly suitable for sequence labelling tasks (Lafferty et al., 2001). Beyond the possibility to include a huge number of features using the same framework as Maximum Entropy models (Berger et al., 1996), CRF models encode global conditional probabilities normalized at sentence level. Given a sequence of N words W1N = w1, ..., wN and its corresponding components sequence EN1 = e1, ..., eN, CRF trains the conditional probabilities P(EN1|W1N) = Figure 3: Processing schema of the two-steps approach proposed 1 N exp M � in this work: CRF plus PCFG Z ri E n+2 λm · hm(en−1, en, wn−2) (1) coming from syntactic parsing to perform named entity annotation in “one-shot” is not robust on the data used in this work, we adopt a two-steps. The first is designed to be robust to noisy data and is used to anno</context>
</contexts>
<marker>Berger, Pietra, Pietra, 1996</marker>
<rawString>Adam L. Berger, Stephen A. Della Pietra, and Vincent J. Della Pietra. 1996. A maximum entropy approach to natural language processing. COMPUTATIONAL LINGUISTICS, 22:39–71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Lavergne</author>
<author>Olivier Capp´e</author>
<author>Franc¸ois Yvon</author>
</authors>
<title>Practical very large scale CRFs.</title>
<date>2010</date>
<booktitle>In Proceedings the 48th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>504--513</pages>
<marker>Lavergne, Capp´e, Yvon, 2010</marker>
<rawString>Thomas Lavergne, Olivier Capp´e, and Franc¸ois Yvon. 2010. Practical very large scale CRFs. In Proceedings the 48th Annual Meeting of the Association for Computational Linguistics (ACL), pages 504–513. Association for Computational Linguistics, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Riezler</author>
<author>Alexander Vasserman</author>
</authors>
<title>Incremental feature selection and l1 regularization for relaxed maximum-entropy modeling.</title>
<date>2004</date>
<booktitle>In Proceedings of the International Conference on Empirical Methods for Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="10505" citStr="Riezler and Vasserman, 2004" startWordPosition="1748" endWordPosition="1751">H(˜en−1, ˜en, wn+2 n−2) (2) which ensures that probabilities sum up to one. �en−1 and �en are components for previous and current words, H(En−1, �en, wn+2 n−2) is an abbreviation for EMm=1 λm · hm(en−1, en, wn+2 n−2), i.e. the set of active feature functions at current position in the sequence. In the last few years different CRF implementations have been realized. The implementation we refer in this work is the one described in (Lavergne et al., 2010), which optimize the following objective function: −log(P(EN1|W1N))+ρ1kλk1+ ρ2 2 kλk2 (3) 2 IIλII1 and IIλII2 2 are the l1 and l2 regularizers (Riezler and Vasserman, 2004), and together in a linear combination implement the elastic net regularizer (Zou and Hastie, 2005). As mentioned in (Lavergne et al., 2010), this kind of regularizers are very effective for feature selection at training time, which is a very good point when dealing with noisy data and big set of features. N ri n=1 Z =L ˜eN 1 176 4 Models for Parsing Trees The models used in this work for parsing entity trees refer to the models described in (Johnson, 1998), in (Charniak, 1997; Caraballo and Charniak, 1997) and (Charniak et al., 1998), and which constitutes the basis of the maximum entropy mod</context>
</contexts>
<marker>Riezler, Vasserman, 2004</marker>
<rawString>Stefan Riezler and Alexander Vasserman. 2004. Incremental feature selection and l1 regularization for relaxed maximum-entropy modeling. In Proceedings of the International Conference on Empirical Methods for Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hui Zou</author>
<author>Trevor Hastie</author>
</authors>
<title>Regularization and variable selection via the Elastic Net.</title>
<date>2005</date>
<journal>Journal of the Royal Statistical Society B,</journal>
<pages>67--301</pages>
<contexts>
<context position="10604" citStr="Zou and Hastie, 2005" startWordPosition="1763" endWordPosition="1766">or previous and current words, H(En−1, �en, wn+2 n−2) is an abbreviation for EMm=1 λm · hm(en−1, en, wn+2 n−2), i.e. the set of active feature functions at current position in the sequence. In the last few years different CRF implementations have been realized. The implementation we refer in this work is the one described in (Lavergne et al., 2010), which optimize the following objective function: −log(P(EN1|W1N))+ρ1kλk1+ ρ2 2 kλk2 (3) 2 IIλII1 and IIλII2 2 are the l1 and l2 regularizers (Riezler and Vasserman, 2004), and together in a linear combination implement the elastic net regularizer (Zou and Hastie, 2005). As mentioned in (Lavergne et al., 2010), this kind of regularizers are very effective for feature selection at training time, which is a very good point when dealing with noisy data and big set of features. N ri n=1 Z =L ˜eN 1 176 4 Models for Parsing Trees The models used in this work for parsing entity trees refer to the models described in (Johnson, 1998), in (Charniak, 1997; Caraballo and Charniak, 1997) and (Charniak et al., 1998), and which constitutes the basis of the maximum entropy model for parsing described in (Charniak, 2000). A similar lexicalized model has been proposed also by</context>
</contexts>
<marker>Zou, Hastie, 2005</marker>
<rawString>Hui Zou and Trevor Hastie. 2005. Regularization and variable selection via the Elastic Net. Journal of the Royal Statistical Society B, 67:301–320.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
</authors>
<title>Statistical parsing with a context-free grammar and word statistics.</title>
<date>1997</date>
<booktitle>In Proceedings of the fourteenth national conference on artificial intelligence and ninth conference on Innovative applications of artificial intelligence, AAAI’97/IAAI’97,</booktitle>
<pages>598--603</pages>
<publisher>AAAI Press.</publisher>
<contexts>
<context position="10986" citStr="Charniak, 1997" startWordPosition="1839" endWordPosition="1840">e function: −log(P(EN1|W1N))+ρ1kλk1+ ρ2 2 kλk2 (3) 2 IIλII1 and IIλII2 2 are the l1 and l2 regularizers (Riezler and Vasserman, 2004), and together in a linear combination implement the elastic net regularizer (Zou and Hastie, 2005). As mentioned in (Lavergne et al., 2010), this kind of regularizers are very effective for feature selection at training time, which is a very good point when dealing with noisy data and big set of features. N ri n=1 Z =L ˜eN 1 176 4 Models for Parsing Trees The models used in this work for parsing entity trees refer to the models described in (Johnson, 1998), in (Charniak, 1997; Caraballo and Charniak, 1997) and (Charniak et al., 1998), and which constitutes the basis of the maximum entropy model for parsing described in (Charniak, 2000). A similar lexicalized model has been proposed also by Collins (Collins, 1997). All these models are based on a PCFG trained from data and used in a chart parsing algorithm to find the best parse for the given input. The PCFG model of (Johnson, 1998) is made of rules of the form: • XZ ⇒ X3Xk • XZ ⇒ w where X are non-terminal entities and w are terminal symbols (words in our case).1 The probability associated to these rules are: P(Xi</context>
<context position="22797" citStr="Charniak, 1997" startWordPosition="3863" endWordPosition="3864"> discuss some important models here. Beyond the models for parsing discussed in section 4, together with motivations for using or not in our work, another important model for syntactic parsing has been proposed in (Ratnaparkhi, 1999). Such model is made of four Maximum Entropy models used in cascade for parsing at different stages. Also this model makes use of head words, like those described in section 4, thus the same considerations hold, moreover it seems quite complex for real applications, as it involves the use of four different models together. The models described in (Johnson, 1998), (Charniak, 1997; Caraballo and Charniak, 1997), (Charniak et al., 1998), (Charniak, 2000), (Collins, 1997) and (Ratnaparkhi, 1999), constitute the main individual models proposed for constituent-based syntactic parsing. Later other approaches based on models combination have been proposed, like e.g. the reranking approach described in (Collins and Koo, 2005), among many, and also evolutions or improvements of these models. More recently, approaches based on log-linear models have been proposed (Clark and Curran, 2007; Finkel et al., 2008) for parsing, called also “Tree CRF&apos;, using also different training cri</context>
</contexts>
<marker>Charniak, 1997</marker>
<rawString>Eugene Charniak. 1997. Statistical parsing with a context-free grammar and word statistics. In Proceedings of the fourteenth national conference on artificial intelligence and ninth conference on Innovative applications of artificial intelligence, AAAI’97/IAAI’97, pages 598–603. AAAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
</authors>
<title>A maximum-entropyinspired parser.</title>
<date>2000</date>
<booktitle>In Proceedings of the 1st North American chapter of the Association for Computational Linguistics conference,</booktitle>
<pages>132--139</pages>
<publisher>Morgan Kaufmann Publishers Inc.</publisher>
<location>San Francisco, CA, USA.</location>
<contexts>
<context position="11149" citStr="Charniak, 2000" startWordPosition="1865" endWordPosition="1866">mbination implement the elastic net regularizer (Zou and Hastie, 2005). As mentioned in (Lavergne et al., 2010), this kind of regularizers are very effective for feature selection at training time, which is a very good point when dealing with noisy data and big set of features. N ri n=1 Z =L ˜eN 1 176 4 Models for Parsing Trees The models used in this work for parsing entity trees refer to the models described in (Johnson, 1998), in (Charniak, 1997; Caraballo and Charniak, 1997) and (Charniak et al., 1998), and which constitutes the basis of the maximum entropy model for parsing described in (Charniak, 2000). A similar lexicalized model has been proposed also by Collins (Collins, 1997). All these models are based on a PCFG trained from data and used in a chart parsing algorithm to find the best parse for the given input. The PCFG model of (Johnson, 1998) is made of rules of the form: • XZ ⇒ X3Xk • XZ ⇒ w where X are non-terminal entities and w are terminal symbols (words in our case).1 The probability associated to these rules are: P(Xi ==&gt; Xj,Xk) (4) P(Xi) P(Xi � w) pi —w = (5) P(Xi) The models described in (Charniak, 1997; Caraballo and Charniak, 1997) encode probabilities involving more inform</context>
<context position="16737" citStr="Charniak, 2000" startWordPosition="2792" endWordPosition="2793">l referred to as parent-node-iller. This representation is a good trade-off between contextual information and rigidity, by still representing entities as concatenation of labels, while using a common special label for entity fillers. This allows to keep lower the number of entities annotated on words, i.e. components. Using different tree representations affects both the structure and the performance of the parsing model. The structure is described in the next section, the performance in the evaluation section. 4.2 Structure of the Model Lexicalized models for syntactic parsing described in (Charniak, 2000; Charniak et al., 1998) and (Collins, 1997), integrate more information than what is used in equations 4 and 5. Considering a particular node in the entity tree, not including terminals, the information used is: • s: the head word of the node, i.e. the most important word of the chunk covered by the current node • h: the head word of the parent node • t: the entity tag of the current node • l: the entity tag of the parent node The head word of the parent node is defined percolating head words from children nodes to parent nodes, giving the priority to verbs. They can be found using automatic </context>
<context position="18554" citStr="Charniak, 2000" startWordPosition="3118" endWordPosition="3119">nformation are available to estimate reliably the probability with more conditioning, the model can still provide a probability with terms conditioned with less information. The use of head words and their percolation over the tree is called lexicalization. The goal of tree lexicalization is to add lexical information all over the tree. This way the probability of all rules can be conditioned also on lexical information, allowing to define the probabilities P(s|h, t, l) and P(s|ch, t, l). Tree lexicalization reflects the characteristics of syntactic parsing, for which the models described in (Charniak, 2000; Charniak et al., 1998) and (Collins, 1997) were defined. Head words are very informative since they constitute keywords instantiating labels, regardless if they are syntactic constituents or named entities. However, for named entity recognition it doesn’t make sense to give priority to verbs when percolating head words over the tree, even more because head words of named entities are most of the time nouns. Moreover, it doesn’t make sense to give priority to the head word of a particular entity with respect to the others, all entities in a sentence have the same importance. Intuitively, lexi</context>
<context position="22871" citStr="Charniak, 2000" startWordPosition="3873" endWordPosition="3874">sed in section 4, together with motivations for using or not in our work, another important model for syntactic parsing has been proposed in (Ratnaparkhi, 1999). Such model is made of four Maximum Entropy models used in cascade for parsing at different stages. Also this model makes use of head words, like those described in section 4, thus the same considerations hold, moreover it seems quite complex for real applications, as it involves the use of four different models together. The models described in (Johnson, 1998), (Charniak, 1997; Caraballo and Charniak, 1997), (Charniak et al., 1998), (Charniak, 2000), (Collins, 1997) and (Ratnaparkhi, 1999), constitute the main individual models proposed for constituent-based syntactic parsing. Later other approaches based on models combination have been proposed, like e.g. the reranking approach described in (Collins and Koo, 2005), among many, and also evolutions or improvements of these models. More recently, approaches based on log-linear models have been proposed (Clark and Curran, 2007; Finkel et al., 2008) for parsing, called also “Tree CRF&apos;, using also different training criteria (Auli and Lopez, 2011). Using such models in our work has basically </context>
</contexts>
<marker>Charniak, 2000</marker>
<rawString>Eugene Charniak. 2000. A maximum-entropyinspired parser. In Proceedings of the 1st North American chapter of the Association for Computational Linguistics conference, pages 132–139, San Francisco, CA, USA. Morgan Kaufmann Publishers Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sharon A Caraballo</author>
<author>Eugene Charniak</author>
</authors>
<title>New figures of merit for best-first probabilistic chart parsing.</title>
<date>1997</date>
<journal>Computational Linguistics,</journal>
<pages>24--275</pages>
<contexts>
<context position="11017" citStr="Caraballo and Charniak, 1997" startWordPosition="1841" endWordPosition="1844">(P(EN1|W1N))+ρ1kλk1+ ρ2 2 kλk2 (3) 2 IIλII1 and IIλII2 2 are the l1 and l2 regularizers (Riezler and Vasserman, 2004), and together in a linear combination implement the elastic net regularizer (Zou and Hastie, 2005). As mentioned in (Lavergne et al., 2010), this kind of regularizers are very effective for feature selection at training time, which is a very good point when dealing with noisy data and big set of features. N ri n=1 Z =L ˜eN 1 176 4 Models for Parsing Trees The models used in this work for parsing entity trees refer to the models described in (Johnson, 1998), in (Charniak, 1997; Caraballo and Charniak, 1997) and (Charniak et al., 1998), and which constitutes the basis of the maximum entropy model for parsing described in (Charniak, 2000). A similar lexicalized model has been proposed also by Collins (Collins, 1997). All these models are based on a PCFG trained from data and used in a chart parsing algorithm to find the best parse for the given input. The PCFG model of (Johnson, 1998) is made of rules of the form: • XZ ⇒ X3Xk • XZ ⇒ w where X are non-terminal entities and w are terminal symbols (words in our case).1 The probability associated to these rules are: P(Xi ==&gt; Xj,Xk) (4) P(Xi) P(Xi � w)</context>
<context position="22828" citStr="Caraballo and Charniak, 1997" startWordPosition="3865" endWordPosition="3868">portant models here. Beyond the models for parsing discussed in section 4, together with motivations for using or not in our work, another important model for syntactic parsing has been proposed in (Ratnaparkhi, 1999). Such model is made of four Maximum Entropy models used in cascade for parsing at different stages. Also this model makes use of head words, like those described in section 4, thus the same considerations hold, moreover it seems quite complex for real applications, as it involves the use of four different models together. The models described in (Johnson, 1998), (Charniak, 1997; Caraballo and Charniak, 1997), (Charniak et al., 1998), (Charniak, 2000), (Collins, 1997) and (Ratnaparkhi, 1999), constitute the main individual models proposed for constituent-based syntactic parsing. Later other approaches based on models combination have been proposed, like e.g. the reranking approach described in (Collins and Koo, 2005), among many, and also evolutions or improvements of these models. More recently, approaches based on log-linear models have been proposed (Clark and Curran, 2007; Finkel et al., 2008) for parsing, called also “Tree CRF&apos;, using also different training criteria (Auli and Lopez, 2011). U</context>
</contexts>
<marker>Caraballo, Charniak, 1997</marker>
<rawString>Sharon A. Caraballo and Eugene Charniak. 1997. New figures of merit for best-first probabilistic chart parsing. Computational Linguistics, 24:275–298.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Three generative, lexicalised models for statistical parsing.</title>
<date>1997</date>
<booktitle>In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics and Eighth Conference of the European Chapter of the Association for Computational Linguistics, ACL ’98,</booktitle>
<pages>16--23</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="11228" citStr="Collins, 1997" startWordPosition="1878" endWordPosition="1879">oned in (Lavergne et al., 2010), this kind of regularizers are very effective for feature selection at training time, which is a very good point when dealing with noisy data and big set of features. N ri n=1 Z =L ˜eN 1 176 4 Models for Parsing Trees The models used in this work for parsing entity trees refer to the models described in (Johnson, 1998), in (Charniak, 1997; Caraballo and Charniak, 1997) and (Charniak et al., 1998), and which constitutes the basis of the maximum entropy model for parsing described in (Charniak, 2000). A similar lexicalized model has been proposed also by Collins (Collins, 1997). All these models are based on a PCFG trained from data and used in a chart parsing algorithm to find the best parse for the given input. The PCFG model of (Johnson, 1998) is made of rules of the form: • XZ ⇒ X3Xk • XZ ⇒ w where X are non-terminal entities and w are terminal symbols (words in our case).1 The probability associated to these rules are: P(Xi ==&gt; Xj,Xk) (4) P(Xi) P(Xi � w) pi —w = (5) P(Xi) The models described in (Charniak, 1997; Caraballo and Charniak, 1997) encode probabilities involving more information, such as head words. In order to have a PCFG model made of rules with the</context>
<context position="16781" citStr="Collins, 1997" startWordPosition="2799" endWordPosition="2800">resentation is a good trade-off between contextual information and rigidity, by still representing entities as concatenation of labels, while using a common special label for entity fillers. This allows to keep lower the number of entities annotated on words, i.e. components. Using different tree representations affects both the structure and the performance of the parsing model. The structure is described in the next section, the performance in the evaluation section. 4.2 Structure of the Model Lexicalized models for syntactic parsing described in (Charniak, 2000; Charniak et al., 1998) and (Collins, 1997), integrate more information than what is used in equations 4 and 5. Considering a particular node in the entity tree, not including terminals, the information used is: • s: the head word of the node, i.e. the most important word of the chunk covered by the current node • h: the head word of the parent node • t: the entity tag of the current node • l: the entity tag of the parent node The head word of the parent node is defined percolating head words from children nodes to parent nodes, giving the priority to verbs. They can be found using automatic approaches based on words and entity tag co-</context>
<context position="18598" citStr="Collins, 1997" startWordPosition="3125" endWordPosition="3126">y the probability with more conditioning, the model can still provide a probability with terms conditioned with less information. The use of head words and their percolation over the tree is called lexicalization. The goal of tree lexicalization is to add lexical information all over the tree. This way the probability of all rules can be conditioned also on lexical information, allowing to define the probabilities P(s|h, t, l) and P(s|ch, t, l). Tree lexicalization reflects the characteristics of syntactic parsing, for which the models described in (Charniak, 2000; Charniak et al., 1998) and (Collins, 1997) were defined. Head words are very informative since they constitute keywords instantiating labels, regardless if they are syntactic constituents or named entities. However, for named entity recognition it doesn’t make sense to give priority to verbs when percolating head words over the tree, even more because head words of named entities are most of the time nouns. Moreover, it doesn’t make sense to give priority to the head word of a particular entity with respect to the others, all entities in a sentence have the same importance. Intuitively, lexicalization of entity trees is not straightfo</context>
<context position="22888" citStr="Collins, 1997" startWordPosition="3875" endWordPosition="3876">together with motivations for using or not in our work, another important model for syntactic parsing has been proposed in (Ratnaparkhi, 1999). Such model is made of four Maximum Entropy models used in cascade for parsing at different stages. Also this model makes use of head words, like those described in section 4, thus the same considerations hold, moreover it seems quite complex for real applications, as it involves the use of four different models together. The models described in (Johnson, 1998), (Charniak, 1997; Caraballo and Charniak, 1997), (Charniak et al., 1998), (Charniak, 2000), (Collins, 1997) and (Ratnaparkhi, 1999), constitute the main individual models proposed for constituent-based syntactic parsing. Later other approaches based on models combination have been proposed, like e.g. the reranking approach described in (Collins and Koo, 2005), among many, and also evolutions or improvements of these models. More recently, approaches based on log-linear models have been proposed (Clark and Curran, 2007; Finkel et al., 2008) for parsing, called also “Tree CRF&apos;, using also different training criteria (Auli and Lopez, 2011). Using such models in our work has basically two problems: one</context>
</contexts>
<marker>Collins, 1997</marker>
<rawString>Michael Collins. 1997. Three generative, lexicalised models for statistical parsing. In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics and Eighth Conference of the European Chapter of the Association for Computational Linguistics, ACL ’98, pages 16–23, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
<author>Sharon Goldwater</author>
<author>Mark Johnson</author>
</authors>
<title>Edge-based best-first chart parsing. In</title>
<date>1998</date>
<booktitle>In Proceedings of the Sixth Workshop on Very Large Corpora,</booktitle>
<pages>127--133</pages>
<publisher>Morgan Kaufmann.</publisher>
<contexts>
<context position="11045" citStr="Charniak et al., 1998" startWordPosition="1846" endWordPosition="1849">2 IIλII1 and IIλII2 2 are the l1 and l2 regularizers (Riezler and Vasserman, 2004), and together in a linear combination implement the elastic net regularizer (Zou and Hastie, 2005). As mentioned in (Lavergne et al., 2010), this kind of regularizers are very effective for feature selection at training time, which is a very good point when dealing with noisy data and big set of features. N ri n=1 Z =L ˜eN 1 176 4 Models for Parsing Trees The models used in this work for parsing entity trees refer to the models described in (Johnson, 1998), in (Charniak, 1997; Caraballo and Charniak, 1997) and (Charniak et al., 1998), and which constitutes the basis of the maximum entropy model for parsing described in (Charniak, 2000). A similar lexicalized model has been proposed also by Collins (Collins, 1997). All these models are based on a PCFG trained from data and used in a chart parsing algorithm to find the best parse for the given input. The PCFG model of (Johnson, 1998) is made of rules of the form: • XZ ⇒ X3Xk • XZ ⇒ w where X are non-terminal entities and w are terminal symbols (words in our case).1 The probability associated to these rules are: P(Xi ==&gt; Xj,Xk) (4) P(Xi) P(Xi � w) pi —w = (5) P(Xi) The model</context>
<context position="16761" citStr="Charniak et al., 1998" startWordPosition="2794" endWordPosition="2797"> parent-node-iller. This representation is a good trade-off between contextual information and rigidity, by still representing entities as concatenation of labels, while using a common special label for entity fillers. This allows to keep lower the number of entities annotated on words, i.e. components. Using different tree representations affects both the structure and the performance of the parsing model. The structure is described in the next section, the performance in the evaluation section. 4.2 Structure of the Model Lexicalized models for syntactic parsing described in (Charniak, 2000; Charniak et al., 1998) and (Collins, 1997), integrate more information than what is used in equations 4 and 5. Considering a particular node in the entity tree, not including terminals, the information used is: • s: the head word of the node, i.e. the most important word of the chunk covered by the current node • h: the head word of the parent node • t: the entity tag of the current node • l: the entity tag of the parent node The head word of the parent node is defined percolating head words from children nodes to parent nodes, giving the priority to verbs. They can be found using automatic approaches based on word</context>
<context position="18578" citStr="Charniak et al., 1998" startWordPosition="3120" endWordPosition="3123">vailable to estimate reliably the probability with more conditioning, the model can still provide a probability with terms conditioned with less information. The use of head words and their percolation over the tree is called lexicalization. The goal of tree lexicalization is to add lexical information all over the tree. This way the probability of all rules can be conditioned also on lexical information, allowing to define the probabilities P(s|h, t, l) and P(s|ch, t, l). Tree lexicalization reflects the characteristics of syntactic parsing, for which the models described in (Charniak, 2000; Charniak et al., 1998) and (Collins, 1997) were defined. Head words are very informative since they constitute keywords instantiating labels, regardless if they are syntactic constituents or named entities. However, for named entity recognition it doesn’t make sense to give priority to verbs when percolating head words over the tree, even more because head words of named entities are most of the time nouns. Moreover, it doesn’t make sense to give priority to the head word of a particular entity with respect to the others, all entities in a sentence have the same importance. Intuitively, lexicalization of entity tre</context>
<context position="22853" citStr="Charniak et al., 1998" startWordPosition="3869" endWordPosition="3872">models for parsing discussed in section 4, together with motivations for using or not in our work, another important model for syntactic parsing has been proposed in (Ratnaparkhi, 1999). Such model is made of four Maximum Entropy models used in cascade for parsing at different stages. Also this model makes use of head words, like those described in section 4, thus the same considerations hold, moreover it seems quite complex for real applications, as it involves the use of four different models together. The models described in (Johnson, 1998), (Charniak, 1997; Caraballo and Charniak, 1997), (Charniak et al., 1998), (Charniak, 2000), (Collins, 1997) and (Ratnaparkhi, 1999), constitute the main individual models proposed for constituent-based syntactic parsing. Later other approaches based on models combination have been proposed, like e.g. the reranking approach described in (Collins and Koo, 2005), among many, and also evolutions or improvements of these models. More recently, approaches based on log-linear models have been proposed (Clark and Curran, 2007; Finkel et al., 2008) for parsing, called also “Tree CRF&apos;, using also different training criteria (Auli and Lopez, 2011). Using such models in our w</context>
</contexts>
<marker>Charniak, Goldwater, Johnson, 1998</marker>
<rawString>Eugene Charniak, Sharon Goldwater, and Mark Johnson. 1998. Edge-based best-first chart parsing. In In Proceedings of the Sixth Workshop on Very Large Corpora, pages 127–133. Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexandre Allauzen</author>
<author>H´el´ene Bonneau-Maynard</author>
</authors>
<title>Training and evaluation of pos taggers on the french multitag corpus.</title>
<date>2008</date>
<booktitle>In Proceedings of the Sixth International Language Resources and Evaluation (LREC’08),</booktitle>
<location>Marrakech, Morocco,</location>
<contexts>
<context position="25457" citStr="Allauzen and Bonneau-Maynard, 2008" startWordPosition="4288" endWordPosition="4291">d in (Lavergne et al., 2010), named wapiti.3 We didn’t optimize parameters p1 and p2 of the elastic net (see section 3.1), although this improves significantly the performances and leads to more compact models, default values lead in most cases to very accurate models. We used a wide set of features in CRF models, in a window of [−2, +2] around the target word: • A set of standard features like word prefixes and suffixes of length from 1 to 6, plus some Yes/No features like Does the word start with capital letter?, etc. • Morpho-syntactic features extracted from the output of the tool tagger (Allauzen and Bonneau-Maynard, 2008) • Features extracted from the output of the semantic analyzer (Rosset et al., (2009)) provided by the tool WMatch (Galibert, 2009). This analysis morpho-syntactic information as well as semantic information at the same level of named entities. Using two different sets of morpho-syntactic features results in more effective models, as they create a kind of agreement for a given word in case of match. Concerning the PCFG model, grammars, tree binarization and the different tree representations are created with our own scripts, while entity tree parsing is performed with the chart parsing algorit</context>
</contexts>
<marker>Allauzen, Bonneau-Maynard, 2008</marker>
<rawString>Alexandre Allauzen and H´el´ene Bonneau-Maynard. 2008. Training and evaluation of pos taggers on the french multitag corpus. In Proceedings of the Sixth International Language Resources and Evaluation (LREC’08), Marrakech, Morocco, may.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Olivier Galibert</author>
</authors>
<title>Approches et m´ethodologies pour la r´eponse automatique a` des questions adapt´ees a` un cadre interactif en domaine ouvert.</title>
<date>2009</date>
<tech>Ph.D. thesis,</tech>
<institution>Universit´e Paris Sud,</institution>
<location>Orsay.</location>
<contexts>
<context position="25588" citStr="Galibert, 2009" startWordPosition="4313" endWordPosition="4314">ficantly the performances and leads to more compact models, default values lead in most cases to very accurate models. We used a wide set of features in CRF models, in a window of [−2, +2] around the target word: • A set of standard features like word prefixes and suffixes of length from 1 to 6, plus some Yes/No features like Does the word start with capital letter?, etc. • Morpho-syntactic features extracted from the output of the tool tagger (Allauzen and Bonneau-Maynard, 2008) • Features extracted from the output of the semantic analyzer (Rosset et al., (2009)) provided by the tool WMatch (Galibert, 2009). This analysis morpho-syntactic information as well as semantic information at the same level of named entities. Using two different sets of morpho-syntactic features results in more effective models, as they create a kind of agreement for a given word in case of match. Concerning the PCFG model, grammars, tree binarization and the different tree representations are created with our own scripts, while entity tree parsing is performed with the chart parsing algorithm described in (Johnson, 1998).4 3available at http://wapiti.limsi.fr 4available at http://web.science.mq.edu.au/ ˜mjohnson/Softwa</context>
</contexts>
<marker>Galibert, 2009</marker>
<rawString>Olivier Galibert. 2009. Approches et m´ethodologies pour la r´eponse automatique a` des questions adapt´ees a` un cadre interactif en domaine ouvert. Ph.D. thesis, Universit´e Paris Sud, Orsay.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rosset Sophie</author>
<author>Galibert Olivier</author>
<author>Bernard Guillaume</author>
<author>Bilinski Eric</author>
<author>Adda Gilles</author>
</authors>
<title>The LIMSI multilingual, multitask QAst system.</title>
<date>2009</date>
<booktitle>In Proceedings of the 9th Cross-language evaluation forum conference on Evaluating systems for multilingual and multimodal information access, CLEF’08,</booktitle>
<pages>480--487</pages>
<publisher>SpringerVerlag.</publisher>
<location>Berlin, Heidelberg,</location>
<marker>Sophie, Olivier, Guillaume, Eric, Gilles, 2009</marker>
<rawString>Rosset Sophie, Galibert Olivier, Bernard Guillaume, Bilinski Eric, and Adda Gilles. The LIMSI multilingual, multitask QAst system. In Proceedings of the 9th Cross-language evaluation forum conference on Evaluating systems for multilingual and multimodal information access, CLEF’08, pages 480–487, Berlin, Heidelberg, 2009. SpringerVerlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Azeddine Zidouni</author>
<author>Sophie Rosset</author>
<author>Herv´e Glotin</author>
</authors>
<title>Efficient combined approach for named entity recognition in spoken language.</title>
<date>2010</date>
<booktitle>In Proceedings of the International Conference of the Speech Communication Assosiation (Interspeech),</booktitle>
<location>Makuhari, Japan</location>
<marker>Zidouni, Rosset, Glotin, 2010</marker>
<rawString>Azeddine Zidouni, Sophie Rosset, and Herv´e Glotin. 2010. Efficient combined approach for named entity recognition in spoken language. In Proceedings of the International Conference of the Speech Communication Assosiation (Interspeech), Makuhari, Japan</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Makhoul</author>
<author>Francis Kubala</author>
<author>Richard Schwartz</author>
<author>Ralph Weischedel</author>
</authors>
<title>Performance measures for information extraction.</title>
<date>1999</date>
<booktitle>In Proceedings of DARPA Broadcast News Workshop,</booktitle>
<pages>249--252</pages>
<contexts>
<context position="26610" citStr="Makhoul et al., 1999" startWordPosition="4458" endWordPosition="4461">hile entity tree parsing is performed with the chart parsing algorithm described in (Johnson, 1998).4 3available at http://wapiti.limsi.fr 4available at http://web.science.mq.edu.au/ ˜mjohnson/Software.htm 180 CRF PCFG Model # features # labels # rules baseline 3,041,797 55 29,611 filler-parent 3,637,990 112 29,611 parent-context 3,605,019 120 29,611 parent-node 3,718,089 441 31,110 parent-node-filler 3,723,964 378 31,110 Table 3: Statistics showing the characteristics of the different models used in this work 6.2 Evaluation Metrics All results are expressed in terms of Slot Error Rate (SER) (Makhoul et al., 1999) which has a similar definition of word error rate for ASR systems, with the difference that substitution errors are split in three types: i) correct entity type with wrong segmentation; ii) wrong entity type with correct segmentation; iii) wrong entity type with wrong segmentation; here, i) and ii) are given half points, while iii), as well as insertion and deletion errors, are given full points. Moreover, results are given using the well known F1 measure, defined as a function of precision and recall. 6.3 Results In this section we provide evaluations of the models described in this work, ba</context>
</contexts>
<marker>Makhoul, Kubala, Schwartz, Weischedel, 1999</marker>
<rawString>John Makhoul, Francis Kubala, Richard Schwartz, and Ralph Weischedel. 1999. Performance measures for information extraction. In Proceedings of DARPA Broadcast News Workshop, pages 249–252.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adwait Ratnaparkhi</author>
</authors>
<title>Learning to Parse Natural Language with Maximum Entropy Models.</title>
<date>1999</date>
<journal>Journal of Machine Learning,</journal>
<volume>34</volume>
<pages>1--3</pages>
<contexts>
<context position="22416" citStr="Ratnaparkhi, 1999" startWordPosition="3801" endWordPosition="3802"> posterior probabilities. 2The set of features used in the CRF model will be described in more details in the evaluation section. 179 5 Related Work While the models used for named entity detection and the set of named entities defined along the years have been discussed in the introduction and in section 2, since CRFs and models for parsing constitute the main issue in our work, we discuss some important models here. Beyond the models for parsing discussed in section 4, together with motivations for using or not in our work, another important model for syntactic parsing has been proposed in (Ratnaparkhi, 1999). Such model is made of four Maximum Entropy models used in cascade for parsing at different stages. Also this model makes use of head words, like those described in section 4, thus the same considerations hold, moreover it seems quite complex for real applications, as it involves the use of four different models together. The models described in (Johnson, 1998), (Charniak, 1997; Caraballo and Charniak, 1997), (Charniak et al., 1998), (Charniak, 2000), (Collins, 1997) and (Ratnaparkhi, 1999), constitute the main individual models proposed for constituent-based syntactic parsing. Later other ap</context>
</contexts>
<marker>Ratnaparkhi, 1999</marker>
<rawString>Adwait Ratnaparkhi. 1999. Learning to Parse Natural Language with Maximum Entropy Models. Journal of Machine Learning, vol. 34, issue 1-3, pages 151– 175.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Terry Koo</author>
</authors>
<title>Discriminative Re-ranking for Natural Language Parsing.</title>
<date>2005</date>
<journal>Journal of Machine Learning,</journal>
<volume>31</volume>
<pages>25--70</pages>
<contexts>
<context position="23142" citStr="Collins and Koo, 2005" startWordPosition="3908" endWordPosition="3911">o this model makes use of head words, like those described in section 4, thus the same considerations hold, moreover it seems quite complex for real applications, as it involves the use of four different models together. The models described in (Johnson, 1998), (Charniak, 1997; Caraballo and Charniak, 1997), (Charniak et al., 1998), (Charniak, 2000), (Collins, 1997) and (Ratnaparkhi, 1999), constitute the main individual models proposed for constituent-based syntactic parsing. Later other approaches based on models combination have been proposed, like e.g. the reranking approach described in (Collins and Koo, 2005), among many, and also evolutions or improvements of these models. More recently, approaches based on log-linear models have been proposed (Clark and Curran, 2007; Finkel et al., 2008) for parsing, called also “Tree CRF&apos;, using also different training criteria (Auli and Lopez, 2011). Using such models in our work has basically two problems: one related to scaling issues, since our data present a large number of labels, which makes CRF training problematic, even more when using “Tree CRF&apos;; another problem is related to the difference between syntactic parsing and named entity detection tasks, a</context>
</contexts>
<marker>Collins, Koo, 2005</marker>
<rawString>Michael Collins and Terry Koo. 2005. Discriminative Re-ranking for Natural Language Parsing. Journal of Machine Learning, vol. 31, issue 1, pages 25–70.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Clark</author>
<author>James R Curran</author>
</authors>
<title>WideCoverage Efficient Statistical Parsing with CCG and Log-Linear Models.</title>
<date>2007</date>
<journal>Journal of Computational Linguistics,</journal>
<volume>33</volume>
<pages>493--552</pages>
<contexts>
<context position="23304" citStr="Clark and Curran, 2007" startWordPosition="3932" endWordPosition="3935"> as it involves the use of four different models together. The models described in (Johnson, 1998), (Charniak, 1997; Caraballo and Charniak, 1997), (Charniak et al., 1998), (Charniak, 2000), (Collins, 1997) and (Ratnaparkhi, 1999), constitute the main individual models proposed for constituent-based syntactic parsing. Later other approaches based on models combination have been proposed, like e.g. the reranking approach described in (Collins and Koo, 2005), among many, and also evolutions or improvements of these models. More recently, approaches based on log-linear models have been proposed (Clark and Curran, 2007; Finkel et al., 2008) for parsing, called also “Tree CRF&apos;, using also different training criteria (Auli and Lopez, 2011). Using such models in our work has basically two problems: one related to scaling issues, since our data present a large number of labels, which makes CRF training problematic, even more when using “Tree CRF&apos;; another problem is related to the difference between syntactic parsing and named entity detection tasks, as mentioned in sub-section 4.2. Adapting “Tree CRF&apos; to our task is thus a quite complex work, it constitutes an entire work by itself, we leave it as feature work</context>
</contexts>
<marker>Clark, Curran, 2007</marker>
<rawString>Clark, Stephen and Curran, James R. 2007. WideCoverage Efficient Statistical Parsing with CCG and Log-Linear Models. Journal of Computational Linguistics, vol. 33, issue 4, pages 493–552.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny R Finkel</author>
<author>Alex Kleeman</author>
<author>Christopher D Manning</author>
</authors>
<title>Efficient, Feature-based, Conditional Random Field Parsing.</title>
<date>2008</date>
<booktitle>Proceedings of the Association for Computational Linguistics,</booktitle>
<pages>959--967</pages>
<location>Columbus, Ohio.</location>
<contexts>
<context position="23326" citStr="Finkel et al., 2008" startWordPosition="3936" endWordPosition="3939">of four different models together. The models described in (Johnson, 1998), (Charniak, 1997; Caraballo and Charniak, 1997), (Charniak et al., 1998), (Charniak, 2000), (Collins, 1997) and (Ratnaparkhi, 1999), constitute the main individual models proposed for constituent-based syntactic parsing. Later other approaches based on models combination have been proposed, like e.g. the reranking approach described in (Collins and Koo, 2005), among many, and also evolutions or improvements of these models. More recently, approaches based on log-linear models have been proposed (Clark and Curran, 2007; Finkel et al., 2008) for parsing, called also “Tree CRF&apos;, using also different training criteria (Auli and Lopez, 2011). Using such models in our work has basically two problems: one related to scaling issues, since our data present a large number of labels, which makes CRF training problematic, even more when using “Tree CRF&apos;; another problem is related to the difference between syntactic parsing and named entity detection tasks, as mentioned in sub-section 4.2. Adapting “Tree CRF&apos; to our task is thus a quite complex work, it constitutes an entire work by itself, we leave it as feature work. Concerning linear-ch</context>
</contexts>
<marker>Finkel, Kleeman, Manning, 2008</marker>
<rawString>Finkel, Jenny R. and Kleeman, Alex and Manning, Christopher D. 2008. Efficient, Feature-based, Conditional Random Field Parsing. Proceedings of the Association for Computational Linguistics, pages 959–967, Columbus, Ohio.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Auli</author>
<author>Adam Lopez</author>
</authors>
<title>Training a LogLinear Parser with Loss Functions via SoftmaxMargin.</title>
<date>2011</date>
<booktitle>Proceedings of Empirical Methods for Natural Language Processing,</booktitle>
<pages>333--343</pages>
<location>Edinburgh, U.K.</location>
<contexts>
<context position="23425" citStr="Auli and Lopez, 2011" startWordPosition="3951" endWordPosition="3954">allo and Charniak, 1997), (Charniak et al., 1998), (Charniak, 2000), (Collins, 1997) and (Ratnaparkhi, 1999), constitute the main individual models proposed for constituent-based syntactic parsing. Later other approaches based on models combination have been proposed, like e.g. the reranking approach described in (Collins and Koo, 2005), among many, and also evolutions or improvements of these models. More recently, approaches based on log-linear models have been proposed (Clark and Curran, 2007; Finkel et al., 2008) for parsing, called also “Tree CRF&apos;, using also different training criteria (Auli and Lopez, 2011). Using such models in our work has basically two problems: one related to scaling issues, since our data present a large number of labels, which makes CRF training problematic, even more when using “Tree CRF&apos;; another problem is related to the difference between syntactic parsing and named entity detection tasks, as mentioned in sub-section 4.2. Adapting “Tree CRF&apos; to our task is thus a quite complex work, it constitutes an entire work by itself, we leave it as feature work. Concerning linear-chain CRF models, the one we use is a state-of-the-art implementation (Lavergne et al., 2010), as it </context>
</contexts>
<marker>Auli, Lopez, 2011</marker>
<rawString>Michael Auli and Adam Lopez 2011. Training a LogLinear Parser with Loss Functions via SoftmaxMargin. Proceedings of Empirical Methods for Natural Language Processing, pages 333–343, Edinburgh, U.K.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jie Tang</author>
<author>MingCai Hong</author>
<author>Juan-Zi Li</author>
<author>Bangyong Liang</author>
</authors>
<date>2006</date>
<booktitle>Tree-Structured Conditional Random Fields for Semantic Annotation. Proceedgins of the International Semantic Web Conference,</booktitle>
<pages>640--653</pages>
<publisher>Springer.</publisher>
<note>Edited by</note>
<contexts>
<context position="24273" citStr="Tang et al., 2006" startWordPosition="4085" endWordPosition="4088">related to the difference between syntactic parsing and named entity detection tasks, as mentioned in sub-section 4.2. Adapting “Tree CRF&apos; to our task is thus a quite complex work, it constitutes an entire work by itself, we leave it as feature work. Concerning linear-chain CRF models, the one we use is a state-of-the-art implementation (Lavergne et al., 2010), as it implements the most effective optimization algorithms as well as state-of-the-art regularizers (see sub-section 3.1). Some improvement of linear-chain CRF have been proposed, trying to integrate higher order target-side features (Tang et al., 2006). An integration of the same kind of features has been tried also in the model used in this work, without giving significant improvements, but making model training much harder. Thus, this direction has not been further investigated. 6 Evaluation In this section we describe experiments performed to evaluate our models. We first describe the settings used for the two models involved in the entity tree parsing, and then describe and comment the results obtained on the test corpus. 6.1 Settings The CRF implementation used in this work is described in (Lavergne et al., 2010), named wapiti.3 We did</context>
</contexts>
<marker>Tang, Hong, Li, Liang, 2006</marker>
<rawString>Tang, Jie and Hong, MingCai and Li, Juan-Zi and Liang, Bangyong. 2006. Tree-Structured Conditional Random Fields for Semantic Annotation. Proceedgins of the International Semantic Web Conference, pages 640–653, Edited by Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Olivier Galibert</author>
</authors>
<title>Sophie Rosset; Cyril Grouin; Pierre Zweigenbaum; Ludovic Quintard.</title>
<date>2011</date>
<marker>Galibert, 2011</marker>
<rawString>Olivier Galibert; Sophie Rosset; Cyril Grouin; Pierre Zweigenbaum; Ludovic Quintard. 2011. Structured and Extended Named Entity Evaluation in Automatic Speech Transcriptions. IJCNLP 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Dinarelli</author>
</authors>
<title>Sophie Rosset. Models Cascade for Tree-Structured Named Entity Detection IJCNLP</title>
<date>2011</date>
<marker>Dinarelli, 2011</marker>
<rawString>Marco Dinarelli, Sophie Rosset. Models Cascade for Tree-Structured Named Entity Detection IJCNLP 2011.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>