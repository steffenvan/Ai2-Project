<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000005">
<note confidence="0.723265">
Computational Linguistics Volume 19, Number 3
</note>
<title confidence="0.925397">
The Logic of Typed Feature Structures
</title>
<author confidence="0.968598">
Bob Carpenter
</author>
<affiliation confidence="0.67897625">
(Carnegie Mellon University)
Cambridge, England: Cambridge
University Press (Cambridge Tracts in
Computer Science 32, edited by
</affiliation>
<address confidence="0.492592333333333">
C. J. van Rijsbergen), 1992, viii +
270 pp.
Hardbound, ISBN 0-521-41932-8, $34.95
</address>
<figure confidence="0.552947333333333">
Reviewed by
Fernando Pereira
AT&amp;T Bell Laboratories
</figure>
<sectionHeader confidence="0.915629" genericHeader="abstract">
1. Introduction
</sectionHeader>
<bodyText confidence="0.999967571428572">
For those of us who belonged to the &amp;quot;Bay Area (Computational) Linguistics Commu-
nity,&amp;quot; the early eighties were a heady time. Local researchers working on linguistics,
computational linguistics, and logic programming were investigating notions of cat-
egory, type, feature, term, and partial specification that appeared to converge to a
powerful new approach for describing (linguistic) objects and their relationships by
monotonic accumulation of constraints between their features. The seed notions had
almost independently arisen in generalized phrase structure grammar (GPSG) (Gazdar
et al. 1985), lexical-functional grammar (LFG) (Bresnan and Kaplan 1982), functional-
unification grammar (FUG) (Kay 1985), logic programming (Colmerauer 1978, Pereira
and Warren 1980), and terminological reasoning systems (AIt-Kaci 1984). It took, how-
ever, a lot of experimental and theoretical work to identify precisely what the core no-
tions were, how particular systems related to the core notions, and what were the most
illuminating mathematical accounts of that core. The development of the unification-
based formalism PATR-II (Shieber 1984) was an early step toward the definition of the
core, but its mathematical analysis, and the clarification of the connections between
the various systems, are only now coming to a reasonable closure. The Logic of Typed
Feature Structures is the first monograph that brings all the main theoretical ideas into
one place where they can be related and compared in a unified setting. Carpenter&apos;s
book touches most of the crucial questions of the developments during the decade,
provides proofs for central results, and reaches right up to the edge of current research
in the field. These contributions alone make it an indispensable compendium for the
researcher or graduate student working on constraint-based grammatical formalisms,
and they also make it a very useful reference work for researchers in object-oriented
databases and logic programming.
Having discharged the main obligation of the reviewer of saying who should read
the book under review and why, I will now survey each of the book&apos;s four parts while
raising some more general questions impinging on the whole book as they arise from
the discussion of each part.
</bodyText>
<sectionHeader confidence="0.953385" genericHeader="keywords">
2. Basics
</sectionHeader>
<bodyText confidence="0.9562905">
From the beginning, Carpenter emphasizes the strong links between attribute-value
formalisms in computational linguistics and in knowledge representation (KR). This
</bodyText>
<page confidence="0.994305">
544
</page>
<subsectionHeader confidence="0.774735">
Book Reviews
</subsectionHeader>
<bodyText confidence="0.999833333333333">
is a welcome conceptual connection. Historically, however, the two strands developed
fairly independently of each other. Alt-Kaci&apos;s dissertation (1984) arose from an attempt
to define a computationally tractable core of inheritance and frame-based reasoning,
but its relevance to the analysis of linguistic categories was not appreciated as early as
it should have been. Interestingly, systemic and dependency grammars had the lead
in bringing inheritance and featural classification notions together on the linguistic
side, but their influence in the particulars of the linguistic formalisms under consid-
eration was slight, if any. Inheritance reasoning played no direct role in LFG, GPSG,
PATR-II, or logic grammars, and it came into play first as a lexicon organization disci-
pline (Flickinger, Pollard, and Wasow 1985; Sheiber 1985), not as a central part of the
formalism.
The organization of the first part of the book follows naturally from the emphasis
on KR ideas. Types and inheritance are discussed first, followed by feature (attribute—
value) structures and the relations and operations that they inherit from the under-
lying type system: subsumption and join (unification). The last introductory chapter
addresses in detail the crucial move of Kasper and Rounds (1986) to clarify the mean-
ing of feature structures by viewing them as models of appropriately chosen modal
logics.
</bodyText>
<subsectionHeader confidence="0.999752">
2.1 Feature Structures and Feature Logics
</subsectionHeader>
<bodyText confidence="0.999872">
The fruitful connection between feature structures and feature logics is pursued
throughout the book, with soundness and completeness results for the basic system
and all the major extensions and variations considered later. If something is missing
in that comprehensive development, it might be some effort to relate feature logics
to modal logics, and feature structures to modal frames. I believe that the original
Kasper—Rounds logic was to some extent inspired by modal logics of concurrency, in
particular the modal Hennessy—Milner logic for CCS (Hennessy and Milner 1985). It
has also been argued that the connection to modal logic is an important route for
easier and more general proofs of the required normal form and completeness results
(Blackburn 1991).
</bodyText>
<subsectionHeader confidence="0.999923">
2.2 Representations versus Algorithms
</subsectionHeader>
<bodyText confidence="0.999958352941177">
The introductory part establishes the algebraic, denotational semantics orientation of
the book, and throughout the book, the more computational aspects of feature logics
receive little attention. In purely conjunctive feature logics such as those arising from
PATR-II, there is a simple connection between formulas and models. An almost linear
satisfiability procedure, based on the UNION-FIND algorithm (Aho, Hoperoft, and
Ullman 1976, Ait-Kaci 1984, Jaffar 1984), can be used to build the unique most-general
feature structure satisfying a formula. There is thus relatively little to say about com-
putational complexity (but not about practical computation costs, as will be observed
below when rational unification is discussed), and the algebraic approach is direct and
instructive. When we move to more-expressive feature logics, however, the situation
changes radically. There are no longer unique most-general models, the algebraic ap-
proach becomes more labored, and satisfiability becomes NP-hard or worse. Computa-
tional complexity results were a central part of the development of the more-expressive
feature logics by Rounds, Kasper, Moshier (Kasper and Rounds 1986, Moshier and
Rounds 1987) and others, but they are barely mentioned in Carpenter&apos;s book. One
feels that those results, being of a more traditional (finite) model-theoretic character,
may have been left out because they do not fit the book&apos;s algebraic plan.
</bodyText>
<page confidence="0.994135">
545
</page>
<note confidence="0.363767">
Computational Linguistics Volume 19, Number 3
</note>
<subsectionHeader confidence="0.875707">
2.3 Feature Logic Intractability and Natural Language Processing
</subsectionHeader>
<bodyText confidence="0.99994325">
A more general point arises from the computational issues just discussed. The in-
tractability of satisfiability for expressive feature logics might seem a serious roadblock
in the practical application of those logics in grammatical description systems. Two
escape routes, one pragmatic and the other more radical, suggest themselves. The
pragmatic route involves trying to identify more tractable subcases that may cover
most of the situations of interest in actual grammatical description. Such &amp;quot;optimistic&amp;quot;
algorithms were already suggested in Kasper&apos;s dissertation (1987), and have been ex-
tensively investigated since (Maxwell and Kaplan 1989; Eisele and Dorre 1988).
The more radical route, which as far as I know has not been pursued vigor-
ously, looks more closely at the search control aspects of language processing systems
based on feature computations. It takes conjunctive description as the only one that
can have global extent in a computation. Nonconjunctive aspects of a description are
then ephemeral in that nonconjunctive connectives introduced in a derivation must
be eliminated within a bounded number of steps by a committed choice operation
based on some preference-based search control mechanism. Such a view can be seen
as a mild generalization of the ideas of deterministic parsing (Marcus 1980), and also
closely related to the flat-guard committed choice logic programming languages (Ueda
1987; Saraswat 1990). In both of those frameworks a single conjunctive constraint is
constructed incrementally on the basis of local committed choices among alternatives.
Search completeness is of course sacrificed, but the computational intractability aris-
ing from having to consider all the combinations of smaller alternative constraints
into larger consistent constraints is bypassed. Finally, the radical route suggests a dis-
cipline of trying to replace as much as possible disjunctive or negative constraints by
somewhat weaker kinds of underspecification that admit of purely conjunctive formu-
lations. That program was already suggested in the context of deterministic parsing
(d-theory) (Marcus, Hindle, and Fleck 1983), and more recently in the context of in-
cremental monotonic semantic interpretation (Alshawi and Crouch 1992), and might
also be profitably employed in the more abstract feature-logic setting.
</bodyText>
<subsectionHeader confidence="0.788071">
2.4 Prerequisites
</subsectionHeader>
<bodyText confidence="0.999961111111111">
I am well aware of the difficulties in determining what should be taken as a reasonable
common background for readers in an interdisciplinary topic. There is little enough
commonality in the theoretical backgrounds of computer scientists trained in different
schools, and the common background becomes even more difficult to find when one
wants to reach also theoretical linguists and AT researchers. Still, the introductory chap-
ters, including their historical portions, seem to assume more than is strictly necessary,
and in fact sometimes seem to assume what is later explained in the text in careful
detail. This kind of forward reference might confuse readers as to what the book&apos;s
prerequisites are, and what they should know as a matter of course. This is especially
the case with respect to concepts of domain theory such as complete partial orders,
conditional completeness, and powerdomains, which the great majority of potential
readers (even, I believe, many U.S.-trained theoretical computer scientists) will not be
familiar with. The early mentions will thus be confusing to them, even though there is
later in the book a good introduction to those prerequisites. Another instance is the re-
peated mentions to intensionality and extensionality before their careful discussion in
Chapter 8. Those have simply too many (admittedly related) meanings for the reader
who would most benefit from the book to grasp what they refer to in feature logics
before the in-depth discussion.
</bodyText>
<page confidence="0.990022">
546
</page>
<subsectionHeader confidence="0.850298">
Book Reviews
2.5 Quibbles
</subsectionHeader>
<bodyText confidence="0.999663833333333">
2.5.1 Up or Down? Following much of the literature on feature structures, Carpenter
adopts the domain-theoretic convention that places more-specific objects &amp;quot;higher up&amp;quot;
in informational partial orders. This conflicts with the conventions of model theory
and knowledge representation, and leads to occasionally distracting dissonances in
notation, terminology, and figures—for instance, inheritance hierarchies with the most
specific elements at the top.
</bodyText>
<subsubsectionHeader confidence="0.727518">
2.5.2 Abstract Feature Structures and Path Congruences. The discussion of abstract
</subsubsectionHeader>
<bodyText confidence="0.999989">
feature structures raises a historical difficulty. While I do not dispute that the full
theoretical investigation of feature structures modulo renaming is correctly attributed
to Moshier, the idea of representing renaming classes by equivalence relations over
paths seems an obvious variant of the representation of such classes as deductively
closed sets of path equations in Pereira and Shieber&apos;s account (1984) of the semantics
of PATR-II, which is further explored in Shieber&apos;s dissertation (1989).
</bodyText>
<subsubsectionHeader confidence="0.688389">
2.5.3 Unification Tradeoffs. The discussion of the tradeoffs between acyclic and ra-
</subsubsectionHeader>
<bodyText confidence="0.999893892857143">
tional term unification at various points in the book might be a bit misleading. The
original Prolog used a weakened pointer-based version of Robinson&apos;s (1965) unification
algorithm (conceivably attributable to Boyer and Moore) without the occurs check. Re-
moving the occurs check, which blocks the binding of a variable to a term containing
the variable, from Robinson&apos;s algorithm allows cyclic unifiers to be built. This not only
changes the interpretation of unification, but is also a source of potential nontermina-
tion when cyclic unifiers are applied. Nevertheless, in the early development of Prolog
the occurs check was seen as too costly to be involved in the basic computational step
of a programming language, and few if any examples were known in which the lack
caused problems for knowledgeable Prolog programmers. The development of linear
acyclic unification algorithms such as Paterson and Wegman&apos;s (1978) or Martelli and
Montanari&apos;s (1982) did not change that assessment. Those algorithms require far heav-
ier data structures and constant factors than Prolog&apos;s unification, they do not interface
well with Prolog&apos;s backtracking control regime, and, most importantly, they are linear
on the sum of the sizes of the terms involved. In contrast, for most practical purposes,
Prolog&apos;s algorithm is linear on the size of the smaller term involved, which depends
only on program size and not on the length of the computation. This was crucial for
the acceptance of Prolog as a programming language, since it was felt that the cost of a
procedure call in a reasonable programming language should not depend on the sizes
of the actual parameters. In Prolog II, Colmerauer and his colleagues side-stepped the
main weakness of Prolog&apos;s unification, nontermination, by moving to rational term
unification, which also has added representational value for certain applications (al-
though for other applications, particularly those derived from theorem proving, only
acyclic unification makes sense). The best rational term unification algorithms are al-
most linear in all cases, and may be linear on the size of the smaller term in the same
cases as Prolog&apos;s algorithm. However, the data structure complexity and constant fac-
tors are still higher than in Prolog&apos;s algorithm, and the interaction with backtracking
is less straightforward.
</bodyText>
<sectionHeader confidence="0.925723" genericHeader="introduction">
3. Extensions
</sectionHeader>
<bodyText confidence="0.999846666666667">
The second part of the book concerns extensions and specializations: acyclic feature
structures, type constraints, inequations, extensionality, and groundedness. I found
most interesting in this part the very thorough accounts of type constraints and of
</bodyText>
<page confidence="0.953888">
547
</page>
<note confidence="0.330491">
Computational Linguistics Volume 19, Number 3
</note>
<bodyText confidence="0.9998712">
inequations. With type constraints restricting what features are appropriate for a type
(so, for instance, an agreement feature is only appropriate for types of phrases that
are subject to agreement constraints, and must yield a value of appropriate agreement
type), we move decisively beyond what was provided by all earlier formalisms with
the exception of GPSG (which was limited in other ways). Type constraints support
good engineering practice in writing large systems such as wide-coverage grammars.
Furthermore, in certain cases type information can lead to more efficient implementa-
tion. If the set of features for each type can be determined at compile time, the normal
open-ended attribute—value representation of features can be replaced by the kind of
positional representation used for record structures in programming languages such
as C.
Carpenter starts the discussion of inequations from the Prolog II inequation (dif )
mechanism (Colmerauer 1986), and extends it elegantly to feature logics. The simplicity
of the account shows that the earlier exposition was carefully orchestrated to allow
extensions and alterations of the core framework without major upheavals.
</bodyText>
<subsectionHeader confidence="0.997437">
3.1 Extensionality
</subsectionHeader>
<bodyText confidence="0.999974515151515">
I was somewhat less happy about the chapters on extensionality and groundedness.
That material seems less definitive, and indeed various points of the discussion are
confusing or unclearly targeted.
There are conceptual and formal reasons for taking seriously the extensionality
question. Different researchers in the field started with different intuitions of feature
structures, with different identity conditions. GPSG categories, for example, were seen
purely extensionally as labeled trees. As the area developed, mismatches between
pointer-based implementations of feature structures and conceptual choices, and fail-
ures of completeness for various feature logics, pushed for increasing intensionaliza-
tion. However, Carpenter goes directly into technical aspects of extensionality without
much attention to the examples and intuitions that brought the question forward in
the first place. It would have been better if alternative feature-structure models, for
instance various tree and domain-theoretic models, had been compared with respect
to their computational and logical implications, even if they were to be ultimately
discarded in favor of the now standard DFA models. As it is, the reader must turn
elsewhere, for instance Shieber&apos;s (1985) monograph, for a broader comparative analy-
sis of feature models.
As a minor problem related to the above, the discussion of feature structures as a
solution for a (domain) equation over partial functions seems unclear as to whether
that is the most intensional model or the most extensional one (which would seem to
be the case).
The relationship between extensionality and Prolog II unification is hinted at re-
peatedly, but its computational implications are not discussed. The differences in ex-
tensionality of feature structures and Prolog II terms are directly reflected in the differ-
ences between the corresponding unification algorithms. Feature-structure unification
requires the identification of all corresponding feature-structure nodes, while term uni-
fication (leaving aside issues of computational complexity and termination in certain
algorithms) only needs to install pointers from leaf (variable) nodes to corresponding
nodes (Jaffar 1984).
Other algorithmic connections are not noted either, such as that between feature
structure collapsing and DFA minimization. Finally, issues of extensionality and indi-
viduation may be most important for object-oriented databases, but that application
is not discussed.
</bodyText>
<page confidence="0.976577">
548
</page>
<figure confidence="0.301334">
Book Reviews
4. Alternatives
</figure>
<bodyText confidence="0.999914714285714">
The third part of the book, named &amp;quot;Alternatives,&amp;quot; is really an introduction to technical
tools needed in later applications. Variables and assignments add nothing to the power
of previous systems, but are convenient when discussing grammars and in another
form were historically important in Ait-Kaci&apos;s system. Feature algebras, on the other
hand, simplify and generalize radically certain mathematical arguments about feature
structures. In fact, they might have been introduced sooner in the text to improve
conceptual unity and eliminate some repetition in proofs.
</bodyText>
<subsectionHeader confidence="0.999525">
4.1 Domain Theory
</subsectionHeader>
<bodyText confidence="0.999993444444445">
The last chapter of &amp;quot;Alternatives&amp;quot; discusses infinite feature structures and their for-
malization through domains. While the topic is potentially important for rounding out
the theory of feature structures and the sketch of domain theory is for the most part
on target, one wonders again whether the uninitiated reader will not stumble on refer-
ences to notions that are discussed only later or not at all. For instance, compactness is
mentioned informally before its definition, without suitable intuitions being provided.
Scott&apos;s information systems are mentioned, without definition, although they are quite
relevant to the material at hand, particularly abstract feature structures. And some of
the proofs are too sketchy for a reader who presumably is not yet familiar with typ-
ical argument patterns in domain theory. The chapter concludes with the suggestive
comment that a formalization of feature structures in terms of abstract closure opera-
tors on domains would eliminate the repetitiveness of completeness proofs for feature
logics. One wishes the suggestion had been tested in the book, although one might
also wonder whether the full apparatus of domain theory would be needed to take
advantage of the convenience of closure operators. After all, closure operators arise
naturally in logic from the notions of deductive closure and of logical consequence
(Tarski 1983), so one might imagine that the simpler proofs could be carried out in a
model-theoretic setting short of domain theory.
</bodyText>
<sectionHeader confidence="0.96629" genericHeader="method">
5. Applications
</sectionHeader>
<bodyText confidence="0.99988925">
The last part of the book applies the theory developed earlier in three important ar-
eas: the semantics of unification-based phrase structure formalisms, the semantics of
feature-based definite clause programs, and the specification of recursive type con-
straints.
</bodyText>
<subsectionHeader confidence="0.999943">
5.1 Semantics of Grammar Formalisms
</subsectionHeader>
<bodyText confidence="0.916138692307692">
Carpenter&apos;s account of the denotational semantics of unification-based phrase structure
grammars benefits greatly from the extensive use of feature algebras and feature-
algebra morphisms to connect derivation steps. Earlier treatments were much less
perspicuous, because they were based on complex encodings of phrase-structure rules
as feature structures and of derivation steps as formal manipulations on rule encodings
(Pereira and Shieber 1984; Shieber 1984; Rounds and Manaster-Ramer 1987).
As a minor terminological point, the qualifier unification-based used here is some-
what unfortunate, because unification is just a particular constraint-solving algorithm
applicable for certain kinds of constraint-based grammars. The term constraint-based
grammar is both less biased and more appropriate to modern formalisms in which
unification is only one of several constraint-solving methods. Historically, neither LFG
nor GPSG were originally thought of in terms of unification. GPSG features and fea-
ture constraints were seen as abbreviatory conventions for large collections of context-
</bodyText>
<page confidence="0.993754">
549
</page>
<note confidence="0.560199">
Computational Linguistics Volume 19, Number 3
</note>
<bodyText confidence="0.999915222222222">
free terminal categories (Gazdar 1982). LFG F-structures were seen as the result of a
congruence-closure equation-solving process after a sentence was fully analyzed into
constituents (C-structures; Bresnan and Kaplan 1982). Even the term unification in func-
tional unification grammar was chosen by Martin Kay as intuitively suggestive, and not
by analogy with Robinson&apos;s notion of unification.
Constraint-based grammar formalisms would not have gained the attention they
did if they did not have practical parsing and generation algorithms. As is the case
for programming languages, the impetus for giving a sound denotational semantics
to those formalisms arose in part from the need to prove the correctness of particular
implementation methods. However, Carpenter concentrates only in giving the denota-
tional semantics for a typical formalism, and does not show its correspondence to its
operational realization. Proofs of equivalence between denotational and operational
semantics are useful not only as examples of what needs to be done to show the cor-
rectness of a parsing or generation algorithm, but also for the insights they give on
the connections between the semantics of constraint-based formalisms, of logic pro-
grams, and of traditional formal language representations. The reader interested in
those aspects will have to turn elsewhere, especially again to Shieber&apos;s monograph
(1985).
</bodyText>
<subsectionHeader confidence="0.999914">
5.2 Logic Programs and Recursive Types
</subsectionHeader>
<bodyText confidence="0.999709625">
Carpenter&apos;s semantics of constraint-based grammars extends straightforwardly to the
form of definite-clause programming in Ait-Kaci and Nasr&apos;s (1986) LOGIN language,
although one might have hoped for a bit more information on the connection to con-
straint logic programming.
The formalization of recursive type constraints, which were first introduced in Nit-
Kaci&apos;s dissertation, is more challenging. Carpenter clarifies and completes Ait-Kaci&apos;s
work, and relates it nicely to the computational interpretation of the constraint-based
grammatical formalism, HPSG (Pollard and Sag 1987).
</bodyText>
<sectionHeader confidence="0.970334" genericHeader="conclusions">
6. Details
</sectionHeader>
<bodyText confidence="0.999864125">
The book is remarkably free of editorial errors, which can be particularly confusing
but difficult to catch in a mathematical text. Here are a few problems that seem to
have slipped through and could confuse the reader momentarily. The agr type seems
to be missing in the Conc set (13) for the example of Figure 2.11. In Definition 4.2,
and in a few other places, the convention that x = y is intended to mean x and y are
both defined and equal seems to be used without comment, but in other places the
definedness is explicitly stated. On page 130, first sentence, the reference must be to
&amp;quot;Prolog II and Prolog III&amp;quot;, not to &amp;quot;Prolog II and Prolog II.&amp;quot; On page 170, paragraph
before Lemma 12.6, the first sentence should read &amp;quot;Note that even for countably based
domains, there may be an uncountably infinite number of domain objects.&amp;quot; The term
&amp;quot;most-general morphism&amp;quot; used in definition 13.14 was not defined anywhere that I
could find, although there is some mention of pointwise ordering of morphisms (but
are there lubs in the order?). There seems to be something wrong in Definition 15.13. I
believe G@7r should be G, where G. is the result of resolving F along path 7r. Finally,
the initial point in the discussion of fan-out resolution in the limit on page 244 should
be ED, not F.
</bodyText>
<page confidence="0.98714">
550
</page>
<subsectionHeader confidence="0.536952">
Book Reviews
</subsectionHeader>
<bodyText confidence="0.970732944444445">
7. Conclusion
I believe that The Logic of Typed Feature Structures is essential for any practicing or
prospective researcher on feature-based grammar or knowledge representation for-
malisms and also very useful to researchers or graduate students in the grammar
formalisms area of computational linguistics. Nowhere else can one find all the main
mathematical analysis tools related to each other and all the central results carefully
proved. Many readers, however, will need to come equipped with the support of a
careful instructor or an attentive reading of a good introduction to the mathematical
theory of partial orders, for instance, Davey and Priestley&apos;s (1990) Introduction to Lat-
tices and Order. And those readers interested in the complexity of decision procedures
for feature logics or in implementing systems based on them will have to look else-
where for detailed algorithmic descriptions and complexity analyses of operations on
feature structures and formulas. Carpenter&apos;s book is more in the European tradition
that emphasizes algebraic models for formalisms than in the American tradition of
complexity analyses for deductive procedures. Both are important. The Logic of Typed
Feature Structures is the first systematic mapping of the landscape of feature logics,
but many of the underlying processes and mechanisms still await an equally adept
analysis.
</bodyText>
<sectionHeader confidence="0.936621" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9801596">
David Israel made several useful suggestions
on content and form, and Daniel Pereira
helped simplify and clarify the prose. All
remaining errors, obscurities, and biases are,
of course, my own.
</bodyText>
<sectionHeader confidence="0.875752" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.95983953968254">
Aho, A. V.; Hoperoft, J. E.; and Ullman, J. D.
(1976). The Design and Analysis of Computer
Algorithms. Addison-Wesley.
Hasan (1984). A lattice theoretic
approach to computation based on a calculus of
partially ordered type structures. Doctoral
dissertation, University of Pennsylvania,
Philadelphia, PA.
Ait-Kaci, Hasan, and Nasr, R. (1986).
&amp;quot;LOGIN: A logic programming language
with built-in inheritance.&amp;quot; Logic
Programming, 3(3), 185-217.
Alshawi, Hiyan, and Crouch, R. (1992).
&amp;quot;Monotonic semantic interpretation.&amp;quot; In
Proceedings, 30th Annual Meeting of the
Association for Computational Linguistics.
Newark DE, 32-39.
Blackburn, P. (1991). &amp;quot;Modal logic and
attribute value structures.&amp;quot; In Colloquium
on Modal Logic, edited by M. de Rijke.
Dutch Network for Language, Logic and
Information.
Bresnan, Joan, and Kaplan, Ronald (1982).
&amp;quot;Lexical-functional grammar: A formal
system for grammatical representation.&amp;quot; In
The Mental Representation of Grammatical
Relations, edited by Joan Bresnan, 173-281.
The MIT Press.
Colmerauer, Alain (1978). &amp;quot;Metamorphosis
grammars.&amp;quot; In Natural Language
Communication with Computers, edited by
L. Bolc. Springer-Verlag. (First appeared
as &amp;quot;Les grammaires de metamorphose,&amp;quot;
groupe d&apos;intelligence artificielle,
Universite de Marseille II, November
1975.)
Colmerauer, Alain (1986). &amp;quot;Theoretical
model of Prolog II.&amp;quot; In Logic Programming
and its Applications, edited by
M. van Caneghen and David H. D. Wane.
Ablex Series in Artificial Intelligence,
3-31. Ablex.
Davey, B. A., and Priestley, H. A. (1990).
Introduction to Lattices and Order.
Cambridge University Press.
Eisele, A., and Dorre, J. (1988). &amp;quot;Unification
of disjunctive feature descriptions.&amp;quot; In
Proceedings, 26th Annual Meeting of the
Association for Computational Linguistics.
Buffalo NY, 286-294.
Flickinger, Dan; Pollard, Carl; and Wasow,
Thomas (1985). &amp;quot;Structure-sharing in
lexical representation.&amp;quot; In Proceedings, 23rd
Annual Meeting of the Association for
Computational Linguistics. Chicago IL,
262-267.
Gazdar, Gerald (1982). &amp;quot;Phrase structure
grammar.&amp;quot; In The Nature of Syntactic
Representation, edited by Pauline Jacobson
and Geoffrey K. Pullum, 131-186. D.
Reidel.
Gazdar, Gerald; Klein, Ewan; Pullum,
Geoffrey K.; and Sag, Ivan (1985).
</reference>
<page confidence="0.991548">
551
</page>
<note confidence="0.519027">
Computational Linguistics Volume 19, Number 3
</note>
<reference confidence="0.994591205607476">
Generalized Phrase Structure Grammar.
Harvard University Press.
Hennessy, M., and Milner, R. (1985).
&amp;quot;Algebraic laws for nondeterminism and
concurrency.&amp;quot; Journal of the Association for
Computing Machinery, 32(1), 137-161.
Jaffar, J. (1984). &amp;quot;Efficient unification over
infinite terms.&amp;quot; New Generation Computing,
2(3), 207-219.
Kasper, Robert T. (1987). Feature structures: A
logical theory with application to language
analysis. Doctoral dissertation, University
of Michigan, Ann Arbor, Michigan.
Kasper, Robert T., and Rounds, William C.
(1986) &amp;quot;A logical semantics for feature
structures.&amp;quot; In Proceedings, 24th Annual
Meeting of the Association for Computational
Linguistics. New York, 257-266.
Kay, Martin (1985). &amp;quot;Parsing in functional
unification grammar.&amp;quot; In Natural Language
Parsing, edited by David R. Dowty, Lauri
Karttunen, and Arnold M. Zwicky,
251-278. Cambridge University Press.
Marcus, Mitchell P. (1980). A Theory of
Syntactic Recognition for Natural Language.
The MIT Press.
Marcus, Mitchell P.; Hindle, Donald; and
Fleck, Margaret (1983). &amp;quot;D-theory: Talking
about talking about trees.&amp;quot; In Proceedings,
21st Annual Meeting of the Association for
Computational Linguistics. Cambridge MA.
Martelli, A., and Montanan, U. (1982). &amp;quot;An
efficient unification algorithm.&amp;quot; ACM
Transactions on Programming Languages and
Systems, 4(2), 258-282.
Maxwell, J. T. III, and Kaplan, Ronald M.
(1989). &amp;quot;An overview of disjunctive
constraint satisfaction.&amp;quot; In Proceedings, First
International Workshop on Parsing Technology,
edited by Masaru Tomita. Pittsburgh PA.
Moshier, M. D., and Rounds, William C.
(1987). &amp;quot;A logic for partially specified data
structures.&amp;quot; In ACM Symposium on the
Principles of Programming Languages.
Munich, Germany.
Paterson, M. S., and Wegman, M. N. (1978).
&amp;quot;Linear unification.&amp;quot; Journal of Computer
and Systems Sciences, 16(2), 158-167.
Pereira, Fernando C., and Shieber, Stuart M.
(1984). &amp;quot;The semantics of grammar
formalisms seen as computer languages.&amp;quot;
In Proceedings of 1984 International
Computational Linguistics Conference.
Stanford CA, 123-129.
Pereira, Fernando C., and Warren, David
H. D. (1980). &amp;quot;Definite clause grammars
for language analysis-A survey of the
formalism and a comparison with
augmented transition networks.&amp;quot; Artificial
Intelligence, 13,231-278.
Pollard, Carl, and Sag, Ivan (1987).
Information-Based Syntax and Semantics,
Volume I: Fundamentals, Lecture notes 13.
Center for the Study of Language and
Information, Stanford CA.
Robinson, J. (1965). &amp;quot;A machine-oriented
logic based on the resolution principle.&amp;quot;
Journal of the Association for Computational
Machinery, 12(1), 23-44.
Rounds, William C., and Manaster-Ramer,
Alexis (1987). &amp;quot;A logical version of
functional grammar.&amp;quot; In Proceedings, 25th
Annual Meeting of the Association for
Computational Linguistics. Stanford CA,
89-96.
Saraswat, V. A. (1990). &amp;quot;JANUS: A step
towards distributed constraint
programming.&amp;quot; In Logic Programming:
Proceedings of the 1990 North American
Conference, edited by S. Debray and
M. Hermenegildo, 431-446. The MIT
Press.
Shieber, Stuart M. (1984). &amp;quot;The design of a
computer language for linguistic
information.&amp;quot; In Proceedings of 1984
International Computational Linguistics
Conference. Stanford CA, 362-366.
Shieber, Stuart M. (1985). An Introduction to
Unification-Based Approaches to Grammar,
Lecture notes 4. Center for the Study of
Language and Information, Stanford, CA.
Shieber, Stuart M. (1989). Parsing and type
inference for natural and computer languages.
Doctoral dissertation, Department of
Computer Science, Stanford University,
Stanford CA.
Shieber, Stuart M. (1992). Constraint-Based
Grammar Formalisms. The MIT Press.
Tarski, A. (1983). Logic, Semantics,
Metamathematics, Second edition. Hackett
Publishing Company.
Ueda, K. (1987). &amp;quot;Guarded Horn clauses.&amp;quot; In
Concurrent Prolog: Collected papers, edited
by Ehud Shapiro, 140-156. The MIT Press.
Fernando Pereira is president of the Association for Computational Linguistics. Pereira&apos;s address
is: AT&amp;T Bell Laboratories, 2D-447,600 Mountain Avenue, PO Box 636, Murray Hill, NJ 07974-
0636; e-mail: pereira@research.att.com.
</reference>
<page confidence="0.997623">
552
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.581536">
<title confidence="0.9066825">Computational Linguistics Volume 19, Number 3 The Logic of Typed Feature Structures</title>
<author confidence="0.999898">Bob Carpenter</author>
<affiliation confidence="0.999781">(Carnegie Mellon University)</affiliation>
<address confidence="0.989239">Cambridge, England: Cambridge</address>
<note confidence="0.947892833333333">University Press (Cambridge Tracts in Computer Science 32, edited by C. J. van Rijsbergen), 1992, viii + 270 pp. Hardbound, ISBN 0-521-41932-8, $34.95 Reviewed by</note>
<author confidence="0.992896">Fernando Pereira</author>
<affiliation confidence="0.956803">AT&amp;T Bell Laboratories</affiliation>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A V Aho</author>
<author>J E Hoperoft</author>
<author>J D Ullman</author>
</authors>
<title>The Design and Analysis of Computer Algorithms.</title>
<date>1976</date>
<publisher>Addison-Wesley.</publisher>
<marker>Aho, Hoperoft, Ullman, 1976</marker>
<rawString>Aho, A. V.; Hoperoft, J. E.; and Ullman, J. D. (1976). The Design and Analysis of Computer Algorithms. Addison-Wesley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hasan</author>
</authors>
<title>A lattice theoretic approach to computation based on a calculus of partially ordered type structures. Doctoral dissertation,</title>
<date>1984</date>
<institution>University of Pennsylvania,</institution>
<location>Philadelphia, PA.</location>
<marker>Hasan, 1984</marker>
<rawString>Hasan (1984). A lattice theoretic approach to computation based on a calculus of partially ordered type structures. Doctoral dissertation, University of Pennsylvania, Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hasan Ait-Kaci</author>
<author>R Nasr</author>
</authors>
<title>LOGIN: A logic programming language with built-in inheritance.&amp;quot;</title>
<date>1986</date>
<journal>Logic Programming,</journal>
<volume>3</volume>
<issue>3</issue>
<pages>185--217</pages>
<marker>Ait-Kaci, Nasr, 1986</marker>
<rawString>Ait-Kaci, Hasan, and Nasr, R. (1986). &amp;quot;LOGIN: A logic programming language with built-in inheritance.&amp;quot; Logic Programming, 3(3), 185-217.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiyan Alshawi</author>
<author>R Crouch</author>
</authors>
<title>Monotonic semantic interpretation.&amp;quot;</title>
<date>1992</date>
<booktitle>In Proceedings, 30th Annual Meeting of the Association for Computational Linguistics. Newark DE,</booktitle>
<pages>32--39</pages>
<contexts>
<context position="8860" citStr="Alshawi and Crouch 1992" startWordPosition="1308" endWordPosition="1311">ed, but the computational intractability arising from having to consider all the combinations of smaller alternative constraints into larger consistent constraints is bypassed. Finally, the radical route suggests a discipline of trying to replace as much as possible disjunctive or negative constraints by somewhat weaker kinds of underspecification that admit of purely conjunctive formulations. That program was already suggested in the context of deterministic parsing (d-theory) (Marcus, Hindle, and Fleck 1983), and more recently in the context of incremental monotonic semantic interpretation (Alshawi and Crouch 1992), and might also be profitably employed in the more abstract feature-logic setting. 2.4 Prerequisites I am well aware of the difficulties in determining what should be taken as a reasonable common background for readers in an interdisciplinary topic. There is little enough commonality in the theoretical backgrounds of computer scientists trained in different schools, and the common background becomes even more difficult to find when one wants to reach also theoretical linguists and AT researchers. Still, the introductory chapters, including their historical portions, seem to assume more than i</context>
</contexts>
<marker>Alshawi, Crouch, 1992</marker>
<rawString>Alshawi, Hiyan, and Crouch, R. (1992). &amp;quot;Monotonic semantic interpretation.&amp;quot; In Proceedings, 30th Annual Meeting of the Association for Computational Linguistics. Newark DE, 32-39.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Blackburn</author>
</authors>
<title>Modal logic and attribute value structures.&amp;quot; In Colloquium on Modal Logic, edited by M. de Rijke. Dutch Network for Language, Logic and Information.</title>
<date>1991</date>
<contexts>
<context position="5021" citStr="Blackburn 1991" startWordPosition="750" endWordPosition="751">basic system and all the major extensions and variations considered later. If something is missing in that comprehensive development, it might be some effort to relate feature logics to modal logics, and feature structures to modal frames. I believe that the original Kasper—Rounds logic was to some extent inspired by modal logics of concurrency, in particular the modal Hennessy—Milner logic for CCS (Hennessy and Milner 1985). It has also been argued that the connection to modal logic is an important route for easier and more general proofs of the required normal form and completeness results (Blackburn 1991). 2.2 Representations versus Algorithms The introductory part establishes the algebraic, denotational semantics orientation of the book, and throughout the book, the more computational aspects of feature logics receive little attention. In purely conjunctive feature logics such as those arising from PATR-II, there is a simple connection between formulas and models. An almost linear satisfiability procedure, based on the UNION-FIND algorithm (Aho, Hoperoft, and Ullman 1976, Ait-Kaci 1984, Jaffar 1984), can be used to build the unique most-general feature structure satisfying a formula. There is</context>
</contexts>
<marker>Blackburn, 1991</marker>
<rawString>Blackburn, P. (1991). &amp;quot;Modal logic and attribute value structures.&amp;quot; In Colloquium on Modal Logic, edited by M. de Rijke. Dutch Network for Language, Logic and Information.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joan Bresnan</author>
<author>Ronald Kaplan</author>
</authors>
<title>Lexical-functional grammar: A formal system for grammatical representation.&amp;quot;</title>
<date>1982</date>
<booktitle>In The Mental Representation of Grammatical Relations, edited by Joan Bresnan,</booktitle>
<pages>173--281</pages>
<contexts>
<context position="1032" citStr="Bresnan and Kaplan 1982" startWordPosition="139" endWordPosition="142">the &amp;quot;Bay Area (Computational) Linguistics Community,&amp;quot; the early eighties were a heady time. Local researchers working on linguistics, computational linguistics, and logic programming were investigating notions of category, type, feature, term, and partial specification that appeared to converge to a powerful new approach for describing (linguistic) objects and their relationships by monotonic accumulation of constraints between their features. The seed notions had almost independently arisen in generalized phrase structure grammar (GPSG) (Gazdar et al. 1985), lexical-functional grammar (LFG) (Bresnan and Kaplan 1982), functionalunification grammar (FUG) (Kay 1985), logic programming (Colmerauer 1978, Pereira and Warren 1980), and terminological reasoning systems (AIt-Kaci 1984). It took, however, a lot of experimental and theoretical work to identify precisely what the core notions were, how particular systems related to the core notions, and what were the most illuminating mathematical accounts of that core. The development of the unificationbased formalism PATR-II (Shieber 1984) was an early step toward the definition of the core, but its mathematical analysis, and the clarification of the connections b</context>
<context position="21737" citStr="Bresnan and Kaplan 1982" startWordPosition="3210" endWordPosition="3213">straint-based grammar is both less biased and more appropriate to modern formalisms in which unification is only one of several constraint-solving methods. Historically, neither LFG nor GPSG were originally thought of in terms of unification. GPSG features and feature constraints were seen as abbreviatory conventions for large collections of context549 Computational Linguistics Volume 19, Number 3 free terminal categories (Gazdar 1982). LFG F-structures were seen as the result of a congruence-closure equation-solving process after a sentence was fully analyzed into constituents (C-structures; Bresnan and Kaplan 1982). Even the term unification in functional unification grammar was chosen by Martin Kay as intuitively suggestive, and not by analogy with Robinson&apos;s notion of unification. Constraint-based grammar formalisms would not have gained the attention they did if they did not have practical parsing and generation algorithms. As is the case for programming languages, the impetus for giving a sound denotational semantics to those formalisms arose in part from the need to prove the correctness of particular implementation methods. However, Carpenter concentrates only in giving the denotational semantics </context>
</contexts>
<marker>Bresnan, Kaplan, 1982</marker>
<rawString>Bresnan, Joan, and Kaplan, Ronald (1982). &amp;quot;Lexical-functional grammar: A formal system for grammatical representation.&amp;quot; In The Mental Representation of Grammatical Relations, edited by Joan Bresnan, 173-281.</rawString>
</citation>
<citation valid="false">
<publisher>The MIT Press.</publisher>
<marker></marker>
<rawString>The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alain Colmerauer</author>
</authors>
<title>Metamorphosis grammars.&amp;quot; In Natural Language Communication with Computers, edited by</title>
<date>1978</date>
<contexts>
<context position="1116" citStr="Colmerauer 1978" startWordPosition="151" endWordPosition="152">ocal researchers working on linguistics, computational linguistics, and logic programming were investigating notions of category, type, feature, term, and partial specification that appeared to converge to a powerful new approach for describing (linguistic) objects and their relationships by monotonic accumulation of constraints between their features. The seed notions had almost independently arisen in generalized phrase structure grammar (GPSG) (Gazdar et al. 1985), lexical-functional grammar (LFG) (Bresnan and Kaplan 1982), functionalunification grammar (FUG) (Kay 1985), logic programming (Colmerauer 1978, Pereira and Warren 1980), and terminological reasoning systems (AIt-Kaci 1984). It took, however, a lot of experimental and theoretical work to identify precisely what the core notions were, how particular systems related to the core notions, and what were the most illuminating mathematical accounts of that core. The development of the unificationbased formalism PATR-II (Shieber 1984) was an early step toward the definition of the core, but its mathematical analysis, and the clarification of the connections between the various systems, are only now coming to a reasonable closure. The Logic o</context>
</contexts>
<marker>Colmerauer, 1978</marker>
<rawString>Colmerauer, Alain (1978). &amp;quot;Metamorphosis grammars.&amp;quot; In Natural Language Communication with Computers, edited by L. Bolc. Springer-Verlag. (First appeared as &amp;quot;Les grammaires de metamorphose,&amp;quot; groupe d&apos;intelligence artificielle, Universite de Marseille II, November 1975.)</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alain Colmerauer</author>
</authors>
<title>Theoretical model of Prolog II.&amp;quot; In Logic Programming and its Applications,</title>
<date>1986</date>
<booktitle>Ablex Series in Artificial Intelligence,</booktitle>
<pages>3--31</pages>
<publisher>Ablex.</publisher>
<note>edited by</note>
<contexts>
<context position="15226" citStr="Colmerauer 1986" startWordPosition="2271" endWordPosition="2272">eption of GPSG (which was limited in other ways). Type constraints support good engineering practice in writing large systems such as wide-coverage grammars. Furthermore, in certain cases type information can lead to more efficient implementation. If the set of features for each type can be determined at compile time, the normal open-ended attribute—value representation of features can be replaced by the kind of positional representation used for record structures in programming languages such as C. Carpenter starts the discussion of inequations from the Prolog II inequation (dif ) mechanism (Colmerauer 1986), and extends it elegantly to feature logics. The simplicity of the account shows that the earlier exposition was carefully orchestrated to allow extensions and alterations of the core framework without major upheavals. 3.1 Extensionality I was somewhat less happy about the chapters on extensionality and groundedness. That material seems less definitive, and indeed various points of the discussion are confusing or unclearly targeted. There are conceptual and formal reasons for taking seriously the extensionality question. Different researchers in the field started with different intuitions of </context>
</contexts>
<marker>Colmerauer, 1986</marker>
<rawString>Colmerauer, Alain (1986). &amp;quot;Theoretical model of Prolog II.&amp;quot; In Logic Programming and its Applications, edited by M. van Caneghen and David H. D. Wane. Ablex Series in Artificial Intelligence, 3-31. Ablex.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B A Davey</author>
<author>H A Priestley</author>
</authors>
<title>Introduction to Lattices and Order.</title>
<date>1990</date>
<publisher>Cambridge University Press.</publisher>
<marker>Davey, Priestley, 1990</marker>
<rawString>Davey, B. A., and Priestley, H. A. (1990). Introduction to Lattices and Order. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Eisele</author>
<author>J Dorre</author>
</authors>
<title>Unification of disjunctive feature descriptions.&amp;quot;</title>
<date>1988</date>
<booktitle>In Proceedings, 26th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<pages>286--294</pages>
<location>Buffalo NY,</location>
<contexts>
<context position="7278" citStr="Eisele and Dorre 1988" startWordPosition="1073" endWordPosition="1076">nal issues just discussed. The intractability of satisfiability for expressive feature logics might seem a serious roadblock in the practical application of those logics in grammatical description systems. Two escape routes, one pragmatic and the other more radical, suggest themselves. The pragmatic route involves trying to identify more tractable subcases that may cover most of the situations of interest in actual grammatical description. Such &amp;quot;optimistic&amp;quot; algorithms were already suggested in Kasper&apos;s dissertation (1987), and have been extensively investigated since (Maxwell and Kaplan 1989; Eisele and Dorre 1988). The more radical route, which as far as I know has not been pursued vigorously, looks more closely at the search control aspects of language processing systems based on feature computations. It takes conjunctive description as the only one that can have global extent in a computation. Nonconjunctive aspects of a description are then ephemeral in that nonconjunctive connectives introduced in a derivation must be eliminated within a bounded number of steps by a committed choice operation based on some preference-based search control mechanism. Such a view can be seen as a mild generalization o</context>
</contexts>
<marker>Eisele, Dorre, 1988</marker>
<rawString>Eisele, A., and Dorre, J. (1988). &amp;quot;Unification of disjunctive feature descriptions.&amp;quot; In Proceedings, 26th Annual Meeting of the Association for Computational Linguistics. Buffalo NY, 286-294.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Flickinger</author>
<author>Carl Pollard</author>
<author>Thomas Wasow</author>
</authors>
<title>Structure-sharing in lexical representation.&amp;quot;</title>
<date>1985</date>
<booktitle>In Proceedings, 23rd Annual Meeting of the Association for Computational Linguistics. Chicago IL,</booktitle>
<pages>262--267</pages>
<marker>Flickinger, Pollard, Wasow, 1985</marker>
<rawString>Flickinger, Dan; Pollard, Carl; and Wasow, Thomas (1985). &amp;quot;Structure-sharing in lexical representation.&amp;quot; In Proceedings, 23rd Annual Meeting of the Association for Computational Linguistics. Chicago IL, 262-267.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerald Gazdar</author>
</authors>
<title>Phrase structure grammar.&amp;quot;</title>
<date>1982</date>
<booktitle>In The Nature of Syntactic Representation, edited by Pauline Jacobson and</booktitle>
<contexts>
<context position="21552" citStr="Gazdar 1982" startWordPosition="3187" endWordPosition="3188">d here is somewhat unfortunate, because unification is just a particular constraint-solving algorithm applicable for certain kinds of constraint-based grammars. The term constraint-based grammar is both less biased and more appropriate to modern formalisms in which unification is only one of several constraint-solving methods. Historically, neither LFG nor GPSG were originally thought of in terms of unification. GPSG features and feature constraints were seen as abbreviatory conventions for large collections of context549 Computational Linguistics Volume 19, Number 3 free terminal categories (Gazdar 1982). LFG F-structures were seen as the result of a congruence-closure equation-solving process after a sentence was fully analyzed into constituents (C-structures; Bresnan and Kaplan 1982). Even the term unification in functional unification grammar was chosen by Martin Kay as intuitively suggestive, and not by analogy with Robinson&apos;s notion of unification. Constraint-based grammar formalisms would not have gained the attention they did if they did not have practical parsing and generation algorithms. As is the case for programming languages, the impetus for giving a sound denotational semantics </context>
</contexts>
<marker>Gazdar, 1982</marker>
<rawString>Gazdar, Gerald (1982). &amp;quot;Phrase structure grammar.&amp;quot; In The Nature of Syntactic Representation, edited by Pauline Jacobson and Geoffrey K. Pullum, 131-186. D. Reidel.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerald Gazdar</author>
<author>Ewan Klein</author>
<author>Geoffrey K Pullum</author>
<author>Ivan Sag</author>
</authors>
<date>1985</date>
<contexts>
<context position="972" citStr="Gazdar et al. 1985" startWordPosition="132" endWordPosition="135">tories 1. Introduction For those of us who belonged to the &amp;quot;Bay Area (Computational) Linguistics Community,&amp;quot; the early eighties were a heady time. Local researchers working on linguistics, computational linguistics, and logic programming were investigating notions of category, type, feature, term, and partial specification that appeared to converge to a powerful new approach for describing (linguistic) objects and their relationships by monotonic accumulation of constraints between their features. The seed notions had almost independently arisen in generalized phrase structure grammar (GPSG) (Gazdar et al. 1985), lexical-functional grammar (LFG) (Bresnan and Kaplan 1982), functionalunification grammar (FUG) (Kay 1985), logic programming (Colmerauer 1978, Pereira and Warren 1980), and terminological reasoning systems (AIt-Kaci 1984). It took, however, a lot of experimental and theoretical work to identify precisely what the core notions were, how particular systems related to the core notions, and what were the most illuminating mathematical accounts of that core. The development of the unificationbased formalism PATR-II (Shieber 1984) was an early step toward the definition of the core, but its mathe</context>
</contexts>
<marker>Gazdar, Klein, Pullum, Sag, 1985</marker>
<rawString>Gazdar, Gerald; Klein, Ewan; Pullum, Geoffrey K.; and Sag, Ivan (1985).</rawString>
</citation>
<citation valid="false">
<title>Generalized Phrase Structure Grammar.</title>
<publisher>Harvard University Press.</publisher>
<marker></marker>
<rawString>Generalized Phrase Structure Grammar. Harvard University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Hennessy</author>
<author>R Milner</author>
</authors>
<title>Algebraic laws for nondeterminism and concurrency.&amp;quot;</title>
<date>1985</date>
<journal>Journal of the Association for Computing Machinery,</journal>
<volume>32</volume>
<issue>1</issue>
<pages>137--161</pages>
<contexts>
<context position="4834" citStr="Hennessy and Milner 1985" startWordPosition="717" endWordPosition="720">ics. 2.1 Feature Structures and Feature Logics The fruitful connection between feature structures and feature logics is pursued throughout the book, with soundness and completeness results for the basic system and all the major extensions and variations considered later. If something is missing in that comprehensive development, it might be some effort to relate feature logics to modal logics, and feature structures to modal frames. I believe that the original Kasper—Rounds logic was to some extent inspired by modal logics of concurrency, in particular the modal Hennessy—Milner logic for CCS (Hennessy and Milner 1985). It has also been argued that the connection to modal logic is an important route for easier and more general proofs of the required normal form and completeness results (Blackburn 1991). 2.2 Representations versus Algorithms The introductory part establishes the algebraic, denotational semantics orientation of the book, and throughout the book, the more computational aspects of feature logics receive little attention. In purely conjunctive feature logics such as those arising from PATR-II, there is a simple connection between formulas and models. An almost linear satisfiability procedure, ba</context>
</contexts>
<marker>Hennessy, Milner, 1985</marker>
<rawString>Hennessy, M., and Milner, R. (1985). &amp;quot;Algebraic laws for nondeterminism and concurrency.&amp;quot; Journal of the Association for Computing Machinery, 32(1), 137-161.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Jaffar</author>
</authors>
<title>Efficient unification over infinite terms.&amp;quot;</title>
<date>1984</date>
<journal>New Generation Computing,</journal>
<volume>2</volume>
<issue>3</issue>
<pages>207--219</pages>
<contexts>
<context position="5526" citStr="Jaffar 1984" startWordPosition="819" endWordPosition="820">te for easier and more general proofs of the required normal form and completeness results (Blackburn 1991). 2.2 Representations versus Algorithms The introductory part establishes the algebraic, denotational semantics orientation of the book, and throughout the book, the more computational aspects of feature logics receive little attention. In purely conjunctive feature logics such as those arising from PATR-II, there is a simple connection between formulas and models. An almost linear satisfiability procedure, based on the UNION-FIND algorithm (Aho, Hoperoft, and Ullman 1976, Ait-Kaci 1984, Jaffar 1984), can be used to build the unique most-general feature structure satisfying a formula. There is thus relatively little to say about computational complexity (but not about practical computation costs, as will be observed below when rational unification is discussed), and the algebraic approach is direct and instructive. When we move to more-expressive feature logics, however, the situation changes radically. There are no longer unique most-general models, the algebraic approach becomes more labored, and satisfiability becomes NP-hard or worse. Computational complexity results were a central pa</context>
<context position="17673" citStr="Jaffar 1984" startWordPosition="2621" endWordPosition="2622">nship between extensionality and Prolog II unification is hinted at repeatedly, but its computational implications are not discussed. The differences in extensionality of feature structures and Prolog II terms are directly reflected in the differences between the corresponding unification algorithms. Feature-structure unification requires the identification of all corresponding feature-structure nodes, while term unification (leaving aside issues of computational complexity and termination in certain algorithms) only needs to install pointers from leaf (variable) nodes to corresponding nodes (Jaffar 1984). Other algorithmic connections are not noted either, such as that between feature structure collapsing and DFA minimization. Finally, issues of extensionality and individuation may be most important for object-oriented databases, but that application is not discussed. 548 Book Reviews 4. Alternatives The third part of the book, named &amp;quot;Alternatives,&amp;quot; is really an introduction to technical tools needed in later applications. Variables and assignments add nothing to the power of previous systems, but are convenient when discussing grammars and in another form were historically important in Ait-K</context>
</contexts>
<marker>Jaffar, 1984</marker>
<rawString>Jaffar, J. (1984). &amp;quot;Efficient unification over infinite terms.&amp;quot; New Generation Computing, 2(3), 207-219.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert T Kasper</author>
</authors>
<title>Feature structures: A logical theory with application to language analysis. Doctoral dissertation,</title>
<date>1987</date>
<institution>University of Michigan,</institution>
<location>Ann Arbor, Michigan.</location>
<marker>Kasper, 1987</marker>
<rawString>Kasper, Robert T. (1987). Feature structures: A logical theory with application to language analysis. Doctoral dissertation, University of Michigan, Ann Arbor, Michigan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert T Kasper</author>
<author>William C Rounds</author>
</authors>
<title>A logical semantics for feature structures.&amp;quot;</title>
<date>1986</date>
<booktitle>In Proceedings, 24th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<pages>257--266</pages>
<location>New York,</location>
<contexts>
<context position="4104" citStr="Kasper and Rounds (1986)" startWordPosition="606" endWordPosition="609">layed no direct role in LFG, GPSG, PATR-II, or logic grammars, and it came into play first as a lexicon organization discipline (Flickinger, Pollard, and Wasow 1985; Sheiber 1985), not as a central part of the formalism. The organization of the first part of the book follows naturally from the emphasis on KR ideas. Types and inheritance are discussed first, followed by feature (attribute— value) structures and the relations and operations that they inherit from the underlying type system: subsumption and join (unification). The last introductory chapter addresses in detail the crucial move of Kasper and Rounds (1986) to clarify the meaning of feature structures by viewing them as models of appropriately chosen modal logics. 2.1 Feature Structures and Feature Logics The fruitful connection between feature structures and feature logics is pursued throughout the book, with soundness and completeness results for the basic system and all the major extensions and variations considered later. If something is missing in that comprehensive development, it might be some effort to relate feature logics to modal logics, and feature structures to modal frames. I believe that the original Kasper—Rounds logic was to som</context>
<context position="6236" citStr="Kasper and Rounds 1986" startWordPosition="921" endWordPosition="924">here is thus relatively little to say about computational complexity (but not about practical computation costs, as will be observed below when rational unification is discussed), and the algebraic approach is direct and instructive. When we move to more-expressive feature logics, however, the situation changes radically. There are no longer unique most-general models, the algebraic approach becomes more labored, and satisfiability becomes NP-hard or worse. Computational complexity results were a central part of the development of the more-expressive feature logics by Rounds, Kasper, Moshier (Kasper and Rounds 1986, Moshier and Rounds 1987) and others, but they are barely mentioned in Carpenter&apos;s book. One feels that those results, being of a more traditional (finite) model-theoretic character, may have been left out because they do not fit the book&apos;s algebraic plan. 545 Computational Linguistics Volume 19, Number 3 2.3 Feature Logic Intractability and Natural Language Processing A more general point arises from the computational issues just discussed. The intractability of satisfiability for expressive feature logics might seem a serious roadblock in the practical application of those logics in grammat</context>
</contexts>
<marker>Kasper, Rounds, 1986</marker>
<rawString>Kasper, Robert T., and Rounds, William C. (1986) &amp;quot;A logical semantics for feature structures.&amp;quot; In Proceedings, 24th Annual Meeting of the Association for Computational Linguistics. New York, 257-266.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Kay</author>
</authors>
<title>Parsing in functional unification grammar.&amp;quot; In Natural Language Parsing, edited by</title>
<date>1985</date>
<pages>251--278</pages>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="1080" citStr="Kay 1985" startWordPosition="147" endWordPosition="148"> eighties were a heady time. Local researchers working on linguistics, computational linguistics, and logic programming were investigating notions of category, type, feature, term, and partial specification that appeared to converge to a powerful new approach for describing (linguistic) objects and their relationships by monotonic accumulation of constraints between their features. The seed notions had almost independently arisen in generalized phrase structure grammar (GPSG) (Gazdar et al. 1985), lexical-functional grammar (LFG) (Bresnan and Kaplan 1982), functionalunification grammar (FUG) (Kay 1985), logic programming (Colmerauer 1978, Pereira and Warren 1980), and terminological reasoning systems (AIt-Kaci 1984). It took, however, a lot of experimental and theoretical work to identify precisely what the core notions were, how particular systems related to the core notions, and what were the most illuminating mathematical accounts of that core. The development of the unificationbased formalism PATR-II (Shieber 1984) was an early step toward the definition of the core, but its mathematical analysis, and the clarification of the connections between the various systems, are only now coming </context>
</contexts>
<marker>Kay, 1985</marker>
<rawString>Kay, Martin (1985). &amp;quot;Parsing in functional unification grammar.&amp;quot; In Natural Language Parsing, edited by David R. Dowty, Lauri Karttunen, and Arnold M. Zwicky, 251-278. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
</authors>
<title>A Theory of Syntactic Recognition for Natural Language.</title>
<date>1980</date>
<publisher>The MIT Press.</publisher>
<contexts>
<context position="7928" citStr="Marcus 1980" startWordPosition="1178" endWordPosition="1179"> as I know has not been pursued vigorously, looks more closely at the search control aspects of language processing systems based on feature computations. It takes conjunctive description as the only one that can have global extent in a computation. Nonconjunctive aspects of a description are then ephemeral in that nonconjunctive connectives introduced in a derivation must be eliminated within a bounded number of steps by a committed choice operation based on some preference-based search control mechanism. Such a view can be seen as a mild generalization of the ideas of deterministic parsing (Marcus 1980), and also closely related to the flat-guard committed choice logic programming languages (Ueda 1987; Saraswat 1990). In both of those frameworks a single conjunctive constraint is constructed incrementally on the basis of local committed choices among alternatives. Search completeness is of course sacrificed, but the computational intractability arising from having to consider all the combinations of smaller alternative constraints into larger consistent constraints is bypassed. Finally, the radical route suggests a discipline of trying to replace as much as possible disjunctive or negative c</context>
</contexts>
<marker>Marcus, 1980</marker>
<rawString>Marcus, Mitchell P. (1980). A Theory of Syntactic Recognition for Natural Language. The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Donald Hindle</author>
<author>Margaret Fleck</author>
</authors>
<title>D-theory: Talking about talking about trees.&amp;quot;</title>
<date>1983</date>
<booktitle>In Proceedings, 21st Annual Meeting of the Association for Computational Linguistics.</booktitle>
<location>Cambridge MA.</location>
<marker>Marcus, Hindle, Fleck, 1983</marker>
<rawString>Marcus, Mitchell P.; Hindle, Donald; and Fleck, Margaret (1983). &amp;quot;D-theory: Talking about talking about trees.&amp;quot; In Proceedings, 21st Annual Meeting of the Association for Computational Linguistics. Cambridge MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Martelli</author>
<author>U Montanan</author>
</authors>
<title>An efficient unification algorithm.&amp;quot;</title>
<date>1982</date>
<journal>ACM Transactions on Programming Languages and Systems,</journal>
<volume>4</volume>
<issue>2</issue>
<pages>258--282</pages>
<marker>Martelli, Montanan, 1982</marker>
<rawString>Martelli, A., and Montanan, U. (1982). &amp;quot;An efficient unification algorithm.&amp;quot; ACM Transactions on Programming Languages and Systems, 4(2), 258-282.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J T Maxwell</author>
<author>Ronald M Kaplan</author>
</authors>
<title>An overview of disjunctive constraint satisfaction.&amp;quot; In</title>
<date>1989</date>
<booktitle>Proceedings, First International Workshop on Parsing Technology, edited by Masaru Tomita.</booktitle>
<location>Pittsburgh PA.</location>
<contexts>
<context position="7254" citStr="Maxwell and Kaplan 1989" startWordPosition="1069" endWordPosition="1072">rises from the computational issues just discussed. The intractability of satisfiability for expressive feature logics might seem a serious roadblock in the practical application of those logics in grammatical description systems. Two escape routes, one pragmatic and the other more radical, suggest themselves. The pragmatic route involves trying to identify more tractable subcases that may cover most of the situations of interest in actual grammatical description. Such &amp;quot;optimistic&amp;quot; algorithms were already suggested in Kasper&apos;s dissertation (1987), and have been extensively investigated since (Maxwell and Kaplan 1989; Eisele and Dorre 1988). The more radical route, which as far as I know has not been pursued vigorously, looks more closely at the search control aspects of language processing systems based on feature computations. It takes conjunctive description as the only one that can have global extent in a computation. Nonconjunctive aspects of a description are then ephemeral in that nonconjunctive connectives introduced in a derivation must be eliminated within a bounded number of steps by a committed choice operation based on some preference-based search control mechanism. Such a view can be seen as</context>
</contexts>
<marker>Maxwell, Kaplan, 1989</marker>
<rawString>Maxwell, J. T. III, and Kaplan, Ronald M. (1989). &amp;quot;An overview of disjunctive constraint satisfaction.&amp;quot; In Proceedings, First International Workshop on Parsing Technology, edited by Masaru Tomita. Pittsburgh PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M D Moshier</author>
<author>William C Rounds</author>
</authors>
<title>A logic for partially specified data structures.&amp;quot;</title>
<date>1987</date>
<booktitle>In ACM Symposium on the Principles of Programming Languages.</booktitle>
<location>Munich, Germany.</location>
<contexts>
<context position="6262" citStr="Moshier and Rounds 1987" startWordPosition="925" endWordPosition="928">little to say about computational complexity (but not about practical computation costs, as will be observed below when rational unification is discussed), and the algebraic approach is direct and instructive. When we move to more-expressive feature logics, however, the situation changes radically. There are no longer unique most-general models, the algebraic approach becomes more labored, and satisfiability becomes NP-hard or worse. Computational complexity results were a central part of the development of the more-expressive feature logics by Rounds, Kasper, Moshier (Kasper and Rounds 1986, Moshier and Rounds 1987) and others, but they are barely mentioned in Carpenter&apos;s book. One feels that those results, being of a more traditional (finite) model-theoretic character, may have been left out because they do not fit the book&apos;s algebraic plan. 545 Computational Linguistics Volume 19, Number 3 2.3 Feature Logic Intractability and Natural Language Processing A more general point arises from the computational issues just discussed. The intractability of satisfiability for expressive feature logics might seem a serious roadblock in the practical application of those logics in grammatical description systems. </context>
</contexts>
<marker>Moshier, Rounds, 1987</marker>
<rawString>Moshier, M. D., and Rounds, William C. (1987). &amp;quot;A logic for partially specified data structures.&amp;quot; In ACM Symposium on the Principles of Programming Languages. Munich, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M S Paterson</author>
<author>M N Wegman</author>
</authors>
<title>Linear unification.&amp;quot;</title>
<date>1978</date>
<journal>Journal of Computer and Systems Sciences,</journal>
<volume>16</volume>
<issue>2</issue>
<pages>158--167</pages>
<marker>Paterson, Wegman, 1978</marker>
<rawString>Paterson, M. S., and Wegman, M. N. (1978). &amp;quot;Linear unification.&amp;quot; Journal of Computer and Systems Sciences, 16(2), 158-167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernando C Pereira</author>
<author>Stuart M Shieber</author>
</authors>
<title>The semantics of grammar formalisms seen as computer languages.&amp;quot;</title>
<date>1984</date>
<booktitle>In Proceedings of 1984 International Computational Linguistics Conference. Stanford CA,</booktitle>
<pages>123--129</pages>
<contexts>
<context position="20823" citStr="Pereira and Shieber 1984" startWordPosition="3085" endWordPosition="3088">ed phrase structure formalisms, the semantics of feature-based definite clause programs, and the specification of recursive type constraints. 5.1 Semantics of Grammar Formalisms Carpenter&apos;s account of the denotational semantics of unification-based phrase structure grammars benefits greatly from the extensive use of feature algebras and featurealgebra morphisms to connect derivation steps. Earlier treatments were much less perspicuous, because they were based on complex encodings of phrase-structure rules as feature structures and of derivation steps as formal manipulations on rule encodings (Pereira and Shieber 1984; Shieber 1984; Rounds and Manaster-Ramer 1987). As a minor terminological point, the qualifier unification-based used here is somewhat unfortunate, because unification is just a particular constraint-solving algorithm applicable for certain kinds of constraint-based grammars. The term constraint-based grammar is both less biased and more appropriate to modern formalisms in which unification is only one of several constraint-solving methods. Historically, neither LFG nor GPSG were originally thought of in terms of unification. GPSG features and feature constraints were seen as abbreviatory con</context>
</contexts>
<marker>Pereira, Shieber, 1984</marker>
<rawString>Pereira, Fernando C., and Shieber, Stuart M. (1984). &amp;quot;The semantics of grammar formalisms seen as computer languages.&amp;quot; In Proceedings of 1984 International Computational Linguistics Conference. Stanford CA, 123-129.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernando C Pereira</author>
<author>David H D Warren</author>
</authors>
<title>Definite clause grammars for language analysis-A survey of the formalism and a comparison with augmented transition networks.&amp;quot;</title>
<date>1980</date>
<journal>Artificial Intelligence,</journal>
<pages>13--231</pages>
<contexts>
<context position="1142" citStr="Pereira and Warren 1980" startWordPosition="153" endWordPosition="156">working on linguistics, computational linguistics, and logic programming were investigating notions of category, type, feature, term, and partial specification that appeared to converge to a powerful new approach for describing (linguistic) objects and their relationships by monotonic accumulation of constraints between their features. The seed notions had almost independently arisen in generalized phrase structure grammar (GPSG) (Gazdar et al. 1985), lexical-functional grammar (LFG) (Bresnan and Kaplan 1982), functionalunification grammar (FUG) (Kay 1985), logic programming (Colmerauer 1978, Pereira and Warren 1980), and terminological reasoning systems (AIt-Kaci 1984). It took, however, a lot of experimental and theoretical work to identify precisely what the core notions were, how particular systems related to the core notions, and what were the most illuminating mathematical accounts of that core. The development of the unificationbased formalism PATR-II (Shieber 1984) was an early step toward the definition of the core, but its mathematical analysis, and the clarification of the connections between the various systems, are only now coming to a reasonable closure. The Logic of Typed Feature Structures</context>
</contexts>
<marker>Pereira, Warren, 1980</marker>
<rawString>Pereira, Fernando C., and Warren, David H. D. (1980). &amp;quot;Definite clause grammars for language analysis-A survey of the formalism and a comparison with augmented transition networks.&amp;quot; Artificial Intelligence, 13,231-278.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carl Pollard</author>
<author>Ivan Sag</author>
</authors>
<title>Information-Based Syntax and Semantics, Volume I: Fundamentals, Lecture notes 13. Center for the Study of Language and Information,</title>
<date>1987</date>
<location>Stanford CA.</location>
<contexts>
<context position="23536" citStr="Pollard and Sag 1987" startWordPosition="3472" endWordPosition="3475">5.2 Logic Programs and Recursive Types Carpenter&apos;s semantics of constraint-based grammars extends straightforwardly to the form of definite-clause programming in Ait-Kaci and Nasr&apos;s (1986) LOGIN language, although one might have hoped for a bit more information on the connection to constraint logic programming. The formalization of recursive type constraints, which were first introduced in NitKaci&apos;s dissertation, is more challenging. Carpenter clarifies and completes Ait-Kaci&apos;s work, and relates it nicely to the computational interpretation of the constraint-based grammatical formalism, HPSG (Pollard and Sag 1987). 6. Details The book is remarkably free of editorial errors, which can be particularly confusing but difficult to catch in a mathematical text. Here are a few problems that seem to have slipped through and could confuse the reader momentarily. The agr type seems to be missing in the Conc set (13) for the example of Figure 2.11. In Definition 4.2, and in a few other places, the convention that x = y is intended to mean x and y are both defined and equal seems to be used without comment, but in other places the definedness is explicitly stated. On page 130, first sentence, the reference must be</context>
</contexts>
<marker>Pollard, Sag, 1987</marker>
<rawString>Pollard, Carl, and Sag, Ivan (1987). Information-Based Syntax and Semantics, Volume I: Fundamentals, Lecture notes 13. Center for the Study of Language and Information, Stanford CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Robinson</author>
</authors>
<title>A machine-oriented logic based on the resolution principle.&amp;quot;</title>
<date>1965</date>
<journal>Journal of the Association for Computational Machinery,</journal>
<volume>12</volume>
<issue>1</issue>
<pages>23--44</pages>
<marker>Robinson, 1965</marker>
<rawString>Robinson, J. (1965). &amp;quot;A machine-oriented logic based on the resolution principle.&amp;quot; Journal of the Association for Computational Machinery, 12(1), 23-44.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William C Rounds</author>
<author>Alexis Manaster-Ramer</author>
</authors>
<title>A logical version of functional grammar.&amp;quot;</title>
<date>1987</date>
<booktitle>In Proceedings, 25th Annual Meeting of the Association for Computational Linguistics. Stanford CA,</booktitle>
<pages>89--96</pages>
<contexts>
<context position="20870" citStr="Rounds and Manaster-Ramer 1987" startWordPosition="3091" endWordPosition="3094">ntics of feature-based definite clause programs, and the specification of recursive type constraints. 5.1 Semantics of Grammar Formalisms Carpenter&apos;s account of the denotational semantics of unification-based phrase structure grammars benefits greatly from the extensive use of feature algebras and featurealgebra morphisms to connect derivation steps. Earlier treatments were much less perspicuous, because they were based on complex encodings of phrase-structure rules as feature structures and of derivation steps as formal manipulations on rule encodings (Pereira and Shieber 1984; Shieber 1984; Rounds and Manaster-Ramer 1987). As a minor terminological point, the qualifier unification-based used here is somewhat unfortunate, because unification is just a particular constraint-solving algorithm applicable for certain kinds of constraint-based grammars. The term constraint-based grammar is both less biased and more appropriate to modern formalisms in which unification is only one of several constraint-solving methods. Historically, neither LFG nor GPSG were originally thought of in terms of unification. GPSG features and feature constraints were seen as abbreviatory conventions for large collections of context549 Co</context>
</contexts>
<marker>Rounds, Manaster-Ramer, 1987</marker>
<rawString>Rounds, William C., and Manaster-Ramer, Alexis (1987). &amp;quot;A logical version of functional grammar.&amp;quot; In Proceedings, 25th Annual Meeting of the Association for Computational Linguistics. Stanford CA, 89-96.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V A Saraswat</author>
</authors>
<title>JANUS: A step towards distributed constraint programming.&amp;quot;</title>
<date>1990</date>
<booktitle>In Logic Programming: Proceedings of the 1990 North American Conference,</booktitle>
<pages>431--446</pages>
<publisher>The MIT Press.</publisher>
<note>edited by</note>
<contexts>
<context position="8044" citStr="Saraswat 1990" startWordPosition="1194" endWordPosition="1195">g systems based on feature computations. It takes conjunctive description as the only one that can have global extent in a computation. Nonconjunctive aspects of a description are then ephemeral in that nonconjunctive connectives introduced in a derivation must be eliminated within a bounded number of steps by a committed choice operation based on some preference-based search control mechanism. Such a view can be seen as a mild generalization of the ideas of deterministic parsing (Marcus 1980), and also closely related to the flat-guard committed choice logic programming languages (Ueda 1987; Saraswat 1990). In both of those frameworks a single conjunctive constraint is constructed incrementally on the basis of local committed choices among alternatives. Search completeness is of course sacrificed, but the computational intractability arising from having to consider all the combinations of smaller alternative constraints into larger consistent constraints is bypassed. Finally, the radical route suggests a discipline of trying to replace as much as possible disjunctive or negative constraints by somewhat weaker kinds of underspecification that admit of purely conjunctive formulations. That progra</context>
</contexts>
<marker>Saraswat, 1990</marker>
<rawString>Saraswat, V. A. (1990). &amp;quot;JANUS: A step towards distributed constraint programming.&amp;quot; In Logic Programming: Proceedings of the 1990 North American Conference, edited by S. Debray and M. Hermenegildo, 431-446. The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart M Shieber</author>
</authors>
<title>The design of a computer language for linguistic information.&amp;quot;</title>
<date>1984</date>
<booktitle>In Proceedings of 1984 International Computational Linguistics Conference. Stanford CA,</booktitle>
<pages>362--366</pages>
<contexts>
<context position="1505" citStr="Shieber 1984" startWordPosition="210" endWordPosition="211">ently arisen in generalized phrase structure grammar (GPSG) (Gazdar et al. 1985), lexical-functional grammar (LFG) (Bresnan and Kaplan 1982), functionalunification grammar (FUG) (Kay 1985), logic programming (Colmerauer 1978, Pereira and Warren 1980), and terminological reasoning systems (AIt-Kaci 1984). It took, however, a lot of experimental and theoretical work to identify precisely what the core notions were, how particular systems related to the core notions, and what were the most illuminating mathematical accounts of that core. The development of the unificationbased formalism PATR-II (Shieber 1984) was an early step toward the definition of the core, but its mathematical analysis, and the clarification of the connections between the various systems, are only now coming to a reasonable closure. The Logic of Typed Feature Structures is the first monograph that brings all the main theoretical ideas into one place where they can be related and compared in a unified setting. Carpenter&apos;s book touches most of the crucial questions of the developments during the decade, provides proofs for central results, and reaches right up to the edge of current research in the field. These contributions al</context>
<context position="20823" citStr="Shieber 1984" startWordPosition="3087" endWordPosition="3088">ructure formalisms, the semantics of feature-based definite clause programs, and the specification of recursive type constraints. 5.1 Semantics of Grammar Formalisms Carpenter&apos;s account of the denotational semantics of unification-based phrase structure grammars benefits greatly from the extensive use of feature algebras and featurealgebra morphisms to connect derivation steps. Earlier treatments were much less perspicuous, because they were based on complex encodings of phrase-structure rules as feature structures and of derivation steps as formal manipulations on rule encodings (Pereira and Shieber 1984; Shieber 1984; Rounds and Manaster-Ramer 1987). As a minor terminological point, the qualifier unification-based used here is somewhat unfortunate, because unification is just a particular constraint-solving algorithm applicable for certain kinds of constraint-based grammars. The term constraint-based grammar is both less biased and more appropriate to modern formalisms in which unification is only one of several constraint-solving methods. Historically, neither LFG nor GPSG were originally thought of in terms of unification. GPSG features and feature constraints were seen as abbreviatory con</context>
</contexts>
<marker>Shieber, 1984</marker>
<rawString>Shieber, Stuart M. (1984). &amp;quot;The design of a computer language for linguistic information.&amp;quot; In Proceedings of 1984 International Computational Linguistics Conference. Stanford CA, 362-366.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart M Shieber</author>
</authors>
<title>An Introduction to Unification-Based Approaches to Grammar, Lecture notes 4. Center for the Study of Language and Information,</title>
<date>1985</date>
<location>Stanford, CA.</location>
<marker>Shieber, 1985</marker>
<rawString>Shieber, Stuart M. (1985). An Introduction to Unification-Based Approaches to Grammar, Lecture notes 4. Center for the Study of Language and Information, Stanford, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart M Shieber</author>
</authors>
<title>Parsing and type inference for natural and computer languages.</title>
<date>1989</date>
<institution>Department of Computer Science, Stanford University,</institution>
<location>Stanford CA.</location>
<note>Doctoral dissertation,</note>
<marker>Shieber, 1989</marker>
<rawString>Shieber, Stuart M. (1989). Parsing and type inference for natural and computer languages. Doctoral dissertation, Department of Computer Science, Stanford University, Stanford CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart M Shieber</author>
</authors>
<title>Constraint-Based Grammar Formalisms.</title>
<date>1992</date>
<publisher>The MIT Press.</publisher>
<marker>Shieber, 1992</marker>
<rawString>Shieber, Stuart M. (1992). Constraint-Based Grammar Formalisms. The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Tarski</author>
</authors>
<title>Logic, Semantics, Metamathematics, Second edition.</title>
<date>1983</date>
<publisher>Hackett Publishing Company.</publisher>
<contexts>
<context position="19941" citStr="Tarski 1983" startWordPosition="2961" endWordPosition="2962">liar with typical argument patterns in domain theory. The chapter concludes with the suggestive comment that a formalization of feature structures in terms of abstract closure operators on domains would eliminate the repetitiveness of completeness proofs for feature logics. One wishes the suggestion had been tested in the book, although one might also wonder whether the full apparatus of domain theory would be needed to take advantage of the convenience of closure operators. After all, closure operators arise naturally in logic from the notions of deductive closure and of logical consequence (Tarski 1983), so one might imagine that the simpler proofs could be carried out in a model-theoretic setting short of domain theory. 5. Applications The last part of the book applies the theory developed earlier in three important areas: the semantics of unification-based phrase structure formalisms, the semantics of feature-based definite clause programs, and the specification of recursive type constraints. 5.1 Semantics of Grammar Formalisms Carpenter&apos;s account of the denotational semantics of unification-based phrase structure grammars benefits greatly from the extensive use of feature algebras and fea</context>
</contexts>
<marker>Tarski, 1983</marker>
<rawString>Tarski, A. (1983). Logic, Semantics, Metamathematics, Second edition. Hackett Publishing Company.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Ueda</author>
</authors>
<title>Guarded Horn clauses.&amp;quot; In Concurrent Prolog: Collected papers, edited by Ehud Shapiro,</title>
<date>1987</date>
<pages>140--156</pages>
<publisher>The MIT Press.</publisher>
<contexts>
<context position="8028" citStr="Ueda 1987" startWordPosition="1192" endWordPosition="1193">e processing systems based on feature computations. It takes conjunctive description as the only one that can have global extent in a computation. Nonconjunctive aspects of a description are then ephemeral in that nonconjunctive connectives introduced in a derivation must be eliminated within a bounded number of steps by a committed choice operation based on some preference-based search control mechanism. Such a view can be seen as a mild generalization of the ideas of deterministic parsing (Marcus 1980), and also closely related to the flat-guard committed choice logic programming languages (Ueda 1987; Saraswat 1990). In both of those frameworks a single conjunctive constraint is constructed incrementally on the basis of local committed choices among alternatives. Search completeness is of course sacrificed, but the computational intractability arising from having to consider all the combinations of smaller alternative constraints into larger consistent constraints is bypassed. Finally, the radical route suggests a discipline of trying to replace as much as possible disjunctive or negative constraints by somewhat weaker kinds of underspecification that admit of purely conjunctive formulati</context>
</contexts>
<marker>Ueda, 1987</marker>
<rawString>Ueda, K. (1987). &amp;quot;Guarded Horn clauses.&amp;quot; In Concurrent Prolog: Collected papers, edited by Ehud Shapiro, 140-156. The MIT Press.</rawString>
</citation>
<citation valid="false">
<title>Fernando Pereira is president of the Association for Computational Linguistics. Pereira&apos;s address is:</title>
<booktitle>AT&amp;T Bell Laboratories, 2D-447,600 Mountain Avenue, PO Box 636, Murray Hill, NJ 07974-0636; e-mail:</booktitle>
<pages>pereira@research.att.com.</pages>
<marker></marker>
<rawString>Fernando Pereira is president of the Association for Computational Linguistics. Pereira&apos;s address is: AT&amp;T Bell Laboratories, 2D-447,600 Mountain Avenue, PO Box 636, Murray Hill, NJ 07974-0636; e-mail: pereira@research.att.com.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>