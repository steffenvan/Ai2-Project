<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.87292">
A hybrid rule/model-based finite-state framework
for normalizing SMS messages
</title>
<author confidence="0.651505">
Richard Beaufort&apos; Sophie Roekhaut2 Louise-Amélie Cougnon&apos; Cédrick Fairon&apos;
</author>
<address confidence="0.359504">
(1) CENTAL, Université catholique de Louvain – 1348 Louvain-la-Neuve, Belgium
</address>
<email confidence="0.731552">
{richard.beaufort,louise-amelie.cougnon,cedrick.fairon}@uclouvain.be
</email>
<address confidence="0.431051">
(2) TCTS Lab, Université de Mons – 7000 Mons, Belgium
</address>
<email confidence="0.945531">
sophie.roekhaut@umons.ac.be
</email>
<sectionHeader confidence="0.996666" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9994998">
In recent years, research in natural
language processing has increasingly
focused on normalizing SMS messages.
Different well-defined approaches have
been proposed, but the problem remains
far from being solved: best systems
achieve a 11% Word Error Rate. This
paper presents a method that shares
similarities with both spell checking
and machine translation approaches. The
normalization part of the system is entirely
based on models trained from a corpus.
Evaluated in French by 10-fold-cross
validation, the system achieves a 9.3%
Word Error Rate and a 0.83 BLEU score.
</bodyText>
<sectionHeader confidence="0.999515" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999980196721312">
Introduced a few years ago, Short Message
Service (SMS) offers the possibility of exchanging
written messages between mobile phones. SMS
has quickly been adopted by users. These
messages often greatly deviate from traditional
spelling conventions. As shown by specialists
(Thurlow and Brown, 2003; Fairon et al.,
2006; Bieswanger, 2007), this variability is
due to the simultaneous use of numerous coding
strategies, like phonetic plays (2m1 read ‘demain’,
“tomorrow”), phonetic transcriptions (kom instead
of ‘comme’, “like”), consonant skeletons (tjrs
for ‘toujours’, “always”), misapplied, missing
or incorrect separators (j esper for ‘j’espère’, “I
hope”; j’croibi1k, instead of ‘je crois bien que’,
“I am pretty sure that”), etc. These deviations
are due to three main factors: the small number
of characters allowed per text message by the
service (140 bytes), the constraints of the small
phones’ keypads and, last but not least, the fact
that people mostly communicate between friends
and relatives in an informal register.
Whatever their causes, these deviations
considerably hamper any standard natural
language processing (NLP) system, which
stumbles against so many Out-Of-Vocabulary
words. For this reason, as noted by Sproat et al.
(2001), an SMS normalization must be performed
before a more conventional NLP process can
be applied. As defined by Yvon (2008), “SMS
normalization consists in rewriting an SMS text
using a more conventional spelling, in order
to make it more readable for a human or for a
machine.”
The SMS normalization we present here was
developed in the general framework of an SMS-
to-speech synthesis system1. This paper, however,
only focuses on the normalization process.
Evaluated in French, our method shares
similarities with both spell checking and machine
translation. The machine translation-like module
of the system performs the true normalization
task. It is entirely based on models learned from
an SMS corpus and its transcription, aligned
at the character-level in order to get parallel
corpora. Two spell checking-like modules
surround the normalization module. The first
one detects unambiguous tokens, like URLs
or phone numbers, to keep them out of the
normalization. The second one, applied on the
normalized parts only, identifies non-alphabetic
sequences, like punctuations, and labels them
with the corresponding token. This greatly helps
the system’s print module to follow the basic rules
of typography.
This paper is organized as follows. Section 2
proposes an overview of the state of the art.
Section 3 presents the general architecture of
our system, while Section 4 focuses on how we
learn and combine our normalization models.
Section 5 evaluates the system and compares it to
</bodyText>
<footnote confidence="0.9838815">
1The Vocalise project.
See cental.fltr.ucl.ac.be/team/projects/vocalise/.
</footnote>
<page confidence="0.882417">
770
</page>
<note confidence="0.9467795">
Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 770–779,
Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.9952538">
checking approach is the excessive confidence it
places in word boundaries.
previous works. Section 6 draws conclusions and
considers some future possible improvements of
the method.
</bodyText>
<sectionHeader confidence="0.999726" genericHeader="introduction">
2 Related work
</sectionHeader>
<bodyText confidence="0.99998975862069">
As highlighted by Kobus et al. (2008b), SMS
normalization, up to now, has been handled
through three well-known NLP metaphors: spell
checking, machine translation and automatic
speech recognition. In this section, we only
present the pros and cons of these approaches.
Their results are given in Section 5, focused on
our evaluation.
The spell checking metaphor (Guimier de Neef
et al., 2007; Choudhury et al., 2007; Cook and
Stevenson, 2009) performs the normalization task
on a word-per-word basis. On the assumption
that most words should be correct for the purpose
of communication, its principle is to keep In-
Vocabulary words out of the correction process.
Guimier de Neef et al. (2007) proposed a rule-
based system that uses only a few linguistic
resources dedicated to SMS, like specific lexicons
of abbreviations. Choudhury et al. (2007)
and Cook and Stevenson (2009) preferred to
implement the noisy channel metaphor (Shannon,
1948), which assumes a communication process
in which a sender emits the intended message
W through an imperfect (noisy) communication
channel, such that the sequence O observed by
the recipient is a noisy version of the original
message. On this basis, the idea is to recover the
intended message W hidden behind the sequences
of observations O, by maximizing:
</bodyText>
<equation confidence="0.998945333333333">
Wmax = arg max P(W |O) (1)
P(O|W) P(W)
P(O)
</equation>
<bodyText confidence="0.996794031746032">
where P(O) is ignored because constant,
P(O|W) models the channel’s noise, and P(W)
models the language of the source. Choudhury et
al. (2007) implemented the noisy channel through
a Hidden-Markov Model (HMM) able to handle
both graphemic variants and phonetic plays as
proposed by (Toutanova and Moore, 2002), while
Cook and Stevenson (2009) enhanced the model
by adapting the channel’s noise P(O|W, wf)
according to a list of predefined observed
word formations {wf}: stylistic variation, word
clipping, phonetic abbreviations, etc. Whatever
the system, the main limitation of the spell
The machine translation metaphor, which is
historically the first proposed (Bangalore et al.,
2002; Aw et al., 2006), considers the process of
normalizing SMS as a translation task from a
source language (the SMS) to a target language
(its standard written form). This standpoint is
based on the observation that, on the one side,
SMS messages greatly differ from their standard
written forms, and that, on the other side, most
of the errors cross word boundaries and require
a wide context to be handled. On this basis,
Aw et al. (2006) proposed a statistical machine
translation model working at the phrase-level,
by splitting sentences into their k most probable
phrases. While this approach achieves really good
results, Kobus et al. (2008b) make the assertion
that a phrase-based translation can hardly capture
the lexical creativity observed in SMS messages.
Moreover, the translation framework, which can
handle many-to-many correspondences between
sources and targets, exceeds the needs of SMS
normalization, where the normalization task is
almost deterministic.
Based on this analysis, Kobus et al. (2008b)
proposed to handle SMS normalization through
an automatic speech recognition (ASR) metaphor.
The starting point of this approach is the
observation that SMS messages present a lot
of phonetic plays that sometimes make the
SMS word (sré, mwa) closer to its phonetic
representation ([sire], [mwa]) than to its standard
written form (serai, “will be”, moi, “me”).
Typically, an ASR system tries to discover the
best word sequence within a lattice of weighted
phonetic sequences. Applied to the SMS
normalization task, the ASR metaphor consists
in first converting the SMS message into a phone
lattice, before turning it into a word-based lattice
using a phoneme-to-grapheme dictionary. A
language model is then applied on the word
lattice, and the most probable word sequence is
finally chosen by applying a best-path algorithm
on the lattice. One of the advantages of the
grapheme-to-phoneme conversion is its intrinsic
ability to handle word boundaries. However,
this step also presents an important drawback,
raised by the authors themselves: it prevents
next normalization steps from knowing what
graphemes were in the initial sequence.
= arg max
</bodyText>
<page confidence="0.989832">
771
</page>
<bodyText confidence="0.999876833333333">
Our approach, which is detailed in Sections 3
and 4, shares similarities with both the spell
checking approach and the machine translation
principles, trying to combine the advantages
of these methods, while leaving aside their
drawbacks: like in spell checking systems, we
detect unambiguous units of text as soon as
possible and try to rely on word boundaries when
they seem reliable enough; but like in the machine
translation task, our method intrinsically handles
word boundaries in the normalization process if
needed.
</bodyText>
<sectionHeader confidence="0.839031" genericHeader="method">
3 Overview of the system
</sectionHeader>
<subsectionHeader confidence="0.999119">
3.1 Tools in use
</subsectionHeader>
<bodyText confidence="0.9999178">
In our system, all lexicons, language models
and sets of rules are compiled into finite-state
machines (FSMs) and combined with the input
text by composition (o). The reader who is
not familiar with FSMs and their fundamental
theoretical properties, like composition, is urged
to consult the state-of-the-art literature (Roche
and Schabes, 1997; Mohri and Riley, 1997; Mohri
et al., 2000; Mohri et al., 2001).
We used our own finite-state tools: a finite-state
machine library and its associated compiler
(Beaufort, 2008). In conformance with the format
of the library, the compiler builds finite-state
machines from weighted rewrite rules, weighted
regular expressions and n-gram models.
</bodyText>
<subsectionHeader confidence="0.999068">
3.2 Aims
</subsectionHeader>
<bodyText confidence="0.9999756875">
We formulated four constraints before fixing the
system’s architecture. First, special tokens, like
URLs, phones or currencies, should be identified
as soon as possible, to keep them out of the
normalization process.
Second, word boundaries should be taken into
account, as far as they seem reliable enough. The
idea, here, is to base the decision on a learning
able to catch frequent SMS sequences to include
in a dedicated In-Vocabulary (IV) lexicon.
Third, any other SMS sequence should be
considered as Out-Of-Vocabulary (OOV), on
which in-depth rewritings may be applied.
Fourth, the basic rules of typography and
typesettings should be applied on the normalized
version of the SMS message.
</bodyText>
<subsectionHeader confidence="0.999719">
3.3 Architecture
</subsectionHeader>
<bodyText confidence="0.999655235294118">
The architecture depicted in Figure 1 directly
relies on these considerations. In short, an
SMS message first goes through three SMS
modules, which normalize its noisy parts.
Then, two standard NLP modules produce a
morphosyntactic analysis of the normalized text.
A last module, finally, takes advantage of this
linguistic analysis either to print a text that follows
the basic rules of typography, or to synthesize the
corresponding speech signal.
Because this paper focuses on the normalization
task, the rest of this section only presents the
SMS modules and the “smart print” output. The
morphosyntactic analysis, made of state-of-the-art
algorithms, is described in (Beaufort, 2008), and
the text-to-speech synthesis system we use is
presented in (Colotte and Beaufort, 2005).
</bodyText>
<subsectionHeader confidence="0.652143">
3.3.1 SMS modules
</subsectionHeader>
<bodyText confidence="0.995391333333333">
SMS preprocessing. This module relies
on a set of manually-tuned rewrite rules. It
identifies paragraphs and sentences, but also some
</bodyText>
<figureCaption confidence="0.999916">
Figure 1: Architecture of the system
</figureCaption>
<figure confidence="0.999243846153846">
SMS message
Smart print
TTS engine
Standard
written message
Speech
SMS Modules
SMS Preprocessing
SMS Normalization
SMS Postprocessing
Standard NLP Modules
Morphological analysis
Contextual disambiguation
</figure>
<page confidence="0.984214">
772
</page>
<bodyText confidence="0.999925548387097">
unambiguous tokens: URLs, phone numbers,
dates, times, currencies, units of measurement
and, last but not least in the context of SMS,
smileys2. These tokens are kept out of the
normalization process, while any other sequence
of characters is considered – and labelled – as
noisy.
SMS normalization. This module only uses
models learned from a training corpus (cf. Section
4). It involves three steps. First, an SMS-
dedicated lexicon look-up, which differentiates
between known and unknown parts of a noisy
token. Second, a rewrite process, which creates a
lattice of weighted solutions. The rewrite model
differs depending on whether the part to rewrite
is known or not. Third, a combination of the
lattice of solutions with a language model, and the
choice of the best sequence of lexical units. At
this stage, the normalization as such is completed.
SMS postprocessing. Like the preprocessor,
the postprocessor relies on a set of manually-
tuned rewrite rules. The module is only applied
on the normalized version of the noisy tokens,
with the intention to identify any non-alphabetic
sequence and to isolate it in a distinct token.
At this stage, for instance, a point becomes a
‘strong punctuation’. Apart from the list of
tokens already managed by the preprocessor,
the postprocessor handles as well numeric and
alphanumeric strings, fields of data (like bank
account numbers), punctuations and symbols.
</bodyText>
<subsectionHeader confidence="0.95271">
3.3.2 Smart print
</subsectionHeader>
<bodyText confidence="0.999924">
The smart print module, based on manually-tuned
rules, checks either the kind of token (chosen
by the SMS pre-/post-processing modules)
or the grammatical category (chosen by the
morphosyntactic analysis) to make the right
typography choices, such as the insertion of
a space after certain tokens (URLs, phone
numbers), the insertion of two spaces after
a strong punctuation (point, question mark,
exclamation mark), the insertion of two carriage
returns at the end of a paragraph, or the upper
case of the initial letter at the beginning of the
sentence.
</bodyText>
<footnote confidence="0.709205">
2Our list contains about 680 smileys.
</footnote>
<sectionHeader confidence="0.981881" genericHeader="method">
4 The normalization models
</sectionHeader>
<subsectionHeader confidence="0.998896">
4.1 Overview of the normalization algorithm
</subsectionHeader>
<bodyText confidence="0.997264714285714">
Our approach is an approximation of the noisy
channel metaphor (cf. Section 2). It differs
from this general framework, because we adapt
the model of the channel’s noise depending
on whether the noisy token (our sequence
of observations) is In-Vocabulary or Out-Of-
Vocabulary:
</bodyText>
<equation confidence="0.558471">
{ PIV (O|W) if O E IV
POOV (O|W) else
</equation>
<bodyText confidence="0.999834363636364">
Indeed, our algorithm is based on the assumption
that applying different normalization models to IV
and OOV words should both improve the results
and reduce the processing time.
For this purpose, the first step of the algorithm
consists in composing a noisy token T with an
FST Sp whose task is to differentiate between
sequences of IV words and sequences of OOV
words, by labelling them with a special IV or OOV
marker. The token is then split in n segments sgi
according to these markers:
</bodyText>
<equation confidence="0.970497">
{sg} = Split(T o Sp) (3)
</equation>
<bodyText confidence="0.997549333333333">
In a second step, each segment is composed
with a rewrite model according to its kind: the IV
rewrite model RIV for sequences of IV words, and
the OOV rewrite model ROOV for sequences of
OOV words:
{ sgi o RIV if sgi E IV
sgi o ROOV else
All rewritten segments are then concatenated
together in order to get back the complete token:
</bodyText>
<equation confidence="0.999485">
T = (Dni�1(sg&apos;i) (5)
</equation>
<bodyText confidence="0.996081125">
where (D is the concatenation operator.
The third and last normalization step is applied
on a complete sentence S. All tokens Tj of S
are concatenated together and composed with the
lexical language model LM. The result of this
composition is a word lattice, of which we take
the most probable word sequence S&apos; by applying
a best-path algorithm:
</bodyText>
<equation confidence="0.946784">
S&apos; = BestPath( ((Dmj�1Tj) o LM ) (6)
</equation>
<bodyText confidence="0.999177333333333">
where m is the number of tokens of S. In S&apos;,
each noisy token Tj of S is mapped onto its most
probable normalization.
</bodyText>
<equation confidence="0.76521025">
P(O|W) =
(2)
sg&apos;i =
(4)
</equation>
<page confidence="0.986513">
773
</page>
<subsectionHeader confidence="0.889098">
4.2 The corpus alignment
</subsectionHeader>
<bodyText confidence="0.994870918918919">
Our normalization models were trained on a
French SMS corpus of 30,000 messages, gathered
in Belgium, semi-automatically anonymized and
manually normalized by the Catholic University
of Louvain (Fairon and Paumier, 2006). Together,
the SMS corpus and its transcription constitute
parallel corpora aligned at the message-level.
However, in order to learn pieces of knowledge
from these corpora, we needed a string alignment
at the character-level.
One way of implementing this string alignment
is to compute the edit-distance of two strings,
which measures the minimum number of
operations (substitutions, insertions, deletions)
required to transform one string into the other
(Levenshtein, 1966). Using this algorithm,
in which each operation gets a cost of 1, two
strings may be aligned in different ways with
the same global cost. This is the case, for
instance, for the SMS form kozer ([koze]) and
its standard transcription causé (“talked”), as
illustrated by Figure 2. However, from a linguistic
standpoint, alignment (1) is preferable, because
corresponding graphemes are aligned on their first
character.
In order to automatically choose this preferred
alignment, we had to distinguish the three edit-
operations, according to the characters to be
aligned. For that purpose, probabilities were
required. Computing probabilities for each
operation according to the characters to be aligned
was performed through an iterative algorithm
described in (Cougnon and Beaufort, 2009). In
short, this algorithm gradually learns the best way
of aligning strings. On our parallel corpora, it
converged after 7 iterations and provided us with
a result from which the learning could start.
</bodyText>
<figure confidence="0.9967035">
(1) ko_ser (2) k_oser
causé_ causé_
(3) ko_ser (4) k_oser
caus_é caus_é
</figure>
<figureCaption confidence="0.93937975">
Figure 2: Different equidistant alignments, using
a standard edit-cost of 1. Underscores (‘_’) mean
insertion in the upper string, and deletion in the
lower string.
</figureCaption>
<subsectionHeader confidence="0.991283">
4.3 The split model Sp
</subsectionHeader>
<bodyText confidence="0.997782428571429">
In natural language processing, a word is
commonly defined as “a sequence of alphabetic
characters between separators”, and an IV word is
simply a word that belongs to the lexicon in use.
In SMS messages however, separators are
surely indicative, but not reliable. For this reason,
our definition of the word is far from the previous
one, and originates from the string alignment.
After examining our parallel corpora aligned at
the character-level, we decided to consider as a
word “the longest sequence of characters parsed
without meeting the same separator on both sides
of the alignment”. For instance, the following
alignment
</bodyText>
<figure confidence="0.333811333333333">
J esper_ k___tu va_
J’espère que tu vas
(I hope that you will)
is split as follows according to our definition:
J esper_
J’espère
</figure>
<bodyText confidence="0.996352">
since the separator in “J esper” is different
from its transcription, and “ktu” does not
contain any separator. Thus, this SMS sequence
corresponds to 3 SMS words: [J esper], [ktu] and
[va].
A first parsing of our parallel corpora provided
us with a list of SMS sequences corresponding to
our IV lexicon. The FST Sp is built on this basis:
</bodyText>
<listItem confidence="0.903934583333333">
Sp = ( S* (I|O) ( S+(I|O) )* S* ) o G (7)
where:
• I is an FST corresponding to the lexicon,
in which IV words are mapped onto the IV
marker.
• O is the complement of I3. In this OOV
lexicon, OOV sequences are mapped onto the
OOV marker.
• S is an FST corresponding to the list of
separators (any non-alphabetic and non-
numeric character), mapped onto a SEP
marker.
</listItem>
<bodyText confidence="0.832701">
3Actually, the true complement of I accepts sequences
with separators, while these sequences were removed from
O.
</bodyText>
<figure confidence="0.6167285">
k___tu va_
que tu vas
</figure>
<page confidence="0.960069">
774
</page>
<listItem confidence="0.9954988">
• G is an FST able to detect consecutive
sequences of IV (resp. OOV) words, and to
group them under a unique IV (resp. OOV)
marker. By gathering sequences of IVs and
OOVs, SEP markers disappear from Sp.
</listItem>
<bodyText confidence="0.923413428571428">
Figure 3 illustrates the composition of Sp with
the SMS sequence J esper kcv b1 (J’espère que Ca
va bien, “I hope you are well”). For the example,
we make the assumption that kcv was never seen
during the training.
J&apos;&apos; e s p e r&apos;&apos; k c v&apos;&apos; b 1
ry OOy ry
</bodyText>
<figureCaption confidence="0.99304">
Figure 3: Application of the split model Sp. The
OOV sequence starts and ends with separators.
</figureCaption>
<subsectionHeader confidence="0.972608">
4.4 The IV rewrite model RIV
</subsectionHeader>
<bodyText confidence="0.9997116">
This model is built during a second parsing
of our parallel corpora. In short, the parsing
simply gathers all possible normalizations for
each SMS sequence put, by the first parsing, in
the IV lexicon. Contrary to the first parsing, this
second one processes the corpus without taking
separators into account, in order to make sure
that all possible normalizations are collected.
Each normalization w� for a given SMS
sequence w is weighted as follows:
</bodyText>
<equation confidence="0.997348333333333">
Occ( �w, w)
p( �w|w) = (8)
Occ(w)
</equation>
<bodyText confidence="0.998136">
where Occ(x) is the number of occurrences of x in
the corpus. The FST RIV is then built as follows:
</bodyText>
<listItem confidence="0.860358333333333">
RIV = SIV* IVR ( SIV+ IVR )* SIV* (9)
where:
• IVR is a weighted lexicon compiled into an
FST, in which each IV sequence is mapped
onto the list of its possible normalizations.
• SIV is a weighted lexicon of separators, in
which each separator is mapped onto the list
of its possible normalizations. The deletion
is often one of the possible normalization of
a separator. Otherwise, the deletion is added
and is weighted by the following smoothed
probability:
</listItem>
<equation confidence="0.9003135">
0.1
p(DEL|w) = Occ(w) + 0.1 (10)
</equation>
<subsectionHeader confidence="0.878689">
4.5 The OOV rewrite model ROOV
</subsectionHeader>
<bodyText confidence="0.999982285714286">
In contrast to the other models, this one is not a
regular expression made of weighted lexicons.
It corresponds to a set of weighted rewrite rules
(Chomsky and Halle, 1968; Johnson, 1972; Mohri
and Sproat, 1996) learned from the alignment.
Developed in the framework of generative
phonology, rules take the form
</bodyText>
<equation confidence="0.984946">
0 → 0 : A _ p / w (11)
</equation>
<bodyText confidence="0.99973075">
which means that the replacement 0 → 0 is
only performed when 0 is surrounded by A on
the left and p on the right, and gets the weight w.
However, in our case, rules take the simpler form
</bodyText>
<equation confidence="0.994529">
0 → 0 / w (12)
</equation>
<bodyText confidence="0.970715606060606">
which means that the replacement 0 → 0 is
always performed, whatever the context.
Inputs of our rules (0) are sequences of
1 to 5 characters taken from the SMS side
of the alignment, while outputs (0) are their
corresponding normalizations. Our rules are
sorted in the reverse order of the length of their
inputs: rules with longer inputs come first in the
list.
Long-to-short rule ordering reduces the number
of proposed normalizations for a given SMS
sequence for two reasons:
1. the firing of a rule with a longer input blocks
the firing of any shorter sub-rule. This is due
to a constraint expressed on lists of rewrite
rules: a given rule may be applied only if no
more specific and relevant rule has been met
higher in the list;
2. a rule with a longer input usually has fewer
alternative normalizations than a rule with a
shorter input does, because the longer SMS
sequence likely occurred paired with fewer
alternative normalizations in the training
corpus than did the shorter SMS sequence.
Among the wide set of possible sequences
of 2 to 5 characters gathered from the corpus,
we only kept in our list of rules the sequences
that allowed at least one normalization solely
made of IV words. It is important to notice that
here, we refer to the standard notion of IV word:
while gathering the candidate sequences from the
corpus, we systematically checked each word of
the normalizations against a lexicon of French
</bodyText>
<page confidence="0.996441">
775
</page>
<bodyText confidence="0.999948529411765">
standard written forms. The lexicon we used
contains about 430,000 inflected forms and is
derived from Morlex4, a French lexical database.
Figure 4 illustrates these principles by focusing
on 3 input sequences: aussi, au and a. As
shown by the Figure, all rules of a set dedicated
to the same input sequence (for instance, aussi)
are optional (?-*), except the last one, which is
obligatory (-*). In our finite-state compiler, this
convention allows the application of all concurrent
normalizations on the same input sequence, as
depicted in Figure 5.
In our real list of OOV rules, the input sequence
a corresponds to 231 normalizations, while au
accepts 43 normalizations and aussi, only 3. This
highlights the interest, in terms of efficiency, of the
long-to-short rule ordering.
</bodyText>
<subsectionHeader confidence="0.941482">
4.6 The language model
</subsectionHeader>
<bodyText confidence="0.999960333333333">
Our language model is an n-gram of lexical
forms, smoothed by linear interpolation (Chen
and Goodman, 1998), estimated on the normalized
part of our training corpus and compiled into a
weighted FST LM,,,.
At this point, this FST cannot be combined with
our other models, because it works on lexical units
and not on characters. This problem is solved
by composing LM,,, with another FST L, which
represents a lexicon mapping each input word,
considered as a string of characters, onto the same
output words, but considered here as a lexical
unit. Lexical units are then permanently removed
from the language model by keeping only the first
projection (the input side) of the composition:
</bodyText>
<equation confidence="0.941838">
LM = FirstProjection( L o LM,,, ) (13)
</equation>
<bodyText confidence="0.9998145">
In this model, special characters, like
punctuations or symbols, are represented by
their categories (light, medium and strong
punctuations, question mark, symbol, etc.), while
special tokens, like URLs or phone numbers,
are handled as token values (URL, phone, etc.)
instead of as sequences of characters. This
reduces the complexity of the model.
As we explained earlier, tokens of a same
sentence 5 are concatenated together at the end
of the second normalization step. During this
concatenation process, sequences corresponding
to special tokens are automatically replaced by
their token values. Special characters, however,
</bodyText>
<footnote confidence="0.996693">
4See http://bach.arts.kuleuven.be/pmertens/.
</footnote>
<figureCaption confidence="0.9457887">
Figure 4: Samples from the list of OOV
rules. Rules’ weights are negative logarithms
of probabilities: smaller weights are thus better.
Asterisks indicate normalizations solely made of
French IV words.
Figure 5: Application of the OOV rules on
the input sequence aussi. All normalizations
corresponding to this sequence were allowed,
while rules corresponding to shorter input
sequences were ignored.
</figureCaption>
<figure confidence="0.994363837209302">
&amp;quot;aussi&amp;quot; ?-&gt; &amp;quot;au si&amp;quot; / 8.4113 (*)
&amp;quot;aussi&amp;quot; ?-&gt; &amp;quot;ou si&amp;quot; / 6.6743 (*)
&amp;quot;aussi&amp;quot; -&gt; &amp;quot;aussi&amp;quot; / 0.0189 (*)
...
... ?-&gt; &amp;quot;ow&amp;quot; / 14.1787
&amp;quot;au&amp;quot; ?-&gt; &amp;quot;ôt&amp;quot; / 12.5938
... ?-&gt; &amp;quot;du&amp;quot; / 12.1787 (*)
&amp;quot;au&amp;quot; ?-&gt; &amp;quot;o&amp;quot; / 11.8568
&amp;quot;au&amp;quot; ?-&gt; &amp;quot;on&amp;quot; / 10.8568 (*)
&amp;quot;au&amp;quot;
...
&amp;quot;au&amp;quot;
...
&amp;quot;au&amp;quot; ?-&gt; &amp;quot;aud&amp;quot; / 9.9308
&amp;quot;au&amp;quot; ?-&gt; &amp;quot;aux&amp;quot; / 6.1731 (*)
&amp;quot;au&amp;quot; -&gt; &amp;quot;au&amp;quot; / 0.0611 (*)
...
...
&amp;quot;a&amp;quot; ?-&gt; &amp;quot;a d&amp;quot; / 17.8624
&amp;quot;a&amp;quot; ?-&gt; &amp;quot;ation&amp;quot; / 17.8624
&amp;quot;a&amp;quot; ?-&gt; &amp;quot;âts&amp;quot; / 17.8624
...
&amp;quot;a&amp;quot; ?-&gt; &amp;quot;ablement&amp;quot; / 16.8624
&amp;quot;a&amp;quot; ?-&gt; &amp;quot;anisation&amp;quot; / 16.8624
...
&amp;quot;a&amp;quot; ?-&gt; &amp;quot;u&amp;quot; / 15.5404
&amp;quot;a&amp;quot; ?-&gt; &amp;quot;y a&amp;quot; / 15.5404
...
&amp;quot;a&amp;quot; ?-&gt; &amp;quot;abilité&amp;quot; / 13.4029
&amp;quot;a&amp;quot; ?-&gt; &amp;quot;à-&amp;quot; / 12.1899
&amp;quot;a&amp;quot; ?-&gt; &amp;quot;ar&amp;quot; / 11.5225
&amp;quot;a&amp;quot; ?-&gt; \DEL / 9.1175
&amp;quot;a&amp;quot; ?-&gt; &amp;quot;ga&amp;quot; / 6.2019
&amp;quot;a&amp;quot; ?-&gt; &amp;quot;à&amp;quot; / 3.5013
&amp;quot;a&amp;quot; -&gt; &amp;quot;a&amp;quot; / 0.3012
s/0.02
u 6:&amp;quot; &amp;quot;/8.41
a
s
s i
6:&amp;quot; &amp;quot;
a:o/6.67
u
</figure>
<page confidence="0.996493">
776
</page>
<bodyText confidence="0.995743666666667">
are still present in S. For this reason, S is first
composed with an FST Reduce, which maps each
special character onto its corresponding category:
</bodyText>
<note confidence="0.698702">
S o Reduce o LM (14)
</note>
<sectionHeader confidence="0.984828" genericHeader="evaluation">
5 Evaluation
</sectionHeader>
<bodyText confidence="0.999133976744186">
The performance and the efficiency of our system
were evaluated on a MacBook Pro with a 2.4 GHz
Intel Core 2 Duo CPU, 4 GB 667 MHz DDR2
SDRAM, running Mac OS X version 10.5.8.
The evaluation was performed on the corpus
of 30,000 French SMS presented in Section 4.2,
by ten-fold cross-validation (Kohavi, 1995). The
principle of this method of evaluation is to split
the initial corpus into 10 subsets of equal size. The
system is then trained 10 times, each time leaving
out one of the subsets from the training corpus, but
using only this omitted subset as test corpus.
The language model of the evaluation is a
3-gram. We did not try a 4-gram. This choice
was motivated by the experiments of Kobus et
al. (2008a), who showed on a French corpus
comparable to ours that, if using a larger language
model is always rewarded, the improvement
quickly decreases with every higher level and is
already quite small between 2-gram and 3-gram.
Table 1 presents the results in terms of
efficiency. The system seems efficient, while we
cannot compare it with other methods, which did
not provide us with this information.
Table 2, part 1, presents the performance of
our approach (Hybrid) and compares it to a trivial
copy-paste (Copy). The system was evaluated
in terms of BLEU score (Papineni et al., 2001),
Word Error Rate (WER) and Sentence Error Rate
(SER). Concerning WER, the table presents the
distribution between substitutions (Sub), deletions
(Del) and insertions (Ins). The copy-paste results
just inform about the real deviation of our corpus
from the traditional spelling conventions, and
highlight the fact that our system is still at pains
to significantly reduce the SER, while results
in terms of WER and BLEU score are quite
encouraging.
Table 2, part 2, provides the results of the
state-of-the-art approaches. The only results truly
comparable to ours are those of Guimier de Neef
et al. (2007), who evaluated their approach on
the same corpus as ours5; clearly, our method
</bodyText>
<footnote confidence="0.890827">
5They performed an evaluation without ten-fold cross-
</footnote>
<table confidence="0.920137333333333">
mean dev.
bps 1836.57 159.63
ms/SMS (140b) 76.23 22.34
</table>
<tableCaption confidence="0.999836">
Table 1: Efficiency of the system.
</tableCaption>
<bodyText confidence="0.999970903225806">
outperforms theirs. Our results also seem a bit
better than those of Kobus et al. (2008a), although
the comparison with this system, also evaluated in
French, is less easy: they combined the French
corpus we used with another one and performed
a single validation, using a bigger training corpus
(36.704 messages) for a test corpus quite similar
to one of our subsets (2.998 SMS). Other systems
were evaluated in English, and results are more
difficult to compare; at least, our results seem in
line with them.
The analysis of the normalizations produced
by our system pointed out that, most often, errors
are contextual and concern the gender (quel(le),
“what”), the number (bisou(s), “kiss”), the person
([tu t’]inquiète(s), “you are worried”) or the
tense (arrivé/arriver, “arrived”/“to arrive”). That
contextual errors are frequent is not surprising. In
French, as mentioned by Kobus et al. (2008b), n-
gram models are unable to catch this information,
as it is generally out of their scope.
On the other hand, this analysis confirmed
our initial assumptions. First, special tokens
(URLs, phones, etc.) are not modified. Second,
agglutinated words are generally split (Pensa ms
—* Pense à mes, “think to my”), while misapplied
separators tend to be deleted (G t —* J’étais, “I
was”). Of course, we also found some errors at
word boundaries ([il] l’arrange —* [il] la range,
“[he] arranges” —* “[he] pits in order”), but they
were fairly rare.
</bodyText>
<sectionHeader confidence="0.992362" genericHeader="conclusions">
6 Conclusion and perspectives
</sectionHeader>
<bodyText confidence="0.9697648">
In this paper, we presented an SMS normalization
framework based on finite-state machines and
developed in the context of an SMS-to-speech
synthesis system. With the intention to avoid
wrong modifications of special tokens and to
handle word boundaries as easily as possible, we
designed a method that shares similarities with
both spell checking and machine translation. Our
validation, because their rule-based system did not need any
training.
</bodyText>
<page confidence="0.98637">
777
</page>
<table confidence="0.968110090909091">
1. Our approach 2. State of the art
Ten-fold cross-validation, French French English
Copy Hybrid Guimier Kobus 2008 Aw Choud. Cook
x Q x Q 2007 1 2∗ 2006 2006∗∗ 2009∗∗
Sub. 25.90 1.65 6.69 0.45 11.94
Del. 8.24 0.74 1.89 0.31 2.36
Ins. 0.46 0.08 0.72 0.10 2.21
WER 34.59 2.37 9.31 0.78 16.51 10.82 41.00 44.60
SER 85.74 0.87 65.07 1.85 76.05
BLEU 0.47 0.03 0.83 0.01 0.736 0.8 0.81
x=mean, Q=standard deviation
</table>
<tableCaption confidence="0.989213">
Table 2: Performance of the system. (∗) Kobus 2008-1 corresponds to the ASR-like system, while
</tableCaption>
<bodyText confidence="0.983384033898305">
Kobus 2008-2 is a combination of this system with a series of open-source machine translation toolkits.
(∗∗) Scores obtained on noisy data only, out of the sentence’s context.
normalization algorithm is original in two ways.
First, it is entirely based on models learned from
a training corpus. Second, the rewrite model
applied to a noisy sequence differs depending on
whether this sequence is known or not.
Evaluated by ten-fold cross-validation, the
system seems efficient, and the performance
in terms of BLEU score and WER are quite
encouraging. However, the SER remains too high,
which emphasizes the fact that the system needs
several improvements.
First of all, the model should take phonetic
similarities into account, because SMS messages
contain a lot of phonetic plays. The phonetic
model, for instance, should know that o, au,
eau, ... , aux can all be pronounced [o], while
è, ais, ait, ... , aient are often pronounced [E].
However, unlike Kobus et al. (2008a), we feel
that this model must avoid the normalization step
in which the graphemic sequence is converted
into phonemes, because this conversion prevents
the next steps from knowing which graphemes
were in the initial sequence. Instead, we propose
to learn phonetic similarities from a dictionary
of words with phonemic transcriptions, and to
build graphemes-to-graphemes rules. These rules
could then be automatically weighted, by learning
their frequencies from our aligned corpora.
Furthermore, this model should be able to allow
for timbre variation, like [e]–[E], in order to
allow similarities between graphemes frequently
confused in French, like ai ([e]) and ais/ait/aient
([E]). Last but not least, the graphemes-to-
graphemes rules should be contextualized, in
order to reduce the complexity of the model.
It would also be interesting to test the impact of
another lexical language model, learned on non-
SMS sentences. Indeed, the lexical model must
be learned from sequences of standard written
forms, an obvious prerequisite that involves a
major drawback when the corpus is made of SMS
sentences: the corpus must first be transcribed,
an expensive process that reduces the amount
of data on which the model will be trained. For
this reason, we propose to learn a lexical model
from non-SMS sentences. However, the corpus of
external sentences should still share two important
features with the SMS language: it should mimic
the oral language and be as spontaneous as
possible. With this in mind, our intention is
to gather sentences from Internet forums. But
not just any forum, because often forums share
another feature with the SMS language: their
language is noisy. Thus, the idea is to choose
a forum asking its members to pay attention to
spelling mistakes and grammatical errors, and to
avoid the use of the SMS language.
</bodyText>
<sectionHeader confidence="0.997668" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999962166666667">
This research was funded by grants no. 716619
and 616422 from the Walloon Region of Belgium,
and supported by the Multitel research centre.
We sincerely thank our anonymous reviewers
for their insightful and helpful comments on the
first version of this paper.
</bodyText>
<sectionHeader confidence="0.997097" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.6226105">
AiTi Aw, Min Zhang, Juan Xiao, and Jian Su. 2006.
A phrase-based statistical model for SMS text
</reference>
<page confidence="0.983552">
778
</page>
<reference confidence="0.999758339449542">
normalization. In Proc. COLING/ACL 2006.
Srinivas Bangalore, Vanessa Murdock, and Giuseppe
Riccardi. 2002. Bootstrapping bilingual data
using consensus translation for a multilingual instant
messaging system. In Proc. the 19th international
conference on Computational linguistics, pages 1–
7, Morristown, NJ, USA.
Richard Beaufort. 2008. Application des
machines à etats finis en synthèse de la parole.
Sélection d’unités non uniformes et correction
orthographique. Ph.D. thesis, FUNDP, Namur,
Belgium, March. 605 pages.
Markus Bieswanger. 2007. abbrevi8 or not 2 abbrevi8:
A contrastive analysis of different space and time-
saving strategies in English and German text
messages. In Texas Linguistics Forum, volume 50.
Stanley F. Chen and Joshua Goodman. 1998.
An empirical study of smoothing techniques for
language modeling. Technical Report 10-98,
Computer Science Group, Harvard University.
Noam Chomsky and Morris Halle. 1968. The sound
pattern of English. Harper and Row, New York, NY.
Monojit Choudhury, Rahul Saraf, Vijit Jain, Animesh
Mukherjee, Sudeshna Sarkar1, and Anupam Basu.
2007. Investigation and modeling of the structure
of texting language. International Journal on
Document Analysis and Recognition, 10(3):157–
174.
Vincent Colotte and Richard Beaufort. 2005.
Linguistic features weighting for a text-to-speech
system without prosody model. In Proc.
Interspeech’05, pages 2549–2552.
Paul Cook and Suzanne Stevenson. 2009. An
unsupervised model for text message normalization.
In Proc. Workshop on Computational Approaches to
Linguistic Creativity, pages 71–78.
Louise-Amélie Cougnon and Richard Beaufort. 2009.
SSLD: a French SMS to standard language
dictionary. In Sylviane Granger and Magali Paquot,
editors, Proc. eLexicography in the 21st century:
New applications, new challenges (eLEX 2009).
Presses Universitaires de Louvain. To appear.
Cédrick Fairon and Sébastien Paumier. 2006. A
translated corpus of 30,000 French SMS. In Proc.
LREC 2006, May.
Cécrick. Fairon, Jean R. Klein, and Sébastien Paumier.
2006. Le langage SMS: étude d’un corpus
informatisé à partir de l’enquête Faites don de
vos SMS à la science. Presses Universitaires de
Louvain. 136 pages.
Emilie Guimier de Neef, Arnaud Debeurme, and
Jungyeul Park. 2007. TILT correcteur de SMS:
évaluation et bilan quantitatif. In Actes de TALN
2007, pages 123–132, Toulouse, France.
C. Douglas Johnson. 1972. Formal aspects of
phonological description. Mouton, The Hague. 779
Catherine Kobus, François Yvon, and Géraldine
Damnati. 2008a. Normalizing SMS: are two
metaphors better than one? In Proc. COLING 2008,
pages 441–448, Manchester, UK.
Catherine Kobus, François Yvon, and Géraldine
Damnati. 2008b. Transcrire les SMS comme on
reconnaît la parole. In Actes de la Conférence sur
le Traitement Automatique des Langues (TALN’08),
pages 128–138, Avignon, France.
Ron Kohavi. 1995. A study of cross-validation
and bootstrap for accuracy estimation and model
selection. In Proc. IJCAI’95, pages 1137–1143.
Vladimir Levenshtein. 1966. Binary codes capable of
correcting deletions, insertions and reversals. Soviet
Physics, 10:707–710.
Mehryar Mohri and Michael Riley. 1997. Weighted
determinization and minimization for large
vocabulary speech recognition. In Proc.
Eurospeech’97, pages 131–134.
Mehryar Mohri and Richard Sproat. 1996. An
efficient compiler for weighted rewrite rules. In
Proc. ACL’96, pages 231–238.
Mehryar Mohri, Fernando Pereira, and Michael Riley.
2000. The design principles of a weighted finite-
state transducer library. Theoretical Computer
Science, 231(1):17–32.
Mehryar Mohri, Fernando Pereira, and Michael Riley.
2001. Generic e-removal algorithm for weighted
automata. Lecture Notes in Computer Science,
2088:230–242.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2001. BLEU: a method for automatic
evaluation of machine translation. In Proc. ACL
2001, pages 311–318.
Emmanuel Roche and Yves Schabes, editors. 1997.
Finite-state language processing. MIT Press,
Cambridge.
Claude E. Shannon. 1948. A mathematical theory of
communication. The Bell System Technical Journal,
27:379–423.
Richard Sproat, A.W. Black, S. Chen, S. Kumar,
M. Ostendorf, and C. Richards. 2001.
Normalization of non-standard words. Computer
Speech &amp; Language, 15(3):287–333.
Crispin Thurlow and Alex Brown. 2003. Generation
txt? The sociolinguistics of young people’s text-
messaging. Discourse Analysis Online, 1(1).
Kristina Toutanova and Robert C. Moore. 2002.
Pronunciation modeling for improved spelling
correction. In Proc. ACL’02, pages 144–151.
François Yvon. 2008. Reorthography of SMS
messages. Technical Report 2008, LIMSI/CNRS,
Orsay, France.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.029840">
<title confidence="0.985307">A hybrid rule/model-based finite-state framework</title>
<abstract confidence="0.755556842105263">for normalizing SMS messages Louise-Amélie (1) CENTAL, Université catholique de Louvain – 1348 Louvain-la-Neuve, Belgium {richard.beaufort,louise-amelie.cougnon,cedrick.fairon}@uclouvain.be (2) TCTS Lab, Université de Mons – 7000 Mons, Belgium sophie.roekhaut@umons.ac.be Abstract In recent years, research in natural language processing has increasingly focused on normalizing SMS messages. Different well-defined approaches have been proposed, but the problem remains far from being solved: best systems achieve a 11% Word Error Rate. This paper presents a method that shares similarities with both spell checking and machine translation approaches. The normalization part of the system is entirely based on models trained from a corpus.</abstract>
<note confidence="0.497078666666667">Evaluated in French by 10-fold-cross validation, the system achieves a 9.3% Word Error Rate and a 0.83 BLEU score.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>AiTi Aw</author>
<author>Min Zhang</author>
<author>Juan Xiao</author>
<author>Jian Su</author>
</authors>
<title>A phrase-based statistical model for SMS text normalization.</title>
<date>2006</date>
<booktitle>In Proc. COLING/ACL</booktitle>
<contexts>
<context position="6229" citStr="Aw et al., 2006" startWordPosition="925" endWordPosition="928">s the language of the source. Choudhury et al. (2007) implemented the noisy channel through a Hidden-Markov Model (HMM) able to handle both graphemic variants and phonetic plays as proposed by (Toutanova and Moore, 2002), while Cook and Stevenson (2009) enhanced the model by adapting the channel’s noise P(O|W, wf) according to a list of predefined observed word formations {wf}: stylistic variation, word clipping, phonetic abbreviations, etc. Whatever the system, the main limitation of the spell The machine translation metaphor, which is historically the first proposed (Bangalore et al., 2002; Aw et al., 2006), considers the process of normalizing SMS as a translation task from a source language (the SMS) to a target language (its standard written form). This standpoint is based on the observation that, on the one side, SMS messages greatly differ from their standard written forms, and that, on the other side, most of the errors cross word boundaries and require a wide context to be handled. On this basis, Aw et al. (2006) proposed a statistical machine translation model working at the phrase-level, by splitting sentences into their k most probable phrases. While this approach achieves really good </context>
</contexts>
<marker>Aw, Zhang, Xiao, Su, 2006</marker>
<rawString>AiTi Aw, Min Zhang, Juan Xiao, and Jian Su. 2006. A phrase-based statistical model for SMS text normalization. In Proc. COLING/ACL 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Srinivas Bangalore</author>
<author>Vanessa Murdock</author>
<author>Giuseppe Riccardi</author>
</authors>
<title>Bootstrapping bilingual data using consensus translation for a multilingual instant messaging system.</title>
<date>2002</date>
<booktitle>In Proc. the 19th international conference on Computational linguistics,</booktitle>
<volume>1</volume>
<pages>pages</pages>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="6211" citStr="Bangalore et al., 2002" startWordPosition="921" endWordPosition="924">’s noise, and P(W) models the language of the source. Choudhury et al. (2007) implemented the noisy channel through a Hidden-Markov Model (HMM) able to handle both graphemic variants and phonetic plays as proposed by (Toutanova and Moore, 2002), while Cook and Stevenson (2009) enhanced the model by adapting the channel’s noise P(O|W, wf) according to a list of predefined observed word formations {wf}: stylistic variation, word clipping, phonetic abbreviations, etc. Whatever the system, the main limitation of the spell The machine translation metaphor, which is historically the first proposed (Bangalore et al., 2002; Aw et al., 2006), considers the process of normalizing SMS as a translation task from a source language (the SMS) to a target language (its standard written form). This standpoint is based on the observation that, on the one side, SMS messages greatly differ from their standard written forms, and that, on the other side, most of the errors cross word boundaries and require a wide context to be handled. On this basis, Aw et al. (2006) proposed a statistical machine translation model working at the phrase-level, by splitting sentences into their k most probable phrases. While this approach ach</context>
</contexts>
<marker>Bangalore, Murdock, Riccardi, 2002</marker>
<rawString>Srinivas Bangalore, Vanessa Murdock, and Giuseppe Riccardi. 2002. Bootstrapping bilingual data using consensus translation for a multilingual instant messaging system. In Proc. the 19th international conference on Computational linguistics, pages 1– 7, Morristown, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Beaufort</author>
</authors>
<title>Application des machines à etats finis en synthèse de la parole. Sélection d’unités non uniformes et correction orthographique.</title>
<date>2008</date>
<booktitle>Ph.D. thesis, FUNDP,</booktitle>
<volume>605</volume>
<pages>pages.</pages>
<location>Namur, Belgium,</location>
<contexts>
<context position="9469" citStr="Beaufort, 2008" startWordPosition="1431" endWordPosition="1432"> boundaries in the normalization process if needed. 3 Overview of the system 3.1 Tools in use In our system, all lexicons, language models and sets of rules are compiled into finite-state machines (FSMs) and combined with the input text by composition (o). The reader who is not familiar with FSMs and their fundamental theoretical properties, like composition, is urged to consult the state-of-the-art literature (Roche and Schabes, 1997; Mohri and Riley, 1997; Mohri et al., 2000; Mohri et al., 2001). We used our own finite-state tools: a finite-state machine library and its associated compiler (Beaufort, 2008). In conformance with the format of the library, the compiler builds finite-state machines from weighted rewrite rules, weighted regular expressions and n-gram models. 3.2 Aims We formulated four constraints before fixing the system’s architecture. First, special tokens, like URLs, phones or currencies, should be identified as soon as possible, to keep them out of the normalization process. Second, word boundaries should be taken into account, as far as they seem reliable enough. The idea, here, is to base the decision on a learning able to catch frequent SMS sequences to include in a dedicate</context>
<context position="11047" citStr="Beaufort, 2008" startWordPosition="1671" endWordPosition="1672">ions. In short, an SMS message first goes through three SMS modules, which normalize its noisy parts. Then, two standard NLP modules produce a morphosyntactic analysis of the normalized text. A last module, finally, takes advantage of this linguistic analysis either to print a text that follows the basic rules of typography, or to synthesize the corresponding speech signal. Because this paper focuses on the normalization task, the rest of this section only presents the SMS modules and the “smart print” output. The morphosyntactic analysis, made of state-of-the-art algorithms, is described in (Beaufort, 2008), and the text-to-speech synthesis system we use is presented in (Colotte and Beaufort, 2005). 3.3.1 SMS modules SMS preprocessing. This module relies on a set of manually-tuned rewrite rules. It identifies paragraphs and sentences, but also some Figure 1: Architecture of the system SMS message Smart print TTS engine Standard written message Speech SMS Modules SMS Preprocessing SMS Normalization SMS Postprocessing Standard NLP Modules Morphological analysis Contextual disambiguation 772 unambiguous tokens: URLs, phone numbers, dates, times, currencies, units of measurement and, last but not le</context>
</contexts>
<marker>Beaufort, 2008</marker>
<rawString>Richard Beaufort. 2008. Application des machines à etats finis en synthèse de la parole. Sélection d’unités non uniformes et correction orthographique. Ph.D. thesis, FUNDP, Namur, Belgium, March. 605 pages.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Markus Bieswanger</author>
</authors>
<title>abbrevi8 or not 2 abbrevi8: A contrastive analysis of different space and timesaving strategies in English and German text messages.</title>
<date>2007</date>
<booktitle>In Texas Linguistics Forum,</booktitle>
<volume>50</volume>
<contexts>
<context position="1315" citStr="Bieswanger, 2007" startWordPosition="176" endWordPosition="177">s with both spell checking and machine translation approaches. The normalization part of the system is entirely based on models trained from a corpus. Evaluated in French by 10-fold-cross validation, the system achieves a 9.3% Word Error Rate and a 0.83 BLEU score. 1 Introduction Introduced a few years ago, Short Message Service (SMS) offers the possibility of exchanging written messages between mobile phones. SMS has quickly been adopted by users. These messages often greatly deviate from traditional spelling conventions. As shown by specialists (Thurlow and Brown, 2003; Fairon et al., 2006; Bieswanger, 2007), this variability is due to the simultaneous use of numerous coding strategies, like phonetic plays (2m1 read ‘demain’, “tomorrow”), phonetic transcriptions (kom instead of ‘comme’, “like”), consonant skeletons (tjrs for ‘toujours’, “always”), misapplied, missing or incorrect separators (j esper for ‘j’espère’, “I hope”; j’croibi1k, instead of ‘je crois bien que’, “I am pretty sure that”), etc. These deviations are due to three main factors: the small number of characters allowed per text message by the service (140 bytes), the constraints of the small phones’ keypads and, last but not least,</context>
</contexts>
<marker>Bieswanger, 2007</marker>
<rawString>Markus Bieswanger. 2007. abbrevi8 or not 2 abbrevi8: A contrastive analysis of different space and timesaving strategies in English and German text messages. In Texas Linguistics Forum, volume 50.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stanley F Chen</author>
<author>Joshua Goodman</author>
</authors>
<title>An empirical study of smoothing techniques for language modeling.</title>
<date>1998</date>
<tech>Technical Report 10-98,</tech>
<institution>Computer Science Group, Harvard University.</institution>
<contexts>
<context position="23487" citStr="Chen and Goodman, 1998" startWordPosition="3770" endWordPosition="3773">me input sequence (for instance, aussi) are optional (?-*), except the last one, which is obligatory (-*). In our finite-state compiler, this convention allows the application of all concurrent normalizations on the same input sequence, as depicted in Figure 5. In our real list of OOV rules, the input sequence a corresponds to 231 normalizations, while au accepts 43 normalizations and aussi, only 3. This highlights the interest, in terms of efficiency, of the long-to-short rule ordering. 4.6 The language model Our language model is an n-gram of lexical forms, smoothed by linear interpolation (Chen and Goodman, 1998), estimated on the normalized part of our training corpus and compiled into a weighted FST LM,,,. At this point, this FST cannot be combined with our other models, because it works on lexical units and not on characters. This problem is solved by composing LM,,, with another FST L, which represents a lexicon mapping each input word, considered as a string of characters, onto the same output words, but considered here as a lexical unit. Lexical units are then permanently removed from the language model by keeping only the first projection (the input side) of the composition: LM = FirstProjectio</context>
</contexts>
<marker>Chen, Goodman, 1998</marker>
<rawString>Stanley F. Chen and Joshua Goodman. 1998. An empirical study of smoothing techniques for language modeling. Technical Report 10-98, Computer Science Group, Harvard University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Noam Chomsky</author>
<author>Morris Halle</author>
</authors>
<title>The sound pattern of English. Harper and Row,</title>
<date>1968</date>
<location>New York, NY.</location>
<contexts>
<context position="20778" citStr="Chomsky and Halle, 1968" startWordPosition="3299" endWordPosition="3302"> compiled into an FST, in which each IV sequence is mapped onto the list of its possible normalizations. • SIV is a weighted lexicon of separators, in which each separator is mapped onto the list of its possible normalizations. The deletion is often one of the possible normalization of a separator. Otherwise, the deletion is added and is weighted by the following smoothed probability: 0.1 p(DEL|w) = Occ(w) + 0.1 (10) 4.5 The OOV rewrite model ROOV In contrast to the other models, this one is not a regular expression made of weighted lexicons. It corresponds to a set of weighted rewrite rules (Chomsky and Halle, 1968; Johnson, 1972; Mohri and Sproat, 1996) learned from the alignment. Developed in the framework of generative phonology, rules take the form 0 → 0 : A _ p / w (11) which means that the replacement 0 → 0 is only performed when 0 is surrounded by A on the left and p on the right, and gets the weight w. However, in our case, rules take the simpler form 0 → 0 / w (12) which means that the replacement 0 → 0 is always performed, whatever the context. Inputs of our rules (0) are sequences of 1 to 5 characters taken from the SMS side of the alignment, while outputs (0) are their corresponding normaliz</context>
</contexts>
<marker>Chomsky, Halle, 1968</marker>
<rawString>Noam Chomsky and Morris Halle. 1968. The sound pattern of English. Harper and Row, New York, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Monojit Choudhury</author>
<author>Rahul Saraf</author>
<author>Vijit Jain</author>
</authors>
<title>Animesh Mukherjee, Sudeshna Sarkar1, and Anupam Basu.</title>
<date>2007</date>
<journal>International Journal on Document Analysis and Recognition,</journal>
<volume>10</volume>
<issue>3</issue>
<pages>174</pages>
<contexts>
<context position="4598" citStr="Choudhury et al., 2007" startWordPosition="667" endWordPosition="670">guistics checking approach is the excessive confidence it places in word boundaries. previous works. Section 6 draws conclusions and considers some future possible improvements of the method. 2 Related work As highlighted by Kobus et al. (2008b), SMS normalization, up to now, has been handled through three well-known NLP metaphors: spell checking, machine translation and automatic speech recognition. In this section, we only present the pros and cons of these approaches. Their results are given in Section 5, focused on our evaluation. The spell checking metaphor (Guimier de Neef et al., 2007; Choudhury et al., 2007; Cook and Stevenson, 2009) performs the normalization task on a word-per-word basis. On the assumption that most words should be correct for the purpose of communication, its principle is to keep InVocabulary words out of the correction process. Guimier de Neef et al. (2007) proposed a rulebased system that uses only a few linguistic resources dedicated to SMS, like specific lexicons of abbreviations. Choudhury et al. (2007) and Cook and Stevenson (2009) preferred to implement the noisy channel metaphor (Shannon, 1948), which assumes a communication process in which a sender emits the intende</context>
</contexts>
<marker>Choudhury, Saraf, Jain, 2007</marker>
<rawString>Monojit Choudhury, Rahul Saraf, Vijit Jain, Animesh Mukherjee, Sudeshna Sarkar1, and Anupam Basu. 2007. Investigation and modeling of the structure of texting language. International Journal on Document Analysis and Recognition, 10(3):157– 174.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vincent Colotte</author>
<author>Richard Beaufort</author>
</authors>
<title>Linguistic features weighting for a text-to-speech system without prosody model.</title>
<date>2005</date>
<booktitle>In Proc. Interspeech’05,</booktitle>
<pages>2549--2552</pages>
<contexts>
<context position="11140" citStr="Colotte and Beaufort, 2005" startWordPosition="1683" endWordPosition="1686">ize its noisy parts. Then, two standard NLP modules produce a morphosyntactic analysis of the normalized text. A last module, finally, takes advantage of this linguistic analysis either to print a text that follows the basic rules of typography, or to synthesize the corresponding speech signal. Because this paper focuses on the normalization task, the rest of this section only presents the SMS modules and the “smart print” output. The morphosyntactic analysis, made of state-of-the-art algorithms, is described in (Beaufort, 2008), and the text-to-speech synthesis system we use is presented in (Colotte and Beaufort, 2005). 3.3.1 SMS modules SMS preprocessing. This module relies on a set of manually-tuned rewrite rules. It identifies paragraphs and sentences, but also some Figure 1: Architecture of the system SMS message Smart print TTS engine Standard written message Speech SMS Modules SMS Preprocessing SMS Normalization SMS Postprocessing Standard NLP Modules Morphological analysis Contextual disambiguation 772 unambiguous tokens: URLs, phone numbers, dates, times, currencies, units of measurement and, last but not least in the context of SMS, smileys2. These tokens are kept out of the normalization process, </context>
</contexts>
<marker>Colotte, Beaufort, 2005</marker>
<rawString>Vincent Colotte and Richard Beaufort. 2005. Linguistic features weighting for a text-to-speech system without prosody model. In Proc. Interspeech’05, pages 2549–2552.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Cook</author>
<author>Suzanne Stevenson</author>
</authors>
<title>An unsupervised model for text message normalization.</title>
<date>2009</date>
<booktitle>In Proc. Workshop on Computational Approaches to Linguistic Creativity,</booktitle>
<pages>71--78</pages>
<contexts>
<context position="4625" citStr="Cook and Stevenson, 2009" startWordPosition="671" endWordPosition="674">ch is the excessive confidence it places in word boundaries. previous works. Section 6 draws conclusions and considers some future possible improvements of the method. 2 Related work As highlighted by Kobus et al. (2008b), SMS normalization, up to now, has been handled through three well-known NLP metaphors: spell checking, machine translation and automatic speech recognition. In this section, we only present the pros and cons of these approaches. Their results are given in Section 5, focused on our evaluation. The spell checking metaphor (Guimier de Neef et al., 2007; Choudhury et al., 2007; Cook and Stevenson, 2009) performs the normalization task on a word-per-word basis. On the assumption that most words should be correct for the purpose of communication, its principle is to keep InVocabulary words out of the correction process. Guimier de Neef et al. (2007) proposed a rulebased system that uses only a few linguistic resources dedicated to SMS, like specific lexicons of abbreviations. Choudhury et al. (2007) and Cook and Stevenson (2009) preferred to implement the noisy channel metaphor (Shannon, 1948), which assumes a communication process in which a sender emits the intended message W through an impe</context>
<context position="5866" citStr="Cook and Stevenson (2009)" startWordPosition="871" endWordPosition="874">mmunication channel, such that the sequence O observed by the recipient is a noisy version of the original message. On this basis, the idea is to recover the intended message W hidden behind the sequences of observations O, by maximizing: Wmax = arg max P(W |O) (1) P(O|W) P(W) P(O) where P(O) is ignored because constant, P(O|W) models the channel’s noise, and P(W) models the language of the source. Choudhury et al. (2007) implemented the noisy channel through a Hidden-Markov Model (HMM) able to handle both graphemic variants and phonetic plays as proposed by (Toutanova and Moore, 2002), while Cook and Stevenson (2009) enhanced the model by adapting the channel’s noise P(O|W, wf) according to a list of predefined observed word formations {wf}: stylistic variation, word clipping, phonetic abbreviations, etc. Whatever the system, the main limitation of the spell The machine translation metaphor, which is historically the first proposed (Bangalore et al., 2002; Aw et al., 2006), considers the process of normalizing SMS as a translation task from a source language (the SMS) to a target language (its standard written form). This standpoint is based on the observation that, on the one side, SMS messages greatly d</context>
</contexts>
<marker>Cook, Stevenson, 2009</marker>
<rawString>Paul Cook and Suzanne Stevenson. 2009. An unsupervised model for text message normalization. In Proc. Workshop on Computational Approaches to Linguistic Creativity, pages 71–78.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Louise-Amélie Cougnon</author>
<author>Richard Beaufort</author>
</authors>
<title>SSLD: a French SMS to standard language dictionary.</title>
<date>2009</date>
<booktitle>In Sylviane Granger and Magali Paquot, editors, Proc. eLexicography in the 21st century: New applications, new challenges (eLEX 2009). Presses Universitaires de Louvain.</booktitle>
<note>To appear.</note>
<contexts>
<context position="16847" citStr="Cougnon and Beaufort, 2009" startWordPosition="2602" endWordPosition="2605">r instance, for the SMS form kozer ([koze]) and its standard transcription causé (“talked”), as illustrated by Figure 2. However, from a linguistic standpoint, alignment (1) is preferable, because corresponding graphemes are aligned on their first character. In order to automatically choose this preferred alignment, we had to distinguish the three editoperations, according to the characters to be aligned. For that purpose, probabilities were required. Computing probabilities for each operation according to the characters to be aligned was performed through an iterative algorithm described in (Cougnon and Beaufort, 2009). In short, this algorithm gradually learns the best way of aligning strings. On our parallel corpora, it converged after 7 iterations and provided us with a result from which the learning could start. (1) ko_ser (2) k_oser causé_ causé_ (3) ko_ser (4) k_oser caus_é caus_é Figure 2: Different equidistant alignments, using a standard edit-cost of 1. Underscores (‘_’) mean insertion in the upper string, and deletion in the lower string. 4.3 The split model Sp In natural language processing, a word is commonly defined as “a sequence of alphabetic characters between separators”, and an IV word is </context>
</contexts>
<marker>Cougnon, Beaufort, 2009</marker>
<rawString>Louise-Amélie Cougnon and Richard Beaufort. 2009. SSLD: a French SMS to standard language dictionary. In Sylviane Granger and Magali Paquot, editors, Proc. eLexicography in the 21st century: New applications, new challenges (eLEX 2009). Presses Universitaires de Louvain. To appear.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cédrick Fairon</author>
<author>Sébastien Paumier</author>
</authors>
<title>A translated corpus of 30,000 French SMS.</title>
<date>2006</date>
<booktitle>In Proc. LREC</booktitle>
<contexts>
<context position="15587" citStr="Fairon and Paumier, 2006" startWordPosition="2415" endWordPosition="2418">d together and composed with the lexical language model LM. The result of this composition is a word lattice, of which we take the most probable word sequence S&apos; by applying a best-path algorithm: S&apos; = BestPath( ((Dmj�1Tj) o LM ) (6) where m is the number of tokens of S. In S&apos;, each noisy token Tj of S is mapped onto its most probable normalization. P(O|W) = (2) sg&apos;i = (4) 773 4.2 The corpus alignment Our normalization models were trained on a French SMS corpus of 30,000 messages, gathered in Belgium, semi-automatically anonymized and manually normalized by the Catholic University of Louvain (Fairon and Paumier, 2006). Together, the SMS corpus and its transcription constitute parallel corpora aligned at the message-level. However, in order to learn pieces of knowledge from these corpora, we needed a string alignment at the character-level. One way of implementing this string alignment is to compute the edit-distance of two strings, which measures the minimum number of operations (substitutions, insertions, deletions) required to transform one string into the other (Levenshtein, 1966). Using this algorithm, in which each operation gets a cost of 1, two strings may be aligned in different ways with the same </context>
</contexts>
<marker>Fairon, Paumier, 2006</marker>
<rawString>Cédrick Fairon and Sébastien Paumier. 2006. A translated corpus of 30,000 French SMS. In Proc. LREC 2006, May. Cécrick. Fairon, Jean R. Klein, and Sébastien Paumier.</rawString>
</citation>
<citation valid="true">
<title>Le langage SMS: étude d’un corpus informatisé à partir de l’enquête Faites don de vos SMS à la science. Presses Universitaires de Louvain.</title>
<date>2006</date>
<volume>136</volume>
<pages>pages.</pages>
<contexts>
<context position="6650" citStr="(2006)" startWordPosition="1001" endWordPosition="1001">viations, etc. Whatever the system, the main limitation of the spell The machine translation metaphor, which is historically the first proposed (Bangalore et al., 2002; Aw et al., 2006), considers the process of normalizing SMS as a translation task from a source language (the SMS) to a target language (its standard written form). This standpoint is based on the observation that, on the one side, SMS messages greatly differ from their standard written forms, and that, on the other side, most of the errors cross word boundaries and require a wide context to be handled. On this basis, Aw et al. (2006) proposed a statistical machine translation model working at the phrase-level, by splitting sentences into their k most probable phrases. While this approach achieves really good results, Kobus et al. (2008b) make the assertion that a phrase-based translation can hardly capture the lexical creativity observed in SMS messages. Moreover, the translation framework, which can handle many-to-many correspondences between sources and targets, exceeds the needs of SMS normalization, where the normalization task is almost deterministic. Based on this analysis, Kobus et al. (2008b) proposed to handle SM</context>
</contexts>
<marker>2006</marker>
<rawString>2006. Le langage SMS: étude d’un corpus informatisé à partir de l’enquête Faites don de vos SMS à la science. Presses Universitaires de Louvain. 136 pages.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emilie Guimier de Neef</author>
<author>Arnaud Debeurme</author>
<author>Jungyeul Park</author>
</authors>
<title>TILT correcteur de SMS: évaluation et bilan quantitatif.</title>
<date>2007</date>
<journal>Mouton, The Hague.</journal>
<booktitle>In Actes de TALN</booktitle>
<volume>779</volume>
<pages>123--132</pages>
<location>Toulouse,</location>
<marker>de Neef, Debeurme, Park, 2007</marker>
<rawString>Emilie Guimier de Neef, Arnaud Debeurme, and Jungyeul Park. 2007. TILT correcteur de SMS: évaluation et bilan quantitatif. In Actes de TALN 2007, pages 123–132, Toulouse, France. C. Douglas Johnson. 1972. Formal aspects of phonological description. Mouton, The Hague. 779</rawString>
</citation>
<citation valid="true">
<authors>
<author>Catherine Kobus</author>
<author>François Yvon</author>
<author>Géraldine Damnati</author>
</authors>
<title>Normalizing SMS: are two metaphors better than one?</title>
<date>2008</date>
<booktitle>In Proc. COLING</booktitle>
<pages>441--448</pages>
<location>Manchester, UK.</location>
<contexts>
<context position="4219" citStr="Kobus et al. (2008" startWordPosition="608" endWordPosition="611">tion 4 focuses on how we learn and combine our normalization models. Section 5 evaluates the system and compares it to 1The Vocalise project. See cental.fltr.ucl.ac.be/team/projects/vocalise/. 770 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 770–779, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics checking approach is the excessive confidence it places in word boundaries. previous works. Section 6 draws conclusions and considers some future possible improvements of the method. 2 Related work As highlighted by Kobus et al. (2008b), SMS normalization, up to now, has been handled through three well-known NLP metaphors: spell checking, machine translation and automatic speech recognition. In this section, we only present the pros and cons of these approaches. Their results are given in Section 5, focused on our evaluation. The spell checking metaphor (Guimier de Neef et al., 2007; Choudhury et al., 2007; Cook and Stevenson, 2009) performs the normalization task on a word-per-word basis. On the assumption that most words should be correct for the purpose of communication, its principle is to keep InVocabulary words out o</context>
<context position="6856" citStr="Kobus et al. (2008" startWordPosition="1028" endWordPosition="1031">rs the process of normalizing SMS as a translation task from a source language (the SMS) to a target language (its standard written form). This standpoint is based on the observation that, on the one side, SMS messages greatly differ from their standard written forms, and that, on the other side, most of the errors cross word boundaries and require a wide context to be handled. On this basis, Aw et al. (2006) proposed a statistical machine translation model working at the phrase-level, by splitting sentences into their k most probable phrases. While this approach achieves really good results, Kobus et al. (2008b) make the assertion that a phrase-based translation can hardly capture the lexical creativity observed in SMS messages. Moreover, the translation framework, which can handle many-to-many correspondences between sources and targets, exceeds the needs of SMS normalization, where the normalization task is almost deterministic. Based on this analysis, Kobus et al. (2008b) proposed to handle SMS normalization through an automatic speech recognition (ASR) metaphor. The starting point of this approach is the observation that SMS messages present a lot of phonetic plays that sometimes make the SMS w</context>
<context position="26806" citStr="Kobus et al. (2008" startWordPosition="4349" endWordPosition="4352">z Intel Core 2 Duo CPU, 4 GB 667 MHz DDR2 SDRAM, running Mac OS X version 10.5.8. The evaluation was performed on the corpus of 30,000 French SMS presented in Section 4.2, by ten-fold cross-validation (Kohavi, 1995). The principle of this method of evaluation is to split the initial corpus into 10 subsets of equal size. The system is then trained 10 times, each time leaving out one of the subsets from the training corpus, but using only this omitted subset as test corpus. The language model of the evaluation is a 3-gram. We did not try a 4-gram. This choice was motivated by the experiments of Kobus et al. (2008a), who showed on a French corpus comparable to ours that, if using a larger language model is always rewarded, the improvement quickly decreases with every higher level and is already quite small between 2-gram and 3-gram. Table 1 presents the results in terms of efficiency. The system seems efficient, while we cannot compare it with other methods, which did not provide us with this information. Table 2, part 1, presents the performance of our approach (Hybrid) and compares it to a trivial copy-paste (Copy). The system was evaluated in terms of BLEU score (Papineni et al., 2001), Word Error R</context>
<context position="28308" citStr="Kobus et al. (2008" startWordPosition="4593" endWordPosition="4596">hlight the fact that our system is still at pains to significantly reduce the SER, while results in terms of WER and BLEU score are quite encouraging. Table 2, part 2, provides the results of the state-of-the-art approaches. The only results truly comparable to ours are those of Guimier de Neef et al. (2007), who evaluated their approach on the same corpus as ours5; clearly, our method 5They performed an evaluation without ten-fold crossmean dev. bps 1836.57 159.63 ms/SMS (140b) 76.23 22.34 Table 1: Efficiency of the system. outperforms theirs. Our results also seem a bit better than those of Kobus et al. (2008a), although the comparison with this system, also evaluated in French, is less easy: they combined the French corpus we used with another one and performed a single validation, using a bigger training corpus (36.704 messages) for a test corpus quite similar to one of our subsets (2.998 SMS). Other systems were evaluated in English, and results are more difficult to compare; at least, our results seem in line with them. The analysis of the normalizations produced by our system pointed out that, most often, errors are contextual and concern the gender (quel(le), “what”), the number (bisou(s), “</context>
<context position="31625" citStr="Kobus et al. (2008" startWordPosition="5133" endWordPosition="5136">s depending on whether this sequence is known or not. Evaluated by ten-fold cross-validation, the system seems efficient, and the performance in terms of BLEU score and WER are quite encouraging. However, the SER remains too high, which emphasizes the fact that the system needs several improvements. First of all, the model should take phonetic similarities into account, because SMS messages contain a lot of phonetic plays. The phonetic model, for instance, should know that o, au, eau, ... , aux can all be pronounced [o], while è, ais, ait, ... , aient are often pronounced [E]. However, unlike Kobus et al. (2008a), we feel that this model must avoid the normalization step in which the graphemic sequence is converted into phonemes, because this conversion prevents the next steps from knowing which graphemes were in the initial sequence. Instead, we propose to learn phonetic similarities from a dictionary of words with phonemic transcriptions, and to build graphemes-to-graphemes rules. These rules could then be automatically weighted, by learning their frequencies from our aligned corpora. Furthermore, this model should be able to allow for timbre variation, like [e]–[E], in order to allow similarities</context>
</contexts>
<marker>Kobus, Yvon, Damnati, 2008</marker>
<rawString>Catherine Kobus, François Yvon, and Géraldine Damnati. 2008a. Normalizing SMS: are two metaphors better than one? In Proc. COLING 2008, pages 441–448, Manchester, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Catherine Kobus</author>
<author>François Yvon</author>
<author>Géraldine Damnati</author>
</authors>
<title>Transcrire les SMS comme on reconnaît la parole.</title>
<date>2008</date>
<booktitle>In Actes de la Conférence sur le Traitement Automatique des Langues (TALN’08),</booktitle>
<pages>128--138</pages>
<location>Avignon, France.</location>
<contexts>
<context position="4219" citStr="Kobus et al. (2008" startWordPosition="608" endWordPosition="611">tion 4 focuses on how we learn and combine our normalization models. Section 5 evaluates the system and compares it to 1The Vocalise project. See cental.fltr.ucl.ac.be/team/projects/vocalise/. 770 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 770–779, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics checking approach is the excessive confidence it places in word boundaries. previous works. Section 6 draws conclusions and considers some future possible improvements of the method. 2 Related work As highlighted by Kobus et al. (2008b), SMS normalization, up to now, has been handled through three well-known NLP metaphors: spell checking, machine translation and automatic speech recognition. In this section, we only present the pros and cons of these approaches. Their results are given in Section 5, focused on our evaluation. The spell checking metaphor (Guimier de Neef et al., 2007; Choudhury et al., 2007; Cook and Stevenson, 2009) performs the normalization task on a word-per-word basis. On the assumption that most words should be correct for the purpose of communication, its principle is to keep InVocabulary words out o</context>
<context position="6856" citStr="Kobus et al. (2008" startWordPosition="1028" endWordPosition="1031">rs the process of normalizing SMS as a translation task from a source language (the SMS) to a target language (its standard written form). This standpoint is based on the observation that, on the one side, SMS messages greatly differ from their standard written forms, and that, on the other side, most of the errors cross word boundaries and require a wide context to be handled. On this basis, Aw et al. (2006) proposed a statistical machine translation model working at the phrase-level, by splitting sentences into their k most probable phrases. While this approach achieves really good results, Kobus et al. (2008b) make the assertion that a phrase-based translation can hardly capture the lexical creativity observed in SMS messages. Moreover, the translation framework, which can handle many-to-many correspondences between sources and targets, exceeds the needs of SMS normalization, where the normalization task is almost deterministic. Based on this analysis, Kobus et al. (2008b) proposed to handle SMS normalization through an automatic speech recognition (ASR) metaphor. The starting point of this approach is the observation that SMS messages present a lot of phonetic plays that sometimes make the SMS w</context>
<context position="26806" citStr="Kobus et al. (2008" startWordPosition="4349" endWordPosition="4352">z Intel Core 2 Duo CPU, 4 GB 667 MHz DDR2 SDRAM, running Mac OS X version 10.5.8. The evaluation was performed on the corpus of 30,000 French SMS presented in Section 4.2, by ten-fold cross-validation (Kohavi, 1995). The principle of this method of evaluation is to split the initial corpus into 10 subsets of equal size. The system is then trained 10 times, each time leaving out one of the subsets from the training corpus, but using only this omitted subset as test corpus. The language model of the evaluation is a 3-gram. We did not try a 4-gram. This choice was motivated by the experiments of Kobus et al. (2008a), who showed on a French corpus comparable to ours that, if using a larger language model is always rewarded, the improvement quickly decreases with every higher level and is already quite small between 2-gram and 3-gram. Table 1 presents the results in terms of efficiency. The system seems efficient, while we cannot compare it with other methods, which did not provide us with this information. Table 2, part 1, presents the performance of our approach (Hybrid) and compares it to a trivial copy-paste (Copy). The system was evaluated in terms of BLEU score (Papineni et al., 2001), Word Error R</context>
<context position="28308" citStr="Kobus et al. (2008" startWordPosition="4593" endWordPosition="4596">hlight the fact that our system is still at pains to significantly reduce the SER, while results in terms of WER and BLEU score are quite encouraging. Table 2, part 2, provides the results of the state-of-the-art approaches. The only results truly comparable to ours are those of Guimier de Neef et al. (2007), who evaluated their approach on the same corpus as ours5; clearly, our method 5They performed an evaluation without ten-fold crossmean dev. bps 1836.57 159.63 ms/SMS (140b) 76.23 22.34 Table 1: Efficiency of the system. outperforms theirs. Our results also seem a bit better than those of Kobus et al. (2008a), although the comparison with this system, also evaluated in French, is less easy: they combined the French corpus we used with another one and performed a single validation, using a bigger training corpus (36.704 messages) for a test corpus quite similar to one of our subsets (2.998 SMS). Other systems were evaluated in English, and results are more difficult to compare; at least, our results seem in line with them. The analysis of the normalizations produced by our system pointed out that, most often, errors are contextual and concern the gender (quel(le), “what”), the number (bisou(s), “</context>
<context position="31625" citStr="Kobus et al. (2008" startWordPosition="5133" endWordPosition="5136">s depending on whether this sequence is known or not. Evaluated by ten-fold cross-validation, the system seems efficient, and the performance in terms of BLEU score and WER are quite encouraging. However, the SER remains too high, which emphasizes the fact that the system needs several improvements. First of all, the model should take phonetic similarities into account, because SMS messages contain a lot of phonetic plays. The phonetic model, for instance, should know that o, au, eau, ... , aux can all be pronounced [o], while è, ais, ait, ... , aient are often pronounced [E]. However, unlike Kobus et al. (2008a), we feel that this model must avoid the normalization step in which the graphemic sequence is converted into phonemes, because this conversion prevents the next steps from knowing which graphemes were in the initial sequence. Instead, we propose to learn phonetic similarities from a dictionary of words with phonemic transcriptions, and to build graphemes-to-graphemes rules. These rules could then be automatically weighted, by learning their frequencies from our aligned corpora. Furthermore, this model should be able to allow for timbre variation, like [e]–[E], in order to allow similarities</context>
</contexts>
<marker>Kobus, Yvon, Damnati, 2008</marker>
<rawString>Catherine Kobus, François Yvon, and Géraldine Damnati. 2008b. Transcrire les SMS comme on reconnaît la parole. In Actes de la Conférence sur le Traitement Automatique des Langues (TALN’08), pages 128–138, Avignon, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ron Kohavi</author>
</authors>
<title>A study of cross-validation and bootstrap for accuracy estimation and model selection. In</title>
<date>1995</date>
<booktitle>Proc. IJCAI’95,</booktitle>
<pages>1137--1143</pages>
<contexts>
<context position="26403" citStr="Kohavi, 1995" startWordPosition="4277" endWordPosition="4278"> / 9.1175 &amp;quot;a&amp;quot; ?-&gt; &amp;quot;ga&amp;quot; / 6.2019 &amp;quot;a&amp;quot; ?-&gt; &amp;quot;à&amp;quot; / 3.5013 &amp;quot;a&amp;quot; -&gt; &amp;quot;a&amp;quot; / 0.3012 s/0.02 u 6:&amp;quot; &amp;quot;/8.41 a s s i 6:&amp;quot; &amp;quot; a:o/6.67 u 776 are still present in S. For this reason, S is first composed with an FST Reduce, which maps each special character onto its corresponding category: S o Reduce o LM (14) 5 Evaluation The performance and the efficiency of our system were evaluated on a MacBook Pro with a 2.4 GHz Intel Core 2 Duo CPU, 4 GB 667 MHz DDR2 SDRAM, running Mac OS X version 10.5.8. The evaluation was performed on the corpus of 30,000 French SMS presented in Section 4.2, by ten-fold cross-validation (Kohavi, 1995). The principle of this method of evaluation is to split the initial corpus into 10 subsets of equal size. The system is then trained 10 times, each time leaving out one of the subsets from the training corpus, but using only this omitted subset as test corpus. The language model of the evaluation is a 3-gram. We did not try a 4-gram. This choice was motivated by the experiments of Kobus et al. (2008a), who showed on a French corpus comparable to ours that, if using a larger language model is always rewarded, the improvement quickly decreases with every higher level and is already quite small </context>
</contexts>
<marker>Kohavi, 1995</marker>
<rawString>Ron Kohavi. 1995. A study of cross-validation and bootstrap for accuracy estimation and model selection. In Proc. IJCAI’95, pages 1137–1143.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vladimir Levenshtein</author>
</authors>
<title>Binary codes capable of correcting deletions, insertions and reversals.</title>
<date>1966</date>
<journal>Soviet Physics,</journal>
<pages>10--707</pages>
<contexts>
<context position="16062" citStr="Levenshtein, 1966" startWordPosition="2485" endWordPosition="2486">es, gathered in Belgium, semi-automatically anonymized and manually normalized by the Catholic University of Louvain (Fairon and Paumier, 2006). Together, the SMS corpus and its transcription constitute parallel corpora aligned at the message-level. However, in order to learn pieces of knowledge from these corpora, we needed a string alignment at the character-level. One way of implementing this string alignment is to compute the edit-distance of two strings, which measures the minimum number of operations (substitutions, insertions, deletions) required to transform one string into the other (Levenshtein, 1966). Using this algorithm, in which each operation gets a cost of 1, two strings may be aligned in different ways with the same global cost. This is the case, for instance, for the SMS form kozer ([koze]) and its standard transcription causé (“talked”), as illustrated by Figure 2. However, from a linguistic standpoint, alignment (1) is preferable, because corresponding graphemes are aligned on their first character. In order to automatically choose this preferred alignment, we had to distinguish the three editoperations, according to the characters to be aligned. For that purpose, probabilities w</context>
</contexts>
<marker>Levenshtein, 1966</marker>
<rawString>Vladimir Levenshtein. 1966. Binary codes capable of correcting deletions, insertions and reversals. Soviet Physics, 10:707–710.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mehryar Mohri</author>
<author>Michael Riley</author>
</authors>
<title>Weighted determinization and minimization for large vocabulary speech recognition.</title>
<date>1997</date>
<booktitle>In Proc. Eurospeech’97,</booktitle>
<pages>131--134</pages>
<contexts>
<context position="9315" citStr="Mohri and Riley, 1997" startWordPosition="1405" endWordPosition="1408">n as possible and try to rely on word boundaries when they seem reliable enough; but like in the machine translation task, our method intrinsically handles word boundaries in the normalization process if needed. 3 Overview of the system 3.1 Tools in use In our system, all lexicons, language models and sets of rules are compiled into finite-state machines (FSMs) and combined with the input text by composition (o). The reader who is not familiar with FSMs and their fundamental theoretical properties, like composition, is urged to consult the state-of-the-art literature (Roche and Schabes, 1997; Mohri and Riley, 1997; Mohri et al., 2000; Mohri et al., 2001). We used our own finite-state tools: a finite-state machine library and its associated compiler (Beaufort, 2008). In conformance with the format of the library, the compiler builds finite-state machines from weighted rewrite rules, weighted regular expressions and n-gram models. 3.2 Aims We formulated four constraints before fixing the system’s architecture. First, special tokens, like URLs, phones or currencies, should be identified as soon as possible, to keep them out of the normalization process. Second, word boundaries should be taken into account</context>
</contexts>
<marker>Mohri, Riley, 1997</marker>
<rawString>Mehryar Mohri and Michael Riley. 1997. Weighted determinization and minimization for large vocabulary speech recognition. In Proc. Eurospeech’97, pages 131–134.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mehryar Mohri</author>
<author>Richard Sproat</author>
</authors>
<title>An efficient compiler for weighted rewrite rules.</title>
<date>1996</date>
<booktitle>In Proc. ACL’96,</booktitle>
<pages>231--238</pages>
<contexts>
<context position="20818" citStr="Mohri and Sproat, 1996" startWordPosition="3305" endWordPosition="3308">sequence is mapped onto the list of its possible normalizations. • SIV is a weighted lexicon of separators, in which each separator is mapped onto the list of its possible normalizations. The deletion is often one of the possible normalization of a separator. Otherwise, the deletion is added and is weighted by the following smoothed probability: 0.1 p(DEL|w) = Occ(w) + 0.1 (10) 4.5 The OOV rewrite model ROOV In contrast to the other models, this one is not a regular expression made of weighted lexicons. It corresponds to a set of weighted rewrite rules (Chomsky and Halle, 1968; Johnson, 1972; Mohri and Sproat, 1996) learned from the alignment. Developed in the framework of generative phonology, rules take the form 0 → 0 : A _ p / w (11) which means that the replacement 0 → 0 is only performed when 0 is surrounded by A on the left and p on the right, and gets the weight w. However, in our case, rules take the simpler form 0 → 0 / w (12) which means that the replacement 0 → 0 is always performed, whatever the context. Inputs of our rules (0) are sequences of 1 to 5 characters taken from the SMS side of the alignment, while outputs (0) are their corresponding normalizations. Our rules are sorted in the reve</context>
</contexts>
<marker>Mohri, Sproat, 1996</marker>
<rawString>Mehryar Mohri and Richard Sproat. 1996. An efficient compiler for weighted rewrite rules. In Proc. ACL’96, pages 231–238.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mehryar Mohri</author>
<author>Fernando Pereira</author>
<author>Michael Riley</author>
</authors>
<title>The design principles of a weighted finitestate transducer library.</title>
<date>2000</date>
<journal>Theoretical Computer Science,</journal>
<volume>231</volume>
<issue>1</issue>
<contexts>
<context position="9335" citStr="Mohri et al., 2000" startWordPosition="1409" endWordPosition="1412">o rely on word boundaries when they seem reliable enough; but like in the machine translation task, our method intrinsically handles word boundaries in the normalization process if needed. 3 Overview of the system 3.1 Tools in use In our system, all lexicons, language models and sets of rules are compiled into finite-state machines (FSMs) and combined with the input text by composition (o). The reader who is not familiar with FSMs and their fundamental theoretical properties, like composition, is urged to consult the state-of-the-art literature (Roche and Schabes, 1997; Mohri and Riley, 1997; Mohri et al., 2000; Mohri et al., 2001). We used our own finite-state tools: a finite-state machine library and its associated compiler (Beaufort, 2008). In conformance with the format of the library, the compiler builds finite-state machines from weighted rewrite rules, weighted regular expressions and n-gram models. 3.2 Aims We formulated four constraints before fixing the system’s architecture. First, special tokens, like URLs, phones or currencies, should be identified as soon as possible, to keep them out of the normalization process. Second, word boundaries should be taken into account, as far as they see</context>
</contexts>
<marker>Mohri, Pereira, Riley, 2000</marker>
<rawString>Mehryar Mohri, Fernando Pereira, and Michael Riley. 2000. The design principles of a weighted finitestate transducer library. Theoretical Computer Science, 231(1):17–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mehryar Mohri</author>
<author>Fernando Pereira</author>
<author>Michael Riley</author>
</authors>
<title>Generic e-removal algorithm for weighted automata.</title>
<date>2001</date>
<journal>Lecture Notes in Computer Science,</journal>
<pages>2088--230</pages>
<contexts>
<context position="9356" citStr="Mohri et al., 2001" startWordPosition="1413" endWordPosition="1416">aries when they seem reliable enough; but like in the machine translation task, our method intrinsically handles word boundaries in the normalization process if needed. 3 Overview of the system 3.1 Tools in use In our system, all lexicons, language models and sets of rules are compiled into finite-state machines (FSMs) and combined with the input text by composition (o). The reader who is not familiar with FSMs and their fundamental theoretical properties, like composition, is urged to consult the state-of-the-art literature (Roche and Schabes, 1997; Mohri and Riley, 1997; Mohri et al., 2000; Mohri et al., 2001). We used our own finite-state tools: a finite-state machine library and its associated compiler (Beaufort, 2008). In conformance with the format of the library, the compiler builds finite-state machines from weighted rewrite rules, weighted regular expressions and n-gram models. 3.2 Aims We formulated four constraints before fixing the system’s architecture. First, special tokens, like URLs, phones or currencies, should be identified as soon as possible, to keep them out of the normalization process. Second, word boundaries should be taken into account, as far as they seem reliable enough. Th</context>
</contexts>
<marker>Mohri, Pereira, Riley, 2001</marker>
<rawString>Mehryar Mohri, Fernando Pereira, and Michael Riley. 2001. Generic e-removal algorithm for weighted automata. Lecture Notes in Computer Science, 2088:230–242.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>BLEU: a method for automatic evaluation of machine translation.</title>
<date>2001</date>
<booktitle>In Proc. ACL</booktitle>
<pages>311--318</pages>
<contexts>
<context position="27392" citStr="Papineni et al., 2001" startWordPosition="4446" endWordPosition="4449">he experiments of Kobus et al. (2008a), who showed on a French corpus comparable to ours that, if using a larger language model is always rewarded, the improvement quickly decreases with every higher level and is already quite small between 2-gram and 3-gram. Table 1 presents the results in terms of efficiency. The system seems efficient, while we cannot compare it with other methods, which did not provide us with this information. Table 2, part 1, presents the performance of our approach (Hybrid) and compares it to a trivial copy-paste (Copy). The system was evaluated in terms of BLEU score (Papineni et al., 2001), Word Error Rate (WER) and Sentence Error Rate (SER). Concerning WER, the table presents the distribution between substitutions (Sub), deletions (Del) and insertions (Ins). The copy-paste results just inform about the real deviation of our corpus from the traditional spelling conventions, and highlight the fact that our system is still at pains to significantly reduce the SER, while results in terms of WER and BLEU score are quite encouraging. Table 2, part 2, provides the results of the state-of-the-art approaches. The only results truly comparable to ours are those of Guimier de Neef et al.</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2001</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2001. BLEU: a method for automatic evaluation of machine translation. In Proc. ACL 2001, pages 311–318.</rawString>
</citation>
<citation valid="true">
<title>Finite-state language processing.</title>
<date>1997</date>
<editor>Emmanuel Roche and Yves Schabes, editors.</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge.</location>
<marker>1997</marker>
<rawString>Emmanuel Roche and Yves Schabes, editors. 1997. Finite-state language processing. MIT Press, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claude E Shannon</author>
</authors>
<title>A mathematical theory of communication.</title>
<date>1948</date>
<journal>The Bell System Technical Journal,</journal>
<pages>27--379</pages>
<contexts>
<context position="5123" citStr="Shannon, 1948" startWordPosition="752" endWordPosition="753">uation. The spell checking metaphor (Guimier de Neef et al., 2007; Choudhury et al., 2007; Cook and Stevenson, 2009) performs the normalization task on a word-per-word basis. On the assumption that most words should be correct for the purpose of communication, its principle is to keep InVocabulary words out of the correction process. Guimier de Neef et al. (2007) proposed a rulebased system that uses only a few linguistic resources dedicated to SMS, like specific lexicons of abbreviations. Choudhury et al. (2007) and Cook and Stevenson (2009) preferred to implement the noisy channel metaphor (Shannon, 1948), which assumes a communication process in which a sender emits the intended message W through an imperfect (noisy) communication channel, such that the sequence O observed by the recipient is a noisy version of the original message. On this basis, the idea is to recover the intended message W hidden behind the sequences of observations O, by maximizing: Wmax = arg max P(W |O) (1) P(O|W) P(W) P(O) where P(O) is ignored because constant, P(O|W) models the channel’s noise, and P(W) models the language of the source. Choudhury et al. (2007) implemented the noisy channel through a Hidden-Markov Mo</context>
</contexts>
<marker>Shannon, 1948</marker>
<rawString>Claude E. Shannon. 1948. A mathematical theory of communication. The Bell System Technical Journal, 27:379–423.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Sproat</author>
<author>A W Black</author>
<author>S Chen</author>
<author>S Kumar</author>
<author>M Ostendorf</author>
<author>C Richards</author>
</authors>
<title>Normalization of non-standard words.</title>
<date>2001</date>
<journal>Computer Speech &amp; Language,</journal>
<volume>15</volume>
<issue>3</issue>
<contexts>
<context position="2231" citStr="Sproat et al. (2001)" startWordPosition="309" endWordPosition="312">r for ‘j’espère’, “I hope”; j’croibi1k, instead of ‘je crois bien que’, “I am pretty sure that”), etc. These deviations are due to three main factors: the small number of characters allowed per text message by the service (140 bytes), the constraints of the small phones’ keypads and, last but not least, the fact that people mostly communicate between friends and relatives in an informal register. Whatever their causes, these deviations considerably hamper any standard natural language processing (NLP) system, which stumbles against so many Out-Of-Vocabulary words. For this reason, as noted by Sproat et al. (2001), an SMS normalization must be performed before a more conventional NLP process can be applied. As defined by Yvon (2008), “SMS normalization consists in rewriting an SMS text using a more conventional spelling, in order to make it more readable for a human or for a machine.” The SMS normalization we present here was developed in the general framework of an SMSto-speech synthesis system1. This paper, however, only focuses on the normalization process. Evaluated in French, our method shares similarities with both spell checking and machine translation. The machine translation-like module of the</context>
</contexts>
<marker>Sproat, Black, Chen, Kumar, Ostendorf, Richards, 2001</marker>
<rawString>Richard Sproat, A.W. Black, S. Chen, S. Kumar, M. Ostendorf, and C. Richards. 2001. Normalization of non-standard words. Computer Speech &amp; Language, 15(3):287–333.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Crispin Thurlow</author>
<author>Alex Brown</author>
</authors>
<title>Generation txt? The sociolinguistics of young people’s textmessaging.</title>
<date>2003</date>
<booktitle>Discourse Analysis Online,</booktitle>
<volume>1</volume>
<issue>1</issue>
<contexts>
<context position="1275" citStr="Thurlow and Brown, 2003" startWordPosition="168" endWordPosition="171">aper presents a method that shares similarities with both spell checking and machine translation approaches. The normalization part of the system is entirely based on models trained from a corpus. Evaluated in French by 10-fold-cross validation, the system achieves a 9.3% Word Error Rate and a 0.83 BLEU score. 1 Introduction Introduced a few years ago, Short Message Service (SMS) offers the possibility of exchanging written messages between mobile phones. SMS has quickly been adopted by users. These messages often greatly deviate from traditional spelling conventions. As shown by specialists (Thurlow and Brown, 2003; Fairon et al., 2006; Bieswanger, 2007), this variability is due to the simultaneous use of numerous coding strategies, like phonetic plays (2m1 read ‘demain’, “tomorrow”), phonetic transcriptions (kom instead of ‘comme’, “like”), consonant skeletons (tjrs for ‘toujours’, “always”), misapplied, missing or incorrect separators (j esper for ‘j’espère’, “I hope”; j’croibi1k, instead of ‘je crois bien que’, “I am pretty sure that”), etc. These deviations are due to three main factors: the small number of characters allowed per text message by the service (140 bytes), the constraints of the small </context>
</contexts>
<marker>Thurlow, Brown, 2003</marker>
<rawString>Crispin Thurlow and Alex Brown. 2003. Generation txt? The sociolinguistics of young people’s textmessaging. Discourse Analysis Online, 1(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Robert C Moore</author>
</authors>
<title>Pronunciation modeling for improved spelling correction.</title>
<date>2002</date>
<booktitle>In Proc. ACL’02,</booktitle>
<pages>144--151</pages>
<contexts>
<context position="5833" citStr="Toutanova and Moore, 2002" startWordPosition="866" endWordPosition="869"> W through an imperfect (noisy) communication channel, such that the sequence O observed by the recipient is a noisy version of the original message. On this basis, the idea is to recover the intended message W hidden behind the sequences of observations O, by maximizing: Wmax = arg max P(W |O) (1) P(O|W) P(W) P(O) where P(O) is ignored because constant, P(O|W) models the channel’s noise, and P(W) models the language of the source. Choudhury et al. (2007) implemented the noisy channel through a Hidden-Markov Model (HMM) able to handle both graphemic variants and phonetic plays as proposed by (Toutanova and Moore, 2002), while Cook and Stevenson (2009) enhanced the model by adapting the channel’s noise P(O|W, wf) according to a list of predefined observed word formations {wf}: stylistic variation, word clipping, phonetic abbreviations, etc. Whatever the system, the main limitation of the spell The machine translation metaphor, which is historically the first proposed (Bangalore et al., 2002; Aw et al., 2006), considers the process of normalizing SMS as a translation task from a source language (the SMS) to a target language (its standard written form). This standpoint is based on the observation that, on the</context>
</contexts>
<marker>Toutanova, Moore, 2002</marker>
<rawString>Kristina Toutanova and Robert C. Moore. 2002. Pronunciation modeling for improved spelling correction. In Proc. ACL’02, pages 144–151.</rawString>
</citation>
<citation valid="true">
<authors>
<author>François Yvon</author>
</authors>
<title>Reorthography of SMS messages.</title>
<date>2008</date>
<tech>Technical Report</tech>
<location>LIMSI/CNRS, Orsay, France.</location>
<contexts>
<context position="2352" citStr="Yvon (2008)" startWordPosition="331" endWordPosition="332"> three main factors: the small number of characters allowed per text message by the service (140 bytes), the constraints of the small phones’ keypads and, last but not least, the fact that people mostly communicate between friends and relatives in an informal register. Whatever their causes, these deviations considerably hamper any standard natural language processing (NLP) system, which stumbles against so many Out-Of-Vocabulary words. For this reason, as noted by Sproat et al. (2001), an SMS normalization must be performed before a more conventional NLP process can be applied. As defined by Yvon (2008), “SMS normalization consists in rewriting an SMS text using a more conventional spelling, in order to make it more readable for a human or for a machine.” The SMS normalization we present here was developed in the general framework of an SMSto-speech synthesis system1. This paper, however, only focuses on the normalization process. Evaluated in French, our method shares similarities with both spell checking and machine translation. The machine translation-like module of the system performs the true normalization task. It is entirely based on models learned from an SMS corpus and its transcrip</context>
</contexts>
<marker>Yvon, 2008</marker>
<rawString>François Yvon. 2008. Reorthography of SMS messages. Technical Report 2008, LIMSI/CNRS, Orsay, France.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>