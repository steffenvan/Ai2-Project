<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.016128">
<title confidence="0.707115">
RH: A Retro Hybrid Parser
</title>
<author confidence="0.283299">
Paula S. Newman
</author>
<email confidence="0.809089">
newmanp@acm.org
</email>
<sectionHeader confidence="0.97302" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999943333333333">
Contemporary parser research is, to a
large extent, focused on statistical parsers
and deep-unification-based parsers. This
paper describes an alternative, hybrid ar-
chitecture in which an ATN-like parser,
augmented by many preference tests,
builds on the results of a fast chunker.
The combination is as efficient as most
stochastic parsers, and accuracy is close
and continues to improve. These results
raise questions about the practicality of
deep unification for symbolic parsing.
</bodyText>
<sectionHeader confidence="0.9988" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999940413793103">
The original goals of the RH parser were to obtain
accurate parses where (a) application speed was
needed, and (b) large amounts of annotated mate-
rial for a subject idiom were not available. Addi-
tional goals that evolved were (c) that parses for
particular documents could be brought to an almost
arbitrary level of correctness for research purposes,
by grammar correction, and (d) that information
collected during parsing could be modified for an
application with a modest amount of effort. Goal
(a) ruled out the use of unification-based symbolic
parsers, because deep unification is a relatively
slow operation, no matter what amount of compu-
tational sophistication is employed. Until very re-
cently, goal (b) ruled out stochastic parsers, but
new results (McClosky et al. 2006) suggest this
may no longer be the case. However, the &amp;quot;addi-
tional&amp;quot; goals still favor symbolic parsing.
To meet these goals, the RH parser combines a
very efficient shallow parser with an overlay parser
that is &amp;quot;retro&amp;quot;, in that the grammar is related to
Augmented Transition Networks (Woods, 1970),
operating on the shallow-parser output. A major
&amp;quot;augmentation&amp;quot; is a preference-scoring component.
Section 2 below reviews the shallow parser
used, and Section 3 describes the overlay parser.
Some current results are presented in section 4.
Section 5 examines some closely-related work, and
Section 6 discusses some implications.
</bodyText>
<sectionHeader confidence="0.847932" genericHeader="method">
2 The XIP Parser for English
</sectionHeader>
<bodyText confidence="0.947875774193549">
XIP is a robust parser developed by Xerox
Research Center Europe. It is actually a full parser
that produces a tree of chunks, plus identification
of (sometimes alternative) typed dependencies
among the chunk heads (Ait-Mokhtar et al. 2002,
Gala 2004). But because the XIP dependency
analyzer for English was incomplete when RH
work began, and because classic parse trees are
more convenient for discourse-related applications,
we focused on the chunk output.
XIP is astonishingly fast, contributing very little
to RH parse time. It consists of the XIP engine,
plus language-specific grammars, each consisting
of: (a) a finite state lexicon producing alternative
tags and morphological analyses for each token,
together with subcategorization, control and
(some) semantic class features, (b) a part of speech
tagger, and (c) conveniently expressed, layered
rule sets that perform the following functions:
- Lexicon extension, which adds words and
adds or overrides feature information,
- Lexical disambiguation (including use of the
tagger to provide default assignments)
- Multi-word identification for named entities,
dates, short constructions, etc.
- Chunking, obtaining basic chunks such as
basic adjective, adverbial, noun and
prepositional phrases.
- Dependency Analysis (not used in RH)
All rule sets have been extended within RH
development except for the dependency rule sets..
</bodyText>
<sectionHeader confidence="0.986312" genericHeader="method">
3 Overlay Parser
</sectionHeader>
<bodyText confidence="0.998601666666667">
The overlay parser builds on chunker output to
produce a single tree (figure 1) providing syntactic
categories and functions, heads, and head features.
The output tree requires further processing to ob-
tain long distance dependency information, and
make some unambiguous coordination adjustments
</bodyText>
<page confidence="0.975209">
121
</page>
<note confidence="0.6419705">
Proceedings of NAACL HLT 2007, Companion Volume, pages 121–124,
Rochester, NY, April 2007. c�2007 Association for Computational Linguistics
</note>
<figureCaption confidence="0.9993">
Figure 1. Output Parse Tree. * indicates head. Mouseover shows head features
</figureCaption>
<bodyText confidence="0.999940277777778">
Some of this has already been done in a post-parse
phase. The feasibility of such post-parse deepening
(for a statistical parser) is demonstrated by Cahill
et al (2004).
The major parser components are a control, the
ATN-like grammar networks, and collections of
tests. The control is invoked recursively to build
non-chunk constituents by following grammar
network paths and creating output networks.
Figure 2 shows the arcs of an excerpt from a
grammar network used to build a noun phrase. The
Test labels on the arcs resemble specialized cate-
gories. The MetaOps (limited in the illustration to
Prolog-like cuts) expedite processing by permitting
or barring exploration of further ordered arcs
originating at the same state.
An output network, illustrated in figure 3,
mirrors the full paths traversed in a grammar net-
</bodyText>
<table confidence="0.9916871">
From To Test Syn Fin Meta
fun al? Op
S1 S1 PREADV PRE No cut
S1 S2 PRON HEAD Yes cut
S1 S3 PROPER HEAD Yes cut
S1 S4 BASENP HEAD Yes cut
S7
//After pronoun
S2 - REFL REFL Yes cut
S2 - PEOPLE APPS Yes cut
</table>
<figureCaption confidence="0.896908">
Figure 2. Some arcs of grammar network for GNP
</figureCaption>
<bodyText confidence="0.3734676">
From To Cat Synfun Ref
OSa OSb NP HEAD NPChunk
(The park)
OSb OSc PP NMOD Final state of
PP net for
(in Paris)
States Score Final?
Osa 0 No
Osb 0 Yes
OSc 1 Yes
</bodyText>
<figureCaption confidence="0.991935">
Figure 3. Output network for &amp;quot;The park in Paris&amp;quot;
</figureCaption>
<bodyText confidence="0.99995065">
work by one invocation of the control. The arcs
refer either to chunks or to final states of other out-
put networks. Output networks do not contain cy-
cles or converging arcs, so states represent unique
paths. They carry head and other path information,
and a preference score. The final parser output is a
single tree, derived from a highest scoring path of a
topmost output network. Ties are broken by low
attach considerations.
Each invocation of the control is given a
grammar network entry state and a desired
constituent category. After initializing a new
output network, the arcs from the given entry state
are followed. Processing an arc may begin with an
optional pretest. If that succeeds, or there is no
pretest, a constructive test follows. The tests are
indexed by grammar network test labels, and are
expressed as blocks of procedural code, for initial
flexibility in determining the necessary checks.
Pretests include fast feasibility checks, and con-
texted checks of consistency of the potential new
constituent with the current output network path.
Constructive tests can make additional feasibility
checks. If these checks succeed, either a chunk is
returned, or the control is reentered to try to build a
subordinate output network. Results are cached, to
avoid repeated testing.
After a chunk or subordinate network ON&apos; is
returned from a constructive test, one new arc Ai is
added to the current output network ON to
represent each full path through ON&apos;. All added
arcs have the same origin state in ON, but unique
successor states and associated preference scores.
The preference score is the sum of the score at the
common origin state, plus the score of the repre-
sented path in ON&apos;, plus a contexted score for the
alternative within ON. The latter is one of &lt;-1, 0,
+1&gt;, and expresses the consistency of Ai with the
current path with respect to dependency, coordina-
tion and apposition. Structural and punctuation
</bodyText>
<page confidence="0.99021">
122
</page>
<bodyText confidence="0.999616666666667">
aspects are also considered. Preference tests are
indexed by syntactic category or syntactic func-
tion, and are organized for speed. Most tests are
independent of Ai length, and can be applied once
and the results assumed for all Ai.
Before a completed output network is returned,
paths ending at those lower scoring final states
which cannot ultimately be optimal are pruned.
Such pruning is critical to efficiency.
</bodyText>
<sectionHeader confidence="0.999691" genericHeader="method">
4 Indicative Current Results
</sectionHeader>
<bodyText confidence="0.999305866666667">
To provide a snapshot of current RH parser
performance, we compare its current speed and
accuracy directly to those of a widely used
statistical parser, Collins model 3 (Collins, 1999),
and indirectly to two other parsers. Wall Street
Journal section 23 of the Penn Treebank (Marcus
et al. 1994) was used in all experiments.
&amp;quot;Training&amp;quot; of the RH parser on the Wall Street
Journal area (beyond general RH development)
occupied about 8 weeks, and involved testing and
(non-exhaustively) correcting the parser using two
WSJ texts: (a) section 00, and (b) 700 sentences of
section 23 used as a dependency bank by King et
al. (2003). The latter were used early in RH devel-
opment, and so were included in the training set.
</bodyText>
<subsectionHeader confidence="0.994248">
4.1 Comparative Speed
</subsectionHeader>
<bodyText confidence="0.999788818181818">
Table 1 compares RH parser speed with Collins
model 3, using the same CPU, showing the elapsed
times for the entire 2416-line section 23.
The results are then extrapolated to two other
parsers, based on published comparisons with
Collins. The extrapolation to XLE, a mature
unification-based parser that uses a disambiguating
statistical post-processor, is drawn from Kaplan et
al. (2004). Results are given for both the full
grammar and a reduced version that omits less
likely rules. The second comparison is with the
fast stochastic parser by Sagae and Lavie (2005).
Summarizing these results, RH is much faster
than Collins model 3 and the reduced version of
XLE, but a bit slower than Sagae-Lavie.
The table also compares coverage, as percent-
ages of non-parsed sentences. For RH this was
10% for the test set discussed below, which did not
contain any training sentences, and was 10.4% for
the full section 23. This is reasonable for a sym-
bolic parser with limited training on an idiom, and
better than the 21% reported for XLE English.
</bodyText>
<table confidence="0.9997785">
Time No full parse
Sagae/ Lavie ~ 4 min 1.1%
RH parser 5 min 10%
Collins m3 16 min .6%
XLE full ~80 minutes ~21%
XLE reduced ~24 minutes unknown
</table>
<tableCaption confidence="0.992704">
Table 1: Speeds and Extrapolated speeds
</tableCaption>
<table confidence="0.999810857142857">
Fully F-score Avg
accurate cross
brackets
Sagae/Lavie unknwn 86% unknwn
Collins Lbl 33.6% 88.2% 1.05
CollinsNoLbl 35.4% 89.4 % 1.05
RH NoLbl 46% 86 % .59
</table>
<tableCaption confidence="0.999087">
Table 2. Accuracy Comparison
</tableCaption>
<subsectionHeader confidence="0.98973">
4.2 Comparative Acccuracy
</subsectionHeader>
<bodyText confidence="0.98960509375">
Table 2 primarily compares the accuracy of the
Collins model 3 and RH parsers. The entries show
the proportion of fully accurate parses, the f-score
average of bracket precision and recall, and
average crossing brackets, as obtained by EVALB
(Sekine and Collins, 1997). The RH f-score is
currently somewhat lower, but the proportion of
fully correct parses is significantly higher.
This data may be biased toward RH, because, of
necessity, the test set used is smaller, and a
different bracketing method is used. For Collins
model 3, the entries show both labeled and
unlabeled results for all of WSJ section 23. The
Collins results were generated from the bracketed
output and Penn Treebank gold standard files
provided in a recent Collins download.
But because RH does not generate treebank style
tags, the RH entries reflect a test only on a random
sample of 100 sentences from the 1716 sentences
of section 23 not used as &amp;quot;training&amp;quot; data, using a
different, available, gold standard creation and
bracketing method. In that method (Newman,
2005), parser results are produced in a &amp;quot;TextTree&amp;quot;
form, initially developed for fast visual review of
parser output, and then edited to obtain gold
standard trees. Both sets of trees are then bracketed
by a script to obtain, e.g.,
{An automatic transformation
{of parse trees}
{to text trees}}
{can expedite
{parser output reviews}}
</bodyText>
<page confidence="0.997679">
123
</page>
<bodyText confidence="0.9997105">
For non-parsed sentences in the parser outputs,
brackets are applied to the chunks. EVALB is then
used to compare the two sets of bracketed results.
Accuracy for XLE is not given, because the
results reported by Kaplan et al. (2004) compare
labeled functional dependencies drawn from LFG
f-structures with equivalents derived automatically
from Collins outputs. (All f-scores are &lt;= 80%).
</bodyText>
<sectionHeader confidence="0.999963" genericHeader="related work">
5 Related Work
</sectionHeader>
<bodyText confidence="0.999977944444444">
Several efforts combine a chunker with a
dependency analyzer operating on the chunks,
including XIP itself. The XIP dependency analyzer
is very fast, but we do not have current coverage or
accuracy data for XIP English.
Other related hybrids do not build on chunks,
but, rather, adjust full parsers to require or prefer
results consistent with chunk boundaries. Daum et
al. (2003) use chunks to constrain a WCDG
grammar for German, reducing parse times by
about 2/3 (but the same results are obtained using a
tagger alone). They estimate that an ideal chunker
would reduce times by about 75%. No absolute
numbers are given. Also, Frank et al. (2003) use a
German topological field identifier to constrain an
HPSG parser. They show speedups of about 2.2
relative to a tagged baseline, on a corpus whose
average sentence length is about 9 words.
</bodyText>
<sectionHeader confidence="0.999795" genericHeader="conclusions">
6 Discussion
</sectionHeader>
<bodyText confidence="0.999995263157895">
We have shown that the RH hybrid can compete
with stochastic parsers in efficiency and, with only
limited &amp;quot;training&amp;quot; on an idiom, can approach them
in accuracy. Also, the test organization prevents
speed from degrading as the parser is improved.
The method is significant in itself, but also leads
to questions about the advantages of deep-
unification-based parsers for practical NLP. These
parsers are relatively slow, and their large numbers
of results require disambiguation, e.g., by corpus-
trained back-ends. They do provide more informa-
tion than RH, but there is much evidence that the
additional information can be obtained by rapid
analysis of a single best parse. Also, it has never
been shown that their elegant notations actually
facilitate grammar development and maintenance.
Finally, while unification grammars are reversible
for use in generation, good generation methods
remain an open research problem.
</bodyText>
<sectionHeader confidence="0.989838" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999757255319149">
Salah Aït-Mokhtar, Jean-Pierre Chanod, and
Claude Roux. 2002. Robustness beyond shallowness:
incremental deep parsing, Natural Language Engi-
neering 8:121-144, Cambridge University Press.
Aoife Cahill, Michael Burke, Ruth O’Donovan, Josef
van Genabith, and Andy Way. 2004. Long-Distance
Dependency Resolution in Automatically Acquired
Wide-Coverage PCFG-Based LFG Approximations,
In Proc ACL&apos;04. Barcelona
Michael Collins. 1999. Head-Driven Statistical Models
for Natural Language Parsing. Ph.D. thesis, Univer-
sity of Pennsylvania.
Michael A. Daum, Kilian A. Foth, and Wolfgang
Menzel. 2003. Constraint-based integration of deep
and shallow parsing techniques. In Proc EACL&apos;03,
Budapest
Anette Frank, Markus Becker, Berthold Crysmann,
Bernd Kiefer and Ulrich Schaefer. 2003. Integrated
Shallow and Deep Parsing: TopP Meets HPSG. In
Proc ACL&apos;2003, Sapporo
Nuria Gala. 2004. Using a robust parser grammar to
automatically generate UNL graphs. In Proc Work-
shop on Robust Methods for Natural Language Data
at COLING&apos;04, Geneva
Ronald M. Kaplan, Stephan Riezler, Tracy H. King,
John T. Maxwell, Alex Vasserman. 2004. Speed and
accuracy in shallow and deep stochastic parsing. In
Proc HLT/NAACL&apos;04, Boston, MA.
Tracy H. King, Richard Crouch, Stefan Riezler, Mary
Dalrymple, and Ronald M. Kaplan. 2003. The PARC
700 dependency bank. In Proc Workshop on Linguis-
tically Interpreted Corpora, (LINC’03), Budapest
David McClosky, Eugene Charniak, and Mark Johnson.
2006. Reranking and Self-Training for Parser Adap-
tation. In Proc ACL&apos;06. Sydney
Paula Newman. 2005. TextTree Construction for Parser
and Grammar Development. In Proc. Workshop on
Software at ACL&apos;05 Ann Arbor, MI. Available at
http://www.cs.columbia.edu/nlp/acl05soft/
Satoshi Sekine and Michael Collins. 1997. EvalB.
Available at http://nlp.cs.nyu.edu/evalb
Kenji Sagae and Alon Lavie. 2005. A classifier-based
parser with linear run-time complexity. In Proc. 9th
Int&apos;l Workshop on Parsing Technologies. Vancouver
William Woods. 1970. Transition network grammars for
natural language analysis. Communications of the
ACM 13(10), 591-606
</reference>
<page confidence="0.998301">
124
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.982200">
<title confidence="0.99951">RH: A Retro Hybrid Parser</title>
<author confidence="0.998486">S Paula</author>
<email confidence="0.989078">newmanp@acm.org</email>
<abstract confidence="0.999601">Contemporary parser research is, to a large extent, focused on statistical parsers and deep-unification-based parsers. This paper describes an alternative, hybrid architecture in which an ATN-like parser, augmented by many preference tests, builds on the results of a fast chunker. The combination is as efficient as most stochastic parsers, and accuracy is close and continues to improve. These results raise questions about the practicality of deep unification for symbolic parsing.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Salah Aït-Mokhtar</author>
<author>Jean-Pierre Chanod</author>
<author>Claude Roux</author>
</authors>
<title>Robustness beyond shallowness: incremental deep parsing, Natural Language Engineering 8:121-144,</title>
<date>2002</date>
<publisher>University Press.</publisher>
<location>Cambridge</location>
<marker>Aït-Mokhtar, Chanod, Roux, 2002</marker>
<rawString>Salah Aït-Mokhtar, Jean-Pierre Chanod, and Claude Roux. 2002. Robustness beyond shallowness: incremental deep parsing, Natural Language Engineering 8:121-144, Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aoife Cahill</author>
<author>Michael Burke</author>
<author>Ruth O’Donovan</author>
<author>Josef van Genabith</author>
<author>Andy Way</author>
</authors>
<title>Long-Distance Dependency Resolution in Automatically Acquired Wide-Coverage PCFG-Based LFG Approximations,</title>
<date>2004</date>
<booktitle>In Proc ACL&apos;04.</booktitle>
<location>Barcelona</location>
<marker>Cahill, Burke, O’Donovan, van Genabith, Way, 2004</marker>
<rawString>Aoife Cahill, Michael Burke, Ruth O’Donovan, Josef van Genabith, and Andy Way. 2004. Long-Distance Dependency Resolution in Automatically Acquired Wide-Coverage PCFG-Based LFG Approximations, In Proc ACL&apos;04. Barcelona</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Head-Driven Statistical Models for Natural Language Parsing.</title>
<date>1999</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Pennsylvania.</institution>
<contexts>
<context position="7772" citStr="Collins, 1999" startWordPosition="1245" endWordPosition="1246">o considered. Preference tests are indexed by syntactic category or syntactic function, and are organized for speed. Most tests are independent of Ai length, and can be applied once and the results assumed for all Ai. Before a completed output network is returned, paths ending at those lower scoring final states which cannot ultimately be optimal are pruned. Such pruning is critical to efficiency. 4 Indicative Current Results To provide a snapshot of current RH parser performance, we compare its current speed and accuracy directly to those of a widely used statistical parser, Collins model 3 (Collins, 1999), and indirectly to two other parsers. Wall Street Journal section 23 of the Penn Treebank (Marcus et al. 1994) was used in all experiments. &amp;quot;Training&amp;quot; of the RH parser on the Wall Street Journal area (beyond general RH development) occupied about 8 weeks, and involved testing and (non-exhaustively) correcting the parser using two WSJ texts: (a) section 00, and (b) 700 sentences of section 23 used as a dependency bank by King et al. (2003). The latter were used early in RH development, and so were included in the training set. 4.1 Comparative Speed Table 1 compares RH parser speed with Collins</context>
</contexts>
<marker>Collins, 1999</marker>
<rawString>Michael Collins. 1999. Head-Driven Statistical Models for Natural Language Parsing. Ph.D. thesis, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael A Daum</author>
<author>Kilian A Foth</author>
<author>Wolfgang Menzel</author>
</authors>
<title>Constraint-based integration of deep and shallow parsing techniques.</title>
<date>2003</date>
<booktitle>In Proc EACL&apos;03,</booktitle>
<location>Budapest</location>
<contexts>
<context position="11928" citStr="Daum et al. (2003)" startWordPosition="1931" endWordPosition="1934">is not given, because the results reported by Kaplan et al. (2004) compare labeled functional dependencies drawn from LFG f-structures with equivalents derived automatically from Collins outputs. (All f-scores are &lt;= 80%). 5 Related Work Several efforts combine a chunker with a dependency analyzer operating on the chunks, including XIP itself. The XIP dependency analyzer is very fast, but we do not have current coverage or accuracy data for XIP English. Other related hybrids do not build on chunks, but, rather, adjust full parsers to require or prefer results consistent with chunk boundaries. Daum et al. (2003) use chunks to constrain a WCDG grammar for German, reducing parse times by about 2/3 (but the same results are obtained using a tagger alone). They estimate that an ideal chunker would reduce times by about 75%. No absolute numbers are given. Also, Frank et al. (2003) use a German topological field identifier to constrain an HPSG parser. They show speedups of about 2.2 relative to a tagged baseline, on a corpus whose average sentence length is about 9 words. 6 Discussion We have shown that the RH hybrid can compete with stochastic parsers in efficiency and, with only limited &amp;quot;training&amp;quot; on an </context>
</contexts>
<marker>Daum, Foth, Menzel, 2003</marker>
<rawString>Michael A. Daum, Kilian A. Foth, and Wolfgang Menzel. 2003. Constraint-based integration of deep and shallow parsing techniques. In Proc EACL&apos;03, Budapest</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anette Frank</author>
<author>Markus Becker</author>
<author>Berthold Crysmann</author>
<author>Bernd Kiefer</author>
<author>Ulrich Schaefer</author>
</authors>
<title>Integrated Shallow and Deep Parsing: TopP Meets HPSG.</title>
<date>2003</date>
<booktitle>In Proc ACL&apos;2003,</booktitle>
<location>Sapporo</location>
<contexts>
<context position="12197" citStr="Frank et al. (2003)" startWordPosition="1978" endWordPosition="1981">ker with a dependency analyzer operating on the chunks, including XIP itself. The XIP dependency analyzer is very fast, but we do not have current coverage or accuracy data for XIP English. Other related hybrids do not build on chunks, but, rather, adjust full parsers to require or prefer results consistent with chunk boundaries. Daum et al. (2003) use chunks to constrain a WCDG grammar for German, reducing parse times by about 2/3 (but the same results are obtained using a tagger alone). They estimate that an ideal chunker would reduce times by about 75%. No absolute numbers are given. Also, Frank et al. (2003) use a German topological field identifier to constrain an HPSG parser. They show speedups of about 2.2 relative to a tagged baseline, on a corpus whose average sentence length is about 9 words. 6 Discussion We have shown that the RH hybrid can compete with stochastic parsers in efficiency and, with only limited &amp;quot;training&amp;quot; on an idiom, can approach them in accuracy. Also, the test organization prevents speed from degrading as the parser is improved. The method is significant in itself, but also leads to questions about the advantages of deepunification-based parsers for practical NLP. These pa</context>
</contexts>
<marker>Frank, Becker, Crysmann, Kiefer, Schaefer, 2003</marker>
<rawString>Anette Frank, Markus Becker, Berthold Crysmann, Bernd Kiefer and Ulrich Schaefer. 2003. Integrated Shallow and Deep Parsing: TopP Meets HPSG. In Proc ACL&apos;2003, Sapporo</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nuria Gala</author>
</authors>
<title>Using a robust parser grammar to automatically generate UNL graphs.</title>
<date>2004</date>
<booktitle>In Proc Workshop on Robust Methods for Natural Language Data at COLING&apos;04,</booktitle>
<location>Geneva</location>
<contexts>
<context position="2255" citStr="Gala 2004" startWordPosition="348" endWordPosition="349"> operating on the shallow-parser output. A major &amp;quot;augmentation&amp;quot; is a preference-scoring component. Section 2 below reviews the shallow parser used, and Section 3 describes the overlay parser. Some current results are presented in section 4. Section 5 examines some closely-related work, and Section 6 discusses some implications. 2 The XIP Parser for English XIP is a robust parser developed by Xerox Research Center Europe. It is actually a full parser that produces a tree of chunks, plus identification of (sometimes alternative) typed dependencies among the chunk heads (Ait-Mokhtar et al. 2002, Gala 2004). But because the XIP dependency analyzer for English was incomplete when RH work began, and because classic parse trees are more convenient for discourse-related applications, we focused on the chunk output. XIP is astonishingly fast, contributing very little to RH parse time. It consists of the XIP engine, plus language-specific grammars, each consisting of: (a) a finite state lexicon producing alternative tags and morphological analyses for each token, together with subcategorization, control and (some) semantic class features, (b) a part of speech tagger, and (c) conveniently expressed, la</context>
</contexts>
<marker>Gala, 2004</marker>
<rawString>Nuria Gala. 2004. Using a robust parser grammar to automatically generate UNL graphs. In Proc Workshop on Robust Methods for Natural Language Data at COLING&apos;04, Geneva</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronald M Kaplan</author>
<author>Stephan Riezler</author>
<author>Tracy H King</author>
<author>John T Maxwell</author>
<author>Alex Vasserman</author>
</authors>
<title>Speed and accuracy in shallow and deep stochastic parsing.</title>
<date>2004</date>
<booktitle>In Proc HLT/NAACL&apos;04,</booktitle>
<location>Boston, MA.</location>
<contexts>
<context position="8715" citStr="Kaplan et al. (2004)" startWordPosition="1398" endWordPosition="1401">using two WSJ texts: (a) section 00, and (b) 700 sentences of section 23 used as a dependency bank by King et al. (2003). The latter were used early in RH development, and so were included in the training set. 4.1 Comparative Speed Table 1 compares RH parser speed with Collins model 3, using the same CPU, showing the elapsed times for the entire 2416-line section 23. The results are then extrapolated to two other parsers, based on published comparisons with Collins. The extrapolation to XLE, a mature unification-based parser that uses a disambiguating statistical post-processor, is drawn from Kaplan et al. (2004). Results are given for both the full grammar and a reduced version that omits less likely rules. The second comparison is with the fast stochastic parser by Sagae and Lavie (2005). Summarizing these results, RH is much faster than Collins model 3 and the reduced version of XLE, but a bit slower than Sagae-Lavie. The table also compares coverage, as percentages of non-parsed sentences. For RH this was 10% for the test set discussed below, which did not contain any training sentences, and was 10.4% for the full section 23. This is reasonable for a symbolic parser with limited training on an idi</context>
<context position="11376" citStr="Kaplan et al. (2004)" startWordPosition="1846" endWordPosition="1849">on and bracketing method. In that method (Newman, 2005), parser results are produced in a &amp;quot;TextTree&amp;quot; form, initially developed for fast visual review of parser output, and then edited to obtain gold standard trees. Both sets of trees are then bracketed by a script to obtain, e.g., {An automatic transformation {of parse trees} {to text trees}} {can expedite {parser output reviews}} 123 For non-parsed sentences in the parser outputs, brackets are applied to the chunks. EVALB is then used to compare the two sets of bracketed results. Accuracy for XLE is not given, because the results reported by Kaplan et al. (2004) compare labeled functional dependencies drawn from LFG f-structures with equivalents derived automatically from Collins outputs. (All f-scores are &lt;= 80%). 5 Related Work Several efforts combine a chunker with a dependency analyzer operating on the chunks, including XIP itself. The XIP dependency analyzer is very fast, but we do not have current coverage or accuracy data for XIP English. Other related hybrids do not build on chunks, but, rather, adjust full parsers to require or prefer results consistent with chunk boundaries. Daum et al. (2003) use chunks to constrain a WCDG grammar for Germ</context>
</contexts>
<marker>Kaplan, Riezler, King, Maxwell, Vasserman, 2004</marker>
<rawString>Ronald M. Kaplan, Stephan Riezler, Tracy H. King, John T. Maxwell, Alex Vasserman. 2004. Speed and accuracy in shallow and deep stochastic parsing. In Proc HLT/NAACL&apos;04, Boston, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tracy H King</author>
<author>Richard Crouch</author>
<author>Stefan Riezler</author>
<author>Mary Dalrymple</author>
<author>Ronald M Kaplan</author>
</authors>
<date>2003</date>
<booktitle>The PARC 700 dependency bank. In Proc Workshop on Linguistically Interpreted Corpora, (LINC’03),</booktitle>
<location>Budapest</location>
<contexts>
<context position="8215" citStr="King et al. (2003)" startWordPosition="1318" endWordPosition="1321">e a snapshot of current RH parser performance, we compare its current speed and accuracy directly to those of a widely used statistical parser, Collins model 3 (Collins, 1999), and indirectly to two other parsers. Wall Street Journal section 23 of the Penn Treebank (Marcus et al. 1994) was used in all experiments. &amp;quot;Training&amp;quot; of the RH parser on the Wall Street Journal area (beyond general RH development) occupied about 8 weeks, and involved testing and (non-exhaustively) correcting the parser using two WSJ texts: (a) section 00, and (b) 700 sentences of section 23 used as a dependency bank by King et al. (2003). The latter were used early in RH development, and so were included in the training set. 4.1 Comparative Speed Table 1 compares RH parser speed with Collins model 3, using the same CPU, showing the elapsed times for the entire 2416-line section 23. The results are then extrapolated to two other parsers, based on published comparisons with Collins. The extrapolation to XLE, a mature unification-based parser that uses a disambiguating statistical post-processor, is drawn from Kaplan et al. (2004). Results are given for both the full grammar and a reduced version that omits less likely rules. Th</context>
</contexts>
<marker>King, Crouch, Riezler, Dalrymple, Kaplan, 2003</marker>
<rawString>Tracy H. King, Richard Crouch, Stefan Riezler, Mary Dalrymple, and Ronald M. Kaplan. 2003. The PARC 700 dependency bank. In Proc Workshop on Linguistically Interpreted Corpora, (LINC’03), Budapest</rawString>
</citation>
<citation valid="true">
<authors>
<author>David McClosky</author>
<author>Eugene Charniak</author>
<author>Mark Johnson</author>
</authors>
<title>Reranking and Self-Training for Parser Adaptation.</title>
<date>2006</date>
<booktitle>In Proc ACL&apos;06.</booktitle>
<location>Sydney</location>
<contexts>
<context position="1348" citStr="McClosky et al. 2006" startWordPosition="204" endWordPosition="207">ject idiom were not available. Additional goals that evolved were (c) that parses for particular documents could be brought to an almost arbitrary level of correctness for research purposes, by grammar correction, and (d) that information collected during parsing could be modified for an application with a modest amount of effort. Goal (a) ruled out the use of unification-based symbolic parsers, because deep unification is a relatively slow operation, no matter what amount of computational sophistication is employed. Until very recently, goal (b) ruled out stochastic parsers, but new results (McClosky et al. 2006) suggest this may no longer be the case. However, the &amp;quot;additional&amp;quot; goals still favor symbolic parsing. To meet these goals, the RH parser combines a very efficient shallow parser with an overlay parser that is &amp;quot;retro&amp;quot;, in that the grammar is related to Augmented Transition Networks (Woods, 1970), operating on the shallow-parser output. A major &amp;quot;augmentation&amp;quot; is a preference-scoring component. Section 2 below reviews the shallow parser used, and Section 3 describes the overlay parser. Some current results are presented in section 4. Section 5 examines some closely-related work, and Section 6 di</context>
</contexts>
<marker>McClosky, Charniak, Johnson, 2006</marker>
<rawString>David McClosky, Eugene Charniak, and Mark Johnson. 2006. Reranking and Self-Training for Parser Adaptation. In Proc ACL&apos;06. Sydney</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paula Newman</author>
</authors>
<title>TextTree Construction for Parser and Grammar Development.</title>
<date>2005</date>
<booktitle>In Proc. Workshop on Software at ACL&apos;05</booktitle>
<location>Ann Arbor, MI.</location>
<note>Available at http://www.cs.columbia.edu/nlp/acl05soft/</note>
<contexts>
<context position="10811" citStr="Newman, 2005" startWordPosition="1755" endWordPosition="1756">ity, the test set used is smaller, and a different bracketing method is used. For Collins model 3, the entries show both labeled and unlabeled results for all of WSJ section 23. The Collins results were generated from the bracketed output and Penn Treebank gold standard files provided in a recent Collins download. But because RH does not generate treebank style tags, the RH entries reflect a test only on a random sample of 100 sentences from the 1716 sentences of section 23 not used as &amp;quot;training&amp;quot; data, using a different, available, gold standard creation and bracketing method. In that method (Newman, 2005), parser results are produced in a &amp;quot;TextTree&amp;quot; form, initially developed for fast visual review of parser output, and then edited to obtain gold standard trees. Both sets of trees are then bracketed by a script to obtain, e.g., {An automatic transformation {of parse trees} {to text trees}} {can expedite {parser output reviews}} 123 For non-parsed sentences in the parser outputs, brackets are applied to the chunks. EVALB is then used to compare the two sets of bracketed results. Accuracy for XLE is not given, because the results reported by Kaplan et al. (2004) compare labeled functional depende</context>
</contexts>
<marker>Newman, 2005</marker>
<rawString>Paula Newman. 2005. TextTree Construction for Parser and Grammar Development. In Proc. Workshop on Software at ACL&apos;05 Ann Arbor, MI. Available at http://www.cs.columbia.edu/nlp/acl05soft/</rawString>
</citation>
<citation valid="true">
<authors>
<author>Satoshi Sekine</author>
<author>Michael Collins</author>
</authors>
<date>1997</date>
<note>EvalB. Available at http://nlp.cs.nyu.edu/evalb</note>
<contexts>
<context position="10031" citStr="Sekine and Collins, 1997" startWordPosition="1624" endWordPosition="1627">in 1.1% RH parser 5 min 10% Collins m3 16 min .6% XLE full ~80 minutes ~21% XLE reduced ~24 minutes unknown Table 1: Speeds and Extrapolated speeds Fully F-score Avg accurate cross brackets Sagae/Lavie unknwn 86% unknwn Collins Lbl 33.6% 88.2% 1.05 CollinsNoLbl 35.4% 89.4 % 1.05 RH NoLbl 46% 86 % .59 Table 2. Accuracy Comparison 4.2 Comparative Acccuracy Table 2 primarily compares the accuracy of the Collins model 3 and RH parsers. The entries show the proportion of fully accurate parses, the f-score average of bracket precision and recall, and average crossing brackets, as obtained by EVALB (Sekine and Collins, 1997). The RH f-score is currently somewhat lower, but the proportion of fully correct parses is significantly higher. This data may be biased toward RH, because, of necessity, the test set used is smaller, and a different bracketing method is used. For Collins model 3, the entries show both labeled and unlabeled results for all of WSJ section 23. The Collins results were generated from the bracketed output and Penn Treebank gold standard files provided in a recent Collins download. But because RH does not generate treebank style tags, the RH entries reflect a test only on a random sample of 100 se</context>
</contexts>
<marker>Sekine, Collins, 1997</marker>
<rawString>Satoshi Sekine and Michael Collins. 1997. EvalB. Available at http://nlp.cs.nyu.edu/evalb</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenji Sagae</author>
<author>Alon Lavie</author>
</authors>
<title>A classifier-based parser with linear run-time complexity.</title>
<date>2005</date>
<booktitle>In Proc. 9th Int&apos;l Workshop on Parsing Technologies.</booktitle>
<location>Vancouver</location>
<contexts>
<context position="8895" citStr="Sagae and Lavie (2005)" startWordPosition="1429" endWordPosition="1432">e included in the training set. 4.1 Comparative Speed Table 1 compares RH parser speed with Collins model 3, using the same CPU, showing the elapsed times for the entire 2416-line section 23. The results are then extrapolated to two other parsers, based on published comparisons with Collins. The extrapolation to XLE, a mature unification-based parser that uses a disambiguating statistical post-processor, is drawn from Kaplan et al. (2004). Results are given for both the full grammar and a reduced version that omits less likely rules. The second comparison is with the fast stochastic parser by Sagae and Lavie (2005). Summarizing these results, RH is much faster than Collins model 3 and the reduced version of XLE, but a bit slower than Sagae-Lavie. The table also compares coverage, as percentages of non-parsed sentences. For RH this was 10% for the test set discussed below, which did not contain any training sentences, and was 10.4% for the full section 23. This is reasonable for a symbolic parser with limited training on an idiom, and better than the 21% reported for XLE English. Time No full parse Sagae/ Lavie ~ 4 min 1.1% RH parser 5 min 10% Collins m3 16 min .6% XLE full ~80 minutes ~21% XLE reduced ~</context>
</contexts>
<marker>Sagae, Lavie, 2005</marker>
<rawString>Kenji Sagae and Alon Lavie. 2005. A classifier-based parser with linear run-time complexity. In Proc. 9th Int&apos;l Workshop on Parsing Technologies. Vancouver</rawString>
</citation>
<citation valid="true">
<authors>
<author>William Woods</author>
</authors>
<title>Transition network grammars for natural language analysis.</title>
<date>1970</date>
<journal>Communications of the ACM</journal>
<volume>13</volume>
<issue>10</issue>
<pages>591--606</pages>
<contexts>
<context position="1644" citStr="Woods, 1970" startWordPosition="255" endWordPosition="256"> a modest amount of effort. Goal (a) ruled out the use of unification-based symbolic parsers, because deep unification is a relatively slow operation, no matter what amount of computational sophistication is employed. Until very recently, goal (b) ruled out stochastic parsers, but new results (McClosky et al. 2006) suggest this may no longer be the case. However, the &amp;quot;additional&amp;quot; goals still favor symbolic parsing. To meet these goals, the RH parser combines a very efficient shallow parser with an overlay parser that is &amp;quot;retro&amp;quot;, in that the grammar is related to Augmented Transition Networks (Woods, 1970), operating on the shallow-parser output. A major &amp;quot;augmentation&amp;quot; is a preference-scoring component. Section 2 below reviews the shallow parser used, and Section 3 describes the overlay parser. Some current results are presented in section 4. Section 5 examines some closely-related work, and Section 6 discusses some implications. 2 The XIP Parser for English XIP is a robust parser developed by Xerox Research Center Europe. It is actually a full parser that produces a tree of chunks, plus identification of (sometimes alternative) typed dependencies among the chunk heads (Ait-Mokhtar et al. 2002,</context>
</contexts>
<marker>Woods, 1970</marker>
<rawString>William Woods. 1970. Transition network grammars for natural language analysis. Communications of the ACM 13(10), 591-606</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>