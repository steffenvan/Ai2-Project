<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001148">
<title confidence="0.9668715">
A Comparative Study of Hypothesis Alignment and its Improvement
for Machine Translation System Combination
</title>
<author confidence="0.808816">
Boxing Chen*, Min Zhang, Haizhou Li and Aiti Aw
</author>
<affiliation confidence="0.78373">
Institute for Infocomm Research
</affiliation>
<address confidence="0.481717">
1 Fusionopolis Way, 138632 Singapore
</address>
<email confidence="0.981936">
{bxchen, mzhang, hli, aaiti}@i2r.a-star.edu.sg
</email>
<sectionHeader confidence="0.994417" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9989475">
Recently confusion network decoding shows
the best performance in combining outputs
from multiple machine translation (MT) sys-
tems. However, overcoming different word
orders presented in multiple MT systems dur-
ing hypothesis alignment still remains the
biggest challenge to confusion network-based
MT system combination. In this paper, we
compare four commonly used word align-
ment methods, namely GIZA++, TER, CLA
and IHMM, for hypothesis alignment. Then
we propose a method to build the confusion
network from intersection word alignment,
which utilizes both direct and inverse word
alignment between the backbone and hypo-
thesis to improve the reliability of hypothesis
alignment. Experimental results demonstrate
that the intersection word alignment yields
consistent performance improvement for all
four word alignment methods on both Chi-
nese-to-English spoken and written language
tasks.
</bodyText>
<sectionHeader confidence="0.99878" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999210466666667">
Machine translation (MT) system combination
technique leverages on multiple MT systems to
achieve better performance by combining their
outputs. Confusion network based system com-
bination for machine translation has shown
promising advantage compared with other tech-
niques based system combination, such as sen-
tence level hypothesis selection by voting and
source sentence re-decoding using the phrases or
translation models that are learned from the
source sentences and target hypotheses pairs
(Rosti et al., 2007a; Huang and Papineni, 2007).
In general, the confusion network based sys-
tem combination method for MT consists of four
steps: 1) Backbone selection: to select a back-
bone (also called “skeleton”) from all hypotheses.
The backbone defines the word orders of the fi-
nal translation. 2) Hypothesis alignment: to build
word-alignment between backbone and each hy-
pothesis. 3) Confusion network construction: to
build a confusion network based on hypothesis
alignments. 4) Confusion network decoding: to
decode the best translation from a confusion
network. Among the four steps, the hypothesis
alignment presents the biggest challenge to the
method due to the varying word orders between
outputs from different MT systems (Rosti et al,
2007). Many techniques have been studied to
address this issue. Bangalore et al. (2001) used
the edit distance alignment algorithm which is
extended to multiple strings to build confusion
network, it only allows monotonic alignment.
Jayaraman and Lavie (2005) proposed a heuris-
tic-based matching algorithm which allows non-
monotonic alignments to align the words be-
tween the hypotheses. More recently, Matusov et
al. (2006, 2008) used GIZA++ to produce word
alignment for hypotheses pairs. Sim et al. (2007),
Rosti et al. (2007a), and Rosti et al. (2007b) used
minimum Translation Error Rate (TER) (Snover
et al., 2006) alignment to build the confusion
network. Rosti et al. (2008) extended TER algo-
rithm which allows a confusion network as the
reference to compute word alignment. Karakos et
al. (2008) used ITG-based method for hypothesis
alignment. Chen et al. (2008) used Competitive
Linking Algorithm (CLA) (Melamed, 2000) to
align the words to construct confusion network.
Ayan et al. (2008) proposed to improve align-
ment of hypotheses using synonyms as found in
WordNet (Fellbaum, 1998) and a two-pass
alignment strategy based on TER word align-
ment approach. He et al. (2008) proposed an
IHMM-based word alignment method which the
parameters are estimated indirectly from a varie-
ty of sources.
Although many methods have been attempted,
no systematic comparison among them has been
reported. A through and fair comparison among
them would be of great meaning to the MT sys-
</bodyText>
<page confidence="0.9696">
941
</page>
<note confidence="0.999612">
Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 941–948,
Suntec, Singapore, 2-7 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.999959097560976">
tem combination research. In this paper, we im-
plement a confusion network-based decoder.
Based on this decoder, we compare four com-
monly used word alignment methods (GIZA++,
TER, CLA and IHMM) for hypothesis alignment
using the same experimental data and the same
multiple MT system outputs with similar features
in terms of translation performance. We conduct
the comparison study and other experiments in
this paper on both spoken and newswire do-
mains: Chinese-to-English spoken and written
language translation tasks. Our comparison
shows that although the performance differences
between the four methods are not significant,
IHMM consistently show slightly better perfor-
mance than other methods. This is mainly due to
the fact the IHMM is able to explore more know-
ledge sources and Viterbi decoding used in
IHMM allows more thorough search for the best
alignment while other methods has to use less
optimal greedy search.
In addition, for better performance, instead of
only using one direction word alignment (n-to-1
from hypothesis to backbone) as in previous
work, we propose to use more reliable word
alignments which are derived from the intersec-
tion of two-direction hypothesis alignment to
construct confusion network. Experimental re-
sults show that the intersection word alignment-
based method consistently improves the perfor-
mance for all four methods on both spoken and
written language tasks.
This paper is organized as follows. Section 2
presents a standard framework of confusion net-
work based machine translation system combina-
tion. Section 3 introduces four word alignment
methods, and the algorithm of computing inter-
section word alignment for all four word align-
ment methods. Section 4 describes the experi-
ments setting and results on two translation tasks.
Section 5 concludes the paper.
</bodyText>
<sectionHeader confidence="0.9802545" genericHeader="method">
2 Confusion network based system
combination
</sectionHeader>
<bodyText confidence="0.997337388888889">
In order to compare different hypothesis align-
ment methods, we implement a confusion net-
work decoding system as follows:
Backbone selection: in the previous work,
Matusov et al. (2006, 2008) let every hypothesis
play the role of the backbone (also called “skele-
ton” or “alignment reference”) once. We follow
the work of (Sim et al., 2007; Rosti et al., 2007a;
Rosti et al., 2007b; He et al., 2008) and choose
the hypothesis that best agrees with other hypo-
theses on average as the backbone by applying
Minimum Bayes Risk (MBR) decoding (Kumar
and Byrne, 2004). TER score (Snover et al,
2006) is used as the loss function in MBR decod-
ing. Given a hypothesis set H, the backbone can
be computed using the following equation, where
TER(•,•) returns the TER score of two hypothes-
es.
</bodyText>
<equation confidence="0.997300166666667">
Eb arg min
= ∑ TER E E
( ˆ , )
ˆ
E H E H
E E
</equation>
<bodyText confidence="0.987728743589744">
Hypothesis alignment: all hypotheses are
word-aligned to the corresponding backbone in a
many-to-one manner. We apply four word
alignment methods: GIZA++-based, TER-based,
CLA-based, and IHMM-based word alignment
algorithm. For each method, we will give details
in the next section.
Confusion network construction: confusion
network is built from one-to-one word alignment;
therefore, we need to normalize the word align-
ment before constructing the confusion network.
The first normalization operation is removing
duplicated links, since GIZA++ and IHMM-
based word alignments could be n-to-1 mappings
between the hypothesis and backbone. Similar to
the work of (He et al., 2008), we keep the link
which has the highest similarity measure
S(e′j, ei) based on surface matching score, such
as the length of maximum common subsequence
(MCS) of the considered word pair.
2xlen(MCS(ej, ei ))
where MCS(ej′ , ei) is the maximum common
subsequence of word je′ and ei ; len(.) is a
function to compute the length of letter sequence.
The other hypothesis words are set to align to the
null word. For example, in Figure 1, 1e′ and 3e′
are aligned to the same backbone word e2 , we
remove the link between e2 and 3e′ if
S(e3′, e2) &lt; S(e1′, e2), as shown in Figure 1 (b).
The second normalization operation is reorder-
ing the hypothesis words to match the word order
of the backbone. The aligned words are reor-
dered according to their alignment indices. To
reorder the null-aligned words, we need to first
insert the null words into the proper position in
the backbone and then reorder the null-aligned
hypothesis words to match the nulls on the back-
bone side. Reordering null-aligned words varies
based to the word alignment method in the pre-
</bodyText>
<equation confidence="0.994566">
S e e
( , )
′ =
j i len e len e
( ) ( )
′ +
j i
</equation>
<page confidence="0.989486">
942
</page>
<bodyText confidence="0.9999848125">
vious work. We reorder the null-aligned word
following the approach of Chen et al. (2008)
with some extension. The null-aligned words are
reordered with its adjacent word: moving with its
left word (as Figure 1 (c)) or right word (as Fig-
ure 1 (d)). However, to reduce the possibility of
breaking a syntactic phrase, we extend to choose
one of the two above operations depending on
which one has the higher likelihood with the cur-
rent null-aligned word. It is implemented by
comparing two association scores based on co-
occurrence frequencies. They are association
score of the null-aligned word and its left word,
or the null-aligned word and its right word. We
use point-wise mutual information (MI) as Equa-
tion 3 to estimate the likelihood.
</bodyText>
<equation confidence="0.990548777777778">
p e e
( )
′ ′
i i 1
MI e e
′ ′ = +
( , ) log
i i + 1
p(ei )p(ei+1)
</equation>
<bodyText confidence="0.999329285714286">
where p(ei′ei′ +1) is the occurrence probability of
bigram ei′ei′ +1 observed in the hypothesis list;
p(e′i ) and p(ei′+1) are probabilities of hypothe-
sis word ie′ and ei′+1 respectively.
In example of Figure 1, we choose (c)
if MI (e2′ , e3′) &gt; MI (e3′ , e′4) , otherwise, word is
reordered as (d).
</bodyText>
<figure confidence="0.516235">
c d
</figure>
<figureCaption confidence="0.999709">
Figure 1: Example of alignment normalization.
</figureCaption>
<bodyText confidence="0.995898285714286">
Confusion network decoding: the output
translations for a given source sentence are ex-
tracted from the confusion network through a
beam-search algorithm with a log-linear combi-
nation of a set of feature functions. The feature
functions which are employed in the search
process are:
</bodyText>
<listItem confidence="0.989021625">
• Language model(s),
• Direct and inverse IBM model-1,
• Position-based word posterior probabili-
ties (arc scores of the confusion network),
• Word penalty,
• N-gram frequencies (Chen et al., 2005),
• N-gram posterior probabilities (Zens and
Ney, 2006).
</listItem>
<bodyText confidence="0.9998996">
The n-grams used in the last two feature func-
tions are collected from the original hypotheses
list from each single system. The weights of fea-
ture functions are optimized to maximize the
scoring measure (Och, 2003).
</bodyText>
<sectionHeader confidence="0.981542" genericHeader="method">
3 Word alignment algorithms
</sectionHeader>
<bodyText confidence="0.9998555">
We compare four word alignment methods
which are widely used in confusion network
based system combination or bilingual parallel
corpora word alignment.
</bodyText>
<subsectionHeader confidence="0.601471">
3.1 Hypothesis-to-backbone word align-
ment
</subsectionHeader>
<bodyText confidence="0.999410942857143">
GIZA++: Matusov et al. (2006, 2008) proposed
using GIZA++ (Och and Ney, 2003) to align
words between the backbone and hypothesis.
This method uses enhanced HMM model boot-
strapped from IBM Model-1 to estimate the
alignment model. All hypotheses of the whole
test set are collected to create sentence pairs for
GIZA++ training. GIZA++ produces hypothesis-
backbone many-to-1 word alignments.
TER-based: TER-based word alignment
method (Sim et al., 2007; Rosti et al., 2007a;
Rosti et al., 2007b) is an extension of multiple
string matching algorithm based on Levenshtein
edit distance (Bangalore et al., 2001). The TER
(translation error rate) score (Snover et al., 2006)
measures the ratio of minimum number of string
edits between a hypothesis and reference where
the edits include insertions, deletions, substitu-
tions and phrase shifts. The hypothesis is modi-
fied to match the reference, where a greedy
search is used to select the set of shifts because
an optimal sequence of edits (with shifts) is very
expensive to find. The best alignment is the one
that gives the minimum number of translation
edits. TER-based method produces 1-to-1 word
alignments.
CLA-based: Chen et al. (2008) used competi-
tive linking algorithm (CLA) (Melamed, 2000)
to build confusion network for hypothesis rege-
neration. Firstly, an association score is com-
puted for every possible word pair from the
backbone and hypothesis to be aligned. Then a
greedy algorithm is applied to select the best
word alignment. We compute the association
score from a linear combination of two clues:
</bodyText>
<figure confidence="0.999281451612903">
1e
e3
2e
e4
e2
e1
e3
′
′
′
′
1e
2e
e4
e3
′
1e 2e e3 e4
′ e1 b e3
e3 4e′ e2 e′
1e′ 2
e1 e2 e3
′
′
′
e1 e2 e3
a
′
′
′
′
(3)
</figure>
<page confidence="0.99627">
943
</page>
<bodyText confidence="0.999772529411765">
surface similarity computed as Equation (2) and
position difference based distortion score by fol-
lowing (He et al., 2008). CLA works under a 1-
to-1 assumption, so it produces 1-to-1 word
alignments.
IHMM-based: He et al. (2008) propose an
indirect hidden Markov model (IHMM) for hy-
pothesis alignment. Different from traditional
HMM, this model estimates the parameters indi-
rectly from various sources, such as word seman-
tic similarity, surface similarity and distortion
penalty, etc. For fair comparison reason, we also
use the surface similarity computed as Equation
(2) and position difference based distortion score
which are used for CLA-based word alignment.
IHMM-based method produces many-to-1 word
alignments.
</bodyText>
<sectionHeader confidence="0.9407585" genericHeader="method">
3.2 Intersection word alignment and its ex-
pansion
</sectionHeader>
<bodyText confidence="0.996024416666667">
In previous work, Matusov et al. (2006, 2008)
used both direction word alignments to compute
so-called state occupation probabilities and then
compute the final word alignment. The other
work usually used only one direction word
alignment (many/1-to-1 from hypothesis to
backbone). In this paper, we use more reliable
word alignments which are derived from the in-
tersection of both direct (hypothesis-to-backbone)
and inverse (backbone-to-hypothesis) word
alignments with heuristic-based expansion which
is widely used in bilingual word alignment. The
algorithm includes two steps:
1) Generate bi-directional word alignments. It
is straightforward for GIZA++ and IHMM to
generate bi-directional word alignments. This is
simply achieved by switching the parameters of
source and target sentences. Due to the nature of
greedy search in TER, the bi-directional TER-
based word alignments by switching the parame-
ters of source and target sentences are not neces-
sary exactly the same. For example, in Figure 2,
the word “shot” can be aligned to either “shoot”
or “the” as the edit cost of word pair (shot, shoot)
and (shot, the) are the same when compute the
minimum-edit-distance for TER score.
the killer
For CLA word alignment, if we use the same
association score, direct and inverse CLA word
alignments should be exactly the same. There-
fore, we use different functions to compute the
surface similarities, such as using maximum
common subsequence (MCS) to compute inverse
word alignment, and using longest matched pre-
fix (LMP) for computing direct word alignment,
as in Equation (4).
</bodyText>
<equation confidence="0.995480571428571">
S e e
( , )
′ =
j i len e len e
( ) ( )
′ +
j i
</equation>
<bodyText confidence="0.987569846153846">
2) When two word alignments are ready, we
start from the intersection of the two word
alignments, and then continuously add new links
between backbone and hypothesis if and only if
both of the two words of the new link are un-
aligned and this link exists in the union of two
word alignments. If there are more than two links
share a same hypothesis or backbone word and
also satisfy the constraints, we choose the link
that with the highest similarity score. For exam-
ple, in Figure 2, since MCS-based similarity
scores S(shot, shoot) &gt; S(shot, the) , we
choose alignment (a).
</bodyText>
<sectionHeader confidence="0.992422" genericHeader="evaluation">
4 Experiments and results
</sectionHeader>
<subsectionHeader confidence="0.986236">
4.1 Tasks and single systems
</subsectionHeader>
<bodyText confidence="0.9979283">
Experiments are carried out in two domains. One
is in spoken language domain while the other is
on newswire corpus. Both experiments are on
Chinese-to-English translation.
Experiments on spoken language domain were
carried out on the Basic Traveling Expression
Corpus (BTEC) (Takezawa et al., 2002) Chi-
nese- to-English data augmented with HIT-
corpus1. BTEC is a multilingual speech corpus
which contains sentences spoken by tourists.
40K sentence-pairs are used in our experiment.
HIT-corpus is a balanced corpus and has 500K
sentence-pairs in total. We selected 360K sen-
tence-pairs that are more similar to BTEC data
according to its sub-topic. Additionally, the Eng-
lish sentences of Tanaka corpus2 were also used
to train our language model. We ran experiments
on an IWSLT challenge task which uses IWSLT-
20063 DEV clean text set as development set and
IWSLT-2006 TEST clean text as test set.
</bodyText>
<figure confidence="0.996123857142857">
shot
killer
2 x len(LMP(ej′ , ei ))
(4)
shoot
the
killer
shot
killer
I
I
I shoot
I
a b
</figure>
<figureCaption confidence="0.9958265">
Figure 2: Example of two directions TER-based
word alignments.
</figureCaption>
<footnote confidence="0.999247333333333">
1 http://mitlab.hit.edu.cn/
2 http://www.csse.monash.edu.au/~jwb/tanakacorpus.html
3 http:// www.slc.atr.jp/IWSLT2006/
</footnote>
<page confidence="0.998042">
944
</page>
<bodyText confidence="0.917267833333333">
Experiments on newswire domain were car-
ried out on the FBIS4 corpus. We used NIST5
2002 MT evaluation test set as our development
set, and the NIST 2005 test set as our test set.
Table 1 summarizes the statistics of the train-
ing, dev and test data for IWSLT and NIST tasks.
</bodyText>
<table confidence="0.999869933333333">
task data Ch En
Train Sent. 406K
Words 4.4M 4.6M
Dev Sent. 489 489×7
IWSLT Words 5,896 45,449
Test Sent. 500 500×7
Words 6,296 51,227
Add. Words - 1.7M
Train Sent. 238K
Words 7.0M 8.9M
Dev Sent. 878 878×4
NIST 2002 Words 23,248 108,616
Test Sent. 1,082 1,082×4
2005 Words 30,544 141,915
Add. Words - 61.5M
</table>
<tableCaption confidence="0.99984">
Table 1: Statistics of training, dev and test data
</tableCaption>
<bodyText confidence="0.9973621">
for IWSLT and NIST tasks.
In both experiments, we used four systems, as
listed in Table 2, they are phrase-based system
Moses (Koehn et al., 2007), hierarchical phrase-
based system (Chiang, 2007), BTG-based lexica-
lized reordering phrase-based system (Xiong et
al., 2006) and a tree sequence alignment-based
tree-to-tree translation system (Zhang et al.,
2008). Each system for the same task is trained
on the same data set.
</bodyText>
<subsectionHeader confidence="0.96786">
4.2 Experiments setting
</subsectionHeader>
<bodyText confidence="0.994921428571429">
For each system, we used the top 10 scored hy-
potheses to build the confusion network. Similar
to (Rosti et al., 2007a), each word in the hypo-
thesis is assigned with a rank-based score of
1/ (1 + r) , where r is the rank of the hypothesis.
And we assign the same weights to each system.
For selecting the backbone, only the top hypo-
thesis from each system is considered as a candi-
date for the backbone.
Concerning the four alignment methods, we
use the default setting for GIZA++; and use tool-
kit TERCOM (Snover et al., 2006) to compute
the TER-based word alignment, and also use the
default setting. For fair comparison reason, we
</bodyText>
<footnote confidence="0.929007">
4 LDC2003E14
5 http://www.nist.gov/speech/tests/mt/
</footnote>
<bodyText confidence="0.999344875">
decide to do not use any additional resource,
such as target language synonym list, IBM model
lexicon; therefore, only surface similarity is ap-
plied in IHMM-based and CLA-based methods.
We compute the distortion model by following
(He et al., 2008) for IHMM and CLA-based me-
thods. The weights for each model are optimized
on held-out data.
</bodyText>
<table confidence="0.999139777777778">
System Dev Test
Sys1 30.75 27.58
IWSLT Sys2 30.74 28.54
Sys3 29.99 26.91
Sys4 31.32 27.48
Sys1 25.64 23.59
NIST Sys2 24.70 23.57
Sys3 25.89 22.02
Sys4 26.11 21.62
</table>
<tableCaption confidence="0.997591">
Table 2: Results (BLEU% score) of single sys-
tems involved to system combination.
</tableCaption>
<subsectionHeader confidence="0.994857">
4.3 Experiments results
</subsectionHeader>
<bodyText confidence="0.997351">
Our evaluation metric is BLEU (Papineni et al.,
2002), which are to perform case-insensitive
matching of n-grams up to n = 4.
Performance comparison of four methods:
the results based on direct word alignments are
reported in Table 3, row Best is the best single
systems’ scores; row MBR is the scores of back-
bone; GIZA++, TER, CLA, IHMM stand for
scores of systems for four word alignment me-
thods.
</bodyText>
<listItem confidence="0.9956550625">
• MBR decoding slightly improves the per-
formance over the best single system for both
tasks. This suggests that the simple voting strate-
gy to select backbone is workable.
• For both tasks, all methods improve the per-
formance over the backbone. For IWSLT test set,
the improvements are from 2.06 (CLA, 30.88-
28.82) to 2.52 BLEU-score (IHMM, 31.34-
28.82). For NIST test set, the improvements are
from 0.63 (TER, 24.31-23.68) to 1.40 BLEU-
score (IHMM, 25.08-23.68). This verifies that
the confusion network decoding is effective in
combining outputs from multiple MT systems
and the four word-alignment methods are also
workable for hypothesis-to-backbone alignment.
• For IWSLT task where source sentences are
</listItem>
<bodyText confidence="0.9429756">
shorter (12-13 words per sentence in average),
the four word alignment methods achieve similar
performance on both dev and test set. The big-
gest difference is only 0.46 BLEU score (30.88
for CLA, vs. 31.34 for IHMM). For NIST task
</bodyText>
<page confidence="0.997339">
945
</page>
<bodyText confidence="0.999174583333333">
where source sentences are longer (26-28 words
per sentence in average), the difference is more
significant. Here IHMM method achieves the
best performance, followed by GIZA++, CLA
and TER. IHMM is significantly better than TER
by 0.77 BLEU-score (from 24.31 to 25.08,
p&lt;0.05). This is mainly because IHMM exploits
more knowledge source and Viterbi decoding
allows more thorough search for the best align-
ment while other methods use less optimal gree-
dy search. Another reason is that TER uses hard
matching in computing edit distance.
</bodyText>
<table confidence="0.999550307692308">
method Dev Test
Best 31.32 28.54
MBR 31.40 28.82
IWSLT GIZA++ 34.16 31.06
TER 33.92 30.96
CLA 33.85 30.88
IHMM 34.35 31.34
Best 26.11 23.59
MBR 26.36 23.68
NIST GIZA++ 27.58 24.88
TER 27.15 24.31
CLA 27.44 24.51
IHMM 27.76 25.08
</table>
<tableCaption confidence="0.9929215">
Table 3: Results (BLEU% score) of combined
systems based on direct word alignments.
</tableCaption>
<bodyText confidence="0.85218325">
Performance improvement by intersection
word alignment: Table 4 reports the perfor-
mance of the system combinations based on in-
tersection word alignments. It shows that:
• Comparing Tables 3 and 4, we can see that
the intersection word alignment-based expansion
method improves the performance in all the dev
and test sets for both tasks by 0.2-0.57 BLEU-
score and the improvements are consistent under
all conditions. This suggests that the intersection
word alignment-based expansion method is more
effective than the commonly used direct word-
alignment-based hypothesis alignment method in
confusion network-based MT system combina-
tion. This is because intersection word align-
ments are more reliable compared with direct
word alignments, and so for heuristic-based ex-
pansion which is based on the aligned words
with higher scores.
• TER-based method achieves the biggest
performance improvement by 0.4 BLEU-score in
IWSLT and 0.57 in NIST. Our statistics shows
that the TER-based word alignment generates
more inconsistent links between the two-
directional word alignments than other methods.
This may give the intersection with heuristic-
based expansion method more room to improve
performance.
</bodyText>
<listItem confidence="0.992210181818182">
• On the contrast, CLA-based method obtains
relatively small improvement of 0.26 BLEU-
score in IWSLT and 0.21 in NIST. The reason
could be that the similarity functions used in the
two directions are more similar. Therefore, there
are not so many inconsistent links between the
two directions.
• Table 5 shows the number of links modified
by intersection operation and the BLEU-score
improvement. We can see that the more the mod-
ified links, the bigger the improvement.
</listItem>
<table confidence="0.99922">
method Dev Test
MBR 31.40 28.82
GIZA++ 34.38 31.40
IWSLT TER 34.17 31.36
CLA 34.03 31.14
IHMM 34.59 31.74
MBR 26.36 23.68
GIZA++ 27.80 25.11
NIST TER 27.58 24.88
CLA 27.64 24.72
IHMM 27.96 25.37
</table>
<tableCaption confidence="0.993552">
Table 4: Results (BLEU% score) of combined
systems based on intersection word alignments.
</tableCaption>
<table confidence="0.999791142857143">
system IWSLT NIST
Inc. Imp. Inc. Imp.
CLA 1.2K 0.26 9.2K 0.21
GIZA++ 3.2K 0.36 25.5K 0.23
IHMM 3.7K 0.40 21.7K 0.29
TER 4.3K 0.40 40.2K 0.57
#total links 284K 1,390K
</table>
<tableCaption confidence="0.9834305">
Table 5: Number of modified links and absolute
BLEU(%) score improvement on test sets.
</tableCaption>
<bodyText confidence="0.9647379">
Effect of fuzzy matching in TER: the pre-
vious work on TER-based word alignment uses
hard match in counting edits distance. Therefore,
it is not able to handle cognate words match,
such as in Figure 2, original TER script count the
edit cost of (shoot, shot) equals to word pair
(shot, the). Following (Leusch et al., 2006), we
modified the TER script to allow fuzzy matching:
change the substitution cost from 1 for any word
pair to
</bodyText>
<page confidence="0.968726">
946
</page>
<equation confidence="0.818284">
COSTsub(ej′,ei)=1−S(e′j,ei) (5)
which S(ej′ , ei) is the similarity score based on
</equation>
<bodyText confidence="0.977493071428572">
the length of longest matched prefix (LMP)
computed as in Equation (4). As a result, the
fuzzy matching reports
SubCost(shoot,shot) =1−(2x3)/(5+4)=1/3 and
SubCost(shoot,the)=1−(2x0)/(5+3)=1 while in
original TER, both of the two scores are equal to
1. Since cost of word pair (shoot, shot) is smaller
than that of word pair (shot, the), word “shot”
has higher chance to be aligned to “shoot” (Fig-
ure 2 (a)) instead of “the” (Figure 2 (b)). This
fuzzy matching mechanism is very useful to such
kind of monolingual alignment task as in hypo-
thesis-to-backbone word alignment since it can
well model word variances and morphological
changes.
Table 6 summaries the results of TER-based
systems with or without fuzzy matching. We can
see that the fuzzy matching improves the per-
formance for all cases. This verifies the effect of
fuzzy matching for TER in monolingual word
alignment. In addition, the improvement in NIST
test set (0.36 BLEU-score for direct alignment
and 0.21 BLEU-score for intersection one) are
more than that in IWSLT test set (0.15 BLEU-
score for direct alignment and 0.11 BLEU-score
for intersection one). This is because the sen-
tences of IWSLT test set are much shorter than
that of NIST test set.
</bodyText>
<table confidence="0.995784571428571">
TER-based IWSLT NIST
systems
Dev Test Dev Test
Direct align 33.92 30.96 27.15 24.31
+fuzzy match 34.14 31.11 27.53 24.67
Intersect align 34.17 31.36 27.58 24.88
+fuzzy match 34.40 31.47 27.79 25.09
</table>
<tableCaption confidence="0.9770055">
Table 6: Results (BLEU% score) of TER-based
combined systems with or without fuzzy match.
</tableCaption>
<sectionHeader confidence="0.997846" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999343566666667">
Confusion-network-based system combination
shows better performance than other methods in
combining multiple MT systems’ outputs, and
hypothesis alignment is a key step. In this paper,
we first compare four word alignment methods
for hypothesis alignment under the confusion
network framework. We verify that the confu-
sion network framework is very effective in MT
system combination and IHMM achieves the best
performance. Moreover, we propose an intersec-
tion word alignment-based expansion method for
hypothesis alignment, which is more reliable as it
leverages on both direct and inverse word align-
ment. Experimental results on Chinese-to-
English spoken and newswire domains show that
the intersection word alignment-based method
yields consistent improvements across all four
word alignment methods. Finally, we evaluate
the effect of fuzzy matching for TER.
Theoretically, confusion network decoding is
still a word-level voting algorithm although it is
more complicated than other sentence-level vot-
ing algorithms. It changes lexical selection by
considering the posterior probabilities of words
in hypothesis lists. Therefore, like other voting
algorithms, its performance strongly depends on
the quality of the n-best hypotheses of each sin-
gle system. In some extreme cases, it may not be
able to improve BLEU-score (Mauser et al.,
2006; Sim et al., 2007).
</bodyText>
<sectionHeader confidence="0.998343" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9982234375">
N. F. Ayan. J. Zheng and W. Wang. 2008. Improving
Alignments for Better Confusion Networks for
Combining Machine Translation Systems. In Pro-
ceedings of COLING 2008, pp. 33–40. Manchester,
Aug.
S. Bangalore, G. Bordel, and G. Riccardi. 2001.
Computing consensus translation from multiple
machine translation systems. In Proceeding of
IEEE workshop on Automatic Speech Recognition
and Understanding, pp. 351–354. Madonna di
Campiglio, Italy.
B. Chen, R. Cattoni, N. Bertoldi, M. Cettolo and M.
Federico. 2005. The ITC-irst SMT System for
IWSLT-2005. In Proceeding of IWSLT-2005,
pp.98-104, Pittsburgh, USA, October.
B. Chen, M. Zhang, A. Aw and H. Li. 2008. Regene-
rating Hypotheses for Statistical Machine Transla-
tion. In: Proceeding of COLING 2008. pp105-112.
Manchester, UK. Aug.
D. Chiang. 2007. Hierarchical phrase-based transla-
tion. Computational Linguistics, 33(2):201–228.
C. Fellbaum. editor. 1998. WordNet: An Electronic
Lexical Database. MIT Press.
X. He, M. Yang, J. Gao, P. Nguyen, R. Moore, 2008.
Indirect-HMM-based Hypothesis Alignment for
Combining Outputs from Machine Translation
Systems. In Proceeding of EMNLP. Hawaii, US,
Oct.
F. Huang and K. Papinent. 2007. Hierarchical System
Combination for Machine Translation. In Proceed-
ings of the 2007 Joint Conference on Empirical
Methods in Natural Language Processing and
</reference>
<page confidence="0.981588">
947
</page>
<reference confidence="0.998652423076923">
Computational Natural Language Learning
(EMNLP-CoNLL’2007), pp. 277 – 286, Prague,
Czech Republic, June.
S. Jayaraman and A. Lavie. 2005. Multi-engine ma-
chine translation guided by explicit word matching.
In Proceeding of EAMT. pp.143–152.
D. Karakos, J. Eisner, S. Khudanpur, and M. Dreyer.
2008. Machine Translation System Combination
using ITG-based Alignments. In Proceeding of
ACL-HLT 2008, pp. 81–84.
O. Kraif, B. Chen. 2004. Combining clues for lexical
level aligning using the Null hypothesis approach.
In: Proceedings of COLING 2004, Geneva, Au-
gust, pp. 1261-1264.
P. Koehn, H. Hoang, A. Birch, C. Callison-Burch, M.
Federico, N. Bertoldi, B. Cowan, W. Shen, C. Mo-
ran, R. Zens, C. Dyer, O. Bojar, A. Constantin and
E. Herbst. 2007. Moses: Open Source Toolkit for
Statistical Machine Translation. In Proceedings of
ACL-2007. pp. 177-180, Prague, Czech Republic.
S. Kumar and W. Byrne. 2004. Minimum Bayes Risk
Decoding for Statistical Machine Translation. In
Proceedings of HLT-NAACL 2004, May 2004,
Boston, MA, USA.
G. Leusch, N. Ueffing and H. Ney. 2006. CDER: Ef-
ficient MT Evaluation Using Block Movements. In
Proceedings of EACL. pp. 241-248. Trento Italy.
E. Matusov, N. Ueffing, and H. Ney. 2006. Compu-
ting consensus translation from multiple machine
translation systems using enhanced hypotheses
alignment. In Proceeding of EACL, pp. 33-40,
Trento, Italy, April.
E. Matusov, G. Leusch, R. E. Banchs, N. Bertoldi, D.
Dechelotte, M. Federico, M. Kolss, Y. Lee, J. B.
Marino, M. Paulik, S. Roukos, H. Schwenk, and H.
Ney. System Combination for Machine Translation
of Spoken and Written Language. IEEE Transac-
tions on Audio, Speech and Language Processing,
volume 16, number 7, pp. 1222-1237, September.
A. Mauser, R. Zens, E. Matusov, S. Hasan, and H.
Ney. 2006. The RWTH Statistical Machine Trans-
lation System for the IWSLT 2006 Evaluation. In
Proceeding of IWSLT 2006, pp. 103-110, Kyoto,
Japan, November.
I. D. Melamed. 2000. Models of translational equiva-
lence among words. Computational Linguistics,
26(2), pp. 221-249.
F. J. Och. 2003. Minimum error rate training in statis-
tical machine translation. In Proceedings of ACL-
2003. Sapporo, Japan.
F. J. Och and H. Ney. 2003. A systematic comparison
of various statistical alignment models. Computa-
tional Linguistics, 29(1):19-51.
K. Papineni, S. Roukos, T. Ward, and W.-J. Zhu.
2002. BLEU: a method for automatic evaluation of
machine translation. In Proceeding of ACL-2002,
pp. 311-318.
A. I. Rosti, N. F. Ayan, B. Xiang, S. Matsoukas, R.
Schwartz and B. Dorr. 2007a. Combining Outputs
from Multiple Machine Translation Systems. In
Proceeding of NAACL-HLT-2007, pp. 228-235.
Rochester, NY.
A. I. Rosti, S. Matsoukas and R. Schwartz. 2007b.
Improved Word-Level System Combination for
Ma-chine Translation. In Proceeding of ACL-2007,
Prague.
A. I. Rosti, B. Zhang, S. Matsoukas, and R. Schwartz.
2008. Incremental Hypothesis Alignment for
Building Confusion Networks with Application to
Machine Translation System Combination, In Pro-
ceeding of the Third ACL Workshop on Statistical
Machine Translation, pp. 183-186.
K. C. Sim, W. J. Byrne, M. J.F. Gales, H. Sahbi, and
P. C. Woodland. 2007. Consensus network decod-
ing for statistical machine translation system com-
bination. In Proceeding of ICASSP-2007.
M. Snover, B. Dorr, R. Schwartz, L. Micciulla, and J.
Makhoul. 2006. A study of translation edit rate
with targeted human annotation. In Proceeding of
AMTA.
T. Takezawa, E. Sumita, F. Sugaya, H. Yamamoto,
and S. Yamamoto. 2002. Toward a broad-coverage
bilingual corpus for speech translation of travel
conversations in the real world. In Proceeding of
LREC-2002, Las Palmas de Gran Canaria, Spain.
D. Xiong, Q. Liu and S. Lin. 2006. Maximum Entro-
py Based Phrase Reordering Model for Statistical
Machine Translation. In Proceeding of ACL-2006.
pp.521-528.
R. Zens and H. Ney. 2006. N-gram Posterior Prob-
abilities for Statistical Machine Translation. In
Proceeding of HLT-NAACL Workshop on SMT, pp.
72-77, NY.
M. Zhang, H. Jiang, A. Aw, H. Li, C. L. Tan, and S.
Li. 2008. A Tree Sequence Alignment-based Tree-
to-Tree Translation Model. In Proceeding of ACL-
2008. Columbus, US. June.
Y. Zhang, S. Vogel, and A. Waibel 2004. Interpreting
BLEU/NIST scores: How much improvement do
we need to have a better system? In Proceedings of
LREC 2004, pp. 2051-2054.
* The first author has moved to National Research
Council, Canada. His current email address is: Box-
ing.Chen@nrc.ca.
</reference>
<page confidence="0.997313">
948
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.573015">
<title confidence="0.999819">A Comparative Study of Hypothesis Alignment and its Improvement for Machine Translation System Combination</title>
<author confidence="0.999624">Min Zhang</author>
<author confidence="0.999624">Haizhou Li</author>
<author confidence="0.999624">Aiti Aw</author>
<affiliation confidence="0.996119">Institute for Infocomm Research</affiliation>
<address confidence="0.619507">1 Fusionopolis Way, 138632 Singapore</address>
<email confidence="0.932635">bxchen@i2r.a-star.edu.sg</email>
<email confidence="0.932635">mzhang@i2r.a-star.edu.sg</email>
<email confidence="0.932635">hli@i2r.a-star.edu.sg</email>
<email confidence="0.932635">aaiti@i2r.a-star.edu.sg</email>
<abstract confidence="0.997890347826087">Recently confusion network decoding shows the best performance in combining outputs from multiple machine translation (MT) systems. However, overcoming different word orders presented in multiple MT systems during hypothesis alignment still remains the biggest challenge to confusion network-based MT system combination. In this paper, we compare four commonly used word alignment methods, namely GIZA++, TER, CLA and IHMM, for hypothesis alignment. Then we propose a method to build the confusion network from intersection word alignment, which utilizes both direct and inverse word alignment between the backbone and hypothesis to improve the reliability of hypothesis alignment. Experimental results demonstrate that the intersection word alignment yields consistent performance improvement for all four word alignment methods on both Chinese-to-English spoken and written language tasks.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Zheng</author>
<author>W Wang</author>
</authors>
<title>Improving Alignments for Better Confusion Networks for Combining Machine Translation Systems.</title>
<date>2008</date>
<booktitle>In Proceedings of COLING</booktitle>
<pages>33--40</pages>
<location>Manchester,</location>
<marker>Zheng, Wang, 2008</marker>
<rawString>N. F. Ayan. J. Zheng and W. Wang. 2008. Improving Alignments for Better Confusion Networks for Combining Machine Translation Systems. In Proceedings of COLING 2008, pp. 33–40. Manchester, Aug.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Bangalore</author>
<author>G Bordel</author>
<author>G Riccardi</author>
</authors>
<title>Computing consensus translation from multiple machine translation systems.</title>
<date>2001</date>
<booktitle>In Proceeding of IEEE workshop on Automatic Speech Recognition and Understanding,</booktitle>
<pages>351--354</pages>
<institution>Madonna di Campiglio, Italy.</institution>
<contexts>
<context position="2519" citStr="Bangalore et al. (2001)" startWordPosition="361" endWordPosition="364">) from all hypotheses. The backbone defines the word orders of the final translation. 2) Hypothesis alignment: to build word-alignment between backbone and each hypothesis. 3) Confusion network construction: to build a confusion network based on hypothesis alignments. 4) Confusion network decoding: to decode the best translation from a confusion network. Among the four steps, the hypothesis alignment presents the biggest challenge to the method due to the varying word orders between outputs from different MT systems (Rosti et al, 2007). Many techniques have been studied to address this issue. Bangalore et al. (2001) used the edit distance alignment algorithm which is extended to multiple strings to build confusion network, it only allows monotonic alignment. Jayaraman and Lavie (2005) proposed a heuristic-based matching algorithm which allows nonmonotonic alignments to align the words between the hypotheses. More recently, Matusov et al. (2006, 2008) used GIZA++ to produce word alignment for hypotheses pairs. Sim et al. (2007), Rosti et al. (2007a), and Rosti et al. (2007b) used minimum Translation Error Rate (TER) (Snover et al., 2006) alignment to build the confusion network. Rosti et al. (2008) extend</context>
<context position="11266" citStr="Bangalore et al., 2001" startWordPosition="1816" endWordPosition="1819">ne word alignment GIZA++: Matusov et al. (2006, 2008) proposed using GIZA++ (Och and Ney, 2003) to align words between the backbone and hypothesis. This method uses enhanced HMM model bootstrapped from IBM Model-1 to estimate the alignment model. All hypotheses of the whole test set are collected to create sentence pairs for GIZA++ training. GIZA++ produces hypothesisbackbone many-to-1 word alignments. TER-based: TER-based word alignment method (Sim et al., 2007; Rosti et al., 2007a; Rosti et al., 2007b) is an extension of multiple string matching algorithm based on Levenshtein edit distance (Bangalore et al., 2001). The TER (translation error rate) score (Snover et al., 2006) measures the ratio of minimum number of string edits between a hypothesis and reference where the edits include insertions, deletions, substitutions and phrase shifts. The hypothesis is modified to match the reference, where a greedy search is used to select the set of shifts because an optimal sequence of edits (with shifts) is very expensive to find. The best alignment is the one that gives the minimum number of translation edits. TER-based method produces 1-to-1 word alignments. CLA-based: Chen et al. (2008) used competitive lin</context>
</contexts>
<marker>Bangalore, Bordel, Riccardi, 2001</marker>
<rawString>S. Bangalore, G. Bordel, and G. Riccardi. 2001. Computing consensus translation from multiple machine translation systems. In Proceeding of IEEE workshop on Automatic Speech Recognition and Understanding, pp. 351–354. Madonna di Campiglio, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Chen</author>
<author>R Cattoni</author>
<author>N Bertoldi</author>
<author>M Cettolo</author>
<author>M Federico</author>
</authors>
<date>2005</date>
<booktitle>The ITC-irst SMT System for IWSLT-2005. In Proceeding of IWSLT-2005,</booktitle>
<pages>98--104</pages>
<location>Pittsburgh, USA,</location>
<contexts>
<context position="10165" citStr="Chen et al., 2005" startWordPosition="1647" endWordPosition="1650">, we choose (c) if MI (e2′ , e3′) &gt; MI (e3′ , e′4) , otherwise, word is reordered as (d). c d Figure 1: Example of alignment normalization. Confusion network decoding: the output translations for a given source sentence are extracted from the confusion network through a beam-search algorithm with a log-linear combination of a set of feature functions. The feature functions which are employed in the search process are: • Language model(s), • Direct and inverse IBM model-1, • Position-based word posterior probabilities (arc scores of the confusion network), • Word penalty, • N-gram frequencies (Chen et al., 2005), • N-gram posterior probabilities (Zens and Ney, 2006). The n-grams used in the last two feature functions are collected from the original hypotheses list from each single system. The weights of feature functions are optimized to maximize the scoring measure (Och, 2003). 3 Word alignment algorithms We compare four word alignment methods which are widely used in confusion network based system combination or bilingual parallel corpora word alignment. 3.1 Hypothesis-to-backbone word alignment GIZA++: Matusov et al. (2006, 2008) proposed using GIZA++ (Och and Ney, 2003) to align words between the</context>
</contexts>
<marker>Chen, Cattoni, Bertoldi, Cettolo, Federico, 2005</marker>
<rawString>B. Chen, R. Cattoni, N. Bertoldi, M. Cettolo and M. Federico. 2005. The ITC-irst SMT System for IWSLT-2005. In Proceeding of IWSLT-2005, pp.98-104, Pittsburgh, USA, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Chen</author>
<author>M Zhang</author>
<author>A Aw</author>
<author>H Li</author>
</authors>
<title>Regenerating Hypotheses for Statistical Machine Translation. In:</title>
<date>2008</date>
<booktitle>Proceeding of COLING</booktitle>
<pages>105--112</pages>
<location>Manchester, UK.</location>
<contexts>
<context position="3301" citStr="Chen et al. (2008)" startWordPosition="484" endWordPosition="487">e (2005) proposed a heuristic-based matching algorithm which allows nonmonotonic alignments to align the words between the hypotheses. More recently, Matusov et al. (2006, 2008) used GIZA++ to produce word alignment for hypotheses pairs. Sim et al. (2007), Rosti et al. (2007a), and Rosti et al. (2007b) used minimum Translation Error Rate (TER) (Snover et al., 2006) alignment to build the confusion network. Rosti et al. (2008) extended TER algorithm which allows a confusion network as the reference to compute word alignment. Karakos et al. (2008) used ITG-based method for hypothesis alignment. Chen et al. (2008) used Competitive Linking Algorithm (CLA) (Melamed, 2000) to align the words to construct confusion network. Ayan et al. (2008) proposed to improve alignment of hypotheses using synonyms as found in WordNet (Fellbaum, 1998) and a two-pass alignment strategy based on TER word alignment approach. He et al. (2008) proposed an IHMM-based word alignment method which the parameters are estimated indirectly from a variety of sources. Although many methods have been attempted, no systematic comparison among them has been reported. A through and fair comparison among them would be of great meaning to t</context>
<context position="8617" citStr="Chen et al. (2008)" startWordPosition="1372" endWordPosition="1375">1 (b). The second normalization operation is reordering the hypothesis words to match the word order of the backbone. The aligned words are reordered according to their alignment indices. To reorder the null-aligned words, we need to first insert the null words into the proper position in the backbone and then reorder the null-aligned hypothesis words to match the nulls on the backbone side. Reordering null-aligned words varies based to the word alignment method in the preS e e ( , ) ′ = j i len e len e ( ) ( ) ′ + j i 942 vious work. We reorder the null-aligned word following the approach of Chen et al. (2008) with some extension. The null-aligned words are reordered with its adjacent word: moving with its left word (as Figure 1 (c)) or right word (as Figure 1 (d)). However, to reduce the possibility of breaking a syntactic phrase, we extend to choose one of the two above operations depending on which one has the higher likelihood with the current null-aligned word. It is implemented by comparing two association scores based on cooccurrence frequencies. They are association score of the null-aligned word and its left word, or the null-aligned word and its right word. We use point-wise mutual inform</context>
<context position="11845" citStr="Chen et al. (2008)" startWordPosition="1910" endWordPosition="1913"> edit distance (Bangalore et al., 2001). The TER (translation error rate) score (Snover et al., 2006) measures the ratio of minimum number of string edits between a hypothesis and reference where the edits include insertions, deletions, substitutions and phrase shifts. The hypothesis is modified to match the reference, where a greedy search is used to select the set of shifts because an optimal sequence of edits (with shifts) is very expensive to find. The best alignment is the one that gives the minimum number of translation edits. TER-based method produces 1-to-1 word alignments. CLA-based: Chen et al. (2008) used competitive linking algorithm (CLA) (Melamed, 2000) to build confusion network for hypothesis regeneration. Firstly, an association score is computed for every possible word pair from the backbone and hypothesis to be aligned. Then a greedy algorithm is applied to select the best word alignment. We compute the association score from a linear combination of two clues: 1e e3 2e e4 e2 e1 e3 ′ ′ ′ ′ 1e 2e e4 e3 ′ 1e 2e e3 e4 ′ e1 b e3 e3 4e′ e2 e′ 1e′ 2 e1 e2 e3 ′ ′ ′ e1 e2 e3 a ′ ′ ′ ′ (3) 943 surface similarity computed as Equation (2) and position difference based distortion score by foll</context>
</contexts>
<marker>Chen, Zhang, Aw, Li, 2008</marker>
<rawString>B. Chen, M. Zhang, A. Aw and H. Li. 2008. Regenerating Hypotheses for Statistical Machine Translation. In: Proceeding of COLING 2008. pp105-112. Manchester, UK. Aug.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Chiang</author>
</authors>
<title>Hierarchical phrase-based translation.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>2</issue>
<contexts>
<context position="17367" citStr="Chiang, 2007" startWordPosition="2841" endWordPosition="2842"> of the training, dev and test data for IWSLT and NIST tasks. task data Ch En Train Sent. 406K Words 4.4M 4.6M Dev Sent. 489 489×7 IWSLT Words 5,896 45,449 Test Sent. 500 500×7 Words 6,296 51,227 Add. Words - 1.7M Train Sent. 238K Words 7.0M 8.9M Dev Sent. 878 878×4 NIST 2002 Words 23,248 108,616 Test Sent. 1,082 1,082×4 2005 Words 30,544 141,915 Add. Words - 61.5M Table 1: Statistics of training, dev and test data for IWSLT and NIST tasks. In both experiments, we used four systems, as listed in Table 2, they are phrase-based system Moses (Koehn et al., 2007), hierarchical phrasebased system (Chiang, 2007), BTG-based lexicalized reordering phrase-based system (Xiong et al., 2006) and a tree sequence alignment-based tree-to-tree translation system (Zhang et al., 2008). Each system for the same task is trained on the same data set. 4.2 Experiments setting For each system, we used the top 10 scored hypotheses to build the confusion network. Similar to (Rosti et al., 2007a), each word in the hypothesis is assigned with a rank-based score of 1/ (1 + r) , where r is the rank of the hypothesis. And we assign the same weights to each system. For selecting the backbone, only the top hypothesis from each</context>
</contexts>
<marker>Chiang, 2007</marker>
<rawString>D. Chiang. 2007. Hierarchical phrase-based translation. Computational Linguistics, 33(2):201–228.</rawString>
</citation>
<citation valid="true">
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<editor>C. Fellbaum. editor.</editor>
<publisher>MIT Press.</publisher>
<marker>1998</marker>
<rawString>C. Fellbaum. editor. 1998. WordNet: An Electronic Lexical Database. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X He</author>
<author>M Yang</author>
<author>J Gao</author>
<author>P Nguyen</author>
<author>R Moore</author>
</authors>
<title>Indirect-HMM-based Hypothesis Alignment for Combining Outputs from Machine Translation Systems.</title>
<date>2008</date>
<booktitle>In Proceeding of EMNLP.</booktitle>
<location>Hawaii, US,</location>
<contexts>
<context position="3613" citStr="He et al. (2008)" startWordPosition="534" endWordPosition="537">um Translation Error Rate (TER) (Snover et al., 2006) alignment to build the confusion network. Rosti et al. (2008) extended TER algorithm which allows a confusion network as the reference to compute word alignment. Karakos et al. (2008) used ITG-based method for hypothesis alignment. Chen et al. (2008) used Competitive Linking Algorithm (CLA) (Melamed, 2000) to align the words to construct confusion network. Ayan et al. (2008) proposed to improve alignment of hypotheses using synonyms as found in WordNet (Fellbaum, 1998) and a two-pass alignment strategy based on TER word alignment approach. He et al. (2008) proposed an IHMM-based word alignment method which the parameters are estimated indirectly from a variety of sources. Although many methods have been attempted, no systematic comparison among them has been reported. A through and fair comparison among them would be of great meaning to the MT sys941 Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 941–948, Suntec, Singapore, 2-7 August 2009. c�2009 ACL and AFNLP tem combination research. In this paper, we implement a confusion network-based decoder. Based on this decoder, we compare four commonly used wo</context>
<context position="6321" citStr="He et al., 2008" startWordPosition="964" endWordPosition="967">rsection word alignment for all four word alignment methods. Section 4 describes the experiments setting and results on two translation tasks. Section 5 concludes the paper. 2 Confusion network based system combination In order to compare different hypothesis alignment methods, we implement a confusion network decoding system as follows: Backbone selection: in the previous work, Matusov et al. (2006, 2008) let every hypothesis play the role of the backbone (also called “skeleton” or “alignment reference”) once. We follow the work of (Sim et al., 2007; Rosti et al., 2007a; Rosti et al., 2007b; He et al., 2008) and choose the hypothesis that best agrees with other hypotheses on average as the backbone by applying Minimum Bayes Risk (MBR) decoding (Kumar and Byrne, 2004). TER score (Snover et al, 2006) is used as the loss function in MBR decoding. Given a hypothesis set H, the backbone can be computed using the following equation, where TER(•,•) returns the TER score of two hypotheses. Eb arg min = ∑ TER E E ( ˆ , ) ˆ E H E H E E Hypothesis alignment: all hypotheses are word-aligned to the corresponding backbone in a many-to-one manner. We apply four word alignment methods: GIZA++-based, TER-based, C</context>
<context position="12468" citStr="He et al., 2008" startWordPosition="2035" endWordPosition="2038">ompetitive linking algorithm (CLA) (Melamed, 2000) to build confusion network for hypothesis regeneration. Firstly, an association score is computed for every possible word pair from the backbone and hypothesis to be aligned. Then a greedy algorithm is applied to select the best word alignment. We compute the association score from a linear combination of two clues: 1e e3 2e e4 e2 e1 e3 ′ ′ ′ ′ 1e 2e e4 e3 ′ 1e 2e e3 e4 ′ e1 b e3 e3 4e′ e2 e′ 1e′ 2 e1 e2 e3 ′ ′ ′ e1 e2 e3 a ′ ′ ′ ′ (3) 943 surface similarity computed as Equation (2) and position difference based distortion score by following (He et al., 2008). CLA works under a 1- to-1 assumption, so it produces 1-to-1 word alignments. IHMM-based: He et al. (2008) propose an indirect hidden Markov model (IHMM) for hypothesis alignment. Different from traditional HMM, this model estimates the parameters indirectly from various sources, such as word semantic similarity, surface similarity and distortion penalty, etc. For fair comparison reason, we also use the surface similarity computed as Equation (2) and position difference based distortion score which are used for CLA-based word alignment. IHMM-based method produces many-to-1 word alignments. 3.</context>
<context position="18551" citStr="He et al., 2008" startWordPosition="3037" endWordPosition="3040">nly the top hypothesis from each system is considered as a candidate for the backbone. Concerning the four alignment methods, we use the default setting for GIZA++; and use toolkit TERCOM (Snover et al., 2006) to compute the TER-based word alignment, and also use the default setting. For fair comparison reason, we 4 LDC2003E14 5 http://www.nist.gov/speech/tests/mt/ decide to do not use any additional resource, such as target language synonym list, IBM model lexicon; therefore, only surface similarity is applied in IHMM-based and CLA-based methods. We compute the distortion model by following (He et al., 2008) for IHMM and CLA-based methods. The weights for each model are optimized on held-out data. System Dev Test Sys1 30.75 27.58 IWSLT Sys2 30.74 28.54 Sys3 29.99 26.91 Sys4 31.32 27.48 Sys1 25.64 23.59 NIST Sys2 24.70 23.57 Sys3 25.89 22.02 Sys4 26.11 21.62 Table 2: Results (BLEU% score) of single systems involved to system combination. 4.3 Experiments results Our evaluation metric is BLEU (Papineni et al., 2002), which are to perform case-insensitive matching of n-grams up to n = 4. Performance comparison of four methods: the results based on direct word alignments are reported in Table 3, row B</context>
</contexts>
<marker>He, Yang, Gao, Nguyen, Moore, 2008</marker>
<rawString>X. He, M. Yang, J. Gao, P. Nguyen, R. Moore, 2008. Indirect-HMM-based Hypothesis Alignment for Combining Outputs from Machine Translation Systems. In Proceeding of EMNLP. Hawaii, US, Oct.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Huang</author>
<author>K Papinent</author>
</authors>
<title>Hierarchical System Combination for Machine Translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL’2007),</booktitle>
<pages>277--286</pages>
<location>Prague, Czech Republic,</location>
<marker>Huang, Papinent, 2007</marker>
<rawString>F. Huang and K. Papinent. 2007. Hierarchical System Combination for Machine Translation. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL’2007), pp. 277 – 286, Prague, Czech Republic, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Jayaraman</author>
<author>A Lavie</author>
</authors>
<title>Multi-engine machine translation guided by explicit word matching.</title>
<date>2005</date>
<booktitle>In Proceeding of EAMT.</booktitle>
<pages>143--152</pages>
<contexts>
<context position="2691" citStr="Jayaraman and Lavie (2005)" startWordPosition="386" endWordPosition="389">is. 3) Confusion network construction: to build a confusion network based on hypothesis alignments. 4) Confusion network decoding: to decode the best translation from a confusion network. Among the four steps, the hypothesis alignment presents the biggest challenge to the method due to the varying word orders between outputs from different MT systems (Rosti et al, 2007). Many techniques have been studied to address this issue. Bangalore et al. (2001) used the edit distance alignment algorithm which is extended to multiple strings to build confusion network, it only allows monotonic alignment. Jayaraman and Lavie (2005) proposed a heuristic-based matching algorithm which allows nonmonotonic alignments to align the words between the hypotheses. More recently, Matusov et al. (2006, 2008) used GIZA++ to produce word alignment for hypotheses pairs. Sim et al. (2007), Rosti et al. (2007a), and Rosti et al. (2007b) used minimum Translation Error Rate (TER) (Snover et al., 2006) alignment to build the confusion network. Rosti et al. (2008) extended TER algorithm which allows a confusion network as the reference to compute word alignment. Karakos et al. (2008) used ITG-based method for hypothesis alignment. Chen et </context>
</contexts>
<marker>Jayaraman, Lavie, 2005</marker>
<rawString>S. Jayaraman and A. Lavie. 2005. Multi-engine machine translation guided by explicit word matching. In Proceeding of EAMT. pp.143–152.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Karakos</author>
<author>J Eisner</author>
<author>S Khudanpur</author>
<author>M Dreyer</author>
</authors>
<title>Machine Translation System Combination using ITG-based Alignments.</title>
<date>2008</date>
<booktitle>In Proceeding of ACL-HLT</booktitle>
<pages>81--84</pages>
<contexts>
<context position="3234" citStr="Karakos et al. (2008)" startWordPosition="474" endWordPosition="477">fusion network, it only allows monotonic alignment. Jayaraman and Lavie (2005) proposed a heuristic-based matching algorithm which allows nonmonotonic alignments to align the words between the hypotheses. More recently, Matusov et al. (2006, 2008) used GIZA++ to produce word alignment for hypotheses pairs. Sim et al. (2007), Rosti et al. (2007a), and Rosti et al. (2007b) used minimum Translation Error Rate (TER) (Snover et al., 2006) alignment to build the confusion network. Rosti et al. (2008) extended TER algorithm which allows a confusion network as the reference to compute word alignment. Karakos et al. (2008) used ITG-based method for hypothesis alignment. Chen et al. (2008) used Competitive Linking Algorithm (CLA) (Melamed, 2000) to align the words to construct confusion network. Ayan et al. (2008) proposed to improve alignment of hypotheses using synonyms as found in WordNet (Fellbaum, 1998) and a two-pass alignment strategy based on TER word alignment approach. He et al. (2008) proposed an IHMM-based word alignment method which the parameters are estimated indirectly from a variety of sources. Although many methods have been attempted, no systematic comparison among them has been reported. A th</context>
</contexts>
<marker>Karakos, Eisner, Khudanpur, Dreyer, 2008</marker>
<rawString>D. Karakos, J. Eisner, S. Khudanpur, and M. Dreyer. 2008. Machine Translation System Combination using ITG-based Alignments. In Proceeding of ACL-HLT 2008, pp. 81–84.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Kraif</author>
<author>B Chen</author>
</authors>
<title>Combining clues for lexical level aligning using the Null hypothesis approach. In:</title>
<date>2004</date>
<booktitle>Proceedings of COLING 2004,</booktitle>
<pages>1261--1264</pages>
<location>Geneva,</location>
<marker>Kraif, Chen, 2004</marker>
<rawString>O. Kraif, B. Chen. 2004. Combining clues for lexical level aligning using the Null hypothesis approach. In: Proceedings of COLING 2004, Geneva, August, pp. 1261-1264.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>H Hoang</author>
<author>A Birch</author>
<author>C Callison-Burch</author>
<author>M Federico</author>
<author>N Bertoldi</author>
<author>B Cowan</author>
<author>W Shen</author>
<author>C Moran</author>
<author>R Zens</author>
<author>C Dyer</author>
<author>O Bojar</author>
<author>A Constantin</author>
<author>E Herbst</author>
</authors>
<title>Moses: Open Source Toolkit for Statistical Machine Translation.</title>
<date>2007</date>
<booktitle>In Proceedings of ACL-2007.</booktitle>
<pages>177--180</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="17319" citStr="Koehn et al., 2007" startWordPosition="2833" endWordPosition="2836">set as our test set. Table 1 summarizes the statistics of the training, dev and test data for IWSLT and NIST tasks. task data Ch En Train Sent. 406K Words 4.4M 4.6M Dev Sent. 489 489×7 IWSLT Words 5,896 45,449 Test Sent. 500 500×7 Words 6,296 51,227 Add. Words - 1.7M Train Sent. 238K Words 7.0M 8.9M Dev Sent. 878 878×4 NIST 2002 Words 23,248 108,616 Test Sent. 1,082 1,082×4 2005 Words 30,544 141,915 Add. Words - 61.5M Table 1: Statistics of training, dev and test data for IWSLT and NIST tasks. In both experiments, we used four systems, as listed in Table 2, they are phrase-based system Moses (Koehn et al., 2007), hierarchical phrasebased system (Chiang, 2007), BTG-based lexicalized reordering phrase-based system (Xiong et al., 2006) and a tree sequence alignment-based tree-to-tree translation system (Zhang et al., 2008). Each system for the same task is trained on the same data set. 4.2 Experiments setting For each system, we used the top 10 scored hypotheses to build the confusion network. Similar to (Rosti et al., 2007a), each word in the hypothesis is assigned with a rank-based score of 1/ (1 + r) , where r is the rank of the hypothesis. And we assign the same weights to each system. For selecting</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, Dyer, Bojar, Constantin, Herbst, 2007</marker>
<rawString>P. Koehn, H. Hoang, A. Birch, C. Callison-Burch, M. Federico, N. Bertoldi, B. Cowan, W. Shen, C. Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin and E. Herbst. 2007. Moses: Open Source Toolkit for Statistical Machine Translation. In Proceedings of ACL-2007. pp. 177-180, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kumar</author>
<author>W Byrne</author>
</authors>
<title>Minimum Bayes Risk Decoding for Statistical Machine Translation.</title>
<date>2004</date>
<booktitle>In Proceedings of HLT-NAACL</booktitle>
<location>Boston, MA, USA.</location>
<contexts>
<context position="6483" citStr="Kumar and Byrne, 2004" startWordPosition="991" endWordPosition="994">cludes the paper. 2 Confusion network based system combination In order to compare different hypothesis alignment methods, we implement a confusion network decoding system as follows: Backbone selection: in the previous work, Matusov et al. (2006, 2008) let every hypothesis play the role of the backbone (also called “skeleton” or “alignment reference”) once. We follow the work of (Sim et al., 2007; Rosti et al., 2007a; Rosti et al., 2007b; He et al., 2008) and choose the hypothesis that best agrees with other hypotheses on average as the backbone by applying Minimum Bayes Risk (MBR) decoding (Kumar and Byrne, 2004). TER score (Snover et al, 2006) is used as the loss function in MBR decoding. Given a hypothesis set H, the backbone can be computed using the following equation, where TER(•,•) returns the TER score of two hypotheses. Eb arg min = ∑ TER E E ( ˆ , ) ˆ E H E H E E Hypothesis alignment: all hypotheses are word-aligned to the corresponding backbone in a many-to-one manner. We apply four word alignment methods: GIZA++-based, TER-based, CLA-based, and IHMM-based word alignment algorithm. For each method, we will give details in the next section. Confusion network construction: confusion network is</context>
</contexts>
<marker>Kumar, Byrne, 2004</marker>
<rawString>S. Kumar and W. Byrne. 2004. Minimum Bayes Risk Decoding for Statistical Machine Translation. In Proceedings of HLT-NAACL 2004, May 2004, Boston, MA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Leusch</author>
<author>N Ueffing</author>
<author>H Ney</author>
</authors>
<title>CDER: Efficient MT Evaluation Using Block Movements.</title>
<date>2006</date>
<booktitle>In Proceedings of EACL.</booktitle>
<pages>241--248</pages>
<location>Trento</location>
<contexts>
<context position="23625" citStr="Leusch et al., 2006" startWordPosition="3867" endWordPosition="3870">stems based on intersection word alignments. system IWSLT NIST Inc. Imp. Inc. Imp. CLA 1.2K 0.26 9.2K 0.21 GIZA++ 3.2K 0.36 25.5K 0.23 IHMM 3.7K 0.40 21.7K 0.29 TER 4.3K 0.40 40.2K 0.57 #total links 284K 1,390K Table 5: Number of modified links and absolute BLEU(%) score improvement on test sets. Effect of fuzzy matching in TER: the previous work on TER-based word alignment uses hard match in counting edits distance. Therefore, it is not able to handle cognate words match, such as in Figure 2, original TER script count the edit cost of (shoot, shot) equals to word pair (shot, the). Following (Leusch et al., 2006), we modified the TER script to allow fuzzy matching: change the substitution cost from 1 for any word pair to 946 COSTsub(ej′,ei)=1−S(e′j,ei) (5) which S(ej′ , ei) is the similarity score based on the length of longest matched prefix (LMP) computed as in Equation (4). As a result, the fuzzy matching reports SubCost(shoot,shot) =1−(2x3)/(5+4)=1/3 and SubCost(shoot,the)=1−(2x0)/(5+3)=1 while in original TER, both of the two scores are equal to 1. Since cost of word pair (shoot, shot) is smaller than that of word pair (shot, the), word “shot” has higher chance to be aligned to “shoot” (Figure 2 </context>
</contexts>
<marker>Leusch, Ueffing, Ney, 2006</marker>
<rawString>G. Leusch, N. Ueffing and H. Ney. 2006. CDER: Efficient MT Evaluation Using Block Movements. In Proceedings of EACL. pp. 241-248. Trento Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Matusov</author>
<author>N Ueffing</author>
<author>H Ney</author>
</authors>
<title>Computing consensus translation from multiple machine translation systems using enhanced hypotheses alignment.</title>
<date>2006</date>
<booktitle>In Proceeding of EACL,</booktitle>
<pages>33--40</pages>
<location>Trento, Italy,</location>
<contexts>
<context position="2853" citStr="Matusov et al. (2006" startWordPosition="411" endWordPosition="414"> confusion network. Among the four steps, the hypothesis alignment presents the biggest challenge to the method due to the varying word orders between outputs from different MT systems (Rosti et al, 2007). Many techniques have been studied to address this issue. Bangalore et al. (2001) used the edit distance alignment algorithm which is extended to multiple strings to build confusion network, it only allows monotonic alignment. Jayaraman and Lavie (2005) proposed a heuristic-based matching algorithm which allows nonmonotonic alignments to align the words between the hypotheses. More recently, Matusov et al. (2006, 2008) used GIZA++ to produce word alignment for hypotheses pairs. Sim et al. (2007), Rosti et al. (2007a), and Rosti et al. (2007b) used minimum Translation Error Rate (TER) (Snover et al., 2006) alignment to build the confusion network. Rosti et al. (2008) extended TER algorithm which allows a confusion network as the reference to compute word alignment. Karakos et al. (2008) used ITG-based method for hypothesis alignment. Chen et al. (2008) used Competitive Linking Algorithm (CLA) (Melamed, 2000) to align the words to construct confusion network. Ayan et al. (2008) proposed to improve alig</context>
<context position="6107" citStr="Matusov et al. (2006" startWordPosition="925" endWordPosition="928"> is organized as follows. Section 2 presents a standard framework of confusion network based machine translation system combination. Section 3 introduces four word alignment methods, and the algorithm of computing intersection word alignment for all four word alignment methods. Section 4 describes the experiments setting and results on two translation tasks. Section 5 concludes the paper. 2 Confusion network based system combination In order to compare different hypothesis alignment methods, we implement a confusion network decoding system as follows: Backbone selection: in the previous work, Matusov et al. (2006, 2008) let every hypothesis play the role of the backbone (also called “skeleton” or “alignment reference”) once. We follow the work of (Sim et al., 2007; Rosti et al., 2007a; Rosti et al., 2007b; He et al., 2008) and choose the hypothesis that best agrees with other hypotheses on average as the backbone by applying Minimum Bayes Risk (MBR) decoding (Kumar and Byrne, 2004). TER score (Snover et al, 2006) is used as the loss function in MBR decoding. Given a hypothesis set H, the backbone can be computed using the following equation, where TER(•,•) returns the TER score of two hypotheses. Eb a</context>
<context position="10689" citStr="Matusov et al. (2006" startWordPosition="1727" endWordPosition="1730"> (arc scores of the confusion network), • Word penalty, • N-gram frequencies (Chen et al., 2005), • N-gram posterior probabilities (Zens and Ney, 2006). The n-grams used in the last two feature functions are collected from the original hypotheses list from each single system. The weights of feature functions are optimized to maximize the scoring measure (Och, 2003). 3 Word alignment algorithms We compare four word alignment methods which are widely used in confusion network based system combination or bilingual parallel corpora word alignment. 3.1 Hypothesis-to-backbone word alignment GIZA++: Matusov et al. (2006, 2008) proposed using GIZA++ (Och and Ney, 2003) to align words between the backbone and hypothesis. This method uses enhanced HMM model bootstrapped from IBM Model-1 to estimate the alignment model. All hypotheses of the whole test set are collected to create sentence pairs for GIZA++ training. GIZA++ produces hypothesisbackbone many-to-1 word alignments. TER-based: TER-based word alignment method (Sim et al., 2007; Rosti et al., 2007a; Rosti et al., 2007b) is an extension of multiple string matching algorithm based on Levenshtein edit distance (Bangalore et al., 2001). The TER (translation </context>
<context position="13154" citStr="Matusov et al. (2006" startWordPosition="2138" endWordPosition="2141"> alignments. IHMM-based: He et al. (2008) propose an indirect hidden Markov model (IHMM) for hypothesis alignment. Different from traditional HMM, this model estimates the parameters indirectly from various sources, such as word semantic similarity, surface similarity and distortion penalty, etc. For fair comparison reason, we also use the surface similarity computed as Equation (2) and position difference based distortion score which are used for CLA-based word alignment. IHMM-based method produces many-to-1 word alignments. 3.2 Intersection word alignment and its expansion In previous work, Matusov et al. (2006, 2008) used both direction word alignments to compute so-called state occupation probabilities and then compute the final word alignment. The other work usually used only one direction word alignment (many/1-to-1 from hypothesis to backbone). In this paper, we use more reliable word alignments which are derived from the intersection of both direct (hypothesis-to-backbone) and inverse (backbone-to-hypothesis) word alignments with heuristic-based expansion which is widely used in bilingual word alignment. The algorithm includes two steps: 1) Generate bi-directional word alignments. It is straig</context>
</contexts>
<marker>Matusov, Ueffing, Ney, 2006</marker>
<rawString>E. Matusov, N. Ueffing, and H. Ney. 2006. Computing consensus translation from multiple machine translation systems using enhanced hypotheses alignment. In Proceeding of EACL, pp. 33-40, Trento, Italy, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Matusov</author>
<author>G Leusch</author>
<author>R E Banchs</author>
<author>N Bertoldi</author>
<author>D Dechelotte</author>
<author>M Federico</author>
<author>M Kolss</author>
<author>Y Lee</author>
<author>J B Marino</author>
<author>M Paulik</author>
<author>S Roukos</author>
<author>H Schwenk</author>
<author>H Ney</author>
</authors>
<date></date>
<booktitle>System Combination for Machine Translation of Spoken and Written Language. IEEE Transactions on Audio, Speech and Language Processing,</booktitle>
<volume>16</volume>
<pages>1222--1237</pages>
<marker>Matusov, Leusch, Banchs, Bertoldi, Dechelotte, Federico, Kolss, Lee, Marino, Paulik, Roukos, Schwenk, Ney, </marker>
<rawString>E. Matusov, G. Leusch, R. E. Banchs, N. Bertoldi, D. Dechelotte, M. Federico, M. Kolss, Y. Lee, J. B. Marino, M. Paulik, S. Roukos, H. Schwenk, and H. Ney. System Combination for Machine Translation of Spoken and Written Language. IEEE Transactions on Audio, Speech and Language Processing, volume 16, number 7, pp. 1222-1237, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Mauser</author>
<author>R Zens</author>
<author>E Matusov</author>
<author>S Hasan</author>
<author>H Ney</author>
</authors>
<title>Evaluation.</title>
<date>2006</date>
<booktitle>The RWTH Statistical Machine Translation System for the IWSLT</booktitle>
<pages>103--110</pages>
<location>Kyoto, Japan,</location>
<marker>Mauser, Zens, Matusov, Hasan, Ney, 2006</marker>
<rawString>A. Mauser, R. Zens, E. Matusov, S. Hasan, and H. Ney. 2006. The RWTH Statistical Machine Translation System for the IWSLT 2006 Evaluation. In Proceeding of IWSLT 2006, pp. 103-110, Kyoto, Japan, November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I D Melamed</author>
</authors>
<title>Models of translational equivalence among words.</title>
<date>2000</date>
<journal>Computational Linguistics,</journal>
<volume>26</volume>
<issue>2</issue>
<pages>221--249</pages>
<contexts>
<context position="3358" citStr="Melamed, 2000" startWordPosition="493" endWordPosition="494">allows nonmonotonic alignments to align the words between the hypotheses. More recently, Matusov et al. (2006, 2008) used GIZA++ to produce word alignment for hypotheses pairs. Sim et al. (2007), Rosti et al. (2007a), and Rosti et al. (2007b) used minimum Translation Error Rate (TER) (Snover et al., 2006) alignment to build the confusion network. Rosti et al. (2008) extended TER algorithm which allows a confusion network as the reference to compute word alignment. Karakos et al. (2008) used ITG-based method for hypothesis alignment. Chen et al. (2008) used Competitive Linking Algorithm (CLA) (Melamed, 2000) to align the words to construct confusion network. Ayan et al. (2008) proposed to improve alignment of hypotheses using synonyms as found in WordNet (Fellbaum, 1998) and a two-pass alignment strategy based on TER word alignment approach. He et al. (2008) proposed an IHMM-based word alignment method which the parameters are estimated indirectly from a variety of sources. Although many methods have been attempted, no systematic comparison among them has been reported. A through and fair comparison among them would be of great meaning to the MT sys941 Proceedings of the 47th Annual Meeting of th</context>
<context position="11902" citStr="Melamed, 2000" startWordPosition="1920" endWordPosition="1921"> error rate) score (Snover et al., 2006) measures the ratio of minimum number of string edits between a hypothesis and reference where the edits include insertions, deletions, substitutions and phrase shifts. The hypothesis is modified to match the reference, where a greedy search is used to select the set of shifts because an optimal sequence of edits (with shifts) is very expensive to find. The best alignment is the one that gives the minimum number of translation edits. TER-based method produces 1-to-1 word alignments. CLA-based: Chen et al. (2008) used competitive linking algorithm (CLA) (Melamed, 2000) to build confusion network for hypothesis regeneration. Firstly, an association score is computed for every possible word pair from the backbone and hypothesis to be aligned. Then a greedy algorithm is applied to select the best word alignment. We compute the association score from a linear combination of two clues: 1e e3 2e e4 e2 e1 e3 ′ ′ ′ ′ 1e 2e e4 e3 ′ 1e 2e e3 e4 ′ e1 b e3 e3 4e′ e2 e′ 1e′ 2 e1 e2 e3 ′ ′ ′ e1 e2 e3 a ′ ′ ′ ′ (3) 943 surface similarity computed as Equation (2) and position difference based distortion score by following (He et al., 2008). CLA works under a 1- to-1 assump</context>
</contexts>
<marker>Melamed, 2000</marker>
<rawString>I. D. Melamed. 2000. Models of translational equivalence among words. Computational Linguistics, 26(2), pp. 221-249.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
</authors>
<title>Minimum error rate training in statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proceedings of ACL2003.</booktitle>
<location>Sapporo, Japan.</location>
<contexts>
<context position="10436" citStr="Och, 2003" startWordPosition="1693" endWordPosition="1694">rch algorithm with a log-linear combination of a set of feature functions. The feature functions which are employed in the search process are: • Language model(s), • Direct and inverse IBM model-1, • Position-based word posterior probabilities (arc scores of the confusion network), • Word penalty, • N-gram frequencies (Chen et al., 2005), • N-gram posterior probabilities (Zens and Ney, 2006). The n-grams used in the last two feature functions are collected from the original hypotheses list from each single system. The weights of feature functions are optimized to maximize the scoring measure (Och, 2003). 3 Word alignment algorithms We compare four word alignment methods which are widely used in confusion network based system combination or bilingual parallel corpora word alignment. 3.1 Hypothesis-to-backbone word alignment GIZA++: Matusov et al. (2006, 2008) proposed using GIZA++ (Och and Ney, 2003) to align words between the backbone and hypothesis. This method uses enhanced HMM model bootstrapped from IBM Model-1 to estimate the alignment model. All hypotheses of the whole test set are collected to create sentence pairs for GIZA++ training. GIZA++ produces hypothesisbackbone many-to-1 word</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>F. J. Och. 2003. Minimum error rate training in statistical machine translation. In Proceedings of ACL2003. Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<pages>29--1</pages>
<contexts>
<context position="10738" citStr="Och and Ney, 2003" startWordPosition="1735" endWordPosition="1738">lty, • N-gram frequencies (Chen et al., 2005), • N-gram posterior probabilities (Zens and Ney, 2006). The n-grams used in the last two feature functions are collected from the original hypotheses list from each single system. The weights of feature functions are optimized to maximize the scoring measure (Och, 2003). 3 Word alignment algorithms We compare four word alignment methods which are widely used in confusion network based system combination or bilingual parallel corpora word alignment. 3.1 Hypothesis-to-backbone word alignment GIZA++: Matusov et al. (2006, 2008) proposed using GIZA++ (Och and Ney, 2003) to align words between the backbone and hypothesis. This method uses enhanced HMM model bootstrapped from IBM Model-1 to estimate the alignment model. All hypotheses of the whole test set are collected to create sentence pairs for GIZA++ training. GIZA++ produces hypothesisbackbone many-to-1 word alignments. TER-based: TER-based word alignment method (Sim et al., 2007; Rosti et al., 2007a; Rosti et al., 2007b) is an extension of multiple string matching algorithm based on Levenshtein edit distance (Bangalore et al., 2001). The TER (translation error rate) score (Snover et al., 2006) measures </context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>F. J. Och and H. Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19-51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Papineni</author>
<author>S Roukos</author>
<author>T Ward</author>
<author>W-J Zhu</author>
</authors>
<title>BLEU: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceeding of ACL-2002,</booktitle>
<pages>311--318</pages>
<contexts>
<context position="18964" citStr="Papineni et al., 2002" startWordPosition="3107" endWordPosition="3110">ource, such as target language synonym list, IBM model lexicon; therefore, only surface similarity is applied in IHMM-based and CLA-based methods. We compute the distortion model by following (He et al., 2008) for IHMM and CLA-based methods. The weights for each model are optimized on held-out data. System Dev Test Sys1 30.75 27.58 IWSLT Sys2 30.74 28.54 Sys3 29.99 26.91 Sys4 31.32 27.48 Sys1 25.64 23.59 NIST Sys2 24.70 23.57 Sys3 25.89 22.02 Sys4 26.11 21.62 Table 2: Results (BLEU% score) of single systems involved to system combination. 4.3 Experiments results Our evaluation metric is BLEU (Papineni et al., 2002), which are to perform case-insensitive matching of n-grams up to n = 4. Performance comparison of four methods: the results based on direct word alignments are reported in Table 3, row Best is the best single systems’ scores; row MBR is the scores of backbone; GIZA++, TER, CLA, IHMM stand for scores of systems for four word alignment methods. • MBR decoding slightly improves the performance over the best single system for both tasks. This suggests that the simple voting strategy to select backbone is workable. • For both tasks, all methods improve the performance over the backbone. For IWSLT </context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>K. Papineni, S. Roukos, T. Ward, and W.-J. Zhu. 2002. BLEU: a method for automatic evaluation of machine translation. In Proceeding of ACL-2002, pp. 311-318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A I Rosti</author>
<author>N F Ayan</author>
<author>B Xiang</author>
<author>S Matsoukas</author>
<author>R Schwartz</author>
<author>B Dorr</author>
</authors>
<title>Combining Outputs from Multiple Machine Translation Systems.</title>
<date>2007</date>
<booktitle>In Proceeding of NAACL-HLT-2007,</booktitle>
<pages>228--235</pages>
<location>Rochester, NY.</location>
<contexts>
<context position="1702" citStr="Rosti et al., 2007" startWordPosition="235" endWordPosition="238">ur word alignment methods on both Chinese-to-English spoken and written language tasks. 1 Introduction Machine translation (MT) system combination technique leverages on multiple MT systems to achieve better performance by combining their outputs. Confusion network based system combination for machine translation has shown promising advantage compared with other techniques based system combination, such as sentence level hypothesis selection by voting and source sentence re-decoding using the phrases or translation models that are learned from the source sentences and target hypotheses pairs (Rosti et al., 2007a; Huang and Papineni, 2007). In general, the confusion network based system combination method for MT consists of four steps: 1) Backbone selection: to select a backbone (also called “skeleton”) from all hypotheses. The backbone defines the word orders of the final translation. 2) Hypothesis alignment: to build word-alignment between backbone and each hypothesis. 3) Confusion network construction: to build a confusion network based on hypothesis alignments. 4) Confusion network decoding: to decode the best translation from a confusion network. Among the four steps, the hypothesis alignment pr</context>
<context position="2958" citStr="Rosti et al. (2007" startWordPosition="429" endWordPosition="432">thod due to the varying word orders between outputs from different MT systems (Rosti et al, 2007). Many techniques have been studied to address this issue. Bangalore et al. (2001) used the edit distance alignment algorithm which is extended to multiple strings to build confusion network, it only allows monotonic alignment. Jayaraman and Lavie (2005) proposed a heuristic-based matching algorithm which allows nonmonotonic alignments to align the words between the hypotheses. More recently, Matusov et al. (2006, 2008) used GIZA++ to produce word alignment for hypotheses pairs. Sim et al. (2007), Rosti et al. (2007a), and Rosti et al. (2007b) used minimum Translation Error Rate (TER) (Snover et al., 2006) alignment to build the confusion network. Rosti et al. (2008) extended TER algorithm which allows a confusion network as the reference to compute word alignment. Karakos et al. (2008) used ITG-based method for hypothesis alignment. Chen et al. (2008) used Competitive Linking Algorithm (CLA) (Melamed, 2000) to align the words to construct confusion network. Ayan et al. (2008) proposed to improve alignment of hypotheses using synonyms as found in WordNet (Fellbaum, 1998) and a two-pass alignment strategy</context>
<context position="6281" citStr="Rosti et al., 2007" startWordPosition="956" endWordPosition="959">thods, and the algorithm of computing intersection word alignment for all four word alignment methods. Section 4 describes the experiments setting and results on two translation tasks. Section 5 concludes the paper. 2 Confusion network based system combination In order to compare different hypothesis alignment methods, we implement a confusion network decoding system as follows: Backbone selection: in the previous work, Matusov et al. (2006, 2008) let every hypothesis play the role of the backbone (also called “skeleton” or “alignment reference”) once. We follow the work of (Sim et al., 2007; Rosti et al., 2007a; Rosti et al., 2007b; He et al., 2008) and choose the hypothesis that best agrees with other hypotheses on average as the backbone by applying Minimum Bayes Risk (MBR) decoding (Kumar and Byrne, 2004). TER score (Snover et al, 2006) is used as the loss function in MBR decoding. Given a hypothesis set H, the backbone can be computed using the following equation, where TER(•,•) returns the TER score of two hypotheses. Eb arg min = ∑ TER E E ( ˆ , ) ˆ E H E H E E Hypothesis alignment: all hypotheses are word-aligned to the corresponding backbone in a many-to-one manner. We apply four word align</context>
<context position="11129" citStr="Rosti et al., 2007" startWordPosition="1795" endWordPosition="1798">are widely used in confusion network based system combination or bilingual parallel corpora word alignment. 3.1 Hypothesis-to-backbone word alignment GIZA++: Matusov et al. (2006, 2008) proposed using GIZA++ (Och and Ney, 2003) to align words between the backbone and hypothesis. This method uses enhanced HMM model bootstrapped from IBM Model-1 to estimate the alignment model. All hypotheses of the whole test set are collected to create sentence pairs for GIZA++ training. GIZA++ produces hypothesisbackbone many-to-1 word alignments. TER-based: TER-based word alignment method (Sim et al., 2007; Rosti et al., 2007a; Rosti et al., 2007b) is an extension of multiple string matching algorithm based on Levenshtein edit distance (Bangalore et al., 2001). The TER (translation error rate) score (Snover et al., 2006) measures the ratio of minimum number of string edits between a hypothesis and reference where the edits include insertions, deletions, substitutions and phrase shifts. The hypothesis is modified to match the reference, where a greedy search is used to select the set of shifts because an optimal sequence of edits (with shifts) is very expensive to find. The best alignment is the one that gives the </context>
<context position="17736" citStr="Rosti et al., 2007" startWordPosition="2899" endWordPosition="2902">.5M Table 1: Statistics of training, dev and test data for IWSLT and NIST tasks. In both experiments, we used four systems, as listed in Table 2, they are phrase-based system Moses (Koehn et al., 2007), hierarchical phrasebased system (Chiang, 2007), BTG-based lexicalized reordering phrase-based system (Xiong et al., 2006) and a tree sequence alignment-based tree-to-tree translation system (Zhang et al., 2008). Each system for the same task is trained on the same data set. 4.2 Experiments setting For each system, we used the top 10 scored hypotheses to build the confusion network. Similar to (Rosti et al., 2007a), each word in the hypothesis is assigned with a rank-based score of 1/ (1 + r) , where r is the rank of the hypothesis. And we assign the same weights to each system. For selecting the backbone, only the top hypothesis from each system is considered as a candidate for the backbone. Concerning the four alignment methods, we use the default setting for GIZA++; and use toolkit TERCOM (Snover et al., 2006) to compute the TER-based word alignment, and also use the default setting. For fair comparison reason, we 4 LDC2003E14 5 http://www.nist.gov/speech/tests/mt/ decide to do not use any addition</context>
</contexts>
<marker>Rosti, Ayan, Xiang, Matsoukas, Schwartz, Dorr, 2007</marker>
<rawString>A. I. Rosti, N. F. Ayan, B. Xiang, S. Matsoukas, R. Schwartz and B. Dorr. 2007a. Combining Outputs from Multiple Machine Translation Systems. In Proceeding of NAACL-HLT-2007, pp. 228-235. Rochester, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A I Rosti</author>
<author>S Matsoukas</author>
<author>R Schwartz</author>
</authors>
<title>Improved Word-Level System Combination for Ma-chine Translation.</title>
<date>2007</date>
<booktitle>In Proceeding of ACL-2007,</booktitle>
<location>Prague.</location>
<contexts>
<context position="1702" citStr="Rosti et al., 2007" startWordPosition="235" endWordPosition="238">ur word alignment methods on both Chinese-to-English spoken and written language tasks. 1 Introduction Machine translation (MT) system combination technique leverages on multiple MT systems to achieve better performance by combining their outputs. Confusion network based system combination for machine translation has shown promising advantage compared with other techniques based system combination, such as sentence level hypothesis selection by voting and source sentence re-decoding using the phrases or translation models that are learned from the source sentences and target hypotheses pairs (Rosti et al., 2007a; Huang and Papineni, 2007). In general, the confusion network based system combination method for MT consists of four steps: 1) Backbone selection: to select a backbone (also called “skeleton”) from all hypotheses. The backbone defines the word orders of the final translation. 2) Hypothesis alignment: to build word-alignment between backbone and each hypothesis. 3) Confusion network construction: to build a confusion network based on hypothesis alignments. 4) Confusion network decoding: to decode the best translation from a confusion network. Among the four steps, the hypothesis alignment pr</context>
<context position="2958" citStr="Rosti et al. (2007" startWordPosition="429" endWordPosition="432">thod due to the varying word orders between outputs from different MT systems (Rosti et al, 2007). Many techniques have been studied to address this issue. Bangalore et al. (2001) used the edit distance alignment algorithm which is extended to multiple strings to build confusion network, it only allows monotonic alignment. Jayaraman and Lavie (2005) proposed a heuristic-based matching algorithm which allows nonmonotonic alignments to align the words between the hypotheses. More recently, Matusov et al. (2006, 2008) used GIZA++ to produce word alignment for hypotheses pairs. Sim et al. (2007), Rosti et al. (2007a), and Rosti et al. (2007b) used minimum Translation Error Rate (TER) (Snover et al., 2006) alignment to build the confusion network. Rosti et al. (2008) extended TER algorithm which allows a confusion network as the reference to compute word alignment. Karakos et al. (2008) used ITG-based method for hypothesis alignment. Chen et al. (2008) used Competitive Linking Algorithm (CLA) (Melamed, 2000) to align the words to construct confusion network. Ayan et al. (2008) proposed to improve alignment of hypotheses using synonyms as found in WordNet (Fellbaum, 1998) and a two-pass alignment strategy</context>
<context position="6281" citStr="Rosti et al., 2007" startWordPosition="956" endWordPosition="959">thods, and the algorithm of computing intersection word alignment for all four word alignment methods. Section 4 describes the experiments setting and results on two translation tasks. Section 5 concludes the paper. 2 Confusion network based system combination In order to compare different hypothesis alignment methods, we implement a confusion network decoding system as follows: Backbone selection: in the previous work, Matusov et al. (2006, 2008) let every hypothesis play the role of the backbone (also called “skeleton” or “alignment reference”) once. We follow the work of (Sim et al., 2007; Rosti et al., 2007a; Rosti et al., 2007b; He et al., 2008) and choose the hypothesis that best agrees with other hypotheses on average as the backbone by applying Minimum Bayes Risk (MBR) decoding (Kumar and Byrne, 2004). TER score (Snover et al, 2006) is used as the loss function in MBR decoding. Given a hypothesis set H, the backbone can be computed using the following equation, where TER(•,•) returns the TER score of two hypotheses. Eb arg min = ∑ TER E E ( ˆ , ) ˆ E H E H E E Hypothesis alignment: all hypotheses are word-aligned to the corresponding backbone in a many-to-one manner. We apply four word align</context>
<context position="11129" citStr="Rosti et al., 2007" startWordPosition="1795" endWordPosition="1798">are widely used in confusion network based system combination or bilingual parallel corpora word alignment. 3.1 Hypothesis-to-backbone word alignment GIZA++: Matusov et al. (2006, 2008) proposed using GIZA++ (Och and Ney, 2003) to align words between the backbone and hypothesis. This method uses enhanced HMM model bootstrapped from IBM Model-1 to estimate the alignment model. All hypotheses of the whole test set are collected to create sentence pairs for GIZA++ training. GIZA++ produces hypothesisbackbone many-to-1 word alignments. TER-based: TER-based word alignment method (Sim et al., 2007; Rosti et al., 2007a; Rosti et al., 2007b) is an extension of multiple string matching algorithm based on Levenshtein edit distance (Bangalore et al., 2001). The TER (translation error rate) score (Snover et al., 2006) measures the ratio of minimum number of string edits between a hypothesis and reference where the edits include insertions, deletions, substitutions and phrase shifts. The hypothesis is modified to match the reference, where a greedy search is used to select the set of shifts because an optimal sequence of edits (with shifts) is very expensive to find. The best alignment is the one that gives the </context>
<context position="17736" citStr="Rosti et al., 2007" startWordPosition="2899" endWordPosition="2902">.5M Table 1: Statistics of training, dev and test data for IWSLT and NIST tasks. In both experiments, we used four systems, as listed in Table 2, they are phrase-based system Moses (Koehn et al., 2007), hierarchical phrasebased system (Chiang, 2007), BTG-based lexicalized reordering phrase-based system (Xiong et al., 2006) and a tree sequence alignment-based tree-to-tree translation system (Zhang et al., 2008). Each system for the same task is trained on the same data set. 4.2 Experiments setting For each system, we used the top 10 scored hypotheses to build the confusion network. Similar to (Rosti et al., 2007a), each word in the hypothesis is assigned with a rank-based score of 1/ (1 + r) , where r is the rank of the hypothesis. And we assign the same weights to each system. For selecting the backbone, only the top hypothesis from each system is considered as a candidate for the backbone. Concerning the four alignment methods, we use the default setting for GIZA++; and use toolkit TERCOM (Snover et al., 2006) to compute the TER-based word alignment, and also use the default setting. For fair comparison reason, we 4 LDC2003E14 5 http://www.nist.gov/speech/tests/mt/ decide to do not use any addition</context>
</contexts>
<marker>Rosti, Matsoukas, Schwartz, 2007</marker>
<rawString>A. I. Rosti, S. Matsoukas and R. Schwartz. 2007b. Improved Word-Level System Combination for Ma-chine Translation. In Proceeding of ACL-2007, Prague.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A I Rosti</author>
<author>B Zhang</author>
<author>S Matsoukas</author>
<author>R Schwartz</author>
</authors>
<title>Incremental Hypothesis Alignment for Building Confusion Networks with Application to Machine Translation System Combination,</title>
<date>2008</date>
<booktitle>In Proceeding of the Third ACL Workshop on Statistical Machine Translation,</booktitle>
<pages>183--186</pages>
<contexts>
<context position="3112" citStr="Rosti et al. (2008)" startWordPosition="454" endWordPosition="457">e. Bangalore et al. (2001) used the edit distance alignment algorithm which is extended to multiple strings to build confusion network, it only allows monotonic alignment. Jayaraman and Lavie (2005) proposed a heuristic-based matching algorithm which allows nonmonotonic alignments to align the words between the hypotheses. More recently, Matusov et al. (2006, 2008) used GIZA++ to produce word alignment for hypotheses pairs. Sim et al. (2007), Rosti et al. (2007a), and Rosti et al. (2007b) used minimum Translation Error Rate (TER) (Snover et al., 2006) alignment to build the confusion network. Rosti et al. (2008) extended TER algorithm which allows a confusion network as the reference to compute word alignment. Karakos et al. (2008) used ITG-based method for hypothesis alignment. Chen et al. (2008) used Competitive Linking Algorithm (CLA) (Melamed, 2000) to align the words to construct confusion network. Ayan et al. (2008) proposed to improve alignment of hypotheses using synonyms as found in WordNet (Fellbaum, 1998) and a two-pass alignment strategy based on TER word alignment approach. He et al. (2008) proposed an IHMM-based word alignment method which the parameters are estimated indirectly from a </context>
</contexts>
<marker>Rosti, Zhang, Matsoukas, Schwartz, 2008</marker>
<rawString>A. I. Rosti, B. Zhang, S. Matsoukas, and R. Schwartz. 2008. Incremental Hypothesis Alignment for Building Confusion Networks with Application to Machine Translation System Combination, In Proceeding of the Third ACL Workshop on Statistical Machine Translation, pp. 183-186.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K C Sim</author>
<author>W J Byrne</author>
<author>M J F Gales</author>
<author>H Sahbi</author>
<author>P C Woodland</author>
</authors>
<title>Consensus network decoding for statistical machine translation system combination.</title>
<date>2007</date>
<booktitle>In Proceeding of ICASSP-2007.</booktitle>
<contexts>
<context position="2938" citStr="Sim et al. (2007)" startWordPosition="425" endWordPosition="428">challenge to the method due to the varying word orders between outputs from different MT systems (Rosti et al, 2007). Many techniques have been studied to address this issue. Bangalore et al. (2001) used the edit distance alignment algorithm which is extended to multiple strings to build confusion network, it only allows monotonic alignment. Jayaraman and Lavie (2005) proposed a heuristic-based matching algorithm which allows nonmonotonic alignments to align the words between the hypotheses. More recently, Matusov et al. (2006, 2008) used GIZA++ to produce word alignment for hypotheses pairs. Sim et al. (2007), Rosti et al. (2007a), and Rosti et al. (2007b) used minimum Translation Error Rate (TER) (Snover et al., 2006) alignment to build the confusion network. Rosti et al. (2008) extended TER algorithm which allows a confusion network as the reference to compute word alignment. Karakos et al. (2008) used ITG-based method for hypothesis alignment. Chen et al. (2008) used Competitive Linking Algorithm (CLA) (Melamed, 2000) to align the words to construct confusion network. Ayan et al. (2008) proposed to improve alignment of hypotheses using synonyms as found in WordNet (Fellbaum, 1998) and a two-pas</context>
<context position="6261" citStr="Sim et al., 2007" startWordPosition="952" endWordPosition="955"> word alignment methods, and the algorithm of computing intersection word alignment for all four word alignment methods. Section 4 describes the experiments setting and results on two translation tasks. Section 5 concludes the paper. 2 Confusion network based system combination In order to compare different hypothesis alignment methods, we implement a confusion network decoding system as follows: Backbone selection: in the previous work, Matusov et al. (2006, 2008) let every hypothesis play the role of the backbone (also called “skeleton” or “alignment reference”) once. We follow the work of (Sim et al., 2007; Rosti et al., 2007a; Rosti et al., 2007b; He et al., 2008) and choose the hypothesis that best agrees with other hypotheses on average as the backbone by applying Minimum Bayes Risk (MBR) decoding (Kumar and Byrne, 2004). TER score (Snover et al, 2006) is used as the loss function in MBR decoding. Given a hypothesis set H, the backbone can be computed using the following equation, where TER(•,•) returns the TER score of two hypotheses. Eb arg min = ∑ TER E E ( ˆ , ) ˆ E H E H E E Hypothesis alignment: all hypotheses are word-aligned to the corresponding backbone in a many-to-one manner. We a</context>
<context position="11109" citStr="Sim et al., 2007" startWordPosition="1791" endWordPosition="1794">ent methods which are widely used in confusion network based system combination or bilingual parallel corpora word alignment. 3.1 Hypothesis-to-backbone word alignment GIZA++: Matusov et al. (2006, 2008) proposed using GIZA++ (Och and Ney, 2003) to align words between the backbone and hypothesis. This method uses enhanced HMM model bootstrapped from IBM Model-1 to estimate the alignment model. All hypotheses of the whole test set are collected to create sentence pairs for GIZA++ training. GIZA++ produces hypothesisbackbone many-to-1 word alignments. TER-based: TER-based word alignment method (Sim et al., 2007; Rosti et al., 2007a; Rosti et al., 2007b) is an extension of multiple string matching algorithm based on Levenshtein edit distance (Bangalore et al., 2001). The TER (translation error rate) score (Snover et al., 2006) measures the ratio of minimum number of string edits between a hypothesis and reference where the edits include insertions, deletions, substitutions and phrase shifts. The hypothesis is modified to match the reference, where a greedy search is used to select the set of shifts because an optimal sequence of edits (with shifts) is very expensive to find. The best alignment is the</context>
</contexts>
<marker>Sim, Byrne, Gales, Sahbi, Woodland, 2007</marker>
<rawString>K. C. Sim, W. J. Byrne, M. J.F. Gales, H. Sahbi, and P. C. Woodland. 2007. Consensus network decoding for statistical machine translation system combination. In Proceeding of ICASSP-2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Snover</author>
<author>B Dorr</author>
<author>R Schwartz</author>
<author>L Micciulla</author>
<author>J Makhoul</author>
</authors>
<title>A study of translation edit rate with targeted human annotation.</title>
<date>2006</date>
<booktitle>In Proceeding of AMTA.</booktitle>
<contexts>
<context position="3050" citStr="Snover et al., 2006" startWordPosition="444" endWordPosition="447">, 2007). Many techniques have been studied to address this issue. Bangalore et al. (2001) used the edit distance alignment algorithm which is extended to multiple strings to build confusion network, it only allows monotonic alignment. Jayaraman and Lavie (2005) proposed a heuristic-based matching algorithm which allows nonmonotonic alignments to align the words between the hypotheses. More recently, Matusov et al. (2006, 2008) used GIZA++ to produce word alignment for hypotheses pairs. Sim et al. (2007), Rosti et al. (2007a), and Rosti et al. (2007b) used minimum Translation Error Rate (TER) (Snover et al., 2006) alignment to build the confusion network. Rosti et al. (2008) extended TER algorithm which allows a confusion network as the reference to compute word alignment. Karakos et al. (2008) used ITG-based method for hypothesis alignment. Chen et al. (2008) used Competitive Linking Algorithm (CLA) (Melamed, 2000) to align the words to construct confusion network. Ayan et al. (2008) proposed to improve alignment of hypotheses using synonyms as found in WordNet (Fellbaum, 1998) and a two-pass alignment strategy based on TER word alignment approach. He et al. (2008) proposed an IHMM-based word alignmen</context>
<context position="6515" citStr="Snover et al, 2006" startWordPosition="997" endWordPosition="1000">rk based system combination In order to compare different hypothesis alignment methods, we implement a confusion network decoding system as follows: Backbone selection: in the previous work, Matusov et al. (2006, 2008) let every hypothesis play the role of the backbone (also called “skeleton” or “alignment reference”) once. We follow the work of (Sim et al., 2007; Rosti et al., 2007a; Rosti et al., 2007b; He et al., 2008) and choose the hypothesis that best agrees with other hypotheses on average as the backbone by applying Minimum Bayes Risk (MBR) decoding (Kumar and Byrne, 2004). TER score (Snover et al, 2006) is used as the loss function in MBR decoding. Given a hypothesis set H, the backbone can be computed using the following equation, where TER(•,•) returns the TER score of two hypotheses. Eb arg min = ∑ TER E E ( ˆ , ) ˆ E H E H E E Hypothesis alignment: all hypotheses are word-aligned to the corresponding backbone in a many-to-one manner. We apply four word alignment methods: GIZA++-based, TER-based, CLA-based, and IHMM-based word alignment algorithm. For each method, we will give details in the next section. Confusion network construction: confusion network is built from one-to-one word alig</context>
<context position="11328" citStr="Snover et al., 2006" startWordPosition="1826" endWordPosition="1829">ing GIZA++ (Och and Ney, 2003) to align words between the backbone and hypothesis. This method uses enhanced HMM model bootstrapped from IBM Model-1 to estimate the alignment model. All hypotheses of the whole test set are collected to create sentence pairs for GIZA++ training. GIZA++ produces hypothesisbackbone many-to-1 word alignments. TER-based: TER-based word alignment method (Sim et al., 2007; Rosti et al., 2007a; Rosti et al., 2007b) is an extension of multiple string matching algorithm based on Levenshtein edit distance (Bangalore et al., 2001). The TER (translation error rate) score (Snover et al., 2006) measures the ratio of minimum number of string edits between a hypothesis and reference where the edits include insertions, deletions, substitutions and phrase shifts. The hypothesis is modified to match the reference, where a greedy search is used to select the set of shifts because an optimal sequence of edits (with shifts) is very expensive to find. The best alignment is the one that gives the minimum number of translation edits. TER-based method produces 1-to-1 word alignments. CLA-based: Chen et al. (2008) used competitive linking algorithm (CLA) (Melamed, 2000) to build confusion networ</context>
<context position="18144" citStr="Snover et al., 2006" startWordPosition="2976" endWordPosition="2979">, 2008). Each system for the same task is trained on the same data set. 4.2 Experiments setting For each system, we used the top 10 scored hypotheses to build the confusion network. Similar to (Rosti et al., 2007a), each word in the hypothesis is assigned with a rank-based score of 1/ (1 + r) , where r is the rank of the hypothesis. And we assign the same weights to each system. For selecting the backbone, only the top hypothesis from each system is considered as a candidate for the backbone. Concerning the four alignment methods, we use the default setting for GIZA++; and use toolkit TERCOM (Snover et al., 2006) to compute the TER-based word alignment, and also use the default setting. For fair comparison reason, we 4 LDC2003E14 5 http://www.nist.gov/speech/tests/mt/ decide to do not use any additional resource, such as target language synonym list, IBM model lexicon; therefore, only surface similarity is applied in IHMM-based and CLA-based methods. We compute the distortion model by following (He et al., 2008) for IHMM and CLA-based methods. The weights for each model are optimized on held-out data. System Dev Test Sys1 30.75 27.58 IWSLT Sys2 30.74 28.54 Sys3 29.99 26.91 Sys4 31.32 27.48 Sys1 25.64 </context>
</contexts>
<marker>Snover, Dorr, Schwartz, Micciulla, Makhoul, 2006</marker>
<rawString>M. Snover, B. Dorr, R. Schwartz, L. Micciulla, and J. Makhoul. 2006. A study of translation edit rate with targeted human annotation. In Proceeding of AMTA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Takezawa</author>
<author>E Sumita</author>
<author>F Sugaya</author>
<author>H Yamamoto</author>
<author>S Yamamoto</author>
</authors>
<title>Toward a broad-coverage bilingual corpus for speech translation of travel conversations in the real world.</title>
<date>2002</date>
<booktitle>In Proceeding of LREC-2002, Las Palmas de Gran Canaria,</booktitle>
<contexts>
<context position="15674" citStr="Takezawa et al., 2002" startWordPosition="2555" endWordPosition="2558">re than two links share a same hypothesis or backbone word and also satisfy the constraints, we choose the link that with the highest similarity score. For example, in Figure 2, since MCS-based similarity scores S(shot, shoot) &gt; S(shot, the) , we choose alignment (a). 4 Experiments and results 4.1 Tasks and single systems Experiments are carried out in two domains. One is in spoken language domain while the other is on newswire corpus. Both experiments are on Chinese-to-English translation. Experiments on spoken language domain were carried out on the Basic Traveling Expression Corpus (BTEC) (Takezawa et al., 2002) Chinese- to-English data augmented with HITcorpus1. BTEC is a multilingual speech corpus which contains sentences spoken by tourists. 40K sentence-pairs are used in our experiment. HIT-corpus is a balanced corpus and has 500K sentence-pairs in total. We selected 360K sentence-pairs that are more similar to BTEC data according to its sub-topic. Additionally, the English sentences of Tanaka corpus2 were also used to train our language model. We ran experiments on an IWSLT challenge task which uses IWSLT20063 DEV clean text set as development set and IWSLT-2006 TEST clean text as test set. shot </context>
</contexts>
<marker>Takezawa, Sumita, Sugaya, Yamamoto, Yamamoto, 2002</marker>
<rawString>T. Takezawa, E. Sumita, F. Sugaya, H. Yamamoto, and S. Yamamoto. 2002. Toward a broad-coverage bilingual corpus for speech translation of travel conversations in the real world. In Proceeding of LREC-2002, Las Palmas de Gran Canaria, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Xiong</author>
<author>Q Liu</author>
<author>S Lin</author>
</authors>
<title>Maximum Entropy Based Phrase Reordering Model for Statistical Machine Translation.</title>
<date>2006</date>
<booktitle>In Proceeding of ACL-2006.</booktitle>
<pages>521--528</pages>
<contexts>
<context position="17442" citStr="Xiong et al., 2006" startWordPosition="2849" endWordPosition="2852">ta Ch En Train Sent. 406K Words 4.4M 4.6M Dev Sent. 489 489×7 IWSLT Words 5,896 45,449 Test Sent. 500 500×7 Words 6,296 51,227 Add. Words - 1.7M Train Sent. 238K Words 7.0M 8.9M Dev Sent. 878 878×4 NIST 2002 Words 23,248 108,616 Test Sent. 1,082 1,082×4 2005 Words 30,544 141,915 Add. Words - 61.5M Table 1: Statistics of training, dev and test data for IWSLT and NIST tasks. In both experiments, we used four systems, as listed in Table 2, they are phrase-based system Moses (Koehn et al., 2007), hierarchical phrasebased system (Chiang, 2007), BTG-based lexicalized reordering phrase-based system (Xiong et al., 2006) and a tree sequence alignment-based tree-to-tree translation system (Zhang et al., 2008). Each system for the same task is trained on the same data set. 4.2 Experiments setting For each system, we used the top 10 scored hypotheses to build the confusion network. Similar to (Rosti et al., 2007a), each word in the hypothesis is assigned with a rank-based score of 1/ (1 + r) , where r is the rank of the hypothesis. And we assign the same weights to each system. For selecting the backbone, only the top hypothesis from each system is considered as a candidate for the backbone. Concerning the four </context>
</contexts>
<marker>Xiong, Liu, Lin, 2006</marker>
<rawString>D. Xiong, Q. Liu and S. Lin. 2006. Maximum Entropy Based Phrase Reordering Model for Statistical Machine Translation. In Proceeding of ACL-2006. pp.521-528.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Zens</author>
<author>H Ney</author>
</authors>
<title>N-gram Posterior Probabilities for Statistical Machine Translation.</title>
<date>2006</date>
<booktitle>In Proceeding of HLT-NAACL Workshop on SMT,</booktitle>
<pages>72--77</pages>
<contexts>
<context position="10220" citStr="Zens and Ney, 2006" startWordPosition="1655" endWordPosition="1658">therwise, word is reordered as (d). c d Figure 1: Example of alignment normalization. Confusion network decoding: the output translations for a given source sentence are extracted from the confusion network through a beam-search algorithm with a log-linear combination of a set of feature functions. The feature functions which are employed in the search process are: • Language model(s), • Direct and inverse IBM model-1, • Position-based word posterior probabilities (arc scores of the confusion network), • Word penalty, • N-gram frequencies (Chen et al., 2005), • N-gram posterior probabilities (Zens and Ney, 2006). The n-grams used in the last two feature functions are collected from the original hypotheses list from each single system. The weights of feature functions are optimized to maximize the scoring measure (Och, 2003). 3 Word alignment algorithms We compare four word alignment methods which are widely used in confusion network based system combination or bilingual parallel corpora word alignment. 3.1 Hypothesis-to-backbone word alignment GIZA++: Matusov et al. (2006, 2008) proposed using GIZA++ (Och and Ney, 2003) to align words between the backbone and hypothesis. This method uses enhanced HMM</context>
</contexts>
<marker>Zens, Ney, 2006</marker>
<rawString>R. Zens and H. Ney. 2006. N-gram Posterior Probabilities for Statistical Machine Translation. In Proceeding of HLT-NAACL Workshop on SMT, pp. 72-77, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Zhang</author>
<author>H Jiang</author>
<author>A Aw</author>
<author>H Li</author>
<author>C L Tan</author>
<author>S Li</author>
</authors>
<title>A Tree Sequence Alignment-based Treeto-Tree Translation Model.</title>
<date>2008</date>
<booktitle>In Proceeding of ACL2008.</booktitle>
<location>Columbus, US.</location>
<contexts>
<context position="17531" citStr="Zhang et al., 2008" startWordPosition="2861" endWordPosition="2864">st Sent. 500 500×7 Words 6,296 51,227 Add. Words - 1.7M Train Sent. 238K Words 7.0M 8.9M Dev Sent. 878 878×4 NIST 2002 Words 23,248 108,616 Test Sent. 1,082 1,082×4 2005 Words 30,544 141,915 Add. Words - 61.5M Table 1: Statistics of training, dev and test data for IWSLT and NIST tasks. In both experiments, we used four systems, as listed in Table 2, they are phrase-based system Moses (Koehn et al., 2007), hierarchical phrasebased system (Chiang, 2007), BTG-based lexicalized reordering phrase-based system (Xiong et al., 2006) and a tree sequence alignment-based tree-to-tree translation system (Zhang et al., 2008). Each system for the same task is trained on the same data set. 4.2 Experiments setting For each system, we used the top 10 scored hypotheses to build the confusion network. Similar to (Rosti et al., 2007a), each word in the hypothesis is assigned with a rank-based score of 1/ (1 + r) , where r is the rank of the hypothesis. And we assign the same weights to each system. For selecting the backbone, only the top hypothesis from each system is considered as a candidate for the backbone. Concerning the four alignment methods, we use the default setting for GIZA++; and use toolkit TERCOM (Snover </context>
</contexts>
<marker>Zhang, Jiang, Aw, Li, Tan, Li, 2008</marker>
<rawString>M. Zhang, H. Jiang, A. Aw, H. Li, C. L. Tan, and S. Li. 2008. A Tree Sequence Alignment-based Treeto-Tree Translation Model. In Proceeding of ACL2008. Columbus, US. June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Zhang</author>
<author>S Vogel</author>
<author>A Waibel</author>
</authors>
<title>Interpreting BLEU/NIST scores: How much improvement do we need to have a better system?</title>
<date>2004</date>
<booktitle>In Proceedings of LREC</booktitle>
<pages>2051--2054</pages>
<marker>Zhang, Vogel, Waibel, 2004</marker>
<rawString>Y. Zhang, S. Vogel, and A. Waibel 2004. Interpreting BLEU/NIST scores: How much improvement do we need to have a better system? In Proceedings of LREC 2004, pp. 2051-2054.</rawString>
</citation>
<citation valid="false">
<title>The first author has moved to National Research Council, Canada. His current email address is:</title>
<publisher>Boxing.Chen@nrc.ca.</publisher>
<marker></marker>
<rawString>* The first author has moved to National Research Council, Canada. His current email address is: Boxing.Chen@nrc.ca.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>