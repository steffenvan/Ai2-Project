<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.852173">
Phonological Analysis in Typed
Feature Systems
</title>
<author confidence="0.999856">
Steven Bird* Ewan Klein*
</author>
<affiliation confidence="0.999113">
University of Edinburgh University of Edinburgh
</affiliation>
<bodyText confidence="0.9831265">
Research on constraint-based grammar frameworks has focused on syntax and semantics largely to
the exclusion of phonology. Likewise, current developments in phonology have generally ignored
the technical and linguistic innovations available in these frameworks. In this paper we suggest
some strategies for reuniting phonology and the rest of grammar in the context of a uniform
constraint formalism. We explain why this is a desirable goal, and we present some conservative
extensions to current practice in computational linguistics and in nonlinear phonology that we
believe are necessary and sufficient for achieving this goal.
We begin by exploring the application of typed feature logic to phonology and propose a
system of prosodic types. Next, taking HPSG as an exemplar of the grammar frameworks we have
in mind, we show how the phonology attribute can be enriched so that it can encode multi-tiered,
hierarchical phonological representations. Finally, we exemplify the approach in some detail for the
nonconcatenative morphology of Sierra Miwok and for schwa alternation in French. The approach
taken in this paper lends itself particularly well to capturing phonological generalizations in terms
of high-level prosodic constraints.
</bodyText>
<sectionHeader confidence="0.824013" genericHeader="method">
1. Phonology in Constraint-Based Grammar
</sectionHeader>
<bodyText confidence="0.9997924375">
Classical generative phonology is couched within the same set of assumptions that
dominated standard transformational grammar. Despite some claims that &amp;quot;deriva-
tions based on ordered rules (that is, external ordering) and incorporating interme-
diate structures are essential to phonology&amp;quot; (Bromberger and Halle 1989:52), much
recent work has tended toward a new model, frequently described in terms of con-
straints on well-formedness (Paradis 1988; Goldsmith 1993; McCarthy and Prince 1993;
Prince and Smolensky 1993). While this work has an increasingly declarative flavor,
most versions retain procedural devices for repairing representations that fail to meet
certain constraints, or for constraints to override each other. This view is in marked
contrast to the interpretation of constraints in grammar frameworks like LFG, GPSG,
and HPSG1 and in constraint programming systems more generally (Jaffar and Lassez
1987; Smolka 1992). In such approaches, constraints cannot be circumvented, there
are no &apos;intermediate structures,&apos; and the well-formedness constraint (Partee 1979) is
observed (i.e. ill-formed representations can never be created). The advantage of these
frameworks is that they allow interesting linguistic analyses to be encoded while
remaining computationally tractable.
</bodyText>
<footnote confidence="0.5367588">
* University of Edinburgh, Centre for Cognitive Science, 2 Buccleuch Place, Edinburgh EH8 9LW, U.K.
steven.ewan@cogni.ed.ac.uk
1 Lexical Functional Grammar (Kaplan and Bresnan 1982), Generalized Phrase Structure Grammar
(Gazdar, Klein, Pullum, and Sag 1985), and Head-Driven Phrase Structure Grammar (Pollard and Sag
1987).
</footnote>
<note confidence="0.879605">
© 1994 Association for Computational Linguistics
Computational Linguistics Volume 20, Number 3
</note>
<bodyText confidence="0.9999296">
Here, we are interested in the question of what a theory of phonology ought to look
like if it is to be compatible with a constraint-based grammar framework. This issue
has already received attention,&apos; although a thoroughgoing integration of phonology
into constraint-based grammars has yet to be attempted. To ease exposition, we shall
take HPSG as a suitably representative candidate of such approaches. Although we are
broadly committed to a sign-oriented approach to grammar, none of our proposals
depends crucially on specific tenets of HPSG.
Rather than attempting to theorize at an abstract level about constraint-based
phonology, we shall engage in two case studies intended to give a concrete illustra-
tion of important issues: these involve templatic morphology in Sierra Miwok and
schwa alternation in French. Before launching into these studies, however, we present
an overview of some aspects of phonology that present a challenge to standard as-
sumptions taken in sign-oriented constraint-based grammars. Then we describe a (sim-
plified) version of HPSG that will make it possible to illustrate the approach without
irrelevant technical machinery.
</bodyText>
<subsectionHeader confidence="0.989173">
1.1 The Challenge of Phonology
</subsectionHeader>
<bodyText confidence="0.999808633333333">
Given that the dominant focus of most research in constraint-based grammar has
been syntax and semantics, it is not surprising that the phonological content of words
and phrases has been largely limited to orthographic strings, supplemented with a
concatenation operation. How far would such representations have to be enriched if
we wanted to accommodate a more thoroughgoing treatment of phonology?
As remarked earlier, recent work in theoretical phonology has apparently moved
closer to a constraint-based perspective, and is thus a promising starting point for our
investigation. Yet there are at least three challenges that confront anyone looking into
theoretical phonology from the viewpoint of computational linguistics. Most striking
perhaps is the relative informality of the language in which theoretical statements are
couched. Bird and Ladd (1991) have catalogued several examples of this: notational
ambiguity (incoherence), definition by example (informality), variable interpretation
of notation depending on subjective criteria (inconsistency), and uncertainty about
empirical content (indeterminacy). When a clear theoretical statement can be found,
it is usually expressed in procedural terms, which clouds the empirical ramifications
making a theory difficult to falsify. Finally, even when explicit and nonprocedural
generalizations are found, they are commonly stated in a nonlinear model, which
clearly goes beyond the assumptions about phonology made in HPSG as it currently
stands.
We approach these challenges by adopting a formal, nonprocedural, nonlinear
model of phonology and showing how it can be integrated into HPSG, following on
the heels of recent work by the authors (Bird and Klein 1990; Bird 1992; Klein 1992).
One of the starting assumptions of this work is that phonological representations
are intensional, i.e. each representation is actually a description of a class of utterances.
Derivations progress by refining descriptions, further constraining the class of denoted
objects. Lexical representations are likewise partial, and phonological constraints are
cast as generalizations in a lexical inheritance hierarchy or in a prosodic inheritance
hierarchy. When set against the background of constraint-based grammar, this inten-
sional approach is quite natural (cf. Johnson [19881). Moreover, some recent thinking on
the phonology—phonetics interface supports this view (Pierrehumbert 1990; Coleman
</bodyText>
<footnote confidence="0.744485">
2 (Bach and Wheeler 1981; Wheeler 1981; Bird 1990; Cahill 1990; Coleman 1991; Scobbie 1991; Bird 1992;
Walther 1992; Mastroianni 1993; Russell 1993)
</footnote>
<page confidence="0.993753">
456
</page>
<note confidence="0.734827">
Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systems
</note>
<bodyText confidence="0.97410347368421">
1992). However, it represents a fundamental split with the generative tradition, where
rules do not so much refine descriptions as alter the objects themselves (Keating 1984).
While it is clearly possible to integrate an essentially generative model into the
mold of constraint-based grammar (Krieger, Pirker, and Nerbonne 1993), it is less clear
that this is the approach most phonologists would wish to take nowadays. It is be-
coming increasingly apparent that rule-based relationships between surface forms and
hypothetical lexical forms are unable to capture important generalizations about sur-
face forms. This concern was voiced early in the history of generative phonology, when
Kisseberth (1970) complained that such rules regularly conspire to achieve particular
surface configurations, but are unable to express the most elementary observations
about what those surface configurations are. As a criticism of rule-based systems,
Kisseberth&apos;s complaint remains valid and has been echoed several times since then
(Shibatani 1973; Hooper 1976; Hudson 1980; Manaster Ramer 1981). However, recent
work in phonology has moved away from models involving rules that relate lexical
and surface forms toward models involving general systems of interacting constraints,
where this problem has been side-stepped.
Accordingly, we avoid the theoretical framework of early generative phonology,
focusing instead on encoding phonological constraints in a constraint-based grammar
framework. We present an overview of the grammar framework in the next section.
</bodyText>
<subsectionHeader confidence="0.994378">
1.2 Motivation
</subsectionHeader>
<bodyText confidence="0.999893">
At this point, we should briefly address the question: What is gained by integrating
phonology into a constraint-based grammar? One pragmatic answer is that approaches
like HPSG have already taken this step, by introducing a PHONOLOGY attribute that
parallels attributes for SYNTAX and SEMANTICS. Since, as we have already pointed out,
the value of PHONOLOGY needs to be enriched somehow if it is to be linguistically
adequate, it is reasonable to ask whether the formalism allows insightful statements
of phonological generalizations.
An objection might take the following form: phonology is formally less complex
than syntax, as shown by the body of work on finite state analyses of phonology (cf.
Section 1.4). Hence, it is inappropriate to encode phonology in a general purpose for-
malism that has been designed to accommodate more complex phenomena. As a first
response, we would maintain that formalisms should not be confused with theories.
Certainly, we want to have a restrictive theory of phonology and its interactions with
other levels of grammar. But we view constraint-based formalisms as languages for
expressing such theories, not as theories themselves. Moreover, the fact that we use a
uniform constraint formalism does not force us to use homogeneous inferential mech-
anisms for that formalism; this issue is discussed further in Section 1.4 and Section 6.
A further question might be: do natural language grammars require the kind
of interaction between phonology and other levels of grammar made possible by
constraint-based formalisms? This is not the place to explore this issue in the detail
it deserves. However, even if we accept the contention of Pullum and Zwicky (1984)
that the interactions between phonology and syntax (narrowly construed) are highly
restricted, there are still good reasons for wanting to accommodate phonological rep-
resentations as one of the constraints in a sign-based grammar framework.
To begin with, it is relatively uncontroversial that morphology needs to be in-
terfaced with both syntax and phonology. Approaches like that of Krieger and Ner-
bonne (in press) have shown that both derivational and inflectional morphology can
be usefully expressed within the constraint-based paradigm. Taking the further step
of adding phonology seems equally desirable.
Second, the use of typed feature structures within the lexicon has been strongly
</bodyText>
<page confidence="0.995037">
457
</page>
<note confidence="0.925304">
Computational Linguistics Volume 20, Number 3
</note>
<bodyText confidence="0.999819210526316">
argued for by Briscoe (1991) and Copestake et al. (in press). That is, even when we
ignore syntactic combination, constraint-based grammar frameworks turn out to be
well suited to expressing the category and semantic information fields of lexical entries.
But the interaction of phonology with categorial information inside the lexicon is well
documented. Lexical phonology (Kiparsky 1982) has shown in detail how phonological
phenomena are conditioned by morphologically specified domains. If direct interaction
between phonology and morpho-syn tax is prohibited, one can only resort to ad hoc
and poorly motivated diacritic features.
Turning to a different empirical domain, it can be argued that focus constructions
exhibit an interaction between information structure (at the semantic–pragmatic level)
with prosodic structure (at the phonological level). This interaction can be directly
expressed in a sign-oriented approach. In other frameworks it is common practice to
avoid direct reference to phonology by invoking a morpho-syntactic FOCUS feature
(e.g. Selkirk 1984; Rooth 1985); the mediation of syntax in this way appears to be more
an artifact of the grammar architecture than an independently motivated requirement.
Equally, it has been argued that the phenomenon of heavy NP shift is a kind of syntax-
phonology interaction that is simply stated in a constraint-based approach, where the
linear precedence constraints of syntax are sensitive to the phonological category of
weight (Bird 1992).
</bodyText>
<subsectionHeader confidence="0.992997">
1.3 Theoretical Framework
</subsectionHeader>
<bodyText confidence="0.998219705882353">
Typed feature structures (Carpenter 1992) impose a type discipline on constraint-based
grammar formalisms. A partial ordering over the types gives rise to an inheritance
hierarchy of constraints. As Emele and Zajac (1990) point out, this object-oriented
approach brings a number of advantages to grammar writing, such as a high level of
abstraction, inferential capacity and modularity.
On the face of it, such benefits should extend beyond syntax—to phonology for
example. Although there have been some valuable efforts to exploit inheritance and
type hierarchies within phonology (e.g. Reinhard and Gibbon 1991), the potential of
typed feature structures for this area has barely been scratched so far. In this section, we
present a brief overview of HPSG (Pollard and Sag 1987), a constraint-based grammar
formalism built around a type system that suits our purposes in phonology.
In order to formulate the type system of our grammar, we need to make two
kinds of TYPE DECLARATION. The first kind contains information about the subsumption
ordering over types. For example, the basic grammar object in HPSG is the feature
structure of type sign. The type sign has some SUBTYPES. If a is a subtype of T, then a
provides at least as much information as T. A type declaration for sign defines it as
the following disjunction of subtypes:3
</bodyText>
<subsectionHeader confidence="0.725599">
Example 1
</subsectionHeader>
<bodyText confidence="0.98428475">
sign = morph V stem V word V phrase
The second kind of declaration is an APPROPRIATENESS CONDITION. That is, for each
type, we declare (all and only) the attributes for which it is specified, and additionally
the types of values which those attributes can take.&apos; For example, objects of type sign
</bodyText>
<footnote confidence="0.8396006">
3 The constraints proposed here deviate in various respects from the standard version of HPSG. We
follow Carpenter (1992) in using the notation o- cto specify that type cr satisfies constraint rk.
4 We are using what Carpenter (1992) calls TOTAL WELL-TYPING. That is, (i) the only attributes and values
that can be specified for a given feature structure of type r are those appropriate for 7-; and (ii) every
feature structure of type T must be specified for all attributes appropriate for .
</footnote>
<page confidence="0.991568">
458
</page>
<note confidence="0.701110666666667">
Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systems
could be constrained to have the following features defined:
Example 2
</note>
<equation confidence="0.45428125">
[PHON : phon
SYNSEM : synsem
DTRS : list
sign
</equation>
<bodyText confidence="0.994818636363636">
That is, feature structures of type sign must contain the attributes PHON (i.e. phonol-
ogy), SYNSEM (i.e. syntax/semantics),5 and DTRS (i.e. daughters) and these attributes
must take values of a specific type (i.e., phon, synsem, and list, respectively). A further
crucial point is that appropriateness conditions are inherited by subtypes. For exam-
ple, since morph is a subtype of sign, it inherits all the constraints obeyed by sign.
Moreover, as we shall see in Section 3.2, it is subject to some further appropriateness
conditions that are not imposed on any of its supertypes.
Continuing in the same vein, we can assign appropriateness conditions to the types
synsem and phon that occurred as values in (2), (simplifying substantially from standard
HPSG). Here we give the constraints for synsem. The type phon will be discussed in
Section 2.
</bodyText>
<figure confidence="0.891121857142857">
Example 3
_
CAT: cat
AGR: agr
SUBCAT : list
SEM : semantics
-
</figure>
<bodyText confidence="0.999602333333333">
To conclude this section, we shall look very briefly at matters of interpretation
and inference. As shown by Carpenter (1992) and Zajac (1992, in press), we can use
constraint resolution to carry out type inference for feature terms. Following Zajac, let
us say that a GROUND feature term is a term all of whose type symbols are minimal
(i.e., the most specific types in the hierarchy immediately above 1). A WELL-TYPED
feature term is one that obeys all the type definitions. Then the meaning of a feature
term F is given by the set of all well-typed ground feature terms that are subsumed by
F. Evaluating F, construed as a query, involves describing F&apos;s denotation; for example,
enumerating all the well-typed ground feature terms it subsumes. Since the type defi-
nitions obeyed by F might be recursive, its denotation is potentially infinite. Consider
for example the following definitions (where &apos;nelist&apos; and &apos;elist&apos; stand for nonempty list
and empty list respectively, and T subsumes every type):
</bodyText>
<figure confidence="0.7983438">
Example 4
a. list nelist v elist
FIRST: T I
REST: list
nelist
</figure>
<footnote confidence="0.620746333333333">
5 Earlier versions of HPSG kept syntax and semantics as separate attributes, and we shall sometimes
revert to the latter when borrowing examples from other people&apos;s presentations.
synsem
</footnote>
<page confidence="0.964723">
459
</page>
<note confidence="0.550015">
Computational Linguistics Volume 20, Number 3
</note>
<bodyText confidence="0.999973">
Here, the denotation of the type symbol list is the set of all possible ground lists.
In practice, a constraint solver could recursively enumerate all these solutions; an
alternative proposed by Zajac would be to treat the symbol LIST as the best finite
approximation of the infinite set of all lists.
</bodyText>
<subsectionHeader confidence="0.985758">
1.4 Finite-State Phonology
</subsectionHeader>
<bodyText confidence="0.999983677419355">
Over the last decade much has been written on the application of finite-state trans-
ducers (FsTs) to phonology, centering on the TWO-LEVEL MODEL of Koskenniemi (1983).
Antworth (1990) and Sproat (1992) give comprehensive introductions to the field. The
formalism is an attractive computational model for 1960s generative phonology. How-
ever, as has already been noted, phonologists have since moved away from complex
string rewriting systems to a range of so-called nonlinear models of phonology. The
central innovation of this more recent work is the idea that phonological representa-
tions are not strings but collections of strings, synchronized like an orchestral score.
There have been some notable recent attempts to rescue the FST model from its
linearity in order to encompass nonlinear phonology (Kay 1987; Kornai 1991; Wiebe
1992). However, from our perspective, these refinements to the FST model still admit
unwarranted operations on phonological representations, as well as rule conspiracies
and the like. Rather, we believe a more constrained and linguistically appealing ap-
proach is to employ finite-state automata (FsAs) in preference to FSTs, since it has
been shown how FSAs can encode autosegmental representations and a variety of con-
straints on those representations (Bird and Ellison 1994). The leading idea in this work
is that each tier is a partial description of a string, and tiers are put together using the
intersection operation defined on FSAs.
Apart from being truer to current phonological theorizing, this one-level model
has a second important advantage over the two-level model. Since the set of FsAs forms
a Boolean lattice under intersection, union, and complement (a direct consequence of
the standard closure properties for regular languages), we can safely conjoin (&apos;unify&apos;),
disjoin, and negate phonological descriptions. Such a framework is obviously compat-
ible with constraint-based grammar formalisms, and there is no reason in principle
to prevent us from augmenting HPSG with the data type of regular expressions. In
practice, we are not aware of any existing implementations of HPSG (or other feature-
based grammars) that accommodate regular expressions. Ideally, we would envisage a
computational interpretation of typed feature structures where operations on regular
expression values are delegated to a specialized engine that manipulates the corre-
sponding FSAs and returns regular expression results.&apos; This issue is discussed further
in Section 6.
</bodyText>
<subsectionHeader confidence="0.998861">
1.5 Overview of the Paper
</subsectionHeader>
<bodyText confidence="0.999944125">
The structure of the paper is as follows. In the next section, we present our assump-
tions about phonological representations and phenomena, couched in the framework
of typed feature logic. In Section 3 we discuss our view of the lexicon, borrowing heav-
ily on HFSG&apos;s lexical type hierarchy, and developing some operations and representa-
tions needed for morphology. The next two sections investigate various applications
of the approach to two rather differing phenomena, namely Sierra Miwok templatic
morphology and French schwa. Section 6 discusses some implementation issues. The
paper concludes with a summary and a discussion of future prospects.
</bodyText>
<page confidence="0.9760045">
6 A similar approach is envisaged by Krieger, Pirker, and Nerbonne (1993).
460
</page>
<note confidence="0.573408">
Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systems
</note>
<sectionHeader confidence="0.972874" genericHeader="method">
2. String-Based Phonology
</sectionHeader>
<bodyText confidence="0.999859">
In this section we present a string-based phonology based on the HPSG list notation.
We present the approach in Section 2.1 and Section 2.2, concluding in Section 2.3 with
a discussion of prosodic constituency.
</bodyText>
<subsectionHeader confidence="0.995566">
2.1 List Notations
</subsectionHeader>
<bodyText confidence="0.9918116">
As a concession to existing practice in HPSG, we have taken the step of using lists in
place of strings. We shall use angle bracket notation as syntactic sugar for the standard
FIRST/REST encoding.
We shall assume that the type system allows parameterized types of the form
list(a), where a is an atomic type.
</bodyText>
<equation confidence="0.9340534">
Example 5
list(a) = elist(a) V nelist(a)
FIRST: a I
REST : list(a)
nelist(a)
</equation>
<bodyText confidence="0.836049">
We can now treat a* and a+ as abbreviations for list(a) and nelist(a) respectively.
Another useful abbreviatory notation is parenthesized elements within lists. We
shall interpret (a (b)) ,-- L, a list consisting of an a followed by an optional b concate-
nated with an arbitrary list L, as the following constraint:
Example 6
FIRST: a
</bodyText>
<equation confidence="0.9898532">
[FIRST : bj
REST : L VL
REST:
list
list
</equation>
<bodyText confidence="0.996979">
We shall see applications of these list notations in the next section.
</bodyText>
<subsectionHeader confidence="0.99811">
2.2 A Prosodic Type Hierarchy
</subsectionHeader>
<bodyText confidence="0.9999266">
A PROSODIC TYPE HIERARCHY is a subsumption network akin to the lexical hierarchy of
HPSG (Pollard and Sag 1987). The type constraints we have met so far can be used to
define a type hierarchy, which for present purposes will be a Boolean lattice. In this
section we present in outline form a prosodic hierarchy that subsequent analyses will
be based on. Example (7) defines the high-level types in the hierarchy.
</bodyText>
<subsectionHeader confidence="0.74886">
Example 7
</subsectionHeader>
<bodyText confidence="0.98601675">
phon utterance v phrase V foot v syl v segment
Each of these types may have further structure. For example, following Clements
(1985:248) we may wish to classify segments in terms of their place and manner of
articulation, using the following appropriateness declaration.
</bodyText>
<page confidence="0.998967">
461
</page>
<table confidence="0.970703333333333">
Computational Linguistics Volume 20, Number 3
Example 8
LARYNGEAL: SPREAD : boolean boolean
CONSTRICTED: boolean
VOICED : boolean
NASAL :
MANNER: CONTINUANT: boolean
STRIDENT: boolean
[
SUPRALARYNGEAL: CORONAL: boolean
PLACE : ANTERIOR: boolean
DISTRIBUTED: boolean
</table>
<subsubsectionHeader confidence="0.735331">
segment
</subsubsectionHeader>
<bodyText confidence="0.98405575">
Suppose now that we wished to use these structures in a constraint for English homor-
ganic nasal assimilation. This phenomenon does not occur across phonological phrase
boundaries and so the constraint will be part of the definition of the type (phonologi-
cal) phrase. Let us assume that a phrase is equivalent to segment*, i.e. a list of segments.
Informally speaking, we would like to impose a negative filter that bars any nasal
whose value for place of articulation differs from that of the stop consonant that im-
mediately follows. Here, we use SL as an abbreviation for SUPRALARYNGEAL, CONT for
CONTINUANT, MN for MANNER, and PL for PLACE.
</bodyText>
<equation confidence="0.776180428571428">
Example 9
MNINASAL :
ISL: [MNICONT : —
[SL : [
• PL : PL :
segment segment
phrase
</equation>
<bodyText confidence="0.999614333333333">
While the abbreviatory conventions in this filter might appear suspicious, it is straight-
forwardly translated into the constraint in (10). This constraint is divided into three
parts. The first simply requires that hna be a subtype of list(segment). The second part
is lifted from (9), ensuring that the first two positions in the list do not violate the
assimilation constraint. The third part propagates the assimilation constraint to the
rest of the list.
</bodyText>
<footnote confidence="0.7037948">
Example 10
hna list(segment) A FIRST ISL : MNINASAL : A REST: hnal
PL:
REST &apos;FIRST ISL : MNICONT : — 1
PL:
</footnote>
<page confidence="0.989872">
462
</page>
<bodyText confidence="0.873616">
Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systems
Standard techniques can now be used to move the negation in (10) inward.&apos; Since
constraints on adjacent list elements generally seem to be more intelligible in the
format exhibited by (9), we shall stick to that notation in the remainder of the paper.
</bodyText>
<subsectionHeader confidence="0.999592">
2.3 Prosodic Constituency
</subsectionHeader>
<bodyText confidence="0.997104">
One standard phonological approach assumes that prosodic constituency is like phrase
structure (Selkirk 1984). For example, one might use a rewrite rule to define a (phono-
logical) phrase as a sequence of feet, and a foot as sequence of syllables:
</bodyText>
<figure confidence="0.871284666666667">
Example 11
a. phrase foot+
b. foot —&gt; syl+
</figure>
<bodyText confidence="0.999425928571429">
Within the framework of HPSG, it would be simple to mimic such constituency by
admitting a feature structure of type phrase whose DTRs (i.e. daughters) are a list of
feature structures of type foot, and so on down the hierarchy. However, there appears
to be no linguistic motivation for building such structure. Rather, we would like to
say that a phrase is just a nonempty list of feet. But a foot is just a list of syllables, and
if we abandon hierarchical structure (e.g. by viewing lists as strings), we seem to be
stuck with the conclusion that phrases are also just lists of syllables. In a sense this is
indeed the conclusion that we want. However, not any list of syllables will constitute a
phrase, and not every phrase will be a foot. That is, although the data structure may be
the same in each case, there will be additional constraints that have to be satisfied. For
example, we might insist that elements at the periphery of phrases are exempt from
certain sandhi phenomena; and similarly, that feet have no more than three syllables,
and only certain combinations of heavy and light syllables are permissible. Thus, we
shall arrive at a scheme like the following, where the C, indicate the extra constraints:8
</bodyText>
<figure confidence="0.455953666666667">
Example 12
a. phrase foot+ A Ci A . • • A Ck
b. foot syl+ A Ci A ... A Cn
This concludes our discussion of string-based phonology. We have tried to show how
a phonological model based on FSAs is compatible with the list notation and type
regime of HPSG. Next we move onto a consideration of morphology and the lexicon.
7 These techniques employ the following equivalences:
: 0.] V -tB 0]
[-(A: T)] V [A:
</figure>
<footnote confidence="0.798137666666667">
Here -.(A:T) indicates that the attribute A is not appropriate for this feature structure.
8 Sproat and Brunson (1987) have also proposed a model in which prosodic constituents are defined as
conjunctions of constraints.
</footnote>
<page confidence="0.995533">
463
</page>
<note confidence="0.425328">
Computational Linguistics Volume 20, Number 3
</note>
<listItem confidence="0.511098">
3. Morphology and the Lexicon
</listItem>
<subsectionHeader confidence="0.997503">
3.1 Linguistic Hierarchy
</subsectionHeader>
<bodyText confidence="0.999738833333333">
The subsumption ordering over types can be used to induce a hierarchy of grammat-
ically well-formed feature structures. This possibility has been exploited in the HPSG
analysis of the lexicon: lexical entries consist of the idiosyncratic information particu-
lar to the entry, together with an indication of the minimal lexical types from which it
inherits. To take an example from Pollard and Sag (1987), the base form of the English
verb like is given in Example 13.
</bodyText>
<equation confidence="0.9833441">
Example 13
PHON : (1 a I, k)
SYNILOCISUBCAT : ([IT [ ]7)
-
[RELN : like]
LIKER :
LIKEE :
SEMICONT :
2
main A base A strict-trans
</equation>
<bodyText confidence="0.998078769230769">
Since main is a subtype of verb, the entry for like will inherit the constraint that its
major class feature is V; by virtue of the type strict-trans, it will inherit the constraint
that the first element in the SUBCAT list is an accusative NP, while the second ele-
ment is a nominative NP; and so on for various other constraints. Figure 1 shows a
small and simplified portion of the lexical hierarchy in which the verb like is a leaf
node.
Along the phonological dimension of signs, lexical entries will have to observe
any morpheme or word level constraints that apply to the language in question. When
words combine as syntactic phrases, they will also have to satisfy all constraints on
well-formed phonological phrases (which is not to say that phonological phrases are
isomorphic with syntactic ones). In the general case, we may well want to treat words
in the lexicon as unsyllabified sequences of segments. It would then follow that, for ex-
ample, the requirement that syllable-initial voiceless obstruents be aspirated in English
</bodyText>
<figure confidence="0.977307">
lexical-sign
verb unsaturated
main base
trans
strict-trans
like
</figure>
<figureCaption confidence="0.995759">
Figure 1
</figureCaption>
<bodyText confidence="0.863624">
A portion of the lexical hierarchy.
</bodyText>
<page confidence="0.997036">
464
</page>
<bodyText confidence="0.937127125">
Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systems
would have to be observed by each syllable in a phrase (which in the limiting case,
might be a single word), rather than lexical entries per se.
In some languages we may require there to be a special kind of interaction between
the lexical and the prosodic hierarchy. For example, Archangeli and Pulleyblank (1989)
discuss the tongue root harmony of Yoruba, which is restricted to nouns. If atr (i.e.
advanced tongue root) was the type of harmonic utterances, then we could express
the necessary constraint thus:
</bodyText>
<equation confidence="0.96559075">
phon A atr
SYNILOCIHEAD : [MAJ : noun]
LEX :
noun
</equation>
<bodyText confidence="0.99320175">
This kind of constraint is known as a morpheme structure constraint, and phonol-
ogists have frequently needed to have recourse to these (Kenstowicz and Kisseberth
1979). Another interaction between prosody and morphology is the phenomenon of
prosodic morphology, an example of which can be found in Section 4.
</bodyText>
<subsectionHeader confidence="0.999982">
3.2 Morphological Complexity
</subsectionHeader>
<bodyText confidence="0.9969405">
Given the syntactic framework of HPSG, it seems tempting to handle morphological
complexity in an analogous manner to syntactic complexity. That is, morphological
heads would be analyzed as functors that subcategorize for arguments of the appro-
priate type, and morphemes would combine in a Word-Grammar scheme. Simplifying
drastically, such an approach would analyze the English third person singular present
suffix -s in the manner shown in (15), assuming that affixes are taken to be heads.
</bodyText>
<equation confidence="0.96157225">
Example 15
[PHON :
SYNSEM1SUBCAT : (verb-stem)
affix
</equation>
<bodyText confidence="0.999246">
By adding appropriately modified versions of the Head Feature Principle, Subcategor-
ization Principle, and linear order statements, such a functor would combine with a
verb stem to yield a tree-structured sign for walks.
</bodyText>
<equation confidence="0.986095166666667">
Example 14
PHON :
Example 16 (verb-stem [PHON : [I (w i 10] [PHON : E Ks)] &gt;1
PHON : affix
DTRS :
verb -
</equation>
<bodyText confidence="0.9911115">
While one may wish to treat derivational morphology in this way (cf. Krieger
and Nerbonne [in press]), a more economical treatment of inflectional morphology
is obtained if we analyze affixes as partially instantiated word forms.&apos; Example (17)
illustrates this for the suffix -s, where 3ps is a subtype of sign.
</bodyText>
<page confidence="0.6869945">
9 See Riehemann (1992) for a detailed working out of this idea for German derivational morphology.
465
</page>
<figure confidence="0.5087055">
Computational Linguistics Volume 20, Number 3
Example 17
PHON :
MORPH: affix-morph STEM: [PHON : (s)]
AFFIX: verb-stem
[PHON : E
suffix
3ps
</figure>
<bodyText confidence="0.998828">
Note that we have added to sign a new attribute MORPH, with a value morph. The
latter has two subtypes, affix-morph and basic-morph, depending on whether the value
contains a stem and affix or just a stem.
</bodyText>
<equation confidence="0.936201">
Example 18
morph = affix-morph V basic-morph
</equation>
<bodyText confidence="0.9981065">
While both of these types will inherit the attribute STEM, affix-morph must also be
defined for the attribute AFFIX:
</bodyText>
<equation confidence="0.91954475">
Example 19
a.
morph [STEM : stem]
b. affix-morph [AFFIX: affix]
Moreover, affix has two subtypes:
Example 20
affix = prefix V suffix
Thus, (17) is a third person singular verb form whose stem is unspecified.
</equation>
<bodyText confidence="0.9994005">
As indicated in Section 1.3, we can take the interpretation of a complex type to
be equivalent to the disjunction of all of its subtypes. Now, suppose that our lexicon
contained only two instances of verb-stems, namely walk and meet. Then (17) would
evaluate to exactly two fully specified word forms, where verb-stem was expanded
to the signs for walk and meet respectively. Example 21 illustrates the first of these
options.
</bodyText>
<equation confidence="0.792192">
•-■
SYNSEM : [CAT: verb]
1
[
PHON : 0 w 31 k)
verb-stem
[PHON : 2 (s)
suffix
affix-morph
Example 21
PHON :
MORPH:
3ps
</equation>
<bodyText confidence="0.2069315">
STEM:
AFFIX:
</bodyText>
<page confidence="0.975499">
466
</page>
<bodyText confidence="0.9632216">
Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systems
Of course, this statement of suffixation would have to be slightly enriched to
allow for the familiar allomorphic alternation -s,--z-Az. The first pair of allomorphs can
be handled by treating the suffix as unspecified for voicing, together with a voicing
assimilation rule similar to the homorganic nasal rule in (9). The third allomorph
would admit an analysis similar to the one we propose for French schwa in Section 5.
A second comment on (21) is that the information about ordering of affixes relative
to the stem should be abstracted into a more general pair of statements (one for prefixes
and one for suffixes) that would apply to all morphologically complex lexical signs
(e.g. of type affixed); this is straightforward to implement:
</bodyText>
<figure confidence="0.991236058823529">
Example 22
a.
affixed
b.
affixed
[
STEMIPHON :
AFFIX: [PHON :
prefix
•-■
STEMIPHON : E
AFFIX:
suffix [PHON :
PHON :
MORPH:
PHON :
MORPH:
</figure>
<bodyText confidence="0.99919925">
Given this constraint, it is now unnecessary to specify the phonology attribute for
feature terms like (21).
Additionally, it is straightforward to prevent multiple copies of the plural suffix
from being attached to a word by ensuring that 3ps and verb-stem are disjoint.
</bodyText>
<subsectionHeader confidence="0.999945">
3.3 Morphophonological Operations
</subsectionHeader>
<bodyText confidence="0.99999">
In and of itself, HPSG imposes no restrictions on the kind of operations that can be
performed in the course of composing morphemes into words, or words into phrases.
As an illustration, consider the data from German verb inflections analyzed by Krieger,
Pirker, and Nerbonne (1993). As they point out, the second person singular present
inflection -st has three different allomorphs, phonologically conditioned by the stem:
</bodyText>
<subsectionHeader confidence="0.923754">
Example 23
</subsectionHeader>
<bodyText confidence="0.996998">
sag+st arbaut+ost mtks+t
&apos;say&apos; &apos;work&apos; &apos;mix&apos;
Although the main thrust of their paper is to show how an FST treatment of this
allomorphy can be incorporated into an HPsG-style morphological analysis, from a
purely formal point of view, the FST is redundant. Since the lexical sign incorporates
the phonologies of both stem and affix, segments can be freely inserted or deleted in
constructing the output phonology. This is exemplified in (24) for arbeitest and mixt
respectively.
</bodyText>
<page confidence="0.994647">
467
</page>
<note confidence="0.403825">
Computational Linguistics Volume 20, Number 3
</note>
<equation confidence="0.866621153846154">
,--, a —
[STEM : m(...ft,d1
SUFFIX : t)
2
PHON :
MORPH:
[PER:
: sg]
SYN1LOCIHEADIAGR :
2
Example 24
a.
2ps
b.
PHON :
MORPH:
SYNILOCIHEADIAGR :
Th-
STEM
[]
: E(... {S,Z,X})
SUFFIX: (s) ,-, DO
NUM: sg
PER: 2
2
2ps
</equation>
<bodyText confidence="0.999735636363636">
That is, we can easily stipulate that a is intercalated in the concatenation of stem and
suffix if the stem ends with a dental stop (i.e either t or d); and that the s of the suffix is
omitted if the stem ends with alveolar or velar fricative. Although an actual analysis
along these lines would presumably be stated as a conditional, depending on the
form of the stem, the point remains that all the information needed for manipulating
the realization of the suffix (including the fact that there is a morpheme boundary)
is already available without resorting to two level rules!&apos; Of course, the question
this raises is whether such operations should be permitted, given that they appear to
violate the spirit of a constraint-based approach. The position we shall adopt in this
paper is that derivations like (24) should in fact be eschewed. That is, we shall adopt
the following restriction:
</bodyText>
<subsectionHeader confidence="0.918828">
Phonological Compositionality:
</subsectionHeader>
<bodyText confidence="0.999558111111111">
The phonology of a complex form can only be produced by either unifying or con-
catenating the phonologies of its parts.
We believe that some general notion of phonological compositionality is method-
ologically desirable, and we assume that Krieger, Pirker, and Nerbonne would adopt
a similar position to ours. The specific formulation of the principle given above is
intended to ensure that information-combining operations at the phonological level
are monotonic, in the sense that all the information in the operands is preserved in
the result. As we have just seen, the constraint-based approach does not guarantee
this without such an additional restriction.
</bodyText>
<sectionHeader confidence="0.894196" genericHeader="method">
4. Sierra Miwok Templatic Morphology
</sectionHeader>
<bodyText confidence="0.886446833333333">
Noncatenative morphology has featured centrally in the empirical motivations for
autosegmental phonology, since McCarthy&apos;s demonstration that the intercalation of
vowels in Arabic consonantal verb roots could be elegantly handled within this frame-
work (McCarthy 1981). This section presents an approach to intercalation that uses key
10 This approach of using restructuring devices in the process of a derivation has been explored in the
context of extended Montague frameworks by Wheeler (1981) and Hoeksema and Janda (1988).
</bodyText>
<page confidence="0.988716">
468
</page>
<bodyText confidence="0.969099666666667">
Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systems
insights from autosegmental phonology. However, they are captured within constraint-
based grammar where the inflectional paradigm is realized as an inheritance hierarchy
of partially instantiated stem forms (cf. Reinhard and Gibbon [1991]). We also show
that autosegmental association of consonants and vowels to a skeleton can be mod-
eled by reentrancy. Rather than classical Arabic, we use the simpler data from Sierra
Miwok that Goldsmith (1990) chose to illustrate the phenomenon of intercalation in
his textbook.
This section is divided into four subsections. In Section 4.1 we present an overview
of the data, and in Section 4.2 we briefly show what a traditional generative analysis
might look like. Our encoding of association by reentrancy is given in Section 4.3,
while Section 4.4 contains our constraint-based analysis of Sierra Miwok stem forms.
</bodyText>
<subsectionHeader confidence="0.986362">
4.1 Descriptive Overview
</subsectionHeader>
<bodyText confidence="0.994801166666667">
As mentioned above, Goldsmith (1990) takes data from Sierra Miwok verb stems to
illustrate morphologically determined alternations in skeletal structure. He discusses
three of the four types of stem, where the division into types depends primarily
on the syllable structure of the basic form, which is the form used for the present
tense. The three types are given the following autosegmental representations by Gold-
smith:
</bodyText>
<figure confidence="0.980588">
Example 25
a. Type I
k c a w
/\
Type II c e
C V
Type III h
C V
</figure>
<bodyText confidence="0.999833166666667">
As shown in (26), each type has forms other than the basic one, depending on the
morphological or grammatical context; these additional forms are called second, third,
and fourth stems.
Although the associations of vowels and consonants exhibited above are taken as
definitional for the three stem Types, from the data in (26) it appears that the distinction
is only relevant to so-called Basic stem forms.
</bodyText>
<equation confidence="0.549248">
k u
CC V
m
</equation>
<page confidence="0.997849">
469
</page>
<table confidence="0.938820722222222">
Computational Linguistics Second stem Third stem Volume 20, Number 3
Example 26 Fourth stem
Gloss Basic stem
Type I kicaaw kicaww kiccaw kicwa
bleed
jump tuyaau tuyaDD tuyyaD tuyu a
take patiit patitt pattit patti
roll huteel hutell huttel hutle
Type II celku celuld( celluk celku
quit
go home wo?lu wo?ull wo??ul wo?lu
catch up with nakpa nakapp nakkap nakpa
spear wimki wimikk wimmik wimki
Type III hamme hamen hamme? ham?e
bury
dive ?uppi ?upin ?uppi?
speak liwwa liwan liwwa? liw?a
sing milli mili?? milli? mil?i
</table>
<subsectionHeader confidence="0.996914">
4.2 Segmental Analysis
</subsectionHeader>
<bodyText confidence="0.9995745">
Goldsmith (1990) has shown just how complex a traditional segmental account of
Sierra Miwok would have to be, given the assumption that all of the stem forms are
derived by rule from a single underlying string of segments (e.g. that kicaww, kiccaw
and kicwa are all derived from kicaaw). Here, we simplify Goldsmith&apos;s analysis so that
it just works for Type I stems. The left-hand column of (27) contains four rules, and
these are restricted to the different forms according to the second column.
</bodyText>
<table confidence="0.996884571428571">
Example 27 Form Second Third Fourth
Rules kicaaw kicaaw kicaaw
vi-40/C—ViC] all kicaw kicaw kicaw
C,-&gt;C,CACV—V 2 kicaww — —
VC]-CV 3 — kiccaw —
4 — — kicwa
kicaww kiccaw kicwa
</table>
<bodyText confidence="0.999862625">
Thus, the first rule requires that a vowel V, is deleted if it occurs after a consonant
and immediately before an identical vowel V, that in turn is followed by a stem-final
consonant. Goldsmith soundly rejects this style of analysis in favor of an autosegmental
one:
This analysis, with all its morphologically governed phonological rules,
arbitrary rule ordering, and, frankly, its mind-boggling inelegance,
ironically misses the most basic point of the formation of the past
tense in Sierra Miwok. As we have informally noted, all the second
</bodyText>
<page confidence="0.956623">
470
</page>
<note confidence="0.436522">
Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systems
</note>
<bodyText confidence="0.999646">
stem forms are of the shape CVCVCC, with the last consonant a gem-
inate, and the rules that we have hypothetically posited so far all
endeavor to achieve that end without ever directly acknowledging it.
(Goldsmith 1990:87)
</bodyText>
<subsectionHeader confidence="0.916792">
4.3 Association
</subsectionHeader>
<bodyText confidence="0.998716222222222">
We shall not attempt here to give a general encoding of association, although the
technique used in Sections 5.4 could be applied to achieve this end. Moreover, like
Goldsmith we shall ignore the role of syllable structure in the data, though it clearly
does play a role. Instead, we shall confine our attention to the manner in which skeletal
slots are linked to the consonant and vowel melodies. Consider again the skeletal
structure of Type I verb stems shown in (25a). As Goldsmith (1990) points out, there
is a closely related representation that differs only in that the CV information is split
across two tiers (and which allows a much more elegant account of metathesis and
gemination):
</bodyText>
<equation confidence="0.743387">
Example 28
consonantal melody k c w
skeleton X X X X X X
</equation>
<table confidence="0.83346075">
\/
vowel melody i a
The diagram in Example 28 can be translated into the following feature term:
Example 29
phon CON: (E. k c 0 w)
VOW: 2 i a)
SKEL : ( 3
1 1 .‘1 4 D
U
(
That is, since association in (28) consists of slot-filling (rather than the more general
temporal interpretation), it can be adequately encoded by coindexing.
</table>
<subsectionHeader confidence="0.757229">
4.4 Basic Stem Forms
</subsectionHeader>
<bodyText confidence="0.998359333333333">
The analysis starts from the assumption that the Sierra Miwok lexicon will contain
minimally redundant entries for the three types of verb root. Let us consider the root
corresponding to the basic stem form kicaaw. We take the unpredictable information
to be the consonantal and vowel melodies, the valency, the semantics, and the fact it
is a Type I verb stem. This is stated as (30), together with the declaration that lex-bleed
is a subtype of v-root-I.
</bodyText>
<page confidence="0.989015">
471
</page>
<figure confidence="0.935682181818182">
Computational Linguistics Volume 20, Number 3
Example 30
_
PHON :
CON: (k c w)1
VOW: (i a)
phon
lex-bleed
_
SYNSEM : synsem [SUBCAT : (NP)
SEM : bleed
</figure>
<bodyText confidence="0.99723">
Notice that we have said nothing about how the melodies are anchored to a
skeleton—this will be a task for the morphology. Additionally, this entry will inherit
various properties by virtue of its type v-root-I. The three types of verb root share at
least one important property, namely that they are all verbs. This is expressed in the
next two declarations:
</bodyText>
<equation confidence="0.854457">
Example 31
a. v-root = v-root-I V v-root-II V v-root-III
v-root [SYNSEM1CAT : verb]
</equation>
<bodyText confidence="0.99983075">
We shall also assume, for generality, that every v-root is a root, and that every root is
a morph. Anticipating the rest of this section, we show how all the postulated types
are related in Figure 2. The next step is to show how a v-root-I like (30) undergoes
morphological modification to become a basic verb stem; that is, a form with skeletal
structure. Our encoding of the morphology will follow the lines briefly sketched in
Section 3.2.
We begin by stating types that encode the patterns of skeletal anchoring associated
with the three types of basic stem.
</bodyText>
<figure confidence="0.8715458">
Example 32
phon template-I V template-II V template-III
T
phrase / \ \
word stem morph bas-morph-dtrs basic-I basic-III
//\affixed root aff-morph-dtrs basic-II
v-root-I
v-root-II
v-root-III
basic affix
</figure>
<figureCaption confidence="0.888365">
Figure 2
</figureCaption>
<figure confidence="0.81906725">
Sierra Miwok type hierarchy.
/ \
v-root morph-dtrs
sign
</figure>
<page confidence="0.974158">
472
</page>
<note confidence="0.447561">
Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systems
</note>
<bodyText confidence="0.979223333333333">
The appropriateness constraints on these types are given in (33). As an aid to
readability, the numerical tags are supplemented with a C or a V to indicate the type
of value involved.
</bodyText>
<table confidence="0.983883181818182">
Example 33
template-I CON: 3 C TC)
VOW: 2 V)
SKEL : EIC V DC UV TV EC)
CON: (DC 3 5
VOW (TV TV)
template-II SKEL : ( 1 2 V EIC E1V 11C)
ICON: (EJC OC)
VOW : (Tv Er)
SKEL : Er -TV E Ec 37 )
template-III
</table>
<bodyText confidence="0.988708666666667">
Each of these types specializes the constraints on the type phon, and each can be unified
with the phon value earlier assigned to the root form of kicaaw in (30). In particular,
the conjunction of constraints given in (34) evaluates to (29), repeated here:
</bodyText>
<equation confidence="0.981681272727273">
Example 34
[CON : (k c w)]
VOW : (i a) A template-I
phon
Example 29
[
CON: (ik3c5w)
—
VOW: 0 i
SKEL : (
phon
</equation>
<bodyText confidence="0.99973375">
However, we also need to specify the dependency between the three types of verb
root, and the corresponding phonological exponents that determine the appropriate
basic stem forms (cf. Anderson (19921). As a first attempt to express this, let us say
that stem can be either basic or affixed:
</bodyText>
<figure confidence="0.373971272727273">
Example 35
stem affixed V basic
Type declaration (35) ensures that basic will inherit from stem the following constraint,
namely that its SYNSEM value is to be unified with its MORPH&apos;s ROOT&apos;s SYNSEM value:
Example 36 -]
ISYNSEM :
MORPHIROOT1SYNSEM :
stern
a)
2 3 4 4
5 &gt;1
</figure>
<page confidence="0.782326">
473
</page>
<table confidence="0.991224875">
Computational Linguistics specify the Volume 20, Number 3
We could now disjunctively phon A template-I following three sets of constraints on basic:
Example 37 PHON: ROOT: v-root-d
basic MORPH: 1
PHON: phon A template-II
basic MORPH: ROOT: v-root-II
[
PHON: phon A template-III
</table>
<equation confidence="0.857269">
[
MORPH : ROOT : v-root-IIII
</equation>
<bodyText confidence="0.9998268">
Although the example in question does not dramatize the fact, this manner of en-
coding morphological dependency is potentially very redundant, since all the common
constraints on basic have to be repeated each time.&apos; In this particular case, however,
it is easy to locate the dependency in the phon value of the three subtypes of v-root, as
follows:
</bodyText>
<equation confidence="0.8611574">
Example 38
PHON: template-I]
v-root-I
v-root-II [PHON : template-II]
v-root-III [PHON : template-III]
</equation>
<bodyText confidence="0.925842">
We then impose the following constraint on basic:
</bodyText>
<table confidence="0.994790666666667">
Example 39
PHON:
MORPH I ROOT :
basic
[PHON :
v-root
</table>
<bodyText confidence="0.702521">
By iterating through each of the subtypes of v-root, we can infer the appropriate
value of PHON within MORPH&apos;s ROOT, and hence infer the value of PHON at the top level
of the feature term. Example 40 illustrates the result of specializing the type v-root to
lex-bleed:
11 In an attempt to find a general solution to this problem in the context of German verb morphology,
Krieger and Nerbonne (in press) adopt the device of &apos;distributed disjunction&apos; to iteratively associate
morphosyntactic features in one list with their corresponding phonological exponents in another list.
basic
</bodyText>
<page confidence="0.816797">
474
</page>
<figure confidence="0.631360947368421">
Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systems
Example 40
PHON :
CON:
VOW:
SKEL :
phon
k c w)
i a a)
1:1
&gt;1
SYNSEM : E CAT: verb
SUBCAT : (NP)
SEM : bleed
synsem
MORPH: [ROOT: [PHON :
template-morph SYNSEM :
v-root-I
basic -
</figure>
<bodyText confidence="0.994388">
Exactly the same mechanisms will produce the basic stem for the other two types of
verb root. For an account of the other alternations presented in Goldsmith&apos;s paradigm,
and for some discussion of how lexical and surface forms determine each other, see
Klein (1993).
We have just seen an application of constraint-based phonology to Sierra Miwok.
In order to illustrate some of the other expressive capabilities of the approach, we now
turn to the phenomenon of French schwa.
</bodyText>
<sectionHeader confidence="0.961051" genericHeader="method">
5. French Schwa
</sectionHeader>
<bodyText confidence="0.9999076">
Many phonological alternations can be shown to depend on properties of prosodic
structure. In this section we show how the French phenomenon of schwa-zero al-
ternation arises out of the interplay of various syllable structure requirements. This is
done by introducing a system of prosodic types for syllables and a special type declar-
ation showing how a string of segments can be &apos;parsed&apos; into syllables. The standard
(but nonmonotonic) ONSET MAXIMIZATION PRINCIPLE is reinterpreted in the system, as
well as the exceptions to this principle due to a class of words known as h-aspire
words. We also show how a certain kind of disjunction can be used to deal with free
variation. As we shall see, some linguistic analyses are more amenable to a declarative
encoding than others. In order to demonstrate this, it will be necessary to go into some
detail concerning the linguistic data.
This section is divided into four subsections. In Section 5.1 we present a descriptive
overview of the data,&amp;quot; and in Section 5.2 we sketch a traditional generative analysis. A
more recent, nonlinear analysis appears in Section 5.3 while our own, constraint-based
version is presented in Section 5.4.
</bodyText>
<subsectionHeader confidence="0.956382">
5.1 Descriptive Overview
</subsectionHeader>
<bodyText confidence="0.990060833333333">
Unlike schwa in English, the French schwa (or mute e) is a full vowel, usually realized
as the low-mid front rounded vowel ce (and sometimes as the high-mid front rounded
vowel 0 in certain predictable environments). Its distinctive characteristic is that under
12 The data is from standard French taken from (cited) literature, although in some instances we have
found speakers with different acceptability judgments than reported here. See Morin (1987) for a
discussion of some problems with the treatment of French data in the literature.
</bodyText>
<page confidence="0.998102">
475
</page>
<note confidence="0.751947">
Computational Linguistics Volume 20, Number 3
</note>
<bodyText confidence="0.999891363636364">
certain conditions, it fails to be realized phonetically.&amp;quot; From now on we shall use the
term &apos;schwa&apos; to refer to the vowel with this characteristic, rather than to the segment a.
Although schwa is associated with orthographic e, not all es will concern us here.
For example, the orthographic e of samedi [sam.dil &apos;Saturday&apos; can be taken to indicate
that the previous vowel should not be nasalized, while the final e of petite [poe.tit]
indicates that the final t should be pronounced. In morphology, orthographic e marks
feminine gender, first-conjugation verbs, and subjunctive mood.
Instead, we shall be concerned with the pattern of realization and non-realization
exhibited by schwa—a pattern that we interpret as grounded in the alternation of two
allophones of schwa: ce and 0 (zero). This alternation is manifested in forms like (41),14
where the dots indicate syllable boundaries.
</bodyText>
<figure confidence="0.364844666666667">
Example 41
a. six melons [si.mce.15] [sim.15]
b. sept melons [sEt.moe.15], Isetm15]
</figure>
<bodyText confidence="0.866171590909091">
Observe that while six melons can be pronounced with or without the schwa,
sept melons requires the schwa in order to break up the tml cluster that would oth-
erwise be formed. Unfortunately, the conditions on the distribution of schwa are not
as simple (and purely phonological) as this example implies. As we shall see, schwa
alternation in French is governed by an interesting mixture of lexical and prosodic
constraints.
In the remainder of this section, we dispel the initial hypothesis that arises from
(41), namely that schwa alternation is to be treated as a general epenthesis process.&amp;quot;
Consider the following data (Morin 1978:111).
Example 42
Cluster Schwa Possible/Obligatory Schwa Impossible
rdr bordereau [bar.dceso] perdrix [pEr.dri]
rf derechef [dce.roe.fcf] torchon [t3r.15]
skl squelette [skce.lEt] sclerose [skle.roz]
ps depecer [de.pce.se] eclipser fek.lip.sel
The table in (42) gives data for the clusters Erdr], [rf], [skl] and [psi. In the first column
of data, the ce is possible or obligatory, while in the second column, it is absent. Thus,
we see that the apperance of ce cannot be predicted on phonotactic grounds alone.
Consequently, we shall assume that schwa must be encoded in lexical representations.
Note that it is certainly not the case that a lexical schwa will be posited wherever
there is an orthographic e. Consider the data in (43), where these orthographic es are
underlined.
</bodyText>
<footnote confidence="0.690828">
13 The data used in this section is drawn primarily from the careful descriptive work of Morin (1978) and
Tranel (1987b). The particular approach to French schwa described in the following paragraphs most
closely resembles the analysis of Tranel (1987a).
14 We shall not be concerned with another cer-0 alternation known as elision. This is a phonologically
conditioned allomorphy involving alternations such as for example, le chat llce.f al, l&apos;ami [1a.mi].
15 This epenthesis hypothesis was advanced by Martinet (1972).
</footnote>
<page confidence="0.997554">
476
</page>
<figure confidence="0.9857181875">
Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systems
Example 43
Orthography
With Schwa
Without Schwa
bordereau
fais-le
six melons
pelleterie
[bor.dce.ro]
[f€.101
[si.mce.15]
-^
-
[sim.15]
[pel.tri]
</figure>
<bodyText confidence="0.996960375">
In a purely synchronic analysis there is no basis for discussing an alternating vowel
for bordereau, fais-le and pelleterie. Many orthographic es that are not in the first syllable
of a word come into this category.
Accordingly, we begin our analysis with three background assumptions: the alter-
nating schwa is (i) prosodically conditioned, (ii) lexically conditioned, and (iii) not in
direct correspondence with orthographic e. Next we present a generative analysis of
schwa due to Dell, followed by an autosegmental analysis due to Tranel. We conclude
with our own, syllable-based analysis.
</bodyText>
<subsectionHeader confidence="0.998005">
5.2 A Traditional Generative Analysis
</subsectionHeader>
<bodyText confidence="0.999990214285714">
The traditional approach to vowel-zero alternations is to employ either a rule of
epenthesis or a deletion rule. Dell discusses the case of the word secoue, whose pro-
nunciation is either [sku] or [sceku], in a way that parallels (41).
In order to account for alternations such as that between iskul and
[sceku] there are two possibilities: the first consists of positing the
underlying representation /sku/ where no vowel appears between
/s/ and /k/, and to assume that there exists a phonological rule of
epenthesis that inserts a vowel ce between two consonants at the be-
ginning of a word when the preceding word ends in a consonant. ...
The second possibility is preferable: the vowel [cel that appears in
Jacques secoue is the realisation of an underlying vowel /a/ which can
be deleted in certain cases. We shall posit the vcEi rule, which deletes
any /a/ preceded by a single word-initial consonant when the pre-
ceding word ends in a vowel.
</bodyText>
<equation confidence="0.9049455">
VCEi: a--4 0 / V #1 C —
(Dell, 1980:1610
</equation>
<bodyText confidence="0.999979230769231">
Suppose we were to begin our analysis by asking the question: how are we to
express the generalization about schwa expressed in the above rule? Since our declar-
ative, monostratal framework does not admit deletion rules, we would have to give
up. As we shall see below, however, we begin with a different question: how are we to
express the observation about the distribution of schwa that Dell encodes in the above
rule?
There is another good reason for taking this line. As it happens, there is an em-
pirical problem with the above rule, which Dell addresses by admitting a potentially
large number of lexical exceptions to the rule and by making ad hoc stipulations (Dell
1980). Additionally, adding diacritics to lexical entries to indicate which rules they
undergo and employing rules that count # boundaries would seem to complicate a
grammar formalism unnecessarily. As we saw above for the discussion of the word
bordereau, in the approach taken here we have the choice between positing a stable
</bodyText>
<page confidence="0.996099">
477
</page>
<note confidence="0.751014">
Computational Linguistics Volume 20, Number 3
</note>
<bodyText confidence="0.999973527777778">
ce or one that alternates with zero (i.e. a schwa) in the lexicon, whereas Dell must
mark lexical items to indicate which rules they must not undergo. There is also some
evidence for a distinction between the phonetic identity of the ce allophone of schwa
and the phonetic identity of a nonalternating lexical ce in some varieties of French,
requiring that the two be distinguished phonologically (Morin 1978).
Thus, the fact that Dell&apos;s analysis involves deletion does not provide a signifi-
cant stumbling block to our approach. However, Dell employs another procedural
device, namely rule ordering, in the application of the rule. In discussing the phrase
vous me le dites [vu.m(ce).1(ce).dit], in which either schwa (but not both) may be omitted,
Dell writes:
vcEi begins on the left and first deletes the schwa of me, producing
/vu#m#1a#dit/. But vcEi cannot operate again and delete the schwa
of le, for, although this schwa was subject to the rule in the original
representation, it no longer is once the schwa of me has been dropped.
In other words, the first application of vcEi creates new conditions
that prevent it from operating again in the following syllable (Dell
1980:228).
Again, we are not interested in encoding Dell&apos;s particular generalization, and in
fact we are unable to. Rather, it is necessary to look at the underlying observation
about the distribution of schwa. The observation is that schwa does not appear as its
zero allophone in consecutive syllables. This observation is problematic for us, in that
it refers to two levels of representation, an underlying (or lexical) level involving a
schwa segment, and a surface level involving a zero allophone. We cannot formulate
this observation monostratally. However, we can come up with a different observation,
namely that the vowel is never omitted if the omission results in unacceptable syllable
structure. In the case of Dell&apos;s example, vous me le dites, if both schwas are omitted the
result is a [vml] cluster, which cannot be broken up into a valid coda-onset sequence.
This new observation makes a different empirical prediction, namely that schwa can
be omitted in consecutive syllables just in case the result is syllabifiable. As we shall
see below in (51), this prediction is actually borne out.
Before proceeding with our own analysis, we present an overview of an autoseg-
mental analysis of French schwa due to Tranel. This analysis is interesting because
it demonstrates the oft-repeated phenomenon of enriched representations leading to
dramatically simplified rule systems. Given the heavy restriction on rules in a mono-
stratal framework, it will be more natural to take Tranel&apos;s (rather than Dell&apos;s) analysis
as our starting point.
</bodyText>
<subsectionHeader confidence="0.989826">
5.3 Tranel&apos;s Analysis
</subsectionHeader>
<bodyText confidence="0.9997174">
Tranel (1987a) provides an insightful analysis of French schwa cast in the framework of
autosegmental phonology. In this section we give an overview of this analysis. In the
following section we shall endeavour to provide an empirically equivalent analysis.
Tranel adopts a CV skeleton tier and a segmental tier. Schwa is represented as an
unlinked vowel, as shown in the following representation for melons.
</bodyText>
<footnote confidence="0.329673">
Example 44
CV
mce 1 5
</footnote>
<page confidence="0.991897">
478
</page>
<bodyText confidence="0.8736606">
Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systems
On top of this two-tiered structure, Tranel proposes a level of hierarchical organ-
ization for representing syllable structure. Tranel adopts the two syllable formation
rules given in (45). A third (unstated) rule is assumed to incorporate unsyllabified
consonants into coda position.
</bodyText>
<figure confidence="0.95189275">
Example 45
a. Basic syllable formation b. Schwa-syllable formation
A A
OR OR
I 1 1 1
C V —+ C V C —CV
1 1 1
[F] a [F] a
</figure>
<bodyText confidence="0.9427998">
Note that (45a) does not apply to the mce sequence in (44), as the schwa is not linked
to a V node as required on the left-hand side of rule (45a). (Tranel later adopts a
refinement to (45a), preventing it from applying if the V is the first vowel of an h-aspire
morpheme.) For the phrases six melons and sept melons, the basic syllable formation rule
builds the following structures.
</bodyText>
<equation confidence="0.686986857142857">
Example 46
A A )7\ A
OR OR OR OR
II II II II
C V C C V C VC C CV
I 1 1 1 1 1 1 1 1 1 1
s i m ce 1 3 s E tmce 1 3
</equation>
<bodyText confidence="0.99921">
The remaining consonants must either be syllabified leftward into an unsaturated
coda or remain unsyllabified and rescued by the schwa syllable formation rule. For
six melons, both options are possible, as illustrated below. Note that the unlinked ce is
assumed to be phonetically uninterpreted.
</bodyText>
<equation confidence="0.47087975">
Example 47
AA A A A
OR OR OR OR OR
II\ II IIII!!
C V C CV CVC V CV
III II IIIIII
s i m ce 1 5 s imce 1 5
This gives us the two options, fsim.151 and [si.mce.15], according with the observation
</equation>
<page confidence="0.997165">
479
</page>
<note confidence="0.750351">
Computational Linguistics Volume 20, Number 3
</note>
<bodyText confidence="0.99044325">
in (41). For sept melons, however, there is just the one option. The t must be syllabified
into the preceding coda, and the m requires the presence of schwa, and so we have
[set.mce.151. Further examples of this particular kind of schwa alternation are given
below (Tranel 1987b:91).
</bodyText>
<figure confidence="0.882778">
Example 48
Schwa Required
Schwa Optional
</figure>
<bodyText confidence="0.83420848">
de qui parlez-vous? [dcekiparlevul
te casse pas la tete [tcekaspulatEt]
debout [dcebu]
depuis quatre ans [dceptiikatral
dedans [dcedd]
je joue 13ce3u1
le lait [lcelc I
ce salon Iscesalol
vous parlez de qui? Ivuparled(ce)kil
ne te casse pas la tete [ncet(ce)kaspalatet]
il est debout [ilEci(ce)bul
c&apos;est depuis quatre ans Ised(ce)pgikatral
là-dedans [lad(ce)dd]
mais je joue [m3(ce)3u1
dans le lait
dans ce salon Eclas(ce)sali51
So far, we have seen the case where the leftward syllabification of a consonant
licenses the omission of schwa. Now we turn to a similar case, but where the consonant
syllabifies rightward into a following onset provided that the resulting onset cluster
is permitted. The data in (49) are from Tranel (1987b:92).
Example 49 Isku.pa.la.tEt1-1sce.ku.pa.la.tet1 &apos;don&apos;t shake your head&apos;
secoue pas la tete [f Pds.Pcd—[3ce.Pds-Pal &apos;I don&apos;t think so&apos;
je pense pas [zbo.a.r18)—Isce.b6.a.rjel &apos;this good-for-nothing&apos;
ce bon a rien
Tranel gives two additional syllable formation rules, shown in (50).
</bodyText>
<equation confidence="0.759579">
Example 50
a. Onset accretion b. Onset accretion across schwa
0 0 0 0
I /\ I /\
C --, C C C C _, C c
I I I I I I
[Fl IGI [F] [G] [F] ce [G1 [F] ce [Cl
Restriction: Restriction:
</equation>
<bodyText confidence="0.990913">
must create a valid onset [F] must be word-initial
Rule (50a) incorporates as many consonants as possible into an onset so long as the
onset conforms to the phonotactic constraints of the language. Rule (50b), of most
interest here, allows for a consonant to be incorporated into a following onset even if
there is an intervening schwa, provided that the consonant is word-initial (and that
the resulting onset is allowable). The intervening schwa remains unpronounced. Rule
(50b), which is optional, correctly captures the alternations displayed in (49). This rule
is restricted to apply word-initially &amp;quot;so as to avoid the generation of word-internal
triliteral consonant clusters from underlying /CCaC/ sequences (compare marguerite
</bodyText>
<page confidence="0.981545">
480
</page>
<note confidence="0.532667">
Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systems
</note>
<bodyText confidence="0.9988716">
/marg@rit/ [marg@rit] Imargrit] and margrave /margrav/ [margrav] Imargoravp&amp;quot;
(Tranel 1987a:852). Thus, although many CCC sequences are acceptable phonologically,
they are not permitted if a schwa is available to break up the cluster.
We also note that Tranel&apos;s analysis (Tranel 1987a) gives the correct result for cases
of deletion of schwa in consecutive syllables. Consider the following data.
</bodyText>
<subsectionHeader confidence="0.57754">
Example 51
</subsectionHeader>
<bodyText confidence="0.812743857142857">
a. on ne se moque pas rOn.smok.pa] (Valdman 1976:120)
b. sur le chemin [syl.fmN (Morin 1978:82)
For both of these cases we observe an &amp;quot;underlying&amp;quot; C1ceC2ce pattern, but where both
ces are omitted and where C1 syllabifies into the preceding coda and C2 syllabifies
into the following onset.
To conclude, we can summarize the empirical content of Tranel&apos;s analysis as
follows:
</bodyText>
<listItem confidence="0.889834">
(a) Every consonant must be syllabified.
(b) Schwa must be realized if it provides the syllable nucleus for an
immediately preceding consonant that:
(i) cannot be syllabified into a coda, and
(ii) cannot form a permissible (word) onset with an immediately
following consonant.
</listItem>
<bodyText confidence="0.9999298">
Naturally, this statement is not the last word on French schwa and there may be
ways in which it needs to be revised, such as for the treatment of word-final schwas
and thematic schwas (Tranel 1987a:855ff). However, since our purpose is primarily to
illustrate the workings of the theoretical model, we shall take the above statement as
a well-defined starting point on which to base the following analysis.
</bodyText>
<subsectionHeader confidence="0.999878">
5.4 A Constraint-Based Analysis
</subsectionHeader>
<bodyText confidence="0.999972153846154">
Given our formal semantics for the autosegmental notation, it would be a relatively
straightforward matter to implement Tranel&apos;s analysis directly, especially since the
rules only involve the building of structure, and there is no use of destructive processes.
Tranel&apos;s analysis is fully declarative.
However, as it happens, there is no need for us to adopt the rich representation
Tranel employs. We can simulate his analysis using a single tier (rather than two) while
retaining a representation of syllable structure. Observe that the use of the CV tier and
the melody tier was motivated solely by the need to have a floating autosegment, the
ce. It is equivalent to collapse these two tiers, using the alternation ce-0 in place of the
floating ce. This style of approach to zero alternations, which dates back to Bloomfield
(1926), will employ the parenthesis notation for optional items that was defined in
Section 2.1. We follow Tranel in representing syllable structure and we shall do this
using the notation shown in (52).16
</bodyText>
<footnote confidence="0.648804">
16 Our analysis is not crucially tied to this particular version of syllable structure, which is most closely
related to the proposals of Kahn (1976) and Clements and Keyser (1983).
</footnote>
<page confidence="0.996411">
481
</page>
<figure confidence="0.945535">
Computational Linguistics Volume 20, Number 3
Example 52
ONS: onset
NUC: nucleus
CODA: coda
syl
</figure>
<bodyText confidence="0.995641">
An independent tier that represents syllable structure will be encoded as a se-
quence of such syllables, where the segmental constituents of the syllable structure
are coindexed with a separate segmental tier, as defined in (53). Note that the indices
in (53) range over lists that may be empty in the case of onsets and codas, and that
the type phrase denotes phonological phrases.
</bodyText>
<figure confidence="0.966564055555556">
Example 53
a.
SYLS : (
syl
ONS: [d
NUC:
CODA:
[SYLS :
SEGS:
phrase
5
b.
SEGS:
phrase
[SYLS :
SEGS :
phrase
3
</figure>
<bodyText confidence="0.999648888888889">
The notation of (53) states that in order for something to be a well-formed phrase,
its sequence of segments must be parsed into a sequence of well-formed syllables. In
more familiar terms, one could paraphrase (53) as stating that the domain of syllabi-
fication in French is the phrase.
As a simple illustration of the approach, consider again the word melons. The pro-
posed lexical representation for the phonology attribute of this word is
[SEGS: (m (ce) 1 3)1. When we insist that any phrase containing this word must con-
sist of a sequence of well-formed syllables, we can observe the following pattern of
behavior for six melons.
</bodyText>
<figure confidence="0.8139126">
Example 54
a.
phrase
b.
phrase
</figure>
<bodyText confidence="0.823187">
Observe in the above example that the syllabic position of m is variable. In Exam-
ple 54a m is in an onset while in 54b it is in a coda. Therefore, it is inappropriate to
</bodyText>
<figure confidence="0.978562735294117">
SYLS :
SEGS:
SYLS :
ONNUSC (s)
(i)
CODA: (m)
syl
SEGS : (s i m 1 5)
ONNUS: (s
C: (i
CODA:
syl syl
(s i m ce 1 5)
[ONS : (1) )
NUC: (5)
CODA:
syl
ONS : (m) ONS: (1) )
NUC: (CH IUC : (5)
CODA: 0 CODA:
syl
482
Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systems
coaa
internal-coda
((cons))
onset
internal-onset
(obs, liq)
((cons), (glide))
(P. n)
(obs, son)
(s, stop, liq)
cons, cons)
</figure>
<figureCaption confidence="0.905657">
Figure 3
</figureCaption>
<bodyText confidence="0.9768384">
Parts of French type hierarchy.
insist that the syllabic affiliation of segments is determined lexically. Rather, we have
opted for the prosodic type phrase, insisting that anything of this type consists of one
or more well-formed syllables (cf. Example 11).
Now consider the case of the phrase sept melons. This is similar to the situation in
(54), except that we must find a way of ruling out the tml cluster as a valid coda-onset
sequence. We are not aware of any exhaustive study of possible French consonant clus-
ters, although one can find discussions of particular clusters (e.g., Tranel 1987b:95ffl
shows that CLj onset clusters are not tolerated). Consequently, the two hierarchies in
Figure 3 are necessarily preliminary, and are made more for the sake of being explicit
than for their precise content. Note that parentheses indicate optionality, so, for ex-
ample, both onsets and codas are allowed to be null. Additional stipulations will be
necessary to ensure that an intervocalic consonant is syllabified with the material to
its right. We can do this by preventing an onsetless syllable from following a closed
syllable, with the type onset-max-1.
</bodyText>
<figure confidence="0.456173857142857">
Example 55
onset-max-1 sY1
... CODA : nelistl [ONS : elist]...
[
-_7•. —,
Now consider again the phrase six melons. The syllabification Isi.mce1.51 would
be represented as follows:
Example 56
( [ONS : (s)1 NUC
((cV)
ONS : elist
NUC: [NUC : (5) 12
syl CODA: nebst(1) syl
syl
</figure>
<bodyText confidence="0.955931">
Observe that this list of syllables contains a violation of (55), so [si.mce1.51 is ruled
out. Now that we have considered vowel-consonant-vowel (VCV) sequences, we shall
move on to more complex intervocalic consonant clusters.
Although the constraints in Figure 3 produce the desired result for VLLV clus-
ters (L=liquid), by assigning each liquid to a separate syllable (Tranel 1987b), there
is still ambiguity with VOLV clusters (0=obstruent), which are syllabified as V.OLV
according to Tranel. We can deal with this and similar ambiguities by further refining
</bodyText>
<figure confidence="0.503767666666667">
(
phrase
syl
</figure>
<page confidence="0.978371">
483
</page>
<note confidence="0.747764">
Computational Linguistics Volume 20, Number 3
</note>
<bodyText confidence="0.871855">
the classification of syllables and imposing suitable constraints on syllable sequences.
Here is one way of doing this, following the same pattern that we saw in (55).
</bodyText>
<table confidence="0.90940575">
Example 57 )
onset-max-2 [CODA: ( - • • obs • • •)] [ONS: —, (- - - obs • • •)]...
syl syl
phrase
</table>
<bodyText confidence="0.999380222222222">
This constraint states that it is not permissible to have an obstruent in a syllable
coda if the following onse,t lacks an obstruent. Equivalently, we could say that if a
syllable coda contains an obstruent then the following onset must also contain an
obstruent. To see why these constraints are relevant to schwa, consider the case of
demanderions, (also discussed by Tranel [1987b]). The constraints in Figure 3 rule out
*[dce.mildrjo], since the underlined onset cluster is too complex. The constraint in (57)
rules out *[dce.mtid.rj61, where the obstruent d is assigned to the preceding syllable to
leave an rj onset. The remaining two possible pronunciations are [dce.m(l.dce.rjO] and
[dce.md.dri.j.61, as required. (Note that the ions suffix has the two forms, [jO] and [ijO].)
Now let us consider the case of h-aspire words. These vowel-initial words do
not tolerate a preceding consonant being syllabified into the word-initial onset. What
happens to the V.CV and V.OLV constraints when the second vowel is in the first
syllable of an h-aspire word, as we find in sept haches [set.af],*[satafl and quatre haches
[katr. Ikat.ran, Ika.traft? Here, it would appear that Tranel&apos;s analysis breaks
down. Our conjecture is that the constraints in (55) and (57) should only apply when
the second syllable is not an h-aspire syllable. So we need to introduce a further
distinction in syllable types, introducing ha-syl for h-aspire syllables and nha-syl for
the rest.
</bodyText>
<equation confidence="0.7829924">
Example 58
syl = ha-syl V nha-syl
Now ha-syl is defined as follows:
Example 59
ha-syl [ONSET : elist]
</equation>
<bodyText confidence="0.9993525">
Accordingly, the constraints (55) and (57) are refined, so that the second syllable
is of the type nha-syl. The revised constraints are given in (60).
</bodyText>
<subsectionHeader confidence="0.842783">
Example 60
</subsectionHeader>
<bodyText confidence="0.895114857142857">
a. onset-max-1&apos; [CODA : nelist] [ONS : dist] ...)
phrase( syl nha-syl
b. onset-max-2&apos; phrase( [CODA: (• • • obs -)] [ONS: (- • • obs, • • •)] .
syl nha-syl
Now, h-aspire words will be lexically specified as having an initial ha-syl. How-
ever, we must not specify any more syllable structure than is absolutely necessary.
Example 61 displays the required constraint for the word haut.
</bodyText>
<page confidence="0.99702">
484
</page>
<bodyText confidence="0.554898">
Steven Bird and Ewan Klein
</bodyText>
<equation confidence="0.941635454545455">
Example 61
PHON :
phon
SYNSEMICAT : noun
[SYLS :
SEGS:
[NUC : (
(ha-syl
(11 o&gt;
lexical-sign
Phonological Analysis in Typed Feature Systems
</equation>
<bodyText confidence="0.99909225">
So although syllabification operates at the phrase level rather than the morpheme
level (see Example 53), we are still able to impose lexically conditioned constraints on
syllable structure directly.
It remains to be shown how this treatment of h-aspire bears on schwa. Fortunately,
Tranel (1987b:94) has provided the example we need. Consider the phrase dans le haut
[dO..loe.o]. This contains the word le [l(ce)1, which is lexically specified as having an
optional ce, indicated by parentheses.&apos; There are three possible syllabifications, only
the last of which is well formed.
</bodyText>
<table confidence="0.955897">
Example 62 ONS : (d)1 ONS : (1)
a. NUC: (a) NUC: (o)
( syl CODA: CODA:
ha-syl
ONS: (d) ONSET: ONSET: (o
()
* ( NUC: (a) NUC: (oe) N
CODA: (1) CODA: () CODA: /
syl - syl ha-syl
ONS: (d) ONSET: (1) ONSET:
NUC: (CO NUC: (ce) NUC:
( CODA: () CODA: () CODA:
syl syl - ha-syl
</table>
<bodyText confidence="0.999213">
The syllabification in (62a) is unavailable, since the syllable corresponding to the word
haut is lexically specified as ha-syl, which means that its onset must be an elist from
(59). The syllabifications in (62b) are likewise unavailable since these both consist of a
syllable with a coda followed by a syllable without an onset, in contravention of (60a).
This only leaves (62c), which corresponds to the attested form [chilce.o].
We conclude this section with an example derivation for the phrase on ne se moque
pas [On.smpk.pal, which was presented in (51). We assume that at some stage of a
derivation, the PHON attribute of a sign is as follows:
</bodyText>
<subsectionHeader confidence="0.639395">
Example 63
</subsectionHeader>
<bodyText confidence="0.601736333333333">
phon [SEGS: (6) (n (oe)) (s (ce)) Km a k) (p a)]
17 As stated above, we do not address the phenomenon of elision here; this example shows that an
analysis of elision would not require a separate stipulation for h-aspire words.
</bodyText>
<figure confidence="0.998257">
0
(o)
0
</figure>
<page confidence="0.92879">
485
</page>
<note confidence="0.73377">
Computational Linguistics Volume 20, Number 3
</note>
<bodyText confidence="0.965287333333333">
When the appropriate grammatical conditions are met, this phonology attribute will
be given the type phrase. The definition in (53) will accordingly specialize the SYLS
attribute. One possible specialization is given in Example 64.
</bodyText>
<table confidence="0.90713">
Example 64
ONS (): ONSET: (s m) ONSET: (p)
SYLS: C0NC. ( (a) NUC: (a)
syl CODA: (n) syl CODA: (k) syl CODA: ()
SEGS: (Onsmokp a)
phrase
</table>
<bodyText confidence="0.996961230769231">
The reader can check that the onset and coda sequences comply with the constraints in
Figure 3, that the first syllable can have an empty onset because there is no preceding
syllable that could have a coda that matches the requirements of (60a), and that the
obstruent k is permitted by constraint (60b) to appear in the coda of the second syllable
because there is another obstruent p in the following onset.
This concludes our discussion of French schwa. We believe our treatment of schwa
is empirically equivalent to that of Tranel (1987a), except for the analysis of h-aspire.
Several empirical issues remain, but we are optimistic that further refinements to
our proposals will be able to take additional observations on board. Notwithstanding
such further developments, we hope to have demonstrated that the procedural de-
vices of deletion and rule ordering are unnecessary in a typed feature-based grammar
framework, and that constraints represent a perspicuous way of encoding linguistic
observations.
</bodyText>
<sectionHeader confidence="0.998648" genericHeader="method">
6. Prospects for Implementation
</sectionHeader>
<bodyText confidence="0.999967333333333">
In the preceding sections we have shown how the use of parameterized lists in HPSG
is sufficient for encoding a variety of phonological generalizations. While we like this
approach for the purposes of specification and exposition, as stated in Section 1.4,
we actually envisage an implementation employing finite-state automata for string
manipulation. This is simply because we favor the use of existing well-understood
technology when it comes to producing an efficient implementation.
As we have already explained in Section 1.4, we have linguistic reasons for not
wishing to use finite-state transducers and the concomitant two-level model, and in-
stead are interested in exploring the prospects of integrating our work with the au-
tomaton model of Bird and Ellison (1994). In this section we give an overview of this
automaton model and briefly outline the view of automata as types that was originally
proposed in Bird (1992).
</bodyText>
<subsectionHeader confidence="0.962055">
6.1 One-Level Phonology
</subsectionHeader>
<bodyText confidence="0.999481875">
For a variety of reasons already laid out in Section 1, we would like to achieve a closer
integration between phonology and constraint-based grammar frameworks like HPSG.
However, for such an integration to work, it is necessary to adopt a rather unusual
view of phonology; one characterized by such notions as compositionality, intensional-
ity, and lexicalism, and which has come to be called constraint-based phonology (Bird
1990).
Recently, Bird and Ellison (1994) have reinterpreted the constraint-based approach
to phonology using finite-state automata. Nonlinear phonological representations and
</bodyText>
<page confidence="0.997033">
486
</page>
<note confidence="0.799906">
Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systems
</note>
<figureCaption confidence="0.5100095">
Figure 4
Two views of autosegmental association.
rules are encoded as automata. The key insight is that if autosegmental association
is viewed as overlap between intervals with duration (Bird and Klein 1990), then the
overlap can be simulated by using synchronization primitives on automata. Figure 4
illustrates this idea. The diagram on the left of Figure 4 shows two temporal intervals
</figureCaption>
<bodyText confidence="0.999420428571429">
x and y that overlap during the shaded period. On the right, the intervals x and
y themselves are represented as sequences of contiguous tape cells where each cell
contains a copy of the appropriate information (here, simply repeats of x and y).
Again, the shaded period indicates the period of &apos;overlap&apos; of the two intervals. The
reader is referred to Bird and Ellison (1994) for further details.
Although this kind of phonology employs formal devices very similar to the two-
level FST model, there are some important differences in how the two models are used.
In the two-level model the traditional distinction in phonology between RULES and
REPRESENTATIONS is evident in the transducers and tapes respectively. As in constraint-
based grammar more generally, one-level phonology does not have this distinction;
rules and representations alike are interpreted as automata. Figure 5 illustrates this
difference.
Now that we have outlined the one-level model and briefly discussed its relation-
ship with the two-level model, we shall sketch the link to typed feature systems.
</bodyText>
<subsubsectionHeader confidence="0.45727">
Surface Representation
</subsubsectionHeader>
<figureCaption confidence="0.683026">
Figure 5
Comparison of two-level and one-level phonology
</figureCaption>
<figure confidence="0.987892111111111">
(a) Two Level Phonology (b) One Level Phonology
Lexical Representation FSA - Lexical Representation
FSA
- Lexical Constraint
Rules
FSA
FST
- Prosodic Constraint
FSA - Surface Representation
</figure>
<page confidence="0.719331">
487
</page>
<note confidence="0.566861">
Computational Linguistics Volume 20, Number 3
</note>
<subsectionHeader confidence="0.915949">
6.2 Types as Automata
</subsectionHeader>
<bodyText confidence="0.999987888888889">
A type denotes a set of objects. Thus, types are descriptions, and they can be combined
using the familiar operations of meet, join, and negation. Similarly, an automaton de-
notes a set of objects, namely strings (or automaton tapes). And likewise, the operations
of meet, join, and negation are defined for automata and correspond to intersection,
union, and complement of the corresponding sets. Of course, a further operation of
concatenation is defined for automata. We envisage a system for processing linguis-
tic descriptions that implements a subset of the types (which we might simply call
STRING types) as finite-state automata over some predefined alphabet. When the infer-
ence engine requires that two string types be &apos;unified,&apos; the meet of the corresponding
automata will be formed.
Although these string types may be declared as the appropriate values for certain
attributes in a typed feature system, string types are only declared in terms of the
basic alphabet and other string types. It is not possible to employ non-string types in
the definition of string types. This is a severe restriction, since list types (say, in HPSG)
allow arbitrary feature structures as elements, and we would like to be able to do the
same for string types. Work on overcoming this limitation is currently in progress, and
builds on the well-known similarity between feature structures and automata, when
viewed as directed graphs (Kasper and Rounds 1986).
</bodyText>
<sectionHeader confidence="0.791071" genericHeader="conclusions">
7. Conclusion
</sectionHeader>
<bodyText confidence="0.99997672">
In this paper, we have tried to give the reader an impression of how two rather different
phonological phenomena can be given a declarative encoding in a constraint-based
grammar. Although we have focused on phonology, we have also placed our analyses
within a morphological context as befits the multi-dimensional perspective of HPSG.
The formal framework of HPSG is rather powerful; certainly powerful enough to
capture many analyses in the style of classical generative phonology in which arbi-
trary mappings are allowed between underlying and surface representations. We have
limited ourselves further by allowing only one phonological stratum in the grammar,
and by adopting a notion of phonological compositionality that supports monotonicity.
These restrictions make it much harder to carry over generalizations that depended on
a procedural rule format. This is not a handicap, we contend, since it is heuristically
valuable to view the data in a new light rather than just coercing traditional analyses
into a modern grammar formalism.
So what is a constraint-based style of phonological analysis? An important key, we
claim, is the use of generalizations expressed at the level of prosodic types. Coupled
with a systematic underspecification of lexical entries and a regime of type inheritance,
this allows us to have different levels of linguistic abstraction while maintaining a
&apos;concrete&apos; relation between lexical and surface representations of phonology.
We hope to have given enough illustration to show that our approach is viable. In
future, we wish to extend these same techniques to a typologically diverse range of
other linguistic phenomena. A second important goal is to show how the technology
of finite-state automata can be invoked to deal with phonological information in HPSG.
For although we have placed phonology within a general framework of linguistic
constraints, the analyses we have presented only involve manipulation of regular
expressions.
</bodyText>
<sectionHeader confidence="0.971397" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<footnote confidence="0.5575108">
This research is funded by the U.K. Science
and Engineering Research Council, under
grant GR/G-22084 Computational Phonology:
A Constraint-Based Approach, and has been
carried out as part of the research program
</footnote>
<page confidence="0.989634">
488
</page>
<note confidence="0.518341">
Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systems
</note>
<bodyText confidence="0.923098444444444">
of the Human Communication Research
Centre, supported by the U.K. Economic
and Social Research Council. We are
grateful to Ted Briscoe, Tomaz Erjavec,
Daniele Godard, John Nerbonne, Marc
Plenat, Bernard Tranel, and Ivan Sag for
discussions and correspondence relating to
this work, and to two anonymous reviewers
for their helpful suggestions.
</bodyText>
<sectionHeader confidence="0.882216" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998909181818182">
Anderson, S. R. (1992). A-Morphous
Morphology, Volume 62 of Cambridge
Studies in Linguistics. Cambridge
University Press.
Antworth, E. (1990). PC-KIMMO: A
Two-Level Processor for Morphological
Analysis. Summer Institute of Linguistics.
Archangeli, D., and Pulleyblank, D. (1989).
&amp;quot;Yoruba vowel harmony.&amp;quot; Linguistic
Inquiry, 20, 173-217.
Bach, E., and Wheeler, D. W. (1981).
&amp;quot;Montague phonology: A first
approximation.&amp;quot; University of
Massachusetts Occasional Papers in
Linguistics, 7, 27-45.
Bird, S. (1990). Constraint-based phonology.
Doctoral dissertation, University of
Edinburgh. To be published in revised
form by Cambridge University Press,
Studies in Natural Language Processing.
Bird, S. (1992). &amp;quot;Finite-state phonology in
HPSG.&amp;quot; In Proceedings of the 14th
International Conference on Computational
Linguistics (COLING-92). 74-80.
Bird, S., and Ellison, T. M. (1994).
&amp;quot;One-level phonology: Autosegmental
representations and rules as finite
automata.&amp;quot; Computational Linguistics, 20,
55-90.
Bird, S., and Klein, E. (1990). &amp;quot;Phonological
events.&amp;quot; Journal of Linguistics, 26, 33-56.
Bird, S., and Ladd, D. R. (1991). &amp;quot;Presenting
autosegmental phonology.&amp;quot; Journal of
Linguistics, 27, 193-210.
Bloomfield, L. (1926). &amp;quot;A set of postulates
for the science of language.&amp;quot; Language, 2,
153-164. Reprinted in Readings in
Linguistics I: The Development of Descriptive
Linguistics in America 1925-56, edited by
Martin Joos. 26-31.
Briscoe, T. (1991). &amp;quot;Lexical issues in natural
language processing.&amp;quot; In Natural Language
and Speech, edited by E. Klein and
F. Veltman, 39-68. Springer-Verlag.
Bromberger, S., and Halle, M. (1989). &amp;quot;Why
phonology is different.&amp;quot; Linguistic Inquiry,
20, 51-70.
Cahill, L. J. (1990). &amp;quot;Syllable-based
morphology.&amp;quot; In Proceedings, 13th
International Conference on Computational
Linguistics, Volume 3, edited by
H. Karlgren, 48-53.
Carpenter, B. (1992). The Logic of Typed
Feature Structures. Volume 32 of Cambridge
Tracts in Theoretical Computer Science.
Cambridge University Press.
Clements, G. (1985). &amp;quot;The geometry of
phonological features.&amp;quot; Phonology
Yearbook, 2, 225-252.
Clements, G. N., and Keyser, S. J. (1983). CV
Phonology: A Generative Theory of the
Syllable. MIT Press.
Coleman, J. S. (1991). Phonological
representations-their names, forms and
powers. Doctoral dissertation, University
of York.
Coleman, J. S. (1992). &amp;quot;The phonetic
interpretation of headed phonological
structures containing overlapping
constituents.&amp;quot; Phonology, 9, 1-44.
Copestake, A.; Sanfilippo, A.; Briscoe, T.;
and de Paiva, V. (in press). &amp;quot;The
ACQUILEX LK13: An introduction.&amp;quot; In
Default Inheritance in Unification Based
Approaches to the Lexicon, edited by
T. Briscoe, A. Copestake, and V. de Paiva.
Cambridge University Press.
Dell, F. (1980). Generative Phonology and
French Phonology. Cambridge University
Press.
Emele, M. C., and Zajac, R. (1990). &amp;quot;Typed
unification grammars.&amp;quot; In Proceedings,
13th International Conference on
Computational Linguistics. 293-298.
Gazdar, G.; Klein, E.; Pullum, G.; and Sag, I.
(1985). Generalized Phrase Structure
Grammar. Blackwell.
Goldsmith, J. (1990). Autosegmental and
Metrical Phonology. Blackwell.
Goldsmith, J. A. (1993). &amp;quot;Harmonic
phonology.&amp;quot; In The Last Phonological Rule:
Reflections on Constraints and Derivations,
edited by J. A. Goldsmith, 21-60.
University of Chicago Press.
Hoeksema, J., and Janda, R. (1988).
&amp;quot;Implications of process morphology for
categorial grammar.&amp;quot; In Categorial
Grammars and Natural Language Structures,
edited by R. T. Oehrle, E. Bach, and D. W.
Wheeler, 199-247. Reidel.
Hooper, J. (1976). An Introduction to Natural
Generative Phonology. Academic Press.
Hudson, G. (1980). &amp;quot;Automatic alternations
in non-transformational phonology&amp;quot;
Language, 56, 94-125.
Jaffar, J., and Lassez, J.-L. (1987).
&amp;quot;Constraint logic programming.&amp;quot; In ACM
Symposium on Principles of Programming
Languages, 111-119.
Johnson, M. (1988). Attribute-value logic and
</reference>
<page confidence="0.981806">
489
</page>
<note confidence="0.478481">
Computational Linguistics Volume 20, Number 3
</note>
<reference confidence="0.999689844262295">
the theory of grammar. Doctoral
dissertation, Stanford University.
Kahn, D. (1976). Syllable-based Generalizations
in English Phonology. Indiana University
Linguistics Club.
Kaplan, R. M., and Bresnan, J. (1982).
&amp;quot;Lexical-Functional Grammar: A formal
system for grammatical representation.&apos;&apos;
In The Mental Representation of Grammatical
Relations, edited by J. Bresnan. MIT Press.
Kasper, R. T., and Rounds, W. C. (1986). &amp;quot;A
logical semantics for feature structures.&amp;quot;
In Proceedings, 24th Annual Meeting of the
Association for Computational Linguistics.
257-266.
Kay, M. (1987). &amp;quot;Nonconcatenative
finite-state morphology.&amp;quot; In Proceedings,
Third Meeting of the European Chapter of the
Association for Computational Linguistics.
2-10.
Keating, P. (1984). &amp;quot;Phonetic and
phonological representation of stop
consonant voicing.&amp;quot; Language, 60, 286-319.
Kenstowicz, M., and Kisseberth, C. (1979).
Generative Phonology: Description and
Theory. Academic Press.
Kiparsky, P. (1982). Lexical Morphology and
Phonology. Hanshin Publishing Co.
Kisseberth, C. W. (1970). &amp;quot;On the functional
unity of phonological rules.&amp;quot; Linguistic
Inquiry, 1, 291-306.
Klein, E. (1992). &amp;quot;Data types in
computational phonology.&amp;quot; In Proceedings,
14th International Conference on
Computational Linguistics (COLING-92).
149-155.
Klein, E. (1993). &amp;quot;An HPSG approach to
Sierra Miwok verb stems.&amp;quot; In Phonology
and Computation, edited by T. M. Ellison
and J. M. Scobbie. University of
Edinburgh, 19-35.
Kornai, A. (1991). Formal phonology. Doctoral
dissertation, Stanford University.
Koskenniemi, K. (1983). Two-level morphology:
A general computational model for word-form
recognition and production. Doctoral
dissertation, University of Helsinki.
Krieger, H.-U., and Nerbonne, J. (in press).
&amp;quot;Feature-based inheritance networks for
computational lexicons.&amp;quot; In Default
Inheritance in Unification Based Approaches to
the Lexicon, edited by T. Briscoe,
A. Copestake, and V. de Paiva.
Cambridge University Press.
Krieger, H.-U.; Pirker, H.; and Nerbonne, J.
(1993). &amp;quot;Feature-based allomorphy.&amp;quot; In
Proceedings, 31st Annual Meeting of the
Association for Computational Linguistics,
140-147.
Manaster Ramer, A. (1981). How abstruse is
phonology? Doctoral dissertation,
University of Chicago.
Martinet, A. (1972). &amp;quot;La nature
phonologique d&apos;e caduc.&amp;quot; In Papers in
Linguistics and Phonetics to the Memory of
Pierre Delattre, edited by A. Valdman.
Mouton.
Mastroianni, M. (1993). Attribute Logic
Phonology. CMU-LCL 93-4, Carnegie
Mellon University.
McCarthy, J. (1981). &amp;quot;A prosodic theory of
non-concatenative morphology.&amp;quot;
Linguistic Inquiry, 12, 373-418.
McCarthy, J., and Prince, A. (1993).
&amp;quot;Prosodic morphology I-Constraint
interaction and satisfaction.&amp;quot; Unpublished
Report.
Morin, Y.-C. (1978). &amp;quot;The status of mute &apos;e&apos;.&amp;quot;
Studies in French Linguistics, 1, 79-140.
Morin, Y.-C. (1987). &amp;quot;French data and
phonological theory.&amp;quot; Linguistics, 25,
815-843.
Paradis, C. (1988). &amp;quot;On constraints and
repair strategies.&amp;quot; The Linguistic Review, 6,
71-97.
Partee, B. H. (1979). &amp;quot;Montague grammar
and the well-formedness constraint.&amp;quot; In
Syntax and Semantics 10: Selections from the
Third Groningen Round Table, edited by
Heny and H. Schnelle, 275-313.
Academic Press.
Pierrehumbert, J. (1990). &amp;quot;Phonological and
phonetic representation.&amp;quot; Journal of
Phonetics, 18, 375-394.
Pollard, C., and Sag, I. (1987).
Information-Based Syntax and Semantics.
Volume 13 of CSLI Lecture Notes. Stanford:
Center for the Study of Language and
Information.
Prince, A. S., and Smolensky, P. (1993).
&amp;quot;Optimality theory: Constraint interaction
in generative grammar.&amp;quot; Technical
Report 2, Center for Cognitive Science,
Rutgers University.
Pullum, G. K., and Zwicky, A. M. (1984).
&amp;quot;The syntax-phonology boundary and
current syntactic theories.&amp;quot; In Ohio State
University Working Papers in Linguistics:
Papers on Morphology, edited by A. Zwicky
and R. Wallace. Ohio State University.
Reinhard, S., and Gibbon, D. (1991).
&amp;quot;Prosodic inheritance and morphological
generalizations.&amp;quot; In Proceedings, 5th
European ACL Meeting, 131-136.
Riehemann, S. (1992). Word formation in
lexical type hierarchies: A case study of
bar-adjectives in German. Master&apos;s thesis,
Department of Linguistics, University of
Tubingen.
Rooth, M. (1985). Association with focus.
Doctoral dissertation, University of
Massachusetts-Amherst.
</reference>
<page confidence="0.95294">
490
</page>
<note confidence="0.400611">
Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systems
</note>
<reference confidence="0.992651076923077">
Russell, K. (1993). A constraint-based approach
to phonology. Doctoral dissertation,
University of Southern California.
Scobbie, J. (1991). Attribute-value phonology.
Doctoral dissertation, University of
Edinburgh.
Selkirk, E. (1984). Phonology and Syntax. MIT
Press.
Shibatani, M. (1973). &amp;quot;The role of surface
phonetic constraints in generative
phonology.&amp;quot; Language, 49, 87-106.
Smolka, G. (1992). &amp;quot;Feature constraint logics
for unification grammars.&amp;quot; Journal of Logic
Programming, 12, 51-87.
Sproat, R. (1992). Morphology and
Computation. Natural Language
Processing. MIT Press.
Sproat, R., and Brunson, B. (1987).
&amp;quot;Constituent-based morphological
parsing: A new approach to the problem
of word-recognition.&amp;quot; In Proceedings, 25th
Annual Meeting of the Association for
Computational Linguistics. 65-72.
Tranel, B. (1987a). &amp;quot;French schwa and
nonlinear phonology.&amp;quot; Linguistics, 25,
845-866.
Tranel, B. (1987b). The Sounds of French—An
Introduction. Cambridge University Press.
Valdman, A. (1976). Introduction to French
Phonology and Morphology. Newbury
House.
Walther, M. (1992). Deklarative Silbifizierung
in einem constrain tbasierten
Grammatikformalismus. Master&apos;s thesis,
University of Stuttgart.
Wheeler, D. (1981). Aspects of a Categorial
Theory of Phonology. Doctoral dissertation,
University of Massachusetts-Amherst.
Wiebe, B. (1992). Modelling autosegmental
phonology with multi-tape finite state
transducers. Master&apos;s thesis, Simon Fraser
University.
Zajac, R. (1992). &amp;quot;Inheritance and
constraint-based grammar formalisms.&amp;quot;
Computational Linguistics, 18, 159-182.
Zajac, R. (in press). &amp;quot;Issues in the design of
a language for representing linguistic
information based on inheritance and
feature structures.&amp;quot; In Default Inheritance in
Unification Based Approaches to the Lexicon,
edited by T. Briscoe, A. Copestake, and
V. de Paiva. Cambridge University Press.
</reference>
<page confidence="0.99872">
491
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.041648">
<title confidence="0.99952">Phonological Analysis in Typed Feature Systems</title>
<author confidence="0.999921">Steven Bird Ewan Klein</author>
<affiliation confidence="0.999011">University of Edinburgh University of Edinburgh</affiliation>
<abstract confidence="0.9861569375">Research on constraint-based grammar frameworks has focused on syntax and semantics largely to the exclusion of phonology. Likewise, current developments in phonology have generally ignored the technical and linguistic innovations available in these frameworks. In this paper we suggest some strategies for reuniting phonology and the rest of grammar in the context of a uniform constraint formalism. We explain why this is a desirable goal, and we present some conservative extensions to current practice in computational linguistics and in nonlinear phonology that we believe are necessary and sufficient for achieving this goal. We begin by exploring the application of typed feature logic to phonology and propose a of prosodic types. Next, taking an exemplar of the grammar frameworks we have in mind, we show how the phonology attribute can be enriched so that it can encode multi-tiered, hierarchical phonological representations. Finally, we exemplify the approach in some detail for the nonconcatenative morphology of Sierra Miwok and for schwa alternation in French. The approach taken in this paper lends itself particularly well to capturing phonological generalizations in terms of high-level prosodic constraints. 1. Phonology in Constraint-Based Grammar Classical generative phonology is couched within the same set of assumptions that dominated standard transformational grammar. Despite some claims that &amp;quot;derivations based on ordered rules (that is, external ordering) and incorporating intermediate structures are essential to phonology&amp;quot; (Bromberger and Halle 1989:52), much recent work has tended toward a new model, frequently described in terms of constraints on well-formedness (Paradis 1988; Goldsmith 1993; McCarthy and Prince 1993; Prince and Smolensky 1993). While this work has an increasingly declarative flavor, most versions retain procedural devices for repairing representations that fail to meet certain constraints, or for constraints to override each other. This view is in marked to the interpretation of constraints in grammar frameworks like GPSG, and in constraint programming systems more generally (Jaffar and Lassez 1987; Smolka 1992). In such approaches, constraints cannot be circumvented, there are no &apos;intermediate structures,&apos; and the well-formedness constraint (Partee 1979) is observed (i.e. ill-formed representations can never be created). The advantage of these frameworks is that they allow interesting linguistic analyses to be encoded while remaining computationally tractable. * University of Edinburgh, Centre for Cognitive Science, 2 Buccleuch Place, Edinburgh EH8 9LW, U.K.</abstract>
<email confidence="0.721077">steven.ewan@cogni.ed.ac.uk</email>
<note confidence="0.9636214">1 Lexical Functional Grammar (Kaplan and Bresnan 1982), Generalized Phrase Structure Grammar (Gazdar, Klein, Pullum, and Sag 1985), and Head-Driven Phrase Structure Grammar (Pollard and Sag 1987). © 1994 Association for Computational Linguistics Computational Linguistics Volume 20, Number 3</note>
<abstract confidence="0.991042866666667">Here, we are interested in the question of what a theory of phonology ought to look like if it is to be compatible with a constraint-based grammar framework. This issue has already received attention,&apos; although a thoroughgoing integration of phonology into constraint-based grammars has yet to be attempted. To ease exposition, we shall a suitably representative candidate of such approaches. Although we are broadly committed to a sign-oriented approach to grammar, none of our proposals crucially on specific tenets of Rather than attempting to theorize at an abstract level about constraint-based phonology, we shall engage in two case studies intended to give a concrete illustration of important issues: these involve templatic morphology in Sierra Miwok and schwa alternation in French. Before launching into these studies, however, we present an overview of some aspects of phonology that present a challenge to standard assumptions taken in sign-oriented constraint-based grammars. Then we describe a (simversion of will make it possible to illustrate the approach without irrelevant technical machinery. 1.1 The Challenge of Phonology Given that the dominant focus of most research in constraint-based grammar has been syntax and semantics, it is not surprising that the phonological content of words and phrases has been largely limited to orthographic strings, supplemented with a concatenation operation. How far would such representations have to be enriched if we wanted to accommodate a more thoroughgoing treatment of phonology? As remarked earlier, recent work in theoretical phonology has apparently moved closer to a constraint-based perspective, and is thus a promising starting point for our investigation. Yet there are at least three challenges that confront anyone looking into theoretical phonology from the viewpoint of computational linguistics. Most striking is the relative informality of the in theoretical statements are couched. Bird and Ladd (1991) have catalogued several examples of this: notational ambiguity (incoherence), definition by example (informality), variable interpretation of notation depending on subjective criteria (inconsistency), and uncertainty about empirical content (indeterminacy). When a clear theoretical statement can be found, it is usually expressed in procedural terms, which clouds the empirical ramifications making a theory difficult to falsify. Finally, even when explicit and nonprocedural generalizations are found, they are commonly stated in a nonlinear model, which goes beyond the assumptions about phonology made in it currently stands. We approach these challenges by adopting a formal, nonprocedural, nonlinear of phonology and showing how it can be integrated into on the heels of recent work by the authors (Bird and Klein 1990; Bird 1992; Klein 1992). One of the starting assumptions of this work is that phonological representations intensional, i.e. each representation is actually a a class of utterances. Derivations progress by refining descriptions, further constraining the class of denoted objects. Lexical representations are likewise partial, and phonological constraints are cast as generalizations in a lexical inheritance hierarchy or in a prosodic inheritance hierarchy. When set against the background of constraint-based grammar, this intensional approach is quite natural (cf. Johnson [19881). Moreover, some recent thinking on</abstract>
<note confidence="0.7807695">the phonology—phonetics interface supports this view (Pierrehumbert 1990; Coleman 2 (Bach and Wheeler 1981; Wheeler 1981; Bird 1990; Cahill 1990; Coleman 1991; Scobbie 1991; Bird 1992; Walther 1992; Mastroianni 1993; Russell 1993) 456</note>
<title confidence="0.788952">Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systems</title>
<abstract confidence="0.99249125">1992). However, it represents a fundamental split with the generative tradition, where rules do not so much refine descriptions as alter the objects themselves (Keating 1984). While it is clearly possible to integrate an essentially generative model into the mold of constraint-based grammar (Krieger, Pirker, and Nerbonne 1993), it is less clear that this is the approach most phonologists would wish to take nowadays. It is becoming increasingly apparent that rule-based relationships between surface forms and hypothetical lexical forms are unable to capture important generalizations about surface forms. This concern was voiced early in the history of generative phonology, when (1970) complained that such rules regularly achieve particular surface configurations, but are unable to express the most elementary observations about what those surface configurations are. As a criticism of rule-based systems, Kisseberth&apos;s complaint remains valid and has been echoed several times since then (Shibatani 1973; Hooper 1976; Hudson 1980; Manaster Ramer 1981). However, recent work in phonology has moved away from models involving rules that relate lexical and surface forms toward models involving general systems of interacting constraints, where this problem has been side-stepped. Accordingly, we avoid the theoretical framework of early generative phonology, instead on encoding phonological a framework. We present an overview of the grammar framework in the next section. 1.2 Motivation At this point, we should briefly address the question: What is gained by integrating phonology into a constraint-based grammar? One pragmatic answer is that approaches already taken this step, by introducing a that attributes for as we have already pointed out, value of to be enriched somehow if it is to be linguistically adequate, it is reasonable to ask whether the formalism allows insightful statements of phonological generalizations. An objection might take the following form: phonology is formally less complex than syntax, as shown by the body of work on finite state analyses of phonology (cf. Section 1.4). Hence, it is inappropriate to encode phonology in a general purpose formalism that has been designed to accommodate more complex phenomena. As a first response, we would maintain that formalisms should not be confused with theories. Certainly, we want to have a restrictive theory of phonology and its interactions with other levels of grammar. But we view constraint-based formalisms as languages for expressing such theories, not as theories themselves. Moreover, the fact that we use a uniform constraint formalism does not force us to use homogeneous inferential mechanisms for that formalism; this issue is discussed further in Section 1.4 and Section 6. A further question might be: do natural language grammars require the kind of interaction between phonology and other levels of grammar made possible by constraint-based formalisms? This is not the place to explore this issue in the detail it deserves. However, even if we accept the contention of Pullum and Zwicky (1984) that the interactions between phonology and syntax (narrowly construed) are highly restricted, there are still good reasons for wanting to accommodate phonological representations as one of the constraints in a sign-based grammar framework. To begin with, it is relatively uncontroversial that morphology needs to be interfaced with both syntax and phonology. Approaches like that of Krieger and Nerbonne (in press) have shown that both derivational and inflectional morphology can be usefully expressed within the constraint-based paradigm. Taking the further step of adding phonology seems equally desirable. Second, the use of typed feature structures within the lexicon has been strongly 457 Computational Linguistics Volume 20, Number 3 argued for by Briscoe (1991) and Copestake et al. (in press). That is, even when we ignore syntactic combination, constraint-based grammar frameworks turn out to be well suited to expressing the category and semantic information fields of lexical entries. But the interaction of phonology with categorial information inside the lexicon is well documented. Lexical phonology (Kiparsky 1982) has shown in detail how phonological phenomena are conditioned by morphologically specified domains. If direct interaction between phonology and morpho-syn tax is prohibited, one can only resort to ad hoc and poorly motivated diacritic features. Turning to a different empirical domain, it can be argued that focus constructions exhibit an interaction between information structure (at the semantic–pragmatic level) with prosodic structure (at the phonological level). This interaction can be directly expressed in a sign-oriented approach. In other frameworks it is common practice to direct reference to phonology by invoking a morpho-syntactic (e.g. Selkirk 1984; Rooth 1985); the mediation of syntax in this way appears to be more an artifact of the grammar architecture than an independently motivated requirement. it has been argued that the phenomenon of heavy is a kind of syntaxphonology interaction that is simply stated in a constraint-based approach, where the linear precedence constraints of syntax are sensitive to the phonological category of weight (Bird 1992). 1.3 Theoretical Framework Typed feature structures (Carpenter 1992) impose a type discipline on constraint-based grammar formalisms. A partial ordering over the types gives rise to an inheritance hierarchy of constraints. As Emele and Zajac (1990) point out, this object-oriented approach brings a number of advantages to grammar writing, such as a high level of abstraction, inferential capacity and modularity. On the face of it, such benefits should extend beyond syntax—to phonology for example. Although there have been some valuable efforts to exploit inheritance and type hierarchies within phonology (e.g. Reinhard and Gibbon 1991), the potential of typed feature structures for this area has barely been scratched so far. In this section, we a brief overview of and Sag 1987), a constraint-based grammar formalism built around a type system that suits our purposes in phonology. In order to formulate the type system of our grammar, we need to make two of DECLARATION. first kind contains information about the subsumption over types. For example, the basic grammar object in the feature of type type some a subtype of at least as much information as type declaration for it as following disjunction of Example 1 = morph second kind of declaration is an CONDITION. is, for each type, we declare (all and only) the attributes for which it is specified, and additionally types of values which those attributes can take.&apos; For example, objects of type constraints proposed here deviate in various respects from the standard version of Carpenter (1992) in using the notation specify that type constraint rk. We are using what Carpenter (1992) calls WELL-TYPING. is, (i) the only attributes and values can be specified for a given feature structure of type r are those appropriate for and (ii) every structure of type be specified for all attributes appropriate for 458 Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systems could be constrained to have the following features defined: Example 2 : : : sign is, feature structures of type contain the attributes phonoland daughters) and these attributes take values of a specific type (i.e., synsem, A further crucial point is that appropriateness conditions are inherited by subtypes. For examsince a subtype of inherits all the constraints obeyed by Moreover, as we shall see in Section 3.2, it is subject to some further appropriateness conditions that are not imposed on any of its supertypes. Continuing in the same vein, we can assign appropriateness conditions to the types occurred as values in (2), (simplifying substantially from standard we give the constraints for type be discussed in Section 2. Example 3 _ : : - To conclude this section, we shall look very briefly at matters of interpretation and inference. As shown by Carpenter (1992) and Zajac (1992, in press), we can use constraint resolution to carry out type inference for feature terms. Following Zajac, let say that a term is a term all of whose type symbols are minimal the most specific types in the hierarchy immediately above 1). A feature term is one that obeys all the type definitions. Then the meaning of a feature given by the set of all well-typed ground feature terms that are subsumed by as a query, involves describing F&apos;s denotation; for example, enumerating all the well-typed ground feature terms it subsumes. Since the type defiobeyed by be recursive, its denotation is potentially infinite. Consider example the following definitions (where for nonempty list empty list respectively, and every type): Example 4 a. list nelist v elist Earlier versions of syntax and semantics as separate attributes, and we shall sometimes revert to the latter when borrowing examples from other people&apos;s presentations. synsem 459 Computational Linguistics Volume 20, Number 3 the denotation of the type symbol the set of all possible ground lists. In practice, a constraint solver could recursively enumerate all these solutions; an proposed by Zajac would be to treat the symbol the best finite approximation of the infinite set of all lists. 1.4 Finite-State Phonology Over the last decade much has been written on the application of finite-state trans-</abstract>
<note confidence="0.91887">(FsTs) to phonology, centering on the MODEL Koskenniemi (1983).</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S R Anderson</author>
</authors>
<title>A-Morphous Morphology, Volume 62 of Cambridge Studies in Linguistics.</title>
<date>1992</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="44520" citStr="Anderson (1992" startWordPosition="7136" endWordPosition="7137">OW : (Tv Er) SKEL : Er -TV E Ec 37 ) template-III Each of these types specializes the constraints on the type phon, and each can be unified with the phon value earlier assigned to the root form of kicaaw in (30). In particular, the conjunction of constraints given in (34) evaluates to (29), repeated here: Example 34 [CON : (k c w)] VOW : (i a) A template-I phon Example 29 [ CON: (ik3c5w) — VOW: 0 i SKEL : ( phon However, we also need to specify the dependency between the three types of verb root, and the corresponding phonological exponents that determine the appropriate basic stem forms (cf. Anderson (19921). As a first attempt to express this, let us say that stem can be either basic or affixed: Example 35 stem affixed V basic Type declaration (35) ensures that basic will inherit from stem the following constraint, namely that its SYNSEM value is to be unified with its MORPH&apos;s ROOT&apos;s SYNSEM value: Example 36 -] ISYNSEM : MORPHIROOT1SYNSEM : stern a) 2 3 4 4 5 &gt;1 473 Computational Linguistics specify the Volume 20, Number 3 We could now disjunctively phon A template-I following three sets of constraints on basic: Example 37 PHON: ROOT: v-root-d basic MORPH: 1 PHON: phon A template-II basic MORP</context>
</contexts>
<marker>Anderson, 1992</marker>
<rawString>Anderson, S. R. (1992). A-Morphous Morphology, Volume 62 of Cambridge Studies in Linguistics. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Antworth</author>
</authors>
<title>PC-KIMMO: A Two-Level Processor for Morphological Analysis. Summer Institute of Linguistics.</title>
<date>1990</date>
<contexts>
<context position="17564" citStr="Antworth (1990)" startWordPosition="2655" endWordPosition="2656">ng examples from other people&apos;s presentations. synsem 459 Computational Linguistics Volume 20, Number 3 Here, the denotation of the type symbol list is the set of all possible ground lists. In practice, a constraint solver could recursively enumerate all these solutions; an alternative proposed by Zajac would be to treat the symbol LIST as the best finite approximation of the infinite set of all lists. 1.4 Finite-State Phonology Over the last decade much has been written on the application of finite-state transducers (FsTs) to phonology, centering on the TWO-LEVEL MODEL of Koskenniemi (1983). Antworth (1990) and Sproat (1992) give comprehensive introductions to the field. The formalism is an attractive computational model for 1960s generative phonology. However, as has already been noted, phonologists have since moved away from complex string rewriting systems to a range of so-called nonlinear models of phonology. The central innovation of this more recent work is the idea that phonological representations are not strings but collections of strings, synchronized like an orchestral score. There have been some notable recent attempts to rescue the FST model from its linearity in order to encompass </context>
</contexts>
<marker>Antworth, 1990</marker>
<rawString>Antworth, E. (1990). PC-KIMMO: A Two-Level Processor for Morphological Analysis. Summer Institute of Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Archangeli</author>
<author>D Pulleyblank</author>
</authors>
<title>Yoruba vowel harmony.&amp;quot;</title>
<date>1989</date>
<journal>Linguistic Inquiry,</journal>
<volume>20</volume>
<pages>173--217</pages>
<contexts>
<context position="28825" citStr="Archangeli and Pulleyblank (1989)" startWordPosition="4507" endWordPosition="4510">egments. It would then follow that, for example, the requirement that syllable-initial voiceless obstruents be aspirated in English lexical-sign verb unsaturated main base trans strict-trans like Figure 1 A portion of the lexical hierarchy. 464 Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systems would have to be observed by each syllable in a phrase (which in the limiting case, might be a single word), rather than lexical entries per se. In some languages we may require there to be a special kind of interaction between the lexical and the prosodic hierarchy. For example, Archangeli and Pulleyblank (1989) discuss the tongue root harmony of Yoruba, which is restricted to nouns. If atr (i.e. advanced tongue root) was the type of harmonic utterances, then we could express the necessary constraint thus: phon A atr SYNILOCIHEAD : [MAJ : noun] LEX : noun This kind of constraint is known as a morpheme structure constraint, and phonologists have frequently needed to have recourse to these (Kenstowicz and Kisseberth 1979). Another interaction between prosody and morphology is the phenomenon of prosodic morphology, an example of which can be found in Section 4. 3.2 Morphological Complexity Given the syn</context>
</contexts>
<marker>Archangeli, Pulleyblank, 1989</marker>
<rawString>Archangeli, D., and Pulleyblank, D. (1989). &amp;quot;Yoruba vowel harmony.&amp;quot; Linguistic Inquiry, 20, 173-217.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Bach</author>
<author>D W Wheeler</author>
</authors>
<title>Montague phonology: A first approximation.&amp;quot;</title>
<date>1981</date>
<journal>University of Massachusetts Occasional Papers in Linguistics,</journal>
<volume>7</volume>
<pages>27--45</pages>
<contexts>
<context position="6768" citStr="Bach and Wheeler 1981" startWordPosition="967" endWordPosition="970">, i.e. each representation is actually a description of a class of utterances. Derivations progress by refining descriptions, further constraining the class of denoted objects. Lexical representations are likewise partial, and phonological constraints are cast as generalizations in a lexical inheritance hierarchy or in a prosodic inheritance hierarchy. When set against the background of constraint-based grammar, this intensional approach is quite natural (cf. Johnson [19881). Moreover, some recent thinking on the phonology—phonetics interface supports this view (Pierrehumbert 1990; Coleman 2 (Bach and Wheeler 1981; Wheeler 1981; Bird 1990; Cahill 1990; Coleman 1991; Scobbie 1991; Bird 1992; Walther 1992; Mastroianni 1993; Russell 1993) 456 Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systems 1992). However, it represents a fundamental split with the generative tradition, where rules do not so much refine descriptions as alter the objects themselves (Keating 1984). While it is clearly possible to integrate an essentially generative model into the mold of constraint-based grammar (Krieger, Pirker, and Nerbonne 1993), it is less clear that this is the approach most phonologists would </context>
</contexts>
<marker>Bach, Wheeler, 1981</marker>
<rawString>Bach, E., and Wheeler, D. W. (1981). &amp;quot;Montague phonology: A first approximation.&amp;quot; University of Massachusetts Occasional Papers in Linguistics, 7, 27-45.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Bird</author>
</authors>
<title>Constraint-based phonology. Doctoral dissertation,</title>
<date>1990</date>
<booktitle>Studies in Natural Language Processing.</booktitle>
<publisher>Cambridge University Press,</publisher>
<institution>University of Edinburgh.</institution>
<note>To be published in revised form by</note>
<contexts>
<context position="6793" citStr="Bird 1990" startWordPosition="973" endWordPosition="974">y a description of a class of utterances. Derivations progress by refining descriptions, further constraining the class of denoted objects. Lexical representations are likewise partial, and phonological constraints are cast as generalizations in a lexical inheritance hierarchy or in a prosodic inheritance hierarchy. When set against the background of constraint-based grammar, this intensional approach is quite natural (cf. Johnson [19881). Moreover, some recent thinking on the phonology—phonetics interface supports this view (Pierrehumbert 1990; Coleman 2 (Bach and Wheeler 1981; Wheeler 1981; Bird 1990; Cahill 1990; Coleman 1991; Scobbie 1991; Bird 1992; Walther 1992; Mastroianni 1993; Russell 1993) 456 Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systems 1992). However, it represents a fundamental split with the generative tradition, where rules do not so much refine descriptions as alter the objects themselves (Keating 1984). While it is clearly possible to integrate an essentially generative model into the mold of constraint-based grammar (Krieger, Pirker, and Nerbonne 1993), it is less clear that this is the approach most phonologists would wish to take nowadays. It</context>
<context position="75474" citStr="Bird 1990" startWordPosition="12264" endWordPosition="12265">In this section we give an overview of this automaton model and briefly outline the view of automata as types that was originally proposed in Bird (1992). 6.1 One-Level Phonology For a variety of reasons already laid out in Section 1, we would like to achieve a closer integration between phonology and constraint-based grammar frameworks like HPSG. However, for such an integration to work, it is necessary to adopt a rather unusual view of phonology; one characterized by such notions as compositionality, intensionality, and lexicalism, and which has come to be called constraint-based phonology (Bird 1990). Recently, Bird and Ellison (1994) have reinterpreted the constraint-based approach to phonology using finite-state automata. Nonlinear phonological representations and 486 Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systems Figure 4 Two views of autosegmental association. rules are encoded as automata. The key insight is that if autosegmental association is viewed as overlap between intervals with duration (Bird and Klein 1990), then the overlap can be simulated by using synchronization primitives on automata. Figure 4 illustrates this idea. The diagram on the left of F</context>
</contexts>
<marker>Bird, 1990</marker>
<rawString>Bird, S. (1990). Constraint-based phonology. Doctoral dissertation, University of Edinburgh. To be published in revised form by Cambridge University Press, Studies in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Bird</author>
</authors>
<title>Finite-state phonology in HPSG.&amp;quot;</title>
<date>1992</date>
<booktitle>In Proceedings of the 14th International Conference on Computational Linguistics (COLING-92).</booktitle>
<pages>74--80</pages>
<contexts>
<context position="6035" citStr="Bird 1992" startWordPosition="869" endWordPosition="870"> clear theoretical statement can be found, it is usually expressed in procedural terms, which clouds the empirical ramifications making a theory difficult to falsify. Finally, even when explicit and nonprocedural generalizations are found, they are commonly stated in a nonlinear model, which clearly goes beyond the assumptions about phonology made in HPSG as it currently stands. We approach these challenges by adopting a formal, nonprocedural, nonlinear model of phonology and showing how it can be integrated into HPSG, following on the heels of recent work by the authors (Bird and Klein 1990; Bird 1992; Klein 1992). One of the starting assumptions of this work is that phonological representations are intensional, i.e. each representation is actually a description of a class of utterances. Derivations progress by refining descriptions, further constraining the class of denoted objects. Lexical representations are likewise partial, and phonological constraints are cast as generalizations in a lexical inheritance hierarchy or in a prosodic inheritance hierarchy. When set against the background of constraint-based grammar, this intensional approach is quite natural (cf. Johnson [19881). Moreove</context>
<context position="12481" citStr="Bird 1992" startWordPosition="1821" endWordPosition="1822">ressed in a sign-oriented approach. In other frameworks it is common practice to avoid direct reference to phonology by invoking a morpho-syntactic FOCUS feature (e.g. Selkirk 1984; Rooth 1985); the mediation of syntax in this way appears to be more an artifact of the grammar architecture than an independently motivated requirement. Equally, it has been argued that the phenomenon of heavy NP shift is a kind of syntaxphonology interaction that is simply stated in a constraint-based approach, where the linear precedence constraints of syntax are sensitive to the phonological category of weight (Bird 1992). 1.3 Theoretical Framework Typed feature structures (Carpenter 1992) impose a type discipline on constraint-based grammar formalisms. A partial ordering over the types gives rise to an inheritance hierarchy of constraints. As Emele and Zajac (1990) point out, this object-oriented approach brings a number of advantages to grammar writing, such as a high level of abstraction, inferential capacity and modularity. On the face of it, such benefits should extend beyond syntax—to phonology for example. Although there have been some valuable efforts to exploit inheritance and type hierarchies within </context>
<context position="75017" citStr="Bird (1992)" startWordPosition="12194" endWordPosition="12195"> automata for string manipulation. This is simply because we favor the use of existing well-understood technology when it comes to producing an efficient implementation. As we have already explained in Section 1.4, we have linguistic reasons for not wishing to use finite-state transducers and the concomitant two-level model, and instead are interested in exploring the prospects of integrating our work with the automaton model of Bird and Ellison (1994). In this section we give an overview of this automaton model and briefly outline the view of automata as types that was originally proposed in Bird (1992). 6.1 One-Level Phonology For a variety of reasons already laid out in Section 1, we would like to achieve a closer integration between phonology and constraint-based grammar frameworks like HPSG. However, for such an integration to work, it is necessary to adopt a rather unusual view of phonology; one characterized by such notions as compositionality, intensionality, and lexicalism, and which has come to be called constraint-based phonology (Bird 1990). Recently, Bird and Ellison (1994) have reinterpreted the constraint-based approach to phonology using finite-state automata. Nonlinear phonol</context>
</contexts>
<marker>Bird, 1992</marker>
<rawString>Bird, S. (1992). &amp;quot;Finite-state phonology in HPSG.&amp;quot; In Proceedings of the 14th International Conference on Computational Linguistics (COLING-92). 74-80.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Bird</author>
<author>T M Ellison</author>
</authors>
<title>One-level phonology: Autosegmental representations and rules as finite automata.&amp;quot;</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<volume>20</volume>
<pages>55--90</pages>
<contexts>
<context position="18690" citStr="Bird and Ellison 1994" startWordPosition="2823" endWordPosition="2826">n some notable recent attempts to rescue the FST model from its linearity in order to encompass nonlinear phonology (Kay 1987; Kornai 1991; Wiebe 1992). However, from our perspective, these refinements to the FST model still admit unwarranted operations on phonological representations, as well as rule conspiracies and the like. Rather, we believe a more constrained and linguistically appealing approach is to employ finite-state automata (FsAs) in preference to FSTs, since it has been shown how FSAs can encode autosegmental representations and a variety of constraints on those representations (Bird and Ellison 1994). The leading idea in this work is that each tier is a partial description of a string, and tiers are put together using the intersection operation defined on FSAs. Apart from being truer to current phonological theorizing, this one-level model has a second important advantage over the two-level model. Since the set of FsAs forms a Boolean lattice under intersection, union, and complement (a direct consequence of the standard closure properties for regular languages), we can safely conjoin (&apos;unify&apos;), disjoin, and negate phonological descriptions. Such a framework is obviously compatible with c</context>
<context position="74862" citStr="Bird and Ellison (1994)" startWordPosition="12165" endWordPosition="12168">. While we like this approach for the purposes of specification and exposition, as stated in Section 1.4, we actually envisage an implementation employing finite-state automata for string manipulation. This is simply because we favor the use of existing well-understood technology when it comes to producing an efficient implementation. As we have already explained in Section 1.4, we have linguistic reasons for not wishing to use finite-state transducers and the concomitant two-level model, and instead are interested in exploring the prospects of integrating our work with the automaton model of Bird and Ellison (1994). In this section we give an overview of this automaton model and briefly outline the view of automata as types that was originally proposed in Bird (1992). 6.1 One-Level Phonology For a variety of reasons already laid out in Section 1, we would like to achieve a closer integration between phonology and constraint-based grammar frameworks like HPSG. However, for such an integration to work, it is necessary to adopt a rather unusual view of phonology; one characterized by such notions as compositionality, intensionality, and lexicalism, and which has come to be called constraint-based phonology</context>
<context position="76487" citStr="Bird and Ellison (1994)" startWordPosition="12419" endWordPosition="12422"> as overlap between intervals with duration (Bird and Klein 1990), then the overlap can be simulated by using synchronization primitives on automata. Figure 4 illustrates this idea. The diagram on the left of Figure 4 shows two temporal intervals x and y that overlap during the shaded period. On the right, the intervals x and y themselves are represented as sequences of contiguous tape cells where each cell contains a copy of the appropriate information (here, simply repeats of x and y). Again, the shaded period indicates the period of &apos;overlap&apos; of the two intervals. The reader is referred to Bird and Ellison (1994) for further details. Although this kind of phonology employs formal devices very similar to the twolevel FST model, there are some important differences in how the two models are used. In the two-level model the traditional distinction in phonology between RULES and REPRESENTATIONS is evident in the transducers and tapes respectively. As in constraintbased grammar more generally, one-level phonology does not have this distinction; rules and representations alike are interpreted as automata. Figure 5 illustrates this difference. Now that we have outlined the one-level model and briefly discuss</context>
</contexts>
<marker>Bird, Ellison, 1994</marker>
<rawString>Bird, S., and Ellison, T. M. (1994). &amp;quot;One-level phonology: Autosegmental representations and rules as finite automata.&amp;quot; Computational Linguistics, 20, 55-90.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Bird</author>
<author>E Klein</author>
</authors>
<title>Phonological events.&amp;quot;</title>
<date>1990</date>
<journal>Journal of Linguistics,</journal>
<volume>26</volume>
<pages>33--56</pages>
<contexts>
<context position="6024" citStr="Bird and Klein 1990" startWordPosition="865" endWordPosition="868">ndeterminacy). When a clear theoretical statement can be found, it is usually expressed in procedural terms, which clouds the empirical ramifications making a theory difficult to falsify. Finally, even when explicit and nonprocedural generalizations are found, they are commonly stated in a nonlinear model, which clearly goes beyond the assumptions about phonology made in HPSG as it currently stands. We approach these challenges by adopting a formal, nonprocedural, nonlinear model of phonology and showing how it can be integrated into HPSG, following on the heels of recent work by the authors (Bird and Klein 1990; Bird 1992; Klein 1992). One of the starting assumptions of this work is that phonological representations are intensional, i.e. each representation is actually a description of a class of utterances. Derivations progress by refining descriptions, further constraining the class of denoted objects. Lexical representations are likewise partial, and phonological constraints are cast as generalizations in a lexical inheritance hierarchy or in a prosodic inheritance hierarchy. When set against the background of constraint-based grammar, this intensional approach is quite natural (cf. Johnson [1988</context>
<context position="75929" citStr="Bird and Klein 1990" startWordPosition="12325" endWordPosition="12328">nology; one characterized by such notions as compositionality, intensionality, and lexicalism, and which has come to be called constraint-based phonology (Bird 1990). Recently, Bird and Ellison (1994) have reinterpreted the constraint-based approach to phonology using finite-state automata. Nonlinear phonological representations and 486 Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systems Figure 4 Two views of autosegmental association. rules are encoded as automata. The key insight is that if autosegmental association is viewed as overlap between intervals with duration (Bird and Klein 1990), then the overlap can be simulated by using synchronization primitives on automata. Figure 4 illustrates this idea. The diagram on the left of Figure 4 shows two temporal intervals x and y that overlap during the shaded period. On the right, the intervals x and y themselves are represented as sequences of contiguous tape cells where each cell contains a copy of the appropriate information (here, simply repeats of x and y). Again, the shaded period indicates the period of &apos;overlap&apos; of the two intervals. The reader is referred to Bird and Ellison (1994) for further details. Although this kind o</context>
</contexts>
<marker>Bird, Klein, 1990</marker>
<rawString>Bird, S., and Klein, E. (1990). &amp;quot;Phonological events.&amp;quot; Journal of Linguistics, 26, 33-56.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Bird</author>
<author>D R Ladd</author>
</authors>
<title>Presenting autosegmental phonology.&amp;quot;</title>
<date>1991</date>
<journal>Journal of Linguistics,</journal>
<volume>27</volume>
<pages>193--210</pages>
<contexts>
<context position="5161" citStr="Bird and Ladd (1991)" startWordPosition="743" endWordPosition="746"> with a concatenation operation. How far would such representations have to be enriched if we wanted to accommodate a more thoroughgoing treatment of phonology? As remarked earlier, recent work in theoretical phonology has apparently moved closer to a constraint-based perspective, and is thus a promising starting point for our investigation. Yet there are at least three challenges that confront anyone looking into theoretical phonology from the viewpoint of computational linguistics. Most striking perhaps is the relative informality of the language in which theoretical statements are couched. Bird and Ladd (1991) have catalogued several examples of this: notational ambiguity (incoherence), definition by example (informality), variable interpretation of notation depending on subjective criteria (inconsistency), and uncertainty about empirical content (indeterminacy). When a clear theoretical statement can be found, it is usually expressed in procedural terms, which clouds the empirical ramifications making a theory difficult to falsify. Finally, even when explicit and nonprocedural generalizations are found, they are commonly stated in a nonlinear model, which clearly goes beyond the assumptions about </context>
</contexts>
<marker>Bird, Ladd, 1991</marker>
<rawString>Bird, S., and Ladd, D. R. (1991). &amp;quot;Presenting autosegmental phonology.&amp;quot; Journal of Linguistics, 27, 193-210.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Bloomfield</author>
</authors>
<title>A set of postulates for the science of language.&amp;quot;</title>
<date>1926</date>
<journal>Language,</journal>
<volume>2</volume>
<pages>153--164</pages>
<note>Reprinted in Readings in Linguistics</note>
<contexts>
<context position="64049" citStr="Bloomfield (1926)" startWordPosition="10343" endWordPosition="10344">d there is no use of destructive processes. Tranel&apos;s analysis is fully declarative. However, as it happens, there is no need for us to adopt the rich representation Tranel employs. We can simulate his analysis using a single tier (rather than two) while retaining a representation of syllable structure. Observe that the use of the CV tier and the melody tier was motivated solely by the need to have a floating autosegment, the ce. It is equivalent to collapse these two tiers, using the alternation ce-0 in place of the floating ce. This style of approach to zero alternations, which dates back to Bloomfield (1926), will employ the parenthesis notation for optional items that was defined in Section 2.1. We follow Tranel in representing syllable structure and we shall do this using the notation shown in (52).16 16 Our analysis is not crucially tied to this particular version of syllable structure, which is most closely related to the proposals of Kahn (1976) and Clements and Keyser (1983). 481 Computational Linguistics Volume 20, Number 3 Example 52 ONS: onset NUC: nucleus CODA: coda syl An independent tier that represents syllable structure will be encoded as a sequence of such syllables, where the segm</context>
</contexts>
<marker>Bloomfield, 1926</marker>
<rawString>Bloomfield, L. (1926). &amp;quot;A set of postulates for the science of language.&amp;quot; Language, 2, 153-164. Reprinted in Readings in Linguistics I: The Development of Descriptive Linguistics in America 1925-56, edited by Martin Joos. 26-31.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Briscoe</author>
</authors>
<title>Lexical issues in natural language processing.&amp;quot;</title>
<date>1991</date>
<booktitle>In Natural Language and Speech,</booktitle>
<pages>39--68</pages>
<publisher>Springer-Verlag.</publisher>
<note>edited by</note>
<contexts>
<context position="11004" citStr="Briscoe (1991)" startWordPosition="1604" endWordPosition="1605">logical representations as one of the constraints in a sign-based grammar framework. To begin with, it is relatively uncontroversial that morphology needs to be interfaced with both syntax and phonology. Approaches like that of Krieger and Nerbonne (in press) have shown that both derivational and inflectional morphology can be usefully expressed within the constraint-based paradigm. Taking the further step of adding phonology seems equally desirable. Second, the use of typed feature structures within the lexicon has been strongly 457 Computational Linguistics Volume 20, Number 3 argued for by Briscoe (1991) and Copestake et al. (in press). That is, even when we ignore syntactic combination, constraint-based grammar frameworks turn out to be well suited to expressing the category and semantic information fields of lexical entries. But the interaction of phonology with categorial information inside the lexicon is well documented. Lexical phonology (Kiparsky 1982) has shown in detail how phonological phenomena are conditioned by morphologically specified domains. If direct interaction between phonology and morpho-syn tax is prohibited, one can only resort to ad hoc and poorly motivated diacritic fe</context>
</contexts>
<marker>Briscoe, 1991</marker>
<rawString>Briscoe, T. (1991). &amp;quot;Lexical issues in natural language processing.&amp;quot; In Natural Language and Speech, edited by E. Klein and F. Veltman, 39-68. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Bromberger</author>
<author>M Halle</author>
</authors>
<title>Why phonology is different.&amp;quot;</title>
<date>1989</date>
<journal>Linguistic Inquiry,</journal>
<volume>20</volume>
<pages>51--70</pages>
<contexts>
<context position="1717" citStr="Bromberger and Halle 1989" startWordPosition="244" endWordPosition="247">fy the approach in some detail for the nonconcatenative morphology of Sierra Miwok and for schwa alternation in French. The approach taken in this paper lends itself particularly well to capturing phonological generalizations in terms of high-level prosodic constraints. 1. Phonology in Constraint-Based Grammar Classical generative phonology is couched within the same set of assumptions that dominated standard transformational grammar. Despite some claims that &amp;quot;derivations based on ordered rules (that is, external ordering) and incorporating intermediate structures are essential to phonology&amp;quot; (Bromberger and Halle 1989:52), much recent work has tended toward a new model, frequently described in terms of constraints on well-formedness (Paradis 1988; Goldsmith 1993; McCarthy and Prince 1993; Prince and Smolensky 1993). While this work has an increasingly declarative flavor, most versions retain procedural devices for repairing representations that fail to meet certain constraints, or for constraints to override each other. This view is in marked contrast to the interpretation of constraints in grammar frameworks like LFG, GPSG, and HPSG1 and in constraint programming systems more generally (Jaffar and Lassez </context>
</contexts>
<marker>Bromberger, Halle, 1989</marker>
<rawString>Bromberger, S., and Halle, M. (1989). &amp;quot;Why phonology is different.&amp;quot; Linguistic Inquiry, 20, 51-70.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L J Cahill</author>
</authors>
<title>Syllable-based morphology.&amp;quot;</title>
<date>1990</date>
<booktitle>In Proceedings, 13th International Conference on Computational Linguistics, Volume 3, edited</booktitle>
<pages>48--53</pages>
<contexts>
<context position="6806" citStr="Cahill 1990" startWordPosition="975" endWordPosition="976">tion of a class of utterances. Derivations progress by refining descriptions, further constraining the class of denoted objects. Lexical representations are likewise partial, and phonological constraints are cast as generalizations in a lexical inheritance hierarchy or in a prosodic inheritance hierarchy. When set against the background of constraint-based grammar, this intensional approach is quite natural (cf. Johnson [19881). Moreover, some recent thinking on the phonology—phonetics interface supports this view (Pierrehumbert 1990; Coleman 2 (Bach and Wheeler 1981; Wheeler 1981; Bird 1990; Cahill 1990; Coleman 1991; Scobbie 1991; Bird 1992; Walther 1992; Mastroianni 1993; Russell 1993) 456 Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systems 1992). However, it represents a fundamental split with the generative tradition, where rules do not so much refine descriptions as alter the objects themselves (Keating 1984). While it is clearly possible to integrate an essentially generative model into the mold of constraint-based grammar (Krieger, Pirker, and Nerbonne 1993), it is less clear that this is the approach most phonologists would wish to take nowadays. It is becoming </context>
</contexts>
<marker>Cahill, 1990</marker>
<rawString>Cahill, L. J. (1990). &amp;quot;Syllable-based morphology.&amp;quot; In Proceedings, 13th International Conference on Computational Linguistics, Volume 3, edited by H. Karlgren, 48-53.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Carpenter</author>
</authors>
<title>The Logic of Typed Feature Structures. Volume 32 of Cambridge Tracts in Theoretical Computer Science.</title>
<date>1992</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="12550" citStr="Carpenter 1992" startWordPosition="1829" endWordPosition="1830">mmon practice to avoid direct reference to phonology by invoking a morpho-syntactic FOCUS feature (e.g. Selkirk 1984; Rooth 1985); the mediation of syntax in this way appears to be more an artifact of the grammar architecture than an independently motivated requirement. Equally, it has been argued that the phenomenon of heavy NP shift is a kind of syntaxphonology interaction that is simply stated in a constraint-based approach, where the linear precedence constraints of syntax are sensitive to the phonological category of weight (Bird 1992). 1.3 Theoretical Framework Typed feature structures (Carpenter 1992) impose a type discipline on constraint-based grammar formalisms. A partial ordering over the types gives rise to an inheritance hierarchy of constraints. As Emele and Zajac (1990) point out, this object-oriented approach brings a number of advantages to grammar writing, such as a high level of abstraction, inferential capacity and modularity. On the face of it, such benefits should extend beyond syntax—to phonology for example. Although there have been some valuable efforts to exploit inheritance and type hierarchies within phonology (e.g. Reinhard and Gibbon 1991), the potential of typed fea</context>
<context position="14276" citStr="Carpenter (1992)" startWordPosition="2112" endWordPosition="2113">e type sign has some SUBTYPES. If a is a subtype of T, then a provides at least as much information as T. A type declaration for sign defines it as the following disjunction of subtypes:3 Example 1 sign = morph V stem V word V phrase The second kind of declaration is an APPROPRIATENESS CONDITION. That is, for each type, we declare (all and only) the attributes for which it is specified, and additionally the types of values which those attributes can take.&apos; For example, objects of type sign 3 The constraints proposed here deviate in various respects from the standard version of HPSG. We follow Carpenter (1992) in using the notation o- cto specify that type cr satisfies constraint rk. 4 We are using what Carpenter (1992) calls TOTAL WELL-TYPING. That is, (i) the only attributes and values that can be specified for a given feature structure of type r are those appropriate for 7-; and (ii) every feature structure of type T must be specified for all attributes appropriate for . 458 Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systems could be constrained to have the following features defined: Example 2 [PHON : phon SYNSEM : synsem DTRS : list sign That is, feature structures of ty</context>
<context position="15877" citStr="Carpenter (1992)" startWordPosition="2380" endWordPosition="2381"> obeyed by sign. Moreover, as we shall see in Section 3.2, it is subject to some further appropriateness conditions that are not imposed on any of its supertypes. Continuing in the same vein, we can assign appropriateness conditions to the types synsem and phon that occurred as values in (2), (simplifying substantially from standard HPSG). Here we give the constraints for synsem. The type phon will be discussed in Section 2. Example 3 _ CAT: cat AGR: agr SUBCAT : list SEM : semantics - To conclude this section, we shall look very briefly at matters of interpretation and inference. As shown by Carpenter (1992) and Zajac (1992, in press), we can use constraint resolution to carry out type inference for feature terms. Following Zajac, let us say that a GROUND feature term is a term all of whose type symbols are minimal (i.e., the most specific types in the hierarchy immediately above 1). A WELL-TYPED feature term is one that obeys all the type definitions. Then the meaning of a feature term F is given by the set of all well-typed ground feature terms that are subsumed by F. Evaluating F, construed as a query, involves describing F&apos;s denotation; for example, enumerating all the well-typed ground featu</context>
</contexts>
<marker>Carpenter, 1992</marker>
<rawString>Carpenter, B. (1992). The Logic of Typed Feature Structures. Volume 32 of Cambridge Tracts in Theoretical Computer Science. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Clements</author>
</authors>
<title>The geometry of phonological features.&amp;quot;</title>
<date>1985</date>
<journal>Phonology Yearbook,</journal>
<volume>2</volume>
<pages>225--252</pages>
<contexts>
<context position="22380" citStr="Clements (1985" startWordPosition="3418" endWordPosition="3419">tations in the next section. 2.2 A Prosodic Type Hierarchy A PROSODIC TYPE HIERARCHY is a subsumption network akin to the lexical hierarchy of HPSG (Pollard and Sag 1987). The type constraints we have met so far can be used to define a type hierarchy, which for present purposes will be a Boolean lattice. In this section we present in outline form a prosodic hierarchy that subsequent analyses will be based on. Example (7) defines the high-level types in the hierarchy. Example 7 phon utterance v phrase V foot v syl v segment Each of these types may have further structure. For example, following Clements (1985:248) we may wish to classify segments in terms of their place and manner of articulation, using the following appropriateness declaration. 461 Computational Linguistics Volume 20, Number 3 Example 8 LARYNGEAL: SPREAD : boolean boolean CONSTRICTED: boolean VOICED : boolean NASAL : MANNER: CONTINUANT: boolean STRIDENT: boolean [ SUPRALARYNGEAL: CORONAL: boolean PLACE : ANTERIOR: boolean DISTRIBUTED: boolean segment Suppose now that we wished to use these structures in a constraint for English homorganic nasal assimilation. This phenomenon does not occur across phonological phrase boundaries and</context>
</contexts>
<marker>Clements, 1985</marker>
<rawString>Clements, G. (1985). &amp;quot;The geometry of phonological features.&amp;quot; Phonology Yearbook, 2, 225-252.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G N Clements</author>
<author>S J Keyser</author>
</authors>
<title>CV Phonology: A Generative Theory of the Syllable.</title>
<date>1983</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="64429" citStr="Clements and Keyser (1983)" startWordPosition="10403" endWordPosition="10406">ed solely by the need to have a floating autosegment, the ce. It is equivalent to collapse these two tiers, using the alternation ce-0 in place of the floating ce. This style of approach to zero alternations, which dates back to Bloomfield (1926), will employ the parenthesis notation for optional items that was defined in Section 2.1. We follow Tranel in representing syllable structure and we shall do this using the notation shown in (52).16 16 Our analysis is not crucially tied to this particular version of syllable structure, which is most closely related to the proposals of Kahn (1976) and Clements and Keyser (1983). 481 Computational Linguistics Volume 20, Number 3 Example 52 ONS: onset NUC: nucleus CODA: coda syl An independent tier that represents syllable structure will be encoded as a sequence of such syllables, where the segmental constituents of the syllable structure are coindexed with a separate segmental tier, as defined in (53). Note that the indices in (53) range over lists that may be empty in the case of onsets and codas, and that the type phrase denotes phonological phrases. Example 53 a. SYLS : ( syl ONS: [d NUC: CODA: [SYLS : SEGS: phrase 5 b. SEGS: phrase [SYLS : SEGS : phrase 3 The not</context>
</contexts>
<marker>Clements, Keyser, 1983</marker>
<rawString>Clements, G. N., and Keyser, S. J. (1983). CV Phonology: A Generative Theory of the Syllable. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J S Coleman</author>
</authors>
<title>Phonological representations-their names, forms and powers. Doctoral dissertation,</title>
<date>1991</date>
<institution>University of York.</institution>
<contexts>
<context position="6820" citStr="Coleman 1991" startWordPosition="977" endWordPosition="978">ss of utterances. Derivations progress by refining descriptions, further constraining the class of denoted objects. Lexical representations are likewise partial, and phonological constraints are cast as generalizations in a lexical inheritance hierarchy or in a prosodic inheritance hierarchy. When set against the background of constraint-based grammar, this intensional approach is quite natural (cf. Johnson [19881). Moreover, some recent thinking on the phonology—phonetics interface supports this view (Pierrehumbert 1990; Coleman 2 (Bach and Wheeler 1981; Wheeler 1981; Bird 1990; Cahill 1990; Coleman 1991; Scobbie 1991; Bird 1992; Walther 1992; Mastroianni 1993; Russell 1993) 456 Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systems 1992). However, it represents a fundamental split with the generative tradition, where rules do not so much refine descriptions as alter the objects themselves (Keating 1984). While it is clearly possible to integrate an essentially generative model into the mold of constraint-based grammar (Krieger, Pirker, and Nerbonne 1993), it is less clear that this is the approach most phonologists would wish to take nowadays. It is becoming increasingly a</context>
</contexts>
<marker>Coleman, 1991</marker>
<rawString>Coleman, J. S. (1991). Phonological representations-their names, forms and powers. Doctoral dissertation, University of York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J S Coleman</author>
</authors>
<title>The phonetic interpretation of headed phonological structures containing overlapping constituents.&amp;quot;</title>
<date>1992</date>
<journal>Phonology,</journal>
<volume>9</volume>
<pages>1--44</pages>
<marker>Coleman, 1992</marker>
<rawString>Coleman, J. S. (1992). &amp;quot;The phonetic interpretation of headed phonological structures containing overlapping constituents.&amp;quot; Phonology, 9, 1-44.</rawString>
</citation>
<citation valid="false">
<authors>
<author>A Copestake</author>
<author>A Sanfilippo</author>
<author>T Briscoe</author>
<author>V de Paiva</author>
</authors>
<title>The ACQUILEX LK13: An introduction.&amp;quot; In Default Inheritance in Unification Based Approaches to the Lexicon, edited by</title>
<publisher>Cambridge University Press.</publisher>
<marker>Copestake, Sanfilippo, Briscoe, de Paiva, </marker>
<rawString>Copestake, A.; Sanfilippo, A.; Briscoe, T.; and de Paiva, V. (in press). &amp;quot;The ACQUILEX LK13: An introduction.&amp;quot; In Default Inheritance in Unification Based Approaches to the Lexicon, edited by T. Briscoe, A. Copestake, and V. de Paiva. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Dell</author>
</authors>
<title>Generative Phonology and French Phonology.</title>
<date>1980</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="53625" citStr="Dell, 1980" startWordPosition="8614" endWordPosition="8615">the underlying representation /sku/ where no vowel appears between /s/ and /k/, and to assume that there exists a phonological rule of epenthesis that inserts a vowel ce between two consonants at the beginning of a word when the preceding word ends in a consonant. ... The second possibility is preferable: the vowel [cel that appears in Jacques secoue is the realisation of an underlying vowel /a/ which can be deleted in certain cases. We shall posit the vcEi rule, which deletes any /a/ preceded by a single word-initial consonant when the preceding word ends in a vowel. VCEi: a--4 0 / V #1 C — (Dell, 1980:1610 Suppose we were to begin our analysis by asking the question: how are we to express the generalization about schwa expressed in the above rule? Since our declarative, monostratal framework does not admit deletion rules, we would have to give up. As we shall see below, however, we begin with a different question: how are we to express the observation about the distribution of schwa that Dell encodes in the above rule? There is another good reason for taking this line. As it happens, there is an empirical problem with the above rule, which Dell addresses by admitting a potentially large nu</context>
<context position="55865" citStr="Dell 1980" startWordPosition="8986" endWordPosition="8987">ice, namely rule ordering, in the application of the rule. In discussing the phrase vous me le dites [vu.m(ce).1(ce).dit], in which either schwa (but not both) may be omitted, Dell writes: vcEi begins on the left and first deletes the schwa of me, producing /vu#m#1a#dit/. But vcEi cannot operate again and delete the schwa of le, for, although this schwa was subject to the rule in the original representation, it no longer is once the schwa of me has been dropped. In other words, the first application of vcEi creates new conditions that prevent it from operating again in the following syllable (Dell 1980:228). Again, we are not interested in encoding Dell&apos;s particular generalization, and in fact we are unable to. Rather, it is necessary to look at the underlying observation about the distribution of schwa. The observation is that schwa does not appear as its zero allophone in consecutive syllables. This observation is problematic for us, in that it refers to two levels of representation, an underlying (or lexical) level involving a schwa segment, and a surface level involving a zero allophone. We cannot formulate this observation monostratally. However, we can come up with a different observa</context>
</contexts>
<marker>Dell, 1980</marker>
<rawString>Dell, F. (1980). Generative Phonology and French Phonology. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M C Emele</author>
<author>R Zajac</author>
</authors>
<title>Typed unification grammars.&amp;quot;</title>
<date>1990</date>
<booktitle>In Proceedings, 13th International Conference on Computational Linguistics.</booktitle>
<pages>293--298</pages>
<contexts>
<context position="12730" citStr="Emele and Zajac (1990)" startWordPosition="1854" endWordPosition="1857">s to be more an artifact of the grammar architecture than an independently motivated requirement. Equally, it has been argued that the phenomenon of heavy NP shift is a kind of syntaxphonology interaction that is simply stated in a constraint-based approach, where the linear precedence constraints of syntax are sensitive to the phonological category of weight (Bird 1992). 1.3 Theoretical Framework Typed feature structures (Carpenter 1992) impose a type discipline on constraint-based grammar formalisms. A partial ordering over the types gives rise to an inheritance hierarchy of constraints. As Emele and Zajac (1990) point out, this object-oriented approach brings a number of advantages to grammar writing, such as a high level of abstraction, inferential capacity and modularity. On the face of it, such benefits should extend beyond syntax—to phonology for example. Although there have been some valuable efforts to exploit inheritance and type hierarchies within phonology (e.g. Reinhard and Gibbon 1991), the potential of typed feature structures for this area has barely been scratched so far. In this section, we present a brief overview of HPSG (Pollard and Sag 1987), a constraint-based grammar formalism bu</context>
</contexts>
<marker>Emele, Zajac, 1990</marker>
<rawString>Emele, M. C., and Zajac, R. (1990). &amp;quot;Typed unification grammars.&amp;quot; In Proceedings, 13th International Conference on Computational Linguistics. 293-298.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Gazdar</author>
<author>E Klein</author>
<author>G Pullum</author>
<author>I Sag</author>
</authors>
<title>Generalized Phrase Structure Grammar.</title>
<date>1985</date>
<publisher>Blackwell.</publisher>
<marker>Gazdar, Klein, Pullum, Sag, 1985</marker>
<rawString>Gazdar, G.; Klein, E.; Pullum, G.; and Sag, I. (1985). Generalized Phrase Structure Grammar. Blackwell.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Goldsmith</author>
</authors>
<title>Autosegmental and Metrical Phonology.</title>
<date>1990</date>
<publisher>Blackwell.</publisher>
<contexts>
<context position="37085" citStr="Goldsmith (1990)" startWordPosition="5850" endWordPosition="5851">he context of extended Montague frameworks by Wheeler (1981) and Hoeksema and Janda (1988). 468 Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systems insights from autosegmental phonology. However, they are captured within constraintbased grammar where the inflectional paradigm is realized as an inheritance hierarchy of partially instantiated stem forms (cf. Reinhard and Gibbon [1991]). We also show that autosegmental association of consonants and vowels to a skeleton can be modeled by reentrancy. Rather than classical Arabic, we use the simpler data from Sierra Miwok that Goldsmith (1990) chose to illustrate the phenomenon of intercalation in his textbook. This section is divided into four subsections. In Section 4.1 we present an overview of the data, and in Section 4.2 we briefly show what a traditional generative analysis might look like. Our encoding of association by reentrancy is given in Section 4.3, while Section 4.4 contains our constraint-based analysis of Sierra Miwok stem forms. 4.1 Descriptive Overview As mentioned above, Goldsmith (1990) takes data from Sierra Miwok verb stems to illustrate morphologically determined alternations in skeletal structure. He discuss</context>
<context position="38985" citStr="Goldsmith (1990)" startWordPosition="6167" endWordPosition="6168">only relevant to so-called Basic stem forms. k u CC V m 469 Computational Linguistics Second stem Third stem Volume 20, Number 3 Example 26 Fourth stem Gloss Basic stem Type I kicaaw kicaww kiccaw kicwa bleed jump tuyaau tuyaDD tuyyaD tuyu a take patiit patitt pattit patti roll huteel hutell huttel hutle Type II celku celuld( celluk celku quit go home wo?lu wo?ull wo??ul wo?lu catch up with nakpa nakapp nakkap nakpa spear wimki wimikk wimmik wimki Type III hamme hamen hamme? ham?e bury dive ?uppi ?upin ?uppi? speak liwwa liwan liwwa? liw?a sing milli mili?? milli? mil?i 4.2 Segmental Analysis Goldsmith (1990) has shown just how complex a traditional segmental account of Sierra Miwok would have to be, given the assumption that all of the stem forms are derived by rule from a single underlying string of segments (e.g. that kicaww, kiccaw and kicwa are all derived from kicaaw). Here, we simplify Goldsmith&apos;s analysis so that it just works for Type I stems. The left-hand column of (27) contains four rules, and these are restricted to the different forms according to the second column. Example 27 Form Second Third Fourth Rules kicaaw kicaaw kicaaw vi-40/C—ViC] all kicaw kicaw kicaw C,-&gt;C,CACV—V 2 kicaww</context>
<context position="40482" citStr="Goldsmith 1990" startWordPosition="6417" endWordPosition="6418">nalysis in favor of an autosegmental one: This analysis, with all its morphologically governed phonological rules, arbitrary rule ordering, and, frankly, its mind-boggling inelegance, ironically misses the most basic point of the formation of the past tense in Sierra Miwok. As we have informally noted, all the second 470 Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systems stem forms are of the shape CVCVCC, with the last consonant a geminate, and the rules that we have hypothetically posited so far all endeavor to achieve that end without ever directly acknowledging it. (Goldsmith 1990:87) 4.3 Association We shall not attempt here to give a general encoding of association, although the technique used in Sections 5.4 could be applied to achieve this end. Moreover, like Goldsmith we shall ignore the role of syllable structure in the data, though it clearly does play a role. Instead, we shall confine our attention to the manner in which skeletal slots are linked to the consonant and vowel melodies. Consider again the skeletal structure of Type I verb stems shown in (25a). As Goldsmith (1990) points out, there is a closely related representation that differs only in that the CV</context>
</contexts>
<marker>Goldsmith, 1990</marker>
<rawString>Goldsmith, J. (1990). Autosegmental and Metrical Phonology. Blackwell.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J A Goldsmith</author>
</authors>
<title>Harmonic phonology.&amp;quot; In The Last Phonological Rule: Reflections on Constraints and Derivations,</title>
<date>1993</date>
<pages>21--60</pages>
<publisher>University of Chicago Press.</publisher>
<note>edited by</note>
<contexts>
<context position="1864" citStr="Goldsmith 1993" startWordPosition="268" endWordPosition="269"> itself particularly well to capturing phonological generalizations in terms of high-level prosodic constraints. 1. Phonology in Constraint-Based Grammar Classical generative phonology is couched within the same set of assumptions that dominated standard transformational grammar. Despite some claims that &amp;quot;derivations based on ordered rules (that is, external ordering) and incorporating intermediate structures are essential to phonology&amp;quot; (Bromberger and Halle 1989:52), much recent work has tended toward a new model, frequently described in terms of constraints on well-formedness (Paradis 1988; Goldsmith 1993; McCarthy and Prince 1993; Prince and Smolensky 1993). While this work has an increasingly declarative flavor, most versions retain procedural devices for repairing representations that fail to meet certain constraints, or for constraints to override each other. This view is in marked contrast to the interpretation of constraints in grammar frameworks like LFG, GPSG, and HPSG1 and in constraint programming systems more generally (Jaffar and Lassez 1987; Smolka 1992). In such approaches, constraints cannot be circumvented, there are no &apos;intermediate structures,&apos; and the well-formedness constra</context>
</contexts>
<marker>Goldsmith, 1993</marker>
<rawString>Goldsmith, J. A. (1993). &amp;quot;Harmonic phonology.&amp;quot; In The Last Phonological Rule: Reflections on Constraints and Derivations, edited by J. A. Goldsmith, 21-60. University of Chicago Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hoeksema</author>
<author>R Janda</author>
</authors>
<title>Implications of process morphology for categorial grammar.&amp;quot;</title>
<date>1988</date>
<booktitle>In Categorial Grammars and Natural Language Structures,</booktitle>
<note>edited by</note>
<contexts>
<context position="36559" citStr="Hoeksema and Janda (1988)" startWordPosition="5770" endWordPosition="5773">oes not guarantee this without such an additional restriction. 4. Sierra Miwok Templatic Morphology Noncatenative morphology has featured centrally in the empirical motivations for autosegmental phonology, since McCarthy&apos;s demonstration that the intercalation of vowels in Arabic consonantal verb roots could be elegantly handled within this framework (McCarthy 1981). This section presents an approach to intercalation that uses key 10 This approach of using restructuring devices in the process of a derivation has been explored in the context of extended Montague frameworks by Wheeler (1981) and Hoeksema and Janda (1988). 468 Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systems insights from autosegmental phonology. However, they are captured within constraintbased grammar where the inflectional paradigm is realized as an inheritance hierarchy of partially instantiated stem forms (cf. Reinhard and Gibbon [1991]). We also show that autosegmental association of consonants and vowels to a skeleton can be modeled by reentrancy. Rather than classical Arabic, we use the simpler data from Sierra Miwok that Goldsmith (1990) chose to illustrate the phenomenon of intercalation in his textbook. This</context>
</contexts>
<marker>Hoeksema, Janda, 1988</marker>
<rawString>Hoeksema, J., and Janda, R. (1988). &amp;quot;Implications of process morphology for categorial grammar.&amp;quot; In Categorial Grammars and Natural Language Structures, edited by R. T. Oehrle, E. Bach, and D. W. Wheeler, 199-247. Reidel.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hooper</author>
</authors>
<title>An Introduction to Natural Generative Phonology.</title>
<date>1976</date>
<publisher>Academic Press.</publisher>
<contexts>
<context position="8017" citStr="Hooper 1976" startWordPosition="1151" endWordPosition="1152">increasingly apparent that rule-based relationships between surface forms and hypothetical lexical forms are unable to capture important generalizations about surface forms. This concern was voiced early in the history of generative phonology, when Kisseberth (1970) complained that such rules regularly conspire to achieve particular surface configurations, but are unable to express the most elementary observations about what those surface configurations are. As a criticism of rule-based systems, Kisseberth&apos;s complaint remains valid and has been echoed several times since then (Shibatani 1973; Hooper 1976; Hudson 1980; Manaster Ramer 1981). However, recent work in phonology has moved away from models involving rules that relate lexical and surface forms toward models involving general systems of interacting constraints, where this problem has been side-stepped. Accordingly, we avoid the theoretical framework of early generative phonology, focusing instead on encoding phonological constraints in a constraint-based grammar framework. We present an overview of the grammar framework in the next section. 1.2 Motivation At this point, we should briefly address the question: What is gained by integra</context>
</contexts>
<marker>Hooper, 1976</marker>
<rawString>Hooper, J. (1976). An Introduction to Natural Generative Phonology. Academic Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Hudson</author>
</authors>
<title>Automatic alternations in non-transformational phonology&amp;quot;</title>
<date>1980</date>
<journal>Language,</journal>
<volume>56</volume>
<pages>94--125</pages>
<contexts>
<context position="8030" citStr="Hudson 1980" startWordPosition="1153" endWordPosition="1154">apparent that rule-based relationships between surface forms and hypothetical lexical forms are unable to capture important generalizations about surface forms. This concern was voiced early in the history of generative phonology, when Kisseberth (1970) complained that such rules regularly conspire to achieve particular surface configurations, but are unable to express the most elementary observations about what those surface configurations are. As a criticism of rule-based systems, Kisseberth&apos;s complaint remains valid and has been echoed several times since then (Shibatani 1973; Hooper 1976; Hudson 1980; Manaster Ramer 1981). However, recent work in phonology has moved away from models involving rules that relate lexical and surface forms toward models involving general systems of interacting constraints, where this problem has been side-stepped. Accordingly, we avoid the theoretical framework of early generative phonology, focusing instead on encoding phonological constraints in a constraint-based grammar framework. We present an overview of the grammar framework in the next section. 1.2 Motivation At this point, we should briefly address the question: What is gained by integrating phonolog</context>
</contexts>
<marker>Hudson, 1980</marker>
<rawString>Hudson, G. (1980). &amp;quot;Automatic alternations in non-transformational phonology&amp;quot; Language, 56, 94-125.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Jaffar</author>
<author>J-L Lassez</author>
</authors>
<title>Constraint logic programming.&amp;quot;</title>
<date>1987</date>
<booktitle>In ACM Symposium on Principles of Programming Languages,</booktitle>
<pages>111--119</pages>
<contexts>
<context position="2321" citStr="Jaffar and Lassez 1987" startWordPosition="333" endWordPosition="336">ger and Halle 1989:52), much recent work has tended toward a new model, frequently described in terms of constraints on well-formedness (Paradis 1988; Goldsmith 1993; McCarthy and Prince 1993; Prince and Smolensky 1993). While this work has an increasingly declarative flavor, most versions retain procedural devices for repairing representations that fail to meet certain constraints, or for constraints to override each other. This view is in marked contrast to the interpretation of constraints in grammar frameworks like LFG, GPSG, and HPSG1 and in constraint programming systems more generally (Jaffar and Lassez 1987; Smolka 1992). In such approaches, constraints cannot be circumvented, there are no &apos;intermediate structures,&apos; and the well-formedness constraint (Partee 1979) is observed (i.e. ill-formed representations can never be created). The advantage of these frameworks is that they allow interesting linguistic analyses to be encoded while remaining computationally tractable. * University of Edinburgh, Centre for Cognitive Science, 2 Buccleuch Place, Edinburgh EH8 9LW, U.K. steven.ewan@cogni.ed.ac.uk 1 Lexical Functional Grammar (Kaplan and Bresnan 1982), Generalized Phrase Structure Grammar (Gazdar, </context>
</contexts>
<marker>Jaffar, Lassez, 1987</marker>
<rawString>Jaffar, J., and Lassez, J.-L. (1987). &amp;quot;Constraint logic programming.&amp;quot; In ACM Symposium on Principles of Programming Languages, 111-119.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Johnson</author>
</authors>
<title>Attribute-value logic and the theory of grammar. Doctoral dissertation,</title>
<date>1988</date>
<institution>Stanford University.</institution>
<marker>Johnson, 1988</marker>
<rawString>Johnson, M. (1988). Attribute-value logic and the theory of grammar. Doctoral dissertation, Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Kahn</author>
</authors>
<title>Syllable-based Generalizations in English Phonology.</title>
<date>1976</date>
<institution>Indiana University Linguistics Club.</institution>
<contexts>
<context position="64398" citStr="Kahn (1976)" startWordPosition="10400" endWordPosition="10401">tier was motivated solely by the need to have a floating autosegment, the ce. It is equivalent to collapse these two tiers, using the alternation ce-0 in place of the floating ce. This style of approach to zero alternations, which dates back to Bloomfield (1926), will employ the parenthesis notation for optional items that was defined in Section 2.1. We follow Tranel in representing syllable structure and we shall do this using the notation shown in (52).16 16 Our analysis is not crucially tied to this particular version of syllable structure, which is most closely related to the proposals of Kahn (1976) and Clements and Keyser (1983). 481 Computational Linguistics Volume 20, Number 3 Example 52 ONS: onset NUC: nucleus CODA: coda syl An independent tier that represents syllable structure will be encoded as a sequence of such syllables, where the segmental constituents of the syllable structure are coindexed with a separate segmental tier, as defined in (53). Note that the indices in (53) range over lists that may be empty in the case of onsets and codas, and that the type phrase denotes phonological phrases. Example 53 a. SYLS : ( syl ONS: [d NUC: CODA: [SYLS : SEGS: phrase 5 b. SEGS: phrase </context>
</contexts>
<marker>Kahn, 1976</marker>
<rawString>Kahn, D. (1976). Syllable-based Generalizations in English Phonology. Indiana University Linguistics Club.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R M Kaplan</author>
<author>J Bresnan</author>
</authors>
<title>Lexical-Functional Grammar: A formal system for grammatical representation.&apos;&apos;</title>
<date>1982</date>
<booktitle>In The Mental Representation of Grammatical Relations, edited</booktitle>
<publisher>MIT Press.</publisher>
<contexts>
<context position="2873" citStr="Kaplan and Bresnan 1982" startWordPosition="405" endWordPosition="408">in constraint programming systems more generally (Jaffar and Lassez 1987; Smolka 1992). In such approaches, constraints cannot be circumvented, there are no &apos;intermediate structures,&apos; and the well-formedness constraint (Partee 1979) is observed (i.e. ill-formed representations can never be created). The advantage of these frameworks is that they allow interesting linguistic analyses to be encoded while remaining computationally tractable. * University of Edinburgh, Centre for Cognitive Science, 2 Buccleuch Place, Edinburgh EH8 9LW, U.K. steven.ewan@cogni.ed.ac.uk 1 Lexical Functional Grammar (Kaplan and Bresnan 1982), Generalized Phrase Structure Grammar (Gazdar, Klein, Pullum, and Sag 1985), and Head-Driven Phrase Structure Grammar (Pollard and Sag 1987). © 1994 Association for Computational Linguistics Computational Linguistics Volume 20, Number 3 Here, we are interested in the question of what a theory of phonology ought to look like if it is to be compatible with a constraint-based grammar framework. This issue has already received attention,&apos; although a thoroughgoing integration of phonology into constraint-based grammars has yet to be attempted. To ease exposition, we shall take HPSG as a suitably r</context>
</contexts>
<marker>Kaplan, Bresnan, 1982</marker>
<rawString>Kaplan, R. M., and Bresnan, J. (1982). &amp;quot;Lexical-Functional Grammar: A formal system for grammatical representation.&apos;&apos; In The Mental Representation of Grammatical Relations, edited by J. Bresnan. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R T Kasper</author>
<author>W C Rounds</author>
</authors>
<title>A logical semantics for feature structures.&amp;quot;</title>
<date>1986</date>
<booktitle>In Proceedings, 24th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<pages>257--266</pages>
<contexts>
<context position="78974" citStr="Kasper and Rounds 1986" startWordPosition="12807" endWordPosition="12810">e declared as the appropriate values for certain attributes in a typed feature system, string types are only declared in terms of the basic alphabet and other string types. It is not possible to employ non-string types in the definition of string types. This is a severe restriction, since list types (say, in HPSG) allow arbitrary feature structures as elements, and we would like to be able to do the same for string types. Work on overcoming this limitation is currently in progress, and builds on the well-known similarity between feature structures and automata, when viewed as directed graphs (Kasper and Rounds 1986). 7. Conclusion In this paper, we have tried to give the reader an impression of how two rather different phonological phenomena can be given a declarative encoding in a constraint-based grammar. Although we have focused on phonology, we have also placed our analyses within a morphological context as befits the multi-dimensional perspective of HPSG. The formal framework of HPSG is rather powerful; certainly powerful enough to capture many analyses in the style of classical generative phonology in which arbitrary mappings are allowed between underlying and surface representations. We have limit</context>
</contexts>
<marker>Kasper, Rounds, 1986</marker>
<rawString>Kasper, R. T., and Rounds, W. C. (1986). &amp;quot;A logical semantics for feature structures.&amp;quot; In Proceedings, 24th Annual Meeting of the Association for Computational Linguistics. 257-266.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kay</author>
</authors>
<title>Nonconcatenative finite-state morphology.&amp;quot;</title>
<date>1987</date>
<booktitle>In Proceedings, Third Meeting of the European Chapter of the Association for Computational Linguistics.</booktitle>
<pages>2--10</pages>
<contexts>
<context position="18193" citStr="Kay 1987" startWordPosition="2751" endWordPosition="2752">ve comprehensive introductions to the field. The formalism is an attractive computational model for 1960s generative phonology. However, as has already been noted, phonologists have since moved away from complex string rewriting systems to a range of so-called nonlinear models of phonology. The central innovation of this more recent work is the idea that phonological representations are not strings but collections of strings, synchronized like an orchestral score. There have been some notable recent attempts to rescue the FST model from its linearity in order to encompass nonlinear phonology (Kay 1987; Kornai 1991; Wiebe 1992). However, from our perspective, these refinements to the FST model still admit unwarranted operations on phonological representations, as well as rule conspiracies and the like. Rather, we believe a more constrained and linguistically appealing approach is to employ finite-state automata (FsAs) in preference to FSTs, since it has been shown how FSAs can encode autosegmental representations and a variety of constraints on those representations (Bird and Ellison 1994). The leading idea in this work is that each tier is a partial description of a string, and tiers are p</context>
</contexts>
<marker>Kay, 1987</marker>
<rawString>Kay, M. (1987). &amp;quot;Nonconcatenative finite-state morphology.&amp;quot; In Proceedings, Third Meeting of the European Chapter of the Association for Computational Linguistics. 2-10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Keating</author>
</authors>
<title>Phonetic and phonological representation of stop consonant voicing.&amp;quot;</title>
<date>1984</date>
<journal>Language,</journal>
<volume>60</volume>
<pages>286--319</pages>
<contexts>
<context position="7145" citStr="Keating 1984" startWordPosition="1025" endWordPosition="1026">d of constraint-based grammar, this intensional approach is quite natural (cf. Johnson [19881). Moreover, some recent thinking on the phonology—phonetics interface supports this view (Pierrehumbert 1990; Coleman 2 (Bach and Wheeler 1981; Wheeler 1981; Bird 1990; Cahill 1990; Coleman 1991; Scobbie 1991; Bird 1992; Walther 1992; Mastroianni 1993; Russell 1993) 456 Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systems 1992). However, it represents a fundamental split with the generative tradition, where rules do not so much refine descriptions as alter the objects themselves (Keating 1984). While it is clearly possible to integrate an essentially generative model into the mold of constraint-based grammar (Krieger, Pirker, and Nerbonne 1993), it is less clear that this is the approach most phonologists would wish to take nowadays. It is becoming increasingly apparent that rule-based relationships between surface forms and hypothetical lexical forms are unable to capture important generalizations about surface forms. This concern was voiced early in the history of generative phonology, when Kisseberth (1970) complained that such rules regularly conspire to achieve particular surf</context>
</contexts>
<marker>Keating, 1984</marker>
<rawString>Keating, P. (1984). &amp;quot;Phonetic and phonological representation of stop consonant voicing.&amp;quot; Language, 60, 286-319.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kenstowicz</author>
<author>C Kisseberth</author>
</authors>
<title>Generative Phonology: Description and Theory.</title>
<date>1979</date>
<publisher>Academic Press.</publisher>
<contexts>
<context position="29241" citStr="Kenstowicz and Kisseberth 1979" startWordPosition="4576" endWordPosition="4579">le word), rather than lexical entries per se. In some languages we may require there to be a special kind of interaction between the lexical and the prosodic hierarchy. For example, Archangeli and Pulleyblank (1989) discuss the tongue root harmony of Yoruba, which is restricted to nouns. If atr (i.e. advanced tongue root) was the type of harmonic utterances, then we could express the necessary constraint thus: phon A atr SYNILOCIHEAD : [MAJ : noun] LEX : noun This kind of constraint is known as a morpheme structure constraint, and phonologists have frequently needed to have recourse to these (Kenstowicz and Kisseberth 1979). Another interaction between prosody and morphology is the phenomenon of prosodic morphology, an example of which can be found in Section 4. 3.2 Morphological Complexity Given the syntactic framework of HPSG, it seems tempting to handle morphological complexity in an analogous manner to syntactic complexity. That is, morphological heads would be analyzed as functors that subcategorize for arguments of the appropriate type, and morphemes would combine in a Word-Grammar scheme. Simplifying drastically, such an approach would analyze the English third person singular present suffix -s in the man</context>
</contexts>
<marker>Kenstowicz, Kisseberth, 1979</marker>
<rawString>Kenstowicz, M., and Kisseberth, C. (1979). Generative Phonology: Description and Theory. Academic Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Kiparsky</author>
</authors>
<title>Lexical Morphology and Phonology.</title>
<date>1982</date>
<publisher>Hanshin Publishing Co.</publisher>
<contexts>
<context position="11365" citStr="Kiparsky 1982" startWordPosition="1656" endWordPosition="1657">nstraint-based paradigm. Taking the further step of adding phonology seems equally desirable. Second, the use of typed feature structures within the lexicon has been strongly 457 Computational Linguistics Volume 20, Number 3 argued for by Briscoe (1991) and Copestake et al. (in press). That is, even when we ignore syntactic combination, constraint-based grammar frameworks turn out to be well suited to expressing the category and semantic information fields of lexical entries. But the interaction of phonology with categorial information inside the lexicon is well documented. Lexical phonology (Kiparsky 1982) has shown in detail how phonological phenomena are conditioned by morphologically specified domains. If direct interaction between phonology and morpho-syn tax is prohibited, one can only resort to ad hoc and poorly motivated diacritic features. Turning to a different empirical domain, it can be argued that focus constructions exhibit an interaction between information structure (at the semantic–pragmatic level) with prosodic structure (at the phonological level). This interaction can be directly expressed in a sign-oriented approach. In other frameworks it is common practice to avoid direct </context>
</contexts>
<marker>Kiparsky, 1982</marker>
<rawString>Kiparsky, P. (1982). Lexical Morphology and Phonology. Hanshin Publishing Co.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C W Kisseberth</author>
</authors>
<title>On the functional unity of phonological rules.&amp;quot;</title>
<date>1970</date>
<journal>Linguistic Inquiry,</journal>
<volume>1</volume>
<pages>291--306</pages>
<contexts>
<context position="7672" citStr="Kisseberth (1970)" startWordPosition="1103" endWordPosition="1104">re rules do not so much refine descriptions as alter the objects themselves (Keating 1984). While it is clearly possible to integrate an essentially generative model into the mold of constraint-based grammar (Krieger, Pirker, and Nerbonne 1993), it is less clear that this is the approach most phonologists would wish to take nowadays. It is becoming increasingly apparent that rule-based relationships between surface forms and hypothetical lexical forms are unable to capture important generalizations about surface forms. This concern was voiced early in the history of generative phonology, when Kisseberth (1970) complained that such rules regularly conspire to achieve particular surface configurations, but are unable to express the most elementary observations about what those surface configurations are. As a criticism of rule-based systems, Kisseberth&apos;s complaint remains valid and has been echoed several times since then (Shibatani 1973; Hooper 1976; Hudson 1980; Manaster Ramer 1981). However, recent work in phonology has moved away from models involving rules that relate lexical and surface forms toward models involving general systems of interacting constraints, where this problem has been side-st</context>
</contexts>
<marker>Kisseberth, 1970</marker>
<rawString>Kisseberth, C. W. (1970). &amp;quot;On the functional unity of phonological rules.&amp;quot; Linguistic Inquiry, 1, 291-306.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Klein</author>
</authors>
<title>Data types in computational phonology.&amp;quot;</title>
<date>1992</date>
<booktitle>In Proceedings, 14th International Conference on Computational Linguistics (COLING-92).</booktitle>
<pages>149--155</pages>
<contexts>
<context position="6048" citStr="Klein 1992" startWordPosition="871" endWordPosition="872">retical statement can be found, it is usually expressed in procedural terms, which clouds the empirical ramifications making a theory difficult to falsify. Finally, even when explicit and nonprocedural generalizations are found, they are commonly stated in a nonlinear model, which clearly goes beyond the assumptions about phonology made in HPSG as it currently stands. We approach these challenges by adopting a formal, nonprocedural, nonlinear model of phonology and showing how it can be integrated into HPSG, following on the heels of recent work by the authors (Bird and Klein 1990; Bird 1992; Klein 1992). One of the starting assumptions of this work is that phonological representations are intensional, i.e. each representation is actually a description of a class of utterances. Derivations progress by refining descriptions, further constraining the class of denoted objects. Lexical representations are likewise partial, and phonological constraints are cast as generalizations in a lexical inheritance hierarchy or in a prosodic inheritance hierarchy. When set against the background of constraint-based grammar, this intensional approach is quite natural (cf. Johnson [19881). Moreover, some recen</context>
</contexts>
<marker>Klein, 1992</marker>
<rawString>Klein, E. (1992). &amp;quot;Data types in computational phonology.&amp;quot; In Proceedings, 14th International Conference on Computational Linguistics (COLING-92). 149-155.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Klein</author>
</authors>
<title>An HPSG approach to Sierra Miwok verb stems.&amp;quot;</title>
<date>1993</date>
<booktitle>In Phonology and Computation, edited</booktitle>
<institution>University of Edinburgh,</institution>
<contexts>
<context position="46853" citStr="Klein (1993)" startWordPosition="7532" endWordPosition="7533">eatures in one list with their corresponding phonological exponents in another list. basic 474 Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systems Example 40 PHON : CON: VOW: SKEL : phon k c w) i a a) 1:1 &gt;1 SYNSEM : E CAT: verb SUBCAT : (NP) SEM : bleed synsem MORPH: [ROOT: [PHON : template-morph SYNSEM : v-root-I basic - Exactly the same mechanisms will produce the basic stem for the other two types of verb root. For an account of the other alternations presented in Goldsmith&apos;s paradigm, and for some discussion of how lexical and surface forms determine each other, see Klein (1993). We have just seen an application of constraint-based phonology to Sierra Miwok. In order to illustrate some of the other expressive capabilities of the approach, we now turn to the phenomenon of French schwa. 5. French Schwa Many phonological alternations can be shown to depend on properties of prosodic structure. In this section we show how the French phenomenon of schwa-zero alternation arises out of the interplay of various syllable structure requirements. This is done by introducing a system of prosodic types for syllables and a special type declaration showing how a string of segments c</context>
</contexts>
<marker>Klein, 1993</marker>
<rawString>Klein, E. (1993). &amp;quot;An HPSG approach to Sierra Miwok verb stems.&amp;quot; In Phonology and Computation, edited by T. M. Ellison and J. M. Scobbie. University of Edinburgh, 19-35.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kornai</author>
</authors>
<title>Formal phonology. Doctoral dissertation,</title>
<date>1991</date>
<institution>Stanford University.</institution>
<contexts>
<context position="18206" citStr="Kornai 1991" startWordPosition="2753" endWordPosition="2754">ensive introductions to the field. The formalism is an attractive computational model for 1960s generative phonology. However, as has already been noted, phonologists have since moved away from complex string rewriting systems to a range of so-called nonlinear models of phonology. The central innovation of this more recent work is the idea that phonological representations are not strings but collections of strings, synchronized like an orchestral score. There have been some notable recent attempts to rescue the FST model from its linearity in order to encompass nonlinear phonology (Kay 1987; Kornai 1991; Wiebe 1992). However, from our perspective, these refinements to the FST model still admit unwarranted operations on phonological representations, as well as rule conspiracies and the like. Rather, we believe a more constrained and linguistically appealing approach is to employ finite-state automata (FsAs) in preference to FSTs, since it has been shown how FSAs can encode autosegmental representations and a variety of constraints on those representations (Bird and Ellison 1994). The leading idea in this work is that each tier is a partial description of a string, and tiers are put together u</context>
</contexts>
<marker>Kornai, 1991</marker>
<rawString>Kornai, A. (1991). Formal phonology. Doctoral dissertation, Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Koskenniemi</author>
</authors>
<title>Two-level morphology: A general computational model for word-form recognition and production. Doctoral dissertation,</title>
<date>1983</date>
<institution>University of Helsinki.</institution>
<contexts>
<context position="17547" citStr="Koskenniemi (1983)" startWordPosition="2653" endWordPosition="2654"> latter when borrowing examples from other people&apos;s presentations. synsem 459 Computational Linguistics Volume 20, Number 3 Here, the denotation of the type symbol list is the set of all possible ground lists. In practice, a constraint solver could recursively enumerate all these solutions; an alternative proposed by Zajac would be to treat the symbol LIST as the best finite approximation of the infinite set of all lists. 1.4 Finite-State Phonology Over the last decade much has been written on the application of finite-state transducers (FsTs) to phonology, centering on the TWO-LEVEL MODEL of Koskenniemi (1983). Antworth (1990) and Sproat (1992) give comprehensive introductions to the field. The formalism is an attractive computational model for 1960s generative phonology. However, as has already been noted, phonologists have since moved away from complex string rewriting systems to a range of so-called nonlinear models of phonology. The central innovation of this more recent work is the idea that phonological representations are not strings but collections of strings, synchronized like an orchestral score. There have been some notable recent attempts to rescue the FST model from its linearity in or</context>
</contexts>
<marker>Koskenniemi, 1983</marker>
<rawString>Koskenniemi, K. (1983). Two-level morphology: A general computational model for word-form recognition and production. Doctoral dissertation, University of Helsinki.</rawString>
</citation>
<citation valid="false">
<authors>
<author>H-U Krieger</author>
<author>J Nerbonne</author>
</authors>
<title>(in press). &amp;quot;Feature-based inheritance networks for computational lexicons.&amp;quot; In Default Inheritance in Unification Based Approaches to the Lexicon, edited by</title>
<marker>Krieger, Nerbonne, </marker>
<rawString>Krieger, H.-U., and Nerbonne, J. (in press). &amp;quot;Feature-based inheritance networks for computational lexicons.&amp;quot; In Default Inheritance in Unification Based Approaches to the Lexicon, edited by T. Briscoe,</rawString>
</citation>
<citation valid="false">
<authors>
<author>A Copestake</author>
<author>V de Paiva</author>
</authors>
<publisher>Cambridge University Press.</publisher>
<marker>Copestake, de Paiva, </marker>
<rawString>A. Copestake, and V. de Paiva. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H-U Krieger</author>
<author>H Pirker</author>
<author>J Nerbonne</author>
</authors>
<title>Feature-based allomorphy.&amp;quot;</title>
<date>1993</date>
<booktitle>In Proceedings, 31st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>140--147</pages>
<marker>Krieger, Pirker, Nerbonne, 1993</marker>
<rawString>Krieger, H.-U.; Pirker, H.; and Nerbonne, J. (1993). &amp;quot;Feature-based allomorphy.&amp;quot; In Proceedings, 31st Annual Meeting of the Association for Computational Linguistics, 140-147.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manaster Ramer</author>
<author>A</author>
</authors>
<title>How abstruse is phonology? Doctoral dissertation,</title>
<date>1981</date>
<institution>University of Chicago.</institution>
<marker>Ramer, A, 1981</marker>
<rawString>Manaster Ramer, A. (1981). How abstruse is phonology? Doctoral dissertation, University of Chicago.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Martinet</author>
</authors>
<title>La nature phonologique d&apos;e caduc.&amp;quot;</title>
<date>1972</date>
<booktitle>In Papers in Linguistics and Phonetics to the Memory of Pierre Delattre, edited</booktitle>
<contexts>
<context position="51788" citStr="Martinet (1972)" startWordPosition="8315" endWordPosition="8316">e is an orthographic e. Consider the data in (43), where these orthographic es are underlined. 13 The data used in this section is drawn primarily from the careful descriptive work of Morin (1978) and Tranel (1987b). The particular approach to French schwa described in the following paragraphs most closely resembles the analysis of Tranel (1987a). 14 We shall not be concerned with another cer-0 alternation known as elision. This is a phonologically conditioned allomorphy involving alternations such as for example, le chat llce.f al, l&apos;ami [1a.mi]. 15 This epenthesis hypothesis was advanced by Martinet (1972). 476 Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systems Example 43 Orthography With Schwa Without Schwa bordereau fais-le six melons pelleterie [bor.dce.ro] [f€.101 [si.mce.15] -^ - [sim.15] [pel.tri] In a purely synchronic analysis there is no basis for discussing an alternating vowel for bordereau, fais-le and pelleterie. Many orthographic es that are not in the first syllable of a word come into this category. Accordingly, we begin our analysis with three background assumptions: the alternating schwa is (i) prosodically conditioned, (ii) lexically conditioned, and (i</context>
</contexts>
<marker>Martinet, 1972</marker>
<rawString>Martinet, A. (1972). &amp;quot;La nature phonologique d&apos;e caduc.&amp;quot; In Papers in Linguistics and Phonetics to the Memory of Pierre Delattre, edited by A. Valdman. Mouton.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Mastroianni</author>
</authors>
<title>Attribute Logic Phonology.</title>
<date>1993</date>
<tech>CMU-LCL 93-4,</tech>
<institution>Carnegie Mellon University.</institution>
<contexts>
<context position="6877" citStr="Mastroianni 1993" startWordPosition="985" endWordPosition="986">scriptions, further constraining the class of denoted objects. Lexical representations are likewise partial, and phonological constraints are cast as generalizations in a lexical inheritance hierarchy or in a prosodic inheritance hierarchy. When set against the background of constraint-based grammar, this intensional approach is quite natural (cf. Johnson [19881). Moreover, some recent thinking on the phonology—phonetics interface supports this view (Pierrehumbert 1990; Coleman 2 (Bach and Wheeler 1981; Wheeler 1981; Bird 1990; Cahill 1990; Coleman 1991; Scobbie 1991; Bird 1992; Walther 1992; Mastroianni 1993; Russell 1993) 456 Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systems 1992). However, it represents a fundamental split with the generative tradition, where rules do not so much refine descriptions as alter the objects themselves (Keating 1984). While it is clearly possible to integrate an essentially generative model into the mold of constraint-based grammar (Krieger, Pirker, and Nerbonne 1993), it is less clear that this is the approach most phonologists would wish to take nowadays. It is becoming increasingly apparent that rule-based relationships between surface for</context>
</contexts>
<marker>Mastroianni, 1993</marker>
<rawString>Mastroianni, M. (1993). Attribute Logic Phonology. CMU-LCL 93-4, Carnegie Mellon University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J McCarthy</author>
</authors>
<title>A prosodic theory of non-concatenative morphology.&amp;quot;</title>
<date>1981</date>
<journal>Linguistic Inquiry,</journal>
<volume>12</volume>
<pages>373--418</pages>
<contexts>
<context position="36301" citStr="McCarthy 1981" startWordPosition="5731" endWordPosition="5732">iven above is intended to ensure that information-combining operations at the phonological level are monotonic, in the sense that all the information in the operands is preserved in the result. As we have just seen, the constraint-based approach does not guarantee this without such an additional restriction. 4. Sierra Miwok Templatic Morphology Noncatenative morphology has featured centrally in the empirical motivations for autosegmental phonology, since McCarthy&apos;s demonstration that the intercalation of vowels in Arabic consonantal verb roots could be elegantly handled within this framework (McCarthy 1981). This section presents an approach to intercalation that uses key 10 This approach of using restructuring devices in the process of a derivation has been explored in the context of extended Montague frameworks by Wheeler (1981) and Hoeksema and Janda (1988). 468 Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systems insights from autosegmental phonology. However, they are captured within constraintbased grammar where the inflectional paradigm is realized as an inheritance hierarchy of partially instantiated stem forms (cf. Reinhard and Gibbon [1991]). We also show that auto</context>
</contexts>
<marker>McCarthy, 1981</marker>
<rawString>McCarthy, J. (1981). &amp;quot;A prosodic theory of non-concatenative morphology.&amp;quot; Linguistic Inquiry, 12, 373-418.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J McCarthy</author>
<author>A Prince</author>
</authors>
<title>Prosodic morphology I-Constraint interaction and satisfaction.&amp;quot;</title>
<date>1993</date>
<tech>Unpublished Report.</tech>
<contexts>
<context position="1890" citStr="McCarthy and Prince 1993" startWordPosition="270" endWordPosition="273">arly well to capturing phonological generalizations in terms of high-level prosodic constraints. 1. Phonology in Constraint-Based Grammar Classical generative phonology is couched within the same set of assumptions that dominated standard transformational grammar. Despite some claims that &amp;quot;derivations based on ordered rules (that is, external ordering) and incorporating intermediate structures are essential to phonology&amp;quot; (Bromberger and Halle 1989:52), much recent work has tended toward a new model, frequently described in terms of constraints on well-formedness (Paradis 1988; Goldsmith 1993; McCarthy and Prince 1993; Prince and Smolensky 1993). While this work has an increasingly declarative flavor, most versions retain procedural devices for repairing representations that fail to meet certain constraints, or for constraints to override each other. This view is in marked contrast to the interpretation of constraints in grammar frameworks like LFG, GPSG, and HPSG1 and in constraint programming systems more generally (Jaffar and Lassez 1987; Smolka 1992). In such approaches, constraints cannot be circumvented, there are no &apos;intermediate structures,&apos; and the well-formedness constraint (Partee 1979) is obser</context>
</contexts>
<marker>McCarthy, Prince, 1993</marker>
<rawString>McCarthy, J., and Prince, A. (1993). &amp;quot;Prosodic morphology I-Constraint interaction and satisfaction.&amp;quot; Unpublished Report.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y-C Morin</author>
</authors>
<title>The status of mute &apos;e&apos;.&amp;quot;</title>
<date>1978</date>
<journal>Studies in French Linguistics,</journal>
<volume>1</volume>
<pages>79--140</pages>
<contexts>
<context position="50486" citStr="Morin 1978" startWordPosition="8115" endWordPosition="8116">melons can be pronounced with or without the schwa, sept melons requires the schwa in order to break up the tml cluster that would otherwise be formed. Unfortunately, the conditions on the distribution of schwa are not as simple (and purely phonological) as this example implies. As we shall see, schwa alternation in French is governed by an interesting mixture of lexical and prosodic constraints. In the remainder of this section, we dispel the initial hypothesis that arises from (41), namely that schwa alternation is to be treated as a general epenthesis process.&amp;quot; Consider the following data (Morin 1978:111). Example 42 Cluster Schwa Possible/Obligatory Schwa Impossible rdr bordereau [bar.dceso] perdrix [pEr.dri] rf derechef [dce.roe.fcf] torchon [t3r.15] skl squelette [skce.lEt] sclerose [skle.roz] ps depecer [de.pce.se] eclipser fek.lip.sel The table in (42) gives data for the clusters Erdr], [rf], [skl] and [psi. In the first column of data, the ce is possible or obligatory, while in the second column, it is absent. Thus, we see that the apperance of ce cannot be predicted on phonotactic grounds alone. Consequently, we shall assume that schwa must be encoded in lexical representations. No</context>
<context position="55092" citStr="Morin 1978" startWordPosition="8858" endWordPosition="8859">malism unnecessarily. As we saw above for the discussion of the word bordereau, in the approach taken here we have the choice between positing a stable 477 Computational Linguistics Volume 20, Number 3 ce or one that alternates with zero (i.e. a schwa) in the lexicon, whereas Dell must mark lexical items to indicate which rules they must not undergo. There is also some evidence for a distinction between the phonetic identity of the ce allophone of schwa and the phonetic identity of a nonalternating lexical ce in some varieties of French, requiring that the two be distinguished phonologically (Morin 1978). Thus, the fact that Dell&apos;s analysis involves deletion does not provide a significant stumbling block to our approach. However, Dell employs another procedural device, namely rule ordering, in the application of the rule. In discussing the phrase vous me le dites [vu.m(ce).1(ce).dit], in which either schwa (but not both) may be omitted, Dell writes: vcEi begins on the left and first deletes the schwa of me, producing /vu#m#1a#dit/. But vcEi cannot operate again and delete the schwa of le, for, although this schwa was subject to the rule in the original representation, it no longer is once the</context>
<context position="62214" citStr="Morin 1978" startWordPosition="10048" endWordPosition="10049">aC/ sequences (compare marguerite 480 Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systems /marg@rit/ [marg@rit] Imargrit] and margrave /margrav/ [margrav] Imargoravp&amp;quot; (Tranel 1987a:852). Thus, although many CCC sequences are acceptable phonologically, they are not permitted if a schwa is available to break up the cluster. We also note that Tranel&apos;s analysis (Tranel 1987a) gives the correct result for cases of deletion of schwa in consecutive syllables. Consider the following data. Example 51 a. on ne se moque pas rOn.smok.pa] (Valdman 1976:120) b. sur le chemin [syl.fmN (Morin 1978:82) For both of these cases we observe an &amp;quot;underlying&amp;quot; C1ceC2ce pattern, but where both ces are omitted and where C1 syllabifies into the preceding coda and C2 syllabifies into the following onset. To conclude, we can summarize the empirical content of Tranel&apos;s analysis as follows: (a) Every consonant must be syllabified. (b) Schwa must be realized if it provides the syllable nucleus for an immediately preceding consonant that: (i) cannot be syllabified into a coda, and (ii) cannot form a permissible (word) onset with an immediately following consonant. Naturally, this statement is not the la</context>
</contexts>
<marker>Morin, 1978</marker>
<rawString>Morin, Y.-C. (1978). &amp;quot;The status of mute &apos;e&apos;.&amp;quot; Studies in French Linguistics, 1, 79-140.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y-C Morin</author>
</authors>
<title>French data and phonological theory.&amp;quot;</title>
<date>1987</date>
<journal>Linguistics,</journal>
<volume>25</volume>
<pages>815--843</pages>
<contexts>
<context position="48742" citStr="Morin (1987)" startWordPosition="7836" endWordPosition="7837">lysis. A more recent, nonlinear analysis appears in Section 5.3 while our own, constraint-based version is presented in Section 5.4. 5.1 Descriptive Overview Unlike schwa in English, the French schwa (or mute e) is a full vowel, usually realized as the low-mid front rounded vowel ce (and sometimes as the high-mid front rounded vowel 0 in certain predictable environments). Its distinctive characteristic is that under 12 The data is from standard French taken from (cited) literature, although in some instances we have found speakers with different acceptability judgments than reported here. See Morin (1987) for a discussion of some problems with the treatment of French data in the literature. 475 Computational Linguistics Volume 20, Number 3 certain conditions, it fails to be realized phonetically.&amp;quot; From now on we shall use the term &apos;schwa&apos; to refer to the vowel with this characteristic, rather than to the segment a. Although schwa is associated with orthographic e, not all es will concern us here. For example, the orthographic e of samedi [sam.dil &apos;Saturday&apos; can be taken to indicate that the previous vowel should not be nasalized, while the final e of petite [poe.tit] indicates that the final t</context>
</contexts>
<marker>Morin, 1987</marker>
<rawString>Morin, Y.-C. (1987). &amp;quot;French data and phonological theory.&amp;quot; Linguistics, 25, 815-843.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Paradis</author>
</authors>
<title>On constraints and repair strategies.&amp;quot;</title>
<date>1988</date>
<journal>The Linguistic Review,</journal>
<volume>6</volume>
<pages>71--97</pages>
<contexts>
<context position="1848" citStr="Paradis 1988" startWordPosition="266" endWordPosition="267">is paper lends itself particularly well to capturing phonological generalizations in terms of high-level prosodic constraints. 1. Phonology in Constraint-Based Grammar Classical generative phonology is couched within the same set of assumptions that dominated standard transformational grammar. Despite some claims that &amp;quot;derivations based on ordered rules (that is, external ordering) and incorporating intermediate structures are essential to phonology&amp;quot; (Bromberger and Halle 1989:52), much recent work has tended toward a new model, frequently described in terms of constraints on well-formedness (Paradis 1988; Goldsmith 1993; McCarthy and Prince 1993; Prince and Smolensky 1993). While this work has an increasingly declarative flavor, most versions retain procedural devices for repairing representations that fail to meet certain constraints, or for constraints to override each other. This view is in marked contrast to the interpretation of constraints in grammar frameworks like LFG, GPSG, and HPSG1 and in constraint programming systems more generally (Jaffar and Lassez 1987; Smolka 1992). In such approaches, constraints cannot be circumvented, there are no &apos;intermediate structures,&apos; and the well-fo</context>
</contexts>
<marker>Paradis, 1988</marker>
<rawString>Paradis, C. (1988). &amp;quot;On constraints and repair strategies.&amp;quot; The Linguistic Review, 6, 71-97.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B H Partee</author>
</authors>
<title>Montague grammar and the well-formedness constraint.&amp;quot; In Syntax and Semantics 10: Selections from the Third Groningen Round Table, edited by Heny</title>
<date>1979</date>
<pages>275--313</pages>
<publisher>Academic Press.</publisher>
<contexts>
<context position="2481" citStr="Partee 1979" startWordPosition="355" endWordPosition="356">arthy and Prince 1993; Prince and Smolensky 1993). While this work has an increasingly declarative flavor, most versions retain procedural devices for repairing representations that fail to meet certain constraints, or for constraints to override each other. This view is in marked contrast to the interpretation of constraints in grammar frameworks like LFG, GPSG, and HPSG1 and in constraint programming systems more generally (Jaffar and Lassez 1987; Smolka 1992). In such approaches, constraints cannot be circumvented, there are no &apos;intermediate structures,&apos; and the well-formedness constraint (Partee 1979) is observed (i.e. ill-formed representations can never be created). The advantage of these frameworks is that they allow interesting linguistic analyses to be encoded while remaining computationally tractable. * University of Edinburgh, Centre for Cognitive Science, 2 Buccleuch Place, Edinburgh EH8 9LW, U.K. steven.ewan@cogni.ed.ac.uk 1 Lexical Functional Grammar (Kaplan and Bresnan 1982), Generalized Phrase Structure Grammar (Gazdar, Klein, Pullum, and Sag 1985), and Head-Driven Phrase Structure Grammar (Pollard and Sag 1987). © 1994 Association for Computational Linguistics Computational Li</context>
</contexts>
<marker>Partee, 1979</marker>
<rawString>Partee, B. H. (1979). &amp;quot;Montague grammar and the well-formedness constraint.&amp;quot; In Syntax and Semantics 10: Selections from the Third Groningen Round Table, edited by Heny and H. Schnelle, 275-313. Academic Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Pierrehumbert</author>
</authors>
<title>Phonological and phonetic representation.&amp;quot;</title>
<date>1990</date>
<journal>Journal of Phonetics,</journal>
<volume>18</volume>
<pages>375--394</pages>
<contexts>
<context position="6734" citStr="Pierrehumbert 1990" startWordPosition="963" endWordPosition="964">representations are intensional, i.e. each representation is actually a description of a class of utterances. Derivations progress by refining descriptions, further constraining the class of denoted objects. Lexical representations are likewise partial, and phonological constraints are cast as generalizations in a lexical inheritance hierarchy or in a prosodic inheritance hierarchy. When set against the background of constraint-based grammar, this intensional approach is quite natural (cf. Johnson [19881). Moreover, some recent thinking on the phonology—phonetics interface supports this view (Pierrehumbert 1990; Coleman 2 (Bach and Wheeler 1981; Wheeler 1981; Bird 1990; Cahill 1990; Coleman 1991; Scobbie 1991; Bird 1992; Walther 1992; Mastroianni 1993; Russell 1993) 456 Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systems 1992). However, it represents a fundamental split with the generative tradition, where rules do not so much refine descriptions as alter the objects themselves (Keating 1984). While it is clearly possible to integrate an essentially generative model into the mold of constraint-based grammar (Krieger, Pirker, and Nerbonne 1993), it is less clear that this is the</context>
</contexts>
<marker>Pierrehumbert, 1990</marker>
<rawString>Pierrehumbert, J. (1990). &amp;quot;Phonological and phonetic representation.&amp;quot; Journal of Phonetics, 18, 375-394.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Pollard</author>
<author>I Sag</author>
</authors>
<title>Information-Based Syntax and Semantics. Volume 13 of CSLI Lecture Notes. Stanford: Center for the Study of Language and Information.</title>
<date>1987</date>
<contexts>
<context position="3014" citStr="Pollard and Sag 1987" startWordPosition="424" endWordPosition="427">there are no &apos;intermediate structures,&apos; and the well-formedness constraint (Partee 1979) is observed (i.e. ill-formed representations can never be created). The advantage of these frameworks is that they allow interesting linguistic analyses to be encoded while remaining computationally tractable. * University of Edinburgh, Centre for Cognitive Science, 2 Buccleuch Place, Edinburgh EH8 9LW, U.K. steven.ewan@cogni.ed.ac.uk 1 Lexical Functional Grammar (Kaplan and Bresnan 1982), Generalized Phrase Structure Grammar (Gazdar, Klein, Pullum, and Sag 1985), and Head-Driven Phrase Structure Grammar (Pollard and Sag 1987). © 1994 Association for Computational Linguistics Computational Linguistics Volume 20, Number 3 Here, we are interested in the question of what a theory of phonology ought to look like if it is to be compatible with a constraint-based grammar framework. This issue has already received attention,&apos; although a thoroughgoing integration of phonology into constraint-based grammars has yet to be attempted. To ease exposition, we shall take HPSG as a suitably representative candidate of such approaches. Although we are broadly committed to a sign-oriented approach to grammar, none of our proposals d</context>
<context position="13289" citStr="Pollard and Sag 1987" startWordPosition="1941" endWordPosition="1944">nheritance hierarchy of constraints. As Emele and Zajac (1990) point out, this object-oriented approach brings a number of advantages to grammar writing, such as a high level of abstraction, inferential capacity and modularity. On the face of it, such benefits should extend beyond syntax—to phonology for example. Although there have been some valuable efforts to exploit inheritance and type hierarchies within phonology (e.g. Reinhard and Gibbon 1991), the potential of typed feature structures for this area has barely been scratched so far. In this section, we present a brief overview of HPSG (Pollard and Sag 1987), a constraint-based grammar formalism built around a type system that suits our purposes in phonology. In order to formulate the type system of our grammar, we need to make two kinds of TYPE DECLARATION. The first kind contains information about the subsumption ordering over types. For example, the basic grammar object in HPSG is the feature structure of type sign. The type sign has some SUBTYPES. If a is a subtype of T, then a provides at least as much information as T. A type declaration for sign defines it as the following disjunction of subtypes:3 Example 1 sign = morph V stem V word V ph</context>
<context position="21936" citStr="Pollard and Sag 1987" startWordPosition="3339" endWordPosition="3342">IRST: a I REST : list(a) nelist(a) We can now treat a* and a+ as abbreviations for list(a) and nelist(a) respectively. Another useful abbreviatory notation is parenthesized elements within lists. We shall interpret (a (b)) ,-- L, a list consisting of an a followed by an optional b concatenated with an arbitrary list L, as the following constraint: Example 6 FIRST: a [FIRST : bj REST : L VL REST: list list We shall see applications of these list notations in the next section. 2.2 A Prosodic Type Hierarchy A PROSODIC TYPE HIERARCHY is a subsumption network akin to the lexical hierarchy of HPSG (Pollard and Sag 1987). The type constraints we have met so far can be used to define a type hierarchy, which for present purposes will be a Boolean lattice. In this section we present in outline form a prosodic hierarchy that subsequent analyses will be based on. Example (7) defines the high-level types in the hierarchy. Example 7 phon utterance v phrase V foot v syl v segment Each of these types may have further structure. For example, following Clements (1985:248) we may wish to classify segments in terms of their place and manner of articulation, using the following appropriateness declaration. 461 Computationa</context>
<context position="27091" citStr="Pollard and Sag (1987)" startWordPosition="4208" endWordPosition="4211">runson (1987) have also proposed a model in which prosodic constituents are defined as conjunctions of constraints. 463 Computational Linguistics Volume 20, Number 3 3. Morphology and the Lexicon 3.1 Linguistic Hierarchy The subsumption ordering over types can be used to induce a hierarchy of grammatically well-formed feature structures. This possibility has been exploited in the HPSG analysis of the lexicon: lexical entries consist of the idiosyncratic information particular to the entry, together with an indication of the minimal lexical types from which it inherits. To take an example from Pollard and Sag (1987), the base form of the English verb like is given in Example 13. Example 13 PHON : (1 a I, k) SYNILOCISUBCAT : ([IT [ ]7) - [RELN : like] LIKER : LIKEE : SEMICONT : 2 main A base A strict-trans Since main is a subtype of verb, the entry for like will inherit the constraint that its major class feature is V; by virtue of the type strict-trans, it will inherit the constraint that the first element in the SUBCAT list is an accusative NP, while the second element is a nominative NP; and so on for various other constraints. Figure 1 shows a small and simplified portion of the lexical hierarchy in w</context>
</contexts>
<marker>Pollard, Sag, 1987</marker>
<rawString>Pollard, C., and Sag, I. (1987). Information-Based Syntax and Semantics. Volume 13 of CSLI Lecture Notes. Stanford: Center for the Study of Language and Information.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A S Prince</author>
<author>P Smolensky</author>
</authors>
<title>Optimality theory: Constraint interaction in generative grammar.&amp;quot;</title>
<date>1993</date>
<tech>Technical Report 2,</tech>
<institution>Center for Cognitive Science, Rutgers University.</institution>
<contexts>
<context position="1918" citStr="Prince and Smolensky 1993" startWordPosition="274" endWordPosition="277">nological generalizations in terms of high-level prosodic constraints. 1. Phonology in Constraint-Based Grammar Classical generative phonology is couched within the same set of assumptions that dominated standard transformational grammar. Despite some claims that &amp;quot;derivations based on ordered rules (that is, external ordering) and incorporating intermediate structures are essential to phonology&amp;quot; (Bromberger and Halle 1989:52), much recent work has tended toward a new model, frequently described in terms of constraints on well-formedness (Paradis 1988; Goldsmith 1993; McCarthy and Prince 1993; Prince and Smolensky 1993). While this work has an increasingly declarative flavor, most versions retain procedural devices for repairing representations that fail to meet certain constraints, or for constraints to override each other. This view is in marked contrast to the interpretation of constraints in grammar frameworks like LFG, GPSG, and HPSG1 and in constraint programming systems more generally (Jaffar and Lassez 1987; Smolka 1992). In such approaches, constraints cannot be circumvented, there are no &apos;intermediate structures,&apos; and the well-formedness constraint (Partee 1979) is observed (i.e. ill-formed represe</context>
</contexts>
<marker>Prince, Smolensky, 1993</marker>
<rawString>Prince, A. S., and Smolensky, P. (1993). &amp;quot;Optimality theory: Constraint interaction in generative grammar.&amp;quot; Technical Report 2, Center for Cognitive Science, Rutgers University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G K Pullum</author>
<author>A M Zwicky</author>
</authors>
<title>The syntax-phonology boundary and current syntactic theories.&amp;quot;</title>
<date>1984</date>
<institution>In Ohio State University Working Papers</institution>
<note>in Linguistics: Papers on Morphology, edited by</note>
<contexts>
<context position="10233" citStr="Pullum and Zwicky (1984)" startWordPosition="1488" endWordPosition="1491">onstraint-based formalisms as languages for expressing such theories, not as theories themselves. Moreover, the fact that we use a uniform constraint formalism does not force us to use homogeneous inferential mechanisms for that formalism; this issue is discussed further in Section 1.4 and Section 6. A further question might be: do natural language grammars require the kind of interaction between phonology and other levels of grammar made possible by constraint-based formalisms? This is not the place to explore this issue in the detail it deserves. However, even if we accept the contention of Pullum and Zwicky (1984) that the interactions between phonology and syntax (narrowly construed) are highly restricted, there are still good reasons for wanting to accommodate phonological representations as one of the constraints in a sign-based grammar framework. To begin with, it is relatively uncontroversial that morphology needs to be interfaced with both syntax and phonology. Approaches like that of Krieger and Nerbonne (in press) have shown that both derivational and inflectional morphology can be usefully expressed within the constraint-based paradigm. Taking the further step of adding phonology seems equally</context>
</contexts>
<marker>Pullum, Zwicky, 1984</marker>
<rawString>Pullum, G. K., and Zwicky, A. M. (1984). &amp;quot;The syntax-phonology boundary and current syntactic theories.&amp;quot; In Ohio State University Working Papers in Linguistics: Papers on Morphology, edited by A. Zwicky and R. Wallace. Ohio State University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Reinhard</author>
<author>D Gibbon</author>
</authors>
<title>Prosodic inheritance and morphological generalizations.&amp;quot;</title>
<date>1991</date>
<booktitle>In Proceedings, 5th European ACL Meeting,</booktitle>
<pages>131--136</pages>
<contexts>
<context position="13122" citStr="Reinhard and Gibbon 1991" startWordPosition="1912" endWordPosition="1915">l Framework Typed feature structures (Carpenter 1992) impose a type discipline on constraint-based grammar formalisms. A partial ordering over the types gives rise to an inheritance hierarchy of constraints. As Emele and Zajac (1990) point out, this object-oriented approach brings a number of advantages to grammar writing, such as a high level of abstraction, inferential capacity and modularity. On the face of it, such benefits should extend beyond syntax—to phonology for example. Although there have been some valuable efforts to exploit inheritance and type hierarchies within phonology (e.g. Reinhard and Gibbon 1991), the potential of typed feature structures for this area has barely been scratched so far. In this section, we present a brief overview of HPSG (Pollard and Sag 1987), a constraint-based grammar formalism built around a type system that suits our purposes in phonology. In order to formulate the type system of our grammar, we need to make two kinds of TYPE DECLARATION. The first kind contains information about the subsumption ordering over types. For example, the basic grammar object in HPSG is the feature structure of type sign. The type sign has some SUBTYPES. If a is a subtype of T, then a </context>
</contexts>
<marker>Reinhard, Gibbon, 1991</marker>
<rawString>Reinhard, S., and Gibbon, D. (1991). &amp;quot;Prosodic inheritance and morphological generalizations.&amp;quot; In Proceedings, 5th European ACL Meeting, 131-136.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Riehemann</author>
</authors>
<title>Word formation in lexical type hierarchies: A case study of bar-adjectives in German.</title>
<date>1992</date>
<tech>Master&apos;s thesis,</tech>
<institution>Department of Linguistics, University of Tubingen.</institution>
<contexts>
<context position="30617" citStr="Riehemann (1992)" startWordPosition="4798" endWordPosition="4799">f the Head Feature Principle, Subcategorization Principle, and linear order statements, such a functor would combine with a verb stem to yield a tree-structured sign for walks. Example 14 PHON : Example 16 (verb-stem [PHON : [I (w i 10] [PHON : E Ks)] &gt;1 PHON : affix DTRS : verb - While one may wish to treat derivational morphology in this way (cf. Krieger and Nerbonne [in press]), a more economical treatment of inflectional morphology is obtained if we analyze affixes as partially instantiated word forms.&apos; Example (17) illustrates this for the suffix -s, where 3ps is a subtype of sign. 9 See Riehemann (1992) for a detailed working out of this idea for German derivational morphology. 465 Computational Linguistics Volume 20, Number 3 Example 17 PHON : MORPH: affix-morph STEM: [PHON : (s)] AFFIX: verb-stem [PHON : E suffix 3ps Note that we have added to sign a new attribute MORPH, with a value morph. The latter has two subtypes, affix-morph and basic-morph, depending on whether the value contains a stem and affix or just a stem. Example 18 morph = affix-morph V basic-morph While both of these types will inherit the attribute STEM, affix-morph must also be defined for the attribute AFFIX: Example 19 </context>
</contexts>
<marker>Riehemann, 1992</marker>
<rawString>Riehemann, S. (1992). Word formation in lexical type hierarchies: A case study of bar-adjectives in German. Master&apos;s thesis, Department of Linguistics, University of Tubingen.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Rooth</author>
</authors>
<title>Association with focus. Doctoral dissertation,</title>
<date>1985</date>
<institution>University of Massachusetts-Amherst.</institution>
<contexts>
<context position="12064" citStr="Rooth 1985" startWordPosition="1755" endWordPosition="1756">fied domains. If direct interaction between phonology and morpho-syn tax is prohibited, one can only resort to ad hoc and poorly motivated diacritic features. Turning to a different empirical domain, it can be argued that focus constructions exhibit an interaction between information structure (at the semantic–pragmatic level) with prosodic structure (at the phonological level). This interaction can be directly expressed in a sign-oriented approach. In other frameworks it is common practice to avoid direct reference to phonology by invoking a morpho-syntactic FOCUS feature (e.g. Selkirk 1984; Rooth 1985); the mediation of syntax in this way appears to be more an artifact of the grammar architecture than an independently motivated requirement. Equally, it has been argued that the phenomenon of heavy NP shift is a kind of syntaxphonology interaction that is simply stated in a constraint-based approach, where the linear precedence constraints of syntax are sensitive to the phonological category of weight (Bird 1992). 1.3 Theoretical Framework Typed feature structures (Carpenter 1992) impose a type discipline on constraint-based grammar formalisms. A partial ordering over the types gives rise to </context>
</contexts>
<marker>Rooth, 1985</marker>
<rawString>Rooth, M. (1985). Association with focus. Doctoral dissertation, University of Massachusetts-Amherst.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Russell</author>
</authors>
<title>A constraint-based approach to phonology. Doctoral dissertation,</title>
<date>1993</date>
<institution>University of Southern California.</institution>
<contexts>
<context position="6892" citStr="Russell 1993" startWordPosition="987" endWordPosition="988">r constraining the class of denoted objects. Lexical representations are likewise partial, and phonological constraints are cast as generalizations in a lexical inheritance hierarchy or in a prosodic inheritance hierarchy. When set against the background of constraint-based grammar, this intensional approach is quite natural (cf. Johnson [19881). Moreover, some recent thinking on the phonology—phonetics interface supports this view (Pierrehumbert 1990; Coleman 2 (Bach and Wheeler 1981; Wheeler 1981; Bird 1990; Cahill 1990; Coleman 1991; Scobbie 1991; Bird 1992; Walther 1992; Mastroianni 1993; Russell 1993) 456 Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systems 1992). However, it represents a fundamental split with the generative tradition, where rules do not so much refine descriptions as alter the objects themselves (Keating 1984). While it is clearly possible to integrate an essentially generative model into the mold of constraint-based grammar (Krieger, Pirker, and Nerbonne 1993), it is less clear that this is the approach most phonologists would wish to take nowadays. It is becoming increasingly apparent that rule-based relationships between surface forms and hypothet</context>
</contexts>
<marker>Russell, 1993</marker>
<rawString>Russell, K. (1993). A constraint-based approach to phonology. Doctoral dissertation, University of Southern California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Scobbie</author>
</authors>
<title>Attribute-value phonology. Doctoral dissertation,</title>
<date>1991</date>
<institution>University of Edinburgh.</institution>
<contexts>
<context position="6834" citStr="Scobbie 1991" startWordPosition="979" endWordPosition="980">es. Derivations progress by refining descriptions, further constraining the class of denoted objects. Lexical representations are likewise partial, and phonological constraints are cast as generalizations in a lexical inheritance hierarchy or in a prosodic inheritance hierarchy. When set against the background of constraint-based grammar, this intensional approach is quite natural (cf. Johnson [19881). Moreover, some recent thinking on the phonology—phonetics interface supports this view (Pierrehumbert 1990; Coleman 2 (Bach and Wheeler 1981; Wheeler 1981; Bird 1990; Cahill 1990; Coleman 1991; Scobbie 1991; Bird 1992; Walther 1992; Mastroianni 1993; Russell 1993) 456 Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systems 1992). However, it represents a fundamental split with the generative tradition, where rules do not so much refine descriptions as alter the objects themselves (Keating 1984). While it is clearly possible to integrate an essentially generative model into the mold of constraint-based grammar (Krieger, Pirker, and Nerbonne 1993), it is less clear that this is the approach most phonologists would wish to take nowadays. It is becoming increasingly apparent that r</context>
</contexts>
<marker>Scobbie, 1991</marker>
<rawString>Scobbie, J. (1991). Attribute-value phonology. Doctoral dissertation, University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Selkirk</author>
</authors>
<title>Phonology and Syntax.</title>
<date>1984</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="12051" citStr="Selkirk 1984" startWordPosition="1753" endWordPosition="1754">ogically specified domains. If direct interaction between phonology and morpho-syn tax is prohibited, one can only resort to ad hoc and poorly motivated diacritic features. Turning to a different empirical domain, it can be argued that focus constructions exhibit an interaction between information structure (at the semantic–pragmatic level) with prosodic structure (at the phonological level). This interaction can be directly expressed in a sign-oriented approach. In other frameworks it is common practice to avoid direct reference to phonology by invoking a morpho-syntactic FOCUS feature (e.g. Selkirk 1984; Rooth 1985); the mediation of syntax in this way appears to be more an artifact of the grammar architecture than an independently motivated requirement. Equally, it has been argued that the phenomenon of heavy NP shift is a kind of syntaxphonology interaction that is simply stated in a constraint-based approach, where the linear precedence constraints of syntax are sensitive to the phonological category of weight (Bird 1992). 1.3 Theoretical Framework Typed feature structures (Carpenter 1992) impose a type discipline on constraint-based grammar formalisms. A partial ordering over the types g</context>
<context position="24554" citStr="Selkirk 1984" startWordPosition="3770" endWordPosition="3771">tion constraint to the rest of the list. Example 10 hna list(segment) A FIRST ISL : MNINASAL : A REST: hnal PL: REST &apos;FIRST ISL : MNICONT : — 1 PL: 462 Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systems Standard techniques can now be used to move the negation in (10) inward.&apos; Since constraints on adjacent list elements generally seem to be more intelligible in the format exhibited by (9), we shall stick to that notation in the remainder of the paper. 2.3 Prosodic Constituency One standard phonological approach assumes that prosodic constituency is like phrase structure (Selkirk 1984). For example, one might use a rewrite rule to define a (phonological) phrase as a sequence of feet, and a foot as sequence of syllables: Example 11 a. phrase foot+ b. foot —&gt; syl+ Within the framework of HPSG, it would be simple to mimic such constituency by admitting a feature structure of type phrase whose DTRs (i.e. daughters) are a list of feature structures of type foot, and so on down the hierarchy. However, there appears to be no linguistic motivation for building such structure. Rather, we would like to say that a phrase is just a nonempty list of feet. But a foot is just a list of sy</context>
</contexts>
<marker>Selkirk, 1984</marker>
<rawString>Selkirk, E. (1984). Phonology and Syntax. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Shibatani</author>
</authors>
<title>The role of surface phonetic constraints in generative phonology.&amp;quot;</title>
<date>1973</date>
<journal>Language,</journal>
<volume>49</volume>
<pages>87--106</pages>
<contexts>
<context position="8004" citStr="Shibatani 1973" startWordPosition="1149" endWordPosition="1150"> It is becoming increasingly apparent that rule-based relationships between surface forms and hypothetical lexical forms are unable to capture important generalizations about surface forms. This concern was voiced early in the history of generative phonology, when Kisseberth (1970) complained that such rules regularly conspire to achieve particular surface configurations, but are unable to express the most elementary observations about what those surface configurations are. As a criticism of rule-based systems, Kisseberth&apos;s complaint remains valid and has been echoed several times since then (Shibatani 1973; Hooper 1976; Hudson 1980; Manaster Ramer 1981). However, recent work in phonology has moved away from models involving rules that relate lexical and surface forms toward models involving general systems of interacting constraints, where this problem has been side-stepped. Accordingly, we avoid the theoretical framework of early generative phonology, focusing instead on encoding phonological constraints in a constraint-based grammar framework. We present an overview of the grammar framework in the next section. 1.2 Motivation At this point, we should briefly address the question: What is gain</context>
</contexts>
<marker>Shibatani, 1973</marker>
<rawString>Shibatani, M. (1973). &amp;quot;The role of surface phonetic constraints in generative phonology.&amp;quot; Language, 49, 87-106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Smolka</author>
</authors>
<title>Feature constraint logics for unification grammars.&amp;quot;</title>
<date>1992</date>
<journal>Journal of Logic Programming,</journal>
<volume>12</volume>
<pages>51--87</pages>
<contexts>
<context position="2335" citStr="Smolka 1992" startWordPosition="337" endWordPosition="338">much recent work has tended toward a new model, frequently described in terms of constraints on well-formedness (Paradis 1988; Goldsmith 1993; McCarthy and Prince 1993; Prince and Smolensky 1993). While this work has an increasingly declarative flavor, most versions retain procedural devices for repairing representations that fail to meet certain constraints, or for constraints to override each other. This view is in marked contrast to the interpretation of constraints in grammar frameworks like LFG, GPSG, and HPSG1 and in constraint programming systems more generally (Jaffar and Lassez 1987; Smolka 1992). In such approaches, constraints cannot be circumvented, there are no &apos;intermediate structures,&apos; and the well-formedness constraint (Partee 1979) is observed (i.e. ill-formed representations can never be created). The advantage of these frameworks is that they allow interesting linguistic analyses to be encoded while remaining computationally tractable. * University of Edinburgh, Centre for Cognitive Science, 2 Buccleuch Place, Edinburgh EH8 9LW, U.K. steven.ewan@cogni.ed.ac.uk 1 Lexical Functional Grammar (Kaplan and Bresnan 1982), Generalized Phrase Structure Grammar (Gazdar, Klein, Pullum,</context>
</contexts>
<marker>Smolka, 1992</marker>
<rawString>Smolka, G. (1992). &amp;quot;Feature constraint logics for unification grammars.&amp;quot; Journal of Logic Programming, 12, 51-87.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Sproat</author>
</authors>
<title>Morphology and Computation. Natural Language Processing.</title>
<date>1992</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="17582" citStr="Sproat (1992)" startWordPosition="2658" endWordPosition="2659">er people&apos;s presentations. synsem 459 Computational Linguistics Volume 20, Number 3 Here, the denotation of the type symbol list is the set of all possible ground lists. In practice, a constraint solver could recursively enumerate all these solutions; an alternative proposed by Zajac would be to treat the symbol LIST as the best finite approximation of the infinite set of all lists. 1.4 Finite-State Phonology Over the last decade much has been written on the application of finite-state transducers (FsTs) to phonology, centering on the TWO-LEVEL MODEL of Koskenniemi (1983). Antworth (1990) and Sproat (1992) give comprehensive introductions to the field. The formalism is an attractive computational model for 1960s generative phonology. However, as has already been noted, phonologists have since moved away from complex string rewriting systems to a range of so-called nonlinear models of phonology. The central innovation of this more recent work is the idea that phonological representations are not strings but collections of strings, synchronized like an orchestral score. There have been some notable recent attempts to rescue the FST model from its linearity in order to encompass nonlinear phonolog</context>
</contexts>
<marker>Sproat, 1992</marker>
<rawString>Sproat, R. (1992). Morphology and Computation. Natural Language Processing. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Sproat</author>
<author>B Brunson</author>
</authors>
<title>Constituent-based morphological parsing: A new approach to the problem of word-recognition.&amp;quot;</title>
<date>1987</date>
<booktitle>In Proceedings, 25th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<pages>65--72</pages>
<contexts>
<context position="26482" citStr="Sproat and Brunson (1987)" startWordPosition="4114" endWordPosition="4117">e. Thus, we shall arrive at a scheme like the following, where the C, indicate the extra constraints:8 Example 12 a. phrase foot+ A Ci A . • • A Ck b. foot syl+ A Ci A ... A Cn This concludes our discussion of string-based phonology. We have tried to show how a phonological model based on FSAs is compatible with the list notation and type regime of HPSG. Next we move onto a consideration of morphology and the lexicon. 7 These techniques employ the following equivalences: : 0.] V -tB 0] [-(A: T)] V [A: Here -.(A:T) indicates that the attribute A is not appropriate for this feature structure. 8 Sproat and Brunson (1987) have also proposed a model in which prosodic constituents are defined as conjunctions of constraints. 463 Computational Linguistics Volume 20, Number 3 3. Morphology and the Lexicon 3.1 Linguistic Hierarchy The subsumption ordering over types can be used to induce a hierarchy of grammatically well-formed feature structures. This possibility has been exploited in the HPSG analysis of the lexicon: lexical entries consist of the idiosyncratic information particular to the entry, together with an indication of the minimal lexical types from which it inherits. To take an example from Pollard and S</context>
</contexts>
<marker>Sproat, Brunson, 1987</marker>
<rawString>Sproat, R., and Brunson, B. (1987). &amp;quot;Constituent-based morphological parsing: A new approach to the problem of word-recognition.&amp;quot; In Proceedings, 25th Annual Meeting of the Association for Computational Linguistics. 65-72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Tranel</author>
</authors>
<title>French schwa and nonlinear phonology.&amp;quot;</title>
<date>1987</date>
<journal>Linguistics,</journal>
<volume>25</volume>
<pages>845--866</pages>
<contexts>
<context position="51386" citStr="Tranel (1987" startWordPosition="8256" endWordPosition="8257">rs Erdr], [rf], [skl] and [psi. In the first column of data, the ce is possible or obligatory, while in the second column, it is absent. Thus, we see that the apperance of ce cannot be predicted on phonotactic grounds alone. Consequently, we shall assume that schwa must be encoded in lexical representations. Note that it is certainly not the case that a lexical schwa will be posited wherever there is an orthographic e. Consider the data in (43), where these orthographic es are underlined. 13 The data used in this section is drawn primarily from the careful descriptive work of Morin (1978) and Tranel (1987b). The particular approach to French schwa described in the following paragraphs most closely resembles the analysis of Tranel (1987a). 14 We shall not be concerned with another cer-0 alternation known as elision. This is a phonologically conditioned allomorphy involving alternations such as for example, le chat llce.f al, l&apos;ami [1a.mi]. 15 This epenthesis hypothesis was advanced by Martinet (1972). 476 Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systems Example 43 Orthography With Schwa Without Schwa bordereau fais-le six melons pelleterie [bor.dce.ro] [f€.101 [si.mce.1</context>
<context position="57443" citStr="Tranel (1987" startWordPosition="9235" endWordPosition="9236">in consecutive syllables just in case the result is syllabifiable. As we shall see below in (51), this prediction is actually borne out. Before proceeding with our own analysis, we present an overview of an autosegmental analysis of French schwa due to Tranel. This analysis is interesting because it demonstrates the oft-repeated phenomenon of enriched representations leading to dramatically simplified rule systems. Given the heavy restriction on rules in a monostratal framework, it will be more natural to take Tranel&apos;s (rather than Dell&apos;s) analysis as our starting point. 5.3 Tranel&apos;s Analysis Tranel (1987a) provides an insightful analysis of French schwa cast in the framework of autosegmental phonology. In this section we give an overview of this analysis. In the following section we shall endeavour to provide an empirically equivalent analysis. Tranel adopts a CV skeleton tier and a segmental tier. Schwa is represented as an unlinked vowel, as shown in the following representation for melons. Example 44 CV mce 1 5 478 Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systems On top of this two-tiered structure, Tranel proposes a level of hierarchical organization for represent</context>
<context position="59658" citStr="Tranel 1987" startWordPosition="9648" endWordPosition="9649"> illustrated below. Note that the unlinked ce is assumed to be phonetically uninterpreted. Example 47 AA A A A OR OR OR OR OR II\ II IIII!! C V C CV CVC V CV III II IIIIII s i m ce 1 5 s imce 1 5 This gives us the two options, fsim.151 and [si.mce.15], according with the observation 479 Computational Linguistics Volume 20, Number 3 in (41). For sept melons, however, there is just the one option. The t must be syllabified into the preceding coda, and the m requires the presence of schwa, and so we have [set.mce.151. Further examples of this particular kind of schwa alternation are given below (Tranel 1987b:91). Example 48 Schwa Required Schwa Optional de qui parlez-vous? [dcekiparlevul te casse pas la tete [tcekaspulatEt] debout [dcebu] depuis quatre ans [dceptiikatral dedans [dcedd] je joue 13ce3u1 le lait [lcelc I ce salon Iscesalol vous parlez de qui? Ivuparled(ce)kil ne te casse pas la tete [ncet(ce)kaspalatet] il est debout [ilEci(ce)bul c&apos;est depuis quatre ans Ised(ce)pgikatral là-dedans [lad(ce)dd] mais je joue [m3(ce)3u1 dans le lait dans ce salon Eclas(ce)sali51 So far, we have seen the case where the leftward syllabification of a consonant licenses the omission of schwa. Now we turn </context>
<context position="61805" citStr="Tranel 1987" startWordPosition="9983" endWordPosition="9984"> onset even if there is an intervening schwa, provided that the consonant is word-initial (and that the resulting onset is allowable). The intervening schwa remains unpronounced. Rule (50b), which is optional, correctly captures the alternations displayed in (49). This rule is restricted to apply word-initially &amp;quot;so as to avoid the generation of word-internal triliteral consonant clusters from underlying /CCaC/ sequences (compare marguerite 480 Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systems /marg@rit/ [marg@rit] Imargrit] and margrave /margrav/ [margrav] Imargoravp&amp;quot; (Tranel 1987a:852). Thus, although many CCC sequences are acceptable phonologically, they are not permitted if a schwa is available to break up the cluster. We also note that Tranel&apos;s analysis (Tranel 1987a) gives the correct result for cases of deletion of schwa in consecutive syllables. Consider the following data. Example 51 a. on ne se moque pas rOn.smok.pa] (Valdman 1976:120) b. sur le chemin [syl.fmN (Morin 1978:82) For both of these cases we observe an &amp;quot;underlying&amp;quot; C1ceC2ce pattern, but where both ces are omitted and where C1 syllabifies into the preceding coda and C2 syllabifies into the following</context>
<context position="66867" citStr="Tranel 1987" startWordPosition="10845" endWordPosition="10846">ns) Figure 3 Parts of French type hierarchy. insist that the syllabic affiliation of segments is determined lexically. Rather, we have opted for the prosodic type phrase, insisting that anything of this type consists of one or more well-formed syllables (cf. Example 11). Now consider the case of the phrase sept melons. This is similar to the situation in (54), except that we must find a way of ruling out the tml cluster as a valid coda-onset sequence. We are not aware of any exhaustive study of possible French consonant clusters, although one can find discussions of particular clusters (e.g., Tranel 1987b:95ffl shows that CLj onset clusters are not tolerated). Consequently, the two hierarchies in Figure 3 are necessarily preliminary, and are made more for the sake of being explicit than for their precise content. Note that parentheses indicate optionality, so, for example, both onsets and codas are allowed to be null. Additional stipulations will be necessary to ensure that an intervocalic consonant is syllabified with the material to its right. We can do this by preventing an onsetless syllable from following a closed syllable, with the type onset-max-1. Example 55 onset-max-1 sY1 ... CODA :</context>
<context position="68086" citStr="Tranel 1987" startWordPosition="11042" endWordPosition="11043"> [ONS : elist]... [ -_7•. —, Now consider again the phrase six melons. The syllabification Isi.mce1.51 would be represented as follows: Example 56 ( [ONS : (s)1 NUC ((cV) ONS : elist NUC: [NUC : (5) 12 syl CODA: nebst(1) syl syl Observe that this list of syllables contains a violation of (55), so [si.mce1.51 is ruled out. Now that we have considered vowel-consonant-vowel (VCV) sequences, we shall move on to more complex intervocalic consonant clusters. Although the constraints in Figure 3 produce the desired result for VLLV clusters (L=liquid), by assigning each liquid to a separate syllable (Tranel 1987b), there is still ambiguity with VOLV clusters (0=obstruent), which are syllabified as V.OLV according to Tranel. We can deal with this and similar ambiguities by further refining ( phrase syl 483 Computational Linguistics Volume 20, Number 3 the classification of syllables and imposing suitable constraints on syllable sequences. Here is one way of doing this, following the same pattern that we saw in (55). Example 57 ) onset-max-2 [CODA: ( - • • obs • • •)] [ONS: —, (- - - obs • • •)]... syl syl phrase This constraint states that it is not permissible to have an obstruent in a syllable coda </context>
<context position="71176" citStr="Tranel (1987" startWordPosition="11554" endWordPosition="11555">ever, we must not specify any more syllable structure than is absolutely necessary. Example 61 displays the required constraint for the word haut. 484 Steven Bird and Ewan Klein Example 61 PHON : phon SYNSEMICAT : noun [SYLS : SEGS: [NUC : ( (ha-syl (11 o&gt; lexical-sign Phonological Analysis in Typed Feature Systems So although syllabification operates at the phrase level rather than the morpheme level (see Example 53), we are still able to impose lexically conditioned constraints on syllable structure directly. It remains to be shown how this treatment of h-aspire bears on schwa. Fortunately, Tranel (1987b:94) has provided the example we need. Consider the phrase dans le haut [dO..loe.o]. This contains the word le [l(ce)1, which is lexically specified as having an optional ce, indicated by parentheses.&apos; There are three possible syllabifications, only the last of which is well formed. Example 62 ONS : (d)1 ONS : (1) a. NUC: (a) NUC: (o) ( syl CODA: CODA: ha-syl ONS: (d) ONSET: ONSET: (o () * ( NUC: (a) NUC: (oe) N CODA: (1) CODA: () CODA: / syl - syl ha-syl ONS: (d) ONSET: (1) ONSET: NUC: (CO NUC: (ce) NUC: ( CODA: () CODA: () CODA: syl syl - ha-syl The syllabification in (62a) is unavailable, </context>
<context position="73587" citStr="Tranel (1987" startWordPosition="11977" endWordPosition="11978">: (a) syl CODA: (n) syl CODA: (k) syl CODA: () SEGS: (Onsmokp a) phrase The reader can check that the onset and coda sequences comply with the constraints in Figure 3, that the first syllable can have an empty onset because there is no preceding syllable that could have a coda that matches the requirements of (60a), and that the obstruent k is permitted by constraint (60b) to appear in the coda of the second syllable because there is another obstruent p in the following onset. This concludes our discussion of French schwa. We believe our treatment of schwa is empirically equivalent to that of Tranel (1987a), except for the analysis of h-aspire. Several empirical issues remain, but we are optimistic that further refinements to our proposals will be able to take additional observations on board. Notwithstanding such further developments, we hope to have demonstrated that the procedural devices of deletion and rule ordering are unnecessary in a typed feature-based grammar framework, and that constraints represent a perspicuous way of encoding linguistic observations. 6. Prospects for Implementation In the preceding sections we have shown how the use of parameterized lists in HPSG is sufficient fo</context>
</contexts>
<marker>Tranel, 1987</marker>
<rawString>Tranel, B. (1987a). &amp;quot;French schwa and nonlinear phonology.&amp;quot; Linguistics, 25, 845-866.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Tranel</author>
</authors>
<title>The Sounds of French—An Introduction.</title>
<date>1987</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="51386" citStr="Tranel (1987" startWordPosition="8256" endWordPosition="8257">rs Erdr], [rf], [skl] and [psi. In the first column of data, the ce is possible or obligatory, while in the second column, it is absent. Thus, we see that the apperance of ce cannot be predicted on phonotactic grounds alone. Consequently, we shall assume that schwa must be encoded in lexical representations. Note that it is certainly not the case that a lexical schwa will be posited wherever there is an orthographic e. Consider the data in (43), where these orthographic es are underlined. 13 The data used in this section is drawn primarily from the careful descriptive work of Morin (1978) and Tranel (1987b). The particular approach to French schwa described in the following paragraphs most closely resembles the analysis of Tranel (1987a). 14 We shall not be concerned with another cer-0 alternation known as elision. This is a phonologically conditioned allomorphy involving alternations such as for example, le chat llce.f al, l&apos;ami [1a.mi]. 15 This epenthesis hypothesis was advanced by Martinet (1972). 476 Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systems Example 43 Orthography With Schwa Without Schwa bordereau fais-le six melons pelleterie [bor.dce.ro] [f€.101 [si.mce.1</context>
<context position="57443" citStr="Tranel (1987" startWordPosition="9235" endWordPosition="9236">in consecutive syllables just in case the result is syllabifiable. As we shall see below in (51), this prediction is actually borne out. Before proceeding with our own analysis, we present an overview of an autosegmental analysis of French schwa due to Tranel. This analysis is interesting because it demonstrates the oft-repeated phenomenon of enriched representations leading to dramatically simplified rule systems. Given the heavy restriction on rules in a monostratal framework, it will be more natural to take Tranel&apos;s (rather than Dell&apos;s) analysis as our starting point. 5.3 Tranel&apos;s Analysis Tranel (1987a) provides an insightful analysis of French schwa cast in the framework of autosegmental phonology. In this section we give an overview of this analysis. In the following section we shall endeavour to provide an empirically equivalent analysis. Tranel adopts a CV skeleton tier and a segmental tier. Schwa is represented as an unlinked vowel, as shown in the following representation for melons. Example 44 CV mce 1 5 478 Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systems On top of this two-tiered structure, Tranel proposes a level of hierarchical organization for represent</context>
<context position="59658" citStr="Tranel 1987" startWordPosition="9648" endWordPosition="9649"> illustrated below. Note that the unlinked ce is assumed to be phonetically uninterpreted. Example 47 AA A A A OR OR OR OR OR II\ II IIII!! C V C CV CVC V CV III II IIIIII s i m ce 1 5 s imce 1 5 This gives us the two options, fsim.151 and [si.mce.15], according with the observation 479 Computational Linguistics Volume 20, Number 3 in (41). For sept melons, however, there is just the one option. The t must be syllabified into the preceding coda, and the m requires the presence of schwa, and so we have [set.mce.151. Further examples of this particular kind of schwa alternation are given below (Tranel 1987b:91). Example 48 Schwa Required Schwa Optional de qui parlez-vous? [dcekiparlevul te casse pas la tete [tcekaspulatEt] debout [dcebu] depuis quatre ans [dceptiikatral dedans [dcedd] je joue 13ce3u1 le lait [lcelc I ce salon Iscesalol vous parlez de qui? Ivuparled(ce)kil ne te casse pas la tete [ncet(ce)kaspalatet] il est debout [ilEci(ce)bul c&apos;est depuis quatre ans Ised(ce)pgikatral là-dedans [lad(ce)dd] mais je joue [m3(ce)3u1 dans le lait dans ce salon Eclas(ce)sali51 So far, we have seen the case where the leftward syllabification of a consonant licenses the omission of schwa. Now we turn </context>
<context position="61805" citStr="Tranel 1987" startWordPosition="9983" endWordPosition="9984"> onset even if there is an intervening schwa, provided that the consonant is word-initial (and that the resulting onset is allowable). The intervening schwa remains unpronounced. Rule (50b), which is optional, correctly captures the alternations displayed in (49). This rule is restricted to apply word-initially &amp;quot;so as to avoid the generation of word-internal triliteral consonant clusters from underlying /CCaC/ sequences (compare marguerite 480 Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systems /marg@rit/ [marg@rit] Imargrit] and margrave /margrav/ [margrav] Imargoravp&amp;quot; (Tranel 1987a:852). Thus, although many CCC sequences are acceptable phonologically, they are not permitted if a schwa is available to break up the cluster. We also note that Tranel&apos;s analysis (Tranel 1987a) gives the correct result for cases of deletion of schwa in consecutive syllables. Consider the following data. Example 51 a. on ne se moque pas rOn.smok.pa] (Valdman 1976:120) b. sur le chemin [syl.fmN (Morin 1978:82) For both of these cases we observe an &amp;quot;underlying&amp;quot; C1ceC2ce pattern, but where both ces are omitted and where C1 syllabifies into the preceding coda and C2 syllabifies into the following</context>
<context position="66867" citStr="Tranel 1987" startWordPosition="10845" endWordPosition="10846">ns) Figure 3 Parts of French type hierarchy. insist that the syllabic affiliation of segments is determined lexically. Rather, we have opted for the prosodic type phrase, insisting that anything of this type consists of one or more well-formed syllables (cf. Example 11). Now consider the case of the phrase sept melons. This is similar to the situation in (54), except that we must find a way of ruling out the tml cluster as a valid coda-onset sequence. We are not aware of any exhaustive study of possible French consonant clusters, although one can find discussions of particular clusters (e.g., Tranel 1987b:95ffl shows that CLj onset clusters are not tolerated). Consequently, the two hierarchies in Figure 3 are necessarily preliminary, and are made more for the sake of being explicit than for their precise content. Note that parentheses indicate optionality, so, for example, both onsets and codas are allowed to be null. Additional stipulations will be necessary to ensure that an intervocalic consonant is syllabified with the material to its right. We can do this by preventing an onsetless syllable from following a closed syllable, with the type onset-max-1. Example 55 onset-max-1 sY1 ... CODA :</context>
<context position="68086" citStr="Tranel 1987" startWordPosition="11042" endWordPosition="11043"> [ONS : elist]... [ -_7•. —, Now consider again the phrase six melons. The syllabification Isi.mce1.51 would be represented as follows: Example 56 ( [ONS : (s)1 NUC ((cV) ONS : elist NUC: [NUC : (5) 12 syl CODA: nebst(1) syl syl Observe that this list of syllables contains a violation of (55), so [si.mce1.51 is ruled out. Now that we have considered vowel-consonant-vowel (VCV) sequences, we shall move on to more complex intervocalic consonant clusters. Although the constraints in Figure 3 produce the desired result for VLLV clusters (L=liquid), by assigning each liquid to a separate syllable (Tranel 1987b), there is still ambiguity with VOLV clusters (0=obstruent), which are syllabified as V.OLV according to Tranel. We can deal with this and similar ambiguities by further refining ( phrase syl 483 Computational Linguistics Volume 20, Number 3 the classification of syllables and imposing suitable constraints on syllable sequences. Here is one way of doing this, following the same pattern that we saw in (55). Example 57 ) onset-max-2 [CODA: ( - • • obs • • •)] [ONS: —, (- - - obs • • •)]... syl syl phrase This constraint states that it is not permissible to have an obstruent in a syllable coda </context>
<context position="71176" citStr="Tranel (1987" startWordPosition="11554" endWordPosition="11555">ever, we must not specify any more syllable structure than is absolutely necessary. Example 61 displays the required constraint for the word haut. 484 Steven Bird and Ewan Klein Example 61 PHON : phon SYNSEMICAT : noun [SYLS : SEGS: [NUC : ( (ha-syl (11 o&gt; lexical-sign Phonological Analysis in Typed Feature Systems So although syllabification operates at the phrase level rather than the morpheme level (see Example 53), we are still able to impose lexically conditioned constraints on syllable structure directly. It remains to be shown how this treatment of h-aspire bears on schwa. Fortunately, Tranel (1987b:94) has provided the example we need. Consider the phrase dans le haut [dO..loe.o]. This contains the word le [l(ce)1, which is lexically specified as having an optional ce, indicated by parentheses.&apos; There are three possible syllabifications, only the last of which is well formed. Example 62 ONS : (d)1 ONS : (1) a. NUC: (a) NUC: (o) ( syl CODA: CODA: ha-syl ONS: (d) ONSET: ONSET: (o () * ( NUC: (a) NUC: (oe) N CODA: (1) CODA: () CODA: / syl - syl ha-syl ONS: (d) ONSET: (1) ONSET: NUC: (CO NUC: (ce) NUC: ( CODA: () CODA: () CODA: syl syl - ha-syl The syllabification in (62a) is unavailable, </context>
<context position="73587" citStr="Tranel (1987" startWordPosition="11977" endWordPosition="11978">: (a) syl CODA: (n) syl CODA: (k) syl CODA: () SEGS: (Onsmokp a) phrase The reader can check that the onset and coda sequences comply with the constraints in Figure 3, that the first syllable can have an empty onset because there is no preceding syllable that could have a coda that matches the requirements of (60a), and that the obstruent k is permitted by constraint (60b) to appear in the coda of the second syllable because there is another obstruent p in the following onset. This concludes our discussion of French schwa. We believe our treatment of schwa is empirically equivalent to that of Tranel (1987a), except for the analysis of h-aspire. Several empirical issues remain, but we are optimistic that further refinements to our proposals will be able to take additional observations on board. Notwithstanding such further developments, we hope to have demonstrated that the procedural devices of deletion and rule ordering are unnecessary in a typed feature-based grammar framework, and that constraints represent a perspicuous way of encoding linguistic observations. 6. Prospects for Implementation In the preceding sections we have shown how the use of parameterized lists in HPSG is sufficient fo</context>
</contexts>
<marker>Tranel, 1987</marker>
<rawString>Tranel, B. (1987b). The Sounds of French—An Introduction. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Valdman</author>
</authors>
<title>Introduction to French Phonology and Morphology.</title>
<date>1976</date>
<publisher>Newbury House.</publisher>
<contexts>
<context position="62171" citStr="Valdman 1976" startWordPosition="10041" endWordPosition="10042">iteral consonant clusters from underlying /CCaC/ sequences (compare marguerite 480 Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systems /marg@rit/ [marg@rit] Imargrit] and margrave /margrav/ [margrav] Imargoravp&amp;quot; (Tranel 1987a:852). Thus, although many CCC sequences are acceptable phonologically, they are not permitted if a schwa is available to break up the cluster. We also note that Tranel&apos;s analysis (Tranel 1987a) gives the correct result for cases of deletion of schwa in consecutive syllables. Consider the following data. Example 51 a. on ne se moque pas rOn.smok.pa] (Valdman 1976:120) b. sur le chemin [syl.fmN (Morin 1978:82) For both of these cases we observe an &amp;quot;underlying&amp;quot; C1ceC2ce pattern, but where both ces are omitted and where C1 syllabifies into the preceding coda and C2 syllabifies into the following onset. To conclude, we can summarize the empirical content of Tranel&apos;s analysis as follows: (a) Every consonant must be syllabified. (b) Schwa must be realized if it provides the syllable nucleus for an immediately preceding consonant that: (i) cannot be syllabified into a coda, and (ii) cannot form a permissible (word) onset with an immediately following consona</context>
</contexts>
<marker>Valdman, 1976</marker>
<rawString>Valdman, A. (1976). Introduction to French Phonology and Morphology. Newbury House.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Walther</author>
</authors>
<title>Deklarative Silbifizierung in einem constrain tbasierten Grammatikformalismus. Master&apos;s thesis,</title>
<date>1992</date>
<institution>University of Stuttgart.</institution>
<contexts>
<context position="6859" citStr="Walther 1992" startWordPosition="983" endWordPosition="984">by refining descriptions, further constraining the class of denoted objects. Lexical representations are likewise partial, and phonological constraints are cast as generalizations in a lexical inheritance hierarchy or in a prosodic inheritance hierarchy. When set against the background of constraint-based grammar, this intensional approach is quite natural (cf. Johnson [19881). Moreover, some recent thinking on the phonology—phonetics interface supports this view (Pierrehumbert 1990; Coleman 2 (Bach and Wheeler 1981; Wheeler 1981; Bird 1990; Cahill 1990; Coleman 1991; Scobbie 1991; Bird 1992; Walther 1992; Mastroianni 1993; Russell 1993) 456 Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systems 1992). However, it represents a fundamental split with the generative tradition, where rules do not so much refine descriptions as alter the objects themselves (Keating 1984). While it is clearly possible to integrate an essentially generative model into the mold of constraint-based grammar (Krieger, Pirker, and Nerbonne 1993), it is less clear that this is the approach most phonologists would wish to take nowadays. It is becoming increasingly apparent that rule-based relationships b</context>
</contexts>
<marker>Walther, 1992</marker>
<rawString>Walther, M. (1992). Deklarative Silbifizierung in einem constrain tbasierten Grammatikformalismus. Master&apos;s thesis, University of Stuttgart.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Wheeler</author>
</authors>
<title>Aspects of a Categorial Theory of Phonology. Doctoral dissertation,</title>
<date>1981</date>
<institution>University of Massachusetts-Amherst.</institution>
<contexts>
<context position="6768" citStr="Wheeler 1981" startWordPosition="969" endWordPosition="970">ch representation is actually a description of a class of utterances. Derivations progress by refining descriptions, further constraining the class of denoted objects. Lexical representations are likewise partial, and phonological constraints are cast as generalizations in a lexical inheritance hierarchy or in a prosodic inheritance hierarchy. When set against the background of constraint-based grammar, this intensional approach is quite natural (cf. Johnson [19881). Moreover, some recent thinking on the phonology—phonetics interface supports this view (Pierrehumbert 1990; Coleman 2 (Bach and Wheeler 1981; Wheeler 1981; Bird 1990; Cahill 1990; Coleman 1991; Scobbie 1991; Bird 1992; Walther 1992; Mastroianni 1993; Russell 1993) 456 Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systems 1992). However, it represents a fundamental split with the generative tradition, where rules do not so much refine descriptions as alter the objects themselves (Keating 1984). While it is clearly possible to integrate an essentially generative model into the mold of constraint-based grammar (Krieger, Pirker, and Nerbonne 1993), it is less clear that this is the approach most phonologists would </context>
<context position="36529" citStr="Wheeler (1981)" startWordPosition="5767" endWordPosition="5768">nt-based approach does not guarantee this without such an additional restriction. 4. Sierra Miwok Templatic Morphology Noncatenative morphology has featured centrally in the empirical motivations for autosegmental phonology, since McCarthy&apos;s demonstration that the intercalation of vowels in Arabic consonantal verb roots could be elegantly handled within this framework (McCarthy 1981). This section presents an approach to intercalation that uses key 10 This approach of using restructuring devices in the process of a derivation has been explored in the context of extended Montague frameworks by Wheeler (1981) and Hoeksema and Janda (1988). 468 Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systems insights from autosegmental phonology. However, they are captured within constraintbased grammar where the inflectional paradigm is realized as an inheritance hierarchy of partially instantiated stem forms (cf. Reinhard and Gibbon [1991]). We also show that autosegmental association of consonants and vowels to a skeleton can be modeled by reentrancy. Rather than classical Arabic, we use the simpler data from Sierra Miwok that Goldsmith (1990) chose to illustrate the phenomenon of inter</context>
</contexts>
<marker>Wheeler, 1981</marker>
<rawString>Wheeler, D. (1981). Aspects of a Categorial Theory of Phonology. Doctoral dissertation, University of Massachusetts-Amherst.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Wiebe</author>
</authors>
<title>Modelling autosegmental phonology with multi-tape finite state transducers. Master&apos;s thesis,</title>
<date>1992</date>
<institution>Simon Fraser University.</institution>
<contexts>
<context position="18219" citStr="Wiebe 1992" startWordPosition="2755" endWordPosition="2756">uctions to the field. The formalism is an attractive computational model for 1960s generative phonology. However, as has already been noted, phonologists have since moved away from complex string rewriting systems to a range of so-called nonlinear models of phonology. The central innovation of this more recent work is the idea that phonological representations are not strings but collections of strings, synchronized like an orchestral score. There have been some notable recent attempts to rescue the FST model from its linearity in order to encompass nonlinear phonology (Kay 1987; Kornai 1991; Wiebe 1992). However, from our perspective, these refinements to the FST model still admit unwarranted operations on phonological representations, as well as rule conspiracies and the like. Rather, we believe a more constrained and linguistically appealing approach is to employ finite-state automata (FsAs) in preference to FSTs, since it has been shown how FSAs can encode autosegmental representations and a variety of constraints on those representations (Bird and Ellison 1994). The leading idea in this work is that each tier is a partial description of a string, and tiers are put together using the inte</context>
</contexts>
<marker>Wiebe, 1992</marker>
<rawString>Wiebe, B. (1992). Modelling autosegmental phonology with multi-tape finite state transducers. Master&apos;s thesis, Simon Fraser University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Zajac</author>
</authors>
<title>Inheritance and constraint-based grammar formalisms.&amp;quot;</title>
<date>1992</date>
<journal>Computational Linguistics,</journal>
<volume>18</volume>
<pages>159--182</pages>
<contexts>
<context position="15893" citStr="Zajac (1992" startWordPosition="2383" endWordPosition="2384">over, as we shall see in Section 3.2, it is subject to some further appropriateness conditions that are not imposed on any of its supertypes. Continuing in the same vein, we can assign appropriateness conditions to the types synsem and phon that occurred as values in (2), (simplifying substantially from standard HPSG). Here we give the constraints for synsem. The type phon will be discussed in Section 2. Example 3 _ CAT: cat AGR: agr SUBCAT : list SEM : semantics - To conclude this section, we shall look very briefly at matters of interpretation and inference. As shown by Carpenter (1992) and Zajac (1992, in press), we can use constraint resolution to carry out type inference for feature terms. Following Zajac, let us say that a GROUND feature term is a term all of whose type symbols are minimal (i.e., the most specific types in the hierarchy immediately above 1). A WELL-TYPED feature term is one that obeys all the type definitions. Then the meaning of a feature term F is given by the set of all well-typed ground feature terms that are subsumed by F. Evaluating F, construed as a query, involves describing F&apos;s denotation; for example, enumerating all the well-typed ground feature terms it subs</context>
</contexts>
<marker>Zajac, 1992</marker>
<rawString>Zajac, R. (1992). &amp;quot;Inheritance and constraint-based grammar formalisms.&amp;quot; Computational Linguistics, 18, 159-182.</rawString>
</citation>
<citation valid="false">
<authors>
<author>R Zajac</author>
</authors>
<title>Issues in the design of a language for representing linguistic information based on inheritance and feature structures.&amp;quot;</title>
<booktitle>In Default Inheritance in Unification Based Approaches</booktitle>
<publisher>Cambridge University Press.</publisher>
<note>to the Lexicon, edited by</note>
<marker>Zajac, </marker>
<rawString>Zajac, R. (in press). &amp;quot;Issues in the design of a language for representing linguistic information based on inheritance and feature structures.&amp;quot; In Default Inheritance in Unification Based Approaches to the Lexicon, edited by T. Briscoe, A. Copestake, and V. de Paiva. Cambridge University Press.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>