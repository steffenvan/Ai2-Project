<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000002">
<title confidence="0.99063">
The Challenges of Parsing Chinese with Combinatory Categorial Grammar
</title>
<author confidence="0.998679">
Daniel Tse and James R. Curran
</author>
<affiliation confidence="0.81587">
School of Information Technologies
University of Sydney
Australia
</affiliation>
<email confidence="0.952892">
{dtse6695,james}@it.usyd.edu.au
</email>
<sectionHeader confidence="0.994112" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999841888888889">
We apply Combinatory Categorial Grammar
to wide-coverage parsing in Chinese with the
new Chinese CCGbank, bringing a formalism
capable of transparently recovering non-local
dependencies to a language in which they are
particularly frequent.
We train two state-of-the-art English CCG
parsers: the parser of Petrov and Klein (P&amp;K),
and the Clark and Curran (C&amp;C) parser, uncov-
ering a surprising performance gap between
them not observed in English — 72.73 (P&amp;K)
and 67.09 (C&amp;C) F-score on PCTB 6.
We explore the challenges of Chinese CCG
parsing through three novel ideas: develop-
ing corpus variants rather than treating the cor-
pus as fixed; controlling noun/verb and other
POS ambiguities; and quantifying the impact
of constructions like pro-drop.
</bodyText>
<sectionHeader confidence="0.998088" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999877382978724">
Automatic corpus conversions from the Penn Tree-
bank (Marcus et al., 1994) have driven research in
lexicalised grammar formalisms, such as LTAG (Xia,
1999), HPSG (Miyao et al., 2004) and CCG (Hock-
enmaier and Steedman, 2007), producing the lexical
resources key to wide-coverage statistical parsing.
The Chinese Penn Treebank (PCTB; Xue et al.,
2005) has filled a comparable niche, enabling the
development of a Chinese LTAG (Xia et al., 2000),
a wide-coverage HPSG parser (Yu et al., 2011), and
recently Chinese CCGbank (Tse and Curran, 2010),
a 750 000-word corpus of Combinatory Categorial
Grammar (CCG; Steedman, 2000) derivations.
We train two CCG parsers, Clark and Curran (C&amp;C;
2007), and the Petrov and Klein (P&amp;K; 2007) PCFG
parser, on Chinese CCGbank. We follow Fowler and
Penn (2010), who treat the English CCGbank (Hock-
enmaier and Steedman, 2007) grammar as a CFG and
train and evaluate the P&amp;K parser directly on it.
We obtain the first Chinese CCG parsing results:
F-scores of 72.73 (P&amp;K) and 67.09 (C&amp;C) on la-
belled dependencies computed over the PCTB 6 test
set. While the state-of-the-art in Chinese syntactic
parsing has always lagged behind English, this large
gap is surprising, given that Fowler and Penn (2010)
found only a small margin separated the two parsers
on English CCGbank (86.0 versus 85.8).
Levy and Manning (2003) established that prop-
erties of Chinese such as noun/verb ambiguity con-
tribute to the difficulty of Chinese parsing. We focus
on two factors within our control: annotation deci-
sions and parser architecture.
Existing research has varied parsers whilst keep-
ing the corpus fixed. We vary the corpus whilst keep-
ing the parsers fixed by exploring multiple design
choices for particular constructions. By exploiting
the fully automatic CCGbank extraction process, we
can immediately implement these choices and assess
their impact on parsing performance.
Secondly, we contrast the performance of C&amp;C,
with its tagging/parsing pipeline, with P&amp;K, a parser
which performs joint tagging and parsing, and estab-
lish that P&amp;K is less sensitive to the greater lexical
category ambiguity in Chinese CCGbank.
We demonstrate that Chinese CCG parsing is very
difficult, and propose novel techniques for identify-
ing where the challenges lie.
</bodyText>
<page confidence="0.415176">
295
</page>
<note confidence="0.9682075">
2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 295–304,
Montr´eal, Canada, June 3-8, 2012. c�2012 Association for Computational Linguistics
</note>
<figure confidence="0.9730711">
被 困 trap 的  公主 princess 我 I 解救了 rescued
(S[dcl]\NP)/((S[dcl]\NP)/NP) (S[dcl]\NP)/NP (N/N)\(S[dcl]/NP) N NP (S[dcl]\NP)/NP
≻T
S/(S\NP)
≺ ≻B
N/N S[dcl]/NP
≻
T
S/(S/NP) ≻
S[dcl]
</figure>
<figureCaption confidence="0.983423">
Figure 1: 3 types of non-local dependencies in 6 words: “(As for) the trapped princess, I rescued (her).”
</figureCaption>
<figure confidence="0.608195666666667">
≻
S[dcl]\NP
N −� NP
</figure>
<sectionHeader confidence="0.572512" genericHeader="introduction">
2 Background
</sectionHeader>
<note confidence="0.953247571428571">
Bikel and Chiang (2000) developed the first 
parser, demonstrating that Chinese was similar
enough to English for techniques such as a Collins-
style head-driven parser or  to succeed. Later
 parsers used Tree Insertion Grammar (Chi-
ang and Bikel, 2002), s (Levy and Man-
ning, 2003), the Collins models (Bikel, 2004) and
transition-based discriminative models (Wang et al.,
2006; Zhang and Clark, 2009; Huang et al., 2009).
These systems also established the relative difficulty
of parsing Chinese and English; while 
scores over 92% are possible for English (McClosky
et al., 2006), systems for Chinese have achieved only
87% (Zhang and Clark, 2009) on the same metric.
</note>
<bodyText confidence="0.992838772727273">
Non-local dependencies (s) are lexical depen-
dencies which hold over unbounded distances. Guo
et al. (2007) observed that despite the importance of
s for correct semantic interpretation, and the fact
that Chinese syntax generates more s than En-
glish, few parsers in Chinese are equipped to recover
the traces which mark s. For instance, extrac-
tion, a common  type, occurs more frequently in
 sentences (38%) compared to  (17%).
A more satisfying approach is to use a grammar
formalism, such as  (Steedman, 2000), which
generates them inherently, enabling a unified parsing
model over local and non-local dependencies. This
approach is taken in the C&amp;C parser (Clark and Cur-
ran, 2007), which can directly and transparently re-
cover s in English (Rimell et al., 2009).
Chinese CCGbank (Tse and Curran, 2010) demon-
strates that a parsimonious account of Chinese syn-
tax with  is possible. Many familiar objects
of Chinese syntax which generate s, including
the 把 ba/被 bei constructions, topicalisation and
extraction receive natural  analyses in Chinese
</bodyText>
<figure confidence="0.772278666666667">
(a) Derivational
S/S
(b) L
</figure>
<equation confidence="0.901965833333333">
PN
N
N N
P/
re2:Two typ s of mb guity
CCGb
</equation>
<bodyText confidence="0.996935269230769">
ank.Figure1shows the CCG ank ana ysisof p
as ivisation,topi calisation and ext action,crea t-ing
s bet een公主princessand eac of被  , 困tr a
p and解 救re sc ueresp ectively.We t
ak two sta e-of-the-art par ers and tra n the to e
st blish the dif culty of ar ing Chi ese wit .
The firs is he Cla k and Cur an (C&amp; ; 200 )pars
er,whic h use supe rtagging(Cla rk and Cur an,2004
),a lo c l, line ar-time tag ing tec nique whi hdras
tically pru es the spa e of ex cal cat gorieswhic
h the pol nomial-time par ing alg rithm lat rcons
iders.The sec nd is he oar se-to-fine pars erof P
et ov and Kle n (20 7) whi h ite atively refi esits
gra mar by pl tting pro uction rul s to nc verlate
nt dis inctions. Fowl er and Pen (20 0) dem n-stra
te tha the Eng ish CCG ank gra mar is tr nglycont
ext-free,allo wing the to re t it s  a ndt rai
n the Pet ov and Kle n (20 7) par er dir ctly.2.1D
eri vational vs. exical amb guityThe
des gner of C G ank mus fre uently cho sebetw
een der vational and lex cal amb guity (Ho k-enma
ier, 200 ; Tse and Cur an, 201 ). Deri vationalambi
guityanal yses spe ial con tructions thr ugh ar- itr
ary lab l-rewriting phr se str cture rul s,whil elexi
cal amb guity assi gns add tional cat gories to ex ical
ite s for whe the par icipate in pe ial con stru
</bodyText>
<equation confidence="0.93989475">
ctions.296.
exi calS/S(
S/S
)/NNF ig u
</equation>
<bodyText confidence="0.999972333333333">
Derivational and lexical ambiguity often arise in
CCG because of the form-function distinction —
when the syntactic form of a constituent does not co-
incide with its semantic function (Honnibal, 2010).
For instance, in English, topicalisation causes an NP
to appear in clause-initial position, fulfilling the func-
tion of a sentential pre-modifier while maintaining
the form of an NP. Figure 2 shows two distinct CCG
analyses which yield the same dependency edges.
Derivational ambiguity increases the parser search
space, while lexical ambiguity enlarges the tag set,
and hence the complexity of the supertagging task.
</bodyText>
<sectionHeader confidence="0.976354" genericHeader="method">
3 Three versions of Chinese CCGbank
</sectionHeader>
<bodyText confidence="0.999976375">
We extract three versions of Chinese CCGbank to ex-
plore the trade-off between lexical and derivational
ambiguity, training both parsers on each corpus to
determine the impact of the annotation changes. Our
hypothesis is that the scarcity of training data in Chi-
nese means that derivational ambiguity results in bet-
ter coverage and accuracy, at the cost of increasing
time and space requirements of the resulting parser.
</bodyText>
<subsectionHeader confidence="0.997986">
3.1 The lexical category LC (localiser)
</subsectionHeader>
<bodyText confidence="0.996561666666667">
In the following sentences, the words in bold have of-
ten been analysed as belonging to a lexical category
localiser (Chao, 1968; Li and Thompson, 1989).
</bodyText>
<equation confidence="0.9205355">
(1) a. &amp;-T _#_1ffii
house inside:LC
the inside of the house/inside the house
W
tree
(the area) beside the big tree
</equation>
<bodyText confidence="0.999904166666667">
Localisers, like English prepositions, identify a (tem-
poral, spatial, etc.) extent of their complement. How-
ever, the combination Noun + Localiser is ambigu-
ous between noun function (the inside of the house)
and modifier function (inside the house).
We consider two possibilities to represent localis-
ers in CCG, which trade derivational for lexical am-
biguity. In (2-a), a direct CCG transfer of the PCTB
analysis, the preposition r± at expects arguments of
type LCP. In (2-b), r± at now expects only NP argu-
ments, and the unary promotion LCP —* NP allows
LCP-form constituents to function as NPs.
</bodyText>
<listItem confidence="0.609346">
(2) a. r± at M-T room _#_1 in:LC
</listItem>
<equation confidence="0.991481142857143">
PP/LCP NP LCP\NP
�
r
PP/NP NP LCP\NP
LCP —* NP �
r
PP
</equation>
<bodyText confidence="0.999425090909091">
The analysis in (2-a) exhibits greater lexical ambigu-
ity, with the lexical item r± at carrying at least two
categories, PP/NP and PP/LCP, while (2-b) trades
off derivational for lexical ambiguity: the unary pro-
motion LCP —* NP becomes necessary, but r± at
no longer needs the category PP/LCP.
The base release of Chinese CCGbank, corpus A,
like (2-a), makes the distinction between categories
LCP and NP. However, in corpus B, we test the im-
pact of applying (2-b), in which the unary promotion
LCP —* NP is available.
</bodyText>
<subsectionHeader confidence="0.998862">
3.2 The bare/non-bare NP distinction
</subsectionHeader>
<bodyText confidence="0.999909666666667">
The most frequent unary rule in English CCGbank,
occurring in over 91% of sentences, is the promotion
from bare to non-bare nouns: N —* NP. Hocken-
maier (2003) explains that the rule accounts for the
form-function distinction in determiner-less English
nouns which nevertheless have definite reference,
while preventing certain over-generations (e.g. *the
the car). The N-NP distinction also separates adjec-
tives and noun modifiers (category N/N), from pre-
determiners (category NP/NP) (Hockenmaier and
Steedman, 2005), a distinction also made in Chinese.
While Chinese has strategies to mark definite or in-
definite reference, they are not obligatory, and a bare
noun is referentially ambiguous, calling into ques-
tion whether the distinction is justified in CCG:
</bodyText>
<listItem confidence="0.9029255">
(3) a. P1
dog
</listItem>
<figure confidence="0.974492238095238">
Dogs are clever.
b. R WSJ
P1
dog
1SG see
I saw a dog/dogs.
c. P1 Rip- T
dog run-away ASP
The dog/dogs ran away.
b. )�,-
big
95it
beside:LC
LCP
PP
b. r± at M-T room _#_1 in:LC
fa
very
QRJ
clever
297
</figure>
<bodyText confidence="0.997513375">
The fact that the Chinese determiner is not necessar-
ily a maximal projection of the noun – in other words,
the determiner does not ‘close off’ a level of NP –
also argues against importing the English analysis.
In contrast, the English CCGbank determiner cate-
gory NP/N reflects the fact that determiners ‘close
off’ NP — further modification by noun modifiers is
blocked after combining with a determiner.
</bodyText>
<equation confidence="0.3720045">
(4) 共和党
Republican Party
</equation>
<bodyText confidence="0.958405">
this action by the Republican Party
To test its impact on Chinese parsing, we create a
version of Chinese CCGbank (corpus C) which neu-
tralises the distinction. This eliminates the atomic
category N, as well as the promotion rule N —* NP.
</bodyText>
<sectionHeader confidence="0.99925" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999963592592592">
While a standard split of PCTB 5 exists, as defined
by Zhang and Clark (2008), we are not aware of a
consistently used split for PCTB 6. We present a
new split in Table 1 which adds data from the ACE
broadcast section of PCTB 6, maintaining the same
train/dev/test set proportions as the PCTB 5 split.
We train C&amp;C using the hybrid model, the best-
performing model for English, which extracts fea-
tures from the dependency structure (Clark and Cur-
ran, 2007). We use 0 = (0.055, 0.01, 0.05, 0.1) dur-
ing training with a Gaussian smoothing parameter
α = 2.4 (optimised on the corpus A dev set). We
use 0 = (0.15, 0.075, 0.03, 0.01, 0.005, 0.001) dur-
ing parsing, with the maximum number of supercats
(chart entries) set to 5,000,000, reflecting the greater
supertagging ambiguity of Chinese parsing.
The P&amp;K parser is used “off-the-shelf” and trained
with its default parameters, only varying the number
of split-merge iterations and enabling the Chinese-
specific lexicon features. The P&amp;K parser involves
no explicit Pos tagging step, as the (super)tags cor-
respond directly to non-terminals in a CFG.
Fowler and Penn (2010) use the C&amp;C tool
generate to convert P&amp;K output to the C&amp;C evalu-
ation dependency format. generate critically does
not depend on the C&amp;C parsing model, permitting a
fair comparison of the parsers’ output.
</bodyText>
<table confidence="0.99614725">
PCTB 5 +PCTB 6 #sents
Train 1–815, 1001–1136 2000–2980 22033
Test 816–885, 1137–1147 3030–3145 2758
Dev 900–931, 1148–1151 2981–3029 1101
</table>
<tableCaption confidence="0.999638">
Table 1: PCTB 5 and 6 dev/train/test splits
</tableCaption>
<subsectionHeader confidence="0.971922">
4.1 Evaluation
</subsectionHeader>
<bodyText confidence="0.999975743589744">
Carroll et al. (1998) argued against PARsEVAL in
favour of a dependency-based evaluation. Rimell
et al. (2009) focus on evaluating NLD recovery,
proposing a dependency-based evaluation and a GR
mapping procedure for inter-parser comparison.
Since the P&amp;K parser plus generate produce de-
pendencies in the same format as C&amp;C, we can use
the standard Clark and Curran (2007) dependency-
based evaluation from the CCG literature: labelled F-
score (LF) over dependency tuples, as used for CCG
parser evaluation in English. Critically, this metric
is also NLD-sensitive. We also report labelled sen-
tence accuracy (Lsa), the proportion of sentences for
which the parser returned all and only the gold stan-
dard dependencies. Supertagger accuracy compares
leaf categories against the gold standard (stag).
For C&amp;C, we report on two configurations: GoLD,
evaluated using gold standard Pos tags; and AUTo,
with automatic Pos tags provided by the C&amp;C tagger
(Curran and Clark, 2003). For P&amp;K, we vary the num-
ber of split-merge iterations from one to six (follow-
ing Fowler and Penn (2010), the k-iterations model
is called I-k). Because the P&amp;K parser does not use
Pos tags, the most appropriate comparison is against
the AUTo configuration of C&amp;C. For C&amp;C, we use the
average of the logarithm of the chart size (log C) as
a measure of ambiguity, that is, the number of alter-
native analyses the parser must choose between.
Following Fowler and Penn (2010), we perform
two sets of experiments: one evaluated over all sen-
tences in a section, and another evaluated only over
sentences for which both parsers successfully parse
and generate dependencies.
We define the size of a CCG grammar as the num-
ber of categories it contains. The size of a grammar
affects the difficulty of the supertagging task (as the
size of a grammar is the size of the supertag set). We
also consider the number of categories of each shape,
as defined in Table 2. Decomposing the category in-
</bodyText>
<figure confidence="0.855583666666667">
这
this
举动
act
298
Shape Pattern
</figure>
<equation confidence="0.91146">
V (predicate-like) (S[dcl]\NP)$
M (modifier) X|X
P (preposition-like) (X|X)|Y
N (noun-like) N or NP
O (all others)
</equation>
<tableCaption confidence="0.933688">
Table 2: Shapes of categories
</tableCaption>
<table confidence="0.999729846153846">
model LF Lsa % stag cov log C
I-3 68.97 13.45 83.64 95.7 -
A I-6 71.67 15.70 85.00 96.4 -
GOLD 75.45 16.70 89.43 99.4 14.55
AUTO 66.32 12.81 83.88 98.6 14.69
I-3 69.75 14.15 84.07 96.0 -
B I-5 71.40 14.83 84.97 96.4 -
GOLD 75.41 16.67 89.50 99.6 14.74
AUTO 66.24 12.61 83.95 98.7 14.75
I-3 70.22 16.49 84.37 96.5 -
C I-5 72.74 18.59 85.61 96.5 -
GOLD 76.73 20.56 89.66 99.5 13.58
AUTO 66.95 14.62 83.90 99.2 13.86
</table>
<tableCaption confidence="0.999847">
Table 3: Dev set evaluation for P&amp;x and C&amp;C
</tableCaption>
<bodyText confidence="0.9998444">
ventory into shapes demonstrates how changes to the
corpus annotation affect the distribution of types of
category. Finally, we calculate the average number
of tags per lexical item (Avg. Tags/Word), as a metric
of the degree of lexical ambiguity in each corpus.
</bodyText>
<sectionHeader confidence="0.999944" genericHeader="method">
5 Results
</sectionHeader>
<bodyText confidence="0.999928058823529">
Table 3 shows the performance of P&amp;x and C&amp;C on
the three dev sets, and Table 4 only over sentences
parsed by both parsers. (A is the base release, B
includes the unary rule LCP -* NP, and C also
collapses the N-NP distinction.) For P&amp;x on corpus
A, F-score and supertagger accuracy increase mono-
tonically as further split-merge iterations refine the
model. P&amp;x on B and C overfits at 6 iterations, con-
sistent with Fowler and Penn’s findings for English.
The -9% drop in F-score between the GOLD and
AUTO figures shows that C&amp;C is highly sensitive to
POs tagging accuracy (92.56% on the dev set, com-
pared to 96.82% on English). Considering Table 4,
each best P&amp;x model outperforms the corresponding
AUTO model by 3-5%. However, while P&amp;x is sub-
stantially better without gold-standard information,
gold POs tags allow C&amp;C to outperform P&amp;x, again
</bodyText>
<figure confidence="0.9136482">
model LF Lsa % stag cov
I-6 71.74 15.87 85.29 100.0
A
AUTO 67.50 15.36 84.52 100.0
I-5 71.40 14.97 85.26 100.0
B
AUTO 67.72 14.97 84.68 100.0
I-5 72.84 18.69 86.04 100.0
C
AUTO 68.43 16.17 84.57 100.0
</figure>
<tableCaption confidence="0.77846">
Table 4: Dev set evaluation for P&amp;x and C&amp;C on
PCTB 6 sentences parsed by both parsers
</tableCaption>
<table confidence="0.98964625">
model LF Lsa % stag cov log C
I-5 72.73 20.28 85.43 97.1 -
C GOLD 76.89 22.90 89.63 99.1 14.53
AUTO 67.09 15.28 83.95 98.7 14.89
</table>
<tableCaption confidence="0.999743">
Table 5: Test set evaluation for P&amp;x and C&amp;C
</tableCaption>
<bodyText confidence="0.986433130434783">
demonstrating the impact of incorrect POs tags.
Supertagging and parsing accuracy are not en-
tirely correlated between the parsers – in corpora A
and B, AUTO supertagging is comparable or better
than I-3, but F-score is substantially worse.
Comparing A and B in Table 3, C&amp;C receives
small increases in supertagger accuracy and cover-
age, but parsing performance remains largely un-
changed; P&amp;x performance degrades slightly. On
both parsers, C yields the best results out of the three
corpora, with LF gains of 1.07 (P&amp;x), 1.28 (GOLD)
and 0.63 (AUTO) over the base Chinese CCGbank.
We select C for our remaining parser experiments.
Both C&amp;C’s GOLD and AUTO results show higher
coverage than P&amp;x (a combination of parse failures
in P&amp;x itself, and in generate). Since F-score is
only computed over successful parses, it is possible
that P&amp;x is avoiding harder sentences. In Table 4,
evaluated only over sentences parsed by both parsers
shows that as expected, C&amp;C gains more (1.15%)
than P&amp;x on the common sentences.
Table 5 shows that the behaviour of both parsers
on the test section is consistent with the dev section.
</bodyText>
<table confidence="0.9992266">
corpus Avg. Grammar size
tags/word all f &gt; 10
A 1.84 1177 324
B 1.83 1084 303
C 1.79 964 274
</table>
<tableCaption confidence="0.908848">
Table 6: Corpus statistics
</tableCaption>
<table confidence="0.9618548">
299
corpus V P M N O Total
A 791 158 56 2 170 1177
B 712 149 55 2 166 1084
C 670 119 41 1 133 964
</table>
<tableCaption confidence="0.999607">
Table 7: Grammar size, categorised by shape
</tableCaption>
<subsectionHeader confidence="0.990661">
5.1 Corpus ambiguity
</subsectionHeader>
<bodyText confidence="0.999651481481481">
To understand why corpus C is superior for parsing,
we compare the ambiguity and sparsity characteris-
tics of the three corpora. Examining log C, the aver-
age log-chart size (Table 3) shows that the corpus B
changes (the addition of the unary rule LCP —* NP)
increase ambiguity, while the additional corpus C
changes (eliminating the N-NP distinction, resulting
in the removal of the unary rule N —* NP) have the
net effect of reducing ambiguity.
Table 6 shows that the changes reduce the size
of the lexicon, thus reducing the average number of
tags each word can potentially receive, and therefore
the difficulty of the supertagging task. This, in part,
contributes to the reduced log C values in Table 3.
While the size of the lexicon is reduced in B, the cor-
responding log C figure in Table 3 increases slightly,
because of the additional unary rule.
Table 7 breaks down the size of each lexicon
according to category shape. Introducing the rule
LCP —* NP reduces the number of V-shaped cat-
egories by 10%, while not substantially affecting the
quantity of other category shapes, because the sub-
categorisation frames which previously referred to
LCP are no longer necessary. Eliminating the N-NP
distinction, however, reduces the number of P and
M-shaped categories by over 20%, as the distinction
is no longer made between attachment at N and NP.
</bodyText>
<sectionHeader confidence="0.995494" genericHeader="method">
6 Error analysis
</sectionHeader>
<bodyText confidence="0.999692555555555">
The well-known noun/verb ambiguity in Chinese
(where, e.g., iRt建iR ‘design-build’ is both a ver-
bal compound ‘design and build’ and a noun com-
pound ‘design and construction’) greatly affects
parsing accuracy (Levy and Manning, 2003).
However, little work has quantified the impact of
noun/verb ambiguity on parsing, and for that mat-
ter, the impact of other frequent confusion types.
To quantify C&amp;C’s sensitivity to Pos tagging errors,
</bodyText>
<table confidence="0.994429142857143">
Confusion LF ∆LF stag cov
Base (GoLD) 76.73 89.66 99.50
NR ▷◁ NN 76.72 -0.01 89.64 99.37
JJ ▷◁ NN 76.60 -0.12 89.57 99.37
DEC ▷◁ DEG 75.10 -1.50 89.07 98.83
VV ▷◁ NN 73.35 -1.75 87.68 98.74
All (AUTo) 66.95 83.90 99.20
</table>
<tableCaption confidence="0.995762">
Table 8: Corrupting C&amp;C gold Pos tags piecemeal on
</tableCaption>
<bodyText confidence="0.985512657894737">
PCTB 6 dev set of corpus C. ∆LF is the change in
LF when each additional confusion type is allowed.
which we saw in Table 3, we perform an experiment
where we corrupt the gold Pos tags, by gradually re-
introducing automatic Pos errors on a cumulative ba-
sis, one confusion type at a time.
The notation X ▷◁ Y indicates that the Pos tags X
and Y are frequently confused with each other by the
Pos tagger. For example, VV ▷◁ NN represents the
problematic noun/verb ambiguity, allowing the in-
clusion of noun/verb confusion errors.
Table 8 shows that while the confusion types
NR ▷◁ NN and JJ ▷◁ NN have no impact on the evalua-
tion, the confusions DEC ▷◁ DEG and VV ▷◁ NN, intro-
duced one at a time, cause reductions in F-score of
1.50 and 1.75% respectively. This is expected; Chi-
nese CCGbank does not distinguish between noun
modifiers (NN) and adjectives (JJ). On the other
hand, the critical noun/verb ambiguity, and the con-
fusion between DEC/DEG (two senses of the particle
的 de) adversely impact F-score. We performed an
experiment with C&amp;C to merge DEC and DEG into a
single tag, but found that this increased category am-
biguity without improving accuracy.
The VV ▷◁ NN confusion is particularly damag-
ing to the CCG labelled dependency evaluation, be-
cause verbs generate a large number of dependencies.
While Fowler and Penn (2010) report a gap of 6.31%
between C&amp;C’s labelled and unlabelled F-score on
the development set in English, we observe a gap of
10.35% for Chinese.
Table 10 breaks down the 8,414 false positives
generated by C&amp;C on the dev set, according to
whether the head of each dependency was incorrectly
Pos-tagged and/or supertagged. The top-left cell
shows that despite the correct Pos and supertag, C&amp;C
makes a large number of pure attachment location er-
rors. The vast majority of false positives, though, are
</bodyText>
<table confidence="0.983592730769231">
300
C&amp;C AUTo P&amp;K I-5 category NLD?
LF freq LF freq
0.78 4204 0.78 3106 NP/NP
0.73 2173 0.81 1765 (S[dcl]\NP)/NP
0.65 1717 0.72 1459 (S[dcl]\NP)/NP
0.68 870 0.74 643 (S[dcl]\NP)/(S[dcl]\NP)
0.70 862 0.67 697 S[dcl]\NP
0.60 670 0.69 499 (S[dcl]\NP)/(S[dcl]\NP) ✓
0.55 626 0.54 412 (NP/NP)/(NP/NP)
0.57 370 0.68 321 (NP/NP)\(S[dcl]\NP)
0.59 343 0.70 314 (NP/NP)\(S[dcl]\NP) ✓
0.59 110 0.69 84 (NP/NP)\(S[dcl]/NP)
0.63 106 0.75 86 (NP/NP)\(S[dcl]/NP) ✓
dependency function
noun modifier attachment
transitive object
transitive subject
control/raising S complement
intransitive subject
control/raising subject
noun modifier modifier attachment
subject extraction S complement
subject extraction modifier attachment
object extraction S complement
object extraction modifier attachment
</table>
<tableCaption confidence="0.988753">
Table 9: Accuracy per dependency, for selected dependency types
</tableCaption>
<table confidence="0.9942542">
The C&amp;C AUTo parser appears to be biased to-
correct Pos incorrect Pos
correct stag 2307 (27.42%) 51 (0.61% ) wards generating far more of the frequent depen-
incorrect stag 4493 (53.40%) 1563 (18.58%) dency types, yet does not typically have a higher re-
call for these dependency types than P&amp;K.
</table>
<tableCaption confidence="0.939508">
Table 10: Analysis of the 8,414 false positive depen-
dencies from C&amp;C on PCTB 6 dev set
</tableCaption>
<bodyText confidence="0.9960954">
caused by supertagging errors (the bottom row), but
most of these are not a result of incorrect Pos tags,
demonstrating that supertagging and parsing are dif-
ficult even with correct Pos tags.
The sensitivity of C&amp;C to tagging errors, and
the higher performance of the P&amp;K parser, which
does not directly use Pos tags, calls into question
whether Pos tagging yields a net gain in a language
where distinctions such as the noun/verb ambiguity
are often difficult to resolve using local tagging ap-
proaches. The approach of Auli and Lopez (2011),
which achieves superior results in English CCG pars-
ing with a joint supertagging/parsing model, may be
promising in light of the performance difference be-
tween P&amp;K and C&amp;C.
</bodyText>
<subsectionHeader confidence="0.991713">
6.1 Non-local dependencies
</subsectionHeader>
<bodyText confidence="0.999891444444444">
Table 9 shows how well the best models of each
parser recovered selected local and non-local depen-
dencies. The slot represented by each row appears
in boldface. While C&amp;C and P&amp;K perform similarly
recovering NP-internal structure, the ability of P&amp;K
to recover verbal arguments, unbounded long-range
dependencies such as subject and object extraction,
and bounded long-range dependencies such as con-
trol/raising constructions, is superior.
</bodyText>
<subsectionHeader confidence="0.997001">
6.2 Pro-drop and its impact on  parsing
</subsectionHeader>
<bodyText confidence="0.9826374">
One of the most common types of unary rules in
Chinese CCGbank, occurring in 36% of Chinese
CCGbank sentences, is the subject pro-drop rule
S[dcl]\NP —* S[dcl], which accounts for the op-
tional absence of the subject pronoun of a verb for
pragmatic reasons where the referent can be recov-
ered from the discourse (Li and Thompson, 1989).
The subject pro-drop rule is problematic in Chi-
nese parsing because its left hand side, S[dcl]\NP, is
a very common category, and also because several
syntactic distinctions in Chinese CCGbank hinge on
the difference between S[dcl]\NP and S[dcl].
The latter point is illustrated by two of the senses
of n, de, the Chinese subordinating particle. Two
categories which n, de receives in the grammar
are (NP/NP)\(S[dcl]\NP) (introducing a relative
clause) and (NP/NP)\S[dcl] (in the construction S de
NP). Because subject pro-drop promotes any unsatu-
rated S[dcl]\NP to S[dcl], whenever the supertagger
returns both of the above categories for the lexical
item n, de, the parser must consider two alternative
analyses which yield different dependencies:
(5) a. ti f* n, Mimi
ti come out DE questioni
the questions which arise
</bodyText>
<page confidence="0.631532">
301
</page>
<note confidence="0.87856175">
English Chinese
PTB/PCTB-based 92.1% (McClosky et al., 2006) 86.8% (Zhang and Clark, 2009)
CCGbank-based 86.0% (Fowler and Penn, 2010) 72.7% (this work)
85.8% (Clark and Curran, 2007) 67.1% (this work)
</note>
<tableCaption confidence="0.997593">
Table 11: Summary of Chinese parsing approaches
</tableCaption>
<table confidence="0.999206">
model LF Lsa % stag cov log C
C GoLD 74.99 7.42 89.36 98.6 18.35
AUTo (76.73 20.56 89.66 99.5 13.58)
65.42 4.82 83.73 97.9 18.67
(66.95 14.62 83.90 99.2 13.86)
I-5 70.67 8.62 84.99 93.8 -
(72.74 18.59 85.61 96.5 -)
</table>
<tableCaption confidence="0.9913325">
Table 12: Dev set evaluation for C&amp;C over pro-drop
sentences only (and over full set in parentheses)
</tableCaption>
<bodyText confidence="0.993543095238095">
b. pro ffi来 n AM
pro come out DE question
the question of (him, her) coming out
38.1% of sentences in the development set contain
at least one instance of pro-drop. The evaluation
over only these sentences is given in Table 12. This
restricted evaluation shows that while we cannot
conclude that pro-drop is the causative factor, sen-
tences with pro-drop are much more difficult for both
parsers to analyse correctly, although the drops in F-
score and supertagging accuracy are largest for P&amp;K.
Critically, the fact that supertagging performance
on these more difficult sentences is reasonably com-
parable with performance on the full set suggests
that the bottleneck is in the parser rather than the
supertagger. One measure of the complexity of pro-
drop sentences is the substantial increase in the log C
value of these sentences. This suggests that a key to
bringing parser performance on Chinese in line with
English lies in reining in the ambiguity caused by
very productive unary rules such as pro-drop.
</bodyText>
<sectionHeader confidence="0.998439" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999827358974359">
Using Chinese CCGbank (Tse and Curran, 2010), we
have trained and evaluated the first CCG parsers for
Chinese in the literature: the Clark and Curran (C&amp;C;
2007) and Petrov and Klein (P&amp;K; 2007) parsers.
The P&amp;K parser substantially outperformed (72.73)
C&amp;C with automatic Pos tags (67.09).
Table 11 summarises the best performance of
parsers on PTB and CCGbank, for English and Chi-
nese. We observe a drop in performance between En-
glish and Chinese CCG parsers which is much larger
than, but consistent with, PT� parsers. To close this
gap, future research in Chinese parsing should be in-
formed by quantifying the aspects of Chinese which
account most for the deficit.
We start by using corpus conversion to compare
different linguistic representation choices, rather
than for generating a single immutable resource.
This can also be exploited to develop syntactic cor-
pora parameterised for particular applications. We
found that collapsing categorial distinctions moti-
vated by theory can yield less ambiguous corpora,
and hence, more accurate parsers. We have also
taken a novel approach to investigating the impact
of noun/verb and other Pos ambiguities on parsing.
The large gap between Chinese C&amp;C and P&amp;K is
surprising, given that Fowler and Penn (2010) found
only a small gap for English. We found that C&amp;C
is very sensitive to Pos tagging performance, which
leads to its inferior performance given automatically
assigned Pos tags. This suggests that joint supertag-
ging/parsing approaches, as performed by P&amp;K, are
more suitable for Chinese. Finally, we have shown
that pro-drop is correlated with poor performance
on both parsers, suggesting an avenue to closing the
Chinese-English parsing gap.
While developing the first wide-coverage Chinese
CCG parsers, we have shed light on the nature of the
Chinese-English parsing gap, and identified new and
significant challenges for CCG parsing.
</bodyText>
<sectionHeader confidence="0.995578" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9889578">
We thank our anonymous reviewers for their insight-
ful and detailed feedback. James R. Curran was sup-
ported by Australian Research Council (ARC) Dis-
covery grant DP1097291 and the Capital Markets
Cooperative Research Centre.
</bodyText>
<page confidence="0.767583">
302
</page>
<sectionHeader confidence="0.985614" genericHeader="references">
References
</sectionHeader>
<bodyText confidence="0.805053692307692">
Michael Auli and Adam Lopez. 2011. A comparison
of loopy belief propagation and dual decomposition
for integrated ccg supertagging and parsing. In 49th
Annual Meeting of the Association for Computational
Linguistics, pages 470–480. Association for Computa-
tional Linguistics.
Daniel M. Bikel. 2004. On the parameter space of genera-
tive lexicalized statistical parsing models. Ph.D. thesis,
Citeseer.
Daniel M. Bikel and David Chiang. 2000. Two statisti-
cal parsing models applied to the Chinese Treebank. In
Second workshop on Chinese language processing, vol-
ume 12, pages 1–6. Morristown, NJ, USA.
</bodyText>
<reference confidence="0.996638494117647">
John Carroll, Ted Briscoe, and Antonio Sanfilippo. 1998.
Parser evaluation: a survey and a new proposal. In Pro-
ceedings of the 1st International Conference on Lan-
guage Resources and Evaluation, pages 447–454.
Yuen-Ren Chao. 1968. A grammar of spoken Chinese.
University of California Press.
David Chiang and Daniel M. Bikel. 2002. Recovering la-
tent information in treebanks. In Proceedings of the
19th international conference on Computational lin-
guistics, volume 1, pages 1–7. Association for Compu-
tational Linguistics.
Stephen Clark and James R. Curran. 2004. The impor-
tance of supertagging for wide-coverage CCG parsing.
In Proceedings of the 20th international conference on
Computational Linguistics. Association for Computa-
tional Linguistics.
Stephen Clark and James R. Curran. 2007. Wide-
Coverage Efficient Statistical Parsing with CCG and
Log-Linear Models. In Computational Linguistics, vol-
ume 33, pages 493–552.
James R. Curran and Stephen Clark. 2003. Investigating
GIS and smoothing for maximum entropy taggers. In
Proceedings of the 10th Meeting of the EACL, pages
91–98. Budapest, Hungary.
Timothy A.D. Fowler and Gerald Penn. 2010. Accu-
rate context-free parsing with combinatory categorial
grammar. Proceedings of the 48th Annual Meeting of
the Association for Computational Linguistics, pages
335–344.
Yuqing Guo, Haifeng Wang, and Josef Van Genabith.
2007. Recovering non-local dependencies for Chinese.
In EMNLP/CoNLL, pages 257–266.
Julia Hockenmaier. 2003. Data and Models for Statistical
Parsing with Combinatory Categorial Grammar. Ph.D.
thesis, University of Edinburgh.
Julia Hockenmaier and Mark Steedman. 2005. CCGbank:
Users’ manual. Technical report, MS-CIS-05-09, Com-
puter and Information Science, University of Pennsyl-
vania.
Julia Hockenmaier and Mark Steedman. 2007. CCGbank:
A Corpus of CCG Derivations and Dependency Struc-
tures Extracted from the Penn Treebank. Computa-
tional Linguistics, 33(3):355–396.
Matthew Honnibal. 2010. Hat Categories: Represent-
ing Form and Function Simultaneously in Combinatory
Categorial Grammar. Ph.D. thesis, University of Syd-
ney.
Liang Huang, Wenbin Jiang, and Qun Liu. 2009.
Bilingually-constrained (monolingual) shift-reduce
parsing. In Proceedings of the 2009 Conference on
Empirical Methods in Natural Language Process-
ing, volume 3, pages 1222–1231. Association for
Computational Linguistics.
Roger Levy and Christopher Manning. 2003. Is it harder
to parse Chinese, or the Chinese Treebank? In Annual
Meeting of the Association for Computational Linguis-
tics, volume 1, pages 439–446. Morristown, NJ, USA.
Charles N. Li and Sandra A. Thompson. 1989. Mandarin
Chinese: A functional reference grammar. University
of California Press.
Mitchell P. Marcus, Beatrice Santorini, and Mary Ann
Marcinkiewicz. 1994. Building a Large Annotated Cor-
pus of English: The Penn Treebank. Computational
Linguistics, 19(2):313–330.
David McClosky, Eugene Charniak, and Mark Johnson.
2006. Effective self-training for parsing. In Proceed-
ings of the main conference on Human Language Tech-
nology Conference of the North American Chapter of
the Association of Computational Linguistics, pages
152–159. Association for Computational Linguistics.
Yusuke Miyao, Takashi Ninomiya, and Jun’ichi Tsujii.
2004. Corpus-Oriented Grammar Development for Ac-
quiring a Head-Driven Phrase Structure Grammar from
the Penn Treebank. pages 684–693.
Slav Petrov and Dan Klein. 2007. Improved inference for
unlexicalized parsing. In Proceedings of NAACL HLT
2007, pages 404–411.
Laura Rimell, Stephen Clark, and Mark Steedman. 2009.
Unbounded dependency recovery for parser evaluation.
In Proceedings of the 2009 Conference on Empirical
Methods in Natural Language Processing: Volume 2-
Volume 2, pages 813–821. Association for Computa-
tional Linguistics.
Mark Steedman. 2000. The Syntactic Process. MIT Press.
Cambridge, MA, USA.
</reference>
<page confidence="0.754777">
303
</page>
<reference confidence="0.999797720930232">
Daniel Tse and James R. Curran. 2010. Chinese CCG-
bank: extracting CCG derivations from the Penn Chi-
nese Treebank. Proceedings of the 23rd International
Conference on Computational Linguistics (COLING
2010), pages 1083–1091.
Mengqiu Wang, Kenji Sagae, and Teruko Mitamura. 2006.
A fast, accurate deterministic parser for Chinese. In
Proceedings of the 21st International Conference on
Computational Linguistics and the 44th annual meet-
ing of the Association for Computational Linguistics,
pages 425–432. Association for Computational Lin-
guistics.
Fei Xia. 1999. Extracting tree adjoining grammars from
bracketed corpora. In Proceedings of Natural Lan-
guage Processing Pacific Rim Symposium ’99, pages
398–403.
Fei Xia, Chung-hye Han, Martha Palmer, and Aravind
Joshi. 2000. Comparing lexicalized treebank grammars
extracted from Chinese, Korean, and English corpora.
In Proceedings of the second workshop on Chinese lan-
guage processing: held in conjunction with the 38th
Annual Meeting of the Association for Computational
Linguistics, volume 12, pages 52–59. Association for
Computational Linguistics.
Nianwen Xue, Fei Xia, Fu-Dong Chiou, and Martha
Palmer. 2005. The Penn Chinese TreeBank: Phrase
structure annotation of a large corpus. Natural Lan-
guage Engineering, 11(02):207–238.
Kun Yu, Yusuke Miyao, Takuya Matsuzaki, Xiangli
Wang, and Jun’ichi Tsujii. 2011. Analysis of the dif-
ficulties in chinese deep parsing. In 12th International
Conference on Parsing Technologies, page 48.
Yue Zhang and Stephen Clark. 2008. A tale of two
parsers: investigating and combining graph-based
and transition-based dependency parsing using beam-
search. In Proceedings of the Conference on Empir-
ical Methods in Natural Language Processing, pages
562–571. Association for Computational Linguistics.
Yue Zhang and Stephen Clark. 2009. Transition-based
parsing of the Chinese treebank using a global discrim-
inative model. In Proceedings of the 11th International
Conference on Parsing Technologies, pages 162–171.
Association for Computational Linguistics.
</reference>
<page confidence="0.958843">
304
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.820369">
<title confidence="0.998752">The Challenges of Parsing Chinese with Combinatory Categorial Grammar</title>
<author confidence="0.994042">R Tse</author>
<affiliation confidence="0.999174">School of Information University of</affiliation>
<email confidence="0.913147">dtse6695@it.usyd.edu.au</email>
<email confidence="0.913147">james@it.usyd.edu.au</email>
<abstract confidence="0.994991631578947">We apply Combinatory Categorial Grammar to wide-coverage parsing in Chinese with the new Chinese CCGbank, bringing a formalism capable of transparently recovering non-local dependencies to a language in which they are particularly frequent. train two state-of-the-art English the parser of Petrov and Klein the Clark and Curran parser, uncovering a surprising performance gap between not observed in English — 72.73 67.09 on explore the challenges of Chinese parsing through three novel ideas: developing corpus variants rather than treating the corpus as fixed; controlling noun/verb and other and quantifying the impact constructions like</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>John Carroll</author>
<author>Ted Briscoe</author>
<author>Antonio Sanfilippo</author>
</authors>
<title>Parser evaluation: a survey and a new proposal.</title>
<date>1998</date>
<booktitle>In Proceedings of the 1st International Conference on Language Resources and Evaluation,</booktitle>
<pages>447--454</pages>
<contexts>
<context position="12767" citStr="Carroll et al. (1998)" startWordPosition="2126" endWordPosition="2129">ions and enabling the Chinesespecific lexicon features. The P&amp;K parser involves no explicit Pos tagging step, as the (super)tags correspond directly to non-terminals in a CFG. Fowler and Penn (2010) use the C&amp;C tool generate to convert P&amp;K output to the C&amp;C evaluation dependency format. generate critically does not depend on the C&amp;C parsing model, permitting a fair comparison of the parsers’ output. PCTB 5 +PCTB 6 #sents Train 1–815, 1001–1136 2000–2980 22033 Test 816–885, 1137–1147 3030–3145 2758 Dev 900–931, 1148–1151 2981–3029 1101 Table 1: PCTB 5 and 6 dev/train/test splits 4.1 Evaluation Carroll et al. (1998) argued against PARsEVAL in favour of a dependency-based evaluation. Rimell et al. (2009) focus on evaluating NLD recovery, proposing a dependency-based evaluation and a GR mapping procedure for inter-parser comparison. Since the P&amp;K parser plus generate produce dependencies in the same format as C&amp;C, we can use the standard Clark and Curran (2007) dependencybased evaluation from the CCG literature: labelled Fscore (LF) over dependency tuples, as used for CCG parser evaluation in English. Critically, this metric is also NLD-sensitive. We also report labelled sentence accuracy (Lsa), the propor</context>
</contexts>
<marker>Carroll, Briscoe, Sanfilippo, 1998</marker>
<rawString>John Carroll, Ted Briscoe, and Antonio Sanfilippo. 1998. Parser evaluation: a survey and a new proposal. In Proceedings of the 1st International Conference on Language Resources and Evaluation, pages 447–454.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuen-Ren Chao</author>
</authors>
<title>A grammar of spoken Chinese.</title>
<date>1968</date>
<publisher>University of California Press.</publisher>
<contexts>
<context position="8192" citStr="Chao, 1968" startWordPosition="1352" endWordPosition="1353">ons of Chinese CCGbank We extract three versions of Chinese CCGbank to explore the trade-off between lexical and derivational ambiguity, training both parsers on each corpus to determine the impact of the annotation changes. Our hypothesis is that the scarcity of training data in Chinese means that derivational ambiguity results in better coverage and accuracy, at the cost of increasing time and space requirements of the resulting parser. 3.1 The lexical category LC (localiser) In the following sentences, the words in bold have often been analysed as belonging to a lexical category localiser (Chao, 1968; Li and Thompson, 1989). (1) a. &amp;-T _#_1ffii house inside:LC the inside of the house/inside the house W tree (the area) beside the big tree Localisers, like English prepositions, identify a (temporal, spatial, etc.) extent of their complement. However, the combination Noun + Localiser is ambiguous between noun function (the inside of the house) and modifier function (inside the house). We consider two possibilities to represent localisers in CCG, which trade derivational for lexical ambiguity. In (2-a), a direct CCG transfer of the PCTB analysis, the preposition r± at expects arguments of typ</context>
</contexts>
<marker>Chao, 1968</marker>
<rawString>Yuen-Ren Chao. 1968. A grammar of spoken Chinese. University of California Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
<author>Daniel M Bikel</author>
</authors>
<title>Recovering latent information in treebanks.</title>
<date>2002</date>
<booktitle>In Proceedings of the 19th international conference on Computational linguistics,</booktitle>
<volume>1</volume>
<pages>1--7</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="4048" citStr="Chiang and Bikel, 2002" startWordPosition="618" endWordPosition="622"> Association for Computational Linguistics 被 困 trap 的  公主 princess 我 I 解救了 rescued (S[dcl]\NP)/((S[dcl]\NP)/NP) (S[dcl]\NP)/NP (N/N)\(S[dcl]/NP) N NP (S[dcl]\NP)/NP ≻T S/(S\NP) ≺ ≻B N/N S[dcl]/NP ≻ T S/(S/NP) ≻ S[dcl] Figure 1: 3 types of non-local dependencies in 6 words: “(As for) the trapped princess, I rescued (her).” ≻ S[dcl]\NP N −� NP 2 Background Bikel and Chiang (2000) developed the first  parser, demonstrating that Chinese was similar enough to English for techniques such as a Collinsstyle head-driven parser or  to succeed. Later  parsers used Tree Insertion Grammar (Chiang and Bikel, 2002), s (Levy and Manning, 2003), the Collins models (Bikel, 2004) and transition-based discriminative models (Wang et al., 2006; Zhang and Clark, 2009; Huang et al., 2009). These systems also established the relative difficulty of parsing Chinese and English; while  scores over 92% are possible for English (McClosky et al., 2006), systems for Chinese have achieved only 87% (Zhang and Clark, 2009) on the same metric. Non-local dependencies (s) are lexical dependencies which hold over unbounded distances. Guo et al. (2007) observed that despite the importance of s for correct sema</context>
</contexts>
<marker>Chiang, Bikel, 2002</marker>
<rawString>David Chiang and Daniel M. Bikel. 2002. Recovering latent information in treebanks. In Proceedings of the 19th international conference on Computational linguistics, volume 1, pages 1–7. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Clark</author>
<author>James R Curran</author>
</authors>
<title>The importance of supertagging for wide-coverage CCG parsing.</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th international conference on Computational Linguistics. Association for Computational Linguistics.</booktitle>
<marker>Clark, Curran, 2004</marker>
<rawString>Stephen Clark and James R. Curran. 2004. The importance of supertagging for wide-coverage CCG parsing. In Proceedings of the 20th international conference on Computational Linguistics. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Clark</author>
<author>James R Curran</author>
</authors>
<title>WideCoverage Efficient Statistical Parsing with CCG and Log-Linear Models.</title>
<date>2007</date>
<booktitle>In Computational Linguistics,</booktitle>
<volume>33</volume>
<pages>493--552</pages>
<contexts>
<context position="5184" citStr="Clark and Curran, 2007" startWordPosition="798" endWordPosition="802">tances. Guo et al. (2007) observed that despite the importance of s for correct semantic interpretation, and the fact that Chinese syntax generates more s than English, few parsers in Chinese are equipped to recover the traces which mark s. For instance, extraction, a common  type, occurs more frequently in  sentences (38%) compared to  (17%). A more satisfying approach is to use a grammar formalism, such as  (Steedman, 2000), which generates them inherently, enabling a unified parsing model over local and non-local dependencies. This approach is taken in the C&amp;C parser (Clark and Curran, 2007), which can directly and transparently recover s in English (Rimell et al., 2009). Chinese CCGbank (Tse and Curran, 2010) demonstrates that a parsimonious account of Chinese syntax with  is possible. Many familiar objects of Chinese syntax which generate s, including the 把 ba/被 bei constructions, topicalisation and extraction receive natural  analyses in Chinese (a) Derivational S/S (b) L PN N N N P/ re2:Two typ s of mb guity CCGb ank.Figure1shows the CCG ank ana ysisof p as ivisation,topi calisation and ext action,crea t-ing s bet een公主princessand eac of被  , 困tr a p and解 救re </context>
<context position="11682" citStr="Clark and Curran, 2007" startWordPosition="1949" endWordPosition="1953"> a version of Chinese CCGbank (corpus C) which neutralises the distinction. This eliminates the atomic category N, as well as the promotion rule N —* NP. 4 Experiments While a standard split of PCTB 5 exists, as defined by Zhang and Clark (2008), we are not aware of a consistently used split for PCTB 6. We present a new split in Table 1 which adds data from the ACE broadcast section of PCTB 6, maintaining the same train/dev/test set proportions as the PCTB 5 split. We train C&amp;C using the hybrid model, the bestperforming model for English, which extracts features from the dependency structure (Clark and Curran, 2007). We use 0 = (0.055, 0.01, 0.05, 0.1) during training with a Gaussian smoothing parameter α = 2.4 (optimised on the corpus A dev set). We use 0 = (0.15, 0.075, 0.03, 0.01, 0.005, 0.001) during parsing, with the maximum number of supercats (chart entries) set to 5,000,000, reflecting the greater supertagging ambiguity of Chinese parsing. The P&amp;K parser is used “off-the-shelf” and trained with its default parameters, only varying the number of split-merge iterations and enabling the Chinesespecific lexicon features. The P&amp;K parser involves no explicit Pos tagging step, as the (super)tags corresp</context>
<context position="13117" citStr="Clark and Curran (2007)" startWordPosition="2180" endWordPosition="2183">, permitting a fair comparison of the parsers’ output. PCTB 5 +PCTB 6 #sents Train 1–815, 1001–1136 2000–2980 22033 Test 816–885, 1137–1147 3030–3145 2758 Dev 900–931, 1148–1151 2981–3029 1101 Table 1: PCTB 5 and 6 dev/train/test splits 4.1 Evaluation Carroll et al. (1998) argued against PARsEVAL in favour of a dependency-based evaluation. Rimell et al. (2009) focus on evaluating NLD recovery, proposing a dependency-based evaluation and a GR mapping procedure for inter-parser comparison. Since the P&amp;K parser plus generate produce dependencies in the same format as C&amp;C, we can use the standard Clark and Curran (2007) dependencybased evaluation from the CCG literature: labelled Fscore (LF) over dependency tuples, as used for CCG parser evaluation in English. Critically, this metric is also NLD-sensitive. We also report labelled sentence accuracy (Lsa), the proportion of sentences for which the parser returned all and only the gold standard dependencies. Supertagger accuracy compares leaf categories against the gold standard (stag). For C&amp;C, we report on two configurations: GoLD, evaluated using gold standard Pos tags; and AUTo, with automatic Pos tags provided by the C&amp;C tagger (Curran and Clark, 2003). Fo</context>
<context position="26006" citStr="Clark and Curran, 2007" startWordPosition="4361" endWordPosition="4364">he grammar are (NP/NP)\(S[dcl]\NP) (introducing a relative clause) and (NP/NP)\S[dcl] (in the construction S de NP). Because subject pro-drop promotes any unsaturated S[dcl]\NP to S[dcl], whenever the supertagger returns both of the above categories for the lexical item n, de, the parser must consider two alternative analyses which yield different dependencies: (5) a. ti f* n, Mimi ti come out DE questioni the questions which arise 301 English Chinese PTB/PCTB-based 92.1% (McClosky et al., 2006) 86.8% (Zhang and Clark, 2009) CCGbank-based 86.0% (Fowler and Penn, 2010) 72.7% (this work) 85.8% (Clark and Curran, 2007) 67.1% (this work) Table 11: Summary of Chinese parsing approaches model LF Lsa % stag cov log C C GoLD 74.99 7.42 89.36 98.6 18.35 AUTo (76.73 20.56 89.66 99.5 13.58) 65.42 4.82 83.73 97.9 18.67 (66.95 14.62 83.90 99.2 13.86) I-5 70.67 8.62 84.99 93.8 - (72.74 18.59 85.61 96.5 -) Table 12: Dev set evaluation for C&amp;C over pro-drop sentences only (and over full set in parentheses) b. pro ffi来 n AM pro come out DE question the question of (him, her) coming out 38.1% of sentences in the development set contain at least one instance of pro-drop. The evaluation over only these sentences is given in</context>
</contexts>
<marker>Clark, Curran, 2007</marker>
<rawString>Stephen Clark and James R. Curran. 2007. WideCoverage Efficient Statistical Parsing with CCG and Log-Linear Models. In Computational Linguistics, volume 33, pages 493–552.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James R Curran</author>
<author>Stephen Clark</author>
</authors>
<title>Investigating GIS and smoothing for maximum entropy taggers.</title>
<date>2003</date>
<booktitle>In Proceedings of the 10th Meeting of the EACL,</booktitle>
<pages>91--98</pages>
<location>Budapest, Hungary.</location>
<contexts>
<context position="13713" citStr="Curran and Clark, 2003" startWordPosition="2272" endWordPosition="2275">ard Clark and Curran (2007) dependencybased evaluation from the CCG literature: labelled Fscore (LF) over dependency tuples, as used for CCG parser evaluation in English. Critically, this metric is also NLD-sensitive. We also report labelled sentence accuracy (Lsa), the proportion of sentences for which the parser returned all and only the gold standard dependencies. Supertagger accuracy compares leaf categories against the gold standard (stag). For C&amp;C, we report on two configurations: GoLD, evaluated using gold standard Pos tags; and AUTo, with automatic Pos tags provided by the C&amp;C tagger (Curran and Clark, 2003). For P&amp;K, we vary the number of split-merge iterations from one to six (following Fowler and Penn (2010), the k-iterations model is called I-k). Because the P&amp;K parser does not use Pos tags, the most appropriate comparison is against the AUTo configuration of C&amp;C. For C&amp;C, we use the average of the logarithm of the chart size (log C) as a measure of ambiguity, that is, the number of alternative analyses the parser must choose between. Following Fowler and Penn (2010), we perform two sets of experiments: one evaluated over all sentences in a section, and another evaluated only over sentences f</context>
</contexts>
<marker>Curran, Clark, 2003</marker>
<rawString>James R. Curran and Stephen Clark. 2003. Investigating GIS and smoothing for maximum entropy taggers. In Proceedings of the 10th Meeting of the EACL, pages 91–98. Budapest, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothy A D Fowler</author>
<author>Gerald Penn</author>
</authors>
<title>Accurate context-free parsing with combinatory categorial grammar.</title>
<date>2010</date>
<booktitle>Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>335--344</pages>
<contexts>
<context position="1763" citStr="Fowler and Penn (2010)" startWordPosition="263" endWordPosition="266"> al., 2004) and CCG (Hockenmaier and Steedman, 2007), producing the lexical resources key to wide-coverage statistical parsing. The Chinese Penn Treebank (PCTB; Xue et al., 2005) has filled a comparable niche, enabling the development of a Chinese LTAG (Xia et al., 2000), a wide-coverage HPSG parser (Yu et al., 2011), and recently Chinese CCGbank (Tse and Curran, 2010), a 750 000-word corpus of Combinatory Categorial Grammar (CCG; Steedman, 2000) derivations. We train two CCG parsers, Clark and Curran (C&amp;C; 2007), and the Petrov and Klein (P&amp;K; 2007) PCFG parser, on Chinese CCGbank. We follow Fowler and Penn (2010), who treat the English CCGbank (Hockenmaier and Steedman, 2007) grammar as a CFG and train and evaluate the P&amp;K parser directly on it. We obtain the first Chinese CCG parsing results: F-scores of 72.73 (P&amp;K) and 67.09 (C&amp;C) on labelled dependencies computed over the PCTB 6 test set. While the state-of-the-art in Chinese syntactic parsing has always lagged behind English, this large gap is surprising, given that Fowler and Penn (2010) found only a small margin separated the two parsers on English CCGbank (86.0 versus 85.8). Levy and Manning (2003) established that properties of Chinese such as</context>
<context position="12344" citStr="Fowler and Penn (2010)" startWordPosition="2058" endWordPosition="2061">ring training with a Gaussian smoothing parameter α = 2.4 (optimised on the corpus A dev set). We use 0 = (0.15, 0.075, 0.03, 0.01, 0.005, 0.001) during parsing, with the maximum number of supercats (chart entries) set to 5,000,000, reflecting the greater supertagging ambiguity of Chinese parsing. The P&amp;K parser is used “off-the-shelf” and trained with its default parameters, only varying the number of split-merge iterations and enabling the Chinesespecific lexicon features. The P&amp;K parser involves no explicit Pos tagging step, as the (super)tags correspond directly to non-terminals in a CFG. Fowler and Penn (2010) use the C&amp;C tool generate to convert P&amp;K output to the C&amp;C evaluation dependency format. generate critically does not depend on the C&amp;C parsing model, permitting a fair comparison of the parsers’ output. PCTB 5 +PCTB 6 #sents Train 1–815, 1001–1136 2000–2980 22033 Test 816–885, 1137–1147 3030–3145 2758 Dev 900–931, 1148–1151 2981–3029 1101 Table 1: PCTB 5 and 6 dev/train/test splits 4.1 Evaluation Carroll et al. (1998) argued against PARsEVAL in favour of a dependency-based evaluation. Rimell et al. (2009) focus on evaluating NLD recovery, proposing a dependency-based evaluation and a GR mapp</context>
<context position="13818" citStr="Fowler and Penn (2010)" startWordPosition="2292" endWordPosition="2295">dependency tuples, as used for CCG parser evaluation in English. Critically, this metric is also NLD-sensitive. We also report labelled sentence accuracy (Lsa), the proportion of sentences for which the parser returned all and only the gold standard dependencies. Supertagger accuracy compares leaf categories against the gold standard (stag). For C&amp;C, we report on two configurations: GoLD, evaluated using gold standard Pos tags; and AUTo, with automatic Pos tags provided by the C&amp;C tagger (Curran and Clark, 2003). For P&amp;K, we vary the number of split-merge iterations from one to six (following Fowler and Penn (2010), the k-iterations model is called I-k). Because the P&amp;K parser does not use Pos tags, the most appropriate comparison is against the AUTo configuration of C&amp;C. For C&amp;C, we use the average of the logarithm of the chart size (log C) as a measure of ambiguity, that is, the number of alternative analyses the parser must choose between. Following Fowler and Penn (2010), we perform two sets of experiments: one evaluated over all sentences in a section, and another evaluated only over sentences for which both parsers successfully parse and generate dependencies. We define the size of a CCG grammar a</context>
<context position="21715" citStr="Fowler and Penn (2010)" startWordPosition="3687" endWordPosition="3690"> in F-score of 1.50 and 1.75% respectively. This is expected; Chinese CCGbank does not distinguish between noun modifiers (NN) and adjectives (JJ). On the other hand, the critical noun/verb ambiguity, and the confusion between DEC/DEG (two senses of the particle 的 de) adversely impact F-score. We performed an experiment with C&amp;C to merge DEC and DEG into a single tag, but found that this increased category ambiguity without improving accuracy. The VV ▷◁ NN confusion is particularly damaging to the CCG labelled dependency evaluation, because verbs generate a large number of dependencies. While Fowler and Penn (2010) report a gap of 6.31% between C&amp;C’s labelled and unlabelled F-score on the development set in English, we observe a gap of 10.35% for Chinese. Table 10 breaks down the 8,414 false positives generated by C&amp;C on the dev set, according to whether the head of each dependency was incorrectly Pos-tagged and/or supertagged. The top-left cell shows that despite the correct Pos and supertag, C&amp;C makes a large number of pure attachment location errors. The vast majority of false positives, though, are 300 C&amp;C AUTo P&amp;K I-5 category NLD? LF freq LF freq 0.78 4204 0.78 3106 NP/NP 0.73 2173 0.81 1765 (S[dc</context>
<context position="25957" citStr="Fowler and Penn, 2010" startWordPosition="4353" endWordPosition="4356">rticle. Two categories which n, de receives in the grammar are (NP/NP)\(S[dcl]\NP) (introducing a relative clause) and (NP/NP)\S[dcl] (in the construction S de NP). Because subject pro-drop promotes any unsaturated S[dcl]\NP to S[dcl], whenever the supertagger returns both of the above categories for the lexical item n, de, the parser must consider two alternative analyses which yield different dependencies: (5) a. ti f* n, Mimi ti come out DE questioni the questions which arise 301 English Chinese PTB/PCTB-based 92.1% (McClosky et al., 2006) 86.8% (Zhang and Clark, 2009) CCGbank-based 86.0% (Fowler and Penn, 2010) 72.7% (this work) 85.8% (Clark and Curran, 2007) 67.1% (this work) Table 11: Summary of Chinese parsing approaches model LF Lsa % stag cov log C C GoLD 74.99 7.42 89.36 98.6 18.35 AUTo (76.73 20.56 89.66 99.5 13.58) 65.42 4.82 83.73 97.9 18.67 (66.95 14.62 83.90 99.2 13.86) I-5 70.67 8.62 84.99 93.8 - (72.74 18.59 85.61 96.5 -) Table 12: Dev set evaluation for C&amp;C over pro-drop sentences only (and over full set in parentheses) b. pro ffi来 n AM pro come out DE question the question of (him, her) coming out 38.1% of sentences in the development set contain at least one instance of pro-drop. The</context>
<context position="28666" citStr="Fowler and Penn (2010)" startWordPosition="4800" endWordPosition="4803">ch account most for the deficit. We start by using corpus conversion to compare different linguistic representation choices, rather than for generating a single immutable resource. This can also be exploited to develop syntactic corpora parameterised for particular applications. We found that collapsing categorial distinctions motivated by theory can yield less ambiguous corpora, and hence, more accurate parsers. We have also taken a novel approach to investigating the impact of noun/verb and other Pos ambiguities on parsing. The large gap between Chinese C&amp;C and P&amp;K is surprising, given that Fowler and Penn (2010) found only a small gap for English. We found that C&amp;C is very sensitive to Pos tagging performance, which leads to its inferior performance given automatically assigned Pos tags. This suggests that joint supertagging/parsing approaches, as performed by P&amp;K, are more suitable for Chinese. Finally, we have shown that pro-drop is correlated with poor performance on both parsers, suggesting an avenue to closing the Chinese-English parsing gap. While developing the first wide-coverage Chinese CCG parsers, we have shed light on the nature of the Chinese-English parsing gap, and identified new and s</context>
</contexts>
<marker>Fowler, Penn, 2010</marker>
<rawString>Timothy A.D. Fowler and Gerald Penn. 2010. Accurate context-free parsing with combinatory categorial grammar. Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 335–344.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuqing Guo</author>
<author>Haifeng Wang</author>
<author>Josef Van Genabith</author>
</authors>
<title>Recovering non-local dependencies for Chinese. In EMNLP/CoNLL,</title>
<date>2007</date>
<pages>257--266</pages>
<marker>Guo, Wang, Van Genabith, 2007</marker>
<rawString>Yuqing Guo, Haifeng Wang, and Josef Van Genabith. 2007. Recovering non-local dependencies for Chinese. In EMNLP/CoNLL, pages 257–266.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julia Hockenmaier</author>
</authors>
<title>Data and Models for Statistical Parsing with Combinatory Categorial Grammar.</title>
<date>2003</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Edinburgh.</institution>
<contexts>
<context position="9729" citStr="Hockenmaier (2003)" startWordPosition="1618" endWordPosition="1620">at least two categories, PP/NP and PP/LCP, while (2-b) trades off derivational for lexical ambiguity: the unary promotion LCP —* NP becomes necessary, but r± at no longer needs the category PP/LCP. The base release of Chinese CCGbank, corpus A, like (2-a), makes the distinction between categories LCP and NP. However, in corpus B, we test the impact of applying (2-b), in which the unary promotion LCP —* NP is available. 3.2 The bare/non-bare NP distinction The most frequent unary rule in English CCGbank, occurring in over 91% of sentences, is the promotion from bare to non-bare nouns: N —* NP. Hockenmaier (2003) explains that the rule accounts for the form-function distinction in determiner-less English nouns which nevertheless have definite reference, while preventing certain over-generations (e.g. *the the car). The N-NP distinction also separates adjectives and noun modifiers (category N/N), from predeterminers (category NP/NP) (Hockenmaier and Steedman, 2005), a distinction also made in Chinese. While Chinese has strategies to mark definite or indefinite reference, they are not obligatory, and a bare noun is referentially ambiguous, calling into question whether the distinction is justified in CC</context>
</contexts>
<marker>Hockenmaier, 2003</marker>
<rawString>Julia Hockenmaier. 2003. Data and Models for Statistical Parsing with Combinatory Categorial Grammar. Ph.D. thesis, University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julia Hockenmaier</author>
<author>Mark Steedman</author>
</authors>
<title>CCGbank: Users’ manual.</title>
<date>2005</date>
<tech>Technical report, MS-CIS-05-09,</tech>
<institution>Computer and Information Science, University of Pennsylvania.</institution>
<contexts>
<context position="10087" citStr="Hockenmaier and Steedman, 2005" startWordPosition="1664" endWordPosition="1667">mpact of applying (2-b), in which the unary promotion LCP —* NP is available. 3.2 The bare/non-bare NP distinction The most frequent unary rule in English CCGbank, occurring in over 91% of sentences, is the promotion from bare to non-bare nouns: N —* NP. Hockenmaier (2003) explains that the rule accounts for the form-function distinction in determiner-less English nouns which nevertheless have definite reference, while preventing certain over-generations (e.g. *the the car). The N-NP distinction also separates adjectives and noun modifiers (category N/N), from predeterminers (category NP/NP) (Hockenmaier and Steedman, 2005), a distinction also made in Chinese. While Chinese has strategies to mark definite or indefinite reference, they are not obligatory, and a bare noun is referentially ambiguous, calling into question whether the distinction is justified in CCG: (3) a. P1 dog Dogs are clever. b. R WSJ P1 dog 1SG see I saw a dog/dogs. c. P1 Rip- T dog run-away ASP The dog/dogs ran away. b. )�,- big 95it beside:LC LCP PP b. r± at M-T room _#_1 in:LC fa very QRJ clever 297 The fact that the Chinese determiner is not necessarily a maximal projection of the noun – in other words, the determiner does not ‘close off’ </context>
</contexts>
<marker>Hockenmaier, Steedman, 2005</marker>
<rawString>Julia Hockenmaier and Mark Steedman. 2005. CCGbank: Users’ manual. Technical report, MS-CIS-05-09, Computer and Information Science, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julia Hockenmaier</author>
<author>Mark Steedman</author>
</authors>
<title>CCGbank: A Corpus of CCG Derivations and Dependency Structures Extracted from the Penn Treebank.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>3</issue>
<contexts>
<context position="1193" citStr="Hockenmaier and Steedman, 2007" startWordPosition="172" endWordPosition="176"> (C&amp;C) parser, uncovering a surprising performance gap between them not observed in English — 72.73 (P&amp;K) and 67.09 (C&amp;C) F-score on PCTB 6. We explore the challenges of Chinese CCG parsing through three novel ideas: developing corpus variants rather than treating the corpus as fixed; controlling noun/verb and other POS ambiguities; and quantifying the impact of constructions like pro-drop. 1 Introduction Automatic corpus conversions from the Penn Treebank (Marcus et al., 1994) have driven research in lexicalised grammar formalisms, such as LTAG (Xia, 1999), HPSG (Miyao et al., 2004) and CCG (Hockenmaier and Steedman, 2007), producing the lexical resources key to wide-coverage statistical parsing. The Chinese Penn Treebank (PCTB; Xue et al., 2005) has filled a comparable niche, enabling the development of a Chinese LTAG (Xia et al., 2000), a wide-coverage HPSG parser (Yu et al., 2011), and recently Chinese CCGbank (Tse and Curran, 2010), a 750 000-word corpus of Combinatory Categorial Grammar (CCG; Steedman, 2000) derivations. We train two CCG parsers, Clark and Curran (C&amp;C; 2007), and the Petrov and Klein (P&amp;K; 2007) PCFG parser, on Chinese CCGbank. We follow Fowler and Penn (2010), who treat the English CCGban</context>
</contexts>
<marker>Hockenmaier, Steedman, 2007</marker>
<rawString>Julia Hockenmaier and Mark Steedman. 2007. CCGbank: A Corpus of CCG Derivations and Dependency Structures Extracted from the Penn Treebank. Computational Linguistics, 33(3):355–396.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Honnibal</author>
</authors>
<title>Hat Categories: Representing Form and Function Simultaneously in Combinatory Categorial Grammar.</title>
<date>2010</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Sydney.</institution>
<contexts>
<context position="7150" citStr="Honnibal, 2010" startWordPosition="1188" endWordPosition="1189">cal amb guityThe des gner of C G ank mus fre uently cho sebetw een der vational and lex cal amb guity (Ho k-enma ier, 200 ; Tse and Cur an, 201 ). Deri vationalambi guityanal yses spe ial con tructions thr ugh ar- itr ary lab l-rewriting phr se str cture rul s,whil elexi cal amb guity assi gns add tional cat gories to ex ical ite s for whe the par icipate in pe ial con stru ctions.296. exi calS/S( S/S )/NNF ig u Derivational and lexical ambiguity often arise in CCG because of the form-function distinction — when the syntactic form of a constituent does not coincide with its semantic function (Honnibal, 2010). For instance, in English, topicalisation causes an NP to appear in clause-initial position, fulfilling the function of a sentential pre-modifier while maintaining the form of an NP. Figure 2 shows two distinct CCG analyses which yield the same dependency edges. Derivational ambiguity increases the parser search space, while lexical ambiguity enlarges the tag set, and hence the complexity of the supertagging task. 3 Three versions of Chinese CCGbank We extract three versions of Chinese CCGbank to explore the trade-off between lexical and derivational ambiguity, training both parsers on each c</context>
</contexts>
<marker>Honnibal, 2010</marker>
<rawString>Matthew Honnibal. 2010. Hat Categories: Representing Form and Function Simultaneously in Combinatory Categorial Grammar. Ph.D. thesis, University of Sydney.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Huang</author>
<author>Wenbin Jiang</author>
<author>Qun Liu</author>
</authors>
<title>Bilingually-constrained (monolingual) shift-reduce parsing.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<volume>3</volume>
<pages>1222--1231</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="4220" citStr="Huang et al., 2009" startWordPosition="646" endWordPosition="649">S\NP) ≺ ≻B N/N S[dcl]/NP ≻ T S/(S/NP) ≻ S[dcl] Figure 1: 3 types of non-local dependencies in 6 words: “(As for) the trapped princess, I rescued (her).” ≻ S[dcl]\NP N −� NP 2 Background Bikel and Chiang (2000) developed the first  parser, demonstrating that Chinese was similar enough to English for techniques such as a Collinsstyle head-driven parser or  to succeed. Later  parsers used Tree Insertion Grammar (Chiang and Bikel, 2002), s (Levy and Manning, 2003), the Collins models (Bikel, 2004) and transition-based discriminative models (Wang et al., 2006; Zhang and Clark, 2009; Huang et al., 2009). These systems also established the relative difficulty of parsing Chinese and English; while  scores over 92% are possible for English (McClosky et al., 2006), systems for Chinese have achieved only 87% (Zhang and Clark, 2009) on the same metric. Non-local dependencies (s) are lexical dependencies which hold over unbounded distances. Guo et al. (2007) observed that despite the importance of s for correct semantic interpretation, and the fact that Chinese syntax generates more s than English, few parsers in Chinese are equipped to recover the traces which mark s. For insta</context>
</contexts>
<marker>Huang, Jiang, Liu, 2009</marker>
<rawString>Liang Huang, Wenbin Jiang, and Qun Liu. 2009. Bilingually-constrained (monolingual) shift-reduce parsing. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, volume 3, pages 1222–1231. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roger Levy</author>
<author>Christopher Manning</author>
</authors>
<title>Is it harder to parse Chinese, or the Chinese Treebank?</title>
<date>2003</date>
<booktitle>In Annual Meeting of the Association for Computational Linguistics,</booktitle>
<volume>1</volume>
<pages>439--446</pages>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="2316" citStr="Levy and Manning (2003)" startWordPosition="355" endWordPosition="358">007) PCFG parser, on Chinese CCGbank. We follow Fowler and Penn (2010), who treat the English CCGbank (Hockenmaier and Steedman, 2007) grammar as a CFG and train and evaluate the P&amp;K parser directly on it. We obtain the first Chinese CCG parsing results: F-scores of 72.73 (P&amp;K) and 67.09 (C&amp;C) on labelled dependencies computed over the PCTB 6 test set. While the state-of-the-art in Chinese syntactic parsing has always lagged behind English, this large gap is surprising, given that Fowler and Penn (2010) found only a small margin separated the two parsers on English CCGbank (86.0 versus 85.8). Levy and Manning (2003) established that properties of Chinese such as noun/verb ambiguity contribute to the difficulty of Chinese parsing. We focus on two factors within our control: annotation decisions and parser architecture. Existing research has varied parsers whilst keeping the corpus fixed. We vary the corpus whilst keeping the parsers fixed by exploring multiple design choices for particular constructions. By exploiting the fully automatic CCGbank extraction process, we can immediately implement these choices and assess their impact on parsing performance. Secondly, we contrast the performance of C&amp;C, with </context>
<context position="4080" citStr="Levy and Manning, 2003" startWordPosition="624" endWordPosition="628">inguistics 被 困 trap 的  公主 princess 我 I 解救了 rescued (S[dcl]\NP)/((S[dcl]\NP)/NP) (S[dcl]\NP)/NP (N/N)\(S[dcl]/NP) N NP (S[dcl]\NP)/NP ≻T S/(S\NP) ≺ ≻B N/N S[dcl]/NP ≻ T S/(S/NP) ≻ S[dcl] Figure 1: 3 types of non-local dependencies in 6 words: “(As for) the trapped princess, I rescued (her).” ≻ S[dcl]\NP N −� NP 2 Background Bikel and Chiang (2000) developed the first  parser, demonstrating that Chinese was similar enough to English for techniques such as a Collinsstyle head-driven parser or  to succeed. Later  parsers used Tree Insertion Grammar (Chiang and Bikel, 2002), s (Levy and Manning, 2003), the Collins models (Bikel, 2004) and transition-based discriminative models (Wang et al., 2006; Zhang and Clark, 2009; Huang et al., 2009). These systems also established the relative difficulty of parsing Chinese and English; while  scores over 92% are possible for English (McClosky et al., 2006), systems for Chinese have achieved only 87% (Zhang and Clark, 2009) on the same metric. Non-local dependencies (s) are lexical dependencies which hold over unbounded distances. Guo et al. (2007) observed that despite the importance of s for correct semantic interpretation, and the fac</context>
<context position="19910" citStr="Levy and Manning, 2003" startWordPosition="3366" endWordPosition="3369">er of V-shaped categories by 10%, while not substantially affecting the quantity of other category shapes, because the subcategorisation frames which previously referred to LCP are no longer necessary. Eliminating the N-NP distinction, however, reduces the number of P and M-shaped categories by over 20%, as the distinction is no longer made between attachment at N and NP. 6 Error analysis The well-known noun/verb ambiguity in Chinese (where, e.g., iRt建iR ‘design-build’ is both a verbal compound ‘design and build’ and a noun compound ‘design and construction’) greatly affects parsing accuracy (Levy and Manning, 2003). However, little work has quantified the impact of noun/verb ambiguity on parsing, and for that matter, the impact of other frequent confusion types. To quantify C&amp;C’s sensitivity to Pos tagging errors, Confusion LF ∆LF stag cov Base (GoLD) 76.73 89.66 99.50 NR ▷◁ NN 76.72 -0.01 89.64 99.37 JJ ▷◁ NN 76.60 -0.12 89.57 99.37 DEC ▷◁ DEG 75.10 -1.50 89.07 98.83 VV ▷◁ NN 73.35 -1.75 87.68 98.74 All (AUTo) 66.95 83.90 99.20 Table 8: Corrupting C&amp;C gold Pos tags piecemeal on PCTB 6 dev set of corpus C. ∆LF is the change in LF when each additional confusion type is allowed. which we saw in Table 3, w</context>
</contexts>
<marker>Levy, Manning, 2003</marker>
<rawString>Roger Levy and Christopher Manning. 2003. Is it harder to parse Chinese, or the Chinese Treebank? In Annual Meeting of the Association for Computational Linguistics, volume 1, pages 439–446. Morristown, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles N Li</author>
<author>Sandra A Thompson</author>
</authors>
<title>Mandarin Chinese: A functional reference grammar.</title>
<date>1989</date>
<publisher>University of California Press.</publisher>
<contexts>
<context position="8216" citStr="Li and Thompson, 1989" startWordPosition="1354" endWordPosition="1357">se CCGbank We extract three versions of Chinese CCGbank to explore the trade-off between lexical and derivational ambiguity, training both parsers on each corpus to determine the impact of the annotation changes. Our hypothesis is that the scarcity of training data in Chinese means that derivational ambiguity results in better coverage and accuracy, at the cost of increasing time and space requirements of the resulting parser. 3.1 The lexical category LC (localiser) In the following sentences, the words in bold have often been analysed as belonging to a lexical category localiser (Chao, 1968; Li and Thompson, 1989). (1) a. &amp;-T _#_1ffii house inside:LC the inside of the house/inside the house W tree (the area) beside the big tree Localisers, like English prepositions, identify a (temporal, spatial, etc.) extent of their complement. However, the combination Noun + Localiser is ambiguous between noun function (the inside of the house) and modifier function (inside the house). We consider two possibilities to represent localisers in CCG, which trade derivational for lexical ambiguity. In (2-a), a direct CCG transfer of the PCTB analysis, the preposition r± at expects arguments of type LCP. In (2-b), r± at n</context>
<context position="24995" citStr="Li and Thompson, 1989" startWordPosition="4204" endWordPosition="4207">y recovering NP-internal structure, the ability of P&amp;K to recover verbal arguments, unbounded long-range dependencies such as subject and object extraction, and bounded long-range dependencies such as control/raising constructions, is superior. 6.2 Pro-drop and its impact on  parsing One of the most common types of unary rules in Chinese CCGbank, occurring in 36% of Chinese CCGbank sentences, is the subject pro-drop rule S[dcl]\NP —* S[dcl], which accounts for the optional absence of the subject pronoun of a verb for pragmatic reasons where the referent can be recovered from the discourse (Li and Thompson, 1989). The subject pro-drop rule is problematic in Chinese parsing because its left hand side, S[dcl]\NP, is a very common category, and also because several syntactic distinctions in Chinese CCGbank hinge on the difference between S[dcl]\NP and S[dcl]. The latter point is illustrated by two of the senses of n, de, the Chinese subordinating particle. Two categories which n, de receives in the grammar are (NP/NP)\(S[dcl]\NP) (introducing a relative clause) and (NP/NP)\S[dcl] (in the construction S de NP). Because subject pro-drop promotes any unsaturated S[dcl]\NP to S[dcl], whenever the supertagger</context>
</contexts>
<marker>Li, Thompson, 1989</marker>
<rawString>Charles N. Li and Sandra A. Thompson. 1989. Mandarin Chinese: A functional reference grammar. University of California Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Beatrice Santorini</author>
<author>Mary Ann Marcinkiewicz</author>
</authors>
<title>Building a Large Annotated Corpus of English: The Penn Treebank. Computational Linguistics,</title>
<date>1994</date>
<contexts>
<context position="1044" citStr="Marcus et al., 1994" startWordPosition="149" endWordPosition="152">e particularly frequent. We train two state-of-the-art English CCG parsers: the parser of Petrov and Klein (P&amp;K), and the Clark and Curran (C&amp;C) parser, uncovering a surprising performance gap between them not observed in English — 72.73 (P&amp;K) and 67.09 (C&amp;C) F-score on PCTB 6. We explore the challenges of Chinese CCG parsing through three novel ideas: developing corpus variants rather than treating the corpus as fixed; controlling noun/verb and other POS ambiguities; and quantifying the impact of constructions like pro-drop. 1 Introduction Automatic corpus conversions from the Penn Treebank (Marcus et al., 1994) have driven research in lexicalised grammar formalisms, such as LTAG (Xia, 1999), HPSG (Miyao et al., 2004) and CCG (Hockenmaier and Steedman, 2007), producing the lexical resources key to wide-coverage statistical parsing. The Chinese Penn Treebank (PCTB; Xue et al., 2005) has filled a comparable niche, enabling the development of a Chinese LTAG (Xia et al., 2000), a wide-coverage HPSG parser (Yu et al., 2011), and recently Chinese CCGbank (Tse and Curran, 2010), a 750 000-word corpus of Combinatory Categorial Grammar (CCG; Steedman, 2000) derivations. We train two CCG parsers, Clark and Cur</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1994</marker>
<rawString>Mitchell P. Marcus, Beatrice Santorini, and Mary Ann Marcinkiewicz. 1994. Building a Large Annotated Corpus of English: The Penn Treebank. Computational Linguistics, 19(2):313–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David McClosky</author>
<author>Eugene Charniak</author>
<author>Mark Johnson</author>
</authors>
<title>Effective self-training for parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of the main conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics,</booktitle>
<pages>152--159</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="4388" citStr="McClosky et al., 2006" startWordPosition="671" endWordPosition="674">N −� NP 2 Background Bikel and Chiang (2000) developed the first  parser, demonstrating that Chinese was similar enough to English for techniques such as a Collinsstyle head-driven parser or  to succeed. Later  parsers used Tree Insertion Grammar (Chiang and Bikel, 2002), s (Levy and Manning, 2003), the Collins models (Bikel, 2004) and transition-based discriminative models (Wang et al., 2006; Zhang and Clark, 2009; Huang et al., 2009). These systems also established the relative difficulty of parsing Chinese and English; while  scores over 92% are possible for English (McClosky et al., 2006), systems for Chinese have achieved only 87% (Zhang and Clark, 2009) on the same metric. Non-local dependencies (s) are lexical dependencies which hold over unbounded distances. Guo et al. (2007) observed that despite the importance of s for correct semantic interpretation, and the fact that Chinese syntax generates more s than English, few parsers in Chinese are equipped to recover the traces which mark s. For instance, extraction, a common  type, occurs more frequently in  sentences (38%) compared to  (17%). A more satisfying approach is to use a grammar formalism, such</context>
<context position="25883" citStr="McClosky et al., 2006" startWordPosition="4342" endWordPosition="4345">is illustrated by two of the senses of n, de, the Chinese subordinating particle. Two categories which n, de receives in the grammar are (NP/NP)\(S[dcl]\NP) (introducing a relative clause) and (NP/NP)\S[dcl] (in the construction S de NP). Because subject pro-drop promotes any unsaturated S[dcl]\NP to S[dcl], whenever the supertagger returns both of the above categories for the lexical item n, de, the parser must consider two alternative analyses which yield different dependencies: (5) a. ti f* n, Mimi ti come out DE questioni the questions which arise 301 English Chinese PTB/PCTB-based 92.1% (McClosky et al., 2006) 86.8% (Zhang and Clark, 2009) CCGbank-based 86.0% (Fowler and Penn, 2010) 72.7% (this work) 85.8% (Clark and Curran, 2007) 67.1% (this work) Table 11: Summary of Chinese parsing approaches model LF Lsa % stag cov log C C GoLD 74.99 7.42 89.36 98.6 18.35 AUTo (76.73 20.56 89.66 99.5 13.58) 65.42 4.82 83.73 97.9 18.67 (66.95 14.62 83.90 99.2 13.86) I-5 70.67 8.62 84.99 93.8 - (72.74 18.59 85.61 96.5 -) Table 12: Dev set evaluation for C&amp;C over pro-drop sentences only (and over full set in parentheses) b. pro ffi来 n AM pro come out DE question the question of (him, her) coming out 38.1% of sente</context>
</contexts>
<marker>McClosky, Charniak, Johnson, 2006</marker>
<rawString>David McClosky, Eugene Charniak, and Mark Johnson. 2006. Effective self-training for parsing. In Proceedings of the main conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics, pages 152–159. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yusuke Miyao</author>
<author>Takashi Ninomiya</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Corpus-Oriented Grammar Development for Acquiring a Head-Driven Phrase Structure Grammar from the Penn Treebank.</title>
<date>2004</date>
<pages>684--693</pages>
<contexts>
<context position="1152" citStr="Miyao et al., 2004" startWordPosition="166" endWordPosition="169">&amp;K), and the Clark and Curran (C&amp;C) parser, uncovering a surprising performance gap between them not observed in English — 72.73 (P&amp;K) and 67.09 (C&amp;C) F-score on PCTB 6. We explore the challenges of Chinese CCG parsing through three novel ideas: developing corpus variants rather than treating the corpus as fixed; controlling noun/verb and other POS ambiguities; and quantifying the impact of constructions like pro-drop. 1 Introduction Automatic corpus conversions from the Penn Treebank (Marcus et al., 1994) have driven research in lexicalised grammar formalisms, such as LTAG (Xia, 1999), HPSG (Miyao et al., 2004) and CCG (Hockenmaier and Steedman, 2007), producing the lexical resources key to wide-coverage statistical parsing. The Chinese Penn Treebank (PCTB; Xue et al., 2005) has filled a comparable niche, enabling the development of a Chinese LTAG (Xia et al., 2000), a wide-coverage HPSG parser (Yu et al., 2011), and recently Chinese CCGbank (Tse and Curran, 2010), a 750 000-word corpus of Combinatory Categorial Grammar (CCG; Steedman, 2000) derivations. We train two CCG parsers, Clark and Curran (C&amp;C; 2007), and the Petrov and Klein (P&amp;K; 2007) PCFG parser, on Chinese CCGbank. We follow Fowler and </context>
</contexts>
<marker>Miyao, Ninomiya, Tsujii, 2004</marker>
<rawString>Yusuke Miyao, Takashi Ninomiya, and Jun’ichi Tsujii. 2004. Corpus-Oriented Grammar Development for Acquiring a Head-Driven Phrase Structure Grammar from the Penn Treebank. pages 684–693.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Dan Klein</author>
</authors>
<title>Improved inference for unlexicalized parsing.</title>
<date>2007</date>
<booktitle>In Proceedings of NAACL HLT</booktitle>
<pages>404--411</pages>
<marker>Petrov, Klein, 2007</marker>
<rawString>Slav Petrov and Dan Klein. 2007. Improved inference for unlexicalized parsing. In Proceedings of NAACL HLT 2007, pages 404–411.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Laura Rimell</author>
<author>Stephen Clark</author>
<author>Mark Steedman</author>
</authors>
<title>Unbounded dependency recovery for parser evaluation.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume</booktitle>
<volume>2</volume>
<pages>813--821</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="5268" citStr="Rimell et al., 2009" startWordPosition="813" endWordPosition="816">ntic interpretation, and the fact that Chinese syntax generates more s than English, few parsers in Chinese are equipped to recover the traces which mark s. For instance, extraction, a common  type, occurs more frequently in  sentences (38%) compared to  (17%). A more satisfying approach is to use a grammar formalism, such as  (Steedman, 2000), which generates them inherently, enabling a unified parsing model over local and non-local dependencies. This approach is taken in the C&amp;C parser (Clark and Curran, 2007), which can directly and transparently recover s in English (Rimell et al., 2009). Chinese CCGbank (Tse and Curran, 2010) demonstrates that a parsimonious account of Chinese syntax with  is possible. Many familiar objects of Chinese syntax which generate s, including the 把 ba/被 bei constructions, topicalisation and extraction receive natural  analyses in Chinese (a) Derivational S/S (b) L PN N N N P/ re2:Two typ s of mb guity CCGb ank.Figure1shows the CCG ank ana ysisof p as ivisation,topi calisation and ext action,crea t-ing s bet een公主princessand eac of被  , 困tr a p and解 救re sc ueresp ectively.We t ak two sta e-of-the-art par ers and tra n the to e st blish </context>
<context position="12856" citStr="Rimell et al. (2009)" startWordPosition="2139" endWordPosition="2142">t Pos tagging step, as the (super)tags correspond directly to non-terminals in a CFG. Fowler and Penn (2010) use the C&amp;C tool generate to convert P&amp;K output to the C&amp;C evaluation dependency format. generate critically does not depend on the C&amp;C parsing model, permitting a fair comparison of the parsers’ output. PCTB 5 +PCTB 6 #sents Train 1–815, 1001–1136 2000–2980 22033 Test 816–885, 1137–1147 3030–3145 2758 Dev 900–931, 1148–1151 2981–3029 1101 Table 1: PCTB 5 and 6 dev/train/test splits 4.1 Evaluation Carroll et al. (1998) argued against PARsEVAL in favour of a dependency-based evaluation. Rimell et al. (2009) focus on evaluating NLD recovery, proposing a dependency-based evaluation and a GR mapping procedure for inter-parser comparison. Since the P&amp;K parser plus generate produce dependencies in the same format as C&amp;C, we can use the standard Clark and Curran (2007) dependencybased evaluation from the CCG literature: labelled Fscore (LF) over dependency tuples, as used for CCG parser evaluation in English. Critically, this metric is also NLD-sensitive. We also report labelled sentence accuracy (Lsa), the proportion of sentences for which the parser returned all and only the gold standard dependenci</context>
</contexts>
<marker>Rimell, Clark, Steedman, 2009</marker>
<rawString>Laura Rimell, Stephen Clark, and Mark Steedman. 2009. Unbounded dependency recovery for parser evaluation. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 2-Volume 2, pages 813–821. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steedman</author>
</authors>
<title>The Syntactic Process.</title>
<date>2000</date>
<publisher>MIT Press.</publisher>
<location>Cambridge, MA, USA.</location>
<contexts>
<context position="1591" citStr="Steedman, 2000" startWordPosition="236" endWordPosition="237">atic corpus conversions from the Penn Treebank (Marcus et al., 1994) have driven research in lexicalised grammar formalisms, such as LTAG (Xia, 1999), HPSG (Miyao et al., 2004) and CCG (Hockenmaier and Steedman, 2007), producing the lexical resources key to wide-coverage statistical parsing. The Chinese Penn Treebank (PCTB; Xue et al., 2005) has filled a comparable niche, enabling the development of a Chinese LTAG (Xia et al., 2000), a wide-coverage HPSG parser (Yu et al., 2011), and recently Chinese CCGbank (Tse and Curran, 2010), a 750 000-word corpus of Combinatory Categorial Grammar (CCG; Steedman, 2000) derivations. We train two CCG parsers, Clark and Curran (C&amp;C; 2007), and the Petrov and Klein (P&amp;K; 2007) PCFG parser, on Chinese CCGbank. We follow Fowler and Penn (2010), who treat the English CCGbank (Hockenmaier and Steedman, 2007) grammar as a CFG and train and evaluate the P&amp;K parser directly on it. We obtain the first Chinese CCG parsing results: F-scores of 72.73 (P&amp;K) and 67.09 (C&amp;C) on labelled dependencies computed over the PCTB 6 test set. While the state-of-the-art in Chinese syntactic parsing has always lagged behind English, this large gap is surprising, given that Fowler and P</context>
<context position="5012" citStr="Steedman, 2000" startWordPosition="774" endWordPosition="775"> for Chinese have achieved only 87% (Zhang and Clark, 2009) on the same metric. Non-local dependencies (s) are lexical dependencies which hold over unbounded distances. Guo et al. (2007) observed that despite the importance of s for correct semantic interpretation, and the fact that Chinese syntax generates more s than English, few parsers in Chinese are equipped to recover the traces which mark s. For instance, extraction, a common  type, occurs more frequently in  sentences (38%) compared to  (17%). A more satisfying approach is to use a grammar formalism, such as  (Steedman, 2000), which generates them inherently, enabling a unified parsing model over local and non-local dependencies. This approach is taken in the C&amp;C parser (Clark and Curran, 2007), which can directly and transparently recover s in English (Rimell et al., 2009). Chinese CCGbank (Tse and Curran, 2010) demonstrates that a parsimonious account of Chinese syntax with  is possible. Many familiar objects of Chinese syntax which generate s, including the 把 ba/被 bei constructions, topicalisation and extraction receive natural  analyses in Chinese (a) Derivational S/S (b) L PN N N N P/ re2:Two typ </context>
</contexts>
<marker>Steedman, 2000</marker>
<rawString>Mark Steedman. 2000. The Syntactic Process. MIT Press. Cambridge, MA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Tse</author>
<author>James R Curran</author>
</authors>
<title>Chinese CCGbank: extracting CCG derivations from the Penn Chinese Treebank.</title>
<date>2010</date>
<booktitle>Proceedings of the 23rd International Conference on Computational Linguistics (COLING</booktitle>
<pages>1083--1091</pages>
<contexts>
<context position="1512" citStr="Tse and Curran, 2010" startWordPosition="223" endWordPosition="226">ties; and quantifying the impact of constructions like pro-drop. 1 Introduction Automatic corpus conversions from the Penn Treebank (Marcus et al., 1994) have driven research in lexicalised grammar formalisms, such as LTAG (Xia, 1999), HPSG (Miyao et al., 2004) and CCG (Hockenmaier and Steedman, 2007), producing the lexical resources key to wide-coverage statistical parsing. The Chinese Penn Treebank (PCTB; Xue et al., 2005) has filled a comparable niche, enabling the development of a Chinese LTAG (Xia et al., 2000), a wide-coverage HPSG parser (Yu et al., 2011), and recently Chinese CCGbank (Tse and Curran, 2010), a 750 000-word corpus of Combinatory Categorial Grammar (CCG; Steedman, 2000) derivations. We train two CCG parsers, Clark and Curran (C&amp;C; 2007), and the Petrov and Klein (P&amp;K; 2007) PCFG parser, on Chinese CCGbank. We follow Fowler and Penn (2010), who treat the English CCGbank (Hockenmaier and Steedman, 2007) grammar as a CFG and train and evaluate the P&amp;K parser directly on it. We obtain the first Chinese CCG parsing results: F-scores of 72.73 (P&amp;K) and 67.09 (C&amp;C) on labelled dependencies computed over the PCTB 6 test set. While the state-of-the-art in Chinese syntactic parsing has alwa</context>
<context position="5308" citStr="Tse and Curran, 2010" startWordPosition="819" endWordPosition="822">Chinese syntax generates more s than English, few parsers in Chinese are equipped to recover the traces which mark s. For instance, extraction, a common  type, occurs more frequently in  sentences (38%) compared to  (17%). A more satisfying approach is to use a grammar formalism, such as  (Steedman, 2000), which generates them inherently, enabling a unified parsing model over local and non-local dependencies. This approach is taken in the C&amp;C parser (Clark and Curran, 2007), which can directly and transparently recover s in English (Rimell et al., 2009). Chinese CCGbank (Tse and Curran, 2010) demonstrates that a parsimonious account of Chinese syntax with  is possible. Many familiar objects of Chinese syntax which generate s, including the 把 ba/被 bei constructions, topicalisation and extraction receive natural  analyses in Chinese (a) Derivational S/S (b) L PN N N N P/ re2:Two typ s of mb guity CCGb ank.Figure1shows the CCG ank ana ysisof p as ivisation,topi calisation and ext action,crea t-ing s bet een公主princessand eac of被  , 困tr a p and解 救re sc ueresp ectively.We t ak two sta e-of-the-art par ers and tra n the to e st blish the dif culty of ar ing Chi ese wit .</context>
<context position="27452" citStr="Tse and Curran, 2010" startWordPosition="4607" endWordPosition="4610">ore and supertagging accuracy are largest for P&amp;K. Critically, the fact that supertagging performance on these more difficult sentences is reasonably comparable with performance on the full set suggests that the bottleneck is in the parser rather than the supertagger. One measure of the complexity of prodrop sentences is the substantial increase in the log C value of these sentences. This suggests that a key to bringing parser performance on Chinese in line with English lies in reining in the ambiguity caused by very productive unary rules such as pro-drop. 7 Conclusion Using Chinese CCGbank (Tse and Curran, 2010), we have trained and evaluated the first CCG parsers for Chinese in the literature: the Clark and Curran (C&amp;C; 2007) and Petrov and Klein (P&amp;K; 2007) parsers. The P&amp;K parser substantially outperformed (72.73) C&amp;C with automatic Pos tags (67.09). Table 11 summarises the best performance of parsers on PTB and CCGbank, for English and Chinese. We observe a drop in performance between English and Chinese CCG parsers which is much larger than, but consistent with, PT� parsers. To close this gap, future research in Chinese parsing should be informed by quantifying the aspects of Chinese which accou</context>
</contexts>
<marker>Tse, Curran, 2010</marker>
<rawString>Daniel Tse and James R. Curran. 2010. Chinese CCGbank: extracting CCG derivations from the Penn Chinese Treebank. Proceedings of the 23rd International Conference on Computational Linguistics (COLING 2010), pages 1083–1091.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mengqiu Wang</author>
<author>Kenji Sagae</author>
<author>Teruko Mitamura</author>
</authors>
<title>A fast, accurate deterministic parser for Chinese.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics,</booktitle>
<pages>425--432</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="4176" citStr="Wang et al., 2006" startWordPosition="638" endWordPosition="641">/N)\(S[dcl]/NP) N NP (S[dcl]\NP)/NP ≻T S/(S\NP) ≺ ≻B N/N S[dcl]/NP ≻ T S/(S/NP) ≻ S[dcl] Figure 1: 3 types of non-local dependencies in 6 words: “(As for) the trapped princess, I rescued (her).” ≻ S[dcl]\NP N −� NP 2 Background Bikel and Chiang (2000) developed the first  parser, demonstrating that Chinese was similar enough to English for techniques such as a Collinsstyle head-driven parser or  to succeed. Later  parsers used Tree Insertion Grammar (Chiang and Bikel, 2002), s (Levy and Manning, 2003), the Collins models (Bikel, 2004) and transition-based discriminative models (Wang et al., 2006; Zhang and Clark, 2009; Huang et al., 2009). These systems also established the relative difficulty of parsing Chinese and English; while  scores over 92% are possible for English (McClosky et al., 2006), systems for Chinese have achieved only 87% (Zhang and Clark, 2009) on the same metric. Non-local dependencies (s) are lexical dependencies which hold over unbounded distances. Guo et al. (2007) observed that despite the importance of s for correct semantic interpretation, and the fact that Chinese syntax generates more s than English, few parsers in Chinese are equipped to r</context>
</contexts>
<marker>Wang, Sagae, Mitamura, 2006</marker>
<rawString>Mengqiu Wang, Kenji Sagae, and Teruko Mitamura. 2006. A fast, accurate deterministic parser for Chinese. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics, pages 425–432. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Xia</author>
</authors>
<title>Extracting tree adjoining grammars from bracketed corpora.</title>
<date>1999</date>
<booktitle>In Proceedings of Natural Language Processing Pacific Rim Symposium ’99,</booktitle>
<pages>398--403</pages>
<contexts>
<context position="1125" citStr="Xia, 1999" startWordPosition="163" endWordPosition="164">etrov and Klein (P&amp;K), and the Clark and Curran (C&amp;C) parser, uncovering a surprising performance gap between them not observed in English — 72.73 (P&amp;K) and 67.09 (C&amp;C) F-score on PCTB 6. We explore the challenges of Chinese CCG parsing through three novel ideas: developing corpus variants rather than treating the corpus as fixed; controlling noun/verb and other POS ambiguities; and quantifying the impact of constructions like pro-drop. 1 Introduction Automatic corpus conversions from the Penn Treebank (Marcus et al., 1994) have driven research in lexicalised grammar formalisms, such as LTAG (Xia, 1999), HPSG (Miyao et al., 2004) and CCG (Hockenmaier and Steedman, 2007), producing the lexical resources key to wide-coverage statistical parsing. The Chinese Penn Treebank (PCTB; Xue et al., 2005) has filled a comparable niche, enabling the development of a Chinese LTAG (Xia et al., 2000), a wide-coverage HPSG parser (Yu et al., 2011), and recently Chinese CCGbank (Tse and Curran, 2010), a 750 000-word corpus of Combinatory Categorial Grammar (CCG; Steedman, 2000) derivations. We train two CCG parsers, Clark and Curran (C&amp;C; 2007), and the Petrov and Klein (P&amp;K; 2007) PCFG parser, on Chinese CCG</context>
</contexts>
<marker>Xia, 1999</marker>
<rawString>Fei Xia. 1999. Extracting tree adjoining grammars from bracketed corpora. In Proceedings of Natural Language Processing Pacific Rim Symposium ’99, pages 398–403.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Xia</author>
<author>Chung-hye Han</author>
<author>Martha Palmer</author>
<author>Aravind Joshi</author>
</authors>
<title>Comparing lexicalized treebank grammars extracted from Chinese, Korean, and English corpora.</title>
<date>2000</date>
<booktitle>In Proceedings of the second workshop on Chinese language processing: held in conjunction with the 38th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<volume>12</volume>
<pages>52--59</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="1412" citStr="Xia et al., 2000" startWordPosition="207" endWordPosition="210">s variants rather than treating the corpus as fixed; controlling noun/verb and other POS ambiguities; and quantifying the impact of constructions like pro-drop. 1 Introduction Automatic corpus conversions from the Penn Treebank (Marcus et al., 1994) have driven research in lexicalised grammar formalisms, such as LTAG (Xia, 1999), HPSG (Miyao et al., 2004) and CCG (Hockenmaier and Steedman, 2007), producing the lexical resources key to wide-coverage statistical parsing. The Chinese Penn Treebank (PCTB; Xue et al., 2005) has filled a comparable niche, enabling the development of a Chinese LTAG (Xia et al., 2000), a wide-coverage HPSG parser (Yu et al., 2011), and recently Chinese CCGbank (Tse and Curran, 2010), a 750 000-word corpus of Combinatory Categorial Grammar (CCG; Steedman, 2000) derivations. We train two CCG parsers, Clark and Curran (C&amp;C; 2007), and the Petrov and Klein (P&amp;K; 2007) PCFG parser, on Chinese CCGbank. We follow Fowler and Penn (2010), who treat the English CCGbank (Hockenmaier and Steedman, 2007) grammar as a CFG and train and evaluate the P&amp;K parser directly on it. We obtain the first Chinese CCG parsing results: F-scores of 72.73 (P&amp;K) and 67.09 (C&amp;C) on labelled dependencies</context>
</contexts>
<marker>Xia, Han, Palmer, Joshi, 2000</marker>
<rawString>Fei Xia, Chung-hye Han, Martha Palmer, and Aravind Joshi. 2000. Comparing lexicalized treebank grammars extracted from Chinese, Korean, and English corpora. In Proceedings of the second workshop on Chinese language processing: held in conjunction with the 38th Annual Meeting of the Association for Computational Linguistics, volume 12, pages 52–59. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
<author>Fei Xia</author>
<author>Fu-Dong Chiou</author>
<author>Martha Palmer</author>
</authors>
<title>The Penn Chinese TreeBank: Phrase structure annotation of a large corpus.</title>
<date>2005</date>
<journal>Natural Language Engineering,</journal>
<volume>11</volume>
<issue>02</issue>
<contexts>
<context position="1319" citStr="Xue et al., 2005" startWordPosition="191" endWordPosition="194"> We explore the challenges of Chinese CCG parsing through three novel ideas: developing corpus variants rather than treating the corpus as fixed; controlling noun/verb and other POS ambiguities; and quantifying the impact of constructions like pro-drop. 1 Introduction Automatic corpus conversions from the Penn Treebank (Marcus et al., 1994) have driven research in lexicalised grammar formalisms, such as LTAG (Xia, 1999), HPSG (Miyao et al., 2004) and CCG (Hockenmaier and Steedman, 2007), producing the lexical resources key to wide-coverage statistical parsing. The Chinese Penn Treebank (PCTB; Xue et al., 2005) has filled a comparable niche, enabling the development of a Chinese LTAG (Xia et al., 2000), a wide-coverage HPSG parser (Yu et al., 2011), and recently Chinese CCGbank (Tse and Curran, 2010), a 750 000-word corpus of Combinatory Categorial Grammar (CCG; Steedman, 2000) derivations. We train two CCG parsers, Clark and Curran (C&amp;C; 2007), and the Petrov and Klein (P&amp;K; 2007) PCFG parser, on Chinese CCGbank. We follow Fowler and Penn (2010), who treat the English CCGbank (Hockenmaier and Steedman, 2007) grammar as a CFG and train and evaluate the P&amp;K parser directly on it. We obtain the first </context>
</contexts>
<marker>Xue, Xia, Chiou, Palmer, 2005</marker>
<rawString>Nianwen Xue, Fei Xia, Fu-Dong Chiou, and Martha Palmer. 2005. The Penn Chinese TreeBank: Phrase structure annotation of a large corpus. Natural Language Engineering, 11(02):207–238.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kun Yu</author>
<author>Yusuke Miyao</author>
<author>Takuya Matsuzaki</author>
<author>Xiangli Wang</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Analysis of the difficulties in chinese deep parsing.</title>
<date>2011</date>
<booktitle>In 12th International Conference on Parsing Technologies,</booktitle>
<pages>48</pages>
<contexts>
<context position="1459" citStr="Yu et al., 2011" startWordPosition="215" endWordPosition="218">xed; controlling noun/verb and other POS ambiguities; and quantifying the impact of constructions like pro-drop. 1 Introduction Automatic corpus conversions from the Penn Treebank (Marcus et al., 1994) have driven research in lexicalised grammar formalisms, such as LTAG (Xia, 1999), HPSG (Miyao et al., 2004) and CCG (Hockenmaier and Steedman, 2007), producing the lexical resources key to wide-coverage statistical parsing. The Chinese Penn Treebank (PCTB; Xue et al., 2005) has filled a comparable niche, enabling the development of a Chinese LTAG (Xia et al., 2000), a wide-coverage HPSG parser (Yu et al., 2011), and recently Chinese CCGbank (Tse and Curran, 2010), a 750 000-word corpus of Combinatory Categorial Grammar (CCG; Steedman, 2000) derivations. We train two CCG parsers, Clark and Curran (C&amp;C; 2007), and the Petrov and Klein (P&amp;K; 2007) PCFG parser, on Chinese CCGbank. We follow Fowler and Penn (2010), who treat the English CCGbank (Hockenmaier and Steedman, 2007) grammar as a CFG and train and evaluate the P&amp;K parser directly on it. We obtain the first Chinese CCG parsing results: F-scores of 72.73 (P&amp;K) and 67.09 (C&amp;C) on labelled dependencies computed over the PCTB 6 test set. While the s</context>
</contexts>
<marker>Yu, Miyao, Matsuzaki, Wang, Tsujii, 2011</marker>
<rawString>Kun Yu, Yusuke Miyao, Takuya Matsuzaki, Xiangli Wang, and Jun’ichi Tsujii. 2011. Analysis of the difficulties in chinese deep parsing. In 12th International Conference on Parsing Technologies, page 48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yue Zhang</author>
<author>Stephen Clark</author>
</authors>
<title>A tale of two parsers: investigating and combining graph-based and transition-based dependency parsing using beamsearch.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>562--571</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="11304" citStr="Zhang and Clark (2008)" startWordPosition="1882" endWordPosition="1885">off’ a level of NP – also argues against importing the English analysis. In contrast, the English CCGbank determiner category NP/N reflects the fact that determiners ‘close off’ NP — further modification by noun modifiers is blocked after combining with a determiner. (4) 共和党 Republican Party this action by the Republican Party To test its impact on Chinese parsing, we create a version of Chinese CCGbank (corpus C) which neutralises the distinction. This eliminates the atomic category N, as well as the promotion rule N —* NP. 4 Experiments While a standard split of PCTB 5 exists, as defined by Zhang and Clark (2008), we are not aware of a consistently used split for PCTB 6. We present a new split in Table 1 which adds data from the ACE broadcast section of PCTB 6, maintaining the same train/dev/test set proportions as the PCTB 5 split. We train C&amp;C using the hybrid model, the bestperforming model for English, which extracts features from the dependency structure (Clark and Curran, 2007). We use 0 = (0.055, 0.01, 0.05, 0.1) during training with a Gaussian smoothing parameter α = 2.4 (optimised on the corpus A dev set). We use 0 = (0.15, 0.075, 0.03, 0.01, 0.005, 0.001) during parsing, with the maximum num</context>
</contexts>
<marker>Zhang, Clark, 2008</marker>
<rawString>Yue Zhang and Stephen Clark. 2008. A tale of two parsers: investigating and combining graph-based and transition-based dependency parsing using beamsearch. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 562–571. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yue Zhang</author>
<author>Stephen Clark</author>
</authors>
<title>Transition-based parsing of the Chinese treebank using a global discriminative model.</title>
<date>2009</date>
<booktitle>In Proceedings of the 11th International Conference on Parsing Technologies,</booktitle>
<pages>162--171</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="4199" citStr="Zhang and Clark, 2009" startWordPosition="642" endWordPosition="645">P (S[dcl]\NP)/NP ≻T S/(S\NP) ≺ ≻B N/N S[dcl]/NP ≻ T S/(S/NP) ≻ S[dcl] Figure 1: 3 types of non-local dependencies in 6 words: “(As for) the trapped princess, I rescued (her).” ≻ S[dcl]\NP N −� NP 2 Background Bikel and Chiang (2000) developed the first  parser, demonstrating that Chinese was similar enough to English for techniques such as a Collinsstyle head-driven parser or  to succeed. Later  parsers used Tree Insertion Grammar (Chiang and Bikel, 2002), s (Levy and Manning, 2003), the Collins models (Bikel, 2004) and transition-based discriminative models (Wang et al., 2006; Zhang and Clark, 2009; Huang et al., 2009). These systems also established the relative difficulty of parsing Chinese and English; while  scores over 92% are possible for English (McClosky et al., 2006), systems for Chinese have achieved only 87% (Zhang and Clark, 2009) on the same metric. Non-local dependencies (s) are lexical dependencies which hold over unbounded distances. Guo et al. (2007) observed that despite the importance of s for correct semantic interpretation, and the fact that Chinese syntax generates more s than English, few parsers in Chinese are equipped to recover the traces which</context>
<context position="25913" citStr="Zhang and Clark, 2009" startWordPosition="4347" endWordPosition="4350">enses of n, de, the Chinese subordinating particle. Two categories which n, de receives in the grammar are (NP/NP)\(S[dcl]\NP) (introducing a relative clause) and (NP/NP)\S[dcl] (in the construction S de NP). Because subject pro-drop promotes any unsaturated S[dcl]\NP to S[dcl], whenever the supertagger returns both of the above categories for the lexical item n, de, the parser must consider two alternative analyses which yield different dependencies: (5) a. ti f* n, Mimi ti come out DE questioni the questions which arise 301 English Chinese PTB/PCTB-based 92.1% (McClosky et al., 2006) 86.8% (Zhang and Clark, 2009) CCGbank-based 86.0% (Fowler and Penn, 2010) 72.7% (this work) 85.8% (Clark and Curran, 2007) 67.1% (this work) Table 11: Summary of Chinese parsing approaches model LF Lsa % stag cov log C C GoLD 74.99 7.42 89.36 98.6 18.35 AUTo (76.73 20.56 89.66 99.5 13.58) 65.42 4.82 83.73 97.9 18.67 (66.95 14.62 83.90 99.2 13.86) I-5 70.67 8.62 84.99 93.8 - (72.74 18.59 85.61 96.5 -) Table 12: Dev set evaluation for C&amp;C over pro-drop sentences only (and over full set in parentheses) b. pro ffi来 n AM pro come out DE question the question of (him, her) coming out 38.1% of sentences in the development set co</context>
</contexts>
<marker>Zhang, Clark, 2009</marker>
<rawString>Yue Zhang and Stephen Clark. 2009. Transition-based parsing of the Chinese treebank using a global discriminative model. In Proceedings of the 11th International Conference on Parsing Technologies, pages 162–171. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>