<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001047">
<title confidence="0.998336">
A Simultaneous Recognition Framework for the Spoken Language
Understanding Module of Intelligent Personal Assistant Software on
Smart Phones
</title>
<author confidence="0.917304">
Changsu Lee and Youngjoong Ko
</author>
<affiliation confidence="0.890607">
Computer Engineering, Dong-A University
</affiliation>
<address confidence="0.9850655">
840 Hadan 2-dong, Saha-gu,
Busan 604-714 Korea
</address>
<email confidence="0.996659">
{blue772001,youngjoong.ko}@gmail.com
</email>
<author confidence="0.991138">
Jungyun Seo
</author>
<affiliation confidence="0.996318">
Computer Science, Sogang University
</affiliation>
<address confidence="0.9551715">
Sinsu-dong 1, Mapo-gu
Seoul, 121-742, Korea
</address>
<email confidence="0.992157">
seojy@ccs.sogang.ac.kr
</email>
<sectionHeader confidence="0.993813" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999973375">
The intelligent personal assistant soft-
ware such as the Apple’s Siri and Sam-
sung’s S-Voice has been issued these
days. This paper introduces a novel Spo-
ken Language Understanding (SLU)
module to predict user’s intention for de-
termining system actions of the intelli-
gent personal assistant software. The
SLU module usually consists of several
connected recognition tasks on a pipeline
framework, whereas the proposed SLU
module simultaneously recognizes four
recognition tasks on a recognition
framework using Conditional Random
Fields (CRF). The four tasks include
named entity, speech-act, target and op-
eration recognition. In the experiments,
the new simultaneous recognition method
achieves the higher performance of 4%
and faster speed of about 25% than other
method using a pipeline framework. By a
significance test, this improvement is
considered to be statistically significant
as a p-value of smaller than 0.05.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999951615384616">
Currently, one of the most issued and promising
software is the intelligent personal assistant
software such as Apple’s Siri (Wikipedia, 2011)
and Samsung’s S-Voice (Wikipedia, 2012). This
kind of software provides users a natural lan-
guage user interface to answer questions, make
recommendations and perform actions. One of
the core modules to develop this software is the
Spoken Language Understanding (SLU) module.
The SLU module predicts the user’s intention of
user utterance, and one of the various software
actions is selected to provide appropriate infor-
mation to a user (Wang et al., 2005).
The SLU model of the intelligent personal as-
sistant software has several different aspects
from the previous other SLU modules, such as
ones of ATIS (Automatic Terminal Information
Service) and DARPA (Defense Advanced Re-
search Project Agency) projects, which are based
on rule-based methods (Ward et al. 1994; Wang
et al. 2001) and statistical methods (Wang et al.
2006; Raymond et al. 2007). Because the SLU
module is operated for various applications
(Apps) of mobile devices such as weather, trans-
portation, etc., it has to be able to deal with more
heterogeneous domains than the ATIS and
DARPA projects and it does more detailed anal-
ysis for each domain in order to offer users accu-
rate information. In addition, since the SLU
module in the previous dialogue systems has a
complicated architecture that is composes of
many sub-modules, it is difficult for them to be
directly applied into the SLU module of intelli-
gent personal assistant software with those many
domains for mobile devices. That is, building up
a complicated architecture for each domain can
make a heavy system and this kind of system is
not proper to mobile devices.
In this paper, we propose a new SLU module
with a simultaneous recognition framework for
the intelligent personal assistant software. The
proposed SLU module consists of four compo-
nents: named entity (NE), speech-act, target and
operator recognition. Each component of the
proposed SLU module has different recognition
unit, e.g. the named entity recognition is based
on a morpheme/phrase unit, whereas the target,
operator and speech-act are on an utterance unit.
To integrate these recognition units into the same
unit, we develop a new tag addition approach
that represents a user utterance as a tag sequence
for an input to CRF (Lafferty et al. 2001).
</bodyText>
<page confidence="0.780601">
818
</page>
<bodyText confidence="0.925735523809524">
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 818–822,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
In the experiments, the proposed simultaneous
recognition module showed the better perfor-
mance of 4% than a pipeline module. And it has
an additional benefit that it is composed of a
simple architecture with only one recognition
module so it can be more efficient than other
methods with respect to processing time, etc. As
a result, the processing time of our system was
reduced about 25% when compared to the pipe-
line system.
The remainder of the paper is organized as the
follows. Section 2 describes related work. In the
section 3, we define four components of our SLU
module for the intelligent personal assistant
software. Section 4 introduces our simultaneous
recognition framework in detail. Section 5 ex-
plains our experimental settings and results. Fi-
nally, section 6 draws conclusions.
</bodyText>
<sectionHeader confidence="0.999476" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.952962636363636">
The approaches for developing the SLU mod-
ules are largely divided into the rule-based meth-
ods and the statistical methods. The rule-based
modules have typically been implemented via
hand-crafted semantic level grammar rules and
some robust parsers (Seneff. 1992; Ward et al.
1999). However, these semantic grammar ap-
proaches carry a high development cost and they
can also lead to fragile operations since users do
not typically know what grammatical construc-
tions are supported by the system. An alternative
approach is to use some statistical methods to
directly map from word strings to the intended
meaning structures. Statistical methods are at-
tractive because they can be easily adapted to
new conditions using only annotated training
data. Statistical methods for SLU have been stud-
ied in a Hidden Vector State (HVS) Model (He
et al., 2005) and a data-driven statistical models
(Miller et al. 1994; Pieraccini et al. 1992; Wang
et al. 2006). In addition, Jeong and Lee (2008)
proposed a unified probabilistic model (triangu-
lar-chain CRF) combining the named entity and
dialog-act of SLU. This method achieved the
high performance for SLU. But the triangular-
chain CRF has a complicated architecture with a
modified CRF. And this method was built only
to combine the named entity and dialog-act,
whereas we need to combine four components.
In practical, the triangular-chain CRF showed
low performance when combining four compo-
nents in the experiments. As a result, the pro-
posed SLU module achieved high performance
in spite of its simple architecture.
3 Components of the Proposed SLU
Module for the Intelligent Personal
Assistant Software
Since the SLU module of intelligent personal
assistant software needs to determine the actions
of Apps of smart phone according to user needs,
they require more elaborate user intent analysis.
Thus we define four components of the SLU
module. An analysis result of our SLU module is
shown in Figure 1 as follows:
</bodyText>
<figureCaption confidence="0.999758">
Figure 1: Example of analysis results
</figureCaption>
<bodyText confidence="0.999613529411765">
Named Entity (NE) recognition: NE recogni-
tion extracts keywords from user utterances, such
as person, time, location, etc.
Target recognition: target describes the ob-
ject of system action. In Figure 1, the target is
“Temperature_Information.” By this recognized
target, the software can offer users accurate in-
formation.
Operator recognition: operator is to detect
one of the various software actions (Lookup, Set,
Delete, etc.). In Figure 1, the operator is identi-
fied as “Lookup”.
Speech-act recognition: speech-act tries to
designate a surface level speech-act.
“Wh_Question” as speech-act in Figure 1 pro-
vides the user’s intention of surface level to dia-
logue systems.
</bodyText>
<sectionHeader confidence="0.9805815" genericHeader="method">
4 Simultaneous Recognition Frame-
work
</sectionHeader>
<bodyText confidence="0.999888916666667">
We assume that four components of our SLU
module are correlated with each other. In order
to improve the performance and speed of the
SLU module, we propose a new framework to
simultaneously recognize the four components.
But these components have different recognition
units; NE has a morpheme/phrase unit and target,
operator and speech-act have an utterance unit. A
new tag addition method is proposed to solve this
problem. Using this method, we can construct a
novel simultaneous recognition framework for
SLU.
</bodyText>
<page confidence="0.996824">
819
</page>
<figureCaption confidence="0.998871">
Figure 3: Architecture for the simultaneous recognition framework
</figureCaption>
<subsectionHeader confidence="0.991976">
4.1 New tag addition method
</subsectionHeader>
<bodyText confidence="0.9999149">
Target, operator and speech-act are based on
an utterance unit. In order to construct a simulta-
neous recognition framework, we attach pseudo
morphemes with target, operator and speech-act
tags in front of each user utterance. Using these
pseudo morphemes, target, operator and speech-
act can utilize the features of NE, and NE can
also do target, operator and speech-act infor-
mation as additional features. Figure 2 shows an
example of the new tag addition method.
</bodyText>
<figureCaption confidence="0.998738">
Figure 2: Example of the new tag addition method
</figureCaption>
<subsectionHeader confidence="0.865632">
4.2 Simultaneous recognition framework
</subsectionHeader>
<bodyText confidence="0.999985875">
On the simultaneous recognition framework
with the new tag addition method, an input utter-
ance is analyzed by a sequential labeling classifi-
er, CRF. It is possible to use all of component
labels as additional features in this classification
method. We think that this is a main reason why
the proposed method improves recognition per-
formances.
Our framework needs only NE dictionary and
BIO annotated training corpus; BIO tags were
used in (Ramshaw and Marcus. 1995). It is very
simple and fast because it can output all of four
different SLU results in one classification execu-
tion. The architecture of our framework is shown
in Figure 3. Our SLU module is widely divided
into a training step and a test step.
</bodyText>
<subsectionHeader confidence="0.997818">
4.3 Feature Sets
</subsectionHeader>
<bodyText confidence="0.997947">
The three feature sets are extracted for SLU:
basis features (Lee et al. 2010), NE dictionary
features and target/operator/speech-act features.
All the basic and NE dictionary features are ana-
lyzed based on the morpheme unit.
</bodyText>
<listItem confidence="0.541688">
• Basis features
</listItem>
<bodyText confidence="0.983407888888889">
Current lexicon/POS tag information
Based on the position of the current lexicon, lexicon
contextual information. window size : -2~2
Based on the position of the current POS tag, POS tag
contextual information. window size : -2~2
The words of Korean language can consist of one or
more morphemes;
- current morpheme position information in a word
- current morpheme POS tag/word length information
</bodyText>
<listItem confidence="0.52101975">
• NE dictionary features
Based on current morpheme, NE tag information
matched from NE dictionary
• Target/operator/speech-act features
</listItem>
<bodyText confidence="0.64000475">
Verb information in the utterance
Lexicon unigram information in the utterance
Lexicon &amp; POS tag bigram information in the utterance
Lexicon &amp; POS tag trigram information in the utterance
</bodyText>
<sectionHeader confidence="0.996155" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<subsectionHeader confidence="0.996404">
5.1 Experimental settings
</subsectionHeader>
<bodyText confidence="0.999234333333333">
The MADS data set (Multi-Applications Dia-
logues for Smart phones) was constructed and
used to develop the SLU modules for the intelli-
gent personal assistant software. The MADS data
set was annotated by 8 NEs, 28 targets, 5 opera-
tors and 6 speech-act tags. In addition, The
MADS data set consists of 1,925 user utterance
in 6 domains: weather, clock, alarm, schedule,
exchange and traffic. The Mallet toolkit was
chosen for our CRF model (McCallum. 2002).
All experiments were evaluated by accuracy in
the utterance level. When the proposed SLU
module generates all the correct labels of NE,
target, operator and speech-act of an input utter-
ance, the utterance is considered as correct. The
performance of the SLU module is averaged on
5-fold cross validation. In addition, we used the
paired t-test and Wilcoxon singed rank test to
</bodyText>
<page confidence="0.988962">
820
</page>
<bodyText confidence="0.999443333333333">
verify statistically significant between our
framework and compared baseline framework.
The pipeline framework (Moreira et al., 2011) is
used a baseline system in our experiments be-
cause it is the most common method for multi-
domains SLU module.
</bodyText>
<subsectionHeader confidence="0.998955">
5.2 Experimental results
</subsectionHeader>
<bodyText confidence="0.99439225">
Each component of the SLU module is first
evaluated by comparison of accuracies between
the proposed and baseline frameworks. Figure 4
illustrates the accuracies of each component.
</bodyText>
<figureCaption confidence="0.99848">
Figure 4: Comparison of the accuracies of each com-
</figureCaption>
<bodyText confidence="0.782499857142857">
ponent for SLU
A pipeline framework commonly has some
disadvantage that the errors of previous compo-
nent are propagated to the next components. It
can cause a cascade of performance degradation.
Figure 5 shows the accuracies of entire SLU
modules in an utterance level.
</bodyText>
<figureCaption confidence="0.9980535">
Figure 5: Comparison of accuracies of entire SLU
modules on the utterance level
</figureCaption>
<bodyText confidence="0.999578111111111">
The proposed framework achieved significant-
ly better performance than the baseline frame-
work.
To verify statistically significant on accuracy
difference between the proposed and baseline
frameworks, we performed significant test using
the t-test and Wilcoxon singed rank test (Demsar.
2006). Table 1 shows the results of significant
test.
</bodyText>
<table confidence="0.9893166">
p-value &lt; 0.05 (95%) Our framework
vs.
Pipeline framework
paired t-test 0.00001
Wilcox signed rank test 0.021
</table>
<tableCaption confidence="0.999941">
Table 1: Results of significant tests
</tableCaption>
<bodyText confidence="0.996144666666667">
In both of two significance tests, our framework
was statistically significantly better than the
pipeline framework (p&lt;0.05).
In the comparison of processing time, our
framework obtained faster processing speed than
pipeline framework with about 25% reduction.
</bodyText>
<table confidence="0.999760666666667">
Test user utterance (388 utterances)
Our framework 15 sec.
Pipeline framework 19 sec.
</table>
<tableCaption confidence="0.999778">
Table 2: Results of processing time comparison
</tableCaption>
<bodyText confidence="0.997355285714286">
In addition, we tried to compare our module and
the triangular-chain CRF (Jeong and Lee, 2008).
Table 3 shows the performances when NE and
speech-act recognition tasks are combined and
all four recognition tasks are combined. As a re-
sult, our module outperformed the triangular-
chain CRF in both of cases.
</bodyText>
<table confidence="0.995808">
NE+Speech-act All (four tasks)
Our framework 90.61 83.48
Triangular-chain CRF 87.07 16.4
</table>
<tableCaption confidence="0.9934015">
Table 3: comparison of our module and triangular-
chain CRF
</tableCaption>
<sectionHeader confidence="0.998789" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.9999661">
In this paper, we have presented a novel SLU
framework to predict user’s intention for deter-
mining system actions of the intelligent personal
assistant software. The proposed SLU module
with a simultaneous recognition framework
achieved higher performance and faster pro-
cessing speed than the existing pipeline system.
In addition, our module outperformed other
method, the triangular-chain CRF, especially
when four components were all analyzed.
</bodyText>
<sectionHeader confidence="0.978181" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.9607956">
This research was supported by Basic Science
Research Program through the National Research
Foundation of Korea (NRF) funded by the Min-
istry of Education, Science and Technology (No.
NRF-2013R1A1A2009937)
</bodyText>
<page confidence="0.997195">
821
</page>
<sectionHeader confidence="0.988724" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999175805555556">
Janez Demsar. 2006. Statistical comparisons of
classifiers over multiple data sets. Journal of Ma-
chine Learning Research, Vol. 7. pp.1–30.
Yulan He and Steve Young. 2005. Semantic Pro-
cessing using the Hidden Vector State Model.
Computer Speech and Language, Vol. 19, No. 1, pp.
85-106.
Minwoo Jeong and Gary-Geunbae Lee, 2008. Trian-
gular-chain conditional random fields. IEEE
Transactions on Audio, Speech, and Language
Processing, Vol. 16, pp. 1287-1302.
John Lafferty, Andrew McCallum and Fernando C.N.
Pereira. 2001. Conditional random fields: Probabil-
istic models for segmenting and labeling sequence
data, In Proceedings of the Eighteenth Internation-
al Conference on Machine Learning.” Morgan
Kaufmann Publishers Inc., SanFrancisco, CA, USA,
pp. 282-289.
Changki Lee and Myung-Gil Jang. 2010. Named Enti-
ty Recognition with Structural SVMs and Pegasos
algorithm. Korean Journal of Cognitive Science.
Vol. 21. No. 4, 655-667.
Andrew McCallum. 2002. Mallet: A machine learning
for language kit, http://mallet.cs.umass.edu.
Scott Miller, Revert Bobrow, Robert Ingria, and Rob-
ert Schwartz. 1994. Hidden understanding models
of natural language. In Proceedings of the ACL,
Association for Computational Linguistics, pp. 25–
32.
Catarina Moreira, Ana Cristina Mendes, Lu´ısa Co-
heur and Bruno Martins, 2011. Towards the rapid
development of a natural language understanding
module. In Proceedings of 10th international con-
ference on Intelligent virtual agents, pp. 309–315.
Roberto Pieraccini, Evelyne Tzoukermann, Zakhar
Gorelov, Jean-Luc Gauvain, Esther Levin, Chine-
Hui Lee and Jay G. Wilpon. 1992. A speech under-
standing system based on statistical representation
of semantics. In Proceedings of the ICASSP, San
Francisco, CA.
Launce A. Ramshaw and Mitchell P. Marcus. 1995.
Text Chunking using Transformation-Based Learn-
ing. In Proceedings of the Third Workshop on Very
Large Corpora, pp. 82-94.
Christian Raymond and Giuseppe Riccardi. 2007.
Generative and discriminative algorithms for spo-
ken language understanding. In Proceedings of the
Interspeech, Antwerp, Belgium.
Stephanie Seneff. 1992. TINA: A Natural Language
System for Spoken Language Applications. Com-
putational Linguistics.
Ye-Yi Wang. 2001. Robust Spoken Language Under-
standing in MiPad. In proceedings of Eurospeech,
Aalborg, Denmark.
Ye-Yi Wang and Alex Acero. 2006. Discriminative
models for spoken language understanding. In Pro-
ceedings of the ICSLP, Pittsburgh, PA.
Ye-Yi Wang, Li Deng and Alex Acero. 2005. Spoken
language understanding : an introduction to the sta-
tistical framework. IEEE Signal Processing Maga-
zine 22(5): 16-31.
Wayne Ward, Bryan Pellom, and Sameer Pradhan.
1999. The CU Communicator System, IEEE Work-
shop on ASRU Proc., Keystone, Colorado.
Wayne Ward and Sunil lssar. 1994. Recent Improve-
ments in the CMU Spoken language Understanding
System. in Human Language Technology Work-
shop, Plainsboro, New Jersey.
Wikipedia Contributors. 2011. Siri, Wikipedia, the
Free Encyclopedia.
Wikipedia Contributors. 2012. S-Voice, Wikipedia,
the Free Encyclopedia.
</reference>
<page confidence="0.998046">
822
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.200655">
<title confidence="0.976919666666667">A Simultaneous Recognition Framework for the Spoken Understanding Module of Intelligent Personal Assistant Software Smart Phones</title>
<author confidence="0.674943">Changsu Lee</author>
<author confidence="0.674943">Youngjoong</author>
<address confidence="0.805493">Computer Engineering, Dong-A 840 Hadan 2-dong, Busan 604-714 Korea</address>
<email confidence="0.997315">blue772001@gmail.com</email>
<email confidence="0.997315">youngjoong.ko@gmail.com</email>
<author confidence="0.99439">Jungyun Seo</author>
<affiliation confidence="0.999965">Computer Science, Sogang University</affiliation>
<address confidence="0.943277">Sinsu-dong 1, Mapo-gu Seoul, 121-742, Korea</address>
<email confidence="0.986538">seojy@ccs.sogang.ac.kr</email>
<abstract confidence="0.98983204">The intelligent personal assistant softsuch as the Siri Sam- S-Voice been issued these days. This paper introduces a novel Spoken Language Understanding (SLU) to predict intention for determining system actions of the intelligent personal assistant software. The SLU module usually consists of several connected recognition tasks on a pipeline framework, whereas the proposed SLU module simultaneously recognizes four recognition tasks on a recognition framework using Conditional Random Fields (CRF). The four tasks include named entity, speech-act, target and operation recognition. In the experiments, the new simultaneous recognition method achieves the higher performance of 4% and faster speed of about 25% than other method using a pipeline framework. By a significance test, this improvement is considered to be statistically significant a smaller than 0.05.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Janez Demsar</author>
</authors>
<title>Statistical comparisons of classifiers over multiple data sets.</title>
<date>2006</date>
<journal>Journal of Machine Learning Research,</journal>
<volume>7</volume>
<pages>1--30</pages>
<marker>Demsar, 2006</marker>
<rawString>Janez Demsar. 2006. Statistical comparisons of classifiers over multiple data sets. Journal of Machine Learning Research, Vol. 7. pp.1–30.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yulan He</author>
<author>Steve Young</author>
</authors>
<title>Semantic Processing using the Hidden Vector State Model.</title>
<date>2005</date>
<journal>Computer Speech and Language,</journal>
<volume>19</volume>
<pages>85--106</pages>
<marker>He, Young, 2005</marker>
<rawString>Yulan He and Steve Young. 2005. Semantic Processing using the Hidden Vector State Model. Computer Speech and Language, Vol. 19, No. 1, pp. 85-106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minwoo Jeong</author>
<author>Gary-Geunbae Lee</author>
</authors>
<title>Triangular-chain conditional random fields.</title>
<date>2008</date>
<journal>IEEE Transactions on Audio, Speech, and Language Processing,</journal>
<volume>16</volume>
<pages>1287--1302</pages>
<contexts>
<context position="5825" citStr="Jeong and Lee (2008)" startWordPosition="900" endWordPosition="903">y can also lead to fragile operations since users do not typically know what grammatical constructions are supported by the system. An alternative approach is to use some statistical methods to directly map from word strings to the intended meaning structures. Statistical methods are attractive because they can be easily adapted to new conditions using only annotated training data. Statistical methods for SLU have been studied in a Hidden Vector State (HVS) Model (He et al., 2005) and a data-driven statistical models (Miller et al. 1994; Pieraccini et al. 1992; Wang et al. 2006). In addition, Jeong and Lee (2008) proposed a unified probabilistic model (triangular-chain CRF) combining the named entity and dialog-act of SLU. This method achieved the high performance for SLU. But the triangularchain CRF has a complicated architecture with a modified CRF. And this method was built only to combine the named entity and dialog-act, whereas we need to combine four components. In practical, the triangular-chain CRF showed low performance when combining four components in the experiments. As a result, the proposed SLU module achieved high performance in spite of its simple architecture. 3 Components of the Prop</context>
<context position="13111" citStr="Jeong and Lee, 2008" startWordPosition="2045" endWordPosition="2048">95%) Our framework vs. Pipeline framework paired t-test 0.00001 Wilcox signed rank test 0.021 Table 1: Results of significant tests In both of two significance tests, our framework was statistically significantly better than the pipeline framework (p&lt;0.05). In the comparison of processing time, our framework obtained faster processing speed than pipeline framework with about 25% reduction. Test user utterance (388 utterances) Our framework 15 sec. Pipeline framework 19 sec. Table 2: Results of processing time comparison In addition, we tried to compare our module and the triangular-chain CRF (Jeong and Lee, 2008). Table 3 shows the performances when NE and speech-act recognition tasks are combined and all four recognition tasks are combined. As a result, our module outperformed the triangularchain CRF in both of cases. NE+Speech-act All (four tasks) Our framework 90.61 83.48 Triangular-chain CRF 87.07 16.4 Table 3: comparison of our module and triangularchain CRF 6 Conclusions In this paper, we have presented a novel SLU framework to predict user’s intention for determining system actions of the intelligent personal assistant software. The proposed SLU module with a simultaneous recognition framework </context>
</contexts>
<marker>Jeong, Lee, 2008</marker>
<rawString>Minwoo Jeong and Gary-Geunbae Lee, 2008. Triangular-chain conditional random fields. IEEE Transactions on Audio, Speech, and Language Processing, Vol. 16, pp. 1287-1302.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando C N Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data,</title>
<date>2001</date>
<booktitle>In Proceedings of the Eighteenth International Conference on Machine Learning.”</booktitle>
<pages>282--289</pages>
<publisher>Morgan Kaufmann Publishers Inc.,</publisher>
<location>SanFrancisco, CA, USA,</location>
<contexts>
<context position="3750" citStr="Lafferty et al. 2001" startWordPosition="572" endWordPosition="575">LU module with a simultaneous recognition framework for the intelligent personal assistant software. The proposed SLU module consists of four components: named entity (NE), speech-act, target and operator recognition. Each component of the proposed SLU module has different recognition unit, e.g. the named entity recognition is based on a morpheme/phrase unit, whereas the target, operator and speech-act are on an utterance unit. To integrate these recognition units into the same unit, we develop a new tag addition approach that represents a user utterance as a tag sequence for an input to CRF (Lafferty et al. 2001). 818 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 818–822, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics In the experiments, the proposed simultaneous recognition module showed the better performance of 4% than a pipeline module. And it has an additional benefit that it is composed of a simple architecture with only one recognition module so it can be more efficient than other methods with respect to processing time, et</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John Lafferty, Andrew McCallum and Fernando C.N. Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data, In Proceedings of the Eighteenth International Conference on Machine Learning.” Morgan Kaufmann Publishers Inc., SanFrancisco, CA, USA, pp. 282-289.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Changki Lee</author>
<author>Myung-Gil Jang</author>
</authors>
<title>Named Entity Recognition with Structural SVMs and Pegasos algorithm.</title>
<date>2010</date>
<journal>Korean Journal of Cognitive Science.</journal>
<volume>21</volume>
<pages>655--667</pages>
<marker>Lee, Jang, 2010</marker>
<rawString>Changki Lee and Myung-Gil Jang. 2010. Named Entity Recognition with Structural SVMs and Pegasos algorithm. Korean Journal of Cognitive Science. Vol. 21. No. 4, 655-667.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew McCallum</author>
</authors>
<title>Mallet: A machine learning for language kit,</title>
<date>2002</date>
<location>http://mallet.cs.umass.edu.</location>
<marker>McCallum, 2002</marker>
<rawString>Andrew McCallum. 2002. Mallet: A machine learning for language kit, http://mallet.cs.umass.edu.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott Miller</author>
<author>Revert Bobrow</author>
<author>Robert Ingria</author>
<author>Robert Schwartz</author>
</authors>
<title>Hidden understanding models of natural language.</title>
<date>1994</date>
<booktitle>In Proceedings of the ACL, Association for Computational Linguistics,</booktitle>
<pages>25--32</pages>
<contexts>
<context position="5747" citStr="Miller et al. 1994" startWordPosition="886" endWordPosition="889">ver, these semantic grammar approaches carry a high development cost and they can also lead to fragile operations since users do not typically know what grammatical constructions are supported by the system. An alternative approach is to use some statistical methods to directly map from word strings to the intended meaning structures. Statistical methods are attractive because they can be easily adapted to new conditions using only annotated training data. Statistical methods for SLU have been studied in a Hidden Vector State (HVS) Model (He et al., 2005) and a data-driven statistical models (Miller et al. 1994; Pieraccini et al. 1992; Wang et al. 2006). In addition, Jeong and Lee (2008) proposed a unified probabilistic model (triangular-chain CRF) combining the named entity and dialog-act of SLU. This method achieved the high performance for SLU. But the triangularchain CRF has a complicated architecture with a modified CRF. And this method was built only to combine the named entity and dialog-act, whereas we need to combine four components. In practical, the triangular-chain CRF showed low performance when combining four components in the experiments. As a result, the proposed SLU module achieved </context>
</contexts>
<marker>Miller, Bobrow, Ingria, Schwartz, 1994</marker>
<rawString>Scott Miller, Revert Bobrow, Robert Ingria, and Robert Schwartz. 1994. Hidden understanding models of natural language. In Proceedings of the ACL, Association for Computational Linguistics, pp. 25– 32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Catarina Moreira</author>
</authors>
<title>Ana Cristina Mendes, Lu´ısa Coheur</title>
<date>2011</date>
<booktitle>In Proceedings of 10th international conference on Intelligent virtual agents,</booktitle>
<pages>309--315</pages>
<marker>Moreira, 2011</marker>
<rawString>Catarina Moreira, Ana Cristina Mendes, Lu´ısa Coheur and Bruno Martins, 2011. Towards the rapid development of a natural language understanding module. In Proceedings of 10th international conference on Intelligent virtual agents, pp. 309–315.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Pieraccini</author>
<author>Evelyne Tzoukermann</author>
<author>Zakhar Gorelov</author>
<author>Jean-Luc Gauvain</author>
<author>Esther Levin</author>
<author>ChineHui Lee</author>
<author>Jay G Wilpon</author>
</authors>
<title>A speech understanding system based on statistical representation of semantics.</title>
<date>1992</date>
<booktitle>In Proceedings of the ICASSP,</booktitle>
<location>San Francisco, CA.</location>
<contexts>
<context position="5771" citStr="Pieraccini et al. 1992" startWordPosition="890" endWordPosition="893">grammar approaches carry a high development cost and they can also lead to fragile operations since users do not typically know what grammatical constructions are supported by the system. An alternative approach is to use some statistical methods to directly map from word strings to the intended meaning structures. Statistical methods are attractive because they can be easily adapted to new conditions using only annotated training data. Statistical methods for SLU have been studied in a Hidden Vector State (HVS) Model (He et al., 2005) and a data-driven statistical models (Miller et al. 1994; Pieraccini et al. 1992; Wang et al. 2006). In addition, Jeong and Lee (2008) proposed a unified probabilistic model (triangular-chain CRF) combining the named entity and dialog-act of SLU. This method achieved the high performance for SLU. But the triangularchain CRF has a complicated architecture with a modified CRF. And this method was built only to combine the named entity and dialog-act, whereas we need to combine four components. In practical, the triangular-chain CRF showed low performance when combining four components in the experiments. As a result, the proposed SLU module achieved high performance in spit</context>
</contexts>
<marker>Pieraccini, Tzoukermann, Gorelov, Gauvain, Levin, Lee, Wilpon, 1992</marker>
<rawString>Roberto Pieraccini, Evelyne Tzoukermann, Zakhar Gorelov, Jean-Luc Gauvain, Esther Levin, ChineHui Lee and Jay G. Wilpon. 1992. A speech understanding system based on statistical representation of semantics. In Proceedings of the ICASSP, San Francisco, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Launce A Ramshaw</author>
<author>Mitchell P Marcus</author>
</authors>
<title>Text Chunking using Transformation-Based Learning.</title>
<date>1995</date>
<booktitle>In Proceedings of the Third Workshop on Very Large Corpora,</booktitle>
<pages>82--94</pages>
<marker>Ramshaw, Marcus, 1995</marker>
<rawString>Launce A. Ramshaw and Mitchell P. Marcus. 1995. Text Chunking using Transformation-Based Learning. In Proceedings of the Third Workshop on Very Large Corpora, pp. 82-94.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Raymond</author>
<author>Giuseppe Riccardi</author>
</authors>
<title>Generative and discriminative algorithms for spoken language understanding.</title>
<date>2007</date>
<booktitle>In Proceedings of the Interspeech,</booktitle>
<location>Antwerp, Belgium.</location>
<marker>Raymond, Riccardi, 2007</marker>
<rawString>Christian Raymond and Giuseppe Riccardi. 2007. Generative and discriminative algorithms for spoken language understanding. In Proceedings of the Interspeech, Antwerp, Belgium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephanie Seneff</author>
</authors>
<title>TINA: A Natural Language System for Spoken Language Applications. Computational Linguistics.</title>
<date>1992</date>
<marker>Seneff, 1992</marker>
<rawString>Stephanie Seneff. 1992. TINA: A Natural Language System for Spoken Language Applications. Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ye-Yi Wang</author>
</authors>
<title>Robust Spoken Language Understanding in MiPad.</title>
<date>2001</date>
<booktitle>In proceedings of Eurospeech,</booktitle>
<location>Aalborg, Denmark.</location>
<marker>Wang, 2001</marker>
<rawString>Ye-Yi Wang. 2001. Robust Spoken Language Understanding in MiPad. In proceedings of Eurospeech, Aalborg, Denmark.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ye-Yi Wang</author>
<author>Alex Acero</author>
</authors>
<title>Discriminative models for spoken language understanding.</title>
<date>2006</date>
<booktitle>In Proceedings of the ICSLP,</booktitle>
<location>Pittsburgh, PA.</location>
<marker>Wang, Acero, 2006</marker>
<rawString>Ye-Yi Wang and Alex Acero. 2006. Discriminative models for spoken language understanding. In Proceedings of the ICSLP, Pittsburgh, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ye-Yi Wang</author>
<author>Li Deng</author>
<author>Alex Acero</author>
</authors>
<title>Spoken language understanding : an introduction to the statistical framework.</title>
<date>2005</date>
<journal>IEEE Signal Processing Magazine</journal>
<volume>22</volume>
<issue>5</issue>
<pages>16--31</pages>
<contexts>
<context position="1953" citStr="Wang et al., 2005" startWordPosition="278" endWordPosition="281">.05. 1 Introduction Currently, one of the most issued and promising software is the intelligent personal assistant software such as Apple’s Siri (Wikipedia, 2011) and Samsung’s S-Voice (Wikipedia, 2012). This kind of software provides users a natural language user interface to answer questions, make recommendations and perform actions. One of the core modules to develop this software is the Spoken Language Understanding (SLU) module. The SLU module predicts the user’s intention of user utterance, and one of the various software actions is selected to provide appropriate information to a user (Wang et al., 2005). The SLU model of the intelligent personal assistant software has several different aspects from the previous other SLU modules, such as ones of ATIS (Automatic Terminal Information Service) and DARPA (Defense Advanced Research Project Agency) projects, which are based on rule-based methods (Ward et al. 1994; Wang et al. 2001) and statistical methods (Wang et al. 2006; Raymond et al. 2007). Because the SLU module is operated for various applications (Apps) of mobile devices such as weather, transportation, etc., it has to be able to deal with more heterogeneous domains than the ATIS and DARPA</context>
</contexts>
<marker>Wang, Deng, Acero, 2005</marker>
<rawString>Ye-Yi Wang, Li Deng and Alex Acero. 2005. Spoken language understanding : an introduction to the statistical framework. IEEE Signal Processing Magazine 22(5): 16-31.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wayne Ward</author>
<author>Bryan Pellom</author>
<author>Sameer Pradhan</author>
</authors>
<date>1999</date>
<booktitle>The CU Communicator System, IEEE Workshop on ASRU Proc.,</booktitle>
<location>Keystone, Colorado.</location>
<contexts>
<context position="5123" citStr="Ward et al. 1999" startWordPosition="785" endWordPosition="788"> follows. Section 2 describes related work. In the section 3, we define four components of our SLU module for the intelligent personal assistant software. Section 4 introduces our simultaneous recognition framework in detail. Section 5 explains our experimental settings and results. Finally, section 6 draws conclusions. 2 Related Work The approaches for developing the SLU modules are largely divided into the rule-based methods and the statistical methods. The rule-based modules have typically been implemented via hand-crafted semantic level grammar rules and some robust parsers (Seneff. 1992; Ward et al. 1999). However, these semantic grammar approaches carry a high development cost and they can also lead to fragile operations since users do not typically know what grammatical constructions are supported by the system. An alternative approach is to use some statistical methods to directly map from word strings to the intended meaning structures. Statistical methods are attractive because they can be easily adapted to new conditions using only annotated training data. Statistical methods for SLU have been studied in a Hidden Vector State (HVS) Model (He et al., 2005) and a data-driven statistical mo</context>
</contexts>
<marker>Ward, Pellom, Pradhan, 1999</marker>
<rawString>Wayne Ward, Bryan Pellom, and Sameer Pradhan. 1999. The CU Communicator System, IEEE Workshop on ASRU Proc., Keystone, Colorado.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wayne Ward</author>
<author>Sunil lssar</author>
</authors>
<title>Recent Improvements in the CMU Spoken language Understanding System.</title>
<date>1994</date>
<booktitle>in Human Language Technology Workshop,</booktitle>
<location>Plainsboro, New Jersey.</location>
<marker>Ward, lssar, 1994</marker>
<rawString>Wayne Ward and Sunil lssar. 1994. Recent Improvements in the CMU Spoken language Understanding System. in Human Language Technology Workshop, Plainsboro, New Jersey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wikipedia Contributors</author>
</authors>
<date>2011</date>
<journal>Siri, Wikipedia, the Free Encyclopedia.</journal>
<marker>Contributors, 2011</marker>
<rawString>Wikipedia Contributors. 2011. Siri, Wikipedia, the Free Encyclopedia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wikipedia Contributors</author>
</authors>
<title>S-Voice, Wikipedia, the Free Encyclopedia.</title>
<date>2012</date>
<marker>Contributors, 2012</marker>
<rawString>Wikipedia Contributors. 2012. S-Voice, Wikipedia, the Free Encyclopedia.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>