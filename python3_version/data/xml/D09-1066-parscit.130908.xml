<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.020673">
<title confidence="0.999769">
A Comparison of Windowless and Window-Based Computational
Association Measures as Predictors of Syntagmatic Human Associations
</title>
<author confidence="0.999312">
Justin Washtell
</author>
<affiliation confidence="0.997943">
School of Computing
University of Leeds
</affiliation>
<email confidence="0.997214">
washtell@comp.leeds.ac.uk
</email>
<sectionHeader confidence="0.993862" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999899083333333">
Distance-based (windowless) word asso-
cation measures have only very recently
appeared in the NLP literature and their
performance compared to existing win-
dowed or frequency-based measures is
largely unknown. We conduct a large-
scale empirical comparison of a variety of
distance-based and frequency-based mea-
sures for the reproduction of syntagmatic
human assocation norms. Overall, our
results show an improvement in the pre-
dictive power of windowless over win-
dowed measures. This provides support
to some of the previously published the-
oretical advantages and makes window-
less approaches a promising avenue to
explore further. This study also serves
as a first comparison of windowed meth-
ods across numerous human association
datasets. During this comparison we
also introduce some novel variations of
window-based measures which perform as
well as or better in the human association
norm task than established measures.
</bodyText>
<sectionHeader confidence="0.99913" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999121357142857">
Automatic discovery of semantically associated
words has attracted a large amount of attention in
the last decades and a host of computational asso-
ciation measures have been proposed to deal with
this task (see Section 2). These measures tradi-
tionally rely on the co-ocurrence frequency of two
words in a corpus to estimate a relatedness score.
There has been a recent emergence of distance-
based language modelling techiques in NLP (Sav-
icki and Hlavacova, 2002; Terra and Clarke, 2004)
in which the number of tokens separating words
is the essential quantity. While some of this work
has considered distance-based alternatives to con-
ventional association measures (Hardcastle, 2005;
</bodyText>
<author confidence="0.765721">
Katja Markert
</author>
<affiliation confidence="0.979983">
School of Computing
University of Leeds
</affiliation>
<email confidence="0.985453">
markert@comp.leeds.ac.uk
</email>
<bodyText confidence="0.9996865">
Washtell, 2009), there has been no principled em-
pirical evaluation of these measures as predictors
of human association. We remedy this by conduct-
ing a thorough comparison of a wide variety of
frequency-based and distance-based measures as
predictors of human association scores as elicited
in several different free word association tasks.
In this work we focus on first-order associ-
ation measures as predictors of syntagmatic as-
sociations. This is in contrast to second and
higher-order measures which are better predictors
of paradigmatic associations, or word similarity.
The distinction between syntagmatic and paradig-
matic relationship types is neither exact nor mu-
tually exclusive, and many paradigmatic relation-
ships can be observed syntagmatically in the text.
Roughly in keeping with (Rapp, 2002), we hereby
regard paradigmatic assocations as those based
largely on word similarity (i.e. including those
typically classed as synonyms, antonyms, hyper-
nyms, hyponyms etc), whereas syntagmatic as-
sociations are all those words which strongly in-
voke one another yet which cannot readily be
said to be similar. Typically these will have an
identifiable semantic or grammatical relationship
(meronym/holonym: stem – flower, verb/object:
eat – food etc), or may have harder-to-classify top-
ical or idiomatic relationships (family – Christmas,
rock – roll).
We will show in Section 3.2 that syntagmatic
relations by themselves constitute a substantial
25-40% of the strongest human responses to cue
words. Although the automatic detection of these
assocations in text has received less attention
than that of paradigmatic associations, they are
nonetheless important in applications such as the
resolution of bridging anaphora (Vieira and Poe-
sio, 2000).1 Furthermore, first-order associations
</bodyText>
<footnote confidence="0.949936">
1where for example resolving my house – the windows to
the windows of my house can be aided by the knowledge that
windows are often (syntagmatically) associated with houses.
</footnote>
<page confidence="0.858754">
628
</page>
<note confidence="0.996627">
Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 628–637,
Singapore, 6-7 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.999970809523809">
are often the basis of higher-order vector word-
space models used for predicting paradigmatic
relationships: i.e. through the observation of
words which share similar sets of syntagmatic as-
sociations. Therefore improvements made at the
level we are concerned with may reasonably be
expected to carry through to applications which
hinge on the identification of paradigmatic rela-
tionships.
After a discussion of previous work in Sec-
tion 2, we formulate the exact association mea-
sures and parameter settings which we compare
in Section 3, where we also introduce the corpora
and human association sets used. Then, by using
evaluations similar to those described in (Baroni
et al., 2008) and by Rapp (2002), we show that
the best distance-based measures correlate better
overall with human association scores than do the
best window based configurations (see Section 4),
and that they also serve as better predictors of the
strongest human associations (see Section 5).
</bodyText>
<sectionHeader confidence="0.999907" genericHeader="introduction">
2 Related Work
</sectionHeader>
<subsectionHeader confidence="0.99307">
Measures based on co-ocurrence frequency.
</subsectionHeader>
<bodyText confidence="0.999946027777777">
The standard way of estimating the syntagmatic
association of word pairs in a corpus is to ex-
amine the frequency of their co-occurence, and
then usually to compare this to some expected fre-
quency. There are a host of measures which ex-
ist for this purpose. After raw co-occurrence fre-
quency, the simplest and most prevalent in the
literature is Pointwise Mutual Information, fa-
mously used by Church (1989) (as the associa-
tion ratio). This is defined as the log of the ra-
tio of the observed co-occurrence frequency to the
frequency expected under independence. More
sophisticated and statistically-informed measures
include t-Score, z-Score, Chi-Squared and Log-
Likelihood (see Evert (2005) for a thorough re-
view).
All of these measures have in common that they
require co-occurrence frequency to be specified,
and therefore require some definition of a region
within which to count co-occurrences. This re-
gion might be the entirety of a document at one
extreme, or a bigram at the other. A versatile and
hugely popular generalised approach is therefore
to consider a ”‘window”’ of w words, where w can
be varied to suit the application. Unsurprisingly,
it has been found that this is a parameter which
can have a significant impact upon performance
(Yarowsky and Florian, 2002; Lamjiri et al., 2004;
Wang, 2005). While choosing an optimum win-
dow size for an application is often subject to
trial and error, there are some generally recog-
nized trade-offs between small versus large win-
dows, such as the impact of data-sparseness, and
the nature of the associations retrieved (Church
and Hanks, 1989; Church and Hanks, 1991; Rapp,
2002)
</bodyText>
<subsectionHeader confidence="0.956217">
Measures based on distance between words in
</subsectionHeader>
<bodyText confidence="0.999637736842105">
the text. The idea of using distance as an al-
ternative to frequency for modelling language has
been touched upon in recent literature (Savicki and
Hlavacova, 2002; Terra and Clarke, 2004; Hard-
castle, 2005). Washtell (2009) showed that it is
possible to build distance-based analogues of ex-
isting syntagmatic association measures, by using
the notions of mean and expected distance rather
than of frequency. These measures have certain
theoretical qualities - notably scale-independence
and relative resilience to data-sparseness - which
might be expected to provide gains in tasks such
as the reproduction of human association norms
from corpus data. The specific measure introduced
by Washtell, called Co-Dispersion, is based upon
an established biogeographic dispersion measure
(Clark and Evans, 1954). We provide a thor-
ough empirical investigation of Co-Dispersion and
some of its derivatives herein.
</bodyText>
<subsectionHeader confidence="0.886232">
Measures based on syntactic relations. Sev-
</subsectionHeader>
<bodyText confidence="0.999950416666667">
eral researchers (Lin, 1998; Curran, 2003; Pado
and Lapata, 2007) have used word space models
based on grammatical relationships for detecting
and quantifying (mostly paradigmatic) word asso-
ciations. In this paper, we will not use syntactic
relation measures for two main reasons. Firstly
these depend on the availability of parsers, which
is not a given for many languages. Secondly, this
may not be the most pertinent approach for pre-
dicting human free associations, in which certain
observed relationsips can be hard to express in
terms of syntactic relationships.
</bodyText>
<sectionHeader confidence="0.998615" genericHeader="method">
3 Methodology
</sectionHeader>
<bodyText confidence="0.9987015">
Similar to (Rapp, 2002; Baroni et al., 2008, among
others), we use comparison to human assocation
datasets as a test bed for the scores produced by
computational association measures. An alterna-
tive might be to validate scores against those de-
rived from a structured resource such as WordNet.
</bodyText>
<page confidence="0.999733">
629
</page>
<tableCaption confidence="0.999187">
Table 1: Human association datasets
</tableCaption>
<table confidence="0.9279354">
Name Origin Cues Respondents
Kent Kent &amp; Rosanoff (1910) 100 — 1000
Minnesota Russell &amp; Jenkins (1954) 100 — 1000
EAT Kiss et al (1973) 8400 100
Florida Nelson et al (1980) 5019 — 140
</table>
<bodyText confidence="0.99908665">
However, relatedness measures for WordNet are
many and varied and are themselves the subject of
evaluation (Pedersen et al., 2004). Although hu-
man association datasets have their own peculiari-
ties, they do at least provide some kind of definite
Gold Standard. Yet another alternative might be to
incorporate our computational association scores
into an application (such as anaphora resolution),
and measure the performance of that, but noise
from other submodules would complicate evalu-
ation. We leave such extensions to possible future
work.
We use evaluations similar to those used before
(Rapp, 2002; Pado and Lapata, 2007; Baroni et
al., 2008, among others). However, whereas most
existing studies use only one dataset, or hand-
selected parts thereof, we aim to evaluate mea-
sures across four different human datasets. In this
way we hope to get as unbiased a picture as possi-
ble.
</bodyText>
<subsectionHeader confidence="0.999848">
3.1 Association data
</subsectionHeader>
<bodyText confidence="0.999791291666667">
The datasets used are listed in Table 1. While
the exact experimental conditions may differ, the
datasets used were all elicited using the same ba-
sic methodology: by presenting individual words
(cues) to a number of healthy human subjects and
asking in each case for the word that is most imme-
diately or strongly evoked. An association score
can then be derived for each cue/response pair in a
dataset by dividing the number of participants pro-
viding a given response by the number who were
presented with the cue word. In Table 1, respon-
dents refers to the number of people from whom
a response was solicited for each cue word in a
study (this is not to be confused with the number
of unique responses).
Of these four datasets, one (Kent &amp; Rosanoff)
appears not to have been previously used in any
peer-reviewed study of corpus-derived lexical as-
sociation. It is worth noting that some of these
datasets are quite dated, which might affect corre-
lations with corpus-derived scores, as culture and
contemporary language have a fundamental im-
pact upon the associations humans form (White
and Abrams, 2004).
</bodyText>
<subsectionHeader confidence="0.999951">
3.2 Frequency of Syntagmatic Associations
</subsectionHeader>
<bodyText confidence="0.999984307692308">
To verify that strong human associations do in-
clude a large number of syntagmatic associations,
we manually annotated all pairs consisting of
a cue and its strongest human response in the
Minnesota and Kent datasets as expressing ei-
ther a syntagmatic or a paradigmatic relationship.
The overall set to be annotated consisted of 200
pairs.
Annotators were given short (half-page) guide-
lines on syntagmatic and paradigmatic assoca-
tions, stating that very similar items (including
hyponyms/hypernyms) as well as antonyms were
to be judged as paradigmatic whereas words that
do not fulfil this criterion are to be judged as
syntagmatic. The two annotators were the au-
thors of this paper (one native and one near-native
speaker). After independent annotation, agree-
ment was measured at a percentage agreement of
91/93% and a kappa of 0.80/0.82 for Minnesota
and Kent, respectively. Therefore, the distinction
can be made with high reliability.
Overall, 27/39% of the human responses
were syntagmatic in the Kent/Minnesota datasets,
showing that syntagmatic relations make up a
large proportion of even the strongest human as-
sociations.
</bodyText>
<subsectionHeader confidence="0.99705">
3.3 Corpora
</subsectionHeader>
<bodyText confidence="0.999992333333333">
We use two randomized subsets of the British Na-
tional Corpus (BNC), a representative 100 million
word corpus of British English (Burnard, 1995):
one 10 million word sample, and a 1 million word
sample. A vocabulary of approximately 33,000
word types was used. The selected words included
approximately 24,000 word types comprising all
cue and target words from the multiple sets of hu-
man association norms to be used in this study. To
these were added a top-cut of the most frequent
words in the BNC, until the total of 33,000 word
types was reached. The resultant set included ap-
</bodyText>
<page confidence="0.986129">
630
</page>
<bodyText confidence="0.999992793103448">
proximately the 24,000 most common word types
in the BNC, with the remaining 9000 words types
therefore comprising relatively uncommon words
taken from the human associative responses.
The words included in the vocabulary ac-
counted for over 94.5% of tokens in the corpus.
Although statistics for the remaining word types
in the BNC were not gathered, their correspond-
ing tokens were left in the corpus so that these
could be properly accounted for when calculating
distances and window spans.
In order to maximize matching between word
types in the corpus and association norms, all
words in both were normalized by converting to
lower-case and removing hyphens and periods.
Words consisting entirely of numerals, or numer-
als and punctuation, and all ”phrasal” associa-
tive responses (those containing spaces) were dis-
carded. The 33,000 word count was satisfied after
making these normalizations.
In order to maximize the variety of the language
in the samples, the subsets were built from ap-
proximately the first 2000 words only of each ran-
domly selected document from the BNC (a similar
strategy to that used in constructing the 1 million
word Brown Corpus). Both a 10 million word and
a 1 million word sample were constructed in this
fashion, allowing us to also examine the effects of
varying corpus size and content.
</bodyText>
<subsectionHeader confidence="0.9667575">
3.4 Association measures used
3.4.1 Frequency-based measures
</subsectionHeader>
<bodyText confidence="0.999101285714286">
In the following, x is the cue word and y a (possi-
ble) response word. Therefore p(x) is the proba-
bility of observing x, and p(¯x) refers to the prob-
ability of not observing x.
Pointwise Mutual Information (hereonin PMI)
was introduced in Section 2. For ranking word
pairs, we can neglect the usual logarithm.
</bodyText>
<equation confidence="0.9890925">
PMI = p(x, y)
p(x)p(y)
</equation>
<bodyText confidence="0.999906416666667">
PMI is infamous for its tendency to attribute very
high association scores to pairs involving low fre-
quency words, as the denominator is small in such
cases, even though the evidence for association in
such cases is also small. This can result in some
unlikely associations. There exist a number of al-
ternative measures which factor in the amount of
evidence to give an estimate of the significance of
association. One popular and statistically appeal-
ing such measure is Log-Likelihood (LL) (Dun-
ning, 1993). LL works on a similar principle to
PMI but considers the ratio of the observed to ex-
pected co-occurrence frequencies for all contin-
gencies (i.e. including those where the words do
not co-occur). LL, as it most frequently appears in
the literature, is not actually a measure of positive
association: it also responds to significant negative
association. Therefore LL is arguably not suited to
the task in hand. Krenn &amp; Evert (2001) experiment
with one-tailed variants of LL and Chi-Squared
measures, although they do not define these vari-
ants. Here, we construct a one-tailed variant of LL
by simply reversing the signs of the terms which
respond to negative association.
</bodyText>
<equation confidence="0.99932875">
LL1tail = p(x, y) log p(x, y)
p(x)p(y)
− p(¯x, y) log p(¯x, y) + p(¯x,¯y) log p(¯x, ¯y)
p(¯x)p(y) p(¯x)p(¯y)
</equation>
<bodyText confidence="0.999829555555555">
LL does not have a clear analogue amongst
the distance-based measures (introduced in Sec-
tion 3.4.2), whereas PMI for instance does. We
therefore construct variants of PMI and other mea-
sures which take the amount of evidence into ac-
count in a way which can be directly reproduced
in the distance domain. For this we borrow from
Sackett (2001) who asserts that, all other things
being equal, statistical significance is proportional
to the square root of the sample size. There are a
number of ways one might quantify sample size.
We take a consistent approach across the various
distance-based and frequency-based measures: we
assume sample size to be equivalent to the lesser of
the frequencies of the two words as this represents
the total number of words available for pairing,
with fewer observed pairs therefore being consid-
ered to constitute negative evidence.
</bodyText>
<equation confidence="0.994894333333333">
A/ min(p(x), p(y)) p(x, y)
PMIsig =
p(x)p(y)
</equation>
<bodyText confidence="0.999486">
All of the above measures are symmetric. Human
associative responses however are not (Michel-
bacher et al., 2007): a person’s tendency to give
the response because to the cue why does not nec-
essarily reflect their tendency to give the response
why to the cue because.2 A simple asymmetric as-
sociation measure is conditional probability (CP)
</bodyText>
<footnote confidence="0.566524">
2This notion of assymmetry is not to be confused with
</footnote>
<equation confidence="0.994151">
− p(x, ¯y) log p(x, ¯y)
p(x)p(¯y)
</equation>
<page confidence="0.951667">
631
</page>
<bodyText confidence="0.9942815">
- the probability of observing the response, given
that the cue has already occurred.
</bodyText>
<equation confidence="0.997052">
CP = p(y|x) = p(x, y)
p(x)
</equation>
<bodyText confidence="0.998477363636364">
CP suffers from the fact that it does not account
at all for the general frequency of the response
word. It therefore tends to favour very frequent
words, such as function words. An obvious so-
lution would be to divide CP by the frequency of
the response word, however this merely results in
PMI which is symmetric. By multiplying CP with
PMI (and taking the root, to simplify) we obtain a
measure which is asymmetric yet does not overtly
favour frequent response words.3 We refer to this
herein as Semi-Conditional Information (SCI).
</bodyText>
<equation confidence="0.998340333333333">
SCI = p(x, y)
&amp;quot;/
p(x) p(y)
</equation>
<bodyText confidence="0.99984925">
We also explore variants of both CP and SCI with
the additional significance correction presented for
PMI,ig. These can be easily inferred from the for-
mulae above.
</bodyText>
<sectionHeader confidence="0.645777" genericHeader="method">
3.4.2 Distance-based Measures
</sectionHeader>
<bodyText confidence="0.99990040625">
Co-Dispersion (herein CD), introduced by
Washtell (2009), is defined as the ratio of the
mean observed distance to the expected distance,
where the expected distance is derived from
the frequency of the more frequent word type.
Distance refers to the number of tokens separat-
ing an occurrence of one word and the nearest
occurrence of another word. Pairs spanning an
intervening occurrence of either word type or a
document boundary are not considered. Note that
here we specify only the generalised mean M, as
we wish to keep the specific choice of mean as a
parameter to be explored,
where distxyi is ith observed distance between
some occurrence of word type x and its nearest
preceding or following occurrence of word type
y, and n is the total number of such distances ob-
served (being at most equal to the frequency of the
rarer word).
In cases where many occurrences of the less
frequent word were not able to be paired, raw
CD gives midleading results. This is because un-
pairable words themselves provide useful nega-
tive evidence which CD ignores. A more ap-
propriate measure can be formed in which the
mean distance is calculated using the frequency of
the less frequent word, regardless of whether this
many distances were actually observed. This gives
us Neutrally-Weighted Co-Dispersion (NWCD).
Note that for convenience, we keep the standard
definition of the mean and introduce a correction
factor instead.
</bodyText>
<equation confidence="0.9932605">
1/ max(p(x), p(y))
M(distx,l ... distx,n)
</equation>
<bodyText confidence="0.996324625">
An asymmetric association measure can be
formed in a similar manner. Instead of calculat-
ing the mean using the frequency of the less fre-
quent word as described above, we explicitly use
the frequency of the cue word (which in some
cases may actually exceed the number of dis-
tances observed). This gives us Cue-Weighted Co-
Dispersion (CWCD).
</bodyText>
<equation confidence="0.999507">
1/ max(p(x), p(y)) (1)
M(distx,1 ... distx,n )
</equation>
<bodyText confidence="0.999852333333333">
In addition to these measures, we also ex-
plore significance-corrected forms NWCD,ig and
CWCD,ig, by introducing the same sample size
term employed by PMI,ig, CP,ig and SCI,ig.
Again, these can readily be inferred from the ex-
isting formulae in the above two sections.
</bodyText>
<equation confidence="0.99594925">
n
NWCD =
min(p(x), p(y))
n
CWCD = p(x)
M(distx,l ... distx,n)
1/ max(p(x), p(y))
CD =
</equation>
<subsectionHeader confidence="0.483804">
3.5 Co-occurrence Parameters
</subsectionHeader>
<bodyText confidence="0.999383055555556">
that of direction in the text. While the two may correlate, one
can find ample counter-examples: jerky triggers beef more
strongly than beef triggers jerky.
3Note that Wettler &amp; Rapp (1993) introduced a more gen-
eral asymmetric measure for predicting human associations,
by employing an exponent parameter to p(y). Our formuli-
sation is equivalent to their measure with an exponent of 0.5,
whereas they found an exponent of 0.66 to be most effective
in their empirical study. Exponents of 0 and 1 result in CP
and PMI respectively.
For frequency-based co-occurrence statistics, the
principle parameter is the window size. We will
use five window sizes separated by a constant scal-
ing factor, chosen so as to span those most com-
monly encountered in the literature, with some ex-
tension towards the upper end. We use w to rep-
resent this parameter, with w = 2 implying a win-
dow size of +/-2. The parameter values explored
</bodyText>
<page confidence="0.996639">
632
</page>
<bodyText confidence="0.999969473684211">
are w = 2, w = 10, w = 50, w = 250 and
w = 1250. We examine such large window sizes
so as to give a fairer comparison with the distance
approach which is not bounded by a window, and
in acknowledgement of the fact that the entire doc-
ument as context has been used with some success
in other application areas (most notably informa-
tion retrieval).
For distance-based statistics, the principle pa-
rameter is the function via which the various ob-
served distances between tokens are reduced to a
single mean value. In this investigation we will ex-
plore five means. These are the power means with
exponents (which herein we refer to as m) rang-
ing from -2 to +2. These give us the quadratic
mean or RMS (m = 2), the arithmetic mean
(m = 1), the geometric mean (m = 0), the har-
monic mean (m = −1), and the inverse quadratic
mean (m = −2).
</bodyText>
<sectionHeader confidence="0.980757" genericHeader="method">
4 Task I: Correlations on word pairs
</sectionHeader>
<bodyText confidence="0.9999845">
One of the ESSLLI Workshop shared tasks (Ba-
roni et al., 2008) required the evaluation of cor-
relation between a small, manually selected sub-
set of human cue-response scores from the EAT
dataset and automatic scores for the same word
pairs. Here, tather than focusing on word pairs
which meet certain grammatical and frequency
criteria we test on all pairs. For the EAT and
Florida datasets, this amounts to many tens of
thousands of cue-response pairs. Although this
makes the task of correlation harder, it means we
can attribute a great deal of statistical significance
to the results and make our observations as general
as possible.
</bodyText>
<subsectionHeader confidence="0.929078">
4.1 Evaluation Measures, Upper Bounds and
Baselines
</subsectionHeader>
<bodyText confidence="0.999585096774193">
For evaluating agreement between corpus-derived
associations and human associations, we use
Spearman’s Rank correlation. This is appropri-
ate because we are primarily interested in the rel-
ative ranking of word pair associations (in order
to predict particularly strong responses, for exam-
ple). Although some studies have used Pearson’s
correlation, the various association measures ex-
plored here are not linear within each another and
it would be inappropriate to evaluate them under
the assumption of a linear relationship with the hu-
man norms.
Two of the human datasets, Kent and
Minnesota, though collected independently, are
based on the same set of 100 cue words established
by Kent (1910). Therefore by performing a rank
correlation of these two datasets with one another,
(each of which was produced by pooling the re-
sponses of some 1000 people) we can get a useful
upper-bound for correlations: if a computer-based
system were to exceed this upper-bound in corre-
lations with either dataset, then we would need to
suspect it of over-fitting.
As a baseline, we use the corpus frequency of
the response word. The simple assumption is that
the more frequent a word is, the more likely it is
to appear as a human response independent of the
cue given. This is also the simplest formulation
which does not assign equal scores to the various
possible responses, and which is therefore capable
of producing a rank-list of predictions.
</bodyText>
<subsectionHeader confidence="0.969303">
4.2 Task I Results
</subsectionHeader>
<bodyText confidence="0.999831347826087">
Figure 1 shows the Spearman’s rank correlation
co-efficients across all paramaterisations of all as-
sociation measures (frequency-based on the left,
and distance-based on the right), with each human
dataset, for the 10 million word corpus. Embold-
ened are the best performing windowed and win-
dowless configurations for each dataset. The dif-
ference of these figures over the baseline is highly
significant (p &lt; 0.0001 inmost cases). The panels
to the right show summary statistics for these fig-
ures, and for the 1 million word corpus (for which
full figures are not included owing to space limita-
tions). These statistics include the performance of
the baseline, where relevant the estimated upper-
bound (see Section 4.1), and the difference in per-
formance of the distance-based method over the
window-based. The accuracy and error figures are
based on the co-efficients of determination (r2)
and are expressed both as a relative improvement
in accuracy (how much closer (r2) is to 1 under the
distance-based approach) and reduction in error
(how much further r2 is from zero). Also the sig-
nificance of the difference in the r values is given.
</bodyText>
<subsectionHeader confidence="0.991761">
4.3 Discussion
</subsectionHeader>
<bodyText confidence="0.999308142857143">
The two-way Spearman’s rank correlations be-
tween the Kent and Minesota datasets sug-
gested an upper bound of r = 0.4. In theory,
a large proportion of this agreement is accounted
for by paradigmatic associations which we are
not likely to fully reproduce with these first-order
measures. By this standard, the general levels of
</bodyText>
<page confidence="0.998928">
633
</page>
<figureCaption confidence="0.999834">
Figure 1: Correlations for window-based and windowless measures on a 10 million word corpus
</figureCaption>
<bodyText confidence="0.999969058823529">
correlation seen here (for these datasets r = 0.235
and r = 0.239 respectively) seem very reasonable.
What is immediately clear from Figure 1 is that,
for the range of parameters tested here, we see
a relatively small but statistically significant im-
provement across four of the five datasets when
adopting the distance-based approach.
The correlations are unsurprisingly lower across
the board for the much smaller 1 million word cor-
pus. Here, the best distance-based measure statis-
tically significantly outperforms the best window-
based one (with a significance level of p &lt;
0.0001) on one out of four datasets, while the dif-
ferences are not great enough to be considered sta-
tistically significant on the other three datasets.
There is therefore some evidence that the bene-
fits observed with the larger corpus hold in the
presence of limited data, which is in support of
the general theory that distance-based methods
capture more information from the corpus at the
co-occurrence level (Washtell, 2009). It remains
clear, however, that no method is presently a sub-
stitute for using a larger corpus.
In terms of optimum configurations, we find
that for the frequency-based approach with the
larger corpus, a window size of around +/-10 to
+/-50 words more or less consistently produces the
best results, irrespective of association the mea-
sure. Interestingly on the small corpus the ten-
dency appears to be towards a somewhat larger
window size than with the larger corpus. This
may be related to the larger windows’ increased
resilience to data-sparseness. Somewhat surpris-
ingly, we also see that our assymmetric associa-
tion measures SCI and SCIsig perform the best
overall amongst the windowed measures, largely
irrespective of the window or corpus, size.
In the large corpus, the best distance-based
measure is the asymmetric CWCD, with the sig-
nificance corrected measure CWCDsig showing
greater strength in the small corpus: perhaps,
again, for its improved reliability in the presence
of very low-frequency data. The optimum mean
for the distance-based parameterisations is some-
where around m = −1 (the harmonic) to m = 0
(the geometric). We find this unsurprising as the
typical distribution of inter-word distances in a
corpus is heavily skewed towards the smaller dis-
tances - indeed even a random corpus exhibits this
characteristic with the distances following a geo-
metric distribution.
</bodyText>
<sectionHeader confidence="0.887161" genericHeader="method">
5 Task II: Agreement with strongest
human associations
</sectionHeader>
<bodyText confidence="0.999931">
The correlation evalation presented considers all
word pairs present in the human datasets. How-
ever, human association norms tend to contain
a very long tail of hapax legomena - responses
which were given by only one individual. Such
responses are extremely difficult for corpus-based
</bodyText>
<page confidence="0.997674">
634
</page>
<bodyText confidence="0.999721">
association measures to predict, and given that
there is so little consensus amongst human respon-
dents over these items, it is probably not partic-
ularly useful to do so. Rather, it might be most
useful to predict common or majority human re-
sponses.
</bodyText>
<subsectionHeader confidence="0.997365">
5.1 Evaluation measure and Upper Bound
</subsectionHeader>
<bodyText confidence="0.999956083333334">
For the strongest human response to each cue
in the human datasets, its rank was calculated
amongst all 33, 000 possible responses to that
cue, according to each association measure and
parameterisation. Where there were tied scores
for various responses, a median rank was assigned.
As a rough upper bound, we would be impressed
by a computer system which was able to predict
the most popular human response as often as a
randomly selected individual in the human exper-
iments happened to chose the most popular re-
sponse.
</bodyText>
<subsectionHeader confidence="0.995738">
5.2 Task II Results
</subsectionHeader>
<bodyText confidence="0.986885891891892">
Figure 2 illustrates the range of computational as-
sociation scores attributed to only the strongest
human responses. The position of the strongest
human response to each cue word, within the
computationally-ranked lists of all possible re-
sponses, is plotted on the y-axis. For each asso-
ciation measure the points are ordered from best
to worst along the x-axis. In the ideal case there-
fore, the most popular human response for ev-
ery cue word would appear at rank 1 amongst the
computer-generated responses, resulting in a hori-
zonal line at y=1. Generally speaking therefore,
the smaller the area above a line the better the per-
formance of a measure.
Three summary statistics can be derived from
Figure 2:
1) The number of most popular human re-
sponses that are correctly predicted by a measure
is indicated by the x-position at which its line de-
parts from y=1. This can be seen to be around 11%
for CWCDsig and is zero for the two best PMI
parameterizations, with other illustrated measures
performing intermediately.
2) The width of the flat horizontal tails at the op-
posite corner of the figure indicate the proportion
of the cue words for which a measure was unable
to differentiate the strongest human response from
the large contingent of zero association scores re-
sulting from unobservable co-occurrences. This
tail is non-existent for CWCDsig, but afflicts some
25% and 62% of cue words under the two best
PMI parameterizations, again with other illus-
trated measures performing intermediately.
3) The median rank of the most popular human
response for each measure can be read of on the
y-axis at the horizontal mid-point (indicated by a
feint vertical line).
</bodyText>
<figureCaption confidence="0.99904375">
Figure 2: Agreement of computational measures
with strongest human responses
Figure 3: Relative agreement of computational
measures with strongest human responses
</figureCaption>
<bodyText confidence="0.9988398">
The results shown are for the Kent dataset, and
are highly typical. Included in the figure are
the three frequency-based configurations with the
highest median rank: SCIsig at window sizes w =
10 and w = 50, and standard LL at w = 10. Three
</bodyText>
<page confidence="0.997194">
635
</page>
<bodyText confidence="0.999942">
other frequency-based configurations are included
for contrast. Also included is the single window-
less configuration with the highest median rank -
in this case CWCDsig using the harmonic mean.
Several other windowless configurations (notably
CWCD and the nearby means) and had very simi-
lar profiles.
Figure 3 shows the magnitude of the difference
in the ranking of each of the same 100 strong hu-
man cue/response pairs, between the best window-
less versus best windowed method. Points above
the axis represent those cue/response pairs which
the windowless method ranked more highly, and
vice-versa. The points have been ordered on the
x-axis according the the cue word frequency.
</bodyText>
<subsectionHeader confidence="0.847885">
5.3 Discussion
</subsectionHeader>
<bodyText confidence="0.99999317948718">
Noteworthy, studying Figure 2, is the great sen-
sitivity of the frequency-based measures to the
window size parameter. There exists a cut-off
point, linked to window size, beyond which the
frequency-based measures are unable to make
any differentiation between the desired human re-
sponse and a large portion of the 33, 000 candidate
responses. This is almost certainly due to a lack
of evidence in the presence of very low frequency
words. Log-Likelihood performs somewhat better
in this respect, as it takes negative information into
account.
Although the distance-based approach follows
the same general trend as the other measures, it
is nonetheless able to generate a distinct non-zero
association score for every strong human response
and overall it aptly ranks them more highly. A
larger number these responses are actually ranked
first (i.e. successfully predicted) by the distance-
based approach. In fact this number is compara-
ble to, and sometimes exceeds, the upper-bound
of 10% implied by taking the average proportion
of human respondents who give the most popular
response to a given cue.
Whilst Figure 2 showed that overall the win-
dowless method fairs better, on a per-cue basis
(Figure 3) things are a little more interesting: For
a little over a third of cue-words the windowed
method actually appears to perform somewhat bet-
ter. For the majority however, the windowless ap-
proach performs considerably better (note that the
y-axis scale is logarithmic). It can also be seen
that the difference between the methods is most
pronounced for low frequency cue words, with re-
sponses to some cues exhibiting a relative ranking
of around one-hundred times lower for the win-
dowed method. This further supports the theory
that the windowless methods are better able to ex-
ploit sparse data.
</bodyText>
<sectionHeader confidence="0.996176" genericHeader="conclusions">
6 Conclusions and Future work
</sectionHeader>
<bodyText confidence="0.999990107142857">
This paper presented the first empirical compar-
ison of window-based and the relatively recently
introduced windowless association measures, us-
ing their ability to reproduce human association
scores as a testbed. We show that the best win-
dowless measures are always at least as good as
the best window-based measures, both when it
comes to overall correlation with human associ-
ation scores and predicting the strongest human
response. In addition, for several human associ-
ation sets, they perform significantly better. Al-
though not all parameter settings and corpus sizes
could be explored, we conclude that it is worth-
while investigating windowless association mea-
sures further. As a side-benefit, we have also in-
troduced new variants of existing frequency-based
association measures and shown them to perform
as well as or better than their existing counterparts.
Although these measures were semi-principled in
their construction, a deeper understanding of why
they work so well is needed. This may in turn lead
to the construction of superior windowless mea-
sures.
In our own future work, we are especially in-
terested in using higher-order windowless associa-
tion measures for retrieving paradigmatic relations
as well as exploring their use in various NLP ap-
plications.
</bodyText>
<sectionHeader confidence="0.998997" genericHeader="acknowledgments">
7 Acknowledgements
</sectionHeader>
<bodyText confidence="0.99974925">
We would like to extend sincere thanks to Rein-
hard Rapp for providing us with the Minnesota
dataset in digital form, and additional thanks to
Eric Atwell for his support.
</bodyText>
<sectionHeader confidence="0.999473" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999797875">
M. Baroni, S. Evert, and A. Lenci, editors. 2008. Esslli
Workshop on Distributional Lexical Semantics.
L. Burnard, 1995. Users’ Reference Guide, British Na-
tional Corpus. British National Corpus Consortium,
Oxford, England.
K. Church and P. Hanks. 1989. Word association
norms, mutual information, and lexicography. In
Proc. of ACL-89, pages 76–83.
</reference>
<page confidence="0.985862">
636
</page>
<reference confidence="0.999813229885058">
K. Church and P. Hanks. 1991. Word association
norms, mutual information and lexicography. Com-
putational Linguistics, 16(1):22–29.
P. Clark and F.C. Evans. 1954. Distance to near-
est neighbor as a measure of spatial relationships in
populations. Ecology, 35:445–453.
J. Curran. 2003. From distributional to semantic simi-
larity. Ph.D. thesis, University of Edinburgh.
Ted Dunning. 1993. Accurate methods for the statis-
tics of surprise and coincidence. Computational
Linguistics, 19:61–74.
S. Evert. 2005. The Statistics of Word Cooccurrences:
Word Pairs and Collocations. Ph.D. thesis, Insti-
tut fr maschinelle Sprachverarbeitung, University of
Stuttgart.
D. Hardcastle. 2005. Using the distributional hypothe-
sis to derive coocurrence scores from the British Na-
tional Corpus. In Proc. of Corpus Linguistics.
J. Jenkins. 1970. The 1952 Minnesota word associa-
tion norms. In L. Postman and G. Keppel, editors,
Norms of word associations, pages 1–38. Academic
press.
G. Kent and A. Rosanoff. 1910. A study of association
in insanity. Amer. J. of Insanity, pages 317–390.
G. Kiss, C. Armstrong, R. Milroy, and J. Piper. 1973.
An associative thesaurus of English and its computer
analysis. In A. Aitken, R. Bailey, and N. Hamilton-
Smith, editors, The Computer and Literary Studies.
Edinburgh University Press.
B. Krenn and S. Evert. 2001. Cam we do better than
frequency? a case study on extracting pp-verb collo-
cations. In Proc. of the ACL Workshop on Colloca-
tions.
A. Lamjiri, O. El Demerdash, and L. Kosseim. 2004.
Simple features for statistical word sense disam-
biguation. In Proc. of SENSEVAL-2004.
D. Lin. 1998. Automatic retrieval and clustering of
similar words. In Proc. of COLING-ACL-98.
Lukas Michelbacher, Stefan Evert, and Hinrich
Sch¨utze. 2007. Asymmetric association measures.
In Proc. of RANLP-2007.
D. Nelson, C. McEvoy, J. Walling, and J. Wheeler.
1980. The University of South Florida homograph
norms. Behaviour Research Methods and Instru-
mentation, 12:16–37.
S. Pado and M. Lapata. 2007. Dependency-based con-
struction of semantic space models. Computational
Linguistics, 33(2):161–199.
T. Pedersen, S. Patwardhan, and J. Michelizzi. 2004.
Wordnet::similarity - measuring the relatedness of
concepts. In Proc. of the 21&amp;quot; National Conference
on Artificial Intelligence; 2004.
R. Rapp. 2002. The computation of word associa-
tions: comparing syntagmatic and paradigmatic ap-
proaches. In Proc of COLING 2002.
D.L. Sackett. 2001. Why randomized controlled tri-
als fail but needn’t: 2. failure to employ physiolog-
ical statistics, or the only formula a clinician-trialist
is every likely to need (or understand). Canadian
Medical Association Journal, 165(9):1226–1237.
P. Savicki and J. Hlavacova. 2002. Measures of word
commonness. Journal of Quantitative Linguistcs,
9(3):215–231.
E. Terra and C. Clarke. 2004. Fast computation of
lexical affinity models. In Proc of COLING 2004.
Renata Vieira and Massimo Poesio. 2000. An
empirically-based system for processing definite de-
scriptions. Computational Linguistics, 26(4), De-
cember.
X. Wang, 2005. Robust Utilization of Context in Word
Sense Disambiguation, chapter Modeling and Using
Context, pages 529–541. Springer Lecture Notes in
Computer Science.
J. Washtell. 2009. Co-dispersion: A windowless ap-
proach to lexical association. In Proc. of EACL-
2009.
M. Wettler and R. Rapp. 1993. Computation of word
associations based on the co-ocurrences of words in
large corpora. In Proc. of the First Workshop on Very
Large Corpora.
K. White and L. Abrams. 2004. Free associations and
dominance ratings of homophones for young and
older adults. Behaviour Research Methods, Instru-
ments and Computers, 36:408–420.
D. Yarowsky and R Florian. 2002. Evaluating sense
disambiguation across diverse parameter spaces.
Natural Language Engineering, 8(4):293–310.
</reference>
<page confidence="0.997835">
637
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.974439">
<title confidence="0.999515">A Comparison of Windowless and Window-Based Association Measures as Predictors of Syntagmatic Human Associations</title>
<author confidence="0.99813">Justin</author>
<affiliation confidence="0.999108">School of University of</affiliation>
<email confidence="0.993665">washtell@comp.leeds.ac.uk</email>
<abstract confidence="0.99937628">Distance-based (windowless) word assocation measures have only very recently appeared in the NLP literature and their performance compared to existing windowed or frequency-based measures is largely unknown. We conduct a largescale empirical comparison of a variety of distance-based and frequency-based measures for the reproduction of syntagmatic human assocation norms. Overall, our results show an improvement in the predictive power of windowless over windowed measures. This provides support to some of the previously published theoretical advantages and makes windowless approaches a promising avenue to explore further. This study also serves as a first comparison of windowed methods across numerous human association datasets. During this comparison we also introduce some novel variations of window-based measures which perform as well as or better in the human association norm task than established measures.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M Baroni</author>
<author>S Evert</author>
<author>A Lenci</author>
<author>editors</author>
</authors>
<date>2008</date>
<booktitle>Esslli Workshop on Distributional Lexical Semantics.</booktitle>
<contexts>
<context position="4724" citStr="Baroni et al., 2008" startWordPosition="699" endWordPosition="702">d for predicting paradigmatic relationships: i.e. through the observation of words which share similar sets of syntagmatic associations. Therefore improvements made at the level we are concerned with may reasonably be expected to carry through to applications which hinge on the identification of paradigmatic relationships. After a discussion of previous work in Section 2, we formulate the exact association measures and parameter settings which we compare in Section 3, where we also introduce the corpora and human association sets used. Then, by using evaluations similar to those described in (Baroni et al., 2008) and by Rapp (2002), we show that the best distance-based measures correlate better overall with human association scores than do the best window based configurations (see Section 4), and that they also serve as better predictors of the strongest human associations (see Section 5). 2 Related Work Measures based on co-ocurrence frequency. The standard way of estimating the syntagmatic association of word pairs in a corpus is to examine the frequency of their co-occurence, and then usually to compare this to some expected frequency. There are a host of measures which exist for this purpose. Afte</context>
<context position="8312" citStr="Baroni et al., 2008" startWordPosition="1264" endWordPosition="1267">esearchers (Lin, 1998; Curran, 2003; Pado and Lapata, 2007) have used word space models based on grammatical relationships for detecting and quantifying (mostly paradigmatic) word associations. In this paper, we will not use syntactic relation measures for two main reasons. Firstly these depend on the availability of parsers, which is not a given for many languages. Secondly, this may not be the most pertinent approach for predicting human free associations, in which certain observed relationsips can be hard to express in terms of syntactic relationships. 3 Methodology Similar to (Rapp, 2002; Baroni et al., 2008, among others), we use comparison to human assocation datasets as a test bed for the scores produced by computational association measures. An alternative might be to validate scores against those derived from a structured resource such as WordNet. 629 Table 1: Human association datasets Name Origin Cues Respondents Kent Kent &amp; Rosanoff (1910) 100 — 1000 Minnesota Russell &amp; Jenkins (1954) 100 — 1000 EAT Kiss et al (1973) 8400 100 Florida Nelson et al (1980) 5019 — 140 However, relatedness measures for WordNet are many and varied and are themselves the subject of evaluation (Pedersen et al., 2</context>
<context position="21856" citStr="Baroni et al., 2008" startWordPosition="3542" endWordPosition="3546">(most notably information retrieval). For distance-based statistics, the principle parameter is the function via which the various observed distances between tokens are reduced to a single mean value. In this investigation we will explore five means. These are the power means with exponents (which herein we refer to as m) ranging from -2 to +2. These give us the quadratic mean or RMS (m = 2), the arithmetic mean (m = 1), the geometric mean (m = 0), the harmonic mean (m = −1), and the inverse quadratic mean (m = −2). 4 Task I: Correlations on word pairs One of the ESSLLI Workshop shared tasks (Baroni et al., 2008) required the evaluation of correlation between a small, manually selected subset of human cue-response scores from the EAT dataset and automatic scores for the same word pairs. Here, tather than focusing on word pairs which meet certain grammatical and frequency criteria we test on all pairs. For the EAT and Florida datasets, this amounts to many tens of thousands of cue-response pairs. Although this makes the task of correlation harder, it means we can attribute a great deal of statistical significance to the results and make our observations as general as possible. 4.1 Evaluation Measures, </context>
</contexts>
<marker>Baroni, Evert, Lenci, editors, 2008</marker>
<rawString>M. Baroni, S. Evert, and A. Lenci, editors. 2008. Esslli Workshop on Distributional Lexical Semantics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Burnard</author>
</authors>
<title>Users’ Reference Guide,</title>
<date>1995</date>
<institution>British National Corpus. British National Corpus Consortium,</institution>
<location>Oxford, England.</location>
<contexts>
<context position="12124" citStr="Burnard, 1995" startWordPosition="1885" endWordPosition="1886">this paper (one native and one near-native speaker). After independent annotation, agreement was measured at a percentage agreement of 91/93% and a kappa of 0.80/0.82 for Minnesota and Kent, respectively. Therefore, the distinction can be made with high reliability. Overall, 27/39% of the human responses were syntagmatic in the Kent/Minnesota datasets, showing that syntagmatic relations make up a large proportion of even the strongest human associations. 3.3 Corpora We use two randomized subsets of the British National Corpus (BNC), a representative 100 million word corpus of British English (Burnard, 1995): one 10 million word sample, and a 1 million word sample. A vocabulary of approximately 33,000 word types was used. The selected words included approximately 24,000 word types comprising all cue and target words from the multiple sets of human association norms to be used in this study. To these were added a top-cut of the most frequent words in the BNC, until the total of 33,000 word types was reached. The resultant set included ap630 proximately the 24,000 most common word types in the BNC, with the remaining 9000 words types therefore comprising relatively uncommon words taken from the hum</context>
</contexts>
<marker>Burnard, 1995</marker>
<rawString>L. Burnard, 1995. Users’ Reference Guide, British National Corpus. British National Corpus Consortium, Oxford, England.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Church</author>
<author>P Hanks</author>
</authors>
<title>Word association norms, mutual information, and lexicography.</title>
<date>1989</date>
<booktitle>In Proc. of ACL-89,</booktitle>
<pages>76--83</pages>
<contexts>
<context position="6659" citStr="Church and Hanks, 1989" startWordPosition="1013" endWordPosition="1016">t the other. A versatile and hugely popular generalised approach is therefore to consider a ”‘window”’ of w words, where w can be varied to suit the application. Unsurprisingly, it has been found that this is a parameter which can have a significant impact upon performance (Yarowsky and Florian, 2002; Lamjiri et al., 2004; Wang, 2005). While choosing an optimum window size for an application is often subject to trial and error, there are some generally recognized trade-offs between small versus large windows, such as the impact of data-sparseness, and the nature of the associations retrieved (Church and Hanks, 1989; Church and Hanks, 1991; Rapp, 2002) Measures based on distance between words in the text. The idea of using distance as an alternative to frequency for modelling language has been touched upon in recent literature (Savicki and Hlavacova, 2002; Terra and Clarke, 2004; Hardcastle, 2005). Washtell (2009) showed that it is possible to build distance-based analogues of existing syntagmatic association measures, by using the notions of mean and expected distance rather than of frequency. These measures have certain theoretical qualities - notably scale-independence and relative resilience to data-</context>
</contexts>
<marker>Church, Hanks, 1989</marker>
<rawString>K. Church and P. Hanks. 1989. Word association norms, mutual information, and lexicography. In Proc. of ACL-89, pages 76–83.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Church</author>
<author>P Hanks</author>
</authors>
<title>Word association norms, mutual information and lexicography.</title>
<date>1991</date>
<journal>Computational Linguistics,</journal>
<volume>16</volume>
<issue>1</issue>
<contexts>
<context position="6683" citStr="Church and Hanks, 1991" startWordPosition="1017" endWordPosition="1020"> and hugely popular generalised approach is therefore to consider a ”‘window”’ of w words, where w can be varied to suit the application. Unsurprisingly, it has been found that this is a parameter which can have a significant impact upon performance (Yarowsky and Florian, 2002; Lamjiri et al., 2004; Wang, 2005). While choosing an optimum window size for an application is often subject to trial and error, there are some generally recognized trade-offs between small versus large windows, such as the impact of data-sparseness, and the nature of the associations retrieved (Church and Hanks, 1989; Church and Hanks, 1991; Rapp, 2002) Measures based on distance between words in the text. The idea of using distance as an alternative to frequency for modelling language has been touched upon in recent literature (Savicki and Hlavacova, 2002; Terra and Clarke, 2004; Hardcastle, 2005). Washtell (2009) showed that it is possible to build distance-based analogues of existing syntagmatic association measures, by using the notions of mean and expected distance rather than of frequency. These measures have certain theoretical qualities - notably scale-independence and relative resilience to data-sparseness - which might</context>
</contexts>
<marker>Church, Hanks, 1991</marker>
<rawString>K. Church and P. Hanks. 1991. Word association norms, mutual information and lexicography. Computational Linguistics, 16(1):22–29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Clark</author>
<author>F C Evans</author>
</authors>
<title>Distance to nearest neighbor as a measure of spatial relationships in populations.</title>
<date>1954</date>
<journal>Ecology,</journal>
<pages>35--445</pages>
<contexts>
<context position="7544" citStr="Clark and Evans, 1954" startWordPosition="1145" endWordPosition="1148"> 2004; Hardcastle, 2005). Washtell (2009) showed that it is possible to build distance-based analogues of existing syntagmatic association measures, by using the notions of mean and expected distance rather than of frequency. These measures have certain theoretical qualities - notably scale-independence and relative resilience to data-sparseness - which might be expected to provide gains in tasks such as the reproduction of human association norms from corpus data. The specific measure introduced by Washtell, called Co-Dispersion, is based upon an established biogeographic dispersion measure (Clark and Evans, 1954). We provide a thorough empirical investigation of Co-Dispersion and some of its derivatives herein. Measures based on syntactic relations. Several researchers (Lin, 1998; Curran, 2003; Pado and Lapata, 2007) have used word space models based on grammatical relationships for detecting and quantifying (mostly paradigmatic) word associations. In this paper, we will not use syntactic relation measures for two main reasons. Firstly these depend on the availability of parsers, which is not a given for many languages. Secondly, this may not be the most pertinent approach for predicting human free as</context>
</contexts>
<marker>Clark, Evans, 1954</marker>
<rawString>P. Clark and F.C. Evans. 1954. Distance to nearest neighbor as a measure of spatial relationships in populations. Ecology, 35:445–453.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Curran</author>
</authors>
<title>From distributional to semantic similarity.</title>
<date>2003</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Edinburgh.</institution>
<contexts>
<context position="7728" citStr="Curran, 2003" startWordPosition="1174" endWordPosition="1175">tance rather than of frequency. These measures have certain theoretical qualities - notably scale-independence and relative resilience to data-sparseness - which might be expected to provide gains in tasks such as the reproduction of human association norms from corpus data. The specific measure introduced by Washtell, called Co-Dispersion, is based upon an established biogeographic dispersion measure (Clark and Evans, 1954). We provide a thorough empirical investigation of Co-Dispersion and some of its derivatives herein. Measures based on syntactic relations. Several researchers (Lin, 1998; Curran, 2003; Pado and Lapata, 2007) have used word space models based on grammatical relationships for detecting and quantifying (mostly paradigmatic) word associations. In this paper, we will not use syntactic relation measures for two main reasons. Firstly these depend on the availability of parsers, which is not a given for many languages. Secondly, this may not be the most pertinent approach for predicting human free associations, in which certain observed relationsips can be hard to express in terms of syntactic relationships. 3 Methodology Similar to (Rapp, 2002; Baroni et al., 2008, among others),</context>
</contexts>
<marker>Curran, 2003</marker>
<rawString>J. Curran. 2003. From distributional to semantic similarity. Ph.D. thesis, University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Dunning</author>
</authors>
<title>Accurate methods for the statistics of surprise and coincidence.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<pages>19--61</pages>
<contexts>
<context position="14785" citStr="Dunning, 1993" startWordPosition="2329" endWordPosition="2331">introduced in Section 2. For ranking word pairs, we can neglect the usual logarithm. PMI = p(x, y) p(x)p(y) PMI is infamous for its tendency to attribute very high association scores to pairs involving low frequency words, as the denominator is small in such cases, even though the evidence for association in such cases is also small. This can result in some unlikely associations. There exist a number of alternative measures which factor in the amount of evidence to give an estimate of the significance of association. One popular and statistically appealing such measure is Log-Likelihood (LL) (Dunning, 1993). LL works on a similar principle to PMI but considers the ratio of the observed to expected co-occurrence frequencies for all contingencies (i.e. including those where the words do not co-occur). LL, as it most frequently appears in the literature, is not actually a measure of positive association: it also responds to significant negative association. Therefore LL is arguably not suited to the task in hand. Krenn &amp; Evert (2001) experiment with one-tailed variants of LL and Chi-Squared measures, although they do not define these variants. Here, we construct a one-tailed variant of LL by simply</context>
</contexts>
<marker>Dunning, 1993</marker>
<rawString>Ted Dunning. 1993. Accurate methods for the statistics of surprise and coincidence. Computational Linguistics, 19:61–74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Evert</author>
</authors>
<title>The Statistics of Word Cooccurrences: Word Pairs and Collocations.</title>
<date>2005</date>
<tech>Ph.D. thesis,</tech>
<institution>Institut fr maschinelle Sprachverarbeitung, University of Stuttgart.</institution>
<contexts>
<context position="5751" citStr="Evert (2005)" startWordPosition="863" endWordPosition="864"> a corpus is to examine the frequency of their co-occurence, and then usually to compare this to some expected frequency. There are a host of measures which exist for this purpose. After raw co-occurrence frequency, the simplest and most prevalent in the literature is Pointwise Mutual Information, famously used by Church (1989) (as the association ratio). This is defined as the log of the ratio of the observed co-occurrence frequency to the frequency expected under independence. More sophisticated and statistically-informed measures include t-Score, z-Score, Chi-Squared and LogLikelihood (see Evert (2005) for a thorough review). All of these measures have in common that they require co-occurrence frequency to be specified, and therefore require some definition of a region within which to count co-occurrences. This region might be the entirety of a document at one extreme, or a bigram at the other. A versatile and hugely popular generalised approach is therefore to consider a ”‘window”’ of w words, where w can be varied to suit the application. Unsurprisingly, it has been found that this is a parameter which can have a significant impact upon performance (Yarowsky and Florian, 2002; Lamjiri et </context>
</contexts>
<marker>Evert, 2005</marker>
<rawString>S. Evert. 2005. The Statistics of Word Cooccurrences: Word Pairs and Collocations. Ph.D. thesis, Institut fr maschinelle Sprachverarbeitung, University of Stuttgart.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Hardcastle</author>
</authors>
<title>Using the distributional hypothesis to derive coocurrence scores from the British National Corpus.</title>
<date>2005</date>
<booktitle>In Proc. of Corpus Linguistics.</booktitle>
<contexts>
<context position="1836" citStr="Hardcastle, 2005" startWordPosition="270" endWordPosition="271">d a large amount of attention in the last decades and a host of computational association measures have been proposed to deal with this task (see Section 2). These measures traditionally rely on the co-ocurrence frequency of two words in a corpus to estimate a relatedness score. There has been a recent emergence of distancebased language modelling techiques in NLP (Savicki and Hlavacova, 2002; Terra and Clarke, 2004) in which the number of tokens separating words is the essential quantity. While some of this work has considered distance-based alternatives to conventional association measures (Hardcastle, 2005; Katja Markert School of Computing University of Leeds markert@comp.leeds.ac.uk Washtell, 2009), there has been no principled empirical evaluation of these measures as predictors of human association. We remedy this by conducting a thorough comparison of a wide variety of frequency-based and distance-based measures as predictors of human association scores as elicited in several different free word association tasks. In this work we focus on first-order association measures as predictors of syntagmatic associations. This is in contrast to second and higher-order measures which are better pred</context>
<context position="6946" citStr="Hardcastle, 2005" startWordPosition="1061" endWordPosition="1063">ian, 2002; Lamjiri et al., 2004; Wang, 2005). While choosing an optimum window size for an application is often subject to trial and error, there are some generally recognized trade-offs between small versus large windows, such as the impact of data-sparseness, and the nature of the associations retrieved (Church and Hanks, 1989; Church and Hanks, 1991; Rapp, 2002) Measures based on distance between words in the text. The idea of using distance as an alternative to frequency for modelling language has been touched upon in recent literature (Savicki and Hlavacova, 2002; Terra and Clarke, 2004; Hardcastle, 2005). Washtell (2009) showed that it is possible to build distance-based analogues of existing syntagmatic association measures, by using the notions of mean and expected distance rather than of frequency. These measures have certain theoretical qualities - notably scale-independence and relative resilience to data-sparseness - which might be expected to provide gains in tasks such as the reproduction of human association norms from corpus data. The specific measure introduced by Washtell, called Co-Dispersion, is based upon an established biogeographic dispersion measure (Clark and Evans, 1954). </context>
</contexts>
<marker>Hardcastle, 2005</marker>
<rawString>D. Hardcastle. 2005. Using the distributional hypothesis to derive coocurrence scores from the British National Corpus. In Proc. of Corpus Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Jenkins</author>
</authors>
<title>The 1952 Minnesota word association norms.</title>
<date>1970</date>
<booktitle>Norms of word associations,</booktitle>
<pages>1--38</pages>
<editor>In L. Postman and G. Keppel, editors,</editor>
<publisher>Academic press.</publisher>
<marker>Jenkins, 1970</marker>
<rawString>J. Jenkins. 1970. The 1952 Minnesota word association norms. In L. Postman and G. Keppel, editors, Norms of word associations, pages 1–38. Academic press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Kent</author>
<author>A Rosanoff</author>
</authors>
<title>A study of association in insanity.</title>
<date>1910</date>
<journal>Amer. J. of Insanity,</journal>
<pages>317--390</pages>
<contexts>
<context position="8658" citStr="Kent &amp; Rosanoff (1910)" startWordPosition="1319" endWordPosition="1322">given for many languages. Secondly, this may not be the most pertinent approach for predicting human free associations, in which certain observed relationsips can be hard to express in terms of syntactic relationships. 3 Methodology Similar to (Rapp, 2002; Baroni et al., 2008, among others), we use comparison to human assocation datasets as a test bed for the scores produced by computational association measures. An alternative might be to validate scores against those derived from a structured resource such as WordNet. 629 Table 1: Human association datasets Name Origin Cues Respondents Kent Kent &amp; Rosanoff (1910) 100 — 1000 Minnesota Russell &amp; Jenkins (1954) 100 — 1000 EAT Kiss et al (1973) 8400 100 Florida Nelson et al (1980) 5019 — 140 However, relatedness measures for WordNet are many and varied and are themselves the subject of evaluation (Pedersen et al., 2004). Although human association datasets have their own peculiarities, they do at least provide some kind of definite Gold Standard. Yet another alternative might be to incorporate our computational association scores into an application (such as anaphora resolution), and measure the performance of that, but noise from other submodules would c</context>
</contexts>
<marker>Kent, Rosanoff, 1910</marker>
<rawString>G. Kent and A. Rosanoff. 1910. A study of association in insanity. Amer. J. of Insanity, pages 317–390.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Kiss</author>
<author>C Armstrong</author>
<author>R Milroy</author>
<author>J Piper</author>
</authors>
<title>An associative thesaurus of English and its computer analysis.</title>
<date>1973</date>
<booktitle>The Computer and Literary Studies.</booktitle>
<editor>In A. Aitken, R. Bailey, and N. HamiltonSmith, editors,</editor>
<publisher>Edinburgh University Press.</publisher>
<contexts>
<context position="8737" citStr="Kiss et al (1973)" startWordPosition="1335" endWordPosition="1338">predicting human free associations, in which certain observed relationsips can be hard to express in terms of syntactic relationships. 3 Methodology Similar to (Rapp, 2002; Baroni et al., 2008, among others), we use comparison to human assocation datasets as a test bed for the scores produced by computational association measures. An alternative might be to validate scores against those derived from a structured resource such as WordNet. 629 Table 1: Human association datasets Name Origin Cues Respondents Kent Kent &amp; Rosanoff (1910) 100 — 1000 Minnesota Russell &amp; Jenkins (1954) 100 — 1000 EAT Kiss et al (1973) 8400 100 Florida Nelson et al (1980) 5019 — 140 However, relatedness measures for WordNet are many and varied and are themselves the subject of evaluation (Pedersen et al., 2004). Although human association datasets have their own peculiarities, they do at least provide some kind of definite Gold Standard. Yet another alternative might be to incorporate our computational association scores into an application (such as anaphora resolution), and measure the performance of that, but noise from other submodules would complicate evaluation. We leave such extensions to possible future work. We use </context>
</contexts>
<marker>Kiss, Armstrong, Milroy, Piper, 1973</marker>
<rawString>G. Kiss, C. Armstrong, R. Milroy, and J. Piper. 1973. An associative thesaurus of English and its computer analysis. In A. Aitken, R. Bailey, and N. HamiltonSmith, editors, The Computer and Literary Studies. Edinburgh University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Krenn</author>
<author>S Evert</author>
</authors>
<title>Cam we do better than frequency? a case study on extracting pp-verb collocations.</title>
<date>2001</date>
<booktitle>In Proc. of the ACL Workshop on Collocations.</booktitle>
<contexts>
<context position="15217" citStr="Krenn &amp; Evert (2001)" startWordPosition="2400" endWordPosition="2403">s which factor in the amount of evidence to give an estimate of the significance of association. One popular and statistically appealing such measure is Log-Likelihood (LL) (Dunning, 1993). LL works on a similar principle to PMI but considers the ratio of the observed to expected co-occurrence frequencies for all contingencies (i.e. including those where the words do not co-occur). LL, as it most frequently appears in the literature, is not actually a measure of positive association: it also responds to significant negative association. Therefore LL is arguably not suited to the task in hand. Krenn &amp; Evert (2001) experiment with one-tailed variants of LL and Chi-Squared measures, although they do not define these variants. Here, we construct a one-tailed variant of LL by simply reversing the signs of the terms which respond to negative association. LL1tail = p(x, y) log p(x, y) p(x)p(y) − p(¯x, y) log p(¯x, y) + p(¯x,¯y) log p(¯x, ¯y) p(¯x)p(y) p(¯x)p(¯y) LL does not have a clear analogue amongst the distance-based measures (introduced in Section 3.4.2), whereas PMI for instance does. We therefore construct variants of PMI and other measures which take the amount of evidence into account in a way whic</context>
</contexts>
<marker>Krenn, Evert, 2001</marker>
<rawString>B. Krenn and S. Evert. 2001. Cam we do better than frequency? a case study on extracting pp-verb collocations. In Proc. of the ACL Workshop on Collocations.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Lamjiri</author>
<author>O El Demerdash</author>
<author>L Kosseim</author>
</authors>
<title>Simple features for statistical word sense disambiguation.</title>
<date>2004</date>
<booktitle>In Proc. of SENSEVAL-2004.</booktitle>
<marker>Lamjiri, El Demerdash, Kosseim, 2004</marker>
<rawString>A. Lamjiri, O. El Demerdash, and L. Kosseim. 2004. Simple features for statistical word sense disambiguation. In Proc. of SENSEVAL-2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lin</author>
</authors>
<title>Automatic retrieval and clustering of similar words.</title>
<date>1998</date>
<booktitle>In Proc. of COLING-ACL-98.</booktitle>
<contexts>
<context position="7714" citStr="Lin, 1998" startWordPosition="1172" endWordPosition="1173">xpected distance rather than of frequency. These measures have certain theoretical qualities - notably scale-independence and relative resilience to data-sparseness - which might be expected to provide gains in tasks such as the reproduction of human association norms from corpus data. The specific measure introduced by Washtell, called Co-Dispersion, is based upon an established biogeographic dispersion measure (Clark and Evans, 1954). We provide a thorough empirical investigation of Co-Dispersion and some of its derivatives herein. Measures based on syntactic relations. Several researchers (Lin, 1998; Curran, 2003; Pado and Lapata, 2007) have used word space models based on grammatical relationships for detecting and quantifying (mostly paradigmatic) word associations. In this paper, we will not use syntactic relation measures for two main reasons. Firstly these depend on the availability of parsers, which is not a given for many languages. Secondly, this may not be the most pertinent approach for predicting human free associations, in which certain observed relationsips can be hard to express in terms of syntactic relationships. 3 Methodology Similar to (Rapp, 2002; Baroni et al., 2008, </context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>D. Lin. 1998. Automatic retrieval and clustering of similar words. In Proc. of COLING-ACL-98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lukas Michelbacher</author>
<author>Stefan Evert</author>
<author>Hinrich Sch¨utze</author>
</authors>
<title>Asymmetric association measures.</title>
<date>2007</date>
<booktitle>In Proc. of RANLP-2007.</booktitle>
<marker>Michelbacher, Evert, Sch¨utze, 2007</marker>
<rawString>Lukas Michelbacher, Stefan Evert, and Hinrich Sch¨utze. 2007. Asymmetric association measures. In Proc. of RANLP-2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Nelson</author>
<author>C McEvoy</author>
<author>J Walling</author>
<author>J Wheeler</author>
</authors>
<title>The University of South Florida homograph norms.</title>
<date>1980</date>
<booktitle>Behaviour Research Methods and Instrumentation,</booktitle>
<pages>12--16</pages>
<contexts>
<context position="8774" citStr="Nelson et al (1980)" startWordPosition="1342" endWordPosition="1345"> in which certain observed relationsips can be hard to express in terms of syntactic relationships. 3 Methodology Similar to (Rapp, 2002; Baroni et al., 2008, among others), we use comparison to human assocation datasets as a test bed for the scores produced by computational association measures. An alternative might be to validate scores against those derived from a structured resource such as WordNet. 629 Table 1: Human association datasets Name Origin Cues Respondents Kent Kent &amp; Rosanoff (1910) 100 — 1000 Minnesota Russell &amp; Jenkins (1954) 100 — 1000 EAT Kiss et al (1973) 8400 100 Florida Nelson et al (1980) 5019 — 140 However, relatedness measures for WordNet are many and varied and are themselves the subject of evaluation (Pedersen et al., 2004). Although human association datasets have their own peculiarities, they do at least provide some kind of definite Gold Standard. Yet another alternative might be to incorporate our computational association scores into an application (such as anaphora resolution), and measure the performance of that, but noise from other submodules would complicate evaluation. We leave such extensions to possible future work. We use evaluations similar to those used bef</context>
</contexts>
<marker>Nelson, McEvoy, Walling, Wheeler, 1980</marker>
<rawString>D. Nelson, C. McEvoy, J. Walling, and J. Wheeler. 1980. The University of South Florida homograph norms. Behaviour Research Methods and Instrumentation, 12:16–37.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Pado</author>
<author>M Lapata</author>
</authors>
<title>Dependency-based construction of semantic space models.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>2</issue>
<contexts>
<context position="7752" citStr="Pado and Lapata, 2007" startWordPosition="1176" endWordPosition="1179">han of frequency. These measures have certain theoretical qualities - notably scale-independence and relative resilience to data-sparseness - which might be expected to provide gains in tasks such as the reproduction of human association norms from corpus data. The specific measure introduced by Washtell, called Co-Dispersion, is based upon an established biogeographic dispersion measure (Clark and Evans, 1954). We provide a thorough empirical investigation of Co-Dispersion and some of its derivatives herein. Measures based on syntactic relations. Several researchers (Lin, 1998; Curran, 2003; Pado and Lapata, 2007) have used word space models based on grammatical relationships for detecting and quantifying (mostly paradigmatic) word associations. In this paper, we will not use syntactic relation measures for two main reasons. Firstly these depend on the availability of parsers, which is not a given for many languages. Secondly, this may not be the most pertinent approach for predicting human free associations, in which certain observed relationsips can be hard to express in terms of syntactic relationships. 3 Methodology Similar to (Rapp, 2002; Baroni et al., 2008, among others), we use comparison to hu</context>
<context position="9412" citStr="Pado and Lapata, 2007" startWordPosition="1441" endWordPosition="1444">er, relatedness measures for WordNet are many and varied and are themselves the subject of evaluation (Pedersen et al., 2004). Although human association datasets have their own peculiarities, they do at least provide some kind of definite Gold Standard. Yet another alternative might be to incorporate our computational association scores into an application (such as anaphora resolution), and measure the performance of that, but noise from other submodules would complicate evaluation. We leave such extensions to possible future work. We use evaluations similar to those used before (Rapp, 2002; Pado and Lapata, 2007; Baroni et al., 2008, among others). However, whereas most existing studies use only one dataset, or handselected parts thereof, we aim to evaluate measures across four different human datasets. In this way we hope to get as unbiased a picture as possible. 3.1 Association data The datasets used are listed in Table 1. While the exact experimental conditions may differ, the datasets used were all elicited using the same basic methodology: by presenting individual words (cues) to a number of healthy human subjects and asking in each case for the word that is most immediately or strongly evoked. </context>
</contexts>
<marker>Pado, Lapata, 2007</marker>
<rawString>S. Pado and M. Lapata. 2007. Dependency-based construction of semantic space models. Computational Linguistics, 33(2):161–199.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Pedersen</author>
<author>S Patwardhan</author>
<author>J Michelizzi</author>
</authors>
<title>Wordnet::similarity - measuring the relatedness of concepts.</title>
<date>2004</date>
<booktitle>In Proc. of the 21&amp;quot; National Conference on Artificial Intelligence;</booktitle>
<contexts>
<context position="8916" citStr="Pedersen et al., 2004" startWordPosition="1365" endWordPosition="1368">aroni et al., 2008, among others), we use comparison to human assocation datasets as a test bed for the scores produced by computational association measures. An alternative might be to validate scores against those derived from a structured resource such as WordNet. 629 Table 1: Human association datasets Name Origin Cues Respondents Kent Kent &amp; Rosanoff (1910) 100 — 1000 Minnesota Russell &amp; Jenkins (1954) 100 — 1000 EAT Kiss et al (1973) 8400 100 Florida Nelson et al (1980) 5019 — 140 However, relatedness measures for WordNet are many and varied and are themselves the subject of evaluation (Pedersen et al., 2004). Although human association datasets have their own peculiarities, they do at least provide some kind of definite Gold Standard. Yet another alternative might be to incorporate our computational association scores into an application (such as anaphora resolution), and measure the performance of that, but noise from other submodules would complicate evaluation. We leave such extensions to possible future work. We use evaluations similar to those used before (Rapp, 2002; Pado and Lapata, 2007; Baroni et al., 2008, among others). However, whereas most existing studies use only one dataset, or ha</context>
</contexts>
<marker>Pedersen, Patwardhan, Michelizzi, 2004</marker>
<rawString>T. Pedersen, S. Patwardhan, and J. Michelizzi. 2004. Wordnet::similarity - measuring the relatedness of concepts. In Proc. of the 21&amp;quot; National Conference on Artificial Intelligence; 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Rapp</author>
</authors>
<title>The computation of word associations: comparing syntagmatic and paradigmatic approaches.</title>
<date>2002</date>
<booktitle>In Proc of COLING</booktitle>
<contexts>
<context position="2723" citStr="Rapp, 2002" startWordPosition="399" endWordPosition="400">equency-based and distance-based measures as predictors of human association scores as elicited in several different free word association tasks. In this work we focus on first-order association measures as predictors of syntagmatic associations. This is in contrast to second and higher-order measures which are better predictors of paradigmatic associations, or word similarity. The distinction between syntagmatic and paradigmatic relationship types is neither exact nor mutually exclusive, and many paradigmatic relationships can be observed syntagmatically in the text. Roughly in keeping with (Rapp, 2002), we hereby regard paradigmatic assocations as those based largely on word similarity (i.e. including those typically classed as synonyms, antonyms, hypernyms, hyponyms etc), whereas syntagmatic associations are all those words which strongly invoke one another yet which cannot readily be said to be similar. Typically these will have an identifiable semantic or grammatical relationship (meronym/holonym: stem – flower, verb/object: eat – food etc), or may have harder-to-classify topical or idiomatic relationships (family – Christmas, rock – roll). We will show in Section 3.2 that syntagmatic re</context>
<context position="4743" citStr="Rapp (2002)" startWordPosition="705" endWordPosition="706">c relationships: i.e. through the observation of words which share similar sets of syntagmatic associations. Therefore improvements made at the level we are concerned with may reasonably be expected to carry through to applications which hinge on the identification of paradigmatic relationships. After a discussion of previous work in Section 2, we formulate the exact association measures and parameter settings which we compare in Section 3, where we also introduce the corpora and human association sets used. Then, by using evaluations similar to those described in (Baroni et al., 2008) and by Rapp (2002), we show that the best distance-based measures correlate better overall with human association scores than do the best window based configurations (see Section 4), and that they also serve as better predictors of the strongest human associations (see Section 5). 2 Related Work Measures based on co-ocurrence frequency. The standard way of estimating the syntagmatic association of word pairs in a corpus is to examine the frequency of their co-occurence, and then usually to compare this to some expected frequency. There are a host of measures which exist for this purpose. After raw co-occurrence</context>
<context position="6696" citStr="Rapp, 2002" startWordPosition="1021" endWordPosition="1022">ralised approach is therefore to consider a ”‘window”’ of w words, where w can be varied to suit the application. Unsurprisingly, it has been found that this is a parameter which can have a significant impact upon performance (Yarowsky and Florian, 2002; Lamjiri et al., 2004; Wang, 2005). While choosing an optimum window size for an application is often subject to trial and error, there are some generally recognized trade-offs between small versus large windows, such as the impact of data-sparseness, and the nature of the associations retrieved (Church and Hanks, 1989; Church and Hanks, 1991; Rapp, 2002) Measures based on distance between words in the text. The idea of using distance as an alternative to frequency for modelling language has been touched upon in recent literature (Savicki and Hlavacova, 2002; Terra and Clarke, 2004; Hardcastle, 2005). Washtell (2009) showed that it is possible to build distance-based analogues of existing syntagmatic association measures, by using the notions of mean and expected distance rather than of frequency. These measures have certain theoretical qualities - notably scale-independence and relative resilience to data-sparseness - which might be expected </context>
<context position="8291" citStr="Rapp, 2002" startWordPosition="1262" endWordPosition="1263">s. Several researchers (Lin, 1998; Curran, 2003; Pado and Lapata, 2007) have used word space models based on grammatical relationships for detecting and quantifying (mostly paradigmatic) word associations. In this paper, we will not use syntactic relation measures for two main reasons. Firstly these depend on the availability of parsers, which is not a given for many languages. Secondly, this may not be the most pertinent approach for predicting human free associations, in which certain observed relationsips can be hard to express in terms of syntactic relationships. 3 Methodology Similar to (Rapp, 2002; Baroni et al., 2008, among others), we use comparison to human assocation datasets as a test bed for the scores produced by computational association measures. An alternative might be to validate scores against those derived from a structured resource such as WordNet. 629 Table 1: Human association datasets Name Origin Cues Respondents Kent Kent &amp; Rosanoff (1910) 100 — 1000 Minnesota Russell &amp; Jenkins (1954) 100 — 1000 EAT Kiss et al (1973) 8400 100 Florida Nelson et al (1980) 5019 — 140 However, relatedness measures for WordNet are many and varied and are themselves the subject of evaluatio</context>
</contexts>
<marker>Rapp, 2002</marker>
<rawString>R. Rapp. 2002. The computation of word associations: comparing syntagmatic and paradigmatic approaches. In Proc of COLING 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D L Sackett</author>
</authors>
<title>Why randomized controlled trials fail but needn’t: 2. failure to employ physiological statistics, or the only formula a clinician-trialist is every likely to need (or understand).</title>
<date>2001</date>
<journal>Canadian Medical Association Journal,</journal>
<volume>165</volume>
<issue>9</issue>
<contexts>
<context position="15908" citStr="Sackett (2001)" startWordPosition="2520" endWordPosition="2521"> they do not define these variants. Here, we construct a one-tailed variant of LL by simply reversing the signs of the terms which respond to negative association. LL1tail = p(x, y) log p(x, y) p(x)p(y) − p(¯x, y) log p(¯x, y) + p(¯x,¯y) log p(¯x, ¯y) p(¯x)p(y) p(¯x)p(¯y) LL does not have a clear analogue amongst the distance-based measures (introduced in Section 3.4.2), whereas PMI for instance does. We therefore construct variants of PMI and other measures which take the amount of evidence into account in a way which can be directly reproduced in the distance domain. For this we borrow from Sackett (2001) who asserts that, all other things being equal, statistical significance is proportional to the square root of the sample size. There are a number of ways one might quantify sample size. We take a consistent approach across the various distance-based and frequency-based measures: we assume sample size to be equivalent to the lesser of the frequencies of the two words as this represents the total number of words available for pairing, with fewer observed pairs therefore being considered to constitute negative evidence. A/ min(p(x), p(y)) p(x, y) PMIsig = p(x)p(y) All of the above measures are </context>
</contexts>
<marker>Sackett, 2001</marker>
<rawString>D.L. Sackett. 2001. Why randomized controlled trials fail but needn’t: 2. failure to employ physiological statistics, or the only formula a clinician-trialist is every likely to need (or understand). Canadian Medical Association Journal, 165(9):1226–1237.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Savicki</author>
<author>J Hlavacova</author>
</authors>
<title>Measures of word commonness.</title>
<date>2002</date>
<journal>Journal of Quantitative Linguistcs,</journal>
<volume>9</volume>
<issue>3</issue>
<contexts>
<context position="1615" citStr="Savicki and Hlavacova, 2002" startWordPosition="235" endWordPosition="239">troduce some novel variations of window-based measures which perform as well as or better in the human association norm task than established measures. 1 Introduction Automatic discovery of semantically associated words has attracted a large amount of attention in the last decades and a host of computational association measures have been proposed to deal with this task (see Section 2). These measures traditionally rely on the co-ocurrence frequency of two words in a corpus to estimate a relatedness score. There has been a recent emergence of distancebased language modelling techiques in NLP (Savicki and Hlavacova, 2002; Terra and Clarke, 2004) in which the number of tokens separating words is the essential quantity. While some of this work has considered distance-based alternatives to conventional association measures (Hardcastle, 2005; Katja Markert School of Computing University of Leeds markert@comp.leeds.ac.uk Washtell, 2009), there has been no principled empirical evaluation of these measures as predictors of human association. We remedy this by conducting a thorough comparison of a wide variety of frequency-based and distance-based measures as predictors of human association scores as elicited in seve</context>
<context position="6903" citStr="Savicki and Hlavacova, 2002" startWordPosition="1053" endWordPosition="1056">ignificant impact upon performance (Yarowsky and Florian, 2002; Lamjiri et al., 2004; Wang, 2005). While choosing an optimum window size for an application is often subject to trial and error, there are some generally recognized trade-offs between small versus large windows, such as the impact of data-sparseness, and the nature of the associations retrieved (Church and Hanks, 1989; Church and Hanks, 1991; Rapp, 2002) Measures based on distance between words in the text. The idea of using distance as an alternative to frequency for modelling language has been touched upon in recent literature (Savicki and Hlavacova, 2002; Terra and Clarke, 2004; Hardcastle, 2005). Washtell (2009) showed that it is possible to build distance-based analogues of existing syntagmatic association measures, by using the notions of mean and expected distance rather than of frequency. These measures have certain theoretical qualities - notably scale-independence and relative resilience to data-sparseness - which might be expected to provide gains in tasks such as the reproduction of human association norms from corpus data. The specific measure introduced by Washtell, called Co-Dispersion, is based upon an established biogeographic d</context>
</contexts>
<marker>Savicki, Hlavacova, 2002</marker>
<rawString>P. Savicki and J. Hlavacova. 2002. Measures of word commonness. Journal of Quantitative Linguistcs, 9(3):215–231.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Terra</author>
<author>C Clarke</author>
</authors>
<title>Fast computation of lexical affinity models.</title>
<date>2004</date>
<booktitle>In Proc of COLING</booktitle>
<contexts>
<context position="1640" citStr="Terra and Clarke, 2004" startWordPosition="240" endWordPosition="243"> of window-based measures which perform as well as or better in the human association norm task than established measures. 1 Introduction Automatic discovery of semantically associated words has attracted a large amount of attention in the last decades and a host of computational association measures have been proposed to deal with this task (see Section 2). These measures traditionally rely on the co-ocurrence frequency of two words in a corpus to estimate a relatedness score. There has been a recent emergence of distancebased language modelling techiques in NLP (Savicki and Hlavacova, 2002; Terra and Clarke, 2004) in which the number of tokens separating words is the essential quantity. While some of this work has considered distance-based alternatives to conventional association measures (Hardcastle, 2005; Katja Markert School of Computing University of Leeds markert@comp.leeds.ac.uk Washtell, 2009), there has been no principled empirical evaluation of these measures as predictors of human association. We remedy this by conducting a thorough comparison of a wide variety of frequency-based and distance-based measures as predictors of human association scores as elicited in several different free word a</context>
<context position="6927" citStr="Terra and Clarke, 2004" startWordPosition="1057" endWordPosition="1060">mance (Yarowsky and Florian, 2002; Lamjiri et al., 2004; Wang, 2005). While choosing an optimum window size for an application is often subject to trial and error, there are some generally recognized trade-offs between small versus large windows, such as the impact of data-sparseness, and the nature of the associations retrieved (Church and Hanks, 1989; Church and Hanks, 1991; Rapp, 2002) Measures based on distance between words in the text. The idea of using distance as an alternative to frequency for modelling language has been touched upon in recent literature (Savicki and Hlavacova, 2002; Terra and Clarke, 2004; Hardcastle, 2005). Washtell (2009) showed that it is possible to build distance-based analogues of existing syntagmatic association measures, by using the notions of mean and expected distance rather than of frequency. These measures have certain theoretical qualities - notably scale-independence and relative resilience to data-sparseness - which might be expected to provide gains in tasks such as the reproduction of human association norms from corpus data. The specific measure introduced by Washtell, called Co-Dispersion, is based upon an established biogeographic dispersion measure (Clark</context>
</contexts>
<marker>Terra, Clarke, 2004</marker>
<rawString>E. Terra and C. Clarke. 2004. Fast computation of lexical affinity models. In Proc of COLING 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Renata Vieira</author>
<author>Massimo Poesio</author>
</authors>
<title>An empirically-based system for processing definite descriptions.</title>
<date>2000</date>
<journal>Computational Linguistics,</journal>
<volume>26</volume>
<issue>4</issue>
<contexts>
<context position="3670" citStr="Vieira and Poesio, 2000" startWordPosition="536" endWordPosition="540">se will have an identifiable semantic or grammatical relationship (meronym/holonym: stem – flower, verb/object: eat – food etc), or may have harder-to-classify topical or idiomatic relationships (family – Christmas, rock – roll). We will show in Section 3.2 that syntagmatic relations by themselves constitute a substantial 25-40% of the strongest human responses to cue words. Although the automatic detection of these assocations in text has received less attention than that of paradigmatic associations, they are nonetheless important in applications such as the resolution of bridging anaphora (Vieira and Poesio, 2000).1 Furthermore, first-order associations 1where for example resolving my house – the windows to the windows of my house can be aided by the knowledge that windows are often (syntagmatically) associated with houses. 628 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 628–637, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP are often the basis of higher-order vector wordspace models used for predicting paradigmatic relationships: i.e. through the observation of words which share similar sets of syntagmatic associations. Therefore improvements made a</context>
</contexts>
<marker>Vieira, Poesio, 2000</marker>
<rawString>Renata Vieira and Massimo Poesio. 2000. An empirically-based system for processing definite descriptions. Computational Linguistics, 26(4), December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Wang</author>
</authors>
<title>Robust Utilization of Context in Word Sense Disambiguation, chapter Modeling and Using Context,</title>
<date>2005</date>
<journal>Lecture Notes in Computer Science.</journal>
<pages>529--541</pages>
<publisher>Springer</publisher>
<contexts>
<context position="6373" citStr="Wang, 2005" startWordPosition="968" endWordPosition="969">ough review). All of these measures have in common that they require co-occurrence frequency to be specified, and therefore require some definition of a region within which to count co-occurrences. This region might be the entirety of a document at one extreme, or a bigram at the other. A versatile and hugely popular generalised approach is therefore to consider a ”‘window”’ of w words, where w can be varied to suit the application. Unsurprisingly, it has been found that this is a parameter which can have a significant impact upon performance (Yarowsky and Florian, 2002; Lamjiri et al., 2004; Wang, 2005). While choosing an optimum window size for an application is often subject to trial and error, there are some generally recognized trade-offs between small versus large windows, such as the impact of data-sparseness, and the nature of the associations retrieved (Church and Hanks, 1989; Church and Hanks, 1991; Rapp, 2002) Measures based on distance between words in the text. The idea of using distance as an alternative to frequency for modelling language has been touched upon in recent literature (Savicki and Hlavacova, 2002; Terra and Clarke, 2004; Hardcastle, 2005). Washtell (2009) showed th</context>
</contexts>
<marker>Wang, 2005</marker>
<rawString>X. Wang, 2005. Robust Utilization of Context in Word Sense Disambiguation, chapter Modeling and Using Context, pages 529–541. Springer Lecture Notes in Computer Science.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Washtell</author>
</authors>
<title>Co-dispersion: A windowless approach to lexical association.</title>
<date>2009</date>
<booktitle>In Proc. of EACL2009.</booktitle>
<contexts>
<context position="1932" citStr="Washtell, 2009" startWordPosition="281" endWordPosition="282">s have been proposed to deal with this task (see Section 2). These measures traditionally rely on the co-ocurrence frequency of two words in a corpus to estimate a relatedness score. There has been a recent emergence of distancebased language modelling techiques in NLP (Savicki and Hlavacova, 2002; Terra and Clarke, 2004) in which the number of tokens separating words is the essential quantity. While some of this work has considered distance-based alternatives to conventional association measures (Hardcastle, 2005; Katja Markert School of Computing University of Leeds markert@comp.leeds.ac.uk Washtell, 2009), there has been no principled empirical evaluation of these measures as predictors of human association. We remedy this by conducting a thorough comparison of a wide variety of frequency-based and distance-based measures as predictors of human association scores as elicited in several different free word association tasks. In this work we focus on first-order association measures as predictors of syntagmatic associations. This is in contrast to second and higher-order measures which are better predictors of paradigmatic associations, or word similarity. The distinction between syntagmatic and</context>
<context position="6963" citStr="Washtell (2009)" startWordPosition="1064" endWordPosition="1065">et al., 2004; Wang, 2005). While choosing an optimum window size for an application is often subject to trial and error, there are some generally recognized trade-offs between small versus large windows, such as the impact of data-sparseness, and the nature of the associations retrieved (Church and Hanks, 1989; Church and Hanks, 1991; Rapp, 2002) Measures based on distance between words in the text. The idea of using distance as an alternative to frequency for modelling language has been touched upon in recent literature (Savicki and Hlavacova, 2002; Terra and Clarke, 2004; Hardcastle, 2005). Washtell (2009) showed that it is possible to build distance-based analogues of existing syntagmatic association measures, by using the notions of mean and expected distance rather than of frequency. These measures have certain theoretical qualities - notably scale-independence and relative resilience to data-sparseness - which might be expected to provide gains in tasks such as the reproduction of human association norms from corpus data. The specific measure introduced by Washtell, called Co-Dispersion, is based upon an established biogeographic dispersion measure (Clark and Evans, 1954). We provide a thor</context>
<context position="17834" citStr="Washtell (2009)" startWordPosition="2842" endWordPosition="2843">on would be to divide CP by the frequency of the response word, however this merely results in PMI which is symmetric. By multiplying CP with PMI (and taking the root, to simplify) we obtain a measure which is asymmetric yet does not overtly favour frequent response words.3 We refer to this herein as Semi-Conditional Information (SCI). SCI = p(x, y) &amp;quot;/ p(x) p(y) We also explore variants of both CP and SCI with the additional significance correction presented for PMI,ig. These can be easily inferred from the formulae above. 3.4.2 Distance-based Measures Co-Dispersion (herein CD), introduced by Washtell (2009), is defined as the ratio of the mean observed distance to the expected distance, where the expected distance is derived from the frequency of the more frequent word type. Distance refers to the number of tokens separating an occurrence of one word and the nearest occurrence of another word. Pairs spanning an intervening occurrence of either word type or a document boundary are not considered. Note that here we specify only the generalised mean M, as we wish to keep the specific choice of mean as a parameter to be explored, where distxyi is ith observed distance between some occurrence of word</context>
<context position="26516" citStr="Washtell, 2009" startWordPosition="4301" endWordPosition="4302"> board for the much smaller 1 million word corpus. Here, the best distance-based measure statistically significantly outperforms the best windowbased one (with a significance level of p &lt; 0.0001) on one out of four datasets, while the differences are not great enough to be considered statistically significant on the other three datasets. There is therefore some evidence that the benefits observed with the larger corpus hold in the presence of limited data, which is in support of the general theory that distance-based methods capture more information from the corpus at the co-occurrence level (Washtell, 2009). It remains clear, however, that no method is presently a substitute for using a larger corpus. In terms of optimum configurations, we find that for the frequency-based approach with the larger corpus, a window size of around +/-10 to +/-50 words more or less consistently produces the best results, irrespective of association the measure. Interestingly on the small corpus the tendency appears to be towards a somewhat larger window size than with the larger corpus. This may be related to the larger windows’ increased resilience to data-sparseness. Somewhat surprisingly, we also see that our as</context>
</contexts>
<marker>Washtell, 2009</marker>
<rawString>J. Washtell. 2009. Co-dispersion: A windowless approach to lexical association. In Proc. of EACL2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Wettler</author>
<author>R Rapp</author>
</authors>
<title>Computation of word associations based on the co-ocurrences of words in large corpora.</title>
<date>1993</date>
<booktitle>In Proc. of the First Workshop on Very Large Corpora.</booktitle>
<contexts>
<context position="20196" citStr="Wettler &amp; Rapp (1993)" startWordPosition="3236" endWordPosition="3239">). 1/ max(p(x), p(y)) (1) M(distx,1 ... distx,n ) In addition to these measures, we also explore significance-corrected forms NWCD,ig and CWCD,ig, by introducing the same sample size term employed by PMI,ig, CP,ig and SCI,ig. Again, these can readily be inferred from the existing formulae in the above two sections. n NWCD = min(p(x), p(y)) n CWCD = p(x) M(distx,l ... distx,n) 1/ max(p(x), p(y)) CD = 3.5 Co-occurrence Parameters that of direction in the text. While the two may correlate, one can find ample counter-examples: jerky triggers beef more strongly than beef triggers jerky. 3Note that Wettler &amp; Rapp (1993) introduced a more general asymmetric measure for predicting human associations, by employing an exponent parameter to p(y). Our formulisation is equivalent to their measure with an exponent of 0.5, whereas they found an exponent of 0.66 to be most effective in their empirical study. Exponents of 0 and 1 result in CP and PMI respectively. For frequency-based co-occurrence statistics, the principle parameter is the window size. We will use five window sizes separated by a constant scaling factor, chosen so as to span those most commonly encountered in the literature, with some extension towards</context>
</contexts>
<marker>Wettler, Rapp, 1993</marker>
<rawString>M. Wettler and R. Rapp. 1993. Computation of word associations based on the co-ocurrences of words in large corpora. In Proc. of the First Workshop on Very Large Corpora.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K White</author>
<author>L Abrams</author>
</authors>
<title>Free associations and dominance ratings of homophones for young and older adults.</title>
<date>2004</date>
<journal>Behaviour Research Methods, Instruments and Computers,</journal>
<pages>36--408</pages>
<contexts>
<context position="10794" citStr="White and Abrams, 2004" startWordPosition="1678" endWordPosition="1681">r who were presented with the cue word. In Table 1, respondents refers to the number of people from whom a response was solicited for each cue word in a study (this is not to be confused with the number of unique responses). Of these four datasets, one (Kent &amp; Rosanoff) appears not to have been previously used in any peer-reviewed study of corpus-derived lexical association. It is worth noting that some of these datasets are quite dated, which might affect correlations with corpus-derived scores, as culture and contemporary language have a fundamental impact upon the associations humans form (White and Abrams, 2004). 3.2 Frequency of Syntagmatic Associations To verify that strong human associations do include a large number of syntagmatic associations, we manually annotated all pairs consisting of a cue and its strongest human response in the Minnesota and Kent datasets as expressing either a syntagmatic or a paradigmatic relationship. The overall set to be annotated consisted of 200 pairs. Annotators were given short (half-page) guidelines on syntagmatic and paradigmatic assocations, stating that very similar items (including hyponyms/hypernyms) as well as antonyms were to be judged as paradigmatic wher</context>
</contexts>
<marker>White, Abrams, 2004</marker>
<rawString>K. White and L. Abrams. 2004. Free associations and dominance ratings of homophones for young and older adults. Behaviour Research Methods, Instruments and Computers, 36:408–420.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Yarowsky</author>
<author>R Florian</author>
</authors>
<title>Evaluating sense disambiguation across diverse parameter spaces.</title>
<date>2002</date>
<journal>Natural Language Engineering,</journal>
<volume>8</volume>
<issue>4</issue>
<contexts>
<context position="6338" citStr="Yarowsky and Florian, 2002" startWordPosition="960" endWordPosition="963">red and LogLikelihood (see Evert (2005) for a thorough review). All of these measures have in common that they require co-occurrence frequency to be specified, and therefore require some definition of a region within which to count co-occurrences. This region might be the entirety of a document at one extreme, or a bigram at the other. A versatile and hugely popular generalised approach is therefore to consider a ”‘window”’ of w words, where w can be varied to suit the application. Unsurprisingly, it has been found that this is a parameter which can have a significant impact upon performance (Yarowsky and Florian, 2002; Lamjiri et al., 2004; Wang, 2005). While choosing an optimum window size for an application is often subject to trial and error, there are some generally recognized trade-offs between small versus large windows, such as the impact of data-sparseness, and the nature of the associations retrieved (Church and Hanks, 1989; Church and Hanks, 1991; Rapp, 2002) Measures based on distance between words in the text. The idea of using distance as an alternative to frequency for modelling language has been touched upon in recent literature (Savicki and Hlavacova, 2002; Terra and Clarke, 2004; Hardcastl</context>
</contexts>
<marker>Yarowsky, Florian, 2002</marker>
<rawString>D. Yarowsky and R Florian. 2002. Evaluating sense disambiguation across diverse parameter spaces. Natural Language Engineering, 8(4):293–310.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>