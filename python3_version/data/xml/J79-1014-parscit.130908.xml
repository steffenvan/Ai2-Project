<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<affiliation confidence="0.543078">
Journal of Computational Linguistics Microfiche 14 : 1
</affiliation>
<sectionHeader confidence="0.711176" genericHeader="method">
I. FINITE STRING
TTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
</sectionHeader>
<equation confidence="0.185507">
11 - NUMBER 4 DECEMBER 1974
</equation>
<bodyText confidence="0.579205666666667">
plgAs issue was released for production-on March 28,
P0/75% It cohtains abstracts Df preprints and pub-
Eicatiohs availahie to the editors on March 20.
</bodyText>
<sectionHeader confidence="0.791526" genericHeader="method">
NOTICE TO AUTHORS
</sectionHeader>
<bodyText confidence="0.988919083333333">
wscietcer those who read also publish. The help
gg the reader-becoNe-author makes announcement
njournals more helpful,
On preparing drafts for semipublic circu-
lation: send a copy to the editorial
office to be abstracted.
On receiving notice of acceptance fot pub-
lication in a book or journal: tinfgrm
the editor, giving full citation (as much
as known)
th the collaberation of the readers, The Finite
inljng will provide much more timely information.
</bodyText>
<page confidence="0.697618">
2
</page>
<figure confidence="0.718303645833333">
NAME INDEX . la •• 4.• •a 74
NAME INDEX . la •• 4.• •a 74
• . . . ......... , 3
Current trends in linguistics 12: adjacent arts &amp; sciences
Information Processing 74: proceedings of IFIP Congress . 8
Prague Bulletin of Mathematical Linguistics 21 10
Phonetics . , . . le • 41••• . • 4 4 •••••• 12
Speech recognition ... s .... . . . . • ..... • . 15
Grammar 30
Word order and word order change . . . • • 30
A system for automatic inflectional analysis (Russian) . 31
Parsers . , . . • • . . . ••• . 35
Semantics . . . • 00 • • • 36
Lexical semantics: synonymic means of language . . . 36
Discourse . . . • OOOOOOOOOO . . • , • • . . . 40
Comprehension • • • . • • . . 41
Expression. . . . . . . . . . . a a a ....... . a • . 47
Information structures . . . OOOOOOOOOOOO • . . . 48
Inference . . ..
. • • . . . . • • . OOOOOOOO • 4 40 49
Dialectology . . • e • • • • a • ••••••••• . 50
Acquisition . . i 1
a • • • • ....... e • a • 51.
In..• ........... • .„...,• . . J2
Computers, programming, anu natural languages
Literature . . • . . . ....... . . 67,
Computers in the Rumanities: Proceedings ICC!-! I 67
Assocaation for Literary and Linguistic Computing Bulletin 70
Mathematics . . . . . . .......... • • ... 73
General 3
CURRENT TRENDS IN LINGUISTICS
ThomasJk. Sebeok, Editor
Research Center for the Language Sciences
Indiana University
VOLUME 12: LINGUISTICS AND ADJACENT ARTS AND SCIENCES
Associate Editors:
Arthur S. Abramson, Dell Hymes, Herbert Rubenstein
Edward Stankiewicz
Assistant Editor:
Bernard Spolsky
Assistants to the Editor:
Alexandra Di Luglio
Lucia Hadd Zoercher
MOUTON
The Hague • Paris
1974
CONTENTS
Editor&apos;s Introduction V
</figure>
<note confidence="0.7199276">
Master List of Abbreviations 1, • XIII
PART ONE: LINGUISTICS AND PHILOSOPHY
Linguistics and Philosophy, by J. M. E. Maravcsik 3
On Logic and Theoretical Linguistics, by Yehoshua
Bar-Hillell Jonathan Malinp, Avishai Margalit . . . . . . 37
Linguistics and Semantics, by Euaenio Coseriu and
A
VOLUME 12: LINGUISTICS AND ADJACENT ARTS AND SCIENCES (CONTID1)
Paralinguistics, by David Crystal . . . 00090001 265
Facial Expression and BOdy Movement/ by Harvey B. Sarles . 297
</note>
<table confidence="0.212791375">
Proxemics, by 0: Michael Watson , . 4,004040•0$ 311
Classification and Description of Sign Languages,
by William C. Stokoe, Jr. . ........... . •. 345
Writing and Writing Systems, by George L. Trager . . . , 373
Speech Surrogates: Drum and Whistle Systems,
by Donna Jean Umiker .•...•.. . . 497
Formalized Languages: Scientific,
by Sanda Golopentia-Eretescu „ ....is... . . 537
</table>
<note confidence="0.819827333333333">
Zoosemiotics: Ethology and the Theory of Signs
by W. John Smith $0010410,00••••••• 561
PART THREE: LINGUISTICS AND THE VSRBAL ARTS
</note>
<bodyText confidence="0.3213885">
Structural Poetics and Linguistics, by Edward Stankiewicz. 629
Linguistics and Folkloristics, by William O. Hendricks . 661
</bodyText>
<listItem confidence="0.8053775">
Folk Poetry: General Problems, by V. N. Toporov . 683
Folk Poetry: History and Typology, by K. Horalek . , 741
</listItem>
<bodyText confidence="0.469806571428571">
Folk Narrative, by Dorothy Clement and Benjamin N. Colby 809
Growth of the .Theoretical Framework of Modern Poetics,
by Vyacheslav V. Ivanov. .... • 835
Theoretical Poetics in the Twentieth Century,
by F. Svejkovsky . 0••••••••••••••• • 863
Rhetoric and Stylistics, by P. Guiraud 0•04 943
Literary Genres, by Tzvetan Todorov *044 • 957
</bodyText>
<note confidence="0.8199945">
Metrics, by John Lotz 963
PART FOUR: SPECIAL LANGUAGES
</note>
<title confidence="0.278011">
New Formal Devices for Linguistics, by Maurice Gross . . 985
</title>
<note confidence="0.742073">
5
VOLUME 12: LINGUISTICS AND ADJACENT ARTS AND SCIENCES (CONT&apos;DI)
</note>
<author confidence="0.252208">
PART SIX: LINGUISTICS AND PSYCHOLOGY
</author>
<affiliation confidence="0.4232445">
Psycholinguistics: An Overview, by Herbert Rubenstein, . 1071
An Historical View of Psycholinguistics,
by Arthur L. Blumenthal ... . 1105
Some Aspects of Language Acquisition, by Ursula Bellugi 1136
The Interaction of Perception and Linguistic Structures:
A Preliminary Investigation of Neo-Functionalism,
</affiliation>
<note confidence="0.7272415">
by T. G. Bever 1159
Syntactic Factors in Memory, by Samuel Fillenbaum • . 1235
Semantics and Comprehension, by Herbert H. Clark . • 1291
Social Perception of Speech, by Moshe Anisfeld 1429
PART SEVEN: ANTHROPOLOGY AND SOCIOLOGY
Anthropology and Sociology: An Overview, by Dell Hymes • • 1445
Some New Developments in Ethnosemantics and the Theory
and Practice of Lexical/Semantic Fields, by Oswald Werner,
with William Hagedorn, George Roth, Emile Schepers, and
Luis UYiarte. •
. •. 1477
Social Class, Language, and Socialisation, by Basil
</note>
<author confidence="0.550587">
B. Bernstein .. . . . . . . 1545
</author>
<note confidence="0.847841">
Ethnomethodology, by Aaron V. Cicourel . 1563
Sociolinguistics, by J. B. Pride 1607
The Sociology of Language: An Interdisciplinary Social
Science Approach to Language in Society,
by Joshua A. Fishman 1629
PART EIGHT: LINGUISTICS AND ECONOMICS
Linguistics and Economics, by Ferruccio Rossi-Landi • 1787
PART NINE: LINGUISTICS AND EDUCATION
</note>
<page confidence="0.490192">
6
</page>
<note confidence="0.6153146">
VOLUME 12: LINGUISTICS AND ADJACENT ARTS AND SCIENCES (CONT D)
Linguistics and the Language Arts in Elementary
and Secondary Education, by Rudolph C. Troike 2117
Linguistics and Second Language Pedagogy, by E. Glyn Lewis 2131
PART TEN PHONETICS
</note>
<title confidence="0.553514416666667">
Phonetics: An Overview, by Arthur S. Abramson • . . . . • 2187
Phonetics in the Twentieth Century, by D. B. Fry • • * • 2201
Speech Acoustics, by John M. Heinz . . 2241
Physiological Aspects of Articulatory Behavior,
by Katherine S. Harris • • ...... • ....... • 2281
Laryngeal Research in Experimental Phonetics,
by Masayuki Sawashima . . . . . • . . ....... . 2303
The Perception of Speech, by Michael Studdert-Kennedy . . 2349
On Time and Timing in Speech, by Leigh Lisker . . , . . 2387
A Study of Prosodic Features, by Philip Lieberman . • . 2419
Speech Synthesis for Phonetic and Phonological Models,
by Ignatius G. Mattingly 2451
</title>
<author confidence="0.555255333333333">
Phonetic Fieldwork, by J. C. Catford • . 2489
Cross-Language Phonetics, by Andre Malecot• 2507
PART ELEVEN: BIO-MEDICAL APPLICATIONS
</author>
<affiliation confidence="0.744657333333333">
Language in a Biological Frame, by J. Bronowski . 2539
Basic Problems of Neurolinguistics, by A. R. Luria 2561
Language Behavior and Disorders Associated wi,th Brain
</affiliation>
<note confidence="0.5487895">
Damage, by Orlando L. Taylor and Joseph P. Fox . . . . 2595
Speech Pathology, by Eugene T. McDonald . . . 2641
Language and Psychiatry, by Harley C. Shands . . . • 2657
PART TWELVE: COMPUTER APPLICATIONS
</note>
<page confidence="0.831045">
7
</page>
<note confidence="0.9745385">
VOLUME 12: LINGUISTICS AND ADJACENT ARTS AND SCIENCES (CONT 0)
PART THIRTEEN: LINGUISTICS AS A PILOT SCIENCE
</note>
<title confidence="0.8311125">
Linguistics as a Pilot Science, by Solomon Marcus . . . 2871
Specialty Trends in the Language Sciences,
</title>
<author confidence="0.598810666666667">
by Paul L. Garvin ... • • • • • • • 2889
Biographical Notes .• • • . . • . . 2911
Indexes . . . . • 600 •60. 0 • • • . 2931
</author>
<affiliation confidence="0.822261333333333">
Index of Topics
Index of Names
Index of Languages
</affiliation>
<figure confidence="0.59832396">
General 8
INFORMATION PROCESSING 74
PROCEEDINGS OF IFIP CONGRESS 74
Stockholm, August 5-10, 1974
Jack L. Rosenfeld, Editor
Computer Sciences Department
IBM Thomas Jp Watson Research Center
North-Holland Publishing Company
Amsterdam &amp; New York
1974
PARTIAL CONTENTS
Data communications and public networks. G. C. Allery
Composing music and generating sound by computer. P. Barbaud
Social implivalions of computer technology. H. Borko
A programming methodology for operating system design. P. Brinch
Hansen
Recent investigations in relational data base systems. E. Codd
Real-time computer animation. C A. Csuri
Cost and benefits of information systems. J. C. Emery
Extensible languages. B. A. Caller
Computer experience with selected secondary and primary school
children. D. S. Henderson
The impact of LSI technology on computer systems. G. B. Herzog
Complexity of computer computations. J. Hoperoft
Resource allocation in computer systems and computer-communication
networks. L. Xleinrock
Information systems. B. Langefors
9
INFORMATION PROCESSING 74.
PARTIAL CONTENTS
Current and futuretrends in data base management systems. T. W. 011e
Two-level grammars in action. J. E. L. Peck
Alphabetic and numeric data processing: a view from the humanities.
J. Raben
Theoretical impediments to artificial intelligence. M. Q. Rabin
Systems programming as an emerging discipline. G. Seegmtiller
Multiplexing problems in computer communications. J. Seidler
Software implementation studies: problems and prospects.
M. R. Shura-Bura
On the design of programming languages. N. Wirth
General
THE PRAGUE BULLETIN OF
MATHEMATICAL LINGUISTICS
21
TABLE OF CONTENTS
Language types in classic and new typology.
Die Sprachtypen in der klassischen und der neuren Typologie
P. Sgall . OOOOOOOOO . . • . • • • .
On one type of dependency grammars
A. Goralcikova • • • • • • OOOOOOOO . • . . . 11
</figure>
<bodyText confidence="0.985437047619048">
Gaifman showed that in a certain theory of dependency
the number of dependents at a node could not exceed
an integer fixed for each grammar. Fitialov suggested
oriented grammars, rewrite grammars with a governor
marked in each rule; obviously such a grammar does not
suffer Gaifman&apos;s limitation. A specially ordered
grammar divides rules in which the symbol on the left
occurs in the string on the right into recursive rules,
which can be applied to their own output, and pseudo-
recursive rules which cannot. SO grammars are weakly
equivalent to CF grammars.
Questions of graphs and automata in a generative
description of language. - M. Platek . . . . 27
Z-grammar derives a dependency tree from a start
symbol by rules of six types: (1) replace a node
with a governor and one dependent; (2) change the
label at a node; (3) replace the labels of a gover-
nor and one dependent simultaneously; (4) change
the label of a terminal node; (5) change the label
at the origin; (6) move a dependent across its gov-
ernor from left-to-right or from right-to-left.
</bodyText>
<figure confidence="0.730366888888889">
• 10 3
11
Genera
LANGUAGES AMONG COMPUTERS, MACHINES/ ANIMALS AND MEN
Lawrence M. Clark
Computers and People, 24, 1, January 1975, 7-1,3
Reports on a number of aspects of language, discusses some
significant problems of designation of meaning, and indicates
some probable future developments in language. Computers make
extensive use of language to fulfill their functions. To place
computer languages in the perspective of languages in general is
helpful.
DECODING METHODOLOGY AS A TOOL FOR LINGUISTIC RESEARCH
Methode de dechiffrage, outi1 de recherche en .VingOistique
B. V. Suhotin
Russian Language Institute
Moscow
T. A. Informations, 1974, 2, 3-43
</figure>
<bodyText confidence="0.986842">
These methods of analysis are among those that will work for
any language without prior knowledge other than what is gained
from linguistically prior analyses. The examples presented are
algorithms for (1) classification of letters into vowels and
consonants, (2) morpheme classification, (3) determining the
structure of simple phrases, (4) phonetically transcribing
syllabic letters, (5) determining the pronunciation of letters.
</bodyText>
<equation confidence="0.324765">
12
Phonetics
COMPARISON OF THE FORMANT SPACES OF RETROFLEXED AND
NON-RETROFLEXED VOWELS,
Iris Kameny
IEEE Transactions on Acoustics, Speech and Signal Processing
ASSP-23, 1975, 18-49
</equation>
<bodyText confidence="0.99500975">
The formant 1 (FI) and formant 2 (F2) trequency movements
of vowels next to /r/ are compared with the same vowels next to
other consonants. With the exception of /i/ the effect of initial
/r/ on the following syllable nuclei is minimal. The effect of
final In on the gyllable nuclei preceding it is appreciable.
Algorithms are postulated to define a retroflexed vowel space
for vowels preceding /r/ in terms of the non-retroflexed vowel
space.
</bodyText>
<author confidence="0.165185">
THE HUMAN VOCAL CORDS: A MATHEMATICAL MODEL
</author>
<affiliation confidence="0.645321">
Ingo R. Titze
Dept. of Physics &amp; Astronomy
Brigham Young University
Provo, Utah
</affiliation>
<subsubsectionHeader confidence="0.40083">
Phonetica 28, 129-170, 1973
</subsubsectionHeader>
<bodyText confidence="0.999911846153846">
A mathematical model for digital computer simulation of
human-like utterances is developed. The overall system consists
of a period structure of 16 coupled masses for each of the vocal
cords, an 18-section cylindrical tube approximation of the
pharynx and mouth. and a similar 12-section nasal tract. Special
care has been taken to model separately the functions of the
vocal ligament the vacalic muscle, and the mucosa. Simulated
phonation in modal, mixed and falsetto registers is possible.
The parameters which control the nature of the phonation are lung
pressure, external tension applied to ligament, vocalic, and
mucosa, and the internal muscuLar action of the vocalis. Ap-
plications are cited in areas which include physiology, pathology
and pedagogy.
</bodyText>
<equation confidence="0.478777428571429">
13
Phonetics
MRROW PHONETIC TRANSCRIPTION ON THE COMPUTER: TAKING THE PHONE
OFF THE HOOK
Gerald C. Keil
Leeds University
England
</equation>
<subsubsectionHeader confidence="0.411187">
Computers and the Humanities 8, 4, 217-229
</subsubsectionHeader>
<bodyText confidence="0.768703625">
The IMPAC project of the Survey of English Dialects has
developed a system for the machine representation of narrowly
transcribed phonetic data. The external machine representation
seeks to maintain some proximity to the IPA system and to have
the minimum number of symbols used to represent each phone.
The internal code can be considered as a matrix in which members
of each row or column share a common property. An internal pro-
perty table expresses the characteristics of each phone.
</bodyText>
<sectionHeader confidence="0.9909455" genericHeader="method">
COMPUTER CONTROLLED RADIOGRAPHY FOR OBSERVATION OF MOVEMDITS OF
ARTICULATORY AND OTHER HUMAN ORGANS
</sectionHeader>
<author confidence="0.212762">
0. Fujimura, S. Kiritani and H. Ishida
</author>
<affiliation confidence="0.887004333333333">
Research Ihstitute of Logopedics and Phoniatrics,
Faculty of Medicine
University of Tokyo
</affiliation>
<subsubsectionHeader confidence="0.444255">
Computers in Biology and Medicine, 3, 371-384, 1973
</subsubsectionHeader>
<bodyText confidence="0.974833222222222">
On-line computer control of a flying spot X-ray microbeam
generator is proposed for substantial reduction of radiation dose
and automatic processing of radiographic data. A small X-ray
microbeam generator was used in a pilot study. Preliminary ex-
periments have demonstrated its applicability in studies of ar-
ticulatory gestures and cerebral blood flow measurements. Moni-
toring of the position of a fiberscope in the pharynx during
speech utterances has been tested in real time succpsfully With
use of an integrated dose of approximately 16 mR cm&apos;/min at an
</bodyText>
<equation confidence="0.3145865">
14
Phonology
</equation>
<sectionHeader confidence="0.598267" genericHeader="method">
COMPUTER EXPLORATION OF FAST-SPEECH RULES
</sectionHeader>
<subsectionHeader confidence="0.51616225">
Joyce Friedman
Department of Computer and Communication Sciences
University of Michigan
Ann Arbor
</subsectionHeader>
<bodyText confidence="0.868353285714286">
IEEE Transactions on Acoustics, Speech, and Signal Processin.;,
ASSP-23, February 1975, 100-103
A set of fast-speech rules has been tested on the computer
using the phonological grammar tester (PM) program of Friedman
apd Morin. We examine the types of difficulties encountered in
the rules and discuss ways in which the program can be made more
useful for studying fast-speech rules.
</bodyText>
<table confidence="0.864353375">
15
Speech recognition
SYSTEM FOR ACOUSTIC-PHONETIC ANALYSIS OF CONTINUOUS SPEECH
Clifford J. Weinstein and Victor W. ale
$tephanie S. McCandles Department of Electrical
Lee F. Mondshein Engineering
MIT Lincoln Laboratory M.I.T
Lexington, Mass Cambridge, Mass
</table>
<tableCaption confidence="0.4321415">
IEEE Transactions on Acoustics, Speech, and Signal Processing
ASSP-23, Februaru 1975, 54-67
</tableCaption>
<bodyText confidence="0.737752307692308">
Spectrum analysis via linear piediction, computation of
parameters of the spectrum and fundamental frequency extraction.
Preliminary Segmentation and classification yields categories of
vowel.; volume dip within vowel; fricative; stop The decision
tree is based on energy measurements in selected frequency bands,
derivatives and ratios of these measurements, a voicing detector,
and a few editing rules. More detailed classifiCation of diph-
thongs, semivowels, and nasals; detected vowel segment to stored
formant positions in a speaker-noLmalized vowel table; a fricative
identifier, which employs measurement of relative spectral energies
in sevetal bands to group the fricative segments into phoneme-
like categories; stop consonant classification based on the pro-
perties of the plo-sive burst.
</bodyText>
<sectionHeader confidence="0.3085335" genericHeader="method">
MULTIDIMENSIONAL ANALYSIS OF THE PERCEPTUAL UNIQUENESS
OF 31 ENGLISH CONSONANTAL CLUSTERS
</sectionHeader>
<subsectionHeader confidence="0.110958">
John.W. Black, Sadanand Singh and Elizabeth Janocosek
Department of Speech Communication
Ohio State University, Columbus
</subsectionHeader>
<bodyText confidence="0.950390533333333">
Report No. TR-16, March 1974. A13-776 649/6GA
Acoustic recordings were made of 31 &apos;doublet&apos; consonant-
clusters with five vowels by 12 speakers. The pairs of syllables
were heard by twelve listeners who assigned values to the aural
differences between each pair in the manner of magnitude estima-
tion&apos;. The clusters were treated as two groups, 18 non-sibilant
clusters end La albilant clusters. The responses of each listener
became the data for multidimensional analysis. Four-dimensional
space provided the most efficient analysis for both sets of data.
The interpretations of these dimensions were in terms of the fea-
tures either of the first or of the second member of the consonant
clusters. In the instance of the non-sibilant clusters on dimen-
sion one the perceptual feature was determined by the groupings of
the second members, on dimensions two and three by the first mem-
bers.
</bodyText>
<figure confidence="0.837140833333333">
16
Speech Recognition
FERCEPTUAL CONTINUOUS SPEECH RECOGNITION
H. Yilmaz, L Ferber, W. Park, H. Kellett, ahd E. Koprucu
Perception Technology Corporation
Winchester Mass
</figure>
<figureCaption confidence="0.42422">
Report No. RADC-TR-74-180, July 1974
</figureCaption>
<bodyText confidence="0.999393375">
The objective is to study and investigate the recognition
of connected speech composed of a context-free limited vocabulary
A new method of segmentation is based on the recognition of
vowels and vowel-like phonetic segments. This is coupled with
a speaker transformation that maps the vowels of each speaker
into a standard space thus reducing inter-speaker vaxiations. A
method of extending these principles to the recognition of con-
sonants is presented. [AD-783 899/8GA; PC $3.75, MF $2.251
</bodyText>
<figure confidence="0.6168455">
THE OPTIMUM COMB METHOD OF PITCH PERIOD ANALYSIS OF CONTINUOUS
DIGITIZED SPEECH
James A. Moorer
Department of computer Science
Stanford University
Stanford, California
</figure>
<figureCaption confidence="0.3602985">
IEEE Transactions on Acoustics, Speech,. and Signal Processing,
ASSI&amp;quot;,22, 5, October 1974, 330-336
</figureCaption>
<bodyText confidence="0.9999824">
The method is shown to be of similar accuracy as the
Cepstrum technique. Sinca the method involves only additions,
no multiplicatiohl it is shown to be faster than the SIFT
algorithm. The basis of the method is searching for a minimum
in the magnitude of the difference between a speech segment and
a delayed speech segment. This is shown to be equivalent to
selecting the comb filter which best annihilates the input sig-
nal. The computational complexity of the Cepstrum technique
thus is proportional to N *log N where N is the number of points
in the window in question.
</bodyText>
<figure confidence="0.719553111111111">
17
Speech recopition
WHERE THE PHONEMES ARE: DEALING WITH AMBIGUITY IN ACOUSTIC-
PHONETIC RECOGNITION
Richard Schwartz and John Makhoul
Bolt Beranek and Newman Inc.
Cambridge, Mass
IEEE Transacfions of Acoustics, Speech, and Signal Processing
ASSP-23, 1975, 50-53
</figure>
<bodyText confidence="0.770243428571429">
Errors in acoustic phonetic recognition occur not only
because of the limited scope of the recognition algorithm, but
also because certain ambiguities are inherent in analyzing the
speech signal. Examples of such ambiguities in segmentation
and feature extraction are given. A lattice representation of
the segmentation allows for multiple choices that can be sorted
out by higher level processes.
</bodyText>
<sectionHeader confidence="0.874893" genericHeader="method">
INVERSE FILTER FOR SPEAKER IDENTIFICATION
</sectionHeader>
<subsectionHeader confidence="0.708734666666667">
Larry L. Pfeifer
Speech Communications Research Lab Inc.
Santa Barbara, California
</subsectionHeader>
<bodyText confidence="0.940997">
Report No RADC-TR-74-214, August 1974
The objective is to determine if a sample can be associated
with reference talkers. The method of comparing feature vectors
from individual sound elements was chosen for experiments using
the inverse filter analysis technique (the autocorrelation method
of linear prediction). Ten male talkers supplied speech samples
bandlimited to 3250 Hz. Thirteen sound units, 10 vowels and 3
nasals, were studied. Many additional identification tests were
performed for the purpose of evaluating different distance functions
and different feature vectors. [AD-787 860/6GA; PC $5.25, MF $2251
</bodyText>
<page confidence="0.454578">
18
</page>
<table confidence="0.9230525">
Speech recognition
THE ROLE OF PHONOLOGICAL RULES IN SPEECH UNDERSTANDING RESEARCH
Beatrice T. Oshika Victor W. Zue Rollin V. Weeks
Joseph Aurbach M.I.T, Linco System Development
Helene Neu Laboratory Corporation
Speech Communications Lexington, Mass Santa Monica, Cal.
Research Laboratory
Santa Barbara, Cal.
</table>
<tableCaption confidence="0.5038015">
IEEE Transactions on Acoustics, Speech, and Signal Processzng
ASSP-23, February 1975, 104-112
</tableCaption>
<bodyText confidence="0.939202285714286">
This paper presents some phonological rules which describe
systematic pronunciation variation occurring in natural continuous
speech. It is argued that a speech understanding system must
account for such variation by incorporating phonological rules,
either implicitly or explicitly, into the system. Spectrographic
evidence for the phonological phenomena described by the rules is
included.
</bodyText>
<sectionHeader confidence="0.519359" genericHeader="method">
RESEARCH ON SPEECH COMMUNICATION AND AUTOMATIC SPEECH RECOGNITION
</sectionHeader>
<subsectionHeader confidence="0.273236">
David J. Broad
Speech Communications Research Laboratory
Santa Barbara, California
</subsectionHeader>
<bodyText confidence="0.939047909090909">
Report No. AFOSR-TR-74-05132, Febrtlary 2974
Theory of phonology: a theory of symbolization, a large
computer-based quasi-phonemic/orthographic dictionary of American
English, dialect description, and the formalization of a functional
phonemic theory. Logical procedures for the interpretation of
acoustic phonetic data: a massive investigation of formant frequency
transitions in CVC syllables as well as an analysis of the segment
durations in the same syllables: the use of formant frequency infor-
mation in automatic speech recognition; segmentation using formant
dynamics and the sources of formant frequency variability; the re-
lations between applied basic problems in speech and language.
</bodyText>
<figure confidence="0.9167285">
19
Speech recognition
SYLLABLE AS A UNIT OF SPEECH RECOGNITION.
Osamu fujimura
Bell Laboratories
Murray Hill, N.J.
IEEE Transactions on Acoustics, Speech, and Signal Processing
ASSP-23, February 1975, 82 87
</figure>
<bodyText confidence="0.998277625">
Basic problems involved in automatic recognition of contin-
uous speech are discussed with reference to the recently developed
template matching technique using dynamic programming. Irregular-
ities in phonetic manifestations of phonemes are discussed and it
is argued that the syllable, phonologically redefined, will serve
as the effective minimal unit in the time domain. English syllable
structures are discussed from this point of view using the notions
of &amp;quot;syllable features&amp;quot; and &amp;quot;vowel affinity&amp;quot;.
</bodyText>
<sectionHeader confidence="0.992278" genericHeader="method">
A DESCRIPTION OF A PARAMETRICALLY CONTROLLED
MODULAR STRUCTURE FOR SPEECH PROCESSING
</sectionHeader>
<bodyText confidence="0.798732882352941">
N. Rex Dixon and Harvey F. Silverman
Computer, Sciences -Department
IBM Thomas J. Watson Research Center
Yorktown Heights, N.Y.
IEEE Transactions on Acoustics, Speech, and Signal Processing
ASSP-23, February 1975, 87-91
The modular acoustic processor (MAP) has been designed for
speech recognition. The parametrically controlled (spectral)
analyzer (PCA), serves as input to an hierarchically operated string
transcriber (HOST). PCA allows parametric selection of several
analysis methods, including discrete Fourier transform, linear
predictive coding, and chirp z-transform (CZT), and 9f smoothing,
normalization, interpolatiOn, and Fo estimation methods. PCA devel-
ops spectrographic representations and performs spectral-similarity
matching and training. HOST does segmentation, classification, and
prosody analysis. PCA is a packaged, debugged, running system. A
first version of-HOST is operational.
</bodyText>
<figure confidence="0.8850347">
20
Speech recognition
REAL-TIME LINEAR-PREDICTIVE CODING or SPEECH
ON THE SPS-41 TRIPLE-MICROPROCESSOR MACHINE
Michal J. Knudsen
Computer Science Department
Carnegie-Mellon University
Pittsburgh, PA
IEEE Transactions on Acoustics, Speech, and Signal Processing
ASSP-23, February 1975, 140-145
</figure>
<bodyText confidence="0.999567454545454">
SPS-41, a commercially available system, is composed of
three dissimilar micro-processors working in parallel. Using
user-written microcode, one processor performs I/O and master
control, the second handles loop indexing and counting, and the
third does the actual arithmetic on data. Such parallelism allows
2 x 106 I/O operations and 4 x 106 multiplications/s, but actually
realizing this potential requires fresh approaches to some old
algorithms. Most important is a new autocorrelation scheme. The
present program converts frames of 256 16-bit samples into 14 co-
efficients and then into 128 points of logarithmic power spectrum
at 100 frames/s.
</bodyText>
<sectionHeader confidence="0.716536" genericHeader="method">
EXPERIMENTS WITH A TREE-SEARCH METHOD FOR CONVERTING
NOISY PHONETIC REPRESENTATION INTO STANDARD ORTHOGRAPHY
C. C. Tappert
</sectionHeader>
<subsectionHeader confidence="0.645646">
Speech Processing Group
</subsectionHeader>
<bodyText confidence="0.829711272727273">
IBM Thomas J. Watson Research Center
Yorktown Heights, N.Y.
IEEE Transactions on Acoustics, Speech, and Signal Process.ing
ASSP-23, February 1975, 1,29-13-5
A 250-word lexicon and a finite-state grammar specify the
tree. The search is performed in a best-first manner. Phonetic
variants for. each word are generated automatically by a set of
phonological rules. Substantial imprOvement over earlier perfor-
mance on the same data wa realized.
21
Speech recognition
</bodyText>
<table confidence="0.867522166666667">
MINIMUM PREDICTION RESIDUAL PRINCIPLE
APPLIED TO SPEECH RECOGNITION
Fumitada Itakura &amp; Pllectrical Communications Lab
Acoustics Research Department Nippon Telephone &amp; Telegraph
Bell Laboratories Public Corporation
Murray Hill, N.J. Musashino, Tokyo
</table>
<tableCaption confidence="0.4657045">
IEEE Transactions on Acoustics, Speech, and Signal Processing
ASSP-23, February 1975, 67-72
</tableCaption>
<bodyText confidence="0.993270181818182">
Isolated words, spoken by a designated talker, are recog-
nized through calculation of a minimum prediction residual. A
reference pattern for each word i8 stared as a time pattern of
linear prediction coefficients (LPC). The total log prediction
residual of an input signal is minimized by optimally register-
ing the reference LPC onto the input autocorrelation coefficients.
The input signal is recognized as the reference word which pro-
dUces the minimum prediction residual. In a 200-word recognition
experiment, the recognition rate for a designated male talker is
97.3 percent for telephone input, and the recognition time is
about 22 times real time.
</bodyText>
<table confidence="0.71852875">
PITCH DETECTION BY DATA REDUCTION
Neil J. Miller
Artificial Intelligence Laboratory
Department of Computer Science
Stanford University
Stanford, California
IEEE TRANSACTIONS ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING
ASSP-23, February 1975, 72-79
</table>
<bodyText confidence="0.991061">
An algorithm determines fundamental frequency by segmenting
the signal into pitch periods. Segmentation is achieved by ident-
ifying the beginning of each pitch period. Segmentation has three
phases. First, using zero crossing and energy measurements, a
data structure is constructed. Next, the number of candidate pitch
period markers is reduced utilizing syllabic segmentation, coarse
pitch frequency estimations, and discrimiNation functions. Finally,
the remaining markers are corrected. This algorithm processes both
male and female speech, provides a voiced-unvoiced decision, and
operates in real time on a medium speed, general purpose computer.
</bodyText>
<table confidence="0.650367375">
Speech Recognition
A PHONETIC-CONTEXT CONTROLLED STRATEGY
FOR SEGMENTATION AND PHONETIC LABELING OF SPEECH
Paul Mermelstein
Haskins Laboratories
New Haven, Conn.
IEEE Transactions on Acoustics, Speech, and Signal Processing
ASSP-23, February 1975, 79-82
</table>
<bodyText confidence="0.9996704">
In a sequential Strategy processes are applied to a
labeled speech segment and result in a possible subsegmentation;
the subsegments are labeled by the process. No more segments
are considered than those actually differentiated by the analysis
steps. The extraction of acoustic cues pertinent to a phonetic
feature can be tuned to classes of sounds separated on the basis
of other cues, increasing the reliability of segment labeling.
The analysis sequence yields a structure for the syllabic unit8
of the speech signal that can be used to retrieve similar syl-
labic units for detailed comparison.
</bodyText>
<sectionHeader confidence="0.8803535" genericHeader="method">
AN OBJECTIVE PARALLEL EVALUATOR OF SEGMENTATION/
CLASSIFICATION PERFORMANCE FOR MULTIPLE SYSTEMS
</sectionHeader>
<bodyText confidence="0.5955695">
Harvey F. Silverman and N. Rex Dixon
Speech Processing Group
IBM Thomas J. Watson Research Center
Yorktown Heights, N.Y.
</bodyText>
<subsubsectionHeader confidence="0.216091">
IEEE Transactions on Acoustics, Speech, and Signal Processing,
ASSP-23, February 1975, 92-99
</subsubsectionHeader>
<bodyText confidence="0.998006">
The system provides for concurrent objective evaluation
of up to five methods against a single referent. For segmenta-
tion, the evaluator provides first-order statistics, at the
phonetic, class and summary levels, for four types of errors:
Missed, Adventitious, Misplaced, and Adventitious and misplaced
events. For classification, the evaluator gives confusion mat-
rices at the phonetic, class and summary levels. The syfje
still in the developmental process, is operational anOmmurratly
used.
</bodyText>
<table confidence="0.913642714285714">
23
Speech Synthesis
PERFORMANCE OF A SPEECH SYNTHESIS SYSTEM
W. A. Ainsworth
Communication Department
University of .Keele
Keele, Staffordshire, U.K.
</table>
<subsectionHeader confidence="0.83248">
International Journal of Man-Machine Studies 6, 493-511, 1974
</subsectionHeader>
<bodyText confidence="0.9995326">
A string of phonetic symbols representing the sentence to
be uttered iS transformed into the control signals required by a
parametric speech synthesizer using a small digital computer.
The performance of the system was investigated by listening tests.
In the first set of experiments consonant-vowel syllables were
synthesized, and presented to listeners for identification. The
vowels were readily. Identified, but the fricatives less so. In
the second set of experiments the intelligibility of synthesized
sentences was examined. It was found that after about an hour of
transcribing the sentences, listeners identified about 90% of the
words correctly.
A PROGRAMMING SYSTEM FOR STUDIES IN SPEECH SYNTHESIS
P. V. S. Rao, R. B. Thosar
Tata Institute for Fundamental Research
Bombay,
</bodyText>
<equation confidence="0.3175355">
IEEE Transactions on Acoustics, Speech, and Signal Processing,
ASSP-221 3, 217-225, 1974
</equation>
<bodyText confidence="0.999959333333333">
This paper describes a speech synthesis system which is
particularly suitable for experimental investigations. The syn-
thesis is accomplished in two stages. The concatenation stage gen-
erates a schematized spectrographic representation corresponding to
the symbolic input. The second stage consists in generating the
corresponding acoustic signal. The steady state characterization
of each phoneme is supplied as data. Independent concatenation
procedures incorporate context dependent effects such as format
transitions, changes in the normal duration of vowels, etc. The
parameter valties for these procedures are obtained by a set of
rules. Applicability of a rule is determined by attributes as-
signed to the phonemes.
</bodyText>
<page confidence="0.349354">
24
</page>
<table confidence="0.449193375">
Orthography
A THEORETICAL APPROACH FOR CHARACTER RECOGNITION
BASE)) ON PHENOMENOLOGICAL ATTRIBUTES
B. Blesser, R. Shillman, T. Kuklinski, C. Cox, M. Eden and J.
Ventura
Research Laboratory of Electronics
Massachusetts Institute of Technology
Cambridge, Mass.
</table>
<subsectionHeader confidence="0.749615">
International Journai of Man-Machine Studies, 6, 701-714
</subsectionHeader>
<bodyText confidence="0.880185333333333">
A theory based on ambiguities, rather than on the clas-
sical archetypal shape of letters, leads to algorithms which will
perform more accurately. Letters are described in terms of an
abstract set of functional attributes, each of which can be re-
lated to a type of ambiguity between two letters. The relations
between the functional attributes, which specify the letter&apos;s
identity, and the physical attributes, which are derived from
the physical image, are called graphical context rules. These
rules can be determined from psychological experimentation.
</bodyText>
<table confidence="0.882850888888889">
PROBLEME DE LA CLASSIFICATION DES CARACTERES CHINOIS
(ME CHINESE CHARACTER CLASS,IFICATION PROBLEM)
M. R. Finley, Jr.
Department of Mathematics
University of Laval
Quebec
Proceedings of the Second Open Conference on Information Science
in Canada, edited by A. Gamache &amp; R. Penner. Ottawa: Canadian
Association for Information Science, 1974, 163-180
</table>
<tableCaption confidence="0.542172111111111">
The classification problem is presented for the set of
40,000 two-dimensional patterns known as the Chinese characters.
The traditional classification according to certain meaning patterns
termed radicals is sketched together with some variahts derived
from it. Using the notion of two-dimensional formal grammar, a
classification is outlined yielding a quasi-algebraic formula for
each character. Also mentioned are spin-offs on the development
of Chinese text composition devices using graphic-display tech-
niques and mini-computers.
</tableCaption>
<table confidence="0.493826">
25
Concordance
PHRASE DICTIONARY DISTRIBUTION ANALYSIS ARD GROWTH PREDICTION REPORT
J. H. Waite, R. Boehm, J. G. Fisher, S. D. Epstein, D. J. Stewart
Cryptanelytic Computer Sciences Inc.
Cherry Hill, N.J
</table>
<bodyText confidence="0.9942932">
This study of the DDC Phrase Glossary includes a computer
program to tabulate work frequencies for blocks of phrases of op-
tional sizes. On the basis of these distributions, empirical and
statistical analyses are made including two prediction models.
Two-word distributions are also included. Based upon the avail-
able distributions, a two-word Phrase Glossary size of 320,000 two-
word phrases was determined. Also included are analyses of
various techniques, such as suffix truncation, imbedded phrases,
and query effectiveness. Comparisons are made of the DDC system
to other plain language machine retrieval systems. [AD-780 957/7GA
</bodyText>
<equation confidence="0.303057333333333">
PC $3.75, MF S1.45 April 1974]
THE LANGUAGE OF THE &apos;PETERBOROUGH CHRONICAL&apos;
J. L. Mitchell
</equation>
<bodyText confidence="0.9244188">
Computers in the Humanities, J.L. Mitchell, Editor, 1974, 132-145
As a necessary prerequisite to a syntactic investigation of
the chronicle the following analyses are produced: alphabetized
list of every word of the corpus, cumulative frequency, alpha-
betized frequency list, rank of every word, cumulative absolute
frequency af every group of words, percentage and cumulative fre-
quency of the text represented by each word and group of words,
a concordance, a frequency list for grammatical categories, and
the text with each word tagged for syntactic category.
26
Concordance
JEUDEMO: A TEXT HANDLING SYSTEM
P. Bratley, S. Lusignon, and F. Oue lette
Computers in the Humanities, J. L. Mitchell, Editor, 234-249, 1974
In a typical text-processing task, the structure of the
text must be described, the operations, with any restrictions to
be performed defined, and the format of results given. The pre-
sent system allows, for the first part, the definition of the
alphabet of a corpus, the word separators, tags (for homograph
separation, category markers, etc.), and the language of the
text. Allowable operations are: the listing of all words pre-
sent; KWIC concordances; the building of indexes; the searching
for words, or word patterns; and searches as in the previous
operation, but with restrictions to words of specified frequency,
or to sections of the corpus.
</bodyText>
<sectionHeader confidence="0.359752" genericHeader="method">
FROM A WORD-FORM CONCORDANCE TO A DICTIONARY-FORM CONCORDANCE
</sectionHeader>
<bodyText confidence="0.820904833333333">
D. J. Koubourlis
Computers in the Humanities, J.L. Mitchell, Editor, 225-2-33, 1974
A word-form concordance does not conjoin inflected forms
of the same lexeme, nor does it separate homographs. By manually
editing the output of a word-form concordance for these two phe-
nomena and resorting, 1. dictionary-form concordance is produced.
</bodyText>
<figure confidence="0.2644008">
DEVELOPMENT OF A TEXT CONCORDANCE AND STATISTICS PROGRAM
Lance S. Smith
Brigham Young University
Proceedings of the [.317U] Linguistics Symposium, 1973
The system has seven basic phases: (1) Entry of source text;
</figure>
<figureCaption confidence="0.19723375">
(2) Main dictionary update; (3) Creation of upgraded text for
processing; (4) Upgraded text pre-edit for processing; (5) Pro-
duction of KWIC concordance; (6) Proauction of keyword in phrase
concordance; (7) Production of word frequency, parts list, reverse
</figureCaption>
<bodyText confidence="0.982692857142857">
alphabetical word list, and various statistics, e.g. average
number of words per sentence. In (2) an exhaustive list of words
in the text but not in the dictionary is produced, and an inter-
active program requests information for each new word. This in-
formation is merged into the main dictionary. In (3) information
from the dictionary is appended to each word of the text and
ambiguities resolved by interactively interrogating the user.
</bodyText>
<figure confidence="0.7087995">
27
Lexicography
AUTOMATIC IDENTIFICATION OF PHRASAL VERBS,
Godelieve L. M. Berry-Rogghe
Computers in the Humanities, J. L. Mitchell, editor, 16-26, 1974
A phrasal verb is an idiomatic phrase of verb plus parti-
</figure>
<figureCaption confidence="0.428163">
cle, e.g. look after&apos;. The author seeks to automatically con-
struct a lexicon of phrasal verbs given an adequately large
quantity of data, and statistical procedures.
</figureCaption>
<bodyText confidence="0.9064286">
The statistical procedure used is &apos;collocation&apos;--the
probability of syntagmatic association of two items occurring
separated by n items. An analysis of the particle &apos;in&apos; shows
that verbs from phrasal verbs are mpre closely collocated with
this particle than non-idiomatic constituent Verbs.
</bodyText>
<sectionHeader confidence="0.52889" genericHeader="method">
SHAD: A SHAKESPEARE DICTIONARY
</sectionHeader>
<bodyText confidence="0.7197144">
M. Spevack, H. J. Neuhaus, and T, Finkenstaedt
Computers in the Humanities, J. L. Mitchel,l, editor, 111-123, 1974
SHAD merges information from a concordance of Shakespeare,
a computer dictionary (drawn from the Shorter Oxford English Dic-
tionary), and data from semi-automatic lemmatization.
</bodyText>
<page confidence="0.465736">
28
</page>
<figure confidence="0.7128475">
Lexicography
A COMPUTERIZED LEXICON OF ENGLISH
E. R. Maxwell, and R. N. Smith
Computers in the Humanities, J. L. Mitchell, editor, 124-131, 1974
</figure>
<bodyText confidence="0.925527913043479">
An autonomous theory for lexical structure, called Semantic
Field Theory, is preaented. There is a set of primitives (about
20): sameness, difference, events, st, motion, space, emotion,
ets. &apos;Neutral concepts are defined by primitive relations to the
primitives, e.g., cause, change. A semantic field (SF) is taxonOm-
ically related to a neutral concept. For example, the semantic
field &apos;punch&apos; is a member of the neutral concept &apos;hit&apos;, with &apos;fist&apos;
as &apos;instrument&apos;, and &apos;hit&apos; is an &apos;event&apos; involving a motion against
an object (object being defined as experiencer&apos;s body or immediate
environment) by another object, the two objects being different.
A COMMON STRUCTURE FOR LEXICOGRAPHIC DATA
D. Sherman
Computers in the Humanities, J. L. Mitchell, Editor, 215-224, 1974
Libraries in the US and the UK have developed a standard
structure for data exchange, termed MARC--MAchine Readable Catalog.
Each record has a fixed length leader of format defined by the
MARC standard, which gives the general record status and control
information. Following the leader is a table of contents and in-
ventory of all data fields in the record. The data part of a
record is divided into fields, each of which is tagged by a
digit number; sub-fields are headed by a symbol of the form $n,
where n is an identifier code. The system is used to encode
Webster&apos;s seventh Collegiate Dictionary, giving the WEBMARC file.
</bodyText>
<figure confidence="0.859927333333333">
29
Lexicography,
THE &apos;THESEE&apos; THESAURUS FOR ELECTRICITY AND ELECTRONICS
DESCRIPTION AND METHOD OF USE
&apos;Thesee&apos; thesaurus pour l&apos;electricite et l&apos;electronigye:
description et methode d&apos;uti1ization
A. DeWt2e
Grenoble
T. A. Informations, 1974, 1, 2-51
</figure>
<figureCaption confidence="0.9782742">
This trilingual thesaurus, with both orthographic and magnetic
tape implementations, contains about 11,000 terms. Its five
indexes are (1) dictionary, (2) relations of substitution,
descriptors with terms, (3) related terms, (4) polyhierarchic
classification trees; (5) semantic fields.
</figureCaption>
<figure confidence="0.8961475">
LEXICDGRAPHY FOR A STRING GRAMMAR OF FRENCH
La 1exicographie pour une grammaire en chaines du francais
Morris Salkoff and Anne Zribi
Laboratoire d Automatique Documentaire et Linguistique
Universite de Paris
Rapport de ReCherches No. 3
</figure>
<bodyText confidence="0.50403">
The structure of a dictionary to accompany Salkoff&apos;s grammar
(cf. AJCL Microfiche 6:64). Subclasses, selectional. Qonstraints
on verbs, treatment of multiple classification, idioms, hoMonyms,
etc. An extensive analysis of the French lexicon.
</bodyText>
<figure confidence="0.982110666666667">
3U
Grammar
WORD eRDER AND WORD ORDER CHANGE
Charles N. Li, Editor
Linguistics Program
University of California
Santa Barbara
University of Texas Press
Austin and London
1975
TABLE OF CONTENTS
Influences on word order change in American sign language
Susan Fischer 1
Dynamic aspects of word order in the numeral classifier
Joseph H. Greenberg 27
Serial verbs and syntactic change: Niger-Congo.
Talmy Givon 47
On the change from SOV to SVO: Evidence from Niger Congo
Larry M. Hyman 113
A discussion of compound and word order
Winfred P. Lehmann 149
The semantic function of word order: A case study in
Mandarin Charles N. Li and Sandra A. Thompson 163
On some factors that affect and effect word order
Susan Steele 197
An explanation of drift Theo Vennemann 269
Order in base structure Emmon Bach 307
The presentative movement, or why the ideal word order is
V.S.O.P. Robert Hetzron 346
On the explanation of constituent order universals
Gerald Sanders 389
Verb-anchoring and verb movement Arthur Schwartz 437
ISBN 0-292-79002-3
LC Card 74-17620 $12.50
31
Grammar
A SYSTEM FOR AUTOMATIC INFLECTIONAL ANALYSIS
IMPLEMENTED FOR RUSSIAN
Anna-Lena Sagvall
Almqvist &amp; Wiksell
Stockholm
1973
</figure>
<figureCaption confidence="0.5904255">
Part I. On automatic test analysis • •••• •••••• 13
Introduction • . . • • . • . • • . • • . . • • • • 13
General considerations concerning the construction
of a system for automatic text analysis • • • - • • 13
Some comments on the devlopment of systems for
automatic text analysis . . • • 16
Part II. Designing a system for automatic inflectional
analysis of Russian texts - - - 19
1. Background to the constr*ction of a system for
Russian inflectional analysis . • • • • • • • • 19
</figureCaption>
<listItem confidence="0.970304956521739">
2. Specifying the new code (NC) . . . • . • • • • • 20
3. Studying the original code (OC) . . • • • • • . • • 26
4. Some basic problems , . . • • • • • • • • • • • • 27
5. Choosing the dictionary representations • - • • • . 31
6. Verifying compatibility between the dictionary
segment (DS) and the second segments (SSs) for
basic class 7 . . . • . • • • • • • • • • • • • • • 47
7. • • • • • • • 49
Classifying the stems-
8. Selectional criteria . . . • • • • . • • • • • • 55
9. A presentation of the second segment System ,for
basic class 1, 2 and 3 . . - . • - • - • - 69
10. A presentation of the third segment system for
basic class 7 . . . . . . . . . . . . . .. 74
11. Demands on the algorithm for the dictionary search 77
Part III. Processing Russian text . . . • • . 81
1. Preparatory processing of the text material - • - 81
2. Inputting and organizing the text material - - - • 82
3. Prpcessing in AUTLEX . . . - • • . • P • • 83
4. • • • • • 90
Program lists . . . . . - • - •
5. • • • • .
Technical information • • • • - 107
</listItem>
<equation confidence="0.884737857142857">
Conclusion • 108
. . . . • • . • • . • • • • • • • • •
Appendices. • 109
. • • • • • • • • • • • • • • • • • • • • . •
References. • • - 141
. • • • • • • • . • - -
ISBN 91-20-04159-4
</equation>
<page confidence="0.326155">
32
</page>
<figure confidence="0.9020075">
Grammar
CONCERNING THE STRUCTURE OF A COHERENT TEXT
ON THE MORPHOLOGICAL LEVEL
Felix Dreizin
Mathematics Department
Bar--Ilan University
Ramat-Gan, ISRAEL
Hebrew Computational Linguistics No. 8, 1974
</figure>
<figureCaption confidence="0.9600538125">
The proposed set of rules for characterizing agreement
(= concord) phenomena in Modern Hebrew is sub-divided as follows:
a) Gender and Numbek concord within the NP; b) DefinitenesS
assignment; c) Subject -- Main Verb concord -- in turn sub-divided
into cases where the Main Verb is a &amp;quot;full&amp;quot; verb and those where
it is a copula. The formation of these rules is preceded by a
brief descriptive statement of types of redundancy rules which
inter-act with agreement phenomena (e.g. certain types or nom-
inals are inherently H-Definite]). The phenomenon of agreement-
assignment is viewed as a transformational process of &amp;quot;feature-
assignment&amp;quot; whereby a specific feature or set of features (e.g.
Gender, Number) is copied from one term to other terms within a
given syntactic configuration. The process involved is essen-
tially one of &amp;quot;daughter-adjunction&amp;quot;. Note is made of the order-
ing agreement assignment with respect to other processes such
as passivizati.on or nominalization.
</figureCaption>
<sectionHeader confidence="0.484146" genericHeader="method">
JUNCTION GRAMMAR AS A BASE FOR AUTOMATIC LANGUAGE PPOCESSING
</sectionHeader>
<reference confidence="0.622388">
E. Lytle, and D. Packard
Brigham Young University
Provo, Utah
Preprint, Annual Meeting, Association for Computational Linguistics
</reference>
<page confidence="0.34153">
1974
</page>
<bodyText confidence="0.957999444444444">
Junction-rule schemata interrelate constituent operands
via adjunction, conjunction, or subjunction. These fundamental
relations are further subdivided in terms, of: (1) operand cate-
gbries; (2) operand junction attributes; and () operand scope.
Constraints imposed upon the form and content of junctions exclude
those not evidenced by natural language data. At the highest
level of specificity, junction markers represent an interaction of
individual indices, class indices, and a variety of functional
entities.
</bodyText>
<figure confidence="0.504803166666667">
33
Grammar
MACHINE TRANSLATION AND GERMAN VERB CLASS SYSTEM
Mark Strong
Brigham Young University
Proceedings of the [BYU1 Linguistics Symposium, 1972
</figure>
<bodyText confidence="0.995046833333333">
German verbs have 25 forms per verb, and can use either &apos;have&apos;
or &apos;be&apos; 0 an auxiliary. A verb class system is proposed in
which information about the complete conjugation can be stored in
two hexadecimal digits (i.e. in less than 32 classes). This com-
pares with a detailed traditional verb class system that makes 47
distinctions and could not be contained in the space available.
</bodyText>
<sectionHeader confidence="0.62199" genericHeader="method">
PROCEDURES FOR ORDERING WELL-FORMED SYNTACTIC STATEMENTS
</sectionHeader>
<reference confidence="0.291379333333333">
Floyd H. Billings, Jr.
Brigham Young University
Proceedings of the [BYU] Linguistics Symposium, 1973
</reference>
<bodyText confidence="0.999482285714286">
In junction grammar representations of sentence structure, the
relations between lexical items is logical but not linear. Lex-
ical ordering rules are thus independent from th syntactic
representation. Some rules can be assigned by know ng which
junction rule is involved e.g. in English the rule joining a
preposition to its object is always left-to-right, but in German
prepositions have to be classified as either preceding or fol-
lowing. A second type of ordering rule involves the operands of
a junction rule being more closely related to each other than to
any outside element. An example is the processing of articles;
an unmodified noun immediately follows the article, but is
realized elsewhere when the noun is modified. Discontinuous
orderings are omitted at their actual locations and processed at
a designated insertion point.
</bodyText>
<figure confidence="0.891281285714286">
34
Grammar
CORPUS OF MODERN FRENCH VERB-AFFIX NOMINALIZATIONS
Corpus des nominalisations verbaJo-affixales du Francais moderne
Laurent Bourbeau
Groupe de recherches pour la traduction automatique
Universite de Montreal
</figure>
<subsubsectionHeader confidence="0.858597">
Working Papers in the Linguistics of Machine Translation, 1974
</subsubsectionHeader>
<bodyText confidence="0.9993746">
A study of productive affixes serving as lexical indicators.
One program edits a deck and writes a matrix of verbs. A second
lists the verbs by categories of various codes. A third lists
all nominalizations indicated by codes. The results are tools
for research. Tables of codes, card formats, etc.
</bodyText>
<sectionHeader confidence="0.640291" genericHeader="method">
LA NOMINALISATION
</sectionHeader>
<subsectionHeader confidence="0.523535">
Laurent Bourbeau
</subsectionHeader>
<bodyText confidence="0.6152245">
Groupe de recherches pour la traduction automatique
Universite de Montreal
</bodyText>
<subsubsectionHeader confidence="0.559687">
Working Pipers in the Linguistics of Machine Translation, 1974
</subsubsectionHeader>
<bodyText confidence="0.5529985">
Theories of Grevisse, Tesniere, Dubois, Tutescu. Coding of
verbs: morphology, complements, genders of nouns derived.
</bodyText>
<page confidence="0.327399">
35
</page>
<table confidence="0.723552">
Parsers
A BEST-FIRST PARSER
William H. Paxton
Artificial Intelligence Center
Stanford Research Institute
Menlo Park, California
</table>
<subsubsectionHeader confidence="0.541432">
SRI Publication No. Z108 April 1974
</subsubsectionHeader>
<bodyText confidence="0.999525142857143">
A parser for a speech understanding system is described.
The parser uses a best-first strategy in which alternative paths
are assigned priorities and paths ate suspended as long as there
is a higher priority alternative to explore. Discussions are
included on the types of steps in a parse, the assignment of
priorities, cooperation among competing parses, and experimental
results.
</bodyText>
<subsectionHeader confidence="0.412905">
THE LINGUISTIC STRING PARSER
</subsectionHeader>
<bodyText confidence="0.787192">
R. Grishman, N. Sager, C. Raze, and B. Bookchin
New York University
</bodyText>
<subsectionHeader confidence="0.627486">
Proceedings of the National Computer Conference, 1973, 427-434
</subsectionHeader>
<bodyText confidence="0.999591818181818">
The string grammar has three components: (1) A set of some 300
BNF definitions for combining elementary strings into sentences
(2) A set of restrictions on the strings. (3) A word Diction-
ary. The parser is top-down serial with automatic backup. It
produces all parse trees of a sentence. Restrictions are written
in a subset of English and translated by the parser into lists
of basic operations recognized by the restriction interpreter.
For conjunctions, satisfaction of an element of their definition
causes an interrupt to insert in the tree a process node that
later causes zeroed slots to be filled in by link-s to other
subtrees.
</bodyText>
<figure confidence="0.954920818181818">
36
Semantics
4
LEXICAL SEMANTICS
SYNONYMIC MEANS OF LANGUAGE
Leksiceskaja Semantika
SiMonimiceskie Sredstva Jazyka
Ju. D. Apresjan
Science Press
Moscow
1974
</figure>
<tableCaption confidence="0.311486">
Table of Contents
FOREWORD 3
1. The fundamental ideas of modern semantics 6
Sources of semantics . . 6
Modern semantics as part of a general theory of language 11
</tableCaption>
<bodyText confidence="0.542056">
The &amp;quot;Meaning ---- Text&amp;quot; model and its evolution. • • •
</bodyText>
<listItem confidence="0.482313">
2. Semantic language as a means of interpreting lexical
</listItem>
<bodyText confidence="0.825561176470588">
meaning 56
The linguistic sign and the concept of lexical meaning 56
Elements- of a language for the interpretation of
lexical meaning 70
Dictionary of the semantic language 70
Syntax of the semantic language 77
Laws of interaction of signs 79
Requirements for interpretation and for induced
expression 95
Experiments in the interpretation of signs • • ▪ 107
Samples of interpretation 107
Test of the correctness of interpretation • • 113
The role of semantic language for descriptive linguistics 114
From interpretation tO deep syntactic structure: a
model of government 119
The semantic valence of a word 119
A model of word government 133
</bodyText>
<page confidence="0.639162">
37
</page>
<note confidence="0.646434">
LEXICAL SEMANTICS (CONTINUED)
General characteristics of the means of paraphrasing . 156
</note>
<table confidence="0.8497691">
3. Word formation and polysemy ••••••• 164
Word formation in the proper meaning of the word 164
Suppletive word formation 168
Polysemy (semantic derivation) 175
Types of ambiguity in language and speech. •• 176
Polysemy and word formation . . . 187
Regular polysemy of substantives 193
Actant meaning 193
Other types of meaning 200
Regular polysemy of verbs 203
&apos;Causation&apos; - &apos;extraction&apos; - &apos;liquidation&apos; -
&apos;removal&apos; - &apos;elaboration&apos; - &apos;deformation&apos;. 205
Action&apos; - &apos;causation of action&apos; . 208
Other causative meanings . 209
Other types of meaning 209
Regular polysemy of adjectives . . . .. 211
Causative meaning . ....... • • • 212
Purposive meaning 212
Parametric meaning 213
Other types of meaning 214
4. Lexical synonyms ........... . • 216
Definition cf lexical synonyms 216
Status of the auestion 216
Lexical synonymy: analysia and definition ••• 220
Sources of lexical synonyms 224
Combinability distinctions among synonyms 230
Inclusion of combinabilities . . •• 232
Intersection of combinabilities . . . . . . . . 233
Full coincidence of combinabilities 234
Quasisynonyms • • • 235
Geno-specific distinction 235
Specio-specific distinction . ••••••••• 237
Neutralization of semantic distinction 239
38
LEXICAL SEMANTICS (CONTINUED)
On the concept of nuance of meaning 243
Series of quasisynonyms and semantic role . . . 248
5. Lexical converses 256
Preliminary remark and definition •••••••••• 256
Sources of lexical converses . 263
Ready made converses • • • • • • • • 263
Regular methods of formation of converses • • • 265
Basic types of converses 266
Syntactic types ., • , . . 266
Semantic types . 268
Two-place converses • • . 268
Three-place converses . . 272
Combinability types 273
Quasiconverses 275
Definition and basic types . •••••••••• 275
Neutralization of semantic distinctions among
quasiconverses . • • • • ......... , 281
6. Lexical antonyms . . • . • • • 284
Preliminary remark 284
Semantic analysis of antonyms . , • • • •• 282
The &apos;begin&apos; - &apos;end&apos; type ........ . . 288
The &apos;action&apos; - &apos;annihilation of the result of
action&apos; type • • &apos; . . • 290
The &apos;R&apos; - &apos;not R&apos; type 292
The &apos;more&apos; - &apos;less&apos; type •• &apos; • • • 295
</table>
<tableCaption confidence="0.391138571428571">
Other types of antonyms 297
Complex antonymy and the definition of antonyms . 301
Other questions in the theory of antonyms • .• . 302
Semantic asymmetry of antonyms . . . . 302
Combinability distinction of antonyms . •. 305
Means of formation of antonyms . . . 306
Quasiantonyms . • OOOOOOO ••••••• 312
</tableCaption>
<figure confidence="0.964493066666666">
39
LEXICAL SEMANTICS (CONTINUED)
7. Deep syntactic transformation . . . . . . . 316
Introductory note . . . • • • . • 316
Some new rules of paraphrasing . • • • • • . • . • 324
Equimeaning transformations . . . . • • • • 326
Implicative transformations 333
Syntagmatic restrictions imposed on transformation
(filters) . . . . . . . . • . . . . . 335
Conclusion . • • • • • • • • • • 344
Bibliography. • • • • • • • • • • . 346
&apos;
40
Discourse
THE STRUCTURE OFTASK ORIENTED DIALOGS
</figure>
<reference confidence="0.2991475">
Barbara G. Deutsch
Artificial Intelligence Center
Stanford Research Institute
Menlo Park, California
</reference>
<subsubsectionHeader confidence="0.6958">
SRI Publication No. Z106 April 1974
</subsubsectionHeader>
<bodyText confidence="0.998598333333333">
The discourse and task information in task oriented dialogs
and their Use in a speech understanding system are discussed. The
results of analyzing some task oriented dialogs are given. A pre-
liminary model of the structure of these dialogs and heuristics
for bui,lding and using it in a speech understanding system are
presented.
</bodyText>
<page confidence="0.613418">
41
</page>
<table confidence="0.852603166666667">
Comprehension
THE SRI SPEECH UNDERSTANDING SYSTEM
Donald E. Walker
Artificial Intelligence Center
Stanford Research Institute
Menlo Park, California
</table>
<subsubsectionHeader confidence="0.647538">
SRI Publication No. Z107 April 1974
</subsubsectionHeader>
<bodyText confidence="0.999914428571429">
This paper describes the structure of the SRI speech under-
standing system and presents the available data on its performance.
The system is distinctive in the way that knowledge of various
sources is coordinated by a &amp;quot;best-first&amp;quot; parser to predict the
sequence of words in an utterance, and in the use of word functions
--programs that represent the acoustic characteristics of a word--
to test the predictions.
</bodyText>
<figure confidence="0.7677795">
THE BELIEVER SYSTEM
G. Brown
Department of Computer Science
Rutgers University
New Brunswick, N.J.
Report No. CBM-TR-34, 1974
</figure>
<figureCaption confidence="0.712435222222222">
Attempts to understand and interpret natural language
descriptions of human action. Plans and episodes must replace
sentences as units of human action to facilitate interpretation
of motivation. A plan is an action or a sequence of actions
caused by a person in order to achieve a foreseeable goal. An
episode i8 a sequence of acts containing a single plan or several
inter-related plans. The Believer System uses Schmidt&apos;s theory
of intention and personal causation to isolate a plan from a
series of acts which may be mostly unrelated to the plan.
</figureCaption>
<figure confidence="0.4476245">
42
Comprehension
SEMANTICS AND SPEECH UNDERSTANDING
Bonnie L. Nash-Webber
Bolt Beranek and Newman Inc.
Cambridge, Mass
</figure>
<figureCaption confidence="0.276509">
Report No. BBN-2896, AI-19, October, 1974
</figureCaption>
<bodyText confidence="0.996804272727273">
Syntactic constraints and expectations are based on the
patterns formed by a given set ef linguistic objects, e.g. nouns
verbs, adjectives, etc. Pragmatic ones arise from notions of
conversational structure and the types of linguistic behaviot
appropriate to a given situation. The bases for semantic con-
straints and expectations are an a priori sense of what can be
meaningful and the ways in which meaningful concepts can be
realized in actual language. The paper describes how semantics
is being used in several recent speech understanding systems
and discusses in detail some actual problems that have arisen.
[Ad-787 616/2GA; PC $4.25; MF S2.25]
</bodyText>
<sectionHeader confidence="0.833346" genericHeader="method">
THE GASPERS LINGUISTIC ANALYSIS SYSTEM
</sectionHeader>
<reference confidence="0.6903822">
John W. Klovstad and Lee F. Mondshein
M.I.T. Lincoln Laboratory
Lexington, Mass.
IEEE Transactions on Acoustics, Speech, and Signal Processing
ASSP-23, February 1975, 118-123
</reference>
<bodyText confidence="0.977411875">
CASPERS (Computer-Automated Speech Perception System) is
a user-modifiable facility for translating strings of acoustic
symbols into sentences. Three distinctive aspects of the system&apos;s
design are the dynamic application of acoustic-phonological rules
across word boundaries, an acoustic-unit splitting-and-merging
strategy for treating the dictionary matching problem, and an
extensive capability for handling emantic routines within an
augmented context-free grammar.
</bodyText>
<page confidence="0.964052">
43
</page>
<sectionHeader confidence="0.971928333333333" genericHeader="method">
Comprehension
MOTIVATION AND OVERVIEW OF SPEECHLIS: AN EXPERIMENTAL PROTOTYPE
FOR SPEECH UNDERSTANDING RESEARCH
</sectionHeader>
<reference confidence="0.9538022">
W. A. Woods
Bolt Beranek and Newman Inc.
Cambridge, Mass.
IEEE Transactions on Acoustics, speech, and Signal Processing
ASSP-23, 1975, 2-10
</reference>
<bodyText confidence="0.996303583333333">
Syntactic, semantic, pragmatic and lexical knowledge inter-
act with acoustical and phonological information in the process
of speech understanding. A feature-extraction component produces
a segment lattice of phonetic descriptions of the acoustic signal.
Words from a lexicon are matched against the input signal. A
syntaotic component judges the grammaticality of hypothesized
interpretations, and a semantic component judges meaningrulness.
A pragmatic component judges the likelihood of a sentence being
uttered in the situation by the speaker. The control coMponent
uses the above components predictively to construct &apos;theories&apos;
that can be evaluated by other components or used to set monitors,
that, when triggered, initiate procedures to assimilate the event.
</bodyText>
<sectionHeader confidence="0.770758" genericHeader="method">
A PROSODICALLY GUIDED SPEECH UNDERSTANDING STRATEGY
</sectionHeader>
<reference confidence="0.8767622">
Wayne A. Lea, Mark F. Medress, and Toby E. Skinner
Sperry Univac
St. Paul, Minnesota
IEEE Tr*a12sactions on Acoustics Speech, and Signal Processing
ASSP-23, 1975, 30-38
</reference>
<bodyText confidence="0.9523481">
Prosodic features break up continuous speech into sentences
and phrases, and locate stressed syllables in those phrases. The
most reliable phonetic data are obtained by performing a distin-
guishing feature analysis within the stressed syllables and by
locating sibilants and other robust feature information in un-
stressed syllables. The numbers and locations of syntaL.tic boun-
daries and stressed syllables are used to selegt likely syntactic
and semantic structures, with which words are hypothesized to
correspond to the partial distinguishing features matrices obtained
from the segmental analyses.
</bodyText>
<page confidence="0.725783">
44
</page>
<sectionHeader confidence="0.439435" genericHeader="method">
Comprghension
CONTROL CONCEPTS IN A SPEECH UNDERSTANDING SYSTEM
</sectionHeader>
<reference confidence="0.9505626">
Paul Rovner, Bonnie Nash-Webber, and William A. Woods
Bolt Beranek and Newman Inc.
Cambridge, Mass
IEEE Transactions on Acoustics, Speech; and Signal Processing
ASSP-23, 1975, 136-140
</reference>
<bodyText confidence="0.999520076923077">
An entirely accurate and precise acoustic transcription
of speech is unattainable. Applying knowledge about the phono-
logy, syntax, and semantics of a language, and the pragmatic
constraints imposed by a task domain can resolve much of the
acoustic ambiguity. Lexical retrieval and word matching programs
map segments of phonetic transcriptions of the acoustic signal.
Syntactic, semantic and pragmatic components of the system form
hypotheses about the Original utterance which change as evidence
for or against them is found. Theories set traps to catch .evi-
dence; when a trap is triggered, an evaluation is made to decide
if or when to reprocess. A component can also make a &apos;proposal&apos;
which is a request to try immediately to match words against part
of the utterance.
</bodyText>
<sectionHeader confidence="0.977401" genericHeader="method">
SEMANTIC SUPPORT FOR A SPEECH UNDERSTANDING SYSTEM
</sectionHeader>
<reference confidence="0.9190098">
Bonnie Nash-Webber
Bolt Beranek and Newman Inc.
Cambridge, Mass
IEEE Transactions on Acoustics, Speech, and Signal Pro,ce.ssing
ASSP-23, 1975, 124-129
</reference>
<bodyText confidence="0.999187181818182">
The principal data structures of the BBN SPEECHLIS semantic
system are a semantic network and case frame tokens. The network
represents associations among words and concepts. The case frames
describe how the semantic relationships may Ve expressed in an
utterance. The semantic system proposes words that might have
occurred in the original utterance but have not yet been recog-
nized, constructs meaningful sets of word matches from possible
ones, and evaluates the consistency of syntactic structures and
semantic hypothesis. Two further tasks for it are under investiga-
tion: (1) to guide syntax, arid (2) to turn the best theory about
an utterance into a formal procedure for operating on a data base.
</bodyText>
<figure confidence="0.9073526">
45
Comprehension
A PRACTICAL APPLICATION OF A REAL-TIME ISOLATED-WORD RECOGNITION
SYSTEM USING SYNTACTIC CONSTRAINTS
Jean-Paul Haton
Laboratoire d&apos;Electricite et d Automatique
Universite de Nancy,
Nancy, France
IEEE Transactions on Acoustics, Speech, and Signal Processing
ASSP-22, December 1974, 416-419
</figure>
<bodyText confidence="0.989922842105263">
The recognition of sentences of a language used in numerical
command of machine tools is described. The acoustic level operates
with dynamic matching procedure and knowledge about syntactics and
semantics of the language is used to predict the incoming words.
With such a syntax-directed system, real-time recognition of senten-
ces pronounced word-by-word is very accurately achieved, even for
several speakers.
A COMPUTER PROGRAM THAT LEARNS TO UNDERSTAND NATURAL LANGUAGE,
Sara R. Jordan
Computers in the Humanities, J. L. Mitchell, editor, 205-214, 1974
Underlying the system is a memory in graph structure form.
Concept nodes are related by the following relations: transforms
to, combines to form fact, member/subset of this class, class
membership in, equivalence, description. Each concept node
&apos;transforms to&apos; words in natural languages, in this case French,
German, and English. Mechanical translation is performed by
&apos;transforming to&apos; one language from another for the concepts of
the input. Ouestion answering is carried out by inferences on
set membership.
</bodyText>
<page confidence="0.770911">
46
</page>
<sectionHeader confidence="0.680453" genericHeader="method">
Comprehension
</sectionHeader>
<reference confidence="0.9074216">
PROGRESS IN NATURAL LANGUAGE UNDERSTANDING—AN APPLICATION
W. A. Woods
Bolt 8eranek and. Newman
Cambridge, Massachusetts
Proceedings of the National Computer Conference, 1973, 441-450
</reference>
<bodyText confidence="0.997073714285714">
The BBN LUNAR system is described. It enables users to interro-
gate two data files, using.a large subset of English: (1) Ana-
lyses of Apollo 11 lunar rock samples; (2) A key phrase index to
reports of the first annual Lupar Science Confexence. An aug-
mented transition network grammar translates natural language
requests into a formal query language, a generalization of the
predicate calculus, which operates on the data base.
</bodyText>
<sectionHeader confidence="0.962601" genericHeader="method">
SOME PRINCIPLES OF COMPUTERIZED LANGUAGE ANALYSIS
</sectionHeader>
<reference confidence="0.562077333333333">
R. Brent Thompson
Brigham Young University
ProceedIngs of the [NYU] Linguistics Symposium, 1972
</reference>
<bodyText confidence="0.9909975">
The four stages in automatic language analysis are (1) Determin-
ing the kinds of linguistic elements in the input sentence;
</bodyText>
<listItem confidence="0.9892886">
(2) Determining the structural relationships among elements;
(3) Finding the referential information that may be present; (4)
Finding the contextual information that may be present. The BYU
group uses junction grammar for (2&apos;) and is beginning to work on
(3-4)
</listItem>
<sectionHeader confidence="0.874933666666667" genericHeader="method">
TOWARD COMPUTER RECOGNITION OF SPOKEN LANGUAGE
R. Byron Purves
Brigham Young University
</sectionHeader>
<subsectionHeader confidence="0.361637">
Proceedi.ngs of the (14-14U] Linguistics Symposium, 1973
</subsectionHeader>
<bodyText confidence="0.9941746">
A syntactic recognizer utilizing binary rules is applied to the
testiDg of random strings drawn from a vocabulary of 800 words.
Use of the recognizer in a set of 80 utterances gave 65% error-
free results; this compared with 35% when only a rexical recog-
nizer was used.
</bodyText>
<page confidence="0.512307">
47
</page>
<sectionHeader confidence="0.327833" genericHeader="method">
Expression
</sectionHeader>
<reference confidence="0.8091318">
SENTENCE PARAPHRASING FROM A CONCEPTUAL BASE
Neil M. Goldman
Stanford University
Stanford, California
Communications of the A.C.M. 18, 1975, 96-106
</reference>
<bodyText confidence="0.9877696">
A model of natural language based on Schank&apos;s representa-
tion of meaning. A program produces sentence paraphrases which
demonstrate understanding with respect to a given context. This
generator operates in conjunction with a combined memory and in-
erenca model. The model encompasses several diverse classes of
linguistic knowledge, which include (1) executable tests of con-
ceptual properties stored in discrimination nets, (21 information
relating conceptual and syntactic rules, stored in a word sense
dictionary, and .(3) surface grammatical knowledge stored in a
formal grammar.
</bodyText>
<sectionHeader confidence="0.9846115" genericHeader="method">
MODELLING PROPP AND LEVI-STRAUSS IN A
META-SYMBOLIC SIMULATION SYSTEM
</sectionHeader>
<reference confidence="0.942505318181818">
Sheldon Klein, John F. Aeschlimann, Matthew A. Appelbaum,
David F. aalsiger, Elizabeth J. Curtis, Mark Foster, S. David
Kalish, Scott J. Kamin, Ying-Da Lee, Lynne A. Price, David F.
Salsieder
Computer Sciences Department
University of Wisconsin
Madison
Technical Report #226, October 1974 WIS-CS-226-74
The plot of several myths is given in relational form;
the structure Propp suggested is given similarly. Compatibility
of selections of characters, objects, and functions is controlled
by subscripts, etc. Programs, grammars, traces, and output are
exhibited and commented.
48
Information structures
INFORMATION SYSTEMS: FECORDS, RELATIONS,
SETS, ENTITIES, AND THINGS
Michael E. Senko
Mathematical Sciences Department
IBM Research Laboratory
Yorktown Heights, N.Y.
Information Systems, 1, 1975, 3-13
</reference>
<bodyText confidence="0.999365636363636">
This article reviews progress in the creation of a scien-
tific discipline for information systems. It discusses contribu-
tions from four sources of fundamental knowledge: (1) Information
Systems. Technology; (2) Scientific Computation Technology; (3)
Lingnistics; and (4) Mathematics. It then selectively reviews
progress on an information systems science in the most active
areas of study: name-based representations, stored representations,
access languages, and information systems performance. This
discussion relies on the definition of a series of abstract,
structured levels for the description, design, and implementation
of generalized data base management systems.
</bodyText>
<page confidence="0.50869">
49
</page>
<figure confidence="0.886209571428571">
Inference
A HEURISTIC APPROACH TO INDUCTIVE INFERENCE
IN FACT RETRIEVAL SYSTEMS
C. William Skinner
North Carolina State University
Raleigh
Communications of the ACM, 17, December 1974, 707-712&apos;
</figure>
<bodyText confidence="0.995794">
The procedures make use of a similarity structure which is
imposed on the data base using nonnumerical clustering algorithms
They are implemented in a model fact retrieval system which uses
a formal query language and a property-list data sttucture, The
procedures are used in a program of experiments with test data
bases which are altered by deleting part of the data and by pur-
posely introducing false data. the system can infer the correct
response under a variety of conditions involving incomplete and
inconsistent data.
</bodyText>
<sectionHeader confidence="0.957755" genericHeader="method">
REPRESENTATIONS OF THE LANGUAGE RECOGNITION PROBLEM
FOR A THEOREM PROVER
</sectionHeader>
<reference confidence="0.974764666666667">
Jack Minket and Gordon J. VanderBrug
Department of Computer Science
University of Maryland
College Park
International Journal of Computer and Information Sciences, 3, 3,
1974 217-250
</reference>
<bodyText confidence="0.998482055555556">
Two representations of-the language recognition problem for
a theorem prover in first-order logic are presented and contrasted.
One of the representations is based on the familiar method of gen-
erating sentential forms of the language, and the other is based on
the Cocke parsing algorithm. An augmented theorem prover is des-
cribed which permits recognition of recursive languages. The state-
transformation method developed by Cordell Green to construct pro-
blem solutions in resolution-baSed systems can be used to obtain4
the parse tree. In particular the end-order traversal of the
parse tree is derived in one of the representations. The paper de-
fines an inference system, termed the cycle inference system, which
makes it possible for the theorem prover to model the method on
which the representation is based. The general applicability of
the cycle inference system to State-space problems is discussed.
Given an unsatisfiable set S, where each clause has at most one
positive literal, it is shown that there exists an input proof
The clauses for the two representations Satisfy these conditions
as do many state-space problems.
</bodyText>
<figure confidence="0.740710285714286">
50
Dialectology
A COMPUTER MODEL FOR THE ONTOGENY OF PIDGIN g CPEOLE LANGUAGES
Sheldon Klein and V. Rozencvejg
Linguistics Department I MGPIIYa
University of Wisconsin Laboratoriya Machinnogo Perevoda
Madison Moskva
</figure>
<subsubsectionHeader confidence="0.548441">
Technical Report #238, December 1974, Computer Sciences Department
University of Wisconsin
</subsubsectionHeader>
<bodyText confidence="0.990076875">
A system for simulation of language contact as a function
oi sociocultural, demographiC and historical factors; computer
model for the generation and g.rowth of Pidgin and Creole languages
purely in terms of structural principles and mechanisms. A genera-
tive semantic grammar is required for each language. The system
contains representations of speakers interacting Dtversationally.
They negotiate and bargain, trying to communicate, selecting con-
structions that minimize the problems of semantic parsing.
</bodyText>
<sectionHeader confidence="0.997858" genericHeader="method">
A METHOD FOR ASSESSING VARIABLE RULE AND IMPLICATION SCALE
ANALYSES OF LINGUISTIC VARIATION
</sectionHeader>
<reference confidence="0.637999">
D. Sankoff, and P. Rousseau
</reference>
<subsubsectionHeader confidence="0.842022">
In: Computers in the Humanities, J. L Mitchell, ecitor, J-15, 197
</subsubsectionHeader>
<bodyText confidence="0.979848333333333">
There are currently two theories of linguistic variation.
One suggests that there is an underlying probabilistic component
in the competence of each speaker; the other considers the varia-
tion to be an artefact of grouping speakers with discretely dif-
ferent grammars--there being an implicational scaling relation
among the possible grammars..
A rigorous comparison is made by making a variable rule
analysis and an implicational scaling model for data on the de-
letion of the complementizer QUE in Montreal French. Using the
probabilities predicted by the variable rule, the errors expected
in fitting the data to the proposed scale are calculated by Monte
Carla simulation techniques. If the actual number of scaling
errors is significantly less than predicted, then the variable
rule analysis should be rejected. But the number is found to be
exactly as expected from a variable rule analysis.
</bodyText>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.005532">
<title confidence="0.987934">of Linguistics 14 : 1</title>
<author confidence="0.485891">I FINITE STRING</author>
<affiliation confidence="0.534996">TTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS - NUMBER</affiliation>
<abstract confidence="0.981494166666666">was released for production-on March 28, cohtains abstracts Df preprints and pubavailahie to editors on March 20. NOTICE TO AUTHORS those publish. The help makes announcement helpful, On preparing drafts for semipublic circusend copy to the to be On receiving notice of acceptance fot pubin book or tinfgrm as known) of the readers, Finite provide much more timely information. 2 INDEX . •• 4.• •a INDEX . •• 4.• •a • . . . ......... , Current trends in linguistics 12: adjacent arts &amp; sciences Processing 74: proceedings of IFIP Congress . Bulletin of Mathematical Linguistics 21 . , . . • 41••• . • 4 4 •••••• Speech recognition ... s .... . . . . • ..... • . 15 Grammar 30 order and word order change . . . • • system for automatic inflectional analysis (Russian) . . , . . • • . . . 35 . . . • • • • semantics: synonymic means of . . . . . . • OOOOOOOOOO . . • , • • . . . 40 Comprehension • • • . • • . . . . . . . . . . . . a a a ....... . • 47 Information structures . . . OOOOOOOOOOOO • . . . 48 Inference . . .. • • . . . . • • . OOOOOOOO • 40 . . e • • • • a • 50 . . 1 • • • • ....... e • a • ........... • .„...,• . . programming, natural languages . . • . . . ....... . .</abstract>
<title confidence="0.759737">in Rumanities: ICC!-! I for Literary and Computing</title>
<note confidence="0.6135905">Mathematics . . . . . . .......... • • ... 73 General3</note>
<title confidence="0.950778">CURRENT TRENDS IN LINGUISTICS</title>
<author confidence="0.979548">Editor Sebeok</author>
<affiliation confidence="0.97577">Research Center for the Language Sciences Indiana University</affiliation>
<address confidence="0.794137">VOLUME 12: LINGUISTICS AND ADJACENT ARTS AND SCIENCES</address>
<degree confidence="0.7302555">Associate Editors: Arthur S. Abramson, Dell Hymes, Herbert Edward Stankiewicz Assistant Bernard Spolsky Assistants to the</degree>
<author confidence="0.976778">Alexandra Di_Lucia Hadd Zoercher</author>
<affiliation confidence="0.401242">MOUTON Hague •</affiliation>
<date confidence="0.94642">1974</date>
<intro confidence="0.7699">CONTENTS</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>E Lytle</author>
<author>D Packard</author>
</authors>
<institution>Brigham Young University</institution>
<location>Provo, Utah</location>
<marker>Lytle, Packard, </marker>
<rawString>E. Lytle, and D. Packard Brigham Young University Provo, Utah</rawString>
</citation>
<citation valid="true">
<authors>
<author>Annual Preprint</author>
</authors>
<title>Meeting, Association for Computational Linguistics</title>
<date>1973</date>
<booktitle>Proceedings of the [BYU] Linguistics Symposium,</booktitle>
<institution>Brigham Young University</institution>
<marker>Preprint, 1973</marker>
<rawString>Preprint, Annual Meeting, Association for Computational Linguistics Floyd H. Billings, Jr. Brigham Young University Proceedings of the [BYU] Linguistics Symposium, 1973</rawString>
</citation>
<citation valid="false">
<authors>
<author>G Barbara</author>
</authors>
<title>Deutsch Artificial Intelligence Center Stanford Research Institute Menlo Park,</title>
<location>California</location>
<marker>Barbara, </marker>
<rawString>Barbara G. Deutsch Artificial Intelligence Center Stanford Research Institute Menlo Park, California</rawString>
</citation>
<citation valid="false">
<authors>
<author>John W Klovstad</author>
<author>Lee F Mondshein M I T</author>
</authors>
<institution>Lincoln Laboratory</institution>
<location>Lexington, Mass.</location>
<marker>Klovstad, T, </marker>
<rawString>John W. Klovstad and Lee F. Mondshein M.I.T. Lincoln Laboratory Lexington, Mass.</rawString>
</citation>
<citation valid="true">
<date>1975</date>
<booktitle>IEEE Transactions on Acoustics, Speech, and Signal Processing ASSP-23,</booktitle>
<pages>118--123</pages>
<marker>1975</marker>
<rawString>IEEE Transactions on Acoustics, Speech, and Signal Processing ASSP-23, February 1975, 118-123</rawString>
</citation>
<citation valid="false">
<authors>
<author>W A</author>
</authors>
<title>Woods Bolt Beranek and Newman Inc.</title>
<location>Cambridge, Mass.</location>
<marker>A, </marker>
<rawString>W. A. Woods Bolt Beranek and Newman Inc. Cambridge, Mass.</rawString>
</citation>
<citation valid="true">
<date>1975</date>
<booktitle>IEEE Transactions on Acoustics, speech, and Signal Processing ASSP-23,</booktitle>
<pages>2--10</pages>
<marker>1975</marker>
<rawString>IEEE Transactions on Acoustics, speech, and Signal Processing ASSP-23, 1975, 2-10</rawString>
</citation>
<citation valid="false">
<authors>
<author>Wayne A Lea</author>
<author>Mark F Medress</author>
<author>E Toby</author>
</authors>
<institution>Skinner Sperry Univac</institution>
<marker>Lea, Medress, Toby, </marker>
<rawString>Wayne A. Lea, Mark F. Medress, and Toby E. Skinner Sperry Univac</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul</author>
</authors>
<date>1975</date>
<booktitle>IEEE Tr*a12sactions on Acoustics Speech, and Signal Processing ASSP-23,</booktitle>
<pages>30--38</pages>
<location>Minnesota</location>
<marker>Paul, 1975</marker>
<rawString>St. Paul, Minnesota IEEE Tr*a12sactions on Acoustics Speech, and Signal Processing ASSP-23, 1975, 30-38</rawString>
</citation>
<citation valid="false">
<authors>
<author>Paul Rovner</author>
<author>Bonnie Nash-Webber</author>
<author>A William</author>
</authors>
<title>Woods Bolt Beranek and Newman Inc.</title>
<location>Cambridge, Mass</location>
<marker>Rovner, Nash-Webber, William, </marker>
<rawString>Paul Rovner, Bonnie Nash-Webber, and William A. Woods Bolt Beranek and Newman Inc. Cambridge, Mass</rawString>
</citation>
<citation valid="true">
<date>1975</date>
<booktitle>IEEE Transactions on Acoustics, Speech; and Signal Processing ASSP-23,</booktitle>
<pages>136--140</pages>
<marker>1975</marker>
<rawString>IEEE Transactions on Acoustics, Speech; and Signal Processing ASSP-23, 1975, 136-140</rawString>
</citation>
<citation valid="false">
<institution>Bonnie Nash-Webber Bolt Beranek and Newman Inc.</institution>
<marker></marker>
<rawString>Bonnie Nash-Webber Bolt Beranek and Newman Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cambridge</author>
</authors>
<date>1975</date>
<booktitle>Mass IEEE Transactions on Acoustics, Speech, and Signal Pro,ce.ssing ASSP-23,</booktitle>
<pages>124--129</pages>
<marker>Cambridge, 1975</marker>
<rawString>Cambridge, Mass IEEE Transactions on Acoustics, Speech, and Signal Pro,ce.ssing ASSP-23, 1975, 124-129</rawString>
</citation>
<citation valid="true">
<authors>
<author>PROGRESS IN NATURAL LANGUAGE UNDERSTANDING—AN APPLICATION W A</author>
</authors>
<title>Woods Bolt 8eranek and. Newman Cambridge,</title>
<date>1973</date>
<journal>SENTENCE PARAPHRASING FROM A CONCEPTUAL BASE</journal>
<booktitle>Massachusetts Proceedings of the National Computer Conference,</booktitle>
<pages>441--450</pages>
<institution>R. Brent Thompson Brigham Young University</institution>
<marker>A, 1973</marker>
<rawString>PROGRESS IN NATURAL LANGUAGE UNDERSTANDING—AN APPLICATION W. A. Woods Bolt 8eranek and. Newman Cambridge, Massachusetts Proceedings of the National Computer Conference, 1973, 441-450 R. Brent Thompson Brigham Young University ProceedIngs of the [NYU] Linguistics Symposium, 1972 SENTENCE PARAPHRASING FROM A CONCEPTUAL BASE</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Neil</author>
</authors>
<title>Goldman Stanford University Stanford,</title>
<date>1975</date>
<journal>California Communications of the A.C.M.</journal>
<volume>18</volume>
<pages>96--106</pages>
<marker>Neil, 1975</marker>
<rawString>Neil M. Goldman Stanford University Stanford, California Communications of the A.C.M. 18, 1975, 96-106</rawString>
</citation>
<citation valid="false">
<authors>
<author>Sheldon Klein</author>
<author>John F Aeschlimann</author>
<author>Matthew A Appelbaum</author>
<author>David F aalsiger</author>
<author>Elizabeth J Curtis</author>
<author>Mark Foster</author>
<author>S David Kalish</author>
<author>Scott J Kamin</author>
<author>Ying-Da Lee</author>
<author>Lynne A Price</author>
<author>F David</author>
</authors>
<publisher>Salsieder</publisher>
<marker>Klein, Aeschlimann, Appelbaum, aalsiger, Curtis, Foster, Kalish, Kamin, Lee, Price, David, </marker>
<rawString>Sheldon Klein, John F. Aeschlimann, Matthew A. Appelbaum, David F. aalsiger, Elizabeth J. Curtis, Mark Foster, S. David Kalish, Scott J. Kamin, Ying-Da Lee, Lynne A. Price, David F. Salsieder</rawString>
</citation>
<citation valid="false">
<institution>Computer Sciences Department University of Wisconsin Madison</institution>
<marker></marker>
<rawString>Computer Sciences Department University of Wisconsin Madison</rawString>
</citation>
<citation valid="false">
<title>The plot of several myths is given in relational form; the structure Propp suggested is given similarly. Compatibility of selections of characters, objects, and functions is controlled by subscripts, etc. Programs, grammars, traces, and output are exhibited and commented.</title>
<date>1974</date>
<booktitle>Information structures INFORMATION SYSTEMS: FECORDS, RELATIONS, SETS, ENTITIES, AND THINGS</booktitle>
<tech>Technical Report #226,</tech>
<pages>226--74</pages>
<marker>1974</marker>
<rawString>Technical Report #226, October 1974 WIS-CS-226-74 The plot of several myths is given in relational form; the structure Propp suggested is given similarly. Compatibility of selections of characters, objects, and functions is controlled by subscripts, etc. Programs, grammars, traces, and output are exhibited and commented. Information structures INFORMATION SYSTEMS: FECORDS, RELATIONS, SETS, ENTITIES, AND THINGS</rawString>
</citation>
<citation valid="false">
<authors>
<author>E Michael</author>
</authors>
<institution>Senko Mathematical Sciences Department IBM Research Laboratory</institution>
<location>Yorktown Heights, N.Y.</location>
<marker>Michael, </marker>
<rawString>Michael E. Senko Mathematical Sciences Department IBM Research Laboratory Yorktown Heights, N.Y.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jack Minket</author>
<author>J Gordon</author>
</authors>
<date>1975</date>
<journal>Information Systems,</journal>
<volume>1</volume>
<pages>3--13</pages>
<institution>VanderBrug Department of Computer Science University of Maryland College Park</institution>
<marker>Minket, Gordon, 1975</marker>
<rawString>Information Systems, 1, 1975, 3-13 Jack Minket and Gordon J. VanderBrug Department of Computer Science University of Maryland College Park</rawString>
</citation>
<citation valid="true">
<date>1974</date>
<journal>International Journal of Computer and Information Sciences,</journal>
<volume>3</volume>
<pages>217--250</pages>
<marker>1974</marker>
<rawString>International Journal of Computer and Information Sciences, 3, 3, 1974 217-250</rawString>
</citation>
<citation valid="false">
<authors>
<author>D Sankoff</author>
<author>P Rousseau</author>
</authors>
<marker>Sankoff, Rousseau, </marker>
<rawString>D. Sankoff, and P. Rousseau</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>