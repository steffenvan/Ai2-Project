<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.096558">
<title confidence="0.969662">
Morfessor 2.0: Toolkit for statistical morphological segmentation
</title>
<author confidence="0.949905">
Peter Smit1 Sami Virpioja2
</author>
<email confidence="0.938431">
peter.smit@aalto.fi sami.virpioja@aalto.fi
</email>
<author confidence="0.789283">
Stig-Arne Gr¨onroos1 Mikko Kurimo1
</author>
<email confidence="0.663455">
stig-arne.gronroos@aalto.fi mikko.kurimo@aalto.fi
</email>
<affiliation confidence="0.994941">
1Department of Signal Processing and Acoustics, Aalto University
2Department of Information and Computer Science, Aalto University
</affiliation>
<sectionHeader confidence="0.978746" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999735">
Morfessor is a family of probabilistic ma-
chine learning methods for finding the
morphological segmentation from raw text
data. Recent developments include the de-
velopment of semi-supervised methods for
utilizing annotated data. Morfessor 2.0
is a rewrite of the original, widely-used
Morfessor 1.0 software, with well docu-
mented command-line tools and library in-
terface. It includes new features such as
semi-supervised learning, online training,
and integrated evaluation code.
</bodyText>
<sectionHeader confidence="0.998798" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999819432432432">
In the morphological segmentation task, the goal
is to segment words into morphemes, the small-
est meaning-carrying units. Morfessor is a family
of methods for unsupervised morphological seg-
mentation. The first version of Morfessor, called
Morfessor Baseline, was developed by Creutz and
Lagus (2002) its software implementation, Mor-
fessor 1.0, released by Creutz and Lagus (2005b).
A number of Morfessor variants have been devel-
oped later, including Morfessor Categories-MAP
(Creutz and Lagus, 2005a) and Allomorfessor
(Virpioja et al., 2010). Even though these algo-
rithms improve Morfessor Baseline in some areas,
the Baseline version has stayed popular as a gener-
ally applicable morphological analyzer (Spiegler
et al., 2008; Monson et al., 2010).
Over the past years, Morfessor has been used
for a wide range of languages and applications.
The applications include large vocabulary contin-
uous speech recognition (e.g. Hirsim¨aki et al.,
2006), machine translation (e.g. Virpioja et al.,
2007), and speech retrieval (e.g. Arisoy et al.,
2009). Morfessor is well-suited for languages with
concatenative morphology, and the tested lan-
guages include Finnish and Estonian (Hirsim¨aki
et al., 2009), German (El-Desoky Mousa et al.,
2010), and Turkish (Arisoy et al., 2009).
Morfessor 2.0 is a new implementation of the
Morfessor Baseline algorithm.1 It has been writ-
ten in a modular manner and released as an open
source project with a permissive license to encour-
age extensions. This paper includes a summary of
the Morfessor 2.0 software and a description of the
demonstrations that will be held. An extensive de-
scription of the features in Morfessor 2.0, includ-
ing experiments, is available in the report by Vir-
pioja et al. (2013).
</bodyText>
<sectionHeader confidence="0.871201" genericHeader="method">
2 Morfessor model and algorithms
</sectionHeader>
<bodyText confidence="0.998828">
Models of the Morfessor family are generative
probabilistic models that predict compounds and
their analyses (segmentations) given the model pa-
rameters. We provide a brief overview of the
methodology; Virpioja et al. (2013) should be re-
ferred to for the complete formulas and description
of the model and its training algorithms.
Unlike older Morfessor implementations, Mor-
fessor 2.0 is agnostic in regard to the actual data
being segmented. In addition to morphological
segmentation, it can handle, for example, sentence
chunking. To reflect this we use the following
generic terms: The smallest unit that can be split
will be an atom (letter). A compound (word) is a
sequence of atoms. A construction (morph) is a
sequence of atoms contained inside a compound.
</bodyText>
<subsectionHeader confidence="0.998298">
2.1 Model and cost function
</subsectionHeader>
<bodyText confidence="0.998871">
The cost function of Morfessor Baseline is derived
using maximum a posteriori estimation. That is,
the goal is to find the most likely parameters θ
</bodyText>
<footnote confidence="0.99689125">
1Morfessor 2.0 can be downloaded from the Mor-
pho project website (http://www.cis.hut.fi/
projects/morpho/) or GitHub repository (https:
//github.com/aalto-speech/morfessor).
</footnote>
<page confidence="0.992124">
21
</page>
<note confidence="0.7133655">
Proceedings of the Demonstrations at the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 21–24,
Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.949686">
given the observed training data DW:
</bodyText>
<equation confidence="0.9100065">
θMAP = arg max p(θ)p(DW |θ) (1)
θ
</equation>
<bodyText confidence="0.99997125">
Thus we are maximizing the product of the model
prior p(θ) and the data likelihood p(DW  |θ). As
usual, the cost function to minimize is set as the
minus logarithm of the product:
</bodyText>
<equation confidence="0.952723">
L(θ, DW) = − log p(θ) − log p(DW  |θ). (2)
</equation>
<bodyText confidence="0.999985047619048">
During training, the data likelihood is calcu-
lated using a hidden variable that contains the cur-
rent chosen analyses. Secondly, it is assumed that
the constructions in a compound occur indepen-
dently. This simplifies the data likelihood to the
product of all construction probabilities in the cho-
sen analyses. Unlike previous versions, Morfes-
sor 2.0 includes also the probabilities of the com-
pound boundaries in the data likelihood.
For prior probability, Morfessor Baseline de-
fines a distribution over the lexicon of the model.
The prior assigns higher probability to lexicons
that store fewer and shorter constructions. The
lexicon prior consists of to parts, a product over
the form probabilities and a product over the usage
probabilities. The former includes the probability
of a sequence of atoms and the latter the maxi-
mum likelihood estimates of the constructions. In
contrast to Morfessor 1.0, Morfessor 2.0 currently
supports only an implicit exponential length prior
for the constructions.
</bodyText>
<subsectionHeader confidence="0.999014">
2.2 Training and decoding algorithms
</subsectionHeader>
<bodyText confidence="0.999965333333333">
A Morfessor model can be trained in multiple
ways. The standard batch training uses a local
search utilizing recursive splitting. The model is
initialized with the compounds and the full model
cost is calculated. The data structures are designed
in such way that the cost is efficient compute dur-
ing the training.
In one epoch of the algorithm, all compounds
in the training data are processed. For each com-
pound, all possible two-part segmentations are
tested. If one of the segmentations yields the low-
est cost, it is selected and the segmentation is tried
recursively on the resulting segments. In each step
of the algorithm, the cost can only decrease or stay
the same, thus guaranteeing convergence. The al-
gorithm is stopped when the cost decreases less
than a configurable threshold value in one epoch.
An extension of the Viterbi algorithm is used
for decoding, that is, finding the optimal segmen-
tations for new compound forms without changing
the model parameters.
</bodyText>
<sectionHeader confidence="0.945301" genericHeader="method">
3 New features in Morfessor 2.0
</sectionHeader>
<subsectionHeader confidence="0.986186">
3.1 Semi-supervised extensions
</subsectionHeader>
<bodyText confidence="0.99998778125">
One important feature that has been implemented
in Morfessor 2.0 are the semi-supervised exten-
sions as introduced by Kohonen et al. (2010)
Morfessor Baseline tends to undersegment
when the model is trained for morphological seg-
mentation using a large corpus (Creutz and Lagus,
2005b). Oversegmentation or undersegmentation
of the method are easy to control heuristically
by including a weight parameter α for the likeli-
hood in the cost function. A low α increases the
priors influence, favoring small construction lexi-
cons, while a high value increases the data likeli-
hood influence, favoring longer constructions.
In semi-supervised Morfessor, the likelihood of
an annotated data set is added to the cost function.
As the amount of annotated data is typically much
lower than the amount of unannotated data, its ef-
fect on the cost function may be very small com-
pared to the likelihood of the unannotated data.
To control the effect of the annotations, a sepa-
rate weight parameter β can be included for the
annotated data likelihood.
If separate development data set is available for
automatic evaluation of the model, the likelihoods
weights can be optimized to give the best out-
put. This can be done by brute force using a grid
search. However, Morfessor 2.0 implementation
includes a simple heuristic for automatically tun-
ing the value of α during the training, trying to
balance precision and recall. A simple heuristic,
which gives an equivalent contribution to the an-
notated data, is used for β.
</bodyText>
<subsectionHeader confidence="0.987916">
3.2 On-line training
</subsectionHeader>
<bodyText confidence="0.999963222222222">
In addition to the batch training mode, Morfes-
sor 2.0 supports on-line training mode, in which
unannotated text is processed one compound at a
time. This makes it simple to, for example, adapt
pre-trained models for new type of data. As fre-
quent compounds are encountered many times in
running text, Morfessor 2.0 includes an option for
randomly skipping compounds and constructions
that have been recently analyzed. The random
</bodyText>
<page confidence="0.99866">
22
</page>
<figureCaption confidence="0.99974">
Figure 1: Screenshot from the Morfessor 2.0 demo.
</figureCaption>
<bodyText confidence="0.89784">
skips can also be used to speed up the batch train-
ing.
</bodyText>
<subsectionHeader confidence="0.994704">
3.3 Integrated evaluation code
</subsectionHeader>
<bodyText confidence="0.999903083333333">
One common method for evaluating the perfor-
mance of a Morfessor model is to compare it
against a gold standard segmentation using seg-
mentation boundary precision and recall. To make
the evaluation easy, the necessary tools for calcu-
lating the BPR metric by (Virpioja et al., 2011)
are included in Morfessor 2.0. For significance
testing when comparing multiple models, we have
included the Wilcoxon signed-rank test. Both the
evaluation code and statistical testing code are ac-
cessible from both the command line and the li-
brary interface.
</bodyText>
<subsectionHeader confidence="0.961604">
3.4 N-best segmentation
</subsectionHeader>
<bodyText confidence="0.9999286">
In order to generate multiple segmentations for a
single compound, Morfessor 2.0 includes a n-best
Viterbi algorithm. It allows extraction of all possi-
ble segmentations for a compound and the proba-
bilities of the segmentations.
</bodyText>
<sectionHeader confidence="0.998951" genericHeader="conclusions">
4 Demonstration
</sectionHeader>
<bodyText confidence="0.9997905">
In the demonstration session, multiple features
and usages of Morfessor will be shown.
</bodyText>
<subsectionHeader confidence="0.928545">
4.1 Web-based demonstration
</subsectionHeader>
<bodyText confidence="0.97379">
A live demonstration will be given of segmenting
text with Morfessor 2.0 for different language and
training data options. In a web interface, the user
can choose a language, select the size of the train-
ing corpus and other options. After that a word
can be given which will be segmented using n-best
Viterbi, showing the 5 best results.
A list of planned languages can be found in Ta-
ble 1. A screen shot of the demo interface is shown
in Figure 1.
</bodyText>
<table confidence="0.989228285714286">
Languages # Words # Word forms
English 62M 384.903
Estonian 212M 3.908.820
Finnish 36M 2.206.719
German 46M 1.266.159
Swedish 1M 92237
Turkish 12M 617.298
</table>
<tableCaption confidence="0.9607425">
Table 1: List of available languages for Morfessor
2.0 demonstration.
</tableCaption>
<subsectionHeader confidence="0.99861">
4.2 Command line interface
</subsectionHeader>
<bodyText confidence="0.99994775">
The new command line interface will be demon-
strated to train and evaluate Morfessor models
from texts in different languages. A diagram of
the tools is shown in Figure 2
</bodyText>
<subsectionHeader confidence="0.99907">
4.3 Library interface
</subsectionHeader>
<bodyText confidence="0.999811333333333">
Interfacing with the Morfessor 2.0 Python library
will be demonstrated for building own scientific
experiments, as well as integrating Morfessor in
</bodyText>
<page confidence="0.994731">
23
</page>
<figure confidence="0.92441">
Training data
morfessor-train
Morfessor
model
</figure>
<figureCaption confidence="0.9973785">
Figure 2: The standard workflow for Morfessor
command line tools
</figureCaption>
<bodyText confidence="0.982817">
bigger project. Also the code of the Web based
demonstration will be shown as an example.
</bodyText>
<sectionHeader confidence="0.971601" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999411888888889">
The authors have received funding from the EC’s
7th Framework Programme (FP7/2007–2013) un-
der grant agreement n°287678 and the Academy
of Finland under the Finnish Centre of Excel-
lence Program 2012–2017 (grant n°251170) and
the LASTU Programme (grants n°256887 and
259934). The experiments were performed us-
ing computer resources within the Aalto Univer-
sity School of Science ”Science-IT” project.
</bodyText>
<sectionHeader confidence="0.998617" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999270154929577">
E. Arisoy, D. Can, S. Parlak, H. Sak, and M. Saraclar.
2009. Turkish broadcast news transcription and re-
trieval. Audio, Speech, and Language Processing,
IEEE Transactions on, 17(5):874–883.
M. Creutz and K. Lagus. 2002. Unsupervised discov-
ery of morphemes. In Mike Maxwell, editor, Pro-
ceedings of the ACL-02 Workshop on Morphological
and Phonological Learning, pages 21–30. Associa-
tion for Computational Linguistics, July.
M. Creutz and K. Lagus. 2005a. Inducing the mor-
phological lexicon of a natural language from unan-
notated text. In Proceedings of AKRR’05, Interna-
tional and Interdisciplinary Conference on Adaptive
Knowledge Representation and Reasoning, pages
106–113, Espoo, Finland, June. Helsinki University
of Technology.
M. Creutz and K. Lagus. 2005b. Unsupervised
morpheme segmentation and morphology induction
from text corpora using Morfessor 1.0. Technical
Report A81, Publications in Computer and Informa-
tion Science, Helsinki University of Technology.
A. El-Desoky Mousa, M. Ali Basha Shaik, R. Schluter,
and H. Ney. 2010. Sub-lexical language models for
German LVCSR. In Spoken Language Technology
Workshop (SLT), 2010 IEEE, pages 171–176. IEEE.
T. Hirsim¨aki, M. Creutz, V. Siivola, M. Kurimo, S. Vir-
pioja, and J. Pylkk¨onen. 2006. Unlimited vocabu-
lary speech recognition with morph language mod-
els applied to Finnish. Computer Speech &amp; Lan-
guage, 20(4):515–541.
T. Hirsim¨aki, J. Pylkk¨onen, and M. Kurimo. 2009.
Importance of high-order n-gram models in morph-
based speech recognition. Audio, Speech, and
Language Processing, IEEE Transactions on,
17(4):724–732.
O. Kohonen, S. Virpioja, and K. Lagus. 2010. Semi-
supervised learning of concatenative morphology.
In Proceedings of the 11th Meeting of the ACL Spe-
cial Interest Group on Computational Morphology
and Phonology, pages 78–86, Uppsala, Sweden,
July. Association for Computational Linguistics.
C. Monson, K. Hollingshead, and B. Roark. 2010.
Simulating morphological analyzers with stochastic
taggers for confidence estimation. In Multilingual
Information Access Evaluation I. Text Retrieval Ex-
periments, pages 649–657. Springer.
S. Spiegler, B. Gol´enia, K. Shalonova, P. Flach, and
R. Tucker. 2008. Learning the morphology of zulu
with different degrees of supervision. In Spoken
Language Technology Workshop, 2008. SLT 2008.
IEEE, pages 9–12. IEEE.
S. Virpioja, J. V¨ayrynen, M. Creutz, and M. Sadeniemi.
2007. Morphology-aware statistical machine trans-
lation based on morphs induced in an unsupervised
manner. In Proceedings of the Machine Translation
Summit XI, pages 491–498, Copenhagen, Denmark,
September.
S. Virpioja, O. Kohonen, and K. Lagus. 2010. Unsu-
pervised morpheme analysis with Allomorfessor. In
Multilingual Information Access Evaluation I. Text
Retrieval Experiments, volume 6241 of LNCS, pages
609–616. Springer Berlin / Heidelberg.
S. Virpioja, V. Turunen, S. Spiegler, O. Kohonen, and
M. Kurimo. 2011. Empirical comparison of evalua-
tion methods for unsupervised learning of morphol-
ogy. TAL, 52(2):45–90.
S. Virpioja, P. Smit, S. Gr¨onroos, and M. Kurimo.
2013. Morfessor 2.0: Python implementation and
extensions for Morfessor Baseline. Report 25/2013
in Aalto University publication series SCIENCE +
TECHNOLOGY, Aalto University, Finland.
</reference>
<figure confidence="0.997628555555556">
morfessor-
evaluate
Gold standard
BPR-scores
Segmented corpus
morfessor-
segment
Corpus
Annotation data
</figure>
<page confidence="0.979869">
24
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.278615">
<title confidence="0.774911">Morfessor 2.0: Toolkit for statistical morphological segmentation</title>
<abstract confidence="0.654381333333333">peter.smit@aalto.fi sami.virpioja@aalto.fi stig-arne.gronroos@aalto.fi mikko.kurimo@aalto.fi of Signal Processing and Acoustics, Aalto</abstract>
<affiliation confidence="0.844532">of Information and Computer Science, Aalto University</affiliation>
<abstract confidence="0.998396384615385">Morfessor is a family of probabilistic machine learning methods for finding the morphological segmentation from raw text data. Recent developments include the development of semi-supervised methods for utilizing annotated data. Morfessor 2.0 is a rewrite of the original, widely-used Morfessor 1.0 software, with well documented command-line tools and library interface. It includes new features such as semi-supervised learning, online training, and integrated evaluation code.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Arisoy</author>
<author>D Can</author>
<author>S Parlak</author>
<author>H Sak</author>
<author>M Saraclar</author>
</authors>
<title>Turkish broadcast news transcription and retrieval. Audio, Speech, and Language Processing,</title>
<date>2009</date>
<journal>IEEE Transactions on,</journal>
<volume>17</volume>
<issue>5</issue>
<contexts>
<context position="1899" citStr="Arisoy et al., 2009" startWordPosition="258" endWordPosition="261">eveloped later, including Morfessor Categories-MAP (Creutz and Lagus, 2005a) and Allomorfessor (Virpioja et al., 2010). Even though these algorithms improve Morfessor Baseline in some areas, the Baseline version has stayed popular as a generally applicable morphological analyzer (Spiegler et al., 2008; Monson et al., 2010). Over the past years, Morfessor has been used for a wide range of languages and applications. The applications include large vocabulary continuous speech recognition (e.g. Hirsim¨aki et al., 2006), machine translation (e.g. Virpioja et al., 2007), and speech retrieval (e.g. Arisoy et al., 2009). Morfessor is well-suited for languages with concatenative morphology, and the tested languages include Finnish and Estonian (Hirsim¨aki et al., 2009), German (El-Desoky Mousa et al., 2010), and Turkish (Arisoy et al., 2009). Morfessor 2.0 is a new implementation of the Morfessor Baseline algorithm.1 It has been written in a modular manner and released as an open source project with a permissive license to encourage extensions. This paper includes a summary of the Morfessor 2.0 software and a description of the demonstrations that will be held. An extensive description of the features in Morf</context>
</contexts>
<marker>Arisoy, Can, Parlak, Sak, Saraclar, 2009</marker>
<rawString>E. Arisoy, D. Can, S. Parlak, H. Sak, and M. Saraclar. 2009. Turkish broadcast news transcription and retrieval. Audio, Speech, and Language Processing, IEEE Transactions on, 17(5):874–883.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Creutz</author>
<author>K Lagus</author>
</authors>
<title>Unsupervised discovery of morphemes.</title>
<date>2002</date>
<booktitle>Proceedings of the ACL-02 Workshop on Morphological and Phonological Learning,</booktitle>
<pages>21--30</pages>
<editor>In Mike Maxwell, editor,</editor>
<contexts>
<context position="1154" citStr="Creutz and Lagus (2002)" startWordPosition="146" endWordPosition="149"> of semi-supervised methods for utilizing annotated data. Morfessor 2.0 is a rewrite of the original, widely-used Morfessor 1.0 software, with well documented command-line tools and library interface. It includes new features such as semi-supervised learning, online training, and integrated evaluation code. 1 Introduction In the morphological segmentation task, the goal is to segment words into morphemes, the smallest meaning-carrying units. Morfessor is a family of methods for unsupervised morphological segmentation. The first version of Morfessor, called Morfessor Baseline, was developed by Creutz and Lagus (2002) its software implementation, Morfessor 1.0, released by Creutz and Lagus (2005b). A number of Morfessor variants have been developed later, including Morfessor Categories-MAP (Creutz and Lagus, 2005a) and Allomorfessor (Virpioja et al., 2010). Even though these algorithms improve Morfessor Baseline in some areas, the Baseline version has stayed popular as a generally applicable morphological analyzer (Spiegler et al., 2008; Monson et al., 2010). Over the past years, Morfessor has been used for a wide range of languages and applications. The applications include large vocabulary continuous spe</context>
</contexts>
<marker>Creutz, Lagus, 2002</marker>
<rawString>M. Creutz and K. Lagus. 2002. Unsupervised discovery of morphemes. In Mike Maxwell, editor, Proceedings of the ACL-02 Workshop on Morphological and Phonological Learning, pages 21–30. Association for Computational Linguistics, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Creutz</author>
<author>K Lagus</author>
</authors>
<title>Inducing the morphological lexicon of a natural language from unannotated text.</title>
<date>2005</date>
<booktitle>In Proceedings of AKRR’05, International and Interdisciplinary Conference on Adaptive Knowledge Representation and Reasoning,</booktitle>
<pages>106--113</pages>
<institution>Helsinki University of Technology.</institution>
<location>Espoo, Finland,</location>
<contexts>
<context position="1233" citStr="Creutz and Lagus (2005" startWordPosition="158" endWordPosition="161">rite of the original, widely-used Morfessor 1.0 software, with well documented command-line tools and library interface. It includes new features such as semi-supervised learning, online training, and integrated evaluation code. 1 Introduction In the morphological segmentation task, the goal is to segment words into morphemes, the smallest meaning-carrying units. Morfessor is a family of methods for unsupervised morphological segmentation. The first version of Morfessor, called Morfessor Baseline, was developed by Creutz and Lagus (2002) its software implementation, Morfessor 1.0, released by Creutz and Lagus (2005b). A number of Morfessor variants have been developed later, including Morfessor Categories-MAP (Creutz and Lagus, 2005a) and Allomorfessor (Virpioja et al., 2010). Even though these algorithms improve Morfessor Baseline in some areas, the Baseline version has stayed popular as a generally applicable morphological analyzer (Spiegler et al., 2008; Monson et al., 2010). Over the past years, Morfessor has been used for a wide range of languages and applications. The applications include large vocabulary continuous speech recognition (e.g. Hirsim¨aki et al., 2006), machine translation (e.g. Virpi</context>
<context position="6614" citStr="Creutz and Lagus, 2005" startWordPosition="1007" endWordPosition="1010">ergence. The algorithm is stopped when the cost decreases less than a configurable threshold value in one epoch. An extension of the Viterbi algorithm is used for decoding, that is, finding the optimal segmentations for new compound forms without changing the model parameters. 3 New features in Morfessor 2.0 3.1 Semi-supervised extensions One important feature that has been implemented in Morfessor 2.0 are the semi-supervised extensions as introduced by Kohonen et al. (2010) Morfessor Baseline tends to undersegment when the model is trained for morphological segmentation using a large corpus (Creutz and Lagus, 2005b). Oversegmentation or undersegmentation of the method are easy to control heuristically by including a weight parameter α for the likelihood in the cost function. A low α increases the priors influence, favoring small construction lexicons, while a high value increases the data likelihood influence, favoring longer constructions. In semi-supervised Morfessor, the likelihood of an annotated data set is added to the cost function. As the amount of annotated data is typically much lower than the amount of unannotated data, its effect on the cost function may be very small compared to the likeli</context>
</contexts>
<marker>Creutz, Lagus, 2005</marker>
<rawString>M. Creutz and K. Lagus. 2005a. Inducing the morphological lexicon of a natural language from unannotated text. In Proceedings of AKRR’05, International and Interdisciplinary Conference on Adaptive Knowledge Representation and Reasoning, pages 106–113, Espoo, Finland, June. Helsinki University of Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Creutz</author>
<author>K Lagus</author>
</authors>
<title>Unsupervised morpheme segmentation and morphology induction from text corpora using Morfessor 1.0.</title>
<date>2005</date>
<tech>Technical Report A81,</tech>
<institution>Publications in Computer and Information Science, Helsinki University of Technology.</institution>
<contexts>
<context position="1233" citStr="Creutz and Lagus (2005" startWordPosition="158" endWordPosition="161">rite of the original, widely-used Morfessor 1.0 software, with well documented command-line tools and library interface. It includes new features such as semi-supervised learning, online training, and integrated evaluation code. 1 Introduction In the morphological segmentation task, the goal is to segment words into morphemes, the smallest meaning-carrying units. Morfessor is a family of methods for unsupervised morphological segmentation. The first version of Morfessor, called Morfessor Baseline, was developed by Creutz and Lagus (2002) its software implementation, Morfessor 1.0, released by Creutz and Lagus (2005b). A number of Morfessor variants have been developed later, including Morfessor Categories-MAP (Creutz and Lagus, 2005a) and Allomorfessor (Virpioja et al., 2010). Even though these algorithms improve Morfessor Baseline in some areas, the Baseline version has stayed popular as a generally applicable morphological analyzer (Spiegler et al., 2008; Monson et al., 2010). Over the past years, Morfessor has been used for a wide range of languages and applications. The applications include large vocabulary continuous speech recognition (e.g. Hirsim¨aki et al., 2006), machine translation (e.g. Virpi</context>
<context position="6614" citStr="Creutz and Lagus, 2005" startWordPosition="1007" endWordPosition="1010">ergence. The algorithm is stopped when the cost decreases less than a configurable threshold value in one epoch. An extension of the Viterbi algorithm is used for decoding, that is, finding the optimal segmentations for new compound forms without changing the model parameters. 3 New features in Morfessor 2.0 3.1 Semi-supervised extensions One important feature that has been implemented in Morfessor 2.0 are the semi-supervised extensions as introduced by Kohonen et al. (2010) Morfessor Baseline tends to undersegment when the model is trained for morphological segmentation using a large corpus (Creutz and Lagus, 2005b). Oversegmentation or undersegmentation of the method are easy to control heuristically by including a weight parameter α for the likelihood in the cost function. A low α increases the priors influence, favoring small construction lexicons, while a high value increases the data likelihood influence, favoring longer constructions. In semi-supervised Morfessor, the likelihood of an annotated data set is added to the cost function. As the amount of annotated data is typically much lower than the amount of unannotated data, its effect on the cost function may be very small compared to the likeli</context>
</contexts>
<marker>Creutz, Lagus, 2005</marker>
<rawString>M. Creutz and K. Lagus. 2005b. Unsupervised morpheme segmentation and morphology induction from text corpora using Morfessor 1.0. Technical Report A81, Publications in Computer and Information Science, Helsinki University of Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A El-Desoky Mousa</author>
<author>M Ali Basha Shaik</author>
<author>R Schluter</author>
<author>H Ney</author>
</authors>
<title>Sub-lexical language models for German LVCSR.</title>
<date>2010</date>
<booktitle>In Spoken Language Technology Workshop (SLT), 2010 IEEE,</booktitle>
<pages>171--176</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="2089" citStr="Mousa et al., 2010" startWordPosition="285" endWordPosition="288">the Baseline version has stayed popular as a generally applicable morphological analyzer (Spiegler et al., 2008; Monson et al., 2010). Over the past years, Morfessor has been used for a wide range of languages and applications. The applications include large vocabulary continuous speech recognition (e.g. Hirsim¨aki et al., 2006), machine translation (e.g. Virpioja et al., 2007), and speech retrieval (e.g. Arisoy et al., 2009). Morfessor is well-suited for languages with concatenative morphology, and the tested languages include Finnish and Estonian (Hirsim¨aki et al., 2009), German (El-Desoky Mousa et al., 2010), and Turkish (Arisoy et al., 2009). Morfessor 2.0 is a new implementation of the Morfessor Baseline algorithm.1 It has been written in a modular manner and released as an open source project with a permissive license to encourage extensions. This paper includes a summary of the Morfessor 2.0 software and a description of the demonstrations that will be held. An extensive description of the features in Morfessor 2.0, including experiments, is available in the report by Virpioja et al. (2013). 2 Morfessor model and algorithms Models of the Morfessor family are generative probabilistic models th</context>
</contexts>
<marker>Mousa, Shaik, Schluter, Ney, 2010</marker>
<rawString>A. El-Desoky Mousa, M. Ali Basha Shaik, R. Schluter, and H. Ney. 2010. Sub-lexical language models for German LVCSR. In Spoken Language Technology Workshop (SLT), 2010 IEEE, pages 171–176. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Hirsim¨aki</author>
<author>M Creutz</author>
<author>V Siivola</author>
<author>M Kurimo</author>
<author>S Virpioja</author>
<author>J Pylkk¨onen</author>
</authors>
<title>Unlimited vocabulary speech recognition with morph language models applied to Finnish.</title>
<date>2006</date>
<journal>Computer Speech &amp; Language,</journal>
<volume>20</volume>
<issue>4</issue>
<marker>Hirsim¨aki, Creutz, Siivola, Kurimo, Virpioja, Pylkk¨onen, 2006</marker>
<rawString>T. Hirsim¨aki, M. Creutz, V. Siivola, M. Kurimo, S. Virpioja, and J. Pylkk¨onen. 2006. Unlimited vocabulary speech recognition with morph language models applied to Finnish. Computer Speech &amp; Language, 20(4):515–541.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Hirsim¨aki</author>
<author>J Pylkk¨onen</author>
<author>M Kurimo</author>
</authors>
<title>Importance of high-order n-gram models in morphbased speech recognition. Audio, Speech, and Language Processing,</title>
<date>2009</date>
<journal>IEEE Transactions on,</journal>
<volume>17</volume>
<issue>4</issue>
<marker>Hirsim¨aki, Pylkk¨onen, Kurimo, 2009</marker>
<rawString>T. Hirsim¨aki, J. Pylkk¨onen, and M. Kurimo. 2009. Importance of high-order n-gram models in morphbased speech recognition. Audio, Speech, and Language Processing, IEEE Transactions on, 17(4):724–732.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Kohonen</author>
<author>S Virpioja</author>
<author>K Lagus</author>
</authors>
<title>Semisupervised learning of concatenative morphology.</title>
<date>2010</date>
<booktitle>In Proceedings of the 11th Meeting of the ACL Special Interest Group on Computational Morphology and Phonology,</booktitle>
<pages>78--86</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Uppsala, Sweden,</location>
<contexts>
<context position="6471" citStr="Kohonen et al. (2010)" startWordPosition="985" endWordPosition="988">ried recursively on the resulting segments. In each step of the algorithm, the cost can only decrease or stay the same, thus guaranteeing convergence. The algorithm is stopped when the cost decreases less than a configurable threshold value in one epoch. An extension of the Viterbi algorithm is used for decoding, that is, finding the optimal segmentations for new compound forms without changing the model parameters. 3 New features in Morfessor 2.0 3.1 Semi-supervised extensions One important feature that has been implemented in Morfessor 2.0 are the semi-supervised extensions as introduced by Kohonen et al. (2010) Morfessor Baseline tends to undersegment when the model is trained for morphological segmentation using a large corpus (Creutz and Lagus, 2005b). Oversegmentation or undersegmentation of the method are easy to control heuristically by including a weight parameter α for the likelihood in the cost function. A low α increases the priors influence, favoring small construction lexicons, while a high value increases the data likelihood influence, favoring longer constructions. In semi-supervised Morfessor, the likelihood of an annotated data set is added to the cost function. As the amount of annot</context>
</contexts>
<marker>Kohonen, Virpioja, Lagus, 2010</marker>
<rawString>O. Kohonen, S. Virpioja, and K. Lagus. 2010. Semisupervised learning of concatenative morphology. In Proceedings of the 11th Meeting of the ACL Special Interest Group on Computational Morphology and Phonology, pages 78–86, Uppsala, Sweden, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Monson</author>
<author>K Hollingshead</author>
<author>B Roark</author>
</authors>
<title>Simulating morphological analyzers with stochastic taggers for confidence estimation. In Multilingual Information Access Evaluation I. Text Retrieval Experiments,</title>
<date>2010</date>
<pages>649--657</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="1603" citStr="Monson et al., 2010" startWordPosition="213" endWordPosition="216">sor is a family of methods for unsupervised morphological segmentation. The first version of Morfessor, called Morfessor Baseline, was developed by Creutz and Lagus (2002) its software implementation, Morfessor 1.0, released by Creutz and Lagus (2005b). A number of Morfessor variants have been developed later, including Morfessor Categories-MAP (Creutz and Lagus, 2005a) and Allomorfessor (Virpioja et al., 2010). Even though these algorithms improve Morfessor Baseline in some areas, the Baseline version has stayed popular as a generally applicable morphological analyzer (Spiegler et al., 2008; Monson et al., 2010). Over the past years, Morfessor has been used for a wide range of languages and applications. The applications include large vocabulary continuous speech recognition (e.g. Hirsim¨aki et al., 2006), machine translation (e.g. Virpioja et al., 2007), and speech retrieval (e.g. Arisoy et al., 2009). Morfessor is well-suited for languages with concatenative morphology, and the tested languages include Finnish and Estonian (Hirsim¨aki et al., 2009), German (El-Desoky Mousa et al., 2010), and Turkish (Arisoy et al., 2009). Morfessor 2.0 is a new implementation of the Morfessor Baseline algorithm.1 I</context>
</contexts>
<marker>Monson, Hollingshead, Roark, 2010</marker>
<rawString>C. Monson, K. Hollingshead, and B. Roark. 2010. Simulating morphological analyzers with stochastic taggers for confidence estimation. In Multilingual Information Access Evaluation I. Text Retrieval Experiments, pages 649–657. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Spiegler</author>
<author>B Gol´enia</author>
<author>K Shalonova</author>
<author>P Flach</author>
<author>R Tucker</author>
</authors>
<title>Learning the morphology of zulu with different degrees of supervision.</title>
<date>2008</date>
<booktitle>In Spoken Language Technology Workshop,</booktitle>
<pages>9--12</pages>
<publisher>IEEE,</publisher>
<marker>Spiegler, Gol´enia, Shalonova, Flach, Tucker, 2008</marker>
<rawString>S. Spiegler, B. Gol´enia, K. Shalonova, P. Flach, and R. Tucker. 2008. Learning the morphology of zulu with different degrees of supervision. In Spoken Language Technology Workshop, 2008. SLT 2008. IEEE, pages 9–12. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Virpioja</author>
<author>J V¨ayrynen</author>
<author>M Creutz</author>
<author>M Sadeniemi</author>
</authors>
<title>Morphology-aware statistical machine translation based on morphs induced in an unsupervised manner.</title>
<date>2007</date>
<booktitle>In Proceedings of the Machine Translation Summit XI,</booktitle>
<pages>491--498</pages>
<location>Copenhagen, Denmark,</location>
<marker>Virpioja, V¨ayrynen, Creutz, Sadeniemi, 2007</marker>
<rawString>S. Virpioja, J. V¨ayrynen, M. Creutz, and M. Sadeniemi. 2007. Morphology-aware statistical machine translation based on morphs induced in an unsupervised manner. In Proceedings of the Machine Translation Summit XI, pages 491–498, Copenhagen, Denmark, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Virpioja</author>
<author>O Kohonen</author>
<author>K Lagus</author>
</authors>
<title>Unsupervised morpheme analysis with Allomorfessor. In Multilingual Information Access Evaluation I. Text Retrieval Experiments,</title>
<date>2010</date>
<volume>6241</volume>
<pages>609--616</pages>
<publisher>Springer</publisher>
<location>Berlin / Heidelberg.</location>
<contexts>
<context position="1397" citStr="Virpioja et al., 2010" startWordPosition="181" endWordPosition="184">vised learning, online training, and integrated evaluation code. 1 Introduction In the morphological segmentation task, the goal is to segment words into morphemes, the smallest meaning-carrying units. Morfessor is a family of methods for unsupervised morphological segmentation. The first version of Morfessor, called Morfessor Baseline, was developed by Creutz and Lagus (2002) its software implementation, Morfessor 1.0, released by Creutz and Lagus (2005b). A number of Morfessor variants have been developed later, including Morfessor Categories-MAP (Creutz and Lagus, 2005a) and Allomorfessor (Virpioja et al., 2010). Even though these algorithms improve Morfessor Baseline in some areas, the Baseline version has stayed popular as a generally applicable morphological analyzer (Spiegler et al., 2008; Monson et al., 2010). Over the past years, Morfessor has been used for a wide range of languages and applications. The applications include large vocabulary continuous speech recognition (e.g. Hirsim¨aki et al., 2006), machine translation (e.g. Virpioja et al., 2007), and speech retrieval (e.g. Arisoy et al., 2009). Morfessor is well-suited for languages with concatenative morphology, and the tested languages i</context>
</contexts>
<marker>Virpioja, Kohonen, Lagus, 2010</marker>
<rawString>S. Virpioja, O. Kohonen, and K. Lagus. 2010. Unsupervised morpheme analysis with Allomorfessor. In Multilingual Information Access Evaluation I. Text Retrieval Experiments, volume 6241 of LNCS, pages 609–616. Springer Berlin / Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Virpioja</author>
<author>V Turunen</author>
<author>S Spiegler</author>
<author>O Kohonen</author>
<author>M Kurimo</author>
</authors>
<title>Empirical comparison of evaluation methods for unsupervised learning of morphology.</title>
<date>2011</date>
<journal>TAL,</journal>
<volume>52</volume>
<issue>2</issue>
<contexts>
<context position="8703" citStr="Virpioja et al., 2011" startWordPosition="1352" endWordPosition="1355">of data. As frequent compounds are encountered many times in running text, Morfessor 2.0 includes an option for randomly skipping compounds and constructions that have been recently analyzed. The random 22 Figure 1: Screenshot from the Morfessor 2.0 demo. skips can also be used to speed up the batch training. 3.3 Integrated evaluation code One common method for evaluating the performance of a Morfessor model is to compare it against a gold standard segmentation using segmentation boundary precision and recall. To make the evaluation easy, the necessary tools for calculating the BPR metric by (Virpioja et al., 2011) are included in Morfessor 2.0. For significance testing when comparing multiple models, we have included the Wilcoxon signed-rank test. Both the evaluation code and statistical testing code are accessible from both the command line and the library interface. 3.4 N-best segmentation In order to generate multiple segmentations for a single compound, Morfessor 2.0 includes a n-best Viterbi algorithm. It allows extraction of all possible segmentations for a compound and the probabilities of the segmentations. 4 Demonstration In the demonstration session, multiple features and usages of Morfessor </context>
</contexts>
<marker>Virpioja, Turunen, Spiegler, Kohonen, Kurimo, 2011</marker>
<rawString>S. Virpioja, V. Turunen, S. Spiegler, O. Kohonen, and M. Kurimo. 2011. Empirical comparison of evaluation methods for unsupervised learning of morphology. TAL, 52(2):45–90.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Virpioja</author>
<author>P Smit</author>
<author>S Gr¨onroos</author>
<author>M Kurimo</author>
</authors>
<title>Morfessor 2.0: Python implementation and extensions for Morfessor Baseline. Report 25/2013</title>
<date>2013</date>
<booktitle>in Aalto University publication series SCIENCE + TECHNOLOGY,</booktitle>
<institution>Aalto University,</institution>
<marker>Virpioja, Smit, Gr¨onroos, Kurimo, 2013</marker>
<rawString>S. Virpioja, P. Smit, S. Gr¨onroos, and M. Kurimo. 2013. Morfessor 2.0: Python implementation and extensions for Morfessor Baseline. Report 25/2013 in Aalto University publication series SCIENCE + TECHNOLOGY, Aalto University, Finland.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>