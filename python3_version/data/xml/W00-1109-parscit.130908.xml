<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<note confidence="0.784307333333333">
From Information Retrieval to Information Extraction
David Milward and James Thomas
SRI International
Suite 23 Millers Yard
Mill Lane
Cambridge
</note>
<address confidence="0.796833">
CB2 1RQ
</address>
<email confidence="0.997826">
milward@cam.sri.com, jrt1003@cam.sri.com
</email>
<sectionHeader confidence="0.997376" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999347818181818">
This paper describes a system which en-
ables users to create on-the-fly queries
which involve not just keywords, but
also sortal constraints and linguistic con-
straints. The user can specify how the
results should be presented e.g. in terms
of links to documents, or as table en-
tries. The aim is to bridge the gap be-
tween keyword based Information Re-
trieval and pattern based Information
Extraction.
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.982005">
The amount of information available electronically
in a free-text format is ever increasing. People re-
quire tools that give them the best possible answer
to their queries even when a full answer may not
be available.
Current web Information Retrieval (IR) engines
standardly retrieve URLs to whole documents,
and typical user queries are just an unordered
set of keywords. This is robust and allows un-
restricted queries, but precision can be poor, and
the output is not particularly convenient for many
queries. For example, if we are interested in e.g.
companies associated with Mr. Jones, we are likely
to prefer an output in terms of an alphabetically
ordered list of companies (with links to the sen-
tences in which they appear) rather than a list of
URLs.
Information Extraction (IE) systems pro-
vide better presentation of results (e.g. tables,
database records etc.), and tend to include more
precise searches which depend upon not just find-
ing keywords but finding them in particular posi-
tions or in particular grammatical relationships.
However, current IE systems typically require
queries to be programmed beforehand, so are suit-
able only for cases where the same query is to be
used time and again e.g. in the processing of a
newsfeed.
Customisation of an IE system involves two ma-
jor tasks:
</bodyText>
<listItem confidence="0.996082333333333">
• adapting the information extraction system
to a new domain, e.g. adding vocabulary, new
grammatical constructions and domain ontol-
ogy.
• creating new patterns for extraction in the
new domain.
</listItem>
<bodyText confidence="0.997300352941176">
Customising current IE systems is thus expensive.
A domain expert and a linguist with knowledge of
the IE system will generally be required to specify
the task, manually mark-up or categorise domain
data, perhaps build a domain ontology, write ex-
traction patterns and fine-tune them for the best
compromise of precision and recall.
There are thus pressing reasons for automating
the customisation task and reducing the involve-
ment of linguists as much as possible. Several
methods of automatically inferring patterns and
semantic dictionaries from annotated texts have
been suggested, e.g. (Riloff, 1993; Riloff, 1996;
Sonderland et al., 1995; Yangarber and Grishman,
1997). Pierce and Cardie (Cardie and Pierce,
1998) suggest that the use of annotated texts can
be replaced by an interactive approach in which
an end-user assists the system in bootstrapping
patterns from a set of example results. However
even this method is ill suited to one-off queries,
where the user is unlikely to start from example
results, but needs to be able to interactively home
in on a set of answers.
In this paper we describe a system which en-
ables users to build advanced on-the-fly queries.
The interface is intended to be intuitive for users
already familiar with keyword IR but adds the ex-
tra functionality of sortal, linguistic and positional
constraints that are more common in IE. Adding
extra linguistic constraints may improve precision,
and cause a drop in recall, in exactly the same way
as adding an extra non-optional keyword.
The approach is less ambitious than provid-
ing full Natural Language querying, but allows
</bodyText>
<page confidence="0.999497">
85
</page>
<bodyText confidence="0.9993842">
professional users of search technology (e.g. an-
alysts or research scientists) to get most of the
advantages of IE without having to program pat-
terns. We assume that retraining of linguistic
components (such as the tokeniser and tagger) for
a new domain will still be performed by a lin-
guist/programmer, and that end-users will be sup-
plied with libraries of useful sorts such as person
names, companies, locations, protein names etc.
which are appropriate for their domain.
</bodyText>
<sectionHeader confidence="0.984714" genericHeader="introduction">
2 IR and NLP
</sectionHeader>
<bodyText confidence="0.999687302325581">
Our key interest in this work was to provide a sys-
tem which allowed users to get answers: not just
documents or sub-documents. We have not ad-
dressed the question of whether or not these tech-
niques would also be useful for more traditional IR
in the sense of finding the most relevant document
for a particular query. There is some potential
since there are extra options to refine or expand
a query e.g. using sortal constraints such as com-
pany and location, and restrictive constraints such
as subject_of or same sentence. Since the linguis-
tic constraints are under user control the query is
more likely to be accurate than in systems where
linguistic constraints are derived from a natural
language query (though at the expense of usabil-
ity).
The system was designed to deal with multiple
answer queries such as &amp;quot;which protein interacts
with TAF-2?&amp;quot;. This differs somewhat from the
TREC question answering track ((TREC), 2000),
where the emphasis is on questions which have
a single answer, and systems attempt to provide
the most relevant sub-document. To attempt the
TREC task we would need to extend the sys-
tem with a relevance weighting mechanism, and
provide further techniques for query expansion.
We would then expect the system to do well,
since (Srihari and Li, 1999) show that the use of
sortal constraints such as company, location and
time plus constraints such as same sentence give
good results, even with a relatively simple ranking
mechanism.
How much extra cost is involved in using lin-
guistic information? There is obviously some ini-
tial cost in parsing and analysing the texts, how-
ever this can largely be hidden by preprocessing
the documents. In addition there is a space cost
in having a much larger index: this is necessary
since we are keeping more information about the
document&apos;s structure. Finally, there is the cost of
evaluating more complex constraints. The cost of
using sortal constraints is negligible: we can index
them in exactly the same way as words. However,
</bodyText>
<figure confidence="0.919347333333333">
P
i2: a
i3: b
</figure>
<figureCaption confidence="0.999858">
Figure 1: Distributed representation of P (a , b)
</figureCaption>
<bodyText confidence="0.988194857142857">
relational constraints such as same sentence do in-
troduce extra processing. The figures we present
at the end of this paper show that this first im-
plementation of the system is fast enough to be
usable for some real applications (and very fast
by Information Extraction standards), but is not
yet in the same league as standard IR engines.
</bodyText>
<sectionHeader confidence="0.998679" genericHeader="method">
3 Highlight
</sectionHeader>
<bodyText confidence="0.9997912">
Highlight (Thomas et al., 2000) is a general-
purpose IE engine for use in commercial appli-
cations. The work described in the current pa-
per ex-tends Highlight by building an interface on
top of it and replacing the internal representation
of linguistically analysed texts with a representa-
tion based on distributed representations c.f. (Mil-
ward, 2000). Demos of the Highlight System are
accessible from the SRI Cambridge web site at
http://www.cam.sri.com
</bodyText>
<subsectionHeader confidence="0.998832">
3.1 Distributed Representation
</subsectionHeader>
<bodyText confidence="0.999962444444444">
The inspiration for the approach taken here was
the work in (Milward, 2000) on interpretation of
dialogue utterances. This uses distributed seman-
tic representations (based on indexing individual
parts of a semantic structure) to encode both full
and partial semantic analyses. For example, the
logical form P(a,b) is represented by the set of
constraints given in Figure 1.
This approach aims to combine the advantages
of shallow pattern-matching approaches (which
are fast and robust) with those of deeper analysis
which tends to do better for phenomena which in-
volve scope. For example, consider the utterance
&amp;quot;The 2.10 flight to Boston will not stop at New
York&amp;quot;. A simple pattern matching approach look-
ing for [flight] to [location] via [location] would ex-
tract the wrong information since it has no notion
of the scope of the negation.
In this work we take the same idea, but apply
it to Information Extraction. Sets of indexed con-
straints (which are themselves partial descriptions
of semantic structure) are used directly as search
expressions. Since the indexed constraints can en-
code full semantic structures, the search terms can
be more or less specific: we can start with just con-
straints on lexical items, and then build up to a
full semantic structure by adding structural con-
</bodyText>
<page confidence="0.98112">
86
</page>
<figure confidence="0.998983625">
obligatory optional
I:J(K,L),
J: at,
M:leave,
L:T,
time (T)
(1) K&gt;H, H:M(N) =&gt; departure_time(T)
(2) K:M(N)
</figure>
<figureCaption confidence="0.995443">
Figure 2: Extracting a departure time
</figureCaption>
<bodyText confidence="0.9996165">
straints.
Search is now a question of expressing the ap-
propriate constraints on the information to be ex-
tracted. For example, Figure 2 is a sketch rule
to extract departure time from a sentence such
as &amp;quot;I leave at 3pm.&amp;quot; The rule subsumes a range
of rules which vary in the specificity with which
they apply. For example, applying only the oblig-
atory conditions will result in the extraction of
3pm as departure time from sentences such as &amp;quot;I
leave Cambridge to arrive at 3pm&amp;quot; since in the
obligatory component there is no restriction on
M with respect to T, i.e. the leave event and the
time. Adding the optional constraints in (1) gives
us the restriction that the leaving must be domi-
nated by the preposition at, e.g. &amp;quot;I leave from the
station at 3pm,&amp;quot; and (2) requires immediate domi-
nance: &amp;quot;I leave at 3pm.&amp;quot; This ranges from pattern
matching to almost full semantics. Any particu-
lar application of a rule can be scored according to
the number of optional conditions which are ful-
filled, thereby using linguistic constraints if they
are available.
In practice, the system described here departs
from this approach in several respects. Firstly, we
were working with the pre-existing Highlight sys-
tem which uses shallow syntactic processing based
on cascaded patterns (similar to (Hobbs et al.,
1996)). Deriving semantic relationships from this
is not particularly reliable, so it is preferable to use
search terms which rely more on positional clues.
We therefore used a distributed syntactic repre-
sentation to provide more reliable syntactic con-
straints (e.g. head word of, subject of, same sen-
tence) augmented by positional constraints (e.g.
precedes, immediately precedes). Secondly, we
wanted an intuitive user interface so constraints
such as &apos;dominates&apos; were not appropriate.
</bodyText>
<subsectionHeader confidence="0.995415">
3.2 User Interface
</subsectionHeader>
<bodyText confidence="0.999828647058824">
Given the underlying representation described
above, the user&apos;s task in building a query is to
propose a set of constraints which can be matched
against the representation of a text or set of texts.
The interface attempts to preserve the conve-
nience of keyword based IR but also enable more
refined searches, and control over the presenta-
tion of results. Keyword based search is a special
case where the user specifies one or more keywords
which they want to find in a document. However,
users can also specify that they want to find a class
of item (e.g. companies) and refine the search for
items within the same sentence, not just the same
document.
For example, to find &apos;Esso&apos; and a location in the
same sentence we need the set of constraints given
below:
</bodyText>
<equation confidence="0.938458333333333">
J:Esso
location (T)
same_sentence(J,T)
</equation>
<bodyText confidence="0.999954322580645">
The interface emphasises the items the user wants
to search for. Consider Figure 3. The user is
looking for two items, the first including the word
Esso (this could be e.g. &amp;quot;Esso Corp.&amp;quot;, &amp;quot;Esso Hold-
ings&amp;quot; etc.), and the second item of sort &apos;location&apos;.
The effect of pressing &apos;Add&apos; is to include the posi-
tional constraint that the two items must appear
in the same sentence. In later parts of this paper
we provide examples of more sophisticated queries
which imitate what is currently arhieved by pat-
tern matching in more standard IE systems (e.g.
Fastus (Hobbs et al., 1996)).
In our approach IE is a seamless extension of
IR. This can be contrasted with some more typi-
cal ways of tying together IE and IR by performing
an IR search followed by IE. In that approach, IR
is used first to select a limited set of documents,
then IE is applied. This is fine if the queries and
the keywords are fixed (and appropriate for each
other). It is not ideal otherwise. For example,
suppose you are interested in Esso&apos;s profits. To
achieve your query you might use IR to find doc-
uments containing Esso, then use an IE system
which has been customised to look for company
profits. However, some of the results are likely
to be unexpected, for example, you would obtain
Shell&apos;s profits if there were a document describing
Shell&apos;s profits which just happens to mention Esso
in passing.
Items can be constrained to have a particular
head word, to include a particular word or to be of
</bodyText>
<page confidence="0.991407">
87
</page>
<figure confidence="0.983439428571429">
Intelligent Search and Extraction of Information [Expert Mode
Current Query
Name of Search Irf7&apos; Constraints cp..Searrititem
; included word - E s so
; sor&apos;. = caton
Edit Query
Ward Constraints
included word I
Sortal Constraints
Constraints between Search Items
I —I I same. sentence I
New Item
Delete&apos;
Add Alternative Edit Replace]
</figure>
<figureCaption confidence="0.998782">
Figure 3: User interface
</figureCaption>
<page confidence="0.991579">
88
</page>
<bodyText confidence="0.999949194444445">
a particular sort. Multiple constraints on a single
item are possible, as shown in Figure 5. Positional
constraints can include any kind of inter-item con-
straints e.g. precedes, same sentence. There are
further option buttons which concern the files to
be queried and the layout of the output. The de-
fault is to provide a table which includes each item
found plus the sentence in which it appears in the
document.
Two levels of user expertise (novice and expert)
allow more or less control over the technical details
of the query. Expert mode (accessed by clicking
the button at the top right) looks much the same
but has facilities such as altering the template out-
put, naming the items and more options on the
pull-down menus. For instance, in expert mode
the user may specify which items are optional in
the query, and what their syntactic class might be.
There are also additional extra parameters for the
expert user for the output templates.
A typical user query is given in Figure 4. Here
the user is looking for appositives in the pat-
tern Person Noun of Company, for example John
Smith, chairman of X-Corp.1 Note that the query
is not particularly linguistically sophisticated: the
Position item is glossed as a noun group and the
single preposition of is specified when a looser re-
striction (perhaps to be any preposition) would
certainly turn up more results. However, this
query is quick and simple to construct and can
be used as a diagnostic for a more detailed query.
A more complex query is shown in Figure 5 for
a protein interaction task. The sort interaction
in Figure 5 could be defined as a disjunction of
the constraints head word = interact, head word
= bind, head word = associate).
</bodyText>
<subsectionHeader confidence="0.989476">
3.3 One-off Query vs Pattern Base
</subsectionHeader>
<bodyText confidence="0.999948">
Highlight can operate in two distinct modes: in-
teractive and batch. The interactive mode suits
one-off queries as seen but can also be used to
prototype queries on a subset of a corpus. Once
a user is satisfied with the accuracy of a query,
this user-defined &apos;pattern&apos; can be stored for later
use. Batch mode is used when a query is to be
run over a large amount of text and requires no
intervention from the user other than the initial
set-up.
</bodyText>
<subsectionHeader confidence="0.995828">
3.4 Preprocessing Files and Scalability
</subsectionHeader>
<bodyText confidence="0.994995706896552">
If a user makes two queries over the same set of
documents it does not make sense to do all the lin-
guistic processing twice. To avoid this, documents
INVe currently do not index commas but a posi-
tional constraint representing separation by a comma
could easily be added.
can be preprocessed. Preprocessing involves tag-
ging, chunking, recognition of sorts, and conver-
sion of the results into a set of constraints. At
query time, there is no further linguistic process-
ing to be done, just constraint satisfaction.
The system has a relatively simple outer loop
which considers a query for each document in turn
(rather than e.g. using a single cross-document in-
dex). If a document has not been preprocessed,
it is processed, then tested against the query. If
a document has been preprocessed, the results of
preprocessing are loaded, and tested against the
query. Preprocessing produces a worthwhile in-
crease in speed. Loading the preprocessed files
ready for constraint satisfaction takes (on aver-
age) less than a tenth of the time it takes to pro-
cess the files to get to the same stage. However,
preprocessed files do take around 60 times more
filespace than the source files from which they are
derived2.
Although loading a preprocessed file is much
faster than processing from scratch, the loading
is still a significant factor in the total processing
time. In fact for simple queries the loading ac-
counts for over 90% of processing time. We were
therefore keen to load only those files where there
was a chance of success for a query. One way to
do this is to split the query into an IR and an
IE component and to use IR to pre filter the set
of documents. If we only have to load one tenth
of the documents then again we can expect a 10
times speed up (assuming the time to do IR is
relatively trivial relative to the time as a whole).
A simple way to achieve IR filtering is to extract
out any non-optional keywords from the query,
and then only process those documents that con-
tain the keywords. However, many of the queries
which we use do not contain keywords at all, only
sorts. In these cases, we cannot run IR over the
source documents, since these do not contain the
sortal information. Instead we search over a sum-
mary file which is created during preprocessing.
This contains a set of all the sorts and words found
in the file. The IR stage consists of selecting just
those files which match the sorts and keywords
in the query. This set is then passed to the IE
component which deals with relational constraints
such as same sentence, and interactions between
constraints which have to be calculated on the fly
such as precedes which are not indexed during pre-
processing.
The IE component satifies the constraints in the
</bodyText>
<footnote confidence="0.911047">
2This is worse than it need be: we have not yet
attempted to rationalise the preprocessed files, or use
encoding schemes to reduce redundancy.
</footnote>
<page confidence="0.996334">
89
</page>
<figure confidence="0.711204">
Intelligent Search and Extraction of Information Expert Mode
</figure>
<figureCaption confidence="0.941161">
Figure 4: A typical one-off query for case: John Smith, chairman of X-Corp
</figureCaption>
<table confidence="0.968452">
immediately precedes: 1,2
hrunediately precedes: 2,4
immediately precedes: 4,3
90
Intelligent Search and Extraction of Information Expert Mode
Current Query
Name. of Search Item • Constraints on Search Item
sort= o s on
syntax group = noungp
included word - that
Prott:]: sort = protein
&apos; syntax group noungp
Figure 5: Query for protein interactions e.g. observe that Taf-1 binds TBP.
ort= interaction
syntax group = verbgp
sort= protein
syntax group = nourigp
immediately precedes: 1,2
Immediately precedes: 2, Protein 1
kart ediately precedes: Protein 1, Interact
bnmediately precedes: Interaction, Protein 2
</table>
<page confidence="0.995018">
91
</page>
<bodyText confidence="0.999229717948718">
query against the constraints in the preprocessed
file. The constraint solver tries to satisfy the most
specific constraints in the query first. Constraints
are indexed and reverse indexed for efficiency.
The processing times we currently achieve are
very good by the standards of Information Ex-
traction, and are adequate for the applications for
which we have been using the system. The cur-
rent approach is similar to that of e.g. Molla and
Hess (Aliod and Hess, 1999), who first partition
the index space into separate documents, and use
the IR component of queries as a filter.
Table 1 shows the difference in processing times
on two queries for two different datasets. Times
for processing each query on each dataset are la-
belled Old for Highlight with no IR and no prepro-
cessed files, New for Highlight with preprocessed
files and NewIR. for Highlight with both an IR
stage and preprocessed files.3
New% and NewIR% give New/Old and
NewIR/ Old respectively. From the table we
can see that (for these queries) adding the pre-
processed files reduces total processing time by
around 75%. Adding the IR stage reduces it by
a further couple of percent in the case of the FT
files and by 10% for the WSJ files. The perfor-
mance increase on FT data is less dramatic be-
cause the data provides more hits (i.e. we extract
more templates per input file) but note that for
both datasets these improvements are at the worse
end of the spectrum: both the WSJ and FT files
stand a very good chance of containing both per-
son and company (the sorts in our test queries)
and so the IR component will propose a large num-
ber of each set for IE treatment, and we can also
expect several hits per file, which tends to slow
query processing. In other queries, e.g. a search
for a company name, we would expect things to
be much quicker as borne out by the results in
</bodyText>
<tableCaption confidence="0.528664">
Table 2.
</tableCaption>
<sectionHeader confidence="0.998289" genericHeader="method">
4 Performance
</sectionHeader>
<bodyText confidence="0.9989808">
Figures 6, 7 correspond to the queries in Figures 3
and 4 respectively. Figure 8 is the result of search-
ing for protein interactions (a more general version
of the query in Figure 5.)4 Table 2 contrasts these
results. FileslR and FilesIE refer to the number
</bodyText>
<footnote confidence="0.950895111111111">
3The WSJ dataset consists of 100 Wall Street Jour-
nal articles, the FT set comes from 60 Financial Times
documents. Query 1 looks for a person and company
in the same sentence while Query 2 is for Person, X
of/at/in Company. All tests were carried out on a
Sun Ultra 2200 (200MHz, 256Mb RAM) running Sic-
stus Prolog 3.7.1 under Solaris 7.
4For space reasons we have only presented a sample
of our query results.
</footnote>
<bodyText confidence="0.932688">
of files input to each stage of the system, i.e. the
query in Figure 6 was run over 500 news articles,
only one of them was selected by our IR compo-
nent and was thus input to the IE component.
Hits denotes how many of the files passed to lE
actually had at least one template in them and
Templates shows how many templates were ex-
tracted as a result of the query. Time is the total
time for the query in seconds.
The query in Figure 6 looks for documents con-
taining Esso and a location.5 Because Esso is
such a good discriminator in this document set,
appearing in only one out of 500 documents, the
IE query only considers one document and the
whole query succeeds in 0.5sec.
Figure 7 takes longer than this because 218 of
500 files contain the common sorts person and
company. Figure 8 is similar but has the addi-
tional overhead of around 2/3 of all files having
hits where Figure 7 has only 1/20.
Factors affect the total amount of time that a
query takes include:
</bodyText>
<listItem confidence="0.999936">
• specificity of the query
• complexity of the query
• size of the source file
• whether or not there is a hit in the file
</listItem>
<bodyText confidence="0.963158888888889">
With the addition of the IR stage, the specificity
of the query has the potential to impact greatly on
total query time as already seen. Having a hit in
the file can also significantly affect timings since
there is no chance of an early failure of constraint
satisfaction. For example, taking a file from each
of the queries in Figures 7 and 8 which each take
270msec to load (i.e. are of the same size) we find
that the one in which there is no hit takes 10msec
to process but the one is which there is a hit takes
6.5sec (of which just 110msec is spent writing re-
sults to file.)
The lessons from these results are not partic-
ularly surprising: queries should use the most
specific words and sorts possible to get good
value from the IR component. If there are many
solutions—and remember that this system aims
to extract specific information rather than a rele-
vant document or document passage—then there
will be a time penalty.
313ecause there is no sentential restriction on these
two items, they do not appear on the same row in
the output. This is an option available to the user
which means that in queries of this kind, the output
is a summary of the &amp;quot;true&amp;quot; output (a cross product of
each item with each other item) which can obviously
result in very large output tables.
</bodyText>
<page confidence="0.985363">
92
</page>
<table confidence="0.9996076">
Dataset Query Old (msec) New (msec) New% NewIR (msec) NewIR%
WSJ 1 133880 32890 25 19120 14
WSJ 2 135840 33610 25 19540 14
FT 1 94830 21300 22 18850 20
FT 2 92240 21590 23 18960 _ 21
</table>
<tableCaption confidence="0.999441">
Table 1: Comparison of IR and non-1R preprocessing
</tableCaption>
<table confidence="0.99690075">
Figure FilesIR FilesIE Hits Templates Time (s)
6 500 1 1 19 0.5
7 500 218 11 11 27
8 100 59 42 44 66
</table>
<tableCaption confidence="0.999874">
Table 2: Comparison of query times
</tableCaption>
<bodyText confidence="0.999718375">
Our expectation is that complex queries which
also involve a lot of hits are more likely for batch
mode operation, so the time penalty will not be
so crucial. One-off queries will tend to be simpler,
involving searches for less frequent information.
However, we are also investigating further ways
to improve processing speed, in particular during
constraint satisfaction.
</bodyText>
<sectionHeader confidence="0.997822" genericHeader="evaluation">
5 Evaluation
</sectionHeader>
<bodyText confidence="0.99998825">
We have not yet performed a large-scale evalua-
tion of the user-customisable version of Highlight.
The earlier version of Highlight was evaluated for
the task of extracting protein interactions, obtain-
ing a recall of 55-58% and precision of 77%. For
this particular task we would not expect the re-
sults for the new system to differ significantly: the
underlying engine is the same and we can use the
interface to generate sets of constraints which are
equivalent to the previous patterns. For example,
Figures 5 (above) and 9 show how an old pattern
can be generated in the new interface. Both look
for phrases such as ... observed that TAF binds
TBP, the old pattern places an interaction tag
around the relevant text while in the new inter-
face the user selects which items will be output
(in this case, the ones which have names rather
than numbers.)
. For other tasks, there are some factors which
might affect the relative recall and precision fig-
ures between the original Highlight system and
the customisable version. Firstly, the original
Highlight system can use cascades of pattern
matching rules to perform &apos;blocking tactics&apos; i.e.
one rule fires for the sole purpose of preventing
another from firing. To achieve a similar ability
in customisable Highlight we need to introduce a
way of choosing between alternative queries when
more than one can apply e.g. by always choos-
ing the most specific. Secondly, the original High-
light sometimes resorted to external program calls
which is no longer possible.
</bodyText>
<sectionHeader confidence="0.993417" genericHeader="evaluation">
6 Applications
</sectionHeader>
<bodyText confidence="0.99993175">
The system described in this paper is still under
development but is already being used in pilot
projects with commercial clients. Areas in which
it has been deployed include:
</bodyText>
<listItem confidence="0.975184826086957">
• expertise database: extracting relationships
between employees and the projects in which
they are involved from internal company doc-
uments. The relationships degrade from
those which represent certain involvement
(e.g. writing a report) to those that repre-
sent possible involvement (e.g. mentioned in
the same sentence).
• competitor database: extracting information
about companies from Financial Times doc-
uments. Here, we were after in particular the
chairman, chief executive and so on of any
companies in the texts. Again, sets of rela-
tionships showed the degree of certainty with
which a person was related to a company.
• conference database: extracting information
such as conference title, location, date and
cost from conference calls downloaded from
the web. This task was particularly interest-
ing because it required the gathering of in-
formation from a variety of locations in each
document rather than the more usual single
sentence.
</listItem>
<bodyText confidence="0.530801333333333">
In order to test the flexibility of the new system,
we have also been recoding previous applications
of the Highlight system.
</bodyText>
<page confidence="0.99441">
93
</page>
<figure confidence="0.993770555555555">
Query results
I Source
1 2 Sentence !Link!
;nA711Esso Resources
&amp;quot; !Canada Ltd.
kvsj 04731-
Iwsj_04731- Canada
the Arctic
j!
</figure>
<subsectionHeader confidence="0.917055833333333">
The producers include Shell Canada Ltd., a unit of
!Royal Dutch I Shell Group; Esso Resources Canada
ILtd., a unit of Imperial Oil Ltd., which is 71
%-owned by Exxon Corp.; and Gulf Canada
!Resources Ltd., a unit of Olympia &amp; York
IDevelopments Ltd.
</subsectionHeader>
<page confidence="0.78162">
■1■11
</page>
<tableCaption confidence="0.619724625">
Foothills wants to make it clear to other pipeline
&amp;quot;companies that it&apos;s on first insofar as transporting
!gas from the Arctic to southern markets , &apos; Mr.
!Hillary said.
At least two rival applications are expected to
!emerge in coming months, including one from
!TransCanada PipeLines Ltd., Canada&apos;s largest
!natural gas pipeline operator.
</tableCaption>
<table confidence="0.653086975609756">
The Toronto-based company, together with
04731- !Houston :Tenneco Inc. of Houston, has had an incomplete &amp;quot;link
,proposal filed with Canadian regulators since 1984 I
!that it is now updating.
j0473
Iwsj_04731-
1
Iwsj 04731-
!
jwsj_04731-
i
;Like Foothills, TransCanada&apos;s Polar Gas I
!consortium plans to build a pipeline directly south I .
from the Mackenzie River delta in Canada&apos;s !link 1
estern Arctic with an initial capacity to transport I 1
11. 2 billion cubic feet of gas daily. I I
!Industry sources said they ecpect a fierce battle to !
! !emerge between TransCanada, which has a I
I i E
!Alb&amp;quot;monopoly on Canadian gas transportation east of
erta
i !Alberta, and Nova and Westcoast, which control 1link .
1
the pipelines within and running west of Alberta, 1 I
!respectively.
1
&amp;quot;
!U. S. gas buyers must also decide whether they want I
i .
!the Prudhoe Bay ito enter firm contracts for Mackenzie delta gas or I
!develop Alaskan reserves in the Prudhoe Bay area link, area
I !first, a project that has been on hold for more than li
la decade.
,
1 1But Foothills said it plans to seek regulatory I
Alaska !approval to build an alternative line, the Alaska 11,... 1,
!
i !Natural Gas Transportation System further north I-&apos;
I
i !toward Alaska.
! ,
</table>
<figure confidence="0.938974">
Ithe Mackenzie
&amp;quot;River delta
</figure>
<figureCaption confidence="0.997967">
Figure 6: Sample of results from query for keyword Esso and sort location
</figureCaption>
<page confidence="0.933835">
94
</page>
<figure confidence="0.99522776">
I Source 1 Person
I &apos;Robert L
iwsj_01111Bernstein
1
1 . &apos;Murray
iwLs0209,— .
1noomson
I Position
!chairman and
president
Ipresident
1
Query results
i Company
I I&amp;quot; The development could have a
I !dramatic effect on farm
I !production, especially cotton ,&amp;quot;said 1 .
&amp;quot;Delta &amp; Pine Robinson, president of 11,,„1, &apos;
!Land Co. i 1 &amp; Pine Land Co., a
iofIromurreltaaY
&apos;
1 ISouthwide Inc. subsidiary that is :4&amp;quot;&amp;quot;\*
i
i Ione of the largest cotton seed I
1 &apos;producers in the U. S. &apos;
1
[ &apos;
(Inc.andom House
I
4 Sentence
[START Robert L Bernstein,
&apos;chairman and president of Random
of House Inc., announced his
,resignation from the publishing
&apos;house he has run for 23 years.
1 1
&apos;link&apos;
1
link
1 I START Michael Blair, former
I president and chief ececutive
of [officer of Enfield Corp., failed to
twin election to the company&apos;s
I iboard at a special shareholder I
I
meeting.
I I &apos;former president
&apos; and chief iEnfield Corp.
&apos; [executive officer
I
,
,
[wsj_02761Michael Blair
i
I
1
ilink
I
. i
1 ,
,
&apos;David
,
iwsj—&apos;n&apos;&apos;&apos;20 .1 &apos; [Rockefeller
1 I
i !
I &apos;
iIwsj_05091Stephen Wolf
,
I
. I
I&apos;Joseph L
w•_°593 I Dionne
1
I !David Rockefeller, chairman of
</figure>
<tableCaption confidence="0.339120642857143">
I &apos;Rockefeller Group, said the
1Rockefeller Group of [company talked with many
I !potential investors in Japan, the
[ !United States and Europe.
!Among the other alumni are
1„f !Stephen Wolf, now chairman of
I— [UAL Inc., and Thomas Plaskett,
I President of Pan Am Corp
,START Joseph L Dionne,
[chairman and chief executive
!McGraw—Hill Inc. of [officer of McGraw—Hill Inc., was
I &apos;elected to the board of directors of
. .
,tlus electronics manufacturer.
</tableCaption>
<figure confidence="0.977760166666667">
&apos;chairman
[chairman
chairman and
!chief executive
&apos;officer
[UAL Inc.
</figure>
<figureCaption confidence="0.999858">
Figure 7: Sample of results from query for Person, X of Company
</figureCaption>
<page confidence="0.984187">
95
</page>
<table confidence="0.972755734693878">
Query results
Source I Protein 1 !Interaction Protein 2 I Link
i Sentence
I the E2F1 transactivation ITRRAP also interacts specifically with l&apos;&apos;
1bio-10004 TRRAP I ts domain !the E2F1 transactivation domain.
1 &apos; interacts
I
1 I Iln yeast, Cdi 1 interacts with 1
1 io_1014 !Cdil I. lcyclin—dependent kinases, including 1
&apos; 1 fimteracts cyclin—dependent kinases !human CDC2 (116940), CDK2 &apos;Ilink
i I 1(116953), and CDK3 (123828), but not
Iwith CDK4 (123879).
I
I
i . ! both TTF1 and Poll lJansa et al. (1998) demonstrated that 1
I i IPtrf interacts with both TTF1 and Pol I, 1 -
! I !interacts and binds to transcripts containing the !link
ibio 101871M ( 13—prime end of pre—rRNA in vitzo. I
— 1 i
I I RAF ICNK physically interacts with RAF and i
Ibio_10261 I CNK !interacts &apos;appears to localize to cell—Cell contact link
l I iregions.
&apos;
I
&apos; i the parvovirus !record (603419) The SGT protein ,
1 :I The SGT &apos;interacts nonstructural protein !interacts with the parvovirus &apos;link
bio 0408 1 NS1 !nonstructural protein NS1.
— &apos;protein
t
,
&apos;
!
bio_10444IRICK I CLARP ilnohara et al. (1998) demonstrated that l
1 !interacts !RICK physically interacts with CLARP, l iini,
&apos; la caspase—like molecule known to bind
&apos; lto FADD and caspase-8.
&apos;
I&apos; -
l !interacts Drosophila ISangoram et al. (1998) demonstrated I
bio 10876 !human 1 !that human TIM interacts with llink
1 — ITIM , !Drosophila per, mouse PER1, and mouse
I IPER2 (see 603426) in vitro.
,
,--
I
.
I &apos; I. MYC and NMYC I MIZ1 interacts specifically with MYC I .
Ibio 11073 IMIZ1 &amp;quot;interacts land NMYC (164840). &apos;link
I — 1 I
</table>
<figureCaption confidence="0.998316">
Figure 8: Sample of results from query for X interacts with Y
</figureCaption>
<bodyText confidence="0.647240294117647">
bio_relation :sp:
[ VG1/tag(vg,VGType,Word1),
that/ThatTag,
NP1/tag(np,N1,N1Sort,UL/,Id1),
VG/tag(vg,headed_vg,Word),
NP2/tag(np,N2,N2Sort,UL2,Id2)
if
[ VG1/tag(vg,VGType,Word1),
that/ThatTag,
= &gt; [ NP1/tag(np,N1,N1Sort,UL1,Id1),
VG/tag(vg,headed_vg,Word)],
NP2/tag(np,N2,N2Sort,UL2,Id2)
Yinteraction(Id)
]
bio_transitive_relation(Word),
observation_word(Word1),
make_new_id(Id)
</bodyText>
<figureCaption confidence="0.970343">
Figure 9: Pattern from basic Highlight for case: observe that Taf-1 binds TBP.
</figureCaption>
<page confidence="0.983394">
96
</page>
<sectionHeader confidence="0.997896" genericHeader="conclusions">
7 Summary
</sectionHeader>
<bodyText confidence="0.999911714285714">
This paper has given a brief outline of a sys-
tem which may be used for one-off queries in
the style of current Information Retrieval systems
but with the advantages of Information Extrac-
tion technology. The same interface can be used
to build queries appropriate for more traditional
batch mode Information Extraction tasks.
</bodyText>
<sectionHeader confidence="0.998843" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99951688">
Diego Molla Aliod and Micheal Hess. 1999. On
the scalability of the answer extraction system
&amp;quot;extrans&amp;quot;. In Applications of Natural Language
to Information Systems (NLDB&apos;99), pages 219-
224.
Claire Cardie and David Pierce. 1998. Proposal
for an interactive environment for Information
Extraction. Technical Report TR98-1702, De-
partment of Computer Science, Cornell Univer-
sity.
Jerry R. Hobbs, Douglas Appelt, David Israel
John Bear, Megumi Kameyama, Mark Stickel,
and Mabry Tyson. 1996. Fastus: A cascaded
finite-state transducer for extracting informa-
tion from natural-language text. In E. Roche
and Y. Schabes, editors, Finite State Devices
for Natural Language Processing. MIT Press.
David Milward. 2000. Distributing representation
for robust interpretation of dialogue utterances.
In Proceedings of the 38th ACL Conference.
Ellen Riloff. 1993. Automatically constructing
a dictionary for Information Extraction tasks.
In Proceedings of the 11th National Confer-
ence on Artificial Intelligence, pages 811-816.
AAAI/MIT Press.
Ellen Riloff. 1996. Automatically generating ex-
traction patterns from untagged text. In Pro-
ceedings of the 13th National Conference on Ar-
tificial Intelligence, pages 1044-1049.
Stephen Sonderland, David Fisher, Jonathan
Aseltine, and Wendy Lehnert. 1995. CRYS-
TAL:inducing a conceptual dictionary. In Pro-
ceedings of the 14th International Joinct Con-
ference on Artificial Intelligence.
Rohini Sr&apos;ihari and Wei Li. 1999. Information ex-
traction supported question answering. In Pro-
ceedings of the Eighth Text Retrieval Conference
(TREC-8).
James Thomas, David Milward, Christos Ouzou-
nis, Stephen Pulman, and Mark Carroll. 2000.
Automatic extraction of protein interactions
from scientific abstracts. In Pacific Symposium
on Biocomputing.
Text Retrieval Conferences (TREC). 2000.
http://trec.nist.gov/.
Roman Yangarber and Ralph Grishman. 1997.
Customization of Information Extraction sys-
tems. In Proceedings of the International Work-
shop on Lexically Driven Information Extrac-
tion.
</reference>
<page confidence="0.999688">
97
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.099418">
<title confidence="0.999744">From Information Retrieval to Information Extraction</title>
<author confidence="0.958232">David Milward</author>
<author confidence="0.958232">James</author>
<affiliation confidence="0.80684">SRI</affiliation>
<title confidence="0.492683">Suite 23 Millers</title>
<author confidence="0.678767">Mill</author>
<pubnum confidence="0.608844">CB2</pubnum>
<email confidence="0.983246">milward@cam.sri.com,jrt1003@cam.sri.com</email>
<abstract confidence="0.961072181818182">This paper describes a system which enables users to create on-the-fly queries which involve not just keywords, but also sortal constraints and linguistic constraints. The user can specify how the results should be presented e.g. in terms of links to documents, or as table entries. The aim is to bridge the gap between keyword based Information Retrieval and pattern based Information</abstract>
<intro confidence="0.577501">Extraction.</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Diego Molla Aliod</author>
<author>Micheal Hess</author>
</authors>
<title>On the scalability of the answer extraction system &amp;quot;extrans&amp;quot;.</title>
<date>1999</date>
<booktitle>In Applications of Natural Language to Information Systems (NLDB&apos;99),</booktitle>
<pages>219--224</pages>
<contexts>
<context position="19312" citStr="Aliod and Hess, 1999" startWordPosition="3238" endWordPosition="3241">mmediately precedes: 1,2 Immediately precedes: 2, Protein 1 kart ediately precedes: Protein 1, Interact bnmediately precedes: Interaction, Protein 2 91 query against the constraints in the preprocessed file. The constraint solver tries to satisfy the most specific constraints in the query first. Constraints are indexed and reverse indexed for efficiency. The processing times we currently achieve are very good by the standards of Information Extraction, and are adequate for the applications for which we have been using the system. The current approach is similar to that of e.g. Molla and Hess (Aliod and Hess, 1999), who first partition the index space into separate documents, and use the IR component of queries as a filter. Table 1 shows the difference in processing times on two queries for two different datasets. Times for processing each query on each dataset are labelled Old for Highlight with no IR and no preprocessed files, New for Highlight with preprocessed files and NewIR. for Highlight with both an IR stage and preprocessed files.3 New% and NewIR% give New/Old and NewIR/ Old respectively. From the table we can see that (for these queries) adding the preprocessed files reduces total processing t</context>
</contexts>
<marker>Aliod, Hess, 1999</marker>
<rawString>Diego Molla Aliod and Micheal Hess. 1999. On the scalability of the answer extraction system &amp;quot;extrans&amp;quot;. In Applications of Natural Language to Information Systems (NLDB&apos;99), pages 219-224.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claire Cardie</author>
<author>David Pierce</author>
</authors>
<title>Proposal for an interactive environment for Information Extraction.</title>
<date>1998</date>
<tech>Technical Report TR98-1702,</tech>
<institution>Department of Computer Science, Cornell University.</institution>
<contexts>
<context position="2830" citStr="Cardie and Pierce, 1998" startWordPosition="444" endWordPosition="447">e of the IE system will generally be required to specify the task, manually mark-up or categorise domain data, perhaps build a domain ontology, write extraction patterns and fine-tune them for the best compromise of precision and recall. There are thus pressing reasons for automating the customisation task and reducing the involvement of linguists as much as possible. Several methods of automatically inferring patterns and semantic dictionaries from annotated texts have been suggested, e.g. (Riloff, 1993; Riloff, 1996; Sonderland et al., 1995; Yangarber and Grishman, 1997). Pierce and Cardie (Cardie and Pierce, 1998) suggest that the use of annotated texts can be replaced by an interactive approach in which an end-user assists the system in bootstrapping patterns from a set of example results. However even this method is ill suited to one-off queries, where the user is unlikely to start from example results, but needs to be able to interactively home in on a set of answers. In this paper we describe a system which enables users to build advanced on-the-fly queries. The interface is intended to be intuitive for users already familiar with keyword IR but adds the extra functionality of sortal, linguistic an</context>
</contexts>
<marker>Cardie, Pierce, 1998</marker>
<rawString>Claire Cardie and David Pierce. 1998. Proposal for an interactive environment for Information Extraction. Technical Report TR98-1702, Department of Computer Science, Cornell University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry R Hobbs</author>
<author>Douglas Appelt</author>
<author>David Israel John Bear</author>
<author>Megumi Kameyama</author>
<author>Mark Stickel</author>
<author>Mabry Tyson</author>
</authors>
<title>Fastus: A cascaded finite-state transducer for extracting information from natural-language text.</title>
<date>1996</date>
<booktitle>Finite State Devices for Natural Language Processing.</booktitle>
<editor>In E. Roche and Y. Schabes, editors,</editor>
<publisher>MIT Press.</publisher>
<contexts>
<context position="9853" citStr="Hobbs et al., 1996" startWordPosition="1617" endWordPosition="1620"> dominated by the preposition at, e.g. &amp;quot;I leave from the station at 3pm,&amp;quot; and (2) requires immediate dominance: &amp;quot;I leave at 3pm.&amp;quot; This ranges from pattern matching to almost full semantics. Any particular application of a rule can be scored according to the number of optional conditions which are fulfilled, thereby using linguistic constraints if they are available. In practice, the system described here departs from this approach in several respects. Firstly, we were working with the pre-existing Highlight system which uses shallow syntactic processing based on cascaded patterns (similar to (Hobbs et al., 1996)). Deriving semantic relationships from this is not particularly reliable, so it is preferable to use search terms which rely more on positional clues. We therefore used a distributed syntactic representation to provide more reliable syntactic constraints (e.g. head word of, subject of, same sentence) augmented by positional constraints (e.g. precedes, immediately precedes). Secondly, we wanted an intuitive user interface so constraints such as &apos;dominates&apos; were not appropriate. 3.2 User Interface Given the underlying representation described above, the user&apos;s task in building a query is to pro</context>
<context position="11728" citStr="Hobbs et al., 1996" startWordPosition="1928" endWordPosition="1931">below: J:Esso location (T) same_sentence(J,T) The interface emphasises the items the user wants to search for. Consider Figure 3. The user is looking for two items, the first including the word Esso (this could be e.g. &amp;quot;Esso Corp.&amp;quot;, &amp;quot;Esso Holdings&amp;quot; etc.), and the second item of sort &apos;location&apos;. The effect of pressing &apos;Add&apos; is to include the positional constraint that the two items must appear in the same sentence. In later parts of this paper we provide examples of more sophisticated queries which imitate what is currently arhieved by pattern matching in more standard IE systems (e.g. Fastus (Hobbs et al., 1996)). In our approach IE is a seamless extension of IR. This can be contrasted with some more typical ways of tying together IE and IR by performing an IR search followed by IE. In that approach, IR is used first to select a limited set of documents, then IE is applied. This is fine if the queries and the keywords are fixed (and appropriate for each other). It is not ideal otherwise. For example, suppose you are interested in Esso&apos;s profits. To achieve your query you might use IR to find documents containing Esso, then use an IE system which has been customised to look for company profits. Howeve</context>
</contexts>
<marker>Hobbs, Appelt, Bear, Kameyama, Stickel, Tyson, 1996</marker>
<rawString>Jerry R. Hobbs, Douglas Appelt, David Israel John Bear, Megumi Kameyama, Mark Stickel, and Mabry Tyson. 1996. Fastus: A cascaded finite-state transducer for extracting information from natural-language text. In E. Roche and Y. Schabes, editors, Finite State Devices for Natural Language Processing. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Milward</author>
</authors>
<title>Distributing representation for robust interpretation of dialogue utterances.</title>
<date>2000</date>
<booktitle>In Proceedings of the 38th ACL Conference.</booktitle>
<contexts>
<context position="6978" citStr="Milward, 2000" startWordPosition="1144" endWordPosition="1146"> we present at the end of this paper show that this first implementation of the system is fast enough to be usable for some real applications (and very fast by Information Extraction standards), but is not yet in the same league as standard IR engines. 3 Highlight Highlight (Thomas et al., 2000) is a generalpurpose IE engine for use in commercial applications. The work described in the current paper ex-tends Highlight by building an interface on top of it and replacing the internal representation of linguistically analysed texts with a representation based on distributed representations c.f. (Milward, 2000). Demos of the Highlight System are accessible from the SRI Cambridge web site at http://www.cam.sri.com 3.1 Distributed Representation The inspiration for the approach taken here was the work in (Milward, 2000) on interpretation of dialogue utterances. This uses distributed semantic representations (based on indexing individual parts of a semantic structure) to encode both full and partial semantic analyses. For example, the logical form P(a,b) is represented by the set of constraints given in Figure 1. This approach aims to combine the advantages of shallow pattern-matching approaches (which</context>
</contexts>
<marker>Milward, 2000</marker>
<rawString>David Milward. 2000. Distributing representation for robust interpretation of dialogue utterances. In Proceedings of the 38th ACL Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen Riloff</author>
</authors>
<title>Automatically constructing a dictionary for Information Extraction tasks.</title>
<date>1993</date>
<booktitle>In Proceedings of the 11th National Conference on Artificial Intelligence,</booktitle>
<pages>811--816</pages>
<publisher>AAAI/MIT Press.</publisher>
<contexts>
<context position="2715" citStr="Riloff, 1993" startWordPosition="429" endWordPosition="430"> domain. Customising current IE systems is thus expensive. A domain expert and a linguist with knowledge of the IE system will generally be required to specify the task, manually mark-up or categorise domain data, perhaps build a domain ontology, write extraction patterns and fine-tune them for the best compromise of precision and recall. There are thus pressing reasons for automating the customisation task and reducing the involvement of linguists as much as possible. Several methods of automatically inferring patterns and semantic dictionaries from annotated texts have been suggested, e.g. (Riloff, 1993; Riloff, 1996; Sonderland et al., 1995; Yangarber and Grishman, 1997). Pierce and Cardie (Cardie and Pierce, 1998) suggest that the use of annotated texts can be replaced by an interactive approach in which an end-user assists the system in bootstrapping patterns from a set of example results. However even this method is ill suited to one-off queries, where the user is unlikely to start from example results, but needs to be able to interactively home in on a set of answers. In this paper we describe a system which enables users to build advanced on-the-fly queries. The interface is intended t</context>
</contexts>
<marker>Riloff, 1993</marker>
<rawString>Ellen Riloff. 1993. Automatically constructing a dictionary for Information Extraction tasks. In Proceedings of the 11th National Conference on Artificial Intelligence, pages 811-816. AAAI/MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen Riloff</author>
</authors>
<title>Automatically generating extraction patterns from untagged text.</title>
<date>1996</date>
<booktitle>In Proceedings of the 13th National Conference on Artificial Intelligence,</booktitle>
<pages>1044--1049</pages>
<contexts>
<context position="2729" citStr="Riloff, 1996" startWordPosition="431" endWordPosition="432">mising current IE systems is thus expensive. A domain expert and a linguist with knowledge of the IE system will generally be required to specify the task, manually mark-up or categorise domain data, perhaps build a domain ontology, write extraction patterns and fine-tune them for the best compromise of precision and recall. There are thus pressing reasons for automating the customisation task and reducing the involvement of linguists as much as possible. Several methods of automatically inferring patterns and semantic dictionaries from annotated texts have been suggested, e.g. (Riloff, 1993; Riloff, 1996; Sonderland et al., 1995; Yangarber and Grishman, 1997). Pierce and Cardie (Cardie and Pierce, 1998) suggest that the use of annotated texts can be replaced by an interactive approach in which an end-user assists the system in bootstrapping patterns from a set of example results. However even this method is ill suited to one-off queries, where the user is unlikely to start from example results, but needs to be able to interactively home in on a set of answers. In this paper we describe a system which enables users to build advanced on-the-fly queries. The interface is intended to be intuitive</context>
</contexts>
<marker>Riloff, 1996</marker>
<rawString>Ellen Riloff. 1996. Automatically generating extraction patterns from untagged text. In Proceedings of the 13th National Conference on Artificial Intelligence, pages 1044-1049.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Sonderland</author>
<author>David Fisher</author>
<author>Jonathan Aseltine</author>
<author>Wendy Lehnert</author>
</authors>
<title>CRYSTAL:inducing a conceptual dictionary.</title>
<date>1995</date>
<booktitle>In Proceedings of the 14th International Joinct Conference on Artificial Intelligence.</booktitle>
<contexts>
<context position="2754" citStr="Sonderland et al., 1995" startWordPosition="433" endWordPosition="436"> IE systems is thus expensive. A domain expert and a linguist with knowledge of the IE system will generally be required to specify the task, manually mark-up or categorise domain data, perhaps build a domain ontology, write extraction patterns and fine-tune them for the best compromise of precision and recall. There are thus pressing reasons for automating the customisation task and reducing the involvement of linguists as much as possible. Several methods of automatically inferring patterns and semantic dictionaries from annotated texts have been suggested, e.g. (Riloff, 1993; Riloff, 1996; Sonderland et al., 1995; Yangarber and Grishman, 1997). Pierce and Cardie (Cardie and Pierce, 1998) suggest that the use of annotated texts can be replaced by an interactive approach in which an end-user assists the system in bootstrapping patterns from a set of example results. However even this method is ill suited to one-off queries, where the user is unlikely to start from example results, but needs to be able to interactively home in on a set of answers. In this paper we describe a system which enables users to build advanced on-the-fly queries. The interface is intended to be intuitive for users already famili</context>
</contexts>
<marker>Sonderland, Fisher, Aseltine, Lehnert, 1995</marker>
<rawString>Stephen Sonderland, David Fisher, Jonathan Aseltine, and Wendy Lehnert. 1995. CRYSTAL:inducing a conceptual dictionary. In Proceedings of the 14th International Joinct Conference on Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rohini Sr&apos;ihari</author>
<author>Wei Li</author>
</authors>
<title>Information extraction supported question answering.</title>
<date>1999</date>
<booktitle>In Proceedings of the Eighth Text Retrieval Conference (TREC-8).</booktitle>
<marker>Sr&apos;ihari, Li, 1999</marker>
<rawString>Rohini Sr&apos;ihari and Wei Li. 1999. Information extraction supported question answering. In Proceedings of the Eighth Text Retrieval Conference (TREC-8).</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Thomas</author>
<author>David Milward</author>
<author>Christos Ouzounis</author>
<author>Stephen Pulman</author>
<author>Mark Carroll</author>
</authors>
<title>Automatic extraction of protein interactions from scientific abstracts.</title>
<date>2000</date>
<booktitle>In Pacific Symposium on Biocomputing.</booktitle>
<contexts>
<context position="6660" citStr="Thomas et al., 2000" startWordPosition="1092" endWordPosition="1095">, there is the cost of evaluating more complex constraints. The cost of using sortal constraints is negligible: we can index them in exactly the same way as words. However, P i2: a i3: b Figure 1: Distributed representation of P (a , b) relational constraints such as same sentence do introduce extra processing. The figures we present at the end of this paper show that this first implementation of the system is fast enough to be usable for some real applications (and very fast by Information Extraction standards), but is not yet in the same league as standard IR engines. 3 Highlight Highlight (Thomas et al., 2000) is a generalpurpose IE engine for use in commercial applications. The work described in the current paper ex-tends Highlight by building an interface on top of it and replacing the internal representation of linguistically analysed texts with a representation based on distributed representations c.f. (Milward, 2000). Demos of the Highlight System are accessible from the SRI Cambridge web site at http://www.cam.sri.com 3.1 Distributed Representation The inspiration for the approach taken here was the work in (Milward, 2000) on interpretation of dialogue utterances. This uses distributed semant</context>
</contexts>
<marker>Thomas, Milward, Ouzounis, Pulman, Carroll, 2000</marker>
<rawString>James Thomas, David Milward, Christos Ouzounis, Stephen Pulman, and Mark Carroll. 2000. Automatic extraction of protein interactions from scientific abstracts. In Pacific Symposium on Biocomputing.</rawString>
</citation>
<citation valid="true">
<title>Text Retrieval Conferences (TREC).</title>
<date>2000</date>
<note>http://trec.nist.gov/.</note>
<marker>2000</marker>
<rawString>Text Retrieval Conferences (TREC). 2000. http://trec.nist.gov/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roman Yangarber</author>
<author>Ralph Grishman</author>
</authors>
<title>Customization of Information Extraction systems.</title>
<date>1997</date>
<booktitle>In Proceedings of the International Workshop on Lexically Driven Information Extraction.</booktitle>
<contexts>
<context position="2785" citStr="Yangarber and Grishman, 1997" startWordPosition="437" endWordPosition="440">sive. A domain expert and a linguist with knowledge of the IE system will generally be required to specify the task, manually mark-up or categorise domain data, perhaps build a domain ontology, write extraction patterns and fine-tune them for the best compromise of precision and recall. There are thus pressing reasons for automating the customisation task and reducing the involvement of linguists as much as possible. Several methods of automatically inferring patterns and semantic dictionaries from annotated texts have been suggested, e.g. (Riloff, 1993; Riloff, 1996; Sonderland et al., 1995; Yangarber and Grishman, 1997). Pierce and Cardie (Cardie and Pierce, 1998) suggest that the use of annotated texts can be replaced by an interactive approach in which an end-user assists the system in bootstrapping patterns from a set of example results. However even this method is ill suited to one-off queries, where the user is unlikely to start from example results, but needs to be able to interactively home in on a set of answers. In this paper we describe a system which enables users to build advanced on-the-fly queries. The interface is intended to be intuitive for users already familiar with keyword IR but adds the</context>
</contexts>
<marker>Yangarber, Grishman, 1997</marker>
<rawString>Roman Yangarber and Ralph Grishman. 1997. Customization of Information Extraction systems. In Proceedings of the International Workshop on Lexically Driven Information Extraction.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>