<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000186">
<title confidence="0.987863">
User Goal Change Model for Spoken Dialog State Tracking
</title>
<author confidence="0.999415">
Yi Ma
</author>
<affiliation confidence="0.996147">
Department of Computer Science &amp; Engineering
The Ohio State University
</affiliation>
<address confidence="0.595522">
Columbus, OH 43210, USA
</address>
<email confidence="0.999319">
may@cse.ohio-state.edu
</email>
<sectionHeader confidence="0.995651" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999609578947369">
In this paper, a Maximum Entropy Markov
Model (MEMM) for dialog state tracking
is proposed to efficiently handle user goal
evolvement in two steps. The system first
predicts the occurrence of a user goal change
based on linguistic features and dialog context
for each dialog turn, and then the proposed
model could utilize this user goal change in-
formation to infer the most probable dialog
state sequence which underlies the evolve-
ment of user goal during the dialog. It is
believed that with the suggested various do-
main independent feature functions, the pro-
posed model could better exploit not only the
intra-dependencies within long ASR N-best
lists but also the inter-dependencies of the ob-
servations across dialog turns, which leads to
more efficient and accurate dialog state infer-
ence.
</bodyText>
<sectionHeader confidence="0.999136" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999613230769231">
The ability to converse with humans is usually con-
sidered the most important characteristic which de-
fines the intelligent nature of a machine. In recent
years, advanced approaches for handling different
components within a spoken dialogue system have
been proposed and studied. Both statistical infer-
ence methods for dialog state tracking and machine
learning techniques (such as reinforcement learning)
for automatic policy optimization are active domains
of research, which implies that there are still many
open challenges in this field that are worth being ex-
plored. One of such challenges is how to better ex-
ploit the ASR (Automatic Speech Recognition) N-
</bodyText>
<page confidence="0.98291">
91
</page>
<bodyText confidence="0.999802">
best list when the top ASR hypothesis is incorrect.
Furthermore, reasoning over different ASR N-best
lists is also difficult since it is hard to decide when
to detect commonality (when user repeats) and when
to look for differences (when user changes her or his
mind) among multiple ASR N-best lists. Another
challenge is how to handle more complex user ac-
tions such as negotiating alternative choices or seek-
ing out other potential solutions when interacting
with the system.
This proposal presents a probabilistic framework
for modeling the evolvement of user goal during the
dialog (focusing on the shaded component Dialog
State Tracking in Figure 1 that shows a typical di-
agram for a spoken dialog system), which aims to
endow the system with the ability to model natural
negotiation strategies, in the hope of leading to more
accurate and efficient dialog state tracking perfor-
mance.
</bodyText>
<figureCaption confidence="0.994538">
Figure 1: a typical spoken dialogue system
</figureCaption>
<sectionHeader confidence="0.9523335" genericHeader="method">
2 Unanswered Challenges for Spoken
Dialog Systems
</sectionHeader>
<bodyText confidence="0.9815368">
Due to the inevitable erroneous hypotheses made by
the speech recognizer as well as the ubiquitous am-
biguity existing in the natural language understand-
Proceedings of the NAACL HLT 2013 Student Research Workshop, pages 91–97,
Atlanta, Georgia, 13 June 2013. c�2013 Association for Computational Linguistics
ing process, it is impossible for a spoken dialog sys-
tem to observe the true user goal directly. Therefore,
methods to efficiently infer the true hidden dialog
states from noisy observations over multiple dialog
turns become crucial for building a robust spoken
dialog system.
The POMDP (Partially Observable Markov De-
cision Process) framework has been proposed to
maintain multiple dialog state hypotheses under
uncertainty with automated dialog policy learn-
ing (Williams and Young, 2007; Henderson et
al., 2008; Thomson and Young, 2010; Young et
al., 2010). Although the original POMDP frame-
work suffers difficulties of scaling up the model to
handle real-world domains in practice, it provides
a unified statistical framework for existing tech-
niques with global optimization. Partition-based ap-
proaches (Gaˇsi´c and Young, 2011; Williams, 2010;
Young et al., 2010) attempt to group user goals into
a number of partitions and won’t split a partition un-
less when a distinction is required by observations.
Due to this property, partition-based methods could
have high scalability for more complex practical do-
mains.
Bayesian network based approximate methods
also emerged to tackle the complexity of represent-
ing and tracking multiple dialog states within proba-
bilistic frameworks (Raux and Ma, 2011; Thomson
and Young, 2010). In previous work, we presented
a new probabilistic model – DPOT (Dynamic Prob-
abilistic Ontology Trees) – to track dialog state in a
spoken dialog system (Raux and Ma, 2011). DPOT
captures both the user goal and the history of user di-
alog acts (user actions) using a unified Bayesian net-
work. Efficient inference (a form of blocked Gibbs
sampling) is performed to exploit the structure of
the model. Evaluation on a corpus of dialogs from
the CMU Let’s Go system shows that DPOT signif-
icantly outperforms a deterministic baseline by ex-
ploiting long ASR N-best lists without loss of ac-
curacy. At any point in the dialog, the joint distri-
bution over the goal network represents the inferred
dialog state about the user goal.1 The goal network
of DPOT does not expand per time slice for each
turn but the evidence accumulates as the dialog pro-
</bodyText>
<footnote confidence="0.891626333333333">
1In the Let’s Go bus information system, a user goal is de-
composed into three concepts: Bus (the bus number), prig
(the origin stop) and Dest (the destination stop).
</footnote>
<bodyText confidence="0.999604">
gresses. Therefore the model becomes inefficient
when users change their mind – user has to repeat
multiple times in order to possibly trigger a goal
change in the inferred dialog state.
</bodyText>
<figureCaption confidence="0.8567415">
Figure 2: Example of user goal change: at the end of the
dialog the user would like to explore alternative flights at
a different time, but the dialog system did not expect such
a user action, leading to a system failure
</figureCaption>
<bodyText confidence="0.9816182">
Current approaches often assume that user would
have a fixed goal in his or her mind before convers-
ing with the system and this single goal remains un-
changed throughout the dialog. However, the key
question we would like to raise here is that whether
the assumption that a user would not change her or
his mind during the dialog is reasonable or not in
the first place.2 Figure 2 shows an example where
user goal evolves as the dialog moves on. In this ex-
ample, the system did not catch the partial change
of user goal and failed to return alternative answers
given a new request from the user – now the fixed
goal assumption has been challenged. Moreover,
sometimes people do not even have a clear goal in
their minds before they start speaking to the system
(e.g., a user might want a flight from Columbus to
San Francisco during the coming weekend, but the
exact departure date depends on user’s schedule as
well as the price of the ticket.). From the example
dialog shown in Figure 2, clearly it can be noticed
that there are some useful hints or linguistic patterns
– such as How about ...? and ... instead? – which
could be extracted from the user’s spoken language
2It is true that for some simple domains such as luggage re-
trieval or call routing, users are less likely to change their mind.
</bodyText>
<page confidence="0.981244">
92
</page>
<bodyText confidence="0.951021063829787">
as predictors for potential user goal change. We can
then further use this predicted information (user goal
changed or not) to better infer the true user goal and
prevent a system failure or start over. In fact, it is
this intuition that forms the basis of the proposed
methods.
However, existing methods heavily rely on the as-
sumption that user won’t change her or his mind
throughout the dialog. In order to keep the compu-
tations tractable in practice, POMDP-based methods
often assume that user goal does not change during
the dialog (Young et al., 2010). Moreover, within
the POMDP framework there is a user action model
which would suppress the weights of conflict ob-
servations for those slots which have already been
filled – the intuition is that if a value for a certain
slot has already been provided or observed, it is
less likely that a new value will be provided again
(based on the assumption of fixed user goal) and it
is more likely to be a speech recognition error in-
stead (Williams and Young, 2007). Furthermore,
one of the claimed benefit for existing statistical di-
alog state inference methods is the ability to exploit
the information lower down from ASR N-best lists
by aggregating weak information across multiple di-
alog turns – the intuition is that overlapped consis-
tent weak evidence is sometimes a useful hint for
predicting the underlying true user goal (as illus-
trated in Figure 3) – again it implies that the user
would repeatedly refine the same goal until the ma-
chine gets it.
Figure 3: Given the fact that user action BOSTON has
been repeatedly observed as DEPARTURE CITY across
the first two turns – although not at the top position of the
ASR N-best list – existing statistical dialog state tracking
algorithms would capture this pattern and put a strong
bias on BOSTON as the inferred user goal.
It is true that putting such a constraint – assum-
ing a fixed user goal during the dialog – simplifies
the computational complexity, it also sacrifices the
flexibility and usability of a spoken dialog system.
Although one could think of some hand-crafted and
ad-hoc rules such as explicit or implicit confirma-
tion/disconfirmation to deal with sudden user goal
changes during a dialog, it increases the number of
dialog turns and makes the dialog system less natu-
ral and user friendly.
</bodyText>
<sectionHeader confidence="0.943804" genericHeader="method">
3 Spoken Dialog State Tracking with
</sectionHeader>
<subsectionHeader confidence="0.8454695">
Explicit Model of User Goal Change
3.1 BuildByVoice Domain
</subsectionHeader>
<bodyText confidence="0.999937">
In fact, there are many situations where frequent
user goal changes would be highly expected (i.e. the
user might try to negotiate with the system). These
domains might include but not limited to finding
nearby restaurants or hotels, searching for movies
to watch, ordering food or online shopping, etc., in
which users are very likely to explore different alter-
natives and their goals would probably change fre-
quently as the dialog progresses.
</bodyText>
<figureCaption confidence="0.980619">
Figure 4: An experimental web interface prototype for
BuildByVoice – a spoken dialog system aimed to assist
potential car buyers to customize a car by voice
</figureCaption>
<bodyText confidence="0.99995">
Considering one typical example among those do-
mains – a spoken interactive system which could al-
low a user to configure a new car by speech (a pro-
totype web interface of the BuildByVoice system is
shown in Figure 43) – one could imagine the user
would tend to experiment many possible combina-
tions of different configurations for a car. Indeed
that is the purpose of having such a system so that
users could preview the resulting effect before a real
car is made. A BuildByVoice domain may consist of
</bodyText>
<footnote confidence="0.9924105">
3A baseline BuildByVoice system by using DPOT for dialog
state tracking (without user goal change detection) is under im-
plementation. The baseline system will be deployed to Amazon
Mechanical Turk for initial data collection.
</footnote>
<page confidence="0.988723">
93
</page>
<table confidence="0.933607235294118">
the following five independent concepts with their
possible values listed as follows:4
Model: Accord Coupe, Accord Sedan,
Accord Plug-In, Civic Coupe,
Civic Sedan, . . . 5
Engine: V4, V4 Turbo, V4 Sport, V6, V6
Turbo, V6 Sport,...
Exterior Color: Toffee Brown, Coffee
Brown, Candy Brown, Night Blue,
Moonlight Blue,Midnight Blue,...
Interior Color: Black Leather, Black
Vinyl, Gray Leather, Gray Vinyl,
Brown Leather, Brown Vinyl,...
Wheels: 17 inches Steel, 17 inches
Alloy, 18 inches Steel, 18 inches
Alloy, 18 inches Polished Alloy,
. . .
</table>
<bodyText confidence="0.99980147826087">
In (Ammicht et al., 2007), the semantic represen-
tation of a spoken dialog system is augmented with
a dynamic parameter that determines the evolution
of a concept-value pair over time, which could be
considered as early attempts for coping with user
goal changes. However, the determined dynamic
confidence score is used to make a hard choice
for the candidate semantic values, i.e., determin-
ing the birth and death of the observed concept-
value pairs. Thomson and Young (2010) intro-
duced a new POMDP-based framework for building
spoken dialog systems by using Bayesian updates
of dialog state (BUDS). It accommodates for user
goal changes by using a dynamic Bayesian network,
but BUDS is generative rather than a discriminative
model. Therefore it lacks the flexibility of incor-
porating all kinds of overlapping features – one of
the advantages discriminative models have. Further-
more, BUDS assumes limited changes in the user
goal in order to gain further efficiency. More re-
cently, Gaˇsi´c and Young (2011) introduces the ex-
plicit representation of complements in partitions
which enables negotiation-type dialogs when user
</bodyText>
<footnote confidence="0.9993375">
4More concepts could also be included such as Accessories
or MPG Level, but only these five concepts are picked for
demonstration purpose.
5Here Honda car models are used as an example.
</footnote>
<bodyText confidence="0.999927909090909">
goal evolves during the dialog. However, the explicit
representation of complements is used to provide ex-
istential and universal quantifiers in the system’s re-
sponse.6 Also a special pruning technique is needed
in their approach to ensure the number of partitions
doesn’t grow exponentially.
Therefore, new approaches for recognizing the
event of user goal change and utilizing the goal
change information to better infer dialog states have
been proposed in the following two subsections 3.2
and 3.3.
</bodyText>
<subsectionHeader confidence="0.998023">
3.2 Dialog State Tracking with Detected User
Goal Change
</subsectionHeader>
<bodyText confidence="0.995803931034483">
Dialog state tracking is usually considered as the
core component of a spoken dialog system where di-
alog manager uses the inferred dialog states to gen-
erate system responses (normally through a learned
or hand-crafted policy mapping from dialog states to
system actions). A specialized version of Maximum
Entropy Markov Model with user goal change vari-
able is proposed for dialog state tracking.7 The most
probable dialog state sequence as well as the most
likely dialog state value for the latest turn can be in-
ferred given the model. Figure 5 illustrates how the
proposed model could infer dialog states of a sin-
gle concept Exterior Color for a dialog of four user
turns where the user changes her or his mind at the
third dialog turn.8
For traditional dialog state tracking methods with-
out user goal change model, the system would be
quite confused by completely conflicting observed
user actions starting from the third dialog turn. How-
ever, the proposed MEMM with user goal change
detection could notice that the user has already
changed her or his mind. Therefore the proposed
model would not only trust more on the observed
user actions for the current dialog turn, but also fa-
vor those transitions which lead to a different state
value by increasing corresponding transition proba-
bilities.
6E.g., “Charlie Chan is the only Chinese restaurant in the
center.” or “All Chinese restaurants are in the center.”
</bodyText>
<footnote confidence="0.9890884">
7Methods for detecting user goal change are described in
Section 3.3.
8We assume every concept in the domain is mutually inde-
pendent with each other and we model the user goal change
separately for each concept.
</footnote>
<page confidence="0.998959">
94
</page>
<figureCaption confidence="0.973025">
Figure 5: MEMM for dialog state tracking with explicit user goal change variable. A single concept Exterior Color
</figureCaption>
<bodyText confidence="0.91629096">
from BuildByVoice domain is tracked by the model. The shaded nodes are observed user actions and the white nodes
are hidden dialog states. The bold text in the observed nodes indicates the true user actions whereas the bold text in
the hidden states shows the true dialog state sequence (in this case it is also the most probable decoded dialog state
path inferred by the model).
A more formal description of the proposed
MEMM is given as follows. The observations ot
(shaded nodes) consist of N-best lists of semantic
speech hypotheses (or dialog acts) with confidence
scores (scale from 0 to 100) for the current dialog
turn hypt and previous turn hypt−1 as well as the
binary goal change variable gct for the current turn
– essentially a context window of speech hypotheses
including history:
ot = {hypt−1, hypt, gct}
Typically the semantic speech hypotheses hypt are
extracted concept-value pairs out of ASR results by
using a semantic tagger (such as an FST (Finite State
Transducer) parser or a segment-based semi-Markov
CRF semantic labeler (Liu et al., 2012)). The hid-
den dialog state qt (white nodes) represents the user
goal for dialog turn t (such as a particular color
Moonlight Blue for Exterior Color at time t).
The individual probability of a transition from a state
qt−1 to a state qt producing an observation ot is in a
form of the following:
</bodyText>
<equation confidence="0.965665">
exp(En k=1 wkfk(qt−1, qt, ot))
P(qt|qt−1, ot) =
Z(ot, qt−1)
</equation>
<bodyText confidence="0.999975375">
Given labeled sequences of true dialog states (true
user goal) for each turn, the corresponding obser-
vations and designed feature functions, we want to
learn a set of weights wk to optimize the discrimina-
tion among competing state values given the train-
ing data. In other words, the learning procedure in-
volves searching in parameter space to maximize the
following conditional likelihood:
</bodyText>
<equation confidence="0.8337235">
exp(Enk=1 wkfk(qi,t−1, qit, oit))
Z(oit, qi,t−1)
</equation>
<bodyText confidence="0.999961888888889">
where N is the number of training dialogs. MEMM
can be trained with methods from the field of convex
optimization and Viterbi decoding algorithm could
be applied to MEMMs for inference (McCallum et
al., 2000).
The proposed feature functions are as follows.
The first feature function (1a) implies that if the user
goal is not changed, the system should look for the
common evidence across dialog turns.
</bodyText>
<equation confidence="0.893313333333333">
1 if gct=0 &amp;
vEcommon(hypt−1, hypt)
0 otherwise
</equation>
<bodyText confidence="0.974437142857143">
(1a)
where common(hypt−1, hypt) will return the over-
lapped values from the two N-best lists of dialog
acts hypt−1 and hypt. The second and third feature
functions ((1b) and (1c)) are basically saying that if a
user goal change has been detected, then we should
expect a different state value, otherwise we should
</bodyText>
<equation confidence="0.9752849">
N
i=1
P(Q|O) =
T
H
t=1
f(qt = v, ot) =
⎧
⎨
⎩
</equation>
<page confidence="0.972419">
95
</page>
<bodyText confidence="0.900954">
remain the same value from previous dialog turn.
</bodyText>
<equation confidence="0.941191666666667">
r 1 if get=0 &amp; u=v
f (qt−1 = u, qt = v, ot) =Sl 0 otherwise
r 1 if get=1 &amp; u�v
</equation>
<bodyText confidence="0.9789155">
f (qt−1 = u, qt = v, ot) =Sl 0 otherwise
The intuition behind the following four feature func-
tions (feature function (1d) to (1g)) is that if the user
changes her or his mind then the model should trust
more on the current observed user actions than those
from previous turn; but if the user does not change
her or his mind, we could then consider the observa-
tions from the past.
</bodyText>
<equation confidence="0.966470909090909">
_ _ r 1 if get=0 &amp; vEhypt−1
f (qt — v, ot) S 0 otherwise
� 1 if get=1 &amp; vEhypt−1
f(qt = v, ot) =
0 otherwise
(1e)
_ = r 1 if get=0 &amp; vEhypt
f (qt — v, ot)S (1f)
0 otherwise
� _ 1 if get=1 &amp; vEhypt 1
f (qt = v ot) 0 otherwise (g)
</equation>
<bodyText confidence="0.999958">
The last two feature functions ((1h) and (1i)) try
to incorporate information from confidence scores
– the higher the confidence score is, the more likely
the hypothesis is to be correct.
</bodyText>
<figure confidence="0.708599571428571">
{ 1 if vEhypt &amp;
confidencehypt(v)&gt;C
0 otherwise
{ 1 if get=0 &amp;
vEhypt−1 &amp;
confidencehypt−1(v)&gt;C
0 otherwise
</figure>
<bodyText confidence="0.999787">
where confidencehypt(v) returns the confidence
score for value v in the speech hypotheses N-best
list hypt and C is an empirical constant threshold
range between 0 to 100 obtained from the training
corpus.
</bodyText>
<subsectionHeader confidence="0.943606">
3.3 User Goal Change Detection with
Linguistic Features and Dialog Context
</subsectionHeader>
<bodyText confidence="0.999990033333333">
In previous subsection 3.2, we assume we already
know whether or not user changes her or his mind
at each dialog turn, whereas this subsection we dis-
cuss the possible approaches on how to detect a user
goal change. Detecting user goal changes during a
dialog could be cast as a binary classification prob-
lem where class 0 means no goal change and class 1
indicates user changes her or his mind during a dia-
log turn. Candidate machine learning algorithms in-
cluding MLP (Multi-layer Perceptron), SVM (Sup-
port Vector Machine) or Logistic Regression could
be applied to this binary classification problem in
a supervised manner. The input features might be
extracted from user utterance transcription9 and the
corresponding ASR N-best list for each dialog turn.
As mentioned in Section 2, the language patterns
found in the user utterances as presented in the ex-
ample dialog (shown in Figure 2) forms the intuition
for linguistic features to identify user goal change.
The dialog context such as last system action could
also be included as useful hint for predicting a po-
tential user goal change – user is likely to change
her or his goal if system returns empty results for a
request. Also other helpful features could include
bag of words model, n-grams, prosodic features
(e.g., a pitch change or initial pause) and parsed fea-
tures (e.g., WH questions). Baseline system such
as key word spotting based approach (i.e. look for
How/What about in a sentence) could also be imple-
mented for performance comparison.10
</bodyText>
<sectionHeader confidence="0.999554" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999984727272727">
By modeling the user goal change in a probabilistic
framework, the proposed approach should better ex-
ploit the mutual information buried deep in the ASR
N-best lists across dialog turns, which leads to more
robust and accurate dialog state estimation. With
the ability to predict and handle user goal change,
proposed techniques provide a bottom-up solution
for managing negotiation style dialogs and not only
should produce more efficient and natural conver-
sations but also open up new possibilities for auto-
mated negotiation dialog policy learning.
</bodyText>
<footnote confidence="0.93565725">
9At test time, this could be approximated by the top hypoth-
esis in the ASR N-best list.
10A detailed list of proposed features is omitted due to space
limit.
</footnote>
<equation confidence="0.9956415">
f(qt = v, ot) =
f(qt = v, ot) =
</equation>
<page confidence="0.997026">
96
</page>
<sectionHeader confidence="0.995876" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999390317073171">
Egbert Ammicht, Eric Fosler-Lussier, and Alexandros
Potamianos. 2007. Information seeking spoken di-
alogue systems—part i: Semantics and pragmatics.
Multimedia, IEEE Transactions on, 9(3):532–549.
M. Ga&amp;quot;si´c and S. Young. 2011. Effective handling
of dialogue state in the hidden information state
pomdp-based dialogue manager. ACM Transactions
on Speech and Language Processing (TSLP), 7(3):4.
James Henderson, Oliver Lemon, and Kallirroi Georgila.
2008. Hybrid reinforcement/supervised learning of di-
alogue policies from fixed data sets. Computational
Linguistics, 34(4):487–511.
J. Liu, S. Cyphers, P. Pasupat, I. McGraw, and J. Glass.
2012. A conversational movie search system based on
conditional random fields. In INTERSPEECH.
A. McCallum, D. Freitag, and F. Pereira. 2000. Maxi-
mum entropy markov models for information extrac-
tion and segmentation. In Proceedings of the Seven-
teenth International Conference on Machine Learning,
volume 951, pages 591–598.
A. Raux and Y. Ma. 2011. Efficient probabilistic track-
ing of user goal and dialog history for spoken dialog
systems. In Twelfth Annual Conference of the Interna-
tional Speech Communication Association.
Blaise Thomson and Steve Young. 2010. Bayesian up-
date of dialogue state: A pomdp framework for spo-
ken dialogue systems. Computer Speech &amp; Language,
24(4):562–588.
J.D. Williams and S. Young. 2007. Partially observable
markov decision processes for spoken dialog systems.
Computer Speech &amp; Language, 21(2):393–422.
Jason D Williams. 2010. Incremental partition recombi-
nation for efficient tracking of multiple dialog states.
In Acoustics Speech and Signal Processing (ICASSP),
2010 IEEE International Conference on, pages 5382–
5385. IEEE.
S. Young, M. Ga&amp;quot;si´c, S. Keizer, F. Mairesse, J. Schatz-
mann, B. Thomson, and K. Yu. 2010. The hidden
information state model: A practical framework for
pomdp-based spoken dialogue management. Com-
puter Speech &amp; Language, 24(2):150–174.
</reference>
<page confidence="0.99969">
97
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.798843">
<title confidence="0.999617">User Goal Change Model for Spoken Dialog State Tracking</title>
<author confidence="0.997748">Yi</author>
<affiliation confidence="0.9823265">Department of Computer Science &amp; The Ohio State</affiliation>
<address confidence="0.992059">Columbus, OH 43210,</address>
<email confidence="0.999788">may@cse.ohio-state.edu</email>
<abstract confidence="0.99177395">In this paper, a Maximum Entropy Markov Model (MEMM) for dialog state tracking is proposed to efficiently handle user goal evolvement in two steps. The system first predicts the occurrence of a user goal change based on linguistic features and dialog context for each dialog turn, and then the proposed model could utilize this user goal change information to infer the most probable dialog state sequence which underlies the evolvement of user goal during the dialog. It is believed that with the suggested various domain independent feature functions, the proposed model could better exploit not only the intra-dependencies within long ASR N-best lists but also the inter-dependencies of the observations across dialog turns, which leads to more efficient and accurate dialog state inference.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Egbert Ammicht</author>
</authors>
<title>Eric Fosler-Lussier, and Alexandros Potamianos.</title>
<date>2007</date>
<journal>IEEE Transactions on,</journal>
<volume>9</volume>
<issue>3</issue>
<marker>Ammicht, 2007</marker>
<rawString>Egbert Ammicht, Eric Fosler-Lussier, and Alexandros Potamianos. 2007. Information seeking spoken dialogue systems—part i: Semantics and pragmatics. Multimedia, IEEE Transactions on, 9(3):532–549.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Gasi´c</author>
<author>S Young</author>
</authors>
<title>Effective handling of dialogue state in the hidden information state pomdp-based dialogue manager.</title>
<date>2011</date>
<journal>ACM Transactions on Speech and Language Processing (TSLP),</journal>
<volume>7</volume>
<issue>3</issue>
<marker>Gasi´c, Young, 2011</marker>
<rawString>M. Ga&amp;quot;si´c and S. Young. 2011. Effective handling of dialogue state in the hidden information state pomdp-based dialogue manager. ACM Transactions on Speech and Language Processing (TSLP), 7(3):4.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Henderson</author>
<author>Oliver Lemon</author>
<author>Kallirroi Georgila</author>
</authors>
<title>Hybrid reinforcement/supervised learning of dialogue policies from fixed data sets.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>4</issue>
<contexts>
<context position="3462" citStr="Henderson et al., 2008" startWordPosition="539" endWordPosition="542">earch Workshop, pages 91–97, Atlanta, Georgia, 13 June 2013. c�2013 Association for Computational Linguistics ing process, it is impossible for a spoken dialog system to observe the true user goal directly. Therefore, methods to efficiently infer the true hidden dialog states from noisy observations over multiple dialog turns become crucial for building a robust spoken dialog system. The POMDP (Partially Observable Markov Decision Process) framework has been proposed to maintain multiple dialog state hypotheses under uncertainty with automated dialog policy learning (Williams and Young, 2007; Henderson et al., 2008; Thomson and Young, 2010; Young et al., 2010). Although the original POMDP framework suffers difficulties of scaling up the model to handle real-world domains in practice, it provides a unified statistical framework for existing techniques with global optimization. Partition-based approaches (Gaˇsi´c and Young, 2011; Williams, 2010; Young et al., 2010) attempt to group user goals into a number of partitions and won’t split a partition unless when a distinction is required by observations. Due to this property, partition-based methods could have high scalability for more complex practical doma</context>
</contexts>
<marker>Henderson, Lemon, Georgila, 2008</marker>
<rawString>James Henderson, Oliver Lemon, and Kallirroi Georgila. 2008. Hybrid reinforcement/supervised learning of dialogue policies from fixed data sets. Computational Linguistics, 34(4):487–511.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Liu</author>
<author>S Cyphers</author>
<author>P Pasupat</author>
<author>I McGraw</author>
<author>J Glass</author>
</authors>
<title>A conversational movie search system based on conditional random fields.</title>
<date>2012</date>
<booktitle>In INTERSPEECH.</booktitle>
<contexts>
<context position="15956" citStr="Liu et al., 2012" startWordPosition="2633" endWordPosition="2636">he observations ot (shaded nodes) consist of N-best lists of semantic speech hypotheses (or dialog acts) with confidence scores (scale from 0 to 100) for the current dialog turn hypt and previous turn hypt−1 as well as the binary goal change variable gct for the current turn – essentially a context window of speech hypotheses including history: ot = {hypt−1, hypt, gct} Typically the semantic speech hypotheses hypt are extracted concept-value pairs out of ASR results by using a semantic tagger (such as an FST (Finite State Transducer) parser or a segment-based semi-Markov CRF semantic labeler (Liu et al., 2012)). The hidden dialog state qt (white nodes) represents the user goal for dialog turn t (such as a particular color Moonlight Blue for Exterior Color at time t). The individual probability of a transition from a state qt−1 to a state qt producing an observation ot is in a form of the following: exp(En k=1 wkfk(qt−1, qt, ot)) P(qt|qt−1, ot) = Z(ot, qt−1) Given labeled sequences of true dialog states (true user goal) for each turn, the corresponding observations and designed feature functions, we want to learn a set of weights wk to optimize the discrimination among competing state values given t</context>
</contexts>
<marker>Liu, Cyphers, Pasupat, McGraw, Glass, 2012</marker>
<rawString>J. Liu, S. Cyphers, P. Pasupat, I. McGraw, and J. Glass. 2012. A conversational movie search system based on conditional random fields. In INTERSPEECH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A McCallum</author>
<author>D Freitag</author>
<author>F Pereira</author>
</authors>
<title>Maximum entropy markov models for information extraction and segmentation.</title>
<date>2000</date>
<booktitle>In Proceedings of the Seventeenth International Conference on Machine Learning,</booktitle>
<volume>951</volume>
<pages>591--598</pages>
<contexts>
<context position="16958" citStr="McCallum et al., 2000" startWordPosition="2800" endWordPosition="2803">f true dialog states (true user goal) for each turn, the corresponding observations and designed feature functions, we want to learn a set of weights wk to optimize the discrimination among competing state values given the training data. In other words, the learning procedure involves searching in parameter space to maximize the following conditional likelihood: exp(Enk=1 wkfk(qi,t−1, qit, oit)) Z(oit, qi,t−1) where N is the number of training dialogs. MEMM can be trained with methods from the field of convex optimization and Viterbi decoding algorithm could be applied to MEMMs for inference (McCallum et al., 2000). The proposed feature functions are as follows. The first feature function (1a) implies that if the user goal is not changed, the system should look for the common evidence across dialog turns. 1 if gct=0 &amp; vEcommon(hypt−1, hypt) 0 otherwise (1a) where common(hypt−1, hypt) will return the overlapped values from the two N-best lists of dialog acts hypt−1 and hypt. The second and third feature functions ((1b) and (1c)) are basically saying that if a user goal change has been detected, then we should expect a different state value, otherwise we should N i=1 P(Q|O) = T H t=1 f(qt = v, ot) = ⎧ ⎨ ⎩</context>
</contexts>
<marker>McCallum, Freitag, Pereira, 2000</marker>
<rawString>A. McCallum, D. Freitag, and F. Pereira. 2000. Maximum entropy markov models for information extraction and segmentation. In Proceedings of the Seventeenth International Conference on Machine Learning, volume 951, pages 591–598.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Raux</author>
<author>Y Ma</author>
</authors>
<title>Efficient probabilistic tracking of user goal and dialog history for spoken dialog systems.</title>
<date>2011</date>
<booktitle>In Twelfth Annual Conference of the International Speech Communication Association.</booktitle>
<contexts>
<context position="4250" citStr="Raux and Ma, 2011" startWordPosition="659" endWordPosition="662">, it provides a unified statistical framework for existing techniques with global optimization. Partition-based approaches (Gaˇsi´c and Young, 2011; Williams, 2010; Young et al., 2010) attempt to group user goals into a number of partitions and won’t split a partition unless when a distinction is required by observations. Due to this property, partition-based methods could have high scalability for more complex practical domains. Bayesian network based approximate methods also emerged to tackle the complexity of representing and tracking multiple dialog states within probabilistic frameworks (Raux and Ma, 2011; Thomson and Young, 2010). In previous work, we presented a new probabilistic model – DPOT (Dynamic Probabilistic Ontology Trees) – to track dialog state in a spoken dialog system (Raux and Ma, 2011). DPOT captures both the user goal and the history of user dialog acts (user actions) using a unified Bayesian network. Efficient inference (a form of blocked Gibbs sampling) is performed to exploit the structure of the model. Evaluation on a corpus of dialogs from the CMU Let’s Go system shows that DPOT significantly outperforms a deterministic baseline by exploiting long ASR N-best lists without</context>
</contexts>
<marker>Raux, Ma, 2011</marker>
<rawString>A. Raux and Y. Ma. 2011. Efficient probabilistic tracking of user goal and dialog history for spoken dialog systems. In Twelfth Annual Conference of the International Speech Communication Association.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Blaise Thomson</author>
<author>Steve Young</author>
</authors>
<title>Bayesian update of dialogue state: A pomdp framework for spoken dialogue systems.</title>
<date>2010</date>
<journal>Computer Speech &amp; Language,</journal>
<volume>24</volume>
<issue>4</issue>
<contexts>
<context position="3487" citStr="Thomson and Young, 2010" startWordPosition="543" endWordPosition="546">–97, Atlanta, Georgia, 13 June 2013. c�2013 Association for Computational Linguistics ing process, it is impossible for a spoken dialog system to observe the true user goal directly. Therefore, methods to efficiently infer the true hidden dialog states from noisy observations over multiple dialog turns become crucial for building a robust spoken dialog system. The POMDP (Partially Observable Markov Decision Process) framework has been proposed to maintain multiple dialog state hypotheses under uncertainty with automated dialog policy learning (Williams and Young, 2007; Henderson et al., 2008; Thomson and Young, 2010; Young et al., 2010). Although the original POMDP framework suffers difficulties of scaling up the model to handle real-world domains in practice, it provides a unified statistical framework for existing techniques with global optimization. Partition-based approaches (Gaˇsi´c and Young, 2011; Williams, 2010; Young et al., 2010) attempt to group user goals into a number of partitions and won’t split a partition unless when a distinction is required by observations. Due to this property, partition-based methods could have high scalability for more complex practical domains. Bayesian network bas</context>
<context position="11753" citStr="Thomson and Young (2010)" startWordPosition="1948" endWordPosition="1951">ay Vinyl, Brown Leather, Brown Vinyl,... Wheels: 17 inches Steel, 17 inches Alloy, 18 inches Steel, 18 inches Alloy, 18 inches Polished Alloy, . . . In (Ammicht et al., 2007), the semantic representation of a spoken dialog system is augmented with a dynamic parameter that determines the evolution of a concept-value pair over time, which could be considered as early attempts for coping with user goal changes. However, the determined dynamic confidence score is used to make a hard choice for the candidate semantic values, i.e., determining the birth and death of the observed conceptvalue pairs. Thomson and Young (2010) introduced a new POMDP-based framework for building spoken dialog systems by using Bayesian updates of dialog state (BUDS). It accommodates for user goal changes by using a dynamic Bayesian network, but BUDS is generative rather than a discriminative model. Therefore it lacks the flexibility of incorporating all kinds of overlapping features – one of the advantages discriminative models have. Furthermore, BUDS assumes limited changes in the user goal in order to gain further efficiency. More recently, Gaˇsi´c and Young (2011) introduces the explicit representation of complements in partitions</context>
</contexts>
<marker>Thomson, Young, 2010</marker>
<rawString>Blaise Thomson and Steve Young. 2010. Bayesian update of dialogue state: A pomdp framework for spoken dialogue systems. Computer Speech &amp; Language, 24(4):562–588.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J D Williams</author>
<author>S Young</author>
</authors>
<title>Partially observable markov decision processes for spoken dialog systems.</title>
<date>2007</date>
<journal>Computer Speech &amp; Language,</journal>
<volume>21</volume>
<issue>2</issue>
<contexts>
<context position="3438" citStr="Williams and Young, 2007" startWordPosition="535" endWordPosition="538">NAACL HLT 2013 Student Research Workshop, pages 91–97, Atlanta, Georgia, 13 June 2013. c�2013 Association for Computational Linguistics ing process, it is impossible for a spoken dialog system to observe the true user goal directly. Therefore, methods to efficiently infer the true hidden dialog states from noisy observations over multiple dialog turns become crucial for building a robust spoken dialog system. The POMDP (Partially Observable Markov Decision Process) framework has been proposed to maintain multiple dialog state hypotheses under uncertainty with automated dialog policy learning (Williams and Young, 2007; Henderson et al., 2008; Thomson and Young, 2010; Young et al., 2010). Although the original POMDP framework suffers difficulties of scaling up the model to handle real-world domains in practice, it provides a unified statistical framework for existing techniques with global optimization. Partition-based approaches (Gaˇsi´c and Young, 2011; Williams, 2010; Young et al., 2010) attempt to group user goals into a number of partitions and won’t split a partition unless when a distinction is required by observations. Due to this property, partition-based methods could have high scalability for mor</context>
<context position="8009" citStr="Williams and Young, 2007" startWordPosition="1328" endWordPosition="1331">dialog. In order to keep the computations tractable in practice, POMDP-based methods often assume that user goal does not change during the dialog (Young et al., 2010). Moreover, within the POMDP framework there is a user action model which would suppress the weights of conflict observations for those slots which have already been filled – the intuition is that if a value for a certain slot has already been provided or observed, it is less likely that a new value will be provided again (based on the assumption of fixed user goal) and it is more likely to be a speech recognition error instead (Williams and Young, 2007). Furthermore, one of the claimed benefit for existing statistical dialog state inference methods is the ability to exploit the information lower down from ASR N-best lists by aggregating weak information across multiple dialog turns – the intuition is that overlapped consistent weak evidence is sometimes a useful hint for predicting the underlying true user goal (as illustrated in Figure 3) – again it implies that the user would repeatedly refine the same goal until the machine gets it. Figure 3: Given the fact that user action BOSTON has been repeatedly observed as DEPARTURE CITY across the </context>
</contexts>
<marker>Williams, Young, 2007</marker>
<rawString>J.D. Williams and S. Young. 2007. Partially observable markov decision processes for spoken dialog systems. Computer Speech &amp; Language, 21(2):393–422.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason D Williams</author>
</authors>
<title>Incremental partition recombination for efficient tracking of multiple dialog states.</title>
<date>2010</date>
<booktitle>In Acoustics Speech and Signal Processing (ICASSP), 2010 IEEE International Conference on,</booktitle>
<pages>5382--5385</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="3796" citStr="Williams, 2010" startWordPosition="590" endWordPosition="591"> for building a robust spoken dialog system. The POMDP (Partially Observable Markov Decision Process) framework has been proposed to maintain multiple dialog state hypotheses under uncertainty with automated dialog policy learning (Williams and Young, 2007; Henderson et al., 2008; Thomson and Young, 2010; Young et al., 2010). Although the original POMDP framework suffers difficulties of scaling up the model to handle real-world domains in practice, it provides a unified statistical framework for existing techniques with global optimization. Partition-based approaches (Gaˇsi´c and Young, 2011; Williams, 2010; Young et al., 2010) attempt to group user goals into a number of partitions and won’t split a partition unless when a distinction is required by observations. Due to this property, partition-based methods could have high scalability for more complex practical domains. Bayesian network based approximate methods also emerged to tackle the complexity of representing and tracking multiple dialog states within probabilistic frameworks (Raux and Ma, 2011; Thomson and Young, 2010). In previous work, we presented a new probabilistic model – DPOT (Dynamic Probabilistic Ontology Trees) – to track dial</context>
</contexts>
<marker>Williams, 2010</marker>
<rawString>Jason D Williams. 2010. Incremental partition recombination for efficient tracking of multiple dialog states. In Acoustics Speech and Signal Processing (ICASSP), 2010 IEEE International Conference on, pages 5382– 5385. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Young</author>
<author>M Gasi´c</author>
<author>S Keizer</author>
<author>F Mairesse</author>
<author>J Schatzmann</author>
<author>B Thomson</author>
<author>K Yu</author>
</authors>
<title>The hidden information state model: A practical framework for pomdp-based spoken dialogue management.</title>
<date>2010</date>
<journal>Computer Speech &amp; Language,</journal>
<volume>24</volume>
<issue>2</issue>
<marker>Young, Gasi´c, Keizer, Mairesse, Schatzmann, Thomson, Yu, 2010</marker>
<rawString>S. Young, M. Ga&amp;quot;si´c, S. Keizer, F. Mairesse, J. Schatzmann, B. Thomson, and K. Yu. 2010. The hidden information state model: A practical framework for pomdp-based spoken dialogue management. Computer Speech &amp; Language, 24(2):150–174.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>