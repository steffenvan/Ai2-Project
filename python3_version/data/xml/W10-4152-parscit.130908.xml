<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002297">
<title confidence="0.9954795">
The Chinese Persons Name Disambiguation Evaluation: Exploration of
Personal Name Disambiguation in Chinese News
</title>
<author confidence="0.888102">
Ying Chen*, Peng Jin†, Wenjie Li*,Chu-Ren Huang*
</author>
<affiliation confidence="0.805882">
* China Agricultural University †Leshan Teachers’ College *The Hong Kong Polytechnic University
</affiliation>
<email confidence="0.941899">
chenying3176@gmail.com jandp@pku.edu.cn cswjli@comp.polyu.edu.hk
churenhuang@gmail.com
</email>
<sectionHeader confidence="0.995421" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999246272727273">
Personal name disambiguation becomes hot as it
provides a way to incorporate semantic under-
standing into information retrieval. In this cam-
paign, we explore Chinese personal name
disambiguation in news. In order to examine how
well disambiguation technologies work, we con-
centrate on news articles, which is well-formatted
and whose genre is well-studied. We then design a
diagnosis test to explore the impact of Chinese
word segmentation to personal name disambigua-
tion.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999870895833334">
Incorporating semantic understanding technolo-
gies from the field of NLP becomes one of further
directions for information retrieval. Among them,
named entity disambiguation, which intends to
use state-of-the-art named entity processing to
enhance a search engine, is a hot research issue.
Because of the popularity of personal names in
queries, more efforts are put on personal name
disambiguation. The personal name disambigua-
tion used both in Web Personal Search (WePS1)
and our campaign is defined as follow. Given
documents containing a personal name in interest,
the task is to cluster them according to which en-
tity the name in a document refers to.
WePS, which explores English personal name
disambiguation, has been held twice (Artiles et al.,
2007, 2009). Compared to the one in English, per-
sonal name disambiguation in Chinese has special
issues, such as Chinese text processing and Chi-
nese personal naming system. Therefore, we hold
Chinese personal name disambiguation (CPND) to
explore those problems. In this campaign, we
mainly examine the relationships between Chinese
word segmentation and Chinese personal name
disambiguation.
Moreover, from our experiences in WePS
(Chen et al., 2007, 2009), we notice that webpages
are so noisy that text pre-processing that extracts
useful text for disambiguation needs much effort.
In fact, text pre-processing for webpages is rather
complicated, such as deleting of HTML tags, the
detection of JavaScript codes and so on. Therefore,
the final system performance in the WePS cam-
paign sometimes does not reflect the disambigua-
tion power of the system, and instead it shows the
comprehensive result of text pre-processing as
well as disambiguation. In order to focus on per-
sonal name disambiguation, we choose news
documents in CPND.
The paper is organized as follows. Section 2 de-
scribes our formal test including datasets and
evaluation. Section 3 introduces the diagnosis test,
which explores the impact of Chinese word seg-
mentation to personal name disambiguation. Sec-
tion 4 describes our campaign, and Section 5
presents the results of the participating systems.
Finally, Section 6 concludes our main findings in
this campaign.
</bodyText>
<footnote confidence="0.7302105">
1 http://nlp.uned.es/weps/
2 The Formal Test one-in-one and all-in-one clustering. Although the
</footnote>
<bodyText confidence="0.885249">
hybrid cheat system can achieve fairly good per-
formance, it is not useful for real applications. In
</bodyText>
<subsectionHeader confidence="0.612992">
2.1 Datasets the formal test, these three systems serve as the
</subsectionHeader>
<bodyText confidence="0.994382">
baseline.
To avoid the difficulty to clean a webpage, we
choose news articles in this campaign. Given a
full name in Chinese, we search the character-
based personal name string in all documents of
Chinese Gigaword Corpus, a large Chinese news
collection. If a document contains the name, it is
belonged to the dataset of this name. To ensure
the popularity of a personal name, we keep only a
personal name whose corresponding dataset com-
prises more than 100 documents. In addition, if
there are more than 300 documents in that dataset,
we randomly select 300 articles to annotate. Fi-
nally, there are totally 58 personal names and
12,534 news articles used in our data, where 32
names are in the development data and 26 names
are in the test data, as shown Appendix Table 4
and 5 separately.
From Table 4 and 5, we can find that the ambi-
guity (the document number per cluster) distribu-
tion is much different between the development
data and the test data. In fact, the ambiguity var-
ies with a personal name in interest, such as the
popularity of the name in the given corpus, the
celebrity degree of the name, and so on.
</bodyText>
<subsectionHeader confidence="0.9949">
2.2 Evaluation
</subsectionHeader>
<bodyText confidence="0.99990347368421">
In WePS, Artiles et al. (2009) made an intensive
study of clustering evaluation metrics, and found
that B-Cubed metric is an appropriate evaluation
approach. Moreover, in order to handle overlap-
ping clusters (i.e. a personal name in a document
refers to more than one person entity in reality),
we extend B-Cubed metric as Table 1, where S =
{S1, S2, ...} is a system clustering and R = {R1,
R2, ...} is a gold-standard clustering. The final
performance of a system clustering for a personal
name is the F score (= 0.5), and the final per-
formance of a system is the Mac F score, the aver-
age of the F scores of all personal names.
Moreover, Artiles et al. (2009) also discuss
three cheat systems: one-in-one, all-in-one, and
the hybrid cheat system. One-in-one assigns each
document into a cluster, and in contrast, all-in-one
put all documents into one cluster. The hybrid
cheat system just incorporates all clusters both in
</bodyText>
<figure confidence="0.921272071428571">
Formula
Precision i∩ j
 |S R |
� � max R d j
S i ∈ S d∈S i R ; R
j ∈ ∈
i
|S |
ESi∈S |Si |
Recall |Ri∩Sj
7 m Y
ERi ∈ R L∈Ri MaASj ∈S;d∈Sj  |R |
i
ERi∈R  |Ri |
</figure>
<tableCaption confidence="0.961418">
Table 1: the formula of the modified B-cubed
metrics
</tableCaption>
<sectionHeader confidence="0.989313" genericHeader="method">
3 The Diagnosis Test
</sectionHeader>
<bodyText confidence="0.999848384615385">
Because of no word delimiter, Chinese text proc-
essing often needs to do Chinese word segmenta-
tion first. In order to explore the relationship
between personal name disambiguation and word
segmentation, we provide a diagnosis data which
attempts to examine the impact of word segmenta-
tion to disambiguation.
Firstly, for each personal name, its correspond-
ing dataset will be manually divided into three
groups as follows. The disambiguation system
then runs for each group of documents. The three
clustering outputs are merged into the final clus-
tering for that personal name.
</bodyText>
<listItem confidence="0.72079525">
(1) Exactly matching: news articles contain-
ing personal names that exactly match
the query personal name.
(2) Partially matching: news articles contain-
ing personal names that are super-strings
of the query personal name. For instance,
an article that has a person named with
“” (Gao Jun Tian) is retrieved
</listItem>
<bodyText confidence="0.960603">
for the query personal name “ ” (Gao
Jun).
</bodyText>
<listItem confidence="0.744407">
(3) Discarded: news articles containing
</listItem>
<bodyText confidence="0.980873">
character sequences that match the query
personal name string and however in fact
are not a personal name. For instance, an
article that has the string “
” (Zui Gao Jun Shi Fa Yuan: supreme
military court) is also retrieved for the
personal name “” (Gao Jun).
This diagnosis test is designed to simulate the
realistic scenario where Chinese word segmenta-
tion works before personal name disambiguation.
If a Chinese word segmenter works perfectly, a
word-based matching can be used to retrieve the
documents containing a personal name, and arti-
cles in Groups (2) and (3) should not be returned.
The personal name disambiguation task that is
limited to the documents in Group (1) should be
simpler.
Moreover, in this diagnosis test, we propose a
baseline based on the gold-standard word segmen-
tation as follows, namely the word-segment sys-
tem.
</bodyText>
<listItem confidence="0.704509444444444">
1) All articles in the “exactly matching”
group are merged into a cluster, and all
articles in the “discarded” group are
merged into a cluster.
2) In the “partially matching” group, enti-
ties exactly sharing the same personal
name are merged into a cluster. For ex-
ample, all articles containing “”
(Gao Jun Tian) are merged into a cluster,
</listItem>
<bodyText confidence="0.9404665">
and all articles containing ” (Gao
Jun Hua) are merged into another cluster.
</bodyText>
<sectionHeader confidence="0.994967" genericHeader="method">
4 Campaign Design
</sectionHeader>
<subsectionHeader confidence="0.984308">
4.1 The Participants
</subsectionHeader>
<bodyText confidence="0.999886666666667">
The task of Chinese personal name disambigua-
tion in news has attracted the participation of 10
teams. As a team can submit at most 2 results,
there are 17 submissions from the 10 teams in the
formal test, and there are 11 submissions from 7
teams in the diagnosis.
</bodyText>
<subsectionHeader confidence="0.989272">
4.2 System descriptions
</subsectionHeader>
<bodyText confidence="0.999964677419355">
Regarding system architecture, all systems are
based on clustering, and most of them comprise
two components: feature extraction and clustering.
However, NEU-1 and HITSZ_CITYU develop a
different clustering, which in fact is a cascaded
clustering. Taking the advantage of the properties
of a news article, both systems first divide the
dataset for a personal name into two groups ac-
cording to whether the person in question is a re-
porter of the news. They then choose a different
strategy to make further clustering for each group.
In terms of feature extraction, we find that all
systems except SoochowHY use word segmenta-
tion as pre-processing. Moreover, most systems
choose named entity detection to enhance their
feature extraction. In addition, character-based
bigrams are also used in some systems. In Ap-
pendix Table 6, we give the summary of word
segmentation and named entity detection used in
the participating systems.
Regarding clustering algorithms, agglomerative
hierarchical clustering is popular in the submis-
sions. Moreover, we find that weight learning is
very crucial for similarity matrix, which has a big
impact to the final clustering performance. Be-
sides the popular Boolean and TFIDF weighting
schemes, SoochowHY and NEU-2 use different
weighting learning. NEU-2 manually assigns
weights to different kinds of features. So-
ochowHY develops an algorithm that iteratively
learns a weight for a character-based n-gram.
</bodyText>
<sectionHeader confidence="0.999917" genericHeader="evaluation">
5 Results
</sectionHeader>
<bodyText confidence="0.999912">
We first provide the performances of the formal
test, and make some analysis. We then present and
discuss the performances of the diagnosis test.
</bodyText>
<subsectionHeader confidence="0.977813">
5.1 Results of the Formal test
</subsectionHeader>
<bodyText confidence="0.998934352941176">
For the formal test, we show the performances of
11 submissions from 10 teams in Table 2. For
each team, we keep only the better result except
the NEU team because they use different tech-
nologies in their two submissions (NEU_1 and
NEU_2).
From Table 2, we first observe that 7 submis-
sions perform better than the hybrid cheat system.
In contrast, in Artiles et al. (2009), only 3 teams
can beat the hybrid system. From our analysis,
this may attribute to the following facts.
1) Personal name disambiguation on Chinese
may be easier than the one on English. For
example, one of key issues in personal name
disambiguation is to capture the occurrences
of a query name in text. However, various
personal name expressions, such as the use of
</bodyText>
<table confidence="0.999944866666667">
Precision Recall Macro F
NEU_1 95.76 88.37 91.47
NEU_2 95.08 88.62 91.15
HITSZ_CITYU 83.99 93.29 87.42
ICL_1 83.68 92.23 86.94
DLUT_1 82.69 91.33 86.36
BUPT_1 80.33 94.52 85.79
XMU 90.55 84.88 85.72
Hybrid cheat system 73.48 100 82.37
HIT_ITNLP_2 91.08 62.75 71.03
BIT 80.2 68.75 68.4
ALL-IN-ONE 52.54 100 61.74
BUPT_pris02 72.39 58.35 57.68
SoochowHY_2 84.51 44.17 51.42
ONE-IN-ONE 94.42 14.41 21.07
</table>
<tableCaption confidence="0.998764">
Table 2: The B-Cubed performances of the formal test
</tableCaption>
<table confidence="0.9999611">
Precision Recall Macro F
NEU_1 95.6 89.74 92.14
NEU_2 94.53 89.99 91.66
XMU 89.84 89.84 89.08
ICL_1 84.53 93.42 87.96
BUPT_1 80.43 95.41 86.18
Word-segment system 71.11 100 80.92
BUPT_pris01 77.91 75.09 74.25
BIT 94.62 63.32 72.48
SoochowHY 87.22 58.52 61.85
</table>
<tableCaption confidence="0.99998">
Table 3: The B-Cubed performances of the diagnosis test
</tableCaption>
<bodyText confidence="0.9998295">
middle names in English, cause many prob-
lems during recognizing of the occurrences
of a personal name in interest.
2) We works on news articles, which have less
noisy information compared to webpages
used in Artiles et al. (2009). More efforts are
put on the exploration directly on disam-
biguation, not on text pre-processing. Fur-
thermore, most of systems extract features
based on some popular NLP techniques, such
as Chinese word segmentation, named entity
recognition and POS tagger. As those tools
usually are developed based on news corpora,
they should extract high-quality features for
disambiguation in our task.
We then notice that the NEU team achieves the
best performance. From their system description,
we find that they make some special processing
just for this task. For example, they develop a per-
sonal name recognition system to detect the occur-
rences of a query name in a news article, and a
cascaded clustering for different kinds of persons.
</bodyText>
<subsectionHeader confidence="0.999084">
5.2 Results of the Diagnosis test
</subsectionHeader>
<bodyText confidence="0.999823285714286">
We present the performances of 8 submissions for
the diagnosis test from 7 teams in Table 3 as the
format of Table 2. Meanwhile, we use the word-
segment system as the baseline.
Comparing Table 2 and 3, we first find that the
word-segment system has a lower performance
than the hybrid cheat system although the word-
segment system is more useful for real applica-
tions. This implies the importance to develop an
appropriate evaluation method for clustering.
From Table 3, five submissions achieve better
performances than the word-segment system.
Given the gold-standard word segmentation on
personal names in the diagnosis test, from Table 3,
our total impression is that the top systems take
less advantages, and the bottom systems take
more. This indicates that bottom systems suffer
from their low-quality word segmentation and
named entity detection. For example,
BUPT_pris01 increases ~22% F score (from
52.81% to 74.25%).
</bodyText>
<sectionHeader confidence="0.996308" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999903083333333">
This campaign follows the work of WePS, and
explores Chinese personal name disambiguation
on news. We examine two issues: one is for Chi-
nese word segmentation, and the other is noisy
information. As Chinese word segmentation usu-
ally is a pre-processing for most NLP processing,
we investigate the impact of word segmentation to
disambiguation. To avoid noisy information for
disambiguation, such as HTML tags in webpage
used in WePS, we choose news article to work on
so that we can capture how good the state-of-the-
art disambiguation technique is.
</bodyText>
<sectionHeader confidence="0.767973" genericHeader="acknowledgments">
References
</sectionHeader>
<note confidence="0.898688142857143">
Artiles, Javier, Julio Gonzalo and Satoshi Sekine.2007.
The SemEval-2007 WePS Evaluation: Establishing
a benchmark for the Web People Search Task. In
Proceedings of Semeval 2007, Association for Com-
putational Linguistics.
Artiles, Javier, Julio Gonzalo and Satoshi Sekine. 2009.
WePS 2 Evaluation Campaign: overview of the Web
</note>
<reference confidence="0.892325529411765">
People Search Clustering Task. In 2nd Web People
Search Evaluation Workshop (WePS 2009), 18th
WWW Conference.
Bagga, Amit and Breck Baldwin.1998. Entity-based
Cross-document Co-referencing Using the Vector
Space Model. In Proceedings of the 17th Interna-
tional Conference on Computational Linguistics.
Chen, Ying and James H. Martin. 2007. CU-COMSEM:
Exploring Rich Features for Unsupervised Web Per-
sonal Name Disambiguation. In Proceedings of Se-
meval 2007, Association for Computational
Linguistics.
Chen, Ying, Sophia Yat Mei Lee and Chu-Ren Huang.
2009. PolyUHK: A Robust Information Extraction
System for Web Personal Names. In 2nd Web Peo-
ple Search Evaluation Workshop (WePS 2009), 18th
WWW Conference.
</reference>
<sectionHeader confidence="0.888125" genericHeader="references">
Appendix
</sectionHeader>
<table confidence="0.999887485714286">
name document # cluster # document #
per cluster
155 37 4.19
301 42 7.17
300 5 60
105 30 3.5
156 42 3.71
350 15 23.33
269 70 3.84
257 8 32.13
211 109 1.94
177 36 4.92
358 165 2.17
300 20 15
140 57 2.46
300 27 11.11
296 73 4.05
135 75 1.8
297 14 21.21
110 24 4.58
207 68 3.04
131 26 5.04
145 22 6.59
164 15 10.93
247 20 12.35
173 34 5.09
171 21 8.14
170 34 5
195 32 6.09
301 22 13.68
318 76 4.18
234 117 2
134 9 14.89
123 7 17.57
6930 1352 5.13
</table>
<tableCaption confidence="0.999687">
Table 4: The training data distribution
</tableCaption>
<table confidence="0.996725846153846">
name document # cluster # document #
per cluster
190 96 1.99
191 5 38.2
258 16 16.13
224 32 7
118 29 4.07
239 21 11.38
208 43 4.84
201 17 11.82
317 3 105.67
151 6 25.17
188 61 3.08
200 2 100
213 69 3.09
182 5 36.4
278 11 25.27
180 4 45
286 1 286
206 38 5.42
193 16 12.06
172 9 19.11
174 5 34.8
299 39 7.67
233 90 2.59
300 13 23.08
141 25 5.64
262 13 20.15
5604 669 8.38
Table5: The test data distribution
Word segmentation Named Entity
NEU Name: Neucsp Name: in-house
Source: 1998 People&apos;s Daily
HITSZ_CITYU
ICL Name: LTP Name: LTP
F score: 96.5%
Source: 2nd SIGHAN
DLUT
BUPT Name: in-house
F score: 96.5%
Source: SIGHAN 2010
XMU Name: in-house
Source: 1998 People&apos;s Daily
F score: 97.8%
HIT_ITNLP Name: IRLAS Name: IRLAS
Source: 1998 People&apos;s Daily
F score: 97.4%
BIT Name: ICTCLAS2010 Name: ICTCLAS2010
Precision: ~97%
Source: 1998 People&apos;s Daily
BUPT_pris Name: LTP Name: LTP
SoochowHY None None
</table>
<tableCaption confidence="0.9757255">
Table 6: The summary of word segmentation and named entity detection used in the participants
* LTP(Language Technology Platform)
</tableCaption>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.412076">
<title confidence="0.9974015">The Chinese Persons Name Disambiguation Evaluation: Exploration of Personal Name Disambiguation in Chinese News</title>
<author confidence="0.981425">Peng Wenjie</author>
<affiliation confidence="0.999905">Agricultural University Teachers’ College Hong Kong Polytechnic University</affiliation>
<email confidence="0.763455">chenying3176@gmail.comjandp@pku.edu.cncswjli@comp.polyu.edu.hkchurenhuang@gmail.com</email>
<abstract confidence="0.982474916666667">Personal name disambiguation becomes hot as it provides a way to incorporate semantic understanding into information retrieval. In this campaign, we explore Chinese personal name disambiguation in news. In order to examine how well disambiguation technologies work, we concentrate on news articles, which is well-formatted and whose genre is well-studied. We then design a diagnosis test to explore the impact of Chinese word segmentation to personal name disambiguation.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>People Search</author>
</authors>
<title>Clustering Task.</title>
<booktitle>In 2nd Web People Search Evaluation Workshop (WePS 2009), 18th WWW Conference.</booktitle>
<marker>Search, </marker>
<rawString>People Search Clustering Task. In 2nd Web People Search Evaluation Workshop (WePS 2009), 18th WWW Conference.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Amit Bagga</author>
<author>Breck Baldwin 1998</author>
</authors>
<title>Entity-based Cross-document Co-referencing Using the Vector Space Model.</title>
<booktitle>In Proceedings of the 17th International Conference on Computational Linguistics.</booktitle>
<marker>Bagga, 1998, </marker>
<rawString>Bagga, Amit and Breck Baldwin.1998. Entity-based Cross-document Co-referencing Using the Vector Space Model. In Proceedings of the 17th International Conference on Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ying Chen</author>
<author>James H Martin</author>
</authors>
<title>CU-COMSEM: Exploring Rich Features for Unsupervised Web Personal Name Disambiguation.</title>
<date>2007</date>
<booktitle>In Proceedings of Semeval 2007, Association for Computational Linguistics.</booktitle>
<marker>Chen, Martin, 2007</marker>
<rawString>Chen, Ying and James H. Martin. 2007. CU-COMSEM: Exploring Rich Features for Unsupervised Web Personal Name Disambiguation. In Proceedings of Semeval 2007, Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ying Chen</author>
<author>Sophia Yat Mei Lee</author>
<author>Chu-Ren Huang</author>
</authors>
<title>PolyUHK: A Robust Information Extraction System for Web Personal Names.</title>
<date>2009</date>
<booktitle>In 2nd Web People Search Evaluation Workshop (WePS 2009), 18th WWW Conference.</booktitle>
<marker>Chen, Lee, Huang, 2009</marker>
<rawString>Chen, Ying, Sophia Yat Mei Lee and Chu-Ren Huang. 2009. PolyUHK: A Robust Information Extraction System for Web Personal Names. In 2nd Web People Search Evaluation Workshop (WePS 2009), 18th WWW Conference.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>