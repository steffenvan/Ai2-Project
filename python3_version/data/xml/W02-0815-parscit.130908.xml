<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003968">
<note confidence="0.996813">
Proceedings of the SIGLEX/SENSEVAL Workshop on Word Sense
Disambiguation: Recent Successes and Future Directions, Philadelphia,
July 2002, pp. 102-108. Association for Computational Linguistics.
</note>
<bodyText confidence="0.998450833333333">
a task-based evaluation are specific to the lan-
guage pair: the number of senses of a word cor-
responds to the number of translations into the
target language. Thus such a task-based evalu-
ation method avoids the problems from point 1.
In this paper, we investigate evaluating WSD
using a task-based method in the context of SCF
acquisition. SCF acquisition is potentially a
well suited task for WSD as subcategorization is
known to be sensitive to sense variation (Roland
et al., 2000; Roland and Jurafsky, 2001).
We take an existing subcategorization acqui-
sition system (Korhonen, 2002) and carry out
a small scale experiment (initially discussed in
(Preiss et al., 2002)) to investigate whether it
is possible to improve the performance of this
system using WSD. Our preliminary results on
sense annotated data derived from the SemCor
corpus are encouraging, showing that WSD can
indeed improve the accuracy of subcategoriza-
tion acquisition. We therefore conclude that
SCF acquisition can potentially be used as a
task-based evaluation method for WSD.
In Section 2 we describe the baseline subcat-
egorization acquisition system, discuss the need
for WSD and report the modifications made to
the system to enable it to use WSD. We de-
scribe our experiment with the modified system
in Section 3, draw our conclusions in Section 4
and discuss future work in Section 5.
</bodyText>
<sectionHeader confidence="0.955314" genericHeader="abstract">
2 Subcategorization Acquisition
</sectionHeader>
<subsectionHeader confidence="0.897501">
2.1 Baseline System
</subsectionHeader>
<bodyText confidence="0.997529272727273">
Building on the SCF acquisition framework
of Briscoe and Carroll (1997), Korhonen (2002)
has proposed a system which uses knowledge of
verb semantics to guide the process of subcate-
gorization acquisition.2
The approach adopted for SCF acquisition is
motivated by research which has demonstrated
that semantically similar verbs are similar also
in terms of subcategorization (Levin, 1993). Not
only verb senses but also verb forms correlate
well in terms of SCF distributions, provided that
</bodyText>
<footnote confidence="0.938211666666667">
2This system currently only treats verbs but plans are
under way to extend it to other parts of speech (nouns
and adjectives).
</footnote>
<bodyText confidence="0.999545523809524">
they are classified semantically according to a
verbs&apos; predominant sense (Korhonen, 2002). For
example, as the predominant senses of fly and
move are similar (they both belong to the Levin
&amp;quot;Motion verbs&amp;quot;), their SCF distributions corre-
late quite closely. Good correlation is observed
because the majority of SCF occurrences tend
to be of the predominant sense (Preiss et al.,
2002).
The system of Korhonen (2002) resembles
other subcategorization systems (e.g. (Carroll
and Rooth, 1998; Sarkar and Zeman, 2000)) in
that it acquires SCFs specific to verb form rather
than sense. Back-off (i.e. probability) estimates
based on the predominant sense are, however,
used to guide the acquisition process.
The system works by first identifying the
sense, i.e. the semantic class for a predi-
cate. The semantic classes are based on Levin
classes (Levin, 1993); mostly on broad classes
(e.g. 51. &amp;quot;Motion verbs&amp;quot;) rather than subclasses
(e.g. 51.2 &amp;quot;Leave verbs&amp;quot;) as the former are usu-
ally found distinctive enough in terms of sub-
categorization.3 Verbs are classified according
to their predominant sense in WordNet. This
is done using a mapping which links WordNet
synsets with Levin classes.4
After semantic class assignment, the
subcategorization acquisition machinery of
Briscoe and Carroll (1997) is used to acquire
a putative SCF distribution from corpus data.
The system tags, lemmatizes and parses corpus
data using a robust statistical parser which
employs a grammar written in a feature-based
unification grammar formalism. This yields
complete though shallow parses.
Local syntactic frames are extracted from
parses, from sentence subanalyses which be-
gin/end at the boundaries of predicates. A com-
prehensive SCF classifier is then applied, which
assigns the resulting patterns to SCFs or rejects
them as unclassifiable (on the basis of the fea-
</bodyText>
<footnote confidence="0.996715">
3This is examined beforehand by investigating (i) the
syntactic similarity of Levin (sub)classes and (ii) the sub-
categorization similarity between individual verbs from
these classes.
4See the work of Korhonen (2002) for details of the
mapping.
</footnote>
<bodyText confidence="0.999713705882353">
ture values of syntactic categories and head lem-
mas, which are included in each pattern). The
classifier chooses from 163 verbal SCFs, a super-
set of those found in the ANLT (Boguraev and
Briscoe, 1987) and COMLEX Syntax dictionar-
ies (Grishman et al., 1994).
Finally, sets of SCFs are gathered for verbs
and putative lexical entries are constructed. A
putative lexical entry includes various informa-
tion, e.g. the relative frequency of the SCF given
the verb.
The SCF distribution is smoothed using the
probability (i.e. &amp;quot;back-off&amp;quot;) estimates of the se-
mantic class of the verb. Smoothing is done
using linear interpolation (e.g. (Manning and
Schiitze, 1999)). The back-off estimates are ob-
tained using the following method:
</bodyText>
<listItem confidence="0.8856605">
(i) 4-5 individual verbs are chosen from a verb
class.
(ii) SCF distributions are built for these verbs
by manually analysing c. 300 occurrences
of each verb in the British National Corpus
(BNC) (Leech, 1992).
(iii) The resulting SCF distributions are
merged.
</listItem>
<bodyText confidence="0.999736210526316">
The SCF distribution for the verb for which
subcategorization is being acquired is always ex-
cluded from the back-off estimates. The back-off
estimates for the &amp;quot;Motion verb&amp;quot; fly, for exam-
ple, are constructed by merging the SCF distri-
butions for 5 other &amp;quot;Motion verbs&amp;quot; e.g. move,
slide, arrive, travel, and sail.
As a final step, a simple empirically deter-
mined threshold is used on the probability esti-
mates after smoothing to filter out noisy SCFs.
The back-off estimates based on the predom-
inant sense of the verb help to correct the ac-
quired SCF distribution and deal with sparse
data. Where the predominant sense is assigned
correctly, Korhonen (2002) reports significant
improvement in SCF acquisition. On a test set
of 45 verbs from 18 semantic classes, the pro-
posed method yields 78 F-measure,5 while the
F-measure is only 61 when no sense is assumed
</bodyText>
<subsubsectionHeader confidence="0.284755">
5See Section 3.3.1 for calculation of F-measure.
</subsubsectionHeader>
<bodyText confidence="0.9996955">
(i.e. when no back-off estimates are employed
and no smoothing is done).
</bodyText>
<subsectionHeader confidence="0.988759">
2.2 The Need for WSD
</subsectionHeader>
<bodyText confidence="0.99463675">
Preiss et al. (2002) examined the effect of the
current predominant sense heuristics on the
baseline system performance. The following ob-
servations were made:
</bodyText>
<listItem confidence="0.879686357142857">
1. Significant improvement is reported with
SCF acquisition by assuming the predom-
inant sense only. This indicates that all
senses are not equally important.
2. Good results are obtained by assuming a
fairly wide notion of sense based on a broad
Levin class. This indicates that WordNet
style fine-grained sense distinctions are not
necessary for the task.6
3. When the predominant sense assignment is
done correctly, the system performs better
with some verbs than with others. This im-
plies that we may obtain an increase in ac-
curacy if we consider more senses.
</listItem>
<bodyText confidence="0.987856521739131">
Preiss et al. (2002) investigated to what ex-
tent WSD would improve the system perfor-
mance. They showed that those high frequency
polysemous verbs whose predominant sense is
not very frequent would benefit from WSD. The
distribution of senses is not as zipfian for these
verbs as it is for other verbs. That is, the pre-
dominant sense does not cover enough of the
total frequency mass for back-off estimates to
yield maximum benefit.
WSD was not proposed for all senses of high
frequency polysemous verbs. The number of
senses considered for WSD, Preiss et al. (2002)
suggested, would depend on the frequency mass
covered by the senses. They suggested consider-
ing 75% of the total frequency mass. For exam-
ple, for the verb continue, to cover 75% of fre-
quency mass, it is only necessary to consider the
first two out of a total of nine WordNet senses.
6Note that this is beneficial: the method would suffer
from sparse data problems if a narrow WordNet style no-
tion of sense was assumed. It would be difficult to obtain
back-off estimates for senses with very low in frequency.
</bodyText>
<subsectionHeader confidence="0.999054">
2.3 Modifications
</subsectionHeader>
<bodyText confidence="0.995726322580645">
We modified the baseline system outlined in Sec-
tion 2.1 so that it can benefit from WSD. Firstly,
the mapping which links predominant WordNet
senses (synsets) with Levin classes was extended
so that it covers all verb senses corresponding to
75% frequency mass.7 This makes it possible to
classify verbs to more than one semantic class
(i.e. we are no longer restricted to the semantic
class corresponding to the verb&apos;s predominant
sense).
A number of different datasets were created,
corresponding to the senses being disambiguated
(initial senses) and the remaining senses (which
were grouped together). The system was mod-
ified so that SCFs are acquired separately for
each of these datasets. For each dataset corre-
sponding to the initial senses, the back-off esti-
mates of the relevant sense are used for smooth-
ing. No smoothing is done in the case of the
dataset of grouped senses.
Finally, the SCF lexicons acquired for differ-
ent datasets are merged8 to yield a SCF distri-
bution specific to a verb form rather than sense.
This is done merely for evaluation purposes:
(i) it allows to compare the SCF distribution
acquired using the baseline system to the
one acquired using the modified system,
and currently,
(ii) we do not (yet) have gold standard SCF dis-
tributions which could be used in evaluation
of verb sense specific subcategorization.
</bodyText>
<sectionHeader confidence="0.9988" genericHeader="keywords">
3 Experiment
</sectionHeader>
<bodyText confidence="0.9997975">
An experiment was conducted to investigate
the performance of the subcategorization acqui-
sition system modified for WSD. Section 3.1
describes the method adopted for WSD, Sec-
tion 3.2 introduces our test data and the details
of the evaluation are given in Section 3.3.
</bodyText>
<footnote confidence="0.7676065">
7This was done only for the verbs used in our prelim-
inary experiments.
8When merging SCF lexicons, each lexicon receives
a weight corresponding to its size. For example, if two
lexicons of an equal size are merged, they both receive
an equal weight.
</footnote>
<table confidence="0.9918524">
Corpus No of words Verbs
brownl 198796 26686
brown2 160936 21804
browny 316814 41525
Total 676546 90015
</table>
<tableCaption confidence="0.999512">
Table 1: Size of SemCor
</tableCaption>
<subsectionHeader confidence="0.993844">
3.1 Method for WSD
</subsectionHeader>
<bodyText confidence="0.999933380952381">
To show that subcategorization acquisition can
benefit from WSD, we would need a reliable
WSD system. This is however difficult to ob-
tain. In the SENSEVAL-2 English all-words
task,9 only two systems performed better than
always choosing the most frequent sense. Both
of these systems only outperformed this baseline
by a few percent (achieving a final precision in
the high eighties).
As our aim is to investigate the benefit of
WSD for our task, we believe that it is impor-
tant to carry out preliminary investigations with
very accurate WSD annotations. Only if the ac-
quired frames improve in this case, is it possi-
ble to consider SCF acquisition as a method for
evaluating WSD. We therefore used SemCor to
obtain an accurately sense tagged corpus. This
is a balanced collection of texts (derived from
the Brown corpus), released as part of WordNet,
which has almost all words hand annotated with
WordNet senses.
</bodyText>
<subsectionHeader confidence="0.999957">
3.2 Test Data
</subsectionHeader>
<bodyText confidence="0.999946875">
The size of the concordance, shown in Table 1,
along with the lack of a full mapping between
WordNet and Levin, proved to be the biggest
problems introducing many sparse data difficul-
ties19. It restricted our investigation to a small
scale as we only found 10 verbs with sufficiently
many occurrences in anything other than the
predominant sense.
</bodyText>
<footnote confidence="0.9794525">
91n this task, participants were presented with three
pieces of continuous text and were asked to sense tag
every occurrence of noun, verb, adjective and adverb in
them.
19Dorr (1997) provides a full mapping between Word-
net and Levin, but we cannot utilize this mapping: it is
not accurate enough for our purposes and does not cover
predominant senses of all verbs.
</footnote>
<table confidence="0.999174333333333">
Verb Senses
1st Other
add 114 81
carry 69 74
drop 35 60
fill 57 28
give 414 271
meet 75 151
throw 59 13
</table>
<tableCaption confidence="0.971204">
Table 2: Chosen verbs with two sense distinc-
tions
</tableCaption>
<table confidence="0.9991632">
Senses
Verb 1st 2nd Other
keep 215 36 68
hit 41 20 19
move 124 52 65
</table>
<tableCaption confidence="0.905847">
Table 3: Chosen verbs with three sense distinc-
tions
</tableCaption>
<bodyText confidence="0.999888555555556">
The ten chosen verbs are shown in Tables 2
and 3. There were three verbs for which enough
data was present to distinguish the first and
second (Levin) sense, all remaining senses were
lumped together in the &amp;quot;other&amp;quot; category (see Ta-
ble 3 for the number of occurrences of each of
these). For the remaining seven verbs, we could
only distinguish the first sense and any other
sense (see Table 2).
</bodyText>
<subsectionHeader confidence="0.9962705">
3.3 Evaluation
3.3.1 Method
</subsectionHeader>
<bodyText confidence="0.998733041666667">
We took the SemCor data and processed the
sentences containing the test verbs using the
modified subcategorization system outlined in
Section 2.3. For the verbs in Table 2, subcat-
egorization was thus acquired separately for (i)
the first sense (the data was smoothed using the
relevant back-off estimates) and for (ii) the re-
maining senses (no smoothing was done), after
which the two distributions were combined. For
the verbs in Table 3, subcategorization was ac-
quired separately for the two senses (two sets of
back-off estimates were used, one for each sense)
and no smoothing was done for the remaining
senses, after which the three distributions were
merged.
The results were evaluated against a manual
analysis of the corpus data. This was obtained
by analysing a maximum of 300 occurrences for
each test verb in the BNC corpus.&amp;quot;
We calculated type precision (the percentage
of SCF types that the system proposes which
are correct), type recall (the percentage of SCF
types in the gold standard that the system pro-
poses) and F-measure:
</bodyText>
<equation confidence="0.669682">
F2 . precision • recall
</equation>
<bodyText confidence="0.987807444444444">
=
precision + recall
We also calculated the Kullback-Leibler dis-
tance (KL) and the Spearman rank correlation
(RC) between the acquired unfiltered12 SCF dis-
tributions and the gold standard distributions.
KL measures the dissimilarity of two SCF dis-
tributions (the acquired and the gold standard
distributions) and RC compares the ranking of
SCFs within the distributions.13
Finally, we recorded the number of SCFs miss-
ing in the distributions, i.e. the type of false neg-
atives which did not even occur in the unfiltered
distributions. This was to investigate how well a
method deals with sparse data, i.e. how accurate
the back-off estimates are.14
For comparison, we also reported results for
the baseline system described in Section 2.1.
</bodyText>
<sectionHeader confidence="0.79653" genericHeader="introduction">
3.3.2 Results
</sectionHeader>
<bodyText confidence="0.9675055">
The results for the modified system are shown
in Table 4 and those for the baseline system in
Table 5. The tables first list the results for the
individual verbs and then the average results for
the 7 and 3 verbs, respectively.
When WSD is used to simply separate the
first sense from any other sense (for the 7 verbs)
we observe an increase in the F-measure from
&amp;quot;We acknowledge that the gold standard is not fully
ideal for SemCor data, however, we believe that is rea-
sonable, given that both SemCor and BNC are balanced
corpora.
</bodyText>
<footnote confidence="0.99197275">
12No threshold was applied to remove the noisy SCFs
from the distributions.
13Note that KL &gt; 0, with KL near to 0 denoting strong
association, and —1 &lt; RC &lt;1, with RC near to 0 denot-
ing a low degree of association and RC near to -1 and 1
denoting strong association.
14See (Korhonen, 2002) for details of all the evaluation
methods discussed in this section.
</footnote>
<table confidence="0.9757365">
(1)
Verb KL RC System results Unseen
SCFs
Precision (%) Recall (%) F
add 0.20 0.76 100.0 66.7 80.0 1
carry 0.26 0.77 69.2 90.0 78.2 1
drop 0.29 0.73 88.9 66.7 76.2 1
fi// 0.07 0.77 100.0 75.0 85.7 0
give 0.57 0.76 71.4 46.5 56.3 3
meet 0.30 0.89 71.4 62.5 66.7 2
throw 0.48 0.66 100.0 88.9 94.1 0
AVERAGE 0.31 0.76 85.8 70.9 77.6 1.1
keep 0.33 0.46 87.5 43.8 58.4 1
hit 0.66 0.76 86.5 75.0 80.3 0
move 0.15 0.67 100.0 89.0 94.2 0
AVERAGE 0.38 0.63 91.3 69.3 78.8 0.3
</table>
<tableCaption confidence="0.997321">
Table 4: Results with WSD
</tableCaption>
<table confidence="0.999982666666667">
Verb KL RC System results Unseen
SCFs
Precision (%) Recall (%) F
add 0.55 0.73 100.0 55.6 71.5 1
carry 0.34 0.81 81.8 90.0 85.7 1
drop 0.30 0.63 88.9 66.7 76.2 1
fi// 0.12 0.75 100.0 61.5 76.2 0
give 0.62 0.72 66.7 44.4 53.3 3
meet 0.37 0.84 66.7 50.0 57.2 2
throw 0.50 0.69 100.0 88.9 94.1 0
AVERAGE 0.40 0.74 86.3 65.3 74.3 1.1
keep 0.48 0.63 77.8 43.8 56.0 5
hit 0.61 0.61 85.7 75.0 80.0 0
move 0.19 0.60 100.0 77.8 87.5 1
AVERAGE 0.43 0.61 87.8 65.5 75.0 2.0
</table>
<tableCaption confidence="0.999934">
Table 5: Results with baseline system
</tableCaption>
<bodyText confidence="0.999723346153846">
74.3 to 77.6. In the case of those 3 verbs where
we distinguished three sense groups we report an
increase in the F-measure from 75.0 to 78.8. For
these verbs using two sets of back-off estimates
instead of only one makes a clear difference: the
average number of false negative SCFs missing
altogether in data decreases from 2.0 to 0.3.
The benefit of WSD shows as well on KL and
RC, although not as clearly: KL improves 0.09
for 7 verbs and 0.05 for 3 verbs, while RC im-
proves 0.02 for both 7 and 3 verbs. The im-
provements are smaller here because KL and
RC are more sensitive measures. They both
consider unfiltered SCF distributions and (un-
like type precision and type recall) evaluate the
actual frequencies/ranks of SCFs.
Although back-off estimates generally help to
correct the frequencies/ranks, the improvement
obtained is higher the more accurate the original
unsmoothed distribution is. In our experiments,
the system often could not acquire an accurate
SCF distribution because an insufficient num-
ber of corpus occurrences were available. Thus
we require adequate data for all the senses con-
sidered to investigate the full potential of the
modified system.
</bodyText>
<sectionHeader confidence="0.998843" genericHeader="method">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.9999274">
The main contribution of this paper was to show
that WSD can improve the accuracy of SCF ac-
quisition. This indicates that SCF acquisition
may be used as task-based evaluation for WSD
systems.
In our experiments, subcategorization acquisi-
tion performed better when the first sense occur-
rences were simply separated from all the other
occurrences (as opposed to assuming the first
sense for all the occurrences). Disambiguating
two senses (for those verbs which require it) has
the additional advantage that two sets of back-
off estimates can be employed, in which case
smoothing yields a more comprehensive SCF
distribution.
</bodyText>
<sectionHeader confidence="0.99918" genericHeader="method">
5 Future Work
</sectionHeader>
<bodyText confidence="0.9999115">
We have carried out a very small scale experi-
ment. As a next step, we would like to carry out
an experiment on a bigger scale. However, for
this to be possible, we would need to employ an
accurate WSD system. As we propose to always
restrict the evaluation to particular (high fre-
quency polysemous) words, a supervised WSD
system suggests itself as we can collect train-
ing data specific to these words. With sufficient
training data, a supervised system should per-
form better than the most frequent sense base-
line.
</bodyText>
<sectionHeader confidence="0.998065" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999744548387097">
S. Atkins. 1992. Tools for corpus-aided lexicography:
the HECTOR project. Acta Linguistica Hungar-
ica, 41:5-72.
B. K. Boguraev and E. J. Briscoe. 1987. Large
lexicons for natural language processing utilising
the grammar coding system of the Longman Dic-
tionary of Contemporary English. Computational
Linguistics, 13(4):219-240.
E. Briscoe and J. Carroll. 1997. Automatic extrac-
tion of subcategorization from corpora. In Pro-
ceedings of ACL ANLP97, pages 356-363.
G. Carroll and M. Rooth. 1998. Valence induction
with a head-lexicalized PCFG. In 3rd Conference
on Empirical Methods in Natural Language Proce
ssing.
B. Dorr. 1997. Large-scale dictionary construc-
tion for foreign language tutoring and interlin-
gual machine translation. Machine Translation,
12(4):271-325.
R. Grishman, C. Macleod, and A. Meyers. 1994.
Comlex syntax: building a computational lexi-
con. In International Conference on Computa-
tional Linguistics, COLING-94, pages 268-272.
A. Kilgarriff. 1998. SENSEVAL: An exercise in eval-
uating word sense disambiguation programs. In
Proceedings of LREC, pages 581-588.
A. Korhonen. 2002. Subcategorization Acquisition.
Ph.D. thesis, University of Cambridge.
S. Kurohashi. 2002. SENSEVAL-2 Japanese trans-
lation task. In Proceedings of SENSEVAL-2: Sec-
ond International Workshop on Evaluating Word
Sense Disambiguating Systems.
G. Leech. 1992. 100 million words of English:
the British National Corpus. Language Research,
28(1):1-13.
B. Levin. 1993. English Verb Classes and Alterna-
tions. Chicago University Press.
C. D. Manning and H. Schaze. 1999. Foundations
of Statistical Natural Language Processing. MIT
Press.
G. Miller, R. Beckwith, C. Felbaum, D. Gross, and
K. Miller. 1990. Introduction to WordNet: An
on-line lexical database. Journal of Lexicography,
3(4):235-244.
J. Preiss, A. Korhonen, and T. Briscoe. 2002. Sub-
categorization acquisition as an evaluation method
for WSD. In Proceedings of LREC.
D. Roland and D. Jurafsky. 2001. Verb sense and
verb subcategorization probabilities. In S. Steven-
son and P. Merlo, editors, The Lexical Basis of
Sentence Processing: Formal, Computational, and
Experimental Issue. Cambridge University Press,
Jon Benjamins, Amsterdam. To appear.
D. Roland, D. Jurafsky, L. Menn, S. Gahl, E. Elder,
and C. Riddoch. 2000. Verb subcatecorization
frequency differences between business-news and
balanced corpora. In ACL Workshop on Compar-
ing Corpora, pages 28-34.
A. Sarkar and D. Zeman. 2000. Automatic extrac-
tion of subcategorization frames for Czech. In 19th
International Conference on Computational Lin-
guistics, pages 691-697.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.016504">
<note confidence="0.894278">Proceedings of the SIGLEX/SENSEVAL Workshop on Word Sense Disambiguation: Recent Successes and Future Directions, Philadelphia,</note>
<abstract confidence="0.986139582089553">July 2002, pp. 102-108. Association for Computational Linguistics. a task-based evaluation are specific to the language pair: the number of senses of a word corresponds to the number of translations into the target language. Thus such a task-based evaluation method avoids the problems from point 1. In this paper, we investigate evaluating WSD using a task-based method in the context of SCF acquisition. SCF acquisition is potentially a well suited task for WSD as subcategorization is known to be sensitive to sense variation (Roland et al., 2000; Roland and Jurafsky, 2001). We take an existing subcategorization acquisition system (Korhonen, 2002) and carry out a small scale experiment (initially discussed in (Preiss et al., 2002)) to investigate whether it is possible to improve the performance of this system using WSD. Our preliminary results on sense annotated data derived from the SemCor corpus are encouraging, showing that WSD can indeed improve the accuracy of subcategorization acquisition. We therefore conclude that SCF acquisition can potentially be used as a task-based evaluation method for WSD. In Section 2 we describe the baseline subcategorization acquisition system, discuss the need for WSD and report the modifications made to the system to enable it to use WSD. We describe our experiment with the modified system in Section 3, draw our conclusions in Section 4 and discuss future work in Section 5. 2 Subcategorization Acquisition 2.1 Baseline System Building on the SCF acquisition framework of Briscoe and Carroll (1997), Korhonen (2002) has proposed a system which uses knowledge of verb semantics to guide the process of subcate- The approach adopted for SCF acquisition is motivated by research which has demonstrated that semantically similar verbs are similar also in terms of subcategorization (Levin, 1993). Not verb also verb well in terms of SCF distributions, provided that system currently only treats verbs but plans are under way to extend it to other parts of speech (nouns and adjectives). they are classified semantically according to a verbs&apos; predominant sense (Korhonen, 2002). For as the predominant senses of similar (they both belong to the Levin &amp;quot;Motion verbs&amp;quot;), their SCF distributions correlate quite closely. Good correlation is observed because the majority of SCF occurrences tend to be of the predominant sense (Preiss et al., 2002). The system of Korhonen (2002) resembles other subcategorization systems (e.g. (Carroll and Rooth, 1998; Sarkar and Zeman, 2000)) in that it acquires SCFs specific to verb form rather than sense. Back-off (i.e. probability) estimates based on the predominant sense are, however, used to guide the acquisition process. The system works by first identifying the sense, i.e. the semantic class for a predicate. The semantic classes are based on Levin classes (Levin, 1993); mostly on broad classes (e.g. 51. &amp;quot;Motion verbs&amp;quot;) rather than subclasses 51.2 as the former are usually found distinctive enough in terms of sub- Verbs are classified according to their predominant sense in WordNet. This is done using a mapping which links WordNet with Levin After semantic class assignment, the subcategorization acquisition machinery of Briscoe and Carroll (1997) is used to acquire a putative SCF distribution from corpus data. The system tags, lemmatizes and parses corpus data using a robust statistical parser which employs a grammar written in a feature-based unification grammar formalism. This yields complete though shallow parses. Local syntactic frames are extracted from parses, from sentence subanalyses which begin/end at the boundaries of predicates. A comprehensive SCF classifier is then applied, which assigns the resulting patterns to SCFs or rejects as unclassifiable (on the basis of the feais examined beforehand by investigating (i) the syntactic similarity of Levin (sub)classes and (ii) the subcategorization similarity between individual verbs from these classes. the work of Korhonen (2002) for details of the mapping. ture values of syntactic categories and head lemmas, which are included in each pattern). The classifier chooses from 163 verbal SCFs, a superset of those found in the ANLT (Boguraev and Briscoe, 1987) and COMLEX Syntax dictionaries (Grishman et al., 1994). Finally, sets of SCFs are gathered for verbs and putative lexical entries are constructed. A putative lexical entry includes various information, e.g. the relative frequency of the SCF given the verb. The SCF distribution is smoothed using the probability (i.e. &amp;quot;back-off&amp;quot;) estimates of the semantic class of the verb. Smoothing is done using linear interpolation (e.g. (Manning and Schiitze, 1999)). The back-off estimates are obtained using the following method: (i) 4-5 individual verbs are chosen from a verb class. (ii) SCF distributions are built for these verbs by manually analysing c. 300 occurrences of each verb in the British National Corpus (BNC) (Leech, 1992). (iii) The resulting SCF distributions are merged. The SCF distribution for the verb for which subcategorization is being acquired is always excluded from the back-off estimates. The back-off estimates for the &amp;quot;Motion verb&amp;quot; fly, for example, are constructed by merging the SCF distrifor 5 other &amp;quot;Motion verbs&amp;quot; e.g. arrive, travel, As a final step, a simple empirically determined threshold is used on the probability estimates after smoothing to filter out noisy SCFs. The back-off estimates based on the predominant sense of the verb help to correct the acquired SCF distribution and deal with sparse data. Where the predominant sense is assigned correctly, Korhonen (2002) reports significant improvement in SCF acquisition. On a test set of 45 verbs from 18 semantic classes, the promethod yields 78 while the F-measure is only 61 when no sense is assumed Section 3.3.1 for calculation of F-measure. (i.e. when no back-off estimates are employed and no smoothing is done). 2.2 The Need for WSD Preiss et al. (2002) examined the effect of the current predominant sense heuristics on the baseline system performance. The following observations were made: 1. Significant improvement is reported with SCF acquisition by assuming the predominant sense only. This indicates that all senses are not equally important. 2. Good results are obtained by assuming a fairly wide notion of sense based on a broad Levin class. This indicates that WordNet style fine-grained sense distinctions are not for the 3. When the predominant sense assignment is done correctly, the system performs better with some verbs than with others. This implies that we may obtain an increase in accuracy if we consider more senses. Preiss et al. (2002) investigated to what extent WSD would improve the system performance. They showed that those high frequency polysemous verbs whose predominant sense is not very frequent would benefit from WSD. The distribution of senses is not as zipfian for these verbs as it is for other verbs. That is, the predominant sense does not cover enough of the total frequency mass for back-off estimates to yield maximum benefit. WSD was not proposed for all senses of high frequency polysemous verbs. The number of senses considered for WSD, Preiss et al. (2002) suggested, would depend on the frequency mass covered by the senses. They suggested considering 75% of the total frequency mass. For examfor the verb cover 75% of frequency mass, it is only necessary to consider the first two out of a total of nine WordNet senses. that this is beneficial: the method would suffer from sparse data problems if a narrow WordNet style notion of sense was assumed. It would be difficult to obtain back-off estimates for senses with very low in frequency. 2.3 Modifications We modified the baseline system outlined in Section 2.1 so that it can benefit from WSD. Firstly, the mapping which links predominant WordNet senses (synsets) with Levin classes was extended so that it covers all verb senses corresponding to frequency This makes it possible to classify verbs to more than one semantic class (i.e. we are no longer restricted to the semantic class corresponding to the verb&apos;s predominant sense). A number of different datasets were created, corresponding to the senses being disambiguated (initial senses) and the remaining senses (which were grouped together). The system was modified so that SCFs are acquired separately for each of these datasets. For each dataset corresponding to the initial senses, the back-off estimates of the relevant sense are used for smoothing. No smoothing is done in the case of the dataset of grouped senses. Finally, the SCF lexicons acquired for differdatasets are to yield a SCF distribution specific to a verb form rather than sense. This is done merely for evaluation purposes: (i) it allows to compare the SCF distribution acquired using the baseline system to the one acquired using the modified system, and currently, (ii) we do not (yet) have gold standard SCF distributions which could be used in evaluation of verb sense specific subcategorization. 3 Experiment An experiment was conducted to investigate the performance of the subcategorization acquisition system modified for WSD. Section 3.1 describes the method adopted for WSD, Section 3.2 introduces our test data and the details of the evaluation are given in Section 3.3. was done only for the verbs used in our preliminary experiments. merging SCF lexicons, each lexicon receives a weight corresponding to its size. For example, if two lexicons of an equal size are merged, they both receive an equal weight. Corpus No of words Verbs brownl 198796 26686 brown2 160936 21804 browny 316814 41525 Total 676546 90015 Table 1: Size of SemCor 3.1 Method for WSD To show that subcategorization acquisition can benefit from WSD, we would need a reliable WSD system. This is however difficult to ob- In the all-words only two systems performed better than always choosing the most frequent sense. Both of these systems only outperformed this baseline by a few percent (achieving a final precision in the high eighties). As our aim is to investigate the benefit of WSD for our task, we believe that it is important to carry out preliminary investigations with very accurate WSD annotations. Only if the acquired frames improve in this case, is it possible to consider SCF acquisition as a method for evaluating WSD. We therefore used SemCor to obtain an accurately sense tagged corpus. This is a balanced collection of texts (derived from the Brown corpus), released as part of WordNet, which has almost all words hand annotated with WordNet senses. 3.2 Test Data The size of the concordance, shown in Table 1, with the lack of a between WordNet and Levin, proved to be the biggest problems introducing many sparse data difficul- It restricted our investigation to a small scale as we only found 10 verbs with sufficiently many occurrences in anything other than the predominant sense. this task, participants were presented with three pieces of continuous text and were asked to sense tag every occurrence of noun, verb, adjective and adverb in them. a full mapping between Wordnet and Levin, but we cannot utilize this mapping: it is not accurate enough for our purposes and does not cover predominant senses of all verbs. Verb Senses 1st Other add 114 81 carry 69 74 drop 35 60 fill 57 28 give 414 271 meet 75 151 throw 59 13 Table 2: Chosen verbs with two sense distinctions Senses Verb 1st 2nd Other keep 215 36 68 hit 41 20 19 move 124 52 65 Table 3: Chosen verbs with three sense distinctions The ten chosen verbs are shown in Tables 2 and 3. There were three verbs for which enough data was present to distinguish the first and second (Levin) sense, all remaining senses were lumped together in the &amp;quot;other&amp;quot; category (see Table 3 for the number of occurrences of each of these). For the remaining seven verbs, we could only distinguish the first sense and any other sense (see Table 2). 3.3 Evaluation 3.3.1 Method We took the SemCor data and processed the sentences containing the test verbs using the modified subcategorization system outlined in Section 2.3. For the verbs in Table 2, subcategorization was thus acquired separately for (i) the first sense (the data was smoothed using the relevant back-off estimates) and for (ii) the remaining senses (no smoothing was done), after which the two distributions were combined. For the verbs in Table 3, subcategorization was acquired separately for the two senses (two sets of back-off estimates were used, one for each sense) and no smoothing was done for the remaining senses, after which the three distributions were merged. The results were evaluated against a manual analysis of the corpus data. This was obtained by analysing a maximum of 300 occurrences for each test verb in the BNC corpus.&amp;quot; We calculated type precision (the percentage of SCF types that the system proposes which are correct), type recall (the percentage of SCF types in the gold standard that the system proposes) and F-measure: . • recall = precision + recall We also calculated the Kullback-Leibler distance (KL) and the Spearman rank correlation between the acquired SCF distributions and the gold standard distributions. KL measures the dissimilarity of two SCF distributions (the acquired and the gold standard distributions) and RC compares the ranking of within the Finally, we recorded the number of SCFs missing in the distributions, i.e. the type of false negatives which did not even occur in the unfiltered distributions. This was to investigate how well a method deals with sparse data, i.e. how accurate back-off estimates For comparison, we also reported results for the baseline system described in Section 2.1. 3.3.2 Results The results for the modified system are shown in Table 4 and those for the baseline system in Table 5. The tables first list the results for the individual verbs and then the average results for the 7 and 3 verbs, respectively. When WSD is used to simply separate the first sense from any other sense (for the 7 verbs) we observe an increase in the F-measure from &amp;quot;We acknowledge that the gold standard is not fully ideal for SemCor data, however, we believe that is reasonable, given that both SemCor and BNC are balanced corpora. threshold was applied to remove the noisy SCFs from the distributions. that KL &gt; 0, with KL near to 0 denoting strong association, and —1 &lt; RC &lt;1, with RC near to 0 denoting a low degree of association and RC near to -1 and 1 denoting strong association. (Korhonen, 2002) for details of all the evaluation methods discussed in this section. (1) Verb KL RC System results SCFs Precision (%) Recall (%) F add 0.20 0.76 100.0 66.7 80.0 1 carry 0.26 0.77 69.2 90.0 78.2 1 drop 0.29 0.73 88.9 66.7 76.2 1 fi// 0.07 0.77 100.0 75.0 85.7 0 give 0.57 0.76 71.4 46.5 56.3 3 meet 0.30 0.89 71.4 62.5 66.7 2 throw 0.48 0.66 100.0 88.9 94.1 0 AVERAGE 0.31 0.76 85.8 70.9 77.6 1.1 keep 0.33 0.46 87.5 43.8 58.4 1 hit 0.66 0.76 86.5 75.0 80.3 0 move 0.15 0.67 100.0 89.0 94.2 0 AVERAGE 0.38 0.63 91.3 69.3 78.8 0.3 Table 4: Results with WSD Verb KL RC System results SCFs Precision (%) Recall (%) F add 0.55 0.73 100.0 55.6 71.5 1 carry 0.34 0.81 81.8 90.0 85.7 1 drop 0.30 0.63 88.9 66.7 76.2 1 fi// 0.12 0.75 100.0 61.5 76.2 0 give 0.62 0.72 66.7 44.4 53.3 3 meet 0.37 0.84 66.7 50.0 57.2 2 throw 0.50 0.69 100.0 88.9 94.1 0 AVERAGE 0.40 0.74 86.3 65.3 74.3 1.1 keep 0.48 0.63 77.8 43.8 56.0 5 hit 0.61 0.61 85.7 75.0 80.0 0 move 0.19 0.60 100.0 77.8 87.5 1 AVERAGE 0.43 0.61 87.8 65.5 75.0 2.0 Table 5: Results with baseline system 74.3 to 77.6. In the case of those 3 verbs where we distinguished three sense groups we report an increase in the F-measure from 75.0 to 78.8. For these verbs using two sets of back-off estimates instead of only one makes a clear difference: the average number of false negative SCFs missing altogether in data decreases from 2.0 to 0.3. The benefit of WSD shows as well on KL and RC, although not as clearly: KL improves 0.09 for 7 verbs and 0.05 for 3 verbs, while RC improves 0.02 for both 7 and 3 verbs. The improvements are smaller here because KL and RC are more sensitive measures. They both consider unfiltered SCF distributions and (unlike type precision and type recall) evaluate the actual frequencies/ranks of SCFs. Although back-off estimates generally help to correct the frequencies/ranks, the improvement obtained is higher the more accurate the original unsmoothed distribution is. In our experiments, the system often could not acquire an accurate SCF distribution because an insufficient number of corpus occurrences were available. Thus we require adequate data for all the senses considered to investigate the full potential of the modified system. 4 Conclusion The main contribution of this paper was to show that WSD can improve the accuracy of SCF acquisition. This indicates that SCF acquisition may be used as task-based evaluation for WSD systems. In our experiments, subcategorization acquisition performed better when the first sense occurrences were simply separated from all the other occurrences (as opposed to assuming the first sense for all the occurrences). Disambiguating two senses (for those verbs which require it) has the additional advantage that two sets of backoff estimates can be employed, in which case smoothing yields a more comprehensive SCF distribution. 5 Future Work We have carried out a very small scale experiment. As a next step, we would like to carry out an experiment on a bigger scale. However, for this to be possible, we would need to employ an accurate WSD system. As we propose to always restrict the evaluation to particular (high frequency polysemous) words, a supervised WSD system suggests itself as we can collect training data specific to these words. With sufficient training data, a supervised system should perform better than the most frequent sense baseline. References S. Atkins. 1992. Tools for corpus-aided lexicography: HECTOR project. Linguistica Hungar- B. K. Boguraev and E. J. Briscoe. 1987. Large lexicons for natural language processing utilising grammar coding system of the Dictionary of Contemporary English. Computational E. Briscoe and J. Carroll. 1997. Automatic extracof subcategorization from corpora. In Proof ACL ANLP97, 356-363. G. Carroll and M. Rooth. 1998. Valence induction a head-lexicalized PCFG. In Conference on Empirical Methods in Natural Language Proce ssing. B. Dorr. 1997. Large-scale dictionary construction for foreign language tutoring and interlinmachine translation. Translation,</abstract>
<note confidence="0.946369608695652">12(4):271-325. R. Grishman, C. Macleod, and A. Meyers. 1994. Comlex syntax: building a computational lexi- In Conference on Computa- Linguistics, COLING-94, 268-272. A. Kilgarriff. 1998. SENSEVAL: An exercise in evaluating word sense disambiguation programs. In of LREC, 581-588. Korhonen. 2002. Acquisition. Ph.D. thesis, University of Cambridge. S. Kurohashi. 2002. SENSEVAL-2 Japanese transtask. In of SENSEVAL-2: Second International Workshop on Evaluating Word Sense Disambiguating Systems. G. Leech. 1992. 100 million words of English: British National Corpus. Research, 28(1):1-13. Levin. 1993. Verb Classes and Alterna- University Press. D. Manning and H. Schaze. 1999. Statistical Natural Language Processing. Press. G. Miller, R. Beckwith, C. Felbaum, D. Gross, and</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Atkins</author>
</authors>
<title>Tools for corpus-aided lexicography: the HECTOR project.</title>
<date>1992</date>
<journal>Acta Linguistica Hungarica,</journal>
<pages>41--5</pages>
<marker>Atkins, 1992</marker>
<rawString>S. Atkins. 1992. Tools for corpus-aided lexicography: the HECTOR project. Acta Linguistica Hungarica, 41:5-72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B K Boguraev</author>
<author>E J Briscoe</author>
</authors>
<title>Large lexicons for natural language processing utilising the grammar coding system of the Longman Dictionary of Contemporary English.</title>
<date>1987</date>
<journal>Computational Linguistics,</journal>
<pages>13--4</pages>
<contexts>
<context position="4516" citStr="Boguraev and Briscoe, 1987" startWordPosition="698" endWordPosition="701">the boundaries of predicates. A comprehensive SCF classifier is then applied, which assigns the resulting patterns to SCFs or rejects them as unclassifiable (on the basis of the fea3This is examined beforehand by investigating (i) the syntactic similarity of Levin (sub)classes and (ii) the subcategorization similarity between individual verbs from these classes. 4See the work of Korhonen (2002) for details of the mapping. ture values of syntactic categories and head lemmas, which are included in each pattern). The classifier chooses from 163 verbal SCFs, a superset of those found in the ANLT (Boguraev and Briscoe, 1987) and COMLEX Syntax dictionaries (Grishman et al., 1994). Finally, sets of SCFs are gathered for verbs and putative lexical entries are constructed. A putative lexical entry includes various information, e.g. the relative frequency of the SCF given the verb. The SCF distribution is smoothed using the probability (i.e. &amp;quot;back-off&amp;quot;) estimates of the semantic class of the verb. Smoothing is done using linear interpolation (e.g. (Manning and Schiitze, 1999)). The back-off estimates are obtained using the following method: (i) 4-5 individual verbs are chosen from a verb class. (ii) SCF distributions </context>
</contexts>
<marker>Boguraev, Briscoe, 1987</marker>
<rawString>B. K. Boguraev and E. J. Briscoe. 1987. Large lexicons for natural language processing utilising the grammar coding system of the Longman Dictionary of Contemporary English. Computational Linguistics, 13(4):219-240.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Briscoe</author>
<author>J Carroll</author>
</authors>
<title>Automatic extraction of subcategorization from corpora.</title>
<date>1997</date>
<booktitle>In Proceedings of ACL ANLP97,</booktitle>
<pages>356--363</pages>
<contexts>
<context position="1682" citStr="Briscoe and Carroll (1997)" startWordPosition="259" endWordPosition="262">owing that WSD can indeed improve the accuracy of subcategorization acquisition. We therefore conclude that SCF acquisition can potentially be used as a task-based evaluation method for WSD. In Section 2 we describe the baseline subcategorization acquisition system, discuss the need for WSD and report the modifications made to the system to enable it to use WSD. We describe our experiment with the modified system in Section 3, draw our conclusions in Section 4 and discuss future work in Section 5. 2 Subcategorization Acquisition 2.1 Baseline System Building on the SCF acquisition framework of Briscoe and Carroll (1997), Korhonen (2002) has proposed a system which uses knowledge of verb semantics to guide the process of subcategorization acquisition.2 The approach adopted for SCF acquisition is motivated by research which has demonstrated that semantically similar verbs are similar also in terms of subcategorization (Levin, 1993). Not only verb senses but also verb forms correlate well in terms of SCF distributions, provided that 2This system currently only treats verbs but plans are under way to extend it to other parts of speech (nouns and adjectives). they are classified semantically according to a verbs&apos;</context>
<context position="3517" citStr="Briscoe and Carroll (1997)" startWordPosition="542" endWordPosition="545">ed to guide the acquisition process. The system works by first identifying the sense, i.e. the semantic class for a predicate. The semantic classes are based on Levin classes (Levin, 1993); mostly on broad classes (e.g. 51. &amp;quot;Motion verbs&amp;quot;) rather than subclasses (e.g. 51.2 &amp;quot;Leave verbs&amp;quot;) as the former are usually found distinctive enough in terms of subcategorization.3 Verbs are classified according to their predominant sense in WordNet. This is done using a mapping which links WordNet synsets with Levin classes.4 After semantic class assignment, the subcategorization acquisition machinery of Briscoe and Carroll (1997) is used to acquire a putative SCF distribution from corpus data. The system tags, lemmatizes and parses corpus data using a robust statistical parser which employs a grammar written in a feature-based unification grammar formalism. This yields complete though shallow parses. Local syntactic frames are extracted from parses, from sentence subanalyses which begin/end at the boundaries of predicates. A comprehensive SCF classifier is then applied, which assigns the resulting patterns to SCFs or rejects them as unclassifiable (on the basis of the fea3This is examined beforehand by investigating (</context>
</contexts>
<marker>Briscoe, Carroll, 1997</marker>
<rawString>E. Briscoe and J. Carroll. 1997. Automatic extraction of subcategorization from corpora. In Proceedings of ACL ANLP97, pages 356-363.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Carroll</author>
<author>M Rooth</author>
</authors>
<title>Valence induction with a head-lexicalized PCFG.</title>
<date>1998</date>
<booktitle>In 3rd Conference on Empirical Methods in Natural Language Proce ssing.</booktitle>
<contexts>
<context position="2713" citStr="Carroll and Rooth, 1998" startWordPosition="418" endWordPosition="421">vided that 2This system currently only treats verbs but plans are under way to extend it to other parts of speech (nouns and adjectives). they are classified semantically according to a verbs&apos; predominant sense (Korhonen, 2002). For example, as the predominant senses of fly and move are similar (they both belong to the Levin &amp;quot;Motion verbs&amp;quot;), their SCF distributions correlate quite closely. Good correlation is observed because the majority of SCF occurrences tend to be of the predominant sense (Preiss et al., 2002). The system of Korhonen (2002) resembles other subcategorization systems (e.g. (Carroll and Rooth, 1998; Sarkar and Zeman, 2000)) in that it acquires SCFs specific to verb form rather than sense. Back-off (i.e. probability) estimates based on the predominant sense are, however, used to guide the acquisition process. The system works by first identifying the sense, i.e. the semantic class for a predicate. The semantic classes are based on Levin classes (Levin, 1993); mostly on broad classes (e.g. 51. &amp;quot;Motion verbs&amp;quot;) rather than subclasses (e.g. 51.2 &amp;quot;Leave verbs&amp;quot;) as the former are usually found distinctive enough in terms of subcategorization.3 Verbs are classified according to their predominan</context>
</contexts>
<marker>Carroll, Rooth, 1998</marker>
<rawString>G. Carroll and M. Rooth. 1998. Valence induction with a head-lexicalized PCFG. In 3rd Conference on Empirical Methods in Natural Language Proce ssing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Dorr</author>
</authors>
<title>Large-scale dictionary construction for foreign language tutoring and interlingual machine translation.</title>
<date>1997</date>
<journal>Machine Translation,</journal>
<pages>12--4</pages>
<contexts>
<context position="11597" citStr="Dorr (1997)" startWordPosition="1879" endWordPosition="1880">et, which has almost all words hand annotated with WordNet senses. 3.2 Test Data The size of the concordance, shown in Table 1, along with the lack of a full mapping between WordNet and Levin, proved to be the biggest problems introducing many sparse data difficulties19. It restricted our investigation to a small scale as we only found 10 verbs with sufficiently many occurrences in anything other than the predominant sense. 91n this task, participants were presented with three pieces of continuous text and were asked to sense tag every occurrence of noun, verb, adjective and adverb in them. 19Dorr (1997) provides a full mapping between Wordnet and Levin, but we cannot utilize this mapping: it is not accurate enough for our purposes and does not cover predominant senses of all verbs. Verb Senses 1st Other add 114 81 carry 69 74 drop 35 60 fill 57 28 give 414 271 meet 75 151 throw 59 13 Table 2: Chosen verbs with two sense distinctions Senses Verb 1st 2nd Other keep 215 36 68 hit 41 20 19 move 124 52 65 Table 3: Chosen verbs with three sense distinctions The ten chosen verbs are shown in Tables 2 and 3. There were three verbs for which enough data was present to distinguish the first and second</context>
</contexts>
<marker>Dorr, 1997</marker>
<rawString>B. Dorr. 1997. Large-scale dictionary construction for foreign language tutoring and interlingual machine translation. Machine Translation, 12(4):271-325.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Grishman</author>
<author>C Macleod</author>
<author>A Meyers</author>
</authors>
<title>Comlex syntax: building a computational lexicon.</title>
<date>1994</date>
<booktitle>In International Conference on Computational Linguistics, COLING-94,</booktitle>
<pages>268--272</pages>
<contexts>
<context position="4571" citStr="Grishman et al., 1994" startWordPosition="707" endWordPosition="710"> is then applied, which assigns the resulting patterns to SCFs or rejects them as unclassifiable (on the basis of the fea3This is examined beforehand by investigating (i) the syntactic similarity of Levin (sub)classes and (ii) the subcategorization similarity between individual verbs from these classes. 4See the work of Korhonen (2002) for details of the mapping. ture values of syntactic categories and head lemmas, which are included in each pattern). The classifier chooses from 163 verbal SCFs, a superset of those found in the ANLT (Boguraev and Briscoe, 1987) and COMLEX Syntax dictionaries (Grishman et al., 1994). Finally, sets of SCFs are gathered for verbs and putative lexical entries are constructed. A putative lexical entry includes various information, e.g. the relative frequency of the SCF given the verb. The SCF distribution is smoothed using the probability (i.e. &amp;quot;back-off&amp;quot;) estimates of the semantic class of the verb. Smoothing is done using linear interpolation (e.g. (Manning and Schiitze, 1999)). The back-off estimates are obtained using the following method: (i) 4-5 individual verbs are chosen from a verb class. (ii) SCF distributions are built for these verbs by manually analysing c. 300 </context>
</contexts>
<marker>Grishman, Macleod, Meyers, 1994</marker>
<rawString>R. Grishman, C. Macleod, and A. Meyers. 1994. Comlex syntax: building a computational lexicon. In International Conference on Computational Linguistics, COLING-94, pages 268-272.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kilgarriff</author>
</authors>
<title>SENSEVAL: An exercise in evaluating word sense disambiguation programs.</title>
<date>1998</date>
<booktitle>In Proceedings of LREC,</booktitle>
<pages>581--588</pages>
<marker>Kilgarriff, 1998</marker>
<rawString>A. Kilgarriff. 1998. SENSEVAL: An exercise in evaluating word sense disambiguation programs. In Proceedings of LREC, pages 581-588.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Korhonen</author>
</authors>
<title>Subcategorization Acquisition.</title>
<date>2002</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Cambridge.</institution>
<contexts>
<context position="780" citStr="Korhonen, 2002" startWordPosition="117" endWordPosition="118">or Computational Linguistics. a task-based evaluation are specific to the language pair: the number of senses of a word corresponds to the number of translations into the target language. Thus such a task-based evaluation method avoids the problems from point 1. In this paper, we investigate evaluating WSD using a task-based method in the context of SCF acquisition. SCF acquisition is potentially a well suited task for WSD as subcategorization is known to be sensitive to sense variation (Roland et al., 2000; Roland and Jurafsky, 2001). We take an existing subcategorization acquisition system (Korhonen, 2002) and carry out a small scale experiment (initially discussed in (Preiss et al., 2002)) to investigate whether it is possible to improve the performance of this system using WSD. Our preliminary results on sense annotated data derived from the SemCor corpus are encouraging, showing that WSD can indeed improve the accuracy of subcategorization acquisition. We therefore conclude that SCF acquisition can potentially be used as a task-based evaluation method for WSD. In Section 2 we describe the baseline subcategorization acquisition system, discuss the need for WSD and report the modifications mad</context>
<context position="2317" citStr="Korhonen, 2002" startWordPosition="358" endWordPosition="359">s proposed a system which uses knowledge of verb semantics to guide the process of subcategorization acquisition.2 The approach adopted for SCF acquisition is motivated by research which has demonstrated that semantically similar verbs are similar also in terms of subcategorization (Levin, 1993). Not only verb senses but also verb forms correlate well in terms of SCF distributions, provided that 2This system currently only treats verbs but plans are under way to extend it to other parts of speech (nouns and adjectives). they are classified semantically according to a verbs&apos; predominant sense (Korhonen, 2002). For example, as the predominant senses of fly and move are similar (they both belong to the Levin &amp;quot;Motion verbs&amp;quot;), their SCF distributions correlate quite closely. Good correlation is observed because the majority of SCF occurrences tend to be of the predominant sense (Preiss et al., 2002). The system of Korhonen (2002) resembles other subcategorization systems (e.g. (Carroll and Rooth, 1998; Sarkar and Zeman, 2000)) in that it acquires SCFs specific to verb form rather than sense. Back-off (i.e. probability) estimates based on the predominant sense are, however, used to guide the acquisitio</context>
<context position="4286" citStr="Korhonen (2002)" startWordPosition="660" endWordPosition="661">ch employs a grammar written in a feature-based unification grammar formalism. This yields complete though shallow parses. Local syntactic frames are extracted from parses, from sentence subanalyses which begin/end at the boundaries of predicates. A comprehensive SCF classifier is then applied, which assigns the resulting patterns to SCFs or rejects them as unclassifiable (on the basis of the fea3This is examined beforehand by investigating (i) the syntactic similarity of Levin (sub)classes and (ii) the subcategorization similarity between individual verbs from these classes. 4See the work of Korhonen (2002) for details of the mapping. ture values of syntactic categories and head lemmas, which are included in each pattern). The classifier chooses from 163 verbal SCFs, a superset of those found in the ANLT (Boguraev and Briscoe, 1987) and COMLEX Syntax dictionaries (Grishman et al., 1994). Finally, sets of SCFs are gathered for verbs and putative lexical entries are constructed. A putative lexical entry includes various information, e.g. the relative frequency of the SCF given the verb. The SCF distribution is smoothed using the probability (i.e. &amp;quot;back-off&amp;quot;) estimates of the semantic class of the </context>
<context position="5952" citStr="Korhonen (2002)" startWordPosition="932" endWordPosition="933">hich subcategorization is being acquired is always excluded from the back-off estimates. The back-off estimates for the &amp;quot;Motion verb&amp;quot; fly, for example, are constructed by merging the SCF distributions for 5 other &amp;quot;Motion verbs&amp;quot; e.g. move, slide, arrive, travel, and sail. As a final step, a simple empirically determined threshold is used on the probability estimates after smoothing to filter out noisy SCFs. The back-off estimates based on the predominant sense of the verb help to correct the acquired SCF distribution and deal with sparse data. Where the predominant sense is assigned correctly, Korhonen (2002) reports significant improvement in SCF acquisition. On a test set of 45 verbs from 18 semantic classes, the proposed method yields 78 F-measure,5 while the F-measure is only 61 when no sense is assumed 5See Section 3.3.1 for calculation of F-measure. (i.e. when no back-off estimates are employed and no smoothing is done). 2.2 The Need for WSD Preiss et al. (2002) examined the effect of the current predominant sense heuristics on the baseline system performance. The following observations were made: 1. Significant improvement is reported with SCF acquisition by assuming the predominant sense o</context>
<context position="15118" citStr="Korhonen, 2002" startWordPosition="2494" endWordPosition="2495"> verbs, respectively. When WSD is used to simply separate the first sense from any other sense (for the 7 verbs) we observe an increase in the F-measure from &amp;quot;We acknowledge that the gold standard is not fully ideal for SemCor data, however, we believe that is reasonable, given that both SemCor and BNC are balanced corpora. 12No threshold was applied to remove the noisy SCFs from the distributions. 13Note that KL &gt; 0, with KL near to 0 denoting strong association, and —1 &lt; RC &lt;1, with RC near to 0 denoting a low degree of association and RC near to -1 and 1 denoting strong association. 14See (Korhonen, 2002) for details of all the evaluation methods discussed in this section. (1) Verb KL RC System results Unseen SCFs Precision (%) Recall (%) F add 0.20 0.76 100.0 66.7 80.0 1 carry 0.26 0.77 69.2 90.0 78.2 1 drop 0.29 0.73 88.9 66.7 76.2 1 fi// 0.07 0.77 100.0 75.0 85.7 0 give 0.57 0.76 71.4 46.5 56.3 3 meet 0.30 0.89 71.4 62.5 66.7 2 throw 0.48 0.66 100.0 88.9 94.1 0 AVERAGE 0.31 0.76 85.8 70.9 77.6 1.1 keep 0.33 0.46 87.5 43.8 58.4 1 hit 0.66 0.76 86.5 75.0 80.3 0 move 0.15 0.67 100.0 89.0 94.2 0 AVERAGE 0.38 0.63 91.3 69.3 78.8 0.3 Table 4: Results with WSD Verb KL RC System results Unseen SCFs</context>
</contexts>
<marker>Korhonen, 2002</marker>
<rawString>A. Korhonen. 2002. Subcategorization Acquisition. Ph.D. thesis, University of Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kurohashi</author>
</authors>
<title>SENSEVAL-2 Japanese translation task.</title>
<date>2002</date>
<booktitle>In Proceedings of SENSEVAL-2: Second International Workshop on Evaluating Word Sense Disambiguating Systems.</booktitle>
<marker>Kurohashi, 2002</marker>
<rawString>S. Kurohashi. 2002. SENSEVAL-2 Japanese translation task. In Proceedings of SENSEVAL-2: Second International Workshop on Evaluating Word Sense Disambiguating Systems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Leech</author>
</authors>
<title>100 million words of English:</title>
<date>1992</date>
<journal>the British National Corpus. Language Research,</journal>
<pages>28--1</pages>
<contexts>
<context position="5246" citStr="Leech, 1992" startWordPosition="816" endWordPosition="817">ical entries are constructed. A putative lexical entry includes various information, e.g. the relative frequency of the SCF given the verb. The SCF distribution is smoothed using the probability (i.e. &amp;quot;back-off&amp;quot;) estimates of the semantic class of the verb. Smoothing is done using linear interpolation (e.g. (Manning and Schiitze, 1999)). The back-off estimates are obtained using the following method: (i) 4-5 individual verbs are chosen from a verb class. (ii) SCF distributions are built for these verbs by manually analysing c. 300 occurrences of each verb in the British National Corpus (BNC) (Leech, 1992). (iii) The resulting SCF distributions are merged. The SCF distribution for the verb for which subcategorization is being acquired is always excluded from the back-off estimates. The back-off estimates for the &amp;quot;Motion verb&amp;quot; fly, for example, are constructed by merging the SCF distributions for 5 other &amp;quot;Motion verbs&amp;quot; e.g. move, slide, arrive, travel, and sail. As a final step, a simple empirically determined threshold is used on the probability estimates after smoothing to filter out noisy SCFs. The back-off estimates based on the predominant sense of the verb help to correct the acquired SCF </context>
</contexts>
<marker>Leech, 1992</marker>
<rawString>G. Leech. 1992. 100 million words of English: the British National Corpus. Language Research, 28(1):1-13.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Levin</author>
</authors>
<title>English Verb Classes and Alternations.</title>
<date>1993</date>
<publisher>Chicago University Press.</publisher>
<contexts>
<context position="1998" citStr="Levin, 1993" startWordPosition="307" endWordPosition="308">he system to enable it to use WSD. We describe our experiment with the modified system in Section 3, draw our conclusions in Section 4 and discuss future work in Section 5. 2 Subcategorization Acquisition 2.1 Baseline System Building on the SCF acquisition framework of Briscoe and Carroll (1997), Korhonen (2002) has proposed a system which uses knowledge of verb semantics to guide the process of subcategorization acquisition.2 The approach adopted for SCF acquisition is motivated by research which has demonstrated that semantically similar verbs are similar also in terms of subcategorization (Levin, 1993). Not only verb senses but also verb forms correlate well in terms of SCF distributions, provided that 2This system currently only treats verbs but plans are under way to extend it to other parts of speech (nouns and adjectives). they are classified semantically according to a verbs&apos; predominant sense (Korhonen, 2002). For example, as the predominant senses of fly and move are similar (they both belong to the Levin &amp;quot;Motion verbs&amp;quot;), their SCF distributions correlate quite closely. Good correlation is observed because the majority of SCF occurrences tend to be of the predominant sense (Preiss et</context>
</contexts>
<marker>Levin, 1993</marker>
<rawString>B. Levin. 1993. English Verb Classes and Alternations. Chicago University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C D Manning</author>
<author>H Schaze</author>
</authors>
<title>Foundations of Statistical Natural Language Processing.</title>
<date>1999</date>
<publisher>MIT Press.</publisher>
<marker>Manning, Schaze, 1999</marker>
<rawString>C. D. Manning and H. Schaze. 1999. Foundations of Statistical Natural Language Processing. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Miller</author>
<author>R Beckwith</author>
<author>C Felbaum</author>
<author>D Gross</author>
<author>K Miller</author>
</authors>
<title>Introduction to WordNet: An on-line lexical database.</title>
<date>1990</date>
<journal>Journal of Lexicography,</journal>
<pages>3--4</pages>
<marker>Miller, Beckwith, Felbaum, Gross, Miller, 1990</marker>
<rawString>G. Miller, R. Beckwith, C. Felbaum, D. Gross, and K. Miller. 1990. Introduction to WordNet: An on-line lexical database. Journal of Lexicography, 3(4):235-244.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Preiss</author>
<author>A Korhonen</author>
<author>T Briscoe</author>
</authors>
<title>Subcategorization acquisition as an evaluation method for WSD.</title>
<date>2002</date>
<booktitle>In Proceedings of LREC.</booktitle>
<contexts>
<context position="865" citStr="Preiss et al., 2002" startWordPosition="129" endWordPosition="132">ge pair: the number of senses of a word corresponds to the number of translations into the target language. Thus such a task-based evaluation method avoids the problems from point 1. In this paper, we investigate evaluating WSD using a task-based method in the context of SCF acquisition. SCF acquisition is potentially a well suited task for WSD as subcategorization is known to be sensitive to sense variation (Roland et al., 2000; Roland and Jurafsky, 2001). We take an existing subcategorization acquisition system (Korhonen, 2002) and carry out a small scale experiment (initially discussed in (Preiss et al., 2002)) to investigate whether it is possible to improve the performance of this system using WSD. Our preliminary results on sense annotated data derived from the SemCor corpus are encouraging, showing that WSD can indeed improve the accuracy of subcategorization acquisition. We therefore conclude that SCF acquisition can potentially be used as a task-based evaluation method for WSD. In Section 2 we describe the baseline subcategorization acquisition system, discuss the need for WSD and report the modifications made to the system to enable it to use WSD. We describe our experiment with the modified</context>
<context position="2609" citStr="Preiss et al., 2002" startWordPosition="404" endWordPosition="407">in, 1993). Not only verb senses but also verb forms correlate well in terms of SCF distributions, provided that 2This system currently only treats verbs but plans are under way to extend it to other parts of speech (nouns and adjectives). they are classified semantically according to a verbs&apos; predominant sense (Korhonen, 2002). For example, as the predominant senses of fly and move are similar (they both belong to the Levin &amp;quot;Motion verbs&amp;quot;), their SCF distributions correlate quite closely. Good correlation is observed because the majority of SCF occurrences tend to be of the predominant sense (Preiss et al., 2002). The system of Korhonen (2002) resembles other subcategorization systems (e.g. (Carroll and Rooth, 1998; Sarkar and Zeman, 2000)) in that it acquires SCFs specific to verb form rather than sense. Back-off (i.e. probability) estimates based on the predominant sense are, however, used to guide the acquisition process. The system works by first identifying the sense, i.e. the semantic class for a predicate. The semantic classes are based on Levin classes (Levin, 1993); mostly on broad classes (e.g. 51. &amp;quot;Motion verbs&amp;quot;) rather than subclasses (e.g. 51.2 &amp;quot;Leave verbs&amp;quot;) as the former are usually fou</context>
<context position="6318" citStr="Preiss et al. (2002)" startWordPosition="993" endWordPosition="996">imates after smoothing to filter out noisy SCFs. The back-off estimates based on the predominant sense of the verb help to correct the acquired SCF distribution and deal with sparse data. Where the predominant sense is assigned correctly, Korhonen (2002) reports significant improvement in SCF acquisition. On a test set of 45 verbs from 18 semantic classes, the proposed method yields 78 F-measure,5 while the F-measure is only 61 when no sense is assumed 5See Section 3.3.1 for calculation of F-measure. (i.e. when no back-off estimates are employed and no smoothing is done). 2.2 The Need for WSD Preiss et al. (2002) examined the effect of the current predominant sense heuristics on the baseline system performance. The following observations were made: 1. Significant improvement is reported with SCF acquisition by assuming the predominant sense only. This indicates that all senses are not equally important. 2. Good results are obtained by assuming a fairly wide notion of sense based on a broad Levin class. This indicates that WordNet style fine-grained sense distinctions are not necessary for the task.6 3. When the predominant sense assignment is done correctly, the system performs better with some verbs </context>
<context position="7585" citStr="Preiss et al. (2002)" startWordPosition="1203" endWordPosition="1206">in an increase in accuracy if we consider more senses. Preiss et al. (2002) investigated to what extent WSD would improve the system performance. They showed that those high frequency polysemous verbs whose predominant sense is not very frequent would benefit from WSD. The distribution of senses is not as zipfian for these verbs as it is for other verbs. That is, the predominant sense does not cover enough of the total frequency mass for back-off estimates to yield maximum benefit. WSD was not proposed for all senses of high frequency polysemous verbs. The number of senses considered for WSD, Preiss et al. (2002) suggested, would depend on the frequency mass covered by the senses. They suggested considering 75% of the total frequency mass. For example, for the verb continue, to cover 75% of frequency mass, it is only necessary to consider the first two out of a total of nine WordNet senses. 6Note that this is beneficial: the method would suffer from sparse data problems if a narrow WordNet style notion of sense was assumed. It would be difficult to obtain back-off estimates for senses with very low in frequency. 2.3 Modifications We modified the baseline system outlined in Section 2.1 so that it can b</context>
</contexts>
<marker>Preiss, Korhonen, Briscoe, 2002</marker>
<rawString>J. Preiss, A. Korhonen, and T. Briscoe. 2002. Subcategorization acquisition as an evaluation method for WSD. In Proceedings of LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Roland</author>
<author>D Jurafsky</author>
</authors>
<title>Verb sense and verb subcategorization probabilities.</title>
<date>2001</date>
<booktitle>The Lexical Basis of Sentence Processing: Formal, Computational, and Experimental Issue.</booktitle>
<editor>In S. Stevenson and P. Merlo, editors,</editor>
<publisher>Cambridge University Press,</publisher>
<location>Jon Benjamins, Amsterdam.</location>
<note>To appear.</note>
<contexts>
<context position="705" citStr="Roland and Jurafsky, 2001" startWordPosition="105" endWordPosition="108">t Successes and Future Directions, Philadelphia, July 2002, pp. 102-108. Association for Computational Linguistics. a task-based evaluation are specific to the language pair: the number of senses of a word corresponds to the number of translations into the target language. Thus such a task-based evaluation method avoids the problems from point 1. In this paper, we investigate evaluating WSD using a task-based method in the context of SCF acquisition. SCF acquisition is potentially a well suited task for WSD as subcategorization is known to be sensitive to sense variation (Roland et al., 2000; Roland and Jurafsky, 2001). We take an existing subcategorization acquisition system (Korhonen, 2002) and carry out a small scale experiment (initially discussed in (Preiss et al., 2002)) to investigate whether it is possible to improve the performance of this system using WSD. Our preliminary results on sense annotated data derived from the SemCor corpus are encouraging, showing that WSD can indeed improve the accuracy of subcategorization acquisition. We therefore conclude that SCF acquisition can potentially be used as a task-based evaluation method for WSD. In Section 2 we describe the baseline subcategorization ac</context>
</contexts>
<marker>Roland, Jurafsky, 2001</marker>
<rawString>D. Roland and D. Jurafsky. 2001. Verb sense and verb subcategorization probabilities. In S. Stevenson and P. Merlo, editors, The Lexical Basis of Sentence Processing: Formal, Computational, and Experimental Issue. Cambridge University Press, Jon Benjamins, Amsterdam. To appear.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Roland</author>
<author>D Jurafsky</author>
<author>L Menn</author>
<author>S Gahl</author>
<author>E Elder</author>
<author>C Riddoch</author>
</authors>
<title>Verb subcatecorization frequency differences between business-news and balanced corpora.</title>
<date>2000</date>
<booktitle>In ACL Workshop on Comparing Corpora,</booktitle>
<pages>28--34</pages>
<contexts>
<context position="677" citStr="Roland et al., 2000" startWordPosition="101" endWordPosition="104">Disambiguation: Recent Successes and Future Directions, Philadelphia, July 2002, pp. 102-108. Association for Computational Linguistics. a task-based evaluation are specific to the language pair: the number of senses of a word corresponds to the number of translations into the target language. Thus such a task-based evaluation method avoids the problems from point 1. In this paper, we investigate evaluating WSD using a task-based method in the context of SCF acquisition. SCF acquisition is potentially a well suited task for WSD as subcategorization is known to be sensitive to sense variation (Roland et al., 2000; Roland and Jurafsky, 2001). We take an existing subcategorization acquisition system (Korhonen, 2002) and carry out a small scale experiment (initially discussed in (Preiss et al., 2002)) to investigate whether it is possible to improve the performance of this system using WSD. Our preliminary results on sense annotated data derived from the SemCor corpus are encouraging, showing that WSD can indeed improve the accuracy of subcategorization acquisition. We therefore conclude that SCF acquisition can potentially be used as a task-based evaluation method for WSD. In Section 2 we describe the b</context>
</contexts>
<marker>Roland, Jurafsky, Menn, Gahl, Elder, Riddoch, 2000</marker>
<rawString>D. Roland, D. Jurafsky, L. Menn, S. Gahl, E. Elder, and C. Riddoch. 2000. Verb subcatecorization frequency differences between business-news and balanced corpora. In ACL Workshop on Comparing Corpora, pages 28-34.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Sarkar</author>
<author>D Zeman</author>
</authors>
<title>Automatic extraction of subcategorization frames for Czech.</title>
<date>2000</date>
<booktitle>In 19th International Conference on Computational Linguistics,</booktitle>
<pages>691--697</pages>
<contexts>
<context position="2738" citStr="Sarkar and Zeman, 2000" startWordPosition="422" endWordPosition="425">urrently only treats verbs but plans are under way to extend it to other parts of speech (nouns and adjectives). they are classified semantically according to a verbs&apos; predominant sense (Korhonen, 2002). For example, as the predominant senses of fly and move are similar (they both belong to the Levin &amp;quot;Motion verbs&amp;quot;), their SCF distributions correlate quite closely. Good correlation is observed because the majority of SCF occurrences tend to be of the predominant sense (Preiss et al., 2002). The system of Korhonen (2002) resembles other subcategorization systems (e.g. (Carroll and Rooth, 1998; Sarkar and Zeman, 2000)) in that it acquires SCFs specific to verb form rather than sense. Back-off (i.e. probability) estimates based on the predominant sense are, however, used to guide the acquisition process. The system works by first identifying the sense, i.e. the semantic class for a predicate. The semantic classes are based on Levin classes (Levin, 1993); mostly on broad classes (e.g. 51. &amp;quot;Motion verbs&amp;quot;) rather than subclasses (e.g. 51.2 &amp;quot;Leave verbs&amp;quot;) as the former are usually found distinctive enough in terms of subcategorization.3 Verbs are classified according to their predominant sense in WordNet. This </context>
</contexts>
<marker>Sarkar, Zeman, 2000</marker>
<rawString>A. Sarkar and D. Zeman. 2000. Automatic extraction of subcategorization frames for Czech. In 19th International Conference on Computational Linguistics, pages 691-697.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>