<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002853">
<title confidence="0.9934085">
The BioScope corpus: annotation for negation, uncertainty and their
scope in biomedical texts
</title>
<author confidence="0.999624">
György Szarvas1, Veronika Vincze1, Richárd Farkas2 and János Csirik2
</author>
<affiliation confidence="0.9986335">
1Department of Informatics 2Research Group on Artificial Intelligence
University of Szeged Hungarian Academy of Science
</affiliation>
<address confidence="0.721796">
H-6720, Szeged, Árpád tér 2. H-6720, Szeged, Aradi vértanúk tere 1.
</address>
<email confidence="0.961155">
{szarvas, vinczev, rfarkas, csirik}@inf.u-szeged.hu
</email>
<sectionHeader confidence="0.995364" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999721333333333">
This article reports on a corpus annotation
project that has produced a freely available re-
source for research on handling negation and
uncertainty in biomedical texts (we call this
corpus the BioScope corpus). The corpus con-
sists of three parts, namely medical free texts,
biological full papers and biological scientific
abstracts. The dataset contains annotations at
the token level for negative and speculative
keywords and at the sentence level for their
linguistic scope. The annotation process was
carried out by two independent linguist anno-
tators and a chief annotator – also responsible
for setting up the annotation guidelines – who
resolved cases where the annotators disagreed.
We will report our statistics on corpus size,
ambiguity levels and the consistency of anno-
tations.
</bodyText>
<sectionHeader confidence="0.999135" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999955957446809">
Detecting uncertain and negative assertions is es-
sential in most Text Mining tasks where in general,
the aim is to derive factual knowledge from textual
data. This is especially so for many tasks in the
biomedical (medical and biological) domain,
where these language forms are used extensively in
textual documents and are intended to express im-
pressions, hypothesised explanations of experi-
mental results or negative findings. Take, for
example, the clinical coding of medical reports,
where the coding of a negative or uncertain disease
diagnosis may result in an over-coding financial
penalty. Another example from the biological do-
main is interaction extraction, where the aim is to
mine text evidence for biological entities with cer-
tain relations between them. Here, while an uncer-
tain relation or the non-existence of a relation
might be of some interest for an end-user as well,
such information must not be confused with real
textual evidence (reliable information). A general
conclusion is that for text mining, extracted infor-
mation that is within the scope of some negative /
speculative (hedge or soft negation) keyword
should either be discarded or presented separately
from factual information.
Even though many successful text processing
systems (Friedman et al., 1994, Chapman et al.
2001, Elkin et al. 2005) handle the above-
mentioned phenomena, most of them exploit hand-
crafted rule-based negation/uncertainty detection
modules. To the best of our knowledge, there are
no publicly available standard corpora of reason-
able size that are usable for evaluating the auto-
matic detection and scope resolution of these
language phenomena. The availability of such a
resource would undoubtedly facilitate the devel-
opment of corpus-based statistical systems for ne-
gation/hedge detection and resolution.
Our study seeks to fill this gap by presenting the
BioScope corpus, which consists of medical and
biological texts annotated for negation, speculation
and their linguistic scope. This was done to permit
a comparison between and to facilitate the devel-
opment of systems for negation/hedge detection
and scope resolution. The corpus described in this
paper has been made publicly available for re-
search purposes and it is freely downloadable1.
</bodyText>
<footnote confidence="0.970339">
1 www.inf.u-szeged.hu/rgai/bioscope
</footnote>
<page confidence="0.977831">
38
</page>
<note confidence="0.795783">
BioNLP 2008: Current Trends in Biomedical Natural Language Processing, pages 38–45,
Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics
</note>
<sectionHeader confidence="0.878304" genericHeader="introduction">
1.1 Related work
</sectionHeader>
<bodyText confidence="0.999705542372881">
Chapman et al. (2001) created a simple regular
expression algorithm called NegEx that can detect
phrases indicating negation and identify medical
terms falling within the negative scope. With this
process, a large part of negatives can be identified
in discharge summaries.
Mutalik et al. (2001) earlier developed
Negfinder in order to recognise negated patterns in
medical texts. Their lexer uses regular expressions
to identify words indicating negation and then it
passes them as special tokens to the parser, which
makes use of the single-token look-ahead strategy.
Thus, without appealing to the syntactic structure
of the sentence, Negfinder can reliably identify
negated concepts in medical narrative when they
are located near the negation markers.
Huang and Lowe (2007) implemented a hybrid
approach to automated negation detection. They
combined regular expression matching with
grammatical parsing: negations are classified on
the basis of syntactic categories and they are
located in parse trees. Their hybrid approach is
able to identify negated concepts in radiology
reports even when they are located at some
distance from the negative term.
The Medical Language Extraction and Encoding
(MedLEE) system was developed as a general
natural language processor in order to encode
clinical documents in a structured form (Friedman
et al., 1994). Negated concepts and certainty
modifiers are also encoded within the system, thus
it enables them to make a distinction between
negated/uncertain concepts and factual information
which is crucial in information retrieval.
Elkin et al. (2005) use a list of negation words
and a list of negation scope-ending words in order
to identify negated statements and their scope.
Although a fair amount of literature on
uncertainty (or hedging) in scientific texts has been
produced since the 1990s (e.g. Hyland, 1994),
speculative language from a Natural Language
Processing perspective has only been studied in the
past few years. Previous studies (Light et al., 2004)
showed that the detection of hedging can be solved
effectively by looking for specific keywords which
imply speculative content.
Another possibility is to treat the problem as a
classification task and train a statistical model to
discriminate speculative and non-speculative
assertions. This approach requires the availability
of labeled instances to train the models on.
Medlock and Briscoe (2007) proposed a weakly
supervised setting for hedge classification in
scientific texts where the aim is to minimise human
supervision needed to obtain an adequate amount
of training data. Their system focuses on locating
hedge cues in text and thus they do not determine
the scopes (in other words in a text they define the
scope to be a whole sentence).
</bodyText>
<subsectionHeader confidence="0.886012">
1.2 Related resources
</subsectionHeader>
<bodyText confidence="0.995002333333333">
Even though the problems of negation (mainly in
the medical domain) and hedging (mainly in the
scientific domain) have received much interest in
the past few years, open access annotated resources
for training, testing and comparison are rare and
relatively small in size. Our corpus is the first one
with an annotation of negative/speculative
keywords and their scope. The authors are only
aware of the following related corpora:
</bodyText>
<listItem confidence="0.861452">
• The Hedge classification corpus (Medlock
and Briscoe, 2007), which has been
annotated for hedge cues (at the sentence
level) and consists of five full biological
</listItem>
<bodyText confidence="0.911691">
research papers (1537 sentences). No scope
annotation is given in the original corpus.
We included this publicly available corpus
in ours, enriching the data with annotation
for negation cues and linguistic scope for
both hedging and negation.
</bodyText>
<listItem confidence="0.9931278">
• The Genia Event corpus (Kim et al., 2008),
which annotates biological events with
negation and three levels of uncertainty
(1000 abstracts).
• The BioInfer corpus (Pyysalo et al., 2007),
</listItem>
<bodyText confidence="0.9273944">
where biological relations are annotated for
negation (1100 sentences in size).
In the two latter corpora biological terms
(relations and events) have been annotated for both
negation and hedging, but linguistic cues (i.e.
which keyword modifies the semantics of the
statement) have not been annotated. We annotated
keywords and their linguistic scope, which is very
useful for machine learning or rule-based negation
and hedge detection systems.
</bodyText>
<page confidence="0.999574">
39
</page>
<sectionHeader confidence="0.93936" genericHeader="method">
2 Annotation guidelines
</sectionHeader>
<bodyText confidence="0.99999125">
This section describes the basic principles on the
annotation of speculative and negative scopes in
biomedical texts. Some basic definitions and tech-
nical details are given in Section 2.1, then the gen-
eral guidelines are discussed in Section 2.2 and the
most typical keywords and their scopes are illus-
trated with examples in Section 2.3. Some special
cases and exceptions are listed in Section 2.4, then
the annotation process of the corpus is described
and discussed in Section 2.5. The complete annota-
tion guidelines document is available from the cor-
pus homepage.
</bodyText>
<subsectionHeader confidence="0.992055">
2.1 Basic issues
</subsectionHeader>
<bodyText confidence="0.999420108108108">
In a text, just sentences with some instance of
speculative or negative language are considered for
annotation. The annotation is based on linguistic
principles, i.e. parts of sentences which do not con-
tain any biomedical term are also annotated if they
assert the non-existence/uncertainty of something.
As for speculative annotation, if a sentence is a
statement, that is, it does not include any specula-
tive element that suggests uncertainty, it is disre-
garded. Questions inherently suggest uncertainty –
which is why they are asked –, but they will be
neglected and not annotated unless they contain
speculative language.
Sentences containing any kind of negation are
examined for negative annotation. Negation is un-
derstood as the implication of the non-existence of
something. However, the presence of a word with
negative content does not imply that the sentence
should be annotated as negative, since there are
sentences that include grammatically negative
words but have a speculative meaning or are actu-
ally regular assertions (see the examples below).
In the corpus, instances of speculative and nega-
tive language – that is, keywords and their scope –
are annotated. Speculative elements are marked by
angled brackets: &lt;or&gt;, &lt;suggests&gt; etc., while
negative keywords are marked by square brackets:
[no], [without] etc. The scope of both negative and
speculative keywords is denoted by parentheses.
Also, the speculative or negative cue is always in-
cluded within its scope:
This result (&lt;suggests&gt; that the valency of Bi in
the material is smaller than + 3).
Stable appearance the right kidney ([without] hy-
dronephrosis).
In the following, the general guidelines for specu-
lative and negative annotation are presented.
</bodyText>
<subsectionHeader confidence="0.998359">
2.2 General guidelines
</subsectionHeader>
<bodyText confidence="0.995304382352941">
During the annotation process, we followed a min-
max strategy for the marking of keywords and their
scope. When marking the keywords, a minimalist
strategy was followed: the minimal unit that ex-
pressed hedging or negation was marked as a key-
word. However, there are some cases when hedge
or negation can be expressed via a phrase rather
than a single word. Complex keywords are phrases
that express uncertainty or negation together, but
they cannot do this on their own (the meaning or
the semantics of its subcomponents are signifi-
cantly different from the semantics of the whole
phrase). An instance of a complex keyword can be
seen in the following sentence:
Mild bladder wall thickening (&lt;raises the question
of&gt; cystitis).
On the other hand, a sequence of words cannot be
marked as a complex keyword if it is only one of
those words that express speculative or negative
content (even without the other word). Thus prepo-
sitions, determiners, adverbs and so on are not an-
notated as parts of the complex keyword if the
keyword can have a speculative or negative con-
tent on its own:
The picture most (&lt;likely&gt; reflects airways dis-
ease).
Complex keywords are not to be confused with the
sequence of two or more keywords because they
can express hedge or negation on their own, that is,
without the other keyword as well. In this case,
each keyword is annotated separately, as is shown
in the following example:
Slightly increased perihilar lung markings (&lt;may&gt;
(&lt;indicate&gt; early reactive airways disease)).
</bodyText>
<subsectionHeader confidence="0.999189">
2.3 Scope marking
</subsectionHeader>
<bodyText confidence="0.9988522">
When marking the scopes of negative and specula-
tive keywords, we extended the scope to the big-
gest syntactic unit possible (in contrast to other
corpora like the one described in (Mutalik et al.,
2001)). Thus, annotated scopes always have the
</bodyText>
<page confidence="0.990531">
40
</page>
<bodyText confidence="0.971667639534884">
maximal length – as opposed to the strategy for
annotating keywords, where we marked the mini-
mal unit possible. Our decision was supported by
two facts. First, since scopes must contain their
keywords, it seemed better to include every ele-
ment in between the keyword and the target word
in order to avoid “empty” scopes, that is, scopes
without a keyword. In the next example, however
is not affected by the hedge cue but it should be
included within the scope, otherwise the keyword
and its target phrase would be separated:
(Atelectasis in the right mid zone is, however,
&lt;possible&gt;).
Second, the status of modifiers is occasionally
vague: it is sometimes not clear whether the modi-
fier of the target word belongs to its scope as well.
The following sentence can describe two different
situations:
There is [no] primary impairment of glucocorti-
coid metabolism in the asthmatics.
First, the glucocorticoid metabolism is impaired in
the asthmatics but not primarily, that is, the scope
of no extends to primary. Second, the scope of no
extends to impairment (and its modifiers and com-
plements as well), thus there is no impairment of
the glucocorticoid metabolism at all. Another ex-
ample is shown here:
Mild viral &lt;or&gt; reactive airways disease is de-
tected.
The syntactic structure of the above sentence is
ambiguous. First, the airways disease is surely
mild, but it is not known whether it is viral or reac-
tive; or second, the airways disease is either mild
and viral or reactive and not mild. Most of the sen-
tences with similar problems cannot be disambigu-
ated on the basis of contextual information, hence
the proper treatment of such sentences remains
problematic. However, we chose to mark the wid-
est scope available: in other words, we preferred to
include every possible element within the scope
rather than exclude elements that should probably
be included.
The scope of a keyword can be determined on
the basis of syntax. The scope of verbs, auxiliaries,
adjectives and adverbs usually extends to the right
of the keyword. In the case of verbal elements, i.e.
verbs and auxiliaries, it ends at the end of the
clause (if the verbal element is within a relative
clause or a coordinated clause) or the sentence,
hence all complements and adjuncts are included,
in accordance with the principle of maximal scope
size. Take the following examples:
The presence of urothelial thickening and mild
dilatation of the left ureter (&lt;suggest&gt; that the
patient may have continued vesicoureteral reflux).
These findings that (&lt;may&gt; be from an acute
pneumonia) include minimal bronchiectasis as
well.
These findings (&lt;might&gt; be chronic) and (&lt;may&gt;
represent reactive airways disease).
The scope of attributive adjectives generally ex-
tends to the following noun phrase, whereas the
scope of predicative adjectives includes the whole
sentence. For example, in the following two state-
ments:
This is a 3 month old patient who had (&lt;possible&gt;
pyelonephritis) with elevated fever.
(The demonstration of hormone receptor proteins
in cells from malignant effusions is &lt;possible&gt;).
Sentential adverbs have a scope over the entire
sentence, while the scope of other adverbs usually
ends at the end of the clause or sentence. For in-
stance,
(The chimaeric oncoprotein &lt;probably&gt; affects
cell survival rather than cell growth).
Right upper lobe volume loss and (&lt;probably&gt;
pneumonia).
The scope of conjunctions extends to all members
of the coordination. That is, it usually extends to
the both left and right:
Symptoms may include (fever, cough &lt;or&gt; itches).
Complex keywords such as either ... or have one
scope:
Mild perihilar bronchial wall thickening may rep-
resent (&lt;either&gt; viral infection &lt;or&gt; reactive
airways disease).
</bodyText>
<listItem confidence="0.785224">
Prepositions have a scope over the following
(noun) phrase:
</listItem>
<bodyText confidence="0.6646155">
Mildly hyperinflated lungs ([without] focal opac-
ity).
</bodyText>
<page confidence="0.997618">
41
</page>
<bodyText confidence="0.98752314">
When the subject of the sentence contains the
negative determiners no or neither, its scope ex-
tends to the entire sentence:
Surprisingly, however, ([neither] of these proteins
bound in vitro to EBS1 or EBS2).
The main exception that changes the original scope
of the keyword is the passive voice. The subject of
the passive sentence was originally the object of
the verb, that is, it should be within its scope. This
is why the subject must also be marked within the
scope of the verb or auxiliary. For instance,
(A small amount of adenopathy &lt;cannot be&gt; com-
pletely &lt;excluded&gt;).
Another example of scope change is the case of
raising verbs (seem, appear, be expected, be likely
etc.). These can have two different syntactic pat-
terns, as the following examples suggest:
It seems that the treatment is successful.
The treatment seems to be successful.
In the first case, the scope of seems starts right
with the verb. If this was the case in the second
pattern, the treatment would not be included in the
scope, but it should be like that shown in the first
pattern. Hence in the second sentence, the scope
must be extended to the subject as well:
It (&lt;seems&gt; that the treatment is successful).
(The treatment &lt;seems&gt; to be successful).
Sometimes a negative keyword is present in the
text apparently without a scope: negative obviously
expresses negation, but the negated fact – what
medical problem the radiograph is negative for – is
not part of the sentence. In such cases, the keyword
is marked and the scope contains just the keyword:
([Negative]) chest radiograph.
In the case of elliptic sentences, the same strategy
is followed: the keyword is marked and its scope
includes only the keyword since the verbal phrase,
that is, the scope of not, is not repeated in the sen-
tence.
This decrease was seen in patients who responded
to the therapy as well as in those who did ([not]).
Generally, punctuation marks or conjunctions
function as scope boundary markers in the corpus,
in contrast to the corpus described in (Mutalik et
al., 2001) where certain lexical items are treated as
negation-termination tokens. Since in our corpus
the scope of negation or speculation is mostly ex-
tended to the entire clause in the case of verbal
elements, it is clear that markers of a sentence or
clause boundary determine the end of their scope.
</bodyText>
<subsectionHeader confidence="0.994232">
2.4 Special cases
</subsectionHeader>
<bodyText confidence="0.975708512820513">
It seems unequivocal that whenever there is a
speculative or negative cue in the sentence, the
sentence expresses hedge or negation. However,
we have come across several cases where the pres-
ence of a speculative/negative keyword does not
imply a hedge/negation. That is, some of the cues
do not denote speculation or negation in all their
occurrences, in other words, they are ambiguous.
For instance, the following sentence is a state-
ment and it is the degree of probability that is pre-
cisely determined, but it is not an instance of
hedging although it contains the cue probable:
The planar amide groups in which is still digging
nylon splay around 30 less probable event.
As for negative cues, sentences including a nega-
tive keyword are not necessarily to be annotated
for negation. They can, however, have a specula-
tive content as well. The following sentence con-
tains cannot, which is a negative keyword on its
own, but not in this case:
(A small amount of adenopathy &lt;cannot be&gt; com-
pletely &lt;excluded&gt;).
Some other sentences containing a negative key-
word are not to be annotated either for speculation
or for negation. In the following example, the
negative keyword is accompanied by an adverb
and their meaning is neither speculative nor nega-
tive. The sequence of the negative keyword and the
adverb can be easily substituted by another adverb
or adjective having the same (or a similar) mean-
ing, which is by no means negative – as shown in
the example. In this way, the sentence below can
be viewed as a positive assertion (not a statement
of the non-existence of something).
Thus, signaling in NK3.3 cells is not always
(=sometimes) identical with that in primary NK
cells.
As can be seen from the above examples, hedging
or negation is determined not just by the presence
</bodyText>
<page confidence="0.998224">
42
</page>
<bodyText confidence="0.999792666666667">
of an apparent cue: it is rather an issue of the key-
word, the context and the syntactic structure of the
sentence taken together.
</bodyText>
<subsectionHeader confidence="0.994822">
2.5 Annotation process
</subsectionHeader>
<bodyText confidence="0.9999966875">
Our BioScope corpus was annotated by two inde-
pendent linguists following the guidelines written
by our linguist expert before the annotation of the
corpus was initiated. These guidelines were devel-
oped throughout the annotation process as annota-
tors were often confronted with problematic issues.
The annotators were not allowed to communicate
with each other as far as the annotation process
was concerned, but they could turn to the expert
when needed and regular meetings were also held
between the annotators and the linguist expert in
order to discuss recurring and/or frequent problem-
atic issues. When the two annotations for one sub-
corpus were finalised, differences between the two
were resolved by the linguist expert, yielding the
gold standard labeling of the subcorpus.
</bodyText>
<sectionHeader confidence="0.949004" genericHeader="method">
3 Corpus details
</sectionHeader>
<bodyText confidence="0.999958375">
In this section we will discuss in detail the overall
characteristics of the corpus we developed, includ-
ing a brief description of the texts that constitute
the BioScope corpus and some general statistics
concerning the size of each part, distribution of
negation/hedge cues, ambiguity levels and finally
we will present statistics on the final results of the
annotation work.
</bodyText>
<subsectionHeader confidence="0.99981">
3.1 Corpus texts
</subsectionHeader>
<bodyText confidence="0.999931696969697">
The corpus consists of texts taken from 4 different
sources and 3 different types in order to ensure that
it captures the heterogenity of language use in the
biomedical domain. We decided to add clinical
free-texts (radiology reports), biological full papers
and biological paper abstracts (texts from Genia).
Table 1 summarises the chief characteristics of
the three subcorpora. The 3rd and 5th rows of the
table show the ratio of sentences which contain
negated or uncertain statements. The 4rd and 6th
rows show the number of negation and hedge cue
occurrences in the given corpus.
A major part of the corpus consists of clinical
free-texts. We chose to add medical texts to the
corpus in order to facilitate research on nega-
tion/hedge detection in the clinical domain. The
radiology report corpus that was used for the clini-
cal coding challenge (Pestian et al., 2007) organ-
ised by the Computational Medicine Center in
Cincinatti, Ohio in 2007 was annotated for nega-
tions and uncertainty along with the scopes of each
phenomenon. This part contains 1954 documents,
each having a clinical history and an impression
part, the latter being denser in negated and specula-
tive parts.
Another part of the corpus consists of full sci-
entific articles. 5 articles from FlyBase (the same
data were used by Medlock and Briscoe (2007) for
evaluating sentence-level hedge classifiers) and 4
articles from the open access BMC Bioinformatics
website were downloaded and annotated for nega-
tions, uncertainty and their scopes. Full papers are
particularly useful for evaluating negation/hedge
classifiers as different parts of an article display
different properties in the use of speculative or ne-
gated phrases. Take, for instance, the Conclusions
section of scientific papers that tends to contain
significantly more uncertain or negative findings
than the description of Experimental settings and
methods.
Scientific abstracts are the main targets for
various Text Mining applications like protein-
protein interaction mining due to their public ac-
cessibility (e.g. through PubMed). We therefore
decided to include quite a lot of texts from the ab-
stracts of scientific papers. This is why we in-
cluded the abstracts of the Genia corpus (Collier et
al., 1999). This decision was straightforward for
two reasons. First, the Genia corpus contains syn-
tax tree annotation, which allows a comparison
between scope annotation and syntactic structure.
Being syntactic in nature, scopes should align with
the bracket structure of syntax trees, while scope
resolution algorithms that exploit treebank data can
be used as a theoretical upper bound for the
evaluation of parsers for resolving negative/hedge
scopes. The other reason was that scope annotation
can mutually benefit from the rich annotations of
the Genia corpus, such as term annotation (evalua-
tion) and event annotation (comparison with the
biologist uncertainty labeling of events).
The corpus consists of more than 20.000 anno-
tated sentences altogether. We consider this size to
be sufficiently large to serve as a standard evalua-
tion corpus for negation/hedge detection in the
biomedical domain.
</bodyText>
<page confidence="0.999126">
43
</page>
<table confidence="0.999915125">
Clinical Full Paper Abstract
#Documents 1954 9 1273
#Sentences 6383 2624 11872
Negation 6.6% 13.76% 13.45%
sentences
#Negation cues 871 404 1757
Hedge sentences 13.4% 22.29% 17.69%
#Hedge cues 1137 783 2691
</table>
<tableCaption confidence="0.999833">
Table 1: Statistics of the three subcorpora.
</tableCaption>
<subsectionHeader confidence="0.999944">
3.2 Agreement analysis
</subsectionHeader>
<bodyText confidence="0.999821653846154">
We measured the consistency level of the annota-
tion using inter-annotator agreement analysis. The
inter-annotator agreement rate is defined as the
Fß=1 measure of one annotation, treating the second
one as the gold standard. We calculated agreement
rates for all three subcorpora between the two in-
dependent annotators and between the two annota-
tors and the gold standard labeling. The gold
standard labeling was prepared by the creator of
the annotation guide, who resolved all cases where
the two annotators disagreed on a keyword or its
scope annotation.
We measured the agreement rate of annotating
negative and hedge keywords, and the agreement
rate of annotating the linguistic scope for each
phenomenon. We distinguished left-scope, right-
scope and full scope agreement that required both
left and right scope boundaries to match exactly to
be considered as coinciding annotations. A detailed
analysis of the consistency levels for the three sub-
corpora and the ambiguity levels for each negative
and hedge keyword (that is, the ratio of a keyword
being annotated as a negative/speculative cue and
the number of all the occurrences of the same
keyword in the corpus) can be found at the corpus
homepage.
</bodyText>
<subsectionHeader confidence="0.996054">
3.3 BioScope corpus availability
</subsectionHeader>
<bodyText confidence="0.9998264">
The corpus is available free of charge for research
purposes and can be obtained for a modest price
for business use. For more details, see the Bio-
Scope homepage:
www.inf.u-szeged.hu/rgai/bioscope.
</bodyText>
<sectionHeader confidence="0.999725" genericHeader="conclusions">
4 Conclusions
</sectionHeader>
<bodyText confidence="0.999824075471698">
In this paper we reported on the construction of a
corpus annotated for negations, speculations and
their linguistic scopes. The corpus is accessible for
academic purposes and is free of charge. Apart
from the intended goal of serving as a common
resource for the training, testing and comparison of
biomedical Natural Language Processing systems,
the corpus is also a good resource for the linguistic
analysis of scientific and clinical texts.
The most obvious conclusions here are that the
usual language of clinical documents makes it
much easier to detect negation and uncertainty
cues than in scientific texts because of the very
high ratio of the actual cue words (i.e. low ambigu-
ity level), which explains the high accuracy scores
reported in the literature. In scientific texts – which
are nowadays becoming a popular target for Text
Mining (for literature-based knowledge discovery)
– the detection and scope resolution of negation
and uncertainty is, on the other hand, a problem of
great complexity, with the percentage of non-
hedge occurrences being as high as 90% for some
hedge cue candidates in biological paper abstracts.
Take for example the keyword or which is labeled
as a speculative keyword in only 11.32% of the
cases in scientific abstracts, while it was labeled as
speculative in 97.86% of the cases in clinical texts.
Identifying the scope is also more difficult in sci-
entific texts where the average sentence length is
much longer than in clinical data, and the style of
the texts is also more literary in the former case.
In our study we found that hedge detection is a
more difficult problem than identifying negations
because the number of possible cue words is higher
and the ratio of real cues is significantly lower in
the case of speculation (higher keyword/non-
keyword ambiguity). The annotator-agreement ta-
ble also confirms this opinion: the detection of
hedging is more complicated than negation even
for humans.
Our corpus statistics also prove the importance
of negation and hedge detection. The ratio of ne-
gated and hedge sentences in the corpus varies in
the subcorpora, but we can say that over 20% of
the sentences contains a modifier that radically
influences the semantic content of the sentence.
One of the chief construction principles of the
BioScope corpus was to facilitate the train-
ing/development of automatic negation and hedge
detection systems. Such systems have to solve two
sub-problems: they have to identify real cue words
(note that the probability of any word being a key-
word can be different for various domains) and
</bodyText>
<page confidence="0.997118">
44
</page>
<bodyText confidence="0.999936647058824">
then they have to determine the linguistic scope of
actual keywords.
These automatic hedge and negation detection
methods can be utilised in a variety of ways in a
(biomedical) Text Mining system. They can be
used as a preprocessing tool, i.e. each word in a
detected scope can be removed from the docu-
ments if we seek to extract true assertions. This can
significantly reduce the level of noise for process-
ing in such cases where only a document-level la-
beling is provided (like that for the ICD-9 coding
dataset) and just clear textual evidence for certain
things should be extracted. On the other hand,
similar systems can classify previously extracted
statements according to their certainty or uncer-
tainty, which is generally an important issue in the
automatic processing of scientific texts.
</bodyText>
<sectionHeader confidence="0.998929" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999946153846154">
This work was supported in part by the NKTH
grant of the Jedlik Ányos R&amp;D Programme 2007
(project codename TUDORKA7) of the Hungarian
government. The authors wish to thank the anony-
mous reviewers for their useful suggestions and
comments. The authors also wish to thank the crea-
tors of the ICD-9 coding dataset and the Genia
corpus for making the texts that were used here
publicly available. The authors thank Jin-Dong
Kim as well for the useful comments and sugges-
tions on the annotation guide and Orsolya Vincze
and Mihály Minkó (the two annotators) for their
work.
</bodyText>
<sectionHeader confidence="0.999253" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999838612903226">
Wendy W. Chapman, Will Bridewell, Paul Hanbury,
Gregory F. Cooper and Bruce G. Buchanan. 2001. A
Simple Algorithm for Identifying Negated Findings
and Diseases in Discharge Summaries. Journal of
Biomedical Informatics, 34(5):301–310.
N. Collier, H. S. Park, N. Ogata, Y. Tateishi, C. Nobata,
T. Ohta, T. Sekimizu, H. Imai, K. Ibushi, and J. Tsu-
jii. 1999. The GENIA project: corpus-based knowl-
edge acquisition and information extraction from
genome research papers. Proceedings of EACL-99.
Peter L. Elkin, Steven H. Brown, Brent A. Bauer, Casey
S. Husser, William Carruth, Larry R. Bergstrom and
Dietlind L. Wahner-Roedler. 2005. A controlled trial
of automated classification of negation from clinical
notes. BMC Medical Informatics and Decision Mak-
ing 5:13 doi:10.1186/1472-6947-5-13.
C. Friedman, P.O. Alderson, J.H. Austin, J.J. Cimino,
and S.B. Johnson. 1994. A general natural-language
text processor for clinical radiology. Journal of the
American Medical Informatics Association,
1(2):161–174.
Yang Huang and Henry J. Lowe. 2007. A Novel Hybrid
Approach to Automated Negation Detection in Clini-
cal Radiology Reports. Journal of the American
Medical Informatics Association, 14(3):304–311.
Ken Hyland. 1994. Hedging in academic writing and
EAP textbooks. English for Specific Purposes,
13(3):239–256.
Jin-Dong Kim, Tomoko Ohta, and Jun&apos;ichi Tsujii. 2008.
Corpus annotation for mining biomedical events
from literature. BMC Bioinformatics 2008, 9:10.
Marc Light, Xin Ting Qui, and Padmini Srinivasan.
2004. The language of bioscience: Facts, specula-
tions, and statements in between. In Proceedings of
BioLink 2004 Workshop on Linking Biological Lit-
erature, Ontologies and Databases: Tools for Users.
Boston, Massachusetts, Association for Computa-
tional Linguistics, 17–24.
Ben Medlock and Ted Briscoe. 2007. Weakly super-
vised learning for hedge classification in scientific
literature. In Proceedings of the 45th Annual Meeting
of the Association of Computational Linguistics. Pra-
gue, Association for Computational Linguistics, 992–
999.
Pradeep G. Mutalik, Aniruddha Deshpande, and
Prakash M. Nadkarni. 2001. Use of General-purpose
Negation Detection to Augment Concept Indexing of
Medical Documents: A Quantitative Study Using the
UMLS. Journal of the American Medical Informatics
Association, 8(6):598–609.
John P. Pestian, Chris Brew, Pawel Matykiewicz, DJ
Hovermale, Neil Johnson, K. Bretonnel Cohen, and
Wlodzislaw Duch. 2007. A shared task involving
multi-label classification of clinical free text. In Bio-
logical, translational, and clinical language process-
ing. Prague, Association for Computational
Linguistics, 97–104.
Sampo Pyysalo, Filip Ginter, Juho Heimonen, Jari
Björne, Jorma Boberg, Jouni Järvinen, and Tapio
Salakoski. 2007. BioInfer: a corpus for information
extraction in the biomedical domain. BMC Bioinfor-
matics 2007, 8:50 doi:10.1186/1471-2105-8-50.
</reference>
<page confidence="0.99939">
45
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.474131">
<title confidence="0.993686">The BioScope corpus: annotation for negation, uncertainty and scope in biomedical texts</title>
<author confidence="0.990593">Veronika Richárd</author>
<author confidence="0.990593">János</author>
<affiliation confidence="0.984014">of Informatics Group on Artificial Intelligence University of Szeged Hungarian Academy of Science</affiliation>
<address confidence="0.556625">H-6720, Szeged, Árpád tér 2. H-6720, Szeged, Aradi vértanúk tere 1.</address>
<email confidence="0.956054">szarvas@inf.u-szeged.hu</email>
<email confidence="0.956054">vinczev@inf.u-szeged.hu</email>
<email confidence="0.956054">rfarkas@inf.u-szeged.hu</email>
<email confidence="0.956054">csirik@inf.u-szeged.hu</email>
<abstract confidence="0.995068842105263">This article reports on a corpus annotation project that has produced a freely available resource for research on handling negation and uncertainty in biomedical texts (we call this corpus the BioScope corpus). The corpus consists of three parts, namely medical free texts, biological full papers and biological scientific abstracts. The dataset contains annotations at the token level for negative and speculative keywords and at the sentence level for their linguistic scope. The annotation process was carried out by two independent linguist annotators and a chief annotator – also responsible for setting up the annotation guidelines – who resolved cases where the annotators disagreed. We will report our statistics on corpus size, ambiguity levels and the consistency of annotations.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Wendy W Chapman</author>
<author>Will Bridewell</author>
<author>Paul Hanbury</author>
<author>Gregory F Cooper</author>
<author>Bruce G Buchanan</author>
</authors>
<title>A Simple Algorithm for Identifying Negated Findings and Diseases in Discharge Summaries.</title>
<date>2001</date>
<journal>Journal of Biomedical Informatics,</journal>
<volume>34</volume>
<issue>5</issue>
<contexts>
<context position="2523" citStr="Chapman et al. 2001" startWordPosition="377" endWordPosition="380"> mine text evidence for biological entities with certain relations between them. Here, while an uncertain relation or the non-existence of a relation might be of some interest for an end-user as well, such information must not be confused with real textual evidence (reliable information). A general conclusion is that for text mining, extracted information that is within the scope of some negative / speculative (hedge or soft negation) keyword should either be discarded or presented separately from factual information. Even though many successful text processing systems (Friedman et al., 1994, Chapman et al. 2001, Elkin et al. 2005) handle the abovementioned phenomena, most of them exploit handcrafted rule-based negation/uncertainty detection modules. To the best of our knowledge, there are no publicly available standard corpora of reasonable size that are usable for evaluating the automatic detection and scope resolution of these language phenomena. The availability of such a resource would undoubtedly facilitate the development of corpus-based statistical systems for negation/hedge detection and resolution. Our study seeks to fill this gap by presenting the BioScope corpus, which consists of medical</context>
</contexts>
<marker>Chapman, Bridewell, Hanbury, Cooper, Buchanan, 2001</marker>
<rawString>Wendy W. Chapman, Will Bridewell, Paul Hanbury, Gregory F. Cooper and Bruce G. Buchanan. 2001. A Simple Algorithm for Identifying Negated Findings and Diseases in Discharge Summaries. Journal of Biomedical Informatics, 34(5):301–310.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Collier</author>
<author>H S Park</author>
<author>N Ogata</author>
<author>Y Tateishi</author>
<author>C Nobata</author>
<author>T Ohta</author>
<author>T Sekimizu</author>
<author>H Imai</author>
<author>K Ibushi</author>
<author>J Tsujii</author>
</authors>
<title>The GENIA project: corpus-based knowledge acquisition and information extraction from genome research papers.</title>
<date>1999</date>
<booktitle>Proceedings of EACL-99.</booktitle>
<contexts>
<context position="23639" citStr="Collier et al., 1999" startWordPosition="3765" endWordPosition="3768"> display different properties in the use of speculative or negated phrases. Take, for instance, the Conclusions section of scientific papers that tends to contain significantly more uncertain or negative findings than the description of Experimental settings and methods. Scientific abstracts are the main targets for various Text Mining applications like proteinprotein interaction mining due to their public accessibility (e.g. through PubMed). We therefore decided to include quite a lot of texts from the abstracts of scientific papers. This is why we included the abstracts of the Genia corpus (Collier et al., 1999). This decision was straightforward for two reasons. First, the Genia corpus contains syntax tree annotation, which allows a comparison between scope annotation and syntactic structure. Being syntactic in nature, scopes should align with the bracket structure of syntax trees, while scope resolution algorithms that exploit treebank data can be used as a theoretical upper bound for the evaluation of parsers for resolving negative/hedge scopes. The other reason was that scope annotation can mutually benefit from the rich annotations of the Genia corpus, such as term annotation (evaluation) and ev</context>
</contexts>
<marker>Collier, Park, Ogata, Tateishi, Nobata, Ohta, Sekimizu, Imai, Ibushi, Tsujii, 1999</marker>
<rawString>N. Collier, H. S. Park, N. Ogata, Y. Tateishi, C. Nobata, T. Ohta, T. Sekimizu, H. Imai, K. Ibushi, and J. Tsujii. 1999. The GENIA project: corpus-based knowledge acquisition and information extraction from genome research papers. Proceedings of EACL-99.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter L Elkin</author>
<author>Steven H Brown</author>
<author>Brent A Bauer</author>
<author>Casey S Husser</author>
<author>William Carruth</author>
<author>Larry R Bergstrom</author>
<author>Dietlind L Wahner-Roedler</author>
</authors>
<title>A controlled trial of automated classification of negation from clinical notes.</title>
<date>2005</date>
<journal>BMC Medical Informatics and Decision Making</journal>
<volume>5</volume>
<pages>10--1186</pages>
<contexts>
<context position="2543" citStr="Elkin et al. 2005" startWordPosition="381" endWordPosition="384">or biological entities with certain relations between them. Here, while an uncertain relation or the non-existence of a relation might be of some interest for an end-user as well, such information must not be confused with real textual evidence (reliable information). A general conclusion is that for text mining, extracted information that is within the scope of some negative / speculative (hedge or soft negation) keyword should either be discarded or presented separately from factual information. Even though many successful text processing systems (Friedman et al., 1994, Chapman et al. 2001, Elkin et al. 2005) handle the abovementioned phenomena, most of them exploit handcrafted rule-based negation/uncertainty detection modules. To the best of our knowledge, there are no publicly available standard corpora of reasonable size that are usable for evaluating the automatic detection and scope resolution of these language phenomena. The availability of such a resource would undoubtedly facilitate the development of corpus-based statistical systems for negation/hedge detection and resolution. Our study seeks to fill this gap by presenting the BioScope corpus, which consists of medical and biological text</context>
<context position="5290" citStr="Elkin et al. (2005)" startWordPosition="785" endWordPosition="788">ey are located in parse trees. Their hybrid approach is able to identify negated concepts in radiology reports even when they are located at some distance from the negative term. The Medical Language Extraction and Encoding (MedLEE) system was developed as a general natural language processor in order to encode clinical documents in a structured form (Friedman et al., 1994). Negated concepts and certainty modifiers are also encoded within the system, thus it enables them to make a distinction between negated/uncertain concepts and factual information which is crucial in information retrieval. Elkin et al. (2005) use a list of negation words and a list of negation scope-ending words in order to identify negated statements and their scope. Although a fair amount of literature on uncertainty (or hedging) in scientific texts has been produced since the 1990s (e.g. Hyland, 1994), speculative language from a Natural Language Processing perspective has only been studied in the past few years. Previous studies (Light et al., 2004) showed that the detection of hedging can be solved effectively by looking for specific keywords which imply speculative content. Another possibility is to treat the problem as a cl</context>
</contexts>
<marker>Elkin, Brown, Bauer, Husser, Carruth, Bergstrom, Wahner-Roedler, 2005</marker>
<rawString>Peter L. Elkin, Steven H. Brown, Brent A. Bauer, Casey S. Husser, William Carruth, Larry R. Bergstrom and Dietlind L. Wahner-Roedler. 2005. A controlled trial of automated classification of negation from clinical notes. BMC Medical Informatics and Decision Making 5:13 doi:10.1186/1472-6947-5-13.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Friedman</author>
<author>P O Alderson</author>
<author>J H Austin</author>
<author>J J Cimino</author>
<author>S B Johnson</author>
</authors>
<title>A general natural-language text processor for clinical radiology.</title>
<date>1994</date>
<journal>Journal of the American Medical Informatics Association,</journal>
<volume>1</volume>
<issue>2</issue>
<contexts>
<context position="2502" citStr="Friedman et al., 1994" startWordPosition="373" endWordPosition="376">on, where the aim is to mine text evidence for biological entities with certain relations between them. Here, while an uncertain relation or the non-existence of a relation might be of some interest for an end-user as well, such information must not be confused with real textual evidence (reliable information). A general conclusion is that for text mining, extracted information that is within the scope of some negative / speculative (hedge or soft negation) keyword should either be discarded or presented separately from factual information. Even though many successful text processing systems (Friedman et al., 1994, Chapman et al. 2001, Elkin et al. 2005) handle the abovementioned phenomena, most of them exploit handcrafted rule-based negation/uncertainty detection modules. To the best of our knowledge, there are no publicly available standard corpora of reasonable size that are usable for evaluating the automatic detection and scope resolution of these language phenomena. The availability of such a resource would undoubtedly facilitate the development of corpus-based statistical systems for negation/hedge detection and resolution. Our study seeks to fill this gap by presenting the BioScope corpus, whic</context>
<context position="5047" citStr="Friedman et al., 1994" startWordPosition="750" endWordPosition="753">ar the negation markers. Huang and Lowe (2007) implemented a hybrid approach to automated negation detection. They combined regular expression matching with grammatical parsing: negations are classified on the basis of syntactic categories and they are located in parse trees. Their hybrid approach is able to identify negated concepts in radiology reports even when they are located at some distance from the negative term. The Medical Language Extraction and Encoding (MedLEE) system was developed as a general natural language processor in order to encode clinical documents in a structured form (Friedman et al., 1994). Negated concepts and certainty modifiers are also encoded within the system, thus it enables them to make a distinction between negated/uncertain concepts and factual information which is crucial in information retrieval. Elkin et al. (2005) use a list of negation words and a list of negation scope-ending words in order to identify negated statements and their scope. Although a fair amount of literature on uncertainty (or hedging) in scientific texts has been produced since the 1990s (e.g. Hyland, 1994), speculative language from a Natural Language Processing perspective has only been studie</context>
</contexts>
<marker>Friedman, Alderson, Austin, Cimino, Johnson, 1994</marker>
<rawString>C. Friedman, P.O. Alderson, J.H. Austin, J.J. Cimino, and S.B. Johnson. 1994. A general natural-language text processor for clinical radiology. Journal of the American Medical Informatics Association, 1(2):161–174.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yang Huang</author>
<author>Henry J Lowe</author>
</authors>
<title>A Novel Hybrid Approach to Automated Negation Detection in Clinical Radiology Reports.</title>
<date>2007</date>
<journal>Journal of the American Medical Informatics Association,</journal>
<volume>14</volume>
<issue>3</issue>
<contexts>
<context position="4471" citStr="Huang and Lowe (2007)" startWordPosition="664" endWordPosition="667">ng within the negative scope. With this process, a large part of negatives can be identified in discharge summaries. Mutalik et al. (2001) earlier developed Negfinder in order to recognise negated patterns in medical texts. Their lexer uses regular expressions to identify words indicating negation and then it passes them as special tokens to the parser, which makes use of the single-token look-ahead strategy. Thus, without appealing to the syntactic structure of the sentence, Negfinder can reliably identify negated concepts in medical narrative when they are located near the negation markers. Huang and Lowe (2007) implemented a hybrid approach to automated negation detection. They combined regular expression matching with grammatical parsing: negations are classified on the basis of syntactic categories and they are located in parse trees. Their hybrid approach is able to identify negated concepts in radiology reports even when they are located at some distance from the negative term. The Medical Language Extraction and Encoding (MedLEE) system was developed as a general natural language processor in order to encode clinical documents in a structured form (Friedman et al., 1994). Negated concepts and c</context>
</contexts>
<marker>Huang, Lowe, 2007</marker>
<rawString>Yang Huang and Henry J. Lowe. 2007. A Novel Hybrid Approach to Automated Negation Detection in Clinical Radiology Reports. Journal of the American Medical Informatics Association, 14(3):304–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ken Hyland</author>
</authors>
<title>Hedging in academic writing and EAP textbooks. English for Specific Purposes,</title>
<date>1994</date>
<contexts>
<context position="5557" citStr="Hyland, 1994" startWordPosition="831" endWordPosition="832">l language processor in order to encode clinical documents in a structured form (Friedman et al., 1994). Negated concepts and certainty modifiers are also encoded within the system, thus it enables them to make a distinction between negated/uncertain concepts and factual information which is crucial in information retrieval. Elkin et al. (2005) use a list of negation words and a list of negation scope-ending words in order to identify negated statements and their scope. Although a fair amount of literature on uncertainty (or hedging) in scientific texts has been produced since the 1990s (e.g. Hyland, 1994), speculative language from a Natural Language Processing perspective has only been studied in the past few years. Previous studies (Light et al., 2004) showed that the detection of hedging can be solved effectively by looking for specific keywords which imply speculative content. Another possibility is to treat the problem as a classification task and train a statistical model to discriminate speculative and non-speculative assertions. This approach requires the availability of labeled instances to train the models on. Medlock and Briscoe (2007) proposed a weakly supervised setting for hedge </context>
</contexts>
<marker>Hyland, 1994</marker>
<rawString>Ken Hyland. 1994. Hedging in academic writing and EAP textbooks. English for Specific Purposes, 13(3):239–256.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jin-Dong Kim</author>
<author>Tomoko Ohta</author>
<author>Jun&apos;ichi Tsujii</author>
</authors>
<title>Corpus annotation for mining biomedical events from literature.</title>
<date>2008</date>
<journal>BMC Bioinformatics</journal>
<pages>9--10</pages>
<contexts>
<context position="7364" citStr="Kim et al., 2008" startWordPosition="1113" endWordPosition="1116">n size. Our corpus is the first one with an annotation of negative/speculative keywords and their scope. The authors are only aware of the following related corpora: • The Hedge classification corpus (Medlock and Briscoe, 2007), which has been annotated for hedge cues (at the sentence level) and consists of five full biological research papers (1537 sentences). No scope annotation is given in the original corpus. We included this publicly available corpus in ours, enriching the data with annotation for negation cues and linguistic scope for both hedging and negation. • The Genia Event corpus (Kim et al., 2008), which annotates biological events with negation and three levels of uncertainty (1000 abstracts). • The BioInfer corpus (Pyysalo et al., 2007), where biological relations are annotated for negation (1100 sentences in size). In the two latter corpora biological terms (relations and events) have been annotated for both negation and hedging, but linguistic cues (i.e. which keyword modifies the semantics of the statement) have not been annotated. We annotated keywords and their linguistic scope, which is very useful for machine learning or rule-based negation and hedge detection systems. 39 2 An</context>
</contexts>
<marker>Kim, Ohta, Tsujii, 2008</marker>
<rawString>Jin-Dong Kim, Tomoko Ohta, and Jun&apos;ichi Tsujii. 2008. Corpus annotation for mining biomedical events from literature. BMC Bioinformatics 2008, 9:10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Light</author>
<author>Xin Ting Qui</author>
<author>Padmini Srinivasan</author>
</authors>
<title>The language of bioscience: Facts, speculations, and statements in between.</title>
<date>2004</date>
<journal>Association for Computational Linguistics,</journal>
<booktitle>In Proceedings of BioLink 2004 Workshop on Linking Biological Literature, Ontologies and Databases: Tools for Users.</booktitle>
<pages>17--24</pages>
<location>Boston, Massachusetts,</location>
<contexts>
<context position="5709" citStr="Light et al., 2004" startWordPosition="852" endWordPosition="855">are also encoded within the system, thus it enables them to make a distinction between negated/uncertain concepts and factual information which is crucial in information retrieval. Elkin et al. (2005) use a list of negation words and a list of negation scope-ending words in order to identify negated statements and their scope. Although a fair amount of literature on uncertainty (or hedging) in scientific texts has been produced since the 1990s (e.g. Hyland, 1994), speculative language from a Natural Language Processing perspective has only been studied in the past few years. Previous studies (Light et al., 2004) showed that the detection of hedging can be solved effectively by looking for specific keywords which imply speculative content. Another possibility is to treat the problem as a classification task and train a statistical model to discriminate speculative and non-speculative assertions. This approach requires the availability of labeled instances to train the models on. Medlock and Briscoe (2007) proposed a weakly supervised setting for hedge classification in scientific texts where the aim is to minimise human supervision needed to obtain an adequate amount of training data. Their system foc</context>
</contexts>
<marker>Light, Qui, Srinivasan, 2004</marker>
<rawString>Marc Light, Xin Ting Qui, and Padmini Srinivasan. 2004. The language of bioscience: Facts, speculations, and statements in between. In Proceedings of BioLink 2004 Workshop on Linking Biological Literature, Ontologies and Databases: Tools for Users. Boston, Massachusetts, Association for Computational Linguistics, 17–24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ben Medlock</author>
<author>Ted Briscoe</author>
</authors>
<title>Weakly supervised learning for hedge classification in scientific literature.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics. Prague, Association for Computational Linguistics, 992–</booktitle>
<pages>999</pages>
<contexts>
<context position="6109" citStr="Medlock and Briscoe (2007)" startWordPosition="910" endWordPosition="913"> in scientific texts has been produced since the 1990s (e.g. Hyland, 1994), speculative language from a Natural Language Processing perspective has only been studied in the past few years. Previous studies (Light et al., 2004) showed that the detection of hedging can be solved effectively by looking for specific keywords which imply speculative content. Another possibility is to treat the problem as a classification task and train a statistical model to discriminate speculative and non-speculative assertions. This approach requires the availability of labeled instances to train the models on. Medlock and Briscoe (2007) proposed a weakly supervised setting for hedge classification in scientific texts where the aim is to minimise human supervision needed to obtain an adequate amount of training data. Their system focuses on locating hedge cues in text and thus they do not determine the scopes (in other words in a text they define the scope to be a whole sentence). 1.2 Related resources Even though the problems of negation (mainly in the medical domain) and hedging (mainly in the scientific domain) have received much interest in the past few years, open access annotated resources for training, testing and comp</context>
<context position="22720" citStr="Medlock and Briscoe (2007)" startWordPosition="3627" endWordPosition="3630">to facilitate research on negation/hedge detection in the clinical domain. The radiology report corpus that was used for the clinical coding challenge (Pestian et al., 2007) organised by the Computational Medicine Center in Cincinatti, Ohio in 2007 was annotated for negations and uncertainty along with the scopes of each phenomenon. This part contains 1954 documents, each having a clinical history and an impression part, the latter being denser in negated and speculative parts. Another part of the corpus consists of full scientific articles. 5 articles from FlyBase (the same data were used by Medlock and Briscoe (2007) for evaluating sentence-level hedge classifiers) and 4 articles from the open access BMC Bioinformatics website were downloaded and annotated for negations, uncertainty and their scopes. Full papers are particularly useful for evaluating negation/hedge classifiers as different parts of an article display different properties in the use of speculative or negated phrases. Take, for instance, the Conclusions section of scientific papers that tends to contain significantly more uncertain or negative findings than the description of Experimental settings and methods. Scientific abstracts are the m</context>
</contexts>
<marker>Medlock, Briscoe, 2007</marker>
<rawString>Ben Medlock and Ted Briscoe. 2007. Weakly supervised learning for hedge classification in scientific literature. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics. Prague, Association for Computational Linguistics, 992– 999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pradeep G Mutalik</author>
<author>Aniruddha Deshpande</author>
<author>Prakash M Nadkarni</author>
</authors>
<title>Use of General-purpose Negation Detection to Augment Concept Indexing of Medical Documents: A Quantitative Study Using the UMLS.</title>
<date>2001</date>
<journal>Journal of the American Medical Informatics Association,</journal>
<volume>8</volume>
<issue>6</issue>
<contexts>
<context position="3988" citStr="Mutalik et al. (2001)" startWordPosition="592" endWordPosition="595">bed in this paper has been made publicly available for research purposes and it is freely downloadable1. 1 www.inf.u-szeged.hu/rgai/bioscope 38 BioNLP 2008: Current Trends in Biomedical Natural Language Processing, pages 38–45, Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics 1.1 Related work Chapman et al. (2001) created a simple regular expression algorithm called NegEx that can detect phrases indicating negation and identify medical terms falling within the negative scope. With this process, a large part of negatives can be identified in discharge summaries. Mutalik et al. (2001) earlier developed Negfinder in order to recognise negated patterns in medical texts. Their lexer uses regular expressions to identify words indicating negation and then it passes them as special tokens to the parser, which makes use of the single-token look-ahead strategy. Thus, without appealing to the syntactic structure of the sentence, Negfinder can reliably identify negated concepts in medical narrative when they are located near the negation markers. Huang and Lowe (2007) implemented a hybrid approach to automated negation detection. They combined regular expression matching with gramma</context>
<context position="12044" citStr="Mutalik et al., 2001" startWordPosition="1863" endWordPosition="1866">kely&gt; reflects airways disease). Complex keywords are not to be confused with the sequence of two or more keywords because they can express hedge or negation on their own, that is, without the other keyword as well. In this case, each keyword is annotated separately, as is shown in the following example: Slightly increased perihilar lung markings (&lt;may&gt; (&lt;indicate&gt; early reactive airways disease)). 2.3 Scope marking When marking the scopes of negative and speculative keywords, we extended the scope to the biggest syntactic unit possible (in contrast to other corpora like the one described in (Mutalik et al., 2001)). Thus, annotated scopes always have the 40 maximal length – as opposed to the strategy for annotating keywords, where we marked the minimal unit possible. Our decision was supported by two facts. First, since scopes must contain their keywords, it seemed better to include every element in between the keyword and the target word in order to avoid “empty” scopes, that is, scopes without a keyword. In the next example, however is not affected by the hedge cue but it should be included within the scope, otherwise the keyword and its target phrase would be separated: (Atelectasis in the right mid</context>
<context position="17954" citStr="Mutalik et al., 2001" startWordPosition="2836" endWordPosition="2839">gative for – is not part of the sentence. In such cases, the keyword is marked and the scope contains just the keyword: ([Negative]) chest radiograph. In the case of elliptic sentences, the same strategy is followed: the keyword is marked and its scope includes only the keyword since the verbal phrase, that is, the scope of not, is not repeated in the sentence. This decrease was seen in patients who responded to the therapy as well as in those who did ([not]). Generally, punctuation marks or conjunctions function as scope boundary markers in the corpus, in contrast to the corpus described in (Mutalik et al., 2001) where certain lexical items are treated as negation-termination tokens. Since in our corpus the scope of negation or speculation is mostly extended to the entire clause in the case of verbal elements, it is clear that markers of a sentence or clause boundary determine the end of their scope. 2.4 Special cases It seems unequivocal that whenever there is a speculative or negative cue in the sentence, the sentence expresses hedge or negation. However, we have come across several cases where the presence of a speculative/negative keyword does not imply a hedge/negation. That is, some of the cues </context>
</contexts>
<marker>Mutalik, Deshpande, Nadkarni, 2001</marker>
<rawString>Pradeep G. Mutalik, Aniruddha Deshpande, and Prakash M. Nadkarni. 2001. Use of General-purpose Negation Detection to Augment Concept Indexing of Medical Documents: A Quantitative Study Using the UMLS. Journal of the American Medical Informatics Association, 8(6):598–609.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John P Pestian</author>
<author>Chris Brew</author>
<author>Pawel Matykiewicz</author>
<author>DJ Hovermale</author>
<author>Neil Johnson</author>
<author>K Bretonnel Cohen</author>
<author>Wlodzislaw Duch</author>
</authors>
<title>A shared task involving multi-label classification of clinical free text.</title>
<date>2007</date>
<booktitle>In Biological, translational, and clinical language processing. Prague, Association for Computational Linguistics,</booktitle>
<pages>97--104</pages>
<contexts>
<context position="22267" citStr="Pestian et al., 2007" startWordPosition="3552" endWordPosition="3555">l papers and biological paper abstracts (texts from Genia). Table 1 summarises the chief characteristics of the three subcorpora. The 3rd and 5th rows of the table show the ratio of sentences which contain negated or uncertain statements. The 4rd and 6th rows show the number of negation and hedge cue occurrences in the given corpus. A major part of the corpus consists of clinical free-texts. We chose to add medical texts to the corpus in order to facilitate research on negation/hedge detection in the clinical domain. The radiology report corpus that was used for the clinical coding challenge (Pestian et al., 2007) organised by the Computational Medicine Center in Cincinatti, Ohio in 2007 was annotated for negations and uncertainty along with the scopes of each phenomenon. This part contains 1954 documents, each having a clinical history and an impression part, the latter being denser in negated and speculative parts. Another part of the corpus consists of full scientific articles. 5 articles from FlyBase (the same data were used by Medlock and Briscoe (2007) for evaluating sentence-level hedge classifiers) and 4 articles from the open access BMC Bioinformatics website were downloaded and annotated for </context>
</contexts>
<marker>Pestian, Brew, Matykiewicz, Hovermale, Johnson, Cohen, Duch, 2007</marker>
<rawString>John P. Pestian, Chris Brew, Pawel Matykiewicz, DJ Hovermale, Neil Johnson, K. Bretonnel Cohen, and Wlodzislaw Duch. 2007. A shared task involving multi-label classification of clinical free text. In Biological, translational, and clinical language processing. Prague, Association for Computational Linguistics, 97–104.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sampo Pyysalo</author>
<author>Filip Ginter</author>
<author>Juho Heimonen</author>
<author>Jari Björne</author>
<author>Jorma Boberg</author>
<author>Jouni Järvinen</author>
<author>Tapio Salakoski</author>
</authors>
<title>BioInfer: a corpus for information extraction in the biomedical domain.</title>
<date>2007</date>
<journal>BMC Bioinformatics</journal>
<volume>8</volume>
<pages>10--1186</pages>
<contexts>
<context position="7508" citStr="Pyysalo et al., 2007" startWordPosition="1134" endWordPosition="1137">ollowing related corpora: • The Hedge classification corpus (Medlock and Briscoe, 2007), which has been annotated for hedge cues (at the sentence level) and consists of five full biological research papers (1537 sentences). No scope annotation is given in the original corpus. We included this publicly available corpus in ours, enriching the data with annotation for negation cues and linguistic scope for both hedging and negation. • The Genia Event corpus (Kim et al., 2008), which annotates biological events with negation and three levels of uncertainty (1000 abstracts). • The BioInfer corpus (Pyysalo et al., 2007), where biological relations are annotated for negation (1100 sentences in size). In the two latter corpora biological terms (relations and events) have been annotated for both negation and hedging, but linguistic cues (i.e. which keyword modifies the semantics of the statement) have not been annotated. We annotated keywords and their linguistic scope, which is very useful for machine learning or rule-based negation and hedge detection systems. 39 2 Annotation guidelines This section describes the basic principles on the annotation of speculative and negative scopes in biomedical texts. Some b</context>
</contexts>
<marker>Pyysalo, Ginter, Heimonen, Björne, Boberg, Järvinen, Salakoski, 2007</marker>
<rawString>Sampo Pyysalo, Filip Ginter, Juho Heimonen, Jari Björne, Jorma Boberg, Jouni Järvinen, and Tapio Salakoski. 2007. BioInfer: a corpus for information extraction in the biomedical domain. BMC Bioinformatics 2007, 8:50 doi:10.1186/1471-2105-8-50.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>