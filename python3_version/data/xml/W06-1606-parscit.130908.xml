<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002450">
<title confidence="0.995312">
SPMT: Statistical Machine Translation with
Syntactified Target Language Phrases
</title>
<author confidence="0.998804">
Daniel Marcu, Wei Wang, Abdessamad Echihabi, and Kevin Knight
</author>
<affiliation confidence="0.838267">
Language Weaver Inc.
4640 Admiralty Way, Suite 1210
</affiliation>
<address confidence="0.739518">
Marina del Rey, CA 90292
</address>
<email confidence="0.999374">
{dmarcu,wwang,aechihabi,kknight}@languageweaver.com
</email>
<sectionHeader confidence="0.997397" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999968">
We introduce SPMT, a new class of sta-
tistical Translation Models that use Syn-
tactified target language Phrases. The
SPMT models outperform a state of the art
phrase-based baseline model by 2.64 Bleu
points on the NIST 2003 Chinese-English
test corpus and 0.28 points on a human-
based quality metric that ranks translations
on a scale from 1 to 5.
</bodyText>
<sectionHeader confidence="0.999393" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999907918918919">
During the last four years, various implemen-
tations and extentions to phrase-based statistical
models (Marcu and Wong, 2002; Koehn et al.,
2003; Och and Ney, 2004) have led to signif-
icant increases in machine translation accuracy.
Although phrase-based models yield high-quality
translations for language pairs that exhibit simi-
lar word order, they fail to produce grammatical
outputs for language pairs that are syntactically
divergent. Recent models that exploit syntactic
information of the source language (Quirk et al.,
2005) have been shown to produce better outputs
than phrase-based systems when evaluated on rel-
atively small scale, domain specific corpora. And
syntax-inspired formal models (Chiang, 2005), in
spite of being trained on significantly less data,
have shown promising results when compared on
the same test sets with mature phrase-based sys-
tems. To our knowledge though, no previous re-
search has demonstrated that a syntax-based sta-
tistical translation system could produce better re-
sults than a phrase-based system on a large-scale,
well-established, open domain translation task. In
this paper we present such a system.
Our translation models rely upon and naturally
exploit submodels (feature functions) that have
been initially developed in phrase-based systems
for choosing target translations of source language
phrases, and use new, syntax-based translation and
target language submodels for assembling target
phrases into well-formed, grammatical outputs.
After we introduce our models intuitively, we
discuss their formal underpinning and parameter
training in Section 2. In Section 3, we present our
decoder and, in Section 4, we evaluate our models
empirically. In Section 5, we conclude with a brief
discussion.
</bodyText>
<sectionHeader confidence="0.997502" genericHeader="method">
2 SPMT: statistical Machine Translation
with Syntactified Phrases
</sectionHeader>
<subsectionHeader confidence="0.996301">
2.1 An intuitive introduction to SPMT
</subsectionHeader>
<bodyText confidence="0.9814775">
After being exposed to 100M+ words of parallel
Chinese-English texts, current phrase-based statis-
tical machine translation learners induce reason-
ably reliable phrase-based probabilistic dictionar-
ies. For example, our baseline statistical phrase-
based system learns that, with high probabilities,
the Chinese phrases “ASTRO- -NAUTS”, “FRANCE
AND RUSSIA” and “COMINGFROM” can be trans-
lated into English as “astronauts”/“cosmonauts”,
“france and russia”/“france and russian” and
“coming from”/“from”, respectively. 1 Unfortu-
nately, when given as input Chinese sentence 1,
our phrase-based system produces the output
shown in 2 and not the translation in 3, which
correctly orders the phrasal translations into a
grammatical sequence. We believe this hap-
pens because the distortion/reordering models that
are used by state-of-the-art phrase-based systems,
which exploit phrase movement and ngram target
&apos;To increase readability, in this paper, we represent Chi-
nese words using fully capitalized English glosses and En-
glish words using lowercased letters.
</bodyText>
<page confidence="0.990621">
44
</page>
<note confidence="0.8615355">
Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP 2006), pages 44–52,
Sydney, July 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.94250525">
language models (Och and Ney, 2004; Tillman,
2004), are too weak to help a phrase-based de-
coder reorder the target phrases into grammatical
outputs.
</bodyText>
<note confidence="0.922979">
THESE 7PEOPLE INCLUDE COMINGFROM
FRANCE AND RUSSIA p-DE ASTRO- -NAUTS .
</note>
<figureCaption confidence="0.809834">
the 7 people including those from france
and the russian cosmonauts .
</figureCaption>
<bodyText confidence="0.999962407407407">
One method for increasing the ability of a de-
coder to reorder target language phrases is that
of decorating them with syntactic constituent in-
formation. For example, we may make ex-
plicit that the Chinese phrase “ASTRO- -NAUTS”
may be translated into English as a noun phrase,
NP(NNS(astronauts)); that the phrase FRANCE AND
RUSSIA may be translated into a complex noun-
phrase, NP(NP(NNP(france)) CC(and) NP(NNP(russia)));
that the phrase COMINGFROM may be translated
into a partially realized verb phrase that is look-
ing for a noun phrase to its right in order to be
fully realized, VP(VBG(coming) PP(IN(from) NP:x0));
and that the Chinese particle p-DE, when occurring
between a Chinese string that was translated into
a verb phrase to its left and another Chinese string
that was translated into a noun phrase to its right,
VP:x1 p-DE NP:x0, should be translated to noth-
ing, while forcing the reordering of the two con-
stituents, NP(NP:x0, VP:x1). If all these translation
rules (labeled r1 to r4 in Figure 1) were available
to a decoder that derives English parse trees start-
ing from Chinese input strings, this decoder could
produce derivations such as that shown in Fig-
ure 2. Because our approach uses translation rules
with Syntactified target language Phrases (see Fig-
ure 1), we call it SPMT.
</bodyText>
<subsectionHeader confidence="0.997065">
2.2 A formal introduction to SPMT
2.2.1 Theoretical foundations
</subsectionHeader>
<bodyText confidence="0.999943333333333">
We are interested to model a generative process
that explains how English parse trees 7r and their
associated English string yields E, foreign sen-
tences, F, and word-level alignments, A, are pro-
duced. We assume that observed (7r, F, A) triplets
are generated by a stochastic process similar to
</bodyText>
<figure confidence="0.826608">
(3)
</figure>
<figureCaption confidence="0.5098125">
from france and russia .
these 7 people include astronauts coming
</figureCaption>
<equation confidence="0.995456777777778">
r1 :NP(NNS(astronauts)) → ASTRO- -NAUTS
r2 :NP(NP(NNP(france)) CC(and) NP(NNP(russia))) →
FRANCE AND RUSSIA
r3 :VP(VBG(coming) PP(IN(from) NP:x0)) →
COMINGFROM x0
r4 :NP(NP:x0, VP:x1) → x1 p-DE x0
r5 :NNP(france) → FRANCE
rs :NP(NP(NNP(france)) CC(and) NP:x0) → FRANCE AND x0
r7 :NNS(astronauts) → ASTRO- -NAUTS
rs :NNP(russia) → RUSSIA
rg :NP(NNS:x0) → x0
r10 :PP(IN:x0 NP:x1) → x0 x1
r11 :NP(NP:x0 CC:x1 NP:x2) → x0 x1 x2
r12 :NP(NNP:x0) → x0
r13 :CC(and) → AND
r14 :NP(NP:x0 CC(and) NP:x1) → x0 AND x1
r15 :NP(NP:x0 VP(VBG(coming) PP(IN(from) NP:x1))) →
x1 COMINGFROM x0
</equation>
<figureCaption confidence="0.998946">
Figure 1: Examples of xRS rules.
</figureCaption>
<bodyText confidence="0.993663107142857">
that used in Data Oriented Parsing models (Bon-
nema, 2002). For example, if we assume that the
generative process has already produced the top
NP node in Figure 2, then the corresponding par-
tial English parse tree, foreign/source string, and
word-level alignment could be generated by the
rule derivation r4(r1, r3(r2)), where each rule is
assumed to have some probability.
The extended tree to string transducers intro-
duced by Knight and Graehl (2005) provide a nat-
ural framework for expressing the tree to string
transformations specific to our SPMT models.
The transformation rules we plan to exploit are
equivalent to one-state xRS top-down transduc-
ers with look ahead, which map subtree patterns
to strings. For example, rule r3 in Figure 1 can
be applied only when one is in a state that has a
VP as its syntactic constituent and the tree pat-
tern VP(VBG(coming) PP(IN(from) NP)) immediately
underneath. The rule application outputs the string
“COMINGFROM” as the transducer moves to the
state co-indexed by x0; the outputs produced from
the new state will be concatenated to the right of
the string “COMINGFROM”.
Since there are multiple derivations that could
lead to the same outcome, the probability of a
tuple (7r, F, A) is obtained by summing over all
derivations Oi E O that are consistent with the tu-
</bodyText>
<page confidence="0.99949">
45
</page>
<figureCaption confidence="0.953934333333333">
Figure 2: English parse tree derivation of the Chi-
nese string COMINGFROM FRANCE AND RUSSIA p-
DE ASTRO- -NAUTS.
</figureCaption>
<bodyText confidence="0.86922725">
ple, c(0) _ (7r, F, A). The probability of each
derivation BZ is given by the product of the proba-
bilities of all the rules p(rj) in the derivation (see
equation 4).
</bodyText>
<equation confidence="0.995709">
�Pr(7r, F, A) _
BiEO,c(0)=(7r,F,A) rjEBi
</equation>
<bodyText confidence="0.999626636363636">
In order to acquire the rules specific to our
model and to induce their probabilities, we parse
the English side of our corpus with an in-house
implementation (Soricut, 2005) of Collins pars-
ing models (Collins, 2003) and we word-align the
parallel corpus with the Giza++2 implementation
of the IBM models (Brown et al., 1993). We
use the automatically derived (English-parse-tree,
English-sentence, Foreign-sentence, Word-level-
alignment) tuples in order to induce xRS rules for
several models.
</bodyText>
<subsubsectionHeader confidence="0.851142">
2.2.2 SPMT Model 1
</subsubsectionHeader>
<bodyText confidence="0.998805833333333">
In our simplest model, we assume that each
tuple (7r, F, A) in our automatically annotated
corpus could be produced by applying a com-
bination of minimally syntactified, lexicalized,
phrase-based compatible xRS rules, and mini-
mal/necessary, non-lexicalized xRS rules. We call
a rule non-lexicalized whenever it does not have
any directly aligned source-to-target words. Rules
r9–r12 in Figure 1 are examples of non-lexicalized
rules.
Minimally syntactified, lexicalized, phrase-
based-compatible xRS rules are extracted via a
</bodyText>
<footnote confidence="0.504061">
2http://www.fjoch.com/GIZA++.html
</footnote>
<bodyText confidence="0.9999552">
simple algorithm that finds for each foreign phrase
FZj , the smallest xRS rule that is consistent with
the foreign phrase FZj , the English syntactic tree
7r, and the alignment A. The algorithm finds for
each foreign/source phrase span its projected span
on the English side and then traverses the En-
glish parse tree bottom up until it finds a node
that subsumes the projected span. If this node has
children that fall outside the projected span, then
those children give rise to rules that have variables.
For example, if the tuple shown in Figure 2 is in
our training corpus, for the foreign/source phrases
FRANCE, FRANCE AND, FRANCE AND RUSSIA, and
ASTRO- -NAUTS, we extract the minimally syntac-
tified, lexicalized phrase-based-compatible xRS
rules r5, r6, r2, and r7 in Figure 1, respectively.
Because, as in phrase-based MT, all our rules have
continuous phrases on both the source and target
language sides, we call these phrase-based com-
patible xRS rules.
Since these lexicalized rules are not sufficient to
explain an entire (7r, F, A) tuple, we also extract
the required minimal/necessary, non-lexicalized
xRS rules. The minimal non-lexicalized rules that
are licensed by the tuple in Figure 2 are labeled
r4, r9, r10, r11 and r12 in Figure 1. To obtain the
non-lexicalized xRS rules, we compute the set of
all minimal rules (lexicalized and non-lexicalized)
by applying the algorithm proposed by Galley et
al. (2006) and then remove the lexicalized rules.
We remove the Galley et al.’s lexicalized rules
because they are either already accounted for by
the minimally syntactified, lexicalized, phrase-
based-compatible xRS rules or they subsume non-
continuous source-target phrase pairs.
It is worth mentioning that, in our framework,
a rule is defined to be “minimal” with respect to a
foreign/source language phrase, i.e., it is the min-
imal xRS rule that yields that source phrase. In
contrast, in the work of Galley et al. (2004; 2006),
a rule is defined to be minimal when it is necessary
in order to explain a (7r, F, A) tuple.
Under SPMT model 1, the tree in Figure 2 can
be produced, for example, by the following deriva-
tion: r4(r9(r7),r3(r6(r12(rs)))).
</bodyText>
<subsubsectionHeader confidence="0.864567">
2.2.3 SPMT Model 1 Composed
</subsubsectionHeader>
<bodyText confidence="0.9999434">
We hypothesize that composed rules, i.e., rules
that can be decomposed via the application of a
sequence of Model 1 rules may improve the per-
formance of an SPMT system. For example, al-
though the minimal Model 1 rules r11 and r13 are
</bodyText>
<equation confidence="0.987312">
p(rj) (4)
</equation>
<page confidence="0.99577">
46
</page>
<figureCaption confidence="0.988914">
Figure 3: Problematic syntactifications of phrasal
translations.
</figureCaption>
<bodyText confidence="0.99977628">
sufficient for building an English NP on top of two
NPs separated by the Chinese conjunction AND,
the composed rule r14 in Figure 1 accomplishes
the same result in only one step. We hope that the
composed rules could play in SPMT the same role
that phrases play in string-based translation mod-
els.
To test our hypothesis, we modify our rule ex-
traction algorithm so that for every foreign phrase
FZ , we extract not only a minimally syntactified,
lexicalized xRS rule, but also one composed rule.
The composed rule is obtained by extracting the
rule licensed by the foreign/source phrase, align-
ment, English parse tree, and the first multi-child
ancestor node of the root of the minimal rule. Our
intuition is that composed rules that involve the ap-
plication of more than two minimal rules are not
reliable. For example, for the tuple in Figure 2,
the composed rule that we extract given the for-
eign phrases AND and COMINGFROM are respec-
tively labeled as rules r14 and r15 in Figure 1.
Under the SPMT composed model 1,
the tree in Figure 2 can be produced,
for example, by the following derivation:
r15(r9(r7), r14(r12(r5), r12(rs))).
</bodyText>
<subsubsectionHeader confidence="0.913447">
2.2.4 SPMT Model 2
</subsubsectionHeader>
<bodyText confidence="0.995097294117647">
In many instances, the tuples (7r, F, A) in our
training corpus exhibit alignment patterns that can
be easily handled within a phrase-based SMT
framework, but that become problematic in the
SPMT models discussed until now.
Consider, for example, the (7r, F, A) tuple frag-
ment in Figure 3. When using a phrase-based
translation model, one can easily extract the
phrase pair (THE MUTUAL; the mutual) and use it
during the phrase-based model estimation phrase
and in decoding. However, within the xRS trans-
ducer framework that we use, it is impossible to
extract an equivalent syntactified phrase transla-
tion rule that subsumes the same phrase pair be-
cause valid xRS translation rules cannot be multi-
headed. When faced with this constraint, one has
several options:
</bodyText>
<listItem confidence="0.99095215">
• One can label such phrase pairs as non-
syntactifiable and ignore them. Unfortu-
nately, this is a lossy choice. On our par-
allel English-Chinese corpus, we have found
that approximately 28% of the foreign/source
phrases are non-syntactifiable by this defini-
tion.
• One can also traverse the parse tree upwards
until one reaches a node that is xRS valid, i.e.,
a node that subsumes the entire English span
induced by a foreign/source phrase and the
corresponding word-level alignment. This
choice is also inappropriate because phrase
pairs that are usually available to phrase-
based translation systems are then expanded
and made available in the SPTM models only
in larger applicability contexts.
• A third option is to create xRS compati-
ble translation rules that overcome this con-
straint.
</listItem>
<bodyText confidence="0.999902666666667">
Our SPMT Model 2 adopts the third option by
rewriting on the fly the English parse tree for each
foreign/source phrase and alignment that lead to
non-syntactifiable phrase pairs. The rewriting pro-
cess adds new rules to those that can be created
under the SPMT model 1 constraints. The process
creates one xRS rule that is headed by a pseudo,
non-syntactic nonterminal symbol that subsumes
the target phrase and corresponding multi-headed
syntactic structure; and one sibling xRS rule that
explains how the non-syntactic nonterminal sym-
bol can be combined with other genuine nonter-
minals in order to obtain genuine parse trees. In
this view, the foreign/source phrase THE MUTUAL
and corresponding alignment in Figure 3 licenses
the rules *NPB* NN(DT(the) JJ(mutual)) --+ THE MU-
TUAL and NPB(*NPB* NN:x0 NN:x1) --+ x0 x1 even
though the foreign word UNDERSTANDING is
aligned to an English word outside the NPB con-
situent. The name of the non-syntactic nontermi-
nal reflects the intuition that the English phrase “the
mutual” corresponds to a partially realized NPB that
needs an NN to its right in order to be fully real-
ized.
</bodyText>
<page confidence="0.996811">
47
</page>
<bodyText confidence="0.999966714285714">
Our hope is that the rules headed by pseudo
nonterminals could make available to an SPMT
system all the rules that are typically available to
a phrase-based system; and that the sibling rules
could provide a sufficiently robust generalization
layer for integrating pseudo, partially realized con-
stituents into the overall decoding process.
</bodyText>
<subsubsectionHeader confidence="0.601111">
2.2.5 SPMT Model 2 Composed
</subsubsectionHeader>
<bodyText confidence="0.998862">
The SPMT composed model 2 uses all rule
types described in the previous models.
</bodyText>
<subsectionHeader confidence="0.996693">
2.3 Estimating rule probabilities
</subsectionHeader>
<bodyText confidence="0.999945714285714">
For each model, we extract all rule instances that
are licensed by a symmetrized Giza-aligned paral-
lel corpus and the constraints we put on the model.
We condition on the root node of each rule and use
the rule counts f(r) and a basic maximum likeli-
hood estimator to assign to each rule type a condi-
tional probability (see equation 5).
</bodyText>
<equation confidence="0.995767">
f(r)
p(r|root(r)) = �) (5)
ErI:root(rI
</equation>
<bodyText confidence="0.995759347826087">
It is unlikely that this joint probability model
can be discriminative enough to distinguish be-
tween good and bad translations. We are not too
concerned though because, in practice, we decode
using a larger set of submodels (feature functions).
Given the way all our lexicalized xRS rules have
been created, one can safely strip out the syntac-
tic information and end up with phrase-to-phrase
translation rules. For example, in string-to-string
world, rule r5 in Figure 1 can be rewritten as “fiance
--+ FRANCE”; and rule r6 can be rewritten as “fiance
and --+ FRANCE AND”. When one analyzes the lex-
icalized xRS rules in this manner, it is easy to as-
sociate with them any of the submodel probability
distributions that have been proven useful in statis-
tical phrase-based MT. The non-lexicalized rules
are assigned probability distributions under these
submodels as well by simply assuming a NULL
phrase for any missing lexicalized source or target
phrase.
In the experiments described in this paper, we
use the following submodels (feature functions):
Syntax-based-like submodels:
</bodyText>
<listItem confidence="0.99803378125">
• proot(rz) is the root normalized conditional
probability of all the rules in a model.
• pcfg(rz) is the CFG-like probability of the
non-lexicalized rules in the model. The lexi-
calized rules have by definition pcfg = 1.
• is lexicalized(rz) is an indicator feature func-
tion that has value 1 for lexicalized rules, and
value 0 otherwise.
• is composed(rz) is an indicator feature func-
tion that has value 1 for composed rules.
• is lowcount(rz) is an indicator feature func-
tion that has value 1 for the rules that occur
less than 3 times in the training corpus.
Phrase-based-like submodels:
• lex pef(rz) is the direct phrase-based con-
ditional probability computed over the for-
eign/source and target phrases subsumed by
a rule.
• lex pfe(rz) is the inverse phrase-based condi-
tional probability computed over the source
and target phrases subsumed by a rule.
• m1(rz) is the IBM model 1 probability com-
puted over the bags of words that occur on
the source and target sides of a rule.
• m1inv(rz) is the IBM model 1 inverse prob-
ability computed over the bags of words that
occur on the source and target sides of a rule.
• lm(e) is the language model probability of
the target translation under an ngram lan-
guage model.
• wp(e) is a word penalty model designed to
favor longer translations.
</listItem>
<bodyText confidence="0.999003866666667">
All these models are combined log-linearly dur-
ing decoding. The weights of the models are
computed automatically using a variant of the
Maximum Bleu training procedure proposed by
Och (2003).
The phrase-based-like submodels have been
proved useful in phrase-based approaches to
SMT (Och and Ney, 2004). The first two syntax-
based submodels implement a “fused” translation
and lexical grounded distortion model (proot) and
a syntax-based distortion model (pcfg). The indi-
cator submodels are used to determine the extent
to which our system prefers lexicalized vs. non-
lexicalized rules; simple vs. composed rules; and
high vs. low count rules.
</bodyText>
<equation confidence="0.809844333333333">
f
)=root(r)
(r
</equation>
<page confidence="0.997208">
48
</page>
<sectionHeader confidence="0.99953" genericHeader="method">
3 Decoding
</sectionHeader>
<subsectionHeader confidence="0.999951">
3.1 Decoding with one SPMT model
</subsectionHeader>
<bodyText confidence="0.999871647058823">
We decode with each of our SPMT models using
a straightforward, bottom-up, CKY-style decoder
that builds English syntactic constituents on the
top of Chinese sentences. The decoder uses a bina-
rized representation of the rules, which is obtained
via a syncronous binarization procedure (Zhang et
al., 2006). The CKY-style decoder computes the
probability of English syntactic constituents in a
bottom up fashion, by log-linearly interpolating all
the submodel scores described in Section 2.3.
The decoder is capable of producing nbest
derivations and nbest lists (Knight and Graehl,
2005), which are used for Maximum Bleu train-
ing (Och, 2003). When decoding the test cor-
pus, the decoder returns the translation that has the
most probable derivation; in other words, the sum
operator in equation 4 is replaced with an argmax.
</bodyText>
<subsectionHeader confidence="0.999913">
3.2 Decoding with multiple SPMT models
</subsectionHeader>
<bodyText confidence="0.999971807692308">
Combining multiple MT outputs to increase per-
formance is, in general, a difficult task (Matusov
et al., 2006) when significantly different engines
compete for producing the best outputs. In our
case, combining multiple MT outputs is much
simpler because the submodel probabilities across
the four models described here are mostly iden-
tifical, with the exception of the root normalized
and CFG-like submodels which are scaled differ-
ently – since Model 2 composed has, for example,
more rules than Model 1, the root normalized and
CFG-like submodels have smaller probabilities for
identical rules in Model 2 composed than in Model
1. We compare these two probabilities across the
submodels and we scale all model probabilities to
be compatible with those of Model 2 composed.
With this scaling procedure into place, we pro-
duce 6,000 non-unique nbest lists for all sentences
in our development corpus, using all SPMT sub-
models. We concatenate the lists and we learn a
new combination of weights that maximizes the
Bleu score of the combined nbest list using the
same development corpus we used for tuning the
individual systems (Och, 2003). We use the new
weights in order to rerank the nbest outputs on the
test corpus.
</bodyText>
<sectionHeader confidence="0.999856" genericHeader="evaluation">
4 Experiments
</sectionHeader>
<subsectionHeader confidence="0.99929">
4.1 Automatic evaluation of the models
</subsectionHeader>
<bodyText confidence="0.9990972">
We evaluate our models on a Chinese to English
machine translation task. We use the same training
corpus, 138.7M words of parallel Chinese-English
data released by LDC, in order to train several
statistical-based MT systems:
</bodyText>
<listItem confidence="0.988639363636364">
• PBMT, a strong state of the art phrase-based
system that implements the alignment tem-
plate model (Och and Ney, 2004); this is the
system ISI has used in the 2004 and 2005
NIST evaluations.
• four SPMT systems (M1, M1C, M2, M2C)
that implement each of the models discussed
in this paper;
• a SPMT system, Comb, that combines the
outputs of all SPMT models using the pro-
cedure described in Section 3.2.
</listItem>
<bodyText confidence="0.999605580645161">
In all systems, we use a rule extraction algo-
rithm that limits the size of the foreign/source
phrases to four words. For all systems, we use
a Kneser-Ney (1995) smoothed trigram language
model trained on 2.3 billion words of English. As
development data for the SPMT systems, we used
the sentences in the 2002 NIST development cor-
pus that are shorter than 20 words; we made this
choice in order to finish all experiments in time for
this submission. The PBMT system used all sen-
tences in the 2002 NIST corpus for development.
As test data, we used the 2003 NIST test set.
Table 1 shows the number of string-to-string or
tree-to-string rules extracted by each system and
the performance on both the subset of sentences in
the test corpus that were shorter than 20 words and
the entire test corpus. The performance is mea-
sured using the Bleu metric (Papineni et al., 2002)
on lowercased, tokenized outputs/references.
The results show that the SPMT models clearly
outperform the phrase-based systems – the 95%
confidence intervals computed via bootstrap re-
sampling in all cases are around 1 Bleu point. The
results also show that the simple system combina-
tion procedure that we have employed is effective
in our setting. The improvement on the develop-
ment corpus transfers to the test setting as well.
A visual inspection of the outputs shows signif-
icant differences between the outputs of the four
models. The models that use composed rules pre-
fer to produce outputs by using mostly lexicalized
</bodyText>
<page confidence="0.998932">
49
</page>
<table confidence="0.9566957">
System # of rules Bleu score Bleu score Bleu score
(in millions) on Dev on Test on Test
(4 refs) (4 refs) (4 refs)
&lt; 20 words &lt; 20 words
PBMT 125.8 34.56 34.83 31.46
SPMT-M1 34.2 37.60 38.18 33.15
SPMT-M1C 75.7 37.30 38.10 32.39
SPMT-M2 70.4 37.77 38.74 33.39
SPMT-M2C 111.1 37.48 38.59 33.16
SPMT-Comb 111.1 39.44 39.56 34.10
</table>
<tableCaption confidence="0.9998">
Table 1: Automatic evaluation results.
</tableCaption>
<bodyText confidence="0.999918266666667">
rules; in contrast, the simple M1 and M2 mod-
els produce outputs in which content is translated
primarily using lexicalized rules and reorderings
and word insertions are explained primarily by the
non-lexical rules. It appears that the two strategies
are complementary, succeeding and failing in dif-
ferent instances. We believe that this complemen-
tarity and the overcoming of some of the search
errors in our decoder during the model rescoring
phase explain the success of the system combina-
tion experiments.
We suspect that our decoder still makes many
search errors. In spite of this, the SPTM outputs
are still significantly better than the PBMT out-
puts.
</bodyText>
<subsectionHeader confidence="0.997131">
4.2 Human-based evaluation of the models
</subsectionHeader>
<bodyText confidence="0.999956222222222">
We also tested whether the Bleu score improve-
ments translate into improvements that can be per-
ceived by humans. To this end, we randomly se-
lected 138 sentences of less than 20 words from
our development corpus; we expected the transla-
tion quality of sentences of this size to be easier to
assess than that of sentences that are very long.
We prepared a web-based evaluation interface
that showed for each input sentence:
</bodyText>
<listItem confidence="0.999659666666667">
• the Chinese input;
• three English reference translations;
• the output of seven `MT systems”.
</listItem>
<bodyText confidence="0.99986466">
The evaluated `MT systems” were the six systems
shown in Table 1 and one of the reference trans-
lations. The reference translation presented as
automatically produced output was selected from
the set of four reference translations provided by
NIST so as to be representative of human transla-
tion quality. More precisely, we chose the second
best reference translation in the NIST corpus ac-
cording to its Bleu score against the other three
reference translations. The seven outputs were
randomly shufied and presented to three English
speakers for assessment.
The judges who participated in our experiment
were instructed to carefully read the three refer-
ence translations and seven machine translation
outputs, and assign a score between 1 and 5 to
each translation output on the basis of its quality.
Human judges were told that the translation qual-
ity assessment should take into consideration both
the grammatical iuency of the outputs and their
translation adequacy. Table 2 shows the average
scores obtained by each system according to each
judge. For convenience, the table also shows the
Bleu scores of all systems (including the human
translations) on three reference translations.
The results in Table 2 show that the human
judges are remarkably consistent in preferring the
syntax-based outputs over the phrase-based out-
puts. On a 1 to 5 quality scale, the difference be-
tween the phrase-based and syntax-based systems
was, on average, between 0.2 and 0.3 points. All
differences between the phrase-based baseline and
the syntax-based outputs were statistically signif-
icant. For example, when comparing the phrase-
based baseline against the combined system, the
improvement in human scores was significant at
P = 4.04e−6(t = 4.67, df = 413).
The results also show that the LDC reference
translations are far from being perfect. Although
we selected from the four references the second
best according to the Bleu metric, this human ref-
erence was judged to be at a quality level of only
4.67 on a scale from 1 to 5. Most of the translation
errors were iuency errors. Although the human
outputs had most of the time the right meaning,
the syntax was sometimes incorrect.
In order to give readers a iavor of the types
of re-orderings enabled by the SPMT models, we
present in Table 3, several translation outputs pro-
duced by the phrase-based baseline and the com-
</bodyText>
<page confidence="0.979035">
50
</page>
<table confidence="0.998288">
System Bleu score Judge 1 Judge 2 Judge 3 Judge
on Dev avg
(3 refs)
&lt; 20 words
PBMT 31.00 3.00 3.34 2.95 3.10
SPMT-M1 33.79 3.28 3.49 3.04 3.27
SPMT-M1C 33.66 3.23 3.43 3.26 3.31
SPMT-M2 34.05 3.24 3.45 3.10 3.26
SPMT-M2C 33.42 3.24 3.48 3.13 3.28
SPMT-Combined 35.33 3.31 3.59 3.25 3.38
Human Ref 40.84 4.64 4.62 4.75 4.67
</table>
<tableCaption confidence="0.998225">
Table 2: Human-based evaluation results.
</tableCaption>
<bodyText confidence="0.801776">
bined SPMT system. The outputs were selected to
reflect both positive and negative effects of large-
scale re-orderings.
</bodyText>
<sectionHeader confidence="0.999851" genericHeader="conclusions">
5 Discussion
</sectionHeader>
<bodyText confidence="0.999948616666667">
The SPMT models are similar to the models pro-
posed by Chiang (2005) and Galley et al. (2006).
If we analyze these three models in terms of ex-
pressive power, the Galley et al. (2006) model is
more expressive than the SPMT models, which
in turn, are more expressive than Chiang’s model.
The xRS formalism utilized by Galley et al. (2006)
allows for the use of translation rules that have
multi-level target tree annotations and discontin-
uous source language phrases. The SPMT mod-
els are less general: they use translation rules that
have multi-level target tree annotations but require
that the source language phrases are continuous.
The Syncronous Grammar formalism utilized by
Chiang is stricter than SPMT since it allows only
for single-level target tree annotations.
The parameters of the SPMT models presented
in this paper are easier to estimate than those of
Galley et al’s (2006) and can easily exploit and
expand on previous research in phrase-based ma-
chine translation. Also, the SPMT models yield
significantly fewer rules that the model of Galley
et al. In contrast with the model proposed by Chi-
ang, the SPMT models introduced in this paper are
fully grounded in syntax; this makes them good
candidates for exploring the impact that syntax-
based language models could have on translation
performance.
From a machine translation perspective, the
SPMT translation model family we have proposed
in this paper is promising. To our knowledge,
we are the first to report results that show that a
syntax-based system can produce results that are
better than those produced by a strong phrase-
based system in experimental conditions similar
to those used in large-scale, well-established in-
dependent evaluations, such as those carried out
annually by NIST.
Although the number of syntax-based rules
used by our models is smaller than the number
of phrase-based rules used in our state-of-the-art
baseline system, the SPMT models produce out-
puts of higher quality. This feature is encouraging
because it shows that the syntactified translation
rules learned in the SPMT models can generalize
better than the phrase-based rules.
We were also pleased to see that the Bleu
score improvements going from the phrase- to the
syntax-based models, as well as the Bleu improve-
ments going from the simple syntax-based models
to the combined models system are fully consis-
tent with the human qualitative judgments in our
subjective evaluations. This correlation suggests
that we can continue to use the Bleu metric to fur-
ther improve our models and systems.
Acknowledgements. This research was par-
tially supported by the National Institute of Stan-
dards and Technology’s Advanced Technology
Program Award 70NANB4H3050 to Language
Weaver Inc.
</bodyText>
<sectionHeader confidence="0.999004" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999332333333333">
R. Bonnema. 2002. Probability models for DOP. In
Data-Oriented Parsing. CSLI publications.
Peter F. Brown, Stephen A. Della Pietra, Vincent J.
Della Pietra, and Robert L. Mercer. 1993. The
mathematics of statistical machine translation: Pa-
rameter estimation. Computational Linguistics,
19(2):263–311.
David Chiang. 2005. A hierarchical phrase-based
model for statistical machine translation. In Pro-
ceedings of the 43rd Annual Meeting of the Associa-
tion for Computational Linguistics (ACL’05), pages
263–270, Ann Arbor, Michigan, June.
</reference>
<page confidence="0.999354">
51
</page>
<bodyText confidence="0.9975173">
System Output
PBMT fujian is china ’s coastal areas most rapid development of foreign trade of the region.
SPMT-Combined china ’s coastal areas of fujian is one of the areas of the most rapid development of
foreign trade and economic cooperation.
PBMT investment in macao has become the largest foreign investors.
SPMT-Combined the chinese - funded enterprises have become the largest foreign investor in macao.
PBMT they are now two people were unaccounted for.
SPMT-Combined currently, both of them remain unaccounted for.
PBMT there was no further statement.
SPMT-Combined the statement did not explain further.
</bodyText>
<tableCaption confidence="0.981395">
Table 3: Sample translations.
</tableCaption>
<reference confidence="0.999860227848101">
Michael Collins. 2003. Head-driven statistical models
for natural language parsing. Computational Lin-
guistics, 29(4):589–637, December.
Michel Galley, Mark Hopkins, Kevin Knight, and
Daniel Marcu. 2004. What’s in a translation
rule? In HLT-NAACL’2004: Main Proceedings,
pages 273–280, Boston, Massachusetts, USA, May
2 - May 7.
Michel Galley, Jonathan Graehl, Kevin Knight, Daniel
Marcu, Steve DeNeefe, Wei Wang, and Ignacio
Thayer. 2006. Scalable inferences and training
of context-rich syntax translation models. In Pro-
ceedings of the Annual Meeting of the Association
for Computational Linguistics (ACL’2006), Sydney,
Australia, July.
Reinhard Kneser and Hermann Ney. 1995. Improved
backing-off for m-gram language modeling. In Pro-
ceedings of the International Conference on Acous-
tics, Speech, and Signal Processing (ICASSP’95),
volume 1, pages 181–184.
Kevin Knight and Jonathan Graehl. 2005. An
overview of probabilistic tree transducers for natu-
ral language processing. In Proc. of the Sixth In-
ternational Conference on Intelligent Text Process-
ing and Computational Linguistics (CICLing’2005),
pages 1–25. Springer Verlag.
Philipp Koehn, Franz Joseph Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In Pro-
ceedings of the Human Language Technology and
North American Association for Computational Lin-
guistics Conference (HLT-NAACL’2003), Edmon-
ton, Canada, May 27–June 1.
Daniel Marcu and William Wong. 2002. A phrase-
based, joint probability model for statistical machine
translation. In Proceedings of the Conference on
Empirical Methods in Natural Language Processing
(EMNLP’2002), pages 133–139, Philadelphia, PA,
July 6-7.
Evgeny Matusov, Nicola Ueffing, and Hermann Ney.
2006. Computing consensus translation from mul-
tiple machine translation systems using enhanced
hypothesis alignment. In Proceedings of the An-
nual Meeting of the European Chapter of the Asso-
ciation for Computational Linguistics (EACL’2006),
Trento, Italy.
Franz Joseph Och and Hermann Ney. 2004. The align-
ment template approach to statistical machine trans-
lation. Computational Linguistics, 30(4), Decem-
ber.
Franz Joseph Och. 2003. Minimum error training
in statistical machine translation. In Proceedings
of the Annual Meeting of the Association for Com-
putational Linguistics (ACL’2003), pages 160–167,
Sapooro, Japan.
Kishore Papineni, Salim Roukos, Todd Ward, John
Henderson, and Florence Reeder. 2002. Corpus-
based comprehensive and diagnostic MT evaluation:
Initial Arabic, Chinese, French, and Spanish results.
In Proceedings of the Human Language Technology
Conference (ACL’2002), pages 124–127, San Diego,
CA, March 24-27.
Chris Quirk, Arul Menezes, and Colin Cherry. 2005.
Dependency treelet translation: Syntactically in-
formed phrasal SMT. In Proceedings of the 43rd
Annual Meeting of the Association for Computa-
tional Linguistics (ACL’2005), pages 271–279, Ann
Arbor, Michigan, June.
Radu Soricut. 2005. A reimplementation of Collins’s
parsing models.
Christoph Tillman. 2004. A unigram orienta-
tion model for statistical machine translation. In
HLT-NAACL 2004: Short Papers, pages 101–104,
Boston, Massachusetts, USA, May 2 - May 7.
Hao Zhang, Liang Huang, Daniel Gildea, and Kevin
Knight. 2006. Syncronous binarization for ma-
chine translation. In Proceding of the Human Lan-
guage Technology and North American Chapter of
the Associationfor Computational Linguistics (HLT-
NAACL’2006), New York, June.
</reference>
<page confidence="0.998855">
52
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.390962">
<title confidence="0.999514">SPMT: Statistical Machine Translation Syntactified Target Language Phrases</title>
<author confidence="0.976314">Daniel Marcu</author>
<author confidence="0.976314">Wei Wang</author>
<author confidence="0.976314">Abdessamad Echihabi</author>
<author confidence="0.976314">Kevin</author>
<affiliation confidence="0.565816">Language Weaver</affiliation>
<address confidence="0.970678">4640 Admiralty Way, Suite</address>
<author confidence="0.729116">Marina del Rey</author>
<author confidence="0.729116">CA</author>
<abstract confidence="0.9946681">We introduce SPMT, a new class of statistical Translation Models that use Syntactified target language Phrases. The SPMT models outperform a state of the art phrase-based baseline model by 2.64 Bleu points on the NIST 2003 Chinese-English test corpus and 0.28 points on a humanbased quality metric that ranks translations on a scale from 1 to 5.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>R Bonnema</author>
</authors>
<title>Probability models for DOP. In Data-Oriented Parsing.</title>
<date>2002</date>
<publisher>CSLI publications.</publisher>
<contexts>
<context position="6408" citStr="Bonnema, 2002" startWordPosition="972" endWordPosition="974">NNP(france)) CC(and) NP(NNP(russia))) → FRANCE AND RUSSIA r3 :VP(VBG(coming) PP(IN(from) NP:x0)) → COMINGFROM x0 r4 :NP(NP:x0, VP:x1) → x1 p-DE x0 r5 :NNP(france) → FRANCE rs :NP(NP(NNP(france)) CC(and) NP:x0) → FRANCE AND x0 r7 :NNS(astronauts) → ASTRO- -NAUTS rs :NNP(russia) → RUSSIA rg :NP(NNS:x0) → x0 r10 :PP(IN:x0 NP:x1) → x0 x1 r11 :NP(NP:x0 CC:x1 NP:x2) → x0 x1 x2 r12 :NP(NNP:x0) → x0 r13 :CC(and) → AND r14 :NP(NP:x0 CC(and) NP:x1) → x0 AND x1 r15 :NP(NP:x0 VP(VBG(coming) PP(IN(from) NP:x1))) → x1 COMINGFROM x0 Figure 1: Examples of xRS rules. that used in Data Oriented Parsing models (Bonnema, 2002). For example, if we assume that the generative process has already produced the top NP node in Figure 2, then the corresponding partial English parse tree, foreign/source string, and word-level alignment could be generated by the rule derivation r4(r1, r3(r2)), where each rule is assumed to have some probability. The extended tree to string transducers introduced by Knight and Graehl (2005) provide a natural framework for expressing the tree to string transformations specific to our SPMT models. The transformation rules we plan to exploit are equivalent to one-state xRS top-down transducers w</context>
</contexts>
<marker>Bonnema, 2002</marker>
<rawString>R. Bonnema. 2002. Probability models for DOP. In Data-Oriented Parsing. CSLI publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Stephen A Della Pietra</author>
<author>Vincent J Della Pietra</author>
<author>Robert L Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: Parameter estimation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="8308" citStr="Brown et al., 1993" startWordPosition="1292" endWordPosition="1295"> tree derivation of the Chinese string COMINGFROM FRANCE AND RUSSIA pDE ASTRO- -NAUTS. ple, c(0) _ (7r, F, A). The probability of each derivation BZ is given by the product of the probabilities of all the rules p(rj) in the derivation (see equation 4). �Pr(7r, F, A) _ BiEO,c(0)=(7r,F,A) rjEBi In order to acquire the rules specific to our model and to induce their probabilities, we parse the English side of our corpus with an in-house implementation (Soricut, 2005) of Collins parsing models (Collins, 2003) and we word-align the parallel corpus with the Giza++2 implementation of the IBM models (Brown et al., 1993). We use the automatically derived (English-parse-tree, English-sentence, Foreign-sentence, Word-levelalignment) tuples in order to induce xRS rules for several models. 2.2.2 SPMT Model 1 In our simplest model, we assume that each tuple (7r, F, A) in our automatically annotated corpus could be produced by applying a combination of minimally syntactified, lexicalized, phrase-based compatible xRS rules, and minimal/necessary, non-lexicalized xRS rules. We call a rule non-lexicalized whenever it does not have any directly aligned source-to-target words. Rules r9–r12 in Figure 1 are examples of no</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della Pietra, and Robert L. Mercer. 1993. The mathematics of statistical machine translation: Parameter estimation. Computational Linguistics, 19(2):263–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>A hierarchical phrase-based model for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05),</booktitle>
<pages>263--270</pages>
<location>Ann Arbor, Michigan,</location>
<contexts>
<context position="1355" citStr="Chiang, 2005" startWordPosition="197" endWordPosition="198"> (Marcu and Wong, 2002; Koehn et al., 2003; Och and Ney, 2004) have led to significant increases in machine translation accuracy. Although phrase-based models yield high-quality translations for language pairs that exhibit similar word order, they fail to produce grammatical outputs for language pairs that are syntactically divergent. Recent models that exploit syntactic information of the source language (Quirk et al., 2005) have been shown to produce better outputs than phrase-based systems when evaluated on relatively small scale, domain specific corpora. And syntax-inspired formal models (Chiang, 2005), in spite of being trained on significantly less data, have shown promising results when compared on the same test sets with mature phrase-based systems. To our knowledge though, no previous research has demonstrated that a syntax-based statistical translation system could produce better results than a phrase-based system on a large-scale, well-established, open domain translation task. In this paper we present such a system. Our translation models rely upon and naturally exploit submodels (feature functions) that have been initially developed in phrase-based systems for choosing target trans</context>
<context position="28091" citStr="Chiang (2005)" startWordPosition="4561" endWordPosition="4562">duced by the phrase-based baseline and the com50 System Bleu score Judge 1 Judge 2 Judge 3 Judge on Dev avg (3 refs) &lt; 20 words PBMT 31.00 3.00 3.34 2.95 3.10 SPMT-M1 33.79 3.28 3.49 3.04 3.27 SPMT-M1C 33.66 3.23 3.43 3.26 3.31 SPMT-M2 34.05 3.24 3.45 3.10 3.26 SPMT-M2C 33.42 3.24 3.48 3.13 3.28 SPMT-Combined 35.33 3.31 3.59 3.25 3.38 Human Ref 40.84 4.64 4.62 4.75 4.67 Table 2: Human-based evaluation results. bined SPMT system. The outputs were selected to reflect both positive and negative effects of largescale re-orderings. 5 Discussion The SPMT models are similar to the models proposed by Chiang (2005) and Galley et al. (2006). If we analyze these three models in terms of expressive power, the Galley et al. (2006) model is more expressive than the SPMT models, which in turn, are more expressive than Chiang’s model. The xRS formalism utilized by Galley et al. (2006) allows for the use of translation rules that have multi-level target tree annotations and discontinuous source language phrases. The SPMT models are less general: they use translation rules that have multi-level target tree annotations but require that the source language phrases are continuous. The Syncronous Grammar formalism u</context>
</contexts>
<marker>Chiang, 2005</marker>
<rawString>David Chiang. 2005. A hierarchical phrase-based model for statistical machine translation. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05), pages 263–270, Ann Arbor, Michigan, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Head-driven statistical models for natural language parsing.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>4</issue>
<contexts>
<context position="8199" citStr="Collins, 2003" startWordPosition="1276" endWordPosition="1277">btained by summing over all derivations Oi E O that are consistent with the tu45 Figure 2: English parse tree derivation of the Chinese string COMINGFROM FRANCE AND RUSSIA pDE ASTRO- -NAUTS. ple, c(0) _ (7r, F, A). The probability of each derivation BZ is given by the product of the probabilities of all the rules p(rj) in the derivation (see equation 4). �Pr(7r, F, A) _ BiEO,c(0)=(7r,F,A) rjEBi In order to acquire the rules specific to our model and to induce their probabilities, we parse the English side of our corpus with an in-house implementation (Soricut, 2005) of Collins parsing models (Collins, 2003) and we word-align the parallel corpus with the Giza++2 implementation of the IBM models (Brown et al., 1993). We use the automatically derived (English-parse-tree, English-sentence, Foreign-sentence, Word-levelalignment) tuples in order to induce xRS rules for several models. 2.2.2 SPMT Model 1 In our simplest model, we assume that each tuple (7r, F, A) in our automatically annotated corpus could be produced by applying a combination of minimally syntactified, lexicalized, phrase-based compatible xRS rules, and minimal/necessary, non-lexicalized xRS rules. We call a rule non-lexicalized whene</context>
</contexts>
<marker>Collins, 2003</marker>
<rawString>Michael Collins. 2003. Head-driven statistical models for natural language parsing. Computational Linguistics, 29(4):589–637, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Galley</author>
<author>Mark Hopkins</author>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
</authors>
<title>What’s in a translation rule?</title>
<date>2004</date>
<booktitle>In HLT-NAACL’2004: Main Proceedings,</booktitle>
<volume>2</volume>
<pages>273--280</pages>
<location>Boston, Massachusetts, USA,</location>
<contexts>
<context position="10992" citStr="Galley et al. (2004" startWordPosition="1711" endWordPosition="1714"> minimal rules (lexicalized and non-lexicalized) by applying the algorithm proposed by Galley et al. (2006) and then remove the lexicalized rules. We remove the Galley et al.’s lexicalized rules because they are either already accounted for by the minimally syntactified, lexicalized, phrasebased-compatible xRS rules or they subsume noncontinuous source-target phrase pairs. It is worth mentioning that, in our framework, a rule is defined to be “minimal” with respect to a foreign/source language phrase, i.e., it is the minimal xRS rule that yields that source phrase. In contrast, in the work of Galley et al. (2004; 2006), a rule is defined to be minimal when it is necessary in order to explain a (7r, F, A) tuple. Under SPMT model 1, the tree in Figure 2 can be produced, for example, by the following derivation: r4(r9(r7),r3(r6(r12(rs)))). 2.2.3 SPMT Model 1 Composed We hypothesize that composed rules, i.e., rules that can be decomposed via the application of a sequence of Model 1 rules may improve the performance of an SPMT system. For example, although the minimal Model 1 rules r11 and r13 are p(rj) (4) 46 Figure 3: Problematic syntactifications of phrasal translations. sufficient for building an Engl</context>
</contexts>
<marker>Galley, Hopkins, Knight, Marcu, 2004</marker>
<rawString>Michel Galley, Mark Hopkins, Kevin Knight, and Daniel Marcu. 2004. What’s in a translation rule? In HLT-NAACL’2004: Main Proceedings, pages 273–280, Boston, Massachusetts, USA, May 2 - May 7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Galley</author>
<author>Jonathan Graehl</author>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
<author>Steve DeNeefe</author>
<author>Wei Wang</author>
<author>Ignacio Thayer</author>
</authors>
<title>Scalable inferences and training of context-rich syntax translation models.</title>
<date>2006</date>
<booktitle>In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL’2006),</booktitle>
<location>Sydney, Australia,</location>
<contexts>
<context position="10480" citStr="Galley et al. (2006)" startWordPosition="1628" endWordPosition="1631"> as in phrase-based MT, all our rules have continuous phrases on both the source and target language sides, we call these phrase-based compatible xRS rules. Since these lexicalized rules are not sufficient to explain an entire (7r, F, A) tuple, we also extract the required minimal/necessary, non-lexicalized xRS rules. The minimal non-lexicalized rules that are licensed by the tuple in Figure 2 are labeled r4, r9, r10, r11 and r12 in Figure 1. To obtain the non-lexicalized xRS rules, we compute the set of all minimal rules (lexicalized and non-lexicalized) by applying the algorithm proposed by Galley et al. (2006) and then remove the lexicalized rules. We remove the Galley et al.’s lexicalized rules because they are either already accounted for by the minimally syntactified, lexicalized, phrasebased-compatible xRS rules or they subsume noncontinuous source-target phrase pairs. It is worth mentioning that, in our framework, a rule is defined to be “minimal” with respect to a foreign/source language phrase, i.e., it is the minimal xRS rule that yields that source phrase. In contrast, in the work of Galley et al. (2004; 2006), a rule is defined to be minimal when it is necessary in order to explain a (7r,</context>
<context position="28116" citStr="Galley et al. (2006)" startWordPosition="4564" endWordPosition="4567">e-based baseline and the com50 System Bleu score Judge 1 Judge 2 Judge 3 Judge on Dev avg (3 refs) &lt; 20 words PBMT 31.00 3.00 3.34 2.95 3.10 SPMT-M1 33.79 3.28 3.49 3.04 3.27 SPMT-M1C 33.66 3.23 3.43 3.26 3.31 SPMT-M2 34.05 3.24 3.45 3.10 3.26 SPMT-M2C 33.42 3.24 3.48 3.13 3.28 SPMT-Combined 35.33 3.31 3.59 3.25 3.38 Human Ref 40.84 4.64 4.62 4.75 4.67 Table 2: Human-based evaluation results. bined SPMT system. The outputs were selected to reflect both positive and negative effects of largescale re-orderings. 5 Discussion The SPMT models are similar to the models proposed by Chiang (2005) and Galley et al. (2006). If we analyze these three models in terms of expressive power, the Galley et al. (2006) model is more expressive than the SPMT models, which in turn, are more expressive than Chiang’s model. The xRS formalism utilized by Galley et al. (2006) allows for the use of translation rules that have multi-level target tree annotations and discontinuous source language phrases. The SPMT models are less general: they use translation rules that have multi-level target tree annotations but require that the source language phrases are continuous. The Syncronous Grammar formalism utilized by Chiang is stri</context>
</contexts>
<marker>Galley, Graehl, Knight, Marcu, DeNeefe, Wang, Thayer, 2006</marker>
<rawString>Michel Galley, Jonathan Graehl, Kevin Knight, Daniel Marcu, Steve DeNeefe, Wei Wang, and Ignacio Thayer. 2006. Scalable inferences and training of context-rich syntax translation models. In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL’2006), Sydney, Australia, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reinhard Kneser</author>
<author>Hermann Ney</author>
</authors>
<title>Improved backing-off for m-gram language modeling.</title>
<date>1995</date>
<booktitle>In Proceedings of the International Conference on Acoustics, Speech, and Signal Processing (ICASSP’95),</booktitle>
<volume>1</volume>
<pages>181--184</pages>
<marker>Kneser, Ney, 1995</marker>
<rawString>Reinhard Kneser and Hermann Ney. 1995. Improved backing-off for m-gram language modeling. In Proceedings of the International Conference on Acoustics, Speech, and Signal Processing (ICASSP’95), volume 1, pages 181–184.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Knight</author>
<author>Jonathan Graehl</author>
</authors>
<title>An overview of probabilistic tree transducers for natural language processing.</title>
<date>2005</date>
<booktitle>In Proc. of the Sixth International Conference on Intelligent Text Processing and Computational Linguistics (CICLing’2005),</booktitle>
<pages>1--25</pages>
<publisher>Springer Verlag.</publisher>
<contexts>
<context position="6802" citStr="Knight and Graehl (2005)" startWordPosition="1034" endWordPosition="1037">P:x0) → x0 r13 :CC(and) → AND r14 :NP(NP:x0 CC(and) NP:x1) → x0 AND x1 r15 :NP(NP:x0 VP(VBG(coming) PP(IN(from) NP:x1))) → x1 COMINGFROM x0 Figure 1: Examples of xRS rules. that used in Data Oriented Parsing models (Bonnema, 2002). For example, if we assume that the generative process has already produced the top NP node in Figure 2, then the corresponding partial English parse tree, foreign/source string, and word-level alignment could be generated by the rule derivation r4(r1, r3(r2)), where each rule is assumed to have some probability. The extended tree to string transducers introduced by Knight and Graehl (2005) provide a natural framework for expressing the tree to string transformations specific to our SPMT models. The transformation rules we plan to exploit are equivalent to one-state xRS top-down transducers with look ahead, which map subtree patterns to strings. For example, rule r3 in Figure 1 can be applied only when one is in a state that has a VP as its syntactic constituent and the tree pattern VP(VBG(coming) PP(IN(from) NP)) immediately underneath. The rule application outputs the string “COMINGFROM” as the transducer moves to the state co-indexed by x0; the outputs produced from the new s</context>
<context position="19905" citStr="Knight and Graehl, 2005" startWordPosition="3188" endWordPosition="3191">ing 3.1 Decoding with one SPMT model We decode with each of our SPMT models using a straightforward, bottom-up, CKY-style decoder that builds English syntactic constituents on the top of Chinese sentences. The decoder uses a binarized representation of the rules, which is obtained via a syncronous binarization procedure (Zhang et al., 2006). The CKY-style decoder computes the probability of English syntactic constituents in a bottom up fashion, by log-linearly interpolating all the submodel scores described in Section 2.3. The decoder is capable of producing nbest derivations and nbest lists (Knight and Graehl, 2005), which are used for Maximum Bleu training (Och, 2003). When decoding the test corpus, the decoder returns the translation that has the most probable derivation; in other words, the sum operator in equation 4 is replaced with an argmax. 3.2 Decoding with multiple SPMT models Combining multiple MT outputs to increase performance is, in general, a difficult task (Matusov et al., 2006) when significantly different engines compete for producing the best outputs. In our case, combining multiple MT outputs is much simpler because the submodel probabilities across the four models described here are m</context>
</contexts>
<marker>Knight, Graehl, 2005</marker>
<rawString>Kevin Knight and Jonathan Graehl. 2005. An overview of probabilistic tree transducers for natural language processing. In Proc. of the Sixth International Conference on Intelligent Text Processing and Computational Linguistics (CICLing’2005), pages 1–25. Springer Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz Joseph Och</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistical phrase-based translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the Human Language Technology and North American Association for Computational Linguistics Conference (HLT-NAACL’2003),</booktitle>
<location>Edmonton, Canada,</location>
<contexts>
<context position="784" citStr="Koehn et al., 2003" startWordPosition="113" endWordPosition="116">0 Admiralty Way, Suite 1210 Marina del Rey, CA 90292 {dmarcu,wwang,aechihabi,kknight}@languageweaver.com Abstract We introduce SPMT, a new class of statistical Translation Models that use Syntactified target language Phrases. The SPMT models outperform a state of the art phrase-based baseline model by 2.64 Bleu points on the NIST 2003 Chinese-English test corpus and 0.28 points on a humanbased quality metric that ranks translations on a scale from 1 to 5. 1 Introduction During the last four years, various implementations and extentions to phrase-based statistical models (Marcu and Wong, 2002; Koehn et al., 2003; Och and Ney, 2004) have led to significant increases in machine translation accuracy. Although phrase-based models yield high-quality translations for language pairs that exhibit similar word order, they fail to produce grammatical outputs for language pairs that are syntactically divergent. Recent models that exploit syntactic information of the source language (Quirk et al., 2005) have been shown to produce better outputs than phrase-based systems when evaluated on relatively small scale, domain specific corpora. And syntax-inspired formal models (Chiang, 2005), in spite of being trained o</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Philipp Koehn, Franz Joseph Och, and Daniel Marcu. 2003. Statistical phrase-based translation. In Proceedings of the Human Language Technology and North American Association for Computational Linguistics Conference (HLT-NAACL’2003), Edmonton, Canada, May 27–June 1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Marcu</author>
<author>William Wong</author>
</authors>
<title>A phrasebased, joint probability model for statistical machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP’2002),</booktitle>
<pages>133--139</pages>
<location>Philadelphia, PA,</location>
<contexts>
<context position="764" citStr="Marcu and Wong, 2002" startWordPosition="109" endWordPosition="112">nguage Weaver Inc. 4640 Admiralty Way, Suite 1210 Marina del Rey, CA 90292 {dmarcu,wwang,aechihabi,kknight}@languageweaver.com Abstract We introduce SPMT, a new class of statistical Translation Models that use Syntactified target language Phrases. The SPMT models outperform a state of the art phrase-based baseline model by 2.64 Bleu points on the NIST 2003 Chinese-English test corpus and 0.28 points on a humanbased quality metric that ranks translations on a scale from 1 to 5. 1 Introduction During the last four years, various implementations and extentions to phrase-based statistical models (Marcu and Wong, 2002; Koehn et al., 2003; Och and Ney, 2004) have led to significant increases in machine translation accuracy. Although phrase-based models yield high-quality translations for language pairs that exhibit similar word order, they fail to produce grammatical outputs for language pairs that are syntactically divergent. Recent models that exploit syntactic information of the source language (Quirk et al., 2005) have been shown to produce better outputs than phrase-based systems when evaluated on relatively small scale, domain specific corpora. And syntax-inspired formal models (Chiang, 2005), in spit</context>
</contexts>
<marker>Marcu, Wong, 2002</marker>
<rawString>Daniel Marcu and William Wong. 2002. A phrasebased, joint probability model for statistical machine translation. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP’2002), pages 133–139, Philadelphia, PA, July 6-7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Evgeny Matusov</author>
<author>Nicola Ueffing</author>
<author>Hermann Ney</author>
</authors>
<title>Computing consensus translation from multiple machine translation systems using enhanced hypothesis alignment.</title>
<date>2006</date>
<booktitle>In Proceedings of the Annual Meeting of the European Chapter of the Association for Computational Linguistics (EACL’2006),</booktitle>
<location>Trento, Italy.</location>
<contexts>
<context position="20290" citStr="Matusov et al., 2006" startWordPosition="3253" endWordPosition="3256">ty of English syntactic constituents in a bottom up fashion, by log-linearly interpolating all the submodel scores described in Section 2.3. The decoder is capable of producing nbest derivations and nbest lists (Knight and Graehl, 2005), which are used for Maximum Bleu training (Och, 2003). When decoding the test corpus, the decoder returns the translation that has the most probable derivation; in other words, the sum operator in equation 4 is replaced with an argmax. 3.2 Decoding with multiple SPMT models Combining multiple MT outputs to increase performance is, in general, a difficult task (Matusov et al., 2006) when significantly different engines compete for producing the best outputs. In our case, combining multiple MT outputs is much simpler because the submodel probabilities across the four models described here are mostly identifical, with the exception of the root normalized and CFG-like submodels which are scaled differently – since Model 2 composed has, for example, more rules than Model 1, the root normalized and CFG-like submodels have smaller probabilities for identical rules in Model 2 composed than in Model 1. We compare these two probabilities across the submodels and we scale all mode</context>
</contexts>
<marker>Matusov, Ueffing, Ney, 2006</marker>
<rawString>Evgeny Matusov, Nicola Ueffing, and Hermann Ney. 2006. Computing consensus translation from multiple machine translation systems using enhanced hypothesis alignment. In Proceedings of the Annual Meeting of the European Chapter of the Association for Computational Linguistics (EACL’2006), Trento, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Joseph Och</author>
<author>Hermann Ney</author>
</authors>
<title>The alignment template approach to statistical machine translation.</title>
<date>2004</date>
<journal>Computational Linguistics,</journal>
<volume>30</volume>
<issue>4</issue>
<contexts>
<context position="804" citStr="Och and Ney, 2004" startWordPosition="117" endWordPosition="120">te 1210 Marina del Rey, CA 90292 {dmarcu,wwang,aechihabi,kknight}@languageweaver.com Abstract We introduce SPMT, a new class of statistical Translation Models that use Syntactified target language Phrases. The SPMT models outperform a state of the art phrase-based baseline model by 2.64 Bleu points on the NIST 2003 Chinese-English test corpus and 0.28 points on a humanbased quality metric that ranks translations on a scale from 1 to 5. 1 Introduction During the last four years, various implementations and extentions to phrase-based statistical models (Marcu and Wong, 2002; Koehn et al., 2003; Och and Ney, 2004) have led to significant increases in machine translation accuracy. Although phrase-based models yield high-quality translations for language pairs that exhibit similar word order, they fail to produce grammatical outputs for language pairs that are syntactically divergent. Recent models that exploit syntactic information of the source language (Quirk et al., 2005) have been shown to produce better outputs than phrase-based systems when evaluated on relatively small scale, domain specific corpora. And syntax-inspired formal models (Chiang, 2005), in spite of being trained on significantly less</context>
<context position="3761" citStr="Och and Ney, 2004" startWordPosition="539" endWordPosition="542"> which correctly orders the phrasal translations into a grammatical sequence. We believe this happens because the distortion/reordering models that are used by state-of-the-art phrase-based systems, which exploit phrase movement and ngram target &apos;To increase readability, in this paper, we represent Chinese words using fully capitalized English glosses and English words using lowercased letters. 44 Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP 2006), pages 44–52, Sydney, July 2006. c�2006 Association for Computational Linguistics language models (Och and Ney, 2004; Tillman, 2004), are too weak to help a phrase-based decoder reorder the target phrases into grammatical outputs. THESE 7PEOPLE INCLUDE COMINGFROM FRANCE AND RUSSIA p-DE ASTRO- -NAUTS . the 7 people including those from france and the russian cosmonauts . One method for increasing the ability of a decoder to reorder target language phrases is that of decorating them with syntactic constituent information. For example, we may make explicit that the Chinese phrase “ASTRO- -NAUTS” may be translated into English as a noun phrase, NP(NNS(astronauts)); that the phrase FRANCE AND RUSSIA may be trans</context>
<context position="18916" citStr="Och and Ney, 2004" startWordPosition="3036" endWordPosition="3039">of a rule. • m1inv(rz) is the IBM model 1 inverse probability computed over the bags of words that occur on the source and target sides of a rule. • lm(e) is the language model probability of the target translation under an ngram language model. • wp(e) is a word penalty model designed to favor longer translations. All these models are combined log-linearly during decoding. The weights of the models are computed automatically using a variant of the Maximum Bleu training procedure proposed by Och (2003). The phrase-based-like submodels have been proved useful in phrase-based approaches to SMT (Och and Ney, 2004). The first two syntaxbased submodels implement a “fused” translation and lexical grounded distortion model (proot) and a syntax-based distortion model (pcfg). The indicator submodels are used to determine the extent to which our system prefers lexicalized vs. nonlexicalized rules; simple vs. composed rules; and high vs. low count rules. f )=root(r) (r 48 3 Decoding 3.1 Decoding with one SPMT model We decode with each of our SPMT models using a straightforward, bottom-up, CKY-style decoder that builds English syntactic constituents on the top of Chinese sentences. The decoder uses a binarized </context>
<context position="21795" citStr="Och and Ney, 2004" startWordPosition="3499" endWordPosition="3502"> maximizes the Bleu score of the combined nbest list using the same development corpus we used for tuning the individual systems (Och, 2003). We use the new weights in order to rerank the nbest outputs on the test corpus. 4 Experiments 4.1 Automatic evaluation of the models We evaluate our models on a Chinese to English machine translation task. We use the same training corpus, 138.7M words of parallel Chinese-English data released by LDC, in order to train several statistical-based MT systems: • PBMT, a strong state of the art phrase-based system that implements the alignment template model (Och and Ney, 2004); this is the system ISI has used in the 2004 and 2005 NIST evaluations. • four SPMT systems (M1, M1C, M2, M2C) that implement each of the models discussed in this paper; • a SPMT system, Comb, that combines the outputs of all SPMT models using the procedure described in Section 3.2. In all systems, we use a rule extraction algorithm that limits the size of the foreign/source phrases to four words. For all systems, we use a Kneser-Ney (1995) smoothed trigram language model trained on 2.3 billion words of English. As development data for the SPMT systems, we used the sentences in the 2002 NIST </context>
</contexts>
<marker>Och, Ney, 2004</marker>
<rawString>Franz Joseph Och and Hermann Ney. 2004. The alignment template approach to statistical machine translation. Computational Linguistics, 30(4), December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Joseph Och</author>
</authors>
<title>Minimum error training in statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL’2003),</booktitle>
<pages>160--167</pages>
<location>Sapooro, Japan.</location>
<contexts>
<context position="18805" citStr="Och (2003)" startWordPosition="3022" endWordPosition="3023"> the IBM model 1 probability computed over the bags of words that occur on the source and target sides of a rule. • m1inv(rz) is the IBM model 1 inverse probability computed over the bags of words that occur on the source and target sides of a rule. • lm(e) is the language model probability of the target translation under an ngram language model. • wp(e) is a word penalty model designed to favor longer translations. All these models are combined log-linearly during decoding. The weights of the models are computed automatically using a variant of the Maximum Bleu training procedure proposed by Och (2003). The phrase-based-like submodels have been proved useful in phrase-based approaches to SMT (Och and Ney, 2004). The first two syntaxbased submodels implement a “fused” translation and lexical grounded distortion model (proot) and a syntax-based distortion model (pcfg). The indicator submodels are used to determine the extent to which our system prefers lexicalized vs. nonlexicalized rules; simple vs. composed rules; and high vs. low count rules. f )=root(r) (r 48 3 Decoding 3.1 Decoding with one SPMT model We decode with each of our SPMT models using a straightforward, bottom-up, CKY-style de</context>
<context position="21317" citStr="Och, 2003" startWordPosition="3421" endWordPosition="3422">nd CFG-like submodels have smaller probabilities for identical rules in Model 2 composed than in Model 1. We compare these two probabilities across the submodels and we scale all model probabilities to be compatible with those of Model 2 composed. With this scaling procedure into place, we produce 6,000 non-unique nbest lists for all sentences in our development corpus, using all SPMT submodels. We concatenate the lists and we learn a new combination of weights that maximizes the Bleu score of the combined nbest list using the same development corpus we used for tuning the individual systems (Och, 2003). We use the new weights in order to rerank the nbest outputs on the test corpus. 4 Experiments 4.1 Automatic evaluation of the models We evaluate our models on a Chinese to English machine translation task. We use the same training corpus, 138.7M words of parallel Chinese-English data released by LDC, in order to train several statistical-based MT systems: • PBMT, a strong state of the art phrase-based system that implements the alignment template model (Och and Ney, 2004); this is the system ISI has used in the 2004 and 2005 NIST evaluations. • four SPMT systems (M1, M1C, M2, M2C) that imple</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Joseph Och. 2003. Minimum error training in statistical machine translation. In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL’2003), pages 160–167, Sapooro, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>John Henderson</author>
<author>Florence Reeder</author>
</authors>
<title>Corpusbased comprehensive and diagnostic MT evaluation: Initial Arabic, Chinese, French, and Spanish results.</title>
<date>2002</date>
<booktitle>In Proceedings of the Human Language Technology Conference (ACL’2002),</booktitle>
<pages>124--127</pages>
<location>San Diego, CA,</location>
<contexts>
<context position="22950" citStr="Papineni et al., 2002" startWordPosition="3706" endWordPosition="3709"> data for the SPMT systems, we used the sentences in the 2002 NIST development corpus that are shorter than 20 words; we made this choice in order to finish all experiments in time for this submission. The PBMT system used all sentences in the 2002 NIST corpus for development. As test data, we used the 2003 NIST test set. Table 1 shows the number of string-to-string or tree-to-string rules extracted by each system and the performance on both the subset of sentences in the test corpus that were shorter than 20 words and the entire test corpus. The performance is measured using the Bleu metric (Papineni et al., 2002) on lowercased, tokenized outputs/references. The results show that the SPMT models clearly outperform the phrase-based systems – the 95% confidence intervals computed via bootstrap resampling in all cases are around 1 Bleu point. The results also show that the simple system combination procedure that we have employed is effective in our setting. The improvement on the development corpus transfers to the test setting as well. A visual inspection of the outputs shows significant differences between the outputs of the four models. The models that use composed rules prefer to produce outputs by u</context>
</contexts>
<marker>Papineni, Roukos, Ward, Henderson, Reeder, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, John Henderson, and Florence Reeder. 2002. Corpusbased comprehensive and diagnostic MT evaluation: Initial Arabic, Chinese, French, and Spanish results. In Proceedings of the Human Language Technology Conference (ACL’2002), pages 124–127, San Diego, CA, March 24-27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Quirk</author>
<author>Arul Menezes</author>
<author>Colin Cherry</author>
</authors>
<title>Dependency treelet translation: Syntactically informed phrasal SMT.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’2005),</booktitle>
<pages>271--279</pages>
<location>Ann Arbor, Michigan,</location>
<contexts>
<context position="1171" citStr="Quirk et al., 2005" startWordPosition="169" endWordPosition="172">humanbased quality metric that ranks translations on a scale from 1 to 5. 1 Introduction During the last four years, various implementations and extentions to phrase-based statistical models (Marcu and Wong, 2002; Koehn et al., 2003; Och and Ney, 2004) have led to significant increases in machine translation accuracy. Although phrase-based models yield high-quality translations for language pairs that exhibit similar word order, they fail to produce grammatical outputs for language pairs that are syntactically divergent. Recent models that exploit syntactic information of the source language (Quirk et al., 2005) have been shown to produce better outputs than phrase-based systems when evaluated on relatively small scale, domain specific corpora. And syntax-inspired formal models (Chiang, 2005), in spite of being trained on significantly less data, have shown promising results when compared on the same test sets with mature phrase-based systems. To our knowledge though, no previous research has demonstrated that a syntax-based statistical translation system could produce better results than a phrase-based system on a large-scale, well-established, open domain translation task. In this paper we present </context>
</contexts>
<marker>Quirk, Menezes, Cherry, 2005</marker>
<rawString>Chris Quirk, Arul Menezes, and Colin Cherry. 2005. Dependency treelet translation: Syntactically informed phrasal SMT. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’2005), pages 271–279, Ann Arbor, Michigan, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Radu Soricut</author>
</authors>
<title>A reimplementation of Collins’s parsing models.</title>
<date>2005</date>
<contexts>
<context position="8157" citStr="Soricut, 2005" startWordPosition="1269" endWordPosition="1270">the probability of a tuple (7r, F, A) is obtained by summing over all derivations Oi E O that are consistent with the tu45 Figure 2: English parse tree derivation of the Chinese string COMINGFROM FRANCE AND RUSSIA pDE ASTRO- -NAUTS. ple, c(0) _ (7r, F, A). The probability of each derivation BZ is given by the product of the probabilities of all the rules p(rj) in the derivation (see equation 4). �Pr(7r, F, A) _ BiEO,c(0)=(7r,F,A) rjEBi In order to acquire the rules specific to our model and to induce their probabilities, we parse the English side of our corpus with an in-house implementation (Soricut, 2005) of Collins parsing models (Collins, 2003) and we word-align the parallel corpus with the Giza++2 implementation of the IBM models (Brown et al., 1993). We use the automatically derived (English-parse-tree, English-sentence, Foreign-sentence, Word-levelalignment) tuples in order to induce xRS rules for several models. 2.2.2 SPMT Model 1 In our simplest model, we assume that each tuple (7r, F, A) in our automatically annotated corpus could be produced by applying a combination of minimally syntactified, lexicalized, phrase-based compatible xRS rules, and minimal/necessary, non-lexicalized xRS r</context>
</contexts>
<marker>Soricut, 2005</marker>
<rawString>Radu Soricut. 2005. A reimplementation of Collins’s parsing models.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christoph Tillman</author>
</authors>
<title>A unigram orientation model for statistical machine translation.</title>
<date>2004</date>
<booktitle>In HLT-NAACL 2004: Short Papers,</booktitle>
<pages>101--104</pages>
<location>Boston, Massachusetts, USA,</location>
<contexts>
<context position="3777" citStr="Tillman, 2004" startWordPosition="543" endWordPosition="544">ders the phrasal translations into a grammatical sequence. We believe this happens because the distortion/reordering models that are used by state-of-the-art phrase-based systems, which exploit phrase movement and ngram target &apos;To increase readability, in this paper, we represent Chinese words using fully capitalized English glosses and English words using lowercased letters. 44 Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP 2006), pages 44–52, Sydney, July 2006. c�2006 Association for Computational Linguistics language models (Och and Ney, 2004; Tillman, 2004), are too weak to help a phrase-based decoder reorder the target phrases into grammatical outputs. THESE 7PEOPLE INCLUDE COMINGFROM FRANCE AND RUSSIA p-DE ASTRO- -NAUTS . the 7 people including those from france and the russian cosmonauts . One method for increasing the ability of a decoder to reorder target language phrases is that of decorating them with syntactic constituent information. For example, we may make explicit that the Chinese phrase “ASTRO- -NAUTS” may be translated into English as a noun phrase, NP(NNS(astronauts)); that the phrase FRANCE AND RUSSIA may be translated into a com</context>
</contexts>
<marker>Tillman, 2004</marker>
<rawString>Christoph Tillman. 2004. A unigram orientation model for statistical machine translation. In HLT-NAACL 2004: Short Papers, pages 101–104, Boston, Massachusetts, USA, May 2 - May 7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hao Zhang</author>
<author>Liang Huang</author>
<author>Daniel Gildea</author>
<author>Kevin Knight</author>
</authors>
<title>Syncronous binarization for machine translation.</title>
<date>2006</date>
<booktitle>In Proceding of the Human Language Technology and North American Chapter of the Associationfor Computational Linguistics (HLTNAACL’2006),</booktitle>
<location>New York,</location>
<contexts>
<context position="19623" citStr="Zhang et al., 2006" startWordPosition="3147" endWordPosition="3150">ed distortion model (proot) and a syntax-based distortion model (pcfg). The indicator submodels are used to determine the extent to which our system prefers lexicalized vs. nonlexicalized rules; simple vs. composed rules; and high vs. low count rules. f )=root(r) (r 48 3 Decoding 3.1 Decoding with one SPMT model We decode with each of our SPMT models using a straightforward, bottom-up, CKY-style decoder that builds English syntactic constituents on the top of Chinese sentences. The decoder uses a binarized representation of the rules, which is obtained via a syncronous binarization procedure (Zhang et al., 2006). The CKY-style decoder computes the probability of English syntactic constituents in a bottom up fashion, by log-linearly interpolating all the submodel scores described in Section 2.3. The decoder is capable of producing nbest derivations and nbest lists (Knight and Graehl, 2005), which are used for Maximum Bleu training (Och, 2003). When decoding the test corpus, the decoder returns the translation that has the most probable derivation; in other words, the sum operator in equation 4 is replaced with an argmax. 3.2 Decoding with multiple SPMT models Combining multiple MT outputs to increase </context>
</contexts>
<marker>Zhang, Huang, Gildea, Knight, 2006</marker>
<rawString>Hao Zhang, Liang Huang, Daniel Gildea, and Kevin Knight. 2006. Syncronous binarization for machine translation. In Proceding of the Human Language Technology and North American Chapter of the Associationfor Computational Linguistics (HLTNAACL’2006), New York, June.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>