<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000027">
<figure confidence="0.361160375">
BOOK REVIEWS
AN ARTIFICIAL INTELLIGENCE APPROACH TO LEGAL
REASONING
Anne von der Lieth Gardner
Cambridge, MA: MIT Press, 1987, xiii + 225 pp.
ISBN 0-262-07104-5; $22.50 (hb)
Reviewed by
Martha Evens
</figure>
<affiliation confidence="0.859268">
Illinois Institute of Technology
</affiliation>
<bodyText confidence="0.99693138028169">
This book provides an extremely well-written introduc-
tion to legal artificial intelligence combined with a
highly original approach to problems of legal reasoning.
Although this book is a revised version of her Ph.D.
thesis, Gardner&apos;s ideas are mature and the exposition is
designed to make both legal and computational prob-
lems clear to the general reader. These ideas are em-
bodied in an automated system for solving offer and
acceptance problems in contract law.
Chapter 1 provides an introduction to the problems
of modeling legal reasoning. One major complication is
the open texture or incomplete definition of many legal
predicates. Another is that the program must be able to
distinguish between problems it can handle and those
that may well cause experts to disagree. The choice of
offer and acceptance problems in contract law as a
problem domain has the advantage that this area does
not require a great deal of legal background. Also these
problems make more use of case law than of statutes;
thus they are rule-guided but not rule-governed.
Chapter 2 goes more deeply into the place of rules in
legal reasoning. From the point of view of the expert
system designer, the law has certain advantages. Law-
yers have been known to write down explicit, if non-
computational, rules for legal reasoning, although much
of this work is controversial. Chapter 3 goes on to
discuss the problem of applying rules to the stated facts
of the case. Rules of commonsense knowledge are
necessary here as well as heuristics for understanding
cases and recognizing examples of patterns. Chapter 4
relates this research to other work in legal artificial
intelligence.
Chapter 5 attacks problems of the representation of
natural language text. The facts of a problem are
translated into a set of logical formulas in the predicate-
calculus syntax of Genesereth&apos;s MRS. The representa-
tion methodology pays particular attention to reported
speech, an important feature of contract cases. Analysis
of the predicate-calculus representation determines
whether any given speech act has the effective force of
a declaration. Then declarations are further analyzed to
see whether they are indeed legal acts.
Chapter 6 focuses on a different kind of representa-
tion problem, the problem of representing legal knowl-
edge. Knowledge of the basic legal categories and the
way elements of those categories may be ordered is
represented in an augmented transition network with
arcs labeled &amp;quot;offer&amp;quot;, &amp;quot;acceptance&amp;quot;, etc. Knowledge of
the definitions of the major categories is expressed in
&amp;quot;if. . . then&amp;quot; rules. Knowledge about undefined pred-
icates is expressed in the representation system already
developed for representing text in the previous chapter.
Finally, Chapter 7 traces the operations of Dr Gardner&apos;s
system on a number of illuminating example problems,
annotated with insightful comments. Her program is
written in a combination of MRS and MacLisp and runs
on a DecSystem-20 at Stanford.
In summary, this book provides a fascinating com-
putational framework for modeling legal reasoning,
combining automated reasoning, concepts from legal
theory, and techniques for representing legal knowledge
and natural language text. For the computational lin-
guist the most interesting sections are the discussion of
speech acts and the methodology for representing re-
ported speech in Chapter 5.
Martha Evens is a past president of the ACL. She and James
Sprowl developed the legal document generation system
ABF. Her present research concerns computational uses of
on-line dictionaries, especially for text generation. Evens&apos;s
address is: Department of Computer Science, Illinois Institute
of Technology, 10 West 31st Street, Chicago, IL 60616.
</bodyText>
<email confidence="0.647993">
E-mail: csevens@iitvax.bitnet
</email>
<sectionHeader confidence="0.950778" genericHeader="abstract">
MATHEMATICS OF LANGUAGE
</sectionHeader>
<subsectionHeader confidence="0.6060935">
Alexis Manaster-Ramer (ed.)
(Wayne State University)
</subsectionHeader>
<bodyText confidence="0.661114666666667">
Amsterdam: John Benjamins, 1987, x + 401 pp.
ISBN 1-55619-032-8 and 90-272-2049-2, Dfl 125.-,
$50.00 (hb)
</bodyText>
<figure confidence="0.441505">
Reviewed by
Barron Brainerd
</figure>
<subsubsectionHeader confidence="0.49583">
University of Toronto
</subsubsectionHeader>
<bodyText confidence="0.997157605042017">
The editor takes the mathematics of language to mean
&amp;quot;the mathematical properties that may—under certain
assumptions about modeling—be attributed to human
language and related symbolic systems, as well as the
increasingly active and autonomous scholarly discipline
Computational Linguistics, Volume 15, Number 1, March 1989 53
Book Reviews Mathematics of Language
that studies such things.&amp;quot; This is an umbrella under
which almost all of us can shelter. Indeed, the book
contains, according to the editor, &amp;quot;applications of the
several fields of the theory of computation (formal
languages, automata, complexity), formal logic, topol-
ogy, set theory, graph theory, and statistics.&amp;quot; This sort
of hyperbole seems to be almost essential to the genre.
Take graph theory as an example: there are lots of
graphs in the book but little of the theory of same comes
into play within the discussions.
The book is not well edited: there are references to
texts not in bibliographies (p. 4), typos (e.g., pp. 3, 181,
258, 260, 281), missing edges on graphs (p. 194), page
permutations (p. 273 should follow 271 directly) to
mention only the tip of the iceberg.
The informal style is sometimes too much so: Kuroda
(A &amp;quot;topological approach to structural equivalence of
formal languages&amp;quot;), for example, defines a partial sen-
tence as a subtree of the tree corresponding to a
sentence of a grammar G with at least one terminal
attached and then says, a little later, that the sentences
of a regular language are the only partial sentences! In
general, the exposition is too casual to the extent that it
is not clear what the space being topologized is—the
trees in K or the subtrees in K. Finally, he makes
statements asserting the existence of homeomorphisms
without specifying the mappings—cf. particularly pp.
184 and 185. The paper finally founders in vagueness at
the end.
The papers are uneven in length, quality, and degree
of specificity—some being lists of theorems, in some
cases not proved even elsewhere (Kac and Kuroda).
The longest paper (56 pages), Roach&apos;s &amp;quot;Formal proper-
ties of head grammars&amp;quot;, though potentially very inter-
esting, is marred by expositional infelicities such as a
lack of examples to support the definitions, multiple
reference (N can be either the natural numbers or a set
of nonterminal symbols), the introduction of unspeci-
fied symbols (u, g, v, w, h, and x in Definition 9), and a
general peppering of typos. It takes a more devoted
reader than this one to bother sorting it all out.
The shortest paper (12 pages), Walter J. Savitch&apos;s
&amp;quot;Theories of language learnability&amp;quot;, is at the other end
of the spectrum. It investigates definitions of formal
learnability and shows that they tend either to accept all
recursively enumerable languages as learnable or only
finite languages as learnable. And then he suggests,
&amp;quot;Why not finite languages?&amp;quot; These would be too large
for the learner to learn the language as a list, but s/he
might achieve economy of description &amp;quot;in going from
finite to context-free descriptions&amp;quot; (p. 370). There&apos;s a
lot to be said for the notion that present-day English is
&amp;quot;essentially&amp;quot; finite, and in order to be &amp;quot;learnable&amp;quot;, its
structure must be organized in some way. The learning
process is then the internalization of the organization in
some form.
&amp;quot;Finding natural languages a home in formal lan-
guage theory&amp;quot;, by Rounds, Manaster-Ramer, and
Friedman, suggests, &amp;quot;instead of regarding a language as
a monolithic infinite collection of strings, we consider it
a sequence of finite languages, each of which is an
approximation to the ideal infinite language&amp;quot; (p. 354).
Their concern is then with economy of description of
these approximating languages. A CFG is profligate if it
has more nonterminal than terminal symbols. They then
show that no nonprofligate CFG exists for a language
with mirror images as a productive grammatical device.
Since we would like grammars to be non-profligate and
natural languages don&apos;t support productive mirror im-
ages, there seems to be no problem here, but the
authors show an analogous result for finitely productive
reduplication. Since natural languages do reduplicate, in
order to achieve economy of description we must go
beyond CFGs to generate natural languages.
The second-longest paper, &amp;quot;On the design of finite
transducers for parsing phrase-structure languages&amp;quot; by
Langendoen and Langsam, defines a finite transducer
that recognizes a context-free fragment of English that
contains left and right embedding and finite central
embedding. They argue that &amp;quot;the theory of finite trans-
ducers . . . is appropriate as a theory of a person&apos;s
knowledge of a natural language, but that a more
powerful theory is needed as a theory of natural lan-
guage itself&apos; (p. 234).
The papers of Berwick and Ristad are concerned
with inadequacies of various models popular among
present-day linguists. Berwick (&amp;quot;Computational com-
plexity, mathematical linguistics, and linguistic the-
ory&amp;quot;) makes the point that we &amp;quot;should not be looking
for some familiar natural mathematical class of objects
as coextensive with the natural languages; rather we
should first try to determine what the properties of
natural languages are, and then fix their mathematical
properties&amp;quot; (p. 2). He proceeds to outline some of the
shortcomings of GPSG, GB, and LFG theories in terms
of complexity theory.
Ristad (&amp;quot;Sources of intractability in GPSG theory&amp;quot;)
gives a clear exposition of the notion NP-hard and
proves that GPSG-recognition is NP-hard and hence
GPSGs as they stand are not parsable in polynomial
time.
Marsh (&amp;quot;Graphs and grammars&amp;quot;) deals with classes
of grammars (extensions of CFGs), the structure of
whose outputs is depicted using directed acyclic graphs
that are not trees—in particular Pereira&apos;s extraposition
grammars, phrase-linking grammars of Peters and Rit-
chie, and his mother-and-daughter grammars. He inves-
tigates their generating power and closure properties.
Proofs included!
Ojeda (&amp;quot;Discontinuity and phrase structure gram-
mar&amp;quot;) extends the GPSG model beyond trees in an
attempt to handle discontinuous constituents in Spanish
</bodyText>
<page confidence="0.967611">
54 Computational Linguistics, Volume 15, Number 1, March 1989
</page>
<note confidence="0.503894">
Book Reviews The Vastness of Natural Languages
</note>
<bodyText confidence="0.991148253968254">
and English. His extension is to my mind ad hoc and
although it works for his examples, might not adapt
itself to more complex problems like negation in
French.
Karen Jensen (&amp;quot;Binary rules and nonbinary trees:
Breaking down the concept of phrase structure&amp;quot;) is
concerned with the passage from binary rules (and
trees) that capture significant generalizations about nat-
ural languages to list structures that are more satisfac-
tory for further processing. Her solution can handle
discontinuous constituents and is suitable for treating
languages with free word order.
In &amp;quot;The notion of &apos;rule of grammar&apos; reconsidered&amp;quot;
Michael Kac defends the notion that &amp;quot;grammatical
analysis requires that we have a way of formally repre-
senting the variety of distinct etiological properties that
can be manifested by ungrammatical strings, this diver-
sity corresponding to the variety of distinct rules of
grammar&amp;quot; (p. 137). He argues that getting the standard
linguistic theories (various versions of TG, GPSG, etc.)
to serve the purpose of etiological analysis is &amp;quot;problem-
atical&amp;quot;. His &amp;quot;fundamental principles&amp;quot; (pp. 120, 122)
appear to require that a grammar supply a structure not
only for elements of the language L that it generates but
also for the elements in the complement of L. In his
formal development, however, he defines an object
(Definition 9) in terms of itself and this circularity would
appear to render the result ill-defined. Since his main
argument depends on this definition, I stopped reading.
It is a good practice to buttress complicated definitions
with examples both for the good of the writer as well as
that of the reader.
There are three papers on tree-adjoining grammars:
an introduction by Joshi, &amp;quot;Unbounded dependencies
and subjacency in a tree adjoining grammar&amp;quot; by A.S.
Kroch, and &amp;quot;On the progression from context-free to
tree adjoining languages&amp;quot; by Joshi et al. This presents
an easy access to a useful collection of results concern-
ing a rather pregnant linguistic model.
Finally, three of the papers are concerned with
semantics proper. G.N. Carlson&apos;s &amp;quot;Exceptions to ge-
neric generalizations&amp;quot; deals with the construction of a
formal semantics using a sort of default mechanism in
order to interpret statements like &amp;quot;Dogs bark&amp;quot; when
clearly barkless dogs exist. Davis and Papcun in &amp;quot;The
structure underlying a semantic domain&amp;quot; provide a
rather metaphorical model yr (volumetric representa-
tion) &amp;quot;to formalize lexical knowledge in a practical
way&amp;quot;. They investigate various models—semantic net-
works, multi-dimensional scaling, and clustering—be-
fore settling on their own spatial (and somewhat inten-
sional) model of a semantic domain. The third paper,
R.H. Thomason&apos;s &amp;quot;Remarks on linguistic semantics&amp;quot;,
is an expository article concerned with the interface
between linguistics and philosophy, dealing with the
literature of such topics as tense and aspect, proposi-
tional attitudes, and vagueness.
Barron Brainerd is Professor of Mathematics and Linguistics
at the University of Toronto. He is the author of Weighing
Evidence in Language and Literature: A Statistical Approach
and Introduction to the Mathematics of Language Study.
Brainerd&apos;s address is: Department of Mathematics, Univer-
sity of Toronto, Toronto, Ontario, Canada M5S 1AL
</bodyText>
<sectionHeader confidence="0.944679" genericHeader="categories and subject descriptors">
THE VASTNESS OF NATURAL LANGUAGES
</sectionHeader>
<reference confidence="0.7112529">
D. Terence Langendoen and Paul M. Postal
(Graduate Center, City University of New York and
IBM Thomas J. Watson Research Center,
Yorktown Heights, NY)
Oxford, England; Basil Blackwell, 1984, ix + 189 pp.
ISBN 0-631-13461-1 (hb); ISBN 0-631-14756-X, £8.95
(sb)
Reviewed by
James V. Rauff
Millikin University
</reference>
<bodyText confidence="0.959957210526316">
This book is an extended argument in support of the
theses that natural languages are transfinitely un-
bounded collections, that sentences are not limited in
length (number of words) by any cardinal number, finite
or transfinite, and that no constructive grammar can be
an adequate grammar for any natural language.
Chapter 1 is an introduction to those aspects of set
theory needed to develop the main points of the book.
Specifically, the notion of a class arising from Cantor&apos;s
and Russell&apos;s paradoxes and the Cantor power set are
introduced.
Chapter 2 sets forth what the authors call the &amp;quot;re-
ceived position about natural languages&amp;quot; (hereafter
NLs). The received position is that NL sentences are
finite in length. Length is defined in terms of number of
words, although the authors argue later that we could
just as well count phonemes as words without seriously
affecting their arguments. NLs as collections of finite-
length sentences are therefore countably infinite (or
denumerable). Finally, related to the finiteness of sen-
tences is the &amp;quot;received position&amp;quot; that grammars for
NLs are constructive.
Chapter 3 argues that there is &amp;quot;no motivation for
imposing size laws on NL sentences&amp;quot; (p. 44). Invoking
Occam&apos;s Razor, the authors claim that size laws are
extra-linguistic restrictions not needed for grammatical
description and therefore unjustified.
Chapter 4 presents the main theoretical points of the
book. Taking as axiomatic for NLs a property of
coordination that allows for unrestricted coordinate
compounding of sentences, the authors present the NL
Vastness Theorem, which asserts that NLs are not sets,
but rather classes with no fixed cardinality. The argu-
ment can be illustrated with their example (pp. 55-57):
I. Let L be the NL English.
2. The set So is contained in L, where
So = {Babar is happy; I know that Babar is happy;
I know that I know that Babar is happy; . . .}
</bodyText>
<page confidence="0.231308">
Computational Linguistics, Volume 15, Number 1, March 1989 55
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.549768">
<title confidence="0.989764">BOOK REVIEWS AN ARTIFICIAL INTELLIGENCE APPROACH TO LEGAL REASONING</title>
<author confidence="0.957586">Anne von_der_Lieth Gardner</author>
<address confidence="0.660236">Cambridge, MA: MIT Press, 1987, xiii + 225 pp.</address>
<note confidence="0.9805955">ISBN 0-262-07104-5; $22.50 (hb) Reviewed by</note>
<author confidence="0.997757">Martha Evens</author>
<affiliation confidence="0.996073">Illinois Institute of Technology</affiliation>
<abstract confidence="0.989200333333333">This book provides an extremely well-written introduction to legal artificial intelligence combined with a highly original approach to problems of legal reasoning. Although this book is a revised version of her Ph.D. thesis, Gardner&apos;s ideas are mature and the exposition is designed to make both legal and computational problems clear to the general reader. These ideas are embodied in an automated system for solving offer and acceptance problems in contract law.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>D Terence Langendoen</author>
<author>M Paul</author>
</authors>
<publisher>Postal</publisher>
<marker>Langendoen, Paul, </marker>
<rawString>D. Terence Langendoen and Paul M. Postal</rawString>
</citation>
<citation valid="false">
<authors>
<author>IBM Thomas J</author>
</authors>
<title>Watson Research Center,</title>
<institution>Graduate Center, City University of New York</institution>
<location>Yorktown Heights, NY</location>
<marker>J, </marker>
<rawString>(Graduate Center, City University of New York and IBM Thomas J. Watson Research Center, Yorktown Heights, NY)</rawString>
</citation>
<citation valid="true">
<authors>
<author>England Oxford</author>
<author>Basil Blackwell</author>
</authors>
<date>1984</date>
<journal>ix +</journal>
<volume>189</volume>
<pages>0--631</pages>
<note>(hb); ISBN 0-631-14756-X, £8.95 (sb)</note>
<marker>Oxford, Blackwell, 1984</marker>
<rawString>Oxford, England; Basil Blackwell, 1984, ix + 189 pp. ISBN 0-631-13461-1 (hb); ISBN 0-631-14756-X, £8.95 (sb)</rawString>
</citation>
<citation valid="false">
<authors>
<author>Reviewed by James V</author>
</authors>
<institution>Rauff Millikin University</institution>
<marker>V, </marker>
<rawString>Reviewed by James V. Rauff Millikin University</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>