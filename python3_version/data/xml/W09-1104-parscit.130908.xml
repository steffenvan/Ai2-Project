<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001049">
<title confidence="0.999272">
Data-Driven Dependency Parsing of New Languages
Using Incomplete and Noisy Training Data
</title>
<author confidence="0.99487">
Kathrin Spreyer and Jonas Kuhn
</author>
<affiliation confidence="0.9987055">
Department of Linguistics
University of Potsdam, Germany
</affiliation>
<email confidence="0.998014">
{spreyer,kuhn}@ling.uni-potsdam.de
</email>
<sectionHeader confidence="0.997376" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.993907619047619">
We present a simple but very effective ap-
proach to identifying high-quality data in
noisy data sets for structured problems like
parsing, by greedily exploiting partial struc-
tures. We analyze our approach in an anno-
tation projection framework for dependency
trees, and show how dependency parsers from
two different paradigms (graph-based and
transition-based) can be trained on the result-
ing tree fragments. We train parsers for Dutch
to evaluate our method and to investigate
to which degree graph-based and transition-
based parsers can benefit from incomplete
training data. We find that partial correspon-
dence projection gives rise to parsers that out-
perform parsers trained on aggressively fil-
tered data sets, and achieve unlabeled attach-
ment scores that are only 5% behind the aver-
age UAS for Dutch in the CoNLL-X Shared
Task on supervised parsing (Buchholz and
Marsi, 2006).
</bodyText>
<sectionHeader confidence="0.999478" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999953058823529">
Many weakly supervised approaches to NLP rely on
heuristics or filtering techniques to deal with noise
in unlabeled or automatically labeled training data,
e.g., in the exploitation of parallel corpora for cross-
lingual projection of morphological, syntactic or se-
mantic information. While heuristic approaches can
implement (linguistic) knowledge that helps to de-
tect noisy data (e.g., Hwa et al. (2005)), they are typ-
ically task- and language-specific and thus introduce
a component of indirect supervision. Non-heuristic
filtering techniques, on the other hand, employ re-
liability measures (often unrelated to the task) to
predict high-precision data points (e.g., Yarowsky
et al. (2001)). In order to reach a sufficient level
of precision, filtering typically has to be aggressive,
especially for highly structured tasks like parsing.
Such aggressive filtering techniques incur massive
data loss and enforce trade-offs between the quality
and the amount of usable data.
Ideally, a general filtering strategy for weakly su-
pervised training of structured analysis tools should
eliminate noisy subparts in the automatic annota-
tion without discarding its high-precision aspects;
thereby data loss would be kept to a minimum.
In this paper, we propose an extremely simple ap-
proach to noise reduction which greedily exploits
partial correspondences in a parallel corpus, i.e.,
correspondences potentially covering only substruc-
tures of translated sentences. We implemented this
method in an annotation projection framework to
create training data for two dependency parsers rep-
resenting different parsing paradigms: The MST-
Parser (McDonald et al., 2005) as an instance of
graph-based dependency parsing, and the Malt-
Parser (Nivre et al., 2006) to represent transition-
based dependency parsing. In an empirical evalu-
ation, we investigate how they react differently to
incomplete and noisy training data.
Despite its simplicity, the partial correspondence
approach proves very effective and leads to parsers
that achieve unlabeled attachment scores that are
only 5% behind the average UAS for Dutch in the
CoNLL-X Shared Task (Buchholz and Marsi, 2006).
After a summary of related work in Sec. 2, we
discuss dependency tree projection (Sec. 3) and par-
tial correspondence (Sec. 4). In Sec. 5, we give an
overview of graph- and transition-based dependency
parsing and describe how each can be adapted for
training on partial training data in Sec. 6. Experi-
mental results are presented in Sec. 7, followed by
an analysis in Sec. 8. Sec. 9 concludes.
</bodyText>
<page confidence="0.984676">
12
</page>
<note confidence="0.9625572">
Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL), pages 12–20,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
a. b. c.
English (L1): I have two questions You are absolutely right You are absolutely right
Dutch (L2): Ik heb twee vragen U heeft volkomen gelijk U heeft volkomen gelijk
</note>
<page confidence="0.736162">
3
2
</page>
<figureCaption confidence="0.9855485">
Figure 1: Dependency tree projection from English to Dutch. (a) Ideal scenario with bidirectional alignments. (b)
Projection fails due to weak alignments. (c) Constrained fallback projection.
</figureCaption>
<note confidence="0.296696">
1
</note>
<sectionHeader confidence="0.999696" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.995559490566038">
Annotation projection has been applied to many dif-
ferent NLP tasks. On the word or phrase level, these
include morphological analysis, part-of-speech tag-
ging and NP-bracketing (Yarowsky et al., 2001),
temporal analysis (Spreyer and Frank, 2008), or se-
mantic role labeling (Pad´o and Lapata, 2006). In
these tasks, word labels can technically be intro-
duced in isolation, without reference to the rest of
the annotation. This means that an aggressive filter
can be used to discard unreliable data points (words
in a sentence) without necessarily affecting high-
precision data points in the same sentence. By us-
ing only the bidirectional word alignment links, one
can implement a very robust such filter, as the bidi-
rectional links are generally reliable, even though
they have low recall for overall translational cor-
respondences (Koehn et al., 2003). The bidirec-
tional alignment filter is common practice (Pad´o and
Lapata, 2006); a similar strategy is to discard en-
tire sentences with low aggregated alignment scores
(Yarowsky et al., 2001).
On the sentence level, Hwa et al. (2005) were
the first to project dependency trees from English
to Spanish and Chinese. They identify unreliable
target parses (as a whole) on the basis of the num-
ber of unaligned or over-aligned words. In addition,
they manipulate the trees to accommodate for non-
isomorphic sentences. Systematic non-parallelisms
between source and target language are then ad-
dressed by hand-crafted rules in a post-projection
step. These rules account for an enormous increase
in the unlabeled f-score of the direct projections,
from 33.9 to 65.7 for Spanish and from 26.3 to 52.4
for Chinese. But they need to be designed anew for
every target language, which is time-consuming and
requires knowledge of that language.
Research in the field of unsupervised and weakly
supervised parsing ranges from various forms of EM
training (Pereira and Schabes, 1992; Klein and Man-
ning, 2004; Smith and Eisner, 2004; Smith and Eis-
ner, 2005) over bootstrapping approaches like self-
training (McClosky et al., 2006) to feature-based
enhancements of discriminative reranking models
(Koo et al., 2008) and the application of semi-
supervised SVMs (Wang et al., 2008). The partial
correspondence method we present in this paper is
compatible with such approaches and can be com-
bined with other weakly supervised machine learn-
ing schemes. Our approach is similar to that of
Clark and Curran (2006) who use partial training
data (CCG lexical categories) for domain adaptation;
however, they assume an existing CCG resource for
the language in question to provide this data.
</bodyText>
<sectionHeader confidence="0.901119" genericHeader="method">
3 Projection of Dependency Trees
</sectionHeader>
<bodyText confidence="0.999762368421053">
Most state-of-the-art parsers for natural languages
are data-driven and depend on the availability of suf-
ficient amounts of labeled training data. However,
manual creation of treebanks is time-consuming and
labour-intensive. One way to avoid the expensive
annotation process is to automatically label the train-
ing data using annotation projection (Yarowsky et
al., 2001): Given a suitable resource (such as a
parser) in language L1, and a word-aligned paral-
lel corpus with languages L1 and L2, label the L1-
portion of the parallel text (with the parser) and copy
the annotations to the corresponding (i.e., aligned)
elements in language L2. This is illustrated in Fig.
1a. The arrows between English and Dutch words
indicate the word alignment. Assuming we have a
parser to produce the dependency tree for the En-
glish sentence, we build the tree for the Dutch sen-
tence by establishing arcs between words wD (e.g.,
Ik) and hD (heb) if there are aligned pairs (wD, wE)
</bodyText>
<page confidence="0.998706">
13
</page>
<table confidence="0.999519666666667">
#sents w/ avg. sent vocab
projected parse length (lemma)
unfiltered (100,000) 24.92 19,066
bidirectional 2,112 6.39 1,905
fallback 6,426 9.72 4,801
bi+frags≤3 7,208 9.44 4,631
</table>
<tableCaption confidence="0.999626">
Table 1: Data reduction effect of noise filters.
</tableCaption>
<bodyText confidence="0.999776448275862">
(Ik and I) and (hD, hE) (heb and have) such that hE
is the head of wE in the English tree.
Annotation projection assumes direct correspon-
dence (Hwa et al., 2005) between languages (or
annotations), which—although it is valid in many
cases—does not hold in general: non-parallelism
between corresponding expressions in L1 and L2
causes errors in the target annotations. The word
alignment constitutes a further source for errors if it
is established automatically—which is typically the
case in large parallel corpora.
We have implemented a language-independent
framework for dependency projection and use the
Europarl corpus (Koehn, 2005) as the parallel text.
Europarl consists of the proceedings of the Euro-
pean Parliament, professionally translated in 11 lan-
guages (approx. 30mln words per language). The
data was aligned on the word level with GIZA++
(Och and Ney, 2003).1 In the experiments reported
here, we use the language pair English-Dutch, with
English as the source for projection (L1) and Dutch
as L2. The English portion of the Europarl cor-
pus was lemmatized and POS tagged with the Tree-
Tagger (Schmid, 1994) and then parsed with Malt-
Parser (which is described in Sec. 6), trained on a
dependency-converted version of the WSJ part from
the Penn Treebank (Marcus et al., 1994), but with
the automatic POS tags. The Dutch sentences were
only POS tagged (with TreeTagger).2
</bodyText>
<subsectionHeader confidence="0.998217">
3.1 Data Loss Through Filtering
</subsectionHeader>
<bodyText confidence="0.913909225806452">
We quantitatively assess the impact of various fil-
tering techniques on a random sample of 100,000
English-Dutch sentence pairs from Europarl (avg.
1Following standard practice, we computed word align-
ments in both directions (L1 → L2 and L2 → L1); this gives
rise to two unidirectional alignments. The bidirectional align-
ment is the intersection of the two unidirectional ones.
2The Dutch POS tags are used to train the monolingual
parsers from the projected dependency trees (Sec. 7).
24.9 words/sentence). The English dependency
trees are projected to their Dutch counterparts as ex-
plained above for Fig. 1a.
The first filter we examine is the one that consid-
ers exclusively bidirectional alignments. It admits
dependency arcs to be projected only if the head hE
and the dependent wE are each aligned bidirection-
ally with some word in the Dutch sentence. This is
indicated in Fig. 1b, where the English verb are is
aligned with the Dutch translation heeft only in one
direction. This means that none of the dependencies
involving are are projected, and the projected struc-
ture is not connected. We will discuss in subsequent
sections how less restricted projection methods can
still incorporate such data.
Table 1 shows the quantitative effect of the bidi-
rectional filter in the row labeled ‘bidirectional’. The
proportion of usable sentences is reduced to 2.11%.
Consequently, the vocabulary size diminishes by a
factor of 10, and the average sentence length drops
considerably from almost 25 to less than 7 words,
suggesting that most non-trivial examples are lost.
</bodyText>
<subsectionHeader confidence="0.999633">
3.2 Constrained Fallback Projection
</subsectionHeader>
<bodyText confidence="0.997699625">
As an instance of a more relaxed projection of com-
plete structures, we also implemented a fallback to
unidirectional links which projects further depen-
dencies after a partial structure has been built based
on the more reliable bidirectional links. That is, the
dependencies established via unidirectional align-
ments are constrained by the existing subtrees, and
are subject to the wellformedness conditions for de-
pendency trees.3 Fig. 1c shows how the fallback
mechanism, initialized with the unconnected struc-
ture built with the bidirectional filter, recovers a
parse tree for the weakly aligned sentence pair in
Fig. 1b. Starting with the leftmost word in the Dutch
sentence and its English translation (U and You),
there is a unidirectional alignment for the head of
You: are is aligned to heeft, so U is established as
a dependent of heeft via fallback. Likewise, heeft
can now be identified as the root node. Note that the
(incorrect) alignment between heeft and You will not
be pursued because it would lead to heeft being a de-
pendent of itself and thus violating the wellformed-
3I.e., single headedness and acyclicity; we do not require the
trees to be projective, but instead train pseudo-projective models
(Nivre and Nilsson, 2005) on the projected data (cf. fn. 5).
</bodyText>
<page confidence="0.995331">
14
</page>
<table confidence="0.998986428571429">
#frags 1 2 3 4–15 &gt;15
#words
&lt;4 425 80 12 – –
4–9 1,331 1,375 1,567 4,793 –
10–19 339 859 1,503 27,910 522
20–30 17 45 143 20,756 10,087
&gt;30 0 5 5 4,813 23,362
</table>
<tableCaption confidence="0.991896333333333">
Table 2: Fragmented parses projected with the alignment
filter. The sentences included in the data set ‘bi+frags≤3’
are in boldface.
</tableCaption>
<bodyText confidence="0.999422111111111">
ness conditions. Finally, the subtree rooted in gelijk
is incorporated as the second dependent of heeft.
As expected, the proportion of examples that pass
this filter rises, to 6.42% (Table 1, ‘fallback’). How-
ever, we will see in Sec. 7 that parsers trained on
this data do not improve over parsers trained on the
bidirectionally aligned sentences alone. This is pre-
sumably due to the noise that inevitably enters the
training data through fallback.
</bodyText>
<sectionHeader confidence="0.988951" genericHeader="method">
4 Partial Correspondence Projection
</sectionHeader>
<bodyText confidence="0.996548595238095">
So far, we have only considered complete trees,
i.e., projected structures with exactly one root node.
This is a rather strict requirement, given that even
state-of-the-art parsers sometimes fail to produce
plausible complete analyses for long sentences, and
that non-sentential phrases such as complex noun
phrases still contain valuable, non-trivial informa-
tion. We therefore propose partial correspondence
projection which, in addition to the complete anno-
tations produced by tree-oriented projection, yields
partial structures: It admits fragmented analyses in
case the tree-oriented projection cannot construct a
complete tree. Of course, the nature of those frag-
ments needs to be restricted so as to exclude data
with no (interesting) dependencies. E.g., a sentence
of five words with a parse consisting of five frag-
ments provides virtually no information about de-
pendency structure. Hence, we impose a limit (fixed
at 3 after quick preliminary tests on automatically
labeled development data) on the number of frag-
ments that can make up an analysis. Alternatively,
one could require a minimum fragment size.
As an example, consider again Fig. 1b. This ex-
ample would be discarded in strict tree projection,
but under partial correspondence it is included as a
partial analysis consisting of three fragments:
U heeft volkomen gelijk
Although the amount of information provided in
this analysis is limited, the arc between gelijk and
volkomen, which is strongly supported by the align-
ment, can be established without including poten-
tially noisy data points that are only weakly aligned.
We use partial correspondence in combination
with bidirectional projection.4 As can be seen in
Table 1 (‘bi+frags≤3’), this combination boosts the
amount of usable data to a range similar to that of
the fallback technique for trees; but unlike the latter,
partial correspondence continues to impose a high-
precision filter (bidirectionality) while improving re-
call through relaxed structural requirements (partial
correspondence). Table 2 shows how fragment size
varies with sentence length.
</bodyText>
<sectionHeader confidence="0.993229" genericHeader="method">
5 Data-driven Dependency Parsing
</sectionHeader>
<bodyText confidence="0.9998975">
Models for data-driven dependency parsing can be
roughly divided into two paradigms: Graph-based
and transition-based models (McDonald and Nivre,
2007).
</bodyText>
<subsectionHeader confidence="0.692918">
5.1 Graph-based Models
</subsectionHeader>
<bodyText confidence="0.9987125">
In the graph-based approach, global optimization
considers all possible arcs to find the tree Tˆ s.t.
</bodyText>
<equation confidence="0.989490666666667">
1] s(T) = arg max
TED
(i,j,l)EAT
</equation>
<bodyText confidence="0.999984636363636">
where D is the set of all well-formed dependency
trees for the sentence, AT is the set of arcs in T, and
s(i, j, l) is the score of an arc between words wi and
wj with label l. The specific graph-based parser we
use in this paper is the MSTParser of McDonald et
al. (2005). The MSTParser learns the scoring func-
tion s using an online learning algorithm (Crammer
and Singer, 2003) which maximizes the margin be-
tween Tˆ and D \ { Tˆ }, based on a loss function that
counts the number of words with incorrect parents
relative to the correct tree.
</bodyText>
<subsectionHeader confidence="0.866383">
5.2 Transition-based Models
</subsectionHeader>
<bodyText confidence="0.808796">
In contrast to the global optimization employed in
graph-based models, transition-based models con-
struct a parse tree in a stepwise way: At each point,
4Fragments from fallback projection turned out not to be
helpful as training data for dependency parsers.
</bodyText>
<equation confidence="0.977572666666667">
Tˆ = arg max
TED
s(i, j, l)
</equation>
<page confidence="0.961888">
15
</page>
<bodyText confidence="0.999621666666667">
the locally optimal parser action (transition) t* is de-
termined greedily on the basis of the current config-
uration c (previous actions plus local features):
</bodyText>
<equation confidence="0.99524">
t* = arg max
tET
</equation>
<bodyText confidence="0.9998568">
where T is the set of possible transitions. As a rep-
resentative of the transition-based paradigm, we use
the MaltParser (Nivre et al., 2006). It implements in-
cremental, deterministic parsing algorithms and em-
ploys SVMs to learn the transition scores s.
</bodyText>
<sectionHeader confidence="0.897345" genericHeader="method">
6 Parsing with Fragmented Trees
</sectionHeader>
<bodyText confidence="0.999319722222222">
To make effective use of the fragmented trees pro-
duced by partial correspondence projection, both
parsing approaches need to be adapted for training
on sentences with unconnected substructures. Here
we briefly discuss how we represent these structures,
and then describe how we modified the parsers.
We use the CoNLL-X data format for dependency
trees (Buchholz and Marsi, 2006) to encode partial
structures. Specifically, every fragment root spec-
ifies as its head an artificial root token w0 (distin-
guished from a true root dependency by a special
relation FRAG). Thus, sentences with a fragmented
parse are still represented as a single sentence, in-
cluding all words; the difference from a fully parsed
sentence is that unconnected substructures are at-
tached directly under w0. For instance, the partial
parse in Fig. 1b would be represented as follows (de-
tails omitted):
</bodyText>
<equation confidence="0.84677925">
(1) 1 U pron 0 FRAG
2 heeft verb 0 ROOT
3 volkomen adj 4 mod
4 gelijk noun 0 FRAG
</equation>
<subsectionHeader confidence="0.907327">
6.1 Graph-based Model: fMST
</subsectionHeader>
<bodyText confidence="0.999980052631579">
In the training phase, the MSTParser tries to max-
imize the scoring margin between the correct parse
and all other valid dependency trees for the sentence.
However, in the case of fragmented trees, the train-
ing example is not strictly speaking correct, in the
sense that it does not coincide with the desired parse
tree. In fact, this desired tree is among the other
possible trees that MST assumes to be incorrect, or
at least suboptimal. In order to relax this assump-
tion, we have to ensure that the loss of the desired
tree is zero. While it is impossible to single out this
one tree (since we do not know which one it is), we
can steer the margin in the right direction with a loss
function that assigns zero loss to all trees that are
consistent with the training example, i.e., trees that
differ from the training example at most on those
words that are fragment roots (e.g., gelijk in Fig. 1).
To reflect this notion of loss during optimization, we
also adjust the definition of the score of a tree:
</bodyText>
<equation confidence="0.987942">
s(T) = � s(i, j, l)
(i,j,l)EAT: l�FRAG
</equation>
<bodyText confidence="0.991776">
We refer to this modified model as f(iltering)MST.
</bodyText>
<subsectionHeader confidence="0.946211">
6.2 Transition-based Model: fMalt
</subsectionHeader>
<bodyText confidence="0.999988210526316">
In the transition-based paradigm, it is particularly
important to preserve the original context (includ-
ing unattached words) of a partial analysis, because
the parser partly bases its decisions on neighboring
words in the sentence.
Emphasis of the role of isolated FRAG dependents
as context rather than proper nodes in the tree can
be achieved, as with the MSTParser, by eliminat-
ing their effect on the margin learned by the SVMs.
Since MaltParser scores local decisions, this simply
amounts to suppressing the creation of SVM train-
ing instances for such nodes (U and gelijk in (1)).
That is, where the feature model refers to context
information, unattached words provide this infor-
mation (e.g., the feature vector for volkomen in (1)
contains the form and POS of gelijk), but there are
no instances indicating how they should be attached
themselves. This technique of excluding fragment
roots during training will be referred to as fMalt.
</bodyText>
<sectionHeader confidence="0.999151" genericHeader="method">
7 Experiments
</sectionHeader>
<subsectionHeader confidence="0.964279">
7.1 Setup
</subsectionHeader>
<bodyText confidence="0.860457090909091">
We train instances of the graph- and the transition-
based parser on projected dependencies, and occa-
sionally refer to these as “projected parsers”.5
All results were obtained on the held-out
CoNLL-X test set of 386 sentences (avg. 12.9
5The MaltParsers use the projective Nivre arc-standard pars-
ing algorithm. For SVM training, data are split on the coarse
POS tag, with a threshold of 5,000 instances. MSTParser in-
stances use the projective Eisner parsing algorithm, and first-
order features. The input for both systems is projectivized using
the head+path schema (Nivre and Nilsson, 2005).
</bodyText>
<equation confidence="0.682141">
s(c, t)
</equation>
<page confidence="0.956807">
16
</page>
<table confidence="0.999277666666667">
Malt MST
Alpino 80.05 82.43
EP 75.33 73.09
Alpino + EP 77.47 81.63
baseline 1 (previous) 23.65
baseline 2 (next) 27.63
</table>
<tableCaption confidence="0.999683">
Table 3: Upper and lower bounds (UAS).
</tableCaption>
<bodyText confidence="0.998540866666667">
words/sentence) from the Alpino treebank (van der
Beek et al., 2002). The Alpino treebank consists
mostly of newspaper text, which means that we are
evaluating the projected parsers, which are trained
on Europarl, in an out-of-domain setting, in the ab-
sence of manually annotated Europarl test data.
Parsing performance is measured in terms of un-
labeled attachment score (UAS), i.e., the proportion
of tokens that are assigned the correct head, irrespec-
tive of the label.6
To establish upper and lower bounds for our task
of weakly supervised dependency parsing, we pro-
ceed as follows. We train MaltParsers and MST-
Parsers on (i) the CoNLL-X training portion of the
Alpino treebank (195,000 words), (ii) 100,000 Eu-
roparl sentences parsed with the parser obtained
from (i), and (iii) the concatenation of the data
sets (i) and (ii). The first is a supervised upper
bound (80.05/82.43% UAS)7 trained on manually
labeled in-domain data, while the second constitutes
a weaker bound (75.33/73.09%) subject to the same
out-of-domain evaluation as the projected parsers,
and the third (77.47%) is a self-trained version of (i).
We note in passing that the supervised model does
not benefit from self-training. Two simple baselines
provide approximations to a lower bound: Baseline
1 attaches every word to the preceding word, achiev-
ing 23.65%. Analogously, baseline 2 attaches every
word to the following word (27.63%). These sys-
tems are summarized in Table 3.
</bodyText>
<footnote confidence="0.9834107">
6The labeled accuracy of our parsers lags behind the UAS,
because the Dutch dependency relations in the projected anno-
tations arise from a coarse heuristic mapping from the original
English labels. We therefore report only UAS.
7The upper bound models are trained with the same param-
eter settings as the projected parsers (see fn. 5), which were ad-
justed for noisy training data. Thus improvements are likely
with other settings: Nivre et al. (2006) report 81.35% for a
Dutch MaltParser with optimized parameter settings. McDon-
ald et al. (2006) report 83.57% with MST.
</footnote>
<table confidence="0.999350076923077">
words Malt MST
a. trees (bidirectional) 13,500 65.94 67.76
trees (fallback) 62,500 59.28 65.08
bi+frags&lt;3 68,000 55.09 57.14
bi+frags&lt;3 (fMalt/fMST) 68,000 69.15 70.02
b. trees (bidirectional) 100,000 61.86 69.91
trees (fallback) 100,000 60.05 64.84
bi+frags&lt;3 100,000 54.50 55.87
bi+frags&lt;3 (fMalt/fMST) 100,000 68.65 69.86
c. trees (bidirectional) 102,300 63.32 69.85
trees (fallback) 465,500 53.45 64.88
bi+frags&lt;3 523,000 51.48 57.20
bi+frags&lt;3 (fMalt/fMST) 523,000 69.52 70.33
</table>
<tableCaption confidence="0.9936922">
Table 4: UAS of parsers trained on projected dependency
structures for (a) a sample of 100,000 sentences, subject
to filtering, (b) 10 random samples, each with 100,000
words after filtering (average scores given), and (c) the
entire Europarl corpus, subject to filtering.
</tableCaption>
<subsectionHeader confidence="0.81798">
7.2 Results
</subsectionHeader>
<bodyText confidence="0.99979137037037">
Table 4a summarizes the results of training parsers
on the 100,000-sentence sample analyzed above.
Both the graph-based (MST) and the transition-
based (Malt) parsers react similarly to the more or
less aggressive filtering methods, but to different de-
grees. The first two rows of the table show the
parsers trained on complete trees (‘trees (bidirec-
tional)’ and ‘trees (fallback)’). In spite of the ad-
ditional training data gained by the fallback method,
the resulting parsers do not achieve higher accuracy;
on the contrary, there is a drop in UAS, especially
in the transition-based model (−6.66%). The in-
creased level of noise in the fallback data has less
(but significant)8 impact on the graph-based coun-
terpart (−2.68%).
Turning to the parsers trained on partial cor-
respondence data (‘bi+frags&lt;3’), we observe even
greater deterioration in both parsing paradigms if the
data is used as is. However, in combination with the
fMalt/fMST systems (‘bi+frags&lt;3 (fMalt/fMST)’),
both parsers significantly outperform the tree-
8Significance testing (p&lt;.01) was performed by means of
the t-test on the results of 10 training cycles (Table 4c ‘trees
(fb.)’ only 2 cycles due to time constraints). For the experiments
in Table 4a and 4c, the cycles differed in terms of the order in
which sentences where passed to the parser. In Table 4b we base
significance on 10 true random samples for training.
</bodyText>
<page confidence="0.995379">
17
</page>
<table confidence="0.999894666666667">
Recall Precision
dep.length 1 2 3–6 &gt;7 root 1 2 3–6 &gt;7 root
a. trees (bi.) 83.41 66.44 52.94 40.64 52.45 82.46 66.06 61.38 34.95 50.97
trees (fb.) 82.20 64.21 54.59 37.95 55.72 82.64 61.41 54.39 31.96 68.55
bi+frags≤3 70.18 59.50 46.61 32.14 61.87 83.75 67.22 58.25 32.81 27.01
bi+frags≤3 (fMalt) 89.23 75.34 59.18 41.65 59.06 83.46 69.05 65.85 48.21 75.79
Alpino-Malt 92.81 84.94 75.11 65.44 66.15 89.71 81.08 77.56 62.57 84.58
b. trees (bi.) 87.53 73.79 59.57 46.79 71.01 86.43 74.08 64.78 45.17 66.79
trees (fb.) 82.53 69.37 55.77 37.46 70.24 85.31 69.29 59.85 40.14 53.99
bi+frags≤3 68.11 57.48 34.30 13.00 90.68 90.28 78.54 66.36 43.70 23.41
bi+frags≤3 (fMST) 87.73 72.84 62.55 50.15 67.78 86.94 71.60 66.05 48.48 68.20
Alpino-MST 94.13 86.60 76.91 65.14 71.60 91.76 82.49 76.23 71.96 85.38
</table>
<tableCaption confidence="0.999637">
Table 5: Performance relative to dependency length. (a) Projected MaltParsers and (b) projected MSTParsers.
</tableCaption>
<bodyText confidence="0.9987248">
oriented models (‘trees (bidirectional)’) by 3.21%
(Malt) and 2.26% (MST).
It would be natural to presume that the superior-
ity of the partial correspondence filter is merely due
to the amount of training data, which is larger by
a factor of 5.04. We address this issue by isolat-
ing the effect on the quality of the data, and hence
the success at noise reduction: In Table 4b, we con-
trol for the amount of data that is effectively used
in training, so that each filtered training set consists
of 100,000 words. Considering the Malt models, we
find that the trends suggested in Table 4a are con-
firmed: The pattern of relative performance emerges
even though any quantitative (dis-)advantages have
been eliminated.9 10 Interestingly, the MSTParser
does not appear to gain from the increased variety
(cf. Table 1) in the partial data: it does not differ
significantly from the ‘trees (bi.)’ model.
Finally, Table 4c provides the results of training
on the entire Europarl, or what remains of the corpus
after the respective filters have applied. The results
corroborate those obtained for the smaller samples.
In summary, the results support our initial hy-
pothesis that partial correspondence for sentences
containing a highly reliable part is preferable to
</bodyText>
<footnote confidence="0.712142444444445">
9The degree of skewedness in the filtered data is not con-
trolled, as it is an important characteristic of the filters.
10Some of the parsers trained on the larger data sets (Table
4b+c) achieve worse results than their smaller counterparts in
Table 4a. We conjecture that it is due to the thresholded POS-
based data split, performed prior to SVM training: Larger train-
ing sets induce decision models with more specialized SVMs,
which are more susceptible to tagging errors. This could be
avoided by increasing the threshold for splitting.
</footnote>
<bodyText confidence="0.999693833333333">
relaxing the reliability citerion, and—in the case
of the transition-based MaltParser—also to aggres-
sively filtering out all but the reliable complete trees.
With UASs around 70%, both systems are only 5%
behind the average 75.07% UAS achieved for Dutch
in the CoNLL-X Shared Task.
</bodyText>
<sectionHeader confidence="0.956378" genericHeader="evaluation">
8 Analysis
</sectionHeader>
<bodyText confidence="0.9999838">
We have seen that the graph- and the transition-
based parser react similarly to the various filtering
methods. However, there are interesting differences
in the magnitude of the performance changes. If
we compare the two tree-oriented filters ‘trees (bi.)’
and ‘trees (fb.)’, we observe that, although both Malt
and MST suffer from the additional noise that is in-
troduced via the unidirectional alignments, the drop
in accuracy is much less pronounced in the latter,
graph-based model. Recall that in this paradigm,
optimization is performed over the entire tree by
scoring edges independenly; this might explain why
noisy arcs in the training data have only a negligi-
ble impact. Conversely, the transition-based Malt-
Parser, which constructs parse trees in steps of lo-
cally optimal decisions, has an advantage when con-
fronted with partial structures: The individual frag-
ments provide exactly the local context, plus lexical
information about the (unconnected) wider context.
To give a more detailed picture of the differences
between predicted and actual annotations, we show
the performance (of the parsers from Table 4b) sep-
arately for binned arc length (Table 5) and sen-
tence length (Table 6). As expected, the perfor-
mance of both the supervised upper bounds (Alpino-
</bodyText>
<page confidence="0.994657">
18
</page>
<table confidence="0.979563090909091">
sent. length &lt;4 4–9 10–19 20–30 &gt; 30
a. trees (bi.) 73.87 62.13 65.67 60.81 55.18
trees (fb.) 69.91 57.84 62.29 60.04 55.47
bi+frags≤3 74.14 54.40 56.62 54.07 48.95
bi+fr≤3 (fMalt) 73.51 65.69 71.70 68.49 63.71
Alpino-Malt 81.98 69.81 81.11 82.82 76.02
b. trees (bi.) 76.67 70.16 73.09 69.56 63.57
trees (fb.) 73.24 64.93 67.79 64.98 57.70
bi+frags≤3 77.48 59.65 55.96 55.27 52.74
bi+fr≤3 (fMST) 73.24 67.84 73.46 70.04 62.92
Alpino-MST 81.98 72.24 85.10 83.86 78.51
</table>
<tableCaption confidence="0.994573">
Table 6: UAS relative to sentence length. (a) Projected
MaltParsers and (b) projected MSTParsers.
</tableCaption>
<bodyText confidence="0.999970606060606">
Malt/MST) and the projected parsers degrades as de-
pendencies get longer, and the difference between
the two grows. Performance across sentence length
remains relatively stable. But note that both tables
again reflect the pattern we saw in Table 4. Impor-
tantly, the relative ranking (in terms of f-score, not
shown, resp. UAS) is still in place even in long dis-
tance dependencies and long sentences. This indi-
cates that the effects we have described are not arti-
facts of a bias towards short dependencies.
In addition, Table 5 sheds some light on the im-
pact of fMalt/fMST in terms of the trade-off between
precision and recall. Without the specific adjust-
ments to handle fragments, partial structures in the
training data lead to an immense drop in recall. By
contrast, when the adapted parsers fMalt/fMST are
applied, they boosts recall back to a level compara-
ble to or even above that of the tree-oriented pro-
jection parsers, while maintaining precision. Again,
this effect can be observed across all arc lengths, ex-
cept arcs to root, which naturally the ‘bi+frags’ mod-
els are overly eager to predict.
Finally, the learning curves in Fig. 2 illus-
trate how much labeled data would be required to
achieve comparable performance in a supervised
setting. The graph-based upper bound (Alpino-
MST) reaches the performance of fMST (trained
on the entire Europarl) with approx. 25,000 words
of manually labeled treebank data; Alpino-Malt
achieves the performance of fMalt with approx.
35,000 words. The manual annotation of even these
moderate amounts of data involves considerable ef-
forts, including the creation of annotation guidelines
</bodyText>
<figureCaption confidence="0.997361666666667">
Figure 2: Learning curves for the supervised upper
bounds. They reach the performance of the projected
parsers with ∼25,000 (MST) resp. 35,000 (Malt) words.
</figureCaption>
<bodyText confidence="0.815749">
and tools, the training of annotators etc.
</bodyText>
<sectionHeader confidence="0.99762" genericHeader="conclusions">
9 Conclusion
</sectionHeader>
<bodyText confidence="0.9999863">
In the context of dependency parsing, we have pro-
posed partial correspondence projection as a greedy
method for noise reduction, and illustrated how it
can be integrated with data-driven parsing. Our ex-
perimental results show that partial tree structures
are well suited to train transition-based dependency
parsers. Graph-based models do not benefit as much
from additional partial structures, but instead are
more robust to noisy training data, even when the
training set is very small.
In future work, we will explore how well the tech-
niques presented here for English and Dutch work
for languages that are typologically further apart,
e.g., English-Greek or English-Finnish. Moreover,
we are going to investigate how our approach, which
essentially ignores unknown parts of the annotation,
compares to approaches that marginalize over hid-
den variables. We will also explore ways of combin-
ing graph-based and transition-based parsers along
the lines of Nivre and McDonald (2008).
</bodyText>
<sectionHeader confidence="0.998817" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.96536275">
The research reported in this paper has been sup-
ported by the German Research Foundation DFG as
part of SFB 632 “Information structure” (project D4;
PI: Kuhn).
</bodyText>
<page confidence="0.998963">
19
</page>
<sectionHeader confidence="0.996381" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999903373737373">
Sabine Buchholz and Erwin Marsi. 2006. Conll-x shared
task on multilingual dependency parsing. In Proceed-
ings of CoNLL-X, pages 149–164, New York City,
June.
Stephen Clark and James R. Curran. 2006. Partial train-
ing for a lexicalized-grammar parser. In Proceed-
ings ofHLT-NAACL 2006, pages 144–151, New York,
June.
Koby Crammer and Yoram Singer. 2003. Ultraconserva-
tive online algorithms for multiclass problems. Jour-
nal of Machine Learning Reseach, 3:951–991, Jan-
uary.
Rebecca Hwa, Philip Resnik, Amy Weinberg, Clara
Cabezas, and Okan Kolak. 2005. Bootstrapping
parsers via syntactic projection across parallel texts.
Natural Language Engineering, 11(3):311–325.
Dan Klein and Christopher D. Manning. 2004. Corpus-
based induction of syntactic structure: Models of de-
pendency and constituency. In Proceedings of ACL
2004, pages 478–485, Barcelona, Spain.
Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In Proceed-
ings ofHLT-NAACL 2003, pages 127–133.
Philipp Koehn. 2005. Europarl: A Parallel Corpus for
Statistical Machine Translation. In Proceedings of the
MT Summit 2005.
Terry Koo, Xavier Carreras, and Michael Collins. 2008.
Simple semi-supervised dependency parsing. In Pro-
ceedings ofACL-HLT 2008), pages 595–603, Colum-
bus, Ohio, June.
Mitchell Marcus, Grace Kim, Mary Marcinkiewicz,
Robert MacIntyre, Ann Bies, Mark Ferguson, Karen
Katz, and Britta Schasberger. 1994. The Penn tree-
bank: Annotating predicate argument structure. In
ARPA Human Language Technology Workshop.
David McClosky, Eugene Charniak, and Mark Johnson.
2006. Effective self-training for parsing. In Proceed-
ings ofHLT-NAACL 2006, pages 152–159, New York,
June.
Ryan McDonald and Joakim Nivre. 2007. Characteriz-
ing the errors of data-driven dependency parsing mod-
els. In Proceedings of EMNLP-CoNLL 2007, pages
122–131.
Ryan McDonald, Fernando Pereira, Kiril Ribarov, and
Jan Hajiˇc. 2005. Non-projective dependency pars-
ing using spanning tree algorithms. In Proceedings
ofHLT-EMNLP 2005).
Ryan McDonald, Kevin Lerman, and Fernando Pereira.
2006. Multilingual dependency analysis with a two-
stage discriminative parser. In Proceedings of CoNLL-
X.
Joakim Nivre and Ryan McDonald. 2008. Integrating
graph-based and transition-based dependency parsers.
In Proceedings of ACL-HLT 2008, pages 950–958,
Columbus, Ohio, June.
Joakim Nivre and Jens Nilsson. 2005. Pseudo-projective
dependency parsing. In Proceedings of ACL 2005,
pages 99–106.
Joakim Nivre, Johan Hall, Jens Nilsson, G¨uls¸en Eryiˇgit,
and Svetoslav Marinov. 2006. Labeled pseudo-
projective dependency parsing with support vector ma-
chines. In Proceedings of CoNLL-X, pages 221–225.
Franz Josef Och and Hermann Ney. 2003. A system-
atic comparison of various statistical alignment mod-
els. Computational Linguistics, 29(1):19–51.
Sebastian Pad´o and Mirella Lapata. 2006. Optimal con-
stituent alignment with edge covers for semantic pro-
jection. In Proceedings of COLING/ACL 2006, Syd-
ney, Australia.
Fernando Pereira and Yves Schabes. 1992. Inside-
outside reestimation from partially bracketed corpora.
In Proceedings ofACL 1992, pages 128–135.
Helmut Schmid. 1994. Probabilistic part-of-speech tag-
ging using decision trees. In International Conference
on New Methods in Language Processing, pages 44–
49, Manchester, England.
Noah A. Smith and Jason Eisner. 2004. Annealing
techniques for unsupervised statistical language learn-
ing. In Proceedings of ACL 2004, pages 487–494,
Barcelona, July.
Noah A. Smith and Jason Eisner. 2005. Contrastive esti-
mation: Training log-linear models on unlabeled data.
In Proceedings ofACL 2005, pages 354–362, Ann Ar-
bor, MI, June.
Kathrin Spreyer and Anette Frank. 2008. Projection-
based acquisition of a temporal labeller. In Proceed-
ings ofIJCNLP 2008, Hyderabad, India, January.
Leonoor van der Beek, Gosse Bouma, Robert Malouf,
and Gertjan van Noord. 2002. The Alpino depen-
dency treebank. In Computational Linguistics in the
Netherlands (CLIN).
Qin Iris Wang, Dale Schuurmans, and Dekang Lin. 2008.
Semi-supervised convex training for dependency pars-
ing. In Proceedings of ACL-HLT 2008, pages 532–
540, Columbus, Ohio, June.
David Yarowsky, Grace Ngai, and Richard Wicentowski.
2001. Inducing multilingual text analysis tools via ro-
bust projection across aligned corpora. In Proceedings
ofHLT 2001.
</reference>
<page confidence="0.994871">
20
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.273406">
<title confidence="0.9925485">Data-Driven Dependency Parsing of New Using Incomplete and Noisy Training Data</title>
<author confidence="0.757286">Spreyer</author>
<affiliation confidence="0.9984725">Department of University of Potsdam,</affiliation>
<abstract confidence="0.9765532">We present a simple but very effective approach to identifying high-quality data in noisy data sets for structured problems like parsing, by greedily exploiting partial structures. We analyze our approach in an annotation projection framework for dependency trees, and show how dependency parsers from two different paradigms (graph-based and transition-based) can be trained on the resulting tree fragments. We train parsers for Dutch to evaluate our method and to investigate to which degree graph-based and transitionbased parsers can benefit from incomplete training data. We find that partial correspondence projection gives rise to parsers that outperform parsers trained on aggressively filtered data sets, and achieve unlabeled attachment scores that are only 5% behind the average UAS for Dutch in the CoNLL-X Shared</abstract>
<note confidence="0.7153565">Task on supervised parsing (Buchholz and Marsi, 2006).</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Sabine Buchholz</author>
<author>Erwin Marsi</author>
</authors>
<title>Conll-x shared task on multilingual dependency parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of CoNLL-X,</booktitle>
<pages>149--164</pages>
<location>New York City,</location>
<contexts>
<context position="1100" citStr="Buchholz and Marsi, 2006" startWordPosition="161" endWordPosition="164">ncy trees, and show how dependency parsers from two different paradigms (graph-based and transition-based) can be trained on the resulting tree fragments. We train parsers for Dutch to evaluate our method and to investigate to which degree graph-based and transitionbased parsers can benefit from incomplete training data. We find that partial correspondence projection gives rise to parsers that outperform parsers trained on aggressively filtered data sets, and achieve unlabeled attachment scores that are only 5% behind the average UAS for Dutch in the CoNLL-X Shared Task on supervised parsing (Buchholz and Marsi, 2006). 1 Introduction Many weakly supervised approaches to NLP rely on heuristics or filtering techniques to deal with noise in unlabeled or automatically labeled training data, e.g., in the exploitation of parallel corpora for crosslingual projection of morphological, syntactic or semantic information. While heuristic approaches can implement (linguistic) knowledge that helps to detect noisy data (e.g., Hwa et al. (2005)), they are typically task- and language-specific and thus introduce a component of indirect supervision. Non-heuristic filtering techniques, on the other hand, employ reliability </context>
<context position="3263" citStr="Buchholz and Marsi, 2006" startWordPosition="480" endWordPosition="483">o create training data for two dependency parsers representing different parsing paradigms: The MSTParser (McDonald et al., 2005) as an instance of graph-based dependency parsing, and the MaltParser (Nivre et al., 2006) to represent transitionbased dependency parsing. In an empirical evaluation, we investigate how they react differently to incomplete and noisy training data. Despite its simplicity, the partial correspondence approach proves very effective and leads to parsers that achieve unlabeled attachment scores that are only 5% behind the average UAS for Dutch in the CoNLL-X Shared Task (Buchholz and Marsi, 2006). After a summary of related work in Sec. 2, we discuss dependency tree projection (Sec. 3) and partial correspondence (Sec. 4). In Sec. 5, we give an overview of graph- and transition-based dependency parsing and describe how each can be adapted for training on partial training data in Sec. 6. Experimental results are presented in Sec. 7, followed by an analysis in Sec. 8. Sec. 9 concludes. 12 Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL), pages 12–20, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics a. b. c. English </context>
<context position="17276" citStr="Buchholz and Marsi, 2006" startWordPosition="2730" endWordPosition="2733">ions. As a representative of the transition-based paradigm, we use the MaltParser (Nivre et al., 2006). It implements incremental, deterministic parsing algorithms and employs SVMs to learn the transition scores s. 6 Parsing with Fragmented Trees To make effective use of the fragmented trees produced by partial correspondence projection, both parsing approaches need to be adapted for training on sentences with unconnected substructures. Here we briefly discuss how we represent these structures, and then describe how we modified the parsers. We use the CoNLL-X data format for dependency trees (Buchholz and Marsi, 2006) to encode partial structures. Specifically, every fragment root specifies as its head an artificial root token w0 (distinguished from a true root dependency by a special relation FRAG). Thus, sentences with a fragmented parse are still represented as a single sentence, including all words; the difference from a fully parsed sentence is that unconnected substructures are attached directly under w0. For instance, the partial parse in Fig. 1b would be represented as follows (details omitted): (1) 1 U pron 0 FRAG 2 heeft verb 0 ROOT 3 volkomen adj 4 mod 4 gelijk noun 0 FRAG 6.1 Graph-based Model:</context>
</contexts>
<marker>Buchholz, Marsi, 2006</marker>
<rawString>Sabine Buchholz and Erwin Marsi. 2006. Conll-x shared task on multilingual dependency parsing. In Proceedings of CoNLL-X, pages 149–164, New York City, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Clark</author>
<author>James R Curran</author>
</authors>
<title>Partial training for a lexicalized-grammar parser.</title>
<date>2006</date>
<booktitle>In Proceedings ofHLT-NAACL 2006,</booktitle>
<pages>144--151</pages>
<location>New York,</location>
<contexts>
<context position="6668" citStr="Clark and Curran (2006)" startWordPosition="1023" endWordPosition="1026">sed and weakly supervised parsing ranges from various forms of EM training (Pereira and Schabes, 1992; Klein and Manning, 2004; Smith and Eisner, 2004; Smith and Eisner, 2005) over bootstrapping approaches like selftraining (McClosky et al., 2006) to feature-based enhancements of discriminative reranking models (Koo et al., 2008) and the application of semisupervised SVMs (Wang et al., 2008). The partial correspondence method we present in this paper is compatible with such approaches and can be combined with other weakly supervised machine learning schemes. Our approach is similar to that of Clark and Curran (2006) who use partial training data (CCG lexical categories) for domain adaptation; however, they assume an existing CCG resource for the language in question to provide this data. 3 Projection of Dependency Trees Most state-of-the-art parsers for natural languages are data-driven and depend on the availability of sufficient amounts of labeled training data. However, manual creation of treebanks is time-consuming and labour-intensive. One way to avoid the expensive annotation process is to automatically label the training data using annotation projection (Yarowsky et al., 2001): Given a suitable re</context>
</contexts>
<marker>Clark, Curran, 2006</marker>
<rawString>Stephen Clark and James R. Curran. 2006. Partial training for a lexicalized-grammar parser. In Proceedings ofHLT-NAACL 2006, pages 144–151, New York, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Koby Crammer</author>
<author>Yoram Singer</author>
</authors>
<title>Ultraconservative online algorithms for multiclass problems.</title>
<date>2003</date>
<journal>Journal of Machine Learning Reseach,</journal>
<pages>3--951</pages>
<contexts>
<context position="15957" citStr="Crammer and Singer, 2003" startWordPosition="2512" endWordPosition="2515">into two paradigms: Graph-based and transition-based models (McDonald and Nivre, 2007). 5.1 Graph-based Models In the graph-based approach, global optimization considers all possible arcs to find the tree Tˆ s.t. 1] s(T) = arg max TED (i,j,l)EAT where D is the set of all well-formed dependency trees for the sentence, AT is the set of arcs in T, and s(i, j, l) is the score of an arc between words wi and wj with label l. The specific graph-based parser we use in this paper is the MSTParser of McDonald et al. (2005). The MSTParser learns the scoring function s using an online learning algorithm (Crammer and Singer, 2003) which maximizes the margin between Tˆ and D \ { Tˆ }, based on a loss function that counts the number of words with incorrect parents relative to the correct tree. 5.2 Transition-based Models In contrast to the global optimization employed in graph-based models, transition-based models construct a parse tree in a stepwise way: At each point, 4Fragments from fallback projection turned out not to be helpful as training data for dependency parsers. Tˆ = arg max TED s(i, j, l) 15 the locally optimal parser action (transition) t* is determined greedily on the basis of the current configuration c (</context>
</contexts>
<marker>Crammer, Singer, 2003</marker>
<rawString>Koby Crammer and Yoram Singer. 2003. Ultraconservative online algorithms for multiclass problems. Journal of Machine Learning Reseach, 3:951–991, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rebecca Hwa</author>
<author>Philip Resnik</author>
<author>Amy Weinberg</author>
<author>Clara Cabezas</author>
<author>Okan Kolak</author>
</authors>
<title>Bootstrapping parsers via syntactic projection across parallel texts.</title>
<date>2005</date>
<journal>Natural Language Engineering,</journal>
<volume>11</volume>
<issue>3</issue>
<contexts>
<context position="1520" citStr="Hwa et al. (2005)" startWordPosition="223" endWordPosition="226">ggressively filtered data sets, and achieve unlabeled attachment scores that are only 5% behind the average UAS for Dutch in the CoNLL-X Shared Task on supervised parsing (Buchholz and Marsi, 2006). 1 Introduction Many weakly supervised approaches to NLP rely on heuristics or filtering techniques to deal with noise in unlabeled or automatically labeled training data, e.g., in the exploitation of parallel corpora for crosslingual projection of morphological, syntactic or semantic information. While heuristic approaches can implement (linguistic) knowledge that helps to detect noisy data (e.g., Hwa et al. (2005)), they are typically task- and language-specific and thus introduce a component of indirect supervision. Non-heuristic filtering techniques, on the other hand, employ reliability measures (often unrelated to the task) to predict high-precision data points (e.g., Yarowsky et al. (2001)). In order to reach a sufficient level of precision, filtering typically has to be aggressive, especially for highly structured tasks like parsing. Such aggressive filtering techniques incur massive data loss and enforce trade-offs between the quality and the amount of usable data. Ideally, a general filtering s</context>
<context position="5313" citStr="Hwa et al. (2005)" startWordPosition="807" endWordPosition="810">sed to discard unreliable data points (words in a sentence) without necessarily affecting highprecision data points in the same sentence. By using only the bidirectional word alignment links, one can implement a very robust such filter, as the bidirectional links are generally reliable, even though they have low recall for overall translational correspondences (Koehn et al., 2003). The bidirectional alignment filter is common practice (Pad´o and Lapata, 2006); a similar strategy is to discard entire sentences with low aggregated alignment scores (Yarowsky et al., 2001). On the sentence level, Hwa et al. (2005) were the first to project dependency trees from English to Spanish and Chinese. They identify unreliable target parses (as a whole) on the basis of the number of unaligned or over-aligned words. In addition, they manipulate the trees to accommodate for nonisomorphic sentences. Systematic non-parallelisms between source and target language are then addressed by hand-crafted rules in a post-projection step. These rules account for an enormous increase in the unlabeled f-score of the direct projections, from 33.9 to 65.7 for Spanish and from 26.3 to 52.4 for Chinese. But they need to be designed</context>
<context position="8234" citStr="Hwa et al., 2005" startWordPosition="1278" endWordPosition="1281">ment. Assuming we have a parser to produce the dependency tree for the English sentence, we build the tree for the Dutch sentence by establishing arcs between words wD (e.g., Ik) and hD (heb) if there are aligned pairs (wD, wE) 13 #sents w/ avg. sent vocab projected parse length (lemma) unfiltered (100,000) 24.92 19,066 bidirectional 2,112 6.39 1,905 fallback 6,426 9.72 4,801 bi+frags≤3 7,208 9.44 4,631 Table 1: Data reduction effect of noise filters. (Ik and I) and (hD, hE) (heb and have) such that hE is the head of wE in the English tree. Annotation projection assumes direct correspondence (Hwa et al., 2005) between languages (or annotations), which—although it is valid in many cases—does not hold in general: non-parallelism between corresponding expressions in L1 and L2 causes errors in the target annotations. The word alignment constitutes a further source for errors if it is established automatically—which is typically the case in large parallel corpora. We have implemented a language-independent framework for dependency projection and use the Europarl corpus (Koehn, 2005) as the parallel text. Europarl consists of the proceedings of the European Parliament, professionally translated in 11 lan</context>
</contexts>
<marker>Hwa, Resnik, Weinberg, Cabezas, Kolak, 2005</marker>
<rawString>Rebecca Hwa, Philip Resnik, Amy Weinberg, Clara Cabezas, and Okan Kolak. 2005. Bootstrapping parsers via syntactic projection across parallel texts. Natural Language Engineering, 11(3):311–325.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Corpusbased induction of syntactic structure: Models of dependency and constituency.</title>
<date>2004</date>
<booktitle>In Proceedings of ACL 2004,</booktitle>
<pages>478--485</pages>
<location>Barcelona,</location>
<contexts>
<context position="6171" citStr="Klein and Manning, 2004" startWordPosition="943" endWordPosition="947">to accommodate for nonisomorphic sentences. Systematic non-parallelisms between source and target language are then addressed by hand-crafted rules in a post-projection step. These rules account for an enormous increase in the unlabeled f-score of the direct projections, from 33.9 to 65.7 for Spanish and from 26.3 to 52.4 for Chinese. But they need to be designed anew for every target language, which is time-consuming and requires knowledge of that language. Research in the field of unsupervised and weakly supervised parsing ranges from various forms of EM training (Pereira and Schabes, 1992; Klein and Manning, 2004; Smith and Eisner, 2004; Smith and Eisner, 2005) over bootstrapping approaches like selftraining (McClosky et al., 2006) to feature-based enhancements of discriminative reranking models (Koo et al., 2008) and the application of semisupervised SVMs (Wang et al., 2008). The partial correspondence method we present in this paper is compatible with such approaches and can be combined with other weakly supervised machine learning schemes. Our approach is similar to that of Clark and Curran (2006) who use partial training data (CCG lexical categories) for domain adaptation; however, they assume an </context>
</contexts>
<marker>Klein, Manning, 2004</marker>
<rawString>Dan Klein and Christopher D. Manning. 2004. Corpusbased induction of syntactic structure: Models of dependency and constituency. In Proceedings of ACL 2004, pages 478–485, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz Josef Och</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistical phrase-based translation.</title>
<date>2003</date>
<booktitle>In Proceedings ofHLT-NAACL</booktitle>
<pages>127--133</pages>
<contexts>
<context position="5079" citStr="Koehn et al., 2003" startWordPosition="769" endWordPosition="772">and Frank, 2008), or semantic role labeling (Pad´o and Lapata, 2006). In these tasks, word labels can technically be introduced in isolation, without reference to the rest of the annotation. This means that an aggressive filter can be used to discard unreliable data points (words in a sentence) without necessarily affecting highprecision data points in the same sentence. By using only the bidirectional word alignment links, one can implement a very robust such filter, as the bidirectional links are generally reliable, even though they have low recall for overall translational correspondences (Koehn et al., 2003). The bidirectional alignment filter is common practice (Pad´o and Lapata, 2006); a similar strategy is to discard entire sentences with low aggregated alignment scores (Yarowsky et al., 2001). On the sentence level, Hwa et al. (2005) were the first to project dependency trees from English to Spanish and Chinese. They identify unreliable target parses (as a whole) on the basis of the number of unaligned or over-aligned words. In addition, they manipulate the trees to accommodate for nonisomorphic sentences. Systematic non-parallelisms between source and target language are then addressed by ha</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Philipp Koehn, Franz Josef Och, and Daniel Marcu. 2003. Statistical phrase-based translation. In Proceedings ofHLT-NAACL 2003, pages 127–133.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Europarl: A Parallel Corpus for Statistical Machine Translation.</title>
<date>2005</date>
<booktitle>In Proceedings of the MT</booktitle>
<location>Summit</location>
<contexts>
<context position="8711" citStr="Koehn, 2005" startWordPosition="1347" endWordPosition="1348">eb and have) such that hE is the head of wE in the English tree. Annotation projection assumes direct correspondence (Hwa et al., 2005) between languages (or annotations), which—although it is valid in many cases—does not hold in general: non-parallelism between corresponding expressions in L1 and L2 causes errors in the target annotations. The word alignment constitutes a further source for errors if it is established automatically—which is typically the case in large parallel corpora. We have implemented a language-independent framework for dependency projection and use the Europarl corpus (Koehn, 2005) as the parallel text. Europarl consists of the proceedings of the European Parliament, professionally translated in 11 languages (approx. 30mln words per language). The data was aligned on the word level with GIZA++ (Och and Ney, 2003).1 In the experiments reported here, we use the language pair English-Dutch, with English as the source for projection (L1) and Dutch as L2. The English portion of the Europarl corpus was lemmatized and POS tagged with the TreeTagger (Schmid, 1994) and then parsed with MaltParser (which is described in Sec. 6), trained on a dependency-converted version of the WS</context>
</contexts>
<marker>Koehn, 2005</marker>
<rawString>Philipp Koehn. 2005. Europarl: A Parallel Corpus for Statistical Machine Translation. In Proceedings of the MT Summit 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Terry Koo</author>
<author>Xavier Carreras</author>
<author>Michael Collins</author>
</authors>
<title>Simple semi-supervised dependency parsing.</title>
<date>2008</date>
<booktitle>In Proceedings ofACL-HLT 2008),</booktitle>
<pages>595--603</pages>
<location>Columbus, Ohio,</location>
<contexts>
<context position="6376" citStr="Koo et al., 2008" startWordPosition="974" endWordPosition="977">increase in the unlabeled f-score of the direct projections, from 33.9 to 65.7 for Spanish and from 26.3 to 52.4 for Chinese. But they need to be designed anew for every target language, which is time-consuming and requires knowledge of that language. Research in the field of unsupervised and weakly supervised parsing ranges from various forms of EM training (Pereira and Schabes, 1992; Klein and Manning, 2004; Smith and Eisner, 2004; Smith and Eisner, 2005) over bootstrapping approaches like selftraining (McClosky et al., 2006) to feature-based enhancements of discriminative reranking models (Koo et al., 2008) and the application of semisupervised SVMs (Wang et al., 2008). The partial correspondence method we present in this paper is compatible with such approaches and can be combined with other weakly supervised machine learning schemes. Our approach is similar to that of Clark and Curran (2006) who use partial training data (CCG lexical categories) for domain adaptation; however, they assume an existing CCG resource for the language in question to provide this data. 3 Projection of Dependency Trees Most state-of-the-art parsers for natural languages are data-driven and depend on the availability </context>
</contexts>
<marker>Koo, Carreras, Collins, 2008</marker>
<rawString>Terry Koo, Xavier Carreras, and Michael Collins. 2008. Simple semi-supervised dependency parsing. In Proceedings ofACL-HLT 2008), pages 595–603, Columbus, Ohio, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell Marcus</author>
<author>Grace Kim</author>
<author>Mary Marcinkiewicz</author>
<author>Robert MacIntyre</author>
<author>Ann Bies</author>
<author>Mark Ferguson</author>
<author>Karen Katz</author>
<author>Britta Schasberger</author>
</authors>
<title>The Penn treebank: Annotating predicate argument structure.</title>
<date>1994</date>
<booktitle>In ARPA Human Language Technology Workshop.</booktitle>
<contexts>
<context position="9362" citStr="Marcus et al., 1994" startWordPosition="1455" endWordPosition="1458"> consists of the proceedings of the European Parliament, professionally translated in 11 languages (approx. 30mln words per language). The data was aligned on the word level with GIZA++ (Och and Ney, 2003).1 In the experiments reported here, we use the language pair English-Dutch, with English as the source for projection (L1) and Dutch as L2. The English portion of the Europarl corpus was lemmatized and POS tagged with the TreeTagger (Schmid, 1994) and then parsed with MaltParser (which is described in Sec. 6), trained on a dependency-converted version of the WSJ part from the Penn Treebank (Marcus et al., 1994), but with the automatic POS tags. The Dutch sentences were only POS tagged (with TreeTagger).2 3.1 Data Loss Through Filtering We quantitatively assess the impact of various filtering techniques on a random sample of 100,000 English-Dutch sentence pairs from Europarl (avg. 1Following standard practice, we computed word alignments in both directions (L1 → L2 and L2 → L1); this gives rise to two unidirectional alignments. The bidirectional alignment is the intersection of the two unidirectional ones. 2The Dutch POS tags are used to train the monolingual parsers from the projected dependency tre</context>
</contexts>
<marker>Marcus, Kim, Marcinkiewicz, MacIntyre, Bies, Ferguson, Katz, Schasberger, 1994</marker>
<rawString>Mitchell Marcus, Grace Kim, Mary Marcinkiewicz, Robert MacIntyre, Ann Bies, Mark Ferguson, Karen Katz, and Britta Schasberger. 1994. The Penn treebank: Annotating predicate argument structure. In ARPA Human Language Technology Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David McClosky</author>
<author>Eugene Charniak</author>
<author>Mark Johnson</author>
</authors>
<title>Effective self-training for parsing.</title>
<date>2006</date>
<booktitle>In Proceedings ofHLT-NAACL 2006,</booktitle>
<pages>152--159</pages>
<location>New York,</location>
<contexts>
<context position="6292" citStr="McClosky et al., 2006" startWordPosition="963" endWordPosition="966">sed by hand-crafted rules in a post-projection step. These rules account for an enormous increase in the unlabeled f-score of the direct projections, from 33.9 to 65.7 for Spanish and from 26.3 to 52.4 for Chinese. But they need to be designed anew for every target language, which is time-consuming and requires knowledge of that language. Research in the field of unsupervised and weakly supervised parsing ranges from various forms of EM training (Pereira and Schabes, 1992; Klein and Manning, 2004; Smith and Eisner, 2004; Smith and Eisner, 2005) over bootstrapping approaches like selftraining (McClosky et al., 2006) to feature-based enhancements of discriminative reranking models (Koo et al., 2008) and the application of semisupervised SVMs (Wang et al., 2008). The partial correspondence method we present in this paper is compatible with such approaches and can be combined with other weakly supervised machine learning schemes. Our approach is similar to that of Clark and Curran (2006) who use partial training data (CCG lexical categories) for domain adaptation; however, they assume an existing CCG resource for the language in question to provide this data. 3 Projection of Dependency Trees Most state-of-t</context>
</contexts>
<marker>McClosky, Charniak, Johnson, 2006</marker>
<rawString>David McClosky, Eugene Charniak, and Mark Johnson. 2006. Effective self-training for parsing. In Proceedings ofHLT-NAACL 2006, pages 152–159, New York, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Joakim Nivre</author>
</authors>
<title>Characterizing the errors of data-driven dependency parsing models.</title>
<date>2007</date>
<booktitle>In Proceedings of EMNLP-CoNLL</booktitle>
<pages>122--131</pages>
<contexts>
<context position="15418" citStr="McDonald and Nivre, 2007" startWordPosition="2413" endWordPosition="2416">bidirectional projection.4 As can be seen in Table 1 (‘bi+frags≤3’), this combination boosts the amount of usable data to a range similar to that of the fallback technique for trees; but unlike the latter, partial correspondence continues to impose a highprecision filter (bidirectionality) while improving recall through relaxed structural requirements (partial correspondence). Table 2 shows how fragment size varies with sentence length. 5 Data-driven Dependency Parsing Models for data-driven dependency parsing can be roughly divided into two paradigms: Graph-based and transition-based models (McDonald and Nivre, 2007). 5.1 Graph-based Models In the graph-based approach, global optimization considers all possible arcs to find the tree Tˆ s.t. 1] s(T) = arg max TED (i,j,l)EAT where D is the set of all well-formed dependency trees for the sentence, AT is the set of arcs in T, and s(i, j, l) is the score of an arc between words wi and wj with label l. The specific graph-based parser we use in this paper is the MSTParser of McDonald et al. (2005). The MSTParser learns the scoring function s using an online learning algorithm (Crammer and Singer, 2003) which maximizes the margin between Tˆ and D \ { Tˆ }, based </context>
</contexts>
<marker>McDonald, Nivre, 2007</marker>
<rawString>Ryan McDonald and Joakim Nivre. 2007. Characterizing the errors of data-driven dependency parsing models. In Proceedings of EMNLP-CoNLL 2007, pages 122–131.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Fernando Pereira</author>
<author>Kiril Ribarov</author>
<author>Jan Hajiˇc</author>
</authors>
<title>Non-projective dependency parsing using spanning tree algorithms.</title>
<date>2005</date>
<booktitle>In Proceedings ofHLT-EMNLP</booktitle>
<marker>McDonald, Pereira, Ribarov, Hajiˇc, 2005</marker>
<rawString>Ryan McDonald, Fernando Pereira, Kiril Ribarov, and Jan Hajiˇc. 2005. Non-projective dependency parsing using spanning tree algorithms. In Proceedings ofHLT-EMNLP 2005).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Kevin Lerman</author>
<author>Fernando Pereira</author>
</authors>
<title>Multilingual dependency analysis with a twostage discriminative parser.</title>
<date>2006</date>
<booktitle>In Proceedings of CoNLLX.</booktitle>
<contexts>
<context position="22734" citStr="McDonald et al. (2006)" startWordPosition="3637" endWordPosition="3641">word to the following word (27.63%). These systems are summarized in Table 3. 6The labeled accuracy of our parsers lags behind the UAS, because the Dutch dependency relations in the projected annotations arise from a coarse heuristic mapping from the original English labels. We therefore report only UAS. 7The upper bound models are trained with the same parameter settings as the projected parsers (see fn. 5), which were adjusted for noisy training data. Thus improvements are likely with other settings: Nivre et al. (2006) report 81.35% for a Dutch MaltParser with optimized parameter settings. McDonald et al. (2006) report 83.57% with MST. words Malt MST a. trees (bidirectional) 13,500 65.94 67.76 trees (fallback) 62,500 59.28 65.08 bi+frags&lt;3 68,000 55.09 57.14 bi+frags&lt;3 (fMalt/fMST) 68,000 69.15 70.02 b. trees (bidirectional) 100,000 61.86 69.91 trees (fallback) 100,000 60.05 64.84 bi+frags&lt;3 100,000 54.50 55.87 bi+frags&lt;3 (fMalt/fMST) 100,000 68.65 69.86 c. trees (bidirectional) 102,300 63.32 69.85 trees (fallback) 465,500 53.45 64.88 bi+frags&lt;3 523,000 51.48 57.20 bi+frags&lt;3 (fMalt/fMST) 523,000 69.52 70.33 Table 4: UAS of parsers trained on projected dependency structures for (a) a sample of 100,00</context>
</contexts>
<marker>McDonald, Lerman, Pereira, 2006</marker>
<rawString>Ryan McDonald, Kevin Lerman, and Fernando Pereira. 2006. Multilingual dependency analysis with a twostage discriminative parser. In Proceedings of CoNLLX.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Ryan McDonald</author>
</authors>
<title>Integrating graph-based and transition-based dependency parsers.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-HLT 2008,</booktitle>
<pages>950--958</pages>
<location>Columbus, Ohio,</location>
<marker>Nivre, McDonald, 2008</marker>
<rawString>Joakim Nivre and Ryan McDonald. 2008. Integrating graph-based and transition-based dependency parsers. In Proceedings of ACL-HLT 2008, pages 950–958, Columbus, Ohio, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Jens Nilsson</author>
</authors>
<title>Pseudo-projective dependency parsing.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL</booktitle>
<pages>99--106</pages>
<contexts>
<context position="12334" citStr="Nivre and Nilsson, 2005" startWordPosition="1932" endWordPosition="1935">ig. 1b. Starting with the leftmost word in the Dutch sentence and its English translation (U and You), there is a unidirectional alignment for the head of You: are is aligned to heeft, so U is established as a dependent of heeft via fallback. Likewise, heeft can now be identified as the root node. Note that the (incorrect) alignment between heeft and You will not be pursued because it would lead to heeft being a dependent of itself and thus violating the wellformed3I.e., single headedness and acyclicity; we do not require the trees to be projective, but instead train pseudo-projective models (Nivre and Nilsson, 2005) on the projected data (cf. fn. 5). 14 #frags 1 2 3 4–15 &gt;15 #words &lt;4 425 80 12 – – 4–9 1,331 1,375 1,567 4,793 – 10–19 339 859 1,503 27,910 522 20–30 17 45 143 20,756 10,087 &gt;30 0 5 5 4,813 23,362 Table 2: Fragmented parses projected with the alignment filter. The sentences included in the data set ‘bi+frags≤3’ are in boldface. ness conditions. Finally, the subtree rooted in gelijk is incorporated as the second dependent of heeft. As expected, the proportion of examples that pass this filter rises, to 6.42% (Table 1, ‘fallback’). However, we will see in Sec. 7 that parsers trained on this da</context>
<context position="20566" citStr="Nivre and Nilsson, 2005" startWordPosition="3287" endWordPosition="3290">o as fMalt. 7 Experiments 7.1 Setup We train instances of the graph- and the transitionbased parser on projected dependencies, and occasionally refer to these as “projected parsers”.5 All results were obtained on the held-out CoNLL-X test set of 386 sentences (avg. 12.9 5The MaltParsers use the projective Nivre arc-standard parsing algorithm. For SVM training, data are split on the coarse POS tag, with a threshold of 5,000 instances. MSTParser instances use the projective Eisner parsing algorithm, and firstorder features. The input for both systems is projectivized using the head+path schema (Nivre and Nilsson, 2005). s(c, t) 16 Malt MST Alpino 80.05 82.43 EP 75.33 73.09 Alpino + EP 77.47 81.63 baseline 1 (previous) 23.65 baseline 2 (next) 27.63 Table 3: Upper and lower bounds (UAS). words/sentence) from the Alpino treebank (van der Beek et al., 2002). The Alpino treebank consists mostly of newspaper text, which means that we are evaluating the projected parsers, which are trained on Europarl, in an out-of-domain setting, in the absence of manually annotated Europarl test data. Parsing performance is measured in terms of unlabeled attachment score (UAS), i.e., the proportion of tokens that are assigned th</context>
</contexts>
<marker>Nivre, Nilsson, 2005</marker>
<rawString>Joakim Nivre and Jens Nilsson. 2005. Pseudo-projective dependency parsing. In Proceedings of ACL 2005, pages 99–106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Johan Hall</author>
<author>Jens Nilsson</author>
<author>G¨uls¸en Eryiˇgit</author>
<author>Svetoslav Marinov</author>
</authors>
<title>Labeled pseudoprojective dependency parsing with support vector machines.</title>
<date>2006</date>
<booktitle>In Proceedings of CoNLL-X,</booktitle>
<pages>221--225</pages>
<marker>Nivre, Hall, Nilsson, Eryiˇgit, Marinov, 2006</marker>
<rawString>Joakim Nivre, Johan Hall, Jens Nilsson, G¨uls¸en Eryiˇgit, and Svetoslav Marinov. 2006. Labeled pseudoprojective dependency parsing with support vector machines. In Proceedings of CoNLL-X, pages 221–225.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="8947" citStr="Och and Ney, 2003" startWordPosition="1384" endWordPosition="1387">general: non-parallelism between corresponding expressions in L1 and L2 causes errors in the target annotations. The word alignment constitutes a further source for errors if it is established automatically—which is typically the case in large parallel corpora. We have implemented a language-independent framework for dependency projection and use the Europarl corpus (Koehn, 2005) as the parallel text. Europarl consists of the proceedings of the European Parliament, professionally translated in 11 languages (approx. 30mln words per language). The data was aligned on the word level with GIZA++ (Och and Ney, 2003).1 In the experiments reported here, we use the language pair English-Dutch, with English as the source for projection (L1) and Dutch as L2. The English portion of the Europarl corpus was lemmatized and POS tagged with the TreeTagger (Schmid, 1994) and then parsed with MaltParser (which is described in Sec. 6), trained on a dependency-converted version of the WSJ part from the Penn Treebank (Marcus et al., 1994), but with the automatic POS tags. The Dutch sentences were only POS tagged (with TreeTagger).2 3.1 Data Loss Through Filtering We quantitatively assess the impact of various filtering </context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Pad´o</author>
<author>Mirella Lapata</author>
</authors>
<title>Optimal constituent alignment with edge covers for semantic projection.</title>
<date>2006</date>
<booktitle>In Proceedings of COLING/ACL 2006,</booktitle>
<location>Sydney, Australia.</location>
<marker>Pad´o, Lapata, 2006</marker>
<rawString>Sebastian Pad´o and Mirella Lapata. 2006. Optimal constituent alignment with edge covers for semantic projection. In Proceedings of COLING/ACL 2006, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernando Pereira</author>
<author>Yves Schabes</author>
</authors>
<title>Insideoutside reestimation from partially bracketed corpora.</title>
<date>1992</date>
<booktitle>In Proceedings ofACL</booktitle>
<pages>128--135</pages>
<contexts>
<context position="6146" citStr="Pereira and Schabes, 1992" startWordPosition="939" endWordPosition="942"> they manipulate the trees to accommodate for nonisomorphic sentences. Systematic non-parallelisms between source and target language are then addressed by hand-crafted rules in a post-projection step. These rules account for an enormous increase in the unlabeled f-score of the direct projections, from 33.9 to 65.7 for Spanish and from 26.3 to 52.4 for Chinese. But they need to be designed anew for every target language, which is time-consuming and requires knowledge of that language. Research in the field of unsupervised and weakly supervised parsing ranges from various forms of EM training (Pereira and Schabes, 1992; Klein and Manning, 2004; Smith and Eisner, 2004; Smith and Eisner, 2005) over bootstrapping approaches like selftraining (McClosky et al., 2006) to feature-based enhancements of discriminative reranking models (Koo et al., 2008) and the application of semisupervised SVMs (Wang et al., 2008). The partial correspondence method we present in this paper is compatible with such approaches and can be combined with other weakly supervised machine learning schemes. Our approach is similar to that of Clark and Curran (2006) who use partial training data (CCG lexical categories) for domain adaptation;</context>
</contexts>
<marker>Pereira, Schabes, 1992</marker>
<rawString>Fernando Pereira and Yves Schabes. 1992. Insideoutside reestimation from partially bracketed corpora. In Proceedings ofACL 1992, pages 128–135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
</authors>
<title>Probabilistic part-of-speech tagging using decision trees.</title>
<date>1994</date>
<booktitle>In International Conference on New Methods in Language Processing,</booktitle>
<pages>44--49</pages>
<location>Manchester, England.</location>
<contexts>
<context position="9195" citStr="Schmid, 1994" startWordPosition="1428" endWordPosition="1429">corpora. We have implemented a language-independent framework for dependency projection and use the Europarl corpus (Koehn, 2005) as the parallel text. Europarl consists of the proceedings of the European Parliament, professionally translated in 11 languages (approx. 30mln words per language). The data was aligned on the word level with GIZA++ (Och and Ney, 2003).1 In the experiments reported here, we use the language pair English-Dutch, with English as the source for projection (L1) and Dutch as L2. The English portion of the Europarl corpus was lemmatized and POS tagged with the TreeTagger (Schmid, 1994) and then parsed with MaltParser (which is described in Sec. 6), trained on a dependency-converted version of the WSJ part from the Penn Treebank (Marcus et al., 1994), but with the automatic POS tags. The Dutch sentences were only POS tagged (with TreeTagger).2 3.1 Data Loss Through Filtering We quantitatively assess the impact of various filtering techniques on a random sample of 100,000 English-Dutch sentence pairs from Europarl (avg. 1Following standard practice, we computed word alignments in both directions (L1 → L2 and L2 → L1); this gives rise to two unidirectional alignments. The bidi</context>
</contexts>
<marker>Schmid, 1994</marker>
<rawString>Helmut Schmid. 1994. Probabilistic part-of-speech tagging using decision trees. In International Conference on New Methods in Language Processing, pages 44– 49, Manchester, England.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Noah A Smith</author>
<author>Jason Eisner</author>
</authors>
<title>Annealing techniques for unsupervised statistical language learning.</title>
<date>2004</date>
<booktitle>In Proceedings of ACL 2004,</booktitle>
<pages>487--494</pages>
<location>Barcelona,</location>
<contexts>
<context position="6195" citStr="Smith and Eisner, 2004" startWordPosition="948" endWordPosition="951">morphic sentences. Systematic non-parallelisms between source and target language are then addressed by hand-crafted rules in a post-projection step. These rules account for an enormous increase in the unlabeled f-score of the direct projections, from 33.9 to 65.7 for Spanish and from 26.3 to 52.4 for Chinese. But they need to be designed anew for every target language, which is time-consuming and requires knowledge of that language. Research in the field of unsupervised and weakly supervised parsing ranges from various forms of EM training (Pereira and Schabes, 1992; Klein and Manning, 2004; Smith and Eisner, 2004; Smith and Eisner, 2005) over bootstrapping approaches like selftraining (McClosky et al., 2006) to feature-based enhancements of discriminative reranking models (Koo et al., 2008) and the application of semisupervised SVMs (Wang et al., 2008). The partial correspondence method we present in this paper is compatible with such approaches and can be combined with other weakly supervised machine learning schemes. Our approach is similar to that of Clark and Curran (2006) who use partial training data (CCG lexical categories) for domain adaptation; however, they assume an existing CCG resource fo</context>
</contexts>
<marker>Smith, Eisner, 2004</marker>
<rawString>Noah A. Smith and Jason Eisner. 2004. Annealing techniques for unsupervised statistical language learning. In Proceedings of ACL 2004, pages 487–494, Barcelona, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Noah A Smith</author>
<author>Jason Eisner</author>
</authors>
<title>Contrastive estimation: Training log-linear models on unlabeled data.</title>
<date>2005</date>
<booktitle>In Proceedings ofACL 2005,</booktitle>
<pages>354--362</pages>
<location>Ann Arbor, MI,</location>
<contexts>
<context position="6220" citStr="Smith and Eisner, 2005" startWordPosition="952" endWordPosition="956">matic non-parallelisms between source and target language are then addressed by hand-crafted rules in a post-projection step. These rules account for an enormous increase in the unlabeled f-score of the direct projections, from 33.9 to 65.7 for Spanish and from 26.3 to 52.4 for Chinese. But they need to be designed anew for every target language, which is time-consuming and requires knowledge of that language. Research in the field of unsupervised and weakly supervised parsing ranges from various forms of EM training (Pereira and Schabes, 1992; Klein and Manning, 2004; Smith and Eisner, 2004; Smith and Eisner, 2005) over bootstrapping approaches like selftraining (McClosky et al., 2006) to feature-based enhancements of discriminative reranking models (Koo et al., 2008) and the application of semisupervised SVMs (Wang et al., 2008). The partial correspondence method we present in this paper is compatible with such approaches and can be combined with other weakly supervised machine learning schemes. Our approach is similar to that of Clark and Curran (2006) who use partial training data (CCG lexical categories) for domain adaptation; however, they assume an existing CCG resource for the language in questio</context>
</contexts>
<marker>Smith, Eisner, 2005</marker>
<rawString>Noah A. Smith and Jason Eisner. 2005. Contrastive estimation: Training log-linear models on unlabeled data. In Proceedings ofACL 2005, pages 354–362, Ann Arbor, MI, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kathrin Spreyer</author>
<author>Anette Frank</author>
</authors>
<title>Projectionbased acquisition of a temporal labeller.</title>
<date>2008</date>
<booktitle>In Proceedings ofIJCNLP 2008,</booktitle>
<location>Hyderabad, India,</location>
<contexts>
<context position="4476" citStr="Spreyer and Frank, 2008" startWordPosition="671" endWordPosition="674">c. English (L1): I have two questions You are absolutely right You are absolutely right Dutch (L2): Ik heb twee vragen U heeft volkomen gelijk U heeft volkomen gelijk 3 2 Figure 1: Dependency tree projection from English to Dutch. (a) Ideal scenario with bidirectional alignments. (b) Projection fails due to weak alignments. (c) Constrained fallback projection. 1 2 Related Work Annotation projection has been applied to many different NLP tasks. On the word or phrase level, these include morphological analysis, part-of-speech tagging and NP-bracketing (Yarowsky et al., 2001), temporal analysis (Spreyer and Frank, 2008), or semantic role labeling (Pad´o and Lapata, 2006). In these tasks, word labels can technically be introduced in isolation, without reference to the rest of the annotation. This means that an aggressive filter can be used to discard unreliable data points (words in a sentence) without necessarily affecting highprecision data points in the same sentence. By using only the bidirectional word alignment links, one can implement a very robust such filter, as the bidirectional links are generally reliable, even though they have low recall for overall translational correspondences (Koehn et al., 20</context>
</contexts>
<marker>Spreyer, Frank, 2008</marker>
<rawString>Kathrin Spreyer and Anette Frank. 2008. Projectionbased acquisition of a temporal labeller. In Proceedings ofIJCNLP 2008, Hyderabad, India, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leonoor van der Beek</author>
<author>Gosse Bouma</author>
<author>Robert Malouf</author>
<author>Gertjan van Noord</author>
</authors>
<title>The Alpino dependency treebank.</title>
<date>2002</date>
<booktitle>In Computational Linguistics in the Netherlands (CLIN).</booktitle>
<marker>van der Beek, Bouma, Malouf, van Noord, 2002</marker>
<rawString>Leonoor van der Beek, Gosse Bouma, Robert Malouf, and Gertjan van Noord. 2002. The Alpino dependency treebank. In Computational Linguistics in the Netherlands (CLIN).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qin Iris Wang</author>
<author>Dale Schuurmans</author>
<author>Dekang Lin</author>
</authors>
<title>Semi-supervised convex training for dependency parsing.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-HLT 2008,</booktitle>
<pages>532--540</pages>
<location>Columbus, Ohio,</location>
<contexts>
<context position="6439" citStr="Wang et al., 2008" startWordPosition="985" endWordPosition="988">rom 33.9 to 65.7 for Spanish and from 26.3 to 52.4 for Chinese. But they need to be designed anew for every target language, which is time-consuming and requires knowledge of that language. Research in the field of unsupervised and weakly supervised parsing ranges from various forms of EM training (Pereira and Schabes, 1992; Klein and Manning, 2004; Smith and Eisner, 2004; Smith and Eisner, 2005) over bootstrapping approaches like selftraining (McClosky et al., 2006) to feature-based enhancements of discriminative reranking models (Koo et al., 2008) and the application of semisupervised SVMs (Wang et al., 2008). The partial correspondence method we present in this paper is compatible with such approaches and can be combined with other weakly supervised machine learning schemes. Our approach is similar to that of Clark and Curran (2006) who use partial training data (CCG lexical categories) for domain adaptation; however, they assume an existing CCG resource for the language in question to provide this data. 3 Projection of Dependency Trees Most state-of-the-art parsers for natural languages are data-driven and depend on the availability of sufficient amounts of labeled training data. However, manual</context>
</contexts>
<marker>Wang, Schuurmans, Lin, 2008</marker>
<rawString>Qin Iris Wang, Dale Schuurmans, and Dekang Lin. 2008. Semi-supervised convex training for dependency parsing. In Proceedings of ACL-HLT 2008, pages 532– 540, Columbus, Ohio, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
<author>Grace Ngai</author>
<author>Richard Wicentowski</author>
</authors>
<title>Inducing multilingual text analysis tools via robust projection across aligned corpora.</title>
<date>2001</date>
<booktitle>In Proceedings ofHLT</booktitle>
<contexts>
<context position="1806" citStr="Yarowsky et al. (2001)" startWordPosition="264" endWordPosition="267">ering techniques to deal with noise in unlabeled or automatically labeled training data, e.g., in the exploitation of parallel corpora for crosslingual projection of morphological, syntactic or semantic information. While heuristic approaches can implement (linguistic) knowledge that helps to detect noisy data (e.g., Hwa et al. (2005)), they are typically task- and language-specific and thus introduce a component of indirect supervision. Non-heuristic filtering techniques, on the other hand, employ reliability measures (often unrelated to the task) to predict high-precision data points (e.g., Yarowsky et al. (2001)). In order to reach a sufficient level of precision, filtering typically has to be aggressive, especially for highly structured tasks like parsing. Such aggressive filtering techniques incur massive data loss and enforce trade-offs between the quality and the amount of usable data. Ideally, a general filtering strategy for weakly supervised training of structured analysis tools should eliminate noisy subparts in the automatic annotation without discarding its high-precision aspects; thereby data loss would be kept to a minimum. In this paper, we propose an extremely simple approach to noise r</context>
<context position="4431" citStr="Yarowsky et al., 2001" startWordPosition="665" endWordPosition="668">iation for Computational Linguistics a. b. c. English (L1): I have two questions You are absolutely right You are absolutely right Dutch (L2): Ik heb twee vragen U heeft volkomen gelijk U heeft volkomen gelijk 3 2 Figure 1: Dependency tree projection from English to Dutch. (a) Ideal scenario with bidirectional alignments. (b) Projection fails due to weak alignments. (c) Constrained fallback projection. 1 2 Related Work Annotation projection has been applied to many different NLP tasks. On the word or phrase level, these include morphological analysis, part-of-speech tagging and NP-bracketing (Yarowsky et al., 2001), temporal analysis (Spreyer and Frank, 2008), or semantic role labeling (Pad´o and Lapata, 2006). In these tasks, word labels can technically be introduced in isolation, without reference to the rest of the annotation. This means that an aggressive filter can be used to discard unreliable data points (words in a sentence) without necessarily affecting highprecision data points in the same sentence. By using only the bidirectional word alignment links, one can implement a very robust such filter, as the bidirectional links are generally reliable, even though they have low recall for overall tr</context>
<context position="7247" citStr="Yarowsky et al., 2001" startWordPosition="1108" endWordPosition="1111"> similar to that of Clark and Curran (2006) who use partial training data (CCG lexical categories) for domain adaptation; however, they assume an existing CCG resource for the language in question to provide this data. 3 Projection of Dependency Trees Most state-of-the-art parsers for natural languages are data-driven and depend on the availability of sufficient amounts of labeled training data. However, manual creation of treebanks is time-consuming and labour-intensive. One way to avoid the expensive annotation process is to automatically label the training data using annotation projection (Yarowsky et al., 2001): Given a suitable resource (such as a parser) in language L1, and a word-aligned parallel corpus with languages L1 and L2, label the L1- portion of the parallel text (with the parser) and copy the annotations to the corresponding (i.e., aligned) elements in language L2. This is illustrated in Fig. 1a. The arrows between English and Dutch words indicate the word alignment. Assuming we have a parser to produce the dependency tree for the English sentence, we build the tree for the Dutch sentence by establishing arcs between words wD (e.g., Ik) and hD (heb) if there are aligned pairs (wD, wE) 13</context>
</contexts>
<marker>Yarowsky, Ngai, Wicentowski, 2001</marker>
<rawString>David Yarowsky, Grace Ngai, and Richard Wicentowski. 2001. Inducing multilingual text analysis tools via robust projection across aligned corpora. In Proceedings ofHLT 2001.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>