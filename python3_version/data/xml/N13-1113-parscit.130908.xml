<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000021">
<title confidence="0.9973775">
Improved Information Structure Analysis of Scientific Documents Through
Discourse and Lexical Constraints
</title>
<author confidence="0.997845">
Yufan Guo
</author>
<affiliation confidence="0.996903">
University of Cambridge, UK
</affiliation>
<email confidence="0.993447">
yg244@cam.ac.uk
</email>
<author confidence="0.993213">
Roi Reichart
</author>
<affiliation confidence="0.995138">
University of Cambridge, UK
</affiliation>
<email confidence="0.993659">
rr439@cam.ac.uk
</email>
<author confidence="0.993478">
Anna Korhonen
</author>
<affiliation confidence="0.994718">
University of Cambridge, UK
</affiliation>
<email confidence="0.995841">
alk23@cam.ac.uk
</email>
<sectionHeader confidence="0.995583" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999568944444444">
Inferring the information structure of scien-
tific documents is useful for many down-
stream applications. Existing feature-based
machine learning approaches to this task re-
quire substantial training data and suffer from
limited performance. Our idea is to guide
feature-based models with declarative domain
knowledge encoded as posterior distribution
constraints. We explore a rich set of discourse
and lexical constraints which we incorporate
through the Generalized Expectation (GE) cri-
terion. Our constrained model improves the
performance of existing fully and lightly su-
pervised models. Even a fully unsupervised
version of this model outperforms lightly su-
pervised feature-based models, showing that
our approach can be useful even when no la-
beled data is available.
</bodyText>
<sectionHeader confidence="0.99899" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999882058823529">
Techniques that enable automatic analysis of the in-
formation structure of scientific articles can help sci-
entists identify information of interest in the grow-
ing volume of scientific literature. For example,
classification of sentences according to argumenta-
tive zones (AZ) – an information structure scheme
that is applicable across scientific domains (Teufel
et al., 2009) – can support information retrieval, in-
formation extraction and summarization (Teufel and
Moens, 2002; Tbahriti et al., 2006; Ruch et al.,
2007; Liakata et al., 2012; Contractor et al., 2012).
Previous work on sentence-based classification of
scientific literature according to categories of infor-
mation structure has mostly used feature-based ma-
chine learning, such as Support Vector Machines
(SVM) and Conditional Random Fields (CRF) (e.g.
(Teufel and Moens, 2002; Lin et al., 2006; Hiro-
hata et al., 2008; Shatkay et al., 2008; Guo et al.,
2010; Liakata et al., 2012)). Unfortunately, the per-
formance of these methods is rather limited, as indi-
cated e.g. by the relatively low numbers reported by
Liakata et al. (2012) in biochemistry and chemistry
with per-class F-scores ranging from .18 to .76.
We propose a novel approach to this task in which
traditional feature-based models are augmented with
explicit declarative expert and domain knowledge,
and apply it to sentence-based AZ. We explore two
sources of declarative knowledge for our task - dis-
course and lexical. One way to utilize discourse
knowledge is to guide the model predictions by en-
coding a desired predicted class (i.e. information
category) distribution in a given position in the doc-
ument. Consider, for example, sentence (1) from the
first paragraph of the Discussion section in a paper:
</bodyText>
<listItem confidence="0.767472333333333">
(1) In time, this will prove to be most suitable for
detailed analysis of the role of these hormones in
mammary cancer development.
</listItem>
<bodyText confidence="0.999419363636364">
Although the future tense and cue phrases such as
“in time” can indicate that authors are discussing fu-
ture work (i.e. the “Future work” class in the AZ
scheme), in this case they refer to their own contri-
bution (i.e. the “Conclusion” class in AZ). As most
authors discuss their own contribution in the begin-
ning of the Discussion section and future directions
in the end, encoding the desired class distribution as
a function of the position in this section can guide
the model to the right decision.
Likewise, lexical knowledge can guide the model
</bodyText>
<page confidence="0.961818">
928
</page>
<note confidence="0.4725185">
Proceedings of NAACL-HLT 2013, pages 928–937,
Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.99922925">
through predicted class distributions for sentences
that contain specific vocabulary. Consider, for ex-
ample, sentence (2):
(2) The values calculated for lungs include the
presumed DNA adduct of BA and might thus be
slightly overestimated.
The verb “calculated” usually indicates the
“Method” class, but, when accompanied by the
modal verb “might”, it is more likely to imply that
authors are interpreting their own results (i.e. the
“Conclusion” class in AZ). This can be explicitly
encoded in the model through a target distribution
for sentences containing certain modal verbs.
Recent work has shown that explicit declaration
of domain and expert knowledge can be highly use-
ful for structured NLP tasks such as parsing, POS
tagging and information extraction (Chang et al.,
2007; Mann and McCallum, 2008; Ganchev et al.,
2010). These works have encoded expert knowledge
through constraints, with different frameworks dif-
fering in the type of constraints and the inference
and learning algorithms used. We build on the Gen-
eralized Expectation (GE) framework (Mann and
McCallum, 2007) which encodes expert knowledge
through a preference (i.e. soft) constraints for pa-
rameter settings for which the predicted label distri-
bution matches a target distribution.
In order to integrate domain knowledge with a
features-based model, we develop a simple taxon-
omy of constraints (i.e. desired class distributions)
and employ a top-down classification algorithm on
top of a Maximum Entropy Model augmented with
GE constraints. This algorithm enables us to break
the multi-class prediction into a pipeline of consecu-
tive, simpler predictions which can be better assisted
by the encoded knowledge.
We experiment in the biological domain with the
eight-category AZ scheme (Table 1) adapted from
(Mizuta et al., 2006) and described in (Contractor
et al., 2012). The results show that our constrained
model substantially outperforms a baseline uncon-
strained Maximum Entropy Model. While this type
of constrained models have previously improved
the feature-based model performance mostly in the
weakly supervised and domain adaptation scenarios
(e.g. (Mann and McCallum, 2007; Mann and Mc-
Callum, 2008; Ganchev et al., 2010)), we demon-
strate substantial gains both when the Maximum En-
</bodyText>
<tableCaption confidence="0.9588225">
Table 1: The AZ categories included in the categorization
scheme of this paper.
</tableCaption>
<figure confidence="0.877338222222222">
Zone Definition
Background (BKG) the background of the study
Problem (PROB) the research problem
Method (METH) the methods used
Result (RES) the results achieved
Conclusion (CON) the authors’ conclusions
Connection (CN) work consistent with the current work
Difference (DIFF) work inconsistent with the current work
Future work (FUT) the potential future direction of the research
</figure>
<bodyText confidence="0.998617">
tropy Model is fully trained and when its training
data is sparse. This demonstrates the importance of
expert knowledge for our task and supports our mod-
eling decision that combines feature-based methods
with domain knowledge encoded via constraints.
</bodyText>
<sectionHeader confidence="0.994542" genericHeader="introduction">
2 Previous work
</sectionHeader>
<bodyText confidence="0.999083290322581">
Information structure analysis The information
structure of scientific documents (e.g. journal ar-
ticles, abstracts, essays) can be analyzed in terms
of patterns of topics, functions or relations observed
in multi-sentence scientific text. Computational ap-
proaches have mainly focused on analysis based
on argumentative zones (Teufel and Moens, 2002;
Mizuta et al., 2006; Hachey and Grover, 2006;
Teufel et al., 2009), discourse structure (Burstein et
al., 2003; Webber et al., 2011), qualitative dimen-
sions (Shatkay et al., 2008), scientific claims (Blake,
2009), scientific concepts (Liakata et al., 2010) and
information status (Markert et al., 2012).
Most existing methods for analyzing scientific
text according to information structure use full
supervision in the form of thousands of manu-
ally annotated sentences (Teufel and Moens, 2002;
Burstein et al., 2003; Mizuta et al., 2006; Shatkay
et al., 2008; Guo et al., 2010; Liakata et al., 2012;
Markert et al., 2012). Because manual annotation is
prohibitively expensive, approaches based on light
supervision are now emerging for the task, including
those based on active learning and self-training (Guo
et al., 2011) and unsupervised methods (Varga et al.,
2012; Reichart and Korhonen, 2012). Unfortunately,
these approaches do not reach the performance level
of fully supervised models, let alone exceed it. Our
novel method addresses this problem.
Declarative knowledge and constraints Previ-
ous work has shown that incorporating declara-
tive constraints into feature-based machine learning
</bodyText>
<page confidence="0.99761">
929
</page>
<bodyText confidence="0.999888578947369">
models works well in many NLP tasks (Chang et
al., 2007; Mann and McCallum, 2008; Druck et al.,
2008; Bellare et al., 2009; Ganchev et al., 2010).
Such constraints can be used in a semi-supervised or
unsupervised fashion. For example, (Mann and Mc-
Callum, 2008) shows that using CRF in conjunction
with auxiliary constraints on unlabeled data signif-
icantly outperforms traditional CRF in information
extraction, and (Druck et al., 2008) shows that using
declarative constraints alone for unsupervised learn-
ing achieves good results in text classification. We
show that declarative constraints can be highly use-
ful for the identification of information structure of
scientific documents. In contrast with most previous
works, we show that such constraints can improve
the performance of a fully supervised model. The
constraints are particularly helpful for identifying
low-frequency information categories, but still yield
high performance on high-frequency categories.
</bodyText>
<sectionHeader confidence="0.902278" genericHeader="method">
3 Maximum-Entropy Estimation and
Generalized Expectation (GE)
</sectionHeader>
<bodyText confidence="0.998078428571428">
In this section we describe the Generalized Expecta-
tion method for declarative knowledge encoding.
Maximum Entropy (ME) The idea of General-
ized Expectation (Dud´ık, 2007; Mann and McCal-
lum, 2008; Druck et al., 2008) stems from the prin-
ciple of maximum entropy (Jaynes, 1957; Pietra and
Pietra, 1993) which raises the following constrained
</bodyText>
<equation confidence="0.964649571428571">
optimization problem:
max
p
subject to Ep[f(·)] = E˜p[f(·)]
p(·) ≥ 0
X
p(·) = 1, (1)
</equation>
<bodyText confidence="0.999914">
where p(·) is the empirical distribution, p(·) is a
probability distribution in the model and H(·) is the
corresponding information entropy, f(·) is a collec-
tion of feature functions, and Ep[f(·)] and Ef,[f(·)]
are the expectations of f with respect to p(·) and
p(·). An example of p(·) could be a conditional
probability distribution p(y|x), and H(·) could be
a conditional entropy H(y|x). The optimal p(y|x)
will take on an exponential form:
</bodyText>
<equation confidence="0.989468666666667">
1
pλ(y|x) = exp(λ · f(x, y)), (2)
Zλ
</equation>
<bodyText confidence="0.9979372">
where A is the Lagrange multipliers in the corre-
sponding unconstrained objective function, and Z),
is the partition function. The dual problem be-
comes maximizing the conditional log-likelihood of
labeled data L (Berger et al., 1996):
</bodyText>
<equation confidence="0.93112825">
X log(pλ(yi|xi)), (3)
max
λ
(xi,yi)∈L
</equation>
<bodyText confidence="0.5571425">
which is usually known as a Log-linear or Maximum
Entropy Model (MaxEnt).
ME with Generalized Expectation The objec-
tive function and the constraints on expectations in
</bodyText>
<equation confidence="0.817781333333333">
(1) can be generalized to:
˜p(x)D(pλ(y|x)||p0(y|x))
− g(E˜p(x)[Epa(y|x)[f(x, y)|x]]), (4)
</equation>
<bodyText confidence="0.999858888888889">
where D(p),||p0) is the divergence from p), to a base
distribution p0, and g(·) is a constraint/penalty func-
tion that takes empirical evidence EP(x�y)[f(x, y)] as
a reference point (Pietra and Pietra, 1993; Chen et
al., 2000; Dud´ık, 2007). Note that a special case of
this is MaxEnt where p0 is set to be a uniform distri-
bution, D(·) to be the KL divergence, and g(·) to be
an equality constraint.
The constraint g(·) can be set in a relaxed manner:
</bodyText>
<equation confidence="0.657827">
(E˜p(x)[Epa(y|x)[fk(x, y)|x]] − E˜p(x,y)[fk(x, y)])2,
</equation>
<bodyText confidence="0.999647333333333">
which is the logarithm of a Gaussian distribution
centered at the reference values with a diagonal co-
variance matrix (Pietra and Pietra, 1993), and the
dual problem will become a regularized MaxEnt
with a Gaussian prior (µk = 0, Qk = Pk) over the
parameters:
</bodyText>
<equation confidence="0.969527">
X X 2
max log(pλ(yi|xi)) − λk (5)
λ k 2σ2k
(xi,yi)∈L
</equation>
<bodyText confidence="0.99605525">
Such a model can be further extended to include
expert knowledge or auxiliary constraints on unla-
beled data U (Mann and McCallum, 2008; Druck et
al., 2008; Bellare et al., 2009):
</bodyText>
<equation confidence="0.9987168">
X X λ2
max log(pλ(yi|xi)) − k
λ k 2σ2k
(xi,yi)∈L
− γg∗(Epa(y|x)[f∗(x, y)]) (6)
</equation>
<bodyText confidence="0.9992824">
where f*(·) is a collection of auxiliary feature func-
tions on U, g*(·) is a constraint function that takes
expert/declarative knowledge Ep∗(y|x)[f*(x, y)] as a
reference point, and -y is the weight of the auxiliary
GE term.
</bodyText>
<equation confidence="0.707718666666666">
H(·)
X
max −
λ
x
1
X
k
2ρ2k
</equation>
<page confidence="0.958822">
930
</page>
<bodyText confidence="0.999932571428571">
The auxiliary constraint g∗(·) can take on many
forms and the one we used in this work is an L2
penalty function (Dudik, 2007). We trained the
model with L-BFGS (Nocedal, 1980) in supervised,
semi-supervised and unsupervised fashions on la-
beled and/or unlabeled data, using the Mallet soft-
ware (McCallum, 2002).
</bodyText>
<sectionHeader confidence="0.992162" genericHeader="method">
4 Incorporating Expert Knowledge into
GE constraints
</sectionHeader>
<bodyText confidence="0.9999445">
We defined the auxiliary feature functions – the ex-
pert knowledge on unlabeled data as1:
</bodyText>
<equation confidence="0.983854">
f∗k (x, y) = ✶(xk,yk)(x, y),
such that Ep*(y|x)[fk(x, y)] = p∗(yk|xk), (7)
</equation>
<bodyText confidence="0.999318666666667">
where ✶(xk�yk)(x, y) is an indicator function, and
p∗(yk|xk) is a conditional probability specified in
the form of
</bodyText>
<equation confidence="0.990101">
p∗(yk|xk) E [ak, bk] (8)
</equation>
<bodyText confidence="0.9718944">
by experts. In particular, we took
as the reference point when calculating g∗(·).
We defined two types of constraints: those based
on discourse properties such as the location of a sen-
tence in a particular section or paragraph, and those
based on lexical properties such as citations, refer-
ences to tables and figures, word lists, tenses, and
so on. Note that the word lists actually contain both
lexical and semantic information.
To make an efficient use of the declarative knowl-
edge we build a taxonomy of information structure
categories centered around the distinction between
categories that describe the authors’ OWN work and
those that describe OTHER work (see Section 5). In
practice, our model labels every sentence with an
AZ category augmented by one of the two cate-
gories, OWN or OTHER. In evaluation we consider
only the standard AZ categories which are part of
the annotation scheme of (Contractor et al., 2012).
1Accordingly, Ep,(y|x)[fk(x, y)] = pλ(yk|xk)
</bodyText>
<tableCaption confidence="0.894588666666667">
Table 2: Discourse and lexical constraints for identifying infor-
mation categories at different levels of the information structure
taxonomy.
</tableCaption>
<figure confidence="0.988487492307692">
(a) OWN / OTHER
OWN Discourse
(1) Target(last part of paragraph) = 1
(2) Target(last part of section) = 1
Lexical
(3) Target(tables/figures) ≥ 1
(4) ∃x ∈ {w|w∼we} Target(x) = 1
∧ ∀y ∈ {w|w∼previous} Target(y) = 0
(5) ∃x ∈ {w|w∼thus} Target(x) = 1
OTHER Lexical
(6) Target(cite) = 1
(7) Target(cite) &gt; 1
(8) Backward(cite) = 1
∧ ∃x ∈ {w|w∼in addition} Target(x) = 1
(b) PROB / METH / RES / CON / FUT
PROB Discourse
(1) Target(last part in section) = 1
Lexical
(2) ∃x ∈ {w|w∼aim} Target(x) = 1
(3) ∃x ∈ {w|w∼question} Target(x) = 1
(4) ∃x ∈ {w|w∼investigate} Target(x) = 1
METH Lexical
(5) ∃x ∈ {w|w∼{use,method}} Target(x) = 1
RES Lexical
(6) Target(tables/figures) ≥ 1
(7) ∃x ∈ {w|w∼observe} Target(x) = 1
CON Lexical
(8) Target(cite) ≥ 1
(9) ∃x ∈ {w|w∼conclude} Target(x) = 1
(10) ∃x ∈ {w|w∼{suggest, thus, because, likely}}
Target(x) = 1
FUT Discourse
(11) Target(first part in section) = 1
(12) Target(last part in section) = 1
∧ ∃x ∈ {w|w∼{will,need,future}} Target(x) = 1
Lexical
(13) ∃x {w|w∼will,future} Target(x) = 1
(14) Target(present continuous tense) = 1
(c) BKG / CN / DIFF
ak if pλ(yk|xk) &lt; a
bk if pλ(yk|xk) &gt; b (9)
pλ(yk|xk) if a &lt; pλ(yk|xk) &lt; b
⎧
⎨
⎩
p∗(yk|xk) =
BKG Discourse
(1) Target(first part in paragraph) = 1
(2) Target(first part in section) = 1
Lexical
(3) ∃x ∈ {w|w∼we} Target(x) = 1
∧ ∀y ∈ {w|w∼previous} Target(y) = 0
(4) Forward(cite) = 1
∧ ∀x ∈ {w|w∼{consistent,inconsistent,than}}
(Target(x) = 0 ∧ Forward(x) = 0)
CN Lexical
(5) ∃x ∈ {w|w∼consistent} Target(x) = 1
(6) ∃x ∈ {w|w∼consistent} Forward(x) = 1
Lexical
(7) ∃x ∈ {w|w∼inconsistent} Target(x) = 1
(8) ∃x ∈ {w|w∼inconsistent} Forward(x) = 1
(9) ∃x ∈ {w|w∼{inconsistent,than,however}}
Forward(x) = 1 ∧ ∃y ∈ {w|w∼we} Forward(y) = 1
∧ ∀z ∈ {w|w∼previous}} Forward(z) = 0
DIFF
</figure>
<page confidence="0.985773">
931
</page>
<tableCaption confidence="0.99988">
Table 3: The lexical sets used as properties in the constraints.
</tableCaption>
<table confidence="0.935426458333333">
Cue Synonyms
our, present study
previously, recent, recently
therefore
objective, goal, purpose
hypothesis, ?
explore, study, test, examine, evaluate, assess, deter-
mine, characterize, analyze, report, present
employ
algorithm, assay
see, find, show
conclusion, summarize, summary
illustrate, demonstrate, imply, indicate, confirm, re-
flect, support, prove, reveal
result from, attribute to
probable, probably, possible, possibly, may, could
remain
further
match, agree, support, in line, in agreement, similar,
same, analogous
conflicting, conflict, contrast, contrary, differ, differ-
ent, difference
compare
other hand, although, though, but
</table>
<bodyText confidence="0.998596413793103">
The constraints in Table 2(a) refer to the top level
of this taxonomy: distinction between the authors’
own work and the work of others, and the constraints
in Tables 2(b)-(c) refer to the bottom level of the tax-
onomy: distinction between AZ categories related to
the authors’ own work (Table 2(b)) and other’s work
(Table 2(c)).
The first and second columns in each table refer
to the y and x variables in Equation (8), respectively.
The functions Target(·), Forward(·) and Backward(·)
refer to the property value for the target, next and
preceding sentence, respectively. If their value is 1
then the property holds for the respective sentence,
if it is 0, the property does not hold. In some cases
the value of such functions can be greater than 1,
meaning that the property appears multiple times in
the sentence. Terms of the form {wJw—{wi}} refer
to any word/bi-grams that have the same sense as wi,
where the actual word set we use with every example
word in Table 2 is described in Table 3.
For example, take constraints (1) and (4) in Table
2(a). The former is a standard discourse constraint
that refers to the probability that the target sentence
describes the authors’ own work given that it appears
in the last of the ten parts in the paragraph. The lat-
ter is a standard lexical constraint that refers to the
probability that a sentence presents other people’s
work given that it contains any words in {we, our,
present study} and that it doesn’t contain any words
</bodyText>
<figureCaption confidence="0.998426">
Figure 1: The constraint taxonomy for top-down modeling.
</figureCaption>
<table confidence="0.750701">
INFO [Table 2(a)]
OWN [Table 2(b)] OTHER [Table 2(c)]
</table>
<bodyText confidence="0.99890575">
in {previous, previously, recent, recently}. Our con-
straint set further includes constraints that combine
both types of information. For example, constraint
(12) in Table 2(b) refers to the probability that a sen-
tence discusses future work given that it appears in
the last of the ten parts of the section (discourse) and
that it contains at least one word in {will, future, fur-
ther, need, remain} (lexical).
</bodyText>
<sectionHeader confidence="0.999786" genericHeader="method">
5 Top-Down Model
</sectionHeader>
<bodyText confidence="0.99995375">
An interesting property of our task and domain is
that the available expert knowledge does not directly
support the distinctions between AZ categories, but
it does provide valuable indirect guidance. For ex-
ample, the number of citations in a sentence is only
useful for separating the authors’ work from other
people’s work, but not for further fine grained dis-
tinctions between zone categories. Moreover, those
constraints that are useful for making fine grained
distinctions between AZ categories are usually use-
ful only for a particular subset of the categories only.
For example, all the constraints in Table 2(b) are
conditioned on the assumption that the sentence de-
scribes the authors’ own work.
To make the best use of the domain knowledge,
we developed a simple constraint taxonomy, and ap-
ply a top-down classification approach which uti-
lizes it. The taxonomy is presented in Figure 1. For
classification we trained three MaxEnt models aug-
mented with GE constraints: one for distinguishing
between OWN and OTHER2, one for distinguishing
between the AZ categories under the OWN auxiliary
category and one for distinguishing between the AZ
categories under the OTHER auxiliary category. At
test time we first apply the first classifier and based
on its prediction we apply either the classifier that
distinguishes between OWN categories or the one
that distinguishes between OTHER categories.
</bodyText>
<footnote confidence="0.9963825">
2For the training of this model, each training data AZ cate-
gory is mapped to its respective auxiliary class.
</footnote>
<note confidence="0.781288">
PROB METH RES CON FUT
</note>
<figure confidence="0.99847475">
BKG CN DIFF
we
previous
thus
aim
question
investigate
use
method
observe
conclude
suggest
because
likely
need
future
consistent
inconsistent
than
however
</figure>
<page confidence="0.987165">
932
</page>
<sectionHeader confidence="0.996423" genericHeader="method">
6 Experiments
</sectionHeader>
<bodyText confidence="0.999820369565217">
Data We used the full paper corpus used by Contrac-
tor et al. (2012) which contains 8171 sentences from
50 biomedical journal articles. The corpus is anno-
tated according to the AZ scheme described in Table
1. AZ describes the logical structure, scientific argu-
mentation and intellectual attribution of a scientific
paper. It was originally introduced by Teufel and
Moens (2002) and applied to computational linguis-
tics papers, and later adapted to other domains such
as biology (Mizuta et al., 2006) – which we used in
this work – and chemistry (Teufel et al., 2009).
Table 4 shows the AZ class distribution in full ar-
ticles as well as in individual sections. Since section
names vary across scientific articles, we grouped
similar sections before calculating the statistics (e.g.
Discussion and Conclusions sections were grouped
under Discussion). We can see that although there is
a major category in each section (e.g. CON in Dis-
cussion), up to 36.5% of the sentences in each sec-
tion still belong to other categories.
Features We extracted the following features
from each sentence and used them in the feature-
based classifiers: (1) Discourse features: location in
the article/section/paragraph. For this feature each
text batch was divided to ten equal size parts and the
corresponding feature value identifies the relevant
part; (2) Lexical features: number of citations and
references to tables and figures (0, 1, or more), word,
bi-gram, verb, and verb class (obtained by spectral
clustering (Sun and Korhonen, 2009)); (3) Syntac-
tic features: tense and voice (POS tags of main and
auxiliary verbs), grammatical relation, subject and
object. The lexical and the syntactic features were
extracted for the represented sentence as well as for
its surrounding sentences. We used the C&amp;C POS
tagger and parser (Curran et al., 2007) for extract-
ing the lexical and the syntactic features. Note that
all the information encoded into our constraints is
also encoded in the features and is thus available to
the feature-based model. This enables us to properly
evaluate the impact of our modeling decision which
augments a feature-based model with constraints.
Baselines We compared our model against four
baselines, two with full supervision: Support Vec-
tor Machines (SVM) and Maximum Entropy Mod-
els (MaxEnt), and two with light supervision: Trans-
</bodyText>
<tableCaption confidence="0.969857">
Table 4: Class distribution (shown in percentages) in articles
and their individual sections in the AZ-annotated corpus.
</tableCaption>
<table confidence="0.983745">
BKG PROB METH RES CON CN DIFF FUT
Article 16.9 2.8 34.8 17.9 22.3 4.3 0.8 0.2
Introduction 74.8 13.2 5.4 0.6 5.9 0.1 - -
Methods 0.5 0.2 97.5 1.4 0.2 0.2 0.1 -
Results 4.0 2.1 11.7 68.9 12.1 1.1 0.1 -
Discussion 16.9 1.1 0.7 1.5 63.5 13.3 2.4 0.7
</table>
<tableCaption confidence="0.998818">
Table 5: Performance of baselines on the Discussion section.
</tableCaption>
<sectionHeader confidence="0.356363" genericHeader="method">
BKG PROB METH RES CON CN DIFF FUT
</sectionHeader>
<subsectionHeader confidence="0.50955">
Full supervision
</subsectionHeader>
<equation confidence="0.976617714285714">
SVM .56 0 0 0 .84 .35 0 0
MaxEnt .55 .08 0 0 .84 .38 0 0
Light supervision with 150 labeled sentence
SVM .26 0 0 0 .80 .05 0 0
TSVM .25 .04 .04 .03 .33 14 .06 .02
MaxEnt .25 0 0 0 .80 .10 0 0
MaxEnt+ER .23 0 0 0 .80 .07 0 0
</equation>
<bodyText confidence="0.99991045">
ductive SVM (TSVM) and semi-supervised Max-
Ent based on Entropy Regularization (ER) (Vapnik,
1998; Jiao et al., 2006). SVM and MaxEnt have
proved successful in information structure analysis
(e.g. (Merity et al., 2009; Guo et al., 2011)) but,
to the best of our knowledge, their semi-supervised
versions have not been used for AZ of full articles.
Parameter tuning The boundaries of the ref-
erence probabilities (ak and bk in Equation (8))
were defined and optimized on the development data
which consists of one third of the corpus. We con-
sidered six types of boundaries: Fairly High for
1, High for [0.9,1), Medium High for [0.5,0.9),
Medium Low for [0.1,0.5), Low for [0,0.1), and
Fairly Low for 0.
Evaluation We evaluated the precision, recall and
F-score for each category, using a standard ten-fold
cross-validation scheme. The models were tested on
each of the ten folds and trained on the rest of them,
and the results were averaged across the ten folds.
</bodyText>
<sectionHeader confidence="0.999727" genericHeader="evaluation">
7 Results
</sectionHeader>
<bodyText confidence="0.987586888888889">
We report results at two levels of granularity. We
first provide detailed results for the Discussion sec-
tion which should be, as is clearly evident from Ta-
ble 4, the most difficult section for AZ prediction as
only 63.5% of its sentences take its most dominant
class (CON). As we show below, this is also where
our constrained model is most effective. We then
show the advantages of our model for other sections.
Results for the Discussion section To get a bet-
</bodyText>
<page confidence="0.998977">
933
</page>
<tableCaption confidence="0.832201">
Table 6: Discussion section performance of MaxEnt, MaxEnt+GE and a MaxEnt+GE model that does not include our top-down
classification scheme. Results are presented for different amounts of labeled training data. The MaxEnt+GE (Top-down) model
outperforms the MaxEnt in 44 out of 48 cases, and MaxEnt+GE (Flat) in 39 out of 48 cases.
</tableCaption>
<table confidence="0.9992941">
MaxEnt MaxEnt + GE (Top-down) MaxEnt + GE (Flat)
50 100 150 500 1000 Full 50 100 150 500 1000 Full 50 100 150 500 1000 Full
BKG .10 .26 .25 .44 .48 .55 .49 .49 .48 .52 .55 .57 .35 .37 .37 .46 .51 .53
PROB 0 0 0 0 0 0 .38 .16 .29 .13 .30 .41 .38 .23 .19 .39 .38 .33
METH 0 0 0 0 0 0 .17 .22 .37 .35 .50 .39 .16 .17 .21 .24 .32 .29
RES 0 0 0 0 0 0 .18 .24 .58 0 0 .46 .13 .05 .21 .31 .25 .34
CON .79 .80 .80 .83 .83 .84 .77 .78 .82 .83 .84 .84 .63 .66 .68 .74 .78 .78
CN .02 .04 .10 .24 .34 .38 .29 .31 .33 .35 .40 .39 .21 .21 .24 .26 .30 .32
DIFF 0 0 0 0 0 0 .26 .25 .25 .19 .24 .21 .14 .16 .15 .14 .18 .17
FUT 0 0 0 0 0 0 .35 .38 .31 .25 .35 .31 .36 .36 .39 .33 .25 .37
</table>
<figureCaption confidence="0.9719885">
Figure 2: Performance of the MaxEnt and MaxEnt+GE models on the Introduction (left), Methods (middle) and Results (right)
sections. The MaxEnt+GE model is superior.
</figureCaption>
<figure confidence="0.99081936">
MaxEnt MaxEnt+GE
MaxEnt MaxEnt+GE
MaxEnt MaxEnt+GE
F-score
0.8
0.6
0.4
0.2
0
1
F-score
0.8
0.6
0.4
0.2
0
1
F-score
0.8
0.6
0.4
0.2
0
1
BKG PROB METH RES CON CN DIFF FUT BKG PROB MErH RES CON CN DIFF FUr BKG PROB METH RES CON CN DIFF FUT
</figure>
<tableCaption confidence="0.8724728">
Table 7: Discussion section performance of the MaxEnt, Max-
Ent+GE and unsupervised GE models when the former two are
trained with 150 labeled sentences. Unsupervised GE outper-
forms the standard MaxEnt model for all categories except for
CON – the major ctegory of the section. The result pattern for
</tableCaption>
<table confidence="0.985674642857143">
MaxEnt MaxEnt+GE
the other sections are very similar.
MaxEnt F MaxEnt + GE Unsup GE
P R P R F P R F
BKG .38 .19 .25 .49 .48 .48 .49 .44 .46
.6 0 0 0 .38 .23 .29 .28 .38 .32
PROB 0 0 0 .29 .50 .37 .08 .56 .14
METH 0 0 0 .68 .51 .58 .08 .51 .14
.4RES .69 .96 .80 .81 .84 .82 .74 .69 .71
CON .35 .06 .10 .39 .29 .33 .40 .13 .20
CN 0 0 0 .21 .30 .25 .12 .13 .12
DIFF 0 0 S0 ON.24 .44 .31 .26 .61 .36
0 RO ET D FU
FUT
</table>
<bodyText confidence="0.999877153846154">
ter understanding of the nature of the challenge we
face, Table 5 shows the F-scores of fully- and semi-
supervised SVM and MaxEnt on the Discussion sec-
tion. The dominant zone category CON, which ac-
counts for 63.5% of the section sentences, has the
highest F-scores for all methods and scenarios. Most
of the methods also identify the second and the third
most frequent zones BKG and CN, but with relatively
lower F-scores. Other low-frequency categories can
hardly be identified by any of the methods regardless
of the amount of labeled data available for training.
Note that the compared models perform quite sim-
ilarly. We therefore use the MaxEnt model, which
</bodyText>
<tableCaption confidence="0.957501">
Table 8: Analysis of the impact of the different constraint types
for the lightly supervised and the fully supervised cases. Results
are presented for the Discussion section. Using only the lexical
constraints is generally preferable in the fully supervised case.
Combining the different constraint types is preferable for the
lightly supervised case.
</tableCaption>
<table confidence="0.9862901">
Discourse Lexical Full Discourse+Lexical
150 Full 150 150 Full
BKG .29 .55 .46 .58 .48 .57
PROB 0 0 .37 .40 .29 .41
METH 0 .11 .29 .35 .37 .39
RES 0 .06 .32 .47 .58 .46
CON .81 .84 .80 .84 .82 .84
CN .12 .34 .35 .42 .33 .39
DIFF 0 0 .21 .21 .25 .21
FUT 0 0 0 .29 .31 .31
</table>
<bodyText confidence="0.998058461538462">
is most naturally augmented with GE constraints, as
the baseline unconstrained model.
When adding the GE constraints we observe a
substantial performance gain, in both the fully and
the lightly supervised cases, especially for the low-
frequency categories. Table 6 presents the F-scores
of MaxEnt with and without GE constraints (“Max-
Ent+GE (Top-down)” and “MaxEnt”) in the light
and full supervision scenarios. Incorporating GE
into MaxEnt results in a substantial F-score im-
provement for all AZ categories except for the ma-
jor category CON for which the performance is kept
very similar. In total, MaxEnt+GE (Top-down) is
</bodyText>
<page confidence="0.996301">
934
</page>
<bodyText confidence="0.999982583333333">
better in 44 out of the 48 cases presented in the table.
Importantly, the constrained model provides sub-
stantial improvements for both the relatively high-
frequency classes (BKG and CN which together label
30.2% of the sentences) and for the low-frequency
classes (which together label 6.4% of the sentences).
The table also clearly demonstrates the impact of
our tree-based top-down classification scheme, by
comparing the Top-down version of MaxEnt+GE
to the standard “Flat” version. In 39 out of 48
cases, the Top-down model performs better. In some
cases, especially for high-frequency categories and
when the amount of training data increases, un-
constrained MaxEnt even outperforms the flat Max-
Ent+GE model. The results presented in the rest of
the paper for the MaxEnt+GE model therefore refer
to its Top-down version.
All sections We next turn to the performance of
our model on the three other sections. Our exper-
iments show that augmenting the MaxEnt model
with domain knowledge constraints improves per-
formance for all the categories (either low or high
frequency), except the major section category, and
keep the performance for the latter on the same level.
Figure 2 demonstrates this pattern for the lightly su-
pervised case with 150 training sentences but the
same pattern applies to all other amounts of training
data, including the fully supervised case. Naturally,
we cannot demonstrate all these cases due to space
limitations. The result patterns are very similar to
those presented above for the Discussion section.
Unsupervised GE We next explore the quality of
the domain knowledge constraints when used in iso-
lation from a feature-based model. The objective
function of this model is identical to Equation (6)
except that the first (likelihood) term is omitted. Our
experiments reveal that this unsupervised GE model
outperforms standard MaxEnt for all the categories
except the major category of the section, when up
to 150 training sentences are used. Table 7 demon-
strates this for the Discussion section. This pattern
holds for the other scientific article sections. Even
when more than 150 labeled sentences are used, the
unsupervised model better detects the low frequency
categories (i.e. those that label less than 10% of
the sentences) for all sections. These results provide
strong evidence for the usefulness of our constraints
even when they are used with no labeled data.
Model component analysis We finally analyze
the impact of the different types of constraints on
the performance of our model. Table 8 presents the
Discussion section performance of the constrained
model with only one or the full set of constraints.
Interestingly, when the feature-based model is fully
trained the application of the lexical constraints
alone results in a very similar performance to the
application of the full set of lexical and discourse
constraints. It is only in the lightly supervised case
where the full set of constraints is required and re-
sults in the best performing model.
</bodyText>
<sectionHeader confidence="0.997159" genericHeader="conclusions">
8 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999981272727273">
We have explored the application of posterior dis-
course and lexical constraints for the analysis of the
information structure of scientific documents. Our
results are strong. Our constrained model outper-
forms standard feature-based models by a large mar-
gin in both the fully and the lightly supervised cases.
Even an unsupervised model based on these con-
straints provides substantial gains over feature-based
models for most AZ categories.
We provide a detailed analysis of the results
which reveals a number of interesting properties of
our model which may be useful for future research.
First, the constrained model significantly outper-
forms its unconstrained counterpart for low-medium
frequency categories while keeping the performance
on the major section category very similar to that of
the baseline model. Improved modeling of the major
category is one direction for future research. Sec-
ond, our full constraint set is most beneficial in the
lightly supervised case while the lexical constraints
alone yield equally good performance in the fully
supervised case. This calls for better understand-
ing of the role of discourse constraints for our task
as well as for the design of additional constraints
that can enhance the model performance either in
combination with the existing constraints or when
separately applied to the task. Finally, we demon-
strated that our top-down tree classification scheme
provides a substantial portion of our model’s impact.
A clear direction for future research is the design of
more fine-grained constraint taxonomies which can
enable efficient usage of other constraint types and
can result in further improvements in performance.
</bodyText>
<page confidence="0.997616">
935
</page>
<sectionHeader confidence="0.990005" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9996918">
Kedar Bellare, Gregory Druck, and Andrew McCallum.
2009. Alternating projections for learning with expec-
tation constraints. In Proceedings of the Twenty-Fifth
Conference on Uncertainty in Artificial Intelligence,
UAI ’09, pages 43–50, Arlington, Virginia, United
States. AUAI Press.
Adam L. Berger, Vincent J. Della Pietra, and Stephen
A. Della Pietra. 1996. A maximum entropy approach
to natural language processing. Comput. Linguist.,
22(1):39–71.
Catherine Blake. 2009. Beyond genes, proteins, and
abstracts: Identifying scientific claims from full-text
biomedical articles. JBiomed Inform, 43(2):173–89.
Jill Burstein, Daniel Marcu, and Kevin Knight. 2003.
Finding the write stuff: Automatic identification of
discourse structure in student essays. IEEE Intelligent
Systems, 18(1):32–39.
M.W. Chang, L. Ratinovc, and D. Roth. 2007. Guiding
semi-supervision with constraint-driven learning. In
ACL.
Stanley F. Chen, Ronald Rosenfeld, and Associate Mem-
ber. 2000. A survey of smoothing techniques for me
models. IEEE Transactions on Speech and Audio Pro-
cessing, 8:37–50.
Danish Contractor, Yufan Guo, and Anna Korhonen.
2012. Using argumentative zones for extractive sum-
marization of scientific articles. In COLING.
J. R. Curran, S. Clark, and J. Bos. 2007. Linguisti-
cally motivated large-scale nlp with c&amp;c and boxer. In
Proceedings of the ACL 2007 Demonstrations Session,
pages 33–36.
Gregory Druck, Gideon Mann, and Andrew McCallum.
2008. Learning from labeled features using gener-
alized expectation criteria. In Proceedings of the
31st annual international ACM SIGIR conference on
Research and development in information retrieval,
pages 595–602.
Miroslav Dud´ık. 2007. Maximum entropy density
estimation and modeling geographic distributions of
species. Ph.D. thesis.
K. Ganchev, J. Graca, J. Gillenwater, and B. Taskar.
2010. Posterior regularization for structured latent
variable models. Journal of Machine Learning Re-
search.
Yufan Guo, Anna Korhonen, Maria Liakata, Ilona Silins
Karolinska, Lin Sun, and Ulla Stenius. 2010. Identi-
fying the information structure of scientific abstracts:
an investigation of three different schemes. In Pro-
ceedings of BioNLP, pages 99–107.
Yufan Guo, Anna Korhonen, and Thierry Poibeau. 2011.
A weakly-supervised approach to argumentative zon-
ing of scientific documents. In Proceedings of the
2011 Conference on Empirical Methods in Natural
Language Processing, pages 273–283.
Ben Hachey and Claire Grover. 2006. Extractive sum-
marisation of legal texts. Artif. Intell. Law, 14:305–
345.
K. Hirohata, N. Okazaki, S. Ananiadou, and M. Ishizuka.
2008. Identifying sections in scientific abstracts us-
ing conditional random fields. In Proceedings of 3rd
International Joint Conference on Natural Language
Processing, pages 381–388.
E. T. Jaynes. 1957. Information Theory and Statistical
Mechanics. Physical Review Online Archive (Prola),
106(4):620–630.
F. Jiao, S. Wang, C. Lee, R. Greiner, and D. Schuur-
mans. 2006. Semi-supervised conditional random
fields for improved sequence segmentation and label-
ing. In COLING/ACL, pages 209–216.
M. Liakata, S. Teufel, A. Siddharthan, and C. Batchelor.
2010. Corpora for the conceptualisation and zoning of
scientific papers. In Proceedings of LREC’10.
Maria Liakata, Shyamasree Saha, Simon Dobnik, Colin
Batchelor, and Dietrich Rebholz-Schuhmann. 2012.
Automatic recognition of conceptualisation zones in
scientific articles and two life science applications.
Bioinformatics, 28:991–1000.
J. Lin, D. Karakos, D. Demner-Fushman, and S. Khu-
danpur. 2006. Generative content models for struc-
tural analysis of medical abstracts. In Proceedings of
BioNLP-06, pages 65–72.
G. Mann and A. McCallum. 2007. Simple, robust, scal-
able semi-supervised learning via expectation regular-
ization. In ICML.
G. Mann and A. McCallum. 2008. Generalized expec-
tation criteria for semi-supervised learning of condi-
tional random fields. In ACL.
Katja Markert, Yufang Hou, and Michael Strube. 2012.
Collective classification for fine-grained information
status. In Proceedings of ACL 2012, pages 795–804.
A. K. McCallum. 2002. Mallet: A machine learning for
language toolkit. http://mallet.cs.umass.edu.
S. Merity, T. Murphy, and J. R. Curran. 2009. Accurate
argumentative zoning with maximum entropy models.
In Proceedings of the 2009 Workshop on Text and Ci-
tation Analysis for Scholarly Digital Libraries, pages
19–26.
Y. Mizuta, A. Korhonen, T. Mullen, and N. Collier. 2006.
Zone analysis in biology articles as a basis for in-
formation extraction. International Journal of Med-
ical Informatics on Natural Language Processing in
Biomedicine and Its Applications, 75(6):468–487.
Jorge Nocedal. 1980. Updating Quasi-Newton Matrices
with Limited Storage. Mathematics of Computation,
35(151):773–782.
</reference>
<page confidence="0.985744">
936
</page>
<reference confidence="0.998690275">
S. Della Pietra and V. Della Pietra. 1993. Statistical mod-
eling by me. Technical report, IBM.
Roi Reichart and Anna Korhonen. 2012. Document and
corpus level inference for unsupervised and transduc-
tive learning of information structure of scientic docu-
ments. In Proceedings of COLING 2012.
P. Ruch, C. Boyer, C. Chichester, I. Tbahriti, A. Geiss-
buhler, P. Fabry, J. Gobeill, V. Pillet, D. Rebholz-
Schuhmann, C. Lovis, and A. L. Veuthey. 2007. Using
argumentation to extract key sentences from biomedi-
cal abstracts. Int J Med Inform, 76(2-3):195–200.
H. Shatkay, F. Pan, A. Rzhetsky, and W. J. Wilbur. 2008.
Multi-dimensional classification of biomedical text:
Toward automated, practical provision of high-utility
text to diverse users. Bioinformatics, 24(18):2086–
2093.
L. Sun and A. Korhonen. 2009. Improving verb cluster-
ing with automatically acquired selectional preference.
In Proceedings of EMNLP, pages 638–647.
I. Tbahriti, C. Chichester, Frederique Lisacek, and
P. Ruch. 2006. Using argumentation to retrieve
articles with similar citations. Int J Med Inform,
75(6):488–495.
S. Teufel and M. Moens. 2002. Summarizing scien-
tific articles: Experiments with relevance and rhetor-
ical status. Computational Linguistics, 28:409–445.
S. Teufel, A. Siddharthan, and C. Batchelor. 2009. To-
wards discipline-independent argumentative zoning:
Evidence from chemistry and computational linguis-
tics. In EMNLP.
V. N. Vapnik. 1998. Statistical learning theory. Wiley,
New York.
Andrea Varga, Daniel Preotiuc-Pietro, and Fabio
Ciravegna. 2012. Unsupervised document zone iden-
tification using probabilistic graphical models. In
Proceedings of the Eight International Conference on
Language Resources and Evaluation (LREC’12).
B. Webber, M. Egg, and V. Kordoni. 2011. Discourse
structure and language technology. Natural Language
Engineering, 18:437–490.
</reference>
<page confidence="0.99756">
937
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.482520">
<title confidence="0.999246">Improved Information Structure Analysis of Scientific Documents Through Discourse and Lexical Constraints</title>
<author confidence="0.999876">Yufan Guo</author>
<affiliation confidence="0.997929">University of Cambridge, UK</affiliation>
<email confidence="0.984977">yg244@cam.ac.uk</email>
<author confidence="0.999633">Roi Reichart</author>
<affiliation confidence="0.998537">University of Cambridge, UK</affiliation>
<email confidence="0.926136">rr439@cam.ac.uk</email>
<author confidence="0.537252">Anna</author>
<affiliation confidence="0.999921">University of Cambridge,</affiliation>
<email confidence="0.990923">alk23@cam.ac.uk</email>
<abstract confidence="0.998199526315789">Inferring the information structure of scientific documents is useful for many downstream applications. Existing feature-based machine learning approaches to this task require substantial training data and suffer from limited performance. Our idea is to guide feature-based models with declarative domain knowledge encoded as posterior distribution constraints. We explore a rich set of discourse and lexical constraints which we incorporate through the Generalized Expectation (GE) criterion. Our constrained model improves the performance of existing fully and lightly supervised models. Even a fully unsupervised version of this model outperforms lightly supervised feature-based models, showing that our approach can be useful even when no labeled data is available.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Kedar Bellare</author>
<author>Gregory Druck</author>
<author>Andrew McCallum</author>
</authors>
<title>Alternating projections for learning with expectation constraints.</title>
<date>2009</date>
<booktitle>In Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence, UAI ’09,</booktitle>
<pages>43--50</pages>
<publisher>AUAI Press.</publisher>
<location>Arlington, Virginia, United States.</location>
<contexts>
<context position="8290" citStr="Bellare et al., 2009" startWordPosition="1255" endWordPosition="1258">upervision are now emerging for the task, including those based on active learning and self-training (Guo et al., 2011) and unsupervised methods (Varga et al., 2012; Reichart and Korhonen, 2012). Unfortunately, these approaches do not reach the performance level of fully supervised models, let alone exceed it. Our novel method addresses this problem. Declarative knowledge and constraints Previous work has shown that incorporating declarative constraints into feature-based machine learning 929 models works well in many NLP tasks (Chang et al., 2007; Mann and McCallum, 2008; Druck et al., 2008; Bellare et al., 2009; Ganchev et al., 2010). Such constraints can be used in a semi-supervised or unsupervised fashion. For example, (Mann and McCallum, 2008) shows that using CRF in conjunction with auxiliary constraints on unlabeled data significantly outperforms traditional CRF in information extraction, and (Druck et al., 2008) shows that using declarative constraints alone for unsupervised learning achieves good results in text classification. We show that declarative constraints can be highly useful for the identification of information structure of scientific documents. In contrast with most previous works</context>
<context position="11628" citStr="Bellare et al., 2009" startWordPosition="1785" endWordPosition="1788">e an equality constraint. The constraint g(·) can be set in a relaxed manner: (E˜p(x)[Epa(y|x)[fk(x, y)|x]] − E˜p(x,y)[fk(x, y)])2, which is the logarithm of a Gaussian distribution centered at the reference values with a diagonal covariance matrix (Pietra and Pietra, 1993), and the dual problem will become a regularized MaxEnt with a Gaussian prior (µk = 0, Qk = Pk) over the parameters: X X 2 max log(pλ(yi|xi)) − λk (5) λ k 2σ2k (xi,yi)∈L Such a model can be further extended to include expert knowledge or auxiliary constraints on unlabeled data U (Mann and McCallum, 2008; Druck et al., 2008; Bellare et al., 2009): X X λ2 max log(pλ(yi|xi)) − k λ k 2σ2k (xi,yi)∈L − γg∗(Epa(y|x)[f∗(x, y)]) (6) where f*(·) is a collection of auxiliary feature functions on U, g*(·) is a constraint function that takes expert/declarative knowledge Ep∗(y|x)[f*(x, y)] as a reference point, and -y is the weight of the auxiliary GE term. H(·) X max − λ x 1 X k 2ρ2k 930 The auxiliary constraint g∗(·) can take on many forms and the one we used in this work is an L2 penalty function (Dudik, 2007). We trained the model with L-BFGS (Nocedal, 1980) in supervised, semi-supervised and unsupervised fashions on labeled and/or unlabeled d</context>
</contexts>
<marker>Bellare, Druck, McCallum, 2009</marker>
<rawString>Kedar Bellare, Gregory Druck, and Andrew McCallum. 2009. Alternating projections for learning with expectation constraints. In Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence, UAI ’09, pages 43–50, Arlington, Virginia, United States. AUAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam L Berger</author>
<author>Vincent J Della Pietra</author>
<author>Stephen A Della Pietra</author>
</authors>
<title>A maximum entropy approach to natural language processing.</title>
<date>1996</date>
<journal>Comput. Linguist.,</journal>
<volume>22</volume>
<issue>1</issue>
<contexts>
<context position="10336" citStr="Berger et al., 1996" startWordPosition="1569" endWordPosition="1572"> H(·) is the corresponding information entropy, f(·) is a collection of feature functions, and Ep[f(·)] and Ef,[f(·)] are the expectations of f with respect to p(·) and p(·). An example of p(·) could be a conditional probability distribution p(y|x), and H(·) could be a conditional entropy H(y|x). The optimal p(y|x) will take on an exponential form: 1 pλ(y|x) = exp(λ · f(x, y)), (2) Zλ where A is the Lagrange multipliers in the corresponding unconstrained objective function, and Z), is the partition function. The dual problem becomes maximizing the conditional log-likelihood of labeled data L (Berger et al., 1996): X log(pλ(yi|xi)), (3) max λ (xi,yi)∈L which is usually known as a Log-linear or Maximum Entropy Model (MaxEnt). ME with Generalized Expectation The objective function and the constraints on expectations in (1) can be generalized to: ˜p(x)D(pλ(y|x)||p0(y|x)) − g(E˜p(x)[Epa(y|x)[f(x, y)|x]]), (4) where D(p),||p0) is the divergence from p), to a base distribution p0, and g(·) is a constraint/penalty function that takes empirical evidence EP(x�y)[f(x, y)] as a reference point (Pietra and Pietra, 1993; Chen et al., 2000; Dud´ık, 2007). Note that a special case of this is MaxEnt where p0 is set to</context>
</contexts>
<marker>Berger, Pietra, Pietra, 1996</marker>
<rawString>Adam L. Berger, Vincent J. Della Pietra, and Stephen A. Della Pietra. 1996. A maximum entropy approach to natural language processing. Comput. Linguist., 22(1):39–71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Catherine Blake</author>
</authors>
<title>Beyond genes, proteins, and abstracts: Identifying scientific claims from full-text biomedical articles. JBiomed</title>
<date>2009</date>
<journal>Inform,</journal>
<volume>43</volume>
<issue>2</issue>
<contexts>
<context position="7178" citStr="Blake, 2009" startWordPosition="1087" endWordPosition="1088">nowledge encoded via constraints. 2 Previous work Information structure analysis The information structure of scientific documents (e.g. journal articles, abstracts, essays) can be analyzed in terms of patterns of topics, functions or relations observed in multi-sentence scientific text. Computational approaches have mainly focused on analysis based on argumentative zones (Teufel and Moens, 2002; Mizuta et al., 2006; Hachey and Grover, 2006; Teufel et al., 2009), discourse structure (Burstein et al., 2003; Webber et al., 2011), qualitative dimensions (Shatkay et al., 2008), scientific claims (Blake, 2009), scientific concepts (Liakata et al., 2010) and information status (Markert et al., 2012). Most existing methods for analyzing scientific text according to information structure use full supervision in the form of thousands of manually annotated sentences (Teufel and Moens, 2002; Burstein et al., 2003; Mizuta et al., 2006; Shatkay et al., 2008; Guo et al., 2010; Liakata et al., 2012; Markert et al., 2012). Because manual annotation is prohibitively expensive, approaches based on light supervision are now emerging for the task, including those based on active learning and self-training (Guo et</context>
</contexts>
<marker>Blake, 2009</marker>
<rawString>Catherine Blake. 2009. Beyond genes, proteins, and abstracts: Identifying scientific claims from full-text biomedical articles. JBiomed Inform, 43(2):173–89.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jill Burstein</author>
<author>Daniel Marcu</author>
<author>Kevin Knight</author>
</authors>
<title>Finding the write stuff: Automatic identification of discourse structure in student essays.</title>
<date>2003</date>
<journal>IEEE Intelligent Systems,</journal>
<volume>18</volume>
<issue>1</issue>
<contexts>
<context position="7076" citStr="Burstein et al., 2003" startWordPosition="1070" endWordPosition="1073">ert knowledge for our task and supports our modeling decision that combines feature-based methods with domain knowledge encoded via constraints. 2 Previous work Information structure analysis The information structure of scientific documents (e.g. journal articles, abstracts, essays) can be analyzed in terms of patterns of topics, functions or relations observed in multi-sentence scientific text. Computational approaches have mainly focused on analysis based on argumentative zones (Teufel and Moens, 2002; Mizuta et al., 2006; Hachey and Grover, 2006; Teufel et al., 2009), discourse structure (Burstein et al., 2003; Webber et al., 2011), qualitative dimensions (Shatkay et al., 2008), scientific claims (Blake, 2009), scientific concepts (Liakata et al., 2010) and information status (Markert et al., 2012). Most existing methods for analyzing scientific text according to information structure use full supervision in the form of thousands of manually annotated sentences (Teufel and Moens, 2002; Burstein et al., 2003; Mizuta et al., 2006; Shatkay et al., 2008; Guo et al., 2010; Liakata et al., 2012; Markert et al., 2012). Because manual annotation is prohibitively expensive, approaches based on light supervi</context>
</contexts>
<marker>Burstein, Marcu, Knight, 2003</marker>
<rawString>Jill Burstein, Daniel Marcu, and Kevin Knight. 2003. Finding the write stuff: Automatic identification of discourse structure in student essays. IEEE Intelligent Systems, 18(1):32–39.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M W Chang</author>
<author>L Ratinovc</author>
<author>D Roth</author>
</authors>
<title>Guiding semi-supervision with constraint-driven learning.</title>
<date>2007</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="4401" citStr="Chang et al., 2007" startWordPosition="671" endWordPosition="674">lude the presumed DNA adduct of BA and might thus be slightly overestimated. The verb “calculated” usually indicates the “Method” class, but, when accompanied by the modal verb “might”, it is more likely to imply that authors are interpreting their own results (i.e. the “Conclusion” class in AZ). This can be explicitly encoded in the model through a target distribution for sentences containing certain modal verbs. Recent work has shown that explicit declaration of domain and expert knowledge can be highly useful for structured NLP tasks such as parsing, POS tagging and information extraction (Chang et al., 2007; Mann and McCallum, 2008; Ganchev et al., 2010). These works have encoded expert knowledge through constraints, with different frameworks differing in the type of constraints and the inference and learning algorithms used. We build on the Generalized Expectation (GE) framework (Mann and McCallum, 2007) which encodes expert knowledge through a preference (i.e. soft) constraints for parameter settings for which the predicted label distribution matches a target distribution. In order to integrate domain knowledge with a features-based model, we develop a simple taxonomy of constraints (i.e. desi</context>
<context position="8223" citStr="Chang et al., 2007" startWordPosition="1243" endWordPosition="1246">nnotation is prohibitively expensive, approaches based on light supervision are now emerging for the task, including those based on active learning and self-training (Guo et al., 2011) and unsupervised methods (Varga et al., 2012; Reichart and Korhonen, 2012). Unfortunately, these approaches do not reach the performance level of fully supervised models, let alone exceed it. Our novel method addresses this problem. Declarative knowledge and constraints Previous work has shown that incorporating declarative constraints into feature-based machine learning 929 models works well in many NLP tasks (Chang et al., 2007; Mann and McCallum, 2008; Druck et al., 2008; Bellare et al., 2009; Ganchev et al., 2010). Such constraints can be used in a semi-supervised or unsupervised fashion. For example, (Mann and McCallum, 2008) shows that using CRF in conjunction with auxiliary constraints on unlabeled data significantly outperforms traditional CRF in information extraction, and (Druck et al., 2008) shows that using declarative constraints alone for unsupervised learning achieves good results in text classification. We show that declarative constraints can be highly useful for the identification of information stru</context>
</contexts>
<marker>Chang, Ratinovc, Roth, 2007</marker>
<rawString>M.W. Chang, L. Ratinovc, and D. Roth. 2007. Guiding semi-supervision with constraint-driven learning. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stanley F Chen</author>
<author>Ronald Rosenfeld</author>
<author>Associate Member</author>
</authors>
<title>A survey of smoothing techniques for me models.</title>
<date>2000</date>
<booktitle>IEEE Transactions on Speech and Audio Processing,</booktitle>
<pages>8--37</pages>
<contexts>
<context position="10858" citStr="Chen et al., 2000" startWordPosition="1648" endWordPosition="1651">oblem becomes maximizing the conditional log-likelihood of labeled data L (Berger et al., 1996): X log(pλ(yi|xi)), (3) max λ (xi,yi)∈L which is usually known as a Log-linear or Maximum Entropy Model (MaxEnt). ME with Generalized Expectation The objective function and the constraints on expectations in (1) can be generalized to: ˜p(x)D(pλ(y|x)||p0(y|x)) − g(E˜p(x)[Epa(y|x)[f(x, y)|x]]), (4) where D(p),||p0) is the divergence from p), to a base distribution p0, and g(·) is a constraint/penalty function that takes empirical evidence EP(x�y)[f(x, y)] as a reference point (Pietra and Pietra, 1993; Chen et al., 2000; Dud´ık, 2007). Note that a special case of this is MaxEnt where p0 is set to be a uniform distribution, D(·) to be the KL divergence, and g(·) to be an equality constraint. The constraint g(·) can be set in a relaxed manner: (E˜p(x)[Epa(y|x)[fk(x, y)|x]] − E˜p(x,y)[fk(x, y)])2, which is the logarithm of a Gaussian distribution centered at the reference values with a diagonal covariance matrix (Pietra and Pietra, 1993), and the dual problem will become a regularized MaxEnt with a Gaussian prior (µk = 0, Qk = Pk) over the parameters: X X 2 max log(pλ(yi|xi)) − λk (5) λ k 2σ2k (xi,yi)∈L Such a </context>
</contexts>
<marker>Chen, Rosenfeld, Member, 2000</marker>
<rawString>Stanley F. Chen, Ronald Rosenfeld, and Associate Member. 2000. A survey of smoothing techniques for me models. IEEE Transactions on Speech and Audio Processing, 8:37–50.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Danish Contractor</author>
<author>Yufan Guo</author>
<author>Anna Korhonen</author>
</authors>
<title>Using argumentative zones for extractive summarization of scientific articles.</title>
<date>2012</date>
<booktitle>In COLING.</booktitle>
<contexts>
<context position="1636" citStr="Contractor et al., 2012" startWordPosition="229" endWordPosition="232">ul even when no labeled data is available. 1 Introduction Techniques that enable automatic analysis of the information structure of scientific articles can help scientists identify information of interest in the growing volume of scientific literature. For example, classification of sentences according to argumentative zones (AZ) – an information structure scheme that is applicable across scientific domains (Teufel et al., 2009) – can support information retrieval, information extraction and summarization (Teufel and Moens, 2002; Tbahriti et al., 2006; Ruch et al., 2007; Liakata et al., 2012; Contractor et al., 2012). Previous work on sentence-based classification of scientific literature according to categories of information structure has mostly used feature-based machine learning, such as Support Vector Machines (SVM) and Conditional Random Fields (CRF) (e.g. (Teufel and Moens, 2002; Lin et al., 2006; Hirohata et al., 2008; Shatkay et al., 2008; Guo et al., 2010; Liakata et al., 2012)). Unfortunately, the performance of these methods is rather limited, as indicated e.g. by the relatively low numbers reported by Liakata et al. (2012) in biochemistry and chemistry with per-class F-scores ranging from .18</context>
<context position="5467" citStr="Contractor et al., 2012" startWordPosition="833" endWordPosition="836">tion matches a target distribution. In order to integrate domain knowledge with a features-based model, we develop a simple taxonomy of constraints (i.e. desired class distributions) and employ a top-down classification algorithm on top of a Maximum Entropy Model augmented with GE constraints. This algorithm enables us to break the multi-class prediction into a pipeline of consecutive, simpler predictions which can be better assisted by the encoded knowledge. We experiment in the biological domain with the eight-category AZ scheme (Table 1) adapted from (Mizuta et al., 2006) and described in (Contractor et al., 2012). The results show that our constrained model substantially outperforms a baseline unconstrained Maximum Entropy Model. While this type of constrained models have previously improved the feature-based model performance mostly in the weakly supervised and domain adaptation scenarios (e.g. (Mann and McCallum, 2007; Mann and McCallum, 2008; Ganchev et al., 2010)), we demonstrate substantial gains both when the Maximum EnTable 1: The AZ categories included in the categorization scheme of this paper. Zone Definition Background (BKG) the background of the study Problem (PROB) the research problem Me</context>
<context position="13559" citStr="Contractor et al., 2012" startWordPosition="2110" endWordPosition="2113">bles and figures, word lists, tenses, and so on. Note that the word lists actually contain both lexical and semantic information. To make an efficient use of the declarative knowledge we build a taxonomy of information structure categories centered around the distinction between categories that describe the authors’ OWN work and those that describe OTHER work (see Section 5). In practice, our model labels every sentence with an AZ category augmented by one of the two categories, OWN or OTHER. In evaluation we consider only the standard AZ categories which are part of the annotation scheme of (Contractor et al., 2012). 1Accordingly, Ep,(y|x)[fk(x, y)] = pλ(yk|xk) Table 2: Discourse and lexical constraints for identifying information categories at different levels of the information structure taxonomy. (a) OWN / OTHER OWN Discourse (1) Target(last part of paragraph) = 1 (2) Target(last part of section) = 1 Lexical (3) Target(tables/figures) ≥ 1 (4) ∃x ∈ {w|w∼we} Target(x) = 1 ∧ ∀y ∈ {w|w∼previous} Target(y) = 0 (5) ∃x ∈ {w|w∼thus} Target(x) = 1 OTHER Lexical (6) Target(cite) = 1 (7) Target(cite) &gt; 1 (8) Backward(cite) = 1 ∧ ∃x ∈ {w|w∼in addition} Target(x) = 1 (b) PROB / METH / RES / CON / FUT PROB Discours</context>
<context position="20006" citStr="Contractor et al. (2012)" startWordPosition="3172" endWordPosition="3176"> categories under the OTHER auxiliary category. At test time we first apply the first classifier and based on its prediction we apply either the classifier that distinguishes between OWN categories or the one that distinguishes between OTHER categories. 2For the training of this model, each training data AZ category is mapped to its respective auxiliary class. PROB METH RES CON FUT BKG CN DIFF we previous thus aim question investigate use method observe conclude suggest because likely need future consistent inconsistent than however 932 6 Experiments Data We used the full paper corpus used by Contractor et al. (2012) which contains 8171 sentences from 50 biomedical journal articles. The corpus is annotated according to the AZ scheme described in Table 1. AZ describes the logical structure, scientific argumentation and intellectual attribution of a scientific paper. It was originally introduced by Teufel and Moens (2002) and applied to computational linguistics papers, and later adapted to other domains such as biology (Mizuta et al., 2006) – which we used in this work – and chemistry (Teufel et al., 2009). Table 4 shows the AZ class distribution in full articles as well as in individual sections. Since se</context>
</contexts>
<marker>Contractor, Guo, Korhonen, 2012</marker>
<rawString>Danish Contractor, Yufan Guo, and Anna Korhonen. 2012. Using argumentative zones for extractive summarization of scientific articles. In COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Curran</author>
<author>S Clark</author>
<author>J Bos</author>
</authors>
<title>Linguistically motivated large-scale nlp with c&amp;c and boxer.</title>
<date>2007</date>
<booktitle>In Proceedings of the ACL 2007 Demonstrations Session,</booktitle>
<pages>33--36</pages>
<contexts>
<context position="21770" citStr="Curran et al., 2007" startWordPosition="3454" endWordPosition="3457">ure each text batch was divided to ten equal size parts and the corresponding feature value identifies the relevant part; (2) Lexical features: number of citations and references to tables and figures (0, 1, or more), word, bi-gram, verb, and verb class (obtained by spectral clustering (Sun and Korhonen, 2009)); (3) Syntactic features: tense and voice (POS tags of main and auxiliary verbs), grammatical relation, subject and object. The lexical and the syntactic features were extracted for the represented sentence as well as for its surrounding sentences. We used the C&amp;C POS tagger and parser (Curran et al., 2007) for extracting the lexical and the syntactic features. Note that all the information encoded into our constraints is also encoded in the features and is thus available to the feature-based model. This enables us to properly evaluate the impact of our modeling decision which augments a feature-based model with constraints. Baselines We compared our model against four baselines, two with full supervision: Support Vector Machines (SVM) and Maximum Entropy Models (MaxEnt), and two with light supervision: TransTable 4: Class distribution (shown in percentages) in articles and their individual sect</context>
</contexts>
<marker>Curran, Clark, Bos, 2007</marker>
<rawString>J. R. Curran, S. Clark, and J. Bos. 2007. Linguistically motivated large-scale nlp with c&amp;c and boxer. In Proceedings of the ACL 2007 Demonstrations Session, pages 33–36.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gregory Druck</author>
<author>Gideon Mann</author>
<author>Andrew McCallum</author>
</authors>
<title>Learning from labeled features using generalized expectation criteria.</title>
<date>2008</date>
<booktitle>In Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval,</booktitle>
<pages>595--602</pages>
<contexts>
<context position="8268" citStr="Druck et al., 2008" startWordPosition="1251" endWordPosition="1254">hes based on light supervision are now emerging for the task, including those based on active learning and self-training (Guo et al., 2011) and unsupervised methods (Varga et al., 2012; Reichart and Korhonen, 2012). Unfortunately, these approaches do not reach the performance level of fully supervised models, let alone exceed it. Our novel method addresses this problem. Declarative knowledge and constraints Previous work has shown that incorporating declarative constraints into feature-based machine learning 929 models works well in many NLP tasks (Chang et al., 2007; Mann and McCallum, 2008; Druck et al., 2008; Bellare et al., 2009; Ganchev et al., 2010). Such constraints can be used in a semi-supervised or unsupervised fashion. For example, (Mann and McCallum, 2008) shows that using CRF in conjunction with auxiliary constraints on unlabeled data significantly outperforms traditional CRF in information extraction, and (Druck et al., 2008) shows that using declarative constraints alone for unsupervised learning achieves good results in text classification. We show that declarative constraints can be highly useful for the identification of information structure of scientific documents. In contrast wi</context>
<context position="11605" citStr="Druck et al., 2008" startWordPosition="1781" endWordPosition="1784">gence, and g(·) to be an equality constraint. The constraint g(·) can be set in a relaxed manner: (E˜p(x)[Epa(y|x)[fk(x, y)|x]] − E˜p(x,y)[fk(x, y)])2, which is the logarithm of a Gaussian distribution centered at the reference values with a diagonal covariance matrix (Pietra and Pietra, 1993), and the dual problem will become a regularized MaxEnt with a Gaussian prior (µk = 0, Qk = Pk) over the parameters: X X 2 max log(pλ(yi|xi)) − λk (5) λ k 2σ2k (xi,yi)∈L Such a model can be further extended to include expert knowledge or auxiliary constraints on unlabeled data U (Mann and McCallum, 2008; Druck et al., 2008; Bellare et al., 2009): X X λ2 max log(pλ(yi|xi)) − k λ k 2σ2k (xi,yi)∈L − γg∗(Epa(y|x)[f∗(x, y)]) (6) where f*(·) is a collection of auxiliary feature functions on U, g*(·) is a constraint function that takes expert/declarative knowledge Ep∗(y|x)[f*(x, y)] as a reference point, and -y is the weight of the auxiliary GE term. H(·) X max − λ x 1 X k 2ρ2k 930 The auxiliary constraint g∗(·) can take on many forms and the one we used in this work is an L2 penalty function (Dudik, 2007). We trained the model with L-BFGS (Nocedal, 1980) in supervised, semi-supervised and unsupervised fashions on lab</context>
</contexts>
<marker>Druck, Mann, McCallum, 2008</marker>
<rawString>Gregory Druck, Gideon Mann, and Andrew McCallum. 2008. Learning from labeled features using generalized expectation criteria. In Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval, pages 595–602.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Miroslav Dud´ık</author>
</authors>
<title>Maximum entropy density estimation and modeling geographic distributions of species.</title>
<date>2007</date>
<tech>Ph.D. thesis.</tech>
<marker>Dud´ık, 2007</marker>
<rawString>Miroslav Dud´ık. 2007. Maximum entropy density estimation and modeling geographic distributions of species. Ph.D. thesis.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Ganchev</author>
<author>J Graca</author>
<author>J Gillenwater</author>
<author>B Taskar</author>
</authors>
<title>Posterior regularization for structured latent variable models.</title>
<date>2010</date>
<journal>Journal of Machine Learning Research.</journal>
<contexts>
<context position="4449" citStr="Ganchev et al., 2010" startWordPosition="679" endWordPosition="682">thus be slightly overestimated. The verb “calculated” usually indicates the “Method” class, but, when accompanied by the modal verb “might”, it is more likely to imply that authors are interpreting their own results (i.e. the “Conclusion” class in AZ). This can be explicitly encoded in the model through a target distribution for sentences containing certain modal verbs. Recent work has shown that explicit declaration of domain and expert knowledge can be highly useful for structured NLP tasks such as parsing, POS tagging and information extraction (Chang et al., 2007; Mann and McCallum, 2008; Ganchev et al., 2010). These works have encoded expert knowledge through constraints, with different frameworks differing in the type of constraints and the inference and learning algorithms used. We build on the Generalized Expectation (GE) framework (Mann and McCallum, 2007) which encodes expert knowledge through a preference (i.e. soft) constraints for parameter settings for which the predicted label distribution matches a target distribution. In order to integrate domain knowledge with a features-based model, we develop a simple taxonomy of constraints (i.e. desired class distributions) and employ a top-down c</context>
<context position="5828" citStr="Ganchev et al., 2010" startWordPosition="885" endWordPosition="888">pipeline of consecutive, simpler predictions which can be better assisted by the encoded knowledge. We experiment in the biological domain with the eight-category AZ scheme (Table 1) adapted from (Mizuta et al., 2006) and described in (Contractor et al., 2012). The results show that our constrained model substantially outperforms a baseline unconstrained Maximum Entropy Model. While this type of constrained models have previously improved the feature-based model performance mostly in the weakly supervised and domain adaptation scenarios (e.g. (Mann and McCallum, 2007; Mann and McCallum, 2008; Ganchev et al., 2010)), we demonstrate substantial gains both when the Maximum EnTable 1: The AZ categories included in the categorization scheme of this paper. Zone Definition Background (BKG) the background of the study Problem (PROB) the research problem Method (METH) the methods used Result (RES) the results achieved Conclusion (CON) the authors’ conclusions Connection (CN) work consistent with the current work Difference (DIFF) work inconsistent with the current work Future work (FUT) the potential future direction of the research tropy Model is fully trained and when its training data is sparse. This demonst</context>
<context position="8313" citStr="Ganchev et al., 2010" startWordPosition="1259" endWordPosition="1262">rging for the task, including those based on active learning and self-training (Guo et al., 2011) and unsupervised methods (Varga et al., 2012; Reichart and Korhonen, 2012). Unfortunately, these approaches do not reach the performance level of fully supervised models, let alone exceed it. Our novel method addresses this problem. Declarative knowledge and constraints Previous work has shown that incorporating declarative constraints into feature-based machine learning 929 models works well in many NLP tasks (Chang et al., 2007; Mann and McCallum, 2008; Druck et al., 2008; Bellare et al., 2009; Ganchev et al., 2010). Such constraints can be used in a semi-supervised or unsupervised fashion. For example, (Mann and McCallum, 2008) shows that using CRF in conjunction with auxiliary constraints on unlabeled data significantly outperforms traditional CRF in information extraction, and (Druck et al., 2008) shows that using declarative constraints alone for unsupervised learning achieves good results in text classification. We show that declarative constraints can be highly useful for the identification of information structure of scientific documents. In contrast with most previous works, we show that such con</context>
</contexts>
<marker>Ganchev, Graca, Gillenwater, Taskar, 2010</marker>
<rawString>K. Ganchev, J. Graca, J. Gillenwater, and B. Taskar. 2010. Posterior regularization for structured latent variable models. Journal of Machine Learning Research.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yufan Guo</author>
<author>Anna Korhonen</author>
<author>Maria Liakata</author>
<author>Ilona Silins Karolinska</author>
<author>Lin Sun</author>
<author>Ulla Stenius</author>
</authors>
<title>Identifying the information structure of scientific abstracts: an investigation of three different schemes.</title>
<date>2010</date>
<booktitle>In Proceedings of BioNLP,</booktitle>
<pages>99--107</pages>
<contexts>
<context position="1991" citStr="Guo et al., 2010" startWordPosition="284" endWordPosition="287">me that is applicable across scientific domains (Teufel et al., 2009) – can support information retrieval, information extraction and summarization (Teufel and Moens, 2002; Tbahriti et al., 2006; Ruch et al., 2007; Liakata et al., 2012; Contractor et al., 2012). Previous work on sentence-based classification of scientific literature according to categories of information structure has mostly used feature-based machine learning, such as Support Vector Machines (SVM) and Conditional Random Fields (CRF) (e.g. (Teufel and Moens, 2002; Lin et al., 2006; Hirohata et al., 2008; Shatkay et al., 2008; Guo et al., 2010; Liakata et al., 2012)). Unfortunately, the performance of these methods is rather limited, as indicated e.g. by the relatively low numbers reported by Liakata et al. (2012) in biochemistry and chemistry with per-class F-scores ranging from .18 to .76. We propose a novel approach to this task in which traditional feature-based models are augmented with explicit declarative expert and domain knowledge, and apply it to sentence-based AZ. We explore two sources of declarative knowledge for our task - discourse and lexical. One way to utilize discourse knowledge is to guide the model predictions </context>
<context position="7542" citStr="Guo et al., 2010" startWordPosition="1142" endWordPosition="1145">entative zones (Teufel and Moens, 2002; Mizuta et al., 2006; Hachey and Grover, 2006; Teufel et al., 2009), discourse structure (Burstein et al., 2003; Webber et al., 2011), qualitative dimensions (Shatkay et al., 2008), scientific claims (Blake, 2009), scientific concepts (Liakata et al., 2010) and information status (Markert et al., 2012). Most existing methods for analyzing scientific text according to information structure use full supervision in the form of thousands of manually annotated sentences (Teufel and Moens, 2002; Burstein et al., 2003; Mizuta et al., 2006; Shatkay et al., 2008; Guo et al., 2010; Liakata et al., 2012; Markert et al., 2012). Because manual annotation is prohibitively expensive, approaches based on light supervision are now emerging for the task, including those based on active learning and self-training (Guo et al., 2011) and unsupervised methods (Varga et al., 2012; Reichart and Korhonen, 2012). Unfortunately, these approaches do not reach the performance level of fully supervised models, let alone exceed it. Our novel method addresses this problem. Declarative knowledge and constraints Previous work has shown that incorporating declarative constraints into feature-b</context>
</contexts>
<marker>Guo, Korhonen, Liakata, Karolinska, Sun, Stenius, 2010</marker>
<rawString>Yufan Guo, Anna Korhonen, Maria Liakata, Ilona Silins Karolinska, Lin Sun, and Ulla Stenius. 2010. Identifying the information structure of scientific abstracts: an investigation of three different schemes. In Proceedings of BioNLP, pages 99–107.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yufan Guo</author>
<author>Anna Korhonen</author>
<author>Thierry Poibeau</author>
</authors>
<title>A weakly-supervised approach to argumentative zoning of scientific documents.</title>
<date>2011</date>
<booktitle>In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>273--283</pages>
<contexts>
<context position="7789" citStr="Guo et al., 2011" startWordPosition="1179" endWordPosition="1182"> 2009), scientific concepts (Liakata et al., 2010) and information status (Markert et al., 2012). Most existing methods for analyzing scientific text according to information structure use full supervision in the form of thousands of manually annotated sentences (Teufel and Moens, 2002; Burstein et al., 2003; Mizuta et al., 2006; Shatkay et al., 2008; Guo et al., 2010; Liakata et al., 2012; Markert et al., 2012). Because manual annotation is prohibitively expensive, approaches based on light supervision are now emerging for the task, including those based on active learning and self-training (Guo et al., 2011) and unsupervised methods (Varga et al., 2012; Reichart and Korhonen, 2012). Unfortunately, these approaches do not reach the performance level of fully supervised models, let alone exceed it. Our novel method addresses this problem. Declarative knowledge and constraints Previous work has shown that incorporating declarative constraints into feature-based machine learning 929 models works well in many NLP tasks (Chang et al., 2007; Mann and McCallum, 2008; Druck et al., 2008; Bellare et al., 2009; Ganchev et al., 2010). Such constraints can be used in a semi-supervised or unsupervised fashion.</context>
<context position="23221" citStr="Guo et al., 2011" startWordPosition="3720" endWordPosition="3723">Discussion 16.9 1.1 0.7 1.5 63.5 13.3 2.4 0.7 Table 5: Performance of baselines on the Discussion section. BKG PROB METH RES CON CN DIFF FUT Full supervision SVM .56 0 0 0 .84 .35 0 0 MaxEnt .55 .08 0 0 .84 .38 0 0 Light supervision with 150 labeled sentence SVM .26 0 0 0 .80 .05 0 0 TSVM .25 .04 .04 .03 .33 14 .06 .02 MaxEnt .25 0 0 0 .80 .10 0 0 MaxEnt+ER .23 0 0 0 .80 .07 0 0 ductive SVM (TSVM) and semi-supervised MaxEnt based on Entropy Regularization (ER) (Vapnik, 1998; Jiao et al., 2006). SVM and MaxEnt have proved successful in information structure analysis (e.g. (Merity et al., 2009; Guo et al., 2011)) but, to the best of our knowledge, their semi-supervised versions have not been used for AZ of full articles. Parameter tuning The boundaries of the reference probabilities (ak and bk in Equation (8)) were defined and optimized on the development data which consists of one third of the corpus. We considered six types of boundaries: Fairly High for 1, High for [0.9,1), Medium High for [0.5,0.9), Medium Low for [0.1,0.5), Low for [0,0.1), and Fairly Low for 0. Evaluation We evaluated the precision, recall and F-score for each category, using a standard ten-fold cross-validation scheme. The mod</context>
</contexts>
<marker>Guo, Korhonen, Poibeau, 2011</marker>
<rawString>Yufan Guo, Anna Korhonen, and Thierry Poibeau. 2011. A weakly-supervised approach to argumentative zoning of scientific documents. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 273–283.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ben Hachey</author>
<author>Claire Grover</author>
</authors>
<title>Extractive summarisation of legal texts.</title>
<date>2006</date>
<journal>Artif. Intell. Law,</journal>
<volume>14</volume>
<pages>345</pages>
<contexts>
<context position="7010" citStr="Hachey and Grover, 2006" startWordPosition="1060" endWordPosition="1063">its training data is sparse. This demonstrates the importance of expert knowledge for our task and supports our modeling decision that combines feature-based methods with domain knowledge encoded via constraints. 2 Previous work Information structure analysis The information structure of scientific documents (e.g. journal articles, abstracts, essays) can be analyzed in terms of patterns of topics, functions or relations observed in multi-sentence scientific text. Computational approaches have mainly focused on analysis based on argumentative zones (Teufel and Moens, 2002; Mizuta et al., 2006; Hachey and Grover, 2006; Teufel et al., 2009), discourse structure (Burstein et al., 2003; Webber et al., 2011), qualitative dimensions (Shatkay et al., 2008), scientific claims (Blake, 2009), scientific concepts (Liakata et al., 2010) and information status (Markert et al., 2012). Most existing methods for analyzing scientific text according to information structure use full supervision in the form of thousands of manually annotated sentences (Teufel and Moens, 2002; Burstein et al., 2003; Mizuta et al., 2006; Shatkay et al., 2008; Guo et al., 2010; Liakata et al., 2012; Markert et al., 2012). Because manual annota</context>
</contexts>
<marker>Hachey, Grover, 2006</marker>
<rawString>Ben Hachey and Claire Grover. 2006. Extractive summarisation of legal texts. Artif. Intell. Law, 14:305– 345.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Hirohata</author>
<author>N Okazaki</author>
<author>S Ananiadou</author>
<author>M Ishizuka</author>
</authors>
<title>Identifying sections in scientific abstracts using conditional random fields.</title>
<date>2008</date>
<booktitle>In Proceedings of 3rd International Joint Conference on Natural Language Processing,</booktitle>
<pages>381--388</pages>
<contexts>
<context position="1951" citStr="Hirohata et al., 2008" startWordPosition="275" endWordPosition="279">ve zones (AZ) – an information structure scheme that is applicable across scientific domains (Teufel et al., 2009) – can support information retrieval, information extraction and summarization (Teufel and Moens, 2002; Tbahriti et al., 2006; Ruch et al., 2007; Liakata et al., 2012; Contractor et al., 2012). Previous work on sentence-based classification of scientific literature according to categories of information structure has mostly used feature-based machine learning, such as Support Vector Machines (SVM) and Conditional Random Fields (CRF) (e.g. (Teufel and Moens, 2002; Lin et al., 2006; Hirohata et al., 2008; Shatkay et al., 2008; Guo et al., 2010; Liakata et al., 2012)). Unfortunately, the performance of these methods is rather limited, as indicated e.g. by the relatively low numbers reported by Liakata et al. (2012) in biochemistry and chemistry with per-class F-scores ranging from .18 to .76. We propose a novel approach to this task in which traditional feature-based models are augmented with explicit declarative expert and domain knowledge, and apply it to sentence-based AZ. We explore two sources of declarative knowledge for our task - discourse and lexical. One way to utilize discourse know</context>
</contexts>
<marker>Hirohata, Okazaki, Ananiadou, Ishizuka, 2008</marker>
<rawString>K. Hirohata, N. Okazaki, S. Ananiadou, and M. Ishizuka. 2008. Identifying sections in scientific abstracts using conditional random fields. In Proceedings of 3rd International Joint Conference on Natural Language Processing, pages 381–388.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E T Jaynes</author>
</authors>
<title>Information Theory and Statistical Mechanics. Physical Review Online Archive (Prola),</title>
<date>1957</date>
<contexts>
<context position="9472" citStr="Jaynes, 1957" startWordPosition="1428" endWordPosition="1429">trast with most previous works, we show that such constraints can improve the performance of a fully supervised model. The constraints are particularly helpful for identifying low-frequency information categories, but still yield high performance on high-frequency categories. 3 Maximum-Entropy Estimation and Generalized Expectation (GE) In this section we describe the Generalized Expectation method for declarative knowledge encoding. Maximum Entropy (ME) The idea of Generalized Expectation (Dud´ık, 2007; Mann and McCallum, 2008; Druck et al., 2008) stems from the principle of maximum entropy (Jaynes, 1957; Pietra and Pietra, 1993) which raises the following constrained optimization problem: max p subject to Ep[f(·)] = E˜p[f(·)] p(·) ≥ 0 X p(·) = 1, (1) where p(·) is the empirical distribution, p(·) is a probability distribution in the model and H(·) is the corresponding information entropy, f(·) is a collection of feature functions, and Ep[f(·)] and Ef,[f(·)] are the expectations of f with respect to p(·) and p(·). An example of p(·) could be a conditional probability distribution p(y|x), and H(·) could be a conditional entropy H(y|x). The optimal p(y|x) will take on an exponential form: 1 pλ(</context>
</contexts>
<marker>Jaynes, 1957</marker>
<rawString>E. T. Jaynes. 1957. Information Theory and Statistical Mechanics. Physical Review Online Archive (Prola), 106(4):620–630.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Jiao</author>
<author>S Wang</author>
<author>C Lee</author>
<author>R Greiner</author>
<author>D Schuurmans</author>
</authors>
<title>Semi-supervised conditional random fields for improved sequence segmentation and labeling.</title>
<date>2006</date>
<booktitle>In COLING/ACL,</booktitle>
<pages>209--216</pages>
<contexts>
<context position="23102" citStr="Jiao et al., 2006" startWordPosition="3701" endWordPosition="3704">roduction 74.8 13.2 5.4 0.6 5.9 0.1 - - Methods 0.5 0.2 97.5 1.4 0.2 0.2 0.1 - Results 4.0 2.1 11.7 68.9 12.1 1.1 0.1 - Discussion 16.9 1.1 0.7 1.5 63.5 13.3 2.4 0.7 Table 5: Performance of baselines on the Discussion section. BKG PROB METH RES CON CN DIFF FUT Full supervision SVM .56 0 0 0 .84 .35 0 0 MaxEnt .55 .08 0 0 .84 .38 0 0 Light supervision with 150 labeled sentence SVM .26 0 0 0 .80 .05 0 0 TSVM .25 .04 .04 .03 .33 14 .06 .02 MaxEnt .25 0 0 0 .80 .10 0 0 MaxEnt+ER .23 0 0 0 .80 .07 0 0 ductive SVM (TSVM) and semi-supervised MaxEnt based on Entropy Regularization (ER) (Vapnik, 1998; Jiao et al., 2006). SVM and MaxEnt have proved successful in information structure analysis (e.g. (Merity et al., 2009; Guo et al., 2011)) but, to the best of our knowledge, their semi-supervised versions have not been used for AZ of full articles. Parameter tuning The boundaries of the reference probabilities (ak and bk in Equation (8)) were defined and optimized on the development data which consists of one third of the corpus. We considered six types of boundaries: Fairly High for 1, High for [0.9,1), Medium High for [0.5,0.9), Medium Low for [0.1,0.5), Low for [0,0.1), and Fairly Low for 0. Evaluation We ev</context>
</contexts>
<marker>Jiao, Wang, Lee, Greiner, Schuurmans, 2006</marker>
<rawString>F. Jiao, S. Wang, C. Lee, R. Greiner, and D. Schuurmans. 2006. Semi-supervised conditional random fields for improved sequence segmentation and labeling. In COLING/ACL, pages 209–216.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Liakata</author>
<author>S Teufel</author>
<author>A Siddharthan</author>
<author>C Batchelor</author>
</authors>
<title>Corpora for the conceptualisation and zoning of scientific papers.</title>
<date>2010</date>
<booktitle>In Proceedings of LREC’10.</booktitle>
<contexts>
<context position="7222" citStr="Liakata et al., 2010" startWordPosition="1091" endWordPosition="1094"> Previous work Information structure analysis The information structure of scientific documents (e.g. journal articles, abstracts, essays) can be analyzed in terms of patterns of topics, functions or relations observed in multi-sentence scientific text. Computational approaches have mainly focused on analysis based on argumentative zones (Teufel and Moens, 2002; Mizuta et al., 2006; Hachey and Grover, 2006; Teufel et al., 2009), discourse structure (Burstein et al., 2003; Webber et al., 2011), qualitative dimensions (Shatkay et al., 2008), scientific claims (Blake, 2009), scientific concepts (Liakata et al., 2010) and information status (Markert et al., 2012). Most existing methods for analyzing scientific text according to information structure use full supervision in the form of thousands of manually annotated sentences (Teufel and Moens, 2002; Burstein et al., 2003; Mizuta et al., 2006; Shatkay et al., 2008; Guo et al., 2010; Liakata et al., 2012; Markert et al., 2012). Because manual annotation is prohibitively expensive, approaches based on light supervision are now emerging for the task, including those based on active learning and self-training (Guo et al., 2011) and unsupervised methods (Varga </context>
</contexts>
<marker>Liakata, Teufel, Siddharthan, Batchelor, 2010</marker>
<rawString>M. Liakata, S. Teufel, A. Siddharthan, and C. Batchelor. 2010. Corpora for the conceptualisation and zoning of scientific papers. In Proceedings of LREC’10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maria Liakata</author>
<author>Shyamasree Saha</author>
<author>Simon Dobnik</author>
<author>Colin Batchelor</author>
<author>Dietrich Rebholz-Schuhmann</author>
</authors>
<title>Automatic recognition of conceptualisation zones in scientific articles and two life science applications.</title>
<date>2012</date>
<journal>Bioinformatics,</journal>
<pages>28--991</pages>
<contexts>
<context position="1610" citStr="Liakata et al., 2012" startWordPosition="225" endWordPosition="228">r approach can be useful even when no labeled data is available. 1 Introduction Techniques that enable automatic analysis of the information structure of scientific articles can help scientists identify information of interest in the growing volume of scientific literature. For example, classification of sentences according to argumentative zones (AZ) – an information structure scheme that is applicable across scientific domains (Teufel et al., 2009) – can support information retrieval, information extraction and summarization (Teufel and Moens, 2002; Tbahriti et al., 2006; Ruch et al., 2007; Liakata et al., 2012; Contractor et al., 2012). Previous work on sentence-based classification of scientific literature according to categories of information structure has mostly used feature-based machine learning, such as Support Vector Machines (SVM) and Conditional Random Fields (CRF) (e.g. (Teufel and Moens, 2002; Lin et al., 2006; Hirohata et al., 2008; Shatkay et al., 2008; Guo et al., 2010; Liakata et al., 2012)). Unfortunately, the performance of these methods is rather limited, as indicated e.g. by the relatively low numbers reported by Liakata et al. (2012) in biochemistry and chemistry with per-class</context>
<context position="7564" citStr="Liakata et al., 2012" startWordPosition="1146" endWordPosition="1149">ufel and Moens, 2002; Mizuta et al., 2006; Hachey and Grover, 2006; Teufel et al., 2009), discourse structure (Burstein et al., 2003; Webber et al., 2011), qualitative dimensions (Shatkay et al., 2008), scientific claims (Blake, 2009), scientific concepts (Liakata et al., 2010) and information status (Markert et al., 2012). Most existing methods for analyzing scientific text according to information structure use full supervision in the form of thousands of manually annotated sentences (Teufel and Moens, 2002; Burstein et al., 2003; Mizuta et al., 2006; Shatkay et al., 2008; Guo et al., 2010; Liakata et al., 2012; Markert et al., 2012). Because manual annotation is prohibitively expensive, approaches based on light supervision are now emerging for the task, including those based on active learning and self-training (Guo et al., 2011) and unsupervised methods (Varga et al., 2012; Reichart and Korhonen, 2012). Unfortunately, these approaches do not reach the performance level of fully supervised models, let alone exceed it. Our novel method addresses this problem. Declarative knowledge and constraints Previous work has shown that incorporating declarative constraints into feature-based machine learning </context>
</contexts>
<marker>Liakata, Saha, Dobnik, Batchelor, Rebholz-Schuhmann, 2012</marker>
<rawString>Maria Liakata, Shyamasree Saha, Simon Dobnik, Colin Batchelor, and Dietrich Rebholz-Schuhmann. 2012. Automatic recognition of conceptualisation zones in scientific articles and two life science applications. Bioinformatics, 28:991–1000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lin</author>
<author>D Karakos</author>
<author>D Demner-Fushman</author>
<author>S Khudanpur</author>
</authors>
<title>Generative content models for structural analysis of medical abstracts.</title>
<date>2006</date>
<booktitle>In Proceedings of BioNLP-06,</booktitle>
<pages>65--72</pages>
<contexts>
<context position="1928" citStr="Lin et al., 2006" startWordPosition="271" endWordPosition="274">ing to argumentative zones (AZ) – an information structure scheme that is applicable across scientific domains (Teufel et al., 2009) – can support information retrieval, information extraction and summarization (Teufel and Moens, 2002; Tbahriti et al., 2006; Ruch et al., 2007; Liakata et al., 2012; Contractor et al., 2012). Previous work on sentence-based classification of scientific literature according to categories of information structure has mostly used feature-based machine learning, such as Support Vector Machines (SVM) and Conditional Random Fields (CRF) (e.g. (Teufel and Moens, 2002; Lin et al., 2006; Hirohata et al., 2008; Shatkay et al., 2008; Guo et al., 2010; Liakata et al., 2012)). Unfortunately, the performance of these methods is rather limited, as indicated e.g. by the relatively low numbers reported by Liakata et al. (2012) in biochemistry and chemistry with per-class F-scores ranging from .18 to .76. We propose a novel approach to this task in which traditional feature-based models are augmented with explicit declarative expert and domain knowledge, and apply it to sentence-based AZ. We explore two sources of declarative knowledge for our task - discourse and lexical. One way to</context>
</contexts>
<marker>Lin, Karakos, Demner-Fushman, Khudanpur, 2006</marker>
<rawString>J. Lin, D. Karakos, D. Demner-Fushman, and S. Khudanpur. 2006. Generative content models for structural analysis of medical abstracts. In Proceedings of BioNLP-06, pages 65–72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Mann</author>
<author>A McCallum</author>
</authors>
<title>Simple, robust, scalable semi-supervised learning via expectation regularization.</title>
<date>2007</date>
<booktitle>In ICML.</booktitle>
<contexts>
<context position="4705" citStr="Mann and McCallum, 2007" startWordPosition="717" endWordPosition="720">This can be explicitly encoded in the model through a target distribution for sentences containing certain modal verbs. Recent work has shown that explicit declaration of domain and expert knowledge can be highly useful for structured NLP tasks such as parsing, POS tagging and information extraction (Chang et al., 2007; Mann and McCallum, 2008; Ganchev et al., 2010). These works have encoded expert knowledge through constraints, with different frameworks differing in the type of constraints and the inference and learning algorithms used. We build on the Generalized Expectation (GE) framework (Mann and McCallum, 2007) which encodes expert knowledge through a preference (i.e. soft) constraints for parameter settings for which the predicted label distribution matches a target distribution. In order to integrate domain knowledge with a features-based model, we develop a simple taxonomy of constraints (i.e. desired class distributions) and employ a top-down classification algorithm on top of a Maximum Entropy Model augmented with GE constraints. This algorithm enables us to break the multi-class prediction into a pipeline of consecutive, simpler predictions which can be better assisted by the encoded knowledge</context>
</contexts>
<marker>Mann, McCallum, 2007</marker>
<rawString>G. Mann and A. McCallum. 2007. Simple, robust, scalable semi-supervised learning via expectation regularization. In ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Mann</author>
<author>A McCallum</author>
</authors>
<title>Generalized expectation criteria for semi-supervised learning of conditional random fields.</title>
<date>2008</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="4426" citStr="Mann and McCallum, 2008" startWordPosition="675" endWordPosition="678">A adduct of BA and might thus be slightly overestimated. The verb “calculated” usually indicates the “Method” class, but, when accompanied by the modal verb “might”, it is more likely to imply that authors are interpreting their own results (i.e. the “Conclusion” class in AZ). This can be explicitly encoded in the model through a target distribution for sentences containing certain modal verbs. Recent work has shown that explicit declaration of domain and expert knowledge can be highly useful for structured NLP tasks such as parsing, POS tagging and information extraction (Chang et al., 2007; Mann and McCallum, 2008; Ganchev et al., 2010). These works have encoded expert knowledge through constraints, with different frameworks differing in the type of constraints and the inference and learning algorithms used. We build on the Generalized Expectation (GE) framework (Mann and McCallum, 2007) which encodes expert knowledge through a preference (i.e. soft) constraints for parameter settings for which the predicted label distribution matches a target distribution. In order to integrate domain knowledge with a features-based model, we develop a simple taxonomy of constraints (i.e. desired class distributions) </context>
<context position="5805" citStr="Mann and McCallum, 2008" startWordPosition="880" endWordPosition="884">-class prediction into a pipeline of consecutive, simpler predictions which can be better assisted by the encoded knowledge. We experiment in the biological domain with the eight-category AZ scheme (Table 1) adapted from (Mizuta et al., 2006) and described in (Contractor et al., 2012). The results show that our constrained model substantially outperforms a baseline unconstrained Maximum Entropy Model. While this type of constrained models have previously improved the feature-based model performance mostly in the weakly supervised and domain adaptation scenarios (e.g. (Mann and McCallum, 2007; Mann and McCallum, 2008; Ganchev et al., 2010)), we demonstrate substantial gains both when the Maximum EnTable 1: The AZ categories included in the categorization scheme of this paper. Zone Definition Background (BKG) the background of the study Problem (PROB) the research problem Method (METH) the methods used Result (RES) the results achieved Conclusion (CON) the authors’ conclusions Connection (CN) work consistent with the current work Difference (DIFF) work inconsistent with the current work Future work (FUT) the potential future direction of the research tropy Model is fully trained and when its training data </context>
<context position="8248" citStr="Mann and McCallum, 2008" startWordPosition="1247" endWordPosition="1250">tively expensive, approaches based on light supervision are now emerging for the task, including those based on active learning and self-training (Guo et al., 2011) and unsupervised methods (Varga et al., 2012; Reichart and Korhonen, 2012). Unfortunately, these approaches do not reach the performance level of fully supervised models, let alone exceed it. Our novel method addresses this problem. Declarative knowledge and constraints Previous work has shown that incorporating declarative constraints into feature-based machine learning 929 models works well in many NLP tasks (Chang et al., 2007; Mann and McCallum, 2008; Druck et al., 2008; Bellare et al., 2009; Ganchev et al., 2010). Such constraints can be used in a semi-supervised or unsupervised fashion. For example, (Mann and McCallum, 2008) shows that using CRF in conjunction with auxiliary constraints on unlabeled data significantly outperforms traditional CRF in information extraction, and (Druck et al., 2008) shows that using declarative constraints alone for unsupervised learning achieves good results in text classification. We show that declarative constraints can be highly useful for the identification of information structure of scientific docum</context>
<context position="11585" citStr="Mann and McCallum, 2008" startWordPosition="1777" endWordPosition="1780">, D(·) to be the KL divergence, and g(·) to be an equality constraint. The constraint g(·) can be set in a relaxed manner: (E˜p(x)[Epa(y|x)[fk(x, y)|x]] − E˜p(x,y)[fk(x, y)])2, which is the logarithm of a Gaussian distribution centered at the reference values with a diagonal covariance matrix (Pietra and Pietra, 1993), and the dual problem will become a regularized MaxEnt with a Gaussian prior (µk = 0, Qk = Pk) over the parameters: X X 2 max log(pλ(yi|xi)) − λk (5) λ k 2σ2k (xi,yi)∈L Such a model can be further extended to include expert knowledge or auxiliary constraints on unlabeled data U (Mann and McCallum, 2008; Druck et al., 2008; Bellare et al., 2009): X X λ2 max log(pλ(yi|xi)) − k λ k 2σ2k (xi,yi)∈L − γg∗(Epa(y|x)[f∗(x, y)]) (6) where f*(·) is a collection of auxiliary feature functions on U, g*(·) is a constraint function that takes expert/declarative knowledge Ep∗(y|x)[f*(x, y)] as a reference point, and -y is the weight of the auxiliary GE term. H(·) X max − λ x 1 X k 2ρ2k 930 The auxiliary constraint g∗(·) can take on many forms and the one we used in this work is an L2 penalty function (Dudik, 2007). We trained the model with L-BFGS (Nocedal, 1980) in supervised, semi-supervised and unsuperv</context>
</contexts>
<marker>Mann, McCallum, 2008</marker>
<rawString>G. Mann and A. McCallum. 2008. Generalized expectation criteria for semi-supervised learning of conditional random fields. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katja Markert</author>
<author>Yufang Hou</author>
<author>Michael Strube</author>
</authors>
<title>Collective classification for fine-grained information status.</title>
<date>2012</date>
<booktitle>In Proceedings of ACL 2012,</booktitle>
<pages>795--804</pages>
<contexts>
<context position="7268" citStr="Markert et al., 2012" startWordPosition="1098" endWordPosition="1101">The information structure of scientific documents (e.g. journal articles, abstracts, essays) can be analyzed in terms of patterns of topics, functions or relations observed in multi-sentence scientific text. Computational approaches have mainly focused on analysis based on argumentative zones (Teufel and Moens, 2002; Mizuta et al., 2006; Hachey and Grover, 2006; Teufel et al., 2009), discourse structure (Burstein et al., 2003; Webber et al., 2011), qualitative dimensions (Shatkay et al., 2008), scientific claims (Blake, 2009), scientific concepts (Liakata et al., 2010) and information status (Markert et al., 2012). Most existing methods for analyzing scientific text according to information structure use full supervision in the form of thousands of manually annotated sentences (Teufel and Moens, 2002; Burstein et al., 2003; Mizuta et al., 2006; Shatkay et al., 2008; Guo et al., 2010; Liakata et al., 2012; Markert et al., 2012). Because manual annotation is prohibitively expensive, approaches based on light supervision are now emerging for the task, including those based on active learning and self-training (Guo et al., 2011) and unsupervised methods (Varga et al., 2012; Reichart and Korhonen, 2012). Un</context>
</contexts>
<marker>Markert, Hou, Strube, 2012</marker>
<rawString>Katja Markert, Yufang Hou, and Michael Strube. 2012. Collective classification for fine-grained information status. In Proceedings of ACL 2012, pages 795–804.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A K McCallum</author>
</authors>
<title>Mallet: A machine learning for language toolkit.</title>
<date>2002</date>
<note>http://mallet.cs.umass.edu.</note>
<contexts>
<context position="12275" citStr="McCallum, 2002" startWordPosition="1901" endWordPosition="1902">λ k 2σ2k (xi,yi)∈L − γg∗(Epa(y|x)[f∗(x, y)]) (6) where f*(·) is a collection of auxiliary feature functions on U, g*(·) is a constraint function that takes expert/declarative knowledge Ep∗(y|x)[f*(x, y)] as a reference point, and -y is the weight of the auxiliary GE term. H(·) X max − λ x 1 X k 2ρ2k 930 The auxiliary constraint g∗(·) can take on many forms and the one we used in this work is an L2 penalty function (Dudik, 2007). We trained the model with L-BFGS (Nocedal, 1980) in supervised, semi-supervised and unsupervised fashions on labeled and/or unlabeled data, using the Mallet software (McCallum, 2002). 4 Incorporating Expert Knowledge into GE constraints We defined the auxiliary feature functions – the expert knowledge on unlabeled data as1: f∗k (x, y) = ✶(xk,yk)(x, y), such that Ep*(y|x)[fk(x, y)] = p∗(yk|xk), (7) where ✶(xk�yk)(x, y) is an indicator function, and p∗(yk|xk) is a conditional probability specified in the form of p∗(yk|xk) E [ak, bk] (8) by experts. In particular, we took as the reference point when calculating g∗(·). We defined two types of constraints: those based on discourse properties such as the location of a sentence in a particular section or paragraph, and those bas</context>
</contexts>
<marker>McCallum, 2002</marker>
<rawString>A. K. McCallum. 2002. Mallet: A machine learning for language toolkit. http://mallet.cs.umass.edu.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Merity</author>
<author>T Murphy</author>
<author>J R Curran</author>
</authors>
<title>Accurate argumentative zoning with maximum entropy models.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Workshop on Text and Citation Analysis for Scholarly Digital Libraries,</booktitle>
<pages>pages</pages>
<contexts>
<context position="23202" citStr="Merity et al., 2009" startWordPosition="3716" endWordPosition="3719"> 68.9 12.1 1.1 0.1 - Discussion 16.9 1.1 0.7 1.5 63.5 13.3 2.4 0.7 Table 5: Performance of baselines on the Discussion section. BKG PROB METH RES CON CN DIFF FUT Full supervision SVM .56 0 0 0 .84 .35 0 0 MaxEnt .55 .08 0 0 .84 .38 0 0 Light supervision with 150 labeled sentence SVM .26 0 0 0 .80 .05 0 0 TSVM .25 .04 .04 .03 .33 14 .06 .02 MaxEnt .25 0 0 0 .80 .10 0 0 MaxEnt+ER .23 0 0 0 .80 .07 0 0 ductive SVM (TSVM) and semi-supervised MaxEnt based on Entropy Regularization (ER) (Vapnik, 1998; Jiao et al., 2006). SVM and MaxEnt have proved successful in information structure analysis (e.g. (Merity et al., 2009; Guo et al., 2011)) but, to the best of our knowledge, their semi-supervised versions have not been used for AZ of full articles. Parameter tuning The boundaries of the reference probabilities (ak and bk in Equation (8)) were defined and optimized on the development data which consists of one third of the corpus. We considered six types of boundaries: Fairly High for 1, High for [0.9,1), Medium High for [0.5,0.9), Medium Low for [0.1,0.5), Low for [0,0.1), and Fairly Low for 0. Evaluation We evaluated the precision, recall and F-score for each category, using a standard ten-fold cross-validat</context>
</contexts>
<marker>Merity, Murphy, Curran, 2009</marker>
<rawString>S. Merity, T. Murphy, and J. R. Curran. 2009. Accurate argumentative zoning with maximum entropy models. In Proceedings of the 2009 Workshop on Text and Citation Analysis for Scholarly Digital Libraries, pages 19–26.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Mizuta</author>
<author>A Korhonen</author>
<author>T Mullen</author>
<author>N Collier</author>
</authors>
<title>Zone analysis in biology articles as a basis for information extraction.</title>
<date>2006</date>
<journal>International Journal of Medical Informatics on Natural Language Processing in Biomedicine and Its Applications,</journal>
<volume>75</volume>
<issue>6</issue>
<contexts>
<context position="5424" citStr="Mizuta et al., 2006" startWordPosition="826" endWordPosition="829"> for which the predicted label distribution matches a target distribution. In order to integrate domain knowledge with a features-based model, we develop a simple taxonomy of constraints (i.e. desired class distributions) and employ a top-down classification algorithm on top of a Maximum Entropy Model augmented with GE constraints. This algorithm enables us to break the multi-class prediction into a pipeline of consecutive, simpler predictions which can be better assisted by the encoded knowledge. We experiment in the biological domain with the eight-category AZ scheme (Table 1) adapted from (Mizuta et al., 2006) and described in (Contractor et al., 2012). The results show that our constrained model substantially outperforms a baseline unconstrained Maximum Entropy Model. While this type of constrained models have previously improved the feature-based model performance mostly in the weakly supervised and domain adaptation scenarios (e.g. (Mann and McCallum, 2007; Mann and McCallum, 2008; Ganchev et al., 2010)), we demonstrate substantial gains both when the Maximum EnTable 1: The AZ categories included in the categorization scheme of this paper. Zone Definition Background (BKG) the background of the s</context>
<context position="6985" citStr="Mizuta et al., 2006" startWordPosition="1056" endWordPosition="1059">lly trained and when its training data is sparse. This demonstrates the importance of expert knowledge for our task and supports our modeling decision that combines feature-based methods with domain knowledge encoded via constraints. 2 Previous work Information structure analysis The information structure of scientific documents (e.g. journal articles, abstracts, essays) can be analyzed in terms of patterns of topics, functions or relations observed in multi-sentence scientific text. Computational approaches have mainly focused on analysis based on argumentative zones (Teufel and Moens, 2002; Mizuta et al., 2006; Hachey and Grover, 2006; Teufel et al., 2009), discourse structure (Burstein et al., 2003; Webber et al., 2011), qualitative dimensions (Shatkay et al., 2008), scientific claims (Blake, 2009), scientific concepts (Liakata et al., 2010) and information status (Markert et al., 2012). Most existing methods for analyzing scientific text according to information structure use full supervision in the form of thousands of manually annotated sentences (Teufel and Moens, 2002; Burstein et al., 2003; Mizuta et al., 2006; Shatkay et al., 2008; Guo et al., 2010; Liakata et al., 2012; Markert et al., 201</context>
<context position="20437" citStr="Mizuta et al., 2006" startWordPosition="3240" endWordPosition="3243">ate use method observe conclude suggest because likely need future consistent inconsistent than however 932 6 Experiments Data We used the full paper corpus used by Contractor et al. (2012) which contains 8171 sentences from 50 biomedical journal articles. The corpus is annotated according to the AZ scheme described in Table 1. AZ describes the logical structure, scientific argumentation and intellectual attribution of a scientific paper. It was originally introduced by Teufel and Moens (2002) and applied to computational linguistics papers, and later adapted to other domains such as biology (Mizuta et al., 2006) – which we used in this work – and chemistry (Teufel et al., 2009). Table 4 shows the AZ class distribution in full articles as well as in individual sections. Since section names vary across scientific articles, we grouped similar sections before calculating the statistics (e.g. Discussion and Conclusions sections were grouped under Discussion). We can see that although there is a major category in each section (e.g. CON in Discussion), up to 36.5% of the sentences in each section still belong to other categories. Features We extracted the following features from each sentence and used them </context>
</contexts>
<marker>Mizuta, Korhonen, Mullen, Collier, 2006</marker>
<rawString>Y. Mizuta, A. Korhonen, T. Mullen, and N. Collier. 2006. Zone analysis in biology articles as a basis for information extraction. International Journal of Medical Informatics on Natural Language Processing in Biomedicine and Its Applications, 75(6):468–487.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jorge Nocedal</author>
</authors>
<title>Updating Quasi-Newton Matrices with Limited Storage.</title>
<date>1980</date>
<journal>Mathematics of Computation,</journal>
<volume>35</volume>
<issue>151</issue>
<contexts>
<context position="12141" citStr="Nocedal, 1980" startWordPosition="1882" endWordPosition="1883">y constraints on unlabeled data U (Mann and McCallum, 2008; Druck et al., 2008; Bellare et al., 2009): X X λ2 max log(pλ(yi|xi)) − k λ k 2σ2k (xi,yi)∈L − γg∗(Epa(y|x)[f∗(x, y)]) (6) where f*(·) is a collection of auxiliary feature functions on U, g*(·) is a constraint function that takes expert/declarative knowledge Ep∗(y|x)[f*(x, y)] as a reference point, and -y is the weight of the auxiliary GE term. H(·) X max − λ x 1 X k 2ρ2k 930 The auxiliary constraint g∗(·) can take on many forms and the one we used in this work is an L2 penalty function (Dudik, 2007). We trained the model with L-BFGS (Nocedal, 1980) in supervised, semi-supervised and unsupervised fashions on labeled and/or unlabeled data, using the Mallet software (McCallum, 2002). 4 Incorporating Expert Knowledge into GE constraints We defined the auxiliary feature functions – the expert knowledge on unlabeled data as1: f∗k (x, y) = ✶(xk,yk)(x, y), such that Ep*(y|x)[fk(x, y)] = p∗(yk|xk), (7) where ✶(xk�yk)(x, y) is an indicator function, and p∗(yk|xk) is a conditional probability specified in the form of p∗(yk|xk) E [ak, bk] (8) by experts. In particular, we took as the reference point when calculating g∗(·). We defined two types of c</context>
</contexts>
<marker>Nocedal, 1980</marker>
<rawString>Jorge Nocedal. 1980. Updating Quasi-Newton Matrices with Limited Storage. Mathematics of Computation, 35(151):773–782.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Della Pietra</author>
<author>V Della Pietra</author>
</authors>
<title>Statistical modeling by me.</title>
<date>1993</date>
<tech>Technical report, IBM.</tech>
<contexts>
<context position="9498" citStr="Pietra and Pietra, 1993" startWordPosition="1430" endWordPosition="1433">t previous works, we show that such constraints can improve the performance of a fully supervised model. The constraints are particularly helpful for identifying low-frequency information categories, but still yield high performance on high-frequency categories. 3 Maximum-Entropy Estimation and Generalized Expectation (GE) In this section we describe the Generalized Expectation method for declarative knowledge encoding. Maximum Entropy (ME) The idea of Generalized Expectation (Dud´ık, 2007; Mann and McCallum, 2008; Druck et al., 2008) stems from the principle of maximum entropy (Jaynes, 1957; Pietra and Pietra, 1993) which raises the following constrained optimization problem: max p subject to Ep[f(·)] = E˜p[f(·)] p(·) ≥ 0 X p(·) = 1, (1) where p(·) is the empirical distribution, p(·) is a probability distribution in the model and H(·) is the corresponding information entropy, f(·) is a collection of feature functions, and Ep[f(·)] and Ef,[f(·)] are the expectations of f with respect to p(·) and p(·). An example of p(·) could be a conditional probability distribution p(y|x), and H(·) could be a conditional entropy H(y|x). The optimal p(y|x) will take on an exponential form: 1 pλ(y|x) = exp(λ · f(x, y)), (</context>
<context position="10839" citStr="Pietra and Pietra, 1993" startWordPosition="1644" endWordPosition="1647">ion function. The dual problem becomes maximizing the conditional log-likelihood of labeled data L (Berger et al., 1996): X log(pλ(yi|xi)), (3) max λ (xi,yi)∈L which is usually known as a Log-linear or Maximum Entropy Model (MaxEnt). ME with Generalized Expectation The objective function and the constraints on expectations in (1) can be generalized to: ˜p(x)D(pλ(y|x)||p0(y|x)) − g(E˜p(x)[Epa(y|x)[f(x, y)|x]]), (4) where D(p),||p0) is the divergence from p), to a base distribution p0, and g(·) is a constraint/penalty function that takes empirical evidence EP(x�y)[f(x, y)] as a reference point (Pietra and Pietra, 1993; Chen et al., 2000; Dud´ık, 2007). Note that a special case of this is MaxEnt where p0 is set to be a uniform distribution, D(·) to be the KL divergence, and g(·) to be an equality constraint. The constraint g(·) can be set in a relaxed manner: (E˜p(x)[Epa(y|x)[fk(x, y)|x]] − E˜p(x,y)[fk(x, y)])2, which is the logarithm of a Gaussian distribution centered at the reference values with a diagonal covariance matrix (Pietra and Pietra, 1993), and the dual problem will become a regularized MaxEnt with a Gaussian prior (µk = 0, Qk = Pk) over the parameters: X X 2 max log(pλ(yi|xi)) − λk (5) λ k 2σ2</context>
</contexts>
<marker>Pietra, Pietra, 1993</marker>
<rawString>S. Della Pietra and V. Della Pietra. 1993. Statistical modeling by me. Technical report, IBM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roi Reichart</author>
<author>Anna Korhonen</author>
</authors>
<title>Document and corpus level inference for unsupervised and transductive learning of information structure of scientic documents.</title>
<date>2012</date>
<booktitle>In Proceedings of COLING</booktitle>
<contexts>
<context position="7864" citStr="Reichart and Korhonen, 2012" startWordPosition="1190" endWordPosition="1193">on status (Markert et al., 2012). Most existing methods for analyzing scientific text according to information structure use full supervision in the form of thousands of manually annotated sentences (Teufel and Moens, 2002; Burstein et al., 2003; Mizuta et al., 2006; Shatkay et al., 2008; Guo et al., 2010; Liakata et al., 2012; Markert et al., 2012). Because manual annotation is prohibitively expensive, approaches based on light supervision are now emerging for the task, including those based on active learning and self-training (Guo et al., 2011) and unsupervised methods (Varga et al., 2012; Reichart and Korhonen, 2012). Unfortunately, these approaches do not reach the performance level of fully supervised models, let alone exceed it. Our novel method addresses this problem. Declarative knowledge and constraints Previous work has shown that incorporating declarative constraints into feature-based machine learning 929 models works well in many NLP tasks (Chang et al., 2007; Mann and McCallum, 2008; Druck et al., 2008; Bellare et al., 2009; Ganchev et al., 2010). Such constraints can be used in a semi-supervised or unsupervised fashion. For example, (Mann and McCallum, 2008) shows that using CRF in conjunction</context>
</contexts>
<marker>Reichart, Korhonen, 2012</marker>
<rawString>Roi Reichart and Anna Korhonen. 2012. Document and corpus level inference for unsupervised and transductive learning of information structure of scientic documents. In Proceedings of COLING 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Ruch</author>
<author>C Boyer</author>
<author>C Chichester</author>
<author>I Tbahriti</author>
<author>A Geissbuhler</author>
<author>P Fabry</author>
<author>J Gobeill</author>
<author>V Pillet</author>
<author>D RebholzSchuhmann</author>
<author>C Lovis</author>
<author>A L Veuthey</author>
</authors>
<title>Using argumentation to extract key sentences from biomedical abstracts.</title>
<date>2007</date>
<journal>Int J Med Inform,</journal>
<pages>76--2</pages>
<contexts>
<context position="1588" citStr="Ruch et al., 2007" startWordPosition="221" endWordPosition="224">ls, showing that our approach can be useful even when no labeled data is available. 1 Introduction Techniques that enable automatic analysis of the information structure of scientific articles can help scientists identify information of interest in the growing volume of scientific literature. For example, classification of sentences according to argumentative zones (AZ) – an information structure scheme that is applicable across scientific domains (Teufel et al., 2009) – can support information retrieval, information extraction and summarization (Teufel and Moens, 2002; Tbahriti et al., 2006; Ruch et al., 2007; Liakata et al., 2012; Contractor et al., 2012). Previous work on sentence-based classification of scientific literature according to categories of information structure has mostly used feature-based machine learning, such as Support Vector Machines (SVM) and Conditional Random Fields (CRF) (e.g. (Teufel and Moens, 2002; Lin et al., 2006; Hirohata et al., 2008; Shatkay et al., 2008; Guo et al., 2010; Liakata et al., 2012)). Unfortunately, the performance of these methods is rather limited, as indicated e.g. by the relatively low numbers reported by Liakata et al. (2012) in biochemistry and ch</context>
</contexts>
<marker>Ruch, Boyer, Chichester, Tbahriti, Geissbuhler, Fabry, Gobeill, Pillet, RebholzSchuhmann, Lovis, Veuthey, 2007</marker>
<rawString>P. Ruch, C. Boyer, C. Chichester, I. Tbahriti, A. Geissbuhler, P. Fabry, J. Gobeill, V. Pillet, D. RebholzSchuhmann, C. Lovis, and A. L. Veuthey. 2007. Using argumentation to extract key sentences from biomedical abstracts. Int J Med Inform, 76(2-3):195–200.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Shatkay</author>
<author>F Pan</author>
<author>A Rzhetsky</author>
<author>W J Wilbur</author>
</authors>
<title>Multi-dimensional classification of biomedical text: Toward automated, practical provision of high-utility text to diverse users.</title>
<date>2008</date>
<journal>Bioinformatics,</journal>
<volume>24</volume>
<issue>18</issue>
<contexts>
<context position="1973" citStr="Shatkay et al., 2008" startWordPosition="280" endWordPosition="283">rmation structure scheme that is applicable across scientific domains (Teufel et al., 2009) – can support information retrieval, information extraction and summarization (Teufel and Moens, 2002; Tbahriti et al., 2006; Ruch et al., 2007; Liakata et al., 2012; Contractor et al., 2012). Previous work on sentence-based classification of scientific literature according to categories of information structure has mostly used feature-based machine learning, such as Support Vector Machines (SVM) and Conditional Random Fields (CRF) (e.g. (Teufel and Moens, 2002; Lin et al., 2006; Hirohata et al., 2008; Shatkay et al., 2008; Guo et al., 2010; Liakata et al., 2012)). Unfortunately, the performance of these methods is rather limited, as indicated e.g. by the relatively low numbers reported by Liakata et al. (2012) in biochemistry and chemistry with per-class F-scores ranging from .18 to .76. We propose a novel approach to this task in which traditional feature-based models are augmented with explicit declarative expert and domain knowledge, and apply it to sentence-based AZ. We explore two sources of declarative knowledge for our task - discourse and lexical. One way to utilize discourse knowledge is to guide the </context>
<context position="7145" citStr="Shatkay et al., 2008" startWordPosition="1081" endWordPosition="1084">mbines feature-based methods with domain knowledge encoded via constraints. 2 Previous work Information structure analysis The information structure of scientific documents (e.g. journal articles, abstracts, essays) can be analyzed in terms of patterns of topics, functions or relations observed in multi-sentence scientific text. Computational approaches have mainly focused on analysis based on argumentative zones (Teufel and Moens, 2002; Mizuta et al., 2006; Hachey and Grover, 2006; Teufel et al., 2009), discourse structure (Burstein et al., 2003; Webber et al., 2011), qualitative dimensions (Shatkay et al., 2008), scientific claims (Blake, 2009), scientific concepts (Liakata et al., 2010) and information status (Markert et al., 2012). Most existing methods for analyzing scientific text according to information structure use full supervision in the form of thousands of manually annotated sentences (Teufel and Moens, 2002; Burstein et al., 2003; Mizuta et al., 2006; Shatkay et al., 2008; Guo et al., 2010; Liakata et al., 2012; Markert et al., 2012). Because manual annotation is prohibitively expensive, approaches based on light supervision are now emerging for the task, including those based on active l</context>
</contexts>
<marker>Shatkay, Pan, Rzhetsky, Wilbur, 2008</marker>
<rawString>H. Shatkay, F. Pan, A. Rzhetsky, and W. J. Wilbur. 2008. Multi-dimensional classification of biomedical text: Toward automated, practical provision of high-utility text to diverse users. Bioinformatics, 24(18):2086– 2093.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Sun</author>
<author>A Korhonen</author>
</authors>
<title>Improving verb clustering with automatically acquired selectional preference.</title>
<date>2009</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>638--647</pages>
<contexts>
<context position="21461" citStr="Sun and Korhonen, 2009" startWordPosition="3404" endWordPosition="3407">in each section (e.g. CON in Discussion), up to 36.5% of the sentences in each section still belong to other categories. Features We extracted the following features from each sentence and used them in the featurebased classifiers: (1) Discourse features: location in the article/section/paragraph. For this feature each text batch was divided to ten equal size parts and the corresponding feature value identifies the relevant part; (2) Lexical features: number of citations and references to tables and figures (0, 1, or more), word, bi-gram, verb, and verb class (obtained by spectral clustering (Sun and Korhonen, 2009)); (3) Syntactic features: tense and voice (POS tags of main and auxiliary verbs), grammatical relation, subject and object. The lexical and the syntactic features were extracted for the represented sentence as well as for its surrounding sentences. We used the C&amp;C POS tagger and parser (Curran et al., 2007) for extracting the lexical and the syntactic features. Note that all the information encoded into our constraints is also encoded in the features and is thus available to the feature-based model. This enables us to properly evaluate the impact of our modeling decision which augments a feat</context>
</contexts>
<marker>Sun, Korhonen, 2009</marker>
<rawString>L. Sun and A. Korhonen. 2009. Improving verb clustering with automatically acquired selectional preference. In Proceedings of EMNLP, pages 638–647.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Tbahriti</author>
<author>C Chichester</author>
<author>Frederique Lisacek</author>
<author>P Ruch</author>
</authors>
<title>Using argumentation to retrieve articles with similar citations.</title>
<date>2006</date>
<journal>Int J Med Inform,</journal>
<volume>75</volume>
<issue>6</issue>
<contexts>
<context position="1569" citStr="Tbahriti et al., 2006" startWordPosition="217" endWordPosition="220">ised feature-based models, showing that our approach can be useful even when no labeled data is available. 1 Introduction Techniques that enable automatic analysis of the information structure of scientific articles can help scientists identify information of interest in the growing volume of scientific literature. For example, classification of sentences according to argumentative zones (AZ) – an information structure scheme that is applicable across scientific domains (Teufel et al., 2009) – can support information retrieval, information extraction and summarization (Teufel and Moens, 2002; Tbahriti et al., 2006; Ruch et al., 2007; Liakata et al., 2012; Contractor et al., 2012). Previous work on sentence-based classification of scientific literature according to categories of information structure has mostly used feature-based machine learning, such as Support Vector Machines (SVM) and Conditional Random Fields (CRF) (e.g. (Teufel and Moens, 2002; Lin et al., 2006; Hirohata et al., 2008; Shatkay et al., 2008; Guo et al., 2010; Liakata et al., 2012)). Unfortunately, the performance of these methods is rather limited, as indicated e.g. by the relatively low numbers reported by Liakata et al. (2012) in </context>
</contexts>
<marker>Tbahriti, Chichester, Lisacek, Ruch, 2006</marker>
<rawString>I. Tbahriti, C. Chichester, Frederique Lisacek, and P. Ruch. 2006. Using argumentation to retrieve articles with similar citations. Int J Med Inform, 75(6):488–495.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Teufel</author>
<author>M Moens</author>
</authors>
<title>Summarizing scientific articles: Experiments with relevance and rhetorical status.</title>
<date>2002</date>
<journal>Computational Linguistics,</journal>
<pages>28--409</pages>
<contexts>
<context position="1546" citStr="Teufel and Moens, 2002" startWordPosition="213" endWordPosition="216">tperforms lightly supervised feature-based models, showing that our approach can be useful even when no labeled data is available. 1 Introduction Techniques that enable automatic analysis of the information structure of scientific articles can help scientists identify information of interest in the growing volume of scientific literature. For example, classification of sentences according to argumentative zones (AZ) – an information structure scheme that is applicable across scientific domains (Teufel et al., 2009) – can support information retrieval, information extraction and summarization (Teufel and Moens, 2002; Tbahriti et al., 2006; Ruch et al., 2007; Liakata et al., 2012; Contractor et al., 2012). Previous work on sentence-based classification of scientific literature according to categories of information structure has mostly used feature-based machine learning, such as Support Vector Machines (SVM) and Conditional Random Fields (CRF) (e.g. (Teufel and Moens, 2002; Lin et al., 2006; Hirohata et al., 2008; Shatkay et al., 2008; Guo et al., 2010; Liakata et al., 2012)). Unfortunately, the performance of these methods is rather limited, as indicated e.g. by the relatively low numbers reported by Li</context>
<context position="6964" citStr="Teufel and Moens, 2002" startWordPosition="1052" endWordPosition="1055">search tropy Model is fully trained and when its training data is sparse. This demonstrates the importance of expert knowledge for our task and supports our modeling decision that combines feature-based methods with domain knowledge encoded via constraints. 2 Previous work Information structure analysis The information structure of scientific documents (e.g. journal articles, abstracts, essays) can be analyzed in terms of patterns of topics, functions or relations observed in multi-sentence scientific text. Computational approaches have mainly focused on analysis based on argumentative zones (Teufel and Moens, 2002; Mizuta et al., 2006; Hachey and Grover, 2006; Teufel et al., 2009), discourse structure (Burstein et al., 2003; Webber et al., 2011), qualitative dimensions (Shatkay et al., 2008), scientific claims (Blake, 2009), scientific concepts (Liakata et al., 2010) and information status (Markert et al., 2012). Most existing methods for analyzing scientific text according to information structure use full supervision in the form of thousands of manually annotated sentences (Teufel and Moens, 2002; Burstein et al., 2003; Mizuta et al., 2006; Shatkay et al., 2008; Guo et al., 2010; Liakata et al., 2012</context>
<context position="20315" citStr="Teufel and Moens (2002)" startWordPosition="3220" endWordPosition="3223">ategory is mapped to its respective auxiliary class. PROB METH RES CON FUT BKG CN DIFF we previous thus aim question investigate use method observe conclude suggest because likely need future consistent inconsistent than however 932 6 Experiments Data We used the full paper corpus used by Contractor et al. (2012) which contains 8171 sentences from 50 biomedical journal articles. The corpus is annotated according to the AZ scheme described in Table 1. AZ describes the logical structure, scientific argumentation and intellectual attribution of a scientific paper. It was originally introduced by Teufel and Moens (2002) and applied to computational linguistics papers, and later adapted to other domains such as biology (Mizuta et al., 2006) – which we used in this work – and chemistry (Teufel et al., 2009). Table 4 shows the AZ class distribution in full articles as well as in individual sections. Since section names vary across scientific articles, we grouped similar sections before calculating the statistics (e.g. Discussion and Conclusions sections were grouped under Discussion). We can see that although there is a major category in each section (e.g. CON in Discussion), up to 36.5% of the sentences in eac</context>
</contexts>
<marker>Teufel, Moens, 2002</marker>
<rawString>S. Teufel and M. Moens. 2002. Summarizing scientific articles: Experiments with relevance and rhetorical status. Computational Linguistics, 28:409–445.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Teufel</author>
<author>A Siddharthan</author>
<author>C Batchelor</author>
</authors>
<title>Towards discipline-independent argumentative zoning: Evidence from chemistry and computational linguistics.</title>
<date>2009</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="1444" citStr="Teufel et al., 2009" startWordPosition="199" endWordPosition="202"> of existing fully and lightly supervised models. Even a fully unsupervised version of this model outperforms lightly supervised feature-based models, showing that our approach can be useful even when no labeled data is available. 1 Introduction Techniques that enable automatic analysis of the information structure of scientific articles can help scientists identify information of interest in the growing volume of scientific literature. For example, classification of sentences according to argumentative zones (AZ) – an information structure scheme that is applicable across scientific domains (Teufel et al., 2009) – can support information retrieval, information extraction and summarization (Teufel and Moens, 2002; Tbahriti et al., 2006; Ruch et al., 2007; Liakata et al., 2012; Contractor et al., 2012). Previous work on sentence-based classification of scientific literature according to categories of information structure has mostly used feature-based machine learning, such as Support Vector Machines (SVM) and Conditional Random Fields (CRF) (e.g. (Teufel and Moens, 2002; Lin et al., 2006; Hirohata et al., 2008; Shatkay et al., 2008; Guo et al., 2010; Liakata et al., 2012)). Unfortunately, the performa</context>
<context position="7032" citStr="Teufel et al., 2009" startWordPosition="1064" endWordPosition="1067">se. This demonstrates the importance of expert knowledge for our task and supports our modeling decision that combines feature-based methods with domain knowledge encoded via constraints. 2 Previous work Information structure analysis The information structure of scientific documents (e.g. journal articles, abstracts, essays) can be analyzed in terms of patterns of topics, functions or relations observed in multi-sentence scientific text. Computational approaches have mainly focused on analysis based on argumentative zones (Teufel and Moens, 2002; Mizuta et al., 2006; Hachey and Grover, 2006; Teufel et al., 2009), discourse structure (Burstein et al., 2003; Webber et al., 2011), qualitative dimensions (Shatkay et al., 2008), scientific claims (Blake, 2009), scientific concepts (Liakata et al., 2010) and information status (Markert et al., 2012). Most existing methods for analyzing scientific text according to information structure use full supervision in the form of thousands of manually annotated sentences (Teufel and Moens, 2002; Burstein et al., 2003; Mizuta et al., 2006; Shatkay et al., 2008; Guo et al., 2010; Liakata et al., 2012; Markert et al., 2012). Because manual annotation is prohibitively </context>
<context position="20504" citStr="Teufel et al., 2009" startWordPosition="3254" endWordPosition="3257">consistent inconsistent than however 932 6 Experiments Data We used the full paper corpus used by Contractor et al. (2012) which contains 8171 sentences from 50 biomedical journal articles. The corpus is annotated according to the AZ scheme described in Table 1. AZ describes the logical structure, scientific argumentation and intellectual attribution of a scientific paper. It was originally introduced by Teufel and Moens (2002) and applied to computational linguistics papers, and later adapted to other domains such as biology (Mizuta et al., 2006) – which we used in this work – and chemistry (Teufel et al., 2009). Table 4 shows the AZ class distribution in full articles as well as in individual sections. Since section names vary across scientific articles, we grouped similar sections before calculating the statistics (e.g. Discussion and Conclusions sections were grouped under Discussion). We can see that although there is a major category in each section (e.g. CON in Discussion), up to 36.5% of the sentences in each section still belong to other categories. Features We extracted the following features from each sentence and used them in the featurebased classifiers: (1) Discourse features: location i</context>
</contexts>
<marker>Teufel, Siddharthan, Batchelor, 2009</marker>
<rawString>S. Teufel, A. Siddharthan, and C. Batchelor. 2009. Towards discipline-independent argumentative zoning: Evidence from chemistry and computational linguistics. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V N Vapnik</author>
</authors>
<title>Statistical learning theory.</title>
<date>1998</date>
<publisher>Wiley,</publisher>
<location>New York.</location>
<contexts>
<context position="23082" citStr="Vapnik, 1998" startWordPosition="3699" endWordPosition="3700">.3 0.8 0.2 Introduction 74.8 13.2 5.4 0.6 5.9 0.1 - - Methods 0.5 0.2 97.5 1.4 0.2 0.2 0.1 - Results 4.0 2.1 11.7 68.9 12.1 1.1 0.1 - Discussion 16.9 1.1 0.7 1.5 63.5 13.3 2.4 0.7 Table 5: Performance of baselines on the Discussion section. BKG PROB METH RES CON CN DIFF FUT Full supervision SVM .56 0 0 0 .84 .35 0 0 MaxEnt .55 .08 0 0 .84 .38 0 0 Light supervision with 150 labeled sentence SVM .26 0 0 0 .80 .05 0 0 TSVM .25 .04 .04 .03 .33 14 .06 .02 MaxEnt .25 0 0 0 .80 .10 0 0 MaxEnt+ER .23 0 0 0 .80 .07 0 0 ductive SVM (TSVM) and semi-supervised MaxEnt based on Entropy Regularization (ER) (Vapnik, 1998; Jiao et al., 2006). SVM and MaxEnt have proved successful in information structure analysis (e.g. (Merity et al., 2009; Guo et al., 2011)) but, to the best of our knowledge, their semi-supervised versions have not been used for AZ of full articles. Parameter tuning The boundaries of the reference probabilities (ak and bk in Equation (8)) were defined and optimized on the development data which consists of one third of the corpus. We considered six types of boundaries: Fairly High for 1, High for [0.9,1), Medium High for [0.5,0.9), Medium Low for [0.1,0.5), Low for [0,0.1), and Fairly Low for</context>
</contexts>
<marker>Vapnik, 1998</marker>
<rawString>V. N. Vapnik. 1998. Statistical learning theory. Wiley, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Varga</author>
<author>Daniel Preotiuc-Pietro</author>
<author>Fabio Ciravegna</author>
</authors>
<title>Unsupervised document zone identification using probabilistic graphical models.</title>
<date>2012</date>
<booktitle>In Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC’12).</booktitle>
<contexts>
<context position="7834" citStr="Varga et al., 2012" startWordPosition="1186" endWordPosition="1189"> 2010) and information status (Markert et al., 2012). Most existing methods for analyzing scientific text according to information structure use full supervision in the form of thousands of manually annotated sentences (Teufel and Moens, 2002; Burstein et al., 2003; Mizuta et al., 2006; Shatkay et al., 2008; Guo et al., 2010; Liakata et al., 2012; Markert et al., 2012). Because manual annotation is prohibitively expensive, approaches based on light supervision are now emerging for the task, including those based on active learning and self-training (Guo et al., 2011) and unsupervised methods (Varga et al., 2012; Reichart and Korhonen, 2012). Unfortunately, these approaches do not reach the performance level of fully supervised models, let alone exceed it. Our novel method addresses this problem. Declarative knowledge and constraints Previous work has shown that incorporating declarative constraints into feature-based machine learning 929 models works well in many NLP tasks (Chang et al., 2007; Mann and McCallum, 2008; Druck et al., 2008; Bellare et al., 2009; Ganchev et al., 2010). Such constraints can be used in a semi-supervised or unsupervised fashion. For example, (Mann and McCallum, 2008) shows</context>
</contexts>
<marker>Varga, Preotiuc-Pietro, Ciravegna, 2012</marker>
<rawString>Andrea Varga, Daniel Preotiuc-Pietro, and Fabio Ciravegna. 2012. Unsupervised document zone identification using probabilistic graphical models. In Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC’12).</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Webber</author>
<author>M Egg</author>
<author>V Kordoni</author>
</authors>
<date>2011</date>
<booktitle>Discourse structure and language technology. Natural Language Engineering,</booktitle>
<pages>18--437</pages>
<contexts>
<context position="7098" citStr="Webber et al., 2011" startWordPosition="1074" endWordPosition="1077">ask and supports our modeling decision that combines feature-based methods with domain knowledge encoded via constraints. 2 Previous work Information structure analysis The information structure of scientific documents (e.g. journal articles, abstracts, essays) can be analyzed in terms of patterns of topics, functions or relations observed in multi-sentence scientific text. Computational approaches have mainly focused on analysis based on argumentative zones (Teufel and Moens, 2002; Mizuta et al., 2006; Hachey and Grover, 2006; Teufel et al., 2009), discourse structure (Burstein et al., 2003; Webber et al., 2011), qualitative dimensions (Shatkay et al., 2008), scientific claims (Blake, 2009), scientific concepts (Liakata et al., 2010) and information status (Markert et al., 2012). Most existing methods for analyzing scientific text according to information structure use full supervision in the form of thousands of manually annotated sentences (Teufel and Moens, 2002; Burstein et al., 2003; Mizuta et al., 2006; Shatkay et al., 2008; Guo et al., 2010; Liakata et al., 2012; Markert et al., 2012). Because manual annotation is prohibitively expensive, approaches based on light supervision are now emerging </context>
</contexts>
<marker>Webber, Egg, Kordoni, 2011</marker>
<rawString>B. Webber, M. Egg, and V. Kordoni. 2011. Discourse structure and language technology. Natural Language Engineering, 18:437–490.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>