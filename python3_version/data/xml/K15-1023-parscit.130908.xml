<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000463">
<title confidence="0.9874665">
Quantity, Contrast, and Convention in Cross-Situated Language
Comprehension
</title>
<author confidence="0.993782">
Ian Perera and James F. Allen
</author>
<affiliation confidence="0.940776">
University of Rochester, Department of Computer Science, Rochester, NY 14627 USA
Institute for Human and Machine Cognition, Pensacola, FL 32502 USA
</affiliation>
<email confidence="0.987739">
{iperera,jallen}@ihmc.us
</email>
<sectionHeader confidence="0.984383" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999732368421053">
Typically, visually-grounded language
learning systems only accept feature
data about objects in the environment
that are explicitly mentioned, whether
through annotation labels or direct ref-
erence through natural language. We
show that when objects are described
ambiguously using natural language, a
system can use a combination of the
pragmatic principles of Contrast and
Conventionality, and multiple-instance
learning to learn from ambiguous exam-
ples in an online fashion. Applying child
language learning strategies to visual
learning enables more effective learning
in real-time environments, which can
lead to enhanced teaching interactions
with robots or grounded systems in
multi-object environments.
</bodyText>
<sectionHeader confidence="0.992544" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999923983050848">
As opposed to the serial nature of labeled data
presented to a machine learning classifier, chil-
dren and robots “in the wild” must learn object
names and attributes like color, size, and shape
while being surrounded by a number of stimuli
and possible referents. When a child hears “the red
ball”, they must first identify the object mentioned,
then use existing knowledge to identify that “red”
and “ball” are distinct concepts, and over time,
learn that objects called “red” share some sim-
ilarity in color while objects called “ball” share
some similarity in shape. Learning for them there-
fore requires both identification and establishing
joint attention with the speaker before assigning
a label to an object, while also applying other
language learning strategies to narrow down the
search space of possible referents, as illustrated by
Quine’s “gavagai” problem (1964).
Trying to learn attributes and objects without
non-linguistic cues such as pointing and gaze
might seem an insurmountable challenge. Yet a
child experiences many such situations and can
nevertheless learn grounded concepts over time.
Fortunately, adult speakers tend to understand
the limitation of these cues in certain situations
and adjust their speech in accordance to Grice’s
Maxim of Quantity when referring to objects : be
only as informative as necessary (Grice, 1975).
We therefore treat the language describing a par-
ticular object in a scene as an expression of an it-
erative process, where the speaker is attempting to
guide the listener towards the referent in a way that
avoids both ambiguity and unnecessary verbosity.
Language learners additionally make use of the
pragmatic assumptions of Conventionality, that
speakers agree upon the meaning of a word, and
Contrast, that different words have different mean-
ings (Clark, 2009). The extension of these princi-
ples to grounded language learning yields the as-
sumptions that the referents picked out by a refer-
ring expression will have some similarity (percep-
tual in our domain), and will be dissimilar com-
pared to objects not included in the reference.
Children will eventually generalize learned con-
cepts or accept synonyms in a way that violates
these principles (Baldwin, 1992), but these as-
sumptions aid in the initial acquisition of concepts.
In our system, we manifest these principles us-
ing distance metrics and thereby allow significant
flexibility in the implementation of object and at-
tribute representations while allowing a classifier
to aid in reference resolution.
When faced with unresolvable ambiguity in de-
termining the correct referent, past, ambiguous
experiences can be called upon to resolve ambi-
guity in the current situation in a strategy called
Cross-Situational Learning (XSL). There is some
debate over whether people use XSL, as it re-
quires considerable memory and computational
</bodyText>
<page confidence="0.43129">
226
</page>
<note confidence="0.996827">
Proceedings of the 19th Conference on Computational Language Learning, pages 226–236,
Beijing, China, July 30-31, 2015. c�2015 Association for Computational Linguistics
</note>
<bodyText confidence="0.998677051282051">
load (Trueswell et al., 2013). However, other ex-
periments show evidence for XSL in adults and
children in certain situations (Smith and Yu, 2008;
Smith et al., 2011). We believe these instances
that show evidence of XSL certainly merit an im-
plementation both for better understanding lan-
guage learning and for advancing grounded lan-
guage learning in the realm of robotics where such
limitations do not exist. We show that by reason-
ing over multiple ambiguous learning instances
and constraining possibilities with pragmatic in-
ferences, a system can quickly learn attributes and
names of objects without a single unambiguous
training example.
Our overarching research goal is to learn com-
positional models of grounded attributes towards
describing an object in a scene, rather than just
identifying it. That is, we do not only learn
to recognize instances of objects, but also learn
attributes constrained to feature spaces that will
be compatible with contextual modifiers such as
dark/light in terms of color, or small/large in terms
of size and object classification. Therefore, we
approach the static, visual aspects of the symbol
grounding problem with an eye towards ensur-
ing that our grounded representations of attributes
can be composed in the same way that their se-
mantic analogues can. We continue our previous
work (Perera and Allen, 2013) with two evalua-
tions to demonstrate the effectiveness of applying
the principles of Quantity, Contrast, and Conven-
tionality, as well as incorporating quantifier con-
straints, negative information, and classification
in the training step. Our first evaluation is ref-
erence resolution to determine how well the sys-
tem identifies the correct objects to attend to, and
our second is description generation to determine
how well the system uses those training examples
to understand attributes and object classes.
</bodyText>
<sectionHeader confidence="0.999443" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999982392156863">
Our algorithm for reference resolution and XSL
fits into our previous work on a situated language
learning system for grounding linguistic symbols
in perception. The integration of language in a
multi-modal task is a burgeoning area of research,
with the grounded data being any of a range of
possible situations, from objects on a table (Ma-
tuszek et al., 2012) to wetlab experiments (Naim
et al., 2014). Our end goal of using natural lan-
guage to learn from visual scenes is similar to
work by Krishnamurthy and Kollar (2013) and Yu
and Siskind (2013), and our emphasis on attributes
is related to work by Farhadi et al. (2009). How-
ever, our focus is on learning from situations that
a child would be exposed to, without using anno-
tated data, and to test implementations of child
language learning strategies in a computational
system.
We use a tutor-directed approach to training our
system where the speaker presents objects to the
system and describes them, as in work by Skocaj
et al. (2011). The focus of this work is in evaluat-
ing referring expressions as in work by Mohan et
al. (2013), although without any dialogue for dis-
ambiguation. Kollar et al. (2013) also incorporate
quantifier and pragmatic constraints on reference
resolution in a setting similar to ours. In this work,
we undertake a more detailed analysis of the ef-
fects of different pragmatic constraints on system
performance.
The task of training a classifier from “bags”
of instances with a label applying to only some
of the instances contained within is referred to
as Multiple-Instance Learning (MIL) (Dietterich,
1997), and is the machine-learning analogue of
cross-situational learning. There is a wide range
of methods used in MIL and a number of differ-
ent assumptions that can be made to fit the task at
hand (Foulds and Frank, 2010). Online MIL meth-
ods so far have been used for object tracking (Li et
al., 2010), and Dindo and Zambuto (2010) apply
MIL to grounded language learning, but we are not
aware of any research that investigates the applica-
tion of online MIL to studying cognitive models of
incremental grounded language learning. In addi-
tion, we find that we must relax many assumptions
used in MIL to handle natural language references,
such as the 1-of-N assumption used by Dindo and
Zambuto. The lack of appropriate algorithms for
handling this task motivates our development of a
novel algorithm for language learning situations.
</bodyText>
<sectionHeader confidence="0.999201" genericHeader="method">
3 Experimental Design
</sectionHeader>
<subsectionHeader confidence="0.9940205">
3.1 Learning Environment and Data
Collection
</subsectionHeader>
<bodyText confidence="0.999968333333333">
Our environment in this experiment consists of a
table with blocks of nine different shapes and two
toy cars, with the objects spanning four colors. A
person stands behind the table, places a randomly
chosen group of objects in a designated demon-
stration area on the table as shown in Figure 1,
</bodyText>
<page confidence="0.775697">
227
</page>
<figureCaption confidence="0.945265">
Figure 1: One of the training examples, described
</figureCaption>
<bodyText confidence="0.998565071428572">
as “The two red blocks [left-most two blocks in
this figure] are next to the other blocks.”
and describes one or more of the objects directly
while possibly mentioning some relation to the
surrounding objects. The goal of this setup is to
facilitate object descriptions that more closely ap-
proximate child-directed speech, compared to the
language in captioned images. Audio is recorded
and transcribed by hand with timestamps at the ut-
terance level, but there are no other annotations be-
yond timestamps. We use these intervals to match
the spoken descriptions to the video data, which
is recorded using the Microsoft Kinect to obtain
RGB + Depth information.
</bodyText>
<subsectionHeader confidence="0.999346">
3.2 Training and Test Instances
</subsectionHeader>
<bodyText confidence="0.999994647058823">
All training instances involved multiple objects,
with an average of 2.8 objects per demonstration.
The subject could select any set of objects to de-
scribe (often with respect to the other objects).
References to objects varied in detail, from “the
cube” to “a tall yellow rectangle”. Since a set
of objects might have different shapes, the most
common descriptor was “block”. The majority
(80%) of the quantifiers were definite or numeric,
and 85% of the demonstrations referred to a sin-
gle object. Test instances consisted solely of sin-
gle objects presented one at a time. 20% of the
objects used as test instances appeared in training
because of the limited set of objects available, yet
the objects were placed in slightly different ori-
entations and at different locations, deforming the
shape contour due to perspective.
</bodyText>
<subsectionHeader confidence="0.999308">
3.3 Prior System Knowledge
</subsectionHeader>
<bodyText confidence="0.99998575">
We encode some existing linguistic and percep-
tual knowledge into the system to aid in learn-
ing from unconstrained object descriptions. The
representative feature, defined as the system’s fea-
ture space assigned to a property name (e.g., color
for “white”, or shape for “round”), was precho-
sen for the task’s vocabulary to reduce the number
of factors affecting the evaluation of the system.
In previous work, we showed that the accuracy
of the system’s automatic choice of representative
features can reach 78% after about 50 demonstra-
tions of objects presented one at a time (Perera and
Allen, 2013). In addition, we developed an ex-
tension to a semantic parser that distinguishes be-
tween attributes and object names using syntactic
constructions.
</bodyText>
<subsectionHeader confidence="0.991857">
3.4 Language Processing
</subsectionHeader>
<bodyText confidence="0.999987722222222">
The transcribed utterances are passed through the
TRIPS parser (Allen et al., 2008) for simultane-
ous lexicon learning and recognition of object de-
scriptions. The parser outputs generalized quanti-
fiers and numeric constraints (capturing singular/-
plural instances, as well as specific numbers) in
referring expressions, which are used for applying
quantifier constraints to the possibilities of the ref-
erent object or group of objects. The parser’s abil-
ity to distinguish between attributes and objects
through syntax greatly increases learning perfor-
mance, as demonstrated in our previous work (Per-
era and Allen, 2013). We extract the speech act
(for detecting when an utterance is demonstrating
a new object or adding additional information to
a known object) and the referring expression from
the TRIPS semantic output. Figure 2 shows the
format of such a referring expression.
</bodyText>
<equation confidence="0.998022285714286">
(MENTIONED : ID ONT :: V11915
:TERMS
( (TERM ONT :: V11915 :CLASS (: ∗
ONT :: REFERENTIAL−SEM W:: BLOCK)
: PROPERTIES ( ( : ∗
ONT :: MODIFIER W::YELLOW) )
:QUAN ONT :: THE) ) )
</equation>
<bodyText confidence="0.958689416666667">
Figure 2: Primary referring expression extraction
from the semantic parse for ”The yellow block is
next to the others”.
Although there may be many objects or groups
of objects mentioned, we only store the properties
of the reference that is the subject of the sentence.
For example, in, “Some blue cars are next to the
yellow ones”, we will extract that there exists at
least two blue cars. Because it is an indefinite
reference, we cannot draw any further inference
about whether the reference set includes all exam-
ples of blue cars.
</bodyText>
<page confidence="0.572984">
228
</page>
<subsectionHeader confidence="0.945752">
3.5 Feature Extraction
</subsectionHeader>
<bodyText confidence="0.9999822">
To extract features, we first perform object seg-
mentation using Kinect depth information, which
provides a pixel-level contour around each of the
objects in the scene. Then for each object, we
record its dimensions and location, extract visual
features corresponding to color, shape, size, color
variance, and texture. No sophisticated track-
ing algorithm is needed as the objects are sta-
tionary on the table. Color is represented in
LAB space for perceptual similarity to humans
using Euclidean distance, shape is captured us-
ing scale- and rotation-invariant 25-dimensional
Zernike moments (Khotanzad and Hong, 1990),
and texture is captured using 13-dimensional Har-
alick features (Haralick et al., 1973).
</bodyText>
<subsectionHeader confidence="0.995533">
3.6 Classification and Distance Measures
</subsectionHeader>
<bodyText confidence="0.999992615384615">
To determine the similarity of new properties and
objects to the system’s previous knowledge of
such descriptors, we use a k-Nearest Neighbor
classifier (k-NN) with Mahalanobis distance met-
ric (Mahalanobis, 1936), distance weighting, and
class weighting using the method described in
Brown and Koplowitz (1979).
Our k-NN implementation allows negative ex-
amples so as to incorporate information that we
infer about unmentioned objects. We do not train
the system with any explicit negative information
(i.e., we have no training examples described as
“This is not a red block.”, but if the system is confi-
dent that an object is not red, it can mark a training
example as such). A negative example contributes
a weight to the voting equal and opposite to what
its weight would have been if it were a positive
example of that class.
The Mahalanobis distance provides a way to
incorporate a k-nearest neighbor classifier into a
probabilistic framework. Because the squared Ma-
halanobis distance is equal to the number of stan-
dard deviations from the mean of the data assum-
ing a normal distribution (Rencher, 2003), we can
convert the Mahalanobis distance to a probability
measure to be used in probabilistic reasoning.
</bodyText>
<sectionHeader confidence="0.939813" genericHeader="method">
4 The Reference Lattice
</sectionHeader>
<bodyText confidence="0.999232925925926">
To learn from underspecified training examples,
we must resolve the referring expression and as-
sign the properties and object name in the expres-
sion to the correct referents. To incorporate exist-
ing perceptual knowledge, semi-supervised meth-
ods, and pragmatic constraints in the reference res-
olution task, we use a probabilistic lattice structure
that we call the reference lattice.
The reference lattice consists of nodes corre-
sponding to possible partitions of the scene for
each descriptor (either property or object name).
There is one column of nodes for each descriptor,
with the object name as the final column. Edges
signify the set-intersection of the connected nodes
along a path.
Paths through the lattice correspond to a suc-
cessive application of these set-intersections, ul-
timately resulting in a set of objects correspond-
ing to the hypothesized referent group. In this
way, paths represent a series of steps in referring
expression generation where the speaker provides
salient attributes sequentially to eventually make
the referent set clear.
Figure 3: Three examples of paths in the ref-
erence lattice for the referring expression “the
white square”, when the visible objects are a grey
square, white square, and a white triangle.
</bodyText>
<subsectionHeader confidence="0.998888">
4.1 Lattice Generation
</subsectionHeader>
<bodyText confidence="0.999893909090909">
For each descriptor, we generate a node for ev-
ery possible partition of the scene into positive and
negative examples of that descriptor. For example,
if the descriptor is “red”, each node is a hypoth-
esized split that attempts to put red objects in the
positive set and non-red objects in the negative set.
For each column there are 2&apos; − 1 nodes, where n
is the number of objects in the scene (the empty
set is not included, as it would lead to an empty
reference set). We then generate lattice edges be-
tween every pair of partitions in adjacent columns.
</bodyText>
<page confidence="0.696883">
229
</page>
<bodyText confidence="0.999726333333333">
We can discard a large proportion of these edges,
as many will correspond to the intersection of dis-
joint partitions and will therefore be empty. Fi-
nally, we generate all possible paths through the
lattice, and, if using quantifier constraints, discard
any paths with a final output referent set that does
not agree with the number constraints on the men-
tioned referent group.
The structure of the lattice is shown in Figure
3. In this figure, partitions are represented by split
boxes in the first two columns, with positive exam-
ples in solid lines and negative examples in dotted
lines. Not shown are edges connecting each parti-
tion in one column with each partition in the next
and the paths they create. The intersection of the
partitions in path (a) lead to a null set, and the path
is removed from the lattice. Path (b) is the ground
truth path, as the individual partitions accurately
describe the composition of the attributes. Path
(c) contains an overspecified edge and achieves the
correct referent set albeit using incorrect assump-
tions about the attributes. The result sets from
both (b) and (c) agree with the quantifier constraint
(definite singular).
</bodyText>
<equation confidence="0.999193571428571">
Pintra = min
x,y ∈ +
�
maxx∈+,y∈− P(xc = yc) if |− |&gt; 0
Pinter =
1 if |− |= 0
Pdistance = Pintra × (1 − Pinter)
</equation>
<bodyText confidence="0.999833642857143">
The classifier probability is similar, except
rather than comparing objects to other objects in
the partition, the objects are compared to the mean
of the column’s descriptor C in the descriptor’s
representative feature. If the descriptor is a class
name, we instead choose the Zernike shape fea-
ture, implementing the shape bias children show
in word learning (Landau et al., 1998).
If there is insufficient labeled data to use, then
the classifier probability is set to 1 for the entire
column, meaning only the distance probabilities
will affect the probabilities of the nodes. For a
given descriptor C, the classifier probabilities are
as follows:
</bodyText>
<equation confidence="0.999953571428571">
Ppos(C) = min
x∈+
P(xc = yc)
P(xc = C)
Pneg(C) = rmaxx∈− P(xc = C) if |− |&gt; 0
1 if|− |= 0
Pclassifier(C) = Ppos(C) × (1 − Pneg(C))
</equation>
<subsectionHeader confidence="0.903439">
4.2 Node Probabilities
</subsectionHeader>
<bodyText confidence="0.999990857142857">
We consider two probabilities for determining the
probability of a partition: that which can be deter-
mined from distance data (considering distances
between objects in the partition), and that which
requires previous labeled data to hypothesize a
class using the classifier (considering distances
from each object to the mean of the data labeled
with the descriptor).
The distance probability, our implementation of
the principle of Contrast, is a prior that enforces
minimum intraclass distance for the positive ex-
amples and maximum interclass distance across
the partition. The motivation and implementation
shares some similarities with the Diverse Density
framework for multiple instance learning (Maron
and Lozano-P´erez, 1998), although here it also
acts as an unsupervised clustering for determining
the best reference set. It is the product of the min-
imum probability that any two objects in the pos-
itive examples are in the same set multiplied by
the complement of the maximum probability that
any two objects across the partition are in the same
class. Therefore, for partition N with positive ex-
amples + and negative examples −:
The final probability of a partition is the product
of the distance probability and the classifier prob-
ability, and the node probabilities are normalized
for each column.
</bodyText>
<subsectionHeader confidence="0.994193">
4.3 Overspecification and Edge Probabilities
</subsectionHeader>
<bodyText confidence="0.973083">
Edges have a constant transition probability equal
to the overspecification probability if overspec-
ified, or equal to the complement otherwise.
We use these probabilities to incorporate the
phenomenon of overspecification in our model,
where, contrary to a strict interpretation of Grice’s
Maxim of Quantity, speakers will give more in-
formation than is needed to identify a referent
(Koolen et al., 2011). An edge is considered over-
specified if the hypothesis for the objects that sat-
isfy the next descriptor does not add additional in-
formation, i.e., the set-intersection it corresponds
to does not remove any possible objects from the
referent set. Thus the model will prefer hypothe-
ses for the next descriptor that narrow down the
hypothesized set of referents.
230
</bodyText>
<subsectionHeader confidence="0.989852">
4.4 Path Probabilities
</subsectionHeader>
<bodyText confidence="0.99999375">
The probability of each path is the product of prob-
abilities of each of the partitions along its path and
the edge (overspecification) probabilities. If there
is a single path with a probability greater than all
others by an amount E, the labels of the parti-
tions along that path are assigned to the positive
examples while also being assigned as negative
properties for the negative examples. We perform
this updating step after each utterance to simulate
incremental continuous language learning and to
provide the most current knowledge available for
resolving new ambiguous data.
If there are multiple best paths within E of the
highest probability path, then the learning example
is considered ambiguous and saved in memory to
resolve with information from future examples.
</bodyText>
<subsectionHeader confidence="0.990634">
4.5 Multiple-Instance Learning
</subsectionHeader>
<bodyText confidence="0.99999559375">
In many cases, especially in the system’s first
learning instances, there is not enough information
to unambiguously learn from the demonstration.
Without any unambiguous examples, our system
would struggle to learn no matter how much data
was available to it. An ambiguous training exam-
ple yields more than one highest probability path.
Our goal is to use new information from each new
training demonstration to reevaluate these paths
and determine a singular best path, which allows
us to update our knowledge accordingly.
To do this, we independently consider columns
for each unknown descriptors from unresolved
demonstrations containing that descriptor and
combine them to form super-partitions which are
then evaluated using our distance probability func-
tion. For example, consider two instances de-
scribed with “the red box”. The first has a red
and a blue box, while the second has a red and
a green box. Individually they are ambiguous to
a system that does not know what “red” means
and therefore each demonstration would have two
paths with equal probability. If we combine the
partitions across the two demonstrations into four
super-partitions, the highest probability will be
generated when the two red boxes are in the pos-
itive set. This probability is stored in each of the
constituent partitions as a meta-probability, which
is otherwise 1 when multiple-instance learning
is not required to resolve ambiguity. The meta-
probability allows us to find the most probable
path given previous instances.
</bodyText>
<sectionHeader confidence="0.943431" genericHeader="method">
5 System Pipeline
</sectionHeader>
<subsectionHeader confidence="0.980745">
5.1 Training
</subsectionHeader>
<bodyText confidence="0.999937363636364">
To train the system on a video, we transcribe the
video with sentence-level timestamps, and extract
features from the demonstration video. The sys-
tem takes as input the feature data aligned with
utterances from the demonstration video. It then
finds the most likely path through the reference
lattice and adds all hypothesized positive exam-
ples for the descriptor as class examples for the
classifier. If there is more than one likely path, it
saves the lattice for later resolution using multiple-
instance learning.
</bodyText>
<subsectionHeader confidence="0.998999">
5.2 Description Generation
</subsectionHeader>
<bodyText confidence="0.99999305882353">
During testing, the system generates a description
for an object in the test set by finding examples of
properties and objects similar to it in previously
seen objects. For properties, the system checks
each feature space separately to find previous ex-
amples of objects similar in that feature space and
adds each found property label to the k-NN voting
set, weighted by the distance. If the majority la-
bel does not have the matching representative fea-
ture, the system skips this feature space for adding
a property to the description. The object name is
chosen using a distance generated from the sum
of the distances (normalized and weighted through
the Mahalanobis distance metric) to the most sim-
ilar previous examples. More details about the de-
scription generation process can be found in our
previous paper (Perera and Allen, 2013).
</bodyText>
<sectionHeader confidence="0.997035" genericHeader="method">
6 Evaluation
</sectionHeader>
<bodyText confidence="0.999971">
To evaluate our system, we use two metrics: our
evaluation method used in previous work for rat-
ing the quality of generated descriptions (Perera
and Allen, 2013), and a standard precision/recall
measurement to determine the accuracy of refer-
ence resolution.
The description generated by the system is com-
pared with a number of possible ground truth de-
scriptions which are generated using precision and
recall equivalence classes from our previous work.
Precision is calculated according to which words
in the description could be found in a ground truth
description, while recall is calculated according to
which words in the closest ground truth descrip-
tion were captured by the system’s description. As
an example, a system output of “red rectangle”
</bodyText>
<page confidence="0.739584">
231
</page>
<bodyText confidence="0.957205171428571">
Figure 4: F-Score for Description Generation in
grey and Reference Resolution in black for vari-
ous configurations of the system run on 4 under-
specificed videos. Error bars are one standard de-
viation.
when the ground truth description is “red square”
or “red cube” would have a precision score of 1
(because both “red” and “rectangle” are accurate
descriptors of the object) but a recall of .5 (because
the square-ness was not captured by the system’s
description).
In the reference resolution evaluation, precision
and recall are calculated on the training set accord-
ing to the standard measures by comparing the ref-
erent set obtained by the system and the ground
truth referent set (those objects actually referred
to by the speaker). Training instances lacking fea-
ture data because of an error in recording were ex-
cluded from the F1-score for reference resolution.
Each underspecified demonstration video con-
sisted of 15-20 demonstrations containing one or
more focal objects referenced in the description
and, in most cases, distractor objects that are not
mentioned. We used the same test video from our
previous work with objects removed that could not
be described using terms used in the training set,
leaving 15 objects.
We tested eight different system configurations.
The baseline system simply guessed at a path
through the lattice without any multiple-instance
learning (G). We then added multiple instance
learning (M), distance probabilities (D), classifier
probabilities (C), quantifier constraints (Q), and
negative information (N). We show the data for
these different methods in Figure 4.
</bodyText>
<sectionHeader confidence="0.993553" genericHeader="evaluation">
7 Results and Discussion
</sectionHeader>
<subsectionHeader confidence="0.961521">
7.1 Learning Methods
</subsectionHeader>
<bodyText confidence="0.999962962264151">
Rather than comparing our language learning sys-
tem to others on a common dataset, we choose to
focus our analysis on how our implementations of
pragmatic inference and child language learning
strategies affected performance of reference reso-
lution and description generation.
The relatively strong naming performance of G
can be attributed to the fact that many demon-
strations had similarities among the objects pre-
sented that could be learned from choosing any of
the objects. However, reference resolution perfor-
mance for G averaged a .34 F1-score compared
with a .70 F1-score for our best performing con-
figuration. Adding quantifier constraints (GQ)
did not help, although quantifier constraints with
multiple-instance learning (GMQ) led to a signifi-
cant increase in reference resolution performance.
Multiple-instance learning provided a signifi-
cant gain in reference resolution performance, and
with quantifier constraints also yielded the highest
naming performance (QDM and QDML). The rel-
ative lower performance by inclusion of classifier
probabilities with this limited training data is due
to errors in classification that compound in this
online-learning framework. In multiple-instance
cases where there are a number of previous exam-
ples to draw from, then the information provided
by classifier probability is redundant and less ac-
curate. However, as the approach scales and re-
taining previous instances is intractable, the classi-
fier probabilities provide a more concise represen-
tation of knowledge to be used in future learning.
We found that negative information hurt perfor-
mance in this framework (QDMCN vs. QDMC)
for two reasons. First, the risk of introducing neg-
ative information is high compared to its possible
reward. While it promises to remove some errors
in classification, an accurate piece of negative in-
formation only removes one class from consider-
ation when multiple other alternatives exist, while
an inaccurate piece of negative information con-
tributes to erroneous classification.
Second, situations where negative information
might be inferred are induced by a natural lan-
guage description which, by Grice’s Maxims, will
attempt to be as clear as possible given the lis-
tener’s information. This means that, adhering
to the Contrast principle, negative examples are
likely already far from the positive examples for
the class.
Figure 5 shows results from the averaging of
random combinations of 4 underspecified videos,
using our highest-scoring configuration QDM to
</bodyText>
<page confidence="0.393058">
232
</page>
<figureCaption confidence="0.91268">
Figure 5: Description generation results from
</figureCaption>
<bodyText confidence="0.999125636363636">
training according to the number of training videos
with standard error bars. The solid line is the
QDM’s performance learning from underspecified
videos. The dashed line is the system’s perfor-
mance learning from videos where objects are pre-
sented one at a time. The dotted line is the baseline
(G). F1-score for reference resolution in the under-
specified case was consistent across videos (mean
.7, SD .01).
show the increase in performance as more training
data is provided to the system. We compare our re-
sults on videos with multiple objects to the perfor-
mance of the system with objects presented one at
a time and with the baseline G. Because the train-
ing objects are slightly different, we present results
on a subset of objects where at least a ground truth
object name was present in the training data. Our
results show that while the performance is lower in
the ambiguous case, the general learning rate per
video is comparable with the single-object case. In
the 1-video case, guessing is equally as effective as
our method due to the system being too tentative
with assigning labels to objects without more in-
formation to minimize errors affecting learning in
later demonstrations.
We did see an effect of the order in which videos
were presented to the system on performance, sug-
gesting that learning the correct concepts early
on can have long-term ramifications for an online
learning process. Possible ways to mitigate this
effect include a memory model with forgetting or
a more robust classifier. We leave such efforts to
future work.
</bodyText>
<subsectionHeader confidence="0.999731">
7.2 Running Time Performance
</subsectionHeader>
<bodyText confidence="0.9998881">
While the number of nodes and paths in the lat-
tice is exponential in the number of objects in the
scene, our system can still perform quickly enough
to serve as a language learning agent suitable for
real-time interaction. The pragmatic constraints
on possible referent sets allow us to remove a large
number of paths, which is especially important
when there are many objects in the scene or when
the referring expression contains a number of de-
scriptors. In situations with more than 4-5 objects,
we expect that other cues can establish joint atten-
tion with enough resolution to remove some ob-
jects from consideration.
Visual features can be extracted from video at
3 frames per second, which is acceptable for real-
time interaction as only 5 frames are needed for
training or testing. Not including the feature ex-
traction (performed separately), the QUM config-
uration processed our 55 demonstrations in about
1 minute on a 2.3 GHz Intel Core i7.
</bodyText>
<subsectionHeader confidence="0.98897">
7.3 Relation Between Evaluation Metrics
</subsectionHeader>
<bodyText confidence="0.999997173913044">
We compared our results from the description gen-
eration metric with the reference resolution metric
to evaluate how the quality of reference resolution
affected learning performance. The description
generation F-score was more strongly positively
correlated with the reference resolution precision
than with the recall. We found a reference resolu-
tion F-score with Q = .7 (as opposed to the stan-
dard Q = 1) had the highest Pearson correlation
with the F-score (r = .63,p &lt; .0001), indicat-
ing that reference resolution precision is roughly
1.4 times more important than recall in predicting
learning performance in this system.
This result provides evidence that the quality
of the first data in a limited data learning algo-
rithm can be critical in establishing long-term per-
formance, especially in an online learning system,
and suggests that our results could be improved
by correcting hypotheses that once appeared rea-
sonable to the system. It also suggests that F1-
score may not be the most appropriate measure for
performance of a component that is relied upon to
give accurate data for further learning.
</bodyText>
<subsectionHeader confidence="0.946674">
7.4 Overspecification
</subsectionHeader>
<bodyText confidence="0.9999072">
Accounting for overspecification in the model
more closely approximates human speech at the
expense of a strict interpretation of the Maxim of
Quantity. It allows us to use graded pragmatic con-
straints that admit helpful heuristics for learning
without treating them as a rule. In our training
data, the speaker was typically over-descriptive,
leading to a high optimal overspecification. Figure
6 shows the effect of different values for the over-
specification probability on the performance of the
</bodyText>
<page confidence="0.808623">
233
</page>
<figureCaption confidence="0.856933">
Figure 6: Effect of varying overspecification prob-
</figureCaption>
<bodyText confidence="0.971331785714286">
ability on the F1 score for both Description Gen-
eration (black dashed) and Reference Resolution
(grey solid), calculated on a dataset with hand lo-
cation information.
system. The strong dip in reference resolution per-
formance at an overspecification probability of 0
shows the significant negative effect a strict inter-
pretation of the Maxim of Quantity would have in
this situation. The correct value for overspecifica-
tion probability for a given situation depends on
a number of factors such as scene complexity and
descriptor type (Koolen et al., 2011), but we have
not yet incorporated these factors into our over-
specification probability in this work.
</bodyText>
<subsectionHeader confidence="0.996662">
7.5 Comparison to Other Multi-Instance
Learning Methods
</subsectionHeader>
<bodyText confidence="0.999984529411765">
Our multi-instance learning procedure can be clas-
sified as instance-level with witnesses, which
means that we identify the positive examples that
lead to the label of the “bag”, or demonstration in
this case. In addition, we relax the assumption that
there is only a single positive instance correspond-
ing to the label of the demonstration. This relax-
ation increases the complexity of cross-instance
relationships, but allows for references to multiple
objects simultaneously and therefore faster train-
ing than a sequential presentation would allow. In
accounting for overspecification, we also must es-
tablish a dependence on the labels of the image
via the edges of the lattice. This adds additional
complexity, but our results show that accounting
for overspecification can lead to increased perfor-
mance.
</bodyText>
<sectionHeader confidence="0.997469" genericHeader="discussions">
8 Future Work
</sectionHeader>
<bodyText confidence="0.999762772727273">
Work on this system is ongoing, with extensions
planned for improving performance, generating
more complete symbol grounding, and allowing
more flexibility in both environment and language.
While the parser in our system can interpret
phrases such as “the tall block”, we do not have
a way of resolving the non-intersective predicate
“tall” in our current framework. Non-intersective
predicates add complexity to the system because
their reference point is not necessarily the other
objects in the scene - it may be a reference to other
objects in the same class (i.e., blocks).
Also, our set of features is rather rudimen-
tary and could be improved, as we chose low-
dimensional, continuous features in an attempt to
facilitate a close connection between language and
vision. The use of continuous features ensures
that primitive concepts are grounded solely in per-
ception and not higher-order conceptual models
(Perera and Allen, 2014). Initial results using 3D
shape features show a considerable performance
increase on a kitchen dataset we are developing.
</bodyText>
<sectionHeader confidence="0.989599" genericHeader="conclusions">
9 Conclusion
</sectionHeader>
<bodyText confidence="0.99999">
We have proposed a probabilistic framework for
using pragmatic inference to learn from under-
specified visual descriptions. We show that this
system can use pragmatic assumptions attenuated
by overspecification probability to learn attributes
and object names from videos that include a num-
ber of distractors. We also analyzed various learn-
ing methods in an attempt to gain a deeper under-
standing of the theoretical and practical consider-
ations of situated language learning, finding that
Conventionality and Contrast learning strategies
with quantifiers and overspecification probabilities
yielded the best performing system. These results
support the idea that an understanding of how hu-
mans learn and communicate can lead to better vi-
sually grounded language learning systems. We
believe this work is an important step towards sys-
tems in which natural language not only stands in
for manual annotation, but also enables new meth-
ods of training robots and other situated systems.
</bodyText>
<sectionHeader confidence="0.991625" genericHeader="acknowledgments">
10 Acknowledgements
</sectionHeader>
<bodyText confidence="0.98667925">
This work was funded by The Office of Naval
Research (N000141210547), the Nuance Founda-
tion, and DARPA Big Mechanism program under
ARO contract W911NF-14-1-0391.
</bodyText>
<page confidence="0.829955">
234
</page>
<sectionHeader confidence="0.99275" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.995123311926606">
J. Allen, Mary Swift, and Will de Beaumont. 2008.
Deep Semantic Analysis of Text. In Symp. Semant.
Syst. Text Process., volume 2008, pages 343–354,
Morristown, NJ, USA. Association for Computa-
tional Linguistics.
D A Baldwin. 1992. Clarifying the role of shape in
children’s taxonomic assumption. J. Exp. Child Psy-
chol., 54(3):392–416.
T Brown and J Koplowitz. 1979. The Weighted
Nearest Neighbor Rule for Class Dependent Sample
Sizes. IEEE Trans. Inf. Theory, I(5):617–619.
Eve V. Clark. 2009. On the pragmatics of contrast. J.
Child Lang., 17(02):417, February.
T Dietterich. 1997. Solving the multiple instance
problem with axis-parallel rectangles. Artif. Intell.,
89:31–71.
Haris Dindo and Daniele Zambuto. 2010. A prob-
abilistic approach to learning a visually grounded
language model through human-robot interaction.
IEEE✓RSJ 2010 Int. Conf. Intell. Robot. Syst. IROS
2010 - Conf. Proc., pages 790–796.
A. Farhadi, I. Endres, D. Hoiem, and D. Forsyth. 2009.
Describing objects by their attributes. 2009 IEEE
Conf. Comput. Vis. Pattern Recognit., pages 1778–
1785, June.
James Foulds and Eibe Frank. 2010. A review of
multi-instance learning assumptions. Knowl. Eng.
Rev., 25:1.
HP Grice. 1975. Logic and conversation. In Peter
Cole and Jerry L. Morgan, editors, Syntax Semant.,
pages 41–58. Academic Press.
Robert M. Haralick, K. Shanmugam, and Its’hak Din-
stein. 1973. Textural features for image classifica-
tion. IEEE Trans. Syst. Man, Cybern. SMC-3.
A Khotanzad and Y H Hong. 1990. Invariant Image
Recognition by Zernike Moments. IEEE Trans. Pat-
tern Anal. Mach. Intell., 12(5):489–497, May.
Thomas Kollar, Jayant Krishnamurthy, and Grant
Strimel. 2013. Toward interactive grounded lan-
guage acquisition. Proc. Robot. Sci. Syst.
Ruud Koolen, Albert Gatt, Martijn Goudbeek, and
Emiel Krahmer. 2011. Factors causing over-
specification in definite descriptions. J. Pragmat.,
43(13):3231–3250, October.
Jayant Krishnamurthy and Thomas Kollar. 2013.
Jointly Learning to Parse and Perceive: Connecting
Natural Language to the Physical World. Trans. As-
soc. Comput. Linguist., 1:193–206.
Barbara Landau, Linda Smith, and Susan Jones. 1998.
Object Shape, Object Function, and Object Name.
J. Mem. Lang., 38(1):1–27, January.
Mu Li, James T. Kwok, and Bao Liang Lu. 2010.
Online multiple instance learning with no regret.
Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern
Recognit., pages 1395–1401.
PC C Mahalanobis. 1936. On The Generalized Dis-
tance in Statistics. Proc. Natl. Inst. Sci. India, pages
49–55.
Oded Maron and Tom´as Lozano-P´erez. 1998. A
framework for multiple-instance learning. Adv. Neu-
ral Inf. Process. Syst., 10:570 – 576.
Cynthia Matuszek, N FitzGerald, Luke Zettlemoyer,
Liefeng Bo, and Dieter Fox. 2012. A Joint Model
of Language and Perception for Grounded Attribute
Learning. In Proc. Int. Conf. Mach. Learn.
Shiwali Mohan, John E Laird, and Laird Umich Edu.
2013. Towards an Indexical Model of Situated
Language Comprehension for Real-World Cognitive
Agents. 2013:153–170.
Iftekhar Naim, Young Chol Song, Qiguang Liu, Henry
Kautz, Jiebo Luo, and Daniel Gildea. 2014. Un-
supervised Alignment of Natural Language Instruc-
tions with Video Segments. In AAAI.
Ian Perera and JF Allen. 2013. SALL-E: Situated
Agent for Language Learning. In Twenty-Seventh
AAAI Conf. Artif. Intell.
Ian Perera and James F Allen. 2014. What is the
Ground ? Continuous Maps for Grounding Percep-
tual Primitives. In P Bello, M. Guarini, M Mc-
Shane, and Brian Scassellati, editors, Proc. 36th
Annu. Conf. Cogn. Sci. Soc., Austin, TX. Cognitive
Science Society.
A C Rencher. 2003. Methods of Multivariate Analysis.
Wiley Series in Probability and Statistics. Wiley.
Danijel Skocaj, Matej Kristan, Alen Vrecko, Marko
Mahnic, Miroslav Janicek, Geert-Jan M. Krui-
jff, Marc Hanheide, Nick Hawes, Thomas Keller,
Michael Zillich, and Kai Zhou. 2011. A system
for interactive learning in dialogue with a tutor. In
2011 IEEE✓RSJ Int. Conf. Intell. Robot. Syst., pages
3387–3394. IEEE, September.
Linda Smith and Chen Yu. 2008. Infants rapidly learn
word-referent mappings via cross-situational statis-
tics. Cognition, 106:1558–1568.
Kenny Smith, Andrew D M Smith, and Richard a.
Blythe. 2011. Cross-situational learning: An exper-
imental study of word-learning mechanisms. Cogn.
Sci., 35:480–498.
John C Trueswell, Tamara Nicol Medina, Alon Hafri,
and Lila R Gleitman. 2013. Propose but verify:
fast mapping meets cross-situational word learning.
Cogn. Psychol., 66(1):126–56, February.
W Van Orman Quine. 1964. Word and Object. MIT
Press paperback series. MIT Press.
235
Haonan Yu and Jeffrey Mark Siskind. 2013. Grounded
Language Learning from Video Described with Sen-
tences. In Proc. 51st Annu. Meet. Assoc. Comput.
Linguist., pages 53–63.
</reference>
<page confidence="0.935532">
236
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.691676">
<title confidence="0.9878815">Quantity, Contrast, and Convention in Cross-Situated Comprehension</title>
<author confidence="0.951693">F Perera</author>
<affiliation confidence="0.881373">University of Rochester, Department of Computer Science, Rochester, NY 14627</affiliation>
<address confidence="0.720851">Institute for Human and Machine Cognition, Pensacola, FL 32502</address>
<abstract confidence="0.99922725">Typically, visually-grounded language learning systems only accept feature data about objects in the environment that are explicitly mentioned, whether through annotation labels or direct reference through natural language. We show that when objects are described ambiguously using natural language, a system can use a combination of the pragmatic principles of Contrast and Conventionality, and multiple-instance learning to learn from ambiguous examples in an online fashion. Applying child language learning strategies to visual learning enables more effective learning in real-time environments, which can lead to enhanced teaching interactions with robots or grounded systems in multi-object environments.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Allen</author>
<author>Mary Swift</author>
<author>Will de Beaumont</author>
</authors>
<title>Deep Semantic Analysis of Text.</title>
<date>2008</date>
<booktitle>In Symp. Semant. Syst. Text Process.,</booktitle>
<volume>volume</volume>
<pages>343--354</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<marker>Allen, Swift, de Beaumont, 2008</marker>
<rawString>J. Allen, Mary Swift, and Will de Beaumont. 2008. Deep Semantic Analysis of Text. In Symp. Semant. Syst. Text Process., volume 2008, pages 343–354, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D A Baldwin</author>
</authors>
<title>Clarifying the role of shape in children’s taxonomic assumption.</title>
<date>1992</date>
<journal>J. Exp. Child Psychol.,</journal>
<volume>54</volume>
<issue>3</issue>
<contexts>
<context position="3231" citStr="Baldwin, 1992" startWordPosition="484" endWordPosition="485">ity. Language learners additionally make use of the pragmatic assumptions of Conventionality, that speakers agree upon the meaning of a word, and Contrast, that different words have different meanings (Clark, 2009). The extension of these principles to grounded language learning yields the assumptions that the referents picked out by a referring expression will have some similarity (perceptual in our domain), and will be dissimilar compared to objects not included in the reference. Children will eventually generalize learned concepts or accept synonyms in a way that violates these principles (Baldwin, 1992), but these assumptions aid in the initial acquisition of concepts. In our system, we manifest these principles using distance metrics and thereby allow significant flexibility in the implementation of object and attribute representations while allowing a classifier to aid in reference resolution. When faced with unresolvable ambiguity in determining the correct referent, past, ambiguous experiences can be called upon to resolve ambiguity in the current situation in a strategy called Cross-Situational Learning (XSL). There is some debate over whether people use XSL, as it requires considerable</context>
</contexts>
<marker>Baldwin, 1992</marker>
<rawString>D A Baldwin. 1992. Clarifying the role of shape in children’s taxonomic assumption. J. Exp. Child Psychol., 54(3):392–416.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Brown</author>
<author>J Koplowitz</author>
</authors>
<title>The Weighted Nearest Neighbor Rule for Class Dependent Sample Sizes.</title>
<date>1979</date>
<journal>IEEE Trans. Inf. Theory,</journal>
<pages>5--617</pages>
<contexts>
<context position="13739" citStr="Brown and Koplowitz (1979)" startWordPosition="2167" endWordPosition="2170">n LAB space for perceptual similarity to humans using Euclidean distance, shape is captured using scale- and rotation-invariant 25-dimensional Zernike moments (Khotanzad and Hong, 1990), and texture is captured using 13-dimensional Haralick features (Haralick et al., 1973). 3.6 Classification and Distance Measures To determine the similarity of new properties and objects to the system’s previous knowledge of such descriptors, we use a k-Nearest Neighbor classifier (k-NN) with Mahalanobis distance metric (Mahalanobis, 1936), distance weighting, and class weighting using the method described in Brown and Koplowitz (1979). Our k-NN implementation allows negative examples so as to incorporate information that we infer about unmentioned objects. We do not train the system with any explicit negative information (i.e., we have no training examples described as “This is not a red block.”, but if the system is confident that an object is not red, it can mark a training example as such). A negative example contributes a weight to the voting equal and opposite to what its weight would have been if it were a positive example of that class. The Mahalanobis distance provides a way to incorporate a k-nearest neighbor clas</context>
</contexts>
<marker>Brown, Koplowitz, 1979</marker>
<rawString>T Brown and J Koplowitz. 1979. The Weighted Nearest Neighbor Rule for Class Dependent Sample Sizes. IEEE Trans. Inf. Theory, I(5):617–619.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eve V Clark</author>
</authors>
<title>On the pragmatics of contrast.</title>
<date>2009</date>
<journal>J. Child Lang.,</journal>
<volume>17</volume>
<issue>02</issue>
<contexts>
<context position="2831" citStr="Clark, 2009" startWordPosition="419" endWordPosition="420">ns and adjust their speech in accordance to Grice’s Maxim of Quantity when referring to objects : be only as informative as necessary (Grice, 1975). We therefore treat the language describing a particular object in a scene as an expression of an iterative process, where the speaker is attempting to guide the listener towards the referent in a way that avoids both ambiguity and unnecessary verbosity. Language learners additionally make use of the pragmatic assumptions of Conventionality, that speakers agree upon the meaning of a word, and Contrast, that different words have different meanings (Clark, 2009). The extension of these principles to grounded language learning yields the assumptions that the referents picked out by a referring expression will have some similarity (perceptual in our domain), and will be dissimilar compared to objects not included in the reference. Children will eventually generalize learned concepts or accept synonyms in a way that violates these principles (Baldwin, 1992), but these assumptions aid in the initial acquisition of concepts. In our system, we manifest these principles using distance metrics and thereby allow significant flexibility in the implementation o</context>
</contexts>
<marker>Clark, 2009</marker>
<rawString>Eve V. Clark. 2009. On the pragmatics of contrast. J. Child Lang., 17(02):417, February.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Dietterich</author>
</authors>
<title>Solving the multiple instance problem with axis-parallel rectangles.</title>
<date>1997</date>
<journal>Artif. Intell.,</journal>
<pages>89--31</pages>
<contexts>
<context position="7499" citStr="Dietterich, 1997" startWordPosition="1161" endWordPosition="1162">caj et al. (2011). The focus of this work is in evaluating referring expressions as in work by Mohan et al. (2013), although without any dialogue for disambiguation. Kollar et al. (2013) also incorporate quantifier and pragmatic constraints on reference resolution in a setting similar to ours. In this work, we undertake a more detailed analysis of the effects of different pragmatic constraints on system performance. The task of training a classifier from “bags” of instances with a label applying to only some of the instances contained within is referred to as Multiple-Instance Learning (MIL) (Dietterich, 1997), and is the machine-learning analogue of cross-situational learning. There is a wide range of methods used in MIL and a number of different assumptions that can be made to fit the task at hand (Foulds and Frank, 2010). Online MIL methods so far have been used for object tracking (Li et al., 2010), and Dindo and Zambuto (2010) apply MIL to grounded language learning, but we are not aware of any research that investigates the application of online MIL to studying cognitive models of incremental grounded language learning. In addition, we find that we must relax many assumptions used in MIL to h</context>
</contexts>
<marker>Dietterich, 1997</marker>
<rawString>T Dietterich. 1997. Solving the multiple instance problem with axis-parallel rectangles. Artif. Intell., 89:31–71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Haris Dindo</author>
<author>Daniele Zambuto</author>
</authors>
<title>A probabilistic approach to learning a visually grounded language model through human-robot interaction.</title>
<date>2010</date>
<booktitle>IEEE✓RSJ 2010 Int. Conf. Intell. Robot. Syst. IROS 2010 - Conf. Proc.,</booktitle>
<pages>790--796</pages>
<contexts>
<context position="7827" citStr="Dindo and Zambuto (2010)" startWordPosition="1219" endWordPosition="1222"> a more detailed analysis of the effects of different pragmatic constraints on system performance. The task of training a classifier from “bags” of instances with a label applying to only some of the instances contained within is referred to as Multiple-Instance Learning (MIL) (Dietterich, 1997), and is the machine-learning analogue of cross-situational learning. There is a wide range of methods used in MIL and a number of different assumptions that can be made to fit the task at hand (Foulds and Frank, 2010). Online MIL methods so far have been used for object tracking (Li et al., 2010), and Dindo and Zambuto (2010) apply MIL to grounded language learning, but we are not aware of any research that investigates the application of online MIL to studying cognitive models of incremental grounded language learning. In addition, we find that we must relax many assumptions used in MIL to handle natural language references, such as the 1-of-N assumption used by Dindo and Zambuto. The lack of appropriate algorithms for handling this task motivates our development of a novel algorithm for language learning situations. 3 Experimental Design 3.1 Learning Environment and Data Collection Our environment in this experi</context>
</contexts>
<marker>Dindo, Zambuto, 2010</marker>
<rawString>Haris Dindo and Daniele Zambuto. 2010. A probabilistic approach to learning a visually grounded language model through human-robot interaction. IEEE✓RSJ 2010 Int. Conf. Intell. Robot. Syst. IROS 2010 - Conf. Proc., pages 790–796.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Farhadi</author>
<author>I Endres</author>
<author>D Hoiem</author>
<author>D Forsyth</author>
</authors>
<title>Describing objects by their attributes.</title>
<date>2009</date>
<journal>IEEE Conf. Comput. Vis. Pattern Recognit.,</journal>
<pages>1778--1785</pages>
<contexts>
<context position="6531" citStr="Farhadi et al. (2009)" startWordPosition="1001" endWordPosition="1004">gorithm for reference resolution and XSL fits into our previous work on a situated language learning system for grounding linguistic symbols in perception. The integration of language in a multi-modal task is a burgeoning area of research, with the grounded data being any of a range of possible situations, from objects on a table (Matuszek et al., 2012) to wetlab experiments (Naim et al., 2014). Our end goal of using natural language to learn from visual scenes is similar to work by Krishnamurthy and Kollar (2013) and Yu and Siskind (2013), and our emphasis on attributes is related to work by Farhadi et al. (2009). However, our focus is on learning from situations that a child would be exposed to, without using annotated data, and to test implementations of child language learning strategies in a computational system. We use a tutor-directed approach to training our system where the speaker presents objects to the system and describes them, as in work by Skocaj et al. (2011). The focus of this work is in evaluating referring expressions as in work by Mohan et al. (2013), although without any dialogue for disambiguation. Kollar et al. (2013) also incorporate quantifier and pragmatic constraints on refer</context>
</contexts>
<marker>Farhadi, Endres, Hoiem, Forsyth, 2009</marker>
<rawString>A. Farhadi, I. Endres, D. Hoiem, and D. Forsyth. 2009. Describing objects by their attributes. 2009 IEEE Conf. Comput. Vis. Pattern Recognit., pages 1778– 1785, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Foulds</author>
<author>Eibe Frank</author>
</authors>
<title>A review of multi-instance learning assumptions.</title>
<date>2010</date>
<journal>Knowl. Eng. Rev.,</journal>
<pages>25--1</pages>
<contexts>
<context position="7717" citStr="Foulds and Frank, 2010" startWordPosition="1198" endWordPosition="1201">er and pragmatic constraints on reference resolution in a setting similar to ours. In this work, we undertake a more detailed analysis of the effects of different pragmatic constraints on system performance. The task of training a classifier from “bags” of instances with a label applying to only some of the instances contained within is referred to as Multiple-Instance Learning (MIL) (Dietterich, 1997), and is the machine-learning analogue of cross-situational learning. There is a wide range of methods used in MIL and a number of different assumptions that can be made to fit the task at hand (Foulds and Frank, 2010). Online MIL methods so far have been used for object tracking (Li et al., 2010), and Dindo and Zambuto (2010) apply MIL to grounded language learning, but we are not aware of any research that investigates the application of online MIL to studying cognitive models of incremental grounded language learning. In addition, we find that we must relax many assumptions used in MIL to handle natural language references, such as the 1-of-N assumption used by Dindo and Zambuto. The lack of appropriate algorithms for handling this task motivates our development of a novel algorithm for language learning</context>
</contexts>
<marker>Foulds, Frank, 2010</marker>
<rawString>James Foulds and Eibe Frank. 2010. A review of multi-instance learning assumptions. Knowl. Eng. Rev., 25:1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>HP Grice</author>
</authors>
<title>Logic and conversation.</title>
<date>1975</date>
<booktitle>Syntax Semant.,</booktitle>
<pages>41--58</pages>
<editor>In Peter Cole and Jerry L. Morgan, editors,</editor>
<publisher>Academic Press.</publisher>
<contexts>
<context position="2366" citStr="Grice, 1975" startWordPosition="345" endWordPosition="346">language learning strategies to narrow down the search space of possible referents, as illustrated by Quine’s “gavagai” problem (1964). Trying to learn attributes and objects without non-linguistic cues such as pointing and gaze might seem an insurmountable challenge. Yet a child experiences many such situations and can nevertheless learn grounded concepts over time. Fortunately, adult speakers tend to understand the limitation of these cues in certain situations and adjust their speech in accordance to Grice’s Maxim of Quantity when referring to objects : be only as informative as necessary (Grice, 1975). We therefore treat the language describing a particular object in a scene as an expression of an iterative process, where the speaker is attempting to guide the listener towards the referent in a way that avoids both ambiguity and unnecessary verbosity. Language learners additionally make use of the pragmatic assumptions of Conventionality, that speakers agree upon the meaning of a word, and Contrast, that different words have different meanings (Clark, 2009). The extension of these principles to grounded language learning yields the assumptions that the referents picked out by a referring e</context>
</contexts>
<marker>Grice, 1975</marker>
<rawString>HP Grice. 1975. Logic and conversation. In Peter Cole and Jerry L. Morgan, editors, Syntax Semant., pages 41–58. Academic Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert M Haralick</author>
<author>K Shanmugam</author>
<author>Its’hak Dinstein</author>
</authors>
<title>Textural features for image classification.</title>
<date>1973</date>
<journal>IEEE Trans. Syst. Man, Cybern. SMC-3.</journal>
<contexts>
<context position="13386" citStr="Haralick et al., 1973" startWordPosition="2117" endWordPosition="2120">mation, which provides a pixel-level contour around each of the objects in the scene. Then for each object, we record its dimensions and location, extract visual features corresponding to color, shape, size, color variance, and texture. No sophisticated tracking algorithm is needed as the objects are stationary on the table. Color is represented in LAB space for perceptual similarity to humans using Euclidean distance, shape is captured using scale- and rotation-invariant 25-dimensional Zernike moments (Khotanzad and Hong, 1990), and texture is captured using 13-dimensional Haralick features (Haralick et al., 1973). 3.6 Classification and Distance Measures To determine the similarity of new properties and objects to the system’s previous knowledge of such descriptors, we use a k-Nearest Neighbor classifier (k-NN) with Mahalanobis distance metric (Mahalanobis, 1936), distance weighting, and class weighting using the method described in Brown and Koplowitz (1979). Our k-NN implementation allows negative examples so as to incorporate information that we infer about unmentioned objects. We do not train the system with any explicit negative information (i.e., we have no training examples described as “This i</context>
</contexts>
<marker>Haralick, Shanmugam, Dinstein, 1973</marker>
<rawString>Robert M. Haralick, K. Shanmugam, and Its’hak Dinstein. 1973. Textural features for image classification. IEEE Trans. Syst. Man, Cybern. SMC-3.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Khotanzad</author>
<author>Y H Hong</author>
</authors>
<title>Invariant Image Recognition by Zernike Moments.</title>
<date>1990</date>
<journal>IEEE Trans. Pattern Anal. Mach. Intell.,</journal>
<volume>12</volume>
<issue>5</issue>
<contexts>
<context position="13298" citStr="Khotanzad and Hong, 1990" startWordPosition="2104" endWordPosition="2107">traction To extract features, we first perform object segmentation using Kinect depth information, which provides a pixel-level contour around each of the objects in the scene. Then for each object, we record its dimensions and location, extract visual features corresponding to color, shape, size, color variance, and texture. No sophisticated tracking algorithm is needed as the objects are stationary on the table. Color is represented in LAB space for perceptual similarity to humans using Euclidean distance, shape is captured using scale- and rotation-invariant 25-dimensional Zernike moments (Khotanzad and Hong, 1990), and texture is captured using 13-dimensional Haralick features (Haralick et al., 1973). 3.6 Classification and Distance Measures To determine the similarity of new properties and objects to the system’s previous knowledge of such descriptors, we use a k-Nearest Neighbor classifier (k-NN) with Mahalanobis distance metric (Mahalanobis, 1936), distance weighting, and class weighting using the method described in Brown and Koplowitz (1979). Our k-NN implementation allows negative examples so as to incorporate information that we infer about unmentioned objects. We do not train the system with an</context>
</contexts>
<marker>Khotanzad, Hong, 1990</marker>
<rawString>A Khotanzad and Y H Hong. 1990. Invariant Image Recognition by Zernike Moments. IEEE Trans. Pattern Anal. Mach. Intell., 12(5):489–497, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Kollar</author>
<author>Jayant Krishnamurthy</author>
<author>Grant Strimel</author>
</authors>
<title>Toward interactive grounded language acquisition.</title>
<date>2013</date>
<booktitle>Proc. Robot. Sci. Syst.</booktitle>
<contexts>
<context position="7068" citStr="Kollar et al. (2013)" startWordPosition="1093" endWordPosition="1096"> (2013), and our emphasis on attributes is related to work by Farhadi et al. (2009). However, our focus is on learning from situations that a child would be exposed to, without using annotated data, and to test implementations of child language learning strategies in a computational system. We use a tutor-directed approach to training our system where the speaker presents objects to the system and describes them, as in work by Skocaj et al. (2011). The focus of this work is in evaluating referring expressions as in work by Mohan et al. (2013), although without any dialogue for disambiguation. Kollar et al. (2013) also incorporate quantifier and pragmatic constraints on reference resolution in a setting similar to ours. In this work, we undertake a more detailed analysis of the effects of different pragmatic constraints on system performance. The task of training a classifier from “bags” of instances with a label applying to only some of the instances contained within is referred to as Multiple-Instance Learning (MIL) (Dietterich, 1997), and is the machine-learning analogue of cross-situational learning. There is a wide range of methods used in MIL and a number of different assumptions that can be made</context>
</contexts>
<marker>Kollar, Krishnamurthy, Strimel, 2013</marker>
<rawString>Thomas Kollar, Jayant Krishnamurthy, and Grant Strimel. 2013. Toward interactive grounded language acquisition. Proc. Robot. Sci. Syst.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ruud Koolen</author>
<author>Albert Gatt</author>
<author>Martijn Goudbeek</author>
<author>Emiel Krahmer</author>
</authors>
<title>Factors causing overspecification in definite descriptions.</title>
<date>2011</date>
<journal>J. Pragmat.,</journal>
<volume>43</volume>
<issue>13</issue>
<contexts>
<context position="20340" citStr="Koolen et al., 2011" startWordPosition="3257" endWordPosition="3260">The final probability of a partition is the product of the distance probability and the classifier probability, and the node probabilities are normalized for each column. 4.3 Overspecification and Edge Probabilities Edges have a constant transition probability equal to the overspecification probability if overspecified, or equal to the complement otherwise. We use these probabilities to incorporate the phenomenon of overspecification in our model, where, contrary to a strict interpretation of Grice’s Maxim of Quantity, speakers will give more information than is needed to identify a referent (Koolen et al., 2011). An edge is considered overspecified if the hypothesis for the objects that satisfy the next descriptor does not add additional information, i.e., the set-intersection it corresponds to does not remove any possible objects from the referent set. Thus the model will prefer hypotheses for the next descriptor that narrow down the hypothesized set of referents. 230 4.4 Path Probabilities The probability of each path is the product of probabilities of each of the partitions along its path and the edge (overspecification) probabilities. If there is a single path with a probability greater than all </context>
<context position="34245" citStr="Koolen et al., 2011" startWordPosition="5465" endWordPosition="5468">ance of the 233 Figure 6: Effect of varying overspecification probability on the F1 score for both Description Generation (black dashed) and Reference Resolution (grey solid), calculated on a dataset with hand location information. system. The strong dip in reference resolution performance at an overspecification probability of 0 shows the significant negative effect a strict interpretation of the Maxim of Quantity would have in this situation. The correct value for overspecification probability for a given situation depends on a number of factors such as scene complexity and descriptor type (Koolen et al., 2011), but we have not yet incorporated these factors into our overspecification probability in this work. 7.5 Comparison to Other Multi-Instance Learning Methods Our multi-instance learning procedure can be classified as instance-level with witnesses, which means that we identify the positive examples that lead to the label of the “bag”, or demonstration in this case. In addition, we relax the assumption that there is only a single positive instance corresponding to the label of the demonstration. This relaxation increases the complexity of cross-instance relationships, but allows for references t</context>
</contexts>
<marker>Koolen, Gatt, Goudbeek, Krahmer, 2011</marker>
<rawString>Ruud Koolen, Albert Gatt, Martijn Goudbeek, and Emiel Krahmer. 2011. Factors causing overspecification in definite descriptions. J. Pragmat., 43(13):3231–3250, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jayant Krishnamurthy</author>
<author>Thomas Kollar</author>
</authors>
<title>Jointly Learning to Parse and Perceive: Connecting Natural Language to the Physical World.</title>
<date>2013</date>
<journal>Trans. Assoc. Comput. Linguist.,</journal>
<pages>1--193</pages>
<contexts>
<context position="6429" citStr="Krishnamurthy and Kollar (2013)" startWordPosition="982" endWordPosition="985"> well the system uses those training examples to understand attributes and object classes. 2 Related Work Our algorithm for reference resolution and XSL fits into our previous work on a situated language learning system for grounding linguistic symbols in perception. The integration of language in a multi-modal task is a burgeoning area of research, with the grounded data being any of a range of possible situations, from objects on a table (Matuszek et al., 2012) to wetlab experiments (Naim et al., 2014). Our end goal of using natural language to learn from visual scenes is similar to work by Krishnamurthy and Kollar (2013) and Yu and Siskind (2013), and our emphasis on attributes is related to work by Farhadi et al. (2009). However, our focus is on learning from situations that a child would be exposed to, without using annotated data, and to test implementations of child language learning strategies in a computational system. We use a tutor-directed approach to training our system where the speaker presents objects to the system and describes them, as in work by Skocaj et al. (2011). The focus of this work is in evaluating referring expressions as in work by Mohan et al. (2013), although without any dialogue f</context>
</contexts>
<marker>Krishnamurthy, Kollar, 2013</marker>
<rawString>Jayant Krishnamurthy and Thomas Kollar. 2013. Jointly Learning to Parse and Perceive: Connecting Natural Language to the Physical World. Trans. Assoc. Comput. Linguist., 1:193–206.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara Landau</author>
<author>Linda Smith</author>
<author>Susan Jones</author>
</authors>
<title>Object Shape, Object Function, and Object Name.</title>
<date>1998</date>
<journal>J. Mem. Lang.,</journal>
<volume>38</volume>
<issue>1</issue>
<contexts>
<context position="18156" citStr="Landau et al., 1998" startWordPosition="2910" endWordPosition="2913">umptions about the attributes. The result sets from both (b) and (c) agree with the quantifier constraint (definite singular). Pintra = min x,y ∈ + � maxx∈+,y∈− P(xc = yc) if |− |&gt; 0 Pinter = 1 if |− |= 0 Pdistance = Pintra × (1 − Pinter) The classifier probability is similar, except rather than comparing objects to other objects in the partition, the objects are compared to the mean of the column’s descriptor C in the descriptor’s representative feature. If the descriptor is a class name, we instead choose the Zernike shape feature, implementing the shape bias children show in word learning (Landau et al., 1998). If there is insufficient labeled data to use, then the classifier probability is set to 1 for the entire column, meaning only the distance probabilities will affect the probabilities of the nodes. For a given descriptor C, the classifier probabilities are as follows: Ppos(C) = min x∈+ P(xc = yc) P(xc = C) Pneg(C) = rmaxx∈− P(xc = C) if |− |&gt; 0 1 if|− |= 0 Pclassifier(C) = Ppos(C) × (1 − Pneg(C)) 4.2 Node Probabilities We consider two probabilities for determining the probability of a partition: that which can be determined from distance data (considering distances between objects in the part</context>
</contexts>
<marker>Landau, Smith, Jones, 1998</marker>
<rawString>Barbara Landau, Linda Smith, and Susan Jones. 1998. Object Shape, Object Function, and Object Name. J. Mem. Lang., 38(1):1–27, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mu Li</author>
<author>James T Kwok</author>
<author>Bao Liang Lu</author>
</authors>
<title>Online multiple instance learning with no regret.</title>
<date>2010</date>
<booktitle>Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit.,</booktitle>
<pages>1395--1401</pages>
<contexts>
<context position="7797" citStr="Li et al., 2010" startWordPosition="1214" endWordPosition="1217">his work, we undertake a more detailed analysis of the effects of different pragmatic constraints on system performance. The task of training a classifier from “bags” of instances with a label applying to only some of the instances contained within is referred to as Multiple-Instance Learning (MIL) (Dietterich, 1997), and is the machine-learning analogue of cross-situational learning. There is a wide range of methods used in MIL and a number of different assumptions that can be made to fit the task at hand (Foulds and Frank, 2010). Online MIL methods so far have been used for object tracking (Li et al., 2010), and Dindo and Zambuto (2010) apply MIL to grounded language learning, but we are not aware of any research that investigates the application of online MIL to studying cognitive models of incremental grounded language learning. In addition, we find that we must relax many assumptions used in MIL to handle natural language references, such as the 1-of-N assumption used by Dindo and Zambuto. The lack of appropriate algorithms for handling this task motivates our development of a novel algorithm for language learning situations. 3 Experimental Design 3.1 Learning Environment and Data Collection </context>
</contexts>
<marker>Li, Kwok, Lu, 2010</marker>
<rawString>Mu Li, James T. Kwok, and Bao Liang Lu. 2010. Online multiple instance learning with no regret. Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit., pages 1395–1401.</rawString>
</citation>
<citation valid="true">
<authors>
<author>PC C Mahalanobis</author>
</authors>
<title>On The Generalized Distance in Statistics.</title>
<date>1936</date>
<booktitle>Proc. Natl. Inst. Sci. India,</booktitle>
<pages>49--55</pages>
<contexts>
<context position="13641" citStr="Mahalanobis, 1936" startWordPosition="2155" endWordPosition="2156">ing algorithm is needed as the objects are stationary on the table. Color is represented in LAB space for perceptual similarity to humans using Euclidean distance, shape is captured using scale- and rotation-invariant 25-dimensional Zernike moments (Khotanzad and Hong, 1990), and texture is captured using 13-dimensional Haralick features (Haralick et al., 1973). 3.6 Classification and Distance Measures To determine the similarity of new properties and objects to the system’s previous knowledge of such descriptors, we use a k-Nearest Neighbor classifier (k-NN) with Mahalanobis distance metric (Mahalanobis, 1936), distance weighting, and class weighting using the method described in Brown and Koplowitz (1979). Our k-NN implementation allows negative examples so as to incorporate information that we infer about unmentioned objects. We do not train the system with any explicit negative information (i.e., we have no training examples described as “This is not a red block.”, but if the system is confident that an object is not red, it can mark a training example as such). A negative example contributes a weight to the voting equal and opposite to what its weight would have been if it were a positive examp</context>
</contexts>
<marker>Mahalanobis, 1936</marker>
<rawString>PC C Mahalanobis. 1936. On The Generalized Distance in Statistics. Proc. Natl. Inst. Sci. India, pages 49–55.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oded Maron</author>
<author>Tom´as Lozano-P´erez</author>
</authors>
<title>A framework for multiple-instance learning.</title>
<date>1998</date>
<booktitle>Adv. Neural Inf. Process. Syst., 10:570 –</booktitle>
<pages>576</pages>
<marker>Maron, Lozano-P´erez, 1998</marker>
<rawString>Oded Maron and Tom´as Lozano-P´erez. 1998. A framework for multiple-instance learning. Adv. Neural Inf. Process. Syst., 10:570 – 576.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cynthia Matuszek</author>
<author>N FitzGerald</author>
<author>Luke Zettlemoyer</author>
<author>Liefeng Bo</author>
<author>Dieter Fox</author>
</authors>
<title>A Joint Model of Language and Perception for Grounded Attribute Learning.</title>
<date>2012</date>
<booktitle>In Proc. Int. Conf.</booktitle>
<location>Mach. Learn.</location>
<contexts>
<context position="6265" citStr="Matuszek et al., 2012" startWordPosition="952" endWordPosition="956">eference resolution to determine how well the system identifies the correct objects to attend to, and our second is description generation to determine how well the system uses those training examples to understand attributes and object classes. 2 Related Work Our algorithm for reference resolution and XSL fits into our previous work on a situated language learning system for grounding linguistic symbols in perception. The integration of language in a multi-modal task is a burgeoning area of research, with the grounded data being any of a range of possible situations, from objects on a table (Matuszek et al., 2012) to wetlab experiments (Naim et al., 2014). Our end goal of using natural language to learn from visual scenes is similar to work by Krishnamurthy and Kollar (2013) and Yu and Siskind (2013), and our emphasis on attributes is related to work by Farhadi et al. (2009). However, our focus is on learning from situations that a child would be exposed to, without using annotated data, and to test implementations of child language learning strategies in a computational system. We use a tutor-directed approach to training our system where the speaker presents objects to the system and describes them, </context>
</contexts>
<marker>Matuszek, FitzGerald, Zettlemoyer, Bo, Fox, 2012</marker>
<rawString>Cynthia Matuszek, N FitzGerald, Luke Zettlemoyer, Liefeng Bo, and Dieter Fox. 2012. A Joint Model of Language and Perception for Grounded Attribute Learning. In Proc. Int. Conf. Mach. Learn.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shiwali Mohan</author>
<author>John E Laird</author>
<author>Laird Umich Edu</author>
</authors>
<title>Towards an Indexical Model of Situated Language Comprehension for Real-World Cognitive Agents.</title>
<date>2013</date>
<pages>2013--153</pages>
<contexts>
<context position="6996" citStr="Mohan et al. (2013)" startWordPosition="1082" endWordPosition="1085">s similar to work by Krishnamurthy and Kollar (2013) and Yu and Siskind (2013), and our emphasis on attributes is related to work by Farhadi et al. (2009). However, our focus is on learning from situations that a child would be exposed to, without using annotated data, and to test implementations of child language learning strategies in a computational system. We use a tutor-directed approach to training our system where the speaker presents objects to the system and describes them, as in work by Skocaj et al. (2011). The focus of this work is in evaluating referring expressions as in work by Mohan et al. (2013), although without any dialogue for disambiguation. Kollar et al. (2013) also incorporate quantifier and pragmatic constraints on reference resolution in a setting similar to ours. In this work, we undertake a more detailed analysis of the effects of different pragmatic constraints on system performance. The task of training a classifier from “bags” of instances with a label applying to only some of the instances contained within is referred to as Multiple-Instance Learning (MIL) (Dietterich, 1997), and is the machine-learning analogue of cross-situational learning. There is a wide range of me</context>
</contexts>
<marker>Mohan, Laird, Edu, 2013</marker>
<rawString>Shiwali Mohan, John E Laird, and Laird Umich Edu. 2013. Towards an Indexical Model of Situated Language Comprehension for Real-World Cognitive Agents. 2013:153–170.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Iftekhar Naim</author>
<author>Young Chol Song</author>
<author>Qiguang Liu</author>
<author>Henry Kautz</author>
<author>Jiebo Luo</author>
<author>Daniel Gildea</author>
</authors>
<title>Unsupervised Alignment of Natural Language Instructions with Video Segments.</title>
<date>2014</date>
<booktitle>In AAAI.</booktitle>
<contexts>
<context position="6307" citStr="Naim et al., 2014" startWordPosition="960" endWordPosition="963">system identifies the correct objects to attend to, and our second is description generation to determine how well the system uses those training examples to understand attributes and object classes. 2 Related Work Our algorithm for reference resolution and XSL fits into our previous work on a situated language learning system for grounding linguistic symbols in perception. The integration of language in a multi-modal task is a burgeoning area of research, with the grounded data being any of a range of possible situations, from objects on a table (Matuszek et al., 2012) to wetlab experiments (Naim et al., 2014). Our end goal of using natural language to learn from visual scenes is similar to work by Krishnamurthy and Kollar (2013) and Yu and Siskind (2013), and our emphasis on attributes is related to work by Farhadi et al. (2009). However, our focus is on learning from situations that a child would be exposed to, without using annotated data, and to test implementations of child language learning strategies in a computational system. We use a tutor-directed approach to training our system where the speaker presents objects to the system and describes them, as in work by Skocaj et al. (2011). The fo</context>
</contexts>
<marker>Naim, Song, Liu, Kautz, Luo, Gildea, 2014</marker>
<rawString>Iftekhar Naim, Young Chol Song, Qiguang Liu, Henry Kautz, Jiebo Luo, and Daniel Gildea. 2014. Unsupervised Alignment of Natural Language Instructions with Video Segments. In AAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ian Perera</author>
<author>JF Allen</author>
</authors>
<title>SALL-E: Situated Agent for Language Learning.</title>
<date>2013</date>
<booktitle>In Twenty-Seventh AAAI Conf. Artif. Intell.</booktitle>
<contexts>
<context position="5380" citStr="Perera and Allen, 2013" startWordPosition="814" endWordPosition="817"> towards describing an object in a scene, rather than just identifying it. That is, we do not only learn to recognize instances of objects, but also learn attributes constrained to feature spaces that will be compatible with contextual modifiers such as dark/light in terms of color, or small/large in terms of size and object classification. Therefore, we approach the static, visual aspects of the symbol grounding problem with an eye towards ensuring that our grounded representations of attributes can be composed in the same way that their semantic analogues can. We continue our previous work (Perera and Allen, 2013) with two evaluations to demonstrate the effectiveness of applying the principles of Quantity, Contrast, and Conventionality, as well as incorporating quantifier constraints, negative information, and classification in the training step. Our first evaluation is reference resolution to determine how well the system identifies the correct objects to attend to, and our second is description generation to determine how well the system uses those training examples to understand attributes and object classes. 2 Related Work Our algorithm for reference resolution and XSL fits into our previous work o</context>
<context position="10890" citStr="Perera and Allen, 2013" startWordPosition="1719" endWordPosition="1722"> Prior System Knowledge We encode some existing linguistic and perceptual knowledge into the system to aid in learning from unconstrained object descriptions. The representative feature, defined as the system’s feature space assigned to a property name (e.g., color for “white”, or shape for “round”), was prechosen for the task’s vocabulary to reduce the number of factors affecting the evaluation of the system. In previous work, we showed that the accuracy of the system’s automatic choice of representative features can reach 78% after about 50 demonstrations of objects presented one at a time (Perera and Allen, 2013). In addition, we developed an extension to a semantic parser that distinguishes between attributes and object names using syntactic constructions. 3.4 Language Processing The transcribed utterances are passed through the TRIPS parser (Allen et al., 2008) for simultaneous lexicon learning and recognition of object descriptions. The parser outputs generalized quantifiers and numeric constraints (capturing singular/- plural instances, as well as specific numbers) in referring expressions, which are used for applying quantifier constraints to the possibilities of the referent object or group of o</context>
<context position="24462" citStr="Perera and Allen, 2013" startWordPosition="3917" endWordPosition="3920">e space separately to find previous examples of objects similar in that feature space and adds each found property label to the k-NN voting set, weighted by the distance. If the majority label does not have the matching representative feature, the system skips this feature space for adding a property to the description. The object name is chosen using a distance generated from the sum of the distances (normalized and weighted through the Mahalanobis distance metric) to the most similar previous examples. More details about the description generation process can be found in our previous paper (Perera and Allen, 2013). 6 Evaluation To evaluate our system, we use two metrics: our evaluation method used in previous work for rating the quality of generated descriptions (Perera and Allen, 2013), and a standard precision/recall measurement to determine the accuracy of reference resolution. The description generated by the system is compared with a number of possible ground truth descriptions which are generated using precision and recall equivalence classes from our previous work. Precision is calculated according to which words in the description could be found in a ground truth description, while recall is ca</context>
</contexts>
<marker>Perera, Allen, 2013</marker>
<rawString>Ian Perera and JF Allen. 2013. SALL-E: Situated Agent for Language Learning. In Twenty-Seventh AAAI Conf. Artif. Intell.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ian Perera</author>
<author>James F Allen</author>
</authors>
<title>What is the Ground ? Continuous Maps for Grounding Perceptual Primitives. In</title>
<date>2014</date>
<booktitle>Proc. 36th Annu. Conf. Cogn. Sci. Soc.,</booktitle>
<editor>P Bello, M. Guarini, M McShane, and Brian Scassellati, editors,</editor>
<publisher>Cognitive Science Society.</publisher>
<location>Austin, TX.</location>
<contexts>
<context position="36158" citStr="Perera and Allen, 2014" startWordPosition="5762" endWordPosition="5765">intersective predicate “tall” in our current framework. Non-intersective predicates add complexity to the system because their reference point is not necessarily the other objects in the scene - it may be a reference to other objects in the same class (i.e., blocks). Also, our set of features is rather rudimentary and could be improved, as we chose lowdimensional, continuous features in an attempt to facilitate a close connection between language and vision. The use of continuous features ensures that primitive concepts are grounded solely in perception and not higher-order conceptual models (Perera and Allen, 2014). Initial results using 3D shape features show a considerable performance increase on a kitchen dataset we are developing. 9 Conclusion We have proposed a probabilistic framework for using pragmatic inference to learn from underspecified visual descriptions. We show that this system can use pragmatic assumptions attenuated by overspecification probability to learn attributes and object names from videos that include a number of distractors. We also analyzed various learning methods in an attempt to gain a deeper understanding of the theoretical and practical considerations of situated language</context>
</contexts>
<marker>Perera, Allen, 2014</marker>
<rawString>Ian Perera and James F Allen. 2014. What is the Ground ? Continuous Maps for Grounding Perceptual Primitives. In P Bello, M. Guarini, M McShane, and Brian Scassellati, editors, Proc. 36th Annu. Conf. Cogn. Sci. Soc., Austin, TX. Cognitive Science Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A C Rencher</author>
</authors>
<title>Methods of Multivariate Analysis.</title>
<date>2003</date>
<booktitle>Series in Probability and Statistics.</booktitle>
<publisher>Wiley</publisher>
<contexts>
<context position="14537" citStr="Rencher, 2003" startWordPosition="2305" endWordPosition="2306">mation (i.e., we have no training examples described as “This is not a red block.”, but if the system is confident that an object is not red, it can mark a training example as such). A negative example contributes a weight to the voting equal and opposite to what its weight would have been if it were a positive example of that class. The Mahalanobis distance provides a way to incorporate a k-nearest neighbor classifier into a probabilistic framework. Because the squared Mahalanobis distance is equal to the number of standard deviations from the mean of the data assuming a normal distribution (Rencher, 2003), we can convert the Mahalanobis distance to a probability measure to be used in probabilistic reasoning. 4 The Reference Lattice To learn from underspecified training examples, we must resolve the referring expression and assign the properties and object name in the expression to the correct referents. To incorporate existing perceptual knowledge, semi-supervised methods, and pragmatic constraints in the reference resolution task, we use a probabilistic lattice structure that we call the reference lattice. The reference lattice consists of nodes corresponding to possible partitions of the sce</context>
</contexts>
<marker>Rencher, 2003</marker>
<rawString>A C Rencher. 2003. Methods of Multivariate Analysis. Wiley Series in Probability and Statistics. Wiley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Danijel Skocaj</author>
<author>Matej Kristan</author>
<author>Alen Vrecko</author>
<author>Marko Mahnic</author>
<author>Miroslav Janicek</author>
<author>Geert-Jan M Kruijff</author>
<author>Marc Hanheide</author>
<author>Nick Hawes</author>
<author>Thomas Keller</author>
<author>Michael Zillich</author>
<author>Kai Zhou</author>
</authors>
<title>A system for interactive learning in dialogue with a tutor.</title>
<date>2011</date>
<booktitle>In 2011 IEEE✓RSJ Int. Conf. Intell. Robot. Syst.,</booktitle>
<pages>3387--3394</pages>
<publisher>IEEE,</publisher>
<contexts>
<context position="6899" citStr="Skocaj et al. (2011)" startWordPosition="1063" endWordPosition="1066">eriments (Naim et al., 2014). Our end goal of using natural language to learn from visual scenes is similar to work by Krishnamurthy and Kollar (2013) and Yu and Siskind (2013), and our emphasis on attributes is related to work by Farhadi et al. (2009). However, our focus is on learning from situations that a child would be exposed to, without using annotated data, and to test implementations of child language learning strategies in a computational system. We use a tutor-directed approach to training our system where the speaker presents objects to the system and describes them, as in work by Skocaj et al. (2011). The focus of this work is in evaluating referring expressions as in work by Mohan et al. (2013), although without any dialogue for disambiguation. Kollar et al. (2013) also incorporate quantifier and pragmatic constraints on reference resolution in a setting similar to ours. In this work, we undertake a more detailed analysis of the effects of different pragmatic constraints on system performance. The task of training a classifier from “bags” of instances with a label applying to only some of the instances contained within is referred to as Multiple-Instance Learning (MIL) (Dietterich, 1997)</context>
</contexts>
<marker>Skocaj, Kristan, Vrecko, Mahnic, Janicek, Kruijff, Hanheide, Hawes, Keller, Zillich, Zhou, 2011</marker>
<rawString>Danijel Skocaj, Matej Kristan, Alen Vrecko, Marko Mahnic, Miroslav Janicek, Geert-Jan M. Kruijff, Marc Hanheide, Nick Hawes, Thomas Keller, Michael Zillich, and Kai Zhou. 2011. A system for interactive learning in dialogue with a tutor. In 2011 IEEE✓RSJ Int. Conf. Intell. Robot. Syst., pages 3387–3394. IEEE, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Linda Smith</author>
<author>Chen Yu</author>
</authors>
<title>Infants rapidly learn word-referent mappings via cross-situational statistics.</title>
<date>2008</date>
<journal>Cognition,</journal>
<pages>106--1558</pages>
<contexts>
<context position="4174" citStr="Smith and Yu, 2008" startWordPosition="623" endWordPosition="626">le ambiguity in determining the correct referent, past, ambiguous experiences can be called upon to resolve ambiguity in the current situation in a strategy called Cross-Situational Learning (XSL). There is some debate over whether people use XSL, as it requires considerable memory and computational 226 Proceedings of the 19th Conference on Computational Language Learning, pages 226–236, Beijing, China, July 30-31, 2015. c�2015 Association for Computational Linguistics load (Trueswell et al., 2013). However, other experiments show evidence for XSL in adults and children in certain situations (Smith and Yu, 2008; Smith et al., 2011). We believe these instances that show evidence of XSL certainly merit an implementation both for better understanding language learning and for advancing grounded language learning in the realm of robotics where such limitations do not exist. We show that by reasoning over multiple ambiguous learning instances and constraining possibilities with pragmatic inferences, a system can quickly learn attributes and names of objects without a single unambiguous training example. Our overarching research goal is to learn compositional models of grounded attributes towards describi</context>
</contexts>
<marker>Smith, Yu, 2008</marker>
<rawString>Linda Smith and Chen Yu. 2008. Infants rapidly learn word-referent mappings via cross-situational statistics. Cognition, 106:1558–1568.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenny Smith</author>
<author>Andrew D M Smith</author>
<author>Richard a Blythe</author>
</authors>
<title>Cross-situational learning: An experimental study of word-learning mechanisms.</title>
<date>2011</date>
<journal>Cogn. Sci.,</journal>
<pages>35--480</pages>
<contexts>
<context position="4195" citStr="Smith et al., 2011" startWordPosition="627" endWordPosition="630">rmining the correct referent, past, ambiguous experiences can be called upon to resolve ambiguity in the current situation in a strategy called Cross-Situational Learning (XSL). There is some debate over whether people use XSL, as it requires considerable memory and computational 226 Proceedings of the 19th Conference on Computational Language Learning, pages 226–236, Beijing, China, July 30-31, 2015. c�2015 Association for Computational Linguistics load (Trueswell et al., 2013). However, other experiments show evidence for XSL in adults and children in certain situations (Smith and Yu, 2008; Smith et al., 2011). We believe these instances that show evidence of XSL certainly merit an implementation both for better understanding language learning and for advancing grounded language learning in the realm of robotics where such limitations do not exist. We show that by reasoning over multiple ambiguous learning instances and constraining possibilities with pragmatic inferences, a system can quickly learn attributes and names of objects without a single unambiguous training example. Our overarching research goal is to learn compositional models of grounded attributes towards describing an object in a sce</context>
</contexts>
<marker>Smith, Smith, Blythe, 2011</marker>
<rawString>Kenny Smith, Andrew D M Smith, and Richard a. Blythe. 2011. Cross-situational learning: An experimental study of word-learning mechanisms. Cogn. Sci., 35:480–498.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John C Trueswell</author>
<author>Tamara Nicol Medina</author>
<author>Alon Hafri</author>
<author>Lila R Gleitman</author>
</authors>
<title>Propose but verify: fast mapping meets cross-situational word learning.</title>
<date>2013</date>
<journal>Cogn. Psychol.,</journal>
<volume>66</volume>
<issue>1</issue>
<contexts>
<context position="4059" citStr="Trueswell et al., 2013" startWordPosition="604" endWordPosition="607">ect and attribute representations while allowing a classifier to aid in reference resolution. When faced with unresolvable ambiguity in determining the correct referent, past, ambiguous experiences can be called upon to resolve ambiguity in the current situation in a strategy called Cross-Situational Learning (XSL). There is some debate over whether people use XSL, as it requires considerable memory and computational 226 Proceedings of the 19th Conference on Computational Language Learning, pages 226–236, Beijing, China, July 30-31, 2015. c�2015 Association for Computational Linguistics load (Trueswell et al., 2013). However, other experiments show evidence for XSL in adults and children in certain situations (Smith and Yu, 2008; Smith et al., 2011). We believe these instances that show evidence of XSL certainly merit an implementation both for better understanding language learning and for advancing grounded language learning in the realm of robotics where such limitations do not exist. We show that by reasoning over multiple ambiguous learning instances and constraining possibilities with pragmatic inferences, a system can quickly learn attributes and names of objects without a single unambiguous train</context>
</contexts>
<marker>Trueswell, Medina, Hafri, Gleitman, 2013</marker>
<rawString>John C Trueswell, Tamara Nicol Medina, Alon Hafri, and Lila R Gleitman. 2013. Propose but verify: fast mapping meets cross-situational word learning. Cogn. Psychol., 66(1):126–56, February.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Van Orman Quine</author>
</authors>
<title>Word and Object.</title>
<date>1964</date>
<pages>235</pages>
<publisher>MIT Press</publisher>
<marker>Quine, 1964</marker>
<rawString>W Van Orman Quine. 1964. Word and Object. MIT Press paperback series. MIT Press. 235</rawString>
</citation>
<citation valid="true">
<authors>
<author>Haonan Yu</author>
<author>Jeffrey Mark Siskind</author>
</authors>
<title>Grounded Language Learning from Video Described with Sentences.</title>
<date>2013</date>
<booktitle>In Proc. 51st Annu. Meet. Assoc. Comput. Linguist.,</booktitle>
<pages>53--63</pages>
<contexts>
<context position="6455" citStr="Yu and Siskind (2013)" startWordPosition="987" endWordPosition="990"> examples to understand attributes and object classes. 2 Related Work Our algorithm for reference resolution and XSL fits into our previous work on a situated language learning system for grounding linguistic symbols in perception. The integration of language in a multi-modal task is a burgeoning area of research, with the grounded data being any of a range of possible situations, from objects on a table (Matuszek et al., 2012) to wetlab experiments (Naim et al., 2014). Our end goal of using natural language to learn from visual scenes is similar to work by Krishnamurthy and Kollar (2013) and Yu and Siskind (2013), and our emphasis on attributes is related to work by Farhadi et al. (2009). However, our focus is on learning from situations that a child would be exposed to, without using annotated data, and to test implementations of child language learning strategies in a computational system. We use a tutor-directed approach to training our system where the speaker presents objects to the system and describes them, as in work by Skocaj et al. (2011). The focus of this work is in evaluating referring expressions as in work by Mohan et al. (2013), although without any dialogue for disambiguation. Kollar </context>
</contexts>
<marker>Yu, Siskind, 2013</marker>
<rawString>Haonan Yu and Jeffrey Mark Siskind. 2013. Grounded Language Learning from Video Described with Sentences. In Proc. 51st Annu. Meet. Assoc. Comput. Linguist., pages 53–63.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>