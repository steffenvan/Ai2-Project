<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000085">
<title confidence="0.9985485">
Age Prediction in Blogs: A Study of Style, Content, and Online
Behavior in Pre- and Post-Social Media Generations
</title>
<author confidence="0.998119">
Sara Rosenthal
</author>
<affiliation confidence="0.996623">
Department of Computer Science
Columbia University
</affiliation>
<address confidence="0.99049">
New York, NY 10027, USA
</address>
<email confidence="0.999535">
sara@cs.columbia.edu
</email>
<author confidence="0.998029">
Kathleen McKeown
</author>
<affiliation confidence="0.996625">
Department of Computer Science
Columbia University
</affiliation>
<address confidence="0.990526">
New York, NY 10027, USA
</address>
<email confidence="0.999649">
kathy@cs.columbia.edu
</email>
<sectionHeader confidence="0.995654" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999649388888889">
We investigate whether wording, stylistic
choices, and online behavior can be used
to predict the age category of blog authors.
Our hypothesis is that significant changes
in writing style distinguish pre-social me-
dia bloggers from post-social media blog-
gers. Through experimentation with a
range of years, we found that the birth
dates of students in college at the time
when social media such as AIM, SMS text
messaging, MySpace and Facebook first
became popular, enable accurate age pre-
diction. We also show that internet writing
characteristics are important features for
age prediction, but that lexical content is
also needed to produce significantly more
accurate results. Our best results allow for
81.57% accuracy.
</bodyText>
<sectionHeader confidence="0.999134" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.95076525">
The evolution of the internet has changed the
way that people communicate. The introduction
of instant messaging, forums, social networking
and blogs has made it possible for people of ev-
ery age to become authors. The users of these
social media platforms have created their own
form of unstructured writing that is best char-
acterized as informal. Even how people com-
municate has dramatically changed, with multi-
tasking increasing and responses generated im-
mediately. We should be able to exploit those
differences to automatically determine from blog
posts whether an author is part of a pre- or post-
763
social media generation. This problem is called
age prediction and raises two main questions:
</bodyText>
<listItem confidence="0.944367166666667">
• Is there a point in time that proves to be
a significantly better dividing line between
pre and post-social media generations?
• What features of communication most di-
rectly reveal the generation in which a blog-
ger was born?
</listItem>
<bodyText confidence="0.999649">
We hypothesize that the dividing line(s) oc-
cur when people in generation Yi, or the millen-
nial generation, (born anywhere from the mid-
1970s to the early 2000s) were typical college-
aged students (18-22). We focus on this gen-
eration due to the rise of popular social media
technologies such as messaging and online social
networks sites that occurred during that time.
Therefore, we experimented with binary clas-
sification into age groups using all birth dates
from 1975 through 1988, thus including students
from generation Y who were in college during
the emergence of social media technologies. We
find five years where binary classification is sig-
nificantly more accurate than other years: 1977,
1979, and 1982-1984. The appearance of social
media technologies such as AOL Instant Messen-
ger (AIM), weblogs, SMS text messaging, Face-
book and MySpace occurred when people with
these birth dates were in college.
We explore two of these years in more detail,
1979 and 1984, and examine a wide variety of
</bodyText>
<footnote confidence="0.904013">
lhttp://en.wikipedia.org/wiki/Generation Y
</footnote>
<note confidence="0.9850955">
Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 763–772,
Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics
</note>
<bodyText confidence="0.99996372">
features that differ between the pre-social me-
dia and post-social media bloggers. We examine
lexical-content features such as collocations and
part-of-speech collocations, lexical-stylistic fea-
tures such as internet slang and capitalization,
and features representing online behavior such
as time of post and number of friends. We find
that both stylistic and content features have a
significant impact on age prediction and show
that, for unseen blogs, we are able to classify
authors as born before or after 1979 with 80%
accuracy and born before or after 1984 with 82%
accuracy.
In the remainder of this paper, we first dis-
cuss work to date on age prediction for blogs
and then present the features that we extracted,
which is a larger set than previously explored.
We then turn separately to three experiments.
In the first, we implement a prior approach to
show that we can produce a similar outcome. In
the second, we show how the accuracy of age
prediction changes over time and pinpoint when
major changes occur. In the last experiment, we
describe our age prediction experiments in more
detail for the most significant years.
</bodyText>
<sectionHeader confidence="0.999694" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999981911764706">
In previous work, Mackinnon (2006) , used Live-
Journal data to identify a blogger&apos;s age by ex-
amining the mean age of his peer group using
his social network and not just his immediate
friends. They were able to predict the correct
age within +/-5 years at 98% accuracy. This ap-
proach, however, is very different from ours as it
requires access to the age of each of the blogger&apos;s
friends. Our approach uses only a body of text
written by a person along with his blogging be-
havior to determine which age group he is more
closely identified with.
Initial research on predicting age without us-
ing the ages of friends focuses on identifying im-
portant candidate features, including blogging
characteristics (e.g., time of post), text features
(e.g., length of post), and profile information
(e.g., interests) (Burger and Henderson, 2006).
They aimed at binary prediction of age, classify-
ing LiveJournal bloggers as either over or under
18, but were unable to automatically predict age
with more accuracy than a baseline model that
always chose the majority class. In our study on
determining the ideal age split we did not find
18 (bloggers born in 1986 in their dataset) to be
significant.
Prior work by Schler et al. (2006) has ex-
amined metadata such as gender and age in
blogger.com bloggers. In contrast to our work,
they examine bloggers based on their age at the
time of the experiment, whether in the 10&apos;s, 20&apos;s
or 30&apos;s age bracket. They identify interesting
changes in content and style features across cat-
egories, in which they include blogging words
(e.g., “LOL&amp;quot;), all defined by the Linguistic In-
quiry and Word Count (LIWC) (Pennebaker et
al., 2007). They did not use characteristics of
online behavior (e.g., friends). They can distin-
guish between bloggers in the 10&apos;s and in the 30&apos;s
with relatively high accuracy (above 96%) but
many 30s are misclassified as 20s, which results
in a overall accuracy of 76.2%. We re-implement
Schler et al.&apos;s work in section 5.1 with similar
findings. Their work shows that ease of classi-
fication is dependent in part on what division
is made between age groups and in turn moti-
vates our decision to study whether the creation
of social media technologies can be used to find
the dividing line(s). Neither Schler et al., nor
we, attempt to determine how a person’s writ-
ing changes over his lifespan (Pennebaker and
Stone, 2003; Robins et al., 2002). Goswami et
al. (2009) add to Schler et al.&apos;s approach using
the same data and have a 4% increase in accu-
racy. However, the paper is lacking details and
it is entirely unclear how they were able to do
this with fewer features than Schler et al.
In other work, Tam and Martell (2009) at-
tempt to detect age in the NPS chat corpus be-
tween teens and other ages. They use an SVM
classifier with only n-grams as features. They
achieve &gt; 90% accuracy when classifying teens
vs 30s, 40s, 50s, and all adults and achieve at
best 76% when using 3 character gram features
in classifying teens vs 20s. This work shows that
n-grams are useful features for detecting age and
it is difficult to detect differences between con-
secutive groups such as teens and 20s, and this
</bodyText>
<page confidence="0.96427">
764
</page>
<bodyText confidence="0.944487565217391">
Journal blogs containing age. We represent age
as the year a person was born and not his age
at the time of the experiment. Since technol-
ogy has different effects in different countries,
we only analyze the blogs of people who have
listed US as their country. It is possible that
text written in a language other than English
is included in our corpus. However, in a man-
ual check of a small portion of text from 500
blogs, we only found English words. Each blog
was written by a unique individual and includes
a user profile and up to 25 recent posts written
between 2000-2010 with the most recent post be-
ing written in 2009-2010. The birth dates of the
bloggers range in years from 1940 to 2000 and
thus, their age ranges from 10 to 70 in 2010. Fig-
ure 1 shows the number of bloggers per age in
our group with birth dates from 1950 to 1996.
The majority of bloggers on LiveJournal were
born between 1978-1989.
4 Methods
We pre-processed the data to add Part-of-
Speech tags (POS) and dependencies (de Marn-
</bodyText>
<figureCaption confidence="0.987033375">
effe et al., 2006) between words using the Stan-
ford Parser (Klein and Manning, 2003a; Klein
and Manning, 2003b). The POS and syntactic
dependencies were only found for approximately
the first 90 words in each sentence. Our classifi-
cation method investigates 17 different features
that fall into three categories: online behavior,
lexical-stylistic and lexical-content. All of the
features we used are explained in Table 1 along
with their trend as age decreases where applica-
ble. Any feature that increased, decreased, or
fluctuated should have some positive impact on
the accuracy of predicting age.
4.1 Online Behavior and Interests
Online behavior features are blog specific, such
as number of comments and friends as described
in Table 1.1. The first feature, interests, is our
only feature that is specific to LiveJournal. In-
terests appear in the LiveJournal user profile,
but are not found on all blog sites. All other
online behavior features are typically available
in any blog.
Figure 1: Number of bloggers in 2010 by year of birth
from 1950-1996. A minimal amount of data occurred
</figureCaption>
<bodyText confidence="0.956397939393939">
in years not shown.
provides evidence for the need to find a good
classification split.
Other researchers have investigated weblogs
for differences in writing style depending on gen-
der identification (Herring and Paolillo, 2006;
Yan and Yan, 2006; Nowson and Oberlander,
2006). Herring et al (2006) found that the typi-
cal gender related features were based on genre
and independent of author gender. Yan et al
(2006) used text categorization and stylistic web
features, such as emoticons, to identify gender
and achieved 60% F-measure. Nowson et al
(2006) employed dictionary and n-gram based
content analysis and achieved 91.5% accuracy
using an SVM classifier. We also use a super-
vised machine learning approach, but classifica-
tion by gender is naturally a binary classification
task, while our work requires determining a nat-
ural dividing point.
3 Data Collection
Our corpus consists of blogs downloaded from
the virtual community LiveJournal. We chose
to use LiveJournal blogs for our corpus because
the website provides an easy-to-use format in
XML for downloading and crawling their site.
In addition, LiveJournal gives bloggers the op-
portunity to post their age on their profile. We
take advantage of this feature by downloading
blogs where the user chooses to publicly provide
this metadata.
We downloaded approximately 24,500 Live-
765
</bodyText>
<table confidence="0.995635">
Feature Explanation Example Trend as Age
Decreases
1 Interests Top3 interests provided on the profile page2 disney N/A
2 # of Friends Number of friends the blogger has 45 fluctuates
# of Posts Number of downloadable posts (0-25) 23 decrease
# of Lifetime Posts Number of posts written in total 821 decrease
Time Mode hour (00-23) and day the blogger posts 11/Monday no change
Comments Average number of comments per post 2.64 increase
3 Emoticons number of emoticons1 :) increase
Acronyms number of internet acronyms1 lol increase
Slang number of words that are not found in the dictionary1 wazzup increase
Punctuation number of stand-alone punctuation1 ... increase
Capitalization number of words (with length &gt; 1) that are all CAPS1 YOU increase
Sentence Length average sentence length 40 decrease
Links/Images number of url and image links1 www.site.com fluctuates
4 Collocations Top3 Collocations in the age group. to [] the N/A
Syntax Collocations Top3 Syntax Collocations in the age group. best friends N/A
POS Collocations Top3 Part-of-Speech Collocations in the age group. this [] [] VB N/A
Words Top3 words in the age group his N/A
</table>
<tableCaption confidence="0.725492">
Table 1: List of all features used during classification divided into three categories (1,2) online behavior and
interests, (3) lexical - content, and (4) lexical - stylistic 1 normalized per sentence per entry, 2 available in
LiveJournal only, 3 pruned from top 200 features to include those that do not occur within +/- 10 position
in any other age group
</tableCaption>
<bodyText confidence="0.99995892">
We extracted the top 200 interests based on
occurrence in the profile page from 1500 random
blogs in three age groups. These age groups are
used solely to illustrate the differences that oc-
cur at different ages and are not used in our
classification experiments. We then pruned the
list of interests by excluding any interest that
occurred within a +/-10 window (based on its
position in the list) in multiple age groups. We
show the top interests in each age group in Ta-
ble 2. For example, “disney&amp;quot; is the most popu-
lar unique interest in the 18-22 age group with
only 39 other non-unique interests in that age
group occurring more frequently. “Fanfiction&amp;quot;
is a popular interest in all age groups, but it
is significantly more popular in the 18-22 age
group than in other age groups.
Amongst the other online behavior features,
the number of friends tends to fluctuate but
seems to be higher for older bloggers. The num-
ber of lifetime posts (Figure 2(d)), and posts de-
creases as bloggers get younger which is as one
would expect unless younger people were orders
of magnitude more prolific than older people.
The mode time (Figure 2(b)), refers to the most
</bodyText>
<table confidence="0.998993333333333">
18-22 28-32 38-42
disney 39 tori amos 49 polyamory 40
yaoi 40 hiking 55 sca 67
johnny depp 42 women 61 babylon 5 84
rent 44 gaming 62 leather 94
house 45 comic books 67 farscape 103
fanfiction 11 fanfiction 58 fanfiction 138
drawing 10 drawing 25 drawing 65
sci-fi 199 sci-fi 37 sci-fi 21
</table>
<tableCaption confidence="0.99726">
Table 2: Top interests for three different age groups.
</tableCaption>
<bodyText confidence="0.9244463">
The top half refers to the top 5 interests that are
unique to each age group. The value refers to the
position of the interest in its list
common hour of posting from 00-24 based on
GMT time. We didn’t compute time based on
the time zone because city/state is often not in-
cluded. We found time to not be a useful feature
in this manner and it is difficult to come to any
conclusions from its change as year of birth de-
creases.
</bodyText>
<subsectionHeader confidence="0.99059">
4.2 Lexical - Stylistic
</subsectionHeader>
<bodyText confidence="0.9951545">
The Lexical-Stylistic features in Table 1.2, such
as slang and sentence length, are computed us-
</bodyText>
<page confidence="0.994462">
766
</page>
<figureCaption confidence="0.792828">
Figure 2: Examples of change to features over time (a) Average number of emoticons in a sentence increases
as age decreases (b) The most common time fluctuates until 1982, where it is consistent (c) The number
of links/images in a sentence fluctuates (d) The average number of lifetime posts per year decreases as age
decreases
</figureCaption>
<bodyText confidence="0.999198357142857">
ing the text from all of the posts written by the
blogger. Other than sentence length, they were
normalized by sentence and post to keep the
numbers consistent between bloggers regardless
of whether the user wrote one or many posts in
his/her blog. The number of emoticons (Figure
2(a)), acronyms, and capital words increased as
bloggers got younger. Slang and punctuation,
which excludes the emoticons and acronyms
counted in the other features, increased as well,
but not as significantly. The length of sentences
decreased as bloggers got younger and the num-
ber of links/images varied across all years as
shown in Figure 2(c).
</bodyText>
<subsectionHeader confidence="0.998575">
4.3 Lexical - Content
</subsectionHeader>
<bodyText confidence="0.999976333333333">
The last category of features described in Ta-
ble 1.3 consists of collocations and words, which
are content based lexical terms. The top words
are produced using a typical “bag-of-words” ap-
proach. The top collocations are computed us-
ing a system called Xtract (Smadja, 1993).
We use Xtract to obtain important lexical col-
locations, syntactic collocations, and POS col-
locations as features from our text. Syntac-
tic collocations refer to significant word pairs
that have specific syntactic dependencies such
as subject/verb and verb/object. Due to the
length of time it takes to run this program, we
ran Xtract on 1500 random blogs from each age
group and examined the first 1000 words per
blog. We looked at 1.5 million words in total
and found approximately 2500-2700 words that
were repeated more than 50 times.
We extracted the top 200 words and colloca-
tions sorted by post frequency (pf), which is the
number of posts the term occurred in. Then,
similarly to interests, we pruned each list to
include the features that did not occur within
+/-10 window (based on its position in the list)
within each age group. Prior to settling on these
metrics, we also experimented with other met-
rics such as the number of times the collocation
</bodyText>
<page confidence="0.971529">
767
</page>
<table confidence="0.999741888888889">
18-22 28-32 38-42
ldquot (&apos;) 101 great 166 may 164
t 152 find 167 old 183
school 172 many 177 house 191
x 173 years 179 world 192
anything 175 week 181 please 198
maybe 179 post 190 - -
because 68 because 80 because 93
him 59 him 85 him 73
</table>
<tableCaption confidence="0.89122225">
Table 3: Top words for three age groups. The top
half refers to the top 5 words that are unique to each
age group. The value refers to the position of the
interest in its list
</tableCaption>
<table confidence="0.9997457">
blogger.com livejournal.com
download 2004 2010
year
# of Blogs 19320 11521
# of Posts1 1.4 million 256,000
# of words1 295 million 50 million
age 13·17 23·27 33·37 18·22 28·32 38·42
size 8240 8086 2994 3518 5549 2454
majority 43.8% (13-17) 48.2% (22-32)
baseline
</table>
<tableCaption confidence="0.99217">
Table 4: Statistics for Schler et al.�s data (blog-
ger.com) vs our data (livejournal.com) 1 is approxi-
mate amount.
</tableCaption>
<bodyText confidence="0.999917545454546">
occurred in total, defined as collocation or term
frequency (tf), the number of blogs the colloca-
tion occurred in, defined as blog frequency (bf),
and variations of TF*IDF (Salton and Buck-
ley, 1988) where we tried using inverse blog fre-
quency and inverse post frequency as the value
for IDF. In addition, we also experimented with
looking at a different number of important words
and collocations ranging from the top 100-300
terms and experimented without pruning. None
of these variations improved accuracy in our
experiments, however, and thus, were dropped
from further experimentation.
Table 3 shows the top words for each age
group; older people tend to use words such as
“house” and “old&amp;quot; frequently and younger peo-
ple talk about “school”.
In our analysis of the top collocations, we
found that younger people tend to use first per-
son singular (I,me) in subject position while
older people tend to use first person plural (we)
in subject position, both with a variety of verbs.
</bodyText>
<sectionHeader confidence="0.996659" genericHeader="related work">
5 Experiments and Results
</sectionHeader>
<bodyText confidence="0.99998080952381">
We ran three separate experiments to determine
how well we can predict age: 1. classifying into
three distinct age groups (Schler et al. (2006)
experiment), 2. binary classification with the
split at each birth year from 1975-1988 and 3.
Detailed classification on two significant splits
from the second experiment.
We ran all of our experiments in Weka (Hall et
al., 2009) using logistic regression over 10 runs
of 10-fold cross-validation. All values shown are
the averages of the accuracies from the 10 cross-
validation runs and all results were compared
for statistical significance using the t-test where
applicable.
We use logistic regression as our classifier be-
cause it has been shown that logistic regression
typically has lower asymptotic error than naive
Bayes for multiple classification tasks as well as
for text classification (Ng and Jordan, 2002).
We experimented with an SVM classifier and
found logistic regression to do slightly better.
</bodyText>
<subsectionHeader confidence="0.998645">
5.1 Age Groups
</subsectionHeader>
<bodyText confidence="0.9999819">
The first experiment implements a variation of
the experiment done by Schler et al. (2006).
The differences between the two datasets are
shown in Tables 4. The experiment looks at
three age groups containing a 5-year gap be-
tween each group. Intermediate years were not
included to provide clear differentiation between
the groups because many of the blogs have been
active for several years and this will make it less
common for a blogger to have posts that fall into
two age groups (Schler et al., 2006).
We did not use the same age groups as Schler
et al. because very few blogs on LiveJournal, in
2010, are in the 13-17 age group. Many early de-
mographic studies (Perseus Development, 2004;
Herring et al., 2004) show teens as the dom-
inant age group in all blogs. However, more
recent studies (Nowson and Oberlander, 2006;
Lenhart et al., 2010) show that less teens blog.
Furthermore, an early study on the LiveJournal
</bodyText>
<page confidence="0.994825">
768
</page>
<subsectionHeader confidence="0.61141">
5.2 Social Media and Generation Y
</subsectionHeader>
<bodyText confidence="0.974088411764706">
In the first experiment we used the current age
of a blogger based on when he wrote his last
post. However, the age of a person changes;
someone who was in one age group now will be
in a different age group in 5 years. Furthermore,
a blogger&apos;s posts can fall into two categories de-
pending on his age at the time. Therefore, our
second experiment looks at year of birth instead
of age, as that never changes. In contrast to
Schler et al.&apos;s experiment, our division does not
introduce a gap between age groups, we do bi-
nary classification, and we use significantly less
data.
We approach age prediction as attempting to
identify a shift in writing style over a 14 year
time span from birth years 1975-1988:
For each year X = 1975-1988:
</bodyText>
<listItem confidence="0.535728166666667">
• get 1500 blogs (�33,000 posts) balanced across
years BEFORE X
• get 1500 blogs (�33,000 posts) balanced across
years IN/AFTER X
• Perform binary classification between blogs BE-
FORE X and IN/AFTER X
</listItem>
<bodyText confidence="0.771947368421053">
The experiment focuses on the range of birth
years of bloggers from 1975-1888 to identify at
what point in time, if any, shift(s) in writing
style occurred amongst college-aged students in
generation Y. We were motivated to examine
these years due to the emergence of social me-
dia technologies during that time. Furthermore,
research by Pew Internet (Zickuhr, 2010) has
found that this generation (defined as 1977-
1992 in their research) uses social networking,
blogs, and instant messaging more than their
elders. The experiment is balanced to ensure
that each birth year is evenly represented. We
balance the data by choosing a blogger consec-
utively from each birth year in the category, re-
peating these sweeps through the category until
we have obtained 1500 blogs. We chose to use
1500 blogs from each group because of process-
ing power, time constraints, and the amount of
blogs needed to reasonably sample the age group
at each split. Due to the extensive running time,
we only examined variations of a combination of
Figure 3: Style vs Content: Accuracy from 1975-
1988 for Style (Online-Behavior+Lexical-Stylistic)
vs Content (BOW)
demographic (Kumar et al., 2004) reported that
28.6% of blogs are written by bloggers between
the ages 13-18 whereas based on the current de-
mographic statistics, in 20102, only 6.96% of
blogs are written by that age group and the
number of bloggers in the 31-36 age group in-
creased from 3.9% to 12.08%. We chose the later
age groups because this study is based on blogs
updated in 2009-10 which is 5-6 years later and
thus, the 13-17 age group is now 18-22 and so
on.
We use style-based (lexical-stylistic) and
content-based features (BOW, interests) to
mimic Schler et al.&apos;s experiment as closely as
possible and also experimented with adding
online-behavior features. Our experiment with
style-based and content-based features had an
accuracy of 57%. However, when we added
online-behavior, we increased our accuracy to
67%. A more detailed look at the better results
show that our accuracies are consistently 7%
lower than the original work but we have similar
findings; 18-22s are distinguishable from 38-42s
with accuracy of 94.5%, and 18-22s are distin-
guishable from 28-32s with accuracy of 80.5%.
However, many 38-42s are misclassified as 28-
32s with an accuracy of 72.1%, yielding overall
accuracy of 67%. Due to our findings, we believe
that adding online-behavior features to Schler et
al.&apos;s dataset would improve their results as well.
2http://www.livejournal.com/stats.bml
769
</bodyText>
<figureCaption confidence="0.98528725">
Figure 4: Style and Content: Accuracy from 1975-
1988 using BOW, Online Behavior, and Lexical-
Stylistic features
Figure 5: The impact of social media technologies:
The arrows correspond to the years that generation
Yers were college aged students. The highlighted
years represent the significant years. &apos;Year it be-
came popular (Urmann, 2009)
</figureCaption>
<bodyText confidence="0.999417078947368">
online-behavior, lexical-stylistic, and BOW fea-
tures.
We found accuracy to increase as year of birth
increases in various feature experiments which is
consistent with the trends we found while exam-
ining the distribution of features such as emoti-
cons and lifetime posts in Figure 2. We ex-
perimented with style and content features and
found that both help improve accuracy. Figure 3
shows that content helps more than style, but
style helps more as age decreases. However, as
shown in Figure 4, style and content combined
provided the best results. We found 5 years to
have significant improvement over all prior years
for p G .0005: 1977, 1979, and 1982-1984.
Generation Y is considered the social me-
dia generation, so we decided to examine how
the creation and/or popularity of social media
technologies compared to the years that had a
change in writing style. We looked at many pop-
ular social media technologies such as weblogs,
messaging, and social networking sites. Figure 5
compares the significant years 1977,1979, and
1982-1984 against when each technology was
created or became popular amongst college aged
students. We find that all the technologies had
an effect on one or more of those years. AIM and
weblogs coincide with the earlier shifts at 1977
and 1979, SMS messaging coincide with both
the earlier and later shifts at 1979 and 1982,
and the social networking sites, MySpace and
Facebook coincide with the later shifts of 1982-
1984. On the other hand, web forums and Twit-
ter each coincide with only one outlying year
which suggests that either they had less of an
impact on writing style or, in the case of Twit-
ter, the change has not yet been transferred to
other writing forms.
</bodyText>
<subsectionHeader confidence="0.998278">
5.3 A Closer Look: 1979 and 1984
</subsectionHeader>
<bodyText confidence="0.999973666666667">
Our final experiment provides a more detailed
explanation of the results using various feature
combinations when splitting pre- and post- so-
cial media bloggers by year of birth at two of
the significant years found in the previous sec-
tion; 1979 and 1984. The results for all of the
experiments described are shown in Table 5.
We experimented against two baselines, on-
line behavior and interests. We chose these two
features as baselines because they are both easy
to generate and not lexical in nature. We found
that we were able to exceed the baselines sig-
nificantly using a simple bag-of-words (BOW)
approach. This means the BOW does a better
job of picking topics than interests. We found
that including all 17 features did not do well, but
we were able to get good results using a subset
of the lexical features. We found the best re-
sults to have an accuracy of 79.96% and 81.57%
for 1979 and 1984 respectively using BOW, in-
terests, online behavior, and all lexical-stylistic
features.
In addition, we show accuracy without in-
terests since they are not always available.
</bodyText>
<page confidence="0.986297">
770
</page>
<table confidence="0.999911111111111">
Experiment 1979 1984
Online-Behavior 59.66 61.61
Interests 70.22 74.61
Lexical-Stylistic 65.382 67.282
Slang+Emoticons+Acronyms 60.572 62.102
Online-Behavior + Lexical- 67.162 71.312
Stylistic
Collocations + Syntax Colloca- 53.471 73.452
tions
POS-Collocations + POS- 55.541 74.002
Syntax Collocations
BOW 75.26 77.76
BOW+Online-Behavior 76.39 79.22
BOW + Online-Behavior + 77.45 80.88
Lexical-Stylistic
BOW + Online-Behavior + 74.8 80.36
Lexical-Stylistic + Syntax Collo-
cations
BOW + Online-Behavior 74.73 80.54
+ Lexical-Stylistic + POS-
Collocations + POS Syntax
Collocations
Online-Behavior + Interests + 74.39 77.20
Lexical-Stylistic
BOW + Online-Behavior + In- 79.96 81.57
terests + Lexical-Stylistic
All Features 71.26 74.072
</table>
<tableCaption confidence="0.623904">
Table 5: Feature Accuracy. The top portion refers to
the baselines. The best accuracies are shown in bold.
Unless otherwise marked, all accuracies are statisti-
cally significant at p&lt;=.0005 for both baselines. 1
not statistically significant over Online-Behavior and
Interests. 2 not statistically significant over Interests.
</tableCaption>
<bodyText confidence="0.9932213">
BOW, online-behavior, and lexical-stylistic fea-
tures combined did best achieving accuracy of
77.45% and 80.88% in 1979 and 1984 respec-
tively. This indicates that our classification
method could work well on blogs from any web-
site. It is interesting to note that colloca-
tions and POS-collocations were useful, but only
when we use 1984 as the split which implies that
bloggers born in 1984 and later are more homo-
geneous.
</bodyText>
<sectionHeader confidence="0.997331" genericHeader="conclusions">
6 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.99994904">
We have shown that it is possible to predict the
age group of a person based on style, content,
and online behavior features with good accu-
racy; these are all features that are available
in any blog. While features representing writ-
ing practices that emerged with social media
(e.g., capitalized words, abbreviations, slang)
do not significantly impact age prediction on
their own, these features have a clear change of
value across time, with post-social media blog-
gers using them more often. We found that
the birth years that had a significant change
in writing style corresponded to the birth dates
of college-aged students at the time of the cre-
ation/popularity of social media technologies,
AIM, SMS text messaging, weblogs, Facebook
and MySpace.
In the future we plan on using age and other
metadata to improve results in larger tasks such
as identifying opinion, persuasion and power
by targeting our approach in those tasks to
the identified age of the person. Another ap-
proach that we will experiment with is the use
of ranking, regression, and/or clustering to cre-
ate meaningful age groups.
</bodyText>
<sectionHeader confidence="0.998358" genericHeader="acknowledgments">
7 Acknowledgements
</sectionHeader>
<bodyText confidence="0.999935666666667">
This research was funded by the Office of the
Director of National Intelligence (ODNI), In-
telligence Advanced Research Projects Activity
(IARPA), through the U.S. Army Research Lab.
All statements of fact, opinion or conclusions
contained herein are those of the authors and
should not be construed as representing the of-
ficial views or policies of IARPA, the ODNI or
the U.S. Government.
</bodyText>
<sectionHeader confidence="0.999249" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999226">
Shlomo Argamon, Moshe Koppel, Jonathan Fine,
and Anat Rachel Shimoni. 2003. Gender, genre,
and writing style in formal written texts. TEXT,
23:321–346.
John D. Burger and John C. Henderson. 2006. An
exploration of observable features related to blog-
ger age. In AAAI Spring Symposia.
Marie-Catherine de Marneffe, Bill MacCartney, and
Christopher D. Manning. 2006. Generating typed
dependency parses from phrase structure parses.
In In LREC 2006.
Sumit Goswami, Sudeshna Sarkar, and Mayur
Rustagi. 2009. Stylometric analysis of bloggers&apos;
</reference>
<page confidence="0.972547">
771
</page>
<reference confidence="0.99886176">
age and gender. In International AAAI Confer-
ence on Weblogs and Social Media.
Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard
Pfahringer, Peter Reutemann, and Ian H. Witten.
2009. The weka data mining software: An update.
Susan C. Herring and John C. Paolillo. 2006. Gen-
der and genre variation in weblogs. Journal of
Sociolinguistics, 10(4):439–459.
Susan C. Herring, L.A. Scheidt, S. Bonus, and
E. Wright. 2004. Bridging the gap: A genre anal-
ysis of weblogs. In Proceedings of the 37th Hawaii
International Conference on System Sciences.
Dan Klein and Christopher D. Manning. 2003a. Ac-
curate unlexicalized parsing. In Proceedings of the
1st Annual Meeting of the Association for Com-
putational Linguistics, pages 423–430.
Dan Klein and Christopher D. Manning. 2003b. Fast
exact inference with a factored model for natural
language parsing. In Advances in Neural Informa-
tion Processing Systems, volume 15. MIT Press.
Ravi Kumar, Jasmine Novak, Prabhakar Raghavan,
and Andrew Tomkins. 2004. Structure and evolu-
tion of blogspace. Commun. ACM, 47:35–39, De-
cember.
Amanda Lenhart, Kristen Purcell, Aaron Smith, and
Kathryn Zickuhr. 2010. Social media and young
adults.
Ian Mackinnon. 2006. Age and geographic inferences
of the livejournal social network. In In Statistical
Network Analysis Workshop.
Andrew Y Ng and Michael I Jordan. 2002. On dis-
criminative vs. generative classifiers: A compari-
son of logistic regression and naive bayes. Neural
Information Processing Systems, 2:841–848.
Scott Nowson and Jon Oberlander. 2006. The iden-
tity of bloggers: Openness and gender in personal
weblogs.
James W Pennebaker and Lori D Stone. 2003.
Words of wisdom: language use over the life span.
J Pers Soc Psychol, 85(2):291–301.
J.W. Pennebaker, R.E. Booth, and M.E. Fran-
cis. 2007. Linguistic inquiry and word count:
Liwc2007 D operatorOs manual. Technical report,
LIWC, Austin, TX.
Perseus Development. 2004. The blogging iceberg:
Of 4.12 million hosted weblogs, most little seen
and quickly abandoned. Technical report, Perseus
Development.
R.W. Robins, K. H. Trzesniewski, J.L. Tracy, S.D
Gosling, and J Potter. 2002. Global self-esteem
across the lifespan. Psychology and Aging, 17:423–
434.
Gerard Salton and Christopher Buckley. 1988.
Term-weighting approaches in automatic text re-
trieval. In Information Processing and Manage-
ment, pages 513–523.
J. Schler, M. Koppel, S. Argamon, and J. Pen-
nebaker. 2006. Effects of age and gender on blog-
ging. In AAAI Spring Symposium on Computa-
tional Approaches for Analyzing Weblogs.
Frank Smadja. 1993. Retrieving collocations from
text: Xtract. Computational Linguistics, 19:143–
177.
Jenny Tam and Craig H. Martell. 2009. Age detec-
tion in chat. In Proceedings of the 2009 IEEE In-
ternational Conference on Semantic Computing,
ICSC &apos;09, pages 33–39, Washington, DC, USA.
IEEE Computer Society.
David H. Urmann. 2009. The history of text mes-
saging.
Xiang Yan and Ling Yan. 2006. Gender classification
of weblog authors. In AAAI Spring Symposium
Series on Computation Approaches to Analyzing
Weblogs, pages 228–230.
Kathryn Zickuhr. 2010. Generations 2010.
</reference>
<page confidence="0.997407">
772
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.473617">
<title confidence="0.9704775">Age Prediction in Blogs: A Study of Style, Content, and Behavior in Preand Post-Social Media Generations</title>
<author confidence="0.991745">Sara</author>
<affiliation confidence="0.999913">Department of Computer</affiliation>
<address confidence="0.896953">Columbia New York, NY 10027,</address>
<email confidence="0.998812">sara@cs.columbia.edu</email>
<author confidence="0.994033">Kathleen</author>
<affiliation confidence="0.999953">Department of Computer</affiliation>
<address confidence="0.8971905">Columbia New York, NY 10027,</address>
<email confidence="0.999746">kathy@cs.columbia.edu</email>
<abstract confidence="0.988854157894737">We investigate whether wording, stylistic choices, and online behavior can be used to predict the age category of blog authors. Our hypothesis is that significant changes in writing style distinguish pre-social media bloggers from post-social media bloggers. Through experimentation with a range of years, we found that the birth dates of students in college at the time when social media such as AIM, SMS text messaging, MySpace and Facebook first became popular, enable accurate age prediction. We also show that internet writing characteristics are important features for age prediction, but that lexical content is also needed to produce significantly more accurate results. Our best results allow for 81.57% accuracy.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Shlomo Argamon</author>
<author>Moshe Koppel</author>
<author>Jonathan Fine</author>
<author>Anat Rachel Shimoni</author>
</authors>
<title>Gender, genre, and writing style in formal written texts.</title>
<date>2003</date>
<tech>TEXT,</tech>
<pages>23--321</pages>
<marker>Argamon, Koppel, Fine, Shimoni, 2003</marker>
<rawString>Shlomo Argamon, Moshe Koppel, Jonathan Fine, and Anat Rachel Shimoni. 2003. Gender, genre, and writing style in formal written texts. TEXT, 23:321–346.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John D Burger</author>
<author>John C Henderson</author>
</authors>
<title>An exploration of observable features related to blogger age. In</title>
<date>2006</date>
<publisher>AAAI Spring Symposia.</publisher>
<contexts>
<context position="5227" citStr="Burger and Henderson, 2006" startWordPosition="831" endWordPosition="834">le to predict the correct age within +/-5 years at 98% accuracy. This approach, however, is very different from ours as it requires access to the age of each of the blogger&apos;s friends. Our approach uses only a body of text written by a person along with his blogging behavior to determine which age group he is more closely identified with. Initial research on predicting age without using the ages of friends focuses on identifying important candidate features, including blogging characteristics (e.g., time of post), text features (e.g., length of post), and profile information (e.g., interests) (Burger and Henderson, 2006). They aimed at binary prediction of age, classifying LiveJournal bloggers as either over or under 18, but were unable to automatically predict age with more accuracy than a baseline model that always chose the majority class. In our study on determining the ideal age split we did not find 18 (bloggers born in 1986 in their dataset) to be significant. Prior work by Schler et al. (2006) has examined metadata such as gender and age in blogger.com bloggers. In contrast to our work, they examine bloggers based on their age at the time of the experiment, whether in the 10&apos;s, 20&apos;s or 30&apos;s age bracke</context>
</contexts>
<marker>Burger, Henderson, 2006</marker>
<rawString>John D. Burger and John C. Henderson. 2006. An exploration of observable features related to blogger age. In AAAI Spring Symposia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine de Marneffe</author>
<author>Bill MacCartney</author>
<author>Christopher D Manning</author>
</authors>
<title>Generating typed dependency parses from phrase structure parses. In</title>
<date>2006</date>
<booktitle>In LREC</booktitle>
<marker>de Marneffe, MacCartney, Manning, 2006</marker>
<rawString>Marie-Catherine de Marneffe, Bill MacCartney, and Christopher D. Manning. 2006. Generating typed dependency parses from phrase structure parses. In In LREC 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sumit Goswami</author>
<author>Sudeshna Sarkar</author>
<author>Mayur Rustagi</author>
</authors>
<title>Stylometric analysis of bloggers&apos; age and gender.</title>
<date>2009</date>
<booktitle>In International AAAI Conference on Weblogs and Social Media.</booktitle>
<contexts>
<context position="6808" citStr="Goswami et al. (2009)" startWordPosition="1103" endWordPosition="1106">with relatively high accuracy (above 96%) but many 30s are misclassified as 20s, which results in a overall accuracy of 76.2%. We re-implement Schler et al.&apos;s work in section 5.1 with similar findings. Their work shows that ease of classification is dependent in part on what division is made between age groups and in turn motivates our decision to study whether the creation of social media technologies can be used to find the dividing line(s). Neither Schler et al., nor we, attempt to determine how a person’s writing changes over his lifespan (Pennebaker and Stone, 2003; Robins et al., 2002). Goswami et al. (2009) add to Schler et al.&apos;s approach using the same data and have a 4% increase in accuracy. However, the paper is lacking details and it is entirely unclear how they were able to do this with fewer features than Schler et al. In other work, Tam and Martell (2009) attempt to detect age in the NPS chat corpus between teens and other ages. They use an SVM classifier with only n-grams as features. They achieve &gt; 90% accuracy when classifying teens vs 30s, 40s, 50s, and all adults and achieve at best 76% when using 3 character gram features in classifying teens vs 20s. This work shows that n-grams are</context>
</contexts>
<marker>Goswami, Sarkar, Rustagi, 2009</marker>
<rawString>Sumit Goswami, Sudeshna Sarkar, and Mayur Rustagi. 2009. Stylometric analysis of bloggers&apos; age and gender. In International AAAI Conference on Weblogs and Social Media.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Hall</author>
<author>Eibe Frank</author>
<author>Geoffrey Holmes</author>
<author>Bernhard Pfahringer</author>
<author>Peter Reutemann</author>
<author>Ian H Witten</author>
</authors>
<title>The weka data mining software: An update.</title>
<date>2009</date>
<contexts>
<context position="18929" citStr="Hall et al., 2009" startWordPosition="3178" endWordPosition="3181">the top collocations, we found that younger people tend to use first person singular (I,me) in subject position while older people tend to use first person plural (we) in subject position, both with a variety of verbs. 5 Experiments and Results We ran three separate experiments to determine how well we can predict age: 1. classifying into three distinct age groups (Schler et al. (2006) experiment), 2. binary classification with the split at each birth year from 1975-1988 and 3. Detailed classification on two significant splits from the second experiment. We ran all of our experiments in Weka (Hall et al., 2009) using logistic regression over 10 runs of 10-fold cross-validation. All values shown are the averages of the accuracies from the 10 crossvalidation runs and all results were compared for statistical significance using the t-test where applicable. We use logistic regression as our classifier because it has been shown that logistic regression typically has lower asymptotic error than naive Bayes for multiple classification tasks as well as for text classification (Ng and Jordan, 2002). We experimented with an SVM classifier and found logistic regression to do slightly better. 5.1 Age Groups The</context>
</contexts>
<marker>Hall, Frank, Holmes, Pfahringer, Reutemann, Witten, 2009</marker>
<rawString>Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard Pfahringer, Peter Reutemann, and Ian H. Witten. 2009. The weka data mining software: An update.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Susan C Herring</author>
<author>John C Paolillo</author>
</authors>
<title>Gender and genre variation in weblogs.</title>
<date>2006</date>
<journal>Journal of Sociolinguistics,</journal>
<volume>10</volume>
<issue>4</issue>
<contexts>
<context position="9869" citStr="Herring and Paolillo, 2006" startWordPosition="1635" endWordPosition="1638">r of comments and friends as described in Table 1.1. The first feature, interests, is our only feature that is specific to LiveJournal. Interests appear in the LiveJournal user profile, but are not found on all blog sites. All other online behavior features are typically available in any blog. Figure 1: Number of bloggers in 2010 by year of birth from 1950-1996. A minimal amount of data occurred in years not shown. provides evidence for the need to find a good classification split. Other researchers have investigated weblogs for differences in writing style depending on gender identification (Herring and Paolillo, 2006; Yan and Yan, 2006; Nowson and Oberlander, 2006). Herring et al (2006) found that the typical gender related features were based on genre and independent of author gender. Yan et al (2006) used text categorization and stylistic web features, such as emoticons, to identify gender and achieved 60% F-measure. Nowson et al (2006) employed dictionary and n-gram based content analysis and achieved 91.5% accuracy using an SVM classifier. We also use a supervised machine learning approach, but classification by gender is naturally a binary classification task, while our work requires determining a na</context>
</contexts>
<marker>Herring, Paolillo, 2006</marker>
<rawString>Susan C. Herring and John C. Paolillo. 2006. Gender and genre variation in weblogs. Journal of Sociolinguistics, 10(4):439–459.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Susan C Herring</author>
<author>L A Scheidt</author>
<author>S Bonus</author>
<author>E Wright</author>
</authors>
<title>Bridging the gap: A genre analysis of weblogs.</title>
<date>2004</date>
<booktitle>In Proceedings of the 37th Hawaii International Conference on System Sciences.</booktitle>
<contexts>
<context position="20240" citStr="Herring et al., 2004" startWordPosition="3395" endWordPosition="3398">he differences between the two datasets are shown in Tables 4. The experiment looks at three age groups containing a 5-year gap between each group. Intermediate years were not included to provide clear differentiation between the groups because many of the blogs have been active for several years and this will make it less common for a blogger to have posts that fall into two age groups (Schler et al., 2006). We did not use the same age groups as Schler et al. because very few blogs on LiveJournal, in 2010, are in the 13-17 age group. Many early demographic studies (Perseus Development, 2004; Herring et al., 2004) show teens as the dominant age group in all blogs. However, more recent studies (Nowson and Oberlander, 2006; Lenhart et al., 2010) show that less teens blog. Furthermore, an early study on the LiveJournal 768 5.2 Social Media and Generation Y In the first experiment we used the current age of a blogger based on when he wrote his last post. However, the age of a person changes; someone who was in one age group now will be in a different age group in 5 years. Furthermore, a blogger&apos;s posts can fall into two categories depending on his age at the time. Therefore, our second experiment looks at </context>
</contexts>
<marker>Herring, Scheidt, Bonus, Wright, 2004</marker>
<rawString>Susan C. Herring, L.A. Scheidt, S. Bonus, and E. Wright. 2004. Bridging the gap: A genre analysis of weblogs. In Proceedings of the 37th Hawaii International Conference on System Sciences.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Accurate unlexicalized parsing.</title>
<date>2003</date>
<booktitle>In Proceedings of the 1st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>423--430</pages>
<contexts>
<context position="8634" citStr="Klein and Manning, 2003" startWordPosition="1441" endWordPosition="1444">as written by a unique individual and includes a user profile and up to 25 recent posts written between 2000-2010 with the most recent post being written in 2009-2010. The birth dates of the bloggers range in years from 1940 to 2000 and thus, their age ranges from 10 to 70 in 2010. Figure 1 shows the number of bloggers per age in our group with birth dates from 1950 to 1996. The majority of bloggers on LiveJournal were born between 1978-1989. 4 Methods We pre-processed the data to add Part-ofSpeech tags (POS) and dependencies (de Marneffe et al., 2006) between words using the Stanford Parser (Klein and Manning, 2003a; Klein and Manning, 2003b). The POS and syntactic dependencies were only found for approximately the first 90 words in each sentence. Our classification method investigates 17 different features that fall into three categories: online behavior, lexical-stylistic and lexical-content. All of the features we used are explained in Table 1 along with their trend as age decreases where applicable. Any feature that increased, decreased, or fluctuated should have some positive impact on the accuracy of predicting age. 4.1 Online Behavior and Interests Online behavior features are blog specific, such</context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Dan Klein and Christopher D. Manning. 2003a. Accurate unlexicalized parsing. In Proceedings of the 1st Annual Meeting of the Association for Computational Linguistics, pages 423–430.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Fast exact inference with a factored model for natural language parsing.</title>
<date>2003</date>
<booktitle>In Advances in Neural Information Processing Systems,</booktitle>
<volume>15</volume>
<publisher>MIT Press.</publisher>
<contexts>
<context position="8634" citStr="Klein and Manning, 2003" startWordPosition="1441" endWordPosition="1444">as written by a unique individual and includes a user profile and up to 25 recent posts written between 2000-2010 with the most recent post being written in 2009-2010. The birth dates of the bloggers range in years from 1940 to 2000 and thus, their age ranges from 10 to 70 in 2010. Figure 1 shows the number of bloggers per age in our group with birth dates from 1950 to 1996. The majority of bloggers on LiveJournal were born between 1978-1989. 4 Methods We pre-processed the data to add Part-ofSpeech tags (POS) and dependencies (de Marneffe et al., 2006) between words using the Stanford Parser (Klein and Manning, 2003a; Klein and Manning, 2003b). The POS and syntactic dependencies were only found for approximately the first 90 words in each sentence. Our classification method investigates 17 different features that fall into three categories: online behavior, lexical-stylistic and lexical-content. All of the features we used are explained in Table 1 along with their trend as age decreases where applicable. Any feature that increased, decreased, or fluctuated should have some positive impact on the accuracy of predicting age. 4.1 Online Behavior and Interests Online behavior features are blog specific, such</context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Dan Klein and Christopher D. Manning. 2003b. Fast exact inference with a factored model for natural language parsing. In Advances in Neural Information Processing Systems, volume 15. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ravi Kumar</author>
<author>Jasmine Novak</author>
<author>Prabhakar Raghavan</author>
<author>Andrew Tomkins</author>
</authors>
<title>Structure and evolution of blogspace.</title>
<date>2004</date>
<journal>Commun. ACM,</journal>
<pages>47--35</pages>
<contexts>
<context position="22591" citStr="Kumar et al., 2004" startWordPosition="3796" endWordPosition="3799">that each birth year is evenly represented. We balance the data by choosing a blogger consecutively from each birth year in the category, repeating these sweeps through the category until we have obtained 1500 blogs. We chose to use 1500 blogs from each group because of processing power, time constraints, and the amount of blogs needed to reasonably sample the age group at each split. Due to the extensive running time, we only examined variations of a combination of Figure 3: Style vs Content: Accuracy from 1975- 1988 for Style (Online-Behavior+Lexical-Stylistic) vs Content (BOW) demographic (Kumar et al., 2004) reported that 28.6% of blogs are written by bloggers between the ages 13-18 whereas based on the current demographic statistics, in 20102, only 6.96% of blogs are written by that age group and the number of bloggers in the 31-36 age group increased from 3.9% to 12.08%. We chose the later age groups because this study is based on blogs updated in 2009-10 which is 5-6 years later and thus, the 13-17 age group is now 18-22 and so on. We use style-based (lexical-stylistic) and content-based features (BOW, interests) to mimic Schler et al.&apos;s experiment as closely as possible and also experimented </context>
</contexts>
<marker>Kumar, Novak, Raghavan, Tomkins, 2004</marker>
<rawString>Ravi Kumar, Jasmine Novak, Prabhakar Raghavan, and Andrew Tomkins. 2004. Structure and evolution of blogspace. Commun. ACM, 47:35–39, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amanda Lenhart</author>
<author>Kristen Purcell</author>
<author>Aaron Smith</author>
<author>Kathryn Zickuhr</author>
</authors>
<title>Social media and young adults.</title>
<date>2010</date>
<contexts>
<context position="20372" citStr="Lenhart et al., 2010" startWordPosition="3418" endWordPosition="3421">een each group. Intermediate years were not included to provide clear differentiation between the groups because many of the blogs have been active for several years and this will make it less common for a blogger to have posts that fall into two age groups (Schler et al., 2006). We did not use the same age groups as Schler et al. because very few blogs on LiveJournal, in 2010, are in the 13-17 age group. Many early demographic studies (Perseus Development, 2004; Herring et al., 2004) show teens as the dominant age group in all blogs. However, more recent studies (Nowson and Oberlander, 2006; Lenhart et al., 2010) show that less teens blog. Furthermore, an early study on the LiveJournal 768 5.2 Social Media and Generation Y In the first experiment we used the current age of a blogger based on when he wrote his last post. However, the age of a person changes; someone who was in one age group now will be in a different age group in 5 years. Furthermore, a blogger&apos;s posts can fall into two categories depending on his age at the time. Therefore, our second experiment looks at year of birth instead of age, as that never changes. In contrast to Schler et al.&apos;s experiment, our division does not introduce a ga</context>
</contexts>
<marker>Lenhart, Purcell, Smith, Zickuhr, 2010</marker>
<rawString>Amanda Lenhart, Kristen Purcell, Aaron Smith, and Kathryn Zickuhr. 2010. Social media and young adults.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ian Mackinnon</author>
</authors>
<title>Age and geographic inferences of the livejournal social network. In</title>
<date>2006</date>
<booktitle>In Statistical Network Analysis Workshop.</booktitle>
<contexts>
<context position="4430" citStr="Mackinnon (2006)" startWordPosition="697" endWordPosition="698">82% accuracy. In the remainder of this paper, we first discuss work to date on age prediction for blogs and then present the features that we extracted, which is a larger set than previously explored. We then turn separately to three experiments. In the first, we implement a prior approach to show that we can produce a similar outcome. In the second, we show how the accuracy of age prediction changes over time and pinpoint when major changes occur. In the last experiment, we describe our age prediction experiments in more detail for the most significant years. 2 Related Work In previous work, Mackinnon (2006) , used LiveJournal data to identify a blogger&apos;s age by examining the mean age of his peer group using his social network and not just his immediate friends. They were able to predict the correct age within +/-5 years at 98% accuracy. This approach, however, is very different from ours as it requires access to the age of each of the blogger&apos;s friends. Our approach uses only a body of text written by a person along with his blogging behavior to determine which age group he is more closely identified with. Initial research on predicting age without using the ages of friends focuses on identifyin</context>
</contexts>
<marker>Mackinnon, 2006</marker>
<rawString>Ian Mackinnon. 2006. Age and geographic inferences of the livejournal social network. In In Statistical Network Analysis Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Y Ng</author>
<author>Michael I Jordan</author>
</authors>
<title>On discriminative vs. generative classifiers: A comparison of logistic regression and naive bayes.</title>
<date>2002</date>
<booktitle>Neural Information Processing Systems,</booktitle>
<pages>2--841</pages>
<contexts>
<context position="19417" citStr="Ng and Jordan, 2002" startWordPosition="3253" endWordPosition="3256">ailed classification on two significant splits from the second experiment. We ran all of our experiments in Weka (Hall et al., 2009) using logistic regression over 10 runs of 10-fold cross-validation. All values shown are the averages of the accuracies from the 10 crossvalidation runs and all results were compared for statistical significance using the t-test where applicable. We use logistic regression as our classifier because it has been shown that logistic regression typically has lower asymptotic error than naive Bayes for multiple classification tasks as well as for text classification (Ng and Jordan, 2002). We experimented with an SVM classifier and found logistic regression to do slightly better. 5.1 Age Groups The first experiment implements a variation of the experiment done by Schler et al. (2006). The differences between the two datasets are shown in Tables 4. The experiment looks at three age groups containing a 5-year gap between each group. Intermediate years were not included to provide clear differentiation between the groups because many of the blogs have been active for several years and this will make it less common for a blogger to have posts that fall into two age groups (Schler </context>
</contexts>
<marker>Ng, Jordan, 2002</marker>
<rawString>Andrew Y Ng and Michael I Jordan. 2002. On discriminative vs. generative classifiers: A comparison of logistic regression and naive bayes. Neural Information Processing Systems, 2:841–848.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott Nowson</author>
<author>Jon Oberlander</author>
</authors>
<title>The identity of bloggers: Openness and gender in personal weblogs.</title>
<date>2006</date>
<contexts>
<context position="9918" citStr="Nowson and Oberlander, 2006" startWordPosition="1643" endWordPosition="1646"> 1.1. The first feature, interests, is our only feature that is specific to LiveJournal. Interests appear in the LiveJournal user profile, but are not found on all blog sites. All other online behavior features are typically available in any blog. Figure 1: Number of bloggers in 2010 by year of birth from 1950-1996. A minimal amount of data occurred in years not shown. provides evidence for the need to find a good classification split. Other researchers have investigated weblogs for differences in writing style depending on gender identification (Herring and Paolillo, 2006; Yan and Yan, 2006; Nowson and Oberlander, 2006). Herring et al (2006) found that the typical gender related features were based on genre and independent of author gender. Yan et al (2006) used text categorization and stylistic web features, such as emoticons, to identify gender and achieved 60% F-measure. Nowson et al (2006) employed dictionary and n-gram based content analysis and achieved 91.5% accuracy using an SVM classifier. We also use a supervised machine learning approach, but classification by gender is naturally a binary classification task, while our work requires determining a natural dividing point. 3 Data Collection Our corpu</context>
<context position="20349" citStr="Nowson and Oberlander, 2006" startWordPosition="3414" endWordPosition="3417"> containing a 5-year gap between each group. Intermediate years were not included to provide clear differentiation between the groups because many of the blogs have been active for several years and this will make it less common for a blogger to have posts that fall into two age groups (Schler et al., 2006). We did not use the same age groups as Schler et al. because very few blogs on LiveJournal, in 2010, are in the 13-17 age group. Many early demographic studies (Perseus Development, 2004; Herring et al., 2004) show teens as the dominant age group in all blogs. However, more recent studies (Nowson and Oberlander, 2006; Lenhart et al., 2010) show that less teens blog. Furthermore, an early study on the LiveJournal 768 5.2 Social Media and Generation Y In the first experiment we used the current age of a blogger based on when he wrote his last post. However, the age of a person changes; someone who was in one age group now will be in a different age group in 5 years. Furthermore, a blogger&apos;s posts can fall into two categories depending on his age at the time. Therefore, our second experiment looks at year of birth instead of age, as that never changes. In contrast to Schler et al.&apos;s experiment, our division </context>
</contexts>
<marker>Nowson, Oberlander, 2006</marker>
<rawString>Scott Nowson and Jon Oberlander. 2006. The identity of bloggers: Openness and gender in personal weblogs.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James W Pennebaker</author>
<author>Lori D Stone</author>
</authors>
<title>Words of wisdom: language use over the life span.</title>
<date>2003</date>
<journal>J Pers Soc Psychol,</journal>
<volume>85</volume>
<issue>2</issue>
<contexts>
<context position="6763" citStr="Pennebaker and Stone, 2003" startWordPosition="1095" endWordPosition="1098">uish between bloggers in the 10&apos;s and in the 30&apos;s with relatively high accuracy (above 96%) but many 30s are misclassified as 20s, which results in a overall accuracy of 76.2%. We re-implement Schler et al.&apos;s work in section 5.1 with similar findings. Their work shows that ease of classification is dependent in part on what division is made between age groups and in turn motivates our decision to study whether the creation of social media technologies can be used to find the dividing line(s). Neither Schler et al., nor we, attempt to determine how a person’s writing changes over his lifespan (Pennebaker and Stone, 2003; Robins et al., 2002). Goswami et al. (2009) add to Schler et al.&apos;s approach using the same data and have a 4% increase in accuracy. However, the paper is lacking details and it is entirely unclear how they were able to do this with fewer features than Schler et al. In other work, Tam and Martell (2009) attempt to detect age in the NPS chat corpus between teens and other ages. They use an SVM classifier with only n-grams as features. They achieve &gt; 90% accuracy when classifying teens vs 30s, 40s, 50s, and all adults and achieve at best 76% when using 3 character gram features in classifying t</context>
</contexts>
<marker>Pennebaker, Stone, 2003</marker>
<rawString>James W Pennebaker and Lori D Stone. 2003. Words of wisdom: language use over the life span. J Pers Soc Psychol, 85(2):291–301.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J W Pennebaker</author>
<author>R E Booth</author>
<author>M E Francis</author>
</authors>
<title>Linguistic inquiry and word count:</title>
<date>2007</date>
<booktitle>Liwc2007 D operatorOs manual. Technical report, LIWC,</booktitle>
<location>Austin, TX.</location>
<contexts>
<context position="6050" citStr="Pennebaker et al., 2007" startWordPosition="973" endWordPosition="976">s chose the majority class. In our study on determining the ideal age split we did not find 18 (bloggers born in 1986 in their dataset) to be significant. Prior work by Schler et al. (2006) has examined metadata such as gender and age in blogger.com bloggers. In contrast to our work, they examine bloggers based on their age at the time of the experiment, whether in the 10&apos;s, 20&apos;s or 30&apos;s age bracket. They identify interesting changes in content and style features across categories, in which they include blogging words (e.g., “LOL&amp;quot;), all defined by the Linguistic Inquiry and Word Count (LIWC) (Pennebaker et al., 2007). They did not use characteristics of online behavior (e.g., friends). They can distinguish between bloggers in the 10&apos;s and in the 30&apos;s with relatively high accuracy (above 96%) but many 30s are misclassified as 20s, which results in a overall accuracy of 76.2%. We re-implement Schler et al.&apos;s work in section 5.1 with similar findings. Their work shows that ease of classification is dependent in part on what division is made between age groups and in turn motivates our decision to study whether the creation of social media technologies can be used to find the dividing line(s). Neither Schler </context>
</contexts>
<marker>Pennebaker, Booth, Francis, 2007</marker>
<rawString>J.W. Pennebaker, R.E. Booth, and M.E. Francis. 2007. Linguistic inquiry and word count: Liwc2007 D operatorOs manual. Technical report, LIWC, Austin, TX.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Perseus Development</author>
</authors>
<title>The blogging iceberg: Of 4.12 million hosted weblogs, most little seen and quickly abandoned.</title>
<date>2004</date>
<tech>Technical report, Perseus Development.</tech>
<contexts>
<context position="20217" citStr="Development, 2004" startWordPosition="3393" endWordPosition="3394">er et al. (2006). The differences between the two datasets are shown in Tables 4. The experiment looks at three age groups containing a 5-year gap between each group. Intermediate years were not included to provide clear differentiation between the groups because many of the blogs have been active for several years and this will make it less common for a blogger to have posts that fall into two age groups (Schler et al., 2006). We did not use the same age groups as Schler et al. because very few blogs on LiveJournal, in 2010, are in the 13-17 age group. Many early demographic studies (Perseus Development, 2004; Herring et al., 2004) show teens as the dominant age group in all blogs. However, more recent studies (Nowson and Oberlander, 2006; Lenhart et al., 2010) show that less teens blog. Furthermore, an early study on the LiveJournal 768 5.2 Social Media and Generation Y In the first experiment we used the current age of a blogger based on when he wrote his last post. However, the age of a person changes; someone who was in one age group now will be in a different age group in 5 years. Furthermore, a blogger&apos;s posts can fall into two categories depending on his age at the time. Therefore, our seco</context>
</contexts>
<marker>Development, 2004</marker>
<rawString>Perseus Development. 2004. The blogging iceberg: Of 4.12 million hosted weblogs, most little seen and quickly abandoned. Technical report, Perseus Development.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R W Robins</author>
<author>K H Trzesniewski</author>
<author>J L Tracy</author>
<author>S D Gosling</author>
<author>J Potter</author>
</authors>
<title>Global self-esteem across the lifespan. Psychology and Aging,</title>
<date>2002</date>
<pages>17--423</pages>
<contexts>
<context position="6785" citStr="Robins et al., 2002" startWordPosition="1099" endWordPosition="1102"> 10&apos;s and in the 30&apos;s with relatively high accuracy (above 96%) but many 30s are misclassified as 20s, which results in a overall accuracy of 76.2%. We re-implement Schler et al.&apos;s work in section 5.1 with similar findings. Their work shows that ease of classification is dependent in part on what division is made between age groups and in turn motivates our decision to study whether the creation of social media technologies can be used to find the dividing line(s). Neither Schler et al., nor we, attempt to determine how a person’s writing changes over his lifespan (Pennebaker and Stone, 2003; Robins et al., 2002). Goswami et al. (2009) add to Schler et al.&apos;s approach using the same data and have a 4% increase in accuracy. However, the paper is lacking details and it is entirely unclear how they were able to do this with fewer features than Schler et al. In other work, Tam and Martell (2009) attempt to detect age in the NPS chat corpus between teens and other ages. They use an SVM classifier with only n-grams as features. They achieve &gt; 90% accuracy when classifying teens vs 30s, 40s, 50s, and all adults and achieve at best 76% when using 3 character gram features in classifying teens vs 20s. This work</context>
</contexts>
<marker>Robins, Trzesniewski, Tracy, Gosling, Potter, 2002</marker>
<rawString>R.W. Robins, K. H. Trzesniewski, J.L. Tracy, S.D Gosling, and J Potter. 2002. Global self-esteem across the lifespan. Psychology and Aging, 17:423– 434.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerard Salton</author>
<author>Christopher Buckley</author>
</authors>
<title>Term-weighting approaches in automatic text retrieval.</title>
<date>1988</date>
<booktitle>In Information Processing and Management,</booktitle>
<pages>513--523</pages>
<contexts>
<context position="17743" citStr="Salton and Buckley, 1988" startWordPosition="2981" endWordPosition="2985">efers to the position of the interest in its list blogger.com livejournal.com download 2004 2010 year # of Blogs 19320 11521 # of Posts1 1.4 million 256,000 # of words1 295 million 50 million age 13·17 23·27 33·37 18·22 28·32 38·42 size 8240 8086 2994 3518 5549 2454 majority 43.8% (13-17) 48.2% (22-32) baseline Table 4: Statistics for Schler et al.�s data (blogger.com) vs our data (livejournal.com) 1 is approximate amount. occurred in total, defined as collocation or term frequency (tf), the number of blogs the collocation occurred in, defined as blog frequency (bf), and variations of TF*IDF (Salton and Buckley, 1988) where we tried using inverse blog frequency and inverse post frequency as the value for IDF. In addition, we also experimented with looking at a different number of important words and collocations ranging from the top 100-300 terms and experimented without pruning. None of these variations improved accuracy in our experiments, however, and thus, were dropped from further experimentation. Table 3 shows the top words for each age group; older people tend to use words such as “house” and “old&amp;quot; frequently and younger people talk about “school”. In our analysis of the top collocations, we found t</context>
</contexts>
<marker>Salton, Buckley, 1988</marker>
<rawString>Gerard Salton and Christopher Buckley. 1988. Term-weighting approaches in automatic text retrieval. In Information Processing and Management, pages 513–523.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Schler</author>
<author>M Koppel</author>
<author>S Argamon</author>
<author>J Pennebaker</author>
</authors>
<title>Effects of age and gender on blogging.</title>
<date>2006</date>
<booktitle>In AAAI Spring Symposium on Computational Approaches for Analyzing Weblogs.</booktitle>
<contexts>
<context position="5615" citStr="Schler et al. (2006)" startWordPosition="899" endWordPosition="902">es of friends focuses on identifying important candidate features, including blogging characteristics (e.g., time of post), text features (e.g., length of post), and profile information (e.g., interests) (Burger and Henderson, 2006). They aimed at binary prediction of age, classifying LiveJournal bloggers as either over or under 18, but were unable to automatically predict age with more accuracy than a baseline model that always chose the majority class. In our study on determining the ideal age split we did not find 18 (bloggers born in 1986 in their dataset) to be significant. Prior work by Schler et al. (2006) has examined metadata such as gender and age in blogger.com bloggers. In contrast to our work, they examine bloggers based on their age at the time of the experiment, whether in the 10&apos;s, 20&apos;s or 30&apos;s age bracket. They identify interesting changes in content and style features across categories, in which they include blogging words (e.g., “LOL&amp;quot;), all defined by the Linguistic Inquiry and Word Count (LIWC) (Pennebaker et al., 2007). They did not use characteristics of online behavior (e.g., friends). They can distinguish between bloggers in the 10&apos;s and in the 30&apos;s with relatively high accurac</context>
<context position="18699" citStr="Schler et al. (2006)" startWordPosition="3141" endWordPosition="3144">er, and thus, were dropped from further experimentation. Table 3 shows the top words for each age group; older people tend to use words such as “house” and “old&amp;quot; frequently and younger people talk about “school”. In our analysis of the top collocations, we found that younger people tend to use first person singular (I,me) in subject position while older people tend to use first person plural (we) in subject position, both with a variety of verbs. 5 Experiments and Results We ran three separate experiments to determine how well we can predict age: 1. classifying into three distinct age groups (Schler et al. (2006) experiment), 2. binary classification with the split at each birth year from 1975-1988 and 3. Detailed classification on two significant splits from the second experiment. We ran all of our experiments in Weka (Hall et al., 2009) using logistic regression over 10 runs of 10-fold cross-validation. All values shown are the averages of the accuracies from the 10 crossvalidation runs and all results were compared for statistical significance using the t-test where applicable. We use logistic regression as our classifier because it has been shown that logistic regression typically has lower asympt</context>
<context position="20030" citStr="Schler et al., 2006" startWordPosition="3357" endWordPosition="3360">, 2002). We experimented with an SVM classifier and found logistic regression to do slightly better. 5.1 Age Groups The first experiment implements a variation of the experiment done by Schler et al. (2006). The differences between the two datasets are shown in Tables 4. The experiment looks at three age groups containing a 5-year gap between each group. Intermediate years were not included to provide clear differentiation between the groups because many of the blogs have been active for several years and this will make it less common for a blogger to have posts that fall into two age groups (Schler et al., 2006). We did not use the same age groups as Schler et al. because very few blogs on LiveJournal, in 2010, are in the 13-17 age group. Many early demographic studies (Perseus Development, 2004; Herring et al., 2004) show teens as the dominant age group in all blogs. However, more recent studies (Nowson and Oberlander, 2006; Lenhart et al., 2010) show that less teens blog. Furthermore, an early study on the LiveJournal 768 5.2 Social Media and Generation Y In the first experiment we used the current age of a blogger based on when he wrote his last post. However, the age of a person changes; someone </context>
</contexts>
<marker>Schler, Koppel, Argamon, Pennebaker, 2006</marker>
<rawString>J. Schler, M. Koppel, S. Argamon, and J. Pennebaker. 2006. Effects of age and gender on blogging. In AAAI Spring Symposium on Computational Approaches for Analyzing Weblogs.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank Smadja</author>
</authors>
<title>Retrieving collocations from text: Xtract. Computational Linguistics,</title>
<date>1993</date>
<pages>177</pages>
<contexts>
<context position="15787" citStr="Smadja, 1993" startWordPosition="2635" endWordPosition="2636">rds increased as bloggers got younger. Slang and punctuation, which excludes the emoticons and acronyms counted in the other features, increased as well, but not as significantly. The length of sentences decreased as bloggers got younger and the number of links/images varied across all years as shown in Figure 2(c). 4.3 Lexical - Content The last category of features described in Table 1.3 consists of collocations and words, which are content based lexical terms. The top words are produced using a typical “bag-of-words” approach. The top collocations are computed using a system called Xtract (Smadja, 1993). We use Xtract to obtain important lexical collocations, syntactic collocations, and POS collocations as features from our text. Syntactic collocations refer to significant word pairs that have specific syntactic dependencies such as subject/verb and verb/object. Due to the length of time it takes to run this program, we ran Xtract on 1500 random blogs from each age group and examined the first 1000 words per blog. We looked at 1.5 million words in total and found approximately 2500-2700 words that were repeated more than 50 times. We extracted the top 200 words and collocations sorted by pos</context>
</contexts>
<marker>Smadja, 1993</marker>
<rawString>Frank Smadja. 1993. Retrieving collocations from text: Xtract. Computational Linguistics, 19:143– 177.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny Tam</author>
<author>Craig H Martell</author>
</authors>
<title>Age detection in chat.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 IEEE International Conference on Semantic Computing, ICSC &apos;09,</booktitle>
<pages>33--39</pages>
<publisher>IEEE Computer Society.</publisher>
<location>Washington, DC, USA.</location>
<contexts>
<context position="7068" citStr="Tam and Martell (2009)" startWordPosition="1153" endWordPosition="1156"> in part on what division is made between age groups and in turn motivates our decision to study whether the creation of social media technologies can be used to find the dividing line(s). Neither Schler et al., nor we, attempt to determine how a person’s writing changes over his lifespan (Pennebaker and Stone, 2003; Robins et al., 2002). Goswami et al. (2009) add to Schler et al.&apos;s approach using the same data and have a 4% increase in accuracy. However, the paper is lacking details and it is entirely unclear how they were able to do this with fewer features than Schler et al. In other work, Tam and Martell (2009) attempt to detect age in the NPS chat corpus between teens and other ages. They use an SVM classifier with only n-grams as features. They achieve &gt; 90% accuracy when classifying teens vs 30s, 40s, 50s, and all adults and achieve at best 76% when using 3 character gram features in classifying teens vs 20s. This work shows that n-grams are useful features for detecting age and it is difficult to detect differences between consecutive groups such as teens and 20s, and this 764 Journal blogs containing age. We represent age as the year a person was born and not his age at the time of the experime</context>
</contexts>
<marker>Tam, Martell, 2009</marker>
<rawString>Jenny Tam and Craig H. Martell. 2009. Age detection in chat. In Proceedings of the 2009 IEEE International Conference on Semantic Computing, ICSC &apos;09, pages 33–39, Washington, DC, USA. IEEE Computer Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David H Urmann</author>
</authors>
<title>The history of text messaging.</title>
<date>2009</date>
<contexts>
<context position="24289" citStr="Urmann, 2009" startWordPosition="4067" endWordPosition="4068"> 38-42s are misclassified as 28- 32s with an accuracy of 72.1%, yielding overall accuracy of 67%. Due to our findings, we believe that adding online-behavior features to Schler et al.&apos;s dataset would improve their results as well. 2http://www.livejournal.com/stats.bml 769 Figure 4: Style and Content: Accuracy from 1975- 1988 using BOW, Online Behavior, and LexicalStylistic features Figure 5: The impact of social media technologies: The arrows correspond to the years that generation Yers were college aged students. The highlighted years represent the significant years. &apos;Year it became popular (Urmann, 2009) online-behavior, lexical-stylistic, and BOW features. We found accuracy to increase as year of birth increases in various feature experiments which is consistent with the trends we found while examining the distribution of features such as emoticons and lifetime posts in Figure 2. We experimented with style and content features and found that both help improve accuracy. Figure 3 shows that content helps more than style, but style helps more as age decreases. However, as shown in Figure 4, style and content combined provided the best results. We found 5 years to have significant improvement ov</context>
</contexts>
<marker>Urmann, 2009</marker>
<rawString>David H. Urmann. 2009. The history of text messaging.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiang Yan</author>
<author>Ling Yan</author>
</authors>
<title>Gender classification of weblog authors.</title>
<date>2006</date>
<booktitle>In AAAI Spring Symposium Series on Computation Approaches to Analyzing Weblogs,</booktitle>
<pages>228--230</pages>
<contexts>
<context position="9888" citStr="Yan and Yan, 2006" startWordPosition="1639" endWordPosition="1642"> described in Table 1.1. The first feature, interests, is our only feature that is specific to LiveJournal. Interests appear in the LiveJournal user profile, but are not found on all blog sites. All other online behavior features are typically available in any blog. Figure 1: Number of bloggers in 2010 by year of birth from 1950-1996. A minimal amount of data occurred in years not shown. provides evidence for the need to find a good classification split. Other researchers have investigated weblogs for differences in writing style depending on gender identification (Herring and Paolillo, 2006; Yan and Yan, 2006; Nowson and Oberlander, 2006). Herring et al (2006) found that the typical gender related features were based on genre and independent of author gender. Yan et al (2006) used text categorization and stylistic web features, such as emoticons, to identify gender and achieved 60% F-measure. Nowson et al (2006) employed dictionary and n-gram based content analysis and achieved 91.5% accuracy using an SVM classifier. We also use a supervised machine learning approach, but classification by gender is naturally a binary classification task, while our work requires determining a natural dividing poin</context>
</contexts>
<marker>Yan, Yan, 2006</marker>
<rawString>Xiang Yan and Ling Yan. 2006. Gender classification of weblog authors. In AAAI Spring Symposium Series on Computation Approaches to Analyzing Weblogs, pages 228–230.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kathryn Zickuhr</author>
</authors>
<date>2010</date>
<contexts>
<context position="21784" citStr="Zickuhr, 2010" startWordPosition="3667" endWordPosition="3668">th years 1975-1988: For each year X = 1975-1988: • get 1500 blogs (�33,000 posts) balanced across years BEFORE X • get 1500 blogs (�33,000 posts) balanced across years IN/AFTER X • Perform binary classification between blogs BEFORE X and IN/AFTER X The experiment focuses on the range of birth years of bloggers from 1975-1888 to identify at what point in time, if any, shift(s) in writing style occurred amongst college-aged students in generation Y. We were motivated to examine these years due to the emergence of social media technologies during that time. Furthermore, research by Pew Internet (Zickuhr, 2010) has found that this generation (defined as 1977- 1992 in their research) uses social networking, blogs, and instant messaging more than their elders. The experiment is balanced to ensure that each birth year is evenly represented. We balance the data by choosing a blogger consecutively from each birth year in the category, repeating these sweeps through the category until we have obtained 1500 blogs. We chose to use 1500 blogs from each group because of processing power, time constraints, and the amount of blogs needed to reasonably sample the age group at each split. Due to the extensive run</context>
</contexts>
<marker>Zickuhr, 2010</marker>
<rawString>Kathryn Zickuhr. 2010. Generations 2010.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>