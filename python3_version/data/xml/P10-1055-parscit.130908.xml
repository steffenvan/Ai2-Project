<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000309">
<title confidence="0.97204">
The Importance of Rule Restrictions in CCG
</title>
<author confidence="0.999197">
Marco Kuhlmann Alexander Koller Giorgio Satta
</author>
<affiliation confidence="0.993081333333333">
Dept. of Linguistics and Philology Cluster of Excellence Dept. of Information Engineering
Uppsala University Saarland University University of Padua
Uppsala, Sweden Saarbrücken, Germany Padua, Italy
</affiliation>
<sectionHeader confidence="0.976925" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.996363615384615">
Combinatory Categorial Grammar (CCG)
is generally construed as a fully lexicalized
formalism, where all grammars use one and
the same universal set of rules, and cross-
linguistic variation is isolated in the lexicon.
In this paper, we show that the weak gener-
ative capacity of this ‘pure’ form of CCG is
strictly smaller than that of CCG with gram-
mar-specific rules, and of other mildly con-
text-sensitive grammar formalisms, includ-
ing Tree Adjoining Grammar (TAG). Our
result also carries over to a multi-modal
extension of CCG.
</bodyText>
<sectionHeader confidence="0.998762" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999441738461539">
Combinatory Categorial Grammar (CCG) (Steed-
man, 2001; Steedman and Baldridge, 2010) is an
expressive grammar formalism with formal roots
in combinatory logic (Curry et al., 1958) and links
to the type-logical tradition of categorial grammar
(Moortgat, 1997). It has been successfully used for
a wide range of practical tasks, such as data-driven
parsing (Hockenmaier and Steedman, 2002; Clark
and Curran, 2007), wide-coverage semantic con-
struction (Bos et al., 2004), and the modelling of
syntactic priming (Reitter et al., 2006).
It is well-known that CCG can generate lan-
guages that are not context-free (which is neces-
sary to capture natural languages), but can still
be parsed in polynomial time. Specifically, Vijay-
Shanker and Weir (1994) identified a version of
CCG that is weakly equivalent to Tree Adjoining
Grammar (TAG) (Joshi and Schabes, 1997) and
other mildly context-sensitive grammar formalisms,
and can generate non-context-free languages such
as anbncn. The generative capacity of CCG is com-
monly attributed to its flexible composition rules,
which allow it to model more complex word orders
that context-free grammar can.
The discussion of the (weak and strong) gener-
ative capacity of CCG and TAG has recently been
revived (Hockenmaier and Young, 2008; Koller and
Kuhlmann, 2009). In particular, Koller and Kuhl-
mann (2009) have shown that CCGs that are pure
(i.e., they can only use generalized composition
rules, and there is no way to restrict the instances
of these rules that may be used) and first-order
(i.e., all argument categories are atomic) can not
generate anbncn. This shows that the generative
capacity of at least first-order CCG crucially relies
on its ability to restrict rule instantiations, and is at
odds with the general conception of CCG as a fully
lexicalized formalism, in which all grammars use
one and the same set of universal rules. A question
then is whether the result carries over to pure CCG
with higher-order categories.
In this paper, we answer this question to the pos-
itive: We show that the weak generative capacity of
general pure CCG is still strictly smaller than that
of the formalism considered by Vijay-Shanker and
Weir (1994); composition rules can only achieve
their full expressive potential if their use can be
restricted. Our technical result is that every lan-
guage L that can be generated by a pure CCG has
a context-free sublanguage L&apos; C_ L such that every
string in L is a permutation of a string in L&apos;, and
vice versa. This means that anbncn, for instance,
cannot be generated by pure CCG, as it does not
have any (non-trivial) permutation-equivalent sub-
languages. Conversely, we show that there are still
languages that can be generated by pure CCG but
not by context-free grammar.
We then show that our permutation language
lemma also holds for pure multi-modal CCG as
defined by Baldridge and Kruijff (2003), in which
the use of rules can be controlled through the lex-
icon entries by assigning types to slashes. Since
this extension was intended to do away with
the need for grammar-specific rule restrictions, it
comes as quite a surprise that pure multi-modal
</bodyText>
<page confidence="0.971945">
534
</page>
<note confidence="0.9437415">
Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 534–543,
Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999549952380952">
CCG in the style of Baldridge and Kruijff (2003) is
still less expressive than the CCG formalism used
by Vijay-Shanker and Weir (1994). This means that
word order in CCG cannot be fully lexicalized with
the current formal tools; some ordering constraints
must be specified via language-specific combina-
tion rules and not in lexicon entries. On the other
hand, as pure multi-modal CCG has been success-
fully applied to model the syntax of a variety of
natural languages, another way to read our results
is as contributions to a discussion about the exact
expressiveness needed to model natural language.
The remainder of this paper is structured as fol-
lows. In Section 2, we introduce the formalism
of pure CCG that we consider in this paper, and
illustrate the relevance of rule restrictions. We then
study the generative capacity of pure CCG in Sec-
tion 3; this section also presents our main result. In
Section 4, we show that this result still holds for
multi-modal CCG. Section 5 concludes the paper
with a discussion of the relevance of our findings.
</bodyText>
<sectionHeader confidence="0.99207" genericHeader="method">
2 Combinatory Categorial Grammar
</sectionHeader>
<bodyText confidence="0.999887666666667">
We start by providing formal definitions for cat-
egories, syntactic rules, and grammars, and then
discuss the relevance of rule restrictions for CCG.
</bodyText>
<subsectionHeader confidence="0.887868">
2.1 Categories
</subsectionHeader>
<bodyText confidence="0.999882739130435">
Given a finite set A of atomic categories, the set of
categories over A is the smallest set C such that
A C_ C, and (x/y), (x\y) E C whenever x, y E C.
A category x/y represents a function that seeks a
string with category y to the right (indicated by the
forward slash) and returns a new string with cat-
egory x; a category x\y instead seeks its argument
to the left (indicated by the backward slash). In
the remainder of this paper, we use lowercase sans-
serif letters such as x, y, z as variables for categor-
ies, and the vertical bar l as a variable for slashes.
In order to save some parentheses, we understand
slashes as left-associative operators, and write a
category such as (x/y)\z as x/y\z.
The list of arguments of a category c is defined
recursively as follows: If c is atomic, then it has no
arguments. If c = xly for some categories x and y,
then the arguments of c are the slashed category ly,
plus the arguments of x. We number the arguments
of a category from outermost to innermost. The
arity of a category is the number of its arguments.
The target of a category c is the atomic category
that remains when stripping c of its arguments.
</bodyText>
<figure confidence="0.387968333333333">
x/y y x forward application &gt;
y x\y x backward application &lt;
x/y y/z x/z forward harmonic composition &gt;B
y\z x\y x\z backward harmonic composition &lt;B
x/y y\z x\z forward crossed composition &gt;Bx
y/z x\y x/z backward crossed composition &lt;Bx
</figure>
<figureCaption confidence="0.999253">
Figure 1: The core set of rules of CCG.
</figureCaption>
<subsectionHeader confidence="0.996455">
2.2 Rules
</subsectionHeader>
<bodyText confidence="0.999990307692308">
The syntactic rules of CCG are directed versions
of combinators in the sense of combinatory logic
(Curry et al., 1958). Figure 1 lists a core set of
commonly assumed rules, derived from functional
application and the B combinator, which models
functional composition. When talking about these
rules, we refer to the premise containing the argu-
ment ly as the primary premise, and to the other
premise as the secondary premise of the rule.
The rules in Figure 1 can be generalized into
composition rules of higher degrees. These are
defined as follows, where n &gt; 0 and # is a variable
for a sequence of n arguments.
</bodyText>
<equation confidence="0.86418">
x/y y# x# generalized forward composition &gt;n
y# x\y x# generalized backward composition &lt;n
</equation>
<bodyText confidence="0.999959727272728">
We call the value n the degree of the composition
rule. Note that the rules in Figure 1 are the special
cases for n = 0 and n = 1.
Apart from the core rules given in Figure 1, some
versions of CCG also use rules derived from the S
and T combinators of combinatory logic, called
substitution and type-raising, the latter restricted
to the lexicon. However, since our main point of
reference in this paper, the CCG formalism defined
by Vijay-Shanker and Weir (1994), does not use
such rules, we will not consider them here, either.
</bodyText>
<subsectionHeader confidence="0.999077">
2.3 Grammars and Derivations
</subsectionHeader>
<bodyText confidence="0.998005">
With the set of rules in place, we can define a
pure combinatory categorial grammar (PCCG) as
a construct G = (A, E, L, s), where A is an alpha-
bet of atomic categories, s E A is a distinguished
atomic category called the final category, E is a
finite set of terminal symbols, and L is a finite rela-
tion between symbols in E and categories over A,
called the lexicon. The elements of the lexicon L
are called lexicon entries, and we represent them
using the notation a �- x, where a E E and x
is a category over A. A category that occurs in a
lexicon entry is called a lexical category.
</bodyText>
<page confidence="0.997117">
535
</page>
<bodyText confidence="0.999812071428571">
A derivation in a grammar G can be represen-
ted as a derivation tree as follows. Given a string
w E E*, we choose a lexicon entry for each oc-
currence of a symbol in w, line up the respective
lexical categories from left to right, and apply ad-
missible rules to adjacent pairs of categories. After
the application of a rule, only the conclusion is
available for future applications. We iterate this
process until we end up with a single category. The
string w is called the yield of the resulting deriva-
tion tree. A derivation tree is complete, if the last
category is the final category of G. The language
generated by G, denoted by L(G), is formed by
the yields of all complete derivation trees.
</bodyText>
<subsectionHeader confidence="0.994444">
2.4 Degree Restrictions
</subsectionHeader>
<bodyText confidence="0.998485939393939">
Work on CCG generally assumes an upper bound
on the degree of composition rules that can be used
in derivations. We also employ this restriction, and
only consider grammars with compositions of some
bounded (but arbitrary) degree n &gt; 0.1 CCG with
unbounded-degree compositions is more express-
ive than bounded-degree CCG or TAG (Weir and
Joshi, 1988).
Bounded-degree grammars have a number of
useful properties, one of which we mention here.
The following lemma rephrases Lemma 3.1 in
Vijay-Shanker and Weir (1994).
Lemma 1 For every grammar G, every argument
in a derivation of G is the argument of some lexical
category of G.
As a consequence, there is only a finite number
of categories that can occur as arguments in some
derivation. In the presence of a bound on the degree
of composition rules, this implies the following:
Lemma 2 For every grammar G, there is a finite
number of categories that can occur as secondary
premises in derivations of G.
Proof. The arity of a secondary premise c can be
written as m + n, where m is the arity of the first
argument of the corresponding primary premise,
and n is the degree of the rule applied. Since each
argument is an argument of some lexical category
of G (Lemma 1), and since n is assumed to be
bounded, both m and n are bounded. Hence, there
is a bound on the number of choices for c. 0
Note that the number of categories that can occur
as primary premises is generally unbounded even
in a grammar with bounded degree.
</bodyText>
<footnote confidence="0.977531">
1For practical grammars, n &lt; 4.
</footnote>
<subsectionHeader confidence="0.994356">
2.5 Rule Restrictions
</subsectionHeader>
<bodyText confidence="0.999990904761905">
The rule set of pure CCG is universal: the differ-
ence between the grammars of different languages
should be restricted to different choices of categor-
ies in the lexicon. This is what makes pure CCG
a lexicalized grammar formalism (Steedman and
Baldridge, 2010). However, most practical CCG
grammars rely on the possibility to exclude or re-
strict certain rules. For example, Steedman (2001)
bans the rule of forward crossed composition from
his grammar of English, and stipulates that the rule
of backward crossed composition may be applied
only if both of its premises share the common tar-
get category s, representing sentences. Exclusions
and restrictions of rules are also assumed in much
of the language-theoretic work on CCG. In partic-
ular, they are essential for the formalism used in
the aforementioned equivalence proof for CCG and
TAG (Vijay-Shanker and Weir, 1994).
To illustrate the formal relevance of rule restric-
tions, suppose that we wanted to write a pure CCG
that generates the language
</bodyText>
<equation confidence="0.964648">
L3 = {anbncn I n &gt; 1},
</equation>
<bodyText confidence="0.962287291666667">
which is not context-free. An attempt could be
G1 = ({s,a,b,c},{a,b,c },L,s),
where the lexicon L is given as follows:
a�- a, b�- s/c\a , b i b/c\a ,
b i s/c/b\a , b i s/c/b\a , c�- c.
From a few sample derivations like the one given
in Figure 2a, we can convince ourselves that G1
generates all strings of the form anbncn, for any
n &gt; 1. However, a closer inspection reveals that it
also generates other, unwanted strings—in partic-
ular, strings of the form (ab)ncn, as witnessed by
the derivation given in Figure 2b.
Now suppose that we would have a way to only
allow those instances of generalized composition in
which the secondary premise has the form b/c/b\a
or b/c\a. Then the compositions
b/c/b b/c 1 and s/c/b b/c 1
b/c/c s/c/c
would be disallowed, and it is not hard to see
that G1 would generate exactly anbncn.
As we will show in this paper, our attempt to
capture L3 with a pure CCG grammar failed not
only because we could not think of one: L3 cannot
be generated by any pure CCG.
</bodyText>
<page confidence="0.98587">
536
</page>
<figure confidence="0.999808411764706">
a...................
a
a...........
a
a...
a
b...
s/c/b\a
s/c/c/b\a
b.......
b/c/b\a
&lt;0
&lt;0
&gt;3 b...............
b/c\a
s/c/c/c
s/c/b
&lt;0
s/c/c/b
s/c/c/c\a
&gt;2 c.......................
c
&gt;0 c...........................
c
&gt;0 c...............................
c
&gt;0
s/c/c
s/c
(a) Derivation of the string aaabbbccc.
s
c...................
c
&gt;0
ab
..
....
..
..
....
....
.. ..
a s/c/b\a
s/c/b
ab
..
.. ..
a b/c\a
&lt;0 &lt;0
b/c/b b/c &gt;1
b/c
&lt;0
&gt;1
c...........
c
&gt;0
c.......................
c
&gt;0
b...
b/c/b\a
a...
a
b/c/c
s/c/c
s/c
s
(b) Derivation of the string abababccc.
</figure>
<figureCaption confidence="0.997089">
Figure 2: Two derivations of the grammar G1.
</figureCaption>
<sectionHeader confidence="0.918606" genericHeader="method">
3 The Generative Capacity of Pure CCG
</sectionHeader>
<bodyText confidence="0.964337714285714">
We will now develop a formal argument showing
that rule restrictions increase the weak generative
capacity of CCG. We will first prove that pure CCG
is still more expressive than context-free grammar.
We will then spend the rest of this section working
towards the result that pure CCG is strictly less
expressive than CCG with rule restrictions. Our
main technical result will be the following:
Theorem 1 Every language that can be generated
by a pure CCG has a Parikh-equivalent context-free
sublanguage.
Here, two languages L and L&apos; are called Parikh-
equivalent if every string in L is the permutation
of a string in L&apos; and vice versa.
</bodyText>
<subsectionHeader confidence="0.999333">
3.1 CFG ¨ PCCG
</subsectionHeader>
<bodyText confidence="0.995263916666667">
Proposition 1 The class of languages generated
by pure CCG properly includes the class of context-
free languages.
Proof. To see the inclusion, it suffices to note that
pure CCG when restricted to application rules is
the same as AB-grammar, the classical categorial
formalism investigated by Ajdukiewicz and Bar-
Hillel (Bar-Hillel et al., 1964). This formalism is
weakly equivalent to context-free grammar.
To see that the inclusion is proper, we can go
back to the grammar G1 that we gave in Section 2.5.
We have already discussed that the language L3 is
included in L(G1). We can also convince ourselves
that all strings generated by the grammar G1 have
an equal number of as, bs and cs. Consider now
the regular language R = a*b*c*. From our ob-
servations, it follows that L(G1) n R = L3. Since
context-free languages are closed under intersec-
tion with regular languages, we find that L(G1)
can be context-free only if L3 is. Since L3 is not
context-free, we therefore conclude that L(G1) is
not context-free, either. 0
Two things are worth noting. First, our result shows
that the ability of CCG to generate non-context-free
languages does not hinge on the availability of sub-
stitution and type-raising rules: The derivations
of G1 only use generalized compositions. Neither
does it require the use of functional argument cat-
egories: The grammar G1 is first-order in the sense
of Koller and Kuhlmann (2009).
Second, it is important to note that if the com-
position degree n is restricted to 0 or 1, pure CCG
actually collapses to context-free expressive power.
This is clear for n = 0 because of the equivalence
to AB grammar. For n = 1, observe that the arity
of the result of a composition is at most as high as
</bodyText>
<page confidence="0.98521">
537
</page>
<bodyText confidence="0.999902444444444">
that of each premise. This means that the arity of
any derived category is bounded by the maximal
arity of lexical categories in the grammar, which
together with Lemma 1 implies that there is only
a finite set of derivable categories. The set of all
valid derivations can then be simulated by a con-
text-free grammar. In the presence of rules with
n &gt; 2, the arities of derived categories can grow
unboundedly.
</bodyText>
<subsectionHeader confidence="0.998812">
3.2 Active and Inactive Arguments
</subsectionHeader>
<bodyText confidence="0.9826005">
In the remainder of this section, we will develop
the proof of Theorem 1, and use it to show that the
generative capacity of PCCG is strictly smaller than
that of CCG with rule restrictions. For the proof,
we adopt a certain way to view the information
flow in CCG derivations. Consider the following
instance of forward harmonic composition:
a/b b/c =:� a/c
This rule should be understood as obtaining its con-
clusion a/c from the primary premise a/b by the
removal of the argument /b and the subsequent
transfer of the argument /c from the secondary
premise. With this picture in mind, we will view
the two occurrences of /c in the secondary premise
and in the conclusion as two occurrences of one
and the same argument. Under this perspective,
in a given derivation, an argument has a lifespan
that starts in a lexical category and ends in one
of two ways: either in the primary or in the sec-
ondary premise of a composition rule. If it ends
in a primary premise, it is because it is matched
against a subcategory of the corresponding second-
ary premise; this is the case for the argument /b
in the example above. We will refer to such argu-
ments as active. If an argument ends its life in a
secondary premise, it is because it is consumed as
part of a higher-order argument. This is the case
for the argument /c in the secondary premise of
the following rule instance:
a/(b/c) b/c/d =:� a/d
(Recall that we assume that slashes are left-associ-
ative.) We will refer to such arguments as inactive.
Note that the status of an argument as either active
or inactive is not determined by the grammar, but
depends on a concrete derivation.
The following lemma states an elementary prop-
erty in connection with active and inactive argu-
ments, which we will refer to as segmentation:
Lemma 3 Every category that occurs in a CCG
derivation has the general form aao, where a is an
atomic category, a is a sequence of inactive argu-
ments, and o is a sequence of active arguments.
Proof. The proof is by induction on the depth of a
node in the derivation. The property holds for the
root (which is labeled with the final category), and
is transferred from conclusions to premises. 0
</bodyText>
<subsectionHeader confidence="0.989848">
3.3 Transformation
</subsectionHeader>
<bodyText confidence="0.999993813953488">
The fundamental reason for why the example gram-
mar G1 from Section 2.5 overgenerates is that in
the absence of rule restrictions, we have no means
to control the point in a derivation at which a cat-
egory combines with its arguments. Consider the
examples in Figure 2: It is because we cannot en-
sure that the bs finish combining with the other bs
before combining with the cs that the undesirable
word order in Figure 2b has a derivation. To put
it as a slogan: Permuting the words allows us to
saturate arguments prematurely.
In this section, we show that this property applies
to all pure CCGs. More specifically, we show that,
in a derivation of a pure CCG, almost all active
arguments of a category can be saturated before
that category is used as a secondary premise; at
most one active argument must be transferred to
the conclusion of that premise. Conversely, any
derivation that still contains a category with at least
two active arguments can be transformed into a
new derivation that brings us closer to the special
property just characterized.
We formalize this transformation by means of a
system of rewriting rules in the sense of Baader and
Nipkow (1998). The rules are given in Figure 3. To
see how they work, let us consider the first rule, R1;
the other ones are symmetric. This rules states that,
whenever we see a derivation in which a category
of the form x/y (here marked as A) is combined
with a category of the form yo/z (marked as B),
and the result of this combination is combined with
a category of the form zy (C), then the resulting
category can also be obtained by ‘rotating’ the de-
rivation to first saturate /z by combining B with C,
and only then do the combination with A. When ap-
plying these rotations exhaustively, we end up with
a derivation in which almost all active arguments of
a category are saturated before that category is used
as a secondary premise. Applying the transform-
ation to the derivation in Figure 2a, for instance,
yields the derivation in Figure 2b.
We need the following result for some of the
lemmas we prove below. We call a node in a deriv-
</bodyText>
<page confidence="0.982516">
538
</page>
<figure confidence="0.999680888888889">
A x/y B yO/z R1 yO/z zy B yO/z A xny R2 yO/z zy
xO/z C zy H) x/y yOy xO/z C zy H) yOy xny
xOy
xOy xOy xOy
A x/y B yOnz R3 zy yOnz B yOnz A xny R4 zy yOnz
H) x/y H)
C zy xOnz yOy C zy xOnz yOy xny
xOy
xOy xOy xOy
</figure>
<figureCaption confidence="0.9859155">
Figure 3: Rewriting rules used in the transformation. Here, y represents a (possibly empty) sequence of
arguments, and O represents a sequence of arguments in which the first (outermost) argument is active.
</figureCaption>
<bodyText confidence="0.989560142857143">
ation critical if its corresponding category contains
more than one active argument and it is the second-
ary premise of a rule. We say that u is a highest
critical node if there is no other critical node whose
distance to the root is shorter.
Lemma 4 If u is a highest critical node, then we
can apply one of the transformation rules to the
grandparent of u.
Proof. Suppose that the category at u has the form
yO/z, where /z is an active argument, and the first
argument in O is active as well. (The other possible
case, in which the relevant occurrence has the form
yOnz, can be treated symmetrically.) Since u is a
secondary premise, it is involved in an inference of
one of the following two forms:
x/y yO/z yO/z xny
xO/z xO/z
Since u is a highest critical node, the conclusion
of this inference is not a critical node itself; in
particular, it is not a secondary premise. Therefore,
the above inferences can be extended as follows:
</bodyText>
<equation confidence="0.880855333333333">
x/y yO/z
xO/z zy
xOy
</equation>
<bodyText confidence="0.995834857142857">
These partial derivations match the left-hand side of
the rewriting rules R1 and R2, respectively. Hence,
we can apply a rewriting rule to the derivation. 0
We now show that the transformation is well-
defined, in the sense that it terminates and trans-
forms derivations of a grammar G into new deriva-
tions of G.
Lemma 5 The rewriting of a derivation tree ends
after a finite number of steps.
Proof. We assign natural numbers to the nodes
of a derivation tree as follows. Each leaf node
is assigned the number 0. For an inner node u,
which corresponds to the conclusion of a composi-
tion rule, let m, n be the numbers assigned to the
nodes corresponding to the primary and second-
ary premise, respectively. Then u is assigned the
number 1 C 2m C n. Suppose now that we have as-
sociated premise A with the number x, premise B
with the number y, and premise C with the num-
ber z. It is then easy to verify that the conclusion
of the partial derivation on the left-hand side of
each rule has the value 3 C 4x C 2y C z, while
the conclusion of the right-hand side has the value
2 C 2x C 2y C z. Thus, each step decreases the
value of a derivation tree under our assignment by
the amount 1 C 2x. Since this value is positive for
all choices of x, the rewriting ends after a finite
number of steps. 0
To convince ourselves that our transformation does
not create ill-formed derivations, we need to show
that none of the rewriting rules necessitates the use
of composition operations whose degree is higher
than the degree of the operations used in the ori-
ginal derivation.
Lemma 6 Applying the rewriting rules from the
top down does not increase the degree of the com-
position operations.
Proof. The first composition rule used in the left-
hand side of each rewriting rule has degree jOj C 1,
the second rule has degree jyj; the first rule used in
the right-hand side has degree jyj, the second rule
has degree jOj C jyj. To prove the claim, it suffices
to show that jyj &lt; 1. This is a consequence of the
following two observations.
1. In the category xOy, the arguments in y occur
on top of the arguments in O, the first of which is
active. Using the segmentation property stated in
Lemma 3, we can therefore infer that y does not
contain any inactive arguments.
</bodyText>
<equation confidence="0.665201666666667">
yO/z xny
xO/z zy
xOy
</equation>
<page confidence="0.990294">
539
</page>
<bodyText confidence="0.996215416666666">
2. Because we apply rules top-down, premise B
is a highest critical node in the derivation (by
Lemma 4). This means that the category at
premise C contains at most one active argument;
otherwise, premise C would be a critical node
closer to the root than premise B. 0
We conclude that, if we rewrite a derivation d of G
top-down until exhaustion, then we obtain a new
valid derivation d&apos;. We call all derivations d&apos; that
we can build in this way transformed. It is easy to
see that a derivation is transformed if and only if it
contains no critical nodes.
</bodyText>
<subsectionHeader confidence="0.995019">
3.4 Properties of Transformed Derivations
</subsectionHeader>
<bodyText confidence="0.999326333333333">
The special property established by our transform-
ation has consequences for the generative capacity
of pure CCG. In particular, we will now show that
the set of all transformed derivations of a given
grammar yields a context-free language. The cru-
cial lemma is the following:
</bodyText>
<construct confidence="0.945416333333333">
Lemma 7 For every grammar G, there is some
k &gt; 0 such that no category in a transformed
derivation of G has arity greater than k.
</construct>
<bodyText confidence="0.998158414634147">
Proof. The number of inactive arguments in the
primary premise of a rule does not exceed the num-
ber of inactive arguments in the conclusion. In
a transformed derivation, a symmetric property
holds for active arguments: Since each second-
ary premise contains at most one active argument,
the number of active arguments in the conclusion
of a rule is not greater than the number of act-
ive arguments in its primary premise. Taken to-
gether, this implies that the arity of a category that
occurs in a transformed derivation is bounded by
the sum of the maximal arity of a lexical category
(which bounds the number of active arguments),
and the maximal arity of a secondary premise
(which bounds the number of inactive arguments).
Both of these values are bounded in G. 0
Lemma 8 The yields corresponding to the set of
all transformed derivations of a pure CCG form a
context-free language.
Proof. Let G be a pure CCG. We construct a con-
text-free grammar GT that generates the yields of
the set of all transformed derivations of G.
As the set of terminals of GT , we use the set of
terminals of G. To form the set of nonterminals, we
take all categories that can occur in a transformed
derivation of G, and mark each argument as either
‘active’ (+) or ‘inactive’ (—), in all possible ways
that respect the segmentation property stated in
Lemma 3. Note that, because of Lemma 7 and
Lemma 1, the set of nonterminals is finite. As the
start symbol, we use s, the final category of G.
The set of productions of GT is constructed as
follows. For each lexicon entry a �- c of G, we in-
clude all productions of the form x --* a, where x
is some marked version of c. These productions
represent all valid guesses about the activity of the
arguments of c during a derivation of G. The re-
maining productions encode all valid instantiations
of composition rules, keeping track of active and
inactive arguments to prevent derivations with crit-
ical nodes. More specifically, they have the form
</bodyText>
<equation confidence="0.662052">
xP --* x=y+ yP or xP --* yP x\y+ ,
</equation>
<bodyText confidence="0.9929215">
where the arguments in the y-part of the secondary
premise are all marked as inactive, the sequence P
contains at most one argument marked as active,
and the annotations of the left-hand side nonter-
minal are copied over from the corresponding an-
notations on the right-hand side.
The correctness of the construction of GT can be
proved by induction on the length of a transformed
derivation of G on the one hand, and the length of
a derivation of GT on the other hand. 0
</bodyText>
<subsectionHeader confidence="0.994031">
3.5 PCCG ¨ CCG
</subsectionHeader>
<bodyText confidence="0.974214521739131">
We are now ready to prove our main result, repeated
here for convenience.
Theorem 1 Every language that can be generated
by a pure CCG grammar has a Parikh-equivalent
context-free sublanguage.
Proof. Let G be a pure CCG, and let LT be the
set of yields of the transformed derivations of G.
Inspecting the rewriting rules, it is clear that every
string of L(G) is the permutation of a string in LT :
the transformation only rearranges the yields. By
Lemma 8, we also know that LT is context-free.
Since every transformed derivation is a valid deriv-
ation of G, we have LT c L(G).
As an immediate consequence, we find:
Proposition 2 The class of languages generated
by pure CCG cannot generate all languages that
can be generated by CCG with rule restrictions.
Proof. The CCG formalism considered by Vijay-
Shanker and Weir (1994) can generate the non-con-
text-free language L3. However, the only Parikh-
equivalent sublanguage of that language is L3 itself.
From Theorem 1, we therefore conclude that L3
cannot be generated by pure CCG. 0
</bodyText>
<page confidence="0.98767">
540
</page>
<bodyText confidence="0.99615325">
In the light of the equivalence result established
by Vijay-Shanker and Weir (1994), this means that
pure CCG cannot generate all languages that can
be generated by TAG.
</bodyText>
<table confidence="0.808732428571428">
x/?y y x forward application
y x\?y x backward application
x/oy y/oz# x/oz# forward harmonic composition
x/xy y\xz# x\xz# forward crossed composition
y\oz# x\oy x\oz# backward harmonic composition
y/xz# x\xy x/xz# backward crossed composition
4 Multi-Modal CCG
</table>
<bodyText confidence="0.999784428571429">
We now extend Theorem 1 to multi-modal CCG.
We will see that at least for a popular version
of multi-modal CCG, the B&amp;K-CCG formalism
presented by Baldridge and Kruijff (2003), the
proof can be adapted quite straightforwardly. This
means that even B&amp;K-CCG becomes less express-
ive when rule restrictions are disallowed.
</bodyText>
<subsectionHeader confidence="0.941951">
4.1 Multi-Modal CCG
</subsectionHeader>
<bodyText confidence="0.999971424242424">
The term ‘multi-modal CCG’ (MM-CCG) refers to
a family of extensions to CCG which attempt to
bring some of the expressive power of Categorial
Type Logic (Moortgat, 1997) into CCG. Slashes in
MM-CCG have slash types, and rules can be restric-
ted to only apply to arguments that have slashes
of the correct type. The idea behind this extension
is that many constraints that in ordinary CCG can
only be expressed in terms of rule restrictions can
now be specified in the lexicon entries by giving
the slashes the appropriate types.
The most widely-known version of multi-modal
CCG is the formalism defined by Baldridge and
Kruijff (2003) and used by Steedman and Baldridge
(2010); we refer to it as B&amp;K-CCG. This formalism
uses an inventory of four slash types, { *, x, o, • I
arranged in a simple type hierarchy: * is the most
general type, • the most specific, and x and o are
in between. Every slash in a B&amp;K-CCG lexicon is
annotated with one of these slash types.
The combinatory rules in B&amp;K-CCG, given in
Figure 4, are defined to be sensitive to the slash
types. In particular, slashes with the types o and x
can only be eliminated by harmonic and crossed
compositions, respectively.2 Thus, a grammar
writer can constrain the application of harmonic
and crossed composition rules to certain categor-
ies by assigning appropriate types to the slashes
of this category in the lexicon. Application rules
apply to slashes of any type. As before, we call
an MM-CCG grammar pure if it only uses applic-
ation and generalized compositions, and does not
provide means to restrict rule applications.
</bodyText>
<footnote confidence="0.970593333333333">
2Our definitions of generalized harmonic and crossed com-
position are the same as the ones used by Hockenmaier and
Young (2008), but see the discussion in Section 4.3.
</footnote>
<figureCaption confidence="0.996976">
Figure 4: Rules in B&amp;K-CCG.
</figureCaption>
<subsectionHeader confidence="0.980762">
4.2 Rule Restrictions in B&amp;K-CCG
</subsectionHeader>
<bodyText confidence="0.978228575">
We will now see what happens to the proof of The-
orem 1 in the context of pure B&amp;K-CCG. There
is only one point in the entire proof that could be
damaged by the introduction of slash types, and
that is the result that if a transformation rule from
Figure 3 is applied to a correct derivation, then the
result is also grammatical. For this, it must not
only be the case that the degree on the composition
operations is preserved (Lemma 6), but also that
the transformed derivation remains consistent with
the slash types. Slash types make the derivation
process sensitive to word order by restricting the
use of compositions to categories with the appropri-
ate type, and the transformation rules permute the
order of the words in the string. There is a chance
therefore that a transformed derivation might not
be grammatical in B&amp;K-CCG.
We now show that this does not actually happen,
for rule R3; the other three rules are analogous.
Using s1, s2, s3 as variables for the relevant slash
types, rule R3 appears in B&amp;K-CCG as follows:
x/s1y yIs2w#\s3z
xIs2w#y
Because the original derivation is correct, we know
that, if the slash of w is forward, then s1 and s2 are
subtypes of o; if the slash is backward, they are
subtypes of x. A similar condition holds for s3 and
the first slash in y; if y is empty, then s3 can be
anything because the second rule is an application.
After the transformation, the argument /s1y is
used to compose with yIs2w#y. The direction of
the slash in front of the w is the same as before,
so the (harmonic or crossed) composition is still
compatible with the slash types s1 and s2. An
analogous argument shows that the correctness of
combining \s3z with y carries over from the left to
the right-hand side. Thus the transformation maps
grammatical derivations into grammatical deriva-
tions. The rest of the proof in Section 3 continues
to work literally, so we have the following result:
</bodyText>
<figure confidence="0.937921166666667">
zy xIs2w#\s3z
R3
= x/s1y
yIs2w#y
xIs2w#y
zy yIs2w#\s3z
</figure>
<page confidence="0.966694">
541
</page>
<construct confidence="0.735758666666667">
Theorem 2 Every language that can be generated
by a pure B&amp;K-CCG grammar contains a Parikh-
equivalent context-free sublanguage.
</construct>
<bodyText confidence="0.999882888888889">
This means that pure B&amp;K-CCG is just as unable
to generate L3 as pure CCG is. In other words,
the weak generative capacity of CCG with rule
restrictions, and in particular that of the formalism
considered by Vijay-Shanker and Weir (1994), is
strictly greater than the generative capacity of pure
B&amp;K-CCG—although we conjecture (but cannot
prove) that pure B&amp;K-CCG is still more expressive
than pure non-modal CCG.
</bodyText>
<subsectionHeader confidence="0.995631">
4.3 Towards More Expressive MM-CCGs
</subsectionHeader>
<bodyText confidence="0.999993226415094">
To put the result of Theorem 2 into perspective, we
will now briefly consider ways in which B&amp;K-CCG
might be modified in order to obtain a pure multi-
modal CCG that is weakly equivalent to CCG in
the style of Vijay-Shanker and Weir (1994). Such
a modification would have to break the proof in
Section 4.2, which is harder than it may seem at
first glance. For instance, simply assuming a more
complex type system will not do it, because the
arguments \s3z and /s1y are eliminated using the
same rules in the original and the transformed deriv-
ations, so if the derivation step was valid before, it
will still be valid after the transformation. Instead,
we believe that it is necessary to make the composi-
tion rules sensitive to the categories inside 0 and y
instead of only the arguments \s3z and /s1y, and
we can see two ways how to do this.
First, one could imagine a version of multi-
modal CCG with unary modalities that can be used
to mark certain category occurrences. In such an
MM-CCG, the composition rules for a certain slash
type could be made sensitive to the presence or
absence of unary modalities in 0. Say for instance
that the slash type s1 in the modalized version of
R3 in Section 4.2 would require that no category in
the secondary argument is marked with the unary
modality ‘❑’, but 0 contains a category marked
with ‘❑’. Then the transformed derivation would
be ungrammatical.
A second approach concerns the precise defin-
ition of the generalized composition rules, about
which there is a surprising degree of disagreement.
We have followed Hockenmaier and Young (2008)
in classifying instances of generalized forward
composition as harmonic if the innermost slash of
the secondary argument is forward and crossed if
it is backward. However, generalized forward com-
position is sometimes only accepted as harmonic
if all slashes of the secondary argument are for-
ward (see e.g. Baldridge (2002) (40, 41), Steedman
(2001) (19)). At the same time, based on the prin-
ciple that CCG rules should be derived from proofs
of Categorial Type Logic as Baldridge (2002) does,
it can be argued that generalized composition rules
of the form x/y y/z\w =:� x/z\w, which we
have considered as harmonic, should actually be
classified as crossed, due to the presence of a slash
of opposite directionality in front of the w. This
definition would break our proof. Thus our res-
ult might motivate further research on the ‘correct’
definition of generalized composition rules, which
might then strengthen the generative capacity of
pure MM-CCG.
</bodyText>
<sectionHeader confidence="0.999448" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.9999778">
In this paper, we have shown that the weak generat-
ive capacity of pure CCG and even pure B&amp;K-CCG
crucially depends on the ability to restrict the ap-
plication of individual rules. This means that these
formalisms cannot be fully lexicalized, in the sense
that certain languages can only be described by
selecting language-specific rules.
Our result generalizes Koller and Kuhlmann’s
(2009) result for pure first-order CCG. Our proof
is not as different as it looks at first glance, as
their construction of mapping a CCG derivation to
a valency tree and back to a derivation provides a
different transformation on derivation trees. Our
transformation is also technically related to the nor-
mal form construction for CCG parsing presented
by Eisner (1996).
Of course, at the end of the day, the issue that is
more relevant to computational linguistics than a
formalism’s ability to generate artificial languages
such as L3 is how useful it is for modeling natural
languages. CCG, and multi-modal CCG in partic-
ular, has a very good track record for this. In this
sense, our formal result can also be understood as
a contribution to a discussion about the expressive
power that is needed to model natural languages.
</bodyText>
<sectionHeader confidence="0.998665" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999459">
We have profited enormously from discussions with
Jason Baldridge and Mark Steedman, and would
also like to thank the anonymous reviewers for their
detailed comments.
</bodyText>
<page confidence="0.995526">
542
</page>
<sectionHeader confidence="0.995845" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999906316455696">
Franz Baader and Tobias Nipkow. 1998. Term Rewrit-
ing and All That. Cambridge University Press.
Jason Baldridge and Geert-Jan M. Kruijff. 2003.
Multi-modal Combinatory Categorial Grammar.
In Proceedings of the Tenth Conference of the
European Chapter of the Association for Compu-
tational Linguistics (EACL), pages 211–218, Bud-
apest, Hungary.
Jason Baldridge. 2002. Lexically Specified Deriva-
tional Control in Combinatory Categorial Grammar.
Ph.D. thesis, University of Edinburgh.
Yehoshua Bar-Hillel, Haim Gaifman, and Eli Shamir.
1964. On categorial and phrase structure gram-
mars. In Language and Information: Selected Es-
says on their Theory and Application, pages 99–115.
Addison-Wesley.
Johan Bos, Stephen Clark, Mark Steedman, James R.
Curran, and Julia Hockenmaier. 2004. Wide-
coverage semantic representations from a CCG
parser. In Proceedings of the 20th International
Conference on Computational Linguistics (COL-
ING), pages 176–182, Geneva, Switzerland.
Stephen Clark and James Curran. 2007. Wide-
coverage efficient statistical parsing with CCG
and log-linear models. Computational Linguistics,
33(4).
Haskell B. Curry, Robert Feys, and William Craig.
1958. Combinatory Logic. Volume 1. Studies in
Logic and the Foundations of Mathematics. North-
Holland.
Jason Eisner. 1996. Efficient normal-form parsing
for combinatory categorial grammar. In Proceed-
ings of the 34th Annual Meeting of the Association
for Computational Linguistics (ACL), pages 79–86,
Santa Cruz, CA, USA.
Julia Hockenmaier and Mark Steedman. 2002. Gen-
erative models for statistical parsing with Combin-
atory Categorial Grammar. In Proceedings of the
40th Annual Meeting of the Association for Com-
putational Linguistics (ACL), pages 335–342, Phil-
adelphia, USA.
Julia Hockenmaier and Peter Young. 2008. Non-local
scrambling: the equivalence of TAG and CCG revis-
ited. In Proceedings of the 9th Internal Workshop on
Tree Adjoining Grammars and Related Formalisms
(TAG+9), Tübingen, Germany.
Aravind K. Joshi and Yves Schabes. 1997. Tree-
Adjoining Grammars. In Grzegorz Rozenberg and
Arto Salomaa, editors, Handbook of Formal Lan-
guages, volume 3, pages 69–123. Springer.
Alexander Koller and Marco Kuhlmann. 2009. De-
pendency trees and the strong generative capacity of
CCG. In Proceedings of the Twelfth Conference of
the European Chapter of the Association for Compu-
tational Linguistics (EACL), pages 460–468, Athens,
Greece.
Michael Moortgat. 1997. Categorial type logics. In
Handbook of Logic and Language, chapter 2, pages
93–177. Elsevier.
David Reitter, Julia Hockenmaier, and Frank Keller.
2006. Priming effects in combinatory categorial
grammar. In Proceedings of the 2006 Conference on
Empirical Methods in Natural Language Processing
(EMNLP), pages 308–316, Sydney, Australia.
Mark Steedman and Jason Baldridge. 2010. Combin-
atory categorial grammar. In R. Borsley and K. Bor-
jars, editors, Non-Transformational Syntax. Black-
well. Draft 7.0, to appear.
Mark Steedman. 2001. The Syntactic Process. MIT
Press.
K. Vijay-Shanker and David J. Weir. 1994. The equi-
valence of four extensions of context-free grammars.
Mathematical Systems Theory, 27(6):511–546.
David J. Weir and Aravind K. Joshi. 1988. Combinat-
ory categorial grammars: Generative power and rela-
tionship to linear context-free rewriting systems. In
Proceedings of the 26th Annual Meeting of the As-
sociation for Computational Linguistics, pages 278–
285, Buffalo, NY, USA.
</reference>
<page confidence="0.998922">
543
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.629431">
<title confidence="0.999856">The Importance of Rule Restrictions in CCG</title>
<author confidence="0.999988">Marco Kuhlmann Alexander Koller Giorgio Satta</author>
<affiliation confidence="0.998824">Dept. of Linguistics and Philology Cluster of Excellence Dept. of Information Engineering Uppsala University Saarland University University of Padua</affiliation>
<address confidence="0.984926">Uppsala, Sweden Saarbrücken, Germany Padua, Italy</address>
<abstract confidence="0.994422692307692">Categorial Grammar is generally construed as a fully lexicalized formalism, where all grammars use one and the same universal set of rules, and crosslinguistic variation is isolated in the lexicon. In this paper, we show that the weak genercapacity of this ‘pure’ form of smaller than that of grammar-specific rules, and of other mildly context-sensitive grammar formalisms, includ- Tree Adjoining Grammar Our result also carries over to a multi-modal</abstract>
<intro confidence="0.659061">of</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Franz Baader</author>
<author>Tobias Nipkow</author>
</authors>
<title>Term Rewriting and All That.</title>
<date>1998</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="19792" citStr="Baader and Nipkow (1998)" startWordPosition="3425" endWordPosition="3428">e show that this property applies to all pure CCGs. More specifically, we show that, in a derivation of a pure CCG, almost all active arguments of a category can be saturated before that category is used as a secondary premise; at most one active argument must be transferred to the conclusion of that premise. Conversely, any derivation that still contains a category with at least two active arguments can be transformed into a new derivation that brings us closer to the special property just characterized. We formalize this transformation by means of a system of rewriting rules in the sense of Baader and Nipkow (1998). The rules are given in Figure 3. To see how they work, let us consider the first rule, R1; the other ones are symmetric. This rules states that, whenever we see a derivation in which a category of the form x/y (here marked as A) is combined with a category of the form yo/z (marked as B), and the result of this combination is combined with a category of the form zy (C), then the resulting category can also be obtained by ‘rotating’ the derivation to first saturate /z by combining B with C, and only then do the combination with A. When applying these rotations exhaustively, we end up with a de</context>
</contexts>
<marker>Baader, Nipkow, 1998</marker>
<rawString>Franz Baader and Tobias Nipkow. 1998. Term Rewriting and All That. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Baldridge</author>
<author>Geert-Jan M Kruijff</author>
</authors>
<title>Multi-modal Combinatory Categorial Grammar.</title>
<date>2003</date>
<booktitle>In Proceedings of the Tenth Conference of the European Chapter of the Association for Computational Linguistics (EACL),</booktitle>
<pages>211--218</pages>
<location>Budapest, Hungary.</location>
<contexts>
<context position="3719" citStr="Baldridge and Kruijff (2003)" startWordPosition="591" endWordPosition="594">ial if their use can be restricted. Our technical result is that every language L that can be generated by a pure CCG has a context-free sublanguage L&apos; C_ L such that every string in L is a permutation of a string in L&apos;, and vice versa. This means that anbncn, for instance, cannot be generated by pure CCG, as it does not have any (non-trivial) permutation-equivalent sublanguages. Conversely, we show that there are still languages that can be generated by pure CCG but not by context-free grammar. We then show that our permutation language lemma also holds for pure multi-modal CCG as defined by Baldridge and Kruijff (2003), in which the use of rules can be controlled through the lexicon entries by assigning types to slashes. Since this extension was intended to do away with the need for grammar-specific rule restrictions, it comes as quite a surprise that pure multi-modal 534 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 534–543, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics CCG in the style of Baldridge and Kruijff (2003) is still less expressive than the CCG formalism used by Vijay-Shanker and Weir (1994). This means that wo</context>
<context position="29514" citStr="Baldridge and Kruijff (2003)" startWordPosition="5204" endWordPosition="5207">ed by pure CCG. 0 540 In the light of the equivalence result established by Vijay-Shanker and Weir (1994), this means that pure CCG cannot generate all languages that can be generated by TAG. x/?y y x forward application y x\?y x backward application x/oy y/oz# x/oz# forward harmonic composition x/xy y\xz# x\xz# forward crossed composition y\oz# x\oy x\oz# backward harmonic composition y/xz# x\xy x/xz# backward crossed composition 4 Multi-Modal CCG We now extend Theorem 1 to multi-modal CCG. We will see that at least for a popular version of multi-modal CCG, the B&amp;K-CCG formalism presented by Baldridge and Kruijff (2003), the proof can be adapted quite straightforwardly. This means that even B&amp;K-CCG becomes less expressive when rule restrictions are disallowed. 4.1 Multi-Modal CCG The term ‘multi-modal CCG’ (MM-CCG) refers to a family of extensions to CCG which attempt to bring some of the expressive power of Categorial Type Logic (Moortgat, 1997) into CCG. Slashes in MM-CCG have slash types, and rules can be restricted to only apply to arguments that have slashes of the correct type. The idea behind this extension is that many constraints that in ordinary CCG can only be expressed in terms of rule restrictio</context>
</contexts>
<marker>Baldridge, Kruijff, 2003</marker>
<rawString>Jason Baldridge and Geert-Jan M. Kruijff. 2003. Multi-modal Combinatory Categorial Grammar. In Proceedings of the Tenth Conference of the European Chapter of the Association for Computational Linguistics (EACL), pages 211–218, Budapest, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Baldridge</author>
</authors>
<title>Lexically Specified Derivational Control in Combinatory Categorial Grammar.</title>
<date>2002</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Edinburgh.</institution>
<contexts>
<context position="35952" citStr="Baldridge (2002)" startWordPosition="6311" endWordPosition="6312">’, but 0 contains a category marked with ‘❑’. Then the transformed derivation would be ungrammatical. A second approach concerns the precise definition of the generalized composition rules, about which there is a surprising degree of disagreement. We have followed Hockenmaier and Young (2008) in classifying instances of generalized forward composition as harmonic if the innermost slash of the secondary argument is forward and crossed if it is backward. However, generalized forward composition is sometimes only accepted as harmonic if all slashes of the secondary argument are forward (see e.g. Baldridge (2002) (40, 41), Steedman (2001) (19)). At the same time, based on the principle that CCG rules should be derived from proofs of Categorial Type Logic as Baldridge (2002) does, it can be argued that generalized composition rules of the form x/y y/z\w =:� x/z\w, which we have considered as harmonic, should actually be classified as crossed, due to the presence of a slash of opposite directionality in front of the w. This definition would break our proof. Thus our result might motivate further research on the ‘correct’ definition of generalized composition rules, which might then strengthen the genera</context>
</contexts>
<marker>Baldridge, 2002</marker>
<rawString>Jason Baldridge. 2002. Lexically Specified Derivational Control in Combinatory Categorial Grammar. Ph.D. thesis, University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yehoshua Bar-Hillel</author>
<author>Haim Gaifman</author>
<author>Eli Shamir</author>
</authors>
<title>On categorial and phrase structure grammars.</title>
<date>1964</date>
<booktitle>In Language and Information: Selected Essays on their Theory and Application,</booktitle>
<pages>99--115</pages>
<publisher>Addison-Wesley.</publisher>
<contexts>
<context position="14619" citStr="Bar-Hillel et al., 1964" startWordPosition="2507" endWordPosition="2510">t will be the following: Theorem 1 Every language that can be generated by a pure CCG has a Parikh-equivalent context-free sublanguage. Here, two languages L and L&apos; are called Parikhequivalent if every string in L is the permutation of a string in L&apos; and vice versa. 3.1 CFG ¨ PCCG Proposition 1 The class of languages generated by pure CCG properly includes the class of contextfree languages. Proof. To see the inclusion, it suffices to note that pure CCG when restricted to application rules is the same as AB-grammar, the classical categorial formalism investigated by Ajdukiewicz and BarHillel (Bar-Hillel et al., 1964). This formalism is weakly equivalent to context-free grammar. To see that the inclusion is proper, we can go back to the grammar G1 that we gave in Section 2.5. We have already discussed that the language L3 is included in L(G1). We can also convince ourselves that all strings generated by the grammar G1 have an equal number of as, bs and cs. Consider now the regular language R = a*b*c*. From our observations, it follows that L(G1) n R = L3. Since context-free languages are closed under intersection with regular languages, we find that L(G1) can be context-free only if L3 is. Since L3 is not </context>
</contexts>
<marker>Bar-Hillel, Gaifman, Shamir, 1964</marker>
<rawString>Yehoshua Bar-Hillel, Haim Gaifman, and Eli Shamir. 1964. On categorial and phrase structure grammars. In Language and Information: Selected Essays on their Theory and Application, pages 99–115. Addison-Wesley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johan Bos</author>
<author>Stephen Clark</author>
<author>Mark Steedman</author>
<author>James R Curran</author>
<author>Julia Hockenmaier</author>
</authors>
<title>Widecoverage semantic representations from a CCG parser.</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th International Conference on Computational Linguistics (COLING),</booktitle>
<pages>176--182</pages>
<location>Geneva, Switzerland.</location>
<contexts>
<context position="1306" citStr="Bos et al., 2004" startWordPosition="192" endWordPosition="195">t-sensitive grammar formalisms, including Tree Adjoining Grammar (TAG). Our result also carries over to a multi-modal extension of CCG. 1 Introduction Combinatory Categorial Grammar (CCG) (Steedman, 2001; Steedman and Baldridge, 2010) is an expressive grammar formalism with formal roots in combinatory logic (Curry et al., 1958) and links to the type-logical tradition of categorial grammar (Moortgat, 1997). It has been successfully used for a wide range of practical tasks, such as data-driven parsing (Hockenmaier and Steedman, 2002; Clark and Curran, 2007), wide-coverage semantic construction (Bos et al., 2004), and the modelling of syntactic priming (Reitter et al., 2006). It is well-known that CCG can generate languages that are not context-free (which is necessary to capture natural languages), but can still be parsed in polynomial time. Specifically, VijayShanker and Weir (1994) identified a version of CCG that is weakly equivalent to Tree Adjoining Grammar (TAG) (Joshi and Schabes, 1997) and other mildly context-sensitive grammar formalisms, and can generate non-context-free languages such as anbncn. The generative capacity of CCG is commonly attributed to its flexible composition rules, which </context>
</contexts>
<marker>Bos, Clark, Steedman, Curran, Hockenmaier, 2004</marker>
<rawString>Johan Bos, Stephen Clark, Mark Steedman, James R. Curran, and Julia Hockenmaier. 2004. Widecoverage semantic representations from a CCG parser. In Proceedings of the 20th International Conference on Computational Linguistics (COLING), pages 176–182, Geneva, Switzerland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Clark</author>
<author>James Curran</author>
</authors>
<title>Widecoverage efficient statistical parsing with CCG and log-linear models.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>4</issue>
<contexts>
<context position="1250" citStr="Clark and Curran, 2007" startWordPosition="184" endWordPosition="187">of CCG with grammar-specific rules, and of other mildly context-sensitive grammar formalisms, including Tree Adjoining Grammar (TAG). Our result also carries over to a multi-modal extension of CCG. 1 Introduction Combinatory Categorial Grammar (CCG) (Steedman, 2001; Steedman and Baldridge, 2010) is an expressive grammar formalism with formal roots in combinatory logic (Curry et al., 1958) and links to the type-logical tradition of categorial grammar (Moortgat, 1997). It has been successfully used for a wide range of practical tasks, such as data-driven parsing (Hockenmaier and Steedman, 2002; Clark and Curran, 2007), wide-coverage semantic construction (Bos et al., 2004), and the modelling of syntactic priming (Reitter et al., 2006). It is well-known that CCG can generate languages that are not context-free (which is necessary to capture natural languages), but can still be parsed in polynomial time. Specifically, VijayShanker and Weir (1994) identified a version of CCG that is weakly equivalent to Tree Adjoining Grammar (TAG) (Joshi and Schabes, 1997) and other mildly context-sensitive grammar formalisms, and can generate non-context-free languages such as anbncn. The generative capacity of CCG is commo</context>
</contexts>
<marker>Clark, Curran, 2007</marker>
<rawString>Stephen Clark and James Curran. 2007. Widecoverage efficient statistical parsing with CCG and log-linear models. Computational Linguistics, 33(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Haskell B Curry</author>
<author>Robert Feys</author>
<author>William Craig</author>
</authors>
<date>1958</date>
<booktitle>Combinatory Logic. Volume 1. Studies in Logic and the Foundations of Mathematics.</booktitle>
<publisher>NorthHolland.</publisher>
<contexts>
<context position="1018" citStr="Curry et al., 1958" startWordPosition="149" endWordPosition="152">l grammars use one and the same universal set of rules, and crosslinguistic variation is isolated in the lexicon. In this paper, we show that the weak generative capacity of this ‘pure’ form of CCG is strictly smaller than that of CCG with grammar-specific rules, and of other mildly context-sensitive grammar formalisms, including Tree Adjoining Grammar (TAG). Our result also carries over to a multi-modal extension of CCG. 1 Introduction Combinatory Categorial Grammar (CCG) (Steedman, 2001; Steedman and Baldridge, 2010) is an expressive grammar formalism with formal roots in combinatory logic (Curry et al., 1958) and links to the type-logical tradition of categorial grammar (Moortgat, 1997). It has been successfully used for a wide range of practical tasks, such as data-driven parsing (Hockenmaier and Steedman, 2002; Clark and Curran, 2007), wide-coverage semantic construction (Bos et al., 2004), and the modelling of syntactic priming (Reitter et al., 2006). It is well-known that CCG can generate languages that are not context-free (which is necessary to capture natural languages), but can still be parsed in polynomial time. Specifically, VijayShanker and Weir (1994) identified a version of CCG that i</context>
<context position="6976" citStr="Curry et al., 1958" startWordPosition="1157" endWordPosition="1160"> the arguments of a category from outermost to innermost. The arity of a category is the number of its arguments. The target of a category c is the atomic category that remains when stripping c of its arguments. x/y y x forward application &gt; y x\y x backward application &lt; x/y y/z x/z forward harmonic composition &gt;B y\z x\y x\z backward harmonic composition &lt;B x/y y\z x\z forward crossed composition &gt;Bx y/z x\y x/z backward crossed composition &lt;Bx Figure 1: The core set of rules of CCG. 2.2 Rules The syntactic rules of CCG are directed versions of combinators in the sense of combinatory logic (Curry et al., 1958). Figure 1 lists a core set of commonly assumed rules, derived from functional application and the B combinator, which models functional composition. When talking about these rules, we refer to the premise containing the argument ly as the primary premise, and to the other premise as the secondary premise of the rule. The rules in Figure 1 can be generalized into composition rules of higher degrees. These are defined as follows, where n &gt; 0 and # is a variable for a sequence of n arguments. x/y y# x# generalized forward composition &gt;n y# x\y x# generalized backward composition &lt;n We call the v</context>
</contexts>
<marker>Curry, Feys, Craig, 1958</marker>
<rawString>Haskell B. Curry, Robert Feys, and William Craig. 1958. Combinatory Logic. Volume 1. Studies in Logic and the Foundations of Mathematics. NorthHolland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Eisner</author>
</authors>
<title>Efficient normal-form parsing for combinatory categorial grammar.</title>
<date>1996</date>
<booktitle>In Proceedings of the 34th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>79--86</pages>
<location>Santa Cruz, CA, USA.</location>
<contexts>
<context position="37347" citStr="Eisner (1996)" startWordPosition="6539" endWordPosition="6540">ct the application of individual rules. This means that these formalisms cannot be fully lexicalized, in the sense that certain languages can only be described by selecting language-specific rules. Our result generalizes Koller and Kuhlmann’s (2009) result for pure first-order CCG. Our proof is not as different as it looks at first glance, as their construction of mapping a CCG derivation to a valency tree and back to a derivation provides a different transformation on derivation trees. Our transformation is also technically related to the normal form construction for CCG parsing presented by Eisner (1996). Of course, at the end of the day, the issue that is more relevant to computational linguistics than a formalism’s ability to generate artificial languages such as L3 is how useful it is for modeling natural languages. CCG, and multi-modal CCG in particular, has a very good track record for this. In this sense, our formal result can also be understood as a contribution to a discussion about the expressive power that is needed to model natural languages. Acknowledgments We have profited enormously from discussions with Jason Baldridge and Mark Steedman, and would also like to thank the anonymo</context>
</contexts>
<marker>Eisner, 1996</marker>
<rawString>Jason Eisner. 1996. Efficient normal-form parsing for combinatory categorial grammar. In Proceedings of the 34th Annual Meeting of the Association for Computational Linguistics (ACL), pages 79–86, Santa Cruz, CA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julia Hockenmaier</author>
<author>Mark Steedman</author>
</authors>
<title>Generative models for statistical parsing with Combinatory Categorial Grammar.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>335--342</pages>
<location>Philadelphia, USA.</location>
<contexts>
<context position="1225" citStr="Hockenmaier and Steedman, 2002" startWordPosition="180" endWordPosition="183">G is strictly smaller than that of CCG with grammar-specific rules, and of other mildly context-sensitive grammar formalisms, including Tree Adjoining Grammar (TAG). Our result also carries over to a multi-modal extension of CCG. 1 Introduction Combinatory Categorial Grammar (CCG) (Steedman, 2001; Steedman and Baldridge, 2010) is an expressive grammar formalism with formal roots in combinatory logic (Curry et al., 1958) and links to the type-logical tradition of categorial grammar (Moortgat, 1997). It has been successfully used for a wide range of practical tasks, such as data-driven parsing (Hockenmaier and Steedman, 2002; Clark and Curran, 2007), wide-coverage semantic construction (Bos et al., 2004), and the modelling of syntactic priming (Reitter et al., 2006). It is well-known that CCG can generate languages that are not context-free (which is necessary to capture natural languages), but can still be parsed in polynomial time. Specifically, VijayShanker and Weir (1994) identified a version of CCG that is weakly equivalent to Tree Adjoining Grammar (TAG) (Joshi and Schabes, 1997) and other mildly context-sensitive grammar formalisms, and can generate non-context-free languages such as anbncn. The generative</context>
</contexts>
<marker>Hockenmaier, Steedman, 2002</marker>
<rawString>Julia Hockenmaier and Mark Steedman. 2002. Generative models for statistical parsing with Combinatory Categorial Grammar. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL), pages 335–342, Philadelphia, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julia Hockenmaier</author>
<author>Peter Young</author>
</authors>
<title>Non-local scrambling: the equivalence of TAG and CCG revisited.</title>
<date>2008</date>
<booktitle>In Proceedings of the 9th Internal Workshop on Tree Adjoining Grammars and Related Formalisms (TAG+9),</booktitle>
<location>Tübingen, Germany.</location>
<contexts>
<context position="2109" citStr="Hockenmaier and Young, 2008" startWordPosition="318" endWordPosition="321">al languages), but can still be parsed in polynomial time. Specifically, VijayShanker and Weir (1994) identified a version of CCG that is weakly equivalent to Tree Adjoining Grammar (TAG) (Joshi and Schabes, 1997) and other mildly context-sensitive grammar formalisms, and can generate non-context-free languages such as anbncn. The generative capacity of CCG is commonly attributed to its flexible composition rules, which allow it to model more complex word orders that context-free grammar can. The discussion of the (weak and strong) generative capacity of CCG and TAG has recently been revived (Hockenmaier and Young, 2008; Koller and Kuhlmann, 2009). In particular, Koller and Kuhlmann (2009) have shown that CCGs that are pure (i.e., they can only use generalized composition rules, and there is no way to restrict the instances of these rules that may be used) and first-order (i.e., all argument categories are atomic) can not generate anbncn. This shows that the generative capacity of at least first-order CCG crucially relies on its ability to restrict rule instantiations, and is at odds with the general conception of CCG as a fully lexicalized formalism, in which all grammars use one and the same set of univers</context>
<context position="31393" citStr="Hockenmaier and Young (2008)" startWordPosition="5523" endWordPosition="5526"> with the types o and x can only be eliminated by harmonic and crossed compositions, respectively.2 Thus, a grammar writer can constrain the application of harmonic and crossed composition rules to certain categories by assigning appropriate types to the slashes of this category in the lexicon. Application rules apply to slashes of any type. As before, we call an MM-CCG grammar pure if it only uses application and generalized compositions, and does not provide means to restrict rule applications. 2Our definitions of generalized harmonic and crossed composition are the same as the ones used by Hockenmaier and Young (2008), but see the discussion in Section 4.3. Figure 4: Rules in B&amp;K-CCG. 4.2 Rule Restrictions in B&amp;K-CCG We will now see what happens to the proof of Theorem 1 in the context of pure B&amp;K-CCG. There is only one point in the entire proof that could be damaged by the introduction of slash types, and that is the result that if a transformation rule from Figure 3 is applied to a correct derivation, then the result is also grammatical. For this, it must not only be the case that the degree on the composition operations is preserved (Lemma 6), but also that the transformed derivation remains consistent </context>
<context position="35629" citStr="Hockenmaier and Young (2008)" startWordPosition="6259" endWordPosition="6262">occurrences. In such an MM-CCG, the composition rules for a certain slash type could be made sensitive to the presence or absence of unary modalities in 0. Say for instance that the slash type s1 in the modalized version of R3 in Section 4.2 would require that no category in the secondary argument is marked with the unary modality ‘❑’, but 0 contains a category marked with ‘❑’. Then the transformed derivation would be ungrammatical. A second approach concerns the precise definition of the generalized composition rules, about which there is a surprising degree of disagreement. We have followed Hockenmaier and Young (2008) in classifying instances of generalized forward composition as harmonic if the innermost slash of the secondary argument is forward and crossed if it is backward. However, generalized forward composition is sometimes only accepted as harmonic if all slashes of the secondary argument are forward (see e.g. Baldridge (2002) (40, 41), Steedman (2001) (19)). At the same time, based on the principle that CCG rules should be derived from proofs of Categorial Type Logic as Baldridge (2002) does, it can be argued that generalized composition rules of the form x/y y/z\w =:� x/z\w, which we have conside</context>
</contexts>
<marker>Hockenmaier, Young, 2008</marker>
<rawString>Julia Hockenmaier and Peter Young. 2008. Non-local scrambling: the equivalence of TAG and CCG revisited. In Proceedings of the 9th Internal Workshop on Tree Adjoining Grammars and Related Formalisms (TAG+9), Tübingen, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aravind K Joshi</author>
<author>Yves Schabes</author>
</authors>
<title>TreeAdjoining Grammars.</title>
<date>1997</date>
<booktitle>In Grzegorz Rozenberg and Arto Salomaa, editors, Handbook of Formal Languages,</booktitle>
<volume>3</volume>
<pages>69--123</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="1695" citStr="Joshi and Schabes, 1997" startWordPosition="255" endWordPosition="258">l grammar (Moortgat, 1997). It has been successfully used for a wide range of practical tasks, such as data-driven parsing (Hockenmaier and Steedman, 2002; Clark and Curran, 2007), wide-coverage semantic construction (Bos et al., 2004), and the modelling of syntactic priming (Reitter et al., 2006). It is well-known that CCG can generate languages that are not context-free (which is necessary to capture natural languages), but can still be parsed in polynomial time. Specifically, VijayShanker and Weir (1994) identified a version of CCG that is weakly equivalent to Tree Adjoining Grammar (TAG) (Joshi and Schabes, 1997) and other mildly context-sensitive grammar formalisms, and can generate non-context-free languages such as anbncn. The generative capacity of CCG is commonly attributed to its flexible composition rules, which allow it to model more complex word orders that context-free grammar can. The discussion of the (weak and strong) generative capacity of CCG and TAG has recently been revived (Hockenmaier and Young, 2008; Koller and Kuhlmann, 2009). In particular, Koller and Kuhlmann (2009) have shown that CCGs that are pure (i.e., they can only use generalized composition rules, and there is no way to </context>
</contexts>
<marker>Joshi, Schabes, 1997</marker>
<rawString>Aravind K. Joshi and Yves Schabes. 1997. TreeAdjoining Grammars. In Grzegorz Rozenberg and Arto Salomaa, editors, Handbook of Formal Languages, volume 3, pages 69–123. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Koller</author>
<author>Marco Kuhlmann</author>
</authors>
<title>Dependency trees and the strong generative capacity of CCG.</title>
<date>2009</date>
<booktitle>In Proceedings of the Twelfth Conference of the European Chapter of the Association for Computational Linguistics (EACL),</booktitle>
<pages>460--468</pages>
<location>Athens, Greece.</location>
<contexts>
<context position="2137" citStr="Koller and Kuhlmann, 2009" startWordPosition="322" endWordPosition="325">be parsed in polynomial time. Specifically, VijayShanker and Weir (1994) identified a version of CCG that is weakly equivalent to Tree Adjoining Grammar (TAG) (Joshi and Schabes, 1997) and other mildly context-sensitive grammar formalisms, and can generate non-context-free languages such as anbncn. The generative capacity of CCG is commonly attributed to its flexible composition rules, which allow it to model more complex word orders that context-free grammar can. The discussion of the (weak and strong) generative capacity of CCG and TAG has recently been revived (Hockenmaier and Young, 2008; Koller and Kuhlmann, 2009). In particular, Koller and Kuhlmann (2009) have shown that CCGs that are pure (i.e., they can only use generalized composition rules, and there is no way to restrict the instances of these rules that may be used) and first-order (i.e., all argument categories are atomic) can not generate anbncn. This shows that the generative capacity of at least first-order CCG crucially relies on its ability to restrict rule instantiations, and is at odds with the general conception of CCG as a fully lexicalized formalism, in which all grammars use one and the same set of universal rules. A question then is</context>
<context position="15684" citStr="Koller and Kuhlmann (2009)" startWordPosition="2689" endWordPosition="2692">R = L3. Since context-free languages are closed under intersection with regular languages, we find that L(G1) can be context-free only if L3 is. Since L3 is not context-free, we therefore conclude that L(G1) is not context-free, either. 0 Two things are worth noting. First, our result shows that the ability of CCG to generate non-context-free languages does not hinge on the availability of substitution and type-raising rules: The derivations of G1 only use generalized compositions. Neither does it require the use of functional argument categories: The grammar G1 is first-order in the sense of Koller and Kuhlmann (2009). Second, it is important to note that if the composition degree n is restricted to 0 or 1, pure CCG actually collapses to context-free expressive power. This is clear for n = 0 because of the equivalence to AB grammar. For n = 1, observe that the arity of the result of a composition is at most as high as 537 that of each premise. This means that the arity of any derived category is bounded by the maximal arity of lexical categories in the grammar, which together with Lemma 1 implies that there is only a finite set of derivable categories. The set of all valid derivations can then be simulated</context>
</contexts>
<marker>Koller, Kuhlmann, 2009</marker>
<rawString>Alexander Koller and Marco Kuhlmann. 2009. Dependency trees and the strong generative capacity of CCG. In Proceedings of the Twelfth Conference of the European Chapter of the Association for Computational Linguistics (EACL), pages 460–468, Athens, Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Moortgat</author>
</authors>
<title>Categorial type logics.</title>
<date>1997</date>
<booktitle>In Handbook of Logic and Language, chapter 2,</booktitle>
<pages>93--177</pages>
<publisher>Elsevier.</publisher>
<contexts>
<context position="1097" citStr="Moortgat, 1997" startWordPosition="162" endWordPosition="163">on is isolated in the lexicon. In this paper, we show that the weak generative capacity of this ‘pure’ form of CCG is strictly smaller than that of CCG with grammar-specific rules, and of other mildly context-sensitive grammar formalisms, including Tree Adjoining Grammar (TAG). Our result also carries over to a multi-modal extension of CCG. 1 Introduction Combinatory Categorial Grammar (CCG) (Steedman, 2001; Steedman and Baldridge, 2010) is an expressive grammar formalism with formal roots in combinatory logic (Curry et al., 1958) and links to the type-logical tradition of categorial grammar (Moortgat, 1997). It has been successfully used for a wide range of practical tasks, such as data-driven parsing (Hockenmaier and Steedman, 2002; Clark and Curran, 2007), wide-coverage semantic construction (Bos et al., 2004), and the modelling of syntactic priming (Reitter et al., 2006). It is well-known that CCG can generate languages that are not context-free (which is necessary to capture natural languages), but can still be parsed in polynomial time. Specifically, VijayShanker and Weir (1994) identified a version of CCG that is weakly equivalent to Tree Adjoining Grammar (TAG) (Joshi and Schabes, 1997) a</context>
<context position="29847" citStr="Moortgat, 1997" startWordPosition="5258" endWordPosition="5259"># x\oy x\oz# backward harmonic composition y/xz# x\xy x/xz# backward crossed composition 4 Multi-Modal CCG We now extend Theorem 1 to multi-modal CCG. We will see that at least for a popular version of multi-modal CCG, the B&amp;K-CCG formalism presented by Baldridge and Kruijff (2003), the proof can be adapted quite straightforwardly. This means that even B&amp;K-CCG becomes less expressive when rule restrictions are disallowed. 4.1 Multi-Modal CCG The term ‘multi-modal CCG’ (MM-CCG) refers to a family of extensions to CCG which attempt to bring some of the expressive power of Categorial Type Logic (Moortgat, 1997) into CCG. Slashes in MM-CCG have slash types, and rules can be restricted to only apply to arguments that have slashes of the correct type. The idea behind this extension is that many constraints that in ordinary CCG can only be expressed in terms of rule restrictions can now be specified in the lexicon entries by giving the slashes the appropriate types. The most widely-known version of multi-modal CCG is the formalism defined by Baldridge and Kruijff (2003) and used by Steedman and Baldridge (2010); we refer to it as B&amp;K-CCG. This formalism uses an inventory of four slash types, { *, x, o, </context>
</contexts>
<marker>Moortgat, 1997</marker>
<rawString>Michael Moortgat. 1997. Categorial type logics. In Handbook of Logic and Language, chapter 2, pages 93–177. Elsevier.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Reitter</author>
<author>Julia Hockenmaier</author>
<author>Frank Keller</author>
</authors>
<title>Priming effects in combinatory categorial grammar.</title>
<date>2006</date>
<booktitle>In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>308--316</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="1369" citStr="Reitter et al., 2006" startWordPosition="202" endWordPosition="205">ammar (TAG). Our result also carries over to a multi-modal extension of CCG. 1 Introduction Combinatory Categorial Grammar (CCG) (Steedman, 2001; Steedman and Baldridge, 2010) is an expressive grammar formalism with formal roots in combinatory logic (Curry et al., 1958) and links to the type-logical tradition of categorial grammar (Moortgat, 1997). It has been successfully used for a wide range of practical tasks, such as data-driven parsing (Hockenmaier and Steedman, 2002; Clark and Curran, 2007), wide-coverage semantic construction (Bos et al., 2004), and the modelling of syntactic priming (Reitter et al., 2006). It is well-known that CCG can generate languages that are not context-free (which is necessary to capture natural languages), but can still be parsed in polynomial time. Specifically, VijayShanker and Weir (1994) identified a version of CCG that is weakly equivalent to Tree Adjoining Grammar (TAG) (Joshi and Schabes, 1997) and other mildly context-sensitive grammar formalisms, and can generate non-context-free languages such as anbncn. The generative capacity of CCG is commonly attributed to its flexible composition rules, which allow it to model more complex word orders that context-free gr</context>
</contexts>
<marker>Reitter, Hockenmaier, Keller, 2006</marker>
<rawString>David Reitter, Julia Hockenmaier, and Frank Keller. 2006. Priming effects in combinatory categorial grammar. In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 308–316, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steedman</author>
<author>Jason Baldridge</author>
</authors>
<title>Combinatory categorial grammar.</title>
<date>2010</date>
<journal>Non-Transformational Syntax. Blackwell. Draft</journal>
<volume>7</volume>
<editor>In R. Borsley and K. Borjars, editors,</editor>
<note>to appear.</note>
<contexts>
<context position="923" citStr="Steedman and Baldridge, 2010" startWordPosition="134" endWordPosition="137">ct Combinatory Categorial Grammar (CCG) is generally construed as a fully lexicalized formalism, where all grammars use one and the same universal set of rules, and crosslinguistic variation is isolated in the lexicon. In this paper, we show that the weak generative capacity of this ‘pure’ form of CCG is strictly smaller than that of CCG with grammar-specific rules, and of other mildly context-sensitive grammar formalisms, including Tree Adjoining Grammar (TAG). Our result also carries over to a multi-modal extension of CCG. 1 Introduction Combinatory Categorial Grammar (CCG) (Steedman, 2001; Steedman and Baldridge, 2010) is an expressive grammar formalism with formal roots in combinatory logic (Curry et al., 1958) and links to the type-logical tradition of categorial grammar (Moortgat, 1997). It has been successfully used for a wide range of practical tasks, such as data-driven parsing (Hockenmaier and Steedman, 2002; Clark and Curran, 2007), wide-coverage semantic construction (Bos et al., 2004), and the modelling of syntactic priming (Reitter et al., 2006). It is well-known that CCG can generate languages that are not context-free (which is necessary to capture natural languages), but can still be parsed in</context>
<context position="11218" citStr="Steedman and Baldridge, 2010" startWordPosition="1922" endWordPosition="1925">ment is an argument of some lexical category of G (Lemma 1), and since n is assumed to be bounded, both m and n are bounded. Hence, there is a bound on the number of choices for c. 0 Note that the number of categories that can occur as primary premises is generally unbounded even in a grammar with bounded degree. 1For practical grammars, n &lt; 4. 2.5 Rule Restrictions The rule set of pure CCG is universal: the difference between the grammars of different languages should be restricted to different choices of categories in the lexicon. This is what makes pure CCG a lexicalized grammar formalism (Steedman and Baldridge, 2010). However, most practical CCG grammars rely on the possibility to exclude or restrict certain rules. For example, Steedman (2001) bans the rule of forward crossed composition from his grammar of English, and stipulates that the rule of backward crossed composition may be applied only if both of its premises share the common target category s, representing sentences. Exclusions and restrictions of rules are also assumed in much of the language-theoretic work on CCG. In particular, they are essential for the formalism used in the aforementioned equivalence proof for CCG and TAG (Vijay-Shanker an</context>
<context position="30353" citStr="Steedman and Baldridge (2010)" startWordPosition="5342" endWordPosition="5345">a family of extensions to CCG which attempt to bring some of the expressive power of Categorial Type Logic (Moortgat, 1997) into CCG. Slashes in MM-CCG have slash types, and rules can be restricted to only apply to arguments that have slashes of the correct type. The idea behind this extension is that many constraints that in ordinary CCG can only be expressed in terms of rule restrictions can now be specified in the lexicon entries by giving the slashes the appropriate types. The most widely-known version of multi-modal CCG is the formalism defined by Baldridge and Kruijff (2003) and used by Steedman and Baldridge (2010); we refer to it as B&amp;K-CCG. This formalism uses an inventory of four slash types, { *, x, o, • I arranged in a simple type hierarchy: * is the most general type, • the most specific, and x and o are in between. Every slash in a B&amp;K-CCG lexicon is annotated with one of these slash types. The combinatory rules in B&amp;K-CCG, given in Figure 4, are defined to be sensitive to the slash types. In particular, slashes with the types o and x can only be eliminated by harmonic and crossed compositions, respectively.2 Thus, a grammar writer can constrain the application of harmonic and crossed composition</context>
</contexts>
<marker>Steedman, Baldridge, 2010</marker>
<rawString>Mark Steedman and Jason Baldridge. 2010. Combinatory categorial grammar. In R. Borsley and K. Borjars, editors, Non-Transformational Syntax. Blackwell. Draft 7.0, to appear.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steedman</author>
</authors>
<title>The Syntactic Process.</title>
<date>2001</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="892" citStr="Steedman, 2001" startWordPosition="131" endWordPosition="133">ua, Italy Abstract Combinatory Categorial Grammar (CCG) is generally construed as a fully lexicalized formalism, where all grammars use one and the same universal set of rules, and crosslinguistic variation is isolated in the lexicon. In this paper, we show that the weak generative capacity of this ‘pure’ form of CCG is strictly smaller than that of CCG with grammar-specific rules, and of other mildly context-sensitive grammar formalisms, including Tree Adjoining Grammar (TAG). Our result also carries over to a multi-modal extension of CCG. 1 Introduction Combinatory Categorial Grammar (CCG) (Steedman, 2001; Steedman and Baldridge, 2010) is an expressive grammar formalism with formal roots in combinatory logic (Curry et al., 1958) and links to the type-logical tradition of categorial grammar (Moortgat, 1997). It has been successfully used for a wide range of practical tasks, such as data-driven parsing (Hockenmaier and Steedman, 2002; Clark and Curran, 2007), wide-coverage semantic construction (Bos et al., 2004), and the modelling of syntactic priming (Reitter et al., 2006). It is well-known that CCG can generate languages that are not context-free (which is necessary to capture natural languag</context>
<context position="11347" citStr="Steedman (2001)" startWordPosition="1944" endWordPosition="1945">bound on the number of choices for c. 0 Note that the number of categories that can occur as primary premises is generally unbounded even in a grammar with bounded degree. 1For practical grammars, n &lt; 4. 2.5 Rule Restrictions The rule set of pure CCG is universal: the difference between the grammars of different languages should be restricted to different choices of categories in the lexicon. This is what makes pure CCG a lexicalized grammar formalism (Steedman and Baldridge, 2010). However, most practical CCG grammars rely on the possibility to exclude or restrict certain rules. For example, Steedman (2001) bans the rule of forward crossed composition from his grammar of English, and stipulates that the rule of backward crossed composition may be applied only if both of its premises share the common target category s, representing sentences. Exclusions and restrictions of rules are also assumed in much of the language-theoretic work on CCG. In particular, they are essential for the formalism used in the aforementioned equivalence proof for CCG and TAG (Vijay-Shanker and Weir, 1994). To illustrate the formal relevance of rule restrictions, suppose that we wanted to write a pure CCG that generates</context>
<context position="35978" citStr="Steedman (2001)" startWordPosition="6315" endWordPosition="6316">y marked with ‘❑’. Then the transformed derivation would be ungrammatical. A second approach concerns the precise definition of the generalized composition rules, about which there is a surprising degree of disagreement. We have followed Hockenmaier and Young (2008) in classifying instances of generalized forward composition as harmonic if the innermost slash of the secondary argument is forward and crossed if it is backward. However, generalized forward composition is sometimes only accepted as harmonic if all slashes of the secondary argument are forward (see e.g. Baldridge (2002) (40, 41), Steedman (2001) (19)). At the same time, based on the principle that CCG rules should be derived from proofs of Categorial Type Logic as Baldridge (2002) does, it can be argued that generalized composition rules of the form x/y y/z\w =:� x/z\w, which we have considered as harmonic, should actually be classified as crossed, due to the presence of a slash of opposite directionality in front of the w. This definition would break our proof. Thus our result might motivate further research on the ‘correct’ definition of generalized composition rules, which might then strengthen the generative capacity of pure MM-C</context>
</contexts>
<marker>Steedman, 2001</marker>
<rawString>Mark Steedman. 2001. The Syntactic Process. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Vijay-Shanker</author>
<author>David J Weir</author>
</authors>
<title>The equivalence of four extensions of context-free grammars.</title>
<date>1994</date>
<booktitle>Mathematical Systems Theory,</booktitle>
<pages>27--6</pages>
<contexts>
<context position="3026" citStr="Vijay-Shanker and Weir (1994)" startWordPosition="472" endWordPosition="475"> are atomic) can not generate anbncn. This shows that the generative capacity of at least first-order CCG crucially relies on its ability to restrict rule instantiations, and is at odds with the general conception of CCG as a fully lexicalized formalism, in which all grammars use one and the same set of universal rules. A question then is whether the result carries over to pure CCG with higher-order categories. In this paper, we answer this question to the positive: We show that the weak generative capacity of general pure CCG is still strictly smaller than that of the formalism considered by Vijay-Shanker and Weir (1994); composition rules can only achieve their full expressive potential if their use can be restricted. Our technical result is that every language L that can be generated by a pure CCG has a context-free sublanguage L&apos; C_ L such that every string in L is a permutation of a string in L&apos;, and vice versa. This means that anbncn, for instance, cannot be generated by pure CCG, as it does not have any (non-trivial) permutation-equivalent sublanguages. Conversely, we show that there are still languages that can be generated by pure CCG but not by context-free grammar. We then show that our permutation </context>
<context position="4299" citStr="Vijay-Shanker and Weir (1994)" startWordPosition="682" endWordPosition="685">al CCG as defined by Baldridge and Kruijff (2003), in which the use of rules can be controlled through the lexicon entries by assigning types to slashes. Since this extension was intended to do away with the need for grammar-specific rule restrictions, it comes as quite a surprise that pure multi-modal 534 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 534–543, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics CCG in the style of Baldridge and Kruijff (2003) is still less expressive than the CCG formalism used by Vijay-Shanker and Weir (1994). This means that word order in CCG cannot be fully lexicalized with the current formal tools; some ordering constraints must be specified via language-specific combination rules and not in lexicon entries. On the other hand, as pure multi-modal CCG has been successfully applied to model the syntax of a variety of natural languages, another way to read our results is as contributions to a discussion about the exact expressiveness needed to model natural language. The remainder of this paper is structured as follows. In Section 2, we introduce the formalism of pure CCG that we consider in this </context>
<context position="8026" citStr="Vijay-Shanker and Weir (1994)" startWordPosition="1343" endWordPosition="1346">as follows, where n &gt; 0 and # is a variable for a sequence of n arguments. x/y y# x# generalized forward composition &gt;n y# x\y x# generalized backward composition &lt;n We call the value n the degree of the composition rule. Note that the rules in Figure 1 are the special cases for n = 0 and n = 1. Apart from the core rules given in Figure 1, some versions of CCG also use rules derived from the S and T combinators of combinatory logic, called substitution and type-raising, the latter restricted to the lexicon. However, since our main point of reference in this paper, the CCG formalism defined by Vijay-Shanker and Weir (1994), does not use such rules, we will not consider them here, either. 2.3 Grammars and Derivations With the set of rules in place, we can define a pure combinatory categorial grammar (PCCG) as a construct G = (A, E, L, s), where A is an alphabet of atomic categories, s E A is a distinguished atomic category called the final category, E is a finite set of terminal symbols, and L is a finite relation between symbols in E and categories over A, called the lexicon. The elements of the lexicon L are called lexicon entries, and we represent them using the notation a �- x, where a E E and x is a categor</context>
<context position="9944" citStr="Vijay-Shanker and Weir (1994)" startWordPosition="1689" endWordPosition="1692"> generated by G, denoted by L(G), is formed by the yields of all complete derivation trees. 2.4 Degree Restrictions Work on CCG generally assumes an upper bound on the degree of composition rules that can be used in derivations. We also employ this restriction, and only consider grammars with compositions of some bounded (but arbitrary) degree n &gt; 0.1 CCG with unbounded-degree compositions is more expressive than bounded-degree CCG or TAG (Weir and Joshi, 1988). Bounded-degree grammars have a number of useful properties, one of which we mention here. The following lemma rephrases Lemma 3.1 in Vijay-Shanker and Weir (1994). Lemma 1 For every grammar G, every argument in a derivation of G is the argument of some lexical category of G. As a consequence, there is only a finite number of categories that can occur as arguments in some derivation. In the presence of a bound on the degree of composition rules, this implies the following: Lemma 2 For every grammar G, there is a finite number of categories that can occur as secondary premises in derivations of G. Proof. The arity of a secondary premise c can be written as m + n, where m is the arity of the first argument of the corresponding primary premise, and n is th</context>
<context position="11831" citStr="Vijay-Shanker and Weir, 1994" startWordPosition="2020" endWordPosition="2023">Baldridge, 2010). However, most practical CCG grammars rely on the possibility to exclude or restrict certain rules. For example, Steedman (2001) bans the rule of forward crossed composition from his grammar of English, and stipulates that the rule of backward crossed composition may be applied only if both of its premises share the common target category s, representing sentences. Exclusions and restrictions of rules are also assumed in much of the language-theoretic work on CCG. In particular, they are essential for the formalism used in the aforementioned equivalence proof for CCG and TAG (Vijay-Shanker and Weir, 1994). To illustrate the formal relevance of rule restrictions, suppose that we wanted to write a pure CCG that generates the language L3 = {anbncn I n &gt; 1}, which is not context-free. An attempt could be G1 = ({s,a,b,c},{a,b,c },L,s), where the lexicon L is given as follows: a�- a, b�- s/c\a , b i b/c\a , b i s/c/b\a , b i s/c/b\a , c�- c. From a few sample derivations like the one given in Figure 2a, we can convince ourselves that G1 generates all strings of the form anbncn, for any n &gt; 1. However, a closer inspection reveals that it also generates other, unwanted strings—in particular, strings o</context>
<context position="28991" citStr="Vijay-Shanker and Weir (1994)" startWordPosition="5122" endWordPosition="5125">free. Since every transformed derivation is a valid derivation of G, we have LT c L(G). As an immediate consequence, we find: Proposition 2 The class of languages generated by pure CCG cannot generate all languages that can be generated by CCG with rule restrictions. Proof. The CCG formalism considered by VijayShanker and Weir (1994) can generate the non-context-free language L3. However, the only Parikhequivalent sublanguage of that language is L3 itself. From Theorem 1, we therefore conclude that L3 cannot be generated by pure CCG. 0 540 In the light of the equivalence result established by Vijay-Shanker and Weir (1994), this means that pure CCG cannot generate all languages that can be generated by TAG. x/?y y x forward application y x\?y x backward application x/oy y/oz# x/oz# forward harmonic composition x/xy y\xz# x\xz# forward crossed composition y\oz# x\oy x\oz# backward harmonic composition y/xz# x\xy x/xz# backward crossed composition 4 Multi-Modal CCG We now extend Theorem 1 to multi-modal CCG. We will see that at least for a popular version of multi-modal CCG, the B&amp;K-CCG formalism presented by Baldridge and Kruijff (2003), the proof can be adapted quite straightforwardly. This means that even B&amp;K-</context>
<context position="33830" citStr="Vijay-Shanker and Weir (1994)" startWordPosition="5949" endWordPosition="5952">t to the right-hand side. Thus the transformation maps grammatical derivations into grammatical derivations. The rest of the proof in Section 3 continues to work literally, so we have the following result: zy xIs2w#\s3z R3 = x/s1y yIs2w#y xIs2w#y zy yIs2w#\s3z 541 Theorem 2 Every language that can be generated by a pure B&amp;K-CCG grammar contains a Parikhequivalent context-free sublanguage. This means that pure B&amp;K-CCG is just as unable to generate L3 as pure CCG is. In other words, the weak generative capacity of CCG with rule restrictions, and in particular that of the formalism considered by Vijay-Shanker and Weir (1994), is strictly greater than the generative capacity of pure B&amp;K-CCG—although we conjecture (but cannot prove) that pure B&amp;K-CCG is still more expressive than pure non-modal CCG. 4.3 Towards More Expressive MM-CCGs To put the result of Theorem 2 into perspective, we will now briefly consider ways in which B&amp;K-CCG might be modified in order to obtain a pure multimodal CCG that is weakly equivalent to CCG in the style of Vijay-Shanker and Weir (1994). Such a modification would have to break the proof in Section 4.2, which is harder than it may seem at first glance. For instance, simply assuming a </context>
</contexts>
<marker>Vijay-Shanker, Weir, 1994</marker>
<rawString>K. Vijay-Shanker and David J. Weir. 1994. The equivalence of four extensions of context-free grammars. Mathematical Systems Theory, 27(6):511–546.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David J Weir</author>
<author>Aravind K Joshi</author>
</authors>
<title>Combinatory categorial grammars: Generative power and relationship to linear context-free rewriting systems.</title>
<date>1988</date>
<booktitle>In Proceedings of the 26th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>278--285</pages>
<location>Buffalo, NY, USA.</location>
<contexts>
<context position="9780" citStr="Weir and Joshi, 1988" startWordPosition="1664" endWordPosition="1667"> string w is called the yield of the resulting derivation tree. A derivation tree is complete, if the last category is the final category of G. The language generated by G, denoted by L(G), is formed by the yields of all complete derivation trees. 2.4 Degree Restrictions Work on CCG generally assumes an upper bound on the degree of composition rules that can be used in derivations. We also employ this restriction, and only consider grammars with compositions of some bounded (but arbitrary) degree n &gt; 0.1 CCG with unbounded-degree compositions is more expressive than bounded-degree CCG or TAG (Weir and Joshi, 1988). Bounded-degree grammars have a number of useful properties, one of which we mention here. The following lemma rephrases Lemma 3.1 in Vijay-Shanker and Weir (1994). Lemma 1 For every grammar G, every argument in a derivation of G is the argument of some lexical category of G. As a consequence, there is only a finite number of categories that can occur as arguments in some derivation. In the presence of a bound on the degree of composition rules, this implies the following: Lemma 2 For every grammar G, there is a finite number of categories that can occur as secondary premises in derivations o</context>
</contexts>
<marker>Weir, Joshi, 1988</marker>
<rawString>David J. Weir and Aravind K. Joshi. 1988. Combinatory categorial grammars: Generative power and relationship to linear context-free rewriting systems. In Proceedings of the 26th Annual Meeting of the Association for Computational Linguistics, pages 278– 285, Buffalo, NY, USA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>