<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000435">
<title confidence="0.974518">
Efficient Tree-based Approximation for Entailment Graph Learning
</title>
<author confidence="0.995534">
Jonathan Berant§, Ido Dagant, Meni Adlert, Jacob Goldbergert
</author>
<affiliation confidence="0.978915333333333">
§ The Blavatnik School of Computer Science, Tel Aviv University
† Department of Computer Science, Bar-Ilan University
$ Faculty of Engineering, Bar-Ilan University
</affiliation>
<email confidence="0.835874666666667">
jonatha6@post.tau.ac.il
{dagan,goldbej}@{cs,eng}.biu.ac.il
adlerm@cs.bgu.ac.il
</email>
<sectionHeader confidence="0.996215" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999712894736842">
Learning entailment rules is fundamental in
many semantic-inference applications and has
been an active field of research in recent years.
In this paper we address the problem of learn-
ing transitive graphs that describe entailment
rules between predicates (termed entailment
graphs). We first identify that entailment
graphs exhibit a “tree-like” property and are
very similar to a novel type of graph termed
forest-reducible graph. We utilize this prop-
erty to develop an iterative efficient approxi-
mation algorithm for learning the graph edges,
where each iteration takes linear time. We
compare our approximation algorithm to a
recently-proposed state-of-the-art exact algo-
rithm and show that it is more efficient and
scalable both theoretically and empirically,
while its output quality is close to that given
by the optimal solution of the exact algorithm.
</bodyText>
<sectionHeader confidence="0.998882" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999932191489362">
Performing textual inference is in the heart of many
semantic inference applications such as Question
Answering (QA) and Information Extraction (IE). A
prominent generic paradigm for textual inference is
Textual Entailment (TUE) (Dagan et al., 2009). In
TUE, the goal is to recognize, given two text frag-
ments termed text and hypothesis, whether the hy-
pothesis can be inferred from the text. For example,
the text “Cyprus was invaded by the Ottoman Em-
pire in 1571” implies the hypothesis “The Ottomans
attacked Cyprus”.
Semantic inference applications such as QA and
IE crucially rely on entailment rules (Ravichandran
and Hovy, 2002; Shinyama and Sekine, 2006) or
equivalently inference rules, that is, rules that de-
scribe a directional inference relation between two
fragments of text. An important type of entailment
rule specifies the entailment relation between natu-
ral language predicates, e.g., the entailment rule ‘X
invade Y —* X attack Y’ can be helpful in inferring
the aforementioned hypothesis. Consequently, sub-
stantial effort has been made to learn such rules (Lin
and Pantel, 2001; Sekine, 2005; Szpektor and Da-
gan, 2008; Schoenmackers et al., 2010).
Textual entailment is inherently a transitive rela-
tion , that is, the rules ‘x —* y’ and ‘y —* z’ imply
the rule ‘x —* z’. Accordingly, Berant et al. (2010)
formulated the problem of learning entailment rules
as a graph optimization problem, where nodes are
predicates and edges represent entailment rules that
respect transitivity. Since finding the optimal set of
edges respecting transitivity is NP-hard, they em-
ployed Integer Linear Programming (ILP) to find the
exact solution. Indeed, they showed that applying
global transitivity constraints improves rule learning
comparing to methods that ignore graph structure.
More recently, Berant et al. (Berant et al., 2011) in-
troduced a more efficient exact algorithm, which de-
composes the graph into connected components and
then applies an ILP solver over each component.
Despite this progress, finding the exact solution
remains NP-hard – the authors themselves report
they were unable to solve some graphs of rather
moderate size and that the coverage of their method
is limited. Thus, scaling their algorithm to data sets
with tens of thousands of predicates (e.g., the extrac-
tions of Fader et al. (2011)) is unlikely.
</bodyText>
<page confidence="0.968795">
117
</page>
<note confidence="0.9858085">
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 117–125,
Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.999735903225806">
In this paper we present a novel method for learn-
ing the edges of entailment graphs. Our method
computes much more efficiently an approximate so-
lution that is empirically almost as good as the exact
solution. To that end, we first (Section 3) conjecture
and empirically show that entailment graphs exhibit
a “tree-like” property, i.e., that they can be reduced
into a structure similar to a directed forest.
Then, we present in Section 4 our iterative ap-
proximation algorithm, where in each iteration a
node is removed and re-attached back to the graph in
a locally-optimal way. Combining this scheme with
our conjecture about the graph structure enables a
linear algorithm for node re-attachment. Section 5
shows empirically that this algorithm is by orders of
magnitude faster than the state-of-the-art exact al-
gorithm, and that though an optimal solution is not
guaranteed, the area under the precision-recall curve
drops by merely a point.
To conclude, the contribution of this paper is two-
fold: First, we define a novel modeling assumption
about the tree-like structure of entailment graphs and
demonstrate its validity. Second, we exploit this as-
sumption to develop a polynomial approximation al-
gorithm for learning entailment graphs that can scale
to much larger graphs than in the past. Finally, we
note that learning entailment graphs bears strong
similarities to related tasks such as Taxonomy In-
duction (Snow et al., 2006) and Ontology induction
(Poon and Domingos, 2010), and thus our approach
may improve scalability in these fields as well.
</bodyText>
<sectionHeader confidence="0.977539" genericHeader="introduction">
2 Background
</sectionHeader>
<bodyText confidence="0.979437051282051">
Until recently, work on learning entailment rules be-
tween predicates considered each rule independently
of others and did not exploit global dependencies.
Most methods utilized the distributional similarity
hypothesis that states that semantically similar pred-
icates occur with similar arguments (Lin and Pan-
tel, 2001; Szpektor et al., 2004; Yates and Etzioni,
2009; Schoenmackers et al., 2010). Some meth-
ods extracted rules from lexicographic resources
such as WordNet (Szpektor and Dagan, 2009) or
FrameNet (Bob and Rambow, 2009; Ben Aharon et
al., 2010), and others assumed that semantic rela-
tions between predicates can be deduced from their
co-occurrence in a corpus via manually-constructed
patterns (Chklovski and Pantel, 2004).
Recently, Berant et al. (2010; 2011) formulated
the problem as the problem of learning global entail-
ment graphs. In entailment graphs, nodes are predi-
cates (e.g., ‘X attack Y’) and edges represent entail-
ment rules between them (‘X invade Y → X attack
Y’). For every pair of predicates i, j, an entailment
score wij was learned by training a classifier over
distributional similarity features. A positive wij in-
dicated that the classifier believes i → j and a nega-
tive wij indicated that the classifier believes i 9 j.
Given the graph nodes V (corresponding to the pred-
icates) and the weighting function w : V × V → R,
they aim to find the edges of a graph G = (V, E)
that maximize the objective 11(i,j)EE wij under the
constraint that the graph is transitive (i.e., for every
node triplet (i, j, k), if (i, j) ∈ E and (j, k) ∈ E,
then (i, k) ∈ E).
Berant et al. proved that this optimization prob-
lem, which we term Max-Trans-Graph, is NP-hard,
and so described it as an Integer Linear Program
(ILP). Let xij be a binary variable indicating the ex-
istence of an edge i → j in E. Then, X = {xij :
i =6 j} are the variables of the following ILP for
Max-Trans-Graph:
</bodyText>
<equation confidence="0.999126">
�arg max wij · xij (1)
X i#j
s.t. ∀i,j,kEV xij + xjk − xik ≤ 1
∀i,jEV xij ∈ {0, 1}
</equation>
<bodyText confidence="0.999959611111111">
The objective function is the sum of weights over the
edges of G and the constraint xij + xjk − xik ≤ 1
on the binary variables enforces that whenever xij =
xjk =1, then also xik = 1 (transitivity).
Since ILP is NP-hard, applying an ILP solver di-
rectly does not scale well because the number of
variables is O(|V |2) and the number of constraints is
O(|V |3). Thus, even a graph with ∼80 nodes (predi-
cates) has more than half a million constraints. Con-
sequently, in (Berant et al., 2011), they proposed a
method that efficiently decomposes the graph into
smaller components and applies an ILP solver on
each component separately using a cutting-plane
procedure (Riedel and Clarke, 2006). Although this
method is exact and improves scalability, it does
not guarantee an efficient solution. When the graph
does not decompose into sufficiently small compo-
nents, and the weights generate many violations of
</bodyText>
<page confidence="0.997325">
118
</page>
<bodyText confidence="0.999286696969697">
transitivity, solving Max-Trans-Graph becomes in-
tractable. To address this problem, we present in
this paper a method for approximating the optimal
set of edges within each component and show that
it is much more efficient and scalable both theoreti-
cally and empirically.
Do and Roth (2010) suggested a method for a re-
lated task of learning taxonomic relations between
terms. Given a pair of terms, a small graph is con-
structed and constraints are imposed on the graph
structure. Their work, however, is geared towards
scenarios where relations are determined on-the-fly
for a given pair of terms and no global knowledge
base is explicitly constructed. Thus, their method
easily produces solutions where global constraints,
such as transitivity, are violated.
Another approximation method that violates tran-
sitivity constraints is LP relaxation (Martins et al.,
2009). In LP relaxation, the constraint xzj E {0, 11
is replaced by 0 &lt; xzj &lt; 1, transforming the prob-
lem from an ILP to a Linear Program (LP), which
is polynomial. An LP solver is then applied on the
problem, and variables xzj that are assigned a frac-
tional value are rounded to their nearest integer and
so many violations of transitivity easily occur. The
solution when applying LP relaxation is not a transi-
tive graph, but nevertheless we show for comparison
in Section 5 that our method is much faster.
Last, we note that transitive relations have been
explored in adjacent fields such as Temporal Infor-
mation Extraction (Ling and Weld, 2010), Ontol-
ogy Induction (Poon and Domingos, 2010), and Co-
reference Resolution (Finkel and Manning, 2008).
</bodyText>
<sectionHeader confidence="0.996258" genericHeader="method">
3 Forest-reducible Graphs
</sectionHeader>
<bodyText confidence="0.999642083333333">
The entailment relation, described by entailment
graphs, is typically from a “semantically-specific”
predicate to a more “general” one. Thus, intuitively,
the topology of an entailment graph is expected to be
“tree-like”. In this section we first formalize this in-
tuition and then empirically analyze its validity. This
property of entailment graphs is an interesting topo-
logical observation on its own, but also enables the
efficient approximation algorithm of Section 4.
For a directed edge i —* j in a directed acyclic
graphs (DAG), we term the node i a child of node
j, and j a parent of i. A directed forest is a DAG
</bodyText>
<figureCaption confidence="0.957134">
Figure 1: A fragment of an entailment graph (a), its SCC
graph (b) and its reduced graph (c). Nodes are predicates
with typed variables (see Section 5), which are omitted in
(b) and (c) for compactness.
</figureCaption>
<bodyText confidence="0.999844277777778">
where all nodes have no more than one parent.
The entailment graph in Figure 1a (subgraph from
the data set described in Section 5) is clearly not a
directed forest – it contains a cycle of size two com-
prising the nodes ‘X common in Y’ and ‘Xfrequent in
Y’, and in addition the node ‘X be epidemic in Y’ has
3 parents. However, we can convert it to a directed
forest by applying the following operations. Any
directed graph G can be converted into a Strongly-
Connected-Component (SCC) graph in the follow-
ing way: every strongly connected component (a set
of semantically-equivalent predicates, in our graphs)
is contracted into a single node, and an edge is added
from SCC S1 to SCC S2 if there is an edge in G from
some node in S1 to some node in S2. The SCC graph
is always a DAG (Cormen et al., 2002), and if G is
transitive then the SCC graph is also transitive. The
graph in Figure 1b is the SCC graph of the one in
</bodyText>
<figure confidence="0.999426583333333">
Xdisease be
epidemic in
Ycountry
Xdisease
common in
Ycountry
Xdisease
occur in
Ycountry
Xdisease
frequent in
Ycountry
Xdisease
begin in
Ycountry
occur in
common in begin in
frequent in
be epidemic in
be epidemic in
common in
frequent in
occur in
begin in
</figure>
<page confidence="0.753595">
119
</page>
<figureCaption confidence="0.8897725">
Figure 2: A fragment of an entailment graph that is not
an FRG.
Figure 1a, but is still not a directed forest since the
node ‘X be epidemic in Y’ has two parents.
</figureCaption>
<bodyText confidence="0.999831649122807">
The transitive closure of a directed graph G is
obtained by adding an edge from node i to node j
if there is a path in G from i to j. The transitive
reduction of G is obtained by removing all edges
whose absence does not affect its transitive closure.
In DAGs, the result of transitive reduction is unique
(Aho et al., 1972). We thus define the reduced graph
Gred = (Vred, Ered) of a directed graph G as the
transitive reduction of its SCC graph. The graph in
Figure 1c is the reduced graph of the one in Fig-
ure 1a and is a directed forest. We say a graph is a
forest-reducible graph (FRG) if all nodes in its re-
duced form have no more than one parent.
We now hypothesize that entailment graphs are
FRGs. The intuition behind this assumption is
that the predicate on the left-hand-side of a uni-
directional entailment rule has a more specific mean-
ing than the one on the right-hand-side. For instance,
in Figure 1a ‘X be epidemic in Y’ (where ‘X’ is a type
of disease and ‘Y’ is a country) is more specific than
‘X common in Y’ and ‘X frequent in Y’, which are
equivalent, while ‘X occur in Y’ is even more gen-
eral. Accordingly, the reduced graph in Figure 1c
is an FRG. We note that this is not always the case:
for example, the entailment graph in Figure 2 is not
an FRG, because ‘X annex Y’ entails both ‘Y be part
of X’ and ‘X invade Y’, while the latter two do not
entail one another. However, we hypothesize that
this scenario is rather uncommon. Consequently, a
natural variant of the Max-Trans-Graph problem is
to restrict the required output graph of the optimiza-
tion problem (1) to an FRG. We term this problem
Max-Trans-Forest.
To test whether our hypothesis holds empirically
we performed the following analysis. We sampled
7 gold standard entailment graphs from the data set
described in Section 5, manually transformed them
into FRGs by deleting a minimal number of edges,
and measured recall over the set of edges in each
graph (precision is naturally 1.0, as we only delete
gold standard edges). The lowest recall value ob-
tained was 0.95, illustrating that deleting a very
small proportion of edges converts an entailment
graph into an FRG. Further support for the prac-
tical validity of this hypothesis is obtained from
our experiments in Section 5. In these experiments
we show that exactly solving Max-Trans-Graph and
Max-Trans-Forest (with an ILP solver) results in
nearly identical performance.
An ILP formulation for Max-Trans-Forest is sim-
ple – a transitive graph is an FRG if all nodes in
its reduced graph have no more than one parent. It
can be verified that this is equivalent to the following
statement: for every triplet of nodes i, j, k, if i —* j
and i —* k, then either j —* k or k —* j (or both).
Therefore, the ILP is formulated by adding this lin-
ear constraint to ILP (1):
</bodyText>
<equation confidence="0.976034">
di,j,kEV xij+xik+(1 − xjk)+(1 − xkj) :� 3 (2)
</equation>
<bodyText confidence="0.99999">
We note that despite the restriction to FRGs, Max-
Trans-Forest is an NP-hard problem by a reduction
from the X3C problem (Garey and Johnson, 1979).
We omit the reduction details for brevity.
</bodyText>
<sectionHeader confidence="0.995012" genericHeader="method">
4 Sequential Approximation Algorithms
</sectionHeader>
<bodyText confidence="0.99993275">
In this section we present Tree-Node-Fix, an efficient
approximation algorithm for Max-Trans-Forest, as
well as Graph-Node-Fix, an approximation for Max-
Trans-Graph.
</bodyText>
<subsectionHeader confidence="0.997473">
4.1 Tree-Node-Fix
</subsectionHeader>
<bodyText confidence="0.995697166666667">
The scheme of Tree-Node-Fix (TNF) is the follow-
ing. First, an initial FRG is constructed, using some
initialization procedure. Then, at each iteration a
single node v is re-attached (see below) to the FRG
in a way that improves the objective function. This
is repeated until the value of the objective function
cannot be improved anymore by re-attaching a node.
Re-attaching a node v is performed by removing
v from the graph and connecting it back with a better
set of edges, while maintaining the constraint that it
is an FRG. This is done by considering all possible
edges from/to the other graph nodes and choosing
</bodyText>
<table confidence="0.859986">
Xcountry annex Yplace
Xcountry invade Yplace
Yplace be part of Xcountry
</table>
<page confidence="0.876437">
120
</page>
<figureCaption confidence="0.973422">
Figure 3: (a) Inserting v into a component c E Vred. (b)
</figureCaption>
<bodyText confidence="0.8626662">
Inserting v as a child of c and a parent of a subset of c’s
children in Gred. (b’) A node d that is a descendant but
not a child of c can not choose v as a parent, as v becomes
its second parent. (c) Inserting v as a new root.
the optimal subset, while the rest of the graph re-
mains fixed. Formally, let Sv−in = Pi#v wiv · xiv
be the sum of scores over v’s incoming edges and
Sv−out = Pk#v wvk · xvk be the sum of scores over
v’s outgoing edges. Re-attachment amounts to opti-
mizing a linear objective:
</bodyText>
<equation confidence="0.9665385">
arg max (Sv-in + Sv-out) (3)
X„
</equation>
<bodyText confidence="0.999993111111111">
where the variables Xv C_ X are indicators for all
pairs of nodes involving v. We approximate a solu-
tion for (1) by iteratively optimizing the simpler ob-
jective (3). Clearly, at each re-attachment the value
of the objective function cannot decrease, since the
optimization algorithm considers the previous graph
as one of its candidate solutions.
We now show that re-attaching a node v is lin-
ear. To analyze v’s re-attachment, we consider the
structure of the directed forest Gred just before v is
re-inserted, and examine the possibilities for v’s in-
sertion relative to that structure. We start by defin-
ing some helpful notations. Every node c E Vred
is a connected component in G. Let vc E c be an
arbitrary representative node in c. We denote by
Sv-in(c) the sum of weights from all nodes in c and
their descendants to v, and by Sv-out(c) the sum of
weights from v to all nodes in c and their ancestors:
</bodyText>
<equation confidence="0.9758935">
XSv-in(c) = Xwiv + wkvxkv,
iEc k Oc
XSv-out(c) = Xwvi + wvkxv,k
iEc k Oc
</equation>
<bodyText confidence="0.978592583333334">
Note that {xv,k, xkv,} are edge indicators in G
and not Gred. There are two possibilities for re-
attaching v – either it is inserted into an existing
component c E Vred (Figure 3a), or it forms a new
component. In the latter, there are also two cases:
either v is inserted as a child of a component c (Fig-
ure 3b), or not and then it becomes a root in Gred
(Figure 3c). We describe the details of these 3 cases:
Case 1: Inserting v into a component c E Vred.
In this case we add in G edges from all nodes in c
and their descendants to v and from v to all nodes in
c and their ancestors. The score (3) in this case is
</bodyText>
<equation confidence="0.99361">
s1(c) Sv-in(c) + Sv-out(c) (4)
</equation>
<bodyText confidence="0.995186">
Case 2: Inserting v as a child of some c E Vred.
Once c is chosen as the parent of v, choosing v’s
children in Gred is substantially constrained. A node
that is not a descendant of c can not become a child
of v, since this would create a new path from that
node to c and would require by transitivity to add a
corresponding directed edge to c (but all graph edges
not connecting v are fixed). Moreover, only a direct
child of c can choose v as a parent instead of c (Fig-
ure 3b), since for any other descendant of c, v would
become a second parent, and Gred will no longer be
a directed forest (Figure 3b’). Thus, this case re-
quires adding in G edges from v to all nodes in c and
their ancestors, and also for each new child of v, de-
noted by d E Vred, we add edges from all nodes in
d and their descendants to v. Crucially, although the
number of possible subsets of c’s children in Gred is
exponential, the fact that they are independent trees
in Gred allows us to go over them one by one, and
decide for each one whether it will be a child of v
or not, depending on whether Sv-in(d) is positive.
Therefore, the score (3) in this case is:
</bodyText>
<equation confidence="0.997385">
Xs2(c) 0= Sv-out(c)+ max(0, Sv-in(d)) (5)
dEchild(c)
</equation>
<bodyText confidence="0.997528428571429">
where child(c) are the children of c.
Case 3: Inserting v as a new root in Gred. Similar
to case 2, only roots of Gred can become children of
v. In this case for each chosen root r we add in G
edges from the nodes in r and their descendants to
v. Again, each root can be examined independently.
Therefore, the score (3) of re-attaching v is:
</bodyText>
<equation confidence="0.9954145">
Xs3 0= max(0, Sv-in(r)) (6)
r
</equation>
<bodyText confidence="0.995883666666667">
where the summation is over the roots of Gred.
It can be easily verified that Sv-in(c) and
Sv-out(c) satisfy the recursive definitions:
</bodyText>
<figure confidence="0.967953103448276">
(a)
(b)
c
c v
v
d1 d2 ...
(b’)
...
d
c
v r1 r2
... ... ...
(c)
v
r3
...
121
Algorithm 1 Computing optimal re-attachment
Input: FRG G = (V, E), function w, node v ∈ V
Output: optimal re-attachment of v
1: remove v and compute Gred = (Vred, Ered).
2: for all c ∈ Vred in post-order compute S„-i,,,,(c) (Eq.
7)
3: for all c ∈ Vred in pre-order compute S,-out(c) (Eq.
8)
4: case 1: s1 = maxcEVTed s1(c) (Eq. 4)
5: case 2: s2 = maxcEV,ed s2(c) (Eq. 5)
6: case 3: compute s3 (Eq. 6)
7: re-attach v according to max(s1, s2, s3).
</figure>
<equation confidence="0.97460725">
�Sv-in(c) = �wiv + Sv-in(d), c ∈ Vred (7)
iEc dEchild(c)
�Sv-out(c) = wvi + Sv-out(p), c ∈ Vred (8)
iEc
</equation>
<bodyText confidence="0.999822826086956">
where p is the parent of c in Gred. These recursive
definitions allow to compute in linear time Sv-in(c)
and Sv-out(c) for all c (given Gred) using dynamic
programming, before going over the cases for re-
attaching v. Sv-in(c) is computed going over Vred
leaves-to-root (post-order), and Sv-out(c) is com-
puted going over Vred root-to-leaves (pre-order).
Re-attachment is summarized in Algorithm 1.
Computing an SCC graph is linear (Cormen et al.,
2002) and it is easy to verify that transitive reduction
in FRGs is also linear (Line 1). Computing Sv-in(c)
and Sv-out(c) (Lines 2-3) is also linear, as explained.
Cases 1 and 3 are trivially linear and in case 2 we go
over the children of all nodes in Vred. As the reduced
graph is a forest, this simply means going over all
nodes of Vred, and so the entire algorithm is linear.
Since re-attachment is linear, re-attaching all
nodes is quadratic. Thus if we bound the number
of iterations over all nodes, the overall complexity is
quadratic. This is dramatically more efficient and
scalable than applying an ILP solver. In Section
5 we ran TNF until convergence and the maximal
number of iterations over graph nodes was 8.
</bodyText>
<subsectionHeader confidence="0.991171">
4.2 Graph-node-fix
</subsectionHeader>
<bodyText confidence="0.999694166666667">
Next, we show Graph-Node-Fix (GNF), a similar
approximation that employs the same re-attachment
strategy but does not assume the graph is an FRG.
Thus, re-attachment of a node v is done with an
ILP solver. Nevertheless, the ILP in GNF is sim-
pler than (1), since we consider only candidate edges
</bodyText>
<figureCaption confidence="0.986493">
Figure 4: Three types of transitivity constraint violations.
</figureCaption>
<bodyText confidence="0.892911642857143">
involving v. Figure 4 illustrates the three types of
possible transitivity constraint violations when re-
attaching v. The left side depicts a violation when
(i, k) ∈/ E, expressed by the constraint in (9) below,
and the middle and right depict two violations when
the edge (i, k) ∈ E, expressed by the constraints
in (10). Thus, the ILP is formulated by adding the
following constraints to the objective function (3):
∀i,kEV \{v} if (i, k) ∈/ E, xiv + xvk ≤ 1
if (i, k) ∈ E, xvi ≤ xvk, xkv ≤ xiv
xiv, xvk ∈ {0, 1}
Complexity is exponential due to the ILP solver;
however, the ILP size is reduced by an order of mag-
nitude to O(|V |) variables and O(|V |2) constraints.
</bodyText>
<subsectionHeader confidence="0.999909">
4.3 Adding local constraints
</subsectionHeader>
<bodyText confidence="0.999964375">
For some pairs of predicates i, j we sometimes have
prior knowledge whether i entails j or not. We term
such pairs local constraints, and incorporate them
into the aforementioned algorithms in the following
way. In all algorithms that apply an ILP solver, we
add a constraint xig = 1 if i entails j or xig = 0 if i
does not entail j. Similarly, in TNF we incorporate
local constraints by setting wig = ∞ or wig = −∞.
</bodyText>
<sectionHeader confidence="0.991004" genericHeader="evaluation">
5 Experiments and Results
</sectionHeader>
<bodyText confidence="0.999887333333333">
In this section we empirically demonstrate that TNF
is more efficient than other baselines and its output
quality is close to that given by the optimal solution.
</bodyText>
<subsectionHeader confidence="0.99575">
5.1 Experimental setting
</subsectionHeader>
<bodyText confidence="0.999881333333333">
In our experiments we utilize the data set released
by Berant et al. (2011). The data set contains 10 en-
tailment graphs, where graph nodes are typed pred-
icates. A typed predicate (e.g., ‘Xdisease occur in
Ycountry’) includes a predicate and two typed vari-
ables that specify the semantic type of the argu-
ments. For instance, the typed variable Xdisease can
be instantiated by arguments such as ‘~u’ or ‘dia-
betes’. The data set contains 39,012 potential edges,
</bodyText>
<figure confidence="0.874683">
i k
v
i k
v
i k
v
122
10 50 100 500 5000 50000
</figure>
<bodyText confidence="0.999781326086957">
of which 3,427 are annotated as edges (valid entail-
ment rules) and 35,585 are annotated as non-edges.
The data set also contains, for every pair of pred-
icates i, j in every graph, a local score sig, which is
the output of a classifier trained over distributional
similarity features. A positive sig indicates that the
classifier believes i → j. The weighting function for
the graph edges w is defined as wig = sig −A, where
A is a single parameter controlling graph sparseness:
as A increases, wig decreases and becomes nega-
tive for more pairs of predicates, rendering the graph
more sparse. In addition, the data set contains a set
of local constraints (see Section 4.3).
We implemented the following algorithms for
learning graph edges, where in all of them the graph
is first decomposed into components according to
Berant et al’s method, as explained in Section 2.
No-trans Local scores are used without transitiv-
ity constraints – an edge (i, j) is inserted iff wig &gt; 0.
Exact-graph Berant et al.’s exact method (2011)
for Max-Trans-Graph, which utilizes an ILP solver1.
Exact-forest Solving Max-Trans-Forest exactly
by applying an ILP solver (see Eq. 2).
LP-relax Solving Max-Trans-Graph approxi-
mately by applying LP-relaxation (see Section 2)
on each graph component. We apply the LP solver
within the same cutting-plane procedure as Exact-
graph to allow for a direct comparison. This also
keeps memory consumption manageable, as other-
wise all |V |3 constraints must be explicitly encoded
into the LP. As mentioned, our goal is to present
a method for learning transitive graphs, while LP-
relax produces solutions that violate transitivity.
However, we run it on our data set to obtain empiri-
cal results, and to compare run-times against TNF.
Graph-Node-Fix (GNF) Initialization of each
component is performed in the following way: if the
graph is very sparse, i.e. A ≥ C for some constant C
(set to 1 in our experiments), then solving the graph
exactly is not an issue and we use Exact-graph. Oth-
erwise, we initialize by applying Exact-graph in a
sparse configuration, i.e., A = C.
Tree-Node-Fix (TNF) Initialization is done as in
GNF, except that if it generates a graph that is not an
FRG, it is corrected by a simple heuristic: for every
node in the reduced graph GTed that has more than
</bodyText>
<footnote confidence="0.867056">
1We use the Gurobi optimization package in all experiments.
</footnote>
<figure confidence="0.392683">
−0.8 −0.6 −0.4 −0.2 0.0
</figure>
<figureCaption confidence="0.999385">
Figure 5: Run-time in seconds for various −A values.
</figureCaption>
<bodyText confidence="0.999944">
one parent, we choose from its current parents the
single one whose SCC is composed of the largest
number of nodes in G.
We evaluate algorithms by comparing the set of
gold standard edges with the set of edges learned by
each algorithm. We measure recall, precision and
Fs for various values of the sparseness parameter
A, and compute the area under the precision-recall
Curve (AUC) generated. Efficiency is evaluated by
comparing run-times.
</bodyText>
<subsectionHeader confidence="0.893516">
5.2 Results
</subsectionHeader>
<bodyText confidence="0.999950666666667">
We first focus on run-times and show that TNF is
efficient and has potential to scale to large data sets.
Figure 5 compares run-times2 of Exact-graph,
GNF, TNF, and LP-relax as −A increases and the
graph becomes denser. Note that the y-axis is in
logarithmic scale. Clearly, Exact-graph is extremely
slow and run-time increases quickly. For A = 0.3
run-time was already 12 hours and we were unable
to obtain results for A &lt; 0.3, while in TNF we easily
got a solution for any A. When A = 0.6, where both
Exact-graph and TNF achieve best Fs, TNF is 10
times faster than Exact-graph. When A = 0.5, TNF
is 50 times faster than Exact-graph and so on. Most
importantly, run-time for GNF and TNF increases
much more slowly than for Exact-graph.
</bodyText>
<footnote confidence="0.533364">
2Run on a multi-core 2.5GHz server with 32GB of RAM.
</footnote>
<figure confidence="0.997390272727273">
●
●
●
●
●
●
●
● Exact−graph
LP−relax
GNF
TNF
</figure>
<page confidence="0.853344">
123
</page>
<figureCaption confidence="0.92679">
Figure 6: Precision (y-axis) vs. recall (x-axis) curve.
Maximal Fl on the curve is .43 for Exact-graph, .41 for
TNF, and .34 for No-trans. AUC in the recall range 0-0.5
is .32 for Exact-graph, .31 for TNF, and .26 for No-trans.
</figureCaption>
<bodyText confidence="0.999981378378378">
Run-time of LP-relax is also bad compared to
TNF and GNF. Run-time increases more slowly than
Exact-graph, but still very fast comparing to TNF.
When A = 0.6, LP-relax is almost 10 times slower
than TNF, and when A = −0.1, LP-relax is 200
times slower than TNF. This points to the difficulty
of scaling LP-relax to large graphs.
As for the quality of learned graphs, Figure 6 pro-
vides a precision-recall curve for Exact-graph, TNF
and No-trans (GNF and LP-relax are omitted from
the figure and described below to improve readabil-
ity). We observe that both Exact-graph and TNF
substantially outperform No-trans and that TNF’s
graph quality is only slightly lower than Exact-graph
(which is extremely slow). Following Berant et al.,
we report in the caption the maximal F1 on the curve
and AUC in the recall range 0-0.5 (the widest range
for which we have results for all algorithms). Note
that compared to Exact-graph, TNF reduces AUC by
a point and the maximal F1 score by 2 points only.
GNF results are almost identical to those of TNF
(maximal F1=0.41, AUC: 0.31), and in fact for all
A configurations TNF outperforms GNF by no more
than one F1 point. As for LP-relax, results are just
slightly lower than Exact-graph (maximal F1: 0.43,
AUC: 0.32), but its output is not a transitive graph,
and as shown above run-time is quite slow. Last, we
note that the results of Exact-forest are almost iden-
tical to Exact-graph (maximal F1: 0.43), illustrating
that assuming that entailment graphs are FRGs (Sec-
tion 3) is reasonable in this data set.
To conclude, TNF learns transitive entailment
graphs of good quality much faster than Exact-
graph. Our experiment utilized an available data
set of moderate size; However, we expect TNF to
scale to large data sets (that are currently unavail-
able), where other baselines would be impractical.
</bodyText>
<sectionHeader confidence="0.998916" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999962173913043">
Learning large and accurate resources of entailment
rules is essential in many semantic inference appli-
cations. Employing transitivity has been shown to
improve rule learning, but raises issues of efficiency
and scalability.
The first contribution of this paper is a novel mod-
eling assumption that entailment graphs are very
similar to FRGs, which is analyzed and validated
empirically. The main contribution of the paper is
an efficient polynomial approximation algorithm for
learning entailment rules, which is based on this
assumption. We demonstrate empirically that our
method is by orders of magnitude faster than the
state-of-the-art exact algorithm, but still produces an
output that is almost as good as the optimal solution.
We suggest our method as an important step to-
wards scalable acquisition of precise entailment re-
sources. In future work, we aim to evaluate TNF on
large graphs that are automatically generated from
huge corpora. This of course requires substantial ef-
forts of pre-processing and test-set annotation. We
also plan to examine the benefit of TNF in learning
similar structures, e.g., taxonomies or ontologies.
</bodyText>
<sectionHeader confidence="0.99698" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999936666666667">
This work was partially supported by the Israel
Science Foundation grant 1112/08, the PASCAL-
2 Network of Excellence of the European Com-
munity FP7-ICT-2007-1-216886, and the Euro-
pean Community’s Seventh Framework Programme
(FP7/2007-2013) under grant agreement no. 287923
(EXCITEMENT). The first author has carried out
this research in partial fulfilment of the requirements
for the Ph.D. degree.
</bodyText>
<figure confidence="0.999466095238095">
0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7
0.0 0.2 0.4 0.6 0.8 1.0
●
●
●● ●
●
●
● ●
●
●
●
● ●
●
●
●
●
●
●
● Exact−graph
TNF
No−trans
</figure>
<page confidence="0.989826">
124
</page>
<sectionHeader confidence="0.992749" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999786783505155">
Alfred V. Aho, Michael R. Garey, and Jeffrey D. Ullman.
1972. The transitive reduction of a directed graph.
SIAM Journal on Computing, 1(2):131–137.
Roni Ben Aharon, Idan Szpektor, and Ido Dagan. 2010.
Generating entailment rules from framenet. In Pro-
ceedings of the 48th Annual Meeting of the Association
for Computational Linguistics.
Jonathan Berant, Ido Dagan, and Jacob Goldberger.
2010. Global learning of focused entailment graphs.
In Proceedings of the 48th Annual Meeting of the As-
sociation for Computational Linguistics.
Jonathan Berant, Ido Dagan, and Jacob Goldberger.
2011. Global learning of typed entailment rules. In
Proceedings of the 49th Annual Meeting of the Associ-
ation for Computational Linguistics.
Coyne Bob and Owen Rambow. 2009. Lexpar: A freely
available english paraphrase lexicon automatically ex-
tracted from framenet. In Proceedings of IEEE Inter-
national Conference on Semantic Computing.
Timothy Chklovski and Patrick Pantel. 2004. Verb
ocean: Mining the web for fine-grained semantic verb
relations. In Proceedings of Empirical Methods in
Natural Language Processing.
Thomas H. Cormen, Charles E. leiserson, Ronald L.
Rivest, and Clifford Stein. 2002. Introduction to Al-
gorithms. The MIT Press.
Ido Dagan, Bill Dolan, Bernardo Magnini, and Dan Roth.
2009. Recognizing textual entailment: Rational, eval-
uation and approaches. Natural Language Engineer-
ing, 15(4):1–17.
Quang Do and Dan Roth. 2010. Constraints based tax-
onomic relation classification. In Proceedings of Em-
pirical Methods in Natural Language Processing.
Anthony Fader, Stephen Soderland, and Oren Etzioni.
2011. Identifying relations for open information ex-
traction. In Proceedings of Empirical Methods in Nat-
ural Language Processing.
J. R. Finkel and C. D. Manning. 2008. Enforcing transi-
tivity in coreference resolution. In Proceedings of the
46th Annual Meeting of the Association for Computa-
tional Linguistics.
Michael R. Garey and David S. Johnson. 1979. Comput-
ers and Intractability: A Guide to the Theory of NP-
Completeness. W. H. Freeman.
Dekang Lin and Patrick Pantel. 2001. Discovery of infer-
ence rules for question answering. Natural Language
Engineering, 7(4):343–360.
Xiao Ling and Dan S. Weld. 2010. Temporal informa-
tion extraction. In Proceedings of the 24th AAAI Con-
ference on Artificial Intelligence.
Andre Martins, Noah Smith, and Eric Xing. 2009. Con-
cise integer linear programming formulations for de-
pendency parsing. In Proceedings of the 47th Annual
Meeting of the Association for Computational Linguis-
tics.
Hoifung Poon and Pedro Domingos. 2010. Unsuper-
vised ontology induction from text. In Proceedings of
the 48th Annual Meeting of the Association for Com-
putational Linguistics.
Deepak Ravichandran and Eduard Hovy. 2002. Learning
surface text patterns for a question answering system.
In Proceedings of the 40th Annual Meeting of the As-
sociation for Computational Linguistics.
Sebastian Riedel and James Clarke. 2006. Incremental
integer linear programming for non-projective depen-
dency parsing. In Proceedings of Empirical Methods
in Natural Language Processing.
Stefan Schoenmackers, Jesse Davis, Oren Etzioni, and
Daniel S. Weld. 2010. Learning first-order horn
clauses from web text. In Proceedings of Empirical
Methods in Natural Language Processing.
Satoshi Sekine. 2005. Automatic paraphrase discovery
based on context and keywords between ne pairs. In
Proceedings of IWP.
Yusuke Shinyama and Satoshi Sekine. 2006. Preemptive
information extraction using unrestricted relation dis-
covery. In Proceedings of the Human Language Tech-
nology Conference of the NAACL, Main Conference.
Rion Snow, Dan Jurafsky, and Andrew Y. Ng. 2006.
Semantic taxonomy induction from heterogenous ev-
idence. In Proceedings of the 44th Annual Meeting of
the Association for Computational Linguistics.
Idan Szpektor and Ido Dagan. 2008. Learning entail-
ment rules for unary templates. In Proceedings of the
22nd International Conference on Computational Lin-
guistics.
Idan Szpektor and Ido Dagan. 2009. Augmenting
wordnet-based inference with argument mapping. In
Proceedings of TextInfer.
Idan Szpektor, Hristo Tanev, Ido Dagan, and Bonaven-
tura Coppola. 2004. Scaling web-based acquisition
of entailment relations. In Proceedings of Empirical
Methods in Natural Language Processing.
Alexander Yates and Oren Etzioni. 2009. Unsupervised
methods for determining object and relation synonyms
on the web. Journal ofArtificial Intelligence Research,
34:255–296.
</reference>
<page confidence="0.998495">
125
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.373272">
<title confidence="0.999915">Efficient Tree-based Approximation for Entailment Graph Learning</title>
<author confidence="0.892339">Ido Meni Jacob Blavatnik School of Computer Science</author>
<author confidence="0.892339">Tel Aviv</author>
<affiliation confidence="0.79674">of Computer Science, Bar-Ilan of Engineering, Bar-Ilan University</affiliation>
<email confidence="0.911429">jonatha6@post.tau.ac.iladlerm@cs.bgu.ac.il</email>
<abstract confidence="0.99945215">Learning entailment rules is fundamental in many semantic-inference applications and has been an active field of research in recent years. In this paper we address the problem of learning transitive graphs that describe entailment between predicates (termed We first identify that entailment graphs exhibit a “tree-like” property and are very similar to a novel type of graph termed We utilize this property to develop an iterative efficient approximation algorithm for learning the graph edges, where each iteration takes linear time. We compare our approximation algorithm to a recently-proposed state-of-the-art exact algorithm and show that it is more efficient and scalable both theoretically and empirically, while its output quality is close to that given by the optimal solution of the exact algorithm.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Alfred V Aho</author>
<author>Michael R Garey</author>
<author>Jeffrey D Ullman</author>
</authors>
<title>The transitive reduction of a directed graph.</title>
<date>1972</date>
<journal>SIAM Journal on Computing,</journal>
<volume>1</volume>
<issue>2</issue>
<contexts>
<context position="12377" citStr="Aho et al., 1972" startWordPosition="2050" endWordPosition="2053">gin in Ycountry occur in common in begin in frequent in be epidemic in be epidemic in common in frequent in occur in begin in 119 Figure 2: A fragment of an entailment graph that is not an FRG. Figure 1a, but is still not a directed forest since the node ‘X be epidemic in Y’ has two parents. The transitive closure of a directed graph G is obtained by adding an edge from node i to node j if there is a path in G from i to j. The transitive reduction of G is obtained by removing all edges whose absence does not affect its transitive closure. In DAGs, the result of transitive reduction is unique (Aho et al., 1972). We thus define the reduced graph Gred = (Vred, Ered) of a directed graph G as the transitive reduction of its SCC graph. The graph in Figure 1c is the reduced graph of the one in Figure 1a and is a directed forest. We say a graph is a forest-reducible graph (FRG) if all nodes in its reduced form have no more than one parent. We now hypothesize that entailment graphs are FRGs. The intuition behind this assumption is that the predicate on the left-hand-side of a unidirectional entailment rule has a more specific meaning than the one on the right-hand-side. For instance, in Figure 1a ‘X be epid</context>
</contexts>
<marker>Aho, Garey, Ullman, 1972</marker>
<rawString>Alfred V. Aho, Michael R. Garey, and Jeffrey D. Ullman. 1972. The transitive reduction of a directed graph. SIAM Journal on Computing, 1(2):131–137.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roni Ben Aharon</author>
<author>Idan Szpektor</author>
<author>Ido Dagan</author>
</authors>
<title>Generating entailment rules from framenet.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="5916" citStr="Aharon et al., 2010" startWordPosition="902" endWordPosition="905">h may improve scalability in these fields as well. 2 Background Until recently, work on learning entailment rules between predicates considered each rule independently of others and did not exploit global dependencies. Most methods utilized the distributional similarity hypothesis that states that semantically similar predicates occur with similar arguments (Lin and Pantel, 2001; Szpektor et al., 2004; Yates and Etzioni, 2009; Schoenmackers et al., 2010). Some methods extracted rules from lexicographic resources such as WordNet (Szpektor and Dagan, 2009) or FrameNet (Bob and Rambow, 2009; Ben Aharon et al., 2010), and others assumed that semantic relations between predicates can be deduced from their co-occurrence in a corpus via manually-constructed patterns (Chklovski and Pantel, 2004). Recently, Berant et al. (2010; 2011) formulated the problem as the problem of learning global entailment graphs. In entailment graphs, nodes are predicates (e.g., ‘X attack Y’) and edges represent entailment rules between them (‘X invade Y → X attack Y’). For every pair of predicates i, j, an entailment score wij was learned by training a classifier over distributional similarity features. A positive wij indicated th</context>
</contexts>
<marker>Aharon, Szpektor, Dagan, 2010</marker>
<rawString>Roni Ben Aharon, Idan Szpektor, and Ido Dagan. 2010. Generating entailment rules from framenet. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan Berant</author>
<author>Ido Dagan</author>
<author>Jacob Goldberger</author>
</authors>
<title>Global learning of focused entailment graphs.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="2577" citStr="Berant et al. (2010)" startWordPosition="384" endWordPosition="387"> rules that describe a directional inference relation between two fragments of text. An important type of entailment rule specifies the entailment relation between natural language predicates, e.g., the entailment rule ‘X invade Y —* X attack Y’ can be helpful in inferring the aforementioned hypothesis. Consequently, substantial effort has been made to learn such rules (Lin and Pantel, 2001; Sekine, 2005; Szpektor and Dagan, 2008; Schoenmackers et al., 2010). Textual entailment is inherently a transitive relation , that is, the rules ‘x —* y’ and ‘y —* z’ imply the rule ‘x —* z’. Accordingly, Berant et al. (2010) formulated the problem of learning entailment rules as a graph optimization problem, where nodes are predicates and edges represent entailment rules that respect transitivity. Since finding the optimal set of edges respecting transitivity is NP-hard, they employed Integer Linear Programming (ILP) to find the exact solution. Indeed, they showed that applying global transitivity constraints improves rule learning comparing to methods that ignore graph structure. More recently, Berant et al. (Berant et al., 2011) introduced a more efficient exact algorithm, which decomposes the graph into connec</context>
<context position="6125" citStr="Berant et al. (2010" startWordPosition="932" endWordPosition="935">dencies. Most methods utilized the distributional similarity hypothesis that states that semantically similar predicates occur with similar arguments (Lin and Pantel, 2001; Szpektor et al., 2004; Yates and Etzioni, 2009; Schoenmackers et al., 2010). Some methods extracted rules from lexicographic resources such as WordNet (Szpektor and Dagan, 2009) or FrameNet (Bob and Rambow, 2009; Ben Aharon et al., 2010), and others assumed that semantic relations between predicates can be deduced from their co-occurrence in a corpus via manually-constructed patterns (Chklovski and Pantel, 2004). Recently, Berant et al. (2010; 2011) formulated the problem as the problem of learning global entailment graphs. In entailment graphs, nodes are predicates (e.g., ‘X attack Y’) and edges represent entailment rules between them (‘X invade Y → X attack Y’). For every pair of predicates i, j, an entailment score wij was learned by training a classifier over distributional similarity features. A positive wij indicated that the classifier believes i → j and a negative wij indicated that the classifier believes i 9 j. Given the graph nodes V (corresponding to the predicates) and the weighting function w : V × V → R, they aim to</context>
</contexts>
<marker>Berant, Dagan, Goldberger, 2010</marker>
<rawString>Jonathan Berant, Ido Dagan, and Jacob Goldberger. 2010. Global learning of focused entailment graphs. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan Berant</author>
<author>Ido Dagan</author>
<author>Jacob Goldberger</author>
</authors>
<title>Global learning of typed entailment rules.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="3093" citStr="Berant et al., 2011" startWordPosition="458" endWordPosition="461">on , that is, the rules ‘x —* y’ and ‘y —* z’ imply the rule ‘x —* z’. Accordingly, Berant et al. (2010) formulated the problem of learning entailment rules as a graph optimization problem, where nodes are predicates and edges represent entailment rules that respect transitivity. Since finding the optimal set of edges respecting transitivity is NP-hard, they employed Integer Linear Programming (ILP) to find the exact solution. Indeed, they showed that applying global transitivity constraints improves rule learning comparing to methods that ignore graph structure. More recently, Berant et al. (Berant et al., 2011) introduced a more efficient exact algorithm, which decomposes the graph into connected components and then applies an ILP solver over each component. Despite this progress, finding the exact solution remains NP-hard – the authors themselves report they were unable to solve some graphs of rather moderate size and that the coverage of their method is limited. Thus, scaling their algorithm to data sets with tens of thousands of predicates (e.g., the extractions of Fader et al. (2011)) is unlikely. 117 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages </context>
<context position="7828" citStr="Berant et al., 2011" startWordPosition="1263" endWordPosition="1266">riables of the following ILP for Max-Trans-Graph: �arg max wij · xij (1) X i#j s.t. ∀i,j,kEV xij + xjk − xik ≤ 1 ∀i,jEV xij ∈ {0, 1} The objective function is the sum of weights over the edges of G and the constraint xij + xjk − xik ≤ 1 on the binary variables enforces that whenever xij = xjk =1, then also xik = 1 (transitivity). Since ILP is NP-hard, applying an ILP solver directly does not scale well because the number of variables is O(|V |2) and the number of constraints is O(|V |3). Thus, even a graph with ∼80 nodes (predicates) has more than half a million constraints. Consequently, in (Berant et al., 2011), they proposed a method that efficiently decomposes the graph into smaller components and applies an ILP solver on each component separately using a cutting-plane procedure (Riedel and Clarke, 2006). Although this method is exact and improves scalability, it does not guarantee an efficient solution. When the graph does not decompose into sufficiently small components, and the weights generate many violations of 118 transitivity, solving Max-Trans-Graph becomes intractable. To address this problem, we present in this paper a method for approximating the optimal set of edges within each compone</context>
<context position="23500" citStr="Berant et al. (2011)" startWordPosition="4105" endWordPosition="4108"> j or not. We term such pairs local constraints, and incorporate them into the aforementioned algorithms in the following way. In all algorithms that apply an ILP solver, we add a constraint xig = 1 if i entails j or xig = 0 if i does not entail j. Similarly, in TNF we incorporate local constraints by setting wig = ∞ or wig = −∞. 5 Experiments and Results In this section we empirically demonstrate that TNF is more efficient than other baselines and its output quality is close to that given by the optimal solution. 5.1 Experimental setting In our experiments we utilize the data set released by Berant et al. (2011). The data set contains 10 entailment graphs, where graph nodes are typed predicates. A typed predicate (e.g., ‘Xdisease occur in Ycountry’) includes a predicate and two typed variables that specify the semantic type of the arguments. For instance, the typed variable Xdisease can be instantiated by arguments such as ‘~u’ or ‘diabetes’. The data set contains 39,012 potential edges, i k v i k v i k v 122 10 50 100 500 5000 50000 of which 3,427 are annotated as edges (valid entailment rules) and 35,585 are annotated as non-edges. The data set also contains, for every pair of predicates i, j in ev</context>
</contexts>
<marker>Berant, Dagan, Goldberger, 2011</marker>
<rawString>Jonathan Berant, Ido Dagan, and Jacob Goldberger. 2011. Global learning of typed entailment rules. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Coyne Bob</author>
<author>Owen Rambow</author>
</authors>
<title>Lexpar: A freely available english paraphrase lexicon automatically extracted from framenet.</title>
<date>2009</date>
<booktitle>In Proceedings of IEEE International Conference on Semantic Computing.</booktitle>
<contexts>
<context position="5890" citStr="Bob and Rambow, 2009" startWordPosition="897" endWordPosition="900">010), and thus our approach may improve scalability in these fields as well. 2 Background Until recently, work on learning entailment rules between predicates considered each rule independently of others and did not exploit global dependencies. Most methods utilized the distributional similarity hypothesis that states that semantically similar predicates occur with similar arguments (Lin and Pantel, 2001; Szpektor et al., 2004; Yates and Etzioni, 2009; Schoenmackers et al., 2010). Some methods extracted rules from lexicographic resources such as WordNet (Szpektor and Dagan, 2009) or FrameNet (Bob and Rambow, 2009; Ben Aharon et al., 2010), and others assumed that semantic relations between predicates can be deduced from their co-occurrence in a corpus via manually-constructed patterns (Chklovski and Pantel, 2004). Recently, Berant et al. (2010; 2011) formulated the problem as the problem of learning global entailment graphs. In entailment graphs, nodes are predicates (e.g., ‘X attack Y’) and edges represent entailment rules between them (‘X invade Y → X attack Y’). For every pair of predicates i, j, an entailment score wij was learned by training a classifier over distributional similarity features. A</context>
</contexts>
<marker>Bob, Rambow, 2009</marker>
<rawString>Coyne Bob and Owen Rambow. 2009. Lexpar: A freely available english paraphrase lexicon automatically extracted from framenet. In Proceedings of IEEE International Conference on Semantic Computing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothy Chklovski</author>
<author>Patrick Pantel</author>
</authors>
<title>Verb ocean: Mining the web for fine-grained semantic verb relations.</title>
<date>2004</date>
<booktitle>In Proceedings of Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="6094" citStr="Chklovski and Pantel, 2004" startWordPosition="927" endWordPosition="930">others and did not exploit global dependencies. Most methods utilized the distributional similarity hypothesis that states that semantically similar predicates occur with similar arguments (Lin and Pantel, 2001; Szpektor et al., 2004; Yates and Etzioni, 2009; Schoenmackers et al., 2010). Some methods extracted rules from lexicographic resources such as WordNet (Szpektor and Dagan, 2009) or FrameNet (Bob and Rambow, 2009; Ben Aharon et al., 2010), and others assumed that semantic relations between predicates can be deduced from their co-occurrence in a corpus via manually-constructed patterns (Chklovski and Pantel, 2004). Recently, Berant et al. (2010; 2011) formulated the problem as the problem of learning global entailment graphs. In entailment graphs, nodes are predicates (e.g., ‘X attack Y’) and edges represent entailment rules between them (‘X invade Y → X attack Y’). For every pair of predicates i, j, an entailment score wij was learned by training a classifier over distributional similarity features. A positive wij indicated that the classifier believes i → j and a negative wij indicated that the classifier believes i 9 j. Given the graph nodes V (corresponding to the predicates) and the weighting func</context>
</contexts>
<marker>Chklovski, Pantel, 2004</marker>
<rawString>Timothy Chklovski and Patrick Pantel. 2004. Verb ocean: Mining the web for fine-grained semantic verb relations. In Proceedings of Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas H Cormen</author>
<author>Charles E leiserson</author>
<author>Ronald L Rivest</author>
<author>Clifford Stein</author>
</authors>
<title>Introduction to Algorithms.</title>
<date>2002</date>
<publisher>The MIT Press.</publisher>
<contexts>
<context position="11513" citStr="Cormen et al., 2002" startWordPosition="1885" endWordPosition="1888">ycle of size two comprising the nodes ‘X common in Y’ and ‘Xfrequent in Y’, and in addition the node ‘X be epidemic in Y’ has 3 parents. However, we can convert it to a directed forest by applying the following operations. Any directed graph G can be converted into a StronglyConnected-Component (SCC) graph in the following way: every strongly connected component (a set of semantically-equivalent predicates, in our graphs) is contracted into a single node, and an edge is added from SCC S1 to SCC S2 if there is an edge in G from some node in S1 to some node in S2. The SCC graph is always a DAG (Cormen et al., 2002), and if G is transitive then the SCC graph is also transitive. The graph in Figure 1b is the SCC graph of the one in Xdisease be epidemic in Ycountry Xdisease common in Ycountry Xdisease occur in Ycountry Xdisease frequent in Ycountry Xdisease begin in Ycountry occur in common in begin in frequent in be epidemic in be epidemic in common in frequent in occur in begin in 119 Figure 2: A fragment of an entailment graph that is not an FRG. Figure 1a, but is still not a directed forest since the node ‘X be epidemic in Y’ has two parents. The transitive closure of a directed graph G is obtained by </context>
<context position="21004" citStr="Cormen et al., 2002" startWordPosition="3658" endWordPosition="3661">: compute s3 (Eq. 6) 7: re-attach v according to max(s1, s2, s3). �Sv-in(c) = �wiv + Sv-in(d), c ∈ Vred (7) iEc dEchild(c) �Sv-out(c) = wvi + Sv-out(p), c ∈ Vred (8) iEc where p is the parent of c in Gred. These recursive definitions allow to compute in linear time Sv-in(c) and Sv-out(c) for all c (given Gred) using dynamic programming, before going over the cases for reattaching v. Sv-in(c) is computed going over Vred leaves-to-root (post-order), and Sv-out(c) is computed going over Vred root-to-leaves (pre-order). Re-attachment is summarized in Algorithm 1. Computing an SCC graph is linear (Cormen et al., 2002) and it is easy to verify that transitive reduction in FRGs is also linear (Line 1). Computing Sv-in(c) and Sv-out(c) (Lines 2-3) is also linear, as explained. Cases 1 and 3 are trivially linear and in case 2 we go over the children of all nodes in Vred. As the reduced graph is a forest, this simply means going over all nodes of Vred, and so the entire algorithm is linear. Since re-attachment is linear, re-attaching all nodes is quadratic. Thus if we bound the number of iterations over all nodes, the overall complexity is quadratic. This is dramatically more efficient and scalable than applyin</context>
</contexts>
<marker>Cormen, leiserson, Rivest, Stein, 2002</marker>
<rawString>Thomas H. Cormen, Charles E. leiserson, Ronald L. Rivest, and Clifford Stein. 2002. Introduction to Algorithms. The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Bill Dolan</author>
<author>Bernardo Magnini</author>
<author>Dan Roth</author>
</authors>
<title>Recognizing textual entailment: Rational, evaluation and approaches.</title>
<date>2009</date>
<journal>Natural Language Engineering,</journal>
<volume>15</volume>
<issue>4</issue>
<contexts>
<context position="1503" citStr="Dagan et al., 2009" startWordPosition="206" endWordPosition="209">algorithm for learning the graph edges, where each iteration takes linear time. We compare our approximation algorithm to a recently-proposed state-of-the-art exact algorithm and show that it is more efficient and scalable both theoretically and empirically, while its output quality is close to that given by the optimal solution of the exact algorithm. 1 Introduction Performing textual inference is in the heart of many semantic inference applications such as Question Answering (QA) and Information Extraction (IE). A prominent generic paradigm for textual inference is Textual Entailment (TUE) (Dagan et al., 2009). In TUE, the goal is to recognize, given two text fragments termed text and hypothesis, whether the hypothesis can be inferred from the text. For example, the text “Cyprus was invaded by the Ottoman Empire in 1571” implies the hypothesis “The Ottomans attacked Cyprus”. Semantic inference applications such as QA and IE crucially rely on entailment rules (Ravichandran and Hovy, 2002; Shinyama and Sekine, 2006) or equivalently inference rules, that is, rules that describe a directional inference relation between two fragments of text. An important type of entailment rule specifies the entailment</context>
</contexts>
<marker>Dagan, Dolan, Magnini, Roth, 2009</marker>
<rawString>Ido Dagan, Bill Dolan, Bernardo Magnini, and Dan Roth. 2009. Recognizing textual entailment: Rational, evaluation and approaches. Natural Language Engineering, 15(4):1–17.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Quang Do</author>
<author>Dan Roth</author>
</authors>
<title>Constraints based taxonomic relation classification.</title>
<date>2010</date>
<booktitle>In Proceedings of Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="8538" citStr="Do and Roth (2010)" startWordPosition="1372" endWordPosition="1375">pplies an ILP solver on each component separately using a cutting-plane procedure (Riedel and Clarke, 2006). Although this method is exact and improves scalability, it does not guarantee an efficient solution. When the graph does not decompose into sufficiently small components, and the weights generate many violations of 118 transitivity, solving Max-Trans-Graph becomes intractable. To address this problem, we present in this paper a method for approximating the optimal set of edges within each component and show that it is much more efficient and scalable both theoretically and empirically. Do and Roth (2010) suggested a method for a related task of learning taxonomic relations between terms. Given a pair of terms, a small graph is constructed and constraints are imposed on the graph structure. Their work, however, is geared towards scenarios where relations are determined on-the-fly for a given pair of terms and no global knowledge base is explicitly constructed. Thus, their method easily produces solutions where global constraints, such as transitivity, are violated. Another approximation method that violates transitivity constraints is LP relaxation (Martins et al., 2009). In LP relaxation, the</context>
</contexts>
<marker>Do, Roth, 2010</marker>
<rawString>Quang Do and Dan Roth. 2010. Constraints based taxonomic relation classification. In Proceedings of Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anthony Fader</author>
<author>Stephen Soderland</author>
<author>Oren Etzioni</author>
</authors>
<title>Identifying relations for open information extraction.</title>
<date>2011</date>
<booktitle>In Proceedings of Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="3579" citStr="Fader et al. (2011)" startWordPosition="538" endWordPosition="541">nstraints improves rule learning comparing to methods that ignore graph structure. More recently, Berant et al. (Berant et al., 2011) introduced a more efficient exact algorithm, which decomposes the graph into connected components and then applies an ILP solver over each component. Despite this progress, finding the exact solution remains NP-hard – the authors themselves report they were unable to solve some graphs of rather moderate size and that the coverage of their method is limited. Thus, scaling their algorithm to data sets with tens of thousands of predicates (e.g., the extractions of Fader et al. (2011)) is unlikely. 117 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 117–125, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics In this paper we present a novel method for learning the edges of entailment graphs. Our method computes much more efficiently an approximate solution that is empirically almost as good as the exact solution. To that end, we first (Section 3) conjecture and empirically show that entailment graphs exhibit a “tree-like” property, i.e., that they can be reduced into a structure similar t</context>
</contexts>
<marker>Fader, Soderland, Etzioni, 2011</marker>
<rawString>Anthony Fader, Stephen Soderland, and Oren Etzioni. 2011. Identifying relations for open information extraction. In Proceedings of Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Finkel</author>
<author>C D Manning</author>
</authors>
<title>Enforcing transitivity in coreference resolution.</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="9858" citStr="Finkel and Manning, 2008" startWordPosition="1589" endWordPosition="1592">Linear Program (LP), which is polynomial. An LP solver is then applied on the problem, and variables xzj that are assigned a fractional value are rounded to their nearest integer and so many violations of transitivity easily occur. The solution when applying LP relaxation is not a transitive graph, but nevertheless we show for comparison in Section 5 that our method is much faster. Last, we note that transitive relations have been explored in adjacent fields such as Temporal Information Extraction (Ling and Weld, 2010), Ontology Induction (Poon and Domingos, 2010), and Coreference Resolution (Finkel and Manning, 2008). 3 Forest-reducible Graphs The entailment relation, described by entailment graphs, is typically from a “semantically-specific” predicate to a more “general” one. Thus, intuitively, the topology of an entailment graph is expected to be “tree-like”. In this section we first formalize this intuition and then empirically analyze its validity. This property of entailment graphs is an interesting topological observation on its own, but also enables the efficient approximation algorithm of Section 4. For a directed edge i —* j in a directed acyclic graphs (DAG), we term the node i a child of node j</context>
</contexts>
<marker>Finkel, Manning, 2008</marker>
<rawString>J. R. Finkel and C. D. Manning. 2008. Enforcing transitivity in coreference resolution. In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael R Garey</author>
<author>David S Johnson</author>
</authors>
<date>1979</date>
<booktitle>Computers and Intractability: A Guide to the Theory of</booktitle>
<contexts>
<context position="15050" citStr="Garey and Johnson, 1979" startWordPosition="2534" endWordPosition="2537">results in nearly identical performance. An ILP formulation for Max-Trans-Forest is simple – a transitive graph is an FRG if all nodes in its reduced graph have no more than one parent. It can be verified that this is equivalent to the following statement: for every triplet of nodes i, j, k, if i —* j and i —* k, then either j —* k or k —* j (or both). Therefore, the ILP is formulated by adding this linear constraint to ILP (1): di,j,kEV xij+xik+(1 − xjk)+(1 − xkj) :� 3 (2) We note that despite the restriction to FRGs, MaxTrans-Forest is an NP-hard problem by a reduction from the X3C problem (Garey and Johnson, 1979). We omit the reduction details for brevity. 4 Sequential Approximation Algorithms In this section we present Tree-Node-Fix, an efficient approximation algorithm for Max-Trans-Forest, as well as Graph-Node-Fix, an approximation for MaxTrans-Graph. 4.1 Tree-Node-Fix The scheme of Tree-Node-Fix (TNF) is the following. First, an initial FRG is constructed, using some initialization procedure. Then, at each iteration a single node v is re-attached (see below) to the FRG in a way that improves the objective function. This is repeated until the value of the objective function cannot be improved anym</context>
</contexts>
<marker>Garey, Johnson, 1979</marker>
<rawString>Michael R. Garey and David S. Johnson. 1979. Computers and Intractability: A Guide to the Theory of NPCompleteness. W. H. Freeman.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
<author>Patrick Pantel</author>
</authors>
<title>Discovery of inference rules for question answering.</title>
<date>2001</date>
<journal>Natural Language Engineering,</journal>
<volume>7</volume>
<issue>4</issue>
<contexts>
<context position="2350" citStr="Lin and Pantel, 2001" startWordPosition="342" endWordPosition="345"> hypothesis “The Ottomans attacked Cyprus”. Semantic inference applications such as QA and IE crucially rely on entailment rules (Ravichandran and Hovy, 2002; Shinyama and Sekine, 2006) or equivalently inference rules, that is, rules that describe a directional inference relation between two fragments of text. An important type of entailment rule specifies the entailment relation between natural language predicates, e.g., the entailment rule ‘X invade Y —* X attack Y’ can be helpful in inferring the aforementioned hypothesis. Consequently, substantial effort has been made to learn such rules (Lin and Pantel, 2001; Sekine, 2005; Szpektor and Dagan, 2008; Schoenmackers et al., 2010). Textual entailment is inherently a transitive relation , that is, the rules ‘x —* y’ and ‘y —* z’ imply the rule ‘x —* z’. Accordingly, Berant et al. (2010) formulated the problem of learning entailment rules as a graph optimization problem, where nodes are predicates and edges represent entailment rules that respect transitivity. Since finding the optimal set of edges respecting transitivity is NP-hard, they employed Integer Linear Programming (ILP) to find the exact solution. Indeed, they showed that applying global trans</context>
<context position="5677" citStr="Lin and Pantel, 2001" startWordPosition="863" endWordPosition="867">rger graphs than in the past. Finally, we note that learning entailment graphs bears strong similarities to related tasks such as Taxonomy Induction (Snow et al., 2006) and Ontology induction (Poon and Domingos, 2010), and thus our approach may improve scalability in these fields as well. 2 Background Until recently, work on learning entailment rules between predicates considered each rule independently of others and did not exploit global dependencies. Most methods utilized the distributional similarity hypothesis that states that semantically similar predicates occur with similar arguments (Lin and Pantel, 2001; Szpektor et al., 2004; Yates and Etzioni, 2009; Schoenmackers et al., 2010). Some methods extracted rules from lexicographic resources such as WordNet (Szpektor and Dagan, 2009) or FrameNet (Bob and Rambow, 2009; Ben Aharon et al., 2010), and others assumed that semantic relations between predicates can be deduced from their co-occurrence in a corpus via manually-constructed patterns (Chklovski and Pantel, 2004). Recently, Berant et al. (2010; 2011) formulated the problem as the problem of learning global entailment graphs. In entailment graphs, nodes are predicates (e.g., ‘X attack Y’) and </context>
</contexts>
<marker>Lin, Pantel, 2001</marker>
<rawString>Dekang Lin and Patrick Pantel. 2001. Discovery of inference rules for question answering. Natural Language Engineering, 7(4):343–360.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiao Ling</author>
<author>Dan S Weld</author>
</authors>
<title>Temporal information extraction.</title>
<date>2010</date>
<booktitle>In Proceedings of the 24th AAAI Conference on Artificial Intelligence.</booktitle>
<contexts>
<context position="9757" citStr="Ling and Weld, 2010" startWordPosition="1574" endWordPosition="1577">e constraint xzj E {0, 11 is replaced by 0 &lt; xzj &lt; 1, transforming the problem from an ILP to a Linear Program (LP), which is polynomial. An LP solver is then applied on the problem, and variables xzj that are assigned a fractional value are rounded to their nearest integer and so many violations of transitivity easily occur. The solution when applying LP relaxation is not a transitive graph, but nevertheless we show for comparison in Section 5 that our method is much faster. Last, we note that transitive relations have been explored in adjacent fields such as Temporal Information Extraction (Ling and Weld, 2010), Ontology Induction (Poon and Domingos, 2010), and Coreference Resolution (Finkel and Manning, 2008). 3 Forest-reducible Graphs The entailment relation, described by entailment graphs, is typically from a “semantically-specific” predicate to a more “general” one. Thus, intuitively, the topology of an entailment graph is expected to be “tree-like”. In this section we first formalize this intuition and then empirically analyze its validity. This property of entailment graphs is an interesting topological observation on its own, but also enables the efficient approximation algorithm of Section 4</context>
</contexts>
<marker>Ling, Weld, 2010</marker>
<rawString>Xiao Ling and Dan S. Weld. 2010. Temporal information extraction. In Proceedings of the 24th AAAI Conference on Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andre Martins</author>
<author>Noah Smith</author>
<author>Eric Xing</author>
</authors>
<title>Concise integer linear programming formulations for dependency parsing.</title>
<date>2009</date>
<booktitle>In Proceedings of the 47th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="9115" citStr="Martins et al., 2009" startWordPosition="1460" endWordPosition="1463">etically and empirically. Do and Roth (2010) suggested a method for a related task of learning taxonomic relations between terms. Given a pair of terms, a small graph is constructed and constraints are imposed on the graph structure. Their work, however, is geared towards scenarios where relations are determined on-the-fly for a given pair of terms and no global knowledge base is explicitly constructed. Thus, their method easily produces solutions where global constraints, such as transitivity, are violated. Another approximation method that violates transitivity constraints is LP relaxation (Martins et al., 2009). In LP relaxation, the constraint xzj E {0, 11 is replaced by 0 &lt; xzj &lt; 1, transforming the problem from an ILP to a Linear Program (LP), which is polynomial. An LP solver is then applied on the problem, and variables xzj that are assigned a fractional value are rounded to their nearest integer and so many violations of transitivity easily occur. The solution when applying LP relaxation is not a transitive graph, but nevertheless we show for comparison in Section 5 that our method is much faster. Last, we note that transitive relations have been explored in adjacent fields such as Temporal In</context>
</contexts>
<marker>Martins, Smith, Xing, 2009</marker>
<rawString>Andre Martins, Noah Smith, and Eric Xing. 2009. Concise integer linear programming formulations for dependency parsing. In Proceedings of the 47th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hoifung Poon</author>
<author>Pedro Domingos</author>
</authors>
<title>Unsupervised ontology induction from text.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="5274" citStr="Poon and Domingos, 2010" startWordPosition="805" endWordPosition="808">is not guaranteed, the area under the precision-recall curve drops by merely a point. To conclude, the contribution of this paper is twofold: First, we define a novel modeling assumption about the tree-like structure of entailment graphs and demonstrate its validity. Second, we exploit this assumption to develop a polynomial approximation algorithm for learning entailment graphs that can scale to much larger graphs than in the past. Finally, we note that learning entailment graphs bears strong similarities to related tasks such as Taxonomy Induction (Snow et al., 2006) and Ontology induction (Poon and Domingos, 2010), and thus our approach may improve scalability in these fields as well. 2 Background Until recently, work on learning entailment rules between predicates considered each rule independently of others and did not exploit global dependencies. Most methods utilized the distributional similarity hypothesis that states that semantically similar predicates occur with similar arguments (Lin and Pantel, 2001; Szpektor et al., 2004; Yates and Etzioni, 2009; Schoenmackers et al., 2010). Some methods extracted rules from lexicographic resources such as WordNet (Szpektor and Dagan, 2009) or FrameNet (Bob </context>
<context position="9803" citStr="Poon and Domingos, 2010" startWordPosition="1581" endWordPosition="1584"> &lt; xzj &lt; 1, transforming the problem from an ILP to a Linear Program (LP), which is polynomial. An LP solver is then applied on the problem, and variables xzj that are assigned a fractional value are rounded to their nearest integer and so many violations of transitivity easily occur. The solution when applying LP relaxation is not a transitive graph, but nevertheless we show for comparison in Section 5 that our method is much faster. Last, we note that transitive relations have been explored in adjacent fields such as Temporal Information Extraction (Ling and Weld, 2010), Ontology Induction (Poon and Domingos, 2010), and Coreference Resolution (Finkel and Manning, 2008). 3 Forest-reducible Graphs The entailment relation, described by entailment graphs, is typically from a “semantically-specific” predicate to a more “general” one. Thus, intuitively, the topology of an entailment graph is expected to be “tree-like”. In this section we first formalize this intuition and then empirically analyze its validity. This property of entailment graphs is an interesting topological observation on its own, but also enables the efficient approximation algorithm of Section 4. For a directed edge i —* j in a directed acy</context>
</contexts>
<marker>Poon, Domingos, 2010</marker>
<rawString>Hoifung Poon and Pedro Domingos. 2010. Unsupervised ontology induction from text. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Deepak Ravichandran</author>
<author>Eduard Hovy</author>
</authors>
<title>Learning surface text patterns for a question answering system.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="1887" citStr="Ravichandran and Hovy, 2002" startWordPosition="270" endWordPosition="273">ming textual inference is in the heart of many semantic inference applications such as Question Answering (QA) and Information Extraction (IE). A prominent generic paradigm for textual inference is Textual Entailment (TUE) (Dagan et al., 2009). In TUE, the goal is to recognize, given two text fragments termed text and hypothesis, whether the hypothesis can be inferred from the text. For example, the text “Cyprus was invaded by the Ottoman Empire in 1571” implies the hypothesis “The Ottomans attacked Cyprus”. Semantic inference applications such as QA and IE crucially rely on entailment rules (Ravichandran and Hovy, 2002; Shinyama and Sekine, 2006) or equivalently inference rules, that is, rules that describe a directional inference relation between two fragments of text. An important type of entailment rule specifies the entailment relation between natural language predicates, e.g., the entailment rule ‘X invade Y —* X attack Y’ can be helpful in inferring the aforementioned hypothesis. Consequently, substantial effort has been made to learn such rules (Lin and Pantel, 2001; Sekine, 2005; Szpektor and Dagan, 2008; Schoenmackers et al., 2010). Textual entailment is inherently a transitive relation , that is, </context>
</contexts>
<marker>Ravichandran, Hovy, 2002</marker>
<rawString>Deepak Ravichandran and Eduard Hovy. 2002. Learning surface text patterns for a question answering system. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Riedel</author>
<author>James Clarke</author>
</authors>
<title>Incremental integer linear programming for non-projective dependency parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="8027" citStr="Riedel and Clarke, 2006" startWordPosition="1292" endWordPosition="1295"> G and the constraint xij + xjk − xik ≤ 1 on the binary variables enforces that whenever xij = xjk =1, then also xik = 1 (transitivity). Since ILP is NP-hard, applying an ILP solver directly does not scale well because the number of variables is O(|V |2) and the number of constraints is O(|V |3). Thus, even a graph with ∼80 nodes (predicates) has more than half a million constraints. Consequently, in (Berant et al., 2011), they proposed a method that efficiently decomposes the graph into smaller components and applies an ILP solver on each component separately using a cutting-plane procedure (Riedel and Clarke, 2006). Although this method is exact and improves scalability, it does not guarantee an efficient solution. When the graph does not decompose into sufficiently small components, and the weights generate many violations of 118 transitivity, solving Max-Trans-Graph becomes intractable. To address this problem, we present in this paper a method for approximating the optimal set of edges within each component and show that it is much more efficient and scalable both theoretically and empirically. Do and Roth (2010) suggested a method for a related task of learning taxonomic relations between terms. Giv</context>
</contexts>
<marker>Riedel, Clarke, 2006</marker>
<rawString>Sebastian Riedel and James Clarke. 2006. Incremental integer linear programming for non-projective dependency parsing. In Proceedings of Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Schoenmackers</author>
<author>Jesse Davis</author>
<author>Oren Etzioni</author>
<author>Daniel S Weld</author>
</authors>
<title>Learning first-order horn clauses from web text.</title>
<date>2010</date>
<booktitle>In Proceedings of Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="2419" citStr="Schoenmackers et al., 2010" startWordPosition="353" endWordPosition="356"> applications such as QA and IE crucially rely on entailment rules (Ravichandran and Hovy, 2002; Shinyama and Sekine, 2006) or equivalently inference rules, that is, rules that describe a directional inference relation between two fragments of text. An important type of entailment rule specifies the entailment relation between natural language predicates, e.g., the entailment rule ‘X invade Y —* X attack Y’ can be helpful in inferring the aforementioned hypothesis. Consequently, substantial effort has been made to learn such rules (Lin and Pantel, 2001; Sekine, 2005; Szpektor and Dagan, 2008; Schoenmackers et al., 2010). Textual entailment is inherently a transitive relation , that is, the rules ‘x —* y’ and ‘y —* z’ imply the rule ‘x —* z’. Accordingly, Berant et al. (2010) formulated the problem of learning entailment rules as a graph optimization problem, where nodes are predicates and edges represent entailment rules that respect transitivity. Since finding the optimal set of edges respecting transitivity is NP-hard, they employed Integer Linear Programming (ILP) to find the exact solution. Indeed, they showed that applying global transitivity constraints improves rule learning comparing to methods that </context>
<context position="5754" citStr="Schoenmackers et al., 2010" startWordPosition="876" endWordPosition="879">t graphs bears strong similarities to related tasks such as Taxonomy Induction (Snow et al., 2006) and Ontology induction (Poon and Domingos, 2010), and thus our approach may improve scalability in these fields as well. 2 Background Until recently, work on learning entailment rules between predicates considered each rule independently of others and did not exploit global dependencies. Most methods utilized the distributional similarity hypothesis that states that semantically similar predicates occur with similar arguments (Lin and Pantel, 2001; Szpektor et al., 2004; Yates and Etzioni, 2009; Schoenmackers et al., 2010). Some methods extracted rules from lexicographic resources such as WordNet (Szpektor and Dagan, 2009) or FrameNet (Bob and Rambow, 2009; Ben Aharon et al., 2010), and others assumed that semantic relations between predicates can be deduced from their co-occurrence in a corpus via manually-constructed patterns (Chklovski and Pantel, 2004). Recently, Berant et al. (2010; 2011) formulated the problem as the problem of learning global entailment graphs. In entailment graphs, nodes are predicates (e.g., ‘X attack Y’) and edges represent entailment rules between them (‘X invade Y → X attack Y’). Fo</context>
</contexts>
<marker>Schoenmackers, Davis, Etzioni, Weld, 2010</marker>
<rawString>Stefan Schoenmackers, Jesse Davis, Oren Etzioni, and Daniel S. Weld. 2010. Learning first-order horn clauses from web text. In Proceedings of Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Satoshi Sekine</author>
</authors>
<title>Automatic paraphrase discovery based on context and keywords between ne pairs.</title>
<date>2005</date>
<booktitle>In Proceedings of IWP.</booktitle>
<contexts>
<context position="2364" citStr="Sekine, 2005" startWordPosition="346" endWordPosition="347">ans attacked Cyprus”. Semantic inference applications such as QA and IE crucially rely on entailment rules (Ravichandran and Hovy, 2002; Shinyama and Sekine, 2006) or equivalently inference rules, that is, rules that describe a directional inference relation between two fragments of text. An important type of entailment rule specifies the entailment relation between natural language predicates, e.g., the entailment rule ‘X invade Y —* X attack Y’ can be helpful in inferring the aforementioned hypothesis. Consequently, substantial effort has been made to learn such rules (Lin and Pantel, 2001; Sekine, 2005; Szpektor and Dagan, 2008; Schoenmackers et al., 2010). Textual entailment is inherently a transitive relation , that is, the rules ‘x —* y’ and ‘y —* z’ imply the rule ‘x —* z’. Accordingly, Berant et al. (2010) formulated the problem of learning entailment rules as a graph optimization problem, where nodes are predicates and edges represent entailment rules that respect transitivity. Since finding the optimal set of edges respecting transitivity is NP-hard, they employed Integer Linear Programming (ILP) to find the exact solution. Indeed, they showed that applying global transitivity constr</context>
</contexts>
<marker>Sekine, 2005</marker>
<rawString>Satoshi Sekine. 2005. Automatic paraphrase discovery based on context and keywords between ne pairs. In Proceedings of IWP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yusuke Shinyama</author>
<author>Satoshi Sekine</author>
</authors>
<title>Preemptive information extraction using unrestricted relation discovery.</title>
<date>2006</date>
<booktitle>In Proceedings of the Human Language Technology Conference of the NAACL, Main Conference.</booktitle>
<contexts>
<context position="1915" citStr="Shinyama and Sekine, 2006" startWordPosition="274" endWordPosition="277">the heart of many semantic inference applications such as Question Answering (QA) and Information Extraction (IE). A prominent generic paradigm for textual inference is Textual Entailment (TUE) (Dagan et al., 2009). In TUE, the goal is to recognize, given two text fragments termed text and hypothesis, whether the hypothesis can be inferred from the text. For example, the text “Cyprus was invaded by the Ottoman Empire in 1571” implies the hypothesis “The Ottomans attacked Cyprus”. Semantic inference applications such as QA and IE crucially rely on entailment rules (Ravichandran and Hovy, 2002; Shinyama and Sekine, 2006) or equivalently inference rules, that is, rules that describe a directional inference relation between two fragments of text. An important type of entailment rule specifies the entailment relation between natural language predicates, e.g., the entailment rule ‘X invade Y —* X attack Y’ can be helpful in inferring the aforementioned hypothesis. Consequently, substantial effort has been made to learn such rules (Lin and Pantel, 2001; Sekine, 2005; Szpektor and Dagan, 2008; Schoenmackers et al., 2010). Textual entailment is inherently a transitive relation , that is, the rules ‘x —* y’ and ‘y —*</context>
</contexts>
<marker>Shinyama, Sekine, 2006</marker>
<rawString>Yusuke Shinyama and Satoshi Sekine. 2006. Preemptive information extraction using unrestricted relation discovery. In Proceedings of the Human Language Technology Conference of the NAACL, Main Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rion Snow</author>
<author>Dan Jurafsky</author>
<author>Andrew Y Ng</author>
</authors>
<title>Semantic taxonomy induction from heterogenous evidence.</title>
<date>2006</date>
<booktitle>In Proceedings of the 44th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="5225" citStr="Snow et al., 2006" startWordPosition="798" endWordPosition="801">rithm, and that though an optimal solution is not guaranteed, the area under the precision-recall curve drops by merely a point. To conclude, the contribution of this paper is twofold: First, we define a novel modeling assumption about the tree-like structure of entailment graphs and demonstrate its validity. Second, we exploit this assumption to develop a polynomial approximation algorithm for learning entailment graphs that can scale to much larger graphs than in the past. Finally, we note that learning entailment graphs bears strong similarities to related tasks such as Taxonomy Induction (Snow et al., 2006) and Ontology induction (Poon and Domingos, 2010), and thus our approach may improve scalability in these fields as well. 2 Background Until recently, work on learning entailment rules between predicates considered each rule independently of others and did not exploit global dependencies. Most methods utilized the distributional similarity hypothesis that states that semantically similar predicates occur with similar arguments (Lin and Pantel, 2001; Szpektor et al., 2004; Yates and Etzioni, 2009; Schoenmackers et al., 2010). Some methods extracted rules from lexicographic resources such as Wor</context>
</contexts>
<marker>Snow, Jurafsky, Ng, 2006</marker>
<rawString>Rion Snow, Dan Jurafsky, and Andrew Y. Ng. 2006. Semantic taxonomy induction from heterogenous evidence. In Proceedings of the 44th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Idan Szpektor</author>
<author>Ido Dagan</author>
</authors>
<title>Learning entailment rules for unary templates.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics.</booktitle>
<contexts>
<context position="2390" citStr="Szpektor and Dagan, 2008" startWordPosition="348" endWordPosition="352">yprus”. Semantic inference applications such as QA and IE crucially rely on entailment rules (Ravichandran and Hovy, 2002; Shinyama and Sekine, 2006) or equivalently inference rules, that is, rules that describe a directional inference relation between two fragments of text. An important type of entailment rule specifies the entailment relation between natural language predicates, e.g., the entailment rule ‘X invade Y —* X attack Y’ can be helpful in inferring the aforementioned hypothesis. Consequently, substantial effort has been made to learn such rules (Lin and Pantel, 2001; Sekine, 2005; Szpektor and Dagan, 2008; Schoenmackers et al., 2010). Textual entailment is inherently a transitive relation , that is, the rules ‘x —* y’ and ‘y —* z’ imply the rule ‘x —* z’. Accordingly, Berant et al. (2010) formulated the problem of learning entailment rules as a graph optimization problem, where nodes are predicates and edges represent entailment rules that respect transitivity. Since finding the optimal set of edges respecting transitivity is NP-hard, they employed Integer Linear Programming (ILP) to find the exact solution. Indeed, they showed that applying global transitivity constraints improves rule learni</context>
</contexts>
<marker>Szpektor, Dagan, 2008</marker>
<rawString>Idan Szpektor and Ido Dagan. 2008. Learning entailment rules for unary templates. In Proceedings of the 22nd International Conference on Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Idan Szpektor</author>
<author>Ido Dagan</author>
</authors>
<title>Augmenting wordnet-based inference with argument mapping.</title>
<date>2009</date>
<booktitle>In Proceedings of TextInfer.</booktitle>
<contexts>
<context position="5856" citStr="Szpektor and Dagan, 2009" startWordPosition="891" endWordPosition="894">ntology induction (Poon and Domingos, 2010), and thus our approach may improve scalability in these fields as well. 2 Background Until recently, work on learning entailment rules between predicates considered each rule independently of others and did not exploit global dependencies. Most methods utilized the distributional similarity hypothesis that states that semantically similar predicates occur with similar arguments (Lin and Pantel, 2001; Szpektor et al., 2004; Yates and Etzioni, 2009; Schoenmackers et al., 2010). Some methods extracted rules from lexicographic resources such as WordNet (Szpektor and Dagan, 2009) or FrameNet (Bob and Rambow, 2009; Ben Aharon et al., 2010), and others assumed that semantic relations between predicates can be deduced from their co-occurrence in a corpus via manually-constructed patterns (Chklovski and Pantel, 2004). Recently, Berant et al. (2010; 2011) formulated the problem as the problem of learning global entailment graphs. In entailment graphs, nodes are predicates (e.g., ‘X attack Y’) and edges represent entailment rules between them (‘X invade Y → X attack Y’). For every pair of predicates i, j, an entailment score wij was learned by training a classifier over dis</context>
</contexts>
<marker>Szpektor, Dagan, 2009</marker>
<rawString>Idan Szpektor and Ido Dagan. 2009. Augmenting wordnet-based inference with argument mapping. In Proceedings of TextInfer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Idan Szpektor</author>
<author>Hristo Tanev</author>
<author>Ido Dagan</author>
<author>Bonaventura Coppola</author>
</authors>
<title>Scaling web-based acquisition of entailment relations.</title>
<date>2004</date>
<booktitle>In Proceedings of Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="5700" citStr="Szpektor et al., 2004" startWordPosition="868" endWordPosition="871">e past. Finally, we note that learning entailment graphs bears strong similarities to related tasks such as Taxonomy Induction (Snow et al., 2006) and Ontology induction (Poon and Domingos, 2010), and thus our approach may improve scalability in these fields as well. 2 Background Until recently, work on learning entailment rules between predicates considered each rule independently of others and did not exploit global dependencies. Most methods utilized the distributional similarity hypothesis that states that semantically similar predicates occur with similar arguments (Lin and Pantel, 2001; Szpektor et al., 2004; Yates and Etzioni, 2009; Schoenmackers et al., 2010). Some methods extracted rules from lexicographic resources such as WordNet (Szpektor and Dagan, 2009) or FrameNet (Bob and Rambow, 2009; Ben Aharon et al., 2010), and others assumed that semantic relations between predicates can be deduced from their co-occurrence in a corpus via manually-constructed patterns (Chklovski and Pantel, 2004). Recently, Berant et al. (2010; 2011) formulated the problem as the problem of learning global entailment graphs. In entailment graphs, nodes are predicates (e.g., ‘X attack Y’) and edges represent entailm</context>
</contexts>
<marker>Szpektor, Tanev, Dagan, Coppola, 2004</marker>
<rawString>Idan Szpektor, Hristo Tanev, Ido Dagan, and Bonaventura Coppola. 2004. Scaling web-based acquisition of entailment relations. In Proceedings of Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Yates</author>
<author>Oren Etzioni</author>
</authors>
<title>Unsupervised methods for determining object and relation synonyms on the web.</title>
<date>2009</date>
<journal>Journal ofArtificial Intelligence Research,</journal>
<pages>34--255</pages>
<contexts>
<context position="5725" citStr="Yates and Etzioni, 2009" startWordPosition="872" endWordPosition="875">e that learning entailment graphs bears strong similarities to related tasks such as Taxonomy Induction (Snow et al., 2006) and Ontology induction (Poon and Domingos, 2010), and thus our approach may improve scalability in these fields as well. 2 Background Until recently, work on learning entailment rules between predicates considered each rule independently of others and did not exploit global dependencies. Most methods utilized the distributional similarity hypothesis that states that semantically similar predicates occur with similar arguments (Lin and Pantel, 2001; Szpektor et al., 2004; Yates and Etzioni, 2009; Schoenmackers et al., 2010). Some methods extracted rules from lexicographic resources such as WordNet (Szpektor and Dagan, 2009) or FrameNet (Bob and Rambow, 2009; Ben Aharon et al., 2010), and others assumed that semantic relations between predicates can be deduced from their co-occurrence in a corpus via manually-constructed patterns (Chklovski and Pantel, 2004). Recently, Berant et al. (2010; 2011) formulated the problem as the problem of learning global entailment graphs. In entailment graphs, nodes are predicates (e.g., ‘X attack Y’) and edges represent entailment rules between them (‘</context>
</contexts>
<marker>Yates, Etzioni, 2009</marker>
<rawString>Alexander Yates and Oren Etzioni. 2009. Unsupervised methods for determining object and relation synonyms on the web. Journal ofArtificial Intelligence Research, 34:255–296.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>