<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000017">
<title confidence="0.991574">
Latent Variable Models for Semantic Orientations of Phrases
</title>
<author confidence="0.602571">
Hiroya Takamura Takashi Inui
Precision and Intelligence Laboratory Japan Society of the Promotion of Science
</author>
<affiliation confidence="0.808533">
Tokyo Institute of Technology tinui@lr.pi.titech.ac.jp
</affiliation>
<email confidence="0.984833">
takamura@pi.titech.ac.jp
</email>
<author confidence="0.866789">
Manabu Okumura
</author>
<affiliation confidence="0.8146865">
Precision and Intelligence Laboratory
Tokyo Institute of Technology
</affiliation>
<email confidence="0.99863">
oku@pi.titech.ac.jp
</email>
<sectionHeader confidence="0.998599" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999820733333333">
We propose models for semantic orienta-
tions of phrases as well as classification
methods based on the models. Although
each phrase consists of multiple words, the
semantic orientation of the phrase is not a
mere sum of the orientations of the com-
ponent words. Some words can invert the
orientation. In order to capture the prop-
erty of such phrases, we introduce latent
variables into the models. Through exper-
iments, we show that the proposed latent
variable models work well in the classifi-
cation of semantic orientations of phrases
and achieved nearly 82% classification ac-
curacy.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99993450877193">
Technology for affect analysis of texts has recently
gained attention in both academic and industrial
areas. It can be applied to, for example, a survey
of new products or a questionnaire analysis. Au-
tomatic sentiment analysis enables a fast and com-
prehensive investigation.
The most fundamental step for sentiment anal-
ysis is to acquire the semantic orientations of
words: desirable or undesirable (positive or neg-
ative). For example, the word “beautiful” is pos-
itive, while the word “dirty” is negative. Many
researchers have developed several methods for
this purpose and obtained good results (Hatzi-
vassiloglou and McKeown, 1997; Turney and
Littman, 2003; Kamps et al., 2004; Takamura
et al., 2005; Kobayashi et al., 2001). One of
the next problems to be solved is to acquire se-
mantic orientations of phrases, or multi-term ex-
pressions. No computational model for semanti-
cally oriented phrases has been proposed so far al-
though some researchers have used techniques de-
veloped for single words. The purpose of this pa-
per is to propose computational models for phrases
with semantic orientations as well as classification
methods based on the models. Indeed the seman-
tic orientations of phrases depend on context just
as the semantic orientations of words do, but we
would like to obtain the most basic orientations of
phrases. We believe that we can use the obtained
basic orientations of phrases for affect analysis of
higher linguistic units such as sentences and doc-
uments.
The semantic orientation of a phrase is not a
mere sum of its component words. Semantic
orientations can emerge out of combinations of
non-oriented words. For example, “light laptop-
computer” is positively oriented although neither
“light” nor “laptop-computer” has a positive ori-
entation. Besides, some words can invert the ori-
entation of a neighboring word, such as “low”
in “low risk”, where the negative orientation of
“risk” is inverted to a “positive” by the adjective
“low”. This kind of non-compositional operation
has to be incorporated into the model. We focus
on “noun+adjective” in this paper, since this type
of phrase contains most of interesting properties
of phrases, such as emergence or inversion of se-
mantic orientations.
In order to capture the properties of semantic
orientations of phrases, we introduce latent vari-
ables into the models, where one random variable
corresponds to nouns and another random vari-
able corresponds to adjectives. The words that
are similar in terms of semantic orientations, such
as “risk” and “mortality” (i.e., the positive ori-
entation emerges when they are “low”), make a
cluster in these models. Our method is language-
</bodyText>
<page confidence="0.995796">
201
</page>
<bodyText confidence="0.7320225">
independent in the sense that it uses only cooccur-
rence data of words and semantic orientations.
</bodyText>
<sectionHeader confidence="0.998743" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999754666666667">
We briefly explain related work from two view-
points: the classification of word pairs and the
identification of semantic orientation.
</bodyText>
<subsectionHeader confidence="0.996938">
2.1 Classification of Word Pairs
</subsectionHeader>
<bodyText confidence="0.99975132">
Torisawa (2001) used a probabilistic model to
identify the appropriate case for a pair of words
constituting a noun and a verb with the case of
the noun-verb pair unknown. Their model is the
same as Probabilistic Latent Semantic Indexing
(PLSI) (Hofmann, 2001), which is a generative
probability model of two random variables. Tori-
sawa’s method is similar to ours in that a latent
variable model is used for word pairs. How-
ever, Torisawa’s objective is different from ours.
In addition, we used not the original PLSI, but
its expanded version, which is more suitable for
this task of semantic orientation classification of
phrases.
Fujita et al. (2004) addressed the task of the de-
tection of incorrect case assignment in automat-
ically paraphrased sentences. They reduced the
task to a problem of classifying pairs of a verb
and a noun with a case into correct or incorrect.
They first obtained a latent semantic space with
PLSI and adopted the nearest-neighbors method,
in which they used latent variables as features. Fu-
jita et al.’s method is different from ours, and also
from Torisawa’s, in that a probabilistic model is
used for feature extraction.
</bodyText>
<subsectionHeader confidence="0.999899">
2.2 Identification of Semantic Orientations
</subsectionHeader>
<bodyText confidence="0.999808648148148">
The semantic orientation classification of words
has been pursued by several researchers (Hatzi-
vassiloglou and McKeown, 1997; Turney and
Littman, 2003; Kamps et al., 2004; Takamura et
al., 2005). However, no computational model for
semantically oriented phrases has been proposed
to date although research for a similar purpose has
been proposed.
Some researchers used sequences of words as
features in document classification according to
semantic orientation. Pang et al. (2002) used bi-
grams. Matsumoto et al. (2005) used sequential
patterns and tree patterns. Although such patterns
were proved to be effective in document classi-
fication, the semantic orientations of the patterns
themselves are not considered.
Suzuki et al. (2006) used the Expectation-
Maximization algorithm and the naive bayes clas-
sifier to incorporate the unlabeled data in the clas-
sification of 3-term evaluative expressions. They
focused on the utilization of context information
such as neighboring words and emoticons. Tur-
ney (2002) applied an internet-based technique to
the semantic orientation classification of phrases,
which had originally been developed for word sen-
timent classification. In their method, the num-
ber of hits returned by a search-engine, with a
query consisting of a phrase and a seed word (e.g.,
“phrase NEAR good”) is used to determine the
orientation. Baron and Hirst (2004) extracted col-
locations with Xtract (Smadja, 1993) and classi-
fied the collocations using the orientations of the
words in the neighboring sentences. Their method
is similar to Turney’s in the sense that cooccur-
rence with seed words is used. The three methods
above are based on context information. In con-
trast, our method exploits the internal structure of
the semantic orientations of phrases.
Inui (2004) introduced an attribute plus/minus
for each word and proposed several rules that
determine the semantic orientations of phrases
on the basis of the plus/minus attribute val-
ues and the positive/negative attribute values of
the component words. For example, a rule
[negative+minus=positive] determines “low (mi-
nus) risk (negative)” to be positive. Wilson et
al. (2005) worked on phrase-level semantic orien-
tations. They introduced a polarity shifter, which
is almost equivalent to the plus/minus attribute
above. They manually created the list of polarity
shifters. The method that we propose in this paper
is an automatic version of Inui’s or Wilson et al.’s
idea, in the sense that the method automatically
creates word clusters and their polarity shifters.
</bodyText>
<sectionHeader confidence="0.899585" genericHeader="method">
3 Latent Variable Models for Semantic
</sectionHeader>
<subsectionHeader confidence="0.663024">
Orientations of Phrases
</subsectionHeader>
<bodyText confidence="0.999969222222222">
As mentioned in the Introduction, the semantic
orientation of a phrase is not a mere sum of its
component words. If we know that “low risk” is
positive, and that “risk” and “mortality”, in some
sense, belong to the same semantic cluster, we can
infer that “low mortality” is also positive. There-
fore, we propose to use latent variable models to
extract such latent semantic clusters and to real-
ize an accurate classification of phrases (we focus
</bodyText>
<page confidence="0.977971">
202
</page>
<equation confidence="0.6987812">
N Z
N
N Z
N Z
N Z
</equation>
<figure confidence="0.993168666666667">
A
A C
A C
A C
A C
(a) (b) (c) (d) (e)
</figure>
<figureCaption confidence="0.996938">
Figure 1: Graphical representations:(a) PLSI, (b) naive bayes, (c) 3-PLSI, (d) triangle, (e) U-shaped;
</figureCaption>
<bodyText confidence="0.992331">
Each node indicates a random variable. Arrows indicate statistical dependency between variables. N, A,
Z and C respectively correspond to nouns, adjectives, latent clusters and semantic orientations.
on two-term phrases in this paper). The models
adopted in this paper are also used for collabora-
tive filtering by Hofmann (2004).
With these models, the nouns (e.g., “risk” and
“mortality”) that become positive by reducing
their degree or amount would make a cluster. On
the other hand, the adjectives or verbs (e.g., “re-
duce” and “decrease”) that are related to reduction
would also make a cluster.
Figure 1 shows graphical representations of sta-
tistical dependencies of models with a latent vari-
able. N, A, Z and C respectively correspond to
nouns, adjectives, latent clusters and semantic ori-
entations. Figure 1-(a) is the PLSI model, which
cannot be used in this task due to the absence of
a variable for semantic orientations. Figure 1-(b)
is the naive bayes model, in which nouns and ad-
jectives are statistically independent of each other
given the semantic orientation. Figure 1-(c) is,
what we call, the 3-PLSI model, which is the 3-
observable variable version of the PLSI. We call
Figure 1-(d) the triangle model, since three of its
four variables make a triangle. We call Figure 1-
(e) the U-shaped model. In the triangle model and
the U-shaped model, adjectives directly influence
semantic orientations (rating categories) through
the probability P(cJaz). While nouns and adjec-
tives are associated with the same set of clusters Z
in the 3-PLSI and the triangle models, only nouns
are clustered in the U-shaped model.
In the following, we construct a probability
model for the semantic orientations of phrases us-
ing each model of (b) to (e) in Figure 1. We ex-
plain in detail the triangle model and the U-shaped
model, which we will propose to use for this task.
</bodyText>
<subsectionHeader confidence="0.97208">
3.1 Triangle Model
</subsectionHeader>
<bodyText confidence="0.9995655">
Suppose that a set D of tuples of noun n, adjective
a (predicate, generally) and the rating c is given:
</bodyText>
<equation confidence="0.991597">
D = {(n1, a1, c1),···, (n|D|, a|D|, c|D|)}, (1)
</equation>
<bodyText confidence="0.999861333333333">
where c E {−1, 0, 11, for example. This can be
easily expanded to the case of c E 11, · · · , 51. Our
purpose is to predict the rating c for unknown pairs
of n and a.
According to Figure 1-(d), the generative prob-
ability of n, a, c, z is the following :
</bodyText>
<equation confidence="0.985131333333333">
P(nacz) = P(z|n)P(a|z)P(c|az)P(n). (2)
Remember that for the original PLSI model,
P(naz) = P(zJn)P(aJz)P(n).
</equation>
<bodyText confidence="0.999994444444444">
We use the Expectation-Maximization (EM) al-
gorithm (Dempster et al., 1977) to estimate the pa-
rameters of the model. According to the theory of
the EM algorithm, we can increase the likelihood
of the model with latent variables by iteratively in-
creasing the Q-function. The Q-function (i.e., the
expected log-likelihood of the joint probability of
complete data with respect to the conditional pos-
terior of the latent variable) is expressed as :
</bodyText>
<equation confidence="0.998091">
Q(θ) = X Xfnac P¯(z|nac) log P(nazc|θ), (3)
</equation>
<bodyText confidence="0.940056285714286">
nac z
where θ denotes the set of the new parameters.
fnac denotes the frequency of a tuple n, a, c in the
data. P¯ represents the posterior computed using
the current parameters.
The E-step (expectation step) corresponds to
simple posterior computation:
</bodyText>
<equation confidence="0.9925175">
P¯(z|nac) = P(z|n)P(a|z)P(c|az) (4)
Pz P(z |n)P(a |z)P(c |az)
</equation>
<bodyText confidence="0.997692833333333">
For derivation of update rules in the M-step (max-
imization step), we use a simple Lagrange method
for this optimization problem with constraints :
bz, Pn P(nJz) = 1, bz, Pa P(aJz) = 1, and
ba, z, Pc P(cJaz) = 1. We obtain the following
update rules :
</bodyText>
<equation confidence="0.911079">
Pac fnac P¯ (z|nac)
P(z|n) = P , (5)
ac fnac
203
Pnc fnac P¯ (z|nac)
P(y|z) = (6)
Pnac fnac P¯(z|nac),
na)
|
=Pz P(z|n)P(a|z)P(c|az) (8)
Pcz P(z|n)P(a|z)P(c|az)
</equation>
<bodyText confidence="0.999557">
Then the rating category c that maximize P(c|na)
is selected.
</bodyText>
<subsectionHeader confidence="0.915179">
3.2 U-shaped Model
</subsectionHeader>
<bodyText confidence="0.9999935">
We suppose that the conditional probability of c
and z given n and a is expressed as :
</bodyText>
<equation confidence="0.999773">
P(cz|na) = P(c|az)P(z|n). (9)
</equation>
<bodyText confidence="0.999878">
We compute parameters above using the EM al-
gorithm with the Q-function :
</bodyText>
<equation confidence="0.998982">
Q(θ) = X Xfnac P¯(z|nac) log P(cz|na, θ).(10)
</equation>
<bodyText confidence="0.854411666666667">
nac z
We obtain the following update rules :
E step
</bodyText>
<equation confidence="0.963860909090909">
P(c|az)P(z|n)
P¯(z|nac) = Pz P(c|az)P(z|n), (11)
M step
P n fnac P¯ (z|nac)
P(c|az) = (12)
Pnc fnac P¯(z|nac),
Pac fnac P¯ (z|nac)
P(z|n) = P . (13)
ac fnac
For classification, we use the formula:
P (c|na) = X P(c|az)P(z|n). (14)
</equation>
<sectionHeader confidence="0.408687" genericHeader="method">
z
</sectionHeader>
<subsectionHeader confidence="0.983003">
3.3 Other Models for Comparison
</subsectionHeader>
<bodyText confidence="0.996355">
We will also test the 3-PLSI model corresponding
to Figure 1-(c).
In addition to the latent models, we test a base-
line classifier, which uses the posterior probabil-
ity :
</bodyText>
<equation confidence="0.986197">
P(c|na) ∝ P(n|c)P(a|c)P(c). (15)
</equation>
<bodyText confidence="0.9998805">
This baseline model is equivalent to the 2-term
naive bayes classifier (Mitchell, 1997). The graph-
ical representation of the naive bayes model is (b)
in Figure 1. The parameters are estimated as :
</bodyText>
<equation confidence="0.9997966">
1 + fnc
P(n|c) = (16)
|N |+ fc
1 + fac
P(a|c) = |A |+ fc , (17)
</equation>
<bodyText confidence="0.9999355">
where |N |and |A |are the numbers of the words
for n and a, respectively.
Thus, we have four different models : naive
bayes (baseline), 3-PLSI, triangle, and U-shaped.
</bodyText>
<subsectionHeader confidence="0.905466">
3.4 Discussions on the EM computation, the
Models and the Task
</subsectionHeader>
<bodyText confidence="0.999518">
In the actual EM computation, we use the tem-
pered EM (Hofmann, 2001) instead of the stan-
dard EM explained above, because the tempered
EM can avoid an inaccurate estimation of the
model caused by “over-confidence” in computing
the posterior probabilities. The tempered EM can
be realized by a slight modification to the E-step,
which results in a new E-step :
</bodyText>
<equation confidence="0.971347333333333">
¡P(c|az)P(z|n)¢β
P¯ (z|nac) = (18)
Pz ¡P(c|az)P(z|n)¢β
</equation>
<bodyText confidence="0.999795193548387">
for the U-shaped model, where β is a positive
hyper-parameter, called the inverse temperature.
The new E-steps for the other models are similarly
expressed.
Now we have two hyper-parameters : inverse
temperature β, and the number of possible val-
ues M of latent variables. We determine the
values of these hyper-parameters by splitting the
given training dataset into two datasets (the tempo-
rary training dataset 90% and the held-out dataset
10%), and by obtaining the classification accuracy
for the held-out dataset, which is yielded by the
classifier with the temporary training dataset.
We should also note that Z (or any variable)
should not have incoming arrows simultaneously
from N and A, because the model with such ar-
rows has P(z|na), which usually requires an ex-
cessively large memory.
To work with numerical scales of the rating
variable (i.e., the difference between c = −1 and
c = 1 should be larger than that of c = −1
and c = 0), Hofmann (2004) used also a Gaus-
sian distribution for P(c|az) in collaborative filter-
ing. However, we do not employ a Gaussian, be-
cause in our dataset, the number of rating classes is
These steps are iteratively computed until conver-
gence. If the difference of the values of Q-function
before and after an iteration becomes smaller than
a threshold, we regard it as converged.
For classification of an unknown pair n, a, we
compare the values of
</bodyText>
<equation confidence="0.907763875">
P(c
204
P(c |az) = fn ac
(7)
P¯ (z|nac).
Pn
P¯(z  |nac)
Pnc fnac
</equation>
<bodyText confidence="0.999985973684211">
only 3, which is so small that a Gaussian distribu-
tion cannot be a good approximation of the actual
probability density function. We conducted pre-
liminary experiments with the model with Gaus-
sians, but failed to obtain good results. For other
datasets with more classes, Gaussians might be a
good model for P(c|az).
The task we address in this paper is somewhat
similar to the trigram prediction task, in the sense
that both are classification tasks given two words.
However, we should note the difference between
these two tasks. In our task, the actual answer
given two specific words are fixed as illustrated
by the fact ‘high+salary’ is always positive, while
the answer for the trigram prediction task is ran-
domly distributed. We are therefore interested in
the semantic orientations of unseen pairs of words,
while the main purpose of the trigram prediction
is accurately estimate the probability of (possibly
seen) word sequences.
In the proposed models, only the words that ap-
peared in the training dataset can be classified. An
attempt to deal with the unseen words is an in-
teresting task. For example, we could extend our
models to semi-supervised models by regarding C
as a partially observable variable. We could also
use distributional similarity of words (e.g., based
on window-size cooccurrence) to find an observed
word that is most similar to the given unseen word.
However, such methods would not work for the
semantic orientation classification, because those
methods are designed for simple cooccurrence and
cannot distinguish “survival-rate” from “infection-
rate”. In fact, the similarity-based method men-
tioned above failed to work efficiently in our pre-
liminary experiments. To solve the problem of un-
seen words, we would have to use other linguistic
resources such as a thesaurus or a dictionary.
</bodyText>
<sectionHeader confidence="0.999917" genericHeader="method">
4 Experiments
</sectionHeader>
<subsectionHeader confidence="0.997189">
4.1 Experimental Settings
</subsectionHeader>
<bodyText confidence="0.999976591836734">
We extracted pairs of a noun (subject) and an ad-
jective (predicate), from Mainichi newspaper ar-
ticles (1995) written in Japanese, and annotated
the pairs with semantic orientation tags : positive,
neutral or negative. We thus obtained the labeled
dataset consisting of 12066 pair instances (7416
different pairs). The dataset contains 4459 neg-
ative instances, 4252 neutral instances, and 3355
positive instances. The number of distinct nouns is
4770 and the number of distinct adjectives is 384.
To check the inter-annotator agreement between
two annotators, we calculated n statistics, which
was 0.640. This value is allowable, but not quite
high. However, positive-negative disagreement is
observed for only 0.7% of the data. In other words,
this statistics means that the task of extracting neu-
tral examples, which has hardly been explored, is
intrinsically difficult.
We employ 10-fold cross-validation to obtain
the average value of the classification accuracy.
We split the dataset such that there is no overlap-
ping pair (i.e., any pair in the training dataset does
not appear in the test dataset).
If either of the two words in a pair in the test
dataset does not appear in the training dataset, we
excluded the pair from the test dataset since the
problem of unknown words is not in the scope of
this research. Therefore, we evaluate the pairs that
are not in the training dataset, but whose compo-
nent words appear in the training dataset.
In addition to the original dataset, which we call
the standard dataset, we prepared another dataset
in order to examine the power of the latent variable
model. The new dataset, which we call the hard
dataset, consists only of examples with 17 difficult
adjectives such as “high”, “low”, “large”, “small”,
“heavy”, and “light”. 1 The semantic orientations
of pairs including these difficult words often shift
depending on the noun they modify. Thus, the
hard dataset is a subset of the standard dataset. The
size of the hard dataset is 4787. Please note that
the hard dataset is used only as a test dataset. For
training, we always use the standard dataset in our
experiments.
We performed experiments with all the values
of Q in 10.1, 0.2, · · · ,1.0} and with all the values
of M in 110, 30, 50, 70,100, 200, 300, 500}, and
predicted the best values of the hyper-parameters
with the held-out method in Section 3.4.
</bodyText>
<sectionHeader confidence="0.611442" genericHeader="evaluation">
4.2 Results
</sectionHeader>
<bodyText confidence="0.990547363636364">
The classification accuracies of the four methods
with Q and M predicted by the held-out method
are shown in Table 1. Please note that the naive
bayes method is irrelevant of Q and M. The table
shows that the triangle model and the U-shaped
1The complete list of the 17 Japanese adjectives with their
English counterparts are : takai (high), hikui (low), ookii
(large), chiisai (small), omoi (heavy), karui (light), tsuyoi
(strong), yowai (weak), ooi (many), sukunai (few/little), nai
(no), sugoi (terrific), hageshii (terrific), hukai (deep), asai
(shallow), nagai (long), mizikai (short).
</bodyText>
<page confidence="0.999382">
205
</page>
<tableCaption confidence="0.999979">
Table 1: Accuracies with predicted Q and M
</tableCaption>
<table confidence="0.998503333333333">
standard hard
accuracy Q M accuracy Q M
Naive Bayes 73.40 – – 65.93 – –
3-PLSI 67.02 0.73 91.7 60.51 0.80 87.4
Triangle model 81.39 0.60 174.0 77.95 0.60 191.0
U-shaped model 81.94 0.64 60.0 75.86 0.65 48.3
</table>
<bodyText confidence="0.999877675">
model achieved high accuracies and outperformed
the naive bayes method. This result suggests that
we succeeded in capturing the internal structure
of semantically oriented phrases by way of latent
variables. The more complex structure of the tri-
angle model resulted in the accuracy that is higher
than that of the U-shaped model.
The performance of the 3-PLSI method is even
worse than the baseline method. This result shows
that we should use a model in which adjectives can
directly influence the rating category.
Figures 2, 3, 4 show cross-validated accuracy
values for various values of Q, respectively yielded
by the 3-PLSI model, the triangle model and the
U-shaped model with different numbers M of pos-
sible states for the latent variable. As the figures
show, the classification performance is sensitive to
the value of Q. M = 100 and M = 300 are mostly
better than M = 10. However, this is a tradeoff
between classification performance and training
time, since large values of M demand heavy com-
putation. In that sense, the U-shaped model is use-
ful in many practical situations, since it achieved a
good accuracy even with a relatively small M.
To observe the overall tendency of errors, we
show the contingency table of classification by the
U-shaped model with the predicted values of hy-
perparameters, in Table 2. As this table shows,
most of the errors are caused by the difficulty of
classifying neutral examples. Only 2.26% of the
errors are mix-ups of the positive orientation and
the negative orientation.
We next investigate the causes of errors by ob-
serving those mix-ups of the positive orientation
and the negative orientation.
One type of frequent errors is illustrated by the
pair “food (’s price) is high”, in which the word
“price” is omitted in the actual example 2. As in
this expression, the attribute (price, in this case) of
an example is sometimes omitted or not correctly
</bodyText>
<subsectionHeader confidence="0.469163">
2This kind of ellipsis often occurs in Japanese.
</subsectionHeader>
<figure confidence="0.872795">
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
beta
</figure>
<figureCaption confidence="0.98684">
Figure 4: U-shaped model with standard dataset
</figureCaption>
<figure confidence="0.998965375">
Accuracy (%)
84
82
80
78
76
74
72
70
68
66
64
62
M=300
M=100
M=10
</figure>
<figureCaption confidence="0.648012">
Figure 2: 3-PLSI model with standard dataset
</figureCaption>
<figure confidence="0.996114466666667">
84
82
80
78
76
74
72
70
68
66
64
62
Accuracy (%)
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
beta
</figure>
<figureCaption confidence="0.782633">
Figure 3: Triangle model with standard dataset
</figureCaption>
<figure confidence="0.99257880952381">
84
82
80
78
76
74
72
70
68
66
64
62
Accuracy (%)
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
beta
M=300
M=100
M=10
M=300
M=100
M=10
</figure>
<page confidence="0.996689">
206
</page>
<tableCaption confidence="0.998919">
Table 2: Contingency table of classification result by the U-shaped model
</tableCaption>
<table confidence="0.839040333333333">
U-shaped model
positive neutral negative sum
positive 1856 281 69 2206
Gold standard neutral 202 2021 394 2617
negative 102 321 2335 2758
sum 2160 2623 2798 7581
</table>
<bodyText confidence="0.994017076923077">
identified. To tackle these examples, we will need
methods for correctly identifying attributes and
objects. Some researchers are starting to work on
this problem (e.g., Popescu and Etzioni (2005)).
We succeeded in addressing the data-sparseness
problem by introducing a latent variable. How-
ever, this problem still causes some errors. Pre-
cise statistics cannot be obtained for infrequent
words. This problem will be solved by incorporat-
ing other resources such as thesaurus or a dictio-
nary, or combining our method with other methods
using external wider contexts (Suzuki et al., 2006;
Turney, 2002; Baron and Hirst, 2004).
</bodyText>
<subsectionHeader confidence="0.999303">
4.3 Examples of Obtained Clusters
</subsectionHeader>
<bodyText confidence="0.988162388888889">
Next, we qualitatively evaluate the proposed meth-
ods. For several clusters z, we extract the words
that occur more than twice in the whole dataset
and are in top 50 according to P(zln). The model
used here as an example is the U-shaped model.
The experimental settings are Q = 0.6 and M =
60. Although some elements of clusters are com-
posed of multiple words in English, the original
Japanese counterparts are single words.
Cluster 1 trouble, objection, disease, complaint, anx-
iety, anamnesis, relapse
Cluster 2 risk, mortality, infection rate, onset rate
Cluster 3 bond, opinion, love, meaning, longing, will
Cluster 4 vote, application, topic, supporter
Cluster 5 abuse, deterioration, shock, impact, burden
Cluster 6 deterioration, discrimination, load, abuse
Cluster 7 relative importance, degree of influence,
number, weight, sense of belonging, wave,
</bodyText>
<subsectionHeader confidence="0.391705">
reputation
</subsectionHeader>
<bodyText confidence="0.999989166666667">
These obtained clusters match our intuition. For
example, in cluster 2 are the nouns that are neg-
ative when combined with “high”, and positive
when combined with “low”. In fact, the posterior
probabilities of semantic orientations for cluster 2
are as follows :
</bodyText>
<equation confidence="0.9600635">
P (negative|high, cluster 2) = 0.995,
P (positive|low, cluster 2) = 0.973.
</equation>
<bodyText confidence="0.996788428571429">
With conventional clustering methods based on
the cooccurrence of two words, cluster 2 would
include the words resulting in the opposite orien-
tation, such as “success rate”. We succeeded in
obtaining the clusters that are suitable for our task,
by incorporating the new variable c for semantic
orientation in the EM computation.
</bodyText>
<sectionHeader confidence="0.9993" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999993772727273">
We proposed models for phrases with semantic
orientations as well as a classification method
based on the models. We introduced a latent vari-
able into the models to capture the properties of
phrases. Through experiments, we showed that
the proposed latent variable models work well
in the classification of semantic orientations of
phrases and achieved nearly 82% classification ac-
curacy. We should also note that our method is
language-independent although evaluation was on
a Japanese dataset.
We plan next to adopt a semi-supervised learn-
ing method in order to correctly classify phrases
with infrequent words, as mentioned in Sec-
tion 4.2. We would also like to extend our method
to 3- or more term phrases. We can also use the
obtained latent variables as features for another
classifier, as Fujita et al. (2004) used latent vari-
ables of PLSI for the k-nearest neighbors method.
One important and promising task would be the
use of semantic orientations of words for phrase
level classification.
</bodyText>
<sectionHeader confidence="0.998798" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9887815">
Faye Baron and Graeme Hirst. 2004. Collocations
as cues to semantic orientation. In AAAI Spring
Symposium on Exploring Attitude and Affect in Text:
Theories and Applications.
Arthur P. Dempster, Nan M. Laird, and Donald B. Ru-
bin. 1977. Maximum likelihood from incomplete
data via the EM algorithm. Journal of the Royal Sta-
tistical Society Series B, 39(1):1–38.
</reference>
<page confidence="0.968512">
207
</page>
<reference confidence="0.99983675">
Atsushi Fujita, Kentaro Inui, and Yuji Matsumoto.
2004. Detection of incorrect case assignments in au-
tomatically generated paraphrases of Japanese sen-
tences. In Proceedings of the 1st International Joint
Conference on Natural Language Processing (IJC-
NLP), pages 14–21.
Vasileios Hatzivassiloglou and Kathleen R. McKeown.
1997. Predicting the semantic orientation of ad-
jectives. In Proceedings of the Thirty-Fifth Annual
Meeting of the Association for Computational Lin-
guistics and the Eighth Conference of the European
Chapter of the Association for Computational Lin-
guistics, pages 174–181.
Thomas Hofmann. 2001. Unsupervised learning
by probabilistic latent semantic analysis. Machine
Learning, 42:177–196.
Thomas Hofmann. 2004. Latent semantic models for
collaborative filtering. ACM Transactions on Infor-
mation Systems, 22:89–115.
Takashi Inui. 2004. Acquiring Causal Knowledge from
Text Using Connective Markers. Ph.D. thesis, Grad-
uate School of Information Science, Nara Institute
of Science and Technology.
Jaap Kamps, Maarten Marx, Robert J. Mokken, and
Maarten de Rijke. 2004. Using wordnet to measure
semantic orientation of adjectives. In Proceedings
of the 4th International Conference on Language
Resources and Evaluation (LREC 2004), volume IV,
pages 1115–1118.
Nozomi Kobayashi, Takashi Inui, and Kentaro Inui.
2001. Dictionary-based acquisition of the lexical
knowledge for p/n analysis (in Japanese). In Pro-
ceedings of Japanese Society for Artificial Intelli-
gence, SLUD-33, pages 45–50.
Mainichi. 1995. Mainichi Shimbun CD-ROM version.
Shotaro Matsumoto, Hiroya Takamura, and Manabu
Okumura. 2005. Sentiment classification using
word sub-sequences and dependency sub-trees. In
Proceedings of the 9th Pacific-Asia Conference on
Knowledge Discovery and Data Mining (PAKDD-
05), pages 301–310.
Tom M. Mitchell. 1997. Machine Learning. McGraw
Hill.
Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.
2002. Thumbs up? sentiment classification using
machine learning techniques. In Proceedings of the
Conference on Empirical Methods in Natural Lan-
guage Processing (EMNLP’02), pages 79–86.
Ana-Maria Popescu and Oren Etzioni. 2005. Ex-
tracting product features and opinions from re-
views. In Proceedings of joint conference on Hu-
man Language Technology / Conference on Em-
pirical Methods in Natural Language Processing
(HLT/EMNLP’05), pages 339–346.
Frank Z. Smadja. 1993. Retrieving collocations
from text: Xtract. Computational Linguistics,,
19(1):143–177.
Yasuhiro Suzuki, Hiroya Takamura, and Manabu Oku-
mura. 2006. Application of semi-supervised learn-
ing to evaluative expression classification. In Pro-
ceedings of the 7th International Conference on In-
telligent Text Processing and Computational Lin-
guistics (CICLing-06), pages 502–513.
Hiroya Takamura, Takashi Inui, and Manabu Okumura.
2005. Extracting semantic orientations of words us-
ing spin model. In Proceedings 43rd Annual Meet-
ing of the Association for Computational Linguistics
(ACL’05), pages 133–140.
Kentaro Torisawa. 2001. An unsuperveised method
for canonicalization of Japanese postpositions. In
Proceedings of the 6th Natural Language Process-
ing Pacific Rim Symposium (NLPRS 2001), pages
211–218.
Peter D. Turney and Michael L. Littman. 2003. Mea-
suring praise and criticism: Inference of semantic
orientation from association. ACM Transactions on
Information Systems, 21(4):315–346.
Peter D. Turney. 2002. Thumbs up or thumbs down?
semantic orientation applied to unsupervised clas-
sification of reviews. In Proceedings 40th Annual
Meeting of the Association for Computational Lin-
guistics (ACL’02), pages 417–424.
Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.
2005. Recognizing contextual polarity in phrase-
level sentiment analysis. In Proceedings of joint
conference on Human Language Technology / Con-
ference on Empirical Methods in Natural Language
Processing (HLT/EMNLP’05), pages 347–354.
</reference>
<page confidence="0.997778">
208
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.337691">
<title confidence="0.998715">Latent Variable Models for Semantic Orientations of Phrases</title>
<author confidence="0.754966">Hiroya Takamura Takashi Inui</author>
<affiliation confidence="0.867762">Precision and Intelligence Laboratory Japan Society of the Promotion of Science Institute of Technology tinui@lr.pi.titech.ac.jp</affiliation>
<email confidence="0.628416">takamura@pi.titech.ac.jp</email>
<author confidence="0.957062">Manabu Okumura</author>
<affiliation confidence="0.999805">Precision and Intelligence Laboratory Tokyo Institute of Technology</affiliation>
<email confidence="0.930803">oku@pi.titech.ac.jp</email>
<abstract confidence="0.9836669375">We propose models for semantic orientations of phrases as well as classification methods based on the models. Although each phrase consists of multiple words, the semantic orientation of the phrase is not a mere sum of the orientations of the component words. Some words can invert the orientation. In order to capture the property of such phrases, we introduce latent variables into the models. Through experiments, we show that the proposed latent variable models work well in the classification of semantic orientations of phrases and achieved nearly 82% classification accuracy.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Faye Baron</author>
<author>Graeme Hirst</author>
</authors>
<title>Collocations as cues to semantic orientation.</title>
<date>2004</date>
<booktitle>In AAAI Spring Symposium on Exploring Attitude and Affect in Text: Theories and Applications.</booktitle>
<contexts>
<context position="6466" citStr="Baron and Hirst (2004)" startWordPosition="1009" endWordPosition="1012">onMaximization algorithm and the naive bayes classifier to incorporate the unlabeled data in the classification of 3-term evaluative expressions. They focused on the utilization of context information such as neighboring words and emoticons. Turney (2002) applied an internet-based technique to the semantic orientation classification of phrases, which had originally been developed for word sentiment classification. In their method, the number of hits returned by a search-engine, with a query consisting of a phrase and a seed word (e.g., “phrase NEAR good”) is used to determine the orientation. Baron and Hirst (2004) extracted collocations with Xtract (Smadja, 1993) and classified the collocations using the orientations of the words in the neighboring sentences. Their method is similar to Turney’s in the sense that cooccurrence with seed words is used. The three methods above are based on context information. In contrast, our method exploits the internal structure of the semantic orientations of phrases. Inui (2004) introduced an attribute plus/minus for each word and proposed several rules that determine the semantic orientations of phrases on the basis of the plus/minus attribute values and the positive</context>
<context position="23486" citStr="Baron and Hirst, 2004" startWordPosition="3900" endWordPosition="3903">dentified. To tackle these examples, we will need methods for correctly identifying attributes and objects. Some researchers are starting to work on this problem (e.g., Popescu and Etzioni (2005)). We succeeded in addressing the data-sparseness problem by introducing a latent variable. However, this problem still causes some errors. Precise statistics cannot be obtained for infrequent words. This problem will be solved by incorporating other resources such as thesaurus or a dictionary, or combining our method with other methods using external wider contexts (Suzuki et al., 2006; Turney, 2002; Baron and Hirst, 2004). 4.3 Examples of Obtained Clusters Next, we qualitatively evaluate the proposed methods. For several clusters z, we extract the words that occur more than twice in the whole dataset and are in top 50 according to P(zln). The model used here as an example is the U-shaped model. The experimental settings are Q = 0.6 and M = 60. Although some elements of clusters are composed of multiple words in English, the original Japanese counterparts are single words. Cluster 1 trouble, objection, disease, complaint, anxiety, anamnesis, relapse Cluster 2 risk, mortality, infection rate, onset rate Cluster </context>
</contexts>
<marker>Baron, Hirst, 2004</marker>
<rawString>Faye Baron and Graeme Hirst. 2004. Collocations as cues to semantic orientation. In AAAI Spring Symposium on Exploring Attitude and Affect in Text: Theories and Applications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arthur P Dempster</author>
<author>Nan M Laird</author>
<author>Donald B Rubin</author>
</authors>
<title>Maximum likelihood from incomplete data via the EM algorithm.</title>
<date>1977</date>
<journal>Journal of the Royal Statistical Society Series B,</journal>
<volume>39</volume>
<issue>1</issue>
<contexts>
<context position="10784" citStr="Dempster et al., 1977" startWordPosition="1736" endWordPosition="1739">or this task. 3.1 Triangle Model Suppose that a set D of tuples of noun n, adjective a (predicate, generally) and the rating c is given: D = {(n1, a1, c1),···, (n|D|, a|D|, c|D|)}, (1) where c E {−1, 0, 11, for example. This can be easily expanded to the case of c E 11, · · · , 51. Our purpose is to predict the rating c for unknown pairs of n and a. According to Figure 1-(d), the generative probability of n, a, c, z is the following : P(nacz) = P(z|n)P(a|z)P(c|az)P(n). (2) Remember that for the original PLSI model, P(naz) = P(zJn)P(aJz)P(n). We use the Expectation-Maximization (EM) algorithm (Dempster et al., 1977) to estimate the parameters of the model. According to the theory of the EM algorithm, we can increase the likelihood of the model with latent variables by iteratively increasing the Q-function. The Q-function (i.e., the expected log-likelihood of the joint probability of complete data with respect to the conditional posterior of the latent variable) is expressed as : Q(θ) = X Xfnac P¯(z|nac) log P(nazc|θ), (3) nac z where θ denotes the set of the new parameters. fnac denotes the frequency of a tuple n, a, c in the data. P¯ represents the posterior computed using the current parameters. The E-</context>
</contexts>
<marker>Dempster, Laird, Rubin, 1977</marker>
<rawString>Arthur P. Dempster, Nan M. Laird, and Donald B. Rubin. 1977. Maximum likelihood from incomplete data via the EM algorithm. Journal of the Royal Statistical Society Series B, 39(1):1–38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Atsushi Fujita</author>
<author>Kentaro Inui</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Detection of incorrect case assignments in automatically generated paraphrases of Japanese sentences.</title>
<date>2004</date>
<booktitle>In Proceedings of the 1st International Joint Conference on Natural Language Processing (IJCNLP),</booktitle>
<pages>14--21</pages>
<contexts>
<context position="4544" citStr="Fujita et al. (2004)" startWordPosition="712" endWordPosition="715">stic model to identify the appropriate case for a pair of words constituting a noun and a verb with the case of the noun-verb pair unknown. Their model is the same as Probabilistic Latent Semantic Indexing (PLSI) (Hofmann, 2001), which is a generative probability model of two random variables. Torisawa’s method is similar to ours in that a latent variable model is used for word pairs. However, Torisawa’s objective is different from ours. In addition, we used not the original PLSI, but its expanded version, which is more suitable for this task of semantic orientation classification of phrases. Fujita et al. (2004) addressed the task of the detection of incorrect case assignment in automatically paraphrased sentences. They reduced the task to a problem of classifying pairs of a verb and a noun with a case into correct or incorrect. They first obtained a latent semantic space with PLSI and adopted the nearest-neighbors method, in which they used latent variables as features. Fujita et al.’s method is different from ours, and also from Torisawa’s, in that a probabilistic model is used for feature extraction. 2.2 Identification of Semantic Orientations The semantic orientation classification of words has b</context>
</contexts>
<marker>Fujita, Inui, Matsumoto, 2004</marker>
<rawString>Atsushi Fujita, Kentaro Inui, and Yuji Matsumoto. 2004. Detection of incorrect case assignments in automatically generated paraphrases of Japanese sentences. In Proceedings of the 1st International Joint Conference on Natural Language Processing (IJCNLP), pages 14–21.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vasileios Hatzivassiloglou</author>
<author>Kathleen R McKeown</author>
</authors>
<title>Predicting the semantic orientation of adjectives.</title>
<date>1997</date>
<booktitle>In Proceedings of the Thirty-Fifth Annual Meeting of the Association for Computational Linguistics and the Eighth Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>174--181</pages>
<contexts>
<context position="1591" citStr="Hatzivassiloglou and McKeown, 1997" startWordPosition="232" endWordPosition="236">n Technology for affect analysis of texts has recently gained attention in both academic and industrial areas. It can be applied to, for example, a survey of new products or a questionnaire analysis. Automatic sentiment analysis enables a fast and comprehensive investigation. The most fundamental step for sentiment analysis is to acquire the semantic orientations of words: desirable or undesirable (positive or negative). For example, the word “beautiful” is positive, while the word “dirty” is negative. Many researchers have developed several methods for this purpose and obtained good results (Hatzivassiloglou and McKeown, 1997; Turney and Littman, 2003; Kamps et al., 2004; Takamura et al., 2005; Kobayashi et al., 2001). One of the next problems to be solved is to acquire semantic orientations of phrases, or multi-term expressions. No computational model for semantically oriented phrases has been proposed so far although some researchers have used techniques developed for single words. The purpose of this paper is to propose computational models for phrases with semantic orientations as well as classification methods based on the models. Indeed the semantic orientations of phrases depend on context just as the seman</context>
<context position="5214" citStr="Hatzivassiloglou and McKeown, 1997" startWordPosition="817" endWordPosition="821"> of incorrect case assignment in automatically paraphrased sentences. They reduced the task to a problem of classifying pairs of a verb and a noun with a case into correct or incorrect. They first obtained a latent semantic space with PLSI and adopted the nearest-neighbors method, in which they used latent variables as features. Fujita et al.’s method is different from ours, and also from Torisawa’s, in that a probabilistic model is used for feature extraction. 2.2 Identification of Semantic Orientations The semantic orientation classification of words has been pursued by several researchers (Hatzivassiloglou and McKeown, 1997; Turney and Littman, 2003; Kamps et al., 2004; Takamura et al., 2005). However, no computational model for semantically oriented phrases has been proposed to date although research for a similar purpose has been proposed. Some researchers used sequences of words as features in document classification according to semantic orientation. Pang et al. (2002) used bigrams. Matsumoto et al. (2005) used sequential patterns and tree patterns. Although such patterns were proved to be effective in document classification, the semantic orientations of the patterns themselves are not considered. Suzuki et</context>
</contexts>
<marker>Hatzivassiloglou, McKeown, 1997</marker>
<rawString>Vasileios Hatzivassiloglou and Kathleen R. McKeown. 1997. Predicting the semantic orientation of adjectives. In Proceedings of the Thirty-Fifth Annual Meeting of the Association for Computational Linguistics and the Eighth Conference of the European Chapter of the Association for Computational Linguistics, pages 174–181.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Hofmann</author>
</authors>
<title>Unsupervised learning by probabilistic latent semantic analysis.</title>
<date>2001</date>
<booktitle>Machine Learning,</booktitle>
<pages>42--177</pages>
<contexts>
<context position="4152" citStr="Hofmann, 2001" startWordPosition="649" endWordPosition="650">they are “low”), make a cluster in these models. Our method is language201 independent in the sense that it uses only cooccurrence data of words and semantic orientations. 2 Related Work We briefly explain related work from two viewpoints: the classification of word pairs and the identification of semantic orientation. 2.1 Classification of Word Pairs Torisawa (2001) used a probabilistic model to identify the appropriate case for a pair of words constituting a noun and a verb with the case of the noun-verb pair unknown. Their model is the same as Probabilistic Latent Semantic Indexing (PLSI) (Hofmann, 2001), which is a generative probability model of two random variables. Torisawa’s method is similar to ours in that a latent variable model is used for word pairs. However, Torisawa’s objective is different from ours. In addition, we used not the original PLSI, but its expanded version, which is more suitable for this task of semantic orientation classification of phrases. Fujita et al. (2004) addressed the task of the detection of incorrect case assignment in automatically paraphrased sentences. They reduced the task to a problem of classifying pairs of a verb and a noun with a case into correct </context>
<context position="13323" citStr="Hofmann, 2001" startWordPosition="2189" endWordPosition="2190">terior probability : P(c|na) ∝ P(n|c)P(a|c)P(c). (15) This baseline model is equivalent to the 2-term naive bayes classifier (Mitchell, 1997). The graphical representation of the naive bayes model is (b) in Figure 1. The parameters are estimated as : 1 + fnc P(n|c) = (16) |N |+ fc 1 + fac P(a|c) = |A |+ fc , (17) where |N |and |A |are the numbers of the words for n and a, respectively. Thus, we have four different models : naive bayes (baseline), 3-PLSI, triangle, and U-shaped. 3.4 Discussions on the EM computation, the Models and the Task In the actual EM computation, we use the tempered EM (Hofmann, 2001) instead of the standard EM explained above, because the tempered EM can avoid an inaccurate estimation of the model caused by “over-confidence” in computing the posterior probabilities. The tempered EM can be realized by a slight modification to the E-step, which results in a new E-step : ¡P(c|az)P(z|n)¢β P¯ (z|nac) = (18) Pz ¡P(c|az)P(z|n)¢β for the U-shaped model, where β is a positive hyper-parameter, called the inverse temperature. The new E-steps for the other models are similarly expressed. Now we have two hyper-parameters : inverse temperature β, and the number of possible values M of </context>
</contexts>
<marker>Hofmann, 2001</marker>
<rawString>Thomas Hofmann. 2001. Unsupervised learning by probabilistic latent semantic analysis. Machine Learning, 42:177–196.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Hofmann</author>
</authors>
<title>Latent semantic models for collaborative filtering.</title>
<date>2004</date>
<journal>ACM Transactions on Information Systems,</journal>
<pages>22--89</pages>
<contexts>
<context position="8631" citStr="Hofmann (2004)" startWordPosition="1364" endWordPosition="1365">nt variable models to extract such latent semantic clusters and to realize an accurate classification of phrases (we focus 202 N Z N N Z N Z N Z A A C A C A C A C (a) (b) (c) (d) (e) Figure 1: Graphical representations:(a) PLSI, (b) naive bayes, (c) 3-PLSI, (d) triangle, (e) U-shaped; Each node indicates a random variable. Arrows indicate statistical dependency between variables. N, A, Z and C respectively correspond to nouns, adjectives, latent clusters and semantic orientations. on two-term phrases in this paper). The models adopted in this paper are also used for collaborative filtering by Hofmann (2004). With these models, the nouns (e.g., “risk” and “mortality”) that become positive by reducing their degree or amount would make a cluster. On the other hand, the adjectives or verbs (e.g., “reduce” and “decrease”) that are related to reduction would also make a cluster. Figure 1 shows graphical representations of statistical dependencies of models with a latent variable. N, A, Z and C respectively correspond to nouns, adjectives, latent clusters and semantic orientations. Figure 1-(a) is the PLSI model, which cannot be used in this task due to the absence of a variable for semantic orientatio</context>
<context position="14628" citStr="Hofmann (2004)" startWordPosition="2407" endWordPosition="2408">training dataset into two datasets (the temporary training dataset 90% and the held-out dataset 10%), and by obtaining the classification accuracy for the held-out dataset, which is yielded by the classifier with the temporary training dataset. We should also note that Z (or any variable) should not have incoming arrows simultaneously from N and A, because the model with such arrows has P(z|na), which usually requires an excessively large memory. To work with numerical scales of the rating variable (i.e., the difference between c = −1 and c = 1 should be larger than that of c = −1 and c = 0), Hofmann (2004) used also a Gaussian distribution for P(c|az) in collaborative filtering. However, we do not employ a Gaussian, because in our dataset, the number of rating classes is These steps are iteratively computed until convergence. If the difference of the values of Q-function before and after an iteration becomes smaller than a threshold, we regard it as converged. For classification of an unknown pair n, a, we compare the values of P(c 204 P(c |az) = fn ac (7) P¯ (z|nac). Pn P¯(z |nac) Pnc fnac only 3, which is so small that a Gaussian distribution cannot be a good approximation of the actual proba</context>
</contexts>
<marker>Hofmann, 2004</marker>
<rawString>Thomas Hofmann. 2004. Latent semantic models for collaborative filtering. ACM Transactions on Information Systems, 22:89–115.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Takashi Inui</author>
</authors>
<title>Acquiring Causal Knowledge from Text Using Connective Markers.</title>
<date>2004</date>
<tech>Ph.D. thesis,</tech>
<institution>Graduate School of Information Science, Nara Institute of Science and Technology.</institution>
<contexts>
<context position="6873" citStr="Inui (2004)" startWordPosition="1076" endWordPosition="1077">In their method, the number of hits returned by a search-engine, with a query consisting of a phrase and a seed word (e.g., “phrase NEAR good”) is used to determine the orientation. Baron and Hirst (2004) extracted collocations with Xtract (Smadja, 1993) and classified the collocations using the orientations of the words in the neighboring sentences. Their method is similar to Turney’s in the sense that cooccurrence with seed words is used. The three methods above are based on context information. In contrast, our method exploits the internal structure of the semantic orientations of phrases. Inui (2004) introduced an attribute plus/minus for each word and proposed several rules that determine the semantic orientations of phrases on the basis of the plus/minus attribute values and the positive/negative attribute values of the component words. For example, a rule [negative+minus=positive] determines “low (minus) risk (negative)” to be positive. Wilson et al. (2005) worked on phrase-level semantic orientations. They introduced a polarity shifter, which is almost equivalent to the plus/minus attribute above. They manually created the list of polarity shifters. The method that we propose in this </context>
</contexts>
<marker>Inui, 2004</marker>
<rawString>Takashi Inui. 2004. Acquiring Causal Knowledge from Text Using Connective Markers. Ph.D. thesis, Graduate School of Information Science, Nara Institute of Science and Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jaap Kamps</author>
<author>Maarten Marx</author>
<author>Robert J Mokken</author>
<author>Maarten de Rijke</author>
</authors>
<title>Using wordnet to measure semantic orientation of adjectives.</title>
<date>2004</date>
<booktitle>In Proceedings of the 4th International Conference on Language Resources and Evaluation (LREC 2004), volume IV,</booktitle>
<pages>1115--1118</pages>
<marker>Kamps, Marx, Mokken, de Rijke, 2004</marker>
<rawString>Jaap Kamps, Maarten Marx, Robert J. Mokken, and Maarten de Rijke. 2004. Using wordnet to measure semantic orientation of adjectives. In Proceedings of the 4th International Conference on Language Resources and Evaluation (LREC 2004), volume IV, pages 1115–1118.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nozomi Kobayashi</author>
<author>Takashi Inui</author>
<author>Kentaro Inui</author>
</authors>
<title>Dictionary-based acquisition of the lexical knowledge for p/n analysis (in Japanese).</title>
<date>2001</date>
<booktitle>In Proceedings of Japanese Society for Artificial Intelligence, SLUD-33,</booktitle>
<pages>45--50</pages>
<contexts>
<context position="1685" citStr="Kobayashi et al., 2001" startWordPosition="249" endWordPosition="252">reas. It can be applied to, for example, a survey of new products or a questionnaire analysis. Automatic sentiment analysis enables a fast and comprehensive investigation. The most fundamental step for sentiment analysis is to acquire the semantic orientations of words: desirable or undesirable (positive or negative). For example, the word “beautiful” is positive, while the word “dirty” is negative. Many researchers have developed several methods for this purpose and obtained good results (Hatzivassiloglou and McKeown, 1997; Turney and Littman, 2003; Kamps et al., 2004; Takamura et al., 2005; Kobayashi et al., 2001). One of the next problems to be solved is to acquire semantic orientations of phrases, or multi-term expressions. No computational model for semantically oriented phrases has been proposed so far although some researchers have used techniques developed for single words. The purpose of this paper is to propose computational models for phrases with semantic orientations as well as classification methods based on the models. Indeed the semantic orientations of phrases depend on context just as the semantic orientations of words do, but we would like to obtain the most basic orientations of phras</context>
</contexts>
<marker>Kobayashi, Inui, Inui, 2001</marker>
<rawString>Nozomi Kobayashi, Takashi Inui, and Kentaro Inui. 2001. Dictionary-based acquisition of the lexical knowledge for p/n analysis (in Japanese). In Proceedings of Japanese Society for Artificial Intelligence, SLUD-33, pages 45–50.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mainichi</author>
</authors>
<title>Mainichi Shimbun CD-ROM version. Shotaro Matsumoto, Hiroya Takamura, and Manabu Okumura.</title>
<date>1995</date>
<booktitle>In Proceedings of the 9th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD05),</booktitle>
<pages>301--310</pages>
<marker>Mainichi, 1995</marker>
<rawString>Mainichi. 1995. Mainichi Shimbun CD-ROM version. Shotaro Matsumoto, Hiroya Takamura, and Manabu Okumura. 2005. Sentiment classification using word sub-sequences and dependency sub-trees. In Proceedings of the 9th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD05), pages 301–310.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tom M Mitchell</author>
</authors>
<date>1997</date>
<booktitle>Machine Learning.</booktitle>
<publisher>McGraw Hill.</publisher>
<contexts>
<context position="12850" citStr="Mitchell, 1997" startWordPosition="2097" endWordPosition="2098"> θ).(10) nac z We obtain the following update rules : E step P(c|az)P(z|n) P¯(z|nac) = Pz P(c|az)P(z|n), (11) M step P n fnac P¯ (z|nac) P(c|az) = (12) Pnc fnac P¯(z|nac), Pac fnac P¯ (z|nac) P(z|n) = P . (13) ac fnac For classification, we use the formula: P (c|na) = X P(c|az)P(z|n). (14) z 3.3 Other Models for Comparison We will also test the 3-PLSI model corresponding to Figure 1-(c). In addition to the latent models, we test a baseline classifier, which uses the posterior probability : P(c|na) ∝ P(n|c)P(a|c)P(c). (15) This baseline model is equivalent to the 2-term naive bayes classifier (Mitchell, 1997). The graphical representation of the naive bayes model is (b) in Figure 1. The parameters are estimated as : 1 + fnc P(n|c) = (16) |N |+ fc 1 + fac P(a|c) = |A |+ fc , (17) where |N |and |A |are the numbers of the words for n and a, respectively. Thus, we have four different models : naive bayes (baseline), 3-PLSI, triangle, and U-shaped. 3.4 Discussions on the EM computation, the Models and the Task In the actual EM computation, we use the tempered EM (Hofmann, 2001) instead of the standard EM explained above, because the tempered EM can avoid an inaccurate estimation of the model caused by </context>
</contexts>
<marker>Mitchell, 1997</marker>
<rawString>Tom M. Mitchell. 1997. Machine Learning. McGraw Hill.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
<author>Shivakumar Vaithyanathan</author>
</authors>
<title>Thumbs up? sentiment classification using machine learning techniques.</title>
<date>2002</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP’02),</booktitle>
<pages>79--86</pages>
<contexts>
<context position="5570" citStr="Pang et al. (2002)" startWordPosition="871" endWordPosition="874">ours, and also from Torisawa’s, in that a probabilistic model is used for feature extraction. 2.2 Identification of Semantic Orientations The semantic orientation classification of words has been pursued by several researchers (Hatzivassiloglou and McKeown, 1997; Turney and Littman, 2003; Kamps et al., 2004; Takamura et al., 2005). However, no computational model for semantically oriented phrases has been proposed to date although research for a similar purpose has been proposed. Some researchers used sequences of words as features in document classification according to semantic orientation. Pang et al. (2002) used bigrams. Matsumoto et al. (2005) used sequential patterns and tree patterns. Although such patterns were proved to be effective in document classification, the semantic orientations of the patterns themselves are not considered. Suzuki et al. (2006) used the ExpectationMaximization algorithm and the naive bayes classifier to incorporate the unlabeled data in the classification of 3-term evaluative expressions. They focused on the utilization of context information such as neighboring words and emoticons. Turney (2002) applied an internet-based technique to the semantic orientation classi</context>
</contexts>
<marker>Pang, Lee, Vaithyanathan, 2002</marker>
<rawString>Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan. 2002. Thumbs up? sentiment classification using machine learning techniques. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP’02), pages 79–86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ana-Maria Popescu</author>
<author>Oren Etzioni</author>
</authors>
<title>Extracting product features and opinions from reviews.</title>
<date>2005</date>
<booktitle>In Proceedings of joint conference on Human Language Technology / Conference on Empirical Methods in Natural Language Processing (HLT/EMNLP’05),</booktitle>
<pages>339--346</pages>
<contexts>
<context position="23059" citStr="Popescu and Etzioni (2005)" startWordPosition="3833" endWordPosition="3836">7 0.8 0.9 1 beta Figure 3: Triangle model with standard dataset 84 82 80 78 76 74 72 70 68 66 64 62 Accuracy (%) 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 beta M=300 M=100 M=10 M=300 M=100 M=10 206 Table 2: Contingency table of classification result by the U-shaped model U-shaped model positive neutral negative sum positive 1856 281 69 2206 Gold standard neutral 202 2021 394 2617 negative 102 321 2335 2758 sum 2160 2623 2798 7581 identified. To tackle these examples, we will need methods for correctly identifying attributes and objects. Some researchers are starting to work on this problem (e.g., Popescu and Etzioni (2005)). We succeeded in addressing the data-sparseness problem by introducing a latent variable. However, this problem still causes some errors. Precise statistics cannot be obtained for infrequent words. This problem will be solved by incorporating other resources such as thesaurus or a dictionary, or combining our method with other methods using external wider contexts (Suzuki et al., 2006; Turney, 2002; Baron and Hirst, 2004). 4.3 Examples of Obtained Clusters Next, we qualitatively evaluate the proposed methods. For several clusters z, we extract the words that occur more than twice in the whol</context>
</contexts>
<marker>Popescu, Etzioni, 2005</marker>
<rawString>Ana-Maria Popescu and Oren Etzioni. 2005. Extracting product features and opinions from reviews. In Proceedings of joint conference on Human Language Technology / Conference on Empirical Methods in Natural Language Processing (HLT/EMNLP’05), pages 339–346.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank Z Smadja</author>
</authors>
<title>Retrieving collocations from text:</title>
<date>1993</date>
<journal>Xtract. Computational Linguistics,,</journal>
<volume>19</volume>
<issue>1</issue>
<contexts>
<context position="6516" citStr="Smadja, 1993" startWordPosition="1018" endWordPosition="1019">incorporate the unlabeled data in the classification of 3-term evaluative expressions. They focused on the utilization of context information such as neighboring words and emoticons. Turney (2002) applied an internet-based technique to the semantic orientation classification of phrases, which had originally been developed for word sentiment classification. In their method, the number of hits returned by a search-engine, with a query consisting of a phrase and a seed word (e.g., “phrase NEAR good”) is used to determine the orientation. Baron and Hirst (2004) extracted collocations with Xtract (Smadja, 1993) and classified the collocations using the orientations of the words in the neighboring sentences. Their method is similar to Turney’s in the sense that cooccurrence with seed words is used. The three methods above are based on context information. In contrast, our method exploits the internal structure of the semantic orientations of phrases. Inui (2004) introduced an attribute plus/minus for each word and proposed several rules that determine the semantic orientations of phrases on the basis of the plus/minus attribute values and the positive/negative attribute values of the component words.</context>
</contexts>
<marker>Smadja, 1993</marker>
<rawString>Frank Z. Smadja. 1993. Retrieving collocations from text: Xtract. Computational Linguistics,, 19(1):143–177.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yasuhiro Suzuki</author>
<author>Hiroya Takamura</author>
<author>Manabu Okumura</author>
</authors>
<title>Application of semi-supervised learning to evaluative expression classification.</title>
<date>2006</date>
<booktitle>In Proceedings of the 7th International Conference on Intelligent Text Processing and Computational Linguistics (CICLing-06),</booktitle>
<pages>502--513</pages>
<contexts>
<context position="5825" citStr="Suzuki et al. (2006)" startWordPosition="910" endWordPosition="913">own, 1997; Turney and Littman, 2003; Kamps et al., 2004; Takamura et al., 2005). However, no computational model for semantically oriented phrases has been proposed to date although research for a similar purpose has been proposed. Some researchers used sequences of words as features in document classification according to semantic orientation. Pang et al. (2002) used bigrams. Matsumoto et al. (2005) used sequential patterns and tree patterns. Although such patterns were proved to be effective in document classification, the semantic orientations of the patterns themselves are not considered. Suzuki et al. (2006) used the ExpectationMaximization algorithm and the naive bayes classifier to incorporate the unlabeled data in the classification of 3-term evaluative expressions. They focused on the utilization of context information such as neighboring words and emoticons. Turney (2002) applied an internet-based technique to the semantic orientation classification of phrases, which had originally been developed for word sentiment classification. In their method, the number of hits returned by a search-engine, with a query consisting of a phrase and a seed word (e.g., “phrase NEAR good”) is used to determin</context>
<context position="23448" citStr="Suzuki et al., 2006" startWordPosition="3894" endWordPosition="3897">2335 2758 sum 2160 2623 2798 7581 identified. To tackle these examples, we will need methods for correctly identifying attributes and objects. Some researchers are starting to work on this problem (e.g., Popescu and Etzioni (2005)). We succeeded in addressing the data-sparseness problem by introducing a latent variable. However, this problem still causes some errors. Precise statistics cannot be obtained for infrequent words. This problem will be solved by incorporating other resources such as thesaurus or a dictionary, or combining our method with other methods using external wider contexts (Suzuki et al., 2006; Turney, 2002; Baron and Hirst, 2004). 4.3 Examples of Obtained Clusters Next, we qualitatively evaluate the proposed methods. For several clusters z, we extract the words that occur more than twice in the whole dataset and are in top 50 according to P(zln). The model used here as an example is the U-shaped model. The experimental settings are Q = 0.6 and M = 60. Although some elements of clusters are composed of multiple words in English, the original Japanese counterparts are single words. Cluster 1 trouble, objection, disease, complaint, anxiety, anamnesis, relapse Cluster 2 risk, mortalit</context>
</contexts>
<marker>Suzuki, Takamura, Okumura, 2006</marker>
<rawString>Yasuhiro Suzuki, Hiroya Takamura, and Manabu Okumura. 2006. Application of semi-supervised learning to evaluative expression classification. In Proceedings of the 7th International Conference on Intelligent Text Processing and Computational Linguistics (CICLing-06), pages 502–513.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroya Takamura</author>
<author>Takashi Inui</author>
<author>Manabu Okumura</author>
</authors>
<title>Extracting semantic orientations of words using spin model.</title>
<date>2005</date>
<booktitle>In Proceedings 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05),</booktitle>
<pages>133--140</pages>
<contexts>
<context position="1660" citStr="Takamura et al., 2005" startWordPosition="245" endWordPosition="248">ademic and industrial areas. It can be applied to, for example, a survey of new products or a questionnaire analysis. Automatic sentiment analysis enables a fast and comprehensive investigation. The most fundamental step for sentiment analysis is to acquire the semantic orientations of words: desirable or undesirable (positive or negative). For example, the word “beautiful” is positive, while the word “dirty” is negative. Many researchers have developed several methods for this purpose and obtained good results (Hatzivassiloglou and McKeown, 1997; Turney and Littman, 2003; Kamps et al., 2004; Takamura et al., 2005; Kobayashi et al., 2001). One of the next problems to be solved is to acquire semantic orientations of phrases, or multi-term expressions. No computational model for semantically oriented phrases has been proposed so far although some researchers have used techniques developed for single words. The purpose of this paper is to propose computational models for phrases with semantic orientations as well as classification methods based on the models. Indeed the semantic orientations of phrases depend on context just as the semantic orientations of words do, but we would like to obtain the most ba</context>
<context position="5284" citStr="Takamura et al., 2005" startWordPosition="830" endWordPosition="833"> the task to a problem of classifying pairs of a verb and a noun with a case into correct or incorrect. They first obtained a latent semantic space with PLSI and adopted the nearest-neighbors method, in which they used latent variables as features. Fujita et al.’s method is different from ours, and also from Torisawa’s, in that a probabilistic model is used for feature extraction. 2.2 Identification of Semantic Orientations The semantic orientation classification of words has been pursued by several researchers (Hatzivassiloglou and McKeown, 1997; Turney and Littman, 2003; Kamps et al., 2004; Takamura et al., 2005). However, no computational model for semantically oriented phrases has been proposed to date although research for a similar purpose has been proposed. Some researchers used sequences of words as features in document classification according to semantic orientation. Pang et al. (2002) used bigrams. Matsumoto et al. (2005) used sequential patterns and tree patterns. Although such patterns were proved to be effective in document classification, the semantic orientations of the patterns themselves are not considered. Suzuki et al. (2006) used the ExpectationMaximization algorithm and the naive b</context>
</contexts>
<marker>Takamura, Inui, Okumura, 2005</marker>
<rawString>Hiroya Takamura, Takashi Inui, and Manabu Okumura. 2005. Extracting semantic orientations of words using spin model. In Proceedings 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05), pages 133–140.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kentaro Torisawa</author>
</authors>
<title>An unsuperveised method for canonicalization of Japanese postpositions.</title>
<date>2001</date>
<booktitle>In Proceedings of the 6th Natural Language Processing Pacific Rim Symposium (NLPRS</booktitle>
<pages>211--218</pages>
<contexts>
<context position="3907" citStr="Torisawa (2001)" startWordPosition="608" endWordPosition="609">dels, where one random variable corresponds to nouns and another random variable corresponds to adjectives. The words that are similar in terms of semantic orientations, such as “risk” and “mortality” (i.e., the positive orientation emerges when they are “low”), make a cluster in these models. Our method is language201 independent in the sense that it uses only cooccurrence data of words and semantic orientations. 2 Related Work We briefly explain related work from two viewpoints: the classification of word pairs and the identification of semantic orientation. 2.1 Classification of Word Pairs Torisawa (2001) used a probabilistic model to identify the appropriate case for a pair of words constituting a noun and a verb with the case of the noun-verb pair unknown. Their model is the same as Probabilistic Latent Semantic Indexing (PLSI) (Hofmann, 2001), which is a generative probability model of two random variables. Torisawa’s method is similar to ours in that a latent variable model is used for word pairs. However, Torisawa’s objective is different from ours. In addition, we used not the original PLSI, but its expanded version, which is more suitable for this task of semantic orientation classifica</context>
</contexts>
<marker>Torisawa, 2001</marker>
<rawString>Kentaro Torisawa. 2001. An unsuperveised method for canonicalization of Japanese postpositions. In Proceedings of the 6th Natural Language Processing Pacific Rim Symposium (NLPRS 2001), pages 211–218.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
<author>Michael L Littman</author>
</authors>
<title>Measuring praise and criticism: Inference of semantic orientation from association.</title>
<date>2003</date>
<journal>ACM Transactions on Information Systems,</journal>
<volume>21</volume>
<issue>4</issue>
<contexts>
<context position="1617" citStr="Turney and Littman, 2003" startWordPosition="237" endWordPosition="240">texts has recently gained attention in both academic and industrial areas. It can be applied to, for example, a survey of new products or a questionnaire analysis. Automatic sentiment analysis enables a fast and comprehensive investigation. The most fundamental step for sentiment analysis is to acquire the semantic orientations of words: desirable or undesirable (positive or negative). For example, the word “beautiful” is positive, while the word “dirty” is negative. Many researchers have developed several methods for this purpose and obtained good results (Hatzivassiloglou and McKeown, 1997; Turney and Littman, 2003; Kamps et al., 2004; Takamura et al., 2005; Kobayashi et al., 2001). One of the next problems to be solved is to acquire semantic orientations of phrases, or multi-term expressions. No computational model for semantically oriented phrases has been proposed so far although some researchers have used techniques developed for single words. The purpose of this paper is to propose computational models for phrases with semantic orientations as well as classification methods based on the models. Indeed the semantic orientations of phrases depend on context just as the semantic orientations of words </context>
<context position="5240" citStr="Turney and Littman, 2003" startWordPosition="822" endWordPosition="825">omatically paraphrased sentences. They reduced the task to a problem of classifying pairs of a verb and a noun with a case into correct or incorrect. They first obtained a latent semantic space with PLSI and adopted the nearest-neighbors method, in which they used latent variables as features. Fujita et al.’s method is different from ours, and also from Torisawa’s, in that a probabilistic model is used for feature extraction. 2.2 Identification of Semantic Orientations The semantic orientation classification of words has been pursued by several researchers (Hatzivassiloglou and McKeown, 1997; Turney and Littman, 2003; Kamps et al., 2004; Takamura et al., 2005). However, no computational model for semantically oriented phrases has been proposed to date although research for a similar purpose has been proposed. Some researchers used sequences of words as features in document classification according to semantic orientation. Pang et al. (2002) used bigrams. Matsumoto et al. (2005) used sequential patterns and tree patterns. Although such patterns were proved to be effective in document classification, the semantic orientations of the patterns themselves are not considered. Suzuki et al. (2006) used the Expec</context>
</contexts>
<marker>Turney, Littman, 2003</marker>
<rawString>Peter D. Turney and Michael L. Littman. 2003. Measuring praise and criticism: Inference of semantic orientation from association. ACM Transactions on Information Systems, 21(4):315–346.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
</authors>
<title>Thumbs up or thumbs down? semantic orientation applied to unsupervised classification of reviews.</title>
<date>2002</date>
<booktitle>In Proceedings 40th Annual Meeting of the Association for Computational Linguistics (ACL’02),</booktitle>
<pages>417--424</pages>
<contexts>
<context position="6099" citStr="Turney (2002)" startWordPosition="952" endWordPosition="954">res in document classification according to semantic orientation. Pang et al. (2002) used bigrams. Matsumoto et al. (2005) used sequential patterns and tree patterns. Although such patterns were proved to be effective in document classification, the semantic orientations of the patterns themselves are not considered. Suzuki et al. (2006) used the ExpectationMaximization algorithm and the naive bayes classifier to incorporate the unlabeled data in the classification of 3-term evaluative expressions. They focused on the utilization of context information such as neighboring words and emoticons. Turney (2002) applied an internet-based technique to the semantic orientation classification of phrases, which had originally been developed for word sentiment classification. In their method, the number of hits returned by a search-engine, with a query consisting of a phrase and a seed word (e.g., “phrase NEAR good”) is used to determine the orientation. Baron and Hirst (2004) extracted collocations with Xtract (Smadja, 1993) and classified the collocations using the orientations of the words in the neighboring sentences. Their method is similar to Turney’s in the sense that cooccurrence with seed words i</context>
<context position="23462" citStr="Turney, 2002" startWordPosition="3898" endWordPosition="3899">23 2798 7581 identified. To tackle these examples, we will need methods for correctly identifying attributes and objects. Some researchers are starting to work on this problem (e.g., Popescu and Etzioni (2005)). We succeeded in addressing the data-sparseness problem by introducing a latent variable. However, this problem still causes some errors. Precise statistics cannot be obtained for infrequent words. This problem will be solved by incorporating other resources such as thesaurus or a dictionary, or combining our method with other methods using external wider contexts (Suzuki et al., 2006; Turney, 2002; Baron and Hirst, 2004). 4.3 Examples of Obtained Clusters Next, we qualitatively evaluate the proposed methods. For several clusters z, we extract the words that occur more than twice in the whole dataset and are in top 50 according to P(zln). The model used here as an example is the U-shaped model. The experimental settings are Q = 0.6 and M = 60. Although some elements of clusters are composed of multiple words in English, the original Japanese counterparts are single words. Cluster 1 trouble, objection, disease, complaint, anxiety, anamnesis, relapse Cluster 2 risk, mortality, infection r</context>
</contexts>
<marker>Turney, 2002</marker>
<rawString>Peter D. Turney. 2002. Thumbs up or thumbs down? semantic orientation applied to unsupervised classification of reviews. In Proceedings 40th Annual Meeting of the Association for Computational Linguistics (ACL’02), pages 417–424.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Wilson</author>
<author>Janyce Wiebe</author>
<author>Paul Hoffmann</author>
</authors>
<title>Recognizing contextual polarity in phraselevel sentiment analysis.</title>
<date>2005</date>
<booktitle>In Proceedings of joint conference on Human Language Technology / Conference on Empirical Methods in Natural Language Processing (HLT/EMNLP’05),</booktitle>
<pages>347--354</pages>
<contexts>
<context position="7240" citStr="Wilson et al. (2005)" startWordPosition="1128" endWordPosition="1131"> method is similar to Turney’s in the sense that cooccurrence with seed words is used. The three methods above are based on context information. In contrast, our method exploits the internal structure of the semantic orientations of phrases. Inui (2004) introduced an attribute plus/minus for each word and proposed several rules that determine the semantic orientations of phrases on the basis of the plus/minus attribute values and the positive/negative attribute values of the component words. For example, a rule [negative+minus=positive] determines “low (minus) risk (negative)” to be positive. Wilson et al. (2005) worked on phrase-level semantic orientations. They introduced a polarity shifter, which is almost equivalent to the plus/minus attribute above. They manually created the list of polarity shifters. The method that we propose in this paper is an automatic version of Inui’s or Wilson et al.’s idea, in the sense that the method automatically creates word clusters and their polarity shifters. 3 Latent Variable Models for Semantic Orientations of Phrases As mentioned in the Introduction, the semantic orientation of a phrase is not a mere sum of its component words. If we know that “low risk” is pos</context>
</contexts>
<marker>Wilson, Wiebe, Hoffmann, 2005</marker>
<rawString>Theresa Wilson, Janyce Wiebe, and Paul Hoffmann. 2005. Recognizing contextual polarity in phraselevel sentiment analysis. In Proceedings of joint conference on Human Language Technology / Conference on Empirical Methods in Natural Language Processing (HLT/EMNLP’05), pages 347–354.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>