<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002468">
<title confidence="0.991802">
Guiding a Constraint Dependency Parser with Supertags
</title>
<author confidence="0.998079">
Kilian Foth, Tomas By, and Wolfgang Menzel
</author>
<affiliation confidence="0.967216">
Department f¨ur Informatik, Universit¨at Hamburg, Germany
</affiliation>
<email confidence="0.975792">
foth|by|menzel@informatik.uni-hamburg.de
</email>
<sectionHeader confidence="0.99335" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999715571428571">
We investigate the utility of supertag infor-
mation for guiding an existing dependency
parser of German. Using weighted con-
straints to integrate the additionally avail-
able information, the decision process of
the parser is influenced by changing its
preferences, without excluding alternative
structural interpretations from being con-
sidered. The paper reports on a series of
experiments using varying models of su-
pertags that significantly increase the pars-
ing accuracy. In addition, an upper bound
on the accuracy that can be achieved with
perfect supertags is estimated.
</bodyText>
<sectionHeader confidence="0.998988" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999957629032258">
Supertagging is based on the combination of two
powerful and influential ideas of natural language
processing: On the one hand, parsing is (at least
partially) reduced to a decision on the optimal se-
quence of categories, a problem for which efficient
and easily trainable procedures exist. On the other
hand, supertagging exploits complex categories,
i.e. tree fragments which much better reflect the
mutual compatibility between neighbouring lexi-
cal items than say part-of-speech tags.
Bangalore and Joshi (1999) derived the notion
of supertag within the framework of Lexicalized
Tree-Adjoining Grammars (LTAG) (Schabes and
Joshi, 1991). They considered supertagging a pro-
cess of almost parsing, since all that needs to be
done after having a sufficiently reliable sequence
of supertags available is to decide on their combi-
nation into a spanning tree for the complete sen-
tence. Thus the approach lends itself easily to pre-
processing sentences or filtering parsing results
with the goal of guiding the parser or reducing its
output ambiguity.
Nasr and Rambow (2004) estimated that perfect
supertag information already provides for a pars-
ing accuracy of 98% if a correct supertag assign-
ment were available. Unfortunately, perfectly re-
liable supertag information cannot be expected;
usually this uncertainty is compensated by run-
ning the tagger in multi-tagging mode, expecting
that the reliability can be increased by not forcing
the tagger to take unreliable decisions but instead
offering a set of alternatives from which a subse-
quent processing component can choose.
A grammar formalism which seems particularly
well suited to decompose structural descriptions
into lexicalized tree fragments is dependency
grammar. It allows us to define supertags on differ-
ent levels of granularity (White, 2000; Wang and
Harper, 2002), thus facilitating a fine grained anal-
ysis of how the different aspects of supertag in-
formation influence the parsing behaviour. In the
following we will use this characteristic to study
in more detail the utility of different kinds of su-
pertag information for guiding the parsing process.
Usually supertags are combined with a parser in
a filtering mode, i.e. parsing hypotheses which
are not compatible with the supertag predic-
tions are simply discarded. Drawing on the abil-
ity of Weighted Constraint Dependency Grammar
(WCDG) (Schr¨oder et al., 2000) to deal with de-
feasible constraints, here we try another option for
making available supertag information: Using a
score to estimate the general reliability of unique
supertag decisions, the information can be com-
bined with evidence derived from other constraints
of the grammar in a soft manner. It makes possi-
ble to rank parsing hypotheses according to their
plausibility and allows the parser to even override
potentially wrong supertag decisions.
Starting from a range of possible supertag mod-
els, Section 2 explores the reliability with which
dependency-based supertags can be determined on
</bodyText>
<page confidence="0.977422">
289
</page>
<note confidence="0.969633">
Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 289–296,
Sydney, July 2006. c�2006 Association for Computational Linguistics
</note>
<figureCaption confidence="0.999767">
Figure 1: Dependency tree for sentence 19601 of the NEGRA corpus.
</figureCaption>
<figure confidence="0.993356428571429">
EXPL
PP
AUX
DET
DET
PN
S
SUBJC
KONJ
OBJA
SUBJ
ATTR
DET
ATTR
</figure>
<bodyText confidence="0.950976">
es mag sein , daß die Franzosen kein schlüssiges Konzept für eine echte Partnerschaft besitzen .
different levels of granularity. Then, Section 3 de-
scribes how supertags are integrated into the exist-
ing parser for German. The complex nature of su-
pertags as we define them makes it possible to sep-
arate the different structural predictions made by a
single supertag into components and study their
contributions independently (c.f. Section 4). We
can show that indeed the parser is robust enough to
tolerate supertag errors and that even with a fairly
low tagger performance it can profit from the ad-
ditional, though unreliable information.
</bodyText>
<sectionHeader confidence="0.87317" genericHeader="method">
2 Supertagging German text
</sectionHeader>
<bodyText confidence="0.999988272727273">
In defining the nature of supertags for depen-
dency parsing, a trade-off has to be made between
expressiveness and accuracy. A simple definition
with very small number of supertags will not be
able to capture the full variety of syntactic con-
texts that actually occur, while an overly expres-
sive definition may lead to a tag set that is so large
that it cannot be accurately learnt from the train-
ing data. The local context of a word to be en-
coded in a supertag could include its edge label,
the attachment direction, the occurrence of obliga-
tory1 or of all dependents, whether each predicted
dependent occurs to the right or to the left of the
word, and the relative order among different de-
pendents. The simplest useful task that could be
asked of a supertagger would be to predict the de-
pendency relation that each word enters. In terms
of the WCDG formalism, this means associating
each word at least with one of the syntactic labels
that decorate dependency edges, such as SUBJ or
DET; in other words, the supertag set would be
identical to the label set. The example sentence
</bodyText>
<footnote confidence="0.713440636363636">
1The model of German used here considers the objects
of verbs, prepositions and conjunctions to be obligatory and
most other relations as optional. This corresponds closely to
the set of needs roles of (Wang and Harper, 2002).
“Es mag sein, daß die Franzosen kein schl¨ussiges Konzept
f¨ur eine echte Partnerschaft besitzen.”
(Perhaps the French do not have a viable concept for a true
partnership.)
if analyzed as in Figure 1, would then be de-
scribed by a supertag sequence beginning with
EXPL S AUX ...
</footnote>
<bodyText confidence="0.9932005">
Following (Wang and Harper, 2002), we further
classify dependencies into Left (L), Right (R), and
No attachments (N), depending on whether a word
is attached to its left or right, or not at all. We
combine the label with the attachment direction
to obtain composite supertags. The sequence of
supertags describing the example sentence would
then begin with EXPL/R S/N AUX/L ...
Although this kind of supertag describes the role
of each word in a sentence, it still does not spec-
ify the entire local context; for instance, it asso-
ciates the information that a word functions as a
subject only with the subject and not with the verb
that takes the subject. In other words, it does not
predict the relations under a given word. Greater
expressivity is reached by also encoding the la-
bels of these relations into the supertag. For in-
stance, the word ‘mag’ in the example sentence
is modified by an expletive (EXPL) on its left
side and by an auxiliary (AUX) and a subject
clause (SUBJC) dependency on its right side. To
capture this extended local context, these labels
must be encoded into the supertag. We add the
local context of a word to the end of its su-
pertag, separated with the delimiter +. This yields
the expression S/N+AUX,EXPL,SUBJC. If we
also want to express that the EXPL precedes the
word but the AUX follows it, we can instead
add two new fields to the left and to the right
of the supertag, which leads to the new supertag
EXPL+S/N+AUX,SUBJC.
Table 1 shows the annotation of the example us-
</bodyText>
<page confidence="0.988448">
290
</page>
<figure confidence="0.951125176470588">
Word Supertag model J
+EXPL/R+
EXPL+S/N+AUX,SUBJC
+AUX/L+
+/N+
+KONJ/R+
+DET/R+
DET+SUBJ/R+
+DET/R+
+ATTR/R+
ATTR,DET+OBJA/R+PP
+PP/L+PN
+DET/R+
+ATTR/R+
ATTR,DET+PN/L+
KONJ,OBJA,SUBJ+SUBJC/L+
+/N+
</figure>
<tableCaption confidence="0.999227">
Table 1: An annotation of the example sentence
</tableCaption>
<table confidence="0.972494846153846">
ST Prediction of #tags Super- Com-
mo- label direc- depen- order tag ponent
del tion dents accuracy accuracy
A yes no none no 35 84.1% 84.1%
B yes yes none no 73 78.9% 85.7%
C yes no oblig. no 914 81.1% 88.5%
D yes yes oblig. no 1336 76.9% 90.8%
E yes no oblig. yes 1465 80.6% 91.8%
F yes yes oblig. yes 2026 76.2% 90.9%
G yes no all no 6858 71.8% 81.3%
H yes yes all no 8684 67.9% 85.8%
I yes no all yes 10762 71.6% 84.3%
J yes yes all yes 12947 67.6% 84.5%
</table>
<tableCaption confidence="0.999011">
Table 2: Definition of all supertag models used.
</tableCaption>
<bodyText confidence="0.999505754716981">
ing the most sophisticated supertag model. Note
that the notation +EXPL/R+ explicitly represents
the fact that the word labelled EXPL has no de-
pendents of its own, while the simpler EXPL/R
made no assertion of this kind. The extended con-
text specification with two + delimiters expresses
the complete set of dependents of a word and
whether they occur to its left or right. However, it
does not distinguish the order of the left or right
dependents among each other (we order the la-
bels on either side alphabetically for consistency).
Also, duplicate labels among the dependents on ei-
ther side are not represented. For instance, a verb
with two post-modifying prepositions would still
list PP only once in its right context. This ensures
that the set of possible supertags is finite. The full
set of different supertag models we used is given
in Table 2. Note that the more complicated mod-
els G, H, I and J predict all dependents of each
word, while the others predict obligatory depen-
dents only, which should be an easier task.
To obtain and evaluate supertag predictions, we
used the NEGRA and TIGER corpora (Brants et
al., 1997; Brants et al., 2002), automatically trans-
formed into dependency format with the freely
available tool DepSy (Daum et al., 2004). As
our test set we used sentences 18,602–19,601 of
the NEGRA corpus, for comparability to earlier
work. All other sentences (59,622 sentences with
1,032,091 words) were used as the training set. For
each word in the training set, the local context was
extracted and expressed in our supertag notation.
The word/supertag pairs were then used to train
the statistical part-of-speech tagger TnT (Brants,
2000), which performs trigram tagging efficiently
and allows easy retraining on different data. How-
ever, a few of TnT’s limitations had to be worked
around: since it cannot deal with words that have
more than 510 different possible tags, we system-
atically replaced the rarest tags in the training set
with a generic ‘OTHER’ tag until the limit was
met. Also, in tagging mode it can fail to process
sentences with many unknown words in close suc-
cession. In such cases, we simply ran it on shorter
fragments of the sentence until no error occurred.
Fewer than 0.5% of all sentences were affected by
this problem even with the largest tag set.
A more serious problem arises when using a
stochastic process to assign tags that partially pre-
dict structure: the tags emitted by the model may
contradict each other. Consider, for instance, the
following supertagger output for the previous ex-
ample sentence:
</bodyText>
<listItem confidence="0.723552">
es: +EXPL/R+ mag: +S/N+AUX,SUBJC
sein: PRED+AUX/L+ ...
</listItem>
<bodyText confidence="0.99998745">
The supertagger correctly predicts that the first
three labels are EXPL, S, and AUX. It also pre-
dicts that the word ‘sein’ has a preceding PRED
complement, but this is impossible if the two pre-
ceding words are labelled EXPL and S. Such con-
tradictory information is not fatal in a robust sys-
tem, but it is likely to cause unnecessary work
for the parser when some rules demand the im-
possible. We therefore decided simply to ignore
context predictions when they contradict the ba-
sic label predictions made for the same sentence;
in other words, we pretend that the prediction
for the third word was just +AUX/L+ rather than
PRED+AUX/L+. Up to 13% of all predictions
were simplified in this way for the most complex
supertag model.
The last columns of Table 2 give the number of
different supertags in the training set and the per-
formance of the retrained TnT on the test set in
single-tagging mode. Although the number of oc-
</bodyText>
<figure confidence="0.924647625">
es
mag
sein
,
daß
die
Franzosen
kein
schl¨ussiges
Konzept
f¨ur
eine
echte
Partnerschaft
besitzen
.
</figure>
<page confidence="0.990437">
291
</page>
<bodyText confidence="0.999984553571429">
curring tags rises and the prediction accuracy falls
with the supertag complexity, the correlation is not
absolute: It seems markedly easier to predict su-
pertags with complements but no direction infor-
mation (C) than supertags with direction informa-
tion but no complements (B), although the tag set
is larger by an order of magnitude. In fact, the pre-
diction of attachment direction seems much more
difficult than that of undirected supertags in every
case, due to the semi-free word order of German.
The greater tag set size when predicting comple-
ments of each words is at least partly offset by
the contextual information available to the n-gram
model, since it is much more likely that a word
will have, e.g., a ‘SUBJ’ complement when an ad-
jacent ‘SUBJ’ supertag is present.
For the simplest model A, all 35 possible su-
pertags actually occur, while in the most compli-
cated model J, only 12,947 different supertags are
observed in the training data (out of a theoretically
possible 1024 for a set of 35 edge labels). Note that
this is still considerably larger than most other re-
ported supertag sets. The prediction quality falls to
rather low values with the more complicated mod-
els; however, our goal in this paper is not to opti-
mize the supertagger, but to estimate the effect that
an imperfect one has on an existing parser. Alto-
gether most results fall into a range of 70–80% of
accuracy; as we will see later, this is in fact enough
to provide a benefit to automatic parsing.
Although supertag accuracy is usually deter-
mined by simply counting matching and non-
matching predictions, a more accurate measure
should take into account how many of the indi-
vidual predictions that are combined into a su-
pertag are correct or wrong. For instance, a word
that is attached to its left as a subject, is pre-
ceded by a preposition and an attributive adjec-
tive, and followed by an apposition would bear
the supertag PP,ATTR+SUBJ/L+APP. Since the
prepositional attachment is notoriously difficult to
predict, a supertagger might miss it and emit the
slightly different tag ATTR+SUBJ/L+APP. Al-
though this supertag is technically wrong, it is in
fact much more right than wrong: of the four pre-
dictions of label, direction, preceding and follow-
ing dependents, three are correct and only one is
wrong. We therefore define the component accu-
racy for a given model as the ratio of correct pre-
dictions among the possible ones, which results
in a value of 0.75 rather than 0 for the exam-
ple prediction. The component accuracy of the su-
pertag model J e. g. is in fact 84.5% rather than
67.6%. We would expect the component accuracy
to match the effect on parsing more closely than
the supertag accuracy.
</bodyText>
<sectionHeader confidence="0.724402" genericHeader="method">
3 Using supertag information in WCDG
</sectionHeader>
<bodyText confidence="0.977723285714286">
Weighted Constraint Dependency Grammar
(WCDG) is a formalism in which declarative
constraints can be formulated that describe
well-formed dependency trees in a particular
natural language. A grammar composed of such
constraints can be used for parsing by feeding it
to a constraint-solving component that searches
for structures that satisfy the constraints.
Each constraint carries a numeric score or penalty
between 0 and 1 that indicates its importance. The
penalties of all instances of constraint violations
are multiplied to yield a score for an entire anal-
ysis; hence, an analysis that satisfies all rules of
the WCDG bears the score 1, while lower values
indicate small or large aberrations from the lan-
guage norm. A constraint penalty of 0, then, cor-
responds to a hard constraint, since every analysis
that violates such a constraint will always bear the
worst possible score of 0. This means that of two
constraints, the one with the lower penalty is more
important to the grammar.
Since constraints can be soft as well as hard, pars-
ing in the WCDG formalism amounts to multi-
dimensional optimization. Of two possible analy-
ses of an utterance, the one that satisfies more (or
more important) constraints is always preferred.
All knowledge about grammatical rules is encoded
in the constraints that (together with the lexicon)
constitute the grammar. Adding a constraint which
is sensitive to supertag predictions will therefore
change the objective function of the optimiza-
tion problem, hopefully leading to a higher share
of correct attachments. Details about the WDCG
parser can be found in (Foth and Menzel, 2006).
A grammar of German is available (Foth et al.,
2004) that achieves a good accuracy on written
German input. Despite its good results, it seems
probable that the information provided by a su-
pertag prediction component could improve the
accuracy further. First, because the optimization
problem that WCDG defines is infeasible to solve
exactly, the parser must usually use incomplete,
</bodyText>
<page confidence="0.984878">
292
</page>
<bodyText confidence="0.999907133333333">
heuristic algorithms to try to compute the opti-
mal analysis. This means that it sometimes fails
to find the correct analysis even if the language
model accurately defines it, because of search er-
rors during heuristic optimization. A component
that makes specific predictions about local struc-
ture could guide the process so that the correct
alternative is tried first in more cases, and help
prevent such search errors. Second, the existing
grammar rules deal mainly with structural compat-
ibility, while supertagging exploits patterns in the
sequence of words in its input, i. e. both models
contribute complementary information. Moreover,
the parser can be expected to profit from supertags
providing highly lexicalized pieces of information.
</bodyText>
<table confidence="0.999554230769231">
Model Supertag Component Parsing accuracy
accuracy accuracy unlabelled labelled
baseline – – 89.6% 87.9%
A 84.1% 84.1% 90.8% 89.4%
B 78.9% 85.7% 90.6% 89.2%
C 81.1% 88.5% 91.0% 89.6%
D 76.9% 90.8% 91.1% 89.8%
E 80.6% 91.8% 90.9% 89.6%
F 76.2% 90.9% 91.4% 90.0%
G 71.8% 81.3% 90.8% 89.4%
H 67.9% 85.8% 90.8% 89.4%
I 71.6% 84.3% 91.8% 90.4%
J 67.6% 84.5% 91.8% 90.5%
</table>
<tableCaption confidence="0.9962775">
Table 3: Influence of supertag integration on pars-
ing accuracy.
</tableCaption>
<table confidence="0.999384181818182">
Constraint penalty Parsing accuracy
unlabelled labelled
0.0 3.7% 3.7%
0.05 85.2% 83.5%
0.1 87.6% 85.7%
0.2 88.9% 87.3%
0.5 91.2% 89.5%
0.7 91.5% 90.1%
0.9 91.8% 90.5%
0.95 91.1% 89.8%
1.0 89.6% 87.9%
</table>
<tableCaption confidence="0.931045">
Table 4: Parsing accuracy depending on different
strength of supertag integration.
</tableCaption>
<bodyText confidence="0.999967548387097">
To make the information from the supertag se-
quence available to the parser, we treat the com-
plex supertags as a set of predictions and write
constraints to prefer those analyses that satisfy
them. The predictions of label and direction made
by models A and B are mapped onto two con-
straints which demand that each word in the anal-
ysis should exhibit the predicted label and direc-
tion. The more complicated supertag models con-
strain the local context of each word further. Effec-
tively, they predict that the specified dependents of
a word occur, and that no other dependents occur.
The former prediction equates to an existence con-
dition, so constraints are added which demand the
presence of the predicted relation types under that
word (one for left dependents and one for right de-
pendents). The latter prediction disallows all other
dependents; it is implemented by two constraints
that test the edge label of each word-to-word at-
tachment against the set of predicted dependents
of the regent (again, separately for left and right
dependents). Altogether six new constraints are
added to the grammar which refer to the output
of the supertagger on the current sentence.
Note that in contrast to most other approaches we
do not perform multi-supertagging; exactly one
supertag is assumed for each word. Alternatives
could be integrated by computing the logical dis-
junctions of the predictions made by each su-
pertag, and then adapting the new constraints ac-
cordingly.
</bodyText>
<sectionHeader confidence="0.999585" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999993107142857">
We tested the effect of supertag predictions on
a full parser by adding the new constraints to
the WCDG of German described in (Foth et al.,
2004) and re-parsing the same 1,000 sentences
from the NEGRA corpus. The quality of a de-
pendency parser such as this can be measured as
the ratio of correctly attached words to all words
(structural accuracy) or the ratio of the correctly
attached and correctly labelled words to all words
(labelled accuracy). Note that because the parser
always finds exactly one analysis with exactly one
subordination per word, there is no distinction be-
tween recall and precision. The structural accuracy
without any supertags is 89.6%.
To determine the best trade-off between complex-
ity and prediction quality, we tested all 10 supertag
models against the baseline case of no supertags at
all. The results are given in Table 3. Two observa-
tions can be made about the effect of the supertag
model on parsing. Firstly, all types of supertag pre-
diction, even the very basic model A which pre-
dicts only edge labels, improve the overall accu-
racy of parsing, although the baseline is already
quite high. Second, the richer models of supertags
appear to be more suitable for guiding the parser
than the simpler ones, even though their own ac-
curacy is markedly lower; almost one third of the
supertag predictions according to the most compli-
</bodyText>
<page confidence="0.996497">
293
</page>
<bodyText confidence="0.99992634">
cated definition J are wrong, but nevertheless their
inclusion reduces the remaining error rate of the
parser by over 20%.
This result confirms the assumption that if su-
pertags are integrated as individual constraints,
their component accuracy is more important than
the supertag accuracy. The decreasing accuracy of
more complex supertags is more than counterbal-
anced by the additional information that they con-
tribute to the analysis. Obviously, this trend can-
not continue indefinitely; a supertag definition that
predicted even larger parts of the dependency tree
would certainly lead to much lower accuracy by
even the most lenient measure, and a prediction
that is mostly wrong must ultimately degrade pars-
ing performance. Since the most complex model J
shows no parsing improvement over its succes-
sor I, this point might already have been reached.
The use of supertags in WCDG is comparable
to previous work which integrated POS tagging
and chunk parsing. (Foth and Hagenstr¨om, 2002;
Daum et al., 2003) showed that the correct bal-
ance between the new knowledge and the exist-
ing grammar is crucial for successful integration.
This is achieved by means of an additional pa-
rameter, modeling how trustworthy supertag pre-
dictions are considered. Its effect is shown in Ta-
ble 4. As expected, making supertag constraints
hard (with a value of 0.0) over-constrains most
parsing problems, so that hardly any analyses can
be computed. Other values near 0 avoid this prob-
lem but still lead to much worse overall perfor-
mance, as wrong or even impossible predictions
too often overrule the normal syntax constraints.
The previously used value of 0.9 actually yields
the best results with this particular grammar.
The fact that a statistical model can improve pars-
ing performance when superimposed on a sophis-
ticated hand-written grammar is of particular in-
terest because the statistical model we used is so
simple, and in fact not particularly accurate; it
certainly does not represent the state of the art
in supertagging. This gives rise to the hope that
as better supertaggers for German become avail-
able, parsing results will continue to see additional
improvements, i.e., future supertagging research
will directly benefit parsing. The obvious ques-
tion is how great this benefit might conceivably
become under optimal conditions. To obtain this
upper limit of the utility of supertags we repeated
</bodyText>
<table confidence="0.999466">
Supertag 0.9 Constraint penalty
model 0.0
A 92.7% / 92.2% 94.0% / 94.0%
B 94.3% / 93.7% 96.0% / 96.0%
C 92.8% / 92.4% 94.1% / 94.1%
D 94.3% / 93.8% 96.0% / 96.0%
E 93.1% / 92.6% 94.3% / 94.3%
F 94.6% / 94.1% 96.1% / 96.1%
G 94.2% / 93.7% 95.8% / 95.8%
H 95.2% / 94.7% 97.4% / 97.4%
I 97.1% / 96.8% 99.5% / 99.5%
J 97.1% / 96.8% 99.6% / 99.6%
</table>
<tableCaption confidence="0.954426">
Table 5: Unlabelled and labelled parsing accuracy
with a simulated perfect supertagger.
</tableCaption>
<bodyText confidence="0.997195315789474">
the process of translating each supertag into addi-
tional WCDG constraints, but this time using the
test set itself rather than TnT’s predictions.
Table 5 again gives the unlabelled and labelled
parsing accuracy for all 10 different supertag mod-
els with the integration strengths of 0 and 0.9.
(Note that since all our models predict the edge
label of each word, hard integration of perfect
predictions eliminates the difference between la-
belled und unlabelled accuracy.) As expected, an
improved accuracy of supertagging would lead
to improved parsing accuracy in each case. In
fact, knowing the correct supertag would solve the
parsing problem almost completely with the more
complex models. This confirms earlier findings for
English (Nasr and Rambow, 2004).
Since perfect supertaggers are not available, we
have to make do with the imperfect ones that do
exist. One method of avoiding some errors intro-
duced by supertagging would be to reject supertag
predictions that tend to be wrong. To this end, we
ran the supertagger on its training set and deter-
mined the average component accuracy of each
occurring supertag. The supertags whose average
precision fell below a variable threshold were not
considered during parsing as if the supertagger had
not made a prediction. This means that a threshold
of 100% corresponds to the baseline of not using
supertags at all, while a threshold of 0% prunes
nothing, so that these two cases duplicate the first
and last line from Table 2.
As Table 6 shows, pruning supertags that are
wrong more often than they are right results in
a further small improvement in parsing accu-
racy: unlabelled syntax accuracy rises up to 92.1%
against the 91.8% if all supertags of model J are
used. However, the effect is not very noticeable,
so that it would be almost certainly more useful to
</bodyText>
<page confidence="0.996078">
294
</page>
<table confidence="0.981664555555556">
Parsing accuracy
Threshold unlabelled labelled
0% 91.8% 90.5%
20% 91.8% 90.4%
40% 91.9% 90.5%
50% 92.0% 90.7%
60% 92.1% 91.0%
80% 91.4% 90.0%
100% 89.6% 87.9%
</table>
<tableCaption confidence="0.961937">
Table 6: Parsing accuracy with empirically pruned
supertag predictions.
</tableCaption>
<bodyText confidence="0.5589365">
improve the supertagger itself rather than second-
guess its output.
</bodyText>
<sectionHeader confidence="0.999894" genericHeader="method">
5 Related work
</sectionHeader>
<bodyText confidence="0.999944927536232">
Supertagging was originally suggested as a
method to reduce lexical ambiguity, and thereby
the amount of disambiguation work done by the
parser. Sakar et al. (2000) report that this increases
the speed of their LTAG parser by a factor of 26
(from 548k to 21k seconds) but at the price of only
being able to parse 59% of the sentences in their
test data (of 2250 sentences), because too often the
correct supertag is missing from the output of the
supertagger. Chen et al. (2002) investigate differ-
ent supertagging methods as pre-processors to a
Tree-Adjoining Grammar parser, and they claim a
1-best supertagging accuracy of 81.47%, and a 4-
best accuracy of 91.41%. With the latter they reach
the highest parser coverage, about three quarters of
the 1700 sentences in their test data.
Clark and Curran (2004a; 2004b) describe a com-
bination of supertagger and parser for parsing
Combinatory Categorial Grammar, where the tag-
ger is used to filter the parses produced by the
grammar, before the computation of the model pa-
rameters. The parser uses an incremental method:
the supertagger first assigns a small number of cat-
egories to each word, and the parser requests more
alternatives only if the analysis fails. They report
91.4% precision and 91.0% recall of unlabelled
dependencies and a speed of 1.6 minutes to parse
2401 sentences, and claim a parser speedup of a
factor of 77 thanks to supertagging.
The supertagging approach that is closest to ours
in terms of linguistic representations is probably
(Wang and Harper, 2002; Wang and Harper, 2004)
whose ‘Super Abstract Role Values’ are very sim-
ilar to our model F supertags (Table 2). It is in-
teresting to note that they only report between 328
and 791 SuperARVs for different corpora, whereas
we have 2026 category F supertags. Part of the dif-
ference is explained by our larger label set: 35,
the same as the number of model A supertags
in table 2 against their 24 (White, 2000, p. 50).
Also, we are not using the same corpus. In ad-
dition to determining the optimal SuperARV se-
quence in isolation, Wang and Harper (2002) also
combine the SuperARV n-gram probabilities with
a dependency assignment probability into a depen-
dency parser for English. A maximum tagging ac-
curacy of 96.3% (for sentences up to 100 words) is
achieved using a 4-gram n-best tagger producing
the 100 best SuperARV sequences for a sentence.
The tightly integrated model is able to determine
96.6% of SuperARVs correctly. The parser itself
reaches a labelled precision of 92.6% and a la-
belled recall of 92.2% (Wang and Harper, 2004).
In general, the effect of supertagging in the other
systems mentioned here is to reduce the ambi-
guity in the input to the parser and thereby in-
crease its speed, in some cases dramatically. For
us, supertagging decreases the speed slightly, be-
cause additional constraints means more work for
the parser, and because our supertagger-parser in-
tegration is not yet optimal. On the other hand
it gives us better parsing accuracy. Using a con-
straint penalty of 0.0 for the supertagger integra-
tion (c.f. Table 5) does speed up our parser several
times, but would only be practical with very high
tagging accuracy. An important point is that for
some other systems, like (Sarkar et al., 2000) and
(Chen et al., 2002), parsing is not actually feasible
without the supertagging speedup.
</bodyText>
<sectionHeader confidence="0.996456" genericHeader="conclusions">
6 Conclusions and future work
</sectionHeader>
<bodyText confidence="0.999954">
We have shown that a statistical supertagging
component can significantly improve the parsing
accuracy of a general-purpose dependency parser
for German. The error rate among syntactic at-
tachments can be reduced by 24% over an al-
ready competitive baseline. After all, the integra-
tion of the supertagging results helped to reach a
quality level which compares favourably with the
state-of-the-art in probabilistic dependency pars-
ing for German as defined with 87.34%/90.38%
labelled/unlabelled attachment accuracy on this
years shared CoNLL task by (McDonald et al.,
2005) (see (Foth and Menzel, 2006) for a more de-
tailed comparison). Although the statistical model
used in our system is rather simple-minded, it
clearly captures at least some distributional char-
</bodyText>
<page confidence="0.993382">
295
</page>
<bodyText confidence="0.998115136363636">
acteristics of German text that the hand-written
rules do not.
A crucial factor for success is the defeasible in-
tegration of the supertagging predictions via soft
constraints. Rather than pursuing a strict filtering
approach where supertagging errors are partially
compensated by an n-best selection, we commit to
only one supertag per word, but reduce its influ-
ence. Treating supertag predictions as weak pref-
erences yields the best results. By measuring the
accuracy of the different types of predictions made
by complex supertags, different weights could also
be assigned to the six new constraints.
Of the investigated supertag models, the most
complex ones guide the parser best, although
their own accuracy is not the best one, even
when measured by the more pertinent component
accuracy. Since purely statistical parsing methods
do not reach comparable parsing accuracy on
the same data, we assume that this trend does
not continue indefinitely, but would stop at some
point, perhaps already reached.
</bodyText>
<sectionHeader confidence="0.999115" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999962975">
S. Bangalore and A. K. Joshi. 1999. Supertagging: an
approach to almost parsing. Computational Linguis-
tics, 25(2):237–265.
T. Brants, R. Hendriks, S. Kramp, B. Krenn, C. Preis,
W. Skut, and H. Uszkoreit. 1997. Das NEGRA-
Annotationsschema. Technical report, Universit¨at des
Saarlandes, Computerlinguistik.
S. Brants, St. Dipper, S. Hansen, W. Lezius, and
G. Smith. 2002. The TIGER treebank. In Proc. Work-
shop on Treebanks and Linguistic Theories, Sozopol.
T. Brants. 2000. TnT – A statistical part-of-speech
tagger. In Proc. the 6th Conf. on Applied Natural Lan-
guage Processing, ANLP-2000, pages 224–231, Seat-
tle, WA.
J. Chen, S. Bangalore, M. Collins, and O. Rambow.
2002. Reranking an N-gram supertagger. In Proc. 6th
Int. Workshop on Tree Adjoining Grammar and Related
Frameworks.
S. Clark and J. R. Curran. 2004a. The importance of
supertagging for wide-coverage CCG parsing. In Proc.
20th Int. Conf. on Computational Linguistics.
S. Clark and J. R. Curran. 2004b. Parsing the WSJ us-
ing CCG and log-linear models. In Proc. 42nd Meeting
of the ACL.
M. Daum, K. Foth, and W. Menzel. 2003. Constraint
based integration of deep and shallow parsing tech-
niques. In Proc. 11th Conf. of the EACL, Budapest,
Hungary.
M. Daum, K. Foth, and W. Menzel. 2004. Au-
tomatic transformation of phrase treebanks to depen-
dency trees. In Proc. 4th Int. Conf. on Language Re-
sources and Evaluation, LREC-2004, pages 99–106,
Lisbon, Portugal.
K. Foth and J. Hagenstr¨om. 2002. Tagging for robust
parsers. In 2nd Workshop on Robust Methods in Anal-
ysis ofNatural Language Data, ROMAND-2002, pages
21 – 32, Frascati, Italy.
K. Foth and W. Menzel. 2006. Hybrid parsing: Us-
ing probabilistic models as predictors for a symbolic
parser. In Proc. 21st Int. Conf. on Computational Lin-
guistics, Coling-ACL-2006, Sydney.
K. Foth, M. Daum, and W. Menzel. 2004. A broad-
coverage parser for german based on defeasible con-
straints. In 7. Konferenz zur Verarbeitung nat¨urlicher
Sprache, KONVENS-2004, pages 45–52, Wien.
R. McDonald, F. Pereira, K. Ribarov, and J. Hajic.
2005. Non-projective dependency parsing using span-
ning tree algorithms. In Proc. Human Language
Technology Conference, HLT/EMNLP-2005, Vancou-
ver, B.C.
A. Nasr and O. Rambow. 2004. A simple string-
rewriting formalism for dependency grammar. In
Coling-Workshop Recent Advances in Dependency
Grammar, pages 17–24, Geneva, Switzerland.
A. Sarkar, F. Xia, and A. Joshi. 2000. Some experi-
ments on indicators of parsing complexity for lexical-
ized grammars. In Proc. COLING Workshop on Effi-
ciency in Large-Scale Parsing Systems.
Y. Schabes and A. K. Joshi. 1991. Parsing with lexi-
calized tree adjoining grammar. In M. Tomita, editor,
Current Issues in Parsing Technologies. Kluwer Aca-
demic Publishers.
I. Schr¨oder, W. Menzel, K. Foth, and M. Schulz. 2000.
Modeling dependency grammar with restricted con-
straints. Traitement Automatique des Langues (T.A.L.),
41(1):97–126.
W. Wang and M. P. Harper. 2002. The SuperARV lan-
guage model: Investigating the effectiveness of tightly
integrating multiple knowledge sources. In Proc. Conf.
on Empirical Methods in Natural Language Process-
ing, EMNLP-2002, pages 238–247, Philadelphia, PA.
W. Wang and M. P. Harper. 2004. A statistical
constraint dependency grammar (CDG) parser. In
Proc. ACL Workshop Incremental Parsing: Bringing
Engineering and Cognition Together, pages 42–49,
Barcelona, Spain.
Ch. M. White. 2000. Rapid Grammar Development
and Parsing: Constraint Dependency Grammar with
Abstract Role Values. Ph.D. thesis, Purdue University,
West Lafayette, IN.
</reference>
<page confidence="0.998562">
296
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.672363">
<title confidence="0.999979">Guiding a Constraint Dependency Parser with Supertags</title>
<author confidence="0.996496">Kilian Foth</author>
<author confidence="0.996496">Tomas By</author>
<author confidence="0.996496">Wolfgang Menzel</author>
<affiliation confidence="0.686538">Department f¨ur Informatik, Universit¨at Hamburg, Germany</affiliation>
<abstract confidence="0.998626733333334">We investigate the utility of supertag information for guiding an existing dependency parser of German. Using weighted constraints to integrate the additionally available information, the decision process of the parser is influenced by changing its preferences, without excluding alternative structural interpretations from being considered. The paper reports on a series of experiments using varying models of supertags that significantly increase the parsing accuracy. In addition, an upper bound on the accuracy that can be achieved with perfect supertags is estimated.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Bangalore</author>
<author>A K Joshi</author>
</authors>
<title>Supertagging: an approach to almost parsing.</title>
<date>1999</date>
<journal>Computational Linguistics,</journal>
<volume>25</volume>
<issue>2</issue>
<contexts>
<context position="1306" citStr="Bangalore and Joshi (1999)" startWordPosition="183" endWordPosition="186">ddition, an upper bound on the accuracy that can be achieved with perfect supertags is estimated. 1 Introduction Supertagging is based on the combination of two powerful and influential ideas of natural language processing: On the one hand, parsing is (at least partially) reduced to a decision on the optimal sequence of categories, a problem for which efficient and easily trainable procedures exist. On the other hand, supertagging exploits complex categories, i.e. tree fragments which much better reflect the mutual compatibility between neighbouring lexical items than say part-of-speech tags. Bangalore and Joshi (1999) derived the notion of supertag within the framework of Lexicalized Tree-Adjoining Grammars (LTAG) (Schabes and Joshi, 1991). They considered supertagging a process of almost parsing, since all that needs to be done after having a sufficiently reliable sequence of supertags available is to decide on their combination into a spanning tree for the complete sentence. Thus the approach lends itself easily to preprocessing sentences or filtering parsing results with the goal of guiding the parser or reducing its output ambiguity. Nasr and Rambow (2004) estimated that perfect supertag information al</context>
</contexts>
<marker>Bangalore, Joshi, 1999</marker>
<rawString>S. Bangalore and A. K. Joshi. 1999. Supertagging: an approach to almost parsing. Computational Linguistics, 25(2):237–265.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Brants</author>
<author>R Hendriks</author>
<author>S Kramp</author>
<author>B Krenn</author>
<author>C Preis</author>
<author>W Skut</author>
<author>H Uszkoreit</author>
</authors>
<title>Das NEGRAAnnotationsschema.</title>
<date>1997</date>
<tech>Technical report,</tech>
<institution>Universit¨at des Saarlandes, Computerlinguistik.</institution>
<contexts>
<context position="9736" citStr="Brants et al., 1997" startWordPosition="1597" endWordPosition="1600">cally for consistency). Also, duplicate labels among the dependents on either side are not represented. For instance, a verb with two post-modifying prepositions would still list PP only once in its right context. This ensures that the set of possible supertags is finite. The full set of different supertag models we used is given in Table 2. Note that the more complicated models G, H, I and J predict all dependents of each word, while the others predict obligatory dependents only, which should be an easier task. To obtain and evaluate supertag predictions, we used the NEGRA and TIGER corpora (Brants et al., 1997; Brants et al., 2002), automatically transformed into dependency format with the freely available tool DepSy (Daum et al., 2004). As our test set we used sentences 18,602–19,601 of the NEGRA corpus, for comparability to earlier work. All other sentences (59,622 sentences with 1,032,091 words) were used as the training set. For each word in the training set, the local context was extracted and expressed in our supertag notation. The word/supertag pairs were then used to train the statistical part-of-speech tagger TnT (Brants, 2000), which performs trigram tagging efficiently and allows easy re</context>
</contexts>
<marker>Brants, Hendriks, Kramp, Krenn, Preis, Skut, Uszkoreit, 1997</marker>
<rawString>T. Brants, R. Hendriks, S. Kramp, B. Krenn, C. Preis, W. Skut, and H. Uszkoreit. 1997. Das NEGRAAnnotationsschema. Technical report, Universit¨at des Saarlandes, Computerlinguistik.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Hansen Dipper</author>
<author>W Lezius</author>
<author>G Smith</author>
</authors>
<title>The TIGER treebank.</title>
<date>2002</date>
<booktitle>In Proc. Workshop on Treebanks and Linguistic Theories,</booktitle>
<location>Sozopol.</location>
<marker>Dipper, Lezius, Smith, 2002</marker>
<rawString>S. Brants, St. Dipper, S. Hansen, W. Lezius, and G. Smith. 2002. The TIGER treebank. In Proc. Workshop on Treebanks and Linguistic Theories, Sozopol.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Brants</author>
</authors>
<title>TnT – A statistical part-of-speech tagger.</title>
<date>2000</date>
<booktitle>In Proc. the 6th Conf. on Applied Natural Language Processing, ANLP-2000,</booktitle>
<pages>224--231</pages>
<location>Seattle, WA.</location>
<contexts>
<context position="10273" citStr="Brants, 2000" startWordPosition="1683" endWordPosition="1684">pertag predictions, we used the NEGRA and TIGER corpora (Brants et al., 1997; Brants et al., 2002), automatically transformed into dependency format with the freely available tool DepSy (Daum et al., 2004). As our test set we used sentences 18,602–19,601 of the NEGRA corpus, for comparability to earlier work. All other sentences (59,622 sentences with 1,032,091 words) were used as the training set. For each word in the training set, the local context was extracted and expressed in our supertag notation. The word/supertag pairs were then used to train the statistical part-of-speech tagger TnT (Brants, 2000), which performs trigram tagging efficiently and allows easy retraining on different data. However, a few of TnT’s limitations had to be worked around: since it cannot deal with words that have more than 510 different possible tags, we systematically replaced the rarest tags in the training set with a generic ‘OTHER’ tag until the limit was met. Also, in tagging mode it can fail to process sentences with many unknown words in close succession. In such cases, we simply ran it on shorter fragments of the sentence until no error occurred. Fewer than 0.5% of all sentences were affected by this pro</context>
</contexts>
<marker>Brants, 2000</marker>
<rawString>T. Brants. 2000. TnT – A statistical part-of-speech tagger. In Proc. the 6th Conf. on Applied Natural Language Processing, ANLP-2000, pages 224–231, Seattle, WA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Chen</author>
<author>S Bangalore</author>
<author>M Collins</author>
<author>O Rambow</author>
</authors>
<title>Reranking an N-gram supertagger.</title>
<date>2002</date>
<booktitle>In Proc. 6th Int. Workshop on Tree Adjoining Grammar and Related Frameworks.</booktitle>
<contexts>
<context position="26736" citStr="Chen et al. (2002)" startWordPosition="4429" endWordPosition="4432">ng accuracy with empirically pruned supertag predictions. improve the supertagger itself rather than secondguess its output. 5 Related work Supertagging was originally suggested as a method to reduce lexical ambiguity, and thereby the amount of disambiguation work done by the parser. Sakar et al. (2000) report that this increases the speed of their LTAG parser by a factor of 26 (from 548k to 21k seconds) but at the price of only being able to parse 59% of the sentences in their test data (of 2250 sentences), because too often the correct supertag is missing from the output of the supertagger. Chen et al. (2002) investigate different supertagging methods as pre-processors to a Tree-Adjoining Grammar parser, and they claim a 1-best supertagging accuracy of 81.47%, and a 4- best accuracy of 91.41%. With the latter they reach the highest parser coverage, about three quarters of the 1700 sentences in their test data. Clark and Curran (2004a; 2004b) describe a combination of supertagger and parser for parsing Combinatory Categorial Grammar, where the tagger is used to filter the parses produced by the grammar, before the computation of the model parameters. The parser uses an incremental method: the super</context>
<context position="29529" citStr="Chen et al., 2002" startWordPosition="4901" endWordPosition="4904">e ambiguity in the input to the parser and thereby increase its speed, in some cases dramatically. For us, supertagging decreases the speed slightly, because additional constraints means more work for the parser, and because our supertagger-parser integration is not yet optimal. On the other hand it gives us better parsing accuracy. Using a constraint penalty of 0.0 for the supertagger integration (c.f. Table 5) does speed up our parser several times, but would only be practical with very high tagging accuracy. An important point is that for some other systems, like (Sarkar et al., 2000) and (Chen et al., 2002), parsing is not actually feasible without the supertagging speedup. 6 Conclusions and future work We have shown that a statistical supertagging component can significantly improve the parsing accuracy of a general-purpose dependency parser for German. The error rate among syntactic attachments can be reduced by 24% over an already competitive baseline. After all, the integration of the supertagging results helped to reach a quality level which compares favourably with the state-of-the-art in probabilistic dependency parsing for German as defined with 87.34%/90.38% labelled/unlabelled attachme</context>
</contexts>
<marker>Chen, Bangalore, Collins, Rambow, 2002</marker>
<rawString>J. Chen, S. Bangalore, M. Collins, and O. Rambow. 2002. Reranking an N-gram supertagger. In Proc. 6th Int. Workshop on Tree Adjoining Grammar and Related Frameworks.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Clark</author>
<author>J R Curran</author>
</authors>
<title>The importance of supertagging for wide-coverage CCG parsing.</title>
<date>2004</date>
<booktitle>In Proc. 20th Int. Conf. on Computational Linguistics.</booktitle>
<contexts>
<context position="27066" citStr="Clark and Curran (2004" startWordPosition="4481" endWordPosition="4484">eases the speed of their LTAG parser by a factor of 26 (from 548k to 21k seconds) but at the price of only being able to parse 59% of the sentences in their test data (of 2250 sentences), because too often the correct supertag is missing from the output of the supertagger. Chen et al. (2002) investigate different supertagging methods as pre-processors to a Tree-Adjoining Grammar parser, and they claim a 1-best supertagging accuracy of 81.47%, and a 4- best accuracy of 91.41%. With the latter they reach the highest parser coverage, about three quarters of the 1700 sentences in their test data. Clark and Curran (2004a; 2004b) describe a combination of supertagger and parser for parsing Combinatory Categorial Grammar, where the tagger is used to filter the parses produced by the grammar, before the computation of the model parameters. The parser uses an incremental method: the supertagger first assigns a small number of categories to each word, and the parser requests more alternatives only if the analysis fails. They report 91.4% precision and 91.0% recall of unlabelled dependencies and a speed of 1.6 minutes to parse 2401 sentences, and claim a parser speedup of a factor of 77 thanks to supertagging. The</context>
</contexts>
<marker>Clark, Curran, 2004</marker>
<rawString>S. Clark and J. R. Curran. 2004a. The importance of supertagging for wide-coverage CCG parsing. In Proc. 20th Int. Conf. on Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Clark</author>
<author>J R Curran</author>
</authors>
<title>Parsing the WSJ using CCG and log-linear models.</title>
<date>2004</date>
<booktitle>In Proc. 42nd Meeting of the ACL.</booktitle>
<contexts>
<context position="27066" citStr="Clark and Curran (2004" startWordPosition="4481" endWordPosition="4484">eases the speed of their LTAG parser by a factor of 26 (from 548k to 21k seconds) but at the price of only being able to parse 59% of the sentences in their test data (of 2250 sentences), because too often the correct supertag is missing from the output of the supertagger. Chen et al. (2002) investigate different supertagging methods as pre-processors to a Tree-Adjoining Grammar parser, and they claim a 1-best supertagging accuracy of 81.47%, and a 4- best accuracy of 91.41%. With the latter they reach the highest parser coverage, about three quarters of the 1700 sentences in their test data. Clark and Curran (2004a; 2004b) describe a combination of supertagger and parser for parsing Combinatory Categorial Grammar, where the tagger is used to filter the parses produced by the grammar, before the computation of the model parameters. The parser uses an incremental method: the supertagger first assigns a small number of categories to each word, and the parser requests more alternatives only if the analysis fails. They report 91.4% precision and 91.0% recall of unlabelled dependencies and a speed of 1.6 minutes to parse 2401 sentences, and claim a parser speedup of a factor of 77 thanks to supertagging. The</context>
</contexts>
<marker>Clark, Curran, 2004</marker>
<rawString>S. Clark and J. R. Curran. 2004b. Parsing the WSJ using CCG and log-linear models. In Proc. 42nd Meeting of the ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Daum</author>
<author>K Foth</author>
<author>W Menzel</author>
</authors>
<title>Constraint based integration of deep and shallow parsing techniques.</title>
<date>2003</date>
<booktitle>In Proc. 11th Conf. of the EACL,</booktitle>
<location>Budapest, Hungary.</location>
<contexts>
<context position="22304" citStr="Daum et al., 2003" startWordPosition="3682" endWordPosition="3685">rmation that they contribute to the analysis. Obviously, this trend cannot continue indefinitely; a supertag definition that predicted even larger parts of the dependency tree would certainly lead to much lower accuracy by even the most lenient measure, and a prediction that is mostly wrong must ultimately degrade parsing performance. Since the most complex model J shows no parsing improvement over its successor I, this point might already have been reached. The use of supertags in WCDG is comparable to previous work which integrated POS tagging and chunk parsing. (Foth and Hagenstr¨om, 2002; Daum et al., 2003) showed that the correct balance between the new knowledge and the existing grammar is crucial for successful integration. This is achieved by means of an additional parameter, modeling how trustworthy supertag predictions are considered. Its effect is shown in Table 4. As expected, making supertag constraints hard (with a value of 0.0) over-constrains most parsing problems, so that hardly any analyses can be computed. Other values near 0 avoid this problem but still lead to much worse overall performance, as wrong or even impossible predictions too often overrule the normal syntax constraints</context>
</contexts>
<marker>Daum, Foth, Menzel, 2003</marker>
<rawString>M. Daum, K. Foth, and W. Menzel. 2003. Constraint based integration of deep and shallow parsing techniques. In Proc. 11th Conf. of the EACL, Budapest, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Daum</author>
<author>K Foth</author>
<author>W Menzel</author>
</authors>
<title>Automatic transformation of phrase treebanks to dependency trees.</title>
<date>2004</date>
<booktitle>In Proc. 4th Int. Conf. on Language Resources and Evaluation, LREC-2004,</booktitle>
<pages>99--106</pages>
<location>Lisbon, Portugal.</location>
<contexts>
<context position="9865" citStr="Daum et al., 2004" startWordPosition="1617" endWordPosition="1620">two post-modifying prepositions would still list PP only once in its right context. This ensures that the set of possible supertags is finite. The full set of different supertag models we used is given in Table 2. Note that the more complicated models G, H, I and J predict all dependents of each word, while the others predict obligatory dependents only, which should be an easier task. To obtain and evaluate supertag predictions, we used the NEGRA and TIGER corpora (Brants et al., 1997; Brants et al., 2002), automatically transformed into dependency format with the freely available tool DepSy (Daum et al., 2004). As our test set we used sentences 18,602–19,601 of the NEGRA corpus, for comparability to earlier work. All other sentences (59,622 sentences with 1,032,091 words) were used as the training set. For each word in the training set, the local context was extracted and expressed in our supertag notation. The word/supertag pairs were then used to train the statistical part-of-speech tagger TnT (Brants, 2000), which performs trigram tagging efficiently and allows easy retraining on different data. However, a few of TnT’s limitations had to be worked around: since it cannot deal with words that hav</context>
</contexts>
<marker>Daum, Foth, Menzel, 2004</marker>
<rawString>M. Daum, K. Foth, and W. Menzel. 2004. Automatic transformation of phrase treebanks to dependency trees. In Proc. 4th Int. Conf. on Language Resources and Evaluation, LREC-2004, pages 99–106, Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Foth</author>
<author>J Hagenstr¨om</author>
</authors>
<title>Tagging for robust parsers.</title>
<date>2002</date>
<booktitle>In 2nd Workshop on Robust Methods in Analysis ofNatural Language Data, ROMAND-2002,</booktitle>
<pages>21--32</pages>
<location>Frascati, Italy.</location>
<marker>Foth, Hagenstr¨om, 2002</marker>
<rawString>K. Foth and J. Hagenstr¨om. 2002. Tagging for robust parsers. In 2nd Workshop on Robust Methods in Analysis ofNatural Language Data, ROMAND-2002, pages 21 – 32, Frascati, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Foth</author>
<author>W Menzel</author>
</authors>
<title>Hybrid parsing: Using probabilistic models as predictors for a symbolic parser.</title>
<date>2006</date>
<booktitle>In Proc. 21st Int. Conf. on Computational Linguistics, Coling-ACL-2006,</booktitle>
<location>Sydney.</location>
<contexts>
<context position="16601" citStr="Foth and Menzel, 2006" startWordPosition="2751" endWordPosition="2754">raints can be soft as well as hard, parsing in the WCDG formalism amounts to multidimensional optimization. Of two possible analyses of an utterance, the one that satisfies more (or more important) constraints is always preferred. All knowledge about grammatical rules is encoded in the constraints that (together with the lexicon) constitute the grammar. Adding a constraint which is sensitive to supertag predictions will therefore change the objective function of the optimization problem, hopefully leading to a higher share of correct attachments. Details about the WDCG parser can be found in (Foth and Menzel, 2006). A grammar of German is available (Foth et al., 2004) that achieves a good accuracy on written German input. Despite its good results, it seems probable that the information provided by a supertag prediction component could improve the accuracy further. First, because the optimization problem that WCDG defines is infeasible to solve exactly, the parser must usually use incomplete, 292 heuristic algorithms to try to compute the optimal analysis. This means that it sometimes fails to find the correct analysis even if the language model accurately defines it, because of search errors during heur</context>
<context position="30228" citStr="Foth and Menzel, 2006" startWordPosition="5005" endWordPosition="5008">sions and future work We have shown that a statistical supertagging component can significantly improve the parsing accuracy of a general-purpose dependency parser for German. The error rate among syntactic attachments can be reduced by 24% over an already competitive baseline. After all, the integration of the supertagging results helped to reach a quality level which compares favourably with the state-of-the-art in probabilistic dependency parsing for German as defined with 87.34%/90.38% labelled/unlabelled attachment accuracy on this years shared CoNLL task by (McDonald et al., 2005) (see (Foth and Menzel, 2006) for a more detailed comparison). Although the statistical model used in our system is rather simple-minded, it clearly captures at least some distributional char295 acteristics of German text that the hand-written rules do not. A crucial factor for success is the defeasible integration of the supertagging predictions via soft constraints. Rather than pursuing a strict filtering approach where supertagging errors are partially compensated by an n-best selection, we commit to only one supertag per word, but reduce its influence. Treating supertag predictions as weak preferences yields the best </context>
</contexts>
<marker>Foth, Menzel, 2006</marker>
<rawString>K. Foth and W. Menzel. 2006. Hybrid parsing: Using probabilistic models as predictors for a symbolic parser. In Proc. 21st Int. Conf. on Computational Linguistics, Coling-ACL-2006, Sydney.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Foth</author>
<author>M Daum</author>
<author>W Menzel</author>
</authors>
<title>A broadcoverage parser for german based on defeasible constraints.</title>
<date>2004</date>
<booktitle>In 7. Konferenz zur Verarbeitung nat¨urlicher Sprache, KONVENS-2004,</booktitle>
<pages>45--52</pages>
<location>Wien.</location>
<contexts>
<context position="16655" citStr="Foth et al., 2004" startWordPosition="2761" endWordPosition="2764">rmalism amounts to multidimensional optimization. Of two possible analyses of an utterance, the one that satisfies more (or more important) constraints is always preferred. All knowledge about grammatical rules is encoded in the constraints that (together with the lexicon) constitute the grammar. Adding a constraint which is sensitive to supertag predictions will therefore change the objective function of the optimization problem, hopefully leading to a higher share of correct attachments. Details about the WDCG parser can be found in (Foth and Menzel, 2006). A grammar of German is available (Foth et al., 2004) that achieves a good accuracy on written German input. Despite its good results, it seems probable that the information provided by a supertag prediction component could improve the accuracy further. First, because the optimization problem that WCDG defines is infeasible to solve exactly, the parser must usually use incomplete, 292 heuristic algorithms to try to compute the optimal analysis. This means that it sometimes fails to find the correct analysis even if the language model accurately defines it, because of search errors during heuristic optimization. A component that makes specific pr</context>
<context position="20074" citStr="Foth et al., 2004" startWordPosition="3316" endWordPosition="3319">ely for left and right dependents). Altogether six new constraints are added to the grammar which refer to the output of the supertagger on the current sentence. Note that in contrast to most other approaches we do not perform multi-supertagging; exactly one supertag is assumed for each word. Alternatives could be integrated by computing the logical disjunctions of the predictions made by each supertag, and then adapting the new constraints accordingly. 4 Experiments We tested the effect of supertag predictions on a full parser by adding the new constraints to the WCDG of German described in (Foth et al., 2004) and re-parsing the same 1,000 sentences from the NEGRA corpus. The quality of a dependency parser such as this can be measured as the ratio of correctly attached words to all words (structural accuracy) or the ratio of the correctly attached and correctly labelled words to all words (labelled accuracy). Note that because the parser always finds exactly one analysis with exactly one subordination per word, there is no distinction between recall and precision. The structural accuracy without any supertags is 89.6%. To determine the best trade-off between complexity and prediction quality, we te</context>
</contexts>
<marker>Foth, Daum, Menzel, 2004</marker>
<rawString>K. Foth, M. Daum, and W. Menzel. 2004. A broadcoverage parser for german based on defeasible constraints. In 7. Konferenz zur Verarbeitung nat¨urlicher Sprache, KONVENS-2004, pages 45–52, Wien.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R McDonald</author>
<author>F Pereira</author>
<author>K Ribarov</author>
<author>J Hajic</author>
</authors>
<title>Non-projective dependency parsing using spanning tree algorithms.</title>
<date>2005</date>
<booktitle>In Proc. Human Language Technology Conference, HLT/EMNLP-2005,</booktitle>
<location>Vancouver, B.C.</location>
<contexts>
<context position="30199" citStr="McDonald et al., 2005" startWordPosition="5000" endWordPosition="5003">upertagging speedup. 6 Conclusions and future work We have shown that a statistical supertagging component can significantly improve the parsing accuracy of a general-purpose dependency parser for German. The error rate among syntactic attachments can be reduced by 24% over an already competitive baseline. After all, the integration of the supertagging results helped to reach a quality level which compares favourably with the state-of-the-art in probabilistic dependency parsing for German as defined with 87.34%/90.38% labelled/unlabelled attachment accuracy on this years shared CoNLL task by (McDonald et al., 2005) (see (Foth and Menzel, 2006) for a more detailed comparison). Although the statistical model used in our system is rather simple-minded, it clearly captures at least some distributional char295 acteristics of German text that the hand-written rules do not. A crucial factor for success is the defeasible integration of the supertagging predictions via soft constraints. Rather than pursuing a strict filtering approach where supertagging errors are partially compensated by an n-best selection, we commit to only one supertag per word, but reduce its influence. Treating supertag predictions as weak</context>
</contexts>
<marker>McDonald, Pereira, Ribarov, Hajic, 2005</marker>
<rawString>R. McDonald, F. Pereira, K. Ribarov, and J. Hajic. 2005. Non-projective dependency parsing using spanning tree algorithms. In Proc. Human Language Technology Conference, HLT/EMNLP-2005, Vancouver, B.C.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Nasr</author>
<author>O Rambow</author>
</authors>
<title>A simple stringrewriting formalism for dependency grammar.</title>
<date>2004</date>
<booktitle>In Coling-Workshop Recent Advances in Dependency Grammar,</booktitle>
<pages>17--24</pages>
<location>Geneva, Switzerland.</location>
<contexts>
<context position="1859" citStr="Nasr and Rambow (2004)" startWordPosition="271" endWordPosition="274">exical items than say part-of-speech tags. Bangalore and Joshi (1999) derived the notion of supertag within the framework of Lexicalized Tree-Adjoining Grammars (LTAG) (Schabes and Joshi, 1991). They considered supertagging a process of almost parsing, since all that needs to be done after having a sufficiently reliable sequence of supertags available is to decide on their combination into a spanning tree for the complete sentence. Thus the approach lends itself easily to preprocessing sentences or filtering parsing results with the goal of guiding the parser or reducing its output ambiguity. Nasr and Rambow (2004) estimated that perfect supertag information already provides for a parsing accuracy of 98% if a correct supertag assignment were available. Unfortunately, perfectly reliable supertag information cannot be expected; usually this uncertainty is compensated by running the tagger in multi-tagging mode, expecting that the reliability can be increased by not forcing the tagger to take unreliable decisions but instead offering a set of alternatives from which a subsequent processing component can choose. A grammar formalism which seems particularly well suited to decompose structural descriptions in</context>
<context position="24880" citStr="Nasr and Rambow, 2004" startWordPosition="4112" endWordPosition="4115">ictions. Table 5 again gives the unlabelled and labelled parsing accuracy for all 10 different supertag models with the integration strengths of 0 and 0.9. (Note that since all our models predict the edge label of each word, hard integration of perfect predictions eliminates the difference between labelled und unlabelled accuracy.) As expected, an improved accuracy of supertagging would lead to improved parsing accuracy in each case. In fact, knowing the correct supertag would solve the parsing problem almost completely with the more complex models. This confirms earlier findings for English (Nasr and Rambow, 2004). Since perfect supertaggers are not available, we have to make do with the imperfect ones that do exist. One method of avoiding some errors introduced by supertagging would be to reject supertag predictions that tend to be wrong. To this end, we ran the supertagger on its training set and determined the average component accuracy of each occurring supertag. The supertags whose average precision fell below a variable threshold were not considered during parsing as if the supertagger had not made a prediction. This means that a threshold of 100% corresponds to the baseline of not using supertag</context>
</contexts>
<marker>Nasr, Rambow, 2004</marker>
<rawString>A. Nasr and O. Rambow. 2004. A simple stringrewriting formalism for dependency grammar. In Coling-Workshop Recent Advances in Dependency Grammar, pages 17–24, Geneva, Switzerland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Sarkar</author>
<author>F Xia</author>
<author>A Joshi</author>
</authors>
<title>Some experiments on indicators of parsing complexity for lexicalized grammars.</title>
<date>2000</date>
<booktitle>In Proc. COLING Workshop on Efficiency in Large-Scale Parsing Systems.</booktitle>
<contexts>
<context position="29505" citStr="Sarkar et al., 2000" startWordPosition="4896" endWordPosition="4899">ioned here is to reduce the ambiguity in the input to the parser and thereby increase its speed, in some cases dramatically. For us, supertagging decreases the speed slightly, because additional constraints means more work for the parser, and because our supertagger-parser integration is not yet optimal. On the other hand it gives us better parsing accuracy. Using a constraint penalty of 0.0 for the supertagger integration (c.f. Table 5) does speed up our parser several times, but would only be practical with very high tagging accuracy. An important point is that for some other systems, like (Sarkar et al., 2000) and (Chen et al., 2002), parsing is not actually feasible without the supertagging speedup. 6 Conclusions and future work We have shown that a statistical supertagging component can significantly improve the parsing accuracy of a general-purpose dependency parser for German. The error rate among syntactic attachments can be reduced by 24% over an already competitive baseline. After all, the integration of the supertagging results helped to reach a quality level which compares favourably with the state-of-the-art in probabilistic dependency parsing for German as defined with 87.34%/90.38% labe</context>
</contexts>
<marker>Sarkar, Xia, Joshi, 2000</marker>
<rawString>A. Sarkar, F. Xia, and A. Joshi. 2000. Some experiments on indicators of parsing complexity for lexicalized grammars. In Proc. COLING Workshop on Efficiency in Large-Scale Parsing Systems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Schabes</author>
<author>A K Joshi</author>
</authors>
<title>Parsing with lexicalized tree adjoining grammar.</title>
<date>1991</date>
<booktitle>Current Issues in Parsing Technologies.</booktitle>
<editor>In M. Tomita, editor,</editor>
<publisher>Kluwer Academic Publishers.</publisher>
<contexts>
<context position="1430" citStr="Schabes and Joshi, 1991" startWordPosition="200" endWordPosition="203">is based on the combination of two powerful and influential ideas of natural language processing: On the one hand, parsing is (at least partially) reduced to a decision on the optimal sequence of categories, a problem for which efficient and easily trainable procedures exist. On the other hand, supertagging exploits complex categories, i.e. tree fragments which much better reflect the mutual compatibility between neighbouring lexical items than say part-of-speech tags. Bangalore and Joshi (1999) derived the notion of supertag within the framework of Lexicalized Tree-Adjoining Grammars (LTAG) (Schabes and Joshi, 1991). They considered supertagging a process of almost parsing, since all that needs to be done after having a sufficiently reliable sequence of supertags available is to decide on their combination into a spanning tree for the complete sentence. Thus the approach lends itself easily to preprocessing sentences or filtering parsing results with the goal of guiding the parser or reducing its output ambiguity. Nasr and Rambow (2004) estimated that perfect supertag information already provides for a parsing accuracy of 98% if a correct supertag assignment were available. Unfortunately, perfectly relia</context>
</contexts>
<marker>Schabes, Joshi, 1991</marker>
<rawString>Y. Schabes and A. K. Joshi. 1991. Parsing with lexicalized tree adjoining grammar. In M. Tomita, editor, Current Issues in Parsing Technologies. Kluwer Academic Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Schr¨oder</author>
<author>W Menzel</author>
<author>K Foth</author>
<author>M Schulz</author>
</authors>
<title>Modeling dependency grammar with restricted constraints.</title>
<date>2000</date>
<booktitle>Traitement Automatique des Langues (T.A.L.),</booktitle>
<pages>41--1</pages>
<marker>Schr¨oder, Menzel, Foth, Schulz, 2000</marker>
<rawString>I. Schr¨oder, W. Menzel, K. Foth, and M. Schulz. 2000. Modeling dependency grammar with restricted constraints. Traitement Automatique des Langues (T.A.L.), 41(1):97–126.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Wang</author>
<author>M P Harper</author>
</authors>
<title>The SuperARV language model: Investigating the effectiveness of tightly integrating multiple knowledge sources.</title>
<date>2002</date>
<booktitle>In Proc. Conf. on Empirical Methods in Natural Language Processing, EMNLP-2002,</booktitle>
<pages>238--247</pages>
<location>Philadelphia, PA.</location>
<contexts>
<context position="2616" citStr="Wang and Harper, 2002" startWordPosition="384" endWordPosition="387">able. Unfortunately, perfectly reliable supertag information cannot be expected; usually this uncertainty is compensated by running the tagger in multi-tagging mode, expecting that the reliability can be increased by not forcing the tagger to take unreliable decisions but instead offering a set of alternatives from which a subsequent processing component can choose. A grammar formalism which seems particularly well suited to decompose structural descriptions into lexicalized tree fragments is dependency grammar. It allows us to define supertags on different levels of granularity (White, 2000; Wang and Harper, 2002), thus facilitating a fine grained analysis of how the different aspects of supertag information influence the parsing behaviour. In the following we will use this characteristic to study in more detail the utility of different kinds of supertag information for guiding the parsing process. Usually supertags are combined with a parser in a filtering mode, i.e. parsing hypotheses which are not compatible with the supertag predictions are simply discarded. Drawing on the ability of Weighted Constraint Dependency Grammar (WCDG) (Schr¨oder et al., 2000) to deal with defeasible constraints, here we </context>
<context position="6067" citStr="Wang and Harper, 2002" startWordPosition="953" endWordPosition="956">rent dependents. The simplest useful task that could be asked of a supertagger would be to predict the dependency relation that each word enters. In terms of the WCDG formalism, this means associating each word at least with one of the syntactic labels that decorate dependency edges, such as SUBJ or DET; in other words, the supertag set would be identical to the label set. The example sentence 1The model of German used here considers the objects of verbs, prepositions and conjunctions to be obligatory and most other relations as optional. This corresponds closely to the set of needs roles of (Wang and Harper, 2002). “Es mag sein, daß die Franzosen kein schl¨ussiges Konzept f¨ur eine echte Partnerschaft besitzen.” (Perhaps the French do not have a viable concept for a true partnership.) if analyzed as in Figure 1, would then be described by a supertag sequence beginning with EXPL S AUX ... Following (Wang and Harper, 2002), we further classify dependencies into Left (L), Right (R), and No attachments (N), depending on whether a word is attached to its left or right, or not at all. We combine the label with the attachment direction to obtain composite supertags. The sequence of supertags describing the ex</context>
<context position="27786" citStr="Wang and Harper, 2002" startWordPosition="4599" endWordPosition="4602">ar, where the tagger is used to filter the parses produced by the grammar, before the computation of the model parameters. The parser uses an incremental method: the supertagger first assigns a small number of categories to each word, and the parser requests more alternatives only if the analysis fails. They report 91.4% precision and 91.0% recall of unlabelled dependencies and a speed of 1.6 minutes to parse 2401 sentences, and claim a parser speedup of a factor of 77 thanks to supertagging. The supertagging approach that is closest to ours in terms of linguistic representations is probably (Wang and Harper, 2002; Wang and Harper, 2004) whose ‘Super Abstract Role Values’ are very similar to our model F supertags (Table 2). It is interesting to note that they only report between 328 and 791 SuperARVs for different corpora, whereas we have 2026 category F supertags. Part of the difference is explained by our larger label set: 35, the same as the number of model A supertags in table 2 against their 24 (White, 2000, p. 50). Also, we are not using the same corpus. In addition to determining the optimal SuperARV sequence in isolation, Wang and Harper (2002) also combine the SuperARV n-gram probabilities wit</context>
</contexts>
<marker>Wang, Harper, 2002</marker>
<rawString>W. Wang and M. P. Harper. 2002. The SuperARV language model: Investigating the effectiveness of tightly integrating multiple knowledge sources. In Proc. Conf. on Empirical Methods in Natural Language Processing, EMNLP-2002, pages 238–247, Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Wang</author>
<author>M P Harper</author>
</authors>
<title>A statistical constraint dependency grammar (CDG) parser.</title>
<date>2004</date>
<booktitle>In Proc. ACL Workshop Incremental Parsing: Bringing Engineering and Cognition Together,</booktitle>
<pages>42--49</pages>
<location>Barcelona,</location>
<contexts>
<context position="27810" citStr="Wang and Harper, 2004" startWordPosition="4603" endWordPosition="4606"> used to filter the parses produced by the grammar, before the computation of the model parameters. The parser uses an incremental method: the supertagger first assigns a small number of categories to each word, and the parser requests more alternatives only if the analysis fails. They report 91.4% precision and 91.0% recall of unlabelled dependencies and a speed of 1.6 minutes to parse 2401 sentences, and claim a parser speedup of a factor of 77 thanks to supertagging. The supertagging approach that is closest to ours in terms of linguistic representations is probably (Wang and Harper, 2002; Wang and Harper, 2004) whose ‘Super Abstract Role Values’ are very similar to our model F supertags (Table 2). It is interesting to note that they only report between 328 and 791 SuperARVs for different corpora, whereas we have 2026 category F supertags. Part of the difference is explained by our larger label set: 35, the same as the number of model A supertags in table 2 against their 24 (White, 2000, p. 50). Also, we are not using the same corpus. In addition to determining the optimal SuperARV sequence in isolation, Wang and Harper (2002) also combine the SuperARV n-gram probabilities with a dependency assignmen</context>
</contexts>
<marker>Wang, Harper, 2004</marker>
<rawString>W. Wang and M. P. Harper. 2004. A statistical constraint dependency grammar (CDG) parser. In Proc. ACL Workshop Incremental Parsing: Bringing Engineering and Cognition Together, pages 42–49, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M White</author>
</authors>
<title>Rapid Grammar Development and Parsing: Constraint Dependency Grammar with Abstract Role Values.</title>
<date>2000</date>
<tech>Ph.D. thesis,</tech>
<institution>Purdue University,</institution>
<location>West Lafayette, IN.</location>
<contexts>
<context position="2592" citStr="White, 2000" startWordPosition="382" endWordPosition="383">nt were available. Unfortunately, perfectly reliable supertag information cannot be expected; usually this uncertainty is compensated by running the tagger in multi-tagging mode, expecting that the reliability can be increased by not forcing the tagger to take unreliable decisions but instead offering a set of alternatives from which a subsequent processing component can choose. A grammar formalism which seems particularly well suited to decompose structural descriptions into lexicalized tree fragments is dependency grammar. It allows us to define supertags on different levels of granularity (White, 2000; Wang and Harper, 2002), thus facilitating a fine grained analysis of how the different aspects of supertag information influence the parsing behaviour. In the following we will use this characteristic to study in more detail the utility of different kinds of supertag information for guiding the parsing process. Usually supertags are combined with a parser in a filtering mode, i.e. parsing hypotheses which are not compatible with the supertag predictions are simply discarded. Drawing on the ability of Weighted Constraint Dependency Grammar (WCDG) (Schr¨oder et al., 2000) to deal with defeasib</context>
<context position="28192" citStr="White, 2000" startWordPosition="4676" endWordPosition="4677">1 sentences, and claim a parser speedup of a factor of 77 thanks to supertagging. The supertagging approach that is closest to ours in terms of linguistic representations is probably (Wang and Harper, 2002; Wang and Harper, 2004) whose ‘Super Abstract Role Values’ are very similar to our model F supertags (Table 2). It is interesting to note that they only report between 328 and 791 SuperARVs for different corpora, whereas we have 2026 category F supertags. Part of the difference is explained by our larger label set: 35, the same as the number of model A supertags in table 2 against their 24 (White, 2000, p. 50). Also, we are not using the same corpus. In addition to determining the optimal SuperARV sequence in isolation, Wang and Harper (2002) also combine the SuperARV n-gram probabilities with a dependency assignment probability into a dependency parser for English. A maximum tagging accuracy of 96.3% (for sentences up to 100 words) is achieved using a 4-gram n-best tagger producing the 100 best SuperARV sequences for a sentence. The tightly integrated model is able to determine 96.6% of SuperARVs correctly. The parser itself reaches a labelled precision of 92.6% and a labelled recall of 92</context>
</contexts>
<marker>White, 2000</marker>
<rawString>Ch. M. White. 2000. Rapid Grammar Development and Parsing: Constraint Dependency Grammar with Abstract Role Values. Ph.D. thesis, Purdue University, West Lafayette, IN.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>