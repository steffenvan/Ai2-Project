<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003025">
<title confidence="0.989779">
An MDL-based approach to extracting subword units for
grapheme-to-phoneme conversion
</title>
<author confidence="0.994089">
Sravana Reddy
</author>
<affiliation confidence="0.999622">
Department of Computer Science
The University of Chicago
</affiliation>
<address confidence="0.808289">
Chicago, IL 60637
</address>
<email confidence="0.998858">
sravana@cs.uchicago.edu
</email>
<author confidence="0.997036">
John Goldsmith
</author>
<affiliation confidence="0.995175">
Departments of Linguistics
and Computer Science
The University of Chicago
</affiliation>
<address confidence="0.807838">
Chicago, IL 60637
</address>
<email confidence="0.998736">
goldsmith@uchicago.edu
</email>
<sectionHeader confidence="0.99564" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9996639">
We address a key problem in grapheme-to-
phoneme conversion: the ambiguity in map-
ping grapheme units to phonemes. Rather than
using single letters and phonemes as units, we
propose learning chunks, or subwords, to re-
duce ambiguity. This can be interpreted as
learning a lexicon of subwords that has min-
imum description length. We implement an
algorithm to build such a lexicon, as well as a
simple decoder that uses these subwords.
</bodyText>
<sectionHeader confidence="0.99899" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.990100642857143">
A system for converting written words to their pro-
nunciations is an important component of speech-
related applications, especially in large vocabulary
tasks. This problem, commonly termed “grapheme-
to-phoneme conversion”, or g2p, is non-trivial for
several written languages, including English, since a
given letter (grapheme) may represent one of several
possible phonemes, depending on the context. Be-
cause the length of the context varies throughout the
dictionary, fixed-length contexts may overfit some
words, or inaccurately model others.
We approach this problem by treating g2p as a
function from contiguous sequences of graphemes,
which we call ‘grapheme subwords’, to sequences
of phonemes (‘phoneme subwords’), so that there is
minimal ambiguity in finding the phoneme subword
that corresponds to a given grapheme subword. That
is, we seek to minimize both these quantities:
1. The conditional entropy of the phoneme sub-
words given a grapheme subword. This di-
rectly tackles the problem of ambiguity – a per-
fectly unambiguous phoneme subword condi-
tional distribution would have entropy = 0.
2. The entropy of the grapheme subwords. This
prevents the model from getting arbitrarily
complex.
As a toy example, consider the following word-
pronunciation1 pairs:
</bodyText>
<equation confidence="0.768771666666667">
time T AY M
sting S T IH NG
negation N AH G EY SH AH N
</equation>
<bodyText confidence="0.99901225">
There are at least 5 graphemes whose correspond-
ing phoneme distribution is ambiguous (‘i’, ‘e’, ‘t’,
‘n’, ‘g’). In the segmentation below, every grapheme
subword corresponds to only one phoneme subword:
</bodyText>
<equation confidence="0.822825666666667">
t + ime T + AY M
s+t+ing S + T + IH NG
neg + a + tion N AH G + EY + SH AH N
</equation>
<sectionHeader confidence="0.99927" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999268916666667">
Many grapheme-to-phoneme algorithms rely on
something resembling subwords; these are mainly
used to account for sequences of letters representing
a single phoneme (‘ph’ for F), or vice versa (‘x’ for
K S). Some of the early works that create one-to-
one alignments between a word and its pronuncia-
tion address these cases by allowing a letter to map
to one phoneme, a null phoneme, or 2-3 phonemes.
Jiampojamarn and Kondrak (2009) use
expectation-maximization (EM) to learn many-
to-many alignments between words and pro-
nunciations, effectively obtaining subwords.
</bodyText>
<footnote confidence="0.931071">
1All phonemes are denoted by their Arpabet representations.
</footnote>
<page confidence="0.943516">
713
</page>
<subsubsectionHeader confidence="0.559031">
Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 713–716,
</subsubsectionHeader>
<subsectionHeader confidence="0.269607">
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</subsectionHeader>
<bodyText confidence="0.999943866666667">
Joint-sequence models divide a word-pronunciation
pair into a sequence of disjoint graphones or
graphonemes – tuples containing grapheme and
phoneme subwords. Such segmentations may
include only trivial graphones containing subwords
of length at most 1 (Chen, 2003). Other such
models use EM to learn the maximum likelihood
segmentation into graphones (Deligne and Bimbot,
1995; Bisani and Ney, 2008; Vozilla et al., 2003).
Subwords – or phrases – are used widely in ma-
chine translation. There is a large body of work on
phrase extraction starting from word alignments; see
Koehn et al. (2003) for a review. Marcu and Wong
(2002) learn phrases directly from sentence pairs us-
ing a joint probability model.
</bodyText>
<sectionHeader confidence="0.997358" genericHeader="method">
3 Subword Extraction
</sectionHeader>
<subsectionHeader confidence="0.998064">
3.1 Motivation for using MDL
</subsectionHeader>
<bodyText confidence="0.959568111111111">
Consider a lexicon of grapheme subwords !9 and
phoneme subwords P that is extracted from a dic-
tionary of word-pronunciation pairs, along with a
joint probability distribution over !g and P. As
stated earlier, our objective is to minimize the en-
tropy of phoneme subwords conditioned on a given
grapheme subword, as well as the entropy of the
grapheme subwords. That is, we would like to min-
imize H(P|!9) + H(!9), which is
</bodyText>
<equation confidence="0.986933">
H(�, P) = − � E pr(g, p) log pr(g, p) (1)
9E9 PEP
</equation>
<bodyText confidence="0.999853714285714">
This objective can be restated as minimizing the
expected description length of the lexicon, which is
given by its entropy. This is reflected in the MDL
principle (Rissanen, 1978), which seeks to find a
lexicon such that the description length of the lex-
icon (and the compression of the data under the lex-
icon) is minimized.
</bodyText>
<subsectionHeader confidence="0.999054">
3.2 Lexicon Induction
</subsectionHeader>
<bodyText confidence="0.99973745">
We begin with an initial alignment between a word’s
graphemes and the phonemes in its pronunciation
for all word-pronunciation pairs in the training dic-
tionary. These alignments are derived using the stan-
dard string edit distance dynamic programming al-
gorithm (Wagner and Fischer, 1974), giving a list
of tuples t = [(w1, r1), (w2, r2), ...I for each word-
pronunciation pair.2 The set of all tuple lists t com-
poses the training dictionary T .
The initial lexicon is composed of all singleton
graphemes and phonemes (including null). The
probability pr(g, p) is taken to be the number of
times the tuple (g, p) occurs in T divided by the total
number of tuples over all alignments in T .
Following a procedure similar the word-discovery
algorithm of de Marcken (1996), the lexicon is iter-
atively updated as sketched in Table 1. At no point
do we delete singleton graphemes or phonemes.
The subwords in the final updated lexicon are then
used to decode the pronunciations of unseen words.
</bodyText>
<sectionHeader confidence="0.999507" genericHeader="method">
4 G2P Decoding
</sectionHeader>
<subsectionHeader confidence="0.999643">
4.1 Joint segmentation and decoding
</subsectionHeader>
<bodyText confidence="0.999954333333333">
Finding the pronunciation of a word based on the
induced subword lexicon involves segmenting the
word into a sequence of grapheme subwords, and
mapping it to a sequence of phoneme subwords.
One possibility is carry these steps out sequen-
tially: first parse the word into grapheme subwords,
and then use a sequence labeling algorithm to find
the best corresponding sequence of phoneme sub-
words. However, it is likely that the true pronuncia-
tion of a word is not derived from its best parse into
grapheme units. For example, the best parse of the
word ‘gnat’ is ‘g nat’, which yields the pronuncia-
tion G N AE T, while the parse ‘gn at’ would give
the correct pronunciation N AE T.
Therefore, we search for the best pronunciation
over all segmentations of the word, adapting the
monotone search algorithm proposed by Zens and
Ney (2004) for phrase-based machine translation.3
</bodyText>
<subsectionHeader confidence="0.988003">
4.2 Smoothing
</subsectionHeader>
<bodyText confidence="0.9998032">
A bigram model is used over both the grapheme
and phoneme subwords. These bigrams need to be
smoothed before the decoding step. Adding an equal
probability mass to unseen bigrams would fail to re-
flect simple phonotactics (patterns that govern sound
</bodyText>
<footnote confidence="0.9977124">
2Phoneme insertions and deletions are represented by the
null grapheme and null phoneme respectively.
3The key adaptation is in using a bigram model over both
graphemes and phonemes, rather than only phonemes as in the
original algorithm.
</footnote>
<page confidence="0.997992">
714
</page>
<tableCaption confidence="0.983004">
Table 1: Concatenative algorithm for building a subword lexicon that minimizes description length. The input is T ,
the set of alignments, and a threshold integer k, which is tuned using a held-out development set.
</tableCaption>
<bodyText confidence="0.927953857142857">
1 Update pr(g, p) by computing the posterior probabilities of the tuple (g, p) in T,
2 using the forward-backward algorithm. Repeat once more to get an intermediate lexicon.
3 Compute the Viterbi parse of each t E T under the lexicon derived in step 1.
Let A, the set of candidate tuples for addition to the lexicon, contain all tuples (wiwi+1, riri+1) such that
(wi, ri) and (wi+1, ri+1) are adjacent more than k times in the computed Viterbi parses. For each (g, p) E A,
estimate the change in description length of the lexicon if (g, p) is added. If description length decreases,
remove any null symbols within g and p, and add (g, p) to the lexicon.
</bodyText>
<figure confidence="0.66884625">
4 Repeat steps 1 and 2.
5 Delete all tuples that do not occur in any of the Viterbi parses.
6 Compare the description length of the new lexicon with the lexicon at the start of the iteration. If the
difference is sufficiently small, return the new lexicon; else, repeat from step 1.
</figure>
<equation confidence="0.794246">
sequences) in several cases. For example, the bi-
gram L UW K + S is much more likely than L UW
K + Z, since S is more likely than Z to follow K.
</equation>
<bodyText confidence="0.9996784">
To introduce a bias towards phonotacticaly likely
bigrams, we define the smoothed bigram probability
of the subword a following a subword b. Given that
b is made up of a sequence of l phonemes b1b2 ... bl,
the probability is defined as the interpolation4:
</bodyText>
<equation confidence="0.999899">
prnew(a|b) = A1pr(a|b1b2 ... bl) +
A2pr(a|b1b2 ... bl−1) + A3pr(a|b1b2 ... bl−2)
</equation>
<bodyText confidence="0.995447">
Both the grapheme and phoneme subword bi-
grams are smoothed as described.
</bodyText>
<sectionHeader confidence="0.999928" genericHeader="evaluation">
5 Results
</sectionHeader>
<bodyText confidence="0.999796133333333">
We test our algorithm on the CMU Pronouncing
Dictionary5. The dictionary is divided randomly
into a training (90% of the data) and a test set. Per-
formance is evaluated by measuring the phoneme er-
ror rate (PER) and the word error rate (WER).
The subword extraction algorithm converges in 3
iterations.We run the g2p decoder using the lexicon
after 3 iterations, as well as after 0,1 and 2 itera-
tions. The results are shown in Table 2.
Figure 1 compares the results of our method (de-
noted by ‘MDL-Sub’) to two baselines, at different
values of maximum subword length. To evaluate the
quality of our subwords, we substitute another ex-
traction algorithm to create the lexicon – the grow-
diag-final phrase extraction method (Koehn et al.,
</bodyText>
<footnote confidence="0.997381666666667">
4In our experiments, we set A1 = 0.5, A2 = 0.3, A3 = 0.2.
5The CMU Pronouncing Dictionary. Available online at
http://www.speech.cs.cmu.edu/cgi-bin/cmudict
</footnote>
<tableCaption confidence="0.845188333333333">
Table 2: Results after each iteration of subword extrac-
tion. While the maximum subword length after iteration
3 is 8, the vast majority of subwords have length 6 or less.
</tableCaption>
<table confidence="0.980204333333333">
# subwords Max subword WER PER
length
0 |9 |: 27, |P |: 40 1 73.16 24.20
1 |9 |: 819, |P |: 1254 2 48.39 12.43
2 |9 |: 5430, |P |: 4954 4 28.32 7.16
3 |9|: 6417, |P |: 5358 6 26.31 6.29
</table>
<bodyText confidence="0.999422315789474">
2005), denoted by ‘GD’ in the figure. We also run
the implementation of Bisani and Ney (2008) – de-
noted by ‘BN’ – on the same data. BN is an example
of a joint-sequence n-gram model, which uses a joint
distribution pr(!9, P) of graphemes and phonemes
(‘graphones’), conditioned on the preceding n-1 gra-
phones for context information. Since this algorithm
outperforms most of the existing g2p algorithms, it
serves as a good point of comparison to the state of
the art in g2p. The results of BN using an n-gram
model are compared to MDL-Sub with an n-1 max-
imum subword length6.
The MDL-Sub lexicon does significantly better
than the phrases extracted by GD. While BN starts
off doing better than MDL-Sub, the latter outper-
forms BN at longer subword lengths. Most of the ad-
ditional errors in BN at that stage involve grapheme-
to-phoneme ambiguity – phonemes like AE, AA, and
AH being confused for one another when mapping
</bodyText>
<footnote confidence="0.996641666666667">
6The contextual information of (n-1)-length subwords with
bigrams is assumed to be roughly comparable to that of very
short subwords over n-grams.
</footnote>
<page confidence="0.996995">
715
</page>
<bodyText confidence="0.9998213">
the grapheme ‘a’, and so on. Far fewer of these er-
rors are produced by our algorithm. However, some
of the longer subwords in MDL-Sub do introduce
additional errors, mainly because the extraction al-
gorithm merges smaller subwords from previous it-
erations. For example, one of the items in the ex-
tracted lexicon is ‘icati’ – a product of merging ‘ic’
and ‘ati’ – corresponding to IH K EY SH, thus
generating incorrect pronunciations for words con-
taining the string ‘icating’.
</bodyText>
<figureCaption confidence="0.999414">
Figure 1: Comparison of error rates.
</figureCaption>
<sectionHeader confidence="0.998173" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999956107142857">
This paper deals with translational ambiguity, which
is a major issue in grapheme-to-phoneme conver-
sion. The core of our system consists of extract-
ing subwords of graphemes and phonemes from the
training data, so that the ambiguity of deriving a
phoneme subword from a grapheme subword is min-
imized. This is achieved by formalizing ambiguity
in terms of the minimum description length princi-
ple, and using an algorithm that reduces the descrip-
tion length of the subword lexicon at each iteration.
In addition, we also introduce a smoothing mech-
anism which retains some of the phonotactic depen-
dencies that may be lost when using subwords rather
than singleton letters and phonemes.
While retaining the basic approach to minimizing
ambiguity, there are some avenues for improvement.
The algorithm that builds the lexicon creates a more
or less hierarchical structure – subwords tend to be
composed from those extracted at the previous iter-
ation. This appears to be the cause of many of the
errors produced by our method. A subword extrac-
tion algorithm that does not use a strictly bottom-up
process may create a more robust lexicon.
Our method of subword extraction could also be
applied to phrase extraction for machine transla-
tion, or in finding subwords for related problems like
transliteration. It may also be useful in deriving sub-
word units for speech recognition.
</bodyText>
<sectionHeader confidence="0.999435" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999845972972973">
Maximilian Bisani and Hermann Ney. 2008. Joint-
sequence models for grapheme-to-phoneme conver-
sion. Speech Communication, 50:434–451.
Stanley F Chen. 2003. Conditional and joint models for
grapheme-to-phoneme conversion. In Proceedings of
Eurospeech.
Carl G de Marcken. 1996. Unsupervised Language Ac-
quisistion. Ph.D. thesis, MIT.
Sabine Deligne and Frederic Bimbot. 1995. Language
modeling by variable length sequences: theoretical
formulation and evaluation of multigrams. In Pro-
ceedings of ICASSP.
Sittichai Jiampojamarn and Grzegorz Kondrak. 2009.
Online discriminative training for grapheme-to-
phoneme conversion. In Proceedings of Interspeech.
Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In Proceed-
ings of HLT-NAACL.
Philipp Koehn, Amittai Axelrod, Alexandra Birch
Mayne, Chris Callison-Burch, Miles Osborne, and
David Talbot. 2005. Edinburgh System Description
for the 2005 IWSLT Speech Translation Evaluation.
In Proceedings of IWSLT.
Daniel Marcu and William Wong. 2002. A phrase-based,
joint probability model for statistical machine transla-
tion. In Proceedings of EMNLP.
Jorma Rissanen. 1978. Modeling by the shortest data
description. Automatica.
Paul Vozilla, Jeff Adams, Yuliya Lobacheva, and Ryan
Thomas. 2003. Grapheme to phoneme conversion and
dictionary verification using graphonemes. In Pro-
ceedings of Eurospeech.
Robert Wagner and Michael Fischer. 1974. The string-
to-string correction problem. Journal of the ACM.
Richard Zens and Hermann Ney. 2004. Improvements in
phrase-based statistical machine translation. In Pro-
ceedings of HLT-NAACL.
</reference>
<page confidence="0.998516">
716
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.144794">
<title confidence="0.96089">An MDL-based approach to extracting subword units grapheme-to-phoneme conversion</title>
<author confidence="0.951152">Sravana</author>
<affiliation confidence="0.99903">Department of Computer The University of</affiliation>
<address confidence="0.494523">Chicago, IL</address>
<email confidence="0.996793">sravana@cs.uchicago.edu</email>
<author confidence="0.605744">John</author>
<affiliation confidence="0.995297666666667">Departments of and Computer The University of</affiliation>
<address confidence="0.537149">Chicago, IL</address>
<email confidence="0.999149">goldsmith@uchicago.edu</email>
<abstract confidence="0.999832">We address a key problem in grapheme-tophoneme conversion: the ambiguity in mapping grapheme units to phonemes. Rather than and phonemes as units, we learning chunks, or to reduce ambiguity. This can be interpreted as learning a lexicon of subwords that has minimum description length. We implement an algorithm to build such a lexicon, as well as a simple decoder that uses these subwords.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Maximilian Bisani</author>
<author>Hermann Ney</author>
</authors>
<title>Jointsequence models for grapheme-to-phoneme conversion.</title>
<date>2008</date>
<journal>Speech Communication,</journal>
<pages>50--434</pages>
<contexts>
<context position="3618" citStr="Bisani and Ney, 2008" startWordPosition="562" endWordPosition="565">t representations. 713 Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 713–716, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics Joint-sequence models divide a word-pronunciation pair into a sequence of disjoint graphones or graphonemes – tuples containing grapheme and phoneme subwords. Such segmentations may include only trivial graphones containing subwords of length at most 1 (Chen, 2003). Other such models use EM to learn the maximum likelihood segmentation into graphones (Deligne and Bimbot, 1995; Bisani and Ney, 2008; Vozilla et al., 2003). Subwords – or phrases – are used widely in machine translation. There is a large body of work on phrase extraction starting from word alignments; see Koehn et al. (2003) for a review. Marcu and Wong (2002) learn phrases directly from sentence pairs using a joint probability model. 3 Subword Extraction 3.1 Motivation for using MDL Consider a lexicon of grapheme subwords !9 and phoneme subwords P that is extracted from a dictionary of word-pronunciation pairs, along with a joint probability distribution over !g and P. As stated earlier, our objective is to minimize the e</context>
<context position="10264" citStr="Bisani and Ney (2008)" startWordPosition="1730" endWordPosition="1733">(Koehn et al., 4In our experiments, we set A1 = 0.5, A2 = 0.3, A3 = 0.2. 5The CMU Pronouncing Dictionary. Available online at http://www.speech.cs.cmu.edu/cgi-bin/cmudict Table 2: Results after each iteration of subword extraction. While the maximum subword length after iteration 3 is 8, the vast majority of subwords have length 6 or less. # subwords Max subword WER PER length 0 |9 |: 27, |P |: 40 1 73.16 24.20 1 |9 |: 819, |P |: 1254 2 48.39 12.43 2 |9 |: 5430, |P |: 4954 4 28.32 7.16 3 |9|: 6417, |P |: 5358 6 26.31 6.29 2005), denoted by ‘GD’ in the figure. We also run the implementation of Bisani and Ney (2008) – denoted by ‘BN’ – on the same data. BN is an example of a joint-sequence n-gram model, which uses a joint distribution pr(!9, P) of graphemes and phonemes (‘graphones’), conditioned on the preceding n-1 graphones for context information. Since this algorithm outperforms most of the existing g2p algorithms, it serves as a good point of comparison to the state of the art in g2p. The results of BN using an n-gram model are compared to MDL-Sub with an n-1 maximum subword length6. The MDL-Sub lexicon does significantly better than the phrases extracted by GD. While BN starts off doing better tha</context>
</contexts>
<marker>Bisani, Ney, 2008</marker>
<rawString>Maximilian Bisani and Hermann Ney. 2008. Jointsequence models for grapheme-to-phoneme conversion. Speech Communication, 50:434–451.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stanley F Chen</author>
</authors>
<title>Conditional and joint models for grapheme-to-phoneme conversion.</title>
<date>2003</date>
<booktitle>In Proceedings of Eurospeech.</booktitle>
<contexts>
<context position="3484" citStr="Chen, 2003" startWordPosition="543" endWordPosition="544">o-many alignments between words and pronunciations, effectively obtaining subwords. 1All phonemes are denoted by their Arpabet representations. 713 Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 713–716, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics Joint-sequence models divide a word-pronunciation pair into a sequence of disjoint graphones or graphonemes – tuples containing grapheme and phoneme subwords. Such segmentations may include only trivial graphones containing subwords of length at most 1 (Chen, 2003). Other such models use EM to learn the maximum likelihood segmentation into graphones (Deligne and Bimbot, 1995; Bisani and Ney, 2008; Vozilla et al., 2003). Subwords – or phrases – are used widely in machine translation. There is a large body of work on phrase extraction starting from word alignments; see Koehn et al. (2003) for a review. Marcu and Wong (2002) learn phrases directly from sentence pairs using a joint probability model. 3 Subword Extraction 3.1 Motivation for using MDL Consider a lexicon of grapheme subwords !9 and phoneme subwords P that is extracted from a dictionary of word</context>
</contexts>
<marker>Chen, 2003</marker>
<rawString>Stanley F Chen. 2003. Conditional and joint models for grapheme-to-phoneme conversion. In Proceedings of Eurospeech.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carl G de Marcken</author>
</authors>
<title>Unsupervised Language Acquisistion.</title>
<date>1996</date>
<tech>Ph.D. thesis,</tech>
<institution>MIT.</institution>
<marker>de Marcken, 1996</marker>
<rawString>Carl G de Marcken. 1996. Unsupervised Language Acquisistion. Ph.D. thesis, MIT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Deligne</author>
<author>Frederic Bimbot</author>
</authors>
<title>Language modeling by variable length sequences: theoretical formulation and evaluation of multigrams.</title>
<date>1995</date>
<booktitle>In Proceedings of ICASSP.</booktitle>
<contexts>
<context position="3596" citStr="Deligne and Bimbot, 1995" startWordPosition="558" endWordPosition="561">re denoted by their Arpabet representations. 713 Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 713–716, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics Joint-sequence models divide a word-pronunciation pair into a sequence of disjoint graphones or graphonemes – tuples containing grapheme and phoneme subwords. Such segmentations may include only trivial graphones containing subwords of length at most 1 (Chen, 2003). Other such models use EM to learn the maximum likelihood segmentation into graphones (Deligne and Bimbot, 1995; Bisani and Ney, 2008; Vozilla et al., 2003). Subwords – or phrases – are used widely in machine translation. There is a large body of work on phrase extraction starting from word alignments; see Koehn et al. (2003) for a review. Marcu and Wong (2002) learn phrases directly from sentence pairs using a joint probability model. 3 Subword Extraction 3.1 Motivation for using MDL Consider a lexicon of grapheme subwords !9 and phoneme subwords P that is extracted from a dictionary of word-pronunciation pairs, along with a joint probability distribution over !g and P. As stated earlier, our objectiv</context>
</contexts>
<marker>Deligne, Bimbot, 1995</marker>
<rawString>Sabine Deligne and Frederic Bimbot. 1995. Language modeling by variable length sequences: theoretical formulation and evaluation of multigrams. In Proceedings of ICASSP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sittichai Jiampojamarn</author>
<author>Grzegorz Kondrak</author>
</authors>
<title>Online discriminative training for grapheme-tophoneme conversion.</title>
<date>2009</date>
<booktitle>In Proceedings of Interspeech.</booktitle>
<contexts>
<context position="2824" citStr="Jiampojamarn and Kondrak (2009)" startWordPosition="452" endWordPosition="455">‘e’, ‘t’, ‘n’, ‘g’). In the segmentation below, every grapheme subword corresponds to only one phoneme subword: t + ime T + AY M s+t+ing S + T + IH NG neg + a + tion N AH G + EY + SH AH N 2 Related Work Many grapheme-to-phoneme algorithms rely on something resembling subwords; these are mainly used to account for sequences of letters representing a single phoneme (‘ph’ for F), or vice versa (‘x’ for K S). Some of the early works that create one-toone alignments between a word and its pronunciation address these cases by allowing a letter to map to one phoneme, a null phoneme, or 2-3 phonemes. Jiampojamarn and Kondrak (2009) use expectation-maximization (EM) to learn manyto-many alignments between words and pronunciations, effectively obtaining subwords. 1All phonemes are denoted by their Arpabet representations. 713 Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 713–716, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics Joint-sequence models divide a word-pronunciation pair into a sequence of disjoint graphones or graphonemes – tuples containing grapheme and phoneme subwords. Such segmentations may include only trivial gr</context>
</contexts>
<marker>Jiampojamarn, Kondrak, 2009</marker>
<rawString>Sittichai Jiampojamarn and Grzegorz Kondrak. 2009. Online discriminative training for grapheme-tophoneme conversion. In Proceedings of Interspeech.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz Josef Och</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistical phrase-based translation.</title>
<date>2003</date>
<booktitle>In Proceedings of HLT-NAACL.</booktitle>
<contexts>
<context position="3812" citStr="Koehn et al. (2003)" startWordPosition="597" endWordPosition="600">Computational Linguistics Joint-sequence models divide a word-pronunciation pair into a sequence of disjoint graphones or graphonemes – tuples containing grapheme and phoneme subwords. Such segmentations may include only trivial graphones containing subwords of length at most 1 (Chen, 2003). Other such models use EM to learn the maximum likelihood segmentation into graphones (Deligne and Bimbot, 1995; Bisani and Ney, 2008; Vozilla et al., 2003). Subwords – or phrases – are used widely in machine translation. There is a large body of work on phrase extraction starting from word alignments; see Koehn et al. (2003) for a review. Marcu and Wong (2002) learn phrases directly from sentence pairs using a joint probability model. 3 Subword Extraction 3.1 Motivation for using MDL Consider a lexicon of grapheme subwords !9 and phoneme subwords P that is extracted from a dictionary of word-pronunciation pairs, along with a joint probability distribution over !g and P. As stated earlier, our objective is to minimize the entropy of phoneme subwords conditioned on a given grapheme subword, as well as the entropy of the grapheme subwords. That is, we would like to minimize H(P|!9) + H(!9), which is H(�, P) = − � E </context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Philipp Koehn, Franz Josef Och, and Daniel Marcu. 2003. Statistical phrase-based translation. In Proceedings of HLT-NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Amittai Axelrod</author>
<author>Alexandra Birch Mayne</author>
<author>Chris Callison-Burch</author>
<author>Miles Osborne</author>
<author>David Talbot</author>
</authors>
<title>IWSLT Speech Translation Evaluation.</title>
<date>2005</date>
<booktitle>Edinburgh System Description for the</booktitle>
<marker>Koehn, Axelrod, Mayne, Callison-Burch, Osborne, Talbot, 2005</marker>
<rawString>Philipp Koehn, Amittai Axelrod, Alexandra Birch Mayne, Chris Callison-Burch, Miles Osborne, and David Talbot. 2005. Edinburgh System Description for the 2005 IWSLT Speech Translation Evaluation. In Proceedings of IWSLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Marcu</author>
<author>William Wong</author>
</authors>
<title>A phrase-based, joint probability model for statistical machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="3848" citStr="Marcu and Wong (2002)" startWordPosition="604" endWordPosition="607">quence models divide a word-pronunciation pair into a sequence of disjoint graphones or graphonemes – tuples containing grapheme and phoneme subwords. Such segmentations may include only trivial graphones containing subwords of length at most 1 (Chen, 2003). Other such models use EM to learn the maximum likelihood segmentation into graphones (Deligne and Bimbot, 1995; Bisani and Ney, 2008; Vozilla et al., 2003). Subwords – or phrases – are used widely in machine translation. There is a large body of work on phrase extraction starting from word alignments; see Koehn et al. (2003) for a review. Marcu and Wong (2002) learn phrases directly from sentence pairs using a joint probability model. 3 Subword Extraction 3.1 Motivation for using MDL Consider a lexicon of grapheme subwords !9 and phoneme subwords P that is extracted from a dictionary of word-pronunciation pairs, along with a joint probability distribution over !g and P. As stated earlier, our objective is to minimize the entropy of phoneme subwords conditioned on a given grapheme subword, as well as the entropy of the grapheme subwords. That is, we would like to minimize H(P|!9) + H(!9), which is H(�, P) = − � E pr(g, p) log pr(g, p) (1) 9E9 PEP Th</context>
</contexts>
<marker>Marcu, Wong, 2002</marker>
<rawString>Daniel Marcu and William Wong. 2002. A phrase-based, joint probability model for statistical machine translation. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jorma Rissanen</author>
</authors>
<title>Modeling by the shortest data description.</title>
<date>1978</date>
<journal>Automatica.</journal>
<contexts>
<context position="4625" citStr="Rissanen, 1978" startWordPosition="742" endWordPosition="743">ords !9 and phoneme subwords P that is extracted from a dictionary of word-pronunciation pairs, along with a joint probability distribution over !g and P. As stated earlier, our objective is to minimize the entropy of phoneme subwords conditioned on a given grapheme subword, as well as the entropy of the grapheme subwords. That is, we would like to minimize H(P|!9) + H(!9), which is H(�, P) = − � E pr(g, p) log pr(g, p) (1) 9E9 PEP This objective can be restated as minimizing the expected description length of the lexicon, which is given by its entropy. This is reflected in the MDL principle (Rissanen, 1978), which seeks to find a lexicon such that the description length of the lexicon (and the compression of the data under the lexicon) is minimized. 3.2 Lexicon Induction We begin with an initial alignment between a word’s graphemes and the phonemes in its pronunciation for all word-pronunciation pairs in the training dictionary. These alignments are derived using the standard string edit distance dynamic programming algorithm (Wagner and Fischer, 1974), giving a list of tuples t = [(w1, r1), (w2, r2), ...I for each wordpronunciation pair.2 The set of all tuple lists t composes the training dicti</context>
</contexts>
<marker>Rissanen, 1978</marker>
<rawString>Jorma Rissanen. 1978. Modeling by the shortest data description. Automatica.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Vozilla</author>
<author>Jeff Adams</author>
<author>Yuliya Lobacheva</author>
<author>Ryan Thomas</author>
</authors>
<title>Grapheme to phoneme conversion and dictionary verification using graphonemes.</title>
<date>2003</date>
<booktitle>In Proceedings of Eurospeech.</booktitle>
<contexts>
<context position="3641" citStr="Vozilla et al., 2003" startWordPosition="566" endWordPosition="569"> Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 713–716, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics Joint-sequence models divide a word-pronunciation pair into a sequence of disjoint graphones or graphonemes – tuples containing grapheme and phoneme subwords. Such segmentations may include only trivial graphones containing subwords of length at most 1 (Chen, 2003). Other such models use EM to learn the maximum likelihood segmentation into graphones (Deligne and Bimbot, 1995; Bisani and Ney, 2008; Vozilla et al., 2003). Subwords – or phrases – are used widely in machine translation. There is a large body of work on phrase extraction starting from word alignments; see Koehn et al. (2003) for a review. Marcu and Wong (2002) learn phrases directly from sentence pairs using a joint probability model. 3 Subword Extraction 3.1 Motivation for using MDL Consider a lexicon of grapheme subwords !9 and phoneme subwords P that is extracted from a dictionary of word-pronunciation pairs, along with a joint probability distribution over !g and P. As stated earlier, our objective is to minimize the entropy of phoneme subwo</context>
</contexts>
<marker>Vozilla, Adams, Lobacheva, Thomas, 2003</marker>
<rawString>Paul Vozilla, Jeff Adams, Yuliya Lobacheva, and Ryan Thomas. 2003. Grapheme to phoneme conversion and dictionary verification using graphonemes. In Proceedings of Eurospeech.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Wagner</author>
<author>Michael Fischer</author>
</authors>
<title>The stringto-string correction problem.</title>
<date>1974</date>
<journal>Journal of the ACM.</journal>
<contexts>
<context position="5079" citStr="Wagner and Fischer, 1974" startWordPosition="814" endWordPosition="817">ective can be restated as minimizing the expected description length of the lexicon, which is given by its entropy. This is reflected in the MDL principle (Rissanen, 1978), which seeks to find a lexicon such that the description length of the lexicon (and the compression of the data under the lexicon) is minimized. 3.2 Lexicon Induction We begin with an initial alignment between a word’s graphemes and the phonemes in its pronunciation for all word-pronunciation pairs in the training dictionary. These alignments are derived using the standard string edit distance dynamic programming algorithm (Wagner and Fischer, 1974), giving a list of tuples t = [(w1, r1), (w2, r2), ...I for each wordpronunciation pair.2 The set of all tuple lists t composes the training dictionary T . The initial lexicon is composed of all singleton graphemes and phonemes (including null). The probability pr(g, p) is taken to be the number of times the tuple (g, p) occurs in T divided by the total number of tuples over all alignments in T . Following a procedure similar the word-discovery algorithm of de Marcken (1996), the lexicon is iteratively updated as sketched in Table 1. At no point do we delete singleton graphemes or phonemes. Th</context>
</contexts>
<marker>Wagner, Fischer, 1974</marker>
<rawString>Robert Wagner and Michael Fischer. 1974. The stringto-string correction problem. Journal of the ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Zens</author>
<author>Hermann Ney</author>
</authors>
<title>Improvements in phrase-based statistical machine translation.</title>
<date>2004</date>
<booktitle>In Proceedings of HLT-NAACL.</booktitle>
<contexts>
<context position="6663" citStr="Zens and Ney (2004)" startWordPosition="1091" endWordPosition="1094"> these steps out sequentially: first parse the word into grapheme subwords, and then use a sequence labeling algorithm to find the best corresponding sequence of phoneme subwords. However, it is likely that the true pronunciation of a word is not derived from its best parse into grapheme units. For example, the best parse of the word ‘gnat’ is ‘g nat’, which yields the pronunciation G N AE T, while the parse ‘gn at’ would give the correct pronunciation N AE T. Therefore, we search for the best pronunciation over all segmentations of the word, adapting the monotone search algorithm proposed by Zens and Ney (2004) for phrase-based machine translation.3 4.2 Smoothing A bigram model is used over both the grapheme and phoneme subwords. These bigrams need to be smoothed before the decoding step. Adding an equal probability mass to unseen bigrams would fail to reflect simple phonotactics (patterns that govern sound 2Phoneme insertions and deletions are represented by the null grapheme and null phoneme respectively. 3The key adaptation is in using a bigram model over both graphemes and phonemes, rather than only phonemes as in the original algorithm. 714 Table 1: Concatenative algorithm for building a subwor</context>
</contexts>
<marker>Zens, Ney, 2004</marker>
<rawString>Richard Zens and Hermann Ney. 2004. Improvements in phrase-based statistical machine translation. In Proceedings of HLT-NAACL.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>