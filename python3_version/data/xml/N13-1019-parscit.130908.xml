<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000002">
<title confidence="0.979519">
Topic Segmentation with a Structured Topic Model
</title>
<author confidence="0.997506">
Lan Du
</author>
<affiliation confidence="0.997005">
Department of Computing
Macquarie University
</affiliation>
<address confidence="0.567057">
Sydney, Australia
</address>
<email confidence="0.996494">
lan.du@mq.edu.au
</email>
<author confidence="0.935937">
Wray Buntine
</author>
<affiliation confidence="0.865176333333333">
Canberra Research Lab
National ICT Australia
Canberra, Australia
</affiliation>
<email confidence="0.994765">
wray.buntine@nicta.com.au
</email>
<author confidence="0.991984">
Mark Johnson
</author>
<affiliation confidence="0.9967725">
Department of Computing
Macquarie University
</affiliation>
<address confidence="0.567645">
Sydney, Australia
</address>
<email confidence="0.997841">
mark.johnson@mq.edu.au
</email>
<sectionHeader confidence="0.996652" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999872714285714">
We present a new hierarchical Bayesian model
for unsupervised topic segmentation. This new
model integrates a point-wise boundary sam-
pling algorithm used in Bayesian segmenta-
tion into a structured topic model that can cap-
ture a simple hierarchical topic structure latent
in documents. We develop an MCMC infer-
ence algorithm to split/merge segment(s). Ex-
perimental results show that our model out-
performs previous unsupervised segmentation
methods using only lexical information on
Choi’s datasets and two meeting transcripts
and has performance comparable to those pre-
vious methods on two written datasets.
</bodyText>
<sectionHeader confidence="0.998783" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999844529411765">
Documents are usually comprised of topically co-
herent text segments, each of which contains some
number of text passages (e.g., sentences or para-
graphs) (Salton et al., 1996). Within each topically
coherent segment, one would expect that the word
usage demonstrates more consistent lexical distri-
butions (known as lexical cohesion (Eisenstein and
Barzilay, 2008)) than that across segments. A linear
partition of texts into topic segments may reveal in-
formation about, for example, themes of segments
and the overall thematic structure of the text, and
can subsequently be useful for text analysis tasks,
such as information retrieval (e.g., passage retrieval
(Salton et al., 1996)), document summarisation and
discourse analysis (Galley et al., 2003).
In this paper we consider how to automatically
find a topic segmentation. It involves identifying
the most prominent topic changes in a sequence
of text passages, and splits those passages into a
sequence of topically coherent segments (Hearst,
1997; Beeferman et al., 1999). This task can be cast
as an unsupervised machine learning problem: plac-
ing topic boundaries in unannotated text.
Although a variety of cues in text can be used for
topic segmentation, such as cue phases (Beeferman
et al., 1999; Reynar, 1999; Eisenstein and Barzi-
lay, 2008)) and discourse information (Galley et al.,
2003), in this paper, we focus on lexical cohesion
and use it as the primary cue in developing an un-
supervised segmentation model. The effectiveness
of lexical cohesion has been demonstrated by Text-
Tiling (Hearst, 1997), c99 (Choi, 2000), MinCut
(Malioutov and Barzilay, 2006), PLDA (Purver et
al., 2006), Bayesseg (Eisenstein and Barzilay, 2008),
TopicTiling (Riedl and Biemann, 2012), etc.
Our work uses recent progress in hierarchi-
cal topic modelling with non-parametric Bayesian
methods (Du et al., 2010; Chen et al., 2011; Du et
al., 2012a), and is based on Bayesian segmentation
methods (Goldwater et al., 2009; Purver et al., 2006;
Eisenstein and Barzilay, 2008) using topic mod-
els. This can also be viewed as a multi-topic exten-
sion of hierarchical Bayesian segmentation (Eisen-
stein, 2009), although our use of hierarchies is used
to improve the performance of linear segmentation,
rather than develop hierarchical segmentation.
Recently, topic models are increasingly used in
various text analysis tasks including topic segmen-
tation. Previous work (Purver et al., 2006; Misra
et al., 2008; Sun et al., 2008; Misra et al., 2009;
Riedl and Biemann, 2012) has shown that using
</bodyText>
<page confidence="0.972672">
190
</page>
<note confidence="0.472092">
Proceedings of NAACL-HLT 2013, pages 190–200,
Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.999872735849057">
topic assignments or topic distributions instead of
word frequency can significantly improve segmen-
tation performance. Here we consider more ad-
vanced topic models that model dependencies be-
tween (sub-)sections in a document, such as struc-
tured topic models (STMs) presented in (Du et al.,
2010; Du et al., 2012b). STMs treat each text as
a sequence of segments, each of which is a set of
text passages (e.g., a paragraph or sentence). Text
passages in a segment share the same prior distribu-
tion on their topics. The topic distributions of seg-
ments in a single document are then encouraged to
be similar via a hierarchical prior. This gives a sub-
stantial improvement in modelling accuracy. How-
ever, instead of explicitly learning the segmentation,
STMs just leverage the existing structure of docu-
ments from the given segmentation.
Given a sequence of text passages, how can we
automatically learn the segmentation? The word
boundary sampling algorithm introduced in (Gold-
water et al., 2009) uses point-wise sampling of word
boundaries after phonemes in an utterance. Simi-
larly, the segmentation method of PLDA (Purver
et al., 2006) samples segment boundaries, but also
jointly samples a topic model. This is different to
other topic modelling approaches that run LDA as
a precursor to a separate segmentation step (Misra
et al., 2009; Riedl and Biemann, 2012). While con-
ceptually similar to PLDA, our non-parametric ap-
proach built on STM required new methods to im-
plement, but the resulting improvement by the stan-
dard segmentation scores is substantial.
This paper presents a new hierarchical Bayesian
unsupervised topic segmentation model, integrating
a point-wise boundary sampling algorithm with a
structured topic model. This new model takes ad-
vantage of the high modelling accuracy of structured
topic models (Du et al., 2010) to produce a topic
segmentation based on the distribution of latent top-
ics. We show that this model provides high quality
segmentation performance on Choi’s dataset, as well
as two sets of meeting transcripts and written texts.
In the following sections we describe our topic
segmentation model and an MCMC inference al-
gorithm for the non-parametric split/merge pro-
cess. The rest of the paper is organised as follows. In
Section 2 we review recent related work in the topic
segmentation literature. Section 3 presents the new
topic segmentation model, followed by the deriva-
tion of a sampling algorithm in Section 4. We report
the experimental results by comparing several re-
lated topic segmentation methods in Section 5. Sec-
tion 6 concludes the paper.
</bodyText>
<sectionHeader confidence="0.999442" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.9999675">
We are interested in unsupervised topic segmenta-
tion in either written or spoken language. There is a
large body of work on unsupervised topic segmen-
tation of text based on lexical cohesion. It can be
characterised by how lexical cohesion is modelled.
One branch of this work represents the lexical co-
hesion in a vector space by exploring the word co-
occurrence patterns, e.g., TF or TF-IDF. Work fol-
lowing this line includes TextTiling (Hearst, 1997),
which calculates the cosine similarity between two
adjacent blocks of words purely based on the word
frequency; C99 (Choi, 2000), an algorithm based
on divisive clustering with a matrix-ranking scheme;
LSeg (Galley et al., 2003), which uses a lexical
chain to identify and weight word repetitions; U00
(Utiyama and Isahara, 2001), a probalistic approach
using dynamic programming to find a segmenta-
tion with a minimum cost; MinCut (Malioutov and
Barzilay, 2006), which casts segmentation as a graph
cut problem, and APS (Kazantseva and Szpakowicz,
2011), which uses affinity propagation to learn clus-
tering for segmentation.
The other branch of this work characterises the
lexical cohesion using topic models, to which the
model introduced in Section 3 belongs. Lexical co-
hesion in this line of research is modelled by a
probabilistic generative process. PLDA presented by
Purver et al. (2006) is an unsupervised topic mod-
elling approach for segmentation. It chains a set of
LDAs (Blei et al., 2003) by assuming a Markov
structure on topic distributions. A binary topic shift
variable is attached to each text passage (i.e., an ut-
terance in (Purver et al., 2006)). It is sampled to in-
dicate whether the jth text passage shares the topic
distribution with the (j − 1)th passage.
Using a similar Markov structure, SITS (Nguyen
et al., 2012) chains a set of HDP-LDAs (Teh et al.,
2006). Unlike PLDA, SITS assumes each text pas-
sage is associated with a speaker identity that is at-
tached to the topic shift variable as supervising in-
</bodyText>
<page confidence="0.99763">
191
</page>
<bodyText confidence="0.999853428571429">
formation. SITS further assumes speakers have dif-
ferent topic change probabilities that work as pri-
ors on topic shift variables. Instead of assuming
documents in a dataset share the same set of top-
ics, Bayesseg (Eisenstein and Barzilay, 2008) treats
words in a segment generated from a segment spe-
cific multinomial language model, i.e., it assumes
each segment is generated from one topic, and a
later hierarchical extension (Eisenstein, 2009) as-
sumes each segment is generated from one topic or
its parents. Other methods using as input the output
of topic models include (Sun et al., 2008), (Misra et
al., 2009), and (Riedl and Biemann, 2012).
In this paper we take a generative approach ly-
ing between PLDA and SITS. In contrast to PLDA,
which uses a flat topic model (i.e., LDA), we assume
each text has a latent topic structure that can reflect
the topic coherence pattern, and the model adapts its
parameters to the segments to further improve per-
formance. Unlike SITS that targets analysing multi-
party meeting transcripts, where speaker identities
are available, we are interested in more general texts
and assume each text has a specific topic change
probability, since (1) the identity information is not
always available for all kinds of texts (e.g., continu-
ous broadcast news transcripts (Allan et al., 1998)),
(2) even for the same author, topic change probabil-
ities for his/her different articles might be different.
</bodyText>
<sectionHeader confidence="0.803469" genericHeader="method">
3 Segmentation with Topic Models
</sectionHeader>
<bodyText confidence="0.985280741935484">
In documents, topically coherent segments usually
encapsulate a set of consecutive passages that are
semantically related (Wang et al., 2011). However,
the topic boundaries between segments are often un-
available a priori. Thus we treat all passage bound-
aries (e.g., sentence boundaries, paragraph bound-
aries or pauses between utterances) as possible topic
boundaries. To recover the topic boundaries we de-
velop a structured topic segmentation model by inte-
grating ideas from the segmented topic model (Du et
al., 2010, STM) and Bayesian segmentation models.
The basic idea of our model is that each docu-
ment consists of a set of segments where text pas-
sages in the same segment are generated from the
same topic distribution, called segment level topic
distribution. The segment level topic distribution is
drawn from a topic distribution associated with the
whole document, called document level topic distri-
bution. The relationships between the levels is man-
aged using Bayesian non-parametric methods and a
significant change in segment level topic distribution
indicates a segment change.
Our unsupervised topic segmentation model is
based on the premise that using a hierarchical topic
model like the STM with a point-wise segment
sampling algorithm should allow better detection
of topic boundaries. We believe that (1) segment
change should be associated with significant change
in the topic distribution, (2) topic cohesion can be
reflected in document topic structure, (3) the log-
likelihood of a topically coherent segment is typi-
cally higher than an incoherent segment (Misra et
al., 2008).
Assume we have a corpus of D documents, each
document d consists of a sequence of Ud text pas-
sages, and each passage u contains a set of Nd,u
words denoted by wd,u that are from a vocabulary
W. Our model consists of:
Modelling topic boundary: We assume each
document has its own topic shift probability
7rd, a Beta distributed random variable, i.e.,
7rd—Beta(A0, A1). Then, we associate a bound-
ary indicator variable pd,u with u, like the
topic shift variable in PLDA and SITS. pd,u
is Bernoulli distributed with parameter 7rd, i.e.,
pd,u—Bernoulli(7rd). It indicates whether there is a
topic boundary after text passage u or not. To sample
pd,u, we use a point-wise sampling algorithm. Con-
sequently, a sequence of p’s defines a set of seg-
ments, i.e., a topic segmentation of d. For example,
let a p vector p = (0, 0, 1, 0, 1, 0, 0, 1)1, it gives
us three segments, which are {1, 2, 3}, {4, 5} and
{6, 7, 8}.
Modelling topic structure: Following the idea of
the STM, we assume each document d is associated
with a document level topic distribution µd, which
is drawn from a Dirichlet distribution with param-
eter α; and text passages in topic segment s in d
are generated from vd,s, a segment level topic dis-
tribution. The number of segments Sd can be com-
puted as Sd=1 + �U��1
u�1 pd,u. Then, a Pitman-Yor
</bodyText>
<footnote confidence="0.9706345">
1The last 1 in ρ is the document boundary that is know a
priori. This means one does not need to sample it.
</footnote>
<page confidence="0.993615">
192
</page>
<figureCaption confidence="0.999933">
Figure 1: The topic segmentation model
</figureCaption>
<bodyText confidence="0.9983956">
process with a discount parameter a and a concen-
tration parameter b is used to link µd and Vd,s by
Vd,s—PYP(a, b, µd), which forms a simple topic
hierarchy. The idea here is that topics discussed in
segments can be variants of topics of the whole
document. Du et al. (2010) have shown that this
topic structure can significantly improve the mod-
elling accuracy, which should contribute to more ac-
curate segmentation. This generative process is dif-
ferent from PLDA. PLDA does not assume the docu-
ment level topic distribution and each time generates
the segment level topic distribution directly from a
Dirichlet distribution.
The complete probabilistic generative process,
shown as a graph in Figure 1 is as follows:
</bodyText>
<listItem confidence="0.9951702">
1. For each topic k ∈ {1, ... ,K}, draw a word distribution
Ok ∼ DirichletW (γ).
2. For each document d ∈ {1, ... , D},
(a) Draw topic shift probability Mrd ∼ Beta(A0, A1).
(b) Draw µd ∼ DirichletK (α).
(c) For each text passage (except last) u ∈
{1, ... , Ud − 1}, draw Pd,u ∼ Bernoulli(Mrd).
(d) Compute Sd the number of segments as 1 +
[� Ud−1
Lu=1 Pd,u.
(e) For each segment s ∈ {1, ... ,Sd}, draw Vd,s ∼
PYP(a, b, µd).
(f) For each text passage u ∈ {1, ... , Ud},
i. Set segment sd,u = 1 + Eu−1
v=1 Pd,v.
</listItem>
<bodyText confidence="0.336347">
ii. For each word index n ∈ {1, ... , Nd,u},
</bodyText>
<figure confidence="0.602121666666667">
).
A. Draw topic zd,u,n ∼ DiscreteK (Vd,sd,u
B. Draw word wd,u,n ∼ DiscreteK(Ozd,u,J
</figure>
<bodyText confidence="0.99985">
where sd,u indicates which segment text passage u
belongs to. We assume the dimensionality of the
Dirichlet distribution (i.e., the number of topics) is
known and fixed, and word probabilities are param-
eterized with a K x Wmatrix 4&gt; = (O1, ..., OK).
In future work we plan to investigate replace the
</bodyText>
<tableCaption confidence="0.997846">
Table 1: List of statistics
</tableCaption>
<table confidence="0.893261818181818">
Mk,71 total number of words with topic k.
Mk a vector of Mk,711.
nd,s,k total number of words with topic k in segment
s in document d.
Nd,s total number of words in segment s.
td,s,k table count of topic k in the CRP for segment
s in document d.
td,s a vector of td,s,k for segment s in d.
Td,s total table count in segment s.
cd,1 total number of topic boundaries in d.
cd,0 total number of non-topic boundaries in d.
</table>
<bodyText confidence="0.996454">
Dirichlet prior cx on µ with a Pitman-Yor prior (Pit-
man and Yor, 1997) to make the model fully non-
parametric, like SITS.
</bodyText>
<sectionHeader confidence="0.984479" genericHeader="method">
4 Posterior Inference
</sectionHeader>
<bodyText confidence="0.999980821428571">
In this section we develop a collapsed Gibbs sam-
pling algorithm to do an approximate inference
by integrating out some latent variables (i.e., µ’s,
V’s and �d’s). The hierarchy in our model can be
well explained with the Chinese restaurant franchise
metaphor introduced in (Teh et al., 2006). For easier
understanding, terminologies of the Chinese Restau-
rant Process (CRP) will be used throughout this sec-
tion, i.e., customers, dishes and restaurants, corre-
spond to words, topics, and segments respectively.
Statistics used are listed in Table 1.
To integrate out the Vd,s’s generated from the
PYP, we use the technique presented in (Chen et
al., 2011), which computes the joint posterior for
the PYP by summing out all the possible seating
arrangements for a sequence of customers (Teh,
2006). In this technique an auxiliary binary variable,
called table indicator (Sd,u,n), is introduced to fa-
cilitate computing table count td,s,k for topic k. This
method has two effects: (1) faster mixing of the sam-
pler, and (2) elimination of the need for dynamic
memory to store the populations/counts of each ta-
ble in the CRP. In the CRP each word wd,u,n in topic
k (i.e., where zd,u,n=k) contributes a count to nd,s,k
for u C s; and, if wd,u,n, as a customer, also opens
a new table to the CRP, it leads to increasing td,s,k
by one. In this case, Sd,u,n=1 indicates wd,u,n is the
first customer on the table, called table head. Thus,
</bodyText>
<equation confidence="0.994086">
�td,s,k = Nd,uE Sd,u,n1zd,u,,=k . (1)
uEs n=1
</equation>
<bodyText confidence="0.545562">
Note the two constraints on these two counts, i.e.,
</bodyText>
<equation confidence="0.959538333333333">
nd,s,k&gt;td,s,k&gt;0 and td,s,k=0 iff nd,s,k=0 (2)
D
K
</equation>
<page confidence="0.990108">
193
</page>
<bodyText confidence="0.999814043478261">
can be replaced be a simpler constraint in the table
indicator representation.
The sampler we develop is an MCMC sampler
on the space 0 = {z, S, p} where z defines the
topic assignments of words, S maintains the needed
CRP configuration (from which t is derived) and p
defines the segmentation. Moreover, it is not a tra-
ditional Gibbs sampler changing one variable at a
time, but is a block Gibbs sampler where two dif-
ferent kinds of blocks are used. The first block is
(zd,u,n, Sd,u,n) (for each word wd,u,n), which can
be sampled with a table indicator variant of a hier-
archical topic sampler (Du et al., 2010), described
in Section 4.1. This corresponds to Equation (6) in
(Purver et al., 2006). The second kind of block is
a boundary indicator pd,u together with a particular
constrained set of table counts designed to handle
splitting and merging, which corresponds to Equa-
tion (7) in (Purver et al., 2006). Sampling this sec-
ond kind of block is harder in our non-parametric
model requiring a potentially exponential summa-
tion, a problem we overcome using symmetric poly-
nomials, shown in Section 4.2.
</bodyText>
<subsectionHeader confidence="0.999398">
4.1 Sampling Topics
</subsectionHeader>
<bodyText confidence="0.998548285714286">
One step in our model is to sample the assignments
of topics to words conditioned on all p’s. As dis-
cussed in Section 3, given the sequence of pd,u’s,
pd, one can figure out which segment s text passage
u belongs to. Thus, conditioned on a set of segments
s given by p, the joint posterior distribution of w, z
and S is computed as p(z, w, S  |p, 4),, a, b, &apos;y)
</bodyText>
<equation confidence="0.953156">
)
BetaK �α + Es td,s BetaW (&apos;y + Mk)
BetaK (α) kR BetaW (&apos;y)
(b�a)Td,s
td)Nd,s k
RStdda kka (nd,s,k l−1 ,(3)
</equation>
<bodyText confidence="0.9995215">
where BetaK(·) is a K-dimension Beta function,
(x|y)n the Pochhammer symbol2, and Sn�,a the gen-
eralised Stirling number of the second kind (Hsu
and Shiue, 1998)3 precomputed in a table so cost-
</bodyText>
<footnote confidence="0.867538777777778">
2The Pochhammer symbol (x|y)n denotes the rising facto-
rial with a specified increment, i.e., y. It is defined as (x|y)n =
x(x + y)...(x + (n − 1)y).
3A Stirling number of the second kind is used to study
the number of ways of partitioning a set of n objects into
k nonempty subsets. The generalised version given by Hsu
and Shiue (1998) has a linear recursion which in our case is
Sm,a
n+1= Sn m−1,a + (n − ��)Sn m,a.
</footnote>
<bodyText confidence="0.997110833333333">
ing O(1) to use (Buntine and Hutter, 2012).Eq (3)
is an indicator variant of Eq (1) in (Du et al., 2010)
with applying Theorem 1 in (Chen et al., 2011).
Given the current segmentation and topic assign-
ments for all other words, using Bayes rule, we can
derive the following two conditionals from Eq (3):
</bodyText>
<listItem confidence="0.813530333333333">
1. The joint probability of assigning topic k to word
wd,u,n and wd,u,n being a table head, p(zd,u,n =
k, Sd,u,n = 1 |0&apos;)
</listItem>
<equation confidence="0.99549775">
ywi,j,n + Mk,wi,j,n αk + Es td,s,k
Ek αk + Es,k td,s,k
td,s,k + 1 (4)
nd,s,k + 1
</equation>
<bodyText confidence="0.86989">
2. The joint probability of assigning k to wd,u,n
and wd,u,n not being a table head, p(zd,u,n =
</bodyText>
<equation confidence="0.951131625">
k, Sd,u,n = 0 |0&apos;)
= ywi,j,l + Mk,wi,j,l
E
w yw + Mk,w
Snd,s,k+1
td,s,k,a nd,s,k + 1 − td,s,k Snd,s,k nd,s,k + 1 (5)
b + Nd,s
td,s,k,a
</equation>
<bodyText confidence="0.999596">
where 0&apos; = {z−zd,u,n, w, S−δd,u,n, p, α, a, b,&apos;y}.
From the two conditionals, we develop a blocked
Gibbs sampling algorithm for (zd,u,n, Sd,u,n).
</bodyText>
<subsectionHeader confidence="0.999219">
4.2 Sampling Segmentation Boundaries
</subsectionHeader>
<bodyText confidence="0.9998134">
In our model, each segment corresponds to a
Chinese restaurant in the CRP. Sampling topic
boundaries corresponds to splitting/merging restau-
rant(s). This is different from the split-merge process
proposed by Jian and Neal (2004), where one actu-
ally splits/merges table(s). To our knowledge, there
has been no method developed to split/merge restau-
rant(s). We tried different approximations, such
as the minimum-path-assumption (Wallach, 2008),
which in our case assumes one table for each topic
k, and all words in k are placed in the same ta-
ble. Although this simplifies the split-merge pro-
cess, it yielded poor results. We instead developed a
novel approximate block Gibbs sampling algorithm
using symmetric polynomials. Its segmentation per-
formance worked well in our development dataset.
For simplicity, we consider a passage u in doc-
ument d, and assume: (1) If pd,u=1, there are two
segments, sl and sr; sl ends at text passage u, and sr
starts at text passage u+1. (2) If pd,u=0, there is one
</bodyText>
<figure confidence="0.997254538461538">
R=
d
R
d
R
sEs
=
Ew(yw + Mk,w)
b + aTd,s Snd,s,k+1
td,s,k+1,a
b+Nd,s Snd,s,k
td,s,k,a
1
</figure>
<page confidence="0.992554">
194
</page>
<bodyText confidence="0.919193911111111">
segment, sm, where u is is somewhere in the middle
of sm. The split-merge choice we sample is one to
many, for a given split pair (sl, sr) we consider a set
of merged states sm (represented by different possi-
ble table counts). Then, to compute the Gibbs prob-
ability for splitting/merging restaurant(s), we con-
sider the probability of the single split, the probabil-
ity of the corresponding set of merges, and then if a
merge is selected, we have to sample from the set of
merges. These are as follows:
Splitting: split sm into sr and sl by placing a
boundary after u. Since passages have a fixed order
in each document, all the words are put into sr and
sl based on which passages they belong to. Then,
given all the topic assignments, we first sample all
table indicators δd,u,,n, for n E {1, ..., Nd,u,} and
u&apos; E sm using Bernoulli sampling without replace-
ment. It runs as follows: 1) sample δd,u,,n according
to probability td,s.,k/nd,s.,k; 2) decrease td,s.,k if
δd,u,,n = 1, otherwise, just decrease nd,s.,k. Us-
ing the sampled δd,u,,n’s we compute the inferred ta-
ble counts td,s,k (from Eq (1)) and customer counts
nd,s,k respectively for segments s=sl and sr and
topics k. The computation may result in the follow-
ing cases: for a given topic k,
(I) Both sl and sr have nd,s,k&gt;0 and td,s,k&gt;1, which
means both segments have words assigned to k and
words being labelled with table head. According
to constraints (2), after splitting, restaurants corre-
sponding to sl and sr are valid. We do not make any
change on table counts.
(II) Either sl or sr has nd,s,k=0 and td,s,k=0. In this
case, for example, all the words assigned to k in sm
are in sl after splitting, and all those labelled with
table head should also be in sl. sr has no words as-
signed to k. Thus, there is no need to change table
counts.
(III) Either sl or sr has nd,s,k&gt;0 and td,s,k=0. Both seg-
ments have words assigned to k, but those labelled
with table head only exist in one segment. For in-
stance, if they only exist in sl then sr has no table
head, which means the restaurant of sr has customers
eating a dish, but no tables serving that dish. Thus,
we set td,sr,k=1 to make the constraints (2) satisfied.
The Gibbs probability for splitting a segment is
</bodyText>
<equation confidence="0.978102857142857">
p(ρd,u
— 1 |9��) a λ1 + cd,1 (6)
—
λ0 + λ1 + cd,0 + cd,1
(b|a)Td,s Y Snd,s,k
,
(b) Nd,s k td,s,k,a
</equation>
<bodyText confidence="0.881551">
where θ&apos;&apos; = {z, w, S, pρd,u, α, a, b, λ0, λ1}.
Merging: remove the boundary after u, and merge
sr and sl to one segment sm. For this case, both
sr and sl satisfy constraints (2) for all k’s, and set
nd,s.,k=nd,s,,,k + nd,sl,k. The following cases are
considered: for a topic k
(I) Both sl and sr have nd,s,k&gt;0 and td,s,k&gt;1. We
compute td,sm,k using Eq (7). Thus table counts
before and after merging are equal.
(II) Either sl or sr has nd,s,k=0 and td,s,k=0. Similar
to the above case, we use Eq (7).
(III) Both sl and sr have nd,s,k&gt;0, and either of them
has td,s,k=1 or both. We have to choose between
Eq (7) and Eq (8), i.e., to decide whether a table
should be removed or not.
</bodyText>
<equation confidence="0.999967">
td,sm,k = td,sl,k + td,sr,k (7)
td,sm,k = td,sl,k + td,sr,k − 1 (8)
</equation>
<bodyText confidence="0.999954538461538">
Note that choosing Eq (8) means we need to de-
crease the table count td,s.,k by one. The idea here
is that we sample to decide whether the remove table
was added due to splitting case (III) or not. Clearly,
we have a one-to-many split-merge choice. To com-
pute the probability of a set of possible merges,
we use elementary symmetric polynomials as fol-
lows: let KS be a set of topic-segment combinations
that satisfy the condition in merging case (III), for
(k, s) E KS, we sample either Eq (7) or Eq (8).
Let T = {td,s,k : (k, s) E KS} be the set of table
counts affected by the changes of Eq (7) or Eq (8).
The Gibbs probability for merging two segments is
</bodyText>
<equation confidence="0.955910166666667">
Xp(ρd,u = 0  |����) = p(ρd,u = 0, T  |Off/) (9)
T
�
(b|a)Td,smY nd,sm,k
(b) Std, sm , k,a ,
Nd,sm k
</equation>
<bodyText confidence="0.9954005">
where θ&apos;&apos;&apos; = {z, w, t − T , pρd,u, α, a, b, λ0, λ1}.
This is converted to a sum on |T  |booleans with
independent terms and evaluated recursively in
O(|T |2) by symmetric polynomials. If a merge is
chosen, one then samples according to the terms in
the sum using a similar recursion.
</bodyText>
<sectionHeader confidence="0.999548" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<bodyText confidence="0.999">
To demonstrate the effectiveness of our model (de-
noted by TSM) in topic segmentation tasks, we
</bodyText>
<equation confidence="0.924042272727273">
~
X
a
λ0 + λ1 + cd,0 + cd,1
T s=1
λ0 + cd,0 �
BetaK �α + X td,s
Sd
BetaK (α + XSd td� Y
s=1 ,s
sE{sl,srJ
</equation>
<page confidence="0.996616">
195
</page>
<bodyText confidence="0.999930590909091">
evaluate it on three different kinds of corpora4: a
set of synthetic documents, two meeting transcripts
and two sets of text books (see Tables 2 and 3);
and compare TSM with the following methods: two
baselines (the Random algorithm that places topic
boundaries uniformly at random, and the Even al-
gorithm that places a boundary after every mth text
passage, where m is the average gold-standard seg-
ment length (Beeferman et al., 1999)), C99, MinCut,
Bayesseg, APS (Kazantseva and Szpakowicz, 2011),
and PLDA.
Metrics: We evaluated the segmentation perfor-
mance with PK (Beeferman et al., 1999) and Win-
dowDiff (WD&apos;) (Pevzner and Hearst, 2002), which
are two common metrics used in topic segmenta-
tion. Both move a sliding window of fixed size k
over the document, and compare the inferred seg-
mentation with the gold-standard segmentation for
each window. The window size is usually set to
the half of the average gold-standard segment size
(Pevzner and Hearst, 2002). In addition, we also
used an extended WindowDiff proposed by Lam-
prier et al. (2007), denoted by WD&apos;. One problem
of WD&apos; is that errors near the two ends of a text are
penalised less than those in the middle. To solve the
problem WD&apos; adds k fictive text passages at the be-
ginning and the end of the text when computing the
score. We evaluated all the methods with the same
Java code for the three metrics.
Parameter Settings: In order to make all the
methods comparable, we chose for each method
the parameter settings that give the gold-standard
number of segments5. Specifically, we used a
11 x 11 rank mask for C99, as suggested by
Choi (2000), the configurations included in the code
(http://groups.csail.mit.edu/rbg/code)
for Bayesseg and manually tuned parameters for
MinCut. For APS, a greedy approach was used to
search parameter settings that can approximately
give the gold-standard number of segments. For
PLDA, two randomly initialised Gibbs chains were
used. Each chain ran for 75,000 burn-in iterations,
then 1000 samples were drawn at a lag of 25 from
each chain. For TSM, 10 randomly initialised
</bodyText>
<footnote confidence="0.986088">
4For preprocessing, we only removed stop words.
5The segments learnt by those methods will differ, but just
the segment count will be the same as the gold-standard count.
</footnote>
<tableCaption confidence="0.97979">
Table 2: The Choi’s dataset
</tableCaption>
<table confidence="0.999879833333333">
Range of n 3-11 3-5 6-8 9-11
#docs 400 100 100 100
DocLen mean 69.7 39.3 69.6 98.6
std 8.2 2.6 2.9 3.5
SegLen mean 7 4 7 10
std 2.57 0.84 0.87 1.03
</table>
<tableCaption confidence="0.910646">
Table 3: Real dataset statistics
</tableCaption>
<table confidence="0.997911">
ICSI Election Fiction Clinical
# doc 25 4 84 227
DocLen mean 994.5 144.3 325.0 139.5
std 354.5 16.4 230.1 110.4
SegLen mean 188 7 22 35
std 219.1 8.9 23.8 41.7
</table>
<bodyText confidence="0.998930294117647">
Gibbs chains were used. Each chain ran for 30,000
iterations with 25,000 for burn-in, then 200 samples
were drawn. The concentration parameter b in TSM
was sampled using the Adaptive-Reject sampling
scheme introduced in (Du et al., 2012b), the dis-
count parameter a = 0.2, and A0 = A1 = 0.1. To
derive the final segmentation for PLDA and TSM,
we first estimated the marginal probabilities of
placing boundaries after text passages from the total
of 2000 samples. These probabilities were then
thresholded to give the gold-standard number of
segments. Precisely, we apply a small amount of
Gaussian smoothing to the marginal probabilities
(except for Choi’s dataset), like Puerver et al. (2006)
does. Finally, we used a symmetric Dirichlet prior
in PLDA and STM, the one on topic distributions is
a = 0.1, the other on word distributions -y = 0.01.
</bodyText>
<subsectionHeader confidence="0.998864">
5.1 Evaluation on Choi’s Dataset
</subsectionHeader>
<bodyText confidence="0.999828">
Choi’s dataset (Choi, 2000) is commonly used in
evaluating topic segmentation methods. It consists
of 700 documents, each being a concatenation of 10
segments. Each segment is the first n sentences of
a randomly selected document from the Brown cor-
pus, s.t. 3 &lt; n &lt; 11. Those documents are divided
into 4 subsets with different range of n, as shown in
Table 2. We ran PLDA and STM with 50 topics. Re-
sults in Table 4 show that our model significantly
outperforms all the other methods on the four sub-
sets over all the metrics. Furthermore, comparing to
other published results, this also outperforms (Misra
et al., 2009) (see their table 2), and (Riedl and Bie-
mann, 2012) (they report an average of 1.04 and 1.06
in Tables 1 and 2, whereas TSM averages 0.93). This
gives TSM the best reported results to date.
</bodyText>
<page confidence="0.99934">
196
</page>
<tableCaption confidence="0.999881">
Table 4: Comparison on Choi’s datasets with WD and PK (%)
</tableCaption>
<table confidence="0.9999288">
3-11 3-5 6-8 9-11
WDT WDe PK WDT WDe PK WDT WDe PK WDT WDe PK
Random 51.7 49.1 48.7 51.4 50.0 48.4 52.5 49.9 49.2 52.4 48.9 49.2
Even 49.1 46.7 49.0 46.3 45.8 46.3 38.8 37.3 38.8 30.0 28.6 30.0
MinCut 30.4 29.8 26.7 41.6 41.5 37.3 28.2 27.4 25.5 23.6 22.7 21.6
APS 40.7 38.8 38.4 32.0 30.6 31.8 34.4 32.6 32.7 34.5 32.2 33.2
C99 13.5 12.3 12.3 11.3 10.2 10.8 10.2 9.3 9.8 8.9 8.1 8.6
Bayesseg 11.6 10.9 10.9 11.8 11.5 11.1 7.7 7.2 7.3 6.1 5.7 5.7
PLDA 2.4 2.2 1.8 4.0 3.9 3.3 3.6 3.5 2.7 3.0 2.8 2.0
TSM 0.8 0.8 0.6 1.3 1.3 1.0 1.4 1.4 0.9 1.9 1.8 1.2
</table>
<tableCaption confidence="0.999298">
Table 5: Comparison on the meeting transcripts and written texts with WD and PK (%)
</tableCaption>
<table confidence="0.9995955">
ICSI Election Fiction Clinical
WDT WDe PK WDT WDe PK WDT WDe PK WDT WDe PK
Random 46.3 41.7 44.1 51.0 49.7 45.1 51.0 48.7 47.5 45.9 38.5 44.1
Even 48.3 43.0 46.4 56.0 55.1 51.2 48.1 45.9 46.3 49.2 42.0 48.8
C99 42.9 37.4 39.9 43.1 41.5 37.0 48.1 45.1 42.1 39.7 31.9 38.7
MinCut 40.6 36.9 36.9 43.6 43.3 39.0 40.5 39.7 37.1 38.2 36.2 36.8
APS 58.2 49.7 54.6 47.7 36.8 40.6 48.0 45.8 45.1 39.9 32.8 39.6
Bayesseg 32.4 29.7 26.7 41.1 41.3 34.1 33.7 32.8 27.8 35.0 28.8 34.0
PLDA 32.6 28.8 29.4 40.6 41.1 32.0 43.0 41.3 36.1 37.3 32.1 32.4
TSM 30.2 26.8 25.8 38.1 38.9 31.3 40.8 38.7 32.5 34.5 29.1 30.6
</table>
<equation confidence="0.981071">
P(P=1)
P(P = 1)
</equation>
<bodyText confidence="0.999959454545455">
Note the lexical transitions in these concatenated
documents are very sharp (Malioutov and Barzi-
lay, 2006). The sharp transitions lead to significant
change in segment level topic distributions, which
further implies the variance of these distributions is
large. In TSM, a large variance causes a small con-
centration parameter b. We observed that the sam-
pled b’s (about 0.1) are indeed small for the four sub-
sets, which shows there is no topic sharing among
segments. Therefore, TSM is able to recognise the
segments are unrelated text.
</bodyText>
<subsectionHeader confidence="0.999854">
5.2 Evaluation on Meeting Transcripts
</subsectionHeader>
<bodyText confidence="0.99916625">
We applied our model to segmenting the two meet-
ing transcripts, which are the ICSI meeting tran-
scripts (Janin et al., 2003) and the 2008 presidential
election debates (Boydstun et al., 2011). The ICSI
meeting has 75 transcripts, we used the 25 annotated
transcripts provided by Galley et al. (2003) for eval-
uation. For the election debates, we used the four
annotated debates used in (Nguyen et al., 2012). The
statistics are shown in Table 3. PLDA and TSM were
trained with 10 topics on the ICSI and 50 on the
Election. In this set of experiments, we show that
our model is robust to meeting transcripts.
</bodyText>
<figure confidence="0.990643">
TSM
0.2
0
PIDA
0.2
0
0 100 200 300 400 500 600 700 800
Utterance position in sequence
</figure>
<figureCaption confidence="0.968901333333333">
Figure 2: Probability of a topic boundary, compared with
gold-standard segmentation (shown in red and at the top
of each diagram) on one ICSI transcript.
</figureCaption>
<bodyText confidence="0.999957733333333">
As shown in Table 5, topic modelling based meth-
ods (i.e., Bayesseg, PLDA and TSM) outperform
those using either TF or TF-IDF, which is consistent
with previously reported results (Misra et al., 2009;
Riedl and Biemann, 2012). Among the topic model
based methods, TSM achieves the best results on all
the three metrics. On the ICSI transcripts, TSM per-
forms 6.8%, 9.7% and 3.4% better than Bayesseg
on the WD&apos;, WDe and PK metrics respectively. Fig-
ure 2 shows an example of how the inferred topic
boundary probabilities at utterances compare with
the gold-standard boundaries on one ICSI meeting
transcript. The gold-standard segmentation is {77,
95, 189, 365, 508, 609, 8601, TSM and PLDA in-
fer {85, 96, 188, 363, 499, 508, 860} and {96, 136,
</bodyText>
<figure confidence="0.98649075">
0.6
0.4
0.6
0.4
</figure>
<page confidence="0.977594">
197
</page>
<tableCaption confidence="0.985542">
Table 6: Sampled concentration parameters
</tableCaption>
<table confidence="0.79161">
Choi ICSI Election Fiction Clinical
b 0.1 5.2 5.4 18.4 4.8
</table>
<bodyText confidence="0.998778333333333">
203, 226, 361, 508, 8601 respectively. Both models
miss the boundary after the 609th utterance, but put a
boundary after the 508th utterance. Note the bound-
aries placed by TSM are always within 10 utterances
with respect to the gold standard.
Although TSM still performs the best on the de-
bates, all the methods have relatively worse perfor-
mance than on the ICSI meeting transcripts. Nguyen
et al. (2012) pointed out that the ICSI meetings are
characterised by pragmatic topic changes, in con-
trast, the debates are characterised by strategic topic
changes with strong rewards for setting the agenda,
dodging a question, etc. Thus, considering the prop-
erties of debates might further improve the segmen-
tation performance.
</bodyText>
<subsectionHeader confidence="0.998427">
5.3 Evaluation on Written Texts
</subsectionHeader>
<bodyText confidence="0.999987727272727">
We further tested TSM on two written text datasets,
Clinical (Eisenstein and Barzilay, 2008) and Fiction
(Kazantseva and Szpakowicz, 2011). The statistics
are shown in Table 3. Each document in the Clinical
dataset is a chapter of a medical textbook. Section
breaks are selected to be the true topic boundaries.
For the Fiction dataset, each document is a fiction
downloaded from Project Gutenberg, the true topic
boundaries are chapter breaks. We trained PLDA
and TSM with 25 topics on the Fiction and 50 on the
Clinical. Results are shown in Table 5. TSM com-
pares favourably with Bayesseg and outperforms the
other methods on the Clinical dataset, but it does not
perform as well as Bayesseg on the Fiction dataset.
In fiction books, the topic boundaries between
sections are usually blurred by the authors for rea-
sons of continuity (Reynar, 1999). We observed that
the sampled concentration (or inverse variance) pa-
rameter b in TSM is about 18.4 on Fiction, but 4.8 on
Clinical, as shown in Table 6. This means the vari-
ance of segment level topic distributions v learnt by
TSM is not large for the fiction, so chapter breaks
may not necessarily indicate topic changes. For ex-
ample, there is a document in the Fiction dataset
where gold-standard topic boundaries are placed af-
ter each block of text. In contrast, Bayesseg assumes
each segment has its own distribution over words,
i.e., one topic per segment, which means topics are
not shared among segments. We hypothesize that
for certain kinds of documents where the change in
topic distribution is subtle, such as fiction, assuming
one topic per segment can capture subtle changes in
word usage. This is an area for future investigation.
</bodyText>
<sectionHeader confidence="0.998918" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999971153846154">
In this paper, we have presented a hierarchical
Bayesian model for unsupervised topic segmen-
tation. This new model takes advances of both
Bayesian segmentation and structured topic mod-
elling. It uses a point-wise boundary sampling al-
gorithm to sample a topic segmentation, while con-
currently building a structured topic model. We
have developed a novel approximation to com-
pute the Gibbs probabilities of spliting/merging seg-
ment(s). Our model shows prominent segmentation
performance on both written or spoken texts.
In future work, we would like to make the model
fully nonparametric and investigate the effects of
adding different cues in texts, such as cue phrases,
pronoun usage, prosody, etc. Currently, our model
uses marginal boundary probabilities to generate
the final segmentation. Instead, we could develop a
Metropolis-Hasting sampling algorithm to move one
boundary at a time, given the gold-standard number
of segments. To further study the effectiveness of
our model, we would like to compare it with other
methods, like SITS (Nguyen et al., 2012) and to run
on more datasets, like email (Joty et al., 2010). For
example, in order to compare with SITS, one can
make an assumption that each document just has one
speaker.
</bodyText>
<sectionHeader confidence="0.996979" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999633">
The authors would like to thank all the anony-
mous reviewers for their valuable comments.
This research was supported under Australian
Research Council’s Discovery Projects funding
scheme (project numbers DP110102506 and
DP110102593). NICTA is funded by the Australian
Government as represented by the Department
of Broadband, Communications and the Digital
Economy and the Australian Research Council
through the ICT Centre of Excellence program.
</bodyText>
<page confidence="0.998007">
198
</page>
<sectionHeader confidence="0.982087" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999752575471698">
J. Allan, J. Carbonell, G. Doddington, J. Yamron, and
Y. Yang. 1998. Topic detection and tracking pi-
lot study: Final report. In Proceedings of the
DARPA Broadcast News Transcription and Under-
standing Workshop, pages 194–218.
Doug Beeferman, Adam Berger, and John Lafferty.
1999. Statistical models for text segmentation. Mach.
Learn., 34(1-3):177–210.
David M. Blei, Andrew Y. Ng, and Michael I. Jordan.
2003. Latent Dirichlet allocation. J. Mach. Learn.
Res., 3:993–1022.
A.E. Boydstun, C. Phillips, and R.A. Glazier. 2011. Its
the economy again, stupid: Agenda control in the 2008
presidential debates.
W. Buntine and M. Hutter. 2012. A Bayesian review
of the Poisson-Dirichlet process. Technical Report
arXiv:1007.0296v2, ArXiv, Cornell.
Changyou Chen, Lan Du, and Wray Buntine. 2011.
Sampling for the Poisson-Dirichlet process. In Euro-
pean Conference on Machine Learning and Principles
and Practice of Knowledge Discovery in Database,
pages 296–311.
Freddy Y. Y. Choi. 2000. Advances in domain inde-
pendent linear text segmentation. In Proceedings of
the 1st North American chapter of the Association for
Computational Linguistics conference, NAACL 2000,
pages 26–33.
Lan Du, Wray Buntine, and Huidong Jin. 2010. A
segmented topic model based on the two-parameter
Poisson-Dirichlet process. Mach. Learn., 81(1):5–19.
Lan Du, Wray Buntine, and Huidong Jin. 2012a. Mod-
elling sequential text with an adaptive topic model.
In Proceedings of the 2012 Joint Conference on Em-
pirical Methods in Natural Language Processing and
Computational Natural Language Learning, pages
535–545.
Lan Du, Wray Buntine, Huidong Jin, and Changyou
Chen. 2012b. Sequential latent Dirichlet allocation.
Knowledge and Information Systems, 31(3):475–503.
Jacob Eisenstein and Regina Barzilay. 2008. Bayesian
unsupervised topic segmentation. In Proceedings of
the Conference on Empirical Methods in Natural Lan-
guage Processing, EMNLP’08, pages 334–343.
Jacob Eisenstein. 2009. Hierarchical text segmentation
from multi-scale lexical cohesion. In Human Lan-
guage Technologies: Conference of the North Amer-
ican Chapter of the Association of Computational Lin-
guistics, pages 353–361. The Association for Compu-
tational Linguistics.
Michel Galley, Kathleen R. McKeown, Eric Fosler-
Lussier, and Hongyan Jing. 2003. Discourse segmen-
tation of multi-party conversation. In Proceedings of
the 41st Annual Meeting of the Association for Com-
putational Linguistics, pages 562–569.
Sharon Goldwater, Thomas L. Griffiths, and Mark John-
son. 2009. A Bayesian framework for word segmen-
tation: Exploring the effects of context. Cognition,
112(1):21–53.
Marti A. Hearst. 1997. TextTiling: segmenting text
into multi-paragraph subtopic passages. Comput. Lin-
guist., 23(1):33–64.
Leetsch C. Hsu and Peter Jau-Shyong Shiue. 1998. A
unified approach to generalized Stirling numbers. Adv.
Appl. Math., 20:366–384, April.
Sonia Jain and Radford Neal. 2004. A split-merge
Markov chain Monte Carlo procedure for the Dirichlet
process mixture model. Journal of Computational and
Graphical Statistics, 13(1):158–182.
A. Janin, D. Baron, J. Edwards, D. Ellis, D. Gelbart,
N. Morgan, B. Peskin, T. Pfau, E. Shriberg, A. Stolcke,
and C. Wooters. 2003. The ICSI Meeting Corpus. In
Proceedings of 2003 IEEE International Conference
on Acoustics, Speech, and Signal (ICASSP ’03), pages
364–367.
Shafiq Joty, Giuseppe Carenini, Gabriel Murray, and
Raymond T. Ng. 2010. Exploiting conversation struc-
ture in unsupervised topic segmentation for emails.
In Proceedings of the 2010 Conference on Empirical
Methods in Natural Language Processing, pages 388–
398.
Anna Kazantseva and Stan Szpakowicz. 2011. Linear
text segmentation using affinity propagation. In Pro-
ceedings of the 2011 Conference on Empirical Meth-
ods in Natural Language Processing, pages 284–293.
Sylvain Lamprier, Tassadit Amghar, Bernard Levrat, and
Frederic Saubion. 2007. On evaluation methodologies
for text segmentation algorithms. In Proceedings of
the 19th IEEE International Conference on Tools with
Artificial Intelligence - Volume 02, ICTAI ’07, pages
19–26.
Igor Malioutov and Regina Barzilay. 2006. Minimum
cut model for spoken lecture segmentation. In Pro-
ceedings of the 21st International Conference on Com-
putational Linguistics and the 44th annual meeting of
the Association for Computational Linguistics, ACL-
44, pages 25–32.
Hemant Misra, Olivier Cappe, and Francois Yvon. 2008.
Using LDA to detect semantically incoherent docu-
ments. In Proceedings of CoNLL-08, pages 41–48.
Hemant Misra, Franc¸ois Yvon, Joemon M. Jose, and
Olivier Cappe. 2009. Text segmentation via topic
modeling: an analytical study. In Proceedings of the
18th ACM conference on Information and knowledge
management, CIKM ’09, pages 1553–1556.
Viet-An Nguyen, Jordan Boyd-Graber, and Philip
Resnik. 2012. SITS: A hierarchical nonparametric
</reference>
<page confidence="0.985964">
199
</page>
<reference confidence="0.998782352941176">
model using speaker identity for topic segmentation in
multiparty conversations. In Proceedings of the 50th
Annual Meeting of the Association for Computational
Linguistics (Volume 1: Long Papers), pages 78–87.
Lev Pevzner and Marti A. Hearst. 2002. A critique and
improvement of an evaluation metric for text segmen-
tation. Comput. Linguist., 28(1):19–36.
J. Pitman and M. Yor. 1997. The two-parameter Poisson-
Diriclet distribution derived from a stable subordina-
tor. Annals Probability, 25:855–900.
Matthew Purver, Thomas L. Griffiths, Konrad P. K¨ording,
and Joshua B. Tenenbaum. 2006. Unsupervised topic
modelling for multi-party spoken discourse. In Pro-
ceedings of the 21st International Conference on Com-
putational Linguistics and the 44th annual meeting of
the Association for Computational Linguistics, ACL-
44, pages 17–24.
Jeffrey C. Reynar. 1999. Statistical models for topic seg-
mentation. In Proceedings of the 37th Annual Meet-
ing of the Association for Computational Linguistics,
pages 357–364.
Martin Riedl and Chris Biemann. 2012. How text seg-
mentation algorithms gain from topic models. In Pro-
ceedings of the 2012 Conference of the North Ameri-
can Chapter of the Association for Computational Lin-
guistics: Human Language Technologies.
Gerard Salton, Amit Singhal, Chris Buckley, and Mandar
Mitra. 1996. Automatic text decomposition using text
segments and text themes. In Proceedings of the the
seventh ACM conference on Hypertext, pages 53–65.
Qi Sun, Runxin Li, Dingsheng Luo, and Xihong Wu.
2008. Text segmentation with LDA-based Fisher ker-
nel. In Proceedings of ACL-08: HLT, Short Papers,
pages 269–272.
Y. W. Teh, M. I. Jordan, M. J. Beal, and D. M. Blei. 2006.
Hierarchical Dirichlet processes. Journal of the Amer-
ican Statistical Association, 101(476):1566–1581.
Y. W. Teh. 2006. A Bayesian interpretation of interpo-
lated Kneser-Ney. Technical Report TRA2/06, School
of Computing, National University of Singapore.
Masao Utiyama and Hitoshi Isahara. 2001. A statistical
model for domain-independent text segmentation. In
Proceedings of 39th Annual Meeting of the Associa-
tion for Computational Linguistics, pages 499–506.
H.M. Wallach. 2008. Structured topic models for lan-
guage. doctoral dissertation, Univ. of Cambridge.
Hongning Wang, Duo Zhang, and ChengXiang Zhai.
2011. Structural topic model for latent topical struc-
ture analysis. In Proceedings of the 49th Annual Meet-
ing of the Association for Computational Linguistics:
Human Language Technologies, pages 1526–1535.
</reference>
<page confidence="0.996546">
200
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.074610">
<title confidence="0.996686">Topic Segmentation with a Structured Topic Model</title>
<author confidence="0.94039">Lan</author>
<affiliation confidence="0.7155365">Department of Macquarie</affiliation>
<address confidence="0.413278">Sydney,</address>
<email confidence="0.99789">lan.du@mq.edu.au</email>
<author confidence="0.900032">Wray</author>
<affiliation confidence="0.9979055">Canberra Research National ICT</affiliation>
<address confidence="0.675774">Canberra,</address>
<email confidence="0.998349">wray.buntine@nicta.com.au</email>
<author confidence="0.992359">Mark</author>
<affiliation confidence="0.987424">Department of</affiliation>
<title confidence="0.409603">Macquarie</title>
<author confidence="0.48592">Sydney</author>
<email confidence="0.997672">mark.johnson@mq.edu.au</email>
<abstract confidence="0.9992126">We present a new hierarchical Bayesian model for unsupervised topic segmentation. This new model integrates a point-wise boundary sampling algorithm used in Bayesian segmentation into a structured topic model that can capture a simple hierarchical topic structure latent in documents. We develop an MCMC inference algorithm to split/merge segment(s). Experimental results show that our model outperforms previous unsupervised segmentation methods using only lexical information on Choi’s datasets and two meeting transcripts and has performance comparable to those previous methods on two written datasets.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Allan</author>
<author>J Carbonell</author>
<author>G Doddington</author>
<author>J Yamron</author>
<author>Y Yang</author>
</authors>
<title>Topic detection and tracking pilot study: Final report.</title>
<date>1998</date>
<booktitle>In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop,</booktitle>
<pages>194--218</pages>
<contexts>
<context position="9535" citStr="Allan et al., 1998" startWordPosition="1502" endWordPosition="1505">ween PLDA and SITS. In contrast to PLDA, which uses a flat topic model (i.e., LDA), we assume each text has a latent topic structure that can reflect the topic coherence pattern, and the model adapts its parameters to the segments to further improve performance. Unlike SITS that targets analysing multiparty meeting transcripts, where speaker identities are available, we are interested in more general texts and assume each text has a specific topic change probability, since (1) the identity information is not always available for all kinds of texts (e.g., continuous broadcast news transcripts (Allan et al., 1998)), (2) even for the same author, topic change probabilities for his/her different articles might be different. 3 Segmentation with Topic Models In documents, topically coherent segments usually encapsulate a set of consecutive passages that are semantically related (Wang et al., 2011). However, the topic boundaries between segments are often unavailable a priori. Thus we treat all passage boundaries (e.g., sentence boundaries, paragraph boundaries or pauses between utterances) as possible topic boundaries. To recover the topic boundaries we develop a structured topic segmentation model by inte</context>
</contexts>
<marker>Allan, Carbonell, Doddington, Yamron, Yang, 1998</marker>
<rawString>J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang. 1998. Topic detection and tracking pilot study: Final report. In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194–218.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Doug Beeferman</author>
<author>Adam Berger</author>
<author>John Lafferty</author>
</authors>
<title>Statistical models for text segmentation.</title>
<date>1999</date>
<pages>34--1</pages>
<location>Mach. Learn.,</location>
<contexts>
<context position="1997" citStr="Beeferman et al., 1999" startWordPosition="283" endWordPosition="286">ition of texts into topic segments may reveal information about, for example, themes of segments and the overall thematic structure of the text, and can subsequently be useful for text analysis tasks, such as information retrieval (e.g., passage retrieval (Salton et al., 1996)), document summarisation and discourse analysis (Galley et al., 2003). In this paper we consider how to automatically find a topic segmentation. It involves identifying the most prominent topic changes in a sequence of text passages, and splits those passages into a sequence of topically coherent segments (Hearst, 1997; Beeferman et al., 1999). This task can be cast as an unsupervised machine learning problem: placing topic boundaries in unannotated text. Although a variety of cues in text can be used for topic segmentation, such as cue phases (Beeferman et al., 1999; Reynar, 1999; Eisenstein and Barzilay, 2008)) and discourse information (Galley et al., 2003), in this paper, we focus on lexical cohesion and use it as the primary cue in developing an unsupervised segmentation model. The effectiveness of lexical cohesion has been demonstrated by TextTiling (Hearst, 1997), c99 (Choi, 2000), MinCut (Malioutov and Barzilay, 2006), PLDA</context>
<context position="25543" citStr="Beeferman et al., 1999" startWordPosition="4393" endWordPosition="4396">he effectiveness of our model (denoted by TSM) in topic segmentation tasks, we ~ X a λ0 + λ1 + cd,0 + cd,1 T s=1 λ0 + cd,0 � BetaK �α + X td,s Sd BetaK (α + XSd td� Y s=1 ,s sE{sl,srJ 195 evaluate it on three different kinds of corpora4: a set of synthetic documents, two meeting transcripts and two sets of text books (see Tables 2 and 3); and compare TSM with the following methods: two baselines (the Random algorithm that places topic boundaries uniformly at random, and the Even algorithm that places a boundary after every mth text passage, where m is the average gold-standard segment length (Beeferman et al., 1999)), C99, MinCut, Bayesseg, APS (Kazantseva and Szpakowicz, 2011), and PLDA. Metrics: We evaluated the segmentation performance with PK (Beeferman et al., 1999) and WindowDiff (WD&apos;) (Pevzner and Hearst, 2002), which are two common metrics used in topic segmentation. Both move a sliding window of fixed size k over the document, and compare the inferred segmentation with the gold-standard segmentation for each window. The window size is usually set to the half of the average gold-standard segment size (Pevzner and Hearst, 2002). In addition, we also used an extended WindowDiff proposed by Lamprier</context>
</contexts>
<marker>Beeferman, Berger, Lafferty, 1999</marker>
<rawString>Doug Beeferman, Adam Berger, and John Lafferty. 1999. Statistical models for text segmentation. Mach. Learn., 34(1-3):177–210.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Blei</author>
<author>Andrew Y Ng</author>
<author>Michael I Jordan</author>
</authors>
<title>Latent Dirichlet allocation.</title>
<date>2003</date>
<journal>J. Mach. Learn. Res.,</journal>
<pages>3--993</pages>
<contexts>
<context position="7684" citStr="Blei et al., 2003" startWordPosition="1190" endWordPosition="1193">o find a segmentation with a minimum cost; MinCut (Malioutov and Barzilay, 2006), which casts segmentation as a graph cut problem, and APS (Kazantseva and Szpakowicz, 2011), which uses affinity propagation to learn clustering for segmentation. The other branch of this work characterises the lexical cohesion using topic models, to which the model introduced in Section 3 belongs. Lexical cohesion in this line of research is modelled by a probabilistic generative process. PLDA presented by Purver et al. (2006) is an unsupervised topic modelling approach for segmentation. It chains a set of LDAs (Blei et al., 2003) by assuming a Markov structure on topic distributions. A binary topic shift variable is attached to each text passage (i.e., an utterance in (Purver et al., 2006)). It is sampled to indicate whether the jth text passage shares the topic distribution with the (j − 1)th passage. Using a similar Markov structure, SITS (Nguyen et al., 2012) chains a set of HDP-LDAs (Teh et al., 2006). Unlike PLDA, SITS assumes each text passage is associated with a speaker identity that is attached to the topic shift variable as supervising in191 formation. SITS further assumes speakers have different topic chang</context>
</contexts>
<marker>Blei, Ng, Jordan, 2003</marker>
<rawString>David M. Blei, Andrew Y. Ng, and Michael I. Jordan. 2003. Latent Dirichlet allocation. J. Mach. Learn. Res., 3:993–1022.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A E Boydstun</author>
<author>C Phillips</author>
<author>R A Glazier</author>
</authors>
<title>Its the economy again, stupid: Agenda control in the 2008 presidential debates.</title>
<date>2011</date>
<contexts>
<context position="31493" citStr="Boydstun et al., 2011" startWordPosition="5456" endWordPosition="5459">ficant change in segment level topic distributions, which further implies the variance of these distributions is large. In TSM, a large variance causes a small concentration parameter b. We observed that the sampled b’s (about 0.1) are indeed small for the four subsets, which shows there is no topic sharing among segments. Therefore, TSM is able to recognise the segments are unrelated text. 5.2 Evaluation on Meeting Transcripts We applied our model to segmenting the two meeting transcripts, which are the ICSI meeting transcripts (Janin et al., 2003) and the 2008 presidential election debates (Boydstun et al., 2011). The ICSI meeting has 75 transcripts, we used the 25 annotated transcripts provided by Galley et al. (2003) for evaluation. For the election debates, we used the four annotated debates used in (Nguyen et al., 2012). The statistics are shown in Table 3. PLDA and TSM were trained with 10 topics on the ICSI and 50 on the Election. In this set of experiments, we show that our model is robust to meeting transcripts. TSM 0.2 0 PIDA 0.2 0 0 100 200 300 400 500 600 700 800 Utterance position in sequence Figure 2: Probability of a topic boundary, compared with gold-standard segmentation (shown in red </context>
</contexts>
<marker>Boydstun, Phillips, Glazier, 2011</marker>
<rawString>A.E. Boydstun, C. Phillips, and R.A. Glazier. 2011. Its the economy again, stupid: Agenda control in the 2008 presidential debates.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Buntine</author>
<author>M Hutter</author>
</authors>
<title>A Bayesian review of the Poisson-Dirichlet process.</title>
<date>2012</date>
<tech>Technical Report arXiv:1007.0296v2,</tech>
<location>ArXiv, Cornell.</location>
<contexts>
<context position="18807" citStr="Buntine and Hutter, 2012" startWordPosition="3140" endWordPosition="3143">sion Beta function, (x|y)n the Pochhammer symbol2, and Sn�,a the generalised Stirling number of the second kind (Hsu and Shiue, 1998)3 precomputed in a table so cost2The Pochhammer symbol (x|y)n denotes the rising factorial with a specified increment, i.e., y. It is defined as (x|y)n = x(x + y)...(x + (n − 1)y). 3A Stirling number of the second kind is used to study the number of ways of partitioning a set of n objects into k nonempty subsets. The generalised version given by Hsu and Shiue (1998) has a linear recursion which in our case is Sm,a n+1= Sn m−1,a + (n − ��)Sn m,a. ing O(1) to use (Buntine and Hutter, 2012).Eq (3) is an indicator variant of Eq (1) in (Du et al., 2010) with applying Theorem 1 in (Chen et al., 2011). Given the current segmentation and topic assignments for all other words, using Bayes rule, we can derive the following two conditionals from Eq (3): 1. The joint probability of assigning topic k to word wd,u,n and wd,u,n being a table head, p(zd,u,n = k, Sd,u,n = 1 |0&apos;) ywi,j,n + Mk,wi,j,n αk + Es td,s,k Ek αk + Es,k td,s,k td,s,k + 1 (4) nd,s,k + 1 2. The joint probability of assigning k to wd,u,n and wd,u,n not being a table head, p(zd,u,n = k, Sd,u,n = 0 |0&apos;) = ywi,j,l + Mk,wi,j,l</context>
</contexts>
<marker>Buntine, Hutter, 2012</marker>
<rawString>W. Buntine and M. Hutter. 2012. A Bayesian review of the Poisson-Dirichlet process. Technical Report arXiv:1007.0296v2, ArXiv, Cornell.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Changyou Chen</author>
<author>Lan Du</author>
<author>Wray Buntine</author>
</authors>
<title>Sampling for the Poisson-Dirichlet process.</title>
<date>2011</date>
<booktitle>In European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Database,</booktitle>
<pages>296--311</pages>
<contexts>
<context position="2841" citStr="Chen et al., 2011" startWordPosition="417" endWordPosition="420">9; Reynar, 1999; Eisenstein and Barzilay, 2008)) and discourse information (Galley et al., 2003), in this paper, we focus on lexical cohesion and use it as the primary cue in developing an unsupervised segmentation model. The effectiveness of lexical cohesion has been demonstrated by TextTiling (Hearst, 1997), c99 (Choi, 2000), MinCut (Malioutov and Barzilay, 2006), PLDA (Purver et al., 2006), Bayesseg (Eisenstein and Barzilay, 2008), TopicTiling (Riedl and Biemann, 2012), etc. Our work uses recent progress in hierarchical topic modelling with non-parametric Bayesian methods (Du et al., 2010; Chen et al., 2011; Du et al., 2012a), and is based on Bayesian segmentation methods (Goldwater et al., 2009; Purver et al., 2006; Eisenstein and Barzilay, 2008) using topic models. This can also be viewed as a multi-topic extension of hierarchical Bayesian segmentation (Eisenstein, 2009), although our use of hierarchies is used to improve the performance of linear segmentation, rather than develop hierarchical segmentation. Recently, topic models are increasingly used in various text analysis tasks including topic segmentation. Previous work (Purver et al., 2006; Misra et al., 2008; Sun et al., 2008; Misra et </context>
<context position="15632" citStr="Chen et al., 2011" startWordPosition="2565" endWordPosition="2568">psed Gibbs sampling algorithm to do an approximate inference by integrating out some latent variables (i.e., µ’s, V’s and �d’s). The hierarchy in our model can be well explained with the Chinese restaurant franchise metaphor introduced in (Teh et al., 2006). For easier understanding, terminologies of the Chinese Restaurant Process (CRP) will be used throughout this section, i.e., customers, dishes and restaurants, correspond to words, topics, and segments respectively. Statistics used are listed in Table 1. To integrate out the Vd,s’s generated from the PYP, we use the technique presented in (Chen et al., 2011), which computes the joint posterior for the PYP by summing out all the possible seating arrangements for a sequence of customers (Teh, 2006). In this technique an auxiliary binary variable, called table indicator (Sd,u,n), is introduced to facilitate computing table count td,s,k for topic k. This method has two effects: (1) faster mixing of the sampler, and (2) elimination of the need for dynamic memory to store the populations/counts of each table in the CRP. In the CRP each word wd,u,n in topic k (i.e., where zd,u,n=k) contributes a count to nd,s,k for u C s; and, if wd,u,n, as a customer, </context>
<context position="18916" citStr="Chen et al., 2011" startWordPosition="3162" endWordPosition="3165"> and Shiue, 1998)3 precomputed in a table so cost2The Pochhammer symbol (x|y)n denotes the rising factorial with a specified increment, i.e., y. It is defined as (x|y)n = x(x + y)...(x + (n − 1)y). 3A Stirling number of the second kind is used to study the number of ways of partitioning a set of n objects into k nonempty subsets. The generalised version given by Hsu and Shiue (1998) has a linear recursion which in our case is Sm,a n+1= Sn m−1,a + (n − ��)Sn m,a. ing O(1) to use (Buntine and Hutter, 2012).Eq (3) is an indicator variant of Eq (1) in (Du et al., 2010) with applying Theorem 1 in (Chen et al., 2011). Given the current segmentation and topic assignments for all other words, using Bayes rule, we can derive the following two conditionals from Eq (3): 1. The joint probability of assigning topic k to word wd,u,n and wd,u,n being a table head, p(zd,u,n = k, Sd,u,n = 1 |0&apos;) ywi,j,n + Mk,wi,j,n αk + Es td,s,k Ek αk + Es,k td,s,k td,s,k + 1 (4) nd,s,k + 1 2. The joint probability of assigning k to wd,u,n and wd,u,n not being a table head, p(zd,u,n = k, Sd,u,n = 0 |0&apos;) = ywi,j,l + Mk,wi,j,l E w yw + Mk,w Snd,s,k+1 td,s,k,a nd,s,k + 1 − td,s,k Snd,s,k nd,s,k + 1 (5) b + Nd,s td,s,k,a where 0&apos; = {z−</context>
</contexts>
<marker>Chen, Du, Buntine, 2011</marker>
<rawString>Changyou Chen, Lan Du, and Wray Buntine. 2011. Sampling for the Poisson-Dirichlet process. In European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Database, pages 296–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Freddy Y Y Choi</author>
</authors>
<title>Advances in domain independent linear text segmentation.</title>
<date>2000</date>
<booktitle>In Proceedings of the 1st North American chapter of the Association for Computational Linguistics conference, NAACL</booktitle>
<pages>26--33</pages>
<contexts>
<context position="2552" citStr="Choi, 2000" startWordPosition="376" endWordPosition="377">coherent segments (Hearst, 1997; Beeferman et al., 1999). This task can be cast as an unsupervised machine learning problem: placing topic boundaries in unannotated text. Although a variety of cues in text can be used for topic segmentation, such as cue phases (Beeferman et al., 1999; Reynar, 1999; Eisenstein and Barzilay, 2008)) and discourse information (Galley et al., 2003), in this paper, we focus on lexical cohesion and use it as the primary cue in developing an unsupervised segmentation model. The effectiveness of lexical cohesion has been demonstrated by TextTiling (Hearst, 1997), c99 (Choi, 2000), MinCut (Malioutov and Barzilay, 2006), PLDA (Purver et al., 2006), Bayesseg (Eisenstein and Barzilay, 2008), TopicTiling (Riedl and Biemann, 2012), etc. Our work uses recent progress in hierarchical topic modelling with non-parametric Bayesian methods (Du et al., 2010; Chen et al., 2011; Du et al., 2012a), and is based on Bayesian segmentation methods (Goldwater et al., 2009; Purver et al., 2006; Eisenstein and Barzilay, 2008) using topic models. This can also be viewed as a multi-topic extension of hierarchical Bayesian segmentation (Eisenstein, 2009), although our use of hierarchies is use</context>
<context position="6813" citStr="Choi, 2000" startWordPosition="1054" endWordPosition="1055">udes the paper. 2 Related Work We are interested in unsupervised topic segmentation in either written or spoken language. There is a large body of work on unsupervised topic segmentation of text based on lexical cohesion. It can be characterised by how lexical cohesion is modelled. One branch of this work represents the lexical cohesion in a vector space by exploring the word cooccurrence patterns, e.g., TF or TF-IDF. Work following this line includes TextTiling (Hearst, 1997), which calculates the cosine similarity between two adjacent blocks of words purely based on the word frequency; C99 (Choi, 2000), an algorithm based on divisive clustering with a matrix-ranking scheme; LSeg (Galley et al., 2003), which uses a lexical chain to identify and weight word repetitions; U00 (Utiyama and Isahara, 2001), a probalistic approach using dynamic programming to find a segmentation with a minimum cost; MinCut (Malioutov and Barzilay, 2006), which casts segmentation as a graph cut problem, and APS (Kazantseva and Szpakowicz, 2011), which uses affinity propagation to learn clustering for segmentation. The other branch of this work characterises the lexical cohesion using topic models, to which the model</context>
<context position="26719" citStr="Choi (2000)" startWordPosition="4599" endWordPosition="4600">ded WindowDiff proposed by Lamprier et al. (2007), denoted by WD&apos;. One problem of WD&apos; is that errors near the two ends of a text are penalised less than those in the middle. To solve the problem WD&apos; adds k fictive text passages at the beginning and the end of the text when computing the score. We evaluated all the methods with the same Java code for the three metrics. Parameter Settings: In order to make all the methods comparable, we chose for each method the parameter settings that give the gold-standard number of segments5. Specifically, we used a 11 x 11 rank mask for C99, as suggested by Choi (2000), the configurations included in the code (http://groups.csail.mit.edu/rbg/code) for Bayesseg and manually tuned parameters for MinCut. For APS, a greedy approach was used to search parameter settings that can approximately give the gold-standard number of segments. For PLDA, two randomly initialised Gibbs chains were used. Each chain ran for 75,000 burn-in iterations, then 1000 samples were drawn at a lag of 25 from each chain. For TSM, 10 randomly initialised 4For preprocessing, we only removed stop words. 5The segments learnt by those methods will differ, but just the segment count will be </context>
<context position="28632" citStr="Choi, 2000" startWordPosition="4922" endWordPosition="4923">rive the final segmentation for PLDA and TSM, we first estimated the marginal probabilities of placing boundaries after text passages from the total of 2000 samples. These probabilities were then thresholded to give the gold-standard number of segments. Precisely, we apply a small amount of Gaussian smoothing to the marginal probabilities (except for Choi’s dataset), like Puerver et al. (2006) does. Finally, we used a symmetric Dirichlet prior in PLDA and STM, the one on topic distributions is a = 0.1, the other on word distributions -y = 0.01. 5.1 Evaluation on Choi’s Dataset Choi’s dataset (Choi, 2000) is commonly used in evaluating topic segmentation methods. It consists of 700 documents, each being a concatenation of 10 segments. Each segment is the first n sentences of a randomly selected document from the Brown corpus, s.t. 3 &lt; n &lt; 11. Those documents are divided into 4 subsets with different range of n, as shown in Table 2. We ran PLDA and STM with 50 topics. Results in Table 4 show that our model significantly outperforms all the other methods on the four subsets over all the metrics. Furthermore, comparing to other published results, this also outperforms (Misra et al., 2009) (see th</context>
</contexts>
<marker>Choi, 2000</marker>
<rawString>Freddy Y. Y. Choi. 2000. Advances in domain independent linear text segmentation. In Proceedings of the 1st North American chapter of the Association for Computational Linguistics conference, NAACL 2000, pages 26–33.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lan Du</author>
<author>Wray Buntine</author>
<author>Huidong Jin</author>
</authors>
<title>A segmented topic model based on the two-parameter Poisson-Dirichlet process.</title>
<date>2010</date>
<journal>Mach. Learn.,</journal>
<volume>81</volume>
<issue>1</issue>
<contexts>
<context position="2822" citStr="Du et al., 2010" startWordPosition="413" endWordPosition="416">erman et al., 1999; Reynar, 1999; Eisenstein and Barzilay, 2008)) and discourse information (Galley et al., 2003), in this paper, we focus on lexical cohesion and use it as the primary cue in developing an unsupervised segmentation model. The effectiveness of lexical cohesion has been demonstrated by TextTiling (Hearst, 1997), c99 (Choi, 2000), MinCut (Malioutov and Barzilay, 2006), PLDA (Purver et al., 2006), Bayesseg (Eisenstein and Barzilay, 2008), TopicTiling (Riedl and Biemann, 2012), etc. Our work uses recent progress in hierarchical topic modelling with non-parametric Bayesian methods (Du et al., 2010; Chen et al., 2011; Du et al., 2012a), and is based on Bayesian segmentation methods (Goldwater et al., 2009; Purver et al., 2006; Eisenstein and Barzilay, 2008) using topic models. This can also be viewed as a multi-topic extension of hierarchical Bayesian segmentation (Eisenstein, 2009), although our use of hierarchies is used to improve the performance of linear segmentation, rather than develop hierarchical segmentation. Recently, topic models are increasingly used in various text analysis tasks including topic segmentation. Previous work (Purver et al., 2006; Misra et al., 2008; Sun et a</context>
<context position="5464" citStr="Du et al., 2010" startWordPosition="830" endWordPosition="833">t to other topic modelling approaches that run LDA as a precursor to a separate segmentation step (Misra et al., 2009; Riedl and Biemann, 2012). While conceptually similar to PLDA, our non-parametric approach built on STM required new methods to implement, but the resulting improvement by the standard segmentation scores is substantial. This paper presents a new hierarchical Bayesian unsupervised topic segmentation model, integrating a point-wise boundary sampling algorithm with a structured topic model. This new model takes advantage of the high modelling accuracy of structured topic models (Du et al., 2010) to produce a topic segmentation based on the distribution of latent topics. We show that this model provides high quality segmentation performance on Choi’s dataset, as well as two sets of meeting transcripts and written texts. In the following sections we describe our topic segmentation model and an MCMC inference algorithm for the non-parametric split/merge process. The rest of the paper is organised as follows. In Section 2 we review recent related work in the topic segmentation literature. Section 3 presents the new topic segmentation model, followed by the derivation of a sampling algori</context>
<context position="10196" citStr="Du et al., 2010" startWordPosition="1603" endWordPosition="1606">probabilities for his/her different articles might be different. 3 Segmentation with Topic Models In documents, topically coherent segments usually encapsulate a set of consecutive passages that are semantically related (Wang et al., 2011). However, the topic boundaries between segments are often unavailable a priori. Thus we treat all passage boundaries (e.g., sentence boundaries, paragraph boundaries or pauses between utterances) as possible topic boundaries. To recover the topic boundaries we develop a structured topic segmentation model by integrating ideas from the segmented topic model (Du et al., 2010, STM) and Bayesian segmentation models. The basic idea of our model is that each document consists of a set of segments where text passages in the same segment are generated from the same topic distribution, called segment level topic distribution. The segment level topic distribution is drawn from a topic distribution associated with the whole document, called document level topic distribution. The relationships between the levels is managed using Bayesian non-parametric methods and a significant change in segment level topic distribution indicates a segment change. Our unsupervised topic se</context>
<context position="13008" citStr="Du et al. (2010)" startWordPosition="2090" endWordPosition="2093">; and text passages in topic segment s in d are generated from vd,s, a segment level topic distribution. The number of segments Sd can be computed as Sd=1 + �U��1 u�1 pd,u. Then, a Pitman-Yor 1The last 1 in ρ is the document boundary that is know a priori. This means one does not need to sample it. 192 Figure 1: The topic segmentation model process with a discount parameter a and a concentration parameter b is used to link µd and Vd,s by Vd,s—PYP(a, b, µd), which forms a simple topic hierarchy. The idea here is that topics discussed in segments can be variants of topics of the whole document. Du et al. (2010) have shown that this topic structure can significantly improve the modelling accuracy, which should contribute to more accurate segmentation. This generative process is different from PLDA. PLDA does not assume the document level topic distribution and each time generates the segment level topic distribution directly from a Dirichlet distribution. The complete probabilistic generative process, shown as a graph in Figure 1 is as follows: 1. For each topic k ∈ {1, ... ,K}, draw a word distribution Ok ∼ DirichletW (γ). 2. For each document d ∈ {1, ... , D}, (a) Draw topic shift probability Mrd ∼</context>
<context position="17170" citStr="Du et al., 2010" startWordPosition="2839" endWordPosition="2842">193 can be replaced be a simpler constraint in the table indicator representation. The sampler we develop is an MCMC sampler on the space 0 = {z, S, p} where z defines the topic assignments of words, S maintains the needed CRP configuration (from which t is derived) and p defines the segmentation. Moreover, it is not a traditional Gibbs sampler changing one variable at a time, but is a block Gibbs sampler where two different kinds of blocks are used. The first block is (zd,u,n, Sd,u,n) (for each word wd,u,n), which can be sampled with a table indicator variant of a hierarchical topic sampler (Du et al., 2010), described in Section 4.1. This corresponds to Equation (6) in (Purver et al., 2006). The second kind of block is a boundary indicator pd,u together with a particular constrained set of table counts designed to handle splitting and merging, which corresponds to Equation (7) in (Purver et al., 2006). Sampling this second kind of block is harder in our non-parametric model requiring a potentially exponential summation, a problem we overcome using symmetric polynomials, shown in Section 4.2. 4.1 Sampling Topics One step in our model is to sample the assignments of topics to words conditioned on </context>
<context position="18869" citStr="Du et al., 2010" startWordPosition="3153" endWordPosition="3156">lised Stirling number of the second kind (Hsu and Shiue, 1998)3 precomputed in a table so cost2The Pochhammer symbol (x|y)n denotes the rising factorial with a specified increment, i.e., y. It is defined as (x|y)n = x(x + y)...(x + (n − 1)y). 3A Stirling number of the second kind is used to study the number of ways of partitioning a set of n objects into k nonempty subsets. The generalised version given by Hsu and Shiue (1998) has a linear recursion which in our case is Sm,a n+1= Sn m−1,a + (n − ��)Sn m,a. ing O(1) to use (Buntine and Hutter, 2012).Eq (3) is an indicator variant of Eq (1) in (Du et al., 2010) with applying Theorem 1 in (Chen et al., 2011). Given the current segmentation and topic assignments for all other words, using Bayes rule, we can derive the following two conditionals from Eq (3): 1. The joint probability of assigning topic k to word wd,u,n and wd,u,n being a table head, p(zd,u,n = k, Sd,u,n = 1 |0&apos;) ywi,j,n + Mk,wi,j,n αk + Es td,s,k Ek αk + Es,k td,s,k td,s,k + 1 (4) nd,s,k + 1 2. The joint probability of assigning k to wd,u,n and wd,u,n not being a table head, p(zd,u,n = k, Sd,u,n = 0 |0&apos;) = ywi,j,l + Mk,wi,j,l E w yw + Mk,w Snd,s,k+1 td,s,k,a nd,s,k + 1 − td,s,k Snd,s,k </context>
</contexts>
<marker>Du, Buntine, Jin, 2010</marker>
<rawString>Lan Du, Wray Buntine, and Huidong Jin. 2010. A segmented topic model based on the two-parameter Poisson-Dirichlet process. Mach. Learn., 81(1):5–19.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lan Du</author>
<author>Wray Buntine</author>
<author>Huidong Jin</author>
</authors>
<title>Modelling sequential text with an adaptive topic model.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,</booktitle>
<pages>535--545</pages>
<contexts>
<context position="2858" citStr="Du et al., 2012" startWordPosition="421" endWordPosition="424">senstein and Barzilay, 2008)) and discourse information (Galley et al., 2003), in this paper, we focus on lexical cohesion and use it as the primary cue in developing an unsupervised segmentation model. The effectiveness of lexical cohesion has been demonstrated by TextTiling (Hearst, 1997), c99 (Choi, 2000), MinCut (Malioutov and Barzilay, 2006), PLDA (Purver et al., 2006), Bayesseg (Eisenstein and Barzilay, 2008), TopicTiling (Riedl and Biemann, 2012), etc. Our work uses recent progress in hierarchical topic modelling with non-parametric Bayesian methods (Du et al., 2010; Chen et al., 2011; Du et al., 2012a), and is based on Bayesian segmentation methods (Goldwater et al., 2009; Purver et al., 2006; Eisenstein and Barzilay, 2008) using topic models. This can also be viewed as a multi-topic extension of hierarchical Bayesian segmentation (Eisenstein, 2009), although our use of hierarchies is used to improve the performance of linear segmentation, rather than develop hierarchical segmentation. Recently, topic models are increasingly used in various text analysis tasks including topic segmentation. Previous work (Purver et al., 2006; Misra et al., 2008; Sun et al., 2008; Misra et al., 2009; Riedl </context>
<context position="27961" citStr="Du et al., 2012" startWordPosition="4808" endWordPosition="4811">rd count. Table 2: The Choi’s dataset Range of n 3-11 3-5 6-8 9-11 #docs 400 100 100 100 DocLen mean 69.7 39.3 69.6 98.6 std 8.2 2.6 2.9 3.5 SegLen mean 7 4 7 10 std 2.57 0.84 0.87 1.03 Table 3: Real dataset statistics ICSI Election Fiction Clinical # doc 25 4 84 227 DocLen mean 994.5 144.3 325.0 139.5 std 354.5 16.4 230.1 110.4 SegLen mean 188 7 22 35 std 219.1 8.9 23.8 41.7 Gibbs chains were used. Each chain ran for 30,000 iterations with 25,000 for burn-in, then 200 samples were drawn. The concentration parameter b in TSM was sampled using the Adaptive-Reject sampling scheme introduced in (Du et al., 2012b), the discount parameter a = 0.2, and A0 = A1 = 0.1. To derive the final segmentation for PLDA and TSM, we first estimated the marginal probabilities of placing boundaries after text passages from the total of 2000 samples. These probabilities were then thresholded to give the gold-standard number of segments. Precisely, we apply a small amount of Gaussian smoothing to the marginal probabilities (except for Choi’s dataset), like Puerver et al. (2006) does. Finally, we used a symmetric Dirichlet prior in PLDA and STM, the one on topic distributions is a = 0.1, the other on word distributions </context>
</contexts>
<marker>Du, Buntine, Jin, 2012</marker>
<rawString>Lan Du, Wray Buntine, and Huidong Jin. 2012a. Modelling sequential text with an adaptive topic model. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 535–545.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Lan Du</author>
<author>Wray Buntine</author>
<author>Huidong Jin</author>
<author>Changyou Chen</author>
</authors>
<booktitle>2012b. Sequential latent Dirichlet allocation. Knowledge and Information Systems,</booktitle>
<pages>31--3</pages>
<marker>Du, Buntine, Jin, Chen, </marker>
<rawString>Lan Du, Wray Buntine, Huidong Jin, and Changyou Chen. 2012b. Sequential latent Dirichlet allocation. Knowledge and Information Systems, 31(3):475–503.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacob Eisenstein</author>
<author>Regina Barzilay</author>
</authors>
<title>Bayesian unsupervised topic segmentation.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP’08,</booktitle>
<pages>334--343</pages>
<contexts>
<context position="1332" citStr="Eisenstein and Barzilay, 2008" startWordPosition="181" endWordPosition="184">erimental results show that our model outperforms previous unsupervised segmentation methods using only lexical information on Choi’s datasets and two meeting transcripts and has performance comparable to those previous methods on two written datasets. 1 Introduction Documents are usually comprised of topically coherent text segments, each of which contains some number of text passages (e.g., sentences or paragraphs) (Salton et al., 1996). Within each topically coherent segment, one would expect that the word usage demonstrates more consistent lexical distributions (known as lexical cohesion (Eisenstein and Barzilay, 2008)) than that across segments. A linear partition of texts into topic segments may reveal information about, for example, themes of segments and the overall thematic structure of the text, and can subsequently be useful for text analysis tasks, such as information retrieval (e.g., passage retrieval (Salton et al., 1996)), document summarisation and discourse analysis (Galley et al., 2003). In this paper we consider how to automatically find a topic segmentation. It involves identifying the most prominent topic changes in a sequence of text passages, and splits those passages into a sequence of t</context>
<context position="2661" citStr="Eisenstein and Barzilay, 2008" startWordPosition="389" endWordPosition="392">pervised machine learning problem: placing topic boundaries in unannotated text. Although a variety of cues in text can be used for topic segmentation, such as cue phases (Beeferman et al., 1999; Reynar, 1999; Eisenstein and Barzilay, 2008)) and discourse information (Galley et al., 2003), in this paper, we focus on lexical cohesion and use it as the primary cue in developing an unsupervised segmentation model. The effectiveness of lexical cohesion has been demonstrated by TextTiling (Hearst, 1997), c99 (Choi, 2000), MinCut (Malioutov and Barzilay, 2006), PLDA (Purver et al., 2006), Bayesseg (Eisenstein and Barzilay, 2008), TopicTiling (Riedl and Biemann, 2012), etc. Our work uses recent progress in hierarchical topic modelling with non-parametric Bayesian methods (Du et al., 2010; Chen et al., 2011; Du et al., 2012a), and is based on Bayesian segmentation methods (Goldwater et al., 2009; Purver et al., 2006; Eisenstein and Barzilay, 2008) using topic models. This can also be viewed as a multi-topic extension of hierarchical Bayesian segmentation (Eisenstein, 2009), although our use of hierarchies is used to improve the performance of linear segmentation, rather than develop hierarchical segmentation. Recently,</context>
<context position="8459" citStr="Eisenstein and Barzilay, 2008" startWordPosition="1324" endWordPosition="1327">rver et al., 2006)). It is sampled to indicate whether the jth text passage shares the topic distribution with the (j − 1)th passage. Using a similar Markov structure, SITS (Nguyen et al., 2012) chains a set of HDP-LDAs (Teh et al., 2006). Unlike PLDA, SITS assumes each text passage is associated with a speaker identity that is attached to the topic shift variable as supervising in191 formation. SITS further assumes speakers have different topic change probabilities that work as priors on topic shift variables. Instead of assuming documents in a dataset share the same set of topics, Bayesseg (Eisenstein and Barzilay, 2008) treats words in a segment generated from a segment specific multinomial language model, i.e., it assumes each segment is generated from one topic, and a later hierarchical extension (Eisenstein, 2009) assumes each segment is generated from one topic or its parents. Other methods using as input the output of topic models include (Sun et al., 2008), (Misra et al., 2009), and (Riedl and Biemann, 2012). In this paper we take a generative approach lying between PLDA and SITS. In contrast to PLDA, which uses a flat topic model (i.e., LDA), we assume each text has a latent topic structure that can r</context>
<context position="33857" citStr="Eisenstein and Barzilay, 2008" startWordPosition="5858" endWordPosition="5861">spect to the gold standard. Although TSM still performs the best on the debates, all the methods have relatively worse performance than on the ICSI meeting transcripts. Nguyen et al. (2012) pointed out that the ICSI meetings are characterised by pragmatic topic changes, in contrast, the debates are characterised by strategic topic changes with strong rewards for setting the agenda, dodging a question, etc. Thus, considering the properties of debates might further improve the segmentation performance. 5.3 Evaluation on Written Texts We further tested TSM on two written text datasets, Clinical (Eisenstein and Barzilay, 2008) and Fiction (Kazantseva and Szpakowicz, 2011). The statistics are shown in Table 3. Each document in the Clinical dataset is a chapter of a medical textbook. Section breaks are selected to be the true topic boundaries. For the Fiction dataset, each document is a fiction downloaded from Project Gutenberg, the true topic boundaries are chapter breaks. We trained PLDA and TSM with 25 topics on the Fiction and 50 on the Clinical. Results are shown in Table 5. TSM compares favourably with Bayesseg and outperforms the other methods on the Clinical dataset, but it does not perform as well as Bayesse</context>
</contexts>
<marker>Eisenstein, Barzilay, 2008</marker>
<rawString>Jacob Eisenstein and Regina Barzilay. 2008. Bayesian unsupervised topic segmentation. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP’08, pages 334–343.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacob Eisenstein</author>
</authors>
<title>Hierarchical text segmentation from multi-scale lexical cohesion.</title>
<date>2009</date>
<booktitle>In Human Language Technologies: Conference of the North American Chapter of the Association of Computational Linguistics,</booktitle>
<pages>353--361</pages>
<contexts>
<context position="3112" citStr="Eisenstein, 2009" startWordPosition="462" endWordPosition="464">monstrated by TextTiling (Hearst, 1997), c99 (Choi, 2000), MinCut (Malioutov and Barzilay, 2006), PLDA (Purver et al., 2006), Bayesseg (Eisenstein and Barzilay, 2008), TopicTiling (Riedl and Biemann, 2012), etc. Our work uses recent progress in hierarchical topic modelling with non-parametric Bayesian methods (Du et al., 2010; Chen et al., 2011; Du et al., 2012a), and is based on Bayesian segmentation methods (Goldwater et al., 2009; Purver et al., 2006; Eisenstein and Barzilay, 2008) using topic models. This can also be viewed as a multi-topic extension of hierarchical Bayesian segmentation (Eisenstein, 2009), although our use of hierarchies is used to improve the performance of linear segmentation, rather than develop hierarchical segmentation. Recently, topic models are increasingly used in various text analysis tasks including topic segmentation. Previous work (Purver et al., 2006; Misra et al., 2008; Sun et al., 2008; Misra et al., 2009; Riedl and Biemann, 2012) has shown that using 190 Proceedings of NAACL-HLT 2013, pages 190–200, Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics topic assignments or topic distributions instead of word frequency can significan</context>
<context position="8660" citStr="Eisenstein, 2009" startWordPosition="1357" endWordPosition="1358">-LDAs (Teh et al., 2006). Unlike PLDA, SITS assumes each text passage is associated with a speaker identity that is attached to the topic shift variable as supervising in191 formation. SITS further assumes speakers have different topic change probabilities that work as priors on topic shift variables. Instead of assuming documents in a dataset share the same set of topics, Bayesseg (Eisenstein and Barzilay, 2008) treats words in a segment generated from a segment specific multinomial language model, i.e., it assumes each segment is generated from one topic, and a later hierarchical extension (Eisenstein, 2009) assumes each segment is generated from one topic or its parents. Other methods using as input the output of topic models include (Sun et al., 2008), (Misra et al., 2009), and (Riedl and Biemann, 2012). In this paper we take a generative approach lying between PLDA and SITS. In contrast to PLDA, which uses a flat topic model (i.e., LDA), we assume each text has a latent topic structure that can reflect the topic coherence pattern, and the model adapts its parameters to the segments to further improve performance. Unlike SITS that targets analysing multiparty meeting transcripts, where speaker </context>
</contexts>
<marker>Eisenstein, 2009</marker>
<rawString>Jacob Eisenstein. 2009. Hierarchical text segmentation from multi-scale lexical cohesion. In Human Language Technologies: Conference of the North American Chapter of the Association of Computational Linguistics, pages 353–361. The Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Galley</author>
<author>Kathleen R McKeown</author>
<author>Eric FoslerLussier</author>
<author>Hongyan Jing</author>
</authors>
<title>Discourse segmentation of multi-party conversation.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>562--569</pages>
<contexts>
<context position="1721" citStr="Galley et al., 2003" startWordPosition="240" endWordPosition="243">tences or paragraphs) (Salton et al., 1996). Within each topically coherent segment, one would expect that the word usage demonstrates more consistent lexical distributions (known as lexical cohesion (Eisenstein and Barzilay, 2008)) than that across segments. A linear partition of texts into topic segments may reveal information about, for example, themes of segments and the overall thematic structure of the text, and can subsequently be useful for text analysis tasks, such as information retrieval (e.g., passage retrieval (Salton et al., 1996)), document summarisation and discourse analysis (Galley et al., 2003). In this paper we consider how to automatically find a topic segmentation. It involves identifying the most prominent topic changes in a sequence of text passages, and splits those passages into a sequence of topically coherent segments (Hearst, 1997; Beeferman et al., 1999). This task can be cast as an unsupervised machine learning problem: placing topic boundaries in unannotated text. Although a variety of cues in text can be used for topic segmentation, such as cue phases (Beeferman et al., 1999; Reynar, 1999; Eisenstein and Barzilay, 2008)) and discourse information (Galley et al., 2003),</context>
<context position="6913" citStr="Galley et al., 2003" startWordPosition="1067" endWordPosition="1070">er written or spoken language. There is a large body of work on unsupervised topic segmentation of text based on lexical cohesion. It can be characterised by how lexical cohesion is modelled. One branch of this work represents the lexical cohesion in a vector space by exploring the word cooccurrence patterns, e.g., TF or TF-IDF. Work following this line includes TextTiling (Hearst, 1997), which calculates the cosine similarity between two adjacent blocks of words purely based on the word frequency; C99 (Choi, 2000), an algorithm based on divisive clustering with a matrix-ranking scheme; LSeg (Galley et al., 2003), which uses a lexical chain to identify and weight word repetitions; U00 (Utiyama and Isahara, 2001), a probalistic approach using dynamic programming to find a segmentation with a minimum cost; MinCut (Malioutov and Barzilay, 2006), which casts segmentation as a graph cut problem, and APS (Kazantseva and Szpakowicz, 2011), which uses affinity propagation to learn clustering for segmentation. The other branch of this work characterises the lexical cohesion using topic models, to which the model introduced in Section 3 belongs. Lexical cohesion in this line of research is modelled by a probabi</context>
<context position="31601" citStr="Galley et al. (2003)" startWordPosition="5474" endWordPosition="5477">is large. In TSM, a large variance causes a small concentration parameter b. We observed that the sampled b’s (about 0.1) are indeed small for the four subsets, which shows there is no topic sharing among segments. Therefore, TSM is able to recognise the segments are unrelated text. 5.2 Evaluation on Meeting Transcripts We applied our model to segmenting the two meeting transcripts, which are the ICSI meeting transcripts (Janin et al., 2003) and the 2008 presidential election debates (Boydstun et al., 2011). The ICSI meeting has 75 transcripts, we used the 25 annotated transcripts provided by Galley et al. (2003) for evaluation. For the election debates, we used the four annotated debates used in (Nguyen et al., 2012). The statistics are shown in Table 3. PLDA and TSM were trained with 10 topics on the ICSI and 50 on the Election. In this set of experiments, we show that our model is robust to meeting transcripts. TSM 0.2 0 PIDA 0.2 0 0 100 200 300 400 500 600 700 800 Utterance position in sequence Figure 2: Probability of a topic boundary, compared with gold-standard segmentation (shown in red and at the top of each diagram) on one ICSI transcript. As shown in Table 5, topic modelling based methods (</context>
</contexts>
<marker>Galley, McKeown, FoslerLussier, Jing, 2003</marker>
<rawString>Michel Galley, Kathleen R. McKeown, Eric FoslerLussier, and Hongyan Jing. 2003. Discourse segmentation of multi-party conversation. In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics, pages 562–569.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sharon Goldwater</author>
<author>Thomas L Griffiths</author>
<author>Mark Johnson</author>
</authors>
<title>A Bayesian framework for word segmentation: Exploring the effects of context.</title>
<date>2009</date>
<journal>Cognition,</journal>
<volume>112</volume>
<issue>1</issue>
<contexts>
<context position="2931" citStr="Goldwater et al., 2009" startWordPosition="432" endWordPosition="435"> al., 2003), in this paper, we focus on lexical cohesion and use it as the primary cue in developing an unsupervised segmentation model. The effectiveness of lexical cohesion has been demonstrated by TextTiling (Hearst, 1997), c99 (Choi, 2000), MinCut (Malioutov and Barzilay, 2006), PLDA (Purver et al., 2006), Bayesseg (Eisenstein and Barzilay, 2008), TopicTiling (Riedl and Biemann, 2012), etc. Our work uses recent progress in hierarchical topic modelling with non-parametric Bayesian methods (Du et al., 2010; Chen et al., 2011; Du et al., 2012a), and is based on Bayesian segmentation methods (Goldwater et al., 2009; Purver et al., 2006; Eisenstein and Barzilay, 2008) using topic models. This can also be viewed as a multi-topic extension of hierarchical Bayesian segmentation (Eisenstein, 2009), although our use of hierarchies is used to improve the performance of linear segmentation, rather than develop hierarchical segmentation. Recently, topic models are increasingly used in various text analysis tasks including topic segmentation. Previous work (Purver et al., 2006; Misra et al., 2008; Sun et al., 2008; Misra et al., 2009; Riedl and Biemann, 2012) has shown that using 190 Proceedings of NAACL-HLT 2013</context>
<context position="4622" citStr="Goldwater et al., 2009" startWordPosition="698" endWordPosition="702">f which is a set of text passages (e.g., a paragraph or sentence). Text passages in a segment share the same prior distribution on their topics. The topic distributions of segments in a single document are then encouraged to be similar via a hierarchical prior. This gives a substantial improvement in modelling accuracy. However, instead of explicitly learning the segmentation, STMs just leverage the existing structure of documents from the given segmentation. Given a sequence of text passages, how can we automatically learn the segmentation? The word boundary sampling algorithm introduced in (Goldwater et al., 2009) uses point-wise sampling of word boundaries after phonemes in an utterance. Similarly, the segmentation method of PLDA (Purver et al., 2006) samples segment boundaries, but also jointly samples a topic model. This is different to other topic modelling approaches that run LDA as a precursor to a separate segmentation step (Misra et al., 2009; Riedl and Biemann, 2012). While conceptually similar to PLDA, our non-parametric approach built on STM required new methods to implement, but the resulting improvement by the standard segmentation scores is substantial. This paper presents a new hierarchi</context>
</contexts>
<marker>Goldwater, Griffiths, Johnson, 2009</marker>
<rawString>Sharon Goldwater, Thomas L. Griffiths, and Mark Johnson. 2009. A Bayesian framework for word segmentation: Exploring the effects of context. Cognition, 112(1):21–53.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marti A Hearst</author>
</authors>
<title>TextTiling: segmenting text into multi-paragraph subtopic passages.</title>
<date>1997</date>
<journal>Comput. Linguist.,</journal>
<volume>23</volume>
<issue>1</issue>
<contexts>
<context position="1972" citStr="Hearst, 1997" startWordPosition="281" endWordPosition="282"> A linear partition of texts into topic segments may reveal information about, for example, themes of segments and the overall thematic structure of the text, and can subsequently be useful for text analysis tasks, such as information retrieval (e.g., passage retrieval (Salton et al., 1996)), document summarisation and discourse analysis (Galley et al., 2003). In this paper we consider how to automatically find a topic segmentation. It involves identifying the most prominent topic changes in a sequence of text passages, and splits those passages into a sequence of topically coherent segments (Hearst, 1997; Beeferman et al., 1999). This task can be cast as an unsupervised machine learning problem: placing topic boundaries in unannotated text. Although a variety of cues in text can be used for topic segmentation, such as cue phases (Beeferman et al., 1999; Reynar, 1999; Eisenstein and Barzilay, 2008)) and discourse information (Galley et al., 2003), in this paper, we focus on lexical cohesion and use it as the primary cue in developing an unsupervised segmentation model. The effectiveness of lexical cohesion has been demonstrated by TextTiling (Hearst, 1997), c99 (Choi, 2000), MinCut (Malioutov </context>
<context position="6683" citStr="Hearst, 1997" startWordPosition="1034" endWordPosition="1035"> Section 4. We report the experimental results by comparing several related topic segmentation methods in Section 5. Section 6 concludes the paper. 2 Related Work We are interested in unsupervised topic segmentation in either written or spoken language. There is a large body of work on unsupervised topic segmentation of text based on lexical cohesion. It can be characterised by how lexical cohesion is modelled. One branch of this work represents the lexical cohesion in a vector space by exploring the word cooccurrence patterns, e.g., TF or TF-IDF. Work following this line includes TextTiling (Hearst, 1997), which calculates the cosine similarity between two adjacent blocks of words purely based on the word frequency; C99 (Choi, 2000), an algorithm based on divisive clustering with a matrix-ranking scheme; LSeg (Galley et al., 2003), which uses a lexical chain to identify and weight word repetitions; U00 (Utiyama and Isahara, 2001), a probalistic approach using dynamic programming to find a segmentation with a minimum cost; MinCut (Malioutov and Barzilay, 2006), which casts segmentation as a graph cut problem, and APS (Kazantseva and Szpakowicz, 2011), which uses affinity propagation to learn cl</context>
</contexts>
<marker>Hearst, 1997</marker>
<rawString>Marti A. Hearst. 1997. TextTiling: segmenting text into multi-paragraph subtopic passages. Comput. Linguist., 23(1):33–64.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leetsch C Hsu</author>
<author>Peter Jau-Shyong Shiue</author>
</authors>
<title>A unified approach to generalized Stirling numbers.</title>
<date>1998</date>
<journal>Adv. Appl. Math.,</journal>
<pages>20--366</pages>
<contexts>
<context position="18315" citStr="Hsu and Shiue, 1998" startWordPosition="3045" endWordPosition="3048">n our model is to sample the assignments of topics to words conditioned on all p’s. As discussed in Section 3, given the sequence of pd,u’s, pd, one can figure out which segment s text passage u belongs to. Thus, conditioned on a set of segments s given by p, the joint posterior distribution of w, z and S is computed as p(z, w, S |p, 4),, a, b, &apos;y) ) BetaK �α + Es td,s BetaW (&apos;y + Mk) BetaK (α) kR BetaW (&apos;y) (b�a)Td,s td)Nd,s k RStdda kka (nd,s,k l−1 ,(3) where BetaK(·) is a K-dimension Beta function, (x|y)n the Pochhammer symbol2, and Sn�,a the generalised Stirling number of the second kind (Hsu and Shiue, 1998)3 precomputed in a table so cost2The Pochhammer symbol (x|y)n denotes the rising factorial with a specified increment, i.e., y. It is defined as (x|y)n = x(x + y)...(x + (n − 1)y). 3A Stirling number of the second kind is used to study the number of ways of partitioning a set of n objects into k nonempty subsets. The generalised version given by Hsu and Shiue (1998) has a linear recursion which in our case is Sm,a n+1= Sn m−1,a + (n − ��)Sn m,a. ing O(1) to use (Buntine and Hutter, 2012).Eq (3) is an indicator variant of Eq (1) in (Du et al., 2010) with applying Theorem 1 in (Chen et al., 2011</context>
</contexts>
<marker>Hsu, Shiue, 1998</marker>
<rawString>Leetsch C. Hsu and Peter Jau-Shyong Shiue. 1998. A unified approach to generalized Stirling numbers. Adv. Appl. Math., 20:366–384, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sonia Jain</author>
<author>Radford Neal</author>
</authors>
<title>A split-merge Markov chain Monte Carlo procedure for the Dirichlet process mixture model.</title>
<date>2004</date>
<journal>Journal of Computational and Graphical Statistics,</journal>
<volume>13</volume>
<issue>1</issue>
<marker>Jain, Neal, 2004</marker>
<rawString>Sonia Jain and Radford Neal. 2004. A split-merge Markov chain Monte Carlo procedure for the Dirichlet process mixture model. Journal of Computational and Graphical Statistics, 13(1):158–182.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Janin</author>
<author>D Baron</author>
<author>J Edwards</author>
<author>D Ellis</author>
<author>D Gelbart</author>
<author>N Morgan</author>
<author>B Peskin</author>
<author>T Pfau</author>
<author>E Shriberg</author>
<author>A Stolcke</author>
<author>C Wooters</author>
</authors>
<title>The ICSI Meeting Corpus.</title>
<date>2003</date>
<booktitle>In Proceedings of 2003 IEEE International Conference on Acoustics, Speech, and Signal (ICASSP ’03),</booktitle>
<pages>364--367</pages>
<contexts>
<context position="31426" citStr="Janin et al., 2003" startWordPosition="5446" endWordPosition="5449">lioutov and Barzilay, 2006). The sharp transitions lead to significant change in segment level topic distributions, which further implies the variance of these distributions is large. In TSM, a large variance causes a small concentration parameter b. We observed that the sampled b’s (about 0.1) are indeed small for the four subsets, which shows there is no topic sharing among segments. Therefore, TSM is able to recognise the segments are unrelated text. 5.2 Evaluation on Meeting Transcripts We applied our model to segmenting the two meeting transcripts, which are the ICSI meeting transcripts (Janin et al., 2003) and the 2008 presidential election debates (Boydstun et al., 2011). The ICSI meeting has 75 transcripts, we used the 25 annotated transcripts provided by Galley et al. (2003) for evaluation. For the election debates, we used the four annotated debates used in (Nguyen et al., 2012). The statistics are shown in Table 3. PLDA and TSM were trained with 10 topics on the ICSI and 50 on the Election. In this set of experiments, we show that our model is robust to meeting transcripts. TSM 0.2 0 PIDA 0.2 0 0 100 200 300 400 500 600 700 800 Utterance position in sequence Figure 2: Probability of a topi</context>
</contexts>
<marker>Janin, Baron, Edwards, Ellis, Gelbart, Morgan, Peskin, Pfau, Shriberg, Stolcke, Wooters, 2003</marker>
<rawString>A. Janin, D. Baron, J. Edwards, D. Ellis, D. Gelbart, N. Morgan, B. Peskin, T. Pfau, E. Shriberg, A. Stolcke, and C. Wooters. 2003. The ICSI Meeting Corpus. In Proceedings of 2003 IEEE International Conference on Acoustics, Speech, and Signal (ICASSP ’03), pages 364–367.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shafiq Joty</author>
<author>Giuseppe Carenini</author>
<author>Gabriel Murray</author>
<author>Raymond T Ng</author>
</authors>
<title>Exploiting conversation structure in unsupervised topic segmentation for emails.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>388--398</pages>
<marker>Joty, Carenini, Murray, Ng, 2010</marker>
<rawString>Shafiq Joty, Giuseppe Carenini, Gabriel Murray, and Raymond T. Ng. 2010. Exploiting conversation structure in unsupervised topic segmentation for emails. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 388– 398.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anna Kazantseva</author>
<author>Stan Szpakowicz</author>
</authors>
<title>Linear text segmentation using affinity propagation.</title>
<date>2011</date>
<booktitle>In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>284--293</pages>
<contexts>
<context position="7238" citStr="Kazantseva and Szpakowicz, 2011" startWordPosition="1117" endWordPosition="1120">g., TF or TF-IDF. Work following this line includes TextTiling (Hearst, 1997), which calculates the cosine similarity between two adjacent blocks of words purely based on the word frequency; C99 (Choi, 2000), an algorithm based on divisive clustering with a matrix-ranking scheme; LSeg (Galley et al., 2003), which uses a lexical chain to identify and weight word repetitions; U00 (Utiyama and Isahara, 2001), a probalistic approach using dynamic programming to find a segmentation with a minimum cost; MinCut (Malioutov and Barzilay, 2006), which casts segmentation as a graph cut problem, and APS (Kazantseva and Szpakowicz, 2011), which uses affinity propagation to learn clustering for segmentation. The other branch of this work characterises the lexical cohesion using topic models, to which the model introduced in Section 3 belongs. Lexical cohesion in this line of research is modelled by a probabilistic generative process. PLDA presented by Purver et al. (2006) is an unsupervised topic modelling approach for segmentation. It chains a set of LDAs (Blei et al., 2003) by assuming a Markov structure on topic distributions. A binary topic shift variable is attached to each text passage (i.e., an utterance in (Purver et a</context>
<context position="25606" citStr="Kazantseva and Szpakowicz, 2011" startWordPosition="4401" endWordPosition="4404">c segmentation tasks, we ~ X a λ0 + λ1 + cd,0 + cd,1 T s=1 λ0 + cd,0 � BetaK �α + X td,s Sd BetaK (α + XSd td� Y s=1 ,s sE{sl,srJ 195 evaluate it on three different kinds of corpora4: a set of synthetic documents, two meeting transcripts and two sets of text books (see Tables 2 and 3); and compare TSM with the following methods: two baselines (the Random algorithm that places topic boundaries uniformly at random, and the Even algorithm that places a boundary after every mth text passage, where m is the average gold-standard segment length (Beeferman et al., 1999)), C99, MinCut, Bayesseg, APS (Kazantseva and Szpakowicz, 2011), and PLDA. Metrics: We evaluated the segmentation performance with PK (Beeferman et al., 1999) and WindowDiff (WD&apos;) (Pevzner and Hearst, 2002), which are two common metrics used in topic segmentation. Both move a sliding window of fixed size k over the document, and compare the inferred segmentation with the gold-standard segmentation for each window. The window size is usually set to the half of the average gold-standard segment size (Pevzner and Hearst, 2002). In addition, we also used an extended WindowDiff proposed by Lamprier et al. (2007), denoted by WD&apos;. One problem of WD&apos; is that erro</context>
<context position="33903" citStr="Kazantseva and Szpakowicz, 2011" startWordPosition="5864" endWordPosition="5867">ll performs the best on the debates, all the methods have relatively worse performance than on the ICSI meeting transcripts. Nguyen et al. (2012) pointed out that the ICSI meetings are characterised by pragmatic topic changes, in contrast, the debates are characterised by strategic topic changes with strong rewards for setting the agenda, dodging a question, etc. Thus, considering the properties of debates might further improve the segmentation performance. 5.3 Evaluation on Written Texts We further tested TSM on two written text datasets, Clinical (Eisenstein and Barzilay, 2008) and Fiction (Kazantseva and Szpakowicz, 2011). The statistics are shown in Table 3. Each document in the Clinical dataset is a chapter of a medical textbook. Section breaks are selected to be the true topic boundaries. For the Fiction dataset, each document is a fiction downloaded from Project Gutenberg, the true topic boundaries are chapter breaks. We trained PLDA and TSM with 25 topics on the Fiction and 50 on the Clinical. Results are shown in Table 5. TSM compares favourably with Bayesseg and outperforms the other methods on the Clinical dataset, but it does not perform as well as Bayesseg on the Fiction dataset. In fiction books, th</context>
</contexts>
<marker>Kazantseva, Szpakowicz, 2011</marker>
<rawString>Anna Kazantseva and Stan Szpakowicz. 2011. Linear text segmentation using affinity propagation. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 284–293.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sylvain Lamprier</author>
<author>Tassadit Amghar</author>
<author>Bernard Levrat</author>
<author>Frederic Saubion</author>
</authors>
<title>On evaluation methodologies for text segmentation algorithms.</title>
<date>2007</date>
<booktitle>In Proceedings of the 19th IEEE International Conference on Tools with Artificial Intelligence - Volume 02, ICTAI ’07,</booktitle>
<pages>pages</pages>
<contexts>
<context position="26157" citStr="Lamprier et al. (2007)" startWordPosition="4492" endWordPosition="4496">., 1999)), C99, MinCut, Bayesseg, APS (Kazantseva and Szpakowicz, 2011), and PLDA. Metrics: We evaluated the segmentation performance with PK (Beeferman et al., 1999) and WindowDiff (WD&apos;) (Pevzner and Hearst, 2002), which are two common metrics used in topic segmentation. Both move a sliding window of fixed size k over the document, and compare the inferred segmentation with the gold-standard segmentation for each window. The window size is usually set to the half of the average gold-standard segment size (Pevzner and Hearst, 2002). In addition, we also used an extended WindowDiff proposed by Lamprier et al. (2007), denoted by WD&apos;. One problem of WD&apos; is that errors near the two ends of a text are penalised less than those in the middle. To solve the problem WD&apos; adds k fictive text passages at the beginning and the end of the text when computing the score. We evaluated all the methods with the same Java code for the three metrics. Parameter Settings: In order to make all the methods comparable, we chose for each method the parameter settings that give the gold-standard number of segments5. Specifically, we used a 11 x 11 rank mask for C99, as suggested by Choi (2000), the configurations included in the c</context>
</contexts>
<marker>Lamprier, Amghar, Levrat, Saubion, 2007</marker>
<rawString>Sylvain Lamprier, Tassadit Amghar, Bernard Levrat, and Frederic Saubion. 2007. On evaluation methodologies for text segmentation algorithms. In Proceedings of the 19th IEEE International Conference on Tools with Artificial Intelligence - Volume 02, ICTAI ’07, pages 19–26.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Igor Malioutov</author>
<author>Regina Barzilay</author>
</authors>
<title>Minimum cut model for spoken lecture segmentation.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics, ACL44,</booktitle>
<pages>25--32</pages>
<contexts>
<context position="2591" citStr="Malioutov and Barzilay, 2006" startWordPosition="379" endWordPosition="382">arst, 1997; Beeferman et al., 1999). This task can be cast as an unsupervised machine learning problem: placing topic boundaries in unannotated text. Although a variety of cues in text can be used for topic segmentation, such as cue phases (Beeferman et al., 1999; Reynar, 1999; Eisenstein and Barzilay, 2008)) and discourse information (Galley et al., 2003), in this paper, we focus on lexical cohesion and use it as the primary cue in developing an unsupervised segmentation model. The effectiveness of lexical cohesion has been demonstrated by TextTiling (Hearst, 1997), c99 (Choi, 2000), MinCut (Malioutov and Barzilay, 2006), PLDA (Purver et al., 2006), Bayesseg (Eisenstein and Barzilay, 2008), TopicTiling (Riedl and Biemann, 2012), etc. Our work uses recent progress in hierarchical topic modelling with non-parametric Bayesian methods (Du et al., 2010; Chen et al., 2011; Du et al., 2012a), and is based on Bayesian segmentation methods (Goldwater et al., 2009; Purver et al., 2006; Eisenstein and Barzilay, 2008) using topic models. This can also be viewed as a multi-topic extension of hierarchical Bayesian segmentation (Eisenstein, 2009), although our use of hierarchies is used to improve the performance of linear </context>
<context position="7146" citStr="Malioutov and Barzilay, 2006" startWordPosition="1103" endWordPosition="1106">ts the lexical cohesion in a vector space by exploring the word cooccurrence patterns, e.g., TF or TF-IDF. Work following this line includes TextTiling (Hearst, 1997), which calculates the cosine similarity between two adjacent blocks of words purely based on the word frequency; C99 (Choi, 2000), an algorithm based on divisive clustering with a matrix-ranking scheme; LSeg (Galley et al., 2003), which uses a lexical chain to identify and weight word repetitions; U00 (Utiyama and Isahara, 2001), a probalistic approach using dynamic programming to find a segmentation with a minimum cost; MinCut (Malioutov and Barzilay, 2006), which casts segmentation as a graph cut problem, and APS (Kazantseva and Szpakowicz, 2011), which uses affinity propagation to learn clustering for segmentation. The other branch of this work characterises the lexical cohesion using topic models, to which the model introduced in Section 3 belongs. Lexical cohesion in this line of research is modelled by a probabilistic generative process. PLDA presented by Purver et al. (2006) is an unsupervised topic modelling approach for segmentation. It chains a set of LDAs (Blei et al., 2003) by assuming a Markov structure on topic distributions. A bina</context>
<context position="30834" citStr="Malioutov and Barzilay, 2006" startWordPosition="5347" endWordPosition="5351">4.1 51.0 49.7 45.1 51.0 48.7 47.5 45.9 38.5 44.1 Even 48.3 43.0 46.4 56.0 55.1 51.2 48.1 45.9 46.3 49.2 42.0 48.8 C99 42.9 37.4 39.9 43.1 41.5 37.0 48.1 45.1 42.1 39.7 31.9 38.7 MinCut 40.6 36.9 36.9 43.6 43.3 39.0 40.5 39.7 37.1 38.2 36.2 36.8 APS 58.2 49.7 54.6 47.7 36.8 40.6 48.0 45.8 45.1 39.9 32.8 39.6 Bayesseg 32.4 29.7 26.7 41.1 41.3 34.1 33.7 32.8 27.8 35.0 28.8 34.0 PLDA 32.6 28.8 29.4 40.6 41.1 32.0 43.0 41.3 36.1 37.3 32.1 32.4 TSM 30.2 26.8 25.8 38.1 38.9 31.3 40.8 38.7 32.5 34.5 29.1 30.6 P(P=1) P(P = 1) Note the lexical transitions in these concatenated documents are very sharp (Malioutov and Barzilay, 2006). The sharp transitions lead to significant change in segment level topic distributions, which further implies the variance of these distributions is large. In TSM, a large variance causes a small concentration parameter b. We observed that the sampled b’s (about 0.1) are indeed small for the four subsets, which shows there is no topic sharing among segments. Therefore, TSM is able to recognise the segments are unrelated text. 5.2 Evaluation on Meeting Transcripts We applied our model to segmenting the two meeting transcripts, which are the ICSI meeting transcripts (Janin et al., 2003) and the</context>
</contexts>
<marker>Malioutov, Barzilay, 2006</marker>
<rawString>Igor Malioutov and Regina Barzilay. 2006. Minimum cut model for spoken lecture segmentation. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics, ACL44, pages 25–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hemant Misra</author>
<author>Olivier Cappe</author>
<author>Francois Yvon</author>
</authors>
<title>Using LDA to detect semantically incoherent documents.</title>
<date>2008</date>
<booktitle>In Proceedings of CoNLL-08,</booktitle>
<pages>41--48</pages>
<contexts>
<context position="3412" citStr="Misra et al., 2008" startWordPosition="505" endWordPosition="508">ian methods (Du et al., 2010; Chen et al., 2011; Du et al., 2012a), and is based on Bayesian segmentation methods (Goldwater et al., 2009; Purver et al., 2006; Eisenstein and Barzilay, 2008) using topic models. This can also be viewed as a multi-topic extension of hierarchical Bayesian segmentation (Eisenstein, 2009), although our use of hierarchies is used to improve the performance of linear segmentation, rather than develop hierarchical segmentation. Recently, topic models are increasingly used in various text analysis tasks including topic segmentation. Previous work (Purver et al., 2006; Misra et al., 2008; Sun et al., 2008; Misra et al., 2009; Riedl and Biemann, 2012) has shown that using 190 Proceedings of NAACL-HLT 2013, pages 190–200, Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics topic assignments or topic distributions instead of word frequency can significantly improve segmentation performance. Here we consider more advanced topic models that model dependencies between (sub-)sections in a document, such as structured topic models (STMs) presented in (Du et al., 2010; Du et al., 2012b). STMs treat each text as a sequence of segments, each of which is a </context>
<context position="11277" citStr="Misra et al., 2008" startWordPosition="1771" endWordPosition="1774"> non-parametric methods and a significant change in segment level topic distribution indicates a segment change. Our unsupervised topic segmentation model is based on the premise that using a hierarchical topic model like the STM with a point-wise segment sampling algorithm should allow better detection of topic boundaries. We believe that (1) segment change should be associated with significant change in the topic distribution, (2) topic cohesion can be reflected in document topic structure, (3) the loglikelihood of a topically coherent segment is typically higher than an incoherent segment (Misra et al., 2008). Assume we have a corpus of D documents, each document d consists of a sequence of Ud text passages, and each passage u contains a set of Nd,u words denoted by wd,u that are from a vocabulary W. Our model consists of: Modelling topic boundary: We assume each document has its own topic shift probability 7rd, a Beta distributed random variable, i.e., 7rd—Beta(A0, A1). Then, we associate a boundary indicator variable pd,u with u, like the topic shift variable in PLDA and SITS. pd,u is Bernoulli distributed with parameter 7rd, i.e., pd,u—Bernoulli(7rd). It indicates whether there is a topic bound</context>
</contexts>
<marker>Misra, Cappe, Yvon, 2008</marker>
<rawString>Hemant Misra, Olivier Cappe, and Francois Yvon. 2008. Using LDA to detect semantically incoherent documents. In Proceedings of CoNLL-08, pages 41–48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hemant Misra</author>
<author>Franc¸ois Yvon</author>
<author>Joemon M Jose</author>
<author>Olivier Cappe</author>
</authors>
<title>Text segmentation via topic modeling: an analytical study.</title>
<date>2009</date>
<booktitle>In Proceedings of the 18th ACM conference on Information and knowledge management, CIKM ’09,</booktitle>
<pages>1553--1556</pages>
<contexts>
<context position="3450" citStr="Misra et al., 2009" startWordPosition="513" endWordPosition="516">al., 2011; Du et al., 2012a), and is based on Bayesian segmentation methods (Goldwater et al., 2009; Purver et al., 2006; Eisenstein and Barzilay, 2008) using topic models. This can also be viewed as a multi-topic extension of hierarchical Bayesian segmentation (Eisenstein, 2009), although our use of hierarchies is used to improve the performance of linear segmentation, rather than develop hierarchical segmentation. Recently, topic models are increasingly used in various text analysis tasks including topic segmentation. Previous work (Purver et al., 2006; Misra et al., 2008; Sun et al., 2008; Misra et al., 2009; Riedl and Biemann, 2012) has shown that using 190 Proceedings of NAACL-HLT 2013, pages 190–200, Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics topic assignments or topic distributions instead of word frequency can significantly improve segmentation performance. Here we consider more advanced topic models that model dependencies between (sub-)sections in a document, such as structured topic models (STMs) presented in (Du et al., 2010; Du et al., 2012b). STMs treat each text as a sequence of segments, each of which is a set of text passages (e.g., a paragrap</context>
<context position="4965" citStr="Misra et al., 2009" startWordPosition="754" endWordPosition="757">itly learning the segmentation, STMs just leverage the existing structure of documents from the given segmentation. Given a sequence of text passages, how can we automatically learn the segmentation? The word boundary sampling algorithm introduced in (Goldwater et al., 2009) uses point-wise sampling of word boundaries after phonemes in an utterance. Similarly, the segmentation method of PLDA (Purver et al., 2006) samples segment boundaries, but also jointly samples a topic model. This is different to other topic modelling approaches that run LDA as a precursor to a separate segmentation step (Misra et al., 2009; Riedl and Biemann, 2012). While conceptually similar to PLDA, our non-parametric approach built on STM required new methods to implement, but the resulting improvement by the standard segmentation scores is substantial. This paper presents a new hierarchical Bayesian unsupervised topic segmentation model, integrating a point-wise boundary sampling algorithm with a structured topic model. This new model takes advantage of the high modelling accuracy of structured topic models (Du et al., 2010) to produce a topic segmentation based on the distribution of latent topics. We show that this model </context>
<context position="8830" citStr="Misra et al., 2009" startWordPosition="1386" endWordPosition="1389">in191 formation. SITS further assumes speakers have different topic change probabilities that work as priors on topic shift variables. Instead of assuming documents in a dataset share the same set of topics, Bayesseg (Eisenstein and Barzilay, 2008) treats words in a segment generated from a segment specific multinomial language model, i.e., it assumes each segment is generated from one topic, and a later hierarchical extension (Eisenstein, 2009) assumes each segment is generated from one topic or its parents. Other methods using as input the output of topic models include (Sun et al., 2008), (Misra et al., 2009), and (Riedl and Biemann, 2012). In this paper we take a generative approach lying between PLDA and SITS. In contrast to PLDA, which uses a flat topic model (i.e., LDA), we assume each text has a latent topic structure that can reflect the topic coherence pattern, and the model adapts its parameters to the segments to further improve performance. Unlike SITS that targets analysing multiparty meeting transcripts, where speaker identities are available, we are interested in more general texts and assume each text has a specific topic change probability, since (1) the identity information is not </context>
<context position="29224" citStr="Misra et al., 2009" startWordPosition="5025" endWordPosition="5028">Choi’s dataset (Choi, 2000) is commonly used in evaluating topic segmentation methods. It consists of 700 documents, each being a concatenation of 10 segments. Each segment is the first n sentences of a randomly selected document from the Brown corpus, s.t. 3 &lt; n &lt; 11. Those documents are divided into 4 subsets with different range of n, as shown in Table 2. We ran PLDA and STM with 50 topics. Results in Table 4 show that our model significantly outperforms all the other methods on the four subsets over all the metrics. Furthermore, comparing to other published results, this also outperforms (Misra et al., 2009) (see their table 2), and (Riedl and Biemann, 2012) (they report an average of 1.04 and 1.06 in Tables 1 and 2, whereas TSM averages 0.93). This gives TSM the best reported results to date. 196 Table 4: Comparison on Choi’s datasets with WD and PK (%) 3-11 3-5 6-8 9-11 WDT WDe PK WDT WDe PK WDT WDe PK WDT WDe PK Random 51.7 49.1 48.7 51.4 50.0 48.4 52.5 49.9 49.2 52.4 48.9 49.2 Even 49.1 46.7 49.0 46.3 45.8 46.3 38.8 37.3 38.8 30.0 28.6 30.0 MinCut 30.4 29.8 26.7 41.6 41.5 37.3 28.2 27.4 25.5 23.6 22.7 21.6 APS 40.7 38.8 38.4 32.0 30.6 31.8 34.4 32.6 32.7 34.5 32.2 33.2 C99 13.5 12.3 12.3 11.3</context>
<context position="32347" citStr="Misra et al., 2009" startWordPosition="5608" endWordPosition="5611">shown in Table 3. PLDA and TSM were trained with 10 topics on the ICSI and 50 on the Election. In this set of experiments, we show that our model is robust to meeting transcripts. TSM 0.2 0 PIDA 0.2 0 0 100 200 300 400 500 600 700 800 Utterance position in sequence Figure 2: Probability of a topic boundary, compared with gold-standard segmentation (shown in red and at the top of each diagram) on one ICSI transcript. As shown in Table 5, topic modelling based methods (i.e., Bayesseg, PLDA and TSM) outperform those using either TF or TF-IDF, which is consistent with previously reported results (Misra et al., 2009; Riedl and Biemann, 2012). Among the topic model based methods, TSM achieves the best results on all the three metrics. On the ICSI transcripts, TSM performs 6.8%, 9.7% and 3.4% better than Bayesseg on the WD&apos;, WDe and PK metrics respectively. Figure 2 shows an example of how the inferred topic boundary probabilities at utterances compare with the gold-standard boundaries on one ICSI meeting transcript. The gold-standard segmentation is {77, 95, 189, 365, 508, 609, 8601, TSM and PLDA infer {85, 96, 188, 363, 499, 508, 860} and {96, 136, 0.6 0.4 0.6 0.4 197 Table 6: Sampled concentration param</context>
</contexts>
<marker>Misra, Yvon, Jose, Cappe, 2009</marker>
<rawString>Hemant Misra, Franc¸ois Yvon, Joemon M. Jose, and Olivier Cappe. 2009. Text segmentation via topic modeling: an analytical study. In Proceedings of the 18th ACM conference on Information and knowledge management, CIKM ’09, pages 1553–1556.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Viet-An Nguyen</author>
<author>Jordan Boyd-Graber</author>
<author>Philip Resnik</author>
</authors>
<title>SITS: A hierarchical nonparametric model using speaker identity for topic segmentation in multiparty conversations.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),</booktitle>
<pages>78--87</pages>
<contexts>
<context position="8023" citStr="Nguyen et al., 2012" startWordPosition="1249" endWordPosition="1252"> the model introduced in Section 3 belongs. Lexical cohesion in this line of research is modelled by a probabilistic generative process. PLDA presented by Purver et al. (2006) is an unsupervised topic modelling approach for segmentation. It chains a set of LDAs (Blei et al., 2003) by assuming a Markov structure on topic distributions. A binary topic shift variable is attached to each text passage (i.e., an utterance in (Purver et al., 2006)). It is sampled to indicate whether the jth text passage shares the topic distribution with the (j − 1)th passage. Using a similar Markov structure, SITS (Nguyen et al., 2012) chains a set of HDP-LDAs (Teh et al., 2006). Unlike PLDA, SITS assumes each text passage is associated with a speaker identity that is attached to the topic shift variable as supervising in191 formation. SITS further assumes speakers have different topic change probabilities that work as priors on topic shift variables. Instead of assuming documents in a dataset share the same set of topics, Bayesseg (Eisenstein and Barzilay, 2008) treats words in a segment generated from a segment specific multinomial language model, i.e., it assumes each segment is generated from one topic, and a later hier</context>
<context position="31708" citStr="Nguyen et al., 2012" startWordPosition="5493" endWordPosition="5496">’s (about 0.1) are indeed small for the four subsets, which shows there is no topic sharing among segments. Therefore, TSM is able to recognise the segments are unrelated text. 5.2 Evaluation on Meeting Transcripts We applied our model to segmenting the two meeting transcripts, which are the ICSI meeting transcripts (Janin et al., 2003) and the 2008 presidential election debates (Boydstun et al., 2011). The ICSI meeting has 75 transcripts, we used the 25 annotated transcripts provided by Galley et al. (2003) for evaluation. For the election debates, we used the four annotated debates used in (Nguyen et al., 2012). The statistics are shown in Table 3. PLDA and TSM were trained with 10 topics on the ICSI and 50 on the Election. In this set of experiments, we show that our model is robust to meeting transcripts. TSM 0.2 0 PIDA 0.2 0 0 100 200 300 400 500 600 700 800 Utterance position in sequence Figure 2: Probability of a topic boundary, compared with gold-standard segmentation (shown in red and at the top of each diagram) on one ICSI transcript. As shown in Table 5, topic modelling based methods (i.e., Bayesseg, PLDA and TSM) outperform those using either TF or TF-IDF, which is consistent with previous</context>
<context position="33416" citStr="Nguyen et al. (2012)" startWordPosition="5791" endWordPosition="5794">, 189, 365, 508, 609, 8601, TSM and PLDA infer {85, 96, 188, 363, 499, 508, 860} and {96, 136, 0.6 0.4 0.6 0.4 197 Table 6: Sampled concentration parameters Choi ICSI Election Fiction Clinical b 0.1 5.2 5.4 18.4 4.8 203, 226, 361, 508, 8601 respectively. Both models miss the boundary after the 609th utterance, but put a boundary after the 508th utterance. Note the boundaries placed by TSM are always within 10 utterances with respect to the gold standard. Although TSM still performs the best on the debates, all the methods have relatively worse performance than on the ICSI meeting transcripts. Nguyen et al. (2012) pointed out that the ICSI meetings are characterised by pragmatic topic changes, in contrast, the debates are characterised by strategic topic changes with strong rewards for setting the agenda, dodging a question, etc. Thus, considering the properties of debates might further improve the segmentation performance. 5.3 Evaluation on Written Texts We further tested TSM on two written text datasets, Clinical (Eisenstein and Barzilay, 2008) and Fiction (Kazantseva and Szpakowicz, 2011). The statistics are shown in Table 3. Each document in the Clinical dataset is a chapter of a medical textbook. </context>
<context position="36535" citStr="Nguyen et al., 2012" startWordPosition="6294" endWordPosition="6297"> shows prominent segmentation performance on both written or spoken texts. In future work, we would like to make the model fully nonparametric and investigate the effects of adding different cues in texts, such as cue phrases, pronoun usage, prosody, etc. Currently, our model uses marginal boundary probabilities to generate the final segmentation. Instead, we could develop a Metropolis-Hasting sampling algorithm to move one boundary at a time, given the gold-standard number of segments. To further study the effectiveness of our model, we would like to compare it with other methods, like SITS (Nguyen et al., 2012) and to run on more datasets, like email (Joty et al., 2010). For example, in order to compare with SITS, one can make an assumption that each document just has one speaker. Acknowledgments The authors would like to thank all the anonymous reviewers for their valuable comments. This research was supported under Australian Research Council’s Discovery Projects funding scheme (project numbers DP110102506 and DP110102593). NICTA is funded by the Australian Government as represented by the Department of Broadband, Communications and the Digital Economy and the Australian Research Council through t</context>
</contexts>
<marker>Nguyen, Boyd-Graber, Resnik, 2012</marker>
<rawString>Viet-An Nguyen, Jordan Boyd-Graber, and Philip Resnik. 2012. SITS: A hierarchical nonparametric model using speaker identity for topic segmentation in multiparty conversations. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 78–87.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lev Pevzner</author>
<author>Marti A Hearst</author>
</authors>
<title>A critique and improvement of an evaluation metric for text segmentation.</title>
<date>2002</date>
<journal>Comput. Linguist.,</journal>
<volume>28</volume>
<issue>1</issue>
<contexts>
<context position="25749" citStr="Pevzner and Hearst, 2002" startWordPosition="4424" endWordPosition="4427">hree different kinds of corpora4: a set of synthetic documents, two meeting transcripts and two sets of text books (see Tables 2 and 3); and compare TSM with the following methods: two baselines (the Random algorithm that places topic boundaries uniformly at random, and the Even algorithm that places a boundary after every mth text passage, where m is the average gold-standard segment length (Beeferman et al., 1999)), C99, MinCut, Bayesseg, APS (Kazantseva and Szpakowicz, 2011), and PLDA. Metrics: We evaluated the segmentation performance with PK (Beeferman et al., 1999) and WindowDiff (WD&apos;) (Pevzner and Hearst, 2002), which are two common metrics used in topic segmentation. Both move a sliding window of fixed size k over the document, and compare the inferred segmentation with the gold-standard segmentation for each window. The window size is usually set to the half of the average gold-standard segment size (Pevzner and Hearst, 2002). In addition, we also used an extended WindowDiff proposed by Lamprier et al. (2007), denoted by WD&apos;. One problem of WD&apos; is that errors near the two ends of a text are penalised less than those in the middle. To solve the problem WD&apos; adds k fictive text passages at the beginn</context>
</contexts>
<marker>Pevzner, Hearst, 2002</marker>
<rawString>Lev Pevzner and Marti A. Hearst. 2002. A critique and improvement of an evaluation metric for text segmentation. Comput. Linguist., 28(1):19–36.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Pitman</author>
<author>M Yor</author>
</authors>
<title>The two-parameter PoissonDiriclet distribution derived from a stable subordinator. Annals Probability,</title>
<date>1997</date>
<pages>25--855</pages>
<contexts>
<context position="14907" citStr="Pitman and Yor, 1997" startWordPosition="2447" endWordPosition="2451"> parameterized with a K x Wmatrix 4&gt; = (O1, ..., OK). In future work we plan to investigate replace the Table 1: List of statistics Mk,71 total number of words with topic k. Mk a vector of Mk,711. nd,s,k total number of words with topic k in segment s in document d. Nd,s total number of words in segment s. td,s,k table count of topic k in the CRP for segment s in document d. td,s a vector of td,s,k for segment s in d. Td,s total table count in segment s. cd,1 total number of topic boundaries in d. cd,0 total number of non-topic boundaries in d. Dirichlet prior cx on µ with a Pitman-Yor prior (Pitman and Yor, 1997) to make the model fully nonparametric, like SITS. 4 Posterior Inference In this section we develop a collapsed Gibbs sampling algorithm to do an approximate inference by integrating out some latent variables (i.e., µ’s, V’s and �d’s). The hierarchy in our model can be well explained with the Chinese restaurant franchise metaphor introduced in (Teh et al., 2006). For easier understanding, terminologies of the Chinese Restaurant Process (CRP) will be used throughout this section, i.e., customers, dishes and restaurants, correspond to words, topics, and segments respectively. Statistics used are</context>
</contexts>
<marker>Pitman, Yor, 1997</marker>
<rawString>J. Pitman and M. Yor. 1997. The two-parameter PoissonDiriclet distribution derived from a stable subordinator. Annals Probability, 25:855–900.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Purver</author>
<author>Thomas L Griffiths</author>
<author>Konrad P K¨ording</author>
<author>Joshua B Tenenbaum</author>
</authors>
<title>Unsupervised topic modelling for multi-party spoken discourse.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics, ACL44,</booktitle>
<pages>17--24</pages>
<marker>Purver, Griffiths, K¨ording, Tenenbaum, 2006</marker>
<rawString>Matthew Purver, Thomas L. Griffiths, Konrad P. K¨ording, and Joshua B. Tenenbaum. 2006. Unsupervised topic modelling for multi-party spoken discourse. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics, ACL44, pages 17–24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeffrey C Reynar</author>
</authors>
<title>Statistical models for topic segmentation.</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>357--364</pages>
<contexts>
<context position="2239" citStr="Reynar, 1999" startWordPosition="326" endWordPosition="327">al (Salton et al., 1996)), document summarisation and discourse analysis (Galley et al., 2003). In this paper we consider how to automatically find a topic segmentation. It involves identifying the most prominent topic changes in a sequence of text passages, and splits those passages into a sequence of topically coherent segments (Hearst, 1997; Beeferman et al., 1999). This task can be cast as an unsupervised machine learning problem: placing topic boundaries in unannotated text. Although a variety of cues in text can be used for topic segmentation, such as cue phases (Beeferman et al., 1999; Reynar, 1999; Eisenstein and Barzilay, 2008)) and discourse information (Galley et al., 2003), in this paper, we focus on lexical cohesion and use it as the primary cue in developing an unsupervised segmentation model. The effectiveness of lexical cohesion has been demonstrated by TextTiling (Hearst, 1997), c99 (Choi, 2000), MinCut (Malioutov and Barzilay, 2006), PLDA (Purver et al., 2006), Bayesseg (Eisenstein and Barzilay, 2008), TopicTiling (Riedl and Biemann, 2012), etc. Our work uses recent progress in hierarchical topic modelling with non-parametric Bayesian methods (Du et al., 2010; Chen et al., 20</context>
<context position="34614" citStr="Reynar, 1999" startWordPosition="5987" endWordPosition="5988">ical textbook. Section breaks are selected to be the true topic boundaries. For the Fiction dataset, each document is a fiction downloaded from Project Gutenberg, the true topic boundaries are chapter breaks. We trained PLDA and TSM with 25 topics on the Fiction and 50 on the Clinical. Results are shown in Table 5. TSM compares favourably with Bayesseg and outperforms the other methods on the Clinical dataset, but it does not perform as well as Bayesseg on the Fiction dataset. In fiction books, the topic boundaries between sections are usually blurred by the authors for reasons of continuity (Reynar, 1999). We observed that the sampled concentration (or inverse variance) parameter b in TSM is about 18.4 on Fiction, but 4.8 on Clinical, as shown in Table 6. This means the variance of segment level topic distributions v learnt by TSM is not large for the fiction, so chapter breaks may not necessarily indicate topic changes. For example, there is a document in the Fiction dataset where gold-standard topic boundaries are placed after each block of text. In contrast, Bayesseg assumes each segment has its own distribution over words, i.e., one topic per segment, which means topics are not shared amon</context>
</contexts>
<marker>Reynar, 1999</marker>
<rawString>Jeffrey C. Reynar. 1999. Statistical models for topic segmentation. In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics, pages 357–364.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Riedl</author>
<author>Chris Biemann</author>
</authors>
<title>How text segmentation algorithms gain from topic models.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Conference of the North American Chapter of the Association</booktitle>
<contexts>
<context position="2700" citStr="Riedl and Biemann, 2012" startWordPosition="394" endWordPosition="397">pic boundaries in unannotated text. Although a variety of cues in text can be used for topic segmentation, such as cue phases (Beeferman et al., 1999; Reynar, 1999; Eisenstein and Barzilay, 2008)) and discourse information (Galley et al., 2003), in this paper, we focus on lexical cohesion and use it as the primary cue in developing an unsupervised segmentation model. The effectiveness of lexical cohesion has been demonstrated by TextTiling (Hearst, 1997), c99 (Choi, 2000), MinCut (Malioutov and Barzilay, 2006), PLDA (Purver et al., 2006), Bayesseg (Eisenstein and Barzilay, 2008), TopicTiling (Riedl and Biemann, 2012), etc. Our work uses recent progress in hierarchical topic modelling with non-parametric Bayesian methods (Du et al., 2010; Chen et al., 2011; Du et al., 2012a), and is based on Bayesian segmentation methods (Goldwater et al., 2009; Purver et al., 2006; Eisenstein and Barzilay, 2008) using topic models. This can also be viewed as a multi-topic extension of hierarchical Bayesian segmentation (Eisenstein, 2009), although our use of hierarchies is used to improve the performance of linear segmentation, rather than develop hierarchical segmentation. Recently, topic models are increasingly used in </context>
<context position="4991" citStr="Riedl and Biemann, 2012" startWordPosition="758" endWordPosition="761">gmentation, STMs just leverage the existing structure of documents from the given segmentation. Given a sequence of text passages, how can we automatically learn the segmentation? The word boundary sampling algorithm introduced in (Goldwater et al., 2009) uses point-wise sampling of word boundaries after phonemes in an utterance. Similarly, the segmentation method of PLDA (Purver et al., 2006) samples segment boundaries, but also jointly samples a topic model. This is different to other topic modelling approaches that run LDA as a precursor to a separate segmentation step (Misra et al., 2009; Riedl and Biemann, 2012). While conceptually similar to PLDA, our non-parametric approach built on STM required new methods to implement, but the resulting improvement by the standard segmentation scores is substantial. This paper presents a new hierarchical Bayesian unsupervised topic segmentation model, integrating a point-wise boundary sampling algorithm with a structured topic model. This new model takes advantage of the high modelling accuracy of structured topic models (Du et al., 2010) to produce a topic segmentation based on the distribution of latent topics. We show that this model provides high quality segm</context>
<context position="8861" citStr="Riedl and Biemann, 2012" startWordPosition="1391" endWordPosition="1394">her assumes speakers have different topic change probabilities that work as priors on topic shift variables. Instead of assuming documents in a dataset share the same set of topics, Bayesseg (Eisenstein and Barzilay, 2008) treats words in a segment generated from a segment specific multinomial language model, i.e., it assumes each segment is generated from one topic, and a later hierarchical extension (Eisenstein, 2009) assumes each segment is generated from one topic or its parents. Other methods using as input the output of topic models include (Sun et al., 2008), (Misra et al., 2009), and (Riedl and Biemann, 2012). In this paper we take a generative approach lying between PLDA and SITS. In contrast to PLDA, which uses a flat topic model (i.e., LDA), we assume each text has a latent topic structure that can reflect the topic coherence pattern, and the model adapts its parameters to the segments to further improve performance. Unlike SITS that targets analysing multiparty meeting transcripts, where speaker identities are available, we are interested in more general texts and assume each text has a specific topic change probability, since (1) the identity information is not always available for all kinds </context>
<context position="29275" citStr="Riedl and Biemann, 2012" startWordPosition="5034" endWordPosition="5038">n evaluating topic segmentation methods. It consists of 700 documents, each being a concatenation of 10 segments. Each segment is the first n sentences of a randomly selected document from the Brown corpus, s.t. 3 &lt; n &lt; 11. Those documents are divided into 4 subsets with different range of n, as shown in Table 2. We ran PLDA and STM with 50 topics. Results in Table 4 show that our model significantly outperforms all the other methods on the four subsets over all the metrics. Furthermore, comparing to other published results, this also outperforms (Misra et al., 2009) (see their table 2), and (Riedl and Biemann, 2012) (they report an average of 1.04 and 1.06 in Tables 1 and 2, whereas TSM averages 0.93). This gives TSM the best reported results to date. 196 Table 4: Comparison on Choi’s datasets with WD and PK (%) 3-11 3-5 6-8 9-11 WDT WDe PK WDT WDe PK WDT WDe PK WDT WDe PK Random 51.7 49.1 48.7 51.4 50.0 48.4 52.5 49.9 49.2 52.4 48.9 49.2 Even 49.1 46.7 49.0 46.3 45.8 46.3 38.8 37.3 38.8 30.0 28.6 30.0 MinCut 30.4 29.8 26.7 41.6 41.5 37.3 28.2 27.4 25.5 23.6 22.7 21.6 APS 40.7 38.8 38.4 32.0 30.6 31.8 34.4 32.6 32.7 34.5 32.2 33.2 C99 13.5 12.3 12.3 11.3 10.2 10.8 10.2 9.3 9.8 8.9 8.1 8.6 Bayesseg 11.6 1</context>
<context position="32373" citStr="Riedl and Biemann, 2012" startWordPosition="5612" endWordPosition="5615">DA and TSM were trained with 10 topics on the ICSI and 50 on the Election. In this set of experiments, we show that our model is robust to meeting transcripts. TSM 0.2 0 PIDA 0.2 0 0 100 200 300 400 500 600 700 800 Utterance position in sequence Figure 2: Probability of a topic boundary, compared with gold-standard segmentation (shown in red and at the top of each diagram) on one ICSI transcript. As shown in Table 5, topic modelling based methods (i.e., Bayesseg, PLDA and TSM) outperform those using either TF or TF-IDF, which is consistent with previously reported results (Misra et al., 2009; Riedl and Biemann, 2012). Among the topic model based methods, TSM achieves the best results on all the three metrics. On the ICSI transcripts, TSM performs 6.8%, 9.7% and 3.4% better than Bayesseg on the WD&apos;, WDe and PK metrics respectively. Figure 2 shows an example of how the inferred topic boundary probabilities at utterances compare with the gold-standard boundaries on one ICSI meeting transcript. The gold-standard segmentation is {77, 95, 189, 365, 508, 609, 8601, TSM and PLDA infer {85, 96, 188, 363, 499, 508, 860} and {96, 136, 0.6 0.4 0.6 0.4 197 Table 6: Sampled concentration parameters Choi ICSI Election F</context>
</contexts>
<marker>Riedl, Biemann, 2012</marker>
<rawString>Martin Riedl and Chris Biemann. 2012. How text segmentation algorithms gain from topic models. In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerard Salton</author>
<author>Amit Singhal</author>
<author>Chris Buckley</author>
<author>Mandar Mitra</author>
</authors>
<title>Automatic text decomposition using text segments and text themes.</title>
<date>1996</date>
<booktitle>In Proceedings of the the seventh ACM conference on Hypertext,</booktitle>
<pages>53--65</pages>
<contexts>
<context position="1144" citStr="Salton et al., 1996" startWordPosition="155" endWordPosition="158">on into a structured topic model that can capture a simple hierarchical topic structure latent in documents. We develop an MCMC inference algorithm to split/merge segment(s). Experimental results show that our model outperforms previous unsupervised segmentation methods using only lexical information on Choi’s datasets and two meeting transcripts and has performance comparable to those previous methods on two written datasets. 1 Introduction Documents are usually comprised of topically coherent text segments, each of which contains some number of text passages (e.g., sentences or paragraphs) (Salton et al., 1996). Within each topically coherent segment, one would expect that the word usage demonstrates more consistent lexical distributions (known as lexical cohesion (Eisenstein and Barzilay, 2008)) than that across segments. A linear partition of texts into topic segments may reveal information about, for example, themes of segments and the overall thematic structure of the text, and can subsequently be useful for text analysis tasks, such as information retrieval (e.g., passage retrieval (Salton et al., 1996)), document summarisation and discourse analysis (Galley et al., 2003). In this paper we cons</context>
</contexts>
<marker>Salton, Singhal, Buckley, Mitra, 1996</marker>
<rawString>Gerard Salton, Amit Singhal, Chris Buckley, and Mandar Mitra. 1996. Automatic text decomposition using text segments and text themes. In Proceedings of the the seventh ACM conference on Hypertext, pages 53–65.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qi Sun</author>
<author>Runxin Li</author>
<author>Dingsheng Luo</author>
<author>Xihong Wu</author>
</authors>
<title>Text segmentation with LDA-based Fisher kernel.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT, Short Papers,</booktitle>
<pages>269--272</pages>
<contexts>
<context position="3430" citStr="Sun et al., 2008" startWordPosition="509" endWordPosition="512">l., 2010; Chen et al., 2011; Du et al., 2012a), and is based on Bayesian segmentation methods (Goldwater et al., 2009; Purver et al., 2006; Eisenstein and Barzilay, 2008) using topic models. This can also be viewed as a multi-topic extension of hierarchical Bayesian segmentation (Eisenstein, 2009), although our use of hierarchies is used to improve the performance of linear segmentation, rather than develop hierarchical segmentation. Recently, topic models are increasingly used in various text analysis tasks including topic segmentation. Previous work (Purver et al., 2006; Misra et al., 2008; Sun et al., 2008; Misra et al., 2009; Riedl and Biemann, 2012) has shown that using 190 Proceedings of NAACL-HLT 2013, pages 190–200, Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics topic assignments or topic distributions instead of word frequency can significantly improve segmentation performance. Here we consider more advanced topic models that model dependencies between (sub-)sections in a document, such as structured topic models (STMs) presented in (Du et al., 2010; Du et al., 2012b). STMs treat each text as a sequence of segments, each of which is a set of text passag</context>
<context position="8808" citStr="Sun et al., 2008" startWordPosition="1382" endWordPosition="1385">able as supervising in191 formation. SITS further assumes speakers have different topic change probabilities that work as priors on topic shift variables. Instead of assuming documents in a dataset share the same set of topics, Bayesseg (Eisenstein and Barzilay, 2008) treats words in a segment generated from a segment specific multinomial language model, i.e., it assumes each segment is generated from one topic, and a later hierarchical extension (Eisenstein, 2009) assumes each segment is generated from one topic or its parents. Other methods using as input the output of topic models include (Sun et al., 2008), (Misra et al., 2009), and (Riedl and Biemann, 2012). In this paper we take a generative approach lying between PLDA and SITS. In contrast to PLDA, which uses a flat topic model (i.e., LDA), we assume each text has a latent topic structure that can reflect the topic coherence pattern, and the model adapts its parameters to the segments to further improve performance. Unlike SITS that targets analysing multiparty meeting transcripts, where speaker identities are available, we are interested in more general texts and assume each text has a specific topic change probability, since (1) the identi</context>
</contexts>
<marker>Sun, Li, Luo, Wu, 2008</marker>
<rawString>Qi Sun, Runxin Li, Dingsheng Luo, and Xihong Wu. 2008. Text segmentation with LDA-based Fisher kernel. In Proceedings of ACL-08: HLT, Short Papers, pages 269–272.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y W Teh</author>
<author>M I Jordan</author>
<author>M J Beal</author>
<author>D M Blei</author>
</authors>
<title>Hierarchical Dirichlet processes.</title>
<date>2006</date>
<journal>Journal of the American Statistical Association,</journal>
<volume>101</volume>
<issue>476</issue>
<contexts>
<context position="8067" citStr="Teh et al., 2006" startWordPosition="1258" endWordPosition="1261">ical cohesion in this line of research is modelled by a probabilistic generative process. PLDA presented by Purver et al. (2006) is an unsupervised topic modelling approach for segmentation. It chains a set of LDAs (Blei et al., 2003) by assuming a Markov structure on topic distributions. A binary topic shift variable is attached to each text passage (i.e., an utterance in (Purver et al., 2006)). It is sampled to indicate whether the jth text passage shares the topic distribution with the (j − 1)th passage. Using a similar Markov structure, SITS (Nguyen et al., 2012) chains a set of HDP-LDAs (Teh et al., 2006). Unlike PLDA, SITS assumes each text passage is associated with a speaker identity that is attached to the topic shift variable as supervising in191 formation. SITS further assumes speakers have different topic change probabilities that work as priors on topic shift variables. Instead of assuming documents in a dataset share the same set of topics, Bayesseg (Eisenstein and Barzilay, 2008) treats words in a segment generated from a segment specific multinomial language model, i.e., it assumes each segment is generated from one topic, and a later hierarchical extension (Eisenstein, 2009) assume</context>
<context position="15271" citStr="Teh et al., 2006" startWordPosition="2508" endWordPosition="2511">cument d. td,s a vector of td,s,k for segment s in d. Td,s total table count in segment s. cd,1 total number of topic boundaries in d. cd,0 total number of non-topic boundaries in d. Dirichlet prior cx on µ with a Pitman-Yor prior (Pitman and Yor, 1997) to make the model fully nonparametric, like SITS. 4 Posterior Inference In this section we develop a collapsed Gibbs sampling algorithm to do an approximate inference by integrating out some latent variables (i.e., µ’s, V’s and �d’s). The hierarchy in our model can be well explained with the Chinese restaurant franchise metaphor introduced in (Teh et al., 2006). For easier understanding, terminologies of the Chinese Restaurant Process (CRP) will be used throughout this section, i.e., customers, dishes and restaurants, correspond to words, topics, and segments respectively. Statistics used are listed in Table 1. To integrate out the Vd,s’s generated from the PYP, we use the technique presented in (Chen et al., 2011), which computes the joint posterior for the PYP by summing out all the possible seating arrangements for a sequence of customers (Teh, 2006). In this technique an auxiliary binary variable, called table indicator (Sd,u,n), is introduced t</context>
</contexts>
<marker>Teh, Jordan, Beal, Blei, 2006</marker>
<rawString>Y. W. Teh, M. I. Jordan, M. J. Beal, and D. M. Blei. 2006. Hierarchical Dirichlet processes. Journal of the American Statistical Association, 101(476):1566–1581.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y W Teh</author>
</authors>
<title>A Bayesian interpretation of interpolated Kneser-Ney.</title>
<date>2006</date>
<tech>Technical Report TRA2/06,</tech>
<institution>School of Computing, National University of Singapore.</institution>
<contexts>
<context position="15773" citStr="Teh, 2006" startWordPosition="2590" endWordPosition="2591"> model can be well explained with the Chinese restaurant franchise metaphor introduced in (Teh et al., 2006). For easier understanding, terminologies of the Chinese Restaurant Process (CRP) will be used throughout this section, i.e., customers, dishes and restaurants, correspond to words, topics, and segments respectively. Statistics used are listed in Table 1. To integrate out the Vd,s’s generated from the PYP, we use the technique presented in (Chen et al., 2011), which computes the joint posterior for the PYP by summing out all the possible seating arrangements for a sequence of customers (Teh, 2006). In this technique an auxiliary binary variable, called table indicator (Sd,u,n), is introduced to facilitate computing table count td,s,k for topic k. This method has two effects: (1) faster mixing of the sampler, and (2) elimination of the need for dynamic memory to store the populations/counts of each table in the CRP. In the CRP each word wd,u,n in topic k (i.e., where zd,u,n=k) contributes a count to nd,s,k for u C s; and, if wd,u,n, as a customer, also opens a new table to the CRP, it leads to increasing td,s,k by one. In this case, Sd,u,n=1 indicates wd,u,n is the first customer on the</context>
</contexts>
<marker>Teh, 2006</marker>
<rawString>Y. W. Teh. 2006. A Bayesian interpretation of interpolated Kneser-Ney. Technical Report TRA2/06, School of Computing, National University of Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Masao Utiyama</author>
<author>Hitoshi Isahara</author>
</authors>
<title>A statistical model for domain-independent text segmentation.</title>
<date>2001</date>
<booktitle>In Proceedings of 39th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>499--506</pages>
<contexts>
<context position="7014" citStr="Utiyama and Isahara, 2001" startWordPosition="1083" endWordPosition="1086"> of text based on lexical cohesion. It can be characterised by how lexical cohesion is modelled. One branch of this work represents the lexical cohesion in a vector space by exploring the word cooccurrence patterns, e.g., TF or TF-IDF. Work following this line includes TextTiling (Hearst, 1997), which calculates the cosine similarity between two adjacent blocks of words purely based on the word frequency; C99 (Choi, 2000), an algorithm based on divisive clustering with a matrix-ranking scheme; LSeg (Galley et al., 2003), which uses a lexical chain to identify and weight word repetitions; U00 (Utiyama and Isahara, 2001), a probalistic approach using dynamic programming to find a segmentation with a minimum cost; MinCut (Malioutov and Barzilay, 2006), which casts segmentation as a graph cut problem, and APS (Kazantseva and Szpakowicz, 2011), which uses affinity propagation to learn clustering for segmentation. The other branch of this work characterises the lexical cohesion using topic models, to which the model introduced in Section 3 belongs. Lexical cohesion in this line of research is modelled by a probabilistic generative process. PLDA presented by Purver et al. (2006) is an unsupervised topic modelling </context>
</contexts>
<marker>Utiyama, Isahara, 2001</marker>
<rawString>Masao Utiyama and Hitoshi Isahara. 2001. A statistical model for domain-independent text segmentation. In Proceedings of 39th Annual Meeting of the Association for Computational Linguistics, pages 499–506.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H M Wallach</author>
</authors>
<title>Structured topic models for language. doctoral dissertation,</title>
<date>2008</date>
<institution>Univ. of Cambridge.</institution>
<contexts>
<context position="20127" citStr="Wallach, 2008" startWordPosition="3371" endWordPosition="3372">{z−zd,u,n, w, S−δd,u,n, p, α, a, b,&apos;y}. From the two conditionals, we develop a blocked Gibbs sampling algorithm for (zd,u,n, Sd,u,n). 4.2 Sampling Segmentation Boundaries In our model, each segment corresponds to a Chinese restaurant in the CRP. Sampling topic boundaries corresponds to splitting/merging restaurant(s). This is different from the split-merge process proposed by Jian and Neal (2004), where one actually splits/merges table(s). To our knowledge, there has been no method developed to split/merge restaurant(s). We tried different approximations, such as the minimum-path-assumption (Wallach, 2008), which in our case assumes one table for each topic k, and all words in k are placed in the same table. Although this simplifies the split-merge process, it yielded poor results. We instead developed a novel approximate block Gibbs sampling algorithm using symmetric polynomials. Its segmentation performance worked well in our development dataset. For simplicity, we consider a passage u in document d, and assume: (1) If pd,u=1, there are two segments, sl and sr; sl ends at text passage u, and sr starts at text passage u+1. (2) If pd,u=0, there is one R= d R d R sEs = Ew(yw + Mk,w) b + aTd,s Sn</context>
</contexts>
<marker>Wallach, 2008</marker>
<rawString>H.M. Wallach. 2008. Structured topic models for language. doctoral dissertation, Univ. of Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hongning Wang</author>
<author>Duo Zhang</author>
<author>ChengXiang Zhai</author>
</authors>
<title>Structural topic model for latent topical structure analysis.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>1526--1535</pages>
<contexts>
<context position="9820" citStr="Wang et al., 2011" startWordPosition="1544" endWordPosition="1547">s analysing multiparty meeting transcripts, where speaker identities are available, we are interested in more general texts and assume each text has a specific topic change probability, since (1) the identity information is not always available for all kinds of texts (e.g., continuous broadcast news transcripts (Allan et al., 1998)), (2) even for the same author, topic change probabilities for his/her different articles might be different. 3 Segmentation with Topic Models In documents, topically coherent segments usually encapsulate a set of consecutive passages that are semantically related (Wang et al., 2011). However, the topic boundaries between segments are often unavailable a priori. Thus we treat all passage boundaries (e.g., sentence boundaries, paragraph boundaries or pauses between utterances) as possible topic boundaries. To recover the topic boundaries we develop a structured topic segmentation model by integrating ideas from the segmented topic model (Du et al., 2010, STM) and Bayesian segmentation models. The basic idea of our model is that each document consists of a set of segments where text passages in the same segment are generated from the same topic distribution, called segment </context>
</contexts>
<marker>Wang, Zhang, Zhai, 2011</marker>
<rawString>Hongning Wang, Duo Zhang, and ChengXiang Zhai. 2011. Structural topic model for latent topical structure analysis. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 1526–1535.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>