<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001199">
<title confidence="0.997696">
Lexically-Triggered Hidden Markov Models
for Clinical Document Coding
</title>
<author confidence="0.997018">
Svetlana Kiritchenko Colin Cherry
</author>
<affiliation confidence="0.991346">
Institute for Information Technology
National Research Council Canada
</affiliation>
<email confidence="0.842497">
{Svetlana.Kiritchenko,Colin.Cherry}@nrc-cnrc.gc.ca
</email>
<sectionHeader confidence="0.997479" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999866416666667">
The automatic coding of clinical documents
is an important task for today’s healthcare
providers. Though it can be viewed as
multi-label document classification, the cod-
ing problem has the interesting property that
most code assignments can be supported by
a single phrase found in the input docu-
ment. We propose a Lexically-Triggered Hid-
den Markov Model (LT-HMM) that leverages
these phrases to improve coding accuracy. The
LT-HMM works in two stages: first, a lexical
match is performed against a term dictionary
to collect a set of candidate codes for a docu-
ment. Next, a discriminative HMM selects the
best subset of codes to assign to the document
by tagging candidates as present or absent.
By confirming codes proposed by a dictio-
nary, the LT-HMM can share features across
codes, enabling strong performance even on
rare codes. In fact, we are able to recover
codes that do not occur in the training set at
all. Our approach achieves the best ever per-
formance on the 2007 Medical NLP Challenge
test set, with an F-measure of 89.84.
</bodyText>
<sectionHeader confidence="0.999472" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999979833333333">
The clinical domain presents a number of interesting
challenges for natural language processing. Con-
ventionally, most clinical documentation, such as
doctor’s notes, discharge summaries and referrals,
are written in a free-text form. This narrative form
is flexible, allowing healthcare professionals to ex-
press any kind of concept or event, but it is not
particularly suited for large-scale analysis, search,
or decision support. Converting clinical narratives
into a structured form would support essential activi-
ties such as administrative reporting, quality control,
biosurveillance and biomedical research (Meystre
et al., 2008). One way of representing a docu-
ment is to code the patient’s conditions and the per-
formed procedures into a nomenclature of clinical
codes. The International Classification of Diseases,
9th and 10th revisions, Clinical Modification (ICD-
9-CM, ICD-10-CM) are the official administrative
coding schemes for healthcare organizations in sev-
eral countries, including the US and Canada. Typi-
cally, coding is performed by trained coding profes-
sionals, but this process can be both costly and error-
prone. Automated methods can speed-up the cod-
ing process, improve the accuracy and consistency
of internal documentation, and even result in higher
reimbursement for the healthcare organization (Ben-
son, 2006).
Traditionally, statistical document coding is
viewed as multi-class multi-label document classifi-
cation, where each clinical free-text document is la-
belled with one or several codes from a pre-defined,
possibly very large set of codes (Patrick et al., 2007;
Suominen et al., 2008). One classification model is
learned for each code, and then all models are ap-
plied in turn to a new document to determine which
codes should be assigned to the document. The
drawback of this approach is poor predictive perfor-
mance on low-frequency codes, which are ubiqui-
tous in the clinical domain.
This paper presents a novel approach to document
coding that simultaneously models code-specific as
well as general patterns in the data. This allows
</bodyText>
<page confidence="0.945186">
742
</page>
<note confidence="0.9800795">
Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 742–751,
Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics
</note>
<bodyText confidence="0.997675857142857">
us to predict any code label, even codes for which
no training data is available. Our approach, the
lexically-triggered HMM (LT-HMM), is based on
the fact that a code assignment is often indicated
by short lexical triggers in the text. Consequently,
a two-stage coding method is proposed. First, the
LT-HMM identifies candidate codes by matching
terms from a medical terminology dictionary. Then,
it confirms or rejects each of the candidates by ap-
plying a discriminative sequence model. In this ar-
chitecture, low-frequency codes can still be matched
and confirmed using general characteristics of their
trigger’s local context, leading to better prediction
performance on these codes.
</bodyText>
<sectionHeader confidence="0.923582" genericHeader="introduction">
2 Document Coding and Lexical Triggers
</sectionHeader>
<bodyText confidence="0.999953138888889">
Document coding is a special case of multi-class
multi-label text classification. Given a fixed set of
possible codes, the ultimate goal is to assign a set of
codes to documents, based on their content. Further-
more, we observe that for each code assigned to a
document, there is generally at least one correspond-
ing trigger term in the text that accounts for the
code’s assignment. For example, if an ICD-9-CM
coding professional were to see “allergic bronchitis”
somewhere in a clinical narrative, he or she would
immediately consider adding code 493.9 (Asthma,
unspecified) to the document’s code set. The pres-
ence of these trigger terms separates document cod-
ing from text classification tasks, such as topic or
genre classification, where evidence for a particular
label is built up throughout a document. However,
this does not make document coding a term recogni-
tion task, concerned only with the detection of trig-
gers. Codes are assigned to a document as a whole,
and code assignment decisions within a document
may interact. It is an interesting combination of sen-
tence and document-level processing.
Formally, we define the document coding task
as follows: given a set of documents X and a set
of available codes C, assign to each document xi
a subset of codes Ci C C. We also assume ac-
cess to a (noisy) mechanism to detect candidate trig-
gers in a document. In particular, we will assume
that an (incomplete) dictionary D(c) exists for each
code c E C, which lists specific code terms asso-
ciated with c.1 To continue our running example:
D(493.9) would include the term “allergic bron-
chitis”. Each code can have several corresponding
terms while each term indicates the presence of ex-
actly one code. A candidate code c is proposed each
time a term from D(c) is found in a document.
</bodyText>
<subsectionHeader confidence="0.991269">
2.1 From triggers to codes
</subsectionHeader>
<bodyText confidence="0.9938418">
The presence of a term from D(c) does not automat-
ically imply the assignment of code c to a document.
Even with extremely precise dictionaries, there are
three main reasons why a candidate code may not
appear in a document’s code subset.
</bodyText>
<listItem confidence="0.974624791666667">
1. The context of the trigger term might indicate
the irrelevancy of the code. In the clinical do-
main, such irrelevancy can be specified by a
negative or speculative statement (e.g., “evalu-
ate for pneumonia”) or a family-related context
(e.g., “family history of diabetes”). Only defi-
nite diagnosis of the patient should be coded.
2. There can be several closely related candidate
codes; yet only one, the best fitted code should
be assigned to the document. For example, the
triggers “left-sided flank pain” (code 789.09)
and “abdominal pain” (code 789.00) may both
appear in the same clinical report, but only the
most specific code, 789.09, should end up in
the document code set.
3. The domain can have code dependency rules.
For example, the ICD-9-CM coding rules state
that no symptom codes should be given to
a document if a definite diagnosis is present.
That is, if a document is coded with pneumo-
nia, it should not be coded with a fever or
cough. On the other hand, if the diagnosis is
uncertain, then codes for the symptoms should
be assigned.
</listItem>
<bodyText confidence="0.9994584">
This suggests a paradigm where a candidate code,
suggested by a detected trigger term, is assessed
in terms of both its local context (item 1) and the
presence of other candidate codes for the document
(items 2 and 3).
</bodyText>
<footnote confidence="0.945867333333333">
1Note that dictionary-based trigger detection could be re-
placed by tagging approaches similar to those used in named-
entity-recognition or information extraction.
</footnote>
<page confidence="0.997108">
743
</page>
<subsectionHeader confidence="0.975244">
2.2 ICD-9-CM Coding
</subsectionHeader>
<bodyText confidence="0.999983256410257">
As a specific application we have chosen the task
of assigning ICD-9-CM codes to free-form clinical
narratives. We use the dataset collected for the 2007
Medical NLP Challenge organized by the Compu-
tational Medicine Center in Cincinnati, Ohio, here-
after refereed to as “CMC Challenge” (Pestian et al.,
2007). For this challenge, 1954 radiology reports
on outpatient chest x-ray and renal procedures were
collected, disambiguated, and anonymized. The re-
ports were annotated with ICD-9-CM codes by three
coding companies, and the majority codes were se-
lected as a gold standard. In total, 45 distinct codes
were used.
For this task, our use of a dictionary to detect lex-
ical triggers is quite reasonable. The medical do-
main is rich with manually-created and carefully-
maintained knowledge resources. In particular, the
ICD-9-CM coding guidelines come with an index
file that contains hundreds of thousands of terms
mapped to corresponding codes. Another valuable
resource is Metathesaurus from the Unified Medical
Language System (UMLS) (Lindberg et al., 1993).
It has millions of terms related to medical problems,
procedures, treatments, organizations, etc. Often,
hospitals, clinics, and other healthcare organizations
maintain their own vocabularies to introduce con-
sistency in their internal and external documenta-
tion and to support reporting, reviewing, and meta-
analysis.
This task has some very challenging properties.
As mentioned above, the ICD-9-CM coding rules
create strong code dependencies: codes are assigned
to a document as a set and not individually. Fur-
thermore, the code distribution throughout the CMC
training documents has a very heavy tail; that is,
there are a few heavily-used codes and a large
number of codes that are used only occasionally.
An ideal approach will work well with both high-
frequency and low-frequency codes.
</bodyText>
<sectionHeader confidence="0.999982" genericHeader="method">
3 Related work
</sectionHeader>
<bodyText confidence="0.999985811320755">
Automated clinical coding has received much atten-
tion in the medical informatics literature. Stanfill et
al. reviewed 113 studies on automated coding pub-
lished in the last 40 years (Stanfill et al., 2010). The
authors conclude that there exists a variety of tools
covering different purposes, healthcare specialties,
and clinical document types; however, these tools
are not generalizable and neither are their evaluation
results. One major obstacle that hinders the progress
in this domain is data privacy issues. To overcome
this obstacle, the CMC Challenge was organized in
2007. The purpose of the challenge was to provide
a common realistic dataset to stimulate the research
in the area and to assess the current level of perfor-
mance on the task. Forty-four teams participated in
the challenge. The top-performing system achieved
micro-averaged F1-score of 0.8908, and the mean
score was 0.7670.
Several teams, including the winner, built pure
symbolic (i.e., hand-crafted rule-based) systems
(e.g., (Goldstein et al., 2007)). This approach is fea-
sible for the small code set used in the challenge,
but it is questionable in real-life settings where thou-
sands of codes need to be considered. Later, the
winning team showed how their hand-crafted rules
can be built in a semi-automatic way: the initial set
of rules adopted from the official coding guidelines
were automatically extended with additional syn-
onyms and code dependency rules generated from
the training data (Farkas and Szarvas, 2008).
Statistical systems trained on only text-derived
features (such as n-grams) did not show good per-
formance due to a wide variety of medical language
and a relatively small training set (Goldstein et al.,
2007). This led to the creation of hybrid systems:
symbolic and statistical classifiers used together in
an ensemble or cascade (Aronson et al., 2007; Cram-
mer et al., 2007) or a symbolic component provid-
ing features for a statistical component (Patrick et
al., 2007; Suominen et al., 2008). Strong competi-
tion systems had good answers for dealing with neg-
ative and speculative contexts, taking advantage of
the competition’s limited set of possible code com-
binations, and handling of low-frequency codes.
Our proposed approach is a combination system
as well. We combine a symbolic component that
matches lexical strings of a document against a med-
ical dictionary to determine possible codes (Lussier
et al., 2000; Kevers and Medori, 2010) and a sta-
tistical component that finalizes the assignment of
codes to the document. Our statistical component
is similar to that of Crammer et al. (2007), in that
we train a single model for all codes with code-
</bodyText>
<page confidence="0.989248">
744
</page>
<bodyText confidence="0.9999004">
specific and generic features. However, Crammer
et al. (2007) did not employ our lexical trigger step
or our sequence-modeling formulation. In fact, they
considered all possible code subsets, which can be
infeasible in real-life settings.
</bodyText>
<sectionHeader confidence="0.981272" genericHeader="method">
4 Method
</sectionHeader>
<bodyText confidence="0.982909333333333">
To address the task of document coding, our
lexically-triggered HMM operates using a two-stage
procedure:
</bodyText>
<listItem confidence="0.9895115">
1. Lexically match text to the dictionary to get a
set of candidate codes;
2. Using features derived from the candidates and
the document, select the best code subset.
</listItem>
<bodyText confidence="0.999936526315789">
In the first stage, dictionary terms are detected in the
document using exact string matching. All codes
corresponding to matches become candidate codes,
and no other codes can be proposed for this docu-
ment.
In the second stage, a single classifier is trained to
select the best code subset from the matched candi-
dates. By training a single classifier, we use all of
the training data to assign binary labels (present or
absent) to candidates. This is the key distinction of
our method from the traditional statistical approach
where a separate classifier is trained for each code.
The LT-HMM allows features learned from a doc-
ument coded with ci to transfer at test time to pre-
dict code c�, provided their respective triggers ap-
pear in similar contexts. Training one common clas-
sifier improves our chances to reliably predict codes
that have few training instances, and even codes that
do not appear at all in the training data.
</bodyText>
<subsectionHeader confidence="0.991782">
4.1 Trigger Detection
</subsectionHeader>
<bodyText confidence="0.999991222222222">
We have manually assembled a dictionary of terms
for each of the 45 codes used in the CMC chal-
lenge.2 The dictionaries were built by collecting rel-
evant medical terminology from UMLS, the ICD-9-
CM coding guidelines, and the CMC training data.
The test data was not consulted during dictionary
construction. The dictionaries contain 440 terms,
with 9.78 terms per code on average. Given these
dictionaries, the exact-matching of terms to input
</bodyText>
<footnote confidence="0.966745">
2Online at https://sites.google.com/site/
colinacherry/ICD9CM ACL11.txt
</footnote>
<bodyText confidence="0.999938571428571">
documents is straightforward. In our experiments,
this process finds on average 1.83 distinct candidate
codes per document.
The quality of the dictionary significantly affects
the prediction performance of the proposed two-
stage approach. Especially important is the cover-
age of the dictionary. If a trigger term is missing
from the dictionary and, as the result, the code is not
selected as a candidate code, it will not be recov-
ered in the following stage, resulting in a false neg-
ative. Preliminary experiments show that our dictio-
nary recovers 94.42% of the codes in the training set
and 93.20% in the test set. These numbers provide
an upper bound on recall for the overall approach.
</bodyText>
<subsectionHeader confidence="0.99438">
4.2 Sequence Construction
</subsectionHeader>
<bodyText confidence="0.999953133333333">
After trigger detection, we view the input document
as a sequence of candidate codes, each correspond-
ing to a detected trigger (see Figure 1). By tagging
these candidates in sequence, we can label each can-
didate code as present or absent and use previous
tagging decisions to model code interactions. The
final code subset is constructed by collecting all can-
didate codes tagged as present.
Our training data consists of [document, code set]
pairs, augmented with the trigger terms detected
through dictionary matching. We transform this into
a sequence to be tagged using the following steps:
Ordering: The candidate code sequence is pre-
sented in reverse chronological order, according to
when their corresponding trigger terms appear in the
document. That is, the last candidate to be detected
by the dictionary will be the first code to appear in
our candidate sequence. Reverse order was chosen
because clinical documents often close with a final
(and informative) diagnosis.
Merging: Each detected trigger corresponds to
exactly one code; however, several triggers may be
detected for the same code throughout a document.
If a code has several triggers, we keep only the last
occurrence. When possible, we collect relevant fea-
tures (such as negation information) of all occur-
rences and associate them with this last occurrence.
Labelling: Each candidate code is assigned a bi-
nary label (present or absent) based on whether it
appears in the gold-standard code set. Note that this
</bodyText>
<page confidence="0.992398">
745
</page>
<table confidence="0.92553475">
Gold code set: {486}
Cough, fever in 9-year-
old male. IMPRESSION:
1. Right middle lobe
pneumonia. 2. Minimal
pleural thickening on
the right may represent
small pleural effusion.
511.9 486 780.6 786.2
pleural effusion pneumonia fever cough
context=neg context=pos context=pos context=pos
sem=disease sem=disease sem=symptom sem=symptom
N
Y
N
N
</table>
<figureCaption confidence="0.979832">
Figure 1: An example document and its corresponding gold-standard tag sequence. The top binary layer is the correct
output tag sequence, which confirms or rejects the presence of candidate codes. The bottom layer shows the candidate
code sequence derived from the text, with corresponding trigger phrases and some prominent features.
</figureCaption>
<bodyText confidence="0.994534928571429">
process can not introduce gold-standard codes that
were not proposed by the dictionary.
The final output of these steps is depicted in Fig-
ure 1. To the left, we have an input text with un-
derlined trigger phrases, as detected by our dictio-
nary. This implies an input sequence (bottom right),
which consists of detected codes and their corre-
sponding trigger phrases. The gold-standard code
set for the document is used to infer a gold-standard
label sequence for these codes (top right). At test
time, the goal of the classifier is to correctly predict
the correct binary label sequence for new inputs. We
discuss the construction of the features used to make
this prediction in section 4.3.
</bodyText>
<subsectionHeader confidence="0.995593">
4.3 Model
</subsectionHeader>
<bodyText confidence="0.999984615384615">
We model this sequence data using a discriminative
SVM-HMM (Taskar et al., 2003; Altun et al., 2003).
This allows us to use rich, over-lapping features of
the input while also modeling interactions between
labels. A discriminative HMM has two major cate-
gories of features: emission features, which charac-
terize a candidate’s tag in terms of the input docu-
ment x, and transition features, which characterize
a tag in terms of the tags that have come before it.
We describe these two feature categories and then
our training mechanism. All feature engineering dis-
cussed below was carried out using 10-fold cross-
validation on the training set.
</bodyText>
<sectionHeader confidence="0.666979" genericHeader="method">
Transition Features
</sectionHeader>
<bodyText confidence="0.999607538461538">
The transition features are modeled as simple in-
dicators over n-grams of present codes, for values of
n up to 10, the largest number of codes proposed by
our dictionary in the training set.3 This allows the
system to learn sequences of codes that are (and are
not) likely to occur in the gold-standard data.
We found it useful to pad our n-grams with “be-
ginning of document” tokens for sequences when
fewer than n codes have been labelled as present,
but found it harmful to include an end-of-document
tag once labelling is complete. We suspect that the
small training set for the challenge makes the system
prone to over-fit when modeling code-set length.
</bodyText>
<sectionHeader confidence="0.895123" genericHeader="method">
Emission Features
</sectionHeader>
<bodyText confidence="0.999407882352941">
The vast majority of our training signal comes
from emission features, which carefully model both
the trigger term’s local context and the document as
a whole. For each candidate code, three types of
features are generated: document features, ConText
features, and code-semantics features (Table 1).
Document: Document features include indicators
on all individual words, 2-grams, 3-grams, and 4-
grams found in the document. These n-gram fea-
tures have the candidate code appended to them,
making them similar to features traditionally used
in multiclass document categorization.
ConText: We take advantage of the ConText algo-
rithm’s output. ConText is publicly available soft-
ware that determines the presence of negated, hypo-
thetical, historical, and family-related context for a
given phrase in a clinical text (Harkema et al., 2009).
</bodyText>
<footnote confidence="0.988960333333333">
3We can easily afford such a long history because input se-
quences are generally short and the tagging is binary, resulting
in only a small number of possible histories for a document.
</footnote>
<page confidence="0.972262">
746
</page>
<table confidence="0.999754588235294">
Features gen. spec.
Document x
n-gram
ConText x x
current match x x
context x x
only in context x x
more than once in context x x
other matches x x
present
present in context = pos
code present in context
Code Semantics x x
current match x
sem type
other matches
sem type, context =pos
</table>
<tableCaption confidence="0.9894365">
Table 1: The emission features used in LT-HMM.
Typeset words represent variables replaced with spe-
</tableCaption>
<figureCaption confidence="0.62399575">
cific values, i.e. context E {pos,neg}, sem type E
{symptom,disease}, code is one of 45 challenge codes,
n-gram is a document n-gram. Features can come in
generic and/or code-specific version.
</figureCaption>
<bodyText confidence="0.993084898550725">
The algorithm is based on regular expression match-
ing of the context to a precompiled list of context
indicators. Regardless of its simplicity, the algo-
rithm has shown very good performance on a vari-
ety of clinical document types. We run ConText for
each trigger term located in the text and produce two
types of features: features related to the candidate
code in question and features related to other candi-
date codes of the document. Negated, hypothetical,
and family-related contexts are clustered into a sin-
gle negative context for the term. Absence of the
negative context implies the positive context.
We used the following ConText derived indicator
features: for the current candidate code, if there is at
least one trigger term found in a positive (negative)
context, if all trigger terms for this code are found
in a positive (negative) context, if there are more
than one trigger terms for the code found in a posi-
tive (negative) context; for other candidate codes of
the document, if there is at least one other candidate
code, if there is another candidate code with at least
one trigger term found in a positive context, if there
is a trigger term for candidate code cz found in a pos-
itive (negative) context.
Code Semantics: We include features that indi-
cate if the code itself corresponds to a disease or a
symptom. This assignment was determined based
on the UMLS semantic type of the code. Like the
ConText features, code features come in two types:
those regarding the candidate code in question and
those regarding other candidate codes from the same
document.
Generic versus Specific: Most of our features
come in two versions: generic and code-specific.
Generic features are concerned with classifying any
candidate as present or absent based on characteris-
tics of its trigger or semantics. Code-specific fea-
tures append the candidate code to the feature. For
example, the feature context=pos represents that
the current candidate has a trigger term in a positive
context, while context=pos:486 adds the infor-
mation that the code in question is 486. Note that
n-grams features are only code-specific, as they are
not connected to any specific trigger term.
To an extent, code-specific features allow us
to replicate the traditional classification approach,
which focuses on one code at a time. Using these
features, the classifier is free to build complex sub-
models for a particular code, provided that this code
has enough training examples. Generic versions of
the features, on the other hand, make it possible to
learn common rules applicable to all codes, includ-
ing low-frequency ones. In this way, even in the ex-
treme case of having zero training examples for a
particular code, the model can still potentially assign
the code to new documents, provided it is detected
by our dictionary. This is impossible in a traditional
document-classification setting.
Training
We train our SVM-HMM with the objective of
separating the correct tag sequence from all others
by a fixed margin of 1, using a primal stochastic
gradient optimization algorithm that follows Shalev-
Shwartz et al. (2007). Let 5 be a set of training
points (x, y), where x is the input and y is the cor-
responding gold-standard tag sequence. Let O(x, y)
be a function that transforms complete input-output
pairs into feature vectors. We also use O(x, y&apos;, y)
as shorthand for the difference in features between
</bodyText>
<page confidence="0.981721">
747
</page>
<bodyText confidence="0.477234">
begin
</bodyText>
<equation confidence="0.839593941176471">
Input: S, λ, n
Initialize: Set w0 to the 0 vector
for t = 1,2 ..., n|S|
Choose (x, y) ∈ S at random
Set the learning rate: ηt = 1�t
Search:
y0 = arg maxy„ [δ(y, y00) + wt · φ(x, y00)]
Update:
)
wt+1 = wt + ηt�φ(x, y, y0) − λwt
Adjust:
� √ �
wt+1 = wt+1 · min 1, 1� �
kwt+1k
end
Output: wn|S|+1
end
</equation>
<figureCaption confidence="0.993568">
Figure 2: Training an SVM-HMM
</figureCaption>
<bodyText confidence="0.967762">
two outputs: φ(x, y0, y) = φ(x, y0) − φ(x, y). With
this notation in place, the SVM-HMM minimizes
the regularized hinge-loss:
</bodyText>
<equation confidence="0.816631">
min λ 2 w2 + |S |1: `(w; (x, y)) (1)
w (x,y)∈S
</equation>
<bodyText confidence="0.763489">
where
</bodyText>
<equation confidence="0.9204275">
`(w; (x, y)) = max [δ(y, y0) + w · φ(x, y0, y)]
y&apos;
</equation>
<bodyText confidence="0.997549615384616">
(2)
and where δ(y, y0) = 0 when y = y0 and 1 oth-
erwise.4 Intuitively, the objective attempts to find
a small weight vector w that separates all incorrect
tag sequences y0 from the correct tag sequence y by
a margin of 1. λ controls the trade-off between reg-
ularization and training hinge-loss.
The stochastic gradient descent algorithm used
to optimize this objective is shown in Figure 2. It
bears many similarities to perceptron HMM train-
ing (Collins, 2002), with theoretically-motivated al-
terations, such as selecting training points at ran-
dom5 and the explicit inclusion of a learning rate η
</bodyText>
<footnote confidence="0.933182714285714">
4We did not experiment with structured versions of S that
account for the number of incorrect tags in the label sequence
y&apos;, as a fixed margin was already working very well. We intend
to explore structured costs in future work.
5Like many implementations, we make n passes through S,
shuffling S before each pass, rather than sampling from S with
replacement nISI times.
</footnote>
<table confidence="0.997161833333333">
training test
# of documents 978 976
# of distinct codes 45 45
# of distinct code subsets 94 94
# of codes with &lt; 10 ex. 24 24
avg # of codes per document 1.25 1.23
</table>
<tableCaption confidence="0.999884">
Table 2: The training and test set characteristics.
</tableCaption>
<bodyText confidence="0.999749833333333">
and a regularization term λ. The search step can be
carried out with a two-best version of the Viterbi al-
gorithm; if the one-best answer y01 matches the gold-
standard y, that is δ(y, y01) = 0, then y02 is checked
to see if its loss is higher.
We tune two hyper-parameters using 10-fold
cross-validation: the regularization parameter λ and
a number of passes n through the training data. Us-
ing F1 as measured by 10-fold cross-validation on
the training set, we found values of λ = 0.1 with
n = 5 to prove optimal. Training time is less than
one minute on modern hardware.
</bodyText>
<sectionHeader confidence="0.998311" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<subsectionHeader confidence="0.987753">
5.1 Data
</subsectionHeader>
<bodyText confidence="0.999989214285714">
For testing purposes, we use the CMC Challenge
dataset. The data consists of 978 training and 976
test medical records labelled with one or more ICD-
9-CM codes from a set of 45 codes. The data statis-
tics are presented in Table 2. The training and test
sets have similar, very imbalanced distributions of
codes. In particular, all codes in the test set have at
least one training example. Moreover, for any code
subset assigned to a test document there is at least
one training document labelled with the same code
subset. Notably, more than half of the codes have
less than 10 instances in both training and test sets.
Following the challenge’s protocol, we use micro-
averaged F1-measure for evaluation.
</bodyText>
<subsectionHeader confidence="0.997126">
5.2 Baseline
</subsectionHeader>
<bodyText confidence="0.999814571428571">
As the first baseline for comparison, we built a
one-classifier-per-code statistical system. A docu-
ment’s code subset is implied by the set of classi-
fiers that assign it a positive label. The classifiers
use a feature set designed to mimic our LT-HMM
as closely as possible, including n-grams, dictionary
matches, ConText output, and symptom/disease se-
</bodyText>
<page confidence="0.994235">
748
</page>
<bodyText confidence="0.999890029411765">
mantic types. Each classifier is trained as an SVM
with a linear kernel.
Unlike our approach, this baseline cannot share
features across codes, and it does not allow coding
decisions for a document to inform one another. It
also cannot propose codes that have not been seen in
the training data as it has no model for these codes.
However, one should note that it is a very strong
baseline. Like our proposed system, it is built with
many features derived from dictionary matches and
their contexts, and thus it shares many of our sys-
tem’s strengths. In fact, this baseline system outper-
forms all published statistical approaches tested on
the CMC data.
Our second baseline is a symbolic system, de-
signed to evaluate the quality of our rule-based com-
ponents when used alone. It is based on the same
hand-crafted dictionary, filtered according to the
ConText algorithm and four code dependency rules
from (Farkas and Szarvas, 2008). These rules ad-
dress the problem of overcoding: some symptom
codes should be omitted when a specific disease
code is present.6
This symbolic system has access to the same
hand-crafted resources as our LT-HMM and, there-
fore, has a good chance of predicting low-frequency
and unseen codes. However, it lacks the flexibility of
our statistical solution to accept or reject code candi-
dates based on the whole document text, which pre-
vents it from compensating for dictionary or Con-
Text errors. Similarly, the structure of the code de-
pendency rules may not provide the same flexibility
as our features that look at other detected triggers
and previous code assignments.
</bodyText>
<subsectionHeader confidence="0.999909">
5.3 Coding Accuracy
</subsectionHeader>
<bodyText confidence="0.999818222222222">
We evaluate the proposed approach on both the
training set (using 10-fold cross-validation) and the
test set (Table 3). The experiments demonstrate the
superiority of the proposed LT-HMM approach over
the one-per-code statistical scheme as well as our
symbolic baseline. Furthermore, the new approach
shows the best results ever achieved on the dataset,
beating the top-performing system in the challenge,
a symbolic method.
</bodyText>
<footnote confidence="0.956912666666667">
6Note that we do not match the performance of the Farkas
and Szarvas system, likely due to our use of a different (and
simpler) dictionary.
</footnote>
<table confidence="0.999153">
Cross-fold Test
Symbolic baseline N/A 85.96
Statistical baseline 87.39 88.26
LT-HMM 89.39 89.84
CMC Best N/A 89.08
</table>
<tableCaption confidence="0.976934666666667">
Table 3: Micro-averaged F1-scores for statistical and
symbolic baselines, the proposed LT-HMM approach,
and the best CMC hand-crafted rule-based system.
</tableCaption>
<table confidence="0.999918">
System Prec. Rec. F1
Full 90.91 88.80 89.84
-ConText 88.54 85.89 87.19
-Document 89.89 88.55 89.21
-Code Semantics 90.10 88.38 89.23
-Append code-specific 88.96 88.30 88.63
-Transition 90.79 88.38 89.57
-ConText &amp; Transition 86.91 85.39 86.14
</table>
<tableCaption confidence="0.9965525">
Table 4: Results on the CMC test data with each major
component removed.
</tableCaption>
<subsectionHeader confidence="0.95827">
5.4 Ablation
</subsectionHeader>
<bodyText confidence="0.999983142857143">
Our system employs a number of emission feature
templates. We measure the impact of each by re-
moving the template, re-training, and testing on the
challenge test data, as shown in Table 4. By far the
most important component of our system is the out-
put of the ConText algorithm.
We also tested a version of the system that does
not create a parallel code-specific feature set by ap-
pending the candidate code to emission features.
This system tags code-candidates without any code-
specific components, but it still does very well, out-
performing the baselines.
Removing the sequence-based transition features
from our system has only a small impact on accu-
racy. This is because several of our emission fea-
tures look at features of other candidate codes. This
provides a strong approximation to the actual tag-
ging decisions for these candidates. If we remove
the ConText features, the HMM’s transition features
become more important (compare line 2 of Table 4
to line 7).
</bodyText>
<subsectionHeader confidence="0.857066">
5.5 Low-frequency codes
</subsectionHeader>
<bodyText confidence="0.998935">
As one can see from Table 2, more than half of the
available codes appear fewer than 10 times in the
</bodyText>
<page confidence="0.994296">
749
</page>
<table confidence="0.999461">
System Prec. Rec. F1
Symbolic baseline 42.53 56.06 48.37
Statistical baseline 73.33 33.33 45.83
LT-HMM 70.00 53.03 60.34
</table>
<tableCaption confidence="0.996447">
Table 5: Results on the CMC test set, looking only at the
codes with fewer than 10 examples in the training set.
</tableCaption>
<table confidence="0.99984875">
System Prec. Rec. F1
Symbolic baseline 60.00 80.00 68.57
All training data 72.92 74.47 73.68
One code held out 79.31 48.94 60.53
</table>
<tableCaption confidence="0.9213955">
Table 6: Results on the CMC test set when all instances
of a low-frequency code are held-out during training.
</tableCaption>
<bodyText confidence="0.999868772727273">
training documents. This does not provide much
training data for a one-classifier-per-code approach,
which has been a major motivating factor in the de-
sign of our LT-HMM. In Table 5, we compare our
system to the baselines on the CMC test set, con-
sidering only these low-frequency codes. We show
a 15-point gain in F1 over the statistical baseline
on these hard cases, brought on by an substantial
increase in recall. Similarly, we improve over the
symbolic baseline, due to a much higher precision.
In this way, the LT-HMM captures the strengths of
both approaches.
Our system also has the ability to predict codes
that have not been seen during training, by labelling
a dictionary match for a code as present according to
its local context. We simulate this setting by drop-
ping training data. For each low-frequency code c,
we hold out all training documents that include c in
their gold-standard code set. We then train our sys-
tem on the reduced training set and measure its abil-
ity to detect c on the unseen test data. 11 of the 24
low-frequency codes have no dictionary matches in
our test data; we omit them from our analysis as we
are unable to predict them. The micro-averaged re-
sults for the remaining 13 low-frequency codes are
shown in Table 6, with the results from the symbolic
baseline and from our system trained on the com-
plete training data provided for comparison.
We were able to recover 49% of the test-time oc-
currences of codes withheld from training, while
maintaining our full system’s precision. Consider-
ing that traditional statistical strategies would lead
to recall dropping uniformly to 0, this is a vast im-
provement. However, the symbolic baseline recalls
80% of occurrences in aggregate, indicating that we
are not yet making optimal use of the dictionary for
cases when a code is missing from the training data.
By holding out only correct occurrences of a code
c, our system becomes biased against it: all trigger
terms for c that are found in the training data must
be labelled absent. Nonetheless, out of the 13 codes
with dictionary matches, there were 9 codes that we
were able to recall at a rate of 50% or more, and 5
codes that achieved 100% recall.
</bodyText>
<sectionHeader confidence="0.999626" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999992517241379">
We have presented the lexically-triggered HMM, a
novel and effective approach for clinical document
coding. The LT-HMM takes advantage of lexical
triggers for clinical codes by operating in two stages:
first, a lexical match is performed against a trigger
term dictionary to collect a set of candidates codes
for a document; next, a discriminative HMM se-
lects the best subset of codes to assign to the docu-
ment. Using both generic and code-specific features,
the LT-HMM outperforms a traditional one-per-
code statistical classification method, with substan-
tial improvements on low-frequency codes. Also,
it achieves the best ever performance on a common
testbed, beating the top-performer of the 2007 CMC
Challenge, a hand-crafted rule-based system. Fi-
nally, we have demonstrated that the LT-HMM can
correctly predict codes never seen in the training set,
a vital characteristic missing from previous statisti-
cal methods.
In the future, we would like to augment our
dictionary-based matching component with entity-
recognition technology. It would be interesting to
model triggers as latent variables in the document
coding process, in a manner similar to how latent
subjective sentences have been used in document-
level sentiment analysis (Yessenalina et al., 2010).
This would allow us to employ a learned matching
component that is trained to compliment our classi-
fication component.
</bodyText>
<sectionHeader confidence="0.998756" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9552465">
Many thanks to Berry de Bruijn, Joel Martin, and
the ACL-HLT reviewers for their helpful comments.
</bodyText>
<page confidence="0.994413">
750
</page>
<sectionHeader confidence="0.998339" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999734301369863">
Y. Altun, I. Tsochantaridis, and T. Hofmann. 2003. Hid-
den Markov support vector machines. In ICML.
A. R. Aronson, O. Bodenreider, D. Demner-Fushman,
K. W. Fung, V. K. Lee, J. G. Mork, A. Nvol, L. Peters,
and W. J. Rogers. 2007. From indexing the biomed-
ical literature to coding clinical text: Experience with
MTI and machine learning approaches. In BioNLP,
pages 105–112.
S. Benson. 2006. Computer assisted coding software
improves documentation, coding, compliance and rev-
enue. Perspectives in Health Information Manage-
ment, CAC Proceedings, Fall.
M. Collins. 2002. Discriminative training methods for
Hidden Markov Models: Theory and experiments with
perceptron algorithms. In EMNLP.
K. Crammer, M. Dredze, K. Ganchev, P. P. Talukdar, and
S. Carroll. 2007. Automatic code assignment to med-
ical text. In BioNLP, pages 129–136.
R. Farkas and G. Szarvas. 2008. Automatic construc-
tion of rule-based ICD-9-CM coding systems. BMC
Bioinformatics, 9(Suppl 3):S10.
I. Goldstein, A. Arzumtsyan, and Uzuner. 2007. Three
approaches to automatic assignment of ICD-9-CM
codes to radiology reports. In AMIA, pages 279–283.
H. Harkema, J. N. Dowling, T. Thornblade, and W. W.
Chapman. 2009. Context: An algorithm for determin-
ing negation, experiencer, and temporal status from
clinical reports. Journal of Biomedical Informatics,
42(5):839–851, October.
L. Kevers and J. Medori. 2010. Symbolic classifica-
tion methods for patient discharge summaries encod-
ing into ICD. In Proceedings of the 7th International
Conference on NLP (IceTAL), pages 197–208, Reyk-
javik, Iceland, August.
D. A. Lindberg, B. L. Humphreys, and A. T. McCray.
1993. The Unified Medical Language System. Meth-
ods of Information in Medicine, 32(4):281–291.
Y. A. Lussier, L. Shagina, and C. Friedman. 2000. Au-
tomating ICD-9-CM encoding using medical language
processing: A feasibility study. In AMIA, page 1072.
S. M. Meystre, G. K. Savova, K. C. Kipper-Schuler, and
J. F. Hurdle. 2008. Extracting information from tex-
tual documents in the electronic health record: a re-
view of recent research. Methods of Information in
Medicine, 47(Suppl 1):128–144.
J. Patrick, Y. Zhang, and Y. Wang. 2007. Developing
feature types for classifying clinical notes. In BioNLP,
pages 191–192.
J. P. Pestian, C. Brew, P. Matykiewicz, D. J. Hovermale,
N. Johnson, K. B. Cohen, and W. Duch. 2007. A
shared task involving multi-label classification of clin-
ical free text. In BioNLP, pages 97–104.
S. Shalev-Shwartz, Y. Singer, and N. Srebro. 2007. Pega-
sos: Primal Estimated sub-GrAdient SOlver for SVM.
In ICML, Corvallis, OR.
M. H. Stanfill, M. Williams, S. H. Fenton, R. A. Jenders,
and W. R. Hersh. 2010. A systematic literature re-
view of automated clinical coding and classification
systems. JAMIA, 17:646–651.
H. Suominen, F. Ginter, S. Pyysalo, A. Airola,
T. Pahikkala, S. Salanter, and T. Salakoski. 2008.
Machine learning to automate the assignment of di-
agnosis codes to free-text radiology reports: a method
description. In Proceedings of the ICML Workshop
on Machine Learning for Health-Care Applications,
Helsinki, Finland.
B. Taskar, C. Guestrin, and D. Koller. 2003. Max-margin
markov networks. In Neural Information Processing
Systems Conference (NIPS03), Vancouver, Canada,
December.
A. Yessenalina, Y. Yue, and C. Cardie. 2010. Multi-
level structured models for document-level sentiment
classification. In EMNLP.
</reference>
<page confidence="0.998286">
751
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.668096">
<title confidence="0.996848">Lexically-Triggered Hidden Markov for Clinical Document Coding</title>
<author confidence="0.996472">Svetlana Kiritchenko Colin Cherry</author>
<affiliation confidence="0.9806425">Institute for Information National Research Council Canada</affiliation>
<abstract confidence="0.98512484">The automatic coding of clinical documents is an important task for today’s healthcare providers. Though it can be viewed as multi-label document classification, the coding problem has the interesting property that most code assignments can be supported by a single phrase found in the input document. We propose a Lexically-Triggered Hidden Markov Model (LT-HMM) that leverages these phrases to improve coding accuracy. The LT-HMM works in two stages: first, a lexical match is performed against a term dictionary to collect a set of candidate codes for a document. Next, a discriminative HMM selects the best subset of codes to assign to the document by tagging candidates as present or absent. By confirming codes proposed by a dictionary, the LT-HMM can share features across codes, enabling strong performance even on rare codes. In fact, we are able to recover codes that do not occur in the training set at all. Our approach achieves the best ever performance on the 2007 Medical NLP Challenge test set, with an F-measure of 89.84.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Y Altun</author>
<author>I Tsochantaridis</author>
<author>T Hofmann</author>
</authors>
<title>Hidden Markov support vector machines.</title>
<date>2003</date>
<booktitle>In ICML.</booktitle>
<contexts>
<context position="17983" citStr="Altun et al., 2003" startWordPosition="2860" endWordPosition="2863">ith underlined trigger phrases, as detected by our dictionary. This implies an input sequence (bottom right), which consists of detected codes and their corresponding trigger phrases. The gold-standard code set for the document is used to infer a gold-standard label sequence for these codes (top right). At test time, the goal of the classifier is to correctly predict the correct binary label sequence for new inputs. We discuss the construction of the features used to make this prediction in section 4.3. 4.3 Model We model this sequence data using a discriminative SVM-HMM (Taskar et al., 2003; Altun et al., 2003). This allows us to use rich, over-lapping features of the input while also modeling interactions between labels. A discriminative HMM has two major categories of features: emission features, which characterize a candidate’s tag in terms of the input document x, and transition features, which characterize a tag in terms of the tags that have come before it. We describe these two feature categories and then our training mechanism. All feature engineering discussed below was carried out using 10-fold crossvalidation on the training set. Transition Features The transition features are modeled as </context>
</contexts>
<marker>Altun, Tsochantaridis, Hofmann, 2003</marker>
<rawString>Y. Altun, I. Tsochantaridis, and T. Hofmann. 2003. Hidden Markov support vector machines. In ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A R Aronson</author>
<author>O Bodenreider</author>
<author>D Demner-Fushman</author>
<author>K W Fung</author>
<author>V K Lee</author>
<author>J G Mork</author>
<author>A Nvol</author>
<author>L Peters</author>
<author>W J Rogers</author>
</authors>
<title>From indexing the biomedical literature to coding clinical text: Experience with MTI and machine learning approaches. In BioNLP,</title>
<date>2007</date>
<pages>105--112</pages>
<contexts>
<context position="11508" citStr="Aronson et al., 2007" startWordPosition="1817" endWordPosition="1820">r hand-crafted rules can be built in a semi-automatic way: the initial set of rules adopted from the official coding guidelines were automatically extended with additional synonyms and code dependency rules generated from the training data (Farkas and Szarvas, 2008). Statistical systems trained on only text-derived features (such as n-grams) did not show good performance due to a wide variety of medical language and a relatively small training set (Goldstein et al., 2007). This led to the creation of hybrid systems: symbolic and statistical classifiers used together in an ensemble or cascade (Aronson et al., 2007; Crammer et al., 2007) or a symbolic component providing features for a statistical component (Patrick et al., 2007; Suominen et al., 2008). Strong competition systems had good answers for dealing with negative and speculative contexts, taking advantage of the competition’s limited set of possible code combinations, and handling of low-frequency codes. Our proposed approach is a combination system as well. We combine a symbolic component that matches lexical strings of a document against a medical dictionary to determine possible codes (Lussier et al., 2000; Kevers and Medori, 2010) and a sta</context>
</contexts>
<marker>Aronson, Bodenreider, Demner-Fushman, Fung, Lee, Mork, Nvol, Peters, Rogers, 2007</marker>
<rawString>A. R. Aronson, O. Bodenreider, D. Demner-Fushman, K. W. Fung, V. K. Lee, J. G. Mork, A. Nvol, L. Peters, and W. J. Rogers. 2007. From indexing the biomedical literature to coding clinical text: Experience with MTI and machine learning approaches. In BioNLP, pages 105–112.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Benson</author>
</authors>
<title>Computer assisted coding software improves documentation, coding, compliance and revenue.</title>
<date>2006</date>
<booktitle>Perspectives in Health Information Management, CAC Proceedings,</booktitle>
<location>Fall.</location>
<contexts>
<context position="2619" citStr="Benson, 2006" startWordPosition="389" endWordPosition="391">ormed procedures into a nomenclature of clinical codes. The International Classification of Diseases, 9th and 10th revisions, Clinical Modification (ICD9-CM, ICD-10-CM) are the official administrative coding schemes for healthcare organizations in several countries, including the US and Canada. Typically, coding is performed by trained coding professionals, but this process can be both costly and errorprone. Automated methods can speed-up the coding process, improve the accuracy and consistency of internal documentation, and even result in higher reimbursement for the healthcare organization (Benson, 2006). Traditionally, statistical document coding is viewed as multi-class multi-label document classification, where each clinical free-text document is labelled with one or several codes from a pre-defined, possibly very large set of codes (Patrick et al., 2007; Suominen et al., 2008). One classification model is learned for each code, and then all models are applied in turn to a new document to determine which codes should be assigned to the document. The drawback of this approach is poor predictive performance on low-frequency codes, which are ubiquitous in the clinical domain. This paper prese</context>
</contexts>
<marker>Benson, 2006</marker>
<rawString>S. Benson. 2006. Computer assisted coding software improves documentation, coding, compliance and revenue. Perspectives in Health Information Management, CAC Proceedings, Fall.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
</authors>
<title>Discriminative training methods for Hidden Markov Models: Theory and experiments with perceptron algorithms.</title>
<date>2002</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="25246" citStr="Collins, 2002" startWordPosition="4099" endWordPosition="4100"> the SVM-HMM minimizes the regularized hinge-loss: min λ 2 w2 + |S |1: `(w; (x, y)) (1) w (x,y)∈S where `(w; (x, y)) = max [δ(y, y0) + w · φ(x, y0, y)] y&apos; (2) and where δ(y, y0) = 0 when y = y0 and 1 otherwise.4 Intuitively, the objective attempts to find a small weight vector w that separates all incorrect tag sequences y0 from the correct tag sequence y by a margin of 1. λ controls the trade-off between regularization and training hinge-loss. The stochastic gradient descent algorithm used to optimize this objective is shown in Figure 2. It bears many similarities to perceptron HMM training (Collins, 2002), with theoretically-motivated alterations, such as selecting training points at random5 and the explicit inclusion of a learning rate η 4We did not experiment with structured versions of S that account for the number of incorrect tags in the label sequence y&apos;, as a fixed margin was already working very well. We intend to explore structured costs in future work. 5Like many implementations, we make n passes through S, shuffling S before each pass, rather than sampling from S with replacement nISI times. training test # of documents 978 976 # of distinct codes 45 45 # of distinct code subsets 94</context>
</contexts>
<marker>Collins, 2002</marker>
<rawString>M. Collins. 2002. Discriminative training methods for Hidden Markov Models: Theory and experiments with perceptron algorithms. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Crammer</author>
<author>M Dredze</author>
<author>K Ganchev</author>
<author>P P Talukdar</author>
<author>S Carroll</author>
</authors>
<title>Automatic code assignment to medical text. In BioNLP,</title>
<date>2007</date>
<pages>129--136</pages>
<contexts>
<context position="11531" citStr="Crammer et al., 2007" startWordPosition="1821" endWordPosition="1825">an be built in a semi-automatic way: the initial set of rules adopted from the official coding guidelines were automatically extended with additional synonyms and code dependency rules generated from the training data (Farkas and Szarvas, 2008). Statistical systems trained on only text-derived features (such as n-grams) did not show good performance due to a wide variety of medical language and a relatively small training set (Goldstein et al., 2007). This led to the creation of hybrid systems: symbolic and statistical classifiers used together in an ensemble or cascade (Aronson et al., 2007; Crammer et al., 2007) or a symbolic component providing features for a statistical component (Patrick et al., 2007; Suominen et al., 2008). Strong competition systems had good answers for dealing with negative and speculative contexts, taking advantage of the competition’s limited set of possible code combinations, and handling of low-frequency codes. Our proposed approach is a combination system as well. We combine a symbolic component that matches lexical strings of a document against a medical dictionary to determine possible codes (Lussier et al., 2000; Kevers and Medori, 2010) and a statistical component that</context>
</contexts>
<marker>Crammer, Dredze, Ganchev, Talukdar, Carroll, 2007</marker>
<rawString>K. Crammer, M. Dredze, K. Ganchev, P. P. Talukdar, and S. Carroll. 2007. Automatic code assignment to medical text. In BioNLP, pages 129–136.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Farkas</author>
<author>G Szarvas</author>
</authors>
<title>Automatic construction of rule-based ICD-9-CM coding systems.</title>
<date>2008</date>
<journal>BMC Bioinformatics,</journal>
<volume>9</volume>
<pages>3--10</pages>
<contexts>
<context position="11154" citStr="Farkas and Szarvas, 2008" startWordPosition="1760" endWordPosition="1763"> mean score was 0.7670. Several teams, including the winner, built pure symbolic (i.e., hand-crafted rule-based) systems (e.g., (Goldstein et al., 2007)). This approach is feasible for the small code set used in the challenge, but it is questionable in real-life settings where thousands of codes need to be considered. Later, the winning team showed how their hand-crafted rules can be built in a semi-automatic way: the initial set of rules adopted from the official coding guidelines were automatically extended with additional synonyms and code dependency rules generated from the training data (Farkas and Szarvas, 2008). Statistical systems trained on only text-derived features (such as n-grams) did not show good performance due to a wide variety of medical language and a relatively small training set (Goldstein et al., 2007). This led to the creation of hybrid systems: symbolic and statistical classifiers used together in an ensemble or cascade (Aronson et al., 2007; Crammer et al., 2007) or a symbolic component providing features for a statistical component (Patrick et al., 2007; Suominen et al., 2008). Strong competition systems had good answers for dealing with negative and speculative contexts, taking a</context>
<context position="28565" citStr="Farkas and Szarvas, 2008" startWordPosition="4672" endWordPosition="4675">no model for these codes. However, one should note that it is a very strong baseline. Like our proposed system, it is built with many features derived from dictionary matches and their contexts, and thus it shares many of our system’s strengths. In fact, this baseline system outperforms all published statistical approaches tested on the CMC data. Our second baseline is a symbolic system, designed to evaluate the quality of our rule-based components when used alone. It is based on the same hand-crafted dictionary, filtered according to the ConText algorithm and four code dependency rules from (Farkas and Szarvas, 2008). These rules address the problem of overcoding: some symptom codes should be omitted when a specific disease code is present.6 This symbolic system has access to the same hand-crafted resources as our LT-HMM and, therefore, has a good chance of predicting low-frequency and unseen codes. However, it lacks the flexibility of our statistical solution to accept or reject code candidates based on the whole document text, which prevents it from compensating for dictionary or ConText errors. Similarly, the structure of the code dependency rules may not provide the same flexibility as our features th</context>
</contexts>
<marker>Farkas, Szarvas, 2008</marker>
<rawString>R. Farkas and G. Szarvas. 2008. Automatic construction of rule-based ICD-9-CM coding systems. BMC Bioinformatics, 9(Suppl 3):S10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Goldstein</author>
<author>A Arzumtsyan</author>
<author>Uzuner</author>
</authors>
<title>Three approaches to automatic assignment of ICD-9-CM codes to radiology reports.</title>
<date>2007</date>
<booktitle>In AMIA,</booktitle>
<pages>279--283</pages>
<contexts>
<context position="10681" citStr="Goldstein et al., 2007" startWordPosition="1683" endWordPosition="1686">heir evaluation results. One major obstacle that hinders the progress in this domain is data privacy issues. To overcome this obstacle, the CMC Challenge was organized in 2007. The purpose of the challenge was to provide a common realistic dataset to stimulate the research in the area and to assess the current level of performance on the task. Forty-four teams participated in the challenge. The top-performing system achieved micro-averaged F1-score of 0.8908, and the mean score was 0.7670. Several teams, including the winner, built pure symbolic (i.e., hand-crafted rule-based) systems (e.g., (Goldstein et al., 2007)). This approach is feasible for the small code set used in the challenge, but it is questionable in real-life settings where thousands of codes need to be considered. Later, the winning team showed how their hand-crafted rules can be built in a semi-automatic way: the initial set of rules adopted from the official coding guidelines were automatically extended with additional synonyms and code dependency rules generated from the training data (Farkas and Szarvas, 2008). Statistical systems trained on only text-derived features (such as n-grams) did not show good performance due to a wide varie</context>
</contexts>
<marker>Goldstein, Arzumtsyan, Uzuner, 2007</marker>
<rawString>I. Goldstein, A. Arzumtsyan, and Uzuner. 2007. Three approaches to automatic assignment of ICD-9-CM codes to radiology reports. In AMIA, pages 279–283.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Harkema</author>
<author>J N Dowling</author>
<author>T Thornblade</author>
<author>W W Chapman</author>
</authors>
<title>Context: An algorithm for determining negation, experiencer, and temporal status from clinical reports.</title>
<date>2009</date>
<journal>Journal of Biomedical Informatics,</journal>
<volume>42</volume>
<issue>5</issue>
<contexts>
<context position="20054" citStr="Harkema et al., 2009" startWordPosition="3191" endWordPosition="3194">enerated: document features, ConText features, and code-semantics features (Table 1). Document: Document features include indicators on all individual words, 2-grams, 3-grams, and 4- grams found in the document. These n-gram features have the candidate code appended to them, making them similar to features traditionally used in multiclass document categorization. ConText: We take advantage of the ConText algorithm’s output. ConText is publicly available software that determines the presence of negated, hypothetical, historical, and family-related context for a given phrase in a clinical text (Harkema et al., 2009). 3We can easily afford such a long history because input sequences are generally short and the tagging is binary, resulting in only a small number of possible histories for a document. 746 Features gen. spec. Document x n-gram ConText x x current match x x context x x only in context x x more than once in context x x other matches x x present present in context = pos code present in context Code Semantics x x current match x sem type other matches sem type, context =pos Table 1: The emission features used in LT-HMM. Typeset words represent variables replaced with specific values, i.e. context</context>
</contexts>
<marker>Harkema, Dowling, Thornblade, Chapman, 2009</marker>
<rawString>H. Harkema, J. N. Dowling, T. Thornblade, and W. W. Chapman. 2009. Context: An algorithm for determining negation, experiencer, and temporal status from clinical reports. Journal of Biomedical Informatics, 42(5):839–851, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Kevers</author>
<author>J Medori</author>
</authors>
<title>Symbolic classification methods for patient discharge summaries encoding into ICD.</title>
<date>2010</date>
<booktitle>In Proceedings of the 7th International Conference on NLP (IceTAL),</booktitle>
<pages>197--208</pages>
<location>Reykjavik, Iceland,</location>
<contexts>
<context position="12098" citStr="Kevers and Medori, 2010" startWordPosition="1911" endWordPosition="1914">e or cascade (Aronson et al., 2007; Crammer et al., 2007) or a symbolic component providing features for a statistical component (Patrick et al., 2007; Suominen et al., 2008). Strong competition systems had good answers for dealing with negative and speculative contexts, taking advantage of the competition’s limited set of possible code combinations, and handling of low-frequency codes. Our proposed approach is a combination system as well. We combine a symbolic component that matches lexical strings of a document against a medical dictionary to determine possible codes (Lussier et al., 2000; Kevers and Medori, 2010) and a statistical component that finalizes the assignment of codes to the document. Our statistical component is similar to that of Crammer et al. (2007), in that we train a single model for all codes with code744 specific and generic features. However, Crammer et al. (2007) did not employ our lexical trigger step or our sequence-modeling formulation. In fact, they considered all possible code subsets, which can be infeasible in real-life settings. 4 Method To address the task of document coding, our lexically-triggered HMM operates using a two-stage procedure: 1. Lexically match text to the </context>
</contexts>
<marker>Kevers, Medori, 2010</marker>
<rawString>L. Kevers and J. Medori. 2010. Symbolic classification methods for patient discharge summaries encoding into ICD. In Proceedings of the 7th International Conference on NLP (IceTAL), pages 197–208, Reykjavik, Iceland, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D A Lindberg</author>
<author>B L Humphreys</author>
<author>A T McCray</author>
</authors>
<title>The Unified Medical Language System.</title>
<date>1993</date>
<journal>Methods of Information in Medicine,</journal>
<volume>32</volume>
<issue>4</issue>
<contexts>
<context position="8844" citStr="Lindberg et al., 1993" startWordPosition="1403" endWordPosition="1406">nonymized. The reports were annotated with ICD-9-CM codes by three coding companies, and the majority codes were selected as a gold standard. In total, 45 distinct codes were used. For this task, our use of a dictionary to detect lexical triggers is quite reasonable. The medical domain is rich with manually-created and carefullymaintained knowledge resources. In particular, the ICD-9-CM coding guidelines come with an index file that contains hundreds of thousands of terms mapped to corresponding codes. Another valuable resource is Metathesaurus from the Unified Medical Language System (UMLS) (Lindberg et al., 1993). It has millions of terms related to medical problems, procedures, treatments, organizations, etc. Often, hospitals, clinics, and other healthcare organizations maintain their own vocabularies to introduce consistency in their internal and external documentation and to support reporting, reviewing, and metaanalysis. This task has some very challenging properties. As mentioned above, the ICD-9-CM coding rules create strong code dependencies: codes are assigned to a document as a set and not individually. Furthermore, the code distribution throughout the CMC training documents has a very heavy </context>
</contexts>
<marker>Lindberg, Humphreys, McCray, 1993</marker>
<rawString>D. A. Lindberg, B. L. Humphreys, and A. T. McCray. 1993. The Unified Medical Language System. Methods of Information in Medicine, 32(4):281–291.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y A Lussier</author>
<author>L Shagina</author>
<author>C Friedman</author>
</authors>
<title>Automating ICD-9-CM encoding using medical language processing: A feasibility study.</title>
<date>2000</date>
<booktitle>In AMIA,</booktitle>
<pages>1072</pages>
<contexts>
<context position="12072" citStr="Lussier et al., 2000" startWordPosition="1907" endWordPosition="1910">together in an ensemble or cascade (Aronson et al., 2007; Crammer et al., 2007) or a symbolic component providing features for a statistical component (Patrick et al., 2007; Suominen et al., 2008). Strong competition systems had good answers for dealing with negative and speculative contexts, taking advantage of the competition’s limited set of possible code combinations, and handling of low-frequency codes. Our proposed approach is a combination system as well. We combine a symbolic component that matches lexical strings of a document against a medical dictionary to determine possible codes (Lussier et al., 2000; Kevers and Medori, 2010) and a statistical component that finalizes the assignment of codes to the document. Our statistical component is similar to that of Crammer et al. (2007), in that we train a single model for all codes with code744 specific and generic features. However, Crammer et al. (2007) did not employ our lexical trigger step or our sequence-modeling formulation. In fact, they considered all possible code subsets, which can be infeasible in real-life settings. 4 Method To address the task of document coding, our lexically-triggered HMM operates using a two-stage procedure: 1. Le</context>
</contexts>
<marker>Lussier, Shagina, Friedman, 2000</marker>
<rawString>Y. A. Lussier, L. Shagina, and C. Friedman. 2000. Automating ICD-9-CM encoding using medical language processing: A feasibility study. In AMIA, page 1072.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M Meystre</author>
<author>G K Savova</author>
<author>K C Kipper-Schuler</author>
<author>J F Hurdle</author>
</authors>
<title>Extracting information from textual documents in the electronic health record: a review of recent research.</title>
<date>2008</date>
<journal>Methods of Information in Medicine,</journal>
<volume>47</volume>
<pages>1--128</pages>
<contexts>
<context position="1921" citStr="Meystre et al., 2008" startWordPosition="283" endWordPosition="286"> domain presents a number of interesting challenges for natural language processing. Conventionally, most clinical documentation, such as doctor’s notes, discharge summaries and referrals, are written in a free-text form. This narrative form is flexible, allowing healthcare professionals to express any kind of concept or event, but it is not particularly suited for large-scale analysis, search, or decision support. Converting clinical narratives into a structured form would support essential activities such as administrative reporting, quality control, biosurveillance and biomedical research (Meystre et al., 2008). One way of representing a document is to code the patient’s conditions and the performed procedures into a nomenclature of clinical codes. The International Classification of Diseases, 9th and 10th revisions, Clinical Modification (ICD9-CM, ICD-10-CM) are the official administrative coding schemes for healthcare organizations in several countries, including the US and Canada. Typically, coding is performed by trained coding professionals, but this process can be both costly and errorprone. Automated methods can speed-up the coding process, improve the accuracy and consistency of internal doc</context>
</contexts>
<marker>Meystre, Savova, Kipper-Schuler, Hurdle, 2008</marker>
<rawString>S. M. Meystre, G. K. Savova, K. C. Kipper-Schuler, and J. F. Hurdle. 2008. Extracting information from textual documents in the electronic health record: a review of recent research. Methods of Information in Medicine, 47(Suppl 1):128–144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Patrick</author>
<author>Y Zhang</author>
<author>Y Wang</author>
</authors>
<title>Developing feature types for classifying clinical notes. In BioNLP,</title>
<date>2007</date>
<pages>191--192</pages>
<contexts>
<context position="2877" citStr="Patrick et al., 2007" startWordPosition="426" endWordPosition="429">eral countries, including the US and Canada. Typically, coding is performed by trained coding professionals, but this process can be both costly and errorprone. Automated methods can speed-up the coding process, improve the accuracy and consistency of internal documentation, and even result in higher reimbursement for the healthcare organization (Benson, 2006). Traditionally, statistical document coding is viewed as multi-class multi-label document classification, where each clinical free-text document is labelled with one or several codes from a pre-defined, possibly very large set of codes (Patrick et al., 2007; Suominen et al., 2008). One classification model is learned for each code, and then all models are applied in turn to a new document to determine which codes should be assigned to the document. The drawback of this approach is poor predictive performance on low-frequency codes, which are ubiquitous in the clinical domain. This paper presents a novel approach to document coding that simultaneously models code-specific as well as general patterns in the data. This allows 742 Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 742–751, Portland, Oregon</context>
<context position="11624" citStr="Patrick et al., 2007" startWordPosition="1837" endWordPosition="1840"> guidelines were automatically extended with additional synonyms and code dependency rules generated from the training data (Farkas and Szarvas, 2008). Statistical systems trained on only text-derived features (such as n-grams) did not show good performance due to a wide variety of medical language and a relatively small training set (Goldstein et al., 2007). This led to the creation of hybrid systems: symbolic and statistical classifiers used together in an ensemble or cascade (Aronson et al., 2007; Crammer et al., 2007) or a symbolic component providing features for a statistical component (Patrick et al., 2007; Suominen et al., 2008). Strong competition systems had good answers for dealing with negative and speculative contexts, taking advantage of the competition’s limited set of possible code combinations, and handling of low-frequency codes. Our proposed approach is a combination system as well. We combine a symbolic component that matches lexical strings of a document against a medical dictionary to determine possible codes (Lussier et al., 2000; Kevers and Medori, 2010) and a statistical component that finalizes the assignment of codes to the document. Our statistical component is similar to t</context>
</contexts>
<marker>Patrick, Zhang, Wang, 2007</marker>
<rawString>J. Patrick, Y. Zhang, and Y. Wang. 2007. Developing feature types for classifying clinical notes. In BioNLP, pages 191–192.</rawString>
</citation>
<citation valid="false">
<authors>
<author>J P Pestian</author>
<author>C Brew</author>
<author>P Matykiewicz</author>
<author>D J Hovermale</author>
</authors>
<marker>Pestian, Brew, Matykiewicz, Hovermale, </marker>
<rawString>J. P. Pestian, C. Brew, P. Matykiewicz, D. J. Hovermale,</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Johnson</author>
<author>K B Cohen</author>
<author>W Duch</author>
</authors>
<title>A shared task involving multi-label classification of clinical free text. In BioNLP,</title>
<date>2007</date>
<pages>97--104</pages>
<marker>Johnson, Cohen, Duch, 2007</marker>
<rawString>N. Johnson, K. B. Cohen, and W. Duch. 2007. A shared task involving multi-label classification of clinical free text. In BioNLP, pages 97–104.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Shalev-Shwartz</author>
<author>Y Singer</author>
<author>N Srebro</author>
</authors>
<title>Pegasos: Primal Estimated sub-GrAdient SOlver for SVM. In ICML,</title>
<date>2007</date>
<location>Corvallis, OR.</location>
<marker>Shalev-Shwartz, Singer, Srebro, 2007</marker>
<rawString>S. Shalev-Shwartz, Y. Singer, and N. Srebro. 2007. Pegasos: Primal Estimated sub-GrAdient SOlver for SVM. In ICML, Corvallis, OR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M H Stanfill</author>
<author>M Williams</author>
<author>S H Fenton</author>
<author>R A Jenders</author>
<author>W R Hersh</author>
</authors>
<title>A systematic literature review of automated clinical coding and classification systems.</title>
<date>2010</date>
<journal>JAMIA,</journal>
<pages>17--646</pages>
<contexts>
<context position="9856" citStr="Stanfill et al., 2010" startWordPosition="1559" endWordPosition="1562"> ICD-9-CM coding rules create strong code dependencies: codes are assigned to a document as a set and not individually. Furthermore, the code distribution throughout the CMC training documents has a very heavy tail; that is, there are a few heavily-used codes and a large number of codes that are used only occasionally. An ideal approach will work well with both highfrequency and low-frequency codes. 3 Related work Automated clinical coding has received much attention in the medical informatics literature. Stanfill et al. reviewed 113 studies on automated coding published in the last 40 years (Stanfill et al., 2010). The authors conclude that there exists a variety of tools covering different purposes, healthcare specialties, and clinical document types; however, these tools are not generalizable and neither are their evaluation results. One major obstacle that hinders the progress in this domain is data privacy issues. To overcome this obstacle, the CMC Challenge was organized in 2007. The purpose of the challenge was to provide a common realistic dataset to stimulate the research in the area and to assess the current level of performance on the task. Forty-four teams participated in the challenge. The </context>
</contexts>
<marker>Stanfill, Williams, Fenton, Jenders, Hersh, 2010</marker>
<rawString>M. H. Stanfill, M. Williams, S. H. Fenton, R. A. Jenders, and W. R. Hersh. 2010. A systematic literature review of automated clinical coding and classification systems. JAMIA, 17:646–651.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Suominen</author>
<author>F Ginter</author>
<author>S Pyysalo</author>
<author>A Airola</author>
<author>T Pahikkala</author>
<author>S Salanter</author>
<author>T Salakoski</author>
</authors>
<title>Machine learning to automate the assignment of diagnosis codes to free-text radiology reports: a method description.</title>
<date>2008</date>
<booktitle>In Proceedings of the ICML Workshop on Machine Learning for Health-Care Applications,</booktitle>
<location>Helsinki, Finland.</location>
<contexts>
<context position="2901" citStr="Suominen et al., 2008" startWordPosition="430" endWordPosition="433">ing the US and Canada. Typically, coding is performed by trained coding professionals, but this process can be both costly and errorprone. Automated methods can speed-up the coding process, improve the accuracy and consistency of internal documentation, and even result in higher reimbursement for the healthcare organization (Benson, 2006). Traditionally, statistical document coding is viewed as multi-class multi-label document classification, where each clinical free-text document is labelled with one or several codes from a pre-defined, possibly very large set of codes (Patrick et al., 2007; Suominen et al., 2008). One classification model is learned for each code, and then all models are applied in turn to a new document to determine which codes should be assigned to the document. The drawback of this approach is poor predictive performance on low-frequency codes, which are ubiquitous in the clinical domain. This paper presents a novel approach to document coding that simultaneously models code-specific as well as general patterns in the data. This allows 742 Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 742–751, Portland, Oregon, June 19-24, 2011. c�20</context>
<context position="11648" citStr="Suominen et al., 2008" startWordPosition="1841" endWordPosition="1844">atically extended with additional synonyms and code dependency rules generated from the training data (Farkas and Szarvas, 2008). Statistical systems trained on only text-derived features (such as n-grams) did not show good performance due to a wide variety of medical language and a relatively small training set (Goldstein et al., 2007). This led to the creation of hybrid systems: symbolic and statistical classifiers used together in an ensemble or cascade (Aronson et al., 2007; Crammer et al., 2007) or a symbolic component providing features for a statistical component (Patrick et al., 2007; Suominen et al., 2008). Strong competition systems had good answers for dealing with negative and speculative contexts, taking advantage of the competition’s limited set of possible code combinations, and handling of low-frequency codes. Our proposed approach is a combination system as well. We combine a symbolic component that matches lexical strings of a document against a medical dictionary to determine possible codes (Lussier et al., 2000; Kevers and Medori, 2010) and a statistical component that finalizes the assignment of codes to the document. Our statistical component is similar to that of Crammer et al. (2</context>
</contexts>
<marker>Suominen, Ginter, Pyysalo, Airola, Pahikkala, Salanter, Salakoski, 2008</marker>
<rawString>H. Suominen, F. Ginter, S. Pyysalo, A. Airola, T. Pahikkala, S. Salanter, and T. Salakoski. 2008. Machine learning to automate the assignment of diagnosis codes to free-text radiology reports: a method description. In Proceedings of the ICML Workshop on Machine Learning for Health-Care Applications, Helsinki, Finland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Taskar</author>
<author>C Guestrin</author>
<author>D Koller</author>
</authors>
<title>Max-margin markov networks.</title>
<date>2003</date>
<booktitle>In Neural Information Processing Systems Conference (NIPS03),</booktitle>
<location>Vancouver, Canada,</location>
<contexts>
<context position="17962" citStr="Taskar et al., 2003" startWordPosition="2856" endWordPosition="2859"> have an input text with underlined trigger phrases, as detected by our dictionary. This implies an input sequence (bottom right), which consists of detected codes and their corresponding trigger phrases. The gold-standard code set for the document is used to infer a gold-standard label sequence for these codes (top right). At test time, the goal of the classifier is to correctly predict the correct binary label sequence for new inputs. We discuss the construction of the features used to make this prediction in section 4.3. 4.3 Model We model this sequence data using a discriminative SVM-HMM (Taskar et al., 2003; Altun et al., 2003). This allows us to use rich, over-lapping features of the input while also modeling interactions between labels. A discriminative HMM has two major categories of features: emission features, which characterize a candidate’s tag in terms of the input document x, and transition features, which characterize a tag in terms of the tags that have come before it. We describe these two feature categories and then our training mechanism. All feature engineering discussed below was carried out using 10-fold crossvalidation on the training set. Transition Features The transition fea</context>
</contexts>
<marker>Taskar, Guestrin, Koller, 2003</marker>
<rawString>B. Taskar, C. Guestrin, and D. Koller. 2003. Max-margin markov networks. In Neural Information Processing Systems Conference (NIPS03), Vancouver, Canada, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Yessenalina</author>
<author>Y Yue</author>
<author>C Cardie</author>
</authors>
<title>Multilevel structured models for document-level sentiment classification.</title>
<date>2010</date>
<booktitle>In EMNLP.</booktitle>
<marker>Yessenalina, Yue, Cardie, 2010</marker>
<rawString>A. Yessenalina, Y. Yue, and C. Cardie. 2010. Multilevel structured models for document-level sentiment classification. In EMNLP.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>