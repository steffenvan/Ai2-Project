<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000029">
<title confidence="0.995045">
Harnessing different knowledge sources to measure semantic relatedness
under a uniform model
</title>
<author confidence="0.999112">
Ziqi Zhang Anna Lisa Gentile Fabio Ciravegna
</author>
<affiliation confidence="0.999536">
Department of Computer Science, University of Sheffield
</affiliation>
<address confidence="0.923725">
211 Portobello, Regent Court
Sheffield, S1 4DP
</address>
<email confidence="0.603132">
z.zhang@dcs.shef.ac.
</email>
<bodyText confidence="0.977047">
uk
a.l.gentile@dcs.shef
.ac.uk
f.ciravegna@dcs.shef
.ac.uk
</bodyText>
<sectionHeader confidence="0.886781" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99982475">
Measuring semantic relatedness between
words or concepts is a crucial process to
many Natural Language Processing tasks.
Exiting methods exploit semantic evidence
from a single knowledge source, and are
predominantly evaluated only in the
general domain. This paper introduces a
method of harnessing different knowledge
sources under a uniform model for
measuring semantic relatedness between
words or concepts. Using Wikipedia and
WordNet as examples, and evaluated in
both the general and biomedical domains, it
successfully combines strengths from both
knowledge sources and outperforms state-
of-the-art on many datasets.
</bodyText>
<sectionHeader confidence="0.995164" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999912377358491">
Semantic relatedness (SR) measures how much
two (strings of) words or concepts are related by
encompassing all kinds of relations between them
(Strube and Ponzetto, 2006). It is more general
than semantic similarity. SR is often an important
pre-processing step to many complex Natural
Language Processing (NLP) tasks, such as Word
Sense Disambiguation (Leacock and Chodorow,
1998; Han and Zhao, 2010), and information
retrieval (Finkelstein et al., 2002). In the
biomedical domain, SR is an important technique
for discovering gene functions and interactions
(Wu et al., 2005; Ye et al., 2005).
There is an abundant literature on measuring
SR between words or concepts. Typically, these
methods extract semantic evidence of words and
concepts from a background knowledge source,
with which their relatedness is assessed. The
knowledge sources can be unstructured documents
or (semi-)structured resources such as Wikipedia,
WordNet, and domain specific ontologies (e.g., the
Gene Ontology1).
In this paper, we identify two issues that have
not been addressed in the previous works. First,
existing works typically employ a single
knowledge source of semantic evidence. Research
(Strube and Ponzetto, 2006; Zesch and Gurevych,
2010; Zhang et al., 2010) has shown that the
accuracy of an SR method differs depending on the
choice of the knowledge sources, and there is no
conclusion which knowledge source is superior to
others. Zhang et al. (2010) argue that this indicates
different knowledge sources may complement each
other. Second, the majority of SR methods have
been evaluated in general domains only, except a
few earlier WordNet-based methods that have been
adapted to biomedical ontologies and evaluated in
that domain (Lord et al., 2003; Pedersen et al.,
2006; Pozo et al., 2008). Given the significant
attention that SR has received in specific domains
(Pesquita et al., 2007), evaluation of SR methods
in specific domains is increasingly important.
This paper addresses these issues by proposing
a generic and uniform model for computing SR
between words or concepts using multiple
knowledge sources, and evaluating the proposed
method in both general and specific domains. The
method combines and integrates semantic evidence
of words or concepts extracted from any
knowledge source in a generic graph
representation, with which the SR between
concepts or words is computed. Using two of the
most popular general-domain knowledge sources,
</bodyText>
<note confidence="0.663665">
1 http://www.geneontology.org/, last retrieved in Mar. 2011
</note>
<page confidence="0.59168">
991
</page>
<bodyText confidence="0.805817933333334">
Wikipedia and WordNet as examples, the method resources (Agirre et al., 2009; Gabrilovich and
is evaluated on 7 benchmarking datasets, including Markovitch, 2007; Gouws et al., 2010; Zesch and
three datasets from the biomedical domain and Gurevych, 2007; Zhang et al., 2010). Hybrid
four from the general domain. It has achieved methods combine different purebred methods in
excellent results: compared to the baselines that certain ways. For example Riensche et al. (2007)
use each single knowledge sources, combining employ both an IC based method (Resnik, 1995)
both knowledge sources has improved the accuracy and a statistical method (cosine vector similarity)
on all datasets by 2~11%; compared to state-of- in their study. Pozo et al. (2008) derive a taxonomy
the-art on the general domain datasets, the method of terms from unstructured documents by applying
achieves the best results on three datasets; and on hierarchical clustering based on corpus statistics,
the other three biomedical datasets, it obtains the then apply path based method on this taxonomy to
best result in one case; and second and third best compute SR. Han and Zhao (2010) use one IC
results on the other two among eight participating based method and two statistical methods to
methods, where all other competitors exploit some compute SR, then derive an aggregated score.
domain-specific knowledge sources. 2.2 SR knowledge sources and domains
</bodyText>
<note confidence="0.958206542857143">
The remainder of this paper is organized as Computing SR requires background knowledge
follows. Section 2 discusses related work; Section about concepts or words, which can be extracted
3 presents the proposed method; Section 4 from unstructured corpora, semi-structured and
describes the experiments and evaluation; Section structured knowledge resources. Unstructured
5 discusses results and findings; Section 6 corpora are easier to create and cheaper to
concludes this paper. maintain, however, semantic relations between
2 Related work words or concepts are implicit. Methods (Chen et
2.1 SR methods al., 2006; Cilibrasi and Vitanyi 2007; Matsuo et al.,
Methods for computing SR can be classified into 2006) that exploit unstructured corpora typically
path based, Information Content (IC) based, depend on distributional statistics, and thus may
statistical and hybrid methods. Path based ignore important semantic evidences present in
methods (Hirst and St-Onge, 1998; Leacock and (semi-)structured knowledge sources (Pan and
Chodorow, 1998; Pekar and Staab, 2002; Rada et Farrell, 2007). Recent studies (Harrington, 2010;
al., 1989; Wu and Palmer, 1994) measure SR Pozo et al., 2008; Wojtinnek and Pulman, 2011)
between words or concepts as a function of their propose to pre-process a corpus to learn a semantic
distance in a semantic network, usually calculated network, with which SR is computed. This creates
based on the path connecting the words or concepts high pre-processing cost; also, the choice of corpus
by certain semantic (typically is-a) links. IC based and its size often have a direct correlation with the
methods (Jiang and Conrath, 1997; Lin, 1998; accuracy of SR methods (Batet et al., 2010).
Pirro et al., 2009; Resnik, 1995; Seco et al., 2004) (Semi-)Structured knowledge sources on the
assess relatedness between words or concepts by other hand, organize semantic knowledge about
the amount of information they share, usually concepts and words explicitly and interlink them
determined by a higher level concept that with semantic relations. They have been popular
subsumes both concepts in a taxonomic structure. choices in the studies of SR, and they include
Statistical methods measure relatedness between lexical resources such as WordNet, Wiktionary,
words or concepts based on their distribution of and (semi-)structured encyclopedic resources such
contextual evidence. This can be formalized as co- as Wikipedia. WordNet has been used in earlier
occurrence statistics collected from unstructured studies (Hirst and St-Onge, 1998; Jiang and
documents (Chen et al., 2006; Cilibrasi and Conrath, 1997; Lin, 1998; Leacock and Chodorow
Vitanyi, 2007; Matsuo et al., 2006), or 1998; Resnik, 1995; Seco et al., 2004; Wu and
distributional concept or word vectors with Palmer, 1994) and is still a preferred knowledge
features extracted from either unstructured source in recent works (Agirre et al., 2009).
documents (Harrington, 2010; Wojtinnek and However, its effectiveness may be hindered by its
Pulman, 2011) or (semi-)structured knowledge lack of coverage of specialized lexicons and
992 domain specific concepts (Strube and Ponzetto,
</note>
<bodyText confidence="0.998509545454546">
2006; Zhang et al., 2010). Wikipedia and
Wiktionary are collaboratively maintained know-
ledge sources and therefore may overcome this
limitation. Wikipedia in particular, is found to have
reasonable coverage of many domains (Holloway
et al., 2007; Halavais, 2008). It has become
increasingly popular in SR studies recently.
However, research (Zesch and Gurevych, 2010)
have shown that methods based on Wikipedia have
no clear advantage over WordNet-based methods
on some general domain datasets in terms of
accuracy, while Zhang et al. (2010) argue that
different knowledge sources may complement each
other, and SR methods may benefit from
harnessing different knowledge sources.
Several studies (Lord et al., 2003; Pedersen et
al., 2006; Petrakis et al., 2006; Pozo et al., 2008)
have adapted state-of-the-art to domain specific
knowledge sources (e.g., the Gene Ontology, the
MeSH2) and evaluated them therein. Despite these
efforts, a large proportion of state-of-the-art is still
only evaluated in the general domain.
</bodyText>
<subsectionHeader confidence="0.882154">
2.3 SR methods similar to this work
</subsectionHeader>
<bodyText confidence="0.9999732">
Few works have attempted at combining different
knowledge sources in SR studies, especially (semi-
)structured knowledge sources. The closest studies
are Han and Zhao (2010) and Tsang and Stevenson
(2010). Han and Zhao firstly compute SR between
words using three state-of-the-art SR methods
separately. Next, one score is chosen subject to an
arbitrary preference order, and used to create a
connected graph of weighted edges between
words. A recursive function is then applied to the
graph to compute final SR scores between words.
Essentially, each SR method is applied in isolation
and features from different sources are used
separately with each distinctive method. Although
this retains advantages of each method, the
limitations of them are also combined.
Tsang and Stevenson (2010) combine WordNet
and unstructured documents by weighing each
word found in WordNet using its frequency
observed in a large corpus. The frequencies
however, are sensitive to the choice of corpus, thus
different corpora may result in different accuracies.
Furthermore, their method is only applicable to
computing SR between pairs of sets of words or
concepts.
</bodyText>
<sectionHeader confidence="0.997485" genericHeader="introduction">
3 Methodology
</sectionHeader>
<bodyText confidence="0.998619">
We define a set of requirements for SR methods
that harness different knowledge sources:
</bodyText>
<listItem confidence="0.972922">
• It should improve over the same method
based on a single knowledge source
• It should be generic and applicable to any
knowledge source
• It should be robust in dealing with
knowledge source specific features but
also tolerate the quality and coverage
issues of individual knowledge source
</listItem>
<bodyText confidence="0.999921666666666">
Our method of harnessing different knowledge
sources contains four steps. Firstly (Section 3.1),
each word or word segment is searched in each
knowledge source to identify their contexts that is
specific to that knowledge source. We define a
context as the representation of meaning or a
concept for a word. In the following, we say that
each context is associated with a distinct concept.
Secondly (Section 3.2), for each concept of an
input word, features are extracted from its context
and a graph representation of each concept and
their features is created. Thirdly (Section 3.3),
cross-source contexts are mapped where they refer
to the same concept, thus their features from
different sources can be combined to derive an
enriched representation. This creates a final,
uniform graph representation where input words
are connected by shared features of their
underlying candidate concepts. Then (Section 3.4)
the graph is submitted to a generic algorithm to
compute SR between words.
In the following, we discuss details with respect
to different types of knowledge sources, while
focusing on Wikipedia and WordNet in our
experiments for two reasons. First, they are used
by the majority of SR methods and are therefore
most representative knowledge sources. Second,
they have strongly distinctive and complementary
characteristics, which make ideal testbeds for the
requirements. On one hand, WordNet is a lexical
resource containing rich and strict semantic
relations between words, but lacks coverage of
specialized vocabularies. On the other hand,
Wikipedia is a semi-structured resource with good
coverage of domains and named entities, but the
semantic knowledge is organized in a looser way.
</bodyText>
<footnote confidence="0.740585">
2 http://www.nlm.nih.gov/mesh/ last retrieved in March 2011
</footnote>
<page confidence="0.89703">
993
</page>
<subsectionHeader confidence="0.999255">
3.1 Context retrieval
</subsectionHeader>
<bodyText confidence="0.999882733333333">
Given a pair of words or word segments, we firstly
identify contexts representing the underlying
meanings or concepts from each knowledge
source. For lexical resources, this could be
distinctive word senses. In WordNet (WN), a
context corresponds to a single synset, which
corresponds to a concept. We search each word in
WordNet and extract all possible synsets. Let w be
a word or word segment (e.g., “cat”), and
be the set of k concepts of w
extracted from WordNet.
Using Wikipedia (WK) as an example semi-
structured resource, the context can be an article
that describes a unique concept. Thus we search
for underlying articles that describe different
concepts. Firstly, we search w in Wikipedia, where
three situations may be anticipated. If a single non-
disambiguation page describing a concept is
returned, the concept is selected and the retrieval is
complete. In the second case, a disambiguation
page linking to all possible concept pages may be
returned. This page lists all underlying concepts
and entities referenced by w as links and a short
description with each link. In this case, we always
keep the first concept page, which is found often to
be the most common sense of the word;
additionally, we select other concept pages whose
short descriptions contain the word w. We do not
select all linked pages because many of these in
fact link to a concept relevant to w, but not
necessarily a candidate sense of w. Thirdly, if no
pages are returned for w, we search for the most
relevant page using w as keyword(s) in an inverted
index of all Wikipedia pages (e.g., via search
engines). We denote concepts retrieved from
Wikipedia as .
For unstructured sources such as documents, a
simple approach could be defining a word context
as a text passage around each occurrence of w, and
grouping similar contexts of w as representation of
its underlying meanings, or concepts. Alternatively,
more complex approaches such as Pozo et al.
(2008) and Harrington (2010) may be applied to
extract a lexical network of words, whereby similar
methods to WordNet can be applied.
</bodyText>
<subsectionHeader confidence="0.999799">
3.2 Feature extraction and representation
</subsectionHeader>
<bodyText confidence="0.959210875">
Next, for each concept identified from a
knowledge source, features are extracted from their
corresponding contexts. In our case, for each
, we follow the work by Zhang et al.
(2010) to extract four types of features from their
corresponding Wikipedia pages. Figure 1 shows an
example representation of a concept and its
Wikipedia features:
</bodyText>
<listItem confidence="0.999452142857143">
• Words from page titles and redirection
links (can be considered as synonyms)
• Words from categories, used as higher
level hypernyms in some studies (Zesch et
al., 2010; Strube and Ponzetto, 2006)
• Words from outgoing links
• Top n most frequent words from a page
</listItem>
<figureCaption confidence="0.84948">
Figure 1. Representation of the concept “cat, the
</figureCaption>
<bodyText confidence="0.9928896">
mammal” using different types of features
extracted from Wikipedia. The shaded circle
represents the concept; ovals represent feature
values; edges connecting feature values to the
concept and &lt;labels&gt; represent feature types
For each , we extract ten features from
WordNet: hypernyms, hyponyms, meronyms,
holonyms, synonyms, antonyms, attributes, “see
also” words, “related” words, and gloss. These are
also represented in the same way as in Figure 1.
With unstructured sources, contextual words
can be used as features. Alternatively, if a lexical
network is extracted, features may be extracted in a
similar way to those of WordNet.
Additionally, with WordNet and Wikipedia, we
also propose several intra-resource feature merging
strategies to study the effect of feature
diversification. This is because, while some
approaches (such as Agirre et al., 2009;
Harrington, 2010; Yeh et al., 2009) do not
distinguish different feature types in graph
construction, or adopt a bag-of-words feature
representation (such as Zesch and Gurevych,
2010), others (such as Yazdani and Popescu-Belis,
2010; Zhang et al., 2010) have used differentiated
</bodyText>
<page confidence="0.657618">
994
</page>
<bodyText confidence="0.999808166666667">
feature types and weights in their model. We
therefore carry out studies to investigate this issue.
Specifically, for the original four Wikipedia
features, we create a bag-of-words feature that
simply merges all feature types (i.e., all edges in
Figure 1 will have the same label). For the original
ten WordNet features, we propose two merged
representations corresponding to that of Wikipedia,
so as to support the studies of feature enrichment
in the following section. We introduce a bag-of-
words feature that collapses all different feature
types, and a four-feature representation as follow:
</bodyText>
<listItem confidence="0.999057636363636">
• wn-synant merges WordNet synonyms and
antonyms.
• wn-hypoer merges WordNet hypernyms
and hyponyms, collectively representing
features by “is-a” semantic relation
• wn-assc merges WordNet meronyms,
holonyms, related and “see also”, which
are features corresponding to associative
relations
• wn-dist merges WordNet gloss and
attributes that generally describe a concept.
</listItem>
<subsectionHeader confidence="0.996847">
3.3 Concept mapping and feature enrichment
</subsectionHeader>
<bodyText confidence="0.9981994375">
Our method essentially harnesses different
knowledge sources by combining features
extracted from different sources in a uniform
model. This requires two sub-processes: cross-
source concept mapping and cross-source
feature enrichment.
In cross-source concept mapping, concepts
extracted from different knowledge sources are
mapped according to similar meanings such that
cross-source features can be combined. To do so,
we select the concepts from one knowledge source
as the reference concept set; then concepts from
other knowledge sources are mapped to reference
concepts of similar meanings. There can be
different criteria of choosing reference knowledge
source concepts. Empirically, we found it
necessary to choose the knowledge source with
broader coverage and richer features. This will be
discussed later in Section 5. Following this
strategy, in our example, CWWk is chosen as
reference concepts, and for each CWWk E CWWk we
select a cWW E CWW such that CWWk and cWW refer to
the same meaning. To do so, we apply a simple
maximum set overlap metric to their feature
values. Let F(c) be a function that returns all
feature values of c as bag-of-words, then for each
Cwk E Cwk , it is mapped to a cr such that
lF(Cwn)l n lF(Cwk)l is maximized among all
cr E Cr. The resulting concept candidates are
denoted as CWm apd , where cWmapd= {CWWk, CWWn} is a
mapped set of concepts potentially referring to the
same meaning. If CWWn = 0 then CWm apd =
</bodyText>
<equation confidence="0.994497">
, .., ., .
W W
</equation>
<bodyText confidence="0.99957075">
Next, cross-source feature enrichment creates
a uniform feature representation for each mapped
sets of concepts. The process can be considered as
enriching the features from one knowledge source
with others. The most straightforward approach is
to simply collect features extracted from each
knowledge source on to a single graph, retaining
the diversity in feature types. For example, Figure
2 shows a graph representation based on the
collection of the four Wikipedia features and the
four derived WordNet features. We refer to this
approach as “feature combination”.
</bodyText>
<figureCaption confidence="0.967928">
Figure 2. Representation of “cat, the mammal”
after concept mapping and feature combination
</figureCaption>
<bodyText confidence="0.9999836">
On the other hand, cross-source features may be
merged according to their semantics. For example,
WordNet and Wikipedia contain features based on
synonyms of concepts; while Wikipedia and
unstructured documents contain word distribution-
al features. Thus we define “feature integration”
as merging feature types from different knowledge
sources into single types of features based on their
similarity in semantics. With WordNet and Wiki-
pedia, we integrate features as below (Figure 3):
</bodyText>
<listItem confidence="0.98063675">
• merged-synant merges Wikipedia page
titles and redirection links with wn-synant
• merged-hypoer merges merges Wikipedia
categories with wn-hypoer
995
• merged-assc merges Wikipedia links with
wn-assc. We consider Wikipedia links bear
other associative relations and are
therefore merged with features extracted
by other WordNet relations
• merged-dist merges Wikipedia frequent n
words with wn-dist.
</listItem>
<figureCaption confidence="0.9683055">
Figure 3. Representation of “cat, the mammal”
after concept mapping and feature integration
</figureCaption>
<bodyText confidence="0.999964166666667">
Note that the difference between cross-source
feature combination and integration is that the
former introduces more types of features, whereas
the latter retains same number of feature types but
increases feature values for each type. Both have
the effect of establishing additional path (via
features) between concepts, but in different ways.
With intra-resource feature diversification, cross-
source feature combination and feature
integration, we create a total of nine intra- and
cross-source feature representations to be tested
with the uniform random walk model:
</bodyText>
<listItem confidence="0.999901333333333">
• four types of Wikipedia features (wk-4F)
• one type of Wikipedia features (wk-1F)
• ten types of WordNet features (wn-10F)
• four types of WordNet features (wn-4F)
• one type of WordNet features (wn-1F)
• wk-4F combines wn-4F: wk-4F+wn4F,C
• wk-4F integrates wn-4F: wk-4F+wn4F,I
• wk-1F combines wn-1F: wk-1F+wn1F,C
• wk-1F integrates wn-1F: wk-1F+wn1F,I
</listItem>
<subsectionHeader confidence="0.979841">
3.4 Computing SR using the graph
</subsectionHeader>
<bodyText confidence="0.995517096774194">
The algorithm for computing SR using the graph is
based on the idea of random walk. It formalizes the
idea that taking successive steps along the paths in
a graph, the “easier” it is to arrive at a target node
starting from a source node, the more related the
two nodes are. Following the previous steps, the
feature representations of all candidate concepts
relevant to the input word pairs are joined, which
creates a single undirected, weighted, bi-partite
graph. Let G = (V, E) be the graph, where V is the
set of nodes (concepts and feature values); E is the
set of edges (feature types) that connect concepts
and features. As shown in Figure 4, different
concepts are connected if they share same values
of same types of features, namely, there exists a
path that connects one concept to another.
Figure 4. Paths are established between different
concepts if they share values of same feature types
&lt;bold underlined&gt;
Using Figure 4 it is easier to comprehend the
difference between feature combination and
integration. Since concept nodes can only be
connected by same types of edges (feature types),
feature combination increases the chances of
connectivity by adding in more types of edges,
while integration merges similar types of edges
across knowledge sources and increases the
number of feature nodes connected by each type.
From the graph, we start by building an
adjacency matrix W of initial probability
distribution:
</bodyText>
<equation confidence="0.978283571428571">
 w l
( ) 
k , ( , ) 
  l L i j E
[1]
W
ij 0,
</equation>
<bodyText confidence="0.998815">
Where Wij is the ith-line and jth-column entry of W,
indexed by V; l(i, j) is a function that returns the
type of edge (i.e., type of feature) connecting
nodes i and j; L is the set of all possible types; w(l)
returns the weight for that type. Essentially, L is
the collection of all feature types, and w(l) assigns
</bodyText>
<equation confidence="0.6106975">
otherwise 
996
</equation>
<bodyText confidence="0.998554882352941">
a weight to a particular feature type. Next, we
compute the transition probability matrix P(t)(j|i) =
[(D−1W)t]ij (Dii = ∑kWik), which returns the
probability of reaching other nodes from a starting
node on the graph after t steps. In this method, we
follow the work by Rowe and Ciravegna (2010) to
set t=2 in order to preserve locally connected
nodes. Next, we extract the probability vectors
corresponding to concept nodes from P, and
compute pair-wise relatedness using the cosine
function. Effectively, this formalizes the notion
that two concepts related to a third concept is also
semantically related, which is similar to the
hypothesis proposed by Patwardhan and Pedersen
(2006) in their method based on second-order
context vectors. The final SR between the input
word pair is the maximum pair-wise concept SR.
</bodyText>
<sectionHeader confidence="0.957543" genericHeader="method">
4 Experiment and evaluation
</sectionHeader>
<bodyText confidence="0.99689190625">
We evaluate the method based on correlation
against human judgment (gold standard) on seven
benchmarking datasets covering both general and
technical domains. These include four general
domain datasets: the Rubenstein and Goodenough
(1965) dataset containing 65 pairs of nouns
(RG65); the Miller and Charles (1991) dataset that
is a subset of the RG-65 dataset and contains 30
pairs (MC30); the Finkelstein et al. (2002) dataset
with 353 pairs of words, including nouns, verbs,
adjectives, as well as named entities. This contains
two subsets, a set of 153 pairs (Fin153) and a set of
200 (Fin200) pairs each annotated by a different
groups of annotators. Zesch and Gurevych (2010)
show largely varying Inter-Annotator-Agreement
(IAA) between the two sets (Table 1), and argue
that they should be treated as separate datasets.
Three biomedical datasets are selected to evaluate
domain-specific performance of the proposed
method. These include a set of 36 MeSH term pairs
in Petrakis et al. (2006) (MeSH36), 30 pairs of
medical terms annotated by a group of physicians
as in Pedersen et al. (2006) (Ped30-p) and the same
set annotated by a different group of medical
coders (Ped30-c). Table 1 shows statistics of the
seven datasets.
The correlation is computed using the
Spearman rank order coefficient for two reasons.
First, it is a better metric than other alternatives
(Zesch and Gurevych, 2010). Second, it is
consistent with the majority of studies such that
results can be compared.
</bodyText>
<table confidence="0.99923575">
Dataset Size Domain IAA
MC30 30 General 0.9
RG65 65 General 0.8
Fin153 153 General 0.73
Fin200 200 General 0.55
Ped30-p 30 Biomedical 0.68
Ped30-c 30 Biomedical 0.78
MeSH36 36 Biomedical -
</table>
<tableCaption confidence="0.999918">
Table 1: Information of benchmarking datasets
</tableCaption>
<bodyText confidence="0.999886230769231">
We distribute feature weights w(l) across
different feature types L evenly in each feature
representation. Although Zhang et al. (2010) show
that discriminated feature weights leads to
improved accuracy; this is not the focus of this
study. Since we aim to investigate the effects of
harnessing different knowledge sources, we
obtained baseline performances by applying the
method to those feature representations based on
single knowledge sources (i.e., wk-4F, wk-1F, wn-
10F, wn-4F, wn-1F). Tables 2 and 3 show the best
results obtained with baselines and corresponding
knowledge sources and feature representation.
</bodyText>
<table confidence="0.999572875">
Dataset Corr. Feature Coverage (% pairs)
MC30 0.77 wn-1F 77%
RG65 0.71 wn-1F 65%
Fin153 0.45 wn-4F 82%
Fin200 0.35 wn-4F 76%
Ped30-p 0.66 wn-4F 33%
Ped30-c 0.8 wn-4F 33%
MeSH36 0.49 wn-1F 50%
</table>
<tableCaption confidence="0.835168">
Table 2: Correlation obtained using WordNet.
Many word pairs are not covered due to sparse
feature space and lack of coverage. Only covered
</tableCaption>
<table confidence="0.947918555555555">
pairs are accounted.
Dataset Corr. Feature
MC30 0.74 wk-1F
RG65 0.67 wk-1F
Fin153 0.7 wk-1F
Fin200 0.51 wk-4F
Ped30-p 0.53 wk-4F
Ped30-c 0.58 wk-4F
MeSH36 0.73 wk-4F
</table>
<tableCaption confidence="0.95883">
Table 3: Correlation obtained using only
Wikipedia. All word pairs are 100% covered.
</tableCaption>
<page confidence="0.648526">
997
</page>
<tableCaption confidence="0.7006795">
Tables 4 – 6 show results obtained with
enriched feature representation.
</tableCaption>
<table confidence="0.9999355">
Combination (C) Integration (I)
Dataset wn-4F + wn-1F + wn-4F + wn-1F
wk-4F wk-1F wk-4F + wk-1F
MC30 0.77 0.8 0.8 0.79
RG65 0.74 0.73 0.73 0.729
Fin153 0.73 0.75 0.74 0.73
Fin200 0.52 0.54 0.53 0.54
Ped30-p 0.63 0.52 0.64 0.47
Ped30-c 0.64 0.52 0.67 0.49
MeSH36 0.7 0.694 0.75 0.7
</table>
<tableCaption confidence="0.9557395">
Table 4: Correlation obtained using both
knowledge sources. Word pairs are 100% covered.
</tableCaption>
<table confidence="0.999688444444444">
KS and # of feature types
WN WK WK+WN,C WK+WN, I
MC30 1 1 1 4
RG65 1 1 4 4
Fin153 4 1 1 4
Fin200 4 4 1 1
Ped30-p 4 4 4 4
Ped30-c 4 4 4 4
MeSH36 1 4 4 4
</table>
<tableCaption confidence="0.727108333333333">
Table 5: Number of feature types with which best
results are obtained on each dataset. KS:
Knowledge Source
</tableCaption>
<table confidence="0.999307888888889">
Single KS Multiple KS Impr.
Dataset Best corr. Best corr. Strategy
MC30 0.74 0.8 C/I 0.06
RG65 0.67 0.74 C 0.07
Fin153 0.7 0.75 C 0.05
Fin200 0.51 0.54 C/I 0.03
Ped30-p 0.53 0.64 I 0.11
Ped30-c 0.58 0.67 I 0.09
MeSH36 0.73 0.75 I 0.02
</table>
<tableCaption confidence="0.864341">
Table 6: Improvement achieved by harnessing
multiple KSs. Best correlation with single KS is
based on Wikipedia, which provides 100%
coverage of word pairs.
</tableCaption>
<table confidence="0.999934">
MC30 RG65 Fin153 Fin200 KS
best of 0.8 0.74 0.75 0.54 Both
WN+WK
Rad89* 0.75 0.79 0.33 0.24 WN
LC98* 0.75 0.79 0.33 0.24 WN
WP94* 0.77 0.78 0.38 0.24 WN
HS98* 0.76 0.79 0.33 0.32 WN
Res95* 0.72 0.74 0.35 0.26 WN
JC97* 0.68 0.58 0.28 0.10 WN
Lin98* 0.67 0.60 0.27 0.17 WN
Zes07* 0.77 0.82 0.6 0.51 WK
GM07* 0.67 0.75 0.69 0.51 WK
Zha10 0.71 0.76 0.71 0.46 WK
</table>
<tableCaption confidence="0.952830666666667">
Table 73: Comparison against state-of-the-art in the
general domain. (* figures from Zesch and
Gurevych, 2010)
</tableCaption>
<table confidence="0.999923333333333">
Ped30-p Ped30-c MeSH36 KS
best of 0.64 0.67 0.75 WN+
WN+WK WK
Pet06 best - - 0.74 MeSH
Ped06 best 0.84 0.75 - GO, D
Ped06 second 0.62 0.68 - GO, D
</table>
<tableCaption confidence="0.929803">
Table 84: Comparison against state-of-the-art in the
biomedical domain. GO – Gene Ontology; D –
document sets.
</tableCaption>
<bodyText confidence="0.999661933333333">
Given the fact that some datasets (i.e., MC30,
Ped30-p, Ped30-c, MeSH36) have a relatively low
sample size, we cannot always be sure that
correlation values are accurate or occurred by
chance. Therefore, we measure the statistical
significance of correlation by computing the p-
value for the correlation values reported for our
system in Tables 7 and 8. For all cases, a p-value
of less than 0.001 is obtained, which indicates that
correlation values are statistically significant.
Tables 7 and 8 compare our method against state-
of-the-art. For Table 8, figures for other state-of-
the-art systems can be found in corresponding
publications; while we only list the best
performing systems for comparison.
</bodyText>
<note confidence="0.931610125">
3 Rada (1989) (Rad89); Leacock and Chodorow (1998)
(LC98); Wu and Palmer (1994) (WP04); Hirst and St-Onge
(1998) (HS98); Resnik (1995) (Res95); Jiang and Conrath
(1997) (JC97); Lin (1998) (Lin98); Zesch and Gurevych
(2007) (ZG07); Gabrilovich and Markovitch (2007) (GM07);
Zhang et al. (2010) (Zha10)
4 Petrakis et al. (2006) (Pet06); Pedersen et al. (2006) (Ped06).
Original participating systems can be found in these works.
</note>
<page confidence="0.794103">
998
</page>
<sectionHeader confidence="0.996743" genericHeader="method">
5 Discussion
</sectionHeader>
<bodyText confidence="0.999746575757576">
Single v.s. multiple knowledge sources As shown
in Table 6, considering the best performances
across all feature enrichment strategies and feature
sets, the proposed method successfully harnessed
different knowledge sources and improved over the
baselines using single knowledge sources by 0.02
~ 0.11. The biggest improvement (0.11) is on a
domain-specific dataset, on which the method
based on single knowledge source performed
poorly in terms of coverage and accuracy. The best
enrichment strategy that has consistently improved
the baselines is wk-4F+wn-4F, Integration (Table
4 v.s. Table 3). With features enriched from
multiple knowledge sources, the method also
consistently improved over their corresponding
single-source features on all datasets, except
MeSH36, on which wk-4F+wn-4F, Combination
(Table 4) slightly reduced the accuracy obtained
with wk-4F (Table 3) only.
The large proportion of uncovered word pairs
using WordNet is due to its lack of coverage of
specialized lexicons, and sparser semantic content.
For example, of all 115 distinctive terms in the
Ped30 and MeSH36 datasets, 30% are not included
in WordNet. And of all 447 distinctive words in all
general domain datasets, only 69% have multiple
synonyms. Features such as attributes and “see
also” are present for less than 20 words. This is the
reason that some approaches using WordNet (e.g.,
Agirre et al., 2009) require a graph of all WordNet
lexicons to be built, thus intermediate words may
“bridge” input words even if they do not connect
directly by their features. Nevertheless, the
improvement in accuracy and 100% coverage after
harnessing both knowledge sources suggests that
they complement each other well. On one hand,
Wikipedia brings its strength in domain and
content coverage; on the other hand, WordNet
brings useful semantic evidences for words that are
covered.
Concept mapping and feature enrichment
methods While the set overlap based method for
cross-source concept mapping using the reference
knowledge source concepts is simple and proved
successful, the accuracy of mapping and its
correlation with the accuracy of the SR method
was not studied. This will be explored in the future.
Also, alternative mapping methods will be
investigated. For example, Toral and Muñoz (2006)
describe a different method of mapping Wikipedia
articles to WordNet synsets; one could also adopt a
simple disambiguation process to select the best
candidate concept from each knowledge source
suited for the input word pairs, whereby cross-
source concept mapping becomes straightforward.
In terms of feature enrichment strategies, there is
no strong indication (Table 6) of which (feature
combination v.s. integration) is more effective,
although the system consistently outperforms the
baselines (Table 4 v.s. Table 3) with the wk-
4F+wn-4F, Integration strategy.
Feature diversification v.s. unification Table
5 suggests that in most cases, differentiating
feature types leads to better results than merging
them uniformly, despite the knowledge sources
used. This is consistent with the findings by Zhang
et al. (2010). This can be understandable since
although unifying feature types effectively
increases possibility of sharing features, equally,
this may also increase the proportion of noisy
features. For example, consider the Wikipedia
article of “Horse” (animal), which has a category
label “livestock”; and the article “Famine”, which
has an outgoing link “livestock” (in a sentence
describing diseases that caused decline of livestock
production). By differentiating the feature types
“has_category” and “has_outlink”, the two
concepts will not be connected even if they both
have the same word “livestock” in their feature
representation. However, using a bag-of-words
representation where feature types are
undistinguished, the strength of their relatedness is
boosted by sharing this word, which may be
uninteresting in this occasion.
Compared against state-of-the-art, the
proposed method has achieved promising results.
Overall, by harnessing different knowledge sources,
the method achieves, and in many cases,
outperforms state-of-the-art. In the general domain,
it outperforms state-of-the-art on three out of four
datasets. It is worth noting that all methods based
on WordNet generally have poor performance on
the Fin153 and Fin200 datasets (Table 7). Despite
the heterogeneity in these datasets, this may also
relate to the quality of the feature space generated
with WordNet. In fact methods using Wikipedia
perform better on these datasets. With enriched
features from both knowledge sources, the
accuracies are further improved.
</bodyText>
<page confidence="0.764929">
999
</page>
<bodyText confidence="0.999981714285714">
In the biomedical domain, the proposed method
outperforms state-of-the-art on one dataset and
produces competitive results on others. Note that
all other methods exploit domain-specific
ontologies and corpora. The Ped06 best and Ped06
second methods also depend on a corpus of one
million documents. These results further confirmed
the benefits of our method: harnessing knowledge
from general-purpose knowledge sources of
limited domain coverage, it is possible to achieve
results that rival methods based on well-curated
and specially tailored domain-specific knowledge
sources. This is an encouraging finding. Although
there are abundant resources in the biomedical
domain for this type of tasks, such resources may
be scarce in other domains and are expensive to
build. However, the results suggest that the
proposed method offers a more affordable
approach that provides reasonable coverage and
quality, even if individual general knowledge
sources may be limited in themselves.
Generality of the method The proposed
method represents features extracted from different
knowledge sources in a generic manner, which
facilitates cross-source feature enrichment and
requires generic algorithm computation. As
discussed in Section 3, semantic evidence of words
and concepts may be extracted from different
knowledge sources in different ways, while
harnessed in the generic model. In contrast, other
methods using multiple knowledge sources (e.g.,
Han and Zhao, 2010; Tsang and Stevenson, 2010)
introduce algorithms that are bound to the
knowledge sources, which may limit their
adaptability and portability.
</bodyText>
<sectionHeader confidence="0.998618" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999981275862069">
This paper introduced a generic method of
harnessing different knowledge sources to compute
semantic relatedness. We have shown empirically
that different knowledge sources contain
complementary semantic evidence, which, when
combined together under a uniform model, can
improve the accuracy of SR methods. Moreover,
we have demonstrated its robustness in dealing
with knowledge sources of different quality and
coverage. Several remaining issues will be studied
in the future. First, additional knowledge sources
will be studied, particularly unstructured corpora
and domain-specific resources. The experiments
have shown that although harnessing different
knowledge sources achieved encouraging results
on biomedical datasets, they are still far from being
perfect. While it should be appreciated that the
results are obtained using only general purpose
knowledge sources, it would be interesting to
investigate whether harnessing domain specific
knowledge sources (where available) further
improves the performance. Second, different
methods of concept mapping will be studied. We
will also design methods for assessing the quality
of mapping, and analyze their correlations with the
SR methods. Third, analyses will be carried out to
uncover the differences between feature
combination and integration that have led to
different accuracies.
</bodyText>
<sectionHeader confidence="0.99567" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.945218333333333">
Part of this research has been funded under the EC
7th Framework Program, in the context of the
SmartProducts project (231204).
</bodyText>
<sectionHeader confidence="0.982554" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998256198895029">
Agirre, E., Alfonseca, E., Hall, K., Kravalova, J., Pasca,
M., Soroa, A. 2009. A Study on Similarity and
Relatedness Using Distributional and WordNet-
based Approaches. In Proceedings of NAACL’09
Batet, M., Sánchez, D., Valls, A. 2010. An ontology-
based measure to compute semantic similarity in
biomedicine. In Journal of Biomedical Informatics,
44(1), 118-125
Chen, H., Lin, M., Wei, Y. 2006. Novel association
measures using web search with double checking.
Proceedings of COLING’06-ACL’06, pp. 1009-
1016
Cilibrasi, R., Vitanyi, P. 2007. The Google Similarity
Distance. In IEEE Transactions on Knowledge and
Data Engineering. 19(3), 370-383
Finkelstein, L., Gabrilovich, E., Matias, Y., Rivlin, E.,
Solan, Z., Wolfman, G., and Ruppin, E. (2002).
Placing search in context: the concept revisited. In
ACM Transactions on Information Systems, 20 (1),
pp. 116 – 131
Gabrilovich, E., Markovitch, S. 2007. Computing
semantic relatedness using Wikipedia-based explicit
semantic analysis. In proceeding of IJCAI&apos;07
Gouws, S., Rooyen, G., Engelbrecht, H. 2010.
Measuring conceptual similarity by spreading
activation over Wikipedia’s hyperlink structure.
Proceedings of the 2nd Workshop on The People’s
Web Meets NLP: Collaboratively Constructed
Semantic Resources
1000
Halavais , A. 2008. An Analysis of Topical Coverage of
Wikipedia. Journal of Computer-Mediated
Communication, 13(2)
Han, X., Zhao, J. 2010. Structural semantic relatedness:
a knowledge-based method to named entity
disambiguation. In the 48th Annual Meeting of the
Association for Computational Linguistics.
Harrington, B. 2010. A semantic network approach to
measuring relatedness. In Proceedings of COLING’
10
Hirst, G., and St-Onge, D. 1998. Lexical chains as
representation of context for the detection and
correction malapropisms. In Christiane Fellbaum
(ed.), WordNet: An Electronic Lexical Database and
Some of Its Applications, pp. 305–332. Cambridge,
MA: The MIT Press.
Holloway, T., Bozicevic, M., Börner, K. 2007.
Analyzing and visualizing the semantic coverage of
Wikipedia and its authors. In Journal of Complexity,
Special issue on Understanding Complex Systems,
12(3), 30-40
Jiang, J. and D. Conrath. 1997. Semantic similarity
based on corpus statistics and lexical taxonomy.
Proceedings of the International Conference on
Research in Computational Linguistics, pp. 19-33
Leacock, C., Chodorow, M. 1998. Combining local
context and WordNet similarity for word sense
identification. In C. Fellbaum (Ed.), WordNet. An
Electronic Lexical Database, Chp. 11, pp. 265-283.
Lin, D. 1998. An information-theoretic definition of
similarity. Proceedings of the Fifteenth International
Conference on Machine Learning, pp. 296-304
Lord, P., Stevens, R., Brass, A., Goble, C. 2003.
Investigating semantic similarity measures across
the Gene Ontology: the relationship between
sequence and annotation. In Bioinformatics, 19(10),
pp. 1275–1283
Matsuo, Y., T. Sakaki., K., Uchiyama, M., Ishizuka.
2006. Graph-based word clustering using a web
search engine. In Proceedings of the Conference on
Empirical Methods in Natural Language Processing
(EMNLP), pp.542-550
Miller, G., Charles, W. 1991. Contextual correlates of
semantic similarity. In Language and Cognitive
Processes, 6(1): 1-28
Pan, F., Farrell, R. 2007. Computing semantic similarity
between skill statements for approximate matching.
In Proceedings of NAACL-HLT’07, pp. 572-579
Patwardhan, S., Pedersen, T. 2006. Using WordNet-
based context vectors to estimate the semantic
relatedness of concepts. Proceedings of the EACL
2006 Workshop on Making Sense of Sense:
Bringing Computational Linguistics and
Psycholinguistics Together
Pedersen, T., Pakhomov, S., Patwardhan, S., Chute, C.
2006. Measures of semantic similarity and
relatedness in the biomedical domain. Journal of
Biomedical Informatics 40(3), 288-299
Pekar, V., Staab, S. 2002. Taxonomy learning: factoring
the structure of a taxonomy into a semantic
classification decision. Proceedings of COLING’02.
pp. 786-792
Pesquita, C., Faria, D., Bastos, H., Falcão, A., Couto, F.
(2007). Evaluating GO-based Semantic Similarity
Measures. ISMB/ECCB 2007 SIG Meeting Program
Materials, International Society for Computational
Biology 2007
Petrakis, E., Varelas, G., Hliaoutakis, A., Raftopoulou,
P. 2006. Design and evaluation of semantic
similarity measures for concepts stemming from the
same or different ontologies. In 4th Workshop on
Multimedia Semantics (WMS&apos;06), pp. 44-52.
Pirro, G. 2009. A semantic similarity metric combining
features and intrinsic information content. In Data
and Knowledge Engineering, 68(11), pp. 1289-1308
Pozo A., Pazos F., Valencia, A. 2008. Defining
functional distances over gene ontology. In BMC
Bioinformatics 9, pp.50
Rada, R., Mili, H., Bicknell, E., Blettner, M. 1989.
Development and application of a metric on
semantic nets. In IEEE Transactions on Systems,
Man and Cybernetics 19(1), pp.17-30
Resnik, P. (1995). Using information content to evaluate
semantic similarity in a taxonomy. In Proceedings of
IJCAI-95, pp. 448-453
Riensche, R., Baddeley, B., Sanfilippo, A., Posse, C.,
Gopalan, B. 2007. XOA: Web-Enabled Cross-
Ontological Analytics. IEEE Congress on Services,
pp. 99-105
Rowe, M., Ciravegna, F. 2010. Disambiguating identity
web references using Web 2.0 data and semantics.
M Rowe and F Ciravegna. The Journal of Web
Semantics.
Rubenstein, H., Goodenough, J. 1965. Contextual
correlates of synonymy. In Communications of the
ACM, 8(10):627-633
Seco, N., and Hayes, T. 2004. An intrinsic information
content metric for semantic similarity in WordNet.
In Proceedings of the 16th European conference on
Artificial Intelligence
Strube, M., Ponzetto, S. 2006. WikiRelate! Computing
semantic relatedness using Wikipedia. In
Proceedings of the 21st national conference on
Artificial intelligence (AAAI)
Toral, A., Muñoz, R. 2006. A Proposal to Automatically
Build and Maintain Gazetteers for Named Entity
Recognition by using Wikipedia. In Proceedings of
Workshop on New Text, ACL’06.
Tsang, V., Stevenson, S. 2010. A graph-theoretic
framework for semantic distance. In Journal of
Computational Linguistics, 36(1).
1001
Wojtinnek, P., Pulman, S. 2011. Semantic relatedness
from automatically generated semantic networks. In
Proceedings of the Ninth International Conference
on Computational Semantics (IWCS’11)
Wu, Z. Palmer, M. 1994. Verbs semantics and lexical
selection. Proceedings of the 32nd annual meeting
on Association for Computational Linguistics, pp.
133-138
Wu, H., Su, Z., Mao, F., Olman, V., Xu, Y. 2005.
Prediction of functional modules based on
comparative genome analysis and gene ontology
application. Nucleic Acids Research, 33, pp. 2822–
2837.
Yazdani, M., Popescu-Belis, A. 2010. A random walk
framework to compute textual semantic similarity: a
unified model for three benchmark tasks. IEEE
Fourth International Conference on Semantic
Computing (ICSC), pp. 424-429
Ye, P., Peyser, B., Pan, X., Boek, J., Spencer, F., Bader,
J. 2005. Gene function prediction from congruent
synthetic lethal interactions in yeast. In Molecular
system biology
Yeh, E., Ramage, D., Manning, C., Agirre, E., Soroa, A.
2009. WikiWalk: random walks on Wikipedia for
semantic relatedness. In Proceedings of the
TextGraphs-4, Workshop on Graph-based Methods
for Natural Language Processing, ACL2009
Zesch, T., and Gurevych, I. 2007. Analysis of the
Wikipedia category graph for NLP applications. In
Proceedings of the TextGraphs-2 Workshop
(NAACL-HLT 2007), pp. 1–8
Zesch, T., Gurevych, I. 2010. Wisdom of crowds versus
wisdom of linguists: measuring the semantic
relatedness of words. In Journal of Natural
Language Engineering, 16, pp. 25-59
Zhang, Z., Gentile, A., Xia, L., Iria, J., Chapman, S.
2010. A random graph walk based approach to
compute semantic relatedness using knowledge from
Wikipedia. In Proceedings of LREC’10.
</reference>
<page confidence="0.844483">
1002
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.359978">
<title confidence="0.940633">Harnessing different knowledge sources to measure semantic relatedness under a uniform model</title>
<author confidence="0.994204">Zhang Lisa Gentile Ciravegna</author>
<affiliation confidence="0.999776">Department of Computer Science, University of</affiliation>
<address confidence="0.93753">211 Portobello, Regent Court Sheffield, S1 4DP</address>
<abstract confidence="0.961609565217391">z.zhang@dcs.shef.ac. uk a.l.gentile@dcs.shef .ac.uk f.ciravegna@dcs.shef .ac.uk Abstract Measuring semantic relatedness between words or concepts is a crucial process to many Natural Language Processing tasks. Exiting methods exploit semantic evidence from a single knowledge source, and are predominantly evaluated only in the general domain. This paper introduces a method of harnessing different knowledge sources under a uniform model for measuring semantic relatedness between words or concepts. Using Wikipedia and WordNet as examples, and evaluated in both the general and biomedical domains, it successfully combines strengths from both knowledge sources and outperforms stateof-the-art on many datasets.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Agirre</author>
<author>E Alfonseca</author>
<author>K Hall</author>
<author>J Kravalova</author>
<author>M Pasca</author>
<author>A Soroa</author>
</authors>
<title>A Study on Similarity and Relatedness Using Distributional and WordNetbased Approaches.</title>
<date>2009</date>
<booktitle>In Proceedings of NAACL’09</booktitle>
<contexts>
<context position="3561" citStr="Agirre et al., 2009" startWordPosition="520" endWordPosition="523">ddresses these issues by proposing a generic and uniform model for computing SR between words or concepts using multiple knowledge sources, and evaluating the proposed method in both general and specific domains. The method combines and integrates semantic evidence of words or concepts extracted from any knowledge source in a generic graph representation, with which the SR between concepts or words is computed. Using two of the most popular general-domain knowledge sources, 1 http://www.geneontology.org/, last retrieved in Mar. 2011 991 Wikipedia and WordNet as examples, the method resources (Agirre et al., 2009; Gabrilovich and is evaluated on 7 benchmarking datasets, including Markovitch, 2007; Gouws et al., 2010; Zesch and three datasets from the biomedical domain and Gurevych, 2007; Zhang et al., 2010). Hybrid four from the general domain. It has achieved methods combine different purebred methods in excellent results: compared to the baselines that certain ways. For example Riensche et al. (2007) use each single knowledge sources, combining employ both an IC based method (Resnik, 1995) both knowledge sources has improved the accuracy and a statistical method (cosine vector similarity) on all dat</context>
<context position="7849" citStr="Agirre et al., 2009" startWordPosition="1171" endWordPosition="1174">eir distribution of and (semi-)structured encyclopedic resources such contextual evidence. This can be formalized as co- as Wikipedia. WordNet has been used in earlier occurrence statistics collected from unstructured studies (Hirst and St-Onge, 1998; Jiang and documents (Chen et al., 2006; Cilibrasi and Conrath, 1997; Lin, 1998; Leacock and Chodorow Vitanyi, 2007; Matsuo et al., 2006), or 1998; Resnik, 1995; Seco et al., 2004; Wu and distributional concept or word vectors with Palmer, 1994) and is still a preferred knowledge features extracted from either unstructured source in recent works (Agirre et al., 2009). documents (Harrington, 2010; Wojtinnek and However, its effectiveness may be hindered by its Pulman, 2011) or (semi-)structured knowledge lack of coverage of specialized lexicons and 992 domain specific concepts (Strube and Ponzetto, 2006; Zhang et al., 2010). Wikipedia and Wiktionary are collaboratively maintained knowledge sources and therefore may overcome this limitation. Wikipedia in particular, is found to have reasonable coverage of many domains (Holloway et al., 2007; Halavais, 2008). It has become increasingly popular in SR studies recently. However, research (Zesch and Gurevych, 20</context>
<context position="16112" citStr="Agirre et al., 2009" startWordPosition="2468" endWordPosition="2471">extract ten features from WordNet: hypernyms, hyponyms, meronyms, holonyms, synonyms, antonyms, attributes, “see also” words, “related” words, and gloss. These are also represented in the same way as in Figure 1. With unstructured sources, contextual words can be used as features. Alternatively, if a lexical network is extracted, features may be extracted in a similar way to those of WordNet. Additionally, with WordNet and Wikipedia, we also propose several intra-resource feature merging strategies to study the effect of feature diversification. This is because, while some approaches (such as Agirre et al., 2009; Harrington, 2010; Yeh et al., 2009) do not distinguish different feature types in graph construction, or adopt a bag-of-words feature representation (such as Zesch and Gurevych, 2010), others (such as Yazdani and Popescu-Belis, 2010; Zhang et al., 2010) have used differentiated 994 feature types and weights in their model. We therefore carry out studies to investigate this issue. Specifically, for the original four Wikipedia features, we create a bag-of-words feature that simply merges all feature types (i.e., all edges in Figure 1 will have the same label). For the original ten WordNet feat</context>
<context position="31437" citStr="Agirre et al., 2009" startWordPosition="4946" endWordPosition="4949"> which wk-4F+wn-4F, Combination (Table 4) slightly reduced the accuracy obtained with wk-4F (Table 3) only. The large proportion of uncovered word pairs using WordNet is due to its lack of coverage of specialized lexicons, and sparser semantic content. For example, of all 115 distinctive terms in the Ped30 and MeSH36 datasets, 30% are not included in WordNet. And of all 447 distinctive words in all general domain datasets, only 69% have multiple synonyms. Features such as attributes and “see also” are present for less than 20 words. This is the reason that some approaches using WordNet (e.g., Agirre et al., 2009) require a graph of all WordNet lexicons to be built, thus intermediate words may “bridge” input words even if they do not connect directly by their features. Nevertheless, the improvement in accuracy and 100% coverage after harnessing both knowledge sources suggests that they complement each other well. On one hand, Wikipedia brings its strength in domain and content coverage; on the other hand, WordNet brings useful semantic evidences for words that are covered. Concept mapping and feature enrichment methods While the set overlap based method for cross-source concept mapping using the refere</context>
</contexts>
<marker>Agirre, Alfonseca, Hall, Kravalova, Pasca, Soroa, 2009</marker>
<rawString>Agirre, E., Alfonseca, E., Hall, K., Kravalova, J., Pasca, M., Soroa, A. 2009. A Study on Similarity and Relatedness Using Distributional and WordNetbased Approaches. In Proceedings of NAACL’09</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Batet</author>
<author>D Sánchez</author>
<author>A Valls</author>
</authors>
<title>An ontologybased measure to compute semantic similarity in biomedicine.</title>
<date>2010</date>
<journal>In Journal of Biomedical Informatics,</journal>
<volume>44</volume>
<issue>1</issue>
<pages>118--125</pages>
<contexts>
<context position="6632" citStr="Batet et al., 2010" startWordPosition="990" endWordPosition="993">t studies (Harrington, 2010; al., 1989; Wu and Palmer, 1994) measure SR Pozo et al., 2008; Wojtinnek and Pulman, 2011) between words or concepts as a function of their propose to pre-process a corpus to learn a semantic distance in a semantic network, usually calculated network, with which SR is computed. This creates based on the path connecting the words or concepts high pre-processing cost; also, the choice of corpus by certain semantic (typically is-a) links. IC based and its size often have a direct correlation with the methods (Jiang and Conrath, 1997; Lin, 1998; accuracy of SR methods (Batet et al., 2010). Pirro et al., 2009; Resnik, 1995; Seco et al., 2004) (Semi-)Structured knowledge sources on the assess relatedness between words or concepts by other hand, organize semantic knowledge about the amount of information they share, usually concepts and words explicitly and interlink them determined by a higher level concept that with semantic relations. They have been popular subsumes both concepts in a taxonomic structure. choices in the studies of SR, and they include Statistical methods measure relatedness between lexical resources such as WordNet, Wiktionary, words or concepts based on their</context>
</contexts>
<marker>Batet, Sánchez, Valls, 2010</marker>
<rawString>Batet, M., Sánchez, D., Valls, A. 2010. An ontologybased measure to compute semantic similarity in biomedicine. In Journal of Biomedical Informatics, 44(1), 118-125</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Chen</author>
<author>M Lin</author>
<author>Y Wei</author>
</authors>
<title>Novel association measures using web search with double checking.</title>
<date>2006</date>
<booktitle>Proceedings of COLING’06-ACL’06,</booktitle>
<pages>1009--1016</pages>
<contexts>
<context position="7519" citStr="Chen et al., 2006" startWordPosition="1119" endWordPosition="1122">d interlink them determined by a higher level concept that with semantic relations. They have been popular subsumes both concepts in a taxonomic structure. choices in the studies of SR, and they include Statistical methods measure relatedness between lexical resources such as WordNet, Wiktionary, words or concepts based on their distribution of and (semi-)structured encyclopedic resources such contextual evidence. This can be formalized as co- as Wikipedia. WordNet has been used in earlier occurrence statistics collected from unstructured studies (Hirst and St-Onge, 1998; Jiang and documents (Chen et al., 2006; Cilibrasi and Conrath, 1997; Lin, 1998; Leacock and Chodorow Vitanyi, 2007; Matsuo et al., 2006), or 1998; Resnik, 1995; Seco et al., 2004; Wu and distributional concept or word vectors with Palmer, 1994) and is still a preferred knowledge features extracted from either unstructured source in recent works (Agirre et al., 2009). documents (Harrington, 2010; Wojtinnek and However, its effectiveness may be hindered by its Pulman, 2011) or (semi-)structured knowledge lack of coverage of specialized lexicons and 992 domain specific concepts (Strube and Ponzetto, 2006; Zhang et al., 2010). Wikiped</context>
</contexts>
<marker>Chen, Lin, Wei, 2006</marker>
<rawString>Chen, H., Lin, M., Wei, Y. 2006. Novel association measures using web search with double checking. Proceedings of COLING’06-ACL’06, pp. 1009-1016</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Cilibrasi</author>
<author>P Vitanyi</author>
</authors>
<title>The Google Similarity Distance. In</title>
<date>2007</date>
<journal>IEEE Transactions on Knowledge and Data Engineering.</journal>
<volume>19</volume>
<issue>3</issue>
<pages>370--383</pages>
<contexts>
<context position="5555" citStr="Cilibrasi and Vitanyi 2007" startWordPosition="823" endWordPosition="826"> this paper is organized as Computing SR requires background knowledge follows. Section 2 discusses related work; Section about concepts or words, which can be extracted 3 presents the proposed method; Section 4 from unstructured corpora, semi-structured and describes the experiments and evaluation; Section structured knowledge resources. Unstructured 5 discusses results and findings; Section 6 corpora are easier to create and cheaper to concludes this paper. maintain, however, semantic relations between 2 Related work words or concepts are implicit. Methods (Chen et 2.1 SR methods al., 2006; Cilibrasi and Vitanyi 2007; Matsuo et al., Methods for computing SR can be classified into 2006) that exploit unstructured corpora typically path based, Information Content (IC) based, depend on distributional statistics, and thus may statistical and hybrid methods. Path based ignore important semantic evidences present in methods (Hirst and St-Onge, 1998; Leacock and (semi-)structured knowledge sources (Pan and Chodorow, 1998; Pekar and Staab, 2002; Rada et Farrell, 2007). Recent studies (Harrington, 2010; al., 1989; Wu and Palmer, 1994) measure SR Pozo et al., 2008; Wojtinnek and Pulman, 2011) between words or concep</context>
</contexts>
<marker>Cilibrasi, Vitanyi, 2007</marker>
<rawString>Cilibrasi, R., Vitanyi, P. 2007. The Google Similarity Distance. In IEEE Transactions on Knowledge and Data Engineering. 19(3), 370-383</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Finkelstein</author>
<author>E Gabrilovich</author>
<author>Y Matias</author>
<author>E Rivlin</author>
<author>Z Solan</author>
<author>G Wolfman</author>
<author>E Ruppin</author>
</authors>
<title>Placing search in context: the concept revisited.</title>
<date>2002</date>
<journal>In ACM Transactions on Information Systems,</journal>
<volume>20</volume>
<issue>1</issue>
<pages>116--131</pages>
<contexts>
<context position="1424" citStr="Finkelstein et al., 2002" startWordPosition="194" endWordPosition="197"> both the general and biomedical domains, it successfully combines strengths from both knowledge sources and outperforms stateof-the-art on many datasets. 1 Introduction Semantic relatedness (SR) measures how much two (strings of) words or concepts are related by encompassing all kinds of relations between them (Strube and Ponzetto, 2006). It is more general than semantic similarity. SR is often an important pre-processing step to many complex Natural Language Processing (NLP) tasks, such as Word Sense Disambiguation (Leacock and Chodorow, 1998; Han and Zhao, 2010), and information retrieval (Finkelstein et al., 2002). In the biomedical domain, SR is an important technique for discovering gene functions and interactions (Wu et al., 2005; Ye et al., 2005). There is an abundant literature on measuring SR between words or concepts. Typically, these methods extract semantic evidence of words and concepts from a background knowledge source, with which their relatedness is assessed. The knowledge sources can be unstructured documents or (semi-)structured resources such as Wikipedia, WordNet, and domain specific ontologies (e.g., the Gene Ontology1). In this paper, we identify two issues that have not been addres</context>
<context position="24567" citStr="Finkelstein et al. (2002)" startWordPosition="3808" endWordPosition="3811"> proposed by Patwardhan and Pedersen (2006) in their method based on second-order context vectors. The final SR between the input word pair is the maximum pair-wise concept SR. 4 Experiment and evaluation We evaluate the method based on correlation against human judgment (gold standard) on seven benchmarking datasets covering both general and technical domains. These include four general domain datasets: the Rubenstein and Goodenough (1965) dataset containing 65 pairs of nouns (RG65); the Miller and Charles (1991) dataset that is a subset of the RG-65 dataset and contains 30 pairs (MC30); the Finkelstein et al. (2002) dataset with 353 pairs of words, including nouns, verbs, adjectives, as well as named entities. This contains two subsets, a set of 153 pairs (Fin153) and a set of 200 (Fin200) pairs each annotated by a different groups of annotators. Zesch and Gurevych (2010) show largely varying Inter-Annotator-Agreement (IAA) between the two sets (Table 1), and argue that they should be treated as separate datasets. Three biomedical datasets are selected to evaluate domain-specific performance of the proposed method. These include a set of 36 MeSH term pairs in Petrakis et al. (2006) (MeSH36), 30 pairs of </context>
</contexts>
<marker>Finkelstein, Gabrilovich, Matias, Rivlin, Solan, Wolfman, Ruppin, 2002</marker>
<rawString>Finkelstein, L., Gabrilovich, E., Matias, Y., Rivlin, E., Solan, Z., Wolfman, G., and Ruppin, E. (2002). Placing search in context: the concept revisited. In ACM Transactions on Information Systems, 20 (1), pp. 116 – 131</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Gabrilovich</author>
<author>S Markovitch</author>
</authors>
<title>Computing semantic relatedness using Wikipedia-based explicit semantic analysis.</title>
<date>2007</date>
<booktitle>In proceeding of IJCAI&apos;07</booktitle>
<contexts>
<context position="29863" citStr="Gabrilovich and Markovitch (2007)" startWordPosition="4706" endWordPosition="4709"> in Tables 7 and 8. For all cases, a p-value of less than 0.001 is obtained, which indicates that correlation values are statistically significant. Tables 7 and 8 compare our method against stateof-the-art. For Table 8, figures for other state-ofthe-art systems can be found in corresponding publications; while we only list the best performing systems for comparison. 3 Rada (1989) (Rad89); Leacock and Chodorow (1998) (LC98); Wu and Palmer (1994) (WP04); Hirst and St-Onge (1998) (HS98); Resnik (1995) (Res95); Jiang and Conrath (1997) (JC97); Lin (1998) (Lin98); Zesch and Gurevych (2007) (ZG07); Gabrilovich and Markovitch (2007) (GM07); Zhang et al. (2010) (Zha10) 4 Petrakis et al. (2006) (Pet06); Pedersen et al. (2006) (Ped06). Original participating systems can be found in these works. 998 5 Discussion Single v.s. multiple knowledge sources As shown in Table 6, considering the best performances across all feature enrichment strategies and feature sets, the proposed method successfully harnessed different knowledge sources and improved over the baselines using single knowledge sources by 0.02 ~ 0.11. The biggest improvement (0.11) is on a domain-specific dataset, on which the method based on single knowledge source </context>
</contexts>
<marker>Gabrilovich, Markovitch, 2007</marker>
<rawString>Gabrilovich, E., Markovitch, S. 2007. Computing semantic relatedness using Wikipedia-based explicit semantic analysis. In proceeding of IJCAI&apos;07</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Gouws</author>
<author>G Rooyen</author>
<author>H Engelbrecht</author>
</authors>
<title>Measuring conceptual similarity by spreading activation over Wikipedia’s hyperlink structure.</title>
<date>2010</date>
<booktitle>Proceedings of the 2nd Workshop on The People’s Web Meets NLP: Collaboratively Constructed Semantic Resources</booktitle>
<pages>1000</pages>
<contexts>
<context position="3666" citStr="Gouws et al., 2010" startWordPosition="535" endWordPosition="538">using multiple knowledge sources, and evaluating the proposed method in both general and specific domains. The method combines and integrates semantic evidence of words or concepts extracted from any knowledge source in a generic graph representation, with which the SR between concepts or words is computed. Using two of the most popular general-domain knowledge sources, 1 http://www.geneontology.org/, last retrieved in Mar. 2011 991 Wikipedia and WordNet as examples, the method resources (Agirre et al., 2009; Gabrilovich and is evaluated on 7 benchmarking datasets, including Markovitch, 2007; Gouws et al., 2010; Zesch and three datasets from the biomedical domain and Gurevych, 2007; Zhang et al., 2010). Hybrid four from the general domain. It has achieved methods combine different purebred methods in excellent results: compared to the baselines that certain ways. For example Riensche et al. (2007) use each single knowledge sources, combining employ both an IC based method (Resnik, 1995) both knowledge sources has improved the accuracy and a statistical method (cosine vector similarity) on all datasets by 2~11%; compared to state-of- in their study. Pozo et al. (2008) derive a taxonomy the-art on the</context>
</contexts>
<marker>Gouws, Rooyen, Engelbrecht, 2010</marker>
<rawString>Gouws, S., Rooyen, G., Engelbrecht, H. 2010. Measuring conceptual similarity by spreading activation over Wikipedia’s hyperlink structure. Proceedings of the 2nd Workshop on The People’s Web Meets NLP: Collaboratively Constructed Semantic Resources 1000</rawString>
</citation>
<citation valid="true">
<authors>
<author>Halavais</author>
</authors>
<title>An Analysis of Topical Coverage of Wikipedia.</title>
<date>2008</date>
<journal>Journal of Computer-Mediated Communication,</journal>
<volume>13</volume>
<issue>2</issue>
<contexts>
<context position="8347" citStr="Halavais, 2008" startWordPosition="1243" endWordPosition="1244"> still a preferred knowledge features extracted from either unstructured source in recent works (Agirre et al., 2009). documents (Harrington, 2010; Wojtinnek and However, its effectiveness may be hindered by its Pulman, 2011) or (semi-)structured knowledge lack of coverage of specialized lexicons and 992 domain specific concepts (Strube and Ponzetto, 2006; Zhang et al., 2010). Wikipedia and Wiktionary are collaboratively maintained knowledge sources and therefore may overcome this limitation. Wikipedia in particular, is found to have reasonable coverage of many domains (Holloway et al., 2007; Halavais, 2008). It has become increasingly popular in SR studies recently. However, research (Zesch and Gurevych, 2010) have shown that methods based on Wikipedia have no clear advantage over WordNet-based methods on some general domain datasets in terms of accuracy, while Zhang et al. (2010) argue that different knowledge sources may complement each other, and SR methods may benefit from harnessing different knowledge sources. Several studies (Lord et al., 2003; Pedersen et al., 2006; Petrakis et al., 2006; Pozo et al., 2008) have adapted state-of-the-art to domain specific knowledge sources (e.g., the Gen</context>
</contexts>
<marker>Halavais, 2008</marker>
<rawString>Halavais , A. 2008. An Analysis of Topical Coverage of Wikipedia. Journal of Computer-Mediated Communication, 13(2)</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Han</author>
<author>J Zhao</author>
</authors>
<title>Structural semantic relatedness: a knowledge-based method to named entity disambiguation.</title>
<date>2010</date>
<booktitle>In the 48th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="1370" citStr="Han and Zhao, 2010" startWordPosition="187" endWordPosition="190">ipedia and WordNet as examples, and evaluated in both the general and biomedical domains, it successfully combines strengths from both knowledge sources and outperforms stateof-the-art on many datasets. 1 Introduction Semantic relatedness (SR) measures how much two (strings of) words or concepts are related by encompassing all kinds of relations between them (Strube and Ponzetto, 2006). It is more general than semantic similarity. SR is often an important pre-processing step to many complex Natural Language Processing (NLP) tasks, such as Word Sense Disambiguation (Leacock and Chodorow, 1998; Han and Zhao, 2010), and information retrieval (Finkelstein et al., 2002). In the biomedical domain, SR is an important technique for discovering gene functions and interactions (Wu et al., 2005; Ye et al., 2005). There is an abundant literature on measuring SR between words or concepts. Typically, these methods extract semantic evidence of words and concepts from a background knowledge source, with which their relatedness is assessed. The knowledge sources can be unstructured documents or (semi-)structured resources such as Wikipedia, WordNet, and domain specific ontologies (e.g., the Gene Ontology1). In this p</context>
<context position="4639" citStr="Han and Zhao (2010)" startWordPosition="689" endWordPosition="692">C based method (Resnik, 1995) both knowledge sources has improved the accuracy and a statistical method (cosine vector similarity) on all datasets by 2~11%; compared to state-of- in their study. Pozo et al. (2008) derive a taxonomy the-art on the general domain datasets, the method of terms from unstructured documents by applying achieves the best results on three datasets; and on hierarchical clustering based on corpus statistics, the other three biomedical datasets, it obtains the then apply path based method on this taxonomy to best result in one case; and second and third best compute SR. Han and Zhao (2010) use one IC results on the other two among eight participating based method and two statistical methods to methods, where all other competitors exploit some compute SR, then derive an aggregated score. domain-specific knowledge sources. 2.2 SR knowledge sources and domains The remainder of this paper is organized as Computing SR requires background knowledge follows. Section 2 discusses related work; Section about concepts or words, which can be extracted 3 presents the proposed method; Section 4 from unstructured corpora, semi-structured and describes the experiments and evaluation; Section s</context>
<context position="9314" citStr="Han and Zhao (2010)" startWordPosition="1387" endWordPosition="1390">d SR methods may benefit from harnessing different knowledge sources. Several studies (Lord et al., 2003; Pedersen et al., 2006; Petrakis et al., 2006; Pozo et al., 2008) have adapted state-of-the-art to domain specific knowledge sources (e.g., the Gene Ontology, the MeSH2) and evaluated them therein. Despite these efforts, a large proportion of state-of-the-art is still only evaluated in the general domain. 2.3 SR methods similar to this work Few works have attempted at combining different knowledge sources in SR studies, especially (semi)structured knowledge sources. The closest studies are Han and Zhao (2010) and Tsang and Stevenson (2010). Han and Zhao firstly compute SR between words using three state-of-the-art SR methods separately. Next, one score is chosen subject to an arbitrary preference order, and used to create a connected graph of weighted edges between words. A recursive function is then applied to the graph to compute final SR scores between words. Essentially, each SR method is applied in isolation and features from different sources are used separately with each distinctive method. Although this retains advantages of each method, the limitations of them are also combined. Tsang and</context>
<context position="36150" citStr="Han and Zhao, 2010" startWordPosition="5634" endWordPosition="5637">able approach that provides reasonable coverage and quality, even if individual general knowledge sources may be limited in themselves. Generality of the method The proposed method represents features extracted from different knowledge sources in a generic manner, which facilitates cross-source feature enrichment and requires generic algorithm computation. As discussed in Section 3, semantic evidence of words and concepts may be extracted from different knowledge sources in different ways, while harnessed in the generic model. In contrast, other methods using multiple knowledge sources (e.g., Han and Zhao, 2010; Tsang and Stevenson, 2010) introduce algorithms that are bound to the knowledge sources, which may limit their adaptability and portability. 6 Conclusion This paper introduced a generic method of harnessing different knowledge sources to compute semantic relatedness. We have shown empirically that different knowledge sources contain complementary semantic evidence, which, when combined together under a uniform model, can improve the accuracy of SR methods. Moreover, we have demonstrated its robustness in dealing with knowledge sources of different quality and coverage. Several remaining issu</context>
</contexts>
<marker>Han, Zhao, 2010</marker>
<rawString>Han, X., Zhao, J. 2010. Structural semantic relatedness: a knowledge-based method to named entity disambiguation. In the 48th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Harrington</author>
</authors>
<title>A semantic network approach to measuring relatedness.</title>
<date>2010</date>
<booktitle>In Proceedings of COLING’</booktitle>
<volume>10</volume>
<contexts>
<context position="6040" citStr="Harrington, 2010" startWordPosition="893" endWordPosition="894">ations between 2 Related work words or concepts are implicit. Methods (Chen et 2.1 SR methods al., 2006; Cilibrasi and Vitanyi 2007; Matsuo et al., Methods for computing SR can be classified into 2006) that exploit unstructured corpora typically path based, Information Content (IC) based, depend on distributional statistics, and thus may statistical and hybrid methods. Path based ignore important semantic evidences present in methods (Hirst and St-Onge, 1998; Leacock and (semi-)structured knowledge sources (Pan and Chodorow, 1998; Pekar and Staab, 2002; Rada et Farrell, 2007). Recent studies (Harrington, 2010; al., 1989; Wu and Palmer, 1994) measure SR Pozo et al., 2008; Wojtinnek and Pulman, 2011) between words or concepts as a function of their propose to pre-process a corpus to learn a semantic distance in a semantic network, usually calculated network, with which SR is computed. This creates based on the path connecting the words or concepts high pre-processing cost; also, the choice of corpus by certain semantic (typically is-a) links. IC based and its size often have a direct correlation with the methods (Jiang and Conrath, 1997; Lin, 1998; accuracy of SR methods (Batet et al., 2010). Pirro </context>
<context position="7878" citStr="Harrington, 2010" startWordPosition="1176" endWordPosition="1177">ructured encyclopedic resources such contextual evidence. This can be formalized as co- as Wikipedia. WordNet has been used in earlier occurrence statistics collected from unstructured studies (Hirst and St-Onge, 1998; Jiang and documents (Chen et al., 2006; Cilibrasi and Conrath, 1997; Lin, 1998; Leacock and Chodorow Vitanyi, 2007; Matsuo et al., 2006), or 1998; Resnik, 1995; Seco et al., 2004; Wu and distributional concept or word vectors with Palmer, 1994) and is still a preferred knowledge features extracted from either unstructured source in recent works (Agirre et al., 2009). documents (Harrington, 2010; Wojtinnek and However, its effectiveness may be hindered by its Pulman, 2011) or (semi-)structured knowledge lack of coverage of specialized lexicons and 992 domain specific concepts (Strube and Ponzetto, 2006; Zhang et al., 2010). Wikipedia and Wiktionary are collaboratively maintained knowledge sources and therefore may overcome this limitation. Wikipedia in particular, is found to have reasonable coverage of many domains (Holloway et al., 2007; Halavais, 2008). It has become increasingly popular in SR studies recently. However, research (Zesch and Gurevych, 2010) have shown that methods b</context>
<context position="14447" citStr="Harrington (2010)" startWordPosition="2210" endWordPosition="2211"> to a concept relevant to w, but not necessarily a candidate sense of w. Thirdly, if no pages are returned for w, we search for the most relevant page using w as keyword(s) in an inverted index of all Wikipedia pages (e.g., via search engines). We denote concepts retrieved from Wikipedia as . For unstructured sources such as documents, a simple approach could be defining a word context as a text passage around each occurrence of w, and grouping similar contexts of w as representation of its underlying meanings, or concepts. Alternatively, more complex approaches such as Pozo et al. (2008) and Harrington (2010) may be applied to extract a lexical network of words, whereby similar methods to WordNet can be applied. 3.2 Feature extraction and representation Next, for each concept identified from a knowledge source, features are extracted from their corresponding contexts. In our case, for each , we follow the work by Zhang et al. (2010) to extract four types of features from their corresponding Wikipedia pages. Figure 1 shows an example representation of a concept and its Wikipedia features: • Words from page titles and redirection links (can be considered as synonyms) • Words from categories, used as</context>
<context position="16130" citStr="Harrington, 2010" startWordPosition="2472" endWordPosition="2473">from WordNet: hypernyms, hyponyms, meronyms, holonyms, synonyms, antonyms, attributes, “see also” words, “related” words, and gloss. These are also represented in the same way as in Figure 1. With unstructured sources, contextual words can be used as features. Alternatively, if a lexical network is extracted, features may be extracted in a similar way to those of WordNet. Additionally, with WordNet and Wikipedia, we also propose several intra-resource feature merging strategies to study the effect of feature diversification. This is because, while some approaches (such as Agirre et al., 2009; Harrington, 2010; Yeh et al., 2009) do not distinguish different feature types in graph construction, or adopt a bag-of-words feature representation (such as Zesch and Gurevych, 2010), others (such as Yazdani and Popescu-Belis, 2010; Zhang et al., 2010) have used differentiated 994 feature types and weights in their model. We therefore carry out studies to investigate this issue. Specifically, for the original four Wikipedia features, we create a bag-of-words feature that simply merges all feature types (i.e., all edges in Figure 1 will have the same label). For the original ten WordNet features, we propose t</context>
</contexts>
<marker>Harrington, 2010</marker>
<rawString>Harrington, B. 2010. A semantic network approach to measuring relatedness. In Proceedings of COLING’ 10</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Hirst</author>
<author>D St-Onge</author>
</authors>
<title>Lexical chains as representation of context for the detection and correction malapropisms.</title>
<date>1998</date>
<booktitle>In Christiane Fellbaum (ed.), WordNet: An Electronic Lexical Database and Some of Its Applications,</booktitle>
<pages>305--332</pages>
<publisher>The MIT Press.</publisher>
<location>Cambridge, MA:</location>
<contexts>
<context position="5886" citStr="Hirst and St-Onge, 1998" startWordPosition="870" endWordPosition="873">urces. Unstructured 5 discusses results and findings; Section 6 corpora are easier to create and cheaper to concludes this paper. maintain, however, semantic relations between 2 Related work words or concepts are implicit. Methods (Chen et 2.1 SR methods al., 2006; Cilibrasi and Vitanyi 2007; Matsuo et al., Methods for computing SR can be classified into 2006) that exploit unstructured corpora typically path based, Information Content (IC) based, depend on distributional statistics, and thus may statistical and hybrid methods. Path based ignore important semantic evidences present in methods (Hirst and St-Onge, 1998; Leacock and (semi-)structured knowledge sources (Pan and Chodorow, 1998; Pekar and Staab, 2002; Rada et Farrell, 2007). Recent studies (Harrington, 2010; al., 1989; Wu and Palmer, 1994) measure SR Pozo et al., 2008; Wojtinnek and Pulman, 2011) between words or concepts as a function of their propose to pre-process a corpus to learn a semantic distance in a semantic network, usually calculated network, with which SR is computed. This creates based on the path connecting the words or concepts high pre-processing cost; also, the choice of corpus by certain semantic (typically is-a) links. IC ba</context>
<context position="7479" citStr="Hirst and St-Onge, 1998" startWordPosition="1112" endWordPosition="1115">hare, usually concepts and words explicitly and interlink them determined by a higher level concept that with semantic relations. They have been popular subsumes both concepts in a taxonomic structure. choices in the studies of SR, and they include Statistical methods measure relatedness between lexical resources such as WordNet, Wiktionary, words or concepts based on their distribution of and (semi-)structured encyclopedic resources such contextual evidence. This can be formalized as co- as Wikipedia. WordNet has been used in earlier occurrence statistics collected from unstructured studies (Hirst and St-Onge, 1998; Jiang and documents (Chen et al., 2006; Cilibrasi and Conrath, 1997; Lin, 1998; Leacock and Chodorow Vitanyi, 2007; Matsuo et al., 2006), or 1998; Resnik, 1995; Seco et al., 2004; Wu and distributional concept or word vectors with Palmer, 1994) and is still a preferred knowledge features extracted from either unstructured source in recent works (Agirre et al., 2009). documents (Harrington, 2010; Wojtinnek and However, its effectiveness may be hindered by its Pulman, 2011) or (semi-)structured knowledge lack of coverage of specialized lexicons and 992 domain specific concepts (Strube and Ponz</context>
<context position="29711" citStr="Hirst and St-Onge (1998)" startWordPosition="4685" endWordPosition="4688">e. Therefore, we measure the statistical significance of correlation by computing the pvalue for the correlation values reported for our system in Tables 7 and 8. For all cases, a p-value of less than 0.001 is obtained, which indicates that correlation values are statistically significant. Tables 7 and 8 compare our method against stateof-the-art. For Table 8, figures for other state-ofthe-art systems can be found in corresponding publications; while we only list the best performing systems for comparison. 3 Rada (1989) (Rad89); Leacock and Chodorow (1998) (LC98); Wu and Palmer (1994) (WP04); Hirst and St-Onge (1998) (HS98); Resnik (1995) (Res95); Jiang and Conrath (1997) (JC97); Lin (1998) (Lin98); Zesch and Gurevych (2007) (ZG07); Gabrilovich and Markovitch (2007) (GM07); Zhang et al. (2010) (Zha10) 4 Petrakis et al. (2006) (Pet06); Pedersen et al. (2006) (Ped06). Original participating systems can be found in these works. 998 5 Discussion Single v.s. multiple knowledge sources As shown in Table 6, considering the best performances across all feature enrichment strategies and feature sets, the proposed method successfully harnessed different knowledge sources and improved over the baselines using single</context>
</contexts>
<marker>Hirst, St-Onge, 1998</marker>
<rawString>Hirst, G., and St-Onge, D. 1998. Lexical chains as representation of context for the detection and correction malapropisms. In Christiane Fellbaum (ed.), WordNet: An Electronic Lexical Database and Some of Its Applications, pp. 305–332. Cambridge, MA: The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Holloway</author>
<author>M Bozicevic</author>
<author>K Börner</author>
</authors>
<title>Analyzing and visualizing the semantic coverage of Wikipedia and its authors.</title>
<date>2007</date>
<journal>In Journal of Complexity, Special issue on Understanding Complex Systems,</journal>
<volume>12</volume>
<issue>3</issue>
<pages>30--40</pages>
<contexts>
<context position="8330" citStr="Holloway et al., 2007" startWordPosition="1239" endWordPosition="1242">th Palmer, 1994) and is still a preferred knowledge features extracted from either unstructured source in recent works (Agirre et al., 2009). documents (Harrington, 2010; Wojtinnek and However, its effectiveness may be hindered by its Pulman, 2011) or (semi-)structured knowledge lack of coverage of specialized lexicons and 992 domain specific concepts (Strube and Ponzetto, 2006; Zhang et al., 2010). Wikipedia and Wiktionary are collaboratively maintained knowledge sources and therefore may overcome this limitation. Wikipedia in particular, is found to have reasonable coverage of many domains (Holloway et al., 2007; Halavais, 2008). It has become increasingly popular in SR studies recently. However, research (Zesch and Gurevych, 2010) have shown that methods based on Wikipedia have no clear advantage over WordNet-based methods on some general domain datasets in terms of accuracy, while Zhang et al. (2010) argue that different knowledge sources may complement each other, and SR methods may benefit from harnessing different knowledge sources. Several studies (Lord et al., 2003; Pedersen et al., 2006; Petrakis et al., 2006; Pozo et al., 2008) have adapted state-of-the-art to domain specific knowledge sourc</context>
</contexts>
<marker>Holloway, Bozicevic, Börner, 2007</marker>
<rawString>Holloway, T., Bozicevic, M., Börner, K. 2007. Analyzing and visualizing the semantic coverage of Wikipedia and its authors. In Journal of Complexity, Special issue on Understanding Complex Systems, 12(3), 30-40</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Jiang</author>
<author>D Conrath</author>
</authors>
<title>Semantic similarity based on corpus statistics and lexical taxonomy.</title>
<date>1997</date>
<booktitle>Proceedings of the International Conference on Research in Computational Linguistics,</booktitle>
<pages>19--33</pages>
<contexts>
<context position="6576" citStr="Jiang and Conrath, 1997" startWordPosition="980" endWordPosition="983">, 1998; Pekar and Staab, 2002; Rada et Farrell, 2007). Recent studies (Harrington, 2010; al., 1989; Wu and Palmer, 1994) measure SR Pozo et al., 2008; Wojtinnek and Pulman, 2011) between words or concepts as a function of their propose to pre-process a corpus to learn a semantic distance in a semantic network, usually calculated network, with which SR is computed. This creates based on the path connecting the words or concepts high pre-processing cost; also, the choice of corpus by certain semantic (typically is-a) links. IC based and its size often have a direct correlation with the methods (Jiang and Conrath, 1997; Lin, 1998; accuracy of SR methods (Batet et al., 2010). Pirro et al., 2009; Resnik, 1995; Seco et al., 2004) (Semi-)Structured knowledge sources on the assess relatedness between words or concepts by other hand, organize semantic knowledge about the amount of information they share, usually concepts and words explicitly and interlink them determined by a higher level concept that with semantic relations. They have been popular subsumes both concepts in a taxonomic structure. choices in the studies of SR, and they include Statistical methods measure relatedness between lexical resources such </context>
<context position="29767" citStr="Jiang and Conrath (1997)" startWordPosition="4693" endWordPosition="4696"> correlation by computing the pvalue for the correlation values reported for our system in Tables 7 and 8. For all cases, a p-value of less than 0.001 is obtained, which indicates that correlation values are statistically significant. Tables 7 and 8 compare our method against stateof-the-art. For Table 8, figures for other state-ofthe-art systems can be found in corresponding publications; while we only list the best performing systems for comparison. 3 Rada (1989) (Rad89); Leacock and Chodorow (1998) (LC98); Wu and Palmer (1994) (WP04); Hirst and St-Onge (1998) (HS98); Resnik (1995) (Res95); Jiang and Conrath (1997) (JC97); Lin (1998) (Lin98); Zesch and Gurevych (2007) (ZG07); Gabrilovich and Markovitch (2007) (GM07); Zhang et al. (2010) (Zha10) 4 Petrakis et al. (2006) (Pet06); Pedersen et al. (2006) (Ped06). Original participating systems can be found in these works. 998 5 Discussion Single v.s. multiple knowledge sources As shown in Table 6, considering the best performances across all feature enrichment strategies and feature sets, the proposed method successfully harnessed different knowledge sources and improved over the baselines using single knowledge sources by 0.02 ~ 0.11. The biggest improveme</context>
</contexts>
<marker>Jiang, Conrath, 1997</marker>
<rawString>Jiang, J. and D. Conrath. 1997. Semantic similarity based on corpus statistics and lexical taxonomy. Proceedings of the International Conference on Research in Computational Linguistics, pp. 19-33</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Leacock</author>
<author>M Chodorow</author>
</authors>
<title>Combining local context and WordNet similarity for word sense identification.</title>
<date>1998</date>
<booktitle>In C. Fellbaum (Ed.), WordNet. An Electronic Lexical Database, Chp.</booktitle>
<volume>11</volume>
<pages>265--283</pages>
<contexts>
<context position="1349" citStr="Leacock and Chodorow, 1998" startWordPosition="183" endWordPosition="186">words or concepts. Using Wikipedia and WordNet as examples, and evaluated in both the general and biomedical domains, it successfully combines strengths from both knowledge sources and outperforms stateof-the-art on many datasets. 1 Introduction Semantic relatedness (SR) measures how much two (strings of) words or concepts are related by encompassing all kinds of relations between them (Strube and Ponzetto, 2006). It is more general than semantic similarity. SR is often an important pre-processing step to many complex Natural Language Processing (NLP) tasks, such as Word Sense Disambiguation (Leacock and Chodorow, 1998; Han and Zhao, 2010), and information retrieval (Finkelstein et al., 2002). In the biomedical domain, SR is an important technique for discovering gene functions and interactions (Wu et al., 2005; Ye et al., 2005). There is an abundant literature on measuring SR between words or concepts. Typically, these methods extract semantic evidence of words and concepts from a background knowledge source, with which their relatedness is assessed. The knowledge sources can be unstructured documents or (semi-)structured resources such as Wikipedia, WordNet, and domain specific ontologies (e.g., the Gene </context>
<context position="29649" citStr="Leacock and Chodorow (1998)" startWordPosition="4675" endWordPosition="4678">be sure that correlation values are accurate or occurred by chance. Therefore, we measure the statistical significance of correlation by computing the pvalue for the correlation values reported for our system in Tables 7 and 8. For all cases, a p-value of less than 0.001 is obtained, which indicates that correlation values are statistically significant. Tables 7 and 8 compare our method against stateof-the-art. For Table 8, figures for other state-ofthe-art systems can be found in corresponding publications; while we only list the best performing systems for comparison. 3 Rada (1989) (Rad89); Leacock and Chodorow (1998) (LC98); Wu and Palmer (1994) (WP04); Hirst and St-Onge (1998) (HS98); Resnik (1995) (Res95); Jiang and Conrath (1997) (JC97); Lin (1998) (Lin98); Zesch and Gurevych (2007) (ZG07); Gabrilovich and Markovitch (2007) (GM07); Zhang et al. (2010) (Zha10) 4 Petrakis et al. (2006) (Pet06); Pedersen et al. (2006) (Ped06). Original participating systems can be found in these works. 998 5 Discussion Single v.s. multiple knowledge sources As shown in Table 6, considering the best performances across all feature enrichment strategies and feature sets, the proposed method successfully harnessed different </context>
</contexts>
<marker>Leacock, Chodorow, 1998</marker>
<rawString>Leacock, C., Chodorow, M. 1998. Combining local context and WordNet similarity for word sense identification. In C. Fellbaum (Ed.), WordNet. An Electronic Lexical Database, Chp. 11, pp. 265-283.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lin</author>
</authors>
<title>An information-theoretic definition of similarity.</title>
<date>1998</date>
<booktitle>Proceedings of the Fifteenth International Conference on Machine Learning,</booktitle>
<pages>296--304</pages>
<contexts>
<context position="6587" citStr="Lin, 1998" startWordPosition="984" endWordPosition="985">2002; Rada et Farrell, 2007). Recent studies (Harrington, 2010; al., 1989; Wu and Palmer, 1994) measure SR Pozo et al., 2008; Wojtinnek and Pulman, 2011) between words or concepts as a function of their propose to pre-process a corpus to learn a semantic distance in a semantic network, usually calculated network, with which SR is computed. This creates based on the path connecting the words or concepts high pre-processing cost; also, the choice of corpus by certain semantic (typically is-a) links. IC based and its size often have a direct correlation with the methods (Jiang and Conrath, 1997; Lin, 1998; accuracy of SR methods (Batet et al., 2010). Pirro et al., 2009; Resnik, 1995; Seco et al., 2004) (Semi-)Structured knowledge sources on the assess relatedness between words or concepts by other hand, organize semantic knowledge about the amount of information they share, usually concepts and words explicitly and interlink them determined by a higher level concept that with semantic relations. They have been popular subsumes both concepts in a taxonomic structure. choices in the studies of SR, and they include Statistical methods measure relatedness between lexical resources such as WordNet,</context>
<context position="29786" citStr="Lin (1998)" startWordPosition="4698" endWordPosition="4699">lue for the correlation values reported for our system in Tables 7 and 8. For all cases, a p-value of less than 0.001 is obtained, which indicates that correlation values are statistically significant. Tables 7 and 8 compare our method against stateof-the-art. For Table 8, figures for other state-ofthe-art systems can be found in corresponding publications; while we only list the best performing systems for comparison. 3 Rada (1989) (Rad89); Leacock and Chodorow (1998) (LC98); Wu and Palmer (1994) (WP04); Hirst and St-Onge (1998) (HS98); Resnik (1995) (Res95); Jiang and Conrath (1997) (JC97); Lin (1998) (Lin98); Zesch and Gurevych (2007) (ZG07); Gabrilovich and Markovitch (2007) (GM07); Zhang et al. (2010) (Zha10) 4 Petrakis et al. (2006) (Pet06); Pedersen et al. (2006) (Ped06). Original participating systems can be found in these works. 998 5 Discussion Single v.s. multiple knowledge sources As shown in Table 6, considering the best performances across all feature enrichment strategies and feature sets, the proposed method successfully harnessed different knowledge sources and improved over the baselines using single knowledge sources by 0.02 ~ 0.11. The biggest improvement (0.11) is on a d</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>Lin, D. 1998. An information-theoretic definition of similarity. Proceedings of the Fifteenth International Conference on Machine Learning, pp. 296-304</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Lord</author>
<author>R Stevens</author>
<author>A Brass</author>
<author>C Goble</author>
</authors>
<title>Investigating semantic similarity measures across the Gene Ontology: the relationship between sequence and annotation.</title>
<date>2003</date>
<booktitle>In Bioinformatics,</booktitle>
<pages>1275--1283</pages>
<contexts>
<context position="2715" citStr="Lord et al., 2003" startWordPosition="393" endWordPosition="396"> knowledge source of semantic evidence. Research (Strube and Ponzetto, 2006; Zesch and Gurevych, 2010; Zhang et al., 2010) has shown that the accuracy of an SR method differs depending on the choice of the knowledge sources, and there is no conclusion which knowledge source is superior to others. Zhang et al. (2010) argue that this indicates different knowledge sources may complement each other. Second, the majority of SR methods have been evaluated in general domains only, except a few earlier WordNet-based methods that have been adapted to biomedical ontologies and evaluated in that domain (Lord et al., 2003; Pedersen et al., 2006; Pozo et al., 2008). Given the significant attention that SR has received in specific domains (Pesquita et al., 2007), evaluation of SR methods in specific domains is increasingly important. This paper addresses these issues by proposing a generic and uniform model for computing SR between words or concepts using multiple knowledge sources, and evaluating the proposed method in both general and specific domains. The method combines and integrates semantic evidence of words or concepts extracted from any knowledge source in a generic graph representation, with which the </context>
<context position="8799" citStr="Lord et al., 2003" startWordPosition="1309" endWordPosition="1312">ces and therefore may overcome this limitation. Wikipedia in particular, is found to have reasonable coverage of many domains (Holloway et al., 2007; Halavais, 2008). It has become increasingly popular in SR studies recently. However, research (Zesch and Gurevych, 2010) have shown that methods based on Wikipedia have no clear advantage over WordNet-based methods on some general domain datasets in terms of accuracy, while Zhang et al. (2010) argue that different knowledge sources may complement each other, and SR methods may benefit from harnessing different knowledge sources. Several studies (Lord et al., 2003; Pedersen et al., 2006; Petrakis et al., 2006; Pozo et al., 2008) have adapted state-of-the-art to domain specific knowledge sources (e.g., the Gene Ontology, the MeSH2) and evaluated them therein. Despite these efforts, a large proportion of state-of-the-art is still only evaluated in the general domain. 2.3 SR methods similar to this work Few works have attempted at combining different knowledge sources in SR studies, especially (semi)structured knowledge sources. The closest studies are Han and Zhao (2010) and Tsang and Stevenson (2010). Han and Zhao firstly compute SR between words using </context>
</contexts>
<marker>Lord, Stevens, Brass, Goble, 2003</marker>
<rawString>Lord, P., Stevens, R., Brass, A., Goble, C. 2003. Investigating semantic similarity measures across the Gene Ontology: the relationship between sequence and annotation. In Bioinformatics, 19(10), pp. 1275–1283</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Matsuo</author>
<author>T Sakaki</author>
<author>K Uchiyama</author>
<author>M Ishizuka</author>
</authors>
<title>Graph-based word clustering using a web search engine.</title>
<date>2006</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>542--550</pages>
<contexts>
<context position="7617" citStr="Matsuo et al., 2006" startWordPosition="1134" endWordPosition="1137">een popular subsumes both concepts in a taxonomic structure. choices in the studies of SR, and they include Statistical methods measure relatedness between lexical resources such as WordNet, Wiktionary, words or concepts based on their distribution of and (semi-)structured encyclopedic resources such contextual evidence. This can be formalized as co- as Wikipedia. WordNet has been used in earlier occurrence statistics collected from unstructured studies (Hirst and St-Onge, 1998; Jiang and documents (Chen et al., 2006; Cilibrasi and Conrath, 1997; Lin, 1998; Leacock and Chodorow Vitanyi, 2007; Matsuo et al., 2006), or 1998; Resnik, 1995; Seco et al., 2004; Wu and distributional concept or word vectors with Palmer, 1994) and is still a preferred knowledge features extracted from either unstructured source in recent works (Agirre et al., 2009). documents (Harrington, 2010; Wojtinnek and However, its effectiveness may be hindered by its Pulman, 2011) or (semi-)structured knowledge lack of coverage of specialized lexicons and 992 domain specific concepts (Strube and Ponzetto, 2006; Zhang et al., 2010). Wikipedia and Wiktionary are collaboratively maintained knowledge sources and therefore may overcome this</context>
</contexts>
<marker>Matsuo, Sakaki, Uchiyama, Ishizuka, 2006</marker>
<rawString>Matsuo, Y., T. Sakaki., K., Uchiyama, M., Ishizuka. 2006. Graph-based word clustering using a web search engine. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), pp.542-550</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Miller</author>
<author>W Charles</author>
</authors>
<title>Contextual correlates of semantic similarity.</title>
<date>1991</date>
<booktitle>In Language and Cognitive Processes,</booktitle>
<volume>6</volume>
<issue>1</issue>
<pages>1--28</pages>
<contexts>
<context position="24461" citStr="Miller and Charles (1991)" startWordPosition="3789" endWordPosition="3792">t two concepts related to a third concept is also semantically related, which is similar to the hypothesis proposed by Patwardhan and Pedersen (2006) in their method based on second-order context vectors. The final SR between the input word pair is the maximum pair-wise concept SR. 4 Experiment and evaluation We evaluate the method based on correlation against human judgment (gold standard) on seven benchmarking datasets covering both general and technical domains. These include four general domain datasets: the Rubenstein and Goodenough (1965) dataset containing 65 pairs of nouns (RG65); the Miller and Charles (1991) dataset that is a subset of the RG-65 dataset and contains 30 pairs (MC30); the Finkelstein et al. (2002) dataset with 353 pairs of words, including nouns, verbs, adjectives, as well as named entities. This contains two subsets, a set of 153 pairs (Fin153) and a set of 200 (Fin200) pairs each annotated by a different groups of annotators. Zesch and Gurevych (2010) show largely varying Inter-Annotator-Agreement (IAA) between the two sets (Table 1), and argue that they should be treated as separate datasets. Three biomedical datasets are selected to evaluate domain-specific performance of the p</context>
</contexts>
<marker>Miller, Charles, 1991</marker>
<rawString>Miller, G., Charles, W. 1991. Contextual correlates of semantic similarity. In Language and Cognitive Processes, 6(1): 1-28</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Pan</author>
<author>R Farrell</author>
</authors>
<title>Computing semantic similarity between skill statements for approximate matching.</title>
<date>2007</date>
<booktitle>In Proceedings of NAACL-HLT’07,</booktitle>
<pages>572--579</pages>
<marker>Pan, Farrell, 2007</marker>
<rawString>Pan, F., Farrell, R. 2007. Computing semantic similarity between skill statements for approximate matching. In Proceedings of NAACL-HLT’07, pp. 572-579</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Patwardhan</author>
<author>T Pedersen</author>
</authors>
<title>Using WordNetbased context vectors to estimate the semantic relatedness of concepts.</title>
<date>2006</date>
<booktitle>Proceedings of the EACL 2006 Workshop on Making Sense of Sense: Bringing Computational Linguistics and Psycholinguistics Together</booktitle>
<contexts>
<context position="23985" citStr="Patwardhan and Pedersen (2006)" startWordPosition="3718" endWordPosition="3721">the transition probability matrix P(t)(j|i) = [(D−1W)t]ij (Dii = ∑kWik), which returns the probability of reaching other nodes from a starting node on the graph after t steps. In this method, we follow the work by Rowe and Ciravegna (2010) to set t=2 in order to preserve locally connected nodes. Next, we extract the probability vectors corresponding to concept nodes from P, and compute pair-wise relatedness using the cosine function. Effectively, this formalizes the notion that two concepts related to a third concept is also semantically related, which is similar to the hypothesis proposed by Patwardhan and Pedersen (2006) in their method based on second-order context vectors. The final SR between the input word pair is the maximum pair-wise concept SR. 4 Experiment and evaluation We evaluate the method based on correlation against human judgment (gold standard) on seven benchmarking datasets covering both general and technical domains. These include four general domain datasets: the Rubenstein and Goodenough (1965) dataset containing 65 pairs of nouns (RG65); the Miller and Charles (1991) dataset that is a subset of the RG-65 dataset and contains 30 pairs (MC30); the Finkelstein et al. (2002) dataset with 353 </context>
</contexts>
<marker>Patwardhan, Pedersen, 2006</marker>
<rawString>Patwardhan, S., Pedersen, T. 2006. Using WordNetbased context vectors to estimate the semantic relatedness of concepts. Proceedings of the EACL 2006 Workshop on Making Sense of Sense: Bringing Computational Linguistics and Psycholinguistics Together</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Pedersen</author>
<author>S Pakhomov</author>
<author>S Patwardhan</author>
<author>C Chute</author>
</authors>
<title>Measures of semantic similarity and relatedness in the biomedical domain.</title>
<date>2006</date>
<journal>Journal of Biomedical Informatics</journal>
<volume>40</volume>
<issue>3</issue>
<pages>288--299</pages>
<contexts>
<context position="2738" citStr="Pedersen et al., 2006" startWordPosition="397" endWordPosition="400">f semantic evidence. Research (Strube and Ponzetto, 2006; Zesch and Gurevych, 2010; Zhang et al., 2010) has shown that the accuracy of an SR method differs depending on the choice of the knowledge sources, and there is no conclusion which knowledge source is superior to others. Zhang et al. (2010) argue that this indicates different knowledge sources may complement each other. Second, the majority of SR methods have been evaluated in general domains only, except a few earlier WordNet-based methods that have been adapted to biomedical ontologies and evaluated in that domain (Lord et al., 2003; Pedersen et al., 2006; Pozo et al., 2008). Given the significant attention that SR has received in specific domains (Pesquita et al., 2007), evaluation of SR methods in specific domains is increasingly important. This paper addresses these issues by proposing a generic and uniform model for computing SR between words or concepts using multiple knowledge sources, and evaluating the proposed method in both general and specific domains. The method combines and integrates semantic evidence of words or concepts extracted from any knowledge source in a generic graph representation, with which the SR between concepts or </context>
<context position="8822" citStr="Pedersen et al., 2006" startWordPosition="1313" endWordPosition="1316">ay overcome this limitation. Wikipedia in particular, is found to have reasonable coverage of many domains (Holloway et al., 2007; Halavais, 2008). It has become increasingly popular in SR studies recently. However, research (Zesch and Gurevych, 2010) have shown that methods based on Wikipedia have no clear advantage over WordNet-based methods on some general domain datasets in terms of accuracy, while Zhang et al. (2010) argue that different knowledge sources may complement each other, and SR methods may benefit from harnessing different knowledge sources. Several studies (Lord et al., 2003; Pedersen et al., 2006; Petrakis et al., 2006; Pozo et al., 2008) have adapted state-of-the-art to domain specific knowledge sources (e.g., the Gene Ontology, the MeSH2) and evaluated them therein. Despite these efforts, a large proportion of state-of-the-art is still only evaluated in the general domain. 2.3 SR methods similar to this work Few works have attempted at combining different knowledge sources in SR studies, especially (semi)structured knowledge sources. The closest studies are Han and Zhao (2010) and Tsang and Stevenson (2010). Han and Zhao firstly compute SR between words using three state-of-the-art </context>
<context position="25244" citStr="Pedersen et al. (2006)" startWordPosition="3918" endWordPosition="3921">s, adjectives, as well as named entities. This contains two subsets, a set of 153 pairs (Fin153) and a set of 200 (Fin200) pairs each annotated by a different groups of annotators. Zesch and Gurevych (2010) show largely varying Inter-Annotator-Agreement (IAA) between the two sets (Table 1), and argue that they should be treated as separate datasets. Three biomedical datasets are selected to evaluate domain-specific performance of the proposed method. These include a set of 36 MeSH term pairs in Petrakis et al. (2006) (MeSH36), 30 pairs of medical terms annotated by a group of physicians as in Pedersen et al. (2006) (Ped30-p) and the same set annotated by a different group of medical coders (Ped30-c). Table 1 shows statistics of the seven datasets. The correlation is computed using the Spearman rank order coefficient for two reasons. First, it is a better metric than other alternatives (Zesch and Gurevych, 2010). Second, it is consistent with the majority of studies such that results can be compared. Dataset Size Domain IAA MC30 30 General 0.9 RG65 65 General 0.8 Fin153 153 General 0.73 Fin200 200 General 0.55 Ped30-p 30 Biomedical 0.68 Ped30-c 30 Biomedical 0.78 MeSH36 36 Biomedical - Table 1: Informati</context>
<context position="29956" citStr="Pedersen et al. (2006)" startWordPosition="4722" endWordPosition="4725">ation values are statistically significant. Tables 7 and 8 compare our method against stateof-the-art. For Table 8, figures for other state-ofthe-art systems can be found in corresponding publications; while we only list the best performing systems for comparison. 3 Rada (1989) (Rad89); Leacock and Chodorow (1998) (LC98); Wu and Palmer (1994) (WP04); Hirst and St-Onge (1998) (HS98); Resnik (1995) (Res95); Jiang and Conrath (1997) (JC97); Lin (1998) (Lin98); Zesch and Gurevych (2007) (ZG07); Gabrilovich and Markovitch (2007) (GM07); Zhang et al. (2010) (Zha10) 4 Petrakis et al. (2006) (Pet06); Pedersen et al. (2006) (Ped06). Original participating systems can be found in these works. 998 5 Discussion Single v.s. multiple knowledge sources As shown in Table 6, considering the best performances across all feature enrichment strategies and feature sets, the proposed method successfully harnessed different knowledge sources and improved over the baselines using single knowledge sources by 0.02 ~ 0.11. The biggest improvement (0.11) is on a domain-specific dataset, on which the method based on single knowledge source performed poorly in terms of coverage and accuracy. The best enrichment strategy that has con</context>
</contexts>
<marker>Pedersen, Pakhomov, Patwardhan, Chute, 2006</marker>
<rawString>Pedersen, T., Pakhomov, S., Patwardhan, S., Chute, C. 2006. Measures of semantic similarity and relatedness in the biomedical domain. Journal of Biomedical Informatics 40(3), 288-299</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Pekar</author>
<author>S Staab</author>
</authors>
<title>Taxonomy learning: factoring the structure of a taxonomy into a semantic classification decision.</title>
<date>2002</date>
<booktitle>Proceedings of COLING’02.</booktitle>
<pages>786--792</pages>
<contexts>
<context position="5982" citStr="Pekar and Staab, 2002" startWordPosition="883" endWordPosition="886">heaper to concludes this paper. maintain, however, semantic relations between 2 Related work words or concepts are implicit. Methods (Chen et 2.1 SR methods al., 2006; Cilibrasi and Vitanyi 2007; Matsuo et al., Methods for computing SR can be classified into 2006) that exploit unstructured corpora typically path based, Information Content (IC) based, depend on distributional statistics, and thus may statistical and hybrid methods. Path based ignore important semantic evidences present in methods (Hirst and St-Onge, 1998; Leacock and (semi-)structured knowledge sources (Pan and Chodorow, 1998; Pekar and Staab, 2002; Rada et Farrell, 2007). Recent studies (Harrington, 2010; al., 1989; Wu and Palmer, 1994) measure SR Pozo et al., 2008; Wojtinnek and Pulman, 2011) between words or concepts as a function of their propose to pre-process a corpus to learn a semantic distance in a semantic network, usually calculated network, with which SR is computed. This creates based on the path connecting the words or concepts high pre-processing cost; also, the choice of corpus by certain semantic (typically is-a) links. IC based and its size often have a direct correlation with the methods (Jiang and Conrath, 1997; Lin,</context>
</contexts>
<marker>Pekar, Staab, 2002</marker>
<rawString>Pekar, V., Staab, S. 2002. Taxonomy learning: factoring the structure of a taxonomy into a semantic classification decision. Proceedings of COLING’02. pp. 786-792</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Pesquita</author>
<author>D Faria</author>
<author>H Bastos</author>
<author>A Falcão</author>
<author>F Couto</author>
</authors>
<title>Evaluating GO-based Semantic Similarity Measures.</title>
<date>2007</date>
<booktitle>ISMB/ECCB 2007 SIG Meeting Program Materials, International Society for Computational Biology</booktitle>
<contexts>
<context position="2856" citStr="Pesquita et al., 2007" startWordPosition="416" endWordPosition="419">t the accuracy of an SR method differs depending on the choice of the knowledge sources, and there is no conclusion which knowledge source is superior to others. Zhang et al. (2010) argue that this indicates different knowledge sources may complement each other. Second, the majority of SR methods have been evaluated in general domains only, except a few earlier WordNet-based methods that have been adapted to biomedical ontologies and evaluated in that domain (Lord et al., 2003; Pedersen et al., 2006; Pozo et al., 2008). Given the significant attention that SR has received in specific domains (Pesquita et al., 2007), evaluation of SR methods in specific domains is increasingly important. This paper addresses these issues by proposing a generic and uniform model for computing SR between words or concepts using multiple knowledge sources, and evaluating the proposed method in both general and specific domains. The method combines and integrates semantic evidence of words or concepts extracted from any knowledge source in a generic graph representation, with which the SR between concepts or words is computed. Using two of the most popular general-domain knowledge sources, 1 http://www.geneontology.org/, las</context>
</contexts>
<marker>Pesquita, Faria, Bastos, Falcão, Couto, 2007</marker>
<rawString>Pesquita, C., Faria, D., Bastos, H., Falcão, A., Couto, F. (2007). Evaluating GO-based Semantic Similarity Measures. ISMB/ECCB 2007 SIG Meeting Program Materials, International Society for Computational Biology 2007</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Petrakis</author>
<author>G Varelas</author>
<author>A Hliaoutakis</author>
<author>P Raftopoulou</author>
</authors>
<title>Design and evaluation of semantic similarity measures for concepts stemming from the same or different ontologies.</title>
<date>2006</date>
<booktitle>In 4th Workshop on Multimedia Semantics (WMS&apos;06),</booktitle>
<pages>44--52</pages>
<contexts>
<context position="8845" citStr="Petrakis et al., 2006" startWordPosition="1317" endWordPosition="1320">tion. Wikipedia in particular, is found to have reasonable coverage of many domains (Holloway et al., 2007; Halavais, 2008). It has become increasingly popular in SR studies recently. However, research (Zesch and Gurevych, 2010) have shown that methods based on Wikipedia have no clear advantage over WordNet-based methods on some general domain datasets in terms of accuracy, while Zhang et al. (2010) argue that different knowledge sources may complement each other, and SR methods may benefit from harnessing different knowledge sources. Several studies (Lord et al., 2003; Pedersen et al., 2006; Petrakis et al., 2006; Pozo et al., 2008) have adapted state-of-the-art to domain specific knowledge sources (e.g., the Gene Ontology, the MeSH2) and evaluated them therein. Despite these efforts, a large proportion of state-of-the-art is still only evaluated in the general domain. 2.3 SR methods similar to this work Few works have attempted at combining different knowledge sources in SR studies, especially (semi)structured knowledge sources. The closest studies are Han and Zhao (2010) and Tsang and Stevenson (2010). Han and Zhao firstly compute SR between words using three state-of-the-art SR methods separately. </context>
<context position="25144" citStr="Petrakis et al. (2006)" startWordPosition="3900" endWordPosition="3903">0 pairs (MC30); the Finkelstein et al. (2002) dataset with 353 pairs of words, including nouns, verbs, adjectives, as well as named entities. This contains two subsets, a set of 153 pairs (Fin153) and a set of 200 (Fin200) pairs each annotated by a different groups of annotators. Zesch and Gurevych (2010) show largely varying Inter-Annotator-Agreement (IAA) between the two sets (Table 1), and argue that they should be treated as separate datasets. Three biomedical datasets are selected to evaluate domain-specific performance of the proposed method. These include a set of 36 MeSH term pairs in Petrakis et al. (2006) (MeSH36), 30 pairs of medical terms annotated by a group of physicians as in Pedersen et al. (2006) (Ped30-p) and the same set annotated by a different group of medical coders (Ped30-c). Table 1 shows statistics of the seven datasets. The correlation is computed using the Spearman rank order coefficient for two reasons. First, it is a better metric than other alternatives (Zesch and Gurevych, 2010). Second, it is consistent with the majority of studies such that results can be compared. Dataset Size Domain IAA MC30 30 General 0.9 RG65 65 General 0.8 Fin153 153 General 0.73 Fin200 200 General </context>
<context position="29924" citStr="Petrakis et al. (2006)" startWordPosition="4717" endWordPosition="4720">ned, which indicates that correlation values are statistically significant. Tables 7 and 8 compare our method against stateof-the-art. For Table 8, figures for other state-ofthe-art systems can be found in corresponding publications; while we only list the best performing systems for comparison. 3 Rada (1989) (Rad89); Leacock and Chodorow (1998) (LC98); Wu and Palmer (1994) (WP04); Hirst and St-Onge (1998) (HS98); Resnik (1995) (Res95); Jiang and Conrath (1997) (JC97); Lin (1998) (Lin98); Zesch and Gurevych (2007) (ZG07); Gabrilovich and Markovitch (2007) (GM07); Zhang et al. (2010) (Zha10) 4 Petrakis et al. (2006) (Pet06); Pedersen et al. (2006) (Ped06). Original participating systems can be found in these works. 998 5 Discussion Single v.s. multiple knowledge sources As shown in Table 6, considering the best performances across all feature enrichment strategies and feature sets, the proposed method successfully harnessed different knowledge sources and improved over the baselines using single knowledge sources by 0.02 ~ 0.11. The biggest improvement (0.11) is on a domain-specific dataset, on which the method based on single knowledge source performed poorly in terms of coverage and accuracy. The best </context>
</contexts>
<marker>Petrakis, Varelas, Hliaoutakis, Raftopoulou, 2006</marker>
<rawString>Petrakis, E., Varelas, G., Hliaoutakis, A., Raftopoulou, P. 2006. Design and evaluation of semantic similarity measures for concepts stemming from the same or different ontologies. In 4th Workshop on Multimedia Semantics (WMS&apos;06), pp. 44-52.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Pirro</author>
</authors>
<title>A semantic similarity metric combining features and intrinsic information content.</title>
<date>2009</date>
<journal>In Data and Knowledge Engineering,</journal>
<volume>68</volume>
<issue>11</issue>
<pages>1289--1308</pages>
<marker>Pirro, 2009</marker>
<rawString>Pirro, G. 2009. A semantic similarity metric combining features and intrinsic information content. In Data and Knowledge Engineering, 68(11), pp. 1289-1308</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Pozo</author>
<author>F Pazos</author>
<author>A Valencia</author>
</authors>
<title>Defining functional distances over gene ontology.</title>
<date>2008</date>
<journal>In BMC Bioinformatics</journal>
<volume>9</volume>
<pages>50</pages>
<contexts>
<context position="2758" citStr="Pozo et al., 2008" startWordPosition="401" endWordPosition="404">search (Strube and Ponzetto, 2006; Zesch and Gurevych, 2010; Zhang et al., 2010) has shown that the accuracy of an SR method differs depending on the choice of the knowledge sources, and there is no conclusion which knowledge source is superior to others. Zhang et al. (2010) argue that this indicates different knowledge sources may complement each other. Second, the majority of SR methods have been evaluated in general domains only, except a few earlier WordNet-based methods that have been adapted to biomedical ontologies and evaluated in that domain (Lord et al., 2003; Pedersen et al., 2006; Pozo et al., 2008). Given the significant attention that SR has received in specific domains (Pesquita et al., 2007), evaluation of SR methods in specific domains is increasingly important. This paper addresses these issues by proposing a generic and uniform model for computing SR between words or concepts using multiple knowledge sources, and evaluating the proposed method in both general and specific domains. The method combines and integrates semantic evidence of words or concepts extracted from any knowledge source in a generic graph representation, with which the SR between concepts or words is computed. U</context>
<context position="4233" citStr="Pozo et al. (2008)" startWordPosition="623" endWordPosition="626">ets, including Markovitch, 2007; Gouws et al., 2010; Zesch and three datasets from the biomedical domain and Gurevych, 2007; Zhang et al., 2010). Hybrid four from the general domain. It has achieved methods combine different purebred methods in excellent results: compared to the baselines that certain ways. For example Riensche et al. (2007) use each single knowledge sources, combining employ both an IC based method (Resnik, 1995) both knowledge sources has improved the accuracy and a statistical method (cosine vector similarity) on all datasets by 2~11%; compared to state-of- in their study. Pozo et al. (2008) derive a taxonomy the-art on the general domain datasets, the method of terms from unstructured documents by applying achieves the best results on three datasets; and on hierarchical clustering based on corpus statistics, the other three biomedical datasets, it obtains the then apply path based method on this taxonomy to best result in one case; and second and third best compute SR. Han and Zhao (2010) use one IC results on the other two among eight participating based method and two statistical methods to methods, where all other competitors exploit some compute SR, then derive an aggregated</context>
<context position="6102" citStr="Pozo et al., 2008" startWordPosition="903" endWordPosition="906"> Methods (Chen et 2.1 SR methods al., 2006; Cilibrasi and Vitanyi 2007; Matsuo et al., Methods for computing SR can be classified into 2006) that exploit unstructured corpora typically path based, Information Content (IC) based, depend on distributional statistics, and thus may statistical and hybrid methods. Path based ignore important semantic evidences present in methods (Hirst and St-Onge, 1998; Leacock and (semi-)structured knowledge sources (Pan and Chodorow, 1998; Pekar and Staab, 2002; Rada et Farrell, 2007). Recent studies (Harrington, 2010; al., 1989; Wu and Palmer, 1994) measure SR Pozo et al., 2008; Wojtinnek and Pulman, 2011) between words or concepts as a function of their propose to pre-process a corpus to learn a semantic distance in a semantic network, usually calculated network, with which SR is computed. This creates based on the path connecting the words or concepts high pre-processing cost; also, the choice of corpus by certain semantic (typically is-a) links. IC based and its size often have a direct correlation with the methods (Jiang and Conrath, 1997; Lin, 1998; accuracy of SR methods (Batet et al., 2010). Pirro et al., 2009; Resnik, 1995; Seco et al., 2004) (Semi-)Structur</context>
<context position="8865" citStr="Pozo et al., 2008" startWordPosition="1321" endWordPosition="1324">icular, is found to have reasonable coverage of many domains (Holloway et al., 2007; Halavais, 2008). It has become increasingly popular in SR studies recently. However, research (Zesch and Gurevych, 2010) have shown that methods based on Wikipedia have no clear advantage over WordNet-based methods on some general domain datasets in terms of accuracy, while Zhang et al. (2010) argue that different knowledge sources may complement each other, and SR methods may benefit from harnessing different knowledge sources. Several studies (Lord et al., 2003; Pedersen et al., 2006; Petrakis et al., 2006; Pozo et al., 2008) have adapted state-of-the-art to domain specific knowledge sources (e.g., the Gene Ontology, the MeSH2) and evaluated them therein. Despite these efforts, a large proportion of state-of-the-art is still only evaluated in the general domain. 2.3 SR methods similar to this work Few works have attempted at combining different knowledge sources in SR studies, especially (semi)structured knowledge sources. The closest studies are Han and Zhao (2010) and Tsang and Stevenson (2010). Han and Zhao firstly compute SR between words using three state-of-the-art SR methods separately. Next, one score is c</context>
<context position="14425" citStr="Pozo et al. (2008)" startWordPosition="2205" endWordPosition="2208">y of these in fact link to a concept relevant to w, but not necessarily a candidate sense of w. Thirdly, if no pages are returned for w, we search for the most relevant page using w as keyword(s) in an inverted index of all Wikipedia pages (e.g., via search engines). We denote concepts retrieved from Wikipedia as . For unstructured sources such as documents, a simple approach could be defining a word context as a text passage around each occurrence of w, and grouping similar contexts of w as representation of its underlying meanings, or concepts. Alternatively, more complex approaches such as Pozo et al. (2008) and Harrington (2010) may be applied to extract a lexical network of words, whereby similar methods to WordNet can be applied. 3.2 Feature extraction and representation Next, for each concept identified from a knowledge source, features are extracted from their corresponding contexts. In our case, for each , we follow the work by Zhang et al. (2010) to extract four types of features from their corresponding Wikipedia pages. Figure 1 shows an example representation of a concept and its Wikipedia features: • Words from page titles and redirection links (can be considered as synonyms) • Words fr</context>
</contexts>
<marker>Pozo, Pazos, Valencia, 2008</marker>
<rawString>Pozo A., Pazos F., Valencia, A. 2008. Defining functional distances over gene ontology. In BMC Bioinformatics 9, pp.50</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Rada</author>
<author>H Mili</author>
<author>E Bicknell</author>
<author>M Blettner</author>
</authors>
<title>Development and application of a metric on semantic nets.</title>
<date>1989</date>
<journal>In IEEE Transactions on Systems, Man and Cybernetics</journal>
<volume>19</volume>
<issue>1</issue>
<pages>17--30</pages>
<marker>Rada, Mili, Bicknell, Blettner, 1989</marker>
<rawString>Rada, R., Mili, H., Bicknell, E., Blettner, M. 1989. Development and application of a metric on semantic nets. In IEEE Transactions on Systems, Man and Cybernetics 19(1), pp.17-30</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Resnik</author>
</authors>
<title>Using information content to evaluate semantic similarity in a taxonomy.</title>
<date>1995</date>
<booktitle>In Proceedings of IJCAI-95,</booktitle>
<pages>448--453</pages>
<contexts>
<context position="4049" citStr="Resnik, 1995" startWordPosition="596" endWordPosition="597">neontology.org/, last retrieved in Mar. 2011 991 Wikipedia and WordNet as examples, the method resources (Agirre et al., 2009; Gabrilovich and is evaluated on 7 benchmarking datasets, including Markovitch, 2007; Gouws et al., 2010; Zesch and three datasets from the biomedical domain and Gurevych, 2007; Zhang et al., 2010). Hybrid four from the general domain. It has achieved methods combine different purebred methods in excellent results: compared to the baselines that certain ways. For example Riensche et al. (2007) use each single knowledge sources, combining employ both an IC based method (Resnik, 1995) both knowledge sources has improved the accuracy and a statistical method (cosine vector similarity) on all datasets by 2~11%; compared to state-of- in their study. Pozo et al. (2008) derive a taxonomy the-art on the general domain datasets, the method of terms from unstructured documents by applying achieves the best results on three datasets; and on hierarchical clustering based on corpus statistics, the other three biomedical datasets, it obtains the then apply path based method on this taxonomy to best result in one case; and second and third best compute SR. Han and Zhao (2010) use one I</context>
<context position="6666" citStr="Resnik, 1995" startWordPosition="998" endWordPosition="999">u and Palmer, 1994) measure SR Pozo et al., 2008; Wojtinnek and Pulman, 2011) between words or concepts as a function of their propose to pre-process a corpus to learn a semantic distance in a semantic network, usually calculated network, with which SR is computed. This creates based on the path connecting the words or concepts high pre-processing cost; also, the choice of corpus by certain semantic (typically is-a) links. IC based and its size often have a direct correlation with the methods (Jiang and Conrath, 1997; Lin, 1998; accuracy of SR methods (Batet et al., 2010). Pirro et al., 2009; Resnik, 1995; Seco et al., 2004) (Semi-)Structured knowledge sources on the assess relatedness between words or concepts by other hand, organize semantic knowledge about the amount of information they share, usually concepts and words explicitly and interlink them determined by a higher level concept that with semantic relations. They have been popular subsumes both concepts in a taxonomic structure. choices in the studies of SR, and they include Statistical methods measure relatedness between lexical resources such as WordNet, Wiktionary, words or concepts based on their distribution of and (semi-)struct</context>
<context position="29733" citStr="Resnik (1995)" startWordPosition="4690" endWordPosition="4691">istical significance of correlation by computing the pvalue for the correlation values reported for our system in Tables 7 and 8. For all cases, a p-value of less than 0.001 is obtained, which indicates that correlation values are statistically significant. Tables 7 and 8 compare our method against stateof-the-art. For Table 8, figures for other state-ofthe-art systems can be found in corresponding publications; while we only list the best performing systems for comparison. 3 Rada (1989) (Rad89); Leacock and Chodorow (1998) (LC98); Wu and Palmer (1994) (WP04); Hirst and St-Onge (1998) (HS98); Resnik (1995) (Res95); Jiang and Conrath (1997) (JC97); Lin (1998) (Lin98); Zesch and Gurevych (2007) (ZG07); Gabrilovich and Markovitch (2007) (GM07); Zhang et al. (2010) (Zha10) 4 Petrakis et al. (2006) (Pet06); Pedersen et al. (2006) (Ped06). Original participating systems can be found in these works. 998 5 Discussion Single v.s. multiple knowledge sources As shown in Table 6, considering the best performances across all feature enrichment strategies and feature sets, the proposed method successfully harnessed different knowledge sources and improved over the baselines using single knowledge sources by </context>
</contexts>
<marker>Resnik, 1995</marker>
<rawString>Resnik, P. (1995). Using information content to evaluate semantic similarity in a taxonomy. In Proceedings of IJCAI-95, pp. 448-453</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Riensche</author>
<author>B Baddeley</author>
<author>A Sanfilippo</author>
<author>C Posse</author>
<author>B Gopalan</author>
</authors>
<title>XOA: Web-Enabled CrossOntological Analytics.</title>
<date>2007</date>
<journal>IEEE Congress on Services,</journal>
<pages>99--105</pages>
<contexts>
<context position="3958" citStr="Riensche et al. (2007)" startWordPosition="580" endWordPosition="583">r words is computed. Using two of the most popular general-domain knowledge sources, 1 http://www.geneontology.org/, last retrieved in Mar. 2011 991 Wikipedia and WordNet as examples, the method resources (Agirre et al., 2009; Gabrilovich and is evaluated on 7 benchmarking datasets, including Markovitch, 2007; Gouws et al., 2010; Zesch and three datasets from the biomedical domain and Gurevych, 2007; Zhang et al., 2010). Hybrid four from the general domain. It has achieved methods combine different purebred methods in excellent results: compared to the baselines that certain ways. For example Riensche et al. (2007) use each single knowledge sources, combining employ both an IC based method (Resnik, 1995) both knowledge sources has improved the accuracy and a statistical method (cosine vector similarity) on all datasets by 2~11%; compared to state-of- in their study. Pozo et al. (2008) derive a taxonomy the-art on the general domain datasets, the method of terms from unstructured documents by applying achieves the best results on three datasets; and on hierarchical clustering based on corpus statistics, the other three biomedical datasets, it obtains the then apply path based method on this taxonomy to b</context>
</contexts>
<marker>Riensche, Baddeley, Sanfilippo, Posse, Gopalan, 2007</marker>
<rawString>Riensche, R., Baddeley, B., Sanfilippo, A., Posse, C., Gopalan, B. 2007. XOA: Web-Enabled CrossOntological Analytics. IEEE Congress on Services, pp. 99-105</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Rowe</author>
<author>F Ciravegna</author>
</authors>
<title>Disambiguating identity web references using Web 2.0 data and semantics.</title>
<date>2010</date>
<journal>M Rowe and F Ciravegna. The Journal of Web Semantics.</journal>
<contexts>
<context position="23594" citStr="Rowe and Ciravegna (2010)" startWordPosition="3659" endWordPosition="3662">re Wij is the ith-line and jth-column entry of W, indexed by V; l(i, j) is a function that returns the type of edge (i.e., type of feature) connecting nodes i and j; L is the set of all possible types; w(l) returns the weight for that type. Essentially, L is the collection of all feature types, and w(l) assigns otherwise  996 a weight to a particular feature type. Next, we compute the transition probability matrix P(t)(j|i) = [(D−1W)t]ij (Dii = ∑kWik), which returns the probability of reaching other nodes from a starting node on the graph after t steps. In this method, we follow the work by Rowe and Ciravegna (2010) to set t=2 in order to preserve locally connected nodes. Next, we extract the probability vectors corresponding to concept nodes from P, and compute pair-wise relatedness using the cosine function. Effectively, this formalizes the notion that two concepts related to a third concept is also semantically related, which is similar to the hypothesis proposed by Patwardhan and Pedersen (2006) in their method based on second-order context vectors. The final SR between the input word pair is the maximum pair-wise concept SR. 4 Experiment and evaluation We evaluate the method based on correlation aga</context>
</contexts>
<marker>Rowe, Ciravegna, 2010</marker>
<rawString>Rowe, M., Ciravegna, F. 2010. Disambiguating identity web references using Web 2.0 data and semantics. M Rowe and F Ciravegna. The Journal of Web Semantics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Rubenstein</author>
<author>J Goodenough</author>
</authors>
<title>Contextual correlates of synonymy.</title>
<date>1965</date>
<journal>In Communications of the ACM,</journal>
<pages>8--10</pages>
<contexts>
<context position="24386" citStr="Rubenstein and Goodenough (1965)" startWordPosition="3777" endWordPosition="3780">relatedness using the cosine function. Effectively, this formalizes the notion that two concepts related to a third concept is also semantically related, which is similar to the hypothesis proposed by Patwardhan and Pedersen (2006) in their method based on second-order context vectors. The final SR between the input word pair is the maximum pair-wise concept SR. 4 Experiment and evaluation We evaluate the method based on correlation against human judgment (gold standard) on seven benchmarking datasets covering both general and technical domains. These include four general domain datasets: the Rubenstein and Goodenough (1965) dataset containing 65 pairs of nouns (RG65); the Miller and Charles (1991) dataset that is a subset of the RG-65 dataset and contains 30 pairs (MC30); the Finkelstein et al. (2002) dataset with 353 pairs of words, including nouns, verbs, adjectives, as well as named entities. This contains two subsets, a set of 153 pairs (Fin153) and a set of 200 (Fin200) pairs each annotated by a different groups of annotators. Zesch and Gurevych (2010) show largely varying Inter-Annotator-Agreement (IAA) between the two sets (Table 1), and argue that they should be treated as separate datasets. Three biomed</context>
</contexts>
<marker>Rubenstein, Goodenough, 1965</marker>
<rawString>Rubenstein, H., Goodenough, J. 1965. Contextual correlates of synonymy. In Communications of the ACM, 8(10):627-633</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Seco</author>
<author>T Hayes</author>
</authors>
<title>An intrinsic information content metric for semantic similarity in WordNet.</title>
<date>2004</date>
<booktitle>In Proceedings of the 16th European conference on Artificial Intelligence</booktitle>
<marker>Seco, Hayes, 2004</marker>
<rawString>Seco, N., and Hayes, T. 2004. An intrinsic information content metric for semantic similarity in WordNet. In Proceedings of the 16th European conference on Artificial Intelligence</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Strube</author>
<author>S Ponzetto</author>
</authors>
<title>WikiRelate! Computing semantic relatedness using Wikipedia.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st national conference on Artificial intelligence (AAAI)</booktitle>
<contexts>
<context position="1139" citStr="Strube and Ponzetto, 2006" startWordPosition="152" endWordPosition="155">dge source, and are predominantly evaluated only in the general domain. This paper introduces a method of harnessing different knowledge sources under a uniform model for measuring semantic relatedness between words or concepts. Using Wikipedia and WordNet as examples, and evaluated in both the general and biomedical domains, it successfully combines strengths from both knowledge sources and outperforms stateof-the-art on many datasets. 1 Introduction Semantic relatedness (SR) measures how much two (strings of) words or concepts are related by encompassing all kinds of relations between them (Strube and Ponzetto, 2006). It is more general than semantic similarity. SR is often an important pre-processing step to many complex Natural Language Processing (NLP) tasks, such as Word Sense Disambiguation (Leacock and Chodorow, 1998; Han and Zhao, 2010), and information retrieval (Finkelstein et al., 2002). In the biomedical domain, SR is an important technique for discovering gene functions and interactions (Wu et al., 2005; Ye et al., 2005). There is an abundant literature on measuring SR between words or concepts. Typically, these methods extract semantic evidence of words and concepts from a background knowledg</context>
<context position="8089" citStr="Strube and Ponzetto, 2006" startWordPosition="1204" endWordPosition="1207">d St-Onge, 1998; Jiang and documents (Chen et al., 2006; Cilibrasi and Conrath, 1997; Lin, 1998; Leacock and Chodorow Vitanyi, 2007; Matsuo et al., 2006), or 1998; Resnik, 1995; Seco et al., 2004; Wu and distributional concept or word vectors with Palmer, 1994) and is still a preferred knowledge features extracted from either unstructured source in recent works (Agirre et al., 2009). documents (Harrington, 2010; Wojtinnek and However, its effectiveness may be hindered by its Pulman, 2011) or (semi-)structured knowledge lack of coverage of specialized lexicons and 992 domain specific concepts (Strube and Ponzetto, 2006; Zhang et al., 2010). Wikipedia and Wiktionary are collaboratively maintained knowledge sources and therefore may overcome this limitation. Wikipedia in particular, is found to have reasonable coverage of many domains (Holloway et al., 2007; Halavais, 2008). It has become increasingly popular in SR studies recently. However, research (Zesch and Gurevych, 2010) have shown that methods based on Wikipedia have no clear advantage over WordNet-based methods on some general domain datasets in terms of accuracy, while Zhang et al. (2010) argue that different knowledge sources may complement each oth</context>
<context position="15134" citStr="Strube and Ponzetto, 2006" startWordPosition="2319" endWordPosition="2322">y similar methods to WordNet can be applied. 3.2 Feature extraction and representation Next, for each concept identified from a knowledge source, features are extracted from their corresponding contexts. In our case, for each , we follow the work by Zhang et al. (2010) to extract four types of features from their corresponding Wikipedia pages. Figure 1 shows an example representation of a concept and its Wikipedia features: • Words from page titles and redirection links (can be considered as synonyms) • Words from categories, used as higher level hypernyms in some studies (Zesch et al., 2010; Strube and Ponzetto, 2006) • Words from outgoing links • Top n most frequent words from a page Figure 1. Representation of the concept “cat, the mammal” using different types of features extracted from Wikipedia. The shaded circle represents the concept; ovals represent feature values; edges connecting feature values to the concept and &lt;labels&gt; represent feature types For each , we extract ten features from WordNet: hypernyms, hyponyms, meronyms, holonyms, synonyms, antonyms, attributes, “see also” words, “related” words, and gloss. These are also represented in the same way as in Figure 1. With unstructured sources, c</context>
</contexts>
<marker>Strube, Ponzetto, 2006</marker>
<rawString>Strube, M., Ponzetto, S. 2006. WikiRelate! Computing semantic relatedness using Wikipedia. In Proceedings of the 21st national conference on Artificial intelligence (AAAI)</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Toral</author>
<author>R Muñoz</author>
</authors>
<title>A Proposal to Automatically Build and Maintain Gazetteers for Named Entity Recognition by using Wikipedia.</title>
<date>2006</date>
<booktitle>In Proceedings of Workshop on New Text, ACL’06.</booktitle>
<contexts>
<context position="32324" citStr="Toral and Muñoz (2006)" startWordPosition="5083" endWordPosition="5086">ts that they complement each other well. On one hand, Wikipedia brings its strength in domain and content coverage; on the other hand, WordNet brings useful semantic evidences for words that are covered. Concept mapping and feature enrichment methods While the set overlap based method for cross-source concept mapping using the reference knowledge source concepts is simple and proved successful, the accuracy of mapping and its correlation with the accuracy of the SR method was not studied. This will be explored in the future. Also, alternative mapping methods will be investigated. For example, Toral and Muñoz (2006) describe a different method of mapping Wikipedia articles to WordNet synsets; one could also adopt a simple disambiguation process to select the best candidate concept from each knowledge source suited for the input word pairs, whereby crosssource concept mapping becomes straightforward. In terms of feature enrichment strategies, there is no strong indication (Table 6) of which (feature combination v.s. integration) is more effective, although the system consistently outperforms the baselines (Table 4 v.s. Table 3) with the wk4F+wn-4F, Integration strategy. Feature diversification v.s. unific</context>
</contexts>
<marker>Toral, Muñoz, 2006</marker>
<rawString>Toral, A., Muñoz, R. 2006. A Proposal to Automatically Build and Maintain Gazetteers for Named Entity Recognition by using Wikipedia. In Proceedings of Workshop on New Text, ACL’06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Tsang</author>
<author>S Stevenson</author>
</authors>
<title>A graph-theoretic framework for semantic distance.</title>
<date>2010</date>
<journal>In Journal of Computational Linguistics,</journal>
<volume>36</volume>
<issue>1</issue>
<contexts>
<context position="9345" citStr="Tsang and Stevenson (2010)" startWordPosition="1392" endWordPosition="1395"> from harnessing different knowledge sources. Several studies (Lord et al., 2003; Pedersen et al., 2006; Petrakis et al., 2006; Pozo et al., 2008) have adapted state-of-the-art to domain specific knowledge sources (e.g., the Gene Ontology, the MeSH2) and evaluated them therein. Despite these efforts, a large proportion of state-of-the-art is still only evaluated in the general domain. 2.3 SR methods similar to this work Few works have attempted at combining different knowledge sources in SR studies, especially (semi)structured knowledge sources. The closest studies are Han and Zhao (2010) and Tsang and Stevenson (2010). Han and Zhao firstly compute SR between words using three state-of-the-art SR methods separately. Next, one score is chosen subject to an arbitrary preference order, and used to create a connected graph of weighted edges between words. A recursive function is then applied to the graph to compute final SR scores between words. Essentially, each SR method is applied in isolation and features from different sources are used separately with each distinctive method. Although this retains advantages of each method, the limitations of them are also combined. Tsang and Stevenson (2010) combine WordN</context>
<context position="36178" citStr="Tsang and Stevenson, 2010" startWordPosition="5638" endWordPosition="5641">rovides reasonable coverage and quality, even if individual general knowledge sources may be limited in themselves. Generality of the method The proposed method represents features extracted from different knowledge sources in a generic manner, which facilitates cross-source feature enrichment and requires generic algorithm computation. As discussed in Section 3, semantic evidence of words and concepts may be extracted from different knowledge sources in different ways, while harnessed in the generic model. In contrast, other methods using multiple knowledge sources (e.g., Han and Zhao, 2010; Tsang and Stevenson, 2010) introduce algorithms that are bound to the knowledge sources, which may limit their adaptability and portability. 6 Conclusion This paper introduced a generic method of harnessing different knowledge sources to compute semantic relatedness. We have shown empirically that different knowledge sources contain complementary semantic evidence, which, when combined together under a uniform model, can improve the accuracy of SR methods. Moreover, we have demonstrated its robustness in dealing with knowledge sources of different quality and coverage. Several remaining issues will be studied in the fu</context>
</contexts>
<marker>Tsang, Stevenson, 2010</marker>
<rawString>Tsang, V., Stevenson, S. 2010. A graph-theoretic framework for semantic distance. In Journal of Computational Linguistics, 36(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Wojtinnek</author>
<author>S Pulman</author>
</authors>
<title>Semantic relatedness from automatically generated semantic networks.</title>
<date>2011</date>
<booktitle>In Proceedings of the Ninth International Conference on Computational Semantics (IWCS’11)</booktitle>
<contexts>
<context position="6131" citStr="Wojtinnek and Pulman, 2011" startWordPosition="907" endWordPosition="910">.1 SR methods al., 2006; Cilibrasi and Vitanyi 2007; Matsuo et al., Methods for computing SR can be classified into 2006) that exploit unstructured corpora typically path based, Information Content (IC) based, depend on distributional statistics, and thus may statistical and hybrid methods. Path based ignore important semantic evidences present in methods (Hirst and St-Onge, 1998; Leacock and (semi-)structured knowledge sources (Pan and Chodorow, 1998; Pekar and Staab, 2002; Rada et Farrell, 2007). Recent studies (Harrington, 2010; al., 1989; Wu and Palmer, 1994) measure SR Pozo et al., 2008; Wojtinnek and Pulman, 2011) between words or concepts as a function of their propose to pre-process a corpus to learn a semantic distance in a semantic network, usually calculated network, with which SR is computed. This creates based on the path connecting the words or concepts high pre-processing cost; also, the choice of corpus by certain semantic (typically is-a) links. IC based and its size often have a direct correlation with the methods (Jiang and Conrath, 1997; Lin, 1998; accuracy of SR methods (Batet et al., 2010). Pirro et al., 2009; Resnik, 1995; Seco et al., 2004) (Semi-)Structured knowledge sources on the a</context>
</contexts>
<marker>Wojtinnek, Pulman, 2011</marker>
<rawString>Wojtinnek, P., Pulman, S. 2011. Semantic relatedness from automatically generated semantic networks. In Proceedings of the Ninth International Conference on Computational Semantics (IWCS’11)</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Palmer Wu</author>
<author>M</author>
</authors>
<title>Verbs semantics and lexical selection.</title>
<date>1994</date>
<booktitle>Proceedings of the 32nd annual meeting on Association for Computational Linguistics,</booktitle>
<pages>133--138</pages>
<marker>Wu, M, 1994</marker>
<rawString>Wu, Z. Palmer, M. 1994. Verbs semantics and lexical selection. Proceedings of the 32nd annual meeting on Association for Computational Linguistics, pp. 133-138</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Wu</author>
<author>Z Su</author>
<author>F Mao</author>
<author>V Olman</author>
<author>Y Xu</author>
</authors>
<title>Prediction of functional modules based on comparative genome analysis and gene ontology application.</title>
<date>2005</date>
<journal>Nucleic Acids Research,</journal>
<volume>33</volume>
<pages>2822--2837</pages>
<contexts>
<context position="1545" citStr="Wu et al., 2005" startWordPosition="213" endWordPosition="216">e-art on many datasets. 1 Introduction Semantic relatedness (SR) measures how much two (strings of) words or concepts are related by encompassing all kinds of relations between them (Strube and Ponzetto, 2006). It is more general than semantic similarity. SR is often an important pre-processing step to many complex Natural Language Processing (NLP) tasks, such as Word Sense Disambiguation (Leacock and Chodorow, 1998; Han and Zhao, 2010), and information retrieval (Finkelstein et al., 2002). In the biomedical domain, SR is an important technique for discovering gene functions and interactions (Wu et al., 2005; Ye et al., 2005). There is an abundant literature on measuring SR between words or concepts. Typically, these methods extract semantic evidence of words and concepts from a background knowledge source, with which their relatedness is assessed. The knowledge sources can be unstructured documents or (semi-)structured resources such as Wikipedia, WordNet, and domain specific ontologies (e.g., the Gene Ontology1). In this paper, we identify two issues that have not been addressed in the previous works. First, existing works typically employ a single knowledge source of semantic evidence. Researc</context>
</contexts>
<marker>Wu, Su, Mao, Olman, Xu, 2005</marker>
<rawString>Wu, H., Su, Z., Mao, F., Olman, V., Xu, Y. 2005. Prediction of functional modules based on comparative genome analysis and gene ontology application. Nucleic Acids Research, 33, pp. 2822– 2837.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Yazdani</author>
<author>A Popescu-Belis</author>
</authors>
<title>A random walk framework to compute textual semantic similarity: a unified model for three benchmark tasks.</title>
<date>2010</date>
<booktitle>IEEE Fourth International Conference on Semantic Computing (ICSC),</booktitle>
<pages>424--429</pages>
<contexts>
<context position="16346" citStr="Yazdani and Popescu-Belis, 2010" startWordPosition="2502" endWordPosition="2505">ructured sources, contextual words can be used as features. Alternatively, if a lexical network is extracted, features may be extracted in a similar way to those of WordNet. Additionally, with WordNet and Wikipedia, we also propose several intra-resource feature merging strategies to study the effect of feature diversification. This is because, while some approaches (such as Agirre et al., 2009; Harrington, 2010; Yeh et al., 2009) do not distinguish different feature types in graph construction, or adopt a bag-of-words feature representation (such as Zesch and Gurevych, 2010), others (such as Yazdani and Popescu-Belis, 2010; Zhang et al., 2010) have used differentiated 994 feature types and weights in their model. We therefore carry out studies to investigate this issue. Specifically, for the original four Wikipedia features, we create a bag-of-words feature that simply merges all feature types (i.e., all edges in Figure 1 will have the same label). For the original ten WordNet features, we propose two merged representations corresponding to that of Wikipedia, so as to support the studies of feature enrichment in the following section. We introduce a bag-ofwords feature that collapses all different feature types</context>
</contexts>
<marker>Yazdani, Popescu-Belis, 2010</marker>
<rawString>Yazdani, M., Popescu-Belis, A. 2010. A random walk framework to compute textual semantic similarity: a unified model for three benchmark tasks. IEEE Fourth International Conference on Semantic Computing (ICSC), pp. 424-429</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Ye</author>
<author>B Peyser</author>
<author>X Pan</author>
<author>J Boek</author>
<author>F Spencer</author>
<author>J Bader</author>
</authors>
<title>Gene function prediction from congruent synthetic lethal interactions in yeast.</title>
<date>2005</date>
<booktitle>In Molecular system biology</booktitle>
<contexts>
<context position="1563" citStr="Ye et al., 2005" startWordPosition="217" endWordPosition="220">asets. 1 Introduction Semantic relatedness (SR) measures how much two (strings of) words or concepts are related by encompassing all kinds of relations between them (Strube and Ponzetto, 2006). It is more general than semantic similarity. SR is often an important pre-processing step to many complex Natural Language Processing (NLP) tasks, such as Word Sense Disambiguation (Leacock and Chodorow, 1998; Han and Zhao, 2010), and information retrieval (Finkelstein et al., 2002). In the biomedical domain, SR is an important technique for discovering gene functions and interactions (Wu et al., 2005; Ye et al., 2005). There is an abundant literature on measuring SR between words or concepts. Typically, these methods extract semantic evidence of words and concepts from a background knowledge source, with which their relatedness is assessed. The knowledge sources can be unstructured documents or (semi-)structured resources such as Wikipedia, WordNet, and domain specific ontologies (e.g., the Gene Ontology1). In this paper, we identify two issues that have not been addressed in the previous works. First, existing works typically employ a single knowledge source of semantic evidence. Research (Strube and Ponz</context>
</contexts>
<marker>Ye, Peyser, Pan, Boek, Spencer, Bader, 2005</marker>
<rawString>Ye, P., Peyser, B., Pan, X., Boek, J., Spencer, F., Bader, J. 2005. Gene function prediction from congruent synthetic lethal interactions in yeast. In Molecular system biology</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Yeh</author>
<author>D Ramage</author>
<author>C Manning</author>
<author>E Agirre</author>
<author>A Soroa</author>
</authors>
<title>WikiWalk: random walks on Wikipedia for semantic relatedness.</title>
<date>2009</date>
<booktitle>In Proceedings of the TextGraphs-4, Workshop on Graph-based Methods for Natural Language Processing, ACL2009</booktitle>
<contexts>
<context position="16149" citStr="Yeh et al., 2009" startWordPosition="2474" endWordPosition="2477">rnyms, hyponyms, meronyms, holonyms, synonyms, antonyms, attributes, “see also” words, “related” words, and gloss. These are also represented in the same way as in Figure 1. With unstructured sources, contextual words can be used as features. Alternatively, if a lexical network is extracted, features may be extracted in a similar way to those of WordNet. Additionally, with WordNet and Wikipedia, we also propose several intra-resource feature merging strategies to study the effect of feature diversification. This is because, while some approaches (such as Agirre et al., 2009; Harrington, 2010; Yeh et al., 2009) do not distinguish different feature types in graph construction, or adopt a bag-of-words feature representation (such as Zesch and Gurevych, 2010), others (such as Yazdani and Popescu-Belis, 2010; Zhang et al., 2010) have used differentiated 994 feature types and weights in their model. We therefore carry out studies to investigate this issue. Specifically, for the original four Wikipedia features, we create a bag-of-words feature that simply merges all feature types (i.e., all edges in Figure 1 will have the same label). For the original ten WordNet features, we propose two merged represent</context>
</contexts>
<marker>Yeh, Ramage, Manning, Agirre, Soroa, 2009</marker>
<rawString>Yeh, E., Ramage, D., Manning, C., Agirre, E., Soroa, A. 2009. WikiWalk: random walks on Wikipedia for semantic relatedness. In Proceedings of the TextGraphs-4, Workshop on Graph-based Methods for Natural Language Processing, ACL2009</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Zesch</author>
<author>I Gurevych</author>
</authors>
<title>Analysis of the Wikipedia category graph for NLP applications.</title>
<date>2007</date>
<booktitle>In Proceedings of the TextGraphs-2 Workshop (NAACL-HLT</booktitle>
<pages>1--8</pages>
<contexts>
<context position="29821" citStr="Zesch and Gurevych (2007)" startWordPosition="4701" endWordPosition="4704">ion values reported for our system in Tables 7 and 8. For all cases, a p-value of less than 0.001 is obtained, which indicates that correlation values are statistically significant. Tables 7 and 8 compare our method against stateof-the-art. For Table 8, figures for other state-ofthe-art systems can be found in corresponding publications; while we only list the best performing systems for comparison. 3 Rada (1989) (Rad89); Leacock and Chodorow (1998) (LC98); Wu and Palmer (1994) (WP04); Hirst and St-Onge (1998) (HS98); Resnik (1995) (Res95); Jiang and Conrath (1997) (JC97); Lin (1998) (Lin98); Zesch and Gurevych (2007) (ZG07); Gabrilovich and Markovitch (2007) (GM07); Zhang et al. (2010) (Zha10) 4 Petrakis et al. (2006) (Pet06); Pedersen et al. (2006) (Ped06). Original participating systems can be found in these works. 998 5 Discussion Single v.s. multiple knowledge sources As shown in Table 6, considering the best performances across all feature enrichment strategies and feature sets, the proposed method successfully harnessed different knowledge sources and improved over the baselines using single knowledge sources by 0.02 ~ 0.11. The biggest improvement (0.11) is on a domain-specific dataset, on which th</context>
</contexts>
<marker>Zesch, Gurevych, 2007</marker>
<rawString>Zesch, T., and Gurevych, I. 2007. Analysis of the Wikipedia category graph for NLP applications. In Proceedings of the TextGraphs-2 Workshop (NAACL-HLT 2007), pp. 1–8</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Zesch</author>
<author>I Gurevych</author>
</authors>
<title>Wisdom of crowds versus wisdom of linguists: measuring the semantic relatedness of words.</title>
<date>2010</date>
<journal>In Journal of Natural Language Engineering,</journal>
<volume>16</volume>
<pages>25--59</pages>
<contexts>
<context position="2199" citStr="Zesch and Gurevych, 2010" startWordPosition="309" endWordPosition="312">n abundant literature on measuring SR between words or concepts. Typically, these methods extract semantic evidence of words and concepts from a background knowledge source, with which their relatedness is assessed. The knowledge sources can be unstructured documents or (semi-)structured resources such as Wikipedia, WordNet, and domain specific ontologies (e.g., the Gene Ontology1). In this paper, we identify two issues that have not been addressed in the previous works. First, existing works typically employ a single knowledge source of semantic evidence. Research (Strube and Ponzetto, 2006; Zesch and Gurevych, 2010; Zhang et al., 2010) has shown that the accuracy of an SR method differs depending on the choice of the knowledge sources, and there is no conclusion which knowledge source is superior to others. Zhang et al. (2010) argue that this indicates different knowledge sources may complement each other. Second, the majority of SR methods have been evaluated in general domains only, except a few earlier WordNet-based methods that have been adapted to biomedical ontologies and evaluated in that domain (Lord et al., 2003; Pedersen et al., 2006; Pozo et al., 2008). Given the significant attention that SR</context>
<context position="8452" citStr="Zesch and Gurevych, 2010" startWordPosition="1256" endWordPosition="1259"> (Agirre et al., 2009). documents (Harrington, 2010; Wojtinnek and However, its effectiveness may be hindered by its Pulman, 2011) or (semi-)structured knowledge lack of coverage of specialized lexicons and 992 domain specific concepts (Strube and Ponzetto, 2006; Zhang et al., 2010). Wikipedia and Wiktionary are collaboratively maintained knowledge sources and therefore may overcome this limitation. Wikipedia in particular, is found to have reasonable coverage of many domains (Holloway et al., 2007; Halavais, 2008). It has become increasingly popular in SR studies recently. However, research (Zesch and Gurevych, 2010) have shown that methods based on Wikipedia have no clear advantage over WordNet-based methods on some general domain datasets in terms of accuracy, while Zhang et al. (2010) argue that different knowledge sources may complement each other, and SR methods may benefit from harnessing different knowledge sources. Several studies (Lord et al., 2003; Pedersen et al., 2006; Petrakis et al., 2006; Pozo et al., 2008) have adapted state-of-the-art to domain specific knowledge sources (e.g., the Gene Ontology, the MeSH2) and evaluated them therein. Despite these efforts, a large proportion of state-of-</context>
<context position="16297" citStr="Zesch and Gurevych, 2010" startWordPosition="2495" endWordPosition="2498">d in the same way as in Figure 1. With unstructured sources, contextual words can be used as features. Alternatively, if a lexical network is extracted, features may be extracted in a similar way to those of WordNet. Additionally, with WordNet and Wikipedia, we also propose several intra-resource feature merging strategies to study the effect of feature diversification. This is because, while some approaches (such as Agirre et al., 2009; Harrington, 2010; Yeh et al., 2009) do not distinguish different feature types in graph construction, or adopt a bag-of-words feature representation (such as Zesch and Gurevych, 2010), others (such as Yazdani and Popescu-Belis, 2010; Zhang et al., 2010) have used differentiated 994 feature types and weights in their model. We therefore carry out studies to investigate this issue. Specifically, for the original four Wikipedia features, we create a bag-of-words feature that simply merges all feature types (i.e., all edges in Figure 1 will have the same label). For the original ten WordNet features, we propose two merged representations corresponding to that of Wikipedia, so as to support the studies of feature enrichment in the following section. We introduce a bag-ofwords f</context>
<context position="24828" citStr="Zesch and Gurevych (2010)" startWordPosition="3852" endWordPosition="3855">n judgment (gold standard) on seven benchmarking datasets covering both general and technical domains. These include four general domain datasets: the Rubenstein and Goodenough (1965) dataset containing 65 pairs of nouns (RG65); the Miller and Charles (1991) dataset that is a subset of the RG-65 dataset and contains 30 pairs (MC30); the Finkelstein et al. (2002) dataset with 353 pairs of words, including nouns, verbs, adjectives, as well as named entities. This contains two subsets, a set of 153 pairs (Fin153) and a set of 200 (Fin200) pairs each annotated by a different groups of annotators. Zesch and Gurevych (2010) show largely varying Inter-Annotator-Agreement (IAA) between the two sets (Table 1), and argue that they should be treated as separate datasets. Three biomedical datasets are selected to evaluate domain-specific performance of the proposed method. These include a set of 36 MeSH term pairs in Petrakis et al. (2006) (MeSH36), 30 pairs of medical terms annotated by a group of physicians as in Pedersen et al. (2006) (Ped30-p) and the same set annotated by a different group of medical coders (Ped30-c). Table 1 shows statistics of the seven datasets. The correlation is computed using the Spearman r</context>
<context position="28638" citStr="Zesch and Gurevych, 2010" startWordPosition="4507" endWordPosition="4510">Table 6: Improvement achieved by harnessing multiple KSs. Best correlation with single KS is based on Wikipedia, which provides 100% coverage of word pairs. MC30 RG65 Fin153 Fin200 KS best of 0.8 0.74 0.75 0.54 Both WN+WK Rad89* 0.75 0.79 0.33 0.24 WN LC98* 0.75 0.79 0.33 0.24 WN WP94* 0.77 0.78 0.38 0.24 WN HS98* 0.76 0.79 0.33 0.32 WN Res95* 0.72 0.74 0.35 0.26 WN JC97* 0.68 0.58 0.28 0.10 WN Lin98* 0.67 0.60 0.27 0.17 WN Zes07* 0.77 0.82 0.6 0.51 WK GM07* 0.67 0.75 0.69 0.51 WK Zha10 0.71 0.76 0.71 0.46 WK Table 73: Comparison against state-of-the-art in the general domain. (* figures from Zesch and Gurevych, 2010) Ped30-p Ped30-c MeSH36 KS best of 0.64 0.67 0.75 WN+ WN+WK WK Pet06 best - - 0.74 MeSH Ped06 best 0.84 0.75 - GO, D Ped06 second 0.62 0.68 - GO, D Table 84: Comparison against state-of-the-art in the biomedical domain. GO – Gene Ontology; D – document sets. Given the fact that some datasets (i.e., MC30, Ped30-p, Ped30-c, MeSH36) have a relatively low sample size, we cannot always be sure that correlation values are accurate or occurred by chance. Therefore, we measure the statistical significance of correlation by computing the pvalue for the correlation values reported for our system in Tabl</context>
</contexts>
<marker>Zesch, Gurevych, 2010</marker>
<rawString>Zesch, T., Gurevych, I. 2010. Wisdom of crowds versus wisdom of linguists: measuring the semantic relatedness of words. In Journal of Natural Language Engineering, 16, pp. 25-59</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Zhang</author>
<author>A Gentile</author>
<author>L Xia</author>
<author>J Iria</author>
<author>S Chapman</author>
</authors>
<title>A random graph walk based approach to compute semantic relatedness using knowledge from Wikipedia.</title>
<date>2010</date>
<booktitle>In Proceedings of LREC’10.</booktitle>
<contexts>
<context position="2220" citStr="Zhang et al., 2010" startWordPosition="313" endWordPosition="316">easuring SR between words or concepts. Typically, these methods extract semantic evidence of words and concepts from a background knowledge source, with which their relatedness is assessed. The knowledge sources can be unstructured documents or (semi-)structured resources such as Wikipedia, WordNet, and domain specific ontologies (e.g., the Gene Ontology1). In this paper, we identify two issues that have not been addressed in the previous works. First, existing works typically employ a single knowledge source of semantic evidence. Research (Strube and Ponzetto, 2006; Zesch and Gurevych, 2010; Zhang et al., 2010) has shown that the accuracy of an SR method differs depending on the choice of the knowledge sources, and there is no conclusion which knowledge source is superior to others. Zhang et al. (2010) argue that this indicates different knowledge sources may complement each other. Second, the majority of SR methods have been evaluated in general domains only, except a few earlier WordNet-based methods that have been adapted to biomedical ontologies and evaluated in that domain (Lord et al., 2003; Pedersen et al., 2006; Pozo et al., 2008). Given the significant attention that SR has received in spec</context>
<context position="3759" citStr="Zhang et al., 2010" startWordPosition="550" endWordPosition="553">cific domains. The method combines and integrates semantic evidence of words or concepts extracted from any knowledge source in a generic graph representation, with which the SR between concepts or words is computed. Using two of the most popular general-domain knowledge sources, 1 http://www.geneontology.org/, last retrieved in Mar. 2011 991 Wikipedia and WordNet as examples, the method resources (Agirre et al., 2009; Gabrilovich and is evaluated on 7 benchmarking datasets, including Markovitch, 2007; Gouws et al., 2010; Zesch and three datasets from the biomedical domain and Gurevych, 2007; Zhang et al., 2010). Hybrid four from the general domain. It has achieved methods combine different purebred methods in excellent results: compared to the baselines that certain ways. For example Riensche et al. (2007) use each single knowledge sources, combining employ both an IC based method (Resnik, 1995) both knowledge sources has improved the accuracy and a statistical method (cosine vector similarity) on all datasets by 2~11%; compared to state-of- in their study. Pozo et al. (2008) derive a taxonomy the-art on the general domain datasets, the method of terms from unstructured documents by applying achieve</context>
<context position="8110" citStr="Zhang et al., 2010" startWordPosition="1208" endWordPosition="1211">documents (Chen et al., 2006; Cilibrasi and Conrath, 1997; Lin, 1998; Leacock and Chodorow Vitanyi, 2007; Matsuo et al., 2006), or 1998; Resnik, 1995; Seco et al., 2004; Wu and distributional concept or word vectors with Palmer, 1994) and is still a preferred knowledge features extracted from either unstructured source in recent works (Agirre et al., 2009). documents (Harrington, 2010; Wojtinnek and However, its effectiveness may be hindered by its Pulman, 2011) or (semi-)structured knowledge lack of coverage of specialized lexicons and 992 domain specific concepts (Strube and Ponzetto, 2006; Zhang et al., 2010). Wikipedia and Wiktionary are collaboratively maintained knowledge sources and therefore may overcome this limitation. Wikipedia in particular, is found to have reasonable coverage of many domains (Holloway et al., 2007; Halavais, 2008). It has become increasingly popular in SR studies recently. However, research (Zesch and Gurevych, 2010) have shown that methods based on Wikipedia have no clear advantage over WordNet-based methods on some general domain datasets in terms of accuracy, while Zhang et al. (2010) argue that different knowledge sources may complement each other, and SR methods ma</context>
<context position="14777" citStr="Zhang et al. (2010)" startWordPosition="2262" endWordPosition="2265">ocuments, a simple approach could be defining a word context as a text passage around each occurrence of w, and grouping similar contexts of w as representation of its underlying meanings, or concepts. Alternatively, more complex approaches such as Pozo et al. (2008) and Harrington (2010) may be applied to extract a lexical network of words, whereby similar methods to WordNet can be applied. 3.2 Feature extraction and representation Next, for each concept identified from a knowledge source, features are extracted from their corresponding contexts. In our case, for each , we follow the work by Zhang et al. (2010) to extract four types of features from their corresponding Wikipedia pages. Figure 1 shows an example representation of a concept and its Wikipedia features: • Words from page titles and redirection links (can be considered as synonyms) • Words from categories, used as higher level hypernyms in some studies (Zesch et al., 2010; Strube and Ponzetto, 2006) • Words from outgoing links • Top n most frequent words from a page Figure 1. Representation of the concept “cat, the mammal” using different types of features extracted from Wikipedia. The shaded circle represents the concept; ovals represen</context>
<context position="16367" citStr="Zhang et al., 2010" startWordPosition="2506" endWordPosition="2509">s can be used as features. Alternatively, if a lexical network is extracted, features may be extracted in a similar way to those of WordNet. Additionally, with WordNet and Wikipedia, we also propose several intra-resource feature merging strategies to study the effect of feature diversification. This is because, while some approaches (such as Agirre et al., 2009; Harrington, 2010; Yeh et al., 2009) do not distinguish different feature types in graph construction, or adopt a bag-of-words feature representation (such as Zesch and Gurevych, 2010), others (such as Yazdani and Popescu-Belis, 2010; Zhang et al., 2010) have used differentiated 994 feature types and weights in their model. We therefore carry out studies to investigate this issue. Specifically, for the original four Wikipedia features, we create a bag-of-words feature that simply merges all feature types (i.e., all edges in Figure 1 will have the same label). For the original ten WordNet features, we propose two merged representations corresponding to that of Wikipedia, so as to support the studies of feature enrichment in the following section. We introduce a bag-ofwords feature that collapses all different feature types, and a four-feature </context>
<context position="26007" citStr="Zhang et al. (2010)" startWordPosition="4039" endWordPosition="4042">elation is computed using the Spearman rank order coefficient for two reasons. First, it is a better metric than other alternatives (Zesch and Gurevych, 2010). Second, it is consistent with the majority of studies such that results can be compared. Dataset Size Domain IAA MC30 30 General 0.9 RG65 65 General 0.8 Fin153 153 General 0.73 Fin200 200 General 0.55 Ped30-p 30 Biomedical 0.68 Ped30-c 30 Biomedical 0.78 MeSH36 36 Biomedical - Table 1: Information of benchmarking datasets We distribute feature weights w(l) across different feature types L evenly in each feature representation. Although Zhang et al. (2010) show that discriminated feature weights leads to improved accuracy; this is not the focus of this study. Since we aim to investigate the effects of harnessing different knowledge sources, we obtained baseline performances by applying the method to those feature representations based on single knowledge sources (i.e., wk-4F, wk-1F, wn10F, wn-4F, wn-1F). Tables 2 and 3 show the best results obtained with baselines and corresponding knowledge sources and feature representation. Dataset Corr. Feature Coverage (% pairs) MC30 0.77 wn-1F 77% RG65 0.71 wn-1F 65% Fin153 0.45 wn-4F 82% Fin200 0.35 wn-4</context>
<context position="29891" citStr="Zhang et al. (2010)" startWordPosition="4711" endWordPosition="4714">ue of less than 0.001 is obtained, which indicates that correlation values are statistically significant. Tables 7 and 8 compare our method against stateof-the-art. For Table 8, figures for other state-ofthe-art systems can be found in corresponding publications; while we only list the best performing systems for comparison. 3 Rada (1989) (Rad89); Leacock and Chodorow (1998) (LC98); Wu and Palmer (1994) (WP04); Hirst and St-Onge (1998) (HS98); Resnik (1995) (Res95); Jiang and Conrath (1997) (JC97); Lin (1998) (Lin98); Zesch and Gurevych (2007) (ZG07); Gabrilovich and Markovitch (2007) (GM07); Zhang et al. (2010) (Zha10) 4 Petrakis et al. (2006) (Pet06); Pedersen et al. (2006) (Ped06). Original participating systems can be found in these works. 998 5 Discussion Single v.s. multiple knowledge sources As shown in Table 6, considering the best performances across all feature enrichment strategies and feature sets, the proposed method successfully harnessed different knowledge sources and improved over the baselines using single knowledge sources by 0.02 ~ 0.11. The biggest improvement (0.11) is on a domain-specific dataset, on which the method based on single knowledge source performed poorly in terms of</context>
<context position="33145" citStr="Zhang et al. (2010)" startWordPosition="5203" endWordPosition="5206"> for the input word pairs, whereby crosssource concept mapping becomes straightforward. In terms of feature enrichment strategies, there is no strong indication (Table 6) of which (feature combination v.s. integration) is more effective, although the system consistently outperforms the baselines (Table 4 v.s. Table 3) with the wk4F+wn-4F, Integration strategy. Feature diversification v.s. unification Table 5 suggests that in most cases, differentiating feature types leads to better results than merging them uniformly, despite the knowledge sources used. This is consistent with the findings by Zhang et al. (2010). This can be understandable since although unifying feature types effectively increases possibility of sharing features, equally, this may also increase the proportion of noisy features. For example, consider the Wikipedia article of “Horse” (animal), which has a category label “livestock”; and the article “Famine”, which has an outgoing link “livestock” (in a sentence describing diseases that caused decline of livestock production). By differentiating the feature types “has_category” and “has_outlink”, the two concepts will not be connected even if they both have the same word “livestock” in</context>
</contexts>
<marker>Zhang, Gentile, Xia, Iria, Chapman, 2010</marker>
<rawString>Zhang, Z., Gentile, A., Xia, L., Iria, J., Chapman, S. 2010. A random graph walk based approach to compute semantic relatedness using knowledge from Wikipedia. In Proceedings of LREC’10.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>