<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003301">
<title confidence="0.995181">
Robust Interaction through Partial Interpretation and Dialogue
Management
</title>
<author confidence="0.968193">
Arne J6nsson and Lena Strombacks
</author>
<affiliation confidence="0.869185">
Department of Computer and Information Science
Linkoping University, S - 58183 Linkoping, Sweden
</affiliation>
<email confidence="0.998599">
email: arj@ida.liu.se lestr@ida.liu.se
</email>
<sectionHeader confidence="0.99452" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.979719538461538">
In this paper we present results on developing ro-
bust natural language interfaces by combining shal-
low and partial interpretation with dialogue manage-
ment. The key issue is to reduce the effort needed
to adapt the knowledge sources for parsing and in-
terpretation to a necessary minimum. In the paper
we identify different types of information and present
corresponding computational models. The approach
utilizes an automatically generated lexicon which is
updated with information from a corpus of simulat-
ed dialogues. The grammar is developed manually
from the same knowledge sources. We also present
results from evaluations that support the approach.
</bodyText>
<sectionHeader confidence="0.998739" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999958958333333">
Relying on a traditional deep and complete
analysis of the utterances in a natural lan-
guage interface requires much effort on building
grammars and lexicons for each domain. An-
alyzing a whole utterance also gives problems
with robustness, since the grammars need to
cope with all possible variations of an utter-
ance. In this paper we present results on devel-
oping knowledge-based natural language inter-
faces for information retrieval applications uti-
lizing shallow and partial interpretation. Simi-
lar approaches are proposed in, for instance, the
work on flexible parsing (Carbonell and Hayes,
1987) and in speech systems (cf. (Sjtilander
and Gustafson, 1997; Bennacef et al., 1994)).
The interpretation is driven by the information
needed by the background system and guided
by expectations from a dialogue manager.
The analysis is done by parsing as small
parts of the utterance as possible. The infor-
mation needed by the interpretation module,
i.e. grammar and lexicon, is derived from the
database of the background system and infor-
mation from dialogues collected in Wizard of
</bodyText>
<listItem confidence="0.943479">
• Authors are in alphabetical order
</listItem>
<bodyText confidence="0.999289833333333">
Oz-experiments. We will present what types of
information that are needed for the interpreta-
tion modules. We will also report on the sizes
of the grammars and lexicon and results from
applying the approach to information retrieval
systems.
</bodyText>
<sectionHeader confidence="0.985161" genericHeader="introduction">
2 Dialogue management
</sectionHeader>
<bodyText confidence="0.99950815625">
Partial interpretation is particularly well-suited
for dialogue systems, as we can utilize informa-
tion from a dialogue manager on what is ex-
pected and use this to guide the analysis. Fur-
thermore, dialogue management allows for focus
tracking as well as clarification subdialogues to
further improve the interaction (J8nsson, 1997).
In information retrieval systems a common
user initiative is a request for domain concept
information from the database; users specify a
database object, or a set of objects, and ask
for the value of a property of that object or set
of objects. In the dialogue model this can be
modeled in two focal parameters: Objects relat-
ed to database objects and Properties modeling
the domain concept information. The Proper-
ties parameter models the domain concept in
a sub-parameter termed Aspect which can be
specified in another sub-parameter termed Val-
ue. The specification of these parameters in
turn depends on information from the user ini-
tiative together with context information and
the answer from the database system. The ac-
tion to be carried out by the interface for task-
related questions depends on the specification
of values passed to the Objects and Properties
parameters (Jonsson, 1997).
We can also distinguish two types of infor-
mation sources utilized by the dialogue manag-
er; the database with task information, T, or
system-related information about the applica-
tion, S.
</bodyText>
<page confidence="0.997454">
590
</page>
<sectionHeader confidence="0.873097" genericHeader="method">
3 Types of information
</sectionHeader>
<bodyText confidence="0.99995096">
We can identify different types of information
utilized when interpreting an utterance in a
natural language interface to a database sys-
tem. This information corresponds to the in-
formation that needs to be analyzed in user-
utterances.
Domain concepts are concepts about which
the system has information, mainly concepts
from the database, T, but also synonyms to such
concepts acquired, for instance, from the infor-
mation base describing the system, S.
In a database query system users also often
request information by relating concepts and
objects, e.g. which one is the cheapest. We
call this type of language constructions relation-
al expressions. The relational expressions can
be identified from the corpus.
Another common type of expressions are
numbers. Numbers can occur in various forms,
such as dates, object and property values.
Set operations. It is necessary to distinguish
utterances such as: show all cars costing less
than 70 000 from which of these costs less than
70 000. The former should get all cars costing
less than 70 000 whereas the latter should uti-
lize the set of cars recorded as Objects by the
dialogue manager. In some cases the user uses
expressions such as remove all cars more expen-
sive than 70 000, and thus is restricting a set by
mentioning the objects that should be removed.
Interactional concepts. This class of con-
cepts consists of words and phrases that concern
the interaction such as Yes, No, etc (cf. (Byron
and Heeman, 1997)).
Task/System expressions. Users can use do-
main concepts such as explain, indicating that
the domain concept is not referring to a request
for information from the database, T, but in-
stead from the system description, S.
When acquiring information for the interpreter,
three different sources of information can be uti-
lized: 1) background system information, i.e.
the database, T, and the information describ-
ing the background system&apos;s capabilities, S, 2)
information from dialogues collected with users
of the system, and 3) common sense and prior
knowledge on human-computer interaction and
natural language dialogue. The various infor-
mation sources can be used for different pur-
poses (JOnsson, 1993).
</bodyText>
<sectionHeader confidence="0.981003" genericHeader="method">
4 The interpretation module
</sectionHeader>
<bodyText confidence="0.999838795454545">
The approach we are investigating relies on an-
alyzing as small and crucial parts of the ut-
terances as possible. One of the key issues is
to find these parts. In some cases an analy-
sis could consist of one single domain or inter-
actional concept, but for most cases we need
to analyze small sub-phrases of an utterance to
get a more reliable analysis. This requires flex-
ibility in processing of the utterances and is a
further development of the ideas described in
Stromback (1994). In this work we have cho-
sen to use PATR-II but in the future construc-
tions from a more expressive formalism such as
EFLUF (Stromback, 1997) could be needed.
Flexibility in processing is achieved by one ex-
tension to ordinary PATR and some additions
to a chart parser environment. Our version of
PATR allows for a set of unknown words with-
in phrases. This gives general grammar rules,
and helps avoiding the analysis to be stuck in
case of unknown words. In the chart parsing
environment it is possible to define which of the
inactive edges that constitute the result.
The grammar is divided into five grammar
modules where each module corresponds to
some information requested by the dialogue
manager. The modules can be used indepen-
dently from each other.
Domain concepts are captured using two
grammar modules. The task of these grammars
is to find keywords or sub-phrases in the expres-
sions that correspond to the objects and prop-
erties in the database. The properties can be
concept keywords or relational expressions con-
taining concept keywords. Numbers are typed
according to the property they describe, e.g.
40000 denote a price.
To simplify the grammars we only require
that the grammar recognizes all objects and
properties mentioned. The results of the
analyses are filtered through the heuristics that
only the most specific objects are presented to
the dialogue manager.
Set operations. This grammar module
</bodyText>
<page confidence="0.989526">
591
</page>
<bodyText confidence="0.99993725">
provides a masker to tell the dialogue man-
ager what type of set operation the initiative
requests, new, old or restrict. The user&apos;s
utterance is searched for indicators of any of
these three set operators. If no indicators are
found we will assume that the operator is old.
The chart is searched for the first and largest
phrase that indicates a set operator.
</bodyText>
<subsectionHeader confidence="0.582483">
Recognizing interactional utterances.
</subsectionHeader>
<bodyText confidence="0.975622909090909">
Many interactional utterances are not nec-
essary to interpret for information retrieval
systems, such as Thank you. However, Yes/No-
expressions are important. They can be
recognized by looking for one of the keywords
yes or no. One example of this is the utterance
No, just the medium sized cars as an answer to
if the user wants to see all cars in a large table.
The Yes/No-grammar can conclude that it is
a no answer and the property grammar will
recognize the phrase medium sized cars.
System/Task recognition. Utterances
asking for information about a concept, e.g.
Explain the numbers for rust, can be distin-
guished from utterances requesting information
acquired from the background system How rust
prone are these cars by defining keywords with
a special meaning, such as explain. If any of
these keywords are found in an utterance the
dialogue manager will interpret the question as
system-related. If not it will assume that the
question is task-related.
</bodyText>
<sectionHeader confidence="0.963458" genericHeader="method">
5 An example
</sectionHeader>
<bodyText confidence="0.99704">
To illustrate the behaviour of the system con-
sider an utterance such as show cars costing less
than 100000 crowns. The word cars indicates
that the set operator is new. The relational
expression will be interpreted by the grammar
rules:
</bodyText>
<figure confidence="0.900144">
relprop -&gt; property :
0 properties = 1 properties
relprop -&gt; property comp glue entity :
0 properties = 1 properties :
O properties = 2 properties :
0 properties = 4 properties :
O properties value erg = 4 value .
</figure>
<bodyText confidence="0.950743642857143">
This results in two analyses [Aspect: price]
and [Aspect: price, Value: [Relation: less, Arg:
100000]] which, when filtered by the heuristics,
present the latter, the most specific analysis, to
the dialogue manager. The dialogue manager
inspects the result and as it is a valid database
request forwards it to the background system.
However, too many objects satisfy the request
and the dialogue manager initiates a clarifica-
tion request to the user to further specify the
request. The user responds with remove audi
1985 and 1988. The keyword remove triggers
the set operator restrict and the objects are in-
terpreted by the rules:
</bodyText>
<equation confidence="0.4860436">
object -&gt; manufacturer :
O object = 1 object .
object -&gt; manufacturer * 2 year :
O object = 1 object :
O object year = 2 year .
</equation>
<bodyText confidence="0.9925985">
This results in three objects [Manufacturer:
audi], [Manufacturer: audi, Year: 1985] and
[Manufacturer: audi, Year: 1988]. When filtered
the first interpretation is removed. This is in-
tegrated by the dialogue manager to provide
a specification on both Objects and Properties
which is passed to the background system and
a correct response can be provided.
</bodyText>
<sectionHeader confidence="0.6908845" genericHeader="method">
6 Empirical evidence for the
approach
</sectionHeader>
<bodyText confidence="0.9988416">
In this section we present results on partial in-
terpretation&apos; for a natural language interface for
the CARS-application; a system for typed inter-
action to a relational database with information
on second hand cars. The corpus contains 300
utterances from 10 dialogues. Five dialogues
from the corpus were used when developing the
interpretation methods, the Development set,
and five dialogues were used for evaluation, the
Test set.
</bodyText>
<subsectionHeader confidence="0.810894">
6.1 Results
</subsectionHeader>
<bodyText confidence="0.9915196">
The lexicon includes information on what type
of entity a keyword belongs to, i.e. Objects
or Properties. This information is acquired au-
tomatically from the database with synonyms
added manually from the background system
description.
The automatically generated lexicon of con-
cepts consists of 102 entries describing Objects
&apos;Results on dialogue management has been presented
in JOnsson (1997).
</bodyText>
<page confidence="0.998646">
592
</page>
<tableCaption confidence="0.999591">
Table 1: Precision and recall for the grammars
</tableCaption>
<table confidence="0.992012384615385">
Yes/No SIT Set
Devel. set 100% 100% 97,5%
Test set 100% 91,7% 86,1%
Objects
Fully
Recall Precision
Devel. set 100% 98%
Test set 94,1% 80%
Properties
Fully
Recall Precision
Devel. set 97% 97%
Test set 59,6% 73,9%
</table>
<bodyText confidence="0.999352081081081">
and Properties. From the system description in-
formation base 23 synonyms to concepts in the
database were added to the lexicon. From the
Development set another 7 synonyms to con-
cepts in the database, 12 relational concepts and
7 markers were added.
The five grammars were developed manually
from the Development set. The object gram-
mar consists of 5 rules and the property gram-
mar consists of 21 rules. The grammar used
for finding set indicators consists of 13 rules.
The Yes/No grammar and System/Task gram-
mar need no grammar rules. The time for devel-
oping these grammars is estimated to a couple
of days.
The obtained grammars and the lexicon of to-
tally 151 entries were tested on both the Devel-
opment set and on the five new dialogues in the
Test set. The results are presented in table 1. In
the first half of the table we present the number
of utterances where the Yes/No, System/Task
and Set parameters were correctly classified. In
the second we present recall and precision for
Objects and Properties.
We have distinguished fully correct inter-
pretations from partially correct. A partially
correct interpretation provides information on
the Aspect but might fail to consider Value-
restrictions, e.g. provide the Aspect value price
but not the Value-restriction cheapest to an ut-
terance such as what is the price of the cheapest
volvo. This is because cheapest was not in the
first five dialogues.
The majority of the problems are due to such
missing concepts. We therefore added informa-
tion from the Test set. This set provided anoth-
er 4 concepts, 2 relational concepts, and 1 mark-
</bodyText>
<tableCaption confidence="0.8774545">
Table 2: Precision and recall when concepts
from the test set were added
</tableCaption>
<table confidence="0.550974">
Properties
Fully Partial
Recall Precision Recall Precision
Test set 92,3% 79,5% 93,8% 90,6%
</table>
<bodyText confidence="0.99879675">
er and led us to believe that we have reached a
fairly stable set of concepts. Adding these rela-
tional and domain concepts increased the cor-
rect recognition of set operations to 95,8%. It
also increased the numbers for Properties recall
and precision, as seen in table 2. The other re-
sults remained unchanged.
To verify the hypothesis that the concepts are
conveyed from the database and a small number
of dialogues, we analyzed another 10 dialogues
from the same setting but where the users know
that a human interprets their utterance. From
these ten dialogues only another 3 concepts and
1 relational concept were identified. Further-
more, the concepts are borderline cases, such as
mapping the concept inside measurement onto
the database property coupe, which could well
result in a system-related answer if not added
to the lexicon.
As a comparison to this a traditional non-
partial PATR-grammar, developed for good
coverage on only one of the dialogues consists of
about 200 rules. The lexicon needed to cover all
ten dialogues consists of around 470 words, to
compare with the 158 of the lexicon used here.
The principles have also been evaluated on
a system with information on charter trips to
the Greek archipelago, TRAVEL. This corpus
contains 540 utterances from 10 dialogues. The
information base for TRAVEL consists of texts
from travel brochures which contains a lot of
information. It includes a total of around 750
different concepts. Testing this lexicon on the
corpus of ten dialogues 20 synonyms were found.
When tested on a set of ten dialogues collected
with users who knew it was a simulation (cf. the
CARS corpus) another 10 synonyms were found.
Thus 99% of the concepts utilized in this part of
the corpus were captured from the information
base and the first ten dialogues. This clearly
supports the hypothesis that the relevant con-
cepts can be captured from the background sys-
tem and a fairly small number of dialogues.
For the TRAVEL application we have also es-
</bodyText>
<figure confidence="0.998193375">
Partial
Recall Precision
100% 98%
100% 85%
Partial
Recall Precision
99% 100%
73,7% 91,3%
</figure>
<page confidence="0.997404">
593
</page>
<bodyText confidence="0.99984125">
timated how many of the utterances in the cor-
pus that can be analyzed by this model. 90,4%
of the utterances can easily be captured by the
model. Of the remaining utterances 4,3% are
partly outside the task of the system and a stan-
dard system message would be a sufficient re-
sponse. This leaves only 4,8% of the utterances
that can not be handled by the approach.
</bodyText>
<subsectionHeader confidence="0.976213">
6.2 Discussion
</subsectionHeader>
<bodyText confidence="0.999965379310345">
When processing data from the dialogues we
have used a system for lexical error recov-
ery, which corrects user mistakes such as mis-
spellings, and segmentation errors. This system
utilizes a trained HMM and accounts for most
errors (IngeIs, 1996). In the results on lexical
data presented above we have assumed a system
for morphological analysis to handle inflections
and compounds.
The approach does not handle anaphora.
This can result in erroneous responses, for in-
stance, Show rust for the mercedes will interpret
the mercedes as a new set of cars and the answer
will contain all mercedeses not only those in the
previous discourse. In the applications studied
here this is not a serious problem. However,
for other applications it can be important to
handle such expressions correctly. One possible
solution is to interpret definite form of object
descriptions as a marker for an old set.
The application of the method have only uti-
lized information acquired from the database,
from information on the system&apos;s capabilities
and from corpus information. The motivation
for this was that we wanted to use unbiased
information sources. In practice, however, one
would like to augment this with common sense
knowledge on human-computer interaction as
discussed in Jonsson (1993).
</bodyText>
<sectionHeader confidence="0.999233" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.999908785714286">
We have presented a method for robust inter-
pretation based on a generalization of PATR-II
which allows for generalization of grammar rules
and partial parsing. This reduces the sizes of
the grammar and lexicon which results in re-
duced development time and faster computa-
tion. The lexical entries corresponding to en-
tities about which a user can achieve informa-
tion is mainly automatically created from the
background system. Furthermore, the system
will be fairly robust as we can invest time on
establishing a knowledge base corresponding to
most ways in which a user can express a domain
concept.
</bodyText>
<sectionHeader confidence="0.998643" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99989325">
This work results from a number of projects on de-
velopment of natural language interfaces supported
by The Swedish Transport St Communications Re-
search Board (KFB) and the joint Research Pro-
gram for Language Technology (HSFR/NUTEK).
We are indebted to Hanna Benjaminsson and Magne
Hansen for work on generating the lexicon and de-
veloping the parser.
</bodyText>
<sectionHeader confidence="0.999431" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999745097560976">
S. Bennacef, H. Bonneau-Maynard, J. L. Gauvin,
L. Lamel, and W. Minker. 1994. A spoken lan-
guage system for information retrieval. In Pro-
ceedings of ICLSP&apos;94.
Donna K. Byron and Peter A. Heeman. 1997. Dis-
course marker use in task-oriented spoken dialog.
In Proceedings of Eurospeech&apos;97, Rhodes, Greece,
pages 2223-2226.
Jaime G. Carbonell and Philip J. Hayes. 1987. Ro-
bust parsing using multiple construction-specific
strategies. In Leonard Bole, editor, Natural Lan-
guage Parsing Systems, pages 1-32. Springer-
Verlag.
Peter Ingels. 1996. Connected text recognition us-
ing layered HMMs and token passing. In K. Oflaz-
er and H. Somers, editors, Proceedings of the
Second Conference on New Methods in Language
Processing, pages 121-132, Sept.
Arne J8nsson. 1993. A method for development of
dialogue managers for natural language interfaces.
In Proceedings of the Eleventh National Confer-
ence of Artificial Intelligence, Washington DC,
pages 190-195.
Arne Jonsson. 1997. A model for habitable and
efficient dialogue management for natural lan-
guage interaction. Natural Language Engineering,
3(2/3):103-122.
Ka&apos;re Sjolander and Joakim Gustafson. 1997. An in-
tegrated system for teaching spoken dialogue sys-
tems technology. In Proceedings of Eurospeech&apos;97,
Rhodes, Greece, pages 1927-1930.
Lena Stromback. 1994. Achieving flexibility in uni-
fication formalisms. In Proceedings of 15th Int.
Conf. on Computational Linguistics (Coling &apos;94),
volume II, pages 842-846, August. Kyoto, Japan.
Lena Stromback. 1997. EFLUF - an implementa-
tion of a flexible unification formalism. In Proc
of ENVGRAM - Computational Environments
for Practical Grammar Development, Processing
and Integration with other NLP modules., July.
Madrid, Spain.
</reference>
<page confidence="0.998462">
594
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.901475">
<title confidence="0.9944685">Robust Interaction through Partial Interpretation and Dialogue Management</title>
<author confidence="0.995775">Arne Jnsson</author>
<author confidence="0.995775">Lena Strombacks</author>
<affiliation confidence="0.999944">Department of Computer and Information Science</affiliation>
<address confidence="0.9412">Linkoping University, S - 58183 Linkoping, Sweden</address>
<email confidence="0.986104">arj@ida.liu.selestr@ida.liu.se</email>
<abstract confidence="0.998898857142857">In this paper we present results on developing robust natural language interfaces by combining shallow and partial interpretation with dialogue management. The key issue is to reduce the effort needed to adapt the knowledge sources for parsing and interpretation to a necessary minimum. In the paper we identify different types of information and present corresponding computational models. The approach utilizes an automatically generated lexicon which is updated with information from a corpus of simulated dialogues. The grammar is developed manually from the same knowledge sources. We also present results from evaluations that support the approach.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Bennacef</author>
<author>H Bonneau-Maynard</author>
<author>J L Gauvin</author>
<author>L Lamel</author>
<author>W Minker</author>
</authors>
<title>A spoken language system for information retrieval.</title>
<date>1994</date>
<booktitle>In Proceedings of ICLSP&apos;94.</booktitle>
<contexts>
<context position="1604" citStr="Bennacef et al., 1994" startWordPosition="234" endWordPosition="237">tterances in a natural language interface requires much effort on building grammars and lexicons for each domain. Analyzing a whole utterance also gives problems with robustness, since the grammars need to cope with all possible variations of an utterance. In this paper we present results on developing knowledge-based natural language interfaces for information retrieval applications utilizing shallow and partial interpretation. Similar approaches are proposed in, for instance, the work on flexible parsing (Carbonell and Hayes, 1987) and in speech systems (cf. (Sjtilander and Gustafson, 1997; Bennacef et al., 1994)). The interpretation is driven by the information needed by the background system and guided by expectations from a dialogue manager. The analysis is done by parsing as small parts of the utterance as possible. The information needed by the interpretation module, i.e. grammar and lexicon, is derived from the database of the background system and information from dialogues collected in Wizard of • Authors are in alphabetical order Oz-experiments. We will present what types of information that are needed for the interpretation modules. We will also report on the sizes of the grammars and lexico</context>
</contexts>
<marker>Bennacef, Bonneau-Maynard, Gauvin, Lamel, Minker, 1994</marker>
<rawString>S. Bennacef, H. Bonneau-Maynard, J. L. Gauvin, L. Lamel, and W. Minker. 1994. A spoken language system for information retrieval. In Proceedings of ICLSP&apos;94.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donna K Byron</author>
<author>Peter A Heeman</author>
</authors>
<title>Discourse marker use in task-oriented spoken dialog.</title>
<date>1997</date>
<booktitle>In Proceedings of Eurospeech&apos;97,</booktitle>
<pages>2223--2226</pages>
<location>Rhodes, Greece,</location>
<contexts>
<context position="5209" citStr="Byron and Heeman, 1997" startWordPosition="820" endWordPosition="823">erations. It is necessary to distinguish utterances such as: show all cars costing less than 70 000 from which of these costs less than 70 000. The former should get all cars costing less than 70 000 whereas the latter should utilize the set of cars recorded as Objects by the dialogue manager. In some cases the user uses expressions such as remove all cars more expensive than 70 000, and thus is restricting a set by mentioning the objects that should be removed. Interactional concepts. This class of concepts consists of words and phrases that concern the interaction such as Yes, No, etc (cf. (Byron and Heeman, 1997)). Task/System expressions. Users can use domain concepts such as explain, indicating that the domain concept is not referring to a request for information from the database, T, but instead from the system description, S. When acquiring information for the interpreter, three different sources of information can be utilized: 1) background system information, i.e. the database, T, and the information describing the background system&apos;s capabilities, S, 2) information from dialogues collected with users of the system, and 3) common sense and prior knowledge on human-computer interaction and natura</context>
</contexts>
<marker>Byron, Heeman, 1997</marker>
<rawString>Donna K. Byron and Peter A. Heeman. 1997. Discourse marker use in task-oriented spoken dialog. In Proceedings of Eurospeech&apos;97, Rhodes, Greece, pages 2223-2226.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jaime G Carbonell</author>
<author>Philip J Hayes</author>
</authors>
<title>Robust parsing using multiple construction-specific strategies.</title>
<date>1987</date>
<booktitle>Natural Language Parsing Systems,</booktitle>
<pages>1--32</pages>
<editor>In Leonard Bole, editor,</editor>
<publisher>SpringerVerlag.</publisher>
<contexts>
<context position="1521" citStr="Carbonell and Hayes, 1987" startWordPosition="221" endWordPosition="224">e approach. 1 Introduction Relying on a traditional deep and complete analysis of the utterances in a natural language interface requires much effort on building grammars and lexicons for each domain. Analyzing a whole utterance also gives problems with robustness, since the grammars need to cope with all possible variations of an utterance. In this paper we present results on developing knowledge-based natural language interfaces for information retrieval applications utilizing shallow and partial interpretation. Similar approaches are proposed in, for instance, the work on flexible parsing (Carbonell and Hayes, 1987) and in speech systems (cf. (Sjtilander and Gustafson, 1997; Bennacef et al., 1994)). The interpretation is driven by the information needed by the background system and guided by expectations from a dialogue manager. The analysis is done by parsing as small parts of the utterance as possible. The information needed by the interpretation module, i.e. grammar and lexicon, is derived from the database of the background system and information from dialogues collected in Wizard of • Authors are in alphabetical order Oz-experiments. We will present what types of information that are needed for the </context>
</contexts>
<marker>Carbonell, Hayes, 1987</marker>
<rawString>Jaime G. Carbonell and Philip J. Hayes. 1987. Robust parsing using multiple construction-specific strategies. In Leonard Bole, editor, Natural Language Parsing Systems, pages 1-32. SpringerVerlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Ingels</author>
</authors>
<title>Connected text recognition using layered HMMs and token passing.</title>
<date>1996</date>
<booktitle>Proceedings of the Second Conference on New Methods in Language Processing,</booktitle>
<pages>121--132</pages>
<editor>In K. Oflazer and H. Somers, editors,</editor>
<marker>Ingels, 1996</marker>
<rawString>Peter Ingels. 1996. Connected text recognition using layered HMMs and token passing. In K. Oflazer and H. Somers, editors, Proceedings of the Second Conference on New Methods in Language Processing, pages 121-132, Sept.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arne J8nsson</author>
</authors>
<title>A method for development of dialogue managers for natural language interfaces.</title>
<date>1993</date>
<booktitle>In Proceedings of the Eleventh National Conference of Artificial Intelligence,</booktitle>
<pages>190--195</pages>
<location>Washington DC,</location>
<marker>J8nsson, 1993</marker>
<rawString>Arne J8nsson. 1993. A method for development of dialogue managers for natural language interfaces. In Proceedings of the Eleventh National Conference of Artificial Intelligence, Washington DC, pages 190-195.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arne Jonsson</author>
</authors>
<title>A model for habitable and efficient dialogue management for natural language interaction.</title>
<date>1997</date>
<journal>Natural Language Engineering,</journal>
<pages>3--2</pages>
<contexts>
<context position="3526" citStr="Jonsson, 1997" startWordPosition="543" endWordPosition="544">modeled in two focal parameters: Objects related to database objects and Properties modeling the domain concept information. The Properties parameter models the domain concept in a sub-parameter termed Aspect which can be specified in another sub-parameter termed Value. The specification of these parameters in turn depends on information from the user initiative together with context information and the answer from the database system. The action to be carried out by the interface for taskrelated questions depends on the specification of values passed to the Objects and Properties parameters (Jonsson, 1997). We can also distinguish two types of information sources utilized by the dialogue manager; the database with task information, T, or system-related information about the application, S. 590 3 Types of information We can identify different types of information utilized when interpreting an utterance in a natural language interface to a database system. This information corresponds to the information that needs to be analyzed in userutterances. Domain concepts are concepts about which the system has information, mainly concepts from the database, T, but also synonyms to such concepts acquired,</context>
</contexts>
<marker>Jonsson, 1997</marker>
<rawString>Arne Jonsson. 1997. A model for habitable and efficient dialogue management for natural language interaction. Natural Language Engineering, 3(2/3):103-122.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ka&apos;re Sjolander</author>
<author>Joakim Gustafson</author>
</authors>
<title>An integrated system for teaching spoken dialogue systems technology.</title>
<date>1997</date>
<booktitle>In Proceedings of Eurospeech&apos;97,</booktitle>
<pages>1927--1930</pages>
<location>Rhodes, Greece,</location>
<marker>Sjolander, Gustafson, 1997</marker>
<rawString>Ka&apos;re Sjolander and Joakim Gustafson. 1997. An integrated system for teaching spoken dialogue systems technology. In Proceedings of Eurospeech&apos;97, Rhodes, Greece, pages 1927-1930.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lena Stromback</author>
</authors>
<title>Achieving flexibility in unification formalisms.</title>
<date>1994</date>
<booktitle>In Proceedings of 15th Int. Conf. on Computational Linguistics (Coling &apos;94), volume II,</booktitle>
<pages>842--846</pages>
<location>Kyoto, Japan.</location>
<contexts>
<context position="6421" citStr="Stromback (1994)" startWordPosition="1019" endWordPosition="1020">tural language dialogue. The various information sources can be used for different purposes (JOnsson, 1993). 4 The interpretation module The approach we are investigating relies on analyzing as small and crucial parts of the utterances as possible. One of the key issues is to find these parts. In some cases an analysis could consist of one single domain or interactional concept, but for most cases we need to analyze small sub-phrases of an utterance to get a more reliable analysis. This requires flexibility in processing of the utterances and is a further development of the ideas described in Stromback (1994). In this work we have chosen to use PATR-II but in the future constructions from a more expressive formalism such as EFLUF (Stromback, 1997) could be needed. Flexibility in processing is achieved by one extension to ordinary PATR and some additions to a chart parser environment. Our version of PATR allows for a set of unknown words within phrases. This gives general grammar rules, and helps avoiding the analysis to be stuck in case of unknown words. In the chart parsing environment it is possible to define which of the inactive edges that constitute the result. The grammar is divided into fiv</context>
</contexts>
<marker>Stromback, 1994</marker>
<rawString>Lena Stromback. 1994. Achieving flexibility in unification formalisms. In Proceedings of 15th Int. Conf. on Computational Linguistics (Coling &apos;94), volume II, pages 842-846, August. Kyoto, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lena Stromback</author>
</authors>
<title>EFLUF - an implementation of a flexible unification formalism.</title>
<date>1997</date>
<booktitle>In Proc of ENVGRAM - Computational Environments for Practical Grammar Development, Processing and Integration with other NLP modules.,</booktitle>
<location>Madrid,</location>
<contexts>
<context position="6562" citStr="Stromback, 1997" startWordPosition="1045" endWordPosition="1046">approach we are investigating relies on analyzing as small and crucial parts of the utterances as possible. One of the key issues is to find these parts. In some cases an analysis could consist of one single domain or interactional concept, but for most cases we need to analyze small sub-phrases of an utterance to get a more reliable analysis. This requires flexibility in processing of the utterances and is a further development of the ideas described in Stromback (1994). In this work we have chosen to use PATR-II but in the future constructions from a more expressive formalism such as EFLUF (Stromback, 1997) could be needed. Flexibility in processing is achieved by one extension to ordinary PATR and some additions to a chart parser environment. Our version of PATR allows for a set of unknown words within phrases. This gives general grammar rules, and helps avoiding the analysis to be stuck in case of unknown words. In the chart parsing environment it is possible to define which of the inactive edges that constitute the result. The grammar is divided into five grammar modules where each module corresponds to some information requested by the dialogue manager. The modules can be used independently </context>
</contexts>
<marker>Stromback, 1997</marker>
<rawString>Lena Stromback. 1997. EFLUF - an implementation of a flexible unification formalism. In Proc of ENVGRAM - Computational Environments for Practical Grammar Development, Processing and Integration with other NLP modules., July. Madrid, Spain.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>