<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.022346">
<title confidence="0.987582">
AMBRA: A Ranking Approach to Temporal Text Classification
</title>
<author confidence="0.997495">
Marcos Zampieri1,2, Alina Maria Ciobanu3, Vlad Niculae4, Liviu P. Dinu3
</author>
<affiliation confidence="0.99586125">
Saarland University, Germany1
German Research Center for Artificial Intelligence (DFKI), Germany2
Center for Computational Linguistics, University of Bucharest, Romania3
Deptartment of Computer Science, Cornell University, USA4
</affiliation>
<email confidence="0.992612">
marcos.zampieri@uni-saarland.de; alina.ciobanu@my.fmi.unibuc.ro;
vn66@cornell.edu; ldinu@fmi.unibuc.ro;
</email>
<sectionHeader confidence="0.995617" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999059388888889">
This paper describes the AMBRA system,
entered in the SemEval-2015 Task 7: ‘Di-
achronic Text Evaluation’ subtasks one and
two, which consist of predicting the date when
a text was originally written. The task is
valuable for applications in digital humani-
ties, information systems, and historical lin-
guistics. The novelty of this shared task con-
sists of incorporating label uncertainty by as-
signing an interval within which the document
was written, rather than assigning a clear time
marker to each training document. To deal
with non-linear effects and variable degrees
of uncertainty, we reduce the problem to pair-
wise comparisons of the form is Document A
older than Document B?, and propose a non-
parametric way to transform the ordinal output
into time intervals.
</bodyText>
<sectionHeader confidence="0.999" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999841260869565">
Temporal text classification consists of learning to
automatically predict the publication date of docu-
ments, by using the information contained in their
textual content. The task finds uses in fields as var-
ied as digital humanities, where many texts have are
unidentified or controversial publication dates, in-
formation retrieval (Dakka et al., 2012), where tem-
poral constraints can improve relevance, and his-
torical linguistics, where the interpretation of the
learned models can confirm and reveal insights.
From a technical point of view, the task is usu-
ally tackled either as regression or, more commonly,
as a single-label multi-class problem, with classes
defined as time intervals such as months, years,
decades or centuries. The regression approach as-
sumes that precise timestamps are uniformly avail-
able for each document, which is suitable for cases
of social media documents (Preotiuc-Pietro, 2014),
but less suitable for documents surrounded by more
uncertainty. Multi-class classification, on the other
hand, suffers from a coarseness tradeoff: using
coarser classes is less informative, and using finer
classes reduces the number of training instances in
each class, making the problem more difficult. Fur-
thermore, with a multi-class formulation, the tempo-
ral relationship between classes is lost.
The ‘Diachronic Text Evaluation’ subtasks one
and two from SemEval-2015 are formulated simi-
larly to a multi-class problem, where each document
is assigned to an interval such as 1976-1982. To
accommodate such labels, we propose an approach
based on pairwise comparisons. We train a classi-
fier to learn which document out of a pair is older
and which is newer. If two documents come from
overlapping intervals, then their order cannot be de-
termined with certainty, so the pair is not used in
training. We use the property of linear models to ex-
tend a set of pairwise decisions into a ranking of test
documents (Joachims, 2006).
While previous work uses a regression-based
method to map the ranking back to actual times-
tamps, we propose a novel non-parametric method
to choose the most likely interval. In light of this,
our system is named AMBRA (Anachronism Mod-
eling by Ranking). Our implementation is available
under a permissive open-source license.1
</bodyText>
<footnote confidence="0.991041">
1https://github.com/vene/ambra
</footnote>
<page confidence="0.94147">
851
</page>
<note confidence="0.618235">
Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 851–855,
Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics
</note>
<sectionHeader confidence="0.999018" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999941372881356">
An important class of models for temporal classifi-
cation employs prototype-based classification meth-
ods, using probabilistic language models and dis-
tances in distribution space to classify documents to
the time period with the most similar language (de
Jong et al., 2005; Kumar et al., 2011). Kanhabua
and NOrv˚ag (2009) use temporal language models
to assign timestamps to unlabeled documents.
An extension of such models for continuous time
is proposed by Wang et al. (2008), who use Brow-
nian motion as a model for topic change over time.
This approach is simpler and faster than the discrete
time version, but it cannot be directly applied to doc-
uments with different degrees of label uncertainty,
such as interval labels.
Dalli and Wilks (2006) train a classifier to date
texts within a time span of nine years. The method
uses lexical features and it is aided by words whose
frequencies increase at some point in time, most
notably named entities. Abe and Tsumoto (2010)
propose similarity metrics to categorise texts based
on keywords calculated by indexes such as tf-idf.
Garcia-Fernandez et al. (2011) explore different
NLP techniques on a digitized collection of French
texts published between 1801 and 1944. Style-
related markers and features, including readability
features, have been shown to reveal temporal infor-
mation in English as well as Portuguese (Stamou,
2005; ˇStajner and Zampieri, 2013).
An intersecting research direction combines di-
atopic (regional) and diachronic variation for French
journalistic texts (Grouin et al., 2010) and for the
Dutch Folktale Database, which includes texts from
different dialects and varieties of Dutch, as well as
historical texts (Trieschnigg et al., 2012).
More recently, Ciobanu et al. (2013) propose su-
pervised classification with unigram features with
χ2 feature selection on a collection of historical Ro-
manian texts, noting that the informative features are
words having changed form over time. Niculae et al.
(2014) circumvent the limitations of supervised clas-
sification by posing the problem as ordinal regres-
sion with a learning-to-rank approach. They evalu-
ate their method on datasets in English, Portuguese
and Romanian. The superior flexibility of the rank-
ing approach makes it a better fit for the problem for-
mulation of the ‘Diachronic Text Evaluation’ task,
motivating us to base our implementation on it.
A different, but related, problem is to model and
understand how words usage and meaning change
over time. Wijaya and Yeniterzi (2011) use the
Google NGram corpus aiming to identify clusters
of topics surrounding the word over time. Mihal-
cea and Nastase (2012) split the Google Books cor-
pus into three wide epochs and introduce the task of
word epoch disambiguation. Turning this problem
around, Popescu and Strapparava (2013) use a sim-
ilar approach to statistically characterize epochs by
lexical and emotion features.
</bodyText>
<sectionHeader confidence="0.998846" genericHeader="method">
3 Methods
</sectionHeader>
<bodyText confidence="0.999744">
The ‘Diachronic Text Evaluation’ shared task con-
sists of three subtasks (Popescu and Strapparava,
2015): classification of documents containing ex-
plicit references to time-specific persons or events
(T1), classification of documents with time-specific
language use (T2), and recognition of time-specific
expressions (T3). The AMBRA system participated
in T1 and T2.
</bodyText>
<subsectionHeader confidence="0.998586">
3.1 Corpus
</subsectionHeader>
<bodyText confidence="0.999921176470589">
The training data released for the shared task con-
sists of 323 documents for T1 and 4,202 documents
for T2. Each document has a paragraph containing,
on average, 71 tokens, along with a tag indicating
when each text was written/published. The publica-
tion date of texts is indicated by time intervals at all
three granularity levels: fine-, medium- and coarse-
grained (e.g. &lt;textM yes=&amp;quot;1695-1707&amp;quot;&gt; for
a text written between the years 1695 and 1707 in
the medium-grained representation).
The shared task mentions no limitation regarding
the use of external corpora. Nevertheless, to avoid
thematic bias, we use only the corpora provided by
the organizers under the assumption that the test and
training sets are sampled from the same distribution.
The released test set consists of 267 instances for
T1 and 1,041 instances for T2.
</bodyText>
<subsectionHeader confidence="0.99914">
3.2 Algorithm and Features
</subsectionHeader>
<bodyText confidence="0.999633666666667">
We use a ranking approach by pairwise compar-
isons, previously proposed for temporal text mod-
eling by Niculae et al. (2014) .
</bodyText>
<page confidence="0.991521">
852
</page>
<bodyText confidence="0.980657294117647">
Learning. The model learns a linear function
g(x) = w • x to preserve the temporal ordering of
the texts, i.e. if document2 xi predates document
xj, which we will henceforth denote as xi --&lt; xj,
then g(xi) &lt; g(xj). This step can be understood
as learning to rank texts from older to newer. By
making pairwise comparisons, the problem can be
reduced to binary classification using a linear model.
A dataset annotated with intervals has the form
D = {(x, [yfirst, ylast)]} where yfirst &lt; ylast are the
years between which document x was written. Doc-
ument xi can be said to predate document xj only if
its interval predates the other without overlap:
last first
xi --&lt; xj yi &lt; yj .
This allows us to construct a dataset consisting only
of correctly-ordered pairs:
</bodyText>
<equation confidence="0.814981666666667">
Dp = {(xi, xj) : xi --&lt; xj}.
This reduces to linear binary classification:
w•xi &lt;w•xj #==&gt;- w - (xi − xj) &lt; 0.
</equation>
<bodyText confidence="0.977970882352941">
We form a balanced training set by flipping the order
of half of the pairs in Dp at random.
Prediction. Niculae et al. (2014), following Pe-
dregosa et al. (2012), fit a monotonic function map-
ping from years to the space spanned by the learned
linear model. In contrast, to better deal with the
interval formulation, we propose a non-parametric
memory-based approach. After training, we store:
Dscores = {(z = w • x, [yfirst, ylast]}.
When queried about when a previously unseen doc-
ument x was written, we compute z = w • x and
search for the k closest entries in Dscores, which we
denote Dzscores. For each candidate interval for the
test document [yfirst, ylast] we compute its average
distance to the intervals of the k nearest training doc-
uments [yfirst
i , ylast
</bodyText>
<figure confidence="0.845768">
i ] E Dzscores where:
ylast
b + yfirst
b
2
</figure>
<footnote confidence="0.630744">
2We overload xi to refer to the document itself as well as its
representation as a feature vector.
</footnote>
<bodyText confidence="0.9753615">
The predicted interval is the one minimizing the av-
erage distance:
</bodyText>
<equation confidence="0.858681">
yˆ = arg miny∈Y
</equation>
<bodyText confidence="0.9689342">
Importantly, this approach allows for even more
flexibility in interval labels than needed for the ‘Di-
achronic Text Evaluation’ task. While in the task all
intervals (at a given granularity level) have the same
size, our method can deal with intervals of various
sizes,3 half-lines [−oc, a] or [a, oc] for expressing
only a lower or only an upper bound on the time of
writing of a document, and even degenerate intervals
[a, a] for when the time is known exactly.
Features. AMBRA uses four types of features:
</bodyText>
<listItem confidence="0.999964142857143">
• Length meta-features (number of sentences,
types, tokens);
• Stylistic (Average Word Length, Average Sen-
tence Length, Lexical Density, Lexical Rich-
ness);4
• Grammatical (part-of-speech tag n-grams);
• Lexical (token n-grams).
</listItem>
<bodyText confidence="0.9998258">
We use χ2 feature selection with classes defined as
the [50•n, 50•(n+1)] interval that overlaps the most
with the true one. This coarse approach to feature
selection has been shown to work well for temporal
classification (Niculae et al., 2014).
</bodyText>
<sectionHeader confidence="0.999953" genericHeader="evaluation">
4 Results
</sectionHeader>
<bodyText confidence="0.999941090909091">
We perform 5-fold cross-validation over the training
set to estimate the task-specific score. We fix the
number of neighbours used for prediction to k = 10
after cross-validation using only number of tokens
as feature. The model parameter space consists of
the logistic regression’s regularization parameter C,
the minimum and maximum frequency thresholds
for pruning too rare and too common features, n-
gram range for tokens and for part-of-speech tags,
and the number of features to keep after feature se-
lection. We choose the best configuration after many
</bodyText>
<footnote confidence="0.97643875">
3In our implementation, we set dist(ya, yb) to 0 if the
smaller interval is fully contained in the wider one.
4Lexical Density = unique tokens / total tokens; Lexical
Richness = unique lemmas / total tokens.
</footnote>
<figure confidence="0.987834">
dist (ya, yb) = ���� ylast a+ yfirst
a
2
i .
1 X dist(y, yi).
k
yi∈Dzscores
</figure>
<page confidence="0.99444">
853
</page>
<table confidence="0.9992295">
Task 1 Task 2
Model Features Fine Medium Coarse MAE Fine Medium Coarse MAE
Random — 0.09 0.21 0.44 73.16 0.30 0.43 0.59 80.58
Ridge lengths+style 0.15 0.32 0.52 67.94 0.33 0.59 0.77 54.77
AMBRA lengths+style 0.12 0.26 0.48 74.67 0.38 0.58 0.75 57.00
AMBRA full 0.17 0.38 0.55 63.24 0.60 0.77 0.87 31.74
</table>
<tableCaption confidence="0.996729">
Table 1: Evaluation of AMBRA and the baselines on the test data. We report the task-specific score (between 0 and
1, higher is better) for the three levels of granularity, as well as the mean absolute error (MAE, lower is better) for the
fine level of granularity.
</tableCaption>
<bodyText confidence="0.99971380952381">
iterations of randomized search. We compare our
ranking model to a ridge regression baseline, em-
ploying the document length meta-features and us-
ing the middle of the time intervals as target values.
We also evaluate a random baseline where one of
the candidate intervals is chosen with uniform prob-
ability. For evaluation, we use the task-specific met-
ric defined by the organizers (Popescu and Strappa-
rava, 2015), based on the number of interval divi-
sions between the prediction and the right answer.
For context, we also report the mean absolute error
obtained by taking the center of the intervals as a
point estimate of the year. Table 1 shows the perfor-
mance of AMBRA and the baseline systems on the
test documents. On T1, the full AMBRA system is
the only to beat the random baseline in all metrics
(95% confidence). On T2, where more data is avail-
able, AMBRA with length and style features outper-
forms ridge regression at fine granularity (95% con-
fidence), and the full AMBRA system outperforms
all others in all metrics (99% confidence).5
</bodyText>
<subsectionHeader confidence="0.998948">
4.1 Most Informative Features
</subsectionHeader>
<bodyText confidence="0.998492181818182">
To better understand the performance of our method
we analyze the most informative features selected
by our best models. We use identical feature sets for
both tasks, and while there are some common pat-
terns, we observe important differences in the fea-
ture rankings, confirming that T1 and T2 are differ-
ent enough in nature to warrant separate modeling.
Among the features useful for both tasks we find
the length of a document in sentences highly predic-
tive, with newer texts being longer. Also, the lin-
guistic structure determiner + singular proper noun
</bodyText>
<footnote confidence="0.930657">
5All significance results are based on 10000 boostrap itera-
tions with bias correction.
</footnote>
<bodyText confidence="0.999772">
is predictive of older texts, while adjective + singu-
lar noun is predictive of newer texts. The decrease
in use of the contraction ’d is captured in both cases.
From the lexical features, the word letters indicates
older texts, corresponding to the decreasing use of
mail as telecommunication became mainstream.
Words useful for T1 are more topic- and time-
specific ones, such as army, emperor, troops, while
the T2 model, possibly enabled by the larger amount
of data, proves capable of detecting diachronic
spelling variation (publick and public are both se-
lected, with opposite signs), outdated words (upon),
and more subtle stylistic changes such as the de-
crease in use of the Oxford comma (a comma fol-
lowed by a conjunction at the end of a list).
</bodyText>
<sectionHeader confidence="0.990524" genericHeader="conclusions">
5 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999909176470588">
We propose a ranking-based method to handle inter-
val prediction and account for uncertainty in tempo-
ral text classification. Our approach proved compet-
itive in the Semeval-2015 ‘Diachronic Text Evalua-
tion’ subtasks one and two. The features we used
are simplistic but effective. We expect performance
to improve by including linguistic and etymology
expertise in the feature engineering and selection
process, as well as by including world knowledge
through named entities and linked data.
Our model allows for arbitrary interval labels,
which is more expressive and more realistic than the
task formulation. We plan to refine collections of
historical texts and tighten the annotation intervals
wherever possible. Our implementation can be
made more scalable by following the random
sampling methodology of Sculley (2009).
</bodyText>
<page confidence="0.998425">
854
</page>
<sectionHeader confidence="0.998331" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999930833333333">
The authors are thankful to Fabian Pedregosa for
valuable discussion, to the anonymous reviewers for
their helpful and constructive comments, and to the
organizers for preparing and running the shared task.
Liviu P. Dinu was supported by UEFISCDI, PNII-
ID-PCE-2011-3-0959.
</bodyText>
<sectionHeader confidence="0.998461" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999069416666666">
Hidenao Abe and Shusaku Tsumoto. 2010. Text cate-
gorization with considering temporal patterns of term
usages. In Proceedings of ICDM Workshops.
Alina Maria Ciobanu, Liviu P. Dinu, Anca Dinu, and
Vlad Niculae. 2013. Temporal classification for his-
torical Romanian texts. In Proceedings of LaTeCH.
Wisam Dakka, Luis Gravano, and Panagiotis G. Ipeiro-
tis. 2012. Answering general time-sensitive queries.
IEEE Transactions on Knowledge and Data Engineer-
ing, 24(2):220–235.
Angelo Dalli and Yorick Wilks. 2006. Automatic dat-
ing of documents and temporal text classification. In
Proceedings of ARTE, Sidney, Australia.
Franciska de Jong, Henning Rode, and Djoerd Hiemstra.
2005. Temporal language models for the disclosure of
historical text. In Proceedings of AHC.
Anne Garcia-Fernandez, Anne-Laure Ligozat, Marco
Dinarelli, and Delphine Bernhard. 2011. When was it
written? Automatically determining publication dates.
In Proceedings of SPIRE.
Cyril Grouin, Dominic Forest, Lyne Da Sylva,
Patrick Paroubek, and Pierre Zweigenbaum. 2010.
Pr´esentation et r´esultats du d´efi fouille de texte
DEFT2010 o`u et quand un article de presse a-t-il ´et´e
´ecrit? Actes du sixi`eme D ´Efi Fouille de Textes.
Thorsten Joachims. 2006. Training linear SVMs in linear
time. In Proceedings of KDD.
Nattya Kanhabua and Kjetil Nørv˚ag. 2009. Using tem-
poral language models for document dating. In Pro-
ceedings of ECML/PKDD.
Abhimanu Kumar, Matthew Lease, and Jason Baldridge.
2011. Supervised language modelling for temporal
resolution of texts. In Proceedings of CIKM.
Rada Mihalcea and Vivi Nastase. 2012. Word epoch
disambiguation: Finding how words change over time.
In Proceedings of ACL.
Vlad Niculae, Marcos Zampieri, Liviu P. Dinu, and Alina
Ciobanu. 2014. Temporal text ranking and automatic
dating of texts. In Proceedings of EACL.
Fabian Pedregosa, Elodie Cauvet, Gael Varoquaux,
Christophe Pallier, Bertrang Thirion, and Alexandre
Gramfort. 2012. Learning to rank from medical imag-
ing data. CoRR, abs/1207.3598.
Octavian Popescu and Carlo Strapparava. 2013. Behind
the times: Detecting epoch changes using large cor-
pora. In Proceedings of IJCNLP.
Octavian Popescu and Carlo Strapparava. 2015.
Semeval-2015 task 7: Diachronic text evaluation. In
Proceedings of SemEval.
Daniel Preotiuc-Pietro. 2014. Temporal models of
streaming social media data. Ph.D. thesis, University
of Sheffield.
D. Sculley. 2009. Large scale learning to rank. In NIPS
Workshop on Advances in Ranking, pages 1–6.
Sanja ˇStajner and Marcos Zampieri. 2013. Stylistic
changes for temporal text classification. In Proceed-
ings of TSD.
Constantina Stamou. 2005. Dating Victorians: An ex-
perimental approach to stylochronometry. Ph.D. the-
sis, University of Bedfordshire.
Dolf Trieschnigg, Djoerd Hiemstra, Mariet Theune,
Franciska de Jong, and Theo Meder. 2012. An ex-
ploration of language identification techniques for the
dutch folktale database. In Proceedings of LREC2012.
Chong Wang, David Blei, and Heckerman David. 2008.
Continuous time dynamic topic models. In Proceed-
ings of UAI.
Derry Tanti Wijaya and Reyyan Yeniterzi. 2011. Un-
derstanding semantic change of words over centuries.
In Proceedings of the Workshop on Detecting and Ex-
ploiting Cultural Diversity on the Social Web (DE-
TECT).
</reference>
<page confidence="0.998961">
855
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.483724">
<title confidence="0.99878">AMBRA: A Ranking Approach to Temporal Text Classification</title>
<author confidence="0.944035">Alina Maria Vlad Liviu P</author>
<affiliation confidence="0.995424">University, Research Center for Artificial Intelligence (DFKI), for Computational Linguistics, University of Bucharest, of Computer Science, Cornell University,</affiliation>
<email confidence="0.725304">marcos.zampieri@uni-saarland.de;vn66@cornell.edu;ldinu@fmi.unibuc.ro;</email>
<abstract confidence="0.999728842105263">This paper describes the AMBRA system, entered in the SemEval-2015 Task 7: ‘Diachronic Text Evaluation’ subtasks one and two, which consist of predicting the date when a text was originally written. The task is valuable for applications in digital humanities, information systems, and historical linguistics. The novelty of this shared task consists of incorporating label uncertainty by assigning an interval within which the document was written, rather than assigning a clear time marker to each training document. To deal with non-linear effects and variable degrees of uncertainty, we reduce the problem to paircomparisons of the form Document A than Document and propose a nonparametric way to transform the ordinal output into time intervals.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Hidenao Abe</author>
<author>Shusaku Tsumoto</author>
</authors>
<title>Text categorization with considering temporal patterns of term usages.</title>
<date>2010</date>
<booktitle>In Proceedings of ICDM Workshops.</booktitle>
<contexts>
<context position="4728" citStr="Abe and Tsumoto (2010)" startWordPosition="714" endWordPosition="717">assign timestamps to unlabeled documents. An extension of such models for continuous time is proposed by Wang et al. (2008), who use Brownian motion as a model for topic change over time. This approach is simpler and faster than the discrete time version, but it cannot be directly applied to documents with different degrees of label uncertainty, such as interval labels. Dalli and Wilks (2006) train a classifier to date texts within a time span of nine years. The method uses lexical features and it is aided by words whose frequencies increase at some point in time, most notably named entities. Abe and Tsumoto (2010) propose similarity metrics to categorise texts based on keywords calculated by indexes such as tf-idf. Garcia-Fernandez et al. (2011) explore different NLP techniques on a digitized collection of French texts published between 1801 and 1944. Stylerelated markers and features, including readability features, have been shown to reveal temporal information in English as well as Portuguese (Stamou, 2005; ˇStajner and Zampieri, 2013). An intersecting research direction combines diatopic (regional) and diachronic variation for French journalistic texts (Grouin et al., 2010) and for the Dutch Folkta</context>
</contexts>
<marker>Abe, Tsumoto, 2010</marker>
<rawString>Hidenao Abe and Shusaku Tsumoto. 2010. Text categorization with considering temporal patterns of term usages. In Proceedings of ICDM Workshops.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alina Maria Ciobanu</author>
<author>Liviu P Dinu</author>
<author>Anca Dinu</author>
<author>Vlad Niculae</author>
</authors>
<title>Temporal classification for historical Romanian texts.</title>
<date>2013</date>
<booktitle>In Proceedings of LaTeCH.</booktitle>
<contexts>
<context position="5502" citStr="Ciobanu et al. (2013)" startWordPosition="827" endWordPosition="830">NLP techniques on a digitized collection of French texts published between 1801 and 1944. Stylerelated markers and features, including readability features, have been shown to reveal temporal information in English as well as Portuguese (Stamou, 2005; ˇStajner and Zampieri, 2013). An intersecting research direction combines diatopic (regional) and diachronic variation for French journalistic texts (Grouin et al., 2010) and for the Dutch Folktale Database, which includes texts from different dialects and varieties of Dutch, as well as historical texts (Trieschnigg et al., 2012). More recently, Ciobanu et al. (2013) propose supervised classification with unigram features with χ2 feature selection on a collection of historical Romanian texts, noting that the informative features are words having changed form over time. Niculae et al. (2014) circumvent the limitations of supervised classification by posing the problem as ordinal regression with a learning-to-rank approach. They evaluate their method on datasets in English, Portuguese and Romanian. The superior flexibility of the ranking approach makes it a better fit for the problem formulation of the ‘Diachronic Text Evaluation’ task, motivating us to bas</context>
</contexts>
<marker>Ciobanu, Dinu, Dinu, Niculae, 2013</marker>
<rawString>Alina Maria Ciobanu, Liviu P. Dinu, Anca Dinu, and Vlad Niculae. 2013. Temporal classification for historical Romanian texts. In Proceedings of LaTeCH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wisam Dakka</author>
<author>Luis Gravano</author>
<author>Panagiotis G Ipeirotis</author>
</authors>
<title>Answering general time-sensitive queries.</title>
<date>2012</date>
<journal>IEEE Transactions on Knowledge and Data Engineering,</journal>
<volume>24</volume>
<issue>2</issue>
<contexts>
<context position="1605" citStr="Dakka et al., 2012" startWordPosition="224" endWordPosition="227">t. To deal with non-linear effects and variable degrees of uncertainty, we reduce the problem to pairwise comparisons of the form is Document A older than Document B?, and propose a nonparametric way to transform the ordinal output into time intervals. 1 Introduction Temporal text classification consists of learning to automatically predict the publication date of documents, by using the information contained in their textual content. The task finds uses in fields as varied as digital humanities, where many texts have are unidentified or controversial publication dates, information retrieval (Dakka et al., 2012), where temporal constraints can improve relevance, and historical linguistics, where the interpretation of the learned models can confirm and reveal insights. From a technical point of view, the task is usually tackled either as regression or, more commonly, as a single-label multi-class problem, with classes defined as time intervals such as months, years, decades or centuries. The regression approach assumes that precise timestamps are uniformly available for each document, which is suitable for cases of social media documents (Preotiuc-Pietro, 2014), but less suitable for documents surroun</context>
</contexts>
<marker>Dakka, Gravano, Ipeirotis, 2012</marker>
<rawString>Wisam Dakka, Luis Gravano, and Panagiotis G. Ipeirotis. 2012. Answering general time-sensitive queries. IEEE Transactions on Knowledge and Data Engineering, 24(2):220–235.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Angelo Dalli</author>
<author>Yorick Wilks</author>
</authors>
<title>Automatic dating of documents and temporal text classification.</title>
<date>2006</date>
<booktitle>In Proceedings of ARTE,</booktitle>
<location>Sidney, Australia.</location>
<contexts>
<context position="4501" citStr="Dalli and Wilks (2006)" startWordPosition="674" endWordPosition="677">anguage models and distances in distribution space to classify documents to the time period with the most similar language (de Jong et al., 2005; Kumar et al., 2011). Kanhabua and NOrv˚ag (2009) use temporal language models to assign timestamps to unlabeled documents. An extension of such models for continuous time is proposed by Wang et al. (2008), who use Brownian motion as a model for topic change over time. This approach is simpler and faster than the discrete time version, but it cannot be directly applied to documents with different degrees of label uncertainty, such as interval labels. Dalli and Wilks (2006) train a classifier to date texts within a time span of nine years. The method uses lexical features and it is aided by words whose frequencies increase at some point in time, most notably named entities. Abe and Tsumoto (2010) propose similarity metrics to categorise texts based on keywords calculated by indexes such as tf-idf. Garcia-Fernandez et al. (2011) explore different NLP techniques on a digitized collection of French texts published between 1801 and 1944. Stylerelated markers and features, including readability features, have been shown to reveal temporal information in English as we</context>
</contexts>
<marker>Dalli, Wilks, 2006</marker>
<rawString>Angelo Dalli and Yorick Wilks. 2006. Automatic dating of documents and temporal text classification. In Proceedings of ARTE, Sidney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franciska de Jong</author>
<author>Henning Rode</author>
<author>Djoerd Hiemstra</author>
</authors>
<title>Temporal language models for the disclosure of historical text.</title>
<date>2005</date>
<booktitle>In Proceedings of AHC.</booktitle>
<marker>de Jong, Rode, Hiemstra, 2005</marker>
<rawString>Franciska de Jong, Henning Rode, and Djoerd Hiemstra. 2005. Temporal language models for the disclosure of historical text. In Proceedings of AHC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anne Garcia-Fernandez</author>
<author>Anne-Laure Ligozat</author>
<author>Marco Dinarelli</author>
<author>Delphine Bernhard</author>
</authors>
<title>When was it written? Automatically determining publication dates.</title>
<date>2011</date>
<booktitle>In Proceedings of SPIRE.</booktitle>
<contexts>
<context position="4862" citStr="Garcia-Fernandez et al. (2011)" startWordPosition="733" endWordPosition="736">ho use Brownian motion as a model for topic change over time. This approach is simpler and faster than the discrete time version, but it cannot be directly applied to documents with different degrees of label uncertainty, such as interval labels. Dalli and Wilks (2006) train a classifier to date texts within a time span of nine years. The method uses lexical features and it is aided by words whose frequencies increase at some point in time, most notably named entities. Abe and Tsumoto (2010) propose similarity metrics to categorise texts based on keywords calculated by indexes such as tf-idf. Garcia-Fernandez et al. (2011) explore different NLP techniques on a digitized collection of French texts published between 1801 and 1944. Stylerelated markers and features, including readability features, have been shown to reveal temporal information in English as well as Portuguese (Stamou, 2005; ˇStajner and Zampieri, 2013). An intersecting research direction combines diatopic (regional) and diachronic variation for French journalistic texts (Grouin et al., 2010) and for the Dutch Folktale Database, which includes texts from different dialects and varieties of Dutch, as well as historical texts (Trieschnigg et al., 201</context>
</contexts>
<marker>Garcia-Fernandez, Ligozat, Dinarelli, Bernhard, 2011</marker>
<rawString>Anne Garcia-Fernandez, Anne-Laure Ligozat, Marco Dinarelli, and Delphine Bernhard. 2011. When was it written? Automatically determining publication dates. In Proceedings of SPIRE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cyril Grouin</author>
<author>Dominic Forest</author>
<author>Lyne Da Sylva</author>
<author>Patrick Paroubek</author>
<author>Pierre Zweigenbaum</author>
</authors>
<title>Pr´esentation et r´esultats du d´efi fouille de texte DEFT2010 o`u et quand un article de presse a-t-il ´et´e ´ecrit? Actes du sixi`eme D ´Efi Fouille de Textes.</title>
<date>2010</date>
<contexts>
<context position="5303" citStr="Grouin et al., 2010" startWordPosition="796" endWordPosition="799">otably named entities. Abe and Tsumoto (2010) propose similarity metrics to categorise texts based on keywords calculated by indexes such as tf-idf. Garcia-Fernandez et al. (2011) explore different NLP techniques on a digitized collection of French texts published between 1801 and 1944. Stylerelated markers and features, including readability features, have been shown to reveal temporal information in English as well as Portuguese (Stamou, 2005; ˇStajner and Zampieri, 2013). An intersecting research direction combines diatopic (regional) and diachronic variation for French journalistic texts (Grouin et al., 2010) and for the Dutch Folktale Database, which includes texts from different dialects and varieties of Dutch, as well as historical texts (Trieschnigg et al., 2012). More recently, Ciobanu et al. (2013) propose supervised classification with unigram features with χ2 feature selection on a collection of historical Romanian texts, noting that the informative features are words having changed form over time. Niculae et al. (2014) circumvent the limitations of supervised classification by posing the problem as ordinal regression with a learning-to-rank approach. They evaluate their method on datasets</context>
</contexts>
<marker>Grouin, Forest, Sylva, Paroubek, Zweigenbaum, 2010</marker>
<rawString>Cyril Grouin, Dominic Forest, Lyne Da Sylva, Patrick Paroubek, and Pierre Zweigenbaum. 2010. Pr´esentation et r´esultats du d´efi fouille de texte DEFT2010 o`u et quand un article de presse a-t-il ´et´e ´ecrit? Actes du sixi`eme D ´Efi Fouille de Textes.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
</authors>
<title>Training linear SVMs in linear time.</title>
<date>2006</date>
<booktitle>In Proceedings of KDD.</booktitle>
<contexts>
<context position="3192" citStr="Joachims, 2006" startWordPosition="476" endWordPosition="477">ronic Text Evaluation’ subtasks one and two from SemEval-2015 are formulated similarly to a multi-class problem, where each document is assigned to an interval such as 1976-1982. To accommodate such labels, we propose an approach based on pairwise comparisons. We train a classifier to learn which document out of a pair is older and which is newer. If two documents come from overlapping intervals, then their order cannot be determined with certainty, so the pair is not used in training. We use the property of linear models to extend a set of pairwise decisions into a ranking of test documents (Joachims, 2006). While previous work uses a regression-based method to map the ranking back to actual timestamps, we propose a novel non-parametric method to choose the most likely interval. In light of this, our system is named AMBRA (Anachronism Modeling by Ranking). Our implementation is available under a permissive open-source license.1 1https://github.com/vene/ambra 851 Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 851–855, Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics 2 Related Work An important class of models for tempor</context>
</contexts>
<marker>Joachims, 2006</marker>
<rawString>Thorsten Joachims. 2006. Training linear SVMs in linear time. In Proceedings of KDD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nattya Kanhabua</author>
<author>Kjetil Nørv˚ag</author>
</authors>
<title>Using temporal language models for document dating.</title>
<date>2009</date>
<booktitle>In Proceedings of ECML/PKDD.</booktitle>
<marker>Kanhabua, Nørv˚ag, 2009</marker>
<rawString>Nattya Kanhabua and Kjetil Nørv˚ag. 2009. Using temporal language models for document dating. In Proceedings of ECML/PKDD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Abhimanu Kumar</author>
<author>Matthew Lease</author>
<author>Jason Baldridge</author>
</authors>
<title>Supervised language modelling for temporal resolution of texts.</title>
<date>2011</date>
<booktitle>In Proceedings of CIKM.</booktitle>
<contexts>
<context position="4044" citStr="Kumar et al., 2011" startWordPosition="598" endWordPosition="601">Modeling by Ranking). Our implementation is available under a permissive open-source license.1 1https://github.com/vene/ambra 851 Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 851–855, Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics 2 Related Work An important class of models for temporal classification employs prototype-based classification methods, using probabilistic language models and distances in distribution space to classify documents to the time period with the most similar language (de Jong et al., 2005; Kumar et al., 2011). Kanhabua and NOrv˚ag (2009) use temporal language models to assign timestamps to unlabeled documents. An extension of such models for continuous time is proposed by Wang et al. (2008), who use Brownian motion as a model for topic change over time. This approach is simpler and faster than the discrete time version, but it cannot be directly applied to documents with different degrees of label uncertainty, such as interval labels. Dalli and Wilks (2006) train a classifier to date texts within a time span of nine years. The method uses lexical features and it is aided by words whose frequencies</context>
</contexts>
<marker>Kumar, Lease, Baldridge, 2011</marker>
<rawString>Abhimanu Kumar, Matthew Lease, and Jason Baldridge. 2011. Supervised language modelling for temporal resolution of texts. In Proceedings of CIKM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
<author>Vivi Nastase</author>
</authors>
<title>Word epoch disambiguation: Finding how words change over time.</title>
<date>2012</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="6390" citStr="Mihalcea and Nastase (2012)" startWordPosition="967" endWordPosition="971">pervised classification by posing the problem as ordinal regression with a learning-to-rank approach. They evaluate their method on datasets in English, Portuguese and Romanian. The superior flexibility of the ranking approach makes it a better fit for the problem formulation of the ‘Diachronic Text Evaluation’ task, motivating us to base our implementation on it. A different, but related, problem is to model and understand how words usage and meaning change over time. Wijaya and Yeniterzi (2011) use the Google NGram corpus aiming to identify clusters of topics surrounding the word over time. Mihalcea and Nastase (2012) split the Google Books corpus into three wide epochs and introduce the task of word epoch disambiguation. Turning this problem around, Popescu and Strapparava (2013) use a similar approach to statistically characterize epochs by lexical and emotion features. 3 Methods The ‘Diachronic Text Evaluation’ shared task consists of three subtasks (Popescu and Strapparava, 2015): classification of documents containing explicit references to time-specific persons or events (T1), classification of documents with time-specific language use (T2), and recognition of time-specific expressions (T3). The AMBR</context>
</contexts>
<marker>Mihalcea, Nastase, 2012</marker>
<rawString>Rada Mihalcea and Vivi Nastase. 2012. Word epoch disambiguation: Finding how words change over time. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vlad Niculae</author>
<author>Marcos Zampieri</author>
<author>Liviu P Dinu</author>
<author>Alina Ciobanu</author>
</authors>
<title>Temporal text ranking and automatic dating of texts.</title>
<date>2014</date>
<booktitle>In Proceedings of EACL.</booktitle>
<contexts>
<context position="5730" citStr="Niculae et al. (2014)" startWordPosition="862" endWordPosition="865">rtuguese (Stamou, 2005; ˇStajner and Zampieri, 2013). An intersecting research direction combines diatopic (regional) and diachronic variation for French journalistic texts (Grouin et al., 2010) and for the Dutch Folktale Database, which includes texts from different dialects and varieties of Dutch, as well as historical texts (Trieschnigg et al., 2012). More recently, Ciobanu et al. (2013) propose supervised classification with unigram features with χ2 feature selection on a collection of historical Romanian texts, noting that the informative features are words having changed form over time. Niculae et al. (2014) circumvent the limitations of supervised classification by posing the problem as ordinal regression with a learning-to-rank approach. They evaluate their method on datasets in English, Portuguese and Romanian. The superior flexibility of the ranking approach makes it a better fit for the problem formulation of the ‘Diachronic Text Evaluation’ task, motivating us to base our implementation on it. A different, but related, problem is to model and understand how words usage and meaning change over time. Wijaya and Yeniterzi (2011) use the Google NGram corpus aiming to identify clusters of topics</context>
<context position="8015" citStr="Niculae et al. (2014)" startWordPosition="1221" endWordPosition="1224">egrained (e.g. &lt;textM yes=&amp;quot;1695-1707&amp;quot;&gt; for a text written between the years 1695 and 1707 in the medium-grained representation). The shared task mentions no limitation regarding the use of external corpora. Nevertheless, to avoid thematic bias, we use only the corpora provided by the organizers under the assumption that the test and training sets are sampled from the same distribution. The released test set consists of 267 instances for T1 and 1,041 instances for T2. 3.2 Algorithm and Features We use a ranking approach by pairwise comparisons, previously proposed for temporal text modeling by Niculae et al. (2014) . 852 Learning. The model learns a linear function g(x) = w • x to preserve the temporal ordering of the texts, i.e. if document2 xi predates document xj, which we will henceforth denote as xi --&lt; xj, then g(xi) &lt; g(xj). This step can be understood as learning to rank texts from older to newer. By making pairwise comparisons, the problem can be reduced to binary classification using a linear model. A dataset annotated with intervals has the form D = {(x, [yfirst, ylast)]} where yfirst &lt; ylast are the years between which document x was written. Document xi can be said to predate document xj on</context>
<context position="10866" citStr="Niculae et al., 2014" startWordPosition="1722" endWordPosition="1725">time of writing of a document, and even degenerate intervals [a, a] for when the time is known exactly. Features. AMBRA uses four types of features: • Length meta-features (number of sentences, types, tokens); • Stylistic (Average Word Length, Average Sentence Length, Lexical Density, Lexical Richness);4 • Grammatical (part-of-speech tag n-grams); • Lexical (token n-grams). We use χ2 feature selection with classes defined as the [50•n, 50•(n+1)] interval that overlaps the most with the true one. This coarse approach to feature selection has been shown to work well for temporal classification (Niculae et al., 2014). 4 Results We perform 5-fold cross-validation over the training set to estimate the task-specific score. We fix the number of neighbours used for prediction to k = 10 after cross-validation using only number of tokens as feature. The model parameter space consists of the logistic regression’s regularization parameter C, the minimum and maximum frequency thresholds for pruning too rare and too common features, ngram range for tokens and for part-of-speech tags, and the number of features to keep after feature selection. We choose the best configuration after many 3In our implementation, we set</context>
</contexts>
<marker>Niculae, Zampieri, Dinu, Ciobanu, 2014</marker>
<rawString>Vlad Niculae, Marcos Zampieri, Liviu P. Dinu, and Alina Ciobanu. 2014. Temporal text ranking and automatic dating of texts. In Proceedings of EACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fabian Pedregosa</author>
</authors>
<title>Elodie Cauvet, Gael Varoquaux, Christophe Pallier, Bertrang Thirion, and Alexandre Gramfort.</title>
<date>2012</date>
<marker>Pedregosa, 2012</marker>
<rawString>Fabian Pedregosa, Elodie Cauvet, Gael Varoquaux, Christophe Pallier, Bertrang Thirion, and Alexandre Gramfort. 2012. Learning to rank from medical imaging data. CoRR, abs/1207.3598.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Octavian Popescu</author>
<author>Carlo Strapparava</author>
</authors>
<title>Behind the times: Detecting epoch changes using large corpora.</title>
<date>2013</date>
<booktitle>In Proceedings of IJCNLP.</booktitle>
<contexts>
<context position="6556" citStr="Popescu and Strapparava (2013)" startWordPosition="994" endWordPosition="997"> and Romanian. The superior flexibility of the ranking approach makes it a better fit for the problem formulation of the ‘Diachronic Text Evaluation’ task, motivating us to base our implementation on it. A different, but related, problem is to model and understand how words usage and meaning change over time. Wijaya and Yeniterzi (2011) use the Google NGram corpus aiming to identify clusters of topics surrounding the word over time. Mihalcea and Nastase (2012) split the Google Books corpus into three wide epochs and introduce the task of word epoch disambiguation. Turning this problem around, Popescu and Strapparava (2013) use a similar approach to statistically characterize epochs by lexical and emotion features. 3 Methods The ‘Diachronic Text Evaluation’ shared task consists of three subtasks (Popescu and Strapparava, 2015): classification of documents containing explicit references to time-specific persons or events (T1), classification of documents with time-specific language use (T2), and recognition of time-specific expressions (T3). The AMBRA system participated in T1 and T2. 3.1 Corpus The training data released for the shared task consists of 323 documents for T1 and 4,202 documents for T2. Each docume</context>
</contexts>
<marker>Popescu, Strapparava, 2013</marker>
<rawString>Octavian Popescu and Carlo Strapparava. 2013. Behind the times: Detecting epoch changes using large corpora. In Proceedings of IJCNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Octavian Popescu</author>
<author>Carlo Strapparava</author>
</authors>
<title>Semeval-2015 task 7: Diachronic text evaluation.</title>
<date>2015</date>
<booktitle>In Proceedings of SemEval.</booktitle>
<contexts>
<context position="6763" citStr="Popescu and Strapparava, 2015" startWordPosition="1025" endWordPosition="1028">ifferent, but related, problem is to model and understand how words usage and meaning change over time. Wijaya and Yeniterzi (2011) use the Google NGram corpus aiming to identify clusters of topics surrounding the word over time. Mihalcea and Nastase (2012) split the Google Books corpus into three wide epochs and introduce the task of word epoch disambiguation. Turning this problem around, Popescu and Strapparava (2013) use a similar approach to statistically characterize epochs by lexical and emotion features. 3 Methods The ‘Diachronic Text Evaluation’ shared task consists of three subtasks (Popescu and Strapparava, 2015): classification of documents containing explicit references to time-specific persons or events (T1), classification of documents with time-specific language use (T2), and recognition of time-specific expressions (T3). The AMBRA system participated in T1 and T2. 3.1 Corpus The training data released for the shared task consists of 323 documents for T1 and 4,202 documents for T2. Each document has a paragraph containing, on average, 71 tokens, along with a tag indicating when each text was written/published. The publication date of texts is indicated by time intervals at all three granularity l</context>
<context position="12704" citStr="Popescu and Strapparava, 2015" startWordPosition="2034" endWordPosition="2038">on the test data. We report the task-specific score (between 0 and 1, higher is better) for the three levels of granularity, as well as the mean absolute error (MAE, lower is better) for the fine level of granularity. iterations of randomized search. We compare our ranking model to a ridge regression baseline, employing the document length meta-features and using the middle of the time intervals as target values. We also evaluate a random baseline where one of the candidate intervals is chosen with uniform probability. For evaluation, we use the task-specific metric defined by the organizers (Popescu and Strapparava, 2015), based on the number of interval divisions between the prediction and the right answer. For context, we also report the mean absolute error obtained by taking the center of the intervals as a point estimate of the year. Table 1 shows the performance of AMBRA and the baseline systems on the test documents. On T1, the full AMBRA system is the only to beat the random baseline in all metrics (95% confidence). On T2, where more data is available, AMBRA with length and style features outperforms ridge regression at fine granularity (95% confidence), and the full AMBRA system outperforms all others </context>
</contexts>
<marker>Popescu, Strapparava, 2015</marker>
<rawString>Octavian Popescu and Carlo Strapparava. 2015. Semeval-2015 task 7: Diachronic text evaluation. In Proceedings of SemEval.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Preotiuc-Pietro</author>
</authors>
<title>Temporal models of streaming social media data.</title>
<date>2014</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Sheffield.</institution>
<contexts>
<context position="2164" citStr="Preotiuc-Pietro, 2014" startWordPosition="311" endWordPosition="312">l publication dates, information retrieval (Dakka et al., 2012), where temporal constraints can improve relevance, and historical linguistics, where the interpretation of the learned models can confirm and reveal insights. From a technical point of view, the task is usually tackled either as regression or, more commonly, as a single-label multi-class problem, with classes defined as time intervals such as months, years, decades or centuries. The regression approach assumes that precise timestamps are uniformly available for each document, which is suitable for cases of social media documents (Preotiuc-Pietro, 2014), but less suitable for documents surrounded by more uncertainty. Multi-class classification, on the other hand, suffers from a coarseness tradeoff: using coarser classes is less informative, and using finer classes reduces the number of training instances in each class, making the problem more difficult. Furthermore, with a multi-class formulation, the temporal relationship between classes is lost. The ‘Diachronic Text Evaluation’ subtasks one and two from SemEval-2015 are formulated similarly to a multi-class problem, where each document is assigned to an interval such as 1976-1982. To accom</context>
</contexts>
<marker>Preotiuc-Pietro, 2014</marker>
<rawString>Daniel Preotiuc-Pietro. 2014. Temporal models of streaming social media data. Ph.D. thesis, University of Sheffield.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Sculley</author>
</authors>
<title>Large scale learning to rank.</title>
<date>2009</date>
<booktitle>In NIPS Workshop on Advances in Ranking,</booktitle>
<pages>1--6</pages>
<marker>Sculley, 2009</marker>
<rawString>D. Sculley. 2009. Large scale learning to rank. In NIPS Workshop on Advances in Ranking, pages 1–6.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sanja ˇStajner</author>
<author>Marcos Zampieri</author>
</authors>
<title>Stylistic changes for temporal text classification.</title>
<date>2013</date>
<booktitle>In Proceedings of TSD.</booktitle>
<marker>ˇStajner, Zampieri, 2013</marker>
<rawString>Sanja ˇStajner and Marcos Zampieri. 2013. Stylistic changes for temporal text classification. In Proceedings of TSD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Constantina Stamou</author>
</authors>
<title>Dating Victorians: An experimental approach to stylochronometry.</title>
<date>2005</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Bedfordshire.</institution>
<contexts>
<context position="5131" citStr="Stamou, 2005" startWordPosition="775" endWordPosition="776">r to date texts within a time span of nine years. The method uses lexical features and it is aided by words whose frequencies increase at some point in time, most notably named entities. Abe and Tsumoto (2010) propose similarity metrics to categorise texts based on keywords calculated by indexes such as tf-idf. Garcia-Fernandez et al. (2011) explore different NLP techniques on a digitized collection of French texts published between 1801 and 1944. Stylerelated markers and features, including readability features, have been shown to reveal temporal information in English as well as Portuguese (Stamou, 2005; ˇStajner and Zampieri, 2013). An intersecting research direction combines diatopic (regional) and diachronic variation for French journalistic texts (Grouin et al., 2010) and for the Dutch Folktale Database, which includes texts from different dialects and varieties of Dutch, as well as historical texts (Trieschnigg et al., 2012). More recently, Ciobanu et al. (2013) propose supervised classification with unigram features with χ2 feature selection on a collection of historical Romanian texts, noting that the informative features are words having changed form over time. Niculae et al. (2014) </context>
</contexts>
<marker>Stamou, 2005</marker>
<rawString>Constantina Stamou. 2005. Dating Victorians: An experimental approach to stylochronometry. Ph.D. thesis, University of Bedfordshire.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dolf Trieschnigg</author>
<author>Djoerd Hiemstra</author>
<author>Mariet Theune</author>
<author>Franciska de Jong</author>
<author>Theo Meder</author>
</authors>
<title>An exploration of language identification techniques for the dutch folktale database.</title>
<date>2012</date>
<booktitle>In Proceedings of LREC2012.</booktitle>
<marker>Trieschnigg, Hiemstra, Theune, de Jong, Meder, 2012</marker>
<rawString>Dolf Trieschnigg, Djoerd Hiemstra, Mariet Theune, Franciska de Jong, and Theo Meder. 2012. An exploration of language identification techniques for the dutch folktale database. In Proceedings of LREC2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chong Wang</author>
<author>David Blei</author>
<author>Heckerman David</author>
</authors>
<title>Continuous time dynamic topic models.</title>
<date>2008</date>
<booktitle>In Proceedings of UAI.</booktitle>
<contexts>
<context position="4229" citStr="Wang et al. (2008)" startWordPosition="627" endWordPosition="630">c Evaluation (SemEval 2015), pages 851–855, Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics 2 Related Work An important class of models for temporal classification employs prototype-based classification methods, using probabilistic language models and distances in distribution space to classify documents to the time period with the most similar language (de Jong et al., 2005; Kumar et al., 2011). Kanhabua and NOrv˚ag (2009) use temporal language models to assign timestamps to unlabeled documents. An extension of such models for continuous time is proposed by Wang et al. (2008), who use Brownian motion as a model for topic change over time. This approach is simpler and faster than the discrete time version, but it cannot be directly applied to documents with different degrees of label uncertainty, such as interval labels. Dalli and Wilks (2006) train a classifier to date texts within a time span of nine years. The method uses lexical features and it is aided by words whose frequencies increase at some point in time, most notably named entities. Abe and Tsumoto (2010) propose similarity metrics to categorise texts based on keywords calculated by indexes such as tf-id</context>
</contexts>
<marker>Wang, Blei, David, 2008</marker>
<rawString>Chong Wang, David Blei, and Heckerman David. 2008. Continuous time dynamic topic models. In Proceedings of UAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Derry Tanti Wijaya</author>
<author>Reyyan Yeniterzi</author>
</authors>
<title>Understanding semantic change of words over centuries.</title>
<date>2011</date>
<booktitle>In Proceedings of the Workshop on Detecting and Exploiting Cultural Diversity on the Social Web (DETECT).</booktitle>
<contexts>
<context position="6264" citStr="Wijaya and Yeniterzi (2011)" startWordPosition="947" endWordPosition="950"> that the informative features are words having changed form over time. Niculae et al. (2014) circumvent the limitations of supervised classification by posing the problem as ordinal regression with a learning-to-rank approach. They evaluate their method on datasets in English, Portuguese and Romanian. The superior flexibility of the ranking approach makes it a better fit for the problem formulation of the ‘Diachronic Text Evaluation’ task, motivating us to base our implementation on it. A different, but related, problem is to model and understand how words usage and meaning change over time. Wijaya and Yeniterzi (2011) use the Google NGram corpus aiming to identify clusters of topics surrounding the word over time. Mihalcea and Nastase (2012) split the Google Books corpus into three wide epochs and introduce the task of word epoch disambiguation. Turning this problem around, Popescu and Strapparava (2013) use a similar approach to statistically characterize epochs by lexical and emotion features. 3 Methods The ‘Diachronic Text Evaluation’ shared task consists of three subtasks (Popescu and Strapparava, 2015): classification of documents containing explicit references to time-specific persons or events (T1),</context>
</contexts>
<marker>Wijaya, Yeniterzi, 2011</marker>
<rawString>Derry Tanti Wijaya and Reyyan Yeniterzi. 2011. Understanding semantic change of words over centuries. In Proceedings of the Workshop on Detecting and Exploiting Cultural Diversity on the Social Web (DETECT).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>