<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000002">
<note confidence="0.939111">
CompuTerm 2004 - 3rd International Workshop on Computational Terminology 39
</note>
<title confidence="0.998079">
Discovering Specific Semantic Relationships between Nouns and
Verbs in a Specialized French Corpus
</title>
<author confidence="0.991864">
Vincent CLAVEAU and Marie-Claude L&apos;HOMME
</author>
<affiliation confidence="0.986998">
OLST - University of Montreal
</affiliation>
<address confidence="0.872435666666667">
C.P. 6128, succ. Centre-Ville
Montréal, QC, H3C 3J7
Canada
</address>
<email confidence="0.997142">
{Vincent.Claveau,Marie-Claude.L&apos;Homme}@umontreal.ca
</email>
<sectionHeader confidence="0.982958" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998941095238095">
Recent literature in computational termi-
nology has shown an increasing interest in
identifying various semantic relationships
between terms. In this paper, we pro-
pose an original strategy to find specific
noun-verb combinations in a specialized cor-
pus. We focus on verbs that convey a
meaning of realization. To acquire these
noun-verb pairs, we use ASARES, a machine
learning technique that automatically in-
fers extraction patterns from examples and
counter-examples of realization noun-verb
pairs. The patterns are then applied to the
corpus to retrieve new pairs. Results, mea-
sured with a large test set, show that our
acquisition technique outperforms classical
statistical methods used for collocation ac-
quisition. Moreover, the inferred patterns
yield interesting clues on which structures
are more likely to convey the target seman-
tic link.
</bodyText>
<sectionHeader confidence="0.99628" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999458193548387">
Recent literature in computational terminology
has shown an increasing interest in identifying
various semantic relationships between terms.
Different strategies have been developed in or-
der to identify pairs of terms that share a spe-
cific semantic relationship (such as hyperonymy
or meronymy) or to build classes of terms.
However, most strategies are based on &amp;quot;in-
ternal&amp;quot; or &amp;quot;external methods&amp;quot; (Grabar and
Zweigenbaum, 2002), i.e. methods that rely on
the form of terms or on the information gathered
from contexts. (In some cases, an additional
resource, such as a dictionary or a thesaurus,
is used during the identification process.) The
work reported here infers specific semantic rela-
tionships based on sets of examples and counter-
examples.
In this paper, the method is applied to a
French corpus on computing to find noun-verb
combinations in which verbs convey a meaning
of realization. The work is carried out in order
to assist terminographers in the enrichment of a
dictionary on computing that includes colloca-
tional information (L&apos;Homme, 2004).
Even though this work is carried out for ter-
minographical and lexicographical purposes, it
can certainly be of use in other applications,
namely information retrieval. Indeed, such rich
semantic links can be used to extend indices
or reformulate queries (similar to the work by
Voorhees (1994) with WoRDNET relations).
</bodyText>
<sectionHeader confidence="0.97697" genericHeader="introduction">
2 Objectives
</sectionHeader>
<bodyText confidence="0.99944">
The noun-verb combinations we aim to identify
have the following characteristics. They share:
</bodyText>
<listItem confidence="0.992803833333333">
• A syntactic relationship : nouns can be
subjects (e.g., &amp;quot;ordinateur tourne&amp;quot;; &amp;quot;com-
puter runs&amp;quot;); direct objects (e.g., &amp;quot;configurer
l&apos;application&amp;quot;; &amp;quot;configure the application&amp;quot;); or
second complement (e.g., &amp;quot;charger x dans la
memoire&amp;quot;; &amp;quot;load x into memory&amp;quot;);
• A valid semantic relationship. The follow-
ing semantic relationships are sought:
1. verbs that refer to activities carried out
by the nouns (e.g., &amp;quot;serveur demarre&amp;quot;;
&amp;quot;server starts&amp;quot;);
2. verbs that refer to uses of the nouns
(e.g., &amp;quot;activer une option&amp;quot;; &amp;quot;activate an
option&amp;quot; or &amp;quot;naviguer sur Internet&amp;quot;; &amp;quot;surf
the Internet&amp;quot;);
3. verbs that refer to activities carried out
by means of the nouns (e.g., &amp;quot;activer
l&apos;option au moyen de cette commande&amp;quot;;
&amp;quot;activate this option with this com-
mand&amp;quot;); and, finally,
4. verbs that refer to the processes by
which nouns are prepared fur use (e.g.,
&amp;quot;instaler un logiciel&amp;quot;; &amp;quot;install an applica-
tion&amp;quot;).
</listItem>
<footnote confidence="0.495168">
These noun-verb combinations will hereafter be
called valid N-V pairs.
</footnote>
<note confidence="0.791796">
40 CompuTerm 2004 - 3rd International Workshop on Computational Terminology
</note>
<bodyText confidence="0.9987068">
The semantic relationships listed above cor-
respond to a set of lexical functions (LFs) de-
fined in (Mel&apos;cuk et al., 1984 1999), i.e. LFs
used to represent realization (e.g., Facti, Reali,
Labrealij) and to represent the process by which
something is prepared (Prepar)1. (Both of
these types of LFs can be combined with oth-
ers [to create complex lexical functions].) These
LFs are opposed to support verbs represented
by the LFs Funci, Operi, Laborij (e.g., &amp;quot;creer un
fichier&apos;; &amp;quot;create a file&apos;; &amp;quot;definir une variable&apos;; &amp;quot;de-
fine a variable&apos;).).
Realization verbs (and verbs denoting the
preparation of nouns) were chosen since they
are believed to be frequent in technical corpora,
such as the corpus of computing used in this ex-
periment. However, this is seen as a first step
in order to validate an acquisition process for
semantically-related V-N pairs. Other semantic
relationships could be sought in the future.
</bodyText>
<sectionHeader confidence="0.999685" genericHeader="method">
3 Related work
</sectionHeader>
<bodyText confidence="0.971577813953489">
A number of applications have relied on distri-
butional analysis (Harris, 1971) in order to build
classes of semantically related terms. This ap-
proach, which uses words that appear in the con-
text of terms to formulate hypotheses on their
semantic relatedness (Habert et al., 1996, for ex-
ample), does not specify the relationship itself.
Hence, synonyms, co-hyponyms, hyperonyms,
etc. are not differentiated.
More recent work on terminology structuring
has focussed on formal similarity to develop hy-
potheses on the semantic relationships between
terms: Daille (2003) uses derivational morphol-
ogy; Grabar and Zweigenbaum (2002) use, as a
starting point, a number of identical characters.
Up to now, the focus has been on nouns
and adjectives, since these structuring methods
have been applied to lists of extracted candidate
terms (Habert et al., 1996; Daille, 2003) or to
lists of admitted terms (Grabar and Zweigen-
baum, 2002). As a consequence, relationships
considered have been mostly synonymic or tax-
onomic, or defined as term variations.
On the other hand, other work has been car-
ried out in order to acquire collocations. Most of
these endeavours have focused on purely statis-
tical acquisition techniques (Church and Hanks,
&apos;However, our interpretation of LFs in this work is
much looser, since we admitted verbs that would not be
considered to be members of true collocations as Mel&apos;cuk
et al. (1984 1999) define them, i.e. groups of lexical units
that share a restricted cooccurrence relationship.
1990), on linguisitic acquisition (by the use of
Part-of-Speech filters hand-crafted by a linguist)
(Oueslati, 1999) or, more frequently, on a combi-
nation of the two (Smadja, 1993; Kilgarriff and
Tugwell, 2001, for example). It is worth noting
that although these techniques are able to iden-
tify N-V pairs, they do not specify the relation-
ship between N and V, nor are they capable of
focusing on a subset of N-V pairs. The original
acquisition methodology we present in the next
section will allow us to overcome this limitation.
</bodyText>
<sectionHeader confidence="0.969885" genericHeader="method">
4 Methodology for finding valid
noun-verb pairs
</sectionHeader>
<bodyText confidence="0.99993825">
This section is devoted to the description of the
methodology and the data we use to acquire
semantically related noun-verb pairs. We first
describe the specialized corpus used in this ex-
periment. Then, we briefly present ASARES, a
pattern inference tool, on which our acquisition
strategy relies. Finally, we explain the different
steps of the acquisition process.
</bodyText>
<subsectionHeader confidence="0.99635">
4.1 Computer science corpus
</subsectionHeader>
<bodyText confidence="0.999954133333333">
The French corpus used in our experiments is
composed of more than 50 articles from books
or web sites specialized in computer science; all
of them were published between 1988 and 2003.
It covers different computer science sub-domains
(networking, managing Unix computers, web-
cams...) and comprises 600,000 words.
Segmentation, morpho-syntactic tagging and
lemmatization have been carried out using the
tool CORDIAL2. Each word is accompanied by
its lemma and Part-of-Speech tag (noun, verb,
adjective). Also, the tool indicates inflection
(gender and number for nouns, tense and per-
son for verbs) and gives syntactic information
(head-modifier) for noun phrases.
</bodyText>
<subsectionHeader confidence="0.998288">
4.2 Overview of ASARES
</subsectionHeader>
<bodyText confidence="0.999772181818182">
The method used for the acquisition of N-V
pairs relies mainly on ASARES, a pattern in-
ference tool. ASARES is presented in detail in
(Claveau et al., 2003). We simply give a short
account of its basic principles herein.
ASARES is based on a Machine Learning
technique, Inductive Logic Programming (ILP)
(Muggleton and De-Raedt, 1994), which infers
general morpho-syntactic patterns from a set
of examples (this set is noted E+ hereafter)
and counter-examples (E−) of the elements one
</bodyText>
<footnote confidence="0.9455105">
2CORDIAL is a commercial product of Synapse-
Developpement.
</footnote>
<note confidence="0.457808">
CompuTerm 2004 - 3rd International Workshop on Computational Terminology 41
</note>
<bodyText confidence="0.998835">
wants to acquire and their context. The con-
textual patterns produced can then be applied
to the corpus in order to retrieve new elements.
The acquisition process can be summarized in 3
steps:
</bodyText>
<listItem confidence="0.944997666666667">
1. construction of the sets of examples (and
counter-examples);
2. inference of extraction patterns with
ASARES; and
3. extraction of N-V pairs from the corpus
with the inferred patterns.
</listItem>
<bodyText confidence="0.999930117647059">
ASARES has been previously applied to the ac-
quisition of word pairs sharing semantic rela-
tions defined in the Generative Lexicon frame-
work (Pustejovsky, 1995) and called qualia rela-
tions (Bouillon et al., 2001). Here, we propose
to use ASARES in a quite similar way to retrieve
our valid N-V pairs. However, the N-V combi-
nations sought are more specific than those that
were identified in these previous experiments.
Formally, ILP aims at inferring logic pro-
grams (sets of Horn clauses, noted H) from a set
of facts (examples and counter-examples of the
concept to be learnt) and background knowledge
(B), such that the program H logically entails
the examples with respect to the background
knowledge and rejects (most of) the counter-
examples. This is transcribed by the two logical
formulae B n H �= E+, B n H � E−, which set
the aim of an ILP algorithm.
In this framework, ASARES infers clauses ex-
pressing morpho-syntactic patterns that gener-
alize the structures of sentences containing the
target element (examples) but not the structures
of the sentences containing counter-examples.
The background knowledge encodes information
about each word occurring in the example or
counter-example, namely the meaning of its tag
(e.g., adjective in plural form, infinitive verb).
The main benefits of this acquisition tech-
nique lie in the inferred patterns. Indeed, con-
trary to the more classical statistical methods
(Mutual Information, Loglike..., see below) used
for collocation acquisition (see (Pearce, 2002)
for a review), these patterns allow:
</bodyText>
<listItem confidence="0.99759975">
1. understanding of the results, that is, why a
specific element has been retrieved or not;
2. highlighting of the corpus-specific struc-
tures conveying the target element.
</listItem>
<bodyText confidence="0.9995556">
In addition to its explanatory capacity, this sym-
bolic acquisition technique has obtained good
results for other acquisition tasks when com-
pared to existing statistical techniques (Bouillon
et al., 2002).
</bodyText>
<subsectionHeader confidence="0.99764">
4.3 Acquisition process
</subsectionHeader>
<bodyText confidence="0.999388675675676">
To infer extraction patterns, ASARES needs a set
of examples (E+) and a set of counter-examples
(E−) of the elements we want to retrieve. In
our case, E+ must thus be composed of (POS-
tagged) sentences containing valid N-V pairs;
conversely, E− must be composed of sentences
containing non-valid N-V pairs. While this step
is tedious and usually carried out manually, the
originality of our work lies in the fact that E+
and E− are obtained automatically.
To produce the positive examples, we use the
existing entries of a terminological database we
are currently developing. These entries are thus
a kind of bootstrap in our acquisition process.
More precisely, every N-V pair in which V is de-
fined in the database as a realization verb for N
is included. Then, all sentences in our corpus
containing this N-V pair are considered as ex-
amples and added to E+. Note that we do not
check if each occurrence of the N-V pair actually
shares the target semantic link or even a syn-
tactic link in the sentences that are extracted.
Some of the examples in E+ might be incorrect,
but ASARES tolerates a certain amount of noise.
A totally different technique is needed to pro-
duce the E− set, since no information concern-
ing verbs that are not semantically related is
available in the terminological database. To ob-
tain a list of invalid N-V pairs, we acquire them
from our corpus using a statistical technique.
This produces a list of all N-V pairs that ap-
pear in the same sentence, and assigns each a
score. Many statistical coefficients exist (Man-
ning and Schütze, 1999); most of them can be
easily expressed with the help of a contingency
table similar to that reproduced in Table 1 and
by noting S = a + b + c + d. For example, the
</bodyText>
<table confidence="0.995386333333333">
Vj Vk, k =� j
Ni a b
Nl,l =�i c d
</table>
<tableCaption confidence="0.9848385">
Table 1: Contingency table for the pair Ni-Vj
Mutual Information coefficient is defined as:
</tableCaption>
<figure confidence="0.369464333333333">
a
MI = log2
(a + b)(a + c)
</figure>
<figureCaption confidence="0.207257">
and the loglike coefficient (Dunning, 1993) as:
</figureCaption>
<equation confidence="0.944307">
Log = alog a + blog b + clog c + dlog d − (a +
42 CompuTerm 2004 - 3rd International Workshop on Computational Terminology
b) log(a+b) − (a+c) log(a+c) − (b+d) log(b+
d) − (c + d) log(c + d) + S log S.
</equation>
<bodyText confidence="0.999943230769231">
In the work presented here, we have adopted
the Loglike coefficient. From the N-V pair list
produced with this method, we have chosen the
pairs that obtained the lower Loglike scores. As
for the positive examples, we consider that each
sentence containing one of the pairs is a counter-
example and is added to E−.
Finally, ASARES is launched with these E+
and E− sets; each containing about 2600 sen-
tences. About 80 patterns are then produced;
some of them are presented and discussed in sec-
tion 5.1. These patterns can now be applied to
the corpus in order to retrieve valid N-V pairs.
</bodyText>
<sectionHeader confidence="0.971066" genericHeader="method">
5 Performance evaluation
</sectionHeader>
<subsectionHeader confidence="0.727081">
5.1 Inferred patterns
</subsectionHeader>
<bodyText confidence="0.844161444444444">
The inferred patterns give some interesting in-
formation about the way the target semantic re-
lationships are expressed in our corpus. While
some structures are general, others seem very
specific to our corpus.
First of all, proximity is an important factor
in valid relationships between nouns and verbs;
it can be observed in numerous patterns. For
example, the inferred Horn clause:
realization(N,V) :- common_noun(N), contigu-
ous(N,V), N54V. transcribes the fact that a noun
and a verb may be a valid N-V pair if N is
a common noun (common_noun(N)) and V is
contiguous to N (contiguous(N,V). (Determiners
are not taken into account.) This pattern
covers the case in which N precedes V, such as
&amp;quot;les utilisateurs lancent tour-a-tour leurs programmes&amp;quot;
(&amp;quot;users launch in turn their programs&amp;quot;) or
in which V precedes N, such as &amp;quot;il est donc
necessaire d&apos;executer la commande depmod&amp;quot; (&amp;quot;thus
it is necessary to run the depmod command&amp;quot;.
A quite similar clue is given in the following
pattern:
realization(N,V) :- near_verb(N,V), suc(V,C),
suc(C,N), noun(N), V54C, N54C, N54V. The
near_verb(N,V) predicate means that no verb
occurs between N and V, and suc(X,Y) that
the word X is followed by Y. This clause can
be expressed in a more classical way as V +
(anything but a verb) + N and retrieves pairs like
&amp;quot;C&apos;est un service qui vous permet de vous connecter
a Internet&amp;quot; (&amp;quot;This is a service that allows you to
connect to the Internet&amp;quot;).
Another frequent clue in the patterns pro-
duced is, unsurprisingly, that N must be the
head of a noun phrase. For example, realiza-
</bodyText>
<equation confidence="0.731428">
tion(N,V) :- near_word(N,V), near_verb(N,V), pre-
cedes(V,N), noun_ph_head(N), pred(N,C), preposi-
tion(C), V54C, N54C, N54V. This pattern means
V + (anything but a verb)? + (preposition) + N
</equation>
<figureCaption confidence="0.32097775">
head of a noun phrase and retrieves pairs such as:
&amp;quot;les dispositifs d&apos;impression n&apos;etaient pas controles par
ordinateur&amp;quot; (&amp;quot;the printing devices were not con-
trolled by computer&amp;quot;).
</figureCaption>
<bodyText confidence="0.737036">
Prepositions also play an important part
and appear frequently in the patterns: re-
</bodyText>
<equation confidence="0.413832">
alization(N,V) :- near_verb(N,V), pred(N,C),
lemma(C,&amp;quot;sur&amp;quot;), V54C, N54C, N54V. (that is V +
</equation>
<construct confidence="0.6945795">
(anything but a verb)* + sur + N) covers for
example &amp;quot;un terminal (...) permet de travailer sur
l&apos;ordinateur&amp;quot; (&amp;quot;a terminal (...) allows [one/the
user] to work on the computer&amp;quot;).
</construct>
<bodyText confidence="0.937574043478261">
The pattern realization realization(N,V)
:- near_verb(N,V), precedes(V,N), pred(N,C),
lemma(C,&amp;quot;a&amp;quot;), V54C, N54C, N54V., that is V +
(anything but a verb)* + a + N, covers &amp;quot;comment
vous connecter a Internet&amp;quot; (&amp;quot;How to connect to the
Internet&amp;quot;).
realization(N,V) :- near_verb(N,V), precedes(N,V),
pred(V,C), lemma(C,&amp;quot;a&amp;quot;), common_noun(N), V54C,
N54C, N54V., that is N + (anything but a verb)* +
a + V, covers &amp;quot;(...) mode de traitement des don-
nees suivant lequel les programmes a executer (...)&amp;quot;
(&amp;quot;...mode of data processing in which the pro-
grams to execute...&amp;quot;).
A certain number of patterns express struc-
tures more specific to our corpus. For example,
the clause:
realization(N,V) :- near_verb(N,V), precedes(V,N),
suc(N,C), proper_noun(C), common_noun(N), V54C,
N54C, N54V. (that is, V + (anything but a verb)* +
common noun N + (proper noun)) is very specific to
structures including a proper noun, such as the
sentence: &amp;quot;(...) Internet utilise le protocole TCP/IP
(...)&amp;quot; (&amp;quot;the Internet uses the TCP/IP protocol&amp;quot;).
</bodyText>
<subsectionHeader confidence="0.929191">
5.2 Methodology for evaluation
</subsectionHeader>
<bodyText confidence="0.99632930952381">
In order to evaluate the quality of the extracted
N-V pairs, we are interested in two different
measures. The first one expresses the complete-
ness of the set of retrieved N-V pairs, that is,
how many valid pairs are found with respect
to the total number of pairs which should have
been found; this is the recall rate. The second
measure indicates the reliability of the set of re-
trieved N-V pairs, that is, how many valid pairs
are found with respect to the total number of re-
trieved pairs; this is the precision rate (defined
below). These two rates were evaluated using a
test sample containing all this information.
CompuTerm 2004 - 3rd International Workshop on Computational Terminology 43
To construct this test set, we have focused
our attention on ten domain-specific terms: com-
mande (command), configuration, fichier (file), In-
ternet, logiciel (software), option, ordinateur (com-
puter), serveur (server), systeme (system), utilisa-
teur (user). The terms have been identified as
the most specific to our corpus by a program
developed by Drouin (2003) and called TER1vlo-
STAT. The ten most specific nouns have been
produced by comparing our corpus of comput-
ing to the French corpus Le Monde, composed
of newspaper articles (Lemay et al., 2004). Note
that to prevent any bias in the results, none of
these terms were used as positive examples dur-
ing the pattern inference step. (They were re-
moved from the example set.)
For each of these 10 nouns, a manual identifi-
cation of valid and invalid pairs was carried out.
Linguists were asked to analyze the sentences
and decide whether the highlighted pairs were
valid N-V pairs. Examples of the sentences pro-
duced are given in Table 2 for the term utilisateur
(user). A pair is considered as valid if at least
one of its occurrences has the desired semantic
(and syntactic) relationship (cf. section 2).
Finally, 603 of the N-V pairs examined are
valid and 4446 are considered not to be valid.
The results for each noun are detailed in Table 3.
</bodyText>
<table confidence="0.99858225">
valid non-valid total
commande 114 346 460
configuration 4 361 365
fichier 21 604 625
option 69 324 393
systeme 82 605 687
Internet 9 535 544
ordinateur 85 432 517
utilisateur 96 435 531
logiciel 64 440 504
serveur 59 364 423
Total 603 4446 5049
</table>
<tableCaption confidence="0.999802">
Table 3: Summary of the test set
</tableCaption>
<sectionHeader confidence="0.618033" genericHeader="method">
5.3 Results
</sectionHeader>
<bodyText confidence="0.98933125">
To compare the results obtained by our tech-
nique with the analysis carried out manually,
we use the traditional precision/recall approach.
Thus we applied the patterns to the corpus and
kept all the pairs retrieved when N is one of the
ten specific nouns. The results of the compari-
son are summarized with the help of confusion
matrices like the one presented in Table 43.
</bodyText>
<table confidence="0.996027428571429">
actual actual Total
valid non-valid
predicated TP FP PrP
valid
predicated FN TN PrN
non-valid
Total AP AN S
</table>
<tableCaption confidence="0.999821">
Table 4: Confusion matrix
</tableCaption>
<bodyText confidence="0.999970222222222">
It is important to note here that the values in
this confusion matrix depend on a parameter: a
detection threshold. Indeed, a single occurrence
of a N-V pair with the patterns is not sufficient
for a pair to be considered as valid. The thresh-
old, called s, represents the minimal number of
occurrences to be detected to consider a pair as
valid. The recall and precision rates (respec-
tively R and P), measured on our test set, are
thus defined according to s.
In order to represent every possible value of R
and P according to s, we draw a recall-precision
graph in which each value of P is related to
its corresponding value of R. Figure 1 gives
the graph obtained when applying the inferred
patterns to the test set. For comparison pur-
poses, Figure 1 also indicates the recall-precision
graphs obtained by two common statistical tech-
niques for collocation acquisition (the Loglike
et Mutual Information coefficients presented in
section 4.3). As a baseline, this graph also gives
the density, computed as AP/S, which repre-
sents the precision that would be obtained by
a system deciding randomly if a pair is valid or
not.
The recall-precision graph shows that our
symbolic technique outperforms the two statis-
tical ones; for a fixed recall, the precision gain
is up to 45% with respect to the Loglike results
and is even higher with respect the MI coeffi-
cient. Thus, our acquisition technique meets the
objective of offering assistance to the terminog-
rapher, since it provides many reliable N-V pair
candidates. However, results show that invalid
pairs are also retrieved; thus a manual analysis
remains unavoidable.
</bodyText>
<subsectionHeader confidence="0.903494">
5.4 Discussion of the results
</subsectionHeader>
<bodyText confidence="0.940236">
When examining the retrieved pairs, it appears
that most invalid N-V pairs can be classified in
</bodyText>
<footnote confidence="0.948525333333333">
3The meaning of the variables is given by the combi-
nation of the letters: A means actual, Pr predicated, T
true, F false, P positive and N negative.
</footnote>
<table confidence="0.992445227272727">
44 CompuTerm 2004 - 3rd International Workshop on Computational Terminology
Examples Comment
utilisateur___executer 162.823 13.907792621292 Valid syntactic and seman-
* MemCheckBoxInRunDlg Autorise les utilisateurs#N# a executer#V# un tic relationship: &amp;quot;user runs
programme 16 bits dans un processus VDM ( Virtual DOS Machine ) dedie a program&amp;quot;
( non partage ) .
utilisateur___formater 162.823 0.27168791461736 Valid syntactic and seman-
* AllocateDasd Determine quels utilisateurs#N# peuvent formater#V# et tic relationship: &amp;quot;user for-
ejecter les disques_durs amovibles . mats a hard disk&amp;quot;
utilisateur___lancer 162.823 17.9010990569368 Valid syntactic and se-
* Il utilise donc le numero de l_ utilisateur#N# reel qui a lance#V# mantic relationship: &amp;quot;user
la commande pour savoir si c_ est bien l_ utilisateur#N# root qui l_ launches a command&amp;quot;
a lance#V# .
Counter-examples Comment
utilisateur___accepter 162.823 0.0059043737128377 Syntactic relationship is
* Ces commandes sont absolument essentielles pour pouvoir valid; Semantic relation-
utiliser le systeme , mais elles sont assez rebarbatives et peu_d_ ship is not valid
utilisateurs#N# acceptent#V# de s_ en contenter .
utilisateur___entourer 162.823 0.41335402801632 Syntactic relationship is
* Mais , cote utilisateur#N# , plus on a entoure#V# ou rempli not valid
son Macintosh de peripheriques , plus grands sont les risques de
rencontrer des blocages ou des sautes_d_humeur .
</table>
<tableCaption confidence="0.998618">
Table 2: Positive and negative examples with utilisateur (Engl. user)
</tableCaption>
<figure confidence="0.9820935">
0 0.2 0.4 0.6 0.8 1
Recall
</figure>
<figureCaption confidence="0.997017">
Figure 1: Recall-Precision graph
</figureCaption>
<figure confidence="0.995774">
Precision
0.8
0.6
0.4
0.2
0
1
ASARES
Density
Mutual Information
Loglike
</figure>
<bodyText confidence="0.995960386666667">
one of the four following categories.
First, some errors are due to tagging mistakes.
For example, in the sentence &amp;quot;la première solution
est d&apos;utiliser la commande date&amp;quot; (&amp;quot;the first solution
is to use the date command&amp;quot;) the noun date
was incorrectly tagged as a verb, and the N-V
pair commande-dater was retrieved by one of the
inferred patterns. Even if this kind of error does
not come directly from our acquisition technique
and does not call into question our approach, it
is still a factor that should be taken into ac-
count, especially when considering the choice of
CompuTerm 2004 - 3rd International Workshop on Computational Terminology 45
the tagger and the quality of the texts compos-
ing our corpus.
Secondly, in a few cases, there is no syn-
tactic link between N and V, as is the
case with logiciel-garantir (software-guarantee) in
&amp;quot;cette phase garantit la verification du logiciel&amp;quot; (&amp;quot;this
step guarantees the software verification&amp;quot;). Even
if these errors are rare in the retrieved pairs ex-
amined, our symbolic extraction system could
certainly be enhanced with information about
the syntactic function of nouns (subject, direct
object...). The learning algorithm could then
incorporate this information and produce more
relevant patterns.
Thirdly, some N-V pairs are retrieved, al-
though there is no semantic link between N and
V, or at least, not a semantic link that would
be encoded by a terminographer in a dictionary.
This is the case for ordinateur-savoir (computer-
know) in &amp;quot;l&apos;ordinateur ne sait pas ou chercher&amp;quot; (&amp;quot;the
computer does not know where to look&amp;quot;). Again,
morpho-syntactic information is not always suf-
ficient to distinguish between semantically re-
lated pairs and non-semantically (but syntacti-
cally) related ones.
Finally, other very frequent errors are caused
by the fact that there actually is an interesting
semantic link between N and V in a retrieved
pair, but not the realization link we are looking
for. Indeed, some nouns belonging to specific
semantic classes will often cooccur with verbs
expressing realization meanings (and thus often
appear in valid N-V pairs) while others do not.
For example, nouns like ordinateur (computer)
and utilisateur (user) often appear in valid N-V
pairs. On the other hand, other nouns clearly
do not appear in combinations with realization
verbs (e.g., configuration; Internet, refer to Table
3).
These last two kinds of error clearly illustrate
the limitations of our symbolic approach (but
are also very frequent errors in statistical ap-
proaches since cooccurrence is not enough to
capture subtle semantic distinctions). In fact,
they tend to show that our method could be
enhanced if it could incorporate richer linguis-
tic information. Indeed, morpho-syntactic infor-
mation is not always sufficient to operate fine-
grained sense distinctions. For example, the
two sentences below have the same combina-
tion of Part-of-Speech tags: &amp;quot;vous pouvez utiliser la
commande exit&amp;quot; (&amp;quot;you can use the exit command&amp;quot;)
and &amp;quot;vous devez choisir l&apos;option 64MB&amp;quot; (&amp;quot;you must
choose the 64MB option&amp;quot;); in the first one the
underlined N-V pair is valid whereas this is not
the case in the second one. Realization verbs
for option would be valider (validate) and activer
(activate), for example. Here again, these subtle
distinctions could be handled by our symbolic
method provided that some semantic informa-
tion is given on nouns This could be supplied
by a semantic tagger.
</bodyText>
<sectionHeader confidence="0.8413435" genericHeader="method">
6 Concluding remarks and future
work
</sectionHeader>
<bodyText confidence="0.999985514285714">
We have presented an original acquisition pro-
cess for noun-verb pairs in which verbs convey a
realization meaning. These noun-verb pairs are
acquired from a domain-specific corpus of com-
puting. Our acquisition method, which relies
on ASARES, a extraction pattern inference tech-
nique, produces results that are quite good and
could improve manual terminographical work.
In particular, our method outperforms classical
statistical techniques often used for collocation
acquisition. Moreover, the inferred patterns give
interesting clues about the structures that are
likely to convey the target semantic link.
Many possibilities for future work are sug-
gested by this experiment. Concerning our ac-
quisition process, some adaptations could cer-
tainly improve the results, currently limited
by the sole use of Part-of-Speech tags and
noun-phrase information. As was previously
mentioned, syntactic and semantic information
could be added to the corpus through a tag-
ging and parsing process. These two enrich-
ments could help to overcome some limitations
of our symbolic approach to capture the nature
of N-V relationships. In terms of applications, it
would be interesting to use a similar technique
for the acquisition of other more specific seman-
tic links between nouns and verbs and even be-
tween nouns and nouns or other categories of
words. These semantic relationships would al-
low us to complete the description of the ter-
minological units contained in our dictionary of
computing. The comparison of the acquisition
results and of the inferred patterns could lead
to interesting insights.
</bodyText>
<sectionHeader confidence="0.618957" genericHeader="conclusions">
Aknowlegements
</sectionHeader>
<bodyText confidence="0.9997196">
The authors would like to thank Sahara Iveth
Carrefio Cruz and Leonie Demers-Dion for their
help in analyzing the data and Elizabeth Marsh-
man for her comments on a previous version of
this paper.
</bodyText>
<note confidence="0.711463">
46 CompuTerm 2004 - 3rd International Workshop on Computational Terminology
</note>
<sectionHeader confidence="0.972259" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999278030612245">
Pierrette Bouillon, Vincent Claveau, Cecile
Fabre, and Pascale Sebillot. 2001. Using
Part-of-Speech and Semantic Tagging for the
Corpus-Based Learning of Qualia Structure
Elements. In First International Workshop
on Generative Approaches to the Lexicon,
GL&apos;2001, Geneva, Switzerland.
Pierrette Bouillon, Vincent Claveau, Cecile
Fabre, and Pascale Sebillot. 2002. Acqui-
sition of Qualia Elements from Corpora —
Evaluation of a Symbolic Learning Method.
In 3rd International Conference on Language
Resources and Evaluation, LREC 02, Las Pal-
mas de Gran Canaria, Spain.
Kenneth W. Church and Patrick Hanks. 1990.
Word Association Norms, Mutual Informa-
tion, and Lexicography. Computational Lin-
guistics, 16(1):2229.
Vincent Claveau, Pascale Sebillot, Cecile Fabre,
and Pierrette Bouillon. 2003. Learning Se-
mantic Lexicons from a Part-of-Speech and
Semantically Tagged Corpus using Induc-
tive Logic Programming. Journal of Ma-
chine Learning Research, special issue on ILP,
4:493-525.
Beatrice Daille. 2003. Conceptual structuring
through term variation. In Workshop on Mul-
tiword Expressions. Analysis, Acquisition and
Treatment. Proceedings of the ACL&apos;03, Sap-
poro, Japan.
Patrick Drouin. 2003. Term-extraction using
non-technical corpora as a point of leverage.
Terminology, 9(1):99-115.
Ted E. Dunning. 1993. Accurate methods for
the statistics of surprise and coincidence.
Computational Linguistics, 19(1):6174.
Natalia Grabar and Pierre Zweigenbaum.
2002. Lexically-based terminology structur-
ing. some inherent limits. In Second Work-
shop on Computational Terminology, Com-
puterm 2002. Coling 2002, Taipei, Taiwan.
Benoit Habert, Ellie Naulleau, and Adeline
Nazarenko. 1996. Symbolic word clustering
for medium-sized corpora. In Proceedings of
the 16th Conference on Computational Lin-
guistics, Coling&apos;96, Copenhagen, Denmark.
Zellig Harris. 1971. Structures mathematiques
du langage. Paris: Dunod.
Adam Kilgarriff and David Tugwell. 2001.
WORD-SKETCH: Extraction and Display of
Significant Collocations for Lexicography. In
Workshop on Collocation: Computational
Extraction, Analysis and Exploitation, 39th
ACL and 10th EACL Conference, Toulouse,
France.
Chantal Lemay, Marie-Claude L&apos;Homme, and
Patrick Drouin. 2004. Two methods for ex-
tracting &amp;quot;specific&amp;quot; single-word terms from
specialized corpora. Forthcoming.
Marie-Claude L&apos;Homme. 2004. Selection de ter-
mes dans un dictionnaire d&apos;informatique :
Comparaison de corpus et criteres lexico-
semantiques. In Euralex 2004. Proceedings,
Lorient, France. Forthcoming.
Christopher D. Manning and Hinrich Schütze.
1999. Foundations of Statistical Natural Lan-
guage Processing. The MIT Press, Cam-
bridge, MA, USA.
Igor Mel&apos;cuk, Nadia Arbatchewsky-Jumarie,
Leo Elnitsky, Lidija Iordanskaja, Adele Les-
sard, Louise Dagenais, Marie-Noelle Lefeb-
vre, Suzanne Mantha, and Alain Polguere.
1984-1999. Dictionnaire explicatif et combi-
natoire du fran�ais contemporain, Recherches
lexico-semantiques, volumes I-IV. Les Presses
de l&apos;Universite de Montréal, Montréal, QC,
Canada.
Stephen Muggleton and Luc De-Raedt. 1994.
Inductive Logic Programming: Theory and
Methods. Journal of Logic Programming, 19-
20:629-679.
Rochdi Oueslati. 1999. Aide a l&apos;acquisition
de connaissances a partir de corpus. Ph.D.
thesis, Univesite Louis Pasteur, Strasbourg,
France.
Darren Pearce. 2002. A Comparative Evalu-
ation of Collocation Extraction Techniques.
In 3rd International Conference on Language
Resources and Evaluation, LREC 02, Las Pal-
mas de Gran Canaria, Spain.
James Pustejovsky. 1995. The Generative Lexi-
con. The MIT Press, Cambridge, MA, USA.
Frank Smadja. 1993. Retrieving Collocations
from Text: XTRACT. Computational Linguis-
tics, 19(1):143-178.
Ellen M. Voorhees. 1994. Query Expansion Us-
ing Lexical-Semantic Relations. In Proceed-
ings of ACM SIGIR&apos;94, Dublin, Ireland.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.070121">
<note confidence="0.513527375">CompuTerm 2004 - 3rd International Workshop on Computational Terminology 39 Specific Semantic Relationships between Nouns Verbs in a Specialized French Corpus CLAVEAU OLST - University of C.P. 6128, succ. Montréal, QC, H3C {Vincent.Claveau,Marie-Claude.L&apos;Homme}@umontreal.ca</note>
<abstract confidence="0.9975905">Recent literature in computational termihas shown an interest in various semantic relationships between terms. In this paper, we proan to find specific noun-verb combinations in a specialized corpus. We focus on verbs that convey a of realization. To these pairs, we use a machine that automatically infers extraction patterns from examples and counter-examples of realization noun-verb pairs. The patterns are then applied to the corpus to retrieve new pairs. Results, meawith a test set, show that our outperforms classical statistical methods used for collocation ac- Moreover, the inferred patterns clues on which structures more likely to convey the semantic link.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Pierrette Bouillon</author>
<author>Vincent Claveau</author>
<author>Cecile Fabre</author>
<author>Pascale Sebillot</author>
</authors>
<title>Using Part-of-Speech and Semantic Tagging for the Corpus-Based Learning of Qualia Structure Elements.</title>
<date>2001</date>
<booktitle>In First International Workshop on Generative Approaches to the Lexicon, GL&apos;2001,</booktitle>
<location>Geneva, Switzerland.</location>
<contexts>
<context position="9055" citStr="Bouillon et al., 2001" startWordPosition="1397" endWordPosition="1400">on Computational Terminology 41 wants to acquire and their context. The contextual patterns produced can then be applied to the corpus in order to retrieve new elements. The acquisition process can be summarized in 3 steps: 1. construction of the sets of examples (and counter-examples); 2. inference of extraction patterns with ASARES; and 3. extraction of N-V pairs from the corpus with the inferred patterns. ASARES has been previously applied to the acquisition of word pairs sharing semantic relations defined in the Generative Lexicon framework (Pustejovsky, 1995) and called qualia relations (Bouillon et al., 2001). Here, we propose to use ASARES in a quite similar way to retrieve our valid N-V pairs. However, the N-V combinations sought are more specific than those that were identified in these previous experiments. Formally, ILP aims at inferring logic programs (sets of Horn clauses, noted H) from a set of facts (examples and counter-examples of the concept to be learnt) and background knowledge (B), such that the program H logically entails the examples with respect to the background knowledge and rejects (most of) the counterexamples. This is transcribed by the two logical formulae B n H �= E+, B n </context>
</contexts>
<marker>Bouillon, Claveau, Fabre, Sebillot, 2001</marker>
<rawString>Pierrette Bouillon, Vincent Claveau, Cecile Fabre, and Pascale Sebillot. 2001. Using Part-of-Speech and Semantic Tagging for the Corpus-Based Learning of Qualia Structure Elements. In First International Workshop on Generative Approaches to the Lexicon, GL&apos;2001, Geneva, Switzerland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pierrette Bouillon</author>
<author>Vincent Claveau</author>
<author>Cecile Fabre</author>
<author>Pascale Sebillot</author>
</authors>
<title>Acquisition of Qualia Elements from Corpora — Evaluation of a Symbolic Learning Method.</title>
<date>2002</date>
<booktitle>In 3rd International Conference on Language Resources and Evaluation, LREC 02, Las Palmas de Gran Canaria,</booktitle>
<contexts>
<context position="10767" citStr="Bouillon et al., 2002" startWordPosition="1667" endWordPosition="1670">s acquisition technique lie in the inferred patterns. Indeed, contrary to the more classical statistical methods (Mutual Information, Loglike..., see below) used for collocation acquisition (see (Pearce, 2002) for a review), these patterns allow: 1. understanding of the results, that is, why a specific element has been retrieved or not; 2. highlighting of the corpus-specific structures conveying the target element. In addition to its explanatory capacity, this symbolic acquisition technique has obtained good results for other acquisition tasks when compared to existing statistical techniques (Bouillon et al., 2002). 4.3 Acquisition process To infer extraction patterns, ASARES needs a set of examples (E+) and a set of counter-examples (E−) of the elements we want to retrieve. In our case, E+ must thus be composed of (POStagged) sentences containing valid N-V pairs; conversely, E− must be composed of sentences containing non-valid N-V pairs. While this step is tedious and usually carried out manually, the originality of our work lies in the fact that E+ and E− are obtained automatically. To produce the positive examples, we use the existing entries of a terminological database we are currently developing.</context>
</contexts>
<marker>Bouillon, Claveau, Fabre, Sebillot, 2002</marker>
<rawString>Pierrette Bouillon, Vincent Claveau, Cecile Fabre, and Pascale Sebillot. 2002. Acquisition of Qualia Elements from Corpora — Evaluation of a Symbolic Learning Method. In 3rd International Conference on Language Resources and Evaluation, LREC 02, Las Palmas de Gran Canaria, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth W Church</author>
<author>Patrick Hanks</author>
</authors>
<date>1990</date>
<journal>Word Association Norms, Mutual Information, and Lexicography. Computational Linguistics,</journal>
<volume>16</volume>
<issue>1</issue>
<marker>Church, Hanks, 1990</marker>
<rawString>Kenneth W. Church and Patrick Hanks. 1990. Word Association Norms, Mutual Information, and Lexicography. Computational Linguistics, 16(1):2229.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vincent Claveau</author>
<author>Pascale Sebillot</author>
<author>Cecile Fabre</author>
<author>Pierrette Bouillon</author>
</authors>
<title>Learning Semantic Lexicons from a Part-of-Speech and Semantically Tagged Corpus using Inductive Logic Programming.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research, special issue on ILP,</journal>
<pages>4--493</pages>
<contexts>
<context position="8002" citStr="Claveau et al., 2003" startWordPosition="1233" endWordPosition="1236">e sub-domains (networking, managing Unix computers, webcams...) and comprises 600,000 words. Segmentation, morpho-syntactic tagging and lemmatization have been carried out using the tool CORDIAL2. Each word is accompanied by its lemma and Part-of-Speech tag (noun, verb, adjective). Also, the tool indicates inflection (gender and number for nouns, tense and person for verbs) and gives syntactic information (head-modifier) for noun phrases. 4.2 Overview of ASARES The method used for the acquisition of N-V pairs relies mainly on ASARES, a pattern inference tool. ASARES is presented in detail in (Claveau et al., 2003). We simply give a short account of its basic principles herein. ASARES is based on a Machine Learning technique, Inductive Logic Programming (ILP) (Muggleton and De-Raedt, 1994), which infers general morpho-syntactic patterns from a set of examples (this set is noted E+ hereafter) and counter-examples (E−) of the elements one 2CORDIAL is a commercial product of SynapseDeveloppement. CompuTerm 2004 - 3rd International Workshop on Computational Terminology 41 wants to acquire and their context. The contextual patterns produced can then be applied to the corpus in order to retrieve new elements.</context>
</contexts>
<marker>Claveau, Sebillot, Fabre, Bouillon, 2003</marker>
<rawString>Vincent Claveau, Pascale Sebillot, Cecile Fabre, and Pierrette Bouillon. 2003. Learning Semantic Lexicons from a Part-of-Speech and Semantically Tagged Corpus using Inductive Logic Programming. Journal of Machine Learning Research, special issue on ILP, 4:493-525.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beatrice Daille</author>
</authors>
<title>Conceptual structuring through term variation.</title>
<date>2003</date>
<booktitle>In Workshop on Multiword Expressions. Analysis, Acquisition and Treatment. Proceedings of the ACL&apos;03,</booktitle>
<location>Sapporo, Japan.</location>
<contexts>
<context position="5247" citStr="Daille (2003)" startWordPosition="796" endWordPosition="797">s could be sought in the future. 3 Related work A number of applications have relied on distributional analysis (Harris, 1971) in order to build classes of semantically related terms. This approach, which uses words that appear in the context of terms to formulate hypotheses on their semantic relatedness (Habert et al., 1996, for example), does not specify the relationship itself. Hence, synonyms, co-hyponyms, hyperonyms, etc. are not differentiated. More recent work on terminology structuring has focussed on formal similarity to develop hypotheses on the semantic relationships between terms: Daille (2003) uses derivational morphology; Grabar and Zweigenbaum (2002) use, as a starting point, a number of identical characters. Up to now, the focus has been on nouns and adjectives, since these structuring methods have been applied to lists of extracted candidate terms (Habert et al., 1996; Daille, 2003) or to lists of admitted terms (Grabar and Zweigenbaum, 2002). As a consequence, relationships considered have been mostly synonymic or taxonomic, or defined as term variations. On the other hand, other work has been carried out in order to acquire collocations. Most of these endeavours have focused </context>
</contexts>
<marker>Daille, 2003</marker>
<rawString>Beatrice Daille. 2003. Conceptual structuring through term variation. In Workshop on Multiword Expressions. Analysis, Acquisition and Treatment. Proceedings of the ACL&apos;03, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Drouin</author>
</authors>
<title>Term-extraction using non-technical corpora as a point of leverage.</title>
<date>2003</date>
<journal>Terminology,</journal>
<pages>9--1</pages>
<contexts>
<context position="17934" citStr="Drouin (2003)" startWordPosition="2878" endWordPosition="2879">espect to the total number of retrieved pairs; this is the precision rate (defined below). These two rates were evaluated using a test sample containing all this information. CompuTerm 2004 - 3rd International Workshop on Computational Terminology 43 To construct this test set, we have focused our attention on ten domain-specific terms: commande (command), configuration, fichier (file), Internet, logiciel (software), option, ordinateur (computer), serveur (server), systeme (system), utilisateur (user). The terms have been identified as the most specific to our corpus by a program developed by Drouin (2003) and called TER1vloSTAT. The ten most specific nouns have been produced by comparing our corpus of computing to the French corpus Le Monde, composed of newspaper articles (Lemay et al., 2004). Note that to prevent any bias in the results, none of these terms were used as positive examples during the pattern inference step. (They were removed from the example set.) For each of these 10 nouns, a manual identification of valid and invalid pairs was carried out. Linguists were asked to analyze the sentences and decide whether the highlighted pairs were valid N-V pairs. Examples of the sentences pr</context>
</contexts>
<marker>Drouin, 2003</marker>
<rawString>Patrick Drouin. 2003. Term-extraction using non-technical corpora as a point of leverage. Terminology, 9(1):99-115.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted E Dunning</author>
</authors>
<title>Accurate methods for the statistics of surprise and coincidence.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>1</issue>
<contexts>
<context position="12714" citStr="Dunning, 1993" startWordPosition="2022" endWordPosition="2023"> a list of invalid N-V pairs, we acquire them from our corpus using a statistical technique. This produces a list of all N-V pairs that appear in the same sentence, and assigns each a score. Many statistical coefficients exist (Manning and Schütze, 1999); most of them can be easily expressed with the help of a contingency table similar to that reproduced in Table 1 and by noting S = a + b + c + d. For example, the Vj Vk, k =� j Ni a b Nl,l =�i c d Table 1: Contingency table for the pair Ni-Vj Mutual Information coefficient is defined as: a MI = log2 (a + b)(a + c) and the loglike coefficient (Dunning, 1993) as: Log = alog a + blog b + clog c + dlog d − (a + 42 CompuTerm 2004 - 3rd International Workshop on Computational Terminology b) log(a+b) − (a+c) log(a+c) − (b+d) log(b+ d) − (c + d) log(c + d) + S log S. In the work presented here, we have adopted the Loglike coefficient. From the N-V pair list produced with this method, we have chosen the pairs that obtained the lower Loglike scores. As for the positive examples, we consider that each sentence containing one of the pairs is a counterexample and is added to E−. Finally, ASARES is launched with these E+ and E− sets; each containing about 260</context>
</contexts>
<marker>Dunning, 1993</marker>
<rawString>Ted E. Dunning. 1993. Accurate methods for the statistics of surprise and coincidence. Computational Linguistics, 19(1):6174.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Natalia Grabar</author>
<author>Pierre Zweigenbaum</author>
</authors>
<title>Lexically-based terminology structuring. some inherent limits.</title>
<date>2002</date>
<booktitle>In Second Workshop on Computational Terminology, Computerm</booktitle>
<location>Taipei, Taiwan.</location>
<contexts>
<context position="1655" citStr="Grabar and Zweigenbaum, 2002" startWordPosition="232" endWordPosition="235">sical statistical methods used for collocation acquisition. Moreover, the inferred patterns yield interesting clues on which structures are more likely to convey the target semantic link. 1 Introduction Recent literature in computational terminology has shown an increasing interest in identifying various semantic relationships between terms. Different strategies have been developed in order to identify pairs of terms that share a specific semantic relationship (such as hyperonymy or meronymy) or to build classes of terms. However, most strategies are based on &amp;quot;internal&amp;quot; or &amp;quot;external methods&amp;quot; (Grabar and Zweigenbaum, 2002), i.e. methods that rely on the form of terms or on the information gathered from contexts. (In some cases, an additional resource, such as a dictionary or a thesaurus, is used during the identification process.) The work reported here infers specific semantic relationships based on sets of examples and counterexamples. In this paper, the method is applied to a French corpus on computing to find noun-verb combinations in which verbs convey a meaning of realization. The work is carried out in order to assist terminographers in the enrichment of a dictionary on computing that includes collocatio</context>
<context position="5307" citStr="Grabar and Zweigenbaum (2002)" startWordPosition="802" endWordPosition="805">ork A number of applications have relied on distributional analysis (Harris, 1971) in order to build classes of semantically related terms. This approach, which uses words that appear in the context of terms to formulate hypotheses on their semantic relatedness (Habert et al., 1996, for example), does not specify the relationship itself. Hence, synonyms, co-hyponyms, hyperonyms, etc. are not differentiated. More recent work on terminology structuring has focussed on formal similarity to develop hypotheses on the semantic relationships between terms: Daille (2003) uses derivational morphology; Grabar and Zweigenbaum (2002) use, as a starting point, a number of identical characters. Up to now, the focus has been on nouns and adjectives, since these structuring methods have been applied to lists of extracted candidate terms (Habert et al., 1996; Daille, 2003) or to lists of admitted terms (Grabar and Zweigenbaum, 2002). As a consequence, relationships considered have been mostly synonymic or taxonomic, or defined as term variations. On the other hand, other work has been carried out in order to acquire collocations. Most of these endeavours have focused on purely statistical acquisition techniques (Church and Han</context>
</contexts>
<marker>Grabar, Zweigenbaum, 2002</marker>
<rawString>Natalia Grabar and Pierre Zweigenbaum. 2002. Lexically-based terminology structuring. some inherent limits. In Second Workshop on Computational Terminology, Computerm 2002. Coling 2002, Taipei, Taiwan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benoit Habert</author>
<author>Ellie Naulleau</author>
<author>Adeline Nazarenko</author>
</authors>
<title>Symbolic word clustering for medium-sized corpora.</title>
<date>1996</date>
<booktitle>In Proceedings of the 16th Conference on Computational Linguistics, Coling&apos;96,</booktitle>
<location>Copenhagen, Denmark.</location>
<contexts>
<context position="4960" citStr="Habert et al., 1996" startWordPosition="754" endWordPosition="757">aration of nouns) were chosen since they are believed to be frequent in technical corpora, such as the corpus of computing used in this experiment. However, this is seen as a first step in order to validate an acquisition process for semantically-related V-N pairs. Other semantic relationships could be sought in the future. 3 Related work A number of applications have relied on distributional analysis (Harris, 1971) in order to build classes of semantically related terms. This approach, which uses words that appear in the context of terms to formulate hypotheses on their semantic relatedness (Habert et al., 1996, for example), does not specify the relationship itself. Hence, synonyms, co-hyponyms, hyperonyms, etc. are not differentiated. More recent work on terminology structuring has focussed on formal similarity to develop hypotheses on the semantic relationships between terms: Daille (2003) uses derivational morphology; Grabar and Zweigenbaum (2002) use, as a starting point, a number of identical characters. Up to now, the focus has been on nouns and adjectives, since these structuring methods have been applied to lists of extracted candidate terms (Habert et al., 1996; Daille, 2003) or to lists o</context>
</contexts>
<marker>Habert, Naulleau, Nazarenko, 1996</marker>
<rawString>Benoit Habert, Ellie Naulleau, and Adeline Nazarenko. 1996. Symbolic word clustering for medium-sized corpora. In Proceedings of the 16th Conference on Computational Linguistics, Coling&apos;96, Copenhagen, Denmark.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zellig Harris</author>
</authors>
<title>Structures mathematiques du langage.</title>
<date>1971</date>
<location>Paris: Dunod.</location>
<contexts>
<context position="4760" citStr="Harris, 1971" startWordPosition="722" endWordPosition="723">port verbs represented by the LFs Funci, Operi, Laborij (e.g., &amp;quot;creer un fichier&apos;; &amp;quot;create a file&apos;; &amp;quot;definir une variable&apos;; &amp;quot;define a variable&apos;).). Realization verbs (and verbs denoting the preparation of nouns) were chosen since they are believed to be frequent in technical corpora, such as the corpus of computing used in this experiment. However, this is seen as a first step in order to validate an acquisition process for semantically-related V-N pairs. Other semantic relationships could be sought in the future. 3 Related work A number of applications have relied on distributional analysis (Harris, 1971) in order to build classes of semantically related terms. This approach, which uses words that appear in the context of terms to formulate hypotheses on their semantic relatedness (Habert et al., 1996, for example), does not specify the relationship itself. Hence, synonyms, co-hyponyms, hyperonyms, etc. are not differentiated. More recent work on terminology structuring has focussed on formal similarity to develop hypotheses on the semantic relationships between terms: Daille (2003) uses derivational morphology; Grabar and Zweigenbaum (2002) use, as a starting point, a number of identical char</context>
</contexts>
<marker>Harris, 1971</marker>
<rawString>Zellig Harris. 1971. Structures mathematiques du langage. Paris: Dunod.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Kilgarriff</author>
<author>David Tugwell</author>
</authors>
<title>WORD-SKETCH: Extraction and Display of Significant Collocations for Lexicography.</title>
<date>2001</date>
<booktitle>In Workshop on Collocation: Computational Extraction, Analysis and Exploitation, 39th ACL and 10th EACL Conference,</booktitle>
<location>Toulouse, France.</location>
<contexts>
<context position="6396" citStr="Kilgarriff and Tugwell, 2001" startWordPosition="978" endWordPosition="981">ed out in order to acquire collocations. Most of these endeavours have focused on purely statistical acquisition techniques (Church and Hanks, &apos;However, our interpretation of LFs in this work is much looser, since we admitted verbs that would not be considered to be members of true collocations as Mel&apos;cuk et al. (1984 1999) define them, i.e. groups of lexical units that share a restricted cooccurrence relationship. 1990), on linguisitic acquisition (by the use of Part-of-Speech filters hand-crafted by a linguist) (Oueslati, 1999) or, more frequently, on a combination of the two (Smadja, 1993; Kilgarriff and Tugwell, 2001, for example). It is worth noting that although these techniques are able to identify N-V pairs, they do not specify the relationship between N and V, nor are they capable of focusing on a subset of N-V pairs. The original acquisition methodology we present in the next section will allow us to overcome this limitation. 4 Methodology for finding valid noun-verb pairs This section is devoted to the description of the methodology and the data we use to acquire semantically related noun-verb pairs. We first describe the specialized corpus used in this experiment. Then, we briefly present ASARES, </context>
</contexts>
<marker>Kilgarriff, Tugwell, 2001</marker>
<rawString>Adam Kilgarriff and David Tugwell. 2001. WORD-SKETCH: Extraction and Display of Significant Collocations for Lexicography. In Workshop on Collocation: Computational Extraction, Analysis and Exploitation, 39th ACL and 10th EACL Conference, Toulouse, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chantal Lemay</author>
<author>Marie-Claude L&apos;Homme</author>
<author>Patrick Drouin</author>
</authors>
<title>Two methods for extracting &amp;quot;specific&amp;quot; single-word terms from specialized corpora.</title>
<date>2004</date>
<journal>Forthcoming.</journal>
<contexts>
<context position="18125" citStr="Lemay et al., 2004" startWordPosition="2909" endWordPosition="2912">2004 - 3rd International Workshop on Computational Terminology 43 To construct this test set, we have focused our attention on ten domain-specific terms: commande (command), configuration, fichier (file), Internet, logiciel (software), option, ordinateur (computer), serveur (server), systeme (system), utilisateur (user). The terms have been identified as the most specific to our corpus by a program developed by Drouin (2003) and called TER1vloSTAT. The ten most specific nouns have been produced by comparing our corpus of computing to the French corpus Le Monde, composed of newspaper articles (Lemay et al., 2004). Note that to prevent any bias in the results, none of these terms were used as positive examples during the pattern inference step. (They were removed from the example set.) For each of these 10 nouns, a manual identification of valid and invalid pairs was carried out. Linguists were asked to analyze the sentences and decide whether the highlighted pairs were valid N-V pairs. Examples of the sentences produced are given in Table 2 for the term utilisateur (user). A pair is considered as valid if at least one of its occurrences has the desired semantic (and syntactic) relationship (cf. sectio</context>
</contexts>
<marker>Lemay, L&apos;Homme, Drouin, 2004</marker>
<rawString>Chantal Lemay, Marie-Claude L&apos;Homme, and Patrick Drouin. 2004. Two methods for extracting &amp;quot;specific&amp;quot; single-word terms from specialized corpora. Forthcoming.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Claude L&apos;Homme</author>
</authors>
<title>Selection de termes dans un dictionnaire d&apos;informatique : Comparaison de corpus et criteres lexicosemantiques.</title>
<date>2004</date>
<booktitle>In Euralex 2004. Proceedings,</booktitle>
<location>Lorient, France. Forthcoming.</location>
<contexts>
<context position="2286" citStr="L&apos;Homme, 2004" startWordPosition="336" endWordPosition="337">at rely on the form of terms or on the information gathered from contexts. (In some cases, an additional resource, such as a dictionary or a thesaurus, is used during the identification process.) The work reported here infers specific semantic relationships based on sets of examples and counterexamples. In this paper, the method is applied to a French corpus on computing to find noun-verb combinations in which verbs convey a meaning of realization. The work is carried out in order to assist terminographers in the enrichment of a dictionary on computing that includes collocational information (L&apos;Homme, 2004). Even though this work is carried out for terminographical and lexicographical purposes, it can certainly be of use in other applications, namely information retrieval. Indeed, such rich semantic links can be used to extend indices or reformulate queries (similar to the work by Voorhees (1994) with WoRDNET relations). 2 Objectives The noun-verb combinations we aim to identify have the following characteristics. They share: • A syntactic relationship : nouns can be subjects (e.g., &amp;quot;ordinateur tourne&amp;quot;; &amp;quot;computer runs&amp;quot;); direct objects (e.g., &amp;quot;configurer l&apos;application&amp;quot;; &amp;quot;configure the applicatio</context>
</contexts>
<marker>L&apos;Homme, 2004</marker>
<rawString>Marie-Claude L&apos;Homme. 2004. Selection de termes dans un dictionnaire d&apos;informatique : Comparaison de corpus et criteres lexicosemantiques. In Euralex 2004. Proceedings, Lorient, France. Forthcoming.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher D Manning</author>
<author>Hinrich Schütze</author>
</authors>
<title>Foundations of Statistical Natural Language Processing.</title>
<date>1999</date>
<publisher>The MIT Press,</publisher>
<location>Cambridge, MA, USA.</location>
<contexts>
<context position="12354" citStr="Manning and Schütze, 1999" startWordPosition="1942" endWordPosition="1946"> the target semantic link or even a syntactic link in the sentences that are extracted. Some of the examples in E+ might be incorrect, but ASARES tolerates a certain amount of noise. A totally different technique is needed to produce the E− set, since no information concerning verbs that are not semantically related is available in the terminological database. To obtain a list of invalid N-V pairs, we acquire them from our corpus using a statistical technique. This produces a list of all N-V pairs that appear in the same sentence, and assigns each a score. Many statistical coefficients exist (Manning and Schütze, 1999); most of them can be easily expressed with the help of a contingency table similar to that reproduced in Table 1 and by noting S = a + b + c + d. For example, the Vj Vk, k =� j Ni a b Nl,l =�i c d Table 1: Contingency table for the pair Ni-Vj Mutual Information coefficient is defined as: a MI = log2 (a + b)(a + c) and the loglike coefficient (Dunning, 1993) as: Log = alog a + blog b + clog c + dlog d − (a + 42 CompuTerm 2004 - 3rd International Workshop on Computational Terminology b) log(a+b) − (a+c) log(a+c) − (b+d) log(b+ d) − (c + d) log(c + d) + S log S. In the work presented here, we ha</context>
</contexts>
<marker>Manning, Schütze, 1999</marker>
<rawString>Christopher D. Manning and Hinrich Schütze. 1999. Foundations of Statistical Natural Language Processing. The MIT Press, Cambridge, MA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Igor Mel&apos;cuk</author>
<author>Nadia Arbatchewsky-Jumarie</author>
<author>Leo Elnitsky</author>
<author>Lidija Iordanskaja</author>
<author>Adele Lessard</author>
<author>Louise Dagenais</author>
<author>Marie-Noelle Lefebvre</author>
<author>Suzanne Mantha</author>
<author>Alain Polguere</author>
</authors>
<title>Dictionnaire explicatif et combinatoire du fran�ais contemporain, Recherches lexico-semantiques, volumes I-IV. Les Presses de l&apos;Universite de Montréal,</title>
<date>1984</date>
<location>Montréal, QC,</location>
<contexts>
<context position="3873" citStr="Mel&apos;cuk et al., 1984" startWordPosition="578" endWordPosition="581">viguer sur Internet&amp;quot;; &amp;quot;surf the Internet&amp;quot;); 3. verbs that refer to activities carried out by means of the nouns (e.g., &amp;quot;activer l&apos;option au moyen de cette commande&amp;quot;; &amp;quot;activate this option with this command&amp;quot;); and, finally, 4. verbs that refer to the processes by which nouns are prepared fur use (e.g., &amp;quot;instaler un logiciel&amp;quot;; &amp;quot;install an application&amp;quot;). These noun-verb combinations will hereafter be called valid N-V pairs. 40 CompuTerm 2004 - 3rd International Workshop on Computational Terminology The semantic relationships listed above correspond to a set of lexical functions (LFs) defined in (Mel&apos;cuk et al., 1984 1999), i.e. LFs used to represent realization (e.g., Facti, Reali, Labrealij) and to represent the process by which something is prepared (Prepar)1. (Both of these types of LFs can be combined with others [to create complex lexical functions].) These LFs are opposed to support verbs represented by the LFs Funci, Operi, Laborij (e.g., &amp;quot;creer un fichier&apos;; &amp;quot;create a file&apos;; &amp;quot;definir une variable&apos;; &amp;quot;define a variable&apos;).). Realization verbs (and verbs denoting the preparation of nouns) were chosen since they are believed to be frequent in technical corpora, such as the corpus of computing used in t</context>
<context position="6087" citStr="Mel&apos;cuk et al. (1984" startWordPosition="932" endWordPosition="935">plied to lists of extracted candidate terms (Habert et al., 1996; Daille, 2003) or to lists of admitted terms (Grabar and Zweigenbaum, 2002). As a consequence, relationships considered have been mostly synonymic or taxonomic, or defined as term variations. On the other hand, other work has been carried out in order to acquire collocations. Most of these endeavours have focused on purely statistical acquisition techniques (Church and Hanks, &apos;However, our interpretation of LFs in this work is much looser, since we admitted verbs that would not be considered to be members of true collocations as Mel&apos;cuk et al. (1984 1999) define them, i.e. groups of lexical units that share a restricted cooccurrence relationship. 1990), on linguisitic acquisition (by the use of Part-of-Speech filters hand-crafted by a linguist) (Oueslati, 1999) or, more frequently, on a combination of the two (Smadja, 1993; Kilgarriff and Tugwell, 2001, for example). It is worth noting that although these techniques are able to identify N-V pairs, they do not specify the relationship between N and V, nor are they capable of focusing on a subset of N-V pairs. The original acquisition methodology we present in the next section will allow u</context>
</contexts>
<marker>Mel&apos;cuk, Arbatchewsky-Jumarie, Elnitsky, Iordanskaja, Lessard, Dagenais, Lefebvre, Mantha, Polguere, 1984</marker>
<rawString>Igor Mel&apos;cuk, Nadia Arbatchewsky-Jumarie, Leo Elnitsky, Lidija Iordanskaja, Adele Lessard, Louise Dagenais, Marie-Noelle Lefebvre, Suzanne Mantha, and Alain Polguere. 1984-1999. Dictionnaire explicatif et combinatoire du fran�ais contemporain, Recherches lexico-semantiques, volumes I-IV. Les Presses de l&apos;Universite de Montréal, Montréal, QC, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Muggleton</author>
<author>Luc De-Raedt</author>
</authors>
<title>Inductive Logic Programming: Theory and Methods.</title>
<date>1994</date>
<journal>Journal of Logic Programming,</journal>
<pages>19--20</pages>
<contexts>
<context position="8180" citStr="Muggleton and De-Raedt, 1994" startWordPosition="1260" endWordPosition="1263">t using the tool CORDIAL2. Each word is accompanied by its lemma and Part-of-Speech tag (noun, verb, adjective). Also, the tool indicates inflection (gender and number for nouns, tense and person for verbs) and gives syntactic information (head-modifier) for noun phrases. 4.2 Overview of ASARES The method used for the acquisition of N-V pairs relies mainly on ASARES, a pattern inference tool. ASARES is presented in detail in (Claveau et al., 2003). We simply give a short account of its basic principles herein. ASARES is based on a Machine Learning technique, Inductive Logic Programming (ILP) (Muggleton and De-Raedt, 1994), which infers general morpho-syntactic patterns from a set of examples (this set is noted E+ hereafter) and counter-examples (E−) of the elements one 2CORDIAL is a commercial product of SynapseDeveloppement. CompuTerm 2004 - 3rd International Workshop on Computational Terminology 41 wants to acquire and their context. The contextual patterns produced can then be applied to the corpus in order to retrieve new elements. The acquisition process can be summarized in 3 steps: 1. construction of the sets of examples (and counter-examples); 2. inference of extraction patterns with ASARES; and 3. ext</context>
</contexts>
<marker>Muggleton, De-Raedt, 1994</marker>
<rawString>Stephen Muggleton and Luc De-Raedt. 1994. Inductive Logic Programming: Theory and Methods. Journal of Logic Programming, 19-20:629-679.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rochdi Oueslati</author>
</authors>
<title>Aide a l&apos;acquisition de connaissances a partir de corpus.</title>
<date>1999</date>
<tech>Ph.D. thesis,</tech>
<institution>Univesite Louis Pasteur,</institution>
<location>Strasbourg, France.</location>
<contexts>
<context position="6303" citStr="Oueslati, 1999" startWordPosition="964" endWordPosition="965">mic, or defined as term variations. On the other hand, other work has been carried out in order to acquire collocations. Most of these endeavours have focused on purely statistical acquisition techniques (Church and Hanks, &apos;However, our interpretation of LFs in this work is much looser, since we admitted verbs that would not be considered to be members of true collocations as Mel&apos;cuk et al. (1984 1999) define them, i.e. groups of lexical units that share a restricted cooccurrence relationship. 1990), on linguisitic acquisition (by the use of Part-of-Speech filters hand-crafted by a linguist) (Oueslati, 1999) or, more frequently, on a combination of the two (Smadja, 1993; Kilgarriff and Tugwell, 2001, for example). It is worth noting that although these techniques are able to identify N-V pairs, they do not specify the relationship between N and V, nor are they capable of focusing on a subset of N-V pairs. The original acquisition methodology we present in the next section will allow us to overcome this limitation. 4 Methodology for finding valid noun-verb pairs This section is devoted to the description of the methodology and the data we use to acquire semantically related noun-verb pairs. We fir</context>
</contexts>
<marker>Oueslati, 1999</marker>
<rawString>Rochdi Oueslati. 1999. Aide a l&apos;acquisition de connaissances a partir de corpus. Ph.D. thesis, Univesite Louis Pasteur, Strasbourg, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Darren Pearce</author>
</authors>
<title>A Comparative Evaluation of Collocation Extraction Techniques.</title>
<date>2002</date>
<booktitle>In 3rd International Conference on Language Resources and Evaluation, LREC 02, Las Palmas de Gran Canaria,</booktitle>
<contexts>
<context position="10354" citStr="Pearce, 2002" startWordPosition="1606" endWordPosition="1607">s expressing morpho-syntactic patterns that generalize the structures of sentences containing the target element (examples) but not the structures of the sentences containing counter-examples. The background knowledge encodes information about each word occurring in the example or counter-example, namely the meaning of its tag (e.g., adjective in plural form, infinitive verb). The main benefits of this acquisition technique lie in the inferred patterns. Indeed, contrary to the more classical statistical methods (Mutual Information, Loglike..., see below) used for collocation acquisition (see (Pearce, 2002) for a review), these patterns allow: 1. understanding of the results, that is, why a specific element has been retrieved or not; 2. highlighting of the corpus-specific structures conveying the target element. In addition to its explanatory capacity, this symbolic acquisition technique has obtained good results for other acquisition tasks when compared to existing statistical techniques (Bouillon et al., 2002). 4.3 Acquisition process To infer extraction patterns, ASARES needs a set of examples (E+) and a set of counter-examples (E−) of the elements we want to retrieve. In our case, E+ must th</context>
</contexts>
<marker>Pearce, 2002</marker>
<rawString>Darren Pearce. 2002. A Comparative Evaluation of Collocation Extraction Techniques. In 3rd International Conference on Language Resources and Evaluation, LREC 02, Las Palmas de Gran Canaria, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Pustejovsky</author>
</authors>
<title>The Generative Lexicon.</title>
<date>1995</date>
<publisher>The MIT Press,</publisher>
<location>Cambridge, MA, USA.</location>
<contexts>
<context position="9003" citStr="Pustejovsky, 1995" startWordPosition="1390" endWordPosition="1391">nt. CompuTerm 2004 - 3rd International Workshop on Computational Terminology 41 wants to acquire and their context. The contextual patterns produced can then be applied to the corpus in order to retrieve new elements. The acquisition process can be summarized in 3 steps: 1. construction of the sets of examples (and counter-examples); 2. inference of extraction patterns with ASARES; and 3. extraction of N-V pairs from the corpus with the inferred patterns. ASARES has been previously applied to the acquisition of word pairs sharing semantic relations defined in the Generative Lexicon framework (Pustejovsky, 1995) and called qualia relations (Bouillon et al., 2001). Here, we propose to use ASARES in a quite similar way to retrieve our valid N-V pairs. However, the N-V combinations sought are more specific than those that were identified in these previous experiments. Formally, ILP aims at inferring logic programs (sets of Horn clauses, noted H) from a set of facts (examples and counter-examples of the concept to be learnt) and background knowledge (B), such that the program H logically entails the examples with respect to the background knowledge and rejects (most of) the counterexamples. This is trans</context>
</contexts>
<marker>Pustejovsky, 1995</marker>
<rawString>James Pustejovsky. 1995. The Generative Lexicon. The MIT Press, Cambridge, MA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank Smadja</author>
</authors>
<date>1993</date>
<booktitle>Retrieving Collocations from Text: XTRACT. Computational Linguistics,</booktitle>
<pages>19--1</pages>
<contexts>
<context position="6366" citStr="Smadja, 1993" startWordPosition="976" endWordPosition="977">has been carried out in order to acquire collocations. Most of these endeavours have focused on purely statistical acquisition techniques (Church and Hanks, &apos;However, our interpretation of LFs in this work is much looser, since we admitted verbs that would not be considered to be members of true collocations as Mel&apos;cuk et al. (1984 1999) define them, i.e. groups of lexical units that share a restricted cooccurrence relationship. 1990), on linguisitic acquisition (by the use of Part-of-Speech filters hand-crafted by a linguist) (Oueslati, 1999) or, more frequently, on a combination of the two (Smadja, 1993; Kilgarriff and Tugwell, 2001, for example). It is worth noting that although these techniques are able to identify N-V pairs, they do not specify the relationship between N and V, nor are they capable of focusing on a subset of N-V pairs. The original acquisition methodology we present in the next section will allow us to overcome this limitation. 4 Methodology for finding valid noun-verb pairs This section is devoted to the description of the methodology and the data we use to acquire semantically related noun-verb pairs. We first describe the specialized corpus used in this experiment. The</context>
</contexts>
<marker>Smadja, 1993</marker>
<rawString>Frank Smadja. 1993. Retrieving Collocations from Text: XTRACT. Computational Linguistics, 19(1):143-178.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen M Voorhees</author>
</authors>
<title>Query Expansion Using Lexical-Semantic Relations.</title>
<date>1994</date>
<booktitle>In Proceedings of ACM SIGIR&apos;94,</booktitle>
<location>Dublin, Ireland.</location>
<contexts>
<context position="2581" citStr="Voorhees (1994)" startWordPosition="382" endWordPosition="383">rexamples. In this paper, the method is applied to a French corpus on computing to find noun-verb combinations in which verbs convey a meaning of realization. The work is carried out in order to assist terminographers in the enrichment of a dictionary on computing that includes collocational information (L&apos;Homme, 2004). Even though this work is carried out for terminographical and lexicographical purposes, it can certainly be of use in other applications, namely information retrieval. Indeed, such rich semantic links can be used to extend indices or reformulate queries (similar to the work by Voorhees (1994) with WoRDNET relations). 2 Objectives The noun-verb combinations we aim to identify have the following characteristics. They share: • A syntactic relationship : nouns can be subjects (e.g., &amp;quot;ordinateur tourne&amp;quot;; &amp;quot;computer runs&amp;quot;); direct objects (e.g., &amp;quot;configurer l&apos;application&amp;quot;; &amp;quot;configure the application&amp;quot;); or second complement (e.g., &amp;quot;charger x dans la memoire&amp;quot;; &amp;quot;load x into memory&amp;quot;); • A valid semantic relationship. The following semantic relationships are sought: 1. verbs that refer to activities carried out by the nouns (e.g., &amp;quot;serveur demarre&amp;quot;; &amp;quot;server starts&amp;quot;); 2. verbs that refer to us</context>
</contexts>
<marker>Voorhees, 1994</marker>
<rawString>Ellen M. Voorhees. 1994. Query Expansion Using Lexical-Semantic Relations. In Proceedings of ACM SIGIR&apos;94, Dublin, Ireland.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>