<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.007882">
<title confidence="0.987949">
Multi-domain Sentiment Classification
</title>
<author confidence="0.996545">
Shoushan Li and Chengqing Zong
</author>
<affiliation confidence="0.994128">
National Laboratory of Pattern Recognition
Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China
</affiliation>
<email confidence="0.973703">
{sshanli,cqzong}@nlpr.ia.ac.cn
</email>
<sectionHeader confidence="0.993333" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999177384615385">
This paper addresses a new task in sentiment
classification, called multi-domain sentiment
classification, that aims to improve perform-
ance through fusing training data from multi-
ple domains. To achieve this, we propose two
approaches of fusion, feature-level and classi-
fier-level, to use training data from multiple
domains simultaneously. Experimental stud-
ies show that multi-domain sentiment classi-
fication using the classifier-level approach
performs much better than single domain
classification (using the training data indi-
vidually).
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999954625">
Sentiment classification is a special task of text
categorization that aims to classify documents
according to their opinion of, or sentiment toward
a given subject (e.g., if an opinion is supported or
not) (Pang et al., 2002). This task has created a
considerable interest due to its wide applications.
Sentiment classification is a very domain-
specific problem; training a classifier using the
data from one domain may fail when testing
against data from another. As a result, real
application systems usually require some labeled
data from multiple domains, guaranteeing an
acceptable performance for different domains.
However, each domain has a very limited amount
of training data due to the fact that creating large-
scale high-quality labeled corpora is difficult and
time-consuming. Given the limited multi-domain
training data, an interesting task arises, how to
best make full use of all training data to improve
sentiment classification performance. We name
this new task, ‘multi-domain sentiment
classification’.
In this paper, we propose two approaches to
multi-domain sentiment classification. In the first,
called feature-level fusion, we combine the feature
sets from all the domains into one feature set.
Using the unified feature set, we train a classifier
using all the training data regardless of domain. In
the second approach, classifier-level fusion, we
train a base classifier using the training data from
each domain and then apply combination methods
to combine the base classifiers.
</bodyText>
<sectionHeader confidence="0.999748" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999876235294118">
Sentiment classification has become a hot topic
since the publication work that discusses classifi-
cation of movie reviews by Pang et al. (2002).
This was followed by a great many studies into
sentiment classification focusing on many do-
mains besides that of movie.
Research into sentiment classification over
multiple domains remains sparse. It is worth not-
ing that Blitzer et al. (2007) deal with the domain
adaptation problem for sentiment classification
where labeled data from one domain is used to
train a classifier for classifying data from a differ-
ent domain. Our work focuses on the problem of
how to make multiple domains ‘help each other’
when all contain some labeled samples. These two
problems are both important for real applications
of sentiment classification.
</bodyText>
<sectionHeader confidence="0.988431" genericHeader="method">
3 Our Approaches
</sectionHeader>
<subsectionHeader confidence="0.999288">
3.1 Problem Statement
</subsectionHeader>
<bodyText confidence="0.980944">
In a standard supervised classification problem,
we seek a predictor f (also called a classifier) that
</bodyText>
<page confidence="0.991873">
257
</page>
<reference confidence="0.223661">
Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pages 257–260,
Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics
</reference>
<bodyText confidence="0.99784225">
maps an input vector x to the corresponding class
label y. The predictor is trained on a finite set of
labeled examples { (Xi ,Y i ) } (i=1,...,n) and its
objective is to minimize expected error, i.e.,
</bodyText>
<equation confidence="0.9970842">
n
arg min( ( ), )
∑L f X Y
i i
f∈Η i
</equation>
<bodyText confidence="0.9279083125">
Where L is a prescribed loss function and H is a
set of functions called the hypothesis space, which
consists of functions from x to y. In sentiment
classification, the input vector of one document is
constructed from weights of terms. The terms
(t1 ,..., tN) are possibly words, word n-grams, or
even phrases extracted from the training data, with
N being the number of terms. The output label y
has a value of 1 or -1 representing a positive or
negative sentiment classification.
In multi-domain classification, m different
domains are indexed by k={1,...,m}, each with
nk training samples ( , )
Xik Y i k ik = {1,..., nk } . A
straightforward approach is to train a predictor fk
for the k-th domain only using the training
</bodyText>
<equation confidence="0.946053">
data {( , )}
Xik Y i k . We call this approach single
</equation>
<figureCaption confidence="0.98958425">
domain classification and show its architecture in
Figure 1.
Figure 1: The architecture of single domain classifica-
tion.
</figureCaption>
<subsectionHeader confidence="0.999527">
3.2 Feature-level Fusion Approach
</subsectionHeader>
<bodyText confidence="0.997942692307692">
Although terms are extracted from multiple do-
mains, some occur in all domains and convey the
same sentiment (this can be called global senti-
ment information). For example, some terms like
‘excellent’ and ‘perfect’ express positive senti-
ment information independent of domain. To learn
the global sentiment information more correctly,
we can pool the training data from all domains for
training. Our first approach is using a common set
of terms ( &apos;1,..., &apos; )
t t Nall to construct a uniform fea-
ture vector x&apos; and then train a predictor using all
training data:
</bodyText>
<equation confidence="0.9828368">
m nk
arg min ∑∑ L f X Y
( ( &apos; ), )
i i
k k
</equation>
<bodyText confidence="0.99990125">
We call this approach feature-level fusion and
show its architecture in Figure 2. The common set
of terms is the union of the term sets from
multiple domains.
</bodyText>
<subsectionHeader confidence="0.78362625">
Training Data Training Data . . . Training Data
from Domain 1 from Domain 2 from Domain m
Training Data from all Domains
using a Uniform Feature Vector
</subsectionHeader>
<figureCaption confidence="0.9914385">
Figure 2: The architecture of the feature-level fusion
approach
</figureCaption>
<bodyText confidence="0.99997275">
Feature-level fusion approach is simple to
implement and needs no extra labeled data. Note
that training data from different domains
contribute differently to the learning process for a
specific domain. For example, given data from
three domains, books, DVDs and kitchen, we
decide to train a classifier for classifying reviews
from books. As the training data from DVDs is
much more similar to books than that from
kitchen (Blitzer et al., 2007), we should give the
data from DVDs a higher weight. Unfortunately,
the feature-level fusion approach lacks the
capacity to do this. A more qualified approach is
required to deal with the differences among the
classification abilities of training data from
different domains.
</bodyText>
<subsectionHeader confidence="0.999522">
3.3 Classifier-level Fusion Approach
</subsectionHeader>
<bodyText confidence="0.999763636363636">
As mentioned in sub-Section 2.1, single domain
classification is used to train a single classifier for
each domain using the training data in the corre-
sponding domain. As all these single classifiers
aim to determine the sentiment orientation of a
document, a single classifier can certainly be used
to classify documents from other domains. Given
multiple single classifiers, our second approach is
to combine them to be a multiple classifier system
for sentiment classification. We call this approach
classifier-level fusion and show its architecture in
</bodyText>
<figureCaption confidence="0.626692">
Figure 3. This approach consists of two main steps:
</figureCaption>
<figure confidence="0.996229655172414">
f =
. . .
Classifier
1
Classifier
m
Classifier
2
Training Data
from Domain 1
Training Data
from Domain 2
Training Data
from Domain m
. . .
Testing Data
from Domain 1
Testing Data
from Domain 2
Testing Data
from Domain m
. . .
f =
all
fall all
∈ Η k=1 ik=1
Classifier
Testing Data Testing Data . . . Testing Data
from Domain 1 from Domain 2 from Domain m
</figure>
<page confidence="0.97854">
258
</page>
<bodyText confidence="0.991179909090909">
(1) train multiple base classifiers (2) combine the
base classifiers. In the first step, the base classifi-
ers are multiple single classifiers fk (k=1,...,m)
from all domains. In the second step, many com-
bination methods can be applied to combine the
base classifiers. A well-known method called
meta-learning (ML) has been shown to be very
effective (Vilalta and Drissi, 2002). The key idea
behind this method is to train a meta-classifier
with input attributes that are the output of the base
classifiers.
</bodyText>
<figureCaption confidence="0.9948285">
Figure 3: The architecture of the classifier-level fusion
approach
</figureCaption>
<bodyText confidence="0.989601166666667">
Formally, let Xk &apos; denote a feature vector of a
sample from the development data of the
k&apos; -th domain (k&apos;= 1,...,m ) . The output of the
k-th base classifier fk on this sample is the
probability distribution over the set of classes
{c1,c2,...,cn}, i.e.,
</bodyText>
<equation confidence="0.952136">
pk(Xk&apos;) = &lt; pk(c1  |Xk&apos;),...,pk(cn  |Xk&apos;) &gt;
</equation>
<bodyText confidence="0.970381666666667">
For the k&apos; -th domain, we train a meta-classifier
fk&apos; (k&apos;= 1,..., m) using the development data from
the k&apos; -th domain with the meta-level feature
</bodyText>
<equation confidence="0.9733748">
eta
vector X G Rm n
X k = &lt; p X k p k X k p m X k
meta 1 ( &apos; ),..., ( &apos; ),..., ( &apos; ) &gt;
&apos;
</equation>
<bodyText confidence="0.998205428571429">
Each meta-classifier is then used to test the testing
data from the same domain.
Different from the feature-level approach, the
classifier-level approach treats the training data
from different domains individually and thus has
the ability to take the differences in classification
abilities into account.
</bodyText>
<sectionHeader confidence="0.999004" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.997074844444444">
Data Set: We carry out our experiments on the
labeled product reviews from four domains: books,
DVDs, electronics, and kitchen appliances1. Each
domain contains 1,000 positive and 1,000
negative reviews.
Experiment Implementation: We apply SVM
algorithm to construct our classifiers which has
been shown to perform better than many other
classification algorithms (Pang et al., 2002). Here,
we use LIBSVM2 with a linear kernel function for
training and testing. In our experiments, the data
in each domain are partitioned randomly into
training data, development data and testing data
with the proportion of 70%, 20% and 10%
respectively. The development data are used to
train the meta-classifier.
Baseline: The baseline uses the single domain
classification approach mentioned in sub-Section
2.1. We test four different feature sets to construct
our feature vector. First, we use unigrams (e.g.,
‘happy’) as features and perform the standard fea-
ture selection process to find the optimal feature
set of unigrams (1Gram). The selection method is
Bi-Normal Separation (BNS) that is reported to be
excellent in many text categorization tasks (For-
man, 2003). The criterion of the optimization is to
find the set of unigrams with the best performance
on the development data through selecting the
features with high BNS scores. Then, we get the
optimal word bi-gram (e.g., ‘very happy’) (2Gram)
and mixed feature set (1+2Gram) in the same way.
The fourth feature set (1Gram+2Gram) also con-
sists of unigrams and bi-grams just like the third
one. The difference between them lies in their se-
lection strategy. The third feature set is obtained
through selecting the unigrams and bi-grams with
high BNS scores while the fourth one is obtained
through simply uniting the two optimal sets of
1Gram and 2Gram.
From Table 1, we see that 1Gram+2Gram fea-
tures perform much better than other types of fea-
tures, which implies that we need to select good
unigram and bi-gram features separately before
combine them. Although the size of our training
data are smaller than that reported in Blitzer et al.
</bodyText>
<footnote confidence="0.9920705">
1 This data set is collected by Blitzer et al. (2007):
http://www.seas.upenn.edu/~mdredze/datasets/sentiment/
2 LIBSVM is an integrated software for SVM:
http://www.csie.ntu.edu.tw/~cjlin/libsvm/
</footnote>
<figure confidence="0.999022428571428">
Development Data
from Domain 1
Multiple Classifier
System 1
Base Classifier
1
Training Data
from Domain 1
Testing Data
from Domain 1
Training Data
from Domain 2
Development Data
from Domain 2
Testing Data
from Domain 2
Multiple Classifier
System 2
Base Classifier
2
. . .
. . .
. . .
. . .
. . .
Training Data
from Domain m
Development Data
from Domain m
Testing Data
from Domain m
Multiple Classifier
System m
Base Classifier
m
</figure>
<page confidence="0.989923">
259
</page>
<bodyText confidence="0.9348725">
(2007) (70% vs. 80%), the classification perform-
ance is comparative to theirs.
</bodyText>
<table confidence="0.997582833333333">
Features Books DVDs Elec- Kitchen
tronic
1Gram 0.75 0.84 0.8 0.825
2Gram 0.75 0.73 0.815 0.785
1+2Gram 0.765 0.81 0.825 0.80
1Gram+2Gram 0.79 0.845 0.85 0.845
</table>
<tableCaption confidence="0.99863">
Table 1: Accuracy results on the testing data of single
domain classification using different feature sets.
</tableCaption>
<bodyText confidence="0.961313625">
We implement the fusion using 1+2Gram and
1Gram+2Gram respectively. From Figure 4, we
see that both the two fusion approaches generally
outperform single domain classification when us-
ing 1+2Gram features. They increase the average
accuracy from 0.8 to 0.82375 and 0.83875, a sig-
nificant relative error reduction of 11.87% and
19.38% over baseline.
</bodyText>
<figure confidence="0.990954375">
1+2Gram Features
86
83 83 83 84
82.5 81 82.5 81 80 82.5
76.5
Books DVDs Electronics Kitchen
1Gram+2Gram Features
Books DVDs Electronics Kitchen
</figure>
<figureCaption confidence="0.9980355">
Figure 4: Accuracy results on the testing data using
multi-domain classification with different approaches.
</figureCaption>
<bodyText confidence="0.999977363636364">
However, when the performance of baseline in-
creases, the feature level approach fails to help the
performance improvement in three domains. This
is mainly because the base classifiers perform ex-
tremely unbalanced on the testing data of these
domains. For example, the four base classifiers
from Books, DVDs, Electronics, and Kitchen
achieve the accuracies of 0.675, 0.62, 0.85, and
0.79 on the testing data from Electronics respec-
tively. Dealing with such an unbalanced perform-
ance, we definitely need to put enough high
weight on the training data from Electronics.
However, the feature-level fusion approach sim-
ply pools all training data from different domains
and treats them equally. Thus it can not capture
the unbalanced information. In contrast, meta-
learning is able to learn the unbalance automati-
cally through training the meta-classifier using the
development data. Therefore, it can still increase
the average accuracy from 0.8325 to 0.8625, an
impressive relative error reduction of 17.91% over
baseline.
</bodyText>
<sectionHeader confidence="0.9993" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999931125">
In this paper, we propose two approaches to multi-
domain classification task on sentiment classifica-
tion. Empirical studies show that the classifier-
level approach generally outperforms the feature
approach. Compared to single domain classifica-
tion, multi-domain classification with the classi-
fier-level approach can consistently achieve much
better results.
</bodyText>
<sectionHeader confidence="0.997475" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999758">
The research work described in this paper has
been partially supported by the Natural Science
Foundation of China under Grant No. 60575043,
and 60121302, National High-Tech Research and
Development Program of China under Grant No.
2006AA01Z194, National Key Technologies
R&amp;D Program of China under Grant No.
2006BAH03B02, and Nokia (China) Co. Ltd as
well.
</bodyText>
<sectionHeader confidence="0.999268" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999866769230769">
J. Blitzer, M. Dredze, and F. Pereira. 2007. Biographies,
Bollywood, Boom-boxes and Blenders: Domain ad-
aptation for sentiment classification. In Proceedings
of ACL.
G. Forman. 2003. An extensive empirical study of fea-
ture selection metrics for text classification. Journal
of Machine Learning Research, 3: 1533-7928.
B. Pang, L. Lee, and S. Vaithyanathan. 2002. Thumbs
up? Sentiment classification using machine learning
techniques. In Proceedings of EMNLP.
R. Vilalta and Y. Drissi. 2002. A perspective view and
survey of meta-learning. Artificial Intelligence Re-
view, 18(2): 77–95.
</reference>
<figure confidence="0.997244542857143">
Accuracy(%)
90
88
86
84
82
80
78
76
74
89
85
82
88
84.5
83
86
83.5
79
82
84.5
84
Single domain classification
Feature-level fusion
Classifier-level fusion with ML
88
86
Accuracy(%)
84
82
80
78
76
74
72
</figure>
<page confidence="0.950002">
260
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.296521">
<title confidence="0.99995">Multi-domain Sentiment Classification</title>
<author confidence="0.999128">Li Zong</author>
<affiliation confidence="0.7676065">National Laboratory of Pattern Recognition Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China</affiliation>
<email confidence="0.972203">sshanli@nlpr.ia.ac.cn</email>
<email confidence="0.972203">cqzong@nlpr.ia.ac.cn</email>
<abstract confidence="0.969131428571428">This paper addresses a new task in sentiment classification, called multi-domain sentiment classification, that aims to improve performance through fusing training data from multiple domains. To achieve this, we propose two approaches of fusion, feature-level and classifier-level, to use training data from multiple domains simultaneously. Experimental studies show that multi-domain sentiment classification using the classifier-level approach performs much better than single domain classification (using the training data individually).</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<booktitle>Proceedings of ACL-08: HLT, Short Papers (Companion Volume),</booktitle>
<pages>257--260</pages>
<marker></marker>
<rawString>Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pages 257–260,</rawString>
</citation>
<citation valid="true">
<authors>
<author>Columbus</author>
</authors>
<date>2008</date>
<booktitle>c�2008 Association for Computational Linguistics</booktitle>
<location>Ohio, USA,</location>
<marker>Columbus, 2008</marker>
<rawString>Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Blitzer</author>
<author>M Dredze</author>
<author>F Pereira</author>
</authors>
<title>Biographies, Bollywood, Boom-boxes and Blenders: Domain adaptation for sentiment classification.</title>
<date>2007</date>
<booktitle>In Proceedings of ACL.</booktitle>
<marker>Blitzer, Dredze, Pereira, 2007</marker>
<rawString>J. Blitzer, M. Dredze, and F. Pereira. 2007. Biographies, Bollywood, Boom-boxes and Blenders: Domain adaptation for sentiment classification. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Forman</author>
</authors>
<title>An extensive empirical study of feature selection metrics for text classification.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research,</journal>
<volume>3</volume>
<pages>1533--7928</pages>
<marker>Forman, 2003</marker>
<rawString>G. Forman. 2003. An extensive empirical study of feature selection metrics for text classification. Journal of Machine Learning Research, 3: 1533-7928.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Pang</author>
<author>L Lee</author>
<author>S Vaithyanathan</author>
</authors>
<title>Thumbs up? Sentiment classification using machine learning techniques.</title>
<date>2002</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="1010" citStr="Pang et al., 2002" startWordPosition="134" endWordPosition="137">data from multiple domains. To achieve this, we propose two approaches of fusion, feature-level and classifier-level, to use training data from multiple domains simultaneously. Experimental studies show that multi-domain sentiment classification using the classifier-level approach performs much better than single domain classification (using the training data individually). 1 Introduction Sentiment classification is a special task of text categorization that aims to classify documents according to their opinion of, or sentiment toward a given subject (e.g., if an opinion is supported or not) (Pang et al., 2002). This task has created a considerable interest due to its wide applications. Sentiment classification is a very domainspecific problem; training a classifier using the data from one domain may fail when testing against data from another. As a result, real application systems usually require some labeled data from multiple domains, guaranteeing an acceptable performance for different domains. However, each domain has a very limited amount of training data due to the fact that creating largescale high-quality labeled corpora is difficult and time-consuming. Given the limited multi-domain traini</context>
<context position="2450" citStr="Pang et al. (2002)" startWordPosition="352" endWordPosition="355"> two approaches to multi-domain sentiment classification. In the first, called feature-level fusion, we combine the feature sets from all the domains into one feature set. Using the unified feature set, we train a classifier using all the training data regardless of domain. In the second approach, classifier-level fusion, we train a base classifier using the training data from each domain and then apply combination methods to combine the base classifiers. 2 Related Work Sentiment classification has become a hot topic since the publication work that discusses classification of movie reviews by Pang et al. (2002). This was followed by a great many studies into sentiment classification focusing on many domains besides that of movie. Research into sentiment classification over multiple domains remains sparse. It is worth noting that Blitzer et al. (2007) deal with the domain adaptation problem for sentiment classification where labeled data from one domain is used to train a classifier for classifying data from a different domain. Our work focuses on the problem of how to make multiple domains ‘help each other’ when all contain some labeled samples. These two problems are both important for real applica</context>
</contexts>
<marker>Pang, Lee, Vaithyanathan, 2002</marker>
<rawString>B. Pang, L. Lee, and S. Vaithyanathan. 2002. Thumbs up? Sentiment classification using machine learning techniques. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Vilalta</author>
<author>Y Drissi</author>
</authors>
<title>A perspective view and survey of meta-learning.</title>
<date>2002</date>
<journal>Artificial Intelligence Review,</journal>
<volume>18</volume>
<issue>2</issue>
<pages>77--95</pages>
<marker>Vilalta, Drissi, 2002</marker>
<rawString>R. Vilalta and Y. Drissi. 2002. A perspective view and survey of meta-learning. Artificial Intelligence Review, 18(2): 77–95.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>