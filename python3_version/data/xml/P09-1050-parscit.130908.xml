<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000511">
<title confidence="0.988764">
Automatic Set Instance Extraction using the Web
</title>
<author confidence="0.997183">
Richard C. Wang
</author>
<affiliation confidence="0.9826775">
Language Technologies Institute
Carnegie Mellon University
</affiliation>
<email confidence="0.98918">
rcwang@cs.cmu.edu
</email>
<author confidence="0.929447">
William W. Cohen
</author>
<affiliation confidence="0.9549975">
Machine Learning Department
Carnegie Mellon University
</affiliation>
<email confidence="0.991868">
wcohen@cs.cmu.edu
</email>
<sectionHeader confidence="0.997314" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999945538461539">
An important and well-studied problem is
the production of semantic lexicons from
a large corpus. In this paper, we present
a system named ASIA (Automatic Set In-
stance Acquirer), which takes in the name
of a semantic class as input (e.g., “car
makers”) and automatically outputs its in-
stances (e.g., “ford”, “nissan”, “toyota”).
ASIA is based on recent advances in web-
based set expansion - the problem of find-
ing all instances of a set given a small
number of “seed” instances. This ap-
proach effectively exploits web resources
and can be easily adapted to different
languages. In brief, we use language-
dependent hyponym patterns to find a
noisy set of initial seeds, and then use a
state-of-the-art language-independent set
expansion system to expand these seeds.
The proposed approach matches or outper-
forms prior systems on several English-
language benchmarks. It also shows ex-
cellent performance on three dozen addi-
tional benchmark problems from English,
Chinese and Japanese, thus demonstrating
language-independence.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99738925">
An important and well-studied problem is the pro-
duction of semantic lexicons for classes of in-
terest; that is, the generation of all instances of
a set (e.g., “apple”, “orange”, “banana”) given
a name of that set (e.g., “fruits”). This task is
often addressed by linguistically analyzing very
large collections of text (Hearst, 1992; Kozareva
et al., 2008; Etzioni et al., 2005; Pantel and
Ravichandran, 2004; Pasca, 2004), often using
hand-constructed or machine-learned shallow lin-
guistic patterns to detect hyponym instances. A hy-
ponym is a word or phrase whose semantic range
</bodyText>
<figureCaption confidence="0.739226">
Figure 1: Examples of SEAL’s input and output.
</figureCaption>
<bodyText confidence="0.977347551724138">
English entities are reality TV shows, Chinese en-
tities are popular Taiwanese foods, and Japanese
entities are famous cartoon characters.
is included within that of another word. For exam-
ple, x is a hyponym of y if x is a (kind of) y. The
opposite of hyponym is hypernym.
In this paper, we evaluate a novel approach to
this problem, embodied in a system called ASIA1
(Automatic Set Instance Acquirer). ASIA takes a
semantic class name as input (e.g., “car makers”)
and automatically outputs instances (e.g., “ford”,
“nissan”, “toyota”). Unlike prior methods, ASIA
makes heavy use of tools for web-based set ex-
pansion. Set expansion is the task of finding all
instances of a set given a small number of exam-
ple (seed) instances. ASIA uses SEAL (Wang and
Cohen, 2007), a language-independent web-based
system that performed extremely well on a large
number of benchmark sets – given three correct
seeds, SEAL obtained average MAP scores in the
high 90’s for 36 benchmark problems, including a
dozen test problems each for English, Chinese and
Japanese. SEAL works well in part because it can
efficiently find and process many semi-structured
web documents containing instances of the set be-
ing expanded. Figure 1 shows some examples of
SEAL’s input and output.
SEAL has been recently extended to be robust
to errors in its initial set of seeds (Wang et al.,
</bodyText>
<footnote confidence="0.980274">
1http://rcwang.com/asia
</footnote>
<page confidence="0.936795">
441
</page>
<note confidence="0.999618">
Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 441–449,
Suntec, Singapore, 2-7 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.99991237254902">
2008), and to use bootstrapping to iteratively im-
prove its performance (Wang and Cohen, 2008).
These extensions allow ASIA to extract instances
of sets from the Web, as follows. First, given a
semantic class name (e.g., “fruits”), ASIA uses a
small set of language-dependent hyponym patterns
(e.g., “fruits such as ”) to find a large but noisy
set of seed instances. Second, ASIA uses the ex-
tended version of SEAL to expand the noisy set of
seeds.
ASIA’s approach is motivated by the conjecture
that for many natural classes, the amount of infor-
mation available in semi-structured documents on
the Web is much larger than the amount of infor-
mation available in free-text documents; hence, it
is natural to attempt to augment search for set in-
stances in free-text with semi-structured document
analysis. We show that ASIA performs extremely
well experimentally. On the 36 benchmarks used
in (Wang and Cohen, 2007), which are relatively
small closed sets (e.g., countries, constellations,
NBA teams), ASIA has excellent performance
for both recall and precision. On four additional
English-language benchmark problems (US states,
countries, singers, and common fish), we com-
pare to recent work by Kozareva, Riloff, and Hovy
(Kozareva et al., 2008), and show comparable or
better performance on each of these benchmarks;
this is notable because ASIA requires less infor-
mation than the work of Kozareva et al (their sys-
tem requires a concept name and a seed). We also
compare ASIA on twelve additional benchmarks
to the extended Wordnet 2.1 produced by Snow
et al (Snow et al., 2006), and show that for these
twelve sets, ASIA produces more than five times
as many set instances with much higher precision
(98% versus 70%).
Another advantage of ASIA’s approach is that it
is nearly language-independent: since the underly-
ing set-expansion tools are language-independent,
all that is needed to support a new target language
is a new set of hyponym patterns for that lan-
guage. In this paper, we present experimental re-
sults for Chinese and Japanese, as well as English,
to demonstrate this language-independence.
We present related work in Section 2, and ex-
plain our proposed approach for ASIA in Sec-
tion 3. Section 4 presents the details of our ex-
periments, as well as the experimental results. A
comparison of results are illustrated in Section 5,
and the paper concludes in Section 6.
</bodyText>
<sectionHeader confidence="0.999785" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999977591836735">
There has been a significant amount of research
done in the area of semantic class learning (aka
lexical acquisition, lexicon induction, hyponym
extraction, or open-domain information extrac-
tion). However, to the best of our knowledge, there
is not a system that can perform set instance ex-
traction in multiple languages given only the name
of the set.
Hearst (Hearst, 1992) presented an approach
that utilizes hyponym patterns for extracting can-
didate instances given the name of a semantic set.
The approach presented in Section 3.1 is based on
this work, except that we extended it to two other
languages: Chinese and Japanese.
Pantel et al (Pantel and Ravichandran, 2004)
presented an algorithm for automatically inducing
names for semantic classes and for finding their
instances by using “concept signatures” (statistics
on co-occuring instances). Pasca (Pasca, 2004)
presented a method for acquiring named entities in
arbitrary categories using lexico-syntactic extrac-
tion patterns. Etzioni et al (Etzioni et al., 2005)
presented the KnowItAll system that also utilizes
hyponym patterns to extract class instances from
the Web. All the systems mentioned rely on either
a English part-of-speech tagger, a parser, or both,
and hence are language-dependent.
Kozareva et al (Kozareva et al., 2008) illustrated
an approach that uses a single hyponym pattern
combined with graph structures to learn semantic
class from the Web. Section 5.1 shows that our
approach is competitive experimentally; however,
their system requires more information, as it uses
the name of the semantic set and a seed instance.
Pasca (Pas¸ca, 2007b; Pas¸ca, 2007a) illustrated
a set expansion approach that extracts instances
from Web search queries given a set of input seed
instances. This approach is similar in flavor to
SEAL but, addresses a different task from that ad-
dressed here: for ASIA the user provides no seeds,
but instead provides the name of the set being ex-
panded. We compare to Pasca’s system in Sec-
tion 5.2.
Snow et al (Snow et al., 2006) use known hyper-
nym/hyponym pairs to generate training data for a
machine-learning system, which then learns many
lexico-syntactic patterns. The patterns learned are
based on English-language dependency parsing.
We compare to Snow et al’s results in Section 5.3.
</bodyText>
<page confidence="0.999044">
442
</page>
<sectionHeader confidence="0.989288" genericHeader="method">
3 Proposed Approach
</sectionHeader>
<bodyText confidence="0.9999635">
ASIA is composed of three main components: the
Noisy Instance Provider, the Noisy Instance Ex-
pander, and the Bootstrapper. Given a semantic
class name, the Provider extracts a initial set of
noisy candidate instances using hand-coded pat-
terns, and ranks the instances by using a sim-
ple ranking model. The Expander expands and
ranks the instances using evidence from semi-
structured web documents, such that irrelevant
ones are ranked lower in the list. The Bootstrap-
per enhances the quality and completeness of the
ranked list by using an unsupervised iterative tech-
nique. Note that the Expander and Bootstrap-
per rely on SEAL to accomplish their goals. In
this section, we first describe the Noisy Instance
Provider, then we briefly introduce SEAL, fol-
lowed by the Noisy Instance Expander, and finally,
the Bootstrapper.
</bodyText>
<subsectionHeader confidence="0.995188">
3.1 Noisy Instance Provider
</subsectionHeader>
<bodyText confidence="0.998978972972973">
Noisy Instance Provider extracts candidate in-
stances from free text (i.e., web snippets) us-
ing the methods presented in Hearst’s early work
(Hearst, 1992). Hearst exploited several patterns
for identifying hyponymy relation (e.g., such au-
thor as Shakespeare) that many current state-of-
the-art systems (Kozareva et al., 2008; Pantel and
Ravichandran, 2004; Etzioni et al., 2005; Pasca,
2004) are using. However, unlike all of those sys-
tems, ASIA does not use any NLP tool (e.g., parts-
of-speech tagger, parser) or rely on capitalization
for extracting candidates (since we wanted ASIA
to be as language-independent as possible). This
leads to sets of instances that are noisy; however,
we will show that set expansion and re-ranking can
improve the initial sets dramatically. Below, we
will refer to the initial set of noisy instances ex-
tracted by the Provider as the initial set.
In more detail, the Provider first constructs a
few queries of hyponym phrase by using a se-
mantic class name and a set of pre-defined hy-
ponym patterns. For every query, the Provider re-
trieves a hundred snippets from Yahoo!, and splits
each snippet into multiple excerpts (a snippet of-
ten contains multiple continuous excerpts from its
web page). For each excerpt, the Provider extracts
all chunks of characters that would then be used
as candidate instances. Here, we define a chunk
as a sequence of characters bounded by punctua-
tion marks or the beginning and end of an excerpt.
Figure 2: Hyponym patterns in English, Chinese,
and Japanese. In each pattern, &lt;C&gt; is a place-
holder for the semantic class name and &lt;I&gt; is a
placeholder for its instances.
Lastly, the Provider ranks each candidate instance
x based on its weight assigned by the simple rank-
ing model presented below:
</bodyText>
<equation confidence="0.9966245">
weight(x) = sf (x, S) X ef (x, E) X wcf (x, E)
|S ||E ||S|
</equation>
<bodyText confidence="0.999615428571429">
where S is the set of snippets, E is the set of ex-
cerpts, and C is the set of chunks. sf (x, S) is
the snippet frequency of x (i.e., the number of
snippets containing x) and ef (x, E) is the excerpt
frequency of x. Furthermore, wcf (x, E) is the
weighted chunk frequency of x, which is defined
as follows:
</bodyText>
<equation confidence="0.925750333333333">
11
wcf (x, E) =
eEE
</equation>
<bodyText confidence="0.999975238095238">
where dist(x, e) is the number of characters be-
tween x and the hyponym phrase in excerpt e.
This model weights every occurrence of x based
on the assumption that chunks closer to a hyponym
phrase are usually more important than those fur-
ther away. It also heavily rewards frequency, as
our assumption is that the most common instances
will be more useful as seeds for SEAL.
Figure 2 shows the hyponym patterns we use
for English, Chinese, and Japanese. There are two
types of hyponym patterns: The first type are the
ones that require the class name C to precede its
instance I (e.g., C such as I), and the second type
are the opposite ones (e.g., I and other C). In
order to reduce irrelevant chunks, when excerpts
were extracted, the Provider drops all characters
preceding the hyponym phrase in excerpts that
contain the first type, and also drops all charac-
ters following the hyponym phrase in excerpts that
contain the second type. For some semantic class
names (e.g., “cmu buildings”), there are no web
</bodyText>
<figure confidence="0.531782">
1
dist(x,e) + 1
11
xEe
</figure>
<page confidence="0.993803">
443
</page>
<bodyText confidence="0.999958166666667">
documents containing any of the hyponym-phrase
queries that were constructed using the name. In
this case, the Provider turns to a back-off strategy
which simply treats the semantic class name as the
hyponym phrase and extracts/ranks all chunks co-
occurring with the class name in the excerpts.
</bodyText>
<subsectionHeader confidence="0.999913">
3.2 Set Expander - SEAL
</subsectionHeader>
<bodyText confidence="0.97371738">
In this paper, we rely on a set expansion system
named SEAL (Wang and Cohen, 2007), which
stands for Set Expander for Any Language. The
system accepts as input a few seeds of some target
set 5 (e.g., “fruits”) and automatically finds other
probable instances (e.g., “apple”, “banana”) of 5
in web documents. As its name implies, SEAL
is independent of document languages: both the
written (e.g., English) and the markup language
(e.g., HTML). SEAL is a research system that
has shown good performance in published results
(Wang and Cohen, 2007; Wang et al., 2008; Wang
and Cohen, 2008). Figure 1 shows some examples
of SEAL’s input and output.
In more detail, SEAL contains three major com-
ponents: the Fetcher, Extractor, and Ranker. The
Fetcher is responsible for fetching web docu-
ments, and the URLs of the documents come from
top results retrieved from the search engine us-
ing the concatenation of all seeds as the query.
This ensures that every fetched web page contains
all seeds. The Extractor automatically constructs
“wrappers” (i.e. page-specific extraction rules) for
each page that contains the seeds. Every wrap-
per comprises two character strings that specify
the left and right contexts necessary for extract-
ing candidate instances. These contextual strings
are maximally-long contexts that bracket at least
one occurrence of every seed string on a page. All
other candidate instances bracketed by these con-
textual strings derived from a particular page are
extracted from the same page.
After the candidates are extracted, the Ranker
constructs a graph that models all the relations
between documents, wrappers, and candidate in-
stances. Figure 3 shows an example graph where
each node di represents a document, wi a wrapper,
and mi a candidate instance. The Ranker performs
Random Walk with Restart (Tong et al., 2006) on
this graph (where the initial “restart” set is the
set of seeds) until all node weights converge, and
then ranks nodes by their final score; thus nodes
are weighted higher if they are connected to many
Figure 3: An example graph constructed by
SEAL. Every edge from node x to y actually has
an inverse relation edge from node y to x that is
not shown here (e.g., mi is extracted by wi).
seed nodes by many short, low fan-out paths. The
final expanded set contains all candidate instance
nodes, ranked by their weights in the graph.
</bodyText>
<subsectionHeader confidence="0.988083">
3.3 Noisy Instance Expander
</subsectionHeader>
<bodyText confidence="0.999820137931034">
Wang (Wang et al., 2008) illustrated that it is feasi-
ble to perform set expansion on noisy input seeds.
The paper showed that the noisy output of any
Question Answering system for list questions can
be improved by using a noise-resistant version of
SEAL (An example of a list question is “Who
were the husbands of Heddy Lamar?”). Since the
initial set of candidate instances obtained using
Hearst’s method are noisy, the Expander expands
them by performing multiple iterations of set ex-
pansion using the noise-resistant SEAL.
For every iteration, the Expander performs set
expansion on a static collection of web pages. This
collection is pre-fetched by querying Google and
Yahoo! using the input class name and words such
as “list”, “names”, “famous”, and “common” for
discovering web pages that might contain lists of
the input class. In the first iteration, the Expander
expands instances with scores of at least k in the
initial set. In every upcoming iteration, it expands
instances obtained in the last iteration that have
scores of at least k and that also exist in the ini-
tial set. We have determined k to be 0.4 based on
our development set2. This process repeats until
the set of seeds for ith iteration is identical to that
of (i − 1)th iteration.
There are several differences between the origi-
nal SEAL and the noise-resistant SEAL. The most
important difference is the Extractor. In the origi-
</bodyText>
<footnote confidence="0.4558135">
2A collection of closed-set lists such as planets, Nobel
prizes, and continents in English, Chinese and Japanese
</footnote>
<page confidence="0.9972">
444
</page>
<bodyText confidence="0.99994425">
nal SEAL, the Extractor requires the longest com-
mon contexts to bracket at least one instance of ev-
ery seed per web page. However, when seeds are
noisy, such common contexts usually do not ex-
ist. The Extractor in noise-resistant SEAL solves
this problem by requiring the contexts to bracket
at least one instance of a minimum of two seeds,
rather than every seed. This is implemented using
a trie-based method described briefly in the origi-
nal SEAL paper (Wang and Cohen, 2007). In this
paper, the Expander utilizes a slightly-modified
version of the Extractor, which requires the con-
texts to bracket as many seed instances as possible.
This idea is based on the assumption that irrelevant
instances usually do not have common contexts;
whereas relevant ones do.
</bodyText>
<subsectionHeader confidence="0.869377">
3.4 Bootstrapper
</subsectionHeader>
<bodyText confidence="0.999950096774193">
Bootstrapping (Etzioni et al., 2005; Kozareva,
2006; Nadeau et al., 2006) is an unsupervised iter-
ative process in which a system continuously con-
sumes its own outputs to improve its own perfor-
mance. Wang (Wang and Cohen, 2008) showed
that it is feasible to bootstrap the results of set ex-
pansion to improve the quality of a list. The pa-
per introduces an iterative version of SEAL called
iSEAL, which expands a list in multiple iterations.
In each iteration, iSEAL expands a few candi-
dates extracted in previous iterations and aggre-
gates statistics. The Bootstrapper utilizes iSEAL
to further improve the quality of the list returned
by the Expander.
In every iteration, the Bootstrapper retrieves 25
web pages by using the concatenation of three
seeds as query to each of Google and Yahoo!.
In the first iteration, the Bootstrapper expands
randomly-selected instances returned by the Ex-
pander that exist in the initial set. In every upcom-
ing iteration, the Bootstrapper expands randomly-
selected unsupervised instances obtained in the
last iteration that also exist in the initial set. This
process terminates when all possible seed com-
binations have been consumed or five iterations3
have been reached, whichever comes first. No-
tice that from iteration to iteration, statistics are
aggregated by growing the graph described in Sec-
tion 3.2. We perform Random Walk with Restart
(Tong et al., 2006) on this graph to determine the
final ranking of the extracted instances.
</bodyText>
<footnote confidence="0.755344">
3To keep the overall runtime minimal.
</footnote>
<sectionHeader confidence="0.997874" genericHeader="method">
4 Experiments
</sectionHeader>
<subsectionHeader confidence="0.945973">
4.1 Datasets
</subsectionHeader>
<bodyText confidence="0.999949666666667">
We evaluated our approach using the evaluation
set presented in (Wang and Cohen, 2007), which
contains 36 manually constructed lists across
three different languages: English, Chinese, and
Japanese (12 lists per language). Each list contains
all instances of a particular semantic class in a cer-
tain language, and each instance contains a set of
synonyms (e.g., USA, America). There are a total
of 2515 instances, with an average of 70 instances
per semantic class. Figure 4 shows the datasets
and their corresponding semantic class names that
we use in our experiments.
</bodyText>
<subsectionHeader confidence="0.977895">
4.2 Evaluation Metric
</subsectionHeader>
<bodyText confidence="0.999972272727273">
Since the output of ASIA is a ranked list of ex-
tracted instances, we choose mean average pre-
cision (MAP) as our evaluation metric. MAP is
commonly used in the field of Information Re-
trieval for evaluating ranked lists because it is sen-
sitive to the entire ranking and it contains both re-
call and precision-oriented aspects. The MAP for
multiple ranked lists is simply the mean value of
average precisions calculated separately for each
ranked list. We define the average precision of a
single ranked list as:
</bodyText>
<equation confidence="0.962244">
Prec(r) x isFresh(r)
</equation>
<bodyText confidence="0.9560336">
Total # of Correct Instances
where L is a ranked list of extracted instances, r
is the rank ranging from 1 to |L|, Prec(r) is the
precision at rank r. isFresh(r) is a binary function
for ensuring that, if a list contains multiple syn-
onyms of the same instance, we do not evaluate
that instance more than once. More specifically,
the function returns 1 if a) the synonym at r is cor-
rect, and b) it is the highest-ranked synonym of its
instance in the list; it returns 0 otherwise.
</bodyText>
<subsectionHeader confidence="0.998459">
4.3 Experimental Results
</subsectionHeader>
<bodyText confidence="0.999909625">
For each semantic class in our dataset, the
Provider first produces a noisy list of candidate in-
stances, using its corresponding class name shown
in Figure 4. This list is then expanded by the Ex-
pander and further improved by the Bootstrapper.
We present our experimental results in Table 1.
As illustrated, although the Provider performs
badly, the Expander substantially improves the
</bodyText>
<equation confidence="0.884695">
AvgPrec(L) =
|L|
L
r=1
</equation>
<page confidence="0.993481">
445
</page>
<figureCaption confidence="0.999404">
Figure 4: The 36 datasets and their semantic class names used as inputs to ASIA in our experiments.
</figureCaption>
<table confidence="0.999661125">
English Dataset NP NP Chinese Dataset NP NP Japanese Dataset NP NP
NP +NE +NE NP +NE +NE NP +NE +NE
# NP +BS +BS # NP +BS +BS # NP +BS +BS
1. 0.22 0.83 0.82 0.87 13. 0.09 0.75 0.80 0.80 25. 0.20 0.63 0.71 0.76
2. 0.31 1.00 1.00 1.00 14. 0.08 0.99 0.80 0.89 26. 0.20 0.40 0.90 0.96
3. 0.54 0.99 0.99 0.98 15. 0.29 0.66 0.84 0.91 27. 0.16 0.96 0.97 0.96
4. 0.48 1.00 1.00 1.00 *16. 0.09 0.00 0.93 0.93 *28. 0.01 0.00 0.80 0.87
5. 0.54 1.00 1.00 1.00 17. 0.21 0.00 1.00 1.00 29. 0.09 0.00 0.95 0.95
6. 0.64 0.98 1.00 1.00 *18. 0.00 0.00 0.19 0.23 *30. 0.02 0.00 0.73 0.73
7. 0.32 0.82 0.98 0.97 19. 0.11 0.90 0.68 0.89 31. 0.20 0.49 0.83 0.89
8. 0.41 1.00 1.00 1.00 20. 0.18 0.00 0.94 0.97 32. 0.09 0.00 0.88 0.88
9. 0.81 1.00 1.00 1.00 21. 0.64 1.00 1.00 1.00 33. 0.07 0.00 0.95 1.00
*10. 0.00 0.00 0.00 0.00 22. 0.08 0.00 0.67 0.80 34. 0.04 0.32 0.98 0.97
11. 0.11 0.62 0.51 0.76 23. 0.47 1.00 1.00 1.00 35. 0.15 1.00 1.00 1.00
12. 0.01 0.00 0.30 0.30 24. 0.60 1.00 1.00 1.00 36. 0.20 0.90 1.00 1.00
Avg. 0.37 0.77 0.80 0.82 Avg. 0.24 0.52 0.82 0.87 Avg. 0.12 0.39 0.89 0.91
</table>
<tableCaption confidence="0.835826">
Table 1: Performance of set instance extraction for each dataset measured in MAP. NP is the Noisy
Instance Provider, NE is the Noisy Instance Expander, and BS is the Bootstrapper.
</tableCaption>
<bodyText confidence="0.999753285714286">
quality of the initial list, and the Bootstrapper then
enhances it further more. On average, the Ex-
pander improves the performance of the Provider
from 37% to 80% for English, 24% to 82% for
Chinese, and 12% to 89% for Japanese. The Boot-
strapper then further improves the performance of
the Expander to 82%, 87% and 91% respectively.
In addition, the results illustrate that the Bootstrap-
per is also effective even without the Expander; it
directly improves the performance of the Provider
from 37% to 77% for English, 24% to 52% for
Chinese, and 12% to 39% for Japanese.
The simple back-off strategy seems to be effec-
tive as well. There are five datasets (marked with *
in Table 1) of which their hyponym phrases return
zero web documents. For those datasets, ASIA au-
tomatically uses the back-off strategy described in
Section 3.1. Considering only those five datasets,
the Expander, on average, improves the perfor-
mance of the Provider from 2% to 53% and the
Bootstrapper then improves it to 55%.
</bodyText>
<sectionHeader confidence="0.910821" genericHeader="method">
5 Comparison to Prior Work
</sectionHeader>
<bodyText confidence="0.9999464">
We compare ASIA’s performance to the results
of three previously published work. We use the
best-configured ASIA (NP+NE+BS) for all com-
parisons, and we present the comparison results in
this section.
</bodyText>
<subsectionHeader confidence="0.994224">
5.1 (Kozareva et al., 2008)
</subsectionHeader>
<bodyText confidence="0.999896692307692">
Table 2 shows a comparison of our extraction per-
formance to that of Kozareva (Kozareva et al.,
2008). They report results on four tasks: US
states, countries, singers, and common fish. We
evaluated our results manually. The results in-
dicate that ASIA outperforms theirs for all four
datasets that they reported. Note that the input
to their system is a semantic class name plus one
seed instance; whereas, the input to ASIA is only
the class name. In terms of system runtime, for
each semantic class, Kozareva et al reported that
their extraction process usually finished overnight;
however, ASIA usually finished within a minute.
</bodyText>
<page confidence="0.997307">
446
</page>
<table confidence="0.999607846153846">
N Kozareva ASIA
US States
25 1.00 1.00
50 1.00 1.00
64 0.78 0.78
Singers
10 1.00 1.00
25 1.00 1.00
50 0.97 1.00
75 0.96 1.00
100 0.96 1.00
150 0.95 0.97
180 0.91 0.96
</table>
<tableCaption confidence="0.92090575">
Table 2: Set instance extraction performance com-
pared to Kozareva et al. We report our precision
for all semantic classes and at the same ranks re-
ported in their work.
</tableCaption>
<subsectionHeader confidence="0.991298">
5.2 (Pas¸ca, 2007b)
</subsectionHeader>
<bodyText confidence="0.999966636363636">
We compare ASIA to Pasca (Pas¸ca, 2007b) and
present comparison results in Table 3. There are
ten semantic classes in his evaluation dataset, and
the input to his system for each class is a set of
seed entities rather than a class name. We evaluate
every instance manually for each class. The results
show that, on average, ASIA performs better.
However, we should emphasize that for the
three classes: movie, person, and video game,
ASIA did not initially converge to the correct in-
stance list given the most natural concept name.
Given “movies”, ASIA returns as instances strings
like “comedy”, “action”, “drama”, and other kinds
of movies. Given “video games”, it returns “PSP”,
“Xbox”, “Wii”, etc. Given “people”, it returns
“musicians”, “artists”, “politicians”, etc. We ad-
dressed this problem by simply re-running ASIA
with a more specific class name (i.e., the first one
returned); however, the result suggests that future
work is needed to support automatic construction
of hypernym hierarchy using semi-structured web
documents.
</bodyText>
<subsectionHeader confidence="0.990639">
5.3 (Snow et al., 2006)
</subsectionHeader>
<bodyText confidence="0.999578714285714">
Snow (Snow et al., 2006) has extended the Word-
Net 2.1 by adding thousands of entries (synsets)
at a relatively high precision. They have made
several versions of extended WordNet available4.
For comparison purposes, we selected the version
(+30K) that achieved the best F-score in their ex-
periments.
</bodyText>
<footnote confidence="0.966719">
4http://ai.stanford.edu/˜rion/swn/
</footnote>
<table confidence="0.999977416666667">
Precision @
Target Class System 25 50 100 150 250
Cities Pasca 1.00 0.96 0.88 0.84 0.75
ASIA 1.00 1.00 0.97 0.98 0.96
Countries Pasca 1.00 0.98 0.95 0.82 0.60
ASIA 1.00 1.00 1.00 1.00 0.79
Drugs Pasca 1.00 1.00 0.96 0.92 0.75
ASIA 1.00 1.00 1.00 1.00 0.98
Food Pasca 0.88 0.86 0.82 0.78 0.62
ASIA 1.00 1.00 0.93 0.95 0.90
Locations Pasca 1.00 1.00 1.00 1.00 1.00
ASIA 1.00 1.00 1.00 1.00 1.00
Newspapers Pasca 0.96 0.98 0.93 0.86 0.54
ASIA 1.00 1.00 0.98 0.99 0.85
Universities Pasca 1.00 1.00 1.00 1.00 0.99
ASIA 1.00 1.00 1.00 1.00 1.00
Movies Pasca 0.92 0.90 0.88 0.84 0.79
Comedy Movies ASIA 1.00 1.00 1.00 1.00 1.00
People Pasca 1.00 1.00 1.00 1.00 1.00
Jazz Musicians ASIA 1.00 1.00 1.00 0.94 0.88
Video Games Pasca 1.00 1.00 0.99 0.98 0.98
PSP Games ASIA 1.00 1.00 1.00 0.99 0.97
Pasca 0.98 0.97 0.94 0.90 0.80
Average ASIA 1.00 1.00 0.99 0.98 0.93
</table>
<tableCaption confidence="0.999689">
Table 3: Set instance extraction performance com-
</tableCaption>
<bodyText confidence="0.9879534375">
pared to Pasca. We report our precision for all se-
mantic classes and at the same ranks reported in
his work.
For the experimental comparison, we focused
on leaf semantic classes from the extended Word-
Net that have many hypernyms, so that a mean-
ingful comparison could be made: specifically, we
selected nouns that have at least three hypernyms,
such that the hypernyms are the leaf nodes in the
hypernym hierarchy of WordNet. Of these, 210
were extended by Snow. Preliminary experiments
showed that (as in the experiments with Pasca’s
classes above) ASIA did not always converge to
the intended meaning; to avoid this problem, we
instituted a second filter, and discarded ASIA’s re-
sults if the intersection of hypernyms from ASIA
and WordNet constituted less than 50% of those
in WordNet. About 50 of the 210 nouns passed
this filter. Finally, we manually evaluated preci-
sion and recall of a randomly selected set of twelve
of these 50 nouns.
We present the results in Table 4. We used a
fixed cut-off score5 of 0.3 to truncate the ranked
list produced by ASIA, so that we can compute
precision. Since only a few of these twelve nouns
are closed sets, we cannot generally compute re-
call; instead, we define relative recall to be the
ratio of correct instances to the union of correct
instances from both systems. As shown in the re-
sults, ASIA has much higher precision, and much
higher relative recall. When we evaluated Snow’s
extended WordNet, we assumed all instances that
</bodyText>
<figure confidence="0.553771625">
5Determined from our development set.
N Kozareva ASIA
Countries
50 1.00 1.00
100 1.00 1.00
150 1.00 1.00
200 0.90 0.93
300 0.61 0.67
323 0.57 0.62
Common Fish
10 1.00 1.00
25 1.00 1.00
50 1.00 1.00
75 0.93 1.00
100 0.84 1.00
116 0.80 1.00
</figure>
<page confidence="0.668856">
447
</page>
<table confidence="0.999892133333333">
Class Name Snow’s Wordnet (+30k) Relative # Right ASIA Prec. Relative
# Right # Wrong Prec. Recall # Wrong Recall
Film Directors 4 4 0.50 0.01 457 0 1.00 1.00
Manias 11 0 1.00 0.09 120 0 1.00 1.00
Canadian Provinces 10 82 0.11 1.00 10 3 0.77 1.00
Signs of the Zodiac 12 10 0.55 1.00 12 0 1.00 1.00
Roman Emperors 44 4 0.92 0.47 90 0 1.00 0.96
Academic Departments 20 0 1.00 0.67 27 0 1.00 0.90
Choreographers 23 10 0.70 0.14 156 0 1.00 0.94
Elected Officials 5 102 0.05 0.31 12 0 1.00 0.75
Double Stars 11 1 0.92 0.46 20 0 1.00 0.83
South American Countries 12 1 0.92 1.00 12 0 1.00 1.00
Prizefighters 16 4 0.80 0.23 63 1 0.98 0.89
Newspapers 20 0 1.00 0.23 71 0 1.00 0.81
Average 15.7 18.2 0.70 0.47 87.5 0.3 0.98 0.92
</table>
<tableCaption confidence="0.999782">
Table 4: Set instance extraction performance compared to Snow et al.
</tableCaption>
<figureCaption confidence="0.860896666666667">
Figure 5: Examples of ASIA’s input and out-
put. Input class for Chinese is “holidays” and for
Japanese is “dramas”.
</figureCaption>
<bodyText confidence="0.97991175">
were in the original WordNet are correct. The
three incorrect instances of Canadian provinces
from ASIA are actually the three Canadian terri-
tories.
</bodyText>
<sectionHeader confidence="0.999675" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999987979166667">
In this paper, we have shown that ASIA, a SEAL-
based system, extracts set instances with high pre-
cision and recall in multiple languages given only
the set name. It obtains a high MAP score (87%)
averaged over 36 benchmark problems in three
languages (Chinese, Japanese, and English). Fig-
ure 5 shows some real examples of ASIA’s in-
put and output in those three languages. ASIA’s
approach is based on web-based set expansion
using semi-structured documents, and is moti-
vated by the conjecture that for many natural
classes, the amount of information available in
semi-structured documents on the Web is much
larger than the amount of information available
in free-text documents. This conjecture is given
some support by our experiments: for instance,
ASIA finds 457 instances of the set “film direc-
tor” with perfect precision, whereas Snow et al’s
state-of-the-art methods for extraction from free
text extract only four correct instances, with only
50% precision.
ASIA’s approach is also quite language-
independent. By adding a few simple hyponym
patterns, we can easily extend the system to sup-
port other languages. We have also shown that
Hearst’s method works not only for English, but
also for other languages such as Chinese and
Japanese. We note that the ability to construct
semantic lexicons in diverse languages has obvi-
ous applications in machine translation. We have
also illustrated that ASIA outperforms three other
English systems (Kozareva et al., 2008; Pas¸ca,
2007b; Snow et al., 2006), even though many of
these use more input than just a semantic class
name. In addition, ASIA is also quite efficient,
requiring only a few minutes of computation and
couple hundreds of web pages per problem.
In the future, we plan to investigate the pos-
sibility of constructing hypernym hierarchy auto-
matically using semi-structured documents. We
also plan to explore whether lexicons can be con-
structed using only the back-off method for hy-
ponym extraction, to make ASIA completely lan-
guage independent. We also wish to explore
whether performance can be improved by simul-
taneously finding class instances in multiple lan-
guages (e.g., Chinese and English) while learning
translations between the extracted instances.
</bodyText>
<sectionHeader confidence="0.999605" genericHeader="acknowledgments">
7 Acknowledgments
</sectionHeader>
<bodyText confidence="0.972903">
This work was supported by the Google Research
Awards program.
</bodyText>
<page confidence="0.998226">
448
</page>
<sectionHeader confidence="0.998334" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999930554054054">
Oren Etzioni, Michael J. Cafarella, Doug Downey,
Ana-Maria Popescu, Tal Shaked, Stephen Soder-
land, Daniel S. Weld, and Alexander Yates. 2005.
Unsupervised named-entity extraction from the
web: An experimental study. Artif. Intell.,
165(1):91–134.
Marti A. Hearst. 1992. Automatic acquisition of hy-
ponyms from large text corpora. In In Proceedings
of the 14th International Conference on Computa-
tional Linguistics, pages 539–545.
Zornitsa Kozareva, Ellen Riloff, and Eduard Hovy.
2008. Semantic class learning from the web with
hyponym pattern linkage graphs. In Proceedings of
ACL-08: HLT, pages 1048–1056, Columbus, Ohio,
June. Association for Computational Linguistics.
Zornitsa Kozareva. 2006. Bootstrapping named entity
recognition with automatically generated gazetteer
lists. In EACL. The Association for Computer Lin-
guistics.
David Nadeau, Peter D. Turney, and Stan Matwin.
2006. Unsupervised named-entity recognition:
Generating gazetteers and resolving ambiguity. In
Luc Lamontagne and Mario Marchand, editors,
Canadian Conference on AI, volume 4013 of Lec-
ture Notes in Computer Science, pages 266–277.
Springer.
Marius Pas¸ca. 2007a. Organizing and searching the
world wide web of facts – step two: harnessing the
wisdom of the crowds. In WWW ’07: Proceedings
of the 16th international conference on World Wide
Web, pages 101–110, New York, NY, USA. ACM.
Marius Pas¸ca. 2007b. Weakly-supervised discovery
of named entities using web search queries. In
CIKM ’07: Proceedings of the sixteenth ACM con-
ference on Conference on information and knowl-
edge management, pages 683–690, New York, NY,
USA. ACM.
Patrick Pantel and Deepak Ravichandran. 2004.
Automatically labeling semantic classes. In
Daniel Marcu Susan Dumais and Salim Roukos, ed-
itors, HLT-NAACL 2004: Main Proceedings, pages
321–328, Boston, Massachusetts, USA, May 2 -
May 7. Association for Computational Linguistics.
Marius Pasca. 2004. Acquisition of categorized named
entities for web search. In CIKM ’04: Proceed-
ings of the thirteenth ACM international conference
on Information and knowledge management, pages
137–145, New York, NY, USA. ACM.
Rion Snow, Daniel Jurafsky, and Andrew Y. Ng. 2006.
Semantic taxonomy induction from heterogenous
evidence. In ACL ’06: Proceedings of the 21st Inter-
national Conference on Computational Linguistics
and the 44th annual meeting of the ACL, pages 801–
808, Morristown, NJ, USA. Association for Compu-
tational Linguistics.
Hanghang Tong, Christos Faloutsos, and Jia-Yu Pan.
2006. Fast random walk with restart and its appli-
cations. In ICDM, pages 613–622. IEEE Computer
Society.
Richard C. Wang and William W. Cohen. 2007.
Language-independent set expansion of named enti-
ties using the web. In ICDM, pages 342–350. IEEE
Computer Society.
Richard C. Wang and William W. Cohen. 2008. Iter-
ative set expansion of named entities using the web.
In ICDM, pages 1091–1096. IEEE Computer Soci-
ety.
Richard C. Wang, Nico Schlaefer, William W. Co-
hen, and Eric Nyberg. 2008. Automatic set ex-
pansion for list question answering. In Proceedings
of the 2008 Conference on Empirical Methods in
Natural Language Processing, pages 947–954, Hon-
olulu, Hawaii, October. Association for Computa-
tional Linguistics.
</reference>
<page confidence="0.99924">
449
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.756138">
<title confidence="0.999596">Automatic Set Instance Extraction using the Web</title>
<author confidence="0.99999">Richard C Wang</author>
<affiliation confidence="0.998124">Language Technologies Institute Carnegie Mellon University</affiliation>
<email confidence="0.998681">rcwang@cs.cmu.edu</email>
<author confidence="0.999877">William W Cohen</author>
<affiliation confidence="0.9112035">Machine Learning Department Carnegie Mellon University</affiliation>
<email confidence="0.999364">wcohen@cs.cmu.edu</email>
<abstract confidence="0.99640462962963">An important and well-studied problem is the production of semantic lexicons from a large corpus. In this paper, we present a system named ASIA (Automatic Set Instance Acquirer), which takes in the name of a semantic class as input (e.g., “car makers”) and automatically outputs its instances (e.g., “ford”, “nissan”, “toyota”). ASIA is based on recent advances in webexpansion the problem of finding all instances of a set given a small number of “seed” instances. This approach effectively exploits web resources and can be easily adapted to different languages. In brief, we use languagedependent hyponym patterns to find a noisy set of initial seeds, and then use a state-of-the-art language-independent set expansion system to expand these seeds. The proposed approach matches or outperforms prior systems on several Englishlanguage benchmarks. It also shows excellent performance on three dozen additional benchmark problems from English, Chinese and Japanese, thus demonstrating language-independence.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Oren Etzioni</author>
<author>Michael J Cafarella</author>
<author>Doug Downey</author>
<author>Ana-Maria Popescu</author>
<author>Tal Shaked</author>
<author>Stephen Soderland</author>
<author>Daniel S Weld</author>
<author>Alexander Yates</author>
</authors>
<title>Unsupervised named-entity extraction from the web: An experimental study.</title>
<date>2005</date>
<journal>Artif. Intell.,</journal>
<volume>165</volume>
<issue>1</issue>
<contexts>
<context position="1653" citStr="Etzioni et al., 2005" startWordPosition="249" endWordPosition="252"> or outperforms prior systems on several Englishlanguage benchmarks. It also shows excellent performance on three dozen additional benchmark problems from English, Chinese and Japanese, thus demonstrating language-independence. 1 Introduction An important and well-studied problem is the production of semantic lexicons for classes of interest; that is, the generation of all instances of a set (e.g., “apple”, “orange”, “banana”) given a name of that set (e.g., “fruits”). This task is often addressed by linguistically analyzing very large collections of text (Hearst, 1992; Kozareva et al., 2008; Etzioni et al., 2005; Pantel and Ravichandran, 2004; Pasca, 2004), often using hand-constructed or machine-learned shallow linguistic patterns to detect hyponym instances. A hyponym is a word or phrase whose semantic range Figure 1: Examples of SEAL’s input and output. English entities are reality TV shows, Chinese entities are popular Taiwanese foods, and Japanese entities are famous cartoon characters. is included within that of another word. For example, x is a hyponym of y if x is a (kind of) y. The opposite of hyponym is hypernym. In this paper, we evaluate a novel approach to this problem, embodied in a sys</context>
<context position="6865" citStr="Etzioni et al., 2005" startWordPosition="1096" endWordPosition="1099">lizes hyponym patterns for extracting candidate instances given the name of a semantic set. The approach presented in Section 3.1 is based on this work, except that we extended it to two other languages: Chinese and Japanese. Pantel et al (Pantel and Ravichandran, 2004) presented an algorithm for automatically inducing names for semantic classes and for finding their instances by using “concept signatures” (statistics on co-occuring instances). Pasca (Pasca, 2004) presented a method for acquiring named entities in arbitrary categories using lexico-syntactic extraction patterns. Etzioni et al (Etzioni et al., 2005) presented the KnowItAll system that also utilizes hyponym patterns to extract class instances from the Web. All the systems mentioned rely on either a English part-of-speech tagger, a parser, or both, and hence are language-dependent. Kozareva et al (Kozareva et al., 2008) illustrated an approach that uses a single hyponym pattern combined with graph structures to learn semantic class from the Web. Section 5.1 shows that our approach is competitive experimentally; however, their system requires more information, as it uses the name of the semantic set and a seed instance. Pasca (Pas¸ca, 2007b</context>
<context position="9385" citStr="Etzioni et al., 2005" startWordPosition="1496" endWordPosition="1499">trapper rely on SEAL to accomplish their goals. In this section, we first describe the Noisy Instance Provider, then we briefly introduce SEAL, followed by the Noisy Instance Expander, and finally, the Bootstrapper. 3.1 Noisy Instance Provider Noisy Instance Provider extracts candidate instances from free text (i.e., web snippets) using the methods presented in Hearst’s early work (Hearst, 1992). Hearst exploited several patterns for identifying hyponymy relation (e.g., such author as Shakespeare) that many current state-ofthe-art systems (Kozareva et al., 2008; Pantel and Ravichandran, 2004; Etzioni et al., 2005; Pasca, 2004) are using. However, unlike all of those systems, ASIA does not use any NLP tool (e.g., partsof-speech tagger, parser) or rely on capitalization for extracting candidates (since we wanted ASIA to be as language-independent as possible). This leads to sets of instances that are noisy; however, we will show that set expansion and re-ranking can improve the initial sets dramatically. Below, we will refer to the initial set of noisy instances extracted by the Provider as the initial set. In more detail, the Provider first constructs a few queries of hyponym phrase by using a semantic</context>
<context position="17239" citStr="Etzioni et al., 2005" startWordPosition="2842" endWordPosition="2845"> The Extractor in noise-resistant SEAL solves this problem by requiring the contexts to bracket at least one instance of a minimum of two seeds, rather than every seed. This is implemented using a trie-based method described briefly in the original SEAL paper (Wang and Cohen, 2007). In this paper, the Expander utilizes a slightly-modified version of the Extractor, which requires the contexts to bracket as many seed instances as possible. This idea is based on the assumption that irrelevant instances usually do not have common contexts; whereas relevant ones do. 3.4 Bootstrapper Bootstrapping (Etzioni et al., 2005; Kozareva, 2006; Nadeau et al., 2006) is an unsupervised iterative process in which a system continuously consumes its own outputs to improve its own performance. Wang (Wang and Cohen, 2008) showed that it is feasible to bootstrap the results of set expansion to improve the quality of a list. The paper introduces an iterative version of SEAL called iSEAL, which expands a list in multiple iterations. In each iteration, iSEAL expands a few candidates extracted in previous iterations and aggregates statistics. The Bootstrapper utilizes iSEAL to further improve the quality of the list returned by</context>
</contexts>
<marker>Etzioni, Cafarella, Downey, Popescu, Shaked, Soderland, Weld, Yates, 2005</marker>
<rawString>Oren Etzioni, Michael J. Cafarella, Doug Downey, Ana-Maria Popescu, Tal Shaked, Stephen Soderland, Daniel S. Weld, and Alexander Yates. 2005. Unsupervised named-entity extraction from the web: An experimental study. Artif. Intell., 165(1):91–134.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marti A Hearst</author>
</authors>
<title>Automatic acquisition of hyponyms from large text corpora. In</title>
<date>1992</date>
<booktitle>In Proceedings of the 14th International Conference on Computational Linguistics,</booktitle>
<pages>539--545</pages>
<contexts>
<context position="1608" citStr="Hearst, 1992" startWordPosition="243" endWordPosition="244"> seeds. The proposed approach matches or outperforms prior systems on several Englishlanguage benchmarks. It also shows excellent performance on three dozen additional benchmark problems from English, Chinese and Japanese, thus demonstrating language-independence. 1 Introduction An important and well-studied problem is the production of semantic lexicons for classes of interest; that is, the generation of all instances of a set (e.g., “apple”, “orange”, “banana”) given a name of that set (e.g., “fruits”). This task is often addressed by linguistically analyzing very large collections of text (Hearst, 1992; Kozareva et al., 2008; Etzioni et al., 2005; Pantel and Ravichandran, 2004; Pasca, 2004), often using hand-constructed or machine-learned shallow linguistic patterns to detect hyponym instances. A hyponym is a word or phrase whose semantic range Figure 1: Examples of SEAL’s input and output. English entities are reality TV shows, Chinese entities are popular Taiwanese foods, and Japanese entities are famous cartoon characters. is included within that of another word. For example, x is a hyponym of y if x is a (kind of) y. The opposite of hyponym is hypernym. In this paper, we evaluate a nove</context>
<context position="6213" citStr="Hearst, 1992" startWordPosition="1001" endWordPosition="1002">ur proposed approach for ASIA in Section 3. Section 4 presents the details of our experiments, as well as the experimental results. A comparison of results are illustrated in Section 5, and the paper concludes in Section 6. 2 Related Work There has been a significant amount of research done in the area of semantic class learning (aka lexical acquisition, lexicon induction, hyponym extraction, or open-domain information extraction). However, to the best of our knowledge, there is not a system that can perform set instance extraction in multiple languages given only the name of the set. Hearst (Hearst, 1992) presented an approach that utilizes hyponym patterns for extracting candidate instances given the name of a semantic set. The approach presented in Section 3.1 is based on this work, except that we extended it to two other languages: Chinese and Japanese. Pantel et al (Pantel and Ravichandran, 2004) presented an algorithm for automatically inducing names for semantic classes and for finding their instances by using “concept signatures” (statistics on co-occuring instances). Pasca (Pasca, 2004) presented a method for acquiring named entities in arbitrary categories using lexico-syntactic extra</context>
<context position="9163" citStr="Hearst, 1992" startWordPosition="1466" endWordPosition="1467">ments, such that irrelevant ones are ranked lower in the list. The Bootstrapper enhances the quality and completeness of the ranked list by using an unsupervised iterative technique. Note that the Expander and Bootstrapper rely on SEAL to accomplish their goals. In this section, we first describe the Noisy Instance Provider, then we briefly introduce SEAL, followed by the Noisy Instance Expander, and finally, the Bootstrapper. 3.1 Noisy Instance Provider Noisy Instance Provider extracts candidate instances from free text (i.e., web snippets) using the methods presented in Hearst’s early work (Hearst, 1992). Hearst exploited several patterns for identifying hyponymy relation (e.g., such author as Shakespeare) that many current state-ofthe-art systems (Kozareva et al., 2008; Pantel and Ravichandran, 2004; Etzioni et al., 2005; Pasca, 2004) are using. However, unlike all of those systems, ASIA does not use any NLP tool (e.g., partsof-speech tagger, parser) or rely on capitalization for extracting candidates (since we wanted ASIA to be as language-independent as possible). This leads to sets of instances that are noisy; however, we will show that set expansion and re-ranking can improve the initial</context>
</contexts>
<marker>Hearst, 1992</marker>
<rawString>Marti A. Hearst. 1992. Automatic acquisition of hyponyms from large text corpora. In In Proceedings of the 14th International Conference on Computational Linguistics, pages 539–545.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zornitsa Kozareva</author>
<author>Ellen Riloff</author>
<author>Eduard Hovy</author>
</authors>
<title>Semantic class learning from the web with hyponym pattern linkage graphs.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT,</booktitle>
<pages>1048--1056</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Columbus, Ohio,</location>
<contexts>
<context position="1631" citStr="Kozareva et al., 2008" startWordPosition="245" endWordPosition="248">oposed approach matches or outperforms prior systems on several Englishlanguage benchmarks. It also shows excellent performance on three dozen additional benchmark problems from English, Chinese and Japanese, thus demonstrating language-independence. 1 Introduction An important and well-studied problem is the production of semantic lexicons for classes of interest; that is, the generation of all instances of a set (e.g., “apple”, “orange”, “banana”) given a name of that set (e.g., “fruits”). This task is often addressed by linguistically analyzing very large collections of text (Hearst, 1992; Kozareva et al., 2008; Etzioni et al., 2005; Pantel and Ravichandran, 2004; Pasca, 2004), often using hand-constructed or machine-learned shallow linguistic patterns to detect hyponym instances. A hyponym is a word or phrase whose semantic range Figure 1: Examples of SEAL’s input and output. English entities are reality TV shows, Chinese entities are popular Taiwanese foods, and Japanese entities are famous cartoon characters. is included within that of another word. For example, x is a hyponym of y if x is a (kind of) y. The opposite of hyponym is hypernym. In this paper, we evaluate a novel approach to this prob</context>
<context position="4687" citStr="Kozareva et al., 2008" startWordPosition="743" endWordPosition="746">he amount of information available in free-text documents; hence, it is natural to attempt to augment search for set instances in free-text with semi-structured document analysis. We show that ASIA performs extremely well experimentally. On the 36 benchmarks used in (Wang and Cohen, 2007), which are relatively small closed sets (e.g., countries, constellations, NBA teams), ASIA has excellent performance for both recall and precision. On four additional English-language benchmark problems (US states, countries, singers, and common fish), we compare to recent work by Kozareva, Riloff, and Hovy (Kozareva et al., 2008), and show comparable or better performance on each of these benchmarks; this is notable because ASIA requires less information than the work of Kozareva et al (their system requires a concept name and a seed). We also compare ASIA on twelve additional benchmarks to the extended Wordnet 2.1 produced by Snow et al (Snow et al., 2006), and show that for these twelve sets, ASIA produces more than five times as many set instances with much higher precision (98% versus 70%). Another advantage of ASIA’s approach is that it is nearly language-independent: since the underlying set-expansion tools are </context>
<context position="7139" citStr="Kozareva et al., 2008" startWordPosition="1138" endWordPosition="1141">esented an algorithm for automatically inducing names for semantic classes and for finding their instances by using “concept signatures” (statistics on co-occuring instances). Pasca (Pasca, 2004) presented a method for acquiring named entities in arbitrary categories using lexico-syntactic extraction patterns. Etzioni et al (Etzioni et al., 2005) presented the KnowItAll system that also utilizes hyponym patterns to extract class instances from the Web. All the systems mentioned rely on either a English part-of-speech tagger, a parser, or both, and hence are language-dependent. Kozareva et al (Kozareva et al., 2008) illustrated an approach that uses a single hyponym pattern combined with graph structures to learn semantic class from the Web. Section 5.1 shows that our approach is competitive experimentally; however, their system requires more information, as it uses the name of the semantic set and a seed instance. Pasca (Pas¸ca, 2007b; Pas¸ca, 2007a) illustrated a set expansion approach that extracts instances from Web search queries given a set of input seed instances. This approach is similar in flavor to SEAL but, addresses a different task from that addressed here: for ASIA the user provides no seed</context>
<context position="9332" citStr="Kozareva et al., 2008" startWordPosition="1488" endWordPosition="1491"> iterative technique. Note that the Expander and Bootstrapper rely on SEAL to accomplish their goals. In this section, we first describe the Noisy Instance Provider, then we briefly introduce SEAL, followed by the Noisy Instance Expander, and finally, the Bootstrapper. 3.1 Noisy Instance Provider Noisy Instance Provider extracts candidate instances from free text (i.e., web snippets) using the methods presented in Hearst’s early work (Hearst, 1992). Hearst exploited several patterns for identifying hyponymy relation (e.g., such author as Shakespeare) that many current state-ofthe-art systems (Kozareva et al., 2008; Pantel and Ravichandran, 2004; Etzioni et al., 2005; Pasca, 2004) are using. However, unlike all of those systems, ASIA does not use any NLP tool (e.g., partsof-speech tagger, parser) or rely on capitalization for extracting candidates (since we wanted ASIA to be as language-independent as possible). This leads to sets of instances that are noisy; however, we will show that set expansion and re-ranking can improve the initial sets dramatically. Below, we will refer to the initial set of noisy instances extracted by the Provider as the initial set. In more detail, the Provider first construct</context>
<context position="23386" citStr="Kozareva et al., 2008" startWordPosition="3920" endWordPosition="3923"> There are five datasets (marked with * in Table 1) of which their hyponym phrases return zero web documents. For those datasets, ASIA automatically uses the back-off strategy described in Section 3.1. Considering only those five datasets, the Expander, on average, improves the performance of the Provider from 2% to 53% and the Bootstrapper then improves it to 55%. 5 Comparison to Prior Work We compare ASIA’s performance to the results of three previously published work. We use the best-configured ASIA (NP+NE+BS) for all comparisons, and we present the comparison results in this section. 5.1 (Kozareva et al., 2008) Table 2 shows a comparison of our extraction performance to that of Kozareva (Kozareva et al., 2008). They report results on four tasks: US states, countries, singers, and common fish. We evaluated our results manually. The results indicate that ASIA outperforms theirs for all four datasets that they reported. Note that the input to their system is a semantic class name plus one seed instance; whereas, the input to ASIA is only the class name. In terms of system runtime, for each semantic class, Kozareva et al reported that their extraction process usually finished overnight; however, ASIA us</context>
<context position="30930" citStr="Kozareva et al., 2008" startWordPosition="5221" endWordPosition="5224">s state-of-the-art methods for extraction from free text extract only four correct instances, with only 50% precision. ASIA’s approach is also quite languageindependent. By adding a few simple hyponym patterns, we can easily extend the system to support other languages. We have also shown that Hearst’s method works not only for English, but also for other languages such as Chinese and Japanese. We note that the ability to construct semantic lexicons in diverse languages has obvious applications in machine translation. We have also illustrated that ASIA outperforms three other English systems (Kozareva et al., 2008; Pas¸ca, 2007b; Snow et al., 2006), even though many of these use more input than just a semantic class name. In addition, ASIA is also quite efficient, requiring only a few minutes of computation and couple hundreds of web pages per problem. In the future, we plan to investigate the possibility of constructing hypernym hierarchy automatically using semi-structured documents. We also plan to explore whether lexicons can be constructed using only the back-off method for hyponym extraction, to make ASIA completely language independent. We also wish to explore whether performance can be improved</context>
</contexts>
<marker>Kozareva, Riloff, Hovy, 2008</marker>
<rawString>Zornitsa Kozareva, Ellen Riloff, and Eduard Hovy. 2008. Semantic class learning from the web with hyponym pattern linkage graphs. In Proceedings of ACL-08: HLT, pages 1048–1056, Columbus, Ohio, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zornitsa Kozareva</author>
</authors>
<title>Bootstrapping named entity recognition with automatically generated gazetteer lists.</title>
<date>2006</date>
<booktitle>In EACL. The Association</booktitle>
<institution>for Computer Linguistics.</institution>
<contexts>
<context position="17255" citStr="Kozareva, 2006" startWordPosition="2846" endWordPosition="2847">e-resistant SEAL solves this problem by requiring the contexts to bracket at least one instance of a minimum of two seeds, rather than every seed. This is implemented using a trie-based method described briefly in the original SEAL paper (Wang and Cohen, 2007). In this paper, the Expander utilizes a slightly-modified version of the Extractor, which requires the contexts to bracket as many seed instances as possible. This idea is based on the assumption that irrelevant instances usually do not have common contexts; whereas relevant ones do. 3.4 Bootstrapper Bootstrapping (Etzioni et al., 2005; Kozareva, 2006; Nadeau et al., 2006) is an unsupervised iterative process in which a system continuously consumes its own outputs to improve its own performance. Wang (Wang and Cohen, 2008) showed that it is feasible to bootstrap the results of set expansion to improve the quality of a list. The paper introduces an iterative version of SEAL called iSEAL, which expands a list in multiple iterations. In each iteration, iSEAL expands a few candidates extracted in previous iterations and aggregates statistics. The Bootstrapper utilizes iSEAL to further improve the quality of the list returned by the Expander. I</context>
</contexts>
<marker>Kozareva, 2006</marker>
<rawString>Zornitsa Kozareva. 2006. Bootstrapping named entity recognition with automatically generated gazetteer lists. In EACL. The Association for Computer Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Nadeau</author>
<author>Peter D Turney</author>
<author>Stan Matwin</author>
</authors>
<title>Unsupervised named-entity recognition: Generating gazetteers and resolving ambiguity.</title>
<date>2006</date>
<booktitle>In Luc Lamontagne and Mario Marchand, editors, Canadian Conference on AI, volume 4013 of Lecture Notes in Computer Science,</booktitle>
<pages>266--277</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="17277" citStr="Nadeau et al., 2006" startWordPosition="2848" endWordPosition="2851"> solves this problem by requiring the contexts to bracket at least one instance of a minimum of two seeds, rather than every seed. This is implemented using a trie-based method described briefly in the original SEAL paper (Wang and Cohen, 2007). In this paper, the Expander utilizes a slightly-modified version of the Extractor, which requires the contexts to bracket as many seed instances as possible. This idea is based on the assumption that irrelevant instances usually do not have common contexts; whereas relevant ones do. 3.4 Bootstrapper Bootstrapping (Etzioni et al., 2005; Kozareva, 2006; Nadeau et al., 2006) is an unsupervised iterative process in which a system continuously consumes its own outputs to improve its own performance. Wang (Wang and Cohen, 2008) showed that it is feasible to bootstrap the results of set expansion to improve the quality of a list. The paper introduces an iterative version of SEAL called iSEAL, which expands a list in multiple iterations. In each iteration, iSEAL expands a few candidates extracted in previous iterations and aggregates statistics. The Bootstrapper utilizes iSEAL to further improve the quality of the list returned by the Expander. In every iteration, the</context>
</contexts>
<marker>Nadeau, Turney, Matwin, 2006</marker>
<rawString>David Nadeau, Peter D. Turney, and Stan Matwin. 2006. Unsupervised named-entity recognition: Generating gazetteers and resolving ambiguity. In Luc Lamontagne and Mario Marchand, editors, Canadian Conference on AI, volume 4013 of Lecture Notes in Computer Science, pages 266–277. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marius Pas¸ca</author>
</authors>
<title>Organizing and searching the world wide web of facts – step two: harnessing the wisdom of the crowds.</title>
<date>2007</date>
<booktitle>In WWW ’07: Proceedings of the 16th international conference on World Wide Web,</booktitle>
<pages>101--110</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<marker>Pas¸ca, 2007</marker>
<rawString>Marius Pas¸ca. 2007a. Organizing and searching the world wide web of facts – step two: harnessing the wisdom of the crowds. In WWW ’07: Proceedings of the 16th international conference on World Wide Web, pages 101–110, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marius Pas¸ca</author>
</authors>
<title>Weakly-supervised discovery of named entities using web search queries.</title>
<date>2007</date>
<booktitle>In CIKM ’07: Proceedings of the sixteenth ACM conference on Conference on information and knowledge management,</booktitle>
<pages>683--690</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<marker>Pas¸ca, 2007</marker>
<rawString>Marius Pas¸ca. 2007b. Weakly-supervised discovery of named entities using web search queries. In CIKM ’07: Proceedings of the sixteenth ACM conference on Conference on information and knowledge management, pages 683–690, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Pantel</author>
<author>Deepak Ravichandran</author>
</authors>
<title>Automatically labeling semantic classes.</title>
<date>2004</date>
<booktitle>HLT-NAACL 2004: Main Proceedings,</booktitle>
<volume>2</volume>
<pages>321--328</pages>
<editor>In Daniel Marcu Susan Dumais and Salim Roukos, editors,</editor>
<location>Boston, Massachusetts, USA,</location>
<contexts>
<context position="1684" citStr="Pantel and Ravichandran, 2004" startWordPosition="253" endWordPosition="256">systems on several Englishlanguage benchmarks. It also shows excellent performance on three dozen additional benchmark problems from English, Chinese and Japanese, thus demonstrating language-independence. 1 Introduction An important and well-studied problem is the production of semantic lexicons for classes of interest; that is, the generation of all instances of a set (e.g., “apple”, “orange”, “banana”) given a name of that set (e.g., “fruits”). This task is often addressed by linguistically analyzing very large collections of text (Hearst, 1992; Kozareva et al., 2008; Etzioni et al., 2005; Pantel and Ravichandran, 2004; Pasca, 2004), often using hand-constructed or machine-learned shallow linguistic patterns to detect hyponym instances. A hyponym is a word or phrase whose semantic range Figure 1: Examples of SEAL’s input and output. English entities are reality TV shows, Chinese entities are popular Taiwanese foods, and Japanese entities are famous cartoon characters. is included within that of another word. For example, x is a hyponym of y if x is a (kind of) y. The opposite of hyponym is hypernym. In this paper, we evaluate a novel approach to this problem, embodied in a system called ASIA1 (Automatic Set</context>
<context position="6514" citStr="Pantel and Ravichandran, 2004" startWordPosition="1048" endWordPosition="1051">ch done in the area of semantic class learning (aka lexical acquisition, lexicon induction, hyponym extraction, or open-domain information extraction). However, to the best of our knowledge, there is not a system that can perform set instance extraction in multiple languages given only the name of the set. Hearst (Hearst, 1992) presented an approach that utilizes hyponym patterns for extracting candidate instances given the name of a semantic set. The approach presented in Section 3.1 is based on this work, except that we extended it to two other languages: Chinese and Japanese. Pantel et al (Pantel and Ravichandran, 2004) presented an algorithm for automatically inducing names for semantic classes and for finding their instances by using “concept signatures” (statistics on co-occuring instances). Pasca (Pasca, 2004) presented a method for acquiring named entities in arbitrary categories using lexico-syntactic extraction patterns. Etzioni et al (Etzioni et al., 2005) presented the KnowItAll system that also utilizes hyponym patterns to extract class instances from the Web. All the systems mentioned rely on either a English part-of-speech tagger, a parser, or both, and hence are language-dependent. Kozareva et a</context>
<context position="9363" citStr="Pantel and Ravichandran, 2004" startWordPosition="1492" endWordPosition="1495">ote that the Expander and Bootstrapper rely on SEAL to accomplish their goals. In this section, we first describe the Noisy Instance Provider, then we briefly introduce SEAL, followed by the Noisy Instance Expander, and finally, the Bootstrapper. 3.1 Noisy Instance Provider Noisy Instance Provider extracts candidate instances from free text (i.e., web snippets) using the methods presented in Hearst’s early work (Hearst, 1992). Hearst exploited several patterns for identifying hyponymy relation (e.g., such author as Shakespeare) that many current state-ofthe-art systems (Kozareva et al., 2008; Pantel and Ravichandran, 2004; Etzioni et al., 2005; Pasca, 2004) are using. However, unlike all of those systems, ASIA does not use any NLP tool (e.g., partsof-speech tagger, parser) or rely on capitalization for extracting candidates (since we wanted ASIA to be as language-independent as possible). This leads to sets of instances that are noisy; however, we will show that set expansion and re-ranking can improve the initial sets dramatically. Below, we will refer to the initial set of noisy instances extracted by the Provider as the initial set. In more detail, the Provider first constructs a few queries of hyponym phra</context>
</contexts>
<marker>Pantel, Ravichandran, 2004</marker>
<rawString>Patrick Pantel and Deepak Ravichandran. 2004. Automatically labeling semantic classes. In Daniel Marcu Susan Dumais and Salim Roukos, editors, HLT-NAACL 2004: Main Proceedings, pages 321–328, Boston, Massachusetts, USA, May 2 -May 7. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marius Pasca</author>
</authors>
<title>Acquisition of categorized named entities for web search.</title>
<date>2004</date>
<booktitle>In CIKM ’04: Proceedings of the thirteenth ACM international conference on Information and knowledge management,</booktitle>
<pages>137--145</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="1698" citStr="Pasca, 2004" startWordPosition="257" endWordPosition="258">age benchmarks. It also shows excellent performance on three dozen additional benchmark problems from English, Chinese and Japanese, thus demonstrating language-independence. 1 Introduction An important and well-studied problem is the production of semantic lexicons for classes of interest; that is, the generation of all instances of a set (e.g., “apple”, “orange”, “banana”) given a name of that set (e.g., “fruits”). This task is often addressed by linguistically analyzing very large collections of text (Hearst, 1992; Kozareva et al., 2008; Etzioni et al., 2005; Pantel and Ravichandran, 2004; Pasca, 2004), often using hand-constructed or machine-learned shallow linguistic patterns to detect hyponym instances. A hyponym is a word or phrase whose semantic range Figure 1: Examples of SEAL’s input and output. English entities are reality TV shows, Chinese entities are popular Taiwanese foods, and Japanese entities are famous cartoon characters. is included within that of another word. For example, x is a hyponym of y if x is a (kind of) y. The opposite of hyponym is hypernym. In this paper, we evaluate a novel approach to this problem, embodied in a system called ASIA1 (Automatic Set Instance Acqu</context>
<context position="6712" citStr="Pasca, 2004" startWordPosition="1076" endWordPosition="1077">t can perform set instance extraction in multiple languages given only the name of the set. Hearst (Hearst, 1992) presented an approach that utilizes hyponym patterns for extracting candidate instances given the name of a semantic set. The approach presented in Section 3.1 is based on this work, except that we extended it to two other languages: Chinese and Japanese. Pantel et al (Pantel and Ravichandran, 2004) presented an algorithm for automatically inducing names for semantic classes and for finding their instances by using “concept signatures” (statistics on co-occuring instances). Pasca (Pasca, 2004) presented a method for acquiring named entities in arbitrary categories using lexico-syntactic extraction patterns. Etzioni et al (Etzioni et al., 2005) presented the KnowItAll system that also utilizes hyponym patterns to extract class instances from the Web. All the systems mentioned rely on either a English part-of-speech tagger, a parser, or both, and hence are language-dependent. Kozareva et al (Kozareva et al., 2008) illustrated an approach that uses a single hyponym pattern combined with graph structures to learn semantic class from the Web. Section 5.1 shows that our approach is compe</context>
<context position="9399" citStr="Pasca, 2004" startWordPosition="1500" endWordPosition="1501">o accomplish their goals. In this section, we first describe the Noisy Instance Provider, then we briefly introduce SEAL, followed by the Noisy Instance Expander, and finally, the Bootstrapper. 3.1 Noisy Instance Provider Noisy Instance Provider extracts candidate instances from free text (i.e., web snippets) using the methods presented in Hearst’s early work (Hearst, 1992). Hearst exploited several patterns for identifying hyponymy relation (e.g., such author as Shakespeare) that many current state-ofthe-art systems (Kozareva et al., 2008; Pantel and Ravichandran, 2004; Etzioni et al., 2005; Pasca, 2004) are using. However, unlike all of those systems, ASIA does not use any NLP tool (e.g., partsof-speech tagger, parser) or rely on capitalization for extracting candidates (since we wanted ASIA to be as language-independent as possible). This leads to sets of instances that are noisy; however, we will show that set expansion and re-ranking can improve the initial sets dramatically. Below, we will refer to the initial set of noisy instances extracted by the Provider as the initial set. In more detail, the Provider first constructs a few queries of hyponym phrase by using a semantic class name an</context>
</contexts>
<marker>Pasca, 2004</marker>
<rawString>Marius Pasca. 2004. Acquisition of categorized named entities for web search. In CIKM ’04: Proceedings of the thirteenth ACM international conference on Information and knowledge management, pages 137–145, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rion Snow</author>
<author>Daniel Jurafsky</author>
<author>Andrew Y Ng</author>
</authors>
<title>Semantic taxonomy induction from heterogenous evidence.</title>
<date>2006</date>
<booktitle>In ACL ’06: Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the ACL,</booktitle>
<pages>801--808</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="5021" citStr="Snow et al., 2006" startWordPosition="802" endWordPosition="805">ountries, constellations, NBA teams), ASIA has excellent performance for both recall and precision. On four additional English-language benchmark problems (US states, countries, singers, and common fish), we compare to recent work by Kozareva, Riloff, and Hovy (Kozareva et al., 2008), and show comparable or better performance on each of these benchmarks; this is notable because ASIA requires less information than the work of Kozareva et al (their system requires a concept name and a seed). We also compare ASIA on twelve additional benchmarks to the extended Wordnet 2.1 produced by Snow et al (Snow et al., 2006), and show that for these twelve sets, ASIA produces more than five times as many set instances with much higher precision (98% versus 70%). Another advantage of ASIA’s approach is that it is nearly language-independent: since the underlying set-expansion tools are language-independent, all that is needed to support a new target language is a new set of hyponym patterns for that language. In this paper, we present experimental results for Chinese and Japanese, as well as English, to demonstrate this language-independence. We present related work in Section 2, and explain our proposed approach </context>
<context position="7874" citStr="Snow et al., 2006" startWordPosition="1262" endWordPosition="1265">om the Web. Section 5.1 shows that our approach is competitive experimentally; however, their system requires more information, as it uses the name of the semantic set and a seed instance. Pasca (Pas¸ca, 2007b; Pas¸ca, 2007a) illustrated a set expansion approach that extracts instances from Web search queries given a set of input seed instances. This approach is similar in flavor to SEAL but, addresses a different task from that addressed here: for ASIA the user provides no seeds, but instead provides the name of the set being expanded. We compare to Pasca’s system in Section 5.2. Snow et al (Snow et al., 2006) use known hypernym/hyponym pairs to generate training data for a machine-learning system, which then learns many lexico-syntactic patterns. The patterns learned are based on English-language dependency parsing. We compare to Snow et al’s results in Section 5.3. 442 3 Proposed Approach ASIA is composed of three main components: the Noisy Instance Provider, the Noisy Instance Expander, and the Bootstrapper. Given a semantic class name, the Provider extracts a initial set of noisy candidate instances using hand-coded patterns, and ranks the instances by using a simple ranking model. The Expander</context>
<context position="25438" citStr="Snow et al., 2006" startWordPosition="4263" endWordPosition="4266">not initially converge to the correct instance list given the most natural concept name. Given “movies”, ASIA returns as instances strings like “comedy”, “action”, “drama”, and other kinds of movies. Given “video games”, it returns “PSP”, “Xbox”, “Wii”, etc. Given “people”, it returns “musicians”, “artists”, “politicians”, etc. We addressed this problem by simply re-running ASIA with a more specific class name (i.e., the first one returned); however, the result suggests that future work is needed to support automatic construction of hypernym hierarchy using semi-structured web documents. 5.3 (Snow et al., 2006) Snow (Snow et al., 2006) has extended the WordNet 2.1 by adding thousands of entries (synsets) at a relatively high precision. They have made several versions of extended WordNet available4. For comparison purposes, we selected the version (+30K) that achieved the best F-score in their experiments. 4http://ai.stanford.edu/˜rion/swn/ Precision @ Target Class System 25 50 100 150 250 Cities Pasca 1.00 0.96 0.88 0.84 0.75 ASIA 1.00 1.00 0.97 0.98 0.96 Countries Pasca 1.00 0.98 0.95 0.82 0.60 ASIA 1.00 1.00 1.00 1.00 0.79 Drugs Pasca 1.00 1.00 0.96 0.92 0.75 ASIA 1.00 1.00 1.00 1.00 0.98 Food Pas</context>
<context position="30965" citStr="Snow et al., 2006" startWordPosition="5227" endWordPosition="5230">ion from free text extract only four correct instances, with only 50% precision. ASIA’s approach is also quite languageindependent. By adding a few simple hyponym patterns, we can easily extend the system to support other languages. We have also shown that Hearst’s method works not only for English, but also for other languages such as Chinese and Japanese. We note that the ability to construct semantic lexicons in diverse languages has obvious applications in machine translation. We have also illustrated that ASIA outperforms three other English systems (Kozareva et al., 2008; Pas¸ca, 2007b; Snow et al., 2006), even though many of these use more input than just a semantic class name. In addition, ASIA is also quite efficient, requiring only a few minutes of computation and couple hundreds of web pages per problem. In the future, we plan to investigate the possibility of constructing hypernym hierarchy automatically using semi-structured documents. We also plan to explore whether lexicons can be constructed using only the back-off method for hyponym extraction, to make ASIA completely language independent. We also wish to explore whether performance can be improved by simultaneously finding class in</context>
</contexts>
<marker>Snow, Jurafsky, Ng, 2006</marker>
<rawString>Rion Snow, Daniel Jurafsky, and Andrew Y. Ng. 2006. Semantic taxonomy induction from heterogenous evidence. In ACL ’06: Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the ACL, pages 801– 808, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hanghang Tong</author>
<author>Christos Faloutsos</author>
<author>Jia-Yu Pan</author>
</authors>
<title>Fast random walk with restart and its applications. In</title>
<date>2006</date>
<booktitle>ICDM,</booktitle>
<pages>613--622</pages>
<publisher>IEEE Computer Society.</publisher>
<contexts>
<context position="14338" citStr="Tong et al., 2006" startWordPosition="2349" endWordPosition="2352">extracting candidate instances. These contextual strings are maximally-long contexts that bracket at least one occurrence of every seed string on a page. All other candidate instances bracketed by these contextual strings derived from a particular page are extracted from the same page. After the candidates are extracted, the Ranker constructs a graph that models all the relations between documents, wrappers, and candidate instances. Figure 3 shows an example graph where each node di represents a document, wi a wrapper, and mi a candidate instance. The Ranker performs Random Walk with Restart (Tong et al., 2006) on this graph (where the initial “restart” set is the set of seeds) until all node weights converge, and then ranks nodes by their final score; thus nodes are weighted higher if they are connected to many Figure 3: An example graph constructed by SEAL. Every edge from node x to y actually has an inverse relation edge from node y to x that is not shown here (e.g., mi is extracted by wi). seed nodes by many short, low fan-out paths. The final expanded set contains all candidate instance nodes, ranked by their weights in the graph. 3.3 Noisy Instance Expander Wang (Wang et al., 2008) illustrated</context>
<context position="18599" citStr="Tong et al., 2006" startWordPosition="3064" endWordPosition="3067">e and Yahoo!. In the first iteration, the Bootstrapper expands randomly-selected instances returned by the Expander that exist in the initial set. In every upcoming iteration, the Bootstrapper expands randomlyselected unsupervised instances obtained in the last iteration that also exist in the initial set. This process terminates when all possible seed combinations have been consumed or five iterations3 have been reached, whichever comes first. Notice that from iteration to iteration, statistics are aggregated by growing the graph described in Section 3.2. We perform Random Walk with Restart (Tong et al., 2006) on this graph to determine the final ranking of the extracted instances. 3To keep the overall runtime minimal. 4 Experiments 4.1 Datasets We evaluated our approach using the evaluation set presented in (Wang and Cohen, 2007), which contains 36 manually constructed lists across three different languages: English, Chinese, and Japanese (12 lists per language). Each list contains all instances of a particular semantic class in a certain language, and each instance contains a set of synonyms (e.g., USA, America). There are a total of 2515 instances, with an average of 70 instances per semantic cl</context>
</contexts>
<marker>Tong, Faloutsos, Pan, 2006</marker>
<rawString>Hanghang Tong, Christos Faloutsos, and Jia-Yu Pan. 2006. Fast random walk with restart and its applications. In ICDM, pages 613–622. IEEE Computer Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard C Wang</author>
<author>William W Cohen</author>
</authors>
<title>Language-independent set expansion of named entities using the web. In</title>
<date>2007</date>
<booktitle>ICDM,</booktitle>
<pages>342--350</pages>
<publisher>IEEE Computer Society.</publisher>
<contexts>
<context position="2668" citStr="Wang and Cohen, 2007" startWordPosition="418" endWordPosition="421">luded within that of another word. For example, x is a hyponym of y if x is a (kind of) y. The opposite of hyponym is hypernym. In this paper, we evaluate a novel approach to this problem, embodied in a system called ASIA1 (Automatic Set Instance Acquirer). ASIA takes a semantic class name as input (e.g., “car makers”) and automatically outputs instances (e.g., “ford”, “nissan”, “toyota”). Unlike prior methods, ASIA makes heavy use of tools for web-based set expansion. Set expansion is the task of finding all instances of a set given a small number of example (seed) instances. ASIA uses SEAL (Wang and Cohen, 2007), a language-independent web-based system that performed extremely well on a large number of benchmark sets – given three correct seeds, SEAL obtained average MAP scores in the high 90’s for 36 benchmark problems, including a dozen test problems each for English, Chinese and Japanese. SEAL works well in part because it can efficiently find and process many semi-structured web documents containing instances of the set being expanded. Figure 1 shows some examples of SEAL’s input and output. SEAL has been recently extended to be robust to errors in its initial set of seeds (Wang et al., 1http://r</context>
<context position="4354" citStr="Wang and Cohen, 2007" startWordPosition="695" endWordPosition="698"> (e.g., “fruits such as ”) to find a large but noisy set of seed instances. Second, ASIA uses the extended version of SEAL to expand the noisy set of seeds. ASIA’s approach is motivated by the conjecture that for many natural classes, the amount of information available in semi-structured documents on the Web is much larger than the amount of information available in free-text documents; hence, it is natural to attempt to augment search for set instances in free-text with semi-structured document analysis. We show that ASIA performs extremely well experimentally. On the 36 benchmarks used in (Wang and Cohen, 2007), which are relatively small closed sets (e.g., countries, constellations, NBA teams), ASIA has excellent performance for both recall and precision. On four additional English-language benchmark problems (US states, countries, singers, and common fish), we compare to recent work by Kozareva, Riloff, and Hovy (Kozareva et al., 2008), and show comparable or better performance on each of these benchmarks; this is notable because ASIA requires less information than the work of Kozareva et al (their system requires a concept name and a seed). We also compare ASIA on twelve additional benchmarks to </context>
<context position="12588" citStr="Wang and Cohen, 2007" startWordPosition="2068" endWordPosition="2071">tain the first type, and also drops all characters following the hyponym phrase in excerpts that contain the second type. For some semantic class names (e.g., “cmu buildings”), there are no web 1 dist(x,e) + 1 11 xEe 443 documents containing any of the hyponym-phrase queries that were constructed using the name. In this case, the Provider turns to a back-off strategy which simply treats the semantic class name as the hyponym phrase and extracts/ranks all chunks cooccurring with the class name in the excerpts. 3.2 Set Expander - SEAL In this paper, we rely on a set expansion system named SEAL (Wang and Cohen, 2007), which stands for Set Expander for Any Language. The system accepts as input a few seeds of some target set 5 (e.g., “fruits”) and automatically finds other probable instances (e.g., “apple”, “banana”) of 5 in web documents. As its name implies, SEAL is independent of document languages: both the written (e.g., English) and the markup language (e.g., HTML). SEAL is a research system that has shown good performance in published results (Wang and Cohen, 2007; Wang et al., 2008; Wang and Cohen, 2008). Figure 1 shows some examples of SEAL’s input and output. In more detail, SEAL contains three ma</context>
<context position="16901" citStr="Wang and Cohen, 2007" startWordPosition="2790" endWordPosition="2793">the Extractor. In the origi2A collection of closed-set lists such as planets, Nobel prizes, and continents in English, Chinese and Japanese 444 nal SEAL, the Extractor requires the longest common contexts to bracket at least one instance of every seed per web page. However, when seeds are noisy, such common contexts usually do not exist. The Extractor in noise-resistant SEAL solves this problem by requiring the contexts to bracket at least one instance of a minimum of two seeds, rather than every seed. This is implemented using a trie-based method described briefly in the original SEAL paper (Wang and Cohen, 2007). In this paper, the Expander utilizes a slightly-modified version of the Extractor, which requires the contexts to bracket as many seed instances as possible. This idea is based on the assumption that irrelevant instances usually do not have common contexts; whereas relevant ones do. 3.4 Bootstrapper Bootstrapping (Etzioni et al., 2005; Kozareva, 2006; Nadeau et al., 2006) is an unsupervised iterative process in which a system continuously consumes its own outputs to improve its own performance. Wang (Wang and Cohen, 2008) showed that it is feasible to bootstrap the results of set expansion t</context>
<context position="18824" citStr="Wang and Cohen, 2007" startWordPosition="3100" endWordPosition="3103">pervised instances obtained in the last iteration that also exist in the initial set. This process terminates when all possible seed combinations have been consumed or five iterations3 have been reached, whichever comes first. Notice that from iteration to iteration, statistics are aggregated by growing the graph described in Section 3.2. We perform Random Walk with Restart (Tong et al., 2006) on this graph to determine the final ranking of the extracted instances. 3To keep the overall runtime minimal. 4 Experiments 4.1 Datasets We evaluated our approach using the evaluation set presented in (Wang and Cohen, 2007), which contains 36 manually constructed lists across three different languages: English, Chinese, and Japanese (12 lists per language). Each list contains all instances of a particular semantic class in a certain language, and each instance contains a set of synonyms (e.g., USA, America). There are a total of 2515 instances, with an average of 70 instances per semantic class. Figure 4 shows the datasets and their corresponding semantic class names that we use in our experiments. 4.2 Evaluation Metric Since the output of ASIA is a ranked list of extracted instances, we choose mean average prec</context>
</contexts>
<marker>Wang, Cohen, 2007</marker>
<rawString>Richard C. Wang and William W. Cohen. 2007. Language-independent set expansion of named entities using the web. In ICDM, pages 342–350. IEEE Computer Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard C Wang</author>
<author>William W Cohen</author>
</authors>
<title>Iterative set expansion of named entities using the web. In</title>
<date>2008</date>
<booktitle>ICDM,</booktitle>
<pages>1091--1096</pages>
<publisher>IEEE Computer Society.</publisher>
<contexts>
<context position="3535" citStr="Wang and Cohen, 2008" startWordPosition="559" endWordPosition="562">each for English, Chinese and Japanese. SEAL works well in part because it can efficiently find and process many semi-structured web documents containing instances of the set being expanded. Figure 1 shows some examples of SEAL’s input and output. SEAL has been recently extended to be robust to errors in its initial set of seeds (Wang et al., 1http://rcwang.com/asia 441 Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 441–449, Suntec, Singapore, 2-7 August 2009. c�2009 ACL and AFNLP 2008), and to use bootstrapping to iteratively improve its performance (Wang and Cohen, 2008). These extensions allow ASIA to extract instances of sets from the Web, as follows. First, given a semantic class name (e.g., “fruits”), ASIA uses a small set of language-dependent hyponym patterns (e.g., “fruits such as ”) to find a large but noisy set of seed instances. Second, ASIA uses the extended version of SEAL to expand the noisy set of seeds. ASIA’s approach is motivated by the conjecture that for many natural classes, the amount of information available in semi-structured documents on the Web is much larger than the amount of information available in free-text documents; hence, it i</context>
<context position="13091" citStr="Wang and Cohen, 2008" startWordPosition="2151" endWordPosition="2154">e excerpts. 3.2 Set Expander - SEAL In this paper, we rely on a set expansion system named SEAL (Wang and Cohen, 2007), which stands for Set Expander for Any Language. The system accepts as input a few seeds of some target set 5 (e.g., “fruits”) and automatically finds other probable instances (e.g., “apple”, “banana”) of 5 in web documents. As its name implies, SEAL is independent of document languages: both the written (e.g., English) and the markup language (e.g., HTML). SEAL is a research system that has shown good performance in published results (Wang and Cohen, 2007; Wang et al., 2008; Wang and Cohen, 2008). Figure 1 shows some examples of SEAL’s input and output. In more detail, SEAL contains three major components: the Fetcher, Extractor, and Ranker. The Fetcher is responsible for fetching web documents, and the URLs of the documents come from top results retrieved from the search engine using the concatenation of all seeds as the query. This ensures that every fetched web page contains all seeds. The Extractor automatically constructs “wrappers” (i.e. page-specific extraction rules) for each page that contains the seeds. Every wrapper comprises two character strings that specify the left and </context>
<context position="17430" citStr="Wang and Cohen, 2008" startWordPosition="2875" endWordPosition="2878">sing a trie-based method described briefly in the original SEAL paper (Wang and Cohen, 2007). In this paper, the Expander utilizes a slightly-modified version of the Extractor, which requires the contexts to bracket as many seed instances as possible. This idea is based on the assumption that irrelevant instances usually do not have common contexts; whereas relevant ones do. 3.4 Bootstrapper Bootstrapping (Etzioni et al., 2005; Kozareva, 2006; Nadeau et al., 2006) is an unsupervised iterative process in which a system continuously consumes its own outputs to improve its own performance. Wang (Wang and Cohen, 2008) showed that it is feasible to bootstrap the results of set expansion to improve the quality of a list. The paper introduces an iterative version of SEAL called iSEAL, which expands a list in multiple iterations. In each iteration, iSEAL expands a few candidates extracted in previous iterations and aggregates statistics. The Bootstrapper utilizes iSEAL to further improve the quality of the list returned by the Expander. In every iteration, the Bootstrapper retrieves 25 web pages by using the concatenation of three seeds as query to each of Google and Yahoo!. In the first iteration, the Bootstr</context>
</contexts>
<marker>Wang, Cohen, 2008</marker>
<rawString>Richard C. Wang and William W. Cohen. 2008. Iterative set expansion of named entities using the web. In ICDM, pages 1091–1096. IEEE Computer Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard C Wang</author>
<author>Nico Schlaefer</author>
<author>William W Cohen</author>
<author>Eric Nyberg</author>
</authors>
<title>Automatic set expansion for list question answering.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>947--954</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Honolulu, Hawaii,</location>
<contexts>
<context position="13068" citStr="Wang et al., 2008" startWordPosition="2147" endWordPosition="2150">he class name in the excerpts. 3.2 Set Expander - SEAL In this paper, we rely on a set expansion system named SEAL (Wang and Cohen, 2007), which stands for Set Expander for Any Language. The system accepts as input a few seeds of some target set 5 (e.g., “fruits”) and automatically finds other probable instances (e.g., “apple”, “banana”) of 5 in web documents. As its name implies, SEAL is independent of document languages: both the written (e.g., English) and the markup language (e.g., HTML). SEAL is a research system that has shown good performance in published results (Wang and Cohen, 2007; Wang et al., 2008; Wang and Cohen, 2008). Figure 1 shows some examples of SEAL’s input and output. In more detail, SEAL contains three major components: the Fetcher, Extractor, and Ranker. The Fetcher is responsible for fetching web documents, and the URLs of the documents come from top results retrieved from the search engine using the concatenation of all seeds as the query. This ensures that every fetched web page contains all seeds. The Extractor automatically constructs “wrappers” (i.e. page-specific extraction rules) for each page that contains the seeds. Every wrapper comprises two character strings tha</context>
<context position="14926" citStr="Wang et al., 2008" startWordPosition="2456" endWordPosition="2459">th Restart (Tong et al., 2006) on this graph (where the initial “restart” set is the set of seeds) until all node weights converge, and then ranks nodes by their final score; thus nodes are weighted higher if they are connected to many Figure 3: An example graph constructed by SEAL. Every edge from node x to y actually has an inverse relation edge from node y to x that is not shown here (e.g., mi is extracted by wi). seed nodes by many short, low fan-out paths. The final expanded set contains all candidate instance nodes, ranked by their weights in the graph. 3.3 Noisy Instance Expander Wang (Wang et al., 2008) illustrated that it is feasible to perform set expansion on noisy input seeds. The paper showed that the noisy output of any Question Answering system for list questions can be improved by using a noise-resistant version of SEAL (An example of a list question is “Who were the husbands of Heddy Lamar?”). Since the initial set of candidate instances obtained using Hearst’s method are noisy, the Expander expands them by performing multiple iterations of set expansion using the noise-resistant SEAL. For every iteration, the Expander performs set expansion on a static collection of web pages. This</context>
</contexts>
<marker>Wang, Schlaefer, Cohen, Nyberg, 2008</marker>
<rawString>Richard C. Wang, Nico Schlaefer, William W. Cohen, and Eric Nyberg. 2008. Automatic set expansion for list question answering. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 947–954, Honolulu, Hawaii, October. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>