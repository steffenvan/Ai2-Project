<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.941436">
Learning Word-Class Lattices for Definition and Hypernym Extraction
</title>
<author confidence="0.821535">
Roberto Navigli and Paola Velardi
</author>
<affiliation confidence="0.623927">
Dipartimento di Informatica
</affiliation>
<address confidence="0.494401">
Sapienza Universit`a di Roma
</address>
<email confidence="0.971221">
{navigli,velardi}@di.uniroma1.it
</email>
<sectionHeader confidence="0.997043" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999791947368421">
Definition extraction is the task of au-
tomatically identifying definitional sen-
tences within texts. The task has proven
useful in many research areas including
ontology learning, relation extraction and
question answering. However, current ap-
proaches – mostly focused on lexico-
syntactic patterns – suffer from both low
recall and precision, as definitional sen-
tences occur in highly variable syntactic
structures. In this paper, we propose Word-
Class Lattices (WCLs), a generalization of
word lattices that we use to model tex-
tual definitions. Lattices are learned from
a dataset of definitions from Wikipedia.
Our method is applied to the task of def-
inition and hypernym extraction and com-
pares favorably to other pattern general-
ization methods proposed in the literature.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999391933333334">
Textual definitions constitute a fundamental
source to look up when the meaning of a term is
sought. Definitions are usually collected in dictio-
naries and domain glossaries for consultation pur-
poses. However, manually constructing and up-
dating glossaries requires the cooperative effort of
a team of domain experts. Further, in the presence
of new words or usages, and – even worse – new
domains, such resources are of no help. Nonethe-
less, terms are attested in texts and some (usually
few) of the sentences in which a term occurs are
typically definitional, that is they provide a formal
explanation for the term of interest. While it is not
feasible to manually search texts for definitions,
this task can be automatized by means of Machine
Learning (ML) and Natural Language Processing
(NLP) techniques.
Automatic definition extraction is useful not
only in the construction of glossaries, but also
in many other NLP tasks. In ontology learning,
definitions are used to create and enrich concepts
with textual information (Gangemi et al., 2003),
and extract taxonomic and non-taxonomic rela-
tions (Snow et al., 2004; Navigli and Velardi,
2006; Navigli, 2009a). Definitions are also har-
vested in Question Answering to deal with “what
is” questions (Cui et al., 2007; Saggion, 2004).
In eLearning, they are used to help students as-
similate knowledge (Westerhout and Monachesi,
2007), etc.
Much of the current literature focuses on the use
of lexico-syntactic patterns, inspired by Hearst’s
(1992) seminal work. However, these methods
suffer both from low recall and precision, as defi-
nitional sentences occur in highly variable syntac-
tic structures, and because the most frequent def-
initional pattern – X is a Y – is inherently very
noisy.
In this paper we propose a generalized form of
word lattices, called Word-Class Lattices (WCLs),
as an alternative to lexico-syntactic pattern learn-
ing. A lattice is a directed acyclic graph (DAG), a
subclass of non-deterministic finite state automata
(NFA). The lattice structure has the purpose of
preserving the salient differences among distinct
sequences, while eliminating redundant informa-
tion. In computational linguistics, lattices have
been used to model in a compact way many se-
quences of symbols, each representing an alter-
native hypothesis. Lattice-based methods differ
in the types of nodes (words, phonemes, con-
cepts), the interpretation of links (representing ei-
ther a sequential or hierarchical ordering between
nodes), their means of creation, and the scor-
ing method used to extract the best consensus
output from the lattice (Schroeder et al., 2009).
In speech processing, phoneme or word lattices
(Campbell et al., 2007; Mathias and Byrne, 2006;
Collins et al., 2004) are used as an interface be-
tween speech recognition and understanding. Lat-
</bodyText>
<page confidence="0.939316">
1318
</page>
<note confidence="0.942104">
Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1318–1327,
Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999563733333333">
tices are adopted also in Chinese word segmenta-
tion (Jiang et al., 2008), decompounding in Ger-
man (Dyer, 2009), and to represent classes of
translation models in machine translation (Dyer et
al., 2008; Schroeder et al., 2009). In more com-
plex text processing tasks, such as information re-
trieval, information extraction and summarization,
the use of word lattices has been postulated but is
considered unrealistic because of the dimension of
the hypothesis space.
To reduce this problem, concept lattices have
been proposed (Carpineto and Romano, 2005;
Klein, 2008; Zhong et al., 2008). Here links repre-
sent hierarchical relations, rather than the sequen-
tial order of symbols like in word/phoneme lat-
tices, and nodes are clusters of salient words ag-
gregated using synonymy, similarity, or subtrees
of a thesaurus. However, salient word selection
and aggregation is non-obvious and furthermore
it falls into word sense disambiguation, a notori-
ously AI-hard problem (Navigli, 2009b).
In definition extraction, the variability of pat-
terns is higher than for “traditional” applications
of lattices, such as translation and speech, how-
ever not as high as in unconstrained sentences.
The methodology that we propose to align patterns
is based on the use of star (wildcard *) charac-
ters to facilitate sentence clustering. Each clus-
ter of sentences is then generalized to a lattice of
word classes (each class being either a frequent
word or a part of speech). A key feature of our
approach is its inherent ability to both identify def-
initions and extract hypernyms. The method is
tested on an annotated corpus of Wikipedia sen-
tences and a large Web corpus, in order to demon-
strate the independence of the method from the
annotated dataset. WCLs are shown to general-
ize over lexico-syntactic patterns, and outperform
well-known approaches to definition and hyper-
nym extraction.
The paper is organized as follows: Section 2
discusses related work, WCLs are introduced in
Section 3 and illustrated by means of an example
in Section 4, experiments are presented in Section
5. We conclude the paper in Section 6.
</bodyText>
<sectionHeader confidence="0.999874" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.997065943396227">
Definition Extraction. A great deal of work
is concerned with definition extraction in several
languages (Klavans and Muresan, 2001; Storrer
and Wellinghoff, 2006; Gaudio and Branco, 2007;
Iftene et al., 2007; Westerhout and Monachesi,
2007; Przepi´orkowski et al., 2007; Deg´orski et
al., 2008). The majority of these approaches use
symbolic methods that depend on lexico-syntactic
patterns or features, which are manually crafted
or semi-automatically learned (Zhang and Jiang,
2009; Hovy et al., 2003; Fahmi and Bouma, 2006;
Westerhout, 2009). Patterns are either very sim-
ple sequences of words (e.g. “refers to”, “is de-
fined as”, “is a”) or more complex sequences of
words, parts of speech and chunks. A fully au-
tomated method is instead proposed by Borg et
al. (2009): they use genetic programming to learn
simple features to distinguish between definitions
and non-definitions, and then they apply a genetic
algorithm to learn individual weights of features.
However, rules are learned for only one category
of patterns, namely “is” patterns. As we already
remarked, most methods suffer from both low re-
call and precision, because definitional sentences
occur in highly variable and potentially noisy syn-
tactic structures. Higher performance (around 60-
70% F1-measure) is obtained only for specific do-
mains (e.g., an ICT corpus) and patterns (Borg et
al., 2009).
Only few papers try to cope with the general-
ity of patterns and domains in real-world corpora
(like the Web). In the GlossExtractor web-based
system (Velardi et al., 2008), to improve precision
while keeping pattern generality, candidates are
pruned using more refined stylistic patterns and
lexical filters. Cui et al. (2007) propose the use
of probabilistic lexico-semantic patterns, called
soft patterns, for definitional question answering
in the TREC contest1. The authors describe two
soft matching models: one is based on an n-gram
language model (with the Expectation Maximiza-
tion algorithm used to estimate the model param-
eter), the other on Profile Hidden Markov Mod-
els (PHMM). Soft patterns generalize over lexico-
syntactic “hard” patterns in that they allow a par-
tial matching by calculating a generative degree
of match probability between the test instance and
the set of training instances. Thanks to its gen-
eralization power, this method is the most closely
related to our work, however the task of defini-
tional question answering to which it is applied is
slightly different from that of definition extraction,
so a direct performance comparison is not possi-
</bodyText>
<footnote confidence="0.9959955">
1Text REtrieval Conferences: http://trec.nist.
gov
</footnote>
<page confidence="0.997195">
1319
</page>
<bodyText confidence="0.999909333333333">
ble2. In fact, the TREC evaluation datasets cannot
be considered true definitions, but rather text frag-
ments providing some relevant fact about a target
term. For example, sentences like: “Bollywood is
a Bombay-based film industry” and “700 or more
films produced by India with 200 or more from
Bollywood” are both “vital” answers for the ques-
tion “Bollywood”, according to TREC classifica-
tion, but the second sentence is not a definition.
Hypernym Extraction. The literature on hy-
pernym extraction offers a higher variability of
methods, from simple lexical patterns (Hearst,
1992; Oakes, 2005) to statistical and machine
learning techniques (Agirre et al., 2000; Cara-
ballo, 1999; Dolan et al., 1993; Sanfilippo and
Pozna´nski, 1992; Ritter et al., 2009). One of the
highest-coverage methods is proposed by Snow et
al. (2004). They first search sentences that con-
tain two terms which are known to be in a taxo-
nomic relation (term pairs are taken from Word-
Net (Miller et al., 1990)); then they parse the sen-
tences, and automatically extract patterns from the
parse trees. Finally, they train a hypernym clas-
sifer based on these features. Lexico-syntactic pat-
terns are generated for each sentence relating a
term to its hypernym, and a dependency parser is
used to represent them.
</bodyText>
<sectionHeader confidence="0.995178" genericHeader="method">
3 Word-Class Lattices
</sectionHeader>
<subsectionHeader confidence="0.988285">
3.1 Preliminaries
</subsectionHeader>
<bodyText confidence="0.952683636363637">
Notion of definition. In our work, we rely on
a formal notion of textual definition. Specifically,
given a definition, e.g.: “In computer science, a
closure is a first-class function with free variables
that are bound in the lexical environment”, we as-
sume that it contains the following fields (Storrer
and Wellinghoff, 2006):
• The DEFINIENDUM field (DF): this part of
the definition includes the definiendum (that
is, the word being defined) and its modifiers
(e.g., “In computer science, a closure”);
</bodyText>
<listItem confidence="0.790829">
• The DEFINITOR field (VF): it includes the
verb phrase used to introduce the definition
(e.g., “is”);
</listItem>
<bodyText confidence="0.814450166666667">
2In the paper, a 55% recall and 34% precision is achieved
with the best experiment on TREC-13 data. Furthermore, the
classifier of Cui et al. (2007) is based on soft patterns but also
on a bag-of-word relevance heuristic. However, the relative
influence of the two methods on the final performance is not
discussed.
</bodyText>
<listItem confidence="0.9246645">
• The DEFINIENS field (GF): it includes the
genus phrase (usually including the hyper-
nym, e.g., “a first-class function”);
• The REST field (RF): it includes additional
</listItem>
<bodyText confidence="0.952258433333333">
clauses that further specify the differentia of
the definiendum with respect to its genus
(e.g., “with free variables that are bound in
the lexical environment”).
Further examples of definitional sentences an-
notated with the above fields are shown in Table
1. For each sentence, the definiendum (that is, the
word being defined) and its hypernym are marked
in bold and italic, respectively. Given the lexico-
syntactic nature of the definition extraction mod-
els we experiment with, training and test sentences
are part-of-speech tagged with the TreeTagger sys-
tem, a part-of-speech tagger available for many
languages (Schmid, 1995).
Word Classes and Generalized Sentences. We
now introduce our notion of word class, on which
our learning model is based. Let T be the set
of training sentences, manually bracketed with the
DF, VF, GF and RF fields. We first determine the
set F of words in T whose frequency is above a
threshold θ (e.g., the, a, is, of, refer, etc.). In our
training sentences, we replace the term being de-
fined with (TARGET), thus this frequent token is
also included in F.
We use the set of frequent words F to generalize
words to “word classes”. We define a word class
as either a word itself or its part of speech. Given
a sentence s = w1, w2, ... , w|s|, where wi is the
i-th word of s, we generalize its words wi to word
classes ωi as follows:
</bodyText>
<equation confidence="0.95055575">
�
wi if wi E F
ωi =
POS(wi) otherwise
</equation>
<bodyText confidence="0.995731777777778">
that is, a word wi is left unchanged if it occurs
frequently in the training corpus (i.e., wi E F)
or is transformed to its part of speech (POS(wi))
otherwise. As a result, we obtain a general-
ized sentence s&apos; = ω1, ω2, ... , ω|s|. For instance,
given the first sentence in Table 1, we obtain the
corresponding generalized sentence: “In NN, a
(TARGET) is a JJ NN”, where NN and JJ indicate
the noun and adjective classes, respectively.
</bodyText>
<subsectionHeader confidence="0.997954">
3.2 Algorithm
</subsectionHeader>
<bodyText confidence="0.996835333333333">
We now describe our learning algorithm based
on Word-Class Lattices. The algorithm consists of
three steps:
</bodyText>
<page confidence="0.941666">
1320
</page>
<bodyText confidence="0.990821">
[In arts, a chiaroscuro]DF [is]VF [a monochrome picture]GF.
[In mathematics, a graph]DF [is]VF [a data structure]GF [that consists of ... ]REST.
[In computer science, a pixel]DF [is]VF [a dot]GF [that is part of a computer image]REST.
</bodyText>
<tableCaption confidence="0.868897">
Table 1: Example definitions (defined terms are marked in bold face, their hypernyms in italic).
</tableCaption>
<listItem confidence="0.996522583333333">
• Star patterns: each sentence in the training
set is pre-processed and generalized to a star
pattern. For instance, “In arts, a chiaroscuro
is a monochrome picture” is transformed to
“In *, a (TARGET) is a *” (Section 3.2.1);
• Sentence clustering: the training sentences
are then clustered based on the star patterns
to which they belong (Section 3.2.2);
• Word-Class Lattice construction: for each
sentence cluster, a WCL is created by means
of a greedy alignment algorithm (Section
3.2.3).
</listItem>
<bodyText confidence="0.999943">
We present two variants of our WCL model,
dealing either globally with the entire sentence or
separately with its definition fields (Section 3.2.4).
The WCL models can then be used to classify any
input sentence of interest (Section 3.2.5).
</bodyText>
<subsectionHeader confidence="0.811624">
3.2.1 Star Patterns
</subsectionHeader>
<bodyText confidence="0.9971130625">
Let T be the set of training sentences. In this step,
we associate a star pattern σ(s) with each sentence
s E T . To do so, let s E T be a sentence such that
s = w1, w2, ... , w|s|, where wi is its i-th word.
Given the set F of most frequent words in T (cf.
Section 3.1), the star pattern σ(s) associated with
s is obtained by replacing with * all the words
wi E� F, that is all the tokens that are non-frequent
words. For instance, given the sentence “In arts,
a chiaroscuro is a monochrome picture”, the cor-
responding star pattern is “In *, a (TARGET) is a
, where (TARGET) is the defined term.
Note that, here and in what follows, we discard
the sentence fragments tagged with the REST field,
which is used only to delimit the core part of defi-
nitional sentences.
</bodyText>
<subsectionHeader confidence="0.763162">
3.2.2 Sentence Clustering
</subsectionHeader>
<bodyText confidence="0.999968071428571">
In the second step, we cluster the sentences in our
training set T based on their star patterns. For-
mally, let Σ = (σ1, ... , σm) be the set of star
patterns associated with the sentences in T . We
create a clustering C = (C1, ... , Cm) such that
Ci = {s E T : σ(s) = σi}, that is Ci contains all
the sentences whose star pattern is σi.
As an example, assume σ3 = “In *, a
(TARGET) is a *”. The sentences reported in Ta-
ble 1 are all grouped into cluster C3. We note that
each cluster Ci contains sentences whose degree
of variability is generally much lower than for any
pair of sentences in T belonging to two different
clusters.
</bodyText>
<subsectionHeader confidence="0.908229">
3.2.3 Word-Class Lattice Construction
</subsectionHeader>
<bodyText confidence="0.9899335">
Finally, the third step consists of the construction
of a Word-Class Lattice for each sentence cluster.
Given such a cluster Ci E C, we apply a greedy
algorithm that iteratively constructs the WCL.
Let Ci = {s1, s2,... , s|Ci|} and consider
its first sentence s1 = w11, w12, ... , w1|s1 |(wji
denotes the i-th token of the j-th sentence).
We first produce the corresponding general-
ized sentence s01 = ω11, ω12, ... , ω1|s1 |(cf. Sec-
tion 3.1). We then create a directed graph
</bodyText>
<equation confidence="0.9890605">
G = (V, E) such that V = {ω1 1, ... ,ω1 |s1|} and
E = {(ω1 1, ω12), (ω12, ω13), . . . , (ω1 |s1|−1, ω1 |s1|)}.
</equation>
<bodyText confidence="0.999708333333333">
Next, for the subsequent sentences in Ci, that
is, for each j = 2, ... , |Ci|, we determine the
alignment between the sentence sj and each
sentence sk E Ci such that k &lt; j based on the
following dynamic programming formulation
(Cormen et al., 1990, pp. 314–319):
</bodyText>
<equation confidence="0.620237">
Ma,b = max {Ma−1,b−1 + Sa,b, Ma,b−1, Ma−1,b}
</equation>
<bodyText confidence="0.999897666666667">
where a E {1,..., |sk|} and b E {1,..., |sj|},
Sa,b is a score of the matching between the a-th
token of sk and the b-th token of sj, and M0,0,
M0,b and Ma,0 are initially set to 0 for all a and b.
The matching score Sa,b is calculated on the
generalized sentences s0k of sk and s0j of sj as fol-
</bodyText>
<equation confidence="0.88616975">
lows:
�
1 if ωka = ωjb
0 otherwise
</equation>
<bodyText confidence="0.999898571428571">
where ωka and ωjb are the a-th and b-th word classes
of s0k and s0j, respectively. In other words, the
matching score equals 1 if the a-th and the b-th
tokens of the two original sentences have the same
word class.
Finally, the alignment score between sk and sj
is given by M|sk|,|si|, which calculates the mini-
</bodyText>
<figure confidence="0.933415086956522">
*”
Sa,b =
1321
structure
picture
dot
monochrome
JJ
arts
science
mathematics
NN1
, a (TARGET)
data
computer
NN3
NN4
NN2
In
pixel
graph
chiaroscuro
is a
</figure>
<figureCaption confidence="0.9977535">
Figure 1: The Word-Class Lattice for the sentences in Table 1. The support of each word class is reported
beside the corresponding node.
</figureCaption>
<bodyText confidence="0.997056666666667">
mal number of misalignments between the two to-
ken sequences. We repeat this calculation for each
sentence sk (k = 1, ... , j − 1) and choose the
one that maximizes its alignment score with sj.
We then use the best alignment to add sj to the
graph G. Such alignment is obtained by means
of backtracking from M|sk|,|sj |to M0,0. We add
to the set of vertices V the tokens of the gen-
eralized sentence s0j for which there is no align-
ment to s0k and we add to E the edges (ωj1, ωj�),
. . . ,(ωj |sj|−1, ωj |sj|). Furthermore, in the final lat-
tice, nodes associated with the hypernym words in
the learning sentences are marked as hypernyms
in order to be able to determine the hypernym of a
test sentence at classification time.
</bodyText>
<subsectionHeader confidence="0.520577">
3.2.4 Variants of the WCL Model
</subsectionHeader>
<bodyText confidence="0.9999665">
So far, we have assumed that our WCL model
learns lattices from the training sentences in
their entirety (we call this model WCL-1). We
now propose a second model that learns separate
WCLs for each field of the definition, namely:
the DEFINIENDUM (DF), DEFINITOR (VF) and
DEFINIENS (GF) fields (see Section 3.1). We re-
fer to this latter model as WCL-3. Rather than ap-
plying the WCL algorithm to the entire sentence,
the very same method is applied to the sentence
fragments tagged with one of the three definition
fields. The reason for introducing the WCL-3
model is that, while definitional patterns are highly
variable, DF, VF and GF individually exhibit a
lower variability, thus WCL-3 should improve the
generalization power.
</bodyText>
<subsectionHeader confidence="0.655937">
3.2.5 Classification
</subsectionHeader>
<bodyText confidence="0.999770888888889">
Once the learning process is over, a set of WCLs is
produced. Given a test sentence s, the classifica-
tion phase for the WCL-1 model consists of deter-
mining whether it exists a lattice that matches s. In
the case of WCL-3, we consider any combination
of DEFINIENDUM, DEFINITOR and DEFINIENS
lattices. While WCL-1 is applied as a yes-no clas-
sifier as there is a single WCL that can possibly
match the input sentence, WCL-3 selects, if any,
the combination of the three WCLs that best fits
the sentence. In fact, choosing the most appro-
priate combination of lattices impacts the perfor-
mance of hypernym extraction. The best combi-
nation of WCLs is selected by maximizing the fol-
lowing confidence score:
score(s, lDF, lVF, lGF) = coverage · log(support)
where s is the candidate sentence, lDF, lVF and lGF
are three lattices one for each definition field, cov-
erage is the fraction of words of the input sentence
covered by the three lattices, and support is the
sum of the number of sentences in the star patterns
corresponding to the three lattices.
Finally, when a sentence is classified as a def-
inition, its hypernym is extracted by selecting the
words in the input sentence that are marked as “hy-
pernyms” in the WCL-1 lattice (or in the WCL-3
GF lattice).
</bodyText>
<sectionHeader confidence="0.999464" genericHeader="method">
4 Example
</sectionHeader>
<bodyText confidence="0.998059214285714">
As an example, consider the definitions in Table
1. As illustrated in Section 3.2.2, their star pat-
tern is “In *, a (TARGET) is a *”. The corre-
sponding WCL is built as follows: the first part-
of-speech tagged sentence, “In/IN arts/NN , a/DT
(TARGET)/NN is/VBZ a/DT monochrome/JJ pic-
ture/NN”, is considered. The corresponding gen-
eralized sentence is “In NN , a (TARGET) is a
JJ NN”. The initially empty graph is thus popu-
lated with one node for each word class and one
edge for each pair of consecutive tokens, as shown
in Figure 1 (the central sequence of nodes in the
graph). Note that we draw the hypernym token
NN2 with a rectangle shape. We also add to the
</bodyText>
<page confidence="0.976073">
1322
</page>
<bodyText confidence="0.999636875">
graph a start node • and an end node (�), and con-
nect them to the corresponding initial and final
sentence tokens. Next, the second sentence, “In
mathematics, a graph is a data structure that con-
sists of...”, is aligned to the first sentence. The
alignment of the generalized sentence is perfect,
apart from the NN3 node corresponding to “data”.
The node is added to the graph together with the
edges a—* NN3 and NN3 —* NN2 . Finally, the
third sentence in Table 1, “In computer science, a
pixel is a dot that is part of a computer image”,
is generalized as “In NN NN , a (TARGET) is
a NN”. Thus, a new node NN4 is added, corre-
sponding to “computer” and new edges are added:
In—*NN4 and NN4—*NN1. Figure 1 shows the re-
sulting WCL-1 lattice.
</bodyText>
<sectionHeader confidence="0.999938" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<subsectionHeader confidence="0.978928">
5.1 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.9285105">
Datasets. We conducted experiments on two
different datasets:
</bodyText>
<listItem confidence="0.600891">
• A corpus of 4,619 Wikipedia sentences, that
contains 1,908 definitional and 2,711 non-
definitional sentences. The former were ob-
tained from a random selection of the first
sentences of Wikipedia articles3. The de-
</listItem>
<bodyText confidence="0.993467615384615">
fined terms belong to different Wikipedia
domain categories4, so as to capture a
representative and cross-domain sample of
lexical and syntactic patterns for defini-
tions. These sentences were manually an-
notated with DEFINIENDUM, DEFINITOR,
DEFINIENS and REST fields by an expert
annotator, who also marked the hypernyms.
The associated set of negative examples
(“syntactically plausible” false definitions)
was obtained by extracting from the same
Wikipedia articles sentences in which the
page title occurs.
</bodyText>
<listItem confidence="0.477179">
• A subset of the ukWaC Web corpus (Fer-
raresi et al., 2008), a large corpus of the En-
glish language constructed by crawling the
.uk domain of the Web. The subset includes
over 300,000 sentences in which occur any
of 239 terms selected from the terminology
of four different domains (COMPUTER SCI-
</listItem>
<footnote confidence="0.6228535">
3The first sentence of Wikipedia entries is, in the large
majority of cases, a definition of the page title.
4en.wikipedia.org/wiki/Wikipedia:Cate-
gories
</footnote>
<bodyText confidence="0.986860157894737">
ENCE, ASTRONOMY, CARDIOLOGY, AVIA-
TION).
The reason for using the ukWaC corpus is that, un-
like the “clean” Wikipedia dataset, in which rel-
atively simple patterns can achieve good results,
ukWaC represents a real-world test, with many
complex cases. For example, there are sentences
that should be classified as definitional according
to Section 3.1 but are rather uninformative, like
“dynamic programming was the brainchild of an
american mathematician”, as well as informative
sentences that are not definitional (e.g., they do not
have a hypernym), like “cubism was characterised
by muted colours and fragmented images”. Even
more frequently, the dataset includes sentences
which are not definitions but have a definitional
pattern (“A Pacific Northwest tribe’s saga refers to
a young woman who [..]”), or sentences with very
complex definitional patterns (“white body cells
are the body’s clean up squad” and “joule is also
an expression of electric energy”). These cases can
be correctly handled only with fine-grained pat-
terns. Additional details on the corpus and a more
thorough linguistic analysis of complex cases can
be found in Navigli et al. (2010).
Systems. For definition extraction, we experi-
ment with the following systems:
• WCL-1 and WCL-3: these two classifiers
are based on our Word-Class Lattice model.
WCL-1 learns from the training set a lattice
for each cluster of sentences, whereas WCL-
3 identifies clusters (and lattices) separately
for each sentence field (DEFINIENDUM,
DEFINITOR and DEFINIENS) and classifies a
sentence as a definition if any combination
from the three sets of lattices matches (cf.
Section 3.2.4, the best combination is se-
lected).
</bodyText>
<listItem confidence="0.996283545454546">
• Star patterns: a simple classifier based on
the patterns learned as a result of step 1 of our
WCL learning algorithm (cf. Section 3.2.1):
a sentence is classified as a definition if it
matches any of the star patterns in the model.
• Bigrams: an implementation of the bigram
classifier for soft pattern matching proposed
by Cui et al. (2007). The classifier selects as
definitions all the sentences whose probabil-
ity is above a specific threshold. The proba-
bility is calculated as a mixture of bigram and
</listItem>
<page confidence="0.840458">
1323
</page>
<table confidence="0.999712833333333">
Algorithm P R F1 A
WCL-1 99.88 42.09 59.22 76.06
WCL-3 98.81 60.74 75.23 83.48
Star patterns 86.74 66.14 75.05 81.84
Bigrams 66.70 82.70 73.84 75.80
Random BL 50.00 50.00 50.00 50.00
</table>
<tableCaption confidence="0.999825">
Table 2: Performance on the Wikipedia dataset.
</tableCaption>
<bodyText confidence="0.999640317073171">
unigram probabilities, with Laplace smooth-
ing on the latter. We use the very same set-
tings of Cui et al. (2007), including threshold
values. While the authors propose a second
soft-pattern approach based on Profile HMM
(cf. Section 2), their results do not show sig-
nificant improvements over the bigram lan-
guage model.
For hypernym extraction, we compared WCL-
1 and WCL-3 with Hearst’s patterns, a system
that extracts hypernyms from sentences based on
the lexico-syntactic patterns specified in Hearst’s
seminal work (1992). These include (hypernym
in italic): “such NP as {NP ,} {(or  |and)} NP”,
“NP {, NP} {,} or other NP”, “NP {,} includ-
ing { NP ,} {or  |and} NP”, “NP {,} especially {
NP ,} {or  |and} NP”, and variants thereof. How-
ever, it should be noted that hypernym extraction
methods in the literature do not extract hypernyms
from definitional sentences, like we do, but rather
from specific patterns like “X such as Y”. There-
fore a direct comparison with these methods is not
possible. Nonetheless, we decided to implement
Hearst’s patterns for the sake of completeness. We
could not replicate the more refined approach by
Snow et al. (2004) because it requires the annota-
tion of a possibly very large dataset of sentence
fragments. In any case Snow et al. (2004) re-
ported the following performance figures on a cor-
pus of dimension and complexity comparable with
ukWaC: the recall-precision graph indicates preci-
sion 85% at recall 10% and precision 25% at re-
call of 30% for the hypernym classifier. A variant
of the classifier that includes evidence from coor-
dinate terms (terms with a common ancestor in a
taxonomy) obtains an increased precision of 35%
at recall 30%. We see no reasons why these figures
should vary dramatically on the ukWaC.
Finally, we compare all systems with the ran-
dom baseline, that classifies a sentence as a defi-
nition with probability 12.
</bodyText>
<table confidence="0.9995845">
Algorithm P R†
WCL-1 98.33 39.39
WCL-3 94.87 56.57
Star patterns 44.01 63.63
Bigrams 46.60 45.45
Random BL 50.00 50.00
</table>
<tableCaption confidence="0.9195125">
Table 3: Performance on the ukWaC dataset († Re-
call is estimated).
</tableCaption>
<bodyText confidence="0.9919865">
Measures. To assess the performance of our
systems, we calculated the following measures:
</bodyText>
<listItem confidence="0.959175933333334">
• precision – the number of definitional sen-
tences correctly retrieved by the system over
the number of sentences marked by the sys-
tem as definitional.
• recall – the number of definitional sen-
tences correctly retrieved by the system over
the number of definitional sentences in the
dataset.
• the F1-measure – a harmonic mean of preci-
sion (P) and recall (R) given by 2� �
� +�.
• accuracy – the number of correctly classi-
fied sentences (either as definitional or non-
definitional) over the total number of sen-
tences in the dataset.
</listItem>
<subsectionHeader confidence="0.987974">
5.2 Results and Discussion
</subsectionHeader>
<bodyText confidence="0.999827380952381">
Definition Extraction. In Table 2 we report
the results of definition extraction systems on the
Wikipedia dataset. Given this dataset is also used
for training, experiments are performed with 10-
fold cross validation. The results show very high
precision for WCL-1, WCL-3 (around 99%) and
star patterns (86%). As expected, bigrams and star
patterns exhibit a higher recall (82% and 66%, re-
spectively). The lower recall of WCL-1 is due to
its limited ability to generalize compared to WCL-
3 and the other methods. In terms of F1-measure,
star patterns and WCL-3 achieve 75%, and are
thus the best systems. Similar performance is ob-
served when we also account for negative sen-
tences – that is we calculate accuracy (with WCL-
3 performing better). All the systems perform sig-
nificantly better than the random baseline.
From our Wikipedia corpus, we learned over
1,000 lattices (and star patterns). Using WCL-
3, we learned 381 DF, 252 VF and 395 GF lat-
tices, that then we used to extract definitions from
</bodyText>
<page confidence="0.97718">
1324
</page>
<table confidence="0.925452">
Algorithm Full Substring
WCL-1 42.75 77.00
WCL-3 40.73 78.58
</table>
<tableCaption confidence="0.8158445">
Table 4: Precision in hypernym extraction on the
Wikipedia dataset
</tableCaption>
<bodyText confidence="0.99996597368421">
the ukWaC dataset. To calculate precision on this
dataset, we manually validated the definitions out-
put by each system. However, given the large size
of the test set, recall could only be estimated. To
this end, we manually analyzed 50,000 sentences
and identified 99 definitions, against which recall
was calculated. The results are shown in Table 3.
On the ukWaC dataset, WCL-3 performs best, ob-
taining 94.87% precision and 56.57% recall (we
did not calculate F1, as recall is estimated). In-
terestingly, star patterns obtain only 44% preci-
sion and around 63% recall. Bigrams achieve
even lower performance, namely 46.60% preci-
sion, 45.45% recall. The reason for such bad
performance on ukWaC is due to the very dif-
ferent nature of the two datasets: for example, in
Wikipedia most “is a” sentences are definitional,
whereas this property is not verified in the real
world (that is, on the Web, of which ukWaC is
a sample). Also, while WCL does not need any
parameter tuning5, the same does not hold for bi-
grams6, whose probability threshold and mixture
weights need to be best tuned on the task at hand.
Hypernym Extraction. For hypernym extrac-
tion, we tested WCL-1, WCL-3 and Hearst’s pat-
terns. Precision results are reported in Tables 4
and 5 for the two datasets, respectively. The Sub-
string column refers to the case in which the cap-
tured hypernym is a substring of what the annota-
tor considered to be the correct hypernym. Notice
that this is a complex matter, because often the se-
lection of a hypernym depends on semantic and
contextual issues. For example, “Fluoroscopy is
an imaging method” and “the Mosaic was an in-
teresting project” have precisely the same genus
pattern, but (probably depending on the vagueness
of the noun in the first sentence, and of the adjec-
tive in the second) the annotator selected respec-
</bodyText>
<footnote confidence="0.999130166666667">
5WCL has only one threshold value 0 to be set for deter-
mining frequent words (cf. Section 3.1). However, no tuning
was made for choosing the best value of 0.
6We had to re-tune the system parameters on ukWaC,
since with the original settings of Cui et al. (2007) perfor-
mance was much lower.
</footnote>
<table confidence="0.99780825">
Algorithm Full Substring
WCL-1 86.19 (206) 96.23 (230)
WCL-3 89.27 (383) 96.27 (413)
Hearst 65.26 (62) 88.42 (84)
</table>
<tableCaption confidence="0.700004">
Table 5: Precision in hypernym extraction on the
ukWaC dataset (number of hypernyms in paren-
theses).
</tableCaption>
<bodyText confidence="0.99985625">
tively imaging method and project as hypernyms.
For the above reasons it is difficult to achieve high
performance in capturing the correct hypernym
(e.g. 40.73% with WCL-3 on Wikipedia). How-
ever, our performance of identifying a substring
of the correct hypernym is much higher (around
78.58%). In Table 4 we do not report the preci-
sion of Hearst’s patterns, as only one hypernym
was found, due to the inherently low coverage of
the method.
On the ukWaC dataset, the hypernyms returned
by the three systems were manually validated and
precision was calculated. Both WCL-1 and WCL-
3 obtained a very high precision (86-89% and 96%
in identifying the exact hypernym and a substring
of it, respectively). Both WCL models are thus
equally robust in identifying hypernyms, whereas
WCL-1 suffers from a lack of generalization in
definition extraction (cf. Tables 2 and 3). Also,
given that the ukWaC dataset contains sentences
in which any of 239 domain terms occur, WCL-3
extracts on average 1.6 and 1.7 full and substring
hypernyms per term, respectively. Hearst’s pat-
terns also obtain high precision, especially when
substrings are taken into account. However, the
number of hypernyms returned by this method is
much lower, due to the specificity of the patterns
(62 vs. 383 hypernyms returned by WCL-3).
</bodyText>
<sectionHeader confidence="0.999551" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.6512225">
In this paper, we have presented a lattice-based ap-
proach to definition and hypernym extraction. The
novelty of our approach is:
1. The use of a lattice structure to generalize
over lexico-syntactic definitional patterns;
2. The ability of the system to jointly identify
definitions and extract hypernyms;
3. The generality of the method, which applies
to generic Web documents in any domain and
style, and needs no parameter tuning;
</bodyText>
<page confidence="0.979263">
1325
</page>
<bodyText confidence="0.999630476190476">
4. The high performance as compared with the
best-known methods for both definition and
hypernym extraction. Our approach outper-
forms the other systems particularly where
the task is more complex, as in real-world
documents (i.e., the ukWaC corpus).
Even though definitional patterns are learned
from a manually annotated dataset, the dimension
and heterogeneity of the training dataset ensures
that training needs not to be repeated for specific
domains7, as demonstrated by the cross-domain
evaluation on the ukWaC corpus.
The datasets used in our experiments are avail-
able from http://lcl.uniroma1.it/wcl.
We also plan to release our system to the research
community. In the near future, we aim to apply the
output of our classifiers to the task of automated
taxonomy building, and to test the WCL approach
on other information extraction tasks, like hyper-
nym extraction from generic sentence fragments,
as in Snow et al. (2004).
</bodyText>
<sectionHeader confidence="0.998913" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.996316035714286">
Eneko Agirre, Ansa Olatz, Xabier Arregi, Xabier Ar-
tola, Arantza Daz de Ilarraza Snchez, Mikel Ler-
sundi, David Martnez, Kepa Sarasola, and Ruben
Urizar. 2000. Extraction of semantic relations from
a basque monolingual dictionary using constraint
grammar. In Proceedings of Euralex.
Claudia Borg, Mike Rosner, and Gordon Pace. 2009.
Evolutionary algorithms for definition extraction. In
Proceedings of the 1st Workshop on Definition Ex-
traction 2009 (wDE’09).
William M. Campbell, M. F. Richardson, and D. A.
Reynolds. 2007. Language recognition with word
lattices and support vector machines. In Proceed-
ings of the IEEE International Conference on Acous-
tics, Speech and Signal Processing (ICASSP 2007),
pages 989–992, Honolulu, HI.
Sharon A. Caraballo. 1999. Automatic construction
of a hypernym-labeled noun hierarchy from text. In
Proceedings of the 371h Annual Meeting of the Asso-
ciation for Computational Linguistics (ACL), pages
120–126, Maryland, USA.
Claudio Carpineto and Giovanni Romano. 2005. Us-
ing concept lattices for text retrieval and mining. In
B. Ganter, G. Stumme, and R. Wille, editors, Formal
Concept Analysis, pages 161–179.
Christopher Collins, Bob Carpenter, and Gerald Penn.
2004. Head-driven parsing for word lattices. In Pro-
ceedings of the 42nd Meeting of the Association for
</reference>
<footnote confidence="0.853923666666667">
7Of course, it would need some additional work if applied
to languages other than English. However, the approach does
not need to be adapted to the language of interest.
</footnote>
<reference confidence="0.9926678">
Computational Linguistics (ACL’04), Main Volume,
pages 231–238, Barcelona, Spain, July.
Thomas H. Cormen, Charles E. Leiserson, and
Ronald L. Rivest. 1990. Introduction to algorithms.
the MIT Electrical Engineering and Computer Sci-
ence Series. MIT Press, Cambridge, MA.
Hang Cui, Min-Yen Kan, and Tat-Seng Chua. 2007.
Soft pattern matching models for definitional ques-
tion answering. ACM Transactions on Information
Systems, 25(2):8.
Łukasz Deg´orski, Michał Marcinczuk, and Adam
Przepi´orkowski. 2008. Definition extraction us-
ing a sequential combination of baseline grammars
and machine learning classifiers. In Proceedings of
the Sixth International Conference on Language Re-
sources and Evaluation (LREC 2008), Marrakech,
Morocco.
William Dolan, Lucy Vanderwende, and Stephen D.
Richardson. 1993. Automatically deriving struc-
tured knowledge bases from on-line dictionaries. In
Proceedings of the First Conference of the Pacific
Association for Computational Linguistics, pages 5–
14.
Christopher Dyer, Smaranda Muresan, and Philip
Resnik. 2008. Generalizing word lattice translation.
In Proceedings of the Annual Meeting of the Asso-
ciation for Computational Linguistics (ACL 2008),
pages 1012–1020, Columbus, Ohio, USA.
Christopher Dyer. 2009. Using a maximum en-
tropy model to build segmentation lattices for mt.
In Proceedings of Human Language Technologies:
The 2009 Annual Conference of the North American
Chapter of the Association for Computational Lin-
guistics (HLT-NAACL 2009), pages 406–414, Boul-
der, Colorado, USA.
Ismail Fahmi and Gosse Bouma. 2006. Learning to
identify definitions using syntactic features. In Pro-
ceedings of the EACL 2006 workshop on Learning
Structured Information in Natural Language Appli-
cations, pages 64–71, Trento, Italy.
Adriano Ferraresi, Eros Zanchetta, Marco Baroni, and
Silvia Bernardini. 2008. Introducing and evaluating
ukwac, a very large Web-derived corpus of english.
In Proceedings of the 4th Web as Corpus Workshop
(WAC-4), Marrakech, Morocco.
Aldo Gangemi, Roberto Navigli, and Paola Velardi.
2003. The OntoWordNet project: Extension and ax-
iomatization of conceptual relations in WordNet. In
Proceedings of the International Conference on On-
tologies, Databases and Applications of SEmantics
(ODBASE 2003), pages 820–838, Catania, Italy.
Rosa Del Gaudio and Ant´onio Branco. 2007. Auto-
matic extraction of definitions in portuguese: A rule-
based approach. In Proceedings of the TeMa Work-
shop.
Marti Hearst. 1992. Automatic acquisition of hy-
ponyms from large text corpora. In Proceed-
ings of the 141h International Conference on Com-
putational Linguistics (COLING), pages 539–545,
Nantes, France.
</reference>
<page confidence="0.828696">
1326
</page>
<reference confidence="0.999747383333333">
Eduard Hovy, Andrew Philpot, Judith Klavans, Ulrich
Germann, and Peter T. Davis. 2003. Extending
metadata definitions by automatically extracting and
organizing glossary definitions. In Proceedings of
the 2003 Annual National Conference on Digital
Government Research, pages 1–6. Digital Govern-
ment Society of North America.
Adrian Iftene, Diana Trandab˘a, and Ionut Pistol. 2007.
Natural language processing and knowledge repre-
sentation for elearning environments. In Proc. of
Applications for Romanian. Proceedings of RANLP
workshop, pages 19–25.
Wenbin Jiang, Haitao Mi, and Qun Liu. 2008. Word
lattice reranking for chineseword segmentation and
part-of-speech tagging. In Proceedings of the 22nd
International Conference on Computational Lin-
guistics (COLING 2008), pages 385–392, Manch-
ester, UK.
Judith Klavans and Smaranda Muresan. 2001. Eval-
uation of the DEFINDER system for fully auto-
matic glossary construction. In Proc. of the Amer-
ican Medical Informatics Association (AMIA) Sym-
posium.
Michael Tully Klein. 2008. Understanding English
with Lattice-Learning, Master thesis. MIT, Cam-
bridge, MA, USA.
Lambert Mathias and William Byrne. 2006. Statis-
tical phrase-based speech translation. In Proceed-
ings of the IEEE International Conference on Acous-
tics, Speech and Signal Processing (ICASSP 2006),
Toulouse, France.
George A. Miller, R.T. Beckwith, Christiane D. Fell-
baum, D. Gross, and K. Miller. 1990. WordNet:
an online lexical database. International Journal of
Lexicography, 3(4):235–244.
Roberto Navigli and Paola Velardi. 2006. Ontology
enrichment through automatic semantic annotation
of on-line glossaries. In Proceedings of the 15th In-
ternational Conference on Knowledge Engineering
and Knowledge Management (EKAW 2006), pages
126–140, Podebrady, Czech Republic.
Roberto Navigli, Paola Velardi, and Juana Maria Ruiz-
Martinez. 2010. An annotated dataset for extract-
ing definitions and hypernyms from the Web. In
Proceedings of the 7th International Conference on
Language Resources and Evaluation (LREC 2010),
Valletta, Malta.
Roberto Navigli. 2009a. Using cycles and quasi-cycles
to disambiguate dictionary glosses. In Proceed-
ings of the 12th Conference of the European Chap-
ter of the Association for Computational Linguistics
(EACL 2009), pages 594–602, Athens, Greece.
Roberto Navigli. 2009b. Word Sense Disambiguation:
A survey. ACM Computing Surveys, 41(2):1–69.
Michael P. Oakes. 2005. Using hearst’s rules for
the automatic acquisition of hyponyms for mining a
pharmaceutical corpus. In Proceedings of the Work-
shop Text Mining Research.
Adam Przepi´orkowski, Lukasz Deg´orski, Beata
W´ojtowicz, Miroslav Spousta, Vladislav Kuboˇn,
Kiril Simov, Petya Osenova, and Lothar Lemnitzer.
2007. Towards the automatic extraction of defini-
tions in slavic. In Proceedings of the Workshop
on Balto-Slavonic Natural Language Processing (in
ACL ’07), pages 43–50, Prague, Czech Republic.
Association for Computational Linguistics.
Alan Ritter, Stephen Soderland, and Oren Etzioni.
2009. What is this, anyway: Automatic hypernym
discovery. In Proceedings of the 2009 AAAI Spring
Symposium on Learning by Reading and Learning
to Read, pages 88–93.
Horacio Saggion. 2004. Identifying denitions in text
collections for question answering. In Proceedings
of the Fourth International Conference on Language
Resources and Evaluation (LREC 2004), Lisbon,
Portugal.
Antonio Sanfilippo and Victor Pozna´nski. 1992. The
acquisition of lexical knowledge from combined
machine-readable dictionary sources. In Proceed-
ings of the third Conference on Applied Natural Lan-
guage Processing, pages 80–87.
Helmut Schmid. 1995. Improvements in part-of-
speech tagging with an application to german. In
Proceedings of the ACL SIGDAT-Workshop, pages
47–50.
Josh Schroeder, Trevor Cohn, and Philipp Koehn.
2009. Word lattices for multi-source translation. In
Proceedings of the European Chapter of the Asso-
ciation for Computation Linguistics (EACL 2009),
pages 719–727, Athens, Greece.
Rion Snow, Dan Jurafsky, and Andrew Y. Ng. 2004.
Learning syntactic patterns for automatic hypernym
discovery. In Proceedings of Advances in Neural
Information Processing Systems, pages 1297–1304.
Angelika Storrer and Sandra Wellinghoff. 2006. Auto-
mated detection and annotation of term definitions in
german text corpora. In Proceedings of the Fifth In-
ternational Conference on Language Resources and
Evaluation (LREC 2006), Genova, Italy.
Paola Velardi, Roberto Navigli, and Pierluigi
D’Amadio. 2008. Mining the Web to create
specialized glossaries. IEEE Intelligent Systems,
23(5):18–25.
Eline Westerhout and Paola Monachesi. 2007. Extrac-
tion of dutch definitory contexts for eLearning pur-
poses. In Proceedings of CLIN.
Eline Westerhout. 2009. Definition extraction using
linguistic and structural features. In Proceedings
of the RANLP 2009 Workshop on Definition Extrac-
tion, pages 61–67.
Chunxia Zhang and Peng Jiang. 2009. Automatic ex-
traction of definitions. In Proceedings of 2nd IEEE
International Conference on Computer Science and
Information Technology, pages 364–368.
Zhao-man Zhong, Zong-tian Liu, and Yan Guan. 2008.
Precise information extraction from text based on
two-level concept lattice. In Proceedings of the
2008 International Symposiums on Information Pro-
cessing (ISIP ’08), pages 275–279, Washington,
DC, USA.
</reference>
<page confidence="0.993813">
1327
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.457706">
<title confidence="0.999988">Learning Word-Class Lattices for Definition and Hypernym Extraction</title>
<author confidence="0.989935">Navigli Velardi</author>
<affiliation confidence="0.719217">Dipartimento di Informatica Sapienza Universit`a di Roma</affiliation>
<abstract confidence="0.9985679">Definition extraction is the task of automatically identifying definitional sentences within texts. The task has proven useful in many research areas including ontology learning, relation extraction and question answering. However, current approaches – mostly focused on lexicosyntactic patterns – suffer from both low recall and precision, as definitional sentences occur in highly variable syntactic structures. In this paper, we propose Word- Class Lattices (WCLs), a generalization of word lattices that we use to model textual definitions. Lattices are learned from a dataset of definitions from Wikipedia. Our method is applied to the task of definition and hypernym extraction and compares favorably to other pattern generalization methods proposed in the literature.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eneko Agirre</author>
</authors>
<title>Ansa Olatz, Xabier Arregi, Xabier Artola, Arantza Daz de Ilarraza Snchez, Mikel Lersundi,</title>
<date>2000</date>
<booktitle>In Proceedings of Euralex.</booktitle>
<location>David</location>
<marker>Agirre, 2000</marker>
<rawString>Eneko Agirre, Ansa Olatz, Xabier Arregi, Xabier Artola, Arantza Daz de Ilarraza Snchez, Mikel Lersundi, David Martnez, Kepa Sarasola, and Ruben Urizar. 2000. Extraction of semantic relations from a basque monolingual dictionary using constraint grammar. In Proceedings of Euralex.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claudia Borg</author>
<author>Mike Rosner</author>
<author>Gordon Pace</author>
</authors>
<title>Evolutionary algorithms for definition extraction.</title>
<date>2009</date>
<booktitle>In Proceedings of the 1st Workshop on Definition Extraction</booktitle>
<contexts>
<context position="6874" citStr="Borg et al. (2009)" startWordPosition="1067" endWordPosition="1070">ff, 2006; Gaudio and Branco, 2007; Iftene et al., 2007; Westerhout and Monachesi, 2007; Przepi´orkowski et al., 2007; Deg´orski et al., 2008). The majority of these approaches use symbolic methods that depend on lexico-syntactic patterns or features, which are manually crafted or semi-automatically learned (Zhang and Jiang, 2009; Hovy et al., 2003; Fahmi and Bouma, 2006; Westerhout, 2009). Patterns are either very simple sequences of words (e.g. “refers to”, “is defined as”, “is a”) or more complex sequences of words, parts of speech and chunks. A fully automated method is instead proposed by Borg et al. (2009): they use genetic programming to learn simple features to distinguish between definitions and non-definitions, and then they apply a genetic algorithm to learn individual weights of features. However, rules are learned for only one category of patterns, namely “is” patterns. As we already remarked, most methods suffer from both low recall and precision, because definitional sentences occur in highly variable and potentially noisy syntactic structures. Higher performance (around 60- 70% F1-measure) is obtained only for specific domains (e.g., an ICT corpus) and patterns (Borg et al., 2009). On</context>
</contexts>
<marker>Borg, Rosner, Pace, 2009</marker>
<rawString>Claudia Borg, Mike Rosner, and Gordon Pace. 2009. Evolutionary algorithms for definition extraction. In Proceedings of the 1st Workshop on Definition Extraction 2009 (wDE’09).</rawString>
</citation>
<citation valid="true">
<authors>
<author>William M Campbell</author>
<author>M F Richardson</author>
<author>D A Reynolds</author>
</authors>
<title>Language recognition with word lattices and support vector machines.</title>
<date>2007</date>
<booktitle>In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP</booktitle>
<pages>989--992</pages>
<location>Honolulu, HI.</location>
<contexts>
<context position="3669" citStr="Campbell et al., 2007" startWordPosition="560" endWordPosition="563">ient differences among distinct sequences, while eliminating redundant information. In computational linguistics, lattices have been used to model in a compact way many sequences of symbols, each representing an alternative hypothesis. Lattice-based methods differ in the types of nodes (words, phonemes, concepts), the interpretation of links (representing either a sequential or hierarchical ordering between nodes), their means of creation, and the scoring method used to extract the best consensus output from the lattice (Schroeder et al., 2009). In speech processing, phoneme or word lattices (Campbell et al., 2007; Mathias and Byrne, 2006; Collins et al., 2004) are used as an interface between speech recognition and understanding. Lat1318 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1318–1327, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics tices are adopted also in Chinese word segmentation (Jiang et al., 2008), decompounding in German (Dyer, 2009), and to represent classes of translation models in machine translation (Dyer et al., 2008; Schroeder et al., 2009). In more complex text processing tasks, such as informati</context>
</contexts>
<marker>Campbell, Richardson, Reynolds, 2007</marker>
<rawString>William M. Campbell, M. F. Richardson, and D. A. Reynolds. 2007. Language recognition with word lattices and support vector machines. In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2007), pages 989–992, Honolulu, HI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sharon A Caraballo</author>
</authors>
<title>Automatic construction of a hypernym-labeled noun hierarchy from text.</title>
<date>1999</date>
<booktitle>In Proceedings of the 371h Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>120--126</pages>
<location>Maryland, USA.</location>
<contexts>
<context position="9382" citStr="Caraballo, 1999" startWordPosition="1455" endWordPosition="1457">true definitions, but rather text fragments providing some relevant fact about a target term. For example, sentences like: “Bollywood is a Bombay-based film industry” and “700 or more films produced by India with 200 or more from Bollywood” are both “vital” answers for the question “Bollywood”, according to TREC classification, but the second sentence is not a definition. Hypernym Extraction. The literature on hypernym extraction offers a higher variability of methods, from simple lexical patterns (Hearst, 1992; Oakes, 2005) to statistical and machine learning techniques (Agirre et al., 2000; Caraballo, 1999; Dolan et al., 1993; Sanfilippo and Pozna´nski, 1992; Ritter et al., 2009). One of the highest-coverage methods is proposed by Snow et al. (2004). They first search sentences that contain two terms which are known to be in a taxonomic relation (term pairs are taken from WordNet (Miller et al., 1990)); then they parse the sentences, and automatically extract patterns from the parse trees. Finally, they train a hypernym classifer based on these features. Lexico-syntactic patterns are generated for each sentence relating a term to its hypernym, and a dependency parser is used to represent them. </context>
</contexts>
<marker>Caraballo, 1999</marker>
<rawString>Sharon A. Caraballo. 1999. Automatic construction of a hypernym-labeled noun hierarchy from text. In Proceedings of the 371h Annual Meeting of the Association for Computational Linguistics (ACL), pages 120–126, Maryland, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claudio Carpineto</author>
<author>Giovanni Romano</author>
</authors>
<title>Using concept lattices for text retrieval and mining.</title>
<date>2005</date>
<pages>161--179</pages>
<editor>In B. Ganter, G. Stumme, and R. Wille, editors,</editor>
<contexts>
<context position="4537" citStr="Carpineto and Romano, 2005" startWordPosition="691" endWordPosition="694"> Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics tices are adopted also in Chinese word segmentation (Jiang et al., 2008), decompounding in German (Dyer, 2009), and to represent classes of translation models in machine translation (Dyer et al., 2008; Schroeder et al., 2009). In more complex text processing tasks, such as information retrieval, information extraction and summarization, the use of word lattices has been postulated but is considered unrealistic because of the dimension of the hypothesis space. To reduce this problem, concept lattices have been proposed (Carpineto and Romano, 2005; Klein, 2008; Zhong et al., 2008). Here links represent hierarchical relations, rather than the sequential order of symbols like in word/phoneme lattices, and nodes are clusters of salient words aggregated using synonymy, similarity, or subtrees of a thesaurus. However, salient word selection and aggregation is non-obvious and furthermore it falls into word sense disambiguation, a notoriously AI-hard problem (Navigli, 2009b). In definition extraction, the variability of patterns is higher than for “traditional” applications of lattices, such as translation and speech, however not as high as i</context>
</contexts>
<marker>Carpineto, Romano, 2005</marker>
<rawString>Claudio Carpineto and Giovanni Romano. 2005. Using concept lattices for text retrieval and mining. In B. Ganter, G. Stumme, and R. Wille, editors, Formal Concept Analysis, pages 161–179.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher Collins</author>
<author>Bob Carpenter</author>
<author>Gerald Penn</author>
</authors>
<title>Head-driven parsing for word lattices.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Meeting of the Association for Computational Linguistics (ACL’04), Main Volume,</booktitle>
<pages>231--238</pages>
<location>Barcelona, Spain,</location>
<contexts>
<context position="3717" citStr="Collins et al., 2004" startWordPosition="568" endWordPosition="571"> eliminating redundant information. In computational linguistics, lattices have been used to model in a compact way many sequences of symbols, each representing an alternative hypothesis. Lattice-based methods differ in the types of nodes (words, phonemes, concepts), the interpretation of links (representing either a sequential or hierarchical ordering between nodes), their means of creation, and the scoring method used to extract the best consensus output from the lattice (Schroeder et al., 2009). In speech processing, phoneme or word lattices (Campbell et al., 2007; Mathias and Byrne, 2006; Collins et al., 2004) are used as an interface between speech recognition and understanding. Lat1318 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1318–1327, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics tices are adopted also in Chinese word segmentation (Jiang et al., 2008), decompounding in German (Dyer, 2009), and to represent classes of translation models in machine translation (Dyer et al., 2008; Schroeder et al., 2009). In more complex text processing tasks, such as information retrieval, information extraction and summari</context>
</contexts>
<marker>Collins, Carpenter, Penn, 2004</marker>
<rawString>Christopher Collins, Bob Carpenter, and Gerald Penn. 2004. Head-driven parsing for word lattices. In Proceedings of the 42nd Meeting of the Association for Computational Linguistics (ACL’04), Main Volume, pages 231–238, Barcelona, Spain, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas H Cormen</author>
<author>Charles E Leiserson</author>
<author>Ronald L Rivest</author>
</authors>
<title>Introduction to algorithms. the MIT Electrical Engineering and Computer Science Series.</title>
<date>1990</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="16461" citStr="Cormen et al., 1990" startWordPosition="2708" endWordPosition="2711">,... , s|Ci|} and consider its first sentence s1 = w11, w12, ... , w1|s1 |(wji denotes the i-th token of the j-th sentence). We first produce the corresponding generalized sentence s01 = ω11, ω12, ... , ω1|s1 |(cf. Section 3.1). We then create a directed graph G = (V, E) such that V = {ω1 1, ... ,ω1 |s1|} and E = {(ω1 1, ω12), (ω12, ω13), . . . , (ω1 |s1|−1, ω1 |s1|)}. Next, for the subsequent sentences in Ci, that is, for each j = 2, ... , |Ci|, we determine the alignment between the sentence sj and each sentence sk E Ci such that k &lt; j based on the following dynamic programming formulation (Cormen et al., 1990, pp. 314–319): Ma,b = max {Ma−1,b−1 + Sa,b, Ma,b−1, Ma−1,b} where a E {1,..., |sk|} and b E {1,..., |sj|}, Sa,b is a score of the matching between the a-th token of sk and the b-th token of sj, and M0,0, M0,b and Ma,0 are initially set to 0 for all a and b. The matching score Sa,b is calculated on the generalized sentences s0k of sk and s0j of sj as follows: � 1 if ωka = ωjb 0 otherwise where ωka and ωjb are the a-th and b-th word classes of s0k and s0j, respectively. In other words, the matching score equals 1 if the a-th and the b-th tokens of the two original sentences have the same word c</context>
</contexts>
<marker>Cormen, Leiserson, Rivest, 1990</marker>
<rawString>Thomas H. Cormen, Charles E. Leiserson, and Ronald L. Rivest. 1990. Introduction to algorithms. the MIT Electrical Engineering and Computer Science Series. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hang Cui</author>
<author>Min-Yen Kan</author>
<author>Tat-Seng Chua</author>
</authors>
<title>Soft pattern matching models for definitional question answering.</title>
<date>2007</date>
<journal>ACM Transactions on Information Systems,</journal>
<volume>25</volume>
<issue>2</issue>
<contexts>
<context position="2256" citStr="Cui et al., 2007" startWordPosition="343" endWordPosition="346">e to manually search texts for definitions, this task can be automatized by means of Machine Learning (ML) and Natural Language Processing (NLP) techniques. Automatic definition extraction is useful not only in the construction of glossaries, but also in many other NLP tasks. In ontology learning, definitions are used to create and enrich concepts with textual information (Gangemi et al., 2003), and extract taxonomic and non-taxonomic relations (Snow et al., 2004; Navigli and Velardi, 2006; Navigli, 2009a). Definitions are also harvested in Question Answering to deal with “what is” questions (Cui et al., 2007; Saggion, 2004). In eLearning, they are used to help students assimilate knowledge (Westerhout and Monachesi, 2007), etc. Much of the current literature focuses on the use of lexico-syntactic patterns, inspired by Hearst’s (1992) seminal work. However, these methods suffer both from low recall and precision, as definitional sentences occur in highly variable syntactic structures, and because the most frequent definitional pattern – X is a Y – is inherently very noisy. In this paper we propose a generalized form of word lattices, called Word-Class Lattices (WCLs), as an alternative to lexico-s</context>
<context position="7798" citStr="Cui et al. (2007)" startWordPosition="1208" endWordPosition="1211">ethods suffer from both low recall and precision, because definitional sentences occur in highly variable and potentially noisy syntactic structures. Higher performance (around 60- 70% F1-measure) is obtained only for specific domains (e.g., an ICT corpus) and patterns (Borg et al., 2009). Only few papers try to cope with the generality of patterns and domains in real-world corpora (like the Web). In the GlossExtractor web-based system (Velardi et al., 2008), to improve precision while keeping pattern generality, candidates are pruned using more refined stylistic patterns and lexical filters. Cui et al. (2007) propose the use of probabilistic lexico-semantic patterns, called soft patterns, for definitional question answering in the TREC contest1. The authors describe two soft matching models: one is based on an n-gram language model (with the Expectation Maximization algorithm used to estimate the model parameter), the other on Profile Hidden Markov Models (PHMM). Soft patterns generalize over lexicosyntactic “hard” patterns in that they allow a partial matching by calculating a generative degree of match probability between the test instance and the set of training instances. Thanks to its general</context>
<context position="10778" citStr="Cui et al. (2007)" startWordPosition="1684" endWordPosition="1687">cience, a closure is a first-class function with free variables that are bound in the lexical environment”, we assume that it contains the following fields (Storrer and Wellinghoff, 2006): • The DEFINIENDUM field (DF): this part of the definition includes the definiendum (that is, the word being defined) and its modifiers (e.g., “In computer science, a closure”); • The DEFINITOR field (VF): it includes the verb phrase used to introduce the definition (e.g., “is”); 2In the paper, a 55% recall and 34% precision is achieved with the best experiment on TREC-13 data. Furthermore, the classifier of Cui et al. (2007) is based on soft patterns but also on a bag-of-word relevance heuristic. However, the relative influence of the two methods on the final performance is not discussed. • The DEFINIENS field (GF): it includes the genus phrase (usually including the hypernym, e.g., “a first-class function”); • The REST field (RF): it includes additional clauses that further specify the differentia of the definiendum with respect to its genus (e.g., “with free variables that are bound in the lexical environment”). Further examples of definitional sentences annotated with the above fields are shown in Table 1. For</context>
<context position="24918" citStr="Cui et al. (2007)" startWordPosition="4163" endWordPosition="4166">eas WCL3 identifies clusters (and lattices) separately for each sentence field (DEFINIENDUM, DEFINITOR and DEFINIENS) and classifies a sentence as a definition if any combination from the three sets of lattices matches (cf. Section 3.2.4, the best combination is selected). • Star patterns: a simple classifier based on the patterns learned as a result of step 1 of our WCL learning algorithm (cf. Section 3.2.1): a sentence is classified as a definition if it matches any of the star patterns in the model. • Bigrams: an implementation of the bigram classifier for soft pattern matching proposed by Cui et al. (2007). The classifier selects as definitions all the sentences whose probability is above a specific threshold. The probability is calculated as a mixture of bigram and 1323 Algorithm P R F1 A WCL-1 99.88 42.09 59.22 76.06 WCL-3 98.81 60.74 75.23 83.48 Star patterns 86.74 66.14 75.05 81.84 Bigrams 66.70 82.70 73.84 75.80 Random BL 50.00 50.00 50.00 50.00 Table 2: Performance on the Wikipedia dataset. unigram probabilities, with Laplace smoothing on the latter. We use the very same settings of Cui et al. (2007), including threshold values. While the authors propose a second soft-pattern approach bas</context>
<context position="31247" citStr="Cui et al. (2007)" startWordPosition="5241" endWordPosition="5244">cause often the selection of a hypernym depends on semantic and contextual issues. For example, “Fluoroscopy is an imaging method” and “the Mosaic was an interesting project” have precisely the same genus pattern, but (probably depending on the vagueness of the noun in the first sentence, and of the adjective in the second) the annotator selected respec5WCL has only one threshold value 0 to be set for determining frequent words (cf. Section 3.1). However, no tuning was made for choosing the best value of 0. 6We had to re-tune the system parameters on ukWaC, since with the original settings of Cui et al. (2007) performance was much lower. Algorithm Full Substring WCL-1 86.19 (206) 96.23 (230) WCL-3 89.27 (383) 96.27 (413) Hearst 65.26 (62) 88.42 (84) Table 5: Precision in hypernym extraction on the ukWaC dataset (number of hypernyms in parentheses). tively imaging method and project as hypernyms. For the above reasons it is difficult to achieve high performance in capturing the correct hypernym (e.g. 40.73% with WCL-3 on Wikipedia). However, our performance of identifying a substring of the correct hypernym is much higher (around 78.58%). In Table 4 we do not report the precision of Hearst’s pattern</context>
</contexts>
<marker>Cui, Kan, Chua, 2007</marker>
<rawString>Hang Cui, Min-Yen Kan, and Tat-Seng Chua. 2007. Soft pattern matching models for definitional question answering. ACM Transactions on Information Systems, 25(2):8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Łukasz Deg´orski</author>
<author>Michał Marcinczuk</author>
<author>Adam Przepi´orkowski</author>
</authors>
<title>Definition extraction using a sequential combination of baseline grammars and machine learning classifiers.</title>
<date>2008</date>
<booktitle>In Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC</booktitle>
<location>Marrakech, Morocco.</location>
<marker>Deg´orski, Marcinczuk, Przepi´orkowski, 2008</marker>
<rawString>Łukasz Deg´orski, Michał Marcinczuk, and Adam Przepi´orkowski. 2008. Definition extraction using a sequential combination of baseline grammars and machine learning classifiers. In Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC 2008), Marrakech, Morocco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William Dolan</author>
<author>Lucy Vanderwende</author>
<author>Stephen D Richardson</author>
</authors>
<title>Automatically deriving structured knowledge bases from on-line dictionaries.</title>
<date>1993</date>
<booktitle>In Proceedings of the First Conference of the Pacific Association for Computational Linguistics,</booktitle>
<pages>5--14</pages>
<contexts>
<context position="9402" citStr="Dolan et al., 1993" startWordPosition="1458" endWordPosition="1461"> but rather text fragments providing some relevant fact about a target term. For example, sentences like: “Bollywood is a Bombay-based film industry” and “700 or more films produced by India with 200 or more from Bollywood” are both “vital” answers for the question “Bollywood”, according to TREC classification, but the second sentence is not a definition. Hypernym Extraction. The literature on hypernym extraction offers a higher variability of methods, from simple lexical patterns (Hearst, 1992; Oakes, 2005) to statistical and machine learning techniques (Agirre et al., 2000; Caraballo, 1999; Dolan et al., 1993; Sanfilippo and Pozna´nski, 1992; Ritter et al., 2009). One of the highest-coverage methods is proposed by Snow et al. (2004). They first search sentences that contain two terms which are known to be in a taxonomic relation (term pairs are taken from WordNet (Miller et al., 1990)); then they parse the sentences, and automatically extract patterns from the parse trees. Finally, they train a hypernym classifer based on these features. Lexico-syntactic patterns are generated for each sentence relating a term to its hypernym, and a dependency parser is used to represent them. 3 Word-Class Lattice</context>
</contexts>
<marker>Dolan, Vanderwende, Richardson, 1993</marker>
<rawString>William Dolan, Lucy Vanderwende, and Stephen D. Richardson. 1993. Automatically deriving structured knowledge bases from on-line dictionaries. In Proceedings of the First Conference of the Pacific Association for Computational Linguistics, pages 5– 14.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher Dyer</author>
<author>Smaranda Muresan</author>
<author>Philip Resnik</author>
</authors>
<title>Generalizing word lattice translation.</title>
<date>2008</date>
<booktitle>In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL</booktitle>
<pages>1012--1020</pages>
<location>Columbus, Ohio, USA.</location>
<contexts>
<context position="4186" citStr="Dyer et al., 2008" startWordPosition="638" endWordPosition="641">tice (Schroeder et al., 2009). In speech processing, phoneme or word lattices (Campbell et al., 2007; Mathias and Byrne, 2006; Collins et al., 2004) are used as an interface between speech recognition and understanding. Lat1318 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1318–1327, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics tices are adopted also in Chinese word segmentation (Jiang et al., 2008), decompounding in German (Dyer, 2009), and to represent classes of translation models in machine translation (Dyer et al., 2008; Schroeder et al., 2009). In more complex text processing tasks, such as information retrieval, information extraction and summarization, the use of word lattices has been postulated but is considered unrealistic because of the dimension of the hypothesis space. To reduce this problem, concept lattices have been proposed (Carpineto and Romano, 2005; Klein, 2008; Zhong et al., 2008). Here links represent hierarchical relations, rather than the sequential order of symbols like in word/phoneme lattices, and nodes are clusters of salient words aggregated using synonymy, similarity, or subtrees of</context>
</contexts>
<marker>Dyer, Muresan, Resnik, 2008</marker>
<rawString>Christopher Dyer, Smaranda Muresan, and Philip Resnik. 2008. Generalizing word lattice translation. In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL 2008), pages 1012–1020, Columbus, Ohio, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher Dyer</author>
</authors>
<title>Using a maximum entropy model to build segmentation lattices for mt.</title>
<date>2009</date>
<booktitle>In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics (HLT-NAACL</booktitle>
<pages>406--414</pages>
<location>Boulder, Colorado, USA.</location>
<contexts>
<context position="4096" citStr="Dyer, 2009" startWordPosition="626" endWordPosition="627">ation, and the scoring method used to extract the best consensus output from the lattice (Schroeder et al., 2009). In speech processing, phoneme or word lattices (Campbell et al., 2007; Mathias and Byrne, 2006; Collins et al., 2004) are used as an interface between speech recognition and understanding. Lat1318 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1318–1327, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics tices are adopted also in Chinese word segmentation (Jiang et al., 2008), decompounding in German (Dyer, 2009), and to represent classes of translation models in machine translation (Dyer et al., 2008; Schroeder et al., 2009). In more complex text processing tasks, such as information retrieval, information extraction and summarization, the use of word lattices has been postulated but is considered unrealistic because of the dimension of the hypothesis space. To reduce this problem, concept lattices have been proposed (Carpineto and Romano, 2005; Klein, 2008; Zhong et al., 2008). Here links represent hierarchical relations, rather than the sequential order of symbols like in word/phoneme lattices, and</context>
</contexts>
<marker>Dyer, 2009</marker>
<rawString>Christopher Dyer. 2009. Using a maximum entropy model to build segmentation lattices for mt. In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics (HLT-NAACL 2009), pages 406–414, Boulder, Colorado, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ismail Fahmi</author>
<author>Gosse Bouma</author>
</authors>
<title>Learning to identify definitions using syntactic features.</title>
<date>2006</date>
<booktitle>In Proceedings of the EACL 2006 workshop on Learning Structured Information in Natural Language Applications,</booktitle>
<pages>64--71</pages>
<location>Trento, Italy.</location>
<contexts>
<context position="6628" citStr="Fahmi and Bouma, 2006" startWordPosition="1023" endWordPosition="1026"> 4, experiments are presented in Section 5. We conclude the paper in Section 6. 2 Related Work Definition Extraction. A great deal of work is concerned with definition extraction in several languages (Klavans and Muresan, 2001; Storrer and Wellinghoff, 2006; Gaudio and Branco, 2007; Iftene et al., 2007; Westerhout and Monachesi, 2007; Przepi´orkowski et al., 2007; Deg´orski et al., 2008). The majority of these approaches use symbolic methods that depend on lexico-syntactic patterns or features, which are manually crafted or semi-automatically learned (Zhang and Jiang, 2009; Hovy et al., 2003; Fahmi and Bouma, 2006; Westerhout, 2009). Patterns are either very simple sequences of words (e.g. “refers to”, “is defined as”, “is a”) or more complex sequences of words, parts of speech and chunks. A fully automated method is instead proposed by Borg et al. (2009): they use genetic programming to learn simple features to distinguish between definitions and non-definitions, and then they apply a genetic algorithm to learn individual weights of features. However, rules are learned for only one category of patterns, namely “is” patterns. As we already remarked, most methods suffer from both low recall and precisio</context>
</contexts>
<marker>Fahmi, Bouma, 2006</marker>
<rawString>Ismail Fahmi and Gosse Bouma. 2006. Learning to identify definitions using syntactic features. In Proceedings of the EACL 2006 workshop on Learning Structured Information in Natural Language Applications, pages 64–71, Trento, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adriano Ferraresi</author>
<author>Eros Zanchetta</author>
<author>Marco Baroni</author>
<author>Silvia Bernardini</author>
</authors>
<title>Introducing and evaluating ukwac, a very large Web-derived corpus of english.</title>
<date>2008</date>
<booktitle>In Proceedings of the 4th Web as Corpus Workshop (WAC-4),</booktitle>
<location>Marrakech, Morocco.</location>
<contexts>
<context position="22509" citStr="Ferraresi et al., 2008" startWordPosition="3780" endWordPosition="3784">n of the first sentences of Wikipedia articles3. The defined terms belong to different Wikipedia domain categories4, so as to capture a representative and cross-domain sample of lexical and syntactic patterns for definitions. These sentences were manually annotated with DEFINIENDUM, DEFINITOR, DEFINIENS and REST fields by an expert annotator, who also marked the hypernyms. The associated set of negative examples (“syntactically plausible” false definitions) was obtained by extracting from the same Wikipedia articles sentences in which the page title occurs. • A subset of the ukWaC Web corpus (Ferraresi et al., 2008), a large corpus of the English language constructed by crawling the .uk domain of the Web. The subset includes over 300,000 sentences in which occur any of 239 terms selected from the terminology of four different domains (COMPUTER SCI3The first sentence of Wikipedia entries is, in the large majority of cases, a definition of the page title. 4en.wikipedia.org/wiki/Wikipedia:Categories ENCE, ASTRONOMY, CARDIOLOGY, AVIATION). The reason for using the ukWaC corpus is that, unlike the “clean” Wikipedia dataset, in which relatively simple patterns can achieve good results, ukWaC represents a real-</context>
</contexts>
<marker>Ferraresi, Zanchetta, Baroni, Bernardini, 2008</marker>
<rawString>Adriano Ferraresi, Eros Zanchetta, Marco Baroni, and Silvia Bernardini. 2008. Introducing and evaluating ukwac, a very large Web-derived corpus of english. In Proceedings of the 4th Web as Corpus Workshop (WAC-4), Marrakech, Morocco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aldo Gangemi</author>
<author>Roberto Navigli</author>
<author>Paola Velardi</author>
</authors>
<title>The OntoWordNet project: Extension and axiomatization of conceptual relations in WordNet.</title>
<date>2003</date>
<booktitle>In Proceedings of the International Conference on Ontologies, Databases and Applications of SEmantics (ODBASE</booktitle>
<pages>820--838</pages>
<location>Catania, Italy.</location>
<contexts>
<context position="2037" citStr="Gangemi et al., 2003" startWordPosition="308" endWordPosition="311"> Nonetheless, terms are attested in texts and some (usually few) of the sentences in which a term occurs are typically definitional, that is they provide a formal explanation for the term of interest. While it is not feasible to manually search texts for definitions, this task can be automatized by means of Machine Learning (ML) and Natural Language Processing (NLP) techniques. Automatic definition extraction is useful not only in the construction of glossaries, but also in many other NLP tasks. In ontology learning, definitions are used to create and enrich concepts with textual information (Gangemi et al., 2003), and extract taxonomic and non-taxonomic relations (Snow et al., 2004; Navigli and Velardi, 2006; Navigli, 2009a). Definitions are also harvested in Question Answering to deal with “what is” questions (Cui et al., 2007; Saggion, 2004). In eLearning, they are used to help students assimilate knowledge (Westerhout and Monachesi, 2007), etc. Much of the current literature focuses on the use of lexico-syntactic patterns, inspired by Hearst’s (1992) seminal work. However, these methods suffer both from low recall and precision, as definitional sentences occur in highly variable syntactic structure</context>
</contexts>
<marker>Gangemi, Navigli, Velardi, 2003</marker>
<rawString>Aldo Gangemi, Roberto Navigli, and Paola Velardi. 2003. The OntoWordNet project: Extension and axiomatization of conceptual relations in WordNet. In Proceedings of the International Conference on Ontologies, Databases and Applications of SEmantics (ODBASE 2003), pages 820–838, Catania, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rosa Del Gaudio</author>
<author>Ant´onio Branco</author>
</authors>
<title>Automatic extraction of definitions in portuguese: A rulebased approach.</title>
<date>2007</date>
<booktitle>In Proceedings of the TeMa Workshop.</booktitle>
<contexts>
<context position="6289" citStr="Gaudio and Branco, 2007" startWordPosition="973" endWordPosition="976">dependence of the method from the annotated dataset. WCLs are shown to generalize over lexico-syntactic patterns, and outperform well-known approaches to definition and hypernym extraction. The paper is organized as follows: Section 2 discusses related work, WCLs are introduced in Section 3 and illustrated by means of an example in Section 4, experiments are presented in Section 5. We conclude the paper in Section 6. 2 Related Work Definition Extraction. A great deal of work is concerned with definition extraction in several languages (Klavans and Muresan, 2001; Storrer and Wellinghoff, 2006; Gaudio and Branco, 2007; Iftene et al., 2007; Westerhout and Monachesi, 2007; Przepi´orkowski et al., 2007; Deg´orski et al., 2008). The majority of these approaches use symbolic methods that depend on lexico-syntactic patterns or features, which are manually crafted or semi-automatically learned (Zhang and Jiang, 2009; Hovy et al., 2003; Fahmi and Bouma, 2006; Westerhout, 2009). Patterns are either very simple sequences of words (e.g. “refers to”, “is defined as”, “is a”) or more complex sequences of words, parts of speech and chunks. A fully automated method is instead proposed by Borg et al. (2009): they use gene</context>
</contexts>
<marker>Gaudio, Branco, 2007</marker>
<rawString>Rosa Del Gaudio and Ant´onio Branco. 2007. Automatic extraction of definitions in portuguese: A rulebased approach. In Proceedings of the TeMa Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marti Hearst</author>
</authors>
<title>Automatic acquisition of hyponyms from large text corpora.</title>
<date>1992</date>
<booktitle>In Proceedings of the 141h International Conference on Computational Linguistics (COLING),</booktitle>
<pages>539--545</pages>
<location>Nantes, France.</location>
<contexts>
<context position="9283" citStr="Hearst, 1992" startWordPosition="1441" endWordPosition="1442">es: http://trec.nist. gov 1319 ble2. In fact, the TREC evaluation datasets cannot be considered true definitions, but rather text fragments providing some relevant fact about a target term. For example, sentences like: “Bollywood is a Bombay-based film industry” and “700 or more films produced by India with 200 or more from Bollywood” are both “vital” answers for the question “Bollywood”, according to TREC classification, but the second sentence is not a definition. Hypernym Extraction. The literature on hypernym extraction offers a higher variability of methods, from simple lexical patterns (Hearst, 1992; Oakes, 2005) to statistical and machine learning techniques (Agirre et al., 2000; Caraballo, 1999; Dolan et al., 1993; Sanfilippo and Pozna´nski, 1992; Ritter et al., 2009). One of the highest-coverage methods is proposed by Snow et al. (2004). They first search sentences that contain two terms which are known to be in a taxonomic relation (term pairs are taken from WordNet (Miller et al., 1990)); then they parse the sentences, and automatically extract patterns from the parse trees. Finally, they train a hypernym classifer based on these features. Lexico-syntactic patterns are generated for</context>
</contexts>
<marker>Hearst, 1992</marker>
<rawString>Marti Hearst. 1992. Automatic acquisition of hyponyms from large text corpora. In Proceedings of the 141h International Conference on Computational Linguistics (COLING), pages 539–545, Nantes, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eduard Hovy</author>
<author>Andrew Philpot</author>
<author>Judith Klavans</author>
<author>Ulrich Germann</author>
<author>Peter T Davis</author>
</authors>
<title>Extending metadata definitions by automatically extracting and organizing glossary definitions.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 Annual National Conference on Digital Government Research,</booktitle>
<pages>1--6</pages>
<publisher>Digital Government Society of North America.</publisher>
<contexts>
<context position="6605" citStr="Hovy et al., 2003" startWordPosition="1019" endWordPosition="1022"> example in Section 4, experiments are presented in Section 5. We conclude the paper in Section 6. 2 Related Work Definition Extraction. A great deal of work is concerned with definition extraction in several languages (Klavans and Muresan, 2001; Storrer and Wellinghoff, 2006; Gaudio and Branco, 2007; Iftene et al., 2007; Westerhout and Monachesi, 2007; Przepi´orkowski et al., 2007; Deg´orski et al., 2008). The majority of these approaches use symbolic methods that depend on lexico-syntactic patterns or features, which are manually crafted or semi-automatically learned (Zhang and Jiang, 2009; Hovy et al., 2003; Fahmi and Bouma, 2006; Westerhout, 2009). Patterns are either very simple sequences of words (e.g. “refers to”, “is defined as”, “is a”) or more complex sequences of words, parts of speech and chunks. A fully automated method is instead proposed by Borg et al. (2009): they use genetic programming to learn simple features to distinguish between definitions and non-definitions, and then they apply a genetic algorithm to learn individual weights of features. However, rules are learned for only one category of patterns, namely “is” patterns. As we already remarked, most methods suffer from both </context>
</contexts>
<marker>Hovy, Philpot, Klavans, Germann, Davis, 2003</marker>
<rawString>Eduard Hovy, Andrew Philpot, Judith Klavans, Ulrich Germann, and Peter T. Davis. 2003. Extending metadata definitions by automatically extracting and organizing glossary definitions. In Proceedings of the 2003 Annual National Conference on Digital Government Research, pages 1–6. Digital Government Society of North America.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adrian Iftene</author>
<author>Diana Trandab˘a</author>
<author>Ionut Pistol</author>
</authors>
<title>Natural language processing and knowledge representation for elearning environments.</title>
<date>2007</date>
<booktitle>In Proc. of Applications for Romanian. Proceedings of RANLP workshop,</booktitle>
<pages>pages</pages>
<marker>Iftene, Trandab˘a, Pistol, 2007</marker>
<rawString>Adrian Iftene, Diana Trandab˘a, and Ionut Pistol. 2007. Natural language processing and knowledge representation for elearning environments. In Proc. of Applications for Romanian. Proceedings of RANLP workshop, pages 19–25.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wenbin Jiang</author>
<author>Haitao Mi</author>
<author>Qun Liu</author>
</authors>
<title>Word lattice reranking for chineseword segmentation and part-of-speech tagging.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics (COLING</booktitle>
<pages>385--392</pages>
<location>Manchester, UK.</location>
<contexts>
<context position="4058" citStr="Jiang et al., 2008" startWordPosition="618" endWordPosition="621">al ordering between nodes), their means of creation, and the scoring method used to extract the best consensus output from the lattice (Schroeder et al., 2009). In speech processing, phoneme or word lattices (Campbell et al., 2007; Mathias and Byrne, 2006; Collins et al., 2004) are used as an interface between speech recognition and understanding. Lat1318 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1318–1327, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics tices are adopted also in Chinese word segmentation (Jiang et al., 2008), decompounding in German (Dyer, 2009), and to represent classes of translation models in machine translation (Dyer et al., 2008; Schroeder et al., 2009). In more complex text processing tasks, such as information retrieval, information extraction and summarization, the use of word lattices has been postulated but is considered unrealistic because of the dimension of the hypothesis space. To reduce this problem, concept lattices have been proposed (Carpineto and Romano, 2005; Klein, 2008; Zhong et al., 2008). Here links represent hierarchical relations, rather than the sequential order of symb</context>
</contexts>
<marker>Jiang, Mi, Liu, 2008</marker>
<rawString>Wenbin Jiang, Haitao Mi, and Qun Liu. 2008. Word lattice reranking for chineseword segmentation and part-of-speech tagging. In Proceedings of the 22nd International Conference on Computational Linguistics (COLING 2008), pages 385–392, Manchester, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Judith Klavans</author>
<author>Smaranda Muresan</author>
</authors>
<title>Evaluation of the DEFINDER system for fully automatic glossary construction.</title>
<date>2001</date>
<booktitle>In Proc. of the American Medical Informatics Association (AMIA) Symposium.</booktitle>
<contexts>
<context position="6233" citStr="Klavans and Muresan, 2001" startWordPosition="965" endWordPosition="968">ces and a large Web corpus, in order to demonstrate the independence of the method from the annotated dataset. WCLs are shown to generalize over lexico-syntactic patterns, and outperform well-known approaches to definition and hypernym extraction. The paper is organized as follows: Section 2 discusses related work, WCLs are introduced in Section 3 and illustrated by means of an example in Section 4, experiments are presented in Section 5. We conclude the paper in Section 6. 2 Related Work Definition Extraction. A great deal of work is concerned with definition extraction in several languages (Klavans and Muresan, 2001; Storrer and Wellinghoff, 2006; Gaudio and Branco, 2007; Iftene et al., 2007; Westerhout and Monachesi, 2007; Przepi´orkowski et al., 2007; Deg´orski et al., 2008). The majority of these approaches use symbolic methods that depend on lexico-syntactic patterns or features, which are manually crafted or semi-automatically learned (Zhang and Jiang, 2009; Hovy et al., 2003; Fahmi and Bouma, 2006; Westerhout, 2009). Patterns are either very simple sequences of words (e.g. “refers to”, “is defined as”, “is a”) or more complex sequences of words, parts of speech and chunks. A fully automated method </context>
</contexts>
<marker>Klavans, Muresan, 2001</marker>
<rawString>Judith Klavans and Smaranda Muresan. 2001. Evaluation of the DEFINDER system for fully automatic glossary construction. In Proc. of the American Medical Informatics Association (AMIA) Symposium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Tully Klein</author>
</authors>
<title>Understanding English with Lattice-Learning, Master thesis. MIT,</title>
<date>2008</date>
<location>Cambridge, MA, USA.</location>
<contexts>
<context position="4550" citStr="Klein, 2008" startWordPosition="695" endWordPosition="696">2010 Association for Computational Linguistics tices are adopted also in Chinese word segmentation (Jiang et al., 2008), decompounding in German (Dyer, 2009), and to represent classes of translation models in machine translation (Dyer et al., 2008; Schroeder et al., 2009). In more complex text processing tasks, such as information retrieval, information extraction and summarization, the use of word lattices has been postulated but is considered unrealistic because of the dimension of the hypothesis space. To reduce this problem, concept lattices have been proposed (Carpineto and Romano, 2005; Klein, 2008; Zhong et al., 2008). Here links represent hierarchical relations, rather than the sequential order of symbols like in word/phoneme lattices, and nodes are clusters of salient words aggregated using synonymy, similarity, or subtrees of a thesaurus. However, salient word selection and aggregation is non-obvious and furthermore it falls into word sense disambiguation, a notoriously AI-hard problem (Navigli, 2009b). In definition extraction, the variability of patterns is higher than for “traditional” applications of lattices, such as translation and speech, however not as high as in unconstrain</context>
</contexts>
<marker>Klein, 2008</marker>
<rawString>Michael Tully Klein. 2008. Understanding English with Lattice-Learning, Master thesis. MIT, Cambridge, MA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lambert Mathias</author>
<author>William Byrne</author>
</authors>
<title>Statistical phrase-based speech translation.</title>
<date>2006</date>
<booktitle>In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP</booktitle>
<location>Toulouse, France.</location>
<contexts>
<context position="3694" citStr="Mathias and Byrne, 2006" startWordPosition="564" endWordPosition="567">distinct sequences, while eliminating redundant information. In computational linguistics, lattices have been used to model in a compact way many sequences of symbols, each representing an alternative hypothesis. Lattice-based methods differ in the types of nodes (words, phonemes, concepts), the interpretation of links (representing either a sequential or hierarchical ordering between nodes), their means of creation, and the scoring method used to extract the best consensus output from the lattice (Schroeder et al., 2009). In speech processing, phoneme or word lattices (Campbell et al., 2007; Mathias and Byrne, 2006; Collins et al., 2004) are used as an interface between speech recognition and understanding. Lat1318 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1318–1327, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics tices are adopted also in Chinese word segmentation (Jiang et al., 2008), decompounding in German (Dyer, 2009), and to represent classes of translation models in machine translation (Dyer et al., 2008; Schroeder et al., 2009). In more complex text processing tasks, such as information retrieval, information</context>
</contexts>
<marker>Mathias, Byrne, 2006</marker>
<rawString>Lambert Mathias and William Byrne. 2006. Statistical phrase-based speech translation. In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2006), Toulouse, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
<author>R T Beckwith</author>
<author>Christiane D Fellbaum</author>
<author>D Gross</author>
<author>K Miller</author>
</authors>
<title>WordNet: an online lexical database.</title>
<date>1990</date>
<journal>International Journal of Lexicography,</journal>
<volume>3</volume>
<issue>4</issue>
<contexts>
<context position="9683" citStr="Miller et al., 1990" startWordPosition="1508" endWordPosition="1511">according to TREC classification, but the second sentence is not a definition. Hypernym Extraction. The literature on hypernym extraction offers a higher variability of methods, from simple lexical patterns (Hearst, 1992; Oakes, 2005) to statistical and machine learning techniques (Agirre et al., 2000; Caraballo, 1999; Dolan et al., 1993; Sanfilippo and Pozna´nski, 1992; Ritter et al., 2009). One of the highest-coverage methods is proposed by Snow et al. (2004). They first search sentences that contain two terms which are known to be in a taxonomic relation (term pairs are taken from WordNet (Miller et al., 1990)); then they parse the sentences, and automatically extract patterns from the parse trees. Finally, they train a hypernym classifer based on these features. Lexico-syntactic patterns are generated for each sentence relating a term to its hypernym, and a dependency parser is used to represent them. 3 Word-Class Lattices 3.1 Preliminaries Notion of definition. In our work, we rely on a formal notion of textual definition. Specifically, given a definition, e.g.: “In computer science, a closure is a first-class function with free variables that are bound in the lexical environment”, we assume that</context>
</contexts>
<marker>Miller, Beckwith, Fellbaum, Gross, Miller, 1990</marker>
<rawString>George A. Miller, R.T. Beckwith, Christiane D. Fellbaum, D. Gross, and K. Miller. 1990. WordNet: an online lexical database. International Journal of Lexicography, 3(4):235–244.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
<author>Paola Velardi</author>
</authors>
<title>Ontology enrichment through automatic semantic annotation of on-line glossaries.</title>
<date>2006</date>
<booktitle>In Proceedings of the 15th International Conference on Knowledge Engineering and Knowledge Management (EKAW</booktitle>
<pages>126--140</pages>
<location>Podebrady, Czech Republic.</location>
<contexts>
<context position="2134" citStr="Navigli and Velardi, 2006" startWordPosition="323" endWordPosition="326">term occurs are typically definitional, that is they provide a formal explanation for the term of interest. While it is not feasible to manually search texts for definitions, this task can be automatized by means of Machine Learning (ML) and Natural Language Processing (NLP) techniques. Automatic definition extraction is useful not only in the construction of glossaries, but also in many other NLP tasks. In ontology learning, definitions are used to create and enrich concepts with textual information (Gangemi et al., 2003), and extract taxonomic and non-taxonomic relations (Snow et al., 2004; Navigli and Velardi, 2006; Navigli, 2009a). Definitions are also harvested in Question Answering to deal with “what is” questions (Cui et al., 2007; Saggion, 2004). In eLearning, they are used to help students assimilate knowledge (Westerhout and Monachesi, 2007), etc. Much of the current literature focuses on the use of lexico-syntactic patterns, inspired by Hearst’s (1992) seminal work. However, these methods suffer both from low recall and precision, as definitional sentences occur in highly variable syntactic structures, and because the most frequent definitional pattern – X is a Y – is inherently very noisy. In t</context>
</contexts>
<marker>Navigli, Velardi, 2006</marker>
<rawString>Roberto Navigli and Paola Velardi. 2006. Ontology enrichment through automatic semantic annotation of on-line glossaries. In Proceedings of the 15th International Conference on Knowledge Engineering and Knowledge Management (EKAW 2006), pages 126–140, Podebrady, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
<author>Paola Velardi</author>
<author>Juana Maria RuizMartinez</author>
</authors>
<title>An annotated dataset for extracting definitions and hypernyms from the Web.</title>
<date>2010</date>
<booktitle>In Proceedings of the 7th International Conference on Language Resources and Evaluation (LREC 2010),</booktitle>
<location>Valletta,</location>
<contexts>
<context position="24057" citStr="Navigli et al. (2010)" startWordPosition="4022" endWordPosition="4025"> hypernym), like “cubism was characterised by muted colours and fragmented images”. Even more frequently, the dataset includes sentences which are not definitions but have a definitional pattern (“A Pacific Northwest tribe’s saga refers to a young woman who [..]”), or sentences with very complex definitional patterns (“white body cells are the body’s clean up squad” and “joule is also an expression of electric energy”). These cases can be correctly handled only with fine-grained patterns. Additional details on the corpus and a more thorough linguistic analysis of complex cases can be found in Navigli et al. (2010). Systems. For definition extraction, we experiment with the following systems: • WCL-1 and WCL-3: these two classifiers are based on our Word-Class Lattice model. WCL-1 learns from the training set a lattice for each cluster of sentences, whereas WCL3 identifies clusters (and lattices) separately for each sentence field (DEFINIENDUM, DEFINITOR and DEFINIENS) and classifies a sentence as a definition if any combination from the three sets of lattices matches (cf. Section 3.2.4, the best combination is selected). • Star patterns: a simple classifier based on the patterns learned as a result of </context>
</contexts>
<marker>Navigli, Velardi, RuizMartinez, 2010</marker>
<rawString>Roberto Navigli, Paola Velardi, and Juana Maria RuizMartinez. 2010. An annotated dataset for extracting definitions and hypernyms from the Web. In Proceedings of the 7th International Conference on Language Resources and Evaluation (LREC 2010), Valletta, Malta.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
</authors>
<title>Using cycles and quasi-cycles to disambiguate dictionary glosses.</title>
<date>2009</date>
<booktitle>In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics (EACL</booktitle>
<pages>594--602</pages>
<location>Athens, Greece.</location>
<contexts>
<context position="2149" citStr="Navigli, 2009" startWordPosition="327" endWordPosition="328">efinitional, that is they provide a formal explanation for the term of interest. While it is not feasible to manually search texts for definitions, this task can be automatized by means of Machine Learning (ML) and Natural Language Processing (NLP) techniques. Automatic definition extraction is useful not only in the construction of glossaries, but also in many other NLP tasks. In ontology learning, definitions are used to create and enrich concepts with textual information (Gangemi et al., 2003), and extract taxonomic and non-taxonomic relations (Snow et al., 2004; Navigli and Velardi, 2006; Navigli, 2009a). Definitions are also harvested in Question Answering to deal with “what is” questions (Cui et al., 2007; Saggion, 2004). In eLearning, they are used to help students assimilate knowledge (Westerhout and Monachesi, 2007), etc. Much of the current literature focuses on the use of lexico-syntactic patterns, inspired by Hearst’s (1992) seminal work. However, these methods suffer both from low recall and precision, as definitional sentences occur in highly variable syntactic structures, and because the most frequent definitional pattern – X is a Y – is inherently very noisy. In this paper we pr</context>
<context position="4964" citStr="Navigli, 2009" startWordPosition="758" endWordPosition="759">as been postulated but is considered unrealistic because of the dimension of the hypothesis space. To reduce this problem, concept lattices have been proposed (Carpineto and Romano, 2005; Klein, 2008; Zhong et al., 2008). Here links represent hierarchical relations, rather than the sequential order of symbols like in word/phoneme lattices, and nodes are clusters of salient words aggregated using synonymy, similarity, or subtrees of a thesaurus. However, salient word selection and aggregation is non-obvious and furthermore it falls into word sense disambiguation, a notoriously AI-hard problem (Navigli, 2009b). In definition extraction, the variability of patterns is higher than for “traditional” applications of lattices, such as translation and speech, however not as high as in unconstrained sentences. The methodology that we propose to align patterns is based on the use of star (wildcard *) characters to facilitate sentence clustering. Each cluster of sentences is then generalized to a lattice of word classes (each class being either a frequent word or a part of speech). A key feature of our approach is its inherent ability to both identify definitions and extract hypernyms. The method is teste</context>
</contexts>
<marker>Navigli, 2009</marker>
<rawString>Roberto Navigli. 2009a. Using cycles and quasi-cycles to disambiguate dictionary glosses. In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics (EACL 2009), pages 594–602, Athens, Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
</authors>
<title>Word Sense Disambiguation: A survey.</title>
<date>2009</date>
<journal>ACM Computing Surveys,</journal>
<volume>41</volume>
<issue>2</issue>
<contexts>
<context position="2149" citStr="Navigli, 2009" startWordPosition="327" endWordPosition="328">efinitional, that is they provide a formal explanation for the term of interest. While it is not feasible to manually search texts for definitions, this task can be automatized by means of Machine Learning (ML) and Natural Language Processing (NLP) techniques. Automatic definition extraction is useful not only in the construction of glossaries, but also in many other NLP tasks. In ontology learning, definitions are used to create and enrich concepts with textual information (Gangemi et al., 2003), and extract taxonomic and non-taxonomic relations (Snow et al., 2004; Navigli and Velardi, 2006; Navigli, 2009a). Definitions are also harvested in Question Answering to deal with “what is” questions (Cui et al., 2007; Saggion, 2004). In eLearning, they are used to help students assimilate knowledge (Westerhout and Monachesi, 2007), etc. Much of the current literature focuses on the use of lexico-syntactic patterns, inspired by Hearst’s (1992) seminal work. However, these methods suffer both from low recall and precision, as definitional sentences occur in highly variable syntactic structures, and because the most frequent definitional pattern – X is a Y – is inherently very noisy. In this paper we pr</context>
<context position="4964" citStr="Navigli, 2009" startWordPosition="758" endWordPosition="759">as been postulated but is considered unrealistic because of the dimension of the hypothesis space. To reduce this problem, concept lattices have been proposed (Carpineto and Romano, 2005; Klein, 2008; Zhong et al., 2008). Here links represent hierarchical relations, rather than the sequential order of symbols like in word/phoneme lattices, and nodes are clusters of salient words aggregated using synonymy, similarity, or subtrees of a thesaurus. However, salient word selection and aggregation is non-obvious and furthermore it falls into word sense disambiguation, a notoriously AI-hard problem (Navigli, 2009b). In definition extraction, the variability of patterns is higher than for “traditional” applications of lattices, such as translation and speech, however not as high as in unconstrained sentences. The methodology that we propose to align patterns is based on the use of star (wildcard *) characters to facilitate sentence clustering. Each cluster of sentences is then generalized to a lattice of word classes (each class being either a frequent word or a part of speech). A key feature of our approach is its inherent ability to both identify definitions and extract hypernyms. The method is teste</context>
</contexts>
<marker>Navigli, 2009</marker>
<rawString>Roberto Navigli. 2009b. Word Sense Disambiguation: A survey. ACM Computing Surveys, 41(2):1–69.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael P Oakes</author>
</authors>
<title>Using hearst’s rules for the automatic acquisition of hyponyms for mining a pharmaceutical corpus.</title>
<date>2005</date>
<booktitle>In Proceedings of the Workshop Text Mining Research.</booktitle>
<contexts>
<context position="9297" citStr="Oakes, 2005" startWordPosition="1443" endWordPosition="1444">c.nist. gov 1319 ble2. In fact, the TREC evaluation datasets cannot be considered true definitions, but rather text fragments providing some relevant fact about a target term. For example, sentences like: “Bollywood is a Bombay-based film industry” and “700 or more films produced by India with 200 or more from Bollywood” are both “vital” answers for the question “Bollywood”, according to TREC classification, but the second sentence is not a definition. Hypernym Extraction. The literature on hypernym extraction offers a higher variability of methods, from simple lexical patterns (Hearst, 1992; Oakes, 2005) to statistical and machine learning techniques (Agirre et al., 2000; Caraballo, 1999; Dolan et al., 1993; Sanfilippo and Pozna´nski, 1992; Ritter et al., 2009). One of the highest-coverage methods is proposed by Snow et al. (2004). They first search sentences that contain two terms which are known to be in a taxonomic relation (term pairs are taken from WordNet (Miller et al., 1990)); then they parse the sentences, and automatically extract patterns from the parse trees. Finally, they train a hypernym classifer based on these features. Lexico-syntactic patterns are generated for each sentence</context>
</contexts>
<marker>Oakes, 2005</marker>
<rawString>Michael P. Oakes. 2005. Using hearst’s rules for the automatic acquisition of hyponyms for mining a pharmaceutical corpus. In Proceedings of the Workshop Text Mining Research.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Przepi´orkowski</author>
<author>Lukasz Deg´orski</author>
<author>Beata W´ojtowicz</author>
</authors>
<title>Miroslav Spousta, Vladislav Kuboˇn, Kiril Simov, Petya Osenova, and Lothar Lemnitzer.</title>
<date>2007</date>
<booktitle>In Proceedings of the Workshop on Balto-Slavonic Natural Language Processing (in ACL ’07),</booktitle>
<pages>43--50</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic.</location>
<marker>Przepi´orkowski, Deg´orski, W´ojtowicz, 2007</marker>
<rawString>Adam Przepi´orkowski, Lukasz Deg´orski, Beata W´ojtowicz, Miroslav Spousta, Vladislav Kuboˇn, Kiril Simov, Petya Osenova, and Lothar Lemnitzer. 2007. Towards the automatic extraction of definitions in slavic. In Proceedings of the Workshop on Balto-Slavonic Natural Language Processing (in ACL ’07), pages 43–50, Prague, Czech Republic. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alan Ritter</author>
<author>Stephen Soderland</author>
<author>Oren Etzioni</author>
</authors>
<title>What is this, anyway: Automatic hypernym discovery.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 AAAI Spring Symposium on Learning by Reading and Learning to Read,</booktitle>
<pages>88--93</pages>
<contexts>
<context position="9457" citStr="Ritter et al., 2009" startWordPosition="1466" endWordPosition="1469">ct about a target term. For example, sentences like: “Bollywood is a Bombay-based film industry” and “700 or more films produced by India with 200 or more from Bollywood” are both “vital” answers for the question “Bollywood”, according to TREC classification, but the second sentence is not a definition. Hypernym Extraction. The literature on hypernym extraction offers a higher variability of methods, from simple lexical patterns (Hearst, 1992; Oakes, 2005) to statistical and machine learning techniques (Agirre et al., 2000; Caraballo, 1999; Dolan et al., 1993; Sanfilippo and Pozna´nski, 1992; Ritter et al., 2009). One of the highest-coverage methods is proposed by Snow et al. (2004). They first search sentences that contain two terms which are known to be in a taxonomic relation (term pairs are taken from WordNet (Miller et al., 1990)); then they parse the sentences, and automatically extract patterns from the parse trees. Finally, they train a hypernym classifer based on these features. Lexico-syntactic patterns are generated for each sentence relating a term to its hypernym, and a dependency parser is used to represent them. 3 Word-Class Lattices 3.1 Preliminaries Notion of definition. In our work, </context>
</contexts>
<marker>Ritter, Soderland, Etzioni, 2009</marker>
<rawString>Alan Ritter, Stephen Soderland, and Oren Etzioni. 2009. What is this, anyway: Automatic hypernym discovery. In Proceedings of the 2009 AAAI Spring Symposium on Learning by Reading and Learning to Read, pages 88–93.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Horacio Saggion</author>
</authors>
<title>Identifying denitions in text collections for question answering.</title>
<date>2004</date>
<booktitle>In Proceedings of the Fourth International Conference on Language Resources and Evaluation (LREC 2004),</booktitle>
<location>Lisbon, Portugal.</location>
<contexts>
<context position="2272" citStr="Saggion, 2004" startWordPosition="347" endWordPosition="348">ch texts for definitions, this task can be automatized by means of Machine Learning (ML) and Natural Language Processing (NLP) techniques. Automatic definition extraction is useful not only in the construction of glossaries, but also in many other NLP tasks. In ontology learning, definitions are used to create and enrich concepts with textual information (Gangemi et al., 2003), and extract taxonomic and non-taxonomic relations (Snow et al., 2004; Navigli and Velardi, 2006; Navigli, 2009a). Definitions are also harvested in Question Answering to deal with “what is” questions (Cui et al., 2007; Saggion, 2004). In eLearning, they are used to help students assimilate knowledge (Westerhout and Monachesi, 2007), etc. Much of the current literature focuses on the use of lexico-syntactic patterns, inspired by Hearst’s (1992) seminal work. However, these methods suffer both from low recall and precision, as definitional sentences occur in highly variable syntactic structures, and because the most frequent definitional pattern – X is a Y – is inherently very noisy. In this paper we propose a generalized form of word lattices, called Word-Class Lattices (WCLs), as an alternative to lexico-syntactic pattern</context>
</contexts>
<marker>Saggion, 2004</marker>
<rawString>Horacio Saggion. 2004. Identifying denitions in text collections for question answering. In Proceedings of the Fourth International Conference on Language Resources and Evaluation (LREC 2004), Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antonio Sanfilippo</author>
<author>Victor Pozna´nski</author>
</authors>
<title>The acquisition of lexical knowledge from combined machine-readable dictionary sources.</title>
<date>1992</date>
<booktitle>In Proceedings of the third Conference on Applied Natural Language Processing,</booktitle>
<pages>80--87</pages>
<marker>Sanfilippo, Pozna´nski, 1992</marker>
<rawString>Antonio Sanfilippo and Victor Pozna´nski. 1992. The acquisition of lexical knowledge from combined machine-readable dictionary sources. In Proceedings of the third Conference on Applied Natural Language Processing, pages 80–87.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
</authors>
<title>Improvements in part-ofspeech tagging with an application to german.</title>
<date>1995</date>
<booktitle>In Proceedings of the ACL SIGDAT-Workshop,</booktitle>
<pages>47--50</pages>
<contexts>
<context position="11744" citStr="Schmid, 1995" startWordPosition="1837" endWordPosition="1838">ther specify the differentia of the definiendum with respect to its genus (e.g., “with free variables that are bound in the lexical environment”). Further examples of definitional sentences annotated with the above fields are shown in Table 1. For each sentence, the definiendum (that is, the word being defined) and its hypernym are marked in bold and italic, respectively. Given the lexicosyntactic nature of the definition extraction models we experiment with, training and test sentences are part-of-speech tagged with the TreeTagger system, a part-of-speech tagger available for many languages (Schmid, 1995). Word Classes and Generalized Sentences. We now introduce our notion of word class, on which our learning model is based. Let T be the set of training sentences, manually bracketed with the DF, VF, GF and RF fields. We first determine the set F of words in T whose frequency is above a threshold θ (e.g., the, a, is, of, refer, etc.). In our training sentences, we replace the term being defined with (TARGET), thus this frequent token is also included in F. We use the set of frequent words F to generalize words to “word classes”. We define a word class as either a word itself or its part of spee</context>
</contexts>
<marker>Schmid, 1995</marker>
<rawString>Helmut Schmid. 1995. Improvements in part-ofspeech tagging with an application to german. In Proceedings of the ACL SIGDAT-Workshop, pages 47–50.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Josh Schroeder</author>
<author>Trevor Cohn</author>
<author>Philipp Koehn</author>
</authors>
<title>Word lattices for multi-source translation.</title>
<date>2009</date>
<booktitle>In Proceedings of the European Chapter of the Association for Computation Linguistics (EACL</booktitle>
<pages>719--727</pages>
<location>Athens, Greece.</location>
<contexts>
<context position="3598" citStr="Schroeder et al., 2009" startWordPosition="549" endWordPosition="552">tomata (NFA). The lattice structure has the purpose of preserving the salient differences among distinct sequences, while eliminating redundant information. In computational linguistics, lattices have been used to model in a compact way many sequences of symbols, each representing an alternative hypothesis. Lattice-based methods differ in the types of nodes (words, phonemes, concepts), the interpretation of links (representing either a sequential or hierarchical ordering between nodes), their means of creation, and the scoring method used to extract the best consensus output from the lattice (Schroeder et al., 2009). In speech processing, phoneme or word lattices (Campbell et al., 2007; Mathias and Byrne, 2006; Collins et al., 2004) are used as an interface between speech recognition and understanding. Lat1318 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1318–1327, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics tices are adopted also in Chinese word segmentation (Jiang et al., 2008), decompounding in German (Dyer, 2009), and to represent classes of translation models in machine translation (Dyer et al., 2008; Schroeder </context>
</contexts>
<marker>Schroeder, Cohn, Koehn, 2009</marker>
<rawString>Josh Schroeder, Trevor Cohn, and Philipp Koehn. 2009. Word lattices for multi-source translation. In Proceedings of the European Chapter of the Association for Computation Linguistics (EACL 2009), pages 719–727, Athens, Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rion Snow</author>
<author>Dan Jurafsky</author>
<author>Andrew Y Ng</author>
</authors>
<title>Learning syntactic patterns for automatic hypernym discovery.</title>
<date>2004</date>
<booktitle>In Proceedings of Advances in Neural Information Processing Systems,</booktitle>
<pages>1297--1304</pages>
<contexts>
<context position="2107" citStr="Snow et al., 2004" startWordPosition="319" endWordPosition="322">ntences in which a term occurs are typically definitional, that is they provide a formal explanation for the term of interest. While it is not feasible to manually search texts for definitions, this task can be automatized by means of Machine Learning (ML) and Natural Language Processing (NLP) techniques. Automatic definition extraction is useful not only in the construction of glossaries, but also in many other NLP tasks. In ontology learning, definitions are used to create and enrich concepts with textual information (Gangemi et al., 2003), and extract taxonomic and non-taxonomic relations (Snow et al., 2004; Navigli and Velardi, 2006; Navigli, 2009a). Definitions are also harvested in Question Answering to deal with “what is” questions (Cui et al., 2007; Saggion, 2004). In eLearning, they are used to help students assimilate knowledge (Westerhout and Monachesi, 2007), etc. Much of the current literature focuses on the use of lexico-syntactic patterns, inspired by Hearst’s (1992) seminal work. However, these methods suffer both from low recall and precision, as definitional sentences occur in highly variable syntactic structures, and because the most frequent definitional pattern – X is a Y – is </context>
<context position="9528" citStr="Snow et al. (2004)" startWordPosition="1478" endWordPosition="1481">ay-based film industry” and “700 or more films produced by India with 200 or more from Bollywood” are both “vital” answers for the question “Bollywood”, according to TREC classification, but the second sentence is not a definition. Hypernym Extraction. The literature on hypernym extraction offers a higher variability of methods, from simple lexical patterns (Hearst, 1992; Oakes, 2005) to statistical and machine learning techniques (Agirre et al., 2000; Caraballo, 1999; Dolan et al., 1993; Sanfilippo and Pozna´nski, 1992; Ritter et al., 2009). One of the highest-coverage methods is proposed by Snow et al. (2004). They first search sentences that contain two terms which are known to be in a taxonomic relation (term pairs are taken from WordNet (Miller et al., 1990)); then they parse the sentences, and automatically extract patterns from the parse trees. Finally, they train a hypernym classifer based on these features. Lexico-syntactic patterns are generated for each sentence relating a term to its hypernym, and a dependency parser is used to represent them. 3 Word-Class Lattices 3.1 Preliminaries Notion of definition. In our work, we rely on a formal notion of textual definition. Specifically, given a</context>
<context position="26468" citStr="Snow et al. (2004)" startWordPosition="4424" endWordPosition="4427">clude (hypernym in italic): “such NP as {NP ,} {(or |and)} NP”, “NP {, NP} {,} or other NP”, “NP {,} including { NP ,} {or |and} NP”, “NP {,} especially { NP ,} {or |and} NP”, and variants thereof. However, it should be noted that hypernym extraction methods in the literature do not extract hypernyms from definitional sentences, like we do, but rather from specific patterns like “X such as Y”. Therefore a direct comparison with these methods is not possible. Nonetheless, we decided to implement Hearst’s patterns for the sake of completeness. We could not replicate the more refined approach by Snow et al. (2004) because it requires the annotation of a possibly very large dataset of sentence fragments. In any case Snow et al. (2004) reported the following performance figures on a corpus of dimension and complexity comparable with ukWaC: the recall-precision graph indicates precision 85% at recall 10% and precision 25% at recall of 30% for the hypernym classifier. A variant of the classifier that includes evidence from coordinate terms (terms with a common ancestor in a taxonomy) obtains an increased precision of 35% at recall 30%. We see no reasons why these figures should vary dramatically on the ukW</context>
</contexts>
<marker>Snow, Jurafsky, Ng, 2004</marker>
<rawString>Rion Snow, Dan Jurafsky, and Andrew Y. Ng. 2004. Learning syntactic patterns for automatic hypernym discovery. In Proceedings of Advances in Neural Information Processing Systems, pages 1297–1304.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Angelika Storrer</author>
<author>Sandra Wellinghoff</author>
</authors>
<title>Automated detection and annotation of term definitions in german text corpora.</title>
<date>2006</date>
<booktitle>In Proceedings of the Fifth International Conference on Language Resources and Evaluation (LREC</booktitle>
<location>Genova, Italy.</location>
<contexts>
<context position="6264" citStr="Storrer and Wellinghoff, 2006" startWordPosition="969" endWordPosition="972"> in order to demonstrate the independence of the method from the annotated dataset. WCLs are shown to generalize over lexico-syntactic patterns, and outperform well-known approaches to definition and hypernym extraction. The paper is organized as follows: Section 2 discusses related work, WCLs are introduced in Section 3 and illustrated by means of an example in Section 4, experiments are presented in Section 5. We conclude the paper in Section 6. 2 Related Work Definition Extraction. A great deal of work is concerned with definition extraction in several languages (Klavans and Muresan, 2001; Storrer and Wellinghoff, 2006; Gaudio and Branco, 2007; Iftene et al., 2007; Westerhout and Monachesi, 2007; Przepi´orkowski et al., 2007; Deg´orski et al., 2008). The majority of these approaches use symbolic methods that depend on lexico-syntactic patterns or features, which are manually crafted or semi-automatically learned (Zhang and Jiang, 2009; Hovy et al., 2003; Fahmi and Bouma, 2006; Westerhout, 2009). Patterns are either very simple sequences of words (e.g. “refers to”, “is defined as”, “is a”) or more complex sequences of words, parts of speech and chunks. A fully automated method is instead proposed by Borg et </context>
<context position="10348" citStr="Storrer and Wellinghoff, 2006" startWordPosition="1613" endWordPosition="1616">nd automatically extract patterns from the parse trees. Finally, they train a hypernym classifer based on these features. Lexico-syntactic patterns are generated for each sentence relating a term to its hypernym, and a dependency parser is used to represent them. 3 Word-Class Lattices 3.1 Preliminaries Notion of definition. In our work, we rely on a formal notion of textual definition. Specifically, given a definition, e.g.: “In computer science, a closure is a first-class function with free variables that are bound in the lexical environment”, we assume that it contains the following fields (Storrer and Wellinghoff, 2006): • The DEFINIENDUM field (DF): this part of the definition includes the definiendum (that is, the word being defined) and its modifiers (e.g., “In computer science, a closure”); • The DEFINITOR field (VF): it includes the verb phrase used to introduce the definition (e.g., “is”); 2In the paper, a 55% recall and 34% precision is achieved with the best experiment on TREC-13 data. Furthermore, the classifier of Cui et al. (2007) is based on soft patterns but also on a bag-of-word relevance heuristic. However, the relative influence of the two methods on the final performance is not discussed. • </context>
</contexts>
<marker>Storrer, Wellinghoff, 2006</marker>
<rawString>Angelika Storrer and Sandra Wellinghoff. 2006. Automated detection and annotation of term definitions in german text corpora. In Proceedings of the Fifth International Conference on Language Resources and Evaluation (LREC 2006), Genova, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paola Velardi</author>
<author>Roberto Navigli</author>
<author>Pierluigi D’Amadio</author>
</authors>
<title>Mining the Web to create specialized glossaries.</title>
<date>2008</date>
<journal>IEEE Intelligent Systems,</journal>
<volume>23</volume>
<issue>5</issue>
<marker>Velardi, Navigli, D’Amadio, 2008</marker>
<rawString>Paola Velardi, Roberto Navigli, and Pierluigi D’Amadio. 2008. Mining the Web to create specialized glossaries. IEEE Intelligent Systems, 23(5):18–25.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eline Westerhout</author>
<author>Paola Monachesi</author>
</authors>
<title>Extraction of dutch definitory contexts for eLearning purposes.</title>
<date>2007</date>
<booktitle>In Proceedings of CLIN.</booktitle>
<contexts>
<context position="2372" citStr="Westerhout and Monachesi, 2007" startWordPosition="360" endWordPosition="363"> (ML) and Natural Language Processing (NLP) techniques. Automatic definition extraction is useful not only in the construction of glossaries, but also in many other NLP tasks. In ontology learning, definitions are used to create and enrich concepts with textual information (Gangemi et al., 2003), and extract taxonomic and non-taxonomic relations (Snow et al., 2004; Navigli and Velardi, 2006; Navigli, 2009a). Definitions are also harvested in Question Answering to deal with “what is” questions (Cui et al., 2007; Saggion, 2004). In eLearning, they are used to help students assimilate knowledge (Westerhout and Monachesi, 2007), etc. Much of the current literature focuses on the use of lexico-syntactic patterns, inspired by Hearst’s (1992) seminal work. However, these methods suffer both from low recall and precision, as definitional sentences occur in highly variable syntactic structures, and because the most frequent definitional pattern – X is a Y – is inherently very noisy. In this paper we propose a generalized form of word lattices, called Word-Class Lattices (WCLs), as an alternative to lexico-syntactic pattern learning. A lattice is a directed acyclic graph (DAG), a subclass of non-deterministic finite state</context>
<context position="6342" citStr="Westerhout and Monachesi, 2007" startWordPosition="981" endWordPosition="984">taset. WCLs are shown to generalize over lexico-syntactic patterns, and outperform well-known approaches to definition and hypernym extraction. The paper is organized as follows: Section 2 discusses related work, WCLs are introduced in Section 3 and illustrated by means of an example in Section 4, experiments are presented in Section 5. We conclude the paper in Section 6. 2 Related Work Definition Extraction. A great deal of work is concerned with definition extraction in several languages (Klavans and Muresan, 2001; Storrer and Wellinghoff, 2006; Gaudio and Branco, 2007; Iftene et al., 2007; Westerhout and Monachesi, 2007; Przepi´orkowski et al., 2007; Deg´orski et al., 2008). The majority of these approaches use symbolic methods that depend on lexico-syntactic patterns or features, which are manually crafted or semi-automatically learned (Zhang and Jiang, 2009; Hovy et al., 2003; Fahmi and Bouma, 2006; Westerhout, 2009). Patterns are either very simple sequences of words (e.g. “refers to”, “is defined as”, “is a”) or more complex sequences of words, parts of speech and chunks. A fully automated method is instead proposed by Borg et al. (2009): they use genetic programming to learn simple features to distingui</context>
</contexts>
<marker>Westerhout, Monachesi, 2007</marker>
<rawString>Eline Westerhout and Paola Monachesi. 2007. Extraction of dutch definitory contexts for eLearning purposes. In Proceedings of CLIN.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eline Westerhout</author>
</authors>
<title>Definition extraction using linguistic and structural features.</title>
<date>2009</date>
<booktitle>In Proceedings of the RANLP 2009 Workshop on Definition Extraction,</booktitle>
<pages>61--67</pages>
<contexts>
<context position="6647" citStr="Westerhout, 2009" startWordPosition="1027" endWordPosition="1028">sented in Section 5. We conclude the paper in Section 6. 2 Related Work Definition Extraction. A great deal of work is concerned with definition extraction in several languages (Klavans and Muresan, 2001; Storrer and Wellinghoff, 2006; Gaudio and Branco, 2007; Iftene et al., 2007; Westerhout and Monachesi, 2007; Przepi´orkowski et al., 2007; Deg´orski et al., 2008). The majority of these approaches use symbolic methods that depend on lexico-syntactic patterns or features, which are manually crafted or semi-automatically learned (Zhang and Jiang, 2009; Hovy et al., 2003; Fahmi and Bouma, 2006; Westerhout, 2009). Patterns are either very simple sequences of words (e.g. “refers to”, “is defined as”, “is a”) or more complex sequences of words, parts of speech and chunks. A fully automated method is instead proposed by Borg et al. (2009): they use genetic programming to learn simple features to distinguish between definitions and non-definitions, and then they apply a genetic algorithm to learn individual weights of features. However, rules are learned for only one category of patterns, namely “is” patterns. As we already remarked, most methods suffer from both low recall and precision, because definiti</context>
</contexts>
<marker>Westerhout, 2009</marker>
<rawString>Eline Westerhout. 2009. Definition extraction using linguistic and structural features. In Proceedings of the RANLP 2009 Workshop on Definition Extraction, pages 61–67.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chunxia Zhang</author>
<author>Peng Jiang</author>
</authors>
<title>Automatic extraction of definitions.</title>
<date>2009</date>
<booktitle>In Proceedings of 2nd IEEE International Conference on Computer Science and Information Technology,</booktitle>
<pages>364--368</pages>
<contexts>
<context position="6586" citStr="Zhang and Jiang, 2009" startWordPosition="1015" endWordPosition="1018">ustrated by means of an example in Section 4, experiments are presented in Section 5. We conclude the paper in Section 6. 2 Related Work Definition Extraction. A great deal of work is concerned with definition extraction in several languages (Klavans and Muresan, 2001; Storrer and Wellinghoff, 2006; Gaudio and Branco, 2007; Iftene et al., 2007; Westerhout and Monachesi, 2007; Przepi´orkowski et al., 2007; Deg´orski et al., 2008). The majority of these approaches use symbolic methods that depend on lexico-syntactic patterns or features, which are manually crafted or semi-automatically learned (Zhang and Jiang, 2009; Hovy et al., 2003; Fahmi and Bouma, 2006; Westerhout, 2009). Patterns are either very simple sequences of words (e.g. “refers to”, “is defined as”, “is a”) or more complex sequences of words, parts of speech and chunks. A fully automated method is instead proposed by Borg et al. (2009): they use genetic programming to learn simple features to distinguish between definitions and non-definitions, and then they apply a genetic algorithm to learn individual weights of features. However, rules are learned for only one category of patterns, namely “is” patterns. As we already remarked, most method</context>
</contexts>
<marker>Zhang, Jiang, 2009</marker>
<rawString>Chunxia Zhang and Peng Jiang. 2009. Automatic extraction of definitions. In Proceedings of 2nd IEEE International Conference on Computer Science and Information Technology, pages 364–368.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhao-man Zhong</author>
<author>Zong-tian Liu</author>
<author>Yan Guan</author>
</authors>
<title>Precise information extraction from text based on two-level concept lattice.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 International Symposiums on Information Processing (ISIP ’08),</booktitle>
<pages>275--279</pages>
<location>Washington, DC, USA.</location>
<contexts>
<context position="4571" citStr="Zhong et al., 2008" startWordPosition="697" endWordPosition="700">ion for Computational Linguistics tices are adopted also in Chinese word segmentation (Jiang et al., 2008), decompounding in German (Dyer, 2009), and to represent classes of translation models in machine translation (Dyer et al., 2008; Schroeder et al., 2009). In more complex text processing tasks, such as information retrieval, information extraction and summarization, the use of word lattices has been postulated but is considered unrealistic because of the dimension of the hypothesis space. To reduce this problem, concept lattices have been proposed (Carpineto and Romano, 2005; Klein, 2008; Zhong et al., 2008). Here links represent hierarchical relations, rather than the sequential order of symbols like in word/phoneme lattices, and nodes are clusters of salient words aggregated using synonymy, similarity, or subtrees of a thesaurus. However, salient word selection and aggregation is non-obvious and furthermore it falls into word sense disambiguation, a notoriously AI-hard problem (Navigli, 2009b). In definition extraction, the variability of patterns is higher than for “traditional” applications of lattices, such as translation and speech, however not as high as in unconstrained sentences. The met</context>
</contexts>
<marker>Zhong, Liu, Guan, 2008</marker>
<rawString>Zhao-man Zhong, Zong-tian Liu, and Yan Guan. 2008. Precise information extraction from text based on two-level concept lattice. In Proceedings of the 2008 International Symposiums on Information Processing (ISIP ’08), pages 275–279, Washington, DC, USA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>