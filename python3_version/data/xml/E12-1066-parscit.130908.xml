<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001210">
<title confidence="0.746197">
Smart Paradigms and the Predictability and Complexity of Inflectional
Morphology
</title>
<author confidence="0.978009">
Gr´egoire D´etrez and Aarne Ranta
</author>
<affiliation confidence="0.999557">
Department of Computer Science and Engineering
Chalmers University of Technology and University of Gothenburg
</affiliation>
<sectionHeader confidence="0.98016" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999498827586207">
Morphological lexica are often imple-
mented on top of morphological paradigms,
corresponding to different ways of building
the full inflection table of a word. Compu-
tationally precise lexica may use hundreds
of paradigms, and it can be hard for a lex-
icographer to choose among them. To au-
tomate this task, this paper introduces the
notion of a smart paradigm. It is a meta-
paradigm, which inspects the base form and
tries to infer which low-level paradigm ap-
plies. If the result is uncertain, more forms
are given for discrimination. The number
of forms needed in average is a measure
of predictability of an inflection system.
The overall complexity of the system also
has to take into account the code size of
the paradigms definition itself. This pa-
per evaluates the smart paradigms imple-
mented in the open-source GF Resource
Grammar Library. Predictability and com-
plexity are estimated for four different lan-
guages: English, French, Swedish, and
Finnish. The main result is that predictabil-
ity does not decrease when the complex-
ity of morphology grows, which means that
smart paradigms provide an efficient tool
for the manual construction and/or auto-
matically bootstrapping of lexica.
</bodyText>
<sectionHeader confidence="0.998876" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999769933333333">
Paradigms are a cornerstone of grammars in the
European tradition. A classical Latin grammar
has five paradigms for nouns (“declensions”) and
four for verbs (“conjugations”). The modern ref-
erence on French verbs, Bescherelle (Bescherelle,
1997), has 88 paradigms for verbs. Swedish
grammars traditionally have, like Latin, five
paradigms for nouns and four for verbs, but a
modern computational account (Hellberg, 1978),
aiming for more precision, has 235 paradigms for
Swedish.
Mathematically, a paradigm is a function that
produces inflection tables. Its argument is a word
string (either a dictionary form or a stem), and
its value is an n-tuple of strings (the word forms):
</bodyText>
<equation confidence="0.946455">
P : String —* Stringn
</equation>
<bodyText confidence="0.999737058823529">
We assume that the exponent n is determined by
the language and the part of speech. For instance,
English verbs might have n = 5 (for sing, sings,
sang, sung, singing), whereas for French verbs in
Bescherelle, n = 51. We assume the tuples to
be ordered, so that for instance the French sec-
ond person singular present subjunctive is always
found at position 17. In this way, word-paradigm
pairs can be easily converted to morphogical lex-
ica and to transducers that map form descriptions
to surface forms and back. A properly designed
set of paradigms permits a compact representation
of a lexicon and a user-friendly way to extend it.
Different paradigm systems may have different
numbers of paradigms. There are two reasons for
this. One is that traditional paradigms often in fact
require more arguments than one:
</bodyText>
<equation confidence="0.959382">
P : Strings` —* Stringn
</equation>
<bodyText confidence="0.999816090909091">
Here m &lt; n and the set of arguments is a subset
of the set of values. Thus the so-called fourth verb
conjugation in Swedish actually needs three forms
to work properly, for instance sitta, satt, suttit for
the equivalent of sit, sat, sat in English. In Hell-
berg (1978), as in the French Bescherelle, each
paradigm is defined to take exactly one argument,
and hence each vowel alternation pattern must be
a different paradigm.
The other factor that affects the number of
paradigms is the nature of the string operations
</bodyText>
<page confidence="0.985097">
645
</page>
<note confidence="0.9766105">
Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 645–653,
Avignon, France, April 23 - 27 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.999878580645161">
allowed in the function P. In Hellberg (1978),
noun paradigms only permit the concatenation of
suffixes to a stem. Thus the paradigms are iden-
tified with suffix sets. For instance, the inflection
patterns bil–bilar (“car–cars”) and nyckel–nycklar
(“key–keys”) are traditionally both treated as in-
stances of the second declension, with the plural
ending ar and the contraction of the unstressed
e in the case of nyckel. But in Hellberg, the
word nyckel has nyck as its “technical stem”, to
which the paradigm numbered 231 adds the sin-
gular ending el and the plural ending lar.
The notion of paradigm used in this paper al-
lows multiple arguments and powerful string op-
erations. In this way, we will be able to reduce
the number of paradigms drastically: in fact, each
lexical category (noun, adjective, verb), will have
just one paradigm but with a variable number of
arguments. Paradigms that follow this design will
be called smart paradigms and are introduced
in Section 2. Section 3 defines the notions of
predictability and complexity of smart paradigm
systems. Section 4 estimates these figures for four
different languages of increasing richness in mor-
phology: English, Swedish, French, and Finnish.
We also evaluate the smart paradigms as a data
compression method. Section 5 explores some
uses of smart paradigms in lexicon building. Sec-
tion 6 compares smart paradigms with related
techniques such as morphology guessers and ex-
traction tools. Section 7 concludes.
</bodyText>
<sectionHeader confidence="0.853614" genericHeader="method">
2 Smart paradigms
</sectionHeader>
<bodyText confidence="0.999796133333333">
In this paper, we will assume a notion of paradigm
that allows multiple arguments and arbitrary com-
putable string operations. As argued in (Ka-
plan and Kay, 1994) and amply demonstrated in
(Beesley and Karttunen, 2003), no generality is
lost if the string operators are restricted to ones
computable by finite-state transducers. Thus the
examples of paradigms that we will show (only
informally), can be converted to matching and re-
placements with regular expressions.
For example, a majority of French verbs can
be defined by the following paradigm, which
analyzes a variable-size suffix of the infinitive
form and dispatches to the Bescherelle paradigms
(identified by a number and an example verb):
</bodyText>
<equation confidence="0.77502">
mkV : String —* String51
mkV(s) _
</equation>
<listItem confidence="0.9997271">
• conj19finir(s), if s ends ir
• conj53rendre(s), if s ends re
• conj14assi´eger(s), if s ends ´eger
• conj11jeter(s), if s ends eler or
eter
• conj10c´eder(s), if s ends ´eder
• conj07placer(s), if s ends cer
• conj08manger(s), if s ends ger
• conj16payer(s), if s ends yer
• conj06parler(s), if s ends er
</listItem>
<bodyText confidence="0.99960505">
Notice that the cases must be applied in the given
order; for instance, the last case applies only to
those verbs ending with er that are not matched
by the earlier cases.
Also notice that the above paradigm is just
like the more traditional ones, in the sense that
we cannot be sure if it really applies to a given
verb. For instance, the verb partir ends with ir
and would hence receive the same inflection as
finir; however, its real conjugation is number 26
in Bescherelle. That mkV uses 19 rather than
number 26 has a good reason: a vast majority of
ir verbs is inflected in this conjugation, and it is
also the productive one, to which new ir verbs are
added.
Even though there is no mathematical differ-
ence between the mkV paradigm and the tradi-
tional paradigms like those in Bescherelle, there
is a reason to call mkV a smart paradigm. This
name implies two things. First, a smart paradigm
implements some “artificial intelligence” to pick
the underlying “stupid” paradigm. Second, a
smart paradigm uses heuristics (informed guess-
ing) if string matching doesn’t decide the matter;
the guess is informed by statistics of the distribu-
tions of different inflection classes.
One could thus say that smart paradigms are
“second-order” or “meta-paradigms”, compared
to more traditional ones. They implement a
lot of linguistic knowledge and intelligence, and
thereby enable tasks such as lexicon building to
be performed with less expertise than before. For
instance, instead of “07” for foncer and “06”
for marcher, the lexicographer can simply write
“mkV” for all verbs instead of choosing from 88
numbers.
In fact, just “V”, indicating that the word is
a verb, will be enough, since the name of the
paradigm depends only on the part of speech.
This follows the model of many dictionaries and
</bodyText>
<page confidence="0.998546">
646
</page>
<bodyText confidence="0.999767333333333">
methods of language teaching, where character-
istic forms are used instead of paradigm identi-
fiers. For instance, another variant of mkV could
use as its second argument the first person plural
present indicative to decide whether an ir verb is
in conjugation 19 or in 26:
</bodyText>
<equation confidence="0.9224125">
mkV : String —* String51
mkV(s, t) =
</equation>
<listItem confidence="0.998013285714286">
• conj26partir(s), if for some x, s =
x+ir and t = x+ons
• conj19finir(s), if s ends with ir
• (all the other cases that can be rec-
ognized by this extra form)
• mkV(s) otherwise (fall-back to the
one-argument paradigm)
</listItem>
<bodyText confidence="0.999164">
In this way, a series of smart paradigms is built
for each part of speech, with more and more ar-
guments. The trick is to investigate which new
forms have the best discriminating power. For
ease of use, the paradigms should be displayed to
the user in an easy to understand format, e.g. as a
table specifying the possible argument lists:
verb
verb
verb
noun
noun
noun
Notice that, for French nouns, the gender is listed
as one of the pieces of information needed for
lexicon building. In many cases, it can be in-
ferred from the dictionary form just like the in-
flection; for instance, that most nouns ending e
are feminine. A gender argument in the smart
noun paradigm makes it possible to override this
default behaviour.
</bodyText>
<subsectionHeader confidence="0.988814">
2.1 Paradigms in GF
</subsectionHeader>
<bodyText confidence="0.9999965">
Smart paradigms as used in this paper have been
implemented in the GF programming language
(Grammatical Framework, (Ranta, 2011)). GF is
a functional programming lnguage enriched with
regular expressions. For instance, the following
function implements a part of the one-argument
French verb paradigm shown above. It uses a case
expression to pattern match with the argument s;
the pattern _ matches anything, while + divides a
string to two pieces, and  |expresses alternation.
The functions conj19finir etc. are defined
elsewhere in the library. Function application is
expressed without parentheses, by the juxtaposi-
tion of the function and the argument.
</bodyText>
<equation confidence="0.965854285714286">
mkV : Str -&gt; V
mkV s = case s of {
_ + &amp;quot;ir&amp;quot; -&gt; conj19finir s ;
_ + (&amp;quot;eler&amp;quot;|&amp;quot;eter&amp;quot;)
-&gt; conj11jeter s ;
_ + &amp;quot;er&amp;quot; -&gt; conj06parler s ;
}
</equation>
<bodyText confidence="0.999757705882353">
The GF Resource Grammar Library1 has
comprehensive smart paradigms for 18 lan-
guages: Amharic, Catalan, Danish, Dutch, En-
glish, Finnish, French, German, Hindi, Italian,
Nepalese, Norwegian, Romanian, Russian, Span-
ish, Swedish, Turkish, and Urdu. A few other lan-
guages have complete sets of ”traditional” inflec-
tion paradigms but no smart paradigms.
Six languages in the library have comprehen-
sive morphological dictionaries: Bulgarian (53k
lemmas), English (42k), Finnish (42k), French
(92k), Swedish (43k), and Turkish (23k). They
have been extracted from other high-quality re-
sources via conversions to GF using the paradigm
systems. In Section 4, four of them will be used
for estimating the strength of the smart paradigms,
that is, the predictability of each language.
</bodyText>
<sectionHeader confidence="0.715081" genericHeader="method">
3 Cost, predictability, and complexity
</sectionHeader>
<bodyText confidence="0.9970376">
Given a language L, a lexical category C, and a set
P of smart paradigms for C, the predictability of
the morphology of C in L by P depends inversely
on the average number of arguments needed to
generate the correct inflection table for a word.
The lower the number, the more predictable the
system.
Predictability can be estimated from a lexicon
that contains such a set of tables. Formally, a
smart paradigm is a family Pm of functions
</bodyText>
<equation confidence="0.583828">
Pm : Stringm —* Stringn
</equation>
<bodyText confidence="0.970392666666667">
where m ranges over some set of integers from 1
to n, but need not contain all those integers. A
lexicon L is a finite set of inflection tables,
</bodyText>
<equation confidence="0.78298">
L = {wi : Stringn i = 1, ... , ML}
</equation>
<bodyText confidence="0.688431375">
1 Source code and documentation in http://www.
grammaticalframework.org/lib.
parler
parler, parlons
parler, parlons, parlera, parla, parl´e
chien
chien, masculine
chien, chiens, masculine
</bodyText>
<page confidence="0.953427">
647
</page>
<bodyText confidence="0.999618285714286">
As the n is fixed, this is a lexicon specialized to
one part of speech. A word is an element of the
lexicon, that is, an inflection table of size n.
An application of a smart paradigm Pm to a
word w E L is an inflection table resulting from
applying Pm to the appropriate subset Um(w) of
the inflection table w,
</bodyText>
<equation confidence="0.991494">
Pm[w] = Pm(Um(w)) : Stringn
</equation>
<bodyText confidence="0.999837333333333">
Thus we assume that all arguments are existing
word forms (rather than e.g. stems), or features
such as the gender.
</bodyText>
<equation confidence="0.920843">
An application is correct if
Pm[w] = w
</equation>
<bodyText confidence="0.999969">
The cost of a word w is the minimum number of
arguments needed to make the application correct:
</bodyText>
<equation confidence="0.9856425">
cost(w) = argmin
m
</equation>
<bodyText confidence="0.9996216">
For practical applications, it is useful to require
Pm to be monotonic, in the sense that increasing
m preserves correctness.
The cost of a lexicon L is the average cost for
its words,
</bodyText>
<equation confidence="0.970467">
cost(L) =
</equation>
<bodyText confidence="0.9997085">
where ML is the number of words in the lexicon,
as defined above.
The predictability of a lexicon could be de-
fined as a quantity inversely dependent on its cost.
For instance, an information-theoretic measure
could be defined
</bodyText>
<equation confidence="0.998499">
1
predict(L) = 1 + log cost(L)
</equation>
<bodyText confidence="0.98611448">
with the intuition that each added argument cor-
responds to a choice in a decision tree. However,
we will not use this measure in this paper, but just
the concrete cost.
The complexity of a paradigm system is de-
fined as the size of its code in a given coding
system, following the idea of Kolmogorov com-
plexity (Solomonoff, 1964). The notion assumes
a coding system, which we fix to be GF source
code. As the results are relative to the coding
system, they are only usable for comparing def-
initions in the same system. However, using GF
source code size rather than e.g. a finite automa-
ton size gives in our view a better approximation
of the “cognitive load” of the paradigm system,
its “learnability”. As a functional programming
language, GF permits abstractions comparable to
those available for human language learners, who
don’t need to learn the repetitive details of a finite
automaton.
We define the code complexity as the size of
the abstract syntax tree of the source code. This
size is given as the number of nodes in the syntax
tree; for instance,
n
</bodyText>
<listItem confidence="0.993636">
• size(f(x1, ... , xn)) = 1 + size(xi)
i=1
• size(s) = 1, for a string literal s
</listItem>
<bodyText confidence="0.995521307692308">
Using the abstract syntax size makes it possible
to ignore programmer-specific variation such as
identifier size. Measurements of the GF Resource
Grammar Library show that code size measured
in this way is in average 20% of the size of source
files in bytes. Thus a source file of 1 kB has the
code complexity around 200 on the average.
Notice that code complexity is defined in a way
that makes it into a straightforward generaliza-
tion of the cost of a word as expressed in terms
of paradigm applications in GF source code. The
source code complexity of a paradigm application
is
</bodyText>
<equation confidence="0.979271">
size(Pm[w]) = 1 + m
</equation>
<bodyText confidence="0.99979675">
Thus the complexity for a word w is its cost plus
one; the addition of one comes from the applica-
tion node for the function Pm and corresponds to
knowing the part of speech of the word.
</bodyText>
<sectionHeader confidence="0.997461" genericHeader="method">
4 Experimental results
</sectionHeader>
<bodyText confidence="0.999731272727273">
We conducted experiments in four languages (En-
glish, Swedish, French and Finnish2), presented
here in order of morphological richness. We used
trusted full form lexica (i.e. lexica giving the com-
plete inflection table of every word) to compute
the predictability, as defined above, in terms of
the smart paradigms in GF Resource Grammar Li-
brary.
We used a simple algorithm for computing the
cost c of a lexicon L with a set Pm of smart
paradigms:
</bodyText>
<footnote confidence="0.956536">
2This choice correspond to the set of language for which
both comprehensive smart paradigms and morphological
dictionaries were present in GF with the exception of Turk-
ish, which was left out because of time constraints.
</footnote>
<equation confidence="0.9170046">
(Pm[w] = w)
ML
cost(wi)
i=1
ML
</equation>
<page confidence="0.975544">
648
</page>
<listItem confidence="0.882245714285714">
• set c := 0
• for each word wi in L,
– for each m in growing order for which
P,,t is defined:
if P,,,,[w] = w, then c := c+m, else try
with next m
• return c
</listItem>
<bodyText confidence="0.999857965517241">
The average cost is c divided by the size of L.
The procedure presupposes that it is always
possible to get the correct inflection table. For
this to be true, the smart paradigms must have a
“worst case scenario” version that is able to gen-
erate all forms. In practice, this was not always
the case but we checked that the number of prob-
lematic words is so small that it wouldn’t be sta-
tistically significant. A typical problem word was
the equivalent of the verb be in each language.
Another source of deviation is that a lexicon
may have inflection tables with size deviating
from the number n that normally defines a lex-
ical category. Some words may be “defective”,
i.e. lack some forms (e.g. the singular form
in “plurale tantum” words), whereas some words
may have several variants for a given form (e.g.
learned and learnt in English). We made no ef-
fort to predict defective words, but just ignored
them. With variant forms, we treated a prediction
as correct if it matched any of the variants.
The above algorithm can also be used for help-
ing to select the optimal sets of characteristic
forms; we used it in this way to select the first
form of Swedish verbs and the second form of
Finnish nouns.
The results are collected in Table 1. The sec-
tions below give more details of the experiment in
each language.
</bodyText>
<subsectionHeader confidence="0.973512">
4.1 English
</subsectionHeader>
<bodyText confidence="0.9995805">
As gold standard, we used the electronic version
of the Oxford Advanced Learner’s Dictionary of
Current English3 which contains about 40,000
root forms (about 70,000 word forms).
Nouns. We considered English nouns as hav-
ing only two forms (singular and plural), exclud-
ing the genitive forms which can be considered to
be clitics and are completely predictable. About
</bodyText>
<footnote confidence="0.8575065">
3available in electronic form at http://www.eecs.
qmul.ac.uk/˜mpurver/software.html
</footnote>
<bodyText confidence="0.999974923076923">
one third of the nouns of the lexicon were not in-
cluded in the experiment because one of the form
was missing. The vast majority of the remaining
15,000 nouns are very regular, with predictable
deviations such as kiss - kisses and fly -flies which
can be easily predicted by the smart paradigm.
With the average cost of 1.05, this was the most
predictable lexicon in our experiment.
Verbs. Verbs are the most interesting category
in English because they present the richest mor-
phology. Indeed, as shown by Table 1, the cost
for English verbs, 1.21, is similar to what we got
for morphologically richer languages.
</bodyText>
<subsectionHeader confidence="0.973571">
4.2 Swedish
</subsectionHeader>
<bodyText confidence="0.999810041666667">
As gold standard, we used the SALDO lexicon
(Borin et al., 2008).
Nouns. The noun inflection tables had 8
forms (singular/plural indefinite/definite nomina-
tive/genitive) plus a gender (uter/neuter). Swedish
nouns are intrinsically very unpredictable, and
there are many examples of homonyms falling un-
der different paradigms (e.g. val - val “choice” vs.
val -valar “whale”). The cost 1.70 is the highest
of all the lexica considered. Of course, there may
be room for improving the smart paradigm.
Verbs. The verbs had 20 forms, which in-
cluded past participles. We ran two experiments,
by choosing either the infinitive or the present in-
dicative as the base form. In traditional Swedish
grammar, the base form of the verb is considered
to be the infinitive, e.g. spela, leka (“play” in
two different senses). But this form doesn’t dis-
tinguish between the “first” and the “second con-
jugation”. However, the present indicative, here
spelar, leker, does. Using it gives a predictive
power 1.13 as opposed to 1.22 with the infinitive.
Some modern dictionaries such as Lexin4 there-
fore use the present indicative as the base form.
</bodyText>
<subsectionHeader confidence="0.998614">
4.3 French
</subsectionHeader>
<bodyText confidence="0.999960333333333">
For French, we used the Morphalou morpholog-
ical lexicon (Romary et al., 2004). As stated in
the documentation5 the current version of the lex-
icon (version 2.0) is not complete, and in par-
ticular, many entries are missing some or all in-
flected forms. So for those experiments we only
</bodyText>
<footnote confidence="0.999156">
4http://lexin.nada.kth.se/lexin/
5http://www.cnrtl.fr/lexiques/
morphalou/LMF-Morphalou.php#body_3.4.11,
accessed 2011-11-04
</footnote>
<page confidence="0.999168">
649
</page>
<tableCaption confidence="0.9912415">
Table 1: Lexicon size and average cost for the nouns (N) and verbs (V) in four languages, with the percentage of
words correctly inferred from one and two forma (i.e. m = 1 and m &lt; 2, respectively).
</tableCaption>
<table confidence="0.999096222222222">
Lexicon Forms Entries Cost m = 1 m &lt; 2
Eng N 2 15,029 1.05 95% 100%
Eng V 5 5,692 1.21 84% 95%
Swe N 9 59,225 1.70 46% 92%
Swe V 20 4,789 1.13 97% 97%
Fre N 3 42,390 1.25 76% 99%
Fre V 51 6,851 1.27 92% 94%
Fin N 34 25,365 1.26 87% 97%
Fin V 102 10,355 1.09 96% 99%
</table>
<bodyText confidence="0.99475">
included entries where all the necessary forms
were presents.
Nouns: Nouns in French have two forms (sin-
gular and plural) and an intrinsic gender (mascu-
line or feminine), which we also considered to be
a part of the inflection table. Most of the unpre-
dictability comes from the impossibility to guess
the gender.
Verbs: The paradigms generate all of the sim-
ple (as opposed to compound) tenses given in tra-
ditional grammars such as the Bescherelle. Also
the participles are generated. The auxiliary verb
of compound tenses would be impossible to guess
from morphological clues, and was left out of
consideration.
</bodyText>
<subsectionHeader confidence="0.975344">
4.4 Finnish
</subsectionHeader>
<bodyText confidence="0.999973829787234">
The Finnish gold standard was the KOTUS lexi-
con (Kotimaisten Kielten Tutkimuskeskus, 2006).
It has around 90,000 entries tagged with part
of speech, 50 noun paradigms, and 30 verb
paradigms. Some of these paradigms are rather
abstract and powerful; for instance, grade alterna-
tion would multiply many of the paradigms by a
factor of 10 to 20, if it was treated in a concate-
native way. For instance, singular nominative-
genitive pairs show alternations such as talo–talon
(“house”), katto–katon (“roof”), kanto–kannon
(“stub”), rako–raon (“crack”), and sato–sadon
(“harvest”). All of these are treated with one and
the same paradigm, which makes the KOTUS sys-
tem relatively abstract.
The total number of forms of Finnish nouns and
verbs is a question of definition. Koskenniemi
(Koskenniemi, 1983) reports 2000 for nouns and
12,000 for verbs, but most of these forms result by
adding particles and possessive suffixes in an ag-
glutinative way. The traditional number and case
count for nouns gives 26, whereas for verbs the
count is between 100 and 200, depending on how
participles are counted. Notice that the definition
of predictability used in this paper doesn’t depend
on the number of forms produced (i.e. not on n
but only on m); therefore we can simply ignore
this question. However, the question is interesting
if we think about paradigms as a data compression
method (Section 4.5).
Nouns. Compound nouns are a problem for
morphology prediction in Finnish, because inflec-
tion is sensitive to the vowel harmony and num-
ber of syllables, which depend on where the com-
pound boundary goes. While many compounds
are marked in KOTUS, we had to remove some
compounds with unmarked boundaries. Another
peculiarity was that adjectives were included in
nouns; this is no problem since the inflection pat-
terns are the same, if comparison forms are ig-
nored. The figure 1.26 is better than the one re-
ported in (Ranta, 2008), which is 1.42; the reason
is mainly that the current set of paradigms has a
better coverage of three-syllable nouns.
Verbs. Even though more numerous in forms
than nouns, Finnish verbs are highly predictable
(1.09).
</bodyText>
<subsectionHeader confidence="0.998822">
4.5 Complexity and data compression
</subsectionHeader>
<bodyText confidence="0.999945">
The cost of a lexicon has an effect on learnabil-
ity. For instance, even though Finnish words have
ten or a hundred times more forms than English
forms, these forms can be derived from roughly
the same number of characteristic forms as in En-
glish. But this is of course just a part of the truth:
it might still be that the paradigm system itself is
much more complex in some languages than oth-
</bodyText>
<page confidence="0.999109">
650
</page>
<tableCaption confidence="0.844788333333333">
Table 2: Paradigm complexities for nouns and verbs
in the four languages, computed as the syntax tree size
of GF code.
</tableCaption>
<table confidence="0.9968586">
language noun verb total
English 403 837 991
Swedish 918 1039 1884
French 351 2193 2541
Finnish 4772 3343 6885
</table>
<bodyText confidence="0.99641652">
ers.
Following the definitions of Section 3, we have
counted the the complexity of the smart paradigm
definitions for nouns and verbs in the different
languages in the GF Resource Grammar Library.
Notice that the total complexity of the system is
lower than the sum of the parts, because many
definitions (such as morphophonological transfor-
mations) are reused in different parts of speech.
The results are in Table 2.
These figures suggest that Finnish indeed has a
more complex morphology than French, and En-
glish is the simplest. Of course, the paradigms
were not implemented with such comparisons in
mind, and it may happen that some of the differ-
ences come from different coding styles involved
in the collaboratively built library. Measuring
code syntax trees rather than source code text neu-
tralizes some of this variation (Section 3).
Finally, we can estimate the power of smart
paradigms as a data compression function. In a
sense, a paradigm is a function designed for the
very purpose of compressing a lexicon, and one
can expect better compression than with generic
tools such as bzip2. Table 3 shows the compres-
sion rates for the same full-form lexica as used
in the predictability experiment (Table 1). The
sizes are in kilobytes, where the code size for
paradigms is calculated as the number of con-
structors multiplied by 5 (Section 3). The source
lexicon size is a simple character count, similar to
the full-form lexicon.
Unexpectedly, the compression rate of the
paradigms improves as the number of forms in
the full-form lexicon increases (see Table 1 for
these numbers). For English and French nouns,
bzip2 is actually better. But of course, unlike
the paradigms, it also gives a global compression
over all entries in the lexicon. Combining the
two methods by applying bzip2 to the source code
gives, for the Finnish verb lexicon, a file of 60 kB,
which implies a joint compression rate of 227.
That the compression rates for the code can be
higher than the numbers of forms in the full-form
lexicon is explained by the fact that the gener-
ated forms are longer than the base forms. For
instance, the full-form entry of the Finnish verb
uida (”swim”) is 850 bytes, which means that the
average form size is twice the size of the basic
form.
</bodyText>
<sectionHeader confidence="0.440767" genericHeader="method">
5 Smart paradigms in lexicon building
</sectionHeader>
<bodyText confidence="0.9998599375">
Building a high-quality lexicon needs a lot of
manual work. Traditionally, when one is not writ-
ing all the forms by hand (which would be almost
impossible in languages with rich morphology),
sets of paradigms are used that require the lexi-
cographer to specify the base form of the word
and an identifier for the paradigm to use. This has
several usability problems: one has to remember
all the paradigm identifiers and choose correctly
from them.
Smart paradigm can make this task easier, even
accessible to non-specialist, because of their abil-
ity to guess the most probable paradigm from a
single base form. As shown by Table 1, this is
more often correct than not, except for Swedish
nouns. If this information is not enough, only a
few more forms are needed, requiring only prac-
tical knowledge of the language. Usually (92% to
100% in Table 1), adding a second form (m = 2)
is enough to cover all words. Then the best prac-
tice for lexicon writing might be always to give
these two forms instead of just one.
Smart paradigms can also be used for an auto-
matic bootstrapping of a list of base forms into a
full form lexicon. As again shown by the last col-
umn of Table 1, one form alone can provide an
excellent first approximation in most cases. What
is more, it is often the case that uncaught words
belong to a limited set of “irregular” words, such
as the irregular verbs in many languages. All new
words can then be safely inferred from the base
form by using smart paradigms.
</bodyText>
<sectionHeader confidence="0.999975" genericHeader="method">
6 Related work
</sectionHeader>
<bodyText confidence="0.99965">
Smart paradigms were used for a study of Finnish
morphology in (Ranta, 2008). The present paper
can be seen as a generalization of that experiment
to more languages and with the notion of code
</bodyText>
<page confidence="0.999066">
651
</page>
<tableCaption confidence="0.953908">
Table 3: Comparison between using bzip2 and paradigms+lexicon source as a compression method. Sizes in
kB.
</tableCaption>
<table confidence="0.999079888888889">
Lexicon Fullform bzip2 fullform/bzip2 Source fullform/source
Eng N 264 99 2.7 135 2.0
Eng V 245 78 3.2 57 4.4
Swe N 6,243 1,380 4.5 1,207 5.3
Swe V 840 174 4.8 58 15
Fre N 952 277 3.4 450 2.2
Fre V 3,888 811 4.8 98 40
Fin N 11,295 2,165 5.2 343 34
Fin V 13,609 2,297 5.9 123 114
</table>
<bodyText confidence="0.999691121951219">
complexity. Also the paradigms for Finnish are
improved here (cf. Section 4.4 above).
Even though smart paradigm-like descriptions
are common in language text books, there is to
our knowledge no computational equivalent to the
smart paradigms of GF. Finite state morphology
systems often have a function called a guesser,
which, given a word form, tries to guess either
the paradigm this form belongs to or the dictio-
nary form (or both). A typical guesser differs
from a smart paradigms in that it does not make
it possible to correct the result by giving more
forms. Examples of guessers include (Chanod
and Tapanainen, 1995) for French, (Hlav´aˇcov´a,
2001) for Czech, and (Nakov et al., 2003) for Ger-
man.
Another related domain is the unsupervised
learning of morphology where machine learning
is used to automatically build a language mor-
phology from corpora (Goldsmith, 2006). The
main difference is that with the smart paradigms,
the paradigms and the guess heuristics are imple-
mented manually and with a high certainty; in un-
supervised learning of morphology the paradigms
are induced from the input forms with much lower
certainty. Of particular interest are (Chan, 2006)
and (Dreyer and Eisner, 2011), dealing with the
automatic extraction of paradigms from text and
investigate how good these can become. The main
contrast is, again, that our work deals with hand-
written paradigms that are correct by design, and
we try to see how much information we can drop
before losing correctness.
Once given, a set of paradigms can be used in
automated lexicon extraction from raw data, as in
(Forsberg et al., 2006) and (Cl´ement et al., 2004),
by a method that tries to collect a sufficient num-
ber of forms to determine that a word belongs to a
certain paradigm. Smart paradigms can then give
the method to actually construct the full inflection
tables from the characteristic forms.
</bodyText>
<sectionHeader confidence="0.99897" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999991612903226">
We have introduced the notion of smart
paradigms, which implement the linguistic
knowledge involved in inferring the inflection of
words. We have used the paradigms to estimate
the predictability of nouns and verbs in English,
Swedish, French, and Finnish. The main result
is that, with the paradigms used, less than two
forms in average is always enough. In half of the
languages and categories, one form is enough to
predict more than 90% of forms correctly. This
gives a promise for both manual lexicon building
and automatic bootstrapping of lexicon from
word lists.
To estimate the overall complexity of inflection
systems, we have also measured the size of the
source code for the paradigm systems. Unsurpris-
ingly, Finnish is around seven times as complex
as English, and around three times as complex as
Swedish and French. But this cost is amortized
when big lexica are built.
Finally, we looked at smart paradigms as a data
compression method. With simple morphologies,
such as English nouns, bzip2 gave a better com-
pression of the lexicon than the source code us-
ing paradigms. But with Finnish verbs, the com-
pression rate was almost 20 times higher with
paradigms than with bzip2.
The general conclusion is that smart paradigms
are a good investment when building morpho-
logical lexica, as they ease the task of both hu-
man lexicographers and automatic bootstrapping
</bodyText>
<page confidence="0.995584">
652
</page>
<bodyText confidence="0.999928857142857">
methods. They also suggest a method to assess
the complexity and learnability of languages, re-
lated to Kolmogorov complexity. The results in
the current paper are just preliminary in this re-
spect, since they might still tell more about par-
ticular implementations of paradigms than about
the languages themselves.
</bodyText>
<sectionHeader confidence="0.995723" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999944">
We are grateful to the anonymous referees for
valuable remarks and questions. The research
leading to these results has received funding from
the European Union’s Seventh Framework Pro-
gramme (FP7/2007-2013) under grant agreement
no FP7-ICT-247914 (the MOLTO project).
</bodyText>
<sectionHeader confidence="0.999199" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999865265060241">
[Beesley and Karttunen2003] Kenneth R. Beesley and
Lauri Karttunen. 2003. Finite State Morphology.
CSLI Publications.
[Bescherelle1997] Bescherelle. 1997. La conjugaison
pour tous. Hatier.
[Borin et al.2008] Lars Borin, Markus Forsberg, and
Lennart L¨onngren. 2008. Saldo 1.0 (svenskt as-
sociationslexikon version 2). Spr˚akbanken, 05.
[Chan2006] Erwin Chan. 2006. Learning probabilistic
paradigms for morphology in a latent class model.
In Proceedings of the Eighth Meeting of the ACL
Special Interest Group on Computational Phonol-
ogy and Morphology, SIGPHON ’06, pages 69–78,
Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.
[Chanod and Tapanainen1995] Jean-Pierre Chanod
and Pasi Tapanainen. 1995. Creating a tagset,
lexicon and guesser for a french tagger. CoRR,
cmp-lg/9503004.
[Cl´ement et al.2004] Lionel Cl´ement, Benoit Sagot,
and Bernard Lang. 2004. Morphology based au-
tomatic acquisition of large-coverage lexica. In
Proceedings of LREC-04, Lisboa, Portugal, pages
1841–1844.
[Dreyer and Eisner2011] Markus Dreyer and Jason
Eisner. 2011. Discovering morphological
paradigms from plain text using a dirichlet process
mixture model. In Proceedings of the Conference
on Empirical Methods in Natural Language Pro-
cessing, EMNLP ’11, pages 616–627, Stroudsburg,
PA, USA. Association for Computational Linguis-
tics.
[Forsberg et al.2006] Markus Forsberg, Harald Ham-
marstr¨om, and Aarne Ranta. 2006. Morpholog-
ical Lexicon Extraction from Raw Text Data. In
T. Salakoski, editor, FinTAL 2006, volume 4139 of
LNCS/LNAI.
[Goldsmith2006] John Goldsmith. 2006. An Algo-
rithm for the Unsupervised Learning of Morphol-
ogy. Nat. Lang. Eng., 12(4):353–371.
[Hellberg1978] Staffan Hellberg. 1978. The Morphol-
ogy of Present-Day Swedish. Almqvist &amp; Wiksell.
[Hlav´aˇcov´a2001] Jaroslava Hlav´aˇcov´a. 2001. Mor-
phological guesser of czech words. In V´aclav Ma-
touˇsek, Pavel Mautner, Roman Moucek, and Karel
Tauˇser, editors, Text, Speech and Dialogue, volume
2166 of Lecture Notes in Computer Science, pages
70–75. Springer Berlin / Heidelberg.
[Kaplan and Kay1994] R. Kaplan and M. Kay. 1994.
Regular Models of Phonological Rule Systems.
Computational Linguistics, 20:331–380.
[Koskenniemi1983] Kimmo Koskenniemi. 1983.
Two-Level Morphology: A General Computational
Model for Word-Form Recognition and Production.
Ph.D. thesis, University of Helsinki.
[Kotimaisten Kielten Tutkimuskeskus2006]
Kotimaisten Kielten Tutkimuskeskus. 2006.
KOTUS Wordlist. http://kaino.kotus.
fi/sanat/nykysuomi.
[Nakov et al.2003] Preslav Nakov, Yury Bonev, and
et al. 2003. Guessing morphological classes of un-
known german nouns.
[Ranta2008] Aarne Ranta. 2008. How pre-
dictable is Finnish morphology? an experi-
ment on lexicon construction. In J. Nivre and
M. Dahll¨of and B. Megyesi, editor, Resource-
ful Language Technology: Festschrift in Honor
of Anna S˚agvall Hein, pages 130–148. University
of Uppsala. http://publications.uu.se/
abstract.xsql?dbid=8933.
[Ranta2011] Aarne Ranta. 2011. Grammatical Frame-
work: Programming with Multilingual Grammars.
CSLI Publications, Stanford. ISBN-10: 1-57586-
626-9 (Paper), 1-57586-627-7 (Cloth).
[Romary et al.2004] Laurent Romary, Susanne
Salmon-Alt, and Gil Francopoulo. 2004. Standards
going concrete: from LMF to Morphalou. In The
20th International Conference on Computational
Linguistics - COLING 2004, Gen`eve/Switzerland.
coling.
[Solomonoff1964] Ray J. Solomonoff. 1964. A formal
theory of inductive inference: Parts 1 and 2. Infor-
mation and Control, 7:1–22 and 224–254.
</reference>
<page confidence="0.999264">
653
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.751999">
<title confidence="0.927873">Smart Paradigms and the Predictability and Complexity of Inflectional Morphology</title>
<author confidence="0.975521">Gr´egoire D´etrez</author>
<author confidence="0.975521">Aarne</author>
<affiliation confidence="0.9475345">Department of Computer Science and Engineering Chalmers University of Technology and University of Gothenburg</affiliation>
<abstract confidence="0.999018266666666">Morphological lexica are often implemented on top of morphological paradigms, corresponding to different ways of building the full inflection table of a word. Computationally precise lexica may use hundreds of paradigms, and it can be hard for a lexicographer to choose among them. To automate this task, this paper introduces the of a It is a metaparadigm, which inspects the base form and tries to infer which low-level paradigm applies. If the result is uncertain, more forms are given for discrimination. The number of forms needed in average is a measure an inflection system. overall the system also has to take into account the code size of the paradigms definition itself. This paper evaluates the smart paradigms implemented in the open-source GF Resource Grammar Library. Predictability and complexity are estimated for four different languages: English, French, Swedish, and Finnish. The main result is that predictability does not decrease when the complexity of morphology grows, which means that smart paradigms provide an efficient tool for the manual construction and/or automatically bootstrapping of lexica.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Kenneth R Beesley</author>
<author>Lauri Karttunen</author>
</authors>
<title>Finite State Morphology.</title>
<date>2003</date>
<publisher>CSLI Publications.</publisher>
<marker>[Beesley and Karttunen2003]</marker>
<rawString>Kenneth R. Beesley and Lauri Karttunen. 2003. Finite State Morphology. CSLI Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bescherelle</author>
</authors>
<title>La conjugaison pour tous.</title>
<date>1997</date>
<publisher>Hatier.</publisher>
<marker>[Bescherelle1997]</marker>
<rawString>Bescherelle. 1997. La conjugaison pour tous. Hatier.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lars Borin</author>
<author>Markus Forsberg</author>
<author>Lennart L¨onngren</author>
</authors>
<title>Saldo 1.0 (svenskt associationslexikon version 2).</title>
<date>2008</date>
<journal>Spr˚akbanken,</journal>
<volume>05</volume>
<marker>[Borin et al.2008]</marker>
<rawString>Lars Borin, Markus Forsberg, and Lennart L¨onngren. 2008. Saldo 1.0 (svenskt associationslexikon version 2). Spr˚akbanken, 05.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erwin Chan</author>
</authors>
<title>Learning probabilistic paradigms for morphology in a latent class model.</title>
<date>2006</date>
<booktitle>In Proceedings of the Eighth Meeting of the ACL Special Interest Group on Computational Phonology and Morphology, SIGPHON ’06,</booktitle>
<pages>69--78</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<marker>[Chan2006]</marker>
<rawString>Erwin Chan. 2006. Learning probabilistic paradigms for morphology in a latent class model. In Proceedings of the Eighth Meeting of the ACL Special Interest Group on Computational Phonology and Morphology, SIGPHON ’06, pages 69–78, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean-Pierre Chanod</author>
<author>Pasi Tapanainen</author>
</authors>
<title>Creating a tagset, lexicon and guesser for a french tagger.</title>
<date>1995</date>
<tech>CoRR, cmp-lg/9503004.</tech>
<marker>[Chanod and Tapanainen1995]</marker>
<rawString>Jean-Pierre Chanod and Pasi Tapanainen. 1995. Creating a tagset, lexicon and guesser for a french tagger. CoRR, cmp-lg/9503004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lionel Cl´ement</author>
<author>Benoit Sagot</author>
<author>Bernard Lang</author>
</authors>
<title>Morphology based automatic acquisition of large-coverage lexica.</title>
<date>2004</date>
<booktitle>In Proceedings of LREC-04,</booktitle>
<pages>1841--1844</pages>
<location>Lisboa, Portugal,</location>
<marker>[Cl´ement et al.2004]</marker>
<rawString>Lionel Cl´ement, Benoit Sagot, and Bernard Lang. 2004. Morphology based automatic acquisition of large-coverage lexica. In Proceedings of LREC-04, Lisboa, Portugal, pages 1841–1844.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Markus Dreyer</author>
<author>Jason Eisner</author>
</authors>
<title>Discovering morphological paradigms from plain text using a dirichlet process mixture model.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’11,</booktitle>
<pages>616--627</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<marker>[Dreyer and Eisner2011]</marker>
<rawString>Markus Dreyer and Jason Eisner. 2011. Discovering morphological paradigms from plain text using a dirichlet process mixture model. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’11, pages 616–627, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Markus Forsberg</author>
<author>Harald Hammarstr¨om</author>
<author>Aarne Ranta</author>
</authors>
<title>Morphological Lexicon Extraction from Raw Text Data. In</title>
<date>2006</date>
<volume>4139</volume>
<editor>T. Salakoski, editor,</editor>
<location>FinTAL</location>
<marker>[Forsberg et al.2006]</marker>
<rawString>Markus Forsberg, Harald Hammarstr¨om, and Aarne Ranta. 2006. Morphological Lexicon Extraction from Raw Text Data. In T. Salakoski, editor, FinTAL 2006, volume 4139 of LNCS/LNAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Goldsmith</author>
</authors>
<title>An Algorithm for the Unsupervised Learning of Morphology.</title>
<date>2006</date>
<journal>Nat. Lang. Eng.,</journal>
<volume>12</volume>
<issue>4</issue>
<marker>[Goldsmith2006]</marker>
<rawString>John Goldsmith. 2006. An Algorithm for the Unsupervised Learning of Morphology. Nat. Lang. Eng., 12(4):353–371.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Staffan Hellberg</author>
</authors>
<title>The Morphology of Present-Day Swedish.</title>
<date>1978</date>
<publisher>Almqvist &amp; Wiksell.</publisher>
<marker>[Hellberg1978]</marker>
<rawString>Staffan Hellberg. 1978. The Morphology of Present-Day Swedish. Almqvist &amp; Wiksell.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jaroslava Hlav´aˇcov´a</author>
</authors>
<title>Morphological guesser of czech words.</title>
<date>2001</date>
<booktitle>Speech and Dialogue,</booktitle>
<volume>2166</volume>
<pages>70--75</pages>
<editor>In V´aclav Matouˇsek, Pavel Mautner, Roman Moucek, and Karel Tauˇser, editors, Text,</editor>
<publisher>Springer</publisher>
<location>Berlin / Heidelberg.</location>
<marker>[Hlav´aˇcov´a2001]</marker>
<rawString>Jaroslava Hlav´aˇcov´a. 2001. Morphological guesser of czech words. In V´aclav Matouˇsek, Pavel Mautner, Roman Moucek, and Karel Tauˇser, editors, Text, Speech and Dialogue, volume 2166 of Lecture Notes in Computer Science, pages 70–75. Springer Berlin / Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Kaplan</author>
<author>M Kay</author>
</authors>
<title>Regular Models of Phonological Rule Systems. Computational Linguistics,</title>
<date>1994</date>
<pages>20--331</pages>
<marker>[Kaplan and Kay1994]</marker>
<rawString>R. Kaplan and M. Kay. 1994. Regular Models of Phonological Rule Systems. Computational Linguistics, 20:331–380.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kimmo Koskenniemi</author>
</authors>
<title>Two-Level Morphology: A General Computational Model for Word-Form Recognition and Production.</title>
<date>1983</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Helsinki.</institution>
<marker>[Koskenniemi1983]</marker>
<rawString>Kimmo Koskenniemi. 1983. Two-Level Morphology: A General Computational Model for Word-Form Recognition and Production. Ph.D. thesis, University of Helsinki.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kotimaisten Kielten Tutkimuskeskus</author>
</authors>
<date>2006</date>
<note>KOTUS Wordlist. http://kaino.kotus. fi/sanat/nykysuomi.</note>
<marker>[Kotimaisten Kielten Tutkimuskeskus2006]</marker>
<rawString> Kotimaisten Kielten Tutkimuskeskus. 2006. KOTUS Wordlist. http://kaino.kotus. fi/sanat/nykysuomi.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Preslav Nakov</author>
<author>Yury Bonev</author>
</authors>
<title>Guessing morphological classes of unknown german nouns.</title>
<date>2003</date>
<marker>[Nakov et al.2003]</marker>
<rawString>Preslav Nakov, Yury Bonev, and et al. 2003. Guessing morphological classes of unknown german nouns.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aarne Ranta</author>
</authors>
<title>How predictable is Finnish morphology? an experiment on lexicon construction.</title>
<date>2008</date>
<booktitle>Resourceful Language Technology: Festschrift in Honor of Anna S˚agvall Hein,</booktitle>
<pages>130--148</pages>
<editor>In J. Nivre and M. Dahll¨of and B. Megyesi, editor,</editor>
<institution>University of Uppsala.</institution>
<note>http://publications.uu.se/ abstract.xsql?dbid=8933.</note>
<marker>[Ranta2008]</marker>
<rawString>Aarne Ranta. 2008. How predictable is Finnish morphology? an experiment on lexicon construction. In J. Nivre and M. Dahll¨of and B. Megyesi, editor, Resourceful Language Technology: Festschrift in Honor of Anna S˚agvall Hein, pages 130–148. University of Uppsala. http://publications.uu.se/ abstract.xsql?dbid=8933.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aarne Ranta</author>
</authors>
<title>Grammatical Framework: Programming with Multilingual Grammars.</title>
<date>2011</date>
<volume>10</volume>
<pages>1--57586</pages>
<publisher>CSLI Publications,</publisher>
<location>Stanford.</location>
<marker>[Ranta2011]</marker>
<rawString>Aarne Ranta. 2011. Grammatical Framework: Programming with Multilingual Grammars. CSLI Publications, Stanford. ISBN-10: 1-57586-626-9 (Paper), 1-57586-627-7 (Cloth).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Laurent Romary</author>
<author>Susanne Salmon-Alt</author>
<author>Gil Francopoulo</author>
</authors>
<title>Standards going concrete: from LMF to Morphalou.</title>
<date>2004</date>
<booktitle>In The 20th International Conference on Computational Linguistics - COLING 2004, Gen`eve/Switzerland. coling.</booktitle>
<marker>[Romary et al.2004]</marker>
<rawString>Laurent Romary, Susanne Salmon-Alt, and Gil Francopoulo. 2004. Standards going concrete: from LMF to Morphalou. In The 20th International Conference on Computational Linguistics - COLING 2004, Gen`eve/Switzerland. coling.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ray J Solomonoff</author>
</authors>
<title>A formal theory of inductive inference:</title>
<date>1964</date>
<journal>Parts</journal>
<volume>1</volume>
<pages>224--254</pages>
<marker>[Solomonoff1964]</marker>
<rawString>Ray J. Solomonoff. 1964. A formal theory of inductive inference: Parts 1 and 2. Information and Control, 7:1–22 and 224–254.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>