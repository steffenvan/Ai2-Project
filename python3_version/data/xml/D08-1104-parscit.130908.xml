<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9783875">
Construction of an Idiom Corpus and its Application to Idiom Identification
based on WSD incorporating Idiom-Specific Features
</title>
<author confidence="0.989282">
Chikara Hashimoto
</author>
<affiliation confidence="0.99599">
Graduate School of Science and Engineering
Yamagata University
</affiliation>
<address confidence="0.772555">
Yonezawa, Yamagata, 992-8510, JAPAN
</address>
<email confidence="0.998895">
ch@yz.yamagata-u.ac.jp
</email>
<author confidence="0.983672">
Daisuke Kawahara
</author>
<affiliation confidence="0.909927">
National Institute of Information and
Communications Technology
</affiliation>
<address confidence="0.933049">
Sorakugun, Kyoto, 619-0289, JAPAN
</address>
<email confidence="0.999224">
dk@nict.go.jp
</email>
<sectionHeader confidence="0.996662" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.962453375">
Some phrases can be interpreted either id-
iomatically (figuratively) or literally in con-
text, and the precise identification of idioms
is indispensable for full-fledged natural lan-
guage processing (NLP). To this end, we have
constructed an idiom corpus for Japanese.
This paper reports on the corpus and the re-
sults of an idiom identification experiment us-
ing the corpus. The corpus targets 146 am-
biguous idioms, and consists of 102,846 sen-
tences, each of which is annotated with a lit-
eral/idiom label. For idiom identification, we
targeted 90 out of the 146 idioms and adopted
a word sense disambiguation (WSD) method
using both common WSD features and idiom-
specific features. The corpus and the experi-
ment are the largest of their kind, as far as we
know. As a result, we found that a standard
supervised WSD method works well for the
idiom identification and achieved an accuracy
of 89.25% and 88.86% with/without idiom-
specific features and that the most effective
idiom-specific feature is the one involving the
adjacency of idiom constituents.
</bodyText>
<sectionHeader confidence="0.998806" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999943268292683">
Some phrases like kick the bucket are ambiguous
with regard to whether they carry literal or idiomatic
meaning in a certain context. This ambiguity needs
to be resolved in the same manner as ambiguous
words that have been dealt with in the WSD liter-
ature. We term the resolution of the literal/idiomatic
ambiguity as idiom identification, hereafter.
Idiom identification is classified into two kinds;
one is for idiom types and the other is for idiom to-
kens. With the former, phrases that can be inter-
preted as idioms are found in text corpora, typically
for compiling idiom dictionaries. On the other hand,
the latter helps identify a phrase in context as a true
idiom or a phrase that should be interpreted literally
(a literal phrase, henceforth). In this paper, we deal
with the latter, i.e., idiom token identification.
Despite the recent enthusiasm for multiword ex-
pressions (MWEs) (Gr«egoire et al., 2007; Gr«egoire
et al., 2008), the idiom token identification is in an
early phase of its development. Given that many
NLP tasks like machine translation or parsing have
been developed as a result of the availability of lan-
guage resources, idiom token identification should
also be developed when adequate idiom resources
are provided. To this end, we have constructed a
Japanese idiom corpus. We have also conducted
an idiom identification experiment using the corpus
that we hope will be a good reference point for fu-
ture studies on the task. We drew on a standard
WSD framework with machine learning exploiting
both features commonly used in the WSD studies
and idiom-specific features. This paper reports in
detail the corpus and the result of the experiment;
herein, it must be noted that to the best of our knowl-
edge, the corpus and the experiment are the largest
ever of their kind.
We only deal with the ambiguity between lit-
eral and idiomatic interpretations. However, some
phrases have two or more idiomatic meanings with-
out context. For example, a Japanese idiom te-o
dasu (hand-ACC stretch)1 can be interpreted as ei-
</bodyText>
<footnote confidence="0.8688125">
1ACC is the accusative case marker. Likewise we use the
following notation in this paper; NOM for the nominative case
</footnote>
<page confidence="0.862227">
992
</page>
<note confidence="0.8850705">
Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 992–1001,
Honolulu, October 2008. c�2008 Association for Computational Linguistics
</note>
<bodyText confidence="0.9998576">
ther “punch,” “steal” or “make moves on.” This kind
of ambiguity should be placed on the agenda.
We do not tackle the problem of what constitutes
the notion of “idiom.” We simply regard phrases
listed in Sato (2007) as idioms.
The reminder of this paper is organized as fol-
lows. In §2 we present related works. §3 shows the
target idioms. After the idiom corpus is described
in §4, we detail our idiom identification method and
experiment in §5. Finally §6 concludes the paper.
</bodyText>
<sectionHeader confidence="0.999815" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.99982316">
There have only been a few works on the con-
struction of an idiom corpus. In this regard, Birke
and Sarkar (2006) and Cook et al. (2008) are no-
table exceptions. Birke and Sarkar (2006) auto-
matically constructed a corpus of English idiomatic
expressions (words that can be used non-literally).
They targeted 50 expressions and collected about
6,600 examples. They call the corpus TroFi Exam-
ple Base, which is available on the Web.2 Cook
et al. (2008) compiled a corpus of English verb-
noun combinations (VNCs) tokens. Their corpus
deals with 53 VNC expressions and consists of about
3,000 example sentences. Like ours, they assigned
each example with a label indicating whether an ex-
pression in the example is used literally or idiomati-
cally. Our corpus can be regarded as the Japanese
idiom counterpart of these works. However, note
that our corpus targets 146 idioms and consists of
as many as 102,846 example sentences. Another ex-
ception is Tsuchiya et al. (2006), who manually con-
structed an example database of Japanese compound
functional expressions named MUST. They provide
it on the Web.3 Some of the compound functional
expressions in Japanese are ambiguous like idioms
are.4
</bodyText>
<footnote confidence="0.9679469">
marker, DAT for the dative case marker, and GEN for the genitive
case marker. FROM and TO stand for the Japanese counterparts
offrom and to. NEG represents a verbal negation morpheme.
2http://www.cs.sfu.ca/-anoop/students/jbirke/
3http://nlp.iit.tsukuba.ac.jp/must/
4For example, (something)-ni-atatte ((something)-DAT-
run.into) means either “run into (something)” or “on the occa-
sion of (something).” The former is the literal interpretation and
the latter is the idiomatic interpretation of the compound func-
tional expression.
</footnote>
<bodyText confidence="0.997313955555556">
The SAID dataset5 provides data about the syn-
tactic flexibility of English idioms. It does not con-
cern itself with idiom token identification. How-
ever, as in Hashimoto et al. (2006b), Hashimoto et
al. (2006a) and Cook et al. (2007) among others, the
syntactic behavior of idioms is an important clue to
idiom token identification.
Previous studies have mostly focused on the id-
iom type identification (Lin, 1999; Krenn and Evert,
2001; Baldwin et al., 2003; Shudo et al., 2004; Fa-
zly and Stevenson, 2006). However, there has been a
growing interest in idiom token identification in re-
cent times (Katz and Giesbrecht, 2006; Hashimoto
et al., 2006b; Hashimoto et al., 2006a; Birke and
Sarkar, 2006; Cook et al., 2007). Katz and Gies-
brecht (2006) compared the word vector of an id-
iom in context and that of the constituent words of
the idiom using LSA in order to determine if the
expression is idiomatic. Hashimoto et al. (2006b)
and Hashimoto et al. (2006a) (HSU henceforth) fo-
cused their attention on the differences in gram-
matical constraints imposed on idioms and their lit-
eral counterparts such as the possibility of passiviza-
tion, and developed handcrafted rules for Japanese
idiom identification. Although their task is ex-
actly the same as ours and we draw on the gram-
matical knowledge provided by them, the scale of
their experiment is very small, since only 108 sen-
tences were used for idiom identification in their pa-
per. Further, unlike HSU, we employ matured WSD
technologies. Cook et al. (2007) (CFS henceforth)
propose an unsupervised method for English on the
basis of the observation that idioms tend to be ex-
pressed in a small number of fixed forms.
These studies used only the characteristics of id-
ioms (or MWEs). On the other hand, we exploit
a WSD method, for which there have been many
studies and matured technologies, in addition to the
characteristics of idioms. Birke and Sarkar (2006)
also used WSD. However, they employed an unsu-
pervised method, while ours is a completely super-
vised one.
Apart from idioms, Uchiyama et al. (2005) con-
ducted the token classification of Japanese com-
pound verbs exploiting supervised method.
</bodyText>
<footnote confidence="0.858489">
http://www.ldc.upenn.edu/Catalog/
5CatalogEntry.jsp?catalogId=LDC2003T10
</footnote>
<page confidence="0.999016">
993
</page>
<sectionHeader confidence="0.993457" genericHeader="method">
3 Target Idioms
</sectionHeader>
<bodyText confidence="0.99992872972973">
For this study, we selected 146 idioms through the
following procedure. 1 We extracted basic idioms
from Sato (2007). Sato compiled about 3,600 basic
idioms of Japanese from five books: two dictionaries
for elementary school, two idiom dictionaries, and
one linguistics book on idioms. We extracted those
idioms that were described in more than two of these
five books. The total number of such idioms added
up to 926. 2 From among these idioms, we chose
ambiguous ones.6 As a result, 146 idioms were se-
lected.
As for 2 , sometimes it is not trivial to determine
if an idiom is ambiguous or not. Some idioms are
rarely interpreted literally, while others, in all likeli-
hood, take on the literal meaning. Is it meaningful to
regard them as ambiguous and deal with them in this
study? If not, how does one assuredly distinguish
truly ambiguous idioms from those that are mostly
interpreted either literally or figuratively? This can
only be done if there is an accurate idiom identifica-
tion system.
After all, we asked two native speakers of
Japanese (Group A) to classify idioms into two
classes: 1) truly ambiguous ones and 2) completely
unambiguous or practically unambiguous ones. On
the basis of the classification, one of the authors
made final judgments.
To verify how stable this ambiguity endorsement
was, we asked another two other native speakers
of Japanese (Group B) to perform the same task
and calculated the Kappa statistic between the two
speakers. First, we sampled 101 idioms from the 926
chosen earlier. Then, the two members of Group B
classified the sampled idioms into the two classes.
The Kappa statistic was found to be 0.6576, which
indicates middling stability.
Tables 2 and 3 list some of the target idioms.
</bodyText>
<sectionHeader confidence="0.999756" genericHeader="method">
4 Idiom Corpus
</sectionHeader>
<subsectionHeader confidence="0.999909">
4.1 Corpus Specification
</subsectionHeader>
<bodyText confidence="0.998268333333333">
The corpus is designed for the idiom token iden-
tification task. That is, each example sentence in
the corpus is annotated with a label that indicates
</bodyText>
<footnote confidence="0.9258265">
6Some idioms like by and large do not have a literal mean-
ing. They are not dealt with in this paper.
</footnote>
<bodyText confidence="0.99872525">
whether the corresponding phrase in the example is
used as an idiom or a literal phrase. We call the for-
mer the positive example and the latter the negative
example. More specifically, the corpus consists of
lines that each represent one example. A line con-
sists of four fields as follows: 1 Label indicates
whether the example is positive or negative. Label i
is used for positive examples and l for negative ones.
2 ID denotes the idiom that is included in the exam-
ple. In this study, each idiom has a unique num-
ber, which is based on Sato (2007). 3 Lemma also
shows the idiom in the example. We assigned each
idiom its canonical (or standard) form on the basis
of Sato (2007). 4 Example is the example itself.
Given below is a sample of a negative example of
goma-o suru (sesame-ACC crush) ’flatter’.
</bodyText>
<listItem confidence="0.921029">
• l 1417 !&amp;quot;#$% $&amp;&apos;(!&amp;quot;#$&amp; ···
</listItem>
<bodyText confidence="0.998603857142857">
The third field is the lemma of the idiom. The last
one is the example that says ’crushing sesame in a
mortar...’
Before working on the corpus construction, we
prepared a reference by which human annotators
could consistently distinguish between the literal
and figurative meanings of idioms. To be more pre-
cise, this reference specified literal and idiomatic
meanings for each idiom like dictionaries do. For
example, the entry for goma-o suru in the reference
is as follows.
Idiom: To flatter people.
Literal: To crush sesame.
As for the corpus size, we continued to anno-
tate examples for each idiom, regardless of the pro-
portion of idioms and literal phrases, until the total
number of examples for each idiom reached 1,000.7
In the case of a shortage of original data, we anno-
tated as many examples as possible. The original
data were sourced from the Japanese Web corpus
(Kawahara and Kurohashi, 2006).
</bodyText>
<subsectionHeader confidence="0.993946">
4.2 Corpus Construction
</subsectionHeader>
<bodyText confidence="0.99990575">
We constructed the corpus in the following man-
ner: 1 From the Web corpus, we collected exam-
ple sentences that contained one of our target id-
ioms whichever meaning (positive or negative) they
</bodyText>
<footnote confidence="0.995424">
7For idioms that we sampled for preliminary annotation, we
annotated more than 1,000 examples.
</footnote>
<page confidence="0.995125">
994
</page>
<figure confidence="0.997433666666667">
Sentence Ratio
0 500 1000 1500 2000 2500 3000
# of Examples
</figure>
<figureCaption confidence="0.999969">
Figure 1: Distribution of the number of examples
</figureCaption>
<figure confidence="0.386981">
# of Words in a Sentence
</figure>
<figureCaption confidence="0.998849">
Figure 2: Distribution of sentence length
</figureCaption>
<figure confidence="0.999870777777778">
0.25
0.15
0.05
0.3
0.2
0.1
0
Web
News
Idiom
1-5 6-10 11-1516-20 21-25 26-30 31-35 36-40 41-45 46-50 51-55 56-60 61-65 66-70 71-75 76-80
# of Types 60
50
40
30
20
10
0
</figure>
<bodyText confidence="0.998349133333333">
take on. Concretely speaking, we automatically col-
lected sentences in which constituent words of one
of our targets appeared in a canonical dependency
relationship by using KNP8, a Japanese dependency
parser. 2 We classified the collected examples as
positive and negative. This was done by human an-
notators and was based on the reference to distin-
guish the two meanings. For annotation, longer ex-
amples were given higher priority than shorter ex-
amples. Note that we discarded examples that were
collected by mistake due to dependency parsing er-
rors and those that lacked a context that could help
them be interpreted correctly.
This was done by the two members of Group A
and took 230 hours.
</bodyText>
<subsectionHeader confidence="0.999946">
4.3 Status of Corpus
</subsectionHeader>
<bodyText confidence="0.999974545454546">
The corpus consists of 102,846 examples.9 Figure
1 shows the distribution of the number of examples.
For 68 idioms, we annotated more than 1,000 exam-
ples. However, we annotated less than 100 examples
for 17 idioms because of inadequate original data.
The average number of words in a sentence is 46.
Idiom in Figure 2 shows the distribution of sen-
tence length (the number of words) in the corpus.
Web and News indicate the sentence length in the
Web and a newspaper corpora, respectively. This is
drawn from Kawahara and Kurohashi (2006). As
</bodyText>
<footnote confidence="0.948073333333333">
8http://nlp.kuee.kyoto-u.ac.jp/nl-resource/knp.html
9Note that the figures reported here are for the corpus of the
2008-06-25 version and will be slightly changed over time.
</footnote>
<bodyText confidence="0.999918157894737">
you see, our corpus contains many more long sen-
tences. This is because longer sentences were given
priority for annotation, as stated in §4.2. Figure 3
shows the longest and shortest examples each for lit-
eral and idiomatic meanings of goma-o suru drawn
from the corpus.
To determine how consistent the positive/negative
annotation is across different human annotators, we
sampled 1,421 examples from the corpus, asked the
two members of Group B to do the same annota-
tion, and calculated the Kappa statistic between the
two. The value was 0.8519, which indicates very
high agreement.
The corpus is available on the Web.10 Currently
we provide the list of the basic Japanese idioms we
are dealing with, the idiom corpus, and the vector
representation data used for the idiom identification
experiment. The corpus is protected under the BSD
license.
</bodyText>
<sectionHeader confidence="0.997895" genericHeader="method">
5 Idiom Identification Experiment
</sectionHeader>
<subsectionHeader confidence="0.999876">
5.1 Method of Idiom Identification
</subsectionHeader>
<bodyText confidence="0.999963">
We adopted a standard WSD method using machine
learning. More specifically, we used SVM (Vap-
nik, 1995) with a quadratic kernel implemented in
TinySVM.11 The features we used are classified into
either those that have been commonly used in WSD
on the lines of Lee and Ng (2002) (LN hereafter),
</bodyText>
<footnote confidence="0.9583925">
10http://openmwe.sourceforge.jp/
11http://www.chasen.org/-taku/software/TinySVM/
</footnote>
<page confidence="0.995958">
995
</page>
<bodyText confidence="0.922286090909091">
• )*+,-./012345678-./012,9:;&lt;=&gt;?(@A$%BC&gt;?#
D2$%0EF;GHIJK$%LMNOGHI@A2P&amp;,QROGH8STUV%L
WXY34567;Z[\#]^+_W%`Lab,cdI+))a(ef)gX2,hi
jklmnopo2�����,qr;st2`u#v&amp;,wxIyz_m{|}*~(,
+W;&amp;quot;W(,N,+z,({~%`L*X
(But I suspect that the show managers of IT ventures will remain sly and audacious, and survive
by flattering manufacturers, bending over themselves to accede to the demands of governmental
agencies, and talking glibly about buzz terms, without intelligence but with vitality, just like
the brokers of prostitutes in the Edo period were, because Gresham’s law of 1562 says that any
circulating currency consisting of both good and bad money quickly becomes dominated by the
bad money.)
</bodyText>
<listItem confidence="0.732326">
• 2�����
(Just like a pretty official flattering his boss.)
• )#$28,)WOIeVWW;($I,OW ¡¢8,��
���m;(£$a,mfL¤¥O¦ZL+_8,§¨o© ª2#«V,¬#+_
­©#a~_®;ab¯(`$%gX2$ %LWW(+°X
</listItem>
<bodyText confidence="0.988597666666667">
(In order to mash boiled soybeans, it is the best to use a meat chopper, but if you don’t have one,
use the thing to crush sesame, or put them into a plastic bag, cover it with a towel, then mash it
with a glass bottle, which is easier.)
</bodyText>
<listItem confidence="0.60295">
• �����±23Le´%
</listItem>
<bodyText confidence="0.478614">
(Crushing sesame, then adding seasonings to it.)
</bodyText>
<figureCaption confidence="0.999617">
Figure 3: The longest and shortest examples for both literal and idiomatic meanings of goma-o suru
</figureCaption>
<bodyText confidence="0.997838">
or those that have been designed for Japanese idiom
identification proposed by HSU.12
</bodyText>
<listItem confidence="0.961563">
• Common WSD Features
f1: POS of three words on the left side of idiom
and three words on the right side
f2: Local collocations
f3: Single words in the surrounding context
</listItem>
<bodyText confidence="0.919456">
f4a: Lemma of the rightmost word among
those words that are the dependents of the
leftmost constituent word of idiom13
f4b: POS of the rightmost word among those
words that are the dependents of the left-
most constituent word of idiom
f5a: Lemma of the word which the rightmost
constituent word of idiom is the dependent
of
12Remember that HSU implemented them in handcrafted
rules. We adapted them to a machine learning framework.
13Note that Japanese is a head final language.
f5b: POS of the word which the rightmost con-
stituent word of idiom is the dependent of
</bodyText>
<listItem confidence="0.9803405">
f6: Hypernyms of words in the surrounding
context
f7: Domains of words (Hashimoto and Kuro-
hashi, 2007; Hashimoto and Kurohashi,
2008) in the surrounding context
• Idiom-Specific Features
f8: Adnominal modification flag
f9: Topic case marking flag
f10: Voice alternation flag
f11: Negation flag
f12: Volitional modality flag
f13: Adjacency flag
</listItem>
<bodyText confidence="0.9975525">
We used JUMAN,14 a morphological analyzer of
Japanese, and KNP to extract these features.
</bodyText>
<footnote confidence="0.769543">
14http://nlp.kuee.kyoto-u.ac.jp/nl-resource/juman.html
</footnote>
<page confidence="0.994434">
996
</page>
<bodyText confidence="0.991945722222222">
f2 and f3 are the same as those described in LN.
But f1 is slightly different in that we did not use the
Po of LN. f4 and f5 roughly correspond to the syn-
tactic relations of LN. We adapted it to Japanese id-
ioms along with some simplifications. In the case of
the example of mune-o utu (chest-ACC hit) ‘impress’
below,15 f4 is the POS and lemma of tyousyu and f5
corresponds to those of uta.16
‘A beautiful song that impresses the audience’
f6 and f7 are available from JUMAN’s output.
For example, the hypernym of tyousyu (audience)
is human and its domain is culture/media.
Those of uta (song) are abstract-thing and
culture/recreation. They are not used in
LN, but they are known to be useful for WSD
(Tanaka et al., 2007; Magnini et al., 2002).
f8 indicates whether a nominal constituent of an
idiom, if any, undergoes adnominal modification. f9
indicates whether one of Japanese topic case mark-
ers is attached to a nominal constituent of an idiom,
if any. f10 is turned on when a passive or causative
suffix is attached to a verbal constituent of an idiom,
if any.17 f11 and f12 are similar to f10. The former
is used for negated forms and the latter for volitional
modality suffixes of a predicate part of an idiom, if
any.18 Volitional modality includes expressions like
order, request, permission, prohibition, and volition.
Finally, f13 indicates whether the constituents of an
idiom is adjacent to each other.
As discussed in HSU, the idiom-specific fea-
tures are effective to distinguish idioms from lit-
eral phrases. For example, the idiom goma-o suru
does not allow adnominal modification, while its lit-
eral counterpart does. Similarly, the idiom mune-o
utu cannot take volitional modality unlike its literal
counterpart.
</bodyText>
<footnote confidence="0.968052333333333">
15The arrows indicate dependency relations.
16Functional words attaching to either the f4 word or the f5
word are ignored. In the example, no (GEN) is ignored.
17Passivization is indicated by the suffix (r)are in Japanese.
But the same suffix is also used for honorification, potentials
and spontaneous potentials. Since it is beyond the current tech-
nology, we gave up distinguishing them.
18Note that f10, f11 and f12 are applied to only those idioms
that can be used as predicates.
</footnote>
<subsectionHeader confidence="0.975321">
5.2 Experimental Condition
</subsectionHeader>
<bodyText confidence="0.935669833333333">
In the experiment, we dealt with 90 idioms for which
more than 50 examples for both idiomatic and literal
usages were available.19 We conducted experiments
for each idiom.
The performance measure is the accuracy.
# of examples correctly identified
</bodyText>
<equation confidence="0.5400095">
Accuracy =
# of all example
</equation>
<bodyText confidence="0.99975875">
The baseline system uniformly regards all ex-
amples as either positive or negative depending on
which is more dominant in the idiom corpus. Natu-
rally, this is prepared for each idiom.
</bodyText>
<equation confidence="0.875299333333333">
max(# of positive, # of negative)
Baseline =
# of all example
</equation>
<bodyText confidence="0.992080266666667">
The accuracy and the baseline accuracy for each
idiom are calculated in a 10-fold cross validation
style; we split examples of an idiom into 10 pieces
in advance of the experiment.
Also, we calculated the overall accuracy and
baseline accuracy from the individual results. We
summed up all accuracy scores of all the 90 idioms
and then divided it by 90, which is called the macro-
average. We did this for the baseline accuracy, too.
Another performance measure is the relative error
reduction (RER).20
ER of baseline − ER of system
ER of baseline
The overall RER is calculated from the overall ac-
curacy and baseline by the above formula.
</bodyText>
<subsectionHeader confidence="0.992656">
5.3 Experimental Result
</subsectionHeader>
<bodyText confidence="0.838832636363636">
Table 1 shows the overall performance. The first col-
umn is the baseline accuracy (%). The second col-
umn is the accuracy (%) and relative error reduction
(%) of the system without the idiom-specific fea-
tures. The third column is those of the system with
the idiom features. Tables 2 and 3 show the individ-
ual results of the 90 idioms. The first column shows
19Some examples were unavailable due to the feature extrac-
tion failure. Thus, examples used for the experiment are fewer
in number than those included in the corpus.
20ER stands for Error Rate in the formula.
</bodyText>
<figure confidence="0.996890571428571">
• tyousyu-no
audience-GEN
mune-o
chest-ACC
utu utukusi uta
hit beautiful song
RER =
</figure>
<page confidence="0.911445">
997
998
</page>
<tableCaption confidence="0.272034">
Table 2: Individual Results (1/2)
</tableCaption>
<table confidence="0.685008404580153">
Type
µ¶#·_% (blue.vein-ACC emerge) ‘burst a blood vessel’
e¸b#az (sit cross-legged) ‘rest on one’s laurels’
1Iºz (leg-NOM attach) ‘find a clue to solving a case’
1I»% (leg-NOM go.out) ‘run over the budget’
11/4#1/2% (one’s feet-ACC look.down) ‘see someone coming’
1#3/4X (leg-ACC wash) ‘wash one’s hands of ...’
1#¿$ (leg-ACC stretch) ‘go a little further’
ÀIÁW (head-NOM ache) ‘harass oneself about ...’
À#Â´% (head-ACC fold) ‘tear one’s hair out’
À#m)Ã% (head-ACC lift) ‘rear its head’
ÄIÅ% (fat-NOM put.on) ‘warm up to one’s work’
Æ#v% (oil-ACC sell) ‘shoot the breeze’
Æ#Ç% (oil-ACC squeeze) ‘rake someone over the coals’
È#É% (net-ACC spread) ‘wait expectantly’
ÊIË&amp;quot;% (breath-NOM choke.up) ‘stifling’
:abÌ&amp;quot;( (one-FROM ten-TO) ‘all without exception’
Í#ÎX (color-ACC lose) ‘turn pale’
ÏII% (arm-NOM go.up) ‘develop one’s skill’
Ð#Ñz (tail-ACC pull) ‘have a lasting effect’
Ò#»$ (face-ACC present) ‘show up’
Ó#ÔÕ% (shoulder-ACC juxtapose) ‘on a par’
ÖI×V% (corner-NOM remove) ‘become mature’
Ø#aÙ (lip-ACC bite) ‘bite one’s lip’
Ú#Û% (mouth-ACC cut) ‘break the ice’
Ú#LIbÜ% (mouth-ACC sharpen) ‘pout’
ÝIÞbOW (neck-NOM turn-NEG) ‘up to one’s neck’
Ý#Û% (neck-ACC cut) ‘give the axe’
Ý#ßà% (neck-ACC twist) ‘think hard’
á2g%L (thing-DAT depend) ‘perhaps’
!&amp;quot;#$% (sesame-ACC crush) ‘flatter’
â#ã~% (back-ACC train) ‘turn one’s back’
äIAX (blood-NOM flow) ‘humane’
å2æz (midair-DAT float) ‘’
çIºz (dirt-NOM attach) ‘be defeated in sumo wrestling’
èIéz (hand-NOM reach) ‘afford’ ‘reach an age’ ‘attentive’
èIOW (hand-NOM there.isn’t) ‘have no remedy’
èIêV% (hand-NOM get.away) ‘get one’s work done’
è2Å% (hand-DAT ride) ‘fall into someone’s trap’
è#«V% (hand-DAT insert) ‘obtain’
è#ë~% (hand-ACC hang) ‘give a lot of care’
è#Û% (hand-ACC cut) ‘break away’
è#×% (hand-ACC take) ‘give every possible help (to learn)’
è#ì% (hand-ACC grasp) ‘conclude an alliance’
è#í$ (hand-ACC stretch) ‘extend one’s business’
è#îÃ% (hand-ACC open.up) ‘extend one’s business’
è#Þ$ (hand-ACC turn) ‘take measures’
ï#ð$ (mountain.pass-ACC go.over) ‘get over the hump’
ñ#ò% (mud-ACC daub) ‘drag someone through mud’
ó2Å% (wave-DAT ride) ‘catch a wave’
ôIõö% (heat-NOM get.cool) ‘fever goes down’
ô#Ã% (heat-ACC raise) ‘go ape’
ô#«V% (heat-ACC feed.in) ‘enthuse’
÷#ø$ (root-ACC take.down) ‘take root’
÷#É% (root-ACC spread) ‘take root’
ùú2Å&amp;ûV% (bus-DAT miss) ‘miss the boat’
ùü#ý$ (baton-ACC give) ‘have someone succeed his position’
þÊIÿW (nasal.breathing-NOM heavy) ‘full of big talk’
þI�W (nose-NOM high) ‘proud’
þ##Fr% (nose-ACC break) ‘humble (someone)’
þ#u)Ab$ (nose-ACC make.a.sound) ‘make light of ...’
JR#4.4j% (belly-ACC cut) ‘have a heart-to-heart talk’
ik#W�% (teeth-ACC clench) ‘grit one’s teeth’
#X (human-ACC eat) ‘look down on someone’
��#Lb$ (spark-ACC spread) ‘fight heatedly’
w/o I (RER) w/ I (RER)
86.32 (17.68) 86.61 (19.45)
92.66 (80.45) 92.87 (81.02)
77.20 (17.96) 79.62 (26.68)
92.61 (67.01) 93.08 (69.13)
85.89 (66.77) 85.75 (66.45)
92.65 (76.68) 92.65 (76.69)
95.26 (76.03) 95.38 (76.59)
83.94 (61.89) 83.94 (61.89)
91.35 (31.99) 91.35 (31.99)
93.40 (60.83) 93.50 (61.45)
92.94 (56.69) 92.94 (56.69)
92.63 (44.70) 92.63 (44.70)
84.64 (53.71) 86.14 (58.23)
81.28 (37.41) 80.96 (36.31)
79.82 (28.91) 79.50 (27.80)
93.48 (18.51) 93.48 (18.51)
84.23 (40.91) 84.23 (40.91)
84.47 (63.85) 88.75 (73.80)
93.14 (44.15) 93.35 (45.84)
88.60 (26.49) 88.82 (27.93)
93.20 (35.97) 93.10 (34.97)
78.35 (49.13) 78.04 (48.39)
78.40 (25.78) 79.36 (29.10)
84.83 (68.73) 83.69 (66.36)
87.61 (9.40) 87.35 (7.47)
86.41 (59.28) 86.22 (58.71)
89.93 (78.15) 89.80 (77.88)
94.11 (13.85) 93.79 (9.23)
96.50 (89.35) 97.35 (91.94)
92.75 (85.42) 90.99 (81.88)
89.06 (67.14) 89.06 (67.14)
82.41 (64.70) 83.24 (66.37)
88.03 (71.46) 88.69 (73.03)
79.48 (24.97) 78.76 (22.33)
87.66 (35.85) 87.66 (35.85)
92.61 (43.38) 92.83 (45.06)
92.37 (83.59) 92.36 (83.57)
92.86 (81.68) 93.49 (83.30)
93.44 (85.99) 93.59 (86.29)
91.19 (70.04) 91.31 (70.46)
91.08 (78.83) 91.08 (78.83)
92.74 (34.67) 92.62 (33.56)
95.44 (51.93) 95.17 (49.16)
94.01 (42.69) 94.22 (44.72)
89.17 (63.26) 90.15 (66.57)
93.04 (77.64) 93.92 (80.49)
89.28 (61.46) 89.49 (62.23)
91.64 (67.38) 91.92 (68.45)
93.05 (49.55) 92.94 (48.74)
92.02 (21.00) 92.22 (23.00)
94.50 (26.45) 94.71 (29.21)
90.71 (37.80) 91.76 (44.88)
93.23 (52.21) 93.23 (52.21)
87.66 (69.15) 87.66 (69.15)
90.50 (58.74) 92.36 (66.81)
81.70 (47.23) 82.25 (48.81)
75.33 (47.77) 76.62 (50.50)
81.01 (61.81) 82.30 (64.42)
69.58 (29.91) 74.92 (42.20)
80.79 (56.63) 81.21 (57.57)
96.68 (24.16) 96.68 (24.16)
71.97 (18.66) 71.63 (17.66)
87.01 (48.15) 87.01 (48.15)
89.57 (56.56) 89.68 (57.00)
Base (Pos ; Neg)
</table>
<equation confidence="0.951097890625">
83.38 (286 ; 57)
62.45 (587 ; 353)
72.21 (184 ; 478)
77.59 (188 ; 651)
57.53 (420 ; 310)
68.47 (632 ; 291)
80.24 (727 ; 179)
57.87 (158 ; 217)
87.28 (796 ; 116)
83.14 (804 ; 163)
83.69 (196 ; 1006)
86.67 (507 ; 78)
66.83 (69 ; 139)
70.10 (366 ; 858)
71.61 (681 ; 270)
92.00 (770 ; 67)
73.32 (262 ; 720)
57.06 (481 ; 362)
87.72 (843 ; 118)
84.48 (697 ; 128)
89.38 (842 ; 100)
57.45 (370 ; 274)
70.89 (587 ; 241)
51.50 (210 ; 223)
86.33 (663 ; 105)
66.63 (619 ; 310)
53.90 (449 ; 384)
93.16 (885 ; 65)
67.15 (231 ; 113)
50.29 (87 ; 88)
66.70 (597 ; 298)
50.18 (422 ; 419)
58.07 (382 ; 529)
72.66 (70 ; 186)
80.76 (470 ; 112)
86.94 (799 ; 120)
53.49 (360 ; 414)
61.05 (372 ; 583)
53.21 (373 ; 328)
70.57 (241 ; 578)
57.85 (468 ; 341)
88.89 (91 ; 728)
90.51 (73 ; 696)
89.55 (95 ; 814)
70.52 (579 ; 242)
68.86 (246 ; 544)
72.18 (685 ; 264)
74.38 (543 ; 187)
86.23 (783 ; 125)
89.90 (890 ; 100)
92.52 (903 ; 73)
85.06 (723 ; 127)
85.83 (824 ; 136)
60.00 (564 ; 376)
76.97 (199 ; 665)
65.33 (471 ; 250)
52.77 (286 ; 256)
50.27 (659 ; 652)
56.60 (69 ; 90)
55.72 (536 ; 426)
95.62 (1265 ; 58)
65.54 (194 ; 102)
74.95 (727 ; 243)
75.99 (728 ; 230)
</equation>
<tableCaption confidence="0.991608">
Table 3: Individual Results (2/2)
</tableCaption>
<table confidence="0.999908296296296">
Type Base (Pos ; Neg) w/o I (RER) w/ I (RER)
�#«V% (painting.brush-ACC add) ‘correct (writings or paintings)’ 75.80 (213 ; 68) 83.99 (33.84) 84.70 (36.79)
�#`¸ (ship-ACC row) ‘nod’ 50.76 (167 ; 162) 75.82 (50.88) 76.37 (52.01)
ftI#FfV% (bone-NOM break) ‘have difficulty’ 62.30 (575 ; 348) 94.14 (84.46) 94.14 (84.47)
ft#1fö% (bone-ACC bury) ‘make it one’s final home’ 82.82 (757 ; 157) 89.84 (40.85) 90.60 (45.31)
ft##Ff% (bone-ACC break) ‘make efforts’ 60.89 (350 ; 545) 92.74 (81.43) 92.96 (82.01)
�IPAz (curtain-NOM open) ‘start’ 55.64 (533 ; 425) 86.32 (69.17) 86.22 (68.94)
;;tabk (right-FROM left) ‘passing through without staying’ 73.88 (794 ; 2246) 89.90 (61.34) 89.87 (61.21)
*LÆ (water-AND oil) ‘oil and water’ 55.66 (1053 ; 839) 83.19 (62.10) 85.84 (68.07)
*2@$ (water-DAT flush) ‘forgive and forget’ 67.08 (652 ; 320) 85.91 (57.19) 89.40 (67.81)
42º~% (body-DAT put.on) ‘learn’ 90.29 (725 ; 78) 96.51 (64.11) 96.39 (62.82)
$IÁW (ear-NOM ache) ‘make one’s ears burn’ 59.49 (333 ; 489) 88.69 (72.08) 89.54 (74.19)
$2«V% (ear-DAT insert) ‘get word of ...’ 74.89 (501 ; 168) 89.50 (58.20) 90.38 (61.67)
�#� (fruit-ACC bear) ‘bear fruit’ 89.39 (826 ; 98) 95.79 (60.33) 95.68 (59.31)
&amp;quot;IÁÙ (chest-NOM ache) ‘suffer heartache’ 93.59 (876 ; 60) 95.82 (34.78) 95.93 (36.46)
&amp;quot;IhibÙ (chest-NOM expand) ‘feel one’s heart leap’ 55.58 (338 ; 423) 94.08 (86.68) 94.48 (87.57)
&amp;quot;#TT (chest-ACC hit) ‘impress’ 92.39 (801 ; 66) 96.45 (53.34) 96.68 (56.39)
#I»% (germ-NOM come.out) ‘close to making the top’ 56.57 (377 ; 491) 91.33 (80.03) 91.55 (80.55)
IOW (eye-NOMthere.isn’t) ‘have a passion for ...’ 91.81 (829 ; 74) 95.70 (47.47) 95.25 (42.05)
nú#«V% (scalpel-ACC insert) ‘take drastic measures’ 88.96 (741 ; 92) 96.28 (66.30) 96.28 (66.30)
2«% (eye-DAT enter) ‘catch sight of ...’ 84.76 (623 ; 112) 90.22 (35.79) 91.16 (41.97)
#�X (eye-ACC cover) ‘be in a shambles’ 87.24 (725 ; 106) 91.45 (32.99) 92.06 (37.72)
#%t&amp;quot;$ (eye-ACC awake) ‘snap out of ..’ 83.26 (118 ; 587) 87.92 (27.85) 88.64 (32.12)
#% (eye-ACC close) ‘turn a blind eye’ 70.13 (533 ; 227) 90.26 (67.40) 90.26 (67.40)
#,tfz$% (eye-ACC thin) ‘one’s eyes light up’ 53.44 (115 ; 132) 75.20 (46.74) 75.11 (46.54)
#e#z�´% (finger-ACC suck) ‘look enviously’ 92.50 (876 ; 71) 95.68 (42.41) 95.58 (41.09)
FJ#Ñz (bow-ACC draw) ‘defy’ 88.06 (138 ; 1018) 95.51 (62.41) 95.43 (61.68)
</table>
<tableCaption confidence="0.998881">
Table 1: Overall Result
</tableCaption>
<bodyText confidence="0.978170571428572">
Base w/o I (RER) w/ I (RER)
72.92 88.86 (58.87) 89.25 (60.30)
the target idioms. The second column shows base-
line accuracy (%) and the numbers of positive and
negative examples for each idiom. The accuracy (%)
and relative error reduction (%) of the system with-
out the idiom-specific features are described in the
third column. The fourth column is those of the sys-
tem with the idiom features. Bold face indicates a
better performance.
All in all, we see relatively high baseline perfor-
mances. Nevertheless, both systems outperformed
the baseline. Especially, the system without the
idiom-specific features has a noticeable lead over the
baseline, showing that WSD technologies are effec-
tive in the idiom identification. Incorporating the id-
iom features into the system improved the overall
performance, which is statistically significant (Mc-
Nemar test, p&lt;0.01). But performances of some id-
ioms slightly degraded by the incorporation of the
idiom features.
</bodyText>
<tableCaption confidence="0.9168375">
Table 4: Overall Results without Using One of the Idiom
Features
</tableCaption>
<table confidence="0.9995915">
Feature Type Acc
All 89.25
−f8 (w/o Adnominal modification flag) 89.24
−f9 (w/o Topic case marking flag) 89.22
−f10 (w/o Voice alternation flag) 89.15
−f11 (w/o Negation flag) 89.17
−f12 (w/o Volitional modality flag) 89.19
−f13 (w/o Adjacency flag) 89.09
</table>
<bodyText confidence="0.73244075">
Table 4 shows overall results without using one of
the idiom features.21 As you see, the adjacency flag
(f13) contributes to idiom identification accuracy the
most.22 On the other hand, the adnominal modifica-
</bodyText>
<page confidence="0.782764">
23
</page>
<bodyText confidence="0.9915741">
tion flag (f8) contributes to the task only slightly.
21The first row shows the result with all idiom features used,
just for ease of reference.
22Note that greater performance drop indicates greater con-
tribution.
23This result is inconsistent with the result obtained in HSU,
where they reported that grammatical constraints involving ad-
nominal modification was most effective. This inconsistency
might be attributed to the differences of datasets being used for
idiom identification experiment. HSU used only 108 sentences
</bodyText>
<page confidence="0.998425">
999
</page>
<tableCaption confidence="0.998974">
Table 5: Results reported in CFS
</tableCaption>
<table confidence="0.99703975">
Accu RER
Baseline 61.9 Ñ
Unsupervised 72.4 27.6
Supervised 76.2 37.5
</table>
<bodyText confidence="0.995671666666667">
Table 5 shows the results reported in CFS. Their
baseline system regards all instances as idioms. The
performance of the supervised one is obtained by the
method of Katz and Giesbrecht (2006). Though we
cannot simply compare this with our results due to
the difference in experimental conditions, this im-
plies that our WSD-based method was equally good
or possibly better than their methods that are tailored
to MWEs.
</bodyText>
<sectionHeader confidence="0.999439" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999918105263158">
In this paper, we reported on the idiom corpus we
have constructed and the idiom identification exper-
iment using the corpus.
As mentioned in §4.3, some idioms are short of
examples in the current idiom corpus. We plan to
collect more examples by using different characters.
In the Japanese language, there are basically three
character systems: Hiragana, Katakana, and Chinese
characters. Thus, you can write an idiom in different
characters. For example, mune-o utu (chest-ACC hit)
‘impress’ can be either 94�kITS or 94;L-�S.
In spite of its imperfection, we are sure that we
can learn a lot about the idiom identification from
the corpus, since, as far as we know, it is the largest-
ever one, and so is the idiom identification experi-
ment reported in §5.
Also, we showed that a standard supervised WSD
method works well for the idiom identification.
Our system achieved the accuracy of 89.25% and
88.86% with/without idiom-specific features.
Though we dealt with as many as 90 idioms, prac-
tical NLP systems are required to deal with many
more idioms. Toward a scalable idiom identifica-
tion, we have to develop an unsupervised or semi-
supervised method. The unsupervised method of
for the experiment, while 75,011 sentences were used for our
experiment. Also, the dataset of HSU came from newspaper
articles, while our dataset came from the web.
Birke and Sarkar (2006) requires WordNet. Fortu-
nately, the Japanese WordNet is now available (Isa-
hara et al., 2008), thus we can try their method.
Also, CFS propose a language-independent unsu-
pervised method. These could be of help.
At any rate, our idiom corpus will play an im-
portant role in the development of unsupervised or
semi-supervised methods, and the experimental re-
sults obtained in this study will be a good reference
point to evaluate those methods.
</bodyText>
<sectionHeader confidence="0.996884" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9983705">
This work was conducted as a part of the collabora-
tive research project of Kyoto University and NTT
Communication Science Laboratories.
The work was supported from NTT Communica-
tion Science Laboratories and JSPS Grants-in-Aid
for Young Scientists (B) 19700141.
We would like to thank the members of the collab-
orative research group of Kyoto University and NTT
Communication Science Laboratories and Francis
Bond for their stimulating discussion. Our thanks
go as well to Prof. Sato Satoshi, who kindly gave us
the list of basic idioms of Japanese.
</bodyText>
<sectionHeader confidence="0.997862" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998391166666667">
Timothy Baldwin, Colin Bannard, Takaaki Tanaka, and
Dominic Widdows. 2003. An empirical model of
multiword expression decomposability. In Proceed-
ings of the ACL 2003 workshop on Multiword expres-
sions, pages 89–96.
Julia Birke and Anoop Sarkar. 2006. A clustering
approach for the nearly unsupervised recoginition of
nonliteral language. In Proceedings of the 11th Con-
ference of the European Chapter of the Association for
Computational Linguistics (EACL 2006), pages 329–
336.
Paul Cook, Afsaneh Fazly, and Suzanne Stevenson.
2007. Pulling their weight: Exploiting syntactic forms
for the automatic identification of idiomatic expres-
sions in context. In Proceedings of the ACL 2007
Workshop on A Broader Perspective on Multiword Ex-
pressions, pages 41–48.
Paul Cook, Afsaneh Fazly, and Suzanne Stevenson.
2008. The VNC-Tokens Dataset. In Proceedings of
the LREC Workshop Towards a Shared Task for Multi-
word Expressions (MWE2008), pages 19–22.
Afsaneh Fazly and Suzanne Stevenson. 2006. Automat-
ically constructing a lexicon of verb phrase idiomatic
combinations. In Proceedings of the 11th Conference
</reference>
<page confidence="0.532211">
1000
</page>
<reference confidence="0.999821770833333">
of the European Chapter of the Association for Com-
putational Linguistics (EACL-2006), pages 337–344.
Nicole Gr«egoire, Stefan Evert, and Su Nam Kim, editors.
2007. Proceedings of the Workshop on A Broader Per-
spective on Multiword Expressions. Association for
Computational Linguistics, Prague.
Nicole Gr«egoire, Stefan Evert, and Brigitte Krenn, edi-
tors. 2008. Proceedings of the LREC Workshop To-
wards a Shared Task for Multiword Expressions. ACL
Special Interest Group on the Lexicon (SIGLEX),
Marrakech.
Chikara Hashimoto and Sadao Kurohashi. 2007. Con-
struction of Domain Dictionary for Fundamental Vo-
cabulary. In Proceedings of the 45th Annual Meet-
ing of the Association for Computational Linguistics
(ACL’07) Poster, pages 137–140.
Chikara Hashimoto and Sadao Kurohashi. 2008. Blog
Categorization Exploiting Domain Dictionary and Dy-
namically Estimated Domains of Unknown Words. In
Proceedings of the 46th Annual Meeting of the Asso-
ciation for Computational Linguistics (ACL’08) Short
paper, Poster, pages 69–72.
Chikara Hashimoto, Satoshi Sato, and Takehito Utsuro.
2006a. Detecting Japanese idioms with a linguistically
rich dictionary. Language Resources and Evaluation,
40(3–4):243–252.
Chikara Hashimoto, Satoshi Sato, and Takehito Utsuro.
2006b. Japanese Idiom Recognition: Drawing a Line
between Literal and Idiomatic Meanings. In The Joint
21st International Conference on Computational Lin-
guistics and 44th Annual Meeting of the Association
for Computational Linguistics (COLING/ACL 2006)
Poster, pages 353–360, Sydney, July.
Hitoshi Isahara, Francis Bond, Kiyotaka Uchimoto,
Masao Utiyama, and Kyoko Kanzaki. 2008. Devel-
opment of the Japanese WordNet. In The sixth inter-
national conference on Language Resources and Eval-
uation (LREC2008).
Graham Katz and Eugenie Giesbrecht. 2006. Auto-
matic identification of non-compositional multi-word
expressions using latent semantic analysis. In Pro-
ceedings of the Workshop, COLING/ACL 2006, Multi-
word Expressions: Identifying and Exploiting Under-
lying Properties, pages 12–19, July.
Daisuke Kawahara and Sadao Kurohashi. 2006.
Case Frame Compilation from the Web using High-
Performance Computing. In Proceedings of The 5th
International Conference on Language Resources and
Evaluation (LREC-06), pages 1344–1347.
Brigitte Krenn and Stefan Evert. 2001. Can we do better
than frequency? a case study on extracting pp-verb
collocations. In Proceedings of the ACL-01 Workshop
on Collocations, pages 39–46.
Yoong Keok Lee and Hwee Tou Ng. 2002. An empir-
ical evaluation of knowledge sources and learning al-
gorithms for word sense disambiguation. In EMNLP
’02: Proceedings of the ACL-02 conference on Em-
pirical methods in natural language processing, pages
41–48.
Dekang Lin. 1999. Automatic identification of non-
compositional phrases. In Proceeding of the 37th An-
nual Meeting of the Association for Computational
Linguistics, pages 317–324.
Bernardo Magnini, Carlo Strapparava, Giovanni Pezzulo,
and Alfio Gliozzo. 2002. The Role of Domain Infor-
mation in Word Sense Disambiguation. Natural Lan-
guage Engineering, special issue on Word Sense Dis-
ambiguation, 8(3):359–373.
Satoshi Sato. 2007. Compilation of a comparative list
of basic Japanese idioms from five sources. In IPSJ
2007-NL-178, pages 1–6. (in Japanese).
Kosho Shudo, Toshifumi Tanabe, Masahito Takahashi,
and Kenji Yoshimura. 2004. MWEs as Non-
propositional Content Indicators. In the 2nd ACL
Workshop on Multiword Expressions: Integrating Pro-
cessing, pages 32–39.
Takaaki Tanaka, Francis Bond, Timothy Baldwin, Sanae
Fujita, and Chikara Hashimoto. 2007. Word Sense
Disambiguation Incorporating Lexical and Structural
Semantic Information. In Proceedings of the 2007
Joint Conference on Empirical Methods in Natu-
ral Language Processing and Computational Natu-
ral Language Learning (EMNLP-CoNLL), pages 477–
485.
Masatoshi Tsuchiya, Takehito Utsuro, Suguru Mat-
suyoshi, Satoshi Sato, and Seiichi Nakagawa. 2006.
Development and analysis of an example database of
Japanese compound functional expressions. Trans-
actions of Information Processing Society of Japan,
47(6):1728–1741. (in Japanese).
Kiyoko Uchiyama, Timothy Baldwin, and Shun Ishizaki.
2005. Disambiguating Japanese compound verbs.
Computer Speech and Language, Special Issue on
Multiword Expressions, 19(4):497–512.
Vladimir Vapnik. 1995. The Nature of Statistical Learn-
ing Theory. Springer-Verlag, New York.
</reference>
<page confidence="0.988098">
1001
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.347017">
<title confidence="0.998802">Construction of an Idiom Corpus and its Application to Idiom Identification based on WSD incorporating Idiom-Specific Features</title>
<author confidence="0.811292">Chikara</author>
<affiliation confidence="0.796958">Graduate School of Science and Yamagata</affiliation>
<address confidence="0.999708">Yonezawa, Yamagata, 992-8510,</address>
<email confidence="0.980222">ch@yz.yamagata-u.ac.jp</email>
<author confidence="0.931274">Daisuke Kawahara</author>
<affiliation confidence="0.9012415">National Institute of Information Communications</affiliation>
<address confidence="0.912568">Sorakugun, Kyoto, 619-0289,</address>
<email confidence="0.983997">dk@nict.go.jp</email>
<abstract confidence="0.99971516">Some phrases can be interpreted either idiomatically (figuratively) or literally in context, and the precise identification of idioms is indispensable for full-fledged natural language processing (NLP). To this end, we have constructed an idiom corpus for Japanese. This paper reports on the corpus and the results of an idiom identification experiment using the corpus. The corpus targets 146 ambiguous idioms, and consists of 102,846 sentences, each of which is annotated with a literal/idiom label. For idiom identification, we targeted 90 out of the 146 idioms and adopted a word sense disambiguation (WSD) method using both common WSD features and idiomspecific features. The corpus and the experiment are the largest of their kind, as far as we know. As a result, we found that a standard supervised WSD method works well for the idiom identification and achieved an accuracy of 89.25% and 88.86% with/without idiomspecific features and that the most effective idiom-specific feature is the one involving the adjacency of idiom constituents.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Timothy Baldwin</author>
<author>Colin Bannard</author>
<author>Takaaki Tanaka</author>
<author>Dominic Widdows</author>
</authors>
<title>An empirical model of multiword expression decomposability.</title>
<date>2003</date>
<booktitle>In Proceedings of the ACL 2003 workshop on Multiword expressions,</booktitle>
<pages>89--96</pages>
<contexts>
<context position="6462" citStr="Baldwin et al., 2003" startWordPosition="1025" endWordPosition="1028">or “on the occasion of (something).” The former is the literal interpretation and the latter is the idiomatic interpretation of the compound functional expression. The SAID dataset5 provides data about the syntactic flexibility of English idioms. It does not concern itself with idiom token identification. However, as in Hashimoto et al. (2006b), Hashimoto et al. (2006a) and Cook et al. (2007) among others, the syntactic behavior of idioms is an important clue to idiom token identification. Previous studies have mostly focused on the idiom type identification (Lin, 1999; Krenn and Evert, 2001; Baldwin et al., 2003; Shudo et al., 2004; Fazly and Stevenson, 2006). However, there has been a growing interest in idiom token identification in recent times (Katz and Giesbrecht, 2006; Hashimoto et al., 2006b; Hashimoto et al., 2006a; Birke and Sarkar, 2006; Cook et al., 2007). Katz and Giesbrecht (2006) compared the word vector of an idiom in context and that of the constituent words of the idiom using LSA in order to determine if the expression is idiomatic. Hashimoto et al. (2006b) and Hashimoto et al. (2006a) (HSU henceforth) focused their attention on the differences in grammatical constraints imposed on i</context>
</contexts>
<marker>Baldwin, Bannard, Tanaka, Widdows, 2003</marker>
<rawString>Timothy Baldwin, Colin Bannard, Takaaki Tanaka, and Dominic Widdows. 2003. An empirical model of multiword expression decomposability. In Proceedings of the ACL 2003 workshop on Multiword expressions, pages 89–96.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julia Birke</author>
<author>Anoop Sarkar</author>
</authors>
<title>A clustering approach for the nearly unsupervised recoginition of nonliteral language.</title>
<date>2006</date>
<booktitle>In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics (EACL</booktitle>
<pages>329--336</pages>
<contexts>
<context position="4407" citStr="Birke and Sarkar (2006)" startWordPosition="707" endWordPosition="710">ional Linguistics ther “punch,” “steal” or “make moves on.” This kind of ambiguity should be placed on the agenda. We do not tackle the problem of what constitutes the notion of “idiom.” We simply regard phrases listed in Sato (2007) as idioms. The reminder of this paper is organized as follows. In §2 we present related works. §3 shows the target idioms. After the idiom corpus is described in §4, we detail our idiom identification method and experiment in §5. Finally §6 concludes the paper. 2 Related Work There have only been a few works on the construction of an idiom corpus. In this regard, Birke and Sarkar (2006) and Cook et al. (2008) are notable exceptions. Birke and Sarkar (2006) automatically constructed a corpus of English idiomatic expressions (words that can be used non-literally). They targeted 50 expressions and collected about 6,600 examples. They call the corpus TroFi Example Base, which is available on the Web.2 Cook et al. (2008) compiled a corpus of English verbnoun combinations (VNCs) tokens. Their corpus deals with 53 VNC expressions and consists of about 3,000 example sentences. Like ours, they assigned each example with a label indicating whether an expression in the example is used </context>
<context position="6701" citStr="Birke and Sarkar, 2006" startWordPosition="1065" endWordPosition="1068">h idioms. It does not concern itself with idiom token identification. However, as in Hashimoto et al. (2006b), Hashimoto et al. (2006a) and Cook et al. (2007) among others, the syntactic behavior of idioms is an important clue to idiom token identification. Previous studies have mostly focused on the idiom type identification (Lin, 1999; Krenn and Evert, 2001; Baldwin et al., 2003; Shudo et al., 2004; Fazly and Stevenson, 2006). However, there has been a growing interest in idiom token identification in recent times (Katz and Giesbrecht, 2006; Hashimoto et al., 2006b; Hashimoto et al., 2006a; Birke and Sarkar, 2006; Cook et al., 2007). Katz and Giesbrecht (2006) compared the word vector of an idiom in context and that of the constituent words of the idiom using LSA in order to determine if the expression is idiomatic. Hashimoto et al. (2006b) and Hashimoto et al. (2006a) (HSU henceforth) focused their attention on the differences in grammatical constraints imposed on idioms and their literal counterparts such as the possibility of passivization, and developed handcrafted rules for Japanese idiom identification. Although their task is exactly the same as ours and we draw on the grammatical knowledge prov</context>
<context position="34169" citStr="Birke and Sarkar (2006)" startWordPosition="5529" endWordPosition="5532">ted in §5. Also, we showed that a standard supervised WSD method works well for the idiom identification. Our system achieved the accuracy of 89.25% and 88.86% with/without idiom-specific features. Though we dealt with as many as 90 idioms, practical NLP systems are required to deal with many more idioms. Toward a scalable idiom identification, we have to develop an unsupervised or semisupervised method. The unsupervised method of for the experiment, while 75,011 sentences were used for our experiment. Also, the dataset of HSU came from newspaper articles, while our dataset came from the web. Birke and Sarkar (2006) requires WordNet. Fortunately, the Japanese WordNet is now available (Isahara et al., 2008), thus we can try their method. Also, CFS propose a language-independent unsupervised method. These could be of help. At any rate, our idiom corpus will play an important role in the development of unsupervised or semi-supervised methods, and the experimental results obtained in this study will be a good reference point to evaluate those methods. Acknowledgments This work was conducted as a part of the collaborative research project of Kyoto University and NTT Communication Science Laboratories. The wor</context>
</contexts>
<marker>Birke, Sarkar, 2006</marker>
<rawString>Julia Birke and Anoop Sarkar. 2006. A clustering approach for the nearly unsupervised recoginition of nonliteral language. In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics (EACL 2006), pages 329– 336.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Cook</author>
<author>Afsaneh Fazly</author>
<author>Suzanne Stevenson</author>
</authors>
<title>Pulling their weight: Exploiting syntactic forms for the automatic identification of idiomatic expressions in context.</title>
<date>2007</date>
<booktitle>In Proceedings of the ACL 2007 Workshop on A Broader Perspective on Multiword Expressions,</booktitle>
<pages>41--48</pages>
<contexts>
<context position="6237" citStr="Cook et al. (2007)" startWordPosition="989" endWordPosition="992">NEG represents a verbal negation morpheme. 2http://www.cs.sfu.ca/-anoop/students/jbirke/ 3http://nlp.iit.tsukuba.ac.jp/must/ 4For example, (something)-ni-atatte ((something)-DATrun.into) means either “run into (something)” or “on the occasion of (something).” The former is the literal interpretation and the latter is the idiomatic interpretation of the compound functional expression. The SAID dataset5 provides data about the syntactic flexibility of English idioms. It does not concern itself with idiom token identification. However, as in Hashimoto et al. (2006b), Hashimoto et al. (2006a) and Cook et al. (2007) among others, the syntactic behavior of idioms is an important clue to idiom token identification. Previous studies have mostly focused on the idiom type identification (Lin, 1999; Krenn and Evert, 2001; Baldwin et al., 2003; Shudo et al., 2004; Fazly and Stevenson, 2006). However, there has been a growing interest in idiom token identification in recent times (Katz and Giesbrecht, 2006; Hashimoto et al., 2006b; Hashimoto et al., 2006a; Birke and Sarkar, 2006; Cook et al., 2007). Katz and Giesbrecht (2006) compared the word vector of an idiom in context and that of the constituent words of th</context>
<context position="7511" citStr="Cook et al. (2007)" startWordPosition="1204" endWordPosition="1207">n is idiomatic. Hashimoto et al. (2006b) and Hashimoto et al. (2006a) (HSU henceforth) focused their attention on the differences in grammatical constraints imposed on idioms and their literal counterparts such as the possibility of passivization, and developed handcrafted rules for Japanese idiom identification. Although their task is exactly the same as ours and we draw on the grammatical knowledge provided by them, the scale of their experiment is very small, since only 108 sentences were used for idiom identification in their paper. Further, unlike HSU, we employ matured WSD technologies. Cook et al. (2007) (CFS henceforth) propose an unsupervised method for English on the basis of the observation that idioms tend to be expressed in a small number of fixed forms. These studies used only the characteristics of idioms (or MWEs). On the other hand, we exploit a WSD method, for which there have been many studies and matured technologies, in addition to the characteristics of idioms. Birke and Sarkar (2006) also used WSD. However, they employed an unsupervised method, while ours is a completely supervised one. Apart from idioms, Uchiyama et al. (2005) conducted the token classification of Japanese co</context>
</contexts>
<marker>Cook, Fazly, Stevenson, 2007</marker>
<rawString>Paul Cook, Afsaneh Fazly, and Suzanne Stevenson. 2007. Pulling their weight: Exploiting syntactic forms for the automatic identification of idiomatic expressions in context. In Proceedings of the ACL 2007 Workshop on A Broader Perspective on Multiword Expressions, pages 41–48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Cook</author>
<author>Afsaneh Fazly</author>
<author>Suzanne Stevenson</author>
</authors>
<title>The VNC-Tokens Dataset.</title>
<date>2008</date>
<booktitle>In Proceedings of the LREC Workshop Towards a Shared Task for Multiword Expressions (MWE2008),</booktitle>
<pages>pages</pages>
<contexts>
<context position="4430" citStr="Cook et al. (2008)" startWordPosition="712" endWordPosition="715">h,” “steal” or “make moves on.” This kind of ambiguity should be placed on the agenda. We do not tackle the problem of what constitutes the notion of “idiom.” We simply regard phrases listed in Sato (2007) as idioms. The reminder of this paper is organized as follows. In §2 we present related works. §3 shows the target idioms. After the idiom corpus is described in §4, we detail our idiom identification method and experiment in §5. Finally §6 concludes the paper. 2 Related Work There have only been a few works on the construction of an idiom corpus. In this regard, Birke and Sarkar (2006) and Cook et al. (2008) are notable exceptions. Birke and Sarkar (2006) automatically constructed a corpus of English idiomatic expressions (words that can be used non-literally). They targeted 50 expressions and collected about 6,600 examples. They call the corpus TroFi Example Base, which is available on the Web.2 Cook et al. (2008) compiled a corpus of English verbnoun combinations (VNCs) tokens. Their corpus deals with 53 VNC expressions and consists of about 3,000 example sentences. Like ours, they assigned each example with a label indicating whether an expression in the example is used literally or idiomatica</context>
</contexts>
<marker>Cook, Fazly, Stevenson, 2008</marker>
<rawString>Paul Cook, Afsaneh Fazly, and Suzanne Stevenson. 2008. The VNC-Tokens Dataset. In Proceedings of the LREC Workshop Towards a Shared Task for Multiword Expressions (MWE2008), pages 19–22.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Afsaneh Fazly</author>
<author>Suzanne Stevenson</author>
</authors>
<title>Automatically constructing a lexicon of verb phrase idiomatic combinations.</title>
<date>2006</date>
<booktitle>In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics (EACL-2006),</booktitle>
<pages>337--344</pages>
<contexts>
<context position="6510" citStr="Fazly and Stevenson, 2006" startWordPosition="1033" endWordPosition="1037">ormer is the literal interpretation and the latter is the idiomatic interpretation of the compound functional expression. The SAID dataset5 provides data about the syntactic flexibility of English idioms. It does not concern itself with idiom token identification. However, as in Hashimoto et al. (2006b), Hashimoto et al. (2006a) and Cook et al. (2007) among others, the syntactic behavior of idioms is an important clue to idiom token identification. Previous studies have mostly focused on the idiom type identification (Lin, 1999; Krenn and Evert, 2001; Baldwin et al., 2003; Shudo et al., 2004; Fazly and Stevenson, 2006). However, there has been a growing interest in idiom token identification in recent times (Katz and Giesbrecht, 2006; Hashimoto et al., 2006b; Hashimoto et al., 2006a; Birke and Sarkar, 2006; Cook et al., 2007). Katz and Giesbrecht (2006) compared the word vector of an idiom in context and that of the constituent words of the idiom using LSA in order to determine if the expression is idiomatic. Hashimoto et al. (2006b) and Hashimoto et al. (2006a) (HSU henceforth) focused their attention on the differences in grammatical constraints imposed on idioms and their literal counterparts such as the</context>
</contexts>
<marker>Fazly, Stevenson, 2006</marker>
<rawString>Afsaneh Fazly and Suzanne Stevenson. 2006. Automatically constructing a lexicon of verb phrase idiomatic combinations. In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics (EACL-2006), pages 337–344.</rawString>
</citation>
<citation valid="true">
<date>2007</date>
<booktitle>Proceedings of the Workshop on A Broader Perspective on Multiword Expressions. Association for Computational Linguistics,</booktitle>
<editor>Nicole Gr«egoire, Stefan Evert, and Su Nam Kim, editors.</editor>
<location>Prague.</location>
<contexts>
<context position="4017" citStr="(2007)" startWordPosition="639" endWordPosition="639">ontext. For example, a Japanese idiom te-o dasu (hand-ACC stretch)1 can be interpreted as ei1ACC is the accusative case marker. Likewise we use the following notation in this paper; NOM for the nominative case 992 Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 992–1001, Honolulu, October 2008. c�2008 Association for Computational Linguistics ther “punch,” “steal” or “make moves on.” This kind of ambiguity should be placed on the agenda. We do not tackle the problem of what constitutes the notion of “idiom.” We simply regard phrases listed in Sato (2007) as idioms. The reminder of this paper is organized as follows. In §2 we present related works. §3 shows the target idioms. After the idiom corpus is described in §4, we detail our idiom identification method and experiment in §5. Finally §6 concludes the paper. 2 Related Work There have only been a few works on the construction of an idiom corpus. In this regard, Birke and Sarkar (2006) and Cook et al. (2008) are notable exceptions. Birke and Sarkar (2006) automatically constructed a corpus of English idiomatic expressions (words that can be used non-literally). They targeted 50 expressions a</context>
<context position="6237" citStr="(2007)" startWordPosition="992" endWordPosition="992">ts a verbal negation morpheme. 2http://www.cs.sfu.ca/-anoop/students/jbirke/ 3http://nlp.iit.tsukuba.ac.jp/must/ 4For example, (something)-ni-atatte ((something)-DATrun.into) means either “run into (something)” or “on the occasion of (something).” The former is the literal interpretation and the latter is the idiomatic interpretation of the compound functional expression. The SAID dataset5 provides data about the syntactic flexibility of English idioms. It does not concern itself with idiom token identification. However, as in Hashimoto et al. (2006b), Hashimoto et al. (2006a) and Cook et al. (2007) among others, the syntactic behavior of idioms is an important clue to idiom token identification. Previous studies have mostly focused on the idiom type identification (Lin, 1999; Krenn and Evert, 2001; Baldwin et al., 2003; Shudo et al., 2004; Fazly and Stevenson, 2006). However, there has been a growing interest in idiom token identification in recent times (Katz and Giesbrecht, 2006; Hashimoto et al., 2006b; Hashimoto et al., 2006a; Birke and Sarkar, 2006; Cook et al., 2007). Katz and Giesbrecht (2006) compared the word vector of an idiom in context and that of the constituent words of th</context>
<context position="7511" citStr="(2007)" startWordPosition="1207" endWordPosition="1207">ic. Hashimoto et al. (2006b) and Hashimoto et al. (2006a) (HSU henceforth) focused their attention on the differences in grammatical constraints imposed on idioms and their literal counterparts such as the possibility of passivization, and developed handcrafted rules for Japanese idiom identification. Although their task is exactly the same as ours and we draw on the grammatical knowledge provided by them, the scale of their experiment is very small, since only 108 sentences were used for idiom identification in their paper. Further, unlike HSU, we employ matured WSD technologies. Cook et al. (2007) (CFS henceforth) propose an unsupervised method for English on the basis of the observation that idioms tend to be expressed in a small number of fixed forms. These studies used only the characteristics of idioms (or MWEs). On the other hand, we exploit a WSD method, for which there have been many studies and matured technologies, in addition to the characteristics of idioms. Birke and Sarkar (2006) also used WSD. However, they employed an unsupervised method, while ours is a completely supervised one. Apart from idioms, Uchiyama et al. (2005) conducted the token classification of Japanese co</context>
<context position="10820" citStr="(2007)" startWordPosition="1766" endWordPosition="1766">a literal meaning. They are not dealt with in this paper. whether the corresponding phrase in the example is used as an idiom or a literal phrase. We call the former the positive example and the latter the negative example. More specifically, the corpus consists of lines that each represent one example. A line consists of four fields as follows: 1 Label indicates whether the example is positive or negative. Label i is used for positive examples and l for negative ones. 2 ID denotes the idiom that is included in the example. In this study, each idiom has a unique number, which is based on Sato (2007). 3 Lemma also shows the idiom in the example. We assigned each idiom its canonical (or standard) form on the basis of Sato (2007). 4 Example is the example itself. Given below is a sample of a negative example of goma-o suru (sesame-ACC crush) ’flatter’. • l 1417 !&amp;quot;#$% $&amp;&apos;(!&amp;quot;#$&amp; ··· The third field is the lemma of the idiom. The last one is the example that says ’crushing sesame in a mortar...’ Before working on the corpus construction, we prepared a reference by which human annotators could consistently distinguish between the literal and figurative meanings of idioms. To be more precise, th</context>
</contexts>
<marker>2007</marker>
<rawString>Nicole Gr«egoire, Stefan Evert, and Su Nam Kim, editors. 2007. Proceedings of the Workshop on A Broader Perspective on Multiword Expressions. Association for Computational Linguistics, Prague.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicole Gr«egoire</author>
<author>Stefan Evert</author>
<author>Brigitte Krenn</author>
<author>editors</author>
</authors>
<date>2008</date>
<booktitle>Proceedings of the LREC Workshop Towards a Shared Task for Multiword Expressions. ACL Special Interest Group on the Lexicon (SIGLEX),</booktitle>
<location>Marrakech.</location>
<marker>Gr«egoire, Evert, Krenn, editors, 2008</marker>
<rawString>Nicole Gr«egoire, Stefan Evert, and Brigitte Krenn, editors. 2008. Proceedings of the LREC Workshop Towards a Shared Task for Multiword Expressions. ACL Special Interest Group on the Lexicon (SIGLEX), Marrakech.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chikara Hashimoto</author>
<author>Sadao Kurohashi</author>
</authors>
<title>Construction of Domain Dictionary for Fundamental Vocabulary.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics (ACL’07) Poster,</booktitle>
<pages>137--140</pages>
<contexts>
<context position="17594" citStr="Hashimoto and Kurohashi, 2007" startWordPosition="2852" endWordPosition="2856">g those words that are the dependents of the leftmost constituent word of idiom13 f4b: POS of the rightmost word among those words that are the dependents of the leftmost constituent word of idiom f5a: Lemma of the word which the rightmost constituent word of idiom is the dependent of 12Remember that HSU implemented them in handcrafted rules. We adapted them to a machine learning framework. 13Note that Japanese is a head final language. f5b: POS of the word which the rightmost constituent word of idiom is the dependent of f6: Hypernyms of words in the surrounding context f7: Domains of words (Hashimoto and Kurohashi, 2007; Hashimoto and Kurohashi, 2008) in the surrounding context • Idiom-Specific Features f8: Adnominal modification flag f9: Topic case marking flag f10: Voice alternation flag f11: Negation flag f12: Volitional modality flag f13: Adjacency flag We used JUMAN,14 a morphological analyzer of Japanese, and KNP to extract these features. 14http://nlp.kuee.kyoto-u.ac.jp/nl-resource/juman.html 996 f2 and f3 are the same as those described in LN. But f1 is slightly different in that we did not use the Po of LN. f4 and f5 roughly correspond to the syntactic relations of LN. We adapted it to Japanese idio</context>
</contexts>
<marker>Hashimoto, Kurohashi, 2007</marker>
<rawString>Chikara Hashimoto and Sadao Kurohashi. 2007. Construction of Domain Dictionary for Fundamental Vocabulary. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics (ACL’07) Poster, pages 137–140.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chikara Hashimoto</author>
<author>Sadao Kurohashi</author>
</authors>
<title>Blog Categorization Exploiting Domain Dictionary and Dynamically Estimated Domains of Unknown Words.</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics (ACL’08) Short paper, Poster,</booktitle>
<pages>69--72</pages>
<contexts>
<context position="17626" citStr="Hashimoto and Kurohashi, 2008" startWordPosition="2857" endWordPosition="2860">ndents of the leftmost constituent word of idiom13 f4b: POS of the rightmost word among those words that are the dependents of the leftmost constituent word of idiom f5a: Lemma of the word which the rightmost constituent word of idiom is the dependent of 12Remember that HSU implemented them in handcrafted rules. We adapted them to a machine learning framework. 13Note that Japanese is a head final language. f5b: POS of the word which the rightmost constituent word of idiom is the dependent of f6: Hypernyms of words in the surrounding context f7: Domains of words (Hashimoto and Kurohashi, 2007; Hashimoto and Kurohashi, 2008) in the surrounding context • Idiom-Specific Features f8: Adnominal modification flag f9: Topic case marking flag f10: Voice alternation flag f11: Negation flag f12: Volitional modality flag f13: Adjacency flag We used JUMAN,14 a morphological analyzer of Japanese, and KNP to extract these features. 14http://nlp.kuee.kyoto-u.ac.jp/nl-resource/juman.html 996 f2 and f3 are the same as those described in LN. But f1 is slightly different in that we did not use the Po of LN. f4 and f5 roughly correspond to the syntactic relations of LN. We adapted it to Japanese idioms along with some simplificatio</context>
</contexts>
<marker>Hashimoto, Kurohashi, 2008</marker>
<rawString>Chikara Hashimoto and Sadao Kurohashi. 2008. Blog Categorization Exploiting Domain Dictionary and Dynamically Estimated Domains of Unknown Words. In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics (ACL’08) Short paper, Poster, pages 69–72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chikara Hashimoto</author>
<author>Satoshi Sato</author>
<author>Takehito Utsuro</author>
</authors>
<title>Detecting Japanese idioms with a linguistically rich dictionary. Language Resources and Evaluation,</title>
<date>2006</date>
<pages>40--3</pages>
<contexts>
<context position="6186" citStr="Hashimoto et al. (2006" startWordPosition="980" endWordPosition="983"> TO stand for the Japanese counterparts offrom and to. NEG represents a verbal negation morpheme. 2http://www.cs.sfu.ca/-anoop/students/jbirke/ 3http://nlp.iit.tsukuba.ac.jp/must/ 4For example, (something)-ni-atatte ((something)-DATrun.into) means either “run into (something)” or “on the occasion of (something).” The former is the literal interpretation and the latter is the idiomatic interpretation of the compound functional expression. The SAID dataset5 provides data about the syntactic flexibility of English idioms. It does not concern itself with idiom token identification. However, as in Hashimoto et al. (2006b), Hashimoto et al. (2006a) and Cook et al. (2007) among others, the syntactic behavior of idioms is an important clue to idiom token identification. Previous studies have mostly focused on the idiom type identification (Lin, 1999; Krenn and Evert, 2001; Baldwin et al., 2003; Shudo et al., 2004; Fazly and Stevenson, 2006). However, there has been a growing interest in idiom token identification in recent times (Katz and Giesbrecht, 2006; Hashimoto et al., 2006b; Hashimoto et al., 2006a; Birke and Sarkar, 2006; Cook et al., 2007). Katz and Giesbrecht (2006) compared the word vector of an idiom</context>
</contexts>
<marker>Hashimoto, Sato, Utsuro, 2006</marker>
<rawString>Chikara Hashimoto, Satoshi Sato, and Takehito Utsuro. 2006a. Detecting Japanese idioms with a linguistically rich dictionary. Language Resources and Evaluation, 40(3–4):243–252.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chikara Hashimoto</author>
<author>Satoshi Sato</author>
<author>Takehito Utsuro</author>
</authors>
<title>Japanese Idiom Recognition: Drawing a Line between Literal and Idiomatic Meanings.</title>
<date>2006</date>
<booktitle>In The Joint 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics (COLING/ACL 2006) Poster,</booktitle>
<pages>353--360</pages>
<location>Sydney,</location>
<contexts>
<context position="6186" citStr="Hashimoto et al. (2006" startWordPosition="980" endWordPosition="983"> TO stand for the Japanese counterparts offrom and to. NEG represents a verbal negation morpheme. 2http://www.cs.sfu.ca/-anoop/students/jbirke/ 3http://nlp.iit.tsukuba.ac.jp/must/ 4For example, (something)-ni-atatte ((something)-DATrun.into) means either “run into (something)” or “on the occasion of (something).” The former is the literal interpretation and the latter is the idiomatic interpretation of the compound functional expression. The SAID dataset5 provides data about the syntactic flexibility of English idioms. It does not concern itself with idiom token identification. However, as in Hashimoto et al. (2006b), Hashimoto et al. (2006a) and Cook et al. (2007) among others, the syntactic behavior of idioms is an important clue to idiom token identification. Previous studies have mostly focused on the idiom type identification (Lin, 1999; Krenn and Evert, 2001; Baldwin et al., 2003; Shudo et al., 2004; Fazly and Stevenson, 2006). However, there has been a growing interest in idiom token identification in recent times (Katz and Giesbrecht, 2006; Hashimoto et al., 2006b; Hashimoto et al., 2006a; Birke and Sarkar, 2006; Cook et al., 2007). Katz and Giesbrecht (2006) compared the word vector of an idiom</context>
</contexts>
<marker>Hashimoto, Sato, Utsuro, 2006</marker>
<rawString>Chikara Hashimoto, Satoshi Sato, and Takehito Utsuro. 2006b. Japanese Idiom Recognition: Drawing a Line between Literal and Idiomatic Meanings. In The Joint 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics (COLING/ACL 2006) Poster, pages 353–360, Sydney, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hitoshi Isahara</author>
<author>Francis Bond</author>
<author>Kiyotaka Uchimoto</author>
<author>Masao Utiyama</author>
<author>Kyoko Kanzaki</author>
</authors>
<title>Development of the Japanese WordNet.</title>
<date>2008</date>
<booktitle>In The sixth international conference on Language Resources and Evaluation (LREC2008).</booktitle>
<contexts>
<context position="34261" citStr="Isahara et al., 2008" startWordPosition="5543" endWordPosition="5547">tification. Our system achieved the accuracy of 89.25% and 88.86% with/without idiom-specific features. Though we dealt with as many as 90 idioms, practical NLP systems are required to deal with many more idioms. Toward a scalable idiom identification, we have to develop an unsupervised or semisupervised method. The unsupervised method of for the experiment, while 75,011 sentences were used for our experiment. Also, the dataset of HSU came from newspaper articles, while our dataset came from the web. Birke and Sarkar (2006) requires WordNet. Fortunately, the Japanese WordNet is now available (Isahara et al., 2008), thus we can try their method. Also, CFS propose a language-independent unsupervised method. These could be of help. At any rate, our idiom corpus will play an important role in the development of unsupervised or semi-supervised methods, and the experimental results obtained in this study will be a good reference point to evaluate those methods. Acknowledgments This work was conducted as a part of the collaborative research project of Kyoto University and NTT Communication Science Laboratories. The work was supported from NTT Communication Science Laboratories and JSPS Grants-in-Aid for Young</context>
</contexts>
<marker>Isahara, Bond, Uchimoto, Utiyama, Kanzaki, 2008</marker>
<rawString>Hitoshi Isahara, Francis Bond, Kiyotaka Uchimoto, Masao Utiyama, and Kyoko Kanzaki. 2008. Development of the Japanese WordNet. In The sixth international conference on Language Resources and Evaluation (LREC2008).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Graham Katz</author>
<author>Eugenie Giesbrecht</author>
</authors>
<title>Automatic identification of non-compositional multi-word expressions using latent semantic analysis.</title>
<date>2006</date>
<booktitle>In Proceedings of the Workshop, COLING/ACL</booktitle>
<pages>12--19</pages>
<contexts>
<context position="6627" citStr="Katz and Giesbrecht, 2006" startWordPosition="1053" endWordPosition="1056">on. The SAID dataset5 provides data about the syntactic flexibility of English idioms. It does not concern itself with idiom token identification. However, as in Hashimoto et al. (2006b), Hashimoto et al. (2006a) and Cook et al. (2007) among others, the syntactic behavior of idioms is an important clue to idiom token identification. Previous studies have mostly focused on the idiom type identification (Lin, 1999; Krenn and Evert, 2001; Baldwin et al., 2003; Shudo et al., 2004; Fazly and Stevenson, 2006). However, there has been a growing interest in idiom token identification in recent times (Katz and Giesbrecht, 2006; Hashimoto et al., 2006b; Hashimoto et al., 2006a; Birke and Sarkar, 2006; Cook et al., 2007). Katz and Giesbrecht (2006) compared the word vector of an idiom in context and that of the constituent words of the idiom using LSA in order to determine if the expression is idiomatic. Hashimoto et al. (2006b) and Hashimoto et al. (2006a) (HSU henceforth) focused their attention on the differences in grammatical constraints imposed on idioms and their literal counterparts such as the possibility of passivization, and developed handcrafted rules for Japanese idiom identification. Although their task</context>
<context position="32561" citStr="Katz and Giesbrecht (2006)" startWordPosition="5264" endWordPosition="5267">ter contribution. 23This result is inconsistent with the result obtained in HSU, where they reported that grammatical constraints involving adnominal modification was most effective. This inconsistency might be attributed to the differences of datasets being used for idiom identification experiment. HSU used only 108 sentences 999 Table 5: Results reported in CFS Accu RER Baseline 61.9 Ñ Unsupervised 72.4 27.6 Supervised 76.2 37.5 Table 5 shows the results reported in CFS. Their baseline system regards all instances as idioms. The performance of the supervised one is obtained by the method of Katz and Giesbrecht (2006). Though we cannot simply compare this with our results due to the difference in experimental conditions, this implies that our WSD-based method was equally good or possibly better than their methods that are tailored to MWEs. 6 Conclusion In this paper, we reported on the idiom corpus we have constructed and the idiom identification experiment using the corpus. As mentioned in §4.3, some idioms are short of examples in the current idiom corpus. We plan to collect more examples by using different characters. In the Japanese language, there are basically three character systems: Hiragana, Katak</context>
</contexts>
<marker>Katz, Giesbrecht, 2006</marker>
<rawString>Graham Katz and Eugenie Giesbrecht. 2006. Automatic identification of non-compositional multi-word expressions using latent semantic analysis. In Proceedings of the Workshop, COLING/ACL 2006, Multiword Expressions: Identifying and Exploiting Underlying Properties, pages 12–19, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daisuke Kawahara</author>
<author>Sadao Kurohashi</author>
</authors>
<title>Case Frame Compilation from the Web using HighPerformance Computing.</title>
<date>2006</date>
<booktitle>In Proceedings of The 5th International Conference on Language Resources and Evaluation (LREC-06),</booktitle>
<pages>1344--1347</pages>
<contexts>
<context position="12011" citStr="Kawahara and Kurohashi, 2006" startWordPosition="1966" endWordPosition="1969">ings of idioms. To be more precise, this reference specified literal and idiomatic meanings for each idiom like dictionaries do. For example, the entry for goma-o suru in the reference is as follows. Idiom: To flatter people. Literal: To crush sesame. As for the corpus size, we continued to annotate examples for each idiom, regardless of the proportion of idioms and literal phrases, until the total number of examples for each idiom reached 1,000.7 In the case of a shortage of original data, we annotated as many examples as possible. The original data were sourced from the Japanese Web corpus (Kawahara and Kurohashi, 2006). 4.2 Corpus Construction We constructed the corpus in the following manner: 1 From the Web corpus, we collected example sentences that contained one of our target idioms whichever meaning (positive or negative) they 7For idioms that we sampled for preliminary annotation, we annotated more than 1,000 examples. 994 Sentence Ratio 0 500 1000 1500 2000 2500 3000 # of Examples Figure 1: Distribution of the number of examples # of Words in a Sentence Figure 2: Distribution of sentence length 0.25 0.15 0.05 0.3 0.2 0.1 0 Web News Idiom 1-5 6-10 11-1516-20 21-25 26-30 31-35 36-40 41-45 46-50 51-55 56</context>
<context position="13921" citStr="Kawahara and Kurohashi (2006)" startWordPosition="2296" endWordPosition="2299">ectly. This was done by the two members of Group A and took 230 hours. 4.3 Status of Corpus The corpus consists of 102,846 examples.9 Figure 1 shows the distribution of the number of examples. For 68 idioms, we annotated more than 1,000 examples. However, we annotated less than 100 examples for 17 idioms because of inadequate original data. The average number of words in a sentence is 46. Idiom in Figure 2 shows the distribution of sentence length (the number of words) in the corpus. Web and News indicate the sentence length in the Web and a newspaper corpora, respectively. This is drawn from Kawahara and Kurohashi (2006). As 8http://nlp.kuee.kyoto-u.ac.jp/nl-resource/knp.html 9Note that the figures reported here are for the corpus of the 2008-06-25 version and will be slightly changed over time. you see, our corpus contains many more long sentences. This is because longer sentences were given priority for annotation, as stated in §4.2. Figure 3 shows the longest and shortest examples each for literal and idiomatic meanings of goma-o suru drawn from the corpus. To determine how consistent the positive/negative annotation is across different human annotators, we sampled 1,421 examples from the corpus, asked the</context>
</contexts>
<marker>Kawahara, Kurohashi, 2006</marker>
<rawString>Daisuke Kawahara and Sadao Kurohashi. 2006. Case Frame Compilation from the Web using HighPerformance Computing. In Proceedings of The 5th International Conference on Language Resources and Evaluation (LREC-06), pages 1344–1347.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brigitte Krenn</author>
<author>Stefan Evert</author>
</authors>
<title>Can we do better than frequency? a case study on extracting pp-verb collocations.</title>
<date>2001</date>
<booktitle>In Proceedings of the ACL-01 Workshop on Collocations,</booktitle>
<pages>39--46</pages>
<contexts>
<context position="6440" citStr="Krenn and Evert, 2001" startWordPosition="1021" endWordPosition="1024">“run into (something)” or “on the occasion of (something).” The former is the literal interpretation and the latter is the idiomatic interpretation of the compound functional expression. The SAID dataset5 provides data about the syntactic flexibility of English idioms. It does not concern itself with idiom token identification. However, as in Hashimoto et al. (2006b), Hashimoto et al. (2006a) and Cook et al. (2007) among others, the syntactic behavior of idioms is an important clue to idiom token identification. Previous studies have mostly focused on the idiom type identification (Lin, 1999; Krenn and Evert, 2001; Baldwin et al., 2003; Shudo et al., 2004; Fazly and Stevenson, 2006). However, there has been a growing interest in idiom token identification in recent times (Katz and Giesbrecht, 2006; Hashimoto et al., 2006b; Hashimoto et al., 2006a; Birke and Sarkar, 2006; Cook et al., 2007). Katz and Giesbrecht (2006) compared the word vector of an idiom in context and that of the constituent words of the idiom using LSA in order to determine if the expression is idiomatic. Hashimoto et al. (2006b) and Hashimoto et al. (2006a) (HSU henceforth) focused their attention on the differences in grammatical co</context>
</contexts>
<marker>Krenn, Evert, 2001</marker>
<rawString>Brigitte Krenn and Stefan Evert. 2001. Can we do better than frequency? a case study on extracting pp-verb collocations. In Proceedings of the ACL-01 Workshop on Collocations, pages 39–46.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoong Keok Lee</author>
<author>Hwee Tou Ng</author>
</authors>
<title>An empirical evaluation of knowledge sources and learning algorithms for word sense disambiguation.</title>
<date>2002</date>
<booktitle>In EMNLP ’02: Proceedings of the ACL-02 conference on Empirical methods in natural language processing,</booktitle>
<pages>41--48</pages>
<contexts>
<context position="15292" citStr="Lee and Ng (2002)" startWordPosition="2514" endWordPosition="2517">eement. The corpus is available on the Web.10 Currently we provide the list of the basic Japanese idioms we are dealing with, the idiom corpus, and the vector representation data used for the idiom identification experiment. The corpus is protected under the BSD license. 5 Idiom Identification Experiment 5.1 Method of Idiom Identification We adopted a standard WSD method using machine learning. More specifically, we used SVM (Vapnik, 1995) with a quadratic kernel implemented in TinySVM.11 The features we used are classified into either those that have been commonly used in WSD on the lines of Lee and Ng (2002) (LN hereafter), 10http://openmwe.sourceforge.jp/ 11http://www.chasen.org/-taku/software/TinySVM/ 995 • )*+,-./012345678-./012,9:;&lt;=&gt;?(@A$%BC&gt;?# D2$%0EF;GHIJK$%LMNOGHI@A2P&amp;,QROGH8STUV%L WXY34567;Z[\#]^+_W%`Lab,cdI+))a(ef)gX2,hi jklmnopo2�����,qr;st2`u#v&amp;,wxIyz_m{|}*~(, +W;&amp;quot;W(,N,+z,({~%`L*X (But I suspect that the show managers of IT ventures will remain sly and audacious, and survive by flattering manufacturers, bending over themselves to accede to the demands of governmental agencies, and talking glibly about buzz terms, without intelligence but with vitality, just like the br</context>
</contexts>
<marker>Lee, Ng, 2002</marker>
<rawString>Yoong Keok Lee and Hwee Tou Ng. 2002. An empirical evaluation of knowledge sources and learning algorithms for word sense disambiguation. In EMNLP ’02: Proceedings of the ACL-02 conference on Empirical methods in natural language processing, pages 41–48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Automatic identification of noncompositional phrases.</title>
<date>1999</date>
<booktitle>In Proceeding of the 37th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>317--324</pages>
<contexts>
<context position="6417" citStr="Lin, 1999" startWordPosition="1019" endWordPosition="1020">ans either “run into (something)” or “on the occasion of (something).” The former is the literal interpretation and the latter is the idiomatic interpretation of the compound functional expression. The SAID dataset5 provides data about the syntactic flexibility of English idioms. It does not concern itself with idiom token identification. However, as in Hashimoto et al. (2006b), Hashimoto et al. (2006a) and Cook et al. (2007) among others, the syntactic behavior of idioms is an important clue to idiom token identification. Previous studies have mostly focused on the idiom type identification (Lin, 1999; Krenn and Evert, 2001; Baldwin et al., 2003; Shudo et al., 2004; Fazly and Stevenson, 2006). However, there has been a growing interest in idiom token identification in recent times (Katz and Giesbrecht, 2006; Hashimoto et al., 2006b; Hashimoto et al., 2006a; Birke and Sarkar, 2006; Cook et al., 2007). Katz and Giesbrecht (2006) compared the word vector of an idiom in context and that of the constituent words of the idiom using LSA in order to determine if the expression is idiomatic. Hashimoto et al. (2006b) and Hashimoto et al. (2006a) (HSU henceforth) focused their attention on the differ</context>
</contexts>
<marker>Lin, 1999</marker>
<rawString>Dekang Lin. 1999. Automatic identification of noncompositional phrases. In Proceeding of the 37th Annual Meeting of the Association for Computational Linguistics, pages 317–324.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernardo Magnini</author>
<author>Carlo Strapparava</author>
<author>Giovanni Pezzulo</author>
<author>Alfio Gliozzo</author>
</authors>
<date>2002</date>
<booktitle>The Role of Domain Information in Word Sense Disambiguation. Natural Language Engineering, special issue on Word Sense Disambiguation,</booktitle>
<volume>8</volume>
<issue>3</issue>
<contexts>
<context position="18732" citStr="Magnini et al., 2002" startWordPosition="3040" endWordPosition="3043">roughly correspond to the syntactic relations of LN. We adapted it to Japanese idioms along with some simplifications. In the case of the example of mune-o utu (chest-ACC hit) ‘impress’ below,15 f4 is the POS and lemma of tyousyu and f5 corresponds to those of uta.16 ‘A beautiful song that impresses the audience’ f6 and f7 are available from JUMAN’s output. For example, the hypernym of tyousyu (audience) is human and its domain is culture/media. Those of uta (song) are abstract-thing and culture/recreation. They are not used in LN, but they are known to be useful for WSD (Tanaka et al., 2007; Magnini et al., 2002). f8 indicates whether a nominal constituent of an idiom, if any, undergoes adnominal modification. f9 indicates whether one of Japanese topic case markers is attached to a nominal constituent of an idiom, if any. f10 is turned on when a passive or causative suffix is attached to a verbal constituent of an idiom, if any.17 f11 and f12 are similar to f10. The former is used for negated forms and the latter for volitional modality suffixes of a predicate part of an idiom, if any.18 Volitional modality includes expressions like order, request, permission, prohibition, and volition. Finally, f13 i</context>
</contexts>
<marker>Magnini, Strapparava, Pezzulo, Gliozzo, 2002</marker>
<rawString>Bernardo Magnini, Carlo Strapparava, Giovanni Pezzulo, and Alfio Gliozzo. 2002. The Role of Domain Information in Word Sense Disambiguation. Natural Language Engineering, special issue on Word Sense Disambiguation, 8(3):359–373.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Satoshi Sato</author>
</authors>
<title>Compilation of a comparative list of basic Japanese idioms from five sources.</title>
<date>2007</date>
<booktitle>In IPSJ 2007-NL-178,</booktitle>
<pages>1--6</pages>
<note>(in Japanese).</note>
<contexts>
<context position="4017" citStr="Sato (2007)" startWordPosition="638" endWordPosition="639">out context. For example, a Japanese idiom te-o dasu (hand-ACC stretch)1 can be interpreted as ei1ACC is the accusative case marker. Likewise we use the following notation in this paper; NOM for the nominative case 992 Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 992–1001, Honolulu, October 2008. c�2008 Association for Computational Linguistics ther “punch,” “steal” or “make moves on.” This kind of ambiguity should be placed on the agenda. We do not tackle the problem of what constitutes the notion of “idiom.” We simply regard phrases listed in Sato (2007) as idioms. The reminder of this paper is organized as follows. In §2 we present related works. §3 shows the target idioms. After the idiom corpus is described in §4, we detail our idiom identification method and experiment in §5. Finally §6 concludes the paper. 2 Related Work There have only been a few works on the construction of an idiom corpus. In this regard, Birke and Sarkar (2006) and Cook et al. (2008) are notable exceptions. Birke and Sarkar (2006) automatically constructed a corpus of English idiomatic expressions (words that can be used non-literally). They targeted 50 expressions a</context>
<context position="8363" citStr="Sato (2007)" startWordPosition="1338" endWordPosition="1339">d, we exploit a WSD method, for which there have been many studies and matured technologies, in addition to the characteristics of idioms. Birke and Sarkar (2006) also used WSD. However, they employed an unsupervised method, while ours is a completely supervised one. Apart from idioms, Uchiyama et al. (2005) conducted the token classification of Japanese compound verbs exploiting supervised method. http://www.ldc.upenn.edu/Catalog/ 5CatalogEntry.jsp?catalogId=LDC2003T10 993 3 Target Idioms For this study, we selected 146 idioms through the following procedure. 1 We extracted basic idioms from Sato (2007). Sato compiled about 3,600 basic idioms of Japanese from five books: two dictionaries for elementary school, two idiom dictionaries, and one linguistics book on idioms. We extracted those idioms that were described in more than two of these five books. The total number of such idioms added up to 926. 2 From among these idioms, we chose ambiguous ones.6 As a result, 146 idioms were selected. As for 2 , sometimes it is not trivial to determine if an idiom is ambiguous or not. Some idioms are rarely interpreted literally, while others, in all likelihood, take on the literal meaning. Is it meanin</context>
<context position="10820" citStr="Sato (2007)" startWordPosition="1765" endWordPosition="1766">have a literal meaning. They are not dealt with in this paper. whether the corresponding phrase in the example is used as an idiom or a literal phrase. We call the former the positive example and the latter the negative example. More specifically, the corpus consists of lines that each represent one example. A line consists of four fields as follows: 1 Label indicates whether the example is positive or negative. Label i is used for positive examples and l for negative ones. 2 ID denotes the idiom that is included in the example. In this study, each idiom has a unique number, which is based on Sato (2007). 3 Lemma also shows the idiom in the example. We assigned each idiom its canonical (or standard) form on the basis of Sato (2007). 4 Example is the example itself. Given below is a sample of a negative example of goma-o suru (sesame-ACC crush) ’flatter’. • l 1417 !&amp;quot;#$% $&amp;&apos;(!&amp;quot;#$&amp; ··· The third field is the lemma of the idiom. The last one is the example that says ’crushing sesame in a mortar...’ Before working on the corpus construction, we prepared a reference by which human annotators could consistently distinguish between the literal and figurative meanings of idioms. To be more precise, th</context>
</contexts>
<marker>Sato, 2007</marker>
<rawString>Satoshi Sato. 2007. Compilation of a comparative list of basic Japanese idioms from five sources. In IPSJ 2007-NL-178, pages 1–6. (in Japanese).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kosho Shudo</author>
<author>Toshifumi Tanabe</author>
<author>Masahito Takahashi</author>
<author>Kenji Yoshimura</author>
</authors>
<title>MWEs as Nonpropositional Content Indicators.</title>
<date>2004</date>
<booktitle>In the 2nd ACL Workshop on Multiword Expressions: Integrating Processing,</booktitle>
<pages>32--39</pages>
<contexts>
<context position="6482" citStr="Shudo et al., 2004" startWordPosition="1029" endWordPosition="1032"> (something).” The former is the literal interpretation and the latter is the idiomatic interpretation of the compound functional expression. The SAID dataset5 provides data about the syntactic flexibility of English idioms. It does not concern itself with idiom token identification. However, as in Hashimoto et al. (2006b), Hashimoto et al. (2006a) and Cook et al. (2007) among others, the syntactic behavior of idioms is an important clue to idiom token identification. Previous studies have mostly focused on the idiom type identification (Lin, 1999; Krenn and Evert, 2001; Baldwin et al., 2003; Shudo et al., 2004; Fazly and Stevenson, 2006). However, there has been a growing interest in idiom token identification in recent times (Katz and Giesbrecht, 2006; Hashimoto et al., 2006b; Hashimoto et al., 2006a; Birke and Sarkar, 2006; Cook et al., 2007). Katz and Giesbrecht (2006) compared the word vector of an idiom in context and that of the constituent words of the idiom using LSA in order to determine if the expression is idiomatic. Hashimoto et al. (2006b) and Hashimoto et al. (2006a) (HSU henceforth) focused their attention on the differences in grammatical constraints imposed on idioms and their lite</context>
</contexts>
<marker>Shudo, Tanabe, Takahashi, Yoshimura, 2004</marker>
<rawString>Kosho Shudo, Toshifumi Tanabe, Masahito Takahashi, and Kenji Yoshimura. 2004. MWEs as Nonpropositional Content Indicators. In the 2nd ACL Workshop on Multiword Expressions: Integrating Processing, pages 32–39.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Takaaki Tanaka</author>
<author>Francis Bond</author>
<author>Timothy Baldwin</author>
<author>Sanae Fujita</author>
<author>Chikara Hashimoto</author>
</authors>
<title>Word Sense Disambiguation Incorporating Lexical and Structural Semantic Information.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL),</booktitle>
<pages>477--485</pages>
<contexts>
<context position="18709" citStr="Tanaka et al., 2007" startWordPosition="3036" endWordPosition="3039"> Po of LN. f4 and f5 roughly correspond to the syntactic relations of LN. We adapted it to Japanese idioms along with some simplifications. In the case of the example of mune-o utu (chest-ACC hit) ‘impress’ below,15 f4 is the POS and lemma of tyousyu and f5 corresponds to those of uta.16 ‘A beautiful song that impresses the audience’ f6 and f7 are available from JUMAN’s output. For example, the hypernym of tyousyu (audience) is human and its domain is culture/media. Those of uta (song) are abstract-thing and culture/recreation. They are not used in LN, but they are known to be useful for WSD (Tanaka et al., 2007; Magnini et al., 2002). f8 indicates whether a nominal constituent of an idiom, if any, undergoes adnominal modification. f9 indicates whether one of Japanese topic case markers is attached to a nominal constituent of an idiom, if any. f10 is turned on when a passive or causative suffix is attached to a verbal constituent of an idiom, if any.17 f11 and f12 are similar to f10. The former is used for negated forms and the latter for volitional modality suffixes of a predicate part of an idiom, if any.18 Volitional modality includes expressions like order, request, permission, prohibition, and v</context>
</contexts>
<marker>Tanaka, Bond, Baldwin, Fujita, Hashimoto, 2007</marker>
<rawString>Takaaki Tanaka, Francis Bond, Timothy Baldwin, Sanae Fujita, and Chikara Hashimoto. 2007. Word Sense Disambiguation Incorporating Lexical and Structural Semantic Information. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), pages 477– 485.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Masatoshi Tsuchiya</author>
<author>Takehito Utsuro</author>
<author>Suguru Matsuyoshi</author>
<author>Satoshi Sato</author>
<author>Seiichi Nakagawa</author>
</authors>
<title>Development and analysis of an example database of Japanese compound functional expressions.</title>
<date>2006</date>
<journal>Transactions of Information Processing Society of Japan,</journal>
<volume>47</volume>
<issue>6</issue>
<note>(in Japanese).</note>
<contexts>
<context position="5258" citStr="Tsuchiya et al. (2006)" startWordPosition="847" endWordPosition="850">6,600 examples. They call the corpus TroFi Example Base, which is available on the Web.2 Cook et al. (2008) compiled a corpus of English verbnoun combinations (VNCs) tokens. Their corpus deals with 53 VNC expressions and consists of about 3,000 example sentences. Like ours, they assigned each example with a label indicating whether an expression in the example is used literally or idiomatically. Our corpus can be regarded as the Japanese idiom counterpart of these works. However, note that our corpus targets 146 idioms and consists of as many as 102,846 example sentences. Another exception is Tsuchiya et al. (2006), who manually constructed an example database of Japanese compound functional expressions named MUST. They provide it on the Web.3 Some of the compound functional expressions in Japanese are ambiguous like idioms are.4 marker, DAT for the dative case marker, and GEN for the genitive case marker. FROM and TO stand for the Japanese counterparts offrom and to. NEG represents a verbal negation morpheme. 2http://www.cs.sfu.ca/-anoop/students/jbirke/ 3http://nlp.iit.tsukuba.ac.jp/must/ 4For example, (something)-ni-atatte ((something)-DATrun.into) means either “run into (something)” or “on the occas</context>
</contexts>
<marker>Tsuchiya, Utsuro, Matsuyoshi, Sato, Nakagawa, 2006</marker>
<rawString>Masatoshi Tsuchiya, Takehito Utsuro, Suguru Matsuyoshi, Satoshi Sato, and Seiichi Nakagawa. 2006. Development and analysis of an example database of Japanese compound functional expressions. Transactions of Information Processing Society of Japan, 47(6):1728–1741. (in Japanese).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kiyoko Uchiyama</author>
<author>Timothy Baldwin</author>
<author>Shun Ishizaki</author>
</authors>
<title>Disambiguating Japanese compound verbs.</title>
<date>2005</date>
<journal>Computer Speech and Language, Special Issue on Multiword Expressions,</journal>
<volume>19</volume>
<issue>4</issue>
<contexts>
<context position="8061" citStr="Uchiyama et al. (2005)" startWordPosition="1298" endWordPosition="1301">ther, unlike HSU, we employ matured WSD technologies. Cook et al. (2007) (CFS henceforth) propose an unsupervised method for English on the basis of the observation that idioms tend to be expressed in a small number of fixed forms. These studies used only the characteristics of idioms (or MWEs). On the other hand, we exploit a WSD method, for which there have been many studies and matured technologies, in addition to the characteristics of idioms. Birke and Sarkar (2006) also used WSD. However, they employed an unsupervised method, while ours is a completely supervised one. Apart from idioms, Uchiyama et al. (2005) conducted the token classification of Japanese compound verbs exploiting supervised method. http://www.ldc.upenn.edu/Catalog/ 5CatalogEntry.jsp?catalogId=LDC2003T10 993 3 Target Idioms For this study, we selected 146 idioms through the following procedure. 1 We extracted basic idioms from Sato (2007). Sato compiled about 3,600 basic idioms of Japanese from five books: two dictionaries for elementary school, two idiom dictionaries, and one linguistics book on idioms. We extracted those idioms that were described in more than two of these five books. The total number of such idioms added up to </context>
</contexts>
<marker>Uchiyama, Baldwin, Ishizaki, 2005</marker>
<rawString>Kiyoko Uchiyama, Timothy Baldwin, and Shun Ishizaki. 2005. Disambiguating Japanese compound verbs. Computer Speech and Language, Special Issue on Multiword Expressions, 19(4):497–512.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vladimir Vapnik</author>
</authors>
<title>The Nature of Statistical Learning Theory.</title>
<date>1995</date>
<publisher>Springer-Verlag,</publisher>
<location>New York.</location>
<contexts>
<context position="15118" citStr="Vapnik, 1995" startWordPosition="2484" endWordPosition="2486">orpus, asked the two members of Group B to do the same annotation, and calculated the Kappa statistic between the two. The value was 0.8519, which indicates very high agreement. The corpus is available on the Web.10 Currently we provide the list of the basic Japanese idioms we are dealing with, the idiom corpus, and the vector representation data used for the idiom identification experiment. The corpus is protected under the BSD license. 5 Idiom Identification Experiment 5.1 Method of Idiom Identification We adopted a standard WSD method using machine learning. More specifically, we used SVM (Vapnik, 1995) with a quadratic kernel implemented in TinySVM.11 The features we used are classified into either those that have been commonly used in WSD on the lines of Lee and Ng (2002) (LN hereafter), 10http://openmwe.sourceforge.jp/ 11http://www.chasen.org/-taku/software/TinySVM/ 995 • )*+,-./012345678-./012,9:;&lt;=&gt;?(@A$%BC&gt;?# D2$%0EF;GHIJK$%LMNOGHI@A2P&amp;,QROGH8STUV%L WXY34567;Z[\#]^+_W%`Lab,cdI+))a(ef)gX2,hi jklmnopo2�����,qr;st2`u#v&amp;,wxIyz_m{|}*~(, +W;&amp;quot;W(,N,+z,({~%`L*X (But I suspect that the show managers of IT ventures will remain sly and audacious, and survive by flattering manufactu</context>
</contexts>
<marker>Vapnik, 1995</marker>
<rawString>Vladimir Vapnik. 1995. The Nature of Statistical Learning Theory. Springer-Verlag, New York.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>