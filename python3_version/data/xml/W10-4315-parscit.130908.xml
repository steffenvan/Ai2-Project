<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.009514">
<title confidence="0.943528">
Reference reversibility with Reference Domain Theory
</title>
<author confidence="0.676075">
Alexandre Denis
</author>
<note confidence="0.855288666666667">
TALARIS team / UMR 7503 LORIA/INRIA
Lorraine. Campus scientifique, BP 239
F-54506 Vandoeuvre-les-Nancy cedex
</note>
<email confidence="0.989616">
alexandre.denis@loria.fr
</email>
<sectionHeader confidence="0.979606" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998363125">
In this paper we present a reference model
based on Reference Domain Theory that
can work both in interpretation and gener-
ation. We introduce a formalization of key
concepts of RDT, the interpretation and
generation algorithms and show an exam-
ple of behavior in the dynamic, asymmetric
and multimodal GIVE environment.
</bodyText>
<sectionHeader confidence="0.996892" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999804357142857">
The reference task in a dialogue system is two-fold.
On the one hand the system has to interpret the
referring expressions (RE) produced by the user in
his utterances. On the other hand the system has
to generate the REs for the objects it aims to refer
to. We present in this paper a framework that con-
siders that reference interpretation and generation
are two sides of the same coin, hence avoiding any
potential misunderstanding arising from the two
modules discrepancies. Reference Domain Theory
(RDT) (Salmon-Alt and Romary, 2000; Salmon-
Alt and Romary, 2001) proposes to represent the
diversity of referring acts by the diversity of con-
straints they impose on their context of use. The
reversibility then lies in the possibility to express
these constraints independently of the considered
task.
In (Denis, 2010) we described the generation side
of RDT in the context of the GIVE-2 challenge
(Koller et al., 2010) which is an evaluation of in-
struction generation systems in a 3D maze. In this
paper we propose the interpretation counterpart
and show the required modeling to consider the
dynamic, asymmetric and multimodal context of
GIVE. We first present the reference model in sec-
tion 2 and 3, discuss the interpretation problems
in GIVE in section 4, detail an example in section
5 and present evaluation results in section 6.
</bodyText>
<sectionHeader confidence="0.994171" genericHeader="method">
2 Reference Domains
</sectionHeader>
<bodyText confidence="0.980450217391304">
A rich contextual structure is required to give an
account for the different kinds of discrimination
we observe in REs such as semantic discrimina-
tion (e.g. “the blue button”), focus discrimination
(e.g. “this button”) and salience discrimination
(e.g. “this one&amp;quot;). We introduce here the struc-
ture of reference domain which is a local context
supporting these different discriminations.
We assume that Props is the set of unary predi-
cate names e.g. {blue, left, ...}, Types is the set of
types of predicates e.g. {color, position, ...}, and
val is the function val : Types → 2P&apos;ps which maps
a type on the predicates names. Finally, E is the
set of all objects and V the set of ground predicates
e.g. {blue(b1), ...}.
A reference domain D is //then a tuple
(GD, SD, UD, (c, P, F))
where GD C_ E is the set of objects of the do-
main, called the ground of the domain; SD C_ Props
is the semantic description of the domain, satis-
fied by all elements of the ground; UD E N is the
salience of the domain. And (c, P, F) is a parti-
tion structure where c E Types is a differentiation
</bodyText>
<equation confidence="0.837194">
criterion; P is the partition generated by c; and
F C_ P is the focus of P.
</equation>
<bodyText confidence="0.99952175">
For instance, a domain composed of a blue but-
ton b1 and a red button b2, with a salience equal
to 3, where b1 and b2 are differentiated using the
color, and where b1 is in focus, would be noted as:
</bodyText>
<equation confidence="0.9966">
D =({b1, b2}, {button}, 3,
(color, {{b1}, {b2}}, {{b1}}))
</equation>
<bodyText confidence="0.999296">
Finally we define a referential space (RS) as a
set of reference domains (RD) ordered by salience.
</bodyText>
<sectionHeader confidence="0.996152" genericHeader="method">
3 Referring
</sectionHeader>
<bodyText confidence="0.999719166666667">
A RE impose some constraints on the context in
which it can be uttered, that is in which RD the
interpretation has to be made. The constraints are
represented as underspecified domains (UD), spec-
ifying the structure of the suitable RD in terms of
ground, salience or partition. The explicit defini-
tions of the UDs makes possible to share these def-
initions between the interpretation and the gener-
ation modules, hence allowing the implementation
of a type B reversible reference module (Klarner,
2005), that is a module in which both directions
share the same resources.
</bodyText>
<subsubsectionHeader confidence="0.677048">
Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 79–82,
</subsubsectionHeader>
<affiliation confidence="0.890672">
The University of Tokyo, September 24-25, 2010. p@c 2010 Association for Computational Linguistics
</affiliation>
<page confidence="0.997873">
79
</page>
<table confidence="0.756354625">
Expression U(N, t) matches D iff 3(c, P, F) E D;
this one F = {{t}} ∧ msd(D)
this N F = {{t}} ∧ t E N2
the N t E N2 ∧ {t} E P ∧ VX EP, X =�{t}=�.XflN2 =0
the other one F =� 0 ∧ P \ F = {{t}} ∧ msd(D)
the other N F =� 0 ∧ P \ F = {{t}} ∧ GD C N2
another one F =� 0 ∧ {t} E P \ F ∧ msd(D)
another N F =� 0 ∧ {t} E P \ F ∧ GD C N2
</table>
<figure confidence="0.98142">
a N t E N2 ∧ t E GD
interpretation
generation
referent
Underspecified
Domains
Existing
Domains
referring
expression
</figure>
<figureCaption confidence="0.999822">
Figure 1: Reference processes
</figureCaption>
<tableCaption confidence="0.982141">
Table 1: Underspecified domains for each type of
referring expression
</tableCaption>
<subsectionHeader confidence="0.997238">
3.1 Underspecified domains
</subsectionHeader>
<bodyText confidence="0.999499">
The different types of UDs are presented in table 1.
Each UD is a parametric conjunction of constraints
on a RD, noted U(N, t), where t is the intended
referent and N C_ Props is a semantic description.
Nz stands for the extension of N, and msd(D)
stands for most salient description, that is, there
is no more or equally salient domain than D in the
current RS with a different description. Each UD
is associated to a wording combining a determiner
and a wording of the semantic description, for in-
stance “the N&amp;quot; is a shortcut for a definite expres-
sion whose head noun and modifiers are provided
by the wording of N. Finally we say that an UD
matches a RD if all the constraints of the UD are
satisfied by the RD.
</bodyText>
<subsectionHeader confidence="0.999804">
3.2 Referring processes
</subsectionHeader>
<bodyText confidence="0.999979">
Interpretation and generation can now be defined
in terms of UD. The two processes are illustrated
in figure 1 and the algorithms are presented in fig-
ure 2.
The interpretation algorithm consists in finding
or creating a RD from the input UD, U(N,.) cre-
ated from the input RE type and description N.
The algorithm then iterates through the RS in
salience order, and through all the individuals t of
the tested domain to retrieve the first one match-
ing U(N, t). If a matching domain D is found, a
restructuring operation is applied and the referent
t is focused in the partition of D. On the other
hand, if no domain is found, the UD is accommo-
dated, that is a new domain and a new referent sat-
isfying the constraints of U(N, t) are created. Ac-
cording to the task, this accommodation may not
be possible for all REs, but for sake of simplicity
we assume here this operation is always possible.
The generation side is the opposite, that is it
finds an UD from an input RD. It first selects a
RD containing the target referent to generate t,
assuming here that the most salient domain has to
be preferred. The description N used to instan-
tiate the UDs is composed of the description of
the domain and the description of the referent in
the partition (line 2). It then iterates through the
different UDs by Givenness order (Gundel et al.,
1993) and selects the first one that matches. A re-
structuring operation is applied and the found UD
is returned, eventually providing the RE.
The restructuring operation, detailed in (Denis,
2010), aims to restrict the current context by cre-
ating a new domain around the referent in the ref-
erential space or by increasing the salience of the
domain containg the referent. This operation helps
to perform focalization in restricted domains.
</bodyText>
<sectionHeader confidence="0.827776" genericHeader="method">
4 The complex context of GIVE
</sectionHeader>
<bodyText confidence="0.999975885714286">
The dynamic, asymmetric and multimodal context
of GIVE requires additional mechanisms for inter-
pretation. Asymmetry causes the late visual con-
text integration, when the direction giver produces
a RE to objects not yet known by the direction
follower, that are only visually discovered later on.
Space prevents us to describe in details the late in-
tegration algorithm, but the idea is, given a new
physical object t, to scan existing domains of the
actual RS to check if t can be merged semantically
with any previous object t&apos;. If this could be the
case, the integration leads to create two parallel
RS, one in which t = t&apos; (the fusion hypothesis)
and one in which t =� t&apos; (the separation hypoth-
esis). If this cannot be the case, t is added as a
new object. Following (DeVault and Stone, 2007),
these alternative contexts can persist across time
and further referring expressions may reject one or
the other hypothesis as illustrated in section 5.
The second required mechanism is the proper
handling of the multimodal dynamic focus, that
is the combination of the linguistic focus result-
ing from RE, and the visual focus. It is possible
to have two referential spaces for the linguistic or
visual context as in (Kelleher et al., 2005; Byron
et al., 2005), or to have two foci in a partition.
We can also model interleaved focus, that is, only
one focus per domain but that dynamically corre-
sponds to the linguistic focus or the visual focus.
The idea is that after each RE, the referent receives
the focus as described in algorithm 1, but whenever
the visual context changes, the focus is updated to
the visible objects. Although interleaved focus pre-
vents anaphora while the visual context changes,
its complexity is enough for our setup.
</bodyText>
<page confidence="0.99185">
80
</page>
<construct confidence="0.519923">
Algorithm 1 interpret(U(N,.), RS)
</construct>
<listItem confidence="0.99280225">
1: for all domain D in RS by salience order do
2: for all t E GD do
3: if U(N, t) matches D then
4: restructure(D, N, RS)
5: focus t in D
6: return t
7: end if
8: end for
9: end for
10: return accommodate(U(N, .), RS)
Algorithm 2 generate(t, RS)
1: D most salient domain containing t
2: N SD U {p|p E val(c), p(t) E V }
3: for all U(N, t) sorted by Givenness do
4: if U(N, t) matches D then
5: restructure(D, N, RS)
6: return U(N, t)
7: end if
8: end for
9: return failure
</listItem>
<figureCaption confidence="0.994718">
Figure 2: Reference algorithms, relying on the same underspecified domains
</figureCaption>
<sectionHeader confidence="0.979412" genericHeader="method">
5 Example
</sectionHeader>
<bodyText confidence="0.999425529411765">
In this section we present the interpretation side
of some expressions we generated in the GIVE set-
ting (table 2). The detailed generation side of this
example can be found in (Denis, 2010). S is the
system that interprets the RE of U the user. The
situation is: S enters a room with two blue but-
tons b1 and b2, none of them being visible when he
enters and U wants to refer to b1.
However, U utters “Not this one!&amp;quot; rejecting then
the fusion hypothesis. To be able to consider the ef-
fects of this utterance, we have to take into account
the ellipsis. This can be done by assuming that U
is asserting properties of the target of his first RE,
that is, he is actually stating that “[t is] not this
one!&amp;quot;. The RE “this one” leads to the construction
of a demonstrative one-anaphora UD that matches
t in D1FUS but b2 in D1SEP. The following schema
</bodyText>
<table confidence="0.9300375">
hypothesis:
state of S utterance of U shows the contradiction in the fusion
t is not this one
Push a blue button (b1)
see(b2) Not this one! Look for the other one! fusion t # t
see(b1) Yeah! This one! separation t # b2
</table>
<tableCaption confidence="0.998794">
Table 2: Utterances produced by U
</tableCaption>
<bodyText confidence="0.995315428571429">
When S enters the room, U generates an indef-
inite RE “Push a blue button”. S first constructs
an indefinite UD “a N&amp;quot; with N = {blue, button}.
However, because there exists no RD at first, he
has to accommodate the UD, hence creating a new
domain D1 containing a new linguistically focused
individual t:
</bodyText>
<equation confidence="0.87433">
D1 =({t}, {button, blue}, 1,
(id, {{t}}, {{t}}))
</equation>
<bodyText confidence="0.98583775">
We assume that S moves and now sees the blue
button b2 without knowing yet if this is the in-
tended one. The integration of this new physical
object then leads to two hypothesis. In the fu-
sion hypothesis, b2 = t, and in the separation hy-
pothesis, b2 =� t. In both cases, the visible button
is focused in the two versions of D1, D1FUS and
D1SEP:
</bodyText>
<equation confidence="0.96929175">
D1FUS =({t}, {button, blue}, 2,
(id, {{t}}, {{t}}))
D1SEP =({t, b2}, {button, blue}, 2,
(id, {{t}, {b2}}, {{b2}}))
</equation>
<bodyText confidence="0.999844">
Being contradictory, the fusion hypothesis is re-
jected and only D1SEP is maintained. For the
readability of the presentation, D1SEP is rewrit-
ten as D1.
The interpretation of “Look for the other one!&amp;quot;
is straightforward. A definite alternative one-
anaphora UD is built, and both t and b2 are tested
in D1 but only t is matched because it is unfocused
(see the definition of the alternative one-anaphora
in table 1).
Now S moves again and sees b1. As for b2, the
integration of b1 in the referential space leads to
two alternative RS. The buttons b2 and b1 cannot
be merged (we assume here that S can clearly see
they are two different buttons), thus the two alter-
native RS are whether b1 = t or b1 =� t:
</bodyText>
<equation confidence="0.96743925">
D1FUS =({t, b2}, {button, blue}, 3,
(id, {{t}, {b2}}, {{t}}))
D1SEP =({t, b1, b2}, {button, blue}, 3,
(id, {{t}, {b1}, {b2}}, {{b1}}))
</equation>
<bodyText confidence="0.9993806">
Eventually S has to interpret “this one&amp;quot;. Like
previously, in order to take into account the effects
of this utterance, S has to resolve the ellipsis and
must consider “[t is] this one&amp;quot;. The RE “this one”
is resolved on t in D1FUS but on b1 in D1SEP.
</bodyText>
<page confidence="0.960495">
81
</page>
<equation confidence="0.770109">
t is this one
fusion t = t
separation t = bl
</equation>
<bodyText confidence="0.99967475">
This is now the separation hypothesis which is
inconsistent because we assumed that b1 # t. This
RS is then ruled out, and only the fusion RS re-
mains.
</bodyText>
<sectionHeader confidence="0.998688" genericHeader="evaluation">
6 Evaluation
</sectionHeader>
<bodyText confidence="0.9999748">
Only the generation direction has been evaluated
in the GIVE challenge. The results (Koller et al.,
2010) show that the system embedding Reference
Domain Theory proves to rely on less instructions
than other systems (224) and proves to be the most
successful (47% of task success) while being the
fastest (344 seconds). We conjecture that the good
results of RDT can be explained by the low cogni-
tive load resulting from the use of demonstrative
NPs and one-anaphoras, but the role of the over-
all generation strategy has also to be taken into
account in these good results (Denis et al., 2010).
Although it would be very interesting, the in-
terpretation side has not yet been evaluated in
the GIVE setting, but only in the MEDIA cam-
paign (Bonneau Maynard et al., 2009) which is an
unimodal setting. The results show that the in-
terpretation side of RDT achieves a fair precision
in identification (75.2%) but a low recall (44.7%).
We assume that the low recall of the module is
caused by the cascade of errors, one error at the
start of a reference chain leading to several other
errors. Nonetheless, we estimate that error cascad-
ing would be less problematic in the GIVE setting
because of its dynamicity.
</bodyText>
<sectionHeader confidence="0.999043" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.999959">
We presented a reference framework extending
(Salmon-Alt and Romary, 2001) in which interpre-
tation and generation can be defined in terms of the
constraints imposed by the referring expressions on
their context of use. The two modules sharing the
same library of constraints, the model is then said
reversible. However, because of the asymmetry and
dynamicity of our setup, the GIVE challenge, ad-
ditional mechanisms such as uncertainty have to
be modeled. In particular, we have to maintain
different interpretation contexts like (DeVault and
Stone, 2007) to take into account the ambiguity
arising from the late integration of the visual con-
text. It would be interesting now to explore deeper
our reversibility claim by evaluating the interaction
between the two reference algorithms in the GIVE
setting.
</bodyText>
<sectionHeader confidence="0.981102" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999695178571429">
Hel�ene Bonneau Maynard, Matthieu Quignard,
and Alexandre Denis. 2009. MEDIA: a seman-
tically annotated corpus of task oriented dialogs
in French. Language Resources and Evaluation,
43(4):329–354.
Donna K. Byron, Thomas Mampilly, Vinay
Sharma, and Tianfang Xu. 2005. Utilizing vi-
sual attention for cross-modal coreference inter-
pretation. In Proceedings of Context-05, pages
83–96.
Alexandre Denis, Marilisa Amoia, Luciana
Benotti, Laura Perez-Beltrachini, Claire Gar-
dent, and Tarik Osswald. 2010. The GIVE-2
Nancy Generation Systems NA and NM.
Technical report.
Alexandre Denis. 2010. Generating referring ex-
pressions with Reference Domain Theory. In
Proceedings of the 6th International Natural
Language Generation Conference - INLG 2010,
Dublin, Ireland.
David DeVault and Matthew Stone. 2007. Man-
aging ambiguities across utterances in dialogue.
In Proceedings of the 2007 Workshop on the Se-
mantics and Pragmatics of Dialogue (DECA-
LOG 2007), Trento, Italy.
Jeanette K. Gundel, Nancy Hedberg, and Ron
Zacharski. 1993. Cognitive status and the form
of referring expressions in discourse. Language,
69(2):274–307.
John Kelleher, Fintan Costello, and Josef van Gen-
abith. 2005. Dynamically structuring, updating
and interrelating representations of visual and
linguistic discourse context. Artificial Intelli-
gence, 167(1-2):62–102.
Martin Klarner. 2005. Reversibility and re-
usability of resources in NLG and natural lan-
guage dialog systems. In Proceedings of the 10th
European Workshop on Natural Language Gen-
eration (ENLG-05), Aberdeen, Scotland.
Alexander Koller, Kristina Striegnitz, Andrew
Gargett, Donna Byron, Justine Cassell, Robert
Dale, Johanna Moore, and Jon Oberlander.
2010. Report on the second NLG challenge on
generating instructions in virtual environments
(GIVE-2). In Proceedings of the 6th Interna-
tional Natural Language Generation Conference
- INLG 2010, Dublin, Ireland.
Susanne Salmon-Alt and Laurent Romary. 2000.
Generating referring expressions in multimodal
contexts. In Workshop on Coherence in Gener-
ated Multimedia - INLG 2000, Israel.
Susanne Salmon-Alt and Laurent Romary. 2001.
Reference resolution within the framework of
cognitive grammar. In Proceeding of the Inter-
national Colloquium on Cognitive Science, San
Sebastian, Spain.
</reference>
<page confidence="0.999128">
82
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.085835">
<title confidence="0.995805">Reference reversibility with Reference Domain Theory</title>
<author confidence="0.905289">Alexandre</author>
<address confidence="0.344044">TALARIS team / UMR 7503 Lorraine. Campus scientifique, BP F-54506 Vandoeuvre-les-Nancy</address>
<email confidence="0.894596">alexandre.denis@loria.fr</email>
<abstract confidence="0.995028">In this paper we present a reference model based on Reference Domain Theory that can work both in interpretation and generation. We introduce a formalization of key concepts of RDT, the interpretation and generation algorithms and show an example of behavior in the dynamic, asymmetric and multimodal GIVE environment.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Hel�ene Bonneau Maynard</author>
<author>Matthieu Quignard</author>
<author>Alexandre Denis</author>
</authors>
<title>MEDIA: a semantically annotated corpus of task oriented dialogs in French. Language Resources and Evaluation,</title>
<date>2009</date>
<pages>43--4</pages>
<contexts>
<context position="13641" citStr="Maynard et al., 2009" startWordPosition="2462" endWordPosition="2465"> Domain Theory proves to rely on less instructions than other systems (224) and proves to be the most successful (47% of task success) while being the fastest (344 seconds). We conjecture that the good results of RDT can be explained by the low cognitive load resulting from the use of demonstrative NPs and one-anaphoras, but the role of the overall generation strategy has also to be taken into account in these good results (Denis et al., 2010). Although it would be very interesting, the interpretation side has not yet been evaluated in the GIVE setting, but only in the MEDIA campaign (Bonneau Maynard et al., 2009) which is an unimodal setting. The results show that the interpretation side of RDT achieves a fair precision in identification (75.2%) but a low recall (44.7%). We assume that the low recall of the module is caused by the cascade of errors, one error at the start of a reference chain leading to several other errors. Nonetheless, we estimate that error cascading would be less problematic in the GIVE setting because of its dynamicity. 7 Conclusions We presented a reference framework extending (Salmon-Alt and Romary, 2001) in which interpretation and generation can be defined in terms of the con</context>
</contexts>
<marker>Maynard, Quignard, Denis, 2009</marker>
<rawString>Hel�ene Bonneau Maynard, Matthieu Quignard, and Alexandre Denis. 2009. MEDIA: a semantically annotated corpus of task oriented dialogs in French. Language Resources and Evaluation, 43(4):329–354.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donna K Byron</author>
<author>Thomas Mampilly</author>
<author>Vinay Sharma</author>
<author>Tianfang Xu</author>
</authors>
<title>Utilizing visual attention for cross-modal coreference interpretation.</title>
<date>2005</date>
<booktitle>In Proceedings of Context-05,</booktitle>
<pages>83--96</pages>
<contexts>
<context position="8585" citStr="Byron et al., 2005" startWordPosition="1520" endWordPosition="1523">hypothesis) and one in which t =� t&apos; (the separation hypothesis). If this cannot be the case, t is added as a new object. Following (DeVault and Stone, 2007), these alternative contexts can persist across time and further referring expressions may reject one or the other hypothesis as illustrated in section 5. The second required mechanism is the proper handling of the multimodal dynamic focus, that is the combination of the linguistic focus resulting from RE, and the visual focus. It is possible to have two referential spaces for the linguistic or visual context as in (Kelleher et al., 2005; Byron et al., 2005), or to have two foci in a partition. We can also model interleaved focus, that is, only one focus per domain but that dynamically corresponds to the linguistic focus or the visual focus. The idea is that after each RE, the referent receives the focus as described in algorithm 1, but whenever the visual context changes, the focus is updated to the visible objects. Although interleaved focus prevents anaphora while the visual context changes, its complexity is enough for our setup. 80 Algorithm 1 interpret(U(N,.), RS) 1: for all domain D in RS by salience order do 2: for all t E GD do 3: if U(N</context>
</contexts>
<marker>Byron, Mampilly, Sharma, Xu, 2005</marker>
<rawString>Donna K. Byron, Thomas Mampilly, Vinay Sharma, and Tianfang Xu. 2005. Utilizing visual attention for cross-modal coreference interpretation. In Proceedings of Context-05, pages 83–96.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexandre Denis</author>
<author>Marilisa Amoia</author>
<author>Luciana Benotti</author>
<author>Laura Perez-Beltrachini</author>
<author>Claire Gardent</author>
<author>Tarik Osswald</author>
</authors>
<date>2010</date>
<booktitle>The GIVE-2 Nancy Generation Systems NA and NM. Technical report.</booktitle>
<contexts>
<context position="13467" citStr="Denis et al., 2010" startWordPosition="2431" endWordPosition="2434"> RS remains. 6 Evaluation Only the generation direction has been evaluated in the GIVE challenge. The results (Koller et al., 2010) show that the system embedding Reference Domain Theory proves to rely on less instructions than other systems (224) and proves to be the most successful (47% of task success) while being the fastest (344 seconds). We conjecture that the good results of RDT can be explained by the low cognitive load resulting from the use of demonstrative NPs and one-anaphoras, but the role of the overall generation strategy has also to be taken into account in these good results (Denis et al., 2010). Although it would be very interesting, the interpretation side has not yet been evaluated in the GIVE setting, but only in the MEDIA campaign (Bonneau Maynard et al., 2009) which is an unimodal setting. The results show that the interpretation side of RDT achieves a fair precision in identification (75.2%) but a low recall (44.7%). We assume that the low recall of the module is caused by the cascade of errors, one error at the start of a reference chain leading to several other errors. Nonetheless, we estimate that error cascading would be less problematic in the GIVE setting because of its </context>
</contexts>
<marker>Denis, Amoia, Benotti, Perez-Beltrachini, Gardent, Osswald, 2010</marker>
<rawString>Alexandre Denis, Marilisa Amoia, Luciana Benotti, Laura Perez-Beltrachini, Claire Gardent, and Tarik Osswald. 2010. The GIVE-2 Nancy Generation Systems NA and NM. Technical report.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexandre Denis</author>
</authors>
<title>Generating referring expressions with Reference Domain Theory.</title>
<date>2010</date>
<booktitle>In Proceedings of the 6th International Natural Language Generation Conference - INLG 2010,</booktitle>
<location>Dublin, Ireland.</location>
<contexts>
<context position="1364" citStr="Denis, 2010" startWordPosition="209" endWordPosition="210">nerate the REs for the objects it aims to refer to. We present in this paper a framework that considers that reference interpretation and generation are two sides of the same coin, hence avoiding any potential misunderstanding arising from the two modules discrepancies. Reference Domain Theory (RDT) (Salmon-Alt and Romary, 2000; SalmonAlt and Romary, 2001) proposes to represent the diversity of referring acts by the diversity of constraints they impose on their context of use. The reversibility then lies in the possibility to express these constraints independently of the considered task. In (Denis, 2010) we described the generation side of RDT in the context of the GIVE-2 challenge (Koller et al., 2010) which is an evaluation of instruction generation systems in a 3D maze. In this paper we propose the interpretation counterpart and show the required modeling to consider the dynamic, asymmetric and multimodal context of GIVE. We first present the reference model in section 2 and 3, discuss the interpretation problems in GIVE in section 4, detail an example in section 5 and present evaluation results in section 6. 2 Reference Domains A rich contextual structure is required to give an account fo</context>
<context position="7056" citStr="Denis, 2010" startWordPosition="1260" endWordPosition="1261"> opposite, that is it finds an UD from an input RD. It first selects a RD containing the target referent to generate t, assuming here that the most salient domain has to be preferred. The description N used to instantiate the UDs is composed of the description of the domain and the description of the referent in the partition (line 2). It then iterates through the different UDs by Givenness order (Gundel et al., 1993) and selects the first one that matches. A restructuring operation is applied and the found UD is returned, eventually providing the RE. The restructuring operation, detailed in (Denis, 2010), aims to restrict the current context by creating a new domain around the referent in the referential space or by increasing the salience of the domain containg the referent. This operation helps to perform focalization in restricted domains. 4 The complex context of GIVE The dynamic, asymmetric and multimodal context of GIVE requires additional mechanisms for interpretation. Asymmetry causes the late visual context integration, when the direction giver produces a RE to objects not yet known by the direction follower, that are only visually discovered later on. Space prevents us to describe i</context>
<context position="9855" citStr="Denis, 2010" startWordPosition="1761" endWordPosition="1762"> D 6: return t 7: end if 8: end for 9: end for 10: return accommodate(U(N, .), RS) Algorithm 2 generate(t, RS) 1: D most salient domain containing t 2: N SD U {p|p E val(c), p(t) E V } 3: for all U(N, t) sorted by Givenness do 4: if U(N, t) matches D then 5: restructure(D, N, RS) 6: return U(N, t) 7: end if 8: end for 9: return failure Figure 2: Reference algorithms, relying on the same underspecified domains 5 Example In this section we present the interpretation side of some expressions we generated in the GIVE setting (table 2). The detailed generation side of this example can be found in (Denis, 2010). S is the system that interprets the RE of U the user. The situation is: S enters a room with two blue buttons b1 and b2, none of them being visible when he enters and U wants to refer to b1. However, U utters “Not this one!&amp;quot; rejecting then the fusion hypothesis. To be able to consider the effects of this utterance, we have to take into account the ellipsis. This can be done by assuming that U is asserting properties of the target of his first RE, that is, he is actually stating that “[t is] not this one!&amp;quot;. The RE “this one” leads to the construction of a demonstrative one-anaphora UD that ma</context>
</contexts>
<marker>Denis, 2010</marker>
<rawString>Alexandre Denis. 2010. Generating referring expressions with Reference Domain Theory. In Proceedings of the 6th International Natural Language Generation Conference - INLG 2010, Dublin, Ireland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David DeVault</author>
<author>Matthew Stone</author>
</authors>
<title>Managing ambiguities across utterances in dialogue.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Workshop on the Semantics and Pragmatics of Dialogue (DECALOG</booktitle>
<location>Trento, Italy.</location>
<contexts>
<context position="8123" citStr="DeVault and Stone, 2007" startWordPosition="1444" endWordPosition="1447">direction giver produces a RE to objects not yet known by the direction follower, that are only visually discovered later on. Space prevents us to describe in details the late integration algorithm, but the idea is, given a new physical object t, to scan existing domains of the actual RS to check if t can be merged semantically with any previous object t&apos;. If this could be the case, the integration leads to create two parallel RS, one in which t = t&apos; (the fusion hypothesis) and one in which t =� t&apos; (the separation hypothesis). If this cannot be the case, t is added as a new object. Following (DeVault and Stone, 2007), these alternative contexts can persist across time and further referring expressions may reject one or the other hypothesis as illustrated in section 5. The second required mechanism is the proper handling of the multimodal dynamic focus, that is the combination of the linguistic focus resulting from RE, and the visual focus. It is possible to have two referential spaces for the linguistic or visual context as in (Kelleher et al., 2005; Byron et al., 2005), or to have two foci in a partition. We can also model interleaved focus, that is, only one focus per domain but that dynamically corresp</context>
</contexts>
<marker>DeVault, Stone, 2007</marker>
<rawString>David DeVault and Matthew Stone. 2007. Managing ambiguities across utterances in dialogue. In Proceedings of the 2007 Workshop on the Semantics and Pragmatics of Dialogue (DECALOG 2007), Trento, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeanette K Gundel</author>
<author>Nancy Hedberg</author>
<author>Ron Zacharski</author>
</authors>
<title>Cognitive status and the form of referring expressions in discourse.</title>
<date>1993</date>
<journal>Language,</journal>
<volume>69</volume>
<issue>2</issue>
<contexts>
<context position="6865" citStr="Gundel et al., 1993" startWordPosition="1228" endWordPosition="1231">U(N, t) are created. According to the task, this accommodation may not be possible for all REs, but for sake of simplicity we assume here this operation is always possible. The generation side is the opposite, that is it finds an UD from an input RD. It first selects a RD containing the target referent to generate t, assuming here that the most salient domain has to be preferred. The description N used to instantiate the UDs is composed of the description of the domain and the description of the referent in the partition (line 2). It then iterates through the different UDs by Givenness order (Gundel et al., 1993) and selects the first one that matches. A restructuring operation is applied and the found UD is returned, eventually providing the RE. The restructuring operation, detailed in (Denis, 2010), aims to restrict the current context by creating a new domain around the referent in the referential space or by increasing the salience of the domain containg the referent. This operation helps to perform focalization in restricted domains. 4 The complex context of GIVE The dynamic, asymmetric and multimodal context of GIVE requires additional mechanisms for interpretation. Asymmetry causes the late vis</context>
</contexts>
<marker>Gundel, Hedberg, Zacharski, 1993</marker>
<rawString>Jeanette K. Gundel, Nancy Hedberg, and Ron Zacharski. 1993. Cognitive status and the form of referring expressions in discourse. Language, 69(2):274–307.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Kelleher</author>
<author>Fintan Costello</author>
<author>Josef van Genabith</author>
</authors>
<title>Dynamically structuring, updating and interrelating representations of visual and linguistic discourse context.</title>
<date>2005</date>
<journal>Artificial Intelligence,</journal>
<pages>167--1</pages>
<marker>Kelleher, Costello, van Genabith, 2005</marker>
<rawString>John Kelleher, Fintan Costello, and Josef van Genabith. 2005. Dynamically structuring, updating and interrelating representations of visual and linguistic discourse context. Artificial Intelligence, 167(1-2):62–102.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Klarner</author>
</authors>
<title>Reversibility and reusability of resources in NLG and natural language dialog systems.</title>
<date>2005</date>
<booktitle>In Proceedings of the 10th European Workshop on Natural Language Generation (ENLG-05),</booktitle>
<location>Aberdeen, Scotland.</location>
<contexts>
<context position="3921" citStr="Klarner, 2005" startWordPosition="667" endWordPosition="668">)) Finally we define a referential space (RS) as a set of reference domains (RD) ordered by salience. 3 Referring A RE impose some constraints on the context in which it can be uttered, that is in which RD the interpretation has to be made. The constraints are represented as underspecified domains (UD), specifying the structure of the suitable RD in terms of ground, salience or partition. The explicit definitions of the UDs makes possible to share these definitions between the interpretation and the generation modules, hence allowing the implementation of a type B reversible reference module (Klarner, 2005), that is a module in which both directions share the same resources. Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 79–82, The University of Tokyo, September 24-25, 2010. p@c 2010 Association for Computational Linguistics 79 Expression U(N, t) matches D iff 3(c, P, F) E D; this one F = {{t}} ∧ msd(D) this N F = {{t}} ∧ t E N2 the N t E N2 ∧ {t} E P ∧ VX EP, X =�{t}=�.XflN2 =0 the other one F =� 0 ∧ P \ F = {{t}} ∧ msd(D) the other N F =� 0 ∧ P \ F = {{t}} ∧ GD C N2 another one F =� 0 ∧ {t} E P \ F ∧ msd(D) another N F =� 0 ∧</context>
</contexts>
<marker>Klarner, 2005</marker>
<rawString>Martin Klarner. 2005. Reversibility and reusability of resources in NLG and natural language dialog systems. In Proceedings of the 10th European Workshop on Natural Language Generation (ENLG-05), Aberdeen, Scotland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Koller</author>
<author>Kristina Striegnitz</author>
<author>Andrew Gargett</author>
<author>Donna Byron</author>
<author>Justine Cassell</author>
<author>Robert Dale</author>
<author>Johanna Moore</author>
<author>Jon Oberlander</author>
</authors>
<title>Report on the second NLG challenge on generating instructions in virtual environments (GIVE-2).</title>
<date>2010</date>
<booktitle>In Proceedings of the 6th International Natural Language Generation Conference - INLG 2010,</booktitle>
<location>Dublin, Ireland.</location>
<contexts>
<context position="1465" citStr="Koller et al., 2010" startWordPosition="225" endWordPosition="228"> considers that reference interpretation and generation are two sides of the same coin, hence avoiding any potential misunderstanding arising from the two modules discrepancies. Reference Domain Theory (RDT) (Salmon-Alt and Romary, 2000; SalmonAlt and Romary, 2001) proposes to represent the diversity of referring acts by the diversity of constraints they impose on their context of use. The reversibility then lies in the possibility to express these constraints independently of the considered task. In (Denis, 2010) we described the generation side of RDT in the context of the GIVE-2 challenge (Koller et al., 2010) which is an evaluation of instruction generation systems in a 3D maze. In this paper we propose the interpretation counterpart and show the required modeling to consider the dynamic, asymmetric and multimodal context of GIVE. We first present the reference model in section 2 and 3, discuss the interpretation problems in GIVE in section 4, detail an example in section 5 and present evaluation results in section 6. 2 Reference Domains A rich contextual structure is required to give an account for the different kinds of discrimination we observe in REs such as semantic discrimination (e.g. “the </context>
<context position="12979" citStr="Koller et al., 2010" startWordPosition="2346" endWordPosition="2349">{button, blue}, 3, (id, {{t}, {b1}, {b2}}, {{b1}})) Eventually S has to interpret “this one&amp;quot;. Like previously, in order to take into account the effects of this utterance, S has to resolve the ellipsis and must consider “[t is] this one&amp;quot;. The RE “this one” is resolved on t in D1FUS but on b1 in D1SEP. 81 t is this one fusion t = t separation t = bl This is now the separation hypothesis which is inconsistent because we assumed that b1 # t. This RS is then ruled out, and only the fusion RS remains. 6 Evaluation Only the generation direction has been evaluated in the GIVE challenge. The results (Koller et al., 2010) show that the system embedding Reference Domain Theory proves to rely on less instructions than other systems (224) and proves to be the most successful (47% of task success) while being the fastest (344 seconds). We conjecture that the good results of RDT can be explained by the low cognitive load resulting from the use of demonstrative NPs and one-anaphoras, but the role of the overall generation strategy has also to be taken into account in these good results (Denis et al., 2010). Although it would be very interesting, the interpretation side has not yet been evaluated in the GIVE setting,</context>
</contexts>
<marker>Koller, Striegnitz, Gargett, Byron, Cassell, Dale, Moore, Oberlander, 2010</marker>
<rawString>Alexander Koller, Kristina Striegnitz, Andrew Gargett, Donna Byron, Justine Cassell, Robert Dale, Johanna Moore, and Jon Oberlander. 2010. Report on the second NLG challenge on generating instructions in virtual environments (GIVE-2). In Proceedings of the 6th International Natural Language Generation Conference - INLG 2010, Dublin, Ireland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Susanne Salmon-Alt</author>
<author>Laurent Romary</author>
</authors>
<title>Generating referring expressions in multimodal contexts.</title>
<date>2000</date>
<booktitle>In Workshop on Coherence in Generated Multimedia - INLG</booktitle>
<contexts>
<context position="1081" citStr="Salmon-Alt and Romary, 2000" startWordPosition="162" endWordPosition="165">mple of behavior in the dynamic, asymmetric and multimodal GIVE environment. 1 Introduction The reference task in a dialogue system is two-fold. On the one hand the system has to interpret the referring expressions (RE) produced by the user in his utterances. On the other hand the system has to generate the REs for the objects it aims to refer to. We present in this paper a framework that considers that reference interpretation and generation are two sides of the same coin, hence avoiding any potential misunderstanding arising from the two modules discrepancies. Reference Domain Theory (RDT) (Salmon-Alt and Romary, 2000; SalmonAlt and Romary, 2001) proposes to represent the diversity of referring acts by the diversity of constraints they impose on their context of use. The reversibility then lies in the possibility to express these constraints independently of the considered task. In (Denis, 2010) we described the generation side of RDT in the context of the GIVE-2 challenge (Koller et al., 2010) which is an evaluation of instruction generation systems in a 3D maze. In this paper we propose the interpretation counterpart and show the required modeling to consider the dynamic, asymmetric and multimodal contex</context>
</contexts>
<marker>Salmon-Alt, Romary, 2000</marker>
<rawString>Susanne Salmon-Alt and Laurent Romary. 2000. Generating referring expressions in multimodal contexts. In Workshop on Coherence in Generated Multimedia - INLG 2000, Israel.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Susanne Salmon-Alt</author>
<author>Laurent Romary</author>
</authors>
<title>Reference resolution within the framework of cognitive grammar.</title>
<date>2001</date>
<booktitle>In Proceeding of the International Colloquium on Cognitive Science,</booktitle>
<location>San Sebastian,</location>
<contexts>
<context position="14167" citStr="Salmon-Alt and Romary, 2001" startWordPosition="2550" endWordPosition="2553"> yet been evaluated in the GIVE setting, but only in the MEDIA campaign (Bonneau Maynard et al., 2009) which is an unimodal setting. The results show that the interpretation side of RDT achieves a fair precision in identification (75.2%) but a low recall (44.7%). We assume that the low recall of the module is caused by the cascade of errors, one error at the start of a reference chain leading to several other errors. Nonetheless, we estimate that error cascading would be less problematic in the GIVE setting because of its dynamicity. 7 Conclusions We presented a reference framework extending (Salmon-Alt and Romary, 2001) in which interpretation and generation can be defined in terms of the constraints imposed by the referring expressions on their context of use. The two modules sharing the same library of constraints, the model is then said reversible. However, because of the asymmetry and dynamicity of our setup, the GIVE challenge, additional mechanisms such as uncertainty have to be modeled. In particular, we have to maintain different interpretation contexts like (DeVault and Stone, 2007) to take into account the ambiguity arising from the late integration of the visual context. It would be interesting no</context>
</contexts>
<marker>Salmon-Alt, Romary, 2001</marker>
<rawString>Susanne Salmon-Alt and Laurent Romary. 2001. Reference resolution within the framework of cognitive grammar. In Proceeding of the International Colloquium on Cognitive Science, San Sebastian, Spain.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>