<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001754">
<title confidence="0.982313">
SINAI: Syntactic approach for Aspect Based Sentiment Analysis
</title>
<author confidence="0.9754425">
Salud M. Jim´enez-Zafra, Eugenio Martinez-C´amara,
M. Teresa Martin-Valdivia, L. Alfonso Ure˜na-L´opez
</author>
<affiliation confidence="0.889014">
SINAI Research Group
University of Ja´en
E-23071, Ja´en (Spain)
</affiliation>
<email confidence="0.984296">
{sjzafra, emcamara, maite, laurena}@ujaen.es
</email>
<sectionHeader confidence="0.995486" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9994955">
This paper describes the participation of the
SINAI research group in the task Aspect
Based Sentiment Analysis of SemEval Work-
shop 2015 Edition. We propose a syntactic
approach for identifying the words that mod-
ify each aspect, with the aim of classifying the
sentiment expressed towards each attribute of
an entity.
</bodyText>
<sectionHeader confidence="0.998797" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999829357142858">
Opinion Mining (OM), also known as Sentiment
Analysis (SA), is the discipline that focuses on the
computational treatment of opinion, sentiment and
subjectivity in texts (Pang and Lee, 2008). Cur-
rently, OM is a trendy task in the field of Natural
Language Processing, due mainly to the fact of the
proliferation of user-generated content and the in-
terest in the knowledge of the opinion of people by
consumers and businesses.
Most of the systems developed up to now carry
out opinion analysis at document level ((Pang et al.,
2002), (Turney, 2002)) or at sentence level ((Wilson
et al., 2005), (Yu and Hatzivassiloglou, 2003)), that
is, they determine the overall sentiment expressed
by the reviewer about the topic, product, person... of
study. However, the fact that the overall sentiment of
a product is positive does not mean that the author
thinks that all the aspects of the product are posi-
tives, or the fact that is negative does not involve that
everything about the product is bad. For this reason,
users and companies are not satisfied with knowing
the overall sentiment of a product or service, they
seek a more detailed knowledge. Consequently, to
achieve a higher level of detail, part of the scientific
community related to this area is working on SA at
aspect level ((Quan and Ren, 2014), (Marcheggiani
et al., 2014), (Lu et al., 2011), (Thet et al., 2010))
and even, there is a competition on this topic that
began to conduct last year (Pontiki et al., 2014) in
the International Workshop on Semantic Evaluation
2014 (SemEval 2014).
This year, the 2015 edition of SemEval has
also proposed a task for SA at aspect level. The
SemEval-2015 Aspect Based Sentiment Analysis
task is a continuation of SemEval-2014 Task 4 (Pon-
tiki et al., 2014). The aim of this task is to identify
the attributes of an entity that are being reviewed
and the sentiment expressed for each one. It is di-
vided into three slots. The first one is focused on
the identification of every entity E and attribute A
pair (E#A) towards which an opinion is expressed
in the given text. Slot 2 proposes to determine the
expression used in the text to refer to the reviewed
entity, that is, the Opinion Target Expression (OTE).
Finally, Slot 3 has as goal to classify the sentiment
expressed over each category (E#A pair) as positive,
negative or neutral. We have participated in the slot
related to sentiment polarity (Slot 3).
Due to the fact that OM is a domain-dependent
task, the organization proposes the three slots in dif-
ferent domains, two known (restaurants and laptops)
and one unknown until the evaluation (hotels). A
wider description of the task and the dataset used
can be found in the task description paper (Pontiki
et al., 2015).
The rest of the paper is organized as follows. Sec-
</bodyText>
<page confidence="0.941868">
730
</page>
<bodyText confidence="0.805609666666667">
Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 730–735,
Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics
tion 2 describes the system developed and the re-
sources that we have used. To sum up, the results
reached and an analysis of the same are shown in
Section 3.
</bodyText>
<sectionHeader confidence="0.724893" genericHeader="introduction">
2 System description - Slot 3
</sectionHeader>
<bodyText confidence="0.999995307692308">
As we have mentioned above, we have taken part
in the Slot 3. The aim of this slot is to identify the
polarity of each category or each &lt;category, OTE&gt;
pair on which an opinion is expressed in a given re-
view. This task has been carried out on two known
domains an one unknown domain. For each of the
known domains, restaurants and laptops, the organi-
zation has provided a dataset for training, whereas
for the unknown domain any information has been
given until the test set has been released. Therefore,
we have used a supervised method for restaurants
and laptops domains and we have developed an un-
supervised method for the unknown domain.
</bodyText>
<subsectionHeader confidence="0.993778">
2.1 Slot 3 - Restaurant domain ABSA
</subsectionHeader>
<bodyText confidence="0.999932692307692">
The training data related to restaurants domain con-
tains 254 reviews. Each review is composed of dif-
ferent sentences annotated with opinion tuples. Each
opinion tuple has information about the Opinion Tar-
get Expression (OTE), the Entity and Attribute pair
(E#A category) towards the opinion is expressed, the
polarity (positive, negative or neutral) and the posi-
tion of the OTE in the text (from - to).
Using this information we have developed differ-
ent experiments for polarity prediction. In all of
them an SVM classifier of type C-SVC with lin-
ear kernel and the default configuration has been
trained, and a 10-fold-cross validation model has
been used for the assessment (Table 1).
The features that have provided the best results
in the training and that we have used for our par-
ticipation in this slot are the following. For each
&lt;category, OTE, polarity&gt; tuple of the training
data, we have used as label the polarity value and as
features the words that modify the OTE, their PoS
tag, their syntactic relation and their polarity using
three lexicons (taking into account negation): Senti-
WordNet (Baccianella et al., 2010), MPQA (Wilson
et al., 2005) and eBLR (enriched version of Bing Liu
Lexicon (Hu and Liu, 2004) adapted to restaurant
domain). Below, we describe briefly how this infor-
</bodyText>
<table confidence="0.99934588">
Exp. Type Accuracy Features
Exp 1 U 75.57% Modifying words,
PoS, syntactic
relation, polarity
(SentiWordNet,
MPQA, BinLiu)
Exp 2 U 75.88% Modifying words,
PoS, syntactic
relation, polarity
(SentiWordNet,
MPQA, BinLiu)
taking into
account negation
Exp 3 U 75.67% Modifying words,
PoS, syntactic
relation, polarity
(SentiWordNet,
MPQA, eBLR)
Exp 4 U 75.94% Modifying words,
PoS, syntactic
relation, polarity
(SentiWordNet,
MPQA, eBLR)
taking into
account negation
</table>
<tableCaption confidence="0.9793445">
Table 1: Experiments restaurants training data (U =
Unconstrained, C = Constrained).
</tableCaption>
<bodyText confidence="0.995140333333333">
mation has been obtained. Thereby, each &lt;category,
OTE&gt; tuple of the test data is classified using its fea-
tures vector and the trained SVM model.
</bodyText>
<sectionHeader confidence="0.50812" genericHeader="background">
2.1.1 Features
</sectionHeader>
<subsectionHeader confidence="0.332449">
Words that modify the OTE
</subsectionHeader>
<bodyText confidence="0.96657025">
We call words that modify an OTE those words
that specifically have been used in the review to
discuss about the OTE. In order to determine what
these words are, we use the Stanford Dependencies
Parser&apos;. This parser was designed to provide a sim-
ple description of the grammatical relationships that
can appear in a sentence and it can be easily under-
stood and effectively used by people without linguis-
tic expertise who want to extract textual relations
(De Marneffe and Manning, 2008). It represents
all sentence relationships uniformly as typed depen-
&apos;http://nlp.stanford.edu/software/lex-parser.shtml
</bodyText>
<page confidence="0.989185">
731
</page>
<bodyText confidence="0.999792846153846">
dency relations. In this experiment, we have consid-
ered the main relationships for expressing opinion
about a noun or nominal expression: using an ad-
jectival modifier (“amod”), an active or passive verb
(“nsub”, “nsubjpass”), a noun compound modifier
(“nn”) or a dependency relation with another word
(“dep”). In this way, for each OTE of a review,
we use these relationships to extract all the words
that modify the aspect of the entity that has been re-
viewed and we use them as features. If there is no
word related to the aspect using these relationships,
the previous word to the OTE and the following four
words will be used.
</bodyText>
<subsectionHeader confidence="0.827352">
Pos Tag
</subsectionHeader>
<bodyText confidence="0.999527333333333">
In addition, for each of the words that modify an
aspect we get their particular Part of Speech Tag
(noun, verb, adjective... ).
</bodyText>
<subsectionHeader confidence="0.91218">
Syntactic relations
</subsectionHeader>
<bodyText confidence="0.981599222222222">
As it has been mentioned above, the syntactic re-
lation of each modifying word with the OTE has also
been used as feature.
Polarity
The last feature of our SVM classifier is the polar-
ity of each modifying word according to three lexi-
cons: SentiWordNet, MPQA and eBLR. In addition,
it has been used the fixed window method for the
treatment of negation. Then, if any of the preceding
or following 3 words is a negative particle (“not”,
“n’t”, “no”, “never”... ), the modifying word polar-
ity will be reversed (positive —&gt; negative, negative
—&gt; positive, neutral —&gt; neutral).
SentiWordNet is a lexical resource that assigns to
each synset of WordNet2 (Miller, 1995) three senti-
ment scores (positivity, negativity and objectivity)
that describe how positive, negative and objective
the terms contained in the synset are.
MPQA is a subjectivity lexicon formed by over
8000 subjectivity clues. For each word, it has infor-
mation about its prior polarity, its part of speech tag
and its grade of subjectivity (strong or weak).
Finally, eBLR is an enriched version of Bing Liu
Lexicon that we explain below. As is well-known
in the SA research community, the semantic orienta-
tion of a word is domain-dependent. Therefore, we
decided to generate a list of opinion words for the
</bodyText>
<footnote confidence="0.884661">
2Wordnet is an English lexical database which groups words
according to their meaning.
</footnote>
<bodyText confidence="0.999792882352941">
restaurant domain, taking as baseline the Bing Liu
Lexicon and using the training data for restaurant
domain supplied by the organization. For this, we
have employed a corpus-based approach following
the methodology of (Molina-Gonz´alez et al., 2013)
that consists of the use of a sentiment labeled corpus
in order to select the most frequent positive and neg-
ative words. A word is added to the list of opinion
positive words if it only appears in positive reviews
and its frequency exceeds a certain threshold. The
same process is followed for negative words. In the
case of words that appear in both positive and neg-
ative reviews, a word is considered as opinion posi-
tive/negative word if the frequency of occurrence in
positive/negative reviews exceeds the frequency of
occurrence in negative/positive reviews in a certain
threshold.
</bodyText>
<subsectionHeader confidence="0.965549">
2.2 Slot 3 - Laptops domain ABSA
</subsectionHeader>
<bodyText confidence="0.999974">
The training data for laptops domain contains 277
reviews. Each review has different sentences anno-
tated at aspect level with the Entity and Attribute
pair (E#A category) towards each opinion is ex-
pressed and the polarity (positive, negative or neu-
tral). In this case no information about the OTE is
provided and thus, we have followed a different ap-
proach to that used in the restaurant domain. We
have also developed different experiments with an
SVM classifier of type C-SVC with linear kernel
and the default configuration, and we have also used
a 10-fold-cross validation model for the assessment
but with different features (Table 2).
</bodyText>
<table confidence="0.999796416666666">
Exp. Type Accuracy Features
Exp 1 C 75.08% Unigrams, PoS
Exp 2 U 73.76% Unigrams, total
positive words
(Bin Liu), total
negative words
(Bin Liu)
Exp 3 U 79.64% Unigrams, total
positive words
(eBLL), total
negative words
(eBLL)
</table>
<tableCaption confidence="0.988898">
Table 2: Experiments laptops training data (U =
Unconstrained, C = Constrained).
</tableCaption>
<page confidence="0.99619">
732
</page>
<bodyText confidence="0.998446285714286">
For this domain we have submitted two runs,
one constrained (using only the provided training
data) and another unconstrained (using additional
resources for training). These experiments are those
that have provided better results with the training
data and we have used them for our participation in
this domain.
</bodyText>
<listItem confidence="0.822431631578947">
• SINAI B Lap 1 (Exp 1 - constrained). For
each &lt;category(E#A pair), polarity&gt; tuple of
the training data we have used as label the po-
larity and as features the entity and the specific
attribute of this entity about someone is review-
ing, and all the words of the sentence with their
pertinent Part of Speech Tag.
• SINAI B Lap 2 (Exp 3 - unconstrained). In
this case, the features that we have selected
for each &lt;category (E#A pair), polarity&gt; tu-
ple of the training data are the entity and the
attribute about someone is reviewing, all the
words of the sentence and the number of pos-
itive and negative opinion words according to
eBLL. eBLL is an enriched version of Bing Liu
Lexicon for laptops domain. It has been built
using the training data supplied by the organi-
zation for laptops domain, in the same way that
eBLR Lexicon.
</listItem>
<bodyText confidence="0.999216620689656">
to extract all the words that modify it and we use
them to determine the sentiment expressed about the
OTE. If there is no word related to the aspect us-
ing these relationships, the previous word to the as-
pect and the following four words will be used. We
calculate the polarity of each OTE through a voting
system based on three classifiers: Bing Liu Lexicon,
SentiWordNet and MPQA. To do this we determine,
with each of the classifiers individually, the polarity
of an OTE using the words that modify it. Thus, ac-
cording to Bing Liu Lexicon, we count the number
of positive (pw) and negative words (nw) that mod-
ify the OTE and tag it following the equation 1. On
the other hand, we use MPQA as classifier following
the same approach but in this case we take into ac-
count the PoS of the modifying words in order to get
their polarity. At last, we employ SentiWordNet also
following the approach of comparing the number of
positive and negative words but as this lexicon as-
signs three sentiment scores to each synset, we cal-
culate the polarity of each modifying word using the
Denecke method (Denecke, 2008), that is, we cal-
culate the average of the positivity, negativity and
objectivity scores of all the synsets of the word with
the same PoS and assign the word the polarity of the
highest average.
Thus, given a category of the test data, it is clas- pol(OTE) = I positive if (pw &gt; nw) (1)
sified using its features vector and the trained SVM negative if (pw &lt; nw)
model. neutral if (pw = nw)
</bodyText>
<subsectionHeader confidence="0.986426">
2.3 Slot 3 - Out of domain ABSA
</subsectionHeader>
<bodyText confidence="0.999986956521739">
For the last domain, the organization has not pro-
vided any information until the test set has been re-
leased. We only knew that we had to assign a polar-
ity value for each &lt;OTE, category&gt; tuple present
in the test data. In this case we have followed an
unsupervised approach that we present below.
In order to classify the sentiment expressed about
each OTE is important to determine the words that
have been used in the review to discuss about the
aspect. For this, we have employed the Stanford De-
pendencies Parser and the main relationships for ex-
pressing opinion about a noun or nominal expres-
sion: “amod”, “nsubj”, “nsubjpass”, “nn”, “dep”
(they are explained in Subsection 2.1). In this way,
for each OTE of a review, we use these relationships
Therefore, an OTE is positive/negative if there are
at least two classifiers that tag it as positive/negative
and neutral in another case. It may happen that an
OTE is affected by negation, so if any of the pre-
ceding or following 3 words is a negative particle
(“not”, “n’t”, “no”, “never”... ), the OTE polarity
will be reversed (positive —&gt; negative, negative —
&gt; positive, neutral —&gt; neutral).
</bodyText>
<subsectionHeader confidence="0.5257">
3 Analysis of results
</subsectionHeader>
<bodyText confidence="0.999498142857143">
This section shows the results reached in the evalua-
tion of the task using the system described in Section
2. Table 3 presents the official results of our submis-
sions. We also include the results of the best team
and the average of all participants for comparision.
A clear difference between the results obtained by
our team and the average may be seen in Table 3.
</bodyText>
<page confidence="0.996831">
733
</page>
<bodyText confidence="0.999870833333333">
Furthermore, the results in restaurants and laptops
domain are worse than those achieved in the train-
ing phase (Table 1 and Table 2). Therefore, we have
calculated the confusion matrix related to each ex-
periment for a deeper analysis (Table 4, Table 5, Ta-
ble 6 and Table 7).
</bodyText>
<table confidence="0.998646222222222">
Accuracy
SINAI Avg. Best
team
Restaurants 0.6071 (U) 0.7119 0.7870
(U)
0.6586 (C) 0.7935
Laptops 0.5184 (U) 0.7093 (U)
Hotels 0.6372 (U) 0.7079 0.8053
(U)
</table>
<tableCaption confidence="0.975598">
Table 3: Results test data (U = Unconstrained, C =
Constrained).
</tableCaption>
<table confidence="0.999903428571429">
Laptops (U)
Pred. Pred. Pred. Recall
pos. neu. neg.
Real pos. 391 0 150 0.7227
Real neu. 63 0 16 0
Real neg. 228 0 101 0.3070
Precision 0.5733 0 0.3783
</table>
<tableCaption confidence="0.978353">
Table 6: Confusion matrix laptops unconstraint
submission.
</tableCaption>
<table confidence="0.999741">
Hotels
Pred. Pred. Pred. Recall
pos. neu. neg.
Real pos. 181 56 6 0.7449
Real neu. 5 6 1 0.5
Real neg. 15 40 29 0.3452
Precision 0.9005 0.0588 0.8056
</table>
<tableCaption confidence="0.994306">
Table 7: Confusion matrix hotels submission.
</tableCaption>
<table confidence="0.999614142857143">
Restaurants
Pred. Pred. Pred. Recall
pos. neu. neg.
Real pos. 446 0 8 0.9824
Real neu. 43 0 2 0
Real neg. 276 3 67 0.1936
Precision 0.583 0 0.8701
</table>
<tableCaption confidence="0.998057">
Table 4: Confusion matrix restaurants submission.
</tableCaption>
<table confidence="0.999705428571429">
Laptops (C)
Pred. Pred. Pred. Recall
pos. neu. neg.
Real pos. 491 0 50 0.9076
Real neu. 51 0 28 0
Real neg. 195 0 134 0.4073
Precision 0.6662 0 0.6321
</table>
<tableCaption confidence="0.990448">
Table 5: Confusion matrix laptops constraint
submission.
</tableCaption>
<table confidence="0.99940775">
Restaurants Laptops
Positive opinions 1198 1103
Neutral opinions 53 106
Negative opinions 403 765
</table>
<tableCaption confidence="0.999929">
Table 8: Opinions in training data per class.
</tableCaption>
<bodyText confidence="0.995617777777778">
If we observe Table 4, Table 5 and Table 6, we can
see that, in restaurants and laptops domains, the sys-
tem has failed mainly in the classification of negative
and neutral opinions. It has classified most of them
as positive. We think that one of the reasons may
be that the training data for restaurants and laptops
domains is unbalanced (Table 8). For restaurants,
the number of positive opinions is almost three times
the number of negative opinions. Another possible
reason, in restaurants domain, is that we have only
taken into account the scope (words that modify the
OTE) and not the whole context (all words present
in the review). In future works, we will do experi-
ments balancing the datasets in order to test how the
system works. Furthermore, we will take into ac-
count the whole context in restaurants domain to see
if that improves the system.
Regarding the unsupervised system, that has been
</bodyText>
<page confidence="0.993616">
734
</page>
<bodyText confidence="0.999924857142857">
tested with hotels domain, there are also differences
with respect to the mean accuracy of all teams (Table
3). This is a first approach that can be improved with
the consideration of other relationships to determine
which words modify the OTE and with a treatment
of negation more exhaustive. In future works we will
consider these possible improvements.
</bodyText>
<sectionHeader confidence="0.99809" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.998499285714286">
This work has been partially supported by a grant
from the Fondo Europeo de Desarrollo Regional
(FEDER), ATTOS project (TIN2012-38536-C03-0)
from the Spanish Government, AORESCU project
(P11-TIC-7684 MO) from the regional government
of Junta de Andaluc´ıa and CEATIC-2013-01 project
from the University of Ja´en.
</bodyText>
<sectionHeader confidence="0.999113" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997938285714286">
Stefano Baccianella, Andrea Esuli, and Fabrizio Sebas-
tiani. 2010. Sentiwordnet 3.0: An enhanced lexical
resource for sentiment analysis and opinion mining. In
LREC, volume 10, pages 2200–2204.
Marie-Catherine De Marneffe and Christopher D Man-
ning. 2008. Stanford typed dependencies manual.
Kerstin Denecke. 2008. Using sentiwordnet for multilin-
gual sentiment analysis. In Data Engineering Work-
shop, 2008. ICDEW 2008. IEEE 24th International
Conference on, pages 507–512. IEEE.
Minqing Hu and Bing Liu. 2004. Mining and summa-
rizing customer reviews. In Proceedings of the tenth
ACM SIGKDD international conference on Knowl-
edge discovery and data mining, pages 168–177.
ACM.
Bin Lu, Myle Ott, Claire Cardie, and Benjamin K Tsou.
2011. Multi-aspect sentiment analysis with topic mod-
els. In Data Mining Workshops (ICDMW), 2011 IEEE
11th International Conference on, pages 81–88. IEEE.
Diego Marcheggiani, Oscar T¨ackstr¨om, Andrea Esuli,
and Fabrizio Sebastiani. 2014. Hierarchical multi-
label conditional random fields for aspect-oriented
opinion mining. In Advances in Information Retrieval,
pages 273–285. Springer.
George A Miller. 1995. Wordnet: a lexical database for
english. Communications of the ACM, 38(11):39–41.
M Dolores Molina-Gonz´alez, Eugenio Martinez-C´amara,
Maria-Teresa Martin-Valdivia, and Jos´e M Perea-
Ortega. 2013. Semantic orientation for polarity clas-
sification in spanish reviews. Expert Systems with Ap-
plications, 40(18):7250–7257.
Bo Pang and Lillian Lee. 2008. Opinion mining and
sentiment analysis. Found. Trends Inf. Retr., 2(1-2):1–
135, January.
Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.
2002. Thumbs up?: Sentiment classification using
machine learning techniques. In Proceedings of the
ACL-02 Conference on Empirical Methods in Natural
Language Processing - Volume 10, EMNLP ’02, pages
79–86, Stroudsburg, PA, USA.
Maria Pontiki, Haris Papageorgiou, Dimitrios Galanis,
Ion Androutsopoulos, John Pavlopoulos, and Suresh
Manandhar. 2014. Semeval-2014 task 4: Aspect
based sentiment analysis. In Proceedings of the 8th
International Workshop on Semantic Evaluation (Se-
mEval 2014), pages 27–35.
Maria Pontiki, Dimitrios Galanis, Harris Papageorgiou,
Suresh Manandhar, and Ion Androutsopoulos. 2015.
Semeval-2015 task 12: Aspect based sentiment analy-
sis. In Proceedings of the 9th International Workshop
on Semantic Evaluation (SemEval 2015), Denver, Col-
orado.
Changqin Quan and Fuji Ren. 2014. Unsupervised prod-
uct feature extraction for feature-oriented opinion de-
termination. Information Sciences, 272:16–28.
Tun Thura Thet, Jin-Cheon Na, and Christopher SG
Khoo. 2010. Aspect-based sentiment analysis of
movie reviews on discussion boards. Journal of In-
formation Science, page 0165551510388123.
Peter D. Turney. 2002. Thumbs up or thumbs down?:
Semantic orientation applied to unsupervised classi-
fication of reviews. In Proceedings of the 40th An-
nual Meeting on Association for Computational Lin-
guistics, ACL ’02, pages 417–424, Stroudsburg, PA,
USA.
Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.
2005. Recognizing contextual polarity in phrase-level
sentiment analysis. In Proceedings of the Conference
on Human Language Technology and Empirical Meth-
ods in Natural Language Processing, HLT ’05, pages
347–354, Stroudsburg, PA, USA.
Hong Yu and Vasileios Hatzivassiloglou. 2003. Towards
answering opinion questions: Separating facts from
opinions and identifying the polarity of opinion sen-
tences. In Proceedings of the 2003 Conference on
Empirical Methods in Natural Language Processing,
EMNLP ’03, pages 129–136, Stroudsburg, PA, USA.
</reference>
<page confidence="0.998541">
735
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.945530">
<title confidence="0.9997">SINAI: Syntactic approach for Aspect Based Sentiment Analysis</title>
<author confidence="0.9857715">Salud M Jim´enez-Zafra</author>
<author confidence="0.9857715">Eugenio Teresa Martin-Valdivia</author>
<author confidence="0.9857715">L Alfonso</author>
<affiliation confidence="0.9994115">SINAI Research University of</affiliation>
<address confidence="0.984705">E-23071, Ja´en</address>
<email confidence="0.99354">emcamara,maite,</email>
<abstract confidence="0.999467888888889">This paper describes the participation of the SINAI research group in the task Aspect Based Sentiment Analysis of SemEval Workshop 2015 Edition. We propose a syntactic approach for identifying the words that modify each aspect, with the aim of classifying the sentiment expressed towards each attribute of an entity.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Stefano Baccianella</author>
<author>Andrea Esuli</author>
<author>Fabrizio Sebastiani</author>
</authors>
<title>Sentiwordnet 3.0: An enhanced lexical resource for sentiment analysis and opinion mining.</title>
<date>2010</date>
<booktitle>In LREC,</booktitle>
<volume>10</volume>
<pages>2200--2204</pages>
<contexts>
<context position="5576" citStr="Baccianella et al., 2010" startWordPosition="927" endWordPosition="930">m an SVM classifier of type C-SVC with linear kernel and the default configuration has been trained, and a 10-fold-cross validation model has been used for the assessment (Table 1). The features that have provided the best results in the training and that we have used for our participation in this slot are the following. For each &lt;category, OTE, polarity&gt; tuple of the training data, we have used as label the polarity value and as features the words that modify the OTE, their PoS tag, their syntactic relation and their polarity using three lexicons (taking into account negation): SentiWordNet (Baccianella et al., 2010), MPQA (Wilson et al., 2005) and eBLR (enriched version of Bing Liu Lexicon (Hu and Liu, 2004) adapted to restaurant domain). Below, we describe briefly how this inforExp. Type Accuracy Features Exp 1 U 75.57% Modifying words, PoS, syntactic relation, polarity (SentiWordNet, MPQA, BinLiu) Exp 2 U 75.88% Modifying words, PoS, syntactic relation, polarity (SentiWordNet, MPQA, BinLiu) taking into account negation Exp 3 U 75.67% Modifying words, PoS, syntactic relation, polarity (SentiWordNet, MPQA, eBLR) Exp 4 U 75.94% Modifying words, PoS, syntactic relation, polarity (SentiWordNet, MPQA, eBLR) </context>
</contexts>
<marker>Baccianella, Esuli, Sebastiani, 2010</marker>
<rawString>Stefano Baccianella, Andrea Esuli, and Fabrizio Sebastiani. 2010. Sentiwordnet 3.0: An enhanced lexical resource for sentiment analysis and opinion mining. In LREC, volume 10, pages 2200–2204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine De Marneffe</author>
<author>Christopher D Manning</author>
</authors>
<date>2008</date>
<note>Stanford typed dependencies manual.</note>
<marker>De Marneffe, Manning, 2008</marker>
<rawString>Marie-Catherine De Marneffe and Christopher D Manning. 2008. Stanford typed dependencies manual.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kerstin Denecke</author>
</authors>
<title>Using sentiwordnet for multilingual sentiment analysis.</title>
<date>2008</date>
<booktitle>In Data Engineering Workshop,</booktitle>
<pages>507--512</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="13298" citStr="Denecke, 2008" startWordPosition="2219" endWordPosition="2220">at modify it. Thus, according to Bing Liu Lexicon, we count the number of positive (pw) and negative words (nw) that modify the OTE and tag it following the equation 1. On the other hand, we use MPQA as classifier following the same approach but in this case we take into account the PoS of the modifying words in order to get their polarity. At last, we employ SentiWordNet also following the approach of comparing the number of positive and negative words but as this lexicon assigns three sentiment scores to each synset, we calculate the polarity of each modifying word using the Denecke method (Denecke, 2008), that is, we calculate the average of the positivity, negativity and objectivity scores of all the synsets of the word with the same PoS and assign the word the polarity of the highest average. Thus, given a category of the test data, it is clas- pol(OTE) = I positive if (pw &gt; nw) (1) sified using its features vector and the trained SVM negative if (pw &lt; nw) model. neutral if (pw = nw) 2.3 Slot 3 - Out of domain ABSA For the last domain, the organization has not provided any information until the test set has been released. We only knew that we had to assign a polarity value for each &lt;OTE, ca</context>
</contexts>
<marker>Denecke, 2008</marker>
<rawString>Kerstin Denecke. 2008. Using sentiwordnet for multilingual sentiment analysis. In Data Engineering Workshop, 2008. ICDEW 2008. IEEE 24th International Conference on, pages 507–512. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minqing Hu</author>
<author>Bing Liu</author>
</authors>
<title>Mining and summarizing customer reviews.</title>
<date>2004</date>
<booktitle>In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining,</booktitle>
<pages>168--177</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="5670" citStr="Hu and Liu, 2004" startWordPosition="944" endWordPosition="947">nd a 10-fold-cross validation model has been used for the assessment (Table 1). The features that have provided the best results in the training and that we have used for our participation in this slot are the following. For each &lt;category, OTE, polarity&gt; tuple of the training data, we have used as label the polarity value and as features the words that modify the OTE, their PoS tag, their syntactic relation and their polarity using three lexicons (taking into account negation): SentiWordNet (Baccianella et al., 2010), MPQA (Wilson et al., 2005) and eBLR (enriched version of Bing Liu Lexicon (Hu and Liu, 2004) adapted to restaurant domain). Below, we describe briefly how this inforExp. Type Accuracy Features Exp 1 U 75.57% Modifying words, PoS, syntactic relation, polarity (SentiWordNet, MPQA, BinLiu) Exp 2 U 75.88% Modifying words, PoS, syntactic relation, polarity (SentiWordNet, MPQA, BinLiu) taking into account negation Exp 3 U 75.67% Modifying words, PoS, syntactic relation, polarity (SentiWordNet, MPQA, eBLR) Exp 4 U 75.94% Modifying words, PoS, syntactic relation, polarity (SentiWordNet, MPQA, eBLR) taking into account negation Table 1: Experiments restaurants training data (U = Unconstrained</context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>Minqing Hu and Bing Liu. 2004. Mining and summarizing customer reviews. In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining, pages 168–177. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bin Lu</author>
<author>Myle Ott</author>
<author>Claire Cardie</author>
<author>Benjamin K Tsou</author>
</authors>
<title>Multi-aspect sentiment analysis with topic models.</title>
<date>2011</date>
<booktitle>In Data Mining Workshops (ICDMW), 2011 IEEE 11th International Conference on,</booktitle>
<pages>81--88</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="1966" citStr="Lu et al., 2011" startWordPosition="309" endWordPosition="312"> of study. However, the fact that the overall sentiment of a product is positive does not mean that the author thinks that all the aspects of the product are positives, or the fact that is negative does not involve that everything about the product is bad. For this reason, users and companies are not satisfied with knowing the overall sentiment of a product or service, they seek a more detailed knowledge. Consequently, to achieve a higher level of detail, part of the scientific community related to this area is working on SA at aspect level ((Quan and Ren, 2014), (Marcheggiani et al., 2014), (Lu et al., 2011), (Thet et al., 2010)) and even, there is a competition on this topic that began to conduct last year (Pontiki et al., 2014) in the International Workshop on Semantic Evaluation 2014 (SemEval 2014). This year, the 2015 edition of SemEval has also proposed a task for SA at aspect level. The SemEval-2015 Aspect Based Sentiment Analysis task is a continuation of SemEval-2014 Task 4 (Pontiki et al., 2014). The aim of this task is to identify the attributes of an entity that are being reviewed and the sentiment expressed for each one. It is divided into three slots. The first one is focused on the </context>
</contexts>
<marker>Lu, Ott, Cardie, Tsou, 2011</marker>
<rawString>Bin Lu, Myle Ott, Claire Cardie, and Benjamin K Tsou. 2011. Multi-aspect sentiment analysis with topic models. In Data Mining Workshops (ICDMW), 2011 IEEE 11th International Conference on, pages 81–88. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diego Marcheggiani</author>
<author>Oscar T¨ackstr¨om</author>
<author>Andrea Esuli</author>
<author>Fabrizio Sebastiani</author>
</authors>
<title>Hierarchical multilabel conditional random fields for aspect-oriented opinion mining.</title>
<date>2014</date>
<booktitle>In Advances in Information Retrieval,</booktitle>
<pages>273--285</pages>
<publisher>Springer.</publisher>
<marker>Marcheggiani, T¨ackstr¨om, Esuli, Sebastiani, 2014</marker>
<rawString>Diego Marcheggiani, Oscar T¨ackstr¨om, Andrea Esuli, and Fabrizio Sebastiani. 2014. Hierarchical multilabel conditional random fields for aspect-oriented opinion mining. In Advances in Information Retrieval, pages 273–285. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
</authors>
<title>Wordnet: a lexical database for english.</title>
<date>1995</date>
<journal>Communications of the ACM,</journal>
<volume>38</volume>
<issue>11</issue>
<contexts>
<context position="8533" citStr="Miller, 1995" startWordPosition="1408" endWordPosition="1409">lation of each modifying word with the OTE has also been used as feature. Polarity The last feature of our SVM classifier is the polarity of each modifying word according to three lexicons: SentiWordNet, MPQA and eBLR. In addition, it has been used the fixed window method for the treatment of negation. Then, if any of the preceding or following 3 words is a negative particle (“not”, “n’t”, “no”, “never”... ), the modifying word polarity will be reversed (positive —&gt; negative, negative —&gt; positive, neutral —&gt; neutral). SentiWordNet is a lexical resource that assigns to each synset of WordNet2 (Miller, 1995) three sentiment scores (positivity, negativity and objectivity) that describe how positive, negative and objective the terms contained in the synset are. MPQA is a subjectivity lexicon formed by over 8000 subjectivity clues. For each word, it has information about its prior polarity, its part of speech tag and its grade of subjectivity (strong or weak). Finally, eBLR is an enriched version of Bing Liu Lexicon that we explain below. As is well-known in the SA research community, the semantic orientation of a word is domain-dependent. Therefore, we decided to generate a list of opinion words fo</context>
</contexts>
<marker>Miller, 1995</marker>
<rawString>George A Miller. 1995. Wordnet: a lexical database for english. Communications of the ACM, 38(11):39–41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Dolores Molina-Gonz´alez</author>
<author>Eugenio Martinez-C´amara</author>
<author>Maria-Teresa Martin-Valdivia</author>
<author>Jos´e M PereaOrtega</author>
</authors>
<title>Semantic orientation for polarity classification in spanish reviews.</title>
<date>2013</date>
<journal>Expert Systems with Applications,</journal>
<volume>40</volume>
<issue>18</issue>
<marker>Molina-Gonz´alez, Martinez-C´amara, Martin-Valdivia, PereaOrtega, 2013</marker>
<rawString>M Dolores Molina-Gonz´alez, Eugenio Martinez-C´amara, Maria-Teresa Martin-Valdivia, and Jos´e M PereaOrtega. 2013. Semantic orientation for polarity classification in spanish reviews. Expert Systems with Applications, 40(18):7250–7257.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>Opinion mining and sentiment analysis.</title>
<date>2008</date>
<journal>Found. Trends Inf. Retr.,</journal>
<pages>2--1</pages>
<contexts>
<context position="805" citStr="Pang and Lee, 2008" startWordPosition="111" endWordPosition="114">University of Ja´en E-23071, Ja´en (Spain) {sjzafra, emcamara, maite, laurena}@ujaen.es Abstract This paper describes the participation of the SINAI research group in the task Aspect Based Sentiment Analysis of SemEval Workshop 2015 Edition. We propose a syntactic approach for identifying the words that modify each aspect, with the aim of classifying the sentiment expressed towards each attribute of an entity. 1 Introduction Opinion Mining (OM), also known as Sentiment Analysis (SA), is the discipline that focuses on the computational treatment of opinion, sentiment and subjectivity in texts (Pang and Lee, 2008). Currently, OM is a trendy task in the field of Natural Language Processing, due mainly to the fact of the proliferation of user-generated content and the interest in the knowledge of the opinion of people by consumers and businesses. Most of the systems developed up to now carry out opinion analysis at document level ((Pang et al., 2002), (Turney, 2002)) or at sentence level ((Wilson et al., 2005), (Yu and Hatzivassiloglou, 2003)), that is, they determine the overall sentiment expressed by the reviewer about the topic, product, person... of study. However, the fact that the overall sentiment</context>
</contexts>
<marker>Pang, Lee, 2008</marker>
<rawString>Bo Pang and Lillian Lee. 2008. Opinion mining and sentiment analysis. Found. Trends Inf. Retr., 2(1-2):1– 135, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
<author>Shivakumar Vaithyanathan</author>
</authors>
<title>Thumbs up?: Sentiment classification using machine learning techniques.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL-02 Conference on Empirical Methods in Natural Language Processing - Volume 10, EMNLP ’02,</booktitle>
<pages>79--86</pages>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="1146" citStr="Pang et al., 2002" startWordPosition="171" endWordPosition="174">lassifying the sentiment expressed towards each attribute of an entity. 1 Introduction Opinion Mining (OM), also known as Sentiment Analysis (SA), is the discipline that focuses on the computational treatment of opinion, sentiment and subjectivity in texts (Pang and Lee, 2008). Currently, OM is a trendy task in the field of Natural Language Processing, due mainly to the fact of the proliferation of user-generated content and the interest in the knowledge of the opinion of people by consumers and businesses. Most of the systems developed up to now carry out opinion analysis at document level ((Pang et al., 2002), (Turney, 2002)) or at sentence level ((Wilson et al., 2005), (Yu and Hatzivassiloglou, 2003)), that is, they determine the overall sentiment expressed by the reviewer about the topic, product, person... of study. However, the fact that the overall sentiment of a product is positive does not mean that the author thinks that all the aspects of the product are positives, or the fact that is negative does not involve that everything about the product is bad. For this reason, users and companies are not satisfied with knowing the overall sentiment of a product or service, they seek a more detaile</context>
</contexts>
<marker>Pang, Lee, Vaithyanathan, 2002</marker>
<rawString>Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan. 2002. Thumbs up?: Sentiment classification using machine learning techniques. In Proceedings of the ACL-02 Conference on Empirical Methods in Natural Language Processing - Volume 10, EMNLP ’02, pages 79–86, Stroudsburg, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maria Pontiki</author>
<author>Haris Papageorgiou</author>
<author>Dimitrios Galanis</author>
<author>Ion Androutsopoulos</author>
<author>John Pavlopoulos</author>
<author>Suresh Manandhar</author>
</authors>
<title>Semeval-2014 task 4: Aspect based sentiment analysis.</title>
<date>2014</date>
<booktitle>In Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval</booktitle>
<pages>27--35</pages>
<contexts>
<context position="2090" citStr="Pontiki et al., 2014" startWordPosition="332" endWordPosition="335">hat all the aspects of the product are positives, or the fact that is negative does not involve that everything about the product is bad. For this reason, users and companies are not satisfied with knowing the overall sentiment of a product or service, they seek a more detailed knowledge. Consequently, to achieve a higher level of detail, part of the scientific community related to this area is working on SA at aspect level ((Quan and Ren, 2014), (Marcheggiani et al., 2014), (Lu et al., 2011), (Thet et al., 2010)) and even, there is a competition on this topic that began to conduct last year (Pontiki et al., 2014) in the International Workshop on Semantic Evaluation 2014 (SemEval 2014). This year, the 2015 edition of SemEval has also proposed a task for SA at aspect level. The SemEval-2015 Aspect Based Sentiment Analysis task is a continuation of SemEval-2014 Task 4 (Pontiki et al., 2014). The aim of this task is to identify the attributes of an entity that are being reviewed and the sentiment expressed for each one. It is divided into three slots. The first one is focused on the identification of every entity E and attribute A pair (E#A) towards which an opinion is expressed in the given text. Slot 2 </context>
</contexts>
<marker>Pontiki, Papageorgiou, Galanis, Androutsopoulos, Pavlopoulos, Manandhar, 2014</marker>
<rawString>Maria Pontiki, Haris Papageorgiou, Dimitrios Galanis, Ion Androutsopoulos, John Pavlopoulos, and Suresh Manandhar. 2014. Semeval-2014 task 4: Aspect based sentiment analysis. In Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 27–35.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maria Pontiki</author>
<author>Dimitrios Galanis</author>
<author>Harris Papageorgiou</author>
<author>Suresh Manandhar</author>
<author>Ion Androutsopoulos</author>
</authors>
<title>Semeval-2015 task 12: Aspect based sentiment analysis.</title>
<date>2015</date>
<booktitle>In Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015),</booktitle>
<location>Denver, Colorado.</location>
<contexts>
<context position="3341" citStr="Pontiki et al., 2015" startWordPosition="547" endWordPosition="550">ession used in the text to refer to the reviewed entity, that is, the Opinion Target Expression (OTE). Finally, Slot 3 has as goal to classify the sentiment expressed over each category (E#A pair) as positive, negative or neutral. We have participated in the slot related to sentiment polarity (Slot 3). Due to the fact that OM is a domain-dependent task, the organization proposes the three slots in different domains, two known (restaurants and laptops) and one unknown until the evaluation (hotels). A wider description of the task and the dataset used can be found in the task description paper (Pontiki et al., 2015). The rest of the paper is organized as follows. Sec730 Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 730–735, Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics tion 2 describes the system developed and the resources that we have used. To sum up, the results reached and an analysis of the same are shown in Section 3. 2 System description - Slot 3 As we have mentioned above, we have taken part in the Slot 3. The aim of this slot is to identify the polarity of each category or each &lt;category, OTE&gt; pair on which an opin</context>
</contexts>
<marker>Pontiki, Galanis, Papageorgiou, Manandhar, Androutsopoulos, 2015</marker>
<rawString>Maria Pontiki, Dimitrios Galanis, Harris Papageorgiou, Suresh Manandhar, and Ion Androutsopoulos. 2015. Semeval-2015 task 12: Aspect based sentiment analysis. In Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), Denver, Colorado.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Changqin Quan</author>
<author>Fuji Ren</author>
</authors>
<title>Unsupervised product feature extraction for feature-oriented opinion determination. Information Sciences,</title>
<date>2014</date>
<pages>272--16</pages>
<contexts>
<context position="1918" citStr="Quan and Ren, 2014" startWordPosition="301" endWordPosition="304">by the reviewer about the topic, product, person... of study. However, the fact that the overall sentiment of a product is positive does not mean that the author thinks that all the aspects of the product are positives, or the fact that is negative does not involve that everything about the product is bad. For this reason, users and companies are not satisfied with knowing the overall sentiment of a product or service, they seek a more detailed knowledge. Consequently, to achieve a higher level of detail, part of the scientific community related to this area is working on SA at aspect level ((Quan and Ren, 2014), (Marcheggiani et al., 2014), (Lu et al., 2011), (Thet et al., 2010)) and even, there is a competition on this topic that began to conduct last year (Pontiki et al., 2014) in the International Workshop on Semantic Evaluation 2014 (SemEval 2014). This year, the 2015 edition of SemEval has also proposed a task for SA at aspect level. The SemEval-2015 Aspect Based Sentiment Analysis task is a continuation of SemEval-2014 Task 4 (Pontiki et al., 2014). The aim of this task is to identify the attributes of an entity that are being reviewed and the sentiment expressed for each one. It is divided in</context>
</contexts>
<marker>Quan, Ren, 2014</marker>
<rawString>Changqin Quan and Fuji Ren. 2014. Unsupervised product feature extraction for feature-oriented opinion determination. Information Sciences, 272:16–28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tun Thura Thet</author>
<author>Jin-Cheon Na</author>
<author>Christopher SG Khoo</author>
</authors>
<title>Aspect-based sentiment analysis of movie reviews on discussion boards.</title>
<date>2010</date>
<journal>Journal of Information Science,</journal>
<pages>0165551510388123</pages>
<contexts>
<context position="1987" citStr="Thet et al., 2010" startWordPosition="313" endWordPosition="316"> the fact that the overall sentiment of a product is positive does not mean that the author thinks that all the aspects of the product are positives, or the fact that is negative does not involve that everything about the product is bad. For this reason, users and companies are not satisfied with knowing the overall sentiment of a product or service, they seek a more detailed knowledge. Consequently, to achieve a higher level of detail, part of the scientific community related to this area is working on SA at aspect level ((Quan and Ren, 2014), (Marcheggiani et al., 2014), (Lu et al., 2011), (Thet et al., 2010)) and even, there is a competition on this topic that began to conduct last year (Pontiki et al., 2014) in the International Workshop on Semantic Evaluation 2014 (SemEval 2014). This year, the 2015 edition of SemEval has also proposed a task for SA at aspect level. The SemEval-2015 Aspect Based Sentiment Analysis task is a continuation of SemEval-2014 Task 4 (Pontiki et al., 2014). The aim of this task is to identify the attributes of an entity that are being reviewed and the sentiment expressed for each one. It is divided into three slots. The first one is focused on the identification of eve</context>
</contexts>
<marker>Thet, Na, Khoo, 2010</marker>
<rawString>Tun Thura Thet, Jin-Cheon Na, and Christopher SG Khoo. 2010. Aspect-based sentiment analysis of movie reviews on discussion boards. Journal of Information Science, page 0165551510388123.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
</authors>
<title>Thumbs up or thumbs down?: Semantic orientation applied to unsupervised classification of reviews.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ACL ’02,</booktitle>
<pages>417--424</pages>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="1162" citStr="Turney, 2002" startWordPosition="175" endWordPosition="176">ent expressed towards each attribute of an entity. 1 Introduction Opinion Mining (OM), also known as Sentiment Analysis (SA), is the discipline that focuses on the computational treatment of opinion, sentiment and subjectivity in texts (Pang and Lee, 2008). Currently, OM is a trendy task in the field of Natural Language Processing, due mainly to the fact of the proliferation of user-generated content and the interest in the knowledge of the opinion of people by consumers and businesses. Most of the systems developed up to now carry out opinion analysis at document level ((Pang et al., 2002), (Turney, 2002)) or at sentence level ((Wilson et al., 2005), (Yu and Hatzivassiloglou, 2003)), that is, they determine the overall sentiment expressed by the reviewer about the topic, product, person... of study. However, the fact that the overall sentiment of a product is positive does not mean that the author thinks that all the aspects of the product are positives, or the fact that is negative does not involve that everything about the product is bad. For this reason, users and companies are not satisfied with knowing the overall sentiment of a product or service, they seek a more detailed knowledge. Con</context>
</contexts>
<marker>Turney, 2002</marker>
<rawString>Peter D. Turney. 2002. Thumbs up or thumbs down?: Semantic orientation applied to unsupervised classification of reviews. In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ACL ’02, pages 417–424, Stroudsburg, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Wilson</author>
<author>Janyce Wiebe</author>
<author>Paul Hoffmann</author>
</authors>
<title>Recognizing contextual polarity in phrase-level sentiment analysis.</title>
<date>2005</date>
<booktitle>In Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing, HLT ’05,</booktitle>
<pages>347--354</pages>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="1207" citStr="Wilson et al., 2005" startWordPosition="181" endWordPosition="184">f an entity. 1 Introduction Opinion Mining (OM), also known as Sentiment Analysis (SA), is the discipline that focuses on the computational treatment of opinion, sentiment and subjectivity in texts (Pang and Lee, 2008). Currently, OM is a trendy task in the field of Natural Language Processing, due mainly to the fact of the proliferation of user-generated content and the interest in the knowledge of the opinion of people by consumers and businesses. Most of the systems developed up to now carry out opinion analysis at document level ((Pang et al., 2002), (Turney, 2002)) or at sentence level ((Wilson et al., 2005), (Yu and Hatzivassiloglou, 2003)), that is, they determine the overall sentiment expressed by the reviewer about the topic, product, person... of study. However, the fact that the overall sentiment of a product is positive does not mean that the author thinks that all the aspects of the product are positives, or the fact that is negative does not involve that everything about the product is bad. For this reason, users and companies are not satisfied with knowing the overall sentiment of a product or service, they seek a more detailed knowledge. Consequently, to achieve a higher level of detai</context>
<context position="5604" citStr="Wilson et al., 2005" startWordPosition="932" endWordPosition="935"> with linear kernel and the default configuration has been trained, and a 10-fold-cross validation model has been used for the assessment (Table 1). The features that have provided the best results in the training and that we have used for our participation in this slot are the following. For each &lt;category, OTE, polarity&gt; tuple of the training data, we have used as label the polarity value and as features the words that modify the OTE, their PoS tag, their syntactic relation and their polarity using three lexicons (taking into account negation): SentiWordNet (Baccianella et al., 2010), MPQA (Wilson et al., 2005) and eBLR (enriched version of Bing Liu Lexicon (Hu and Liu, 2004) adapted to restaurant domain). Below, we describe briefly how this inforExp. Type Accuracy Features Exp 1 U 75.57% Modifying words, PoS, syntactic relation, polarity (SentiWordNet, MPQA, BinLiu) Exp 2 U 75.88% Modifying words, PoS, syntactic relation, polarity (SentiWordNet, MPQA, BinLiu) taking into account negation Exp 3 U 75.67% Modifying words, PoS, syntactic relation, polarity (SentiWordNet, MPQA, eBLR) Exp 4 U 75.94% Modifying words, PoS, syntactic relation, polarity (SentiWordNet, MPQA, eBLR) taking into account negation</context>
</contexts>
<marker>Wilson, Wiebe, Hoffmann, 2005</marker>
<rawString>Theresa Wilson, Janyce Wiebe, and Paul Hoffmann. 2005. Recognizing contextual polarity in phrase-level sentiment analysis. In Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing, HLT ’05, pages 347–354, Stroudsburg, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hong Yu</author>
<author>Vasileios Hatzivassiloglou</author>
</authors>
<title>Towards answering opinion questions: Separating facts from opinions and identifying the polarity of opinion sentences.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing, EMNLP ’03,</booktitle>
<pages>129--136</pages>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="1240" citStr="Yu and Hatzivassiloglou, 2003" startWordPosition="185" endWordPosition="188">tion Opinion Mining (OM), also known as Sentiment Analysis (SA), is the discipline that focuses on the computational treatment of opinion, sentiment and subjectivity in texts (Pang and Lee, 2008). Currently, OM is a trendy task in the field of Natural Language Processing, due mainly to the fact of the proliferation of user-generated content and the interest in the knowledge of the opinion of people by consumers and businesses. Most of the systems developed up to now carry out opinion analysis at document level ((Pang et al., 2002), (Turney, 2002)) or at sentence level ((Wilson et al., 2005), (Yu and Hatzivassiloglou, 2003)), that is, they determine the overall sentiment expressed by the reviewer about the topic, product, person... of study. However, the fact that the overall sentiment of a product is positive does not mean that the author thinks that all the aspects of the product are positives, or the fact that is negative does not involve that everything about the product is bad. For this reason, users and companies are not satisfied with knowing the overall sentiment of a product or service, they seek a more detailed knowledge. Consequently, to achieve a higher level of detail, part of the scientific communi</context>
</contexts>
<marker>Yu, Hatzivassiloglou, 2003</marker>
<rawString>Hong Yu and Vasileios Hatzivassiloglou. 2003. Towards answering opinion questions: Separating facts from opinions and identifying the polarity of opinion sentences. In Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing, EMNLP ’03, pages 129–136, Stroudsburg, PA, USA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>