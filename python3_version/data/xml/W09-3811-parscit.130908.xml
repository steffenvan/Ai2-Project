<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.034758">
<title confidence="0.996339">
An Improved Oracle for Dependency Parsing with Online Reordering
</title>
<author confidence="0.993837">
Joakim Nivre*† Marco Kuhlmann? Johan Hall?
</author>
<affiliation confidence="0.9966295">
?Uppsala University, Department of Linguistics and Philology, SE-75126 Uppsala
†Växjö University, School of Mathematics and Systems Engineering, SE-35195 Växjö
</affiliation>
<email confidence="0.998881">
E-mail: FIRSTNAME.LASTNAME@lingfil.uu.se
</email>
<sectionHeader confidence="0.99739" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999953222222222">
We present an improved training strategy
for dependency parsers that use online re-
ordering to handle non-projective trees.
The new strategy improves both efficiency
and accuracy by reducing the number of
swap operations performed on non-project-
ive trees by up to 80%. We present state-of-
the-art results for five languages with the
best ever reported results for Czech.
</bodyText>
<sectionHeader confidence="0.999393" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999976974358974">
Recent work on dependency parsing has resulted in
considerable progress with respect to both accuracy
and efficiency, not least in the treatment of discon-
tinuous syntactic constructions, usually modeled
by non-projective dependency trees. While non-
projective dependency relations tend to be rare in
most languages (Kuhlmann and Nivre, 2006), it
is not uncommon that up to 25% of the sentences
have a structure that involves at least one non-pro-
jective relation, a relation that may be crucial for
an adequate analysis of predicate-argument struc-
ture. This makes the treatment of non-projectivity
central for accurate dependency parsing.
Unfortunately, parsing with unrestricted non-pro-
jective structures is a hard problem, for which exact
inference is not possible in polynomial time except
under drastic independence assumptions (McDon-
ald and Satta, 2007), and most data-driven parsers
therefore use approximate methods (Nivre et al.,
2006; McDonald et al., 2006). One recently ex-
plored approach is to perform online reordering
by swapping adjacent words of the input sentence
while building the dependency structure. Using this
technique, the system of Nivre (2009) processes
unrestricted non-projective structures with state-of-
the-art accuracy in observed linear time.
The normal procedure for training a transition-
based parser is to use an oracle that predicts an
optimal transition sequence for every dependency
tree in the training set, and then approximate this
oracle by a classifier. In this paper, we show that
the oracle used for training by Nivre (2009) is sub-
optimal because it eagerly swaps words as early
as possible and therefore makes a large number of
unnecessary transitions, which potentially affects
both efficiency and accuracy. We propose an altern-
ative oracle that reduces the number of transitions
by building larger structures before swapping, but
still handles arbitrary non-projective structures.
</bodyText>
<sectionHeader confidence="0.987775" genericHeader="introduction">
2 Background
</sectionHeader>
<bodyText confidence="0.999943071428571">
The fundamental reason why sentences with non-
projective dependency trees are hard to parse is that
they contain dependencies between non-adjacent
substructures. The basic idea in online reordering
is to allow the parser to swap input words so that
all dependency arcs can be constructed between
adjacent subtrees. This idea is implemented in the
transition system proposed by Nivre (2009). The
first three transitions of this system (LEFT-ARC,
RIGHT-ARC, and SHIFT) are familiar from many
systems for transition-based dependency parsing
(Nivre, 2008). The only novelty is the SWAP trans-
ition, which permutes two nodes by moving the
second-topmost node from the stack back to the
input buffer while leaving the top node on the stack.
To understand how we can parse sentences with
non-projective dependency trees, in spite of the
fact that dependencies can only be added between
nodes that are adjacent on the stack, note that, for
any sentence x with dependency tree G, there is
always some permutation x&apos; of x such that G is pro-
jective with respect to x&apos;. There may be more than
one such permutation, but Nivre (2009) defines the
canonical projective order &lt;G for x given G as
the order given by an inorder traversal of G that
respects the order &lt; between a node and its direct
dependents. This is illustrated in Figure 1, where
the words of a sentence with a non-projective tree
</bodyText>
<page confidence="0.987359">
73
</page>
<note confidence="0.3594265">
Proceedings of the 11th International Conference on Parsing Technologies (IWPT), pages 73–76,
Paris, October 2009. c�2009 Association for Computational Linguistics
</note>
<figure confidence="0.496476">
P
</figure>
<figureCaption confidence="0.998961">
Figure 1: Dependency tree for an English sentence with projective order annotation.
</figureCaption>
<figure confidence="0.998560052631579">
ROOT
0
Who
6
did you
1 2
send the letter
3 4 5
to
7
?
8
NMOD
VG
SUBJ
ROOT
OBJ2
OBJ1
DET
</figure>
<bodyText confidence="0.959442666666667">
have been annotated with their positions in the pro-
jective order; reading the words in this order gives
the permuted string Did you send the letter who to?
</bodyText>
<sectionHeader confidence="0.986649" genericHeader="method">
3 Training Oracles
</sectionHeader>
<bodyText confidence="0.999981230769231">
In order to train classifiers for transition-based pars-
ing, we need a training oracle, that is, a function
that maps every dependency tree T in the training
set to a transition sequence that derives T. While
every complete transition sequence determines a
unique dependency tree, the inverse does not neces-
sarily hold. This also means that it may be possible
to construct different training oracles. For simple
systems that are restricted to projective dependency
trees, such differences are usually trivial, but for
a system that allows online reordering there may
be genuine differences that can affect both the effi-
ciency and accuracy of the resulting parsers.
</bodyText>
<subsectionHeader confidence="0.996516">
3.1 The Old Oracle
</subsectionHeader>
<bodyText confidence="0.999837357142857">
Figure 2 defines the original training oracle 7-1 pro-
posed by Nivre (2009). This oracle follows an
eager reordering strategy; it predicts SWAP in every
configuration where this is possible. The basic in-
sight in this paper is that, by postponing swaps and
building as much of the tree structure as possible
before swapping, we can significantly decrease the
length of the transition sequence for a given sen-
tence and tree. This may benefit the efficiency of
the parser trained using the oracle, as each trans-
ition takes a certain time to predict and to execute.
Longer transition sequences may also be harder to
learn than shorter ones, which potentially affects
the accuracy of the parser.
</bodyText>
<subsectionHeader confidence="0.984528">
3.2 A New Oracle
</subsectionHeader>
<bodyText confidence="0.999964725">
While it is desirable to delay a SWAP transition
for as long as possible, it is not trivial to find the
right time point to actually do the swap. To see
this, consider the dependency tree in Figure 1. In a
parse of this tree, the first configuration in which
swapping is possible is when who6 and did1 are the
two top nodes on the stack. In this configuration we
can delay the swap until did has combined with its
subject you by means of a RIGHT-ARC transition,
but if we do not swap in the second configuration
where this is possible, we eventually end up with
the stack [ROOT0, who6, did1, send3, to7]. Here we
cannot attach who to to by means of a LEFT-ARC
transition and get stuck.
In order to define the new oracle, we introduce
an auxiliary concept. Consider a modification of
the oracle 7-1 from Figure 2 that cannot predict
SWAP transitions. This oracle will be able to pro-
duce valid transition sequences only for projective
target trees; for non-projective trees, it will fail to
reconstruct all dependency arcs. More specifically,
a parse with this oracle will end up in a configur-
ation in which the set of constructed dependency
arcs forms a set of projective dependency trees, not
necessarily a single such tree. We call the elements
of this set the maximal projective components of
the target tree. To illustrate the notion, we have
drawn boxes around nodes in the same component
in Figures 1.
Based on the concept of maximal projective com-
ponents, we define a new training oracle 7-2, which
delays swapping as long as the next node in the
input is in the same maximal projective compon-
ent as the top node on the stack. The definition
of the new oracle 7-2 is identical to that of 7-1 ex-
cept that the third line is replaced by “SWAP if
c =([σ|i, j], [k|β], Ac), j &lt;G i, and MPC(j) =�
MPC(k)”, where MPC(i) is the maximal project-
ive component of node i. As a special case, 7-2
predicts SWAP if j &lt;G i and the buffer B is empty.
</bodyText>
<page confidence="0.970183">
74
</page>
<figure confidence="0.61399625">
7-1(c) = { LEFT-ARCl if c = ([u|i, j], B, A,), (j,l, i)EA and AZ C A,
RIGHT-ARCl if c = ([u|i, j], B, A,), (i,l, j)EA and Ai C A,
SWAP if c = ([u|i, j], B, A,) and j &lt;G i
SHIFT otherwise
</figure>
<figureCaption confidence="0.939946">
Figure 2: Training oracle 7-1 for an arbitrary target tree G = (V,;, A), following the notation of Nivre
</figureCaption>
<bodyText confidence="0.872095636363636">
(2009), where c = (E, B, A,) denotes a configuration c with stack E, input buffer B and arc set A,. We
write AZ to denote the subset of A that only contains the outgoing arcs of the node i. (Note that A, is the
arc set in configuration c, while A is the arc set in the target tree G.)
For example, in extracting the transition se-
quence for the target tree in Figure 1, the new oracle
will postpone swapping of did when you is the next
node in the input, but not postpone when the next
node is send. We can show that a parser informed
by the new training oracle can always proceed to
a terminal configuration, and still derive all (even
non-projective) dependency trees.
</bodyText>
<sectionHeader confidence="0.999732" genericHeader="evaluation">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999977625">
We now test the hypothesis that the new training
oracle can improve both the accuracy and the ef-
ficiency of a transition-based dependency parser.
Our experiments are based on the same five data
sets as Nivre (2009). The training sets vary in size
from 28,750 tokens (1,534 sentences) for Slovene
to 1,249,408 tokens (72,703 sentences) for Czech,
while the test sets all consist of about 5,000 tokens.
</bodyText>
<subsectionHeader confidence="0.993935">
4.1 Number of Transitions
</subsectionHeader>
<bodyText confidence="0.999952909090909">
For each language, we first parsed the training set
with both the old and the new training oracle. This
allowed us to compare the number of SWAP trans-
itions needed to parse all sentences with the two
oracles, shown in Table 1. We see that the reduction
is very substantial, ranging from 55% (for Czech)
to almost 84% (for Arabic). While this difference
does not affect the asymptotic complexity of pars-
ing, it may reduce the number of calls to the classi-
fier, which is where transition-based parsers spend
most of their time.
</bodyText>
<subsectionHeader confidence="0.999652">
4.2 Parsing Accuracy
</subsectionHeader>
<bodyText confidence="0.999903976744186">
In order to assess whether the reduced number of
SWAP transitions also has a positive effect on pars-
ing accuracy, we trained two parsers for each of
the five languages, one for each oracle. All sys-
tems use SVM classifiers with a polynomial kernel
with features and parameters optimized separately
for each language and training oracle. The train-
ing data for these classifiers consist only of the
sequences derived by the oracles, which means that
the parser has no explicit notion of projective order
or maximal projective components at parsing time.
Table 2 shows the labeled parsing accuracy of the
parsers measured by the overall attachment score
(AS), as well as labeled precision, recall and (bal-
anced) F-score for non-projective dependencies.1
For comparison, we also give results for the two
best performing systems in the original CoNLL-X
shared task, Malt (Nivre et al., 2006) and MST (Mc-
Donald et al., 2006), as well as the combo system
MSTMalt, (Nivre and McDonald, 2008).
Looking first at the overall labeled attachment
score, we see that the new training oracle consist-
ently gives higher accuracy than the old one, with
differences of up to 0.5 percentage points (for Ar-
abic and Slovene), which is substantial given that
the frequency of non-projective dependencies is
only 0.4–1.9%. Because the test sets are so small,
none of the differences is statistically significant
(McNemar’s test, α = .05), but the consistent im-
provement over all languages nevertheless strongly
suggests that this is a genuine difference.
In relation to the state of the art, we note that
the parsers with online reordering significantly out-
perform Malt and MST on Czech and Slovene,
and MST on Turkish, and have significantly lower
scores than the combo system MSTMalt only for
Arabic and Danish. For Czech, the parser with
the new oracle actually has the highest attachment
score ever reported, although the difference with
respect to MSTMalt is not statistically significant.
Turning to the scores for non-projective depend-
encies, we again see that the new oracle consist-
ently gives higher scores than the old oracle, with
</bodyText>
<footnote confidence="0.9494415">
1These metrics are not meaningful for Arabic as the test
set only contains 11 non-projective dependencies.
</footnote>
<page confidence="0.99441">
75
</page>
<table confidence="0.99936175">
Arabic Czech Danish Slovene Turkish
Old (τ1) 1416 57011 8296 2191 2828
New (τ2) 229 26208 1497 690 1253
Reduction (%) 83.8 55.0 82.0 68.5 55.7
</table>
<tableCaption confidence="0.9929">
Table 1: Number of SWAP transitions for the old (τ1) and new (τ2) training oracle.
</tableCaption>
<table confidence="0.999911571428571">
Arabic Czech Danish Slovene Turkish
System AS AS P R F ASP R F AS P R F AS P R F
Old (τ1) 67.2 82.5 74.7 72.9 73.8 84.2 30.0 30.0 30.0 75.2 33.3 26.4 29.5 64.7 12.5 11.4 11.9
New (τ2) 67.5 82.7 79.3 71.0 79.3 84.3 38.2 32.5 35.1 75.7 60.6 27.6 37.9 65.0 14.3 13.2 13.7
Malt 66.7 78.4 76.3 57.9 65.8 84.8 45.8 27.5 34.4 70.3 45.9 20.7 25.1 65.7 16.7 9.2 11.9
MST 66.9 80.2 60.5 61.7 61.1 84.8 54.0 62.5 57.9 73.4 33.7 26.4 29.6 63.2 – 11.8 –
MSTMalt 68.6 82.3 63.9 69.2 66.1 86.7 63.0 60.0 61.5 75.9 31.6 27.6 29.5 66.3 11.1 9.2 10.1
</table>
<tableCaption confidence="0.995993">
Table 2: Labeled attachment score (AS) overall; precision (P), recall (R) and balanced F-score (F) for
</tableCaption>
<bodyText confidence="0.996553285714286">
non-projective dependencies. Old = τ1; New = τ2; Malt = Nivre et al. (2006), MST = McDonald et al.
(2006), MSTMalt = Nivre and McDonald (2008).
the single exception that the old one has marginally
higher recall for Czech. Moreover, the reordering
parser with the new oracle has higher F-score than
any other system for all languages except Danish.
Especially the result for Czech, with 79.3% preci-
sion and 71.0% recall, is remarkably good, making
the parser almost as accurate for non-projective de-
pendencies as it is for projective dependencies. It
seems likely that the good results for Czech are due
to the fact that Czech has the highest percentage of
non-projective structures in combination with the
(by far) largest training set.
</bodyText>
<sectionHeader confidence="0.999449" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999991260869565">
We have presented a new training oracle for the
transition system originally presented in Nivre
(2009). This oracle postpones swapping as long as
possible but still fulfills the correctness criterion.
Our experimental results show that the new training
oracle can reduce the necessary number of swaps
by more than 80%, and that parsers trained in this
way achieve higher precision and recall on non-
projective dependency arcs as well as higher at-
tachment score overall. The results are particularly
good for languages with a high percentage of non-
projective dependencies, with an all-time best over
all metrics for Czech.
An interesting theoretical question is whether
the new oracle defined in this paper is optimal with
respect to minimizing the number of swaps. The an-
swer turns out to be negative, and it is possible to re-
duce the number of swaps even further by general-
izing the notion of maximal projective components
to maximal components that may be non-projective.
However, the characterization of these generalized
maximal components is non-trivial, and is therefore
an important problem for future research.
</bodyText>
<sectionHeader confidence="0.999457" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999529576923077">
Marco Kuhlmann and Joakim Nivre. 2006. Mildly
non-projective dependency structures. In Proceed-
ings of the COLING/ACL 2006 Main Conference
Poster Sessions, pages 507–514.
Ryan McDonald and Giorgio Satta. 2007. On the
complexity of non-projective data-driven depend-
ency parsing. In Proceedings of IWPT, pages 122–
131.
Ryan McDonald, Kevin Lerman, and Fernando Pereira.
2006. Multilingual dependency analysis with a
two-stage discriminative parser. In Proceedings of
CoNLL, pages 216–220.
Joakim Nivre and Ryan McDonald. 2008. Integrating
graph-based and transition-based dependency pars-
ers. In Proceedings of ACL, pages 950–958.
Joakim Nivre, Johan Hall, Jens Nilsson, Gülsen Ery-
i˘git, and Svetoslav Marinov. 2006. Labeled pseudo-
projective dependency parsing with support vector
machines. In Proceedings of CoNLL, pages 221–
225.
Joakim Nivre. 2008. Algorithms for deterministic in-
cremental dependency parsing. Computational Lin-
guistics, 34:513–553.
Joakim Nivre. 2009. Non-projective dependency pars-
ing in expected linear time. In Proceedings of ACL-
IJCNLP.
</reference>
<page confidence="0.991757">
76
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.502506">
<title confidence="0.999818">An Improved Oracle for Dependency Parsing with Online Reordering</title>
<author confidence="0.999791">Marco Johan</author>
<address confidence="0.748509">University, Department of Linguistics and Philology, SE-75126 University, School of Mathematics and Systems Engineering, SE-35195</address>
<abstract confidence="0.9939698">We present an improved training strategy for dependency parsers that use online reordering to handle non-projective trees. The new strategy improves both efficiency and accuracy by reducing the number of swap operations performed on non-projective trees by up to 80%. We present state-ofthe-art results for five languages with the best ever reported results for Czech.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Marco Kuhlmann</author>
<author>Joakim Nivre</author>
</authors>
<title>Mildly non-projective dependency structures.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions,</booktitle>
<pages>507--514</pages>
<contexts>
<context position="1042" citStr="Kuhlmann and Nivre, 2006" startWordPosition="142" endWordPosition="145">e non-projective trees. The new strategy improves both efficiency and accuracy by reducing the number of swap operations performed on non-projective trees by up to 80%. We present state-ofthe-art results for five languages with the best ever reported results for Czech. 1 Introduction Recent work on dependency parsing has resulted in considerable progress with respect to both accuracy and efficiency, not least in the treatment of discontinuous syntactic constructions, usually modeled by non-projective dependency trees. While nonprojective dependency relations tend to be rare in most languages (Kuhlmann and Nivre, 2006), it is not uncommon that up to 25% of the sentences have a structure that involves at least one non-projective relation, a relation that may be crucial for an adequate analysis of predicate-argument structure. This makes the treatment of non-projectivity central for accurate dependency parsing. Unfortunately, parsing with unrestricted non-projective structures is a hard problem, for which exact inference is not possible in polynomial time except under drastic independence assumptions (McDonald and Satta, 2007), and most data-driven parsers therefore use approximate methods (Nivre et al., 2006</context>
</contexts>
<marker>Kuhlmann, Nivre, 2006</marker>
<rawString>Marco Kuhlmann and Joakim Nivre. 2006. Mildly non-projective dependency structures. In Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 507–514.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Giorgio Satta</author>
</authors>
<title>On the complexity of non-projective data-driven dependency parsing.</title>
<date>2007</date>
<booktitle>In Proceedings of IWPT,</booktitle>
<pages>122--131</pages>
<contexts>
<context position="1558" citStr="McDonald and Satta, 2007" startWordPosition="219" endWordPosition="223"> trees. While nonprojective dependency relations tend to be rare in most languages (Kuhlmann and Nivre, 2006), it is not uncommon that up to 25% of the sentences have a structure that involves at least one non-projective relation, a relation that may be crucial for an adequate analysis of predicate-argument structure. This makes the treatment of non-projectivity central for accurate dependency parsing. Unfortunately, parsing with unrestricted non-projective structures is a hard problem, for which exact inference is not possible in polynomial time except under drastic independence assumptions (McDonald and Satta, 2007), and most data-driven parsers therefore use approximate methods (Nivre et al., 2006; McDonald et al., 2006). One recently explored approach is to perform online reordering by swapping adjacent words of the input sentence while building the dependency structure. Using this technique, the system of Nivre (2009) processes unrestricted non-projective structures with state-ofthe-art accuracy in observed linear time. The normal procedure for training a transitionbased parser is to use an oracle that predicts an optimal transition sequence for every dependency tree in the training set, and then appr</context>
</contexts>
<marker>McDonald, Satta, 2007</marker>
<rawString>Ryan McDonald and Giorgio Satta. 2007. On the complexity of non-projective data-driven dependency parsing. In Proceedings of IWPT, pages 122– 131.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Kevin Lerman</author>
<author>Fernando Pereira</author>
</authors>
<title>Multilingual dependency analysis with a two-stage discriminative parser.</title>
<date>2006</date>
<booktitle>In Proceedings of CoNLL,</booktitle>
<pages>216--220</pages>
<contexts>
<context position="1666" citStr="McDonald et al., 2006" startWordPosition="236" endWordPosition="239">it is not uncommon that up to 25% of the sentences have a structure that involves at least one non-projective relation, a relation that may be crucial for an adequate analysis of predicate-argument structure. This makes the treatment of non-projectivity central for accurate dependency parsing. Unfortunately, parsing with unrestricted non-projective structures is a hard problem, for which exact inference is not possible in polynomial time except under drastic independence assumptions (McDonald and Satta, 2007), and most data-driven parsers therefore use approximate methods (Nivre et al., 2006; McDonald et al., 2006). One recently explored approach is to perform online reordering by swapping adjacent words of the input sentence while building the dependency structure. Using this technique, the system of Nivre (2009) processes unrestricted non-projective structures with state-ofthe-art accuracy in observed linear time. The normal procedure for training a transitionbased parser is to use an oracle that predicts an optimal transition sequence for every dependency tree in the training set, and then approximate this oracle by a classifier. In this paper, we show that the oracle used for training by Nivre (2009</context>
<context position="10736" citStr="McDonald et al., 2006" startWordPosition="1806" endWordPosition="1810">y for each language and training oracle. The training data for these classifiers consist only of the sequences derived by the oracles, which means that the parser has no explicit notion of projective order or maximal projective components at parsing time. Table 2 shows the labeled parsing accuracy of the parsers measured by the overall attachment score (AS), as well as labeled precision, recall and (balanced) F-score for non-projective dependencies.1 For comparison, we also give results for the two best performing systems in the original CoNLL-X shared task, Malt (Nivre et al., 2006) and MST (McDonald et al., 2006), as well as the combo system MSTMalt, (Nivre and McDonald, 2008). Looking first at the overall labeled attachment score, we see that the new training oracle consistently gives higher accuracy than the old one, with differences of up to 0.5 percentage points (for Arabic and Slovene), which is substantial given that the frequency of non-projective dependencies is only 0.4–1.9%. Because the test sets are so small, none of the differences is statistically significant (McNemar’s test, α = .05), but the consistent improvement over all languages nevertheless strongly suggests that this is a genuine </context>
<context position="13012" citStr="McDonald et al. (2006)" startWordPosition="2209" endWordPosition="2212"> 30.0 30.0 30.0 75.2 33.3 26.4 29.5 64.7 12.5 11.4 11.9 New (τ2) 67.5 82.7 79.3 71.0 79.3 84.3 38.2 32.5 35.1 75.7 60.6 27.6 37.9 65.0 14.3 13.2 13.7 Malt 66.7 78.4 76.3 57.9 65.8 84.8 45.8 27.5 34.4 70.3 45.9 20.7 25.1 65.7 16.7 9.2 11.9 MST 66.9 80.2 60.5 61.7 61.1 84.8 54.0 62.5 57.9 73.4 33.7 26.4 29.6 63.2 – 11.8 – MSTMalt 68.6 82.3 63.9 69.2 66.1 86.7 63.0 60.0 61.5 75.9 31.6 27.6 29.5 66.3 11.1 9.2 10.1 Table 2: Labeled attachment score (AS) overall; precision (P), recall (R) and balanced F-score (F) for non-projective dependencies. Old = τ1; New = τ2; Malt = Nivre et al. (2006), MST = McDonald et al. (2006), MSTMalt = Nivre and McDonald (2008). the single exception that the old one has marginally higher recall for Czech. Moreover, the reordering parser with the new oracle has higher F-score than any other system for all languages except Danish. Especially the result for Czech, with 79.3% precision and 71.0% recall, is remarkably good, making the parser almost as accurate for non-projective dependencies as it is for projective dependencies. It seems likely that the good results for Czech are due to the fact that Czech has the highest percentage of non-projective structures in combination with the</context>
</contexts>
<marker>McDonald, Lerman, Pereira, 2006</marker>
<rawString>Ryan McDonald, Kevin Lerman, and Fernando Pereira. 2006. Multilingual dependency analysis with a two-stage discriminative parser. In Proceedings of CoNLL, pages 216–220.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Ryan McDonald</author>
</authors>
<title>Integrating graph-based and transition-based dependency parsers.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>950--958</pages>
<contexts>
<context position="10801" citStr="Nivre and McDonald, 2008" startWordPosition="1818" endWordPosition="1821"> these classifiers consist only of the sequences derived by the oracles, which means that the parser has no explicit notion of projective order or maximal projective components at parsing time. Table 2 shows the labeled parsing accuracy of the parsers measured by the overall attachment score (AS), as well as labeled precision, recall and (balanced) F-score for non-projective dependencies.1 For comparison, we also give results for the two best performing systems in the original CoNLL-X shared task, Malt (Nivre et al., 2006) and MST (McDonald et al., 2006), as well as the combo system MSTMalt, (Nivre and McDonald, 2008). Looking first at the overall labeled attachment score, we see that the new training oracle consistently gives higher accuracy than the old one, with differences of up to 0.5 percentage points (for Arabic and Slovene), which is substantial given that the frequency of non-projective dependencies is only 0.4–1.9%. Because the test sets are so small, none of the differences is statistically significant (McNemar’s test, α = .05), but the consistent improvement over all languages nevertheless strongly suggests that this is a genuine difference. In relation to the state of the art, we note that the</context>
<context position="13049" citStr="Nivre and McDonald (2008)" startWordPosition="2215" endWordPosition="2218">5 64.7 12.5 11.4 11.9 New (τ2) 67.5 82.7 79.3 71.0 79.3 84.3 38.2 32.5 35.1 75.7 60.6 27.6 37.9 65.0 14.3 13.2 13.7 Malt 66.7 78.4 76.3 57.9 65.8 84.8 45.8 27.5 34.4 70.3 45.9 20.7 25.1 65.7 16.7 9.2 11.9 MST 66.9 80.2 60.5 61.7 61.1 84.8 54.0 62.5 57.9 73.4 33.7 26.4 29.6 63.2 – 11.8 – MSTMalt 68.6 82.3 63.9 69.2 66.1 86.7 63.0 60.0 61.5 75.9 31.6 27.6 29.5 66.3 11.1 9.2 10.1 Table 2: Labeled attachment score (AS) overall; precision (P), recall (R) and balanced F-score (F) for non-projective dependencies. Old = τ1; New = τ2; Malt = Nivre et al. (2006), MST = McDonald et al. (2006), MSTMalt = Nivre and McDonald (2008). the single exception that the old one has marginally higher recall for Czech. Moreover, the reordering parser with the new oracle has higher F-score than any other system for all languages except Danish. Especially the result for Czech, with 79.3% precision and 71.0% recall, is remarkably good, making the parser almost as accurate for non-projective dependencies as it is for projective dependencies. It seems likely that the good results for Czech are due to the fact that Czech has the highest percentage of non-projective structures in combination with the (by far) largest training set. 5 Con</context>
</contexts>
<marker>Nivre, McDonald, 2008</marker>
<rawString>Joakim Nivre and Ryan McDonald. 2008. Integrating graph-based and transition-based dependency parsers. In Proceedings of ACL, pages 950–958.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Johan Hall</author>
<author>Jens Nilsson</author>
<author>Gülsen Eryi˘git</author>
<author>Svetoslav Marinov</author>
</authors>
<title>Labeled pseudoprojective dependency parsing with support vector machines.</title>
<date>2006</date>
<booktitle>In Proceedings of CoNLL,</booktitle>
<pages>221--225</pages>
<marker>Nivre, Hall, Nilsson, Eryi˘git, Marinov, 2006</marker>
<rawString>Joakim Nivre, Johan Hall, Jens Nilsson, Gülsen Eryi˘git, and Svetoslav Marinov. 2006. Labeled pseudoprojective dependency parsing with support vector machines. In Proceedings of CoNLL, pages 221– 225.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
</authors>
<title>Algorithms for deterministic incremental dependency parsing.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<pages>34--513</pages>
<contexts>
<context position="3190" citStr="Nivre, 2008" startWordPosition="467" endWordPosition="468">ill handles arbitrary non-projective structures. 2 Background The fundamental reason why sentences with nonprojective dependency trees are hard to parse is that they contain dependencies between non-adjacent substructures. The basic idea in online reordering is to allow the parser to swap input words so that all dependency arcs can be constructed between adjacent subtrees. This idea is implemented in the transition system proposed by Nivre (2009). The first three transitions of this system (LEFT-ARC, RIGHT-ARC, and SHIFT) are familiar from many systems for transition-based dependency parsing (Nivre, 2008). The only novelty is the SWAP transition, which permutes two nodes by moving the second-topmost node from the stack back to the input buffer while leaving the top node on the stack. To understand how we can parse sentences with non-projective dependency trees, in spite of the fact that dependencies can only be added between nodes that are adjacent on the stack, note that, for any sentence x with dependency tree G, there is always some permutation x&apos; of x such that G is projective with respect to x&apos;. There may be more than one such permutation, but Nivre (2009) defines the canonical projective</context>
</contexts>
<marker>Nivre, 2008</marker>
<rawString>Joakim Nivre. 2008. Algorithms for deterministic incremental dependency parsing. Computational Linguistics, 34:513–553.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
</authors>
<title>Non-projective dependency parsing in expected linear time.</title>
<date>2009</date>
<booktitle>In Proceedings of ACLIJCNLP.</booktitle>
<contexts>
<context position="1869" citStr="Nivre (2009)" startWordPosition="269" endWordPosition="270"> makes the treatment of non-projectivity central for accurate dependency parsing. Unfortunately, parsing with unrestricted non-projective structures is a hard problem, for which exact inference is not possible in polynomial time except under drastic independence assumptions (McDonald and Satta, 2007), and most data-driven parsers therefore use approximate methods (Nivre et al., 2006; McDonald et al., 2006). One recently explored approach is to perform online reordering by swapping adjacent words of the input sentence while building the dependency structure. Using this technique, the system of Nivre (2009) processes unrestricted non-projective structures with state-ofthe-art accuracy in observed linear time. The normal procedure for training a transitionbased parser is to use an oracle that predicts an optimal transition sequence for every dependency tree in the training set, and then approximate this oracle by a classifier. In this paper, we show that the oracle used for training by Nivre (2009) is suboptimal because it eagerly swaps words as early as possible and therefore makes a large number of unnecessary transitions, which potentially affects both efficiency and accuracy. We propose an al</context>
<context position="3757" citStr="Nivre (2009)" startWordPosition="569" endWordPosition="570">sition-based dependency parsing (Nivre, 2008). The only novelty is the SWAP transition, which permutes two nodes by moving the second-topmost node from the stack back to the input buffer while leaving the top node on the stack. To understand how we can parse sentences with non-projective dependency trees, in spite of the fact that dependencies can only be added between nodes that are adjacent on the stack, note that, for any sentence x with dependency tree G, there is always some permutation x&apos; of x such that G is projective with respect to x&apos;. There may be more than one such permutation, but Nivre (2009) defines the canonical projective order &lt;G for x given G as the order given by an inorder traversal of G that respects the order &lt; between a node and its direct dependents. This is illustrated in Figure 1, where the words of a sentence with a non-projective tree 73 Proceedings of the 11th International Conference on Parsing Technologies (IWPT), pages 73–76, Paris, October 2009. c�2009 Association for Computational Linguistics P Figure 1: Dependency tree for an English sentence with projective order annotation. ROOT 0 Who 6 did you 1 2 send the letter 3 4 5 to 7 ? 8 NMOD VG SUBJ ROOT OBJ2 OBJ1 </context>
<context position="5293" citStr="Nivre (2009)" startWordPosition="830" endWordPosition="831">he training set to a transition sequence that derives T. While every complete transition sequence determines a unique dependency tree, the inverse does not necessarily hold. This also means that it may be possible to construct different training oracles. For simple systems that are restricted to projective dependency trees, such differences are usually trivial, but for a system that allows online reordering there may be genuine differences that can affect both the efficiency and accuracy of the resulting parsers. 3.1 The Old Oracle Figure 2 defines the original training oracle 7-1 proposed by Nivre (2009). This oracle follows an eager reordering strategy; it predicts SWAP in every configuration where this is possible. The basic insight in this paper is that, by postponing swaps and building as much of the tree structure as possible before swapping, we can significantly decrease the length of the transition sequence for a given sentence and tree. This may benefit the efficiency of the parser trained using the oracle, as each transition takes a certain time to predict and to execute. Longer transition sequences may also be harder to learn than shorter ones, which potentially affects the accuracy</context>
<context position="8167" citStr="Nivre (2009)" startWordPosition="1361" endWordPosition="1362">ck. The definition of the new oracle 7-2 is identical to that of 7-1 except that the third line is replaced by “SWAP if c =([σ|i, j], [k|β], Ac), j &lt;G i, and MPC(j) =� MPC(k)”, where MPC(i) is the maximal projective component of node i. As a special case, 7-2 predicts SWAP if j &lt;G i and the buffer B is empty. 74 7-1(c) = { LEFT-ARCl if c = ([u|i, j], B, A,), (j,l, i)EA and AZ C A, RIGHT-ARCl if c = ([u|i, j], B, A,), (i,l, j)EA and Ai C A, SWAP if c = ([u|i, j], B, A,) and j &lt;G i SHIFT otherwise Figure 2: Training oracle 7-1 for an arbitrary target tree G = (V,;, A), following the notation of Nivre (2009), where c = (E, B, A,) denotes a configuration c with stack E, input buffer B and arc set A,. We write AZ to denote the subset of A that only contains the outgoing arcs of the node i. (Note that A, is the arc set in configuration c, while A is the arc set in the target tree G.) For example, in extracting the transition sequence for the target tree in Figure 1, the new oracle will postpone swapping of did when you is the next node in the input, but not postpone when the next node is send. We can show that a parser informed by the new training oracle can always proceed to a terminal configuratio</context>
<context position="13759" citStr="Nivre (2009)" startWordPosition="2331" endWordPosition="2332">dering parser with the new oracle has higher F-score than any other system for all languages except Danish. Especially the result for Czech, with 79.3% precision and 71.0% recall, is remarkably good, making the parser almost as accurate for non-projective dependencies as it is for projective dependencies. It seems likely that the good results for Czech are due to the fact that Czech has the highest percentage of non-projective structures in combination with the (by far) largest training set. 5 Conclusion We have presented a new training oracle for the transition system originally presented in Nivre (2009). This oracle postpones swapping as long as possible but still fulfills the correctness criterion. Our experimental results show that the new training oracle can reduce the necessary number of swaps by more than 80%, and that parsers trained in this way achieve higher precision and recall on nonprojective dependency arcs as well as higher attachment score overall. The results are particularly good for languages with a high percentage of nonprojective dependencies, with an all-time best over all metrics for Czech. An interesting theoretical question is whether the new oracle defined in this pap</context>
</contexts>
<marker>Nivre, 2009</marker>
<rawString>Joakim Nivre. 2009. Non-projective dependency parsing in expected linear time. In Proceedings of ACLIJCNLP.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>