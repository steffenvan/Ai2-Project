<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.065926">
<title confidence="0.992353">
Acquiring a Dictionary of Emotion-Provoking Events
</title>
<author confidence="0.994908">
Hoa Trong Vu†,t, Graham Neubig†, Sakriani Sakti†, Tomoki Toda†, Satoshi Nakamura†
</author>
<affiliation confidence="0.976706333333333">
†Graduate School of Information Science, Nara Institute of Science and Technology
8916-5 Takayama-cho, Ikoma-shi, Nara, Japan
tVietnam National University, University of Engineering and Technology
</affiliation>
<address confidence="0.84894">
E3 Building - 144 Xuan Thuy Street, Cau Giay, Hanoi, Vietnam
</address>
<sectionHeader confidence="0.934852" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999733235294118">
This paper is concerned with the discov-
ery and aggregation of events that provoke
a particular emotion in the person who
experiences them, or emotion-provoking
events. We first describe the creation of a
small manually-constructed dictionary of
events through a survey of 30 subjects.
Next, we describe first attempts at auto-
matically acquiring and aggregating these
events from web data, with a baseline from
previous work and some simple extensions
using seed expansion and clustering. Fi-
nally, we propose several evaluation meas-
ures for evaluating the automatically ac-
quired events, and perform an evaluation
of the effectiveness of automatic event ex-
traction.
</bodyText>
<sectionHeader confidence="0.998994" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9998635">
“You look happy today, did something good hap-
pen?” This is a natural question in human dia-
logue, and most humans could think of a variety of
answers, such as “I met my friends” or “I passed a
test.” In this work, we concern ourselves with cre-
ating resources that answer this very question, or
more formally “given a particular emotion, what
are the most prevalent events (or situations, con-
texts) that provoke it?”1 Information about these
emotion-provoking events is potentially useful for
emotion recognition (recognizing emotion based
on events mentioned in a dialogue), response gen-
eration (providing an answer to emotion-related
questions), and answering social-science related
questions (discovering events that affect the emo-
tion of a particular segment of the population).
</bodyText>
<footnote confidence="0.973083333333333">
1This is in contrast to existing sentiment lexicons (Riloff
et al., 2003; Valitutti, 2004; Esuli and Sebastiani, 2006; Ve-
likovich et al., 2010; Mohammad and Turney, 2013), which
only record the sentiment orientation of particular words
(such as “meet” or “friend”), which, while useful, are less dir-
ectly connected to the emotions than the events themselves.
</footnote>
<bodyText confidence="0.999612135135135">
While there is very little previous research on
this subject, one previous work of note by Tok-
uhisa et al. (2008) focused on emotion-provoking
events purely from the viewpoint of emotion re-
cognition. They used large corpus of examples
collected from the Web using manual patterns to
build a k-nearest-neighbors emotion classifier for
dialog systems and found that the classifier sig-
nificantly outperforms baseline methods. This
method provides both an inspiration and a baseline
for our work, but still lacks in that it makes no
attempt to measure the quality of the extracted
events, aggregate similar events, or rank events by
prevalence, all essential factors when attempting
to use extracted events for applications other than
simple emotion recognition.
In this paper, we describe work on creat-
ing prevalence-ranked dictionaries of emotion-
provoking events through both manual labor and
automatic information extraction. To create a
manual dictionary of events, we perform a sur-
vey asking 30 participants to describe events that
caused them to feel a particular emotion, and
manually cleaned and aggregated the results into
a ranked list. Next, we propose several methods
for extracting events automatically from large data
from the Web, which will allow us to increase the
coverage over the smaller manually created dic-
tionary. We start with Tokuhisa et al. (2008)’s pat-
terns as a baseline, and examine methods for im-
proving precision and coverage through the use of
seed expansion and clustering. Finally, we dis-
cuss evaluation measures for the proposed task,
and perform an evaluation of the automatically ex-
tracted emotion-provoking events. The acquired
events will be provided publicly upon acceptance
of the paper.
</bodyText>
<sectionHeader confidence="0.977802" genericHeader="method">
2 Manual Creation of Events
</sectionHeader>
<bodyText confidence="0.994871">
In order to create a small but clean set of gold-
standard data for each emotion, we first performed
</bodyText>
<page confidence="0.956821">
128
</page>
<note confidence="0.832957">
Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 128–132,
Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics
</note>
<subsectionHeader confidence="0.936014">
Emotions Words
</subsectionHeader>
<bodyText confidence="0.999625653846154">
happy, glad
sad, upset
angry, irritated
afraid, scared
surprised, astonished
disgusted, terrible
words for each emotion.
a survey on emotion-provoking events. We did so
by asking a total of 30 subjects (a mixture of male
and female from 20-40 years of age) to write down
five events that provoke each of five emotions:
happiness, sadness, anger, fear, and surprise. As
these events created according to this survey still
have a large amount of lexical variation, we manu-
ally simplify them to their core and merge together
events that have similar meanings.
Finally, for each emotion we extract all the
events that are shared by more than one person. It
should be noted that this will not come anywhere
close to covering the entirety of human emotion,
but as each event is shared by at least two people
in a relatively small sample, any attempt to create
a comprehensive dictionary of emotion-provoking
events should at least be able to cover the pairs in
this collection. We show the most common three
events for each emotion in Table 1.
</bodyText>
<sectionHeader confidence="0.983507" genericHeader="method">
3 Automatic Extraction of Events
</sectionHeader>
<bodyText confidence="0.9999878">
We also performed experiments attempting to
automatically extract and aggregate events from
Web data. As a starting point, we follow Tokuhisa
et al. (2008) in defining a single reliable pattern as
a starting point for event extraction:
</bodyText>
<equation confidence="0.653287">
I am EMOTION that EVENT
</equation>
<bodyText confidence="0.999989214285714">
As this pattern is a relatively reliable indicator that
the event is correct, most events extracted by this
pattern will actually be emotion-provoking events.
For instance, this pattern will be matched with the
sentence “I am happy that my mother is feeling
better”, in which my mother is feeling better cer-
tainly causes happiness.
For the EMOTION placeholder, we take into ac-
count 6 emotions - happiness, sadness, anger, fear,
disgust, and surprise - argued by Ekman (1992) to
be the most basic. We manually create a short list
of words that can be inserted into the above pattern
appropriately, as shown in Table 2.
For the EVENT placeholder, we allow any string
of words, but it is necessary to choose the scope
of the string that is referring to the emotion-
provoking event. To this end, we use a syntactic
parser and set a hard restriction that all events must
be a subtree having root tag S and containing at
least one noun phrase and one verb phrase.
Given these two restrictions, these patterns
provide us with high quality event-emotion pairs,
but the method is still lacking in two respects, lack
of coverage and lack of ability to aggregate sim-
ilar events. As both of these are essential to cre-
ating a high-quality and non-redundant dictionary
of events, we make two simple extensions to the
extraction process as follows.
</bodyText>
<subsectionHeader confidence="0.996184">
3.1 Pattern Expansion
</subsectionHeader>
<bodyText confidence="0.999979380952381">
Pattern expansion, or bootstrapping algorithms are
widely used in the information extraction field
(Ravichandran and Hovy, 2002). In particular Es-
presso (Pantel and Pennacchiotti, 2006) is known
as a state-of-the-art pattern expansion algorithm
widely used in acquiring relationships between
entities. We omit the details of the algorithm
for space concerns, but note that applying the al-
gorithm to our proposed task is relatively straight-
forward, and allows us to acquire additional pat-
terns that may be matched to improve the cover-
age over the single seed pattern. We do, however,
make two changes to the algorithm. The first is
that, as we are interested in extracting events in-
stead of entities, we impose the previously men-
tioned restriction of one verb phrase and one noun
phrase over all events extracted by the patterns.
The second is that we perform normalization of
events to reduce their variability, namely removing
all function words, replacing proper nouns with
special symbol, and lemmatizing words.
</bodyText>
<subsectionHeader confidence="0.999855">
3.2 Grouping events
</subsectionHeader>
<bodyText confidence="0.999782166666667">
The second improvement we perform is group-
ing the extracted events together. Grouping has a
number of potential practical advantages, as noted
frequently in previous work (Becker et al., 2011).
The first is that by grouping similar events to-
gether, we can relieve sparsity issues to some
extent by sharing statistics among the events in
a single group. The second is that aggregating
events together allows humans to browse the lists
more efficiently by reducing the number of re-
dundant entries. In preliminary experiments, we
attempted several clustering methods and even-
</bodyText>
<figure confidence="0.8534898">
happiness
sadness
anger
fear
surprise
disgust
Table 2: Seed
129
Emotions
Events
meeting friends going on a date getting something I want
someone dies/gets sick someone insults me people leave me alone
someone insults me someone breaks a promise someone is too lazy
thinking about the future taking a test walking/driving at night
seeing a friend unexpectedly someone comes to visit receiving a gift
happiness
sadness
anger
fear
surprise
</figure>
<tableCaption confidence="0.989267">
Table 1: The top three events for each emotion.
</tableCaption>
<bodyText confidence="0.9993609">
tually settled on hierarchical agglomerative clus-
tering and the single-linkage criterion using co-
sine similarity as a distance measure (Gower and
Ross, 1969). Choosing the stopping criterion for
agglomerative clustering is somewhat subjective,
in many cases application dependent, but for the
evaluation in this work, we heuristically choose
the number of groups so the average number of
events in each group is four, and leave a further
investigation of the tuning to future work.
</bodyText>
<sectionHeader confidence="0.998278" genericHeader="method">
4 Evaluation Measures
</sectionHeader>
<bodyText confidence="0.99984675862069">
Work on information extraction typically uses ac-
curacy and recall of the extracted information as
an evaluation measure. However, in this work, we
found that it is difficult to assign a clear-cut dis-
tinction between whether an event provokes a par-
ticular emotion or not. In addition, recall is diffi-
cult to measure, as there are essentially infinitely
many events. Thus, in this section, we propose two
new evaluation measures to measure the precision
and recall of the events that we recovered in this
task.
To evaluate the precision of the events extrac-
ted by our method, we focus on the fact that an
event might provoke multiple emotions, but usu-
ally these emotions can be ranked in prominence
or appropriateness. This is, in a way, similar to the
case of information retrieval, where there may be
many search results, but some are more appropri-
ate than others. Based on this observation, we fol-
low the information retrieval literature (Voorhees,
1999) in adapting mean reciprocal rank (MRR) as
an evaluation measure of the accuracy of our ex-
traction. In our case, one event can have multiple
emotions, so for each event that the system out-
puts, we ask an annotator to assign emotions in
descending order of prominence or appropriate-
ness, and assess MRR with respect to these ranked
emotions. 2
We also measure recall with respect to the
</bodyText>
<footnote confidence="0.661343">
2In the current work we did not allow annotators to assign
“ties” between the emotions, but this could be accommodated
in the MRR framework.
</footnote>
<bodyText confidence="0.999820769230769">
manually created dictionary described in Section
2, which gives us an idea of what percent of com-
mon emotions we were able to recover. It should
be noted that in order to measure recall, it is ne-
cessary to take a matching between the events out-
put by the system and the events in the previously
described list. While it would be ideal to do this
automatically, this is difficult due to small lexical
variations between the system output and the list.
Thus, for the current work we perform manual
matching between the system hypotheses and the
references, and hope to examine other ways of
matching in future work.
</bodyText>
<sectionHeader confidence="0.999358" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<bodyText confidence="0.999842333333333">
In this section, we describe an experimental eval-
uation of the accuracy of automatic extraction of
emotion-provoking events.
</bodyText>
<subsectionHeader confidence="0.960653">
5.1 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.999989761904762">
We use Twitter3 as a source of data, as it is it
provides a massive amount of information, and
also because users tend to write about what they
are doing as well as their thoughts, feelings and
emotions. We use a data set that contains more
than 30M English tweets posted during the course
of six weeks in June and July of 2012. To remove
noise, we perform a variety of preprocessing, re-
moving emoticons and tags, normalizing using
the scripts provided by Han and Baldwin (2011),
and Han et al. (2012). CoreNLP4 was used to
get the information about part-of-speech, syntactic
parses, and lemmas.
We prepared four systems for comparison. As a
baseline, we use a method that only uses the ori-
ginal seed pattern mentioned in Section 3 to ac-
quire emotion-provoking events. We also evalu-
ate expansions to this method with clustering, with
pattern expansion, and with both.
We set a 10 iteration limit on the Espresso al-
gorithm and after each iteration, we add the 20
</bodyText>
<footnote confidence="0.994537333333333">
3http://www.twitter.com
4http://nlp.stanford.edu/software/
corenlp.shtml
</footnote>
<page confidence="0.983839">
130
</page>
<table confidence="0.9929782">
Methods MRR Recall
Seed 46.3 (f5.0) 4.6 (f0.5)
Seed + clust 57.2 (f7.9) 8.5 (f0.9)
Espresso 49.4 (f2.8) 8.0 (f0.5)
Espresso + clust 71.7 (f2.9) 15.4 (f0.8)
</table>
<tableCaption confidence="0.961012">
Table 3: MRR and recall of extracted data (with
standard deviation for 3 annotators).
</tableCaption>
<bodyText confidence="0.9996255625">
most reliable patterns to the pattern set, and in-
crease the seed set by one third of its size. These
values were set according to a manual inspection
of the results for several settings, before any eval-
uation was performed.
We examine the utility of each method accord-
ing to the evaluation measures proposed in Sec-
tion 4 over five emotions, happiness, sadness, an-
ger, fear, and surprise.5 To measure MRR and
recall, we used the 20 most frequent events or
groups extracted by each method for these five
emotions, and thus all measures can be interpreted
as MRR@20 and recall@20. As manual annota-
tion is required to calculate both measures, we ac-
quired results for 3 annotators and report the aver-
age and standard deviation.
</bodyText>
<subsectionHeader confidence="0.998957">
5.2 Experimental Results
</subsectionHeader>
<bodyText confidence="0.999954636363636">
The results are found in Table 3. From these res-
ults we can see that clustering the events causes a
significant gain on both MRR and recall, regard-
less of whether we use Espresso or not. Looking
at the results for Espresso, we see that it allows for
small boost in recall when used on its own, due
to the fact that the additional patterns help recover
more instances of each event, making the estimate
of frequency counts more robust. However, Es-
presso is more effective when used in combination
with clustering, showing that both methods are
capturing different varieties of information, both
of which are useful for the task.
In the end, the combination of pattern expansion
and clustering achieves an MRR of 71.7% and re-
call of 15.4%. While the MRR could be deemed
satisfactory, the recall is still relatively low. One
reason for this is that due to the labor-intensive
manual evaluation, it is not realistic to check many
more than the top 20 extracted events for each
emotion, making automatic evaluation metrics the
top on the agenda for future work.
</bodyText>
<footnote confidence="0.994691">
5We exclude disgust, as the seed only matched 26 times
over entire corpus, not enough for a reasonable evaluation.
</footnote>
<table confidence="0.998869666666667">
Emotions MRR Recall
happiness 93.9 23.1
sadness 76.9 10.0
anger 76.5 14.0
fear 48.3 24.3
surprise 59.6 0.0
</table>
<tableCaption confidence="0.912359">
Table 4: Average MRR and recall by emotion for
the Espresso + clustering method.
</tableCaption>
<bodyText confidence="0.999783277777778">
However, even without considering this, we
found that the events extracted from Twitter
were somewhat biased towards common, everyday
events, or events regarding love and dating. On the
other hand, our annotators produced a wide vari-
ety of events including both everyday events, and
events that do not happen every day, but leave a
particularly strong impression when encountered.
This can be seen particularly in the accuracy and
recall results by emotion for the best system shown
in Table 4. We can see that for some emotions we
achieved recall approaching 25%, but for surprise
we didn’t manage to extract any of the emotions
created by the annotators at all, instead extracting
more mundane events such as “surprised I’m not
fat yet” or “surprised my mom hasn’t called me
yet.” Covering the rare, but important events is an
interesting challenge for expansions to this work.
</bodyText>
<sectionHeader confidence="0.996447" genericHeader="conclusions">
6 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.99968665">
In this paper we described our work in creat-
ing a dictionary of emotion-provoking events, and
demonstrated results for four varieties of auto-
matic information extraction to expand this dic-
tionary. As this is the first attempt at acquiring dic-
tionaries of emotion-provoking events, there are
still many future directions that deserve further in-
vestigation. As mentioned in the experimental dis-
cussion, automatic matching for the evaluation of
event extraction, and ways to improve recall over
rarer but more impressive events are necessary.
There are also many improvements that could be
made to the extraction algorithm itself, including
more sophisticated clustering and pattern expan-
sion algorithms. Finally, it would be quite interest-
ing to use the proposed method as a tool for psy-
chological inquiry, including into the differences
between events that are extracted from Twitter and
other media, or the differences between different
demographics.
</bodyText>
<page confidence="0.997847">
131
</page>
<sectionHeader confidence="0.988671" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999664852941177">
Hila Becker, Mor Naaman, and Luis Gravano. 2011.
Beyond trending topics: Real-world event identific-
ation on Twitter. In Proceedings of the Fifth Inter-
national AAAI Conference on Weblogs and Social
Media (ICWSM11).
Paul Ekman. 1992. An argument for basic emotions.
Cognition &amp; Emotion, 6(3-4):169–200.
Andrea Esuli and Fabrizio Sebastiani. 2006. Senti-
wordnet: A publicly available lexical resource for
opinion mining. In In Proceedings of the 5th Con-
ference on Language Resources and Evaluation,
pages 417–422.
John C Gower and GJS Ross. 1969. Minimum span-
ning trees and single linkage cluster analysis. Ap-
plied statistics, pages 54–64.
Bo Han and Timothy Baldwin. 2011. Lexical normal-
isation of short text messages: makn sens a #twitter.
In Proceedings of the 49th Annual Meeting of the
Association for Computational Linguistics: Human
Language Technologies - Volume 1, HLT ’11, pages
368–378.
Bo Han, Paul Cook, and Timothy Baldwin. 2012.
Automatically constructing a normalisation diction-
ary for microblogs. In Proceedings of the 2012 Joint
Conference on Empirical Methods in Natural Lan-
guage Processing and Computational Natural Lan-
guage Learning, pages 421–432, Jeju Island, Korea,
July. Association for Computational Linguistics.
Saif M Mohammad and Peter D Turney. 2013. Crowd-
sourcing a word–emotion association lexicon. Com-
putational Intelligence, 29(3):436–465.
Patrick Pantel and Marco Pennacchiotti. 2006. Es-
presso: leveraging generic patterns for automatic-
ally harvesting semantic relations. In Proceedings
of the 21st International Conference on Computa-
tional Linguistics and the 44th annual meeting of the
Association for Computational Linguistics, ACL-44,
pages 113–120.
Deepak Ravichandran and Eduard Hovy. 2002. Learn-
ing surface text patterns for a question answering
system. In Proceedings of the 40th Annual Meeting
on Association for Computational Linguistics, ACL
’02, pages 41–47.
Ellen Riloff, Janyce Wiebe, and Theresa Wilson. 2003.
Learning subjective nouns using extraction pattern
bootstrapping. In Proceedings of the seventh confer-
ence on Natural language learning at HLT-NAACL
2003-Volume 4, pages 25–32. Association for Com-
putational Linguistics.
Ryoko Tokuhisa, Kentaro Inui, and Yuji Matsumoto.
2008. Emotion classification using massive ex-
amples extracted from the web. In Proceedings
of the 22nd International Conference on Computa-
tional Linguistics - Volume 1, COLING ’08, pages
881–888.
Ro Valitutti. 2004. Wordnet-affect: an affective ex-
tension of wordnet. In In Proceedings of the 4th In-
ternational Conference on Language Resources and
Evaluation, pages 1083–1086.
Leonid Velikovich, Sasha Blair-Goldensohn, Kerry
Hannan, and Ryan McDonald. 2010. The viability
of web-derived polarity lexicons. In Human Lan-
guage Technologies: The 2010 Annual Conference
of the North American Chapter of the Association
for Computational Linguistics, pages 777–785.
Ellen M Voorhees. 1999. The trec-8 question an-
swering track report. In Proceedings of TREC,
volume 99, pages 77–82.
</reference>
<page confidence="0.99773">
132
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.685627">
<title confidence="0.999922">Acquiring a Dictionary of Emotion-Provoking Events</title>
<author confidence="0.998343">Trong Graham Sakriani Tomoki Satoshi</author>
<affiliation confidence="0.999732">School of Information Science, Nara Institute of Science and</affiliation>
<address confidence="0.933556">8916-5 Takayama-cho, Ikoma-shi, Nara, Japan</address>
<affiliation confidence="0.99319">National University, University of Engineering and</affiliation>
<address confidence="0.917511">E3 Building - 144 Xuan Thuy Street, Cau Giay, Hanoi, Vietnam</address>
<abstract confidence="0.988784722222222">This paper is concerned with the discovery and aggregation of events that provoke a particular emotion in the person who them, or We first describe the creation of a small manually-constructed dictionary of events through a survey of 30 subjects. Next, we describe first attempts at automatically acquiring and aggregating these events from web data, with a baseline from previous work and some simple extensions using seed expansion and clustering. Finally, we propose several evaluation measures for evaluating the automatically acquired events, and perform an evaluation of the effectiveness of automatic event extraction.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Hila Becker</author>
<author>Mor Naaman</author>
<author>Luis Gravano</author>
</authors>
<title>Beyond trending topics: Real-world event identification on Twitter.</title>
<date>2011</date>
<booktitle>In Proceedings of the Fifth International AAAI Conference on Weblogs and Social Media (ICWSM11).</booktitle>
<contexts>
<context position="8214" citStr="Becker et al., 2011" startWordPosition="1305" endWordPosition="1308">algorithm. The first is that, as we are interested in extracting events instead of entities, we impose the previously mentioned restriction of one verb phrase and one noun phrase over all events extracted by the patterns. The second is that we perform normalization of events to reduce their variability, namely removing all function words, replacing proper nouns with special symbol, and lemmatizing words. 3.2 Grouping events The second improvement we perform is grouping the extracted events together. Grouping has a number of potential practical advantages, as noted frequently in previous work (Becker et al., 2011). The first is that by grouping similar events together, we can relieve sparsity issues to some extent by sharing statistics among the events in a single group. The second is that aggregating events together allows humans to browse the lists more efficiently by reducing the number of redundant entries. In preliminary experiments, we attempted several clustering methods and evenhappiness sadness anger fear surprise disgust Table 2: Seed 129 Emotions Events meeting friends going on a date getting something I want someone dies/gets sick someone insults me people leave me alone someone insults me </context>
</contexts>
<marker>Becker, Naaman, Gravano, 2011</marker>
<rawString>Hila Becker, Mor Naaman, and Luis Gravano. 2011. Beyond trending topics: Real-world event identification on Twitter. In Proceedings of the Fifth International AAAI Conference on Weblogs and Social Media (ICWSM11).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Ekman</author>
</authors>
<title>An argument for basic emotions.</title>
<date>1992</date>
<journal>Cognition &amp; Emotion,</journal>
<pages>6--3</pages>
<contexts>
<context position="6106" citStr="Ekman (1992)" startWordPosition="959" endWordPosition="960"> we follow Tokuhisa et al. (2008) in defining a single reliable pattern as a starting point for event extraction: I am EMOTION that EVENT As this pattern is a relatively reliable indicator that the event is correct, most events extracted by this pattern will actually be emotion-provoking events. For instance, this pattern will be matched with the sentence “I am happy that my mother is feeling better”, in which my mother is feeling better certainly causes happiness. For the EMOTION placeholder, we take into account 6 emotions - happiness, sadness, anger, fear, disgust, and surprise - argued by Ekman (1992) to be the most basic. We manually create a short list of words that can be inserted into the above pattern appropriately, as shown in Table 2. For the EVENT placeholder, we allow any string of words, but it is necessary to choose the scope of the string that is referring to the emotionprovoking event. To this end, we use a syntactic parser and set a hard restriction that all events must be a subtree having root tag S and containing at least one noun phrase and one verb phrase. Given these two restrictions, these patterns provide us with high quality event-emotion pairs, but the method is stil</context>
</contexts>
<marker>Ekman, 1992</marker>
<rawString>Paul Ekman. 1992. An argument for basic emotions. Cognition &amp; Emotion, 6(3-4):169–200.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Esuli</author>
<author>Fabrizio Sebastiani</author>
</authors>
<title>Sentiwordnet: A publicly available lexical resource for opinion mining. In</title>
<date>2006</date>
<booktitle>In Proceedings of the 5th Conference on Language Resources and Evaluation,</booktitle>
<pages>417--422</pages>
<contexts>
<context position="1977" citStr="Esuli and Sebastiani, 2006" startWordPosition="293" endWordPosition="296">is very question, or more formally “given a particular emotion, what are the most prevalent events (or situations, contexts) that provoke it?”1 Information about these emotion-provoking events is potentially useful for emotion recognition (recognizing emotion based on events mentioned in a dialogue), response generation (providing an answer to emotion-related questions), and answering social-science related questions (discovering events that affect the emotion of a particular segment of the population). 1This is in contrast to existing sentiment lexicons (Riloff et al., 2003; Valitutti, 2004; Esuli and Sebastiani, 2006; Velikovich et al., 2010; Mohammad and Turney, 2013), which only record the sentiment orientation of particular words (such as “meet” or “friend”), which, while useful, are less directly connected to the emotions than the events themselves. While there is very little previous research on this subject, one previous work of note by Tokuhisa et al. (2008) focused on emotion-provoking events purely from the viewpoint of emotion recognition. They used large corpus of examples collected from the Web using manual patterns to build a k-nearest-neighbors emotion classifier for dialog systems and found</context>
</contexts>
<marker>Esuli, Sebastiani, 2006</marker>
<rawString>Andrea Esuli and Fabrizio Sebastiani. 2006. Sentiwordnet: A publicly available lexical resource for opinion mining. In In Proceedings of the 5th Conference on Language Resources and Evaluation, pages 417–422.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John C Gower</author>
<author>GJS Ross</author>
</authors>
<title>Minimum spanning trees and single linkage cluster analysis. Applied statistics,</title>
<date>1969</date>
<pages>54--64</pages>
<contexts>
<context position="9236" citStr="Gower and Ross, 1969" startWordPosition="1467" endWordPosition="1470">er fear surprise disgust Table 2: Seed 129 Emotions Events meeting friends going on a date getting something I want someone dies/gets sick someone insults me people leave me alone someone insults me someone breaks a promise someone is too lazy thinking about the future taking a test walking/driving at night seeing a friend unexpectedly someone comes to visit receiving a gift happiness sadness anger fear surprise Table 1: The top three events for each emotion. tually settled on hierarchical agglomerative clustering and the single-linkage criterion using cosine similarity as a distance measure (Gower and Ross, 1969). Choosing the stopping criterion for agglomerative clustering is somewhat subjective, in many cases application dependent, but for the evaluation in this work, we heuristically choose the number of groups so the average number of events in each group is four, and leave a further investigation of the tuning to future work. 4 Evaluation Measures Work on information extraction typically uses accuracy and recall of the extracted information as an evaluation measure. However, in this work, we found that it is difficult to assign a clear-cut distinction between whether an event provokes a particula</context>
</contexts>
<marker>Gower, Ross, 1969</marker>
<rawString>John C Gower and GJS Ross. 1969. Minimum spanning trees and single linkage cluster analysis. Applied statistics, pages 54–64.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Han</author>
<author>Timothy Baldwin</author>
</authors>
<title>Lexical normalisation of short text messages: makn sens a #twitter.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1, HLT ’11,</booktitle>
<pages>368--378</pages>
<contexts>
<context position="12319" citStr="Han and Baldwin (2011)" startWordPosition="1993" endWordPosition="1996">his section, we describe an experimental evaluation of the accuracy of automatic extraction of emotion-provoking events. 5.1 Experimental Setup We use Twitter3 as a source of data, as it is it provides a massive amount of information, and also because users tend to write about what they are doing as well as their thoughts, feelings and emotions. We use a data set that contains more than 30M English tweets posted during the course of six weeks in June and July of 2012. To remove noise, we perform a variety of preprocessing, removing emoticons and tags, normalizing using the scripts provided by Han and Baldwin (2011), and Han et al. (2012). CoreNLP4 was used to get the information about part-of-speech, syntactic parses, and lemmas. We prepared four systems for comparison. As a baseline, we use a method that only uses the original seed pattern mentioned in Section 3 to acquire emotion-provoking events. We also evaluate expansions to this method with clustering, with pattern expansion, and with both. We set a 10 iteration limit on the Espresso algorithm and after each iteration, we add the 20 3http://www.twitter.com 4http://nlp.stanford.edu/software/ corenlp.shtml 130 Methods MRR Recall Seed 46.3 (f5.0) 4.6</context>
</contexts>
<marker>Han, Baldwin, 2011</marker>
<rawString>Bo Han and Timothy Baldwin. 2011. Lexical normalisation of short text messages: makn sens a #twitter. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1, HLT ’11, pages 368–378.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Han</author>
<author>Paul Cook</author>
<author>Timothy Baldwin</author>
</authors>
<title>Automatically constructing a normalisation dictionary for microblogs.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,</booktitle>
<pages>421--432</pages>
<institution>Jeju Island, Korea, July. Association for Computational Linguistics.</institution>
<contexts>
<context position="12342" citStr="Han et al. (2012)" startWordPosition="1998" endWordPosition="2001">experimental evaluation of the accuracy of automatic extraction of emotion-provoking events. 5.1 Experimental Setup We use Twitter3 as a source of data, as it is it provides a massive amount of information, and also because users tend to write about what they are doing as well as their thoughts, feelings and emotions. We use a data set that contains more than 30M English tweets posted during the course of six weeks in June and July of 2012. To remove noise, we perform a variety of preprocessing, removing emoticons and tags, normalizing using the scripts provided by Han and Baldwin (2011), and Han et al. (2012). CoreNLP4 was used to get the information about part-of-speech, syntactic parses, and lemmas. We prepared four systems for comparison. As a baseline, we use a method that only uses the original seed pattern mentioned in Section 3 to acquire emotion-provoking events. We also evaluate expansions to this method with clustering, with pattern expansion, and with both. We set a 10 iteration limit on the Espresso algorithm and after each iteration, we add the 20 3http://www.twitter.com 4http://nlp.stanford.edu/software/ corenlp.shtml 130 Methods MRR Recall Seed 46.3 (f5.0) 4.6 (f0.5) Seed + clust 57</context>
</contexts>
<marker>Han, Cook, Baldwin, 2012</marker>
<rawString>Bo Han, Paul Cook, and Timothy Baldwin. 2012. Automatically constructing a normalisation dictionary for microblogs. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 421–432, Jeju Island, Korea, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saif M Mohammad</author>
<author>Peter D Turney</author>
</authors>
<title>Crowdsourcing a word–emotion association lexicon.</title>
<date>2013</date>
<journal>Computational Intelligence,</journal>
<volume>29</volume>
<issue>3</issue>
<contexts>
<context position="2030" citStr="Mohammad and Turney, 2013" startWordPosition="302" endWordPosition="305">r emotion, what are the most prevalent events (or situations, contexts) that provoke it?”1 Information about these emotion-provoking events is potentially useful for emotion recognition (recognizing emotion based on events mentioned in a dialogue), response generation (providing an answer to emotion-related questions), and answering social-science related questions (discovering events that affect the emotion of a particular segment of the population). 1This is in contrast to existing sentiment lexicons (Riloff et al., 2003; Valitutti, 2004; Esuli and Sebastiani, 2006; Velikovich et al., 2010; Mohammad and Turney, 2013), which only record the sentiment orientation of particular words (such as “meet” or “friend”), which, while useful, are less directly connected to the emotions than the events themselves. While there is very little previous research on this subject, one previous work of note by Tokuhisa et al. (2008) focused on emotion-provoking events purely from the viewpoint of emotion recognition. They used large corpus of examples collected from the Web using manual patterns to build a k-nearest-neighbors emotion classifier for dialog systems and found that the classifier significantly outperforms baseli</context>
</contexts>
<marker>Mohammad, Turney, 2013</marker>
<rawString>Saif M Mohammad and Peter D Turney. 2013. Crowdsourcing a word–emotion association lexicon. Computational Intelligence, 29(3):436–465.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Pantel</author>
<author>Marco Pennacchiotti</author>
</authors>
<title>Espresso: leveraging generic patterns for automatically harvesting semantic relations.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics, ACL-44,</booktitle>
<pages>113--120</pages>
<contexts>
<context position="7172" citStr="Pantel and Pennacchiotti, 2006" startWordPosition="1137" endWordPosition="1140">g at least one noun phrase and one verb phrase. Given these two restrictions, these patterns provide us with high quality event-emotion pairs, but the method is still lacking in two respects, lack of coverage and lack of ability to aggregate similar events. As both of these are essential to creating a high-quality and non-redundant dictionary of events, we make two simple extensions to the extraction process as follows. 3.1 Pattern Expansion Pattern expansion, or bootstrapping algorithms are widely used in the information extraction field (Ravichandran and Hovy, 2002). In particular Espresso (Pantel and Pennacchiotti, 2006) is known as a state-of-the-art pattern expansion algorithm widely used in acquiring relationships between entities. We omit the details of the algorithm for space concerns, but note that applying the algorithm to our proposed task is relatively straightforward, and allows us to acquire additional patterns that may be matched to improve the coverage over the single seed pattern. We do, however, make two changes to the algorithm. The first is that, as we are interested in extracting events instead of entities, we impose the previously mentioned restriction of one verb phrase and one noun phrase</context>
</contexts>
<marker>Pantel, Pennacchiotti, 2006</marker>
<rawString>Patrick Pantel and Marco Pennacchiotti. 2006. Espresso: leveraging generic patterns for automatically harvesting semantic relations. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics, ACL-44, pages 113–120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Deepak Ravichandran</author>
<author>Eduard Hovy</author>
</authors>
<title>Learning surface text patterns for a question answering system.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ACL ’02,</booktitle>
<pages>41--47</pages>
<contexts>
<context position="7115" citStr="Ravichandran and Hovy, 2002" startWordPosition="1129" endWordPosition="1132">ents must be a subtree having root tag S and containing at least one noun phrase and one verb phrase. Given these two restrictions, these patterns provide us with high quality event-emotion pairs, but the method is still lacking in two respects, lack of coverage and lack of ability to aggregate similar events. As both of these are essential to creating a high-quality and non-redundant dictionary of events, we make two simple extensions to the extraction process as follows. 3.1 Pattern Expansion Pattern expansion, or bootstrapping algorithms are widely used in the information extraction field (Ravichandran and Hovy, 2002). In particular Espresso (Pantel and Pennacchiotti, 2006) is known as a state-of-the-art pattern expansion algorithm widely used in acquiring relationships between entities. We omit the details of the algorithm for space concerns, but note that applying the algorithm to our proposed task is relatively straightforward, and allows us to acquire additional patterns that may be matched to improve the coverage over the single seed pattern. We do, however, make two changes to the algorithm. The first is that, as we are interested in extracting events instead of entities, we impose the previously men</context>
</contexts>
<marker>Ravichandran, Hovy, 2002</marker>
<rawString>Deepak Ravichandran and Eduard Hovy. 2002. Learning surface text patterns for a question answering system. In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ACL ’02, pages 41–47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen Riloff</author>
<author>Janyce Wiebe</author>
<author>Theresa Wilson</author>
</authors>
<title>Learning subjective nouns using extraction pattern bootstrapping.</title>
<date>2003</date>
<booktitle>In Proceedings of the seventh conference on Natural language learning at HLT-NAACL 2003-Volume 4,</booktitle>
<pages>25--32</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="1932" citStr="Riloff et al., 2003" startWordPosition="287" endWordPosition="290">with creating resources that answer this very question, or more formally “given a particular emotion, what are the most prevalent events (or situations, contexts) that provoke it?”1 Information about these emotion-provoking events is potentially useful for emotion recognition (recognizing emotion based on events mentioned in a dialogue), response generation (providing an answer to emotion-related questions), and answering social-science related questions (discovering events that affect the emotion of a particular segment of the population). 1This is in contrast to existing sentiment lexicons (Riloff et al., 2003; Valitutti, 2004; Esuli and Sebastiani, 2006; Velikovich et al., 2010; Mohammad and Turney, 2013), which only record the sentiment orientation of particular words (such as “meet” or “friend”), which, while useful, are less directly connected to the emotions than the events themselves. While there is very little previous research on this subject, one previous work of note by Tokuhisa et al. (2008) focused on emotion-provoking events purely from the viewpoint of emotion recognition. They used large corpus of examples collected from the Web using manual patterns to build a k-nearest-neighbors em</context>
</contexts>
<marker>Riloff, Wiebe, Wilson, 2003</marker>
<rawString>Ellen Riloff, Janyce Wiebe, and Theresa Wilson. 2003. Learning subjective nouns using extraction pattern bootstrapping. In Proceedings of the seventh conference on Natural language learning at HLT-NAACL 2003-Volume 4, pages 25–32. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryoko Tokuhisa</author>
<author>Kentaro Inui</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Emotion classification using massive examples extracted from the web.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics - Volume 1, COLING ’08,</booktitle>
<pages>881--888</pages>
<contexts>
<context position="2332" citStr="Tokuhisa et al. (2008)" startWordPosition="351" endWordPosition="355">ed questions), and answering social-science related questions (discovering events that affect the emotion of a particular segment of the population). 1This is in contrast to existing sentiment lexicons (Riloff et al., 2003; Valitutti, 2004; Esuli and Sebastiani, 2006; Velikovich et al., 2010; Mohammad and Turney, 2013), which only record the sentiment orientation of particular words (such as “meet” or “friend”), which, while useful, are less directly connected to the emotions than the events themselves. While there is very little previous research on this subject, one previous work of note by Tokuhisa et al. (2008) focused on emotion-provoking events purely from the viewpoint of emotion recognition. They used large corpus of examples collected from the Web using manual patterns to build a k-nearest-neighbors emotion classifier for dialog systems and found that the classifier significantly outperforms baseline methods. This method provides both an inspiration and a baseline for our work, but still lacks in that it makes no attempt to measure the quality of the extracted events, aggregate similar events, or rank events by prevalence, all essential factors when attempting to use extracted events for applic</context>
<context position="3588" citStr="Tokuhisa et al. (2008)" startWordPosition="546" endWordPosition="549">ecognition. In this paper, we describe work on creating prevalence-ranked dictionaries of emotionprovoking events through both manual labor and automatic information extraction. To create a manual dictionary of events, we perform a survey asking 30 participants to describe events that caused them to feel a particular emotion, and manually cleaned and aggregated the results into a ranked list. Next, we propose several methods for extracting events automatically from large data from the Web, which will allow us to increase the coverage over the smaller manually created dictionary. We start with Tokuhisa et al. (2008)’s patterns as a baseline, and examine methods for improving precision and coverage through the use of seed expansion and clustering. Finally, we discuss evaluation measures for the proposed task, and perform an evaluation of the automatically extracted emotion-provoking events. The acquired events will be provided publicly upon acceptance of the paper. 2 Manual Creation of Events In order to create a small but clean set of goldstandard data for each emotion, we first performed 128 Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, page</context>
<context position="5527" citStr="Tokuhisa et al. (2008)" startWordPosition="861" endWordPosition="864">ents that are shared by more than one person. It should be noted that this will not come anywhere close to covering the entirety of human emotion, but as each event is shared by at least two people in a relatively small sample, any attempt to create a comprehensive dictionary of emotion-provoking events should at least be able to cover the pairs in this collection. We show the most common three events for each emotion in Table 1. 3 Automatic Extraction of Events We also performed experiments attempting to automatically extract and aggregate events from Web data. As a starting point, we follow Tokuhisa et al. (2008) in defining a single reliable pattern as a starting point for event extraction: I am EMOTION that EVENT As this pattern is a relatively reliable indicator that the event is correct, most events extracted by this pattern will actually be emotion-provoking events. For instance, this pattern will be matched with the sentence “I am happy that my mother is feeling better”, in which my mother is feeling better certainly causes happiness. For the EMOTION placeholder, we take into account 6 emotions - happiness, sadness, anger, fear, disgust, and surprise - argued by Ekman (1992) to be the most basic</context>
</contexts>
<marker>Tokuhisa, Inui, Matsumoto, 2008</marker>
<rawString>Ryoko Tokuhisa, Kentaro Inui, and Yuji Matsumoto. 2008. Emotion classification using massive examples extracted from the web. In Proceedings of the 22nd International Conference on Computational Linguistics - Volume 1, COLING ’08, pages 881–888.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ro Valitutti</author>
</authors>
<title>Wordnet-affect: an affective extension of wordnet. In</title>
<date>2004</date>
<booktitle>In Proceedings of the 4th International Conference on Language Resources and Evaluation,</booktitle>
<pages>1083--1086</pages>
<contexts>
<context position="1949" citStr="Valitutti, 2004" startWordPosition="291" endWordPosition="292">es that answer this very question, or more formally “given a particular emotion, what are the most prevalent events (or situations, contexts) that provoke it?”1 Information about these emotion-provoking events is potentially useful for emotion recognition (recognizing emotion based on events mentioned in a dialogue), response generation (providing an answer to emotion-related questions), and answering social-science related questions (discovering events that affect the emotion of a particular segment of the population). 1This is in contrast to existing sentiment lexicons (Riloff et al., 2003; Valitutti, 2004; Esuli and Sebastiani, 2006; Velikovich et al., 2010; Mohammad and Turney, 2013), which only record the sentiment orientation of particular words (such as “meet” or “friend”), which, while useful, are less directly connected to the emotions than the events themselves. While there is very little previous research on this subject, one previous work of note by Tokuhisa et al. (2008) focused on emotion-provoking events purely from the viewpoint of emotion recognition. They used large corpus of examples collected from the Web using manual patterns to build a k-nearest-neighbors emotion classifier </context>
</contexts>
<marker>Valitutti, 2004</marker>
<rawString>Ro Valitutti. 2004. Wordnet-affect: an affective extension of wordnet. In In Proceedings of the 4th International Conference on Language Resources and Evaluation, pages 1083–1086.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leonid Velikovich</author>
<author>Sasha Blair-Goldensohn</author>
<author>Kerry Hannan</author>
<author>Ryan McDonald</author>
</authors>
<title>The viability of web-derived polarity lexicons.</title>
<date>2010</date>
<booktitle>In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>777--785</pages>
<contexts>
<context position="2002" citStr="Velikovich et al., 2010" startWordPosition="297" endWordPosition="301">rmally “given a particular emotion, what are the most prevalent events (or situations, contexts) that provoke it?”1 Information about these emotion-provoking events is potentially useful for emotion recognition (recognizing emotion based on events mentioned in a dialogue), response generation (providing an answer to emotion-related questions), and answering social-science related questions (discovering events that affect the emotion of a particular segment of the population). 1This is in contrast to existing sentiment lexicons (Riloff et al., 2003; Valitutti, 2004; Esuli and Sebastiani, 2006; Velikovich et al., 2010; Mohammad and Turney, 2013), which only record the sentiment orientation of particular words (such as “meet” or “friend”), which, while useful, are less directly connected to the emotions than the events themselves. While there is very little previous research on this subject, one previous work of note by Tokuhisa et al. (2008) focused on emotion-provoking events purely from the viewpoint of emotion recognition. They used large corpus of examples collected from the Web using manual patterns to build a k-nearest-neighbors emotion classifier for dialog systems and found that the classifier sign</context>
</contexts>
<marker>Velikovich, Blair-Goldensohn, Hannan, McDonald, 2010</marker>
<rawString>Leonid Velikovich, Sasha Blair-Goldensohn, Kerry Hannan, and Ryan McDonald. 2010. The viability of web-derived polarity lexicons. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 777–785.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen M Voorhees</author>
</authors>
<title>The trec-8 question answering track report.</title>
<date>1999</date>
<booktitle>In Proceedings of TREC,</booktitle>
<volume>99</volume>
<pages>77--82</pages>
<contexts>
<context position="10538" citStr="Voorhees, 1999" startWordPosition="1684" endWordPosition="1685"> infinitely many events. Thus, in this section, we propose two new evaluation measures to measure the precision and recall of the events that we recovered in this task. To evaluate the precision of the events extracted by our method, we focus on the fact that an event might provoke multiple emotions, but usually these emotions can be ranked in prominence or appropriateness. This is, in a way, similar to the case of information retrieval, where there may be many search results, but some are more appropriate than others. Based on this observation, we follow the information retrieval literature (Voorhees, 1999) in adapting mean reciprocal rank (MRR) as an evaluation measure of the accuracy of our extraction. In our case, one event can have multiple emotions, so for each event that the system outputs, we ask an annotator to assign emotions in descending order of prominence or appropriateness, and assess MRR with respect to these ranked emotions. 2 We also measure recall with respect to the 2In the current work we did not allow annotators to assign “ties” between the emotions, but this could be accommodated in the MRR framework. manually created dictionary described in Section 2, which gives us an ide</context>
</contexts>
<marker>Voorhees, 1999</marker>
<rawString>Ellen M Voorhees. 1999. The trec-8 question answering track report. In Proceedings of TREC, volume 99, pages 77–82.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>