<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001582">
<title confidence="0.997985">
Score Distribution Based Term Specific Thresholding
for
Spoken Term Detection
</title>
<author confidence="0.980068">
Do˘gan Can and Murat Sarac¸lar
</author>
<affiliation confidence="0.927640666666667">
Electrical &amp; Electronics Engineering Department
Bo˘gazic¸i University
˙Istanbul, Turkey
</affiliation>
<email confidence="0.998284">
{dogan.can, murat.saraclar}@boun.edu.tr
</email>
<sectionHeader confidence="0.99564" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9997394375">
The spoken term detection (STD) task aims
to return relevant segments from a spoken
archive that contain the query terms. This pa-
per focuses on the decision stage of an STD
system. We propose a term specific threshold-
ing (TST) method that uses per query poste-
rior score distributions. The STD system de-
scribed in this paper indexes word-level lat-
tices produced by an LVCSR system using
Weighted Finite State Transducers (WFSTs).
The target application is a sign dictionary
where precision is more important than recall.
Experiments compare the performance of dif-
ferent thresholding techniques. The proposed
approach increases the maximum precision at-
tainable by the system.
</bodyText>
<sectionHeader confidence="0.998988" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999943829787234">
The availability of vast multimedia archives calls
for solutions to efficiently search this data. Multi-
media content also enables interesting applications
which utilize multiple modalities, such as speech
and video. Spoken term detection (STD) is a sub-
field of speech retrieval, which locates occurrences
of a query in a spoken archive. In this work, STD
is used as a tool to segment and retrieve the signs
in news videos for the hearing impaired based on
speech information. After the location of the query
is extracted with STD, the sign video correspond-
ing to that time interval is displayed to the user.
In addition to being used as a sign language dic-
tionary this approach can also be used to automat-
ically create annotated sign databases that can be
utilized for training sign recognizers (Aran et al.,
2008). For these applications the precision of the
system is more important than its recall.
The classical STD approach consists of convert-
ing the speech to word transcripts using large vocab-
ulary continuous speech recognition (LVCSR) tools
and extending classical information retrieval tech-
niques to word transcripts. However, retrieval per-
formance is highly dependent on the recognition er-
rors. In this context, lattice indexing provides a
means of reducing the effect of recognition errors
by incorporating alternative transcriptions in a prob-
abilistic framework. A system using lattices can also
return the posterior probability of a query as a de-
tection score. Various operating points can be ob-
tained by comparing the detection scores to a thresh-
old. In addition to using a global detection thresh-
old, choosing term specific thresholds that optimize
the STD evaluation metric known as Term-Weighted
Value (TWV) was recently proposed (Miller et al.,
2007). A similar approach which trains a neural net-
work mapping various features to the target classes
was used in (Vergyri et al., 2007).
The rest of the paper is organized as follows.
In Section 2 we explain the methods used for spo-
ken term detection. These include the indexing and
search framework based on WFSTs and the detec-
tion framework based on posterior score distribu-
tions. In Section 3 we describe our experimental
setup and present the results. Finally, in Section 4
we summarize our contributions and discuss possi-
ble future directions.
</bodyText>
<page confidence="0.977575">
269
</page>
<note confidence="0.5350915">
Proceedings of NAACL HLT 2009: Short Papers, pages 269–272,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<sectionHeader confidence="0.99086" genericHeader="introduction">
2 Methods
</sectionHeader>
<bodyText confidence="0.999675444444444">
The STD system used in this study consists of four
stages. In the first stage, an LVCSR system is used
to generate lattices from speech. In the second stage
the lattices are indexed for efficient retrieval. When
a query is presented to the system a set of candidates
ranked by posterior probabilities are obtained from
the index. In the final stage, the posterior probabil-
ities are compared to a threshold to decide which
candidates should be returned.
</bodyText>
<subsectionHeader confidence="0.9053295">
2.1 Indexing and Retrieval using Finite-State
Automata
</subsectionHeader>
<bodyText confidence="0.999957380952381">
General indexation of weighted automata (Allauzen
et al., 2004) provides an efficient means of index-
ing for STD (Parlak and Sarac¸lar, 2008; Can et al.,
2009), where retrieval is based on the posterior prob-
ability of a term in a given time interval. In this
work, the weighted automata to be indexed are the
preprocessed lattice outputs of the ASR system. The
input labels are phones, the output labels are quan-
tized time-intervals and the weights are normalized
negative log probabilities. The index is represented
as a WFST where each substring (factor) leads to a
successful path over the input labels whenever that
particular substring was observed. Output labels of
these paths carry the time interval information fol-
lowed by the utterance IDs. The path weights give
the probability of each factor occurring in the spe-
cific time interval of that utterance. The index is op-
timized by WFST determinization and minimization
so that the search complexity is linear in the sum of
the query length and the number of times the query
appears in the index.
</bodyText>
<subsectionHeader confidence="0.99904">
2.2 Decision Mechanism
</subsectionHeader>
<bodyText confidence="0.99998212">
Once a list of candidates ranked with respect to their
posterior probabilities are determined using the in-
dex, the candidates exceeding a threshold are re-
turned by the system. The threshold is computed
to minimize the Bayes risk. In this framework, we
need to specify a cost function, prior probabilities
and likelihood functions for each class. We choose
the cost of a miss to be 1 and the cost of a false alarm
to be a free parameter, α. The prior probabilities and
the likelihood functions are estimated from the pos-
terior scores of the candidate results for each query.
The likelihood functions are found by fitting para-
metric models to the score distributions (Manmatha
et al., 2001). In this study, the score distributions
are modeled by exponential distributions. When the
system returns a score, we do not know whether
it belongs to the correct or incorrect group, so we
use a mixture of two exponential distributions to
model the posterior scores returned by the system.
The exponential mixture model (EMM) parameters
are determined via unsupervised estimation using
the Expectation-Maximization (EM) algorithm. Fig-
ure 1 shows the normalized histogram of posterior
scores and the EM estimate given by our method for
an example query.
</bodyText>
<figure confidence="0.53683">
Posterior Score
</figure>
<figureCaption confidence="0.994531666666667">
Figure 1: The normalized histogram of posterior scores
and the EM estimates for correct and incorrect detections
given an example query.
</figureCaption>
<bodyText confidence="0.998578">
If we denote the posterior score of each candidate
by x, incorrect class by c0 and correct class by c1,
we have
</bodyText>
<equation confidence="0.999535">
p(x) = P(c0)p(x|c0) + P(c1)p(x|c1)
</equation>
<bodyText confidence="0.85694">
where the incorrect class likelihood
</bodyText>
<equation confidence="0.926558857142857">
p(x|c0) = λ0e−λ0x and correct class like-
lihood p(x|c1) = λ1e−λ1(1−x). The model
parameters λ0, λ1, P(c0), P(c1) are estimated
using the EM algorithm given the scores xi for
i = 1, ... , N. Each iteration consists of first
computing P(cj|xi) = P(cj)p(xi|cj)/p(xi) for
j = 1, 2 and then updating
1 �
P (cj) = N
i
__ &amp; P(c0 |xi)
λ0 E,
i P(c0|xi)xi
n
</equation>
<figure confidence="0.987049">
15
10
5
00 0.2 0.4 0.6 0.8 1
Incorrect Class Distribution
Correct Class Distribution
Incorrect Class EM Estimate
Correct Class EM Estimate
P(cj|xi),
</figure>
<page confidence="0.660726">
270
</page>
<equation confidence="0.664718">
Ei P(c1|xi)
λ1 =Ei P(c1|xi)(1 − xi).
</equation>
<bodyText confidence="0.9959034">
After the mixture parameters are estimated, we as-
sume that each mixture represents a class and mix-
ture weights correspond to class priors. Then, the
Minimum Bayes Risk (MBR) detection threshold
for x is given as:
</bodyText>
<equation confidence="0.999373333333333">
λ1 + log(λ0/λ1) + log(P(c0)/P(c1)) + log α
.
λ0 + λ1
</equation>
<sectionHeader confidence="0.999789" genericHeader="method">
3 Experiments
</sectionHeader>
<subsectionHeader confidence="0.999863">
3.1 Data and Application
</subsectionHeader>
<bodyText confidence="0.999970954545454">
Turkish Radio and Television Channel 2 (TRT2)
broadcasts a news program for the hearing impaired
which contains speech as well as signs. We have
collected 11 hours (total speech time) of test ma-
terial from this broadcast and performed our ex-
periments on this data with a total of 10229 sin-
gle word queries extracted from the reference tran-
scriptions. We used IBM Attila speech recognition
toolkit (Soltau et al., 2007) at the back-end of our
system to produce recognition lattices. The ASR
system is trained on 100 hours of speech and tran-
scription data collected from various TV and radio
broadcasts including TRT2 hearing impaired news,
and a general text corpus of size 100 million words.
Our application uses the speech modality to re-
trieve the signs corresponding to a text query. Re-
trieved results are displayed as video demonstrations
to support the learning of sign language. Since the
application acts like an interactive dictionary of sign
language, primary concern is to return correct results
no matter how few they are. Thus high precision is
appreciated much more than high recall rates.
</bodyText>
<subsectionHeader confidence="0.998323">
3.2 Evaluation Measures
</subsectionHeader>
<bodyText confidence="0.896774">
In our experiments, we use precision and recall as
the primary evaluation metrics. For a set of queries
qk,k = 1,...,Q,
</bodyText>
<equation confidence="0.820677">
Precision = 1 E C(qk) Recall = 1 C(qk)
Q k A(qk) Q k R(qk)
</equation>
<bodyText confidence="0.982528785714286">
where:
R(qk): Number of occurences of query qk,
A(qk): Total no. of retrieved documents for qk,
C(qk): No. of correctly retrieved documents for qk.
We obtain a precision/recall curve by changing
the free parameter associated with each thresholding
method to simulate different decision cost settings.
Right end of these curves fall into the high precision
region which is the main concern in our application.
For the case of global thresholding (GT), the same
threshold θ is used for all queries. TWV based
term specific thresholding (TWV-TST) (Miller et al.,
2007) aims to maximize the TWV metric introduced
during NIST 2006 STD Evaluations (NIST, 2006).
</bodyText>
<equation confidence="0.999775">
lPmiss(qk) + β.PFA(qk)j
Pmiss(qk) = 1−C(qk) PFA(qk) = A(qk) − C(qk)
R(qk) T − C(qk)
</equation>
<bodyText confidence="0.999893222222222">
where T is the total duration of the speech archive
and β is a weight assigned to false alarms that is
proportional to the prior probability of occurence of
a specific term and its cost-value ratio. This method
sets individual thresholds for each query term con-
sidering per query expected counts and the tuning
parameter β. In the proposed method α plays the
same role as β and allows us to control the decision
threshold for different cost settings.
</bodyText>
<figure confidence="0.343378">
Precision
</figure>
<figureCaption confidence="0.999214">
Figure 2: The precision and recall curves for various
thresholding techniques.
</figureCaption>
<bodyText confidence="0.927873625">
Figure 2 compares GT, TWV-TST, and the pro-
posed method that utilizes score distributions to de-
rive an optimal decision threshold. For GT and
TWT-TST, last precision/recall point in the figure
corresponds to the limit threshold value which is 1.0.
Both the TWV-TST and the proposed method out-
perform GT over the entire region of interest. While
TWV-TST provides better performance around the
</bodyText>
<figure confidence="0.992431619047619">
3.3 Results
.8 0.85 0.9 0.95 1
Recall 1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0
Global Thresholding
Term Specific Thresholding (TWV)
EMM + EM + MBR Detection
Cheat + EMM + MBR Detection
1
TWV = 1 − Q
Q
E
k=1
</figure>
<page confidence="0.994706">
271
</page>
<bodyText confidence="0.986840555555556">
knees of the curves, proposed method achieves
higher maximum precision values which coincides
with the primary objective of our application.
Figure 2 also provides a curve of what happens
when the correct class labels are used to estimate
the parameters of the exponential mixture model in a
supervised manner instead of using EM. This curve
provides an upper bound on the performance of the
proposed method.
</bodyText>
<sectionHeader confidence="0.99976" genericHeader="discussions">
4 Discussion
</sectionHeader>
<bodyText confidence="0.999973761904762">
In this paper, we proposed a TST scheme for STD
which works almost as good as TWV-TST. Extrapo-
lating from the cheating experiment, we believe that
the proposed method has potential for outperform-
ing the TWV-TST over the entire region of interest
given better initial estimates for the correct and in-
correct classes.
A special remark goes to the performance in the
high precision region where our method clearly out-
performs the rest. While GT and TWV-TST meth-
ods are bounded around 96.5% precision value, our
method reaches at higher precision figures. For GT,
this behavior is due to the inability to set differ-
ent thresholds for different queries. For TWT-TST,
in the high precision region where β is large, the
threshold is very close to 1.0 value no matter what
the expected count of the query term is, thus it es-
sentially acts like a global threshold.
Our current implementation of the proposed
method does not make use of training data to es-
timate the initial parameters for the EM algorithm.
Instead, it relies on some loose assumptions about
the initial parameters of the likelihood functions and
uses uninformative prior distributions. The signifi-
cant difference between the upper bound and the ac-
tual performance of the proposed method indicates
that the current implementation can be improved by
better initial estimates.
Our assumption about the parametric form of the
likelihood function may not be valid at all times.
Maximizing the likelihood with mismatched mod-
els degrades the performance even when initial
parameters are close to the optimal values. In the
future, other parametric forms can be utilized to bet-
ter model the posterior score distributions.
Maximum likelihood estimation with insufficient
data is prone to overtraining. This is a common sit-
uation with the STD task at hand. With the current
data, three or less results are returned for half of the
queries. Bayesian methods can be used to introduce
priors on the model parameters in order to make the
estimation more robust.
</bodyText>
<sectionHeader confidence="0.998285" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9960614">
This study was supported in part by Bo˘gazic¸i Uni-
versity Research Fund (BAP) under the project num-
ber 05HA202, T ¨UB˙ITAK under the project number
105E102 and Turkish State Planning Organization
(DPT) under the project number DPT2007K120610.
</bodyText>
<sectionHeader confidence="0.999194" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999949228571429">
C. Allauzen, M. Mohri, and M. Sarac¸lar. 2004. General-
indexation of weighted automata-application to spo-
ken utterance retrieval. In Proc. Workshop on Inter-
disciplinary Approaches to Speech Indexing and Re-
trieval at HLT-NAACL, pages 33–40, March.
O. Aran, I. Arı, E. Dikici, S. Parlak, P. Campr, M. Hruz,
L. Akarun, and M. Sarac¸lar. 2008. Speech and slid-
ing text aided sign retrieval from hearing impaired sign
news videos. Journal on Multimodal User Interfaces,
2(1):117–131, November.
D. Can, E. Cooper, A. Sethy, C.M. White, B. Ramabhad-
ran, and M. Saraclar. 2009. Effect of pronunciations
on oov queries in spoken term detection. In ICASSP,
April.
R. Manmatha, T. Rath, and F. Feng. 2001. Modeling
score distributions for combining the outputs of search
engines. In SIGIR ’01, pages 267–275, New York, NY,
USA. ACM.
D. R. H. Miller, M. Kleber, C. Kao, O. Kimball,
T. Colthurst, S. A. Lowe, R. M. Schwartz, and H. Gish.
2007. Rapid and accurate spoken term detection. In
Proc. Interspeech, pages 314–317, August.
NIST. 2006. The spoken term detection (STD) 2006
evaluation plan http://www.nist.gov/speech/tests/std/.
S. Parlak and M. Sarac¸lar. 2008. Spoken term detection
for Turkish broadcast news. In Proc. ICASSP, pages
5244–5247, April.
H. Soltau, G. Saon, D. Povey, L. Mangu, J. Kuo,
M. Omar, and G. Zweig. 2007. The IBM 2006 GALE
Arabic ASR system. In Proc. ICASSP 2007, Hon-
olulu, HI, USA.
D. Vergyri, I. Shafran, A. Stolcke, R. R. Gadde, M. Ak-
bacak, B. Roark, and W. Wang. 2007. The SRI/OGI
2006 spoken term detection system. In Proc. Inter-
speech, pages 2393–2396, August.
</reference>
<page confidence="0.997325">
272
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.768371">
<title confidence="0.998683">Score Distribution Based Term Specific Thresholding for Spoken Term Detection</title>
<author confidence="0.869031">Can</author>
<affiliation confidence="0.838833">Electrical &amp; Electronics Engineering</affiliation>
<abstract confidence="0.997612176470588">The spoken term detection (STD) task aims to return relevant segments from a spoken archive that contain the query terms. This paper focuses on the decision stage of an STD system. We propose a term specific thresholding (TST) method that uses per query posterior score distributions. The STD system described in this paper indexes word-level lattices produced by an LVCSR system using Weighted Finite State Transducers (WFSTs). The target application is a sign dictionary where precision is more important than recall. Experiments compare the performance of different thresholding techniques. The proposed approach increases the maximum precision attainable by the system.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>C Allauzen</author>
<author>M Mohri</author>
<author>M Sarac¸lar</author>
</authors>
<title>Generalindexation of weighted automata-application to spoken utterance retrieval.</title>
<date>2004</date>
<booktitle>In Proc. Workshop on Interdisciplinary Approaches to Speech Indexing and Retrieval at HLT-NAACL,</booktitle>
<pages>33--40</pages>
<marker>Allauzen, Mohri, Sarac¸lar, 2004</marker>
<rawString>C. Allauzen, M. Mohri, and M. Sarac¸lar. 2004. Generalindexation of weighted automata-application to spoken utterance retrieval. In Proc. Workshop on Interdisciplinary Approaches to Speech Indexing and Retrieval at HLT-NAACL, pages 33–40, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Aran</author>
<author>I Arı</author>
<author>E Dikici</author>
<author>S Parlak</author>
<author>P Campr</author>
<author>M Hruz</author>
<author>L Akarun</author>
<author>M Sarac¸lar</author>
</authors>
<title>Speech and sliding text aided sign retrieval from hearing impaired sign news videos.</title>
<date>2008</date>
<journal>Journal on Multimodal User Interfaces,</journal>
<volume>2</volume>
<issue>1</issue>
<marker>Aran, Arı, Dikici, Parlak, Campr, Hruz, Akarun, Sarac¸lar, 2008</marker>
<rawString>O. Aran, I. Arı, E. Dikici, S. Parlak, P. Campr, M. Hruz, L. Akarun, and M. Sarac¸lar. 2008. Speech and sliding text aided sign retrieval from hearing impaired sign news videos. Journal on Multimodal User Interfaces, 2(1):117–131, November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Can</author>
<author>E Cooper</author>
<author>A Sethy</author>
<author>C M White</author>
<author>B Ramabhadran</author>
<author>M Saraclar</author>
</authors>
<title>Effect of pronunciations on oov queries in spoken term detection.</title>
<date>2009</date>
<booktitle>In ICASSP,</booktitle>
<contexts>
<context position="4069" citStr="Can et al., 2009" startWordPosition="639" endWordPosition="642">r stages. In the first stage, an LVCSR system is used to generate lattices from speech. In the second stage the lattices are indexed for efficient retrieval. When a query is presented to the system a set of candidates ranked by posterior probabilities are obtained from the index. In the final stage, the posterior probabilities are compared to a threshold to decide which candidates should be returned. 2.1 Indexing and Retrieval using Finite-State Automata General indexation of weighted automata (Allauzen et al., 2004) provides an efficient means of indexing for STD (Parlak and Sarac¸lar, 2008; Can et al., 2009), where retrieval is based on the posterior probability of a term in a given time interval. In this work, the weighted automata to be indexed are the preprocessed lattice outputs of the ASR system. The input labels are phones, the output labels are quantized time-intervals and the weights are normalized negative log probabilities. The index is represented as a WFST where each substring (factor) leads to a successful path over the input labels whenever that particular substring was observed. Output labels of these paths carry the time interval information followed by the utterance IDs. The path</context>
</contexts>
<marker>Can, Cooper, Sethy, White, Ramabhadran, Saraclar, 2009</marker>
<rawString>D. Can, E. Cooper, A. Sethy, C.M. White, B. Ramabhadran, and M. Saraclar. 2009. Effect of pronunciations on oov queries in spoken term detection. In ICASSP, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Manmatha</author>
<author>T Rath</author>
<author>F Feng</author>
</authors>
<title>Modeling score distributions for combining the outputs of search engines.</title>
<date>2001</date>
<booktitle>In SIGIR ’01,</booktitle>
<pages>267--275</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="5675" citStr="Manmatha et al., 2001" startWordPosition="911" endWordPosition="914">robabilities are determined using the index, the candidates exceeding a threshold are returned by the system. The threshold is computed to minimize the Bayes risk. In this framework, we need to specify a cost function, prior probabilities and likelihood functions for each class. We choose the cost of a miss to be 1 and the cost of a false alarm to be a free parameter, α. The prior probabilities and the likelihood functions are estimated from the posterior scores of the candidate results for each query. The likelihood functions are found by fitting parametric models to the score distributions (Manmatha et al., 2001). In this study, the score distributions are modeled by exponential distributions. When the system returns a score, we do not know whether it belongs to the correct or incorrect group, so we use a mixture of two exponential distributions to model the posterior scores returned by the system. The exponential mixture model (EMM) parameters are determined via unsupervised estimation using the Expectation-Maximization (EM) algorithm. Figure 1 shows the normalized histogram of posterior scores and the EM estimate given by our method for an example query. Posterior Score Figure 1: The normalized hist</context>
</contexts>
<marker>Manmatha, Rath, Feng, 2001</marker>
<rawString>R. Manmatha, T. Rath, and F. Feng. 2001. Modeling score distributions for combining the outputs of search engines. In SIGIR ’01, pages 267–275, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D R H Miller</author>
<author>M Kleber</author>
<author>C Kao</author>
<author>O Kimball</author>
<author>T Colthurst</author>
<author>S A Lowe</author>
<author>R M Schwartz</author>
<author>H Gish</author>
</authors>
<title>Rapid and accurate spoken term detection.</title>
<date>2007</date>
<booktitle>In Proc. Interspeech,</booktitle>
<pages>314--317</pages>
<contexts>
<context position="2704" citStr="Miller et al., 2007" startWordPosition="416" endWordPosition="419">rformance is highly dependent on the recognition errors. In this context, lattice indexing provides a means of reducing the effect of recognition errors by incorporating alternative transcriptions in a probabilistic framework. A system using lattices can also return the posterior probability of a query as a detection score. Various operating points can be obtained by comparing the detection scores to a threshold. In addition to using a global detection threshold, choosing term specific thresholds that optimize the STD evaluation metric known as Term-Weighted Value (TWV) was recently proposed (Miller et al., 2007). A similar approach which trains a neural network mapping various features to the target classes was used in (Vergyri et al., 2007). The rest of the paper is organized as follows. In Section 2 we explain the methods used for spoken term detection. These include the indexing and search framework based on WFSTs and the detection framework based on posterior score distributions. In Section 3 we describe our experimental setup and present the results. Finally, in Section 4 we summarize our contributions and discuss possible future directions. 269 Proceedings of NAACL HLT 2009: Short Papers, pages</context>
<context position="9279" citStr="Miller et al., 2007" startWordPosition="1518" endWordPosition="1521">ision = 1 E C(qk) Recall = 1 C(qk) Q k A(qk) Q k R(qk) where: R(qk): Number of occurences of query qk, A(qk): Total no. of retrieved documents for qk, C(qk): No. of correctly retrieved documents for qk. We obtain a precision/recall curve by changing the free parameter associated with each thresholding method to simulate different decision cost settings. Right end of these curves fall into the high precision region which is the main concern in our application. For the case of global thresholding (GT), the same threshold θ is used for all queries. TWV based term specific thresholding (TWV-TST) (Miller et al., 2007) aims to maximize the TWV metric introduced during NIST 2006 STD Evaluations (NIST, 2006). lPmiss(qk) + β.PFA(qk)j Pmiss(qk) = 1−C(qk) PFA(qk) = A(qk) − C(qk) R(qk) T − C(qk) where T is the total duration of the speech archive and β is a weight assigned to false alarms that is proportional to the prior probability of occurence of a specific term and its cost-value ratio. This method sets individual thresholds for each query term considering per query expected counts and the tuning parameter β. In the proposed method α plays the same role as β and allows us to control the decision threshold for</context>
</contexts>
<marker>Miller, Kleber, Kao, Kimball, Colthurst, Lowe, Schwartz, Gish, 2007</marker>
<rawString>D. R. H. Miller, M. Kleber, C. Kao, O. Kimball, T. Colthurst, S. A. Lowe, R. M. Schwartz, and H. Gish. 2007. Rapid and accurate spoken term detection. In Proc. Interspeech, pages 314–317, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>NIST</author>
</authors>
<title>The spoken term detection (STD)</title>
<date>2006</date>
<note>evaluation plan http://www.nist.gov/speech/tests/std/.</note>
<contexts>
<context position="9339" citStr="NIST 2006" startWordPosition="1530" endWordPosition="1531">mber of occurences of query qk, A(qk): Total no. of retrieved documents for qk, C(qk): No. of correctly retrieved documents for qk. We obtain a precision/recall curve by changing the free parameter associated with each thresholding method to simulate different decision cost settings. Right end of these curves fall into the high precision region which is the main concern in our application. For the case of global thresholding (GT), the same threshold θ is used for all queries. TWV based term specific thresholding (TWV-TST) (Miller et al., 2007) aims to maximize the TWV metric introduced during NIST 2006 STD Evaluations (NIST, 2006). lPmiss(qk) + β.PFA(qk)j Pmiss(qk) = 1−C(qk) PFA(qk) = A(qk) − C(qk) R(qk) T − C(qk) where T is the total duration of the speech archive and β is a weight assigned to false alarms that is proportional to the prior probability of occurence of a specific term and its cost-value ratio. This method sets individual thresholds for each query term considering per query expected counts and the tuning parameter β. In the proposed method α plays the same role as β and allows us to control the decision threshold for different cost settings. Precision Figure 2: The precision </context>
</contexts>
<marker>NIST, 2006</marker>
<rawString>NIST. 2006. The spoken term detection (STD) 2006 evaluation plan http://www.nist.gov/speech/tests/std/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Parlak</author>
<author>M Sarac¸lar</author>
</authors>
<title>Spoken term detection for Turkish broadcast news.</title>
<date>2008</date>
<booktitle>In Proc. ICASSP,</booktitle>
<pages>5244--5247</pages>
<marker>Parlak, Sarac¸lar, 2008</marker>
<rawString>S. Parlak and M. Sarac¸lar. 2008. Spoken term detection for Turkish broadcast news. In Proc. ICASSP, pages 5244–5247, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Soltau</author>
<author>G Saon</author>
<author>D Povey</author>
<author>L Mangu</author>
<author>J Kuo</author>
<author>M Omar</author>
<author>G Zweig</author>
</authors>
<date>2007</date>
<booktitle>The IBM 2006 GALE Arabic ASR system. In Proc. ICASSP 2007,</booktitle>
<location>Honolulu, HI, USA.</location>
<contexts>
<context position="7827" citStr="Soltau et al., 2007" startWordPosition="1277" endWordPosition="1280">weights correspond to class priors. Then, the Minimum Bayes Risk (MBR) detection threshold for x is given as: λ1 + log(λ0/λ1) + log(P(c0)/P(c1)) + log α . λ0 + λ1 3 Experiments 3.1 Data and Application Turkish Radio and Television Channel 2 (TRT2) broadcasts a news program for the hearing impaired which contains speech as well as signs. We have collected 11 hours (total speech time) of test material from this broadcast and performed our experiments on this data with a total of 10229 single word queries extracted from the reference transcriptions. We used IBM Attila speech recognition toolkit (Soltau et al., 2007) at the back-end of our system to produce recognition lattices. The ASR system is trained on 100 hours of speech and transcription data collected from various TV and radio broadcasts including TRT2 hearing impaired news, and a general text corpus of size 100 million words. Our application uses the speech modality to retrieve the signs corresponding to a text query. Retrieved results are displayed as video demonstrations to support the learning of sign language. Since the application acts like an interactive dictionary of sign language, primary concern is to return correct results no matter how</context>
</contexts>
<marker>Soltau, Saon, Povey, Mangu, Kuo, Omar, Zweig, 2007</marker>
<rawString>H. Soltau, G. Saon, D. Povey, L. Mangu, J. Kuo, M. Omar, and G. Zweig. 2007. The IBM 2006 GALE Arabic ASR system. In Proc. ICASSP 2007, Honolulu, HI, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Vergyri</author>
<author>I Shafran</author>
<author>A Stolcke</author>
<author>R R Gadde</author>
<author>M Akbacak</author>
<author>B Roark</author>
<author>W Wang</author>
</authors>
<title>spoken term detection system.</title>
<date>2007</date>
<booktitle>The SRI/OGI</booktitle>
<pages>2393--2396</pages>
<contexts>
<context position="2836" citStr="Vergyri et al., 2007" startWordPosition="439" endWordPosition="442">of recognition errors by incorporating alternative transcriptions in a probabilistic framework. A system using lattices can also return the posterior probability of a query as a detection score. Various operating points can be obtained by comparing the detection scores to a threshold. In addition to using a global detection threshold, choosing term specific thresholds that optimize the STD evaluation metric known as Term-Weighted Value (TWV) was recently proposed (Miller et al., 2007). A similar approach which trains a neural network mapping various features to the target classes was used in (Vergyri et al., 2007). The rest of the paper is organized as follows. In Section 2 we explain the methods used for spoken term detection. These include the indexing and search framework based on WFSTs and the detection framework based on posterior score distributions. In Section 3 we describe our experimental setup and present the results. Finally, in Section 4 we summarize our contributions and discuss possible future directions. 269 Proceedings of NAACL HLT 2009: Short Papers, pages 269–272, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics 2 Methods The STD system used in this study</context>
</contexts>
<marker>Vergyri, Shafran, Stolcke, Gadde, Akbacak, Roark, Wang, 2007</marker>
<rawString>D. Vergyri, I. Shafran, A. Stolcke, R. R. Gadde, M. Akbacak, B. Roark, and W. Wang. 2007. The SRI/OGI 2006 spoken term detection system. In Proc. Interspeech, pages 2393–2396, August.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>