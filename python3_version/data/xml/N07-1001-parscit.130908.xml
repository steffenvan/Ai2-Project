<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001233">
<title confidence="0.992851">
Exploiting acoustic and syntactic features for prosody labeling in
a maximum entropy framework
</title>
<author confidence="0.987995">
Vivek Rangarajan, Shrikanth Narayanan Srinivas Bangalore
</author>
<affiliation confidence="0.857784">
Speech Analysis and Interpretation Laboratory AT&amp;T Research Labs
University of Southern California 180 Park Avenue
Viterbi School of Electrical Engineering Florham Park, NJ 07932, U.S.A.
</affiliation>
<email confidence="0.996939">
vrangara@usc.edu,shri@sipi.usc.edu srini@research.att.com
</email>
<sectionHeader confidence="0.980175" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999303631578948">
In this paper we describe an automatic
prosody labeling framework that exploits
both language and speech information.
We model the syntactic-prosodic informa-
tion with a maximum entropy model that
achieves an accuracy of 85.2% and 91.5%
for pitch accent and boundary tone la-
beling on the Boston University Radio
News corpus. We model the acoustic-
prosodic stream with two different mod-
els, one a maximum entropy model and
the other a traditional HMM. We finally
couple the syntactic-prosodic and acoustic-
prosodic components to achieve signifi-
cantly improved pitch accent and bound-
ary tone classification accuracies of 86.0%
and 93.1% respectively. Similar experimen-
tal results are also reported on Boston Di-
rections corpus.
</bodyText>
<sectionHeader confidence="0.996301" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9998776">
Prosody refers to intonation, rhythm and lexical
stress patterns of spoken language that convey lin-
guistic and paralinguistic information such as em-
phasis, intent, attitude and emotion of a speaker.
Prosodic information associated with a unit of
speech, say, syllable, word, phrase or clause, influ-
ence all the segments of the unit in an utterance. In
this sense they are also referred to as suprasegmen-
tals (Lehiste, 1970). Prosody in general is highly
dependent on individual speaker style, gender, di-
alect and other phonological factors. The difficulty in
reliably characterizing suprasegmental information
present in speech has resulted in symbolic and para-
meteric prosody labeling standards like ToBI (Tones
and Break Indices) (Silverman et al., 1992) and Tilt
model (Taylor, 1998) respectively.
Prosody in spoken language can be characterized
through acoustic features or lexical features or both.
Acoustic correlates of duration, intensity and pitch,
like syllable nuclei duration, short time energy and
</bodyText>
<page confidence="0.851442">
1
</page>
<bodyText confidence="0.999916733333334">
fundamental frequency (f0) are some acoustic fea-
tures that are perceived to confer prosodic promi-
nence or stress in English. Lexical features like parts-
of-speech, syllable nuclei identity, syllable stress of
neighboring words have also demonstrated high de-
gree of discriminatory evidence in prosody detection
tasks.
The interplay between acoustic and lexical fea-
tures in characterizing prosodic events has been suc-
cessfully exploited in text-to-speech synthesis (Bu-
lyko and Ostendorf, 2001; Ma et al., 2003), speech
recognition (Hasegawa-Johnson et al., 2005) and
speech understanding (Wightman and Ostendorf,
1994). Text-to-speech synthesis relies on lexical fea-
tures derived predominantly from the input text to
synthesize natural sounding speech with appropri-
ate prosody. In contrast, output of a typical auto-
matic speech recognition (ASR) system is noisy and
hence, the acoustic features are more useful in pre-
dicting prosody than the hypothesized lexical tran-
script which may be erroneous. Speech understand-
ing systems model both the lexical and acoustic fea-
tures at the output of an ASR to improve natural
language understanding. Another source of renewed
interest has come from spoken language translation
(N6th et al., 2000; Agiiero et al., 2006). A pre-
requisite for all these applications is accurate prosody
detection, the topic of the present work.
In this paper, we describe our framework for build-
ing an automatic prosody labeler for English. We
report results on the Boston University (BU) Ra-
dio Speech Corpus (Ostendorf et al., 1995) and
Boston Directions Corpus (BDC) (Hirschberg and
Nakatani, 1996), two publicly available speech cor-
pora with manual ToBI annotations intended for ex-
periments in automatic prosody labeling. We con-
dition prosody not only on word strings and their
parts-of-speech but also on richer syntactic informa-
tion encapsulated in the form of Supertags (Banga-
lore and Joshi, 1999). We propose a maximum en-
tropy modeling framework for the syntactic features.
We model the acoustic-prosodic stream with two dif-
ferent models, a maximum entropy model and a more
traditional hidden markov model (HMM). In an au-
tomatic prosody labeling task, one is essentially try-
</bodyText>
<note confidence="0.829403">
Proceedings of NAACL HLT 2007, pages 1–8,
Rochester, NY, April 2007. c�2007 Association for Computational Linguistics
</note>
<bodyText confidence="0.999591888888889">
ing to predict the correct prosody label sequence for
a given utterance and a maximum entropy model of-
fers an elegant solution to this learning problem. The
framework is also robust in the selection of discrim-
inative features for the classification problem. So,
given a word sequence W = {w1, · · · ,wn} and a set
of acoustic-prosodic features A = {o1, · · · , oT}, the
best prosodic label sequence L* = {l1, l2, · · · , ln} is
obtained as follows,
</bodyText>
<equation confidence="0.998979166666667">
L* = arg max P(L|A, W) (1)
L
= arg max P(L|W).P(A|L,W) (2)
L
r.i arg max P(L|4&apos;(W)).P(A|L,W) (3)
L
</equation>
<bodyText confidence="0.999967277777778">
where 4)(W) is the syntactic feature encoding of the
word sequence W. The first term in Equation (3)
corresponds to the probability obtained through our
maximum entropy syntactic model. The second term
in Equation (3), computed by an HMM corresponds
to the probability of the acoustic data stream which
is assumed to be dependent only on the prosodic la-
bel sequence.
The paper is organized as follows. In section 2
we describe related work in automatic prosody la-
beling followed by a description of the data used in
our experiments in section 3. We present prosody
prediction results from off-the-shelf synthesizers in
section 4. Section 5 details our proposed maximum
entropy syntactic-prosodic model for prosody label-
ing. In section 6, we describe our acoustic-prosodic
model and discuss our results in section 7. We finally
conclude in section 8 with directions for future work.
</bodyText>
<sectionHeader confidence="0.996762" genericHeader="introduction">
2 Related work
</sectionHeader>
<bodyText confidence="0.999979666666667">
Automatic prosody labeling has been an active re-
search topic for over a decade. Wightman and Os-
tendorf (Wightman and Ostendorf, 1994) developed
a decision-tree algorithm for labeling prosodic pat-
terns. The algorithm detected phrasal prominence
and boundary tones at the syllable level. Bulyko
and Ostendorf (Bulyko and Ostendorf, 2001) used
a prosody prediction module to synthesize natural
speech with appropriate prosody. Verbmobil (Noth
et al., 2000) incorporated prosodic labeling into a
translation framework for improved linguistic analy-
sis and speech understanding.
Prosody has typically been represented either sym-
bolically, e.g., ToBI (Silverman et al., 1992) or
parametrically, e.g., Tilt Intonation Model (Tay-
lor, 1998). Parametric approaches either restrict
the variants of prosody by definition or automati-
cally learn prosodic patterns from data (Agiiero et
al., 2006). The BU corpus is a widely used cor-
pus with symbolic representation of prosody. The
hand-labeled ToBI annotations make this an attrac-
tive corpus to perform prosody labeling experiments.
The main drawback of this corpus is that it com-
prises only read speech. Prosody labeling on sponta-
neous speech corpora like Boston Directions corpus
(BDC), Switchboard (SWBD) has garnered atten-
tion in (Hirschberg and Nakatani, 1996; Gregory and
Altun, 2004).
Automatic prosody labeling has been achieved
through various machine learning techniques, such
as decision trees (Hirschberg, 1993; Wightman and
Ostendorf, 1994; Ma et al., 2003), rule-based sys-
tems (Shimei and McKeown, 1999), bagging and
boosting on CART (Sun, 2002), hidden markov
models (Conkie et al., 1999), neural networks
(Hasegawa-Johnson et al., 2005),maximum-entropy
models (Brenier et al., 2005) and conditional ran-
dom fields (Gregory and Altun, 2004).
Prosody labeling of the BU corpus has been re-
ported in many studies (Hirschberg, 1993; Hasegawa-
Johnson et al., 2005; Ananthakrishnan and
Narayanan, 2005). Hirschberg (Hirschberg, 1993)
used a decision-tree based system that achieved
82.4% speaker dependent accent labeling accuracy
at the word level on the BU corpus using lexical fea-
tures. (Ross and Ostendorf, 1996) also used an ap-
proach similar to (Wightman and Ostendorf, 1994)
to predict prosody for a TTS system from lexical fea-
tures. Pitch accent accuracy at the word-level was
reported to be 82.5% and syllable-level accent accu-
racy was 80.2%. (Hasegawa-Johnson et al., 2005)
proposed a neural network based syntactic-prosodic
model and a gaussian mixture model based acoustic-
prosodic model to predict accent and boundary tones
on the BU corpus that achieved 84.2% accuracy in
accent prediction and 93.0% accuracy in intonational
boundary prediction. With syntactic information
alone they achieved 82.7% and 90.1% for accent and
boundary prediction, respectively. (Ananthakrish-
nan and Narayanan, 2005) modeled the acoustic-
prosodic information using a coupled hidden markov
model that modeled the asynchrony between the
acoustic streams. The pitch accent and boundary
tone detection accuracy at the syllable level were
75% and 88% respectively. Our proposed maximum
entropy syntactic model outperforms previous work.
On the BU corpus, with syntactic information alone
we achieve pitch accent and boundary tone accuracy
of 85.2% and 91.5% on the same training and test
sets used in (Chen et al., 2004; Hasegawa-Johnson
et al., 2005). Further, the coupled model with both
acoustic and syntactic information results in accura-
cies of 86.0% and 93.1% respectively. On the BDC
corpus, we achieve pitch accent and boundary tone
accuracies of 79.8% and 90.3%.
</bodyText>
<sectionHeader confidence="0.984756" genericHeader="method">
3 Data
</sectionHeader>
<bodyText confidence="0.9972835">
The BU corpus consists of broadcast news stories in-
cluding original radio broadcasts and laboratory sim-
</bodyText>
<page confidence="0.99342">
2
</page>
<table confidence="0.999484">
Corpus statistics BU BDC
f2b f1a m1b m2b h1 h2 h3 h4
# Utterances 165 69 72 51 10 9 9 9
# words (w/o punc) 12608 3681 5058 3608 2234 4127 1456 3008
# pitch accents 6874 2099 2706 2016 1006 1573 678 1333
# boundary tones (w IP) 3916 1059 1282 1023 498 727 361 333
# boundary tones (w/o IP) 2793 684 771 652 308 428 245 216
</table>
<tableCaption confidence="0.999806">
Table 1: BU and BDC dataset used in experiments
</tableCaption>
<bodyText confidence="0.98442605">
ulations recorded from seven FM radio announcers.
The corpus is annotated with orthographic transcrip-
tion, automatically generated and hand-corrected
part-of-speech tags and automatic phone alignments.
A subset of the corpus is also hand annotated with
ToBI labels. In particular, the experiments in this
paper are carried out on 4 speakers similar to (Chen
et al., 2004), 2 male and 2 female referred to here-
after as m1b, m2b, f1a and f2b. The BDC corpus is
made up of elicited monologues produced by subjects
who were instructed to perform a series of direction-
giving tasks. Both spontaneous and read versions of
the speech are available for four speakers h1, h2, h3
and h4 with hand-annotated ToBI labels and auto-
matic phone alignments, similar to the BU corpus.
Table 1 shows some of the statistics of the speakers
in the BU and BDC corpora.
In Table 1, the pitch accent and boundary tone
statistics are obtained by decomposing the ToBI la-
bels into binary classes using the mapping shown in
</bodyText>
<tableCaption confidence="0.967647">
Table 2.
</tableCaption>
<table confidence="0.999840923076923">
BU Labels Intermediate Mapping Coarse Mapping
H*,!H* Single Accent accent
L*
*,*?,X*?
H+!H*,L+H*,L+!H* Bitonal Accent
L*+!H,L*+H
L-L%,!H-L%,H-L% Final Boundary tone btone
H-H%
L-H%
%?,X%?,%H
L-,H-,!H- Intermediate Phrase (IP) boundary
-X?,-?
&lt;,&gt;,no label none none
</table>
<tableCaption confidence="0.999524">
Table 2: ToBI label mapping used in experiments
</tableCaption>
<bodyText confidence="0.998544818181818">
In all our prosody labeling experiments we adopt
a leave-one-out speaker validation similar to the
method in (Hasegawa-Johnson et al., 2005) for the
four speakers with data from one speaker for testing
and from the other three for training. For the BU
corpus, f2b speaker was always used in the training
set since it contains the most data. In addition to
performing experiments on all the utterances in BU
corpus, we also perform identical experiments on the
train and test sets reported in (Chen et al., 2004)
which is referred to as Hasegawa-Johnson et al. set.
</bodyText>
<sectionHeader confidence="0.990932" genericHeader="method">
4 Baseline Experiments
</sectionHeader>
<bodyText confidence="0.933104025641026">
We present three baseline experiments. One is sim-
ply based on chance where the majority class label is
predicted. The second is a baseline only for pitch ac-
cents derived from the lexical stress obtained through
look-up from a pronunciation lexicon labeled with
stress. Finally, the third and more concrete base-
line is obtained through prosody detection in current
speech synthesis systems.
4.1 Prosody labels derived from lexical
stress
Pitch accents are usually carried by the stressed syl-
lable in a particular word. Lexicons with phonetic
transcription and lexical stress are available in many
languages. Hence, one can use these lexical stress
markers within the syllables and evaluate the corre-
lation with pitch accents. Eventhough the lexicon
has a closed vocabulary, letter-to-sound rules can be
derived from it for unseen words. For each word car-
rying a pitch accent, we find the particular syllable
where the pitch accent occurs from the manual anno-
tation. For the same syllable, we predict pitch accent
based on the presence or absence of a lexical stress
marker in the phonetic transcription. The results are
presented in Table 3.
4.2 Prosody labeling with Festival and
AT&amp;T Natural Voices® Speech
Synthesizer
Festival (Black et al., 1998) and AT&amp;T Natural
Voices® (NV) speech synthesizer (att, ) are two
publicly available speech synthesizers that have a
prosody prediction module available. We performed
automatic prosody labeling using the two synthesiz-
ers to get a baseline.
4.2.1 AT&amp;T Natural Voices® Speech
Synthesizer
The AT&amp;T NV® speech synthesizer is a half
phone speech synthesizer. The toolkit accepts
an input text utterance and predicts appropriate
ToBI pitch accent and boundary tones for each of
</bodyText>
<page confidence="0.990352">
3
</page>
<table confidence="0.999560454545455">
Corpus Speaker Set Prediction Module Pitch accent Boundary tone
Chance Accuracy Chance Accuracy
Lexical stress 54.33 72.64 - -
Entire Set AT&amp;T Natural Voices 54.33 81.51 81.14 89.10
Festival 54.33 69.55 81.14 89.54
Lexical stress 56.53 74.10 - -
BU Hasegawa-Johnson et al. set AT&amp;T Natural Voices 56.53 81.73 82.88 89.67
Festival 56.53 68.65 82.88 90.21
Lexical stress 57.60 67.42 - -
BDC Entire Set AT&amp;T Natural Voices 57.60 68.49 88.90 84.90
Festival 57.60 64.94 88.90 85.17
</table>
<tableCaption confidence="0.999788">
Table 3: Classification results of pitch accents and boundary tones (in %) using Festival and AT&amp;T NV® synthesizer
</tableCaption>
<bodyText confidence="0.998521555555556">
the selected units (in this case, a pair of phones)
from the database. We reverse mapped the se-
lected half phone units to words, thus obtaining
the ToBI labels for each word in the input utter-
ance. The toolkit uses a rule-based procedure to
predict the ToBI labels from lexical information.
The pitch accent labels predicted by the toolkit are
Laccent a {H∗, L∗, none} and the boundary tones
are Lbtone a {L-L%, H-H%, L-H%, none}.
</bodyText>
<subsubsectionHeader confidence="0.953008">
4.2.2 Festival Speech Synthesizer
</subsubsectionHeader>
<bodyText confidence="0.981697">
Festival (Black et al., 1998) is an open-source unit
selection speech synthesizer. The toolkit includes
a CART-based prediction system that can predict
ToBI pitch accents and boundary tones for the input
text utterance. The pitch accent labels predicted by
the toolkit are Laccent a {H∗, L + H∗, !H∗, none}
and the boundary tones are
Lbtone a {L-L%, H-H%, L-H%, none}. The
prosody labeling results obtained through both the
speech synthesis engines are presented in Table
3. The chance column in Table 3 is obtained by
predicting the most frequent label in the data set.
In the next sections, we describe our proposed
maximum entropy based syntactic model and HMM
based acoustic-prosodic model for automatic prosody
labeling.
</bodyText>
<sectionHeader confidence="0.999249" genericHeader="method">
5 Syntactic-prosodic Model
</sectionHeader>
<bodyText confidence="0.997025394736842">
We propose a maximum entropy approach to model
the words, syntactic information and the prosodic
labels as a sequence. We model the prediction prob-
lem as a classification task as follows: given a se-
quence of words wi in a sentence W = {w1, · · · , wn}
and a prosodic label vocabulary (li a L), we need
to predict the best prosodic label sequence L* =
{l1, l2, · · · , ln}. We approximate the conditional
probability to be within a bounded n-gram context.
Thus,
where W = {w1, · · · , wn} is the word sequence and
T = {t1, · · · , tn}, S = {s1, · · · , sn} are the corre-
sponding part-of-speech and additional syntactic in-
formation sequences. The variable k controls the
context.
The BU corpus is automatically labeled (and
hand-corrected) with part-of-speech (POS) tags.
The POS inventory is the same as the Penn treebank
which includes 47 POS tags: 22 open class categories,
14 closed class categories and 11 punctuation labels.
We also automatically tagged the utterances using
the AT&amp;T POS tagger. The POS tags were mapped
to function and content word categories 1 which was
added as a discrete feature. In addition to the POS
tags, we also annotate the utterance with Supertags
(Bangalore and Joshi, 1999). Supertags encapsulate
predicate-argument information in a local structure.
They are composed with each other using substi-
tution and adjunction operations of Tree-Adjoining
Grammars (TAGs) to derive a dependency analysis
of an utterance and its predicate-argument structure.
Even though there is a potential to exploit the de-
pendency structure between supertags and prosody
labels as demonstrated in (Hirschberg and Rambow,
2001), for this paper we use only the supertag labels.
Finally, we generate one feature vector ((D) for
each word in the data set (with local contextual fea-
tures). The best prosodic label sequence is then,
</bodyText>
<equation confidence="0.994411666666667">
n
L* = arg max P(li|`b) (6)
L i
</equation>
<bodyText confidence="0.999847285714286">
To estimate the conditional distribution P(li|(b) we
use the general technique of choosing the maximum
entropy (maxent) distribution that estimates the av-
erage of each feature over the training data (Berger
et al., 1996). This can be written in terms of Gibbs
distribution parameterized with weights A, where V
is the size of the prosodic label set. Hence,
</bodyText>
<equation confidence="0.800272545454546">
L* = arg max
L
P(L|W, T, S) (4)
exji.4b
P(li|(b) =
E_(7)
��1 e��i.�
n
i
≈ arg max i+k i+k i+k &apos;function and content word features were obtained
L p(li|wi−k,ti−k,si−k) (5) through a look-up table based on POS
</equation>
<page confidence="0.618607">
4
</page>
<table confidence="0.9973731">
Corpus Speaker Set Syntactic features k=3
accent btone
BU Entire Set correct POS tags 84.75 91.39
AT&amp;T POS + supertags 84.59 91.34
Joint Model (w AT&amp;T POS + supertags) 84.60 91.36
Hasegawa-Johnson et al. set correct POS tags 85.22 91.33
AT&amp;T POS + supertags 84.95 91.21
Joint Model (w AT&amp;T POS + supertags) 84.78 91.54
BDC Entire Set AT&amp;T POS + supertags 79.81 90.28
Joint Model (w AT&amp;T POS + supertags) 79.57 89.76
</table>
<tableCaption confidence="0.999817">
Table 4: Classification results (%) of pitch accents and boundary tones for different syntactic representation (k = 3)
</tableCaption>
<bodyText confidence="0.988534923076923">
We use the machine learning toolkit LLAMA
(Haffner, 2006) to estimate the conditional distribu-
tion using maxent. LLAMA encodes multiclass max-
ent as binary maxent to increase the training speed
and to scale the method to large data sets. Each of
the V classes in the label set G is encoded as a bit
vector such that, in the vector for class i, the ith bit
is one and all other bits are zero. Finally, V one-
versus-other binary classifiers are used as follows.
where AV is the parameter vector for the anti-label y.
To compute P(li|ib), we use the class independence
assumption and require that yi = 1 and for all j =�
i, yj = 0.
</bodyText>
<equation confidence="0.870360333333333">
V
P(li|�) = P(yi|(b) ri P(yj|`D) (9)
j#i
</equation>
<subsectionHeader confidence="0.822583">
5.1 Joint Modeling of Accents and
Boundary Tones
</subsectionHeader>
<bodyText confidence="0.999912733333334">
Prosodic prominence and phrasing can also be
viewed as joint events occurring simultaneously. Pre-
vious work by (Wightman and Ostendorf, 1994) sug-
gests that a joint labeling approach may be more
beneficial in prosody labeling. In this scenario,
we treat each word to have one of the four labels
li e G = {accent-btone, accent-none, none-
btone, none-none}. We trained the classifier on
the joint labels and then computed the error rates for
individual classes. The results of prosody prediction
using the set of syntactic-prosodic features for k = 3
is shown in Table 4. The joint modeling approach
provides a marginal improvement in the boundary
tone prediction but is slightly worse for pitch accent
prediction.
</bodyText>
<subsectionHeader confidence="0.964277">
5.2 Supertagger performance on
Intermediate Phrase boundaries
</subsectionHeader>
<bodyText confidence="0.998533176470588">
Perceptual experiments have indicated that inter-
annotator agreement for ToBI intermediate phrase
boundaries is very low compared to full-intonational
boundaries (Syrdal and McGory, 2000). Interme-
diate phrasing is important in TTS applications to
synthesize appropriate short pauses to make the ut-
terance sound natural. The significance of syntactic
features in the boundary tone prediction prompted
us to examine the effect of predicting intermediate
phrase boundaries in isolation. It is intuitive to ex-
pect supertags to perform well in this task as they
essentially form a local dependency analysis on an
utterance and provide an encoding of the syntactic
phrasal information. We performed this task as a
three way classification where li e G = {btone, ip,
none}. The results of the classifier on IPs is shown
in Table 5.
</bodyText>
<table confidence="0.998867571428571">
Model Syntactic features IP accuracy
correct POS tags 83.25
k=2 (bigram context) AT&amp;T POS tags 83.32
supertags 83.37
correct POS tags 83.30
k=3 (trigram context) AT&amp;T POS tags 83.46
supertags 83.74
</table>
<tableCaption confidence="0.979628">
Table 5: Accuracy (in %) obtained by leave-one out
speaker validation using IPs as a separate class on
entire speaker set
</tableCaption>
<sectionHeader confidence="0.99613" genericHeader="method">
6 Acoustic-prosodic model
</sectionHeader>
<bodyText confidence="0.99999">
We propose two approaches to modeling the
acoustic-prosodic features for prosody prediction.
First, we propose a maximum entropy framework
similar to the syntactic model where we quantize
the acoustic features and model them as discrete
sequences. Second, we use a more traditional ap-
proach where we train continuous observation den-
sity HMMs to represent pitch accents and bound-
ary tones. We first describe the features used in the
acoustic modeling followed by a more detailed de-
scription of the acoustic-prosodic model.
</bodyText>
<subsectionHeader confidence="0.972053">
6.1 Acoustic-prosodic features
</subsectionHeader>
<bodyText confidence="0.999041333333333">
The BU corpus contains the corresponding acoustic-
prosodic feature file for each utterance. The f0, RMS
energy (e) of the utterance along with features for
</bodyText>
<equation confidence="0.99462375">
eλ,.4b
P(y|(b) = 1 − P(9|�) =
(8)
eλ,.4D + eλv.4b
</equation>
<page confidence="0.982079">
5
</page>
<table confidence="0.983000714285714">
Corpus Speaker Set Model Pitch accent Boundary tone
Acoustics Acoustics+syntax Acoustics Acoustics+syntax
BU Entire Set Maxent acoustic model 80.09 84.53 84.10 91.56
HMM acoustic model 70.58 85.13 71.28 92.91
Hasegawa-Johnson et al. set Maxent acoustic model 80.12 84.84 82.70 91.76
HMM acoustic model 71.42 86.01 73.43 93.09
BDC Entire Set Maxent acoustic model 74.51 78.64 83.53 90.49
</table>
<tableCaption confidence="0.995051">
Table 6: Classification results of pitch accents and boundary tones (in %) with acoustics only and acoustics+syntax
using both our models
</tableCaption>
<bodyText confidence="0.975743818181818">
distinction between voiced/unvoiced segment, cross-
correlation values at estimated f0 value and ratio of
first two cross correlation values are computed over
10 msec frame intervals. In our experiments, we use
these values rather than computing them explicitly
which is straightforward with most audio toolkits.
Both the energy and the f0 levels were normalized
with speaker specific means and variances. Delta
and acceleration coefficients were also computed for
each frame. The final feature vector is 6-dimensional
comprising of f0, Af0, A2f0, e, De, A2e per frame.
</bodyText>
<subsectionHeader confidence="0.8550725">
6.2 Maximum Entropy acoustic-prosodic
model
</subsectionHeader>
<bodyText confidence="0.999905115384615">
We propose a maximum entropy modeling frame-
work to model the continuous acoustic-prosodic ob-
servation sequence as a discrete sequence through
the means of quantization. The quantized acoustic
stream is then used as a feature vector and the condi-
tional probabilities are approximated by an n-gram
model. This is equivalent to reducing the vocabu-
lary of the acoustic-prosodic features and hence of-
fers better estimates of the conditional probabilities.
Such an n-gram model of quantized continuous fea-
tures is similar to representing the set of features
with a linear fit as done in the tilt intonational model
(Taylor, 1998).
The quantized acoustic-prosodic feature stream is
modeled with a maxent acoustic-prosodic model sim-
ilar to the one described in section 5. Finally, we ap-
pend the syntactic and acoustic features to model the
combined stream with the maxent acoustic-syntactic
model, where the objective criterion for maximiza-
tion is Equation (1). The pitch accent and bound-
ary tone prediction accuracies for quantization per-
formed by considering only the first decimal place
is reported in Table 6. As expected, we found the
classification accuracy to drop with increasing num-
ber of bins used in the quantization due to the small
amount of training data.
</bodyText>
<subsectionHeader confidence="0.997505">
6.3 HMM acoustic-prosodic model
</subsectionHeader>
<bodyText confidence="0.999987827586207">
We also investigated the traditional HMM approach
to model the high variability exhibited by the
acoustic-prosodic features. First, we trained sepa-
rate context independent single state Gaussian mix-
ture density HMMs for pitch accents and boundary
tones in a generative framework. The label sequence
was decoded using the viterbi algorithm. Next, we
trained HMMs with 3 state left-to-right topology
with uniform segmentation. The segmentations need
to be uniform due to lack of an acoustic-prosodic
model trained on the features pertinent to our task
to obtain forced segmentation.
The final label sequence using the maximum en-
tropy syntactic-prosodic model and the HMM based
acoustic-prosodic model was obtained by combin-
ing the syntactic and acoustic probabilities shown in
Equation (3). The syntactic-prosodic maxent model
outputs a posterior probability for each class per
word. We formed a lattice out of this structure and
composed it with the lattice generated by the HMM
acoustic-prosodic model. The best path was chosen
from the composed lattice through a Viterbi search.
The acoustic-prosodic probability P(AIL,W) was
raised by a power of y to adjust the weighting be-
tween the acoustic and syntactic model. The value of
y was chosen as 0.008 and 0.015 for pitch accent and
boundary tone respectively, by tuning on the train-
ing set. The results of the acoustic-prosodic model
and the coupled model are shown in Table 6.
</bodyText>
<sectionHeader confidence="0.997463" genericHeader="method">
7 Discussion
</sectionHeader>
<bodyText confidence="0.999977459016394">
The baseline experiment with lexical stress obtained
from a pronunciation lexicon for prediction of pitch
accent yields substantially higher accuracy than
chance. This could be particularly useful in resource-
limited languages where prosody labels are usually
not available but one has access to a reasonable lex-
icon with lexical stress markers. Off-the-shelf speech
synthesizers like Festival and AT&amp;T speech synthe-
sizer perform reasonably well in pitch accent and
boundary tone prediction. AT&amp;T speech synthesizer
performs better than Festival in pitch accent predic-
tion and the latter performs better in boundary tone
prediction. This can be attributed to better rules
in the AT&amp;T synthesizer for pitch accent prediction.
Boundary tones are usually highly correlated with
punctuation and Festival seems to capture this well.
However, both these synthesizers generate a high de-
gree of false alarms.
Our syntactic-prosodic maximum entropy model
proposed in section 5 outperforms previously re-
ported results on pitch accent and boundary tone
classification. Much of the gain comes from the ro-
bustness of the maximum entropy modeling in cap-
turing the uncertainty in the classification task. Con-
sidering the inter-annotator agreement for ToBI la-
bels is only about 81% for pitch accents and 93% for
boundary tones, the maximum entropy framework is
able to capture the uncertainty present in manual an-
notation. The supertag feature offers additional dis-
criminative information over the part-of-speech tags
(also as shown by (Hirschberg and Rambow, 2001).
The maximum entropy acoustic-prosodic model
discussed in section 6.2 performs reasonably well in
isolation. This is a simple method and the quantiza-
tion resolution can be adjusted based on the amount
of data available for training. However, the model
does not perform as well when combined with the
syntactic features. We conjecture that the gener-
alization provided by the acoustic HMM model is
complementary to that provided by the maximum
entropy model, resulting in better accuracy when
combined together as compared to that of a maxent-
based acoustic and syntactic model.
The weighted maximum entropy syntactic-
prosodic model and HMM acoustic-prosodic model
performs the best in pitch accent and boundary tone
classification. The classification accuracies are as
good as the inter-annotator agreement for the ToBI
labels. Our HMM acoustic-prosodic model is a gen-
erative model and does not assume the knowledge
of word boundaries in predicting the prosodic labels
as in most approaches (Hirschberg, 1993; Wightman
and Ostendorf, 1994; Hasegawa-Johnson et al.,
2005). This makes it possible to have true parallel
prosody prediction during speech recognition. The
weighted approach also offers flexibility in prosody
labeling for either speech synthesis or speech recog-
nition. While the syntactic-prosodic model would
be more discriminative for speech synthesis, the
acoustic-prosodic model is more appropriate for
speech recognition.
</bodyText>
<sectionHeader confidence="0.990127" genericHeader="conclusions">
8 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999990461538461">
In this paper, we described a maximum entropy
modeling framework for automatic prosody label-
ing. We presented two schemes for prosody label-
ing that utilize the acoustic and syntactic informa-
tion from the input utterance, a maximum entropy
model that models the acoustic-syntactic informa-
tion as a sequence and the other that combines the
maximum entropy syntactic-prosodic model and a
HMM based acoustic-prosodic model. We also used
enriched syntactic information in the form of su-
pertags in addition to POS tags. The supertags
provide an improvement in both the pitch accent
and boundary tone classification. Especially, in the
case where the input utterance is automatically POS
tagged (and not hand-corrected), supertags provide
a marginal but definite improvement in prosody la-
beling. The maximum entropy syntactic-prosodic
model alone resulted in pitch accent and bound-
ary tone accuracies of 85.2% and 91.5% on training
and test sets identical to (Chen et al., 2004). As
far as we know, these are the best results on the
BU corpus using syntactic information alone and a
train-test split that does not contain the same speak-
ers. The acoustic-syntactic maximum entropy model
performs better than its syntactic-prosodic counter-
part for the boundary tone case but is slightly worse
for pitch accent scenario partly due to the approx-
imation involved in quantization. But these results
are still better than the baseline results from out-
of-the-box speech synthesizers. Finally, our com-
bined maximum entropy syntactic-prosodic model
and HMM acoustic-prosodic model performs the best
with pitch accent and boundary tone labeling accu-
racies of 86.0% and 93.1% respectively.
As a continuation of our work, we are incorpo-
rating our automatic prosody labeler in a speech-
to-speech translation framework. Typically, state-
of-the-art speech translation systems have a source
language recognizer followed by a machine transla-
tion system. The translated text is then synthesized
in the target language with prosody predicted from
text. In this process, some of the critical prosodic
information present in the source data is lost during
translation. With reliable prosody labeling in the
source language, one can transfer the prosody to the
target language (this is feasible for languages with
phrase level correspondence). The prosody labels by
themselves may or may not improve the translation
accuracy but they provide a framework where one
can obtain prosody labels in the target language from
the speech signal rather than depending on a lexical
prosody prediction module in the target language.
</bodyText>
<sectionHeader confidence="0.99075" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999970571428571">
We would like to thank Vincent Goffin, Stephan
Kanthak, Patrick Haffner, Enrico Bocchieri for their
support with acoustic modeling tools. We are also
thankful to Alistair Conkie, Yeon-Jun Kim, Ann
Syrdal and Julia Hirschberg for their help and guid-
ance with the synthesis components and ToBI label-
ing standard.
</bodyText>
<sectionHeader confidence="0.990936" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.6226475">
P. D. Agiiero, J. Adell, and A. Bonafonte. 2006.
Prosody generation for speech-to-speech transla-
</reference>
<page confidence="0.99283">
7
</page>
<reference confidence="0.998491846938775">
tion. In Proceedings of ICASSP, Toulouse, France,
May.
S. Ananthakrishnan and S. Narayanan. 2005. An au-
tomatic prosody recognizer using a coupled multi-
stream acoustic model and a syntactic-prosodic
language model. In In Proceedings of ICASSP,
Philadelphia, PA, March.
AT&amp;T Natural Voices speech synthesizer.
http://www.naturalvoices.att.com.
S. Bangalore and A. K. Joshi. 1999. Supertagging:
An approach to almost parsing. Computational
Linguistics, 25(2), June.
A. Berger, S. D. Pietra, and V. D. Pietra. 1996. A
maximum entropy approach to natural language
processing. Computational Linguistics, 22(1):39–
71.
A. W. Black, P. Taylor, and R. Caley.
1998. The Festival speech synthesis system.
http://festvox.org/festival.
J. M. Brenier, D. Cer, and D. Jurafsky. 2005. The
detection of emphatic words using acoustic and
lexical features. In In Proceedings of Eurospeech.
I. Bulyko and M. Ostendorf. 2001. Joint prosody
prediction and unit selection for concatenative
speech synthesis. In Proc. of ICASSP.
K. Chen, M. Hasegawa-Johnson, and A. Cohen.
2004. An automatic prosody labeling system using
ANN-based syntactic-prosodic model and GMM-
based acoustic-prosodic model. In Proceedings of
ICASSP.
A. Conkie, G. Riccardi, and R. C. Rose. 1999.
Prosody recognition from speech utterances using
acoustic and linguistic based models of prosodic
events. In Proc. Eurospeech, pages 523–526, Bu-
dapest, Hungary.
M. Gregory and Y. Altun. 2004. Using conditional
random fields to predict pitch accent in conver-
sational speech. In 42nd Annual Meeting of the
Association for Computational Linguistics (ACL).
P. Haffner. 2006. Scaling large margin classifiers for
spoken language understanding. Speech Commu-
nication, 48(iv):239–261.
M. Hasegawa-Johnson, K. Chen, J. Cole, S. Borys,
S. Kim, A. Cohen, T. Zhang, J. Choi, H. Kim,
T. Yoon, and S. Chavara. 2005. Simultaneous
recognition of words and prosody in the boston
university radio speech corpus. Speech Communi-
cation, 46:418–439.
J. Hirschberg and C. Nakatani. 1996. A prosodic
analysis of discourse segments in direction-giving
monologues. In Proceedings of the 34th confer-
ence on Association for Computational Linguis-
tics, pages 286–293.
J. Hirschberg and O. Rambow. 2001. Learning
prosodic features using a tree representation. In
Proceedings of Eurospeech, pages 1175–1180, Aal-
borg.
J. Hirschberg. 1993. Pitch accent in context: Pre-
dicting intonational prominence from text. Artifi-
cial Intelligence, 63(1-2).
I. Lehiste. 1970. Suprasegmentals. MIT Press, Cam-
bridge, MA.
X. Ma, W. Zhang, Q. Shi, W. Zhu, and L. Shen.
2003. Automatic prosody labeling using both
text and acoustic information. In Proceedings of
ICASSP, volume 1, pages 516–519, April.
E. Noth, A. Batliner, A. Kieiiling, R. Kompe, and
H. Niemann. 2000. VERBMOBIL: The use of
prosody in the linguistic components of a speech
understanding system. IEEE Transactions on
Speech and Audio processing, 8(5):519–532.
M. Ostendorf, P. J. Price, and S. Shattuck-Hufnagel.
1995. The Boston University Radio News Corpus.
Technical Report ECS-95-001, Boston University,
March.
K. Ross and M. Ostendorf. 1996. Prediction of ab-
stract prosodic labels for speech synthesis. Com-
puter Speech and Language, 10:155–185, Oct.
P. Shimei and K. McKeown. 1999. Word infor-
mativeness and automatic pitch accent modeling.
In In Proceedings of EMNLP/VLC, College Park,
Maryland.
K. Silverman, M. Beckman, J. Pitrelli, M. Osten-
dorf, C. Wightman, P. Price, J. Pierrehumbert,
and J. Hirschberg. 1992. ToBI: A standard for la-
beling English prosody. In Proceedings of ICSLP,
pages 867–870.
X. Sun. 2002. Pitch accent prediction using ensem-
ble machine learning. In Proc. of ICSLP.
A. K. Syrdal and J. McGory. 2000. Inter-transcriber
reliability of tobi prosodic labeling. In Proc. IC-
SLP, pages 235–238, Beijing, China.
P. Taylor. 1998. The tilt intonation model. In Proc.
ICSLP, volume 4, pages 1383–1386.
C. W. Wightman and M. Ostendorf. 1994. Auto-
matic labeling of prosodic patterns. IEEE Trans-
actions on Speech and Audio Processing, 2(3):469–
481.
</reference>
<page confidence="0.99844">
8
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.391962">
<title confidence="0.802135">Exploiting acoustic and syntactic features for prosody labeling a maximum entropy framework</title>
<author confidence="0.921946">Vivek Rangarajan</author>
<author confidence="0.921946">Shrikanth Narayanan Srinivas Bangalore</author>
<affiliation confidence="0.891498">Speech Analysis and Interpretation Laboratory AT&amp;T Research Labs University of Southern California 180 Park Avenue</affiliation>
<address confidence="0.93146">Viterbi School of Electrical Engineering Florham Park, NJ 07932, U.S.A.</address>
<email confidence="0.99859">vrangara@usc.edu,shri@sipi.usc.edusrini@research.att.com</email>
<abstract confidence="0.9949854">In this paper we describe an automatic prosody labeling framework that exploits both language and speech information. We model the syntactic-prosodic information with a maximum entropy model that achieves an accuracy of 85.2% and 91.5% for pitch accent and boundary tone labeling on the Boston University Radio News corpus. We model the acousticprosodic stream with two different models, one a maximum entropy model and the other a traditional HMM. We finally couple the syntactic-prosodic and acousticprosodic components to achieve significantly improved pitch accent and boundary tone classification accuracies of 86.0% and 93.1% respectively. Similar experimental results are also reported on Boston Directions corpus.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>P D Agiiero</author>
<author>J Adell</author>
<author>A Bonafonte</author>
</authors>
<title>Prosody generation for speech-to-speech translation.</title>
<date>2006</date>
<booktitle>In Proceedings of ICASSP,</booktitle>
<location>Toulouse, France,</location>
<contexts>
<context position="3410" citStr="Agiiero et al., 2006" startWordPosition="497" endWordPosition="500">ynthesis relies on lexical features derived predominantly from the input text to synthesize natural sounding speech with appropriate prosody. In contrast, output of a typical automatic speech recognition (ASR) system is noisy and hence, the acoustic features are more useful in predicting prosody than the hypothesized lexical transcript which may be erroneous. Speech understanding systems model both the lexical and acoustic features at the output of an ASR to improve natural language understanding. Another source of renewed interest has come from spoken language translation (N6th et al., 2000; Agiiero et al., 2006). A prerequisite for all these applications is accurate prosody detection, the topic of the present work. In this paper, we describe our framework for building an automatic prosody labeler for English. We report results on the Boston University (BU) Radio Speech Corpus (Ostendorf et al., 1995) and Boston Directions Corpus (BDC) (Hirschberg and Nakatani, 1996), two publicly available speech corpora with manual ToBI annotations intended for experiments in automatic prosody labeling. We condition prosody not only on word strings and their parts-of-speech but also on richer syntactic information e</context>
<context position="6796" citStr="Agiiero et al., 2006" startWordPosition="1043" endWordPosition="1046">es at the syllable level. Bulyko and Ostendorf (Bulyko and Ostendorf, 2001) used a prosody prediction module to synthesize natural speech with appropriate prosody. Verbmobil (Noth et al., 2000) incorporated prosodic labeling into a translation framework for improved linguistic analysis and speech understanding. Prosody has typically been represented either symbolically, e.g., ToBI (Silverman et al., 1992) or parametrically, e.g., Tilt Intonation Model (Taylor, 1998). Parametric approaches either restrict the variants of prosody by definition or automatically learn prosodic patterns from data (Agiiero et al., 2006). The BU corpus is a widely used corpus with symbolic representation of prosody. The hand-labeled ToBI annotations make this an attractive corpus to perform prosody labeling experiments. The main drawback of this corpus is that it comprises only read speech. Prosody labeling on spontaneous speech corpora like Boston Directions corpus (BDC), Switchboard (SWBD) has garnered attention in (Hirschberg and Nakatani, 1996; Gregory and Altun, 2004). Automatic prosody labeling has been achieved through various machine learning techniques, such as decision trees (Hirschberg, 1993; Wightman and Ostendorf</context>
</contexts>
<marker>Agiiero, Adell, Bonafonte, 2006</marker>
<rawString>P. D. Agiiero, J. Adell, and A. Bonafonte. 2006. Prosody generation for speech-to-speech translation. In Proceedings of ICASSP, Toulouse, France, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Ananthakrishnan</author>
<author>S Narayanan</author>
</authors>
<title>An automatic prosody recognizer using a coupled multistream acoustic model and a syntactic-prosodic language model.</title>
<date>2005</date>
<booktitle>In In Proceedings of ICASSP,</booktitle>
<location>Philadelphia, PA,</location>
<contexts>
<context position="7859" citStr="Ananthakrishnan and Narayanan, 2005" startWordPosition="1203" endWordPosition="1206"> and Altun, 2004). Automatic prosody labeling has been achieved through various machine learning techniques, such as decision trees (Hirschberg, 1993; Wightman and Ostendorf, 1994; Ma et al., 2003), rule-based systems (Shimei and McKeown, 1999), bagging and boosting on CART (Sun, 2002), hidden markov models (Conkie et al., 1999), neural networks (Hasegawa-Johnson et al., 2005),maximum-entropy models (Brenier et al., 2005) and conditional random fields (Gregory and Altun, 2004). Prosody labeling of the BU corpus has been reported in many studies (Hirschberg, 1993; HasegawaJohnson et al., 2005; Ananthakrishnan and Narayanan, 2005). Hirschberg (Hirschberg, 1993) used a decision-tree based system that achieved 82.4% speaker dependent accent labeling accuracy at the word level on the BU corpus using lexical features. (Ross and Ostendorf, 1996) also used an approach similar to (Wightman and Ostendorf, 1994) to predict prosody for a TTS system from lexical features. Pitch accent accuracy at the word-level was reported to be 82.5% and syllable-level accent accuracy was 80.2%. (Hasegawa-Johnson et al., 2005) proposed a neural network based syntactic-prosodic model and a gaussian mixture model based acousticprosodic model to p</context>
</contexts>
<marker>Ananthakrishnan, Narayanan, 2005</marker>
<rawString>S. Ananthakrishnan and S. Narayanan. 2005. An automatic prosody recognizer using a coupled multistream acoustic model and a syntactic-prosodic language model. In In Proceedings of ICASSP, Philadelphia, PA, March.</rawString>
</citation>
<citation valid="false">
<title>AT&amp;T Natural Voices speech synthesizer.</title>
<note>http://www.naturalvoices.att.com.</note>
<marker></marker>
<rawString>AT&amp;T Natural Voices speech synthesizer. http://www.naturalvoices.att.com.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Bangalore</author>
<author>A K Joshi</author>
</authors>
<title>Supertagging: An approach to almost parsing.</title>
<date>1999</date>
<journal>Computational Linguistics,</journal>
<volume>25</volume>
<issue>2</issue>
<contexts>
<context position="4074" citStr="Bangalore and Joshi, 1999" startWordPosition="602" endWordPosition="606">tions is accurate prosody detection, the topic of the present work. In this paper, we describe our framework for building an automatic prosody labeler for English. We report results on the Boston University (BU) Radio Speech Corpus (Ostendorf et al., 1995) and Boston Directions Corpus (BDC) (Hirschberg and Nakatani, 1996), two publicly available speech corpora with manual ToBI annotations intended for experiments in automatic prosody labeling. We condition prosody not only on word strings and their parts-of-speech but also on richer syntactic information encapsulated in the form of Supertags (Bangalore and Joshi, 1999). We propose a maximum entropy modeling framework for the syntactic features. We model the acoustic-prosodic stream with two different models, a maximum entropy model and a more traditional hidden markov model (HMM). In an automatic prosody labeling task, one is essentially tryProceedings of NAACL HLT 2007, pages 1–8, Rochester, NY, April 2007. c�2007 Association for Computational Linguistics ing to predict the correct prosody label sequence for a given utterance and a maximum entropy model offers an elegant solution to this learning problem. The framework is also robust in the selection of di</context>
<context position="16643" citStr="Bangalore and Joshi, 1999" startWordPosition="2655" endWordPosition="2658">-of-speech and additional syntactic information sequences. The variable k controls the context. The BU corpus is automatically labeled (and hand-corrected) with part-of-speech (POS) tags. The POS inventory is the same as the Penn treebank which includes 47 POS tags: 22 open class categories, 14 closed class categories and 11 punctuation labels. We also automatically tagged the utterances using the AT&amp;T POS tagger. The POS tags were mapped to function and content word categories 1 which was added as a discrete feature. In addition to the POS tags, we also annotate the utterance with Supertags (Bangalore and Joshi, 1999). Supertags encapsulate predicate-argument information in a local structure. They are composed with each other using substitution and adjunction operations of Tree-Adjoining Grammars (TAGs) to derive a dependency analysis of an utterance and its predicate-argument structure. Even though there is a potential to exploit the dependency structure between supertags and prosody labels as demonstrated in (Hirschberg and Rambow, 2001), for this paper we use only the supertag labels. Finally, we generate one feature vector ((D) for each word in the data set (with local contextual features). The best pr</context>
</contexts>
<marker>Bangalore, Joshi, 1999</marker>
<rawString>S. Bangalore and A. K. Joshi. 1999. Supertagging: An approach to almost parsing. Computational Linguistics, 25(2), June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Berger</author>
<author>S D Pietra</author>
<author>V D Pietra</author>
</authors>
<title>A maximum entropy approach to natural language processing.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<volume>22</volume>
<issue>1</issue>
<pages>71</pages>
<contexts>
<context position="17526" citStr="Berger et al., 1996" startWordPosition="2793" endWordPosition="2796">t structure. Even though there is a potential to exploit the dependency structure between supertags and prosody labels as demonstrated in (Hirschberg and Rambow, 2001), for this paper we use only the supertag labels. Finally, we generate one feature vector ((D) for each word in the data set (with local contextual features). The best prosodic label sequence is then, n L* = arg max P(li|`b) (6) L i To estimate the conditional distribution P(li|(b) we use the general technique of choosing the maximum entropy (maxent) distribution that estimates the average of each feature over the training data (Berger et al., 1996). This can be written in terms of Gibbs distribution parameterized with weights A, where V is the size of the prosodic label set. Hence, L* = arg max L P(L|W, T, S) (4) exji.4b P(li|(b) = E_(7) ��1 e��i.� n i ≈ arg max i+k i+k i+k &apos;function and content word features were obtained L p(li|wi−k,ti−k,si−k) (5) through a look-up table based on POS 4 Corpus Speaker Set Syntactic features k=3 accent btone BU Entire Set correct POS tags 84.75 91.39 AT&amp;T POS + supertags 84.59 91.34 Joint Model (w AT&amp;T POS + supertags) 84.60 91.36 Hasegawa-Johnson et al. set correct POS tags 85.22 91.33 AT&amp;T POS + super</context>
</contexts>
<marker>Berger, Pietra, Pietra, 1996</marker>
<rawString>A. Berger, S. D. Pietra, and V. D. Pietra. 1996. A maximum entropy approach to natural language processing. Computational Linguistics, 22(1):39– 71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A W Black</author>
<author>P Taylor</author>
<author>R Caley</author>
</authors>
<title>The Festival speech synthesis system.</title>
<date>1998</date>
<note>http://festvox.org/festival.</note>
<contexts>
<context position="13151" citStr="Black et al., 1998" startWordPosition="2066" endWordPosition="2069">e lexical stress markers within the syllables and evaluate the correlation with pitch accents. Eventhough the lexicon has a closed vocabulary, letter-to-sound rules can be derived from it for unseen words. For each word carrying a pitch accent, we find the particular syllable where the pitch accent occurs from the manual annotation. For the same syllable, we predict pitch accent based on the presence or absence of a lexical stress marker in the phonetic transcription. The results are presented in Table 3. 4.2 Prosody labeling with Festival and AT&amp;T Natural Voices® Speech Synthesizer Festival (Black et al., 1998) and AT&amp;T Natural Voices® (NV) speech synthesizer (att, ) are two publicly available speech synthesizers that have a prosody prediction module available. We performed automatic prosody labeling using the two synthesizers to get a baseline. 4.2.1 AT&amp;T Natural Voices® Speech Synthesizer The AT&amp;T NV® speech synthesizer is a half phone speech synthesizer. The toolkit accepts an input text utterance and predicts appropriate ToBI pitch accent and boundary tones for each of 3 Corpus Speaker Set Prediction Module Pitch accent Boundary tone Chance Accuracy Chance Accuracy Lexical stress 54.33 72.64 - -</context>
<context position="14711" citStr="Black et al., 1998" startWordPosition="2319" endWordPosition="2322">.90 85.17 Table 3: Classification results of pitch accents and boundary tones (in %) using Festival and AT&amp;T NV® synthesizer the selected units (in this case, a pair of phones) from the database. We reverse mapped the selected half phone units to words, thus obtaining the ToBI labels for each word in the input utterance. The toolkit uses a rule-based procedure to predict the ToBI labels from lexical information. The pitch accent labels predicted by the toolkit are Laccent a {H∗, L∗, none} and the boundary tones are Lbtone a {L-L%, H-H%, L-H%, none}. 4.2.2 Festival Speech Synthesizer Festival (Black et al., 1998) is an open-source unit selection speech synthesizer. The toolkit includes a CART-based prediction system that can predict ToBI pitch accents and boundary tones for the input text utterance. The pitch accent labels predicted by the toolkit are Laccent a {H∗, L + H∗, !H∗, none} and the boundary tones are Lbtone a {L-L%, H-H%, L-H%, none}. The prosody labeling results obtained through both the speech synthesis engines are presented in Table 3. The chance column in Table 3 is obtained by predicting the most frequent label in the data set. In the next sections, we describe our proposed maximum ent</context>
</contexts>
<marker>Black, Taylor, Caley, 1998</marker>
<rawString>A. W. Black, P. Taylor, and R. Caley. 1998. The Festival speech synthesis system. http://festvox.org/festival.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J M Brenier</author>
<author>D Cer</author>
<author>D Jurafsky</author>
</authors>
<title>The detection of emphatic words using acoustic and lexical features. In</title>
<date>2005</date>
<booktitle>In Proceedings of Eurospeech.</booktitle>
<contexts>
<context position="7648" citStr="Brenier et al., 2005" startWordPosition="1170" endWordPosition="1173">comprises only read speech. Prosody labeling on spontaneous speech corpora like Boston Directions corpus (BDC), Switchboard (SWBD) has garnered attention in (Hirschberg and Nakatani, 1996; Gregory and Altun, 2004). Automatic prosody labeling has been achieved through various machine learning techniques, such as decision trees (Hirschberg, 1993; Wightman and Ostendorf, 1994; Ma et al., 2003), rule-based systems (Shimei and McKeown, 1999), bagging and boosting on CART (Sun, 2002), hidden markov models (Conkie et al., 1999), neural networks (Hasegawa-Johnson et al., 2005),maximum-entropy models (Brenier et al., 2005) and conditional random fields (Gregory and Altun, 2004). Prosody labeling of the BU corpus has been reported in many studies (Hirschberg, 1993; HasegawaJohnson et al., 2005; Ananthakrishnan and Narayanan, 2005). Hirschberg (Hirschberg, 1993) used a decision-tree based system that achieved 82.4% speaker dependent accent labeling accuracy at the word level on the BU corpus using lexical features. (Ross and Ostendorf, 1996) also used an approach similar to (Wightman and Ostendorf, 1994) to predict prosody for a TTS system from lexical features. Pitch accent accuracy at the word-level was reporte</context>
</contexts>
<marker>Brenier, Cer, Jurafsky, 2005</marker>
<rawString>J. M. Brenier, D. Cer, and D. Jurafsky. 2005. The detection of emphatic words using acoustic and lexical features. In In Proceedings of Eurospeech.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Bulyko</author>
<author>M Ostendorf</author>
</authors>
<title>Joint prosody prediction and unit selection for concatenative speech synthesis.</title>
<date>2001</date>
<booktitle>In Proc. of ICASSP.</booktitle>
<contexts>
<context position="2645" citStr="Bulyko and Ostendorf, 2001" startWordPosition="379" endWordPosition="383">r lexical features or both. Acoustic correlates of duration, intensity and pitch, like syllable nuclei duration, short time energy and 1 fundamental frequency (f0) are some acoustic features that are perceived to confer prosodic prominence or stress in English. Lexical features like partsof-speech, syllable nuclei identity, syllable stress of neighboring words have also demonstrated high degree of discriminatory evidence in prosody detection tasks. The interplay between acoustic and lexical features in characterizing prosodic events has been successfully exploited in text-to-speech synthesis (Bulyko and Ostendorf, 2001; Ma et al., 2003), speech recognition (Hasegawa-Johnson et al., 2005) and speech understanding (Wightman and Ostendorf, 1994). Text-to-speech synthesis relies on lexical features derived predominantly from the input text to synthesize natural sounding speech with appropriate prosody. In contrast, output of a typical automatic speech recognition (ASR) system is noisy and hence, the acoustic features are more useful in predicting prosody than the hypothesized lexical transcript which may be erroneous. Speech understanding systems model both the lexical and acoustic features at the output of an </context>
<context position="6250" citStr="Bulyko and Ostendorf, 2001" startWordPosition="966" endWordPosition="969">nthesizers in section 4. Section 5 details our proposed maximum entropy syntactic-prosodic model for prosody labeling. In section 6, we describe our acoustic-prosodic model and discuss our results in section 7. We finally conclude in section 8 with directions for future work. 2 Related work Automatic prosody labeling has been an active research topic for over a decade. Wightman and Ostendorf (Wightman and Ostendorf, 1994) developed a decision-tree algorithm for labeling prosodic patterns. The algorithm detected phrasal prominence and boundary tones at the syllable level. Bulyko and Ostendorf (Bulyko and Ostendorf, 2001) used a prosody prediction module to synthesize natural speech with appropriate prosody. Verbmobil (Noth et al., 2000) incorporated prosodic labeling into a translation framework for improved linguistic analysis and speech understanding. Prosody has typically been represented either symbolically, e.g., ToBI (Silverman et al., 1992) or parametrically, e.g., Tilt Intonation Model (Taylor, 1998). Parametric approaches either restrict the variants of prosody by definition or automatically learn prosodic patterns from data (Agiiero et al., 2006). The BU corpus is a widely used corpus with symbolic </context>
</contexts>
<marker>Bulyko, Ostendorf, 2001</marker>
<rawString>I. Bulyko and M. Ostendorf. 2001. Joint prosody prediction and unit selection for concatenative speech synthesis. In Proc. of ICASSP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Chen</author>
<author>M Hasegawa-Johnson</author>
<author>A Cohen</author>
</authors>
<title>An automatic prosody labeling system using ANN-based syntactic-prosodic model and GMMbased acoustic-prosodic model.</title>
<date>2004</date>
<booktitle>In Proceedings of ICASSP.</booktitle>
<contexts>
<context position="9262" citStr="Chen et al., 2004" startWordPosition="1417" endWordPosition="1420">ne they achieved 82.7% and 90.1% for accent and boundary prediction, respectively. (Ananthakrishnan and Narayanan, 2005) modeled the acousticprosodic information using a coupled hidden markov model that modeled the asynchrony between the acoustic streams. The pitch accent and boundary tone detection accuracy at the syllable level were 75% and 88% respectively. Our proposed maximum entropy syntactic model outperforms previous work. On the BU corpus, with syntactic information alone we achieve pitch accent and boundary tone accuracy of 85.2% and 91.5% on the same training and test sets used in (Chen et al., 2004; Hasegawa-Johnson et al., 2005). Further, the coupled model with both acoustic and syntactic information results in accuracies of 86.0% and 93.1% respectively. On the BDC corpus, we achieve pitch accent and boundary tone accuracies of 79.8% and 90.3%. 3 Data The BU corpus consists of broadcast news stories including original radio broadcasts and laboratory sim2 Corpus statistics BU BDC f2b f1a m1b m2b h1 h2 h3 h4 # Utterances 165 69 72 51 10 9 9 9 # words (w/o punc) 12608 3681 5058 3608 2234 4127 1456 3008 # pitch accents 6874 2099 2706 2016 1006 1573 678 1333 # boundary tones (w IP) 3916 105</context>
<context position="11825" citStr="Chen et al., 2004" startWordPosition="1854" endWordPosition="1857">mediate Phrase (IP) boundary -X?,-? &lt;,&gt;,no label none none Table 2: ToBI label mapping used in experiments In all our prosody labeling experiments we adopt a leave-one-out speaker validation similar to the method in (Hasegawa-Johnson et al., 2005) for the four speakers with data from one speaker for testing and from the other three for training. For the BU corpus, f2b speaker was always used in the training set since it contains the most data. In addition to performing experiments on all the utterances in BU corpus, we also perform identical experiments on the train and test sets reported in (Chen et al., 2004) which is referred to as Hasegawa-Johnson et al. set. 4 Baseline Experiments We present three baseline experiments. One is simply based on chance where the majority class label is predicted. The second is a baseline only for pitch accents derived from the lexical stress obtained through look-up from a pronunciation lexicon labeled with stress. Finally, the third and more concrete baseline is obtained through prosody detection in current speech synthesis systems. 4.1 Prosody labels derived from lexical stress Pitch accents are usually carried by the stressed syllable in a particular word. Lexic</context>
<context position="29684" citStr="Chen et al., 2004" startWordPosition="4715" endWordPosition="4718"> syntactic-prosodic model and a HMM based acoustic-prosodic model. We also used enriched syntactic information in the form of supertags in addition to POS tags. The supertags provide an improvement in both the pitch accent and boundary tone classification. Especially, in the case where the input utterance is automatically POS tagged (and not hand-corrected), supertags provide a marginal but definite improvement in prosody labeling. The maximum entropy syntactic-prosodic model alone resulted in pitch accent and boundary tone accuracies of 85.2% and 91.5% on training and test sets identical to (Chen et al., 2004). As far as we know, these are the best results on the BU corpus using syntactic information alone and a train-test split that does not contain the same speakers. The acoustic-syntactic maximum entropy model performs better than its syntactic-prosodic counterpart for the boundary tone case but is slightly worse for pitch accent scenario partly due to the approximation involved in quantization. But these results are still better than the baseline results from outof-the-box speech synthesizers. Finally, our combined maximum entropy syntactic-prosodic model and HMM acoustic-prosodic model perform</context>
</contexts>
<marker>Chen, Hasegawa-Johnson, Cohen, 2004</marker>
<rawString>K. Chen, M. Hasegawa-Johnson, and A. Cohen. 2004. An automatic prosody labeling system using ANN-based syntactic-prosodic model and GMMbased acoustic-prosodic model. In Proceedings of ICASSP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Conkie</author>
<author>G Riccardi</author>
<author>R C Rose</author>
</authors>
<title>Prosody recognition from speech utterances using acoustic and linguistic based models of prosodic events.</title>
<date>1999</date>
<booktitle>In Proc. Eurospeech,</booktitle>
<pages>523--526</pages>
<location>Budapest, Hungary.</location>
<contexts>
<context position="7553" citStr="Conkie et al., 1999" startWordPosition="1159" endWordPosition="1162">e corpus to perform prosody labeling experiments. The main drawback of this corpus is that it comprises only read speech. Prosody labeling on spontaneous speech corpora like Boston Directions corpus (BDC), Switchboard (SWBD) has garnered attention in (Hirschberg and Nakatani, 1996; Gregory and Altun, 2004). Automatic prosody labeling has been achieved through various machine learning techniques, such as decision trees (Hirschberg, 1993; Wightman and Ostendorf, 1994; Ma et al., 2003), rule-based systems (Shimei and McKeown, 1999), bagging and boosting on CART (Sun, 2002), hidden markov models (Conkie et al., 1999), neural networks (Hasegawa-Johnson et al., 2005),maximum-entropy models (Brenier et al., 2005) and conditional random fields (Gregory and Altun, 2004). Prosody labeling of the BU corpus has been reported in many studies (Hirschberg, 1993; HasegawaJohnson et al., 2005; Ananthakrishnan and Narayanan, 2005). Hirschberg (Hirschberg, 1993) used a decision-tree based system that achieved 82.4% speaker dependent accent labeling accuracy at the word level on the BU corpus using lexical features. (Ross and Ostendorf, 1996) also used an approach similar to (Wightman and Ostendorf, 1994) to predict pros</context>
</contexts>
<marker>Conkie, Riccardi, Rose, 1999</marker>
<rawString>A. Conkie, G. Riccardi, and R. C. Rose. 1999. Prosody recognition from speech utterances using acoustic and linguistic based models of prosodic events. In Proc. Eurospeech, pages 523–526, Budapest, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Gregory</author>
<author>Y Altun</author>
</authors>
<title>Using conditional random fields to predict pitch accent in conversational speech.</title>
<date>2004</date>
<booktitle>In 42nd Annual Meeting of the Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="7240" citStr="Gregory and Altun, 2004" startWordPosition="1113" endWordPosition="1116">tonation Model (Taylor, 1998). Parametric approaches either restrict the variants of prosody by definition or automatically learn prosodic patterns from data (Agiiero et al., 2006). The BU corpus is a widely used corpus with symbolic representation of prosody. The hand-labeled ToBI annotations make this an attractive corpus to perform prosody labeling experiments. The main drawback of this corpus is that it comprises only read speech. Prosody labeling on spontaneous speech corpora like Boston Directions corpus (BDC), Switchboard (SWBD) has garnered attention in (Hirschberg and Nakatani, 1996; Gregory and Altun, 2004). Automatic prosody labeling has been achieved through various machine learning techniques, such as decision trees (Hirschberg, 1993; Wightman and Ostendorf, 1994; Ma et al., 2003), rule-based systems (Shimei and McKeown, 1999), bagging and boosting on CART (Sun, 2002), hidden markov models (Conkie et al., 1999), neural networks (Hasegawa-Johnson et al., 2005),maximum-entropy models (Brenier et al., 2005) and conditional random fields (Gregory and Altun, 2004). Prosody labeling of the BU corpus has been reported in many studies (Hirschberg, 1993; HasegawaJohnson et al., 2005; Ananthakrishnan a</context>
</contexts>
<marker>Gregory, Altun, 2004</marker>
<rawString>M. Gregory and Y. Altun. 2004. Using conditional random fields to predict pitch accent in conversational speech. In 42nd Annual Meeting of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Haffner</author>
</authors>
<title>Scaling large margin classifiers for spoken language understanding. Speech Communication,</title>
<date>2006</date>
<contexts>
<context position="18465" citStr="Haffner, 2006" startWordPosition="2960" endWordPosition="2961"> table based on POS 4 Corpus Speaker Set Syntactic features k=3 accent btone BU Entire Set correct POS tags 84.75 91.39 AT&amp;T POS + supertags 84.59 91.34 Joint Model (w AT&amp;T POS + supertags) 84.60 91.36 Hasegawa-Johnson et al. set correct POS tags 85.22 91.33 AT&amp;T POS + supertags 84.95 91.21 Joint Model (w AT&amp;T POS + supertags) 84.78 91.54 BDC Entire Set AT&amp;T POS + supertags 79.81 90.28 Joint Model (w AT&amp;T POS + supertags) 79.57 89.76 Table 4: Classification results (%) of pitch accents and boundary tones for different syntactic representation (k = 3) We use the machine learning toolkit LLAMA (Haffner, 2006) to estimate the conditional distribution using maxent. LLAMA encodes multiclass maxent as binary maxent to increase the training speed and to scale the method to large data sets. Each of the V classes in the label set G is encoded as a bit vector such that, in the vector for class i, the ith bit is one and all other bits are zero. Finally, V oneversus-other binary classifiers are used as follows. where AV is the parameter vector for the anti-label y. To compute P(li|ib), we use the class independence assumption and require that yi = 1 and for all j =� i, yj = 0. V P(li|�) = P(yi|(b) ri P(yj|`</context>
</contexts>
<marker>Haffner, 2006</marker>
<rawString>P. Haffner. 2006. Scaling large margin classifiers for spoken language understanding. Speech Communication, 48(iv):239–261.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Hasegawa-Johnson</author>
<author>K Chen</author>
<author>J Cole</author>
<author>S Borys</author>
<author>S Kim</author>
<author>A Cohen</author>
<author>T Zhang</author>
<author>J Choi</author>
<author>H Kim</author>
<author>T Yoon</author>
<author>S Chavara</author>
</authors>
<title>Simultaneous recognition of words and prosody in the boston university radio speech corpus.</title>
<date>2005</date>
<journal>Speech Communication,</journal>
<pages>46--418</pages>
<contexts>
<context position="2715" citStr="Hasegawa-Johnson et al., 2005" startWordPosition="390" endWordPosition="393">sity and pitch, like syllable nuclei duration, short time energy and 1 fundamental frequency (f0) are some acoustic features that are perceived to confer prosodic prominence or stress in English. Lexical features like partsof-speech, syllable nuclei identity, syllable stress of neighboring words have also demonstrated high degree of discriminatory evidence in prosody detection tasks. The interplay between acoustic and lexical features in characterizing prosodic events has been successfully exploited in text-to-speech synthesis (Bulyko and Ostendorf, 2001; Ma et al., 2003), speech recognition (Hasegawa-Johnson et al., 2005) and speech understanding (Wightman and Ostendorf, 1994). Text-to-speech synthesis relies on lexical features derived predominantly from the input text to synthesize natural sounding speech with appropriate prosody. In contrast, output of a typical automatic speech recognition (ASR) system is noisy and hence, the acoustic features are more useful in predicting prosody than the hypothesized lexical transcript which may be erroneous. Speech understanding systems model both the lexical and acoustic features at the output of an ASR to improve natural language understanding. Another source of renew</context>
<context position="7602" citStr="Hasegawa-Johnson et al., 2005" startWordPosition="1165" endWordPosition="1168">periments. The main drawback of this corpus is that it comprises only read speech. Prosody labeling on spontaneous speech corpora like Boston Directions corpus (BDC), Switchboard (SWBD) has garnered attention in (Hirschberg and Nakatani, 1996; Gregory and Altun, 2004). Automatic prosody labeling has been achieved through various machine learning techniques, such as decision trees (Hirschberg, 1993; Wightman and Ostendorf, 1994; Ma et al., 2003), rule-based systems (Shimei and McKeown, 1999), bagging and boosting on CART (Sun, 2002), hidden markov models (Conkie et al., 1999), neural networks (Hasegawa-Johnson et al., 2005),maximum-entropy models (Brenier et al., 2005) and conditional random fields (Gregory and Altun, 2004). Prosody labeling of the BU corpus has been reported in many studies (Hirschberg, 1993; HasegawaJohnson et al., 2005; Ananthakrishnan and Narayanan, 2005). Hirschberg (Hirschberg, 1993) used a decision-tree based system that achieved 82.4% speaker dependent accent labeling accuracy at the word level on the BU corpus using lexical features. (Ross and Ostendorf, 1996) also used an approach similar to (Wightman and Ostendorf, 1994) to predict prosody for a TTS system from lexical features. Pitch</context>
<context position="9294" citStr="Hasegawa-Johnson et al., 2005" startWordPosition="1421" endWordPosition="1424">.7% and 90.1% for accent and boundary prediction, respectively. (Ananthakrishnan and Narayanan, 2005) modeled the acousticprosodic information using a coupled hidden markov model that modeled the asynchrony between the acoustic streams. The pitch accent and boundary tone detection accuracy at the syllable level were 75% and 88% respectively. Our proposed maximum entropy syntactic model outperforms previous work. On the BU corpus, with syntactic information alone we achieve pitch accent and boundary tone accuracy of 85.2% and 91.5% on the same training and test sets used in (Chen et al., 2004; Hasegawa-Johnson et al., 2005). Further, the coupled model with both acoustic and syntactic information results in accuracies of 86.0% and 93.1% respectively. On the BDC corpus, we achieve pitch accent and boundary tone accuracies of 79.8% and 90.3%. 3 Data The BU corpus consists of broadcast news stories including original radio broadcasts and laboratory sim2 Corpus statistics BU BDC f2b f1a m1b m2b h1 h2 h3 h4 # Utterances 165 69 72 51 10 9 9 9 # words (w/o punc) 12608 3681 5058 3608 2234 4127 1456 3008 # pitch accents 6874 2099 2706 2016 1006 1573 678 1333 # boundary tones (w IP) 3916 1059 1282 1023 498 727 361 333 # bo</context>
<context position="11454" citStr="Hasegawa-Johnson et al., 2005" startWordPosition="1788" endWordPosition="1791">U and BDC corpora. In Table 1, the pitch accent and boundary tone statistics are obtained by decomposing the ToBI labels into binary classes using the mapping shown in Table 2. BU Labels Intermediate Mapping Coarse Mapping H*,!H* Single Accent accent L* *,*?,X*? H+!H*,L+H*,L+!H* Bitonal Accent L*+!H,L*+H L-L%,!H-L%,H-L% Final Boundary tone btone H-H% L-H% %?,X%?,%H L-,H-,!H- Intermediate Phrase (IP) boundary -X?,-? &lt;,&gt;,no label none none Table 2: ToBI label mapping used in experiments In all our prosody labeling experiments we adopt a leave-one-out speaker validation similar to the method in (Hasegawa-Johnson et al., 2005) for the four speakers with data from one speaker for testing and from the other three for training. For the BU corpus, f2b speaker was always used in the training set since it contains the most data. In addition to performing experiments on all the utterances in BU corpus, we also perform identical experiments on the train and test sets reported in (Chen et al., 2004) which is referred to as Hasegawa-Johnson et al. set. 4 Baseline Experiments We present three baseline experiments. One is simply based on chance where the majority class label is predicted. The second is a baseline only for pitc</context>
<context position="28315" citStr="Hasegawa-Johnson et al., 2005" startWordPosition="4509" endWordPosition="4512">imum entropy model, resulting in better accuracy when combined together as compared to that of a maxentbased acoustic and syntactic model. The weighted maximum entropy syntacticprosodic model and HMM acoustic-prosodic model performs the best in pitch accent and boundary tone classification. The classification accuracies are as good as the inter-annotator agreement for the ToBI labels. Our HMM acoustic-prosodic model is a generative model and does not assume the knowledge of word boundaries in predicting the prosodic labels as in most approaches (Hirschberg, 1993; Wightman and Ostendorf, 1994; Hasegawa-Johnson et al., 2005). This makes it possible to have true parallel prosody prediction during speech recognition. The weighted approach also offers flexibility in prosody labeling for either speech synthesis or speech recognition. While the syntactic-prosodic model would be more discriminative for speech synthesis, the acoustic-prosodic model is more appropriate for speech recognition. 8 Conclusions and Future Work In this paper, we described a maximum entropy modeling framework for automatic prosody labeling. We presented two schemes for prosody labeling that utilize the acoustic and syntactic information from th</context>
</contexts>
<marker>Hasegawa-Johnson, Chen, Cole, Borys, Kim, Cohen, Zhang, Choi, Kim, Yoon, Chavara, 2005</marker>
<rawString>M. Hasegawa-Johnson, K. Chen, J. Cole, S. Borys, S. Kim, A. Cohen, T. Zhang, J. Choi, H. Kim, T. Yoon, and S. Chavara. 2005. Simultaneous recognition of words and prosody in the boston university radio speech corpus. Speech Communication, 46:418–439.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hirschberg</author>
<author>C Nakatani</author>
</authors>
<title>A prosodic analysis of discourse segments in direction-giving monologues.</title>
<date>1996</date>
<booktitle>In Proceedings of the 34th conference on Association for Computational Linguistics,</booktitle>
<pages>286--293</pages>
<contexts>
<context position="3771" citStr="Hirschberg and Nakatani, 1996" startWordPosition="555" endWordPosition="558">rroneous. Speech understanding systems model both the lexical and acoustic features at the output of an ASR to improve natural language understanding. Another source of renewed interest has come from spoken language translation (N6th et al., 2000; Agiiero et al., 2006). A prerequisite for all these applications is accurate prosody detection, the topic of the present work. In this paper, we describe our framework for building an automatic prosody labeler for English. We report results on the Boston University (BU) Radio Speech Corpus (Ostendorf et al., 1995) and Boston Directions Corpus (BDC) (Hirschberg and Nakatani, 1996), two publicly available speech corpora with manual ToBI annotations intended for experiments in automatic prosody labeling. We condition prosody not only on word strings and their parts-of-speech but also on richer syntactic information encapsulated in the form of Supertags (Bangalore and Joshi, 1999). We propose a maximum entropy modeling framework for the syntactic features. We model the acoustic-prosodic stream with two different models, a maximum entropy model and a more traditional hidden markov model (HMM). In an automatic prosody labeling task, one is essentially tryProceedings of NAAC</context>
<context position="7214" citStr="Hirschberg and Nakatani, 1996" startWordPosition="1109" endWordPosition="1112">r parametrically, e.g., Tilt Intonation Model (Taylor, 1998). Parametric approaches either restrict the variants of prosody by definition or automatically learn prosodic patterns from data (Agiiero et al., 2006). The BU corpus is a widely used corpus with symbolic representation of prosody. The hand-labeled ToBI annotations make this an attractive corpus to perform prosody labeling experiments. The main drawback of this corpus is that it comprises only read speech. Prosody labeling on spontaneous speech corpora like Boston Directions corpus (BDC), Switchboard (SWBD) has garnered attention in (Hirschberg and Nakatani, 1996; Gregory and Altun, 2004). Automatic prosody labeling has been achieved through various machine learning techniques, such as decision trees (Hirschberg, 1993; Wightman and Ostendorf, 1994; Ma et al., 2003), rule-based systems (Shimei and McKeown, 1999), bagging and boosting on CART (Sun, 2002), hidden markov models (Conkie et al., 1999), neural networks (Hasegawa-Johnson et al., 2005),maximum-entropy models (Brenier et al., 2005) and conditional random fields (Gregory and Altun, 2004). Prosody labeling of the BU corpus has been reported in many studies (Hirschberg, 1993; HasegawaJohnson et al</context>
</contexts>
<marker>Hirschberg, Nakatani, 1996</marker>
<rawString>J. Hirschberg and C. Nakatani. 1996. A prosodic analysis of discourse segments in direction-giving monologues. In Proceedings of the 34th conference on Association for Computational Linguistics, pages 286–293.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hirschberg</author>
<author>O Rambow</author>
</authors>
<title>Learning prosodic features using a tree representation.</title>
<date>2001</date>
<booktitle>In Proceedings of Eurospeech,</booktitle>
<pages>1175--1180</pages>
<location>Aalborg.</location>
<contexts>
<context position="17073" citStr="Hirschberg and Rambow, 2001" startWordPosition="2715" endWordPosition="2718">gs were mapped to function and content word categories 1 which was added as a discrete feature. In addition to the POS tags, we also annotate the utterance with Supertags (Bangalore and Joshi, 1999). Supertags encapsulate predicate-argument information in a local structure. They are composed with each other using substitution and adjunction operations of Tree-Adjoining Grammars (TAGs) to derive a dependency analysis of an utterance and its predicate-argument structure. Even though there is a potential to exploit the dependency structure between supertags and prosody labels as demonstrated in (Hirschberg and Rambow, 2001), for this paper we use only the supertag labels. Finally, we generate one feature vector ((D) for each word in the data set (with local contextual features). The best prosodic label sequence is then, n L* = arg max P(li|`b) (6) L i To estimate the conditional distribution P(li|(b) we use the general technique of choosing the maximum entropy (maxent) distribution that estimates the average of each feature over the training data (Berger et al., 1996). This can be written in terms of Gibbs distribution parameterized with weights A, where V is the size of the prosodic label set. Hence, L* = arg m</context>
<context position="27247" citStr="Hirschberg and Rambow, 2001" startWordPosition="4346" endWordPosition="4349">ic maximum entropy model proposed in section 5 outperforms previously reported results on pitch accent and boundary tone classification. Much of the gain comes from the robustness of the maximum entropy modeling in capturing the uncertainty in the classification task. Considering the inter-annotator agreement for ToBI labels is only about 81% for pitch accents and 93% for boundary tones, the maximum entropy framework is able to capture the uncertainty present in manual annotation. The supertag feature offers additional discriminative information over the part-of-speech tags (also as shown by (Hirschberg and Rambow, 2001). The maximum entropy acoustic-prosodic model discussed in section 6.2 performs reasonably well in isolation. This is a simple method and the quantization resolution can be adjusted based on the amount of data available for training. However, the model does not perform as well when combined with the syntactic features. We conjecture that the generalization provided by the acoustic HMM model is complementary to that provided by the maximum entropy model, resulting in better accuracy when combined together as compared to that of a maxentbased acoustic and syntactic model. The weighted maximum en</context>
</contexts>
<marker>Hirschberg, Rambow, 2001</marker>
<rawString>J. Hirschberg and O. Rambow. 2001. Learning prosodic features using a tree representation. In Proceedings of Eurospeech, pages 1175–1180, Aalborg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hirschberg</author>
</authors>
<title>Pitch accent in context: Predicting intonational prominence from text.</title>
<date>1993</date>
<journal>Artificial Intelligence,</journal>
<pages>63--1</pages>
<contexts>
<context position="7372" citStr="Hirschberg, 1993" startWordPosition="1132" endWordPosition="1133">atterns from data (Agiiero et al., 2006). The BU corpus is a widely used corpus with symbolic representation of prosody. The hand-labeled ToBI annotations make this an attractive corpus to perform prosody labeling experiments. The main drawback of this corpus is that it comprises only read speech. Prosody labeling on spontaneous speech corpora like Boston Directions corpus (BDC), Switchboard (SWBD) has garnered attention in (Hirschberg and Nakatani, 1996; Gregory and Altun, 2004). Automatic prosody labeling has been achieved through various machine learning techniques, such as decision trees (Hirschberg, 1993; Wightman and Ostendorf, 1994; Ma et al., 2003), rule-based systems (Shimei and McKeown, 1999), bagging and boosting on CART (Sun, 2002), hidden markov models (Conkie et al., 1999), neural networks (Hasegawa-Johnson et al., 2005),maximum-entropy models (Brenier et al., 2005) and conditional random fields (Gregory and Altun, 2004). Prosody labeling of the BU corpus has been reported in many studies (Hirschberg, 1993; HasegawaJohnson et al., 2005; Ananthakrishnan and Narayanan, 2005). Hirschberg (Hirschberg, 1993) used a decision-tree based system that achieved 82.4% speaker dependent accent la</context>
<context position="28253" citStr="Hirschberg, 1993" startWordPosition="4503" endWordPosition="4504">del is complementary to that provided by the maximum entropy model, resulting in better accuracy when combined together as compared to that of a maxentbased acoustic and syntactic model. The weighted maximum entropy syntacticprosodic model and HMM acoustic-prosodic model performs the best in pitch accent and boundary tone classification. The classification accuracies are as good as the inter-annotator agreement for the ToBI labels. Our HMM acoustic-prosodic model is a generative model and does not assume the knowledge of word boundaries in predicting the prosodic labels as in most approaches (Hirschberg, 1993; Wightman and Ostendorf, 1994; Hasegawa-Johnson et al., 2005). This makes it possible to have true parallel prosody prediction during speech recognition. The weighted approach also offers flexibility in prosody labeling for either speech synthesis or speech recognition. While the syntactic-prosodic model would be more discriminative for speech synthesis, the acoustic-prosodic model is more appropriate for speech recognition. 8 Conclusions and Future Work In this paper, we described a maximum entropy modeling framework for automatic prosody labeling. We presented two schemes for prosody labeli</context>
</contexts>
<marker>Hirschberg, 1993</marker>
<rawString>J. Hirschberg. 1993. Pitch accent in context: Predicting intonational prominence from text. Artificial Intelligence, 63(1-2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Lehiste</author>
</authors>
<date>1970</date>
<publisher>Suprasegmentals. MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="1566" citStr="Lehiste, 1970" startWordPosition="227" endWordPosition="228"> improved pitch accent and boundary tone classification accuracies of 86.0% and 93.1% respectively. Similar experimental results are also reported on Boston Directions corpus. 1 Introduction Prosody refers to intonation, rhythm and lexical stress patterns of spoken language that convey linguistic and paralinguistic information such as emphasis, intent, attitude and emotion of a speaker. Prosodic information associated with a unit of speech, say, syllable, word, phrase or clause, influence all the segments of the unit in an utterance. In this sense they are also referred to as suprasegmentals (Lehiste, 1970). Prosody in general is highly dependent on individual speaker style, gender, dialect and other phonological factors. The difficulty in reliably characterizing suprasegmental information present in speech has resulted in symbolic and parameteric prosody labeling standards like ToBI (Tones and Break Indices) (Silverman et al., 1992) and Tilt model (Taylor, 1998) respectively. Prosody in spoken language can be characterized through acoustic features or lexical features or both. Acoustic correlates of duration, intensity and pitch, like syllable nuclei duration, short time energy and 1 fundamenta</context>
</contexts>
<marker>Lehiste, 1970</marker>
<rawString>I. Lehiste. 1970. Suprasegmentals. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Ma</author>
<author>W Zhang</author>
<author>Q Shi</author>
<author>W Zhu</author>
<author>L Shen</author>
</authors>
<title>Automatic prosody labeling using both text and acoustic information.</title>
<date>2003</date>
<booktitle>In Proceedings of ICASSP,</booktitle>
<volume>1</volume>
<pages>516--519</pages>
<contexts>
<context position="2663" citStr="Ma et al., 2003" startWordPosition="384" endWordPosition="387">Acoustic correlates of duration, intensity and pitch, like syllable nuclei duration, short time energy and 1 fundamental frequency (f0) are some acoustic features that are perceived to confer prosodic prominence or stress in English. Lexical features like partsof-speech, syllable nuclei identity, syllable stress of neighboring words have also demonstrated high degree of discriminatory evidence in prosody detection tasks. The interplay between acoustic and lexical features in characterizing prosodic events has been successfully exploited in text-to-speech synthesis (Bulyko and Ostendorf, 2001; Ma et al., 2003), speech recognition (Hasegawa-Johnson et al., 2005) and speech understanding (Wightman and Ostendorf, 1994). Text-to-speech synthesis relies on lexical features derived predominantly from the input text to synthesize natural sounding speech with appropriate prosody. In contrast, output of a typical automatic speech recognition (ASR) system is noisy and hence, the acoustic features are more useful in predicting prosody than the hypothesized lexical transcript which may be erroneous. Speech understanding systems model both the lexical and acoustic features at the output of an ASR to improve nat</context>
<context position="7420" citStr="Ma et al., 2003" startWordPosition="1138" endWordPosition="1141"> corpus is a widely used corpus with symbolic representation of prosody. The hand-labeled ToBI annotations make this an attractive corpus to perform prosody labeling experiments. The main drawback of this corpus is that it comprises only read speech. Prosody labeling on spontaneous speech corpora like Boston Directions corpus (BDC), Switchboard (SWBD) has garnered attention in (Hirschberg and Nakatani, 1996; Gregory and Altun, 2004). Automatic prosody labeling has been achieved through various machine learning techniques, such as decision trees (Hirschberg, 1993; Wightman and Ostendorf, 1994; Ma et al., 2003), rule-based systems (Shimei and McKeown, 1999), bagging and boosting on CART (Sun, 2002), hidden markov models (Conkie et al., 1999), neural networks (Hasegawa-Johnson et al., 2005),maximum-entropy models (Brenier et al., 2005) and conditional random fields (Gregory and Altun, 2004). Prosody labeling of the BU corpus has been reported in many studies (Hirschberg, 1993; HasegawaJohnson et al., 2005; Ananthakrishnan and Narayanan, 2005). Hirschberg (Hirschberg, 1993) used a decision-tree based system that achieved 82.4% speaker dependent accent labeling accuracy at the word level on the BU corp</context>
</contexts>
<marker>Ma, Zhang, Shi, Zhu, Shen, 2003</marker>
<rawString>X. Ma, W. Zhang, Q. Shi, W. Zhu, and L. Shen. 2003. Automatic prosody labeling using both text and acoustic information. In Proceedings of ICASSP, volume 1, pages 516–519, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Noth</author>
<author>A Batliner</author>
<author>A Kieiiling</author>
<author>R Kompe</author>
<author>H Niemann</author>
</authors>
<title>VERBMOBIL: The use of prosody in the linguistic components of a speech understanding system.</title>
<date>2000</date>
<booktitle>IEEE Transactions on Speech and Audio processing,</booktitle>
<pages>8--5</pages>
<contexts>
<context position="6368" citStr="Noth et al., 2000" startWordPosition="983" endWordPosition="986">on 6, we describe our acoustic-prosodic model and discuss our results in section 7. We finally conclude in section 8 with directions for future work. 2 Related work Automatic prosody labeling has been an active research topic for over a decade. Wightman and Ostendorf (Wightman and Ostendorf, 1994) developed a decision-tree algorithm for labeling prosodic patterns. The algorithm detected phrasal prominence and boundary tones at the syllable level. Bulyko and Ostendorf (Bulyko and Ostendorf, 2001) used a prosody prediction module to synthesize natural speech with appropriate prosody. Verbmobil (Noth et al., 2000) incorporated prosodic labeling into a translation framework for improved linguistic analysis and speech understanding. Prosody has typically been represented either symbolically, e.g., ToBI (Silverman et al., 1992) or parametrically, e.g., Tilt Intonation Model (Taylor, 1998). Parametric approaches either restrict the variants of prosody by definition or automatically learn prosodic patterns from data (Agiiero et al., 2006). The BU corpus is a widely used corpus with symbolic representation of prosody. The hand-labeled ToBI annotations make this an attractive corpus to perform prosody labelin</context>
</contexts>
<marker>Noth, Batliner, Kieiiling, Kompe, Niemann, 2000</marker>
<rawString>E. Noth, A. Batliner, A. Kieiiling, R. Kompe, and H. Niemann. 2000. VERBMOBIL: The use of prosody in the linguistic components of a speech understanding system. IEEE Transactions on Speech and Audio processing, 8(5):519–532.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Ostendorf</author>
<author>P J Price</author>
<author>S Shattuck-Hufnagel</author>
</authors>
<date>1995</date>
<tech>Technical Report ECS-95-001,</tech>
<institution>The Boston University Radio News Corpus.</institution>
<contexts>
<context position="3704" citStr="Ostendorf et al., 1995" startWordPosition="546" endWordPosition="549">sody than the hypothesized lexical transcript which may be erroneous. Speech understanding systems model both the lexical and acoustic features at the output of an ASR to improve natural language understanding. Another source of renewed interest has come from spoken language translation (N6th et al., 2000; Agiiero et al., 2006). A prerequisite for all these applications is accurate prosody detection, the topic of the present work. In this paper, we describe our framework for building an automatic prosody labeler for English. We report results on the Boston University (BU) Radio Speech Corpus (Ostendorf et al., 1995) and Boston Directions Corpus (BDC) (Hirschberg and Nakatani, 1996), two publicly available speech corpora with manual ToBI annotations intended for experiments in automatic prosody labeling. We condition prosody not only on word strings and their parts-of-speech but also on richer syntactic information encapsulated in the form of Supertags (Bangalore and Joshi, 1999). We propose a maximum entropy modeling framework for the syntactic features. We model the acoustic-prosodic stream with two different models, a maximum entropy model and a more traditional hidden markov model (HMM). In an automat</context>
</contexts>
<marker>Ostendorf, Price, Shattuck-Hufnagel, 1995</marker>
<rawString>M. Ostendorf, P. J. Price, and S. Shattuck-Hufnagel. 1995. The Boston University Radio News Corpus. Technical Report ECS-95-001, Boston University, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Ross</author>
<author>M Ostendorf</author>
</authors>
<title>Prediction of abstract prosodic labels for speech synthesis. Computer Speech and Language,</title>
<date>1996</date>
<pages>10--155</pages>
<contexts>
<context position="8073" citStr="Ross and Ostendorf, 1996" startWordPosition="1235" endWordPosition="1238"> and McKeown, 1999), bagging and boosting on CART (Sun, 2002), hidden markov models (Conkie et al., 1999), neural networks (Hasegawa-Johnson et al., 2005),maximum-entropy models (Brenier et al., 2005) and conditional random fields (Gregory and Altun, 2004). Prosody labeling of the BU corpus has been reported in many studies (Hirschberg, 1993; HasegawaJohnson et al., 2005; Ananthakrishnan and Narayanan, 2005). Hirschberg (Hirschberg, 1993) used a decision-tree based system that achieved 82.4% speaker dependent accent labeling accuracy at the word level on the BU corpus using lexical features. (Ross and Ostendorf, 1996) also used an approach similar to (Wightman and Ostendorf, 1994) to predict prosody for a TTS system from lexical features. Pitch accent accuracy at the word-level was reported to be 82.5% and syllable-level accent accuracy was 80.2%. (Hasegawa-Johnson et al., 2005) proposed a neural network based syntactic-prosodic model and a gaussian mixture model based acousticprosodic model to predict accent and boundary tones on the BU corpus that achieved 84.2% accuracy in accent prediction and 93.0% accuracy in intonational boundary prediction. With syntactic information alone they achieved 82.7% and 9</context>
</contexts>
<marker>Ross, Ostendorf, 1996</marker>
<rawString>K. Ross and M. Ostendorf. 1996. Prediction of abstract prosodic labels for speech synthesis. Computer Speech and Language, 10:155–185, Oct.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Shimei</author>
<author>K McKeown</author>
</authors>
<title>Word informativeness and automatic pitch accent modeling. In</title>
<date>1999</date>
<booktitle>In Proceedings of EMNLP/VLC,</booktitle>
<location>College Park, Maryland.</location>
<contexts>
<context position="7467" citStr="Shimei and McKeown, 1999" startWordPosition="1145" endWordPosition="1148">ymbolic representation of prosody. The hand-labeled ToBI annotations make this an attractive corpus to perform prosody labeling experiments. The main drawback of this corpus is that it comprises only read speech. Prosody labeling on spontaneous speech corpora like Boston Directions corpus (BDC), Switchboard (SWBD) has garnered attention in (Hirschberg and Nakatani, 1996; Gregory and Altun, 2004). Automatic prosody labeling has been achieved through various machine learning techniques, such as decision trees (Hirschberg, 1993; Wightman and Ostendorf, 1994; Ma et al., 2003), rule-based systems (Shimei and McKeown, 1999), bagging and boosting on CART (Sun, 2002), hidden markov models (Conkie et al., 1999), neural networks (Hasegawa-Johnson et al., 2005),maximum-entropy models (Brenier et al., 2005) and conditional random fields (Gregory and Altun, 2004). Prosody labeling of the BU corpus has been reported in many studies (Hirschberg, 1993; HasegawaJohnson et al., 2005; Ananthakrishnan and Narayanan, 2005). Hirschberg (Hirschberg, 1993) used a decision-tree based system that achieved 82.4% speaker dependent accent labeling accuracy at the word level on the BU corpus using lexical features. (Ross and Ostendorf,</context>
</contexts>
<marker>Shimei, McKeown, 1999</marker>
<rawString>P. Shimei and K. McKeown. 1999. Word informativeness and automatic pitch accent modeling. In In Proceedings of EMNLP/VLC, College Park, Maryland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Silverman</author>
<author>M Beckman</author>
<author>J Pitrelli</author>
<author>M Ostendorf</author>
<author>C Wightman</author>
<author>P Price</author>
<author>J Pierrehumbert</author>
<author>J Hirschberg</author>
</authors>
<title>ToBI: A standard for labeling English prosody.</title>
<date>1992</date>
<booktitle>In Proceedings of ICSLP,</booktitle>
<pages>867--870</pages>
<contexts>
<context position="1899" citStr="Silverman et al., 1992" startWordPosition="272" endWordPosition="275">tion such as emphasis, intent, attitude and emotion of a speaker. Prosodic information associated with a unit of speech, say, syllable, word, phrase or clause, influence all the segments of the unit in an utterance. In this sense they are also referred to as suprasegmentals (Lehiste, 1970). Prosody in general is highly dependent on individual speaker style, gender, dialect and other phonological factors. The difficulty in reliably characterizing suprasegmental information present in speech has resulted in symbolic and parameteric prosody labeling standards like ToBI (Tones and Break Indices) (Silverman et al., 1992) and Tilt model (Taylor, 1998) respectively. Prosody in spoken language can be characterized through acoustic features or lexical features or both. Acoustic correlates of duration, intensity and pitch, like syllable nuclei duration, short time energy and 1 fundamental frequency (f0) are some acoustic features that are perceived to confer prosodic prominence or stress in English. Lexical features like partsof-speech, syllable nuclei identity, syllable stress of neighboring words have also demonstrated high degree of discriminatory evidence in prosody detection tasks. The interplay between acous</context>
<context position="6583" citStr="Silverman et al., 1992" startWordPosition="1012" endWordPosition="1015"> research topic for over a decade. Wightman and Ostendorf (Wightman and Ostendorf, 1994) developed a decision-tree algorithm for labeling prosodic patterns. The algorithm detected phrasal prominence and boundary tones at the syllable level. Bulyko and Ostendorf (Bulyko and Ostendorf, 2001) used a prosody prediction module to synthesize natural speech with appropriate prosody. Verbmobil (Noth et al., 2000) incorporated prosodic labeling into a translation framework for improved linguistic analysis and speech understanding. Prosody has typically been represented either symbolically, e.g., ToBI (Silverman et al., 1992) or parametrically, e.g., Tilt Intonation Model (Taylor, 1998). Parametric approaches either restrict the variants of prosody by definition or automatically learn prosodic patterns from data (Agiiero et al., 2006). The BU corpus is a widely used corpus with symbolic representation of prosody. The hand-labeled ToBI annotations make this an attractive corpus to perform prosody labeling experiments. The main drawback of this corpus is that it comprises only read speech. Prosody labeling on spontaneous speech corpora like Boston Directions corpus (BDC), Switchboard (SWBD) has garnered attention in</context>
</contexts>
<marker>Silverman, Beckman, Pitrelli, Ostendorf, Wightman, Price, Pierrehumbert, Hirschberg, 1992</marker>
<rawString>K. Silverman, M. Beckman, J. Pitrelli, M. Ostendorf, C. Wightman, P. Price, J. Pierrehumbert, and J. Hirschberg. 1992. ToBI: A standard for labeling English prosody. In Proceedings of ICSLP, pages 867–870.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Sun</author>
</authors>
<title>Pitch accent prediction using ensemble machine learning.</title>
<date>2002</date>
<booktitle>In Proc. of ICSLP.</booktitle>
<contexts>
<context position="7509" citStr="Sun, 2002" startWordPosition="1154" endWordPosition="1155">annotations make this an attractive corpus to perform prosody labeling experiments. The main drawback of this corpus is that it comprises only read speech. Prosody labeling on spontaneous speech corpora like Boston Directions corpus (BDC), Switchboard (SWBD) has garnered attention in (Hirschberg and Nakatani, 1996; Gregory and Altun, 2004). Automatic prosody labeling has been achieved through various machine learning techniques, such as decision trees (Hirschberg, 1993; Wightman and Ostendorf, 1994; Ma et al., 2003), rule-based systems (Shimei and McKeown, 1999), bagging and boosting on CART (Sun, 2002), hidden markov models (Conkie et al., 1999), neural networks (Hasegawa-Johnson et al., 2005),maximum-entropy models (Brenier et al., 2005) and conditional random fields (Gregory and Altun, 2004). Prosody labeling of the BU corpus has been reported in many studies (Hirschberg, 1993; HasegawaJohnson et al., 2005; Ananthakrishnan and Narayanan, 2005). Hirschberg (Hirschberg, 1993) used a decision-tree based system that achieved 82.4% speaker dependent accent labeling accuracy at the word level on the BU corpus using lexical features. (Ross and Ostendorf, 1996) also used an approach similar to (W</context>
</contexts>
<marker>Sun, 2002</marker>
<rawString>X. Sun. 2002. Pitch accent prediction using ensemble machine learning. In Proc. of ICSLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A K Syrdal</author>
<author>J McGory</author>
</authors>
<title>Inter-transcriber reliability of tobi prosodic labeling.</title>
<date>2000</date>
<booktitle>In Proc. ICSLP,</booktitle>
<pages>235--238</pages>
<location>Beijing, China.</location>
<contexts>
<context position="20084" citStr="Syrdal and McGory, 2000" startWordPosition="3230" endWordPosition="3233">btone, none-none}. We trained the classifier on the joint labels and then computed the error rates for individual classes. The results of prosody prediction using the set of syntactic-prosodic features for k = 3 is shown in Table 4. The joint modeling approach provides a marginal improvement in the boundary tone prediction but is slightly worse for pitch accent prediction. 5.2 Supertagger performance on Intermediate Phrase boundaries Perceptual experiments have indicated that interannotator agreement for ToBI intermediate phrase boundaries is very low compared to full-intonational boundaries (Syrdal and McGory, 2000). Intermediate phrasing is important in TTS applications to synthesize appropriate short pauses to make the utterance sound natural. The significance of syntactic features in the boundary tone prediction prompted us to examine the effect of predicting intermediate phrase boundaries in isolation. It is intuitive to expect supertags to perform well in this task as they essentially form a local dependency analysis on an utterance and provide an encoding of the syntactic phrasal information. We performed this task as a three way classification where li e G = {btone, ip, none}. The results of the c</context>
</contexts>
<marker>Syrdal, McGory, 2000</marker>
<rawString>A. K. Syrdal and J. McGory. 2000. Inter-transcriber reliability of tobi prosodic labeling. In Proc. ICSLP, pages 235–238, Beijing, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Taylor</author>
</authors>
<title>The tilt intonation model.</title>
<date>1998</date>
<booktitle>In Proc. ICSLP,</booktitle>
<volume>4</volume>
<pages>1383--1386</pages>
<contexts>
<context position="1929" citStr="Taylor, 1998" startWordPosition="279" endWordPosition="280">and emotion of a speaker. Prosodic information associated with a unit of speech, say, syllable, word, phrase or clause, influence all the segments of the unit in an utterance. In this sense they are also referred to as suprasegmentals (Lehiste, 1970). Prosody in general is highly dependent on individual speaker style, gender, dialect and other phonological factors. The difficulty in reliably characterizing suprasegmental information present in speech has resulted in symbolic and parameteric prosody labeling standards like ToBI (Tones and Break Indices) (Silverman et al., 1992) and Tilt model (Taylor, 1998) respectively. Prosody in spoken language can be characterized through acoustic features or lexical features or both. Acoustic correlates of duration, intensity and pitch, like syllable nuclei duration, short time energy and 1 fundamental frequency (f0) are some acoustic features that are perceived to confer prosodic prominence or stress in English. Lexical features like partsof-speech, syllable nuclei identity, syllable stress of neighboring words have also demonstrated high degree of discriminatory evidence in prosody detection tasks. The interplay between acoustic and lexical features in ch</context>
<context position="6645" citStr="Taylor, 1998" startWordPosition="1022" endWordPosition="1024">Ostendorf, 1994) developed a decision-tree algorithm for labeling prosodic patterns. The algorithm detected phrasal prominence and boundary tones at the syllable level. Bulyko and Ostendorf (Bulyko and Ostendorf, 2001) used a prosody prediction module to synthesize natural speech with appropriate prosody. Verbmobil (Noth et al., 2000) incorporated prosodic labeling into a translation framework for improved linguistic analysis and speech understanding. Prosody has typically been represented either symbolically, e.g., ToBI (Silverman et al., 1992) or parametrically, e.g., Tilt Intonation Model (Taylor, 1998). Parametric approaches either restrict the variants of prosody by definition or automatically learn prosodic patterns from data (Agiiero et al., 2006). The BU corpus is a widely used corpus with symbolic representation of prosody. The hand-labeled ToBI annotations make this an attractive corpus to perform prosody labeling experiments. The main drawback of this corpus is that it comprises only read speech. Prosody labeling on spontaneous speech corpora like Boston Directions corpus (BDC), Switchboard (SWBD) has garnered attention in (Hirschberg and Nakatani, 1996; Gregory and Altun, 2004). Aut</context>
<context position="23588" citStr="Taylor, 1998" startWordPosition="3781" endWordPosition="3782"> a maximum entropy modeling framework to model the continuous acoustic-prosodic observation sequence as a discrete sequence through the means of quantization. The quantized acoustic stream is then used as a feature vector and the conditional probabilities are approximated by an n-gram model. This is equivalent to reducing the vocabulary of the acoustic-prosodic features and hence offers better estimates of the conditional probabilities. Such an n-gram model of quantized continuous features is similar to representing the set of features with a linear fit as done in the tilt intonational model (Taylor, 1998). The quantized acoustic-prosodic feature stream is modeled with a maxent acoustic-prosodic model similar to the one described in section 5. Finally, we append the syntactic and acoustic features to model the combined stream with the maxent acoustic-syntactic model, where the objective criterion for maximization is Equation (1). The pitch accent and boundary tone prediction accuracies for quantization performed by considering only the first decimal place is reported in Table 6. As expected, we found the classification accuracy to drop with increasing number of bins used in the quantization due</context>
</contexts>
<marker>Taylor, 1998</marker>
<rawString>P. Taylor. 1998. The tilt intonation model. In Proc. ICSLP, volume 4, pages 1383–1386.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C W Wightman</author>
<author>M Ostendorf</author>
</authors>
<title>Automatic labeling of prosodic patterns.</title>
<date>1994</date>
<journal>IEEE Transactions on Speech and Audio Processing,</journal>
<volume>2</volume>
<issue>3</issue>
<pages>481</pages>
<contexts>
<context position="2771" citStr="Wightman and Ostendorf, 1994" startWordPosition="397" endWordPosition="400"> energy and 1 fundamental frequency (f0) are some acoustic features that are perceived to confer prosodic prominence or stress in English. Lexical features like partsof-speech, syllable nuclei identity, syllable stress of neighboring words have also demonstrated high degree of discriminatory evidence in prosody detection tasks. The interplay between acoustic and lexical features in characterizing prosodic events has been successfully exploited in text-to-speech synthesis (Bulyko and Ostendorf, 2001; Ma et al., 2003), speech recognition (Hasegawa-Johnson et al., 2005) and speech understanding (Wightman and Ostendorf, 1994). Text-to-speech synthesis relies on lexical features derived predominantly from the input text to synthesize natural sounding speech with appropriate prosody. In contrast, output of a typical automatic speech recognition (ASR) system is noisy and hence, the acoustic features are more useful in predicting prosody than the hypothesized lexical transcript which may be erroneous. Speech understanding systems model both the lexical and acoustic features at the output of an ASR to improve natural language understanding. Another source of renewed interest has come from spoken language translation (N</context>
<context position="6048" citStr="Wightman and Ostendorf, 1994" startWordPosition="938" endWordPosition="941"> In section 2 we describe related work in automatic prosody labeling followed by a description of the data used in our experiments in section 3. We present prosody prediction results from off-the-shelf synthesizers in section 4. Section 5 details our proposed maximum entropy syntactic-prosodic model for prosody labeling. In section 6, we describe our acoustic-prosodic model and discuss our results in section 7. We finally conclude in section 8 with directions for future work. 2 Related work Automatic prosody labeling has been an active research topic for over a decade. Wightman and Ostendorf (Wightman and Ostendorf, 1994) developed a decision-tree algorithm for labeling prosodic patterns. The algorithm detected phrasal prominence and boundary tones at the syllable level. Bulyko and Ostendorf (Bulyko and Ostendorf, 2001) used a prosody prediction module to synthesize natural speech with appropriate prosody. Verbmobil (Noth et al., 2000) incorporated prosodic labeling into a translation framework for improved linguistic analysis and speech understanding. Prosody has typically been represented either symbolically, e.g., ToBI (Silverman et al., 1992) or parametrically, e.g., Tilt Intonation Model (Taylor, 1998). P</context>
<context position="7402" citStr="Wightman and Ostendorf, 1994" startWordPosition="1134" endWordPosition="1137">(Agiiero et al., 2006). The BU corpus is a widely used corpus with symbolic representation of prosody. The hand-labeled ToBI annotations make this an attractive corpus to perform prosody labeling experiments. The main drawback of this corpus is that it comprises only read speech. Prosody labeling on spontaneous speech corpora like Boston Directions corpus (BDC), Switchboard (SWBD) has garnered attention in (Hirschberg and Nakatani, 1996; Gregory and Altun, 2004). Automatic prosody labeling has been achieved through various machine learning techniques, such as decision trees (Hirschberg, 1993; Wightman and Ostendorf, 1994; Ma et al., 2003), rule-based systems (Shimei and McKeown, 1999), bagging and boosting on CART (Sun, 2002), hidden markov models (Conkie et al., 1999), neural networks (Hasegawa-Johnson et al., 2005),maximum-entropy models (Brenier et al., 2005) and conditional random fields (Gregory and Altun, 2004). Prosody labeling of the BU corpus has been reported in many studies (Hirschberg, 1993; HasegawaJohnson et al., 2005; Ananthakrishnan and Narayanan, 2005). Hirschberg (Hirschberg, 1993) used a decision-tree based system that achieved 82.4% speaker dependent accent labeling accuracy at the word le</context>
<context position="19266" citStr="Wightman and Ostendorf, 1994" startWordPosition="3104" endWordPosition="3107">a sets. Each of the V classes in the label set G is encoded as a bit vector such that, in the vector for class i, the ith bit is one and all other bits are zero. Finally, V oneversus-other binary classifiers are used as follows. where AV is the parameter vector for the anti-label y. To compute P(li|ib), we use the class independence assumption and require that yi = 1 and for all j =� i, yj = 0. V P(li|�) = P(yi|(b) ri P(yj|`D) (9) j#i 5.1 Joint Modeling of Accents and Boundary Tones Prosodic prominence and phrasing can also be viewed as joint events occurring simultaneously. Previous work by (Wightman and Ostendorf, 1994) suggests that a joint labeling approach may be more beneficial in prosody labeling. In this scenario, we treat each word to have one of the four labels li e G = {accent-btone, accent-none, nonebtone, none-none}. We trained the classifier on the joint labels and then computed the error rates for individual classes. The results of prosody prediction using the set of syntactic-prosodic features for k = 3 is shown in Table 4. The joint modeling approach provides a marginal improvement in the boundary tone prediction but is slightly worse for pitch accent prediction. 5.2 Supertagger performance on</context>
<context position="28283" citStr="Wightman and Ostendorf, 1994" startWordPosition="4505" endWordPosition="4508">ry to that provided by the maximum entropy model, resulting in better accuracy when combined together as compared to that of a maxentbased acoustic and syntactic model. The weighted maximum entropy syntacticprosodic model and HMM acoustic-prosodic model performs the best in pitch accent and boundary tone classification. The classification accuracies are as good as the inter-annotator agreement for the ToBI labels. Our HMM acoustic-prosodic model is a generative model and does not assume the knowledge of word boundaries in predicting the prosodic labels as in most approaches (Hirschberg, 1993; Wightman and Ostendorf, 1994; Hasegawa-Johnson et al., 2005). This makes it possible to have true parallel prosody prediction during speech recognition. The weighted approach also offers flexibility in prosody labeling for either speech synthesis or speech recognition. While the syntactic-prosodic model would be more discriminative for speech synthesis, the acoustic-prosodic model is more appropriate for speech recognition. 8 Conclusions and Future Work In this paper, we described a maximum entropy modeling framework for automatic prosody labeling. We presented two schemes for prosody labeling that utilize the acoustic a</context>
</contexts>
<marker>Wightman, Ostendorf, 1994</marker>
<rawString>C. W. Wightman and M. Ostendorf. 1994. Automatic labeling of prosodic patterns. IEEE Transactions on Speech and Audio Processing, 2(3):469– 481.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>