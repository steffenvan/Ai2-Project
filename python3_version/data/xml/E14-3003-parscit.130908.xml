<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000070">
<title confidence="0.9966455">
Enhancing Medical Named Entity Recognition
with Features Derived from Unsupervised Methods
</title>
<author confidence="0.994828">
Maria Skeppstedt
</author>
<affiliation confidence="0.9953">
Dept. of Computer and Systems Sciences (DSV)
</affiliation>
<address confidence="0.505162">
Stockholm University, Forum 100, 164 40 Kista, Sweden
</address>
<email confidence="0.997231">
mariask@dsv.su.se
</email>
<sectionHeader confidence="0.993847" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999960176470588">
A study of the usefulness of features ex-
tracted from unsupervised methods is pro-
posed. The usefulness of these features
will be studied on the task of performing
named entity recognition within one clin-
ical sub-domain as well as on the task of
adapting a named entity recognition model
to a new clinical sub-domain. Four named
entity types, all very relevant for clini-
cal information extraction, will be studied:
Disorder, Finding, Pharmaceutical Drug
and Body Structure. The named entity
recognition will be performed using con-
ditional random fields. As unsupervised
features, a clustering of the semantic rep-
resentation of words obtained from a ran-
dom indexing word space will be used.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999918083333333">
Creating the annotated corpus needed for training
a NER (named entity recognition) model is costly.
This is particularly the case for texts in specialised
domains, for which expert annotators are often re-
quired. In addition, the need for expert annotators
also limits the possibilities of using crowdsourcing
approaches (e.g. Amazon Mechanical Turk). Fea-
tures from unsupervised machine-learning meth-
ods, for which no labelled training data is required,
have, however, been shown to improve the per-
formance of NER systems (Jonnalagadda et al.,
2012). It is therefore likely that by incorporating
features from unsupervised methods, it is possible
to reduce the amount of training data needed to
achieve a fixed level of performance.
Due to differences in the use of language, an
NLP system developed for, or trained on, text
from one sub-domain often shows a drop in per-
formance when applied on texts from another sub-
domain (Martinez et al., 2013). This has the ef-
fect that when performing NER on a new sub-
domain, annotated text from this new targeted sub-
domain might be required, even when there are
annotated corpora from other domains. It would,
however, be preferable to be able to apply a NER
model trained on text from one sub-domain on an-
other sub-domain, with only a minimum of addi-
tional data from this other targeted sub-domain.
Incorporating features from unsupervised meth-
ods might limit the amount of additional annotated
data needed for adapting a NER model to a new
sub-domain.
The proposed study aims at investigating the
usefulness of unsupervised features, both for NER
within one sub-domain and for domain adaptation
of a NER model. The study has two hypotheses.
</bodyText>
<listItem confidence="0.797138">
• Within one subdomain:
</listItem>
<bodyText confidence="0.9505120625">
For reaching the same level of performance
when training a NER model, less training
data is required when unsupervised features
are used.
• For adapting a model trained on one subdo-
main to a new targeted subdomain:
For reaching the same level of performance
when adapting a NER model to a new subdo-
main, less additional training data is required
in the new targeted subdomain when unsu-
pervised features are used.
For both hypotheses, the level of performance is
defined in terms of F-score.
The proposed study will be carried out on dif-
ferent sub-domains within the specialised text do-
main of clinical text.
</bodyText>
<sectionHeader confidence="0.994095" genericHeader="introduction">
2 Related research
</sectionHeader>
<bodyText confidence="0.982058666666667">
There are a number of previous studies on named
entity recognition in clinical text. For instance,
a corpus annotated for the entities Condition,
</bodyText>
<page confidence="0.992418">
21
</page>
<note confidence="0.995233">
Proceedings of the Student Research Workshop at the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 21–30,
Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.999514011494253">
Drug/Device and Locus was used for training
a support vector machine with uneven margins
(Roberts et al., 2008) and a corpus annotated for
the entities Finding, Substance and Body was used
for training a conditional random fields (CRF) sys-
tem (Wang, 2009) as well as for training an en-
semble of different classifiers (Wang and Patrick,
2009). Most studies have, however, been con-
ducted on the i2b2 medication challenge corpus
and the i2b2 challenge on concepts, assertions,
and relations corpus. Conditional random fields
(Patrick and Li, 2010) as well as an ensemble clas-
sifier (Doan et al., 2012) has for instance been used
for extracting the entity Medication names from
the medication challenge corpus, while all but the
best among the top-performing systems used CRF
for extracting the entities Medical Problem, Test
and Treatment from the i2b2 challenge on con-
cepts, assertions, and relations corpus (Uzuner et
al., 2011). The best system (de Bruijn et al., 2011)
used semi-Markov HMM, and in addition to the
features used by most of the other systems (e.g.
tokens/lemmas/stems, orthographics, affixes, part-
of-speech, output of terminology matching), this
system also used features extracted from hierarchi-
cal word clusters on un-annotated text. For con-
structing the clusters, they used Brown clustering,
and represented the feature as a 7-bit showing to
what cluster a word belonged.
Outside of the biomedical domain, there are
many studies on English corpora, which have
shown that using features extracted from clusters
constructed on unlabelled corpora improves per-
formance of NER models, especially when using
a smaller amount of training data (Miller et al.,
2004; Freitag, 2004). This approach has also been
shown to be successful for named entity recogni-
tion in other languages, e.g. German, Dutch and
Spanish (T¨ackstr¨om et al., 2012), as well as on
related NLP tasks (Biemann et al., 2007), and
there are NER tools that automatically incorpo-
rate features extracted from unsupervised methods
(Stanford, 2012). There are a number of addi-
tional studies within the biomedical domain, e.g.
using features from Brown and other clustering
approaches (Stenetorp et al., 2012) or from k-
means clustered vectors from a neural networks-
based word space implementation (Pyysalo et al.,
2014). Jonnalagadda et al. (2012) also present a
study in which unsupervised features are used for
training a model on the i2b2 challenge on con-
cepts, assertions, and relations corpus. As un-
annotated corpus, they used a corpus created by
extracting Medline abstracts that are indexed with
the publication type ”clinical trials”. They then
built a semantic representation of this corpus in
the form of a random indexing-based word space.
This representation was then used for extracting a
number of similar words to each word in the i2b2
challenge on concepts, assertions, and relations
corpus, which were used as features when training
a CRF system. The parameters of the random in-
dexing model were selected by letting the nearest
neighbours of a word vote for one of the UMLS
categories Medical Problem, Treatment and Test
according to the category of the neighbour, and by
comparing the category winning the vote to the ac-
tual category of the word. The authors motivate
their choice of using random indexing for creat-
ing features with that this method is scalable to
very large corpora without requiring large compu-
tational resources.
The method proposed here is similar to the
method used by Jonnalagadda et al. (2012). How-
ever, the focus of the proposed study is to explore
to what extent unsupervised features can help a
machine learning system trained only on very lit-
tle data. It is therefore not feasible to use the large
number of features that would be generated by
using neighbouring words, as that would require
a large training data set to ensure that there are
enough training examples for each generated fea-
ture. Therefore, the proposed method instead fur-
ther processes the word space model by construct-
ing clusters of semantically related words, thereby
reducing the number of generated features, similar
to the approach by Pyysalo et al. (2014).
</bodyText>
<sectionHeader confidence="0.986455" genericHeader="method">
3 Materials and previous results
</sectionHeader>
<bodyText confidence="0.999796777777778">
Texts from three different clinical sub-domains:
cardiac ICU (intensive care unit), orthopaedic ER
(emergency room), and internal medicine ER have
been annotated (Tables 1-3).1 All texts are written
in Swedish, and they all share the characteristics
of text types written under time pressure; all of
them containing many abbreviations and incom-
plete sentences. There are, however, also differ-
ences in e.g. what abbreviations are used and what
</bodyText>
<footnote confidence="0.9808438">
1Research on these texts aiming at extracting informa-
tion related to Disorders/Findings and Pharmaceutical Drugs
has been approved by the Regional Ethical Review Board
in Stockholm (Etikpr¨ovningsn¨amnden i Stockholm), permis-
sion number 2012/834-31/5.
</footnote>
<page confidence="0.997812">
22
</page>
<table confidence="0.542191333333333">
Data set: All
Entity category # entities (Unique)
Disorder 1088 (533)
Finding 1798 (1295)
Pharmaceuticals 1048 (497)
Body structure 461 (252)
</table>
<tableCaption confidence="0.998099">
Table 1: Annotated data, Cardiac ICU
</tableCaption>
<table confidence="0.947821">
Data set: All
Entity category # entities (Unique)
Disorder 1258 (541)
Finding 1439 (785)
Pharmaceuticals 880 (212)
Body structure 1324 (423)
</table>
<tableCaption confidence="0.999086">
Table 2: Annotated data, Orthopaedic ER
</tableCaption>
<bodyText confidence="0.997422294117647">
entities that are frequently mentioned.
The texts from cardiac ICU and orthopaedic ER
will be treated as existing annotations in a cur-
rent domain, whereas internal medicine ER will
be treated as the new target domain. Approxi-
mately a third of the texts from internal medicine
ER have been doubly annotated, and an evaluation
set has been created by manually resolving differ-
ences between the two annotators (Skeppstedt et
al., 2014). This evaluation subset will be used as
held-out data for evaluating the NER task.
The following four entity categories have been
annotated (Skeppstedt et al., 2014): (1) Disorder
(a disease or abnormal condition that is not mo-
mentary and that has an underlying pathological
process), (2) Finding (a symptom reported by the
patient, an observation made by the physician or
the result of a medical examination of the patient),
(3) Pharmaceutical Drug (not limited to generic
name or trade name, but includes also e.g. drugs
expressed by their effect, such as painkiller or
sleeping pill). (4) Body Structure (an anatomically
defined body part).
These three annotated corpora will be used in
the proposed study, together with a large corpus
of un-annotated text from which unsupervised fea-
tures will be extracted. This large corpus will be a
subset of the Stockholm EPR corpus (Dalianis et
al., 2009), which is a large corpus of clinical text
written in Swedish.
Named entity recognition on the internal
medicine ER part of the annotated corpus has al-
ready been studied, and results on the evaluation
set were an F-score of 0.81 for the entity Dis-
order, 0.69 for Finding, 0.88 for Pharmaceutical
Drug, 0.85 for Body Structure and 0.78 for the
combined category Disorder + Finding (Skeppst-
edt et al., 2014). Features used for training the
model on the development/training part of the in-
ternal medicine ER corpus were the lemma forms
of the words, their part of speech, their semantic
category in used vocabulary lists, their word con-
stituents (if the words were compounds) as well
as the orthographics of the words. A narrow con-
text window was used, as shown by the entries
marked in boldface in Figure 1. As terminologies,
the Swedish versions of SNOMED CT2, MeSH3,
ICD-104, the Swedish medical list FASS5 were
used, as well as a vocabulary list of non-medical
words, compiled from the Swedish Parole corpus
(Gellerstam et al., 2000).
</bodyText>
<sectionHeader confidence="0.985281" genericHeader="method">
4 Methodological background
</sectionHeader>
<bodyText confidence="0.99996175">
The proposed method consists of using the train-
ing data first for parameter setting (through n-
fold cross-validation) and thereafter for training a
model using the best parameters. This model is
then to be evaluated on held-out data. A number
of rounds with parameter setting and training will
be carried out, where each new round will make
use of an increasingly larger subset of the training
data. Two versions of parameter setting and model
training will be carried out for each round; one
using features obtained from unsupervised meth-
ods on un-annotated text and one in which such
features are not used. The results of the two ver-
sions are then to be compared, with the hypothesis
that the model incorporating unsupervised meth-
ods will perform better, at least for small training
data sizes.
To accomplish this, the proposed method makes
use of four main components: (1) A system for
training a NER model given features extracted
from an annotated corpus. As this component, a
conditional random fields (CRF) system will be
used. (2) A system for automatic parameter set-
ting. As a large number of models are to be con-
structed on different sizes of the training data, for
which optimal parameters are likely to differ, pa-
rameters for each set of training data has to be
determined automatically for it to be feasible to
</bodyText>
<footnote confidence="0.99999">
2www.ihtsdo.org
3mesh.kib.ki.se
4www.who.int/classifications/icd/en/
5www.fass.se
</footnote>
<page confidence="0.994561">
23
</page>
<table confidence="0.999851142857143">
Data set: Development Final evaluation
Entity category # entities (Unique) # entities
Disorder 1,317 (607) 681
Finding 2,540 (1,353) 1282
Pharmaceuticals 959 (350) 580
Body structure 497 (197) 253
Tokens in corpus 45,482 25,370
</table>
<tableCaption confidence="0.999934">
Table 3: Annotated entities, internal medicine ER
</tableCaption>
<figure confidence="0.4178483">
Token Lemma POS Termi- Compound Ortho- Cluster member- .. Cluster member- Category
nology graphics ship level 1 ship level n
DVT dvt noun disorder - - all upper #40 .. #39423 B-Disorder
patient patient noun person - - - #3 .. #23498 O
with with prep. parole - - - #14 .. #30892 O
chestpain chestpain noun finding chest pain - #40 .. #23409 B-Finding Current
and and conj. parole - - - - .. - O
problems problem noun finding - - - #40 .. #23409 B-Finding
to to prep. finding - - - - .. - I-Finding
breathe breathe verb finding - - - #90 .. #23409 I-Finding
</figure>
<figureCaption confidence="0.69026">
Figure 1: A hypothetical example sentence, with hypothetical features for training a machine learning
model. Features used in a previous medical named entity recognition study (Skeppstedt et al., 2014) on
this corpus are shown in boldface. The last column contains the entity category according to the manual
annotation.
</figureCaption>
<bodyText confidence="0.999808272727273">
carry out the experiments. (3) A system for rep-
resenting semantic similarity of the words in the
un-annotated corpus. As this component, a ran-
dom indexing based word space model will used.
(4) A system for turning the semantic representa-
tion of the word space model into features to use
for the NER model. As this component, clustering
will be used.
To give a methodological background, the theo-
retical foundation for the four components will be
described.
</bodyText>
<subsectionHeader confidence="0.998608">
4.1 Conditional random fields
</subsectionHeader>
<bodyText confidence="0.999973432432433">
Conditional random fields (CRF or CRFs), intro-
duced by Lafferty et al. (2001), is a machine learn-
ing method suitable for segmenting and labelling
sequential data and therefore often used for e.g.
named entity recognition. As described in the re-
lated research section, CRFs have been used in a
number of studies for extracting entities from clin-
ical text. In contrast to many other types of data,
observed data points for sequential data, such as
text, are dependent on other observed data points.
Such dependences between data points are prac-
tical to describe within the framework of graphi-
cal models (Bishop, 2006, p. 359), to which CRF
belongs (Sutton and McCallum, 2006, p. 1). In
the special, but frequently used, case of linear
chain CRF, the output variables are linked in a
chain. Apart from being dependent on the input
variables, each output variable is then condition-
ally independent on all other output variables, ex-
cept on the previous and following output variable,
given these two neighbouring output variables. In
a named entity recognition task, the output vari-
ables are the named entity classes that are to be
predicted and the observed input variables are ob-
served features of the text, such as the tokens or
their part-of-speech.
CRF is closely related to Hidden Markov Mod-
els, which is also typically described as a graph-
ical model. A difference, however, is that Hid-
den Markov Models belongs to the class of gener-
ative models, whereas CRF is a conditional model
(Sutton and McCallum, 2006, p. 1). Generative
models model the joint distribution between input
variables and the variables that are to be predicted
(Bishop, 2006, p. 43). In contrast, CRF and other
conditional models instead directly model the con-
ditional distribution, enabling the use of a larger
</bodyText>
<page confidence="0.994037">
24
</page>
<bodyText confidence="0.987559882352941">
feature set (Sutton and McCallum, 2006, p. 1).
For named entity recognition, the IOB-
encoding is typically used for encoding the out-
put variables. Tokens not annotated as an entity
are then encoded with the label O, whereas labels
for annotated tokens are prefixed with a B, if it
is the first token in the annotated chunk, and an
I otherwise (Jurafsky and Martin, 2008, pp. 763–
764). An example of this encoding is shown in the
last column in Figure 1. In this case, where there
are four types of entities, the model thus learns to
classify in 8+1 different classes: B-Disorder, I-
Disorder, B-Finding, I-Finding, B-Drug, I-Drug,
B-BodyStructure, I-BodyStructure and O.
The dependencies are defined by a large number
of (typically binary) feature functions of input and
output variables. E.g. is all of the following true?
</bodyText>
<listItem confidence="0.998683714285714">
• Output: The output at the current position is
I-Disorder
• Output: The output at the previous position is
B-Disorder
• Input: The token at the current position is
chest-pain
• Input: The token at the previous position is
</listItem>
<sectionHeader confidence="0.453053" genericHeader="method">
experiences
</sectionHeader>
<bodyText confidence="0.999952195652174">
A feature function in a linear chain CRF can
only include the values of the output variable in
current position and in the immediate previous po-
sition, whereas it can include, and thereby show a
dependence on, input variables from any position.
The CRF model is trained through setting
weights for the feature functions, which is carried
out by penalised maximum likelihood. Penalised
means that regularisation is used, and regularisa-
tion is performed by adding a penalty term, which
prevents the weights from reaching too large val-
ues, and thereby prevents over-fitting (Bishop,
2006, p. 10). The L1-norm and the L2-norm are
frequently used for regularisation (Tsuruoka et al.,
2009), and a variable C governs the importance
of the regularisation. Using the L1-norm also re-
sults in that if C is large enough, some of the
weights are driven to zero, resulting in a sparse
model and thereby the feature functions that those
weights control will not play any role in the model.
Thereby, complex models can be trained also on
data sets with a limited size, without being over-
fitted. However, a suitable value of C must still be
determined (Bishop, 2006, p. 145).
The plan for the proposed study is to use the
CRF package CRF++6, which has been used in a
number of previous NER studies, also in the med-
ical domain. The CRF++ package automatically
generates feature functions from user-defined tem-
plates. When using CRF++ as a linear chain CRF,
it generates one binary feature function for each
combination of output class, previous output class
and unique string in the training data that is ex-
panded by a template. This means that L * L *
M feature functions are generated for each tem-
plate, where L = the number of output classes and
M = the number of unique expanded strings. If
only the current token were to be used as a fea-
ture, the number of feature functions would be
9∗9∗|unique tokens in the corpus|. In practice,
a lot of other features are, however, used. Most of
these features will be of no use to the classifier,
which means that it is important to use an infer-
ence method that sets the weights of the feature
functions with irrelevant features to zero, thus an
inference method that promotes sparsity.
</bodyText>
<subsectionHeader confidence="0.990777">
4.2 Parameter setting
</subsectionHeader>
<bodyText confidence="0.999955807692308">
As previously explained, a large number of mod-
els are to be constructed, which requires a simple
and efficient method for parameter setting. An ad-
vantage with using the L1-norm is that only one
parameter, the C-value, has to be optimised, as the
weights for feature functions are driven to zero for
feature functions that are not useful. The L1-norm
will therefore be used in the proposed study. A
very large feature set can then be used, without
running the risk of over-fitting the model. Features
will include those that have been used in previous
clinical NER studies (Jonnalagadda et al., 2012;
de Bruijn et al., 2011; Skeppstedt et al., 2014),
with a context window of four previous and four
following tokens.
When maximising the conditional log likeli-
hood of the parameters, the CRF++ program will
set parameters that are optimal for training the
model for the best micro-averaged results for the
four classes Disorder, Finding, Pharmaceutical
drug and Body structure. A hill climbing search
(Marsland, 2009, pp. 262–264) for finding a good
C-value will be used, starting with a value very
close to zero and thereafter changing it in a direc-
tion that improves the NER results. A decreas-
ingly smaller step size will be used for changing
</bodyText>
<page confidence="0.696497">
6crfpp.sourceforge.net
25
</page>
<table confidence="0.991462857142857">
Lemmatised and stop word filtered with a window size of 2 (1+1):
complain dermatitis eczema itch patient
complain: [0 0 0 2 2]
dermatitis: [0 0 0 1 0]
eczema: [0 0 0 1 0]
itch: [2 1 1 0 0]
patient: [2 0 0 0 0]
1 2 3 ... d
... [0 0 1 ... 0]
complain: [0 0 0 ... 1]
itch: [0 1 1 ... 0]
patient: [-1 0 0 ... 0]
... [... ... ... ... ..]
word w [0 0 -1 ... 0]
</table>
<figureCaption confidence="0.961348833333333">
Figure 3: Index vectors.
Figure 2: Term-by-term co-occurrence matrix for
the small corpus ”Patient complains of itching der-
matitis. Patient complains of itching eczema.”
the C-value, until only small changes in the results
can be observed.
</figureCaption>
<subsectionHeader confidence="0.996716">
4.3 Random indexing
</subsectionHeader>
<bodyText confidence="0.999736026666667">
Random indexing is one version of the word space
model, and as all word space models it is a method
for representing distributional semantics. The ran-
dom indexing method was originally devised by
Kanerva et al. (2000), to deal with the performance
problems (in terms of memory and computation
time) that were associated with the LSA/LSI im-
plementations at that time. Due to its computa-
tional efficiency, random indexing remains to be
a popular method when building distributional se-
mantics models on very large corpora, e.g. large
web corpora (Sahlgren and Karlgren, 2009) or
Medline abstracts (Jonnalagadda et al., 2012).
Distributional semantics is built on the distribu-
tional hypothesis, which states that ”Words with
similar meanings tend to occur in similar con-
texts”. If dermatitis and eczema often occur in
similar contexts, e.g. ”Patient complains of itch-
ing dermatitis” and ”Patient complains of itching
eczema”, it is likely that dermatitis and eczema
have a similar meaning. One possible method
of representing word co-occurrence information is
to construct a term-by-term co-occurrence matrix,
i.e. a matrix of dimensionality w x w, in which w
is the number of terms (unique semantic units, e.g.
words) in the corpus. The elements of the matrix
then contain the number of times each semantic
unit occurs in the context of each other semantic
unit (figure 2).
The context vectors of two semantic units can
then be compared as a measure of semantic sim-
ilarity between units, e.g. using the the euclid-
ian distance between normalised context vectors
or the cosine similarity.
The large dimension of a term-by-term ma-
trix leads, however, to scalability problems, and
the typical solution to this is to apply dimen-
sionality reduction on the matrix. In a semantic
space created by latent semantic analysis, for in-
stance, dimensionality reduction is performed by
applying the linear algebra matrix operation sin-
gular value decomposition (Landauer and Dutnais,
1997). Random indexing is another solution, in
which a matrix with a smaller dimension is created
from start, using the following method (Sahlgren
et al., 2008):
Each term in the data is assigned a unique rep-
resentation, called an index vector. The index vec-
tors all have the dimensionality d (where d ≥ 1000
but « w). Most of the elements of the index vec-
tors are set to 0, but a few, randomly selected, el-
ements are set to either +1 or -1. (Usually around
1-2% of the elements.) Instead of having orthogo-
nal vectors, as is the case for the term-by-term ma-
trix, the index vectors are nearly orthogonal. (See
Figure 3.)
Each term in the data is also assigned a context
vector, also of the dimensionality d. Initially, all
elements in the context vectors are set to 0. The
context vector of each term is then updated by, for
every occurrence of the term in the corpus, adding
the index vectors of the neighboring words. The
neighboring words are called the context window,
and this can be both narrow or wide, depending on
what semantic relations the word space model is
intended to capture. The size of the context win-
dow can have large impact on the results (Sahlgren
et al., 2008), and for detecting paradigmatic re-
lations (i.e. words that occur in similar contexts,
rather than words that occur together) a fairly nar-
row context window has been shown to be most
effective.
The resulting context vectors form a matrix of
dimension w x d. This matrix is an approximation
of the term-by-term matrix, and the same similar-
</bodyText>
<page confidence="0.995868">
26
</page>
<table confidence="0.988840222222222">
Index vectors (never change)
... 1 2 3 ... d
itching: I0 1 1 ... 0]
patient: I-1 0 0 ... 0]
...
Context vectors
1 2 3 ... d
...
complain: I-1 1 1 ... 0]
</table>
<figureCaption confidence="0.996924">
Figure 4: The updated context vectors.
</figureCaption>
<bodyText confidence="0.716468916666667">
Measure similarity between two terms by e.g. cosine 0
Figure 5: Context vectors for terms in a hypothet-
ical word space with d=2. The context vectors for
the semantically similar words eczema and der-
matitis are close in the word space, in which close-
ness is measured as the cosine of the angle be-
tween the vectors. Four hypothetical clusters (C1-
C4) of context vectors are also shown; clusters that
contain a large proportion of known terms.
ity measures can be applied.
A hypothetical word space with d=2 is shown in
Figure 5.
</bodyText>
<subsectionHeader confidence="0.999431">
4.4 Clustering
</subsectionHeader>
<bodyText confidence="0.999986819672131">
As mentioned earlier, for the word space informa-
tion to be useful for training a CRF model on a
small data set, it must be represented as a feature
that can only take a limited number of different
values. The proposed methods for achieving this
is to cluster the context vectors of the word space
model, similar to what has been done in previous
research (Pyysalo et al., 2014). Also similar to
previous research, cluster membership for a word
in the NER training and test data will be used as a
feature. Four named hypothetical clusters of con-
text vectors are shown in the word space model
in Figure 5 to illustrate the general idea, and an
example of how to use cluster membership as a
feature is shown Figure 1.
Different clustering techniques will be evalu-
ated, for the quality of the created clusters, as well
as for their computational efficiency. Having hi-
erarchical clusters might be preferable, as clus-
ter membership to clusters of different granular-
ity then can be offered as features for training the
CRF model. Which granularity that is most suit-
able might vary depending on the entity type and
also depending on the size of the training data.
However, e.g. performing hierarchical agglomera-
tive clustering (Jurafsky and Martin, 2008, p. 700)
on the entire unlabelled corpus might be computa-
tionally intractable (thereby defeating the purpose
of using random indexing), as it requires pairwise
comparisons between the words in the corpus. The
pairwise comparison is a part of the agglomera-
tive clustering algorithm, in which each word is
first assigned its own cluster and then each pair of
clusters is compared for similarity, resulting in a
merge of the most similar clusters. This process
is thereafter iteratively repeated, having the dis-
tance between the centroids of the clusters as sim-
ilarity measure. An alternative, which requires a
less efficient clustering algorithm, would be to not
create clusters of all the words in the corpus, but
to limit initially created clusters to include those
words that occur in available terminologies. Clus-
ter membership of unknown words in the corpus
could then be determined by measuring similarity
to the centroids of these initially created clusters.
Regardless of what clustering technique that is
chosen, the parameters of the random indexing
models, as well as of the clustering, will be deter-
mined by evaluating to what extent words that be-
long to one of the studied semantic categories (ac-
cording to available terminologies) are clustered
together. This will be measured using purity and
inverse purity (Amig´o et al., 2009). However, if
clusters are to be created from all words in the cor-
pus, the true semantic category will only be known
for a very small subset of clustered words. In that
case, the two measures have to be defined as purity
being to what extent a cluster only contains known
words of one category and inverse purity being the
extent to which known words of the same category
are grouped into the same cluster.
</bodyText>
<figure confidence="0.99529025">
dermatitis
eczema
C1
C3
C2
0
C4
0
0
Known term from one entity category
Known term from an other entity category
Unknown term
</figure>
<page confidence="0.990781">
27
</page>
<sectionHeader confidence="0.959247" genericHeader="method">
5 Proposed experiments
</sectionHeader>
<bodyText confidence="0.99362725">
The first phase of the experiments will consist of
finding the best parameters for the random index-
ing model and the clustering, as described above.
The second phase will consist of evaluating the
usefulness of the clustered data for the NER task.
Three main experiments will be carried out in this
phase (I, II and III), using data set(s) from the fol-
lowing sources:
</bodyText>
<listItem confidence="0.6586615">
I: Internal medicine ER
II: Internal medicine ER + Cardiac ICU
III: Internal medicine ER + Orthopaedic ER
In each experiment, the following will be car-
ried out:
1. Divide internal medicine ER training data
</listItem>
<bodyText confidence="0.9962473">
into 5 partitions (into a random division, to
better simulate the situation when not all data
is available, using the same random division
for all experiments).
2. Run step 3-5 in 5 rounds. Each new round
uses one additional internal medicine ER par-
tition: (Experiments II and III always use the
entire data set from the other domain). In
each round, two versions of step 3-5 will be
carried out:
</bodyText>
<listItem confidence="0.92723575">
(a) With unsupervised features.
(b) Without unsupervised features.
3. Use training data for determining C-value (by
n-fold cross-validation).
4. Use training data for training a model with
this C-value.
5. Evaluate the model on the held-out internal
medicine ICU data.
</listItem>
<sectionHeader confidence="0.996498" genericHeader="method">
6 Open issues
</sectionHeader>
<bodyText confidence="0.974453948717949">
What clustering technique to use has previously
been mentioned as one important open issue. The
following are examples of other open issues:
• Could the information obtained from random
indexing be used in some other way than as
transformed to cluster membership features?
Jonnalagadda et al. (2012) used the terms
closest in the semantic space as a feature.
Could this method be adapted in some way
to models constructed with a small amount
of training data? For instance by restricting
what terms are allowed to be used as such a
feature, and thereby limiting the number of
possible values this feature can take.
• Would it be better to use other approaches (or
compare different approaches) for obtaining
features from unlabelled data? A possibil-
ity could be to use a more standard cluster-
ing approach, such as Brown clustering used
in previous clinical NER studies (de Bruijn
et al., 2011). Another possibility could be to
keep the idea of creating clusters from vec-
tors in a word space model, but to use other
methods than random indexing for construct-
ing the word space; e.g. the previously men-
tioned latent semantic analysis (Landauer and
Dutnais, 1997), or a neural networks-based
word space implementation (Pyysalo et al.,
2014).
• Many relevant terms within the medical do-
main are multi-word terms (e.g. of the type
diabetes mellitus), and there are studies on
how to construct semantic spaces with such
multiword terms as the smallest semantic
unit (Henriksson et al., 2013). Should the
whitespace segmented token be treated as the
smallest semantic unit in the proposed study,
or should the use of larger semantic units be
considered?
</bodyText>
<sectionHeader confidence="0.994955" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999537666666667">
Many thanks to Aron Henriksson, Alyaa Alfalahi,
Maria Kvist, Gunnar Nilsson and Hercules Dalia-
nis for taking a very active part in the planing of
the proposed study, as well as to the three anony-
mous reviewers for their constructive and detailed
comments.
</bodyText>
<sectionHeader confidence="0.998991" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998277333333333">
Enrique Amig´o, Julio Gonzalo, Javier Artiles, and Fe-
lisa Verdejo. 2009. A comparison of extrinsic
clustering evaluation metrics based on formal con-
straints. Inf. Retr., 12(4):461–486, aug.
Chris Biemann, Claudio Giuliano, and Alfio Gliozzo.
2007. Unsupervised part of speech tagging support-
ing supervised methods. In RANLP.
Christopher M. Bishop. 2006. Pattern recognition and
machine learning. Springer, New York, NY.
</reference>
<page confidence="0.992005">
28
</page>
<reference confidence="0.991556083333333">
Hercules Dalianis, Martin Hassel, and Sumithra
Velupillai. 2009. The Stockholm EPR Corpus -
Characteristics and Some Initial Findings. In Pro-
ceedings of ISHIMR 2009, Evaluation and imple-
mentation of e-health and health information initia-
tives: international perspectives. 14th International
Symposium for Health Information Management Re-
search, Kalmar, Sweden, pages 243–249.
Berry de Bruijn, Colin Cherry, Svetlana Kiritchenko,
Joel D. Martin, and Xiaodan Zhu. 2011. Machine-
learned solutions for three stages of clinical infor-
mation extraction: the state of the art at i2b2 2010.
JAm Med Inform Assoc, 18(5):557–562.
Son Doan, Nigel Collier, Hua Xu, Hoang Duy Pham,
and Minh Phuong Tu. 2012. Recognition of medi-
cation information from discharge summaries using
ensembles of classifiers. BMC Med Inform Decis
Mak, 12:36.
Dayne Freitag. 2004. Trained named entity recogni-
tion using distributional clusters. In EMNLP, pages
262–269.
M Gellerstam, Y Cederholm, and T Rasmark. 2000.
The bank of Swedish. In LREC 2000. The 2nd In-
ternational Conference on Language Resources and
Evaluation, pages 329–333, Athens, Greece.
Aron Henriksson, Mike Conway, Martin Duneld, and
Wendy W. Chapman. 2013. Identifying syn-
onymy between SNOMED clinical terms of vary-
ing length using distributional analysis of electronic
health records. In Proceedings of the Annual Sym-
posium of the American Medical Informatics Asso-
ciation (AMIA 2013), Washington DC, USA.
Siddhartha Jonnalagadda, Trevor Cohen, Stephen Wu,
and Graciela Gonzalez. 2012. Enhancing clinical
concept extraction with distributional semantics. J
Biomed Inform, 45(1):129–40, Feb.
Daniel Jurafsky and James H. Martin. 2008. Speech
and Language Processing: An Introduction to Nat-
ural Language Processing, Computational Linguis-
tics and Speech Recognition. Prentice Hall, second
edition, February.
Pentti Kanerva, Jan Kristoferson, and Anders Holst.
2000. Random indexing of text samples for latent
semantic analysis. In L. R. Gleitman and A. K.
Joshi, editors, Proceedings of the 22nd Annual Con-
ference of the Cognitive Science Society, Mahwah,
NJ.
John Lafferty, Andrew McCallum, and Fernando
Pereira. 2001. Conditional random fields: Prob-
abilistic models for segmenting and labeling se-
quence data. In Proc. 18th International Conf. on
Machine Learning, pages 282–289. Morgan Kauf-
mann, San Francisco, CA.
Thomas K Landauer and Susan T. Dutnais. 1997. A
solution to Plato’s problem: The latent semantic
analysis theory of acquisition, induction, and rep-
resentation of knowledge. Psychological review,
pages 211–240.
Stephen Marsland. 2009. Machine learning : an algo-
rithmic perspective. Chapman &amp; Hall/CRC, Boca
Raton, FL.
David Martinez, Lawrence Cavedon, and Graham Pit-
son. 2013. Stability of text mining techniques for
identifying cancer staging. In Proceedings of the 4th
International Louhi Workshop on Health Document
Text Mining and Information Analysis - Louhi 2013,
Sydney, Australia, February.
Scott Miller, Jethran Guinness, and Alex Zamanian.
2004. Name tagging with word clusters and dis-
criminative training. In Proceedings of HLT, pages
337–342.
Jon Patrick and Min Li. 2010. High accuracy infor-
mation extraction of medication information from
clinical notes: 2009 i2b2 medication extraction chal-
lenge. J Am Med Inform Assoc, 17(5):524–527,
Sep-Oct.
Sampo Pyysalo, Filip Ginter, Hans Moen, Tapio
Salakoski, and Sophia Ananiadou. 2014. Distribu-
tional semantics resources for biomedical text pro-
cessing. In Proceedings of Languages in Biology
and Medicine.
Angus Roberts, Robert Gaizasukas, Mark Hepple, and
Yikun Guo. 2008. Combining terminology re-
sources and statistical methods for entity recogni-
tion: an evaluation. In Proceedings of the Sixth
International Conference on Language Resources
and Evaluation (LREC’08), pages 2974–2979, Mar-
rakech, Morocco, may. European Language Re-
sources Association (ELRA). http://www.lrec-
conf.org/proceedings/lrec2008/.
Magnus Sahlgren and Jussi Karlgren. 2009. Termi-
nology mining in social media. In Proceedings of
the 18th ACM conference on Information and knowl-
edge management, CIKM ’09.
Magnus Sahlgren, Anders Holst, and Pentti Kanerva.
2008. Permutations as a means to encode order
in word space. In Proceedings of the 30th An-
nual Meeting of the Cognitive Science Society, pages
1300–1305.
Maria Skeppstedt, Maria Kvist, Gunnar H Nilsson, and
Hercules Dalianis. 2014. Automatic recognition of
disorders, findings, pharmaceuticals and body struc-
tures from clinical text: An annotation and machine
learning study. J Biomed Inform, Feb (in press).
NLP Group Stanford. 2012. Stanford Named
Entity Recognizer (NER). http://www-
nlp.stanford.edu/software/CRF-NER.shtml. Ac-
cessed 2012-03-29.
</reference>
<page confidence="0.975772">
29
</page>
<reference confidence="0.9997415">
Pontus Stenetorp, Hubert Soyer, Sampo Pyysalo,
Sophia Ananiadou, and Takashi Chikayama. 2012.
Size (and domain) matters: Evaluating semantic
word space representations for biomedical text. In
Proceedings of the 5th International Symposium on
Semantic Mining in Biomedicine.
Charles. Sutton and Andrew McCallum. 2006. An in-
troduction to conditional random fields for relational
learning. In Lise Getoor and Ben Taskar, editors,
Introduction to Statistical Relational Learning. MIT
Press.
Oscar T¨ackstr¨om, Ryan McDonald, and Jakob Uszko-
reit. 2012. Cross-lingual Word Clusters for Direct
Transfer of Linguistic Structure. In Proceedings of
the 2012 Conference of the North American Chap-
ter of the Association for Computational Linguis-
tics: Human Language Technologies, pages 477–
487, Montr´eal, Canada, June. Association for Com-
putational Linguistics.
Yoshimasa Tsuruoka, Jun’ichi Tsujii, and Sophia Ana-
niadou. 2009. Fast full parsing by linear-chain con-
ditional random fields. In Proceedings of the 12th
Conference of the European Chapter of the Asso-
ciation for Computational Linguistics, EACL ’09,
pages 790–798, Stroudsburg, PA, USA. Association
for Computational Linguistics.
¨Ozlem. Uzuner, Brett R. South, Shuying Shen, and
Scott L. DuVall. 2011. 2010 i2b2/va challenge on
concepts, assertions, and relations in clinical text. J
Am Med Inform Assoc, 18(5):552–556.
Yefeng Wang and Jon Patrick. 2009. Cascading clas-
sifiers for named entity recognition in clinical notes.
In Proceedings of the Workshop on Biomedical In-
formation Extraction, pages 42–49.
Yefeng Wang. 2009. Annotating and recognising
named entities in clinical notes. In Proceedings of
the ACL-IJCNLP Student Research Workshop, pages
18–26, Singapore.
</reference>
<page confidence="0.998806">
30
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.830422">
<title confidence="0.9990175">Enhancing Medical Named Entity with Features Derived from Unsupervised Methods</title>
<author confidence="0.987962">Maria</author>
<affiliation confidence="0.9681835">Dept. of Computer and Systems Sciences Stockholm University, Forum 100, 164 40 Kista,</affiliation>
<email confidence="0.9526">mariask@dsv.su.se</email>
<abstract confidence="0.996558">A study of the usefulness of features extracted from unsupervised methods is proposed. The usefulness of these features will be studied on the task of performing named entity recognition within one clinical sub-domain as well as on the task of adapting a named entity recognition model to a new clinical sub-domain. Four named entity types, all very relevant for clinical information extraction, will be studied: Disorder, Finding, Pharmaceutical Drug and Body Structure. The named entity recognition will be performed using conditional random fields. As unsupervised features, a clustering of the semantic representation of words obtained from a random indexing word space will be used.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Enrique Amig´o</author>
<author>Julio Gonzalo</author>
<author>Javier Artiles</author>
<author>Felisa Verdejo</author>
</authors>
<title>A comparison of extrinsic clustering evaluation metrics based on formal constraints.</title>
<date>2009</date>
<journal>Inf. Retr.,</journal>
<volume>12</volume>
<issue>4</issue>
<marker>Amig´o, Gonzalo, Artiles, Verdejo, 2009</marker>
<rawString>Enrique Amig´o, Julio Gonzalo, Javier Artiles, and Felisa Verdejo. 2009. A comparison of extrinsic clustering evaluation metrics based on formal constraints. Inf. Retr., 12(4):461–486, aug.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Biemann</author>
<author>Claudio Giuliano</author>
<author>Alfio Gliozzo</author>
</authors>
<title>Unsupervised part of speech tagging supporting supervised methods.</title>
<date>2007</date>
<booktitle>In RANLP.</booktitle>
<contexts>
<context position="5566" citStr="Biemann et al., 2007" startWordPosition="884" endWordPosition="887">ey used Brown clustering, and represented the feature as a 7-bit showing to what cluster a word belonged. Outside of the biomedical domain, there are many studies on English corpora, which have shown that using features extracted from clusters constructed on unlabelled corpora improves performance of NER models, especially when using a smaller amount of training data (Miller et al., 2004; Freitag, 2004). This approach has also been shown to be successful for named entity recognition in other languages, e.g. German, Dutch and Spanish (T¨ackstr¨om et al., 2012), as well as on related NLP tasks (Biemann et al., 2007), and there are NER tools that automatically incorporate features extracted from unsupervised methods (Stanford, 2012). There are a number of additional studies within the biomedical domain, e.g. using features from Brown and other clustering approaches (Stenetorp et al., 2012) or from kmeans clustered vectors from a neural networksbased word space implementation (Pyysalo et al., 2014). Jonnalagadda et al. (2012) also present a study in which unsupervised features are used for training a model on the i2b2 challenge on concepts, assertions, and relations corpus. As unannotated corpus, they used</context>
</contexts>
<marker>Biemann, Giuliano, Gliozzo, 2007</marker>
<rawString>Chris Biemann, Claudio Giuliano, and Alfio Gliozzo. 2007. Unsupervised part of speech tagging supporting supervised methods. In RANLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher M Bishop</author>
</authors>
<title>Pattern recognition and machine learning.</title>
<date>2006</date>
<publisher>Springer,</publisher>
<location>New York, NY.</location>
<contexts>
<context position="14962" citStr="Bishop, 2006" startWordPosition="2422" endWordPosition="2423">nditional random fields (CRF or CRFs), introduced by Lafferty et al. (2001), is a machine learning method suitable for segmenting and labelling sequential data and therefore often used for e.g. named entity recognition. As described in the related research section, CRFs have been used in a number of studies for extracting entities from clinical text. In contrast to many other types of data, observed data points for sequential data, such as text, are dependent on other observed data points. Such dependences between data points are practical to describe within the framework of graphical models (Bishop, 2006, p. 359), to which CRF belongs (Sutton and McCallum, 2006, p. 1). In the special, but frequently used, case of linear chain CRF, the output variables are linked in a chain. Apart from being dependent on the input variables, each output variable is then conditionally independent on all other output variables, except on the previous and following output variable, given these two neighbouring output variables. In a named entity recognition task, the output variables are the named entity classes that are to be predicted and the observed input variables are observed features of the text, such as t</context>
<context position="17775" citStr="Bishop, 2006" startWordPosition="2890" endWordPosition="2891">ous position is experiences A feature function in a linear chain CRF can only include the values of the output variable in current position and in the immediate previous position, whereas it can include, and thereby show a dependence on, input variables from any position. The CRF model is trained through setting weights for the feature functions, which is carried out by penalised maximum likelihood. Penalised means that regularisation is used, and regularisation is performed by adding a penalty term, which prevents the weights from reaching too large values, and thereby prevents over-fitting (Bishop, 2006, p. 10). The L1-norm and the L2-norm are frequently used for regularisation (Tsuruoka et al., 2009), and a variable C governs the importance of the regularisation. Using the L1-norm also results in that if C is large enough, some of the weights are driven to zero, resulting in a sparse model and thereby the feature functions that those weights control will not play any role in the model. Thereby, complex models can be trained also on data sets with a limited size, without being overfitted. However, a suitable value of C must still be determined (Bishop, 2006, p. 145). The plan for the propose</context>
</contexts>
<marker>Bishop, 2006</marker>
<rawString>Christopher M. Bishop. 2006. Pattern recognition and machine learning. Springer, New York, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hercules Dalianis</author>
<author>Martin Hassel</author>
<author>Sumithra Velupillai</author>
</authors>
<title>The Stockholm EPR Corpus -Characteristics and Some Initial Findings.</title>
<date>2009</date>
<booktitle>In Proceedings of ISHIMR 2009, Evaluation and implementation of e-health and health information initiatives: international perspectives. 14th International Symposium for Health Information Management Research,</booktitle>
<pages>243--249</pages>
<location>Kalmar, Sweden,</location>
<contexts>
<context position="10234" citStr="Dalianis et al., 2009" startWordPosition="1628" endWordPosition="1631">rocess), (2) Finding (a symptom reported by the patient, an observation made by the physician or the result of a medical examination of the patient), (3) Pharmaceutical Drug (not limited to generic name or trade name, but includes also e.g. drugs expressed by their effect, such as painkiller or sleeping pill). (4) Body Structure (an anatomically defined body part). These three annotated corpora will be used in the proposed study, together with a large corpus of un-annotated text from which unsupervised features will be extracted. This large corpus will be a subset of the Stockholm EPR corpus (Dalianis et al., 2009), which is a large corpus of clinical text written in Swedish. Named entity recognition on the internal medicine ER part of the annotated corpus has already been studied, and results on the evaluation set were an F-score of 0.81 for the entity Disorder, 0.69 for Finding, 0.88 for Pharmaceutical Drug, 0.85 for Body Structure and 0.78 for the combined category Disorder + Finding (Skeppstedt et al., 2014). Features used for training the model on the development/training part of the internal medicine ER corpus were the lemma forms of the words, their part of speech, their semantic category in used</context>
</contexts>
<marker>Dalianis, Hassel, Velupillai, 2009</marker>
<rawString>Hercules Dalianis, Martin Hassel, and Sumithra Velupillai. 2009. The Stockholm EPR Corpus -Characteristics and Some Initial Findings. In Proceedings of ISHIMR 2009, Evaluation and implementation of e-health and health information initiatives: international perspectives. 14th International Symposium for Health Information Management Research, Kalmar, Sweden, pages 243–249.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Berry de Bruijn</author>
<author>Colin Cherry</author>
<author>Svetlana Kiritchenko</author>
<author>Joel D Martin</author>
<author>Xiaodan Zhu</author>
</authors>
<title>Machinelearned solutions for three stages of clinical information extraction: the state of the art at i2b2 2010. JAm Med Inform Assoc,</title>
<date>2011</date>
<marker>de Bruijn, Cherry, Kiritchenko, Martin, Zhu, 2011</marker>
<rawString>Berry de Bruijn, Colin Cherry, Svetlana Kiritchenko, Joel D. Martin, and Xiaodan Zhu. 2011. Machinelearned solutions for three stages of clinical information extraction: the state of the art at i2b2 2010. JAm Med Inform Assoc, 18(5):557–562.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Son Doan</author>
<author>Nigel Collier</author>
<author>Hua Xu</author>
<author>Hoang Duy Pham</author>
<author>Minh Phuong Tu</author>
</authors>
<title>Recognition of medication information from discharge summaries using ensembles of classifiers.</title>
<date>2012</date>
<journal>BMC Med Inform Decis Mak,</journal>
<pages>12--36</pages>
<contexts>
<context position="4258" citStr="Doan et al., 2012" startWordPosition="679" endWordPosition="682">ational Linguistics Drug/Device and Locus was used for training a support vector machine with uneven margins (Roberts et al., 2008) and a corpus annotated for the entities Finding, Substance and Body was used for training a conditional random fields (CRF) system (Wang, 2009) as well as for training an ensemble of different classifiers (Wang and Patrick, 2009). Most studies have, however, been conducted on the i2b2 medication challenge corpus and the i2b2 challenge on concepts, assertions, and relations corpus. Conditional random fields (Patrick and Li, 2010) as well as an ensemble classifier (Doan et al., 2012) has for instance been used for extracting the entity Medication names from the medication challenge corpus, while all but the best among the top-performing systems used CRF for extracting the entities Medical Problem, Test and Treatment from the i2b2 challenge on concepts, assertions, and relations corpus (Uzuner et al., 2011). The best system (de Bruijn et al., 2011) used semi-Markov HMM, and in addition to the features used by most of the other systems (e.g. tokens/lemmas/stems, orthographics, affixes, partof-speech, output of terminology matching), this system also used features extracted </context>
</contexts>
<marker>Doan, Collier, Xu, Pham, Tu, 2012</marker>
<rawString>Son Doan, Nigel Collier, Hua Xu, Hoang Duy Pham, and Minh Phuong Tu. 2012. Recognition of medication information from discharge summaries using ensembles of classifiers. BMC Med Inform Decis Mak, 12:36.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dayne Freitag</author>
</authors>
<title>Trained named entity recognition using distributional clusters.</title>
<date>2004</date>
<booktitle>In EMNLP,</booktitle>
<pages>262--269</pages>
<contexts>
<context position="5351" citStr="Freitag, 2004" startWordPosition="849" endWordPosition="850">/stems, orthographics, affixes, partof-speech, output of terminology matching), this system also used features extracted from hierarchical word clusters on un-annotated text. For constructing the clusters, they used Brown clustering, and represented the feature as a 7-bit showing to what cluster a word belonged. Outside of the biomedical domain, there are many studies on English corpora, which have shown that using features extracted from clusters constructed on unlabelled corpora improves performance of NER models, especially when using a smaller amount of training data (Miller et al., 2004; Freitag, 2004). This approach has also been shown to be successful for named entity recognition in other languages, e.g. German, Dutch and Spanish (T¨ackstr¨om et al., 2012), as well as on related NLP tasks (Biemann et al., 2007), and there are NER tools that automatically incorporate features extracted from unsupervised methods (Stanford, 2012). There are a number of additional studies within the biomedical domain, e.g. using features from Brown and other clustering approaches (Stenetorp et al., 2012) or from kmeans clustered vectors from a neural networksbased word space implementation (Pyysalo et al., 20</context>
</contexts>
<marker>Freitag, 2004</marker>
<rawString>Dayne Freitag. 2004. Trained named entity recognition using distributional clusters. In EMNLP, pages 262–269.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Gellerstam</author>
<author>Y Cederholm</author>
<author>T Rasmark</author>
</authors>
<title>The bank of Swedish.</title>
<date>2000</date>
<booktitle>In LREC 2000. The 2nd International Conference on Language Resources and Evaluation,</booktitle>
<pages>329--333</pages>
<location>Athens, Greece.</location>
<contexts>
<context position="11268" citStr="Gellerstam et al., 2000" startWordPosition="1804" endWordPosition="1807">tures used for training the model on the development/training part of the internal medicine ER corpus were the lemma forms of the words, their part of speech, their semantic category in used vocabulary lists, their word constituents (if the words were compounds) as well as the orthographics of the words. A narrow context window was used, as shown by the entries marked in boldface in Figure 1. As terminologies, the Swedish versions of SNOMED CT2, MeSH3, ICD-104, the Swedish medical list FASS5 were used, as well as a vocabulary list of non-medical words, compiled from the Swedish Parole corpus (Gellerstam et al., 2000). 4 Methodological background The proposed method consists of using the training data first for parameter setting (through nfold cross-validation) and thereafter for training a model using the best parameters. This model is then to be evaluated on held-out data. A number of rounds with parameter setting and training will be carried out, where each new round will make use of an increasingly larger subset of the training data. Two versions of parameter setting and model training will be carried out for each round; one using features obtained from unsupervised methods on un-annotated text and one</context>
</contexts>
<marker>Gellerstam, Cederholm, Rasmark, 2000</marker>
<rawString>M Gellerstam, Y Cederholm, and T Rasmark. 2000. The bank of Swedish. In LREC 2000. The 2nd International Conference on Language Resources and Evaluation, pages 329–333, Athens, Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aron Henriksson</author>
<author>Mike Conway</author>
<author>Martin Duneld</author>
<author>Wendy W Chapman</author>
</authors>
<title>Identifying synonymy between SNOMED clinical terms of varying length using distributional analysis of electronic health records.</title>
<date>2013</date>
<booktitle>In Proceedings of the Annual Symposium of the American Medical Informatics Association (AMIA 2013),</booktitle>
<location>Washington DC, USA.</location>
<marker>Henriksson, Conway, Duneld, Chapman, 2013</marker>
<rawString>Aron Henriksson, Mike Conway, Martin Duneld, and Wendy W. Chapman. 2013. Identifying synonymy between SNOMED clinical terms of varying length using distributional analysis of electronic health records. In Proceedings of the Annual Symposium of the American Medical Informatics Association (AMIA 2013), Washington DC, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Siddhartha Jonnalagadda</author>
<author>Trevor Cohen</author>
<author>Stephen Wu</author>
<author>Graciela Gonzalez</author>
</authors>
<title>Enhancing clinical concept extraction with distributional semantics.</title>
<date>2012</date>
<journal>J Biomed Inform,</journal>
<volume>45</volume>
<issue>1</issue>
<contexts>
<context position="1485" citStr="Jonnalagadda et al., 2012" startWordPosition="222" endWordPosition="225">words obtained from a random indexing word space will be used. 1 Introduction Creating the annotated corpus needed for training a NER (named entity recognition) model is costly. This is particularly the case for texts in specialised domains, for which expert annotators are often required. In addition, the need for expert annotators also limits the possibilities of using crowdsourcing approaches (e.g. Amazon Mechanical Turk). Features from unsupervised machine-learning methods, for which no labelled training data is required, have, however, been shown to improve the performance of NER systems (Jonnalagadda et al., 2012). It is therefore likely that by incorporating features from unsupervised methods, it is possible to reduce the amount of training data needed to achieve a fixed level of performance. Due to differences in the use of language, an NLP system developed for, or trained on, text from one sub-domain often shows a drop in performance when applied on texts from another subdomain (Martinez et al., 2013). This has the effect that when performing NER on a new subdomain, annotated text from this new targeted subdomain might be required, even when there are annotated corpora from other domains. It would, </context>
<context position="5982" citStr="Jonnalagadda et al. (2012)" startWordPosition="947" endWordPosition="950">s approach has also been shown to be successful for named entity recognition in other languages, e.g. German, Dutch and Spanish (T¨ackstr¨om et al., 2012), as well as on related NLP tasks (Biemann et al., 2007), and there are NER tools that automatically incorporate features extracted from unsupervised methods (Stanford, 2012). There are a number of additional studies within the biomedical domain, e.g. using features from Brown and other clustering approaches (Stenetorp et al., 2012) or from kmeans clustered vectors from a neural networksbased word space implementation (Pyysalo et al., 2014). Jonnalagadda et al. (2012) also present a study in which unsupervised features are used for training a model on the i2b2 challenge on concepts, assertions, and relations corpus. As unannotated corpus, they used a corpus created by extracting Medline abstracts that are indexed with the publication type ”clinical trials”. They then built a semantic representation of this corpus in the form of a random indexing-based word space. This representation was then used for extracting a number of similar words to each word in the i2b2 challenge on concepts, assertions, and relations corpus, which were used as features when traini</context>
<context position="20025" citStr="Jonnalagadda et al., 2012" startWordPosition="3284" endWordPosition="3287">ity. 4.2 Parameter setting As previously explained, a large number of models are to be constructed, which requires a simple and efficient method for parameter setting. An advantage with using the L1-norm is that only one parameter, the C-value, has to be optimised, as the weights for feature functions are driven to zero for feature functions that are not useful. The L1-norm will therefore be used in the proposed study. A very large feature set can then be used, without running the risk of over-fitting the model. Features will include those that have been used in previous clinical NER studies (Jonnalagadda et al., 2012; de Bruijn et al., 2011; Skeppstedt et al., 2014), with a context window of four previous and four following tokens. When maximising the conditional log likelihood of the parameters, the CRF++ program will set parameters that are optimal for training the model for the best micro-averaged results for the four classes Disorder, Finding, Pharmaceutical drug and Body structure. A hill climbing search (Marsland, 2009, pp. 262–264) for finding a good C-value will be used, starting with a value very close to zero and thereafter changing it in a direction that improves the NER results. A decreasingly</context>
<context position="21932" citStr="Jonnalagadda et al., 2012" startWordPosition="3621" endWordPosition="3624">xing Random indexing is one version of the word space model, and as all word space models it is a method for representing distributional semantics. The random indexing method was originally devised by Kanerva et al. (2000), to deal with the performance problems (in terms of memory and computation time) that were associated with the LSA/LSI implementations at that time. Due to its computational efficiency, random indexing remains to be a popular method when building distributional semantics models on very large corpora, e.g. large web corpora (Sahlgren and Karlgren, 2009) or Medline abstracts (Jonnalagadda et al., 2012). Distributional semantics is built on the distributional hypothesis, which states that ”Words with similar meanings tend to occur in similar contexts”. If dermatitis and eczema often occur in similar contexts, e.g. ”Patient complains of itching dermatitis” and ”Patient complains of itching eczema”, it is likely that dermatitis and eczema have a similar meaning. One possible method of representing word co-occurrence information is to construct a term-by-term co-occurrence matrix, i.e. a matrix of dimensionality w x w, in which w is the number of terms (unique semantic units, e.g. words) in the</context>
<context position="30233" citStr="Jonnalagadda et al. (2012)" startWordPosition="5037" endWordPosition="5040">o versions of step 3-5 will be carried out: (a) With unsupervised features. (b) Without unsupervised features. 3. Use training data for determining C-value (by n-fold cross-validation). 4. Use training data for training a model with this C-value. 5. Evaluate the model on the held-out internal medicine ICU data. 6 Open issues What clustering technique to use has previously been mentioned as one important open issue. The following are examples of other open issues: • Could the information obtained from random indexing be used in some other way than as transformed to cluster membership features? Jonnalagadda et al. (2012) used the terms closest in the semantic space as a feature. Could this method be adapted in some way to models constructed with a small amount of training data? For instance by restricting what terms are allowed to be used as such a feature, and thereby limiting the number of possible values this feature can take. • Would it be better to use other approaches (or compare different approaches) for obtaining features from unlabelled data? A possibility could be to use a more standard clustering approach, such as Brown clustering used in previous clinical NER studies (de Bruijn et al., 2011). Anot</context>
</contexts>
<marker>Jonnalagadda, Cohen, Wu, Gonzalez, 2012</marker>
<rawString>Siddhartha Jonnalagadda, Trevor Cohen, Stephen Wu, and Graciela Gonzalez. 2012. Enhancing clinical concept extraction with distributional semantics. J Biomed Inform, 45(1):129–40, Feb.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Jurafsky</author>
<author>James H Martin</author>
</authors>
<title>Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics and Speech Recognition.</title>
<date>2008</date>
<publisher>Prentice Hall,</publisher>
<note>second edition,</note>
<contexts>
<context position="16502" citStr="Jurafsky and Martin, 2008" startWordPosition="2681" endWordPosition="2684">models model the joint distribution between input variables and the variables that are to be predicted (Bishop, 2006, p. 43). In contrast, CRF and other conditional models instead directly model the conditional distribution, enabling the use of a larger 24 feature set (Sutton and McCallum, 2006, p. 1). For named entity recognition, the IOBencoding is typically used for encoding the output variables. Tokens not annotated as an entity are then encoded with the label O, whereas labels for annotated tokens are prefixed with a B, if it is the first token in the annotated chunk, and an I otherwise (Jurafsky and Martin, 2008, pp. 763– 764). An example of this encoding is shown in the last column in Figure 1. In this case, where there are four types of entities, the model thus learns to classify in 8+1 different classes: B-Disorder, IDisorder, B-Finding, I-Finding, B-Drug, I-Drug, B-BodyStructure, I-BodyStructure and O. The dependencies are defined by a large number of (typically binary) feature functions of input and output variables. E.g. is all of the following true? • Output: The output at the current position is I-Disorder • Output: The output at the previous position is B-Disorder • Input: The token at the c</context>
<context position="26778" citStr="Jurafsky and Martin, 2008" startWordPosition="4460" endWordPosition="4463"> general idea, and an example of how to use cluster membership as a feature is shown Figure 1. Different clustering techniques will be evaluated, for the quality of the created clusters, as well as for their computational efficiency. Having hierarchical clusters might be preferable, as cluster membership to clusters of different granularity then can be offered as features for training the CRF model. Which granularity that is most suitable might vary depending on the entity type and also depending on the size of the training data. However, e.g. performing hierarchical agglomerative clustering (Jurafsky and Martin, 2008, p. 700) on the entire unlabelled corpus might be computationally intractable (thereby defeating the purpose of using random indexing), as it requires pairwise comparisons between the words in the corpus. The pairwise comparison is a part of the agglomerative clustering algorithm, in which each word is first assigned its own cluster and then each pair of clusters is compared for similarity, resulting in a merge of the most similar clusters. This process is thereafter iteratively repeated, having the distance between the centroids of the clusters as similarity measure. An alternative, which re</context>
</contexts>
<marker>Jurafsky, Martin, 2008</marker>
<rawString>Daniel Jurafsky and James H. Martin. 2008. Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics and Speech Recognition. Prentice Hall, second edition, February.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pentti Kanerva</author>
<author>Jan Kristoferson</author>
<author>Anders Holst</author>
</authors>
<title>Random indexing of text samples for latent semantic analysis.</title>
<date>2000</date>
<booktitle>Proceedings of the 22nd Annual Conference of the Cognitive Science Society,</booktitle>
<editor>In L. R. Gleitman and A. K. Joshi, editors,</editor>
<location>Mahwah, NJ.</location>
<contexts>
<context position="21528" citStr="Kanerva et al. (2000)" startWordPosition="3558" endWordPosition="3561"> 2 3 ... d ... [0 0 1 ... 0] complain: [0 0 0 ... 1] itch: [0 1 1 ... 0] patient: [-1 0 0 ... 0] ... [... ... ... ... ..] word w [0 0 -1 ... 0] Figure 3: Index vectors. Figure 2: Term-by-term co-occurrence matrix for the small corpus ”Patient complains of itching dermatitis. Patient complains of itching eczema.” the C-value, until only small changes in the results can be observed. 4.3 Random indexing Random indexing is one version of the word space model, and as all word space models it is a method for representing distributional semantics. The random indexing method was originally devised by Kanerva et al. (2000), to deal with the performance problems (in terms of memory and computation time) that were associated with the LSA/LSI implementations at that time. Due to its computational efficiency, random indexing remains to be a popular method when building distributional semantics models on very large corpora, e.g. large web corpora (Sahlgren and Karlgren, 2009) or Medline abstracts (Jonnalagadda et al., 2012). Distributional semantics is built on the distributional hypothesis, which states that ”Words with similar meanings tend to occur in similar contexts”. If dermatitis and eczema often occur in sim</context>
</contexts>
<marker>Kanerva, Kristoferson, Holst, 2000</marker>
<rawString>Pentti Kanerva, Jan Kristoferson, and Anders Holst. 2000. Random indexing of text samples for latent semantic analysis. In L. R. Gleitman and A. K. Joshi, editors, Proceedings of the 22nd Annual Conference of the Cognitive Science Society, Mahwah, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In</title>
<date>2001</date>
<booktitle>Proc. 18th International Conf. on Machine Learning,</booktitle>
<pages>282--289</pages>
<publisher>Morgan Kaufmann,</publisher>
<location>San Francisco, CA.</location>
<contexts>
<context position="14425" citStr="Lafferty et al. (2001)" startWordPosition="2331" endWordPosition="2334">s the entity category according to the manual annotation. carry out the experiments. (3) A system for representing semantic similarity of the words in the un-annotated corpus. As this component, a random indexing based word space model will used. (4) A system for turning the semantic representation of the word space model into features to use for the NER model. As this component, clustering will be used. To give a methodological background, the theoretical foundation for the four components will be described. 4.1 Conditional random fields Conditional random fields (CRF or CRFs), introduced by Lafferty et al. (2001), is a machine learning method suitable for segmenting and labelling sequential data and therefore often used for e.g. named entity recognition. As described in the related research section, CRFs have been used in a number of studies for extracting entities from clinical text. In contrast to many other types of data, observed data points for sequential data, such as text, are dependent on other observed data points. Such dependences between data points are practical to describe within the framework of graphical models (Bishop, 2006, p. 359), to which CRF belongs (Sutton and McCallum, 2006, p. </context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John Lafferty, Andrew McCallum, and Fernando Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In Proc. 18th International Conf. on Machine Learning, pages 282–289. Morgan Kaufmann, San Francisco, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas K Landauer</author>
<author>Susan T Dutnais</author>
</authors>
<title>A solution to Plato’s problem: The latent semantic analysis theory of acquisition, induction, and representation of knowledge. Psychological review,</title>
<date>1997</date>
<pages>211--240</pages>
<contexts>
<context position="23280" citStr="Landauer and Dutnais, 1997" startWordPosition="3835" endWordPosition="3838">er semantic unit (figure 2). The context vectors of two semantic units can then be compared as a measure of semantic similarity between units, e.g. using the the euclidian distance between normalised context vectors or the cosine similarity. The large dimension of a term-by-term matrix leads, however, to scalability problems, and the typical solution to this is to apply dimensionality reduction on the matrix. In a semantic space created by latent semantic analysis, for instance, dimensionality reduction is performed by applying the linear algebra matrix operation singular value decomposition (Landauer and Dutnais, 1997). Random indexing is another solution, in which a matrix with a smaller dimension is created from start, using the following method (Sahlgren et al., 2008): Each term in the data is assigned a unique representation, called an index vector. The index vectors all have the dimensionality d (where d ≥ 1000 but « w). Most of the elements of the index vectors are set to 0, but a few, randomly selected, elements are set to either +1 or -1. (Usually around 1-2% of the elements.) Instead of having orthogonal vectors, as is the case for the term-by-term matrix, the index vectors are nearly orthogonal. (</context>
<context position="31094" citStr="Landauer and Dutnais, 1997" startWordPosition="5185" endWordPosition="5188">eature, and thereby limiting the number of possible values this feature can take. • Would it be better to use other approaches (or compare different approaches) for obtaining features from unlabelled data? A possibility could be to use a more standard clustering approach, such as Brown clustering used in previous clinical NER studies (de Bruijn et al., 2011). Another possibility could be to keep the idea of creating clusters from vectors in a word space model, but to use other methods than random indexing for constructing the word space; e.g. the previously mentioned latent semantic analysis (Landauer and Dutnais, 1997), or a neural networks-based word space implementation (Pyysalo et al., 2014). • Many relevant terms within the medical domain are multi-word terms (e.g. of the type diabetes mellitus), and there are studies on how to construct semantic spaces with such multiword terms as the smallest semantic unit (Henriksson et al., 2013). Should the whitespace segmented token be treated as the smallest semantic unit in the proposed study, or should the use of larger semantic units be considered? Acknowledgements Many thanks to Aron Henriksson, Alyaa Alfalahi, Maria Kvist, Gunnar Nilsson and Hercules Daliani</context>
</contexts>
<marker>Landauer, Dutnais, 1997</marker>
<rawString>Thomas K Landauer and Susan T. Dutnais. 1997. A solution to Plato’s problem: The latent semantic analysis theory of acquisition, induction, and representation of knowledge. Psychological review, pages 211–240.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Marsland</author>
</authors>
<title>Machine learning : an algorithmic perspective. Chapman &amp; Hall/CRC,</title>
<date>2009</date>
<location>Boca Raton, FL.</location>
<contexts>
<context position="20441" citStr="Marsland, 2009" startWordPosition="3351" endWordPosition="3352">ry large feature set can then be used, without running the risk of over-fitting the model. Features will include those that have been used in previous clinical NER studies (Jonnalagadda et al., 2012; de Bruijn et al., 2011; Skeppstedt et al., 2014), with a context window of four previous and four following tokens. When maximising the conditional log likelihood of the parameters, the CRF++ program will set parameters that are optimal for training the model for the best micro-averaged results for the four classes Disorder, Finding, Pharmaceutical drug and Body structure. A hill climbing search (Marsland, 2009, pp. 262–264) for finding a good C-value will be used, starting with a value very close to zero and thereafter changing it in a direction that improves the NER results. A decreasingly smaller step size will be used for changing 6crfpp.sourceforge.net 25 Lemmatised and stop word filtered with a window size of 2 (1+1): complain dermatitis eczema itch patient complain: [0 0 0 2 2] dermatitis: [0 0 0 1 0] eczema: [0 0 0 1 0] itch: [2 1 1 0 0] patient: [2 0 0 0 0] 1 2 3 ... d ... [0 0 1 ... 0] complain: [0 0 0 ... 1] itch: [0 1 1 ... 0] patient: [-1 0 0 ... 0] ... [... ... ... ... ..] word w [0 0 </context>
</contexts>
<marker>Marsland, 2009</marker>
<rawString>Stephen Marsland. 2009. Machine learning : an algorithmic perspective. Chapman &amp; Hall/CRC, Boca Raton, FL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Martinez</author>
<author>Lawrence Cavedon</author>
<author>Graham Pitson</author>
</authors>
<title>Stability of text mining techniques for identifying cancer staging.</title>
<date>2013</date>
<booktitle>In Proceedings of the 4th International Louhi Workshop on Health Document Text Mining and Information Analysis - Louhi 2013,</booktitle>
<location>Sydney, Australia,</location>
<contexts>
<context position="1883" citStr="Martinez et al., 2013" startWordPosition="290" endWordPosition="293">. Amazon Mechanical Turk). Features from unsupervised machine-learning methods, for which no labelled training data is required, have, however, been shown to improve the performance of NER systems (Jonnalagadda et al., 2012). It is therefore likely that by incorporating features from unsupervised methods, it is possible to reduce the amount of training data needed to achieve a fixed level of performance. Due to differences in the use of language, an NLP system developed for, or trained on, text from one sub-domain often shows a drop in performance when applied on texts from another subdomain (Martinez et al., 2013). This has the effect that when performing NER on a new subdomain, annotated text from this new targeted subdomain might be required, even when there are annotated corpora from other domains. It would, however, be preferable to be able to apply a NER model trained on text from one sub-domain on another sub-domain, with only a minimum of additional data from this other targeted sub-domain. Incorporating features from unsupervised methods might limit the amount of additional annotated data needed for adapting a NER model to a new sub-domain. The proposed study aims at investigating the usefulnes</context>
</contexts>
<marker>Martinez, Cavedon, Pitson, 2013</marker>
<rawString>David Martinez, Lawrence Cavedon, and Graham Pitson. 2013. Stability of text mining techniques for identifying cancer staging. In Proceedings of the 4th International Louhi Workshop on Health Document Text Mining and Information Analysis - Louhi 2013, Sydney, Australia, February.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott Miller</author>
<author>Jethran Guinness</author>
<author>Alex Zamanian</author>
</authors>
<title>Name tagging with word clusters and discriminative training.</title>
<date>2004</date>
<booktitle>In Proceedings of HLT,</booktitle>
<pages>337--342</pages>
<contexts>
<context position="5335" citStr="Miller et al., 2004" startWordPosition="845" endWordPosition="848">s (e.g. tokens/lemmas/stems, orthographics, affixes, partof-speech, output of terminology matching), this system also used features extracted from hierarchical word clusters on un-annotated text. For constructing the clusters, they used Brown clustering, and represented the feature as a 7-bit showing to what cluster a word belonged. Outside of the biomedical domain, there are many studies on English corpora, which have shown that using features extracted from clusters constructed on unlabelled corpora improves performance of NER models, especially when using a smaller amount of training data (Miller et al., 2004; Freitag, 2004). This approach has also been shown to be successful for named entity recognition in other languages, e.g. German, Dutch and Spanish (T¨ackstr¨om et al., 2012), as well as on related NLP tasks (Biemann et al., 2007), and there are NER tools that automatically incorporate features extracted from unsupervised methods (Stanford, 2012). There are a number of additional studies within the biomedical domain, e.g. using features from Brown and other clustering approaches (Stenetorp et al., 2012) or from kmeans clustered vectors from a neural networksbased word space implementation (Py</context>
</contexts>
<marker>Miller, Guinness, Zamanian, 2004</marker>
<rawString>Scott Miller, Jethran Guinness, and Alex Zamanian. 2004. Name tagging with word clusters and discriminative training. In Proceedings of HLT, pages 337–342.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jon Patrick</author>
<author>Min Li</author>
</authors>
<title>High accuracy information extraction of medication information from clinical notes: 2009 i2b2 medication extraction challenge.</title>
<date>2010</date>
<journal>J Am Med Inform Assoc,</journal>
<volume>17</volume>
<issue>5</issue>
<pages>Sep-Oct.</pages>
<contexts>
<context position="4204" citStr="Patrick and Li, 2010" startWordPosition="668" endWordPosition="671">, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics Drug/Device and Locus was used for training a support vector machine with uneven margins (Roberts et al., 2008) and a corpus annotated for the entities Finding, Substance and Body was used for training a conditional random fields (CRF) system (Wang, 2009) as well as for training an ensemble of different classifiers (Wang and Patrick, 2009). Most studies have, however, been conducted on the i2b2 medication challenge corpus and the i2b2 challenge on concepts, assertions, and relations corpus. Conditional random fields (Patrick and Li, 2010) as well as an ensemble classifier (Doan et al., 2012) has for instance been used for extracting the entity Medication names from the medication challenge corpus, while all but the best among the top-performing systems used CRF for extracting the entities Medical Problem, Test and Treatment from the i2b2 challenge on concepts, assertions, and relations corpus (Uzuner et al., 2011). The best system (de Bruijn et al., 2011) used semi-Markov HMM, and in addition to the features used by most of the other systems (e.g. tokens/lemmas/stems, orthographics, affixes, partof-speech, output of terminolog</context>
</contexts>
<marker>Patrick, Li, 2010</marker>
<rawString>Jon Patrick and Min Li. 2010. High accuracy information extraction of medication information from clinical notes: 2009 i2b2 medication extraction challenge. J Am Med Inform Assoc, 17(5):524–527, Sep-Oct.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sampo Pyysalo</author>
<author>Filip Ginter</author>
<author>Hans Moen</author>
<author>Tapio Salakoski</author>
<author>Sophia Ananiadou</author>
</authors>
<title>Distributional semantics resources for biomedical text processing.</title>
<date>2014</date>
<booktitle>In Proceedings of Languages in Biology and Medicine.</booktitle>
<contexts>
<context position="5954" citStr="Pyysalo et al., 2014" startWordPosition="943" endWordPosition="946">04; Freitag, 2004). This approach has also been shown to be successful for named entity recognition in other languages, e.g. German, Dutch and Spanish (T¨ackstr¨om et al., 2012), as well as on related NLP tasks (Biemann et al., 2007), and there are NER tools that automatically incorporate features extracted from unsupervised methods (Stanford, 2012). There are a number of additional studies within the biomedical domain, e.g. using features from Brown and other clustering approaches (Stenetorp et al., 2012) or from kmeans clustered vectors from a neural networksbased word space implementation (Pyysalo et al., 2014). Jonnalagadda et al. (2012) also present a study in which unsupervised features are used for training a model on the i2b2 challenge on concepts, assertions, and relations corpus. As unannotated corpus, they used a corpus created by extracting Medline abstracts that are indexed with the publication type ”clinical trials”. They then built a semantic representation of this corpus in the form of a random indexing-based word space. This representation was then used for extracting a number of similar words to each word in the i2b2 challenge on concepts, assertions, and relations corpus, which were </context>
<context position="7810" citStr="Pyysalo et al. (2014)" startWordPosition="1251" endWordPosition="1254">s of the proposed study is to explore to what extent unsupervised features can help a machine learning system trained only on very little data. It is therefore not feasible to use the large number of features that would be generated by using neighbouring words, as that would require a large training data set to ensure that there are enough training examples for each generated feature. Therefore, the proposed method instead further processes the word space model by constructing clusters of semantically related words, thereby reducing the number of generated features, similar to the approach by Pyysalo et al. (2014). 3 Materials and previous results Texts from three different clinical sub-domains: cardiac ICU (intensive care unit), orthopaedic ER (emergency room), and internal medicine ER have been annotated (Tables 1-3).1 All texts are written in Swedish, and they all share the characteristics of text types written under time pressure; all of them containing many abbreviations and incomplete sentences. There are, however, also differences in e.g. what abbreviations are used and what 1Research on these texts aiming at extracting information related to Disorders/Findings and Pharmaceutical Drugs has been </context>
<context position="25910" citStr="Pyysalo et al., 2014" startWordPosition="4314" endWordPosition="4317">n the vectors. Four hypothetical clusters (C1- C4) of context vectors are also shown; clusters that contain a large proportion of known terms. ity measures can be applied. A hypothetical word space with d=2 is shown in Figure 5. 4.4 Clustering As mentioned earlier, for the word space information to be useful for training a CRF model on a small data set, it must be represented as a feature that can only take a limited number of different values. The proposed methods for achieving this is to cluster the context vectors of the word space model, similar to what has been done in previous research (Pyysalo et al., 2014). Also similar to previous research, cluster membership for a word in the NER training and test data will be used as a feature. Four named hypothetical clusters of context vectors are shown in the word space model in Figure 5 to illustrate the general idea, and an example of how to use cluster membership as a feature is shown Figure 1. Different clustering techniques will be evaluated, for the quality of the created clusters, as well as for their computational efficiency. Having hierarchical clusters might be preferable, as cluster membership to clusters of different granularity then can be of</context>
<context position="31171" citStr="Pyysalo et al., 2014" startWordPosition="5196" endWordPosition="5199"> Would it be better to use other approaches (or compare different approaches) for obtaining features from unlabelled data? A possibility could be to use a more standard clustering approach, such as Brown clustering used in previous clinical NER studies (de Bruijn et al., 2011). Another possibility could be to keep the idea of creating clusters from vectors in a word space model, but to use other methods than random indexing for constructing the word space; e.g. the previously mentioned latent semantic analysis (Landauer and Dutnais, 1997), or a neural networks-based word space implementation (Pyysalo et al., 2014). • Many relevant terms within the medical domain are multi-word terms (e.g. of the type diabetes mellitus), and there are studies on how to construct semantic spaces with such multiword terms as the smallest semantic unit (Henriksson et al., 2013). Should the whitespace segmented token be treated as the smallest semantic unit in the proposed study, or should the use of larger semantic units be considered? Acknowledgements Many thanks to Aron Henriksson, Alyaa Alfalahi, Maria Kvist, Gunnar Nilsson and Hercules Dalianis for taking a very active part in the planing of the proposed study, as well</context>
</contexts>
<marker>Pyysalo, Ginter, Moen, Salakoski, Ananiadou, 2014</marker>
<rawString>Sampo Pyysalo, Filip Ginter, Hans Moen, Tapio Salakoski, and Sophia Ananiadou. 2014. Distributional semantics resources for biomedical text processing. In Proceedings of Languages in Biology and Medicine.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Angus Roberts</author>
<author>Robert Gaizasukas</author>
<author>Mark Hepple</author>
<author>Yikun Guo</author>
</authors>
<title>Combining terminology resources and statistical methods for entity recognition: an evaluation.</title>
<date>2008</date>
<journal>European Language Resources Association</journal>
<booktitle>In Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC’08),</booktitle>
<pages>2974--2979</pages>
<location>Marrakech, Morocco,</location>
<contexts>
<context position="3771" citStr="Roberts et al., 2008" startWordPosition="599" endWordPosition="602">y will be carried out on different sub-domains within the specialised text domain of clinical text. 2 Related research There are a number of previous studies on named entity recognition in clinical text. For instance, a corpus annotated for the entities Condition, 21 Proceedings of the Student Research Workshop at the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 21–30, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics Drug/Device and Locus was used for training a support vector machine with uneven margins (Roberts et al., 2008) and a corpus annotated for the entities Finding, Substance and Body was used for training a conditional random fields (CRF) system (Wang, 2009) as well as for training an ensemble of different classifiers (Wang and Patrick, 2009). Most studies have, however, been conducted on the i2b2 medication challenge corpus and the i2b2 challenge on concepts, assertions, and relations corpus. Conditional random fields (Patrick and Li, 2010) as well as an ensemble classifier (Doan et al., 2012) has for instance been used for extracting the entity Medication names from the medication challenge corpus, whil</context>
</contexts>
<marker>Roberts, Gaizasukas, Hepple, Guo, 2008</marker>
<rawString>Angus Roberts, Robert Gaizasukas, Mark Hepple, and Yikun Guo. 2008. Combining terminology resources and statistical methods for entity recognition: an evaluation. In Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC’08), pages 2974–2979, Marrakech, Morocco, may. European Language Resources Association (ELRA). http://www.lrecconf.org/proceedings/lrec2008/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Magnus Sahlgren</author>
<author>Jussi Karlgren</author>
</authors>
<title>Terminology mining in social media.</title>
<date>2009</date>
<booktitle>In Proceedings of the 18th ACM conference on Information and knowledge management, CIKM ’09.</booktitle>
<contexts>
<context position="21883" citStr="Sahlgren and Karlgren, 2009" startWordPosition="3614" endWordPosition="3617">ges in the results can be observed. 4.3 Random indexing Random indexing is one version of the word space model, and as all word space models it is a method for representing distributional semantics. The random indexing method was originally devised by Kanerva et al. (2000), to deal with the performance problems (in terms of memory and computation time) that were associated with the LSA/LSI implementations at that time. Due to its computational efficiency, random indexing remains to be a popular method when building distributional semantics models on very large corpora, e.g. large web corpora (Sahlgren and Karlgren, 2009) or Medline abstracts (Jonnalagadda et al., 2012). Distributional semantics is built on the distributional hypothesis, which states that ”Words with similar meanings tend to occur in similar contexts”. If dermatitis and eczema often occur in similar contexts, e.g. ”Patient complains of itching dermatitis” and ”Patient complains of itching eczema”, it is likely that dermatitis and eczema have a similar meaning. One possible method of representing word co-occurrence information is to construct a term-by-term co-occurrence matrix, i.e. a matrix of dimensionality w x w, in which w is the number of</context>
</contexts>
<marker>Sahlgren, Karlgren, 2009</marker>
<rawString>Magnus Sahlgren and Jussi Karlgren. 2009. Terminology mining in social media. In Proceedings of the 18th ACM conference on Information and knowledge management, CIKM ’09.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Magnus Sahlgren</author>
<author>Anders Holst</author>
<author>Pentti Kanerva</author>
</authors>
<title>Permutations as a means to encode order in word space.</title>
<date>2008</date>
<booktitle>In Proceedings of the 30th Annual Meeting of the Cognitive Science Society,</booktitle>
<pages>1300--1305</pages>
<contexts>
<context position="23435" citStr="Sahlgren et al., 2008" startWordPosition="3860" endWordPosition="3863">e euclidian distance between normalised context vectors or the cosine similarity. The large dimension of a term-by-term matrix leads, however, to scalability problems, and the typical solution to this is to apply dimensionality reduction on the matrix. In a semantic space created by latent semantic analysis, for instance, dimensionality reduction is performed by applying the linear algebra matrix operation singular value decomposition (Landauer and Dutnais, 1997). Random indexing is another solution, in which a matrix with a smaller dimension is created from start, using the following method (Sahlgren et al., 2008): Each term in the data is assigned a unique representation, called an index vector. The index vectors all have the dimensionality d (where d ≥ 1000 but « w). Most of the elements of the index vectors are set to 0, but a few, randomly selected, elements are set to either +1 or -1. (Usually around 1-2% of the elements.) Instead of having orthogonal vectors, as is the case for the term-by-term matrix, the index vectors are nearly orthogonal. (See Figure 3.) Each term in the data is also assigned a context vector, also of the dimensionality d. Initially, all elements in the context vectors are se</context>
</contexts>
<marker>Sahlgren, Holst, Kanerva, 2008</marker>
<rawString>Magnus Sahlgren, Anders Holst, and Pentti Kanerva. 2008. Permutations as a means to encode order in word space. In Proceedings of the 30th Annual Meeting of the Cognitive Science Society, pages 1300–1305.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maria Skeppstedt</author>
<author>Maria Kvist</author>
<author>Gunnar H Nilsson</author>
<author>Hercules Dalianis</author>
</authors>
<title>Automatic recognition of disorders, findings, pharmaceuticals and body structures from clinical text: An annotation and machine learning study.</title>
<date>2014</date>
<journal>J Biomed Inform, Feb</journal>
<note>(in press).</note>
<contexts>
<context position="9335" citStr="Skeppstedt et al., 2014" startWordPosition="1482" endWordPosition="1485">ardiac ICU Data set: All Entity category # entities (Unique) Disorder 1258 (541) Finding 1439 (785) Pharmaceuticals 880 (212) Body structure 1324 (423) Table 2: Annotated data, Orthopaedic ER entities that are frequently mentioned. The texts from cardiac ICU and orthopaedic ER will be treated as existing annotations in a current domain, whereas internal medicine ER will be treated as the new target domain. Approximately a third of the texts from internal medicine ER have been doubly annotated, and an evaluation set has been created by manually resolving differences between the two annotators (Skeppstedt et al., 2014). This evaluation subset will be used as held-out data for evaluating the NER task. The following four entity categories have been annotated (Skeppstedt et al., 2014): (1) Disorder (a disease or abnormal condition that is not momentary and that has an underlying pathological process), (2) Finding (a symptom reported by the patient, an observation made by the physician or the result of a medical examination of the patient), (3) Pharmaceutical Drug (not limited to generic name or trade name, but includes also e.g. drugs expressed by their effect, such as painkiller or sleeping pill). (4) Body St</context>
<context position="10639" citStr="Skeppstedt et al., 2014" startWordPosition="1697" endWordPosition="1701">be used in the proposed study, together with a large corpus of un-annotated text from which unsupervised features will be extracted. This large corpus will be a subset of the Stockholm EPR corpus (Dalianis et al., 2009), which is a large corpus of clinical text written in Swedish. Named entity recognition on the internal medicine ER part of the annotated corpus has already been studied, and results on the evaluation set were an F-score of 0.81 for the entity Disorder, 0.69 for Finding, 0.88 for Pharmaceutical Drug, 0.85 for Body Structure and 0.78 for the combined category Disorder + Finding (Skeppstedt et al., 2014). Features used for training the model on the development/training part of the internal medicine ER corpus were the lemma forms of the words, their part of speech, their semantic category in used vocabulary lists, their word constituents (if the words were compounds) as well as the orthographics of the words. A narrow context window was used, as shown by the entries marked in boldface in Figure 1. As terminologies, the Swedish versions of SNOMED CT2, MeSH3, ICD-104, the Swedish medical list FASS5 were used, as well as a vocabulary list of non-medical words, compiled from the Swedish Parole cor</context>
<context position="13741" citStr="Skeppstedt et al., 2014" startWordPosition="2218" endWordPosition="2221">noun disorder - - all upper #40 .. #39423 B-Disorder patient patient noun person - - - #3 .. #23498 O with with prep. parole - - - #14 .. #30892 O chestpain chestpain noun finding chest pain - #40 .. #23409 B-Finding Current and and conj. parole - - - - .. - O problems problem noun finding - - - #40 .. #23409 B-Finding to to prep. finding - - - - .. - I-Finding breathe breathe verb finding - - - #90 .. #23409 I-Finding Figure 1: A hypothetical example sentence, with hypothetical features for training a machine learning model. Features used in a previous medical named entity recognition study (Skeppstedt et al., 2014) on this corpus are shown in boldface. The last column contains the entity category according to the manual annotation. carry out the experiments. (3) A system for representing semantic similarity of the words in the un-annotated corpus. As this component, a random indexing based word space model will used. (4) A system for turning the semantic representation of the word space model into features to use for the NER model. As this component, clustering will be used. To give a methodological background, the theoretical foundation for the four components will be described. 4.1 Conditional random </context>
<context position="20075" citStr="Skeppstedt et al., 2014" startWordPosition="3293" endWordPosition="3296"> a large number of models are to be constructed, which requires a simple and efficient method for parameter setting. An advantage with using the L1-norm is that only one parameter, the C-value, has to be optimised, as the weights for feature functions are driven to zero for feature functions that are not useful. The L1-norm will therefore be used in the proposed study. A very large feature set can then be used, without running the risk of over-fitting the model. Features will include those that have been used in previous clinical NER studies (Jonnalagadda et al., 2012; de Bruijn et al., 2011; Skeppstedt et al., 2014), with a context window of four previous and four following tokens. When maximising the conditional log likelihood of the parameters, the CRF++ program will set parameters that are optimal for training the model for the best micro-averaged results for the four classes Disorder, Finding, Pharmaceutical drug and Body structure. A hill climbing search (Marsland, 2009, pp. 262–264) for finding a good C-value will be used, starting with a value very close to zero and thereafter changing it in a direction that improves the NER results. A decreasingly smaller step size will be used for changing 6crfp</context>
</contexts>
<marker>Skeppstedt, Kvist, Nilsson, Dalianis, 2014</marker>
<rawString>Maria Skeppstedt, Maria Kvist, Gunnar H Nilsson, and Hercules Dalianis. 2014. Automatic recognition of disorders, findings, pharmaceuticals and body structures from clinical text: An annotation and machine learning study. J Biomed Inform, Feb (in press).</rawString>
</citation>
<citation valid="true">
<authors>
<author>NLP Group Stanford</author>
</authors>
<title>Stanford Named Entity Recognizer (NER).</title>
<date>2012</date>
<pages>2012--03</pages>
<note>http://wwwnlp.stanford.edu/software/CRF-NER.shtml. Accessed</note>
<contexts>
<context position="5684" citStr="Stanford, 2012" startWordPosition="902" endWordPosition="903">medical domain, there are many studies on English corpora, which have shown that using features extracted from clusters constructed on unlabelled corpora improves performance of NER models, especially when using a smaller amount of training data (Miller et al., 2004; Freitag, 2004). This approach has also been shown to be successful for named entity recognition in other languages, e.g. German, Dutch and Spanish (T¨ackstr¨om et al., 2012), as well as on related NLP tasks (Biemann et al., 2007), and there are NER tools that automatically incorporate features extracted from unsupervised methods (Stanford, 2012). There are a number of additional studies within the biomedical domain, e.g. using features from Brown and other clustering approaches (Stenetorp et al., 2012) or from kmeans clustered vectors from a neural networksbased word space implementation (Pyysalo et al., 2014). Jonnalagadda et al. (2012) also present a study in which unsupervised features are used for training a model on the i2b2 challenge on concepts, assertions, and relations corpus. As unannotated corpus, they used a corpus created by extracting Medline abstracts that are indexed with the publication type ”clinical trials”. They t</context>
</contexts>
<marker>Stanford, 2012</marker>
<rawString>NLP Group Stanford. 2012. Stanford Named Entity Recognizer (NER). http://wwwnlp.stanford.edu/software/CRF-NER.shtml. Accessed 2012-03-29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pontus Stenetorp</author>
<author>Hubert Soyer</author>
<author>Sampo Pyysalo</author>
<author>Sophia Ananiadou</author>
<author>Takashi Chikayama</author>
</authors>
<title>Size (and domain) matters: Evaluating semantic word space representations for biomedical text.</title>
<date>2012</date>
<booktitle>In Proceedings of the 5th International Symposium on Semantic Mining in Biomedicine.</booktitle>
<contexts>
<context position="5844" citStr="Stenetorp et al., 2012" startWordPosition="925" endWordPosition="928">a improves performance of NER models, especially when using a smaller amount of training data (Miller et al., 2004; Freitag, 2004). This approach has also been shown to be successful for named entity recognition in other languages, e.g. German, Dutch and Spanish (T¨ackstr¨om et al., 2012), as well as on related NLP tasks (Biemann et al., 2007), and there are NER tools that automatically incorporate features extracted from unsupervised methods (Stanford, 2012). There are a number of additional studies within the biomedical domain, e.g. using features from Brown and other clustering approaches (Stenetorp et al., 2012) or from kmeans clustered vectors from a neural networksbased word space implementation (Pyysalo et al., 2014). Jonnalagadda et al. (2012) also present a study in which unsupervised features are used for training a model on the i2b2 challenge on concepts, assertions, and relations corpus. As unannotated corpus, they used a corpus created by extracting Medline abstracts that are indexed with the publication type ”clinical trials”. They then built a semantic representation of this corpus in the form of a random indexing-based word space. This representation was then used for extracting a number </context>
</contexts>
<marker>Stenetorp, Soyer, Pyysalo, Ananiadou, Chikayama, 2012</marker>
<rawString>Pontus Stenetorp, Hubert Soyer, Sampo Pyysalo, Sophia Ananiadou, and Takashi Chikayama. 2012. Size (and domain) matters: Evaluating semantic word space representations for biomedical text. In Proceedings of the 5th International Symposium on Semantic Mining in Biomedicine.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sutton</author>
<author>Andrew McCallum</author>
</authors>
<title>An introduction to conditional random fields for relational learning.</title>
<date>2006</date>
<booktitle>In Lise Getoor and Ben Taskar, editors, Introduction to Statistical Relational Learning.</booktitle>
<publisher>MIT Press.</publisher>
<contexts>
<context position="15020" citStr="Sutton and McCallum, 2006" startWordPosition="2430" endWordPosition="2433">uced by Lafferty et al. (2001), is a machine learning method suitable for segmenting and labelling sequential data and therefore often used for e.g. named entity recognition. As described in the related research section, CRFs have been used in a number of studies for extracting entities from clinical text. In contrast to many other types of data, observed data points for sequential data, such as text, are dependent on other observed data points. Such dependences between data points are practical to describe within the framework of graphical models (Bishop, 2006, p. 359), to which CRF belongs (Sutton and McCallum, 2006, p. 1). In the special, but frequently used, case of linear chain CRF, the output variables are linked in a chain. Apart from being dependent on the input variables, each output variable is then conditionally independent on all other output variables, except on the previous and following output variable, given these two neighbouring output variables. In a named entity recognition task, the output variables are the named entity classes that are to be predicted and the observed input variables are observed features of the text, such as the tokens or their part-of-speech. CRF is closely related </context>
</contexts>
<marker>Sutton, McCallum, 2006</marker>
<rawString>Charles. Sutton and Andrew McCallum. 2006. An introduction to conditional random fields for relational learning. In Lise Getoor and Ben Taskar, editors, Introduction to Statistical Relational Learning. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oscar T¨ackstr¨om</author>
<author>Ryan McDonald</author>
<author>Jakob Uszkoreit</author>
</authors>
<title>Cross-lingual Word Clusters for Direct Transfer of Linguistic Structure.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>477--487</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Montr´eal, Canada,</location>
<marker>T¨ackstr¨om, McDonald, Uszkoreit, 2012</marker>
<rawString>Oscar T¨ackstr¨om, Ryan McDonald, and Jakob Uszkoreit. 2012. Cross-lingual Word Clusters for Direct Transfer of Linguistic Structure. In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 477– 487, Montr´eal, Canada, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoshimasa Tsuruoka</author>
<author>Jun’ichi Tsujii</author>
<author>Sophia Ananiadou</author>
</authors>
<title>Fast full parsing by linear-chain conditional random fields.</title>
<date>2009</date>
<booktitle>In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics, EACL ’09,</booktitle>
<pages>790--798</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="17875" citStr="Tsuruoka et al., 2009" startWordPosition="2904" endWordPosition="2907">values of the output variable in current position and in the immediate previous position, whereas it can include, and thereby show a dependence on, input variables from any position. The CRF model is trained through setting weights for the feature functions, which is carried out by penalised maximum likelihood. Penalised means that regularisation is used, and regularisation is performed by adding a penalty term, which prevents the weights from reaching too large values, and thereby prevents over-fitting (Bishop, 2006, p. 10). The L1-norm and the L2-norm are frequently used for regularisation (Tsuruoka et al., 2009), and a variable C governs the importance of the regularisation. Using the L1-norm also results in that if C is large enough, some of the weights are driven to zero, resulting in a sparse model and thereby the feature functions that those weights control will not play any role in the model. Thereby, complex models can be trained also on data sets with a limited size, without being overfitted. However, a suitable value of C must still be determined (Bishop, 2006, p. 145). The plan for the proposed study is to use the CRF package CRF++6, which has been used in a number of previous NER studies, a</context>
</contexts>
<marker>Tsuruoka, Tsujii, Ananiadou, 2009</marker>
<rawString>Yoshimasa Tsuruoka, Jun’ichi Tsujii, and Sophia Ananiadou. 2009. Fast full parsing by linear-chain conditional random fields. In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics, EACL ’09, pages 790–798, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brett R South Uzuner</author>
<author>Shuying Shen</author>
<author>Scott L DuVall</author>
</authors>
<title>i2b2/va challenge on concepts, assertions, and relations in clinical text.</title>
<date>2011</date>
<journal>J Am Med Inform Assoc,</journal>
<volume>18</volume>
<issue>5</issue>
<contexts>
<context position="4587" citStr="Uzuner et al., 2011" startWordPosition="730" endWordPosition="733">assifiers (Wang and Patrick, 2009). Most studies have, however, been conducted on the i2b2 medication challenge corpus and the i2b2 challenge on concepts, assertions, and relations corpus. Conditional random fields (Patrick and Li, 2010) as well as an ensemble classifier (Doan et al., 2012) has for instance been used for extracting the entity Medication names from the medication challenge corpus, while all but the best among the top-performing systems used CRF for extracting the entities Medical Problem, Test and Treatment from the i2b2 challenge on concepts, assertions, and relations corpus (Uzuner et al., 2011). The best system (de Bruijn et al., 2011) used semi-Markov HMM, and in addition to the features used by most of the other systems (e.g. tokens/lemmas/stems, orthographics, affixes, partof-speech, output of terminology matching), this system also used features extracted from hierarchical word clusters on un-annotated text. For constructing the clusters, they used Brown clustering, and represented the feature as a 7-bit showing to what cluster a word belonged. Outside of the biomedical domain, there are many studies on English corpora, which have shown that using features extracted from cluster</context>
</contexts>
<marker>Uzuner, Shen, DuVall, 2011</marker>
<rawString>¨Ozlem. Uzuner, Brett R. South, Shuying Shen, and Scott L. DuVall. 2011. 2010 i2b2/va challenge on concepts, assertions, and relations in clinical text. J Am Med Inform Assoc, 18(5):552–556.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yefeng Wang</author>
<author>Jon Patrick</author>
</authors>
<title>Cascading classifiers for named entity recognition in clinical notes.</title>
<date>2009</date>
<booktitle>In Proceedings of the Workshop on Biomedical Information Extraction,</booktitle>
<pages>42--49</pages>
<contexts>
<context position="4001" citStr="Wang and Patrick, 2009" startWordPosition="638" endWordPosition="641">nnotated for the entities Condition, 21 Proceedings of the Student Research Workshop at the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 21–30, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics Drug/Device and Locus was used for training a support vector machine with uneven margins (Roberts et al., 2008) and a corpus annotated for the entities Finding, Substance and Body was used for training a conditional random fields (CRF) system (Wang, 2009) as well as for training an ensemble of different classifiers (Wang and Patrick, 2009). Most studies have, however, been conducted on the i2b2 medication challenge corpus and the i2b2 challenge on concepts, assertions, and relations corpus. Conditional random fields (Patrick and Li, 2010) as well as an ensemble classifier (Doan et al., 2012) has for instance been used for extracting the entity Medication names from the medication challenge corpus, while all but the best among the top-performing systems used CRF for extracting the entities Medical Problem, Test and Treatment from the i2b2 challenge on concepts, assertions, and relations corpus (Uzuner et al., 2011). The best sys</context>
</contexts>
<marker>Wang, Patrick, 2009</marker>
<rawString>Yefeng Wang and Jon Patrick. 2009. Cascading classifiers for named entity recognition in clinical notes. In Proceedings of the Workshop on Biomedical Information Extraction, pages 42–49.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yefeng Wang</author>
</authors>
<title>Annotating and recognising named entities in clinical notes.</title>
<date>2009</date>
<booktitle>In Proceedings of the ACL-IJCNLP Student Research Workshop,</booktitle>
<pages>18--26</pages>
<contexts>
<context position="3915" citStr="Wang, 2009" startWordPosition="625" endWordPosition="626">ies on named entity recognition in clinical text. For instance, a corpus annotated for the entities Condition, 21 Proceedings of the Student Research Workshop at the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 21–30, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics Drug/Device and Locus was used for training a support vector machine with uneven margins (Roberts et al., 2008) and a corpus annotated for the entities Finding, Substance and Body was used for training a conditional random fields (CRF) system (Wang, 2009) as well as for training an ensemble of different classifiers (Wang and Patrick, 2009). Most studies have, however, been conducted on the i2b2 medication challenge corpus and the i2b2 challenge on concepts, assertions, and relations corpus. Conditional random fields (Patrick and Li, 2010) as well as an ensemble classifier (Doan et al., 2012) has for instance been used for extracting the entity Medication names from the medication challenge corpus, while all but the best among the top-performing systems used CRF for extracting the entities Medical Problem, Test and Treatment from the i2b2 chall</context>
</contexts>
<marker>Wang, 2009</marker>
<rawString>Yefeng Wang. 2009. Annotating and recognising named entities in clinical notes. In Proceedings of the ACL-IJCNLP Student Research Workshop, pages 18–26, Singapore.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>