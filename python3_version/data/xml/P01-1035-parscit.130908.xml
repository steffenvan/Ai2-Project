<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.005500">
<title confidence="0.946633">
Serial Combination of Rules and Statistics: A Case Study in Czech
Tagging
</title>
<note confidence="0.7837322">
Jan Hajiˇc Pavel Krbec Pavel Kvˇetoˇn Karel Oliva Vladimir Petkeviˇc
IFAL ICNC Computational ITCL
MFF UK FF UK Linguistics FF UK
Prague Prague Univ. of Saarland Prague
Czechia Czechia Germany Czechia
</note>
<figure confidence="0.7216515">
hajic,krbec @
ufal.mff.cuni.cz
Pavel.Kveton@
ff.cuni.cz
oliva@ Vladimir.Petkevic@
coli.uni-sb.de ff.cuni.cz
</figure>
<sectionHeader confidence="0.952415" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999888692307692">
A hybrid system is described which
combines the strength of manual rule-
writing and statistical learning, obtain-
ing results superior to both methods if
applied separately. The combination of
a rule-based system and a statistical one
is not parallel but serial: the rule-based
system performing partial disambigua-
tion with recall close to 100% is applied
first, and a trigram HMM tagger runs on
its results. An experiment in Czech tag-
ging has been performed with encour-
aging results.
</bodyText>
<sectionHeader confidence="0.526667" genericHeader="method">
1 Tagging of Inflective Languages
</sectionHeader>
<bodyText confidence="0.9999795625">
Inflective languages pose a specific problem in
tagging due to two phenomena: highly inflec-
tive nature (causing sparse data problem in any
statistically-based system), and free word order
(causing fixed-context systems, such as n-gram
Hidden Markov Models (HMMs), to be even less
adequate than for English). The average tagset
contains about 1,000 - 2,000 distinct tags; the size
of the set of possible and plausible tags can reach
several thousands.
Apart from agglutinative languages such
as Turkish, Finnish and Hungarian (see e.g.
(Hakkani-Tur et al., 2000)), and Basque (Ezeiza
et al., 1998), which pose quite different and in
the end less severe problems, there have been at-
tempts at solving this problem for some of the
highly inflectional European languages, such as
(Daelemans et al., 1996), (Erjavec et al., 1999)
(Slovenian), (Hajiˇc and Hladk´a, 1997), (Hajiˇc and
Hladk´a, 1998) (Czech) and (Hajiˇc, 2000) (five
Central and Eastern European languages), but
so far no system has reached - in the absolute
terms - a performance comparable to English tag-
ging (such as (Ratnaparkhi, 1996)), which stands
around or above 97%. For example, (Hajiˇc and
Hladk´a, 1998) report results on Czech slightly
above 93% only. One has to realize that even
though such a performance might be adequate for
some tasks (such as word sense disambiguation),
for many other (such as parsing or translation) the
implied sentence error rate at 50% or more is sim-
ply too much to deal with.
</bodyText>
<subsectionHeader confidence="0.998313">
1.1 Statistical Tagging
</subsectionHeader>
<bodyText confidence="0.998357">
Statistical tagging of inflective languages
has been based on many techniques, rang-
ing from plain-old HMM taggers (Mirovsk´y,
1998), memory-based (Erjavec et al., 1999) to
maximum-entropy and feature-based (Hajiˇc and
Hladk´a, 1998), (Hajiˇc, 2000). For Czech, the
best result achieved so far on approximately
300 thousand word training data set has been
described in (Hajiˇc and Hladk´a, 1998).
We are using 1.8M manually annotated tokens
from the Prague Dependency Treebank (PDT)
project (Hajiˇc, 1998). We have decided to work
with an HMM tagger1 in the usual source-channel
setting, with proper smoothing. The HMM tag-
ger uses the Czech morphological processor from
PDT to disambiguate only among those tags
</bodyText>
<footnote confidence="0.732333">
1Mainly because of the ease with which it is trained even
on large data, and also because no other publicly available
tagger was able to cope with the amount and ambiguity of
the data in reasonable time.
</footnote>
<bodyText confidence="0.991693">
which are morphologically plausible for a given
input word form.
</bodyText>
<subsectionHeader confidence="0.998731">
1.2 Manual Rule-based Systems
</subsectionHeader>
<bodyText confidence="0.99995675">
The idea of tagging by means of hand-written
disambiguation rules has been put forward and
implemented for the first time in the form of
Constraint-Based Grammars (Karlsson et al.,
1995). From languages we are acquainted with,
the method has been applied on a larger scale only
to English (Karlsson et al., 1995), (Samuelsson
and Voutilainen, 1997), and French (Chanod and
Tapanainen, 1995). Also (Bick, 1996) and (Bick,
2000) use manually written rules for Brazilian
Portuguese, and there are several publications by
Oflazer for Turkish.
Authors of such systems claim that hand-
written systems can perform better than sys-
tems based on machine learning (Samuelsson and
Voutilainen, 1997); however, except for the work
cited, comparison is difficult to impossible due to
the fact that they do not use the standard evalua-
tion techniques (and not even the same data). But
the substantial disadvantage is that the develop-
ment of manual rule-based systems is demanding
and requires a good deal of very subtle linguistic
expertise and skills if full disambiguation also of
“difficult” texts is to be performed.
</bodyText>
<subsectionHeader confidence="0.992914">
1.3 System Combination
</subsectionHeader>
<bodyText confidence="0.999123710526316">
Combination of (manual) rule-writing and statis-
tical learning has been studied before. E.g., (Ngai
and Yarowsky, 2000) and (Ngai, 2001) provide
a thorough description of many experiments in-
volving rule-based systems and statistical learn-
ers for NP bracketing. For tagging, combination
of purely statistical classifiers has been described
(Hladk´a, 2000), with about 3% relative improve-
ment (error reduction from 18.6% to 18%, trained
on small data) over the best original system. We
regard such systems as working in parallel, since
all the original classifiers run independently of
each other.
In the present study, we have chosen a differ-
ent strategy (similar to the one described for other
types of languages in (Tapanainen and Vouti-
lainen, 1994), (Ezeiza et al., 1998) and (Hakkani-
Tur et al., 2000)). At the same time, the rule-
based component is known to perform well in
eliminating the incorrect alternatives2, rather than
picking the correct one under all circumstances.
Moreover, the rule-based system used can exam-
ine the whole sentential context, again a difficult
thing for a statistical system3. That way, the ambi-
guity of the input text4 decreases. This is exactly
what our statistical HMM tagger needs as its in-
put, since it is already capable of using the lexical
information from a dictionary.
However, also in the rule-based approach, there
is the usual tradeoff between precision and recall.
We have decided to go for the “perfect” solution:
to keep 100% recall, or very close to it, and grad-
ually improve precision by writing rules which
eliminate more and more incorrect tags. This way,
we can be sure (or almost sure) that the perfor-
mance of the HMM tagger performance will not
be hurt by (recall) errors made by the rule compo-
nent.
</bodyText>
<sectionHeader confidence="0.945812" genericHeader="method">
2 The Rule-based Component
</sectionHeader>
<subsectionHeader confidence="0.761369">
2.1 Formal Means
</subsectionHeader>
<bodyText confidence="0.999868428571429">
Taken strictly formally, the rule-based component
has the form of a restarting automaton with dele-
tion (Pl´atek et al., 1995), that is, each rule can
be thought of as a finite-state automaton starting
from the beginning of the sentence and passing to
the right until it finds an input configuration on
which it can operate by deletion of some parts of
the input. Having performed this, the whole sys-
tem is restarted, which means that the next rule
is applied on the changed input (and this input is
again read from the left end). This means that a
single rule has the power of a finite state automa-
ton, but the system as a whole has (even more
than) a context-free power.
</bodyText>
<subsectionHeader confidence="0.999743">
2.2 The Rules and Their Implementation
</subsectionHeader>
<bodyText confidence="0.9941798">
The system of hand-written rules for Czech has a
twofold objective:
practical: an error-free and at the same time
the most accurate tagging of Czech texts
theoretical: the description of the syntactic
</bodyText>
<footnote confidence="0.99715875">
2Such a “negative” learning is thought to be difficult for
any statistical system.
3Causing an immediate data sparseness problem.
4As prepared by the morphological analyzer.
</footnote>
<bodyText confidence="0.997990043478261">
system of Czech, its langue, rather than pa-
role.
The rules are to reduce the input ambiguity of
the input text. During disambiguation the whole
rule system combines two methods:
the oblique one consisting in the elimination
of syntactically wrong tag(s), i.e. in the re-
duction of the input ambiguity by deleting
those tags which are excluded by the context
the direct choice of the correct tag(s).
The overall strategy of the rule system is to
keep the highest recall possible (i.e. 100%) and
gradually improve precision. Thus, the rules are
(manually) assigned reliabilities which divide the
rules into reliability classes, with the most reli-
able (“bullet-proof”) group of rules applied first
and less reliable groups of rules (threatening to
decrease the 100% recall) being applied in subse-
quent steps. The bullet-proof rules reflect general
syntactic regularities of Czech; for instance, no
word form in the nominative case can follow an
unambiguous preposition. The less reliable rules
can be exemplified by those accounting for some
special intricate relations of grammatical agree-
ment in Czech. Within each reliability group the
rules are applied independently, i.e. in any or-
der in a cyclic way until no ambiguity can be re-
solved.
Besides reliability, the rules can be generally
divided according to the locality/nonlocality of
their scope. Some phenomena (not many) in the
structure of Czech sentence are local in nature:
for instance, for the word “se” which is two-way
ambiguous between a preposition (with) and a re-
flexive particle/pronoun (himself, as a particle) a
prepositional reading can be available only in lo-
cal contexts requiring the vocalisation of the basic
form of the preposition “s” (with) resulting in the
form “se”. However, in the majority of phenom-
ena the correct disambiguation requires a much
wider context. Thus, the rules use as wide con-
text as possible with no context limitations be-
ing imposed in advance. During rules develop-
ment performed so far, sentential context has been
used, but nothing in principle limits the context
to a single sentence. If it is generally appropri-
ate for the disambiguation of the languages of the
world to use unlimited context, it is especially fit
for languages with free word order combined with
rich inflection. There are many syntactic phenom-
ena in Czech displaying the following property: a
word form wf1 can be part-of-speech determined
by means of another word form wf2 whose word-
order distance cannot be determined by a fixed
number of positions between the two word forms.
This is exactly a general phenomenon which is
grasped by the hand-written rules.
Formally, each rule consists of
the description of the context (descriptive
component), and
the action to be performed given the context
(executive component): i.e. which tags are
to be discarded or which tag(s) are to be pro-
claimed correct (the rest being discarded as
wrong).
For example,
Context: unambiguous finite verb, fol-
lowed/preceded by a sequence of tokens
containing neither comma nor coordinating
conjunction, at either side of a word x am-
biguous between a finite verb and another
reading
Action: delete the finite verb reading(s) at
the word x.
There are two ways of rule development:
the rules developed by syntactic introspec-
tion: such rules are subsequently verified on
the corpus material, then implemented and
the implemented rules are tested on a testing
corpus
the rules are derived from the corpus by in-
trospection and subsequently implemented
The rules are formulated as generally as pos-
sible and at the same time as error-free (recall-
wise) as possible. This approach of combining the
requirements of maximum recall and maximum
precision demands sophisticated syntactic knowl-
edge of Czech. This knowledge is primarily based
on the study of types of morphological ambiguity
occurring in Czech. There are two main types of
such ambiguity:
regular (paradigm-internal) a bucketed linear interpolation smoothing
casual (lexical) for both models.
The regular (paradigm-internal) ambiguities
occur within a paradigm, i.e. they are common
to all lexemes belonging to a particular inflection
class. For example, in Czech (as in many other in-
flective languages), the nominative, the accusative
and the vocative case have the same form (in sin-
gular on the one hand, and in plural on the other).
The casual (lexical, paradigm-external) morpho-
logical ambiguity is lexically specific and hence
cannot be investigated via paradigmatics.
In addition to the general rules, the rule ap-
proach includes a module which accounts for col-
locations and idioms. The problem is that the
majority of collocations can – besides their most
probable interpretation just as collocations – have
also their literal meaning.
Currently, the system (as evaluated in Sect. 2.3)
consists of 80 rules.
The rules had been implemented procedurally
in the initial phase; a special feature-oriented, in-
terpreted “programming language” is now under
development.
</bodyText>
<subsectionHeader confidence="0.990417">
2.3 Evaluation of the Rule System Alone
</subsectionHeader>
<bodyText confidence="0.999852">
The results are presented in Table 1. We use the
usual equal-weight formula for F-measure:
</bodyText>
<sectionHeader confidence="0.990783" genericHeader="method">
3 The Statistical Component
</sectionHeader>
<subsectionHeader confidence="0.981007">
3.1 The BMM Tagger
</subsectionHeader>
<bodyText confidence="0.995861666666667">
We have used an HMM tagger in the usual source-
channel setting, fine-tuned to perfection using
a 3-gram tag language model
,
a tag-to-word lexical (translation) model us-
ing bigram histories instead of just same-
</bodyText>
<footnote confidence="0.826745">
word conditioning 5,
5First used in (Thede and Harper, 1999), as far as we
know.
</footnote>
<bodyText confidence="0.998986162162162">
Thus the HMM tagger outputs a sequence of
tags according to the usual equation
The tagger has been trained in the usual way,
using part of the training data as heldout data for
smoothing of the two models employed. There
is no threshold being applied for low counts.
Smoothing has been done first without using
buckets, and then with them to show the differ-
ence. Table 2 shows the resulting interpolation
coefficients for the tag language model using the
usual linear interpolation smoothing formula
where p(...) is the “raw” Maximum Likelihood
estimate of the probability distributions, i.e. the
relative frequency in the training data.
The bucketing scheme for smoothing (a neces-
sity when keeping all tag trigrams and tag-to-
word bigrams) uses “buckets bounds” computed
according to the following formula (for more on
bucketing, see (Jelinek, 1997)):
It should be noted that when using this bucket-
ing scheme, the weights of the detailed distribu-
tions (with longest history) grow quickly as the
history reliability increases. However, it is not
monotonic; at several of the most reliable histo-
ries, the weight coefficients “jump” up and down.
We have found that a sudden drop in happens,
e.g., for the bucket containing a history consisting
of two consecutive punctuation symbols, which is
not so much surprising after all.
A similar formula has been used for the lex-
ical model (Table 3), and the strenghtening of
the weights of the most detailed distributions has
been observed, too.
where
and
where
and
</bodyText>
<table confidence="0.973701">
Precision Recall F-measure ( )
Morphology output only (baseline; no rules applied) 28.97% 100.00% 44.92%
After application of the manually written rules 36.43% 99.66% 53.36%
</table>
<tableCaption confidence="0.997209">
Table 1: Evaluation of rules alone, average on all 5 test sets
</tableCaption>
<table confidence="0.999206">
no buckets 0.4371 0.5009 0.0600 0.0020
bucket 0 (least reliable histories) 0.0296 0.7894 0.1791 0.0019
bucket 1 0.1351 0.7120 0.1498 0.0031
bucket 2 0.2099 0.6474 0.1407 0.0019
bucket 32 (most reliable histories) 0.7538 0.2232 0.0224 0.0006
</table>
<tableCaption confidence="0.999396">
Table 2: Example smoothing coefficients for the tag language model (Exp 1 only)
</tableCaption>
<subsectionHeader confidence="0.998135">
3.2 Evaluation of the HMM Tagger alone
</subsectionHeader>
<bodyText confidence="0.999898375">
The HMM tagger described in the previous para-
graph has achieved results shown in Table 4. It
produces only the best tag sequence for every sen-
tence, therefore only accuracy is reported. Five-
fold cross-validation has been performed (Exp 1-
5) on a total data size of 1489983 tokens (exclud-
ing heldout data), divided up to five datasets of
roughly the same size.
</bodyText>
<sectionHeader confidence="0.9899" genericHeader="method">
4 The Serial Combination
</sectionHeader>
<bodyText confidence="0.999966260869565">
When the two systems are coupled together, the
manual rules are run first, and then the HMM tag-
ger runs as usual, except it selects from only those
tags retained at individual tokens by the manual
rule component, instead of from all tags as pro-
duced by the morphological analyzer:
The morphological analyzer is run on the test
data set. Every input token receives a list
of possible tags based on an extensive Czech
morphological dictionary.
The manual rule component is run on the
output of the morphology. The rules elimi-
nate some tags which cannot form grammat-
ical sentences in Czech.
The HMM tagger is run on the output of
the rule component, using only the remain-
ing tags at every input token. The output is
best-only; i.e., the tagger outputs exactly one
tag per input token.
If there is no tag left at a given input token after
the manual rules run, we reinsert all the tags from
morphology and let the statistical tagger decide as
if no rules had been used.
</bodyText>
<subsectionHeader confidence="0.996003">
4.1 Evaluation of the Combined Tagger
</subsectionHeader>
<bodyText confidence="0.9999866">
Table 5 contains the final evaluation of the main
contribution of this paper. Since the rule-based
component does not attempt at full disambigua-
tion, we can only use the F-measure for compari-
son and improvement evaluation6.
</bodyText>
<subsectionHeader confidence="0.866591">
4.2 Error Analysis
</subsectionHeader>
<bodyText confidence="0.9997892">
The not-so-perfect recall of the rule component
has been caused either by some deficiency in the
rules, or by an error in the input morphology (due
to a deficiency in the morphological dictionary),
or by an error in the ’truth’ (caused by an imper-
fect manual annotation).
As Czech syntax is extremely complex, some
of the rules are either not yet absolutely perfect,
or they are too strict7. An example of the rule
which decreases 100% recall for the test data is
the following one:
In Czech, if an unambiguous preposition is de-
tected in a clause, it “must” be followed - not
necessarily immediately - by a nominal element
(noun, adjective, pronoun or numeral) or, in very
</bodyText>
<footnote confidence="0.9959825">
6For the HMM tagger, which works in best-only mode,
accuracy = precision = recall = F-measure, of course.
7“Too strict” is in fact good, given the overall scheme
with the statistical tagger coming next, except in cases when
it severely limits the possibility of increasing the precision.
Nothing unexpected is happening here.
</footnote>
<table confidence="0.86174">
no buckets 0.3873 0.4461 0.0000 0.1666
</table>
<tableCaption confidence="0.99326">
Table 3: Example smoothing coefficients for the lexical model, no buckets (Exp 1 only)
</tableCaption>
<table confidence="0.99985">
Accuracy (smoothing w/o bucketing) Accuracy (bucketing)
Exp 1 95.23% 95.34%
Exp 2 94.95% 95.13%
Exp 3 95.04% 95.19%
Exp 4 94.77% 95.04%
Exp 5 94.86% 95.11%
Average 94.97% 95.16%
</table>
<tableCaption confidence="0.999901">
Table 4: Evaluation of the HMM tagger, 5-fold cross-validation
</tableCaption>
<bodyText confidence="0.99996416">
special cases, such a nominal element may be
missing as it is elided. This fact about the syn-
tax of prepositions in Czech is accounted for by
a rule associating an unambiguous preposition
with such a nominal element which is headed by
the preposition. The rule, however, erroneously
ignores the fact that some prepositions function
as heads of plain adverbs only (e.g., adverbs of
time). As an example occurring in the test data
we can take a simple structure “do kdy” (lit. till
when), where “do” is a preposition (lit. till), when
is an adverb of time and no nominal element fol-
lows. This results in the deletion of the preposi-
tional interpretation of the preposition “do” thus
causing an error. However, in cases like this, it
is more appropriate to add another condition to
the context (gaining back the lost recall) of such a
rule rather than discard the rule as a whole (which
would harm the precision too much).
As examples of erroneous tagging results
which have been eliminated for good due to the
architecture described we might put forward:
preposition requiring case not followed by
any form in case :any preposition has to be
followed by at least one form (of noun, ad-
jective, pronoun or numeral) in the case re-
quired. Turning this around, if a word which
is ambiguous between a preposition and an-
other part of speech is not followed by the
respective form till the end of the sentence,
it is safe to discard the prepositional reading
in almost all non-idiomatic, non-coordinated
cases.
two finite verbs within a clause: Similarly
to most languages, a Czech clause must not
contain more than one finite verb. This
means that if two words, one genuine finite
verb and the other one ambiguous between a
finite verb and another reading, stand in such
a configuration that the material between
them contains no clause separator (comma,
conjunction), it is safe to discard the finite
verb reading with the ambiguous word.
two nominative cases within a clause: The
subject in Czech is usually case-marked by
nominative, and simultaneously, even when
the position of subject is free (it can stand
both to the left or to the right of the main
verb) in Czech, no clause can have two non-
coordinated subjects.
</bodyText>
<sectionHeader confidence="0.996114" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999943071428572">
The improvements obtained (4.58% relative er-
ror reduction) beat the pure statistical classifier
combination (Hladk´a, 2000), which obtained only
3% relative improvement. The most important
task for the manual-rule component is to keep re-
call very close to 100%, with the task of improv-
ing precision as much as possible. Even though
the rule-based component is still under develop-
ment, the 19% relative improvement in F-measure
over the baseline (i.e., 16% reduction in the F-
complement while keeping recall just 0.34% un-
der the absolute one) is encouraging.
In any case, we consider the clear “division
of labor” between the two parts of the system a
</bodyText>
<table confidence="0.999185714285714">
HMM (w/bucketing) Rules Combined diff. combined - HMM (rel.)
Exp 1 95.34% 53.65% 95.53% 4.08%
Exp 2 95.13% 52.39% 95.36% 4.72%
Exp 3 95.19% 53.49% 95.41% 4.57%
Exp 4 95.04% 53.44% 95.28% 4.84%
Exp 5 95.11% 53.82% 95.34% 4.70%
Average 95.16% 53.36% 95.38% 4.58%
</table>
<tableCaption confidence="0.986679">
Table 5: F-measure-based evaluation of the combined tagger, 5-fold cross-validation
</tableCaption>
<table confidence="0.997853777777778">
Word Form Annotator Tagger
Mal´e (Small) AAFP1----1A---- AAFP1----1A----
organizace (businesses) NNFP1 A---- NNFP1 A----
maji(have) VB-P---3P-AA--- VB-P---3P-AA---
probl´emy (problems) NNIP4 A---- NNIP4 A----
se (with) (!ERROR!) P7-X4 RV--7
zisk´anim (getting) NNNS7 A---- NNNS7 A----
telefonnich (phone) AAFP2----1A---- AAFP2----1A----
linek (lines) NNFP2 A---- NNFP2 A----
</table>
<figureCaption confidence="0.998816">
Figure 1: Annotation error: P7-X4 , should have been: RV--7
</figureCaption>
<bodyText confidence="0.976886963636364">
strong advantage. It allows now and in the future
to use different taggers and different rule-based
systems within the same framework but in a com-
pletely independent fashion.
The performance of the pure HMM tagger
alone is an interesting result by itself, beating the
best Czech tagger published (Hajiˇc and Hladk´a,
1998) by almost 2% (30% relative improvement)
and a previous HMM tagger on Czech (Mirovsk´y,
1998) by almost 4% (44% relative improvement).
We believe that the key to this success is both
the increased data size (we have used three times
more training data then reported in the previ-
ous papers) and the meticulous implementation of
smoothing with bucketing together with using all
possible tag trigrams, which has never been done
before.
One might question whether it is worthwhile
to work on a manual rule component if the im-
provement over the pure statistical system is not
so huge, and there is the obvious disadvantage in
its language-specificity. However, we see at least
two situations in which this is the case: first, the
need for high quality tagging for local language
projects, such as human-oriented lexicography,
where every 1/10th of a percent of reduction in
error rate counts, and second, a situation where
not enough training data is available for a high-
quality statistical tagger for a given language, but
a language expertise does exist; the improvement
over an imperfect statistical tagger should then be
more visible8.
Another interesting issue is the evaluation
method used for taggers. From the linguistic
point of view, not all errors are created equal; it
is clear that the manual rule component does not
commit linguistically trivial errors (see Sect. 4.2).
However, the relative weighting (if any) of errors
should be application-based, which is already out-
side of the scope of this paper.
It has been also observed that the improved tag-
ger can serve as an additional means for discov-
ering annotator’s errors (however infrequent they
are, they are there). See Fig. 1 for an example of
wrong annotation of “se”.
In the near future, we plan to add more rules, as
well as continue to work on the statistical tagging.
The lexical component of the tagger might still
have some room for improvement, such as the use
8However, a feature-based log-linear tagger might per-
form better for small training data, as argued in (Hajiˇc,
2000).
of
which can be feasible with the powerful
smoothing we now employ.
</bodyText>
<sectionHeader confidence="0.998954" genericHeader="acknowledgments">
6 Acknowledgements
</sectionHeader>
<bodyText confidence="0.9997715">
The work described herein has been supported by
the following grants: MˇSMT LN00A063 (“Cen-
trum komputaˇcnilingvistiky”), MˇSMT ME 293
(Kontakt), and GAˇCR 405/96/K214.
</bodyText>
<sectionHeader confidence="0.998949" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999808895348837">
E. Bick. 1996. Automatic parsing of Portuguese. Pro-
ceedings ofthe Second Workshop on Computational
Processing of Written Portuguese, Curitiba, pages
91–100.
E. Bick. 2000. The parsing system “Palavras” - au-
tomatic grammatical analysis of Portuguese in a
constraint grammar framework. 2nd International
Conference on Language Resources and Evalua-
tion, Athens, Greece. TELRI.
J. P. Chanod and P. Tapanainen. 1995. Tagging French
- comparing a statistical and a constraint-based
method. In Proceeedings of EACL-95, Dublin,
pages 149–157. ACL.
Walter Daelemans, Jakub Zavrel, Peter Berck, and
Steven Gillis. 1996. MBT: A memory-based
part of speech tagger generator. In Proceedings of
WVLC 4, pages 14–27. ACL.
Tomaˇz Erjavec, Saso Dieroski, and Jakub Zavrel.
1999. Morphosyntactic Tagging of Slovene: Eval-
uating PoS Taggers and Tagsets. Technical Report
IJS-DP 8018, Dept. for Intelligent Systems, J´ozef
ˇStefan Institute, Ljubljana, Slovenia, April 2nd.
N. Ezeiza, I. Alegria, J. M. Ariola, R. Urizar, and
I. Aduriz. 1998. Combining stochastic and rule-
based methods for disambiguation in agglutinative
languages. In Proceedings of ACL/COLING’98,
Montreal, Canada, pages 379–384. ACL/ICCL.
Jan Hajiˇc. 1998. Building a syntactically an-
notated corpus: The Prague Dependency Tree-
bank. In E. Hajiˇcov´a, editor, Festschrift for Jarmila
Panevov´a, pages 106–132. Karolinum, Charles
University, Prague.
Jan Hajiˇc. 2000. Morphological tagging: Data vs. dic-
tionaries. In Proceedings of the NAACL’00, Seattle,
WA, pages 94–101. ACL.
Jan Hajiˇc and Barbora Hladk´a. 1997. Tagging of in-
flective languages: a comparison. In Proceedings of
ANLP’97, Washington, DC, pages 136–143. ACL.
Jan Hajiˇc and Barbora Hladk´a. 1998. Tagging inflec-
tive languages: Prediction of morphological cate-
gories for a rich, structured tagset. In Proceed-
ings ofACL/COLING’98, Montreal, Canada, pages
483–490. ACL/ICCL.
D. Hakkani-Tur, K. Oflazer, and G. Tur. 2000. Statis-
tical morphological disambiguation for agglutina-
tive languages. In Proceedings of the 18th Coling
2000, Saarbruecken, Germany.
Barbora Hladk´a. 2000. Czech Language Tagging.
Ph.D. thesis, ´UFAL, Faculty of Mathematics and
Physics, Charles University, Prague. 135 pp.
Fred Jelinek. 1997. Statistical Methods for Speech
Recognition. MIT Press, Cambridge, MA.
F. Karlsson, A. Voutilainen, J. Heikkil¨a, and A. An-
tilla, editors. 1995. Constraint Grammar: a
Language-Independent System for Parsing Unre-
stricted Text. Mouton de Gruyter, Berlin New York.
Jiˇr´ı Mirovsk´y. 1998. Morfologick´e znaˇckov´anitextu:
automatick´a disambiguace (in Czech). Master’s
thesis, ´UFAL, Faculty of Mathematics and Physics,
Charles University, Prague. 56 pp.
G. Ngai and D. Yarowsky. 2000. Rule writing or
annotation: Cost-efficient resource usage for base
noun phrase chunking. In Proceedings of the 38th
Annual Meeting of the ACL, Hong Kong, pages
117–125. ACL.
G. Ngai. 2001. Maximizing Resources for Corpus-
Based Natural Language Processing. Ph.D. the-
sis, Johns Hopkins University, Baltimore, Mary-
land, USA.
M. Pl´atek, P. Janˇcar, F. Mr´az, and J. Vogel. 1995. On
restarting automata with rewriting. Technical Re-
port 96/5, Charles University, Prague.
Adwait Ratnaparkhi. 1996. A maximum entropy
model for part-of-speech tagging. In Proceedings
ofEMNLP 1, pages 133–142. ACL.
C. Samuelsson and A. Voutilainen. 1997. Compar-
ing a linguistic and a stochastic tagger. In Proceed-
ings ofACL/EACL Joint Conference, Madrid, pages
246–252. ACL.
P. Tapanainen and A. Voutilainen. 1994. Tagging ac-
curately: Don’t guess if you know. Technical re-
port, Xerox Corp.
Scott M. Thede and Mary P. Harper. 1999. A Second-
Order Hidden Markov Model for Part-of-Speech
Tagging. Proceedings of ACL’99, pages 175–182.
ACL.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000012">
<title confidence="0.9984695">Serial Combination of Rules and Statistics: A Case Study in Czech Tagging</title>
<author confidence="0.999475">Jan Hajiˇc Pavel Krbec Pavel Kvˇetoˇn Karel Oliva Vladimir Petkeviˇc</author>
<affiliation confidence="0.824095">IFAL ICNC Computational ITCL MFF UK FF UK Linguistics FF UK Prague Prague Univ. of Saarland Prague Czechia Czechia Germany Czechia</affiliation>
<abstract confidence="0.989959192771084">hajic,krbec @ ufal.mff.cuni.cz Pavel.Kveton@ ff.cuni.cz oliva@ Vladimir.Petkevic@ coli.uni-sb.de ff.cuni.cz Abstract A hybrid system is described which combines the strength of manual rulewriting and statistical learning, obtaining results superior to both methods if applied separately. The combination of a rule-based system and a statistical one is not parallel but serial: the rule-based system performing partial disambiguation with recall close to 100% is applied first, and a trigram HMM tagger runs on its results. An experiment in Czech tagging has been performed with encouraging results. 1 Tagging of Inflective Languages Inflective languages pose a specific problem in tagging due to two phenomena: highly inflective nature (causing sparse data problem in any statistically-based system), and free word order (causing fixed-context systems, such as n-gram Hidden Markov Models (HMMs), to be even less adequate than for English). The average tagset contains about 1,000 - 2,000 distinct tags; the size of the set of possible and plausible tags can reach several thousands. Apart from agglutinative languages such as Turkish, Finnish and Hungarian (see e.g. (Hakkani-Tur et al., 2000)), and Basque (Ezeiza et al., 1998), which pose quite different and in the end less severe problems, there have been attempts at solving this problem for some of the highly inflectional European languages, such as (Daelemans et al., 1996), (Erjavec et al., 1999) (Slovenian), (Hajiˇc and Hladk´a, 1997), (Hajiˇc and Hladk´a, 1998) (Czech) and (Hajiˇc, 2000) (five Central and Eastern European languages), but so far no system has reached in the absolute terms a performance comparable to English tagging (such as (Ratnaparkhi, 1996)), which stands around or above 97%. For example, (Hajiˇc and Hladk´a, 1998) report results on Czech slightly above 93% only. One has to realize that even though such a performance might be adequate for some tasks (such as word sense disambiguation), for many other (such as parsing or translation) the implied sentence error rate at 50% or more is simply too much to deal with. 1.1 Statistical Tagging Statistical tagging of inflective languages has been based on many techniques, ranging from plain-old HMM taggers (Mirovsk´y, 1998), memory-based (Erjavec et al., 1999) to maximum-entropy and feature-based (Hajiˇc and Hladk´a, 1998), (Hajiˇc, 2000). For Czech, the best result achieved so far on approximately 300 thousand word training data set has been described in (Hajiˇc and Hladk´a, 1998). We are using 1.8M manually annotated tokens from the Prague Dependency Treebank (PDT) project (Hajiˇc, 1998). We have decided to work an HMM in the usual source-channel setting, with proper smoothing. The HMM tagger uses the Czech morphological processor from PDT to disambiguate only among those tags because of the ease with which it is trained even on large data, and also because no other publicly available tagger was able to cope with the amount and ambiguity of the data in reasonable time. which are morphologically plausible for a given input word form. 1.2 Manual Rule-based Systems The idea of tagging by means of hand-written disambiguation rules has been put forward and implemented for the first time in the form of Constraint-Based Grammars (Karlsson et al., 1995). From languages we are acquainted with, the method has been applied on a larger scale only</abstract>
<note confidence="0.637883428571429">to English (Karlsson et al., 1995), (Samuelsson and Voutilainen, 1997), and French (Chanod and Tapanainen, 1995). Also (Bick, 1996) and (Bick, 2000) use manually written rules for Brazilian Portuguese, and there are several publications by Oflazer for Turkish. Authors of such systems claim that hand-</note>
<abstract confidence="0.99045344978166">written systems can perform better than systems based on machine learning (Samuelsson and Voutilainen, 1997); however, except for the work cited, comparison is difficult to impossible due to the fact that they do not use the standard evaluation techniques (and not even the same data). But the substantial disadvantage is that the development of manual rule-based systems is demanding and requires a good deal of very subtle linguistic expertise and skills if full disambiguation also of “difficult” texts is to be performed. 1.3 System Combination Combination of (manual) rule-writing and statistical learning has been studied before. E.g., (Ngai and Yarowsky, 2000) and (Ngai, 2001) provide a thorough description of many experiments involving rule-based systems and statistical learners for NP bracketing. For tagging, combination of purely statistical classifiers has been described (Hladk´a, 2000), with about 3% relative improvement (error reduction from 18.6% to 18%, trained on small data) over the best original system. We regard such systems as working in parallel, since all the original classifiers run independently of each other. In the present study, we have chosen a different strategy (similar to the one described for other types of languages in (Tapanainen and Voutilainen, 1994), (Ezeiza et al., 1998) and (Hakkani- Tur et al., 2000)). At the same time, the rulebased component is known to perform well in incorrect rather than picking the correct one under all circumstances. Moreover, the rule-based system used can examine the whole sentential context, again a difficult for a statistical That way, the ambiof the input decreases. This is exactly what our statistical HMM tagger needs as its input, since it is already capable of using the lexical information from a dictionary. However, also in the rule-based approach, there is the usual tradeoff between precision and recall. We have decided to go for the “perfect” solution: to keep 100% recall, or very close to it, and gradually improve precision by writing rules which eliminate more and more incorrect tags. This way, we can be sure (or almost sure) that the performance of the HMM tagger performance will not be hurt by (recall) errors made by the rule component. 2 The Rule-based Component 2.1 Formal Means Taken strictly formally, the rule-based component has the form of a restarting automaton with deletion (Pl´atek et al., 1995), that is, each rule can be thought of as a finite-state automaton starting from the beginning of the sentence and passing to the right until it finds an input configuration on which it can operate by deletion of some parts of the input. Having performed this, the whole system is restarted, which means that the next rule is applied on the changed input (and this input is again read from the left end). This means that a single rule has the power of a finite state automaton, but the system as a whole has (even more than) a context-free power. 2.2 The Rules and Their Implementation The system of hand-written rules for Czech has a twofold objective: practical: an error-free and at the same time the most accurate tagging of Czech texts theoretical: the description of the syntactic a “negative” learning is thought to be difficult for any statistical system. an immediate data sparseness problem. prepared by the morphological analyzer. of Czech, its rather than pa- The rules are to reduce the input ambiguity of the input text. During disambiguation the whole rule system combines two methods: the oblique one consisting in the elimination of syntactically wrong tag(s), i.e. in the reduction of the input ambiguity by deleting those tags which are excluded by the context the direct choice of the correct tag(s). The overall strategy of the rule system is to keep the highest recall possible (i.e. 100%) and gradually improve precision. Thus, the rules are (manually) assigned reliabilities which divide the rules into reliability classes, with the most reliable (“bullet-proof”) group of rules applied first and less reliable groups of rules (threatening to decrease the 100% recall) being applied in subsequent steps. The bullet-proof rules reflect general syntactic regularities of Czech; for instance, no word form in the nominative case can follow an unambiguous preposition. The less reliable rules can be exemplified by those accounting for some special intricate relations of grammatical agreement in Czech. Within each reliability group the rules are applied independently, i.e. in any order in a cyclic way until no ambiguity can be resolved. Besides reliability, the rules can be generally divided according to the locality/nonlocality of their scope. Some phenomena (not many) in the structure of Czech sentence are local in nature: for instance, for the word “se” which is two-way between a preposition and a reparticle/pronoun as a particle) a prepositional reading can be available only in local contexts requiring the vocalisation of the basic of the preposition “s” resulting in the form “se”. However, in the majority of phenomena the correct disambiguation requires a much wider context. Thus, the rules use as wide context as possible with no context limitations being imposed in advance. During rules development performed so far, sentential context has been used, but nothing in principle limits the context to a single sentence. If it is generally appropriate for the disambiguation of the languages of the world to use unlimited context, it is especially fit for languages with free word order combined with rich inflection. There are many syntactic phenomena in Czech displaying the following property: a form be part-of-speech determined means of another word form wordorder distance cannot be determined by a fixed number of positions between the two word forms. This is exactly a general phenomenon which is grasped by the hand-written rules. Formally, each rule consists of the description of the context (descriptive component), and the action to be performed given the context (executive component): i.e. which tags are to be discarded or which tag(s) are to be proclaimed correct (the rest being discarded as wrong). For example, Context: unambiguous finite verb, followed/preceded by a sequence of tokens containing neither comma nor coordinating at either side of a word ambiguous between a finite verb and another reading Action: delete the finite verb reading(s) at word There are two ways of rule development: the rules developed by syntactic introspection: such rules are subsequently verified on the corpus material, then implemented and the implemented rules are tested on a testing corpus the rules are derived from the corpus by introspection and subsequently implemented The rules are formulated as generally as possible and at the same time as error-free (recallwise) as possible. This approach of combining the requirements of maximum recall and maximum precision demands sophisticated syntactic knowledge of Czech. This knowledge is primarily based on the study of types of morphological ambiguity occurring in Czech. There are two main types of such ambiguity: regular (paradigm-internal) casual (lexical) a bucketed linear interpolation smoothing for both models. The regular (paradigm-internal) ambiguities occur within a paradigm, i.e. they are common to all lexemes belonging to a particular inflection class. For example, in Czech (as in many other inflective languages), the nominative, the accusative and the vocative case have the same form (in singular on the one hand, and in plural on the other). The casual (lexical, paradigm-external) morphological ambiguity is lexically specific and hence cannot be investigated via paradigmatics. In addition to the general rules, the rule approach includes a module which accounts for collocations and idioms. The problem is that the majority of collocations can – besides their most probable interpretation just as collocations – have also their literal meaning. Currently, the system (as evaluated in Sect. 2.3) consists of 80 rules. The rules had been implemented procedurally in the initial phase; a special feature-oriented, interpreted “programming language” is now under development. 2.3 Evaluation of the Rule System Alone The results are presented in Table 1. We use the usual equal-weight formula for F-measure: 3 The Statistical Component 3.1 The BMM Tagger We have used an HMM tagger in the usual sourcechannel setting, fine-tuned to perfection using a 3-gram tag language model , a tag-to-word lexical (translation) model usbigram histories instead of just sameconditioning used in (Thede and Harper, 1999), as far as we know. Thus the HMM tagger outputs a sequence of tags according to the usual equation The tagger has been trained in the usual way, using part of the training data as heldout data for smoothing of the two models employed. There is no threshold being applied for low counts. Smoothing has been done first without using buckets, and then with them to show the difference. Table 2 shows the resulting interpolation coefficients for the tag language model using the usual linear interpolation smoothing formula where p(...) is the “raw” Maximum Likelihood estimate of the probability distributions, i.e. the relative frequency in the training data. The bucketing scheme for smoothing (a necessity when keeping all tag trigrams and tag-toword bigrams) uses “buckets bounds” computed according to the following formula (for more on bucketing, see (Jelinek, 1997)): It should be noted that when using this bucketing scheme, the weights of the detailed distributions (with longest history) grow quickly as the history reliability increases. However, it is not monotonic; at several of the most reliable histories, the weight coefficients “jump” up and down. We have found that a sudden drop in happens, e.g., for the bucket containing a history consisting of two consecutive punctuation symbols, which is not so much surprising after all. A similar formula has been used for the lexical model (Table 3), and the strenghtening of the weights of the most detailed distributions has been observed, too. where and where and Precision Recall F-measure ( ) Morphology output only (baseline; no rules applied) 28.97% 100.00% 44.92% After application of the manually written rules 36.43% 99.66% 53.36% Table 1: Evaluation of rules alone, average on all 5 test sets no buckets 0.4371 0.5009 0.0600 0.0020 bucket 0 (least reliable histories) 0.0296 0.7894 0.1791 0.0019 bucket 1 0.1351 0.7120 0.1498 0.0031 bucket 2 0.2099 0.6474 0.1407 0.0019 bucket 32 (most reliable histories) 0.7538 0.2232 0.0224 0.0006 Table 2: Example smoothing coefficients for the tag language model (Exp 1 only) 3.2 Evaluation of the HMM Tagger alone The HMM tagger described in the previous paragraph has achieved results shown in Table 4. It produces only the best tag sequence for every sentence, therefore only accuracy is reported. Fivefold cross-validation has been performed (Exp 1- 5) on a total data size of 1489983 tokens (excluding heldout data), divided up to five datasets of roughly the same size. 4 The Serial Combination When the two systems are coupled together, the manual rules are run first, and then the HMM tagger runs as usual, except it selects from only those tags retained at individual tokens by the manual rule component, instead of from all tags as produced by the morphological analyzer: The morphological analyzer is run on the test data set. Every input token receives a list of possible tags based on an extensive Czech morphological dictionary. The manual rule component is run on the output of the morphology. The rules eliminate some tags which cannot form grammatical sentences in Czech. The HMM tagger is run on the output of the rule component, using only the remaining tags at every input token. The output is best-only; i.e., the tagger outputs exactly one tag per input token. If there is no tag left at a given input token after the manual rules run, we reinsert all the tags from morphology and let the statistical tagger decide as if no rules had been used. 4.1 Evaluation of the Combined Tagger Table 5 contains the final evaluation of the main contribution of this paper. Since the rule-based component does not attempt at full disambiguation, we can only use the F-measure for compariand improvement 4.2 Error Analysis The not-so-perfect recall of the rule component has been caused either by some deficiency in the rules, or by an error in the input morphology (due to a deficiency in the morphological dictionary), or by an error in the ’truth’ (caused by an imperfect manual annotation). As Czech syntax is extremely complex, some of the rules are either not yet absolutely perfect, they are too An example of the rule which decreases 100% recall for the test data is the following one: In Czech, if an unambiguous preposition is detected in a clause, it “must” be followed not necessarily immediately by a nominal element (noun, adjective, pronoun or numeral) or, in very the HMM tagger, which works in best-only mode, accuracy = precision = recall = F-measure, of course. strict” is in fact good, given the overall scheme with the statistical tagger coming next, except in cases when it severely limits the possibility of increasing the precision. Nothing unexpected is happening here. no buckets 0.3873 0.4461 0.0000 0.1666 Table 3: Example smoothing coefficients for the lexical model, no buckets (Exp 1 only) Accuracy (smoothing w/o bucketing) Accuracy (bucketing) Exp 1 95.23% 95.34% Exp 2 94.95% 95.13% Exp 3 95.04% 95.19% Exp 4 94.77% 95.04% Exp 5 94.86% 95.11% Average 94.97% 95.16% Table 4: Evaluation of the HMM tagger, 5-fold cross-validation special cases, such a nominal element may be missing as it is elided. This fact about the syntax of prepositions in Czech is accounted for by a rule associating an unambiguous preposition with such a nominal element which is headed by the preposition. The rule, however, erroneously ignores the fact that some prepositions function as heads of plain adverbs only (e.g., adverbs of time). As an example occurring in the test data can take a simple structure “do kdy” (lit. where “do” is a preposition (lit. is an adverb of time and no nominal element follows. This results in the deletion of the prepositional interpretation of the preposition “do” thus causing an error. However, in cases like this, it is more appropriate to add another condition to the context (gaining back the lost recall) of such a rule rather than discard the rule as a whole (which would harm the precision too much). As examples of erroneous tagging results which have been eliminated for good due to the architecture described we might put forward: preposition requiring case not followed by any form in case :any preposition has to be followed by at least one form (of noun, adjective, pronoun or numeral) in the case required. Turning this around, if a word which is ambiguous between a preposition and another part of speech is not followed by the respective form till the end of the sentence, it is safe to discard the prepositional reading in almost all non-idiomatic, non-coordinated cases. two finite verbs within a clause: Similarly to most languages, a Czech clause must not contain more than one finite verb. This means that if two words, one genuine finite verb and the other one ambiguous between a finite verb and another reading, stand in such a configuration that the material between them contains no clause separator (comma, conjunction), it is safe to discard the finite verb reading with the ambiguous word. two nominative cases within a clause: The subject in Czech is usually case-marked by nominative, and simultaneously, even when the position of subject is free (it can stand both to the left or to the right of the main verb) in Czech, no clause can have two noncoordinated subjects. 5 Conclusions The improvements obtained (4.58% relative error reduction) beat the pure statistical classifier combination (Hladk´a, 2000), which obtained only 3% relative improvement. The most important task for the manual-rule component is to keep recall very close to 100%, with the task of improving precision as much as possible. Even though the rule-based component is still under development, the 19% relative improvement in F-measure over the baseline (i.e., 16% reduction in the Fcomplement while keeping recall just 0.34% under the absolute one) is encouraging. In any case, we consider the clear “division of labor” between the two parts of the system a HMM (w/bucketing) Rules Combined diff. combined - HMM (rel.) Exp 1 95.34% 53.65% 95.53% 4.08% Exp 2 95.13% 52.39% 95.36% 4.72% Exp 3 95.19% 53.49% 95.41% 4.57% Exp 4 95.04% 53.44% 95.28% 4.84% Exp 5 95.11% 53.82% 95.34% 4.70% Average 95.16% 53.36% 95.38% 4.58% Table 5: F-measure-based evaluation of the combined tagger, 5-fold cross-validation Word Form Annotator Tagger AAFP1----1A---- AAFP1----1A---- NNFP1 A---- NNFP1 A---- VB-P---3P-AA--- VB-P---3P-AA--- NNIP4 A---- NNIP4 A---- (with)(!ERROR!) P7-X4 RV--7 NNNS7 A---- NNNS7 A---- AAFP2----1A---- AAFP2----1A---- NNFP2 A---- NNFP2 A---- 1: Annotation error: should have been: strong advantage. It allows now and in the future to use different taggers and different rule-based systems within the same framework but in a completely independent fashion. The performance of the pure HMM tagger alone is an interesting result by itself, beating the best Czech tagger published (Hajiˇc and Hladk´a, 1998) by almost 2% (30% relative improvement) and a previous HMM tagger on Czech (Mirovsk´y, 1998) by almost 4% (44% relative improvement). We believe that the key to this success is both the increased data size (we have used three times more training data then reported in the previous papers) and the meticulous implementation of smoothing with bucketing together with using all possible tag trigrams, which has never been done before. One might question whether it is worthwhile to work on a manual rule component if the improvement over the pure statistical system is not so huge, and there is the obvious disadvantage in its language-specificity. However, we see at least two situations in which this is the case: first, the need for high quality tagging for local language projects, such as human-oriented lexicography, where every 1/10th of a percent of reduction in error rate counts, and second, a situation where not enough training data is available for a highquality statistical tagger for a given language, but a language expertise does exist; the improvement over an imperfect statistical tagger should then be Another interesting issue is the evaluation method used for taggers. From the linguistic point of view, not all errors are created equal; it is clear that the manual rule component does not commit linguistically trivial errors (see Sect. 4.2). However, the relative weighting (if any) of errors should be application-based, which is already outside of the scope of this paper. It has been also observed that the improved tagger can serve as an additional means for discovering annotator’s errors (however infrequent they are, they are there). See Fig. 1 for an example of wrong annotation of “se”. In the near future, we plan to add more rules, as well as continue to work on the statistical tagging. The lexical component of the tagger might still have some room for improvement, such as the use a feature-based log-linear tagger might perform better for small training data, as argued in (Hajiˇc, 2000). of which can be feasible with the powerful smoothing we now employ.</abstract>
<note confidence="0.672112413043478">6 Acknowledgements The work described herein has been supported by following grants: LN00A063 (“Cenkomputaˇcnilingvistiky”), ME 293 and 405/96/K214. References Bick. 1996. Automatic parsing of Portuguese. Proceedings ofthe Second Workshop on Computational of Written Portuguese, pages 91–100. E. Bick. 2000. The parsing system “Palavras” automatic grammatical analysis of Portuguese in a grammar framework. International Conference on Language Resources and Evalua- Athens, Greece. TELRI. J. P. Chanod and P. Tapanainen. 1995. Tagging French comparing a statistical and a constraint-based In of Dublin, pages 149–157. ACL. Walter Daelemans, Jakub Zavrel, Peter Berck, and Steven Gillis. 1996. MBT: A memory-based of speech tagger generator. In of pages 14–27. ACL. Tomaˇz Erjavec, Saso Dieroski, and Jakub Zavrel. 1999. Morphosyntactic Tagging of Slovene: Evaluating PoS Taggers and Tagsets. Technical Report IJS-DP 8018, Dept. for Intelligent Systems, J´ozef Institute, Ljubljana, Slovenia, April 2nd. N. Ezeiza, I. Alegria, J. M. Ariola, R. Urizar, and I. Aduriz. 1998. Combining stochastic and rulebased methods for disambiguation in agglutinative In of Montreal, Canada, pages 379–384. ACL/ICCL. Hajiˇc. 1998. Building a syntactically annotated corpus: The Prague Dependency Tree- In E. Hajiˇcov´a, editor, for Jarmila pages 106–132. Karolinum, Charles University, Prague. Jan Hajiˇc. 2000. Morphological tagging: Data vs. dic- In of the Seattle, WA, pages 94–101. ACL. Jan Hajiˇc and Barbora Hladk´a. 1997. Tagging of inlanguages: a comparison. In of Washington, DC, pages 136–143. ACL. Jan Hajiˇc and Barbora Hladk´a. 1998. Tagging inflective languages: Prediction of morphological catefor a rich, structured tagset. In Proceed- Montreal, Canada, pages 483–490. ACL/ICCL. D. Hakkani-Tur, K. Oflazer, and G. Tur. 2000. Statistical morphological disambiguation for agglutinalanguages. In of the 18th Coling Saarbruecken, Germany. Hladk´a. 2000. Language Ph.D. thesis, ´UFAL, Faculty of Mathematics and Physics, Charles University, Prague. 135 pp. Jelinek. 1997. Methods for Speech MIT Press, Cambridge, MA. F. Karlsson, A. Voutilainen, J. Heikkil¨a, and A. Aneditors. 1995. Grammar: a Language-Independent System for Parsing Unre- Mouton de Gruyter, Berlin New York. Jiˇr´ı Mirovsk´y. 1998. Morfologick´e znaˇckov´anitextu: automatick´a disambiguace (in Czech). Master’s thesis, ´UFAL, Faculty of Mathematics and Physics, Charles University, Prague. 56 pp. G. Ngai and D. Yarowsky. 2000. Rule writing or annotation: Cost-efficient resource usage for base phrase chunking. In of the 38th Meeting of the Hong Kong, pages 117–125. ACL. Ngai. 2001. Resources for Corpus- Natural Language Ph.D. thesis, Johns Hopkins University, Baltimore, Maryland, USA. M. Pl´atek, P. Janˇcar, F. Mr´az, and J. Vogel. 1995. On restarting automata with rewriting. Technical Report 96/5, Charles University, Prague. Adwait Ratnaparkhi. 1996. A maximum entropy for part-of-speech tagging. In pages 133–142. ACL. C. Samuelsson and A. Voutilainen. 1997. Compara linguistic and a stochastic tagger. In ProceedofACL/EACL Joint Madrid, pages 246–252. ACL. P. Tapanainen and A. Voutilainen. 1994. Tagging accurately: Don’t guess if you know. Technical report, Xerox Corp. Scott M. Thede and Mary P. Harper. 1999. A Second- Order Hidden Markov Model for Part-of-Speech of pages 175–182. ACL.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Bick</author>
</authors>
<title>Automatic parsing of Portuguese.</title>
<date>1996</date>
<booktitle>Proceedings ofthe Second Workshop on Computational Processing of Written Portuguese,</booktitle>
<pages>91--100</pages>
<location>Curitiba,</location>
<contexts>
<context position="3826" citStr="Bick, 1996" startWordPosition="600" endWordPosition="601">r publicly available tagger was able to cope with the amount and ambiguity of the data in reasonable time. which are morphologically plausible for a given input word form. 1.2 Manual Rule-based Systems The idea of tagging by means of hand-written disambiguation rules has been put forward and implemented for the first time in the form of Constraint-Based Grammars (Karlsson et al., 1995). From languages we are acquainted with, the method has been applied on a larger scale only to English (Karlsson et al., 1995), (Samuelsson and Voutilainen, 1997), and French (Chanod and Tapanainen, 1995). Also (Bick, 1996) and (Bick, 2000) use manually written rules for Brazilian Portuguese, and there are several publications by Oflazer for Turkish. Authors of such systems claim that handwritten systems can perform better than systems based on machine learning (Samuelsson and Voutilainen, 1997); however, except for the work cited, comparison is difficult to impossible due to the fact that they do not use the standard evaluation techniques (and not even the same data). But the substantial disadvantage is that the development of manual rule-based systems is demanding and requires a good deal of very subtle lingui</context>
</contexts>
<marker>Bick, 1996</marker>
<rawString>E. Bick. 1996. Automatic parsing of Portuguese. Proceedings ofthe Second Workshop on Computational Processing of Written Portuguese, Curitiba, pages 91–100.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Bick</author>
</authors>
<title>The parsing system “Palavras” - automatic grammatical analysis of Portuguese in a constraint grammar framework.</title>
<date>2000</date>
<booktitle>2nd International Conference on Language Resources and Evaluation,</booktitle>
<location>Athens, Greece. TELRI.</location>
<contexts>
<context position="3843" citStr="Bick, 2000" startWordPosition="603" endWordPosition="604">ble tagger was able to cope with the amount and ambiguity of the data in reasonable time. which are morphologically plausible for a given input word form. 1.2 Manual Rule-based Systems The idea of tagging by means of hand-written disambiguation rules has been put forward and implemented for the first time in the form of Constraint-Based Grammars (Karlsson et al., 1995). From languages we are acquainted with, the method has been applied on a larger scale only to English (Karlsson et al., 1995), (Samuelsson and Voutilainen, 1997), and French (Chanod and Tapanainen, 1995). Also (Bick, 1996) and (Bick, 2000) use manually written rules for Brazilian Portuguese, and there are several publications by Oflazer for Turkish. Authors of such systems claim that handwritten systems can perform better than systems based on machine learning (Samuelsson and Voutilainen, 1997); however, except for the work cited, comparison is difficult to impossible due to the fact that they do not use the standard evaluation techniques (and not even the same data). But the substantial disadvantage is that the development of manual rule-based systems is demanding and requires a good deal of very subtle linguistic expertise an</context>
</contexts>
<marker>Bick, 2000</marker>
<rawString>E. Bick. 2000. The parsing system “Palavras” - automatic grammatical analysis of Portuguese in a constraint grammar framework. 2nd International Conference on Language Resources and Evaluation, Athens, Greece. TELRI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J P Chanod</author>
<author>P Tapanainen</author>
</authors>
<title>Tagging French - comparing a statistical and a constraint-based method.</title>
<date>1995</date>
<booktitle>In Proceeedings of EACL-95,</booktitle>
<pages>149--157</pages>
<publisher>ACL.</publisher>
<location>Dublin,</location>
<contexts>
<context position="3807" citStr="Chanod and Tapanainen, 1995" startWordPosition="595" endWordPosition="598">large data, and also because no other publicly available tagger was able to cope with the amount and ambiguity of the data in reasonable time. which are morphologically plausible for a given input word form. 1.2 Manual Rule-based Systems The idea of tagging by means of hand-written disambiguation rules has been put forward and implemented for the first time in the form of Constraint-Based Grammars (Karlsson et al., 1995). From languages we are acquainted with, the method has been applied on a larger scale only to English (Karlsson et al., 1995), (Samuelsson and Voutilainen, 1997), and French (Chanod and Tapanainen, 1995). Also (Bick, 1996) and (Bick, 2000) use manually written rules for Brazilian Portuguese, and there are several publications by Oflazer for Turkish. Authors of such systems claim that handwritten systems can perform better than systems based on machine learning (Samuelsson and Voutilainen, 1997); however, except for the work cited, comparison is difficult to impossible due to the fact that they do not use the standard evaluation techniques (and not even the same data). But the substantial disadvantage is that the development of manual rule-based systems is demanding and requires a good deal of</context>
</contexts>
<marker>Chanod, Tapanainen, 1995</marker>
<rawString>J. P. Chanod and P. Tapanainen. 1995. Tagging French - comparing a statistical and a constraint-based method. In Proceeedings of EACL-95, Dublin, pages 149–157. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Walter Daelemans</author>
<author>Jakub Zavrel</author>
<author>Peter Berck</author>
<author>Steven Gillis</author>
</authors>
<title>MBT: A memory-based part of speech tagger generator.</title>
<date>1996</date>
<booktitle>In Proceedings of WVLC 4,</booktitle>
<pages>14--27</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="1706" citStr="Daelemans et al., 1996" startWordPosition="258" endWordPosition="261"> word order (causing fixed-context systems, such as n-gram Hidden Markov Models (HMMs), to be even less adequate than for English). The average tagset contains about 1,000 - 2,000 distinct tags; the size of the set of possible and plausible tags can reach several thousands. Apart from agglutinative languages such as Turkish, Finnish and Hungarian (see e.g. (Hakkani-Tur et al., 2000)), and Basque (Ezeiza et al., 1998), which pose quite different and in the end less severe problems, there have been attempts at solving this problem for some of the highly inflectional European languages, such as (Daelemans et al., 1996), (Erjavec et al., 1999) (Slovenian), (Hajiˇc and Hladk´a, 1997), (Hajiˇc and Hladk´a, 1998) (Czech) and (Hajiˇc, 2000) (five Central and Eastern European languages), but so far no system has reached - in the absolute terms - a performance comparable to English tagging (such as (Ratnaparkhi, 1996)), which stands around or above 97%. For example, (Hajiˇc and Hladk´a, 1998) report results on Czech slightly above 93% only. One has to realize that even though such a performance might be adequate for some tasks (such as word sense disambiguation), for many other (such as parsing or translation) the</context>
</contexts>
<marker>Daelemans, Zavrel, Berck, Gillis, 1996</marker>
<rawString>Walter Daelemans, Jakub Zavrel, Peter Berck, and Steven Gillis. 1996. MBT: A memory-based part of speech tagger generator. In Proceedings of WVLC 4, pages 14–27. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomaˇz Erjavec</author>
<author>Saso Dieroski</author>
<author>Jakub Zavrel</author>
</authors>
<title>Morphosyntactic Tagging of Slovene: Evaluating PoS Taggers and Tagsets.</title>
<date>1999</date>
<tech>Technical Report IJS-DP 8018,</tech>
<institution>Dept. for Intelligent Systems, J´ozef ˇStefan Institute,</institution>
<location>Ljubljana, Slovenia,</location>
<contexts>
<context position="1730" citStr="Erjavec et al., 1999" startWordPosition="262" endWordPosition="265">-context systems, such as n-gram Hidden Markov Models (HMMs), to be even less adequate than for English). The average tagset contains about 1,000 - 2,000 distinct tags; the size of the set of possible and plausible tags can reach several thousands. Apart from agglutinative languages such as Turkish, Finnish and Hungarian (see e.g. (Hakkani-Tur et al., 2000)), and Basque (Ezeiza et al., 1998), which pose quite different and in the end less severe problems, there have been attempts at solving this problem for some of the highly inflectional European languages, such as (Daelemans et al., 1996), (Erjavec et al., 1999) (Slovenian), (Hajiˇc and Hladk´a, 1997), (Hajiˇc and Hladk´a, 1998) (Czech) and (Hajiˇc, 2000) (five Central and Eastern European languages), but so far no system has reached - in the absolute terms - a performance comparable to English tagging (such as (Ratnaparkhi, 1996)), which stands around or above 97%. For example, (Hajiˇc and Hladk´a, 1998) report results on Czech slightly above 93% only. One has to realize that even though such a performance might be adequate for some tasks (such as word sense disambiguation), for many other (such as parsing or translation) the implied sentence error </context>
</contexts>
<marker>Erjavec, Dieroski, Zavrel, 1999</marker>
<rawString>Tomaˇz Erjavec, Saso Dieroski, and Jakub Zavrel. 1999. Morphosyntactic Tagging of Slovene: Evaluating PoS Taggers and Tagsets. Technical Report IJS-DP 8018, Dept. for Intelligent Systems, J´ozef ˇStefan Institute, Ljubljana, Slovenia, April 2nd.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Ezeiza</author>
<author>I Alegria</author>
<author>J M Ariola</author>
<author>R Urizar</author>
<author>I Aduriz</author>
</authors>
<title>Combining stochastic and rulebased methods for disambiguation in agglutinative languages.</title>
<date>1998</date>
<booktitle>In Proceedings of ACL/COLING’98,</booktitle>
<pages>379--384</pages>
<publisher>ACL/ICCL.</publisher>
<location>Montreal, Canada,</location>
<contexts>
<context position="1503" citStr="Ezeiza et al., 1998" startWordPosition="224" endWordPosition="227">of Inflective Languages Inflective languages pose a specific problem in tagging due to two phenomena: highly inflective nature (causing sparse data problem in any statistically-based system), and free word order (causing fixed-context systems, such as n-gram Hidden Markov Models (HMMs), to be even less adequate than for English). The average tagset contains about 1,000 - 2,000 distinct tags; the size of the set of possible and plausible tags can reach several thousands. Apart from agglutinative languages such as Turkish, Finnish and Hungarian (see e.g. (Hakkani-Tur et al., 2000)), and Basque (Ezeiza et al., 1998), which pose quite different and in the end less severe problems, there have been attempts at solving this problem for some of the highly inflectional European languages, such as (Daelemans et al., 1996), (Erjavec et al., 1999) (Slovenian), (Hajiˇc and Hladk´a, 1997), (Hajiˇc and Hladk´a, 1998) (Czech) and (Hajiˇc, 2000) (five Central and Eastern European languages), but so far no system has reached - in the absolute terms - a performance comparable to English tagging (such as (Ratnaparkhi, 1996)), which stands around or above 97%. For example, (Hajiˇc and Hladk´a, 1998) report results on Czec</context>
<context position="5316" citStr="Ezeiza et al., 1998" startWordPosition="832" endWordPosition="835">gh description of many experiments involving rule-based systems and statistical learners for NP bracketing. For tagging, combination of purely statistical classifiers has been described (Hladk´a, 2000), with about 3% relative improvement (error reduction from 18.6% to 18%, trained on small data) over the best original system. We regard such systems as working in parallel, since all the original classifiers run independently of each other. In the present study, we have chosen a different strategy (similar to the one described for other types of languages in (Tapanainen and Voutilainen, 1994), (Ezeiza et al., 1998) and (HakkaniTur et al., 2000)). At the same time, the rulebased component is known to perform well in eliminating the incorrect alternatives2, rather than picking the correct one under all circumstances. Moreover, the rule-based system used can examine the whole sentential context, again a difficult thing for a statistical system3. That way, the ambiguity of the input text4 decreases. This is exactly what our statistical HMM tagger needs as its input, since it is already capable of using the lexical information from a dictionary. However, also in the rule-based approach, there is the usual tr</context>
</contexts>
<marker>Ezeiza, Alegria, Ariola, Urizar, Aduriz, 1998</marker>
<rawString>N. Ezeiza, I. Alegria, J. M. Ariola, R. Urizar, and I. Aduriz. 1998. Combining stochastic and rulebased methods for disambiguation in agglutinative languages. In Proceedings of ACL/COLING’98, Montreal, Canada, pages 379–384. ACL/ICCL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Hajiˇc</author>
</authors>
<title>Building a syntactically annotated corpus: The Prague Dependency Treebank. In</title>
<date>1998</date>
<booktitle>Festschrift for Jarmila Panevov´a,</booktitle>
<pages>106--132</pages>
<editor>E. Hajiˇcov´a, editor,</editor>
<institution>Karolinum, Charles University,</institution>
<location>Prague.</location>
<marker>Hajiˇc, 1998</marker>
<rawString>Jan Hajiˇc. 1998. Building a syntactically annotated corpus: The Prague Dependency Treebank. In E. Hajiˇcov´a, editor, Festschrift for Jarmila Panevov´a, pages 106–132. Karolinum, Charles University, Prague.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Hajiˇc</author>
</authors>
<title>Morphological tagging: Data vs. dictionaries.</title>
<date>2000</date>
<booktitle>In Proceedings of the NAACL’00,</booktitle>
<pages>94--101</pages>
<publisher>ACL.</publisher>
<location>Seattle, WA,</location>
<marker>Hajiˇc, 2000</marker>
<rawString>Jan Hajiˇc. 2000. Morphological tagging: Data vs. dictionaries. In Proceedings of the NAACL’00, Seattle, WA, pages 94–101. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Hajiˇc</author>
<author>Barbora Hladk´a</author>
</authors>
<title>Tagging of inflective languages: a comparison.</title>
<date>1997</date>
<booktitle>In Proceedings of ANLP’97,</booktitle>
<pages>136--143</pages>
<publisher>ACL.</publisher>
<location>Washington, DC,</location>
<marker>Hajiˇc, Hladk´a, 1997</marker>
<rawString>Jan Hajiˇc and Barbora Hladk´a. 1997. Tagging of inflective languages: a comparison. In Proceedings of ANLP’97, Washington, DC, pages 136–143. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Hajiˇc</author>
<author>Barbora Hladk´a</author>
</authors>
<title>Tagging inflective languages: Prediction of morphological categories for a rich, structured tagset.</title>
<date>1998</date>
<booktitle>In Proceedings ofACL/COLING’98,</booktitle>
<pages>483--490</pages>
<publisher>ACL/ICCL.</publisher>
<location>Montreal, Canada,</location>
<marker>Hajiˇc, Hladk´a, 1998</marker>
<rawString>Jan Hajiˇc and Barbora Hladk´a. 1998. Tagging inflective languages: Prediction of morphological categories for a rich, structured tagset. In Proceedings ofACL/COLING’98, Montreal, Canada, pages 483–490. ACL/ICCL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Hakkani-Tur</author>
<author>K Oflazer</author>
<author>G Tur</author>
</authors>
<title>Statistical morphological disambiguation for agglutinative languages.</title>
<date>2000</date>
<booktitle>In Proceedings of the 18th Coling</booktitle>
<location>Saarbruecken, Germany.</location>
<contexts>
<context position="1468" citStr="Hakkani-Tur et al., 2000" startWordPosition="218" endWordPosition="221">med with encouraging results. 1 Tagging of Inflective Languages Inflective languages pose a specific problem in tagging due to two phenomena: highly inflective nature (causing sparse data problem in any statistically-based system), and free word order (causing fixed-context systems, such as n-gram Hidden Markov Models (HMMs), to be even less adequate than for English). The average tagset contains about 1,000 - 2,000 distinct tags; the size of the set of possible and plausible tags can reach several thousands. Apart from agglutinative languages such as Turkish, Finnish and Hungarian (see e.g. (Hakkani-Tur et al., 2000)), and Basque (Ezeiza et al., 1998), which pose quite different and in the end less severe problems, there have been attempts at solving this problem for some of the highly inflectional European languages, such as (Daelemans et al., 1996), (Erjavec et al., 1999) (Slovenian), (Hajiˇc and Hladk´a, 1997), (Hajiˇc and Hladk´a, 1998) (Czech) and (Hajiˇc, 2000) (five Central and Eastern European languages), but so far no system has reached - in the absolute terms - a performance comparable to English tagging (such as (Ratnaparkhi, 1996)), which stands around or above 97%. For example, (Hajiˇc and Hl</context>
</contexts>
<marker>Hakkani-Tur, Oflazer, Tur, 2000</marker>
<rawString>D. Hakkani-Tur, K. Oflazer, and G. Tur. 2000. Statistical morphological disambiguation for agglutinative languages. In Proceedings of the 18th Coling 2000, Saarbruecken, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbora Hladk´a</author>
</authors>
<title>Czech Language Tagging.</title>
<date>2000</date>
<tech>Ph.D. thesis,</tech>
<volume>135</volume>
<pages>pp.</pages>
<institution>UFAL, Faculty of Mathematics and Physics, Charles University,</institution>
<location>Prague.</location>
<marker>Hladk´a, 2000</marker>
<rawString>Barbora Hladk´a. 2000. Czech Language Tagging. Ph.D. thesis, ´UFAL, Faculty of Mathematics and Physics, Charles University, Prague. 135 pp.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fred Jelinek</author>
</authors>
<title>Statistical Methods for Speech Recognition.</title>
<date>1997</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="13712" citStr="Jelinek, 1997" startWordPosition="2202" endWordPosition="2203">d being applied for low counts. Smoothing has been done first without using buckets, and then with them to show the difference. Table 2 shows the resulting interpolation coefficients for the tag language model using the usual linear interpolation smoothing formula where p(...) is the “raw” Maximum Likelihood estimate of the probability distributions, i.e. the relative frequency in the training data. The bucketing scheme for smoothing (a necessity when keeping all tag trigrams and tag-toword bigrams) uses “buckets bounds” computed according to the following formula (for more on bucketing, see (Jelinek, 1997)): It should be noted that when using this bucketing scheme, the weights of the detailed distributions (with longest history) grow quickly as the history reliability increases. However, it is not monotonic; at several of the most reliable histories, the weight coefficients “jump” up and down. We have found that a sudden drop in happens, e.g., for the bucket containing a history consisting of two consecutive punctuation symbols, which is not so much surprising after all. A similar formula has been used for the lexical model (Table 3), and the strenghtening of the weights of the most detailed di</context>
</contexts>
<marker>Jelinek, 1997</marker>
<rawString>Fred Jelinek. 1997. Statistical Methods for Speech Recognition. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Karlsson</author>
<author>A Voutilainen</author>
<author>J Heikkil¨a</author>
<author>A Antilla</author>
<author>editors</author>
</authors>
<title>Constraint Grammar: a Language-Independent System for Parsing Unrestricted Text. Mouton de Gruyter,</title>
<date>1995</date>
<location>Berlin New York.</location>
<marker>Karlsson, Voutilainen, Heikkil¨a, Antilla, editors, 1995</marker>
<rawString>F. Karlsson, A. Voutilainen, J. Heikkil¨a, and A. Antilla, editors. 1995. Constraint Grammar: a Language-Independent System for Parsing Unrestricted Text. Mouton de Gruyter, Berlin New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jiˇr´ı Mirovsk´y</author>
</authors>
<title>Morfologick´e znaˇckov´anitextu: automatick´a disambiguace (in Czech). Master’s thesis, ´UFAL,</title>
<date>1998</date>
<volume>56</volume>
<pages>pp.</pages>
<institution>Faculty of Mathematics and Physics, Charles University,</institution>
<location>Prague.</location>
<marker>Mirovsk´y, 1998</marker>
<rawString>Jiˇr´ı Mirovsk´y. 1998. Morfologick´e znaˇckov´anitextu: automatick´a disambiguace (in Czech). Master’s thesis, ´UFAL, Faculty of Mathematics and Physics, Charles University, Prague. 56 pp.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Ngai</author>
<author>D Yarowsky</author>
</authors>
<title>Rule writing or annotation: Cost-efficient resource usage for base noun phrase chunking.</title>
<date>2000</date>
<booktitle>In Proceedings of the 38th Annual Meeting of the ACL, Hong Kong,</booktitle>
<pages>117--125</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="4662" citStr="Ngai and Yarowsky, 2000" startWordPosition="729" endWordPosition="732">tems based on machine learning (Samuelsson and Voutilainen, 1997); however, except for the work cited, comparison is difficult to impossible due to the fact that they do not use the standard evaluation techniques (and not even the same data). But the substantial disadvantage is that the development of manual rule-based systems is demanding and requires a good deal of very subtle linguistic expertise and skills if full disambiguation also of “difficult” texts is to be performed. 1.3 System Combination Combination of (manual) rule-writing and statistical learning has been studied before. E.g., (Ngai and Yarowsky, 2000) and (Ngai, 2001) provide a thorough description of many experiments involving rule-based systems and statistical learners for NP bracketing. For tagging, combination of purely statistical classifiers has been described (Hladk´a, 2000), with about 3% relative improvement (error reduction from 18.6% to 18%, trained on small data) over the best original system. We regard such systems as working in parallel, since all the original classifiers run independently of each other. In the present study, we have chosen a different strategy (similar to the one described for other types of languages in (Ta</context>
</contexts>
<marker>Ngai, Yarowsky, 2000</marker>
<rawString>G. Ngai and D. Yarowsky. 2000. Rule writing or annotation: Cost-efficient resource usage for base noun phrase chunking. In Proceedings of the 38th Annual Meeting of the ACL, Hong Kong, pages 117–125. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Ngai</author>
</authors>
<title>Maximizing Resources for CorpusBased Natural Language Processing.</title>
<date>2001</date>
<tech>Ph.D. thesis,</tech>
<institution>Johns Hopkins University,</institution>
<location>Baltimore, Maryland, USA.</location>
<contexts>
<context position="4679" citStr="Ngai, 2001" startWordPosition="734" endWordPosition="735"> (Samuelsson and Voutilainen, 1997); however, except for the work cited, comparison is difficult to impossible due to the fact that they do not use the standard evaluation techniques (and not even the same data). But the substantial disadvantage is that the development of manual rule-based systems is demanding and requires a good deal of very subtle linguistic expertise and skills if full disambiguation also of “difficult” texts is to be performed. 1.3 System Combination Combination of (manual) rule-writing and statistical learning has been studied before. E.g., (Ngai and Yarowsky, 2000) and (Ngai, 2001) provide a thorough description of many experiments involving rule-based systems and statistical learners for NP bracketing. For tagging, combination of purely statistical classifiers has been described (Hladk´a, 2000), with about 3% relative improvement (error reduction from 18.6% to 18%, trained on small data) over the best original system. We regard such systems as working in parallel, since all the original classifiers run independently of each other. In the present study, we have chosen a different strategy (similar to the one described for other types of languages in (Tapanainen and Vout</context>
</contexts>
<marker>Ngai, 2001</marker>
<rawString>G. Ngai. 2001. Maximizing Resources for CorpusBased Natural Language Processing. Ph.D. thesis, Johns Hopkins University, Baltimore, Maryland, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Pl´atek</author>
<author>P Janˇcar</author>
<author>F Mr´az</author>
<author>J Vogel</author>
</authors>
<title>On restarting automata with rewriting.</title>
<date>1995</date>
<tech>Technical Report 96/5,</tech>
<institution>Charles University,</institution>
<location>Prague.</location>
<marker>Pl´atek, Janˇcar, Mr´az, Vogel, 1995</marker>
<rawString>M. Pl´atek, P. Janˇcar, F. Mr´az, and J. Vogel. 1995. On restarting automata with rewriting. Technical Report 96/5, Charles University, Prague.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adwait Ratnaparkhi</author>
</authors>
<title>A maximum entropy model for part-of-speech tagging.</title>
<date>1996</date>
<booktitle>In Proceedings ofEMNLP 1,</booktitle>
<pages>133--142</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="2004" citStr="Ratnaparkhi, 1996" startWordPosition="307" endWordPosition="308">guages such as Turkish, Finnish and Hungarian (see e.g. (Hakkani-Tur et al., 2000)), and Basque (Ezeiza et al., 1998), which pose quite different and in the end less severe problems, there have been attempts at solving this problem for some of the highly inflectional European languages, such as (Daelemans et al., 1996), (Erjavec et al., 1999) (Slovenian), (Hajiˇc and Hladk´a, 1997), (Hajiˇc and Hladk´a, 1998) (Czech) and (Hajiˇc, 2000) (five Central and Eastern European languages), but so far no system has reached - in the absolute terms - a performance comparable to English tagging (such as (Ratnaparkhi, 1996)), which stands around or above 97%. For example, (Hajiˇc and Hladk´a, 1998) report results on Czech slightly above 93% only. One has to realize that even though such a performance might be adequate for some tasks (such as word sense disambiguation), for many other (such as parsing or translation) the implied sentence error rate at 50% or more is simply too much to deal with. 1.1 Statistical Tagging Statistical tagging of inflective languages has been based on many techniques, ranging from plain-old HMM taggers (Mirovsk´y, 1998), memory-based (Erjavec et al., 1999) to maximum-entropy and featu</context>
</contexts>
<marker>Ratnaparkhi, 1996</marker>
<rawString>Adwait Ratnaparkhi. 1996. A maximum entropy model for part-of-speech tagging. In Proceedings ofEMNLP 1, pages 133–142. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Samuelsson</author>
<author>A Voutilainen</author>
</authors>
<title>Comparing a linguistic and a stochastic tagger.</title>
<date>1997</date>
<booktitle>In Proceedings ofACL/EACL Joint Conference,</booktitle>
<pages>246--252</pages>
<publisher>ACL.</publisher>
<location>Madrid,</location>
<contexts>
<context position="3765" citStr="Samuelsson and Voutilainen, 1997" startWordPosition="589" endWordPosition="592">e of the ease with which it is trained even on large data, and also because no other publicly available tagger was able to cope with the amount and ambiguity of the data in reasonable time. which are morphologically plausible for a given input word form. 1.2 Manual Rule-based Systems The idea of tagging by means of hand-written disambiguation rules has been put forward and implemented for the first time in the form of Constraint-Based Grammars (Karlsson et al., 1995). From languages we are acquainted with, the method has been applied on a larger scale only to English (Karlsson et al., 1995), (Samuelsson and Voutilainen, 1997), and French (Chanod and Tapanainen, 1995). Also (Bick, 1996) and (Bick, 2000) use manually written rules for Brazilian Portuguese, and there are several publications by Oflazer for Turkish. Authors of such systems claim that handwritten systems can perform better than systems based on machine learning (Samuelsson and Voutilainen, 1997); however, except for the work cited, comparison is difficult to impossible due to the fact that they do not use the standard evaluation techniques (and not even the same data). But the substantial disadvantage is that the development of manual rule-based system</context>
</contexts>
<marker>Samuelsson, Voutilainen, 1997</marker>
<rawString>C. Samuelsson and A. Voutilainen. 1997. Comparing a linguistic and a stochastic tagger. In Proceedings ofACL/EACL Joint Conference, Madrid, pages 246–252. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Tapanainen</author>
<author>A Voutilainen</author>
</authors>
<title>Tagging accurately: Don’t guess if you know.</title>
<date>1994</date>
<tech>Technical report, Xerox Corp.</tech>
<contexts>
<context position="5293" citStr="Tapanainen and Voutilainen, 1994" startWordPosition="827" endWordPosition="831">0) and (Ngai, 2001) provide a thorough description of many experiments involving rule-based systems and statistical learners for NP bracketing. For tagging, combination of purely statistical classifiers has been described (Hladk´a, 2000), with about 3% relative improvement (error reduction from 18.6% to 18%, trained on small data) over the best original system. We regard such systems as working in parallel, since all the original classifiers run independently of each other. In the present study, we have chosen a different strategy (similar to the one described for other types of languages in (Tapanainen and Voutilainen, 1994), (Ezeiza et al., 1998) and (HakkaniTur et al., 2000)). At the same time, the rulebased component is known to perform well in eliminating the incorrect alternatives2, rather than picking the correct one under all circumstances. Moreover, the rule-based system used can examine the whole sentential context, again a difficult thing for a statistical system3. That way, the ambiguity of the input text4 decreases. This is exactly what our statistical HMM tagger needs as its input, since it is already capable of using the lexical information from a dictionary. However, also in the rule-based approach</context>
</contexts>
<marker>Tapanainen, Voutilainen, 1994</marker>
<rawString>P. Tapanainen and A. Voutilainen. 1994. Tagging accurately: Don’t guess if you know. Technical report, Xerox Corp.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott M Thede</author>
<author>Mary P Harper</author>
</authors>
<title>A SecondOrder Hidden Markov Model for Part-of-Speech Tagging.</title>
<date>1999</date>
<booktitle>Proceedings of ACL’99,</booktitle>
<pages>175--182</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="12842" citStr="Thede and Harper, 1999" startWordPosition="2058" endWordPosition="2061">onsists of 80 rules. The rules had been implemented procedurally in the initial phase; a special feature-oriented, interpreted “programming language” is now under development. 2.3 Evaluation of the Rule System Alone The results are presented in Table 1. We use the usual equal-weight formula for F-measure: 3 The Statistical Component 3.1 The BMM Tagger We have used an HMM tagger in the usual sourcechannel setting, fine-tuned to perfection using a 3-gram tag language model , a tag-to-word lexical (translation) model using bigram histories instead of just sameword conditioning 5, 5First used in (Thede and Harper, 1999), as far as we know. Thus the HMM tagger outputs a sequence of tags according to the usual equation The tagger has been trained in the usual way, using part of the training data as heldout data for smoothing of the two models employed. There is no threshold being applied for low counts. Smoothing has been done first without using buckets, and then with them to show the difference. Table 2 shows the resulting interpolation coefficients for the tag language model using the usual linear interpolation smoothing formula where p(...) is the “raw” Maximum Likelihood estimate of the probability distri</context>
</contexts>
<marker>Thede, Harper, 1999</marker>
<rawString>Scott M. Thede and Mary P. Harper. 1999. A SecondOrder Hidden Markov Model for Part-of-Speech Tagging. Proceedings of ACL’99, pages 175–182. ACL.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>