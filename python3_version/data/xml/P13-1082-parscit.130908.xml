<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.004293">
<title confidence="0.999567">
A Multi-Domain Translation Model Framework
for Statistical Machine Translation
</title>
<author confidence="0.99646">
Rico Sennrich
</author>
<affiliation confidence="0.998559">
Institute of Computational Linguistics
University of Zurich
</affiliation>
<address confidence="0.9347195">
Binzm¨uhlestr. 14
CH-8050 Z¨urich
</address>
<email confidence="0.996522">
sennrich@cl.uzh.ch
</email>
<note confidence="0.4573">
Holger Schwenk and Walid Aransa
LIUM, University of Le Mans
72085 Le Mans cedex 9, France
</note>
<email confidence="0.995527">
lastname@lium.univ-lemans.fr
</email>
<sectionHeader confidence="0.997344" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999206">
While domain adaptation techniques for
SMT have proven to be effective at im-
proving translation quality, their practical-
ity for a multi-domain environment is of-
ten limited because of the computational
and human costs of developing and main-
taining multiple systems adapted to differ-
ent domains. We present an architecture
that delays the computation of translation
model features until decoding, allowing
for the application of mixture-modeling
techniques at decoding time. We also de-
scribe a method for unsupervised adapta-
tion with development and test data from
multiple domains. Experimental results on
two language pairs demonstrate the effec-
tiveness of both our translation model ar-
chitecture and automatic clustering, with
gains of up to 1 BLEU over unadapted sys-
tems and single-domain adaptation.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99994675">
The effectiveness of domain adaptation ap-
proaches such as mixture-modeling (Foster and
Kuhn, 2007) has been established, and has led to
research on a wide array of adaptation techniques
in SMT, for instance (Matsoukas et al., 2009; Shah
et al., 2012). In all these approaches, adaptation is
performed during model training, with respect to a
representative development corpus, and the mod-
els are kept unchanged when then system is de-
ployed. Therefore, when working with multiple
and/or unlabelled domains, domain adaptation is
often impractical for a number of reasons. Firstly,
maintaining multiple systems for each language
pair, each adapted to a different domain, is costly
in terms of computational and human resources:
the full system development pipeline needs to be
performed for all identified domains, all the mod-
els are separately stored and need to be switched at
runtime. This is impractical in many real applica-
tions, in particular a web translation service which
is faced with texts coming from many different do-
mains. Secondly, domain adaptation bears a risk
of performance loss. If there is a mismatch be-
tween the domain of the development set and the
test set, domain adaptation can potentially harm
performance compared to an unadapted baseline.
We introduce a translation model architecture
that delays the computation of features to the de-
coding phase. The calculation is based on a vec-
tor of component models, with each component
providing the sufficient statistics necessary for the
computation of the features. With this framework,
adaptation to a new domain simply consists of up-
dating a weight vector, and multiple domains can
be supported by the same system.
We also present a clustering approach for un-
supervised adaptation in a multi-domain environ-
ment. In the development phase, a set of develop-
ment data is clustered, and the models are adapted
to each cluster. For each sentence that is being
decoded, we choose the weight vector that is op-
timized on the closest cluster, allowing for adap-
tation even with unlabelled and heterogeneous test
data.
</bodyText>
<sectionHeader confidence="0.999952" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999647166666667">
(Ortiz-Mart´ınez et al., 2010) delay the compu-
tation of translation model features for the pur-
pose of interactive machine translation with online
training. The main difference to our approach is
that we store sufficient statistics not for a single
model, but a vector of models, which allows us to
</bodyText>
<page confidence="0.953538">
832
</page>
<note confidence="0.914474">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 832–840,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.999831613636364">
weight the contribution of each component model
to the feature calculation. The similarity suggests
that our framework could also be used for inter-
active learning, with the ability to learn a model
incrementally from user feedback, and weight it
differently than the static models, opening new re-
search opportunities.
(Sennrich, 2012b) perform instance weighting
of translation models, based on the sufficient
statistics. Our framework implements this idea,
with the main difference that the actual combina-
tion is delayed until decoding, to support adapta-
tion to multiple domains in a single system.
(Razmara et al., 2012) describe an ensemble de-
coding framework which combines several trans-
lation models in the decoding step. Our work is
similar to theirs in that the combination is done
at runtime, but we also delay the computation of
translation model probabilities, and thus have ac-
cess to richer sufficient statistics. In principle,
our architecture can support all mixture operations
that (Razmara et al., 2012) describe, plus addi-
tional ones such as forms of instance weighting,
which are not possible after the translation proba-
bilities have been computed.
(Banerjee et al., 2010) focus on the problem of
domain identification in a multi-domain setting.
They use separate translation systems for each do-
main, and a supervised setting, whereas we aim
for a system that integrates support for multiple
domains, with or without supervision.
(Yamamoto and Sumita, 2007) propose unsu-
pervised clustering at both training and decoding
time. The training text is divided into a number
of clusters, a model is trained on each, and during
decoding, each sentence is assigned to the clos-
est cluster-specific model. Our approach bears re-
semblance to this clustering, but is different in that
Yamamoto and Sumita assign each sentence to the
closest model, and use this model for decoding,
whereas in our approach, each cluster is associ-
ated with a mixture of models that is optimized to
the cluster, and the number of clusters need not be
equal to the number of component models.
</bodyText>
<sectionHeader confidence="0.999489" genericHeader="method">
3 Translation Model Architecture
</sectionHeader>
<bodyText confidence="0.999642666666667">
This section covers the architecture of the multi-
domain translation model framework. Our transla-
tion model is embedded in a log-linear model as is
common for SMT, and treated as a single transla-
tion model in this log-linear combination. We im-
plemented this architecture for phrase-based mod-
els, and will use this terminology to describe it,
but in principle, it can be extended to hierarchical
or syntactic models.
The architecture has two goals: move the calcu-
lation of translation model features to the decoding
phase, and allow for multiple knowledge sources
(e.g. bitexts or user-provided data) to contribute to
their calculation. Our immediate purpose for this
paper is domain adaptation in a multi-domain en-
vironment, but the delay of the feature computa-
tion has other potential applications, e.g. in inter-
active MT.
We are concerned with calculating four features
during decoding, henceforth just referred to as the
translation model features: p(s|t), lex(s|t), p(t|s)
and lex(t|s). s and t denote the source and target
phrase. We follow the definitions in (Koehn et al.,
2003).
Traditionally, the phrase translation probabili-
ties p(s|t) and p(t|s) are estimated through un-
smoothed maximum likelihood estimation (MLE).
</bodyText>
<equation confidence="0.9966685">
c(x,y) (1)
Px, c(x&apos;, y)
</equation>
<bodyText confidence="0.9986786">
where c denotes the count of an observation, and
p the model probability.
The lexical weights lex(s|t) and lex(t|s) are
calculated as follows, using a set of word align-
ments a between s and t:1
</bodyText>
<equation confidence="0.993852">
1 X w(si|tj)
|{j|(i,j) ∈ a} |∀(i,j)∈a
</equation>
<bodyText confidence="0.978510555555556">
(2)
A special NULL token is added to t and aligned to
each unaligned word in s. w(si|tj) is calculated
through MLE, as in equation 1, but based on the
word (pair) frequencies.
To combine statistics from a vector of n com-
ponent corpora, we can use a weighted version of
equation 1, which adds a weight vector λ of length
n (Sennrich, 2012b):
</bodyText>
<equation confidence="0.984408">
Pn
p �iCi(x�y) (3)
(x�yi �) _ 1 Ex, Aici(x&apos;, y)
</equation>
<bodyText confidence="0.939554">
The word translation probabilities w(ti|sj) are de-
fined analogously, and used in equation 2 for a
weighted version.
</bodyText>
<footnote confidence="0.882538">
1The equation shows lex(slt); lex(tls) is computed anal-
ogously.
</footnote>
<equation confidence="0.9992775">
c(x, y)
p(x|y) =
c(y)
lex(s|t, a) =
Yn
i=1
</equation>
<page confidence="0.992604">
833
</page>
<bodyText confidence="0.998910730769231">
In order to compute the translation model fea-
tures online, a number of sufficient statistics need
to be accessible at decoding time. For p(s|t)
and p(t|s), we require the statistics c(s), c(t) and
c(s, t). For accessing them during decoding, we
simply store them in the decoder’s data struc-
ture, rather than storing pre-computed translation
model features. This means that we can use exist-
ing, compact data formats for storing and access-
ing them.2
The statistics are accessed when the decoder
collects all translation options for a phrase s in the
source sentence. We then access all translation op-
tions for each component table, obtaining a vector
of statistics c(s) for the source phrase, and c(t) and
c(s, t) for each potential target phrase. For phrase
pairs which are not found, c(s, t) and c(t) are ini-
tially set to 0.
Note that c(t) is potentially incorrect at this
point, since a phrase pair not being found does
not entail that c(t) is 0. After all tables have been
accessed, and we thus know the full set of possi-
ble translation options (s, t), we perform a second
round of lookups for all c(t) in the vector which
are still set to 0. We introduce a second table for
accessing c(t) efficiently, again storing it in the de-
coder’s data structure. We can easily create such a
table by inverting the source and target phrases,
deduplicating it for compactness (we only need
one entry per target phrase), and storing c(t) as
only feature.
For lex(s|t), we require an alignment a, plus
c(tj) and c(sZ, tj) for all pairs (i, j) in a. lex(t|s)
can be based on the same alignment a (with the ex-
ception of NULL alignments, which can be added
online), but uses statistics c(sj) and c(tZ, sj). For
estimating the lexical probabilities, we load the
frequencies into a vector of four hash tables.3
Both space and time complexity of the lookup
is linear to the number of component tables. We
deem it is still practical because the collection of
translation options is typically only a small frac-
tion of total decoding time, with search making
up the largest part. For storing and accessing the
sufficient statistics (except for the word (pair) fre-
quencies), we use an on-disk data structure pro-
2We have released an implementation of the architecture
as part of the Moses decoder.
3c(s, t) and c(t, s) are not identical since the lexical
probabilities are based on the unsymmetrized word align-
ment frequencies (in the Moses implementation which we re-
implement).
</bodyText>
<equation confidence="0.93985">
phrase (pair) c1(x) c2(x)
row 300 80
(row, Zeile)
(row, Reihe)
λ p(Zeile|row) p(Reihe|row)
0.68 0.32
0.40 0.60
0.79 0.21
</equation>
<tableCaption confidence="0.9686005">
Table 1: Illustration of instance weighting with
weight vectors for two corpora.
</tableCaption>
<bodyText confidence="0.9957994">
vided by Moses, which reduces the memory re-
quirements. Still, the number of components may
need to be reduced, for instance through clustering
of training data (Sennrich, 2012a).
With a small modification, our framework could
be changed to use a single table that stores a vec-
tor of n statistics instead of a vector of n tables.
While this would be more compact in terms of
memory, and keep the number of table lookups in-
dependent of the number of components, we chose
a vector of n tables for its flexibility. With a vec-
tor of tables, tables can be quickly added to or re-
moved from the system (conceivable even at run-
time), and can be polymorph. One applications
where this could be desirable is interactive ma-
chine translation, where one could work with a
mix of compact, static tables, and tables designed
to be incrementally trainable.
In the unweighted variant, the resulting fea-
tures are equivalent to training on the concatena-
tion of all training data, excepting differences in
word alignment, pruning4 and rounding. The ar-
chitecture can thus be used as a drop-in replace-
ment for a baseline system that is trained on con-
catenated training data, with non-uniform weights
only being used for texts for which better weights
have been established. This can be done either us-
ing domain labels or unsupervised methods as de-
scribed in the next section.
As a weighted combination method, we imple-
mented instance weighting as described in equa-
tion 3. Table 1 shows the effect of weighting two
corpora on the probability estimates for the trans-
lation of row. German Zeile (row in a table) is pre-
dominant in a bitext from the domain IT, whereas
</bodyText>
<footnote confidence="0.8172442">
4We prune the tables to the most frequent 50 phrase pairs
per source phrase before combining them, since calculat-
ing the features for all phrase pairs of very common source
phrases causes a significant slow-down. We found that this
had no significant effects on BLEU.
</footnote>
<equation confidence="0.6708502">
240 20
60 60
(1, 1)
(1, 10)
(10, 1)
</equation>
<page confidence="0.764557">
834
</page>
<figure confidence="0.99894784375">
6
5
4
3
2
1
0
entropy with Acquis LM (LEGAL)
6
5
4
3
2
1
0
entropy with Acquis LM (LEGAL)
gold clusters
entropy with Acquis LM (LEGAL) 6
5
4
3
2
1
0
0 1 2 3 4 5 6
entropy with KDE LM (IT)
clustering with Euclidean distance
0 1 2 3 4 5 6
entropy with KDE LM (IT)
clustering with cosine similarity
entropy with KDE LM (IT)
0 1 2 3 4 5 6
</figure>
<figureCaption confidence="0.995453333333333">
Figure 1: Clustering of data set which contains sentences from two domains: LEGAL and IT. Compari-
son between gold segmentation, and clustering with two alternative distance/similarity measures. Black:
IT; grey: LEGAL.
</figureCaption>
<bodyText confidence="0.995599230769231">
Reihe (line of objects) occurs more often in a legal
corpus. Note that the larger corpus (or more pre-
cisely, the one in which row occurs more often)
has a stronger impact on the probability distribu-
tion with uniform weights (or in a concatenation of
data sets). Instance weighting allows us to modify
the contribution of each corpus. In our implemen-
tation, the weight vector is set globally, but can be
overridden on a per-sentence basis. In principle,
using different weight vectors for different phrase
pairs in a sentence is conceivable. The framework
can also be extended to support other combination
methods, such as a linear interpolation of models.
</bodyText>
<sectionHeader confidence="0.960884" genericHeader="method">
4 Unsupervised Clustering for Online
Translation Model Adaptation
</sectionHeader>
<bodyText confidence="0.999881823529412">
The framework supports decoding each sentence
with a separate weight vector of size 4n, 4 being
the number of translation model features whose
computation can be weighted, and n the number
of model components. We now address the ques-
tion of how to automatically select good weights in
a multi-domain task. As a way of optimizing in-
stance weights, (Sennrich, 2012b) minimize trans-
lation model perplexity on a set of phrase pairs,
automatically extracted from a parallel develop-
ment set. We follow this technique, but want to
have multiple weight vectors, adapted to different
texts, between which the system switches at de-
coding time. The goal is to perform domain adap-
tation without requiring domain labels or user in-
put, neither for development nor decoding.
The basic idea consists of three steps:
</bodyText>
<listItem confidence="0.9936245">
1. Cluster a development set into k clusters.
2. Optimize translation model weights for each
cluster.
3. For each sentence in the test set, assign it
</listItem>
<bodyText confidence="0.838172166666667">
to the nearest cluster and use the translation
model weights associated with the cluster.
For step 2, we use the algorithm by (Sennrich,
2012b), implemented in the decoder to allow for a
quick optimization of a running system. We will
here discuss steps 1 and 3 in more detail.
</bodyText>
<subsectionHeader confidence="0.989932">
4.1 Clustering the Development Set
</subsectionHeader>
<bodyText confidence="0.999989454545454">
We use k-means clustering to cluster the sentences
of the development set. We train a language model
on the source language side of each of the n
component bitexts, and compute an n-dimensional
vector for each sentence by computing its entropy
with each language model. Our aim is not to dis-
criminate between sentences that are more likely
and unlikely in general, but to cluster on the ba-
sis of relative differences between the language
model entropies. For this purpose, we choose
the cosine as our similarity measure. Figure 1
illustrates clustering in a two-dimensional vector
space, and demonstrates that Euclidean distance is
unsuitable because it may perform a clustering that
is irrelevant to our purposes.
As a result of development set clustering, we
obtain a bitext for each cluster, which we use to
optimize the model weights, and a centroid per
cluster. At decoding time, we need only perform
an assignment step. Each test set sentence is as-
signed to the centroid that is closest to it in the
vector space.
</bodyText>
<subsectionHeader confidence="0.964042">
4.2 Scalability Considerations
</subsectionHeader>
<bodyText confidence="0.9983135">
Our theoretical expectation is that domain adapta-
tion will fail to perform well if the test data is from
</bodyText>
<page confidence="0.993529">
835
</page>
<bodyText confidence="0.991460846153846">
a different domain than the development data, or
if the development data is a heterogeneous mix
of domains. A multi-domain setup can mitigate
this risk, but only if the relevant domain is repre-
sented in the development data, and if the devel-
opment data is adequately segmented for the op-
timization. We thus suggest that the development
data should contain enough data from all domains
that one wants to adapt to, and a high number of
clusters.
While the resource requirements increase with
the number of component models, increasing the
number of clusters is computationally cheap at
runtime. Only the clustering of the develop-
ment set and optimization of the translation model
weights for each clusters is affected by k. This
means that the approach can in principle be scaled
to a high number of clusters, and support a high
number of domains.5
The biggest risk of increasing the number of
clusters is that if the clusters become too small,
perplexity minimization may overfit these small
clusters. We will experiment with different num-
bers of clusters, but since we expect the optimal
number of clusters to depend on the amount of
development data, and the number of domains,
we cannot make generalized statements about the
ideal number of k.
While it is not the focus of this paper, we also
evaluate language model adaptation. We perform
a linear interpolation of models for each clus-
ter, with interpolation coefficients optimized us-
ing perplexity minimization on the development
set. The cost of moving language model interpo-
lation into the decoding phase is far greater than
for translation models, since the number of hy-
potheses that need to be evaluated by the language
model is several orders of magnitudes higher than
the number of phrase pairs used during the trans-
lation. For the experiments with language model
adaptation, we have chosen to perform linear in-
terpolation offline, and perform language model
switching during decoding. While model switch-
ing is a fast operation, it also makes the space com-
plexity of storing the language models linear to the
number of clusters. For scaling the approach to a
high number of clusters, we envision that multi-
5If the development set is labelled, one can also use a gold
segmentation of development sets instead of k-means cluster-
ing. At decoding time, cluster assignment can be performed
by automatically assigning each sentence to the closest cen-
troid, or again through gold labels, if available.
</bodyText>
<table confidence="0.999233722222222">
data set sentences words (de)
kde 216 000 1990 000
kdedoc 2880 41000
kdegb 51300 450 000
oo 41000 434 000
oo3 56 800 432 000
php 38 500 301000
tm 146 000 2 740 000
acquis 2 660 000 58 900 000
dgt 372 000 8 770 000
ecb 110 000 2 850 000
ep7 1920 000 50 500 000
nc7 159 000 3 950 000
total (train) 5 780 000 131000 000
dev (IT) 3500 47 000
dev (LEGAL) 2000 46 800
test (IT) 5520 51800
test (LEGAL) 9780 250 000
</table>
<tableCaption confidence="0.903452">
Table 2: Parallel data sets English–German.
</tableCaption>
<table confidence="0.998738636363636">
data set sentences words (en)
eu 1270 000 25 600 000
fiction 830 000 13 700 000
navajo 30 000 490 000
news 110 000 2 550 000
paraweb 370 000 3 930 000
subtitles 2 840 000 21200 000
techdoc 970 000 7 270 000
total (train) 6 420 000 74 700 000
dev 3500 50 700
test 3500 49 600
</table>
<tableCaption confidence="0.999683">
Table 3: Parallel data sets Czech–English.
</tableCaption>
<bodyText confidence="0.9998346">
pass decoding, with an unadapted language model
in the first phase, and rescoring with a language
model adapted online, could perform adequately,
and keep the complexity independent of the num-
ber of clusters.
</bodyText>
<sectionHeader confidence="0.999816" genericHeader="evaluation">
5 Evaluation
</sectionHeader>
<subsectionHeader confidence="0.999119">
5.1 Data and Methods
</subsectionHeader>
<bodyText confidence="0.999891375">
We conduct all experiments with Moses (Koehn et
al., 2007), SRILM (Stolcke, 2002), and GIZA++
(Och and Ney, 2003). Log-linear weights are op-
timized using MERT (Och and Ney, 2003). We
keep the word alignment and lexical reordering
models constant through the experiments to min-
imize the number of confounding factors. We re-
port translation quality using BLEU (Papineni et
</bodyText>
<page confidence="0.997206">
836
</page>
<table confidence="0.997883555555556">
system TM adaptation LM adaptation TM+LM adaptation
IT LEGAL IT LEGAL IT LEGAL
baseline 21.1 49.9 21.1 49.9 21.1 49.9
1 cluster (no split) 21.3* 49.9 21.8* 49.7 21.8* 49.8
2 clusters 21.6* 49.9 22.2* 50.4* 22.8* 50.2*
4 clusters 21.7* 49.9 23.1* 50.2* 22.6* 50.2*
8 clusters 22.1* 49.9 23.1* 50.1* 22.7* 50.3*
16 clusters 21.1 49.9 22.6* 50.3* 21.9* 50.1*
gold clusters 21.8* 50.1* 22.4* 50.1* 23.2* 49.9
</table>
<tableCaption confidence="0.999912">
Table 4: Translation experiments EN–DE. BLEU scores reported.
</tableCaption>
<bodyText confidence="0.997410743589744">
al., 2002). We account for optimizer instability
by running 3 independent MERT runs per system,
and performing significance testing with MultEval
(Clark et al., 2011). Systems significantly better
than the baseline with p &lt; 0.01 are marked with
(*).
We conduct experiments on two data sets. The
first is an English–German translation task with
two domains, texts related to information technol-
ogy (IT) and legal documents (LEGAL). We use
data sets from both domains, plus out-of-domain
corpora, as shown in table 2. 7 data sets come from
the domain IT: 6 from OPUS (Tiedemann, 2009)
and a translation memory (tm) provided by our in-
dustry partner. 3 data sets are from the legal do-
main: the ECB corpus from OPUS, plus the JRC-
Acquis (Steinberger et al., 2006) and DGT-TM
(Steinberger et al., 2012). 2 data sets are out-of-
domain, made available by the 2012 Workshop on
Statistical Machine Translation (Callison-Burch et
al., 2012). The development sets are random sam-
ples from the respective in-domain bitexts (held-
out from training). The test sets have been pro-
vided by Translated, our industry partner in the
MATECAT project.
Our second data set is CzEng 0.9, a Czech–
English parallel corpus (Bojar and Zabokrtsk´y,
2009). It contains text from 7 different sources, on
which we train separate component models. The
size of the corpora is shown in table 3. As de-
velopment and test sets, we use 500 sentences of
held-out data per source.
For both data sets, language models are trained
on the target side of the bitexts. In all experiments,
we keep the number of component models con-
stant: 12 for EN–DE, 7 for CZ–EN. We vary the
number of clusters k from 1, which corresponds to
adapting the models to the full development set, to
16. The baseline is the concatenation of all train-
</bodyText>
<table confidence="0.999742923076923">
Data set AIT ALEGAL Acluster 1 Acluster 2
kde 1.0 1.0 1.0 1.0
kdedoc 0.64 12.0 86.0 6.4
kdegb 1.6 2.3 1.7 2.7
oo 0.76 1.6 0.73 1.7
oo3 1.8 4.7 2.4 2.7
php 0.79 6.3 0.69 3.5
tm 1.3 1.3 1.5 1.1
acquis 0.024 3.5 0.018 1.9
dgt 0.053 4.5 0.033 2.4
ecb 0.071 2.3 0.039 1.2
ep7 0.037 0.53 0.024 0.29
nc7 0.1 1.1 0.063 0.62
</table>
<tableCaption confidence="0.893781">
Table 5: Weight vectors for feature p(tls) opti-
mized on four development sets (from gold split
</tableCaption>
<bodyText confidence="0.938197833333333">
and clustering with k = 2).
ing data, with no adaptation performed. We also
evaluate the labelled setting, where instead of un-
supervised clustering, we use gold labels to split
the development and test sets, and adapt the mod-
els to each labelled domain.
</bodyText>
<subsectionHeader confidence="0.963368">
5.2 Results
</subsectionHeader>
<bodyText confidence="0.995560571428571">
Table 4 shows results for the EN–DE data set. For
our clustering experiments, the development set is
the concatenation of the LEGAL and IT develop-
ment sets. However, we always use the gold seg-
mentation between LEGAL and IT for MERT and
testing. This allows for a detailed analysis of the
effect of development data clustering for the pur-
pose of model adaptation. In an unlabelled setting,
one would have to run MERT either on the full de-
velopment set (as we will do for the CZ–EN task)
or separately on each cluster, or use an alternative
approach to optimize log-linear weights in a multi-
domain setting, such as feature augmentation as
described by (Clark et al., 2012).
</bodyText>
<page confidence="0.992581">
837
</page>
<table confidence="0.998267875">
system TM adaptation LM adaptation TM+LM adaptation
baseline 34.4 34.4 34.4
1 cluster (no split) 34.5 33.7 34.1
2 clusters 34.6 34.0 34.4
4 clusters 34.7* 34.3 34.6
8 clusters 34.7* 34.5 34.9*
16 clusters 34.7* 34.7* 35.0*
gold clusters 35.0* 35.0* 35.4*
</table>
<tableCaption confidence="0.999719">
Table 6: Translation experiments CZ–EN. BLEU scores reported.
</tableCaption>
<bodyText confidence="0.999973235294118">
We find that an adaptation of the TM and LM
to the full development set (system “1 cluster”)
yields the smallest improvements over the un-
adapted baseline. The reason for this is that the
mixed-domain development set is not representa-
tive for the respective test sets. Using multiple
adapted systems yields better performance. For
the IT test set, the system with gold labels and TM
adaptation yields an improvement of 0.7 BLEU
(21.1 → 21.8), LM adaptation yields 1.3 BLEU
(21.1 → 22.4), and adapting both models outper-
forms the baseline by 2.1 BLEU (21.1 → 23.2).
The systems that use unsupervised clusters reach
a similar level of performance than those with
gold clusters, with best results being achieved
by the systems with 2–8 clusters. Some sys-
tems outperform both the baseline and the gold
clusters, e.g. TM adaptation with 8 clusters
(21.1 → 21.8 → 22.1), or LM adaptation with 4
or 8 clusters (21.1 → 22.4 → 23.1).
Results with 16 clusters are slightly worse than
those with 2–8 clusters due to two effects. Firstly,
for the system with adapted TM, one of the three
MERT runs is an outlier, and the reported BLEU
score of 21.1 is averaged from the three MERT
runs achieving 22.1, 21.6, and 19.6 BLEU, respec-
tively. Secondly, about one third of the IT test
set is assigned to a cluster that is not IT-specific,
which weakens the effect of domain adaptation for
the systems with 16 clusters.
For the LEGAL subset, gains are smaller. This
can be explained by the fact that the majority of
training data is already from the legal domain,
which makes it unnecessary to boost its impact on
the probability distribution even further.
Table 5 shows the automatically obtained trans-
lation model weight vectors for two systems,
“gold clusters” and “2 clusters”, for the feature
p(t|s). It illustrates that all the corpora that we
consider out-of-domain for IT are penalized by
a factor of 10–50 (relative to the in-domain kde
corpus) for the computation of this feature. For
the LEGAL domain, the weights are more uni-
form, which is congruent with our observation that
BLEU changes little.
Table 6 shows results for the CZ–EN data set.
For each system, MERT is performed on the full
development set. As in the first task, adaptation to
the full development set is least effective. The sys-
tems with unsupervised clusters significantly out-
perform the baseline. For the system with 16 clus-
ters, we observe an improvement of 0.3 BLEU for
TM adaptation, and 0.6 BLEU for adapting both
models (34.4 → 34.7 → 35.0). The labelled sys-
tem, i.e. the system with 7 clusters corresponding
to the 7 data sources, both for the development and
test set, performs best. We observe gains of 0.6
BLEU (34.4 → 35.0) for TM or LM adaptation,
and 1 BLEU (34.4 → 35.4) when both models are
adapted.
We conclude that the translation model archi-
tecture is effective in a multi-domain setting, both
with unsupervised clusters and labelled domains.
The fact that language model adaptation yields an
additional improvement in our experiments sug-
gests that it it would be worthwhile to also inves-
tigate a language model data structure that effi-
ciently supports multiple domains.
</bodyText>
<sectionHeader confidence="0.999384" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.9999899">
We have presented a novel translation model ar-
chitecture that delays the computation of trans-
lation model features to the decoding phase, and
uses a vector of component models for this com-
putation. We have also described a usage scenario
for this architecture, namely its ability to quickly
switch between weight vectors in order to serve as
an adapted model for multiple domains. A sim-
ple, unsupervised clustering of development data
is sufficient to make use of this ability and imple-
</bodyText>
<page confidence="0.993933">
838
</page>
<bodyText confidence="0.999948894736842">
ment a multi-domain translation system. If avail-
able, one can also use the architecture in a labelled
setting.
Future work could involve merging our trans-
lation model framework with the online adapta-
tion of other models, or the log-linear weights.
Our approach is orthogonal to that of (Clark et
al., 2012), who perform feature augmentation to
obtain multiple sets of adapted log-linear weights.
While (Clark et al., 2012) use labelled data, their
approach could in principle also be applied after
unsupervised clustering.
The translation model framework could also
serve as the basis of real-time adaptation of trans-
lation systems, e.g. by using incremental means to
update the weight vector, or having an incremen-
tally trainable component model that learns from
the post-edits by the user, and is assigned a suit-
able weight.
</bodyText>
<sectionHeader confidence="0.999157" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9983798">
This research was partially funded by the
Swiss National Science Foundation under grant
105215 126999, the European Commission
(MATECAT, ICT-2011.4.2 287688) and the
DARPA BOLT project.
</bodyText>
<sectionHeader confidence="0.999109" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999657530864197">
Pratyush Banerjee, Jinhua Du, Baoli Li, Sudip Kumar
Naskar, Andy Way, and Josef Van Genabith. 2010.
Combining multi-domain statistical machine trans-
lation models using automatic classifiers. In 9th
Conference of the Association for Machine Trans-
lation in the Americas (AMTA 2010), Denver, Col-
orado, USA.
Ondrej Bojar and Zdenek Zabokrtsk´y. 2009. Czeng
0.9: Large parallel treebank with rich annotation.
Prague Bull. Math. Linguistics, 92:63–84.
Chris Callison-Burch, Philipp Koehn, Christof Monz,
Matt Post, Radu Soricut, and Lucia Specia. 2012.
Findings of the 2012 workshop on statistical ma-
chine translation. In Proceedings of the Seventh
Workshop on Statistical Machine Translation, pages
10–51, Montr´eal, Canada, June. Association for
Computational Linguistics.
Jonathan H. Clark, Chris Dyer, Alon Lavie, and
Noah A. Smith. 2011. Better hypothesis testing for
statistical machine translation: Controlling for op-
timizer instability. In Proceedings of the 49th An-
nual Meeting of the Association for Computational
Linguistics: Human Language Technologies, pages
176–181, Portland, Oregon, USA, June. Association
for Computational Linguistics.
Jonathan H. Clark, Alon Lavie, and Chris Dyer. 2012.
One system, many domains: Open-domain statisti-
cal machine translation via feature augmentation. In
Conference of the Association for Machine Transla-
tion in the Americas 2012 (AMTA 2012), San Diego,
California, USA.
George Foster and Roland Kuhn. 2007. Mixture-
model adaptation for SMT. In Proceedings of the
Second Workshop on Statistical Machine Transla-
tion, StatMT ’07, pages 128–135, Prague, Czech
Republic. Association for Computational Linguis-
tics.
Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In
NAACL ’03: Proceedings of the 2003 Conference
of the North American Chapter of the Association
for Computational Linguistics on Human Language
Technology, pages 48–54, Edmonton, Canada. As-
sociation for Computational Linguistics.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondˇrej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: Open
Source Toolkit for Statistical Machine Translation.
In ACL 2007, Proceedings of the 45th Annual Meet-
ing of the Association for Computational Linguis-
tics Companion Volume Proceedings of the Demo
and Poster Sessions, pages 177–180, Prague, Czech
Republic, June. Association for Computational Lin-
guistics.
Spyros Matsoukas, Antti-Veikko I. Rosti, and Bing
Zhang. 2009. Discriminative corpus weight estima-
tion for machine translation. In Proceedings of the
2009 Conference on Empirical Methods in Natural
Language Processing: Volume 2 - Volume 2, pages
708–717, Singapore. Association for Computational
Linguistics.
Franz Josef Och and Hermann Ney. 2003. A sys-
tematic comparison of various statistical alignment
models. Computational Linguistics, 29(1):19–51.
Daniel Ortiz-Martfnez, Ismael Garcfa-Varea, and Fran-
cisco Casacuberta. 2010. Online learning for in-
teractive statistical machine translation. In HLT-
NAACL, pages 546–554. The Association for Com-
putational Linguistics.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: A method for automatic
evaluation of machine translation. In ACL ’02: Pro-
ceedings of the 40th Annual Meeting on Associa-
tion for Computational Linguistics, pages 311–318,
Philadelphia, Pennsylvania, USA. Association for
Computational Linguistics.
Majid Razmara, George Foster, Baskaran Sankaran,
and Anoop Sarkar. 2012. Mixing multiple trans-
lation models in statistical machine translation. In
</reference>
<page confidence="0.988163">
839
</page>
<reference confidence="0.998758339622641">
Proceedings of the 50th Annual Meeting of the As-
sociation for Computational Linguistics, Jeju, Re-
public of Korea. Association for Computational Lin-
guistics.
Rico Sennrich. 2012a. Mixture-modeling with unsu-
pervised clusters for domain adaptation in statistical
machine translation. In 16th Annual Conference of
the European Association for Machine Translation
(EAMT 2012), pages 185–192, Trento, Italy.
Rico Sennrich. 2012b. Perplexity minimization for
translation model domain adaptation in statistical
machine translation. In Proceedings of the 13th
Conference of the European Chapter of the Asso-
ciation for Computational Linguistics, pages 539–
549, Avignon, France. Association for Computa-
tional Linguistics.
Kashif Shah, Loc Barrault, and Holger Schwenk.
2012. A general framework to weight heteroge-
neous parallel data for model adaptation in statistical
machine translation. In Conference of the Associa-
tion for Machine Translation in the Americas 2012
(AMTA 2012), San Diego, California, USA.
Ralf Steinberger, Bruno Pouliquen, Anna Widiger,
Camelia Ignat, Tomaz Erjavec, Dan Tufis, and
Daniel Varga. 2006. The JRC-Acquis: A multilin-
gual aligned parallel corpus with 20+ languages. In
Proceedings of the 5th International Conference on
Language Resources and Evaluation (LREC’2006),
Genoa, Italy.
Ralf Steinberger, Andreas Eisele, Szymon Klocek,
Spyridon Pilos, and Patrick Schl¨uter. 2012. DGT-
TM: A freely available translation memory in 22 lan-
guages. In Proceedings of the Eight International
Conference on Language Resources and Evaluation
(LREC’12), Istanbul, Turkey. European Language
Resources Association (ELRA).
Andreas Stolcke. 2002. SRILM – An Extensible Lan-
guage Modeling Toolkit. In Seventh International
Conference on Spoken Language Processing, pages
901–904, Denver, CO, USA.
J¨org Tiedemann. 2009. News from OPUS - a col-
lection of multilingual parallel corpora with tools
and interfaces. In N. Nicolov, K. Bontcheva,
G. Angelova, and R. Mitkov, editors, Recent
Advances in Natural Language Processing, vol-
ume V, pages 237–248. John Benjamins, Amster-
dam/Philadelphia, Borovets, Bulgaria.
Hirofumi Yamamoto and Eiichiro Sumita. 2007. Bilin-
gual cluster based models for statistical machine
translation. In Proceedings of the 2007 Joint Con-
ference on Empirical Methods in Natural Language
Processing and Computational Natural Language
Learning, pages 514–523, Prague, Czech Republic.
</reference>
<page confidence="0.997693">
840
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.308764">
<title confidence="0.9993995">A Multi-Domain Translation Model for Statistical Machine Translation</title>
<author confidence="0.994142">Rico</author>
<affiliation confidence="0.804018333333333">Institute of Computational University of Binzm¨uhlestr.</affiliation>
<address confidence="0.613714">CH-8050</address>
<email confidence="0.839552">sennrich@cl.uzh.ch</email>
<author confidence="0.91389">Schwenk</author>
<affiliation confidence="0.999">LIUM, University of Le</affiliation>
<address confidence="0.991027">72085 Le Mans cedex 9,</address>
<email confidence="0.995287">lastname@lium.univ-lemans.fr</email>
<abstract confidence="0.998291238095238">While domain adaptation techniques for SMT have proven to be effective at improving translation quality, their practicality for a multi-domain environment is often limited because of the computational and human costs of developing and maintaining multiple systems adapted to different domains. We present an architecture that delays the computation of translation model features until decoding, allowing for the application of mixture-modeling techniques at decoding time. We also describe a method for unsupervised adaptation with development and test data from multiple domains. Experimental results on two language pairs demonstrate the effectiveness of both our translation model architecture and automatic clustering, with of up to 1 unadapted systems and single-domain adaptation.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Pratyush Banerjee</author>
<author>Jinhua Du</author>
<author>Baoli Li</author>
<author>Sudip Kumar Naskar</author>
<author>Andy Way</author>
<author>Josef Van Genabith</author>
</authors>
<title>Combining multi-domain statistical machine translation models using automatic classifiers.</title>
<date>2010</date>
<booktitle>In 9th Conference of the Association for Machine Translation in the Americas (AMTA 2010),</booktitle>
<location>Denver, Colorado, USA.</location>
<marker>Banerjee, Du, Li, Naskar, Way, Van Genabith, 2010</marker>
<rawString>Pratyush Banerjee, Jinhua Du, Baoli Li, Sudip Kumar Naskar, Andy Way, and Josef Van Genabith. 2010. Combining multi-domain statistical machine translation models using automatic classifiers. In 9th Conference of the Association for Machine Translation in the Americas (AMTA 2010), Denver, Colorado, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ondrej Bojar</author>
<author>Zdenek Zabokrtsk´y</author>
</authors>
<title>Czeng 0.9: Large parallel treebank with rich annotation.</title>
<date>2009</date>
<journal>Prague Bull. Math. Linguistics,</journal>
<pages>92--63</pages>
<marker>Bojar, Zabokrtsk´y, 2009</marker>
<rawString>Ondrej Bojar and Zdenek Zabokrtsk´y. 2009. Czeng 0.9: Large parallel treebank with rich annotation. Prague Bull. Math. Linguistics, 92:63–84.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
<author>Philipp Koehn</author>
<author>Christof Monz</author>
<author>Matt Post</author>
<author>Radu Soricut</author>
<author>Lucia Specia</author>
</authors>
<title>Findings of the 2012 workshop on statistical machine translation.</title>
<date>2012</date>
<booktitle>In Proceedings of the Seventh Workshop on Statistical Machine Translation,</booktitle>
<pages>10--51</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Montr´eal, Canada,</location>
<contexts>
<context position="21484" citStr="Callison-Burch et al., 2012" startWordPosition="3603" endWordPosition="3606">t is an English–German translation task with two domains, texts related to information technology (IT) and legal documents (LEGAL). We use data sets from both domains, plus out-of-domain corpora, as shown in table 2. 7 data sets come from the domain IT: 6 from OPUS (Tiedemann, 2009) and a translation memory (tm) provided by our industry partner. 3 data sets are from the legal domain: the ECB corpus from OPUS, plus the JRCAcquis (Steinberger et al., 2006) and DGT-TM (Steinberger et al., 2012). 2 data sets are out-ofdomain, made available by the 2012 Workshop on Statistical Machine Translation (Callison-Burch et al., 2012). The development sets are random samples from the respective in-domain bitexts (heldout from training). The test sets have been provided by Translated, our industry partner in the MATECAT project. Our second data set is CzEng 0.9, a Czech– English parallel corpus (Bojar and Zabokrtsk´y, 2009). It contains text from 7 different sources, on which we train separate component models. The size of the corpora is shown in table 3. As development and test sets, we use 500 sentences of held-out data per source. For both data sets, language models are trained on the target side of the bitexts. In all e</context>
</contexts>
<marker>Callison-Burch, Koehn, Monz, Post, Soricut, Specia, 2012</marker>
<rawString>Chris Callison-Burch, Philipp Koehn, Christof Monz, Matt Post, Radu Soricut, and Lucia Specia. 2012. Findings of the 2012 workshop on statistical machine translation. In Proceedings of the Seventh Workshop on Statistical Machine Translation, pages 10–51, Montr´eal, Canada, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan H Clark</author>
<author>Chris Dyer</author>
<author>Alon Lavie</author>
<author>Noah A Smith</author>
</authors>
<title>Better hypothesis testing for statistical machine translation: Controlling for optimizer instability.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>176--181</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Portland, Oregon, USA,</location>
<contexts>
<context position="20723" citStr="Clark et al., 2011" startWordPosition="3474" endWordPosition="3477">tation LM adaptation TM+LM adaptation IT LEGAL IT LEGAL IT LEGAL baseline 21.1 49.9 21.1 49.9 21.1 49.9 1 cluster (no split) 21.3* 49.9 21.8* 49.7 21.8* 49.8 2 clusters 21.6* 49.9 22.2* 50.4* 22.8* 50.2* 4 clusters 21.7* 49.9 23.1* 50.2* 22.6* 50.2* 8 clusters 22.1* 49.9 23.1* 50.1* 22.7* 50.3* 16 clusters 21.1 49.9 22.6* 50.3* 21.9* 50.1* gold clusters 21.8* 50.1* 22.4* 50.1* 23.2* 49.9 Table 4: Translation experiments EN–DE. BLEU scores reported. al., 2002). We account for optimizer instability by running 3 independent MERT runs per system, and performing significance testing with MultEval (Clark et al., 2011). Systems significantly better than the baseline with p &lt; 0.01 are marked with (*). We conduct experiments on two data sets. The first is an English–German translation task with two domains, texts related to information technology (IT) and legal documents (LEGAL). We use data sets from both domains, plus out-of-domain corpora, as shown in table 2. 7 data sets come from the domain IT: 6 from OPUS (Tiedemann, 2009) and a translation memory (tm) provided by our industry partner. 3 data sets are from the legal domain: the ECB corpus from OPUS, plus the JRCAcquis (Steinberger et al., 2006) and DGT-</context>
</contexts>
<marker>Clark, Dyer, Lavie, Smith, 2011</marker>
<rawString>Jonathan H. Clark, Chris Dyer, Alon Lavie, and Noah A. Smith. 2011. Better hypothesis testing for statistical machine translation: Controlling for optimizer instability. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 176–181, Portland, Oregon, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan H Clark</author>
<author>Alon Lavie</author>
<author>Chris Dyer</author>
</authors>
<title>One system, many domains: Open-domain statistical machine translation via feature augmentation.</title>
<date>2012</date>
<booktitle>In Conference of the Association for Machine Translation in the Americas 2012 (AMTA 2012),</booktitle>
<location>San Diego, California, USA.</location>
<contexts>
<context position="23683" citStr="Clark et al., 2012" startWordPosition="4001" endWordPosition="4004">ur clustering experiments, the development set is the concatenation of the LEGAL and IT development sets. However, we always use the gold segmentation between LEGAL and IT for MERT and testing. This allows for a detailed analysis of the effect of development data clustering for the purpose of model adaptation. In an unlabelled setting, one would have to run MERT either on the full development set (as we will do for the CZ–EN task) or separately on each cluster, or use an alternative approach to optimize log-linear weights in a multidomain setting, such as feature augmentation as described by (Clark et al., 2012). 837 system TM adaptation LM adaptation TM+LM adaptation baseline 34.4 34.4 34.4 1 cluster (no split) 34.5 33.7 34.1 2 clusters 34.6 34.0 34.4 4 clusters 34.7* 34.3 34.6 8 clusters 34.7* 34.5 34.9* 16 clusters 34.7* 34.7* 35.0* gold clusters 35.0* 35.0* 35.4* Table 6: Translation experiments CZ–EN. BLEU scores reported. We find that an adaptation of the TM and LM to the full development set (system “1 cluster”) yields the smallest improvements over the unadapted baseline. The reason for this is that the mixed-domain development set is not representative for the respective test sets. Using mul</context>
<context position="27963" citStr="Clark et al., 2012" startWordPosition="4728" endWordPosition="4731">or this computation. We have also described a usage scenario for this architecture, namely its ability to quickly switch between weight vectors in order to serve as an adapted model for multiple domains. A simple, unsupervised clustering of development data is sufficient to make use of this ability and imple838 ment a multi-domain translation system. If available, one can also use the architecture in a labelled setting. Future work could involve merging our translation model framework with the online adaptation of other models, or the log-linear weights. Our approach is orthogonal to that of (Clark et al., 2012), who perform feature augmentation to obtain multiple sets of adapted log-linear weights. While (Clark et al., 2012) use labelled data, their approach could in principle also be applied after unsupervised clustering. The translation model framework could also serve as the basis of real-time adaptation of translation systems, e.g. by using incremental means to update the weight vector, or having an incrementally trainable component model that learns from the post-edits by the user, and is assigned a suitable weight. Acknowledgments This research was partially funded by the Swiss National Scienc</context>
</contexts>
<marker>Clark, Lavie, Dyer, 2012</marker>
<rawString>Jonathan H. Clark, Alon Lavie, and Chris Dyer. 2012. One system, many domains: Open-domain statistical machine translation via feature augmentation. In Conference of the Association for Machine Translation in the Americas 2012 (AMTA 2012), San Diego, California, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Foster</author>
<author>Roland Kuhn</author>
</authors>
<title>Mixturemodel adaptation for SMT.</title>
<date>2007</date>
<booktitle>In Proceedings of the Second Workshop on Statistical Machine Translation, StatMT ’07,</booktitle>
<pages>128--135</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="1250" citStr="Foster and Kuhn, 2007" startWordPosition="175" endWordPosition="178">We present an architecture that delays the computation of translation model features until decoding, allowing for the application of mixture-modeling techniques at decoding time. We also describe a method for unsupervised adaptation with development and test data from multiple domains. Experimental results on two language pairs demonstrate the effectiveness of both our translation model architecture and automatic clustering, with gains of up to 1 BLEU over unadapted systems and single-domain adaptation. 1 Introduction The effectiveness of domain adaptation approaches such as mixture-modeling (Foster and Kuhn, 2007) has been established, and has led to research on a wide array of adaptation techniques in SMT, for instance (Matsoukas et al., 2009; Shah et al., 2012). In all these approaches, adaptation is performed during model training, with respect to a representative development corpus, and the models are kept unchanged when then system is deployed. Therefore, when working with multiple and/or unlabelled domains, domain adaptation is often impractical for a number of reasons. Firstly, maintaining multiple systems for each language pair, each adapted to a different domain, is costly in terms of computat</context>
</contexts>
<marker>Foster, Kuhn, 2007</marker>
<rawString>George Foster and Roland Kuhn. 2007. Mixturemodel adaptation for SMT. In Proceedings of the Second Workshop on Statistical Machine Translation, StatMT ’07, pages 128–135, Prague, Czech Republic. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz Josef Och</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistical phrase-based translation.</title>
<date>2003</date>
<booktitle>In NAACL ’03: Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology,</booktitle>
<pages>48--54</pages>
<publisher>Association for</publisher>
<institution>Computational Linguistics.</institution>
<location>Edmonton, Canada.</location>
<contexts>
<context position="6927" citStr="Koehn et al., 2003" startWordPosition="1082" endWordPosition="1085">on of translation model features to the decoding phase, and allow for multiple knowledge sources (e.g. bitexts or user-provided data) to contribute to their calculation. Our immediate purpose for this paper is domain adaptation in a multi-domain environment, but the delay of the feature computation has other potential applications, e.g. in interactive MT. We are concerned with calculating four features during decoding, henceforth just referred to as the translation model features: p(s|t), lex(s|t), p(t|s) and lex(t|s). s and t denote the source and target phrase. We follow the definitions in (Koehn et al., 2003). Traditionally, the phrase translation probabilities p(s|t) and p(t|s) are estimated through unsmoothed maximum likelihood estimation (MLE). c(x,y) (1) Px, c(x&apos;, y) where c denotes the count of an observation, and p the model probability. The lexical weights lex(s|t) and lex(t|s) are calculated as follows, using a set of word alignments a between s and t:1 1 X w(si|tj) |{j|(i,j) ∈ a} |∀(i,j)∈a (2) A special NULL token is added to t and aligned to each unaligned word in s. w(si|tj) is calculated through MLE, as in equation 1, but based on the word (pair) frequencies. To combine statistics from</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Philipp Koehn, Franz Josef Och, and Daniel Marcu. 2003. Statistical phrase-based translation. In NAACL ’03: Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology, pages 48–54, Edmonton, Canada. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
<author>Christine Moran</author>
<author>Richard Zens</author>
<author>Chris Dyer</author>
<author>Ondˇrej Bojar</author>
<author>Alexandra Constantin</author>
<author>Evan Herbst</author>
</authors>
<title>Moses: Open Source Toolkit for Statistical Machine Translation.</title>
<date>2007</date>
<booktitle>In ACL 2007, Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions,</booktitle>
<pages>177--180</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="19773" citStr="Koehn et al., 2007" startWordPosition="3320" endWordPosition="3323">data set sentences words (en) eu 1270 000 25 600 000 fiction 830 000 13 700 000 navajo 30 000 490 000 news 110 000 2 550 000 paraweb 370 000 3 930 000 subtitles 2 840 000 21200 000 techdoc 970 000 7 270 000 total (train) 6 420 000 74 700 000 dev 3500 50 700 test 3500 49 600 Table 3: Parallel data sets Czech–English. pass decoding, with an unadapted language model in the first phase, and rescoring with a language model adapted online, could perform adequately, and keep the complexity independent of the number of clusters. 5 Evaluation 5.1 Data and Methods We conduct all experiments with Moses (Koehn et al., 2007), SRILM (Stolcke, 2002), and GIZA++ (Och and Ney, 2003). Log-linear weights are optimized using MERT (Och and Ney, 2003). We keep the word alignment and lexical reordering models constant through the experiments to minimize the number of confounding factors. We report translation quality using BLEU (Papineni et 836 system TM adaptation LM adaptation TM+LM adaptation IT LEGAL IT LEGAL IT LEGAL baseline 21.1 49.9 21.1 49.9 21.1 49.9 1 cluster (no split) 21.3* 49.9 21.8* 49.7 21.8* 49.8 2 clusters 21.6* 49.9 22.2* 50.4* 22.8* 50.2* 4 clusters 21.7* 49.9 23.1* 50.2* 22.6* 50.2* 8 clusters 22.1* 49</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, Dyer, Bojar, Constantin, Herbst, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondˇrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open Source Toolkit for Statistical Machine Translation. In ACL 2007, Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions, pages 177–180, Prague, Czech Republic, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Spyros Matsoukas</author>
<author>Antti-Veikko I Rosti</author>
<author>Bing Zhang</author>
</authors>
<title>Discriminative corpus weight estimation for machine translation.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume</booktitle>
<volume>2</volume>
<pages>708--717</pages>
<institution>Singapore. Association for Computational Linguistics.</institution>
<contexts>
<context position="1382" citStr="Matsoukas et al., 2009" startWordPosition="198" endWordPosition="201"> mixture-modeling techniques at decoding time. We also describe a method for unsupervised adaptation with development and test data from multiple domains. Experimental results on two language pairs demonstrate the effectiveness of both our translation model architecture and automatic clustering, with gains of up to 1 BLEU over unadapted systems and single-domain adaptation. 1 Introduction The effectiveness of domain adaptation approaches such as mixture-modeling (Foster and Kuhn, 2007) has been established, and has led to research on a wide array of adaptation techniques in SMT, for instance (Matsoukas et al., 2009; Shah et al., 2012). In all these approaches, adaptation is performed during model training, with respect to a representative development corpus, and the models are kept unchanged when then system is deployed. Therefore, when working with multiple and/or unlabelled domains, domain adaptation is often impractical for a number of reasons. Firstly, maintaining multiple systems for each language pair, each adapted to a different domain, is costly in terms of computational and human resources: the full system development pipeline needs to be performed for all identified domains, all the models are</context>
</contexts>
<marker>Matsoukas, Rosti, Zhang, 2009</marker>
<rawString>Spyros Matsoukas, Antti-Veikko I. Rosti, and Bing Zhang. 2009. Discriminative corpus weight estimation for machine translation. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 2 - Volume 2, pages 708–717, Singapore. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="19828" citStr="Och and Ney, 2003" startWordPosition="3329" endWordPosition="3332">tion 830 000 13 700 000 navajo 30 000 490 000 news 110 000 2 550 000 paraweb 370 000 3 930 000 subtitles 2 840 000 21200 000 techdoc 970 000 7 270 000 total (train) 6 420 000 74 700 000 dev 3500 50 700 test 3500 49 600 Table 3: Parallel data sets Czech–English. pass decoding, with an unadapted language model in the first phase, and rescoring with a language model adapted online, could perform adequately, and keep the complexity independent of the number of clusters. 5 Evaluation 5.1 Data and Methods We conduct all experiments with Moses (Koehn et al., 2007), SRILM (Stolcke, 2002), and GIZA++ (Och and Ney, 2003). Log-linear weights are optimized using MERT (Och and Ney, 2003). We keep the word alignment and lexical reordering models constant through the experiments to minimize the number of confounding factors. We report translation quality using BLEU (Papineni et 836 system TM adaptation LM adaptation TM+LM adaptation IT LEGAL IT LEGAL IT LEGAL baseline 21.1 49.9 21.1 49.9 21.1 49.9 1 cluster (no split) 21.3* 49.9 21.8* 49.7 21.8* 49.8 2 clusters 21.6* 49.9 22.2* 50.4* 22.8* 50.2* 4 clusters 21.7* 49.9 23.1* 50.2* 22.6* 50.2* 8 clusters 22.1* 49.9 23.1* 50.1* 22.7* 50.3* 16 clusters 21.1 49.9 22.6* </context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Ortiz-Martfnez</author>
<author>Ismael Garcfa-Varea</author>
<author>Francisco Casacuberta</author>
</authors>
<title>Online learning for interactive statistical machine translation.</title>
<date>2010</date>
<booktitle>In HLTNAACL,</booktitle>
<pages>546--554</pages>
<marker>Ortiz-Martfnez, Garcfa-Varea, Casacuberta, 2010</marker>
<rawString>Daniel Ortiz-Martfnez, Ismael Garcfa-Varea, and Francisco Casacuberta. 2010. Online learning for interactive statistical machine translation. In HLTNAACL, pages 546–554. The Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>Bleu: A method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In ACL ’02: Proceedings of the 40th Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>311--318</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Philadelphia, Pennsylvania, USA.</location>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. Bleu: A method for automatic evaluation of machine translation. In ACL ’02: Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, pages 311–318, Philadelphia, Pennsylvania, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Majid Razmara</author>
<author>George Foster</author>
<author>Baskaran Sankaran</author>
<author>Anoop Sarkar</author>
</authors>
<title>Mixing multiple translation models in statistical machine translation.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, Jeju, Republic of Korea. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="4356" citStr="Razmara et al., 2012" startWordPosition="668" endWordPosition="671">eight the contribution of each component model to the feature calculation. The similarity suggests that our framework could also be used for interactive learning, with the ability to learn a model incrementally from user feedback, and weight it differently than the static models, opening new research opportunities. (Sennrich, 2012b) perform instance weighting of translation models, based on the sufficient statistics. Our framework implements this idea, with the main difference that the actual combination is delayed until decoding, to support adaptation to multiple domains in a single system. (Razmara et al., 2012) describe an ensemble decoding framework which combines several translation models in the decoding step. Our work is similar to theirs in that the combination is done at runtime, but we also delay the computation of translation model probabilities, and thus have access to richer sufficient statistics. In principle, our architecture can support all mixture operations that (Razmara et al., 2012) describe, plus additional ones such as forms of instance weighting, which are not possible after the translation probabilities have been computed. (Banerjee et al., 2010) focus on the problem of domain i</context>
</contexts>
<marker>Razmara, Foster, Sankaran, Sarkar, 2012</marker>
<rawString>Majid Razmara, George Foster, Baskaran Sankaran, and Anoop Sarkar. 2012. Mixing multiple translation models in statistical machine translation. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, Jeju, Republic of Korea. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rico Sennrich</author>
</authors>
<title>Mixture-modeling with unsupervised clusters for domain adaptation in statistical machine translation.</title>
<date>2012</date>
<booktitle>In 16th Annual Conference of the European Association for Machine Translation (EAMT 2012),</booktitle>
<pages>185--192</pages>
<location>Trento, Italy.</location>
<contexts>
<context position="4067" citStr="Sennrich, 2012" startWordPosition="626" endWordPosition="627"> sufficient statistics not for a single model, but a vector of models, which allows us to 832 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 832–840, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics weight the contribution of each component model to the feature calculation. The similarity suggests that our framework could also be used for interactive learning, with the ability to learn a model incrementally from user feedback, and weight it differently than the static models, opening new research opportunities. (Sennrich, 2012b) perform instance weighting of translation models, based on the sufficient statistics. Our framework implements this idea, with the main difference that the actual combination is delayed until decoding, to support adaptation to multiple domains in a single system. (Razmara et al., 2012) describe an ensemble decoding framework which combines several translation models in the decoding step. Our work is similar to theirs in that the combination is done at runtime, but we also delay the computation of translation model probabilities, and thus have access to richer sufficient statistics. In princ</context>
<context position="7662" citStr="Sennrich, 2012" startWordPosition="1213" endWordPosition="1214">od estimation (MLE). c(x,y) (1) Px, c(x&apos;, y) where c denotes the count of an observation, and p the model probability. The lexical weights lex(s|t) and lex(t|s) are calculated as follows, using a set of word alignments a between s and t:1 1 X w(si|tj) |{j|(i,j) ∈ a} |∀(i,j)∈a (2) A special NULL token is added to t and aligned to each unaligned word in s. w(si|tj) is calculated through MLE, as in equation 1, but based on the word (pair) frequencies. To combine statistics from a vector of n component corpora, we can use a weighted version of equation 1, which adds a weight vector λ of length n (Sennrich, 2012b): Pn p �iCi(x�y) (3) (x�yi �) _ 1 Ex, Aici(x&apos;, y) The word translation probabilities w(ti|sj) are defined analogously, and used in equation 2 for a weighted version. 1The equation shows lex(slt); lex(tls) is computed analogously. c(x, y) p(x|y) = c(y) lex(s|t, a) = Yn i=1 833 In order to compute the translation model features online, a number of sufficient statistics need to be accessible at decoding time. For p(s|t) and p(t|s), we require the statistics c(s), c(t) and c(s, t). For accessing them during decoding, we simply store them in the decoder’s data structure, rather than storing pre-c</context>
<context position="10774" citStr="Sennrich, 2012" startWordPosition="1748" endWordPosition="1749">ation of the architecture as part of the Moses decoder. 3c(s, t) and c(t, s) are not identical since the lexical probabilities are based on the unsymmetrized word alignment frequencies (in the Moses implementation which we reimplement). phrase (pair) c1(x) c2(x) row 300 80 (row, Zeile) (row, Reihe) λ p(Zeile|row) p(Reihe|row) 0.68 0.32 0.40 0.60 0.79 0.21 Table 1: Illustration of instance weighting with weight vectors for two corpora. vided by Moses, which reduces the memory requirements. Still, the number of components may need to be reduced, for instance through clustering of training data (Sennrich, 2012a). With a small modification, our framework could be changed to use a single table that stores a vector of n statistics instead of a vector of n tables. While this would be more compact in terms of memory, and keep the number of table lookups independent of the number of components, we chose a vector of n tables for its flexibility. With a vector of tables, tables can be quickly added to or removed from the system (conceivable even at runtime), and can be polymorph. One applications where this could be desirable is interactive machine translation, where one could work with a mix of compact, s</context>
<context position="14185" citStr="Sennrich, 2012" startWordPosition="2353" endWordPosition="2354">eight vectors for different phrase pairs in a sentence is conceivable. The framework can also be extended to support other combination methods, such as a linear interpolation of models. 4 Unsupervised Clustering for Online Translation Model Adaptation The framework supports decoding each sentence with a separate weight vector of size 4n, 4 being the number of translation model features whose computation can be weighted, and n the number of model components. We now address the question of how to automatically select good weights in a multi-domain task. As a way of optimizing instance weights, (Sennrich, 2012b) minimize translation model perplexity on a set of phrase pairs, automatically extracted from a parallel development set. We follow this technique, but want to have multiple weight vectors, adapted to different texts, between which the system switches at decoding time. The goal is to perform domain adaptation without requiring domain labels or user input, neither for development nor decoding. The basic idea consists of three steps: 1. Cluster a development set into k clusters. 2. Optimize translation model weights for each cluster. 3. For each sentence in the test set, assign it to the neare</context>
</contexts>
<marker>Sennrich, 2012</marker>
<rawString>Rico Sennrich. 2012a. Mixture-modeling with unsupervised clusters for domain adaptation in statistical machine translation. In 16th Annual Conference of the European Association for Machine Translation (EAMT 2012), pages 185–192, Trento, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rico Sennrich</author>
</authors>
<title>Perplexity minimization for translation model domain adaptation in statistical machine translation.</title>
<date>2012</date>
<booktitle>In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>539--549</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Avignon, France.</location>
<contexts>
<context position="4067" citStr="Sennrich, 2012" startWordPosition="626" endWordPosition="627"> sufficient statistics not for a single model, but a vector of models, which allows us to 832 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 832–840, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics weight the contribution of each component model to the feature calculation. The similarity suggests that our framework could also be used for interactive learning, with the ability to learn a model incrementally from user feedback, and weight it differently than the static models, opening new research opportunities. (Sennrich, 2012b) perform instance weighting of translation models, based on the sufficient statistics. Our framework implements this idea, with the main difference that the actual combination is delayed until decoding, to support adaptation to multiple domains in a single system. (Razmara et al., 2012) describe an ensemble decoding framework which combines several translation models in the decoding step. Our work is similar to theirs in that the combination is done at runtime, but we also delay the computation of translation model probabilities, and thus have access to richer sufficient statistics. In princ</context>
<context position="7662" citStr="Sennrich, 2012" startWordPosition="1213" endWordPosition="1214">od estimation (MLE). c(x,y) (1) Px, c(x&apos;, y) where c denotes the count of an observation, and p the model probability. The lexical weights lex(s|t) and lex(t|s) are calculated as follows, using a set of word alignments a between s and t:1 1 X w(si|tj) |{j|(i,j) ∈ a} |∀(i,j)∈a (2) A special NULL token is added to t and aligned to each unaligned word in s. w(si|tj) is calculated through MLE, as in equation 1, but based on the word (pair) frequencies. To combine statistics from a vector of n component corpora, we can use a weighted version of equation 1, which adds a weight vector λ of length n (Sennrich, 2012b): Pn p �iCi(x�y) (3) (x�yi �) _ 1 Ex, Aici(x&apos;, y) The word translation probabilities w(ti|sj) are defined analogously, and used in equation 2 for a weighted version. 1The equation shows lex(slt); lex(tls) is computed analogously. c(x, y) p(x|y) = c(y) lex(s|t, a) = Yn i=1 833 In order to compute the translation model features online, a number of sufficient statistics need to be accessible at decoding time. For p(s|t) and p(t|s), we require the statistics c(s), c(t) and c(s, t). For accessing them during decoding, we simply store them in the decoder’s data structure, rather than storing pre-c</context>
<context position="10774" citStr="Sennrich, 2012" startWordPosition="1748" endWordPosition="1749">ation of the architecture as part of the Moses decoder. 3c(s, t) and c(t, s) are not identical since the lexical probabilities are based on the unsymmetrized word alignment frequencies (in the Moses implementation which we reimplement). phrase (pair) c1(x) c2(x) row 300 80 (row, Zeile) (row, Reihe) λ p(Zeile|row) p(Reihe|row) 0.68 0.32 0.40 0.60 0.79 0.21 Table 1: Illustration of instance weighting with weight vectors for two corpora. vided by Moses, which reduces the memory requirements. Still, the number of components may need to be reduced, for instance through clustering of training data (Sennrich, 2012a). With a small modification, our framework could be changed to use a single table that stores a vector of n statistics instead of a vector of n tables. While this would be more compact in terms of memory, and keep the number of table lookups independent of the number of components, we chose a vector of n tables for its flexibility. With a vector of tables, tables can be quickly added to or removed from the system (conceivable even at runtime), and can be polymorph. One applications where this could be desirable is interactive machine translation, where one could work with a mix of compact, s</context>
<context position="14185" citStr="Sennrich, 2012" startWordPosition="2353" endWordPosition="2354">eight vectors for different phrase pairs in a sentence is conceivable. The framework can also be extended to support other combination methods, such as a linear interpolation of models. 4 Unsupervised Clustering for Online Translation Model Adaptation The framework supports decoding each sentence with a separate weight vector of size 4n, 4 being the number of translation model features whose computation can be weighted, and n the number of model components. We now address the question of how to automatically select good weights in a multi-domain task. As a way of optimizing instance weights, (Sennrich, 2012b) minimize translation model perplexity on a set of phrase pairs, automatically extracted from a parallel development set. We follow this technique, but want to have multiple weight vectors, adapted to different texts, between which the system switches at decoding time. The goal is to perform domain adaptation without requiring domain labels or user input, neither for development nor decoding. The basic idea consists of three steps: 1. Cluster a development set into k clusters. 2. Optimize translation model weights for each cluster. 3. For each sentence in the test set, assign it to the neare</context>
</contexts>
<marker>Sennrich, 2012</marker>
<rawString>Rico Sennrich. 2012b. Perplexity minimization for translation model domain adaptation in statistical machine translation. In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 539– 549, Avignon, France. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kashif Shah</author>
<author>Loc Barrault</author>
<author>Holger Schwenk</author>
</authors>
<title>A general framework to weight heterogeneous parallel data for model adaptation in statistical machine translation.</title>
<date>2012</date>
<booktitle>In Conference of the Association for Machine Translation in the Americas 2012 (AMTA 2012),</booktitle>
<location>San Diego, California, USA.</location>
<contexts>
<context position="1402" citStr="Shah et al., 2012" startWordPosition="202" endWordPosition="205">ques at decoding time. We also describe a method for unsupervised adaptation with development and test data from multiple domains. Experimental results on two language pairs demonstrate the effectiveness of both our translation model architecture and automatic clustering, with gains of up to 1 BLEU over unadapted systems and single-domain adaptation. 1 Introduction The effectiveness of domain adaptation approaches such as mixture-modeling (Foster and Kuhn, 2007) has been established, and has led to research on a wide array of adaptation techniques in SMT, for instance (Matsoukas et al., 2009; Shah et al., 2012). In all these approaches, adaptation is performed during model training, with respect to a representative development corpus, and the models are kept unchanged when then system is deployed. Therefore, when working with multiple and/or unlabelled domains, domain adaptation is often impractical for a number of reasons. Firstly, maintaining multiple systems for each language pair, each adapted to a different domain, is costly in terms of computational and human resources: the full system development pipeline needs to be performed for all identified domains, all the models are separately stored a</context>
</contexts>
<marker>Shah, Barrault, Schwenk, 2012</marker>
<rawString>Kashif Shah, Loc Barrault, and Holger Schwenk. 2012. A general framework to weight heterogeneous parallel data for model adaptation in statistical machine translation. In Conference of the Association for Machine Translation in the Americas 2012 (AMTA 2012), San Diego, California, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ralf Steinberger</author>
<author>Bruno Pouliquen</author>
<author>Anna Widiger</author>
<author>Camelia Ignat</author>
<author>Tomaz Erjavec</author>
<author>Dan Tufis</author>
<author>Daniel Varga</author>
</authors>
<title>The JRC-Acquis: A multilingual aligned parallel corpus with 20+ languages.</title>
<date>2006</date>
<booktitle>In Proceedings of the 5th International Conference on Language Resources and Evaluation (LREC’2006),</booktitle>
<location>Genoa, Italy.</location>
<contexts>
<context position="21314" citStr="Steinberger et al., 2006" startWordPosition="3577" endWordPosition="3580">with MultEval (Clark et al., 2011). Systems significantly better than the baseline with p &lt; 0.01 are marked with (*). We conduct experiments on two data sets. The first is an English–German translation task with two domains, texts related to information technology (IT) and legal documents (LEGAL). We use data sets from both domains, plus out-of-domain corpora, as shown in table 2. 7 data sets come from the domain IT: 6 from OPUS (Tiedemann, 2009) and a translation memory (tm) provided by our industry partner. 3 data sets are from the legal domain: the ECB corpus from OPUS, plus the JRCAcquis (Steinberger et al., 2006) and DGT-TM (Steinberger et al., 2012). 2 data sets are out-ofdomain, made available by the 2012 Workshop on Statistical Machine Translation (Callison-Burch et al., 2012). The development sets are random samples from the respective in-domain bitexts (heldout from training). The test sets have been provided by Translated, our industry partner in the MATECAT project. Our second data set is CzEng 0.9, a Czech– English parallel corpus (Bojar and Zabokrtsk´y, 2009). It contains text from 7 different sources, on which we train separate component models. The size of the corpora is shown in table 3. A</context>
</contexts>
<marker>Steinberger, Pouliquen, Widiger, Ignat, Erjavec, Tufis, Varga, 2006</marker>
<rawString>Ralf Steinberger, Bruno Pouliquen, Anna Widiger, Camelia Ignat, Tomaz Erjavec, Dan Tufis, and Daniel Varga. 2006. The JRC-Acquis: A multilingual aligned parallel corpus with 20+ languages. In Proceedings of the 5th International Conference on Language Resources and Evaluation (LREC’2006), Genoa, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ralf Steinberger</author>
<author>Andreas Eisele</author>
<author>Szymon Klocek</author>
<author>Spyridon Pilos</author>
<author>Patrick Schl¨uter</author>
</authors>
<title>DGTTM: A freely available translation memory in 22 languages.</title>
<date>2012</date>
<journal>European Language Resources Association (ELRA).</journal>
<booktitle>In Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC’12),</booktitle>
<location>Istanbul,</location>
<marker>Steinberger, Eisele, Klocek, Pilos, Schl¨uter, 2012</marker>
<rawString>Ralf Steinberger, Andreas Eisele, Szymon Klocek, Spyridon Pilos, and Patrick Schl¨uter. 2012. DGTTM: A freely available translation memory in 22 languages. In Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC’12), Istanbul, Turkey. European Language Resources Association (ELRA).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>SRILM – An Extensible Language Modeling Toolkit.</title>
<date>2002</date>
<booktitle>In Seventh International Conference on Spoken Language Processing,</booktitle>
<pages>901--904</pages>
<location>Denver, CO, USA.</location>
<contexts>
<context position="19796" citStr="Stolcke, 2002" startWordPosition="3325" endWordPosition="3326">) eu 1270 000 25 600 000 fiction 830 000 13 700 000 navajo 30 000 490 000 news 110 000 2 550 000 paraweb 370 000 3 930 000 subtitles 2 840 000 21200 000 techdoc 970 000 7 270 000 total (train) 6 420 000 74 700 000 dev 3500 50 700 test 3500 49 600 Table 3: Parallel data sets Czech–English. pass decoding, with an unadapted language model in the first phase, and rescoring with a language model adapted online, could perform adequately, and keep the complexity independent of the number of clusters. 5 Evaluation 5.1 Data and Methods We conduct all experiments with Moses (Koehn et al., 2007), SRILM (Stolcke, 2002), and GIZA++ (Och and Ney, 2003). Log-linear weights are optimized using MERT (Och and Ney, 2003). We keep the word alignment and lexical reordering models constant through the experiments to minimize the number of confounding factors. We report translation quality using BLEU (Papineni et 836 system TM adaptation LM adaptation TM+LM adaptation IT LEGAL IT LEGAL IT LEGAL baseline 21.1 49.9 21.1 49.9 21.1 49.9 1 cluster (no split) 21.3* 49.9 21.8* 49.7 21.8* 49.8 2 clusters 21.6* 49.9 22.2* 50.4* 22.8* 50.2* 4 clusters 21.7* 49.9 23.1* 50.2* 22.6* 50.2* 8 clusters 22.1* 49.9 23.1* 50.1* 22.7* 50</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Andreas Stolcke. 2002. SRILM – An Extensible Language Modeling Toolkit. In Seventh International Conference on Spoken Language Processing, pages 901–904, Denver, CO, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J¨org Tiedemann</author>
</authors>
<title>News from OPUS - a collection of multilingual parallel corpora with tools and interfaces.</title>
<date>2009</date>
<booktitle>Recent Advances in Natural Language Processing,</booktitle>
<volume>volume V,</volume>
<pages>237--248</pages>
<editor>In N. Nicolov, K. Bontcheva, G. Angelova, and R. Mitkov, editors,</editor>
<location>Amsterdam/Philadelphia, Borovets, Bulgaria.</location>
<contexts>
<context position="21139" citStr="Tiedemann, 2009" startWordPosition="3546" endWordPosition="3547">ents EN–DE. BLEU scores reported. al., 2002). We account for optimizer instability by running 3 independent MERT runs per system, and performing significance testing with MultEval (Clark et al., 2011). Systems significantly better than the baseline with p &lt; 0.01 are marked with (*). We conduct experiments on two data sets. The first is an English–German translation task with two domains, texts related to information technology (IT) and legal documents (LEGAL). We use data sets from both domains, plus out-of-domain corpora, as shown in table 2. 7 data sets come from the domain IT: 6 from OPUS (Tiedemann, 2009) and a translation memory (tm) provided by our industry partner. 3 data sets are from the legal domain: the ECB corpus from OPUS, plus the JRCAcquis (Steinberger et al., 2006) and DGT-TM (Steinberger et al., 2012). 2 data sets are out-ofdomain, made available by the 2012 Workshop on Statistical Machine Translation (Callison-Burch et al., 2012). The development sets are random samples from the respective in-domain bitexts (heldout from training). The test sets have been provided by Translated, our industry partner in the MATECAT project. Our second data set is CzEng 0.9, a Czech– English parall</context>
</contexts>
<marker>Tiedemann, 2009</marker>
<rawString>J¨org Tiedemann. 2009. News from OPUS - a collection of multilingual parallel corpora with tools and interfaces. In N. Nicolov, K. Bontcheva, G. Angelova, and R. Mitkov, editors, Recent Advances in Natural Language Processing, volume V, pages 237–248. John Benjamins, Amsterdam/Philadelphia, Borovets, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hirofumi Yamamoto</author>
<author>Eiichiro Sumita</author>
</authors>
<title>Bilingual cluster based models for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,</booktitle>
<pages>514--523</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="5208" citStr="Yamamoto and Sumita, 2007" startWordPosition="802" endWordPosition="805">n model probabilities, and thus have access to richer sufficient statistics. In principle, our architecture can support all mixture operations that (Razmara et al., 2012) describe, plus additional ones such as forms of instance weighting, which are not possible after the translation probabilities have been computed. (Banerjee et al., 2010) focus on the problem of domain identification in a multi-domain setting. They use separate translation systems for each domain, and a supervised setting, whereas we aim for a system that integrates support for multiple domains, with or without supervision. (Yamamoto and Sumita, 2007) propose unsupervised clustering at both training and decoding time. The training text is divided into a number of clusters, a model is trained on each, and during decoding, each sentence is assigned to the closest cluster-specific model. Our approach bears resemblance to this clustering, but is different in that Yamamoto and Sumita assign each sentence to the closest model, and use this model for decoding, whereas in our approach, each cluster is associated with a mixture of models that is optimized to the cluster, and the number of clusters need not be equal to the number of component models</context>
</contexts>
<marker>Yamamoto, Sumita, 2007</marker>
<rawString>Hirofumi Yamamoto and Eiichiro Sumita. 2007. Bilingual cluster based models for statistical machine translation. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 514–523, Prague, Czech Republic.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>