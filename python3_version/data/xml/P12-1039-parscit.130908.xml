<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001534">
<title confidence="0.990092">
Concept-to-text Generation via Discriminative Reranking
</title>
<author confidence="0.971801">
Ioannis Konstas and Mirella Lapata
</author>
<affiliation confidence="0.9984115">
Institute for Language, Cognition and Computation
School of Informatics, University of Edinburgh
</affiliation>
<address confidence="0.99253">
10 Crichton Street, Edinburgh EH8 9AB
</address>
<email confidence="0.997162">
i.konstas@sms.ed.ac.uk, mlap@inf.ed.ac.uk
</email>
<sectionHeader confidence="0.995627" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999827333333334">
This paper proposes a data-driven method
for concept-to-text generation, the task of
automatically producing textual output from
non-linguistic input. A key insight in our ap-
proach is to reduce the tasks of content se-
lection (“what to say”) and surface realization
(“how to say”) into a common parsing prob-
lem. We define a probabilistic context-free
grammar that describes the structure of the in-
put (a corpus of database records and text de-
scribing some of them) and represent it com-
pactly as a weighted hypergraph. The hyper-
graph structure encodes exponentially many
derivations, which we rerank discriminatively
using local and global features. We propose a
novel decoding algorithm for finding the best
scoring derivation and generating in this set-
ting. Experimental evaluation on the ATIS do-
main shows that our model outperforms a
competitive discriminative system both using
BLEU and in a judgment elicitation study.
</bodyText>
<sectionHeader confidence="0.999131" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999967891304348">
Concept-to-text generation broadly refers to the
task of automatically producing textual output from
non-linguistic input such as databases of records,
logical form, and expert system knowledge bases
(Reiter and Dale, 2000). A variety of concept-to-
text generation systems have been engineered over
the years, with considerable success (e.g., Dale et
al. (2003), Reiter et al. (2005), Green (2006), Turner
et al. (2009)). Unfortunately, it is often difficult
to adapt them across different domains as they rely
mostly on handcrafted components.
In this paper we present a data-driven ap-
proach to concept-to-text generation that is domain-
independent, conceptually simple, and flexible. Our
generator learns from a set of database records and
textual descriptions (for some of them). An exam-
ple from the air travel domain is shown in Figure 1.
Here, the records provide a structured representation
of the flight details (e.g., departure and arrival time,
location), and the text renders some of this infor-
mation in natural language. Given such input, our
model determines which records to talk about (con-
tent selection) and which words to use for describing
them (surface realization). Rather than breaking up
the generation process into a sequence of local deci-
sions, we perform both tasks jointly. A key insight
in our approach is to reduce content selection and
surface realization into a common parsing problem.
Specifically, we define a probabilistic context-free
grammar (PCFG) that captures the structure of the
database and its correspondence to natural language.
This grammar represents multiple derivations which
we encode compactly using a weighted hypergraph
(or packed forest), a data structure that defines a
weight for each tree.
Following a generative approach, we could first
learn the weights of the PCFG by maximising the
joint likelihood of the model and then perform gen-
eration by finding the best derivation tree in the hy-
pergraph. The performance of this baseline system
could be potentially further improved using discrim-
inative reranking (Collins, 2000). Typically, this
method first creates a list of n-best candidates from
a generative model, and then reranks them with arbi-
trary features (both local and global) that are either
not computable or intractable to compute within the
</bodyText>
<page confidence="0.985716">
369
</page>
<note confidence="0.9925395">
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 369–378,
Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics
</note>
<figureCaption confidence="0.9921435">
Figure 1: Example of non-linguistic input as a structured database and logical form and its corresponding text. We
omit record fields that have no value, for the sake of brevity.
</figureCaption>
<note confidence="0.975608142857143">
Flight Day Number Month Condition Search
from to number dep/ar month dep/ar arg1 arg2 type type what
denver boston 9 departure august departure arrival time 1600 &lt; query flight
Database:
X−expression: ax. f light(x) n f rom(x,denver) nto(x,boston) n day number(x,9) n month(x,august)n
Text: less than(arrival time(x),1600)
Give me the flights leaving Denver August ninth coming back to Boston before 4pm.
</note>
<bodyText confidence="0.998729896551724">
baseline system.
An appealing alternative is to rerank the hyper-
graph directly (Huang, 2008). As it compactly en-
codes exponentially many derivations, we can ex-
plore a much larger hypothesis space than would
have been possible with an n-best list. Importantly,
in this framework non-local features are computed
at all internal hypergraph nodes, allowing the de-
coder to take advantage of them continuously at all
stages of the generation process. We incorporate
features that are local with respect to a span of a
sub-derivation in the packed forest; we also (approx-
imately) include features that arbitrarily exceed span
boundaries, thus capturing more global knowledge.
Experimental results on the ATIS domain (Dahl et
al., 1994) demonstrate that our model outperforms
a baseline based on the best derivation and a state-
of-the-art discriminative system (Angeli et al., 2010)
by a wide margin.
Our contributions in this paper are threefold: we
recast concept-to-text generation in a probabilistic
parsing framework that allows to jointly optimize
content selection and surface realization; we repre-
sent parse derivations compactly using hypergraphs
and illustrate the use of an algorithm for generating
(rather than parsing) in this framework; finally, the
application of discriminative reranking to concept-
to-text generation is novel to our knowledge and as
our experiments show beneficial.
</bodyText>
<sectionHeader confidence="0.999783" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.998538586956522">
Early discriminative approaches to text generation
were introduced in spoken dialogue systems, and
usually tackled content selection and surface re-
alization separately. Ratnaparkhi (2002) concep-
tualized surface realization (from a fixed meaning
representation) as a classification task. Local and
non-local information (e.g., word n-grams, long-
range dependencies) was taken into account with the
use of features in a maximum entropy probability
model. More recently, Wong and Mooney (2007)
describe an approach to surface realization based on
synchronous context-free grammars. The latter are
learned using a log-linear model with minimum er-
ror rate training (Och, 2003).
Angeli et al. (2010) were the first to propose a
unified approach to content selection and surface re-
alization. Their model operates over automatically
induced alignments of words to database records
(Liang et al., 2009) and decomposes into a sequence
of discriminative local decisions. They first deter-
mine which records in the database to talk about,
then which fields of those records to mention, and
finally which words to use to describe the chosen
fields. Each of these decisions is implemented as
a log-linear model with features learned from train-
ing data. Their surface realization component per-
forms decisions based on templates that are automat-
ically extracted and smoothed with domain-specific
knowledge in order to guarantee fluent output.
Discriminative reranking has been employed in
many NLP tasks such as syntactic parsing (Char-
niak and Johnson, 2005; Huang, 2008), machine
translation (Shen et al., 2004; Li and Khudanpur,
2009) and semantic parsing (Ge and Mooney, 2006).
Our model is closest to Huang (2008) who also
performs forest reranking on a hypergraph, using
both local and non-local features, whose weights
are tuned with the averaged perceptron algorithm
(Collins, 2002). We adapt forest reranking to gen-
eration and introduce several task-specific features
that boost performance. Although conceptually re-
lated to Angeli et al. (2010), our model optimizes
content selection and surface realization simultane-
ously, rather than as a sequence. The discriminative
aspect of two models is also fundamentally different.
We have a single reranking component that applies
</bodyText>
<page confidence="0.995161">
370
</page>
<bodyText confidence="0.9961705">
throughout, whereas they train different discrimina-
tive models for each local decision.
</bodyText>
<sectionHeader confidence="0.97803" genericHeader="method">
3 Problem Formulation
</sectionHeader>
<bodyText confidence="0.999977032258065">
We assume our generator takes as input a set of
database records d and produces text w that verbal-
izes some of these records. Each record r ∈ d has a
type r.t and a set of fields f associated with it. Fields
have different values f.v and types f.t (i.e., integer
or categorical). For example, in Figure 1, flight is a
record type with fields from and to. The values of
these fields are denver and Boston and their type is
categorical.
During training, our algorithm is given a corpus
consisting of several scenarios, i.e., database records
paired with texts like those shown in Figure 1. The
database (and accompanying texts) are next con-
verted into a PCFG whose weights are learned from
training data. PCFG derivations are represented as
a weighted directed hypergraph (Gallo et al., 1993).
The weights on the hyperarcs are defined by a vari-
ety of feature functions, which we learn via a dis-
criminative online update algorithm. During test-
ing, we are given a set of database records with-
out the corresponding text. Using the learned fea-
ture weights, we compile a hypergraph specific to
this test input and decode it approximately (Huang,
2008). The hypergraph representation allows us
to decompose the feature functions and compute
them piecemeal at each hyperarc (or sub-derivation),
rather than at the root node as in conventional n-best
list reranking. Note that the algorithm does not sep-
arate content selection from surface realization, both
subtasks are optimized jointly through the proba-
bilistic parsing formulation.
</bodyText>
<subsectionHeader confidence="0.997077">
3.1 Grammar Definition
</subsectionHeader>
<bodyText confidence="0.999658166666667">
We capture the structure of the database with a num-
ber of CFG rewrite rules, in a similar way to how
Liang et al. (2009) define Markov chains in their
hierarchical model. These rules are purely syn-
tactic (describing the intuitive relationship between
records, records and fields, fields and corresponding
words), and could apply to any database with sim-
ilar structure irrespectively of the semantics of the
domain.
Our grammar is defined in Table 1 (rules (1)–(9)).
Rule weights are governed by an underlying multi-
nomial distribution and are shown in square brack-
</bodyText>
<listItem confidence="0.959335888888889">
1. S → R(start) [Pr = 1]
2. R(ri.t) → FS(rj,start) R(rj.t) [P(rj.t |ri.t) · λ]
3. R(ri.t) → FS(rj,start) [P(rj.t |ri.t) · λ]
4. FS(r,r.fi) → F(r,r.fj) FS(r,r.fj) [P(fj  |fi)]
5. FS(r,r. fi) → F(r,r.fj) [P(fj  |fi)]
6. F(r,r.f) → W(r,r.f) F(r,r.f) [P(w|w−1,r,r.f)]
7. F(r,r.f) → W(r,r.f) [P(w|w−1,r,r.f)]
8. W(r,r.f) → α [P(α|r,r.f, f.t, f.v)]
9. W(r,r.f) → g(f.v)
</listItem>
<equation confidence="0.611649">
[P(g(f.v).mode|r,r. f, f.t = int)]
</equation>
<tableCaption confidence="0.9914415">
Table 1: Grammar rules and their weights shown in
square brackets.
</tableCaption>
<bodyText confidence="0.999655733333333">
ets. Non-terminal symbols are in capitals and de-
note intermediate states; the terminal symbol α
corresponds to all words seen in the training set,
and g(f.v) is a function for generating integer num-
bers given the value of a field f. All non-terminals,
save the start symbol S, have one or more constraints
(shown in parentheses), similar to number and gen-
der agreement constraints in augmented syntactic
rules.
Rule (1) denotes the expansion from the start
symbol S to record R, which has the special start
type (hence the notation R(start)). Rule (2) de-
fines a chain between two consecutive records ri
and rj. Here, FS(rj,start) represents the set
of fields of the target rj, following the source
record R(ri). For example, the rule R(search1.t) →
FS(flight1,start)R(flight1.t) can be interpreted as
follows. Given that we have talked about search1,
we will next talk about flight1 and thus emit its
corresponding fields. R(flight1.t) is a non-terminal
place-holder for the continuation of the chain of
records, and start in FS is a special boundary field
between consecutive records. The weight of this rule
is the bigram probability of two records conditioned
on their type, multiplied with a normalization fac-
tor λ. We have also defined a null record type i.e., a
record that has no fields and acts as a smoother for
words that may not correspond to a particular record.
Rule (3) is simply an escape rule, so that the parsing
process (on the record level) can finish.
</bodyText>
<equation confidence="0.614269">
Rule (4) is the equivalent of rule (2) at the field
</equation>
<page confidence="0.969899">
371
</page>
<bodyText confidence="0.999924888888889">
level, i.e., it describes the chaining of two con-
secutive fields fi and fj. Non-terminal F(r,r. f)
refers to field f of record r. For example, the rule
FS(flight1, from) → F(flight1,to)FS(flight1,to),
specifies that we should talk about the field to of
record flight1, after talking about the field from.
Analogously to the record level, we have also in-
cluded a special null field type for the emission of
words that do not correspond to a specific record
field. Rule (6) defines the expansion of field F to
a sequence of (binarized) words W, with a weight
equal to the bigram probability of the current word
given the previous word, the current record, and
field.
Rules (8) and (9) define the emission of words and
integer numbers from W, given a field type and its
value. Rule (8) emits a single word from the vocabu-
lary of the training set. Its weight defines a multino-
mial distribution over all seen words, for every value
of field f, given that the field type is categorical or
the special null field. Rule (9) is identical but for
fields whose type is integer. Function g(f.v) gener-
ates an integer number given the field value, using
either of the following six ways (Liang et al., 2009):
identical to the field value, rounding up or rounding
down to a multiple of 5, rounding off to the clos-
est multiple of 5 and finally adding or subtracting
some unexplained noise.1 The weight is a multino-
mial over the six generation function modes, given
the record field f.
The CFG in Table 1 will produce many deriva-
tions for a given input (i.e., a set of database records)
which we represent compactly using a hypergraph or
a packed forest (Klein and Manning, 2001; Huang,
2008). Simplified examples of this representation
are shown in Figure 2.
</bodyText>
<subsectionHeader confidence="0.999876">
3.2 Hypergraph Reranking
</subsectionHeader>
<bodyText confidence="0.9999833">
For our generation task, we are given a set of
database records d, and our goal is to find the best
corresponding text w. This corresponds to the best
grammar derivation among a set of candidate deriva-
tions represented implicitly in the hypergraph struc-
ture. As shown in Table 1, the mapping from d to w
is unknown. Therefore, all the intermediate multino-
mial distributions, described in the previous section,
define a hidden correspondence structure h, between
records, fields, and their values. We find the best
</bodyText>
<footnote confidence="0.981078">
1The noise is modeled as a geometric distribution.
</footnote>
<construct confidence="0.388946">
Algorithm 1: Averaged Structured Perceptron
</construct>
<bodyText confidence="0.541618">
Input: Training scenarios: (di,w∗,h+i )Ni=1
</bodyText>
<equation confidence="0.995762">
1 α ← 0
2 fort ← 1...T do
3 for i ← 1...N do
4 ( ˆw,ˆh) = argmaxw,hα·Φ(di,wi,hi)
if (w∗ i ,h+
5 i ) =6 ( ˆwi, ˆhi) then
i ,h+
6 α ← α+Φ(di,w∗ i )−Φ(di, ˆwi, ˆhi)
1
7 returnT ∑T 1 i=1 αit
t=1 N ∑N
</equation>
<bodyText confidence="0.8842375">
scoring derivation ( ˆw, ˆh) by maximizing over con-
figurations of h:
</bodyText>
<equation confidence="0.9488885">
( ˆw, ˆh) =argmax α·Φ(d,w,h)
w,h
</equation>
<bodyText confidence="0.999986222222222">
We define the score of ( ˆw, ˆh) as the dot product
between a high dimensional feature representation
Φ = (Φ1,...,Φm) and a weight vector α.
We estimate the weights α using the averaged
structured perceptron algorithm (Collins, 2002),
which is well known for its speed and good perfor-
mance in similar large-parameter NLP tasks (Liang
et al., 2006; Huang, 2008). As shown in Algo-
rithm 1, the perceptron makes several passes over
the training scenarios, and in each iteration it com-
putes the best scoring ( ˆw, ˆh) among the candidate
derivations, given the current weights α. In line 6,
the algorithm updates α with the difference (if any)
between the feature representations of the best scor-
ing derivation ( ˆw, ˆh) and the the oracle derivation
(w∗,h+). Here, wˆ is the estimated text, w∗ the gold-
standard text, hˆ is the estimated latent configuration
of the model and h+ the oracle latent configuration.
The final weight vector α is the average of weight
vectors over T iterations and N scenarios. This av-
eraging procedure avoids overfitting and produces
more stable results (Collins, 2002).
In the following, we first explain how we decode
in this framework, i.e., find the best scoring deriva-
tion (Section 3.3) and discuss our definition for the
oracle derivation (w∗,h+) (Section 3.4). Our fea-
tures are described in Section 4.2.
</bodyText>
<subsectionHeader confidence="0.998104">
3.3 Hypergraph Decoding
</subsectionHeader>
<bodyText confidence="0.9996796">
Following Huang (2008), we also distinguish fea-
tures into local, i.e., those that can be computed
within the confines of a single hyperedge, and non-
local, i.e., those that require the prior visit of nodes
other than their antecedents. For example, the
</bodyText>
<page confidence="0.992602">
372
</page>
<bodyText confidence="0.999876127659575">
Alignment feature in Figure 2(a) is local, and thus
can be computed a priori, but the Word Trigrams
is not; in Figure 2(b) words in parentheses are sub-
generations created so far at each word node; their
combination gives rise to the trigrams serving as
input to the feature. However, this combination
may not take place at their immediate ancestors,
since these may not be adjacent nodes in the hy-
pergraph. According to the grammar in Table 1,
there is no direct hyperedge between nodes repre-
senting words (W) and nodes representing the set of
fields these correspond to (FS); rather, W and FS are
connected implicitly via individual fields (F). Note,
that in order to estimate the trigram feature at the
FS node, we need to carry word information in the
derivations of its antecedents, as we go bottom-up.2
Given these two types of features, we can then
adapt Huang’s (2008) approximate decoding algo-
rithm to find ( ˆw, ˆh). Essentially, we perform bottom-
up Viterbi search, visiting the nodes in reverse topo-
logical order, and keeping the k-best derivations for
each. The score of each derivation is a linear com-
bination of local and non-local features weights. In
machine translation, a decoder that implements for-
est rescoring (Huang and Chiang, 2007) uses the lan-
guage model as an external criterion of the good-
ness of sub-translations on account of their gram-
maticality. Analogously here, non-local features in-
fluence the selection of the best combinations, by
introducing knowledge that exceeds the confines of
the node under consideration and thus depend on
the sub-derivations generated so far. (e.g., word tri-
grams spanning a field node rely on evidence from
antecedent nodes that may be arbitrarily deeper than
the field’s immediate children).
Our treatment of leaf nodes (see rules (8) and (9))
differs from the way these are usually handled in
parsing. Since in generation we must emit rather
than observe the words, for each leaf node we there-
fore output the k-best words according to the learned
weights a of the Alignment feature (see Sec-
tion 4.2), and continue building our sub-generations
bottom-up. This generation task is far from triv-
ial: the search space on the word level is the size of
the vocabulary and each field of a record can poten-
tially generate all words. Also, note that in decoding
it is useful to have a way to score different output
</bodyText>
<footnote confidence="0.791439">
2We also store field information to compute structural fea-
tures, described in Section 4.2.
</footnote>
<bodyText confidence="0.9974275">
lengths |w|. Rather than setting w to a fixed length,
we rely on a linear regression predictor that uses the
counts of each record type per scenario as features
and is able to produce variable length texts.
</bodyText>
<subsectionHeader confidence="0.943752">
3.4 Oracle Derivation
</subsectionHeader>
<bodyText confidence="0.999984">
So far we have remained agnostic with respect to
the oracle derivation (w�,h+). In other NLP tasks
such as syntactic parsing, there is a gold-standard
parse, that can be used as the oracle. In our gener-
ation setting, such information is not available. We
do not have the gold-standard alignment between the
database records and the text that verbalizes them.
Instead, we approximate it using the existing de-
coder to find the best latent configuration h+ given
the observed words in the training text w*.3 This is
similar in spirit to the generative alignment model of
Liang et al. (2009).
</bodyText>
<sectionHeader confidence="0.998725" genericHeader="method">
4 Experimental Design
</sectionHeader>
<bodyText confidence="0.9999658">
In this section we present our experimental setup for
assessing the performance of our model. We give
details on our dataset, model parameters and fea-
tures, the approaches used for comparison, and ex-
plain how system output was evaluated.
</bodyText>
<subsectionHeader confidence="0.915993">
4.1 Dataset
</subsectionHeader>
<bodyText confidence="0.9999255">
We conducted our experiments on the Air Travel In-
formation System (ATIS) dataset (Dahl et al., 1994)
which consists of transcriptions of spontaneous ut-
terances of users interacting with a hypothetical on-
line flight booking system. The dataset was orig-
inally created for the development of spoken lan-
guage systems and is partitioned in individual user
turns (e.g., flights from orlando to milwaukee, show
flights from orlando to milwaukee leaving after six
o’clock) each accompanied with an SQL query to a
booking system and the results of this query. These
utterances are typically short expressing a specific
communicative goal (e.g., a question about the ori-
gin of a flight or its time of arrival). This inevitably
results in small scenarios with a few words that of-
ten unambiguously correspond to a single record. To
avoid training our model on a somewhat trivial cor-
pus, we used the dataset introduced in Zettlemoyer
</bodyText>
<footnote confidence="0.91188675">
3In machine translation, Huang (2008) provides a soft al-
gorithm that finds the forest oracle, i.e., the parse among the
reranked candidates with the highest Parseval F-score. How-
ever, it still relies on the gold-standard reference translation.
</footnote>
<page confidence="0.999191">
373
</page>
<bodyText confidence="0.99997471875">
and Collins (2007) instead, which combines the ut-
terances of a single user in one scenario and con-
tains 5,426 scenarios in total; each scenario corre-
sponds to a (manually annotated) formal meaning
representation (X-expression) and its translation in
natural language.
Lambda expressions were automatically con-
verted into records, fields and values following the
conventions adopted in Liang et al. (2009).4 Given
a lambda expression like the one shown in Figure 1,
we first create a record for each variable and constant
(e.g., x, 9, august). We then assign record types ac-
cording to the corresponding class types (e.g., vari-
able x has class type flight). Next, fields and val-
ues are added from predicates with two arguments
with the class type of the first argument matching
that of the record type. The name of the predicate
denotes the field, and the second argument denotes
the value. We also defined special record types, such
as condition and search. The latter is introduced for
every lambda operator and assigned the categorical
field what with the value flight which refers to the
record type of variable x.
Contrary to datasets used in previous generation
studies (e.g., ROBOCUP (Chen and Mooney, 2008)
and WEATHERGOV (Liang et al., 2009)), ATIS has a
much richer vocabulary (927 words); each scenario
corresponds to a single sentence (average length
is 11.2 words) with 2.65 out of 19 record types
mentioned on average. Following Zettlemoyer and
Collins (2007), we trained on 4,962 scenarios and
tested on ATIS NOV93 which contains 448 examples.
</bodyText>
<subsectionHeader confidence="0.7049">
4.2 Features
</subsectionHeader>
<bodyText confidence="0.999912363636364">
Broadly speaking, we defined two types of features,
namely lexical and structural ones. In addition,
we used a generatively trained PCFG as a baseline
feature and an alignment feature based on the co-
occurrence of records (or fields) with words.
Baseline Feature This is the log score of a gen-
erative decoder trained on the PCFG from Table 1.
We converted the grammar into a hypergraph, and
learned its probability distributions using a dynamic
program similar to the inside-outside algorithm (Li
and Eisner, 2009). Decoding was performed approx-
</bodyText>
<footnote confidence="0.891224">
4The resulting dataset and a technical report describ-
ing the mapping procedure in detail are available from
http://homepages.inf.ed.ac.uk/s0793019/index.php?
page=resources
</footnote>
<bodyText confidence="0.999513790697675">
imately via cube pruning (Chiang, 2007), by inte-
grating a trigram language model extracted from the
training set (see Konstas and Lapata (2012) for de-
tails). Intuitively, the feature refers to the overall
goodness of a specific derivation, applied locally in
every hyperedge.
Alignment Features Instances of this feature fam-
ily refer to the count of each PCFG rule from Ta-
ble 1. For example, the number of times rule
R(search1.t) —* FS(flight1,start)R(flight1.t) is in-
cluded in a derivation (see Figure 2(a))
Lexical Features These features encourage gram-
matical coherence and inform lexical selection over
and above the limited horizon of the language model
captured by Rules (6)–(9). They also tackle anoma-
lies in the generated output, due to the ergodicity of
the CFG rules at the record and field level:
Word Bigrams/Trigrams This is a group of
non-local feature functions that count word n-grams
at every level in the hypergraph (see Figure 2(b)).
The integration of words in the sub-derivations is
adapted from Chiang (2007).
Number of Words per Field This feature function
counts the number of words for every field, aiming
to capture compound proper nouns and multi-word
expressions, e.g., fields from and to frequently corre-
spond to two or three words such as ‘new york’ and
‘salt lake city’ (see Figure 2(d)).
Consecutive Word/Bigram/Trigram This feature
family targets adjacent repetitions of the same word,
bigram or trigram, e.g., ‘show me the show me the
flights’.
Structural Features Features in this category tar-
get primarily content selection and influence appro-
priate choice at the field level:
Field bigrams/trigrams Analogously to the lexical
features mentioned above, we introduce a series of
non-local features that capture field n-grams, given
a specific record. For example the record flight in the
air travel domain typically has the values &lt;from to&gt;
(see Figure 2(c)). The integration of fields in sub-
derivations is implemented in fashion similar to the
integration of words.
</bodyText>
<footnote confidence="0.6737615">
Number of Fields per Record This feature family
is a coarser version of the Field bigrams/trigrams
</footnote>
<page confidence="0.99557">
374
</page>
<figure confidence="0.999686233333333">
FS0,3(search1.t,start)
R(search1.t) FS2,6(flight1.t,start)
���
w1,2(search1.t,what)
1
me the
me flights
the flights
���
E
F4,6(flight1.t,to)
FS(flight1.t,start)
R(flight1.t)
w0(search1.t,type)
F2,4(flight1.t,from)
FS4,6(flight1.t,from)
�
� �
show
me
what
���
1
�
� �
 |2 words |
(a)Alignment Features (local) (b)Word Trigrams (non-local) (c)Field Bigrams (non-local)
&lt;R(srch1.t) → FS(fl1.t,st) R(fl1.t)&gt; &lt;show me the&gt;, &lt;show me flights&gt;, etc. &lt;from to&gt;  |flight
(d)Number of Words per Field (local)
&lt;2  |from&gt;
</figure>
<figureCaption confidence="0.999888">
Figure 2: Simplified hypergraph examples with corresponding local and non-local features.
</figureCaption>
<bodyText confidence="0.999956727272727">
feature, which is deemed to be sparse for rarely-seen
records.
Field with No Value Although records in the ATIS
database schema have many fields, only a few are
assigned a value in any given scenario. For exam-
ple, the flight record has 13 fields, of which only 1.7
(on average) have a value. Practically, in a genera-
tive model this kind of sparsity would result in very
low field recall. We thus include an identity feature
function that explicitly counts whether a particular
field has a value.
</bodyText>
<subsectionHeader confidence="0.997215">
4.3 Evaluation
</subsectionHeader>
<bodyText confidence="0.999964555555556">
We evaluated three configurations of our
model. A system that only uses the top scor-
ing derivation in each sub-generation and in-
corporates only the baseline and alignment
features (1-BEST+BASE+ALIGN). Our sec-
ond system considers the k-best derivations
and additionally includes lexical features
(k-BEST+BASE+ALIGN+LEX). The number of
k-best derivations was set to 40 and estimated
experimentally on held-out data. And finally,
our third system includes the full feature set
(k-BEST+BASE+ALIGN+LEX+STR). Note, that
the second and third system incorporate non-local
features, hence the use of k-best derivation lists.5
We compared our model to Angeli et al. (2010)
whose approach is closest to ours.6
We evaluated system output automatically, using
the BLEU-4 modified precision score (Papineni et
</bodyText>
<footnote confidence="0.9946586">
5Since the addition of these features, essentially incurs
reranking, it follows that the systems would exhibit the exact
same performance as the baseline system with 1-best lists.
6We are grateful to Gabor Angeli for providing us with the
code of his system.
</footnote>
<bodyText confidence="0.999702875">
al., 2002) with the human-written text as reference.
We also report results with the METEOR score
(Banerjee and Lavie, 2005), which takes into ac-
count word re-ordering and has been shown to cor-
relate better with human judgments at the sentence
level. In addition, we evaluated the generated text by
eliciting human judgments. Participants were pre-
sented with a scenario and its corresponding verbal-
ization (see Figure 3) and were asked to rate the lat-
ter along two dimensions: fluency (is the text gram-
matical and overall understandable?) and semantic
correctness (does the meaning conveyed by the text
correspond to the database input?). The subjects
used a five point rating scale where a high number
indicates better performance. We randomly selected
12 documents from the test set and generated out-
put with two of our models (1-BEST+BASE+ALIGN
and k-BEST+BASE+ALIGN+LEX+STR) and Angeli
et al.’s (2010) model. We also included the original
text (HUMAN) as a gold standard. We thus obtained
ratings for 48 (12 x 4) scenario-text pairs. The study
was conducted over the Internet, using Amazon Me-
chanical Turk, and was completed by 51 volunteers,
all self reported native English speakers.
</bodyText>
<sectionHeader confidence="0.999821" genericHeader="evaluation">
5 Results
</sectionHeader>
<bodyText confidence="0.9999354">
Table 2 summarizes our results. As can be seen, in-
clusion of lexical features gives our decoder an ab-
solute increase of 6.73% in BLEU over the 1-BEST
system. It also outperforms the discriminative sys-
tem of Angeli et al. (2010). Our lexical features
seem more robust compared to their templates. This
is especially the case with infrequent records, where
their system struggles to learn any meaningful infor-
mation. Addition of the structural features further
boosts performance. Our model increases by 8.69%
</bodyText>
<page confidence="0.996478">
375
</page>
<table confidence="0.995605">
System BLEU METEOR
1-BEST+BASE+ALIGN 21.93 34.01
k-BEST+BASE+ALIGN+LEX 28.66 45.18
k-BEST+BASE+ALIGN+LEX+STR 30.62 46.07
ANGELI 26.77 42.41
</table>
<tableCaption confidence="0.998509">
Table 2: BLEU-4 and METEOR results on ATIS.
</tableCaption>
<bodyText confidence="0.993150818181818">
over the 1-BEST system and 3.85% over ANGELI in
terms of BLEU. We observe a similar trend when
evaluating system output with METEOR. Differ-
ences in magnitude are larger with the latter metric.
The results of our human evaluation study are
shown in Table 5. We carried out an Analysis of
Variance (ANOVA) to examine the effect of system
type (1-BEST, k-BEST, ANGELI, and HUMAN) on
the fluency and semantic correctness ratings. Means
differences were compared using a post-hoc Tukey
test. The k-BEST system is significantly better than
the 1-BEST and ANGELI (a &lt; 0.01) both in terms
of fluency and semantic correctness. ANGELI is
significantly better than 1-BEST with regard to flu-
ency (a &lt; 0.05) but not semantic correctness. There
is no statistically significant difference between the
k-BEST output and the original sentences (HUMAN).
Examples of system output are shown in Table 3.
They broadly convey similar meaning with the gold-
standard; ANGELI exhibits some long-range repeti-
tion, probably due to re-iteration of the same record
patterns. We tackle this issue with the inclusion of
non-local structural features. The 1-BEST system
has some grammaticality issues, which we avoid by
defining features over lexical n-grams and repeated
words. It is worth noting that both our system and
ANGELI produce output that is semantically com-
patible with but lexically different from the gold-
standard (compare please list the flights and show
me the flights against give me the flights). This is
expected given the size of the vocabulary, but raises
concerns regarding the use of automatic metrics for
the evaluation of generation output.
</bodyText>
<sectionHeader confidence="0.999667" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999704666666667">
We presented a discriminative reranking framework
for an end-to-end generation system that performs
both content selection and surface realization. Cen-
tral to our approach is the encoding of generation
as a parsing problem. We reformulate the input (a
set of database records and text describing some of
</bodyText>
<table confidence="0.9959636">
System FluencySemCor
1-BEST+BASE+ALIGN 2.70 3.05
k-BEST+BASE+ALIGN+LEX+STR 4.02 4.04
ANGELI 3.74 3.17
HUMAN 4.18 4.02
</table>
<tableCaption confidence="0.9792875">
Table 3: Mean ratings for fluency and semantic correct-
ness (SemCor) on system output elicited by humans.
</tableCaption>
<figureCaption confidence="0.998989">
Figure 3: Example of scenario input and system output.
</figureCaption>
<bodyText confidence="0.999934571428572">
them) as a PCFG and convert it to a hypergraph. We
find the best scoring derivation via forest reranking
using both local and non-local features, that we train
using the perceptron algorithm. Experimental eval-
uation on the ATIS dataset shows that our model at-
tains significantly higher fluency and semantic cor-
rectness than any of the comparison systems. The
current model can be easily extended to incorporate,
additional, more elaborate features. Likewise, it can
port to other domains with similar database struc-
ture without modification, such as WEATHERGOV
and ROBOCUP. Finally, distributed training strate-
gies have been developed for the perceptron algo-
rithm (McDonald et al., 2010), which would allow
our generator to scale to even larger datasets.
In the future, we would also like to tackle more
challenging domains (e.g., product descriptions) and
to enrich our generator with some notion of dis-
course planning. An interesting question is how to
extend the PCFG-based approach advocated here so
as to capture discourse-level document structure.
</bodyText>
<figure confidence="0.987790083333333">
Flight
from to
phoenix milwaukee
Time
when dep/ar
evening departure
Day
day dep/ar
wednesday departure
Search
type what
query flight
</figure>
<bodyText confidence="0.623309875">
give me the flights from phoenix to milwaukee on
wednesday evening
show me the flights from phoenix to milwaukee on
wednesday evening flights from phoenix to milwaukee
please list the flights from phoenix to milwaukee on
wednesday evening
on wednesday evening from from phoenix to
milwaukee on wednesday evening
</bodyText>
<figure confidence="0.992846">
HUMAN
ANGELI
k-BEST
1-BEST
</figure>
<page confidence="0.996231">
376
</page>
<sectionHeader confidence="0.989583" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999708701923077">
Gabor Angeli, Percy Liang, and Dan Klein. 2010. A
simple domain-independent probabilistic approach to
generation. In Proceedings of the 2010 Conference on
Empirical Methods in Natural Language Processing,
pages 502–512, Cambridge, MA.
Satanjeev Banerjee and Alon Lavie. 2005. METEOR:
An automatic metric for MT evaluation with improved
correlation with human judgments. In Proceedings of
the ACL Workshop on Intrinsic and Extrinsic Evalu-
ation Measures for Machine Translation and/or Sum-
marization, pages 65–72, Ann Arbor, Michigan.
Eugene Charniak and Mark Johnson. 2005. Coarse-to-
fine n-best parsing and maxent discriminative rerank-
ing. In Proceedings of the 43rd Annual Meeting of
the Association for Computational Linguistics, pages
173–180, Ann Arbor, Michigan, June.
David L. Chen and Raymond J. Mooney. 2008. Learn-
ing to sportscast: A test of grounded language acqui-
sition. In Proceedings of International Conference on
Machine Learning, pages 128–135, Helsinki, Finland.
David Chiang. 2007. Hierarchical phrase-based transla-
tion. Computational Linguistics, 33(2):201–228.
Michael Collins. 2000. Discriminative reranking for nat-
ural language parsing. In Proceedings of the 17th In-
ternational Conference on Machine Learning, pages
175–182, Stanford, California.
Michael Collins. 2002. Discriminative training meth-
ods for hidden markov models: Theory and experi-
ments with perceptron algorithms. In Proceedings of
the 2002 Conference on Empirical Methods in Natural
Language Processing, pages 1–8, Philadelphia, Penn-
sylvania.
Deborah A. Dahl, Madeleine Bates, Michael Brown,
William Fisher, Kate Hunicke-Smith, David Pallett,
Christine Pao, Alexander Rudnicky, and Elizabeth
Shriberg. 1994. Expanding the scope of the ATIS
task: the ATIS-3 corpus. In Proceedings of the Work-
shop on Human Language Technology, pages 43–48,
Plainsboro, New Jersey.
Robert Dale, Sabine Geldof, and Jean-Philippe Prost.
2003. Coral: Using natural language generation for
navigational assistance. In Proceedings of the 26th
Australasian Computer Science Conference, pages
35–44, Adelaide, Australia.
Giorgio Gallo, Giustino Longo, Stefano Pallottino, and
Sang Nguyen. 1993. Directed hypergraphs and appli-
cations. Discrete Applied Mathematics, 42:177–201.
Ruifang Ge and Raymond J. Mooney. 2006. Discrimina-
tive reranking for semantic parsing. In Proceedings of
the COLING/ACL 2006 Main Conference Poster Ses-
sions, pages 263–270, Sydney, Australia.
Nancy Green. 2006. Generation of biomedical argu-
ments for lay readers. In Proceedings of the 5th In-
ternational Natural Language Generation Conference,
pages 114–121, Sydney, Australia.
Liang Huang and David Chiang. 2007. Forest rescoring:
Faster decoding with integrated language models. In
Proceedings of the 45th Annual Meeting of the Asso-
ciation of Computational Linguistics, pages 144–151,
Prague, Czech Republic.
Liang Huang. 2008. Forest reranking: Discriminative
parsing with non-local features. In Proceedings of
ACL-08: HLT, pages 586–594, Columbus, Ohio.
Dan Klein and Christopher D. Manning. 2001. Parsing
and hypergraphs. In Proceedings of the 7th Interna-
tional Workshop on Parsing Technologies, pages 123–
134, Beijing, China.
Ioannis Konstas and Mirella Lapata. 2012. Unsuper-
vised concept-to-text generation with hypergraphs. To
appear in Proceedings of the 2012 Conference of the
North American Chapter of the Association for Com-
putational Linguistics: Human Language Technolo-
gies, Montr´eal, Canada.
Zhifei Li and Jason Eisner. 2009. First- and second-order
expectation semirings with applications to minimum-
risk training on translation forests. In Proceedings of
the 2009 Conference on Empirical Methods in Natu-
ral Language Processing, pages 40–51, Suntec, Sin-
gapore.
Zhifei Li and Sanjeev Khudanpur. 2009. Forest rerank-
ing for machine translation with the perceptron algo-
rithm. In GALE Book. GALE.
Percy Liang, Alexandre Bouchard-Cˆot´e, Dan Klein, and
Ben Taskar. 2006. An end-to-end discriminative ap-
proach to machine translation. In Proceedings of the
21st International Conference on Computational Lin-
guistics and the 44th Annual Meeting of the Associ-
ation for Computational Linguistics, pages 761–768,
Sydney, Australia.
Percy Liang, Michael Jordan, and Dan Klein. 2009.
Learning semantic correspondences with less supervi-
sion. In Proceedings of the Joint Conference of the
47th Annual Meeting of the ACL and the 4th Interna-
tional Joint Conference on Natural Language Process-
ing of the AFNLP, pages 91–99, Suntec, Singapore.
Ryan McDonald, Keith Hall, and Gideon Mann. 2010.
Distributed training strategies for the structured per-
ceptron. In Human Language Technologies: The
2010 Annual Conference of the North American Chap-
ter of the Association for Computational Linguistics,
pages 456–464, Los Angeles, CA, June. Association
for Computational Linguistics.
Franz Josef Och. 2003. Minimum error rate training
in statistical machine translation. In Proceedings of
</reference>
<page confidence="0.980494">
377
</page>
<reference confidence="0.9977329">
the 41st Annual Meeting on Association for Computa-
tional Linguistics, pages 160–167, Sapporo, Japan.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a method for automatic eval-
uation of machine translation. In Proceedings of 40th
Annual Meeting of the Association for Computational
Linguistics, pages 311–318, Philadelphia, Pennsylva-
nia.
Adwait Ratnaparkhi. 2002. Trainable approaches to sur-
face natural language generation and their application
to conversational dialog systems. Computer Speech &amp;
Language, 16(3-4):435–455.
Ehud Reiter and Robert Dale. 2000. Building natural
language generation systems. Cambridge University
Press, New York, NY.
Ehud Reiter, Somayajulu Sripada, Jim Hunter, Jin Yu,
and Ian Davy. 2005. Choosing words in computer-
generated weather forecasts. Artificial Intelligence,
167:137–169.
Libin Shen, Anoop Sarkar, and Franz Josef Och. 2004.
Discriminative reranking for machine translation. In
HLT-NAACL 2004: Main Proceedings, pages 177–
184, Boston, Massachusetts.
Ross Turner, Yaji Sripada, and Ehud Reiter. 2009. Gen-
erating approximate geographic descriptions. In Pro-
ceedings of the 12th European Workshop on Natural
Language Generation, pages 42–49, Athens, Greece.
Yuk Wah Wong and Raymond Mooney. 2007. Gener-
ation by inverting a semantic parser that uses statis-
tical machine translation. In Proceedings of the Hu-
man Language Technology and the Conference of the
North American Chapter of the Association for Com-
putational Linguistics, pages 172–179, Rochester, NY.
Luke Zettlemoyer and Michael Collins. 2007. Online
learning of relaxed CCG grammars for parsing to log-
ical form. In Proceedings of the 2007 Joint Confer-
ence on Empirical Methods in Natural Language Pro-
cessing and Computational Natural Language Learn-
ing (EMNLP-CoNLL), pages 678–687, Prague, Czech
Republic.
</reference>
<page confidence="0.998268">
378
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.623734">
<title confidence="0.990658">Concept-to-text Generation via Discriminative Reranking</title>
<author confidence="0.64221">Konstas</author>
<affiliation confidence="0.993859">Institute for Language, Cognition and School of Informatics, University of</affiliation>
<address confidence="0.983494">10 Crichton Street, Edinburgh EH8</address>
<email confidence="0.998101">i.konstas@sms.ed.ac.uk,mlap@inf.ed.ac.uk</email>
<abstract confidence="0.999470454545455">This paper proposes a data-driven method for concept-to-text generation, the task of automatically producing textual output from non-linguistic input. A key insight in our approach is to reduce the tasks of content selection (“what to say”) and surface realization (“how to say”) into a common parsing problem. We define a probabilistic context-free grammar that describes the structure of the input (a corpus of database records and text describing some of them) and represent it compactly as a weighted hypergraph. The hypergraph structure encodes exponentially many derivations, which we rerank discriminatively using local and global features. We propose a novel decoding algorithm for finding the best scoring derivation and generating in this set- Experimental evaluation on the domain shows that our model outperforms a competitive discriminative system both using BLEU and in a judgment elicitation study.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Gabor Angeli</author>
<author>Percy Liang</author>
<author>Dan Klein</author>
</authors>
<title>A simple domain-independent probabilistic approach to generation.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>502--512</pages>
<location>Cambridge, MA.</location>
<contexts>
<context position="5175" citStr="Angeli et al., 2010" startWordPosition="785" endWordPosition="788">antly, in this framework non-local features are computed at all internal hypergraph nodes, allowing the decoder to take advantage of them continuously at all stages of the generation process. We incorporate features that are local with respect to a span of a sub-derivation in the packed forest; we also (approximately) include features that arbitrarily exceed span boundaries, thus capturing more global knowledge. Experimental results on the ATIS domain (Dahl et al., 1994) demonstrate that our model outperforms a baseline based on the best derivation and a stateof-the-art discriminative system (Angeli et al., 2010) by a wide margin. Our contributions in this paper are threefold: we recast concept-to-text generation in a probabilistic parsing framework that allows to jointly optimize content selection and surface realization; we represent parse derivations compactly using hypergraphs and illustrate the use of an algorithm for generating (rather than parsing) in this framework; finally, the application of discriminative reranking to conceptto-text generation is novel to our knowledge and as our experiments show beneficial. 2 Related Work Early discriminative approaches to text generation were introduced i</context>
<context position="6399" citStr="Angeli et al. (2010)" startWordPosition="961" endWordPosition="964">oken dialogue systems, and usually tackled content selection and surface realization separately. Ratnaparkhi (2002) conceptualized surface realization (from a fixed meaning representation) as a classification task. Local and non-local information (e.g., word n-grams, longrange dependencies) was taken into account with the use of features in a maximum entropy probability model. More recently, Wong and Mooney (2007) describe an approach to surface realization based on synchronous context-free grammars. The latter are learned using a log-linear model with minimum error rate training (Och, 2003). Angeli et al. (2010) were the first to propose a unified approach to content selection and surface realization. Their model operates over automatically induced alignments of words to database records (Liang et al., 2009) and decomposes into a sequence of discriminative local decisions. They first determine which records in the database to talk about, then which fields of those records to mention, and finally which words to use to describe the chosen fields. Each of these decisions is implemented as a log-linear model with features learned from training data. Their surface realization component performs decisions </context>
<context position="7742" citStr="Angeli et al. (2010)" startWordPosition="1168" endWordPosition="1171">t output. Discriminative reranking has been employed in many NLP tasks such as syntactic parsing (Charniak and Johnson, 2005; Huang, 2008), machine translation (Shen et al., 2004; Li and Khudanpur, 2009) and semantic parsing (Ge and Mooney, 2006). Our model is closest to Huang (2008) who also performs forest reranking on a hypergraph, using both local and non-local features, whose weights are tuned with the averaged perceptron algorithm (Collins, 2002). We adapt forest reranking to generation and introduce several task-specific features that boost performance. Although conceptually related to Angeli et al. (2010), our model optimizes content selection and surface realization simultaneously, rather than as a sequence. The discriminative aspect of two models is also fundamentally different. We have a single reranking component that applies 370 throughout, whereas they train different discriminative models for each local decision. 3 Problem Formulation We assume our generator takes as input a set of database records d and produces text w that verbalizes some of these records. Each record r ∈ d has a type r.t and a set of fields f associated with it. Fields have different values f.v and types f.t (i.e., i</context>
<context position="27404" citStr="Angeli et al. (2010)" startWordPosition="4407" endWordPosition="4410">odel. A system that only uses the top scoring derivation in each sub-generation and incorporates only the baseline and alignment features (1-BEST+BASE+ALIGN). Our second system considers the k-best derivations and additionally includes lexical features (k-BEST+BASE+ALIGN+LEX). The number of k-best derivations was set to 40 and estimated experimentally on held-out data. And finally, our third system includes the full feature set (k-BEST+BASE+ALIGN+LEX+STR). Note, that the second and third system incorporate non-local features, hence the use of k-best derivation lists.5 We compared our model to Angeli et al. (2010) whose approach is closest to ours.6 We evaluated system output automatically, using the BLEU-4 modified precision score (Papineni et 5Since the addition of these features, essentially incurs reranking, it follows that the systems would exhibit the exact same performance as the baseline system with 1-best lists. 6We are grateful to Gabor Angeli for providing us with the code of his system. al., 2002) with the human-written text as reference. We also report results with the METEOR score (Banerjee and Lavie, 2005), which takes into account word re-ordering and has been shown to correlate better </context>
<context position="29224" citStr="Angeli et al. (2010)" startWordPosition="4702" endWordPosition="4705">ith two of our models (1-BEST+BASE+ALIGN and k-BEST+BASE+ALIGN+LEX+STR) and Angeli et al.’s (2010) model. We also included the original text (HUMAN) as a gold standard. We thus obtained ratings for 48 (12 x 4) scenario-text pairs. The study was conducted over the Internet, using Amazon Mechanical Turk, and was completed by 51 volunteers, all self reported native English speakers. 5 Results Table 2 summarizes our results. As can be seen, inclusion of lexical features gives our decoder an absolute increase of 6.73% in BLEU over the 1-BEST system. It also outperforms the discriminative system of Angeli et al. (2010). Our lexical features seem more robust compared to their templates. This is especially the case with infrequent records, where their system struggles to learn any meaningful information. Addition of the structural features further boosts performance. Our model increases by 8.69% 375 System BLEU METEOR 1-BEST+BASE+ALIGN 21.93 34.01 k-BEST+BASE+ALIGN+LEX 28.66 45.18 k-BEST+BASE+ALIGN+LEX+STR 30.62 46.07 ANGELI 26.77 42.41 Table 2: BLEU-4 and METEOR results on ATIS. over the 1-BEST system and 3.85% over ANGELI in terms of BLEU. We observe a similar trend when evaluating system output with METEOR</context>
</contexts>
<marker>Angeli, Liang, Klein, 2010</marker>
<rawString>Gabor Angeli, Percy Liang, and Dan Klein. 2010. A simple domain-independent probabilistic approach to generation. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 502–512, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Satanjeev Banerjee</author>
<author>Alon Lavie</author>
</authors>
<title>METEOR: An automatic metric for MT evaluation with improved correlation with human judgments.</title>
<date>2005</date>
<booktitle>In Proceedings of the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization,</booktitle>
<pages>65--72</pages>
<location>Ann Arbor, Michigan.</location>
<contexts>
<context position="27921" citStr="Banerjee and Lavie, 2005" startWordPosition="4488" endWordPosition="4491">non-local features, hence the use of k-best derivation lists.5 We compared our model to Angeli et al. (2010) whose approach is closest to ours.6 We evaluated system output automatically, using the BLEU-4 modified precision score (Papineni et 5Since the addition of these features, essentially incurs reranking, it follows that the systems would exhibit the exact same performance as the baseline system with 1-best lists. 6We are grateful to Gabor Angeli for providing us with the code of his system. al., 2002) with the human-written text as reference. We also report results with the METEOR score (Banerjee and Lavie, 2005), which takes into account word re-ordering and has been shown to correlate better with human judgments at the sentence level. In addition, we evaluated the generated text by eliciting human judgments. Participants were presented with a scenario and its corresponding verbalization (see Figure 3) and were asked to rate the latter along two dimensions: fluency (is the text grammatical and overall understandable?) and semantic correctness (does the meaning conveyed by the text correspond to the database input?). The subjects used a five point rating scale where a high number indicates better perf</context>
</contexts>
<marker>Banerjee, Lavie, 2005</marker>
<rawString>Satanjeev Banerjee and Alon Lavie. 2005. METEOR: An automatic metric for MT evaluation with improved correlation with human judgments. In Proceedings of the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization, pages 65–72, Ann Arbor, Michigan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
<author>Mark Johnson</author>
</authors>
<title>Coarse-tofine n-best parsing and maxent discriminative reranking.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>173--180</pages>
<location>Ann Arbor, Michigan,</location>
<contexts>
<context position="7246" citStr="Charniak and Johnson, 2005" startWordPosition="1092" endWordPosition="1096">a sequence of discriminative local decisions. They first determine which records in the database to talk about, then which fields of those records to mention, and finally which words to use to describe the chosen fields. Each of these decisions is implemented as a log-linear model with features learned from training data. Their surface realization component performs decisions based on templates that are automatically extracted and smoothed with domain-specific knowledge in order to guarantee fluent output. Discriminative reranking has been employed in many NLP tasks such as syntactic parsing (Charniak and Johnson, 2005; Huang, 2008), machine translation (Shen et al., 2004; Li and Khudanpur, 2009) and semantic parsing (Ge and Mooney, 2006). Our model is closest to Huang (2008) who also performs forest reranking on a hypergraph, using both local and non-local features, whose weights are tuned with the averaged perceptron algorithm (Collins, 2002). We adapt forest reranking to generation and introduce several task-specific features that boost performance. Although conceptually related to Angeli et al. (2010), our model optimizes content selection and surface realization simultaneously, rather than as a sequenc</context>
</contexts>
<marker>Charniak, Johnson, 2005</marker>
<rawString>Eugene Charniak and Mark Johnson. 2005. Coarse-tofine n-best parsing and maxent discriminative reranking. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics, pages 173–180, Ann Arbor, Michigan, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David L Chen</author>
<author>Raymond J Mooney</author>
</authors>
<title>Learning to sportscast: A test of grounded language acquisition.</title>
<date>2008</date>
<booktitle>In Proceedings of International Conference on Machine Learning,</booktitle>
<pages>128--135</pages>
<location>Helsinki, Finland.</location>
<contexts>
<context position="22454" citStr="Chen and Mooney, 2008" startWordPosition="3647" endWordPosition="3650">rresponding class types (e.g., variable x has class type flight). Next, fields and values are added from predicates with two arguments with the class type of the first argument matching that of the record type. The name of the predicate denotes the field, and the second argument denotes the value. We also defined special record types, such as condition and search. The latter is introduced for every lambda operator and assigned the categorical field what with the value flight which refers to the record type of variable x. Contrary to datasets used in previous generation studies (e.g., ROBOCUP (Chen and Mooney, 2008) and WEATHERGOV (Liang et al., 2009)), ATIS has a much richer vocabulary (927 words); each scenario corresponds to a single sentence (average length is 11.2 words) with 2.65 out of 19 record types mentioned on average. Following Zettlemoyer and Collins (2007), we trained on 4,962 scenarios and tested on ATIS NOV93 which contains 448 examples. 4.2 Features Broadly speaking, we defined two types of features, namely lexical and structural ones. In addition, we used a generatively trained PCFG as a baseline feature and an alignment feature based on the cooccurrence of records (or fields) with word</context>
</contexts>
<marker>Chen, Mooney, 2008</marker>
<rawString>David L. Chen and Raymond J. Mooney. 2008. Learning to sportscast: A test of grounded language acquisition. In Proceedings of International Conference on Machine Learning, pages 128–135, Helsinki, Finland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>Hierarchical phrase-based translation.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>2</issue>
<contexts>
<context position="17778" citStr="Chiang, 2007" startWordPosition="2874" endWordPosition="2875">(F). Note, that in order to estimate the trigram feature at the FS node, we need to carry word information in the derivations of its antecedents, as we go bottom-up.2 Given these two types of features, we can then adapt Huang’s (2008) approximate decoding algorithm to find ( ˆw, ˆh). Essentially, we perform bottomup Viterbi search, visiting the nodes in reverse topological order, and keeping the k-best derivations for each. The score of each derivation is a linear combination of local and non-local features weights. In machine translation, a decoder that implements forest rescoring (Huang and Chiang, 2007) uses the language model as an external criterion of the goodness of sub-translations on account of their grammaticality. Analogously here, non-local features influence the selection of the best combinations, by introducing knowledge that exceeds the confines of the node under consideration and thus depend on the sub-derivations generated so far. (e.g., word trigrams spanning a field node rely on evidence from antecedent nodes that may be arbitrarily deeper than the field’s immediate children). Our treatment of leaf nodes (see rules (8) and (9)) differs from the way these are usually handled i</context>
<context position="23568" citStr="Chiang, 2007" startWordPosition="3819" endWordPosition="3820">aseline feature and an alignment feature based on the cooccurrence of records (or fields) with words. Baseline Feature This is the log score of a generative decoder trained on the PCFG from Table 1. We converted the grammar into a hypergraph, and learned its probability distributions using a dynamic program similar to the inside-outside algorithm (Li and Eisner, 2009). Decoding was performed approx4The resulting dataset and a technical report describing the mapping procedure in detail are available from http://homepages.inf.ed.ac.uk/s0793019/index.php? page=resources imately via cube pruning (Chiang, 2007), by integrating a trigram language model extracted from the training set (see Konstas and Lapata (2012) for details). Intuitively, the feature refers to the overall goodness of a specific derivation, applied locally in every hyperedge. Alignment Features Instances of this feature family refer to the count of each PCFG rule from Table 1. For example, the number of times rule R(search1.t) —* FS(flight1,start)R(flight1.t) is included in a derivation (see Figure 2(a)) Lexical Features These features encourage grammatical coherence and inform lexical selection over and above the limited horizon of</context>
</contexts>
<marker>Chiang, 2007</marker>
<rawString>David Chiang. 2007. Hierarchical phrase-based translation. Computational Linguistics, 33(2):201–228.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Discriminative reranking for natural language parsing.</title>
<date>2000</date>
<booktitle>In Proceedings of the 17th International Conference on Machine Learning,</booktitle>
<pages>175--182</pages>
<location>Stanford, California.</location>
<contexts>
<context position="3290" citStr="Collins, 2000" startWordPosition="496" endWordPosition="497">free grammar (PCFG) that captures the structure of the database and its correspondence to natural language. This grammar represents multiple derivations which we encode compactly using a weighted hypergraph (or packed forest), a data structure that defines a weight for each tree. Following a generative approach, we could first learn the weights of the PCFG by maximising the joint likelihood of the model and then perform generation by finding the best derivation tree in the hypergraph. The performance of this baseline system could be potentially further improved using discriminative reranking (Collins, 2000). Typically, this method first creates a list of n-best candidates from a generative model, and then reranks them with arbitrary features (both local and global) that are either not computable or intractable to compute within the 369 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 369–378, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics Figure 1: Example of non-linguistic input as a structured database and logical form and its corresponding text. We omit record fields that have no value, for the sake of br</context>
</contexts>
<marker>Collins, 2000</marker>
<rawString>Michael Collins. 2000. Discriminative reranking for natural language parsing. In Proceedings of the 17th International Conference on Machine Learning, pages 175–182, Stanford, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms.</title>
<date>2002</date>
<booktitle>In Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1--8</pages>
<location>Philadelphia, Pennsylvania.</location>
<contexts>
<context position="7578" citStr="Collins, 2002" startWordPosition="1146" endWordPosition="1147">ation component performs decisions based on templates that are automatically extracted and smoothed with domain-specific knowledge in order to guarantee fluent output. Discriminative reranking has been employed in many NLP tasks such as syntactic parsing (Charniak and Johnson, 2005; Huang, 2008), machine translation (Shen et al., 2004; Li and Khudanpur, 2009) and semantic parsing (Ge and Mooney, 2006). Our model is closest to Huang (2008) who also performs forest reranking on a hypergraph, using both local and non-local features, whose weights are tuned with the averaged perceptron algorithm (Collins, 2002). We adapt forest reranking to generation and introduce several task-specific features that boost performance. Although conceptually related to Angeli et al. (2010), our model optimizes content selection and surface realization simultaneously, rather than as a sequence. The discriminative aspect of two models is also fundamentally different. We have a single reranking component that applies 370 throughout, whereas they train different discriminative models for each local decision. 3 Problem Formulation We assume our generator takes as input a set of database records d and produces text w that </context>
<context position="15142" citStr="Collins, 2002" startWordPosition="2429" endWordPosition="2430">ithm 1: Averaged Structured Perceptron Input: Training scenarios: (di,w∗,h+i )Ni=1 1 α ← 0 2 fort ← 1...T do 3 for i ← 1...N do 4 ( ˆw,ˆh) = argmaxw,hα·Φ(di,wi,hi) if (w∗ i ,h+ 5 i ) =6 ( ˆwi, ˆhi) then i ,h+ 6 α ← α+Φ(di,w∗ i )−Φ(di, ˆwi, ˆhi) 1 7 returnT ∑T 1 i=1 αit t=1 N ∑N scoring derivation ( ˆw, ˆh) by maximizing over configurations of h: ( ˆw, ˆh) =argmax α·Φ(d,w,h) w,h We define the score of ( ˆw, ˆh) as the dot product between a high dimensional feature representation Φ = (Φ1,...,Φm) and a weight vector α. We estimate the weights α using the averaged structured perceptron algorithm (Collins, 2002), which is well known for its speed and good performance in similar large-parameter NLP tasks (Liang et al., 2006; Huang, 2008). As shown in Algorithm 1, the perceptron makes several passes over the training scenarios, and in each iteration it computes the best scoring ( ˆw, ˆh) among the candidate derivations, given the current weights α. In line 6, the algorithm updates α with the difference (if any) between the feature representations of the best scoring derivation ( ˆw, ˆh) and the the oracle derivation (w∗,h+). Here, wˆ is the estimated text, w∗ the goldstandard text, hˆ is the estimated </context>
</contexts>
<marker>Collins, 2002</marker>
<rawString>Michael Collins. 2002. Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms. In Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing, pages 1–8, Philadelphia, Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Deborah A Dahl</author>
<author>Madeleine Bates</author>
<author>Michael Brown</author>
<author>William Fisher</author>
<author>Kate Hunicke-Smith</author>
<author>David Pallett</author>
<author>Christine Pao</author>
<author>Alexander Rudnicky</author>
<author>Elizabeth Shriberg</author>
</authors>
<title>Expanding the scope of the ATIS task: the ATIS-3 corpus.</title>
<date>1994</date>
<booktitle>In Proceedings of the Workshop on Human Language Technology,</booktitle>
<pages>43--48</pages>
<location>Plainsboro, New Jersey.</location>
<contexts>
<context position="5030" citStr="Dahl et al., 1994" startWordPosition="763" endWordPosition="766">encodes exponentially many derivations, we can explore a much larger hypothesis space than would have been possible with an n-best list. Importantly, in this framework non-local features are computed at all internal hypergraph nodes, allowing the decoder to take advantage of them continuously at all stages of the generation process. We incorporate features that are local with respect to a span of a sub-derivation in the packed forest; we also (approximately) include features that arbitrarily exceed span boundaries, thus capturing more global knowledge. Experimental results on the ATIS domain (Dahl et al., 1994) demonstrate that our model outperforms a baseline based on the best derivation and a stateof-the-art discriminative system (Angeli et al., 2010) by a wide margin. Our contributions in this paper are threefold: we recast concept-to-text generation in a probabilistic parsing framework that allows to jointly optimize content selection and surface realization; we represent parse derivations compactly using hypergraphs and illustrate the use of an algorithm for generating (rather than parsing) in this framework; finally, the application of discriminative reranking to conceptto-text generation is n</context>
<context position="20173" citStr="Dahl et al., 1994" startWordPosition="3276" endWordPosition="3279">erbalizes them. Instead, we approximate it using the existing decoder to find the best latent configuration h+ given the observed words in the training text w*.3 This is similar in spirit to the generative alignment model of Liang et al. (2009). 4 Experimental Design In this section we present our experimental setup for assessing the performance of our model. We give details on our dataset, model parameters and features, the approaches used for comparison, and explain how system output was evaluated. 4.1 Dataset We conducted our experiments on the Air Travel Information System (ATIS) dataset (Dahl et al., 1994) which consists of transcriptions of spontaneous utterances of users interacting with a hypothetical online flight booking system. The dataset was originally created for the development of spoken language systems and is partitioned in individual user turns (e.g., flights from orlando to milwaukee, show flights from orlando to milwaukee leaving after six o’clock) each accompanied with an SQL query to a booking system and the results of this query. These utterances are typically short expressing a specific communicative goal (e.g., a question about the origin of a flight or its time of arrival).</context>
</contexts>
<marker>Dahl, Bates, Brown, Fisher, Hunicke-Smith, Pallett, Pao, Rudnicky, Shriberg, 1994</marker>
<rawString>Deborah A. Dahl, Madeleine Bates, Michael Brown, William Fisher, Kate Hunicke-Smith, David Pallett, Christine Pao, Alexander Rudnicky, and Elizabeth Shriberg. 1994. Expanding the scope of the ATIS task: the ATIS-3 corpus. In Proceedings of the Workshop on Human Language Technology, pages 43–48, Plainsboro, New Jersey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Dale</author>
<author>Sabine Geldof</author>
<author>Jean-Philippe Prost</author>
</authors>
<title>Coral: Using natural language generation for navigational assistance.</title>
<date>2003</date>
<booktitle>In Proceedings of the 26th Australasian Computer Science Conference,</booktitle>
<pages>35--44</pages>
<location>Adelaide, Australia.</location>
<contexts>
<context position="1575" citStr="Dale et al. (2003)" startWordPosition="226" endWordPosition="229">rithm for finding the best scoring derivation and generating in this setting. Experimental evaluation on the ATIS domain shows that our model outperforms a competitive discriminative system both using BLEU and in a judgment elicitation study. 1 Introduction Concept-to-text generation broadly refers to the task of automatically producing textual output from non-linguistic input such as databases of records, logical form, and expert system knowledge bases (Reiter and Dale, 2000). A variety of concept-totext generation systems have been engineered over the years, with considerable success (e.g., Dale et al. (2003), Reiter et al. (2005), Green (2006), Turner et al. (2009)). Unfortunately, it is often difficult to adapt them across different domains as they rely mostly on handcrafted components. In this paper we present a data-driven approach to concept-to-text generation that is domainindependent, conceptually simple, and flexible. Our generator learns from a set of database records and textual descriptions (for some of them). An example from the air travel domain is shown in Figure 1. Here, the records provide a structured representation of the flight details (e.g., departure and arrival time, location</context>
</contexts>
<marker>Dale, Geldof, Prost, 2003</marker>
<rawString>Robert Dale, Sabine Geldof, and Jean-Philippe Prost. 2003. Coral: Using natural language generation for navigational assistance. In Proceedings of the 26th Australasian Computer Science Conference, pages 35–44, Adelaide, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Giorgio Gallo</author>
<author>Giustino Longo</author>
<author>Stefano Pallottino</author>
<author>Sang Nguyen</author>
</authors>
<title>Directed hypergraphs and applications. Discrete Applied Mathematics,</title>
<date>1993</date>
<pages>42--177</pages>
<contexts>
<context position="8876" citStr="Gallo et al., 1993" startWordPosition="1356" endWordPosition="1359"> fields f associated with it. Fields have different values f.v and types f.t (i.e., integer or categorical). For example, in Figure 1, flight is a record type with fields from and to. The values of these fields are denver and Boston and their type is categorical. During training, our algorithm is given a corpus consisting of several scenarios, i.e., database records paired with texts like those shown in Figure 1. The database (and accompanying texts) are next converted into a PCFG whose weights are learned from training data. PCFG derivations are represented as a weighted directed hypergraph (Gallo et al., 1993). The weights on the hyperarcs are defined by a variety of feature functions, which we learn via a discriminative online update algorithm. During testing, we are given a set of database records without the corresponding text. Using the learned feature weights, we compile a hypergraph specific to this test input and decode it approximately (Huang, 2008). The hypergraph representation allows us to decompose the feature functions and compute them piecemeal at each hyperarc (or sub-derivation), rather than at the root node as in conventional n-best list reranking. Note that the algorithm does not </context>
</contexts>
<marker>Gallo, Longo, Pallottino, Nguyen, 1993</marker>
<rawString>Giorgio Gallo, Giustino Longo, Stefano Pallottino, and Sang Nguyen. 1993. Directed hypergraphs and applications. Discrete Applied Mathematics, 42:177–201.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ruifang Ge</author>
<author>Raymond J Mooney</author>
</authors>
<title>Discriminative reranking for semantic parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions,</booktitle>
<pages>263--270</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="7368" citStr="Ge and Mooney, 2006" startWordPosition="1112" endWordPosition="1115">s of those records to mention, and finally which words to use to describe the chosen fields. Each of these decisions is implemented as a log-linear model with features learned from training data. Their surface realization component performs decisions based on templates that are automatically extracted and smoothed with domain-specific knowledge in order to guarantee fluent output. Discriminative reranking has been employed in many NLP tasks such as syntactic parsing (Charniak and Johnson, 2005; Huang, 2008), machine translation (Shen et al., 2004; Li and Khudanpur, 2009) and semantic parsing (Ge and Mooney, 2006). Our model is closest to Huang (2008) who also performs forest reranking on a hypergraph, using both local and non-local features, whose weights are tuned with the averaged perceptron algorithm (Collins, 2002). We adapt forest reranking to generation and introduce several task-specific features that boost performance. Although conceptually related to Angeli et al. (2010), our model optimizes content selection and surface realization simultaneously, rather than as a sequence. The discriminative aspect of two models is also fundamentally different. We have a single reranking component that appl</context>
</contexts>
<marker>Ge, Mooney, 2006</marker>
<rawString>Ruifang Ge and Raymond J. Mooney. 2006. Discriminative reranking for semantic parsing. In Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 263–270, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nancy Green</author>
</authors>
<title>Generation of biomedical arguments for lay readers.</title>
<date>2006</date>
<booktitle>In Proceedings of the 5th International Natural Language Generation Conference,</booktitle>
<pages>114--121</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="1611" citStr="Green (2006)" startWordPosition="234" endWordPosition="235">ion and generating in this setting. Experimental evaluation on the ATIS domain shows that our model outperforms a competitive discriminative system both using BLEU and in a judgment elicitation study. 1 Introduction Concept-to-text generation broadly refers to the task of automatically producing textual output from non-linguistic input such as databases of records, logical form, and expert system knowledge bases (Reiter and Dale, 2000). A variety of concept-totext generation systems have been engineered over the years, with considerable success (e.g., Dale et al. (2003), Reiter et al. (2005), Green (2006), Turner et al. (2009)). Unfortunately, it is often difficult to adapt them across different domains as they rely mostly on handcrafted components. In this paper we present a data-driven approach to concept-to-text generation that is domainindependent, conceptually simple, and flexible. Our generator learns from a set of database records and textual descriptions (for some of them). An example from the air travel domain is shown in Figure 1. Here, the records provide a structured representation of the flight details (e.g., departure and arrival time, location), and the text renders some of this</context>
</contexts>
<marker>Green, 2006</marker>
<rawString>Nancy Green. 2006. Generation of biomedical arguments for lay readers. In Proceedings of the 5th International Natural Language Generation Conference, pages 114–121, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Huang</author>
<author>David Chiang</author>
</authors>
<title>Forest rescoring: Faster decoding with integrated language models.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>144--151</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="17778" citStr="Huang and Chiang, 2007" startWordPosition="2872" endWordPosition="2875">al fields (F). Note, that in order to estimate the trigram feature at the FS node, we need to carry word information in the derivations of its antecedents, as we go bottom-up.2 Given these two types of features, we can then adapt Huang’s (2008) approximate decoding algorithm to find ( ˆw, ˆh). Essentially, we perform bottomup Viterbi search, visiting the nodes in reverse topological order, and keeping the k-best derivations for each. The score of each derivation is a linear combination of local and non-local features weights. In machine translation, a decoder that implements forest rescoring (Huang and Chiang, 2007) uses the language model as an external criterion of the goodness of sub-translations on account of their grammaticality. Analogously here, non-local features influence the selection of the best combinations, by introducing knowledge that exceeds the confines of the node under consideration and thus depend on the sub-derivations generated so far. (e.g., word trigrams spanning a field node rely on evidence from antecedent nodes that may be arbitrarily deeper than the field’s immediate children). Our treatment of leaf nodes (see rules (8) and (9)) differs from the way these are usually handled i</context>
</contexts>
<marker>Huang, Chiang, 2007</marker>
<rawString>Liang Huang and David Chiang. 2007. Forest rescoring: Faster decoding with integrated language models. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 144–151, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Huang</author>
</authors>
<title>Forest reranking: Discriminative parsing with non-local features.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT,</booktitle>
<pages>586--594</pages>
<location>Columbus, Ohio.</location>
<contexts>
<context position="4394" citStr="Huang, 2008" startWordPosition="665" endWordPosition="666">se and logical form and its corresponding text. We omit record fields that have no value, for the sake of brevity. Flight Day Number Month Condition Search from to number dep/ar month dep/ar arg1 arg2 type type what denver boston 9 departure august departure arrival time 1600 &lt; query flight Database: X−expression: ax. f light(x) n f rom(x,denver) nto(x,boston) n day number(x,9) n month(x,august)n Text: less than(arrival time(x),1600) Give me the flights leaving Denver August ninth coming back to Boston before 4pm. baseline system. An appealing alternative is to rerank the hypergraph directly (Huang, 2008). As it compactly encodes exponentially many derivations, we can explore a much larger hypothesis space than would have been possible with an n-best list. Importantly, in this framework non-local features are computed at all internal hypergraph nodes, allowing the decoder to take advantage of them continuously at all stages of the generation process. We incorporate features that are local with respect to a span of a sub-derivation in the packed forest; we also (approximately) include features that arbitrarily exceed span boundaries, thus capturing more global knowledge. Experimental results on</context>
<context position="7260" citStr="Huang, 2008" startWordPosition="1097" endWordPosition="1098"> local decisions. They first determine which records in the database to talk about, then which fields of those records to mention, and finally which words to use to describe the chosen fields. Each of these decisions is implemented as a log-linear model with features learned from training data. Their surface realization component performs decisions based on templates that are automatically extracted and smoothed with domain-specific knowledge in order to guarantee fluent output. Discriminative reranking has been employed in many NLP tasks such as syntactic parsing (Charniak and Johnson, 2005; Huang, 2008), machine translation (Shen et al., 2004; Li and Khudanpur, 2009) and semantic parsing (Ge and Mooney, 2006). Our model is closest to Huang (2008) who also performs forest reranking on a hypergraph, using both local and non-local features, whose weights are tuned with the averaged perceptron algorithm (Collins, 2002). We adapt forest reranking to generation and introduce several task-specific features that boost performance. Although conceptually related to Angeli et al. (2010), our model optimizes content selection and surface realization simultaneously, rather than as a sequence. The discrim</context>
<context position="9230" citStr="Huang, 2008" startWordPosition="1419" endWordPosition="1420">records paired with texts like those shown in Figure 1. The database (and accompanying texts) are next converted into a PCFG whose weights are learned from training data. PCFG derivations are represented as a weighted directed hypergraph (Gallo et al., 1993). The weights on the hyperarcs are defined by a variety of feature functions, which we learn via a discriminative online update algorithm. During testing, we are given a set of database records without the corresponding text. Using the learned feature weights, we compile a hypergraph specific to this test input and decode it approximately (Huang, 2008). The hypergraph representation allows us to decompose the feature functions and compute them piecemeal at each hyperarc (or sub-derivation), rather than at the root node as in conventional n-best list reranking. Note that the algorithm does not separate content selection from surface realization, both subtasks are optimized jointly through the probabilistic parsing formulation. 3.1 Grammar Definition We capture the structure of the database with a number of CFG rewrite rules, in a similar way to how Liang et al. (2009) define Markov chains in their hierarchical model. These rules are purely s</context>
<context position="13865" citStr="Huang, 2008" startWordPosition="2203" endWordPosition="2204">er. Function g(f.v) generates an integer number given the field value, using either of the following six ways (Liang et al., 2009): identical to the field value, rounding up or rounding down to a multiple of 5, rounding off to the closest multiple of 5 and finally adding or subtracting some unexplained noise.1 The weight is a multinomial over the six generation function modes, given the record field f. The CFG in Table 1 will produce many derivations for a given input (i.e., a set of database records) which we represent compactly using a hypergraph or a packed forest (Klein and Manning, 2001; Huang, 2008). Simplified examples of this representation are shown in Figure 2. 3.2 Hypergraph Reranking For our generation task, we are given a set of database records d, and our goal is to find the best corresponding text w. This corresponds to the best grammar derivation among a set of candidate derivations represented implicitly in the hypergraph structure. As shown in Table 1, the mapping from d to w is unknown. Therefore, all the intermediate multinomial distributions, described in the previous section, define a hidden correspondence structure h, between records, fields, and their values. We find th</context>
<context position="15269" citStr="Huang, 2008" startWordPosition="2451" endWordPosition="2452"> ( ˆw,ˆh) = argmaxw,hα·Φ(di,wi,hi) if (w∗ i ,h+ 5 i ) =6 ( ˆwi, ˆhi) then i ,h+ 6 α ← α+Φ(di,w∗ i )−Φ(di, ˆwi, ˆhi) 1 7 returnT ∑T 1 i=1 αit t=1 N ∑N scoring derivation ( ˆw, ˆh) by maximizing over configurations of h: ( ˆw, ˆh) =argmax α·Φ(d,w,h) w,h We define the score of ( ˆw, ˆh) as the dot product between a high dimensional feature representation Φ = (Φ1,...,Φm) and a weight vector α. We estimate the weights α using the averaged structured perceptron algorithm (Collins, 2002), which is well known for its speed and good performance in similar large-parameter NLP tasks (Liang et al., 2006; Huang, 2008). As shown in Algorithm 1, the perceptron makes several passes over the training scenarios, and in each iteration it computes the best scoring ( ˆw, ˆh) among the candidate derivations, given the current weights α. In line 6, the algorithm updates α with the difference (if any) between the feature representations of the best scoring derivation ( ˆw, ˆh) and the the oracle derivation (w∗,h+). Here, wˆ is the estimated text, w∗ the goldstandard text, hˆ is the estimated latent configuration of the model and h+ the oracle latent configuration. The final weight vector α is the average of weight ve</context>
<context position="21031" citStr="Huang (2008)" startWordPosition="3417" endWordPosition="3418">user turns (e.g., flights from orlando to milwaukee, show flights from orlando to milwaukee leaving after six o’clock) each accompanied with an SQL query to a booking system and the results of this query. These utterances are typically short expressing a specific communicative goal (e.g., a question about the origin of a flight or its time of arrival). This inevitably results in small scenarios with a few words that often unambiguously correspond to a single record. To avoid training our model on a somewhat trivial corpus, we used the dataset introduced in Zettlemoyer 3In machine translation, Huang (2008) provides a soft algorithm that finds the forest oracle, i.e., the parse among the reranked candidates with the highest Parseval F-score. However, it still relies on the gold-standard reference translation. 373 and Collins (2007) instead, which combines the utterances of a single user in one scenario and contains 5,426 scenarios in total; each scenario corresponds to a (manually annotated) formal meaning representation (X-expression) and its translation in natural language. Lambda expressions were automatically converted into records, fields and values following the conventions adopted in Lian</context>
</contexts>
<marker>Huang, 2008</marker>
<rawString>Liang Huang. 2008. Forest reranking: Discriminative parsing with non-local features. In Proceedings of ACL-08: HLT, pages 586–594, Columbus, Ohio.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Parsing and hypergraphs.</title>
<date>2001</date>
<booktitle>In Proceedings of the 7th International Workshop on Parsing Technologies,</booktitle>
<pages>123--134</pages>
<location>Beijing, China.</location>
<contexts>
<context position="13851" citStr="Klein and Manning, 2001" startWordPosition="2199" endWordPosition="2202">ields whose type is integer. Function g(f.v) generates an integer number given the field value, using either of the following six ways (Liang et al., 2009): identical to the field value, rounding up or rounding down to a multiple of 5, rounding off to the closest multiple of 5 and finally adding or subtracting some unexplained noise.1 The weight is a multinomial over the six generation function modes, given the record field f. The CFG in Table 1 will produce many derivations for a given input (i.e., a set of database records) which we represent compactly using a hypergraph or a packed forest (Klein and Manning, 2001; Huang, 2008). Simplified examples of this representation are shown in Figure 2. 3.2 Hypergraph Reranking For our generation task, we are given a set of database records d, and our goal is to find the best corresponding text w. This corresponds to the best grammar derivation among a set of candidate derivations represented implicitly in the hypergraph structure. As shown in Table 1, the mapping from d to w is unknown. Therefore, all the intermediate multinomial distributions, described in the previous section, define a hidden correspondence structure h, between records, fields, and their valu</context>
</contexts>
<marker>Klein, Manning, 2001</marker>
<rawString>Dan Klein and Christopher D. Manning. 2001. Parsing and hypergraphs. In Proceedings of the 7th International Workshop on Parsing Technologies, pages 123– 134, Beijing, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ioannis Konstas</author>
<author>Mirella Lapata</author>
</authors>
<title>Unsupervised concept-to-text generation with hypergraphs. To appear in</title>
<date>2012</date>
<booktitle>Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<location>Montr´eal, Canada.</location>
<contexts>
<context position="23672" citStr="Konstas and Lapata (2012)" startWordPosition="3834" endWordPosition="3837">th words. Baseline Feature This is the log score of a generative decoder trained on the PCFG from Table 1. We converted the grammar into a hypergraph, and learned its probability distributions using a dynamic program similar to the inside-outside algorithm (Li and Eisner, 2009). Decoding was performed approx4The resulting dataset and a technical report describing the mapping procedure in detail are available from http://homepages.inf.ed.ac.uk/s0793019/index.php? page=resources imately via cube pruning (Chiang, 2007), by integrating a trigram language model extracted from the training set (see Konstas and Lapata (2012) for details). Intuitively, the feature refers to the overall goodness of a specific derivation, applied locally in every hyperedge. Alignment Features Instances of this feature family refer to the count of each PCFG rule from Table 1. For example, the number of times rule R(search1.t) —* FS(flight1,start)R(flight1.t) is included in a derivation (see Figure 2(a)) Lexical Features These features encourage grammatical coherence and inform lexical selection over and above the limited horizon of the language model captured by Rules (6)–(9). They also tackle anomalies in the generated output, due t</context>
</contexts>
<marker>Konstas, Lapata, 2012</marker>
<rawString>Ioannis Konstas and Mirella Lapata. 2012. Unsupervised concept-to-text generation with hypergraphs. To appear in Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Montr´eal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhifei Li</author>
<author>Jason Eisner</author>
</authors>
<title>First- and second-order expectation semirings with applications to minimumrisk training on translation forests.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>40--51</pages>
<location>Suntec, Singapore.</location>
<contexts>
<context position="23325" citStr="Li and Eisner, 2009" startWordPosition="3788" endWordPosition="3791">s (2007), we trained on 4,962 scenarios and tested on ATIS NOV93 which contains 448 examples. 4.2 Features Broadly speaking, we defined two types of features, namely lexical and structural ones. In addition, we used a generatively trained PCFG as a baseline feature and an alignment feature based on the cooccurrence of records (or fields) with words. Baseline Feature This is the log score of a generative decoder trained on the PCFG from Table 1. We converted the grammar into a hypergraph, and learned its probability distributions using a dynamic program similar to the inside-outside algorithm (Li and Eisner, 2009). Decoding was performed approx4The resulting dataset and a technical report describing the mapping procedure in detail are available from http://homepages.inf.ed.ac.uk/s0793019/index.php? page=resources imately via cube pruning (Chiang, 2007), by integrating a trigram language model extracted from the training set (see Konstas and Lapata (2012) for details). Intuitively, the feature refers to the overall goodness of a specific derivation, applied locally in every hyperedge. Alignment Features Instances of this feature family refer to the count of each PCFG rule from Table 1. For example, the </context>
</contexts>
<marker>Li, Eisner, 2009</marker>
<rawString>Zhifei Li and Jason Eisner. 2009. First- and second-order expectation semirings with applications to minimumrisk training on translation forests. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 40–51, Suntec, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhifei Li</author>
<author>Sanjeev Khudanpur</author>
</authors>
<title>Forest reranking for machine translation with the perceptron algorithm. In</title>
<date>2009</date>
<publisher>GALE Book. GALE.</publisher>
<contexts>
<context position="7325" citStr="Li and Khudanpur, 2009" startWordPosition="1105" endWordPosition="1108">n the database to talk about, then which fields of those records to mention, and finally which words to use to describe the chosen fields. Each of these decisions is implemented as a log-linear model with features learned from training data. Their surface realization component performs decisions based on templates that are automatically extracted and smoothed with domain-specific knowledge in order to guarantee fluent output. Discriminative reranking has been employed in many NLP tasks such as syntactic parsing (Charniak and Johnson, 2005; Huang, 2008), machine translation (Shen et al., 2004; Li and Khudanpur, 2009) and semantic parsing (Ge and Mooney, 2006). Our model is closest to Huang (2008) who also performs forest reranking on a hypergraph, using both local and non-local features, whose weights are tuned with the averaged perceptron algorithm (Collins, 2002). We adapt forest reranking to generation and introduce several task-specific features that boost performance. Although conceptually related to Angeli et al. (2010), our model optimizes content selection and surface realization simultaneously, rather than as a sequence. The discriminative aspect of two models is also fundamentally different. We </context>
</contexts>
<marker>Li, Khudanpur, 2009</marker>
<rawString>Zhifei Li and Sanjeev Khudanpur. 2009. Forest reranking for machine translation with the perceptron algorithm. In GALE Book. GALE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Percy Liang</author>
<author>Alexandre Bouchard-Cˆot´e</author>
<author>Dan Klein</author>
<author>Ben Taskar</author>
</authors>
<title>An end-to-end discriminative approach to machine translation.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and the 44th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>761--768</pages>
<location>Sydney, Australia.</location>
<marker>Liang, Bouchard-Cˆot´e, Klein, Taskar, 2006</marker>
<rawString>Percy Liang, Alexandre Bouchard-Cˆot´e, Dan Klein, and Ben Taskar. 2006. An end-to-end discriminative approach to machine translation. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th Annual Meeting of the Association for Computational Linguistics, pages 761–768, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Percy Liang</author>
<author>Michael Jordan</author>
<author>Dan Klein</author>
</authors>
<title>Learning semantic correspondences with less supervision.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP,</booktitle>
<pages>91--99</pages>
<location>Suntec, Singapore.</location>
<contexts>
<context position="6599" citStr="Liang et al., 2009" startWordPosition="992" endWordPosition="995">ication task. Local and non-local information (e.g., word n-grams, longrange dependencies) was taken into account with the use of features in a maximum entropy probability model. More recently, Wong and Mooney (2007) describe an approach to surface realization based on synchronous context-free grammars. The latter are learned using a log-linear model with minimum error rate training (Och, 2003). Angeli et al. (2010) were the first to propose a unified approach to content selection and surface realization. Their model operates over automatically induced alignments of words to database records (Liang et al., 2009) and decomposes into a sequence of discriminative local decisions. They first determine which records in the database to talk about, then which fields of those records to mention, and finally which words to use to describe the chosen fields. Each of these decisions is implemented as a log-linear model with features learned from training data. Their surface realization component performs decisions based on templates that are automatically extracted and smoothed with domain-specific knowledge in order to guarantee fluent output. Discriminative reranking has been employed in many NLP tasks such a</context>
<context position="9755" citStr="Liang et al. (2009)" startWordPosition="1500" endWordPosition="1503"> we compile a hypergraph specific to this test input and decode it approximately (Huang, 2008). The hypergraph representation allows us to decompose the feature functions and compute them piecemeal at each hyperarc (or sub-derivation), rather than at the root node as in conventional n-best list reranking. Note that the algorithm does not separate content selection from surface realization, both subtasks are optimized jointly through the probabilistic parsing formulation. 3.1 Grammar Definition We capture the structure of the database with a number of CFG rewrite rules, in a similar way to how Liang et al. (2009) define Markov chains in their hierarchical model. These rules are purely syntactic (describing the intuitive relationship between records, records and fields, fields and corresponding words), and could apply to any database with similar structure irrespectively of the semantics of the domain. Our grammar is defined in Table 1 (rules (1)–(9)). Rule weights are governed by an underlying multinomial distribution and are shown in square brack1. S → R(start) [Pr = 1] 2. R(ri.t) → FS(rj,start) R(rj.t) [P(rj.t |ri.t) · λ] 3. R(ri.t) → FS(rj,start) [P(rj.t |ri.t) · λ] 4. FS(r,r.fi) → F(r,r.fj) FS(r,r</context>
<context position="13383" citStr="Liang et al., 2009" startWordPosition="2115" endWordPosition="2118">am probability of the current word given the previous word, the current record, and field. Rules (8) and (9) define the emission of words and integer numbers from W, given a field type and its value. Rule (8) emits a single word from the vocabulary of the training set. Its weight defines a multinomial distribution over all seen words, for every value of field f, given that the field type is categorical or the special null field. Rule (9) is identical but for fields whose type is integer. Function g(f.v) generates an integer number given the field value, using either of the following six ways (Liang et al., 2009): identical to the field value, rounding up or rounding down to a multiple of 5, rounding off to the closest multiple of 5 and finally adding or subtracting some unexplained noise.1 The weight is a multinomial over the six generation function modes, given the record field f. The CFG in Table 1 will produce many derivations for a given input (i.e., a set of database records) which we represent compactly using a hypergraph or a packed forest (Klein and Manning, 2001; Huang, 2008). Simplified examples of this representation are shown in Figure 2. 3.2 Hypergraph Reranking For our generation task, </context>
<context position="19799" citStr="Liang et al. (2009)" startWordPosition="3215" endWordPosition="3218">th texts. 3.4 Oracle Derivation So far we have remained agnostic with respect to the oracle derivation (w�,h+). In other NLP tasks such as syntactic parsing, there is a gold-standard parse, that can be used as the oracle. In our generation setting, such information is not available. We do not have the gold-standard alignment between the database records and the text that verbalizes them. Instead, we approximate it using the existing decoder to find the best latent configuration h+ given the observed words in the training text w*.3 This is similar in spirit to the generative alignment model of Liang et al. (2009). 4 Experimental Design In this section we present our experimental setup for assessing the performance of our model. We give details on our dataset, model parameters and features, the approaches used for comparison, and explain how system output was evaluated. 4.1 Dataset We conducted our experiments on the Air Travel Information System (ATIS) dataset (Dahl et al., 1994) which consists of transcriptions of spontaneous utterances of users interacting with a hypothetical online flight booking system. The dataset was originally created for the development of spoken language systems and is partit</context>
<context position="21646" citStr="Liang et al. (2009)" startWordPosition="3509" endWordPosition="3512">008) provides a soft algorithm that finds the forest oracle, i.e., the parse among the reranked candidates with the highest Parseval F-score. However, it still relies on the gold-standard reference translation. 373 and Collins (2007) instead, which combines the utterances of a single user in one scenario and contains 5,426 scenarios in total; each scenario corresponds to a (manually annotated) formal meaning representation (X-expression) and its translation in natural language. Lambda expressions were automatically converted into records, fields and values following the conventions adopted in Liang et al. (2009).4 Given a lambda expression like the one shown in Figure 1, we first create a record for each variable and constant (e.g., x, 9, august). We then assign record types according to the corresponding class types (e.g., variable x has class type flight). Next, fields and values are added from predicates with two arguments with the class type of the first argument matching that of the record type. The name of the predicate denotes the field, and the second argument denotes the value. We also defined special record types, such as condition and search. The latter is introduced for every lambda opera</context>
</contexts>
<marker>Liang, Jordan, Klein, 2009</marker>
<rawString>Percy Liang, Michael Jordan, and Dan Klein. 2009. Learning semantic correspondences with less supervision. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP, pages 91–99, Suntec, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Keith Hall</author>
<author>Gideon Mann</author>
</authors>
<title>Distributed training strategies for the structured perceptron.</title>
<date>2010</date>
<booktitle>In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>456--464</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Los Angeles, CA,</location>
<contexts>
<context position="32609" citStr="McDonald et al., 2010" startWordPosition="5226" endWordPosition="5229">scoring derivation via forest reranking using both local and non-local features, that we train using the perceptron algorithm. Experimental evaluation on the ATIS dataset shows that our model attains significantly higher fluency and semantic correctness than any of the comparison systems. The current model can be easily extended to incorporate, additional, more elaborate features. Likewise, it can port to other domains with similar database structure without modification, such as WEATHERGOV and ROBOCUP. Finally, distributed training strategies have been developed for the perceptron algorithm (McDonald et al., 2010), which would allow our generator to scale to even larger datasets. In the future, we would also like to tackle more challenging domains (e.g., product descriptions) and to enrich our generator with some notion of discourse planning. An interesting question is how to extend the PCFG-based approach advocated here so as to capture discourse-level document structure. Flight from to phoenix milwaukee Time when dep/ar evening departure Day day dep/ar wednesday departure Search type what query flight give me the flights from phoenix to milwaukee on wednesday evening show me the flights from phoenix </context>
</contexts>
<marker>McDonald, Hall, Mann, 2010</marker>
<rawString>Ryan McDonald, Keith Hall, and Gideon Mann. 2010. Distributed training strategies for the structured perceptron. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 456–464, Los Angeles, CA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>Minimum error rate training in statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>160--167</pages>
<location>Sapporo, Japan.</location>
<contexts>
<context position="6377" citStr="Och, 2003" startWordPosition="959" endWordPosition="960">oduced in spoken dialogue systems, and usually tackled content selection and surface realization separately. Ratnaparkhi (2002) conceptualized surface realization (from a fixed meaning representation) as a classification task. Local and non-local information (e.g., word n-grams, longrange dependencies) was taken into account with the use of features in a maximum entropy probability model. More recently, Wong and Mooney (2007) describe an approach to surface realization based on synchronous context-free grammars. The latter are learned using a log-linear model with minimum error rate training (Och, 2003). Angeli et al. (2010) were the first to propose a unified approach to content selection and surface realization. Their model operates over automatically induced alignments of words to database records (Liang et al., 2009) and decomposes into a sequence of discriminative local decisions. They first determine which records in the database to talk about, then which fields of those records to mention, and finally which words to use to describe the chosen fields. Each of these decisions is implemented as a log-linear model with features learned from training data. Their surface realization compone</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Josef Och. 2003. Minimum error rate training in statistical machine translation. In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics, pages 160–167, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>Bleu: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of 40th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>311--318</pages>
<location>Philadelphia, Pennsylvania.</location>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. Bleu: a method for automatic evaluation of machine translation. In Proceedings of 40th Annual Meeting of the Association for Computational Linguistics, pages 311–318, Philadelphia, Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adwait Ratnaparkhi</author>
</authors>
<title>Trainable approaches to surface natural language generation and their application to conversational dialog systems.</title>
<date>2002</date>
<journal>Computer Speech &amp; Language,</journal>
<pages>16--3</pages>
<contexts>
<context position="5894" citStr="Ratnaparkhi (2002)" startWordPosition="888" endWordPosition="889">n in a probabilistic parsing framework that allows to jointly optimize content selection and surface realization; we represent parse derivations compactly using hypergraphs and illustrate the use of an algorithm for generating (rather than parsing) in this framework; finally, the application of discriminative reranking to conceptto-text generation is novel to our knowledge and as our experiments show beneficial. 2 Related Work Early discriminative approaches to text generation were introduced in spoken dialogue systems, and usually tackled content selection and surface realization separately. Ratnaparkhi (2002) conceptualized surface realization (from a fixed meaning representation) as a classification task. Local and non-local information (e.g., word n-grams, longrange dependencies) was taken into account with the use of features in a maximum entropy probability model. More recently, Wong and Mooney (2007) describe an approach to surface realization based on synchronous context-free grammars. The latter are learned using a log-linear model with minimum error rate training (Och, 2003). Angeli et al. (2010) were the first to propose a unified approach to content selection and surface realization. The</context>
</contexts>
<marker>Ratnaparkhi, 2002</marker>
<rawString>Adwait Ratnaparkhi. 2002. Trainable approaches to surface natural language generation and their application to conversational dialog systems. Computer Speech &amp; Language, 16(3-4):435–455.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ehud Reiter</author>
<author>Robert Dale</author>
</authors>
<title>Building natural language generation systems.</title>
<date>2000</date>
<publisher>Cambridge University Press,</publisher>
<location>New York, NY.</location>
<contexts>
<context position="1438" citStr="Reiter and Dale, 2000" startWordPosition="205" endWordPosition="208">re encodes exponentially many derivations, which we rerank discriminatively using local and global features. We propose a novel decoding algorithm for finding the best scoring derivation and generating in this setting. Experimental evaluation on the ATIS domain shows that our model outperforms a competitive discriminative system both using BLEU and in a judgment elicitation study. 1 Introduction Concept-to-text generation broadly refers to the task of automatically producing textual output from non-linguistic input such as databases of records, logical form, and expert system knowledge bases (Reiter and Dale, 2000). A variety of concept-totext generation systems have been engineered over the years, with considerable success (e.g., Dale et al. (2003), Reiter et al. (2005), Green (2006), Turner et al. (2009)). Unfortunately, it is often difficult to adapt them across different domains as they rely mostly on handcrafted components. In this paper we present a data-driven approach to concept-to-text generation that is domainindependent, conceptually simple, and flexible. Our generator learns from a set of database records and textual descriptions (for some of them). An example from the air travel domain is s</context>
</contexts>
<marker>Reiter, Dale, 2000</marker>
<rawString>Ehud Reiter and Robert Dale. 2000. Building natural language generation systems. Cambridge University Press, New York, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ehud Reiter</author>
<author>Somayajulu Sripada</author>
<author>Jim Hunter</author>
<author>Jin Yu</author>
<author>Ian Davy</author>
</authors>
<title>Choosing words in computergenerated weather forecasts.</title>
<date>2005</date>
<journal>Artificial Intelligence,</journal>
<pages>167--137</pages>
<contexts>
<context position="1597" citStr="Reiter et al. (2005)" startWordPosition="230" endWordPosition="233">e best scoring derivation and generating in this setting. Experimental evaluation on the ATIS domain shows that our model outperforms a competitive discriminative system both using BLEU and in a judgment elicitation study. 1 Introduction Concept-to-text generation broadly refers to the task of automatically producing textual output from non-linguistic input such as databases of records, logical form, and expert system knowledge bases (Reiter and Dale, 2000). A variety of concept-totext generation systems have been engineered over the years, with considerable success (e.g., Dale et al. (2003), Reiter et al. (2005), Green (2006), Turner et al. (2009)). Unfortunately, it is often difficult to adapt them across different domains as they rely mostly on handcrafted components. In this paper we present a data-driven approach to concept-to-text generation that is domainindependent, conceptually simple, and flexible. Our generator learns from a set of database records and textual descriptions (for some of them). An example from the air travel domain is shown in Figure 1. Here, the records provide a structured representation of the flight details (e.g., departure and arrival time, location), and the text render</context>
</contexts>
<marker>Reiter, Sripada, Hunter, Yu, Davy, 2005</marker>
<rawString>Ehud Reiter, Somayajulu Sripada, Jim Hunter, Jin Yu, and Ian Davy. 2005. Choosing words in computergenerated weather forecasts. Artificial Intelligence, 167:137–169.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Libin Shen</author>
<author>Anoop Sarkar</author>
<author>Franz Josef Och</author>
</authors>
<title>Discriminative reranking for machine translation.</title>
<date>2004</date>
<booktitle>In HLT-NAACL 2004: Main Proceedings,</booktitle>
<pages>177--184</pages>
<location>Boston, Massachusetts.</location>
<contexts>
<context position="7300" citStr="Shen et al., 2004" startWordPosition="1101" endWordPosition="1104">ine which records in the database to talk about, then which fields of those records to mention, and finally which words to use to describe the chosen fields. Each of these decisions is implemented as a log-linear model with features learned from training data. Their surface realization component performs decisions based on templates that are automatically extracted and smoothed with domain-specific knowledge in order to guarantee fluent output. Discriminative reranking has been employed in many NLP tasks such as syntactic parsing (Charniak and Johnson, 2005; Huang, 2008), machine translation (Shen et al., 2004; Li and Khudanpur, 2009) and semantic parsing (Ge and Mooney, 2006). Our model is closest to Huang (2008) who also performs forest reranking on a hypergraph, using both local and non-local features, whose weights are tuned with the averaged perceptron algorithm (Collins, 2002). We adapt forest reranking to generation and introduce several task-specific features that boost performance. Although conceptually related to Angeli et al. (2010), our model optimizes content selection and surface realization simultaneously, rather than as a sequence. The discriminative aspect of two models is also fun</context>
</contexts>
<marker>Shen, Sarkar, Och, 2004</marker>
<rawString>Libin Shen, Anoop Sarkar, and Franz Josef Och. 2004. Discriminative reranking for machine translation. In HLT-NAACL 2004: Main Proceedings, pages 177– 184, Boston, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ross Turner</author>
<author>Yaji Sripada</author>
<author>Ehud Reiter</author>
</authors>
<title>Generating approximate geographic descriptions.</title>
<date>2009</date>
<booktitle>In Proceedings of the 12th European Workshop on Natural Language Generation,</booktitle>
<pages>42--49</pages>
<location>Athens, Greece.</location>
<contexts>
<context position="1633" citStr="Turner et al. (2009)" startWordPosition="236" endWordPosition="239">ting in this setting. Experimental evaluation on the ATIS domain shows that our model outperforms a competitive discriminative system both using BLEU and in a judgment elicitation study. 1 Introduction Concept-to-text generation broadly refers to the task of automatically producing textual output from non-linguistic input such as databases of records, logical form, and expert system knowledge bases (Reiter and Dale, 2000). A variety of concept-totext generation systems have been engineered over the years, with considerable success (e.g., Dale et al. (2003), Reiter et al. (2005), Green (2006), Turner et al. (2009)). Unfortunately, it is often difficult to adapt them across different domains as they rely mostly on handcrafted components. In this paper we present a data-driven approach to concept-to-text generation that is domainindependent, conceptually simple, and flexible. Our generator learns from a set of database records and textual descriptions (for some of them). An example from the air travel domain is shown in Figure 1. Here, the records provide a structured representation of the flight details (e.g., departure and arrival time, location), and the text renders some of this information in natura</context>
</contexts>
<marker>Turner, Sripada, Reiter, 2009</marker>
<rawString>Ross Turner, Yaji Sripada, and Ehud Reiter. 2009. Generating approximate geographic descriptions. In Proceedings of the 12th European Workshop on Natural Language Generation, pages 42–49, Athens, Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuk Wah Wong</author>
<author>Raymond Mooney</author>
</authors>
<title>Generation by inverting a semantic parser that uses statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the Human Language Technology and the Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>172--179</pages>
<location>Rochester, NY.</location>
<contexts>
<context position="6196" citStr="Wong and Mooney (2007)" startWordPosition="930" endWordPosition="933">scriminative reranking to conceptto-text generation is novel to our knowledge and as our experiments show beneficial. 2 Related Work Early discriminative approaches to text generation were introduced in spoken dialogue systems, and usually tackled content selection and surface realization separately. Ratnaparkhi (2002) conceptualized surface realization (from a fixed meaning representation) as a classification task. Local and non-local information (e.g., word n-grams, longrange dependencies) was taken into account with the use of features in a maximum entropy probability model. More recently, Wong and Mooney (2007) describe an approach to surface realization based on synchronous context-free grammars. The latter are learned using a log-linear model with minimum error rate training (Och, 2003). Angeli et al. (2010) were the first to propose a unified approach to content selection and surface realization. Their model operates over automatically induced alignments of words to database records (Liang et al., 2009) and decomposes into a sequence of discriminative local decisions. They first determine which records in the database to talk about, then which fields of those records to mention, and finally which</context>
</contexts>
<marker>Wong, Mooney, 2007</marker>
<rawString>Yuk Wah Wong and Raymond Mooney. 2007. Generation by inverting a semantic parser that uses statistical machine translation. In Proceedings of the Human Language Technology and the Conference of the North American Chapter of the Association for Computational Linguistics, pages 172–179, Rochester, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Luke Zettlemoyer</author>
<author>Michael Collins</author>
</authors>
<title>Online learning of relaxed CCG grammars for parsing to logical form.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL),</booktitle>
<pages>678--687</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="22713" citStr="Zettlemoyer and Collins (2007)" startWordPosition="3688" endWordPosition="3691">eld, and the second argument denotes the value. We also defined special record types, such as condition and search. The latter is introduced for every lambda operator and assigned the categorical field what with the value flight which refers to the record type of variable x. Contrary to datasets used in previous generation studies (e.g., ROBOCUP (Chen and Mooney, 2008) and WEATHERGOV (Liang et al., 2009)), ATIS has a much richer vocabulary (927 words); each scenario corresponds to a single sentence (average length is 11.2 words) with 2.65 out of 19 record types mentioned on average. Following Zettlemoyer and Collins (2007), we trained on 4,962 scenarios and tested on ATIS NOV93 which contains 448 examples. 4.2 Features Broadly speaking, we defined two types of features, namely lexical and structural ones. In addition, we used a generatively trained PCFG as a baseline feature and an alignment feature based on the cooccurrence of records (or fields) with words. Baseline Feature This is the log score of a generative decoder trained on the PCFG from Table 1. We converted the grammar into a hypergraph, and learned its probability distributions using a dynamic program similar to the inside-outside algorithm (Li and E</context>
</contexts>
<marker>Zettlemoyer, Collins, 2007</marker>
<rawString>Luke Zettlemoyer and Michael Collins. 2007. Online learning of relaxed CCG grammars for parsing to logical form. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), pages 678–687, Prague, Czech Republic.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>