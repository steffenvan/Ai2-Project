<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000831">
<title confidence="0.9990675">
Blog Categorization Exploiting Domain Dictionary and
Dynamically Estimated Domains of Unknown Words
</title>
<author confidence="0.992753">
Chikara Hashimoto
</author>
<affiliation confidence="0.871279333333333">
Graduate School of Science and Engineering
Yamagata University
Yonezawa-shi, Yamagata, 992-8510, Japan
</affiliation>
<email confidence="0.996899">
ch@yz.yamagata-u.ac.jp
</email>
<author confidence="0.989216">
Sadao Kurohashi
</author>
<affiliation confidence="0.9941675">
Graduate School of Informatics
Kyoto University
</affiliation>
<address confidence="0.567508">
Sakyo-ku, Kyoto, 606-8501, Japan
</address>
<email confidence="0.998624">
kuro@i.kyoto-u.ac.jp
</email>
<sectionHeader confidence="0.995642" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999925">
This paper presents an approach to text cate-
gorization that i) uses no machine learning and
ii) reacts on-the-fly to unknown words. These
features are important for categorizing Blog
articles, which are updated on a daily basis
and filled with newly coined words. We cat-
egorize 600 Blog articles into 12 domains. As
a result, our categorization method achieved
an accuracy of 94.0% (564/600).
</bodyText>
<sectionHeader confidence="0.9988" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999113571428571">
This paper presents a simple but high-performance
method for text categorization. The method assigns
domain tags to words in an article, and categorizes
the article as the most dominant domain. In this
study, the 12 domains in Table 1 are used follow-
ing (Hashimoto and Kurohashi, 2007) (H&amp;K here-
after)&apos;. Fundamental words are assigned with a do-
</bodyText>
<tableCaption confidence="0.983782">
Table 1: Domains Assumed in H&amp;K
</tableCaption>
<sectionHeader confidence="0.99221025" genericHeader="introduction">
CULTURE LIVING SCIENCE
RECREATION DIET BUSINESS
SPORTS TRANSPORTATION MEDIA
HEALTH EDUCATION GOVERNMENT
</sectionHeader>
<bodyText confidence="0.935015857142857">
main tag by H&amp;K’s domain dictionary, while the
domains of non-fundamental words (i.e. unknown
words) are dynamically estimated, which makes the
method different from previous ones. Another hall-
mark of the method is that it requires no machine
&apos;In addition, NODOMAIN is prepared for words belonging to
no particular domain like blue or people.
</bodyText>
<page confidence="0.994749">
69
</page>
<bodyText confidence="0.985926">
learning. All you need is the domain dictionary and
the access to the Web.
</bodyText>
<sectionHeader confidence="0.982186" genericHeader="method">
2 The Domain Dictionary
</sectionHeader>
<bodyText confidence="0.9997005">
H&amp;K constructed a domain dictionary, where about
30,000 Japanese fundamental content words (JFWs)
are associated with appropriate domains. For exam-
ple, homer is associated with SPORTS.
</bodyText>
<subsectionHeader confidence="0.940091">
2.1 Construction Process
</subsectionHeader>
<bodyText confidence="0.98051305882353">
1 Preparing Keywords for each Domain About
20 keywords for each domain were collected manu-
ally from words that appear frequently in the Web.
They represent the contents of domains.
2 Associating JFWs with Domains A JFW is
associated with a domain of the highest Ad score.
An Ad score of domain is calculated by summing
up the top five Ak scores of the domain. Then,
an Ak score, which is defined between a JFW and
a keyword of a domain, is a measure that shows
how strongly the JFW and the keyword are related.
H&amp;K adopt the x2 statistics to calculate an Ak score
and use web pages as a corpus. The number of
co-occurrences is approximated by the number of
search engine hits when the two words are used as
queries. Ak score between a JFW (jw) and a key-
word (kw) is given as below.
</bodyText>
<equation confidence="0.974752333333333">
n(ad − bc)2
Ak(jw, kw) = (1)
(a + b)(c + d)(a + c)(b + d)
</equation>
<bodyText confidence="0.6197">
where n is the total number of Japanese web pages,
</bodyText>
<equation confidence="0.792602666666667">
a = hits(jw &amp; kw), b = hits(jw) − a,
c = hits(kw) − a, d = n − (a + b + c).
Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pages 69–72,
</equation>
<page confidence="0.474415">
Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics
</page>
<bodyText confidence="0.959041666666667">
Note that hits(q) represents the number of search
engine hits when q is used as a query.
3 Manual Correction Manual correction of the
automatic association2 is done to complete the dic-
tionary. Since the accuracy of 2 is 81.3%, manual
correction is not time-consuming.
</bodyText>
<subsectionHeader confidence="0.997739">
2.2 Distinctive Features
</subsectionHeader>
<bodyText confidence="0.999840142857143">
H&amp;K’s method is independent of what domains to
assume. You can create your own dictionary. All
you need is prepare keywords of your own domains.
After that, the same construction process is applied.
Also note that H&amp;K’s method requires no text col-
lection that is typically used for machine learning
techniques. All you need is the access to the Web.
</bodyText>
<sectionHeader confidence="0.98978" genericHeader="method">
3 Blog Categorization
</sectionHeader>
<bodyText confidence="0.924360181818182">
The categorization proceeds as follows: 1 Extract
words from an article, 2 Assign domains and IDFs
to the words, 3 Sum up IDFs for each domain, 4
Categorize the article as the domain of the highest
IDF.3 As for 2, the IDF is calculated as follows:4
IDF (w) lo Total # of Japanese web pages 2
( ) 9 # of hits of w ( )
Fundamental words are assigned with their do-
mains and IDFs by the domain dictionary, while
those for unknown words are dynamically estimated
by the method described in §4.
</bodyText>
<sectionHeader confidence="0.97335" genericHeader="method">
4 Domain Estimation of Unknown Words
</sectionHeader>
<bodyText confidence="0.999982">
The domain (and IDF) of unknown word is dynam-
ically estimated exploiting the Web. More specifi-
cally, we use Wikipedia and Snippets of Web search,
in addition to the domain dictionary. The estimation
proceeds as follows (Figure 1): 1 Search the Web
with an unknown word, acquire the top 100 records,
and calculate the IDF. 2 Get the Wikipedia article
about the word from the search result if any, estimate
the domain of the word with the Wikipedia-strict
module (§4.1), and exit. 3 When no Wikipedia arti-
cle about the word is found, then get any Wikipedia
</bodyText>
<footnote confidence="0.9939628">
2In H&amp;K’s method, reassociating JFWs with NODOMAIN is
required before 3 . We omit that due to the space limitation.
3If the domain of the highest IDF is NODOMAIN, the article
is categorized as the second highest domain.
4We used 10,000,000,000 as the total number.
</footnote>
<figure confidence="0.908079">
Unknown Word
Search Result: 100 records
Remove Corporate Snippets in the Result
Yes
Snippets
No
Yes
Components
No
Failure Domain and IDF
</figure>
<figureCaption confidence="0.999966">
Figure 1: Domain Estimation Process
</figureCaption>
<bodyText confidence="0.999984416666667">
article in the top 30 of the search result if any, es-
timate the domain with the Wikipedia-loose module
(§4.1), and exit. 4 If no Wikipedia article is found
in the top 30 of the search result, then remove all
corporate snippets. 5 Estimate the domain with the
Snippets module (§4.2) if any snippet is left in the
search result, and exit. 6 If no snippet is left but the
unknown word is a compound word containing fun-
damental words, then estimate the domain with the
Components module (§4.3), and exit. 7 If no snip-
pet is left and the word does not contain fundamental
words, then the estimation is a failure.
</bodyText>
<subsectionHeader confidence="0.876789">
4.1 Wikipedia(-strict-loose) Module
</subsectionHeader>
<bodyText confidence="0.9998545">
The two Wikipedia modules take the following pro-
cedure: 1 Extract only fundamental words from the
Wikipedia article. 2 Assign domains and IDFs to
the words using the domain dictionary. 3 Sum up
IDFs for each domain. 4 Assign the domain of the
highest IDF to the unknown word. If the domain
is NODOMAIN, the second highest domain is chosen
for the unknown word under the condition below:
</bodyText>
<figure confidence="0.939827285714286">
Web Search &amp; IDF Calculation
Is There the Wikipedia
Article about the Word in
the Search Result?
Yes
Wikipedia
-strict
No
Is There Any Wikipedia
Article in the Top 30 in
the Search Result?
Yes
Wikipedia
-loose
No
Is There Any Snippet Left
in the Search Result?
Does the Input Contain
Fundamental Words?
70
Second-highest-IDF/ NODOMAIN’s-IDF&gt;0.15
</figure>
<subsectionHeader confidence="0.919712">
4.2 Snippets Module
</subsectionHeader>
<bodyText confidence="0.9999106">
The Snippets module takes as input the snippets that
are left in the search result after removing those
of corporate web sites. We remove snippets in
which corporate keywords like sales appear more
than once. The keywords were collected from the
analysis of our preliminary experiments. Remov-
ing corporate snippets is indispensable because they
bias the estimation toward BUSINESS. This module
is the same as the Wikipedia modules except that it
extracts fundamental words from residual snippets.
</bodyText>
<subsectionHeader confidence="0.992319">
4.3 Components Module
</subsectionHeader>
<bodyText confidence="0.99998425">
This is basically the same as the others except that it
extracts fundamental words from the unknown word
itself. For example, the domain of finance market is
estimated from the domains of finance and market.
</bodyText>
<sectionHeader confidence="0.999434" genericHeader="evaluation">
5 Evaluation
</sectionHeader>
<subsectionHeader confidence="0.989735">
5.1 Experimental Condition
</subsectionHeader>
<bodyText confidence="0.999968947368421">
Data We categorized 600 Blog articles from Ya-
hoo! Blog (blogs.yahoo.co.jp) into the 12 do-
mains (50 articles for each domain). In Yahoo! Blog,
articles are manually classified into Yahoo! Blog cat-
egories (^- domains) by authors of the articles.
Evaluation Method We measured the accuracy of
categorization and the domain estimation. In cate-
gorization, we tried three kinds of words to be ex-
tracted from articles: fundamental words (F only in
Table 3), fundamental and simplex unknown words
(i.e. no compound word) (F+SU), and fundamen-
tal and all unknown words (both simplex and com-
pound, F+AU). Also, we measured the accuracy of
N best outputs (Top N). During the categorization,
about 12,000 unknown words were found in the 600
articles. Then, we sampled 500 estimation results
from them. Table 2 shows the breakdown of the 500
unknown words in terms of their correct domains.
The other 167 words belong to NODOMAIN.
</bodyText>
<subsectionHeader confidence="0.999495">
5.2 Result of Blog Categorization
</subsectionHeader>
<bodyText confidence="0.99318725">
Table 3 shows the accuracy of categorization. The
F only column indicates that a rather simple method
like the one in §3 works well, if fundamental words
are given good clues for categorization: the domain
</bodyText>
<tableCaption confidence="0.995482">
Table 2: Breakdown of Unknown Words
</tableCaption>
<table confidence="0.99742025">
CULT 42 LIVI 19 SCIE 38
RECR 15 DIET 19 BUSI 32
SPOR 27 TRAN 28 MEDI 23
HEAL 22 EDUC 24 GOVE 44
</table>
<tableCaption confidence="0.997123">
Table 3: Accuracy of Blog Categorization
</tableCaption>
<table confidence="0.9990275">
Top N F only F+SU F+AU
0.89 0.91 0.94
0.96 0.97 0.98
0.98 0.98 0.99
</table>
<bodyText confidence="0.999747166666667">
in our case. This is consistent with Kornai et al.
(2003), who claim that only positive evidence mat-
ter in categorization. Also, F+SU slightly outper-
formed F only, and F+AU outperformed the others.
This shows that the domain estimation of unknown
words moderately improves Blog categorization.
Errors are mostly due to the system’s incorrect fo-
cus on topics of secondary importance. For exam-
ple, in an article on a sightseeing trip, which should
be RECREATION, the author frequently mentions the
means of transportation. As a result, the article was
wrongly categorized as TRAFFIC.
</bodyText>
<subsectionHeader confidence="0.999417">
5.3 Result of Domain Estimation
</subsectionHeader>
<bodyText confidence="0.9992225">
The accuracy of the domain estimation of unknown
words was 77.2% (386/500). Table 4 shows the fre-
quency in use and accuracy for each domain esti-
mation module.5 The Snippets module was used
</bodyText>
<tableCaption confidence="0.985765">
Table 4: Frequency and Accuracy for each Module
</tableCaption>
<table confidence="0.874993333333333">
Frequency Accuracy
Wiki-s 0.146 (73/500) 0.85 (62/73)
Wiki-l 0.208 (104/500) 0.70 (73/104)
Snippt 0.614 (307/500) 0.76 (238/307)
Cmpnt 0.028 (14/500) 0.64 (9/14)
Failure 0.004 (2/500) ——
</table>
<bodyText confidence="0.7601404">
most frequently and achieved the reasonably good
accuracy of 76%. Though the Wikipedia-strict mod-
ule showed the best performance, it was used not
SWiki-s, Wiki-l, Snippt and Cmpnt stand for Wikipedia-
strict, Wikipedia-loose, Snippets and Components, respectively.
</bodyText>
<page confidence="0.997971">
71
</page>
<bodyText confidence="0.998897866666667">
so often. However, we expect that as the number
of Wikipedia articles increases, the best performing
module will be used more frequently.
An example of newly coined words whose do-
mains were estimated correctly is , which
is the abbreviation of day-trade.
It was correctly assigned with BUSINESS by the
Wikipedia-loose module.
Errors were mostly due to the subtle boundary be-
tween NODOMAIN and the other particular domains.
For instance, person’s names that are common and
popular should be NODOMAIN. But in most cases
they were associated with some particular domain.
This is due to the fact that virtually any person’s
name is linked to some particular domain in the Web.
</bodyText>
<sectionHeader confidence="0.999978" genericHeader="related work">
6 Related Work
</sectionHeader>
<bodyText confidence="0.999893151515152">
Previous text categorization methods like Joachims
(1999) and Schapire and Singer (2000) are mostly
based on machine learning. Those methods need
huge quantities of training data, which is hard to ob-
tain. Though there has been a growing interest in
semi-supervised learning (Abney, 2007), it is in an
early phase of development.
In contrast, our method requires no training data.
All you need is a manageable amount of fundamen-
tal words with domains. Also note that our method
is NOT tailored to the 12 domains. If you want
your own domains to categorize, it is only neces-
sary to construct your own dictionary, which is also
domain-independent and not time-consuming.
In fact, there have been other proposals without
the burden of preparing training data. Liu et al.
(2004) prepare representative words for each class,
by which they collect initial training data to build
classifier. Ko and Seo (2004) automatically collect
training data using a large amount of unlabeled data
and a small amount of seed information. However,
the novelty of this study is the on-the-fly estimation
of unknown words’ domains. This feature is very
useful for categorizing Blog articles that are updated
on a daily basis and filled with newly coined words.
Domain information has been used for many NLP
tasks. Magnini et al. (2002) show the effectiveness
of domain information for WSD. Piao et al. (2003)
use domain tags to extract MWEs.
Previous domain resources include WordNet
(Fellbaum, 1998) and HowNet (Dong and Dong,
2006), among others. H&amp;K’s dictionary is the first
fully available domain resource for Japanese.
</bodyText>
<sectionHeader confidence="0.996742" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999990333333333">
This paper presented a text categorization method
that exploits H&amp;K’s domain dictionary and the dy-
namic domain estimation of unknown words. In the
Blog categorization, the method achieved the accu-
racy of 94%, and the domain estimation of unknown
words achieved the accuracy of 77%.
</bodyText>
<sectionHeader confidence="0.999441" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999940736842105">
Steven Abney. 2007. Semisupervised Learning for Com-
putational Linguistics. Chapman &amp; Hall.
Zhendong Dong and Qiang Dong. 2006. HowNet and
the Computation ofMeaning. World Scientific Pub Co
Inc.
Christiane Fellbaum. 1998. WordNet: An Electronic
Lexical Database. MIT Press.
Chikara Hashimoto and Sadao Kurohashi. 2007. Con-
struction of Domain Dictionary for Fundamental Vo-
cabulary. In ACL ’07 Poster, pages 137–140.
Thorsten Joachims. 1999. Transductive Inference for
Text Classification using Support Vector Machines. In
Proceedings of the Sixteenth International Conference
on Machine Learning, pages 200–209.
Youngjoong Ko and Jungyun Seo. 2004. Learning with
Unlabeled Data for Text Categorization Using Boot-
strapping and Feature Projection Techniques. In ACL
’04, pages 255–262.
Andr´as Kornai, Marc Krellenstein, Michael Mulligan,
David Twomey, Fruzsina Veress, and Alec Wysoker.
2003. Classifying the Hungarian web. In EACL ’03,
pages 203–210.
Bing Liu, Xiaoli Li, Wee Sun Lee, , and Philip Yu. 2004.
Text Classification by Labeling Words. In AAAI-2004,
pages 425–430.
Bernardo Magnini, Carlo Strapparava, Giovanni Pezzulo,
and Alfio Gliozzo. 2002. The Role of Domain Infor-
mation in Word Sense Disambiguation. Natural Lan-
guage Engineering, special issue on Word Sense Dis-
ambiguation, 8(3):359–373.
Scott S. L. Piao, Paul Rayson, Dawn Archer, Andrew
Wilson, and Tony McEnery. 2003. Extracting multi-
word expressions with a semantic tagger. In Proceed-
ings of the ACL 2003 workshop on Multiword expres-
sions, pages 49–56.
Robert E. Schapire and Yoram Singer. 2000. BoosTex-
ter: A Boosting-based System for Text Categorization.
Machine Learning, 39(2/3):135–168.
</reference>
<page confidence="0.998725">
72
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.561988">
<title confidence="0.997638">Blog Categorization Exploiting Domain Dictionary and Dynamically Estimated Domains of Unknown Words</title>
<author confidence="0.980164">Chikara Hashimoto</author>
<affiliation confidence="0.9969525">Graduate School of Science and Engineering Yamagata University</affiliation>
<address confidence="0.999375">Yonezawa-shi, Yamagata, 992-8510, Japan</address>
<email confidence="0.976326">ch@yz.yamagata-u.ac.jp</email>
<author confidence="0.722838">Sadao Kurohashi</author>
<affiliation confidence="0.9998215">Graduate School of Informatics Kyoto University</affiliation>
<address confidence="0.996173">Sakyo-ku, Kyoto, 606-8501, Japan</address>
<email confidence="0.98774">kuro@i.kyoto-u.ac.jp</email>
<abstract confidence="0.9830206">This paper presents an approach to text catethat no machine learning and on-the-fly to unknown words. These features are important for categorizing Blog articles, which are updated on a daily basis and filled with newly coined words. We categorize 600 Blog articles into 12 domains. As a result, our categorization method achieved an accuracy of 94.0% (564/600).</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Steven Abney</author>
</authors>
<title>Semisupervised Learning for Computational Linguistics.</title>
<date>2007</date>
<publisher>Chapman &amp; Hall.</publisher>
<contexts>
<context position="11061" citStr="Abney, 2007" startWordPosition="1846" endWordPosition="1847">boundary between NODOMAIN and the other particular domains. For instance, person’s names that are common and popular should be NODOMAIN. But in most cases they were associated with some particular domain. This is due to the fact that virtually any person’s name is linked to some particular domain in the Web. 6 Related Work Previous text categorization methods like Joachims (1999) and Schapire and Singer (2000) are mostly based on machine learning. Those methods need huge quantities of training data, which is hard to obtain. Though there has been a growing interest in semi-supervised learning (Abney, 2007), it is in an early phase of development. In contrast, our method requires no training data. All you need is a manageable amount of fundamental words with domains. Also note that our method is NOT tailored to the 12 domains. If you want your own domains to categorize, it is only necessary to construct your own dictionary, which is also domain-independent and not time-consuming. In fact, there have been other proposals without the burden of preparing training data. Liu et al. (2004) prepare representative words for each class, by which they collect initial training data to build classifier. Ko </context>
</contexts>
<marker>Abney, 2007</marker>
<rawString>Steven Abney. 2007. Semisupervised Learning for Computational Linguistics. Chapman &amp; Hall.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhendong Dong</author>
<author>Qiang Dong</author>
</authors>
<title>HowNet and the Computation ofMeaning. World Scientific Pub Co Inc.</title>
<date>2006</date>
<marker>Dong, Dong, 2006</marker>
<rawString>Zhendong Dong and Qiang Dong. 2006. HowNet and the Computation ofMeaning. World Scientific Pub Co Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christiane Fellbaum</author>
</authors>
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<publisher>MIT Press.</publisher>
<marker>Fellbaum, 1998</marker>
<rawString>Christiane Fellbaum. 1998. WordNet: An Electronic Lexical Database. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chikara Hashimoto</author>
<author>Sadao Kurohashi</author>
</authors>
<title>Construction of Domain Dictionary for Fundamental Vocabulary.</title>
<date>2007</date>
<booktitle>In ACL ’07 Poster,</booktitle>
<pages>137--140</pages>
<contexts>
<context position="1064" citStr="Hashimoto and Kurohashi, 2007" startWordPosition="150" endWordPosition="153">uses no machine learning and ii) reacts on-the-fly to unknown words. These features are important for categorizing Blog articles, which are updated on a daily basis and filled with newly coined words. We categorize 600 Blog articles into 12 domains. As a result, our categorization method achieved an accuracy of 94.0% (564/600). 1 Introduction This paper presents a simple but high-performance method for text categorization. The method assigns domain tags to words in an article, and categorizes the article as the most dominant domain. In this study, the 12 domains in Table 1 are used following (Hashimoto and Kurohashi, 2007) (H&amp;K hereafter)&apos;. Fundamental words are assigned with a doTable 1: Domains Assumed in H&amp;K CULTURE LIVING SCIENCE RECREATION DIET BUSINESS SPORTS TRANSPORTATION MEDIA HEALTH EDUCATION GOVERNMENT main tag by H&amp;K’s domain dictionary, while the domains of non-fundamental words (i.e. unknown words) are dynamically estimated, which makes the method different from previous ones. Another hallmark of the method is that it requires no machine &apos;In addition, NODOMAIN is prepared for words belonging to no particular domain like blue or people. 69 learning. All you need is the domain dictionary and the acc</context>
</contexts>
<marker>Hashimoto, Kurohashi, 2007</marker>
<rawString>Chikara Hashimoto and Sadao Kurohashi. 2007. Construction of Domain Dictionary for Fundamental Vocabulary. In ACL ’07 Poster, pages 137–140.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
</authors>
<title>Transductive Inference for Text Classification using Support Vector Machines.</title>
<date>1999</date>
<booktitle>In Proceedings of the Sixteenth International Conference on Machine Learning,</booktitle>
<pages>200--209</pages>
<contexts>
<context position="10831" citStr="Joachims (1999)" startWordPosition="1809" endWordPosition="1810">uently. An example of newly coined words whose domains were estimated correctly is , which is the abbreviation of day-trade. It was correctly assigned with BUSINESS by the Wikipedia-loose module. Errors were mostly due to the subtle boundary between NODOMAIN and the other particular domains. For instance, person’s names that are common and popular should be NODOMAIN. But in most cases they were associated with some particular domain. This is due to the fact that virtually any person’s name is linked to some particular domain in the Web. 6 Related Work Previous text categorization methods like Joachims (1999) and Schapire and Singer (2000) are mostly based on machine learning. Those methods need huge quantities of training data, which is hard to obtain. Though there has been a growing interest in semi-supervised learning (Abney, 2007), it is in an early phase of development. In contrast, our method requires no training data. All you need is a manageable amount of fundamental words with domains. Also note that our method is NOT tailored to the 12 domains. If you want your own domains to categorize, it is only necessary to construct your own dictionary, which is also domain-independent and not time-</context>
</contexts>
<marker>Joachims, 1999</marker>
<rawString>Thorsten Joachims. 1999. Transductive Inference for Text Classification using Support Vector Machines. In Proceedings of the Sixteenth International Conference on Machine Learning, pages 200–209.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Youngjoong Ko</author>
<author>Jungyun Seo</author>
</authors>
<title>Learning with Unlabeled Data for Text Categorization Using Bootstrapping and Feature Projection Techniques.</title>
<date>2004</date>
<booktitle>In ACL ’04,</booktitle>
<pages>255--262</pages>
<contexts>
<context position="11675" citStr="Ko and Seo (2004)" startWordPosition="1948" endWordPosition="1951">07), it is in an early phase of development. In contrast, our method requires no training data. All you need is a manageable amount of fundamental words with domains. Also note that our method is NOT tailored to the 12 domains. If you want your own domains to categorize, it is only necessary to construct your own dictionary, which is also domain-independent and not time-consuming. In fact, there have been other proposals without the burden of preparing training data. Liu et al. (2004) prepare representative words for each class, by which they collect initial training data to build classifier. Ko and Seo (2004) automatically collect training data using a large amount of unlabeled data and a small amount of seed information. However, the novelty of this study is the on-the-fly estimation of unknown words’ domains. This feature is very useful for categorizing Blog articles that are updated on a daily basis and filled with newly coined words. Domain information has been used for many NLP tasks. Magnini et al. (2002) show the effectiveness of domain information for WSD. Piao et al. (2003) use domain tags to extract MWEs. Previous domain resources include WordNet (Fellbaum, 1998) and HowNet (Dong and Don</context>
</contexts>
<marker>Ko, Seo, 2004</marker>
<rawString>Youngjoong Ko and Jungyun Seo. 2004. Learning with Unlabeled Data for Text Categorization Using Bootstrapping and Feature Projection Techniques. In ACL ’04, pages 255–262.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andr´as Kornai</author>
<author>Marc Krellenstein</author>
<author>Michael Mulligan</author>
<author>David Twomey</author>
<author>Fruzsina Veress</author>
<author>Alec Wysoker</author>
</authors>
<title>Classifying the Hungarian web. In</title>
<date>2003</date>
<booktitle>EACL ’03,</booktitle>
<pages>203--210</pages>
<contexts>
<context position="8839" citStr="Kornai et al. (2003)" startWordPosition="1494" endWordPosition="1497"> words in terms of their correct domains. The other 167 words belong to NODOMAIN. 5.2 Result of Blog Categorization Table 3 shows the accuracy of categorization. The F only column indicates that a rather simple method like the one in §3 works well, if fundamental words are given good clues for categorization: the domain Table 2: Breakdown of Unknown Words CULT 42 LIVI 19 SCIE 38 RECR 15 DIET 19 BUSI 32 SPOR 27 TRAN 28 MEDI 23 HEAL 22 EDUC 24 GOVE 44 Table 3: Accuracy of Blog Categorization Top N F only F+SU F+AU 0.89 0.91 0.94 0.96 0.97 0.98 0.98 0.98 0.99 in our case. This is consistent with Kornai et al. (2003), who claim that only positive evidence matter in categorization. Also, F+SU slightly outperformed F only, and F+AU outperformed the others. This shows that the domain estimation of unknown words moderately improves Blog categorization. Errors are mostly due to the system’s incorrect focus on topics of secondary importance. For example, in an article on a sightseeing trip, which should be RECREATION, the author frequently mentions the means of transportation. As a result, the article was wrongly categorized as TRAFFIC. 5.3 Result of Domain Estimation The accuracy of the domain estimation of un</context>
</contexts>
<marker>Kornai, Krellenstein, Mulligan, Twomey, Veress, Wysoker, 2003</marker>
<rawString>Andr´as Kornai, Marc Krellenstein, Michael Mulligan, David Twomey, Fruzsina Veress, and Alec Wysoker. 2003. Classifying the Hungarian web. In EACL ’03, pages 203–210.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Liu</author>
<author>Xiaoli Li</author>
<author>Wee Sun Lee</author>
</authors>
<title>Text Classification by Labeling Words. In</title>
<date>2004</date>
<booktitle>AAAI-2004,</booktitle>
<pages>425--430</pages>
<contexts>
<context position="11547" citStr="Liu et al. (2004)" startWordPosition="1928" endWordPosition="1931">ities of training data, which is hard to obtain. Though there has been a growing interest in semi-supervised learning (Abney, 2007), it is in an early phase of development. In contrast, our method requires no training data. All you need is a manageable amount of fundamental words with domains. Also note that our method is NOT tailored to the 12 domains. If you want your own domains to categorize, it is only necessary to construct your own dictionary, which is also domain-independent and not time-consuming. In fact, there have been other proposals without the burden of preparing training data. Liu et al. (2004) prepare representative words for each class, by which they collect initial training data to build classifier. Ko and Seo (2004) automatically collect training data using a large amount of unlabeled data and a small amount of seed information. However, the novelty of this study is the on-the-fly estimation of unknown words’ domains. This feature is very useful for categorizing Blog articles that are updated on a daily basis and filled with newly coined words. Domain information has been used for many NLP tasks. Magnini et al. (2002) show the effectiveness of domain information for WSD. Piao et</context>
</contexts>
<marker>Liu, Li, Lee, 2004</marker>
<rawString>Bing Liu, Xiaoli Li, Wee Sun Lee, , and Philip Yu. 2004. Text Classification by Labeling Words. In AAAI-2004, pages 425–430.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernardo Magnini</author>
<author>Carlo Strapparava</author>
<author>Giovanni Pezzulo</author>
<author>Alfio Gliozzo</author>
</authors>
<date>2002</date>
<booktitle>The Role of Domain Information in Word Sense Disambiguation. Natural Language Engineering, special issue on Word Sense Disambiguation,</booktitle>
<volume>8</volume>
<issue>3</issue>
<marker>Magnini, Strapparava, Pezzulo, Gliozzo, 2002</marker>
<rawString>Bernardo Magnini, Carlo Strapparava, Giovanni Pezzulo, and Alfio Gliozzo. 2002. The Role of Domain Information in Word Sense Disambiguation. Natural Language Engineering, special issue on Word Sense Disambiguation, 8(3):359–373.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott S L Piao</author>
<author>Paul Rayson</author>
<author>Dawn Archer</author>
<author>Andrew Wilson</author>
<author>Tony McEnery</author>
</authors>
<title>Extracting multiword expressions with a semantic tagger.</title>
<date>2003</date>
<booktitle>In Proceedings of the ACL 2003 workshop on Multiword expressions,</booktitle>
<pages>49--56</pages>
<marker>Piao, Rayson, Archer, Wilson, McEnery, 2003</marker>
<rawString>Scott S. L. Piao, Paul Rayson, Dawn Archer, Andrew Wilson, and Tony McEnery. 2003. Extracting multiword expressions with a semantic tagger. In Proceedings of the ACL 2003 workshop on Multiword expressions, pages 49–56.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert E Schapire</author>
<author>Yoram Singer</author>
</authors>
<title>BoosTexter: A Boosting-based System for Text Categorization.</title>
<date>2000</date>
<booktitle>Machine Learning,</booktitle>
<pages>39--2</pages>
<contexts>
<context position="10862" citStr="Schapire and Singer (2000)" startWordPosition="1812" endWordPosition="1815">f newly coined words whose domains were estimated correctly is , which is the abbreviation of day-trade. It was correctly assigned with BUSINESS by the Wikipedia-loose module. Errors were mostly due to the subtle boundary between NODOMAIN and the other particular domains. For instance, person’s names that are common and popular should be NODOMAIN. But in most cases they were associated with some particular domain. This is due to the fact that virtually any person’s name is linked to some particular domain in the Web. 6 Related Work Previous text categorization methods like Joachims (1999) and Schapire and Singer (2000) are mostly based on machine learning. Those methods need huge quantities of training data, which is hard to obtain. Though there has been a growing interest in semi-supervised learning (Abney, 2007), it is in an early phase of development. In contrast, our method requires no training data. All you need is a manageable amount of fundamental words with domains. Also note that our method is NOT tailored to the 12 domains. If you want your own domains to categorize, it is only necessary to construct your own dictionary, which is also domain-independent and not time-consuming. In fact, there have </context>
</contexts>
<marker>Schapire, Singer, 2000</marker>
<rawString>Robert E. Schapire and Yoram Singer. 2000. BoosTexter: A Boosting-based System for Text Categorization. Machine Learning, 39(2/3):135–168.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>