<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.966631">
ConnotationWordNet:
Learning Connotation over the Word+Sense Network
</title>
<author confidence="0.998477">
Jun Seok Kang Song Feng Leman Akoglu Yejin Choi
</author>
<affiliation confidence="0.967416">
Department of Computer Science
Stony Brook University
</affiliation>
<address confidence="0.938022">
Stony Brook, NY 11794-4400
</address>
<email confidence="0.994799">
junkang, songfeng, leman, ychoi@cs.stonybrook.edu
</email>
<sectionHeader confidence="0.997329" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999912625">
We introduce ConnotationWordNet, a con-
notation lexicon over the network of words
in conjunction with senses. We formulate
the lexicon induction problem as collec-
tive inference over pairwise-Markov Ran-
dom Fields, and present a loopy belief
propagation algorithm for inference. The
key aspect of our method is that it is
the first unified approach that assigns the
polarity of both word- and sense-level
connotations, exploiting the innate bipar-
tite graph structure encoded in WordNet.
We present comprehensive evaluation to
demonstrate the quality and utility of the
resulting lexicon in comparison to existing
connotation and sentiment lexicons.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999988318181818">
We introduce ConnotationWordNet, a connotation
lexicon over the network of words in conjunction
with senses, as defined in WordNet. A connotation
lexicon, as introduced first by Feng et al. (2011),
aims to encompass subtle shades of sentiment a
word may conjure, even for seemingly objective
words such as “sculpture”, “Ph.D.”, “rosettes”.
Understanding the rich and complex layers of con-
notation remains to be a challenging task. As a
starting point, we study a more feasible task of
learning the polarity of connotation.
For non-polysemous words, which constitute a
significant portion of English vocabulary, learning
the general connotation at the word-level (rather
than at the sense-level) would be a natural oper-
ational choice. However, for polysemous words,
which correspond to most frequently used words,
it would be an overly crude assumption that the
same connotative polarity should be assigned for
all senses of a given word. For example, consider
“abound”, for which lexicographers of WordNet
prescribe two different senses:
</bodyText>
<listItem confidence="0.999194">
• (v) abound: (be abundant of plentiful; exist
in large quantities)
• (v) abound, burst, bristle: (be in a state of
</listItem>
<bodyText confidence="0.954827027777778">
movement or action) “The room abounded
with screaming children”; “The garden bris-
tled with toddlers”
For the first sense, which is the most commonly
used sense for “abound”, the general overtone of
the connotation would seem positive. That is, al-
though one can use this sense in both positive and
negative contexts, this sense of “abound” seems
to collocate more often with items that are good to
be abundant (e.g., “resources”), than unfortunate
items being abundant (e.g., “complaints”).
However, as for the second sense, for which
“burst” and “bristle” can be used interchangeably
with respect to this particular sense,1 the general
overtone is slightly more negative with a touch of
unpleasantness, or at least not as positive as that of
the first sense. Especially if we look up the Word-
Net entry for “bristle”, there are noticeably more
negatively connotative words involved in its gloss
and examples.
This word sense issue has been a universal chal-
lenge for a range of Natural Language Processing
applications, including sentiment analysis. Recent
studies have shown that it is fruitful to tease out
subjectivity and objectivity corresponding to dif-
ferent senses of the same word, in order to improve
computational approaches to sentiment analysis
(e.g. Pestian et al. (2012), Mihalcea et al. (2012)
Balahur et al. (2014)). Encouraged by these recent
successes, in this study, we investigate if we can
attain similar gains if we model the connotative
polarity of senses separately.
There is one potential practical issue we would
like to point out in building a sense-level lexical
resource, however. End-users of such a lexicon
may not wish to deal with Word Sense Disam-
</bodyText>
<footnote confidence="0.9930125">
1Hence a sense in WordNet is defined by synset (= syn-
onym set), which is the set of words sharing the same sense.
</footnote>
<page confidence="0.905992">
1544
</page>
<note confidence="0.8337675">
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1544–1554,
Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.999724705882353">
biguation (WSD), which is known to be often too
noisy to be incorporated into the pipeline with re-
spect to other NLP tasks. As a result, researchers
often would need to aggregate labels across differ-
ent senses to derive the word-level label. Although
such aggregation is not entirely unreasonable, it
does not seem to be the most optimal and princi-
pled way of integrating available resources.
Therefore, in this work, we present the first uni-
fied approach that learns both sense- and word-
level connotations simultaneously. This way, end-
users will have access to more accurate sense-level
connotation labels if needed, while also having ac-
cess to more general word-level connotation la-
bels. We formulate the lexicon induction problem
as collective inference over pairwise-Markov Ran-
dom Fields (pairwise-MRF) and derive a loopy be-
lief propagation algorithm for inference.
The key aspect of our approach is that we ex-
ploit the innate bipartite graph structure between
words and senses encoded in WordNet. Although
our approach seems conceptually natural, previous
approaches, to our best knowledge, have not di-
rectly exploited these relations between words and
senses for the purpose of deriving lexical knowl-
edge over words and senses collectively. In ad-
dition, previous studies (for both sentiment and
connotation lexicons) aimed to produce only ei-
ther of the two aspects of the polarity: word-level
or sense-level, while we address both.
Another contribution of our work is the intro-
duction of loopy belief propagation (loopy-BP)
as a lexicon induction algorithm. Loopy-BP in
our study achieves statistically significantly better
performance over the constraint optimization ap-
proaches previously explored. In addition, it runs
much faster and it is considerably easier to imple-
ment. Last but not least, by using probabilistic rep-
resentation of pairwise-MRF in conjunction with
Loopy-BP as inference, the resulting solution has
the natural interpretation as the intensity of con-
notation. This contrasts to approaches that seek
discrete solutions such as Integer Linear Program-
ming(Papadimitriou and Steiglitz, 1998).
ConnotationWordNet, the final outcome of our
study, is a new lexical resource that has conno-
tation labels over both words and senses follow-
ing the structure of WordNet. The lexicon is pub-
licly available at: http://www.cs.sunysb.
edu/˜junkang/connotation_wordnet.)
In what follows, we will first describe the net-
</bodyText>
<figureCaption confidence="0.996379">
Figure 1: GWORD+SENSE with words and senses.
</figureCaption>
<bodyText confidence="0.998248571428571">
work of words and senses (Section 2), then intro-
duce the representation of the network structure as
pairwise Markov Random Fields, and a loopy be-
lief propagation algorithm as collective inference
(Section 3). We then present comprehensive eval-
uation (Section 4 &amp; 5 &amp; 6), followed by related
work (Section 7) and conclusion (Section 8).
</bodyText>
<sectionHeader confidence="0.92555" genericHeader="introduction">
2 Network of Words and Senses
</sectionHeader>
<bodyText confidence="0.998195777777778">
The connotation graph, called GWORD+SENSE, is a
heterogeneous graph with multiple types of nodes
and edges. As shown in Figure 1, it contains two
types of nodes; (i) lemmas (i.e., words, 115K)
and (ii) synsets (63K), and four types of edges;
(t1) predicate-argument (179K), (t2) argument-
argument (144K), (t3) argument-synset (126K),
and (t4) synset-synset (3.4K) edges.
The predicate-argument edges, first introduced
by Feng et al. (2011), depict the selectional prefer-
ence of connotative predicates (i.e., the polarity of
a predicate indicates the polarity of its arguments)
and encode their co-occurrence relations based
on the Google Web 1T corpus. The argument-
argument edges are based on the distributional
similarities among the arguments. The argument-
synset edges capture the synonymy between argu-
ment nodes through the corresponding synsets. Fi-
nally, the synset-synset edges depict the antonym
relations between synset pairs.
In general, our graph construction is similar to
that of Feng et al. (2013), but there are a few im-
portant differences. Most notably, we model both
words and synsets explicitly, and exploit the mem-
bership relations between words and senses. We
expect that edges between words and senses will
encourage senses that belong to the same word to
</bodyText>
<figure confidence="0.999548368421052">
�
put on
gain,
put on
memberships
antonyms
word
sense
Pred-Arg
Arg-Arg
Connotative
Predicates
prevent
losses
pain
�
accident
Arguments
achewound
hurt
injure
Senses
injure,
wound
suffer
lose
win, profits,
winnings
win, gain,
acquire
life
win
enjoy
profit
gain
success
investment
achieve
</figure>
<page confidence="0.991458">
1545
</page>
<bodyText confidence="0.99973805">
receive the same connotation label. Conversely,
we expect that these edges will also encourage
words that belong to the same sense (i.e., synset
definition) to receive the same connotation label.
Another benefit of our approach is that for var-
ious WordNet relations (e.g., antonym relations),
which are defined over synsets (not over words),
we can add edges directly between corresponding
synsets, rather than projecting (i.e., approximat-
ing) those relations over words. Note that the lat-
ter, which has been employed by several previous
studies (e.g., Kamps et al. (2004), Takamura et al.
(2005), Andreevskaia and Bergler (2006), Su and
Markert (2009), Lu et al. (2011), Kaji and Kit-
suregawa (2007), Feng et al. (2013)), could be a
source of noise, as one needs to assume that the
semantic relation between a pair of synsets trans-
fers over the pair of words corresponding to that
pair of synsets. For polysemous words, this as-
sumption may be overly strong.
</bodyText>
<sectionHeader confidence="0.943992" genericHeader="method">
3 Pairwise Markov Random Fields and
Loopy Belief Propagation
</sectionHeader>
<bodyText confidence="0.994798157894737">
We formulate the task of learning sense- and word-
level connotation lexicon as a graph-based clas-
sification task (Sen et al., 2008). More formally,
we denote the connotation graph GWORD+SENSE by
G = (V, E), in which a total of n word and synset
nodes V = {v1, ... , vn} are connected with
typed edges e(vi, vj, t) ∈ E, where edge types
t ∈ {pred-arg, arg-arg, syn-arg, syn-syn} de-
pict the four edge types as described in Section
2. A neighborhood function N, where Nv =
{u |e(u, v) ∈ E} ⊆ V , describes the underlying
network structure.
In our collective classification formulation, each
node in V is represented as a random variable that
takes a value from an appropriate class label do-
main; in our case, L = {+, −} for positive and
negative connotation. In this classification task,
we denote by Y the nodes the labels of which need
to be assigned, and let yi refer to Yi’s label.
</bodyText>
<subsectionHeader confidence="0.998711">
3.1 Pairwise Markov Random Fields
</subsectionHeader>
<bodyText confidence="0.983286956521739">
We next define our objective function. We pro-
pose to use an objective formulation that utilizes
pairwise Markov Random Fields (MRFs) (Kinder-
mann and Snell, 1980), which we adapt to our
problem setting. MRFs are a class of probabilistic
graphical models that are suited for solving infer-
ence problems in networked data. An MRF con-
sists of an undirected graph where each node can
be in any of a finite number of states (i.e., class
labels). The state of a node is assumed to be de-
pendent on each of its neighbors and independent
of other nodes in the graph.2 In pairwise MRFs,
the joint probability of the graph can be written as
a product of pairwise factors, parameterized over
the edges. These factors are referred to as clique
potentials in general MRFs, which are essentially
functions that collectively determine the graph’s
joint probability.
Specifically, let G = (V, E) denote a network
of random variables, where V consists of the un-
observed variables Y that need to be assigned val-
ues from label set L. Let Ψ denote a set of clique
potentials that consists of two types of factors:
</bodyText>
<listItem confidence="0.9944078">
• For each Yi ∈ Y, ψi ∈ Ψ is a prior map-
ping ψi : L → R&gt;0, where R&gt;0 denotes non-
negative real numbers.
• For each e(Yi, Yj, t) ∈ E, ψt ij∈ Ψ is a com-
patibility mapping ψtij : L × L → R&gt;0.
</listItem>
<bodyText confidence="0.9975352">
Objective formulation Given an assignment y
to all the unobserved variables Y and x to ob-
served ones X (variables with known labels, if
any), our objective function is associated with the
following joint probability distribution
</bodyText>
<equation confidence="0.998974333333333">
1
P(y|x) =
(1)
</equation>
<bodyText confidence="0.967135142857143">
where Z(x) is the normalization function. Our
goal is then to infer the maximum likelihood as-
signment of states (i.e., labels) to unobserved vari-
ables (i.e., nodes) that will maximize Equation (1).
Problem Definition Having introduced our
graph-based classification task and objective for-
mulation, we define our problem more formally.
Given
- a connotation graph G = (V, E) of words
and synsets connected with typed edges,
- prior knowledge (i.e., probabilities) of (some
or all) nodes belonging to each class,
- compatibility of two nodes with a given pair
of labels being connected to each other;
Classify the nodes Yi ∈ Y, into one of two classes;
L = {+, −}, such that the class assignments yi
maximize our objective in Equation (1).
We can further rank the network objects by the
probability of their connotation polarity.
2This assumption yields a pairwise Markov Random Field
(MRF); a special case of general MRFs (Yedidia et al., 2003).
</bodyText>
<equation confidence="0.974968666666667">
Z(x) Yi ψi(yi) e(Yi,�)EE ψ&apos; (
j zyi, yj)
iEY
</equation>
<page confidence="0.963666">
1546
</page>
<subsectionHeader confidence="0.999553">
3.2 Loopy Belief Propagation
</subsectionHeader>
<bodyText confidence="0.999994470588235">
Finding the best assignments to unobserved vari-
ables in our objective function is the inference
problem. The brute force approach through enu-
meration of all possible assignments is exponen-
tial and thus intractable. In general, exact in-
ference is known to be NP-hard and there is
no known algorithm which can be theoretically
shown to solve the inference problem for gen-
eral MRFs. Therefore in this work, we em-
ploy a computationally tractable (in fact linearly
scalable with network size) approximate infer-
ence algorithm called Loopy Belief Propagation
(LBP) (Yedidia et al., 2003), which we extend to
handle typed graphs like our connotation graph.
Our inference algorithm is based on iterative
message passing and the core of it can be concisely
expressed as the following two equations:
</bodyText>
<equation confidence="0.848477">
mi,j(yj) = α E C4ij (yi,yj) ψi (yi)
yiEL \
Algorithm 1: CONNOTATION INFERENCE
</equation>
<listItem confidence="0.9879846">
1 Input: Connotation graph G=(V, E), prior
potentials ψs for seed words s ∈ S, and
compatibility potentials ψtij
2 Output: Connotation label probabilities for
each node i ∈ V \P
</listItem>
<equation confidence="0.9134884">
3 foreach e(Yi, Yj, t) ∈ E do // initialize msg.s
foreach yj ∈ L do
mi,j(yj) ← 1
6 foreach i ∈ V do // initialize priors
7 foreach yj ∈ L do
8 if i ∈ S then φi(yj) ← ψi(yj) else
φi(yj) ← 1/|L|
9 repeat // iterative message passing
foreach e(Yi, Yj, t) ∈ E, Yj ∈ YV \S do
foreach yj ∈ L do
</equation>
<figure confidence="0.961406631578947">
Use Equation (2)
13 until all messages stop changing
14 foreach Yi ∈ YV \S do // compute final beliefs
4
5
10
11
12
ri
YkENinY\Yj
mk,i(yi) J , ∀yj ∈ L (2)
15
16
foreach yi ∈ L do
Use Equation (3)
rl mj,i(yi),∀yi ∈ L
bi(yi) = β ψi(yi)
YjENinY
(3)
</figure>
<bodyText confidence="0.997046127659574">
A message mi,j is sent from node i to node j
and captures the belief of i about j, which is the
probability distribution over the labels of j; i.e.
what i “thinks” j’s label is, given the current la-
bel of i and the type of the edge that connects i
and j. Beliefs refer to marginal probability dis-
tributions of nodes over labels; for example bi(yi)
denotes the belief of node i having label yi. α and
β are the normalization constants, which respec-
tively ensure that each message and each set of
marginal probabilities sum to 1. At every iteration,
each node computes its belief based on messages
received from its neighbors, and uses the compat-
ibility mapping to transform its belief into mes-
sages for its neighbors. The key idea is that after
enough iterations of message passes between the
nodes, the “conversations” are likely to come to a
consensus, which determines the marginal proba-
bilities of all the unknown variables.
The pseudo-code of our method is given in Al-
gorithm 1. It first initializes all messages to 1
and priors to unbiased (i.e., equal) probabilities
for all nodes except the seed nodes for which the
sentiment is known (lines 3-9). It then proceeds
by making each Yi ∈ Y communicate messages
with their neighbors in an iterative fashion until
the messages stabilize (lines 10-14), i.e. conver-
gence is reached.3 At convergence, we calculate
the marginal probabilities, that is of assigning Yi
with label yi, by computing the final beliefs bi(yi)
(lines 15-17). We use these maximum likelihood
probabilities for label assignment; for each node i,
we assign the label Li ← max yi bi(yi).
To completely define our algorithm, we need to
instantiate the potentials Ψ, in particular the priors
and the compatibilities, which we discuss next.
Priors The prior beliefs ψi of nodes can be suit-
ably initialized if there is any prior knowledge for
their connotation sentiment (e.g., enjoy is posi-
tive, suffer is negative). As such, our method
is flexible to integrate available side information.
In case there is no prior knowledge available, each
node is initialized equally likely to have any of the
possible labels, i.e., 1
|L |as in Algorithm 1 (line 9).
Compatibilities The compatibility potentials
can be thought of as matrices, with entries
</bodyText>
<footnote confidence="0.9975735">
3Although convergence is not theoretically guaranteed, in
practice LBP converges to beliefs within a small threshold of
change (e.g., 10−6) fairly quickly with accurate results (Pan-
dit et al., 2007; McGlohon et al., 2009; Akoglu et al., 2013).
</footnote>
<page confidence="0.994933">
1547
</page>
<bodyText confidence="0.9965273">
ψtij(yi, yj) that give the likelihood of a node hav-
ing label yi, given that it has a neighbor with label
yj to which it is connected through a type t edge.
A key difference of our method from earlier mod-
els is that we use clique potentials that differ for
edge types, since the connotation graph is hetero-
geneous. This is exactly because the compatibil-
ity of class labels of two adjacent nodes depends
on the type of the edge connecting them: e.g.,
syn-arg
</bodyText>
<equation confidence="0.987948333333333">
+ −−−−−→ + is highly compatible, whereas +
syn-syn
−−−−−→ + is unlikely; as syn-arg edges capture
</equation>
<bodyText confidence="0.829654266666667">
synonymy; i.e., words-sense memberships, while
syn-syn edges depict antonym relations.
A sample instantiation of the compatibilities
is shown in Table 1. Notice that the potentials
for pred-arg, arg-arg, and syn-arg capture ho-
mophily, i.e., nodes with the same label are likely
to connect to each other through these types of
edges.4 On the other hand, syn-syn edges con-
nect nodes that are antonyms of each other, and
thus the compatibilities capture the reverse rela-
tionship among their labels.
Table 1: Instantiation of compatibility potentials.
Entry ψt ij(yi, yj) is the compatibility of a node
with label yi having a neighbor labeled yj, given
the edge between i and j is type t, for small E.
</bodyText>
<table confidence="0.821464545454546">
t: t2 A
A + −
+ 1-2e 2e
− 2e 1-2e
(t1) pred-arg (t2) arg-arg
t: t3 A
S + −
+ 1-� �
− � 1-�
(t3) syn-arg (t4) syn-syn
(synonym relations) (antonym relations)
</table>
<bodyText confidence="0.969925461538462">
Complexity analysis Most demanding compo-
nent of Algorithm 1 is the iterative message pass-
ing over the edges (lines 10-14), with time com-
plexity O(ml2r), where m = |E |is the num-
ber of edges in the connotation graph, l = |L|,
the classes, and r, the iterations until convergence.
Often, l is quite small (in our case, l = 2) and
r « m. Thus running time grows linearly with the
number of edges and is scalable to large datasets.
4arg-arg edges are based on co-occurrence (see Section
2), which does not carry as strong indication of the same con-
notation as e.g., synonymy. Thus, we enforce less homophily
for nodes connected through edges of arg-arg type.
</bodyText>
<sectionHeader confidence="0.994375" genericHeader="method">
4 Evaluation I: Agreement with
</sectionHeader>
<subsectionHeader confidence="0.818725">
Sentiment Lexicons
</subsectionHeader>
<bodyText confidence="0.999869">
ConnotationWordNet is expected to be the super-
set of a sentiment lexicon, as it is highly likely for
any word with positive/negative sentiment to carry
connotation of the same polarity. Thus, we use
two conventional sentiment lexicons, General In-
quirer (GENINQ) (Stone et al., 1966) and MPQA
(Wilson et al., 2005b), as surrogates to measure
the performance of our inference algorithm.
</bodyText>
<subsectionHeader confidence="0.999419">
4.1 Variants of Graph Construction
</subsectionHeader>
<bodyText confidence="0.987826628571428">
The construction of the connotation graph, de-
noted by GWORD+SENSE, which includes words and
synsets, has been described in Section 2. In ad-
dition to this graph, we tried several other graph
constructions, the first three of which have previ-
ously been used in (Feng et al., 2013). We briefly
describe these graphs below, and compare perfor-
mance on all the graphs in the proceeding.
GWORD W/ PRED-ARG: This is a (bipartite)
subgraph of GWORD+SENSE, which only includes
the connotative predicates and their arguments. As
such, it contains only type t1 edges. The edges
between the predicates and the arguments can be
weighted by their Point-wise Mutual Information
(PMI)5 based on the Google Web 1T corpus.
GWORD W/ OVERLAY: The second graph is also
a proper subgraph of GWORD+SENSE, which in-
cludes the predicates and all the argument words.
Predicate words are connected to their arguments
as before. In addition, argument pairs (a1, a2) are
connected if they occurred together in the “a1 and
a2” or “a2 and a1” coordination (Hatzivassiloglou
and McKeown, 1997; Pickering and Branigan,
1998). This graph contains both type t1 and t2
edges. The edges can also be weighted based on
the distributional similarities of the word pairs.
GWORD: The third graph is a super-graph of
GWORD W/ OVERLAY, with additional edges,
where argument pairs in synonym and antonym
relation are connected to each other. Note that un-
like the connotation graph GWORD+SENSE, it does
not contain any synset nodes. Rather, the words
that are synonyms or antonyms of each other are
directly linked in the graph. As such, this graph
contains all edge types t1 through t4.
</bodyText>
<footnote confidence="0.972545">
5PMI scores are widely used in previous studies to mea-
sure association between words (e.g., (Church and Hanks,
1990), (Turney, 2001), (Newman et al., 2009)).
</footnote>
<table confidence="0.998687125">
t: t1 A
P + −
+ 1-� �
− � 1-�
t: t4 S
S + −
+ e 1-e
− 1-e e
</table>
<page confidence="0.857341">
1548
</page>
<note confidence="0.352524">
GWORD+SENSE W/ SYNSIM: This is a super-
</note>
<bodyText confidence="0.998397205128205">
graph of our original GWORD+SENSE graph; that
is, it has all the predicate, arguments, and synset
nodes, as well as the four types of edges between
them. In addition, we add edges of a fifth type t5
between the synset nodes to capture their similar-
ity. To define similarity, we use the glossary def-
initions of the synsets and derive three different
scores. Each score utilizes the count(s1, s2) of
overlapping nouns, verbs, and adjectives/adverbs
among the glosses of the two synsets s1 and s2.
GWORD+SENSE W/ SYNSIM1: We discard edges
with count less than 3. The weighted version has
the counts normalized between 0 and 1.
GWORD+SENSE W/ SYNSIM2: We normalize
the counts by the length of the gloss (the
avg of two lengths), that is, p = count /
avg(len gloss(s1), len gloss(s2))
and discard edges with p &lt; 0.5. The weighted
version contains p values as edge weights.
GWORD+SENSE W/ SYNSIM3: To further sparsify
the graph we discard edges with p &lt; 0.6. To
weigh the edges, we use the cosine similarity be-
tween the gloss vectors of the synsets based on the
TF-IDF values of the words the glosses contain.
Note that the connotation inference algorithm,
as given in Algorithm 1, remains exactly the same
for all the graphs described above. The only dif-
ference is the set of parameters used; while GWORD
W/ PRED-ARG and GWORD W/ OVERLAY contain
one and two edge types, respectively and only use
compatibilities (t1) and (t2), GWORD uses all four
as given in Table 1. The GWORD+SENSE W/ SYN-
SIM graphs use an additional compatibility matrix
for the synset similarity edges of type t5, which is
the same as the one used for t1, i.e., similar synsets
are likely to have the same connotation label. This
flexibility is one of the key advantages of our al-
gorithm as new types of nodes and edges can be
added to the graph seamlessly.
</bodyText>
<subsectionHeader confidence="0.999701">
4.2 Sentiment-Lexicon based Performance
</subsectionHeader>
<bodyText confidence="0.9999212">
In this section, we first compare the performance
of our connotation graph GWORD+SENSE to graphs
that do not include synset nodes but only words.
Then we analyze the performance when the addi-
tional synset similarity edges are added. First, we
briefly describe our performance measures.
The sentiment lexicons we use as gold standard
are small, compared to the size (i.e., number of
words) our graphs contain. Thus, we first find
the overlap between each graph and a senti-
</bodyText>
<table confidence="0.985238944444445">
GENINQ MPQA
P R F F
Variations of GWORD
W/ PRED-ARG 88.0 67.6 76.5 57.3
W/ PRED-ARG-W 84.9 68.9 76.1 57.8
W/ OVERLAY 87.8 70.4 78.1 58.4
W/ OVERLAY-W 82.2 67.7 74.2 54.2
GWORD 88.5 83.1 85.7 69.7
GWORD-W 75.5 71.5 73.4 53.2
Variations of GWORD+SENSE
GWORD+SENSE 88.8 84.1 86.4 70.0
GWORD+SENSE-W 76.8 73.0 74.9 54.6
W/ SYNSIM1 87.2 83.3 85.2 67.9
W/ SYNSIM2 83.9 80.8 82.3 65.1
W/ SYNSIM3 86.5 83.2 84.8 67.8
W/ SYNSIM1-W 88.0 84.3 86.1 69.2
W/ SYNSIM2-W 86.4 83.7 85.0 68.5
W/ SYNSIM3-W 86.7 83.4 85.0 68.2
</table>
<tableCaption confidence="0.998596">
Table 2: Connotation inference performance on
</tableCaption>
<bodyText confidence="0.974019771428572">
various graphs. ‘-W’ indicates weighted versions
(see §4.1). P: precision, R: recall, F: F1-score (%).
ment lexicon. Note that the overlap size maybe
smaller than the lexicon size, as some sen-
timent words may be missing from our graphs.
Then, we calculate the number of correct la-
bel assignments. As such, precision is defined as
(correct / overlap), and recall as (correct
/lexicon size). Finally, F1-score is their har-
monic mean and reflects the overall accuracy.
As shown in Table 2 (top), we first observe that
including the synonym and antonym relations in
the graph, as with GWORD and GWORD+SENSE, im-
prove the performance significantly, almost by an
order of magnitude, over graphs GWORD W/ PRED-
ARG and GWORD W/ OVERLAY that do not contain
those relation types. Furthermore, we notice that
the performances on the GWORD+SENSE graph are
better than those on the word-only graphs. This
shows that including the synset nodes explicitly in
the graph structure is beneficial. What is more,
it gives us a means to obtain connotation labels
for the synsets themselves, which we use in the
evaluations in the next sections. Finally, we note
that using the unweighted versions of the graphs
provide relatively more robust performance, po-
tentially due to noise in the relative edge weights.
Next we analyze the performance when the new
edges between synsets are introduced, as given in
Table 2 (bottom). We observe that connecting the
synset nodes by their gloss-similarity (at least in
the ways we tried) does not yield better perfor-
mance than on our original GWORD+SENSE graph.
Different from earlier, the weighted versions of
the similarity based graphs provide better perfor-
</bodyText>
<page confidence="0.989182">
1549
</page>
<figure confidence="0.924876">
Lexicon Word-level Sense-level
SentiWordNet 27.22 14.29
OpinionFinder 31.95 -
Feng2013 62.72 -
GWORD+SENSE(95%) 84.91 83.43
GWORD+SENSE(99%) 84.91 83.71
E-GWORD+SENSE(95%) 86.98 86.29
E-GWORD+SENSE(99%) 86.69 85.71
</figure>
<tableCaption confidence="0.985622">
Table 3: Word-/Sense-level evaluation results
</tableCaption>
<bodyText confidence="0.9997982">
mance than their unweighted counterparts. This
suggests that glossary similarity would be a more
robust means to correlate nodes; we leave it as fu-
ture work to explore this direction for predicate-
argument and argument-argument relations.
</bodyText>
<subsectionHeader confidence="0.996774">
4.3 Parameter Sensitivity
</subsectionHeader>
<bodyText confidence="0.989723333333333">
Our belief propagation based connotation senti-
ment inference algorithm has one user-specified
parameter E (see Table 1). To study the sensitivity
of its performance to the choice of E, we reran our
experiments for E = {0.02, 0.04, ... , 0.24}6 and
report the accuracy results on our GWORD+SENSE in
Figure 2 for the two lexicons. The results indicate
that the performances remain quite stable across a
wide range of the parameter choice.
</bodyText>
<figure confidence="0.923635">
(a) GENINQ EVAL (b) MPQA EVAL
</figure>
<figureCaption confidence="0.990928">
Figure 2: Performance is stable across various E.
</figureCaption>
<sectionHeader confidence="0.9854045" genericHeader="method">
5 Evaluation II: Human Evaluation on
ConnotationWordNet
</sectionHeader>
<bodyText confidence="0.9999708125">
In this section, we present the result of human
evaluation we executed using Amazon Mechani-
cal Turk (AMT). We collect two separate sets of
labels: a set of labels at the word-level, and an-
other set at the sense-level. We first describe the
labeling process of sense-level connotation: We
selected 350 polysemous words and one of their
senses, and each Turker was asked to rate the con-
notative polarity of a given word (or of a given
sense), from -5 to 5, 0 being the neutral.7 For each
word, we asked 5 Turkers to rate and we took the
average of the 5 ratings as the connotative inten-
sity score of the word. We labeled a word as nega-
tive if its intensity score is less than 0 and positive
otherwise. For word-level labels we apply similar
procedure as above.
</bodyText>
<footnote confidence="0.821477">
6Note that for e &gt; 0.25, compatibilities of 7 pt2 in Table 1
are reversed, hence the maximum of 0.24. Y
7Because senses in WordNet can be tricky to understand,
</footnote>
<bodyText confidence="0.896501666666667">
care should be taken in designing the task so that the Turkers
will focus only on the corresponding sense of a word. There-
fore, we provided the part of speech tag, the WordNet gloss
of the selected sense, and a few examples as given in Word-
Net. As an incentive, each Turker was rewarded $0.07 per hit
which consists of 10 words to label.
</bodyText>
<subsectionHeader confidence="0.964503">
5.1 Word-Level Evaluation
</subsectionHeader>
<bodyText confidence="0.999997142857143">
We first evaluate the word-level assignment of
connotation, as shown in Table 3. The agreement
between the new lexicon and human judges varies
between 84% and 86.98%. Sentiment lexicons
such as SentiWordNet (Baccianella et al. (2010))
and OpinionFinder (Wilson et al. (2005a)) show
low agreement rate with human, which is some-
what as expected: human judges in this study are
labeling for subtle connotation, not for more ex-
plicit sentiment. OpinionFinder’s low agreement
rate was mainly due to the low hit rate of the words
(successful look-up rate, 33.43%). Feng2013 is
the lexicon presented in (Feng et al., 2013) and it
showed a relatively higher 72.13% hit rate.
Note that belief propagation was run until 95%
and 99% of the nodes were converged in their
beliefs. In addition, the seed words with known
connotation labels originally consist of 20 positive
and 20 negative predicates. We also extended the
seed set with the sentiment lexicon words and de-
note these runs with E- for ‘Extended’.
</bodyText>
<subsectionHeader confidence="0.993275">
5.2 Sense-Level Evaluation
</subsectionHeader>
<bodyText confidence="0.9999855">
We also examined the agreement rates on the
sense-level. Since OpinionFinder and Feng2013
do not provide the polarity scores at the sense-
level, we excluded them from this evaluation. Be-
cause sense-level polarity assignment is a harder
(more subtle) task, the performance of all lexicons
decreased to some degree in comparison to that of
word-level evaluations.
</bodyText>
<subsectionHeader confidence="0.997088">
5.3 Pair-wise Intensity Ranking
</subsectionHeader>
<bodyText confidence="0.999981222222222">
A notable goodness of our induction algorithm is
that the outcome of the algorithm can be inter-
preted as an intensity of the corresponding conno-
tation. But are these values meaningful? We an-
swer this question in this section. We formulate a
pair-wise ranking task as a binary decision task as
follows: given a pair of words, we ask which one
is more positive (or more negative) than the other.
Since we collect human labels based on scales, we
</bodyText>
<figure confidence="0.911044709677419">
0.02 0.06 0.10 0.14 0.18 0.22
ε
0.02 0.06 0.10 0.14 0.18 0.22
ε
Performance
100
80
60
40
20
0
precision
recall
F-score
Performance
100
80
60
40
20
0
precision
recall
F-score
1550
Lexicon Correct Undecided
SentiWordNet 33.77 23.34
GWORD+SENSE(95%) 74.83 0.58
GWORD+SENSE(99%) 73.01 0.58
E-GWORD+SENSE(95%) 73.84 1.16
E-GWORD+SENSE(99%) 74.01 1.16
</figure>
<tableCaption confidence="0.871587">
Table 4: Results of pair-wise intensity evaluation,
for intensity difference threshold = 2.0
</tableCaption>
<bodyText confidence="0.96000325">
already have this information at hand. Because
different human judges have different notion of
scales however, subtle differences are more likely
to be noisy. Therefore, we experiment with vary-
ing degrees of differences in their scales, as shown
in Figure 3. Threshold values (ranging from 0.5 to
3.0) indicate the minimum differences in scales for
any pair of words, for the pair to be included in the
test set. As expected, we observe that the perfor-
mance improves as we increase the threshold (as
pairs get better separated). Within range [0.5, 1.5]
(249 pairs examined), the accuracies are as high as
68.27%, which shows that even the subtle differ-
ences of the connotative intensities are relatively
well reflected in the new lexicons.
Threshold
</bodyText>
<figureCaption confidence="0.9971115">
Figure 3: Trend of accuracy for pair-wise intensity
evaluation over threshold
</figureCaption>
<bodyText confidence="0.999978583333333">
The results for pair-wise intensity evaluation
(threshold=2.0, 1,208 pairs) are given in Table 4.
Despite that intensity is generally a harder prop-
erty to measure (than the coarser binary catego-
rization of polarities), our connotation lexicons
perform surprisingly well, reaching up to 74.83%
accuracy. Further study on the incorrect cases re-
veals that SentiWordNet has many pair of words
with the same polarity score (23.34%). Such cases
seems to be due to the limited score patterns of
SentiWordNet. The ratio of such cases are ac-
counted as Undecided in Table 4.
</bodyText>
<sectionHeader confidence="0.852108" genericHeader="method">
6 Evaluation III: Sentiment Analysis
using ConnotationWordNet
</sectionHeader>
<bodyText confidence="0.99999">
Finally, to show the utility of the resulting lexi-
con in the context of a concrete sentiment analysis
task, we perform lexicon-based sentiment analy-
sis. We experiment with SemEval dataset (Strap-
parava and Mihalcea, 2007) that includes the hu-
man labeled dataset for predicting whether a news
headline is a good news or a bad news, which we
expect to have a correlation with the use of con-
notative words that we focus on in this paper. The
good/bad news are annotated with scores (ranging
from -100 to 87). We construct several data sets by
applying different thresholds on scores. For exam-
ple, with the threshold set to 60, we discard the in-
stances whose scores lie between -60 and 60. For
comparison, we also test the connotation lexicon
from (Feng et al., 2013) and the combined senti-
ment lexicon GENINQ+MPQA.
Note that there is a difference in how humans
judge the orientation and the degree of connota-
tion for a given word out of context, and how the
use of such words in context can be perceived as
good/bad news. In particular, we conjecture that
humans may have a bias toward the use of posi-
tive words, which in turn requires calibration from
the readers’ minds (Pennebaker and Stone, 2003).
That is, we might need to tone down the level of
positiveness in order to correctly measure the ac-
tual intended positiveness of the message.
With this in mind, we tune the appropriate cali-
bration from a small training data, by using 1 fold
from N fold cross validation, and using the re-
maining N − 1 folds as testing. We simply learn
the mixture coefficient A to scale the contribution
of positive and negative connotation values. We
tune this parameter A8 for other lexicons we com-
pare against as well. Note that due to this param-
eter learning, we are able to report better perfor-
mance for the connotation lexicon of (Feng et al.,
2013) than what the authors have reported in their
paper (labeled with *) in Table 5.
Table 5 shows the results for N=15, where the
new lexicon consistently outperforms other com-
petitive lexicons. In addition, Figure 4 shows that
the performance does not change much based on
the size of training data used for parameter tuning
(N={5,10,15,20}).
</bodyText>
<sectionHeader confidence="0.999878" genericHeader="related work">
7 Related Work
</sectionHeader>
<bodyText confidence="0.964485666666667">
Several previous approaches explored the use of
graph propagation for sentiment lexicon induction
(Velikovich et al., 2010) and connotation lexicon
</bodyText>
<footnote confidence="0.9792595">
8What is reported is based on A ∈ {20, 40, 60, 80}. More
detailed parameter search does not change the results much.
</footnote>
<figure confidence="0.9955637">
0.5 1.0 2.0 3.0
Accuracy (%)
80
40
60
SentiWordNet
GWord+Sense(95%)
GWord+Sense(99%)
e-GWord+Sense(95%)
e-GWord+Sense(99%)
</figure>
<page confidence="0.965209">
1551
</page>
<table confidence="0.999567727272727">
Lexicon SemEval Threshold
20 40 60 80
Instance Size 955 649 341 86
Feng2013 71.5 77.1 81.6 90.5
GENINQ+MPQA 72.8 77.2 80.4 86.7
GWORD+SENSE(95%) 74.5 79.4 86.5 91.9
GWORD+SENSE(99%) 74.6 79.4 86.8 91.9
E-GWORD+SENSE(95%) 72.5 76.8 82.3 87.2
E-GWORD+SENSE(99%) 72.6 76.9 82.5 87.2
Feng2013* 70.8 74.6 80.8 93.5
GENINQ+MPQA* 64.5 69.0 74.0 80.5
</table>
<figureCaption confidence="0.9891235">
Figure 4: Trend of SemEval performance over N,
the number of CV folds
</figureCaption>
<bodyText confidence="0.999896384615385">
induction (Feng et al., 2013). Our work intro-
duces the use of loopy belief propagation over
pairwise-MRF as an alternative solution to these
tasks. At a high-level, both approaches share the
general idea of propagating confidence or belief
over the graph connectivity. The key difference,
however, is that in our MRF representation, we
can explicitly model various types of word-word,
sense-sense and word-sense relations as edge po-
tentials. In particular, we can naturally encode re-
lations that encourage the same assignment (e.g.,
synonym) as well as the opposite assignment (e.g.,
antonym) of the polarity labels. Note that integra-
tion of the latter is not straightforward in the graph
propagation framework.
There have been a number of previous studies
that aim to construct a word-level sentiment lex-
icon (Wiebe et al., 2005; Qiu et al., 2009) and
a sense-level sentiment lexicon (Esuli and Sebas-
tiani, 2006). But none of these approaches con-
sidered to induce the polarity labels at both the
word-level and sense-level. Although we focus on
learning connotative polarity of words and senses
in this paper, the same approach would be applica-
ble to constructing a sentiment lexicon as well.
There have been recent studies that address
word sense disambiguation issues for sentiment
analysis. SentiWordNet (Esuli and Sebastiani,
2006) was the very first lexicon developed for
sense-level labels of sentiment polarity. In recent
years, Akkaya et al. (2009) report a successful em-
pirical result where WSD helps improving senti-
ment analysis, while Wiebe and Mihalcea (2006)
study the distinction between objectivity and sub-
jectivity in each different sense of a word, and
their empirical effects in the context of sentiment
analysis. Our work shares the high-level spirit of
accessing the sense-level polarity, while also de-
riving the word-level polarity.
In recent years, there has been a growing re-
search interest in investigating more fine-grained
aspects of lexical sentiment beyond positive and
negative sentiment. For example, Mohammad and
Turney (2010) study the affects words can evoke
in people’s minds, while Bollen et al. (2011) study
various moods, e.g., “tension”, “depression”, be-
yond simple dichotomy of positive and negative
sentiment. Our work, and some recent work by
Feng et al. (2011) and Feng et al. (2013) share this
spirit by targeting more subtle, nuanced sentiment
even from those words that would be considered
as objective in early studies of sentiment analysis.
</bodyText>
<sectionHeader confidence="0.998661" genericHeader="conclusions">
8 Conclusion
</sectionHeader>
<bodyText confidence="0.999988117647059">
We have introduced a novel formulation of lexicon
induction operating over both words and senses,
by exploiting the innate structure between the
words and senses as encoded in WordNet. In addi-
tion, we introduce the use of loopy belief propaga-
tion over pairwise-Markov Random Fields as an
effective lexicon induction algorithm. A notable
strength of our approach is its expressiveness: var-
ious types of prior knowledge and lexical relations
can be encoded as node potentials and edge po-
tentials. In addition, it leads to a lexicon of bet-
ter quality while also offering faster run-time and
easiness of implementation. The resulting lexi-
con, called ConnotationWordNet, is the first lex-
icon that has polarity labels over both words and
senses. ConnotationWordNet is publicly available
for research and practical use.
</bodyText>
<sectionHeader confidence="0.998814" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.998433571428571">
This research was supported by the Army Re-
search Office under Contract No. W911NF-14-1-
0029, Stony Brook University Office of Vice Pres-
ident for Research, and gifts from Northrop Grum-
man Aerospace Systems and Google. We thank
reviewers for many insightful comments and sug-
gestions.
</bodyText>
<tableCaption confidence="0.837703">
Table 5: SemEval evaluation results, for N=15
</tableCaption>
<figure confidence="0.998908">
5 10 15 20
N
Accuracy (%)
80
50
70
60
Feng2013
MPQA+GenInq
GWord+Sense(95%)
GWord+Sense(99%)
e-GWord+Sense(95%)
e-GWord+Sense(99%)
</figure>
<page confidence="0.991514">
1552
</page>
<sectionHeader confidence="0.988442" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997927447619048">
Cem Akkaya, Janyce Wiebe, and Rada Mihalcea.
2009. Subjectivity word sense disambiguation. In
Proceedings of the 2009 Conference on Empirical
Methods in Natural Language Processing: Volume
1-Volume 1, pages 190–199. Association for Com-
putational Linguistics.
Leman Akoglu, Rishi Chandy, and Christos Faloutsos.
2013. Opinion fraud detection in online reviews by
network effects.
Alina Andreevskaia and Sabine Bergler. 2006. Min-
ing wordnet for a fuzzy sentiment: Sentiment tag
extraction from wordnet glosses. In EACL, pages
209–216.
Stefano Baccianella, Andrea Esuli, and Fabrizio Sebas-
tiani. 2010. Sentiwordnet 3.0: An enhanced lexical
resource for sentiment analysis and opinion mining.
In LREC, volume 10, pages 2200–2204.
Alexandra Balahur, Rada Mihalcea, and Andr´es Mon-
toyo. 2014. Computational approaches to subjec-
tivity and sentiment analysis: Present and envisaged
methods and applications. Computer Speech &amp; Lan-
guage, 28(1):1–6.
Johan Bollen, Huina Mao, and Alberto Pepe. 2011.
Modeling public mood and emotion: Twitter senti-
ment and socio-economic phenomena. In ICWSM.
K. W. Church and P. Hanks. 1990. Word association
norms, mutual information, and lexicography. Com-
putational Linguistics, 1(16):22–29.
Andrea Esuli and Fabrizio Sebastiani. 2006. Sen-
tiwordnet: A publicly available lexical resource
for opinion mining. In In Proceedings of the 5th
Conference on Language Resources and Evaluation
(LREC06, pages 417–422.
Song Feng, Ritwik Bose, and Yejin Choi. 2011. Learn-
ing general connotation of words using graph-based
algorithms. In Proceedings of the Conference on
Empirical Methods in Natural Language Process-
ing, pages 1092–1103. Association for Computa-
tional Linguistics.
Song Feng, Jun Seok Kang, Polina Kuznetsova, and
Yejin Choi. 2013. Connotation lexicon: A dash
of sentiment beneath the surface meaning. In The
Association for Computer Linguistics, pages 1774–
1784.
Vasileios Hatzivassiloglou and Kathleen McKeown.
1997. Predicting the semantic orientation of adjec-
tives. In Proceedings of the Joint ACL/EACL Con-
ference, pages 174–181.
Nobuhiro Kaji and Masaru Kitsuregawa. 2007. Build-
ing lexicon for sentiment analysis from massive col-
lection of html documents. In EMNLP-CoNLL,
pages 1075–1083.
Jaap Kamps, MJ Marx, Robert J Mokken, and Maarten
De Rijke. 2004. Using wordnet to measure seman-
tic orientations of adjectives.
Ross Kindermann and J. L. Snell. 1980. Markov Ran-
dom Fields and Their Applications.
Yue Lu, Malu Castellanos, Umeshwar Dayal, and
ChengXiang Zhai. 2011. Automatic construction
of a context-aware sentiment lexicon: an optimiza-
tion approach. In Proceedings of the 20th interna-
tional conference on World wide web, pages 347–
356. ACM.
Mary McGlohon, Stephen Bay, Markus G. Anderle,
David M. Steier, and Christos Faloutsos. 2009.
Snare: a link analytic system for graph labeling
and risk detection. In John F. Elder IV, Franoise
Fogelman-Souli, Peter A. Flach, and Mohammed
Zaki, editors, KDD, pages 1265–1274. ACM.
Rada Mihalcea, Carmen Banea, and Janyce Wiebe.
2012. Multilingual subjectivity and sentiment anal-
ysis. In Tutorial Abstracts of ACL 2012, pages 4–4.
Association for Computational Linguistics.
Saif Mohammad and Peter Turney. 2010. Emotions
evoked by common words and phrases: Using me-
chanical turk to create an emotion lexicon. In Pro-
ceedings of the NAACL HLT 2010 Workshop on
Computational Approaches to Analysis and Genera-
tion of Emotion in Text, pages 26–34, Los Angeles,
CA, June. Association for Computational Linguis-
tics.
David Newman, Sarvnaz Karimi, and Lawrence Cave-
don. 2009. External evaluation of topic models.
In Australasian Document Computing Symposium,
pages 11–18, Sydney, December.
Shashank Pandit, Duen Horng Chau, Samuel Wang,
and Christos Faloutsos. 2007. Netprobe: a fast and
scalable system for fraud detection in online auction
networks. In WWW, pages 201–210.
Christos H Papadimitriou and Kenneth Steiglitz. 1998.
Combinatorial optimization: algorithms and com-
plexity. Courier Dover Publications.
James W Pennebaker and Lori D Stone. 2003. Words
of wisdom: language use over the life span. Journal
ofpersonality and social psychology, 85(2):291.
John P Pestian, Pawel Matykiewicz, Michelle Linn-
Gust, Brett South, Ozlem Uzuner, Jan Wiebe, K Bre-
tonnel Cohen, John Hurdle, Christopher Brew, et al.
2012. Sentiment analysis of suicide notes: A shared
task. Biomedical Informatics Insights, 5(Suppl.
1):3.
Martin J. Pickering and Holly P. Branigan. 1998. The
representation of verbs: Evidence from syntactic
priming in language production. Journal of Mem-
ory and Language, 39:633–651.
</reference>
<page confidence="0.61627">
1553
</page>
<reference confidence="0.999817342857143">
Guang Qiu, Bing Liu, Jiajun Bu, and Chun Chen.
2009. Expanding domain sentiment lexicon through
double propagation. In IJCAI, volume 9, pages
1199–1204.
Prithviraj Sen, Galileo Namata, Mustafa Bilgic, Lise
Getoor, Brian Gallagher, and Tina Eliassi-Rad.
2008. Collective classification in network data. AI
Magazine, 29(3):93–106.
Philip J. Stone, Dexter C. Dunphy, Marshall S. Smith,
and Daniel M. Ogilvie. 1966. The General In-
quirer: A Computer Approach to Content Analysis.
MIT Press, Cambridge, MA.
Carlo Strapparava and Rada Mihalcea. 2007. Semeval-
2007 task 14: Affective text. In Proceedings of
the 4th International Workshop on Semantic Evalu-
ations, pages 70–74. Association for Computational
Linguistics.
Fangzhong Su and Katja Markert. 2009. Subjectiv-
ity recognition on word senses via semi-supervised
mincuts. In Proceedings of Human Language Tech-
nologies: The 2009 Annual Conference of the North
American Chapter of the Association for Computa-
tional Linguistics, pages 1–9. Association for Com-
putational Linguistics.
Hiroya Takamura, Takashi Inui, and Manabu Okumura.
2005. Extracting semantic orientations of words us-
ing spin model. In Proceedings of the 43rd Annual
Meeting on Association for Computational Linguis-
tics, pages 133–140. Association for Computational
Linguistics.
Peter D. Turney. 2001. Mining the Web for synonyms:
PMI-IR versus LSA on TOEFL. In Proceedings
of the Twelfth European Conference on Machine
Learning (ECML-01), pages 491–502, Freiburg,
Germany.
Leonid Velikovich, Sasha Blair-Goldensohn, Kerry
Hannan, and Ryan McDonald. 2010. The via-
bility of web-derived polarity lexicons. In Human
Language Technologies: The 2010 Annual Confer-
ence of the North American Chapter of the Associa-
tion for Computational Linguistics. Association for
Computational Linguistics.
Janyce Wiebe and Rada Mihalcea. 2006. Word sense
and subjectivity. In Proceedings of the 21st Inter-
national Conference on Computational Linguistics
and the 44th annual meeting of the Association for
Computational Linguistics, pages 1065–1072. Asso-
ciation for Computational Linguistics.
Janyce Wiebe, Theresa Wilson, and Claire Cardie.
2005. Annotating expressions of opinions and emo-
tions in language. Language Resources and Eval-
uation (formerly Computers and the Humanities),
39(2/3):164–210.
Theresa Wilson, Paul Hoffmann, Swapna Somasun-
daran, Jason Kessler, Janyce Wiebe, Yejin Choi,
Claire Cardie, Ellen Riloff, and Siddharth Patward-
han. 2005a. Opinionfinder: A system for subjec-
tivity analysis. In Proceedings of HLT/EMNLP on
Interactive Demonstrations, pages 34–35. Associa-
tion for Computational Linguistics.
Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.
2005b. Recognizing contextual polarity in phrase-
level sentiment analysis. In Proceedings of Human
Language Technologies Conference/Conference on
Empirical Methods in Natural Language Processing
(HLT/EMNLP 2005), Vancouver, CA.
Jonathan S. Yedidia, William T. Freeman, and Yair
Weiss. 2003. Understanding belief propagation and
its generalizations. In Exploring AI in the new mil-
lennium, pages 239–269.
</reference>
<page confidence="0.995771">
1554
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.851273">
<title confidence="0.9905315">ConnotationWordNet: Learning Connotation over the Word+Sense Network</title>
<author confidence="0.999309">Jun Seok Kang Song Feng Leman Akoglu Yejin Choi</author>
<affiliation confidence="0.998286">Department of Computer</affiliation>
<author confidence="0.917219">Stony Brook Stony Brook</author>
<author confidence="0.917219">NY</author>
<email confidence="0.998929">junkang,songfeng,leman,ychoi@cs.stonybrook.edu</email>
<abstract confidence="0.999584352941176">introduce a conlexicon over the network of conjunction with We formulate the lexicon induction problem as collective inference over pairwise-Markov Random Fields, and present a loopy belief propagation algorithm for inference. The key aspect of our method is that it is unified that assigns the of and sense-level connotations, exploiting the innate bipartite graph structure encoded in WordNet. We present comprehensive evaluation to demonstrate the quality and utility of the resulting lexicon in comparison to existing connotation and sentiment lexicons.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Cem Akkaya</author>
<author>Janyce Wiebe</author>
<author>Rada Mihalcea</author>
</authors>
<title>Subjectivity word sense disambiguation.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume</booktitle>
<volume>1</volume>
<pages>190--199</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="36634" citStr="Akkaya et al. (2009)" startWordPosition="6101" endWordPosition="6104"> al., 2009) and a sense-level sentiment lexicon (Esuli and Sebastiani, 2006). But none of these approaches considered to induce the polarity labels at both the word-level and sense-level. Although we focus on learning connotative polarity of words and senses in this paper, the same approach would be applicable to constructing a sentiment lexicon as well. There have been recent studies that address word sense disambiguation issues for sentiment analysis. SentiWordNet (Esuli and Sebastiani, 2006) was the very first lexicon developed for sense-level labels of sentiment polarity. In recent years, Akkaya et al. (2009) report a successful empirical result where WSD helps improving sentiment analysis, while Wiebe and Mihalcea (2006) study the distinction between objectivity and subjectivity in each different sense of a word, and their empirical effects in the context of sentiment analysis. Our work shares the high-level spirit of accessing the sense-level polarity, while also deriving the word-level polarity. In recent years, there has been a growing research interest in investigating more fine-grained aspects of lexical sentiment beyond positive and negative sentiment. For example, Mohammad and Turney (2010</context>
</contexts>
<marker>Akkaya, Wiebe, Mihalcea, 2009</marker>
<rawString>Cem Akkaya, Janyce Wiebe, and Rada Mihalcea. 2009. Subjectivity word sense disambiguation. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 1-Volume 1, pages 190–199. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leman Akoglu</author>
<author>Rishi Chandy</author>
<author>Christos Faloutsos</author>
</authors>
<title>Opinion fraud detection in online reviews by network effects.</title>
<date>2013</date>
<contexts>
<context position="17034" citStr="Akoglu et al., 2013" startWordPosition="2809" endWordPosition="2812">iment (e.g., enjoy is positive, suffer is negative). As such, our method is flexible to integrate available side information. In case there is no prior knowledge available, each node is initialized equally likely to have any of the possible labels, i.e., 1 |L |as in Algorithm 1 (line 9). Compatibilities The compatibility potentials can be thought of as matrices, with entries 3Although convergence is not theoretically guaranteed, in practice LBP converges to beliefs within a small threshold of change (e.g., 10−6) fairly quickly with accurate results (Pandit et al., 2007; McGlohon et al., 2009; Akoglu et al., 2013). 1547 ψtij(yi, yj) that give the likelihood of a node having label yi, given that it has a neighbor with label yj to which it is connected through a type t edge. A key difference of our method from earlier models is that we use clique potentials that differ for edge types, since the connotation graph is heterogeneous. This is exactly because the compatibility of class labels of two adjacent nodes depends on the type of the edge connecting them: e.g., syn-arg + −−−−−→ + is highly compatible, whereas + syn-syn −−−−−→ + is unlikely; as syn-arg edges capture synonymy; i.e., words-sense membership</context>
</contexts>
<marker>Akoglu, Chandy, Faloutsos, 2013</marker>
<rawString>Leman Akoglu, Rishi Chandy, and Christos Faloutsos. 2013. Opinion fraud detection in online reviews by network effects.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alina Andreevskaia</author>
<author>Sabine Bergler</author>
</authors>
<title>Mining wordnet for a fuzzy sentiment: Sentiment tag extraction from wordnet glosses.</title>
<date>2006</date>
<booktitle>In EACL,</booktitle>
<pages>209--216</pages>
<contexts>
<context position="9100" citStr="Andreevskaia and Bergler (2006)" startWordPosition="1401" endWordPosition="1404">5 receive the same connotation label. Conversely, we expect that these edges will also encourage words that belong to the same sense (i.e., synset definition) to receive the same connotation label. Another benefit of our approach is that for various WordNet relations (e.g., antonym relations), which are defined over synsets (not over words), we can add edges directly between corresponding synsets, rather than projecting (i.e., approximating) those relations over words. Note that the latter, which has been employed by several previous studies (e.g., Kamps et al. (2004), Takamura et al. (2005), Andreevskaia and Bergler (2006), Su and Markert (2009), Lu et al. (2011), Kaji and Kitsuregawa (2007), Feng et al. (2013)), could be a source of noise, as one needs to assume that the semantic relation between a pair of synsets transfers over the pair of words corresponding to that pair of synsets. For polysemous words, this assumption may be overly strong. 3 Pairwise Markov Random Fields and Loopy Belief Propagation We formulate the task of learning sense- and wordlevel connotation lexicon as a graph-based classification task (Sen et al., 2008). More formally, we denote the connotation graph GWORD+SENSE by G = (V, E), in w</context>
</contexts>
<marker>Andreevskaia, Bergler, 2006</marker>
<rawString>Alina Andreevskaia and Sabine Bergler. 2006. Mining wordnet for a fuzzy sentiment: Sentiment tag extraction from wordnet glosses. In EACL, pages 209–216.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefano Baccianella</author>
<author>Andrea Esuli</author>
<author>Fabrizio Sebastiani</author>
</authors>
<title>Sentiwordnet 3.0: An enhanced lexical resource for sentiment analysis and opinion mining.</title>
<date>2010</date>
<booktitle>In LREC,</booktitle>
<volume>10</volume>
<pages>2200--2204</pages>
<contexts>
<context position="28658" citStr="Baccianella et al. (2010)" startWordPosition="4795" endWordPosition="4798">an be tricky to understand, care should be taken in designing the task so that the Turkers will focus only on the corresponding sense of a word. Therefore, we provided the part of speech tag, the WordNet gloss of the selected sense, and a few examples as given in WordNet. As an incentive, each Turker was rewarded $0.07 per hit which consists of 10 words to label. 5.1 Word-Level Evaluation We first evaluate the word-level assignment of connotation, as shown in Table 3. The agreement between the new lexicon and human judges varies between 84% and 86.98%. Sentiment lexicons such as SentiWordNet (Baccianella et al. (2010)) and OpinionFinder (Wilson et al. (2005a)) show low agreement rate with human, which is somewhat as expected: human judges in this study are labeling for subtle connotation, not for more explicit sentiment. OpinionFinder’s low agreement rate was mainly due to the low hit rate of the words (successful look-up rate, 33.43%). Feng2013 is the lexicon presented in (Feng et al., 2013) and it showed a relatively higher 72.13% hit rate. Note that belief propagation was run until 95% and 99% of the nodes were converged in their beliefs. In addition, the seed words with known connotation labels origina</context>
</contexts>
<marker>Baccianella, Esuli, Sebastiani, 2010</marker>
<rawString>Stefano Baccianella, Andrea Esuli, and Fabrizio Sebastiani. 2010. Sentiwordnet 3.0: An enhanced lexical resource for sentiment analysis and opinion mining. In LREC, volume 10, pages 2200–2204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexandra Balahur</author>
<author>Rada Mihalcea</author>
<author>Andr´es Montoyo</author>
</authors>
<title>Computational approaches to subjectivity and sentiment analysis: Present and envisaged methods and applications.</title>
<date>2014</date>
<journal>Computer Speech &amp; Language,</journal>
<volume>28</volume>
<issue>1</issue>
<contexts>
<context position="3400" citStr="Balahur et al. (2014)" startWordPosition="518" endWordPosition="521">t least not as positive as that of the first sense. Especially if we look up the WordNet entry for “bristle”, there are noticeably more negatively connotative words involved in its gloss and examples. This word sense issue has been a universal challenge for a range of Natural Language Processing applications, including sentiment analysis. Recent studies have shown that it is fruitful to tease out subjectivity and objectivity corresponding to different senses of the same word, in order to improve computational approaches to sentiment analysis (e.g. Pestian et al. (2012), Mihalcea et al. (2012) Balahur et al. (2014)). Encouraged by these recent successes, in this study, we investigate if we can attain similar gains if we model the connotative polarity of senses separately. There is one potential practical issue we would like to point out in building a sense-level lexical resource, however. End-users of such a lexicon may not wish to deal with Word Sense Disam1Hence a sense in WordNet is defined by synset (= synonym set), which is the set of words sharing the same sense. 1544 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1544–1554, Baltimore, Maryland, USA,</context>
</contexts>
<marker>Balahur, Mihalcea, Montoyo, 2014</marker>
<rawString>Alexandra Balahur, Rada Mihalcea, and Andr´es Montoyo. 2014. Computational approaches to subjectivity and sentiment analysis: Present and envisaged methods and applications. Computer Speech &amp; Language, 28(1):1–6.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johan Bollen</author>
<author>Huina Mao</author>
<author>Alberto Pepe</author>
</authors>
<title>Modeling public mood and emotion: Twitter sentiment and socio-economic phenomena.</title>
<date>2011</date>
<booktitle>In ICWSM.</booktitle>
<contexts>
<context position="37315" citStr="Bollen et al. (2011)" startWordPosition="6206" endWordPosition="6209">ng sentiment analysis, while Wiebe and Mihalcea (2006) study the distinction between objectivity and subjectivity in each different sense of a word, and their empirical effects in the context of sentiment analysis. Our work shares the high-level spirit of accessing the sense-level polarity, while also deriving the word-level polarity. In recent years, there has been a growing research interest in investigating more fine-grained aspects of lexical sentiment beyond positive and negative sentiment. For example, Mohammad and Turney (2010) study the affects words can evoke in people’s minds, while Bollen et al. (2011) study various moods, e.g., “tension”, “depression”, beyond simple dichotomy of positive and negative sentiment. Our work, and some recent work by Feng et al. (2011) and Feng et al. (2013) share this spirit by targeting more subtle, nuanced sentiment even from those words that would be considered as objective in early studies of sentiment analysis. 8 Conclusion We have introduced a novel formulation of lexicon induction operating over both words and senses, by exploiting the innate structure between the words and senses as encoded in WordNet. In addition, we introduce the use of loopy belief p</context>
</contexts>
<marker>Bollen, Mao, Pepe, 2011</marker>
<rawString>Johan Bollen, Huina Mao, and Alberto Pepe. 2011. Modeling public mood and emotion: Twitter sentiment and socio-economic phenomena. In ICWSM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K W Church</author>
<author>P Hanks</author>
</authors>
<title>Word association norms, mutual information, and lexicography.</title>
<date>1990</date>
<journal>Computational Linguistics,</journal>
<volume>1</volume>
<issue>16</issue>
<contexts>
<context position="21332" citStr="Church and Hanks, 1990" startWordPosition="3545" endWordPosition="3548">ges. The edges can also be weighted based on the distributional similarities of the word pairs. GWORD: The third graph is a super-graph of GWORD W/ OVERLAY, with additional edges, where argument pairs in synonym and antonym relation are connected to each other. Note that unlike the connotation graph GWORD+SENSE, it does not contain any synset nodes. Rather, the words that are synonyms or antonyms of each other are directly linked in the graph. As such, this graph contains all edge types t1 through t4. 5PMI scores are widely used in previous studies to measure association between words (e.g., (Church and Hanks, 1990), (Turney, 2001), (Newman et al., 2009)). t: t1 A P + − + 1-� � − � 1-� t: t4 S S + − + e 1-e − 1-e e 1548 GWORD+SENSE W/ SYNSIM: This is a supergraph of our original GWORD+SENSE graph; that is, it has all the predicate, arguments, and synset nodes, as well as the four types of edges between them. In addition, we add edges of a fifth type t5 between the synset nodes to capture their similarity. To define similarity, we use the glossary definitions of the synsets and derive three different scores. Each score utilizes the count(s1, s2) of overlapping nouns, verbs, and adjectives/adverbs among th</context>
</contexts>
<marker>Church, Hanks, 1990</marker>
<rawString>K. W. Church and P. Hanks. 1990. Word association norms, mutual information, and lexicography. Computational Linguistics, 1(16):22–29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Esuli</author>
<author>Fabrizio Sebastiani</author>
</authors>
<title>Sentiwordnet: A publicly available lexical resource for opinion mining. In</title>
<date>2006</date>
<booktitle>In Proceedings of the 5th Conference on Language Resources and Evaluation (LREC06,</booktitle>
<pages>417--422</pages>
<contexts>
<context position="36090" citStr="Esuli and Sebastiani, 2006" startWordPosition="6016" endWordPosition="6020">e, however, is that in our MRF representation, we can explicitly model various types of word-word, sense-sense and word-sense relations as edge potentials. In particular, we can naturally encode relations that encourage the same assignment (e.g., synonym) as well as the opposite assignment (e.g., antonym) of the polarity labels. Note that integration of the latter is not straightforward in the graph propagation framework. There have been a number of previous studies that aim to construct a word-level sentiment lexicon (Wiebe et al., 2005; Qiu et al., 2009) and a sense-level sentiment lexicon (Esuli and Sebastiani, 2006). But none of these approaches considered to induce the polarity labels at both the word-level and sense-level. Although we focus on learning connotative polarity of words and senses in this paper, the same approach would be applicable to constructing a sentiment lexicon as well. There have been recent studies that address word sense disambiguation issues for sentiment analysis. SentiWordNet (Esuli and Sebastiani, 2006) was the very first lexicon developed for sense-level labels of sentiment polarity. In recent years, Akkaya et al. (2009) report a successful empirical result where WSD helps im</context>
</contexts>
<marker>Esuli, Sebastiani, 2006</marker>
<rawString>Andrea Esuli and Fabrizio Sebastiani. 2006. Sentiwordnet: A publicly available lexical resource for opinion mining. In In Proceedings of the 5th Conference on Language Resources and Evaluation (LREC06, pages 417–422.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Song Feng</author>
<author>Ritwik Bose</author>
<author>Yejin Choi</author>
</authors>
<title>Learning general connotation of words using graph-based algorithms.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1092--1103</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="1114" citStr="Feng et al. (2011)" startWordPosition="156" endWordPosition="159">propagation algorithm for inference. The key aspect of our method is that it is the first unified approach that assigns the polarity of both word- and sense-level connotations, exploiting the innate bipartite graph structure encoded in WordNet. We present comprehensive evaluation to demonstrate the quality and utility of the resulting lexicon in comparison to existing connotation and sentiment lexicons. 1 Introduction We introduce ConnotationWordNet, a connotation lexicon over the network of words in conjunction with senses, as defined in WordNet. A connotation lexicon, as introduced first by Feng et al. (2011), aims to encompass subtle shades of sentiment a word may conjure, even for seemingly objective words such as “sculpture”, “Ph.D.”, “rosettes”. Understanding the rich and complex layers of connotation remains to be a challenging task. As a starting point, we study a more feasible task of learning the polarity of connotation. For non-polysemous words, which constitute a significant portion of English vocabulary, learning the general connotation at the word-level (rather than at the sense-level) would be a natural operational choice. However, for polysemous words, which correspond to most freque</context>
<context position="7344" citStr="Feng et al. (2011)" startWordPosition="1130" endWordPosition="1133">inference (Section 3). We then present comprehensive evaluation (Section 4 &amp; 5 &amp; 6), followed by related work (Section 7) and conclusion (Section 8). 2 Network of Words and Senses The connotation graph, called GWORD+SENSE, is a heterogeneous graph with multiple types of nodes and edges. As shown in Figure 1, it contains two types of nodes; (i) lemmas (i.e., words, 115K) and (ii) synsets (63K), and four types of edges; (t1) predicate-argument (179K), (t2) argumentargument (144K), (t3) argument-synset (126K), and (t4) synset-synset (3.4K) edges. The predicate-argument edges, first introduced by Feng et al. (2011), depict the selectional preference of connotative predicates (i.e., the polarity of a predicate indicates the polarity of its arguments) and encode their co-occurrence relations based on the Google Web 1T corpus. The argumentargument edges are based on the distributional similarities among the arguments. The argumentsynset edges capture the synonymy between argument nodes through the corresponding synsets. Finally, the synset-synset edges depict the antonym relations between synset pairs. In general, our graph construction is similar to that of Feng et al. (2013), but there are a few importan</context>
<context position="37480" citStr="Feng et al. (2011)" startWordPosition="6232" endWordPosition="6235">l effects in the context of sentiment analysis. Our work shares the high-level spirit of accessing the sense-level polarity, while also deriving the word-level polarity. In recent years, there has been a growing research interest in investigating more fine-grained aspects of lexical sentiment beyond positive and negative sentiment. For example, Mohammad and Turney (2010) study the affects words can evoke in people’s minds, while Bollen et al. (2011) study various moods, e.g., “tension”, “depression”, beyond simple dichotomy of positive and negative sentiment. Our work, and some recent work by Feng et al. (2011) and Feng et al. (2013) share this spirit by targeting more subtle, nuanced sentiment even from those words that would be considered as objective in early studies of sentiment analysis. 8 Conclusion We have introduced a novel formulation of lexicon induction operating over both words and senses, by exploiting the innate structure between the words and senses as encoded in WordNet. In addition, we introduce the use of loopy belief propagation over pairwise-Markov Random Fields as an effective lexicon induction algorithm. A notable strength of our approach is its expressiveness: various types of</context>
</contexts>
<marker>Feng, Bose, Choi, 2011</marker>
<rawString>Song Feng, Ritwik Bose, and Yejin Choi. 2011. Learning general connotation of words using graph-based algorithms. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 1092–1103. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Song Feng</author>
<author>Jun Seok Kang</author>
<author>Polina Kuznetsova</author>
<author>Yejin Choi</author>
</authors>
<title>Connotation lexicon: A dash of sentiment beneath the surface meaning.</title>
<date>2013</date>
<booktitle>In The Association for Computer Linguistics,</booktitle>
<pages>1774--1784</pages>
<contexts>
<context position="7914" citStr="Feng et al. (2013)" startWordPosition="1216" endWordPosition="1219">nt edges, first introduced by Feng et al. (2011), depict the selectional preference of connotative predicates (i.e., the polarity of a predicate indicates the polarity of its arguments) and encode their co-occurrence relations based on the Google Web 1T corpus. The argumentargument edges are based on the distributional similarities among the arguments. The argumentsynset edges capture the synonymy between argument nodes through the corresponding synsets. Finally, the synset-synset edges depict the antonym relations between synset pairs. In general, our graph construction is similar to that of Feng et al. (2013), but there are a few important differences. Most notably, we model both words and synsets explicitly, and exploit the membership relations between words and senses. We expect that edges between words and senses will encourage senses that belong to the same word to � put on gain, put on memberships antonyms word sense Pred-Arg Arg-Arg Connotative Predicates prevent losses pain � accident Arguments achewound hurt injure Senses injure, wound suffer lose win, profits, winnings win, gain, acquire life win enjoy profit gain success investment achieve 1545 receive the same connotation label. Convers</context>
<context position="9190" citStr="Feng et al. (2013)" startWordPosition="1418" endWordPosition="1421">that belong to the same sense (i.e., synset definition) to receive the same connotation label. Another benefit of our approach is that for various WordNet relations (e.g., antonym relations), which are defined over synsets (not over words), we can add edges directly between corresponding synsets, rather than projecting (i.e., approximating) those relations over words. Note that the latter, which has been employed by several previous studies (e.g., Kamps et al. (2004), Takamura et al. (2005), Andreevskaia and Bergler (2006), Su and Markert (2009), Lu et al. (2011), Kaji and Kitsuregawa (2007), Feng et al. (2013)), could be a source of noise, as one needs to assume that the semantic relation between a pair of synsets transfers over the pair of words corresponding to that pair of synsets. For polysemous words, this assumption may be overly strong. 3 Pairwise Markov Random Fields and Loopy Belief Propagation We formulate the task of learning sense- and wordlevel connotation lexicon as a graph-based classification task (Sen et al., 2008). More formally, we denote the connotation graph GWORD+SENSE by G = (V, E), in which a total of n word and synset nodes V = {v1, ... , vn} are connected with typed edges </context>
<context position="19854" citStr="Feng et al., 2013" startWordPosition="3302" endWordPosition="3305">is highly likely for any word with positive/negative sentiment to carry connotation of the same polarity. Thus, we use two conventional sentiment lexicons, General Inquirer (GENINQ) (Stone et al., 1966) and MPQA (Wilson et al., 2005b), as surrogates to measure the performance of our inference algorithm. 4.1 Variants of Graph Construction The construction of the connotation graph, denoted by GWORD+SENSE, which includes words and synsets, has been described in Section 2. In addition to this graph, we tried several other graph constructions, the first three of which have previously been used in (Feng et al., 2013). We briefly describe these graphs below, and compare performance on all the graphs in the proceeding. GWORD W/ PRED-ARG: This is a (bipartite) subgraph of GWORD+SENSE, which only includes the connotative predicates and their arguments. As such, it contains only type t1 edges. The edges between the predicates and the arguments can be weighted by their Point-wise Mutual Information (PMI)5 based on the Google Web 1T corpus. GWORD W/ OVERLAY: The second graph is also a proper subgraph of GWORD+SENSE, which includes the predicates and all the argument words. Predicate words are connected to their </context>
<context position="29040" citStr="Feng et al., 2013" startWordPosition="4858" endWordPosition="4861">on We first evaluate the word-level assignment of connotation, as shown in Table 3. The agreement between the new lexicon and human judges varies between 84% and 86.98%. Sentiment lexicons such as SentiWordNet (Baccianella et al. (2010)) and OpinionFinder (Wilson et al. (2005a)) show low agreement rate with human, which is somewhat as expected: human judges in this study are labeling for subtle connotation, not for more explicit sentiment. OpinionFinder’s low agreement rate was mainly due to the low hit rate of the words (successful look-up rate, 33.43%). Feng2013 is the lexicon presented in (Feng et al., 2013) and it showed a relatively higher 72.13% hit rate. Note that belief propagation was run until 95% and 99% of the nodes were converged in their beliefs. In addition, the seed words with known connotation labels originally consist of 20 positive and 20 negative predicates. We also extended the seed set with the sentiment lexicon words and denote these runs with E- for ‘Extended’. 5.2 Sense-Level Evaluation We also examined the agreement rates on the sense-level. Since OpinionFinder and Feng2013 do not provide the polarity scores at the senselevel, we excluded them from this evaluation. Because </context>
<context position="32942" citStr="Feng et al., 2013" startWordPosition="5497" endWordPosition="5500">nalysis. We experiment with SemEval dataset (Strapparava and Mihalcea, 2007) that includes the human labeled dataset for predicting whether a news headline is a good news or a bad news, which we expect to have a correlation with the use of connotative words that we focus on in this paper. The good/bad news are annotated with scores (ranging from -100 to 87). We construct several data sets by applying different thresholds on scores. For example, with the threshold set to 60, we discard the instances whose scores lie between -60 and 60. For comparison, we also test the connotation lexicon from (Feng et al., 2013) and the combined sentiment lexicon GENINQ+MPQA. Note that there is a difference in how humans judge the orientation and the degree of connotation for a given word out of context, and how the use of such words in context can be perceived as good/bad news. In particular, we conjecture that humans may have a bias toward the use of positive words, which in turn requires calibration from the readers’ minds (Pennebaker and Stone, 2003). That is, we might need to tone down the level of positiveness in order to correctly measure the actual intended positiveness of the message. With this in mind, we t</context>
<context position="35206" citStr="Feng et al., 2013" startWordPosition="5877" endWordPosition="5880">ameter search does not change the results much. 0.5 1.0 2.0 3.0 Accuracy (%) 80 40 60 SentiWordNet GWord+Sense(95%) GWord+Sense(99%) e-GWord+Sense(95%) e-GWord+Sense(99%) 1551 Lexicon SemEval Threshold 20 40 60 80 Instance Size 955 649 341 86 Feng2013 71.5 77.1 81.6 90.5 GENINQ+MPQA 72.8 77.2 80.4 86.7 GWORD+SENSE(95%) 74.5 79.4 86.5 91.9 GWORD+SENSE(99%) 74.6 79.4 86.8 91.9 E-GWORD+SENSE(95%) 72.5 76.8 82.3 87.2 E-GWORD+SENSE(99%) 72.6 76.9 82.5 87.2 Feng2013* 70.8 74.6 80.8 93.5 GENINQ+MPQA* 64.5 69.0 74.0 80.5 Figure 4: Trend of SemEval performance over N, the number of CV folds induction (Feng et al., 2013). Our work introduces the use of loopy belief propagation over pairwise-MRF as an alternative solution to these tasks. At a high-level, both approaches share the general idea of propagating confidence or belief over the graph connectivity. The key difference, however, is that in our MRF representation, we can explicitly model various types of word-word, sense-sense and word-sense relations as edge potentials. In particular, we can naturally encode relations that encourage the same assignment (e.g., synonym) as well as the opposite assignment (e.g., antonym) of the polarity labels. Note that in</context>
<context position="37503" citStr="Feng et al. (2013)" startWordPosition="6237" endWordPosition="6240">t of sentiment analysis. Our work shares the high-level spirit of accessing the sense-level polarity, while also deriving the word-level polarity. In recent years, there has been a growing research interest in investigating more fine-grained aspects of lexical sentiment beyond positive and negative sentiment. For example, Mohammad and Turney (2010) study the affects words can evoke in people’s minds, while Bollen et al. (2011) study various moods, e.g., “tension”, “depression”, beyond simple dichotomy of positive and negative sentiment. Our work, and some recent work by Feng et al. (2011) and Feng et al. (2013) share this spirit by targeting more subtle, nuanced sentiment even from those words that would be considered as objective in early studies of sentiment analysis. 8 Conclusion We have introduced a novel formulation of lexicon induction operating over both words and senses, by exploiting the innate structure between the words and senses as encoded in WordNet. In addition, we introduce the use of loopy belief propagation over pairwise-Markov Random Fields as an effective lexicon induction algorithm. A notable strength of our approach is its expressiveness: various types of prior knowledge and le</context>
</contexts>
<marker>Feng, Kang, Kuznetsova, Choi, 2013</marker>
<rawString>Song Feng, Jun Seok Kang, Polina Kuznetsova, and Yejin Choi. 2013. Connotation lexicon: A dash of sentiment beneath the surface meaning. In The Association for Computer Linguistics, pages 1774– 1784.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vasileios Hatzivassiloglou</author>
<author>Kathleen McKeown</author>
</authors>
<title>Predicting the semantic orientation of adjectives.</title>
<date>1997</date>
<booktitle>In Proceedings of the Joint ACL/EACL Conference,</booktitle>
<pages>174--181</pages>
<contexts>
<context position="20634" citStr="Hatzivassiloglou and McKeown, 1997" startWordPosition="3428" endWordPosition="3431">bgraph of GWORD+SENSE, which only includes the connotative predicates and their arguments. As such, it contains only type t1 edges. The edges between the predicates and the arguments can be weighted by their Point-wise Mutual Information (PMI)5 based on the Google Web 1T corpus. GWORD W/ OVERLAY: The second graph is also a proper subgraph of GWORD+SENSE, which includes the predicates and all the argument words. Predicate words are connected to their arguments as before. In addition, argument pairs (a1, a2) are connected if they occurred together in the “a1 and a2” or “a2 and a1” coordination (Hatzivassiloglou and McKeown, 1997; Pickering and Branigan, 1998). This graph contains both type t1 and t2 edges. The edges can also be weighted based on the distributional similarities of the word pairs. GWORD: The third graph is a super-graph of GWORD W/ OVERLAY, with additional edges, where argument pairs in synonym and antonym relation are connected to each other. Note that unlike the connotation graph GWORD+SENSE, it does not contain any synset nodes. Rather, the words that are synonyms or antonyms of each other are directly linked in the graph. As such, this graph contains all edge types t1 through t4. 5PMI scores are wi</context>
</contexts>
<marker>Hatzivassiloglou, McKeown, 1997</marker>
<rawString>Vasileios Hatzivassiloglou and Kathleen McKeown. 1997. Predicting the semantic orientation of adjectives. In Proceedings of the Joint ACL/EACL Conference, pages 174–181.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nobuhiro Kaji</author>
<author>Masaru Kitsuregawa</author>
</authors>
<title>Building lexicon for sentiment analysis from massive collection of html documents.</title>
<date>2007</date>
<booktitle>In EMNLP-CoNLL,</booktitle>
<pages>1075--1083</pages>
<contexts>
<context position="9170" citStr="Kaji and Kitsuregawa (2007)" startWordPosition="1413" endWordPosition="1417">es will also encourage words that belong to the same sense (i.e., synset definition) to receive the same connotation label. Another benefit of our approach is that for various WordNet relations (e.g., antonym relations), which are defined over synsets (not over words), we can add edges directly between corresponding synsets, rather than projecting (i.e., approximating) those relations over words. Note that the latter, which has been employed by several previous studies (e.g., Kamps et al. (2004), Takamura et al. (2005), Andreevskaia and Bergler (2006), Su and Markert (2009), Lu et al. (2011), Kaji and Kitsuregawa (2007), Feng et al. (2013)), could be a source of noise, as one needs to assume that the semantic relation between a pair of synsets transfers over the pair of words corresponding to that pair of synsets. For polysemous words, this assumption may be overly strong. 3 Pairwise Markov Random Fields and Loopy Belief Propagation We formulate the task of learning sense- and wordlevel connotation lexicon as a graph-based classification task (Sen et al., 2008). More formally, we denote the connotation graph GWORD+SENSE by G = (V, E), in which a total of n word and synset nodes V = {v1, ... , vn} are connect</context>
</contexts>
<marker>Kaji, Kitsuregawa, 2007</marker>
<rawString>Nobuhiro Kaji and Masaru Kitsuregawa. 2007. Building lexicon for sentiment analysis from massive collection of html documents. In EMNLP-CoNLL, pages 1075–1083.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jaap Kamps</author>
<author>MJ Marx</author>
<author>Robert J Mokken</author>
<author>Maarten De Rijke</author>
</authors>
<title>Using wordnet to measure semantic orientations of adjectives.</title>
<date>2004</date>
<marker>Kamps, Marx, Mokken, De Rijke, 2004</marker>
<rawString>Jaap Kamps, MJ Marx, Robert J Mokken, and Maarten De Rijke. 2004. Using wordnet to measure semantic orientations of adjectives.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ross Kindermann</author>
<author>J L Snell</author>
</authors>
<title>Markov Random Fields and Their Applications.</title>
<date>1980</date>
<contexts>
<context position="10567" citStr="Kindermann and Snell, 1980" startWordPosition="1664" endWordPosition="1668">tion N, where Nv = {u |e(u, v) ∈ E} ⊆ V , describes the underlying network structure. In our collective classification formulation, each node in V is represented as a random variable that takes a value from an appropriate class label domain; in our case, L = {+, −} for positive and negative connotation. In this classification task, we denote by Y the nodes the labels of which need to be assigned, and let yi refer to Yi’s label. 3.1 Pairwise Markov Random Fields We next define our objective function. We propose to use an objective formulation that utilizes pairwise Markov Random Fields (MRFs) (Kindermann and Snell, 1980), which we adapt to our problem setting. MRFs are a class of probabilistic graphical models that are suited for solving inference problems in networked data. An MRF consists of an undirected graph where each node can be in any of a finite number of states (i.e., class labels). The state of a node is assumed to be dependent on each of its neighbors and independent of other nodes in the graph.2 In pairwise MRFs, the joint probability of the graph can be written as a product of pairwise factors, parameterized over the edges. These factors are referred to as clique potentials in general MRFs, whic</context>
</contexts>
<marker>Kindermann, Snell, 1980</marker>
<rawString>Ross Kindermann and J. L. Snell. 1980. Markov Random Fields and Their Applications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yue Lu</author>
<author>Malu Castellanos</author>
<author>Umeshwar Dayal</author>
<author>ChengXiang Zhai</author>
</authors>
<title>Automatic construction of a context-aware sentiment lexicon: an optimization approach.</title>
<date>2011</date>
<booktitle>In Proceedings of the 20th international conference on World wide web,</booktitle>
<pages>347--356</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="9141" citStr="Lu et al. (2011)" startWordPosition="1409" endWordPosition="1412">ect that these edges will also encourage words that belong to the same sense (i.e., synset definition) to receive the same connotation label. Another benefit of our approach is that for various WordNet relations (e.g., antonym relations), which are defined over synsets (not over words), we can add edges directly between corresponding synsets, rather than projecting (i.e., approximating) those relations over words. Note that the latter, which has been employed by several previous studies (e.g., Kamps et al. (2004), Takamura et al. (2005), Andreevskaia and Bergler (2006), Su and Markert (2009), Lu et al. (2011), Kaji and Kitsuregawa (2007), Feng et al. (2013)), could be a source of noise, as one needs to assume that the semantic relation between a pair of synsets transfers over the pair of words corresponding to that pair of synsets. For polysemous words, this assumption may be overly strong. 3 Pairwise Markov Random Fields and Loopy Belief Propagation We formulate the task of learning sense- and wordlevel connotation lexicon as a graph-based classification task (Sen et al., 2008). More formally, we denote the connotation graph GWORD+SENSE by G = (V, E), in which a total of n word and synset nodes V</context>
</contexts>
<marker>Lu, Castellanos, Dayal, Zhai, 2011</marker>
<rawString>Yue Lu, Malu Castellanos, Umeshwar Dayal, and ChengXiang Zhai. 2011. Automatic construction of a context-aware sentiment lexicon: an optimization approach. In Proceedings of the 20th international conference on World wide web, pages 347– 356. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mary McGlohon</author>
<author>Stephen Bay</author>
<author>Markus G Anderle</author>
<author>David M Steier</author>
<author>Christos Faloutsos</author>
</authors>
<title>Snare: a link analytic system for graph labeling and risk detection. In</title>
<date>2009</date>
<pages>1265--1274</pages>
<editor>John F. Elder IV, Franoise Fogelman-Souli, Peter A. Flach, and Mohammed Zaki, editors, KDD,</editor>
<publisher>ACM.</publisher>
<contexts>
<context position="17012" citStr="McGlohon et al., 2009" startWordPosition="2805" endWordPosition="2808"> their connotation sentiment (e.g., enjoy is positive, suffer is negative). As such, our method is flexible to integrate available side information. In case there is no prior knowledge available, each node is initialized equally likely to have any of the possible labels, i.e., 1 |L |as in Algorithm 1 (line 9). Compatibilities The compatibility potentials can be thought of as matrices, with entries 3Although convergence is not theoretically guaranteed, in practice LBP converges to beliefs within a small threshold of change (e.g., 10−6) fairly quickly with accurate results (Pandit et al., 2007; McGlohon et al., 2009; Akoglu et al., 2013). 1547 ψtij(yi, yj) that give the likelihood of a node having label yi, given that it has a neighbor with label yj to which it is connected through a type t edge. A key difference of our method from earlier models is that we use clique potentials that differ for edge types, since the connotation graph is heterogeneous. This is exactly because the compatibility of class labels of two adjacent nodes depends on the type of the edge connecting them: e.g., syn-arg + −−−−−→ + is highly compatible, whereas + syn-syn −−−−−→ + is unlikely; as syn-arg edges capture synonymy; i.e., </context>
</contexts>
<marker>McGlohon, Bay, Anderle, Steier, Faloutsos, 2009</marker>
<rawString>Mary McGlohon, Stephen Bay, Markus G. Anderle, David M. Steier, and Christos Faloutsos. 2009. Snare: a link analytic system for graph labeling and risk detection. In John F. Elder IV, Franoise Fogelman-Souli, Peter A. Flach, and Mohammed Zaki, editors, KDD, pages 1265–1274. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
<author>Carmen Banea</author>
<author>Janyce Wiebe</author>
</authors>
<title>Multilingual subjectivity and sentiment analysis.</title>
<date>2012</date>
<booktitle>In Tutorial Abstracts of ACL 2012,</booktitle>
<pages>4--4</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="3378" citStr="Mihalcea et al. (2012)" startWordPosition="514" endWordPosition="517">of unpleasantness, or at least not as positive as that of the first sense. Especially if we look up the WordNet entry for “bristle”, there are noticeably more negatively connotative words involved in its gloss and examples. This word sense issue has been a universal challenge for a range of Natural Language Processing applications, including sentiment analysis. Recent studies have shown that it is fruitful to tease out subjectivity and objectivity corresponding to different senses of the same word, in order to improve computational approaches to sentiment analysis (e.g. Pestian et al. (2012), Mihalcea et al. (2012) Balahur et al. (2014)). Encouraged by these recent successes, in this study, we investigate if we can attain similar gains if we model the connotative polarity of senses separately. There is one potential practical issue we would like to point out in building a sense-level lexical resource, however. End-users of such a lexicon may not wish to deal with Word Sense Disam1Hence a sense in WordNet is defined by synset (= synonym set), which is the set of words sharing the same sense. 1544 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1544–1554, Bal</context>
</contexts>
<marker>Mihalcea, Banea, Wiebe, 2012</marker>
<rawString>Rada Mihalcea, Carmen Banea, and Janyce Wiebe. 2012. Multilingual subjectivity and sentiment analysis. In Tutorial Abstracts of ACL 2012, pages 4–4. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saif Mohammad</author>
<author>Peter Turney</author>
</authors>
<title>Emotions evoked by common words and phrases: Using mechanical turk to create an emotion lexicon.</title>
<date>2010</date>
<booktitle>In Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text,</booktitle>
<pages>26--34</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Los Angeles, CA,</location>
<contexts>
<context position="37235" citStr="Mohammad and Turney (2010)" startWordPosition="6192" endWordPosition="6195">ars, Akkaya et al. (2009) report a successful empirical result where WSD helps improving sentiment analysis, while Wiebe and Mihalcea (2006) study the distinction between objectivity and subjectivity in each different sense of a word, and their empirical effects in the context of sentiment analysis. Our work shares the high-level spirit of accessing the sense-level polarity, while also deriving the word-level polarity. In recent years, there has been a growing research interest in investigating more fine-grained aspects of lexical sentiment beyond positive and negative sentiment. For example, Mohammad and Turney (2010) study the affects words can evoke in people’s minds, while Bollen et al. (2011) study various moods, e.g., “tension”, “depression”, beyond simple dichotomy of positive and negative sentiment. Our work, and some recent work by Feng et al. (2011) and Feng et al. (2013) share this spirit by targeting more subtle, nuanced sentiment even from those words that would be considered as objective in early studies of sentiment analysis. 8 Conclusion We have introduced a novel formulation of lexicon induction operating over both words and senses, by exploiting the innate structure between the words and s</context>
</contexts>
<marker>Mohammad, Turney, 2010</marker>
<rawString>Saif Mohammad and Peter Turney. 2010. Emotions evoked by common words and phrases: Using mechanical turk to create an emotion lexicon. In Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text, pages 26–34, Los Angeles, CA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Newman</author>
<author>Sarvnaz Karimi</author>
<author>Lawrence Cavedon</author>
</authors>
<title>External evaluation of topic models.</title>
<date>2009</date>
<booktitle>In Australasian Document Computing Symposium,</booktitle>
<pages>11--18</pages>
<location>Sydney,</location>
<contexts>
<context position="21371" citStr="Newman et al., 2009" startWordPosition="3551" endWordPosition="3554">on the distributional similarities of the word pairs. GWORD: The third graph is a super-graph of GWORD W/ OVERLAY, with additional edges, where argument pairs in synonym and antonym relation are connected to each other. Note that unlike the connotation graph GWORD+SENSE, it does not contain any synset nodes. Rather, the words that are synonyms or antonyms of each other are directly linked in the graph. As such, this graph contains all edge types t1 through t4. 5PMI scores are widely used in previous studies to measure association between words (e.g., (Church and Hanks, 1990), (Turney, 2001), (Newman et al., 2009)). t: t1 A P + − + 1-� � − � 1-� t: t4 S S + − + e 1-e − 1-e e 1548 GWORD+SENSE W/ SYNSIM: This is a supergraph of our original GWORD+SENSE graph; that is, it has all the predicate, arguments, and synset nodes, as well as the four types of edges between them. In addition, we add edges of a fifth type t5 between the synset nodes to capture their similarity. To define similarity, we use the glossary definitions of the synsets and derive three different scores. Each score utilizes the count(s1, s2) of overlapping nouns, verbs, and adjectives/adverbs among the glosses of the two synsets s1 and s2.</context>
</contexts>
<marker>Newman, Karimi, Cavedon, 2009</marker>
<rawString>David Newman, Sarvnaz Karimi, and Lawrence Cavedon. 2009. External evaluation of topic models. In Australasian Document Computing Symposium, pages 11–18, Sydney, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shashank Pandit</author>
<author>Duen Horng Chau</author>
<author>Samuel Wang</author>
<author>Christos Faloutsos</author>
</authors>
<title>Netprobe: a fast and scalable system for fraud detection in online auction networks.</title>
<date>2007</date>
<booktitle>In WWW,</booktitle>
<pages>201--210</pages>
<contexts>
<context position="16989" citStr="Pandit et al., 2007" startWordPosition="2800" endWordPosition="2804">y prior knowledge for their connotation sentiment (e.g., enjoy is positive, suffer is negative). As such, our method is flexible to integrate available side information. In case there is no prior knowledge available, each node is initialized equally likely to have any of the possible labels, i.e., 1 |L |as in Algorithm 1 (line 9). Compatibilities The compatibility potentials can be thought of as matrices, with entries 3Although convergence is not theoretically guaranteed, in practice LBP converges to beliefs within a small threshold of change (e.g., 10−6) fairly quickly with accurate results (Pandit et al., 2007; McGlohon et al., 2009; Akoglu et al., 2013). 1547 ψtij(yi, yj) that give the likelihood of a node having label yi, given that it has a neighbor with label yj to which it is connected through a type t edge. A key difference of our method from earlier models is that we use clique potentials that differ for edge types, since the connotation graph is heterogeneous. This is exactly because the compatibility of class labels of two adjacent nodes depends on the type of the edge connecting them: e.g., syn-arg + −−−−−→ + is highly compatible, whereas + syn-syn −−−−−→ + is unlikely; as syn-arg edges c</context>
</contexts>
<marker>Pandit, Chau, Wang, Faloutsos, 2007</marker>
<rawString>Shashank Pandit, Duen Horng Chau, Samuel Wang, and Christos Faloutsos. 2007. Netprobe: a fast and scalable system for fraud detection in online auction networks. In WWW, pages 201–210.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christos H Papadimitriou</author>
<author>Kenneth Steiglitz</author>
</authors>
<title>Combinatorial optimization: algorithms and complexity.</title>
<date>1998</date>
<publisher>Courier Dover Publications.</publisher>
<contexts>
<context position="6182" citStr="Papadimitriou and Steiglitz, 1998" startWordPosition="949" endWordPosition="953">roduction of loopy belief propagation (loopy-BP) as a lexicon induction algorithm. Loopy-BP in our study achieves statistically significantly better performance over the constraint optimization approaches previously explored. In addition, it runs much faster and it is considerably easier to implement. Last but not least, by using probabilistic representation of pairwise-MRF in conjunction with Loopy-BP as inference, the resulting solution has the natural interpretation as the intensity of connotation. This contrasts to approaches that seek discrete solutions such as Integer Linear Programming(Papadimitriou and Steiglitz, 1998). ConnotationWordNet, the final outcome of our study, is a new lexical resource that has connotation labels over both words and senses following the structure of WordNet. The lexicon is publicly available at: http://www.cs.sunysb. edu/˜junkang/connotation_wordnet.) In what follows, we will first describe the netFigure 1: GWORD+SENSE with words and senses. work of words and senses (Section 2), then introduce the representation of the network structure as pairwise Markov Random Fields, and a loopy belief propagation algorithm as collective inference (Section 3). We then present comprehensive eva</context>
</contexts>
<marker>Papadimitriou, Steiglitz, 1998</marker>
<rawString>Christos H Papadimitriou and Kenneth Steiglitz. 1998. Combinatorial optimization: algorithms and complexity. Courier Dover Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James W Pennebaker</author>
<author>Lori D Stone</author>
</authors>
<title>Words of wisdom: language use over the life span. Journal ofpersonality and social psychology,</title>
<date>2003</date>
<pages>85--2</pages>
<contexts>
<context position="33376" citStr="Pennebaker and Stone, 2003" startWordPosition="5574" endWordPosition="5577">on scores. For example, with the threshold set to 60, we discard the instances whose scores lie between -60 and 60. For comparison, we also test the connotation lexicon from (Feng et al., 2013) and the combined sentiment lexicon GENINQ+MPQA. Note that there is a difference in how humans judge the orientation and the degree of connotation for a given word out of context, and how the use of such words in context can be perceived as good/bad news. In particular, we conjecture that humans may have a bias toward the use of positive words, which in turn requires calibration from the readers’ minds (Pennebaker and Stone, 2003). That is, we might need to tone down the level of positiveness in order to correctly measure the actual intended positiveness of the message. With this in mind, we tune the appropriate calibration from a small training data, by using 1 fold from N fold cross validation, and using the remaining N − 1 folds as testing. We simply learn the mixture coefficient A to scale the contribution of positive and negative connotation values. We tune this parameter A8 for other lexicons we compare against as well. Note that due to this parameter learning, we are able to report better performance for the con</context>
</contexts>
<marker>Pennebaker, Stone, 2003</marker>
<rawString>James W Pennebaker and Lori D Stone. 2003. Words of wisdom: language use over the life span. Journal ofpersonality and social psychology, 85(2):291.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John P Pestian</author>
<author>Pawel Matykiewicz</author>
<author>Michelle LinnGust</author>
<author>Brett South</author>
<author>Ozlem Uzuner</author>
<author>Jan Wiebe</author>
<author>K Bretonnel Cohen</author>
<author>John Hurdle</author>
<author>Christopher Brew</author>
</authors>
<title>Sentiment analysis of suicide notes: A shared task. Biomedical Informatics Insights,</title>
<date>2012</date>
<pages>5--1</pages>
<contexts>
<context position="3354" citStr="Pestian et al. (2012)" startWordPosition="510" endWordPosition="513"> negative with a touch of unpleasantness, or at least not as positive as that of the first sense. Especially if we look up the WordNet entry for “bristle”, there are noticeably more negatively connotative words involved in its gloss and examples. This word sense issue has been a universal challenge for a range of Natural Language Processing applications, including sentiment analysis. Recent studies have shown that it is fruitful to tease out subjectivity and objectivity corresponding to different senses of the same word, in order to improve computational approaches to sentiment analysis (e.g. Pestian et al. (2012), Mihalcea et al. (2012) Balahur et al. (2014)). Encouraged by these recent successes, in this study, we investigate if we can attain similar gains if we model the connotative polarity of senses separately. There is one potential practical issue we would like to point out in building a sense-level lexical resource, however. End-users of such a lexicon may not wish to deal with Word Sense Disam1Hence a sense in WordNet is defined by synset (= synonym set), which is the set of words sharing the same sense. 1544 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguisti</context>
</contexts>
<marker>Pestian, Matykiewicz, LinnGust, South, Uzuner, Wiebe, Cohen, Hurdle, Brew, 2012</marker>
<rawString>John P Pestian, Pawel Matykiewicz, Michelle LinnGust, Brett South, Ozlem Uzuner, Jan Wiebe, K Bretonnel Cohen, John Hurdle, Christopher Brew, et al. 2012. Sentiment analysis of suicide notes: A shared task. Biomedical Informatics Insights, 5(Suppl. 1):3.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin J Pickering</author>
<author>Holly P Branigan</author>
</authors>
<title>The representation of verbs: Evidence from syntactic priming in language production.</title>
<date>1998</date>
<journal>Journal of Memory and Language,</journal>
<pages>39--633</pages>
<contexts>
<context position="20665" citStr="Pickering and Branigan, 1998" startWordPosition="3432" endWordPosition="3435">cludes the connotative predicates and their arguments. As such, it contains only type t1 edges. The edges between the predicates and the arguments can be weighted by their Point-wise Mutual Information (PMI)5 based on the Google Web 1T corpus. GWORD W/ OVERLAY: The second graph is also a proper subgraph of GWORD+SENSE, which includes the predicates and all the argument words. Predicate words are connected to their arguments as before. In addition, argument pairs (a1, a2) are connected if they occurred together in the “a1 and a2” or “a2 and a1” coordination (Hatzivassiloglou and McKeown, 1997; Pickering and Branigan, 1998). This graph contains both type t1 and t2 edges. The edges can also be weighted based on the distributional similarities of the word pairs. GWORD: The third graph is a super-graph of GWORD W/ OVERLAY, with additional edges, where argument pairs in synonym and antonym relation are connected to each other. Note that unlike the connotation graph GWORD+SENSE, it does not contain any synset nodes. Rather, the words that are synonyms or antonyms of each other are directly linked in the graph. As such, this graph contains all edge types t1 through t4. 5PMI scores are widely used in previous studies t</context>
</contexts>
<marker>Pickering, Branigan, 1998</marker>
<rawString>Martin J. Pickering and Holly P. Branigan. 1998. The representation of verbs: Evidence from syntactic priming in language production. Journal of Memory and Language, 39:633–651.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guang Qiu</author>
<author>Bing Liu</author>
<author>Jiajun Bu</author>
<author>Chun Chen</author>
</authors>
<title>Expanding domain sentiment lexicon through double propagation.</title>
<date>2009</date>
<booktitle>In IJCAI,</booktitle>
<volume>9</volume>
<pages>1199--1204</pages>
<contexts>
<context position="36025" citStr="Qiu et al., 2009" startWordPosition="6007" endWordPosition="6010">r belief over the graph connectivity. The key difference, however, is that in our MRF representation, we can explicitly model various types of word-word, sense-sense and word-sense relations as edge potentials. In particular, we can naturally encode relations that encourage the same assignment (e.g., synonym) as well as the opposite assignment (e.g., antonym) of the polarity labels. Note that integration of the latter is not straightforward in the graph propagation framework. There have been a number of previous studies that aim to construct a word-level sentiment lexicon (Wiebe et al., 2005; Qiu et al., 2009) and a sense-level sentiment lexicon (Esuli and Sebastiani, 2006). But none of these approaches considered to induce the polarity labels at both the word-level and sense-level. Although we focus on learning connotative polarity of words and senses in this paper, the same approach would be applicable to constructing a sentiment lexicon as well. There have been recent studies that address word sense disambiguation issues for sentiment analysis. SentiWordNet (Esuli and Sebastiani, 2006) was the very first lexicon developed for sense-level labels of sentiment polarity. In recent years, Akkaya et a</context>
</contexts>
<marker>Qiu, Liu, Bu, Chen, 2009</marker>
<rawString>Guang Qiu, Bing Liu, Jiajun Bu, and Chun Chen. 2009. Expanding domain sentiment lexicon through double propagation. In IJCAI, volume 9, pages 1199–1204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Prithviraj Sen</author>
<author>Galileo Namata</author>
<author>Mustafa Bilgic</author>
<author>Lise Getoor</author>
<author>Brian Gallagher</author>
<author>Tina Eliassi-Rad</author>
</authors>
<title>Collective classification in network data.</title>
<date>2008</date>
<journal>AI Magazine,</journal>
<volume>29</volume>
<issue>3</issue>
<contexts>
<context position="9620" citStr="Sen et al., 2008" startWordPosition="1492" endWordPosition="1495">vious studies (e.g., Kamps et al. (2004), Takamura et al. (2005), Andreevskaia and Bergler (2006), Su and Markert (2009), Lu et al. (2011), Kaji and Kitsuregawa (2007), Feng et al. (2013)), could be a source of noise, as one needs to assume that the semantic relation between a pair of synsets transfers over the pair of words corresponding to that pair of synsets. For polysemous words, this assumption may be overly strong. 3 Pairwise Markov Random Fields and Loopy Belief Propagation We formulate the task of learning sense- and wordlevel connotation lexicon as a graph-based classification task (Sen et al., 2008). More formally, we denote the connotation graph GWORD+SENSE by G = (V, E), in which a total of n word and synset nodes V = {v1, ... , vn} are connected with typed edges e(vi, vj, t) ∈ E, where edge types t ∈ {pred-arg, arg-arg, syn-arg, syn-syn} depict the four edge types as described in Section 2. A neighborhood function N, where Nv = {u |e(u, v) ∈ E} ⊆ V , describes the underlying network structure. In our collective classification formulation, each node in V is represented as a random variable that takes a value from an appropriate class label domain; in our case, L = {+, −} for positive a</context>
</contexts>
<marker>Sen, Namata, Bilgic, Getoor, Gallagher, Eliassi-Rad, 2008</marker>
<rawString>Prithviraj Sen, Galileo Namata, Mustafa Bilgic, Lise Getoor, Brian Gallagher, and Tina Eliassi-Rad. 2008. Collective classification in network data. AI Magazine, 29(3):93–106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip J Stone</author>
<author>Dexter C Dunphy</author>
<author>Marshall S Smith</author>
<author>Daniel M Ogilvie</author>
</authors>
<title>The General Inquirer: A Computer Approach to Content Analysis.</title>
<date>1966</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="19438" citStr="Stone et al., 1966" startWordPosition="3233" endWordPosition="3236">with the number of edges and is scalable to large datasets. 4arg-arg edges are based on co-occurrence (see Section 2), which does not carry as strong indication of the same connotation as e.g., synonymy. Thus, we enforce less homophily for nodes connected through edges of arg-arg type. 4 Evaluation I: Agreement with Sentiment Lexicons ConnotationWordNet is expected to be the superset of a sentiment lexicon, as it is highly likely for any word with positive/negative sentiment to carry connotation of the same polarity. Thus, we use two conventional sentiment lexicons, General Inquirer (GENINQ) (Stone et al., 1966) and MPQA (Wilson et al., 2005b), as surrogates to measure the performance of our inference algorithm. 4.1 Variants of Graph Construction The construction of the connotation graph, denoted by GWORD+SENSE, which includes words and synsets, has been described in Section 2. In addition to this graph, we tried several other graph constructions, the first three of which have previously been used in (Feng et al., 2013). We briefly describe these graphs below, and compare performance on all the graphs in the proceeding. GWORD W/ PRED-ARG: This is a (bipartite) subgraph of GWORD+SENSE, which only incl</context>
</contexts>
<marker>Stone, Dunphy, Smith, Ogilvie, 1966</marker>
<rawString>Philip J. Stone, Dexter C. Dunphy, Marshall S. Smith, and Daniel M. Ogilvie. 1966. The General Inquirer: A Computer Approach to Content Analysis. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carlo Strapparava</author>
<author>Rada Mihalcea</author>
</authors>
<title>Semeval2007 task 14: Affective text.</title>
<date>2007</date>
<booktitle>In Proceedings of the 4th International Workshop on Semantic Evaluations,</booktitle>
<pages>70--74</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="32400" citStr="Strapparava and Mihalcea, 2007" startWordPosition="5397" endWordPosition="5401">), our connotation lexicons perform surprisingly well, reaching up to 74.83% accuracy. Further study on the incorrect cases reveals that SentiWordNet has many pair of words with the same polarity score (23.34%). Such cases seems to be due to the limited score patterns of SentiWordNet. The ratio of such cases are accounted as Undecided in Table 4. 6 Evaluation III: Sentiment Analysis using ConnotationWordNet Finally, to show the utility of the resulting lexicon in the context of a concrete sentiment analysis task, we perform lexicon-based sentiment analysis. We experiment with SemEval dataset (Strapparava and Mihalcea, 2007) that includes the human labeled dataset for predicting whether a news headline is a good news or a bad news, which we expect to have a correlation with the use of connotative words that we focus on in this paper. The good/bad news are annotated with scores (ranging from -100 to 87). We construct several data sets by applying different thresholds on scores. For example, with the threshold set to 60, we discard the instances whose scores lie between -60 and 60. For comparison, we also test the connotation lexicon from (Feng et al., 2013) and the combined sentiment lexicon GENINQ+MPQA. Note that</context>
</contexts>
<marker>Strapparava, Mihalcea, 2007</marker>
<rawString>Carlo Strapparava and Rada Mihalcea. 2007. Semeval2007 task 14: Affective text. In Proceedings of the 4th International Workshop on Semantic Evaluations, pages 70–74. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fangzhong Su</author>
<author>Katja Markert</author>
</authors>
<title>Subjectivity recognition on word senses via semi-supervised mincuts.</title>
<date>2009</date>
<booktitle>In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>1--9</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="9123" citStr="Su and Markert (2009)" startWordPosition="1405" endWordPosition="1408">bel. Conversely, we expect that these edges will also encourage words that belong to the same sense (i.e., synset definition) to receive the same connotation label. Another benefit of our approach is that for various WordNet relations (e.g., antonym relations), which are defined over synsets (not over words), we can add edges directly between corresponding synsets, rather than projecting (i.e., approximating) those relations over words. Note that the latter, which has been employed by several previous studies (e.g., Kamps et al. (2004), Takamura et al. (2005), Andreevskaia and Bergler (2006), Su and Markert (2009), Lu et al. (2011), Kaji and Kitsuregawa (2007), Feng et al. (2013)), could be a source of noise, as one needs to assume that the semantic relation between a pair of synsets transfers over the pair of words corresponding to that pair of synsets. For polysemous words, this assumption may be overly strong. 3 Pairwise Markov Random Fields and Loopy Belief Propagation We formulate the task of learning sense- and wordlevel connotation lexicon as a graph-based classification task (Sen et al., 2008). More formally, we denote the connotation graph GWORD+SENSE by G = (V, E), in which a total of n word </context>
</contexts>
<marker>Su, Markert, 2009</marker>
<rawString>Fangzhong Su and Katja Markert. 2009. Subjectivity recognition on word senses via semi-supervised mincuts. In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 1–9. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroya Takamura</author>
<author>Takashi Inui</author>
<author>Manabu Okumura</author>
</authors>
<title>Extracting semantic orientations of words using spin model.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>133--140</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="9067" citStr="Takamura et al. (2005)" startWordPosition="1397" endWordPosition="1400">s investment achieve 1545 receive the same connotation label. Conversely, we expect that these edges will also encourage words that belong to the same sense (i.e., synset definition) to receive the same connotation label. Another benefit of our approach is that for various WordNet relations (e.g., antonym relations), which are defined over synsets (not over words), we can add edges directly between corresponding synsets, rather than projecting (i.e., approximating) those relations over words. Note that the latter, which has been employed by several previous studies (e.g., Kamps et al. (2004), Takamura et al. (2005), Andreevskaia and Bergler (2006), Su and Markert (2009), Lu et al. (2011), Kaji and Kitsuregawa (2007), Feng et al. (2013)), could be a source of noise, as one needs to assume that the semantic relation between a pair of synsets transfers over the pair of words corresponding to that pair of synsets. For polysemous words, this assumption may be overly strong. 3 Pairwise Markov Random Fields and Loopy Belief Propagation We formulate the task of learning sense- and wordlevel connotation lexicon as a graph-based classification task (Sen et al., 2008). More formally, we denote the connotation grap</context>
</contexts>
<marker>Takamura, Inui, Okumura, 2005</marker>
<rawString>Hiroya Takamura, Takashi Inui, and Manabu Okumura. 2005. Extracting semantic orientations of words using spin model. In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, pages 133–140. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
</authors>
<title>Mining the Web for synonyms: PMI-IR versus LSA on TOEFL.</title>
<date>2001</date>
<booktitle>In Proceedings of the Twelfth European Conference on Machine Learning (ECML-01),</booktitle>
<pages>491--502</pages>
<location>Freiburg, Germany.</location>
<contexts>
<context position="21348" citStr="Turney, 2001" startWordPosition="3549" endWordPosition="3550"> weighted based on the distributional similarities of the word pairs. GWORD: The third graph is a super-graph of GWORD W/ OVERLAY, with additional edges, where argument pairs in synonym and antonym relation are connected to each other. Note that unlike the connotation graph GWORD+SENSE, it does not contain any synset nodes. Rather, the words that are synonyms or antonyms of each other are directly linked in the graph. As such, this graph contains all edge types t1 through t4. 5PMI scores are widely used in previous studies to measure association between words (e.g., (Church and Hanks, 1990), (Turney, 2001), (Newman et al., 2009)). t: t1 A P + − + 1-� � − � 1-� t: t4 S S + − + e 1-e − 1-e e 1548 GWORD+SENSE W/ SYNSIM: This is a supergraph of our original GWORD+SENSE graph; that is, it has all the predicate, arguments, and synset nodes, as well as the four types of edges between them. In addition, we add edges of a fifth type t5 between the synset nodes to capture their similarity. To define similarity, we use the glossary definitions of the synsets and derive three different scores. Each score utilizes the count(s1, s2) of overlapping nouns, verbs, and adjectives/adverbs among the glosses of the</context>
</contexts>
<marker>Turney, 2001</marker>
<rawString>Peter D. Turney. 2001. Mining the Web for synonyms: PMI-IR versus LSA on TOEFL. In Proceedings of the Twelfth European Conference on Machine Learning (ECML-01), pages 491–502, Freiburg, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leonid Velikovich</author>
<author>Sasha Blair-Goldensohn</author>
<author>Kerry Hannan</author>
<author>Ryan McDonald</author>
</authors>
<title>The viability of web-derived polarity lexicons.</title>
<date>2010</date>
<booktitle>In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="34494" citStr="Velikovich et al., 2010" startWordPosition="5766" endWordPosition="5769">st as well. Note that due to this parameter learning, we are able to report better performance for the connotation lexicon of (Feng et al., 2013) than what the authors have reported in their paper (labeled with *) in Table 5. Table 5 shows the results for N=15, where the new lexicon consistently outperforms other competitive lexicons. In addition, Figure 4 shows that the performance does not change much based on the size of training data used for parameter tuning (N={5,10,15,20}). 7 Related Work Several previous approaches explored the use of graph propagation for sentiment lexicon induction (Velikovich et al., 2010) and connotation lexicon 8What is reported is based on A ∈ {20, 40, 60, 80}. More detailed parameter search does not change the results much. 0.5 1.0 2.0 3.0 Accuracy (%) 80 40 60 SentiWordNet GWord+Sense(95%) GWord+Sense(99%) e-GWord+Sense(95%) e-GWord+Sense(99%) 1551 Lexicon SemEval Threshold 20 40 60 80 Instance Size 955 649 341 86 Feng2013 71.5 77.1 81.6 90.5 GENINQ+MPQA 72.8 77.2 80.4 86.7 GWORD+SENSE(95%) 74.5 79.4 86.5 91.9 GWORD+SENSE(99%) 74.6 79.4 86.8 91.9 E-GWORD+SENSE(95%) 72.5 76.8 82.3 87.2 E-GWORD+SENSE(99%) 72.6 76.9 82.5 87.2 Feng2013* 70.8 74.6 80.8 93.5 GENINQ+MPQA* 64.5 69</context>
</contexts>
<marker>Velikovich, Blair-Goldensohn, Hannan, McDonald, 2010</marker>
<rawString>Leonid Velikovich, Sasha Blair-Goldensohn, Kerry Hannan, and Ryan McDonald. 2010. The viability of web-derived polarity lexicons. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janyce Wiebe</author>
<author>Rada Mihalcea</author>
</authors>
<title>Word sense and subjectivity.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics,</booktitle>
<pages>1065--1072</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="36749" citStr="Wiebe and Mihalcea (2006)" startWordPosition="6119" endWordPosition="6122">sidered to induce the polarity labels at both the word-level and sense-level. Although we focus on learning connotative polarity of words and senses in this paper, the same approach would be applicable to constructing a sentiment lexicon as well. There have been recent studies that address word sense disambiguation issues for sentiment analysis. SentiWordNet (Esuli and Sebastiani, 2006) was the very first lexicon developed for sense-level labels of sentiment polarity. In recent years, Akkaya et al. (2009) report a successful empirical result where WSD helps improving sentiment analysis, while Wiebe and Mihalcea (2006) study the distinction between objectivity and subjectivity in each different sense of a word, and their empirical effects in the context of sentiment analysis. Our work shares the high-level spirit of accessing the sense-level polarity, while also deriving the word-level polarity. In recent years, there has been a growing research interest in investigating more fine-grained aspects of lexical sentiment beyond positive and negative sentiment. For example, Mohammad and Turney (2010) study the affects words can evoke in people’s minds, while Bollen et al. (2011) study various moods, e.g., “tensi</context>
</contexts>
<marker>Wiebe, Mihalcea, 2006</marker>
<rawString>Janyce Wiebe and Rada Mihalcea. 2006. Word sense and subjectivity. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics, pages 1065–1072. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janyce Wiebe</author>
<author>Theresa Wilson</author>
<author>Claire Cardie</author>
</authors>
<title>Annotating expressions of opinions and emotions in language.</title>
<date>2005</date>
<booktitle>Language Resources and Evaluation (formerly Computers and the Humanities),</booktitle>
<pages>39--2</pages>
<contexts>
<context position="36006" citStr="Wiebe et al., 2005" startWordPosition="6003" endWordPosition="6006">agating confidence or belief over the graph connectivity. The key difference, however, is that in our MRF representation, we can explicitly model various types of word-word, sense-sense and word-sense relations as edge potentials. In particular, we can naturally encode relations that encourage the same assignment (e.g., synonym) as well as the opposite assignment (e.g., antonym) of the polarity labels. Note that integration of the latter is not straightforward in the graph propagation framework. There have been a number of previous studies that aim to construct a word-level sentiment lexicon (Wiebe et al., 2005; Qiu et al., 2009) and a sense-level sentiment lexicon (Esuli and Sebastiani, 2006). But none of these approaches considered to induce the polarity labels at both the word-level and sense-level. Although we focus on learning connotative polarity of words and senses in this paper, the same approach would be applicable to constructing a sentiment lexicon as well. There have been recent studies that address word sense disambiguation issues for sentiment analysis. SentiWordNet (Esuli and Sebastiani, 2006) was the very first lexicon developed for sense-level labels of sentiment polarity. In recent</context>
</contexts>
<marker>Wiebe, Wilson, Cardie, 2005</marker>
<rawString>Janyce Wiebe, Theresa Wilson, and Claire Cardie. 2005. Annotating expressions of opinions and emotions in language. Language Resources and Evaluation (formerly Computers and the Humanities), 39(2/3):164–210.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Wilson</author>
<author>Paul Hoffmann</author>
<author>Swapna Somasundaran</author>
<author>Jason Kessler</author>
<author>Janyce Wiebe</author>
<author>Yejin Choi</author>
<author>Claire Cardie</author>
<author>Ellen Riloff</author>
<author>Siddharth Patwardhan</author>
</authors>
<title>Opinionfinder: A system for subjectivity analysis.</title>
<date>2005</date>
<booktitle>In Proceedings of HLT/EMNLP on Interactive Demonstrations,</booktitle>
<pages>34--35</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="19468" citStr="Wilson et al., 2005" startWordPosition="3239" endWordPosition="3242">s scalable to large datasets. 4arg-arg edges are based on co-occurrence (see Section 2), which does not carry as strong indication of the same connotation as e.g., synonymy. Thus, we enforce less homophily for nodes connected through edges of arg-arg type. 4 Evaluation I: Agreement with Sentiment Lexicons ConnotationWordNet is expected to be the superset of a sentiment lexicon, as it is highly likely for any word with positive/negative sentiment to carry connotation of the same polarity. Thus, we use two conventional sentiment lexicons, General Inquirer (GENINQ) (Stone et al., 1966) and MPQA (Wilson et al., 2005b), as surrogates to measure the performance of our inference algorithm. 4.1 Variants of Graph Construction The construction of the connotation graph, denoted by GWORD+SENSE, which includes words and synsets, has been described in Section 2. In addition to this graph, we tried several other graph constructions, the first three of which have previously been used in (Feng et al., 2013). We briefly describe these graphs below, and compare performance on all the graphs in the proceeding. GWORD W/ PRED-ARG: This is a (bipartite) subgraph of GWORD+SENSE, which only includes the connotative predicate</context>
<context position="28698" citStr="Wilson et al. (2005" startWordPosition="4801" endWordPosition="4804">en in designing the task so that the Turkers will focus only on the corresponding sense of a word. Therefore, we provided the part of speech tag, the WordNet gloss of the selected sense, and a few examples as given in WordNet. As an incentive, each Turker was rewarded $0.07 per hit which consists of 10 words to label. 5.1 Word-Level Evaluation We first evaluate the word-level assignment of connotation, as shown in Table 3. The agreement between the new lexicon and human judges varies between 84% and 86.98%. Sentiment lexicons such as SentiWordNet (Baccianella et al. (2010)) and OpinionFinder (Wilson et al. (2005a)) show low agreement rate with human, which is somewhat as expected: human judges in this study are labeling for subtle connotation, not for more explicit sentiment. OpinionFinder’s low agreement rate was mainly due to the low hit rate of the words (successful look-up rate, 33.43%). Feng2013 is the lexicon presented in (Feng et al., 2013) and it showed a relatively higher 72.13% hit rate. Note that belief propagation was run until 95% and 99% of the nodes were converged in their beliefs. In addition, the seed words with known connotation labels originally consist of 20 positive and 20 negati</context>
</contexts>
<marker>Wilson, Hoffmann, Somasundaran, Kessler, Wiebe, Choi, Cardie, Riloff, Patwardhan, 2005</marker>
<rawString>Theresa Wilson, Paul Hoffmann, Swapna Somasundaran, Jason Kessler, Janyce Wiebe, Yejin Choi, Claire Cardie, Ellen Riloff, and Siddharth Patwardhan. 2005a. Opinionfinder: A system for subjectivity analysis. In Proceedings of HLT/EMNLP on Interactive Demonstrations, pages 34–35. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Wilson</author>
<author>Janyce Wiebe</author>
<author>Paul Hoffmann</author>
</authors>
<title>Recognizing contextual polarity in phraselevel sentiment analysis.</title>
<date>2005</date>
<booktitle>In Proceedings of Human Language Technologies Conference/Conference on Empirical Methods in Natural Language Processing (HLT/EMNLP</booktitle>
<location>Vancouver, CA.</location>
<contexts>
<context position="19468" citStr="Wilson et al., 2005" startWordPosition="3239" endWordPosition="3242">s scalable to large datasets. 4arg-arg edges are based on co-occurrence (see Section 2), which does not carry as strong indication of the same connotation as e.g., synonymy. Thus, we enforce less homophily for nodes connected through edges of arg-arg type. 4 Evaluation I: Agreement with Sentiment Lexicons ConnotationWordNet is expected to be the superset of a sentiment lexicon, as it is highly likely for any word with positive/negative sentiment to carry connotation of the same polarity. Thus, we use two conventional sentiment lexicons, General Inquirer (GENINQ) (Stone et al., 1966) and MPQA (Wilson et al., 2005b), as surrogates to measure the performance of our inference algorithm. 4.1 Variants of Graph Construction The construction of the connotation graph, denoted by GWORD+SENSE, which includes words and synsets, has been described in Section 2. In addition to this graph, we tried several other graph constructions, the first three of which have previously been used in (Feng et al., 2013). We briefly describe these graphs below, and compare performance on all the graphs in the proceeding. GWORD W/ PRED-ARG: This is a (bipartite) subgraph of GWORD+SENSE, which only includes the connotative predicate</context>
<context position="28698" citStr="Wilson et al. (2005" startWordPosition="4801" endWordPosition="4804">en in designing the task so that the Turkers will focus only on the corresponding sense of a word. Therefore, we provided the part of speech tag, the WordNet gloss of the selected sense, and a few examples as given in WordNet. As an incentive, each Turker was rewarded $0.07 per hit which consists of 10 words to label. 5.1 Word-Level Evaluation We first evaluate the word-level assignment of connotation, as shown in Table 3. The agreement between the new lexicon and human judges varies between 84% and 86.98%. Sentiment lexicons such as SentiWordNet (Baccianella et al. (2010)) and OpinionFinder (Wilson et al. (2005a)) show low agreement rate with human, which is somewhat as expected: human judges in this study are labeling for subtle connotation, not for more explicit sentiment. OpinionFinder’s low agreement rate was mainly due to the low hit rate of the words (successful look-up rate, 33.43%). Feng2013 is the lexicon presented in (Feng et al., 2013) and it showed a relatively higher 72.13% hit rate. Note that belief propagation was run until 95% and 99% of the nodes were converged in their beliefs. In addition, the seed words with known connotation labels originally consist of 20 positive and 20 negati</context>
</contexts>
<marker>Wilson, Wiebe, Hoffmann, 2005</marker>
<rawString>Theresa Wilson, Janyce Wiebe, and Paul Hoffmann. 2005b. Recognizing contextual polarity in phraselevel sentiment analysis. In Proceedings of Human Language Technologies Conference/Conference on Empirical Methods in Natural Language Processing (HLT/EMNLP 2005), Vancouver, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan S Yedidia</author>
<author>William T Freeman</author>
<author>Yair Weiss</author>
</authors>
<title>Understanding belief propagation and its generalizations.</title>
<date>2003</date>
<booktitle>In Exploring AI in the new millennium,</booktitle>
<pages>239--269</pages>
<contexts>
<context position="12872" citStr="Yedidia et al., 2003" startWordPosition="2076" endWordPosition="2079">re formally. Given - a connotation graph G = (V, E) of words and synsets connected with typed edges, - prior knowledge (i.e., probabilities) of (some or all) nodes belonging to each class, - compatibility of two nodes with a given pair of labels being connected to each other; Classify the nodes Yi ∈ Y, into one of two classes; L = {+, −}, such that the class assignments yi maximize our objective in Equation (1). We can further rank the network objects by the probability of their connotation polarity. 2This assumption yields a pairwise Markov Random Field (MRF); a special case of general MRFs (Yedidia et al., 2003). Z(x) Yi ψi(yi) e(Yi,�)EE ψ&apos; ( j zyi, yj) iEY 1546 3.2 Loopy Belief Propagation Finding the best assignments to unobserved variables in our objective function is the inference problem. The brute force approach through enumeration of all possible assignments is exponential and thus intractable. In general, exact inference is known to be NP-hard and there is no known algorithm which can be theoretically shown to solve the inference problem for general MRFs. Therefore in this work, we employ a computationally tractable (in fact linearly scalable with network size) approximate inference algorithm</context>
</contexts>
<marker>Yedidia, Freeman, Weiss, 2003</marker>
<rawString>Jonathan S. Yedidia, William T. Freeman, and Yair Weiss. 2003. Understanding belief propagation and its generalizations. In Exploring AI in the new millennium, pages 239–269.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>