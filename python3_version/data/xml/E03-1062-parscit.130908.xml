<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.021737">
<title confidence="0.998347">
A Flexible Pragmatics-driven Language Generator for Animated Agents
</title>
<author confidence="0.992347">
Paul Piwek
</author>
<affiliation confidence="0.9921735">
ITRI — Information Technology Research Institute
University of Brighton
</affiliation>
<author confidence="0.304982">
Paul .Piwek@itri .bton .ac .uk
</author>
<sectionHeader confidence="0.991817" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999992583333333">
This paper describes the NECA MNLG;
a fully implemented Multimodal Natu-
ral Language Generation module. The
MNLG is deployed as part of the NECA
system which generates dialogues be-
tween animated agents. The genera-
tion module supports the seamless inte-
gration of full grammar rules, templates
and canned text. The generator takes in-
put which allows for the specification of
syntactic, semantic and pragmatic con-
straints on the output.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999981">
This paper introduces the NECA MNLG; a Multi-
modal Natural Language Generator. It has been
developed in the context of the NECA system.1
The NECA system generates dialogue scripts for
animated characters. A first demonstrator in the
car sales domain (ESHowRoom) has been imple-
mented. It allows a user to browse a database of
cars, select a car, select two characters and their
attributes, and subsequently view an automatically
generated film of a dialogue about the selected car.
The demonstrator takes the following input:
</bodyText>
<listItem confidence="0.8492573">
• A database with facts about the selected car (maximum
speed, horse power, etc.).
• A database which correlates facts with value judge-
ments.
1NECA stands for &apos;Net Environment for Embodied Emo-
tional Conversational Agents&apos; and is an EU-IST project
• Information about the characters: 1. Personality traits
such as extroversion and agreeableness. 2. Personal
preferences concerning cars (e.g., a preference for safe
cars). 3. Role of the character (seller or customer).
</listItem>
<bodyText confidence="0.979447">
This input is processed in a pipeline that consists
of the following modules in this order:
</bodyText>
<listItem confidence="0.993799272727273">
• A DIALOGUE PLANNER, which produces an abstract
description of the dialogue (the dialogue plan).
• A MULTI-MODAL NATURAL LANGUAGE GENERA-
TOR which specifies linguistic and non-linguistic real-
izations for the dialogue acts in the dialogue plan.
• A SPEECH SYNTHESIS MODULE, which adds infor-
mation for Speech.
• A GESTURE ASSIGNMENT MODULE, which controls
the temporal coordination of gestures and speech.
• A PLAYER, which plays the animated characters and
the corresponding speech sound files.
</listItem>
<bodyText confidence="0.9997055">
Each step in the pipeline adds more concrete in-
formation to the dialogue plan/script until finally
a player can render it. A single XML compliant
representation language, called RRL, has been de-
veloped for representing the Dialogue Script at its
various stages of completion (Piwek et al., 2002).
In this paper, we describe the requirements for
the NECA MNLG, how these have been translated
into design solutions and finally some of aspects
of the implementation.
</bodyText>
<sectionHeader confidence="0.997604" genericHeader="introduction">
2 Requirements
</sectionHeader>
<bodyText confidence="0.999548">
The requirements in this section derive primarly
from the use case of the NECA system. We do,
however, try to indicate in what respects these re-
quirements transcend this specific application and
are desirable for generation systems in general.
</bodyText>
<tableCaption confidence="0.564580666666667">
REQUIREMENT 1: The linguistic resources of the gen-
erator should support seamless integration of canned text,
templates and full grammar rules.
</tableCaption>
<bodyText confidence="0.999863609756098">
In the NECA system, the dialogue planner creates
a dialogue plan consisting of (1) a description
of the participants, (2) a characterization of the
common ground at the outset of the dialogue in
terms of Discourse Representation Theory (Kamp
and Reyle, 1993) and (3) a set of dialogue acts
and their temporal ordering. For each dialogue
act, the type, speaker, set of addressees, semantic
content, what it is a reaction to (i.e., its rhetorical
relation to other dialogue acts), and emotions
of the speaker can be specified. The amount of
information which the dialogue planner actually
provides for each of these attributes varies,
however, per dialogue act: for some dialogue acts,
a full semantic content can be provided —in the
form of a Discourse Representation Structure—
whereas for other acts, no semantic content is
available at all. Typically, the dialogue planner
can provide detailed semantics for utterances
whose content is covered by the domain model
(e.g., the car domain) whereas this is not possible
for utterances which play an important role in the
conversation but are not part of the domain model
(e.g., greetings). This state of affairs is shared
with most real-world applications.
Since generation by grammar rules is primarily
driven by the input semantics, for certain dialogue
acts full grammar rules cannot be used. These
dialogue acts may be primarily characterized in
terms of their, possibly domain specific, dialogue
act type (greeting, refusal, etc.). Thus, we need
a generator which can cope with both types of
input, and map them to the appropriate output.
Input with little or no semantic content can typ-
ically be dealt with through templates or canned
text, whereas input with fully specified semantic
content can be dealt with through proper grammar
rules. Summarizing, we need a generator which
can cope with (linguistic) resources that contain
an arbritary combination of grammar rules,
templates and canned text.
</bodyText>
<subsubsectionHeader confidence="0.8387425">
REQUIREMENT 2: The generator should allow for
combinations of different types of constraints on its the out-
</subsubsectionHeader>
<bodyText confidence="0.986703272727273">
put, such as syntactic, semantic and pragmatic constraints
In the NECA project the aim is to generate
behaviour for animated agents which simulates
affective situated face-to-face conversational
interaction. This means that the utterances of the
agents have to be adapted not only to the content
of the information which is exchanged but also to
many other properties of the interlocutors, such as
their emotional state, gender, cultural background,
etc. The generator should therefore allow for such
parameters to be part of its input.
</bodyText>
<figureCaption confidence="0.862317">
REQUIREMENT 3: The generator should be sufficiently fast
to be of use in real-world applications
</figureCaption>
<bodyText confidence="0.9999344">
The application in which our generator is
being used is currently fielded as part of a net-
environment. The application will be evaluated
with users through online questionnaires which
are integrated in the application and analysis of
log files (to answer questions such as &apos;Do users
try different settings of the application?&apos;, etc. See
Krenn et al., 2002). Therefore, the generator will
have to be fast in order for it not to negatively
affect the user experience of the system.
</bodyText>
<sectionHeader confidence="0.999258" genericHeader="method">
3 Design Solutions
</sectionHeader>
<bodyText confidence="0.999090181818182">
The NECA MNLG adopts the conventional pipeline
architecture for generators (Reiter and Dale,
2000). Its input is a RRL dialogue plan. This
is parsed and internally represented as a PROFIT
typed feature structure (Erbach, 1995). Subse-
quently, the dialogue acts in the plan are realized
in accordance with their temporal order. For each
act, first a deep syntactic structure is generated.
The deep structure of referring expressions is dealt
with in a separate module, which takes the com-
mon ground of the interlocutors into account. Sub-
sequently, lexical realization (agreement, inflec-
tion) and punctuation is performed. Finally, turn-
taking gestures are added and the output is mapped
back into the RRL XML format.
Here let us concentrate on our approach to the
generation of deep syntactic structure and how it
satisfies the first two requirements. The input to
the MNLG is a node (i.e., feature structure) stipu-
lating the syntactic type of the output (e.g., sen-
tence: &lt;s), semantics and further information on
the current dialogue act in PROFIT:2
</bodyText>
<equation confidence="0.98919325">
(‹s &amp;
sem!drs ([ c_27] ,
[ type (c_27,prestigious) ,
argl (c_27,x_1)] ) &amp;
currentAct !speaker!
(name! john &amp;
polite ! yes &amp;
)
</equation>
<bodyText confidence="0.999964878787879">
Thus various types of information are combined
within one input node. Generation consists of tak-
ing the input node and using it to create a tree
representation of the output. For this purpose,
the MNLG tries to match the input node with the
mother node of one of the trees in its tree repos-
itory. This tree repository contains trees which
can represent proper grammar rules, templates and
canned text. Matching trees might in turn have in-
complete daughter nodes. These are recursively
expanded by matching them with the trees in the
repository, until all daughters are complete.
A daughter node is complete if it is lexically
realized (i.e., the attribute form of the node has
a value) or it is of the type &lt;np and the seman-
tics is an open variable. In the latter instance, the
node is expanded in a separate step by the refer-
ring expressions generation module. This module
finds the discourse referent in the common ground
which binds the open variable and constructs a de-
scription of the object in question. The descrip-
tion is composed of the properties which the ob-
ject has according to the common ground, but can
also be empty if the object is highly salient. The
module is based on the work of Krahmer and The-
une (2002). The (empty) description is mapped
to a deep syntactic structure using the tree repos-
itory. Lexicalization subsequently yields expres-
sions such as &apos;it&apos; (empty descriptive content) or,
for instance, &apos;the red car&apos;.
Let us return to the tree repository and illus-
trate how templates and rules can be represented
uniformly. The representation of a tree is of the
</bodyText>
<footnote confidence="0.987267875">
2That is, PROLOG with some sugaring for the rep-
resentation of feature structures. Feature structures are
also used in the FUF/SURGE generator. It is different
from the NECA MNLG in that it takes as input thematic
trees with content words. Furthermore, it allows for con-
trol annotations in the grammar and uses a special inter-
preter for unification, rather than directly PROLOG. See
http://www.cs.bgu.ac.il/surge/.
</footnote>
<bodyText confidence="0.9987022">
form (Node,[ Treel, Tree2, . . .1 ) , where
the list of trees can be empty, yielding a tree con-
sisting of one node: (Node, [ 1 ) . The following
is a template for dialogue acts of type greeting
with no semantic content and a polite speaker.
</bodyText>
<equation confidence="0.978778166666667">
(‹s &amp;
currentAct!
(type!greeting &amp;
speaker!polite!&amp;quot;yes&amp;quot; &amp;
speaker!name!Speaker) &amp;
sem! &amp;quot;none&apos;,
[ Vs &amp; form!&amp;quot;hello!&amp;quot;,[]),
(&lt;fragment &amp;
form!&amp;quot;My name is&amp;quot;,[]),
Vnp &amp;
sem!concept(Speaker),[])
] ) •
</equation>
<bodyText confidence="0.999892142857143">
This is a template for the text &apos;Hello! My name is
SPEAKER&apos;. Where SPEAKER is a variable which
is bound to the name of the speaker of the utter-
ance. The noun phrase (&lt; np) for this name is gen-
erated by the referring expression generation mod-
ule. The following is a tree representing a gram-
mar rule of the familiar type S —&gt; NP VP:
</bodyText>
<equation confidence="0.99082555">
Vs &amp;
currentAct !type ! statement &amp;
currentAct !CA &amp;
argGap!ArgGap &amp;
auxGap!AuxGap &amp;
sem!drs (_,[ negation (
drs (_,
[ atyprgel ((EE:xTyp) IRI
] ) ),
) ,
[ (&lt;np &amp;
currentAct !CA &amp;
sem!X,[ ] ) ,
(&lt;vP &amp;
argGap!ArgGap &amp;
auxGap!AuxGap &amp;
negated!&lt;true &amp;
sem!drs (_,[ type (E, Type) IR] ) &amp;
currentAct!CA,_)
] ) •
</equation>
<bodyText confidence="0.9951455">
Note that this rule applies to an input node whose
semantic content contains a negation. The nega-
tion is passed on to the VP subtree via the feature
negated. The attributes argGap and auxGap
allow us to capture unbounded dependencies via
feature perlocation. Our use of trees is related to
the Tree Adjoining Grammar approach to genera-
tion (e.g., Stone and Doran, 1997).3
</bodyText>
<footnote confidence="0.847738333333333">
3 Their generation algorithm is, however, very different
from the one proposed here. Whereas they propose an in-
tegrated planning approach, we advocate a very modular sys-
</footnote>
<bodyText confidence="0.999522666666667">
The value of the attribute currentAct is
passed on from the mother node to the daughter
nodes. Thus any pragmatic information (personal-
ity, politeness, emotion, etc.) is passed on through
the tree and can be accessed at a later stage, for
instance, when lexical items are selected.
</bodyText>
<sectionHeader confidence="0.995316" genericHeader="method">
4 Implementation
</sectionHeader>
<bodyText confidence="0.9991066">
The NECA MNLG has been implemented in PRO-
LOG. The output is in the form of an RRL XML
document. Table 1 provides a sample of the re-
sponse times of the compiled code running on a
Pentium iii Mobile 1200 Mhz with Sicstus 3.8.5
PROLOG. We timed the complete generation pro-
cess from parsing the XML input to producing
XML output, including generation of deep syn-
tactic structure, referring expressions, turn taking
gestures (not discussed in this paper), etc.
</bodyText>
<table confidence="0.9837956">
input # acts = 1 &lt; 10
A 19 0.230s 0.741s
B 22 0.290s 0.872s
c 23 0.290s 0.801s
D 31 0.431s 1.372s
</table>
<tableCaption confidence="0.99986">
Table 1: Response Times of the MNLG
</tableCaption>
<bodyText confidence="0.99996258974359">
The results show generation times for entire di-
alogues and according to whether the generator
was asked to produce exactly one solution or se-
lect at random a solution from a set of at most ten
generated solutions (the latter strategy was imple-
mented to obtain more variation in the generator
output). On average for = 1 the generation time
for an individual dialogue act is almost ffi of a
second. For &lt; 10 it is A of a second. The
generator uses a repository of 138 trees (includ-
ing the two examples given above). The repos-
itory has been developed for and integrated into
the ESHOWROOM system which is currently be-
ing fielded. A start is being made with porting the
MNLG to a new domain and documentation is be-
ing created to allow our project partners to carry
out this task. We hope that our efforts will con-
tribute to addressing a challenge expressed in (Re-
tem, supporting fast generation. Moreover, by using features
for unbounded dependencies we do not require the adjunction
operation, which is incompatible with our topdown genera-
tion approach. We follow Nicolov et al. (1996), who also use
TAG, in their commitment to flat semantics. Their generator
does, however, not take pragmatic constraints into account.
iter, 1999): &amp;quot;We hope that future systems such as
STOP will be able to make more use of deep tech-
niques, because of advances in linguistics and the
development of reusable wide-coverage NLG com-
ponents that are robust, well-documented and well
engineered as software artifacts.&amp;quot;
In our view the best way to approach this goal
is by providing a framework which allows for the
flexible integration of shallow and deep genera-
tion, thus making it possible that in the course of
various projects, deep analyses can be developed
alongside the shallow solutions which are diffi-
cult to avoid altogether in software development
projects, due to the pressure to deliver a complete
system within a certain span of time.
</bodyText>
<sectionHeader confidence="0.996673" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.99973125">
This research is supported by the EU Project NECA
IsT-2000-28580. For comments and discussion
thanks are due the EACL reviewers and my col-
leagues in the NECA project.
</bodyText>
<sectionHeader confidence="0.99903" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999792939393939">
Gregor Erbach. 1995. PROFIT 1.54 user&apos;s guide. University
of the Saarland, December 3, 1995.
Hans Kamp and Uwe Reyle. 1993. From Discourse to
Logic. Kluwer, Dordrecht.
Emiel Krahmer and Mariet Theune. 2002. Efficient context-
sensitive generation of referring expressions. In: Kees
Van Deemter and Rodger Kibble (eds.), Information
Sharing, CSLI, Stanford.
Brigitte Krenn, Erich Gstrein, Barbara Neumayr and Mar-
tine Grice. 2002. What can we learn from users
of avatars in net environments?. In: Proc. of the
AAMAS workshop &amp;quot;Embodied conversational agents -
let&apos;s specibi and evaluate them! &amp;quot;, Bologna, Italy.
Nicholas Nicolov, Chris Mellish &amp; Graeme Ritchie. 1996.
Approximate Generation from Non-Hierarchical Rep-
resentattions, Proc. 8th International Workshop on
Natural Language Generation, Herstmonceux Castle,
UK.
Paul Piwek, Brigitte Krenn, Marc Schröder, Martine Grice,
Stefan Baumann and Hannes Pirker. 2002. RRL: A
Rich Representation Language for the Description of
Agent Behaviour in NECA. Proc. of the AAMAS work-
shop &amp;quot;Embodied conversational agents - let&apos;s specibi
and evaluate them! &amp;quot;, Bologna, Italy.
Ehud Reiter. 1999. Shallow vs. Deep Techniques for han-
dling Linguistic Constraints and Optimisations. Proc.
of K1-99 Workshop &amp;quot;May I speakfreely&amp;quot;.
Ehud Reiter and Robert Dale. 2000. Building natural
language generation systems. Cambridge University
Press, Cambridge.
Matthew Stone and Christy Doran. 1997. Sentence Plan-
ning as Description Using Tree-Adjoining Grammar.
Proc. ACL 1997, Madrid, Spain.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.838368">
<title confidence="0.999854">A Flexible Pragmatics-driven Language Generator for Animated Agents</title>
<author confidence="0.999844">Paul Piwek</author>
<affiliation confidence="0.999566">Technology Research Institute University of Brighton</affiliation>
<author confidence="0.939588">Paul Piwekitri bton ac uk</author>
<abstract confidence="0.991696153846154">paper describes the MNLG; a fully implemented Multimodal Natural Language Generation module. The deployed as part of the system which generates dialogues between animated agents. The generation module supports the seamless integration of full grammar rules, templates and canned text. The generator takes input which allows for the specification of syntactic, semantic and pragmatic constraints on the output.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Gregor Erbach</author>
</authors>
<title>PROFIT 1.54 user&apos;s guide.</title>
<date>1995</date>
<journal>University of the Saarland, December</journal>
<volume>3</volume>
<contexts>
<context position="6503" citStr="Erbach, 1995" startWordPosition="1024" endWordPosition="1025">cation will be evaluated with users through online questionnaires which are integrated in the application and analysis of log files (to answer questions such as &apos;Do users try different settings of the application?&apos;, etc. See Krenn et al., 2002). Therefore, the generator will have to be fast in order for it not to negatively affect the user experience of the system. 3 Design Solutions The NECA MNLG adopts the conventional pipeline architecture for generators (Reiter and Dale, 2000). Its input is a RRL dialogue plan. This is parsed and internally represented as a PROFIT typed feature structure (Erbach, 1995). Subsequently, the dialogue acts in the plan are realized in accordance with their temporal order. For each act, first a deep syntactic structure is generated. The deep structure of referring expressions is dealt with in a separate module, which takes the common ground of the interlocutors into account. Subsequently, lexical realization (agreement, inflection) and punctuation is performed. Finally, turntaking gestures are added and the output is mapped back into the RRL XML format. Here let us concentrate on our approach to the generation of deep syntactic structure and how it satisfies the f</context>
</contexts>
<marker>Erbach, 1995</marker>
<rawString>Gregor Erbach. 1995. PROFIT 1.54 user&apos;s guide. University of the Saarland, December 3, 1995.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hans Kamp</author>
<author>Uwe Reyle</author>
</authors>
<title>From Discourse to Logic.</title>
<date>1993</date>
<publisher>Kluwer,</publisher>
<location>Dordrecht.</location>
<contexts>
<context position="3341" citStr="Kamp and Reyle, 1993" startWordPosition="519" endWordPosition="522"> section derive primarly from the use case of the NECA system. We do, however, try to indicate in what respects these requirements transcend this specific application and are desirable for generation systems in general. REQUIREMENT 1: The linguistic resources of the generator should support seamless integration of canned text, templates and full grammar rules. In the NECA system, the dialogue planner creates a dialogue plan consisting of (1) a description of the participants, (2) a characterization of the common ground at the outset of the dialogue in terms of Discourse Representation Theory (Kamp and Reyle, 1993) and (3) a set of dialogue acts and their temporal ordering. For each dialogue act, the type, speaker, set of addressees, semantic content, what it is a reaction to (i.e., its rhetorical relation to other dialogue acts), and emotions of the speaker can be specified. The amount of information which the dialogue planner actually provides for each of these attributes varies, however, per dialogue act: for some dialogue acts, a full semantic content can be provided —in the form of a Discourse Representation Structure— whereas for other acts, no semantic content is available at all. Typically, the </context>
</contexts>
<marker>Kamp, Reyle, 1993</marker>
<rawString>Hans Kamp and Uwe Reyle. 1993. From Discourse to Logic. Kluwer, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emiel Krahmer</author>
<author>Mariet Theune</author>
</authors>
<title>Efficient contextsensitive generation of referring expressions.</title>
<date>2002</date>
<editor>In: Kees Van Deemter and Rodger Kibble (eds.), Information Sharing, CSLI, Stanford.</editor>
<contexts>
<context position="8675" citStr="Krahmer and Theune (2002)" startWordPosition="1398" endWordPosition="1402">omplete if it is lexically realized (i.e., the attribute form of the node has a value) or it is of the type &lt;np and the semantics is an open variable. In the latter instance, the node is expanded in a separate step by the referring expressions generation module. This module finds the discourse referent in the common ground which binds the open variable and constructs a description of the object in question. The description is composed of the properties which the object has according to the common ground, but can also be empty if the object is highly salient. The module is based on the work of Krahmer and Theune (2002). The (empty) description is mapped to a deep syntactic structure using the tree repository. Lexicalization subsequently yields expressions such as &apos;it&apos; (empty descriptive content) or, for instance, &apos;the red car&apos;. Let us return to the tree repository and illustrate how templates and rules can be represented uniformly. The representation of a tree is of the 2That is, PROLOG with some sugaring for the representation of feature structures. Feature structures are also used in the FUF/SURGE generator. It is different from the NECA MNLG in that it takes as input thematic trees with content words. Fu</context>
</contexts>
<marker>Krahmer, Theune, 2002</marker>
<rawString>Emiel Krahmer and Mariet Theune. 2002. Efficient contextsensitive generation of referring expressions. In: Kees Van Deemter and Rodger Kibble (eds.), Information Sharing, CSLI, Stanford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brigitte Krenn</author>
<author>Erich Gstrein</author>
<author>Barbara Neumayr</author>
<author>Martine Grice</author>
</authors>
<title>What can we learn from users of avatars in net environments?. In:</title>
<date>2002</date>
<booktitle>Proc. of the AAMAS workshop</booktitle>
<location>Bologna, Italy.</location>
<contexts>
<context position="6134" citStr="Krenn et al., 2002" startWordPosition="962" endWordPosition="965">the interlocutors, such as their emotional state, gender, cultural background, etc. The generator should therefore allow for such parameters to be part of its input. REQUIREMENT 3: The generator should be sufficiently fast to be of use in real-world applications The application in which our generator is being used is currently fielded as part of a netenvironment. The application will be evaluated with users through online questionnaires which are integrated in the application and analysis of log files (to answer questions such as &apos;Do users try different settings of the application?&apos;, etc. See Krenn et al., 2002). Therefore, the generator will have to be fast in order for it not to negatively affect the user experience of the system. 3 Design Solutions The NECA MNLG adopts the conventional pipeline architecture for generators (Reiter and Dale, 2000). Its input is a RRL dialogue plan. This is parsed and internally represented as a PROFIT typed feature structure (Erbach, 1995). Subsequently, the dialogue acts in the plan are realized in accordance with their temporal order. For each act, first a deep syntactic structure is generated. The deep structure of referring expressions is dealt with in a separat</context>
</contexts>
<marker>Krenn, Gstrein, Neumayr, Grice, 2002</marker>
<rawString>Brigitte Krenn, Erich Gstrein, Barbara Neumayr and Martine Grice. 2002. What can we learn from users of avatars in net environments?. In: Proc. of the AAMAS workshop &amp;quot;Embodied conversational agents -let&apos;s specibi and evaluate them! &amp;quot;, Bologna, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicholas Nicolov</author>
<author>Chris Mellish</author>
<author>Graeme Ritchie</author>
</authors>
<title>Approximate Generation from Non-Hierarchical Representattions,</title>
<date>1996</date>
<booktitle>Proc. 8th International Workshop on Natural Language Generation,</booktitle>
<location>Herstmonceux Castle, UK.</location>
<contexts>
<context position="13035" citStr="Nicolov et al. (1996)" startWordPosition="2161" endWordPosition="2164"> 138 trees (including the two examples given above). The repository has been developed for and integrated into the ESHOWROOM system which is currently being fielded. A start is being made with porting the MNLG to a new domain and documentation is being created to allow our project partners to carry out this task. We hope that our efforts will contribute to addressing a challenge expressed in (Retem, supporting fast generation. Moreover, by using features for unbounded dependencies we do not require the adjunction operation, which is incompatible with our topdown generation approach. We follow Nicolov et al. (1996), who also use TAG, in their commitment to flat semantics. Their generator does, however, not take pragmatic constraints into account. iter, 1999): &amp;quot;We hope that future systems such as STOP will be able to make more use of deep techniques, because of advances in linguistics and the development of reusable wide-coverage NLG components that are robust, well-documented and well engineered as software artifacts.&amp;quot; In our view the best way to approach this goal is by providing a framework which allows for the flexible integration of shallow and deep generation, thus making it possible that in the co</context>
</contexts>
<marker>Nicolov, Mellish, Ritchie, 1996</marker>
<rawString>Nicholas Nicolov, Chris Mellish &amp; Graeme Ritchie. 1996. Approximate Generation from Non-Hierarchical Representattions, Proc. 8th International Workshop on Natural Language Generation, Herstmonceux Castle, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Piwek</author>
<author>Brigitte Krenn</author>
<author>Marc Schröder</author>
<author>Martine Grice</author>
<author>Stefan Baumann</author>
<author>Hannes Pirker</author>
</authors>
<title>RRL: A Rich Representation Language for the Description of Agent Behaviour</title>
<date>2002</date>
<booktitle>in NECA. Proc. of the AAMAS workshop</booktitle>
<location>Bologna, Italy.</location>
<contexts>
<context position="2512" citStr="Piwek et al., 2002" startWordPosition="388" endWordPosition="391">d non-linguistic realizations for the dialogue acts in the dialogue plan. • A SPEECH SYNTHESIS MODULE, which adds information for Speech. • A GESTURE ASSIGNMENT MODULE, which controls the temporal coordination of gestures and speech. • A PLAYER, which plays the animated characters and the corresponding speech sound files. Each step in the pipeline adds more concrete information to the dialogue plan/script until finally a player can render it. A single XML compliant representation language, called RRL, has been developed for representing the Dialogue Script at its various stages of completion (Piwek et al., 2002). In this paper, we describe the requirements for the NECA MNLG, how these have been translated into design solutions and finally some of aspects of the implementation. 2 Requirements The requirements in this section derive primarly from the use case of the NECA system. We do, however, try to indicate in what respects these requirements transcend this specific application and are desirable for generation systems in general. REQUIREMENT 1: The linguistic resources of the generator should support seamless integration of canned text, templates and full grammar rules. In the NECA system, the dialo</context>
</contexts>
<marker>Piwek, Krenn, Schröder, Grice, Baumann, Pirker, 2002</marker>
<rawString>Paul Piwek, Brigitte Krenn, Marc Schröder, Martine Grice, Stefan Baumann and Hannes Pirker. 2002. RRL: A Rich Representation Language for the Description of Agent Behaviour in NECA. Proc. of the AAMAS workshop &amp;quot;Embodied conversational agents - let&apos;s specibi and evaluate them! &amp;quot;, Bologna, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ehud Reiter</author>
</authors>
<title>Shallow vs. Deep Techniques for handling Linguistic Constraints and Optimisations.</title>
<date>1999</date>
<booktitle>Proc. of K1-99 Workshop</booktitle>
<marker>Reiter, 1999</marker>
<rawString>Ehud Reiter. 1999. Shallow vs. Deep Techniques for handling Linguistic Constraints and Optimisations. Proc. of K1-99 Workshop &amp;quot;May I speakfreely&amp;quot;.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ehud Reiter</author>
<author>Robert Dale</author>
</authors>
<title>Building natural language generation systems.</title>
<date>2000</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge.</location>
<contexts>
<context position="6375" citStr="Reiter and Dale, 2000" startWordPosition="1001" endWordPosition="1004"> real-world applications The application in which our generator is being used is currently fielded as part of a netenvironment. The application will be evaluated with users through online questionnaires which are integrated in the application and analysis of log files (to answer questions such as &apos;Do users try different settings of the application?&apos;, etc. See Krenn et al., 2002). Therefore, the generator will have to be fast in order for it not to negatively affect the user experience of the system. 3 Design Solutions The NECA MNLG adopts the conventional pipeline architecture for generators (Reiter and Dale, 2000). Its input is a RRL dialogue plan. This is parsed and internally represented as a PROFIT typed feature structure (Erbach, 1995). Subsequently, the dialogue acts in the plan are realized in accordance with their temporal order. For each act, first a deep syntactic structure is generated. The deep structure of referring expressions is dealt with in a separate module, which takes the common ground of the interlocutors into account. Subsequently, lexical realization (agreement, inflection) and punctuation is performed. Finally, turntaking gestures are added and the output is mapped back into the </context>
</contexts>
<marker>Reiter, Dale, 2000</marker>
<rawString>Ehud Reiter and Robert Dale. 2000. Building natural language generation systems. Cambridge University Press, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Stone</author>
<author>Christy Doran</author>
</authors>
<title>Sentence Planning as Description Using Tree-Adjoining Grammar.</title>
<date>1997</date>
<booktitle>Proc. ACL</booktitle>
<location>Madrid,</location>
<contexts>
<context position="10891" citStr="Stone and Doran, 1997" startWordPosition="1784" endWordPosition="1787">gGap!ArgGap &amp; auxGap!AuxGap &amp; sem!drs (_,[ negation ( drs (_, [ atyprgel ((EE:xTyp) IRI ] ) ), ) , [ (&lt;np &amp; currentAct !CA &amp; sem!X,[ ] ) , (&lt;vP &amp; argGap!ArgGap &amp; auxGap!AuxGap &amp; negated!&lt;true &amp; sem!drs (_,[ type (E, Type) IR] ) &amp; currentAct!CA,_) ] ) • Note that this rule applies to an input node whose semantic content contains a negation. The negation is passed on to the VP subtree via the feature negated. The attributes argGap and auxGap allow us to capture unbounded dependencies via feature perlocation. Our use of trees is related to the Tree Adjoining Grammar approach to generation (e.g., Stone and Doran, 1997).3 3 Their generation algorithm is, however, very different from the one proposed here. Whereas they propose an integrated planning approach, we advocate a very modular sysThe value of the attribute currentAct is passed on from the mother node to the daughter nodes. Thus any pragmatic information (personality, politeness, emotion, etc.) is passed on through the tree and can be accessed at a later stage, for instance, when lexical items are selected. 4 Implementation The NECA MNLG has been implemented in PROLOG. The output is in the form of an RRL XML document. Table 1 provides a sample of the </context>
</contexts>
<marker>Stone, Doran, 1997</marker>
<rawString>Matthew Stone and Christy Doran. 1997. Sentence Planning as Description Using Tree-Adjoining Grammar. Proc. ACL 1997, Madrid, Spain.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>