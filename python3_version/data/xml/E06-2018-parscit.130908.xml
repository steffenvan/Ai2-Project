<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.166370">
<title confidence="0.984845">
Exploring the Sense Distributions of Homographs
</title>
<author confidence="0.926674">
Reinhard Rapp
</author>
<affiliation confidence="0.890102">
University of Mainz, FASK
</affiliation>
<address confidence="0.334584">
76711 Germersheim, Germany
</address>
<email confidence="0.548677">
rrapp@uni-mainz.de
</email>
<sectionHeader confidence="0.98177" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99960552631579">
This paper quantitatively investigates in
how far local context is useful to disam-
biguate the senses of an ambiguous word.
This is done by comparing the co-occur-
rence frequencies of particular context
words. First, one context word repre-
senting a certain sense is chosen, and then
the co-occurrence frequencies with two
other context words, one of the same and
one of another sense, are compared. As
expected, it turns out that context words
belonging to the same sense have consid-
erably higher co-occurrence frequencies
than words belonging to different senses.
In our study, the sense inventory is taken
from the University of South Florida
homograph norms, and the co-occurrence
counts are based on the British National
Corpus.
</bodyText>
<sectionHeader confidence="0.998979" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999846826086956">
Word sense induction and disambiguation is of
importance for many tasks in speech and lan-
guage processing, such as speech recognition,
machine translation, natural language under-
standing, question answering, and information re-
trieval. As evidenced by several SENSEVAL
sense disambiguation competitions (Kilgarriff &amp;
Palmer, 2000), statistical methods are dominant
in this field. However, none of the published al-
gorithms comes close to human performance in
word sense disambiguation, and it is therefore
unclear in how far the statistical regularities that
are exploited in these algorithms are a solid basis
to eventually solve the problem.
Although this is a difficult question, in this
study we try to give at least a partial answer. Our
starting point is the observation that ambiguous
words can usually be disambiguated by their con-
text, and that certain context words can be seen
as indicators of certain senses. For example, con-
text words such as finger and arm are typical of
the hand meaning of palm, whereas coconut and
oil are typical of its tree meaning. The essence
behind many algorithms for word sense disam-
biguation is to implicitly or explicitly classify all
possible context words into groups relating to
one or another sense. This can be done in a su-
pervised (Yarowsky, 1994), a semi-supervised
(Yarowsky, 1995) or a fully unsupervised way
(Pantel &amp; Lin, 2002).
However, the classification can only work if
the statistical clues are clear enough and if there
are not too many exceptions. In terms of word
co-occurrence statistics, we can say that within
the local contexts of an ambiguous word, context
words typical of the same sense should have high
co-occurrence counts, whereas context words as-
sociated with different senses should have co-
occurrence counts that are considerably lower.
Although the relative success of previous disam-
biguation systems (e.g. Yarowsky, 1995) sug-
gests that this should be the case, the effect has
usually not been quantified as the emphasis was
on a task-based evaluation. Also, in most cases
the amount of context to be used has not been
systematically examined.
</bodyText>
<sectionHeader confidence="0.994201" genericHeader="introduction">
2 Methodology
</sectionHeader>
<bodyText confidence="0.999845047619048">
Our starting point is a list of 288 ambiguous
words (homographs) where each comes together
with two associated words that are typical of one
sense and a third associated word that is typical
of another sense. Table 1 shows the first ten en-
tries in the list. It has been derived from the Uni-
versity of South Florida homograph norms (Nel-
son et al., 1980) and is based on a combination of
native speakers’ intuition and the expertise of
specialists.
The University of South Florida homograph
norms comprise 320 words which were all se-
lected from Roget’s International Thesaurus
(1962). Each word has at least two distinct mean-
ings that were judged as likely to be understood
by everyone. As described in detail in Nelson et
al. (1980), the compilation of the norms was con-
ducted as follows: 46 subjects wrote down the
first word that came to mind for each of the 320
homographs. In the next step, for each homo-
graph semantic categories were chosen to reflect
</bodyText>
<page confidence="0.998505">
155
</page>
<bodyText confidence="0.997295">
its meanings. All associative responses given by
the subjects were assigned to one of these catego-
ries. This was first done by four judges individu-
ally, and then, before final categorization, each
response was discussed until a consensus was
achieved.
The data used in our study (first ten items
shown in Table 1) was extracted from these
norms by selecting for each homograph the first
two words relating to its first meaning and the
first word relating to its second meaning.
Thereby we had to abandon those homographs
where all of the subjects’ responses had been as-
signed to a single category, so that only one cate-
gory appeared in the homograph norms. This was
the case for 32 words, which is the reason that
our list comprises only 288 instead of 320 items.
Another resource that we use is the British Na-
tional Corpus (BNC), which is a balanced sample
of written and spoken English that comprises
about 100 million words (Burnard &amp; Aston,
1998). This corpus was used without special pre-
processing, i.e. stop words were not removed and
no stemming was conducted. From the corpus we
extracted concordances comprising text windows
of a certain width (e.g. plus and minus 20 words
around the given word) for each of the 288
homographs. For each concordance we computed
two counts: The first is the number of con-
cordance lines where the two words associated
with sense 1 occur together. The second is the
number of concordance lines where the first word
associated with sense 1 and the word associated
with sense 2 co-occur. The expectation is that the
first count should be higher as words associated
to the same sense should co-occur more often
than words associated to different senses.
homo- sense 1 sense 2
graph
first asso- second asso- first asso-
ciation (w1) ciation (w2) ciation (w3)
arm leg hand war
ball game base dance
bar drink beer crow
bark dog loud tree
base ball line bottom
bass fish trout drum
bat ball boy fly
bay Tampa water hound
bear animal woods weight
beam wood ceiling light
</bodyText>
<tableCaption confidence="0.916755">
Table 1. First ten of 288 homographs and some
associations to their first and second senses.
</tableCaption>
<bodyText confidence="0.995063961538462">
However, as absolute word frequencies can
vary over several orders of magnitude and as this
effect could influence our co-occurrence counts
in an undesired way, we decided to take this into
account by dividing the co-occurrence counts by
the concordance frequency of the second words
in our pairs. We did not normalize for the fre-
quency of the first word as it is identical for both
pairs and therefore represents a constant factor.
Note that we normalized for the observed fre-
quency within the concordance and not within
the entire corpus.
If we denote the first word associated to
sense 1 with w1, the second word associated with
sense 1 with w2, and the word associated with
sense 2 with w3, the two scores s1 and s2 that we
compute can be described as follows:
number of lines where w1 and w2 co-occur
occurrence count of w2 within concordance
number of lines where w1 and w3 co-occur
occurrence count of w3 within concordance
In cases where the denominator was zero we as-
signed a score of zero to the whole expression.
For all 288 homographs we compared s1 to s2. If
it turns out that in the vast majority of cases s1 is
higher than s2, then this result would be an indi-
cator that it is promising to use such co-occur-
rence statistics for the assignment of context
words to senses. On the other hand, should this
not be the case, the conclusion would be that this
approach does not have the potential to work and
should be discarded.
As in statistics the results are often not as clear
cut as would be desirable, for comparison we
conducted another experiment to help us with the
interpretation. This time the question was
whether our results were caused by properties of
the homographs or if we had only measured
properties of the context words w1, w2 and w3.
The idea was to conduct the same experiment
again, but this time not based on concordances
but on the entire corpus. However, considering
the entire corpus would make it necessary to use
a different kind of text window for counting the
co-occurrences as there would be no given word
to center the text window around, which could
lead to artefacts and make the comparison prob-
lematic. We therefore decided to use concor-
dances again, but this time not the concordances
of the homographs (first column in Table 1) but
the concordances of all 288 instances of w1 (sec-
ond column in Table 1). This way we had exactly
</bodyText>
<equation confidence="0.9987035">
s1 =
s2 =
</equation>
<page confidence="0.992889">
156
</page>
<bodyText confidence="0.999908833333333">
the same window type as in the first experiment,
but this time the entire corpus was taken into ac-
count as all co-occurrences of w2 or w3 with w1
must necessarily appear within the concordance
of w1.
We name the scores resulting from this ex-
periment s3 and s4, where s3 corresponds to s1
and s4 corresponds to s2, with the only difference
being that the concordances of the homographs
are replaced by the concordances of the instances
of w1. Regarding the interpretation of the results,
if the ratio between s3 and s4 should turn out to
be similar to the ratio between s1 and s2, then the
influence of the homographs would be margin-
ally or non existent. If there should be a major
difference, then this would give evidence that, as
desired, a property of the homograph has been
measured.
</bodyText>
<sectionHeader confidence="0.999626" genericHeader="related work">
3 Results and discussion
</sectionHeader>
<bodyText confidence="0.999949571428571">
Following the procedure described in the previ-
ous section, Table 2 gives some quantitative re-
sults. It shows the overall results for the homo-
graph-based concordance and for the w1-based
concordance for different concordance widths. In
each case not only the number of cases is given
where the results correspond to expectations
(s1 &gt; s2 and s3 &gt; s4), but also the number of
cases where the outcome is undecided (s1 = s2
and s3 = s4). Although this adds some redun-
dancy, for convenience also the number of cases
with an unexpected outcome is listed. All three
numbers sum up to 288 which is the total number
of homographs considered.
If we look at the left half of Table 2 which
shows the results for the concordances based on
the homographs, we can see that the number of
correct cases steadily increases with increasing
width of the concordance until a width of ±300 is
reached. At the same time, the number of unde-
cided cases rapidly goes down. At a concordance
width of ±300, the number of correct cases (201)
outnumbers the number of incorrect cases (63) by
a factor of 3.2. Note that the increase of incorrect
cases is probably mostly an artefact of the sparse-
data-problem as the number of undecided cases
decreases faster than the number of correct cases
increases.
On the right half of Table 2 the results for the
concordances based on w1 are given. Here the
number of correct cases starts at a far higher level
for small concordance widths, increases up to a
concordance width of ±10 where it reaches its
maximum, and then decreases slowly. At the
concordance width of ±10 the ratio between cor-
rect and incorrect cases is 2.6.
How can we now interpret these results? What
we can say for sure when we look at the number
of undecided cases is that the problem of data
sparseness is much more severe if we consider
the concordances of the homographs rather than
the concordances of w1. This outcome can be ex-
pected as in the first case we only take a (usually
small) fraction of the full corpus into account,
whereas the second case is equivalent to consid-
ering the full corpus. What we can also say is that
the optimal concordance width depends on data
sparseness. If data is more sparse, we need a
wider concordance width to obtain best results.
</bodyText>
<table confidence="0.995990875">
concordance concordance of homograph concordance of w1
width
s1 &gt; s2 s1 = s2 s1 &lt; s2 s3 &gt; s4 s3 = s4 s3 &lt; s4
correct undecided incorrect correct undecided incorrect
±1 1 287 0 107 135 46
±2 15 273 0 158 69 61
±3 32 249 7 179 40 69
±5 54 222 12 194 21 73
±10 81 181 26 199 13 76
±20 126 127 35 196 7 85
±30 129 105 44 192 5 91
±50 165 69 54 192 2 94
±100 182 44 62 185 1 102
±200 198 29 61 177 1 110
±300 201 24 63 177 1 110
±500 199 19 70 171 1 116
</table>
<tableCaption confidence="0.999278">
Table 2. Results for homograph-based concordance (left) and for w1-based concordance (right).
</tableCaption>
<page confidence="0.997201">
157
</page>
<bodyText confidence="0.999923866666667">
In case of the full corpus the optimal width is
around ±10 which is similar to average sentence
length. Larger windows seem to reduce saliency
and therefore affect the results adversely. In
comparison, if we look at the concordances of
the homographs, the negative effect on saliency
with increasing concordance width seems to be
more than outweighed by the decrease in sparse-
ness, as the results at a very large width of ±300
are better than the best results for the full corpus.
However, if we used a much larger corpus than
the BNC, it can be expected that best results
would be achieved at a smaller width, and that
these are likely to be better than the ones
achieved using the BNC.
</bodyText>
<sectionHeader confidence="0.997216" genericHeader="conclusions">
4 Conclusions and future work
</sectionHeader>
<bodyText confidence="0.999989770833333">
Our experiments showed that associations be-
longing to the same sense of a homograph have
far higher co-occurrence counts than associations
belonging to different senses. This is especially
true when we look at the concordances of the
homographs, but – to a somewhat lesser extend –
also when we look at the full corpus. The dis-
crepancy between the two approaches can proba-
bly be enlarged by increasing the size of the cor-
pus. However, further investigations are neces-
sary to verify this claim.
With the approach based on the concordances
of the homographs best results were achieved
with concordance widths that are about an order
of magnitude larger than average sentence
length. However, human performance shows that
the context within a sentence usually suffices to
disambiguate a word. A much larger corpus
could possibly solve this problem as it should al-
low to reduce concordance width without loosing
accuracy. However, since human language ac-
quisition seems to be based on the reception of
only in the order of 100 million words (Lan-
dauer &amp; Dumais, 1997, p. 222), and because the
BNC already is of that size, there also must be
another solution to this problem.
Our suggestion is to not look at the co-occur-
rence frequencies of single word pairs, but at the
average co-occurrence frequencies between sev-
eral pairs derived from larger groups of words.
Let us illustrate this by coming back to our ex-
ample in the introduction, where we stated that
context words such as finger and arm are typical
of the hand meaning of palm, whereas coconut
and oil are typical of its tree meaning. The
sparse-data-problem may possibly prevent our
expectation come true, namely that finger and
arm co-occur more often than finger and coco-
nut. But if we add other words that are typical of
the hand meaning, e.g. hold or wrist, then an in-
cidental lack of observed co-occurrences be-
tween a particular pair can be compensated by
co-occurrences between other pairs. Since the
number of possible pairs increases quadratically
with the number of words that are considered,
this should have a significant positive effect on
the sparse-data-problem, which is to be exam-
ined in future work.
</bodyText>
<sectionHeader confidence="0.99828" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9981535">
I would like to thank the three anonymous re-
viewers for their detailed and helpful comments.
</bodyText>
<sectionHeader confidence="0.999384" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99286125">
Burnard, Lou.; Aston, Guy (1998). The BNC
Handbook: Exploring the British National
Corpus with Sara. Edinburgh University
Press.
Kilgarriff, Adam; Palmer, Martha (eds.) (2000).
International Journal of Computers and the
Humanities. Special Issue on SENSEVAL,
34(1-2), 2000.
Landauer, Thomas K.; Dumais, Susan S. (1997).
A solution to Plato’s problem: the latent se-
mantic analysis theory of acquisition, induc-
tion and representation of knowledge. Psy-
chological Review 104(2), 211-240.
Nelson, Douglas L.; McEvoy, Cathy L.; Walling,
John R.; Wheeler, Joseph W. (1980). The
University of South Florida homograph
norms. Behavior Research Methods &amp; Instru-
mentation 12(1), 16-37.
Pantel, Patrick; Lin, Dekang (2002). Discovering
word senses from text. In: Proceedings of
ACM SIGKDD, Edmonton, 613-619.
Roget’s International Thesaurus (3rd ed., 1962).
New York: Crowell.
Yarowsky, David (1994). Decision lists for lexi-
cal ambiguity resolution: application to accent
restoration in Spanish and French. Proceed-
ings of the 32nd Meeting of the ACL, Las Cru-
ces, NM, 88-95.
Yarowsky, David (1995). Unsupervised word
sense disambiguation rivaling supervised me-
thods. Proceedings of the 33rd Meeting of the
ACL, Cambridge, MA, 189-196.
</reference>
<page confidence="0.997089">
158
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.282899">
<title confidence="0.999924">Exploring the Sense Distributions of Homographs</title>
<author confidence="0.999963">Reinhard Rapp</author>
<affiliation confidence="0.999362">University of Mainz, FASK</affiliation>
<address confidence="0.999868">76711 Germersheim, Germany</address>
<email confidence="0.999433">rrapp@uni-mainz.de</email>
<abstract confidence="0.9878835">This paper quantitatively investigates in how far local context is useful to disambiguate the senses of an ambiguous word. This is done by comparing the co-occurrence frequencies of particular context words. First, one context word representing a certain sense is chosen, and then the co-occurrence frequencies with two other context words, one of the same and one of another sense, are compared. As expected, it turns out that context words belonging to the same sense have considerably higher co-occurrence frequencies than words belonging to different senses. In our study, the sense inventory is taken from the University of South Florida homograph norms, and the co-occurrence</abstract>
<note confidence="0.498033">counts are based on the British National Corpus.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Lou Burnard</author>
<author>Guy Aston</author>
</authors>
<date>1998</date>
<booktitle>The BNC Handbook: Exploring the British National Corpus with Sara.</booktitle>
<publisher>Edinburgh University Press.</publisher>
<contexts>
<context position="4930" citStr="Burnard &amp; Aston, 1998" startWordPosition="810" endWordPosition="813">from these norms by selecting for each homograph the first two words relating to its first meaning and the first word relating to its second meaning. Thereby we had to abandon those homographs where all of the subjects’ responses had been assigned to a single category, so that only one category appeared in the homograph norms. This was the case for 32 words, which is the reason that our list comprises only 288 instead of 320 items. Another resource that we use is the British National Corpus (BNC), which is a balanced sample of written and spoken English that comprises about 100 million words (Burnard &amp; Aston, 1998). This corpus was used without special preprocessing, i.e. stop words were not removed and no stemming was conducted. From the corpus we extracted concordances comprising text windows of a certain width (e.g. plus and minus 20 words around the given word) for each of the 288 homographs. For each concordance we computed two counts: The first is the number of concordance lines where the two words associated with sense 1 occur together. The second is the number of concordance lines where the first word associated with sense 1 and the word associated with sense 2 co-occur. The expectation is that </context>
</contexts>
<marker>Burnard, Aston, 1998</marker>
<rawString>Burnard, Lou.; Aston, Guy (1998). The BNC Handbook: Exploring the British National Corpus with Sara. Edinburgh University Press.</rawString>
</citation>
<citation valid="true">
<date>2000</date>
<booktitle>International Journal of Computers and the Humanities. Special Issue on SENSEVAL,</booktitle>
<pages>34--1</pages>
<editor>Kilgarriff, Adam; Palmer, Martha (eds.) (2000).</editor>
<marker>2000</marker>
<rawString>Kilgarriff, Adam; Palmer, Martha (eds.) (2000). International Journal of Computers and the Humanities. Special Issue on SENSEVAL, 34(1-2), 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas K Landauer</author>
<author>Susan S Dumais</author>
</authors>
<title>A solution to Plato’s problem: the latent semantic analysis theory of acquisition, induction and representation of knowledge.</title>
<date>1997</date>
<journal>Psychological Review</journal>
<volume>104</volume>
<issue>2</issue>
<pages>211--240</pages>
<contexts>
<context position="13856" citStr="Landauer &amp; Dumais, 1997" startWordPosition="2421" endWordPosition="2425">ther investigations are necessary to verify this claim. With the approach based on the concordances of the homographs best results were achieved with concordance widths that are about an order of magnitude larger than average sentence length. However, human performance shows that the context within a sentence usually suffices to disambiguate a word. A much larger corpus could possibly solve this problem as it should allow to reduce concordance width without loosing accuracy. However, since human language acquisition seems to be based on the reception of only in the order of 100 million words (Landauer &amp; Dumais, 1997, p. 222), and because the BNC already is of that size, there also must be another solution to this problem. Our suggestion is to not look at the co-occurrence frequencies of single word pairs, but at the average co-occurrence frequencies between several pairs derived from larger groups of words. Let us illustrate this by coming back to our example in the introduction, where we stated that context words such as finger and arm are typical of the hand meaning of palm, whereas coconut and oil are typical of its tree meaning. The sparse-data-problem may possibly prevent our expectation come true, </context>
</contexts>
<marker>Landauer, Dumais, 1997</marker>
<rawString>Landauer, Thomas K.; Dumais, Susan S. (1997). A solution to Plato’s problem: the latent semantic analysis theory of acquisition, induction and representation of knowledge. Psychological Review 104(2), 211-240.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Douglas L Nelson</author>
<author>Cathy L McEvoy</author>
<author>John R Walling</author>
<author>Joseph W Wheeler</author>
</authors>
<title>The University of South Florida homograph norms.</title>
<date>1980</date>
<journal>Behavior Research Methods &amp; Instrumentation</journal>
<volume>12</volume>
<issue>1</issue>
<pages>16--37</pages>
<contexts>
<context position="3372" citStr="Nelson et al., 1980" startWordPosition="538" endWordPosition="542">on systems (e.g. Yarowsky, 1995) suggests that this should be the case, the effect has usually not been quantified as the emphasis was on a task-based evaluation. Also, in most cases the amount of context to be used has not been systematically examined. 2 Methodology Our starting point is a list of 288 ambiguous words (homographs) where each comes together with two associated words that are typical of one sense and a third associated word that is typical of another sense. Table 1 shows the first ten entries in the list. It has been derived from the University of South Florida homograph norms (Nelson et al., 1980) and is based on a combination of native speakers’ intuition and the expertise of specialists. The University of South Florida homograph norms comprise 320 words which were all selected from Roget’s International Thesaurus (1962). Each word has at least two distinct meanings that were judged as likely to be understood by everyone. As described in detail in Nelson et al. (1980), the compilation of the norms was conducted as follows: 46 subjects wrote down the first word that came to mind for each of the 320 homographs. In the next step, for each homograph semantic categories were chosen to refl</context>
</contexts>
<marker>Nelson, McEvoy, Walling, Wheeler, 1980</marker>
<rawString>Nelson, Douglas L.; McEvoy, Cathy L.; Walling, John R.; Wheeler, Joseph W. (1980). The University of South Florida homograph norms. Behavior Research Methods &amp; Instrumentation 12(1), 16-37.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Pantel</author>
<author>Lin</author>
</authors>
<title>Discovering word senses from text. In:</title>
<date>2002</date>
<booktitle>Proceedings of ACM SIGKDD, Edmonton,</booktitle>
<pages>613--619</pages>
<contexts>
<context position="2268" citStr="Pantel &amp; Lin, 2002" startWordPosition="353" endWordPosition="356">he observation that ambiguous words can usually be disambiguated by their context, and that certain context words can be seen as indicators of certain senses. For example, context words such as finger and arm are typical of the hand meaning of palm, whereas coconut and oil are typical of its tree meaning. The essence behind many algorithms for word sense disambiguation is to implicitly or explicitly classify all possible context words into groups relating to one or another sense. This can be done in a supervised (Yarowsky, 1994), a semi-supervised (Yarowsky, 1995) or a fully unsupervised way (Pantel &amp; Lin, 2002). However, the classification can only work if the statistical clues are clear enough and if there are not too many exceptions. In terms of word co-occurrence statistics, we can say that within the local contexts of an ambiguous word, context words typical of the same sense should have high co-occurrence counts, whereas context words associated with different senses should have cooccurrence counts that are considerably lower. Although the relative success of previous disambiguation systems (e.g. Yarowsky, 1995) suggests that this should be the case, the effect has usually not been quantified a</context>
</contexts>
<marker>Pantel, Lin, 2002</marker>
<rawString>Pantel, Patrick; Lin, Dekang (2002). Discovering word senses from text. In: Proceedings of ACM SIGKDD, Edmonton, 613-619.</rawString>
</citation>
<citation valid="true">
<date>1962</date>
<booktitle>Roget’s International Thesaurus (3rd ed.,</booktitle>
<publisher>Crowell.</publisher>
<location>New York:</location>
<contexts>
<context position="3601" citStr="(1962)" startWordPosition="577" endWordPosition="577"> examined. 2 Methodology Our starting point is a list of 288 ambiguous words (homographs) where each comes together with two associated words that are typical of one sense and a third associated word that is typical of another sense. Table 1 shows the first ten entries in the list. It has been derived from the University of South Florida homograph norms (Nelson et al., 1980) and is based on a combination of native speakers’ intuition and the expertise of specialists. The University of South Florida homograph norms comprise 320 words which were all selected from Roget’s International Thesaurus (1962). Each word has at least two distinct meanings that were judged as likely to be understood by everyone. As described in detail in Nelson et al. (1980), the compilation of the norms was conducted as follows: 46 subjects wrote down the first word that came to mind for each of the 320 homographs. In the next step, for each homograph semantic categories were chosen to reflect 155 its meanings. All associative responses given by the subjects were assigned to one of these categories. This was first done by four judges individually, and then, before final categorization, each response was discussed u</context>
</contexts>
<marker>1962</marker>
<rawString>Roget’s International Thesaurus (3rd ed., 1962). New York: Crowell.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
</authors>
<title>Decision lists for lexical ambiguity resolution: application to accent restoration in Spanish and French.</title>
<date>1994</date>
<booktitle>Proceedings of the 32nd Meeting of the ACL, Las Cruces, NM,</booktitle>
<pages>88--95</pages>
<contexts>
<context position="2183" citStr="Yarowsky, 1994" startWordPosition="342" endWordPosition="343">, in this study we try to give at least a partial answer. Our starting point is the observation that ambiguous words can usually be disambiguated by their context, and that certain context words can be seen as indicators of certain senses. For example, context words such as finger and arm are typical of the hand meaning of palm, whereas coconut and oil are typical of its tree meaning. The essence behind many algorithms for word sense disambiguation is to implicitly or explicitly classify all possible context words into groups relating to one or another sense. This can be done in a supervised (Yarowsky, 1994), a semi-supervised (Yarowsky, 1995) or a fully unsupervised way (Pantel &amp; Lin, 2002). However, the classification can only work if the statistical clues are clear enough and if there are not too many exceptions. In terms of word co-occurrence statistics, we can say that within the local contexts of an ambiguous word, context words typical of the same sense should have high co-occurrence counts, whereas context words associated with different senses should have cooccurrence counts that are considerably lower. Although the relative success of previous disambiguation systems (e.g. Yarowsky, 1995</context>
</contexts>
<marker>Yarowsky, 1994</marker>
<rawString>Yarowsky, David (1994). Decision lists for lexical ambiguity resolution: application to accent restoration in Spanish and French. Proceedings of the 32nd Meeting of the ACL, Las Cruces, NM, 88-95.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
</authors>
<title>Unsupervised word sense disambiguation rivaling supervised methods.</title>
<date>1995</date>
<booktitle>Proceedings of the 33rd Meeting of the ACL,</booktitle>
<pages>189--196</pages>
<location>Cambridge, MA,</location>
<contexts>
<context position="2219" citStr="Yarowsky, 1995" startWordPosition="346" endWordPosition="347">ast a partial answer. Our starting point is the observation that ambiguous words can usually be disambiguated by their context, and that certain context words can be seen as indicators of certain senses. For example, context words such as finger and arm are typical of the hand meaning of palm, whereas coconut and oil are typical of its tree meaning. The essence behind many algorithms for word sense disambiguation is to implicitly or explicitly classify all possible context words into groups relating to one or another sense. This can be done in a supervised (Yarowsky, 1994), a semi-supervised (Yarowsky, 1995) or a fully unsupervised way (Pantel &amp; Lin, 2002). However, the classification can only work if the statistical clues are clear enough and if there are not too many exceptions. In terms of word co-occurrence statistics, we can say that within the local contexts of an ambiguous word, context words typical of the same sense should have high co-occurrence counts, whereas context words associated with different senses should have cooccurrence counts that are considerably lower. Although the relative success of previous disambiguation systems (e.g. Yarowsky, 1995) suggests that this should be the c</context>
</contexts>
<marker>Yarowsky, 1995</marker>
<rawString>Yarowsky, David (1995). Unsupervised word sense disambiguation rivaling supervised methods. Proceedings of the 33rd Meeting of the ACL, Cambridge, MA, 189-196.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>