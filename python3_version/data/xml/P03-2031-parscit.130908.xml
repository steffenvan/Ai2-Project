<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001650">
<title confidence="0.9506295">
Automatic Acquisition of Named Entity Tagged Corpus from World Wide
Web
</title>
<author confidence="0.920085">
Joohui An
</author>
<affiliation confidence="0.720218">
Dept. of CSE
POSTECH
</affiliation>
<address confidence="0.71249">
Pohang, Korea 790-784
</address>
<email confidence="0.965504">
minnie@postech.ac.kr
</email>
<author confidence="0.619901">
Seungwoo Lee
</author>
<affiliation confidence="0.489864">
Dept. of CSE
POSTECH
</affiliation>
<address confidence="0.607393">
Pohang, Korea 790-784
</address>
<email confidence="0.928223">
pinesnow@postech.ac.kr
</email>
<author confidence="0.66042">
Gary Geunbae Lee
</author>
<affiliation confidence="0.521855">
Dept. of CSE
POSTECH
</affiliation>
<address confidence="0.63756">
Pohang, Korea 790-784
</address>
<email confidence="0.96502">
gblee@postech.ac.kr
</email>
<sectionHeader confidence="0.981408" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999905875">
In this paper, we present a method that
automatically constructs a Named En-
tity (NE) tagged corpus from the web
to be used for learning of Named En-
tity Recognition systems. We use an NE
list and an web search engine to col-
lect web documents which contain the
NE instances. The documents are refined
through sentence separation and text re-
finement procedures and NE instances are
finally tagged with the appropriate NE cat-
egories. Our experiments demonstrates
that the suggested method can acquire
enough NE tagged corpus equally useful
to the manually tagged one without any
human intervention.
</bodyText>
<sectionHeader confidence="0.995068" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999848033333333">
Current trend in Named Entity Recognition (NER) is
to apply machine learning approach, which is more
attractive because it is trainable and adaptable, and
subsequently the porting of a machine learning sys-
tem to another domain is much easier than that of a
rule-based one. Various supervised learning meth-
ods for Named Entity (NE) tasks were successfully
applied and have shown reasonably satisfiable per-
formance.((Zhou and Su, 2002)(Borthwick et al.,
1998)(Sassano and Utsuro, 2000)) However, most
of these systems heavily rely on a tagged corpus for
training. For a machine learning approach, a large
corpus is required to circumvent the data sparseness
problem, but the dilemma is that the costs required
to annotate a large training corpus are non-trivial.
In this paper, we suggest a method that automati-
cally constructs an NE tagged corpus from the web
to be used for learning of NER systems. We use an
NE list and an web search engine to collect web doc-
uments which contain the NE instances. The doc-
uments are refined through the sentence separation
and text refinement procedures and NE instances are
finally annotated with the appropriate NE categories.
This automatically tagged corpus may have lower
quality than the manually tagged ones but its size
can be almost infinitely increased without any hu-
man efforts. To verify the usefulness of the con-
structed NE tagged corpus, we apply it to a learn-
ing of NER system and compare the results with the
manually tagged corpus.
</bodyText>
<sectionHeader confidence="0.845338" genericHeader="method">
2 Automatic Acquisition of an NE Tagged
Corpus
</sectionHeader>
<bodyText confidence="0.999990928571429">
We only focus on the three major NE categories (i.e.,
person, organization and location) because others
are relatively easier to recognize and these three cat-
egories actually suffer from the shortage of an NE
tagged corpus.
Various linguistic information is already held in
common in written form on the web and its quantity
is recently increasing to an almost unlimited extent.
The web can be regarded as an infinite language re-
source which contains various NE instances with di-
verse contexts. It is the key idea that automatically
marks such NE instances with appropriate category
labels using pre-compiled NE lists. However, there
should be some general and language-specific con-
</bodyText>
<note confidence="0.672142">
NE list Web page URL
</note>
<figureCaption confidence="0.981782">
Figure 1: Automatic generation of NE tagged corpus
from the web
</figureCaption>
<bodyText confidence="0.999977">
siderations in this marking process because of the
word ambiguity and boundary ambiguity of NE in-
stances. To overcome these ambiguities, the auto-
matic generation process of NE tagged corpus con-
sists of four steps. The process first collects web
documents using a web search engine fed with the
NE entries and secondly segments them into sen-
tences. Next, each sentence is refined and filtered
out by several heuristics. An NE instance in each
sentence is finally tagged with an appropriate NE
category label. Figure 1 explains the entire proce-
dure to automatically generate NE tagged corpus.
</bodyText>
<subsectionHeader confidence="0.99823">
2.1 Collecting Web Documents
</subsectionHeader>
<bodyText confidence="0.999993">
It is not appropriate for our purpose to randomly col-
lect documents from the web. This is because not all
web documents actually contain some NE instances
and we also do not have the list of all NE instances
occurring in the web documents. We need to col-
lect the web documents which necessarily contain
at least one NE instance and also should know its
category to automatically annotate it. This can be
accomplished by using a web search engine queried
with pre-compiled NE list.
As queries to a search engine, we used the list
of Korean Named Entities composed of 937 per-
son names, 1,000 locations and 1,050 organizations.
Using a Part-of-Speech dictionary, we removed am-
biguous entries which are not proper nouns in other
contexts to reduce errors of automatic annotation.
For example, ‘E¶(kyunggi, Kyunggi/business con-
ditions/a game)’ is filtered out because it means a lo-
cation (proper noun) in one context, but also means
business conditions or a game (common noun) in
other contexts. By submitting the NE entries as
queries to a search engine1, we obtained the max-
imum 500 of URL’s for each entry. Then, a web
robot visits the web sites in the URL list and fetches
the corresponding web documents.
</bodyText>
<subsectionHeader confidence="0.999589">
2.2 Splitting into Sentences
</subsectionHeader>
<bodyText confidence="0.999953866666667">
Features used in the most NER systems can be clas-
sified into two groups according to the distance from
a target NE instance. The one includes internal fea-
tures of NE itself and context features within a small
word window or sentence boundary and the other in-
cludes name alias and co-reference information be-
yond a sentence boundary. In fact, it is not easy to
extract name alias and co-reference information di-
rectly from manually tagged NE corpus and needs
additional knowledge or resources. This leads us to
focus on automatic annotation in sentence level, not
document level. Therefore, in this step, we split the
texts of the collected documents into sentences by
(Shim et al., 2002) and remove sentences without
target NE instances.
</bodyText>
<subsectionHeader confidence="0.997701">
2.3 Refining the Web Texts
</subsectionHeader>
<bodyText confidence="0.999975368421053">
The collected web documents may include texts ac-
tually matched by mistake, because most web search
engines for Korean use n-gram, especially, bi-gram
matching. This leads us to refine the sentences to ex-
clude these erroneous matches. Sentence refinement
is accomplished by three different processes: sep-
aration of functional words, segmentation of com-
pound nouns, and verification of the usefulness of
the extracted sentences.
An NE is often concatenated with more than one
josa, a Korean functional word, to compose a
Korean word. Therefore we need to separate the
functional words from an NE instance to detect the
boundary of the NE instance and this is achieved
by a part-of-speech tagger, POSTAG, which can
detect unknown words (Lee et al., 2002). The
separation of functional words gives us another
benefit that we can resolve the ambiguities between
an NE and a common noun plus functional words
</bodyText>
<figure confidence="0.98816403125">
1We used Empas (http://www.empas.com)
S1(t)
S2(t)
S3(t)
NE tagged
corpus
NE tag
generation
W1 URL1
W2 URL2
W3 URL3
Web search
engine
Text
refinement
S1
S2
S3
Refined
sentences
1.html
2.html
...
Web robot
Sentence
separator
Web
documents
1.ans
2.ans
Separated
sentences
</figure>
<table confidence="0.96686675">
Person Location Organization
Training Automatic 29,042 37,480 2,271
Manual 1,014 724 1,338
Test Manual 102 72 193
</table>
<tableCaption confidence="0.916457">
Table 1: Corpus description (number of NE’s) (Au-
tomatic: Automatically annotated corpus, Manual:
Manually annotated corpus
</tableCaption>
<bodyText confidence="0.999682391304348">
and filter out erroneous matches. For example,
‘7j71ê(kyunggi-do)’ can be interpreted as
either ‘7j71ê(Kyunggi Province)’ or ‘7j71+ê(a
game also)’ according to its context. We can remove
the sentence containing the latter case.
A josa-separated Korean word can be a com-
pound noun which only contains a target NE as a
substring. This requires us to segment the compound
noun into several correct single nouns to match with
the target NE. If the segmented single nouns are not
matched with a target NE, the sentence can be fil-
tered out. For example, we try to search for an NE
entry, ‘¶Á(Fin.KL, a Korean singer group)’ and
may actually retrieve sentences including ‘M¶Á
ě(surfing club)’. The compound noun, ‘M¶Áě’,
can be divided into ‘M¶(surfing)’ and ‘Áě(club)’
by a compound-noun segmenting method (Yun et
al., 1997). Since both ‘M¶’ and ‘Áě’ are not
matched with our target NE, ‘¶Á’, we can delete
the sentences. Although a sentence has a correct tar-
get NE, if it does not have context information, it is
not useful as an NE tagged corpus. We also removed
such sentences.
</bodyText>
<subsectionHeader confidence="0.984965">
2.4 Generating an NE tagged corpus
</subsectionHeader>
<bodyText confidence="0.9999645">
The sentences selected by the refining process ex-
plained in previous section are finally annotated with
the NE label. We acquired the NE tagged corpus in-
cluding 68,793 NE instances through this automatic
annotation process. We can annotate only one NE
instance per sentence but almost infinitely increase
the size of the corpus because the web provides un-
limited data and our process is fully automatic.
</bodyText>
<sectionHeader confidence="0.999298" genericHeader="method">
3 Experimental Results
</sectionHeader>
<subsectionHeader confidence="0.981334">
3.1 Usefulness of the Automatically Tagged
Corpus
</subsectionHeader>
<bodyText confidence="0.9987005">
For effectiveness of the learning, both the size and
the accuracy of the training corpus are important.
</bodyText>
<table confidence="0.9993426">
Training corpus Precision Recall F-measure
Seeds only 84.13 42.91 63.52
Manual 80.21 86.11 83.16
Automatic 81.45 85.41 83.43
Manual + Automatic 82.03 85.94 83.99
</table>
<tableCaption confidence="0.999485">
Table 2: Performance of the decision list learning
</tableCaption>
<bodyText confidence="0.9999328">
Generally, the accuracy of automatically created NE
tagged corpus is worse than that of hand-made cor-
pus. Therefore, it is important to examine the useful-
ness of our automatically tagged corpus compared
to the manual corpus. We separately trained the de-
cision list learning features using the automatically
annotated corpus and hand-made one, and compared
the performances. Table 1 shows the details of the
corpus used in our experiments.2
Through the results in Table 2, we can verify that
the performance with the automatic corpus is supe-
rior to that with only the seeds and comparable to
that with the manual corpus.Moreover, the domain
of the manual training corpus is same with that of
the test corpus, i.e., news and novels, while the do-
main of the automatic corpus is unlimited as in the
web. This indicates that the performance with the
automatic corpus should be regarded as much higher
than that with the manual corpus because the per-
formance generally gets worse when we apply the
learned system to different domains from the trained
ones. Also, the automatic corpus is pretty much self-
contained since the performance does not gain much
though we use both the manual corpus and the auto-
matic corpus for training.
</bodyText>
<subsectionHeader confidence="0.999115">
3.2 Size of the Automatically Tagged Corpus
</subsectionHeader>
<bodyText confidence="0.999945363636364">
As another experiment, we tried to investigate how
large automatic corpus we should generate to get the
satisfiable performance. We measured the perfor-
mance according to the size of the automatic cor-
pus. We carried out the experiment with the deci-
sion list learning method and the result is shown in
Table 3. Here, 5% actually corresponds to the size of
the manual corpus. When we trained with that size
of the automatic corpus, the performance was very
low compared to the performance of the manual cor-
pus. The reason is that the automatic corpus is com-
</bodyText>
<tableCaption confidence="0.2977495">
2We used the manual corpus used in Seon et al. (2001) as
training and test data.
</tableCaption>
<table confidence="0.999845">
Corpus size (words) Precision Recall F-measure
90,000 (5%) 72.43 6.94 39.69
448,000 (25%) 73.17 41.66 57.42
902,000 (50%) 75.32 61.53 68.43
1,370,000 (75%) 78.23 77.19 77.71
1,800,000 (100%) 81.45 85.41 83.43
</table>
<tableCaption confidence="0.983079">
Table 3: Performance according to the corpus size
</tableCaption>
<table confidence="0.9998632">
Corpus size (words) Precision Recall F-measure
700,000 79.41 81.82 80.62
1,000,000 82.86 85.29 84.08
1,200,000 83.81 86.27 85.04
1,300,000 83.81 86.27 85.04
</table>
<tableCaption confidence="0.9568515">
Table 4: Saturation point of the performance for
‘person’ category
</tableCaption>
<bodyText confidence="0.999815315789474">
posed of the sentences searched with fewer named
entities and therefore has less lexical and contextual
information than the same size of the manual cor-
pus. However, the automatic generation has a big
merit that the size of the corpus can be increased al-
most infinitely without much cost. From Table 3,
we can see that the performance is improved as the
size of the automatic corpus gets increased. As a
result, the NER system trained with the whole au-
tomatic corpus outperforms the NER system trained
with the manual corpus.
We also conducted an experiment to examine the
saturation point of the performance according to the
size of the automatic corpus. This experiment was
focused on only ‘person’ category and the result is
shown in Table 4. In the case of ‘person’ category,
we can see that the performance does not increase
any more when the corpus size exceeds 1.2 million
words.
</bodyText>
<sectionHeader confidence="0.999401" genericHeader="conclusions">
4 Conclusions
</sectionHeader>
<bodyText confidence="0.9998532">
In this paper, we presented a method that automat-
ically generates an NE tagged corpus using enor-
mous web documents. We use an internet search en-
gine with an NE list to collect web documents which
may contain the NE instances. The web documents
are segmented into sentences and refined through
sentence separation and text refinement procedures.
The sentences are finally tagged with the NE cat-
egories. We experimentally demonstrated that the
suggested method could acquire enough NE tagged
corpus equally useful to the manual corpus without
any human intervention. In the future, we plan to ap-
ply more sophisticated natural language processing
schemes for automatic generation of more accurate
NE tagged corpus.
</bodyText>
<sectionHeader confidence="0.992181" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.993035">
This research was supported by BK21 program of
Korea Ministry of Education and MOCIE strategic
mid-term funding through ITEP.
</bodyText>
<sectionHeader confidence="0.995014" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999899128205128">
Andrew Borthwick, John Sterling, Eugene Agichtein,
and Ralph Grishman. 1998. Exploiting Diverse
Knowledge Sources via Maximum Entropy in Named
Entity Recognition. In Proceedings of the Sixth Work-
shop on Very Large Corpora, pages 152–160, New
Brunswick, New Jersey. Association for Computa-
tional Linguistics.
Gary Geunbae Lee, Jeongwon Cha, and Jong-Hyeok
Lee. 2002. Syllable Pattern-based Unknown Mor-
pheme Segmentation and Estimation for Hybrid Part-
Of-Speech Tagging of Korean. Computational Lin-
guistics, 28(1):53–70.
Manabu Sassano and Takehito Utsuro. 2000. Named
Entity Chunking Techniques in Supervised Learning
for Japanese Named Entity Recognition. In Proceed-
ings of the 18th International Conference on Compu-
tational Linguistics (COLING 2000), pages 705–711,
Germany.
Choong-Nyoung Seon, Youngjoong Ko, Jeong-Seok
Kim, and Jungyun Seo. 2001. Named Entity Recog-
nition using Machine Learning Methods and Pattern-
Selection Rules. In Proceedings of the Sixth Natural
Language Processing Pacific Rim Symposium, pages
229–236, Tokyo, Japan.
Junhyeok Shim, Dongseok Kim, Jeongwon Cha,
Gary Geunbae Lee, and Jungyun Seo. 2002. Multi-
strategic Integrated Web Document Pre-processing for
Sentence and Word Boundary Detection. Information
Processing and Management, 38(4):509–527.
Bo-Hyun Yun, Min-Jeung Cho, and Hae-Chang Rim.
1997. Segmenting Korean Compound Nouns using
Statistical Information and a Preference Rule. Jour-
nal ofKorean Information Science Society, 24(8):900–
909.
GuoDong Zhou and Jian Su. 2002. Named Entity
Recognition using an HMM-based Chunk Tagger. In
Proceedings of the 40th Annual Meeting of the As-
sociation for Computational Linguistics (ACL), pages
473–480, Philadelphia, USA.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.385990">
<title confidence="0.798011">Automatic Acquisition of Named Entity Tagged Corpus from World Wide Web</title>
<author confidence="0.926849">Joohui An</author>
<affiliation confidence="0.9755835">Dept. of CSE POSTECH</affiliation>
<address confidence="0.94475">Pohang, Korea 790-784</address>
<email confidence="0.981495">minnie@postech.ac.kr</email>
<author confidence="0.923812">Seungwoo Lee</author>
<affiliation confidence="0.978534">Dept. of CSE POSTECH</affiliation>
<address confidence="0.975242">Pohang, Korea 790-784</address>
<email confidence="0.974745">pinesnow@postech.ac.kr</email>
<author confidence="0.938978">Gary Geunbae Lee</author>
<affiliation confidence="0.979288">Dept. of CSE POSTECH</affiliation>
<address confidence="0.97912">Pohang, Korea 790-784</address>
<email confidence="0.991543">gblee@postech.ac.kr</email>
<abstract confidence="0.998475823529412">In this paper, we present a method that automatically constructs a Named Entity (NE) tagged corpus from the web to be used for learning of Named Entity Recognition systems. We use an NE list and an web search engine to collect web documents which contain the NE instances. The documents are refined through sentence separation and text refinement procedures and NE instances are finally tagged with the appropriate NE categories. Our experiments demonstrates that the suggested method can acquire enough NE tagged corpus equally useful to the manually tagged one without any human intervention.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Andrew Borthwick</author>
<author>John Sterling</author>
<author>Eugene Agichtein</author>
<author>Ralph Grishman</author>
</authors>
<title>Exploiting Diverse Knowledge Sources via Maximum Entropy in Named Entity Recognition.</title>
<date>1998</date>
<booktitle>In Proceedings of the Sixth Workshop on Very Large Corpora,</booktitle>
<pages>152--160</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>New Brunswick, New Jersey.</location>
<contexts>
<context position="1381" citStr="Borthwick et al., 1998" startWordPosition="211" endWordPosition="214">s demonstrates that the suggested method can acquire enough NE tagged corpus equally useful to the manually tagged one without any human intervention. 1 Introduction Current trend in Named Entity Recognition (NER) is to apply machine learning approach, which is more attractive because it is trainable and adaptable, and subsequently the porting of a machine learning system to another domain is much easier than that of a rule-based one. Various supervised learning methods for Named Entity (NE) tasks were successfully applied and have shown reasonably satisfiable performance.((Zhou and Su, 2002)(Borthwick et al., 1998)(Sassano and Utsuro, 2000)) However, most of these systems heavily rely on a tagged corpus for training. For a machine learning approach, a large corpus is required to circumvent the data sparseness problem, but the dilemma is that the costs required to annotate a large training corpus are non-trivial. In this paper, we suggest a method that automatically constructs an NE tagged corpus from the web to be used for learning of NER systems. We use an NE list and an web search engine to collect web documents which contain the NE instances. The documents are refined through the sentence separation </context>
</contexts>
<marker>Borthwick, Sterling, Agichtein, Grishman, 1998</marker>
<rawString>Andrew Borthwick, John Sterling, Eugene Agichtein, and Ralph Grishman. 1998. Exploiting Diverse Knowledge Sources via Maximum Entropy in Named Entity Recognition. In Proceedings of the Sixth Workshop on Very Large Corpora, pages 152–160, New Brunswick, New Jersey. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gary Geunbae Lee</author>
<author>Jeongwon Cha</author>
<author>Jong-Hyeok Lee</author>
</authors>
<title>Syllable Pattern-based Unknown Morpheme Segmentation and Estimation for Hybrid PartOf-Speech Tagging of Korean.</title>
<date>2002</date>
<journal>Computational Linguistics,</journal>
<volume>28</volume>
<issue>1</issue>
<contexts>
<context position="6591" citStr="Lee et al., 2002" startWordPosition="1080" endWordPosition="1083">cially, bi-gram matching. This leads us to refine the sentences to exclude these erroneous matches. Sentence refinement is accomplished by three different processes: separation of functional words, segmentation of compound nouns, and verification of the usefulness of the extracted sentences. An NE is often concatenated with more than one josa, a Korean functional word, to compose a Korean word. Therefore we need to separate the functional words from an NE instance to detect the boundary of the NE instance and this is achieved by a part-of-speech tagger, POSTAG, which can detect unknown words (Lee et al., 2002). The separation of functional words gives us another benefit that we can resolve the ambiguities between an NE and a common noun plus functional words 1We used Empas (http://www.empas.com) S1(t) S2(t) S3(t) NE tagged corpus NE tag generation W1 URL1 W2 URL2 W3 URL3 Web search engine Text refinement S1 S2 S3 Refined sentences 1.html 2.html ... Web robot Sentence separator Web documents 1.ans 2.ans Separated sentences Person Location Organization Training Automatic 29,042 37,480 2,271 Manual 1,014 724 1,338 Test Manual 102 72 193 Table 1: Corpus description (number of NE’s) (Automatic: Automati</context>
</contexts>
<marker>Lee, Cha, Lee, 2002</marker>
<rawString>Gary Geunbae Lee, Jeongwon Cha, and Jong-Hyeok Lee. 2002. Syllable Pattern-based Unknown Morpheme Segmentation and Estimation for Hybrid PartOf-Speech Tagging of Korean. Computational Linguistics, 28(1):53–70.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manabu Sassano</author>
<author>Takehito Utsuro</author>
</authors>
<title>Named Entity Chunking Techniques in Supervised Learning for Japanese Named Entity Recognition.</title>
<date>2000</date>
<booktitle>In Proceedings of the 18th International Conference on Computational Linguistics (COLING</booktitle>
<pages>705--711</pages>
<contexts>
<context position="1407" citStr="Sassano and Utsuro, 2000" startWordPosition="214" endWordPosition="217">suggested method can acquire enough NE tagged corpus equally useful to the manually tagged one without any human intervention. 1 Introduction Current trend in Named Entity Recognition (NER) is to apply machine learning approach, which is more attractive because it is trainable and adaptable, and subsequently the porting of a machine learning system to another domain is much easier than that of a rule-based one. Various supervised learning methods for Named Entity (NE) tasks were successfully applied and have shown reasonably satisfiable performance.((Zhou and Su, 2002)(Borthwick et al., 1998)(Sassano and Utsuro, 2000)) However, most of these systems heavily rely on a tagged corpus for training. For a machine learning approach, a large corpus is required to circumvent the data sparseness problem, but the dilemma is that the costs required to annotate a large training corpus are non-trivial. In this paper, we suggest a method that automatically constructs an NE tagged corpus from the web to be used for learning of NER systems. We use an NE list and an web search engine to collect web documents which contain the NE instances. The documents are refined through the sentence separation and text refinement proced</context>
</contexts>
<marker>Sassano, Utsuro, 2000</marker>
<rawString>Manabu Sassano and Takehito Utsuro. 2000. Named Entity Chunking Techniques in Supervised Learning for Japanese Named Entity Recognition. In Proceedings of the 18th International Conference on Computational Linguistics (COLING 2000), pages 705–711, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Choong-Nyoung Seon</author>
<author>Youngjoong Ko</author>
<author>Jeong-Seok Kim</author>
<author>Jungyun Seo</author>
</authors>
<title>Named Entity Recognition using Machine Learning Methods and PatternSelection Rules.</title>
<date>2001</date>
<booktitle>In Proceedings of the Sixth Natural Language Processing Pacific Rim Symposium,</booktitle>
<pages>229--236</pages>
<location>Tokyo, Japan.</location>
<contexts>
<context position="11028" citStr="Seon et al. (2001)" startWordPosition="1813" endWordPosition="1816">ged Corpus As another experiment, we tried to investigate how large automatic corpus we should generate to get the satisfiable performance. We measured the performance according to the size of the automatic corpus. We carried out the experiment with the decision list learning method and the result is shown in Table 3. Here, 5% actually corresponds to the size of the manual corpus. When we trained with that size of the automatic corpus, the performance was very low compared to the performance of the manual corpus. The reason is that the automatic corpus is com2We used the manual corpus used in Seon et al. (2001) as training and test data. Corpus size (words) Precision Recall F-measure 90,000 (5%) 72.43 6.94 39.69 448,000 (25%) 73.17 41.66 57.42 902,000 (50%) 75.32 61.53 68.43 1,370,000 (75%) 78.23 77.19 77.71 1,800,000 (100%) 81.45 85.41 83.43 Table 3: Performance according to the corpus size Corpus size (words) Precision Recall F-measure 700,000 79.41 81.82 80.62 1,000,000 82.86 85.29 84.08 1,200,000 83.81 86.27 85.04 1,300,000 83.81 86.27 85.04 Table 4: Saturation point of the performance for ‘person’ category posed of the sentences searched with fewer named entities and therefore has less lexical </context>
</contexts>
<marker>Seon, Ko, Kim, Seo, 2001</marker>
<rawString>Choong-Nyoung Seon, Youngjoong Ko, Jeong-Seok Kim, and Jungyun Seo. 2001. Named Entity Recognition using Machine Learning Methods and PatternSelection Rules. In Proceedings of the Sixth Natural Language Processing Pacific Rim Symposium, pages 229–236, Tokyo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Junhyeok Shim</author>
<author>Dongseok Kim</author>
<author>Jeongwon Cha</author>
<author>Gary Geunbae Lee</author>
<author>Jungyun Seo</author>
</authors>
<title>Multistrategic Integrated Web Document Pre-processing for Sentence and Word Boundary Detection. Information Processing and</title>
<date>2002</date>
<journal>Management,</journal>
<volume>38</volume>
<issue>4</issue>
<contexts>
<context position="5762" citStr="Shim et al., 2002" startWordPosition="947" endWordPosition="950">ps according to the distance from a target NE instance. The one includes internal features of NE itself and context features within a small word window or sentence boundary and the other includes name alias and co-reference information beyond a sentence boundary. In fact, it is not easy to extract name alias and co-reference information directly from manually tagged NE corpus and needs additional knowledge or resources. This leads us to focus on automatic annotation in sentence level, not document level. Therefore, in this step, we split the texts of the collected documents into sentences by (Shim et al., 2002) and remove sentences without target NE instances. 2.3 Refining the Web Texts The collected web documents may include texts actually matched by mistake, because most web search engines for Korean use n-gram, especially, bi-gram matching. This leads us to refine the sentences to exclude these erroneous matches. Sentence refinement is accomplished by three different processes: separation of functional words, segmentation of compound nouns, and verification of the usefulness of the extracted sentences. An NE is often concatenated with more than one josa, a Korean functional word, to compose a Kor</context>
</contexts>
<marker>Shim, Kim, Cha, Lee, Seo, 2002</marker>
<rawString>Junhyeok Shim, Dongseok Kim, Jeongwon Cha, Gary Geunbae Lee, and Jungyun Seo. 2002. Multistrategic Integrated Web Document Pre-processing for Sentence and Word Boundary Detection. Information Processing and Management, 38(4):509–527.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo-Hyun Yun</author>
<author>Min-Jeung Cho</author>
<author>Hae-Chang Rim</author>
</authors>
<title>Segmenting Korean Compound Nouns using Statistical Information and a Preference Rule.</title>
<date>1997</date>
<journal>Journal ofKorean Information Science Society,</journal>
<volume>24</volume>
<issue>8</issue>
<pages>909</pages>
<contexts>
<context position="8067" citStr="Yun et al., 1997" startWordPosition="1313" endWordPosition="1316">ontaining the latter case. A josa-separated Korean word can be a compound noun which only contains a target NE as a substring. This requires us to segment the compound noun into several correct single nouns to match with the target NE. If the segmented single nouns are not matched with a target NE, the sentence can be filtered out. For example, we try to search for an NE entry, ‘¶Á(Fin.KL, a Korean singer group)’ and may actually retrieve sentences including ‘M¶Á ě(surfing club)’. The compound noun, ‘M¶Áě’, can be divided into ‘M¶(surfing)’ and ‘Áě(club)’ by a compound-noun segmenting method (Yun et al., 1997). Since both ‘M¶’ and ‘Áě’ are not matched with our target NE, ‘¶Á’, we can delete the sentences. Although a sentence has a correct target NE, if it does not have context information, it is not useful as an NE tagged corpus. We also removed such sentences. 2.4 Generating an NE tagged corpus The sentences selected by the refining process explained in previous section are finally annotated with the NE label. We acquired the NE tagged corpus including 68,793 NE instances through this automatic annotation process. We can annotate only one NE instance per sentence but almost infinitely increase the</context>
</contexts>
<marker>Yun, Cho, Rim, 1997</marker>
<rawString>Bo-Hyun Yun, Min-Jeung Cho, and Hae-Chang Rim. 1997. Segmenting Korean Compound Nouns using Statistical Information and a Preference Rule. Journal ofKorean Information Science Society, 24(8):900– 909.</rawString>
</citation>
<citation valid="true">
<authors>
<author>GuoDong Zhou</author>
<author>Jian Su</author>
</authors>
<title>Named Entity Recognition using an HMM-based Chunk Tagger.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>473--480</pages>
<location>Philadelphia, USA.</location>
<contexts>
<context position="1357" citStr="Zhou and Su, 2002" startWordPosition="207" endWordPosition="211">ies. Our experiments demonstrates that the suggested method can acquire enough NE tagged corpus equally useful to the manually tagged one without any human intervention. 1 Introduction Current trend in Named Entity Recognition (NER) is to apply machine learning approach, which is more attractive because it is trainable and adaptable, and subsequently the porting of a machine learning system to another domain is much easier than that of a rule-based one. Various supervised learning methods for Named Entity (NE) tasks were successfully applied and have shown reasonably satisfiable performance.((Zhou and Su, 2002)(Borthwick et al., 1998)(Sassano and Utsuro, 2000)) However, most of these systems heavily rely on a tagged corpus for training. For a machine learning approach, a large corpus is required to circumvent the data sparseness problem, but the dilemma is that the costs required to annotate a large training corpus are non-trivial. In this paper, we suggest a method that automatically constructs an NE tagged corpus from the web to be used for learning of NER systems. We use an NE list and an web search engine to collect web documents which contain the NE instances. The documents are refined through </context>
</contexts>
<marker>Zhou, Su, 2002</marker>
<rawString>GuoDong Zhou and Jian Su. 2002. Named Entity Recognition using an HMM-based Chunk Tagger. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL), pages 473–480, Philadelphia, USA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>