<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.032392">
<title confidence="0.985239">
Automatic Acronym Recognition
</title>
<author confidence="0.788095">
Dana Dann´ells
</author>
<affiliation confidence="0.738676">
Computational Linguistics, Department of Linguistics and
Department of Swedish Language
G¨oteborg University
</affiliation>
<address confidence="0.365299">
G¨oteborg, Sweden
</address>
<email confidence="0.987603">
cl2ddoyt@cling.gu.se
</email>
<sectionHeader confidence="0.998516" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999954185185185">
This paper deals with the problem
of recognizing and extracting acronym-
definition pairs in Swedish medical texts.
This project applies a rule-based method
to solve the acronym recognition task and
compares and evaluates the results of dif-
ferent machine learning algorithms on the
same task. The method proposed is based
on the approach that acronym-definition
pairs follow a set of patterns and other
regularities that can be usefully applied
for the acronym identification task. Su-
pervised machine learning was applied to
monitor the performance of the rule-based
method, using Memory Based Learning
(MBL). The rule-based algorithm was
evaluated on a hand tagged acronym cor-
pus and performance was measured using
standard measures recall, precision and f-
score. The results show that performance
could further improve by increasing the
training set and modifying the input set-
tings for the machine learning algorithms.
An analysis of the errors produced indi-
cates that further improvement of the rule-
based method requires the use of syntactic
information and textual pre-processing.
</bodyText>
<sectionHeader confidence="0.99963" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999932846153846">
There are many on-line documents which contain
important information that we want to understand,
thus the need to extract glossaries of domain-
specific names and terms increases, especially in
technical fields such as biomedicine where the vo-
cabulary is quickly expanding. One known phe-
nomenon in biomedical literature is the growth of
new acronyms.
Acronyms are a subset of abbreviations and
are generally formed with capital letters from the
original word or phrase, however many acronyms
are realized in different surface forms i.e. use
of Arabic-numbers, mixed alpha-numeric forms,
low-case acronyms etc.
Several approaches have been proposed for au-
tomatic acronym extraction, with the most com-
mon tools including pattern-matching techniques
and machine learning algorithms. Considering the
large variety in the Swedish acronym-definition
pairs it is practical to use pattern-matching tech-
niques. These will enable to extract relevant in-
formation of which a suitable set of schema will
give a representation valid to present the different
acronym pairs.
This project presents a rule-based algorithm to
process and automatically detect different forms of
acronym-definition pairs. Since machine learning
techniques are generally more robust, can easily
be retrained for a new data and successfully clas-
sify unknown examples, different algorithms were
tested. The acronym pair candidates recognized
by the rule-based algorithm were presented as fea-
ture vectors and were used as the training data for
the supervised machine learning system.
This approach has the advantage of using ma-
chine learning techniques without the need for
manual tagging of the training data. Several ma-
chine learning algorithms were tested and their re-
sults were compared on the task.
</bodyText>
<sectionHeader confidence="0.999902" genericHeader="introduction">
2 Related work
</sectionHeader>
<bodyText confidence="0.9976604">
The task of automatically extracting acronym-
definition pairs from biomedical literature has
been studied, almost exclusively for English, over
the past few decades using technologies from Nat-
ural Language Processing (NLP). This section
</bodyText>
<page confidence="0.99635">
167
</page>
<bodyText confidence="0.99994215">
presents a few approaches and techniques that
were applied to the acronym identification task.
Taghva and Gilbreth (1999) present the
Acronyms Finding Program (AFP), based on
pattern matching. Their program seeks for
acronym candidates which appear as upper case
words. They calculate a heuristic score for each
competing definition by classifying words into:
(1) stop words (”the”, ”of”, ”and”), (2) hyphen-
ated words (3) normal words (words that don’t
fall into any of the above categories) and (4) the
acronyms themselves (since an acronym can
sometimes be a part of the definition). The AFP
utilizes the Longest Common Subsequence (LCS)
algorithm (Hunt and Szymanski, 1977) to find all
possible alignments of the acronym to the text,
followed by simple scoring rules which are based
on matches. The performance reported from their
experiment are: recall of 86% at precision of 98%.
An alternative approach to the AFP was pre-
sented by Yeates (1999). In his program, Three
Letters Acronyms (TLA), he uses more complex
methods and general heuristics to match charac-
ters of the acronym candidate with letters in the
definition string, Yeates reported f-score of 77.8%.
Another approach recognizes that the align-
ment between an acronym and its definition of-
ten follows a set of patterns (Park and Byrd,
2001), (Larkey et al., 2000). Pattern-based meth-
ods use strong constraints to limit the number of
acronyms respectively definitions recognized and
ensure reasonable precision.
Nadeau and Turney (2005) present a machine
learning approach that uses weak constraints to re-
duce the search space of the acronym candidates
and the definition candidates, they reached recall
of 89% at precision of 88%.
Schwartz and Hearst (2003) present a simple al-
gorithm for extracting abbreviations from biomed-
ical text. The algorithm extracts acronym candi-
dates, assuming that either the acronym or the def-
inition occurs between parentheses and by giving
some restrictions for the definition candidate such
as length and capital letter initialization. When an
acronym candidate is found the algorithm scans
the words in the right and left side of the found
acronym and tries to match the shortest definition
that matches the letters in the acronym. Their ap-
proach is based on previous work (Pustejovsky et
al., 2001), they achieved recall of 82% at precision
of 96%.
It should be emphasized that the common char-
acteristic of previous approaches in the surveyed
literature is the use of parentheses as indication for
the acronym pairs, see Nadeau and Turney (2005)
table 1. This limitation has many drawbacks
since it excludes the acronym-definition candi-
dates which don’t occur within parentheses and
thereby don’t provide a complete coverage for all
the acronyms formation.
</bodyText>
<sectionHeader confidence="0.976121" genericHeader="method">
3 Methods and implementation
</sectionHeader>
<bodyText confidence="0.9985314">
The method presented in this section is based on
a similar algorithm described by Schwartz and
Hearst (2003). However it has the advantage of
recognizing acronym-definition pairs which are
not indicated by parentheses.
</bodyText>
<subsectionHeader confidence="0.9993">
3.1 Finding Acronym-Definition Candidates
</subsectionHeader>
<bodyText confidence="0.99977619047619">
A valid acronym candidate is a string of alpha-
betic, numeric and special characters such as ’-’
and ’/’. It is found if the string satisfies the condi-
tions (i) and (ii) and either (iii) or (iv):
(i) The string contains at least two charac-
ters. (ii) The string is not in the list of rejected
words1. (iii) The string contains at least one capi-
tal letter. (iv) The strings’ first or last character is
lower case letter or numeric.
When an acronym is found, the algorithm
searches the words surrounding the acronym for a
definition candidate string that satisfies the follow-
ing conditions (all are necessary in conjunction):
(i) At least one letter of the words in the string
matches the letter in the acronym. (ii) The string
doesn’t contain a colon, semi-colon, question
mark or exclamation mark. (iii) The maximum
length of the string is min(|A|+5,|A|*2), where
|A |is the acronym length (Park and Byrd, 2001).
(iv) The string doesn’t contain only upper case let-
ters.
</bodyText>
<subsectionHeader confidence="0.998992">
3.2 Matching Acronyms with Definitions
</subsectionHeader>
<bodyText confidence="0.999634">
The process of extracting acronym-definition pairs
from a raw text, according to the constraints de-
scribed in Section 3.1 is divided into two steps:
</bodyText>
<listItem confidence="0.459946">
1. Parentheses matching. In practice, most of
the acronym-definition pairs come inside paren-
theses (Schwartz and Hearst, 2003) and can cor-
</listItem>
<bodyText confidence="0.9830695">
respond to two different patterns: (i) defini-
tion (acronym) (ii) acronym (definition). The
</bodyText>
<footnote confidence="0.953219666666667">
1The rejected word list contains frequent acronyms which
appear in the corpus without their definition, e.g. ’USA’,
’UK’, ’EU’.
</footnote>
<page confidence="0.992835">
168
</page>
<bodyText confidence="0.99900356">
algorithm extracts acronym-definition candidates
which correspond to one of these two patterns.
2. Non parentheses matching. The algorithm
seeks for acronym candidates that follow the con-
straints, described in Section 3.1 and are not en-
closed in parentheses. Once an acronym candidate
is found it scans the previous and following con-
text, where the acronym was found, for a definition
candidate. The search space for the definition can-
didate string is limited to four words multiplied by
the number of letters in the acronym candidate.
The next step is to choose the correct substring
of the definition candidate for the acronym can-
didate. This is done by reducing the definition
candidate string as follows: the algorithm searches
for identical characters between the acronym and
the definition starting from the end of both strings
and succeeds in finding a correct substring for
the acronym candidate if it satisfies the follow-
ing conditions: (i) at least one character in the
acronym string matches with a character in the
substring of the definition; (ii) the first character
in the acronym string matches the first character
of the leftmost word in the definition substring, ig-
noring upper/lower case letters.
</bodyText>
<subsectionHeader confidence="0.996894">
3.3 Machine Learning Approach
</subsectionHeader>
<bodyText confidence="0.999265826086957">
To test and compare different supervised learn-
ing algorithms, Tilburg Memory-Based Learner
(TiMBL)2 was used. In memory-based learning
the training set is stored as examples for later eval-
uation. Features vectors were calculated to de-
scribe the acronym-definition pairs. The ten fol-
lowing (numeric) features were chosen: (1) the
acronym or the definition is between parenthe-
ses (0-false, 1-true), (2) the definition appears be-
fore the acronym (0-false, 1-true), (3) the dis-
tance in words between the acronym and the
definition, (4) the number of characters in the
acronym, (5) the number of characters in the def-
inition, (6) the number of lower case letters in the
acronym, (7) the number of lower case letters in
the definition, (8) the number of upper case let-
ters in the acronym, (9) the number of upper case
letters in the definition and (10) the number of
words in the definition. The 11th feature is the
class to predict: true candidate (+), false candi-
date (-). An example of the acronym-definition
pair (”vCJD”, ”variant CJD”) represented as
a feature vector is: 0,1,1,4,11,1,7,3,3,2,+.
</bodyText>
<footnote confidence="0.653155">
2http://ilk.uvt.nl
</footnote>
<sectionHeader confidence="0.92751" genericHeader="evaluation">
4 Evaluation and Results
</sectionHeader>
<subsectionHeader confidence="0.958597">
4.1 Evaluation Corpus
</subsectionHeader>
<bodyText confidence="0.9980005">
The data set used in this experiment consists of
861 acronym-definition pairs. The set was ex-
tracted from Swedish medical texts, the MEDLEX
corpus (Kokkinakis, 2006) and was manually an-
notated using XML tags. For the majority of the
cases there exist one acronym-definition pair per
sentence, but there are cases where two or more
pairs can be found.
</bodyText>
<subsectionHeader confidence="0.996458">
4.2 Experiment and Results
</subsectionHeader>
<bodyText confidence="0.999971481481482">
The rule-based algorithm was evaluated on the un-
tagged MEDLEX corpus samples. Recall, pre-
cision and F-score were used to calculate the
acronym-expansion matching. The algorithm rec-
ognized 671 acronym-definition pairs of which 47
were incorrectly identified. The results obtained
were 93% precision and 72.5% recall, yielding F-
score of 81.5%.
A closer look at the 47 incorrect acronym pairs
that were found showed that the algorithm failed
to make a correct match when: (1) words that
appear in the definition string don’t have a corre-
sponding letter in the acronym string, (2) letters
in the acronym string don’t have a corresponding
word in the definition string, such as ”PGA” from
”glycol alginate l¨osning”, (3) letters in the defini-
tion string don’t match the letters in the acronym
string.
The error analysis showed that the reasons for
missing 190 acronym-definition pairs are: (1) let-
ters in the definition string don’t appear in the
acronym string, due to a mixture of a Swedish
definition with an acronym written in English,
(2) mixture of Arabic and Roman numerals, such
as ”USH3” from ”Usher typ III”, (3) position of
numbers/letters, (4) acronyms of three characters
which appear in lower case letters.
</bodyText>
<subsectionHeader confidence="0.995209">
4.3 Machine Learning Experiment
</subsectionHeader>
<bodyText confidence="0.999979">
The acronym-definition pairs recognized by the
rule-based algorithm were used as the training ma-
terial in this experiment. The 671 pairs were pre-
sented as feature vectors according to the features
described in Section 3.3. The material was di-
vided into two data files: (1) 80% training data;
(2) 20% test data. Four different algorithms were
used to create models. These algorithms are: IB1,
IGTREE, TRIBL and TRIBL2. The results ob-
tained are given in Table 1.
</bodyText>
<page confidence="0.995313">
169
</page>
<table confidence="0.9998576">
Algorithm Precision Recall F-score
IB1 90.6 % 97.1 % 93.7 %
IGTREE 95.4 % 97.2 % 96.3 %
TRIBL 92.0 % 96.3 % 94.1 %
TRIBL2 92.8 % 96.3 % 94.5 %
</table>
<tableCaption confidence="0.999668">
Table 1: Memory-Based algorithm results.
</tableCaption>
<sectionHeader confidence="0.994873" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999958105263158">
The approach presented in this paper relies on
already existing acronym pairs which are seen
in different Swedish texts. The rule-based algo-
rithm utilizes predefined strong constraints to find
and extract acronym-definition pairs with differ-
ent patterns, it has the advantage of recognizing
acronyms and definitions which are not indicated
by parentheses. The recognized pairs were used
to test and compare several machine learning al-
gorithms. This approach does not requires manual
tagging of the training data.
The results given by the rule-based algorithm
are as good as reported from earlier experiments
that have dealt with the same task for the English
language. The algorithm uses backward search al-
gorithm and to increase recall it is necessary to
combine it with forward search algorithm.
The variety of the Swedish acronym pairs is
large and includes structures which are hard to de-
tect, for example: (”V F”, ”kammarflimmer”)
and (”CT”, ”datortomografi”), the acronym
is in English while the extension is written in
Swedish. These structures require a dictio-
nary/database lookup3, especially because there
are also counter examples in the Swedish text
where both the acronym and the definition are in
English. Another problematic structure is three
letter acronyms which consist of only lowercase
letters since there are many prepositions, verbs and
determinates that correspond to this structure. To
solve this problem it may be suitable to combine
textual pre-processing such as part-of-speech an-
notation or/and parsing with the exiting code.
The machine learning experiment shows that
the best results were given by the IGTREE algo-
rithm4. Performance can further improve by mod-
ifying the input settings e.g test different feature
weighting schemes, such as Shared Variance and
</bodyText>
<footnote confidence="0.9518325">
3Due to short time available and the lack of resources this
feature was not used in the experiment.
4The IGTREE algorithm uses information gain in a com-
pressed decision tree structure.
</footnote>
<bodyText confidence="0.998371833333333">
Gain Ratio and combine different values of k for
the k-nearest neighbour classifier5.
On-going work aim to improve the rule-based
method and combine it with a supervised machine
learning algorithm. The model produced will later
be used for making prediction on a new data.
</bodyText>
<sectionHeader confidence="0.996409" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.989827571428571">
Project funded in part by the SematicMining EU
FP6 NoE 507505. This research has been car-
ried out thanks to Lars Borin and Dimitrios Kokki-
nakis. I thank Torbj¨orn Lager for his guidance
and encouragement. I would like to thank Walter
Daelemans, Ko van der Sloot Antal van den Bosch
and Robert Andersson for their help and support.
</bodyText>
<sectionHeader confidence="0.998672" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999154939393939">
Ariel S. Schwartz and Marti A. Hearst. 2003. A simple
algorithm for identifying abbreviation definitions in
biomedical texts. Proc. of the Pacific Symposium on
Biocomputing. University of California, Berkeley.
David Nadeau and Peter Turney. 2005. A Supervised
Learning Approach to Acronym Identification. In-
formation Technology National Research Council,
Ottawa, Ontario, Canada.
Dimitrios Kokkinakis. 2006. Collection, Encoding
and Linguistic Processing of a Swedish Medical
Corpus: The MEDLEX Experience. Proc. of the 5th
LREC. Genoa, Italy.
James W. Hunt and Thomas G. Szymanski. 1977. A
fast algorithm for computing longest common sub-
sequences. Commun. of the ACM, 20(5):350-353.
James Pustejovsky, Jos´e Casta¨no, Brent Cochran, Ma-
ciej Kotecki and Michael Morrella. 2001. Au-
tomation Extraction ofAcronym-MeaningPairs from
Medline Databases. In Proceedings of Medinfo.
Kazen Taghva and Jeff Gilbreth. 1999. Technical Re-
port. Recognizing Acronyms and their Definitions.
University of Nevada, Las Vegas.
Leah S. Larkey, Paul Ogilvie, Andrew M. Price and
Brenden Tamilio. 2000. Acrophile: An Automated
Acronym Extractor and Server. University of Mas-
sachusetts, Dallas TX.
Stuart Yeates. 1999. Automatic extraction of acronyms
from text. Proc. of the Third New Zealand Computer
Science Research Students’ Conference. University
of Waikato, New Zealand.
Youngja Park and Roy J. Byrd. 2001. Hybrid Text Min-
ing for Finding Abbreviations and Their Definitions.
IMB Thomas J. Watson Research Center, NY, USA.
</reference>
<footnote confidence="0.858415">
5In the machine learning experiment default value is used,
k=1.
</footnote>
<page confidence="0.990009">
170
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.732341">
<title confidence="0.999747">Automatic Acronym Recognition</title>
<author confidence="0.999459">Dana Dann´ells</author>
<affiliation confidence="0.966095333333333">Computational Linguistics, Department of Linguistics and Department of Swedish Language G¨oteborg University</affiliation>
<address confidence="0.914227">G¨oteborg, Sweden</address>
<email confidence="0.910571">cl2ddoyt@cling.gu.se</email>
<abstract confidence="0.999183142857143">This paper deals with the problem of recognizing and extracting acronymdefinition pairs in Swedish medical texts. This project applies a rule-based method to solve the acronym recognition task and compares and evaluates the results of different machine learning algorithms on the same task. The method proposed is based on the approach that acronym-definition pairs follow a set of patterns and other regularities that can be usefully applied for the acronym identification task. Supervised machine learning was applied to monitor the performance of the rule-based method, using Memory Based Learning (MBL). The rule-based algorithm was evaluated on a hand tagged acronym corpus and performance was measured using standard measures recall, precision and fscore. The results show that performance could further improve by increasing the training set and modifying the input settings for the machine learning algorithms. An analysis of the errors produced indicates that further improvement of the rulebased method requires the use of syntactic information and textual pre-processing.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Ariel S Schwartz</author>
<author>Marti A Hearst</author>
</authors>
<title>A simple algorithm for identifying abbreviation definitions in biomedical texts.</title>
<date>2003</date>
<booktitle>Proc. of the Pacific Symposium on</booktitle>
<institution>Biocomputing. University of California, Berkeley.</institution>
<contexts>
<context position="5039" citStr="Schwartz and Hearst (2003)" startWordPosition="760" endWordPosition="763">th letters in the definition string, Yeates reported f-score of 77.8%. Another approach recognizes that the alignment between an acronym and its definition often follows a set of patterns (Park and Byrd, 2001), (Larkey et al., 2000). Pattern-based methods use strong constraints to limit the number of acronyms respectively definitions recognized and ensure reasonable precision. Nadeau and Turney (2005) present a machine learning approach that uses weak constraints to reduce the search space of the acronym candidates and the definition candidates, they reached recall of 89% at precision of 88%. Schwartz and Hearst (2003) present a simple algorithm for extracting abbreviations from biomedical text. The algorithm extracts acronym candidates, assuming that either the acronym or the definition occurs between parentheses and by giving some restrictions for the definition candidate such as length and capital letter initialization. When an acronym candidate is found the algorithm scans the words in the right and left side of the found acronym and tries to match the shortest definition that matches the letters in the acronym. Their approach is based on previous work (Pustejovsky et al., 2001), they achieved recall of</context>
<context position="7645" citStr="Schwartz and Hearst, 2003" startWordPosition="1181" endWordPosition="1184">ds in the string matches the letter in the acronym. (ii) The string doesn’t contain a colon, semi-colon, question mark or exclamation mark. (iii) The maximum length of the string is min(|A|+5,|A|*2), where |A |is the acronym length (Park and Byrd, 2001). (iv) The string doesn’t contain only upper case letters. 3.2 Matching Acronyms with Definitions The process of extracting acronym-definition pairs from a raw text, according to the constraints described in Section 3.1 is divided into two steps: 1. Parentheses matching. In practice, most of the acronym-definition pairs come inside parentheses (Schwartz and Hearst, 2003) and can correspond to two different patterns: (i) definition (acronym) (ii) acronym (definition). The 1The rejected word list contains frequent acronyms which appear in the corpus without their definition, e.g. ’USA’, ’UK’, ’EU’. 168 algorithm extracts acronym-definition candidates which correspond to one of these two patterns. 2. Non parentheses matching. The algorithm seeks for acronym candidates that follow the constraints, described in Section 3.1 and are not enclosed in parentheses. Once an acronym candidate is found it scans the previous and following context, where the acronym was foun</context>
</contexts>
<marker>Schwartz, Hearst, 2003</marker>
<rawString>Ariel S. Schwartz and Marti A. Hearst. 2003. A simple algorithm for identifying abbreviation definitions in biomedical texts. Proc. of the Pacific Symposium on Biocomputing. University of California, Berkeley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Nadeau</author>
<author>Peter Turney</author>
</authors>
<title>A Supervised Learning Approach to Acronym Identification.</title>
<date>2005</date>
<booktitle>Information Technology National Research Council,</booktitle>
<location>Ottawa, Ontario, Canada.</location>
<contexts>
<context position="4817" citStr="Nadeau and Turney (2005)" startWordPosition="724" endWordPosition="727">of 98%. An alternative approach to the AFP was presented by Yeates (1999). In his program, Three Letters Acronyms (TLA), he uses more complex methods and general heuristics to match characters of the acronym candidate with letters in the definition string, Yeates reported f-score of 77.8%. Another approach recognizes that the alignment between an acronym and its definition often follows a set of patterns (Park and Byrd, 2001), (Larkey et al., 2000). Pattern-based methods use strong constraints to limit the number of acronyms respectively definitions recognized and ensure reasonable precision. Nadeau and Turney (2005) present a machine learning approach that uses weak constraints to reduce the search space of the acronym candidates and the definition candidates, they reached recall of 89% at precision of 88%. Schwartz and Hearst (2003) present a simple algorithm for extracting abbreviations from biomedical text. The algorithm extracts acronym candidates, assuming that either the acronym or the definition occurs between parentheses and by giving some restrictions for the definition candidate such as length and capital letter initialization. When an acronym candidate is found the algorithm scans the words in</context>
</contexts>
<marker>Nadeau, Turney, 2005</marker>
<rawString>David Nadeau and Peter Turney. 2005. A Supervised Learning Approach to Acronym Identification. Information Technology National Research Council, Ottawa, Ontario, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dimitrios Kokkinakis</author>
</authors>
<title>Collection, Encoding and Linguistic Processing of a Swedish Medical Corpus: The MEDLEX Experience.</title>
<date>2006</date>
<booktitle>Proc. of the 5th LREC.</booktitle>
<location>Genoa, Italy.</location>
<contexts>
<context position="10452" citStr="Kokkinakis, 2006" startWordPosition="1631" endWordPosition="1632">s in the definition, (8) the number of upper case letters in the acronym, (9) the number of upper case letters in the definition and (10) the number of words in the definition. The 11th feature is the class to predict: true candidate (+), false candidate (-). An example of the acronym-definition pair (”vCJD”, ”variant CJD”) represented as a feature vector is: 0,1,1,4,11,1,7,3,3,2,+. 2http://ilk.uvt.nl 4 Evaluation and Results 4.1 Evaluation Corpus The data set used in this experiment consists of 861 acronym-definition pairs. The set was extracted from Swedish medical texts, the MEDLEX corpus (Kokkinakis, 2006) and was manually annotated using XML tags. For the majority of the cases there exist one acronym-definition pair per sentence, but there are cases where two or more pairs can be found. 4.2 Experiment and Results The rule-based algorithm was evaluated on the untagged MEDLEX corpus samples. Recall, precision and F-score were used to calculate the acronym-expansion matching. The algorithm recognized 671 acronym-definition pairs of which 47 were incorrectly identified. The results obtained were 93% precision and 72.5% recall, yielding Fscore of 81.5%. A closer look at the 47 incorrect acronym pai</context>
</contexts>
<marker>Kokkinakis, 2006</marker>
<rawString>Dimitrios Kokkinakis. 2006. Collection, Encoding and Linguistic Processing of a Swedish Medical Corpus: The MEDLEX Experience. Proc. of the 5th LREC. Genoa, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James W Hunt</author>
<author>Thomas G Szymanski</author>
</authors>
<title>A fast algorithm for computing longest common subsequences.</title>
<date>1977</date>
<journal>Commun. of the ACM,</journal>
<pages>20--5</pages>
<contexts>
<context position="3992" citStr="Hunt and Szymanski, 1977" startWordPosition="592" endWordPosition="595">applied to the acronym identification task. Taghva and Gilbreth (1999) present the Acronyms Finding Program (AFP), based on pattern matching. Their program seeks for acronym candidates which appear as upper case words. They calculate a heuristic score for each competing definition by classifying words into: (1) stop words (”the”, ”of”, ”and”), (2) hyphenated words (3) normal words (words that don’t fall into any of the above categories) and (4) the acronyms themselves (since an acronym can sometimes be a part of the definition). The AFP utilizes the Longest Common Subsequence (LCS) algorithm (Hunt and Szymanski, 1977) to find all possible alignments of the acronym to the text, followed by simple scoring rules which are based on matches. The performance reported from their experiment are: recall of 86% at precision of 98%. An alternative approach to the AFP was presented by Yeates (1999). In his program, Three Letters Acronyms (TLA), he uses more complex methods and general heuristics to match characters of the acronym candidate with letters in the definition string, Yeates reported f-score of 77.8%. Another approach recognizes that the alignment between an acronym and its definition often follows a set of </context>
</contexts>
<marker>Hunt, Szymanski, 1977</marker>
<rawString>James W. Hunt and Thomas G. Szymanski. 1977. A fast algorithm for computing longest common subsequences. Commun. of the ACM, 20(5):350-353.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Pustejovsky</author>
<author>Jos´e Casta¨no</author>
<author>Brent Cochran</author>
<author>Maciej Kotecki</author>
<author>Michael Morrella</author>
</authors>
<title>Automation Extraction ofAcronym-MeaningPairs from Medline Databases.</title>
<date>2001</date>
<booktitle>In Proceedings of Medinfo.</booktitle>
<marker>Pustejovsky, Casta¨no, Cochran, Kotecki, Morrella, 2001</marker>
<rawString>James Pustejovsky, Jos´e Casta¨no, Brent Cochran, Maciej Kotecki and Michael Morrella. 2001. Automation Extraction ofAcronym-MeaningPairs from Medline Databases. In Proceedings of Medinfo.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kazen Taghva</author>
<author>Jeff Gilbreth</author>
</authors>
<title>Technical Report. Recognizing Acronyms and their Definitions.</title>
<date>1999</date>
<institution>University of Nevada, Las Vegas.</institution>
<contexts>
<context position="3437" citStr="Taghva and Gilbreth (1999)" startWordPosition="505" endWordPosition="508">ised machine learning system. This approach has the advantage of using machine learning techniques without the need for manual tagging of the training data. Several machine learning algorithms were tested and their results were compared on the task. 2 Related work The task of automatically extracting acronymdefinition pairs from biomedical literature has been studied, almost exclusively for English, over the past few decades using technologies from Natural Language Processing (NLP). This section 167 presents a few approaches and techniques that were applied to the acronym identification task. Taghva and Gilbreth (1999) present the Acronyms Finding Program (AFP), based on pattern matching. Their program seeks for acronym candidates which appear as upper case words. They calculate a heuristic score for each competing definition by classifying words into: (1) stop words (”the”, ”of”, ”and”), (2) hyphenated words (3) normal words (words that don’t fall into any of the above categories) and (4) the acronyms themselves (since an acronym can sometimes be a part of the definition). The AFP utilizes the Longest Common Subsequence (LCS) algorithm (Hunt and Szymanski, 1977) to find all possible alignments of the acron</context>
</contexts>
<marker>Taghva, Gilbreth, 1999</marker>
<rawString>Kazen Taghva and Jeff Gilbreth. 1999. Technical Report. Recognizing Acronyms and their Definitions. University of Nevada, Las Vegas.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leah S Larkey</author>
<author>Paul Ogilvie</author>
<author>Andrew M Price</author>
<author>Brenden Tamilio</author>
</authors>
<title>Acrophile: An Automated Acronym Extractor and Server.</title>
<date>2000</date>
<institution>University of Massachusetts, Dallas TX.</institution>
<contexts>
<context position="4645" citStr="Larkey et al., 2000" startWordPosition="701" endWordPosition="704">of the acronym to the text, followed by simple scoring rules which are based on matches. The performance reported from their experiment are: recall of 86% at precision of 98%. An alternative approach to the AFP was presented by Yeates (1999). In his program, Three Letters Acronyms (TLA), he uses more complex methods and general heuristics to match characters of the acronym candidate with letters in the definition string, Yeates reported f-score of 77.8%. Another approach recognizes that the alignment between an acronym and its definition often follows a set of patterns (Park and Byrd, 2001), (Larkey et al., 2000). Pattern-based methods use strong constraints to limit the number of acronyms respectively definitions recognized and ensure reasonable precision. Nadeau and Turney (2005) present a machine learning approach that uses weak constraints to reduce the search space of the acronym candidates and the definition candidates, they reached recall of 89% at precision of 88%. Schwartz and Hearst (2003) present a simple algorithm for extracting abbreviations from biomedical text. The algorithm extracts acronym candidates, assuming that either the acronym or the definition occurs between parentheses and by</context>
</contexts>
<marker>Larkey, Ogilvie, Price, Tamilio, 2000</marker>
<rawString>Leah S. Larkey, Paul Ogilvie, Andrew M. Price and Brenden Tamilio. 2000. Acrophile: An Automated Acronym Extractor and Server. University of Massachusetts, Dallas TX.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart Yeates</author>
</authors>
<title>Automatic extraction of acronyms from text.</title>
<date>1999</date>
<booktitle>Proc. of the Third</booktitle>
<institution>New Zealand Computer Science Research Students’ Conference. University of Waikato,</institution>
<location>New Zealand.</location>
<contexts>
<context position="4266" citStr="Yeates (1999)" startWordPosition="641" endWordPosition="642">lassifying words into: (1) stop words (”the”, ”of”, ”and”), (2) hyphenated words (3) normal words (words that don’t fall into any of the above categories) and (4) the acronyms themselves (since an acronym can sometimes be a part of the definition). The AFP utilizes the Longest Common Subsequence (LCS) algorithm (Hunt and Szymanski, 1977) to find all possible alignments of the acronym to the text, followed by simple scoring rules which are based on matches. The performance reported from their experiment are: recall of 86% at precision of 98%. An alternative approach to the AFP was presented by Yeates (1999). In his program, Three Letters Acronyms (TLA), he uses more complex methods and general heuristics to match characters of the acronym candidate with letters in the definition string, Yeates reported f-score of 77.8%. Another approach recognizes that the alignment between an acronym and its definition often follows a set of patterns (Park and Byrd, 2001), (Larkey et al., 2000). Pattern-based methods use strong constraints to limit the number of acronyms respectively definitions recognized and ensure reasonable precision. Nadeau and Turney (2005) present a machine learning approach that uses we</context>
</contexts>
<marker>Yeates, 1999</marker>
<rawString>Stuart Yeates. 1999. Automatic extraction of acronyms from text. Proc. of the Third New Zealand Computer Science Research Students’ Conference. University of Waikato, New Zealand.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Youngja Park</author>
<author>Roy J Byrd</author>
</authors>
<title>Hybrid Text Mining for Finding Abbreviations and Their Definitions.</title>
<date>2001</date>
<journal>IMB Thomas J. Watson Research</journal>
<location>Center, NY, USA.</location>
<contexts>
<context position="4622" citStr="Park and Byrd, 2001" startWordPosition="697" endWordPosition="700">ll possible alignments of the acronym to the text, followed by simple scoring rules which are based on matches. The performance reported from their experiment are: recall of 86% at precision of 98%. An alternative approach to the AFP was presented by Yeates (1999). In his program, Three Letters Acronyms (TLA), he uses more complex methods and general heuristics to match characters of the acronym candidate with letters in the definition string, Yeates reported f-score of 77.8%. Another approach recognizes that the alignment between an acronym and its definition often follows a set of patterns (Park and Byrd, 2001), (Larkey et al., 2000). Pattern-based methods use strong constraints to limit the number of acronyms respectively definitions recognized and ensure reasonable precision. Nadeau and Turney (2005) present a machine learning approach that uses weak constraints to reduce the search space of the acronym candidates and the definition candidates, they reached recall of 89% at precision of 88%. Schwartz and Hearst (2003) present a simple algorithm for extracting abbreviations from biomedical text. The algorithm extracts acronym candidates, assuming that either the acronym or the definition occurs bet</context>
<context position="7272" citStr="Park and Byrd, 2001" startWordPosition="1124" endWordPosition="1127">d words1. (iii) The string contains at least one capital letter. (iv) The strings’ first or last character is lower case letter or numeric. When an acronym is found, the algorithm searches the words surrounding the acronym for a definition candidate string that satisfies the following conditions (all are necessary in conjunction): (i) At least one letter of the words in the string matches the letter in the acronym. (ii) The string doesn’t contain a colon, semi-colon, question mark or exclamation mark. (iii) The maximum length of the string is min(|A|+5,|A|*2), where |A |is the acronym length (Park and Byrd, 2001). (iv) The string doesn’t contain only upper case letters. 3.2 Matching Acronyms with Definitions The process of extracting acronym-definition pairs from a raw text, according to the constraints described in Section 3.1 is divided into two steps: 1. Parentheses matching. In practice, most of the acronym-definition pairs come inside parentheses (Schwartz and Hearst, 2003) and can correspond to two different patterns: (i) definition (acronym) (ii) acronym (definition). The 1The rejected word list contains frequent acronyms which appear in the corpus without their definition, e.g. ’USA’, ’UK’, ’E</context>
</contexts>
<marker>Park, Byrd, 2001</marker>
<rawString>Youngja Park and Roy J. Byrd. 2001. Hybrid Text Mining for Finding Abbreviations and Their Definitions. IMB Thomas J. Watson Research Center, NY, USA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>