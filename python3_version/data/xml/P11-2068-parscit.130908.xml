<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.007434">
<title confidence="0.9989665">
Improving On-line Handwritten Recognition using Translation Models
in Multimodal Interactive Machine Translation
</title>
<author confidence="0.937733">
Vicent Alabau, Alberto Sanchis, Francisco Casacuberta
</author>
<affiliation confidence="0.651579">
Institut Tecnol`ogic d’Inform`atica
</affiliation>
<address confidence="0.483805">
Universitat Polit`ecnica de Val`encia
Camide Vera, s/n, Valencia, Spain
</address>
<email confidence="0.99558">
{valabau,asanchis,fcn}@iti.upv.es
</email>
<sectionHeader confidence="0.99559" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99989512">
In interactive machine translation (IMT), a hu-
man expert is integrated into the core of a ma-
chine translation (MT) system. The human ex-
pert interacts with the IMT system by partially
correcting the errors of the system’s output.
Then, the system proposes a new solution.
This process is repeated until the output meets
the desired quality. In this scenario, the in-
teraction is typically performed using the key-
board and the mouse. In this work, we present
an alternative modality to interact within IMT
systems by writing on a tactile display or us-
ing an electronic pen. An on-line handwrit-
ten text recognition (HTR) system has been
specifically designed to operate with IMT sys-
tems. Our HTR system improves previous ap-
proaches in two main aspects. First, HTR de-
coding is tightly coupled with the IMT sys-
tem. Second, the language models proposed
are context aware, in the sense that they take
into account the partial corrections and the
source sentence by using a combination of n-
grams and word-based IBM models. The pro-
posed system achieves an important boost in
performance with respect to previous work.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999929769230769">
Although current state-of-the-art machine transla-
tion (MT) systems have improved greatly in the last
ten years, they are not able to provide the high qual-
ity results that are needed for industrial and busi-
ness purposes. For that reason, a new interactive
paradigm has emerged recently. In interactive ma-
chine translation (IMT) (Foster et al., 1998; Bar-
rachina et al., 2009; Koehn and Haddow, 2009) the
system goal is not to produce “perfect” translations
in a completely automatic way, but to help the user
build the translation with the least effort possible.
A typical approach to IMT is shown in Fig. 1. A
source sentence f is given to the IMT system. First,
the system outputs a translation hypothesis es in the
target language, which would correspond to the out-
put of fully automated MT system. Next, the user
analyses the source sentence and the decoded hy-
pothesis, and validates the longest error-free prefix
ep finding the first error. The user, then, corrects the
erroneous word by typing some keystrokes K, and
sends them along with ep to the system, as a new val-
idated prefix ep„ K. With that information, the sys-
tem is able to produce a new, hopefully improved,
suffix es that continues the previous validated pre-
fix. This process is repeated until the user agrees
with the quality of the resulting translation.
</bodyText>
<equation confidence="0.6238415">
f es
system
ep ,K
user
</equation>
<figureCaption confidence="0.99972">
Figure 1: Diagram of a typical approach to IMT
</figureCaption>
<bodyText confidence="0.9998918">
The usual way in which the user introduces the
corrections K is by means of the keyboard. How-
ever, other interaction modalities are also possible.
For example, the use of speech interaction was stud-
ied in (Vidal et al., 2006). In that work, several sce-
</bodyText>
<page confidence="0.988771">
389
</page>
<note confidence="0.5835925">
Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 389–394,
Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics
</note>
<bodyText confidence="0.999825466666667">
narios were proposed, where the user was expected
to speak aloud parts of the current hypothesis and
possibly one or more corrections. On-line HTR for
interactive systems was first explored for interactive
transcription of text images (Toselli et al., 2010).
Later, we proposed an adaptation to IMT in (Alabau
et al., 2010). For both cases, the decoding of the
on-line handwritten text is performed independently
as a previous step of the suffix es decoding. To our
knowledge, (Alabau et al., 2010) has been the first
and sole approach to the use of on-line handwriting
in IMT so far. However, that work did not exploit
the specific particularities of the MT scenario.
The novelties of this paper with respect to previ-
ous work are summarised in the following items:
</bodyText>
<listItem confidence="0.984663">
• in previous formalisations of the problem, the
HTR decoding and the IMT decoding were per-
formed in two steps. Here, a sound statistical
formalisation is presented where both systems
are tightly coupled.
• the use of specific language modelling for on-
line HTR decoding that take into account the
previous validated prefix ep, κ, and the source
sentence f. A decreasing in error of 2% abso-
lute has been achieved with respect to previous
work.
• additionally, a thorough study of the errors
committed by the HTR subsystem is presented.
</listItem>
<bodyText confidence="0.999915571428571">
The remainder of this paper is organised as fol-
lows: The statistical framework for multimodal IMT
and their alternatives will be studied in Sec. 2. Sec-
tion 3 is devoted to the evaluation of the proposed
models. Here, the results will be analysed and com-
pared to previous approaches. Finally, conclusions
and future work will be discussed in Sec. 4.
</bodyText>
<sectionHeader confidence="0.990414" genericHeader="method">
2 Multimodal IMT
</sectionHeader>
<bodyText confidence="0.999974461538461">
In the traditional IMT scenario, the user interacts
with the system through a series of corrections intro-
duced with the keyboard. This iterative nature of the
process is emphasised by the loop in Fig. 1, which
indicates that, for a source sentence to be translated,
several interactions between the user and the system
should be performed. In each interaction, the system
produces the most probable suffix es that completes
the prefix formed by concatenating the longest cor-
rect prefix from the previous hypothesis ep and the
keyboard correction κ. In addition, the concatena-
tion of them, (ep, κ, es), must be a translation of f.
Statistically, this problem can be formulated as
</bodyText>
<equation confidence="0.988748">
es = argmax Pr(es|ep,κ, f) (1)
e3
</equation>
<bodyText confidence="0.99970625">
The multimodal IMT approach differs from Eq. 1
in that the user introduces the correction using a
touch-screen or an electronic pen, t. Then, Eq. 1
can be rewritten as
</bodyText>
<equation confidence="0.9965125">
es = argmax
e3 Pr(es|ep, t, f) (2)
</equation>
<bodyText confidence="0.9941305">
As t is a non-deterministic input (contrarily to κ),
t needs to be decoded in a word d of the vocabu-
lary. Thus, we must marginalise for every possible
decoding:
</bodyText>
<equation confidence="0.980119">
1: �es = argmax Pr(es, d|ep, t, f) (3)
e3 d
</equation>
<bodyText confidence="0.995916">
Furthermore, by applying simple Bayes transfor-
mations and making reasonable assumptions,
</bodyText>
<equation confidence="0.9971475">
Pr(t|d) Pr(d|ep, f)
Pr(es|ep, d, f) (4)
</equation>
<bodyText confidence="0.999907181818182">
The first term in Eq. 4 is a morphological model
and it can be approximated with hidden Markov
models (HMM). The last term is an IMT model
as described in (Barrachina et al., 2009). Finally,
Pr(d|ep, f) is a constrained language model. Note
that the language model is conditioned to the longest
correct prefix, just as a regular language model. Be-
sides, it is also conditioned to the source sentence,
since d should result of the translation of it.
A typical session of the multimodal IMT is ex-
emplified in Fig. 2. First, the system starts with
an empty prefix, so it proposes a full hypothesis.
The output would be the same of a fully automated
system. Then, the user corrects the first error, not,
by writing on a touch-screen. The HTR subsys-
tem mistakenly recognises in. Consequently, the
user falls back to the keyboard and types is. Next,
the system proposes a new suffix, in which the first
word, not, has been automatically corrected. The
user amends at by writing the word , which is cor-
rectly recognised by the HTR subsystem. Finally, as
the new proposed suffix is correct, the process ends.
</bodyText>
<figure confidence="0.968327263157895">
es Pz� argmax
e3
max
d
390
SOURCE (f): si alguna funci´on no se encuentra disponible en su red
TARGET (e): if any feature is not available in your network
ITER-0 (ep)
ITER-1 (es) if any feature not is available on your network
(ep) if any feature
(t) in
(d) is
(n)
ITER-2 (es) not available at your network
(ep) not available
(t) in
(d)
FINAL (es) your network
(ep ≡ e) if any feature is not available in your network
</figure>
<figureCaption confidence="0.966989666666667">
Figure 2: Example of a multimodal IMT session for translating a Spanish sentence f from the Xerox corpus to an
English sentence e. If the decoding of the pen strokes d is correct, it is displayed in boldface. On the contrary, if d is
incorrect, it is shown crossed out. In this case, the user amends the error with the keyboard n (in typewriter).
</figureCaption>
<subsectionHeader confidence="0.976479">
2.1 Decoupled Approach
</subsectionHeader>
<bodyText confidence="0.9973185">
In (Alabau et al., 2010) we proposed a decoupled
approach to Eq. 4, where the on-line HTR decod-
ing was a separate problem from the IMT problem.
From Eq. 4 a two step process can be performed.
First, d is obtained,
translation model. Let us introduce a hidden vari-
able j that accounts for a position of a word in f
which is a candidate translation of d. Then,
</bodyText>
<equation confidence="0.515061333333333">
|f|
Pr(d|f,i) = L Pr(d, j|f, i) (7)
j=1
d ≈ argmax Pr(t|d) Pr(d|ep, f) (5) ≈ |f |Pr(j|f, i)Pr(d|fj) (8)
d L
j=1
</equation>
<bodyText confidence="0.9924985">
Then, the most likely suffix is obtained as in Eq 1,
but taking d as the corrected word instead of n,
</bodyText>
<equation confidence="0.989699">
es = argmax Pr(es|ep, d, f) (6)
e3
</equation>
<bodyText confidence="0.9976995">
Finally, in that work, the terms of Eq. 5 were in-
terpolated with a unigram in a log-linear model.
</bodyText>
<subsectionHeader confidence="0.998716">
2.2 Coupled Approach
</subsectionHeader>
<bodyText confidence="0.999856777777778">
The formulation presented in Eq. 4 can be tackled
directly to perform a coupled decoding. The prob-
lem resides in how to model the constrained lan-
guage model. A first approach is to drop either the
ep or f terms from the probability. If f is dropped,
then Pr(d|ep) can be modelled as a regular n-gram
model. On the other hand, if ep is dropped, but the
position of d in the target sentence i = |ep |+ 1 is
kept, Pr(d|f, i) can be modelled as a word-based
Both probabilities, Pr(j|f, i) and Pr(d|fj), can
be estimated using IBM models (Brown et al.,
1993). The first term is an alignment probability
while the second is a word dictionary. Word dic-
tionary probabilities can be directly estimated by
IBM1 models. However, word dictionaries are not
symmetric. Alternatively, this probability can be
estimated using the inverse dictionary to provide a
smoothed dictionary,
</bodyText>
<equation confidence="0.9994115">
Pr(d) Pr(fj|d)
Pr(d|fj) = �dl Pr(d0) Pr(fj|d0) (9)
</equation>
<bodyText confidence="0.999323">
Thus, four word-based translation models have
been considered: direct IBM1 and IBM2 models,
and inverse IBM1-inv and IBM2-inv models with
the inverse dictionary from Eq. 9.
However, a more interesting set up than using lan-
guage models or translation models alone is to com-
bine both models. Two schemes have been studied.
</bodyText>
<page confidence="0.994083">
391
</page>
<bodyText confidence="0.999545">
The most formal under a probabilistic point of view
is a linear interpolation of the models,
</bodyText>
<equation confidence="0.9982015">
Pr(d|ep, f) = αPr(d|ep) + (1 − α)Pr(d|f, i)
(10)
</equation>
<bodyText confidence="0.995497">
However, a common approach to combine models
nowadays is log-linear interpolation (Berger et al.,
1996; Papineni et al., 1998; Och and Ney, 2002),
</bodyText>
<equation confidence="0.877251">
exp (&amp;m λmhm(d, f, ep))
Pr(d|ep, f) = (11)
Z
</equation>
<bodyText confidence="0.999767125">
λm being a scaling factor for model m, hm the log-
probability of each model considered in the log-
lineal interpolation and Z a normalisation factor.
Finally, to balance the absolute values of the mor-
phological model, the constrained language model
and the IMT model, these probabilities are com-
bined in a log-linear manner regardless of the lan-
guage modelling approach.
</bodyText>
<sectionHeader confidence="0.999593" genericHeader="method">
3 Experiments
</sectionHeader>
<bodyText confidence="0.9999728">
The Xerox corpus, created on the TT2
project (SchulmbergerSema S.A. et al., 2001),
was used for these experiments, since it has been
extensively used in the literature to obtain IMT
results. The simplified English and Spanish versions
were used to estimate the IMT, IBM and language
models. The corpus consists of 56k sentences of
training and a development and test sets of 1.1k
sentences. Test perplexities for Spanish and English
are 33 and 48, respectively.
For on-line HTR, the on-line handwritten
UNIPEN corpus (Guyon et al., 1994) was used.
The morphological models were represented by con-
tinuous density left-to-right character HMMs with
Gaussian mixtures, as in speech recognition (Ra-
biner, 1989), but with variable number of states per
character. Feature extraction consisted on speed
and size normalisation of pen positions and veloc-
ities, resulting in a sequence of vectors of six fea-
tures (Toselli et al., 2007).
The simulation of user interaction was performed
in the following way. First, the publicly available
IMT decoder Thot (Ortiz-Martinez et al., 2005) 1
was used to run an off-line simulation for keyboard-
based IMT. As a result, a list of words the system
</bodyText>
<footnote confidence="0.983292">
1http://sourceforge.net/projects/thot/
</footnote>
<table confidence="0.9937336">
System dev Spanish dev English
test test
independent HTR (†) 9.6 10.9 7.7 9.6
decoupled (?) 9.5 10.8 7.2 9.6
best coupled 6.7 8.9 5.5 7.2
</table>
<tableCaption confidence="0.93796625">
Table 1: Comparison of the CER with previous systems.
In boldface the best system. (†) is an independent, con-
text unaware system used as baseline. (?) is a model
equivalent to (Alabau et al., 2010).
</tableCaption>
<bodyText confidence="0.997090583333333">
failed to predict was obtained. Supposedly, this is
the list of words that the user would like to cor-
rect with handwriting. Then, from UNIPEN cor-
pus, three users (separated from the training) were
selected to simulate user interaction. For each user,
the handwritten words were generated by concate-
nating random character instances from the user’s
data to form a single stroke. Finally, the generated
handwritten words of the three users were decoded
using the corresponding constrained language model
with a state-of-the-art HMM decoder, iAtros (Luj´an-
Mares et al., 2008).
</bodyText>
<subsectionHeader confidence="0.800766">
3.1 Results
</subsectionHeader>
<bodyText confidence="0.999779478260869">
Results are presented in classification error rate
(CER), i.e. the ratio between the errors committed
by the on-line HTR decoder and the number of hand-
written words introduced by the user. All the results
have been calculated as the average CER of the three
users.
Table 1 shows a comparison between the best
results in this work and the approaches in previ-
ous work. The log-linear and linear weights were
obtained with the simplex algorithm (Nelder and
Mead, 1965) to optimise the development set. Then,
those weights were used for the test set.
Two baseline models have been established for
comparison purposes. On the one hand, (†) is a
completely independent and context unaware sys-
tem. That would be the equivalent to decode the
handwritten text in a separate on-line HTR decoder.
This system obtains the worst results of all. On
the other hand, (?) is the most similar model to the
best system in (Alabau et al., 2010). This system
is clearly outperformed by the proposed coupled ap-
proach.
A summary of the alternatives to language mod-
</bodyText>
<page confidence="0.993624">
392
</page>
<table confidence="0.997749888888889">
System dev Spanish dev English
test test
4gr 7.8 10.0 6.3 8.9
IBM1 7.9 9.6 7.0 8.2
IBM2 7.1 8.6 6.1 7.9
IBM1-inv 8.4 9.5 7.5 9.2
IBM2-inv 7.9 9.1 7.1 9.1
4gr+IBM2 (L-Linear) 7.0 9.1 6.0 7.9
4gr+IBM2 (Linear) 6.7 8.9 5.5 7.2
</table>
<tableCaption confidence="0.991225333333333">
Table 2: Summary of the CER results for various lan-
guage modelling approaches. In boldface the best sys-
tem.
</tableCaption>
<bodyText confidence="0.999955034482758">
elling is shown in Tab. 2. Up to 5-grams were used
in the experiments. However, the results did not
show significant differences between them, except
for the 1-gram. Thus, context does not seem to im-
prove much the performance. This may be due to
the fact that the IMT and the on-line HTR systems
use the same language models (5-gram in the case
of the IMT system). Hence, if the IMT has failed to
predict the correct word because of poor language
modelling that will affect on-line HTR decoding as
well. In fact, although language perplexities for the
test sets are quite low (33 for Spanish and 48 for En-
glish), perplexities accounting only erroneous words
increase until 305 and 420, respectively.
On the contrary, using IBM models provides a
significant boost in performance. Although in-
verse dictionaries have a better vocabulary coverage
(4.7% vs 8.9% in English, 7.4% vs 10.4% in Span-
ish), they tend to perform worse than their direct
dictionary counterparts. Still, inverse IBM models
perform better than the n-grams alone. Log-linear
models show a bit of improvement with respect to
IBM models. However, linear interpolated models
perform the best. In the Spanish test set the result is
not better that the IBM2 since the linear parameters
are clearly over-fitted. Other model combinations
(including a combination of all models) were tested.
Nevertheless, none of them outperformed the best
system in Table 2.
</bodyText>
<subsectionHeader confidence="0.995449">
3.2 Error Analysis
</subsectionHeader>
<bodyText confidence="0.999960736842105">
An analysis of the results showed that 52.2% to
61.7% of the recognition errors were produced by
punctuation and other symbols. To circumvent this
problem, we proposed a contextual menu in (Al-
abau et al., 2010). With such menu, errors would
have been reduced (best test result) to 4.1% in Span-
ish and 2.8% in English. Out-of-vocabulary (OOV)
words also summed up a big percentage of the error
(29.1% and 20.4%, respectively). This difference
is due to the fact that Spanish is a more inflected
language. To solve this problem on-line learning al-
gorithms or methods for dealing with OOV words
should be used. Errors in gender, number and verb
tenses, which rose up to 7.7% and 5.3% of the er-
rors, could be tackled using linguistic information
from both source and target sentences. Finally, the
rest of the errors were mostly due to one-to-three
letter words, which is basically a problem of hand-
writing morphological modelling.
</bodyText>
<sectionHeader confidence="0.99979" genericHeader="conclusions">
4 Conclusions
</sectionHeader>
<bodyText confidence="0.99925525">
In this paper we have described a specific on-line
HTR system that can serve as an alternative interac-
tion modality to IMT. We have shown that a tight in-
tegration of the HTR and IMT decoding process and
the use of the available information can produce sig-
nificant HTR error reductions. Finally, a study of the
system’s errors has revealed the system weaknesses,
and how they could be addressed in the future.
</bodyText>
<sectionHeader confidence="0.999273" genericHeader="acknowledgments">
5 Acknowledgments
</sectionHeader>
<bodyText confidence="0.999982">
Work supported by the EC (FEDER/FSE) and the
Spanish MEC/MICINN under the MIPRCV ”Con-
solider Ingenio 2010” program (CSD2007-00018),
iTrans2 (TIN2009-14511). Also supported by
the Spanish MITyC under the erudito.com (TSI-
020110-2009-439) project and by the Generali-
tat Valenciana under grant Prometeo/2009/014 and
GV/2010/067, and by the ”Vicerrectorado de Inves-
tigaci´on de la UPV” under grant UPV/2009/2851.
</bodyText>
<sectionHeader confidence="0.998675" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.983440125">
[Alabau et al.2010] V. Alabau, D. Ortiz-Martinez, A. San-
chis, and F. Casacuberta. 2010. Multimodal in-
teractive machine translation. In Proceedings of the
2010 International Conference on Multimodal Inter-
faces (ICMI-MLMI’10), pages 46:1–4, Beijing, China,
Nov.
[Barrachina et al.2009] S. Barrachina, O. Bender,
F. Casacuberta, J. Civera, E. Cubel, S. Khadivi, A. L.
</reference>
<page confidence="0.995991">
393
</page>
<reference confidence="0.999619">
Lagarda, H. Ney, J. Tom´as, E. Vidal, and J. M. Vilar.
2009. Statistical approaches to computer-assisted
translation. Computational Linguistics, 35(1):3–28.
[Berger et al.1996] A. L. Berger, S. A. Della Pietra, and
V. J. Della Pietra. 1996. A maximum entropy ap-
proach to natural language processing. Computational
Linguistics, 22:39–71.
[Brown et al.1993] P. F. Brown, S. A. Della Pietra,
V. J. Della Pietra, and R. L. Mercer. 1993. The math-
ematics of machine translation. 19(2):263–311.
[Foster et al.1998] G. Foster, P. Isabelle, and P. Plamon-
don. 1998. Target-text mediated interactive machine
translation. Machine Translation, 12:175–194.
[Guyon et al.1994] Isabelle Guyon, Lambert Schomaker,
R´ejean Plamondon, Mark Liberman, and Stan Janet.
1994. Unipen project of on-line data exchange and
recognizer benchmarks. In Proceedings of Interna-
tional Conference on Pattern Recognition, pages 29–
33.
[Koehn and Haddow2009] P. Koehn and B. Haddow.
2009. Interactive assistance to human translators using
statistical machine translation methods. In Proceed-
ings of MT Summit XII, pages 73–80, Ottawa, Canada.
[Luj´an-Mares et al.2008] Miriam Luj´an-Mares, Vicent
Tamarit, Vicent Alabau, Carlos D. Martinez-
Hinarejos, Mois´es Pastor i Gadea, Alberto Sanchis,
and Alejandro H. Toselli. 2008. iATROS: A speech
and handwritting recognition system. In V Jornadas
en Tecnolog´ıas del Habla (VJTH’2008), pages 75–78,
Bilbao (Spain), Nov.
[Nelder and Mead1965] J. A. Nelder and R. Mead. 1965.
A simplex method for function minimization. Com-
puter Journal, 7:308–313.
[Och and Ney2002] F. J. Och and H. Ney. 2002. Dis-
criminative training and maximum entropy models for
statistical machine translation. In Proceedings of the
40th ACL, pages 295–302, Philadelphia, PA, July.
[Ortiz-Martinez et al.2005] D. Ortiz-Martinez, I. Garcia-
Varea, and F. Casacuberta. 2005. Thot: a toolkit to
train phrase-based statistical translation models. In
Proceedings of the MT Summit X, pages 141–148.
[Papineni et al.1998] K. A. Papineni, S. Roukos, and R. T.
Ward. 1998. Maximum likelihood and discriminative
training of direct translation models. In International
Conference on Acoustics, Speech, and Signal Process-
ing (ICASSP’98), pages 189–192, Seattle, Washing-
ton, USA, May.
[Rabiner1989] L. Rabiner. 1989. A Tutorial of Hidden
Markov Models and Selected Application in Speech
Recognition. Proceedings IEEE, 77:257–286.
[SchulmbergerSema S.A. et al.2001] SchulmbergerSema
S.A., Celer Soluciones, Instituto T´ecnico de In-
form´atica, R.W.T.H. Aachen - Lehrstuhl f¨ur In-
formatik VI, R.A.L.I. Laboratory - University of
Montreal, Soci´et´e Gamma, and Xerox Research
Centre Europe. 2001. X.R.C.: TT2. TransType2
- Computer assisted translation. Project technical
annex.
[Toselli et al.2007] Alejandro H. Toselli, Mois´es Pastor
i Gadea, and Enrique Vidal. 2007. On-line handwrit-
ing recognition system for tamil handwritten charac-
ters. In 3rd Iberian Conference on Pattern Recognition
and Image Analysis, pages 370–377. Girona (Spain),
June.
[Toselli et al.2010] A. H. Toselli, V. Romero, M. Pastor,
and E. Vidal. 2010. Multimodal interactive transcrip-
tion of text images. Pattern Recognition, 43(5):1814–
1825.
[Vidal et al.2006] E. Vidal, F. Casacuberta, L. Rodriguez,
J. Civera, and C. Martinez. 2006. Computer-assisted
translation using speech recognition. IEEE Trans-
action on Audio, Speech and Language Processing,
14(3):941–951.
</reference>
<page confidence="0.998984">
394
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.367591">
<title confidence="0.999006">Improving On-line Handwritten Recognition using Translation in Multimodal Interactive Machine Translation</title>
<author confidence="0.989477">Vicent Alabau</author>
<author confidence="0.989477">Alberto Sanchis</author>
<author confidence="0.989477">Francisco</author>
<affiliation confidence="0.990383">Institut Tecnol`ogic Universitat Polit`ecnica de</affiliation>
<address confidence="0.381756">Camide Vera, s/n, Valencia,</address>
<abstract confidence="0.998994769230769">In interactive machine translation (IMT), a human expert is integrated into the core of a machine translation (MT) system. The human expert interacts with the IMT system by partially correcting the errors of the system’s output. Then, the system proposes a new solution. This process is repeated until the output meets the desired quality. In this scenario, the interaction is typically performed using the keyboard and the mouse. In this work, we present an alternative modality to interact within IMT systems by writing on a tactile display or using an electronic pen. An on-line handwritten text recognition (HTR) system has been specifically designed to operate with IMT systems. Our HTR system improves previous approaches in two main aspects. First, HTR decoding is tightly coupled with the IMT system. Second, the language models proposed are context aware, in the sense that they take into account the partial corrections and the source sentence by using a combination of ngrams and word-based IBM models. The proposed system achieves an important boost in performance with respect to previous work.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>V Alabau</author>
<author>D Ortiz-Martinez</author>
<author>A Sanchis</author>
<author>F Casacuberta</author>
</authors>
<title>Multimodal interactive machine translation.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 International Conference on Multimodal Interfaces (ICMI-MLMI’10),</booktitle>
<pages>46--1</pages>
<location>Beijing, China,</location>
<marker>[Alabau et al.2010]</marker>
<rawString>V. Alabau, D. Ortiz-Martinez, A. Sanchis, and F. Casacuberta. 2010. Multimodal interactive machine translation. In Proceedings of the 2010 International Conference on Multimodal Interfaces (ICMI-MLMI’10), pages 46:1–4, Beijing, China, Nov.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Barrachina</author>
<author>O Bender</author>
<author>F Casacuberta</author>
<author>J Civera</author>
<author>E Cubel</author>
<author>S Khadivi</author>
<author>A L Lagarda</author>
<author>H Ney</author>
<author>J Tom´as</author>
<author>E Vidal</author>
<author>J M Vilar</author>
</authors>
<title>Statistical approaches to computer-assisted translation.</title>
<date>2009</date>
<journal>Computational Linguistics,</journal>
<volume>35</volume>
<issue>1</issue>
<marker>[Barrachina et al.2009]</marker>
<rawString>S. Barrachina, O. Bender, F. Casacuberta, J. Civera, E. Cubel, S. Khadivi, A. L. Lagarda, H. Ney, J. Tom´as, E. Vidal, and J. M. Vilar. 2009. Statistical approaches to computer-assisted translation. Computational Linguistics, 35(1):3–28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A L Berger</author>
<author>S A Della Pietra</author>
<author>V J Della Pietra</author>
</authors>
<title>A maximum entropy approach to natural language processing.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<pages>22--39</pages>
<marker>[Berger et al.1996]</marker>
<rawString>A. L. Berger, S. A. Della Pietra, and V. J. Della Pietra. 1996. A maximum entropy approach to natural language processing. Computational Linguistics, 22:39–71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P F Brown</author>
<author>S A Della Pietra</author>
<author>V J Della Pietra</author>
<author>R L Mercer</author>
</authors>
<title>The mathematics of machine translation.</title>
<date>1993</date>
<marker>[Brown et al.1993]</marker>
<rawString>P. F. Brown, S. A. Della Pietra, V. J. Della Pietra, and R. L. Mercer. 1993. The mathematics of machine translation. 19(2):263–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Foster</author>
<author>P Isabelle</author>
<author>P Plamondon</author>
</authors>
<title>Target-text mediated interactive machine translation.</title>
<date>1998</date>
<booktitle>Machine Translation,</booktitle>
<pages>12--175</pages>
<marker>[Foster et al.1998]</marker>
<rawString>G. Foster, P. Isabelle, and P. Plamondon. 1998. Target-text mediated interactive machine translation. Machine Translation, 12:175–194.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Isabelle Guyon</author>
<author>Lambert Schomaker</author>
<author>R´ejean Plamondon</author>
<author>Mark Liberman</author>
<author>Stan Janet</author>
</authors>
<title>Unipen project of on-line data exchange and recognizer benchmarks.</title>
<date>1994</date>
<booktitle>In Proceedings of International Conference on Pattern Recognition,</booktitle>
<pages>29--33</pages>
<marker>[Guyon et al.1994]</marker>
<rawString>Isabelle Guyon, Lambert Schomaker, R´ejean Plamondon, Mark Liberman, and Stan Janet. 1994. Unipen project of on-line data exchange and recognizer benchmarks. In Proceedings of International Conference on Pattern Recognition, pages 29– 33.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>B Haddow</author>
</authors>
<title>Interactive assistance to human translators using statistical machine translation methods.</title>
<date>2009</date>
<booktitle>In Proceedings of MT Summit XII,</booktitle>
<pages>73--80</pages>
<location>Ottawa, Canada.</location>
<marker>[Koehn and Haddow2009]</marker>
<rawString>P. Koehn and B. Haddow. 2009. Interactive assistance to human translators using statistical machine translation methods. In Proceedings of MT Summit XII, pages 73–80, Ottawa, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Miriam Luj´an-Mares</author>
<author>Vicent Tamarit</author>
<author>Vicent Alabau</author>
<author>Carlos D MartinezHinarejos</author>
<author>Mois´es Pastor i Gadea</author>
<author>Alberto Sanchis</author>
<author>Alejandro H Toselli</author>
</authors>
<title>iATROS: A speech and handwritting recognition system.</title>
<date>2008</date>
<booktitle>In V Jornadas en Tecnolog´ıas del Habla (VJTH’2008),</booktitle>
<pages>75--78</pages>
<location>Bilbao</location>
<marker>[Luj´an-Mares et al.2008]</marker>
<rawString>Miriam Luj´an-Mares, Vicent Tamarit, Vicent Alabau, Carlos D. MartinezHinarejos, Mois´es Pastor i Gadea, Alberto Sanchis, and Alejandro H. Toselli. 2008. iATROS: A speech and handwritting recognition system. In V Jornadas en Tecnolog´ıas del Habla (VJTH’2008), pages 75–78, Bilbao (Spain), Nov.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J A Nelder</author>
<author>R Mead</author>
</authors>
<title>A simplex method for function minimization.</title>
<date>1965</date>
<journal>Computer Journal,</journal>
<pages>7--308</pages>
<marker>[Nelder and Mead1965]</marker>
<rawString>J. A. Nelder and R. Mead. 1965. A simplex method for function minimization. Computer Journal, 7:308–313.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>Discriminative training and maximum entropy models for statistical machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th ACL,</booktitle>
<pages>295--302</pages>
<location>Philadelphia, PA,</location>
<marker>[Och and Ney2002]</marker>
<rawString>F. J. Och and H. Ney. 2002. Discriminative training and maximum entropy models for statistical machine translation. In Proceedings of the 40th ACL, pages 295–302, Philadelphia, PA, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Ortiz-Martinez</author>
<author>I GarciaVarea</author>
<author>F Casacuberta</author>
</authors>
<title>Thot: a toolkit to train phrase-based statistical translation models.</title>
<date>2005</date>
<booktitle>In Proceedings of the MT Summit X,</booktitle>
<pages>141--148</pages>
<marker>[Ortiz-Martinez et al.2005]</marker>
<rawString>D. Ortiz-Martinez, I. GarciaVarea, and F. Casacuberta. 2005. Thot: a toolkit to train phrase-based statistical translation models. In Proceedings of the MT Summit X, pages 141–148.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K A Papineni</author>
<author>S Roukos</author>
<author>R T Ward</author>
</authors>
<title>Maximum likelihood and discriminative training of direct translation models.</title>
<date>1998</date>
<booktitle>In International Conference on Acoustics, Speech, and Signal Processing (ICASSP’98),</booktitle>
<pages>189--192</pages>
<location>Seattle, Washington, USA,</location>
<marker>[Papineni et al.1998]</marker>
<rawString>K. A. Papineni, S. Roukos, and R. T. Ward. 1998. Maximum likelihood and discriminative training of direct translation models. In International Conference on Acoustics, Speech, and Signal Processing (ICASSP’98), pages 189–192, Seattle, Washington, USA, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Rabiner</author>
</authors>
<title>A Tutorial of Hidden Markov Models and Selected Application in Speech Recognition.</title>
<date>1989</date>
<booktitle>Proceedings IEEE,</booktitle>
<pages>77--257</pages>
<marker>[Rabiner1989]</marker>
<rawString>L. Rabiner. 1989. A Tutorial of Hidden Markov Models and Selected Application in Speech Recognition. Proceedings IEEE, 77:257–286.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S A SchulmbergerSema</author>
</authors>
<title>Celer Soluciones, Instituto T´ecnico de Inform´atica, R.W.T.H. Aachen - Lehrstuhl f¨ur</title>
<date>2001</date>
<booktitle>X.R.C.: TT2. TransType2 - Computer assisted translation. Project technical annex.</booktitle>
<institution>Informatik VI, R.A.L.I. Laboratory - University of Montreal, Soci´et´e Gamma, and Xerox Research Centre Europe.</institution>
<marker>[SchulmbergerSema S.A. et al.2001]</marker>
<rawString>SchulmbergerSema S.A., Celer Soluciones, Instituto T´ecnico de Inform´atica, R.W.T.H. Aachen - Lehrstuhl f¨ur Informatik VI, R.A.L.I. Laboratory - University of Montreal, Soci´et´e Gamma, and Xerox Research Centre Europe. 2001. X.R.C.: TT2. TransType2 - Computer assisted translation. Project technical annex.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alejandro H Toselli</author>
<author>Mois´es Pastor i Gadea</author>
<author>Enrique Vidal</author>
</authors>
<title>On-line handwriting recognition system for tamil handwritten characters.</title>
<date>2007</date>
<booktitle>In 3rd Iberian Conference on Pattern Recognition and Image Analysis,</booktitle>
<pages>370--377</pages>
<location>Girona</location>
<marker>[Toselli et al.2007]</marker>
<rawString>Alejandro H. Toselli, Mois´es Pastor i Gadea, and Enrique Vidal. 2007. On-line handwriting recognition system for tamil handwritten characters. In 3rd Iberian Conference on Pattern Recognition and Image Analysis, pages 370–377. Girona (Spain), June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A H Toselli</author>
<author>V Romero</author>
<author>M Pastor</author>
<author>E Vidal</author>
</authors>
<title>Multimodal interactive transcription of text images.</title>
<date>2010</date>
<journal>Pattern Recognition,</journal>
<volume>43</volume>
<issue>5</issue>
<pages>1825</pages>
<marker>[Toselli et al.2010]</marker>
<rawString>A. H. Toselli, V. Romero, M. Pastor, and E. Vidal. 2010. Multimodal interactive transcription of text images. Pattern Recognition, 43(5):1814– 1825.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Vidal</author>
<author>F Casacuberta</author>
<author>L Rodriguez</author>
<author>J Civera</author>
<author>C Martinez</author>
</authors>
<title>Computer-assisted translation using speech recognition.</title>
<date>2006</date>
<journal>IEEE Transaction on Audio, Speech and Language Processing,</journal>
<volume>14</volume>
<issue>3</issue>
<marker>[Vidal et al.2006]</marker>
<rawString>E. Vidal, F. Casacuberta, L. Rodriguez, J. Civera, and C. Martinez. 2006. Computer-assisted translation using speech recognition. IEEE Transaction on Audio, Speech and Language Processing, 14(3):941–951.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>