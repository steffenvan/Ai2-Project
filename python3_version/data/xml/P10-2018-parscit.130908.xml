<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.009384">
<title confidence="0.999579">
A Structured Model for Joint Learning of
Argument Roles and Predicate Senses
</title>
<author confidence="0.996278">
Yotaro Watanabe
</author>
<affiliation confidence="0.9953475">
Graduate School of Information Sciences
Tohoku University
</affiliation>
<address confidence="0.8638765">
6-6-05, Aramaki Aza Aoba, Aoba-ku,
Sendai 980-8579, Japan
</address>
<email confidence="0.997927">
yotaro-w@ecei.tohoku.ac.jp
</email>
<author confidence="0.97657">
Masayuki Asahara Yuji Matsumoto
</author>
<affiliation confidence="0.996686">
Graduate School of Information Science
Nara Institute of Science and Technology
</affiliation>
<address confidence="0.9385065">
8916-5 Takayama, Ikoma,
Nara, 630-0192, Japan
</address>
<email confidence="0.997929">
{masayu-a, matsu}@is.naist.jp
</email>
<sectionHeader confidence="0.997367" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999957681818182">
In predicate-argument structure analysis,
it is important to capture non-local de-
pendencies among arguments and inter-
dependencies between the sense of a pred-
icate and the semantic roles of its argu-
ments. However, no existing approach ex-
plicitly handles both non-local dependen-
cies and semantic dependencies between
predicates and arguments. In this pa-
per we propose a structured model that
overcomes the limitation of existing ap-
proaches; the model captures both types of
dependencies simultaneously by introduc-
ing four types of factors including a global
factor type capturing non-local dependen-
cies among arguments and a pairwise fac-
tor type capturing local dependencies be-
tween a predicate and an argument. In
experiments the proposed model achieved
competitive results compared to the state-
of-the-art systems without applying any
feature selection procedure.
</bodyText>
<sectionHeader confidence="0.999475" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999742535714286">
Predicate-argument structure analysis is a process
of assigning who does what to whom, where,
when, etc. for each predicate. Arguments of a
predicate are assigned particular semantic roles,
such as Agent, Theme, Patient, etc. Lately,
predicate-argument structure analysis has been re-
garded as a task of assigning semantic roles of
arguments as well as word senses of a predicate
(Surdeanu et al., 2008; Hajiˇc et al., 2009).
Several researchers have paid much attention to
predicate-argument structure analysis, and the fol-
lowing two important factors have been shown.
Toutanova et al. (2008), Johansson and Nugues
(2008), and Bj¨orkelund et al. (2009) presented
importance of capturing non-local dependencies
of core arguments in predicate-argument structure
analysis. They used argument sequences tied with
a predicate sense (e.g. AGENT-buy.01/Active-
PATIENT) as a feature for the re-ranker of the
system where predicate sense and argument role
candidates are generated by their pipelined archi-
tecture. They reported that incorporating this type
of features provides substantial gain of the system
performance.
The other factor is inter-dependencies between
a predicate sense and argument roles, which re-
late to selectional preference, and motivated us
to jointly identify a predicate sense and its argu-
ment roles. This type of dependencies has been
explored by Riedel and Meza-Ruiz (2008; 2009b;
2009a), all of which use Markov Logic Networks
(MLN). The work uses the global formulae that
have atoms in terms of both a predicate sense and
each of its argument roles, and the system identi-
fies predicate senses and argument roles simulta-
neously.
Ideally, we want to capture both types of depen-
dencies simultaneously. The former approaches
can not explicitly include features that capture
inter-dependencies between a predicate sense and
its argument roles. Though these are implicitly in-
corporated by re-ranking where the most plausi-
ble assignment is selected from a small subset of
predicate and argument candidates, which are gen-
erated independently. On the other hand, it is dif-
ficult to deal with core argument features in MLN.
Because the number of core arguments varies with
the role assignments, this type of features cannot
be expressed by a single formula.
Thompson et al. (2010) proposed a gener-
ative model that captures both predicate senses
and its argument roles. However, the first-order
markov assumption of the model eliminates abil-
ity to capture non-local dependencies among ar-
guments. Also, generative models are in general
inferior to discriminatively trained linear or log-
</bodyText>
<page confidence="0.980282">
98
</page>
<note confidence="0.844648">
Proceedings of the ACL 2010 Conference Short Papers, pages 98–102,
Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<figureCaption confidence="0.983208">
Figure 1: Undirected graphical model representa-
tion of the structured model
</figureCaption>
<bodyText confidence="0.962324785714286">
linear models.
In this paper we propose a structured model
that overcomes limitations of the previous ap-
proaches. For the model, we introduce several
types of features including those that capture both
non-local dependencies of core arguments, and
inter-dependencies between a predicate sense and
its argument roles. By doing this, both tasks are
mutually influenced, and the model determines
the most plausible set of assignments of a predi-
cate sense and its argument roles simultaneously.
We present an exact inference algorithm for the
model, and a large-margin learning algorithm that
can handle both local and global features.
</bodyText>
<sectionHeader confidence="0.984583" genericHeader="introduction">
2 Model
</sectionHeader>
<bodyText confidence="0.981998">
Figure 1 shows the graphical representation of our
proposed model. The node p corresponds to a
predicate, and the nodes al, ..., aN to arguments
of the predicate. Each node is assigned a particu-
lar predicate sense or an argument role label. The
black squares are factors which provide scores of
label assignments. In the model, the nodes for ar-
guments depend on the predicate sense, and by in-
fluencing labels of a predicate sense and its argu-
ment roles, the most plausible label assignment of
the nodes is determined considering all factors.
In this work, we use linear models. Let x be
words in a sentence, p be a sense of a predicate in
x, and A = {an}N1 be a set of possible role label
assignments for x. A predicate-argument structure
is represented by a pair of p and A. We define
the score function for predicate-argument struc-
tures as s(p, A) = ∑FkE.r Fk(x, p, A). F is a
set of all the factors, Fk(x, p, A) corresponds to a
particular factor in Figure 1, and gives a score to a
predicate or argument label assignments. Since we
use linear models, Fk(x, p, A) = w · &apos;bk(x, p, A).
</bodyText>
<subsectionHeader confidence="0.996261">
2.1 Factors of the Model
</subsectionHeader>
<bodyText confidence="0.997728625">
We define four types of factors for the model.
Predicate Factor FP scores a sense of p, and
does not depend on any arguments. The score
function is defined by FP (x, p, A) = w·&apos;bP (x, p).
Argument Factor FA scores a label assignment
of a particular argument a ∈ A. The score is deter-
mined independently from a predicate sense, and
is given by FA(x, p, a) = w · &apos;bA(x, a).
</bodyText>
<subsectionHeader confidence="0.994739">
Predicate-Argument Pairwise Factor
</subsectionHeader>
<bodyText confidence="0.9995915">
FPA captures inter-dependencies between
a predicate sense and one of its argument
roles. The score function is defined as
FPA(x, p, a) = w · &apos;bPA(x, p, a). The dif-
ference from FA is that FPA influences both
the predicate sense and the argument role. By
introducing this factor, the role label can be
influenced by the predicate sense, and vise versa.
Global Factor FG is introduced to capture plau-
sibility of the whole predicate-argument structure.
Like the other factors, the score function is de-
fined as FG(x, p, A) = w · &apos;bG(x, p, A). A pos-
sible feature that can be considered by this fac-
tor is the mutual dependencies among core argu-
ments. For instance, if a predicate-argument struc-
ture has an agent (A0) followed by the predicate
and a patient (A1), we encode the structure as a
string A0-PRED-A1 and use it as a feature. This
type of features provide plausibility of predicate-
argument structures. Even if the highest scoring
predicate-argument structure with the other factors
misses some core arguments, the global feature
demands the model to fill the missing arguments.
The numbers of factors for each factor type are:
FP and FG are 1, FA and FPA are |A|. By inte-
grating the all factors, the score function becomes
s(p, A)ff = w · &apos;bP (x, p) + w · &apos;bG (x, p, A) + w
∑aEAl&apos;bA
</bodyText>
<subsectionHeader confidence="0.918706">
2.2 Inference
</subsectionHeader>
<bodyText confidence="0.999550444444444">
The crucial point of the model is how to deal
with the global factor FG, because enumerating
possible assignments is too costly. A number of
methods have been proposed for the use of global
features for linear models such as (Daum´e III
and Marcu, 2005; Kazama and Torisawa, 2007).
In this work, we use the approach proposed in
(Kazama and Torisawa, 2007). Although the ap-
proach is proposed for sequence labeling tasks, it
</bodyText>
<figure confidence="0.619225428571428">
FG
P
FP
FPA
a( aZ a3 a4 ...... aN
FA
(x, a) + &apos;bPA(x, p, a)}.
</figure>
<page confidence="0.980822">
99
</page>
<bodyText confidence="0.999926428571429">
can be easily extended to our structured model.
That is, for each possible predicate sense p of the
predicate, we provide N-best argument role as-
signments using three local factors FP, FA and
FPA, and then add scores of the global factor FG,
finally select the argmax from them. In this case,
the argmax is selected from |Pl|N candidates.
</bodyText>
<subsectionHeader confidence="0.997627">
2.3 Learning the Model
</subsectionHeader>
<bodyText confidence="0.999910789473684">
For learning of the model, we borrow a funda-
mental idea of Kazama and Torisawa’s perceptron
learning algorithm. However, we use a more so-
phisticated online-learning algorithm based on the
Passive-Aggressive Algorithm (PA) (Crammer et
al., 2006).
For the sake of simplicity, we introduce some
notations. We denote a predicate-argument struc-
ture y = (p, A), a local feature vector as
4bL(x, y) = 4bP(x,p) + ∑aCA{4bA(x, a) +
4bPA(x, p, a)} a feature vector coupling both
local and global features as 4bL+G(x, y) =
4bL(x, y) + 4bG(x, p, A), the argmax using 4bL+G
as ˆyL+G, the argmax using 4bL as ˆyL. Also, we
use a loss function ρ(y, y&apos;), which is a cost func-
tion associated with y and y&apos;.
The margin perceptron learning proposed by
Kazama and Torisawa can be seen as an optimiza-
tion with the following two constrains.
</bodyText>
<figure confidence="0.8535875">
(A) w·ΦL+G(x, y)−w·ΦL+G(x, ˆyL+G)
(B) w · ΦL(x, y) − w · ΦL(x,ˆyL) ≥ P(y,ˆyL)
</figure>
<bodyText confidence="0.989445">
(A) is the constraint that ensures a sufficient
margin ρ(y, ˆyL+G) between y and ˆyL+G. (B)
is the constraint that ensures a sufficient margin
ρ(y, ˆyL) between y and ˆyL. The necessity of
this constraint is that if we apply only (A), the al-
gorithm does not guarantee a sufficient margin in
terms of local features, and it leads to poor quality
in the N-best assignments. The Kazama and Tori-
sawa’s perceptron algorithm uses constant values
for the cost function ρ(y, ˆyL+G) and ρ(y, ˆyL).
The proposed model is trained using the follow-
ing optimization problem.
</bodyText>
<equation confidence="0.99809175">
2||w� − w||2 + Cξ
1
�s.t. lL+G ≤ξ, ξ ≥ 0 if ˆyL+G =6 y
if ˆyL+G = y =6 ˆyL (1)
s.t. lL ≤ ξ, ξ ≥ 0
lL+G = w · ΦL+G(x, ˆyL+G)
− w · ΦL+G(x, y) + P(y,ˆyL+G) (2)
lL = w · ΦL(x,ˆyL) − w · ΦL(x, y) + P(y,ˆyL) (3)
</equation>
<bodyText confidence="0.999357">
lL+G is the loss function for the case of using
both local and global features, corresponding to
the constraint (A), and lL is the loss function for
the case of using only local features, correspond-
ing to the constraints (B) provided that (A) is sat-
isfied.
</bodyText>
<subsectionHeader confidence="0.979304">
2.4 The Role-less Argument Bias Problem
</subsectionHeader>
<bodyText confidence="0.999938">
The fact that an argument candidate is not as-
signed any role (namely it is assigned the la-
bel “NONE”) is unlikely to contribute pred-
icate sense disambiguation. However, it re-
mains possible that “NONE” arguments is bi-
ased toward a particular predicate sense by FPA
(i.e. w · 4bPA(x, sensei, ak= “NONE&apos;&apos;) &gt; w ·
4bPA(x, sensej, ak= “NONE&apos;&apos;).
In order to avoid this bias, we define a spe-
cial sense label, senseany, that is used to cal-
culate the score for a predicate and a roll-less
argument, regardless of the predicate’s sense.
We use the feature vector 4bPA(x, senseany, ak)
if ak= “NONE&apos;&apos; and 4bPA(x, sensei, ak) other-
wise.
</bodyText>
<sectionHeader confidence="0.999844" genericHeader="method">
3 Experiment
</sectionHeader>
<subsectionHeader confidence="0.999348">
3.1 Experimental Settings
</subsectionHeader>
<bodyText confidence="0.96618312">
We use the CoNLL-2009 Shared Task dataset
(Hajiˇc et al., 2009) for experiments. It is a
dataset for multi-lingual syntactic and semantic
dependency parsing 1. In the SRL-only challenge
of the task, participants are required to identify
predicate-argument structures of only the specified
predicates. Therefore the problems to be solved
are predicate sense disambiguation and argument
role labeling. We use Semantic Labeled F1 for
evaluation.
For generating N-bests, we used the beam-
search algorithm, and the number of N-bests was
set to N = 64. For learning of the joint model, the
loss function ρ(yt, y&apos;) of the Passive-Aggressive
Algorithm was set to the number of incorrect as-
signments of a predicate sense and its argument
roles. Also, the number of iterations of the model
used for testing was selected based on the perfor-
mance on the development data.
Table 1 shows the features used for the struc-
tured model. The global features used for FG are
based on those used in (Toutanova et al., 2008;
Johansson and Nugues, 2008), and the features
&apos;The dataset consists of seven languages: Catalan, Chi-
nese, Czech, English, German, Japanese and Spanish.
</bodyText>
<equation confidence="0.867438333333333">
≥ P(y,ˆyL+G)
wnew = arg min
w/Efitn
</equation>
<page confidence="0.893374">
100
</page>
<bodyText confidence="0.9853036875">
FP Plemma of the predicate and predicate’s head, and ppos of the predicate
Dependency label between the predicate and predicate’s head
The concatenation of the dependency labels of the predicate’s dependents
FA Plemma and ppos of the predicate, the predicate’s head, the argument candidate, and the argument’s head
Plemma and ppos of the leftmost/rightmost dependent and leftmost/rightmost sibling
The dependency label of predicate, argument candidate and argument candidate’s dependent
The position of the argument candidate with respect to the predicate position in the dep. tree (e.g. CHILD)
The position of the head of the dependency relation with respect to the predicate position in the sentence
The left-to-right chain of the deplabels of the predicate’s dependents
Plemma, ppos and dependency label paths between the predicate and the argument candidates
The number of dependency edges between the predicate and the argument candidate
FPA Plemma and plemma&amp;ppos of the argument candidate
Dependency label path between the predicate and the argument candidates
FG The sequence of the predicate and the argument labels in the predicate-argument structure (e.g. A0-PRED-A1
Whether the semantic roles defined in frames exist in the structure, (e.g. CONTAINS:A1)
The conjunction of the predicate sense and the frame information (e.g. wear.01&amp;CONTAINS:A1)
</bodyText>
<tableCaption confidence="0.87332">
Table 1: Features for the Structured Model
</tableCaption>
<table confidence="0.9998365">
Avg. Ca Ch Cz En Ge Jp Sp
FP+FA 79.17 78.00 76.02 85.24 83.09 76.76 77.27 77.83
FP+FA+FPA 79.58 78.38 76.23 85.14 83.36 78.31 77.72 77.92
FP+FA+FG 80.42 79.50 76.96 85.88 84.49 78.64 78.32 79.21
ALL 80.75 79.55 77.20 85.94 84.97 79.62 78.69 79.29
Bj¨orkelund 80.80 80.01 78.60 85.41 85.63 79.71 76.30 79.91
Zhao 80.47 80.32 77.72 85.19 85.44 75.99 78.15 80.46
Meza-Ruiz 77.46 78.00 77.73 75.75 83.34 73.52 76.00 77.91
</table>
<tableCaption confidence="0.993204">
Table 2: Results on the CoNLL-2009 Shared Task dataset (Semantic Labeled F1).
</tableCaption>
<table confidence="0.9806562">
SENSE ARG
FP+FA 89.65 72.20
FP+FA+FPA 89.78 72.74
FP+FA+FG 89.83 74.11
ALL 90.15 74.46
</table>
<tableCaption confidence="0.608744833333333">
Table 3: Predicate sense disambiguation and argu-
ment role labeling results (average).
used for FPA are inspired by formulae used in
the MLN-based SRL systems, such as (Meza-Ruiz
and Riedel, 2009b). We used the same feature
templates for all languages.
</tableCaption>
<subsectionHeader confidence="0.980529">
3.2 Results
</subsectionHeader>
<bodyText confidence="0.999867361111111">
Table 2 shows the results of the experiments, and
also shows the results of the top 3 systems in the
CoNLL-2009 Shared Task participants of the SRL-
only system.
By incorporating FPA, we achieved perfor-
mance improvement for all languages. This results
suggest that it is effective to capture local inter-
dependencies between a predicate sense and one
of its argument roles. Comparing the results with
FP+FA and FP+FA+FG, incorporating FG also
contributed performance improvements for all lan-
guages, especially the substantial F1 improvement
of +1.88 is obtained in German.
Next, we compare our system with top 3 sys-
tems in the CoNLL-2009 Shared Task. By in-
corporating both FPA and FG, our joint model
achieved competitive results compared to the top 2
systems (Bj¨orkelund and Zhao), and achieved the
better results than the Meza-Ruiz’s system 2. The
systems by Bj¨orkelund and Zhao applied feature
selection algorithms in order to select the best set
of feature templates for each language, requiring
about 1 to 2 months to obtain the best feature set.
On the other hand, our system achieved the com-
petitive results with the top two systems, despite
the fact that we used the same feature templates
for all languages without applying any feature en-
gineering procedure.
Table 3 shows the performances of predicate
sense disambiguation and argument role labeling
separately. In terms of sense disambiguation re-
sults, incorporating FPA and FG worked well. Al-
though incorporating either of FPA and FG pro-
vided improvements of +0.13 and +0.18 on av-
erage, adding both factors provided improvements
of +0.50. We compared the predicate sense dis-
</bodyText>
<footnote confidence="0.9930196">
2The result of Meza-Ruiz for Czech is substantially worse
than the other systems because of inappropriate preprocess-
ing for predicate sense disambiguation. Excepting Czech, the
average F1 value of the Meza-Ruiz is 77.75, where as our
system is 79.89.
</footnote>
<page confidence="0.997842">
101
</page>
<bodyText confidence="0.999920421052631">
ambiguation results of FP + FA and ALL with the
McNemar test, and the difference was statistically
significant (p &lt; 0.01). This result suggests that
combination of these factors is effective for sense
disambiguation.
As for argument role labeling results, incorpo-
rating FPA and FG contributed positively for all
languages. Especially, we obtained a substan-
tial gain (+4.18) in German. By incorporating
FPA, the system achieved the F1 improvements
of +0.54 on average. This result shows that cap-
turing inter-dependencies between a predicate and
its arguments contributes to argument role label-
ing. By incorporating FG, the system achieved the
substantial improvement of F1 (+1.91).
Since both tasks improved by using all factors,
we can say that the proposed joint model suc-
ceeded in joint learning of predicate senses and
its argument roles.
</bodyText>
<sectionHeader confidence="0.999745" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999980578947368">
In this paper, we proposed a structured model that
captures both non-local dependencies between ar-
guments, and inter-dependencies between a pred-
icate sense and its argument roles. We designed
a linear model-based structured model, and de-
fined four types of factors: predicate factor, ar-
gument factor, predicate-argument pairwise fac-
tor and global factor for the model. In the ex-
periments, the proposed model achieved compet-
itive results compared to the state-of-the-art sys-
tems without any feature engineering.
A further research direction we are investi-
gating is exploitation of unlabeled texts. Semi-
supervised semantic role labeling methods have
been explored by (Collobert and Weston, 2008;
Deschacht and Moens, 2009; F¨urstenau and La-
pata, 2009), and they have achieved successful
outcomes. However, we believe that there is still
room for further improvement.
</bodyText>
<sectionHeader confidence="0.999643" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999923185185185">
Anders Bj¨orkelund, Love Hafdell, and Pierre Nugues.
2009. Multilingual semantic role labeling. In
CoNLL-2009.
Ronan Collobert and Jason Weston. 2008. A unified
architecture for natural language processing: Deep
neural networks with multitask learning. In ICML
2008.
Koby Crammer, Ofer Dekel, Joseph Keshet, Shai
Shalev-Shwartz, and Yoram Singer. 2006. Online
passive-aggressive algorithms. JMLR, 7:551–585.
Hal Daum´e III and Daniel Marcu. 2005. Learning
as search optimization: Approximate large margin
methods for structured prediction. In ICML-2005.
Koen Deschacht and Marie-Francine Moens. 2009.
Semi-supervised semantic role labeling using the la-
tent words language model. In EMNLP-2009.
Hagen F¨urstenau and Mirella Lapata. 2009. Graph
alignment for semi-supervised semantic role label-
ing. In EMNLP-2009.
Jan Hajiˇc, Massimiliano Ciaramita, Richard Johans-
son, Daisuke Kawahara, Maria Ant`onia Martf, Llufs
M`arquez, Adam Meyers, Joakim Nivre, Sebastian
Pad´o, Jan ˇStˇep´anek, Pavel Straˇn´ak, Mihai Surdeanu,
Nianwen Xue, and Yi Zhang. 2009. The CoNLL-
2009 shared task: Syntactic and semantic dependen-
cies in multiple languages. In CoNLL-2009, Boul-
der, Colorado, USA.
Richard Johansson and Pierre Nugues. 2008.
Dependency-based syntactic-semantic analysis
with propbank and nombank. In CoNLL-2008.
Jun’Ichi Kazama and Kentaro Torisawa. 2007. A new
perceptron algorithm for sequence labeling with
non-local features. In EMNLP-CoNLL 2007.
Ivan Meza-Ruiz and Sebastian Riedel. 2009a. Jointly
identifying predicates, arguments and senses using
markov logic. In HLT/NAACL-2009.
Ivan Meza-Ruiz and Sebastian Riedel. 2009b. Multi-
lingual semantic role labelling with markov logic.
In CoNLL-2009.
Sebastian Riedel and Ivan Meza-Ruiz. 2008. Collec-
tive semantic role labelling with markov logic. In
CoNLL-2008.
Mihai Surdeanu, Richard Johansson, Adam Mey-
ers, Llufs M`arquez, and Joakim Nivre. 2008. The
CoNLL-2008 shared task on joint parsing of syntac-
tic and semantic dependencies. In CoNLL-2008.
Synthia A. Thompson, Roger Levy, and Christopher D.
Manning. 2010. A generative model for semantic
role labeling. In Proceedings of the 48th Annual
Meeting of the Association of Computational Lin-
guistics (to appear).
Kristina Toutanova, Aria Haghighi, and Christopher D.
Manning. 2008. A global joint model for semantic
role labeling. Computational Linguistics, 34(2).
</reference>
<page confidence="0.998625">
102
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.861652">
<title confidence="0.9991625">A Structured Model for Joint Learning of Argument Roles and Predicate Senses</title>
<author confidence="0.996703">Yotaro Watanabe</author>
<affiliation confidence="0.9990855">Graduate School of Information Sciences Tohoku University</affiliation>
<address confidence="0.9944">6-6-05, Aramaki Aza Aoba, Aoba-ku, Sendai 980-8579, Japan</address>
<email confidence="0.978393">yotaro-w@ecei.tohoku.ac.jp</email>
<author confidence="0.911341">Masayuki Asahara Yuji Matsumoto</author>
<affiliation confidence="0.999431">Graduate School of Information Science Nara Institute of Science and Technology</affiliation>
<address confidence="0.9946945">8916-5 Takayama, Ikoma, Nara, 630-0192, Japan</address>
<abstract confidence="0.999730652173913">In predicate-argument structure analysis, it is important to capture non-local dependencies among arguments and interdependencies between the sense of a predicate and the semantic roles of its arguments. However, no existing approach explicitly handles both non-local dependencies and semantic dependencies between predicates and arguments. In this paper we propose a structured model that overcomes the limitation of existing approaches; the model captures both types of dependencies simultaneously by introducing four types of factors including a global factor type capturing non-local dependencies among arguments and a pairwise factor type capturing local dependencies between a predicate and an argument. In experiments the proposed model achieved competitive results compared to the stateof-the-art systems without applying any feature selection procedure.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Anders Bj¨orkelund</author>
<author>Love Hafdell</author>
<author>Pierre Nugues</author>
</authors>
<title>Multilingual semantic role labeling.</title>
<date>2009</date>
<booktitle>In CoNLL-2009.</booktitle>
<marker>Bj¨orkelund, Hafdell, Nugues, 2009</marker>
<rawString>Anders Bj¨orkelund, Love Hafdell, and Pierre Nugues. 2009. Multilingual semantic role labeling. In CoNLL-2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronan Collobert</author>
<author>Jason Weston</author>
</authors>
<title>A unified architecture for natural language processing: Deep neural networks with multitask learning.</title>
<date>2008</date>
<booktitle>In ICML</booktitle>
<marker>Collobert, Weston, 2008</marker>
<rawString>Ronan Collobert and Jason Weston. 2008. A unified architecture for natural language processing: Deep neural networks with multitask learning. In ICML 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Koby Crammer</author>
<author>Ofer Dekel</author>
<author>Joseph Keshet</author>
<author>Shai Shalev-Shwartz</author>
<author>Yoram Singer</author>
</authors>
<title>Online passive-aggressive algorithms.</title>
<date>2006</date>
<journal>JMLR,</journal>
<pages>7--551</pages>
<contexts>
<context position="8685" citStr="Crammer et al., 2006" startWordPosition="1420" endWordPosition="1423">(x, p, a)}. 99 can be easily extended to our structured model. That is, for each possible predicate sense p of the predicate, we provide N-best argument role assignments using three local factors FP, FA and FPA, and then add scores of the global factor FG, finally select the argmax from them. In this case, the argmax is selected from |Pl|N candidates. 2.3 Learning the Model For learning of the model, we borrow a fundamental idea of Kazama and Torisawa’s perceptron learning algorithm. However, we use a more sophisticated online-learning algorithm based on the Passive-Aggressive Algorithm (PA) (Crammer et al., 2006). For the sake of simplicity, we introduce some notations. We denote a predicate-argument structure y = (p, A), a local feature vector as 4bL(x, y) = 4bP(x,p) + ∑aCA{4bA(x, a) + 4bPA(x, p, a)} a feature vector coupling both local and global features as 4bL+G(x, y) = 4bL(x, y) + 4bG(x, p, A), the argmax using 4bL+G as ˆyL+G, the argmax using 4bL as ˆyL. Also, we use a loss function ρ(y, y&apos;), which is a cost function associated with y and y&apos;. The margin perceptron learning proposed by Kazama and Torisawa can be seen as an optimization with the following two constrains. (A) w·ΦL+G(x, y)−w·ΦL+G(x,</context>
</contexts>
<marker>Crammer, Dekel, Keshet, Shalev-Shwartz, Singer, 2006</marker>
<rawString>Koby Crammer, Ofer Dekel, Joseph Keshet, Shai Shalev-Shwartz, and Yoram Singer. 2006. Online passive-aggressive algorithms. JMLR, 7:551–585.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hal Daum´e</author>
<author>Daniel Marcu</author>
</authors>
<title>Learning as search optimization: Approximate large margin methods for structured prediction.</title>
<date>2005</date>
<booktitle>In ICML-2005.</booktitle>
<marker>Daum´e, Marcu, 2005</marker>
<rawString>Hal Daum´e III and Daniel Marcu. 2005. Learning as search optimization: Approximate large margin methods for structured prediction. In ICML-2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Koen Deschacht</author>
<author>Marie-Francine Moens</author>
</authors>
<title>Semi-supervised semantic role labeling using the latent words language model.</title>
<date>2009</date>
<booktitle>In EMNLP-2009.</booktitle>
<marker>Deschacht, Moens, 2009</marker>
<rawString>Koen Deschacht and Marie-Francine Moens. 2009. Semi-supervised semantic role labeling using the latent words language model. In EMNLP-2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hagen F¨urstenau</author>
<author>Mirella Lapata</author>
</authors>
<title>Graph alignment for semi-supervised semantic role labeling.</title>
<date>2009</date>
<booktitle>In EMNLP-2009.</booktitle>
<marker>F¨urstenau, Lapata, 2009</marker>
<rawString>Hagen F¨urstenau and Mirella Lapata. 2009. Graph alignment for semi-supervised semantic role labeling. In EMNLP-2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Hajiˇc</author>
<author>Massimiliano Ciaramita</author>
<author>Richard Johansson</author>
<author>Daisuke Kawahara</author>
<author>Maria Ant`onia Martf</author>
<author>Llufs M`arquez</author>
<author>Adam Meyers</author>
<author>Joakim Nivre</author>
<author>Sebastian Pad´o</author>
<author>Jan ˇStˇep´anek</author>
<author>Pavel Straˇn´ak</author>
<author>Mihai Surdeanu</author>
<author>Nianwen Xue</author>
<author>Yi Zhang</author>
</authors>
<title>The CoNLL2009 shared task: Syntactic and semantic dependencies in multiple languages. In</title>
<date>2009</date>
<booktitle>CoNLL-2009,</booktitle>
<location>Boulder, Colorado, USA.</location>
<marker>Hajiˇc, Ciaramita, Johansson, Kawahara, Martf, M`arquez, Meyers, Nivre, Pad´o, ˇStˇep´anek, Straˇn´ak, Surdeanu, Xue, Zhang, 2009</marker>
<rawString>Jan Hajiˇc, Massimiliano Ciaramita, Richard Johansson, Daisuke Kawahara, Maria Ant`onia Martf, Llufs M`arquez, Adam Meyers, Joakim Nivre, Sebastian Pad´o, Jan ˇStˇep´anek, Pavel Straˇn´ak, Mihai Surdeanu, Nianwen Xue, and Yi Zhang. 2009. The CoNLL2009 shared task: Syntactic and semantic dependencies in multiple languages. In CoNLL-2009, Boulder, Colorado, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Johansson</author>
<author>Pierre Nugues</author>
</authors>
<title>Dependency-based syntactic-semantic analysis with propbank and nombank.</title>
<date>2008</date>
<booktitle>In CoNLL-2008.</booktitle>
<contexts>
<context position="1932" citStr="Johansson and Nugues (2008)" startWordPosition="276" endWordPosition="279">ction Predicate-argument structure analysis is a process of assigning who does what to whom, where, when, etc. for each predicate. Arguments of a predicate are assigned particular semantic roles, such as Agent, Theme, Patient, etc. Lately, predicate-argument structure analysis has been regarded as a task of assigning semantic roles of arguments as well as word senses of a predicate (Surdeanu et al., 2008; Hajiˇc et al., 2009). Several researchers have paid much attention to predicate-argument structure analysis, and the following two important factors have been shown. Toutanova et al. (2008), Johansson and Nugues (2008), and Bj¨orkelund et al. (2009) presented importance of capturing non-local dependencies of core arguments in predicate-argument structure analysis. They used argument sequences tied with a predicate sense (e.g. AGENT-buy.01/ActivePATIENT) as a feature for the re-ranker of the system where predicate sense and argument role candidates are generated by their pipelined architecture. They reported that incorporating this type of features provides substantial gain of the system performance. The other factor is inter-dependencies between a predicate sense and argument roles, which relate to selectio</context>
<context position="12093" citStr="Johansson and Nugues, 2008" startWordPosition="2032" endWordPosition="2035">e use Semantic Labeled F1 for evaluation. For generating N-bests, we used the beamsearch algorithm, and the number of N-bests was set to N = 64. For learning of the joint model, the loss function ρ(yt, y&apos;) of the Passive-Aggressive Algorithm was set to the number of incorrect assignments of a predicate sense and its argument roles. Also, the number of iterations of the model used for testing was selected based on the performance on the development data. Table 1 shows the features used for the structured model. The global features used for FG are based on those used in (Toutanova et al., 2008; Johansson and Nugues, 2008), and the features &apos;The dataset consists of seven languages: Catalan, Chinese, Czech, English, German, Japanese and Spanish. ≥ P(y,ˆyL+G) wnew = arg min w/Efitn 100 FP Plemma of the predicate and predicate’s head, and ppos of the predicate Dependency label between the predicate and predicate’s head The concatenation of the dependency labels of the predicate’s dependents FA Plemma and ppos of the predicate, the predicate’s head, the argument candidate, and the argument’s head Plemma and ppos of the leftmost/rightmost dependent and leftmost/rightmost sibling The dependency label of predicate, ar</context>
</contexts>
<marker>Johansson, Nugues, 2008</marker>
<rawString>Richard Johansson and Pierre Nugues. 2008. Dependency-based syntactic-semantic analysis with propbank and nombank. In CoNLL-2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun’Ichi Kazama</author>
<author>Kentaro Torisawa</author>
</authors>
<title>A new perceptron algorithm for sequence labeling with non-local features.</title>
<date>2007</date>
<booktitle>In EMNLP-CoNLL</booktitle>
<contexts>
<context position="7871" citStr="Kazama and Torisawa, 2007" startWordPosition="1278" endWordPosition="1281">ructure with the other factors misses some core arguments, the global feature demands the model to fill the missing arguments. The numbers of factors for each factor type are: FP and FG are 1, FA and FPA are |A|. By integrating the all factors, the score function becomes s(p, A)ff = w · &apos;bP (x, p) + w · &apos;bG (x, p, A) + w ∑aEAl&apos;bA 2.2 Inference The crucial point of the model is how to deal with the global factor FG, because enumerating possible assignments is too costly. A number of methods have been proposed for the use of global features for linear models such as (Daum´e III and Marcu, 2005; Kazama and Torisawa, 2007). In this work, we use the approach proposed in (Kazama and Torisawa, 2007). Although the approach is proposed for sequence labeling tasks, it FG P FP FPA a( aZ a3 a4 ...... aN FA (x, a) + &apos;bPA(x, p, a)}. 99 can be easily extended to our structured model. That is, for each possible predicate sense p of the predicate, we provide N-best argument role assignments using three local factors FP, FA and FPA, and then add scores of the global factor FG, finally select the argmax from them. In this case, the argmax is selected from |Pl|N candidates. 2.3 Learning the Model For learning of the model, we </context>
</contexts>
<marker>Kazama, Torisawa, 2007</marker>
<rawString>Jun’Ichi Kazama and Kentaro Torisawa. 2007. A new perceptron algorithm for sequence labeling with non-local features. In EMNLP-CoNLL 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Meza-Ruiz</author>
<author>Sebastian Riedel</author>
</authors>
<title>Jointly identifying predicates, arguments and senses using markov logic.</title>
<date>2009</date>
<booktitle>In HLT/NAACL-2009.</booktitle>
<contexts>
<context position="14436" citStr="Meza-Ruiz and Riedel, 2009" startWordPosition="2392" endWordPosition="2395">2 79.50 76.96 85.88 84.49 78.64 78.32 79.21 ALL 80.75 79.55 77.20 85.94 84.97 79.62 78.69 79.29 Bj¨orkelund 80.80 80.01 78.60 85.41 85.63 79.71 76.30 79.91 Zhao 80.47 80.32 77.72 85.19 85.44 75.99 78.15 80.46 Meza-Ruiz 77.46 78.00 77.73 75.75 83.34 73.52 76.00 77.91 Table 2: Results on the CoNLL-2009 Shared Task dataset (Semantic Labeled F1). SENSE ARG FP+FA 89.65 72.20 FP+FA+FPA 89.78 72.74 FP+FA+FG 89.83 74.11 ALL 90.15 74.46 Table 3: Predicate sense disambiguation and argument role labeling results (average). used for FPA are inspired by formulae used in the MLN-based SRL systems, such as (Meza-Ruiz and Riedel, 2009b). We used the same feature templates for all languages. 3.2 Results Table 2 shows the results of the experiments, and also shows the results of the top 3 systems in the CoNLL-2009 Shared Task participants of the SRLonly system. By incorporating FPA, we achieved performance improvement for all languages. This results suggest that it is effective to capture local interdependencies between a predicate sense and one of its argument roles. Comparing the results with FP+FA and FP+FA+FG, incorporating FG also contributed performance improvements for all languages, especially the substantial F1 impr</context>
</contexts>
<marker>Meza-Ruiz, Riedel, 2009</marker>
<rawString>Ivan Meza-Ruiz and Sebastian Riedel. 2009a. Jointly identifying predicates, arguments and senses using markov logic. In HLT/NAACL-2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Meza-Ruiz</author>
<author>Sebastian Riedel</author>
</authors>
<title>Multilingual semantic role labelling with markov logic.</title>
<date>2009</date>
<booktitle>In CoNLL-2009.</booktitle>
<contexts>
<context position="14436" citStr="Meza-Ruiz and Riedel, 2009" startWordPosition="2392" endWordPosition="2395">2 79.50 76.96 85.88 84.49 78.64 78.32 79.21 ALL 80.75 79.55 77.20 85.94 84.97 79.62 78.69 79.29 Bj¨orkelund 80.80 80.01 78.60 85.41 85.63 79.71 76.30 79.91 Zhao 80.47 80.32 77.72 85.19 85.44 75.99 78.15 80.46 Meza-Ruiz 77.46 78.00 77.73 75.75 83.34 73.52 76.00 77.91 Table 2: Results on the CoNLL-2009 Shared Task dataset (Semantic Labeled F1). SENSE ARG FP+FA 89.65 72.20 FP+FA+FPA 89.78 72.74 FP+FA+FG 89.83 74.11 ALL 90.15 74.46 Table 3: Predicate sense disambiguation and argument role labeling results (average). used for FPA are inspired by formulae used in the MLN-based SRL systems, such as (Meza-Ruiz and Riedel, 2009b). We used the same feature templates for all languages. 3.2 Results Table 2 shows the results of the experiments, and also shows the results of the top 3 systems in the CoNLL-2009 Shared Task participants of the SRLonly system. By incorporating FPA, we achieved performance improvement for all languages. This results suggest that it is effective to capture local interdependencies between a predicate sense and one of its argument roles. Comparing the results with FP+FA and FP+FA+FG, incorporating FG also contributed performance improvements for all languages, especially the substantial F1 impr</context>
</contexts>
<marker>Meza-Ruiz, Riedel, 2009</marker>
<rawString>Ivan Meza-Ruiz and Sebastian Riedel. 2009b. Multilingual semantic role labelling with markov logic. In CoNLL-2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Riedel</author>
<author>Ivan Meza-Ruiz</author>
</authors>
<title>Collective semantic role labelling with markov logic.</title>
<date>2008</date>
<booktitle>In CoNLL-2008.</booktitle>
<contexts>
<context position="2700" citStr="Riedel and Meza-Ruiz (2008" startWordPosition="388" endWordPosition="391">lysis. They used argument sequences tied with a predicate sense (e.g. AGENT-buy.01/ActivePATIENT) as a feature for the re-ranker of the system where predicate sense and argument role candidates are generated by their pipelined architecture. They reported that incorporating this type of features provides substantial gain of the system performance. The other factor is inter-dependencies between a predicate sense and argument roles, which relate to selectional preference, and motivated us to jointly identify a predicate sense and its argument roles. This type of dependencies has been explored by Riedel and Meza-Ruiz (2008; 2009b; 2009a), all of which use Markov Logic Networks (MLN). The work uses the global formulae that have atoms in terms of both a predicate sense and each of its argument roles, and the system identifies predicate senses and argument roles simultaneously. Ideally, we want to capture both types of dependencies simultaneously. The former approaches can not explicitly include features that capture inter-dependencies between a predicate sense and its argument roles. Though these are implicitly incorporated by re-ranking where the most plausible assignment is selected from a small subset of predi</context>
</contexts>
<marker>Riedel, Meza-Ruiz, 2008</marker>
<rawString>Sebastian Riedel and Ivan Meza-Ruiz. 2008. Collective semantic role labelling with markov logic. In CoNLL-2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mihai Surdeanu</author>
<author>Richard Johansson</author>
<author>Adam Meyers</author>
<author>Llufs M`arquez</author>
<author>Joakim Nivre</author>
</authors>
<title>The CoNLL-2008 shared task on joint parsing of syntactic and semantic dependencies.</title>
<date>2008</date>
<booktitle>In CoNLL-2008.</booktitle>
<marker>Surdeanu, Johansson, Meyers, M`arquez, Nivre, 2008</marker>
<rawString>Mihai Surdeanu, Richard Johansson, Adam Meyers, Llufs M`arquez, and Joakim Nivre. 2008. The CoNLL-2008 shared task on joint parsing of syntactic and semantic dependencies. In CoNLL-2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Synthia A Thompson</author>
<author>Roger Levy</author>
<author>Christopher D Manning</author>
</authors>
<title>A generative model for semantic role labeling.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association of Computational Linguistics</booktitle>
<note>(to appear).</note>
<contexts>
<context position="3600" citStr="Thompson et al. (2010)" startWordPosition="534" endWordPosition="537">capture both types of dependencies simultaneously. The former approaches can not explicitly include features that capture inter-dependencies between a predicate sense and its argument roles. Though these are implicitly incorporated by re-ranking where the most plausible assignment is selected from a small subset of predicate and argument candidates, which are generated independently. On the other hand, it is difficult to deal with core argument features in MLN. Because the number of core arguments varies with the role assignments, this type of features cannot be expressed by a single formula. Thompson et al. (2010) proposed a generative model that captures both predicate senses and its argument roles. However, the first-order markov assumption of the model eliminates ability to capture non-local dependencies among arguments. Also, generative models are in general inferior to discriminatively trained linear or log98 Proceedings of the ACL 2010 Conference Short Papers, pages 98–102, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics Figure 1: Undirected graphical model representation of the structured model linear models. In this paper we propose a structured model that ove</context>
</contexts>
<marker>Thompson, Levy, Manning, 2010</marker>
<rawString>Synthia A. Thompson, Roger Levy, and Christopher D. Manning. 2010. A generative model for semantic role labeling. In Proceedings of the 48th Annual Meeting of the Association of Computational Linguistics (to appear).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Aria Haghighi</author>
<author>Christopher D Manning</author>
</authors>
<title>A global joint model for semantic role labeling.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>2</issue>
<contexts>
<context position="1903" citStr="Toutanova et al. (2008)" startWordPosition="272" endWordPosition="275">tion procedure. 1 Introduction Predicate-argument structure analysis is a process of assigning who does what to whom, where, when, etc. for each predicate. Arguments of a predicate are assigned particular semantic roles, such as Agent, Theme, Patient, etc. Lately, predicate-argument structure analysis has been regarded as a task of assigning semantic roles of arguments as well as word senses of a predicate (Surdeanu et al., 2008; Hajiˇc et al., 2009). Several researchers have paid much attention to predicate-argument structure analysis, and the following two important factors have been shown. Toutanova et al. (2008), Johansson and Nugues (2008), and Bj¨orkelund et al. (2009) presented importance of capturing non-local dependencies of core arguments in predicate-argument structure analysis. They used argument sequences tied with a predicate sense (e.g. AGENT-buy.01/ActivePATIENT) as a feature for the re-ranker of the system where predicate sense and argument role candidates are generated by their pipelined architecture. They reported that incorporating this type of features provides substantial gain of the system performance. The other factor is inter-dependencies between a predicate sense and argument ro</context>
<context position="12064" citStr="Toutanova et al., 2008" startWordPosition="2028" endWordPosition="2031">rgument role labeling. We use Semantic Labeled F1 for evaluation. For generating N-bests, we used the beamsearch algorithm, and the number of N-bests was set to N = 64. For learning of the joint model, the loss function ρ(yt, y&apos;) of the Passive-Aggressive Algorithm was set to the number of incorrect assignments of a predicate sense and its argument roles. Also, the number of iterations of the model used for testing was selected based on the performance on the development data. Table 1 shows the features used for the structured model. The global features used for FG are based on those used in (Toutanova et al., 2008; Johansson and Nugues, 2008), and the features &apos;The dataset consists of seven languages: Catalan, Chinese, Czech, English, German, Japanese and Spanish. ≥ P(y,ˆyL+G) wnew = arg min w/Efitn 100 FP Plemma of the predicate and predicate’s head, and ppos of the predicate Dependency label between the predicate and predicate’s head The concatenation of the dependency labels of the predicate’s dependents FA Plemma and ppos of the predicate, the predicate’s head, the argument candidate, and the argument’s head Plemma and ppos of the leftmost/rightmost dependent and leftmost/rightmost sibling The depe</context>
</contexts>
<marker>Toutanova, Haghighi, Manning, 2008</marker>
<rawString>Kristina Toutanova, Aria Haghighi, and Christopher D. Manning. 2008. A global joint model for semantic role labeling. Computational Linguistics, 34(2).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>