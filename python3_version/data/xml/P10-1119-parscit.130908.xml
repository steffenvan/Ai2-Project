<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000004">
<title confidence="0.997331">
A Rational Model of Eye Movement Control in Reading
</title>
<author confidence="0.995615">
Klinton Bicknell and Roger Levy
</author>
<affiliation confidence="0.9988">
Department of Linguistics
University of California, San Diego
</affiliation>
<address confidence="0.720276">
9500 Gilman Dr, La Jolla, CA 92093-0108
</address>
<email confidence="0.998949">
{kbicknell,rlevy}@ling.ucsd.edu
</email>
<sectionHeader confidence="0.99739" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999950041666667">
A number of results in the study of real-
time sentence comprehension have been
explained by computational models as re-
sulting from the rational use of probabilis-
tic linguistic information. Many times,
these hypotheses have been tested in read-
ing by linking predictions about relative
word difficulty to word-aggregated eye
tracking measures such as go-past time. In
this paper, we extend these results by ask-
ing to what extent reading is well-modeled
as rational behavior at a finer level of anal-
ysis, predicting not aggregate measures,
but the duration and location of each fix-
ation. We present a new rational model of
eye movement control in reading, the cen-
tral assumption of which is that eye move-
ment decisions are made to obtain noisy
visual information as the reader performs
Bayesian inference on the identities of the
words in the sentence. As a case study,
we present two simulations demonstrating
that the model gives a rational explanation
for between-word regressions.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999953927272728">
The language processing tasks of reading, listen-
ing, and even speaking are remarkably difficult.
Good performance at each one requires integrat-
ing a range of types of probabilistic information
and making incremental predictions on the ba-
sis of noisy, incomplete input. Despite these re-
quirements, empirical work has shown that hu-
mans perform very well (e.g., Tanenhaus, Spivey-
Knowlton, Eberhard, &amp; Sedivy, 1995). Sophisti-
cated models have been developed that explain
many of these effects using the tools of com-
putational linguistics and large-scale corpora to
make normative predictions for optimal perfor-
mance in these tasks (Genzel &amp; Charniak, 2002,
2003; Keller, 2004; Levy &amp; Jaeger, 2007; Jaeger,
2010). To the extent that the behavior of these
models looks like human behavior, it suggests that
humans are making rational use of all the infor-
mation available to them in language processing.
In the domain of incremental language compre-
hension, especially, there is a substantial amount
of computational work suggesting that humans be-
have rationally (e.g., Jurafsky, 1996; Narayanan &amp;
Jurafsky, 2001; Levy, 2008; Levy, Reali, &amp; Grif-
fiths, 2009). Most of this work has taken as its
task predicting the difficulty of each word in a sen-
tence, a major result being that a large component
of the difficulty of a word appears to be a function
of its probability in context (Hale, 2001; Smith &amp;
Levy, 2008). Much of the empirical basis for this
work comes from studying reading, where word
difficulty can be related to the amount of time
that a reader spends on a particular word. To re-
late these predictions about word difficulty to the
data obtained in eye tracking experiments, the eye
movement record has been summarized through
word aggregate measures, such as the average du-
ration of the first fixation on a word, or the amount
of time between when a word is first fixated and
when the eyes move to its right (‘go-past time’).
It is important to note that this notion of word
difficulty is an abstraction over the actual task of
reading, which is made up of more fine-grained
decisions about how long to leave the eyes in
their current position, and where to move them
next, producing the series of relatively stable pe-
riods (fixations) and movements (saccades) that
characterize the eye tracking record. While there
has been much empirical work on reading at
this fine-grained scale (see Rayner, 1998 for an
overview), and there are a number of successful
models (Reichle, Pollatsek, &amp; Rayner, 2006; En-
gbert, Nuthmann, Richter, &amp; Kliegl, 2005), little
is known about the extent to which human read-
ing behavior appears to be rational at this finer
</bodyText>
<page confidence="0.950388">
1168
</page>
<note confidence="0.9423455">
Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1168–1178,
Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999579269230769">
grained scale. In this paper, we present a new ratio-
nal model of eye movement control in reading, the
central assumption of which is that eye movement
decisions are made to obtain noisy visual informa-
tion, which the reader uses in Bayesian inference
about the form and structure of the sentence. As a
case study, we show that this model gives a ratio-
nal explanation for between-word regressions.
In Section 2, we briefly describe the leading
models of eye movements in reading, and in Sec-
tion 3, we describe how these models account for
between-word regressions and the intuition behind
our model’s account of them. Section 4 describes
the model and its implementation and Sections 5–
6 describe two simulations we performed with the
model comparing behavioral policies that make re-
gressions to those that do not. In Simulation 1, we
show that specific regressive policies outperform
specific non-regressive policies, and in Simulation
2, we use optimization to directly find optimal
policies for three performance measures. The re-
sults show that the regressive policies outperform
non-regressive policies across a wide range of per-
formance measures, demonstrating that our model
predicts that making between-word regressions is
a rational strategy for reading.
</bodyText>
<sectionHeader confidence="0.610019" genericHeader="method">
2 Models of eye movements in reading
</sectionHeader>
<bodyText confidence="0.999989742424243">
The two most successful models of eye move-
ments in reading are E-Z Reader (Reichle, Pollat-
sek, Fisher, &amp; Rayner, 1998; Reichle et al., 2006)
and SWIFT (Engbert, Longtin, &amp; Kliegl, 2002;
Engbert et al., 2005). Both of these models charac-
terize the problem of reading as one of word iden-
tification. In E-Z Reader, for example, the system
identifies each word in the sentence serially, mov-
ing attention to the next word in the sentence only
after processing the current word is complete, and
(to slightly oversimplify), the eyes then follow the
attentional shifts at some lag. SWIFT works simi-
larly, but with the main difference being that pro-
cessing and attention are distributed over multiple
words, such that adjacent words can be identified
in parallel. While both of these models provide a
good fit to eye tracking data from reading, neither
model asks the higher level question of what a ra-
tional solution to the problem would look like.
The first model to ask this question, Mr. Chips
(Legge, Klitz, &amp; Tjan, 1997; Legge, Hooven,
Klitz, Mansfield, &amp; Tjan, 2002), predicts the op-
timal sequence of saccade targets to read a text
based on a principle of minimizing the expected
entropy in the distribution over identities of the
current word. Unfortunately, however, the Mr.
Chips model simplifies the problem of reading in
a number of ways: First, it uses a unigram model
as its language model, and thus fails to use any
information in the linguistic context to help with
word identification. Second, it only moves on to
the next word after unambiguous identification of
the current word, whereas there is experimental
evidence that comprehenders maintain some un-
certainty about the word identities. In other work,
we have extended the Mr. Chips model to remove
these two limitations, and show that the result-
ing model more closely matches human perfor-
mance (Bicknell &amp; Levy, 2010). The larger prob-
lem, however, is that each of these models uses
an unrealistic model of visual input, which obtains
absolute knowledge of the characters in its visual
window. Thus, there is no reason for the model to
spend longer on one fixation than another, and the
model only makes predictions for where saccades
are targeted, and not how long fixations last.
Reichle and Laurent (2006) presented a rational
model that overcame the limitations of Mr. Chips
to produce predictions for both fixation durations
and locations, focusing on the ways in which eye
movement behavior is an adaptive response to the
particular constraints of the task of reading. Given
this focus, Reichle and Laurent used a very simple
word identification function, for which the time re-
quired to identify a word was a function only of its
length and the relative position of the eyes. In this
paper, we present another rational model of eye
movement control in reading that, like Reichle and
Laurent, makes predictions for fixation durations
and locations, but which focuses instead on the
dynamics of word identification at the core of the
task of reading. Specifically, our model identifies
the words in a sentence by performing Bayesian
inference combining noisy input from a realistic
visual model with a language model that takes
context into account.
</bodyText>
<sectionHeader confidence="0.94206" genericHeader="method">
3 Explaining between-word regressions
</sectionHeader>
<bodyText confidence="0.998573166666667">
In this paper, we use our model to provide a
novel explanation for between-word regressive
saccades. In reading, about 10–15% of saccades
are regressive – movements from right-to-left (or
to previous lines). To understand how models
such as E-Z Reader or SWIFT account for re-
</bodyText>
<page confidence="0.993604">
1169
</page>
<bodyText confidence="0.999991244444445">
gressive saccades to previous words, recall that
the system identifies words in the sentence (gen-
erally) left to right, and that identification of a
word in these models takes a certain amount of
time and then is completed. In such a setup, why
should the eyes ever move backwards? Three ma-
jor answers have been put forward. One possibil-
ity given by E-Z Reader is as a response to over-
shoot; i.e., the eyes move backwards to a previ-
ous word because they accidentally landed fur-
ther forward than intended due to motor error.
Such an explanation could only account for small
between-word regressions, of about the magni-
tude of motor error. The most recent version,
E-Z Reader 10 (Reichle, Warren, &amp; McConnell,
2009), has a new component that can produce
longer between-word regressions. Specifically, the
model includes a flag for postlexical integration
failure, that – when triggered – will instruct the
model to produce a between-word regression to
the site of the failure. That is, between-word re-
gressions in E-Z Reader 10 can arise because of
postlexical processes external to the model’s main
task of word identification. A final explanation for
between-word regressions, which arises as a result
of normal processes of word identification, comes
from the SWIFT model. In the SWIFT model, the
reader can fail to identify a word but move past
it and continue reading. In these cases, there is
a chance that the eyes will at some point move
back to this unidentified word to identify it. From
the present perspective, however, it is unclear how
it could be rational to move past an unidentified
word and decide to revisit it only much later.
Here, we suggest a new explanation for
between-word regressions that arises as a result
of word identification processes (unlike that of
E-Z Reader) and can be understood as rational
(unlike that of SWIFT). Whereas in SWIFT and
E-Z Reader, word recognition is a process that
takes some amount of time and is then ‘com-
pleted’, some experimental evidence suggests that
word recognition may be best thought of as a
process that is never ‘completed’, as comprehen-
ders appear to both maintain uncertainty about the
identity of previous input and to update that uncer-
tainty as more information is gained about the rest
of the sentence (Connine, Blasko, &amp; Hall, 1991;
Levy, Bicknell, Slattery, &amp; Rayner, 2009). Thus, it
is possible that later parts of a sentence can cause
a reader’s confidence in the identity of the previ-
ous regions to fall. In these cases, a rational way to
respond might be to make a between-word regres-
sive saccade to get more visual information about
the (now) low confidence previous region.
To illustrate this idea, consider the case of a lan-
guage composed of just two strings, AB and BA,
and assume that the eyes can only get noisy in-
formation about the identity of one character at a
time. After obtaining a little information about the
identity of the first character, the reader may be
reasonably confident that its identity is A and move
on to obtaining visual input about the second char-
acter. If the first noisy input about the second char-
acter also indicates that it is probably A, then the
normative probability that the first character is A
(and thus a rational reader’s confidence in its iden-
tity) will fall. This simple example just illustrates
the point that if a reader is combining noisy vi-
sual information with a language model, then con-
fidence in previous regions will sometimes fall.
There are two ways that a rational agent might
deal with this problem. The first option would be
to reach a higher level of confidence in the iden-
tity of each word before moving on to the right,
i.e., slowing down reading left-to-right to prevent
having to make right-to-left regressions. The sec-
ond option is to read left-to-right relatively more
quickly, and then make occasional right-to-left re-
gressions in the cases where probability in pre-
vious regions falls. In this paper, we present two
simulations suggesting that when using a rational
model to read natural language, the best strate-
gies for coping with the problem of confidence
about previous regions dropping – for any trade-
off between speed and accuracy – involve making
between-word regressions. In the next section, we
present the details of our model of reading and its
implementation, and then we present our two sim-
ulations in the sections following.
</bodyText>
<sectionHeader confidence="0.843118" genericHeader="method">
4 Reading as Bayesian inference
</sectionHeader>
<bodyText confidence="0.9988004">
At its core, the framework we are proposing is one
of reading as Bayesian inference. Specifically, the
model begins reading with a prior distribution over
possible identities of a sentence given by its lan-
guage model. On the basis of that distribution, the
model decides whether or not to move its eyes (and
if so where to move them to) and obtains noisy
visual input about the sentence at the eyes’ posi-
tion. That noisy visual input then gives the likeli-
hood term in a Bayesian belief update, where the
</bodyText>
<page confidence="0.983487">
1170
</page>
<bodyText confidence="0.999983063829787">
model’s prior distribution over the identity of the
sentence given the language model is updated to a
posterior distribution taking into account both the
language model and the visual input obtained thus
far. On the basis of that new distribution, the model
again selects an action and the cycle repeats.
This framework is unique among models of eye
movement control in reading (except Mr. Chips)
in having a fully explicit model of how visual in-
put is used to discriminate word identity. This ap-
proach stands in sharp contrast to other models,
which treat the time course of word identifica-
tion as an exogenous function of other influenc-
ing factors (such as word length, frequency, and
predictability). The hope in our approach is that
the influence of these key factors on the eye move-
ment record will fall out as a natural consequence
of rational behavior itself. For example, it is well
known that the higher the conditional probabil-
ity of a word given preceding material, the more
rapidly that word is read (Boston, Hale, Kliegl,
Patil, &amp; Vasishth, 2008; Demberg &amp; Keller, 2008;
Ehrlich &amp; Rayner, 1981; Smith &amp; Levy, 2008).
E-Z Reader and SWIFT incorporate this finding by
specifying a dependency on word predictability in
the exogenous function determining word process-
ing time. In our framework, in contrast, we would
expect such an effect to emerge as a byproduct of
Bayesian inference: words with high prior proba-
bility (conditional on preceding fixations) will re-
quire less visual input to be reliably identified.
An implemented model in this framework must
formalize a number of pieces of the reading prob-
lem, including the possible actions available to the
reader and their consequences, the nature of vi-
sual input, a means of combining visual input with
prior expectations about sentence form and struc-
ture, and a control policy determining how the
model will choose actions on the basis of its poste-
rior distribution over the identities of the sentence.
In the remainder of this section, we present these
details of the formalization of the reading problem
we used for the simulations reported in this paper:
actions (4.1), visual input (4.2), formalization of
the Bayesian inference problem (4.3), control pol-
icy (4.4), and finally, implementation of the model
using weighted finite state automata (4.5).
</bodyText>
<subsectionHeader confidence="0.98542">
4.1 Formal problem of reading: Actions
</subsectionHeader>
<bodyText confidence="0.99998112">
For our model, we assume a series of discrete
timesteps, and on each time step, the model first
obtains visual input around the current location
of the eyes, and then chooses between three ac-
tions: (a) continuing to fixate the currently fixated
position, (b) initiating a saccade to a new posi-
tion, or (c) stopping reading of the sentence. If
on the ith timestep, the model chooses option (a),
the timestep advances to i + 1 and another sam-
ple of visual input is obtained around the current
position. If the model chooses option (c), the read-
ing immediately ends. If a saccade is initiated (b),
there is a lag of two timesteps, roughly represent-
ing the time required to plan and execute a sac-
cade, during which the model again obtains visual
input around the current position and then the eyes
move – with some motor error – toward the in-
tended target ti, landing on position Ei. On the next
time step, visual input is obtained around Ei and
another decision is made. The motor error for sac-
cades follows the form of random error used by all
major models of eye movements in reading: the
landing position &amp; is normally distributed around
the intended target ti with standard deviation given
by a linear function of the intended distance1
</bodyText>
<equation confidence="0.545215">
4 ∼ N (ti,(δ0 + δ1|ti − i−1|)2) (1)
</equation>
<bodyText confidence="0.998459">
for some linear coefficients δ0 and δ1. In the ex-
periments reported in this paper, we follow the
SWIFT model in using δ0 = 0.87,δ1 = 0.084.
</bodyText>
<subsectionHeader confidence="0.983967">
4.2 Noisy visual input
</subsectionHeader>
<bodyText confidence="0.911586571428572">
As stated earlier, the role of noisy visual input in
our model is as the likelihood term in a Bayesian
inference about sentence form and identity. There-
fore, if we denote the input obtained thus far from
a sentence as I, all the information pertinent to
the reader’s inferences can be encapsulated in the
form p(I|w) for possible sentences w. We assume
that the inputs deriving from each character posi-
tion are conditionally independent given sentence
identity, so that if wj denotes letter j of the sen-
tence and I(j) denotes the component of visual
input associated with that letter, then we can de-
compose p(I|w) as jIj p(I(j)|wj). For simplicity,
we assume that each character is either a lowercase
letter or a space. The visual input obtained from
an individual fixation can thus be summarized as
a vector of likelihoods p(I(j)|wj), as shown in
1In the terminology of the literature, the model has only
random motor error (variance), not systematic error (bias).
Following Engbert and Krügel (2010), systematic error may
arise from Bayesian estimation of the best saccade distance.
</bodyText>
<page confidence="0.96334">
1171
</page>
<figure confidence="0.985177045454545">
*
. . . a s a c a t s a t a t a t ...
�
� � � � � � � � � � � � �
.04
�
� � � � � � � � � � � � �
.04
�
� �
.�
.�
. � �
.04 � �
.04 � � �
.�
.�
.
0
�a �
� c �
� �
� .�
� .�
� � . � �
� �
�s �
� t �
� �
� �
� .�
� .�
.
� 0 �
�0 �
� �
� .�
� .�
� �
� . �
� �0 � �
� �
�0 �
� �
� .�
� .�
.
1
� �
.03
� �� �
� �� �
� �
.� �
.� �
.
.25
.01
.07
.01
.
.
.
.03
.003
.
..
0
� �
� �
� �
� �
� �
� �
� �
� �
� �
� �
� �
� �
� �
� �
.02
0
�
.003�
.005 � �� �
.� �
.� �
. � �
� �
.21 .02 0 .07
.08
�
� �
.�
.�
. � �
.02 � �
.05 � � �
.�
.�
.
0
� 0 �
�0 �
� �
� .�
� .�
� �
� . �
� �0 � �
� �
�0 �
� �
� .�
� .�
.
1
.10
�
� � � � � � � � � � � � �
.04
.04
.
.
.
.04
.04
.
..
0
</figure>
<equation confidence="0.996441907407408">
� � 0 � �
.08
.02 � �0 � �
� � � �
.� � .� �
.� � .� �
. � �.04 � �0
.03 � � �0 � �
� � �
� � � �
.� � .� �
.� � .� �
. .
0 1
� �0� �
.15
.07 � �0 � �
� � � �
.� � .� �
.� � .� �
. � �.01 � �0
.01 � � �0 � �
� � �
� � � �
.� � .� �
.� � .� �
. .
0 1
� � 0 � �
.05
.01 � �0 � �
� � � �
.� � .� �
.� � .� �
. � �.002 � �0
.05 � � �0 � �
� � �
� � � �
.� � .� �
.� � .� �
. .
0 1
� � 0 � �
.04
.04 � �0 � �
� � � �
.� � .� �
.� � .� �
. � �.04 � �0
.04 � � �0 � �
� � �
� � � �
.� � .� �
0 J 1
</equation>
<figureCaption confidence="0.968945">
Figure 1: Peripheral and foveal visual input in the model. The asymmetric Gaussian curve indicates
declining perceptual acuity centered around the fixation point (marked by *). The vector underneath each
letter position denotes the likelihood p(Z(j)|wj) for each possible letter wj, taken from a single input
sample with A = 1/-\/3 (see vector at the left edge of the figure for key, and Section 4.2). In peripheral
vision, the letter/whitespace distinction is veridical, but no information about letter identity is obtained.
Note in this particular sample, input from the fixated character and the following one is rather inaccurate.
Figure 1. As in the real visual system, our vi-
</figureCaption>
<bodyText confidence="0.984425545454545">
sual acuity function decreases with retinal eccen-
tricity; we follow the SWIFT model in assuming
that the spatial distribution of visual processing
rate follows an asymmetric Gaussian with σL =
2.41,σR = 3.74, which we discretize into process-
ing rates for each character position. If ε denotes a
character’s eccentricity in characters from the cen-
ter of fixation, then the proportion of the total pro-
cessing rate at that eccentricity λ(ε) is given by
integrating the asymmetric Gaussian over a char-
acter width centered on that position,
</bodyText>
<equation confidence="0.639801">
x &gt; 0
</equation>
<bodyText confidence="0.975787">
where the normalization constant Z is given by
</bodyText>
<equation confidence="0.975834">
�π
Z = 2 (σL + σR).
</equation>
<bodyText confidence="0.99973975">
From this distribution, we derive two types of vi-
sual input, peripheral input giving word boundary
information and foveal input giving information
about letter identity.
</bodyText>
<subsubsectionHeader confidence="0.529876">
4.2.1 Peripheral visual input
</subsubsectionHeader>
<bodyText confidence="0.999990428571429">
In our model, any eccentricity with a processing
rate proportion λ(ε) at least 0.5% of the rate pro-
portion for the centrally fixated character (ε E
[−7,12]), yields peripheral visual input, defined
as veridical word boundary information indicat-
ing whether each character is a letter or a space.
This roughly corresponds to empirical estimates
that humans obtain useful information in reading
from about 19 characters, more from the right of
fixation than the left (Rayner, 1998). Hence in Fig-
ure 1, for example, left-peripheral visual input can
be represented as veridical knowledge of the initial
whitespace (denoted ), and a uniform distribution
over the 26 letters of English for the letter a.
</bodyText>
<subsectionHeader confidence="0.488358">
4.2.2 Foveal visual input
</subsectionHeader>
<bodyText confidence="0.9999744">
In addition, for those eccentricities with a process-
ing rate proportion λ(ε) that is at least 1% of the
total processing rate (ε E [−5,8]) the model re-
ceives foveal visual input, defined only for letters2
to give noisy information about the letter’s iden-
tity. This threshold of 1% roughly corresponds to
estimates that readers get information useful for
letter identification from about 4 characters to the
left and 8 to the right of fixation (Rayner, 1998).
In our model, each letter is equally confusable
with all others, following Norris (2006, 2009),
but ignoring work on letter confusability (which
could be added to future model revisions; Engel,
Dougherty, &amp; Jones, 1973; Geyer, 1977). Visual
information about each character is obtained by
sampling. Specifically, we represent each letter as
a 26-dimensional vector, where a single element
is 1 and the other 25 are zeros, and given this rep-
resentation, foveal input for a letter is given as a
sample from a 26-dimensional Gaussian with a
</bodyText>
<footnote confidence="0.886378">
2For white space, the model is already certain of the iden-
tity because of peripheral input.
</footnote>
<equation confidence="0.897666833333333">
λ(ε) =
IS ε+.5 1 x2
−.5 Z ( )
σL, x &lt; 0
exp - 2σ2 dx, σ = σR,
04 .060.05
.01 .01 0 .05
.03
.07
.02 .12 0 .05
0
0 0 1 L 0
</equation>
<page confidence="0.89494">
1172
</page>
<bodyText confidence="0.999918642857143">
mean equal to the letter’s true identity and a di-
agonal covariance matrix Σ(E) = X(E)−1/2I. It is
relatively straightforward to show that under these
conditions, if we take the processing rate to be the
expected change in log-odds of the true letter iden-
tity relative to any other that a single sample brings
about, then the rate equals X(E). We scale the over-
all processing rate by multiplying each rate by Λ.
For the experiments in this paper, we set Λ = 4.
For each fixation, we sample independently from
the appropriate distribution for each character po-
sition and then compute the likelihood given each
possible letter, as illustrated in the non-peripheral
region of Figure 1.
</bodyText>
<subsectionHeader confidence="0.991397">
4.3 Inference about sentence identity
</subsectionHeader>
<bodyText confidence="0.999988333333333">
Given the visual input and a language model, in-
ferences about the identity of the sentence w can
be made by standard Bayesian inference, where
the prior is given by the language model and the
likelihood is a function of the total visual input ob-
tained from the first to the ith timestep Zi1,
</bodyText>
<equation confidence="0.999580666666667">
p(w|Zi1) = p(w)p(Zitlw) (2)
∑(w�)p(Z1iIw�)
w�
</equation>
<bodyText confidence="0.99988575">
If we let Z(j) denote the input received about char-
acter position j and let wj denote the jth character
in sentence identity w, then the likelihood can be
broken down by character position as
</bodyText>
<equation confidence="0.542434">
p(Zi1(j)|wj)
</equation>
<bodyText confidence="0.999854666666667">
where n is the final character about which there is
any visual input. Similarly, we can decompose this
into the product of the likelihoods of each sample
</bodyText>
<equation confidence="0.92236">
p(Zt(j)|wj). (3)
</equation>
<bodyText confidence="0.988942666666667">
If the eccentricity of the jth character on the tth
timestep Etj is outside of foveal input or the char-
acter is a space, the inner term is 0 or 1. If the sam-
ple was from a letter in foveal input E t j E [−5,8], it
is the probability of sampling Zt(j) from the mul-
tivariate Gaussian N(wj,ΛΣ(Etj)).
</bodyText>
<subsectionHeader confidence="0.999529">
4.4 Control policy
</subsectionHeader>
<bodyText confidence="0.999446">
The model uses a simple policy to decide between
actions based on the marginal probability m of the
</bodyText>
<figure confidence="0.9998995">
(a) m = [.6,.7,.6,.4,.3,.6]: Keep fixating (3)
(b) m = [.6,.4,.9,.4,.3,.6]: Move back (to 2)
(c) m = [.6,.7,.9,.4,.3,.6]: Move forward (to 6)
(d) m = [.6,.7,.9,.8,.7,.7]: Stop reading
</figure>
<figureCaption confidence="0.996612">
Figure 2: Values of m for a 6 character sentence
</figureCaption>
<bodyText confidence="0.958304260869565">
under which a model fixating position 3 would
take each of its four actions, if a = .7 and P = .5.
most likely character c in position j,
Intuitively, a high value of m means that the model
is relatively confident about the character’s iden-
tity, and a low value that it is relatively uncertain.
Given the values of this statistic, our model de-
cides between four possible actions, as illustrated
in Figure 2. If the value of this statistic for the cur-
rent position of the eyes m(�i) is less than a pa-
rameter a, the model chooses to continue fixating
the current position (2a). Otherwise, if the value
of m(j) is less than P for some leftward position
j &lt; Ei, the model initiates a saccade to the closest
such position (2b). If m(j) &gt; P for all j &lt; Ei, then
the model initiates a saccade to n characters past
the closest position to the right j &gt; Ei for which
m(j) &lt; a (2c).3 Finally, if no such positions exist
to the right, the model stops reading the sentence
(2d). Intuitively, then, the model reads by making
a rightward sweep to bring its confidence in each
character up to a, but pauses to move left if confi-
dence in a previous character falls below P.
</bodyText>
<subsectionHeader confidence="0.999458">
4.5 Implementation with wFSAs
</subsectionHeader>
<bodyText confidence="0.999901166666667">
This model can be efficiently and simply im-
plemented using weighted finite-state automata
(wFSAs; Mohri, 1997) as follows: First, we be-
gin with a wFSA representation of the language
model, where each arc emits a single character (or
is an epsilon-transition emitting nothing). To per-
form belief update given a new visual input, we
create a new wFSA to represent the likelihood of
each character from the sample. Specifically, this
wFSA has only a single chain of states, where,
e.g., the first and second state in the chain are con-
nected by 27 (or fewer) arcs, which emit each of
</bodyText>
<footnote confidence="0.989417333333333">
3The role of n is to ensure that the model does not cen-
ter its visual field on the first uncertain character. We did not
attempt to optimize this parameter, but fixed n at 2.
</footnote>
<equation confidence="0.963095866666666">
n
∏
j=1
p(Zi1|w) =
i
∏
t=1
p(Zi1|w) =
n
∏
j=1
m(j) = max p(wn = c|Zi1)
c
= max ∑ p(w�|Zi1). (4)
c w�:w�n=c
</equation>
<page confidence="0.939481">
1173
</page>
<bodyText confidence="0.999987181818182">
the possible characters for w1 along with their re-
spective likelihoods given the visual input (as in
the inner term of Equation 3). Next, these two
wFSAs may simply be composed and then nor-
malized, which completes the belief update, re-
sulting in a new wFSA giving the posterior dis-
tribution over sentences. To calculate the statistic
m, while it is possible to calculate it in closed form
from such a wFSA relatively straightforwardly, for
efficiency we use Monte Carlo estimation based
on samples from the wFSA.
</bodyText>
<sectionHeader confidence="0.992029" genericHeader="method">
5 Simulation 1
</sectionHeader>
<bodyText confidence="0.999995958333333">
With the description of our model in place, we
next proceed to describe the first simulation in
which we used the model to test the hypothesis
that making regressions is a rational way to cope
with confidence in previous regions falling. Be-
cause there is in general no single rational trade-
off between speed and accuracy, our hypothesis
is that, for any given level of speed and accu-
racy achieved by a non-regressive policy, there is a
faster and more accurate policy that makes a faster
left-to-right pass but occasionally does make re-
gressions. In the terms of our model’s policy pa-
rameters α and β described above, non-regressive
policies are exactly those with β = 0, and a pol-
icy that is faster on the left-to-right pass but does
make regressions is one with a lower value of α
but a non-zero β. Thus, we tested the performance
of our model on the reading of a corpus of text typ-
ical of that used in reading experiments at a range
of reasonable non-regressive policies, as well as a
set of regressive policies with lower α and posi-
tive β. Our prediction is that the former set will
be strictly dominated in terms of both speed and
accuracy by the latter.
</bodyText>
<subsectionHeader confidence="0.8155505">
5.1 Methods
5.1.1 Policy parameters
</subsectionHeader>
<bodyText confidence="0.99997725">
We test 4 non-regressive policies (i.e., those with
β = 0) with values of α E {.90,.95,.97,.99}, and
in addition, test regressive policies with a lower
range of α E {.85,.90,.95,.97} and β E {.4,.7}.4
</bodyText>
<subsubsectionHeader confidence="0.690979">
5.1.2 Language model
</subsubsectionHeader>
<bodyText confidence="0.852340166666667">
Our reader’s language model was an unsmoothed
bigram model created using a vocabulary set con-
4We tested all combinations of these values of α and β
except for [α,β] = [.97,.4], because we did not believe that
a value of β so low in relation to α would be very different
from a non-regressive policy.
sisting of the 500 most frequent words in the
British National Corpus (BNC) as well as all the
words in our test corpus. From this vocabulary, we
constructed a bigram model using the counts from
every bigram in the BNC for which both words
were in vocabulary (about 222,000 bigrams).
</bodyText>
<subsubsectionHeader confidence="0.897867">
5.1.3 wFSA implementation
</subsubsectionHeader>
<bodyText confidence="0.999792">
We implemented our model with wFSAs using
the OpenFST library (Allauzen, Riley, Schalk-
wyk, Skut, &amp; Mohri, 2007). Specifically, we
constructed the model’s initial belief state (i.e.,
the distribution over sentences given by its lan-
guage model) by directly translating the bigram
model into a wFSA in the log semiring. We
then composed this wFSA with a weighted finite-
state transducer (wFST) breaking words down
into characters. This was done in order to facili-
tate simple composition with the visual likelihood
wFSA defined over characters. In the Monte Carlo
estimation of m, we used 5000 samples from the
wFSA. Finally, to speed performance, we bounded
the wFSA to have exactly the number of char-
acters present in the actual sentence and then re-
normalized.
</bodyText>
<subsectionHeader confidence="0.838891">
5.1.4 Test corpus
</subsectionHeader>
<bodyText confidence="0.999997090909091">
We tested our model’s performance by simulating
reading of the Schilling corpus (Schilling, Rayner,
&amp; Chumbley, 1998). To ensure that our results
did not depend on smoothing, we only tested the
model on sentences in which every bigram oc-
curred in the BNC. Unfortunately, only 8 of the 48
sentences in the corpus met this criterion. Thus,
we made single-word changes to 25 more of the
sentences (mostly changing proper names and rare
nouns) to produce a total of 33 sentences to read,
for which every bigram did occur in the BNC.
</bodyText>
<subsectionHeader confidence="0.993183">
5.2 Results and discussion
</subsectionHeader>
<bodyText confidence="0.999849583333333">
For each policy we tested, we measured the aver-
age number of timesteps it took to read the sen-
tences, as well as the average (natural) log prob-
ability of the correct sentence identity under the
model’s beliefs after reading ended ‘Accuracy’.
The results are plotted in Figure 3. As shown in
the graph, for each non-regressive policy (the cir-
cles), there is a regressive policy that outperforms
it, both in terms of average number of timesteps
taken to read (further to the left) and the average
log probability of the sentence identity (higher).
Thus, for a range of policies, these results suggest
</bodyText>
<page confidence="0.955169">
1174
</page>
<table confidence="0.9529567">
●
●
●
- Beta
● non− regressive (beta
=0)
regressive (beta =0.4)
● regressive (beta =0.7)
50 55 60 65 70
Timesteps
</table>
<figureCaption confidence="0.960773">
Figure 3: Mean number of timesteps taken to read
</figureCaption>
<bodyText confidence="0.879904272727273">
a sentence and (natural) log probability of the true
identity of the sentence ‘Accuracy’ for a range of
values of a and P. Values of a are not labeled,
but increase with the number of timesteps for a
constant value of P. For each non-regressive pol-
icy (P = 0), there is a policy with a lower a and
higher P that achieves better accuracy in less time.
that making regressions when confidence about
previous regions falls is a rational reader strategy,
in that it appears to lead to better performance,
both in terms of speed and accuracy.
</bodyText>
<sectionHeader confidence="0.995942" genericHeader="method">
6 Simulation 2
</sectionHeader>
<bodyText confidence="0.9999545">
In Simulation 2, we perform a more direct test of
the idea that making regressions is a rational re-
sponse to the problem of confidence falling about
previous regions using optimization techniques.
Specifically, we search for optimal policy param-
eter values (a,P) for three different measures of
performance, each representing a different trade-
off between the importance of accuracy and speed.
</bodyText>
<subsectionHeader confidence="0.938655">
6.1 Methods
6.1.1 Performance measures
</subsectionHeader>
<bodyText confidence="0.999907">
We examine performance measures interpolating
between speed and accuracy of the form
</bodyText>
<equation confidence="0.988604">
L(1− y) − Ty (5)
</equation>
<bodyText confidence="0.999979666666667">
where L is the log probability of the true identity
of the sentence under the model’s beliefs at the end
of reading, and T is the total number of timesteps
before the model decided to stop reading. Thus,
each different performance measure is determined
by the weighting for time y. We test three values of
y E 1.025,.1,.4}. The first of these weights accu-
racy highly, while the final one weights 1 timestep
almost as much as 1 unit of log probability.
</bodyText>
<subsectionHeader confidence="0.965633">
6.1.2 Optimization of policy parameters
</subsectionHeader>
<bodyText confidence="0.999980307692308">
Searching directly for optimal values of a and P
for our stochastic reading model is difficult be-
cause each evaluation of the model with a partic-
ular set of parameters produces a different result.
We use the PEGASUS method (Ng &amp; Jordan, 2000)
to transform this stochastic optimization problem
into a deterministic one on which we can use stan-
dard optimization algorithms.5 Then, we evaluate
the model’s performance at each value of a and P
by reading the full test corpus and averaging per-
formance. We then simply use coordinate ascent
(in logit space) to find the optimal values of a and
P for each performance measure.
</bodyText>
<subsectionHeader confidence="0.786798">
6.1.3 Language model
</subsectionHeader>
<bodyText confidence="0.999990466666667">
The language model used in this simulation be-
gins with the same vocabulary set as in Sim. 1,
i.e., the 500 most frequent words in the BNC and
every word that occurs in our test corpus. Because
the search algorithm demands that we evaluate the
performance of our model at a number of param-
eter values, however, it is too slow to optimize a
and P using the full language model that we used
for Sim. 1. Instead, we begin with the same set of
bigrams used in Sim. 1 – i.e., those that contain
two in-vocabulary words – and trim this set by re-
moving rare bigrams that occur less than 200 times
in the BNC (except that we do not trim any bi-
grams that occur in our test corpus). This reduces
our set of bigrams to about 19,000.
</bodyText>
<subsubsectionHeader confidence="0.636431">
6.1.4 wFSA implementation
</subsubsectionHeader>
<bodyText confidence="0.997466">
The implementation was the same as in Sim. 1.
</bodyText>
<subsectionHeader confidence="0.976732">
6.1.5 Test corpus
</subsectionHeader>
<bodyText confidence="0.991897">
The test corpus was the same as in Sim. 1.
</bodyText>
<subsectionHeader confidence="0.935917">
6.2 Results and discussion
</subsectionHeader>
<bodyText confidence="0.987746384615384">
The optimal values of a and P for each y E
1.025,.1,.4} are given in Table 1 along with the
mean values for L and T found at those parameter
values. As the table shows, the optimization proce-
dure successfully found values of a and P, which
go up (slower reading) as y goes down (valuing
accuracy more than time). In addition, we see that
the average results of reading at these parameter
values are also as we would expect, with T and L
going up as y goes down. As predicted, the optimal
5Specifically, this involves fixing the random number gen-
erator for each run to produce the same values, resulting in
minimizing the variance in performance across evaluations.
</bodyText>
<figure confidence="0.89072775">
−0.6
Accuracy −0.8
−1.0
−1.2
</figure>
<page confidence="0.831682">
1175
</page>
<table confidence="0.9682235">
y a P Timesteps Log probability
.025 .90 .99 41.2 -0.02
.1 .36 .80 25.8 -0.90
.4 .18 .38 16.4 -4.59
</table>
<tableCaption confidence="0.995511">
Table 1: Optimal values of a and P found for each
</tableCaption>
<bodyText confidence="0.992118678571429">
performance measure y tested and mean perfor-
mance at those values, measured in timesteps T
and (natural) log probability L.
values of P found are non-zero across the range of
policies, which include policies that value speed
over accuracy much more than in Sim. 1. This
provides more evidence that whatever the partic-
ular performance measure used, policies making
regressive saccades when confidence in previous
regions falls perform better than those that do not.
There is one interesting difference between the
results of this simulation and those of Sim. 1,
which is that here, the optimal policies all have a
value of P &gt; a. That may at first seem surprising,
since the model’s policy is to fixate a region un-
til its confidence becomes greater than a and then
return if it falls below P. It would seem, then, that
the only reasonable values of P are those that are
strictly below a. In fact, this is not the case be-
cause of the two time step delay between the de-
cision to move the eyes and the execution of that
saccade. Because of this delay, the model’s confi-
dence when it leaves a region (relevant to P) will
generally be higher than when it decided to leave
(determined by a). In Simulation 2, because of the
smaller grammar that was used, the model’s confi-
dence in a region’s identity rises more quickly and
this difference is exaggerated.
</bodyText>
<sectionHeader confidence="0.998919" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999982698113208">
In this paper, we presented a model that performs
Bayesian inference on the identity of a sentence,
combining a language model with noisy informa-
tion about letter identities from a realistic visual
input model. On the basis of these inferences, it
uses a simple policy to determine how long to
continue fixating the current position and where
to fixate next, on the basis of information about
where the model is uncertain about the sentence’s
identity. As such, it constitutes a rational model
of eye movement control in reading, extending the
insights from previous results about rationality in
language comprehension.
The results of two simulations using this model
support a novel explanation for between-word re-
gressive saccades in reading: that they are used to
gather visual input about previous regions when
confidence about them falls. Simulation 1 showed
that a range of policies making regressions in these
cases outperforms a range of non-regressive poli-
cies. In Simulation 2, we directly searched for op-
timal values for the policy parameters for three dif-
ferent performance measures, representing differ-
ent speed-accuracy trade-offs, and found that the
optimal policies in each case make substantial use
of between-word regressions when confidence in
previous regions falls. In addition to supporting
a novel motivation for between-word regressions,
these simulations demonstrate the possibility for
testing a range of questions that were impossi-
ble with previous models of reading related to the
goals of a reader, such as how should reading be-
havior change as accuracy is valued more.
There are a number of obvious ways for the
model to move forward. One natural next step is
to make the model more realistic by using letter
confusability matrices. In addition, the link to pre-
vious work in sentence processing can be made
tighter by incorporating syntax-based language
models. It also remains to compare this model’s
predictions to human data more broadly on stan-
dard benchmark measures for models of read-
ing. The most important future development, how-
ever, will be moving toward richer policy families,
which enable more intelligent decisions about eye
movement control, based not just on simple confi-
dence statistics calculated independently for each
character position, but rather which utilize the rich
structure of the model’s posterior beliefs about the
sentence identity (and of language itself) to make
more informed decisions about the best time to
move the eyes and the best location to direct them
next.
</bodyText>
<sectionHeader confidence="0.998135" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9999061">
The authors thank Jeff Elman, Tom Griffiths,
Andy Kehler, Keith Rayner, and Angela Yu for
useful discussion about this work. This work bene-
fited from feedback from the audiences at the 2010
LSA and CUNY conferences. The research was
partially supported by NIH Training Grant T32-
DC000041 from the Center for Research in Lan-
guage at UC San Diego to K.B., by a research
grant from the UC San Diego Academic Senate
to R.L., and by NSF grant 0953870 to R.L.
</bodyText>
<page confidence="0.991886">
1176
</page>
<sectionHeader confidence="0.988709" genericHeader="references">
References
</sectionHeader>
<bodyText confidence="0.9528785">
Allauzen, C., Riley, M., Schalkwyk, J., Skut, W.,
&amp; Mohri, M. (2007). OpenFst: A general and
efficient weighted finite-state transducer library.
In Proceedings of the Ninth International Con-
ference on Implementation and Application of
Automata, (CIAA 2007) (Vol. 4783, p. 11-23).
Springer.
Bicknell, K., &amp; Levy, R. (2010). Rational eye
movements in reading combining uncertainty
about previous words with contextual probabil-
</bodyText>
<reference confidence="0.986839868131868">
ity. In Proceedings of the 32nd Annual Confer-
ence of the Cognitive Science Society. Austin,
TX: Cognitive Science Society.
Boston, M. F., Hale, J. T., Kliegl, R., Patil, U., &amp;
Vasishth, S. (2008). Parsing costs as predic-
tors of reading difficulty: An evaluation using
the potsdam sentence corpus. Journal of Eye
Movement Research, 2(1), 1–12.
Connine, C. M., Blasko, D. G., &amp; Hall, M. (1991).
Effects of subsequent sentence context in audi-
tory word recognition: Temporal and linguistic
constraints. Journal of Memory and Language,
30, 234–250.
Demberg, V., &amp; Keller, F. (2008). Data from eye-
tracking corpora as evidence for theories of syn-
tactic processing complexity. Cognition, 109,
193–210.
Ehrlich, S. F., &amp; Rayner, K. (1981). Contextual
effects on word perception and eye movements
during reading. Journal of Verbal Learning and
Verbal Behavior, 20, 641–655.
Engbert, R., &amp; Krügel, A. (2010). Readers use
Bayesian estimation for eye movement control.
Psychological Science, 21, 366–371.
Engbert, R., Longtin, A., &amp; Kliegl, R. (2002). A
dynamical model of saccade generation in read-
ing based on spatially distributed lexical pro-
cessing. Vision Research, 42, 621–636.
Engbert, R., Nuthmann, A., Richter, E. M., &amp;
Kliegl, R. (2005). SWIFT: A dynamical model
of saccade generation during reading. Psycho-
logical Review,112, 777–813.
Engel, G. R., Dougherty, W. G., &amp; Jones, B. G.
(1973). Correlation and letter recognition.
Canadian Journal of Psychology, 27, 317–326.
Genzel, D., &amp; Charniak, E. (2002, July). Entropy
rate constancy in text. In Proceedings of the 40th
annual meeting of the Association for Computa-
tional Linguistics (pp. 199–206). Philadelphia:
Association for Computational Linguistics.
Genzel, D., &amp; Charniak, E. (2003). Variation of
entropy and parse trees of sentences as a func-
tion of the sentence number. In M. Collins &amp;
M. Steedman (Eds.), Proceedings of the 2003
Conference on Empirical Methods in Natural
Language Processing (pp. 65–72). Sapporo,
Japan: Association for Computational Linguis-
tics.
Geyer, L. H. (1977). Recognition and confusion
of the lowercase alphabet. Perception &amp; Psy-
chophysics, 22, 487–490.
Hale, J. (2001). A probabilistic Earley parser as
a psycholinguistic model. In Proceedings of the
Second Meeting of the North American Chapter
of the Association for Computational Linguistics
(Vol. 2, pp. 159–166). New Brunswick, NJ: As-
sociation for Computational Linguistics.
Jaeger, T. F. (2010). Redundancy and re-
duction: Speakers manage syntactic in-
formation density. Cognitive Psychology.
doi:10.1016/j.cogpsych.2010.02.002.
Jurafsky, D. (1996). A probabilistic model of
lexical and syntactic access and disambiguation.
Cognitive Science, 20, 137–194.
Keller, F. (2004). The entropy rate principle as
a predictor of processing effort: An evaluation
against eye-tracking data. In D. Lin &amp; D. Wu
(Eds.), Proceedings of the 2004 Conference on
Empirical Methods in Natural Language Pro-
cessing (pp. 317–324). Barcelona, Spain: As-
sociation for Computational Linguistics.
Legge, G. E., Hooven, T. A., Klitz, T. S., Mans-
field, J. S., &amp; Tjan, B. S. (2002). Mr.
Chips 2002: new insights from an ideal-observer
model of reading. Vision Research, 42, 2219–
2234.
Legge, G. E., Klitz, T. S., &amp; Tjan, B. S. (1997).
Mr. Chips: an Ideal-Observer model of reading.
Psychological Review, 104, 524–553.
Levy, R. (2008). A noisy-channel model of ra-
tional human sentence comprehension under un-
certain input. In Proceedings of the 2008 Con-
ference on Empirical Methods in Natural Lan-
guage Processing (pp. 234–243). Honolulu,
Hawaii: Association for Computational Linguis-
tics.
Levy, R., Bicknell, K., Slattery, T., &amp; Rayner,
K. (2009). Eye movement evidence that read-
ers maintain and act on uncertainty about past
linguistic input. Proceedings of the National
Academy of Sciences, 106, 21086–21090.
</reference>
<page confidence="0.878541">
1177
</page>
<reference confidence="0.997862621621622">
Levy, R., &amp; Jaeger, T. F. (2007). Speakers op-
timize information density through syntactic re-
duction. In B. Schölkopf, J. Platt, &amp; T. Hoffman
(Eds.), Advances in Neural Information Pro-
cessing Systems 19 (pp. 849–856). Cambridge,
MA: MIT Press.
Levy, R., Reali, F., &amp; Griffiths, T. L. (2009).
Modeling the effects of memory on human on-
line sentence processing with particle filters. In
D. Koller, D. Schuurmans, Y. Bengio, &amp; L. Bot-
tou (Eds.), Advances in Neural Information Pro-
cessing Systems 21 (pp. 937–944).
Mohri, M. (1997). Finite-state transducers in lan-
guage and speech processing. Computational
Linguistics, 23, 269–311.
Narayanan, S., &amp; Jurafsky, D. (2001). A Bayesian
model predicts human parse preference and
reading time in sentence processing. In T. Diet-
terich, S. Becker, &amp; Z. Ghahramani (Eds.), Ad-
vances in Neural Information Processing Sys-
tems 14 (pp. 59–65). Cambridge, MA: MIT
Press.
Ng, A. Y., &amp; Jordan, M. (2000). PEGASUS:
A policy search method for large MDPs and
POMDPs. In Uncertainty in Artificial Intelli-
gence, Proceedings of the Sixteenth Conference
(pp. 406–415).
Norris, D. (2006). The Bayesian reader: Explain-
ing word recognition as an optimal Bayesian de-
cision process. Psychological Review, 113, 327–
357.
Norris, D. (2009). Putting it all together: A unified
account of word recognition and reaction-time
distributions. Psychological Review, 116, 207–
219.
Rayner, K. (1998). Eye movements in reading and
information processing: 20 years of research.
Psychological Bulletin, 124, 372–422.
Reichle, E. D., &amp; Laurent, P. A. (2006). Using
reinforcement learning to understand the emer-
gence of “intelligent” eye-movement behavior
during reading. Psychological Review, 113,
390–408.
Reichle, E. D., Pollatsek, A., Fisher, D. L., &amp;
Rayner, K. (1998). Toward a model of eye
movement control in reading. Psychological Re-
view, 105, 125–157.
Reichle, E. D., Pollatsek, A., &amp; Rayner, K.
(2006). E-Z Reader: A cognitive-control, serial-
attention model of eye-movement behavior dur-
ing reading. Cognitive Systems Research, 7, 4–
22.
Reichle, E. D., Warren, T., &amp; McConnell, K.
(2009). Using E-Z Reader to model the ef-
fects of higher level language processing on eye
movements during reading. Psychonomic Bul-
letin &amp; Review, 16, 1–21.
Schilling, H. E. H., Rayner, K., &amp; Chumbley, J. I.
(1998). Comparing naming, lexical decision,
and eye fixation times: Word frequency effects
and individual differences. Memory &amp; Cogni-
tion, 26, 1270–1281.
Smith, N. J., &amp; Levy, R. (2008). Optimal process-
ing times in reading: a formal model and empir-
ical investigation. In B. C. Love, K. McRae, &amp;
V. M. Sloutsky (Eds.), Proceedings of the 30th
Annual Conference of the Cognitive Science So-
ciety (pp. 595–600). Austin, TX: Cognitive Sci-
ence Society.
Tanenhaus, M. K., Spivey-Knowlton, M. J., Eber-
hard, K. M., &amp; Sedivy, J. C. (1995). Integration
of visual and linguistic information in spoken
language comprehension. Science, 268, 1632–
1634.
</reference>
<page confidence="0.995281">
1178
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.963597">
<title confidence="0.99954">A Rational Model of Eye Movement Control in Reading</title>
<author confidence="0.998455">Bicknell Levy</author>
<affiliation confidence="0.9997855">Department of Linguistics University of California, San Diego</affiliation>
<address confidence="0.999268">9500 Gilman Dr, La Jolla, CA 92093-0108</address>
<email confidence="0.999762">kbicknell@ling.ucsd.edu</email>
<email confidence="0.999762">rlevy@ling.ucsd.edu</email>
<abstract confidence="0.99863796">A number of results in the study of realtime sentence comprehension have been explained by computational models as resulting from the rational use of probabilistic linguistic information. Many times, these hypotheses have been tested in reading by linking predictions about relative word difficulty to word-aggregated eye tracking measures such as go-past time. In this paper, we extend these results by asking to what extent reading is well-modeled as rational behavior at a finer level of analysis, predicting not aggregate measures, but the duration and location of each fixation. We present a new rational model of eye movement control in reading, the central assumption of which is that eye movement decisions are made to obtain noisy visual information as the reader performs Bayesian inference on the identities of the words in the sentence. As a case study, we present two simulations demonstrating that the model gives a rational explanation for between-word regressions.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>ity</author>
</authors>
<booktitle>In Proceedings of the 32nd Annual Conference of the Cognitive Science Society.</booktitle>
<publisher>Cognitive Science Society.</publisher>
<location>Austin, TX:</location>
<marker>ity, </marker>
<rawString>ity. In Proceedings of the 32nd Annual Conference of the Cognitive Science Society. Austin, TX: Cognitive Science Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M F Boston</author>
<author>J T Hale</author>
<author>R Kliegl</author>
<author>U Patil</author>
<author>S Vasishth</author>
</authors>
<title>Parsing costs as predictors of reading difficulty: An evaluation using the potsdam sentence corpus.</title>
<date>2008</date>
<journal>Journal of Eye Movement Research,</journal>
<volume>2</volume>
<issue>1</issue>
<pages>1--12</pages>
<contexts>
<context position="14888" citStr="Boston, Hale, Kliegl, Patil, &amp; Vasishth, 2008" startWordPosition="2467" endWordPosition="2473">y explicit model of how visual input is used to discriminate word identity. This approach stands in sharp contrast to other models, which treat the time course of word identification as an exogenous function of other influencing factors (such as word length, frequency, and predictability). The hope in our approach is that the influence of these key factors on the eye movement record will fall out as a natural consequence of rational behavior itself. For example, it is well known that the higher the conditional probability of a word given preceding material, the more rapidly that word is read (Boston, Hale, Kliegl, Patil, &amp; Vasishth, 2008; Demberg &amp; Keller, 2008; Ehrlich &amp; Rayner, 1981; Smith &amp; Levy, 2008). E-Z Reader and SWIFT incorporate this finding by specifying a dependency on word predictability in the exogenous function determining word processing time. In our framework, in contrast, we would expect such an effect to emerge as a byproduct of Bayesian inference: words with high prior probability (conditional on preceding fixations) will require less visual input to be reliably identified. An implemented model in this framework must formalize a number of pieces of the reading problem, including the possible actions availa</context>
</contexts>
<marker>Boston, Hale, Kliegl, Patil, Vasishth, 2008</marker>
<rawString>Boston, M. F., Hale, J. T., Kliegl, R., Patil, U., &amp; Vasishth, S. (2008). Parsing costs as predictors of reading difficulty: An evaluation using the potsdam sentence corpus. Journal of Eye Movement Research, 2(1), 1–12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C M Connine</author>
<author>D G Blasko</author>
<author>M Hall</author>
</authors>
<title>Effects of subsequent sentence context in auditory word recognition: Temporal and linguistic constraints.</title>
<date>1991</date>
<journal>Journal of Memory and Language,</journal>
<volume>30</volume>
<pages>234--250</pages>
<contexts>
<context position="11208" citStr="Connine, Blasko, &amp; Hall, 1991" startWordPosition="1837" endWordPosition="1841">tion for between-word regressions that arises as a result of word identification processes (unlike that of E-Z Reader) and can be understood as rational (unlike that of SWIFT). Whereas in SWIFT and E-Z Reader, word recognition is a process that takes some amount of time and is then ‘completed’, some experimental evidence suggests that word recognition may be best thought of as a process that is never ‘completed’, as comprehenders appear to both maintain uncertainty about the identity of previous input and to update that uncertainty as more information is gained about the rest of the sentence (Connine, Blasko, &amp; Hall, 1991; Levy, Bicknell, Slattery, &amp; Rayner, 2009). Thus, it is possible that later parts of a sentence can cause a reader’s confidence in the identity of the previous regions to fall. In these cases, a rational way to respond might be to make a between-word regressive saccade to get more visual information about the (now) low confidence previous region. To illustrate this idea, consider the case of a language composed of just two strings, AB and BA, and assume that the eyes can only get noisy information about the identity of one character at a time. After obtaining a little information about the id</context>
</contexts>
<marker>Connine, Blasko, Hall, 1991</marker>
<rawString>Connine, C. M., Blasko, D. G., &amp; Hall, M. (1991). Effects of subsequent sentence context in auditory word recognition: Temporal and linguistic constraints. Journal of Memory and Language, 30, 234–250.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Demberg</author>
<author>F Keller</author>
</authors>
<title>Data from eyetracking corpora as evidence for theories of syntactic processing complexity.</title>
<date>2008</date>
<journal>Cognition,</journal>
<volume>109</volume>
<pages>193--210</pages>
<contexts>
<context position="14912" citStr="Demberg &amp; Keller, 2008" startWordPosition="2474" endWordPosition="2477"> discriminate word identity. This approach stands in sharp contrast to other models, which treat the time course of word identification as an exogenous function of other influencing factors (such as word length, frequency, and predictability). The hope in our approach is that the influence of these key factors on the eye movement record will fall out as a natural consequence of rational behavior itself. For example, it is well known that the higher the conditional probability of a word given preceding material, the more rapidly that word is read (Boston, Hale, Kliegl, Patil, &amp; Vasishth, 2008; Demberg &amp; Keller, 2008; Ehrlich &amp; Rayner, 1981; Smith &amp; Levy, 2008). E-Z Reader and SWIFT incorporate this finding by specifying a dependency on word predictability in the exogenous function determining word processing time. In our framework, in contrast, we would expect such an effect to emerge as a byproduct of Bayesian inference: words with high prior probability (conditional on preceding fixations) will require less visual input to be reliably identified. An implemented model in this framework must formalize a number of pieces of the reading problem, including the possible actions available to the reader and th</context>
</contexts>
<marker>Demberg, Keller, 2008</marker>
<rawString>Demberg, V., &amp; Keller, F. (2008). Data from eyetracking corpora as evidence for theories of syntactic processing complexity. Cognition, 109, 193–210.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S F Ehrlich</author>
<author>K Rayner</author>
</authors>
<title>Contextual effects on word perception and eye movements during reading.</title>
<date>1981</date>
<journal>Journal of Verbal Learning and Verbal Behavior,</journal>
<volume>20</volume>
<pages>641--655</pages>
<contexts>
<context position="14936" citStr="Ehrlich &amp; Rayner, 1981" startWordPosition="2478" endWordPosition="2481">ity. This approach stands in sharp contrast to other models, which treat the time course of word identification as an exogenous function of other influencing factors (such as word length, frequency, and predictability). The hope in our approach is that the influence of these key factors on the eye movement record will fall out as a natural consequence of rational behavior itself. For example, it is well known that the higher the conditional probability of a word given preceding material, the more rapidly that word is read (Boston, Hale, Kliegl, Patil, &amp; Vasishth, 2008; Demberg &amp; Keller, 2008; Ehrlich &amp; Rayner, 1981; Smith &amp; Levy, 2008). E-Z Reader and SWIFT incorporate this finding by specifying a dependency on word predictability in the exogenous function determining word processing time. In our framework, in contrast, we would expect such an effect to emerge as a byproduct of Bayesian inference: words with high prior probability (conditional on preceding fixations) will require less visual input to be reliably identified. An implemented model in this framework must formalize a number of pieces of the reading problem, including the possible actions available to the reader and their consequences, the na</context>
</contexts>
<marker>Ehrlich, Rayner, 1981</marker>
<rawString>Ehrlich, S. F., &amp; Rayner, K. (1981). Contextual effects on word perception and eye movements during reading. Journal of Verbal Learning and Verbal Behavior, 20, 641–655.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Engbert</author>
<author>A Krügel</author>
</authors>
<title>Readers use Bayesian estimation for eye movement control.</title>
<date>2010</date>
<journal>Psychological Science,</journal>
<volume>21</volume>
<pages>366--371</pages>
<contexts>
<context position="18627" citStr="Engbert and Krügel (2010)" startWordPosition="3107" endWordPosition="3110">g from each character position are conditionally independent given sentence identity, so that if wj denotes letter j of the sentence and I(j) denotes the component of visual input associated with that letter, then we can decompose p(I|w) as jIj p(I(j)|wj). For simplicity, we assume that each character is either a lowercase letter or a space. The visual input obtained from an individual fixation can thus be summarized as a vector of likelihoods p(I(j)|wj), as shown in 1In the terminology of the literature, the model has only random motor error (variance), not systematic error (bias). Following Engbert and Krügel (2010), systematic error may arise from Bayesian estimation of the best saccade distance. 1171 * . . . a s a c a t s a t a t a t ... � � � � � � � � � � � � � � .04 � � � � � � � � � � � � � � .04 � � � .� .� . � � .04 � � .04 � � � .� .� . 0 �a � � c � � � � .� � .� � � . � � � � �s � � t � � � � � � .� � .� . � 0 � �0 � � � � .� � .� � � � . � � �0 � � � � �0 � � � � .� � .� . 1 � � .03 � �� � � �� � � � .� � .� � . .25 .01 .07 .01 . . . .03 .003 . .. 0 � � � � � � � � � � � � � � � � � � � � � � � � � � � � .02 0 � .003� .005 � �� � .� � .� � . � � � � .21 .02 0 .07 .08 � � � .� .� . � � .02 � � </context>
</contexts>
<marker>Engbert, Krügel, 2010</marker>
<rawString>Engbert, R., &amp; Krügel, A. (2010). Readers use Bayesian estimation for eye movement control. Psychological Science, 21, 366–371.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Engbert</author>
<author>A Longtin</author>
<author>R Kliegl</author>
</authors>
<title>A dynamical model of saccade generation in reading based on spatially distributed lexical processing.</title>
<date>2002</date>
<journal>Vision Research,</journal>
<volume>42</volume>
<pages>621--636</pages>
<contexts>
<context position="5552" citStr="Engbert, Longtin, &amp; Kliegl, 2002" startWordPosition="894" endWordPosition="898">c regressive policies outperform specific non-regressive policies, and in Simulation 2, we use optimization to directly find optimal policies for three performance measures. The results show that the regressive policies outperform non-regressive policies across a wide range of performance measures, demonstrating that our model predicts that making between-word regressions is a rational strategy for reading. 2 Models of eye movements in reading The two most successful models of eye movements in reading are E-Z Reader (Reichle, Pollatsek, Fisher, &amp; Rayner, 1998; Reichle et al., 2006) and SWIFT (Engbert, Longtin, &amp; Kliegl, 2002; Engbert et al., 2005). Both of these models characterize the problem of reading as one of word identification. In E-Z Reader, for example, the system identifies each word in the sentence serially, moving attention to the next word in the sentence only after processing the current word is complete, and (to slightly oversimplify), the eyes then follow the attentional shifts at some lag. SWIFT works similarly, but with the main difference being that processing and attention are distributed over multiple words, such that adjacent words can be identified in parallel. While both of these models pr</context>
</contexts>
<marker>Engbert, Longtin, Kliegl, 2002</marker>
<rawString>Engbert, R., Longtin, A., &amp; Kliegl, R. (2002). A dynamical model of saccade generation in reading based on spatially distributed lexical processing. Vision Research, 42, 621–636.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Engbert</author>
<author>A Nuthmann</author>
<author>E M Richter</author>
<author>R Kliegl</author>
</authors>
<title>SWIFT: A dynamical model of saccade generation during reading.</title>
<date>2005</date>
<booktitle>Psychological Review,112,</booktitle>
<pages>777--813</pages>
<contexts>
<context position="3770" citStr="Engbert, Nuthmann, Richter, &amp; Kliegl, 2005" startWordPosition="609" endWordPosition="615">s right (‘go-past time’). It is important to note that this notion of word difficulty is an abstraction over the actual task of reading, which is made up of more fine-grained decisions about how long to leave the eyes in their current position, and where to move them next, producing the series of relatively stable periods (fixations) and movements (saccades) that characterize the eye tracking record. While there has been much empirical work on reading at this fine-grained scale (see Rayner, 1998 for an overview), and there are a number of successful models (Reichle, Pollatsek, &amp; Rayner, 2006; Engbert, Nuthmann, Richter, &amp; Kliegl, 2005), little is known about the extent to which human reading behavior appears to be rational at this finer 1168 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1168–1178, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics grained scale. In this paper, we present a new rational model of eye movement control in reading, the central assumption of which is that eye movement decisions are made to obtain noisy visual information, which the reader uses in Bayesian inference about the form and structure of the sentence. As a </context>
<context position="5575" citStr="Engbert et al., 2005" startWordPosition="899" endWordPosition="902">pecific non-regressive policies, and in Simulation 2, we use optimization to directly find optimal policies for three performance measures. The results show that the regressive policies outperform non-regressive policies across a wide range of performance measures, demonstrating that our model predicts that making between-word regressions is a rational strategy for reading. 2 Models of eye movements in reading The two most successful models of eye movements in reading are E-Z Reader (Reichle, Pollatsek, Fisher, &amp; Rayner, 1998; Reichle et al., 2006) and SWIFT (Engbert, Longtin, &amp; Kliegl, 2002; Engbert et al., 2005). Both of these models characterize the problem of reading as one of word identification. In E-Z Reader, for example, the system identifies each word in the sentence serially, moving attention to the next word in the sentence only after processing the current word is complete, and (to slightly oversimplify), the eyes then follow the attentional shifts at some lag. SWIFT works similarly, but with the main difference being that processing and attention are distributed over multiple words, such that adjacent words can be identified in parallel. While both of these models provide a good fit to eye</context>
</contexts>
<marker>Engbert, Nuthmann, Richter, Kliegl, 2005</marker>
<rawString>Engbert, R., Nuthmann, A., Richter, E. M., &amp; Kliegl, R. (2005). SWIFT: A dynamical model of saccade generation during reading. Psychological Review,112, 777–813.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G R Engel</author>
<author>W G Dougherty</author>
<author>B G Jones</author>
</authors>
<title>Correlation and letter recognition.</title>
<date>1973</date>
<journal>Canadian Journal of Psychology,</journal>
<volume>27</volume>
<pages>317--326</pages>
<contexts>
<context position="22760" citStr="Engel, Dougherty, &amp; Jones, 1973" startWordPosition="4078" endWordPosition="4082">rocessing rate proportion λ(ε) that is at least 1% of the total processing rate (ε E [−5,8]) the model receives foveal visual input, defined only for letters2 to give noisy information about the letter’s identity. This threshold of 1% roughly corresponds to estimates that readers get information useful for letter identification from about 4 characters to the left and 8 to the right of fixation (Rayner, 1998). In our model, each letter is equally confusable with all others, following Norris (2006, 2009), but ignoring work on letter confusability (which could be added to future model revisions; Engel, Dougherty, &amp; Jones, 1973; Geyer, 1977). Visual information about each character is obtained by sampling. Specifically, we represent each letter as a 26-dimensional vector, where a single element is 1 and the other 25 are zeros, and given this representation, foveal input for a letter is given as a sample from a 26-dimensional Gaussian with a 2For white space, the model is already certain of the identity because of peripheral input. λ(ε) = IS ε+.5 1 x2 −.5 Z ( ) σL, x &lt; 0 exp - 2σ2 dx, σ = σR, 04 .060.05 .01 .01 0 .05 .03 .07 .02 .12 0 .05 0 0 0 1 L 0 1172 mean equal to the letter’s true identity and a diagonal covari</context>
</contexts>
<marker>Engel, Dougherty, Jones, 1973</marker>
<rawString>Engel, G. R., Dougherty, W. G., &amp; Jones, B. G. (1973). Correlation and letter recognition. Canadian Journal of Psychology, 27, 317–326.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Genzel</author>
<author>E Charniak</author>
</authors>
<title>Entropy rate constancy in text.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th annual meeting of the Association for Computational Linguistics (pp. 199–206). Philadelphia: Association for Computational Linguistics.</booktitle>
<contexts>
<context position="1874" citStr="Genzel &amp; Charniak, 2002" startWordPosition="289" endWordPosition="292">s of reading, listening, and even speaking are remarkably difficult. Good performance at each one requires integrating a range of types of probabilistic information and making incremental predictions on the basis of noisy, incomplete input. Despite these requirements, empirical work has shown that humans perform very well (e.g., Tanenhaus, SpiveyKnowlton, Eberhard, &amp; Sedivy, 1995). Sophisticated models have been developed that explain many of these effects using the tools of computational linguistics and large-scale corpora to make normative predictions for optimal performance in these tasks (Genzel &amp; Charniak, 2002, 2003; Keller, 2004; Levy &amp; Jaeger, 2007; Jaeger, 2010). To the extent that the behavior of these models looks like human behavior, it suggests that humans are making rational use of all the information available to them in language processing. In the domain of incremental language comprehension, especially, there is a substantial amount of computational work suggesting that humans behave rationally (e.g., Jurafsky, 1996; Narayanan &amp; Jurafsky, 2001; Levy, 2008; Levy, Reali, &amp; Griffiths, 2009). Most of this work has taken as its task predicting the difficulty of each word in a sentence, a majo</context>
</contexts>
<marker>Genzel, Charniak, 2002</marker>
<rawString>Genzel, D., &amp; Charniak, E. (2002, July). Entropy rate constancy in text. In Proceedings of the 40th annual meeting of the Association for Computational Linguistics (pp. 199–206). Philadelphia: Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Genzel</author>
<author>E Charniak</author>
</authors>
<title>Variation of entropy and parse trees of sentences as a function of the sentence number.</title>
<date>2003</date>
<booktitle>In M. Collins &amp; M. Steedman (Eds.), Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing</booktitle>
<pages>65--72</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sapporo, Japan:</location>
<marker>Genzel, Charniak, 2003</marker>
<rawString>Genzel, D., &amp; Charniak, E. (2003). Variation of entropy and parse trees of sentences as a function of the sentence number. In M. Collins &amp; M. Steedman (Eds.), Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing (pp. 65–72). Sapporo, Japan: Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L H Geyer</author>
</authors>
<title>Recognition and confusion of the lowercase alphabet.</title>
<date>1977</date>
<journal>Perception &amp; Psychophysics,</journal>
<volume>22</volume>
<pages>487--490</pages>
<contexts>
<context position="22774" citStr="Geyer, 1977" startWordPosition="4083" endWordPosition="4084">at is at least 1% of the total processing rate (ε E [−5,8]) the model receives foveal visual input, defined only for letters2 to give noisy information about the letter’s identity. This threshold of 1% roughly corresponds to estimates that readers get information useful for letter identification from about 4 characters to the left and 8 to the right of fixation (Rayner, 1998). In our model, each letter is equally confusable with all others, following Norris (2006, 2009), but ignoring work on letter confusability (which could be added to future model revisions; Engel, Dougherty, &amp; Jones, 1973; Geyer, 1977). Visual information about each character is obtained by sampling. Specifically, we represent each letter as a 26-dimensional vector, where a single element is 1 and the other 25 are zeros, and given this representation, foveal input for a letter is given as a sample from a 26-dimensional Gaussian with a 2For white space, the model is already certain of the identity because of peripheral input. λ(ε) = IS ε+.5 1 x2 −.5 Z ( ) σL, x &lt; 0 exp - 2σ2 dx, σ = σR, 04 .060.05 .01 .01 0 .05 .03 .07 .02 .12 0 .05 0 0 0 1 L 0 1172 mean equal to the letter’s true identity and a diagonal covariance matrix Σ(</context>
</contexts>
<marker>Geyer, 1977</marker>
<rawString>Geyer, L. H. (1977). Recognition and confusion of the lowercase alphabet. Perception &amp; Psychophysics, 22, 487–490.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hale</author>
</authors>
<title>A probabilistic Earley parser as a psycholinguistic model.</title>
<date>2001</date>
<booktitle>In Proceedings of the Second Meeting of the North American Chapter of the Association for Computational Linguistics</booktitle>
<volume>2</volume>
<pages>159--166</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>New Brunswick, NJ:</location>
<contexts>
<context position="2606" citStr="Hale, 2001" startWordPosition="415" endWordPosition="416"> behavior, it suggests that humans are making rational use of all the information available to them in language processing. In the domain of incremental language comprehension, especially, there is a substantial amount of computational work suggesting that humans behave rationally (e.g., Jurafsky, 1996; Narayanan &amp; Jurafsky, 2001; Levy, 2008; Levy, Reali, &amp; Griffiths, 2009). Most of this work has taken as its task predicting the difficulty of each word in a sentence, a major result being that a large component of the difficulty of a word appears to be a function of its probability in context (Hale, 2001; Smith &amp; Levy, 2008). Much of the empirical basis for this work comes from studying reading, where word difficulty can be related to the amount of time that a reader spends on a particular word. To relate these predictions about word difficulty to the data obtained in eye tracking experiments, the eye movement record has been summarized through word aggregate measures, such as the average duration of the first fixation on a word, or the amount of time between when a word is first fixated and when the eyes move to its right (‘go-past time’). It is important to note that this notion of word dif</context>
</contexts>
<marker>Hale, 2001</marker>
<rawString>Hale, J. (2001). A probabilistic Earley parser as a psycholinguistic model. In Proceedings of the Second Meeting of the North American Chapter of the Association for Computational Linguistics (Vol. 2, pp. 159–166). New Brunswick, NJ: Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T F Jaeger</author>
</authors>
<title>Redundancy and reduction: Speakers manage syntactic information density. Cognitive Psychology.</title>
<date>2010</date>
<contexts>
<context position="1930" citStr="Jaeger, 2010" startWordPosition="300" endWordPosition="301">t. Good performance at each one requires integrating a range of types of probabilistic information and making incremental predictions on the basis of noisy, incomplete input. Despite these requirements, empirical work has shown that humans perform very well (e.g., Tanenhaus, SpiveyKnowlton, Eberhard, &amp; Sedivy, 1995). Sophisticated models have been developed that explain many of these effects using the tools of computational linguistics and large-scale corpora to make normative predictions for optimal performance in these tasks (Genzel &amp; Charniak, 2002, 2003; Keller, 2004; Levy &amp; Jaeger, 2007; Jaeger, 2010). To the extent that the behavior of these models looks like human behavior, it suggests that humans are making rational use of all the information available to them in language processing. In the domain of incremental language comprehension, especially, there is a substantial amount of computational work suggesting that humans behave rationally (e.g., Jurafsky, 1996; Narayanan &amp; Jurafsky, 2001; Levy, 2008; Levy, Reali, &amp; Griffiths, 2009). Most of this work has taken as its task predicting the difficulty of each word in a sentence, a major result being that a large component of the difficulty </context>
</contexts>
<marker>Jaeger, 2010</marker>
<rawString>Jaeger, T. F. (2010). Redundancy and reduction: Speakers manage syntactic information density. Cognitive Psychology. doi:10.1016/j.cogpsych.2010.02.002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Jurafsky</author>
</authors>
<title>A probabilistic model of lexical and syntactic access and disambiguation.</title>
<date>1996</date>
<journal>Cognitive Science,</journal>
<volume>20</volume>
<pages>137--194</pages>
<contexts>
<context position="2299" citStr="Jurafsky, 1996" startWordPosition="358" endWordPosition="359">lain many of these effects using the tools of computational linguistics and large-scale corpora to make normative predictions for optimal performance in these tasks (Genzel &amp; Charniak, 2002, 2003; Keller, 2004; Levy &amp; Jaeger, 2007; Jaeger, 2010). To the extent that the behavior of these models looks like human behavior, it suggests that humans are making rational use of all the information available to them in language processing. In the domain of incremental language comprehension, especially, there is a substantial amount of computational work suggesting that humans behave rationally (e.g., Jurafsky, 1996; Narayanan &amp; Jurafsky, 2001; Levy, 2008; Levy, Reali, &amp; Griffiths, 2009). Most of this work has taken as its task predicting the difficulty of each word in a sentence, a major result being that a large component of the difficulty of a word appears to be a function of its probability in context (Hale, 2001; Smith &amp; Levy, 2008). Much of the empirical basis for this work comes from studying reading, where word difficulty can be related to the amount of time that a reader spends on a particular word. To relate these predictions about word difficulty to the data obtained in eye tracking experiment</context>
</contexts>
<marker>Jurafsky, 1996</marker>
<rawString>Jurafsky, D. (1996). A probabilistic model of lexical and syntactic access and disambiguation. Cognitive Science, 20, 137–194.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Keller</author>
</authors>
<title>The entropy rate principle as a predictor of processing effort: An evaluation against eye-tracking data. In</title>
<date>2004</date>
<booktitle>Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing</booktitle>
<pages>317--324</pages>
<editor>D. Lin &amp; D. Wu (Eds.),</editor>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Barcelona, Spain:</location>
<contexts>
<context position="1894" citStr="Keller, 2004" startWordPosition="294" endWordPosition="295">en speaking are remarkably difficult. Good performance at each one requires integrating a range of types of probabilistic information and making incremental predictions on the basis of noisy, incomplete input. Despite these requirements, empirical work has shown that humans perform very well (e.g., Tanenhaus, SpiveyKnowlton, Eberhard, &amp; Sedivy, 1995). Sophisticated models have been developed that explain many of these effects using the tools of computational linguistics and large-scale corpora to make normative predictions for optimal performance in these tasks (Genzel &amp; Charniak, 2002, 2003; Keller, 2004; Levy &amp; Jaeger, 2007; Jaeger, 2010). To the extent that the behavior of these models looks like human behavior, it suggests that humans are making rational use of all the information available to them in language processing. In the domain of incremental language comprehension, especially, there is a substantial amount of computational work suggesting that humans behave rationally (e.g., Jurafsky, 1996; Narayanan &amp; Jurafsky, 2001; Levy, 2008; Levy, Reali, &amp; Griffiths, 2009). Most of this work has taken as its task predicting the difficulty of each word in a sentence, a major result being that </context>
</contexts>
<marker>Keller, 2004</marker>
<rawString>Keller, F. (2004). The entropy rate principle as a predictor of processing effort: An evaluation against eye-tracking data. In D. Lin &amp; D. Wu (Eds.), Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing (pp. 317–324). Barcelona, Spain: Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G E Legge</author>
<author>T A Hooven</author>
<author>T S Klitz</author>
<author>J S Mansfield</author>
<author>B S Tjan</author>
</authors>
<title>new insights from an ideal-observer model of reading.</title>
<date>2002</date>
<journal>Mr. Chips</journal>
<volume>42</volume>
<pages>2219--2234</pages>
<contexts>
<context position="6431" citStr="Legge, Hooven, Klitz, Mansfield, &amp; Tjan, 2002" startWordPosition="1042" endWordPosition="1048">n the sentence only after processing the current word is complete, and (to slightly oversimplify), the eyes then follow the attentional shifts at some lag. SWIFT works similarly, but with the main difference being that processing and attention are distributed over multiple words, such that adjacent words can be identified in parallel. While both of these models provide a good fit to eye tracking data from reading, neither model asks the higher level question of what a rational solution to the problem would look like. The first model to ask this question, Mr. Chips (Legge, Klitz, &amp; Tjan, 1997; Legge, Hooven, Klitz, Mansfield, &amp; Tjan, 2002), predicts the optimal sequence of saccade targets to read a text based on a principle of minimizing the expected entropy in the distribution over identities of the current word. Unfortunately, however, the Mr. Chips model simplifies the problem of reading in a number of ways: First, it uses a unigram model as its language model, and thus fails to use any information in the linguistic context to help with word identification. Second, it only moves on to the next word after unambiguous identification of the current word, whereas there is experimental evidence that comprehenders maintain some u</context>
</contexts>
<marker>Legge, Hooven, Klitz, Mansfield, Tjan, 2002</marker>
<rawString>Legge, G. E., Hooven, T. A., Klitz, T. S., Mansfield, J. S., &amp; Tjan, B. S. (2002). Mr. Chips 2002: new insights from an ideal-observer model of reading. Vision Research, 42, 2219– 2234.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G E Legge</author>
<author>T S Klitz</author>
<author>B S Tjan</author>
</authors>
<title>Mr. Chips: an Ideal-Observer model of reading.</title>
<date>1997</date>
<journal>Psychological Review,</journal>
<volume>104</volume>
<pages>524--553</pages>
<contexts>
<context position="6384" citStr="Legge, Klitz, &amp; Tjan, 1997" startWordPosition="1037" endWordPosition="1041">attention to the next word in the sentence only after processing the current word is complete, and (to slightly oversimplify), the eyes then follow the attentional shifts at some lag. SWIFT works similarly, but with the main difference being that processing and attention are distributed over multiple words, such that adjacent words can be identified in parallel. While both of these models provide a good fit to eye tracking data from reading, neither model asks the higher level question of what a rational solution to the problem would look like. The first model to ask this question, Mr. Chips (Legge, Klitz, &amp; Tjan, 1997; Legge, Hooven, Klitz, Mansfield, &amp; Tjan, 2002), predicts the optimal sequence of saccade targets to read a text based on a principle of minimizing the expected entropy in the distribution over identities of the current word. Unfortunately, however, the Mr. Chips model simplifies the problem of reading in a number of ways: First, it uses a unigram model as its language model, and thus fails to use any information in the linguistic context to help with word identification. Second, it only moves on to the next word after unambiguous identification of the current word, whereas there is experimen</context>
</contexts>
<marker>Legge, Klitz, Tjan, 1997</marker>
<rawString>Legge, G. E., Klitz, T. S., &amp; Tjan, B. S. (1997). Mr. Chips: an Ideal-Observer model of reading. Psychological Review, 104, 524–553.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Levy</author>
</authors>
<title>A noisy-channel model of rational human sentence comprehension under uncertain input.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing</booktitle>
<pages>234--243</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Honolulu, Hawaii:</location>
<contexts>
<context position="2339" citStr="Levy, 2008" startWordPosition="364" endWordPosition="365">f computational linguistics and large-scale corpora to make normative predictions for optimal performance in these tasks (Genzel &amp; Charniak, 2002, 2003; Keller, 2004; Levy &amp; Jaeger, 2007; Jaeger, 2010). To the extent that the behavior of these models looks like human behavior, it suggests that humans are making rational use of all the information available to them in language processing. In the domain of incremental language comprehension, especially, there is a substantial amount of computational work suggesting that humans behave rationally (e.g., Jurafsky, 1996; Narayanan &amp; Jurafsky, 2001; Levy, 2008; Levy, Reali, &amp; Griffiths, 2009). Most of this work has taken as its task predicting the difficulty of each word in a sentence, a major result being that a large component of the difficulty of a word appears to be a function of its probability in context (Hale, 2001; Smith &amp; Levy, 2008). Much of the empirical basis for this work comes from studying reading, where word difficulty can be related to the amount of time that a reader spends on a particular word. To relate these predictions about word difficulty to the data obtained in eye tracking experiments, the eye movement record has been summ</context>
<context position="14957" citStr="Levy, 2008" startWordPosition="2484" endWordPosition="2485">rp contrast to other models, which treat the time course of word identification as an exogenous function of other influencing factors (such as word length, frequency, and predictability). The hope in our approach is that the influence of these key factors on the eye movement record will fall out as a natural consequence of rational behavior itself. For example, it is well known that the higher the conditional probability of a word given preceding material, the more rapidly that word is read (Boston, Hale, Kliegl, Patil, &amp; Vasishth, 2008; Demberg &amp; Keller, 2008; Ehrlich &amp; Rayner, 1981; Smith &amp; Levy, 2008). E-Z Reader and SWIFT incorporate this finding by specifying a dependency on word predictability in the exogenous function determining word processing time. In our framework, in contrast, we would expect such an effect to emerge as a byproduct of Bayesian inference: words with high prior probability (conditional on preceding fixations) will require less visual input to be reliably identified. An implemented model in this framework must formalize a number of pieces of the reading problem, including the possible actions available to the reader and their consequences, the nature of visual input,</context>
</contexts>
<marker>Levy, 2008</marker>
<rawString>Levy, R. (2008). A noisy-channel model of rational human sentence comprehension under uncertain input. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing (pp. 234–243). Honolulu, Hawaii: Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Levy</author>
<author>K Bicknell</author>
<author>T Slattery</author>
<author>K Rayner</author>
</authors>
<title>Eye movement evidence that readers maintain and act on uncertainty about past linguistic input.</title>
<date>2009</date>
<booktitle>Proceedings of the National Academy of Sciences,</booktitle>
<volume>106</volume>
<pages>21086--21090</pages>
<contexts>
<context position="11250" citStr="Levy, Bicknell, Slattery, &amp; Rayner, 2009" startWordPosition="1842" endWordPosition="1847">ns that arises as a result of word identification processes (unlike that of E-Z Reader) and can be understood as rational (unlike that of SWIFT). Whereas in SWIFT and E-Z Reader, word recognition is a process that takes some amount of time and is then ‘completed’, some experimental evidence suggests that word recognition may be best thought of as a process that is never ‘completed’, as comprehenders appear to both maintain uncertainty about the identity of previous input and to update that uncertainty as more information is gained about the rest of the sentence (Connine, Blasko, &amp; Hall, 1991; Levy, Bicknell, Slattery, &amp; Rayner, 2009). Thus, it is possible that later parts of a sentence can cause a reader’s confidence in the identity of the previous regions to fall. In these cases, a rational way to respond might be to make a between-word regressive saccade to get more visual information about the (now) low confidence previous region. To illustrate this idea, consider the case of a language composed of just two strings, AB and BA, and assume that the eyes can only get noisy information about the identity of one character at a time. After obtaining a little information about the identity of the first character, the reader </context>
</contexts>
<marker>Levy, Bicknell, Slattery, Rayner, 2009</marker>
<rawString>Levy, R., Bicknell, K., Slattery, T., &amp; Rayner, K. (2009). Eye movement evidence that readers maintain and act on uncertainty about past linguistic input. Proceedings of the National Academy of Sciences, 106, 21086–21090.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Levy</author>
<author>T F Jaeger</author>
</authors>
<title>Speakers optimize information density through syntactic reduction. In</title>
<date>2007</date>
<booktitle>Advances in Neural Information Processing Systems 19</booktitle>
<pages>849--856</pages>
<publisher>MIT Press.</publisher>
<location>Cambridge, MA:</location>
<contexts>
<context position="1915" citStr="Levy &amp; Jaeger, 2007" startWordPosition="296" endWordPosition="299">e remarkably difficult. Good performance at each one requires integrating a range of types of probabilistic information and making incremental predictions on the basis of noisy, incomplete input. Despite these requirements, empirical work has shown that humans perform very well (e.g., Tanenhaus, SpiveyKnowlton, Eberhard, &amp; Sedivy, 1995). Sophisticated models have been developed that explain many of these effects using the tools of computational linguistics and large-scale corpora to make normative predictions for optimal performance in these tasks (Genzel &amp; Charniak, 2002, 2003; Keller, 2004; Levy &amp; Jaeger, 2007; Jaeger, 2010). To the extent that the behavior of these models looks like human behavior, it suggests that humans are making rational use of all the information available to them in language processing. In the domain of incremental language comprehension, especially, there is a substantial amount of computational work suggesting that humans behave rationally (e.g., Jurafsky, 1996; Narayanan &amp; Jurafsky, 2001; Levy, 2008; Levy, Reali, &amp; Griffiths, 2009). Most of this work has taken as its task predicting the difficulty of each word in a sentence, a major result being that a large component of </context>
</contexts>
<marker>Levy, Jaeger, 2007</marker>
<rawString>Levy, R., &amp; Jaeger, T. F. (2007). Speakers optimize information density through syntactic reduction. In B. Schölkopf, J. Platt, &amp; T. Hoffman (Eds.), Advances in Neural Information Processing Systems 19 (pp. 849–856). Cambridge, MA: MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Levy</author>
<author>F Reali</author>
<author>T L Griffiths</author>
</authors>
<title>Modeling the effects of memory on human online sentence processing with particle filters. In</title>
<date>2009</date>
<booktitle>Advances in Neural Information Processing Systems</booktitle>
<volume>21</volume>
<pages>937--944</pages>
<contexts>
<context position="2371" citStr="Levy, Reali, &amp; Griffiths, 2009" startWordPosition="366" endWordPosition="371">nal linguistics and large-scale corpora to make normative predictions for optimal performance in these tasks (Genzel &amp; Charniak, 2002, 2003; Keller, 2004; Levy &amp; Jaeger, 2007; Jaeger, 2010). To the extent that the behavior of these models looks like human behavior, it suggests that humans are making rational use of all the information available to them in language processing. In the domain of incremental language comprehension, especially, there is a substantial amount of computational work suggesting that humans behave rationally (e.g., Jurafsky, 1996; Narayanan &amp; Jurafsky, 2001; Levy, 2008; Levy, Reali, &amp; Griffiths, 2009). Most of this work has taken as its task predicting the difficulty of each word in a sentence, a major result being that a large component of the difficulty of a word appears to be a function of its probability in context (Hale, 2001; Smith &amp; Levy, 2008). Much of the empirical basis for this work comes from studying reading, where word difficulty can be related to the amount of time that a reader spends on a particular word. To relate these predictions about word difficulty to the data obtained in eye tracking experiments, the eye movement record has been summarized through word aggregate me</context>
</contexts>
<marker>Levy, Reali, Griffiths, 2009</marker>
<rawString>Levy, R., Reali, F., &amp; Griffiths, T. L. (2009). Modeling the effects of memory on human online sentence processing with particle filters. In D. Koller, D. Schuurmans, Y. Bengio, &amp; L. Bottou (Eds.), Advances in Neural Information Processing Systems 21 (pp. 937–944).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Mohri</author>
</authors>
<title>Finite-state transducers in language and speech processing.</title>
<date>1997</date>
<journal>Computational Linguistics,</journal>
<volume>23</volume>
<pages>269--311</pages>
<contexts>
<context position="26679" citStr="Mohri, 1997" startWordPosition="4797" endWordPosition="4798">e to the closest such position (2b). If m(j) &gt; P for all j &lt; Ei, then the model initiates a saccade to n characters past the closest position to the right j &gt; Ei for which m(j) &lt; a (2c).3 Finally, if no such positions exist to the right, the model stops reading the sentence (2d). Intuitively, then, the model reads by making a rightward sweep to bring its confidence in each character up to a, but pauses to move left if confidence in a previous character falls below P. 4.5 Implementation with wFSAs This model can be efficiently and simply implemented using weighted finite-state automata (wFSAs; Mohri, 1997) as follows: First, we begin with a wFSA representation of the language model, where each arc emits a single character (or is an epsilon-transition emitting nothing). To perform belief update given a new visual input, we create a new wFSA to represent the likelihood of each character from the sample. Specifically, this wFSA has only a single chain of states, where, e.g., the first and second state in the chain are connected by 27 (or fewer) arcs, which emit each of 3The role of n is to ensure that the model does not center its visual field on the first uncertain character. We did not attempt t</context>
</contexts>
<marker>Mohri, 1997</marker>
<rawString>Mohri, M. (1997). Finite-state transducers in language and speech processing. Computational Linguistics, 23, 269–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Narayanan</author>
<author>D Jurafsky</author>
</authors>
<title>A Bayesian model predicts human parse preference and reading time in sentence processing. In</title>
<date>2001</date>
<booktitle>Advances in Neural Information Processing Systems 14</booktitle>
<pages>59--65</pages>
<publisher>MIT Press.</publisher>
<location>Cambridge, MA:</location>
<contexts>
<context position="2327" citStr="Narayanan &amp; Jurafsky, 2001" startWordPosition="360" endWordPosition="363">se effects using the tools of computational linguistics and large-scale corpora to make normative predictions for optimal performance in these tasks (Genzel &amp; Charniak, 2002, 2003; Keller, 2004; Levy &amp; Jaeger, 2007; Jaeger, 2010). To the extent that the behavior of these models looks like human behavior, it suggests that humans are making rational use of all the information available to them in language processing. In the domain of incremental language comprehension, especially, there is a substantial amount of computational work suggesting that humans behave rationally (e.g., Jurafsky, 1996; Narayanan &amp; Jurafsky, 2001; Levy, 2008; Levy, Reali, &amp; Griffiths, 2009). Most of this work has taken as its task predicting the difficulty of each word in a sentence, a major result being that a large component of the difficulty of a word appears to be a function of its probability in context (Hale, 2001; Smith &amp; Levy, 2008). Much of the empirical basis for this work comes from studying reading, where word difficulty can be related to the amount of time that a reader spends on a particular word. To relate these predictions about word difficulty to the data obtained in eye tracking experiments, the eye movement record h</context>
</contexts>
<marker>Narayanan, Jurafsky, 2001</marker>
<rawString>Narayanan, S., &amp; Jurafsky, D. (2001). A Bayesian model predicts human parse preference and reading time in sentence processing. In T. Dietterich, S. Becker, &amp; Z. Ghahramani (Eds.), Advances in Neural Information Processing Systems 14 (pp. 59–65). Cambridge, MA: MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Y Ng</author>
<author>M Jordan</author>
</authors>
<title>PEGASUS: A policy search method for large MDPs and POMDPs.</title>
<date>2000</date>
<booktitle>In Uncertainty in Artificial Intelligence, Proceedings of the Sixteenth Conference</booktitle>
<pages>406--415</pages>
<contexts>
<context position="33912" citStr="Ng &amp; Jordan, 2000" startWordPosition="6067" endWordPosition="6070"> and T is the total number of timesteps before the model decided to stop reading. Thus, each different performance measure is determined by the weighting for time y. We test three values of y E 1.025,.1,.4}. The first of these weights accuracy highly, while the final one weights 1 timestep almost as much as 1 unit of log probability. 6.1.2 Optimization of policy parameters Searching directly for optimal values of a and P for our stochastic reading model is difficult because each evaluation of the model with a particular set of parameters produces a different result. We use the PEGASUS method (Ng &amp; Jordan, 2000) to transform this stochastic optimization problem into a deterministic one on which we can use standard optimization algorithms.5 Then, we evaluate the model’s performance at each value of a and P by reading the full test corpus and averaging performance. We then simply use coordinate ascent (in logit space) to find the optimal values of a and P for each performance measure. 6.1.3 Language model The language model used in this simulation begins with the same vocabulary set as in Sim. 1, i.e., the 500 most frequent words in the BNC and every word that occurs in our test corpus. Because the sea</context>
</contexts>
<marker>Ng, Jordan, 2000</marker>
<rawString>Ng, A. Y., &amp; Jordan, M. (2000). PEGASUS: A policy search method for large MDPs and POMDPs. In Uncertainty in Artificial Intelligence, Proceedings of the Sixteenth Conference (pp. 406–415).</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Norris</author>
</authors>
<title>The Bayesian reader: Explaining word recognition as an optimal Bayesian decision process.</title>
<date>2006</date>
<journal>Psychological Review,</journal>
<volume>113</volume>
<pages>327--357</pages>
<contexts>
<context position="22629" citStr="Norris (2006" startWordPosition="4061" endWordPosition="4062">26 letters of English for the letter a. 4.2.2 Foveal visual input In addition, for those eccentricities with a processing rate proportion λ(ε) that is at least 1% of the total processing rate (ε E [−5,8]) the model receives foveal visual input, defined only for letters2 to give noisy information about the letter’s identity. This threshold of 1% roughly corresponds to estimates that readers get information useful for letter identification from about 4 characters to the left and 8 to the right of fixation (Rayner, 1998). In our model, each letter is equally confusable with all others, following Norris (2006, 2009), but ignoring work on letter confusability (which could be added to future model revisions; Engel, Dougherty, &amp; Jones, 1973; Geyer, 1977). Visual information about each character is obtained by sampling. Specifically, we represent each letter as a 26-dimensional vector, where a single element is 1 and the other 25 are zeros, and given this representation, foveal input for a letter is given as a sample from a 26-dimensional Gaussian with a 2For white space, the model is already certain of the identity because of peripheral input. λ(ε) = IS ε+.5 1 x2 −.5 Z ( ) σL, x &lt; 0 exp - 2σ2 dx, σ =</context>
</contexts>
<marker>Norris, 2006</marker>
<rawString>Norris, D. (2006). The Bayesian reader: Explaining word recognition as an optimal Bayesian decision process. Psychological Review, 113, 327– 357.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Norris</author>
</authors>
<title>Putting it all together: A unified account of word recognition and reaction-time distributions.</title>
<date>2009</date>
<journal>Psychological Review,</journal>
<volume>116</volume>
<pages>207--219</pages>
<marker>Norris, 2009</marker>
<rawString>Norris, D. (2009). Putting it all together: A unified account of word recognition and reaction-time distributions. Psychological Review, 116, 207– 219.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Rayner</author>
</authors>
<title>Eye movements in reading and information processing: 20 years of research.</title>
<date>1998</date>
<journal>Psychological Bulletin,</journal>
<volume>124</volume>
<pages>372--422</pages>
<contexts>
<context position="3628" citStr="Rayner, 1998" startWordPosition="591" endWordPosition="592">irst fixation on a word, or the amount of time between when a word is first fixated and when the eyes move to its right (‘go-past time’). It is important to note that this notion of word difficulty is an abstraction over the actual task of reading, which is made up of more fine-grained decisions about how long to leave the eyes in their current position, and where to move them next, producing the series of relatively stable periods (fixations) and movements (saccades) that characterize the eye tracking record. While there has been much empirical work on reading at this fine-grained scale (see Rayner, 1998 for an overview), and there are a number of successful models (Reichle, Pollatsek, &amp; Rayner, 2006; Engbert, Nuthmann, Richter, &amp; Kliegl, 2005), little is known about the extent to which human reading behavior appears to be rational at this finer 1168 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1168–1178, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics grained scale. In this paper, we present a new rational model of eye movement control in reading, the central assumption of which is that eye movement decision</context>
<context position="5485" citStr="Rayner, 1998" startWordPosition="886" endWordPosition="887">t do not. In Simulation 1, we show that specific regressive policies outperform specific non-regressive policies, and in Simulation 2, we use optimization to directly find optimal policies for three performance measures. The results show that the regressive policies outperform non-regressive policies across a wide range of performance measures, demonstrating that our model predicts that making between-word regressions is a rational strategy for reading. 2 Models of eye movements in reading The two most successful models of eye movements in reading are E-Z Reader (Reichle, Pollatsek, Fisher, &amp; Rayner, 1998; Reichle et al., 2006) and SWIFT (Engbert, Longtin, &amp; Kliegl, 2002; Engbert et al., 2005). Both of these models characterize the problem of reading as one of word identification. In E-Z Reader, for example, the system identifies each word in the sentence serially, moving attention to the next word in the sentence only after processing the current word is complete, and (to slightly oversimplify), the eyes then follow the attentional shifts at some lag. SWIFT works similarly, but with the main difference being that processing and attention are distributed over multiple words, such that adjacent</context>
<context position="21838" citStr="Rayner, 1998" startWordPosition="3930" endWordPosition="3931">pheral input giving word boundary information and foveal input giving information about letter identity. 4.2.1 Peripheral visual input In our model, any eccentricity with a processing rate proportion λ(ε) at least 0.5% of the rate proportion for the centrally fixated character (ε E [−7,12]), yields peripheral visual input, defined as veridical word boundary information indicating whether each character is a letter or a space. This roughly corresponds to empirical estimates that humans obtain useful information in reading from about 19 characters, more from the right of fixation than the left (Rayner, 1998). Hence in Figure 1, for example, left-peripheral visual input can be represented as veridical knowledge of the initial whitespace (denoted ), and a uniform distribution over the 26 letters of English for the letter a. 4.2.2 Foveal visual input In addition, for those eccentricities with a processing rate proportion λ(ε) that is at least 1% of the total processing rate (ε E [−5,8]) the model receives foveal visual input, defined only for letters2 to give noisy information about the letter’s identity. This threshold of 1% roughly corresponds to estimates that readers get information useful for l</context>
</contexts>
<marker>Rayner, 1998</marker>
<rawString>Rayner, K. (1998). Eye movements in reading and information processing: 20 years of research. Psychological Bulletin, 124, 372–422.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E D Reichle</author>
<author>P A Laurent</author>
</authors>
<title>Using reinforcement learning to understand the emergence of “intelligent” eye-movement behavior during reading.</title>
<date>2006</date>
<journal>Psychological Review,</journal>
<volume>113</volume>
<pages>390--408</pages>
<contexts>
<context position="7640" citStr="Reichle and Laurent (2006)" startWordPosition="1246" endWordPosition="1249">s maintain some uncertainty about the word identities. In other work, we have extended the Mr. Chips model to remove these two limitations, and show that the resulting model more closely matches human performance (Bicknell &amp; Levy, 2010). The larger problem, however, is that each of these models uses an unrealistic model of visual input, which obtains absolute knowledge of the characters in its visual window. Thus, there is no reason for the model to spend longer on one fixation than another, and the model only makes predictions for where saccades are targeted, and not how long fixations last. Reichle and Laurent (2006) presented a rational model that overcame the limitations of Mr. Chips to produce predictions for both fixation durations and locations, focusing on the ways in which eye movement behavior is an adaptive response to the particular constraints of the task of reading. Given this focus, Reichle and Laurent used a very simple word identification function, for which the time required to identify a word was a function only of its length and the relative position of the eyes. In this paper, we present another rational model of eye movement control in reading that, like Reichle and Laurent, makes pred</context>
</contexts>
<marker>Reichle, Laurent, 2006</marker>
<rawString>Reichle, E. D., &amp; Laurent, P. A. (2006). Using reinforcement learning to understand the emergence of “intelligent” eye-movement behavior during reading. Psychological Review, 113, 390–408.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E D Reichle</author>
<author>A Pollatsek</author>
<author>D L Fisher</author>
<author>K Rayner</author>
</authors>
<title>Toward a model of eye movement control in reading.</title>
<date>1998</date>
<journal>Psychological Review,</journal>
<volume>105</volume>
<pages>125--157</pages>
<contexts>
<context position="5485" citStr="Reichle, Pollatsek, Fisher, &amp; Rayner, 1998" startWordPosition="881" endWordPosition="887"> make regressions to those that do not. In Simulation 1, we show that specific regressive policies outperform specific non-regressive policies, and in Simulation 2, we use optimization to directly find optimal policies for three performance measures. The results show that the regressive policies outperform non-regressive policies across a wide range of performance measures, demonstrating that our model predicts that making between-word regressions is a rational strategy for reading. 2 Models of eye movements in reading The two most successful models of eye movements in reading are E-Z Reader (Reichle, Pollatsek, Fisher, &amp; Rayner, 1998; Reichle et al., 2006) and SWIFT (Engbert, Longtin, &amp; Kliegl, 2002; Engbert et al., 2005). Both of these models characterize the problem of reading as one of word identification. In E-Z Reader, for example, the system identifies each word in the sentence serially, moving attention to the next word in the sentence only after processing the current word is complete, and (to slightly oversimplify), the eyes then follow the attentional shifts at some lag. SWIFT works similarly, but with the main difference being that processing and attention are distributed over multiple words, such that adjacent</context>
</contexts>
<marker>Reichle, Pollatsek, Fisher, Rayner, 1998</marker>
<rawString>Reichle, E. D., Pollatsek, A., Fisher, D. L., &amp; Rayner, K. (1998). Toward a model of eye movement control in reading. Psychological Review, 105, 125–157.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E D Reichle</author>
<author>A Pollatsek</author>
<author>K Rayner</author>
</authors>
<title>E-Z Reader: A cognitive-control, serialattention model of eye-movement behavior during reading.</title>
<date>2006</date>
<journal>Cognitive Systems Research,</journal>
<volume>7</volume>
<pages>22</pages>
<contexts>
<context position="3726" citStr="Reichle, Pollatsek, &amp; Rayner, 2006" startWordPosition="604" endWordPosition="608">fixated and when the eyes move to its right (‘go-past time’). It is important to note that this notion of word difficulty is an abstraction over the actual task of reading, which is made up of more fine-grained decisions about how long to leave the eyes in their current position, and where to move them next, producing the series of relatively stable periods (fixations) and movements (saccades) that characterize the eye tracking record. While there has been much empirical work on reading at this fine-grained scale (see Rayner, 1998 for an overview), and there are a number of successful models (Reichle, Pollatsek, &amp; Rayner, 2006; Engbert, Nuthmann, Richter, &amp; Kliegl, 2005), little is known about the extent to which human reading behavior appears to be rational at this finer 1168 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1168–1178, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics grained scale. In this paper, we present a new rational model of eye movement control in reading, the central assumption of which is that eye movement decisions are made to obtain noisy visual information, which the reader uses in Bayesian inference about t</context>
<context position="5508" citStr="Reichle et al., 2006" startWordPosition="888" endWordPosition="891">imulation 1, we show that specific regressive policies outperform specific non-regressive policies, and in Simulation 2, we use optimization to directly find optimal policies for three performance measures. The results show that the regressive policies outperform non-regressive policies across a wide range of performance measures, demonstrating that our model predicts that making between-word regressions is a rational strategy for reading. 2 Models of eye movements in reading The two most successful models of eye movements in reading are E-Z Reader (Reichle, Pollatsek, Fisher, &amp; Rayner, 1998; Reichle et al., 2006) and SWIFT (Engbert, Longtin, &amp; Kliegl, 2002; Engbert et al., 2005). Both of these models characterize the problem of reading as one of word identification. In E-Z Reader, for example, the system identifies each word in the sentence serially, moving attention to the next word in the sentence only after processing the current word is complete, and (to slightly oversimplify), the eyes then follow the attentional shifts at some lag. SWIFT works similarly, but with the main difference being that processing and attention are distributed over multiple words, such that adjacent words can be identifie</context>
</contexts>
<marker>Reichle, Pollatsek, Rayner, 2006</marker>
<rawString>Reichle, E. D., Pollatsek, A., &amp; Rayner, K. (2006). E-Z Reader: A cognitive-control, serialattention model of eye-movement behavior during reading. Cognitive Systems Research, 7, 4– 22.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E D Reichle</author>
<author>T Warren</author>
<author>K McConnell</author>
</authors>
<title>Using E-Z Reader to model the effects of higher level language processing on eye movements during reading.</title>
<date>2009</date>
<journal>Psychonomic Bulletin &amp; Review,</journal>
<volume>16</volume>
<pages>1--21</pages>
<contexts>
<context position="9616" citStr="Reichle, Warren, &amp; McConnell, 2009" startWordPosition="1572" endWordPosition="1576">n the sentence (generally) left to right, and that identification of a word in these models takes a certain amount of time and then is completed. In such a setup, why should the eyes ever move backwards? Three major answers have been put forward. One possibility given by E-Z Reader is as a response to overshoot; i.e., the eyes move backwards to a previous word because they accidentally landed further forward than intended due to motor error. Such an explanation could only account for small between-word regressions, of about the magnitude of motor error. The most recent version, E-Z Reader 10 (Reichle, Warren, &amp; McConnell, 2009), has a new component that can produce longer between-word regressions. Specifically, the model includes a flag for postlexical integration failure, that – when triggered – will instruct the model to produce a between-word regression to the site of the failure. That is, between-word regressions in E-Z Reader 10 can arise because of postlexical processes external to the model’s main task of word identification. A final explanation for between-word regressions, which arises as a result of normal processes of word identification, comes from the SWIFT model. In the SWIFT model, the reader can fai</context>
</contexts>
<marker>Reichle, Warren, McConnell, 2009</marker>
<rawString>Reichle, E. D., Warren, T., &amp; McConnell, K. (2009). Using E-Z Reader to model the effects of higher level language processing on eye movements during reading. Psychonomic Bulletin &amp; Review, 16, 1–21.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H E H Schilling</author>
<author>K Rayner</author>
<author>J I Chumbley</author>
</authors>
<title>Comparing naming, lexical decision, and eye fixation times: Word frequency effects and individual differences.</title>
<date>1998</date>
<journal>Memory &amp; Cognition,</journal>
<volume>26</volume>
<pages>1270--1281</pages>
<contexts>
<context position="30884" citStr="Schilling, Rayner, &amp; Chumbley, 1998" startWordPosition="5537" endWordPosition="5541">anslating the bigram model into a wFSA in the log semiring. We then composed this wFSA with a weighted finitestate transducer (wFST) breaking words down into characters. This was done in order to facilitate simple composition with the visual likelihood wFSA defined over characters. In the Monte Carlo estimation of m, we used 5000 samples from the wFSA. Finally, to speed performance, we bounded the wFSA to have exactly the number of characters present in the actual sentence and then renormalized. 5.1.4 Test corpus We tested our model’s performance by simulating reading of the Schilling corpus (Schilling, Rayner, &amp; Chumbley, 1998). To ensure that our results did not depend on smoothing, we only tested the model on sentences in which every bigram occurred in the BNC. Unfortunately, only 8 of the 48 sentences in the corpus met this criterion. Thus, we made single-word changes to 25 more of the sentences (mostly changing proper names and rare nouns) to produce a total of 33 sentences to read, for which every bigram did occur in the BNC. 5.2 Results and discussion For each policy we tested, we measured the average number of timesteps it took to read the sentences, as well as the average (natural) log probability of the co</context>
</contexts>
<marker>Schilling, Rayner, Chumbley, 1998</marker>
<rawString>Schilling, H. E. H., Rayner, K., &amp; Chumbley, J. I. (1998). Comparing naming, lexical decision, and eye fixation times: Word frequency effects and individual differences. Memory &amp; Cognition, 26, 1270–1281.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N J Smith</author>
<author>R Levy</author>
</authors>
<title>Optimal processing times in reading: a formal model and empirical investigation. In</title>
<date>2008</date>
<booktitle>Proceedings of the 30th Annual Conference of the Cognitive Science Society</booktitle>
<pages>595--600</pages>
<publisher>Cognitive Science Society.</publisher>
<location>Austin, TX:</location>
<contexts>
<context position="2627" citStr="Smith &amp; Levy, 2008" startWordPosition="417" endWordPosition="420">t suggests that humans are making rational use of all the information available to them in language processing. In the domain of incremental language comprehension, especially, there is a substantial amount of computational work suggesting that humans behave rationally (e.g., Jurafsky, 1996; Narayanan &amp; Jurafsky, 2001; Levy, 2008; Levy, Reali, &amp; Griffiths, 2009). Most of this work has taken as its task predicting the difficulty of each word in a sentence, a major result being that a large component of the difficulty of a word appears to be a function of its probability in context (Hale, 2001; Smith &amp; Levy, 2008). Much of the empirical basis for this work comes from studying reading, where word difficulty can be related to the amount of time that a reader spends on a particular word. To relate these predictions about word difficulty to the data obtained in eye tracking experiments, the eye movement record has been summarized through word aggregate measures, such as the average duration of the first fixation on a word, or the amount of time between when a word is first fixated and when the eyes move to its right (‘go-past time’). It is important to note that this notion of word difficulty is an abstrac</context>
<context position="14957" citStr="Smith &amp; Levy, 2008" startWordPosition="2482" endWordPosition="2485">s in sharp contrast to other models, which treat the time course of word identification as an exogenous function of other influencing factors (such as word length, frequency, and predictability). The hope in our approach is that the influence of these key factors on the eye movement record will fall out as a natural consequence of rational behavior itself. For example, it is well known that the higher the conditional probability of a word given preceding material, the more rapidly that word is read (Boston, Hale, Kliegl, Patil, &amp; Vasishth, 2008; Demberg &amp; Keller, 2008; Ehrlich &amp; Rayner, 1981; Smith &amp; Levy, 2008). E-Z Reader and SWIFT incorporate this finding by specifying a dependency on word predictability in the exogenous function determining word processing time. In our framework, in contrast, we would expect such an effect to emerge as a byproduct of Bayesian inference: words with high prior probability (conditional on preceding fixations) will require less visual input to be reliably identified. An implemented model in this framework must formalize a number of pieces of the reading problem, including the possible actions available to the reader and their consequences, the nature of visual input,</context>
</contexts>
<marker>Smith, Levy, 2008</marker>
<rawString>Smith, N. J., &amp; Levy, R. (2008). Optimal processing times in reading: a formal model and empirical investigation. In B. C. Love, K. McRae, &amp; V. M. Sloutsky (Eds.), Proceedings of the 30th Annual Conference of the Cognitive Science Society (pp. 595–600). Austin, TX: Cognitive Science Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M K Tanenhaus</author>
<author>M J Spivey-Knowlton</author>
<author>K M Eberhard</author>
<author>J C Sedivy</author>
</authors>
<title>Integration of visual and linguistic information in spoken language comprehension.</title>
<date>1995</date>
<journal>Science,</journal>
<volume>268</volume>
<pages>1634</pages>
<marker>Tanenhaus, Spivey-Knowlton, Eberhard, Sedivy, 1995</marker>
<rawString>Tanenhaus, M. K., Spivey-Knowlton, M. J., Eberhard, K. M., &amp; Sedivy, J. C. (1995). Integration of visual and linguistic information in spoken language comprehension. Science, 268, 1632– 1634.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>