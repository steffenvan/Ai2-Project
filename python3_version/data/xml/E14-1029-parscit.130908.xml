<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001341">
<title confidence="0.998117">
Iterative Constrained Clustering for Subjectivity Word Sense
Disambiguation
</title>
<author confidence="0.995914">
Cem Akkaya, Janyce Wiebe
</author>
<affiliation confidence="0.8565485">
University of Pittsburgh
Pittsburgh PA, 15260, USA
</affiliation>
<email confidence="0.999504">
{cem,wiebe}@cs.pitt.edu
</email>
<sectionHeader confidence="0.997405" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999572055555556">
Subjectivity word sense disambiguation
(SWSD) is a supervised and application-
specific word sense disambiguation task
disambiguating between subjective and
objective senses of a word. Not sur-
prisingly, SWSD suffers from the knowl-
edge acquisition bottleneck. In this work,
we use a “cluster and label” strategy to
generate labeled data for SWSD semi-
automatically. We define a new algo-
rithm called Iterative Constrained Cluster-
ing (ICC) to improve the clustering purity
and, as a result, the quality of the gener-
ated data. Our experiments show that the
SWSD classifiers trained on the ICC gen-
erated data by requiring only 59% of the
labels can achieve the same performance
as the classifiers trained on the full dataset.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.955416111111111">
Subjectivity lexicons (e.g., (Turney, 2002;
Whitelaw et al., 2005; Riloff and Wiebe, 2003; Yu
and Hatzivassiloglou, 2003; Kim and Hovy, 2004;
Bloom et al., 2007; Andreevskaia and Bergler,
2008; Agarwal et al., 2009)) play an important
role in opinion, sentiment, and subjectivity
analysis. These systems typically look for the
presence of clues in text. Recently, in (Akkaya
et al., 2009), we showed that subjectivity clues
are fairly ambiguous as to whether they express
subjectivity or not – words in such lexicons may
have both subjective and objective usages. We
call this problem subjectivity sense ambiguity.
Consider the following sentence containing the
clue “attack”:
(1) He was attacked by Milosevic for at-
tempting to carve out a new party from the
Socialists.
</bodyText>
<author confidence="0.660757">
Rada Mihalcea
</author>
<affiliation confidence="0.964112">
University of North Texas
</affiliation>
<address confidence="0.556091">
Denton TX, 76207, USA
</address>
<email confidence="0.987485">
rada@cs.unt.edu
</email>
<bodyText confidence="0.9993356">
Knowing that “attack” is a subjectivity clue with
negative polarity will help a system recognize the
negative sentiment in the sentence. But for (2), the
same information is simply misleading, because
the clue is used with an objective meaning.
</bodyText>
<listItem confidence="0.6218255">
(2) A new treatment based on training T-cells
to attack cancerous cells ...
</listItem>
<bodyText confidence="0.998461242424243">
Any opinion analysis system which relies on a
subjectivity lexicon will be misled by subjectiv-
ity clues used with objective senses (false hits).
In (Akkaya et al., 2009), we introduced the task,
Subjectivity Word Sense Disambiguation, which is
to automatically determine which word instances
in a corpus are being used with subjective senses,
and which are being used with objective senses.
SWSD can be considered as a coarse-grained
and application-specific word sense disambigua-
tion task. We showed that sense subjectivity in-
formation about clues can be fed to subjectiv-
ity and sentiment analysis resulting in substantial
improvement for both subjectivity and sentiment
analysis by avoiding false hits.
Although SWSD is a promising tool, it suf-
fers from the knowledge acquisition bottleneck.
SWSD is defined as a supervised task, and fol-
lows a targeted approach common in the WSD lit-
erature for performance reasons. This means, for
each target clue, a different classifier is trained re-
quiring separate training data for each target clue.
It is expensive and time-consuming to obtain an-
notated datasets to train SWSD classifiers limit-
ing scalability. As a countermeasure, in (Akkaya
et al., 2011), we showed that non-expert annota-
tions collected through Amazon Mechanical Turk
(MTurk) can replace expert annotations success-
fully and might be used to apply SWSD on a large
scale.
Although non-expert annotations are cheap and
fast, they still incur some cost. In this work, we
aim to reduce the human annotation effort needed
</bodyText>
<page confidence="0.977176">
269
</page>
<note confidence="0.9929345">
Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 269–278,
Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.999884047619048">
to generate the same amount of subjectivity sense
tagged data by using a “cluster and label” strategy.
We hypothesize that we can obtain large sets of
labeled data by labelling clusters of instances of a
target word instead of single instances.
The main contribution of this work is a novel
constrained clustering algorithm called Iterative
Constrained Clustering (ICC) utilizing an active
constraint selection strategy. A secondary con-
tribution is a mixed word representation that is a
combination of previously proposed context rep-
resentations. We show that a “cluster and label”
strategy relying on these two proposed compo-
nents generates training data of good purity. The
resulting data has sufficient purity to train reli-
able SWSD classifiers. SWSD classifiers trained
on only 59% of the data achieve the same perfor-
mance as classifiers trained on 100% of the data,
resulting in a significant reduction in the annota-
tion effort. Our results take SWSD another step
closer to large scale application.
</bodyText>
<sectionHeader confidence="0.958358" genericHeader="introduction">
2 Cluster and Label
</sectionHeader>
<bodyText confidence="0.999568235294118">
Our approach is inspired by a method lexicogra-
phers commonly employ to create sense invento-
ries, where they create inventories based on ev-
idence found in corpora. They use concordance
information to mine frequent usage patterns. (Kil-
garriff, 1997) describes this process in detail. A
lexicographer collects usages of a word in cor-
pora and groups them into coherent sets. The in-
stances in a set should have more in common with
each other than with the instances in other sets,
according to the criteria the lexicographer consid-
ers. After generating the sets, the lexicographer
codes each set as a dictionary definition based on
the common attributes of the instances. Our goal
is similar. Instead of generating dictionary defini-
tions, we are only interested in generating coher-
ent sets of usages of a word, so that we can label
each induced set – with its instances – to obtain
labeled data for SWSD. Our high-level grouping
criterion is that the instances in a cluster should be
similar subjective (objective) usages of the word.
Training data for an SWSD classifier consists
of instances of the target word tagged as having
a subjective sense (S) or an objective sense (O)
(subjectivity sense tagged data). We train a dif-
ferent SWSD classifier for each target word as in
(Akkaya et al., 2009). Thus, we need a different
training dataset for each target word. Our ultimate
goal is to reduce the human annotation effort re-
quired to create training data for SWSD classifiers.
For this purpose, we utilize a “cluster and label”
strategy relying on context clustering. Each in-
stance of a word is represented as a feature vector
(i.e., a context vector). The annotation process has
the following steps: (1) cluster the context vectors
of word instances, (2) label the induced clusters
as S or O, (3) propagate the given label to all in-
stances in a cluster.
The induced clusters represent different usage
patterns of a word. Thus, we build more than two
clusters, even though SWSD is a binary task. This
implies that two different instances of a word can
both be subjective, but end up in different clusters,
if they are different usages of the word.
Since we are labelling clusters as a whole, we
will introduce noise in the labeled data. Thus, in
developing the clustering process, we need to min-
imize that noise and find as pure clusters as possi-
ble.
The first step is to define the context representa-
tion of the instances. This is addressed in Section
3. Then, we turn in Section 4.2 to the clustering
process itself.
To evaluate our “cluster and label” strategy, we
use two gold standard subjectivity sense tagged
datasets. 1. The first one is called senSWSD gen-
erated in (Akkaya et al., 2009) and the second
one is called mturkSWSD generated in (Akkaya
et al., 2011). They consist of subjectivity sense
tagged data for disjoint sets of 39 and 90 words,
respectively. In this paper, we opt to use the
smaller dataset senSWSD as our development set,
on which we evaluate various context representa-
tions (in Section 3) and our proposed constrained
clustering algorithm (in Section 4.2). Then, on
mturkSWSD, we evaluate the quality of semi-
automatically generated data for SWSD classifi-
cation (in Section 4.3.2).
</bodyText>
<sectionHeader confidence="0.974751" genericHeader="method">
3 Context Representations
</sectionHeader>
<bodyText confidence="0.990939285714286">
There has been much work on context representa-
tions of words for various NLP tasks. Clustering
word instances in order to discriminate senses of
a word is called Word Sense Discrimination. Con-
text representations for this task rely on two main
types of models: distributional semantic models
(DSM) and feature-based models.
</bodyText>
<footnote confidence="0.9980355">
1Available at http://mpqa.cs.pitt.edu/
corpora
</footnote>
<page confidence="0.996543">
270
</page>
<bodyText confidence="0.998525">
(Schutze, 1998), which is still a competi-
tive model for word-sense discrimination by con-
text clustering, relies on a distributional semantic
model (DSM) (Turney and Pantel, 2010; Sahlgren,
2006; Bullinaria and Levy, 2007). A DSM is usu-
ally a word-to-word co-occurrence matrix – also
called semantic space – such that each row repre-
sents the distribution of a target word in a large
text corpus. Each row gives the semantic sig-
nature of a word, which is basically a high di-
mensional numeric vector. Note that this high di-
mensional vector represents word types, not word
tokens. Thus, it cannot model a word instance
in context. For token-based treatment, (Schutze,
1998) utilizes a second-order representation by av-
eraging co-occurrence vectors of the words (cor-
responding to rows of the co-occurrence matrix)
that occur in that particular context. It is impor-
tant to note that (Schutze, 1998) uses an addi-
tive model for compositional representation. Re-
cently, in (Akkaya et al., 2012), we found that a
DSM built using multiplicative composition – pro-
posed by (Mitchell and Lapata, 2010) for a differ-
ent task – gives better performance than the model
described by (Schutze, 1998).
We test both methods in this paper, using the
same semantic space. The space is built from a
corpus consisting of 120 million tokens. The rows
of the space correspond to word forms and the
columns correspond to word lemmas present in the
corpus. We adopt the parameters for our semantic
space from (Mitchell and Lapata, 2010): window
size of 10 and dimension size of 2000 (i.e., the
2000 most frequent lemmas). We do not filter out
stop words, since they have been shown to be use-
ful for various semantic similarity tasks in (Bulli-
naria and Levy, 2007). We use positive point-wise
mutual information to compute values of the vec-
tor components, which has also been shown to be
favourable in (Bullinaria and Levy, 2007).
Purandere and Pedersen is the prominent repre-
sentative of feature-based models. (Purandare and
Pedersen, 2004) creates context vectors from local
feature representations similar to the feature vec-
tors found in supervised WSD. In this work, we
use the following features from (Mihalcea, 2002)
to build the local feature representation: (1) the
target word itself and its part of speech, (2) sur-
rounding context of 3 words and their part of
speech, (3) the head of the noun phrase, (4) the
first noun and verb before the target word, (5) the
first noun and verb after the target word.
skew local dsm add dsm mul mix rep
average 79.90 80.50 80.50 83.53 85.23
appear-v 53.83 54.85 54.85 57.40 69.39
fine-a 70.07 72.26 70.07 74.45 75.18
interest-n 54.41 54.78 55.88 81.62 81.62
restraint-n 70.45 71.97 75.00 71.21 81.82
</bodyText>
<tableCaption confidence="0.999323">
Table 1: Evaluation of Various Context Representations
</tableCaption>
<subsectionHeader confidence="0.99989">
3.1 Evaluation of Context Representations
</subsectionHeader>
<bodyText confidence="0.99997556097561">
In this section, we evaluate context representations
for the context clustering task on the subjectivity
sense tagged data, senSWSD. The evaluation is
done separately for each word.
We use the same clustering algorithm for all
context representations: agglomerative hierarchi-
cal clustering with average linkage criteria. In all
our experiments throughout the paper, we fix the
cluster size to 7 as it is done in (Purandare and
Pedersen, 2004). We think that is reasonable num-
ber since SENSEVAL III reports that the average
number of senses per word is 6.47. We choose
cluster purity as our evaluation metric. To com-
pute cluster purity, we assign each cluster to a
sense label, which is the most frequent one in the
cluster. The number of the correctly assigned in-
stances divided by the number of all the clustered
instances gives us cluster purity.
Row 1 of Table 1 holds the cumulative results
over all the words in senSWSD (micro averages).
The table also reports detailed results for 4 sample
selected words from senSWSD. skew stands for
the percentage of the most frequent label. dsm add
is the representation based on (Schutze, 1998),
dsm mul stands for the representation as described
in (Akkaya et al., 2012) and local features is the
local feature representation based on (Purandare
and Pedersen, 2004). The results show that among
dsm mul, dsm add, and local features; dsm mul
performs the best.
When we look at the context clustering re-
sults for single words separately, we observe
that the performance of different representations
vary. There is not a single winner among all
words. Thus, perhaps choosing one single repre-
sentation for all the words is not optimal. Hav-
ing that in mind, we try merging the dsm mul
and local features representations. We leave out
dsm add representation, since both dsm mul and
dsm add rely on the same type of semantic infor-
mation (i.e., a DSM). We hypothesize that the two
</bodyText>
<page confidence="0.983165">
271
</page>
<bodyText confidence="0.999969">
representations, one relying on a semantic space
and the other relying on local WSD features, may
complement each other.
To merge the representations, we concatenate
the two feature vectors into one. First, however,
we normalize each vector to unit length, since the
individual vectors have different scales and would
have unequal contribution, otherwise. We call this
mixed representation mix rep.
In Table 1, we see that, overall, mix rep per-
forms better than all the other representations. The
improvement is statistically significant at the p &lt;
.05 level on a paired t-test. We observe that, even
when mix rep does not perform the best, it is never
bad. mix rep is the winner or ties for the winner
for 25 out of 39 words. This number is 13, 13, and
15 for dsm add, dsm mul and local features, re-
spectively. For the words for which mix rep is not
the winner, it is, on average, 1.47 points lower than
the winner. This number is 4.22, 6.83, and 7.07
for the others. The results provide evidence that
mix rep is consistently good and reliable. Thus, in
our experiments, mix rep will be our choice as the
context representation.
</bodyText>
<sectionHeader confidence="0.997047" genericHeader="method">
4 Clustering Process
</sectionHeader>
<bodyText confidence="0.999995571428571">
We now turn to the clustering process. In a “clus-
ter and label” strategy, in order to be able to label
clusters, we need to annotate some of the instances
in each cluster. Then, we can accept the majority
label found in a cluster as its label. Thus, some
manual labelling is required, preferably a small
amount.
We propose to provide this small amount of an-
notated data prior to clustering, and then perform
semi-supervised clustering. This way the provided
labels will guide the clustering algorithm to gener-
ate the clusters that are more suitable for our end
task, namely clusters where subjective and objec-
tive instances are grouped together.
</bodyText>
<subsectionHeader confidence="0.996164">
4.1 Constrained Clustering
</subsectionHeader>
<bodyText confidence="0.999518295081967">
Constrained clustering (Grira et al., 2004) also
known as semi-supervised clustering is a recent
development in the clustering literature. In addi-
tion to the similarity information required by un-
supervised clustering, constrained clustering re-
quires pairwise constraints. There are two types
of constraints: (1) must-link and (2) cannot-link
constraints. A must-link constraint dictates that
two instances should be in the same cluster and a
cannot-link dictates that two instances should not
be in the same cluster. In this work, we only con-
sider cannot-links, because of the definition of our
SWSD task. Two instances sharing the same label
do not need to be in the same cluster, since the in-
duced clusters represent different usage patterns of
a word. For example, two instances labeled S need
not be similar to each other. They can be different
usages, both having a subjective meaning. On the
other hand, if two instances are labeled having op-
posing labels, we do not want them to be in the
same cluster. Thus, we utilize cannot-links but not
must-links.
Constraints can be obtained from domain
knowledge or from available instance labels. In
our work, constraints are generated from instance
labels. Each instance pair with opposing labels is
considered to be cannot-linked.
There are two general strategies to incorporate
constraints into clustering. The first is to adapt
the similarity between instances (Xing et al., 2002;
Klein et al., 2002) by adjusting the underlying dis-
tance metric. The main idea is to make the dis-
tance between must-linked instances – their neigh-
bourhoods – smaller and the distance between
cannot-linked instances – their neighbourhoods –
larger. The second strategy is modifying the clus-
tering algorithm itself so that search is biased to-
wards a partitioning for which the constraints hold
(Wagstaff and Cardie, 2000; Basu et al., 2002;
Demiriz et al., 1999).
Our proposed constrained clustering method re-
lies on some ideas from (Klein et al., 2002). Thus,
we explain it in more detail. (Klein et al., 2002)
utilizes agglomerative hierarchical clustering with
complete-linkage. The algorithm imposes con-
straints by changing the distance matrix accord-
ing to the given constraints. The distances be-
tween must-linked instances are set to 0. That is
not enough by itself, since if two instances are
must-linked, other instances close to them should
also get closer to each other. This means there is
a need to propagate the constraints. This is done
by calculating the shortest path between all the in-
stances and updating the distance matrix accord-
ingly. To impose cannot-links, the distance be-
tween two cannot-linked instances is set to some
large number. The complete-linkage property
indirectly propagates the cannot-link constraints,
since it will not allow two clusters to be merged if
they contain instances that are cannot-linked.
Although previous work report on average sub-
</bodyText>
<page confidence="0.983741">
272
</page>
<bodyText confidence="0.99973645">
stantial improvement in the clustering purity,
(Davidson et al., 2006) shows that even if the
constraints are generated from gold-standard data,
some constraint sets can decrease clustering pu-
rity. The results vary significantly depending on
the specific set of constraints used. To our knowl-
edge, there have been two approaches for select-
ing informative constraint sets (Basu et al., 2004;
Klein et al., 2002). The method described in
(Basu et al., 2004) uses the farthest-first traversal
scheme. That strategy is not suitable in our setting,
since we have only two labels. After selecting
just one instance from both labels, this method be-
comes the same as random selection. The strategy
described in (Klein et al., 2002) is more general.
At first, the hierarchical clustering algorithm fol-
lows in a unconstrained fashion until some moder-
ate number of clusters are remaining. Then, the al-
gorithm starts to request constraints between roots
whenever two clusters are merged.
</bodyText>
<subsectionHeader confidence="0.960446">
4.2 Iterative Constrained Clustering
</subsectionHeader>
<bodyText confidence="0.997989">
Our proposed algorithm is closely related to (Klein
et al., 2002). We share the same backbone:
(1) the agglomerative hierarchical clustering with
complete-linkage and (2) the mechanism to im-
pose cannot-link constraints described in Section
4.1. For our algorithm, we implement a second
mechanism for imposing constraints proposed by
(Xing et al., 2002) (Section 4.2.1) and use both
mechanisms in combination. We also propose a
novel constraint selection method (Section 4.2.2).
</bodyText>
<subsubsectionHeader confidence="0.549627">
4.2.1 Imposing Constraints
</subsubsectionHeader>
<bodyText confidence="0.999876342105263">
(Klein et al., 2002) imposes cannot-link con-
straints by adjusting the distance between cannot-
linked pairs heuristically and by relying on com-
plete linkage for propagation. Although this ap-
proach was shown to be effective, we believe it
does not make full use of the provided constraints.
We believe that learning a new distance metric will
result in more reliable distance estimates between
all instances. For this purpose, we learn a Maha-
lanobis distance function following the method de-
scribed in (Davis et al., 2007). (Davis et al., 2007)
formulate the problem of distance metric learn-
ing as minimizing the differential relative entropy
between two multivariate Gaussians under con-
straints. Note that using distance metric learning
for imposing constraints was previously proposed
by (Xing et al., 2002). (Xing et al., 2002) pose
metric learning as a convex optimization problem.
The reason we choose the metric learning method
(Davis et al., 2007) over (Xing et al., 2002) is that
it is computationally more efficient.
(Klein et al., 2002) has a favourable property we
want to keep. The constraints are imposed strictly,
meaning that no cannot-linked instances can ap-
pear in the same cluster. I.e., they are hard con-
straints. In the case of metric learning, the con-
straints are not imposed strictly. In a new learned
distance metric, two cannot-linked instances will
be relatively distant, but there is no guarantee they
will not end up in the same cluster. Although we
think that metric learning makes a better use of
provided constraints, we do not want to lose the
benefit of hard constraints. Thus, we use both
mechanisms in combination to impose constraints.
We first learn a Mahalanobis distance based on the
provided constraints. Then, we compute distance
matrix and employ the mechanism proposed by
(Klein et al., 2002) on the learned distance matrix.
</bodyText>
<subsubsectionHeader confidence="0.597517">
4.2.2 Active Constraint Generation
</subsubsectionHeader>
<bodyText confidence="0.999986466666667">
As mentioned before, the choice of the set of con-
straints affects the quality of the end clustering. In
this work, we define a novel method to choose in-
formative instances, which we believe will have
maximum impact on the end cluster quality, when
they are labeled and used to generate constraints
for our task. We use an iterative approach. Each
iteration consists of three steps: (1) generating
clusters by the process described in Section 4.2.1
imposing available constraints, (2) choosing the
most informative instance, considering the cluster
boundaries, and acquiring its label, (3) extending
the available constraints with the ones we generate
from the newly labeled instance.
We consider an instance to be informative if
there is a high probability that the knowledge of
its label may change the cluster boundaries. The
more probable that change is, the more informa-
tive is the instance. The basic idea is that if an
instance is in a cluster holding instances of type
a and it is close to another cluster holding in-
stances of type b, that instance is most likely mis-
clustered. Thus, it should be queried. Our hypoth-
esis is that, in each iteration, the algorithm will
choose the most problematic – informative – in-
stance that will end up changing cluster bound-
aries. This will result in each iteration in a more
reliable distance metric, which in return will pro-
vide more reliable estimates of problematic in-
stances in future iterations. The imposed con-
</bodyText>
<page confidence="0.996586">
273
</page>
<figure confidence="0.7217155">
Algorithm 1 Iterative Constrained Clustering
1: C = cluster(I)
2: I{L} = labelprototypes(C)
3: while H{L} I &lt; stop do
4: Con = createconstraints(I{L})
5: Matrixdist = learnmetric(I, Con)
6: C = constraintedcluster(Matrixdist, Con)
7: L = labelmostinformative(C)
8: I{L} = I{L} ∪ L
9: end while
10: propagatelabels(I{L}, C) {C...Clusters; Con...Constraints;
I...Instances; I{L}...Labeled Instances; Matrixdist...Distance Matrix}
</figure>
<figureCaption confidence="0.4616095">
straints will move the clustering in each iteration
towards better separation of S and O instances.
</figureCaption>
<bodyText confidence="0.999867157894737">
To define informativeness, we define a scoring
function, which is used to score each data point on
its goodness. The lower the score, the more likely
it is that the instance is mis-clustered. Choosing
the data point with the lowest score will likely
change clustering borders in the next iteration.
Our scoring function is based on the silhouette co-
efficient, a popular unsupervised cluster validation
metric to measure goodness (Tan et al., 2005) of
a cluster member. Basically, the silhouette score
assigns a cluster member that is close to another
cluster a lower score, and a cluster member that
is closer to the cluster center a higher score. That
is partly what we want. In addition, we do not
want to penalize a cluster member that is close to
another cluster having members with the same la-
bel. For this purpose, we calculate the silhouette
score only over clusters with an opposing label
(i.e., holding members with an opposing label). In
addition, we consider only instances labeled so far
when computing the score. We call this new coef-
ficient silhconst. It is computed as follows: (1) for
an instance i, compute its average distance from
the other instances in its cluster xi which are al-
ready labeled, (2) for an instance i, compute its
average distance from the labeled instances of the
clusters from an opposing label and take the mini-
mum of these averages yi, (3) compute the silhou-
ette coefficient as (yi-xi) / max(yi,xi).
The silhconst coefficient has favourable proper-
ties. First, it scores members that are close to
a cluster with an opposing label lower than the
members that are close to a cluster with the same
label. According to our definition, these mem-
bers are more informative. Figure 1 holds a sam-
ple cluster setting. The shape of a member de-
notes its label and its fill denotes whether or not it
has been queried. In this example, silhconst scores
</bodyText>
<figureCaption confidence="0.999756">
Figure 1: Behaviour of selection function
</figureCaption>
<bodyText confidence="0.999726357142857">
members 2 and 3 lower than 1. Thus, member 1
will not be selected, which is the right decision in
this example. Both members 2 and 3 are close to
clusters with an opposing label. In this example
silhconst scores member 3 lower, which is farther
away from already labeled members in the clus-
ter. Thus, member 3 will be selected to be labeled.
This type of behaviour results in an explorative
strategy.
The active selection strategy proposed by (Klein
et al., 2002) is single pass. Thus, it does not have
the opportunity to observe the complete cluster
structure before choosing constraints. We hypoth-
esize that our strategy will provide more informa-
tive constraints, since it has the advantage of be-
ing able to base the decision of which constraints
to generate on fully observed cluster structure in
each iteration.
We call our proposed algorithm Iterative Con-
strained Clustering (ICC). In our final implemen-
tation, ICC starts by simply clustering the in-
stances without any constraints. The algorithm
queries the label of the prototypical member –
the member closest to the cluster center – of each
cluster. Then, the described iterations begin. Al-
gorithm 1 contains the complete ICC algorithm.
Note that line 6 is equivalent to the algorithm of
(Klein et al., 2002).
</bodyText>
<subsectionHeader confidence="0.993243">
4.3 Experiments
</subsectionHeader>
<bodyText confidence="0.999753272727273">
This section gives details on experiments to evalu-
ate the purity of the semi-automatically generated
subjectivity sense tagged data by our “cluster and
label” strategy. We carry out detailed analysis to
quantify the effect of the proposed active selec-
tion strategy and of metric learning on the purity
of the generated data. We compare our active se-
lection strategy to random selection and also to
(Klein et al., 2002). The comparison is done on
the senSWSD dataset. SenSWSD consists of three
subsets, SENSEVAL I,II and III. Since we devel-
</bodyText>
<figure confidence="0.568916333333333">
3
2
1
</figure>
<page confidence="0.927443">
274
</page>
<figureCaption confidence="0.999634">
Figure 2: Label Purity – ICC vs. random selection
</figureCaption>
<bodyText confidence="0.997282545454545">
oped our active selection algorithm on the SEN-
SEVAL I subset, we use only SENSEVAL II and
III subsets for comparison. We apply ICC to each
word in the comparison set separately, and report
cumulative results for the purity of the generated
data. We report results for different percentages of
the queried data amount (e.g. 10% means that the
algorithm queried 10% of the data to create con-
straints). This way, we obtain a learning curve.
We fix the cluster number to 7 as in the context
representation experiments.
</bodyText>
<subsectionHeader confidence="0.984187">
4.3.1 Effect of Active Selection Strategy
</subsectionHeader>
<bodyText confidence="0.967459">
Figure 2 holds the comparison of ICC with
silhconst selection to a random selection baseline.
“majority” stands for majority label frequency in
the dateset. We see that silhconst performs better
than the random selection. By providing labels to
only 25% of the data, we can achieve 87.67% pure
fully labeled data.
For comparison, we also evaluate the perfor-
mance of (Klein et al., 2002) with their active con-
straint selection strategy as described in Section
4.1. Note that originally (Klein et al., 2002) re-
quests the constraint between two roots. In our
setting, it requests labels of the roots and then gen-
erates constraints from the obtained labels. Since
we have a binary task, querying labels makes more
sense. This has the advantage that more con-
straints from each request are obtained. More-
over, it allows a direct comparison to our algo-
rithm. (Klein et al., 2002) does not use any metric
learning. Thus, we run our algorithm also without
metric learning, in order to compare the effective-
ness of both active selection strategies fairly. In
Figure 3, we see that silhconst performs better than
the active selection strategy described in (Klein et
al., 2002). We also see that metric learning results
</bodyText>
<figureCaption confidence="0.9999925">
Figure 3: Label Purity – ICC vs. Klein
Figure 4: SWSD accuracy on ICC generated data
</figureCaption>
<bodyText confidence="0.998908">
in a big improvement. In addition, metric learn-
ing results in a smoother learning curve, which is
a favourable property for a real-world application.
</bodyText>
<subsectionHeader confidence="0.9446525">
4.3.2 SWSD on semi-automatically generated
annotations
</subsectionHeader>
<bodyText confidence="0.9999794">
Now that we have a tool to generate training data
for SWSD, we want to evaluate it on the actual
SWSD task. We want to see if the obtained purity
is enough to create reliable SWSD classifiers. For
this purpose, we test ICC on mturkSWSD dataset.
For each word in our dataset, we conduct 10-
fold cross-validation experiments. ICC is ap-
plied to training folds to label instances semi-
automatically. We train SWSD classifiers on the
generated training fold labels and test the classi-
fiers on the corresponding test fold. We distin-
guish between queried instances and propagated
labels. The queried instances are weighted as
1 and the instances with propagated labels are
weighted by their silhconst score, since that mea-
sure gives the goodness of an instance. The score
is defined between -1 and 1. This score is normal-
ized between 0 and 1, before it is used as a weight.
SVM classifiers from the Weka package (Witten
and Frank., 2005) with its default settings are used
</bodyText>
<page confidence="0.995025">
275
</page>
<bodyText confidence="0.999956391304348">
as in (Akkaya et al., 2011).
We implement two baselines. The first is sim-
ple random sampling and the second is uncer-
tainty sampling, which is an active learning (AL)
method. We use “simple margin” selection as de-
scribed in (Tong and Koller, 2001). It selects, in
each iteration, the instance closest to the decision
boundary of the trained SVM. Each method is run
until it reaches the accuracy of training fully on
the gold-standard data. ICC reaches that bound-
ary when provided only 59% of the labels in the
dataset. For uncertainty sampling and random
sampling, these values are 92% and 100%, respec-
tively. In Figure 4, we see the SWSD accuracy for
different queried data percentages. “full” stands
for training fully on gold-standard data. We see
that training SWSD on semi-automatically labeled
data by ICC does consistently better than uncer-
tainty sampling and random sampling.
It is surprising to see that uncertainty sampling
overall does not do better than random sampling.
We believe that it might be because of sampling
bias. During AL, as more and more labels are
obtained, the training set quickly diverges from
the underlying data distribution. (Sch¨utze et al.,
2006) states that AL can explore the feature space
in such a biased way that it can end up ignoring en-
tire clusters of unlabeled instances. We think that
SWSD is highly prone for the mentioned missed
cluster problem because of its unique nature. As
mentioned, SWSD is a binary task where we dis-
tinguish between subjective and objective usages
of a subjectivity word. Although the classifica-
tion is binary, the underlying usages are grouped
into multiple clusters corresponding to senses of
the word. It is possible that two groups of usages
which are represented quite differently in the fea-
ture space are both subjective or objective. More-
over, one usage group might be closer to a usage
group from the opposing label than to a group with
the same label.
We see that our method reduces the annotation
amount by 36% in comparison to uncertainty sam-
pling and by 41% in comparison to random sam-
pling to reach the performance of the SWSD sys-
tem trained on fully annotated data.
</bodyText>
<sectionHeader confidence="0.999989" genericHeader="evaluation">
5 Related Work
</sectionHeader>
<bodyText confidence="0.999908157894737">
One related line of research is constrained clus-
tering also known as semi-supervised clustering
(Xing et al., 2002; Wagstaff and Cardie, 2000;
Grira et al., 2004; Demiriz et al., 1999). It has
been applied to various datasets and tasks such
as image and document categorization. To our
knowledge, we are the first to utilize constrained
clustering for a difficult NLP task.
There have been only two previous works se-
lecting constraints for constrained clustering ac-
tively (Basu et al., 2004; Klein et al., 2002). The
biggest difference of our approach is that it is iter-
ative as opposed to single pass.
Active Learning (AL) (Settles, 2009; Settles
and Craven, 2008; Hwa, 2004; Tong and Koller,
2001) builds another important set of related work.
Our method is inspired by uncertainty sampling.
We accomplish active selection in the clustering
setting.
</bodyText>
<sectionHeader confidence="0.999793" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999986285714286">
In this paper, we explore a “cluster and la-
bel” strategy to reduce the human annotation ef-
fort needed to generate subjectivity sense-tagged
data. In order to keep the noise in the semi-
automatically labeled data minimal, we investigate
different feature space types and evaluate their ex-
pressiveness. More importantly, we define a new
algorithm called iterative constrained clustering
(ICC) with an active constraint selection strategy.
We show that we can obtain a fairly reliable la-
beled data when we utilize ICC.
We show that the active selection strategy
we propose outperforms a previous approach by
(Klein et al., 2002) for generating subjectivity
sense-tagged data. Training SWSD classifiers on
ICC generated data improves over random sam-
pling and uncertainty sampling (Tong and Koller,
2001). We can achieve on mturkSWSD 36% an-
notation reduction over uncertainty sampling and
41% annotation reduction over random sampling
in order to reach the performance of SWSD clas-
sifiers trained on fully annotated data.
To our knowledge, this work is the first applica-
tion of constrained clustering to a hard NLP prob-
lem. We showcase the power of constrained clus-
tering. We hope that the same “cluster and label”
strategy will be applicable to Word Sense Disam-
biguation. This will be part of our future work.
</bodyText>
<sectionHeader confidence="0.998735" genericHeader="acknowledgments">
7 Acknowledgments
</sectionHeader>
<bodyText confidence="0.779408666666667">
This material is based in part upon work supported
by National Science Foundation awards #0917170
and #0916046.
</bodyText>
<page confidence="0.996777">
276
</page>
<sectionHeader confidence="0.996257" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999722234234235">
Apoorv Agarwal, Fadi Biadsy, and Kathleen Mckeown.
2009. Contextual phrase-level polarity analysis us-
ing lexical affect scoring and syntactic N-grams. In
Proceedings of the 12th Conference of the Euro-
pean Chapter of the ACL (EACL 2009), pages 24–
32, Athens, Greece, March. Association for Compu-
tational Linguistics.
Cem Akkaya, Janyce Wiebe, and Rada Mihalcea.
2009. Subjectivity word sense disambiguation. In
Proceedings of the 2009 Conference on Empirical
Methods in Natural Language Processing, pages
190–199, Singapore, August. Association for Com-
putational Linguistics.
Cem Akkaya, Janyce Wiebe, Alexander Conrad, and
Rada Mihalcea. 2011. Improving the impact of
subjectivity word sense disambiguation on contex-
tual opinion analysis. In Proceedings of the Fif-
teenth Conference on Computational Natural Lan-
guage Learning, pages 87–96, Portland, Oregon,
USA, June. Association for Computational Linguis-
tics.
Cem Akkaya, Janyce Wiebe, and Rada Mihalcea.
2012. Utilizing semantic composition in distribu-
tional semantic models for word sense discrimina-
tion and word sense disambiguation. In ICSC, pages
45–51.
Alina Andreevskaia and Sabine Bergler. 2008. When
specialists and generalists work together: Over-
coming domain dependence in sentiment tagging.
In Proceedings of ACL-08: HLT, pages 290–298,
Columbus, Ohio, June. Association for Computa-
tional Linguistics.
Sugato Basu, Arindam Banerjee, and R. Mooney.
2002. Semi-supervised clustering by seeding. In
In Proceedings of 19th International Conference on
Machine Learning (ICML-2002).
Sugato Basu, Arindam Banerjee, and Raymond J.
Mooney. 2004. Active semi-supervision for pair-
wise constrained clustering. In SDM.
Kenneth Bloom, Navendu Garg, and Shlomo Argamon.
2007. Extracting appraisal expressions. In HLT-
NAACL 2007, pages 308–315, Rochester, NY.
John Bullinaria and Joseph Levy. 2007. Ex-
tracting semantic representations from word
co-occurrence statistics: A computational
study. Behavior Research Methods, 39:510–526.
10.3758/BF03193020.
Ian Davidson, Kiri Wagstaff, and Sugato Basu. 2006.
Measuring constraint-set utility for partitional clus-
tering algorithms. In PKDD, pages 115–126.
Jason V. Davis, Brian Kulis, Prateek Jain, Suvrit Sra,
and Inderjit S. Dhillon. 2007. Information-theoretic
metric learning. In Proceedings of the 24th interna-
tional conference on Machine learning, ICML ’07,
pages 209–216, New York, NY, USA. ACM.
Ayhan Demiriz, Kristin Bennett, and Mark J. Em-
brechts. 1999. Semi-supervised clustering using
genetic algorithms. In In Artificial Neural Networks
in Engineering (ANNIE-99, pages 809–814. ASME
Press.
Nizar Grira, Michel Crucianu, and Nozha Boujemaa.
2004. Unsupervised and semi-supervised cluster-
ing: a brief survey. In in A Review of Ma-
chine Learning Techniques for Processing Multime-
dia Content, Report of the MUSCLE European Net-
work of Excellence.
Rebecca Hwa. 2004. Sample selection for statis-
tical parsing. Comput. Linguist., 30(3):253–276,
September.
Adam Kilgarriff. 1997. I dont believe in word senses.
Computers and the Humanities, 31(2):91–113.
Soo-Min Kim and Eduard Hovy. 2004. Determin-
ing the sentiment of opinions. In Proceedings of
the Twentieth International Conference on Compu-
tational Linguistics (COLING 2004), pages 1267–
1373, Geneva, Switzerland.
D. Klein, K. Toutanova, I.T. Ilhan, S.D. Kamvar, and
C. Manning. 2002. Combining heterogeneous clas-
sifiers for word-sense disambiguation. In Proceed-
ings of the ACL Workshop on ”Word Sense Dis-
ambiguatuion: Recent Successes and Future Direc-
tions, pages 74–80, July.
R. Mihalcea. 2002. Instance based learning with
automatic feature selection applied to Word Sense
Disambiguation. In Proceedings of the 19th Inter-
national Conference on Computational Linguistics
(COLING 2002), Taipei, Taiwan, August.
Jeff Mitchell and Mirella Lapata. 2010. Composition
in distributional models of semantics. Cognitive Sci-
ence, 34(8):1388–1429.
A. Purandare and T. Pedersen. 2004. Word sense dis-
crimination by clustering contexts in vector and sim-
ilarity spaces. In Proceedings of the Conference on
Computational Natural Language Learning (CoNLL
2004), Boston.
Ellen Riloff and Janyce Wiebe. 2003. Learning extrac-
tion patterns for subjective expressions. In Proceed-
ings of the Conference on Empirical Methods in Nat-
ural Language Processing (EMNLP-2003), pages
105–112, Sapporo, Japan.
Magnus Sahlgren. 2006. The Word-Space Model: us-
ing distributional analysis to represent syntagmatic
and paradigmatic relations between words in high-
dimensional vector spaces. Ph.D. thesis, Stockholm
University.
Hinrich Sch¨utze, Emre Velipasaoglu, and Jan O. Ped-
ersen. 2006. Performance thresholding in practical
text classification. In Proceedings of the 15th ACM
international conference on Information and knowl-
edge management, CIKM ’06, pages 662–671, New
York, NY, USA. ACM.
</reference>
<page confidence="0.958857">
277
</page>
<reference confidence="0.9998302">
H. Schutze. 1998. Automatic word sense discrimina-
tion. Computational Linguistics, 24(1):97–124.
Burr Settles and Mark Craven. 2008. An analysis
of active learning strategies for sequence labeling
tasks. In Proceedings of the Conference on Em-
pirical Methods in Natural Language Processing,
EMNLP ’08, pages 1070–1079, Stroudsburg, PA,
USA. Association for Computational Linguistics.
Burr Settles. 2009. Active Learning Literature Survey.
Technical Report 1648, University of Wisconsin–
Madison.
Pang-Ning Tan, Michael Steinbach, and Vipin Kumar.
2005. Introduction to Data Mining, (First Edi-
tion). Addison-Wesley Longman Publishing Co.,
Inc., Boston, MA, USA.
Simon Tong and Daphne Koller. 2001. Support vec-
tor machine active learning with applications to text
classification. Journal of Machine Learning Re-
search, 2:45–66.
Peter D. Turney and Patrick Pantel. 2010. From fre-
quency to meaning: Vector space models of seman-
tics. March.
Peter Turney. 2002. Thumbs up or thumbs down? Se-
mantic orientation applied to unsupervised classifi-
cation of reviews. In Proceedings of the 40th An-
nual Meeting of the Association for Computational
Linguistics (ACL-02), pages 417–424, Philadelphia,
Pennsylvania.
Kiri Wagstaff and Claire Cardie. 2000. Clustering
with instance-level constraints. In Proceedings of
the Seventeenth International Conference on Ma-
chine Learning (ICML-2000), pages 1103–1110.
Casey Whitelaw, Navendu Garg, and Shlomo Arga-
mon. 2005. Using appraisal taxonomies for sen-
timent analysis. In Proceedings of CIKM-05, the
ACM SIGIR Conference on Information and Knowl-
edge Management, Bremen, DE.
I. Witten and E. Frank. 2005. Data Mining: Practi-
cal Machine Learning Tools and Techniques, Second
Edition. Morgan Kaufmann, June.
Eric P. Xing, Andrew Y. Ng, Michael I. Jordan, and
Stuart J. Russell. 2002. Distance metric learning
with application to clustering with side-information.
In NIPS, pages 505–512.
Hong Yu and Vasileios Hatzivassiloglou. 2003. To-
wards answering opinion questions: Separating facts
from opinions and identifying the polarity of opin-
ion sentences. In Proceedings of the Conference on
Empirical Methods in Natural Language Processing
(EMNLP-2003), pages 129–136, Sapporo, Japan.
</reference>
<page confidence="0.996928">
278
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.957423">
<title confidence="0.9979675">Iterative Constrained Clustering for Subjectivity Word Disambiguation</title>
<author confidence="0.973734">Cem Akkaya</author>
<author confidence="0.973734">Janyce</author>
<affiliation confidence="0.99972">University of</affiliation>
<address confidence="0.990739">Pittsburgh PA, 15260,</address>
<abstract confidence="0.999675315789474">Subjectivity word sense disambiguation (SWSD) is a supervised and applicationspecific word sense disambiguation task disambiguating between subjective and objective senses of a word. Not surprisingly, SWSD suffers from the knowledge acquisition bottleneck. In this work, we use a “cluster and label” strategy to generate labeled data for SWSD semiautomatically. We define a new algocalled Constrained Cluster- (ICC) improve the clustering purity and, as a result, the quality of the generated data. Our experiments show that the SWSD classifiers trained on the ICC generated data by requiring only 59% of the labels can achieve the same performance as the classifiers trained on the full dataset.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Apoorv Agarwal</author>
<author>Fadi Biadsy</author>
<author>Kathleen Mckeown</author>
</authors>
<title>Contextual phrase-level polarity analysis using lexical affect scoring and syntactic N-grams.</title>
<date>2009</date>
<booktitle>In Proceedings of the 12th Conference of the European Chapter of the ACL (EACL</booktitle>
<pages>24--32</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Athens, Greece,</location>
<contexts>
<context position="1133" citStr="Agarwal et al., 2009" startWordPosition="167" endWordPosition="170">d data for SWSD semiautomatically. We define a new algorithm called Iterative Constrained Clustering (ICC) to improve the clustering purity and, as a result, the quality of the generated data. Our experiments show that the SWSD classifiers trained on the ICC generated data by requiring only 59% of the labels can achieve the same performance as the classifiers trained on the full dataset. 1 Introduction Subjectivity lexicons (e.g., (Turney, 2002; Whitelaw et al., 2005; Riloff and Wiebe, 2003; Yu and Hatzivassiloglou, 2003; Kim and Hovy, 2004; Bloom et al., 2007; Andreevskaia and Bergler, 2008; Agarwal et al., 2009)) play an important role in opinion, sentiment, and subjectivity analysis. These systems typically look for the presence of clues in text. Recently, in (Akkaya et al., 2009), we showed that subjectivity clues are fairly ambiguous as to whether they express subjectivity or not – words in such lexicons may have both subjective and objective usages. We call this problem subjectivity sense ambiguity. Consider the following sentence containing the clue “attack”: (1) He was attacked by Milosevic for attempting to carve out a new party from the Socialists. Rada Mihalcea University of North Texas Dent</context>
</contexts>
<marker>Agarwal, Biadsy, Mckeown, 2009</marker>
<rawString>Apoorv Agarwal, Fadi Biadsy, and Kathleen Mckeown. 2009. Contextual phrase-level polarity analysis using lexical affect scoring and syntactic N-grams. In Proceedings of the 12th Conference of the European Chapter of the ACL (EACL 2009), pages 24– 32, Athens, Greece, March. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cem Akkaya</author>
<author>Janyce Wiebe</author>
<author>Rada Mihalcea</author>
</authors>
<title>Subjectivity word sense disambiguation.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>190--199</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="1306" citStr="Akkaya et al., 2009" startWordPosition="194" endWordPosition="197">he generated data. Our experiments show that the SWSD classifiers trained on the ICC generated data by requiring only 59% of the labels can achieve the same performance as the classifiers trained on the full dataset. 1 Introduction Subjectivity lexicons (e.g., (Turney, 2002; Whitelaw et al., 2005; Riloff and Wiebe, 2003; Yu and Hatzivassiloglou, 2003; Kim and Hovy, 2004; Bloom et al., 2007; Andreevskaia and Bergler, 2008; Agarwal et al., 2009)) play an important role in opinion, sentiment, and subjectivity analysis. These systems typically look for the presence of clues in text. Recently, in (Akkaya et al., 2009), we showed that subjectivity clues are fairly ambiguous as to whether they express subjectivity or not – words in such lexicons may have both subjective and objective usages. We call this problem subjectivity sense ambiguity. Consider the following sentence containing the clue “attack”: (1) He was attacked by Milosevic for attempting to carve out a new party from the Socialists. Rada Mihalcea University of North Texas Denton TX, 76207, USA rada@cs.unt.edu Knowing that “attack” is a subjectivity clue with negative polarity will help a system recognize the negative sentiment in the sentence. Bu</context>
<context position="6147" citStr="Akkaya et al., 2009" startWordPosition="969" endWordPosition="972">al is similar. Instead of generating dictionary definitions, we are only interested in generating coherent sets of usages of a word, so that we can label each induced set – with its instances – to obtain labeled data for SWSD. Our high-level grouping criterion is that the instances in a cluster should be similar subjective (objective) usages of the word. Training data for an SWSD classifier consists of instances of the target word tagged as having a subjective sense (S) or an objective sense (O) (subjectivity sense tagged data). We train a different SWSD classifier for each target word as in (Akkaya et al., 2009). Thus, we need a different training dataset for each target word. Our ultimate goal is to reduce the human annotation effort required to create training data for SWSD classifiers. For this purpose, we utilize a “cluster and label” strategy relying on context clustering. Each instance of a word is represented as a feature vector (i.e., a context vector). The annotation process has the following steps: (1) cluster the context vectors of word instances, (2) label the induced clusters as S or O, (3) propagate the given label to all instances in a cluster. The induced clusters represent different </context>
<context position="7546" citStr="Akkaya et al., 2009" startWordPosition="1213" endWordPosition="1216"> end up in different clusters, if they are different usages of the word. Since we are labelling clusters as a whole, we will introduce noise in the labeled data. Thus, in developing the clustering process, we need to minimize that noise and find as pure clusters as possible. The first step is to define the context representation of the instances. This is addressed in Section 3. Then, we turn in Section 4.2 to the clustering process itself. To evaluate our “cluster and label” strategy, we use two gold standard subjectivity sense tagged datasets. 1. The first one is called senSWSD generated in (Akkaya et al., 2009) and the second one is called mturkSWSD generated in (Akkaya et al., 2011). They consist of subjectivity sense tagged data for disjoint sets of 39 and 90 words, respectively. In this paper, we opt to use the smaller dataset senSWSD as our development set, on which we evaluate various context representations (in Section 3) and our proposed constrained clustering algorithm (in Section 4.2). Then, on mturkSWSD, we evaluate the quality of semiautomatically generated data for SWSD classification (in Section 4.3.2). 3 Context Representations There has been much work on context representations of wor</context>
</contexts>
<marker>Akkaya, Wiebe, Mihalcea, 2009</marker>
<rawString>Cem Akkaya, Janyce Wiebe, and Rada Mihalcea. 2009. Subjectivity word sense disambiguation. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 190–199, Singapore, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cem Akkaya</author>
<author>Janyce Wiebe</author>
<author>Alexander Conrad</author>
<author>Rada Mihalcea</author>
</authors>
<title>Improving the impact of subjectivity word sense disambiguation on contextual opinion analysis.</title>
<date>2011</date>
<booktitle>In Proceedings of the Fifteenth Conference on Computational Natural Language Learning,</booktitle>
<pages>87--96</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Portland, Oregon, USA,</location>
<contexts>
<context position="3286" citStr="Akkaya et al., 2011" startWordPosition="506" endWordPosition="509">d sentiment analysis resulting in substantial improvement for both subjectivity and sentiment analysis by avoiding false hits. Although SWSD is a promising tool, it suffers from the knowledge acquisition bottleneck. SWSD is defined as a supervised task, and follows a targeted approach common in the WSD literature for performance reasons. This means, for each target clue, a different classifier is trained requiring separate training data for each target clue. It is expensive and time-consuming to obtain annotated datasets to train SWSD classifiers limiting scalability. As a countermeasure, in (Akkaya et al., 2011), we showed that non-expert annotations collected through Amazon Mechanical Turk (MTurk) can replace expert annotations successfully and might be used to apply SWSD on a large scale. Although non-expert annotations are cheap and fast, they still incur some cost. In this work, we aim to reduce the human annotation effort needed 269 Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 269–278, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics to generate the same amount of subjectivity sense tagged</context>
<context position="7620" citStr="Akkaya et al., 2011" startWordPosition="1226" endWordPosition="1229">ince we are labelling clusters as a whole, we will introduce noise in the labeled data. Thus, in developing the clustering process, we need to minimize that noise and find as pure clusters as possible. The first step is to define the context representation of the instances. This is addressed in Section 3. Then, we turn in Section 4.2 to the clustering process itself. To evaluate our “cluster and label” strategy, we use two gold standard subjectivity sense tagged datasets. 1. The first one is called senSWSD generated in (Akkaya et al., 2009) and the second one is called mturkSWSD generated in (Akkaya et al., 2011). They consist of subjectivity sense tagged data for disjoint sets of 39 and 90 words, respectively. In this paper, we opt to use the smaller dataset senSWSD as our development set, on which we evaluate various context representations (in Section 3) and our proposed constrained clustering algorithm (in Section 4.2). Then, on mturkSWSD, we evaluate the quality of semiautomatically generated data for SWSD classification (in Section 4.3.2). 3 Context Representations There has been much work on context representations of words for various NLP tasks. Clustering word instances in order to discrimina</context>
<context position="30201" citStr="Akkaya et al., 2011" startWordPosition="4952" endWordPosition="4955">semiautomatically. We train SWSD classifiers on the generated training fold labels and test the classifiers on the corresponding test fold. We distinguish between queried instances and propagated labels. The queried instances are weighted as 1 and the instances with propagated labels are weighted by their silhconst score, since that measure gives the goodness of an instance. The score is defined between -1 and 1. This score is normalized between 0 and 1, before it is used as a weight. SVM classifiers from the Weka package (Witten and Frank., 2005) with its default settings are used 275 as in (Akkaya et al., 2011). We implement two baselines. The first is simple random sampling and the second is uncertainty sampling, which is an active learning (AL) method. We use “simple margin” selection as described in (Tong and Koller, 2001). It selects, in each iteration, the instance closest to the decision boundary of the trained SVM. Each method is run until it reaches the accuracy of training fully on the gold-standard data. ICC reaches that boundary when provided only 59% of the labels in the dataset. For uncertainty sampling and random sampling, these values are 92% and 100%, respectively. In Figure 4, we se</context>
</contexts>
<marker>Akkaya, Wiebe, Conrad, Mihalcea, 2011</marker>
<rawString>Cem Akkaya, Janyce Wiebe, Alexander Conrad, and Rada Mihalcea. 2011. Improving the impact of subjectivity word sense disambiguation on contextual opinion analysis. In Proceedings of the Fifteenth Conference on Computational Natural Language Learning, pages 87–96, Portland, Oregon, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cem Akkaya</author>
<author>Janyce Wiebe</author>
<author>Rada Mihalcea</author>
</authors>
<title>Utilizing semantic composition in distributional semantic models for word sense discrimination and word sense disambiguation.</title>
<date>2012</date>
<booktitle>In ICSC,</booktitle>
<pages>45--51</pages>
<contexts>
<context position="9447" citStr="Akkaya et al., 2012" startWordPosition="1516" endWordPosition="1519">t word in a large text corpus. Each row gives the semantic signature of a word, which is basically a high dimensional numeric vector. Note that this high dimensional vector represents word types, not word tokens. Thus, it cannot model a word instance in context. For token-based treatment, (Schutze, 1998) utilizes a second-order representation by averaging co-occurrence vectors of the words (corresponding to rows of the co-occurrence matrix) that occur in that particular context. It is important to note that (Schutze, 1998) uses an additive model for compositional representation. Recently, in (Akkaya et al., 2012), we found that a DSM built using multiplicative composition – proposed by (Mitchell and Lapata, 2010) for a different task – gives better performance than the model described by (Schutze, 1998). We test both methods in this paper, using the same semantic space. The space is built from a corpus consisting of 120 million tokens. The rows of the space correspond to word forms and the columns correspond to word lemmas present in the corpus. We adopt the parameters for our semantic space from (Mitchell and Lapata, 2010): window size of 10 and dimension size of 2000 (i.e., the 2000 most frequent le</context>
<context position="12489" citStr="Akkaya et al., 2012" startWordPosition="2025" endWordPosition="2028">ation metric. To compute cluster purity, we assign each cluster to a sense label, which is the most frequent one in the cluster. The number of the correctly assigned instances divided by the number of all the clustered instances gives us cluster purity. Row 1 of Table 1 holds the cumulative results over all the words in senSWSD (micro averages). The table also reports detailed results for 4 sample selected words from senSWSD. skew stands for the percentage of the most frequent label. dsm add is the representation based on (Schutze, 1998), dsm mul stands for the representation as described in (Akkaya et al., 2012) and local features is the local feature representation based on (Purandare and Pedersen, 2004). The results show that among dsm mul, dsm add, and local features; dsm mul performs the best. When we look at the context clustering results for single words separately, we observe that the performance of different representations vary. There is not a single winner among all words. Thus, perhaps choosing one single representation for all the words is not optimal. Having that in mind, we try merging the dsm mul and local features representations. We leave out dsm add representation, since both dsm mu</context>
</contexts>
<marker>Akkaya, Wiebe, Mihalcea, 2012</marker>
<rawString>Cem Akkaya, Janyce Wiebe, and Rada Mihalcea. 2012. Utilizing semantic composition in distributional semantic models for word sense discrimination and word sense disambiguation. In ICSC, pages 45–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alina Andreevskaia</author>
<author>Sabine Bergler</author>
</authors>
<title>When specialists and generalists work together: Overcoming domain dependence in sentiment tagging.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT,</booktitle>
<pages>290--298</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Columbus, Ohio,</location>
<contexts>
<context position="1110" citStr="Andreevskaia and Bergler, 2008" startWordPosition="163" endWordPosition="166">bel” strategy to generate labeled data for SWSD semiautomatically. We define a new algorithm called Iterative Constrained Clustering (ICC) to improve the clustering purity and, as a result, the quality of the generated data. Our experiments show that the SWSD classifiers trained on the ICC generated data by requiring only 59% of the labels can achieve the same performance as the classifiers trained on the full dataset. 1 Introduction Subjectivity lexicons (e.g., (Turney, 2002; Whitelaw et al., 2005; Riloff and Wiebe, 2003; Yu and Hatzivassiloglou, 2003; Kim and Hovy, 2004; Bloom et al., 2007; Andreevskaia and Bergler, 2008; Agarwal et al., 2009)) play an important role in opinion, sentiment, and subjectivity analysis. These systems typically look for the presence of clues in text. Recently, in (Akkaya et al., 2009), we showed that subjectivity clues are fairly ambiguous as to whether they express subjectivity or not – words in such lexicons may have both subjective and objective usages. We call this problem subjectivity sense ambiguity. Consider the following sentence containing the clue “attack”: (1) He was attacked by Milosevic for attempting to carve out a new party from the Socialists. Rada Mihalcea Univers</context>
</contexts>
<marker>Andreevskaia, Bergler, 2008</marker>
<rawString>Alina Andreevskaia and Sabine Bergler. 2008. When specialists and generalists work together: Overcoming domain dependence in sentiment tagging. In Proceedings of ACL-08: HLT, pages 290–298, Columbus, Ohio, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sugato Basu</author>
<author>Arindam Banerjee</author>
<author>R Mooney</author>
</authors>
<title>Semi-supervised clustering by seeding. In</title>
<date>2002</date>
<booktitle>In Proceedings of 19th International Conference on Machine Learning (ICML-2002).</booktitle>
<contexts>
<context position="16890" citStr="Basu et al., 2002" startWordPosition="2761" endWordPosition="2764">idered to be cannot-linked. There are two general strategies to incorporate constraints into clustering. The first is to adapt the similarity between instances (Xing et al., 2002; Klein et al., 2002) by adjusting the underlying distance metric. The main idea is to make the distance between must-linked instances – their neighbourhoods – smaller and the distance between cannot-linked instances – their neighbourhoods – larger. The second strategy is modifying the clustering algorithm itself so that search is biased towards a partitioning for which the constraints hold (Wagstaff and Cardie, 2000; Basu et al., 2002; Demiriz et al., 1999). Our proposed constrained clustering method relies on some ideas from (Klein et al., 2002). Thus, we explain it in more detail. (Klein et al., 2002) utilizes agglomerative hierarchical clustering with complete-linkage. The algorithm imposes constraints by changing the distance matrix according to the given constraints. The distances between must-linked instances are set to 0. That is not enough by itself, since if two instances are must-linked, other instances close to them should also get closer to each other. This means there is a need to propagate the constraints. Th</context>
</contexts>
<marker>Basu, Banerjee, Mooney, 2002</marker>
<rawString>Sugato Basu, Arindam Banerjee, and R. Mooney. 2002. Semi-supervised clustering by seeding. In In Proceedings of 19th International Conference on Machine Learning (ICML-2002).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sugato Basu</author>
<author>Arindam Banerjee</author>
<author>Raymond J Mooney</author>
</authors>
<title>Active semi-supervision for pairwise constrained clustering.</title>
<date>2004</date>
<booktitle>In SDM.</booktitle>
<contexts>
<context position="18326" citStr="Basu et al., 2004" startWordPosition="2986" endWordPosition="2989">he complete-linkage property indirectly propagates the cannot-link constraints, since it will not allow two clusters to be merged if they contain instances that are cannot-linked. Although previous work report on average sub272 stantial improvement in the clustering purity, (Davidson et al., 2006) shows that even if the constraints are generated from gold-standard data, some constraint sets can decrease clustering purity. The results vary significantly depending on the specific set of constraints used. To our knowledge, there have been two approaches for selecting informative constraint sets (Basu et al., 2004; Klein et al., 2002). The method described in (Basu et al., 2004) uses the farthest-first traversal scheme. That strategy is not suitable in our setting, since we have only two labels. After selecting just one instance from both labels, this method becomes the same as random selection. The strategy described in (Klein et al., 2002) is more general. At first, the hierarchical clustering algorithm follows in a unconstrained fashion until some moderate number of clusters are remaining. Then, the algorithm starts to request constraints between roots whenever two clusters are merged. 4.2 Iterative</context>
<context position="32830" citStr="Basu et al., 2004" startWordPosition="5395" endWordPosition="5398">% in comparison to random sampling to reach the performance of the SWSD system trained on fully annotated data. 5 Related Work One related line of research is constrained clustering also known as semi-supervised clustering (Xing et al., 2002; Wagstaff and Cardie, 2000; Grira et al., 2004; Demiriz et al., 1999). It has been applied to various datasets and tasks such as image and document categorization. To our knowledge, we are the first to utilize constrained clustering for a difficult NLP task. There have been only two previous works selecting constraints for constrained clustering actively (Basu et al., 2004; Klein et al., 2002). The biggest difference of our approach is that it is iterative as opposed to single pass. Active Learning (AL) (Settles, 2009; Settles and Craven, 2008; Hwa, 2004; Tong and Koller, 2001) builds another important set of related work. Our method is inspired by uncertainty sampling. We accomplish active selection in the clustering setting. 6 Conclusions In this paper, we explore a “cluster and label” strategy to reduce the human annotation effort needed to generate subjectivity sense-tagged data. In order to keep the noise in the semiautomatically labeled data minimal, we i</context>
</contexts>
<marker>Basu, Banerjee, Mooney, 2004</marker>
<rawString>Sugato Basu, Arindam Banerjee, and Raymond J. Mooney. 2004. Active semi-supervision for pairwise constrained clustering. In SDM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Bloom</author>
<author>Navendu Garg</author>
<author>Shlomo Argamon</author>
</authors>
<title>Extracting appraisal expressions.</title>
<date>2007</date>
<booktitle>In HLTNAACL 2007,</booktitle>
<pages>308--315</pages>
<location>Rochester, NY.</location>
<contexts>
<context position="1078" citStr="Bloom et al., 2007" startWordPosition="159" endWordPosition="162">se a “cluster and label” strategy to generate labeled data for SWSD semiautomatically. We define a new algorithm called Iterative Constrained Clustering (ICC) to improve the clustering purity and, as a result, the quality of the generated data. Our experiments show that the SWSD classifiers trained on the ICC generated data by requiring only 59% of the labels can achieve the same performance as the classifiers trained on the full dataset. 1 Introduction Subjectivity lexicons (e.g., (Turney, 2002; Whitelaw et al., 2005; Riloff and Wiebe, 2003; Yu and Hatzivassiloglou, 2003; Kim and Hovy, 2004; Bloom et al., 2007; Andreevskaia and Bergler, 2008; Agarwal et al., 2009)) play an important role in opinion, sentiment, and subjectivity analysis. These systems typically look for the presence of clues in text. Recently, in (Akkaya et al., 2009), we showed that subjectivity clues are fairly ambiguous as to whether they express subjectivity or not – words in such lexicons may have both subjective and objective usages. We call this problem subjectivity sense ambiguity. Consider the following sentence containing the clue “attack”: (1) He was attacked by Milosevic for attempting to carve out a new party from the S</context>
</contexts>
<marker>Bloom, Garg, Argamon, 2007</marker>
<rawString>Kenneth Bloom, Navendu Garg, and Shlomo Argamon. 2007. Extracting appraisal expressions. In HLTNAACL 2007, pages 308–315, Rochester, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Bullinaria</author>
<author>Joseph Levy</author>
</authors>
<title>Extracting semantic representations from word co-occurrence statistics: A computational study.</title>
<date>2007</date>
<journal>Behavior Research Methods,</journal>
<volume>39</volume>
<pages>10--3758</pages>
<contexts>
<context position="8684" citStr="Bullinaria and Levy, 2007" startWordPosition="1388" endWordPosition="1391">2). 3 Context Representations There has been much work on context representations of words for various NLP tasks. Clustering word instances in order to discriminate senses of a word is called Word Sense Discrimination. Context representations for this task rely on two main types of models: distributional semantic models (DSM) and feature-based models. 1Available at http://mpqa.cs.pitt.edu/ corpora 270 (Schutze, 1998), which is still a competitive model for word-sense discrimination by context clustering, relies on a distributional semantic model (DSM) (Turney and Pantel, 2010; Sahlgren, 2006; Bullinaria and Levy, 2007). A DSM is usually a word-to-word co-occurrence matrix – also called semantic space – such that each row represents the distribution of a target word in a large text corpus. Each row gives the semantic signature of a word, which is basically a high dimensional numeric vector. Note that this high dimensional vector represents word types, not word tokens. Thus, it cannot model a word instance in context. For token-based treatment, (Schutze, 1998) utilizes a second-order representation by averaging co-occurrence vectors of the words (corresponding to rows of the co-occurrence matrix) that occur i</context>
<context position="10195" citStr="Bullinaria and Levy, 2007" startWordPosition="1647" endWordPosition="1651">k – gives better performance than the model described by (Schutze, 1998). We test both methods in this paper, using the same semantic space. The space is built from a corpus consisting of 120 million tokens. The rows of the space correspond to word forms and the columns correspond to word lemmas present in the corpus. We adopt the parameters for our semantic space from (Mitchell and Lapata, 2010): window size of 10 and dimension size of 2000 (i.e., the 2000 most frequent lemmas). We do not filter out stop words, since they have been shown to be useful for various semantic similarity tasks in (Bullinaria and Levy, 2007). We use positive point-wise mutual information to compute values of the vector components, which has also been shown to be favourable in (Bullinaria and Levy, 2007). Purandere and Pedersen is the prominent representative of feature-based models. (Purandare and Pedersen, 2004) creates context vectors from local feature representations similar to the feature vectors found in supervised WSD. In this work, we use the following features from (Mihalcea, 2002) to build the local feature representation: (1) the target word itself and its part of speech, (2) surrounding context of 3 words and their pa</context>
</contexts>
<marker>Bullinaria, Levy, 2007</marker>
<rawString>John Bullinaria and Joseph Levy. 2007. Extracting semantic representations from word co-occurrence statistics: A computational study. Behavior Research Methods, 39:510–526. 10.3758/BF03193020.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ian Davidson</author>
<author>Kiri Wagstaff</author>
<author>Sugato Basu</author>
</authors>
<title>Measuring constraint-set utility for partitional clustering algorithms.</title>
<date>2006</date>
<booktitle>In PKDD,</booktitle>
<pages>115--126</pages>
<contexts>
<context position="18007" citStr="Davidson et al., 2006" startWordPosition="2936" endWordPosition="2939">to them should also get closer to each other. This means there is a need to propagate the constraints. This is done by calculating the shortest path between all the instances and updating the distance matrix accordingly. To impose cannot-links, the distance between two cannot-linked instances is set to some large number. The complete-linkage property indirectly propagates the cannot-link constraints, since it will not allow two clusters to be merged if they contain instances that are cannot-linked. Although previous work report on average sub272 stantial improvement in the clustering purity, (Davidson et al., 2006) shows that even if the constraints are generated from gold-standard data, some constraint sets can decrease clustering purity. The results vary significantly depending on the specific set of constraints used. To our knowledge, there have been two approaches for selecting informative constraint sets (Basu et al., 2004; Klein et al., 2002). The method described in (Basu et al., 2004) uses the farthest-first traversal scheme. That strategy is not suitable in our setting, since we have only two labels. After selecting just one instance from both labels, this method becomes the same as random sele</context>
</contexts>
<marker>Davidson, Wagstaff, Basu, 2006</marker>
<rawString>Ian Davidson, Kiri Wagstaff, and Sugato Basu. 2006. Measuring constraint-set utility for partitional clustering algorithms. In PKDD, pages 115–126.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason V Davis</author>
<author>Brian Kulis</author>
<author>Prateek Jain</author>
<author>Suvrit Sra</author>
<author>Inderjit S Dhillon</author>
</authors>
<title>Information-theoretic metric learning.</title>
<date>2007</date>
<booktitle>In Proceedings of the 24th international conference on Machine learning, ICML ’07,</booktitle>
<pages>209--216</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="19974" citStr="Davis et al., 2007" startWordPosition="3244" endWordPosition="3247">on. We also propose a novel constraint selection method (Section 4.2.2). 4.2.1 Imposing Constraints (Klein et al., 2002) imposes cannot-link constraints by adjusting the distance between cannotlinked pairs heuristically and by relying on complete linkage for propagation. Although this approach was shown to be effective, we believe it does not make full use of the provided constraints. We believe that learning a new distance metric will result in more reliable distance estimates between all instances. For this purpose, we learn a Mahalanobis distance function following the method described in (Davis et al., 2007). (Davis et al., 2007) formulate the problem of distance metric learning as minimizing the differential relative entropy between two multivariate Gaussians under constraints. Note that using distance metric learning for imposing constraints was previously proposed by (Xing et al., 2002). (Xing et al., 2002) pose metric learning as a convex optimization problem. The reason we choose the metric learning method (Davis et al., 2007) over (Xing et al., 2002) is that it is computationally more efficient. (Klein et al., 2002) has a favourable property we want to keep. The constraints are imposed stri</context>
</contexts>
<marker>Davis, Kulis, Jain, Sra, Dhillon, 2007</marker>
<rawString>Jason V. Davis, Brian Kulis, Prateek Jain, Suvrit Sra, and Inderjit S. Dhillon. 2007. Information-theoretic metric learning. In Proceedings of the 24th international conference on Machine learning, ICML ’07, pages 209–216, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ayhan Demiriz</author>
<author>Kristin Bennett</author>
<author>Mark J Embrechts</author>
</authors>
<title>Semi-supervised clustering using genetic algorithms.</title>
<date>1999</date>
<booktitle>In In Artificial Neural Networks in Engineering (ANNIE-99,</booktitle>
<pages>809--814</pages>
<publisher>ASME Press.</publisher>
<contexts>
<context position="16913" citStr="Demiriz et al., 1999" startWordPosition="2765" endWordPosition="2768">-linked. There are two general strategies to incorporate constraints into clustering. The first is to adapt the similarity between instances (Xing et al., 2002; Klein et al., 2002) by adjusting the underlying distance metric. The main idea is to make the distance between must-linked instances – their neighbourhoods – smaller and the distance between cannot-linked instances – their neighbourhoods – larger. The second strategy is modifying the clustering algorithm itself so that search is biased towards a partitioning for which the constraints hold (Wagstaff and Cardie, 2000; Basu et al., 2002; Demiriz et al., 1999). Our proposed constrained clustering method relies on some ideas from (Klein et al., 2002). Thus, we explain it in more detail. (Klein et al., 2002) utilizes agglomerative hierarchical clustering with complete-linkage. The algorithm imposes constraints by changing the distance matrix according to the given constraints. The distances between must-linked instances are set to 0. That is not enough by itself, since if two instances are must-linked, other instances close to them should also get closer to each other. This means there is a need to propagate the constraints. This is done by calculati</context>
<context position="32524" citStr="Demiriz et al., 1999" startWordPosition="5345" endWordPosition="5348">presented quite differently in the feature space are both subjective or objective. Moreover, one usage group might be closer to a usage group from the opposing label than to a group with the same label. We see that our method reduces the annotation amount by 36% in comparison to uncertainty sampling and by 41% in comparison to random sampling to reach the performance of the SWSD system trained on fully annotated data. 5 Related Work One related line of research is constrained clustering also known as semi-supervised clustering (Xing et al., 2002; Wagstaff and Cardie, 2000; Grira et al., 2004; Demiriz et al., 1999). It has been applied to various datasets and tasks such as image and document categorization. To our knowledge, we are the first to utilize constrained clustering for a difficult NLP task. There have been only two previous works selecting constraints for constrained clustering actively (Basu et al., 2004; Klein et al., 2002). The biggest difference of our approach is that it is iterative as opposed to single pass. Active Learning (AL) (Settles, 2009; Settles and Craven, 2008; Hwa, 2004; Tong and Koller, 2001) builds another important set of related work. Our method is inspired by uncertainty </context>
</contexts>
<marker>Demiriz, Bennett, Embrechts, 1999</marker>
<rawString>Ayhan Demiriz, Kristin Bennett, and Mark J. Embrechts. 1999. Semi-supervised clustering using genetic algorithms. In In Artificial Neural Networks in Engineering (ANNIE-99, pages 809–814. ASME Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Grira</author>
<author>Michel Crucianu</author>
<author>Nozha Boujemaa</author>
</authors>
<title>Unsupervised and semi-supervised clustering: a brief survey.</title>
<date>2004</date>
<booktitle>In in A Review of Machine Learning Techniques for Processing Multimedia Content, Report of the MUSCLE European Network of Excellence.</booktitle>
<contexts>
<context position="15063" citStr="Grira et al., 2004" startWordPosition="2467" endWordPosition="2470">label clusters, we need to annotate some of the instances in each cluster. Then, we can accept the majority label found in a cluster as its label. Thus, some manual labelling is required, preferably a small amount. We propose to provide this small amount of annotated data prior to clustering, and then perform semi-supervised clustering. This way the provided labels will guide the clustering algorithm to generate the clusters that are more suitable for our end task, namely clusters where subjective and objective instances are grouped together. 4.1 Constrained Clustering Constrained clustering (Grira et al., 2004) also known as semi-supervised clustering is a recent development in the clustering literature. In addition to the similarity information required by unsupervised clustering, constrained clustering requires pairwise constraints. There are two types of constraints: (1) must-link and (2) cannot-link constraints. A must-link constraint dictates that two instances should be in the same cluster and a cannot-link dictates that two instances should not be in the same cluster. In this work, we only consider cannot-links, because of the definition of our SWSD task. Two instances sharing the same label </context>
<context position="32501" citStr="Grira et al., 2004" startWordPosition="5341" endWordPosition="5344"> usages which are represented quite differently in the feature space are both subjective or objective. Moreover, one usage group might be closer to a usage group from the opposing label than to a group with the same label. We see that our method reduces the annotation amount by 36% in comparison to uncertainty sampling and by 41% in comparison to random sampling to reach the performance of the SWSD system trained on fully annotated data. 5 Related Work One related line of research is constrained clustering also known as semi-supervised clustering (Xing et al., 2002; Wagstaff and Cardie, 2000; Grira et al., 2004; Demiriz et al., 1999). It has been applied to various datasets and tasks such as image and document categorization. To our knowledge, we are the first to utilize constrained clustering for a difficult NLP task. There have been only two previous works selecting constraints for constrained clustering actively (Basu et al., 2004; Klein et al., 2002). The biggest difference of our approach is that it is iterative as opposed to single pass. Active Learning (AL) (Settles, 2009; Settles and Craven, 2008; Hwa, 2004; Tong and Koller, 2001) builds another important set of related work. Our method is i</context>
</contexts>
<marker>Grira, Crucianu, Boujemaa, 2004</marker>
<rawString>Nizar Grira, Michel Crucianu, and Nozha Boujemaa. 2004. Unsupervised and semi-supervised clustering: a brief survey. In in A Review of Machine Learning Techniques for Processing Multimedia Content, Report of the MUSCLE European Network of Excellence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rebecca Hwa</author>
</authors>
<title>Sample selection for statistical parsing.</title>
<date>2004</date>
<journal>Comput. Linguist.,</journal>
<volume>30</volume>
<issue>3</issue>
<contexts>
<context position="33015" citStr="Hwa, 2004" startWordPosition="5429" endWordPosition="5430">as semi-supervised clustering (Xing et al., 2002; Wagstaff and Cardie, 2000; Grira et al., 2004; Demiriz et al., 1999). It has been applied to various datasets and tasks such as image and document categorization. To our knowledge, we are the first to utilize constrained clustering for a difficult NLP task. There have been only two previous works selecting constraints for constrained clustering actively (Basu et al., 2004; Klein et al., 2002). The biggest difference of our approach is that it is iterative as opposed to single pass. Active Learning (AL) (Settles, 2009; Settles and Craven, 2008; Hwa, 2004; Tong and Koller, 2001) builds another important set of related work. Our method is inspired by uncertainty sampling. We accomplish active selection in the clustering setting. 6 Conclusions In this paper, we explore a “cluster and label” strategy to reduce the human annotation effort needed to generate subjectivity sense-tagged data. In order to keep the noise in the semiautomatically labeled data minimal, we investigate different feature space types and evaluate their expressiveness. More importantly, we define a new algorithm called iterative constrained clustering (ICC) with an active cons</context>
</contexts>
<marker>Hwa, 2004</marker>
<rawString>Rebecca Hwa. 2004. Sample selection for statistical parsing. Comput. Linguist., 30(3):253–276, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Kilgarriff</author>
</authors>
<title>I dont believe in word senses.</title>
<date>1997</date>
<journal>Computers and the Humanities,</journal>
<volume>31</volume>
<issue>2</issue>
<contexts>
<context position="5101" citStr="Kilgarriff, 1997" startWordPosition="790" endWordPosition="792">a of good purity. The resulting data has sufficient purity to train reliable SWSD classifiers. SWSD classifiers trained on only 59% of the data achieve the same performance as classifiers trained on 100% of the data, resulting in a significant reduction in the annotation effort. Our results take SWSD another step closer to large scale application. 2 Cluster and Label Our approach is inspired by a method lexicographers commonly employ to create sense inventories, where they create inventories based on evidence found in corpora. They use concordance information to mine frequent usage patterns. (Kilgarriff, 1997) describes this process in detail. A lexicographer collects usages of a word in corpora and groups them into coherent sets. The instances in a set should have more in common with each other than with the instances in other sets, according to the criteria the lexicographer considers. After generating the sets, the lexicographer codes each set as a dictionary definition based on the common attributes of the instances. Our goal is similar. Instead of generating dictionary definitions, we are only interested in generating coherent sets of usages of a word, so that we can label each induced set – w</context>
</contexts>
<marker>Kilgarriff, 1997</marker>
<rawString>Adam Kilgarriff. 1997. I dont believe in word senses. Computers and the Humanities, 31(2):91–113.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Soo-Min Kim</author>
<author>Eduard Hovy</author>
</authors>
<title>Determining the sentiment of opinions.</title>
<date>2004</date>
<booktitle>In Proceedings of the Twentieth International Conference on Computational Linguistics (COLING 2004),</booktitle>
<pages>1267--1373</pages>
<location>Geneva, Switzerland.</location>
<contexts>
<context position="1058" citStr="Kim and Hovy, 2004" startWordPosition="155" endWordPosition="158">. In this work, we use a “cluster and label” strategy to generate labeled data for SWSD semiautomatically. We define a new algorithm called Iterative Constrained Clustering (ICC) to improve the clustering purity and, as a result, the quality of the generated data. Our experiments show that the SWSD classifiers trained on the ICC generated data by requiring only 59% of the labels can achieve the same performance as the classifiers trained on the full dataset. 1 Introduction Subjectivity lexicons (e.g., (Turney, 2002; Whitelaw et al., 2005; Riloff and Wiebe, 2003; Yu and Hatzivassiloglou, 2003; Kim and Hovy, 2004; Bloom et al., 2007; Andreevskaia and Bergler, 2008; Agarwal et al., 2009)) play an important role in opinion, sentiment, and subjectivity analysis. These systems typically look for the presence of clues in text. Recently, in (Akkaya et al., 2009), we showed that subjectivity clues are fairly ambiguous as to whether they express subjectivity or not – words in such lexicons may have both subjective and objective usages. We call this problem subjectivity sense ambiguity. Consider the following sentence containing the clue “attack”: (1) He was attacked by Milosevic for attempting to carve out a </context>
</contexts>
<marker>Kim, Hovy, 2004</marker>
<rawString>Soo-Min Kim and Eduard Hovy. 2004. Determining the sentiment of opinions. In Proceedings of the Twentieth International Conference on Computational Linguistics (COLING 2004), pages 1267– 1373, Geneva, Switzerland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Klein</author>
<author>K Toutanova</author>
<author>I T Ilhan</author>
<author>S D Kamvar</author>
<author>C Manning</author>
</authors>
<title>Combining heterogeneous classifiers for word-sense disambiguation.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL Workshop on ”Word Sense Disambiguatuion: Recent Successes and Future Directions,</booktitle>
<pages>74--80</pages>
<contexts>
<context position="16472" citStr="Klein et al., 2002" startWordPosition="2693" endWordPosition="2696">an be different usages, both having a subjective meaning. On the other hand, if two instances are labeled having opposing labels, we do not want them to be in the same cluster. Thus, we utilize cannot-links but not must-links. Constraints can be obtained from domain knowledge or from available instance labels. In our work, constraints are generated from instance labels. Each instance pair with opposing labels is considered to be cannot-linked. There are two general strategies to incorporate constraints into clustering. The first is to adapt the similarity between instances (Xing et al., 2002; Klein et al., 2002) by adjusting the underlying distance metric. The main idea is to make the distance between must-linked instances – their neighbourhoods – smaller and the distance between cannot-linked instances – their neighbourhoods – larger. The second strategy is modifying the clustering algorithm itself so that search is biased towards a partitioning for which the constraints hold (Wagstaff and Cardie, 2000; Basu et al., 2002; Demiriz et al., 1999). Our proposed constrained clustering method relies on some ideas from (Klein et al., 2002). Thus, we explain it in more detail. (Klein et al., 2002) utilizes </context>
<context position="18347" citStr="Klein et al., 2002" startWordPosition="2990" endWordPosition="2993"> property indirectly propagates the cannot-link constraints, since it will not allow two clusters to be merged if they contain instances that are cannot-linked. Although previous work report on average sub272 stantial improvement in the clustering purity, (Davidson et al., 2006) shows that even if the constraints are generated from gold-standard data, some constraint sets can decrease clustering purity. The results vary significantly depending on the specific set of constraints used. To our knowledge, there have been two approaches for selecting informative constraint sets (Basu et al., 2004; Klein et al., 2002). The method described in (Basu et al., 2004) uses the farthest-first traversal scheme. That strategy is not suitable in our setting, since we have only two labels. After selecting just one instance from both labels, this method becomes the same as random selection. The strategy described in (Klein et al., 2002) is more general. At first, the hierarchical clustering algorithm follows in a unconstrained fashion until some moderate number of clusters are remaining. Then, the algorithm starts to request constraints between roots whenever two clusters are merged. 4.2 Iterative Constrained Clusteri</context>
<context position="20498" citStr="Klein et al., 2002" startWordPosition="3326" endWordPosition="3329">we learn a Mahalanobis distance function following the method described in (Davis et al., 2007). (Davis et al., 2007) formulate the problem of distance metric learning as minimizing the differential relative entropy between two multivariate Gaussians under constraints. Note that using distance metric learning for imposing constraints was previously proposed by (Xing et al., 2002). (Xing et al., 2002) pose metric learning as a convex optimization problem. The reason we choose the metric learning method (Davis et al., 2007) over (Xing et al., 2002) is that it is computationally more efficient. (Klein et al., 2002) has a favourable property we want to keep. The constraints are imposed strictly, meaning that no cannot-linked instances can appear in the same cluster. I.e., they are hard constraints. In the case of metric learning, the constraints are not imposed strictly. In a new learned distance metric, two cannot-linked instances will be relatively distant, but there is no guarantee they will not end up in the same cluster. Although we think that metric learning makes a better use of provided constraints, we do not want to lose the benefit of hard constraints. Thus, we use both mechanisms in combinatio</context>
<context position="25729" citStr="Klein et al., 2002" startWordPosition="4199" endWordPosition="4202">mber denotes its label and its fill denotes whether or not it has been queried. In this example, silhconst scores Figure 1: Behaviour of selection function members 2 and 3 lower than 1. Thus, member 1 will not be selected, which is the right decision in this example. Both members 2 and 3 are close to clusters with an opposing label. In this example silhconst scores member 3 lower, which is farther away from already labeled members in the cluster. Thus, member 3 will be selected to be labeled. This type of behaviour results in an explorative strategy. The active selection strategy proposed by (Klein et al., 2002) is single pass. Thus, it does not have the opportunity to observe the complete cluster structure before choosing constraints. We hypothesize that our strategy will provide more informative constraints, since it has the advantage of being able to base the decision of which constraints to generate on fully observed cluster structure in each iteration. We call our proposed algorithm Iterative Constrained Clustering (ICC). In our final implementation, ICC starts by simply clustering the instances without any constraints. The algorithm queries the label of the prototypical member – the member clos</context>
<context position="26968" citStr="Klein et al., 2002" startWordPosition="4401" endWordPosition="4404">enter – of each cluster. Then, the described iterations begin. Algorithm 1 contains the complete ICC algorithm. Note that line 6 is equivalent to the algorithm of (Klein et al., 2002). 4.3 Experiments This section gives details on experiments to evaluate the purity of the semi-automatically generated subjectivity sense tagged data by our “cluster and label” strategy. We carry out detailed analysis to quantify the effect of the proposed active selection strategy and of metric learning on the purity of the generated data. We compare our active selection strategy to random selection and also to (Klein et al., 2002). The comparison is done on the senSWSD dataset. SenSWSD consists of three subsets, SENSEVAL I,II and III. Since we devel3 2 1 274 Figure 2: Label Purity – ICC vs. random selection oped our active selection algorithm on the SENSEVAL I subset, we use only SENSEVAL II and III subsets for comparison. We apply ICC to each word in the comparison set separately, and report cumulative results for the purity of the generated data. We report results for different percentages of the queried data amount (e.g. 10% means that the algorithm queried 10% of the data to create constraints). This way, we obtain</context>
<context position="28211" citStr="Klein et al., 2002" startWordPosition="4612" endWordPosition="4615">x the cluster number to 7 as in the context representation experiments. 4.3.1 Effect of Active Selection Strategy Figure 2 holds the comparison of ICC with silhconst selection to a random selection baseline. “majority” stands for majority label frequency in the dateset. We see that silhconst performs better than the random selection. By providing labels to only 25% of the data, we can achieve 87.67% pure fully labeled data. For comparison, we also evaluate the performance of (Klein et al., 2002) with their active constraint selection strategy as described in Section 4.1. Note that originally (Klein et al., 2002) requests the constraint between two roots. In our setting, it requests labels of the roots and then generates constraints from the obtained labels. Since we have a binary task, querying labels makes more sense. This has the advantage that more constraints from each request are obtained. Moreover, it allows a direct comparison to our algorithm. (Klein et al., 2002) does not use any metric learning. Thus, we run our algorithm also without metric learning, in order to compare the effectiveness of both active selection strategies fairly. In Figure 3, we see that silhconst performs better than the</context>
<context position="32851" citStr="Klein et al., 2002" startWordPosition="5399" endWordPosition="5402">random sampling to reach the performance of the SWSD system trained on fully annotated data. 5 Related Work One related line of research is constrained clustering also known as semi-supervised clustering (Xing et al., 2002; Wagstaff and Cardie, 2000; Grira et al., 2004; Demiriz et al., 1999). It has been applied to various datasets and tasks such as image and document categorization. To our knowledge, we are the first to utilize constrained clustering for a difficult NLP task. There have been only two previous works selecting constraints for constrained clustering actively (Basu et al., 2004; Klein et al., 2002). The biggest difference of our approach is that it is iterative as opposed to single pass. Active Learning (AL) (Settles, 2009; Settles and Craven, 2008; Hwa, 2004; Tong and Koller, 2001) builds another important set of related work. Our method is inspired by uncertainty sampling. We accomplish active selection in the clustering setting. 6 Conclusions In this paper, we explore a “cluster and label” strategy to reduce the human annotation effort needed to generate subjectivity sense-tagged data. In order to keep the noise in the semiautomatically labeled data minimal, we investigate different </context>
</contexts>
<marker>Klein, Toutanova, Ilhan, Kamvar, Manning, 2002</marker>
<rawString>D. Klein, K. Toutanova, I.T. Ilhan, S.D. Kamvar, and C. Manning. 2002. Combining heterogeneous classifiers for word-sense disambiguation. In Proceedings of the ACL Workshop on ”Word Sense Disambiguatuion: Recent Successes and Future Directions, pages 74–80, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mihalcea</author>
</authors>
<title>Instance based learning with automatic feature selection applied to Word Sense Disambiguation.</title>
<date>2002</date>
<booktitle>In Proceedings of the 19th International Conference on Computational Linguistics (COLING 2002),</booktitle>
<location>Taipei, Taiwan,</location>
<contexts>
<context position="10653" citStr="Mihalcea, 2002" startWordPosition="1720" endWordPosition="1721">equent lemmas). We do not filter out stop words, since they have been shown to be useful for various semantic similarity tasks in (Bullinaria and Levy, 2007). We use positive point-wise mutual information to compute values of the vector components, which has also been shown to be favourable in (Bullinaria and Levy, 2007). Purandere and Pedersen is the prominent representative of feature-based models. (Purandare and Pedersen, 2004) creates context vectors from local feature representations similar to the feature vectors found in supervised WSD. In this work, we use the following features from (Mihalcea, 2002) to build the local feature representation: (1) the target word itself and its part of speech, (2) surrounding context of 3 words and their part of speech, (3) the head of the noun phrase, (4) the first noun and verb before the target word, (5) the first noun and verb after the target word. skew local dsm add dsm mul mix rep average 79.90 80.50 80.50 83.53 85.23 appear-v 53.83 54.85 54.85 57.40 69.39 fine-a 70.07 72.26 70.07 74.45 75.18 interest-n 54.41 54.78 55.88 81.62 81.62 restraint-n 70.45 71.97 75.00 71.21 81.82 Table 1: Evaluation of Various Context Representations 3.1 Evaluation of Con</context>
</contexts>
<marker>Mihalcea, 2002</marker>
<rawString>R. Mihalcea. 2002. Instance based learning with automatic feature selection applied to Word Sense Disambiguation. In Proceedings of the 19th International Conference on Computational Linguistics (COLING 2002), Taipei, Taiwan, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeff Mitchell</author>
<author>Mirella Lapata</author>
</authors>
<title>Composition in distributional models of semantics.</title>
<date>2010</date>
<journal>Cognitive Science,</journal>
<volume>34</volume>
<issue>8</issue>
<contexts>
<context position="9549" citStr="Mitchell and Lapata, 2010" startWordPosition="1533" endWordPosition="1536">ly a high dimensional numeric vector. Note that this high dimensional vector represents word types, not word tokens. Thus, it cannot model a word instance in context. For token-based treatment, (Schutze, 1998) utilizes a second-order representation by averaging co-occurrence vectors of the words (corresponding to rows of the co-occurrence matrix) that occur in that particular context. It is important to note that (Schutze, 1998) uses an additive model for compositional representation. Recently, in (Akkaya et al., 2012), we found that a DSM built using multiplicative composition – proposed by (Mitchell and Lapata, 2010) for a different task – gives better performance than the model described by (Schutze, 1998). We test both methods in this paper, using the same semantic space. The space is built from a corpus consisting of 120 million tokens. The rows of the space correspond to word forms and the columns correspond to word lemmas present in the corpus. We adopt the parameters for our semantic space from (Mitchell and Lapata, 2010): window size of 10 and dimension size of 2000 (i.e., the 2000 most frequent lemmas). We do not filter out stop words, since they have been shown to be useful for various semantic s</context>
</contexts>
<marker>Mitchell, Lapata, 2010</marker>
<rawString>Jeff Mitchell and Mirella Lapata. 2010. Composition in distributional models of semantics. Cognitive Science, 34(8):1388–1429.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Purandare</author>
<author>T Pedersen</author>
</authors>
<title>Word sense discrimination by clustering contexts in vector and similarity spaces.</title>
<date>2004</date>
<booktitle>In Proceedings of the Conference on Computational Natural Language Learning (CoNLL 2004),</booktitle>
<location>Boston.</location>
<contexts>
<context position="10472" citStr="Purandare and Pedersen, 2004" startWordPosition="1690" endWordPosition="1693">respond to word lemmas present in the corpus. We adopt the parameters for our semantic space from (Mitchell and Lapata, 2010): window size of 10 and dimension size of 2000 (i.e., the 2000 most frequent lemmas). We do not filter out stop words, since they have been shown to be useful for various semantic similarity tasks in (Bullinaria and Levy, 2007). We use positive point-wise mutual information to compute values of the vector components, which has also been shown to be favourable in (Bullinaria and Levy, 2007). Purandere and Pedersen is the prominent representative of feature-based models. (Purandare and Pedersen, 2004) creates context vectors from local feature representations similar to the feature vectors found in supervised WSD. In this work, we use the following features from (Mihalcea, 2002) to build the local feature representation: (1) the target word itself and its part of speech, (2) surrounding context of 3 words and their part of speech, (3) the head of the noun phrase, (4) the first noun and verb before the target word, (5) the first noun and verb after the target word. skew local dsm add dsm mul mix rep average 79.90 80.50 80.50 83.53 85.23 appear-v 53.83 54.85 54.85 57.40 69.39 fine-a 70.07 72</context>
<context position="11716" citStr="Purandare and Pedersen, 2004" startWordPosition="1891" endWordPosition="1894"> 75.18 interest-n 54.41 54.78 55.88 81.62 81.62 restraint-n 70.45 71.97 75.00 71.21 81.82 Table 1: Evaluation of Various Context Representations 3.1 Evaluation of Context Representations In this section, we evaluate context representations for the context clustering task on the subjectivity sense tagged data, senSWSD. The evaluation is done separately for each word. We use the same clustering algorithm for all context representations: agglomerative hierarchical clustering with average linkage criteria. In all our experiments throughout the paper, we fix the cluster size to 7 as it is done in (Purandare and Pedersen, 2004). We think that is reasonable number since SENSEVAL III reports that the average number of senses per word is 6.47. We choose cluster purity as our evaluation metric. To compute cluster purity, we assign each cluster to a sense label, which is the most frequent one in the cluster. The number of the correctly assigned instances divided by the number of all the clustered instances gives us cluster purity. Row 1 of Table 1 holds the cumulative results over all the words in senSWSD (micro averages). The table also reports detailed results for 4 sample selected words from senSWSD. skew stands for t</context>
</contexts>
<marker>Purandare, Pedersen, 2004</marker>
<rawString>A. Purandare and T. Pedersen. 2004. Word sense discrimination by clustering contexts in vector and similarity spaces. In Proceedings of the Conference on Computational Natural Language Learning (CoNLL 2004), Boston.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen Riloff</author>
<author>Janyce Wiebe</author>
</authors>
<title>Learning extraction patterns for subjective expressions.</title>
<date>2003</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP-2003),</booktitle>
<pages>105--112</pages>
<location>Sapporo, Japan.</location>
<contexts>
<context position="1007" citStr="Riloff and Wiebe, 2003" startWordPosition="147" endWordPosition="150"> SWSD suffers from the knowledge acquisition bottleneck. In this work, we use a “cluster and label” strategy to generate labeled data for SWSD semiautomatically. We define a new algorithm called Iterative Constrained Clustering (ICC) to improve the clustering purity and, as a result, the quality of the generated data. Our experiments show that the SWSD classifiers trained on the ICC generated data by requiring only 59% of the labels can achieve the same performance as the classifiers trained on the full dataset. 1 Introduction Subjectivity lexicons (e.g., (Turney, 2002; Whitelaw et al., 2005; Riloff and Wiebe, 2003; Yu and Hatzivassiloglou, 2003; Kim and Hovy, 2004; Bloom et al., 2007; Andreevskaia and Bergler, 2008; Agarwal et al., 2009)) play an important role in opinion, sentiment, and subjectivity analysis. These systems typically look for the presence of clues in text. Recently, in (Akkaya et al., 2009), we showed that subjectivity clues are fairly ambiguous as to whether they express subjectivity or not – words in such lexicons may have both subjective and objective usages. We call this problem subjectivity sense ambiguity. Consider the following sentence containing the clue “attack”: (1) He was a</context>
</contexts>
<marker>Riloff, Wiebe, 2003</marker>
<rawString>Ellen Riloff and Janyce Wiebe. 2003. Learning extraction patterns for subjective expressions. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP-2003), pages 105–112, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Magnus Sahlgren</author>
</authors>
<title>The Word-Space Model: using distributional analysis to represent syntagmatic and paradigmatic relations between words in highdimensional vector spaces.</title>
<date>2006</date>
<tech>Ph.D. thesis,</tech>
<institution>Stockholm University.</institution>
<contexts>
<context position="8656" citStr="Sahlgren, 2006" startWordPosition="1386" endWordPosition="1387">(in Section 4.3.2). 3 Context Representations There has been much work on context representations of words for various NLP tasks. Clustering word instances in order to discriminate senses of a word is called Word Sense Discrimination. Context representations for this task rely on two main types of models: distributional semantic models (DSM) and feature-based models. 1Available at http://mpqa.cs.pitt.edu/ corpora 270 (Schutze, 1998), which is still a competitive model for word-sense discrimination by context clustering, relies on a distributional semantic model (DSM) (Turney and Pantel, 2010; Sahlgren, 2006; Bullinaria and Levy, 2007). A DSM is usually a word-to-word co-occurrence matrix – also called semantic space – such that each row represents the distribution of a target word in a large text corpus. Each row gives the semantic signature of a word, which is basically a high dimensional numeric vector. Note that this high dimensional vector represents word types, not word tokens. Thus, it cannot model a word instance in context. For token-based treatment, (Schutze, 1998) utilizes a second-order representation by averaging co-occurrence vectors of the words (corresponding to rows of the co-occ</context>
</contexts>
<marker>Sahlgren, 2006</marker>
<rawString>Magnus Sahlgren. 2006. The Word-Space Model: using distributional analysis to represent syntagmatic and paradigmatic relations between words in highdimensional vector spaces. Ph.D. thesis, Stockholm University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hinrich Sch¨utze</author>
<author>Emre Velipasaoglu</author>
<author>Jan O Pedersen</author>
</authors>
<title>Performance thresholding in practical text classification.</title>
<date>2006</date>
<booktitle>In Proceedings of the 15th ACM international conference on Information and knowledge management, CIKM ’06,</booktitle>
<pages>662--671</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<marker>Sch¨utze, Velipasaoglu, Pedersen, 2006</marker>
<rawString>Hinrich Sch¨utze, Emre Velipasaoglu, and Jan O. Pedersen. 2006. Performance thresholding in practical text classification. In Proceedings of the 15th ACM international conference on Information and knowledge management, CIKM ’06, pages 662–671, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Schutze</author>
</authors>
<title>Automatic word sense discrimination.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<volume>24</volume>
<issue>1</issue>
<contexts>
<context position="8478" citStr="Schutze, 1998" startWordPosition="1359" endWordPosition="1360">on 3) and our proposed constrained clustering algorithm (in Section 4.2). Then, on mturkSWSD, we evaluate the quality of semiautomatically generated data for SWSD classification (in Section 4.3.2). 3 Context Representations There has been much work on context representations of words for various NLP tasks. Clustering word instances in order to discriminate senses of a word is called Word Sense Discrimination. Context representations for this task rely on two main types of models: distributional semantic models (DSM) and feature-based models. 1Available at http://mpqa.cs.pitt.edu/ corpora 270 (Schutze, 1998), which is still a competitive model for word-sense discrimination by context clustering, relies on a distributional semantic model (DSM) (Turney and Pantel, 2010; Sahlgren, 2006; Bullinaria and Levy, 2007). A DSM is usually a word-to-word co-occurrence matrix – also called semantic space – such that each row represents the distribution of a target word in a large text corpus. Each row gives the semantic signature of a word, which is basically a high dimensional numeric vector. Note that this high dimensional vector represents word types, not word tokens. Thus, it cannot model a word instance </context>
<context position="12412" citStr="Schutze, 1998" startWordPosition="2014" endWordPosition="2015">umber of senses per word is 6.47. We choose cluster purity as our evaluation metric. To compute cluster purity, we assign each cluster to a sense label, which is the most frequent one in the cluster. The number of the correctly assigned instances divided by the number of all the clustered instances gives us cluster purity. Row 1 of Table 1 holds the cumulative results over all the words in senSWSD (micro averages). The table also reports detailed results for 4 sample selected words from senSWSD. skew stands for the percentage of the most frequent label. dsm add is the representation based on (Schutze, 1998), dsm mul stands for the representation as described in (Akkaya et al., 2012) and local features is the local feature representation based on (Purandare and Pedersen, 2004). The results show that among dsm mul, dsm add, and local features; dsm mul performs the best. When we look at the context clustering results for single words separately, we observe that the performance of different representations vary. There is not a single winner among all words. Thus, perhaps choosing one single representation for all the words is not optimal. Having that in mind, we try merging the dsm mul and local fea</context>
</contexts>
<marker>Schutze, 1998</marker>
<rawString>H. Schutze. 1998. Automatic word sense discrimination. Computational Linguistics, 24(1):97–124.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Burr Settles</author>
<author>Mark Craven</author>
</authors>
<title>An analysis of active learning strategies for sequence labeling tasks.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’08,</booktitle>
<pages>1070--1079</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="33004" citStr="Settles and Craven, 2008" startWordPosition="5425" endWordPosition="5428">ned clustering also known as semi-supervised clustering (Xing et al., 2002; Wagstaff and Cardie, 2000; Grira et al., 2004; Demiriz et al., 1999). It has been applied to various datasets and tasks such as image and document categorization. To our knowledge, we are the first to utilize constrained clustering for a difficult NLP task. There have been only two previous works selecting constraints for constrained clustering actively (Basu et al., 2004; Klein et al., 2002). The biggest difference of our approach is that it is iterative as opposed to single pass. Active Learning (AL) (Settles, 2009; Settles and Craven, 2008; Hwa, 2004; Tong and Koller, 2001) builds another important set of related work. Our method is inspired by uncertainty sampling. We accomplish active selection in the clustering setting. 6 Conclusions In this paper, we explore a “cluster and label” strategy to reduce the human annotation effort needed to generate subjectivity sense-tagged data. In order to keep the noise in the semiautomatically labeled data minimal, we investigate different feature space types and evaluate their expressiveness. More importantly, we define a new algorithm called iterative constrained clustering (ICC) with an </context>
</contexts>
<marker>Settles, Craven, 2008</marker>
<rawString>Burr Settles and Mark Craven. 2008. An analysis of active learning strategies for sequence labeling tasks. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’08, pages 1070–1079, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Burr Settles</author>
</authors>
<title>Active Learning Literature Survey.</title>
<date>2009</date>
<tech>Technical Report 1648,</tech>
<institution>University of Wisconsin– Madison.</institution>
<contexts>
<context position="32978" citStr="Settles, 2009" startWordPosition="5423" endWordPosition="5424">rch is constrained clustering also known as semi-supervised clustering (Xing et al., 2002; Wagstaff and Cardie, 2000; Grira et al., 2004; Demiriz et al., 1999). It has been applied to various datasets and tasks such as image and document categorization. To our knowledge, we are the first to utilize constrained clustering for a difficult NLP task. There have been only two previous works selecting constraints for constrained clustering actively (Basu et al., 2004; Klein et al., 2002). The biggest difference of our approach is that it is iterative as opposed to single pass. Active Learning (AL) (Settles, 2009; Settles and Craven, 2008; Hwa, 2004; Tong and Koller, 2001) builds another important set of related work. Our method is inspired by uncertainty sampling. We accomplish active selection in the clustering setting. 6 Conclusions In this paper, we explore a “cluster and label” strategy to reduce the human annotation effort needed to generate subjectivity sense-tagged data. In order to keep the noise in the semiautomatically labeled data minimal, we investigate different feature space types and evaluate their expressiveness. More importantly, we define a new algorithm called iterative constrained</context>
</contexts>
<marker>Settles, 2009</marker>
<rawString>Burr Settles. 2009. Active Learning Literature Survey. Technical Report 1648, University of Wisconsin– Madison.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pang-Ning Tan</author>
<author>Michael Steinbach</author>
<author>Vipin Kumar</author>
</authors>
<title>Introduction to Data Mining, (First Edition).</title>
<date>2005</date>
<publisher>Addison-Wesley Longman Publishing Co., Inc.,</publisher>
<location>Boston, MA, USA.</location>
<contexts>
<context position="23793" citStr="Tan et al., 2005" startWordPosition="3859" endWordPosition="3862">...Instances; I{L}...Labeled Instances; Matrixdist...Distance Matrix} straints will move the clustering in each iteration towards better separation of S and O instances. To define informativeness, we define a scoring function, which is used to score each data point on its goodness. The lower the score, the more likely it is that the instance is mis-clustered. Choosing the data point with the lowest score will likely change clustering borders in the next iteration. Our scoring function is based on the silhouette coefficient, a popular unsupervised cluster validation metric to measure goodness (Tan et al., 2005) of a cluster member. Basically, the silhouette score assigns a cluster member that is close to another cluster a lower score, and a cluster member that is closer to the cluster center a higher score. That is partly what we want. In addition, we do not want to penalize a cluster member that is close to another cluster having members with the same label. For this purpose, we calculate the silhouette score only over clusters with an opposing label (i.e., holding members with an opposing label). In addition, we consider only instances labeled so far when computing the score. We call this new coef</context>
</contexts>
<marker>Tan, Steinbach, Kumar, 2005</marker>
<rawString>Pang-Ning Tan, Michael Steinbach, and Vipin Kumar. 2005. Introduction to Data Mining, (First Edition). Addison-Wesley Longman Publishing Co., Inc., Boston, MA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Simon Tong</author>
<author>Daphne Koller</author>
</authors>
<title>Support vector machine active learning with applications to text classification.</title>
<date>2001</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>2--45</pages>
<contexts>
<context position="30420" citStr="Tong and Koller, 2001" startWordPosition="4990" endWordPosition="4993">nstances are weighted as 1 and the instances with propagated labels are weighted by their silhconst score, since that measure gives the goodness of an instance. The score is defined between -1 and 1. This score is normalized between 0 and 1, before it is used as a weight. SVM classifiers from the Weka package (Witten and Frank., 2005) with its default settings are used 275 as in (Akkaya et al., 2011). We implement two baselines. The first is simple random sampling and the second is uncertainty sampling, which is an active learning (AL) method. We use “simple margin” selection as described in (Tong and Koller, 2001). It selects, in each iteration, the instance closest to the decision boundary of the trained SVM. Each method is run until it reaches the accuracy of training fully on the gold-standard data. ICC reaches that boundary when provided only 59% of the labels in the dataset. For uncertainty sampling and random sampling, these values are 92% and 100%, respectively. In Figure 4, we see the SWSD accuracy for different queried data percentages. “full” stands for training fully on gold-standard data. We see that training SWSD on semi-automatically labeled data by ICC does consistently better than uncer</context>
<context position="33039" citStr="Tong and Koller, 2001" startWordPosition="5431" endWordPosition="5434">ervised clustering (Xing et al., 2002; Wagstaff and Cardie, 2000; Grira et al., 2004; Demiriz et al., 1999). It has been applied to various datasets and tasks such as image and document categorization. To our knowledge, we are the first to utilize constrained clustering for a difficult NLP task. There have been only two previous works selecting constraints for constrained clustering actively (Basu et al., 2004; Klein et al., 2002). The biggest difference of our approach is that it is iterative as opposed to single pass. Active Learning (AL) (Settles, 2009; Settles and Craven, 2008; Hwa, 2004; Tong and Koller, 2001) builds another important set of related work. Our method is inspired by uncertainty sampling. We accomplish active selection in the clustering setting. 6 Conclusions In this paper, we explore a “cluster and label” strategy to reduce the human annotation effort needed to generate subjectivity sense-tagged data. In order to keep the noise in the semiautomatically labeled data minimal, we investigate different feature space types and evaluate their expressiveness. More importantly, we define a new algorithm called iterative constrained clustering (ICC) with an active constraint selection strateg</context>
</contexts>
<marker>Tong, Koller, 2001</marker>
<rawString>Simon Tong and Daphne Koller. 2001. Support vector machine active learning with applications to text classification. Journal of Machine Learning Research, 2:45–66.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
<author>Patrick Pantel</author>
</authors>
<title>From frequency to meaning: Vector space models of semantics.</title>
<date>2010</date>
<contexts>
<context position="8640" citStr="Turney and Pantel, 2010" startWordPosition="1382" endWordPosition="1385"> for SWSD classification (in Section 4.3.2). 3 Context Representations There has been much work on context representations of words for various NLP tasks. Clustering word instances in order to discriminate senses of a word is called Word Sense Discrimination. Context representations for this task rely on two main types of models: distributional semantic models (DSM) and feature-based models. 1Available at http://mpqa.cs.pitt.edu/ corpora 270 (Schutze, 1998), which is still a competitive model for word-sense discrimination by context clustering, relies on a distributional semantic model (DSM) (Turney and Pantel, 2010; Sahlgren, 2006; Bullinaria and Levy, 2007). A DSM is usually a word-to-word co-occurrence matrix – also called semantic space – such that each row represents the distribution of a target word in a large text corpus. Each row gives the semantic signature of a word, which is basically a high dimensional numeric vector. Note that this high dimensional vector represents word types, not word tokens. Thus, it cannot model a word instance in context. For token-based treatment, (Schutze, 1998) utilizes a second-order representation by averaging co-occurrence vectors of the words (corresponding to ro</context>
</contexts>
<marker>Turney, Pantel, 2010</marker>
<rawString>Peter D. Turney and Patrick Pantel. 2010. From frequency to meaning: Vector space models of semantics. March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Turney</author>
</authors>
<title>Thumbs up or thumbs down? Semantic orientation applied to unsupervised classification of reviews.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL-02),</booktitle>
<pages>417--424</pages>
<location>Philadelphia, Pennsylvania.</location>
<contexts>
<context position="960" citStr="Turney, 2002" startWordPosition="141" endWordPosition="142">e senses of a word. Not surprisingly, SWSD suffers from the knowledge acquisition bottleneck. In this work, we use a “cluster and label” strategy to generate labeled data for SWSD semiautomatically. We define a new algorithm called Iterative Constrained Clustering (ICC) to improve the clustering purity and, as a result, the quality of the generated data. Our experiments show that the SWSD classifiers trained on the ICC generated data by requiring only 59% of the labels can achieve the same performance as the classifiers trained on the full dataset. 1 Introduction Subjectivity lexicons (e.g., (Turney, 2002; Whitelaw et al., 2005; Riloff and Wiebe, 2003; Yu and Hatzivassiloglou, 2003; Kim and Hovy, 2004; Bloom et al., 2007; Andreevskaia and Bergler, 2008; Agarwal et al., 2009)) play an important role in opinion, sentiment, and subjectivity analysis. These systems typically look for the presence of clues in text. Recently, in (Akkaya et al., 2009), we showed that subjectivity clues are fairly ambiguous as to whether they express subjectivity or not – words in such lexicons may have both subjective and objective usages. We call this problem subjectivity sense ambiguity. Consider the following sent</context>
</contexts>
<marker>Turney, 2002</marker>
<rawString>Peter Turney. 2002. Thumbs up or thumbs down? Semantic orientation applied to unsupervised classification of reviews. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL-02), pages 417–424, Philadelphia, Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kiri Wagstaff</author>
<author>Claire Cardie</author>
</authors>
<title>Clustering with instance-level constraints.</title>
<date>2000</date>
<booktitle>In Proceedings of the Seventeenth International Conference on Machine Learning (ICML-2000),</booktitle>
<pages>1103--1110</pages>
<contexts>
<context position="16871" citStr="Wagstaff and Cardie, 2000" startWordPosition="2757" endWordPosition="2760">ith opposing labels is considered to be cannot-linked. There are two general strategies to incorporate constraints into clustering. The first is to adapt the similarity between instances (Xing et al., 2002; Klein et al., 2002) by adjusting the underlying distance metric. The main idea is to make the distance between must-linked instances – their neighbourhoods – smaller and the distance between cannot-linked instances – their neighbourhoods – larger. The second strategy is modifying the clustering algorithm itself so that search is biased towards a partitioning for which the constraints hold (Wagstaff and Cardie, 2000; Basu et al., 2002; Demiriz et al., 1999). Our proposed constrained clustering method relies on some ideas from (Klein et al., 2002). Thus, we explain it in more detail. (Klein et al., 2002) utilizes agglomerative hierarchical clustering with complete-linkage. The algorithm imposes constraints by changing the distance matrix according to the given constraints. The distances between must-linked instances are set to 0. That is not enough by itself, since if two instances are must-linked, other instances close to them should also get closer to each other. This means there is a need to propagate </context>
<context position="32481" citStr="Wagstaff and Cardie, 2000" startWordPosition="5337" endWordPosition="5340">possible that two groups of usages which are represented quite differently in the feature space are both subjective or objective. Moreover, one usage group might be closer to a usage group from the opposing label than to a group with the same label. We see that our method reduces the annotation amount by 36% in comparison to uncertainty sampling and by 41% in comparison to random sampling to reach the performance of the SWSD system trained on fully annotated data. 5 Related Work One related line of research is constrained clustering also known as semi-supervised clustering (Xing et al., 2002; Wagstaff and Cardie, 2000; Grira et al., 2004; Demiriz et al., 1999). It has been applied to various datasets and tasks such as image and document categorization. To our knowledge, we are the first to utilize constrained clustering for a difficult NLP task. There have been only two previous works selecting constraints for constrained clustering actively (Basu et al., 2004; Klein et al., 2002). The biggest difference of our approach is that it is iterative as opposed to single pass. Active Learning (AL) (Settles, 2009; Settles and Craven, 2008; Hwa, 2004; Tong and Koller, 2001) builds another important set of related w</context>
</contexts>
<marker>Wagstaff, Cardie, 2000</marker>
<rawString>Kiri Wagstaff and Claire Cardie. 2000. Clustering with instance-level constraints. In Proceedings of the Seventeenth International Conference on Machine Learning (ICML-2000), pages 1103–1110.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Casey Whitelaw</author>
<author>Navendu Garg</author>
<author>Shlomo Argamon</author>
</authors>
<title>Using appraisal taxonomies for sentiment analysis.</title>
<date>2005</date>
<booktitle>In Proceedings of CIKM-05, the ACM SIGIR Conference on Information and Knowledge Management,</booktitle>
<location>Bremen, DE.</location>
<contexts>
<context position="983" citStr="Whitelaw et al., 2005" startWordPosition="143" endWordPosition="146">word. Not surprisingly, SWSD suffers from the knowledge acquisition bottleneck. In this work, we use a “cluster and label” strategy to generate labeled data for SWSD semiautomatically. We define a new algorithm called Iterative Constrained Clustering (ICC) to improve the clustering purity and, as a result, the quality of the generated data. Our experiments show that the SWSD classifiers trained on the ICC generated data by requiring only 59% of the labels can achieve the same performance as the classifiers trained on the full dataset. 1 Introduction Subjectivity lexicons (e.g., (Turney, 2002; Whitelaw et al., 2005; Riloff and Wiebe, 2003; Yu and Hatzivassiloglou, 2003; Kim and Hovy, 2004; Bloom et al., 2007; Andreevskaia and Bergler, 2008; Agarwal et al., 2009)) play an important role in opinion, sentiment, and subjectivity analysis. These systems typically look for the presence of clues in text. Recently, in (Akkaya et al., 2009), we showed that subjectivity clues are fairly ambiguous as to whether they express subjectivity or not – words in such lexicons may have both subjective and objective usages. We call this problem subjectivity sense ambiguity. Consider the following sentence containing the clu</context>
</contexts>
<marker>Whitelaw, Garg, Argamon, 2005</marker>
<rawString>Casey Whitelaw, Navendu Garg, and Shlomo Argamon. 2005. Using appraisal taxonomies for sentiment analysis. In Proceedings of CIKM-05, the ACM SIGIR Conference on Information and Knowledge Management, Bremen, DE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Witten</author>
<author>E Frank</author>
</authors>
<date>2005</date>
<booktitle>Data Mining: Practical Machine Learning Tools and Techniques, Second Edition.</booktitle>
<publisher>Morgan Kaufmann,</publisher>
<marker>Witten, Frank, 2005</marker>
<rawString>I. Witten and E. Frank. 2005. Data Mining: Practical Machine Learning Tools and Techniques, Second Edition. Morgan Kaufmann, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric P Xing</author>
<author>Andrew Y Ng</author>
<author>Michael I Jordan</author>
<author>Stuart J Russell</author>
</authors>
<title>Distance metric learning with application to clustering with side-information. In</title>
<date>2002</date>
<booktitle>NIPS,</booktitle>
<pages>505--512</pages>
<contexts>
<context position="16451" citStr="Xing et al., 2002" startWordPosition="2689" endWordPosition="2692"> each other. They can be different usages, both having a subjective meaning. On the other hand, if two instances are labeled having opposing labels, we do not want them to be in the same cluster. Thus, we utilize cannot-links but not must-links. Constraints can be obtained from domain knowledge or from available instance labels. In our work, constraints are generated from instance labels. Each instance pair with opposing labels is considered to be cannot-linked. There are two general strategies to incorporate constraints into clustering. The first is to adapt the similarity between instances (Xing et al., 2002; Klein et al., 2002) by adjusting the underlying distance metric. The main idea is to make the distance between must-linked instances – their neighbourhoods – smaller and the distance between cannot-linked instances – their neighbourhoods – larger. The second strategy is modifying the clustering algorithm itself so that search is biased towards a partitioning for which the constraints hold (Wagstaff and Cardie, 2000; Basu et al., 2002; Demiriz et al., 1999). Our proposed constrained clustering method relies on some ideas from (Klein et al., 2002). Thus, we explain it in more detail. (Klein et</context>
<context position="19302" citStr="Xing et al., 2002" startWordPosition="3138" endWordPosition="3141">st, the hierarchical clustering algorithm follows in a unconstrained fashion until some moderate number of clusters are remaining. Then, the algorithm starts to request constraints between roots whenever two clusters are merged. 4.2 Iterative Constrained Clustering Our proposed algorithm is closely related to (Klein et al., 2002). We share the same backbone: (1) the agglomerative hierarchical clustering with complete-linkage and (2) the mechanism to impose cannot-link constraints described in Section 4.1. For our algorithm, we implement a second mechanism for imposing constraints proposed by (Xing et al., 2002) (Section 4.2.1) and use both mechanisms in combination. We also propose a novel constraint selection method (Section 4.2.2). 4.2.1 Imposing Constraints (Klein et al., 2002) imposes cannot-link constraints by adjusting the distance between cannotlinked pairs heuristically and by relying on complete linkage for propagation. Although this approach was shown to be effective, we believe it does not make full use of the provided constraints. We believe that learning a new distance metric will result in more reliable distance estimates between all instances. For this purpose, we learn a Mahalanobis </context>
<context position="32454" citStr="Xing et al., 2002" startWordPosition="5333" endWordPosition="5336">of the word. It is possible that two groups of usages which are represented quite differently in the feature space are both subjective or objective. Moreover, one usage group might be closer to a usage group from the opposing label than to a group with the same label. We see that our method reduces the annotation amount by 36% in comparison to uncertainty sampling and by 41% in comparison to random sampling to reach the performance of the SWSD system trained on fully annotated data. 5 Related Work One related line of research is constrained clustering also known as semi-supervised clustering (Xing et al., 2002; Wagstaff and Cardie, 2000; Grira et al., 2004; Demiriz et al., 1999). It has been applied to various datasets and tasks such as image and document categorization. To our knowledge, we are the first to utilize constrained clustering for a difficult NLP task. There have been only two previous works selecting constraints for constrained clustering actively (Basu et al., 2004; Klein et al., 2002). The biggest difference of our approach is that it is iterative as opposed to single pass. Active Learning (AL) (Settles, 2009; Settles and Craven, 2008; Hwa, 2004; Tong and Koller, 2001) builds another</context>
</contexts>
<marker>Xing, Ng, Jordan, Russell, 2002</marker>
<rawString>Eric P. Xing, Andrew Y. Ng, Michael I. Jordan, and Stuart J. Russell. 2002. Distance metric learning with application to clustering with side-information. In NIPS, pages 505–512.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hong Yu</author>
<author>Vasileios Hatzivassiloglou</author>
</authors>
<title>Towards answering opinion questions: Separating facts from opinions and identifying the polarity of opinion sentences.</title>
<date>2003</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP-2003),</booktitle>
<pages>129--136</pages>
<location>Sapporo, Japan.</location>
<contexts>
<context position="1038" citStr="Yu and Hatzivassiloglou, 2003" startWordPosition="151" endWordPosition="154">nowledge acquisition bottleneck. In this work, we use a “cluster and label” strategy to generate labeled data for SWSD semiautomatically. We define a new algorithm called Iterative Constrained Clustering (ICC) to improve the clustering purity and, as a result, the quality of the generated data. Our experiments show that the SWSD classifiers trained on the ICC generated data by requiring only 59% of the labels can achieve the same performance as the classifiers trained on the full dataset. 1 Introduction Subjectivity lexicons (e.g., (Turney, 2002; Whitelaw et al., 2005; Riloff and Wiebe, 2003; Yu and Hatzivassiloglou, 2003; Kim and Hovy, 2004; Bloom et al., 2007; Andreevskaia and Bergler, 2008; Agarwal et al., 2009)) play an important role in opinion, sentiment, and subjectivity analysis. These systems typically look for the presence of clues in text. Recently, in (Akkaya et al., 2009), we showed that subjectivity clues are fairly ambiguous as to whether they express subjectivity or not – words in such lexicons may have both subjective and objective usages. We call this problem subjectivity sense ambiguity. Consider the following sentence containing the clue “attack”: (1) He was attacked by Milosevic for attemp</context>
</contexts>
<marker>Yu, Hatzivassiloglou, 2003</marker>
<rawString>Hong Yu and Vasileios Hatzivassiloglou. 2003. Towards answering opinion questions: Separating facts from opinions and identifying the polarity of opinion sentences. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP-2003), pages 129–136, Sapporo, Japan.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>