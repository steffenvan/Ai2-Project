<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.011887">
<title confidence="0.9984435">
Dictionary Definitions based Homograph Identification using a
Generative Hierarchical Model
</title>
<author confidence="0.998051">
Anagha Kulkarni Jamie Callan
</author>
<affiliation confidence="0.9961205">
Language Technologies Institute
School of Computer Science, Carnegie Mellon University
</affiliation>
<address confidence="0.520712">
5000 Forbes Ave, Pittsburgh, PA 15213, USA
</address>
<email confidence="0.995772">
{anaghak, callan}@cs.cmu.edu
</email>
<sectionHeader confidence="0.998564" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.987780875">
A solution to the problem of homograph
(words with multiple distinct meanings) iden-
tification is proposed and evaluated in this pa-
per. It is demonstrated that a mixture model
based framework is better suited for this task
than the standard classification algorithms –
relative improvement of 7% in F1 measure
and 14% in Cohen’s kappa score is observed.
</bodyText>
<sectionHeader confidence="0.999502" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999955923076923">
Lexical ambiguity resolution is an important re-
search problem for the fields of information re-
trieval and machine translation (Sanderson, 2000;
Chan et al., 2007). However, making fine-grained
sense distinctions for words with multiple closely-
related meanings is a subjective task (Jorgenson,
1990; Palmer et al., 2005), which makes it difficult
and error-prone. Fine-grained sense distinctions
aren’t necessary for many tasks, thus a possibly-
simpler alternative is lexical disambiguation at the
level of homographs (Ide and Wilks, 2006).
Homographs are a special case of semantically
ambiguous words: Words that can convey multi-
ple distinct meanings. For example, the word bark
can imply two very different concepts – ‘outer
layer of a tree trunk’, or, ‘the sound made by a
dog’ and thus is a homograph. Ironically, the defi-
nition of the word ‘homograph’ is itself ambiguous
and much debated; however, in this paper we con-
sistently use the above definition.
If the goal is to do word-sense disambiguation
of homographs in a very large corpus, a manually-
generated homograph inventory may be impracti-
cal. In this case, the first step is to determine which
words in a lexicon are homographs. This problem
is the subject of this paper.
</bodyText>
<sectionHeader confidence="0.837727" genericHeader="method">
2 Finding the Homographs in a Lexicon
</sectionHeader>
<bodyText confidence="0.999943052631579">
Our goal is to identify the homographs in a large
lexicon. We assume that manual labor is a scarce
resource, but that online dictionaries are plentiful
(as is the case on the web). Given a word from the
lexicon, definitions are obtained from eight dic-
tionaries: Cambridge Advanced Learners Diction-
ary (CALD), Compact Oxford English Dictionary,
MSN Encarta, Longman Dictionary of Contempo-
rary English (LDOCE), The Online Plain Text
English Dictionary, Wiktionary, WordNet and
Wordsmyth. Using multiple dictionaries provides
more evidence for the inferences to be made and
also minimizes the risk of missing meanings be-
cause a particular dictionary did not include one or
more meanings of a word (a surprisingly common
situation). We can now rephrase the problem defi-
nition as that of determining which words in the
lexicon are homographs given a set of dictionary
definitions for each of the words.
</bodyText>
<subsectionHeader confidence="0.863792">
2.1 Features
</subsectionHeader>
<bodyText confidence="0.9999355">
We use nine meta-features in our algorithm. In-
stead of directly using common lexical features
such as n-grams we use meta-features which are
functions defined on the lexical features. This ab-
</bodyText>
<page confidence="0.997532">
85
</page>
<reference confidence="0.223678">
Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pages 85–88,
Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics
</reference>
<bodyText confidence="0.999327333333333">
straction is essential in this setup for the generality
of the approach. For each word w to be classified
each of the following meta-features are computed.
</bodyText>
<listItem confidence="0.8869062">
1. Cohesiveness Score: Mean of the cosine simi-
larities between each pair of definitions of w.
2. Average Number of Definitions: The average
number of definitions per dictionary.
3. Average Definition Length: The average
length (in words) of definitions of w.
4. Average Number of Null Similarities: The
number of definition pairs that have zero co-
sine similarity score (no word overlap).
5. Number of Tokens: The sum of the lengths
(in words) of the definitions of w.
6. Number of Types: The size of the vocabulary
used by the set of definitions of w.
7. Number of Definition Pairs with n Word
Overlaps: The number of definition pairs that
have more than n=2 words in common.
8. Number of Definition Pairs with m Word
Overlaps: The number of definition pairs that
have more than m=4 words in common.
9. Post Pruning Maximum Similarity: (below)
</listItem>
<bodyText confidence="0.999945038461539">
The last feature sorts the pair-wise cosine similar-
ity scores in ascending order, prunes the top n% of
the scores, and uses the maximum remaining score
as the feature value. This feature is less ad-hoc
than it may seem. The set of definitions is formed
from eight dictionaries, so almost identical defini-
tions are a frequent phenomenon, which makes the
maximum cosine similarity a useless feature. A
pruned maximum turns out to be useful informa-
tion. In this work n=15 was found to be most in-
formative using a tuning dataset.
Each of the above features provides some
amount of discriminative power to the algorithm.
For example, we hypothesized that on average the
cohesiveness score will be lower for homographs
than for non-homographs. Figure 1 provides an
illustration. If empirical support was observed for
such a hypothesis about a candidate feature then
the feature was selected. This empirical evidence
was derived from only the training portion of the
data (Section 3.1).
The above features are computed on definitions
stemmed with the Porter Stemmer. Closed class
words, such as articles and prepositions, and dic-
tionary-specific stopwords, such as ‘transitive’,
‘intransitive’, and ‘countable’, were also removed.
</bodyText>
<figureCaption confidence="0.909489">
Figure 1. Histogram of Cohesiveness scores for Homo-
graphs and Non-homographs.
</figureCaption>
<subsectionHeader confidence="0.997088">
2.2 Models
</subsectionHeader>
<bodyText confidence="0.999641142857143">
We formulate the homograph detection process as
a generative hierarchical model. Figure 2 provides
the plate notation of the graphical model. The la-
tent (unobserved) variable Z models the class in-
formation: homograph or non-homograph. Node X
is the conditioned random vector (Z is the condi-
tioning variable) that models the feature vector.
</bodyText>
<figureCaption confidence="0.997379">
Figure 2. Plate notation for the proposed model.
</figureCaption>
<bodyText confidence="0.999327142857143">
This setup results in a mixture model with two
components, one for each class. The Z is assumed
to be Bernoulli distributed and thus parameterized
by a single parameter p. We experiment with two
continuous multivariate distributions, Dirichlet and
Multivariate Normal (MVN), for the conditional
distribution of X|Z.
</bodyText>
<equation confidence="0.87042275">
Z — Bernoulli (p)
X|Z — Dirichlet (az)
OR
X|Z — MVN (muz, covz)
</equation>
<bodyText confidence="0.9999552">
We will refer to the parameters of the condi-
tional distribution as Oz. For the Dirichlet distribu-
tion, Oz is a ten-dimensional vector az = (az1, ..,
az10). For the MVN, Oz represents a nine-
dimensional mean vector muz = (muz1, .., muz9)
</bodyText>
<equation confidence="0.8324585">
X
Z
N
p
</equation>
<page confidence="0.968145">
86
</page>
<bodyText confidence="0.999969178571429">
and a nine-by-nine-dimensional covariance matrix
covz. We use maximum likelihood estimators
(MLE) for estimating the parameters (p, Oz). The
MLEs for Bernoulli and MVN parameters have
analytical solutions. Dirichlet parameters were es-
timated using an estimation method proposed and
implemented by Tom Minka1.
We experiment with three model setups: Super-
vised, semi-supervised, and unsupervised. In the
supervised setup we use the training data described
in Section 3.1 for parameter estimation and then
use thus fitted models to classify the tuning and
test dataset. We refer to this as the Model I. In
Model II, the semi-supervised setup, the training
data is used to initialize the Expectation-
Maximization (EM) algorithm (Dempster et al.,
1977) and the unlabeled data, described in Section
3.1, updates the initial estimates. The Viterbi
(hard) EM algorithm was used in these experi-
ments. The E-step was modified to include only
those unlabeled data-points for which the posterior
probability was above certain threshold. As a re-
sult, the M-step operates only on these high poste-
rior data-points. The optimal threshold value was
selected using a tuning set (Section 3.1). The unsu-
pervised setup, Model III, is similar to the semi-
supervised setup except that the EM algorithm is
initialized using an informed guess by the authors.
</bodyText>
<sectionHeader confidence="0.997761" genericHeader="method">
3 Data
</sectionHeader>
<bodyText confidence="0.99986425">
In this study, we concentrate on recognizing
homographic nouns, because homographic ambi-
guity is much more common in nouns than in
verbs, adverbs or adjectives.
</bodyText>
<subsectionHeader confidence="0.999774">
3.1 Gold Standard Data
</subsectionHeader>
<bodyText confidence="0.984072916666667">
A set of potentially-homographic nouns was identi-
fied by selecting all words with at least two noun
definitions in both CALD and LDOCE. This set
contained 3,348 words.
225 words were selected for manual annotation
as homograph or non-homograph by random sam-
pling of words that were on the above list and used
in prior psycholinguistic studies of homographs
(Twilley et al., 1994; Azuma, 1996) or on the Aca-
demic Word List (Coxhead, 2000).
Four annotators at, the Qualitative Data Analysis
Program at the University of Pittsburgh, were
</bodyText>
<footnote confidence="0.748799">
1 http://research.microsoft.com/~minka/software/fastfit/
</footnote>
<bodyText confidence="0.999516333333333">
trained to identify homographs using sets of dic-
tionary definitions. After training, each of the 225
words was annotated by each annotator. On aver-
age, annotators categorized each word in just 19
seconds. The inter-annotator agreement was 0.68,
measured by Fleiss’ Kappa.
23 words on which annotators disagreed (2/2
vote) were discarded, leaving a set of 202 words
(the “gold standard”) on which at least 3 of the 4
annotators agreed. The best agreement between the
gold standard and a human annotator was 0.87
kappa, and the worst was 0.78. The class distribu-
tion (homographs and non-homographs) was 0.63,
0.37. The set of 3,123 words that were not anno-
tated was the unlabeled data for the EM algorithm.
</bodyText>
<sectionHeader confidence="0.995502" genericHeader="evaluation">
4 Experiments and Results
</sectionHeader>
<bodyText confidence="0.999992757575757">
A stratified division of the gold standard data in
the proportion of 0.75 and 0.25 was done in the
first step. The smaller portion of this division was
held out as the testing dataset. The bigger portion
was further divided into two portions of 0.75 and
0.25 for the training set and the tuning set, respec-
tively. The best and the worst kappa between a
human annotator and the test set are 0.92 and 0.78.
Each of the three models described in Section
2.2 were experimented with both Dirichlet and
MVN as the conditional. An additional experiment
using two standard classification algorithms – Ker-
nel Based Naïve Bayes (NB) and Support Vector
Machines (SVM) was performed. We refer to this
as the baseline experiment. The Naïve Bayes clas-
sifier outperformed SVM on the tuning as well as
the test set and thus we report NB results only. A
four-fold cross-validation was employed for the all
the experiments on the tuning set. The results are
summarized in Table 1. The reported precision,
recall and F1 values are for the homograph class.
The naïve assumption of class conditional fea-
ture independence is common to simple Naïve
Bayes classifier, a kernel based NB classifier;
however, unlike simple NB it is capable of model-
ing non-Gaussian distributions. Note that in spite
of this advantage the kernel based NB is outper-
formed by the MVN based hierarchical model. Our
nine features are by definition correlated and thus
it was our hypothesis that a multivariate distribu-
tion such as MVN which can capture the covari-
ance amongst the features will be a better fit. The
above finding confirms this hypothesis.
</bodyText>
<page confidence="0.997229">
87
</page>
<table confidence="0.9999096">
Tuning Set Test Set
Preci- Recall F1 Kappa Preci- Recall F1 Kappa
sion sion
Model I – Dirichlet 0.84 0.74 0.78 0.47 0.81 0.62 0.70 0.34
Model II – Dirichlet 0.85 0.71 0.77 0.45 0.81 0.60 0.68 0.33
Model III – Dirichlet 0.78 0.74 0.76 0.37 0.82 0.56 0.67 0.32
Model I – MVN 0.70 0.75 0.78 0.32 0.80 0.73 0.76 0.41
Model II – MVN 0.74 0.82 0.78 0.34 0.71 0.79 0.74 0.25
Model III – MVN 0.69 0.89 0.77 0.22 0.64 0.84 0.72 0.22
Baseline – NB 0.82 0.73 0.77 0.43 0.82 0.63 0.71 0.36
</table>
<tableCaption confidence="0.999594">
Table 1. Results for the six models and the baseline on the tuning and test set.
</tableCaption>
<bodyText confidence="0.99995732">
One of the known situations when mixture mod-
els out-perform standard classification algorithms
is when the data comes from highly overlapping
distributions. In such cases the classification algo-
rithms that try to place the decision boundary in a
sparse area are prone to higher error-rates than
mixture model based approach. We believe that
this is explanations of the observed results. On the
test set a relative improvement of 7% in F1 and
14% in kappa statistic is obtained using the MVN
mixture model.
The results for the semi-supervised models are
non-conclusive. Our post-experimental analysis
reveals that the parameter updation process using
the unlabeled data has an effect of overly separat-
ing the two overlapping distributions. This is trig-
gered by our threshold based EM methodology
which includes only those data-points for which
the model is highly confident; however such data-
points are invariable from the non-overlapping re-
gions of the distribution, which gives a false view
to the learner that the distributions are less over-
lapping. We believe that the unsupervised models
also suffer from the above problem in addition to
the possibility of poor initializations.
</bodyText>
<sectionHeader confidence="0.999237" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999957533333333">
We have demonstrated in this paper that the prob-
lem of homograph identification can be ap-
proached using dictionary definitions as the source
of information about the word. Further more, using
multiple dictionaries provides more evidence for
the inferences to be made and also minimizes the
risk of missing few meanings of the word.
We can conclude that by modeling the underly-
ing data generation process as a mixture model, the
problem of homograph identification can be per-
formed with reasonable accuracy.
The capability of identifying homographs from
non-homographs enables us to take on the next
steps of sense-inventory generation and lexical
ambiguity resolution.
</bodyText>
<sectionHeader confidence="0.999029" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9941842">
We thank Shay Cohen and Dr. Matthew Harrison for the
helpful discussions. This work was supported in part by
the Pittsburgh Science of Learning Center which is
funded by the National Science Foundation, award
number SBE-0354420.
</bodyText>
<sectionHeader confidence="0.998367" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999891785714286">
A. Dempster, N. Laird, and D. Rubin. 1977. Maximum
likelihood from incomplete data via the EM algo-
rithm. Journal of the Royal Statistical Society, Series
B, 39(1):1–38.
A. Coxhead. 2000. A New Academic Word List.
TESOL, Quarterly, 34(2): 213-238.
J. Jorgenson. 1990. The psychological reality of word
senses. Journal of Psycholinguistic Research 19:167-
190.
L. Twilley, P. Dixon, D. Taylor, and K. Clark. 1994.
University of Alberta norms of relative meaning fre-
quency for 566 homographs. Memory and Cognition.
22(1): 111-126.
M. Sanderson. 2000. Retrieving with good sense. In-
formation Retrieval, 2(1): 49-69.
M. Palmer, H. Dang, C. Fellbaum, 2005. Making fine-
grained and coarse-grained sense distinctions. Jour-
nal of Natural Language Engineering. 13: 137-163.
N. Ide and Y. Wilks. 2006. Word Sense Disambigua-
tion, Algorithms and Applications. Springer,
Dordrecht, The Netherlands.
T. Azuma. 1996. Familiarity and Relatedness of Word
Meanings: Ratings for 110 Homographs. Behavior
Research Methods, Instruments and Computers.
28(1): 109-124.
Y. Chan, H. Ng, and D. Chiang. 2007. Proceeding of
Association for Computational Linguistics, Prague,
Czech Republic.
</reference>
<page confidence="0.999408">
88
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.932839">
<title confidence="0.994299">Dictionary Definitions based Homograph Identification using a Generative Hierarchical Model</title>
<author confidence="0.999797">Anagha Kulkarni Jamie Callan</author>
<affiliation confidence="0.997534">Language Technologies Institute School of Computer Science, Carnegie Mellon University</affiliation>
<address confidence="0.999989">5000 Forbes Ave, Pittsburgh, PA 15213, USA</address>
<email confidence="0.999852">anaghak@cs.cmu.edu</email>
<email confidence="0.999852">callan@cs.cmu.edu</email>
<abstract confidence="0.994153">solution to the problem of (words with multiple distinct meanings) identification is proposed and evaluated in this paper. It is demonstrated that a mixture model based framework is better suited for this task than the standard classification algorithms – relative improvement of 7% in F1 measure and 14% in Cohen’s kappa score is observed.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<booktitle>Proceedings of ACL-08: HLT, Short Papers (Companion Volume),</booktitle>
<pages>85--88</pages>
<marker></marker>
<rawString>Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pages 85–88,</rawString>
</citation>
<citation valid="true">
<authors>
<author>Columbus</author>
</authors>
<date>2008</date>
<booktitle>c�2008 Association for Computational Linguistics</booktitle>
<location>Ohio, USA,</location>
<marker>Columbus, 2008</marker>
<rawString>Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Dempster</author>
<author>N Laird</author>
<author>D Rubin</author>
</authors>
<title>Maximum likelihood from incomplete data via the EM algorithm.</title>
<date>1977</date>
<journal>Journal of the Royal Statistical Society, Series B,</journal>
<volume>39</volume>
<issue>1</issue>
<marker>Dempster, Laird, Rubin, 1977</marker>
<rawString>A. Dempster, N. Laird, and D. Rubin. 1977. Maximum likelihood from incomplete data via the EM algorithm. Journal of the Royal Statistical Society, Series B, 39(1):1–38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Coxhead</author>
</authors>
<title>A New Academic Word List.</title>
<date>2000</date>
<journal>TESOL, Quarterly,</journal>
<volume>34</volume>
<issue>2</issue>
<pages>213--238</pages>
<marker>Coxhead, 2000</marker>
<rawString>A. Coxhead. 2000. A New Academic Word List. TESOL, Quarterly, 34(2): 213-238.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Jorgenson</author>
</authors>
<title>The psychological reality of word senses.</title>
<date>1990</date>
<journal>Journal of Psycholinguistic Research</journal>
<pages>19--167</pages>
<contexts>
<context position="954" citStr="Jorgenson, 1990" startWordPosition="135" endWordPosition="136"> multiple distinct meanings) identification is proposed and evaluated in this paper. It is demonstrated that a mixture model based framework is better suited for this task than the standard classification algorithms – relative improvement of 7% in F1 measure and 14% in Cohen’s kappa score is observed. 1 Introduction Lexical ambiguity resolution is an important research problem for the fields of information retrieval and machine translation (Sanderson, 2000; Chan et al., 2007). However, making fine-grained sense distinctions for words with multiple closelyrelated meanings is a subjective task (Jorgenson, 1990; Palmer et al., 2005), which makes it difficult and error-prone. Fine-grained sense distinctions aren’t necessary for many tasks, thus a possiblysimpler alternative is lexical disambiguation at the level of homographs (Ide and Wilks, 2006). Homographs are a special case of semantically ambiguous words: Words that can convey multiple distinct meanings. For example, the word bark can imply two very different concepts – ‘outer layer of a tree trunk’, or, ‘the sound made by a dog’ and thus is a homograph. Ironically, the definition of the word ‘homograph’ is itself ambiguous and much debated; how</context>
</contexts>
<marker>Jorgenson, 1990</marker>
<rawString>J. Jorgenson. 1990. The psychological reality of word senses. Journal of Psycholinguistic Research 19:167-190.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Twilley</author>
<author>P Dixon</author>
<author>D Taylor</author>
<author>K Clark</author>
</authors>
<title>University of Alberta norms of relative meaning frequency for 566 homographs. Memory and Cognition.</title>
<date>1994</date>
<volume>22</volume>
<issue>1</issue>
<pages>111--126</pages>
<marker>Twilley, Dixon, Taylor, Clark, 1994</marker>
<rawString>L. Twilley, P. Dixon, D. Taylor, and K. Clark. 1994. University of Alberta norms of relative meaning frequency for 566 homographs. Memory and Cognition. 22(1): 111-126.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Sanderson</author>
</authors>
<title>Retrieving with good sense.</title>
<date>2000</date>
<journal>Information Retrieval,</journal>
<volume>2</volume>
<issue>1</issue>
<pages>49--69</pages>
<contexts>
<context position="799" citStr="Sanderson, 2000" startWordPosition="113" endWordPosition="114">negie Mellon University 5000 Forbes Ave, Pittsburgh, PA 15213, USA {anaghak, callan}@cs.cmu.edu Abstract A solution to the problem of homograph (words with multiple distinct meanings) identification is proposed and evaluated in this paper. It is demonstrated that a mixture model based framework is better suited for this task than the standard classification algorithms – relative improvement of 7% in F1 measure and 14% in Cohen’s kappa score is observed. 1 Introduction Lexical ambiguity resolution is an important research problem for the fields of information retrieval and machine translation (Sanderson, 2000; Chan et al., 2007). However, making fine-grained sense distinctions for words with multiple closelyrelated meanings is a subjective task (Jorgenson, 1990; Palmer et al., 2005), which makes it difficult and error-prone. Fine-grained sense distinctions aren’t necessary for many tasks, thus a possiblysimpler alternative is lexical disambiguation at the level of homographs (Ide and Wilks, 2006). Homographs are a special case of semantically ambiguous words: Words that can convey multiple distinct meanings. For example, the word bark can imply two very different concepts – ‘outer layer of a tree </context>
</contexts>
<marker>Sanderson, 2000</marker>
<rawString>M. Sanderson. 2000. Retrieving with good sense. Information Retrieval, 2(1): 49-69.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Palmer</author>
<author>H Dang</author>
<author>C Fellbaum</author>
</authors>
<title>Making finegrained and coarse-grained sense distinctions.</title>
<date>2005</date>
<journal>Journal of Natural Language Engineering.</journal>
<volume>13</volume>
<pages>137--163</pages>
<contexts>
<context position="976" citStr="Palmer et al., 2005" startWordPosition="137" endWordPosition="140">t meanings) identification is proposed and evaluated in this paper. It is demonstrated that a mixture model based framework is better suited for this task than the standard classification algorithms – relative improvement of 7% in F1 measure and 14% in Cohen’s kappa score is observed. 1 Introduction Lexical ambiguity resolution is an important research problem for the fields of information retrieval and machine translation (Sanderson, 2000; Chan et al., 2007). However, making fine-grained sense distinctions for words with multiple closelyrelated meanings is a subjective task (Jorgenson, 1990; Palmer et al., 2005), which makes it difficult and error-prone. Fine-grained sense distinctions aren’t necessary for many tasks, thus a possiblysimpler alternative is lexical disambiguation at the level of homographs (Ide and Wilks, 2006). Homographs are a special case of semantically ambiguous words: Words that can convey multiple distinct meanings. For example, the word bark can imply two very different concepts – ‘outer layer of a tree trunk’, or, ‘the sound made by a dog’ and thus is a homograph. Ironically, the definition of the word ‘homograph’ is itself ambiguous and much debated; however, in this paper we</context>
</contexts>
<marker>Palmer, Dang, Fellbaum, 2005</marker>
<rawString>M. Palmer, H. Dang, C. Fellbaum, 2005. Making finegrained and coarse-grained sense distinctions. Journal of Natural Language Engineering. 13: 137-163.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Ide</author>
<author>Y Wilks</author>
</authors>
<title>Word Sense Disambiguation, Algorithms and Applications.</title>
<date>2006</date>
<publisher>Springer,</publisher>
<location>Dordrecht, The Netherlands.</location>
<contexts>
<context position="1194" citStr="Ide and Wilks, 2006" startWordPosition="168" endWordPosition="171">ent of 7% in F1 measure and 14% in Cohen’s kappa score is observed. 1 Introduction Lexical ambiguity resolution is an important research problem for the fields of information retrieval and machine translation (Sanderson, 2000; Chan et al., 2007). However, making fine-grained sense distinctions for words with multiple closelyrelated meanings is a subjective task (Jorgenson, 1990; Palmer et al., 2005), which makes it difficult and error-prone. Fine-grained sense distinctions aren’t necessary for many tasks, thus a possiblysimpler alternative is lexical disambiguation at the level of homographs (Ide and Wilks, 2006). Homographs are a special case of semantically ambiguous words: Words that can convey multiple distinct meanings. For example, the word bark can imply two very different concepts – ‘outer layer of a tree trunk’, or, ‘the sound made by a dog’ and thus is a homograph. Ironically, the definition of the word ‘homograph’ is itself ambiguous and much debated; however, in this paper we consistently use the above definition. If the goal is to do word-sense disambiguation of homographs in a very large corpus, a manuallygenerated homograph inventory may be impractical. In this case, the first step is t</context>
</contexts>
<marker>Ide, Wilks, 2006</marker>
<rawString>N. Ide and Y. Wilks. 2006. Word Sense Disambiguation, Algorithms and Applications. Springer, Dordrecht, The Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Azuma</author>
</authors>
<title>Familiarity and Relatedness of Word Meanings: Ratings for 110 Homographs.</title>
<date>1996</date>
<journal>Behavior Research Methods, Instruments and Computers.</journal>
<volume>28</volume>
<issue>1</issue>
<pages>109--124</pages>
<marker>Azuma, 1996</marker>
<rawString>T. Azuma. 1996. Familiarity and Relatedness of Word Meanings: Ratings for 110 Homographs. Behavior Research Methods, Instruments and Computers. 28(1): 109-124.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Chan</author>
<author>H Ng</author>
<author>D Chiang</author>
</authors>
<date>2007</date>
<booktitle>Proceeding of Association for Computational Linguistics,</booktitle>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="819" citStr="Chan et al., 2007" startWordPosition="115" endWordPosition="118">ersity 5000 Forbes Ave, Pittsburgh, PA 15213, USA {anaghak, callan}@cs.cmu.edu Abstract A solution to the problem of homograph (words with multiple distinct meanings) identification is proposed and evaluated in this paper. It is demonstrated that a mixture model based framework is better suited for this task than the standard classification algorithms – relative improvement of 7% in F1 measure and 14% in Cohen’s kappa score is observed. 1 Introduction Lexical ambiguity resolution is an important research problem for the fields of information retrieval and machine translation (Sanderson, 2000; Chan et al., 2007). However, making fine-grained sense distinctions for words with multiple closelyrelated meanings is a subjective task (Jorgenson, 1990; Palmer et al., 2005), which makes it difficult and error-prone. Fine-grained sense distinctions aren’t necessary for many tasks, thus a possiblysimpler alternative is lexical disambiguation at the level of homographs (Ide and Wilks, 2006). Homographs are a special case of semantically ambiguous words: Words that can convey multiple distinct meanings. For example, the word bark can imply two very different concepts – ‘outer layer of a tree trunk’, or, ‘the sou</context>
</contexts>
<marker>Chan, Ng, Chiang, 2007</marker>
<rawString>Y. Chan, H. Ng, and D. Chiang. 2007. Proceeding of Association for Computational Linguistics, Prague, Czech Republic.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>