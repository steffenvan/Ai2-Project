<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.007345">
<title confidence="0.9974165">
Robust Dialog Management with N-best Hypotheses Using Dialog Examples
and Agenda
</title>
<author confidence="0.995505">
Cheongjae Lee, Sangkeun Jung and Gary Geunbae Lee
</author>
<affiliation confidence="0.993553333333333">
Pohang University of Science and Technology
Department of Computer Science and Engineering
Pohang, Republic of Korea
</affiliation>
<email confidence="0.997502">
flcj80,hugman,gbleel@postech.ac.kr
</email>
<sectionHeader confidence="0.998588" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998973625">
This work presents an agenda-based approach
to improve the robustness of the dialog man-
ager by using dialog examples and n-best
recognition hypotheses. This approach sup-
ports n-best hypotheses in the dialog man-
ager and keeps track of the dialog state us-
ing a discourse interpretation algorithm with
the agenda graph and focus stack. Given
the agenda graph and n-best hypotheses, the
system can predict the next system actions
to maximize multi-level score functions. To
evaluate the proposed method, a spoken dia-
log system for a building guidance robot was
developed. Preliminary evaluation shows this
approach would be effective to improve the ro-
bustness of example-based dialog modeling.
</bodyText>
<sectionHeader confidence="0.999468" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99979975">
Development of spoken dialog systems involves hu-
man language technologies which must cooperate
to answer user queries. Since the performance in
human language technologies such as Automatic
Speech Recognition (ASR) and Natural Language
Understanding (NLU)1 have been improved, this ad-
vance has made it possible to develop spoken dialog
systems for many different application domains.
Nevertheless, there are major problems for practi-
cal spoken dialog systems. One of them which must
be considered by the Dialog Manager (DM) is the
error propagation from ASR and NLU modules. In
</bodyText>
<footnote confidence="0.973844">
1Through this paper, we will use the term natural language
to include both spoken language and written language
</footnote>
<bodyText confidence="0.9998105">
general, errors in spoken dialog systems are preva-
lent due to errors in speech recognition or language
understanding. These errors can cause the dialog
system to misunderstand a user and in turn lead to
an inappropriate response. To avoid these errors, a
basic solution is to improve the accuracy and robust-
ness of the recognition and understanding processes.
However, it has been impossible to develop perfect
ASR and NLU modules because of noisy environ-
ments and unexpected input. Therefore, the devel-
opment of robust dialog management has also been
one of the most important goals in research on prac-
tical spoken dialog systems.
In the dialog manager, a popular method to deal
with these errors is to adopt dialog mechanisms for
detecting and repairing potential errors at the con-
versational level (McTear et al., 2005; Torres et al.,
2005; Lee et al., 2007). In human-computer com-
munication, the goal of error recovery strategy is
to maximize the user’s satisfaction of using the sys-
tem by guiding for the repair of the wrong informa-
tion by human-computer interaction. On the other
hand, there are different approaches to improve the
robustness of dialog management using n-best hy-
potheses. Rather than Markov Decision Processes
(MDPs), partially observable MDPs (POMDPs) po-
tentially provide a much more powerful framework
for robust dialog modeling since they consider n-
best hypotheses to estimate the distribution of the
belief state (Williams and Young, 2007).
In recent, we proposed another data-driven ap-
proach for the dialog modeling called Example-
based Dialog Modeling (EBDM) (Lee et al., 2006a).
However, difficulties occur when attempting to de-
</bodyText>
<page confidence="0.973179">
630
</page>
<note confidence="0.714783">
Proceedings of ACL-08: HLT, pages 630–637,
</note>
<page confidence="0.537049">
Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics
</page>
<bodyText confidence="0.9997845">
ploy EBDM in practical spoken dialog systems in
which ASR and NLU errors are frequent. Thus,
this paper proposes a new method to improve the ro-
bustness of the EBDM framework using an agenda-
based approach and n-best recognition hypotheses.
We consider a domain-specific agenda to estimate
the best dialog state and example because, in task-
oriented systems, a current dialog state is highly cor-
related to the previous dialog state. We have also
used the example-based error recovery approach to
handle exceptional cases due to noisy input or unex-
pected focus shift.
This paper is organized as follows. Previous re-
lated work is described in Section 2, followed by the
methodology and problems of the example-based di-
alog modeling in Section 3. An agenda-based ap-
proach for heuristics is presented in Section 4. Fol-
lowing that, we explain greedy selection with n-best
hypotheses in Section 5. Section 6 describes the
error recovery strategy to handle unexpected cases.
Then, Section 7 provides the experimental results of
a real user evaluation to verify our approach. Finally,
we draw conclusions and make suggestions for fu-
ture work in Section 8.
</bodyText>
<sectionHeader confidence="0.999879" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999945857142857">
In many spoken dialog systems that have been devel-
oped recently, various knowledge sources are used.
One of the knowledge sources, which are usually
application-dependent, is an agenda or task model.
These are powerful representations for segmenting
large tasks into more reasonable subtasks (Rich and
Sidner, 1998; Bohus and Rudnicky, 2003; Young et
al., 2007). These are manually designed for various
purposes including dialog modeling, search space
reduction, domain knowledge, and user simulation.
In Collagen (Rich and Sidner, 1998), a plan tree,
which is an approximate representation of a partial
SharedPlan, is composed of alternating act and plan
recipe nodes for internal discourse state representa-
tion and discourse interpretation.
In addition, Bohus and Rudnicky (2003) have pre-
sented a RavenClaw dialog management which is
an agenda-based architecture using hierarchical task
decomposition and an expectation agenda. For mod-
eling dialog, the domain-specific dialog control is
represented in the Dialog Task Specification layer
using a tree of dialog agents, with each agent han-
dling a certain subtask of the dialog task.
Recently, the problem of a large state space in
POMDP framework has been solved by grouping
states into partitions using user goal trees and on-
tology rules as heuristics (Young et al., 2007).
In this paper, we are interested in exploring algo-
rithms that would integrate this knowledge source
for users to achieve domain-specific goals. We used
an agenda graph whose hierarchy reflects the natu-
ral order of dialog control. This graph is used to both
keep track of the dialog state and to select the best
example using multiple recognition hypotheses for
augmenting previous EBDM framework.
</bodyText>
<sectionHeader confidence="0.997797" genericHeader="method">
3 Example-based Dialog Modeling
</sectionHeader>
<bodyText confidence="0.99992725">
Our approach is implemented based on Example-
Based Dialog Modeling (EBDM) which is one of
generic dialog modelings. We begin with a brief
overview of the EBDM framework in this sec-
tion. EBDM was inspired by Example-Based Ma-
chine Translation (EBMT) (Nagao, 1984), a trans-
lation system in which the source sentence can be
translated using similar example fragments within a
large parallel corpus, without knowledge of the lan-
guage’s structure. The idea of EBMT can be ex-
tended to determine the next system actions by find-
ing similar dialog examples within the dialog cor-
pus. The system action can be predicted by finding
semantically similar user utterances with the dialog
state. The dialog state is defined as the set of relevant
internal variables that affect the next system action.
EBDM needs to automatically construct an example
database from the dialog corpus. Dialog Example
DataBase (DEDB) is semantically indexed to gen-
eralize the data in which the indexing keys can be
determined according to state variables chosen by
a system designer for domain-specific applications
(Figure 1). Each turn pair (user turn, system turn) in
the dialog corpus is mapped to semantic instances in
the DEDB. The index constraints represent the state
variables which are domain-independent attributes.
To determine the next system action, there are three
processes in the EBDM framework as follows:
</bodyText>
<listItem confidence="0.980097">
• Query Generation: The dialog manager
makes Structured Query Language (SQL)
</listItem>
<page confidence="0.996025">
631
</page>
<figureCaption confidence="0.999656">
Figure 1: Indexing scheme for dialog example database on building guidance domain
</figureCaption>
<bodyText confidence="0.997586555555556">
statement using discourse history and NLU re-
sults.
Example Search: The dialog manager
searches for semantically similar dialog exam-
ples in the DEDB given the current dialog state.
If no example is retrieved, some state variables
can be ignored by relaxing particular variables
according to the level of importance given the
dialog’s genre and domain.
</bodyText>
<listItem confidence="0.719735">
•
Example Selection: The dialog manager se-
</listItem>
<bodyText confidence="0.9742505625">
lects the best example to maximize the ut-
terance similarity measure based on lexico-
semantic similarity and discourse history simi-
larity.
Figure 2 illustrates the overall strategy of EBDM
framework for spoken dialog systems. The EBDM
framework is a simple and powerful approach
to rapidly develop natural language interfaces for
multi-domain dialog processing (Lee et al., 2006b).
However, in the context of spoken dialog system for
domain-specific tasks, this framework must solve
two problems: (1) Keeping track of the dialog state
with a view to ensuring steady progress towards task
completion, (2) Supporting n-best recognition hy-
potheses to improve the robustness of dialog man-
ager. Consequently, we sought to solve these prob-
</bodyText>
<figureCaption confidence="0.6517445">
Figure 2: Strategy of the Example-Based Dialog
Modeling (EBDM) framework.
</figureCaption>
<bodyText confidence="0.996718">
lems by integrating the agenda graph as a heuristic
which reflects the natural hierarchy and order of sub-
tasks needed to complete the task.
</bodyText>
<listItem confidence="0.727682">
•
</listItem>
<sectionHeader confidence="0.965097" genericHeader="method">
4 Agenda Graph
</sectionHeader>
<bodyText confidence="0.999928714285714">
In this paper, agenda graph G is simply a way of
encoding the domain-specific dialog control to com-
plete the task. An agenda is one of the subtask flows,
which are possible paths from root node to terminal
node. G is composed of nodes (v) which correspond
to possible intermediate steps in the process of com-
pleting the specified task, and edges (e) which con-
</bodyText>
<page confidence="0.994998">
632
</page>
<figureCaption confidence="0.988168">
Figure 3: Example of an agenda graph for a building
guidance.
</figureCaption>
<listItem confidence="0.912479857142857">
nect nodes. In other words, v corresponds to user
goal state to achieve domain-specific subtask in its
expected agenda. Each node includes three different
components: (1) A precondition that must be true
before the subtask is executed; (2) A description of
the node that includes its label and identifier; and
(3) Links to nodes that will be executed at the subse-
</listItem>
<bodyText confidence="0.986685782608696">
quent turn. For every edge eZj _ (vZ7 vj), we defined
a transition probability based on prior knowledge of
dialog flows. This probability can be assigned based
on empirical analysis of human-computer conversa-
tions, assuming that the users behave in consistent,
goal-directed ways. Alternatively, it can be assigned
manually at the discretion of the system developer
to control the dialog flow. This heuristic has ad-
vantages for practical spoken dialog system because
a key condition for successful task-oriented dialog
system is that the user and system know which task
or subtask is currently being executed. To exem-
plify, Figure 3 illustrates part of the agenda graph for
PHOPE, a building guidance robot using the spoken
dialog system. In Figure 3, G is represented by a
Directed Acyclic Graph (DAG), where each link in
the graph reflects a transition between one user goal
state and the next. The set of paths in G represent
an agenda designed by the system developer. We
adapted DAG representation because it is more in-
tuitive and flexible than hierarchical tree represen-
tation. The syntax for graph representation in our
system is described by an XML schema (Figure 4).
</bodyText>
<subsectionHeader confidence="0.996429">
4.1 Mapping Examples to Nodes
</subsectionHeader>
<bodyText confidence="0.999708333333333">
In the agenda graph G, each node v should hold
relevant dialog examples corresponding to user goal
states. Therefore, the dialog examples in DEDB are
</bodyText>
<figureCaption confidence="0.995991">
Figure 4: XML description for the agenda graph
</figureCaption>
<bodyText confidence="0.999763777777778">
mapped to a user goal state when a precondition of
the node is true. Initially, the root node of the DAG is
the starting state, where there is no dialog example.
Then, the attributes of each dialog example are ex-
amined via the preconditions of each user goal node
by breadth-first traversal. If the precondition is true,
the node holds relevant that may appear in the user’s
goal state. The method of selecting the best of these
examples will be described in 5.
</bodyText>
<subsectionHeader confidence="0.89569">
4.2 Discourse Interpretation
</subsectionHeader>
<bodyText confidence="0.997232133333333">
Inspired by Collagen (Rich and Sidner, 1998; Lesh
et al., 2001), we investigated a discourse interpre-
tation algorithm to consider how the current user’s
goal can contribute to the current agenda in a focus
stack according to Lochbaum’s discourse interpreta-
tion algorithm (Lochbaum, 1998). The focus stack
takes into account the discourse structure by keeping
track of discourse states. In our system, the focus
stack is a set of user goal nodes which lead to com-
pletion of the subtask. The top on the focus stack is
the previous node in this set. The focus stack is up-
dated after every utterance. To interpret the type of
the discourse state, this breaks down into five main
cases of possible current node for an observed user’s
goal:
</bodyText>
<listItem confidence="0.9965704">
• NEW TASK: Starting a new task to complete a
new agenda (Child of the root).
• NEW SUB TASK: Starting a new subtask to
partially shift focus (A different child of the
parent).
</listItem>
<page confidence="0.914005">
633
</page>
<listItem confidence="0.994283857142857">
• NEXT TASK: Working on the next subtask con-
tributing to current agenda (Its child node).
• CURRENT TASK: Repeating or modifying the
observed goal on the current subtask (Current
node).
• PARENT TASK: Modifying the observation on
the previous subtask (Parent node).
</listItem>
<bodyText confidence="0.980129955555555">
Nodes in parentheses denote the topological position
of the current node relative to the top node on the
focus stack. If NEXT TASK is selected, the current
node is pushed to the focus stack. NEXT TASK cov-
ers totally focused behavior, i.e., when there are no
unexpected focus shifts. This occurs when the cur-
rent user utterance is highly correlated to the pre-
vious system utterance. The remaining four cases
cover various types of discourse state. For example,
NEW SUB TASK involves starting a new subtask to
partially shift focus, thereby popping the previous
goal off the focus stack and pushing a new user goal
for the new subtask. NEW TASK, which is placed
on the node linked to root node, involves starting a
new task to complete a new agenda. Therefore, a di-
alog is re-started and the current node is pushed onto
the focus stack with the current user goal as its first
element.
If none of the above cases holds, the discourse in-
terpretation concludes that the current input should
be rejected because we expect user utterances to be
correlated to the previous turn in a task-oriented do-
main. Therefore, this interpretation does not con-
tribute to the current agenda on the focus stack due
to ASR and NLU errors that are due to noisy envi-
ronments and unexpected input. These cases can be
handled by using an error recovery strategy in Sec-
tion 6.
Figure 5 shows some examples of pseudo-codes
used in the discourse interpretation algorithm to
select the best node among possible next nodes.
S,H,and G denote the focus stack, hypothesis, and
agenda graph, respectively. The INTERPRET al-
gorithm is initially called to interpret the current dis-
course state. Furthermore, the essence of a discourse
interpretation algorithm is to find candidate nodes of
possible next subtask for an observed user goal, ex-
pressed in the definition of GENERATE. The SE-
LECT algorithm selects the best node to maximize
Figure 5: Pseudo-codes for the discourse interpreta-
tion algorithm
the score function based on current input and dis-
course structure given the focus stack. The details
of how the score of candidate nodes are calculated
are explained in Section 5.
</bodyText>
<sectionHeader confidence="0.988999" genericHeader="method">
5 Greedy Selection with n-best Hypotheses
</sectionHeader>
<bodyText confidence="0.99998937037037">
Many speech recognizers can generate a list of plau-
sible hypotheses (n-best list) but output only the
most probable one. Examination of the n-best list
reveals that the best hypothesis, the one with the
lowest word error rate, is not always in top-1 posi-
tion but sometimes in the lower rank of the n-best
list. Therefore, we need to select the hypothesis
that maximizes the scoring function among a set of
n-best hypotheses of each utterance. The role of
agenda graph is for a heuristic to score the discourse
state to successfully complete the task given the fo-
cus stack.
The current system depends on a greedy policy
which is based on immediate transitions rather than
full transitions from the initial state. The greedy
selection with n-best hypotheses is implemented as
follows. Firstly, every hypothesis hi is scanned and
all possible nodes are generated using the discourse
interpretation. Secondly, the multi-level score func-
tions are computed for each candidate node ci given
a hypothesis hi. Using the greedy algorithm, the
node with the highest score is selected as the user
goal state. Finally, the system actions are predicted
by the dialog example to maximize the example
score in the best node.
The generation of candidate nodes is based
on multiple hypotheses from the previous EBDM
</bodyText>
<page confidence="0.997947">
634
</page>
<bodyText confidence="0.999951090909091">
framework. This previous EBDM framework chose
a dialog example to maximize the utterance similar-
ity measure. However, our system generates a set of
multiple dialog examples with each utterance sim-
ilarity over a threshold given a specific hypothesis.
Then, the candidate nodes are generated by match-
ing to each dialog example bound to the node. If the
number of matching nodes is exactly one, that node
is selected. Otherwise, the best node which would
be pushed onto the focus stack must be selected us-
ing multi-level score functions.
</bodyText>
<subsectionHeader confidence="0.98602">
5.1 Node Selection
</subsectionHeader>
<bodyText confidence="0.9998915">
The node selection is determined by calculating
some score functions. We defined multi-level score
functions that combine the scores of ASR, SLU, and
DM modules, which range from 0.00 to 1.00. The
best node is selected by greedy search with multiple
hypotheses H and candidate nodes C as follows:
</bodyText>
<equation confidence="0.9971155">
c* = arg max wSH(hi) + (1 − w)SD(ci|S)
hiEH,ciEC
</equation>
<bodyText confidence="0.998196111111111">
where H is a list of n-best hypotheses and C is a
set of nodes to be generated by the discourse in-
terpretation. For the node selection, we divided the
score function into two functions SH(hi), hypothe-
sis score, and SD(ci|S), discourse score, where ci is
the focus node to be generated by single hypothesis
hi.
We defined the hypothesis score at the utterance
level as
</bodyText>
<equation confidence="0.994639">
SH(hi) = αSrec(hi) + QScont(hi)
</equation>
<bodyText confidence="0.999951266666667">
where Srec(hi) denotes the recognition score which
is a generalized confidence score over the confi-
dence score of the top-rank hypothesis. Scont(hi)
is the content score in the view of content manage-
ment to access domain-specific contents. For exam-
ple, in the building guidance domain, theses contents
would be a building knowledge database including
room name, room number, and room type. The score
is defined as:
where Cprev is a set of contents at the previous turn
and Ctotal is a set of total contents in the content
database. Chi denotes a set of focused contents by
hypothesis hi at the current turn. N(C) represents
the number of contents C. This score reflects the
degree of content coherence because the number of
contents of interest has been gradually reduced with-
out any unexpected focus shift. In the hypothesis
score, α and Q denote weights which depend on the
accuracy of speech recognition and language under-
standing, respectively.
In addition to the hypothesis score, we defined the
discourse score SD at the discourse level to consider
the discourse structure between the previous node
and current node given the focus stack S. This score
is the degree to which candidate node ci is in focus
with respect to the previous user goal and system ut-
terance. In the agenda graph G, each transition has
its own probability as prior knowledge. Therefore,
when ci is NEXT TASK, the discourse score is com-
puted as
</bodyText>
<equation confidence="0.989862">
SD(ci|S) = P(ci|c = top(S))
</equation>
<bodyText confidence="0.999899529411765">
where P(ci|c = top(S)) is a transition probabil-
ity from the top node c on the focus stack S to the
candidate node ci. However, there is a problem for
cases other than NEXT TASK because the graph has
no backward probability. To solve this problem, we
assume that the transition probability may be lower
than that of the NEXT TASK case because a user
utterance is likely to be influenced by the previous
turn. Actually, when using the task-oriented dialog
system, typical users stay focused most of the time
during imperfect communication (Lesh et al., 2001).
To assign the backward transition probability, we
obtain the minimum transition probability Pmin(S)
among from the top node on the focus stack S to
its children. Then, the discourse score SD can be
formalized when the candidate node ci does not cor-
respond to NEXT TASK as follows:
</bodyText>
<equation confidence="0.975727">
SD(ci|S) = max{Pmin(S) − ADist(ci,c),01
</equation>
<bodyText confidence="0.999795857142857">
where A is a penalty of distance between candi-
date node and previous node, Dist(ci, c), according
to type of candidate node such as NEW TASK and
NEW SUB TASK. The simplest case is to uniformly
assign A to a specific value.
To select the best node using the node score, we
use w (0 &lt; w &lt; 1) as an interpolation weight
</bodyText>
<equation confidence="0.9980956">
Scont(hi) = {
N(5vp ))
N(Ctota!)
N(Chi) if Chi � Cprev
N(Chi if Chi )&amp;quot;_ Cprev
</equation>
<page confidence="0.994545">
635
</page>
<bodyText confidence="0.9999155">
between the hypothesis score Sh and the discourse
score SD. This weight is empirically assigned ac-
cording to the characteristics of the dialog genre and
task. For example, w can set lower to manage the
transactional dialog in which the user utterance is
highly correlated to the previous system utterance,
i.e., a travel reservation task, because this task usu-
ally has preference orders to fill slots.
</bodyText>
<subsectionHeader confidence="0.999304">
5.2 Example Selection
</subsectionHeader>
<bodyText confidence="0.999684666666667">
After selecting the best node, we use the example
score to select the best dialog example mapped into
this node.
</bodyText>
<equation confidence="0.9983275">
e* = arg max wSutter(h*, ej)+(1−w)Ssem(h*, ej)
ejEE(c*)
</equation>
<bodyText confidence="0.98917125">
where h* is the best hypothesis to maximize the
node score and ej is a dialog example in the best
node c*. Sutter(h, ej) denotes the value of the utter-
ance similarity of the user’s utterances between the
hypothesis h and dialog example ej in the best node
c* (Lee et al., 2006a).
To augment the utterance similarity used in the
EBDM framework, we also defined the semantic
score for example selection, Ssem(h, ej):
Ssem(h, ej) = # of total index keys
The semantic score is the ratio of matching index
keys to the number of total index keys between hy-
pothesis h and example record ej. This score re-
flects that a dialog example is semantically closer to
the current utterance if the example is selected with
more index keys. After processing of the node and
example selection, the best example is used to pre-
dict the system actions. Therefore, the dialog man-
ager can predict the next actions with the agenda
graph and n-best recognition hypotheses.
</bodyText>
<sectionHeader confidence="0.999697" genericHeader="method">
6 Error Recovery Strategy
</sectionHeader>
<bodyText confidence="0.998417">
As noted in Section 4.2, the discourse interpretation
sometimes fails to generate candidate nodes. In ad-
dition, the dialog manager should confirm the cur-
rent information when the score falls below some
threshold. For these cases, we adapt an example-
based error recovery strategy (Lee et al., 2007). In
this approach, the system detects that something is
wrong in the user’s utterance and takes immediate
steps to address the problem using some help mes-
sages such as UtterHelp, InfoHelp, and UsageHelp
in the example-based error recovery strategies. We
also added a new help message, AgendaHelp, that
uses the agenda graph and the label of each node to
tell the user which subtask to perform next such as
”SYSTEM: Next, you can do the subtask 1)Search
Location with Room Name or 2)Search Location
with Room Type”.
</bodyText>
<sectionHeader confidence="0.994076" genericHeader="evaluation">
7 Experiment &amp; Result
</sectionHeader>
<bodyText confidence="0.992869416666667">
First we developed the spoken dialog system for
PHOPE in which an intelligent robot can provide in-
formation about buildings (i.e., room number, room
location, room name, room type) and people (i.e.,
name, phone number, e-mail address, cellular phone
number). If the user selects a specific room to visit,
then the robot takes the user to the desired room.
For this system, ten people used the WOZ method to
collect a dialog corpus of about 500 utterances from
100 dialogs which were based on a set of pre-defined
10 subjects relating to domain-specific tasks. Then,
we designed an agenda graph and integrated it into
the EBDM framework.
In an attempt to quantify the impact of our ap-
proach, five Korean users participated in a prelimi-
nary evaluation. We provided them with pre-defined
scenarios and asked them to collect test data from
50 dialogs, including about 150 utterances. After
processing each dialog, the participants completed
a questionnaire to assess their satisfaction with as-
pects of the performance evaluation. The speech
recognition hypotheses are obtained by using the
Hidden Markov model Toolkit (HTK) speech rec-
ognizer adapted to our application domain in which
the word error rate (WER) is 21.03%. The results of
the Task Completion Rate (TCR) are shown in Table
1. We explored the effects of our agenda-based ap-
proach with n-best hypotheses compared to the pre-
vious EBDM framework which has no agenda graph
and supports only 1-best hypothesis.
Note that using 10-best hypotheses and the
agenda graph increases the TCR from 84.0% to
90.0%, that is, 45 out of 50 dialogs were com-
pleted successfully. The average number of turns
(#AvgTurn) to completion was also shorter, which
# of matching index keys
</bodyText>
<page confidence="0.983456">
636
</page>
<bodyText confidence="0.9997494">
shows 4.35 turns per a dialog using the agenda graph
and 10-best hypotheses. From these results, we con-
clude that the the use of the n-best hypotheses with
the agenda graph is helpful to improve the robust-
ness of the EBDM framework against noisy inputs.
</bodyText>
<table confidence="0.995449">
System #AvgTurn TCR (%)
1-best(-AG) 4.65 84.0
10-best(+AG) 4.35 90.0
</table>
<tableCaption confidence="0.882925333333333">
Table 1: Task completion rate according to using the
AG (Agenda Graph) and n-best hypotheses for n=1
and n=10.
</tableCaption>
<sectionHeader confidence="0.988201" genericHeader="conclusions">
8 Conclusion &amp; Discussion
</sectionHeader>
<bodyText confidence="0.999974375">
This paper has proposed a new agenda-based ap-
proach with n-best recognition hypotheses to im-
prove the robustness of the Example-based Dialog
Modeling (EBDM) framework. The agenda graph
can be thought of as a hidden cost of applying our
methodology. However, an explicit agenda is nec-
essary to successfully achieve the purpose of using
spoken dialog system. Our preliminary results indi-
cate this fact that the use of agenda graph as heuris-
tics can increase the TCR. In addition, our approach
is robust to recognition errors because it maintains
multiple hypotheses for each user utterance.
There are several possible subjects for further re-
search on our approach. First, the optimal interpo-
lation weights should be determined. This task will
require larger dialog corpora by using user simula-
tion. Second, the cost of designing the agenda graph
should be reduced. We have focused on developing a
system to construct this graph semi-automatically by
applying dialog state clustering and utterance clus-
tering to achieve hierarchical clustering of dialog ex-
amples. Finally, future work will include expanding
our system to other applications, such as navigation
systems for automobiles.
</bodyText>
<sectionHeader confidence="0.985209" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.999945">
This work was supported by grant No. RTI04-02-06
from the Regional Technology Innovation Program
and by the Intelligent Robotics Development Pro-
gram, one of the 21st Century Frontier R&amp;D Pro-
grams funded by the Ministry of Commerce, Indus-
try and Energy (MOICE) of Korea.
</bodyText>
<sectionHeader confidence="0.99847" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999866773584906">
Bohus, B. and Rudnicky A. 2003. RavenClaw: Dia-
log Management Using Hierarchical Task Decompo-
sition and an Expectation Agenda. Proceedings of the
European Conference on Speech, Communication and
Technology, 597–600.
Grosz, B.J. and Kraus, S. 1996. Collaborative Plans
for Complex Group Action. Artificial Intelligence,
86(2):269–357.
Lee, C., Jung, S., Eun, J., Jeong, M., and Lee, G.G.
2006. A Situation-based Dialogue Management using
Dialogue Examples. Proceedings of the IEEE Inter-
national Conference on Acoustics, Speech and Signal
Processing, 69–72.
Lee, C., Jung, S., Jeong, M., and Lee, G.G. 2006.
Chat and Goal-oriented Dialog Together: A Unified
Example-based Architecture for Multi-domain Dialog
Management. Proceedings of the IEEE Spoken Lan-
guage Technology Workshop, 194-197.
Lee, C., Jung, S., and Lee, G.G. 2007. Example-based
Error Reocvery Strategy For Spoken Dialog System.
Proceedings of the IEEE Automatic Speech Recogni-
tion and Understanding Workshop, 538–543.
Lesh, N., Rich, C., and Sidner, C. 2001. Collaborat-
ing with focused and unfocused users under imper-
fect communication. Proceedings of the International
Conference on User Modeling, 63–74.
Lochbaum, K.E. 1998. A Collaborative Planning Model
of Intentional Structure. Computational Linguistics,
24(4):525–572.
McTear, M., O’Neil, I., Hanna, P., and Liu, X.
2005. Handling errors and determining confirmation
strategies-An object-based approach. Speech Commu-
nication, 45(3):249–269.
Nagao, M. 1984. A Frame Work of a Mechnical Trans-
latino between Japanese and English by Analogy Prin-
ciple. Proceedings of the international NATO sympo-
sium on artificial and human intelligence, 173–180.
Rich, C. and Sidner, C.. 1998. Collagen: A Collab-
oration Agent for Software Interface Agents. Jour-
nal of User Modeling and User-Adapted Interaction,
8(3):315–350.
Torres, F., Hurtado, L.F., Garcia, F., Sanchis, E., and
Segarra, E. 2005. Error Handling in a Stochastic
Dialog System through Confidence Measure. Speech
Communication, 45(3):211–229.
Williams, J.D. and Young, S. 2007. Partially Observable
Markov Decision Processes for Spoken Dialog Sys-
tems. Computer Speech Language, 21(2):393-422.
Young, S., Schatzmann, J., Weilhammer, K., and Ye, H..
2007. The Hidden Information State Approach to Di-
alog Management. Proceedings of the IEEE Inter-
national Conference on Acoustics, Speech and Signal
Processing, 149–152.
</reference>
<page confidence="0.997826">
637
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.313659">
<title confidence="0.8367875">Robust Dialog Management with N-best Hypotheses Using Dialog Examples and Agenda</title>
<author confidence="0.812615">Cheongjae Lee</author>
<author confidence="0.812615">Sangkeun Jung</author>
<author confidence="0.812615">Gary Geunbae Lee</author>
<affiliation confidence="0.989869">Pohang University of Science and Technology Department of Computer Science and Engineering</affiliation>
<address confidence="0.498672">Pohang, Republic of Korea</address>
<abstract confidence="0.999076823529412">This work presents an agenda-based approach to improve the robustness of the dialog manager by using dialog examples and n-best recognition hypotheses. This approach supports n-best hypotheses in the dialog manager and keeps track of the dialog state using a discourse interpretation algorithm with the agenda graph and focus stack. Given the agenda graph and n-best hypotheses, the system can predict the next system actions to maximize multi-level score functions. To evaluate the proposed method, a spoken dialog system for a building guidance robot was developed. Preliminary evaluation shows this approach would be effective to improve the robustness of example-based dialog modeling.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>B Bohus</author>
<author>A Rudnicky</author>
</authors>
<title>RavenClaw: Dialog Management Using Hierarchical Task Decomposition and an Expectation Agenda.</title>
<date>2003</date>
<booktitle>Proceedings of the European Conference on Speech, Communication and Technology,</booktitle>
<pages>597--600</pages>
<contexts>
<context position="4972" citStr="Bohus and Rudnicky, 2003" startWordPosition="773" endWordPosition="776">n Section 5. Section 6 describes the error recovery strategy to handle unexpected cases. Then, Section 7 provides the experimental results of a real user evaluation to verify our approach. Finally, we draw conclusions and make suggestions for future work in Section 8. 2 Related Work In many spoken dialog systems that have been developed recently, various knowledge sources are used. One of the knowledge sources, which are usually application-dependent, is an agenda or task model. These are powerful representations for segmenting large tasks into more reasonable subtasks (Rich and Sidner, 1998; Bohus and Rudnicky, 2003; Young et al., 2007). These are manually designed for various purposes including dialog modeling, search space reduction, domain knowledge, and user simulation. In Collagen (Rich and Sidner, 1998), a plan tree, which is an approximate representation of a partial SharedPlan, is composed of alternating act and plan recipe nodes for internal discourse state representation and discourse interpretation. In addition, Bohus and Rudnicky (2003) have presented a RavenClaw dialog management which is an agenda-based architecture using hierarchical task decomposition and an expectation agenda. For modeli</context>
</contexts>
<marker>Bohus, Rudnicky, 2003</marker>
<rawString>Bohus, B. and Rudnicky A. 2003. RavenClaw: Dialog Management Using Hierarchical Task Decomposition and an Expectation Agenda. Proceedings of the European Conference on Speech, Communication and Technology, 597–600.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B J Grosz</author>
<author>S Kraus</author>
</authors>
<title>Collaborative Plans for Complex Group Action.</title>
<date>1996</date>
<journal>Artificial Intelligence,</journal>
<volume>86</volume>
<issue>2</issue>
<marker>Grosz, Kraus, 1996</marker>
<rawString>Grosz, B.J. and Kraus, S. 1996. Collaborative Plans for Complex Group Action. Artificial Intelligence, 86(2):269–357.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Lee</author>
<author>S Jung</author>
<author>J Eun</author>
<author>M Jeong</author>
<author>G G Lee</author>
</authors>
<title>A Situation-based Dialogue Management using Dialogue Examples.</title>
<date>2006</date>
<booktitle>Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing,</booktitle>
<pages>69--72</pages>
<contexts>
<context position="3291" citStr="Lee et al., 2006" startWordPosition="507" endWordPosition="510">em by guiding for the repair of the wrong information by human-computer interaction. On the other hand, there are different approaches to improve the robustness of dialog management using n-best hypotheses. Rather than Markov Decision Processes (MDPs), partially observable MDPs (POMDPs) potentially provide a much more powerful framework for robust dialog modeling since they consider nbest hypotheses to estimate the distribution of the belief state (Williams and Young, 2007). In recent, we proposed another data-driven approach for the dialog modeling called Examplebased Dialog Modeling (EBDM) (Lee et al., 2006a). However, difficulties occur when attempting to de630 Proceedings of ACL-08: HLT, pages 630–637, Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics ploy EBDM in practical spoken dialog systems in which ASR and NLU errors are frequent. Thus, this paper proposes a new method to improve the robustness of the EBDM framework using an agendabased approach and n-best recognition hypotheses. We consider a domain-specific agenda to estimate the best dialog state and example because, in taskoriented systems, a current dialog state is highly correlated to the previous dia</context>
<context position="8706" citStr="Lee et al., 2006" startWordPosition="1357" endWordPosition="1360"> the current dialog state. If no example is retrieved, some state variables can be ignored by relaxing particular variables according to the level of importance given the dialog’s genre and domain. • Example Selection: The dialog manager selects the best example to maximize the utterance similarity measure based on lexicosemantic similarity and discourse history similarity. Figure 2 illustrates the overall strategy of EBDM framework for spoken dialog systems. The EBDM framework is a simple and powerful approach to rapidly develop natural language interfaces for multi-domain dialog processing (Lee et al., 2006b). However, in the context of spoken dialog system for domain-specific tasks, this framework must solve two problems: (1) Keeping track of the dialog state with a view to ensuring steady progress towards task completion, (2) Supporting n-best recognition hypotheses to improve the robustness of dialog manager. Consequently, we sought to solve these probFigure 2: Strategy of the Example-Based Dialog Modeling (EBDM) framework. lems by integrating the agenda graph as a heuristic which reflects the natural hierarchy and order of subtasks needed to complete the task. • 4 Agenda Graph In this paper,</context>
<context position="21540" citStr="Lee et al., 2006" startWordPosition="3542" endWordPosition="3545"> highly correlated to the previous system utterance, i.e., a travel reservation task, because this task usually has preference orders to fill slots. 5.2 Example Selection After selecting the best node, we use the example score to select the best dialog example mapped into this node. e* = arg max wSutter(h*, ej)+(1−w)Ssem(h*, ej) ejEE(c*) where h* is the best hypothesis to maximize the node score and ej is a dialog example in the best node c*. Sutter(h, ej) denotes the value of the utterance similarity of the user’s utterances between the hypothesis h and dialog example ej in the best node c* (Lee et al., 2006a). To augment the utterance similarity used in the EBDM framework, we also defined the semantic score for example selection, Ssem(h, ej): Ssem(h, ej) = # of total index keys The semantic score is the ratio of matching index keys to the number of total index keys between hypothesis h and example record ej. This score reflects that a dialog example is semantically closer to the current utterance if the example is selected with more index keys. After processing of the node and example selection, the best example is used to predict the system actions. Therefore, the dialog manager can predict the</context>
</contexts>
<marker>Lee, Jung, Eun, Jeong, Lee, 2006</marker>
<rawString>Lee, C., Jung, S., Eun, J., Jeong, M., and Lee, G.G. 2006. A Situation-based Dialogue Management using Dialogue Examples. Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing, 69–72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Lee</author>
<author>S Jung</author>
<author>M Jeong</author>
<author>G G Lee</author>
</authors>
<title>Chat and Goal-oriented Dialog Together: A Unified Example-based Architecture for Multi-domain Dialog Management.</title>
<date>2006</date>
<booktitle>Proceedings of the IEEE Spoken Language Technology Workshop,</booktitle>
<pages>194--197</pages>
<contexts>
<context position="3291" citStr="Lee et al., 2006" startWordPosition="507" endWordPosition="510">em by guiding for the repair of the wrong information by human-computer interaction. On the other hand, there are different approaches to improve the robustness of dialog management using n-best hypotheses. Rather than Markov Decision Processes (MDPs), partially observable MDPs (POMDPs) potentially provide a much more powerful framework for robust dialog modeling since they consider nbest hypotheses to estimate the distribution of the belief state (Williams and Young, 2007). In recent, we proposed another data-driven approach for the dialog modeling called Examplebased Dialog Modeling (EBDM) (Lee et al., 2006a). However, difficulties occur when attempting to de630 Proceedings of ACL-08: HLT, pages 630–637, Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics ploy EBDM in practical spoken dialog systems in which ASR and NLU errors are frequent. Thus, this paper proposes a new method to improve the robustness of the EBDM framework using an agendabased approach and n-best recognition hypotheses. We consider a domain-specific agenda to estimate the best dialog state and example because, in taskoriented systems, a current dialog state is highly correlated to the previous dia</context>
<context position="8706" citStr="Lee et al., 2006" startWordPosition="1357" endWordPosition="1360"> the current dialog state. If no example is retrieved, some state variables can be ignored by relaxing particular variables according to the level of importance given the dialog’s genre and domain. • Example Selection: The dialog manager selects the best example to maximize the utterance similarity measure based on lexicosemantic similarity and discourse history similarity. Figure 2 illustrates the overall strategy of EBDM framework for spoken dialog systems. The EBDM framework is a simple and powerful approach to rapidly develop natural language interfaces for multi-domain dialog processing (Lee et al., 2006b). However, in the context of spoken dialog system for domain-specific tasks, this framework must solve two problems: (1) Keeping track of the dialog state with a view to ensuring steady progress towards task completion, (2) Supporting n-best recognition hypotheses to improve the robustness of dialog manager. Consequently, we sought to solve these probFigure 2: Strategy of the Example-Based Dialog Modeling (EBDM) framework. lems by integrating the agenda graph as a heuristic which reflects the natural hierarchy and order of subtasks needed to complete the task. • 4 Agenda Graph In this paper,</context>
<context position="21540" citStr="Lee et al., 2006" startWordPosition="3542" endWordPosition="3545"> highly correlated to the previous system utterance, i.e., a travel reservation task, because this task usually has preference orders to fill slots. 5.2 Example Selection After selecting the best node, we use the example score to select the best dialog example mapped into this node. e* = arg max wSutter(h*, ej)+(1−w)Ssem(h*, ej) ejEE(c*) where h* is the best hypothesis to maximize the node score and ej is a dialog example in the best node c*. Sutter(h, ej) denotes the value of the utterance similarity of the user’s utterances between the hypothesis h and dialog example ej in the best node c* (Lee et al., 2006a). To augment the utterance similarity used in the EBDM framework, we also defined the semantic score for example selection, Ssem(h, ej): Ssem(h, ej) = # of total index keys The semantic score is the ratio of matching index keys to the number of total index keys between hypothesis h and example record ej. This score reflects that a dialog example is semantically closer to the current utterance if the example is selected with more index keys. After processing of the node and example selection, the best example is used to predict the system actions. Therefore, the dialog manager can predict the</context>
</contexts>
<marker>Lee, Jung, Jeong, Lee, 2006</marker>
<rawString>Lee, C., Jung, S., Jeong, M., and Lee, G.G. 2006. Chat and Goal-oriented Dialog Together: A Unified Example-based Architecture for Multi-domain Dialog Management. Proceedings of the IEEE Spoken Language Technology Workshop, 194-197.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Lee</author>
<author>S Jung</author>
<author>G G Lee</author>
</authors>
<title>Example-based Error Reocvery Strategy For Spoken Dialog System.</title>
<date>2007</date>
<booktitle>Proceedings of the IEEE Automatic Speech Recognition and Understanding Workshop,</booktitle>
<pages>538--543</pages>
<contexts>
<context position="2548" citStr="Lee et al., 2007" startWordPosition="392" endWordPosition="395"> errors, a basic solution is to improve the accuracy and robustness of the recognition and understanding processes. However, it has been impossible to develop perfect ASR and NLU modules because of noisy environments and unexpected input. Therefore, the development of robust dialog management has also been one of the most important goals in research on practical spoken dialog systems. In the dialog manager, a popular method to deal with these errors is to adopt dialog mechanisms for detecting and repairing potential errors at the conversational level (McTear et al., 2005; Torres et al., 2005; Lee et al., 2007). In human-computer communication, the goal of error recovery strategy is to maximize the user’s satisfaction of using the system by guiding for the repair of the wrong information by human-computer interaction. On the other hand, there are different approaches to improve the robustness of dialog management using n-best hypotheses. Rather than Markov Decision Processes (MDPs), partially observable MDPs (POMDPs) potentially provide a much more powerful framework for robust dialog modeling since they consider nbest hypotheses to estimate the distribution of the belief state (Williams and Young, </context>
<context position="22534" citStr="Lee et al., 2007" startWordPosition="3709" endWordPosition="3712">he current utterance if the example is selected with more index keys. After processing of the node and example selection, the best example is used to predict the system actions. Therefore, the dialog manager can predict the next actions with the agenda graph and n-best recognition hypotheses. 6 Error Recovery Strategy As noted in Section 4.2, the discourse interpretation sometimes fails to generate candidate nodes. In addition, the dialog manager should confirm the current information when the score falls below some threshold. For these cases, we adapt an examplebased error recovery strategy (Lee et al., 2007). In this approach, the system detects that something is wrong in the user’s utterance and takes immediate steps to address the problem using some help messages such as UtterHelp, InfoHelp, and UsageHelp in the example-based error recovery strategies. We also added a new help message, AgendaHelp, that uses the agenda graph and the label of each node to tell the user which subtask to perform next such as ”SYSTEM: Next, you can do the subtask 1)Search Location with Room Name or 2)Search Location with Room Type”. 7 Experiment &amp; Result First we developed the spoken dialog system for PHOPE in which</context>
</contexts>
<marker>Lee, Jung, Lee, 2007</marker>
<rawString>Lee, C., Jung, S., and Lee, G.G. 2007. Example-based Error Reocvery Strategy For Spoken Dialog System. Proceedings of the IEEE Automatic Speech Recognition and Understanding Workshop, 538–543.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Lesh</author>
<author>C Rich</author>
<author>C Sidner</author>
</authors>
<title>Collaborating with focused and unfocused users under imperfect communication.</title>
<date>2001</date>
<booktitle>Proceedings of the International Conference on User Modeling,</booktitle>
<pages>63--74</pages>
<contexts>
<context position="12037" citStr="Lesh et al., 2001" startWordPosition="1916" endWordPosition="1919">ples in DEDB are Figure 4: XML description for the agenda graph mapped to a user goal state when a precondition of the node is true. Initially, the root node of the DAG is the starting state, where there is no dialog example. Then, the attributes of each dialog example are examined via the preconditions of each user goal node by breadth-first traversal. If the precondition is true, the node holds relevant that may appear in the user’s goal state. The method of selecting the best of these examples will be described in 5. 4.2 Discourse Interpretation Inspired by Collagen (Rich and Sidner, 1998; Lesh et al., 2001), we investigated a discourse interpretation algorithm to consider how the current user’s goal can contribute to the current agenda in a focus stack according to Lochbaum’s discourse interpretation algorithm (Lochbaum, 1998). The focus stack takes into account the discourse structure by keeping track of discourse states. In our system, the focus stack is a set of user goal nodes which lead to completion of the subtask. The top on the focus stack is the previous node in this set. The focus stack is updated after every utterance. To interpret the type of the discourse state, this breaks down int</context>
<context position="19949" citStr="Lesh et al., 2001" startWordPosition="3259" endWordPosition="3262">he discourse score is computed as SD(ci|S) = P(ci|c = top(S)) where P(ci|c = top(S)) is a transition probability from the top node c on the focus stack S to the candidate node ci. However, there is a problem for cases other than NEXT TASK because the graph has no backward probability. To solve this problem, we assume that the transition probability may be lower than that of the NEXT TASK case because a user utterance is likely to be influenced by the previous turn. Actually, when using the task-oriented dialog system, typical users stay focused most of the time during imperfect communication (Lesh et al., 2001). To assign the backward transition probability, we obtain the minimum transition probability Pmin(S) among from the top node on the focus stack S to its children. Then, the discourse score SD can be formalized when the candidate node ci does not correspond to NEXT TASK as follows: SD(ci|S) = max{Pmin(S) − ADist(ci,c),01 where A is a penalty of distance between candidate node and previous node, Dist(ci, c), according to type of candidate node such as NEW TASK and NEW SUB TASK. The simplest case is to uniformly assign A to a specific value. To select the best node using the node score, we use w</context>
</contexts>
<marker>Lesh, Rich, Sidner, 2001</marker>
<rawString>Lesh, N., Rich, C., and Sidner, C. 2001. Collaborating with focused and unfocused users under imperfect communication. Proceedings of the International Conference on User Modeling, 63–74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K E Lochbaum</author>
</authors>
<title>A Collaborative Planning Model of Intentional Structure.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<volume>24</volume>
<issue>4</issue>
<contexts>
<context position="12261" citStr="Lochbaum, 1998" startWordPosition="1951" endWordPosition="1952">hen, the attributes of each dialog example are examined via the preconditions of each user goal node by breadth-first traversal. If the precondition is true, the node holds relevant that may appear in the user’s goal state. The method of selecting the best of these examples will be described in 5. 4.2 Discourse Interpretation Inspired by Collagen (Rich and Sidner, 1998; Lesh et al., 2001), we investigated a discourse interpretation algorithm to consider how the current user’s goal can contribute to the current agenda in a focus stack according to Lochbaum’s discourse interpretation algorithm (Lochbaum, 1998). The focus stack takes into account the discourse structure by keeping track of discourse states. In our system, the focus stack is a set of user goal nodes which lead to completion of the subtask. The top on the focus stack is the previous node in this set. The focus stack is updated after every utterance. To interpret the type of the discourse state, this breaks down into five main cases of possible current node for an observed user’s goal: • NEW TASK: Starting a new task to complete a new agenda (Child of the root). • NEW SUB TASK: Starting a new subtask to partially shift focus (A differe</context>
</contexts>
<marker>Lochbaum, 1998</marker>
<rawString>Lochbaum, K.E. 1998. A Collaborative Planning Model of Intentional Structure. Computational Linguistics, 24(4):525–572.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M McTear</author>
<author>I O’Neil</author>
<author>P Hanna</author>
<author>X Liu</author>
</authors>
<title>Handling errors and determining confirmation strategies-An object-based approach.</title>
<date>2005</date>
<journal>Speech Communication,</journal>
<volume>45</volume>
<issue>3</issue>
<marker>McTear, O’Neil, Hanna, Liu, 2005</marker>
<rawString>McTear, M., O’Neil, I., Hanna, P., and Liu, X. 2005. Handling errors and determining confirmation strategies-An object-based approach. Speech Communication, 45(3):249–269.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Nagao</author>
</authors>
<title>A Frame Work of a Mechnical Translatino between Japanese and English by Analogy Principle.</title>
<date>1984</date>
<booktitle>Proceedings of the international NATO symposium on artificial and human intelligence,</booktitle>
<pages>173--180</pages>
<contexts>
<context position="6647" citStr="Nagao, 1984" startWordPosition="1037" endWordPosition="1038"> this knowledge source for users to achieve domain-specific goals. We used an agenda graph whose hierarchy reflects the natural order of dialog control. This graph is used to both keep track of the dialog state and to select the best example using multiple recognition hypotheses for augmenting previous EBDM framework. 3 Example-based Dialog Modeling Our approach is implemented based on ExampleBased Dialog Modeling (EBDM) which is one of generic dialog modelings. We begin with a brief overview of the EBDM framework in this section. EBDM was inspired by Example-Based Machine Translation (EBMT) (Nagao, 1984), a translation system in which the source sentence can be translated using similar example fragments within a large parallel corpus, without knowledge of the language’s structure. The idea of EBMT can be extended to determine the next system actions by finding similar dialog examples within the dialog corpus. The system action can be predicted by finding semantically similar user utterances with the dialog state. The dialog state is defined as the set of relevant internal variables that affect the next system action. EBDM needs to automatically construct an example database from the dialog co</context>
</contexts>
<marker>Nagao, 1984</marker>
<rawString>Nagao, M. 1984. A Frame Work of a Mechnical Translatino between Japanese and English by Analogy Principle. Proceedings of the international NATO symposium on artificial and human intelligence, 173–180.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Rich</author>
<author>C Sidner</author>
</authors>
<title>Collagen: A Collaboration Agent for Software Interface Agents.</title>
<date>1998</date>
<journal>Journal of User Modeling and User-Adapted Interaction,</journal>
<volume>8</volume>
<issue>3</issue>
<contexts>
<context position="4946" citStr="Rich and Sidner, 1998" startWordPosition="769" endWordPosition="772">ith n-best hypotheses in Section 5. Section 6 describes the error recovery strategy to handle unexpected cases. Then, Section 7 provides the experimental results of a real user evaluation to verify our approach. Finally, we draw conclusions and make suggestions for future work in Section 8. 2 Related Work In many spoken dialog systems that have been developed recently, various knowledge sources are used. One of the knowledge sources, which are usually application-dependent, is an agenda or task model. These are powerful representations for segmenting large tasks into more reasonable subtasks (Rich and Sidner, 1998; Bohus and Rudnicky, 2003; Young et al., 2007). These are manually designed for various purposes including dialog modeling, search space reduction, domain knowledge, and user simulation. In Collagen (Rich and Sidner, 1998), a plan tree, which is an approximate representation of a partial SharedPlan, is composed of alternating act and plan recipe nodes for internal discourse state representation and discourse interpretation. In addition, Bohus and Rudnicky (2003) have presented a RavenClaw dialog management which is an agenda-based architecture using hierarchical task decomposition and an expe</context>
<context position="12017" citStr="Rich and Sidner, 1998" startWordPosition="1912" endWordPosition="1915">refore, the dialog examples in DEDB are Figure 4: XML description for the agenda graph mapped to a user goal state when a precondition of the node is true. Initially, the root node of the DAG is the starting state, where there is no dialog example. Then, the attributes of each dialog example are examined via the preconditions of each user goal node by breadth-first traversal. If the precondition is true, the node holds relevant that may appear in the user’s goal state. The method of selecting the best of these examples will be described in 5. 4.2 Discourse Interpretation Inspired by Collagen (Rich and Sidner, 1998; Lesh et al., 2001), we investigated a discourse interpretation algorithm to consider how the current user’s goal can contribute to the current agenda in a focus stack according to Lochbaum’s discourse interpretation algorithm (Lochbaum, 1998). The focus stack takes into account the discourse structure by keeping track of discourse states. In our system, the focus stack is a set of user goal nodes which lead to completion of the subtask. The top on the focus stack is the previous node in this set. The focus stack is updated after every utterance. To interpret the type of the discourse state, </context>
</contexts>
<marker>Rich, Sidner, 1998</marker>
<rawString>Rich, C. and Sidner, C.. 1998. Collagen: A Collaboration Agent for Software Interface Agents. Journal of User Modeling and User-Adapted Interaction, 8(3):315–350.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Torres</author>
<author>L F Hurtado</author>
<author>F Garcia</author>
<author>E Sanchis</author>
<author>E Segarra</author>
</authors>
<title>Error Handling in a Stochastic Dialog System through Confidence Measure.</title>
<date>2005</date>
<journal>Speech Communication,</journal>
<volume>45</volume>
<issue>3</issue>
<contexts>
<context position="2529" citStr="Torres et al., 2005" startWordPosition="388" endWordPosition="391">ponse. To avoid these errors, a basic solution is to improve the accuracy and robustness of the recognition and understanding processes. However, it has been impossible to develop perfect ASR and NLU modules because of noisy environments and unexpected input. Therefore, the development of robust dialog management has also been one of the most important goals in research on practical spoken dialog systems. In the dialog manager, a popular method to deal with these errors is to adopt dialog mechanisms for detecting and repairing potential errors at the conversational level (McTear et al., 2005; Torres et al., 2005; Lee et al., 2007). In human-computer communication, the goal of error recovery strategy is to maximize the user’s satisfaction of using the system by guiding for the repair of the wrong information by human-computer interaction. On the other hand, there are different approaches to improve the robustness of dialog management using n-best hypotheses. Rather than Markov Decision Processes (MDPs), partially observable MDPs (POMDPs) potentially provide a much more powerful framework for robust dialog modeling since they consider nbest hypotheses to estimate the distribution of the belief state (W</context>
</contexts>
<marker>Torres, Hurtado, Garcia, Sanchis, Segarra, 2005</marker>
<rawString>Torres, F., Hurtado, L.F., Garcia, F., Sanchis, E., and Segarra, E. 2005. Error Handling in a Stochastic Dialog System through Confidence Measure. Speech Communication, 45(3):211–229.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J D Williams</author>
<author>S Young</author>
</authors>
<title>Partially Observable Markov Decision Processes for Spoken Dialog Systems. Computer Speech Language,</title>
<date>2007</date>
<pages>21--2</pages>
<contexts>
<context position="3153" citStr="Williams and Young, 2007" startWordPosition="485" endWordPosition="488">5; Lee et al., 2007). In human-computer communication, the goal of error recovery strategy is to maximize the user’s satisfaction of using the system by guiding for the repair of the wrong information by human-computer interaction. On the other hand, there are different approaches to improve the robustness of dialog management using n-best hypotheses. Rather than Markov Decision Processes (MDPs), partially observable MDPs (POMDPs) potentially provide a much more powerful framework for robust dialog modeling since they consider nbest hypotheses to estimate the distribution of the belief state (Williams and Young, 2007). In recent, we proposed another data-driven approach for the dialog modeling called Examplebased Dialog Modeling (EBDM) (Lee et al., 2006a). However, difficulties occur when attempting to de630 Proceedings of ACL-08: HLT, pages 630–637, Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics ploy EBDM in practical spoken dialog systems in which ASR and NLU errors are frequent. Thus, this paper proposes a new method to improve the robustness of the EBDM framework using an agendabased approach and n-best recognition hypotheses. We consider a domain-specific agenda to es</context>
</contexts>
<marker>Williams, Young, 2007</marker>
<rawString>Williams, J.D. and Young, S. 2007. Partially Observable Markov Decision Processes for Spoken Dialog Systems. Computer Speech Language, 21(2):393-422.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Young</author>
<author>J Schatzmann</author>
<author>K Weilhammer</author>
<author>H Ye</author>
</authors>
<title>The Hidden Information State Approach to Dialog Management.</title>
<date>2007</date>
<booktitle>Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing,</booktitle>
<pages>149--152</pages>
<contexts>
<context position="4993" citStr="Young et al., 2007" startWordPosition="777" endWordPosition="780">cribes the error recovery strategy to handle unexpected cases. Then, Section 7 provides the experimental results of a real user evaluation to verify our approach. Finally, we draw conclusions and make suggestions for future work in Section 8. 2 Related Work In many spoken dialog systems that have been developed recently, various knowledge sources are used. One of the knowledge sources, which are usually application-dependent, is an agenda or task model. These are powerful representations for segmenting large tasks into more reasonable subtasks (Rich and Sidner, 1998; Bohus and Rudnicky, 2003; Young et al., 2007). These are manually designed for various purposes including dialog modeling, search space reduction, domain knowledge, and user simulation. In Collagen (Rich and Sidner, 1998), a plan tree, which is an approximate representation of a partial SharedPlan, is composed of alternating act and plan recipe nodes for internal discourse state representation and discourse interpretation. In addition, Bohus and Rudnicky (2003) have presented a RavenClaw dialog management which is an agenda-based architecture using hierarchical task decomposition and an expectation agenda. For modeling dialog, the domain</context>
</contexts>
<marker>Young, Schatzmann, Weilhammer, Ye, 2007</marker>
<rawString>Young, S., Schatzmann, J., Weilhammer, K., and Ye, H.. 2007. The Hidden Information State Approach to Dialog Management. Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing, 149–152.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>