<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000283">
<title confidence="0.985416">
Optimal Constituent Alignment with Edge Covers for Semantic Projection
</title>
<author confidence="0.9846">
Sebastian Padó
</author>
<affiliation confidence="0.983817">
Computational Linguistics
Saarland University
</affiliation>
<address confidence="0.499196">
Saarbrücken, Germany
</address>
<email confidence="0.992407">
pado@coli.uni-sb.de
</email>
<author confidence="0.978866">
Mirella Lapata
</author>
<affiliation confidence="0.859386666666667">
School of Informatics
University of Edinburgh
Edinburgh, UK
</affiliation>
<email confidence="0.995134">
mlap@inf.ed.ac.uk
</email>
<sectionHeader confidence="0.994724" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999879823529412">
Given a parallel corpus, semantic projec-
tion attempts to transfer semantic role an-
notations from one language to another,
typically by exploiting word alignments.
In this paper, we present an improved
method for obtaining constituent align-
ments between parallel sentences to guide
the role projection task. Our extensions
are twofold: (a) we model constituent
alignment as minimum weight edge cov-
ers in a bipartite graph, which allows us to
find a globally optimal solution efficiently;
(b) we propose tree pruning as a promising
strategy for reducing alignment noise. Ex-
perimental results on an English-German
parallel corpus demonstrate improvements
over state-of-the-art models.
</bodyText>
<sectionHeader confidence="0.998783" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999944967741936">
Recent years have witnessed increased interest in
data-driven methods for many natural language
processing (NLP) tasks, ranging from part-of-
speech tagging, to parsing, and semantic role la-
belling. The success of these methods is due partly
to the availability of large amounts of training data
annotated with rich linguistic information. Unfor-
tunately, such resources are largely absent for al-
most all languages except English. Given the data
requirements for supervised learning, and the cur-
rent paucity of suitable data for many languages,
methods for generating annotations (semi-)auto-
matically are becoming increasingly popular.
Annotation projection tackles this problem by
leveraging parallel corpora and the high-accuracy
tools (e.g., parsers, taggers) available for a
few languages. Specifically, through the use of
word alignments, annotations are transfered from
resource-rich languages onto low density ones.
The projection process can be decomposed into
three steps: (a) determining the units of projection;
these are typically words but can also be chunks
or syntactic constituents; (b) inducing alignments
between the projection units and projecting anno-
tations along these alignments; (c) reducing the
amount of noise in the projected annotations, often
due to errors and omissions in the word alignment.
The degree to which analyses are parallel across
languages is crucial for the success of projection
approaches. A number of recent studies rely on
this notion of parallelism and demonstrate that an-
notations can be adequately projected for parts of
speech (Yarowsky and Ngai, 2001; Hi and Hwa,
2005), chunks (Yarowsky and Ngai, 2001), and de-
pendencies (Hwa et al., 2002).
In previous work (Padó and Lapata, 2005) we
considered the annotation projection of seman-
tic roles conveyed by sentential constituents such
as AGENT, PATIENT, or INSTRUMENT. Semantic
roles exhibit a high degree of parallelism across
languages (Boas, 2005) and thus appear amenable
to projection. Furthermore, corpora labelled with
semantic role information can be used to train
shallow semantic parsers (Gildea and Jurafsky,
2002), which could in turn benefit applications in
need of broad-coverage semantic analysis. Exam-
ples include question answering, information ex-
traction, and notably machine translation.
Our experiments concentrated primarily on the
first projection step, i.e., establishing the right
level of linguistic analysis for effecting projec-
tion. We showed that projection schemes based
on constituent alignments significantly outperform
schemes that rely exclusively on word alignments.
A local optimisation strategy was used to find con-
stituent alignments, while relying on a simple fil-
tering technique to handle noise.
The study described here generalises our earlier
semantic role projection framework in two impor-
tant ways. First, we formalise constituent projec-
tion as the search for a minimum weight edge cover
in a weighted bipartite graph. This formalisation
</bodyText>
<page confidence="0.923006">
1161
</page>
<note confidence="0.5223535">
Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 1161–1168,
Sydney, July 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.9994065">
efficiently yields constituent alignments that are
globally optimal. Second, we propose tree prun-
ing as a general noise reduction strategy, which ex-
ploits both structural and linguistic information to
enable projection. Furthermore, we quantitatively
assess the impact of noise on the task by evaluating
both on automatic and manual word alignments.
In Section 2, we describe the task of role-
semantic projection and the syntax-based frame-
work introduced in Padó and Lapata (2005). Sec-
tion 3 explains how semantic role projection can
be modelled with minimum weight edge covers in
bipartite graphs. Section 4 presents our tree prun-
ing strategy. We present our evaluation framework
and results in Section 5. A discussion of related
and future work concludes the paper.
</bodyText>
<sectionHeader confidence="0.991643" genericHeader="introduction">
2 Cross-lingual Semantic Role projection
</sectionHeader>
<bodyText confidence="0.9999348125">
Semantic role projection is illustrated in Figure 1
using English and German as the source-target
language pair. We assume a FrameNet-style se-
mantic analysis (Fillmore et al., 2003). In this
paradigm, the semantics of predicates and their
arguments are described in terms of frames, con-
ceptual structures which model prototypical situ-
ations. The English sentence Kim promised to be
on time in Figure 1 is an instance of the COM-
MITMENT frame. In this particular example, the
frame introduces two roles, i.e., SPEAKER (Kim)
and MESSAGE (to be on time). Other possible,
though unrealised, roles are ADDRESSEE, MES-
SAGE, and TOPIC. The COMMITMENT frame can
be introduced by promise and several other verbs
and nouns such as consent or threat.
We also assume that frame-semantic annota-
tions can be obtained reliably through shallow
semantic parsing.1 Following the assignment of
semantic roles on the English side, (imperfect)
word alignments are used to infer semantic align-
ments between constituents (e.g., to be on time
is aligned with pünktlich zu kommen), and the
role labels are transferred from one language to
the other. Note that role projection can only take
place if the source predicate (here promised) is
word-aligned to a target predicate (here versprach)
evoking the same frame; if this is not the case
(e.g., in metaphors), projected roles will not be
generally appropriate.
We represent the source and target sentences
as sets of linguistic units, Us and Ut, respectively.
</bodyText>
<footnote confidence="0.798538333333333">
1See Carreras and Màrquez (2005) for an overview of re-
cent approaches to semantic parsing.
Kim versprach, pŸnktlich zu kommen
</footnote>
<figureCaption confidence="0.964073">
Figure 1: Projection of semantic roles from En-
glish to German (word alignments as dotted lines)
</figureCaption>
<bodyText confidence="0.999871928571429">
The assignment of semantic roles on the source
side is a function roles : R —* 2Us from roles to
sets of source units. Constituent alignments are
obtained in two steps. First, a real-valued func-
tion sim : Us x Ut —* R estimates pairwise simi-
larities between source and target units. To make
our model robust to alignment noise, we use only
content words to compute the similarity func-
tion. Next, a decision procedure uses the similar-
ity function to determine the set of semantically
equivalent, i.e., aligned units A C_ Us xUt. Once A
is known, semantic projection reduces to transfer-
ring the semantic roles from the source units onto
their aligned target counterparts:
</bodyText>
<equation confidence="0.884697">
rolet(r) = {ut |]us E roles(r) : (us,ut) E A}
</equation>
<bodyText confidence="0.999747533333334">
In Padó and Lapata (2005), we evaluated two
main parameters within this framework: (a) the
choice of linguistic units and (b) methods for com-
puting semantic alignments. Our results revealed
that constituent-based models outperformed word-
based ones by a wide margin (0.65 Fscore
vs. 0.46), thus demonstrating the importance of
bracketing in amending errors and omissions in
the automatic word alignment. We also com-
pared two simplistic alignment schemes, back-
ward alignment and forward alignment. The
first scheme aligns each target constituent to its
most similar source constituent, whereas the sec-
ond (Af) aligns each source constituent to its most
similar target constituent:
</bodyText>
<equation confidence="0.590058">
Af = {(us,ut)|ut = argmax sim(us,u&apos;t)}
</equation>
<page confidence="0.285387">
u�tEUt
</page>
<figure confidence="0.995248">
Commitment
Kim promised to be on time
NP
S
NP
S
Commitment
</figure>
<page confidence="0.996196">
1162
</page>
<bodyText confidence="0.999984711111111">
An example constituent alignment obtained from
the forward scheme is shown in Figure 2 (left
side). The nodes represent constituents in the
source and target language and the edges indicate
the resulting alignment. Forward alignment gener-
ally outperformed backward alignment (0.65 Fs-
core vs. 0.45). Both procedures have a time com-
plexity quadratic in the maximal number of sen-
tence nodes: O(|Us||Ut|) = O(max(|Us|,|Ut|)2).
A shortcoming common to both decision proce-
dures is that they are local, i.e., they optimise the
alignment for each node independently of all other
nodes. Consider again Figure 2. Here, the for-
ward procedure creates alignments for all source
nodes, but leaves constituents from the target set
unaligned (see target node (1)). Moreover, local
alignment methods constitute a rather weak model
of semantic equivalence since they allow one tar-
get node to correspond to any number of source
nodes (see target node (3) in Figure 2, which is
aligned to three source nodes). In fact, by allow-
ing any alignment between constituents, the lo-
cal models can disregard important linguistic in-
formation, thus potentially leading to suboptimal
results. We investigate this possibility by propos-
ing well-understood global optimisation models
which suitably constrain the resulting alignments.
Besides matching constituents reliably, poor
word alignments are a major stumbling block
for achieving accurate projections. Previous re-
search addresses this problem in a post-processing
step, by reestimating parameter values (Yarowsky
and Ngai, 2001), by applying transformation
rules (Hwa et al., 2002), by using manually la-
belled data (Hi and Hwa, 2005), or by relying on
linguistic criteria (Padó and Lapata, 2005). In this
paper, we present a novel filtering technique based
on tree pruning which removes extraneous con-
stituents in a preprocessing stage, thereby disasso-
ciating filtering from the alignment computation.
In the remainder of this paper, we present the
details of our global optimisation and filtering
techniques. We only consider constituent-based
models, since these obtained the best performance
in our previous study (Padó and Lapata, 2005).
</bodyText>
<sectionHeader confidence="0.952542" genericHeader="method">
3 Globally optimal constituent alignment
</sectionHeader>
<bodyText confidence="0.990908547169811">
We model constituent alignment as a minimum
weight bipartite edge cover problem. A bipartite
graph is a graph G = (V,E) whose node set V is
partitioned into two nonempty sets V1 and V2 in
such a way that every edge E joins a node in V1
to a node in V2. In a weighted bipartite graph a
weight is assigned to each edge. An edge cover is
a subgraph of a bipartite graph so that each node is
linked to at least one node of the other partition. A
minimum weight edge cover is an edge cover with
the least possible sum of edge weights.
In our projection application, the two parti-
tions are the sets of source and target sentence
constituents, Us and Ut, respectively. Each source
node is connected to all target nodes and each tar-
get node to all source nodes; these edges can be
thought of as potential constituent alignments. The
edge weights, which represent the (dis)similarity
between nodes us and ut are set to 1−sim(us,ut).2
The minimum weight edge cover then represents
the alignment with the maximal similarity be-
tween source and target constituents. Below, we
present details on graph edge covers and a more
restricted kind, minimum weight perfect bipartite
matchings. We also discuss their computation.
Edge covers Given a bipartite graph G, a min-
imum weight edge cover Ae can be defined as:
Ae = argmin ∑ 1−sim(us,ut)
Edge cover E (us,ut)EE
An example edge cover is illustrated in Figure 2
(middle). Edge covers are somewhat more con-
strained compared to the local model described
above: all source and target nodes have to take part
in some alignment. We argue that this is desirable
in modelling constituent alignment, since impor-
tant linguistic units will not be ignored. As can be
seen, edge covers allow one-to-many alignments
which are common when translating from one lan-
guage to another. For example, an English con-
stituent might be split into several German con-
stituents or alternatively two English constituents
might be merged into a single German constituent.
In Figure 2, the source nodes (3) and (4) corre-
spond to target node (4). Since each node of either
side has to participate in at least one alignment,
edge covers cannot account for insertions arising
when constituents in the source language have no
counterpart in their target language, or vice versa,
as is the case for deletions.
Weighted perfect bipartite matchings Per-
fect bipartite matchings are a more constrained
version of edge covers, in which each node has ex-
actly one adjacent edge. This restricts constituent
</bodyText>
<footnote confidence="0.9722455">
2The choice of similarity function is discussed in Sec-
tion 5.
</footnote>
<page confidence="0.935767">
1163
</page>
<figure confidence="0.999053895833333">
Us Ut Us Ut
2
1
2
1
4
3
4
3
r1
r2
r2
5
6
r1
r1
r2
r2 r2
2
1
2
1
4
3
5
6
4
3
r1
r2
Us Ut
1
2
1
2
r1
r1
4
3
5
6
4
d
d
3
r2
r2
r2
</figure>
<figureCaption confidence="0.940594666666667">
Figure 2: Constituent alignments and role projections resulting from different decision procedures
(Us,Ut: sets of source and target constituents; r1,r2: two semantic roles). Left: local forward alignment;
middle: edge cover; right: perfect matching with dummy nodes
</figureCaption>
<bodyText confidence="0.964680833333333">
alignment to a bijective function: each source
constituent is linked to exactly one target con-
stituent, and vice versa. Analogously, a minimum
weight perfect bipartite matching Am is a mini-
mum weight edge cover obeying the one-to-one
constraint:
</bodyText>
<equation confidence="0.9647015">
Am = argmin ∑ 1− sim(us,ut)
Matching M (us,ut)EM
</equation>
<bodyText confidence="0.995970525">
An example of a perfect bipartite matching is
given in Figure 2 (right), where each node has ex-
actly one adjacent edge. Note that the target side
contains two nodes labelled (d), a shorthand for
“dummy” node. Since sentence pairs will often
differ in length, the resulting graph partitions will
have different sizes as well. In such cases, dummy
nodes are introduced in the smaller partition to
enable perfect matching. Dummy nodes are as-
signed a similarity of zero with all other nodes.
Alignments to dummy nodes (such as for source
nodes (3) and (6)) are ignored during projection.
Perfect matchings are more restrictive models
of constituent alignment than edge covers. Being
bijective, the resulting alignments cannot model
splitting or merging operations at all. Insertions
and deletions can be modelled only indirectly by
aligning nodes in the larger partition to dummy
nodes on the other side (see the source side in Fig-
ure 2 where nodes (3) and (6) are aligned to (d)).
Section 5 assesses if these modelling limitations
impact the quality of the resulting alignments.
Algorithms Minimum weight perfect match-
ings in bipartite graphs can be computed effi-
ciently in cubic time using algorithms for net-
work optimisation (Fredman and Tarjan, 1987;
time O(|Us|2 log|Us|+|Us|2|Ut|)) or algorithms for
the equivalent linear assignment problem (Jonker
and Volgenant, 1987; time O(max(|Us|,|Ut|)3)).
Their complexity is a linear factor slower than the
quadratic runtime of the local optimisation meth-
ods presented in Section 2.
The computation of (general) edge covers has
been investigated by Eiter and Mannila (1997) in
the context of distance metrics for point sets. They
show that edge covers can be reduced to minimum
weight perfect matchings of an auxiliary bipar-
tite graph with two partitions of size |Us |+ |Ut|.
This allows the computation of general minimum
weight edge covers in time O((|Us |+ |Ut|)3).
</bodyText>
<sectionHeader confidence="0.995584" genericHeader="method">
4 Filtering via Tree Pruning
</sectionHeader>
<bodyText confidence="0.988330523809524">
We introduce two filtering techniques which effec-
tively remove constituents from source and target
trees before alignment takes place. Tree pruning as
a preprocessing step is more general and more effi-
cient than our original post-processing filter (Padó
and Lapata, 2005) which was embedded into the
similarity function. Not only does tree pruning not
interfere with the similarity function but also re-
duces the size of the graph, thus speeding up the
algorithms discussed in the previous section.
We present two instantiations of tree pruning:
word-based filtering, which subsumes our earlier
method, and argument-based filtering, which elim-
inates unlikely argument candidates.
Word-based filtering This technique re-
moves terminal nodes from parse trees accord-
ing to certain linguistic or alignment-based crite-
ria. We apply two word-based filters in our ex-
periments. The first removes non-content words,
i.e., all words which are not adjectives, adverbs,
verbs, or nouns, from the source and target sen-
</bodyText>
<page confidence="0.994909">
1164
</page>
<figureCaption confidence="0.9485485">
Figure 3: Filtering of unlikely arguments (predi-
cate in boldface, potential arguments in boxes).
</figureCaption>
<bodyText confidence="0.99914892">
tences (Padó and Lapata, 2005). We also use a
novel filter which removes all words which remain
unaligned in the automatic word alignment. Non-
terminal nodes whose terminals are removed by
these filters, are also pruned.
Argument filtering Previous work in shal-
low semantic parsing has demonstrated that not
all nodes in a tree are equally probable as seman-
tic roles for a given predicate (Xue and Palmer,
2004). In fact, assuming a perfect parse, there is
a “set of likely arguments”, to which almost all
semantic roles roles should be assigned to. This
set of likely arguments consists of all constituents
which are a child of some ancestor of the pred-
icate, provided that (a) they do not dominate the
predicate themselves and (b) there is no sentence
boundary between a constituent and its predicate.
This definition covers long-distance dependencies
such as control constructions for verbs, or support
constructions for nouns and adjectives, and can be
extended slightly to accommodate coordination.
This argument-based filter reduces target trees
to a set of likely arguments. In the example in Fig-
ure 3, all tree nodes are removed except Kim and
pünktlich zu kommen.
</bodyText>
<sectionHeader confidence="0.999496" genericHeader="method">
5 Evaluation Set-up
</sectionHeader>
<subsectionHeader confidence="0.929549">
Data For evaluation, we used the parallel cor-
</subsectionHeader>
<bodyText confidence="0.9989512">
pus3 from our earlier work (Padó and Lapata,
2005). It consists of 1,000 English-German sen-
tence pairs from the Europarl corpus (Koehn,
2005). The sentences were automatically parsed
(using Collin’s 1997 parser for English and
Dubey’s 2005 parser for German), and manually
annotated with FrameNet-like semantic roles (see
Padó and Lapata 2005 for details.)
Word alignments were computed with the
GIZA++ toolkit (Och and Ney, 2003), using the
</bodyText>
<footnote confidence="0.8775095">
3The corpus can be downloaded from http://www.
coli.uni-saarland.de/~pado/projection/.
</footnote>
<bodyText confidence="0.99976562962963">
entire English-German Europarl bitext as training
data (20M words). We used the GIZA++ default
settings to induce alignments for both directions
(source-target, target-source). Following common
practise in MT (Koehn et al., 2003), we considered
only their intersection (bidirectional alignments
are known to exhibit high precision). We also pro-
duced manual word alignments for all sentences
in our corpus, using the GIZA++ alignments as a
starting point and following the Blinker annotation
guidelines (Melamed, 1998).
Method and parameter choice The con-
stituent alignment models we present are unsu-
pervised in that they do not require labelled data
for inferring correct alignments. Nevertheless, our
models have three parameters: (a) the similarity
measure for identifying semantically equivalent
constituents; (b) the filtering procedure for remov-
ing noise in the data (e.g., wrong alignments); and
(c) the decision procedure for projection.
We retained the similarity measure introduced
in Padó and Lapata (2005) which computes the
overlap between a source constituent and its can-
didate projection, in both directions. Let y(cs) and
y(ct) denote the yield of a source and target con-
stituent, respectively, and al(T) the union of all
word alignments for a token set T:
</bodyText>
<equation confidence="0.941701">
sim(cs,ct) = |y(ct)∩al(y(cs)) ||y(cs)∩al(y(ct))|
</equation>
<bodyText confidence="0.999976315789474">
We examined three filtering procedures (see Sec-
tion 4): removing non-aligned words (NA), re-
moving non-content words (NC), and removing
unlikely arguments (Arg). These were combined
with three decision procedures: local forward
alignment (Forward), perfect matching (Perf-
Match), and edge cover matching (EdgeCover)
(see Section 3). We used Jonker and Vol-
genant’s (1987) solver4 to compute weighted per-
fect matchings.
In order to find optimal parameter settings for
our models, we split our corpus randomly into a
development and test set (both 50% of the data)
and examined the parameter space exhaustively
on the development set. The performance of the
best models was then assessed on the test data.
The models had to predict semantic roles for Ger-
man, using English gold standard roles as input,
and were evaluated against German gold standard
</bodyText>
<footnote confidence="0.906542">
4The software is available from http://www.
magiclogic.com/assignment.html.
</footnote>
<figure confidence="0.950480666666667">
VP
S
VP
Kim versprach, pUnktlich zu kommen.
S
|y(cs) ||y(ct)|
</figure>
<page confidence="0.963943">
1165
</page>
<table confidence="0.99986824">
Model Prec Rec F-score
WordBL 45.6 44.8 45.1
Filter Forward 66.0 56.5 60.9
PerfMatch 71.7 54.7 62.1
No EdgeCover 65.6 57.3 61.2
UpperBnd 85.0 84.0 84.0
Model Prec Rec F-score
WordBL 45.6 44.8 45.1
Forward 74.1 56.1 63.9
Fil PerfMatch 73.3 62.1 67.2
NA EdgeCover 70.5 62.9 66.5
UpperBnd 85.0 84.0 84.0
Model Prec Rec F-score
WordBL 45.6 44.8 45.1
Forward 64.3 47.8 54.8
Fi PerfMatch 73.1 56.9 64.0
CN EdgeCover 67.5 57.0 61.8
UpperBnd 85.0 84.0 84.0
Model Prec Rec F-score
WordBL 45.6 44.8 45.1
Forward 69.9 60.7 65.0
Fi PerfMatch 80.4 48.1 60.2
EdgeCover 69.6 60.6 64.8
Arg
UpperBnd 85.0 84.0 84.0
</table>
<tableCaption confidence="0.999753">
Table 1: Model comparison using intersective alignments (development set)
</tableCaption>
<bodyText confidence="0.985586214285714">
roles. To gauge the extent to which alignment er-
rors are harmful, we present results both on inter-
sective and manual alignments.
Upper bound and baseline In Padó and La-
pata (2005), we assessed the feasibility of seman-
tic role projection by measuring how well anno-
tators agreed on identifying roles and their spans.
We obtained an inter-annotator agreement of 0.84
(F-score), which can serve as an upper bound for
the projection task. As a baseline, we use a sim-
ple word-based model (WordBL) from the same
study. The units of this model are words, and the
span of a projected role is the union of all target
terminals aligned to a terminal of the source role.
</bodyText>
<sectionHeader confidence="0.999846" genericHeader="method">
6 Results
</sectionHeader>
<bodyText confidence="0.995283309090909">
Development set Our results on the develop-
ment set are summarised in Table 1. We show how
performance varies for each model according to
different filtering procedures when automatically
produced word alignments are used. No filtering
is applied to the baseline model (WordBL).
Without filtering, local and global models yield
comparable performance. Models based on perfect
bipartite matchings (PerfMatch) and edge covers
(EdgeCover) obtain slight F-score improvements
over the forward alignment model (Forward). It
is worth noticing that PerfMatch yields a signifi-
cantly higher precision (using a χ2 test, p &lt; 0.01)
than Forward and EdgeCover. This indicates that,
even without filtering, PerfMatch delivers rather
accurate projections, however with low recall.
Model performance seems to increase with tree
pruning. When non-aligned words are removed
(Table 1, NA Filter), PerfMatch and EdgeCover
reach an F-score of 67.2 and 66.5, respectively.
This is an increase of approximately 3% over the
local Forward model. Although the latter model
yields high precision (74.1%), its recall is sig-
nificantly lower than PerfMatch and EdgeCover
(p &lt; 0.01). This demonstrates the usefulness of
filtering for the more constrained global models
which as discussed in Section 3 can only represent
a limited set of alignment possibilities.
The non-content words filter (NC filter) yields
smaller improvements. In fact, for the Forward
model, results are worse than applying no filter-
ing at all. We conjecture that NC is an overly
aggressive filter which removes projection-critical
words. This is supported by the relatively low re-
call values. In comparison to NA, recall drops
by 8.3% for Forward and by almost 6% for Perf-
Match and EdgeCover. Nevertheless, both Perf-
Match and EdgeCover outperform the local For-
ward model. PerfMatch is the best performing
model reaching an F-score of 64.0%.
We now consider how the models behave when
the argument-based filter is applied (Arg, Table 1,
bottom). As can be seen, the local model benefits
most from this filter, whereas PerfMatch is worst
affected; it obtains its highest precision (80.4%) as
well as its lowest recall (48.1%). This is somewhat
expected since the filter removes the majority of
nodes in the target partition causing a proliferation
of dummy nodes. The resulting edge covers are
relatively “unnatural”, thus counterbalancing the
advantages of global optimisation.
To summarise, we find on the development set
that PerfMatch in the NA Filter condition obtains
the best performance (F-score 67.2%), followed
closely by EdgeCover (F-score 66.5%) in the same
</bodyText>
<page confidence="0.974866">
1166
</page>
<table confidence="0.999854846153846">
Model Prec Rec F-score
WordBL 45.7 45.0 43.3
ict Forward (Arg) 72.4 63.2 67.5
PerfMatch (NA) 75.7 63.7 69.2
EdgeCover (NA) 73.0 64.9 68.7
UpperBnd 85.0 84.0 84.0
Model Prec Rec F-score
WordBL 62.1 60.7 70.4
Forward (Arg) 72.2 68.6 71.4
lMnaau 75.7 67.5 70.6
PerfMatch (NA) 71.9 69.3 84.0
EdgeCover (NA) 85.0 84.0
UpperBnd 61.4
</table>
<tableCaption confidence="0.9952005">
Table 2: Model comparison using intersective and
manual alignments (test set)
</tableCaption>
<bodyText confidence="0.997291847457627">
condition. In general, PerfMatch seems less sensi-
tive to the type of filtering used; it yields best re-
sults in three out of four filtering conditions (see
boldface figures in Table 1). Our results further in-
dicate that Arg boosts the performance of the local
model by guiding it towards linguistically appro-
priate alignments.5
A comparative analysis of the output of Perf-
Match and EdgeCover revealed that the two mod-
els make similar errors (85% overlap). Disagree-
ments, however, arise with regard to misparses.
Consider as an example the sentence pair:
The Charter is [Nr an opportunity to
bring the EU closer to the people.]
Die Charta ist [Nr eine Chance], [S die
EU den Bürgern näherzubringen.]
An ideal algorithm would align the English NP
to both the German NP and S. EdgeCover, which
can model one-to-many-relationships, acts “con-
fidently” and aligns the NP to the German S to
maximise the overlap similarity, incurring both a
precision and a recall error. PerfMatch, on the
other hand, cannot handle one-to-many relation-
ships, acts “cautiously” and aligns the English NP
to a dummy node, leading to a recall error. Thus,
even though EdgeCover’s analysis is partly right,
it will come out worse than PerfMatch, given the
current dataset and evaluation method.
Test set We now examine whether our results
carry over to the test data. Table 2 shows the
5Experiments using different filter combinations did not
lead to performance gains over individual filters and are not
reported here due to lack of space.
performance of the best models (Forward (Arg),
PerfMatch (NA), and EdgeCover (NA)) on auto-
matic (Intersective) and manual (Manual) align-
ments.6 All models perform significantly better
than the baseline but significantly worse than the
upper bound (both in terms of precision and recall,
p &lt; 0.01). PerfMatch and EdgeCover yield better
F-scores than the Forward model. In fact, Perf-
Match yields a significantly better precision than
Forward (p &lt; 0.01).
Relatively small performance gains are ob-
served when manual alignments are used. The F-
score increases by 2.9% for Forward, 2.2% for
PerfMatch, and 1.9% for EdgeCover. Also note
that this better performance is primarily due to a
significant increase in recall (p &lt; 0.01), but not
precision. This is an encouraging result indicating
that our filters and graph-based algorithms elim-
inate alignment noise to a large extent. Analysis
of the models’ output revealed that the remain-
ing errors are mostly due to incorrect parses (none
of the parsers employed in this work were trained
on the Europarl corpus) but also to modelling de-
ficiencies. Recall from Section 3 that our global
models cannot currently capture one-to-zero cor-
respondences, i.e., deletions and insertions.
</bodyText>
<sectionHeader confidence="0.999933" genericHeader="method">
7 Related work
</sectionHeader>
<bodyText confidence="0.999944052631579">
Previous work has primarily focused on the pro-
jection of grammatical (Yarowsky and Ngai, 2001)
and syntactic information (Hwa et al., 2002). An
exception is Fung and Chen (2004), who also
attempt to induce FrameNet-style annotations in
Chinese. Their method maps English FrameNet
entries to concepts listed in HowNet7, an on-line
ontology for Chinese, without using parallel texts.
The present work extends our earlier projection
framework (Padó and Lapata, 2005) by proposing
global methods for automatic constituent align-
ment. Although our models are evaluated on the
semantic role projection task, we believe they also
show promise in the context of statistical ma-
chine translation. Especially for systems that use
syntactic information to enhance translation qual-
ity. For example, Xia and McCord (2004) exploit
constituent alignment for rearranging sentences in
the source language so as to make their word or-
</bodyText>
<footnote confidence="0.9825532">
6Our results on the test set are slightly higher in compar-
ison to the development set. The fluctuation reflects natural
randomness in the partitioning of our corpus.
7See http://www.keenage.com/zhiwang/e_
zhiwang.html.
</footnote>
<page confidence="0.994912">
1167
</page>
<bodyText confidence="0.999974238095238">
der similar to that of the target language. They
learn tree reordering rules by aligning constituents
heuristically using a naive local optimisation pro-
cedure analogous to forward alignment. A simi-
lar approach is described in Collins et al. (2005);
however, the rules are manually specified and the
constituent alignment step reduces to inspection of
the source-target sentence pairs. The global opti-
misation models presented in this paper could be
easily employed for the reordering task common
to both approaches.
Other approaches treat rewrite rules not as a
preprocessing step (e.g., for reordering source
strings), but as a part of the translation model
itself (Gildea, 2003; Gildea, 2004). Constituent
alignments are learnt by estimating the probabil-
ity of tree transformations, such as node deletions,
insertions, and reorderings. These models have a
greater expressive power than our edge cover mod-
els; however, this implies that approximations are
often used to make computation feasible.
</bodyText>
<sectionHeader confidence="0.999213" genericHeader="conclusions">
8 Conclusions
</sectionHeader>
<bodyText confidence="0.999886230769231">
In this paper, we have proposed a novel method
for obtaining constituent alignments between par-
allel sentences and have shown that it is use-
ful for semantic role projection. A key aspect of
our approach is the formalisation of constituent
alignment as the search for a minimum weight
edge cover in a bipartite graph. This formalisation
provides efficient mechanisms for aligning con-
stituents and yields results superior to heuristic ap-
proaches. Furthermore, we have shown that tree-
based noise filtering techniques are essential for
good performance.
Our approach rests on the assumption that con-
stituent alignment can be determined solely from
the lexical similarity between constituents. Al-
though this allows us to model constituent align-
ments efficiently as edge covers, it falls short of
modelling translational divergences such as substi-
tutions or insertions/deletions. In future work, we
will investigate minimal tree edit distance (Bille,
2005) and related formalisms which are defined
on tree structures and can therefore model diver-
gences explicitly. However, it is an open ques-
tion whether cross-linguistic syntactic analyses are
similar enough to allow for structure-driven com-
putation of alignments.
</bodyText>
<sectionHeader confidence="0.940286" genericHeader="acknowledgments">
Acknowledgments The authors acknowledge
</sectionHeader>
<reference confidence="0.554794">
the support of DFG (Padó; grant Pi-154/9-2) and
EPSRC (Lapata; grant GR/T04540/01).
</reference>
<sectionHeader confidence="0.869249" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999893069444445">
P. Bille. 2005. A survey on tree edit distance and related
problems. Theoretical Computer Science, 337(1-3):217–
239.
H. C. Boas. 2005. Semantic frames as interlingual represen-
tations for multilingual lexical databases. International
Journal of Lexicography, 18(4):445–478.
X. Carreras, L. Màrquez, eds. 2005. Proceedings of the
CoNLL shared task: Semantic role labelling, Boston, MA,
2005.
M. Collins, P. Koehn, I. Kuˇcerová. 2005. Clause restructur-
ing for statistical machine translation. In Proceedings of
the 43rd ACL, 531–540, Ann Arbor, MI.
M. Collins. 1997. Three generative, lexicalised models for
statistical parsing. In Proceedings of the ACL/EACL, 16–
23, Madrid, Spain.
A. Dubey. 2005. What to do when lexicalization fails: pars-
ing German with suffix analysis and smoothing. In Pro-
ceedings of the 43rd ACL, 314–321, Ann Arbor, MI.
T. Eiter, H. Mannila. 1997. Distance measures for point sets
and their computation. Acta Informatica, 34(2):109–133.
C. J. Fillmore, C. R. Johnson, M. R. Petruck. 2003. Back-
ground to FrameNet. International Journal of Lexicogra-
phy, 16:235–250.
M. L. Fredman, R. E. Tarjan. 1987. Fibonacci heaps and
their uses in improved network optimization algorithms.
Journal of the ACM, 34(3):596–615.
P. Fung, B. Chen. 2004. BiFrameNet: Bilingual frame se-
mantics resources construction by cross-lingual induction.
In Proceedings of the 20th COLING, 931–935, Geneva,
Switzerland.
D. Gildea, D. Jurafsky. 2002. Automatic labeling of seman-
tic roles. Computational Linguistics, 28(3):245–288.
D. Gildea. 2003. Loosely tree-based alignment for machine
translation. In Proceedings of the 41st ACL, 80–87, Sap-
poro, Japan.
D. Gildea. 2004. Dependencies vs. constituents for tree-
based alignment. In Proceedings of the EMNLP, 214–221,
Barcelona, Spain.
C. Hi, R. Hwa. 2005. A backoff model for bootstrapping
resources for non-english languages. In Proceedings of
the HLT/EMNLP, 851–858, Vancouver, BC.
R. Hwa, P. Resnik, A. Weinberg, O. Kolak. 2002. Evaluation
of translational correspondence using annotation projec-
tion. In Proceedings of the 40th ACL, 392–399, Philadel-
phia, PA.
R. Jonker, T. Volgenant. 1987. A shortest augmenting path
algorithm for dense and sparse linear assignment prob-
lems. Computing, 38:325–340.
P. Koehn, F. J. Och, D. Marcu. 2003. Statistical phrase-based
translation. In Proceedings of the HLT/NAACL, 127–133,
Edmonton, AL.
P. Koehn. 2005. Europarl: A parallel corpus for statistical
machine translation. In Proceedings of the MT Summit X,
Phuket, Thailand.
I. D. Melamed. 1998. Manual annotation of translational
equivalence: The Blinker project. Technical Report IRCS
TR #98-07, IRCS, University of Pennsylvania, 1998.
F. J. Och, H. Ney. 2003. A systematic comparison of various
statistical alignment models. Computational Linguistics,
29(1):19–52.
S. Padó, M. Lapata. 2005. Cross-lingual projection
of role-semantic information. In Proceedings of the
HLT/EMNLP, 859–866, Vancouver, BC.
F. Xia, M. McCord. 2004. Improving a statistical MT system
with automatically learned rewrite patterns. In Proceed-
ings of the 20th COLING, 508–514, Geneva, Switzerland.
N. Xue, M. Palmer. 2004. Calibrating features for seman-
tic role labeling. In Proceedings of the EMNLP, 88–94,
Barcelona, Spain.
D. Yarowsky, G. Ngai. 2001. Inducing multilingual text
analysis tools via robust projection across aligned corpora.
In Proceedings of the HLT, 161–168, San Diego, CA.
</reference>
<page confidence="0.995238">
1168
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.814170">
<title confidence="0.999971">Optimal Constituent Alignment with Edge Covers for Semantic Projection</title>
<author confidence="0.999486">Sebastian Padó</author>
<affiliation confidence="0.9974345">Computational Linguistics Saarland University</affiliation>
<address confidence="0.993017">Saarbrücken, Germany</address>
<email confidence="0.997163">pado@coli.uni-sb.de</email>
<author confidence="0.99664">Mirella Lapata</author>
<affiliation confidence="0.999969">School of Informatics University of Edinburgh</affiliation>
<address confidence="0.839184">Edinburgh, UK</address>
<email confidence="0.997459">mlap@inf.ed.ac.uk</email>
<abstract confidence="0.999450333333333">Given a parallel corpus, semantic projection attempts to transfer semantic role annotations from one language to another, typically by exploiting word alignments. In this paper, we present an improved for obtaining alignparallel sentences to guide the role projection task. Our extensions are twofold: (a) we model constituent as weight edge cova bipartite graph, which allows us to find a globally optimal solution efficiently; we propose pruning a promising strategy for reducing alignment noise. Experimental results on an English-German parallel corpus demonstrate improvements over state-of-the-art models.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<title>the support of DFG (Padó; grant Pi-154/9-2) and EPSRC (Lapata; grant GR/T04540/01).</title>
<marker></marker>
<rawString>the support of DFG (Padó; grant Pi-154/9-2) and EPSRC (Lapata; grant GR/T04540/01).</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Bille</author>
</authors>
<title>A survey on tree edit distance and related problems.</title>
<date>2005</date>
<journal>Theoretical Computer Science,</journal>
<pages>337--1</pages>
<marker>Bille, 2005</marker>
<rawString>P. Bille. 2005. A survey on tree edit distance and related problems. Theoretical Computer Science, 337(1-3):217– 239.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H C Boas</author>
</authors>
<title>Semantic frames as interlingual representations for multilingual lexical databases.</title>
<date>2005</date>
<journal>International Journal of Lexicography,</journal>
<volume>18</volume>
<issue>4</issue>
<contexts>
<context position="2918" citStr="Boas, 2005" startWordPosition="421" endWordPosition="422">hich analyses are parallel across languages is crucial for the success of projection approaches. A number of recent studies rely on this notion of parallelism and demonstrate that annotations can be adequately projected for parts of speech (Yarowsky and Ngai, 2001; Hi and Hwa, 2005), chunks (Yarowsky and Ngai, 2001), and dependencies (Hwa et al., 2002). In previous work (Padó and Lapata, 2005) we considered the annotation projection of semantic roles conveyed by sentential constituents such as AGENT, PATIENT, or INSTRUMENT. Semantic roles exhibit a high degree of parallelism across languages (Boas, 2005) and thus appear amenable to projection. Furthermore, corpora labelled with semantic role information can be used to train shallow semantic parsers (Gildea and Jurafsky, 2002), which could in turn benefit applications in need of broad-coverage semantic analysis. Examples include question answering, information extraction, and notably machine translation. Our experiments concentrated primarily on the first projection step, i.e., establishing the right level of linguistic analysis for effecting projection. We showed that projection schemes based on constituent alignments significantly outperform</context>
</contexts>
<marker>Boas, 2005</marker>
<rawString>H. C. Boas. 2005. Semantic frames as interlingual representations for multilingual lexical databases. International Journal of Lexicography, 18(4):445–478.</rawString>
</citation>
<citation valid="true">
<date>2005</date>
<booktitle>Proceedings of the CoNLL shared task: Semantic role labelling,</booktitle>
<editor>X. Carreras, L. Màrquez, eds.</editor>
<location>Boston, MA,</location>
<contexts>
<context position="4632" citStr="(2005)" startWordPosition="670" endWordPosition="670">stics and 44th Annual Meeting of the ACL, pages 1161–1168, Sydney, July 2006. c�2006 Association for Computational Linguistics efficiently yields constituent alignments that are globally optimal. Second, we propose tree pruning as a general noise reduction strategy, which exploits both structural and linguistic information to enable projection. Furthermore, we quantitatively assess the impact of noise on the task by evaluating both on automatic and manual word alignments. In Section 2, we describe the task of rolesemantic projection and the syntax-based framework introduced in Padó and Lapata (2005). Section 3 explains how semantic role projection can be modelled with minimum weight edge covers in bipartite graphs. Section 4 presents our tree pruning strategy. We present our evaluation framework and results in Section 5. A discussion of related and future work concludes the paper. 2 Cross-lingual Semantic Role projection Semantic role projection is illustrated in Figure 1 using English and German as the source-target language pair. We assume a FrameNet-style semantic analysis (Fillmore et al., 2003). In this paradigm, the semantics of predicates and their arguments are described in terms</context>
<context position="6477" citStr="(2005)" startWordPosition="965" endWordPosition="965">imperfect) word alignments are used to infer semantic alignments between constituents (e.g., to be on time is aligned with pünktlich zu kommen), and the role labels are transferred from one language to the other. Note that role projection can only take place if the source predicate (here promised) is word-aligned to a target predicate (here versprach) evoking the same frame; if this is not the case (e.g., in metaphors), projected roles will not be generally appropriate. We represent the source and target sentences as sets of linguistic units, Us and Ut, respectively. 1See Carreras and Màrquez (2005) for an overview of recent approaches to semantic parsing. Kim versprach, pŸnktlich zu kommen Figure 1: Projection of semantic roles from English to German (word alignments as dotted lines) The assignment of semantic roles on the source side is a function roles : R —* 2Us from roles to sets of source units. Constituent alignments are obtained in two steps. First, a real-valued function sim : Us x Ut —* R estimates pairwise similarities between source and target units. To make our model robust to alignment noise, we use only content words to compute the similarity function. Next, a decision pro</context>
<context position="19458" citStr="(2005)" startWordPosition="3060" endWordPosition="3060">g the GIZA++ alignments as a starting point and following the Blinker annotation guidelines (Melamed, 1998). Method and parameter choice The constituent alignment models we present are unsupervised in that they do not require labelled data for inferring correct alignments. Nevertheless, our models have three parameters: (a) the similarity measure for identifying semantically equivalent constituents; (b) the filtering procedure for removing noise in the data (e.g., wrong alignments); and (c) the decision procedure for projection. We retained the similarity measure introduced in Padó and Lapata (2005) which computes the overlap between a source constituent and its candidate projection, in both directions. Let y(cs) and y(ct) denote the yield of a source and target constituent, respectively, and al(T) the union of all word alignments for a token set T: sim(cs,ct) = |y(ct)∩al(y(cs)) ||y(cs)∩al(y(ct))| We examined three filtering procedures (see Section 4): removing non-aligned words (NA), removing non-content words (NC), and removing unlikely arguments (Arg). These were combined with three decision procedures: local forward alignment (Forward), perfect matching (PerfMatch), and edge cover ma</context>
<context position="21603" citStr="(2005)" startWordPosition="3405" endWordPosition="3405">7.2 NA EdgeCover 70.5 62.9 66.5 UpperBnd 85.0 84.0 84.0 Model Prec Rec F-score WordBL 45.6 44.8 45.1 Forward 64.3 47.8 54.8 Fi PerfMatch 73.1 56.9 64.0 CN EdgeCover 67.5 57.0 61.8 UpperBnd 85.0 84.0 84.0 Model Prec Rec F-score WordBL 45.6 44.8 45.1 Forward 69.9 60.7 65.0 Fi PerfMatch 80.4 48.1 60.2 EdgeCover 69.6 60.6 64.8 Arg UpperBnd 85.0 84.0 84.0 Table 1: Model comparison using intersective alignments (development set) roles. To gauge the extent to which alignment errors are harmful, we present results both on intersective and manual alignments. Upper bound and baseline In Padó and Lapata (2005), we assessed the feasibility of semantic role projection by measuring how well annotators agreed on identifying roles and their spans. We obtained an inter-annotator agreement of 0.84 (F-score), which can serve as an upper bound for the projection task. As a baseline, we use a simple word-based model (WordBL) from the same study. The units of this model are words, and the span of a projected role is the union of all target terminals aligned to a terminal of the source role. 6 Results Development set Our results on the development set are summarised in Table 1. We show how performance varies f</context>
<context position="29242" citStr="(2005)" startWordPosition="4618" endWordPosition="4618">ample, Xia and McCord (2004) exploit constituent alignment for rearranging sentences in the source language so as to make their word or6Our results on the test set are slightly higher in comparison to the development set. The fluctuation reflects natural randomness in the partitioning of our corpus. 7See http://www.keenage.com/zhiwang/e_ zhiwang.html. 1167 der similar to that of the target language. They learn tree reordering rules by aligning constituents heuristically using a naive local optimisation procedure analogous to forward alignment. A similar approach is described in Collins et al. (2005); however, the rules are manually specified and the constituent alignment step reduces to inspection of the source-target sentence pairs. The global optimisation models presented in this paper could be easily employed for the reordering task common to both approaches. Other approaches treat rewrite rules not as a preprocessing step (e.g., for reordering source strings), but as a part of the translation model itself (Gildea, 2003; Gildea, 2004). Constituent alignments are learnt by estimating the probability of tree transformations, such as node deletions, insertions, and reorderings. These mod</context>
</contexts>
<marker>2005</marker>
<rawString>X. Carreras, L. Màrquez, eds. 2005. Proceedings of the CoNLL shared task: Semantic role labelling, Boston, MA, 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
<author>P Koehn</author>
<author>I Kuˇcerová</author>
</authors>
<title>Clause restructuring for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd ACL, 531–540,</booktitle>
<location>Ann Arbor, MI.</location>
<marker>Collins, Koehn, Kuˇcerová, 2005</marker>
<rawString>M. Collins, P. Koehn, I. Kuˇcerová. 2005. Clause restructuring for statistical machine translation. In Proceedings of the 43rd ACL, 531–540, Ann Arbor, MI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
</authors>
<title>Three generative, lexicalised models for statistical parsing.</title>
<date>1997</date>
<booktitle>In Proceedings of the ACL/EACL, 16– 23,</booktitle>
<location>Madrid,</location>
<marker>Collins, 1997</marker>
<rawString>M. Collins. 1997. Three generative, lexicalised models for statistical parsing. In Proceedings of the ACL/EACL, 16– 23, Madrid, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Dubey</author>
</authors>
<title>What to do when lexicalization fails: parsing German with suffix analysis and smoothing.</title>
<date>2005</date>
<journal>Acta Informatica,</journal>
<booktitle>In Proceedings of the 43rd ACL, 314–321,</booktitle>
<volume>34</volume>
<issue>2</issue>
<location>Ann Arbor, MI.</location>
<marker>Dubey, 2005</marker>
<rawString>A. Dubey. 2005. What to do when lexicalization fails: parsing German with suffix analysis and smoothing. In Proceedings of the 43rd ACL, 314–321, Ann Arbor, MI. T. Eiter, H. Mannila. 1997. Distance measures for point sets and their computation. Acta Informatica, 34(2):109–133.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C J Fillmore</author>
<author>C R Johnson</author>
<author>M R Petruck</author>
</authors>
<title>Background to FrameNet.</title>
<date>2003</date>
<journal>International Journal of Lexicography,</journal>
<pages>16--235</pages>
<contexts>
<context position="5142" citStr="Fillmore et al., 2003" startWordPosition="747" endWordPosition="750">describe the task of rolesemantic projection and the syntax-based framework introduced in Padó and Lapata (2005). Section 3 explains how semantic role projection can be modelled with minimum weight edge covers in bipartite graphs. Section 4 presents our tree pruning strategy. We present our evaluation framework and results in Section 5. A discussion of related and future work concludes the paper. 2 Cross-lingual Semantic Role projection Semantic role projection is illustrated in Figure 1 using English and German as the source-target language pair. We assume a FrameNet-style semantic analysis (Fillmore et al., 2003). In this paradigm, the semantics of predicates and their arguments are described in terms of frames, conceptual structures which model prototypical situations. The English sentence Kim promised to be on time in Figure 1 is an instance of the COMMITMENT frame. In this particular example, the frame introduces two roles, i.e., SPEAKER (Kim) and MESSAGE (to be on time). Other possible, though unrealised, roles are ADDRESSEE, MESSAGE, and TOPIC. The COMMITMENT frame can be introduced by promise and several other verbs and nouns such as consent or threat. We also assume that frame-semantic annotati</context>
</contexts>
<marker>Fillmore, Johnson, Petruck, 2003</marker>
<rawString>C. J. Fillmore, C. R. Johnson, M. R. Petruck. 2003. Background to FrameNet. International Journal of Lexicography, 16:235–250.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M L Fredman</author>
<author>R E Tarjan</author>
</authors>
<title>Fibonacci heaps and their uses in improved network optimization algorithms.</title>
<date>1987</date>
<journal>Journal of the ACM,</journal>
<volume>34</volume>
<issue>3</issue>
<contexts>
<context position="14879" citStr="Fredman and Tarjan, 1987" startWordPosition="2356" endWordPosition="2359">dels of constituent alignment than edge covers. Being bijective, the resulting alignments cannot model splitting or merging operations at all. Insertions and deletions can be modelled only indirectly by aligning nodes in the larger partition to dummy nodes on the other side (see the source side in Figure 2 where nodes (3) and (6) are aligned to (d)). Section 5 assesses if these modelling limitations impact the quality of the resulting alignments. Algorithms Minimum weight perfect matchings in bipartite graphs can be computed efficiently in cubic time using algorithms for network optimisation (Fredman and Tarjan, 1987; time O(|Us|2 log|Us|+|Us|2|Ut|)) or algorithms for the equivalent linear assignment problem (Jonker and Volgenant, 1987; time O(max(|Us|,|Ut|)3)). Their complexity is a linear factor slower than the quadratic runtime of the local optimisation methods presented in Section 2. The computation of (general) edge covers has been investigated by Eiter and Mannila (1997) in the context of distance metrics for point sets. They show that edge covers can be reduced to minimum weight perfect matchings of an auxiliary bipartite graph with two partitions of size |Us |+ |Ut|. This allows the computation of</context>
</contexts>
<marker>Fredman, Tarjan, 1987</marker>
<rawString>M. L. Fredman, R. E. Tarjan. 1987. Fibonacci heaps and their uses in improved network optimization algorithms. Journal of the ACM, 34(3):596–615.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Fung</author>
<author>B Chen</author>
</authors>
<title>BiFrameNet: Bilingual frame semantics resources construction by cross-lingual induction.</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th COLING,</booktitle>
<location>931–935, Geneva, Switzerland.</location>
<contexts>
<context position="28035" citStr="Fung and Chen (2004)" startWordPosition="4435" endWordPosition="4438">filters and graph-based algorithms eliminate alignment noise to a large extent. Analysis of the models’ output revealed that the remaining errors are mostly due to incorrect parses (none of the parsers employed in this work were trained on the Europarl corpus) but also to modelling deficiencies. Recall from Section 3 that our global models cannot currently capture one-to-zero correspondences, i.e., deletions and insertions. 7 Related work Previous work has primarily focused on the projection of grammatical (Yarowsky and Ngai, 2001) and syntactic information (Hwa et al., 2002). An exception is Fung and Chen (2004), who also attempt to induce FrameNet-style annotations in Chinese. Their method maps English FrameNet entries to concepts listed in HowNet7, an on-line ontology for Chinese, without using parallel texts. The present work extends our earlier projection framework (Padó and Lapata, 2005) by proposing global methods for automatic constituent alignment. Although our models are evaluated on the semantic role projection task, we believe they also show promise in the context of statistical machine translation. Especially for systems that use syntactic information to enhance translation quality. For e</context>
</contexts>
<marker>Fung, Chen, 2004</marker>
<rawString>P. Fung, B. Chen. 2004. BiFrameNet: Bilingual frame semantics resources construction by cross-lingual induction. In Proceedings of the 20th COLING, 931–935, Geneva, Switzerland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Gildea</author>
<author>D Jurafsky</author>
</authors>
<title>Automatic labeling of semantic roles.</title>
<date>2002</date>
<journal>Computational Linguistics,</journal>
<volume>28</volume>
<issue>3</issue>
<contexts>
<context position="3093" citStr="Gildea and Jurafsky, 2002" startWordPosition="444" endWordPosition="447">nd demonstrate that annotations can be adequately projected for parts of speech (Yarowsky and Ngai, 2001; Hi and Hwa, 2005), chunks (Yarowsky and Ngai, 2001), and dependencies (Hwa et al., 2002). In previous work (Padó and Lapata, 2005) we considered the annotation projection of semantic roles conveyed by sentential constituents such as AGENT, PATIENT, or INSTRUMENT. Semantic roles exhibit a high degree of parallelism across languages (Boas, 2005) and thus appear amenable to projection. Furthermore, corpora labelled with semantic role information can be used to train shallow semantic parsers (Gildea and Jurafsky, 2002), which could in turn benefit applications in need of broad-coverage semantic analysis. Examples include question answering, information extraction, and notably machine translation. Our experiments concentrated primarily on the first projection step, i.e., establishing the right level of linguistic analysis for effecting projection. We showed that projection schemes based on constituent alignments significantly outperform schemes that rely exclusively on word alignments. A local optimisation strategy was used to find constituent alignments, while relying on a simple filtering technique to hand</context>
</contexts>
<marker>Gildea, Jurafsky, 2002</marker>
<rawString>D. Gildea, D. Jurafsky. 2002. Automatic labeling of semantic roles. Computational Linguistics, 28(3):245–288.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Gildea</author>
</authors>
<title>Loosely tree-based alignment for machine translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st ACL,</booktitle>
<location>80–87, Sapporo, Japan.</location>
<contexts>
<context position="29674" citStr="Gildea, 2003" startWordPosition="4683" endWordPosition="4684">ing rules by aligning constituents heuristically using a naive local optimisation procedure analogous to forward alignment. A similar approach is described in Collins et al. (2005); however, the rules are manually specified and the constituent alignment step reduces to inspection of the source-target sentence pairs. The global optimisation models presented in this paper could be easily employed for the reordering task common to both approaches. Other approaches treat rewrite rules not as a preprocessing step (e.g., for reordering source strings), but as a part of the translation model itself (Gildea, 2003; Gildea, 2004). Constituent alignments are learnt by estimating the probability of tree transformations, such as node deletions, insertions, and reorderings. These models have a greater expressive power than our edge cover models; however, this implies that approximations are often used to make computation feasible. 8 Conclusions In this paper, we have proposed a novel method for obtaining constituent alignments between parallel sentences and have shown that it is useful for semantic role projection. A key aspect of our approach is the formalisation of constituent alignment as the search for </context>
</contexts>
<marker>Gildea, 2003</marker>
<rawString>D. Gildea. 2003. Loosely tree-based alignment for machine translation. In Proceedings of the 41st ACL, 80–87, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Gildea</author>
</authors>
<title>Dependencies vs. constituents for treebased alignment.</title>
<date>2004</date>
<booktitle>In Proceedings of the EMNLP,</booktitle>
<pages>214--221</pages>
<location>Barcelona,</location>
<contexts>
<context position="29689" citStr="Gildea, 2004" startWordPosition="4685" endWordPosition="4686">ligning constituents heuristically using a naive local optimisation procedure analogous to forward alignment. A similar approach is described in Collins et al. (2005); however, the rules are manually specified and the constituent alignment step reduces to inspection of the source-target sentence pairs. The global optimisation models presented in this paper could be easily employed for the reordering task common to both approaches. Other approaches treat rewrite rules not as a preprocessing step (e.g., for reordering source strings), but as a part of the translation model itself (Gildea, 2003; Gildea, 2004). Constituent alignments are learnt by estimating the probability of tree transformations, such as node deletions, insertions, and reorderings. These models have a greater expressive power than our edge cover models; however, this implies that approximations are often used to make computation feasible. 8 Conclusions In this paper, we have proposed a novel method for obtaining constituent alignments between parallel sentences and have shown that it is useful for semantic role projection. A key aspect of our approach is the formalisation of constituent alignment as the search for a minimum weigh</context>
</contexts>
<marker>Gildea, 2004</marker>
<rawString>D. Gildea. 2004. Dependencies vs. constituents for treebased alignment. In Proceedings of the EMNLP, 214–221, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Hi</author>
<author>R Hwa</author>
</authors>
<title>A backoff model for bootstrapping resources for non-english languages.</title>
<date>2005</date>
<booktitle>In Proceedings of the HLT/EMNLP,</booktitle>
<location>851–858, Vancouver, BC.</location>
<contexts>
<context position="2590" citStr="Hi and Hwa, 2005" startWordPosition="369" endWordPosition="372">its of projection; these are typically words but can also be chunks or syntactic constituents; (b) inducing alignments between the projection units and projecting annotations along these alignments; (c) reducing the amount of noise in the projected annotations, often due to errors and omissions in the word alignment. The degree to which analyses are parallel across languages is crucial for the success of projection approaches. A number of recent studies rely on this notion of parallelism and demonstrate that annotations can be adequately projected for parts of speech (Yarowsky and Ngai, 2001; Hi and Hwa, 2005), chunks (Yarowsky and Ngai, 2001), and dependencies (Hwa et al., 2002). In previous work (Padó and Lapata, 2005) we considered the annotation projection of semantic roles conveyed by sentential constituents such as AGENT, PATIENT, or INSTRUMENT. Semantic roles exhibit a high degree of parallelism across languages (Boas, 2005) and thus appear amenable to projection. Furthermore, corpora labelled with semantic role information can be used to train shallow semantic parsers (Gildea and Jurafsky, 2002), which could in turn benefit applications in need of broad-coverage semantic analysis. Examples </context>
<context position="9827" citStr="Hi and Hwa, 2005" startWordPosition="1494" endWordPosition="1497">ituents, the local models can disregard important linguistic information, thus potentially leading to suboptimal results. We investigate this possibility by proposing well-understood global optimisation models which suitably constrain the resulting alignments. Besides matching constituents reliably, poor word alignments are a major stumbling block for achieving accurate projections. Previous research addresses this problem in a post-processing step, by reestimating parameter values (Yarowsky and Ngai, 2001), by applying transformation rules (Hwa et al., 2002), by using manually labelled data (Hi and Hwa, 2005), or by relying on linguistic criteria (Padó and Lapata, 2005). In this paper, we present a novel filtering technique based on tree pruning which removes extraneous constituents in a preprocessing stage, thereby disassociating filtering from the alignment computation. In the remainder of this paper, we present the details of our global optimisation and filtering techniques. We only consider constituent-based models, since these obtained the best performance in our previous study (Padó and Lapata, 2005). 3 Globally optimal constituent alignment We model constituent alignment as a minimum weight</context>
</contexts>
<marker>Hi, Hwa, 2005</marker>
<rawString>C. Hi, R. Hwa. 2005. A backoff model for bootstrapping resources for non-english languages. In Proceedings of the HLT/EMNLP, 851–858, Vancouver, BC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Hwa</author>
<author>P Resnik</author>
<author>A Weinberg</author>
<author>O Kolak</author>
</authors>
<title>Evaluation of translational correspondence using annotation projection.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th ACL,</booktitle>
<location>392–399, Philadelphia, PA.</location>
<contexts>
<context position="2661" citStr="Hwa et al., 2002" startWordPosition="381" endWordPosition="384">syntactic constituents; (b) inducing alignments between the projection units and projecting annotations along these alignments; (c) reducing the amount of noise in the projected annotations, often due to errors and omissions in the word alignment. The degree to which analyses are parallel across languages is crucial for the success of projection approaches. A number of recent studies rely on this notion of parallelism and demonstrate that annotations can be adequately projected for parts of speech (Yarowsky and Ngai, 2001; Hi and Hwa, 2005), chunks (Yarowsky and Ngai, 2001), and dependencies (Hwa et al., 2002). In previous work (Padó and Lapata, 2005) we considered the annotation projection of semantic roles conveyed by sentential constituents such as AGENT, PATIENT, or INSTRUMENT. Semantic roles exhibit a high degree of parallelism across languages (Boas, 2005) and thus appear amenable to projection. Furthermore, corpora labelled with semantic role information can be used to train shallow semantic parsers (Gildea and Jurafsky, 2002), which could in turn benefit applications in need of broad-coverage semantic analysis. Examples include question answering, information extraction, and notably machine</context>
<context position="9775" citStr="Hwa et al., 2002" startWordPosition="1484" endWordPosition="1487">s). In fact, by allowing any alignment between constituents, the local models can disregard important linguistic information, thus potentially leading to suboptimal results. We investigate this possibility by proposing well-understood global optimisation models which suitably constrain the resulting alignments. Besides matching constituents reliably, poor word alignments are a major stumbling block for achieving accurate projections. Previous research addresses this problem in a post-processing step, by reestimating parameter values (Yarowsky and Ngai, 2001), by applying transformation rules (Hwa et al., 2002), by using manually labelled data (Hi and Hwa, 2005), or by relying on linguistic criteria (Padó and Lapata, 2005). In this paper, we present a novel filtering technique based on tree pruning which removes extraneous constituents in a preprocessing stage, thereby disassociating filtering from the alignment computation. In the remainder of this paper, we present the details of our global optimisation and filtering techniques. We only consider constituent-based models, since these obtained the best performance in our previous study (Padó and Lapata, 2005). 3 Globally optimal constituent alignmen</context>
<context position="27997" citStr="Hwa et al., 2002" startWordPosition="4428" endWordPosition="4431">uraging result indicating that our filters and graph-based algorithms eliminate alignment noise to a large extent. Analysis of the models’ output revealed that the remaining errors are mostly due to incorrect parses (none of the parsers employed in this work were trained on the Europarl corpus) but also to modelling deficiencies. Recall from Section 3 that our global models cannot currently capture one-to-zero correspondences, i.e., deletions and insertions. 7 Related work Previous work has primarily focused on the projection of grammatical (Yarowsky and Ngai, 2001) and syntactic information (Hwa et al., 2002). An exception is Fung and Chen (2004), who also attempt to induce FrameNet-style annotations in Chinese. Their method maps English FrameNet entries to concepts listed in HowNet7, an on-line ontology for Chinese, without using parallel texts. The present work extends our earlier projection framework (Padó and Lapata, 2005) by proposing global methods for automatic constituent alignment. Although our models are evaluated on the semantic role projection task, we believe they also show promise in the context of statistical machine translation. Especially for systems that use syntactic information</context>
</contexts>
<marker>Hwa, Resnik, Weinberg, Kolak, 2002</marker>
<rawString>R. Hwa, P. Resnik, A. Weinberg, O. Kolak. 2002. Evaluation of translational correspondence using annotation projection. In Proceedings of the 40th ACL, 392–399, Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Jonker</author>
<author>T Volgenant</author>
</authors>
<title>A shortest augmenting path algorithm for dense and sparse linear assignment problems.</title>
<date>1987</date>
<journal>Computing,</journal>
<pages>38--325</pages>
<contexts>
<context position="15000" citStr="Jonker and Volgenant, 1987" startWordPosition="2371" endWordPosition="2374">ging operations at all. Insertions and deletions can be modelled only indirectly by aligning nodes in the larger partition to dummy nodes on the other side (see the source side in Figure 2 where nodes (3) and (6) are aligned to (d)). Section 5 assesses if these modelling limitations impact the quality of the resulting alignments. Algorithms Minimum weight perfect matchings in bipartite graphs can be computed efficiently in cubic time using algorithms for network optimisation (Fredman and Tarjan, 1987; time O(|Us|2 log|Us|+|Us|2|Ut|)) or algorithms for the equivalent linear assignment problem (Jonker and Volgenant, 1987; time O(max(|Us|,|Ut|)3)). Their complexity is a linear factor slower than the quadratic runtime of the local optimisation methods presented in Section 2. The computation of (general) edge covers has been investigated by Eiter and Mannila (1997) in the context of distance metrics for point sets. They show that edge covers can be reduced to minimum weight perfect matchings of an auxiliary bipartite graph with two partitions of size |Us |+ |Ut|. This allows the computation of general minimum weight edge covers in time O((|Us |+ |Ut|)3). 4 Filtering via Tree Pruning We introduce two filtering te</context>
</contexts>
<marker>Jonker, Volgenant, 1987</marker>
<rawString>R. Jonker, T. Volgenant. 1987. A shortest augmenting path algorithm for dense and sparse linear assignment problems. Computing, 38:325–340.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>F J Och</author>
<author>D Marcu</author>
</authors>
<title>Statistical phrase-based translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the HLT/NAACL,</booktitle>
<pages>127--133</pages>
<location>Edmonton, AL.</location>
<contexts>
<context position="18671" citStr="Koehn et al., 2003" startWordPosition="2942" endWordPosition="2945">5). The sentences were automatically parsed (using Collin’s 1997 parser for English and Dubey’s 2005 parser for German), and manually annotated with FrameNet-like semantic roles (see Padó and Lapata 2005 for details.) Word alignments were computed with the GIZA++ toolkit (Och and Ney, 2003), using the 3The corpus can be downloaded from http://www. coli.uni-saarland.de/~pado/projection/. entire English-German Europarl bitext as training data (20M words). We used the GIZA++ default settings to induce alignments for both directions (source-target, target-source). Following common practise in MT (Koehn et al., 2003), we considered only their intersection (bidirectional alignments are known to exhibit high precision). We also produced manual word alignments for all sentences in our corpus, using the GIZA++ alignments as a starting point and following the Blinker annotation guidelines (Melamed, 1998). Method and parameter choice The constituent alignment models we present are unsupervised in that they do not require labelled data for inferring correct alignments. Nevertheless, our models have three parameters: (a) the similarity measure for identifying semantically equivalent constituents; (b) the filterin</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>P. Koehn, F. J. Och, D. Marcu. 2003. Statistical phrase-based translation. In Proceedings of the HLT/NAACL, 127–133, Edmonton, AL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
</authors>
<title>Europarl: A parallel corpus for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proceedings of the MT Summit X,</booktitle>
<location>Phuket, Thailand.</location>
<contexts>
<context position="18054" citStr="Koehn, 2005" startWordPosition="2859" endWordPosition="2860">een a constituent and its predicate. This definition covers long-distance dependencies such as control constructions for verbs, or support constructions for nouns and adjectives, and can be extended slightly to accommodate coordination. This argument-based filter reduces target trees to a set of likely arguments. In the example in Figure 3, all tree nodes are removed except Kim and pünktlich zu kommen. 5 Evaluation Set-up Data For evaluation, we used the parallel corpus3 from our earlier work (Padó and Lapata, 2005). It consists of 1,000 English-German sentence pairs from the Europarl corpus (Koehn, 2005). The sentences were automatically parsed (using Collin’s 1997 parser for English and Dubey’s 2005 parser for German), and manually annotated with FrameNet-like semantic roles (see Padó and Lapata 2005 for details.) Word alignments were computed with the GIZA++ toolkit (Och and Ney, 2003), using the 3The corpus can be downloaded from http://www. coli.uni-saarland.de/~pado/projection/. entire English-German Europarl bitext as training data (20M words). We used the GIZA++ default settings to induce alignments for both directions (source-target, target-source). Following common practise in MT (Ko</context>
</contexts>
<marker>Koehn, 2005</marker>
<rawString>P. Koehn. 2005. Europarl: A parallel corpus for statistical machine translation. In Proceedings of the MT Summit X, Phuket, Thailand.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I D Melamed</author>
</authors>
<title>Manual annotation of translational equivalence: The Blinker project.</title>
<date>1998</date>
<tech>Technical Report IRCS TR #98-07,</tech>
<institution>IRCS, University of Pennsylvania,</institution>
<contexts>
<context position="18959" citStr="Melamed, 1998" startWordPosition="2986" endWordPosition="2987">using the 3The corpus can be downloaded from http://www. coli.uni-saarland.de/~pado/projection/. entire English-German Europarl bitext as training data (20M words). We used the GIZA++ default settings to induce alignments for both directions (source-target, target-source). Following common practise in MT (Koehn et al., 2003), we considered only their intersection (bidirectional alignments are known to exhibit high precision). We also produced manual word alignments for all sentences in our corpus, using the GIZA++ alignments as a starting point and following the Blinker annotation guidelines (Melamed, 1998). Method and parameter choice The constituent alignment models we present are unsupervised in that they do not require labelled data for inferring correct alignments. Nevertheless, our models have three parameters: (a) the similarity measure for identifying semantically equivalent constituents; (b) the filtering procedure for removing noise in the data (e.g., wrong alignments); and (c) the decision procedure for projection. We retained the similarity measure introduced in Padó and Lapata (2005) which computes the overlap between a source constituent and its candidate projection, in both direct</context>
</contexts>
<marker>Melamed, 1998</marker>
<rawString>I. D. Melamed. 1998. Manual annotation of translational equivalence: The Blinker project. Technical Report IRCS TR #98-07, IRCS, University of Pennsylvania, 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="18343" citStr="Och and Ney, 2003" startWordPosition="2900" endWordPosition="2903">s to a set of likely arguments. In the example in Figure 3, all tree nodes are removed except Kim and pünktlich zu kommen. 5 Evaluation Set-up Data For evaluation, we used the parallel corpus3 from our earlier work (Padó and Lapata, 2005). It consists of 1,000 English-German sentence pairs from the Europarl corpus (Koehn, 2005). The sentences were automatically parsed (using Collin’s 1997 parser for English and Dubey’s 2005 parser for German), and manually annotated with FrameNet-like semantic roles (see Padó and Lapata 2005 for details.) Word alignments were computed with the GIZA++ toolkit (Och and Ney, 2003), using the 3The corpus can be downloaded from http://www. coli.uni-saarland.de/~pado/projection/. entire English-German Europarl bitext as training data (20M words). We used the GIZA++ default settings to induce alignments for both directions (source-target, target-source). Following common practise in MT (Koehn et al., 2003), we considered only their intersection (bidirectional alignments are known to exhibit high precision). We also produced manual word alignments for all sentences in our corpus, using the GIZA++ alignments as a starting point and following the Blinker annotation guidelines</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>F. J. Och, H. Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19–52.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Padó</author>
<author>M Lapata</author>
</authors>
<title>Cross-lingual projection of role-semantic information.</title>
<date>2005</date>
<booktitle>In Proceedings of the HLT/EMNLP,</booktitle>
<pages>859--866</pages>
<location>Vancouver, BC.</location>
<contexts>
<context position="2703" citStr="Padó and Lapata, 2005" startWordPosition="388" endWordPosition="391">alignments between the projection units and projecting annotations along these alignments; (c) reducing the amount of noise in the projected annotations, often due to errors and omissions in the word alignment. The degree to which analyses are parallel across languages is crucial for the success of projection approaches. A number of recent studies rely on this notion of parallelism and demonstrate that annotations can be adequately projected for parts of speech (Yarowsky and Ngai, 2001; Hi and Hwa, 2005), chunks (Yarowsky and Ngai, 2001), and dependencies (Hwa et al., 2002). In previous work (Padó and Lapata, 2005) we considered the annotation projection of semantic roles conveyed by sentential constituents such as AGENT, PATIENT, or INSTRUMENT. Semantic roles exhibit a high degree of parallelism across languages (Boas, 2005) and thus appear amenable to projection. Furthermore, corpora labelled with semantic role information can be used to train shallow semantic parsers (Gildea and Jurafsky, 2002), which could in turn benefit applications in need of broad-coverage semantic analysis. Examples include question answering, information extraction, and notably machine translation. Our experiments concentrated</context>
<context position="4632" citStr="Padó and Lapata (2005)" startWordPosition="667" endWordPosition="670">utational Linguistics and 44th Annual Meeting of the ACL, pages 1161–1168, Sydney, July 2006. c�2006 Association for Computational Linguistics efficiently yields constituent alignments that are globally optimal. Second, we propose tree pruning as a general noise reduction strategy, which exploits both structural and linguistic information to enable projection. Furthermore, we quantitatively assess the impact of noise on the task by evaluating both on automatic and manual word alignments. In Section 2, we describe the task of rolesemantic projection and the syntax-based framework introduced in Padó and Lapata (2005). Section 3 explains how semantic role projection can be modelled with minimum weight edge covers in bipartite graphs. Section 4 presents our tree pruning strategy. We present our evaluation framework and results in Section 5. A discussion of related and future work concludes the paper. 2 Cross-lingual Semantic Role projection Semantic role projection is illustrated in Figure 1 using English and German as the source-target language pair. We assume a FrameNet-style semantic analysis (Fillmore et al., 2003). In this paradigm, the semantics of predicates and their arguments are described in terms</context>
<context position="7408" citStr="Padó and Lapata (2005)" startWordPosition="1124" endWordPosition="1127">Constituent alignments are obtained in two steps. First, a real-valued function sim : Us x Ut —* R estimates pairwise similarities between source and target units. To make our model robust to alignment noise, we use only content words to compute the similarity function. Next, a decision procedure uses the similarity function to determine the set of semantically equivalent, i.e., aligned units A C_ Us xUt. Once A is known, semantic projection reduces to transferring the semantic roles from the source units onto their aligned target counterparts: rolet(r) = {ut |]us E roles(r) : (us,ut) E A} In Padó and Lapata (2005), we evaluated two main parameters within this framework: (a) the choice of linguistic units and (b) methods for computing semantic alignments. Our results revealed that constituent-based models outperformed wordbased ones by a wide margin (0.65 Fscore vs. 0.46), thus demonstrating the importance of bracketing in amending errors and omissions in the automatic word alignment. We also compared two simplistic alignment schemes, backward alignment and forward alignment. The first scheme aligns each target constituent to its most similar source constituent, whereas the second (Af) aligns each sourc</context>
<context position="9889" citStr="Padó and Lapata, 2005" startWordPosition="1504" endWordPosition="1507">tic information, thus potentially leading to suboptimal results. We investigate this possibility by proposing well-understood global optimisation models which suitably constrain the resulting alignments. Besides matching constituents reliably, poor word alignments are a major stumbling block for achieving accurate projections. Previous research addresses this problem in a post-processing step, by reestimating parameter values (Yarowsky and Ngai, 2001), by applying transformation rules (Hwa et al., 2002), by using manually labelled data (Hi and Hwa, 2005), or by relying on linguistic criteria (Padó and Lapata, 2005). In this paper, we present a novel filtering technique based on tree pruning which removes extraneous constituents in a preprocessing stage, thereby disassociating filtering from the alignment computation. In the remainder of this paper, we present the details of our global optimisation and filtering techniques. We only consider constituent-based models, since these obtained the best performance in our previous study (Padó and Lapata, 2005). 3 Globally optimal constituent alignment We model constituent alignment as a minimum weight bipartite edge cover problem. A bipartite graph is a graph G </context>
<context position="15842" citStr="Padó and Lapata, 2005" startWordPosition="2505" endWordPosition="2508">y Eiter and Mannila (1997) in the context of distance metrics for point sets. They show that edge covers can be reduced to minimum weight perfect matchings of an auxiliary bipartite graph with two partitions of size |Us |+ |Ut|. This allows the computation of general minimum weight edge covers in time O((|Us |+ |Ut|)3). 4 Filtering via Tree Pruning We introduce two filtering techniques which effectively remove constituents from source and target trees before alignment takes place. Tree pruning as a preprocessing step is more general and more efficient than our original post-processing filter (Padó and Lapata, 2005) which was embedded into the similarity function. Not only does tree pruning not interfere with the similarity function but also reduces the size of the graph, thus speeding up the algorithms discussed in the previous section. We present two instantiations of tree pruning: word-based filtering, which subsumes our earlier method, and argument-based filtering, which eliminates unlikely argument candidates. Word-based filtering This technique removes terminal nodes from parse trees according to certain linguistic or alignment-based criteria. We apply two word-based filters in our experiments. The</context>
<context position="17963" citStr="Padó and Lapata, 2005" startWordPosition="2843" endWordPosition="2846">ded that (a) they do not dominate the predicate themselves and (b) there is no sentence boundary between a constituent and its predicate. This definition covers long-distance dependencies such as control constructions for verbs, or support constructions for nouns and adjectives, and can be extended slightly to accommodate coordination. This argument-based filter reduces target trees to a set of likely arguments. In the example in Figure 3, all tree nodes are removed except Kim and pünktlich zu kommen. 5 Evaluation Set-up Data For evaluation, we used the parallel corpus3 from our earlier work (Padó and Lapata, 2005). It consists of 1,000 English-German sentence pairs from the Europarl corpus (Koehn, 2005). The sentences were automatically parsed (using Collin’s 1997 parser for English and Dubey’s 2005 parser for German), and manually annotated with FrameNet-like semantic roles (see Padó and Lapata 2005 for details.) Word alignments were computed with the GIZA++ toolkit (Och and Ney, 2003), using the 3The corpus can be downloaded from http://www. coli.uni-saarland.de/~pado/projection/. entire English-German Europarl bitext as training data (20M words). We used the GIZA++ default settings to induce alignme</context>
<context position="19458" citStr="Padó and Lapata (2005)" startWordPosition="3057" endWordPosition="3060">our corpus, using the GIZA++ alignments as a starting point and following the Blinker annotation guidelines (Melamed, 1998). Method and parameter choice The constituent alignment models we present are unsupervised in that they do not require labelled data for inferring correct alignments. Nevertheless, our models have three parameters: (a) the similarity measure for identifying semantically equivalent constituents; (b) the filtering procedure for removing noise in the data (e.g., wrong alignments); and (c) the decision procedure for projection. We retained the similarity measure introduced in Padó and Lapata (2005) which computes the overlap between a source constituent and its candidate projection, in both directions. Let y(cs) and y(ct) denote the yield of a source and target constituent, respectively, and al(T) the union of all word alignments for a token set T: sim(cs,ct) = |y(ct)∩al(y(cs)) ||y(cs)∩al(y(ct))| We examined three filtering procedures (see Section 4): removing non-aligned words (NA), removing non-content words (NC), and removing unlikely arguments (Arg). These were combined with three decision procedures: local forward alignment (Forward), perfect matching (PerfMatch), and edge cover ma</context>
<context position="21603" citStr="Padó and Lapata (2005)" startWordPosition="3401" endWordPosition="3405">atch 73.3 62.1 67.2 NA EdgeCover 70.5 62.9 66.5 UpperBnd 85.0 84.0 84.0 Model Prec Rec F-score WordBL 45.6 44.8 45.1 Forward 64.3 47.8 54.8 Fi PerfMatch 73.1 56.9 64.0 CN EdgeCover 67.5 57.0 61.8 UpperBnd 85.0 84.0 84.0 Model Prec Rec F-score WordBL 45.6 44.8 45.1 Forward 69.9 60.7 65.0 Fi PerfMatch 80.4 48.1 60.2 EdgeCover 69.6 60.6 64.8 Arg UpperBnd 85.0 84.0 84.0 Table 1: Model comparison using intersective alignments (development set) roles. To gauge the extent to which alignment errors are harmful, we present results both on intersective and manual alignments. Upper bound and baseline In Padó and Lapata (2005), we assessed the feasibility of semantic role projection by measuring how well annotators agreed on identifying roles and their spans. We obtained an inter-annotator agreement of 0.84 (F-score), which can serve as an upper bound for the projection task. As a baseline, we use a simple word-based model (WordBL) from the same study. The units of this model are words, and the span of a projected role is the union of all target terminals aligned to a terminal of the source role. 6 Results Development set Our results on the development set are summarised in Table 1. We show how performance varies f</context>
<context position="28321" citStr="Padó and Lapata, 2005" startWordPosition="4476" endWordPosition="4479">eficiencies. Recall from Section 3 that our global models cannot currently capture one-to-zero correspondences, i.e., deletions and insertions. 7 Related work Previous work has primarily focused on the projection of grammatical (Yarowsky and Ngai, 2001) and syntactic information (Hwa et al., 2002). An exception is Fung and Chen (2004), who also attempt to induce FrameNet-style annotations in Chinese. Their method maps English FrameNet entries to concepts listed in HowNet7, an on-line ontology for Chinese, without using parallel texts. The present work extends our earlier projection framework (Padó and Lapata, 2005) by proposing global methods for automatic constituent alignment. Although our models are evaluated on the semantic role projection task, we believe they also show promise in the context of statistical machine translation. Especially for systems that use syntactic information to enhance translation quality. For example, Xia and McCord (2004) exploit constituent alignment for rearranging sentences in the source language so as to make their word or6Our results on the test set are slightly higher in comparison to the development set. The fluctuation reflects natural randomness in the partitioning</context>
</contexts>
<marker>Padó, Lapata, 2005</marker>
<rawString>S. Padó, M. Lapata. 2005. Cross-lingual projection of role-semantic information. In Proceedings of the HLT/EMNLP, 859–866, Vancouver, BC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Xia</author>
<author>M McCord</author>
</authors>
<title>Improving a statistical MT system with automatically learned rewrite patterns.</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th COLING,</booktitle>
<location>508–514, Geneva, Switzerland.</location>
<contexts>
<context position="28664" citStr="Xia and McCord (2004)" startWordPosition="4528" endWordPosition="4531">so attempt to induce FrameNet-style annotations in Chinese. Their method maps English FrameNet entries to concepts listed in HowNet7, an on-line ontology for Chinese, without using parallel texts. The present work extends our earlier projection framework (Padó and Lapata, 2005) by proposing global methods for automatic constituent alignment. Although our models are evaluated on the semantic role projection task, we believe they also show promise in the context of statistical machine translation. Especially for systems that use syntactic information to enhance translation quality. For example, Xia and McCord (2004) exploit constituent alignment for rearranging sentences in the source language so as to make their word or6Our results on the test set are slightly higher in comparison to the development set. The fluctuation reflects natural randomness in the partitioning of our corpus. 7See http://www.keenage.com/zhiwang/e_ zhiwang.html. 1167 der similar to that of the target language. They learn tree reordering rules by aligning constituents heuristically using a naive local optimisation procedure analogous to forward alignment. A similar approach is described in Collins et al. (2005); however, the rules a</context>
</contexts>
<marker>Xia, McCord, 2004</marker>
<rawString>F. Xia, M. McCord. 2004. Improving a statistical MT system with automatically learned rewrite patterns. In Proceedings of the 20th COLING, 508–514, Geneva, Switzerland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Xue</author>
<author>M Palmer</author>
</authors>
<title>Calibrating features for semantic role labeling.</title>
<date>2004</date>
<booktitle>In Proceedings of the EMNLP,</booktitle>
<pages>88--94</pages>
<location>Barcelona,</location>
<contexts>
<context position="17086" citStr="Xue and Palmer, 2004" startWordPosition="2700" endWordPosition="2703">ent words, i.e., all words which are not adjectives, adverbs, verbs, or nouns, from the source and target sen1164 Figure 3: Filtering of unlikely arguments (predicate in boldface, potential arguments in boxes). tences (Padó and Lapata, 2005). We also use a novel filter which removes all words which remain unaligned in the automatic word alignment. Nonterminal nodes whose terminals are removed by these filters, are also pruned. Argument filtering Previous work in shallow semantic parsing has demonstrated that not all nodes in a tree are equally probable as semantic roles for a given predicate (Xue and Palmer, 2004). In fact, assuming a perfect parse, there is a “set of likely arguments”, to which almost all semantic roles roles should be assigned to. This set of likely arguments consists of all constituents which are a child of some ancestor of the predicate, provided that (a) they do not dominate the predicate themselves and (b) there is no sentence boundary between a constituent and its predicate. This definition covers long-distance dependencies such as control constructions for verbs, or support constructions for nouns and adjectives, and can be extended slightly to accommodate coordination. This ar</context>
</contexts>
<marker>Xue, Palmer, 2004</marker>
<rawString>N. Xue, M. Palmer. 2004. Calibrating features for semantic role labeling. In Proceedings of the EMNLP, 88–94, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Yarowsky</author>
<author>G Ngai</author>
</authors>
<title>Inducing multilingual text analysis tools via robust projection across aligned corpora.</title>
<date>2001</date>
<booktitle>In Proceedings of the HLT,</booktitle>
<pages>161--168</pages>
<location>San Diego, CA.</location>
<contexts>
<context position="2571" citStr="Yarowsky and Ngai, 2001" startWordPosition="365" endWordPosition="368">s: (a) determining the units of projection; these are typically words but can also be chunks or syntactic constituents; (b) inducing alignments between the projection units and projecting annotations along these alignments; (c) reducing the amount of noise in the projected annotations, often due to errors and omissions in the word alignment. The degree to which analyses are parallel across languages is crucial for the success of projection approaches. A number of recent studies rely on this notion of parallelism and demonstrate that annotations can be adequately projected for parts of speech (Yarowsky and Ngai, 2001; Hi and Hwa, 2005), chunks (Yarowsky and Ngai, 2001), and dependencies (Hwa et al., 2002). In previous work (Padó and Lapata, 2005) we considered the annotation projection of semantic roles conveyed by sentential constituents such as AGENT, PATIENT, or INSTRUMENT. Semantic roles exhibit a high degree of parallelism across languages (Boas, 2005) and thus appear amenable to projection. Furthermore, corpora labelled with semantic role information can be used to train shallow semantic parsers (Gildea and Jurafsky, 2002), which could in turn benefit applications in need of broad-coverage semantic </context>
<context position="9722" citStr="Yarowsky and Ngai, 2001" startWordPosition="1476" endWordPosition="1479"> node (3) in Figure 2, which is aligned to three source nodes). In fact, by allowing any alignment between constituents, the local models can disregard important linguistic information, thus potentially leading to suboptimal results. We investigate this possibility by proposing well-understood global optimisation models which suitably constrain the resulting alignments. Besides matching constituents reliably, poor word alignments are a major stumbling block for achieving accurate projections. Previous research addresses this problem in a post-processing step, by reestimating parameter values (Yarowsky and Ngai, 2001), by applying transformation rules (Hwa et al., 2002), by using manually labelled data (Hi and Hwa, 2005), or by relying on linguistic criteria (Padó and Lapata, 2005). In this paper, we present a novel filtering technique based on tree pruning which removes extraneous constituents in a preprocessing stage, thereby disassociating filtering from the alignment computation. In the remainder of this paper, we present the details of our global optimisation and filtering techniques. We only consider constituent-based models, since these obtained the best performance in our previous study (Padó and L</context>
<context position="27952" citStr="Yarowsky and Ngai, 2001" startWordPosition="4421" endWordPosition="4424">ecall (p &lt; 0.01), but not precision. This is an encouraging result indicating that our filters and graph-based algorithms eliminate alignment noise to a large extent. Analysis of the models’ output revealed that the remaining errors are mostly due to incorrect parses (none of the parsers employed in this work were trained on the Europarl corpus) but also to modelling deficiencies. Recall from Section 3 that our global models cannot currently capture one-to-zero correspondences, i.e., deletions and insertions. 7 Related work Previous work has primarily focused on the projection of grammatical (Yarowsky and Ngai, 2001) and syntactic information (Hwa et al., 2002). An exception is Fung and Chen (2004), who also attempt to induce FrameNet-style annotations in Chinese. Their method maps English FrameNet entries to concepts listed in HowNet7, an on-line ontology for Chinese, without using parallel texts. The present work extends our earlier projection framework (Padó and Lapata, 2005) by proposing global methods for automatic constituent alignment. Although our models are evaluated on the semantic role projection task, we believe they also show promise in the context of statistical machine translation. Especial</context>
</contexts>
<marker>Yarowsky, Ngai, 2001</marker>
<rawString>D. Yarowsky, G. Ngai. 2001. Inducing multilingual text analysis tools via robust projection across aligned corpora. In Proceedings of the HLT, 161–168, San Diego, CA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>