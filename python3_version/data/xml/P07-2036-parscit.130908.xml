<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.026579">
<title confidence="0.993618">
Extracting Word Sets with Non-Taxonomical Relation
</title>
<author confidence="0.976886">
Eiko Yamamoto Hitoshi Isahara
</author>
<affiliation confidence="0.985833">
Computational Linguistics Group
National Institute of Information and Communications Technology
</affiliation>
<address confidence="0.977846">
3-5 Hikaridai, Seika-cho, Soraku-gun, Kyoto 619-0289, Japan
</address>
<email confidence="0.9994">
{eiko, isahara}@nict.go.jp
</email>
<sectionHeader confidence="0.995648" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999976947368421">
At least two kinds of relations exist among
related words: taxonomical relations and
thematic relations. Both relations identify
related words useful to language under-
standing and generation, information re-
trieval, and so on. However, although
words with taxonomical relations are easy
to identify from linguistic resources such as
dictionaries and thesauri, words with the-
matic relations are difficult to identify be-
cause they are rarely maintained in linguis-
tic resources. In this paper, we sought to
extract thematically (non-taxonomically)
related word sets among words in docu-
ments by employing case-marking particles
derived from syntactic analysis. We then
verified the usefulness of word sets with
non-taxonomical relation that seems to be a
thematic relation for information retrieval.
</bodyText>
<sectionHeader confidence="0.998357" genericHeader="introduction">
1. Introduction
</sectionHeader>
<bodyText confidence="0.999931714285714">
Related word sets are useful linguistic resources
for language understanding and generation, infor-
mation retrieval, and so on. In previous research on
natural language processing, many methodologies
for extracting various relations from corpora have
been developed, such as the “is-a” relation (Hearst
1992), “part-of” relation (Berland and Charniak
1999), causal relation (Girju 2003), and entailment
relation (Geffet and Dagan 2005).
Related words can be used to support retrieval in
order to lead users to high-quality information.
One simple method is to provide additional words
related to the key words users have input, such as
an input support function within the Google search
engine. What kind of relation between the key
words that have been input and the additional word
is effective for information retrieval?
As for the relations among words, at least two
kinds of relations exist: the taxonomical relation
and the thematic relation. The former is a relation
representing the physical resemblance among ob-
jects, which is typically a semantic relation such as
a hierarchal, synonymic, or antonymic relation;
the latter is a relation between objects through a
thematic scene, such as “milk” and “cow” as recol-
lected in the scene “milking a cow,” and “milk”
and “baby,” as recollected in the scene “giving
baby milk,” which include causal relation and en-
tailment relation. Wisniewski and Bassok (1999)
showed that both relations are important in recog-
nizing those objects. However, while taxonomical
relations are comparatively easy to identify from
linguistic resources such as dictionaries and
thesauri, thematic relations are difficult to identify
because they are rarely maintained in linguistic
resources.
In this paper, we sought to extract word sets
with a thematic relation from documents by em-
ploying case-marking particles derived from syn-
tactic analysis. We then verified the usefulness of
word sets with non-taxonomical relation that seems
to be a thematic relation for information retrieval.
</bodyText>
<sectionHeader confidence="0.964159" genericHeader="method">
2. Method
</sectionHeader>
<bodyText confidence="0.999908142857143">
In order to derive word sets that direct users to
obtain information, we applied a method based on
the Complementary Similarity Measure (CSM),
which can determine a relation between two words
in a corpus by estimating inclusive relations
between two vectors representing each appearance
pattern for each words (Yamamoto et al. 2005).
</bodyText>
<page confidence="0.977496">
141
</page>
<bodyText confidence="0.987274705882353">
Proceedings of the ACL 2007 Demo and Poster Sessions, pages 141–144,
Prague, June 2007. c�2007 Association for Computational Linguistics
We first extracted word pairs having an inclu- We extracted word sets by utilizing inclusive re-
sive relation between the words by calculating the lations of the appearance pattern between words
CSM values. Extracted word pairs are expressed based on a modified/modifier relationship in
by a tuple &lt;wi, wj&gt;, where CSM(Vi, Vj) is greater documents. The Japanese language has case-
than CSM(Vj, Vi) when words wi and wj have each marking particles that indicate the semantic rela-
appearance pattern represented by each binary vec- tion between two elements in a dependency rela-
tor Vi and Vj. Then, we connected word pairs with tion. Then, we collected from documents depend-
CSM values greater than a certain threshold and ency relations matching the following five pat-
constructed word sets. A feature of the CSM-based terns; “A &lt;no (of)&gt; B,” “P &lt;wo (object)&gt; V,” “Q
method is that it can extract not only pairs of re- &lt;ga (subject)&gt; V,” “R &lt;ni (dative)&gt; V,” and “S
lated words but also sets of related words because &lt;ha (topic)&gt; V,” where A, B, P, Q, R, and S are
it connects tuples consistently. nouns, V is a verb, and &lt;X&gt; is a case-marking par-
Suppose we have &lt;A, B&gt;, &lt;B, C&gt;, &lt;Z, B&gt;, &lt;C, ticle. From such collected dependency relations,
D&gt;, &lt;C, E&gt;, and &lt;C, F&gt; in the order of their CSM we compiled the following types of experimental
values, which are greater than the threshold. For data; NN-data based on co-occurrence between
example, let &lt;B, C&gt; be an initial word set {B, C}. nouns for each sentence, NV-data based on a de-
First, we find the tuple with the greatest CSM pendency relation between noun and verb for each
value among the tuples in which the word C at the case-marking particle &lt;wo&gt;, &lt;ga&gt;, &lt;ni&gt;, and &lt;ha&gt;,
tail of the current word set is the left word, and and SO-data based on a collocation between sub-
connect the right word behind C. In this example, ject and object that depends on the same verb V
word “D” is connected to {B, C} because &lt;C, D&gt; as the subject. These data are represented with a
has the greatest CSM value among the three tuples binary vector which corresponds to the appearance
&lt;C, D&gt;, &lt;C, E&gt;, and &lt;C, F&gt;, making the current pattern of a noun and these vectors are used as ar-
word set {B, C, D}. This process is repeated until guments of CSM.
no tuples exist. Next, we find the tuple with the We translated descriptors in the MeSH thesaurus
greatest CSM value among the tuples in which the into Japanese and used them as Japanese medical
word B at the head of the current word set is the terms. The number of terms appearing in this ex-
right word, and connect the left word before B. periment is 2,557 among them. We constructed
This process is repeated until no tuples exist. In word sets consisting of these medical terms. Then,
this example, we obtain the word set {A, B, C, D}. we chose 977 word sets consisting of three or more
Finally, we removed ones with a taxonomical terms from them, and removed word sets with a
relation by using thesaurus. The rest of the word taxonomical relation from them with the MeSH
sets have a non-taxonomical relation — including thesaurus in order to obtain the rest 847 word sets
a thematic relation — among the words. We then as word sets with a thematic relation.
extracted those word sets that do not agree with the 4. Verification
thesaurus as word sets with a thematic relation. In verifying the capability of our word sets to re-
3. Experiment trieve Web pages, we examined whether they
In our experiment, we used domain-specific Japa- could help limit the search results to more informa-
nese documents within the medical domain tive Web pages with Google as a search engine.
(225,402 sentences, 10,144 pages, 37MB) gathered We assume that addition of suitable key words
from the Web pages of a medical school and the to the query reduces the number of pages retrieved
2005 Medical Subject Headings (MeSH) thesau- and the remaining pages are informative pages.
rus1. Recently, there has been a study on query Based on this assumption, we examined the de-
expansion with this thesaurus as domain informa- crease of the retrieved pages by additional key
tion (Friberg 2007). words and the contents of the retrieved pages in
order to verify the availability of our word sets.
Among 847 word sets, we used 294 word sets in
which one of the terms is classified into one cate-
gory and the rest are classified into another.
</bodyText>
<table confidence="0.581729666666667">
1 The U.S. National Library of Medicine created, maintains,
and provides the MeSH® thesaurus.
142
Number of Web pages retrieved when a term is added to Type2
ovary - spleen - palpation (NN)
variation - cross reactions - outbreaks - secretion (Wo)
bleeding - pyrexia - hematuria - consciousness disorder
- vertigo - high blood pressure (Ga)
space flight - insemination - immunity (Ni)
cough - fetus
- bronchiolitis obliterans organizing pneumonia (Ha)
latency period - erythrocyte - hepatic cell (SO)
</table>
<figureCaption confidence="0.999609">
Figure 1. Examples of word sets used to verify.
</figureCaption>
<bodyText confidence="0.997819119047619">
Figure 1 shows examples of the word sets,
where terms in a different category are underlined.
In retrieving Web pages for verification, we in-
put the terms composed of these word sets into the
search engine. We created three types of search
terms from the word set we extracted. Suppose the
extracted word set is {X1, ..., Xn, Y}, where Xi is
classified into one category and Y is classified into
another. The first type uses all terms except the one
classified into a category different from the others:
{X1, ..., Xn} removing Y. The second type uses all
terms except the one in the same category as the
rest: {X1, ..., Xk-1, Xk+1, ..., Xn} removing Xk from
Type 1. In our experiment, we removed the term
Xk with the highest or lowest frequency among Xi.
The third type uses terms in Type 2 and Y: {X1, ...,
Xk-1, Xk+1, ..., Xn, Y}.
In other words, when we consider the terms in
Type 2 as base key words, the terms in Type 1 are
key words with the addition of one term having the
highest or lowest frequency among the terms in the
same category; i.e., the additional term has a fea-
ture related to frequency in the documents and is
taxonomically related to other terms. The terms in
Type 3 are key words with the addition of one term
in a category different from those of the other
component terms; i.e., the additional term seems to
be thematically related — at least non-
taxonomically related — to other terms.
First, we quantitatively compared the retrieval
results. We used the estimated number of pages
retrieved by Google’s search engine. Suppose that
we first input Type 2 as key words into Google,
did not satisfy the result extracted, and added one
word to the previous key words. We then sought to
determine whether to use Type 1 or Type 3 to ob-
tain more suitable results. The results are shown in
Figures 2 and 3, which include the results for the
highest frequency and the lowest frequency, re-
spectively. In these figures, the horizontal axis is
the number of pages retrieved with Type 2 and the
vertical axis is the number of pages retrieved when
</bodyText>
<figure confidence="0.986743083333333">
Type3: With additional term in a different category Type1: With additional term in same category
100000000
10000000
1000000
100000
10000
1000
100
10
1
10 100 1000 10000 100000 1000000 10000000100000000 1000000000
Number of Web pages retrieved with Type2 (base key words)
</figure>
<figureCaption confidence="0.9877005">
Figure 2. Fluctuation of number of pages retrieved
(with the high frequency term).
</figureCaption>
<table confidence="0.9989618">
Type of Data NN NV
Wo Ga Ni Ha
Word sets for verification 175 43 23 13 26
Cases in which Type 3 108 37 15 12 18
defeated Type 1 in retrieval
</table>
<tableCaption confidence="0.9579925">
Table 1. Number of cases in which Type 3 de-
feated Type 1 with the high frequency term.
</tableCaption>
<bodyText confidence="0.999671733333333">
a certain term is added to Type 2. The circles (•)
show the retrieval results with additional key word
related taxonomically (Type 1). The crosses (x)
show the results with additional key word related
non-taxonomically (Type 3). The diagonal line
shows that adding one term to the base key words
does not affect the number of Web pages retrieved.
In Figure 2, most crosses fall further below the
line. This graph indicates that when searching by
Google, adding a search term related non-
taxonomically tends to make a bigger difference
than adding a term related taxonomically and with
high frequency. This means that adding a term re-
lated non-taxonomically to the other terms is cru-
cial to retrieving informative pages; that is, such
terms are informative terms themselves. Table 1
shows the number of cases in which term in differ-
ent category decreases the number of hit pages
more than high frequency term. By this table, we
found that most of the additional terms with high
frequency contributed less than additional terms
related non-taxonomically to decreasing the num-
ber of Web pages retrieved. This means that, in
comparison to the high frequency terms, which
might not be so informative in themselves, the
terms in the other category — related non-
taxonomically — are effective for retrieving useful
Web pages.
In Figure 3, most circles fall further below the
line, in contrast to Figure 2. This indicates that
</bodyText>
<page confidence="0.779697">
1
143
</page>
<note confidence="0.906499">
N umber of Web pages retrieved when a term is added to Type2
</note>
<figure confidence="0.972002769230769">
Type3: With additional term in a different category Type1: With additional term in same category
1000 00
000
10000000
1000000
100000
10000
1000
100
10
1
1 10 100 1000 10000 100000 1000000 10000000 100000000 1000000000 10000000000
Number of Web pages retrieved with Type2 (base key words)
</figure>
<figureCaption confidence="0.9886865">
Figure 3. Fluctuation of number of pages retrieved
(with the low frequency term).
</figureCaption>
<table confidence="0.9991008">
Type of Data NN NV
Wo Ga Ni Ha
Word sets for verification 175 43 23 13 26
Cases in which Type 3 61 18 7 6 13
defeated Type 1 in retrieval
</table>
<tableCaption confidence="0.95337">
Table 2. Number of cases in which Type 3 de-
feated Type 1 with the low frequency term.
</tableCaption>
<bodyText confidence="0.999961047619047">
adding a term related taxonomically and with low
frequency tends to make a bigger difference than
adding a term with high frequency. Certainly, addi-
tional terms with low frequency would be informa-
tive terms, even though they are related taxonomi-
cally, because they may be rare terms on the Web
and therefore the number of pages containing the
term would be small. Table 2 shows the number of
cases in which term in different category decreases
the number of hit pages more than low frequency
term. In comparing these numbers, we found that
the additional term with low frequency helped to
reduce the number of Web pages retrieved, making
no effort to determine the kind of relation the term
had with the other terms. Thus, the terms with low
frequencies are quantitatively effective when used
for retrieval. However, if we compare the results
retrieved with Type 1 search terms and Type 3
search terms, it is clear that big differences exist
between them.
For example, consider “latency period - erythro-
cyte - hepatic cell” obtained from SO-data in Fig-
ure 1. “Latency period” is classified into a category
different from the other terms and “hepatic cell”
has the lowest frequency in this word set. When we
used all the three terms, we obtained pages related
to “malaria” at the top of the results and the title of
the top page was “What is malaria?” in Japanese.
With “latency period” and “erythrocyte,” we again
obtained the same page at the top, although it was
not at the top when we used “erythrocyte” and
“hepatic cell” which have a taxonomical relation.
As we showed above, the terms with thematic
relations with other search terms are effective at
directing users to informative pages. Quantitatively,
terms with a high frequency are not effective at
reducing the number of pages retrieved; qualita-
tively, low frequency terms may not effective to
direct users to informative pages. We will continue
our research in order to extract terms in thematic
relation more accurately and verify the usefulness
of them more quantitatively and qualitatively.
</bodyText>
<sectionHeader confidence="0.998615" genericHeader="conclusions">
5. Conclusion
</sectionHeader>
<bodyText confidence="0.9999927">
We sought to extract word sets with a thematic
relation from documents by employing case-
marking particles derived from syntactic analysis.
We compared the results retrieved with terms re-
lated only taxonomically and the results retrieved
with terms that included a term related non-
taxonomically to the other terms. As a result, we
found adding term which is thematically related to
terms that have already been input as key words is
effective at retrieving informative pages.
</bodyText>
<sectionHeader confidence="0.999101" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999113818181818">
Berland, M. and Charniak, E. 1999. Finding parts in
very large corpora, In Proceedings of ACL 99, 57–64.
Friberg, K. 2007. Query expansion using domain infor-
mation in compounds, In Proceedings of NAACL-
HLT 2007 Doctoral Consortium, 1–4.
Geffet, M. and Dagan, I. 2005. The distribution inclu-
sion hypotheses and lexical entailment. In Proceed-
ings of ACL 2005, 107–114.
Girju, R. 2003. Automatic detection of causal relations
for question answering. In Proceedings of ACL
Workshop on Multilingual summarization and ques-
tion answering, 76–114.
Hearst, M. A. 1992, Automatic acquisition of hyponyms
from large text corpora, In Proceedings of Coling 92,
539–545.
Wisniewski, E. J. and Bassok. M. 1999. What makes a
man similar to a tie? Cognitive Psychology, 39: 208–
238.
Yamamoto, E., Kanzaki, K., and Isahara, H. 2005. Ex-
traction of hierarchies based on inclusion of co-
occurring words with frequency information. In Pro-
ceedings of IJCAI 2005, 1166–1172.
</reference>
<page confidence="0.998595">
144
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.970202">
<title confidence="0.99973">Extracting Word Sets with Non-Taxonomical Relation</title>
<author confidence="0.995626">Eiko Yamamoto Hitoshi Isahara</author>
<affiliation confidence="0.999493">Computational Linguistics Group National Institute of Information and Communications Technology</affiliation>
<address confidence="0.998424">3-5 Hikaridai, Seika-cho, Soraku-gun, Kyoto 619-0289, Japan</address>
<email confidence="0.982599">eiko@nict.go.jp</email>
<email confidence="0.982599">isahara@nict.go.jp</email>
<abstract confidence="0.999705">At least two kinds of relations exist among related words: taxonomical relations and thematic relations. Both relations identify related words useful to language understanding and generation, information retrieval, and so on. However, although words with taxonomical relations are easy to identify from linguistic resources such as dictionaries and thesauri, words with thematic relations are difficult to identify because they are rarely maintained in linguistic resources. In this paper, we sought to extract thematically (non-taxonomically) related word sets among words in documents by employing case-marking particles derived from syntactic analysis. We then verified the usefulness of word sets with non-taxonomical relation that seems to be a thematic relation for information retrieval.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M Berland</author>
<author>E Charniak</author>
</authors>
<title>Finding parts in very large corpora,</title>
<date>1999</date>
<booktitle>In Proceedings of ACL 99,</booktitle>
<pages>57--64</pages>
<contexts>
<context position="1439" citStr="Berland and Charniak 1999" startWordPosition="193" endWordPosition="196">ly) related word sets among words in documents by employing case-marking particles derived from syntactic analysis. We then verified the usefulness of word sets with non-taxonomical relation that seems to be a thematic relation for information retrieval. 1. Introduction Related word sets are useful linguistic resources for language understanding and generation, information retrieval, and so on. In previous research on natural language processing, many methodologies for extracting various relations from corpora have been developed, such as the “is-a” relation (Hearst 1992), “part-of” relation (Berland and Charniak 1999), causal relation (Girju 2003), and entailment relation (Geffet and Dagan 2005). Related words can be used to support retrieval in order to lead users to high-quality information. One simple method is to provide additional words related to the key words users have input, such as an input support function within the Google search engine. What kind of relation between the key words that have been input and the additional word is effective for information retrieval? As for the relations among words, at least two kinds of relations exist: the taxonomical relation and the thematic relation. The for</context>
</contexts>
<marker>Berland, Charniak, 1999</marker>
<rawString>Berland, M. and Charniak, E. 1999. Finding parts in very large corpora, In Proceedings of ACL 99, 57–64.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Friberg</author>
</authors>
<title>Query expansion using domain information in compounds,</title>
<date>2007</date>
<booktitle>In Proceedings of NAACLHLT 2007 Doctoral Consortium,</booktitle>
<volume>1</volume>
<contexts>
<context position="7725" citStr="Friberg 2007" startWordPosition="1261" endWordPosition="1262">e search results to more informanese documents within the medical domain tive Web pages with Google as a search engine. (225,402 sentences, 10,144 pages, 37MB) gathered We assume that addition of suitable key words from the Web pages of a medical school and the to the query reduces the number of pages retrieved 2005 Medical Subject Headings (MeSH) thesau- and the remaining pages are informative pages. rus1. Recently, there has been a study on query Based on this assumption, we examined the deexpansion with this thesaurus as domain informa- crease of the retrieved pages by additional key tion (Friberg 2007). words and the contents of the retrieved pages in order to verify the availability of our word sets. Among 847 word sets, we used 294 word sets in which one of the terms is classified into one category and the rest are classified into another. 1 The U.S. National Library of Medicine created, maintains, and provides the MeSH® thesaurus. 142 Number of Web pages retrieved when a term is added to Type2 ovary - spleen - palpation (NN) variation - cross reactions - outbreaks - secretion (Wo) bleeding - pyrexia - hematuria - consciousness disorder - vertigo - high blood pressure (Ga) space flight - </context>
</contexts>
<marker>Friberg, 2007</marker>
<rawString>Friberg, K. 2007. Query expansion using domain information in compounds, In Proceedings of NAACLHLT 2007 Doctoral Consortium, 1–4.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Geffet</author>
<author>I Dagan</author>
</authors>
<title>The distribution inclusion hypotheses and lexical entailment.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL 2005,</booktitle>
<pages>107--114</pages>
<contexts>
<context position="1518" citStr="Geffet and Dagan 2005" startWordPosition="204" endWordPosition="207">derived from syntactic analysis. We then verified the usefulness of word sets with non-taxonomical relation that seems to be a thematic relation for information retrieval. 1. Introduction Related word sets are useful linguistic resources for language understanding and generation, information retrieval, and so on. In previous research on natural language processing, many methodologies for extracting various relations from corpora have been developed, such as the “is-a” relation (Hearst 1992), “part-of” relation (Berland and Charniak 1999), causal relation (Girju 2003), and entailment relation (Geffet and Dagan 2005). Related words can be used to support retrieval in order to lead users to high-quality information. One simple method is to provide additional words related to the key words users have input, such as an input support function within the Google search engine. What kind of relation between the key words that have been input and the additional word is effective for information retrieval? As for the relations among words, at least two kinds of relations exist: the taxonomical relation and the thematic relation. The former is a relation representing the physical resemblance among objects, which is</context>
</contexts>
<marker>Geffet, Dagan, 2005</marker>
<rawString>Geffet, M. and Dagan, I. 2005. The distribution inclusion hypotheses and lexical entailment. In Proceedings of ACL 2005, 107–114.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Girju</author>
</authors>
<title>Automatic detection of causal relations for question answering.</title>
<date>2003</date>
<booktitle>In Proceedings of ACL Workshop on Multilingual summarization and question answering,</booktitle>
<pages>76--114</pages>
<contexts>
<context position="1469" citStr="Girju 2003" startWordPosition="199" endWordPosition="200">s by employing case-marking particles derived from syntactic analysis. We then verified the usefulness of word sets with non-taxonomical relation that seems to be a thematic relation for information retrieval. 1. Introduction Related word sets are useful linguistic resources for language understanding and generation, information retrieval, and so on. In previous research on natural language processing, many methodologies for extracting various relations from corpora have been developed, such as the “is-a” relation (Hearst 1992), “part-of” relation (Berland and Charniak 1999), causal relation (Girju 2003), and entailment relation (Geffet and Dagan 2005). Related words can be used to support retrieval in order to lead users to high-quality information. One simple method is to provide additional words related to the key words users have input, such as an input support function within the Google search engine. What kind of relation between the key words that have been input and the additional word is effective for information retrieval? As for the relations among words, at least two kinds of relations exist: the taxonomical relation and the thematic relation. The former is a relation representing</context>
</contexts>
<marker>Girju, 2003</marker>
<rawString>Girju, R. 2003. Automatic detection of causal relations for question answering. In Proceedings of ACL Workshop on Multilingual summarization and question answering, 76–114.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A Hearst</author>
</authors>
<title>Automatic acquisition of hyponyms from large text corpora,</title>
<date>1992</date>
<booktitle>In Proceedings of Coling 92,</booktitle>
<pages>539--545</pages>
<contexts>
<context position="1391" citStr="Hearst 1992" startWordPosition="189" endWordPosition="190">ract thematically (non-taxonomically) related word sets among words in documents by employing case-marking particles derived from syntactic analysis. We then verified the usefulness of word sets with non-taxonomical relation that seems to be a thematic relation for information retrieval. 1. Introduction Related word sets are useful linguistic resources for language understanding and generation, information retrieval, and so on. In previous research on natural language processing, many methodologies for extracting various relations from corpora have been developed, such as the “is-a” relation (Hearst 1992), “part-of” relation (Berland and Charniak 1999), causal relation (Girju 2003), and entailment relation (Geffet and Dagan 2005). Related words can be used to support retrieval in order to lead users to high-quality information. One simple method is to provide additional words related to the key words users have input, such as an input support function within the Google search engine. What kind of relation between the key words that have been input and the additional word is effective for information retrieval? As for the relations among words, at least two kinds of relations exist: the taxonom</context>
</contexts>
<marker>Hearst, 1992</marker>
<rawString>Hearst, M. A. 1992, Automatic acquisition of hyponyms from large text corpora, In Proceedings of Coling 92, 539–545.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M</author>
</authors>
<title>What makes a man similar to a tie?</title>
<date>1999</date>
<journal>Cognitive Psychology,</journal>
<volume>39</volume>
<pages>208--238</pages>
<marker>M, 1999</marker>
<rawString>Wisniewski, E. J. and Bassok. M. 1999. What makes a man similar to a tie? Cognitive Psychology, 39: 208– 238.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Yamamoto</author>
<author>K Kanzaki</author>
<author>H Isahara</author>
</authors>
<title>Extraction of hierarchies based on inclusion of cooccurring words with frequency information.</title>
<date>2005</date>
<booktitle>In Proceedings of IJCAI 2005,</booktitle>
<pages>1166--1172</pages>
<contexts>
<context position="3442" citStr="Yamamoto et al. 2005" startWordPosition="505" endWordPosition="508">we sought to extract word sets with a thematic relation from documents by employing case-marking particles derived from syntactic analysis. We then verified the usefulness of word sets with non-taxonomical relation that seems to be a thematic relation for information retrieval. 2. Method In order to derive word sets that direct users to obtain information, we applied a method based on the Complementary Similarity Measure (CSM), which can determine a relation between two words in a corpus by estimating inclusive relations between two vectors representing each appearance pattern for each words (Yamamoto et al. 2005). 141 Proceedings of the ACL 2007 Demo and Poster Sessions, pages 141–144, Prague, June 2007. c�2007 Association for Computational Linguistics We first extracted word pairs having an inclu- We extracted word sets by utilizing inclusive resive relation between the words by calculating the lations of the appearance pattern between words CSM values. Extracted word pairs are expressed based on a modified/modifier relationship in by a tuple &lt;wi, wj&gt;, where CSM(Vi, Vj) is greater documents. The Japanese language has casethan CSM(Vj, Vi) when words wi and wj have each marking particles that indicate </context>
</contexts>
<marker>Yamamoto, Kanzaki, Isahara, 2005</marker>
<rawString>Yamamoto, E., Kanzaki, K., and Isahara, H. 2005. Extraction of hierarchies based on inclusion of cooccurring words with frequency information. In Proceedings of IJCAI 2005, 1166–1172.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>