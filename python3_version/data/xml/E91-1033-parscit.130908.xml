<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002913">
<sectionHeader confidence="0.8963695" genericHeader="abstract">
EXPLOITING CONVERSATIONAL IMPLICATURE
FOR GENERATING CONCISE EXPLANATIONS
</sectionHeader>
<bodyText confidence="0.9308525625">
HELMUT HORACEK
Universitat Bielefeld
Fakultat fiir Linguistik und Literaturwissenschaft
Postfach 8640, D-4800 Bielefeld 1, Deutschland
ABSTRACT
This paper presents an approach for achieving
conciseness in generating explanations, which
is done by exploiting formal reconstructions of
aspects of the Gricean principle of relevance to
simulate conversational implicature. By apply-
ing contextually motivated inference rules in an
anticipation feed-back loop, a set of propo-
sitions explicitly representing an explanation&apos;s
content is reduced to a subset which, in the
actual context, can still be considered to convey
the message adequately.
</bodyText>
<sectionHeader confidence="0.990675" genericHeader="introduction">
1. INTRODUCTION
</sectionHeader>
<bodyText confidence="0.999610166666667">
The task of providing informative natural
language explanations for illustrating the results
produced by decision support systems has been
given increased attention recently. The pro-
posed methods preferably address tailoring of
explanations to the needs of their addressees,
including, for instance, object descriptions 181
and presentation of taxonomic knowledge [7].
In addition, particular emphasis has been put on
reactive explanation techniques for selecting an
appropriate content according to contextual
interpretation [6], and on the way of presenting
explanations by taking the information seeking
person&apos;s knowledge into account [1].
Whereas these approaches attack various issues
important for the generation of natural language
explanations, none of them has focussed on the
conciseness of explanations in a broader con-
text. Aiming at the production of natural and
concise texts, we have concentrated our efforts
on presenting different types of knowledge and
their interrelations because this kind of infor-
mation is typically relevant for explanations.
We formally reconstruct aspects of the Gricean
principle of relevance [3] and exploit the results
obtained for creating concise explanations to
questions about solutions proposed by the ex-
pert system OFFICE-PLAN [5]. This system is
able to appropriately assign a set of employees
to a set of rooms in offices, which is guided by
</bodyText>
<listItem confidence="0.805466333333333">
â€¢ a number of constraints expressing various
kinds of the persons&apos; requirements.
2. REPRESENTING DOMAIN
</listItem>
<sectionHeader confidence="0.986971" genericHeader="method">
AND INFERENCE KNOWLEDGE
</sectionHeader>
<bodyText confidence="0.999797425">
Terminological knowledge is represented in a
sorted type hierarchy, which identifies classes
of entities and their relevant subsorts, as well as
relations that may hold between two types of
entities. Moreover, assertions which refer to the
referential level must be consistent with the on-
tology provided by these taxonomic definitions.
Inferential knowledge is represented in terms of
rules which express constraints to be satisfied
in the problem solving process. Rules are
represented according to the syntax of IRS [2],
which is loosely based on predicate logic. The
quantifiers used in our system are all, some,
and unique. The predications contained are re-
stricted to be one- or two-place predications
corresponding to class and relation definitions
introduced in the taxonomic hierarchy. In addi-
tion, the meta-predicate implies is contained in
the innermost predication of a rule, which con-
stitutes the rule&apos;s conclusion (see Figure 1).
The original representation of an explanation to
a certain question consists of a set of propo-
sitions (created by the preceeding component in
the generation process [4]) which includes
inference rules and individual facts that comple-
tely identify the reasons behind. The task is
then to reduce this set of propositions as much
as possible by exploiting a given context so that
the subset obtained still conveys the same infor-
mation - in a partially implicit and more concise
form, but without leading to wrong implica-
tions. The intuition behind this mechanism is as
follows: After having asked a certain expla-
nation seeking question the questioner mentally
attempts to build links between entities referred
to in the question and facts or rules provided as
&apos;explanation&apos;. Hence, if a regularity valid for a
class of entities is uttered, the person attempts
to find out which of the entities mentioned pre-
viously this rule is thought to apply to.
</bodyText>
<figure confidence="0.754055333333333">
((all g (group-leader g))
((some r (and (room r) (in r g)))
(implies (single-room r))))
</figure>
<figureCaption confidence="0.999543">
Figure 1: Inference rule I-Rule 1
</figureCaption>
<bodyText confidence="0.671439">
- 191 -
</bodyText>
<sectionHeader confidence="0.994067" genericHeader="method">
3. EXPRESSING CONVERSATIONAL
IMPLICATURE
</sectionHeader>
<bodyText confidence="0.999946818181818">
The reduction of the set of propositions that ori-
ginally represents the explanation is performed
by exploiting a set of rules which are contex-
tually motivated and express conversational im-
plicature. These rules represent formal recon-
structions of aspects of the Gricean principle of
relevance. They have the same format as the
rules which constitute the system&apos;s inferential
knowledge, but, in addition, they contain meta-
predications referring to contextual, conversa-
tional, or processing states associated with the
individuals referred to (see Figure 2 below).
The rules expressing conversational implicature
allow variables to denote propositions, though
in an extremely limited sense only: a variable x
denoting a proposition must always be restrict-
ed by the predication (newinfo x) so that the eva-
luation process can rely on a definite set of en-
tities when generating legal instances of x.
We have defined three rules that constitute a
fundamental repertoire for exploiting conversa-
tional implicature (see Figure 3). They express
contextually motivated inferences of a fact from
another one, of a fact from an inference rule,
and the relevance of an inference rule justified
by a fact. Moreover, logical substitution is ap-
plied to those domain inference rules which be-
come bound to variables of a contextually moti-
vated inference rule at some processing stage.
The first rule, C-Rule 1, refers to two (sets of)
entities el and e2, which have been both addres-
sed (expressed by topic) in the question and
share the most general superclass (topclass). if
</bodyText>
<figureCaption confidence="0.996894">
Figure 2: Meta-predications and their meanings
</figureCaption>
<bodyText confidence="0.997168071428571">
the explanation also contains new facts p (newin-
fo) about el and the same assertion also applies
to e2 (expressed by subst), and nothing is said
about e2 (no-newinfo), conversational relevance
dictates that the contrary of the newly introdu-
ced facts p is true for e2 (otherwise, the relevant
part of the message would also mention e2).
C-Rule 2 may be applicable if the explanation
contains an inference rule r (referred to by new-
info). In that case an attempt is made to establish
a link between a class el which occurs (about) in
the rule&apos;s premise and all entities e2 mentioned
in the prior question (topic) which could fit (not-
false) the class membership of e/. If this is suc-
cessful for some e2, their class membership
concerning el is considered to be valid.
Finally, C-Rule 3 tries to strenghten the rele-
vance of a proposition (newinfo) concerning an
entity el. First, a unique inference rule r has to
be found (in the addressee&apos;s mental state)
which contains a variable e2 in its premise such
that e/ could fit (not-false) the class membership
of e2. Secondly, the rule&apos;s conclusion must be
consistent with the information available so far;
hence, it must be possible to associate all vari-
ables e3 occurring in the conclusion with vari-
ables e4 by means of a class membership rela-
tion. Then the rule is considered to be relevant.
</bodyText>
<figure confidence="0.472451529411765">
((all p (and (proposition p) (newinfo p)))
((all el (and (entity el) (topic el) (contains p el)))
((all e2 (and (entity e2) (topic e2)
(equal (topclass e2) (topclass el))
(no-newinfo e2)
(unknown (subs: p el e2))))
(implies (not (subs: p el e2))))))
C-Rule I: Inferring a fact from another fact
((all r (and (rule r) (newinfo r)))
((all el (about (premise r) el c))
((all e2 (and (entity e2) (topic e2)
(not-false (subclass (class e2) e))))
(implies (equal (class e2) c)))))
C-Rule 2: Inferring a fact from a rule
((all p (and (proposition p) (newinfo p)))
((all el (and (entity el) (topic el) (contains p el)))
((unique r (and (rule r) (knows user r)))
</figure>
<figureCaption confidence="0.7905235">
((all e2 (and (about (premise r) e2 cl)
(not-false (subclass (class el) cl))))
((all e3 (about (conclusion r) e3 c2))
((some e4 (and (topic e4)
</figureCaption>
<figure confidence="0.71131275">
(not-false (or (subclass (class 64) c2)
(subclass c2 (class eA))))))
(implies (relevant r (subst r e2 el))))))))
C-Rule 3 : Inferring a rule from a fact
</figure>
<figureCaption confidence="0.994328">
Figure 3: Contextually motivated rules
</figureCaption>
<figure confidence="0.991968333333333">
Predicate
(topic a)
(topclass a)
(unknown p)
(newinfo p)
(no-newinfo a)
(subst p a b)
(contains p a)
(about f a c)
(not-false p)
(relevant gr ir)
Meaning
</figure>
<bodyText confidence="0.989883894736842">
the entity referred to by a is mentioned
in the explanation seeking question
the most general class a is a subclass
of (the root wide does not count)
the truth value of proposition p is
considered to be unknown to the user
p is contained in the set of propo-
sitions constituting the explanation
the information about the entity refer-
red to by variable a is not effected by
the explanation given
b is substituted for a in proposition p
proposition p refers to entity a
formulaf contains a proposition asser-
ting variable a to belong to class c
p is either unknown to the user or
considered by him/her to be true
rule gr is relevant for instantiation ir
- 192 -
</bodyText>
<sectionHeader confidence="0.977672" genericHeader="method">
4. THE INFERENCE MECHANISM
</sectionHeader>
<bodyText confidence="0.9999762">
The inference mechanism is applied by using a
simulated anticipation feed-back loop fed by
heuristically generated hypotheses. They are
subsets of the set of propositions that originally
represent the explanation. After the first suc-
cessful application of a contextually motivated
rule only C-Rule 1 and logical substitution are ta-
ken into account for further inferencing. This
process is continued until all propositions con-
tained in the explanation&apos;s explicit form occur
</bodyText>
<listItem confidence="0.999679333333333">
â€¢ in the current hypothesis, or
â€¢ in the user model, or
â€¢ in the set of propositions inferred,
</listItem>
<bodyText confidence="0.999915652173913">
(thus, the explanation is complete) and no con-
tradictions have been derived (it is also impli-
cature-free) - hence, the hypothesis considered
represents a valid explanation. The hypotheses
are created by starting with the smallest sub-
sets, so that the first valid hypothesis can be
expected to be the best choice. In addition, all
inference rules referred to in the explicit form of
the explanation and unknown to the user are
also contained in each hypothesis, as there is no
chance to infer the relevance of a rule without
being acquainted with it (see the clause (knows
user r) in C-Rule 3). Even if the addressee is
familiar with a certain rule, this rule must either
be mentioned or it must be inferable, because
evidence for its relevance in the actual instance
is required. In fact, hypotheses not including
such a rule are preferred because triggering the
inference of a rule&apos;s relevance by means of
uttering an additonal fact can usually be achiev-
ed by shorter utterances than by expressing the
inference rule explicitly. This heuristics has its
source in the Gricean principle of brevity.
</bodyText>
<sectionHeader confidence="0.997448" genericHeader="conclusions">
5. EXAMPLES
</sectionHeader>
<bodyText confidence="0.999446297297297">
The mechanism described has been implement-
ed in CommonLisp on a SUN4. We demon-
strate the system&apos;s behavior by means of the
effects of three different user models when
expressing most adequately the explanation
(represented in Figure 4) to the question: &apos;Why
is person A in room B and not in room C?&apos;
The user models applied comprise stereotypes
for a &apos;local employee&apos; (he/she is acquainted
with all information about the actual office), for
a &apos;novice&apos; (who does not know anything), and
for an &apos;office plan expert&apos; (who is assumed to
know 1-Rule 1 (1) only). Fact (5) is known to
anybody, as it is presupposed by the question.
The process is simple for the &apos;local employee&apos;:
Since he/she also knows facts (2) to (4), the
first hypothesis (I-Rule 1) provides the missing
information. The first hypothesis is identical for
the &apos;novice&apos;, but a series of inferences is need-
ed to prove its adequacy. First, a part of C-Rule
2 matches (1) and, as A is the only person refer-
red to in the question, it is inferred that A is a
group leader, which is what fact (2) expresses.
Then, substituting A and B in I-Rule 1 results in
the evidence that B is a single room, thus prov-
ing fact (3) as well. Finally, C-Rule 1 is appli-
cable by substituting B and C for the variables
el and e2, respectively, concluding that C is not
a single room (and, in fact, a double room if
this is the only other possible type of room).
The first hypothesis for the &apos;expert&apos; consists of
(2) only. Because experts are assumed to be ac-
quainted with I-Rule 1, C-Rule 3 can be applied
proving the relevance of (1). Then, processing
can continue as this is done after the first infer-
ence step for the &apos;novice&apos;, so that fact (2) is
obtained as the best explanation for the expert.
</bodyText>
<figure confidence="0.831577833333333">
(1) (and (Rule 1) &apos;Group leaders must
be in single rooms&apos;
(2) (group-leader A) &apos;A is a group leader&apos;
(3) (single-room B) &apos;B is a single room&apos;
(4) (double-room C) &apos;C is a double room&apos;
(5) (in B A)) &apos;A is in room B&apos;
</figure>
<figureCaption confidence="0.998944">
Figure 4: Representing an explanation
</figureCaption>
<sectionHeader confidence="0.995921" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.988648038461538">
[1] Bateman J., Paris C.: Phrasing a Text in Terms the
User can Understand. In IJCAI-89, pp. 1511-1517,
1989.
[2] Bergmann H., Fliegner M., Gerlach M., Marburger
H., Poesio M.: IRS - The Internal Representation
Language. WISBER Report Nr. 14, University of
Hamburg, 1987.
[3] Grice H.: Logic and Conversation. In Syntax and
Semantics: Vol 3. Speech Acts, pp. 43-58, Acade-
mic Pr., 1975.
[4] Horacek H.: Towards Finding the Reasons Behind -
Generating the Content of Explanations. Submitted
to LICAI-91.
[5] Karbach W., Linster M., VoB A.: OFFICE-PLAN:
Tackling the Synthesis Frontier. In Metzing D.
(ed.), GW41-89, Springer, pp. 379-387, 1989.
[6] Moore J., Swartout W.: A Reactive Approach to
Explanation. In IJCAI-89, pp. 1504-1510, 1989.
[7] Paris C.: Tailoring Object Descriptions to a User&apos;s
Level of Expertise. In Computational Linguistics
14, pp. 64-78, 1988.
[8] Reiter E.: Generating Descriptions that Exploit a
User&apos;s Domain Knowledge. In Current Issues in Na-
tural Language Generation, Dale R., Mellish C.,
Zock M. (eds.), pp. 257-285, Academic Pr., 1990.
- 193 -
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.521191">
<title confidence="0.980655">EXPLOITING CONVERSATIONAL IMPLICATURE FOR GENERATING CONCISE EXPLANATIONS</title>
<author confidence="0.655949">HELMUT HORACEK</author>
<affiliation confidence="0.908321">Universitat Bielefeld Fakultat fiir Linguistik und Literaturwissenschaft</affiliation>
<address confidence="0.942233">8640, D-4800 Bielefeld</address>
<abstract confidence="0.99719125">This paper presents an approach for achieving conciseness in generating explanations, which is done by exploiting formal reconstructions of aspects of the Gricean principle of relevance to simulate conversational implicature. By applying contextually motivated inference rules in an anticipation feed-back loop, a set of propositions explicitly representing an explanation&apos;s content is reduced to a subset which, in the actual context, can still be considered to convey the message adequately.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Bateman</author>
<author>C Paris</author>
</authors>
<title>Phrasing a Text in Terms the User can Understand.</title>
<date>1989</date>
<booktitle>In IJCAI-89,</booktitle>
<pages>1511--1517</pages>
<contexts>
<context position="1370" citStr="[1]" startWordPosition="183" endWordPosition="183">al language explanations for illustrating the results produced by decision support systems has been given increased attention recently. The proposed methods preferably address tailoring of explanations to the needs of their addressees, including, for instance, object descriptions 181 and presentation of taxonomic knowledge [7]. In addition, particular emphasis has been put on reactive explanation techniques for selecting an appropriate content according to contextual interpretation [6], and on the way of presenting explanations by taking the information seeking person&apos;s knowledge into account [1]. Whereas these approaches attack various issues important for the generation of natural language explanations, none of them has focussed on the conciseness of explanations in a broader context. Aiming at the production of natural and concise texts, we have concentrated our efforts on presenting different types of knowledge and their interrelations because this kind of information is typically relevant for explanations. We formally reconstruct aspects of the Gricean principle of relevance [3] and exploit the results obtained for creating concise explanations to questions about solutions propos</context>
</contexts>
<marker>[1]</marker>
<rawString>Bateman J., Paris C.: Phrasing a Text in Terms the User can Understand. In IJCAI-89, pp. 1511-1517, 1989.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Bergmann</author>
<author>M Fliegner</author>
<author>M Gerlach</author>
<author>H Marburger</author>
<author>M Poesio</author>
</authors>
<title>IRS - The Internal Representation Language.</title>
<date>1987</date>
<tech>WISBER Report Nr. 14,</tech>
<institution>University of Hamburg,</institution>
<contexts>
<context position="2772" citStr="[2]" startWordPosition="397" endWordPosition="397">inds of the persons&apos; requirements. 2. REPRESENTING DOMAIN AND INFERENCE KNOWLEDGE Terminological knowledge is represented in a sorted type hierarchy, which identifies classes of entities and their relevant subsorts, as well as relations that may hold between two types of entities. Moreover, assertions which refer to the referential level must be consistent with the ontology provided by these taxonomic definitions. Inferential knowledge is represented in terms of rules which express constraints to be satisfied in the problem solving process. Rules are represented according to the syntax of IRS [2], which is loosely based on predicate logic. The quantifiers used in our system are all, some, and unique. The predications contained are restricted to be one- or two-place predications corresponding to class and relation definitions introduced in the taxonomic hierarchy. In addition, the meta-predicate implies is contained in the innermost predication of a rule, which constitutes the rule&apos;s conclusion (see Figure 1). The original representation of an explanation to a certain question consists of a set of propositions (created by the preceeding component in the generation process [4]) which in</context>
</contexts>
<marker>[2]</marker>
<rawString>Bergmann H., Fliegner M., Gerlach M., Marburger H., Poesio M.: IRS - The Internal Representation Language. WISBER Report Nr. 14, University of Hamburg, 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Grice</author>
</authors>
<title>Logic and Conversation.</title>
<date>1975</date>
<booktitle>In Syntax and Semantics: Vol 3. Speech Acts,</booktitle>
<pages>43--58</pages>
<publisher>Academic Pr.,</publisher>
<contexts>
<context position="1867" citStr="[3]" startWordPosition="257" endWordPosition="257">n the way of presenting explanations by taking the information seeking person&apos;s knowledge into account [1]. Whereas these approaches attack various issues important for the generation of natural language explanations, none of them has focussed on the conciseness of explanations in a broader context. Aiming at the production of natural and concise texts, we have concentrated our efforts on presenting different types of knowledge and their interrelations because this kind of information is typically relevant for explanations. We formally reconstruct aspects of the Gricean principle of relevance [3] and exploit the results obtained for creating concise explanations to questions about solutions proposed by the expert system OFFICE-PLAN [5]. This system is able to appropriately assign a set of employees to a set of rooms in offices, which is guided by â€¢ a number of constraints expressing various kinds of the persons&apos; requirements. 2. REPRESENTING DOMAIN AND INFERENCE KNOWLEDGE Terminological knowledge is represented in a sorted type hierarchy, which identifies classes of entities and their relevant subsorts, as well as relations that may hold between two types of entities. Moreover, assert</context>
</contexts>
<marker>[3]</marker>
<rawString>Grice H.: Logic and Conversation. In Syntax and Semantics: Vol 3. Speech Acts, pp. 43-58, Academic Pr., 1975.</rawString>
</citation>
<citation valid="false">
<authors>
<author>H Horacek</author>
</authors>
<title>Towards Finding the Reasons Behind -Generating the Content of Explanations.</title>
<note>Submitted to LICAI-91.</note>
<contexts>
<context position="3362" citStr="[4]" startWordPosition="489" endWordPosition="489">ax of IRS [2], which is loosely based on predicate logic. The quantifiers used in our system are all, some, and unique. The predications contained are restricted to be one- or two-place predications corresponding to class and relation definitions introduced in the taxonomic hierarchy. In addition, the meta-predicate implies is contained in the innermost predication of a rule, which constitutes the rule&apos;s conclusion (see Figure 1). The original representation of an explanation to a certain question consists of a set of propositions (created by the preceeding component in the generation process [4]) which includes inference rules and individual facts that completely identify the reasons behind. The task is then to reduce this set of propositions as much as possible by exploiting a given context so that the subset obtained still conveys the same information - in a partially implicit and more concise form, but without leading to wrong implications. The intuition behind this mechanism is as follows: After having asked a certain explanation seeking question the questioner mentally attempts to build links between entities referred to in the question and facts or rules provided as &apos;explanatio</context>
</contexts>
<marker>[4]</marker>
<rawString>Horacek H.: Towards Finding the Reasons Behind -Generating the Content of Explanations. Submitted to LICAI-91.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Karbach</author>
<author>M Linster</author>
</authors>
<title>VoB A.: OFFICE-PLAN: Tackling the Synthesis Frontier.</title>
<date>1989</date>
<pages>41--89</pages>
<editor>In Metzing D. (ed.),</editor>
<publisher>Springer,</publisher>
<contexts>
<context position="2009" citStr="[5]" startWordPosition="278" endWordPosition="278">rious issues important for the generation of natural language explanations, none of them has focussed on the conciseness of explanations in a broader context. Aiming at the production of natural and concise texts, we have concentrated our efforts on presenting different types of knowledge and their interrelations because this kind of information is typically relevant for explanations. We formally reconstruct aspects of the Gricean principle of relevance [3] and exploit the results obtained for creating concise explanations to questions about solutions proposed by the expert system OFFICE-PLAN [5]. This system is able to appropriately assign a set of employees to a set of rooms in offices, which is guided by â€¢ a number of constraints expressing various kinds of the persons&apos; requirements. 2. REPRESENTING DOMAIN AND INFERENCE KNOWLEDGE Terminological knowledge is represented in a sorted type hierarchy, which identifies classes of entities and their relevant subsorts, as well as relations that may hold between two types of entities. Moreover, assertions which refer to the referential level must be consistent with the ontology provided by these taxonomic definitions. Inferential knowledge </context>
</contexts>
<marker>[5]</marker>
<rawString>Karbach W., Linster M., VoB A.: OFFICE-PLAN: Tackling the Synthesis Frontier. In Metzing D. (ed.), GW41-89, Springer, pp. 379-387, 1989.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Moore</author>
<author>W Swartout</author>
</authors>
<title>A Reactive Approach to Explanation. In</title>
<date>1989</date>
<booktitle>IJCAI-89,</booktitle>
<pages>1504--1510</pages>
<contexts>
<context position="1257" citStr="[6]" startWordPosition="166" endWordPosition="166">can still be considered to convey the message adequately. 1. INTRODUCTION The task of providing informative natural language explanations for illustrating the results produced by decision support systems has been given increased attention recently. The proposed methods preferably address tailoring of explanations to the needs of their addressees, including, for instance, object descriptions 181 and presentation of taxonomic knowledge [7]. In addition, particular emphasis has been put on reactive explanation techniques for selecting an appropriate content according to contextual interpretation [6], and on the way of presenting explanations by taking the information seeking person&apos;s knowledge into account [1]. Whereas these approaches attack various issues important for the generation of natural language explanations, none of them has focussed on the conciseness of explanations in a broader context. Aiming at the production of natural and concise texts, we have concentrated our efforts on presenting different types of knowledge and their interrelations because this kind of information is typically relevant for explanations. We formally reconstruct aspects of the Gricean principle of rel</context>
</contexts>
<marker>[6]</marker>
<rawString>Moore J., Swartout W.: A Reactive Approach to Explanation. In IJCAI-89, pp. 1504-1510, 1989.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Paris</author>
</authors>
<title>Tailoring Object Descriptions to a User&apos;s Level of Expertise.</title>
<date>1988</date>
<booktitle>In Computational Linguistics 14,</booktitle>
<pages>64--78</pages>
<contexts>
<context position="1095" citStr="[7]" startWordPosition="145" endWordPosition="145">es in an anticipation feed-back loop, a set of propositions explicitly representing an explanation&apos;s content is reduced to a subset which, in the actual context, can still be considered to convey the message adequately. 1. INTRODUCTION The task of providing informative natural language explanations for illustrating the results produced by decision support systems has been given increased attention recently. The proposed methods preferably address tailoring of explanations to the needs of their addressees, including, for instance, object descriptions 181 and presentation of taxonomic knowledge [7]. In addition, particular emphasis has been put on reactive explanation techniques for selecting an appropriate content according to contextual interpretation [6], and on the way of presenting explanations by taking the information seeking person&apos;s knowledge into account [1]. Whereas these approaches attack various issues important for the generation of natural language explanations, none of them has focussed on the conciseness of explanations in a broader context. Aiming at the production of natural and concise texts, we have concentrated our efforts on presenting different types of knowledge</context>
</contexts>
<marker>[7]</marker>
<rawString>Paris C.: Tailoring Object Descriptions to a User&apos;s Level of Expertise. In Computational Linguistics 14, pp. 64-78, 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Reiter</author>
</authors>
<title>Generating Descriptions that Exploit a User&apos;s Domain Knowledge.</title>
<date>1990</date>
<booktitle>In Current Issues in Natural Language Generation,</booktitle>
<pages>257--285</pages>
<editor>Dale R., Mellish C., Zock M. (eds.),</editor>
<marker>[8]</marker>
<rawString>Reiter E.: Generating Descriptions that Exploit a User&apos;s Domain Knowledge. In Current Issues in Natural Language Generation, Dale R., Mellish C., Zock M. (eds.), pp. 257-285, Academic Pr., 1990. - 193 -</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>