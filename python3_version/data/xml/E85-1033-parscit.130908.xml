<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000005">
<note confidence="0.93025">
USING A TEXT MODEL FOR ANALYSIS AND GENERATION
E. FIMBEL, H. GROSCOT, J.M. LANCEL, N. SIMONIN
CAP SOGETI INNOVATION
129, rue de l&apos;Universite
</note>
<sectionHeader confidence="0.524081" genericHeader="abstract">
75007 PARIS
FRANCE
ABSTRACT
</sectionHeader>
<bodyText confidence="0.999695666666667">
The following paper concerns a general scheme
for multilingual text generation, as opposed to
just translation. Our system processes the text
as a whole, from which it extracts a
representation of the meaning of the text. From
this representation, a new text is generated,
using a text model and action rules.
This process is done in six steps : word
analysis, sentence analysis using a Functional
Grammar, reference solving and inference,
construction of the text pattern, sentence
generation, and word generation. Different
kinds of information are used at each step of
the process : text organization, syntax,
semantic, etc.
All the knowledge, as well as the text, is
given in a declarative manner. It is expressed
in a single formalism named Functional
Descriptions. It consists of lexical data, a
Functional Grammar, a knowledge network, action
rules for reference solving and sentence
generation, models of text, rules of
structuration, and sentence schema.
Text representation, included in the semantic
network, is composed of different kinds of
objects (not necessarily distinct) : text
organization, syntactical information, objects
introduced by the discourse, affirmations on
these objects, and links between these
affirmations.
</bodyText>
<sectionHeader confidence="0.993892" genericHeader="method">
1 TEXT VERSUS SENTENCES
</sectionHeader>
<bodyText confidence="0.999977033333334">
Human translation is a complex process whose
activities are not yet entirely understood.
Generation of text differs from generation of
single sentences : our work stresses the
necessary processing of the text as a whole and
restructuring of this text. A translator must on
the one hand rearrange a whole sentence in order
to respect certain stylistic rules and on the
other hand modify the order of these sentences.
Some of them may be deleted and others added.
In any case, in order to be able to generate
a coherent text by means of the information
extracted from a source text, it seems most
important to us to understand what the text is
refering to.
We have restricted our scope to economic
geography texts, taken from a French review
named ATLASECO. These texts deal with industry
and agriculture, involving related concepts
(growth, decline, production, economical
balance.—). Our system parses a french text,
integrates its informative content into a
knowledge base, then generates a new text from
information extracted from this base.
We present in part (2) the text
representation used throughout the process. We
describe in part (3) the knowledge
representation, based on the functional
descriptions. In part (4), we briefly describe
the different steps of the process.
</bodyText>
<sectionHeader confidence="0.954047" genericHeader="method">
2 TEXT REPRESENTATION
</sectionHeader>
<bodyText confidence="0.999947307692308">
A text conveys information by various means.
For example, the order of sentences, as well as
their syntactic structure, may be significant.
The general text representation we use is the
same for understanding and structuring. This
representation includes the different kinds of
information needed for these two processes.
The text is represented by a set of
interrelated objects (sentences, words, semantic
objects...). There are five classes of objects,
not necessarily distinct : the visible objects,
the syntactic components, the discursive objects
(defined later), the affirmations and the links.
</bodyText>
<page confidence="0.996874">
226
</page>
<subsectionHeader confidence="0.923028">
2.1 Visible Objects
</subsectionHeader>
<bodyText confidence="0.9999096">
Visible objects are chapters, paragraphs,
sentences, words and word sequences . They are
related by positional links, describing the
organization of the text, as shown by the
following figure :
</bodyText>
<sectionHeader confidence="0.538619" genericHeader="method">
TEXT
</sectionHeader>
<bodyText confidence="0.924557142857143">
SENTENCE 1 . .FL___,i7NTENCc
OBJ 1 OBJ 2 ..083n au . OFIJ n
fig. 1
These links reflect the hierarchical
organization of the text (chapters and the
dependent relationship of statements (order of
sentences
</bodyText>
<subsectionHeader confidence="0.999374">
2.2 Syntactic Components
</subsectionHeader>
<bodyText confidence="0.798176777777778">
The sentences are represented by means of
unordered &amp;quot;syntactic cases&amp;quot; (subject,
determiner...), linking a component with its
subcomponents. For example :
&amp;quot;the big mouse&amp;quot; I
body determiner qualifier
1 1
mouse definite big
fig. 2
</bodyText>
<subsectionHeader confidence="0.996978">
2.3 Discursive Objects
</subsectionHeader>
<bodyText confidence="0.999489041666667">
Discursive objects represent the semantic
objects or entities introduced by the text. For
example :
&amp;quot;The main crop is wheat, whose production has
strongly decreased. This decline has strongly
affected the commercial balance.&amp;quot;
These two constructions correspond to a
single discursive object, which could be
called : &amp;quot;decrease of the production of wheat&amp;quot; .
The meaning of a sentence is represented by a
network of discursive objects. The propositions,
representing the discursive objects, are
normalized into an objective form. For example :
Peter met John&amp;quot; -&gt; &amp;quot;meeting of John by Peter&amp;quot;
&amp;quot;Mary is ill&amp;quot; -&gt; &amp;quot;illness of Mary&amp;quot;.
This normalization is very useful for co-
reference solving.
The text itself may be a discursive object.
Hence, it is represented by an object which
mentions topic, date and positional links
between sentences of text. During the
Understanding Process, this object will be
enlarged by new information, or modified (for
instance topic may become more explicit).
</bodyText>
<subsectionHeader confidence="0.997086">
2.4 Affirmations
</subsectionHeader>
<bodyText confidence="0.999875555555556">
Implicit within the text, as well as simply
introducing objects, is the evaluation of
certain objects. &amp;quot;The production is increasing&amp;quot;
introduces &amp;quot;the production&amp;quot; and affirms &amp;quot;the
increase of production&amp;quot;.
There are various statement values (&amp;quot;stated
positively in discourse&amp;quot;, &amp;quot;dubious&amp;quot;...). These
values may be given by the author, a figure, an
economical organization, etc.
</bodyText>
<subsectionHeader confidence="0.991569">
2.5 Links
</subsectionHeader>
<bodyText confidence="0.998915">
The links are mainly operators (and, or,
because—) that correlate the affirmations,
which are discursive objects or links : &amp;quot;A
because B&amp;quot; ; &amp;quot;A and B, but C&amp;quot;.
They reflect internal structure of discourse.
For example : &amp;quot;the production increases but the
deficit remains important&amp;quot;.
During Understanding phase, their main role
is to transmit statement values to the objects
they link.
The structuring stage isolates argumentative
effects of the discourse, and builds new links
(possibly the same). The choice of these links
is important because they have to be coherently
acceptable from the reader point of view.
</bodyText>
<sectionHeader confidence="0.998736" genericHeader="method">
3 KNOWLEDGE REPRESENTATION
</sectionHeader>
<bodyText confidence="0.969167">
We use the same representation for all types
of knowledge in the system : lexical
definitions, grammar rules, semantic rules,etc.
They are given separately in the formalism of
functional descriptions and integrated into the
knowledge base that is represented by a
functional descriptions network.
</bodyText>
<page confidence="0.971791">
227
</page>
<bodyText confidence="0.9996294375">
The language of functional descriptions comes
from the functional grammars (DIK 78), which is
a linguistic formalism that can be related to
case grammars (FILLMORE 68). Historically, Kay
(81) used functional descriptions as a general
tool to represent grammars, independently of any
specific linguistic theory, after which
Rousse lot (84) then used functional descriptions
to represent any kind of knowledge (grammar,
semantic rules, scripts—) in a system of story
understanding.
We will use &amp;quot;DF&amp;quot; instead of &amp;quot;functional
description&amp;quot;.
A OF may represent any kind of knowledge. For
example , &amp;quot;William cut himself&amp;quot; may be described
by the following figure :
</bodyText>
<equation confidence="0.9903166">
(action = cut
tense = past
actor = (name = William]
obLact = &lt;1 actor&gt;3
fig. 3
</equation>
<bodyText confidence="0.998154633333333">
A OF is an unordered set of identifier-object
pairs. The identifiers are not pre-defined :
they may be added or removed in any way. This
allows us to put various kinds of information in
the same description : syntactic, semantic, etc.
The objects may be other DFs or paths.
A path is a notation whose aim is to point
to objects that are already defined . We have
two kinds of paths :
A local path &lt;1 list-of-identifier&gt; points to
an object in the current OF, as defined by the
list of identifiers. For example, in fig. 3,
the path &lt;1 actor name&gt; refers to &amp;quot;William&amp;quot;.
A global path, &lt;g starting-point list-of-
identi fiers&gt; points to an object in the
knowledge base. It is defined in the same way
as the local path, except that the starting
point is the current OF.
The internal representation of a OF is a
labelled graph. For example, the representation
of the OF in fig. 3 is shown in fig. 4.
as input and converts it directly into the
labelled graph as shown in fig. 4, which is then
integrated into the knowledge base.
A functional description network is the graph
that represents a set of interlaced DFs, i.e.
the knowledge base. This network is a labelled
graph whose nodes correspond to OEs, and whose
links to elementary object properties. These
links are labelled with identifiers.
</bodyText>
<figure confidence="0.5337805">
colour
table blue
object (DF) property object (DF)
fig. 5
</figure>
<bodyText confidence="0.984634642857143">
Each identifier (e.g. colour) may be given
different properties (e.g. inheritance
properties). This is done through attaching a
node to the identifier.
The graph may contain Dynamic Paths , which
allow access to the objects. A dynamic path is a
function &lt;f starting-point list-of-identifiers&gt;
whose value is a node on the graph. For example,
in fig. 4, the dynamic path &lt;f (M) actor name&gt;
points to the node &amp;quot;William&amp;quot;. Dynamic Paths are
very similar to substituable variables in formal
systems.
The processing of a OF network can be done at
two levels :
</bodyText>
<listItem confidence="0.691736">
- elementary level : insert or delete links
(i.e. properties) or nodes (i.e. objects) ;
- form level : each node of the network can
</listItem>
<figureCaption confidence="0.65789725">
still be viewed as a description, which
corresponds to a complex set of links. This
allows us to work on the form of the
objects (pattern matching and merging).
</figureCaption>
<bodyText confidence="0.842858625">
The main algorithms that operate at the form
level are those of compatibility (pattern
matching) and merging. &amp;quot;Compatilibity&amp;quot; is a
boolean function that decides whether two
descriptions may correspond to the same object
of the real world. For example, could the events
described by &amp;quot;William speaks to himself&amp;quot; also be
described by &amp;quot;Somebody speaks to Ted&amp;quot; ? :
</bodyText>
<figure confidence="0.7854998">
action cut
actor le&amp;quot;---=&apos;&apos;■ William
(N)
obLact
past
</figure>
<figureCaption confidence="0.392733">
fig. 4
</figureCaption>
<bodyText confidence="0.617">
The system takes the OF, as shown in fig. 3,
</bodyText>
<equation confidence="0.916365714285714">
[action = speak
actor = [name = William]
obj-act = &lt;1 actor&gt;]
[action = speak
actor E is-a = human]
obj-act = ( name = Ted]]
fig. 6
</equation>
<page confidence="0.990397">
228
</page>
<bodyText confidence="0.995516714285714">
These two descriptions are not compatible,
because the name of the &amp;quot;obj-act&amp;quot; is &amp;quot;William&amp;quot;
on one hand and &amp;quot;Ted&amp;quot; on the other.
and a dictionary of words and sequences of
words. Each item in the dictionary contains a
semantic definition, its syntactical category,
and its type of inflexion with its roots.
</bodyText>
<equation confidence="0.992506058823529">
&amp;quot;William cut himself &amp;quot;
[action = cut
tense = past
actor = (name = William]
obj-act = &lt;1 actor&gt;]
&amp;quot;X cut Y&amp;quot;
[action = cut
tense = past
actor = [is-a = huma]
obj-act = Estate = changedil
[action = cut
tense = past
actor =r is-a = human
name = William
state = changed]
obj-act = &lt;1 actor&gt;]
fig. 7
</equation>
<bodyText confidence="0.999988090909091">
Two compatible descriptions can be merged.
The result is a new description, more complete
than either of the originals. For example, the
first two DFs of fig. 7 are compatible, and give
the third one as the result of merging.
These two algorithms, inspired by the
functional unification introduced by Kay, are
very powerful and are used at each step of text
processing. Their precise definitions use
mathematical transformations of labelled graphs
and are given in (GROSCOT, ROUSSELOT 85).
</bodyText>
<sectionHeader confidence="0.998957" genericHeader="method">
4 TEXT PROCESSING
</sectionHeader>
<bodyText confidence="0.9990245">
In this section, we describe the following
different steps of the text processing :
</bodyText>
<listItem confidence="0.989542833333333">
- word analysis
- sentence analysis
- reference solving
- construction of the text pattern
- sentence generation
- word generation
</listItem>
<subsectionHeader confidence="0.900431">
4.1 Word Analysis
</subsectionHeader>
<bodyText confidence="0.999168">
The word analyser uses a knowledge base about
the standard inflexions of the initial language
We generate for each word a description of
its syntactic features. All solutions are
generated. For example, the analysis of the word
&amp;quot;burns&amp;quot; gives at least these two DFs :
</bodyText>
<figure confidence="0.8449314">
1) (word burn
number = plural
category = substantive
...
2) [word burn
category = verb
tense present
person = 3
number = singular
fig. 8
</figure>
<subsectionHeader confidence="0.99614">
4.2 Sentence Analysis
</subsectionHeader>
<bodyText confidence="0.995815285714286">
The analyser is based on the work of
Rousselot (84). It works sentence by sentence
and assumes three important functions :
recognition and construction of syntactic
components of a sentence
control of semantic constraints
generation of the semantic representation of
the sentence, i.e. an affirmation or a link
The analyser uses a declarative grammar,
which does not depend upon the way in which the
analyser works. The grammar is a DF, in which
each identifier-object pair represents a grammar
rule. These rules allow the analyser to split a
syntactical category into constituants, to
verify the constraints, and to build the
associated semantic representation.
The analyser works in a top-down manner by
means of an agenda which allows the separation
of the controls. Also included in the analyser
is a graph that contains the partial analysis
which minimizes processing time during the
backtracks.
The starting point of this analyser is the
set of DFs which have been obtained and graphed
after word analysis.
We show here, in an example, the result of
the analysis of the sentence &amp;quot;Agriculture is a
success&amp;quot; :
</bodyText>
<equation confidence="0.906268166666667">
= success
evaluated-object = [object = agriculture
def-undef = definite]
statement-value = true]
fig. 9
[Object
</equation>
<listItem confidence="0.597693">
• 229 •
</listItem>
<subsectionHeader confidence="0.999505">
4.3 Reference Solving
</subsectionHeader>
<bodyText confidence="0.988554409090909">
This stage determines what the pronouns and
noun phrases point to : known objects (already
in the knowledge base), or new objects
introduced (directly or indirectly) by the text.
The process uses action rules, written by
means of DFs. The rules interpreter works in a
&amp;quot;lazy&amp;quot; saturation mode : It locally saturates
the knowledge base regardless of whether or not
all inferences have been made.
The process has three main features :
it is directed by the syntax (definite
articles, pronouns-)
- it identifies the objects at the semantic
level, by testing the compatibility of
discursive objects
- it uses positional links to define the
possible references in each case. For example,
a demonstrative pronoun has to be found among
the preceding objects of the text
It has two important effects :
it constructs a coherent network of discursive
objects (the &amp;quot;meaning&amp;quot; of the text)
</bodyText>
<listItem confidence="0.71983425">
- it integrates the text into the knowledge
base : each time that the text refers to a
known object, links are created from this
object to the text
</listItem>
<subsectionHeader confidence="0.999317">
4.4 Construction of the text pattern
</subsectionHeader>
<bodyText confidence="0.999764820512821">
Once the initial text has been analysed, its
informative content is integrated in the
knowledge base, thereby making it possible to
question this base and to reformulate the so-
obtained information with the aim of generating
a new text.
This stage builds the text structure
(paragraphs, sub-paragraphs, sentences—) using
two complementary approaches : the content of
information and the evolution of the visible
structure of the text. Indeed, text generation
is a reflective process : generation of a single
sentence of the text must take account the
preceding and following text. All the processes
used for structuring are written by means of
rules.
The starting point of structuring is a set of
information extracted from the knowledge
network.
First, all the information is inserted into a
text model by means of their topics. Some
obvious redundancies are eliminated : only one
occurrence will be kept, in the most appropriate
place.
When this is done, the position of the
information, may be inadequate for a coherent
text. Therefore, the text structure is changed :
some information is enhanced ; the paragraphs
are balanced ; the information is reordered
according to chronological order and
significance at the deepest level of the text
structure.
At this step, output text structure is
clearly apparent. But it is not sufficient
because the text has now become a sequence of
unrelated statements. Links are then created
between the discursive objects introduced in the
text (conjunctions, pronouns—) and ellipses
are used to avoid repetitions.
</bodyText>
<subsectionHeader confidence="0.991314">
4.5 Sentence Generation
</subsectionHeader>
<bodyText confidence="0.999902875">
From each DF of the text describing output
information, this stage generates the
description of a suitable sentence.
Syntactic patterns are associated with
concepts (evolutions, appreciations,
numbers—). Action rules combine these patterns
to create the description of a sentence, i.e. a
list of word descriptions.
</bodyText>
<subsectionHeader confidence="0.993287">
4.6 Word Generation
</subsectionHeader>
<bodyText confidence="0.9840615">
Word generation uses the same organization of
the knowledge base (about standard inflexions)
as word analysis.
From a list of word descriptions, including
syntactic features, the system constructs the
output word. For example :
[word burn
cat = verb
tense = present
person 3 --&gt; BURNS
number singulaq
fig. 10
</bodyText>
<sectionHeader confidence="0.999846" genericHeader="method">
5 ANALYSING ECONOMIC GEOGRAPHY TEXTS
</sectionHeader>
<bodyText confidence="0.9999734">
The texts we have analysed, taken from the
French review ATLASECO, describe the main
features of the agriculture in different
countries. They contain an average of 20
sentences, which contain from 10 to 45 words.
</bodyText>
<page confidence="0.978314">
230
</page>
<bodyText confidence="0.977636086956522">
The system used :
- 400 lexical items, which represent 2400 words
- 70 grammar rules
- a semantic network containing 220 concepts, 80
of them being domain-dependant
- 80 semantic rules for inference and reference
solving
- 1 text model, containing 50 paragraphs and
subparagraphs
- 100 rules for text structuring
- 30 sentence patterns for generation
Our system was able to extract the
significant information that such a text
conveys, and produce a new text from this
information. As a matter of convenience, we used
French as the target language for validation,
however the process described here should also
be able to work in a manner independant of the
target language, by chaining certain parts of
the knowledge base.
Now, we are in the process of adapting our
system to generate French appliance operation
manuals from the corresponding ones.
</bodyText>
<sectionHeader confidence="0.989743" genericHeader="method">
REFERENCES
</sectionHeader>
<reference confidence="0.94851484375">
ATLASECO
Atlas dconomique mondial
Le Nouvel Observateur, 1982.
DIK Simon
&amp;quot;Functional Grammar&amp;quot;
Publications in Language Science.
Faris Publications, Dordrecht Holland, 1978.
FILLMORE Charles
&amp;quot;The case for case&amp;quot; in &amp;quot;Universals in
Linguistics Theory&amp;quot;, E. Bach and R. Harms
(eds), p.1-90, 1968.
FIMBEL Eric
&amp;quot;Les reseaux miroirs : un mdcanisme d&apos;infe-
rence general ; application a un systeme
d&apos;assimilation de textes&amp;quot;
These de l&apos;universite Paris 6, mars 1985.
GRIZE Jean-Blaise
&amp;quot;Introduction a la logique naturelle et
approche logique du dialogue&amp;quot;
Approches formelles de la semantique naturelle.
Publication CNRS-UPS-UTM-ADI, 1982.
GROSCOT Herbert, ROUSSELOT Francois
&amp;quot;Un langage declaratif uniforme et un
analyseur syntaxico-semantique&amp;quot;
Proceedings of Cognitive, Paris, juin 1985.
GROSS Maurice
&amp;quot;Mdthodes en syntaxe&amp;quot;
Hermann, 1975.
KAY Martin
&amp;quot;Unification Grammars&amp;quot;
Xerox internal publication, 1981.
McKEOWN Kathleen R.
</reference>
<bodyText confidence="0.860530625">
&amp;quot;Generating natural language text in response
to questions about database structure&amp;quot;
PH.D of the university of Pennsylvania, 1982.
ROUSSELOT Francois
&amp;quot;Realisation d&apos;un programme comprenant des
textes en utilisant un formalisme declaratif
pour representer toutes les connaissances&amp;quot;
These d&apos; état, Paris 6, 1984.
</bodyText>
<sectionHeader confidence="0.897391" genericHeader="method">
SIMONIN Nathalie
</sectionHeader>
<bodyText confidence="0.948088666666667">
&amp;quot;Utilisation d&apos;une expertise pour engendrer
des textes structures en francais&amp;quot;
These de l&apos;universite Paris 6, mars 1985.
</bodyText>
<page confidence="0.996564">
231
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.072235">
<title confidence="0.999907">USING A TEXT MODEL FOR ANALYSIS AND GENERATION</title>
<author confidence="0.999697">E FIMBEL</author>
<author confidence="0.999697">H GROSCOT</author>
<author confidence="0.999697">J M LANCEL</author>
<author confidence="0.999697">N SIMONIN</author>
<affiliation confidence="0.996809">CAP SOGETI INNOVATION</affiliation>
<address confidence="0.901059333333333">129, rue de l&apos;Universite 75007 PARIS FRANCE</address>
<abstract confidence="0.999369206315789">paper concerns a general scheme for multilingual text generation, as opposed to just translation. Our system processes the text as a whole, from which it extracts a representation of the meaning of the text. From this representation, a new text is generated, using a text model and action rules. This process is done in six steps : word analysis, sentence analysis using a Functional Grammar, reference solving and inference, construction of the text pattern, sentence generation, and word generation. Different kinds of information are used at each step of the process : text organization, syntax, semantic, etc. All the knowledge, as well as the text, is given in a declarative manner. It is expressed in a single formalism named Functional Descriptions. It consists of lexical data, a Functional Grammar, a knowledge network, action rules for reference solving and sentence generation, models of text, rules of structuration, and sentence schema. Text representation, included in the semantic network, is composed of different kinds of objects (not necessarily distinct) : text organization, syntactical information, objects introduced by the discourse, affirmations on these objects, and links between these affirmations. 1 TEXT VERSUS SENTENCES translation complex process whose activities are not yet entirely understood. Generation of text differs from generation of single sentences : our work stresses the of the text as a whole and of this text. translator must on the one hand rearrange a whole sentence in order to respect certain stylistic rules and on the other hand modify the order of these sentences. Some of them may be deleted and others added. In any case, in order to be able to generate a coherent text by means of the information extracted from a source text, it seems most important to us to understand what the text is refering to. We have restricted our scope to economic geography texts, taken from a French review named ATLASECO. These texts deal with industry and agriculture, involving related concepts (growth, decline, production, economical balance.—). Our system parses a french text, integrates its informative content into a knowledge base, then generates a new text from information extracted from this base. We present in part (2) the text representation used throughout the process. We in part (3) based on the part we briefly describe the different steps of the process. REPRESENTATION A text conveys information by various means. For example, the order of sentences, as well as their syntactic structure, may be significant. general text representation we use is same for understanding and structuring. This representation includes the different kinds of information needed for these two processes. The text is represented by a set of interrelated objects (sentences, words, semantic objects...). There are five classes of objects, not necessarily distinct : the visible objects, the syntactic components, the discursive objects (defined later), the affirmations and the links. 226 2.1 Visible Objects Visible objects are chapters, paragraphs, sentences, words and word sequences . They are related by positional links, describing the organization of the text, as shown by the following figure : TEXT 1 . 2 n fig. 1 links reflect organization of the text (chapters and the statements (order of sentences 2.2 Syntactic Components The sentences are represented by means of unordered &amp;quot;syntactic cases&amp;quot; (subject, determiner...), linking a component with its subcomponents. For example : &amp;quot;the big mouse&amp;quot; I body determiner qualifier 1 1 mouse definite big fig. 2 2.3 Discursive Objects Discursive objects represent the semantic objects or entities introduced by the text. For example : main crop is wheat, production has decreased. This decline strongly the commercial two constructions correspond to single discursive object, which could be called : &amp;quot;decrease of the production of wheat&amp;quot; . a sentence is represented by a network of discursive objects. The propositions, representing the discursive objects, are into an form. example : Peter met John&amp;quot; -&gt; &amp;quot;meeting of John by Peter&amp;quot; &amp;quot;Mary is ill&amp;quot; -&gt; &amp;quot;illness of Mary&amp;quot;. normalization is useful for coreference solving. itself may discursive Hence, it is represented by an object which topic, date and positional sentences of the Understanding Process, this object will be new information, or modified (for instance topic may become more explicit). 2.4 Affirmations the text, as well simply objects, is the certain objects. &amp;quot;The production is increasing&amp;quot; &amp;quot;the production&amp;quot; and increase of production&amp;quot;. There are various statement values (&amp;quot;stated positively in discourse&amp;quot;, &amp;quot;dubious&amp;quot;...). These values may be given by the author, a figure, an economical organization, etc. 2.5 Links The links are mainly operators (and, or, because—) that correlate the affirmations, which are discursive objects or links : &amp;quot;A B&amp;quot; ; B, but reflect structure discourse. example : &amp;quot;the production increases deficit remains important&amp;quot;. During Understanding phase, their main role is to transmit statement values to the objects they link. The structuring stage isolates argumentative of the discourse, and builds (possibly the same). The choice of these links is important because they have to be coherently acceptable from the reader point of view. 3 KNOWLEDGE REPRESENTATION use same representation for all types knowledge in the system : definitions, grammar rules, semantic rules,etc. They are given separately in the formalism of descriptions integrated into the knowledge base that is represented by a functional descriptions network. 227 The language of functional descriptions comes from the functional grammars (DIK 78), which is a linguistic formalism that can be related to case grammars (FILLMORE 68). Historically, Kay used descriptions a general tool to represent grammars, independently of any specific linguistic theory, after which lot (84) then used descriptions to represent any kind of knowledge (grammar, semantic rules, scripts—) in a system of story understanding. We will use &amp;quot;DF&amp;quot; instead of &amp;quot;functional description&amp;quot;. represent any kind of knowledge. For example , &amp;quot;William cut himself&amp;quot; may be described by the following figure : (action = cut tense = past actor = (name = William] obLact = &lt;1 actor&gt;3 fig. 3 A OF is an unordered set of identifier-object pairs. The identifiers are not pre-defined : they may be added or removed in any way. This allows us to put various kinds of information in the same description : syntactic, semantic, etc. objects may be other DFs or A path is a notation whose aim is to point to objects that are already defined . We have two kinds of paths : A local path &lt;1 list-of-identifier&gt; points to an object in the current OF, as defined by the list of identifiers. For example, in fig. 3, the path &lt;1 actor name&gt; refers to &amp;quot;William&amp;quot;. A global path, &lt;g starting-point list-ofidenti fiers&gt; points to an object in the knowledge base. It is defined in the same way as the local path, except that the starting point is the current OF. The internal representation of a OF is a labelled graph. For example, the representation of the OF in fig. 3 is shown in fig. 4. as input and converts it directly into the labelled graph as shown in fig. 4, which is then integrated into the knowledge base. description network the graph represents a of interlaced DFs, the knowledge base. This network is a labelled graph whose nodes correspond to OEs, and whose links to elementary object properties. These links are labelled with identifiers. colour table blue object (DF) property object (DF) fig. 5 identifier (e.g. be given different properties (e.g. inheritance properties). This is done through attaching a node to the identifier. graph may contain Paths , the objects. A dynamic path is a function &lt;f starting-point list-of-identifiers&gt; whose value is a node on the graph. For example, in fig. 4, the dynamic path &lt;f (M) actor name&gt; points to the node &amp;quot;William&amp;quot;. Dynamic Paths are very similar to substituable variables in formal systems. a OF network can be done at two levels : elementary level : or delete links or nodes ; form level : node of the network can still be viewed as a description, which corresponds to a complex set of links. This us to work on the the objects (pattern matching and merging). The main algorithms that operate at the form are those of and is a boolean function that decides whether two descriptions may correspond to the same object of the real world. For example, could the events described by &amp;quot;William speaks to himself&amp;quot; also be described by &amp;quot;Somebody speaks to Ted&amp;quot; ? : action cut William (N) obLact past fig. 4 The system takes the OF, as shown in fig. 3, [action = speak actor = [name = William] obj-act = &lt;1 actor&gt;] [action = speak = human] obj-act = ( name = Ted]] fig. 6 228 These two descriptions are not compatible, because the name of the &amp;quot;obj-act&amp;quot; is &amp;quot;William&amp;quot; on one hand and &amp;quot;Ted&amp;quot; on the other. and a dictionary of words and sequences of words. Each item in the dictionary contains a semantic definition, its syntactical category, and its type of inflexion with its roots. &amp;quot;William cut himself &amp;quot; [action = cut tense = past actor = (name = William] obj-act = &lt;1 actor&gt;] &amp;quot;X cut Y&amp;quot; [action = cut tense = past actor = [is-a = huma] obj-act = Estate = changedil [action = cut tense = past = human name = William state = changed] obj-act = &lt;1 actor&gt;] fig. 7 Two compatible descriptions can be merged. The result is a new description, more complete than either of the originals. For example, the first two DFs of fig. 7 are compatible, and give the third one as the result of merging. These two algorithms, inspired by the functional unification introduced by Kay, are very powerful and are used at each step of text processing. Their precise definitions use mathematical transformations of labelled graphs and are given in (GROSCOT, ROUSSELOT 85). 4 TEXT PROCESSING In this section, we describe the following different steps of the text processing : word analysis sentence analysis reference solving construction of the text pattern sentence generation word generation 4.1 Word Analysis The word analyser uses a knowledge base about the standard inflexions of the initial language We generate for each word a description of its syntactic features. All solutions are generated. For example, the analysis of the word &amp;quot;burns&amp;quot; gives at least these two DFs : 1) (word burn number = plural category = substantive ... 2) [word burn category = verb tense present person = 3 number = singular fig. 8 4.2 Sentence Analysis The analyser is based on the work of Rousselot (84). It works sentence by sentence and assumes three important functions : recognition and construction of syntactic components of a sentence control of semantic constraints generation of the semantic representation of the sentence, i.e. an affirmation or a link The analyser uses a declarative grammar, which does not depend upon the way in which the analyser works. The grammar is a DF, in which each identifier-object pair represents a grammar rule. These rules allow the analyser to split a syntactical category into constituants, to verify the constraints, and to build the associated semantic representation. The analyser works in a top-down manner by of an allows the separation of the controls. Also included in the analyser a contains the partial analysis which minimizes processing time during the backtracks. The starting point of this analyser is the set of DFs which have been obtained and graphed after word analysis. We show here, in an example, the result of the analysis of the sentence &amp;quot;Agriculture is a success&amp;quot; : = success evaluated-object = [object = agriculture def-undef = definite] statement-value = true] fig. 9 [Object • 229 • 4.3 Reference Solving This stage determines what the pronouns and noun phrases point to : known objects (already in the knowledge base), or new objects introduced (directly or indirectly) by the text. process uses rules, by means of DFs. The rules interpreter works in a &amp;quot;lazy&amp;quot; saturation mode : It locally saturates the knowledge base regardless of whether or not all inferences have been made. The process has three main features : it is directed by the syntax (definite articles, pronouns-) it identifies the objects at the semantic level, by testing the compatibility of discursive objects it uses positional links to define the possible references in each case. For example, a demonstrative pronoun has to be found among the preceding objects of the text It has two important effects : it constructs a coherent network of discursive objects (the &amp;quot;meaning&amp;quot; of the text) it integrates the text into the knowledge base : each time that the text refers to a known object, links are created from this object to the text 4.4 Construction of the text pattern Once the initial text has been analysed, its informative content is integrated in the knowledge base, thereby making it possible to question this base and to reformulate the soobtained information with the aim of generating a new text. This stage builds the text structure (paragraphs, sub-paragraphs, sentences—) using complementary approaches : the and the evolution of the the text. Indeed, text generation is a reflective process : generation of a single sentence of the text must take account the preceding and following text. All the processes used for structuring are written by means of rules. The starting point of structuring is a set of information extracted from the knowledge network. First, all the information is inserted into a text model by means of their topics. Some obvious redundancies are eliminated : only one occurrence will be kept, in the most appropriate place. When this is done, the position of the information, may be inadequate for a coherent text. Therefore, the text structure is changed : some information is enhanced ; the paragraphs are balanced ; the information is reordered according to chronological order and significance at the deepest level of the text structure. At this step, output text structure is clearly apparent. But it is not sufficient because the text has now become a sequence of unrelated statements. Links are then created between the discursive objects introduced in the text (conjunctions, pronouns—) and ellipses are used to avoid repetitions. 4.5 Sentence Generation From each DF of the text describing output information, this stage generates the description of a suitable sentence. Syntactic patterns are associated with concepts (evolutions, appreciations, numbers—). Action rules combine these patterns to create the description of a sentence, i.e. a list of word descriptions. 4.6 Word Generation Word generation uses the same organization of the knowledge base (about standard inflexions) as word analysis. From a list of word descriptions, including syntactic features, the system constructs the output word. For example : [word burn cat = verb tense = present person 3 --&gt; BURNS fig. 10 5 ANALYSING ECONOMIC GEOGRAPHY TEXTS The texts we have analysed, taken from the French review ATLASECO, describe the main features of the agriculture in different countries. They contain an average of 20 sentences, which contain from 10 to 45 words. 230 The system used : - 400 lexical items, which represent 2400 words - 70 grammar rules a semantic network containing 220 concepts, 80 of them being domain-dependant - 80 semantic rules for inference and reference solving - 1 text model, containing 50 paragraphs and subparagraphs - 100 rules for text structuring - 30 sentence patterns for generation Our system was able to extract the significant information that such a text conveys, and produce a new text from this information. As a matter of convenience, we used French as the target language for validation, however the process described here should also be able to work in a manner independant of the target language, by chaining certain parts of the knowledge base. Now, we are in the process of adapting our system to generate French appliance operation manuals from the corresponding ones.</abstract>
<note confidence="0.803499333333333">REFERENCES ATLASECO Atlas dconomique mondial Le Nouvel Observateur, 1982. DIK Simon &amp;quot;Functional Grammar&amp;quot; Publications in Language Science. Faris Publications, Dordrecht Holland, 1978. FILLMORE Charles &amp;quot;The case for case&amp;quot; in &amp;quot;Universals in Linguistics Theory&amp;quot;, E. Bach and R. Harms (eds), p.1-90, 1968.</note>
<title confidence="0.426837">FIMBEL Eric</title>
<abstract confidence="0.9715495">amp;quot;Les reseaux miroirs : un mdcanisme d&apos;inference general ; application a un systeme d&apos;assimilation de textes&amp;quot; These de l&apos;universite Paris 6, mars 1985.</abstract>
<intro confidence="0.966972">GRIZE Jean-Blaise</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<title>Atlas dconomique mondial Le Nouvel Observateur,</title>
<date>1982</date>
<marker>1982</marker>
<rawString>Atlas dconomique mondial Le Nouvel Observateur, 1982.</rawString>
</citation>
<citation valid="true">
<authors>
<author>DIK Simon</author>
</authors>
<title>Functional Grammar&amp;quot; Publications in Language Science.</title>
<date>1978</date>
<publisher>Faris Publications,</publisher>
<location>Dordrecht Holland,</location>
<marker>Simon, 1978</marker>
<rawString>DIK Simon &amp;quot;Functional Grammar&amp;quot; Publications in Language Science. Faris Publications, Dordrecht Holland, 1978.</rawString>
</citation>
<citation valid="false">
<institution>FILLMORE Charles</institution>
<marker></marker>
<rawString>FILLMORE Charles</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Harms</author>
</authors>
<title>The case for case&amp;quot; in &amp;quot;Universals in Linguistics Theory&amp;quot;,</title>
<date>1968</date>
<journal>E. Bach</journal>
<pages>1--90</pages>
<marker>Harms, 1968</marker>
<rawString>&amp;quot;The case for case&amp;quot; in &amp;quot;Universals in Linguistics Theory&amp;quot;, E. Bach and R. Harms (eds), p.1-90, 1968.</rawString>
</citation>
<citation valid="true">
<authors>
<author>FIMBEL Eric</author>
</authors>
<title>Les reseaux miroirs : un mdcanisme d&apos;inference general ; application a un systeme d&apos;assimilation de textes&amp;quot; These de l&apos;universite Paris 6,</title>
<date>1985</date>
<location>mars</location>
<marker>Eric, 1985</marker>
<rawString>FIMBEL Eric &amp;quot;Les reseaux miroirs : un mdcanisme d&apos;inference general ; application a un systeme d&apos;assimilation de textes&amp;quot; These de l&apos;universite Paris 6, mars 1985.</rawString>
</citation>
<citation valid="true">
<authors>
<author>GRIZE Jean-Blaise</author>
</authors>
<title>Introduction a la logique naturelle et approche logique du dialogue&amp;quot; Approches formelles de la semantique naturelle. Publication CNRS-UPS-UTM-ADI,</title>
<date>1982</date>
<marker>Jean-Blaise, 1982</marker>
<rawString>GRIZE Jean-Blaise &amp;quot;Introduction a la logique naturelle et approche logique du dialogue&amp;quot; Approches formelles de la semantique naturelle. Publication CNRS-UPS-UTM-ADI, 1982.</rawString>
</citation>
<citation valid="true">
<authors>
<author>GROSCOT Herbert</author>
</authors>
<title>ROUSSELOT Francois &amp;quot;Un langage declaratif uniforme et un analyseur syntaxico-semantique&amp;quot;</title>
<date>1985</date>
<booktitle>Proceedings of Cognitive,</booktitle>
<location>Paris, juin</location>
<marker>Herbert, 1985</marker>
<rawString>GROSCOT Herbert, ROUSSELOT Francois &amp;quot;Un langage declaratif uniforme et un analyseur syntaxico-semantique&amp;quot; Proceedings of Cognitive, Paris, juin 1985.</rawString>
</citation>
<citation valid="true">
<authors>
<author>GROSS Maurice</author>
</authors>
<title>Mdthodes en syntaxe&amp;quot; Hermann,</title>
<date>1975</date>
<marker>Maurice, 1975</marker>
<rawString>GROSS Maurice &amp;quot;Mdthodes en syntaxe&amp;quot; Hermann, 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>KAY Martin</author>
</authors>
<title>Unification Grammars&amp;quot; Xerox internal publication,</title>
<date>1981</date>
<marker>Martin, 1981</marker>
<rawString>KAY Martin &amp;quot;Unification Grammars&amp;quot; Xerox internal publication, 1981.</rawString>
</citation>
<citation valid="false">
<authors>
<author>McKEOWN Kathleen R</author>
</authors>
<marker>R, </marker>
<rawString>McKEOWN Kathleen R.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>