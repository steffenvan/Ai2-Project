<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.980806">
Hypotheses Selection Criteria in a Reranking Framework for Spoken
Language Understanding
</title>
<author confidence="0.860241">
Marco Dinarelli
</author>
<affiliation confidence="0.479005">
LIMSI-CNRS
</affiliation>
<address confidence="0.649133">
B.P. 133, 91403 Orsay Cedex
France
</address>
<email confidence="0.995498">
marcod@limsi.fr
</email>
<note confidence="0.5718625">
Sophie Rosset
LIMSI-CNRS
</note>
<address confidence="0.592164">
B.P. 133, 91403 Orsay Cedex
France
</address>
<email confidence="0.995354">
rosset@limsi.fr
</email>
<sectionHeader confidence="0.995391" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.997577405405405">
Reranking models have been successfully ap-
plied to many tasks of Natural Language Pro-
cessing. However, there are two aspects of
this approach that need a deeper investiga-
tion: (i) Assessment of hypotheses generated
for reranking at classification phase: baseline
models generate a list of hypotheses and these
are used for reranking without any assess-
ment; (ii) Detection of cases where rerank-
ing models provide a worst result: the best
hypothesis provided by the reranking model
is assumed to be always the best result. In
some cases the reranking model provides an
incorrect hypothesis while the baseline best
hypothesis is correct, especially when base-
line models are accurate. In this paper we
propose solutions for these two aspects: (i)
a semantic inconsistency metric to select pos-
sibly more correct n-best hypotheses, from a
large set generated by an SLU basiline model.
The selected hypotheses are reranked apply-
ing a state-of-the-art model based on Partial
Tree Kernels, which encode SLU hypothe-
ses in Support Vector Machines with com-
plex structured features; (ii) finally, we apply
a decision strategy, based on confidence val-
ues, to select the final hypothesis between the
first ranked hypothesis provided by the base-
line SLU model and the first ranked hypothe-
sis provided by the re-ranker. We show the ef-
fectiveness of these solutions presenting com-
parative results obtained reranking hypothe-
ses generated by a very accurate Conditional
Random Field model. We evaluate our ap-
proach on the French MEDIA corpus. The re-
sults show significant improvements with re-
spect to current state-of-the-art and previous
</bodyText>
<page confidence="0.981115">
1104
</page>
<bodyText confidence="0.460666">
re-ranking models.
</bodyText>
<sectionHeader confidence="0.998929" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9973389">
Discriminative reranking is a widely used approach
for several Natural Language Processing (NLP)
tasks: Syntactic Parsing (Collins, 2000), Named En-
tity Recognition (Collins, 2000; Collins and Duffy,
2001), Semantic Role Labelling (Moschitti et al.,
2008), Machine Translation (Shen et al., 2004),
Question Answering (Moschitti et al., 2007). Re-
cently reranking approaches have been successfully
applied also to Spoken Language Understanding
(SLU) (Dinarelli et al., 2009b).
Discriminative Reranking combines two models:
a first SLU model is used to generate a ranked list
of n-best hypotheses; a reranking model sorts the
list based on a different score and the final result
is the new top ranked hypothesis. The advantage of
reranking approaches is in the possibility to learn di-
rectly complex dependencies in the output domain,
as this is provided in the hypotheses generated by
the baseline model.
In previous approaches complex features are ex-
tracted from the hypotheses for both training and
classification phase, but there are very few stud-
ies on approaches that can be applied to search in
the hypotheses space generated by the baseline SLU
model. Moreover, to keep overall computational
cost reasonable, the size of the n-best list is typically
small (few tens). This is a limitation since the larger
is the hypotheses space generated, the more likely is
to find a better hypothesis. On the other hand, re-
ranking a large set of hypotheses is computationally
</bodyText>
<note confidence="0.948354">
Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1104–1115,
Edinburgh, Scotland, UK, July 27–31, 2011. c�2011 Association for Computational Linguistics
</note>
<bodyText confidence="0.99990043902439">
expensive, thus a strategy to select the best hypothe-
ses to be re-ranked would overcome this problem.
Another aspect of reranking that deserves to be
deeper studied is its applicability. Although a
reranking model improves the baseline model in the
overall performance, in some cases the reranked best
hypotheses can contain more mistakes than the base-
line best hypothesis. A strategy to decide when the
reranking model should be applied and when the
first hypothesis of the baseline model is more accu-
rate would improve reranking performances.
In this paper, we propose two new models for
improving discriminative reranking: (a) a seman-
tic inconsistency metric that can be applied to SLU
hypotheses to select those that are more likely to
be correct; (b) a model selection strategy based on
the confidence scores provided by the baseline SLU
model and the reranker. This provides a decision
function that detects if the original top ranked hy-
pothesis is more accurate than the reranked best hy-
pothesis.
Our re-ranking strategies turn out to be effective
on very accurate baseline models based on state-of-
the-art Conditinal Random Fields (CRF) implemen-
tation (Lavergne et al., 2010). We evaluate our ap-
proach on the well-known French MEDIA corpus
for SLU (Bonneau-Maynard et al., 2006). The re-
sults show that our approach significantly improves
both “traditional” reranking approaches and state-
of-the-art SLU models.
The remainder of the paper is organized as fol-
lows: in Section 2 we introduce the SLU task. Sec-
tion 3 describes our discriminative reranking frame-
work for SLU, in particular the baseline model
adopted, in sub-section 3.1, and the reranking
model, in sub-section 3.2. Section 4 describes
the two strategies proposed in this paper for SLU
reranking, whereas the experiments to evaluate our
approaches are described in Section 5. Finally, after
a discussion in Section 6, in Section 7 we draw some
conclusions.
</bodyText>
<sectionHeader confidence="0.987496" genericHeader="method">
2 Spoken Language Understanding
</sectionHeader>
<bodyText confidence="0.999921833333333">
Spoken Language Understanding is the task of rep-
resenting and extracting the meaning of natural lan-
guage sentences. Designing a general meaning rep-
resentation which can capture the semantics of a
spoken language is very complex. Therefore, in
practice, the meaning representations depend on the
specific application domain being modeled.
For the corpus used in this work, the semantic rep-
resentation is defined in an ontology described in
(Bonneau-Maynard et al., 2006). As an example,
given the following natural language sentence trans-
lated from the MEDIA corpus:
</bodyText>
<figure confidence="0.2496753">
“Good morning I would like to book an hotel room in Lon-
don”
The semantic representation extraction for the
SLU task is performed in two steps:
1. Automatic Concept Labeling
Null{Good morning} command-task{I would like to book}
object-bd{an hotel room} localization-city{in London}
2. Attribute-Value Extraction
command-task[reservation] object-bd[hotel] localization-
city[London]
</figure>
<bodyText confidence="0.993886344827586">
command-task, object-bd and localization-city
are three domain concepts, called also “attributes”,
defined in the ontology and Null is the concept for
words not associated to any concept. As shown in
the example, Null concepts are removed from the fi-
nal output since they don’t bring any semantic con-
tent with respect to the application domain. reserva-
tion, hotel and London are the normalized attribute
values, defined also in the application ontology. This
representation is usually called attribute-value repre-
sentation.
In the last decade several probabilistic models
have been proposed for the Automatic Concept La-
beling step: in (Raymond et al., 2006) a conceptual
language model encoded in Stochastic Finite State
Transducers (SFST) is proposed. In (Raymond and
Riccardi, 2007), the SFST-based model is compared
with Support Vector Machines (SVM) (Vapnik,
1998) and Conditional Random Fields (CRF) (Laf-
ferty et al., 2001). Moreover, in (Hahn et al., 2008a)
two more models are applied to SLU: a Maximum
Entropy (EM) model and a model coming from
the Statistical Machine Translation (SMT) commu-
nity (it is actually a log-linear combination of SMT
models). Among these models, CRF has shown in
general superior performances on sequence labeling
tasks like Named Entity Recognition (NER) (Tjong
Kim Sang and De Meulder, 2003), Grapheme-to-
Phoneme transcription (Sejnowski and Rosenberg,
</bodyText>
<page confidence="0.988309">
1105
</page>
<bodyText confidence="0.990935551724138">
1987) and also Spoken Language Understanding
(Hahn et al., 2008a).
In addition to individual systems, more recently
also some system combination approaches have
been tried on SLU. In (Hahn et al., 2010), two such
approaches are compared, one based on weighted
ROVER (Fiscus, 1997) while the other is the rerank-
ing approach proposed in (Dinarelli et al., 2009b).
Both system combination approaches are applied on
the MEDIA corpus, thus we will refer to (Hahn et
al., 2010) for a comparison with our approach.
Like the other tasks mentioned above, SLU is usu-
ally a supervised learning task, this means that mod-
els are learned from annotated data. This is an im-
portant aspect to take into account when designing
SLU systems. In this respect accurate SLU models
can in part alleviate the problem of manually anno-
tating data.
The second step of SLU, that is Attribute Value
Extraction (from now on AVE) is performed with
two approaches: a) Rule-based approaches apply
Regular Expressions (RE) to map the words realiz-
ing a concept into a normalized value. Regular ex-
pressions are defined for each attribute-value pair.
Given a concept and its realizing surface form, if a
RE for that concept matches the surface, the corre-
sponding value is returned.
An example of surfaces that can be mapped into
the value hotel given the concept object-bd is:
</bodyText>
<listItem confidence="0.9871115">
1. an hotel room
2. a hotel room
3. the hotel
...
</listItem>
<bodyText confidence="0.970286">
Note that these surfaces share the same keyword
for the concept object-bd, which is “hotel”. Thus,
a possible rule extracted from data, for the concept
object-bd can be:
</bodyText>
<equation confidence="0.931288166666667">
Robject−bd(S) =
if S = “an hotel room” or
S = “a hotel room” or
S = “the hotel” then
return “hotel”
end
</equation>
<bodyText confidence="0.998612388888889">
This kind of rules can be easily refined using reg-
ular expressions, so that they can capture all possible
linguistic patterns containing the triggering keyword
(“hotel” in the example).
b) The other approach used for attribute value ex-
traction is based on probabilistic models. In this case
the model learns from data the conditional probabil-
ity of values V , given the concept C and the cor-
responding sequence of words W realizing the con-
cept: P(V |W, C).
The most meaningful work about AVE ap-
proaches in SLU tasks is (Hahn et al., 2010).
The model used in this work for Automatic Con-
cept Labeling is based on CRF. For the Attribute-
Value Extraction phase we use a combination of
rule based and probabilistic approaches. The first
is made of regular expressions, as explained above.
The probabilistic approach is based again on CRF.
</bodyText>
<sectionHeader confidence="0.995662" genericHeader="method">
3 Reranking Framework
</sectionHeader>
<bodyText confidence="0.9997365">
This section describes the different models involved
in the pipeline realising our reranking framework:
</bodyText>
<listItem confidence="0.922496">
• Conditional Random Fields
• Semantic Inconsistency Metric for hypotheses
selection, which is optional and is applied only
at the classification phase
• Support Vector Machines with Partial Tree Ker-
nel
• Decision Strategy to detect when the top ranked
hypothesis of the baseline model is more accu-
rate than the reranked best hypothesis
</listItem>
<bodyText confidence="0.999945363636364">
It is important to underline that the phases in-
volved in the reranking framewrok are distinguished
for a matter of clarity. In principle, the phases
from the hypotheses selection to the last, the deci-
sion strategy, can be thought of as a whole reranking
model.
In the next two subsection we describe the two
models used for hypotheses generation and for
reranking: CRF and SVM with kernel methods. The
two improvements proposed in this paper and listed
above are presented in a dedicated section (4).
</bodyText>
<subsectionHeader confidence="0.999547">
3.1 Conditional Random Fields
</subsectionHeader>
<bodyText confidence="0.9999878">
CRFs have been proposed for the first time for se-
quence segmentation and labeling tasks in (Lafferty
et al., 2001). This model belongs to the family of
exponential or log-linear models. Its main charac-
teristics are the possibility to include a huge number
</bodyText>
<page confidence="0.964071">
1106
</page>
<bodyText confidence="0.996997">
of features, like the Maximum Entropy (ME) model,
but computing global conditional probabilities nor-
malized at sentence level, instead of position level
like in ME. In particular this last point results very
effective since it solves the label bias problem, as
pointed out in (Lafferty et al., 2001).
Given a sequence of N words W1N = w1, ..., wN
and its corresponding sequence of concepts CN1 =
c1, ..., cN, CRF trains the conditional probabilities
</bodyText>
<equation confidence="0.9907085">
HN
P(CN 1 |W1 N ) = 1
Z n=1
(1)
</equation>
<bodyText confidence="0.950592285714286">
where Am are the training parameters.
hm(cn−1, cn, wn+2
n−2) are the feature functions
capturing conditional dependencies of concepts and
words. Z is a probability normalization factor in
order to model well defined probability distribution:
H(˜cn−1, ˜cn, wn+2
</bodyText>
<equation confidence="0.757623">
n−2) (2)
</equation>
<bodyText confidence="0.928152666666667">
here &amp;quot;cn−1 and &amp;quot;cn are the concepts hypoth-
esized for the previous and current words,
H(&amp;quot;cn−1, &amp;quot;cn, wn+2
</bodyText>
<equation confidence="0.853872">
n−2) is an abbreviation for
EMm=1 Am · hm(cn−1, cn, wn+2
n−2).
</equation>
<bodyText confidence="0.999221611111111">
The CRF model used for the Attribute-Value Ex-
traction phase learns in the same way the conditional
probability P(V1N|CN1 ,W1N). In particular we use
attributes-words concatenations on the source side
and attribute values on the target side.
Two particular effective implementations of CRFs
have been recently proposed. One is described in
(Hahn et al., 2009) and uses a margin based criterion
for probabilities estimation. The other is described
in (Lavergne et al., 2010) and has been implemented
in the software wapiti1. The latter solution in partic-
ular trains the model using two different regulariza-
tion factors at the same time:
Gaussian prior, used as l2 regularization and used
in many softwares to avoid overfitting;
Laplacian prior, used as l1 regularization (Riezler
and Vasserman, 2010), which has the effect to filter
out features with very low scores.
</bodyText>
<footnote confidence="0.985494">
1available at http://wapiti.limsi.fr
</footnote>
<bodyText confidence="0.99995">
The two regularization parameters are used to-
gether in the model implementing the so-called elas-
tic net regularization (Zou and Hastie, 2005):
</bodyText>
<equation confidence="0.970869">
l(λ) + ρ1kλk1 + ρ22 kλk2 (3)
2
</equation>
<bodyText confidence="0.999986555555556">
A is the set of parameters of the model introduced
in equation 1, l(A) is the minus-logarithm of equa-
tion 1, used as loss function for training CRF. IIAII1
and IIAII2 are the l1 and l2 regularization, respec-
tively, while p1 and p2 are two parameters that can
be optimized as usual on development data or with
cross validation.
As explained in (Lavergne et al., 2010), using l1
regularization is an effective way for feature selec-
tion in CRF at training time. Note that other ap-
proaches have been proposed for feature selection,
e.g. in (McCallum, 2003). This type of features se-
lection, performed directly at training time, yields
very accurate models, since only the most meaning-
ful features are kept in the final model, which guar-
antee a strong robustness on unseen data.
In this work we refer in particular to the CRF im-
plementation described in (Lavergne et al., 2010).
</bodyText>
<subsectionHeader confidence="0.998739">
3.2 SVM and Kernel Methods
</subsectionHeader>
<bodyText confidence="0.999788909090909">
Our reranking model is based on SVM (Vapnik,
1998) with the use of the Partial Tree Kernel defined
in (Moschitti, 2006).
SVMs are well-known machine learning algo-
rithms belonging to the class of maximal-margin lin-
ear classifiers (Vapnik, 1998). The model represents
a hyperplane which separates the training examples
with a maximum margin. The hyperplane is learned
using optimization theory and is represented in the
dual form as a linear combination of training exam-
ples:
</bodyText>
<equation confidence="0.904799">
i=1..l yiαixix + b = 0,
</equation>
<bodyText confidence="0.999769444444444">
where xi, i E [1,.., l] are training examples rep-
resenting objects oi and o in any feature space, yi is
the label associated with xi and αi are the lagrange
multipliers. The dual form of the hyperplane shows
that SVM training depends on the inner product be-
tween instances. Kernel methods theory (Shawe-
Taylor and Cristianini, 2004), allows us to substitute
the inner product with a so-called kernel function,
computing the same result: K(oi, o) = xi · x.
</bodyText>
<equation confidence="0.9755069">
n+2
λm · hm (cn−1 cn, wn−2)
M
exp E
m=1
N
H
n=1
EZ =
˜cN1
</equation>
<page confidence="0.894622">
1107
</page>
<bodyText confidence="0.999977888888889">
The interesting aspect of using such formulation
is the possibility to compare objects in arbitrar-
ily complex feature spaces implicitly, i.e. without
knowing the features to be used. Since in real world
scenarios data cannot be classified using a simple
linear classifier, kernel methods can be used to carry
out learning in complex feature spaces. In this work
we use the Partial Tree Kernel (PTK) (Moschitti,
2006).
</bodyText>
<subsectionHeader confidence="0.996153">
3.3 Reranking Model
</subsectionHeader>
<bodyText confidence="0.999698771929825">
In order to give an effective representation to SLU
hypotheses in SVM, since we are using PTK, we
need to represent as trees SLU hypotheses like the
one described in section 2.
This problem is easily solved by transforming the
hypotheses into trees like the one depicted in fig-
ure 1. Although there may be more formal solutions
to represent semantic information of SLU hypothe-
ses as trees, we would like to remark that the tree
structure shown in figure 1 contains all the key in-
formation needed for our purposes: the first level of
the tree represents the concept sequence annotated
on surface form. The second level of the tree al-
low to implicitly represent the segmentation of each
concept, while the third level, i.e. the leaves, are the
input words. Moreover, from figure 1 we removed
word categories associated to words in order to keep
the figure readable. Word categories are provided
together with the corpus as an application knowl-
edge base. They comprise domain categories like
city names, hotel names, street names etc., and some
domain independent categories like numbers, dates,
months etc. The categories are used at the same level
of words, they provide a generalization over words
and alleviate the effect of Out-of-Vocabulary (OOV)
words.
The CRF model used as baseline generates the
n most likely conceptual annotations for each input
sentence. These are ranked by the global conditional
probability of the concept sequence, given the input
word sequence of CRF. The n-best list produced by
the baseline model is the list of candidate hypotheses
H1, H2, .., Hn used in the reranking step.
The candidate hypotheses are organized into
pairs, e.g. (H1, H2) or (H1, H3). We build train-
ing pairs such that a reranker can learn to select the
best one between the two hypotheses in a pair, i.e.
the more correct hypothesis with respect to a refer-
ence annotation and a given metric. In particular,
we compute the edit distance of each hypothesis in
the list, with respect to the manual annotation taken
from the corpus. The best hypothesis Hb is used
to build positive instances for the reranker as pairs
(Hb, Hi) for i E [1..n] and i =� b, negative instances
are built as (Hi, Hb), with same constraints on index
i. This means that, if n hypotheses are generated for
a sentence, 2 · n instances are generated from them.
Note that by construction of pairs the model is sym-
metric, this provides a property that will be exploited
at classification phase, as described in (Shen et al.,
2003b).
Hypotheses are then converted into trees like the
one shown in figure 1. Pairs of trees ek = (ti,k, tj,k),
for k varying along all the training or classification
instances, are given as input to the SVM model to
train the reranker using the following reranking ker-
nel:
</bodyText>
<equation confidence="0.999925">
KR(e1, e2) = PTK(t1,1, t1,2) + PTK(t2,1, t2,2) (4)
− PTK(t1,1, t2,2) − PTK(t2,1,t1,2),
</equation>
<bodyText confidence="0.999982826086957">
where e1 and e2 are two pairs of trees to be com-
pared.
The reranking kernel in equation 4, consisting in
summing four different kernels, has been proposed
in (Shen et al., 2003b) for syntactic parsing rerank-
ing, where the basic kernel was a Tree Kernel, and
the idea was taken in turn from (Heibrich et al.,
2000), where pairs where used to learn preference
ranking. The same idea appears also, in a slightly
different form, in early work about reranking, e.g.
(Collins and Duffy, 2002). The same reranking
schema has been used also in (Shen et al., 2004)
for reranking different candidate hypotheses for ma-
chine translation.
For classification, observing that the model is
symmetric and exploiting kernel properties, we can
use, as classification instances, simple hypotheses
instead of pairs. More precisely we use pairs where
the second hypothesis is empty, i.e. (Hi, 0), for
i E [1..n]. This simplification allow a relatively fast
classification phase, since only n instances are gen-
erated for each sentence, instead of n2. This simpli-
fication has been proposed in (Shen et al., 2003b).
</bodyText>
<page confidence="0.992989">
1108
</page>
<figureCaption confidence="0.998462">
Figure 1: An example of semantic tree constructed from an SLU hypothesis from the MEDIA corpus and used in PTK
</figureCaption>
<sectionHeader confidence="0.987609" genericHeader="method">
4 Hypotheses Selection Criteria
</sectionHeader>
<bodyText confidence="0.999991181818182">
This section describes the main contribution of our
work: first, a semantic inconsistency metric based
on the AVE phase of SLU and allowing to select hy-
potheses generated by the baseline model; second, a
strategy to decide, after the reranking phase, if it is
more likely that the baseline best hypothesis is more
accurate than the best reranked hypothesis and al-
lowing to recover the mistake. Similar ideas have
been proposed in (Dinarelli et al., 2010), here we
propose a significant evolution and we give a much
wider description and evaluation.
</bodyText>
<subsectionHeader confidence="0.993569">
4.1 Hypotheses Selection via Attribute Value
Extraction (AVE)
</subsectionHeader>
<bodyText confidence="0.994234294117647">
In previous reranking approaches (Collins, 2000;
Collins and Duffy, 2002; Shen et al., 2003a; Shen
et al., 2003b; Shen et al., 2004; Collins and Koo,
2005; Kudo et al., 2005; Dinarelli et al., 2009b), few
hypotheses are generated with the baseline model,
ranked by the model probability. These are then
used for the reranking model. An interesting strat-
egy to improve reranking performance is the selec-
tion of the best set of hypotheses to be reranked.
In this work we propose a semantic inconsistency
metric (SIM) based on the attribute-value extraction
phase that allows to select better n-best hypotheses.
We combine the scores provided by the rule based
approach and the CRF approach for AVE, comput-
ing a confidence measure.
The rule-based approach for AVE is defined by
a set of rules that map concepts and their realiz-
ing words into the corresponding value. The rules
are extracted from the training data, thus they are
defined to extract correct values from well formed
phrases annotated with correct concepts. This means
that when the corresponding words are annotated
with a wrong concept, the extracted value will prob-
ably be wrong. We use this property to compute a
semantic inconsistency value for hypotheses, which
in turn allows to select hypotheses with higher prob-
abilities to be correct.
We show the application of SIM using the same
example of Section 2. For space issues we ab-
breviate command-task with com-task, object-bd
with obj-bd and localization-city with loc-city. We
also suppose to have already removed Null concepts.
From the same sentence, the three first hypotheses
that may be generated by the baseline model are:
</bodyText>
<listItem confidence="0.999256">
1. obj-bd{I would like to book} obj-bd{an hotel room} loc-
city{in London}
2. com-task{I would like to book} obj-bd{an hotel room} loc-
city{in London}
3. com-task{I would like to book} obj-bd{an hotel} obj-
bd{room} loc-city{in London}
</listItem>
<bodyText confidence="0.5879405">
Two of these annotations show typical errors of an
SLU model:
(i) wrong concepts annotation: in the first hypothe-
sis the phrase “I would like to book” is erroneously
annotated as obj-bd;
(ii) wrong concept segmentation: in the third hy-
pothesis the phrase “an hotel room” is split in two
concepts.
If we apply the AVE module to these hypotheses
the result is:
</bodyText>
<listItem confidence="0.989831">
1. obj-bd[] obj-bd[hotel] loc-city[london]
2. cmd-task[reservation] obj-bd[hotel] loc-city[london]
3. cmd-task[reservation] obj-bd[hotel] obj-bd[] loc-city[london]
</listItem>
<bodyText confidence="0.999265">
As we can see the first concept obj-bd in the first
hypothesis has an empty value since it was incor-
rectly annotated and, therefore, it is not supported
</bodyText>
<page confidence="0.99129">
1109
</page>
<table confidence="0.999056285714286">
MEDIA training dev test
# sentences 12,908 1,259 3,005
words concepts words concepts words concepts
# tokens 94,466 43,078 10,849 4,705 25,606 11,383
# vocabulary 2,210 99 838 66 1,276 78
# singletons 798 16 338 4 494 10
# OOV rate [%] – – 1.33 0.02 1.39 0.04
</table>
<tableCaption confidence="0.999918">
Table 1: Statistics of the MEDIA training and evaluation sets used for all experiments.
</tableCaption>
<bodyText confidence="0.98750092">
by words from which the AVE module can extract
a correct value. In this case, the output of AVE is
empty. In the same way, in the third hypothesis, the
AVE module cannot extract a correct value from the
phrase “room” since it doesn’t contain any keyword
for a obj-bd concept.
For each hypothesis, our SIM simply counts the
number of wrong (or empty) values. In the example
above, we have 1, 0 and 1 for the three hypothe-
sis, respectively. Accordingly, the most accurate hy-
pothesis under SIM is the second, which is also the
correct one.
In order to combine the SIM score computed by
the rule-based AVE module with the score provided
by the CRF AVE model, we consider per-concept
scores from both approaches. In particular, we for-
malize the definition of the SIM metric above on a
concept ci as SIM(ci,w1,...,m
i ). The value of SIM
is simply 0 if the rule-based AVE module can extract
a value from the surface form w1,...,m realizing the
i
concept ci. 1 otherwise. For each concept in a hy-
pothesis, we compute its semantic consistency s(ci)
as
</bodyText>
<equation confidence="0.998938">
P (vi|ci,w1,...,m
i )(5 )
s(ci) = 1
SIM(ci, wi,...,m ) + 1
</equation>
<bodyText confidence="0.957508272727273">
where P(vi|ci,w1,...,m
i ) is the conditional prob-
ability output by the CRF model for the value vi,
given the concept ci and its realizing surface w1,...,m .
i
Equation 5 means that the CRF score provided for a
given value is halved if SIM returns 1, i.e. if the
AVE module cannot extract any value. Otherwise
the score output by the CRF AVE model is kept
unchanged. The semantic inconsistency metric of
an hypothesis Hk containing the concept sequence
</bodyText>
<equation confidence="0.9812195">
CN1 = c1, ..., cN is then defined as
N
S(Hk) = s(ci) (6)
i=1
</equation>
<bodyText confidence="0.997948142857143">
Using S(Hk) as semantic inconsistency metric,
we generate a huge number of hypotheses with the
baseline model and we select only the top n-best. We
use these hypotheses in the discriminative reranking
model, instead of the original n-best generated by
the CRF model. For simplicity, in general context
we denote S(Hk) as SIM.
</bodyText>
<subsectionHeader confidence="0.995189">
4.2 Wrong Rerank Rejection
</subsectionHeader>
<bodyText confidence="0.999949322580645">
After the reranking model is applied, the first hy-
pothesis is selected as final result. This choice as-
sumes that the new hypothesis is more accurate than
the one provided by the baseline model. In gen-
eral this assumption is not true. Indeed, a reranking
model must be carefully tuned in order to correctly
rerank wrong first best hypotheses but keeping the
original baseline best for correct hypotheses. When
the baseline model is relatively accurate, the latter
case occurs in most of the cases. In this situation it
becomes hard to train an accurate reranking model.
Our idea to overcome this problem is to apply the
reranking model and then post-process results to de-
tect when the original best hypothesis is actually bet-
ter than the reranked best.
For this purpose we propose a simple strategy
based on the scores computed by the two models in-
volved in reranking: CRF for the baseline and SVM
with PTK for reranking.
Let Hcrf and HRR be the best hypothesis of the
CRF and reranking (RR) models, respectively. Let
Scrf(Hcrf) and Scrf(HRR) be the scores of the
CRF model for Hcrf and HRR. In the same way,
let SRR(Hcrf) and SRR(HRR) be the scores of the
reranking model on the same hypotheses. We define
the confidence margin of the CRF model the quan-
tity: Mcrf = Scrf(Hcrf) − Scrf(HRR).
In the same way we define the confidence mar-
gin of the RR model: MRR = SRR(Hcrf) −
SRR(HRR).
We compute two thresholds Tcrf and TRR for the
</bodyText>
<page confidence="0.989135">
1110
</page>
<table confidence="0.99998625">
Average score Feature type
0.0528186 Pref2
0.044189 CATEGORY-2
0.0355579 CATEGORY
0.0354006 Pref3-2
0.0338949 Pref4-2
0.0332647 Suff3-2
0.0314831 Suff2
0.030613 Suff4-2
... ...
0.0165602 Suff1
0.000579602 Pref1
</table>
<tableCaption confidence="0.987972">
Table 2: Ranks of average score given by the CRF model to feature
types
</tableCaption>
<bodyText confidence="0.999126">
two margins with respect to error rate minimization
(with a “line search” algorithm).
We select the final best interpretation hypothesis
for a given sentence with the decision function:
</bodyText>
<equation confidence="0.636745">
BestHypothesis =
</equation>
<bodyText confidence="0.999808333333333">
Since this strategy allows to recover from rerank-
ing mistakes, we call it Wrong Rerank Rejection
(WRR).
</bodyText>
<sectionHeader confidence="0.999542" genericHeader="method">
5 Experiments
</sectionHeader>
<bodyText confidence="0.997605523809524">
The data used in our experiments are taken from
the French MEDIA corpus (Bonneau-Maynard et
al., 2006). The corpus is made of 1.250 Human-
Machine dialogs acquired with a Wizard-of-Oz ap-
proach in the domain of informtation and reservation
of French hotels. The data are split into training, de-
velopment and test set. Statistics of the corpus are
presented in table 1.
For our CRF models, both Automatic ConceptAn-
notation and Attribute Value Extraction SLU phases,
we used wapiti2 (Lavergne et al., 2010). The CRF
model for the first SLU phase integrates a tradi-
tional set of features like word prefixes and suffixes
(of length up to 5), plus some Yes/No features like
“Does the word start with capital letter ?”, “Does
the word contain non alphanumeric characters ?”,
“Is the word preceded by non alphanumeric char-
acteris ?” etc. The CRF model for AVE integrates
only words, prefixes and suffixes (length 3 and 4)
concatenated with concepts. Since in this case la-
bels are attribute values, which are a huge set with
</bodyText>
<footnote confidence="0.8662">
available at http://wapiti.limsi.fr
</footnote>
<table confidence="0.9952405">
MEDIA Text Input DEV TEST
Model Attr Attr+Val Attr Attr+Val
CRF 12.1% 14.8% 11.5% 13.8%
CRF+RR 12.0% 14.6% 11.5% 13.7%
CRF+RRSIM 11.7% 13.9% 11.3% 13.4%
CRF+RRWRR 11.2% 13.4% 11.3% 13.0%
</table>
<tableCaption confidence="0.979961">
Table 3: Results of baseline CRF model and reranking models on
MEDIA text input
</tableCaption>
<bodyText confidence="0.999919125">
respect to concepts (˜700 VS 99), using a lot of fea-
tures would make model training problematic. De-
spite the reduced set of features, training error rate
at both token and sentence level is under 1%. We
didn’t carry out optimization for parameters ρ1 and
ρ2 of the elastic net (see section 3.1), default values
lead in most cases to very accurate models.
Reranking models based on SVM and PTK have
been trained with “SVM-Light-TK”3. Kernel param-
eters M and SVM parameter C have been optimized
on the development set, as well as thresholds for the
WRR (see section 4.2).
Concerning hypotheses generation, for training
we generate 100 hypotheses, we select the best with
respect to the edit distance and the reference anno-
tation and we keep a total of 10 hypotheses to build
pairs. For classification, with the “standard” rerank-
ing approach we generate and we keep the 10 best
hypotheses. While using SIM for hypotheses selec-
tion, we generate 1.000 hypotheses and we keep the
10 best with respect to SIM. 1.000 is the best thresh-
old between oracle accuracy and computational cost
for evaluating the hypotheses.
Experiments have been performed on both man-
ual and automatic transcriptions of dialog turns. For
automatic transcriptions the WER of the ASR is
30.3% on development set and 31.4% on test set.
All results are reported in terms of Concept Er-
ror Rate (CER), which is the same as WER, but it is
computed on concept sequences. In all cases we give
results for both attributes only and attributes and val-
ues extraction
</bodyText>
<subsectionHeader confidence="0.755645">
5.1 Results
</subsectionHeader>
<bodyText confidence="0.98718925">
In order to understand feature relevance, in table 2
we report feature types ranked by the average score
given by the CRF model. Each type correspond to
features at any position with respect to the target
</bodyText>
<footnote confidence="0.706093333333333">
3available at http://disi.unitn.it/moschitti/Tree-Kernel.htm
r HRR if Mcrf ≤ Zcrf and MRR ≥ ZRR
Cl Hcrf otherwise.
</footnote>
<page confidence="0.947839">
1111
</page>
<figure confidence="0.9710405">
(a) M kernel parameter VS CER (on (b) C SVM parameter VS training time (c) C SVM parameter VS CER (on
attribute-value extraction) attribute-value extraction)
</figure>
<figureCaption confidence="0.995075">
Figure 2: Optimization of the PTK M parameter and C parameter of SVM
</figureCaption>
<table confidence="0.9994785">
MEDIA Speech Input DEV TEST
Model Attr Attr+Val Attr Attr+Val
CRF 24.1% 29.1% 23.7% 27.6%
CRF+RR 23.9% 29.1% 23.5% 27.6%
CRF+RRSIm 23.9% 28.3% 23.2% 26.8%
CRF+RRWRR 23.3% 27.5% 22.7% 26.1%
</table>
<tableCaption confidence="0.960722">
Table 4: Results of baseline CRF model and reranking models on
MEDIA speech input
</tableCaption>
<bodyText confidence="0.999468125">
word, with label unigrams. In contrast observation
unigrams are distinguished from bigrams using suf-
fixes -1 and -2 respectively. Feature types wrd are
words converted to lower case, Wrd are words kept
with original capitalization. Feature types Pren are
word prefixes of length n, Suf n are word suffixes of
length n. CATEGORY features are word categories
(see section 3.3). As we can see from the table,
although feature relevance depends of course from
the task, surprisingly word prefixes of length 2 are
the most meaningful features. As expected, CATE-
GORY features are also very relevant features, since
they provide a strong generalization over words. An-
other expected outcome is the fact that prefixes and
suffixes of length 1 are the least relevant features.
In figure 2(a), 2(b) and 2(c) we show the curves
resulting from optimization of parameters of rerank-
ing models. In particular we optimized the M kernel
parameter (µ decay factor, see (Moschitti, 2006) for
details), and the C SVM parameter, i.e. the scale
factor for the soft margin (please refer to (Vapnik,
1998) for SVM details). Figure 2(b) shows the learn-
ing time as a function of the C SVM parameter. This
gives an idea of how long takes training our rerank-
ing models.
In table 3 and 4 we report comparative results
over the baseline CRF model, the baseline rerank-
ing model (CRF+RR) and the reranking models ob-
tained applying the two improvements proposed in
this work (CRF+RRSIM and CRF+RRWRR). As
we can see, the baseline reranking model does not
improve significantly the baseline CRF model. This
outcome is expected since we don’t use any other in-
formation in the reranking model than the semantic
tree shown in figure 1. Previous approaches like for
example (Collins and Duffy, 2002), use the baseline
model score as feature, as that the reranking model
cannot do worst than the baseline model. As we
pointed out in section 4.2, this solution require a fine
tuning of the reranking model, especially when the
baseline model is relatively accurate. In our case,
the CRF model has a Sentence Error Rate of 25.0%
on the MEDIA test set. This means that 75% of
the times the best hypothesis of CRF is correct. In
turn this implies that the reranking model must not
rerank 75% of times and rerank the other 25% of
times, someway contrasting the evidence provided
by the baseline model score. In contrast, using our
WRR strategy, we can tune the reranking model to
maximize reranking effect and recover from rerank-
ing errors applying WRR. As shown in tables 3 and
4, we consistently improve CRF baseline as well
as reranking baseline CRF+RR, especially applying
both SIM and WRR (CRF+RRWRR). Comparing
our results with those reported in (Hahn et al., 2010),
we can see that our model reaches, and even im-
</bodyText>
<page confidence="0.980847">
1112
</page>
<table confidence="0.974236166666667">
MEDIA Test set OER[%] correctfound/present
Model
CRF 9.5 2359/2657
CRF+RR 9.5 2375/2657
CRF+RRSIM 7.5 2381/2758
CRF+RRWRR 7.5 2444/2758
</table>
<tableCaption confidence="0.9923835">
Table 5: Analysis over 10-best hypotheses for CRF baseline and the
reranking models showing the effect of hypotheses selection
</tableCaption>
<table confidence="0.999826375">
MEDIA Text Input DEV TEST
Model Pair Attr+Val Attr+Val
CRF vs. CRF+RR 0.2235 0.4075
CRF vs. CRF+RRSIM 0.0299 0.065
CRF vs. CRF+RRWRR 0.0044 1.9998E-4
CRF+RR vs. CRF+RRSIM 0.002 5.9994E-4
CRF+RR vs. CRF+RRWRR 4.9995E-4 9.999E-5
CRF+RRSIM vs. CRF+RRWRR 0.1355 0.0031
</table>
<tableCaption confidence="0.994495333333333">
Table 6: Significance tests on results of models described in this
work. The significance test is based on computationally-intensive ran-
domizations as described in (Yeh and Church, 2000).
</tableCaption>
<bodyText confidence="0.999792482758621">
proves in some cases, state-of-the-art performance.
This is particularly meaningful since best results re-
ported in (Hahn et al., 2010) are obtained combining
6 different SLU models.
In table 5 we report some statistics to show the
effect of SIM on the 10-best hypotheses list. It is
particularly interesting to see that when hypothe-
ses selection is applied, oracle error rate (OER)
drops of 2% points from an already accurate OER
of 9.5%. This is reflected also by the number of ora-
cles present in the 10-best list without applying and
applying SIM. We pass from 2657 without SIM to
2758 applying our hypotheses selection metric.
Finally, in table 6 we report statistical signifi-
cance tests over the models described in this work.
We used the significance test described in (Yeh
and Church, 2000), it is based on computationally-
intensive randomizations of data and tests the null
hypothesis, i.e. the lower the score, the higher the
statistical significance of results difference. Scores
in table 5 reflect results given in terms of CER. We
can see that when the difference between results is
small, this is not statistically significant, when the
score is above 0.05, the difference between the two
corresponding models is not significant. We can thus
conclude that the reranking model we propose, using
hypotheses selection and reranking errors recover,
significantly improves baseline CRF model and “tra-
ditional” reranking models.
</bodyText>
<sectionHeader confidence="0.999519" genericHeader="method">
6 Discussion
</sectionHeader>
<bodyText confidence="0.999961055555556">
Although the new ideas proposed in this paper are
effective and interesting, an important issue is their
applicability to other tasks and domains. In this re-
spect, it is sufficient to note that our ideas comes
from the multi-stage nature of the task and of the
proposed reranking framework. SLU is performed
in two intertwined steps, since attribute values are
extracted from syntactic chunks annotated with con-
cept in the first step. This allows to use the model for
the second step to validate the output of the first step,
and vice versa, which is the principle of our hypothe-
ses selection metric. There are many other tasks,
in NLP and in other domains, that can be modeled
with multiple steps and thus the same idea of “val-
idation” of the output of one step with the other’s
model output can be applied. An example is syntac-
tic parsing, where in most cases parsing is performed
upon POS tagging output.
</bodyText>
<sectionHeader confidence="0.999213" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.999495">
In this paper we propose two improvements for
reranking models to be integrated in a reranking
framework for Spoken Language Understanding.
The reranking model is based on a CRF baseline
model and Support Vector Machines with the Par-
tial Tree Kernel for the reraning model. The two
improvements we propose are: i) hypotheses selec-
tion criteria, used before applying reranking to select
better hypotheses amongst those generated by CRF.
ii) a strategy to recover from reranking errors called
Wrong Rerank Rejection.
We presented a full set of comparative results
showing the viability of our approach. We can reach
performances of state-of-the-art models, improving
them in some cases, especially on automatic tran-
scriptions coming from ASR (speech input).
In particular, the effectiveness of hypotheses se-
lection is shown reporting the improvement of the
Oracle Error Rate on the 10-best hypotheses list.
</bodyText>
<sectionHeader confidence="0.998299" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.983716">
This work has been funded by OSEO under the
Quaero program.
</bodyText>
<page confidence="0.987577">
1113
</page>
<sectionHeader confidence="0.992782" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.985977561904762">
Erik F. Tjong Kim Sang and Fien De Meulder. 2003.
Introduction to the conll-2003 shared task: language-
independent named entity recognition. In Proceedings
of the seventh conference on Natural language learn-
ing at HLT-NAACL 2003 - Volume 4, pages 142–147,
Morristown, NJ, USA. Association for Computational
Linguistics.
Ellen M. Voorhees. 2001. The trec question answering
track. Nat. Lang. Eng., 7:361–378, December.
X. Carreras and Lluis Marquez. 2005. Introduction to
the conll-2005 shared task: Semantic role labeling.
R. De Mori, F. Bechet, D. Hakkani-Tur, M. McTear,
G. Riccardi, and G. Tur. 2008. Spoken language un-
derstanding: A survey. IEEE Signal Processing Mag-
azine, 25:50–58.
Sylvain Galliano, Guillaume Gravier, and Maura
Chaubard. 2009. The ester 2 evaluation campaign
for the rich transcription of french radio broadcasts.
In Proceedings of the International Conference of
the Speech Communication Assosiation (Interspeech),
Brighton, U.K.
E. Charniak and M. Johnson. 2005. Coarse-to-fine n-
best parsing and maxent discriminative reranking. In
Proceedings of the Conference of the Association for
Computational Linguistics (ACL), page 363370, Ann
Arbor, MI.
Michael Collins and Terry Koo. 2005. Discriminative re-
ranking for natural language parsing. Computational
Linguistic (CL), 31(1):25–70.
J. Lafferty, A. McCallum, and F. Pereira. 2001. Con-
ditional random fields: Probabilistic models for seg-
menting and labeling sequence data. In Proceedings of
the Eighteenth International Conference on Machine
Learning (ICML), pages 282–289, Williamstown,
MA, USA, June.
Brigitte Krenn and Christer Samuelsson. 1997. The lin-
guist’s guide to statistics - don’t panic.
Thomas Lavergne, Olivier Capp´e, and Franc¸ois Yvon.
2010. Practical very large scale CRFs. In Proceed-
ings the 48th Annual Meeting of the Association for
Computational Linguistics (ACL), pages 504–513. As-
sociation for Computational Linguistics, July.
Stefan Hahn, Patrick Lehnen, Georg Heigold, and Her-
mann Ney. 2009. Optimizing crfs for slu tasks in vari-
ous languages using modified training criteria. In Pro-
ceedings of the International Conference of the Speech
Communication Assosiation (Interspeech), Brighton,
U.K.
Stefan Riezler and Alexander Vasserman. 2010. Incre-
mental feature selection and l1 regularization for re-
laxed maximum-entropy modeling.
Hui Zou and Trevor Hastie. 2005. Regularization and
variable selection via the Elastic Net. Journal of the
Royal Statistical Society B, 67:301–320.
Andrew McCallum. 2003. Efficiently inducing features
of conditional random fields. In 19th Conference on
Uncertainty in Artificial Intelligence.
Lawrence R. Rabiner. 1989. A tutorial on hidden markov
models and selected applications in speech recogni-
tion. Proceedings of the IEEE, 77(2):257–286.
Mark Johnson. 1998. Pcfg models of linguistic tree rep-
resentations. Computational Linguistics, 24:613–632.
Olivier Galibert, Ludovic Quintard, Sophie Rosset, Pierre
Zweigenbaum, Claire Ndellec, Sophie Aubin, Lau-
rent Gillard, Jean-Pierre Raysz, Delphine Pois, Xavier
Tannier, Louise Delger, and Dominique Laurent.
2010. Named and specific entity detection in var-
ied data: The quro named entity baseline evalu-
ation. In Nicoletta Calzolari (Conference Chair),
Khalid Choukri, Bente Maegaard, Joseph Mariani,
Jan Odijk, Stelios Piperidis, Mike Rosner, and Daniel
Tapias, editors, Proceedings of the Seventh conference
on International Language Resources and Evaluation
(LREC’10), Valletta, Malta, may. European Language
Resources Association (ELRA).
Olivier Galibert. 2009. Approches et m´ethodologies pour
la r´eponse automatique a` des questions adapt´ees un
cadre interactif en domaine ouvert. Ph.D. thesis, Uni-
versit Paris Sud, Orsay.
G. Doddington, A. Mitchell, M. Przybocki, L. Ramshaw,
S. Strassel, and R. Weischedel. 2004. The Automatic
Content Extraction (ACE) Program–Tasks, Data, and
Evaluation. Proceedings of LREC 2004, pages 837–
840.
H´el`ene Bonneau-Maynard, Christelle Ayache, F. Bechet,
A Denis, A Kuhn, Fabrice Lef`evre, D. Mostefa,
M. Qugnard, S. Rosset, and J. Servan, S. Vilaneau.
2006. Results of the french evalda-media evaluation
campaign for literal understanding. In LREC, pages
2054–2059, Genoa, Italy, May.
Christian Raymond, Frdric Bchet, Renato De Mori, and
Graldine Damnati. 2006. On the use of finite state
transducers for semantic interpretation. Speech Com-
munication, 48(3-4):288–304, March-April.
Christian Raymond and Giuseppe Riccardi. 2007. Gen-
erative and discriminative algorithms for spoken lan-
guage understanding. In Proceedings of the Interna-
tional Conference of the Speech Communication As-
sosiation (Interspeech), pages 1605–1608, Antwerp,
Belgium, August.
Vladimir N. Vapnik. 1998. Statistical Learning Theory.
John Wiley and Sons.
T. J. Sejnowski and C. S. Rosenberg. 1987. Parallel net-
works that learn to pronounce English text. Complex
Systems, 1:145–168.
</reference>
<page confidence="0.906026">
1114
</page>
<reference confidence="0.998687846153846">
Stefan Hahn, Marco Dinarelli, Christian Raymond, Fab-
rice Lef`evre, Patrick Lehen, Renato De Mori, Alessan-
dro Moschitti, Hermann Ney, and Giuseppe Riccardi.
2010. Comparing stochastic approaches to spoken
language understanding in multiple languages. IEEE
Transactions on Audio, Speech and Language Pro-
cessing (TASLP), 99.
Marco Dinarelli, Alessandro Moschitti, and Giuseppe
Riccardi. 2009b. Re-ranking models based on small
training data for spoken language understanding. In
Conference of Empirical Methods for Natural Lan-
guage Processing, pages 11–18, Singapore, August.
Marco Dinarelli, Alessandro Moschitti, and Giuseppe
Riccardi. 2010. Hypotheses Selection for Reranking
Semantic Annotation. In IEEE Workshop of Spoken
Language Technology (SLT), Berkeley, USA.
Alessandro Moschitti. 2006. Efficient Convolution Ker-
nels for Dependency and Constituent Syntactic Trees.
In Proceedings ofECML 2006, pages 318–329, Berlin,
Germany.
M. Collins and N. Duffy. 2002. New Ranking Algo-
rithms for Parsing and Tagging: Kernels over Discrete
structures, and the voted perceptron. In Proceedings of
the Association for Computational Linguistics, pages
263–270.
Libin Shen, Anoop Sarkar, and Aravind K. Joshi. 2003.
Using LTAG Based Features in Parse Reranking. In
Proceedings of EMNLP’06.
Herbrich, Ralf and Graepel, Thore and Obermayer,
Klaus. 2000. Large Margin Rank Boundaries for Or-
dinal Regression. In Advances in Large Margin Clas-
sifiers.
Libin Shen, and Aravind K. Joshi. 2003. An SVM Based
Voting Algorithm with Application to Parse Rerank-
ing. In Proceedings of CoNLL 2003.
Libin Shen, Anoop Sarkar, and Franz J. Och. 2004. Dis-
criminative reranking for machine translation. In HLT-
NAACL, pages 177–184.
Taku Kudo, Jun Suzuki, and Hideki Isozaki. 2005.
Boosting-based parse reranking with subtree features.
In Proceedings ofACL’05.
Stefan Hahn, Patrick Lehnen, and Hermann Ney. 2008a.
System combination for spoken language understand-
ing. In Proceedings of the International Conference of
the Speech Communication Assosiation (Interspeech),
pages 236–239, Brisbane, Australia.
J. G. Fiscus. 1997. A post-processing system to yield
reduced word error rates: Recogniser output voting er-
ror reduction (ROVER). In Proceedings 1997 IEEE
Workshop on Automatic Speech Recognition and Un-
derstanding (ASRU), pages 347–352, Santa Barbara,
CA, December.
John Shawe-Taylor and Nello Cristianini. 2004. Kernel
Methods for Pattern Analysis. Cambridge University
Press.
Michael Collins. 2000. Discriminative reranking for nat-
ural language parsing. In ICML, pages 175–182.
Michael Collins and Nigel Duffy. 2001. Convolution
kernels for natural language. In Advances in Neural
Information Processing Systems 14, pages 625–632.
MIT Press.
Rush, Alexander M. and Sontag, David and Collins,
Michael and Jaakkola, Tommi. 2010. On dual decom-
position and linear programming relaxations for nat-
ural language processing. In Empirical Methods for
Natural Language Processing (EMNLP). Cambridge,
Massachusetts, USA.
Alessandro Moschitti, Daniele Pighin, and Roberto
Basili. 2008. Tree kernels for semantic role labeling.
Computational Linguistics, 34(2):193–224.
Alessandro Moschitti, Silvia Quarteroni, Roberto Basili,
and Suresh Manandhar. 2007. Exploiting syntactic
and shallow semantic kernels for question/answer clas-
sification. In Proceedings of ACL’07, Prague, Czech
Republic.
Alexander Yeh and Kelmeth Church. 2000. More accu-
rate tests for the statistical significance of result differ-
ences.
</reference>
<page confidence="0.994928">
1115
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.068068">
<title confidence="0.9983905">Hypotheses Selection Criteria in a Reranking Framework for Spoken Language Understanding</title>
<author confidence="0.861512">Marco</author>
<note confidence="0.21768575">B.P. 133, 91403 Orsay marcod@limsi.fr Sophie B.P. 133, 91403 Orsay</note>
<email confidence="0.97165">rosset@limsi.fr</email>
<abstract confidence="0.998479625">Reranking models have been successfully applied to many tasks of Natural Language Processing. However, there are two aspects of this approach that need a deeper investigation: (i) Assessment of hypotheses generated for reranking at classification phase: baseline models generate a list of hypotheses and these are used for reranking without any assessment; (ii) Detection of cases where reranking models provide a worst result: the best hypothesis provided by the reranking model is assumed to be always the best result. In some cases the reranking model provides an incorrect hypothesis while the baseline best hypothesis is correct, especially when baseline models are accurate. In this paper we propose solutions for these two aspects: (i) a semantic inconsistency metric to select posmore correct hypotheses, from a large set generated by an SLU basiline model. The selected hypotheses are reranked applying a state-of-the-art model based on Partial Tree Kernels, which encode SLU hypotheses in Support Vector Machines with complex structured features; (ii) finally, we apply a decision strategy, based on confidence values, to select the final hypothesis between the first ranked hypothesis provided by the baseline SLU model and the first ranked hypothesis provided by the re-ranker. We show the effectiveness of these solutions presenting comparative results obtained reranking hypotheses generated by a very accurate Conditional Random Field model. We evaluate our approach on the French MEDIA corpus. The results show significant improvements with respect to current state-of-the-art and previous 1104 re-ranking models.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Erik F Tjong Kim Sang</author>
<author>Fien De Meulder</author>
</authors>
<title>Introduction to the conll-2003 shared task: languageindependent named entity recognition.</title>
<date>2003</date>
<booktitle>In Proceedings of the seventh conference on Natural language learning at HLT-NAACL 2003 -</booktitle>
<volume>4</volume>
<pages>142--147</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<marker>Sang, De Meulder, 2003</marker>
<rawString>Erik F. Tjong Kim Sang and Fien De Meulder. 2003. Introduction to the conll-2003 shared task: languageindependent named entity recognition. In Proceedings of the seventh conference on Natural language learning at HLT-NAACL 2003 - Volume 4, pages 142–147, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen M Voorhees</author>
</authors>
<title>The trec question answering track.</title>
<date>2001</date>
<journal>Nat. Lang. Eng.,</journal>
<pages>7--361</pages>
<marker>Voorhees, 2001</marker>
<rawString>Ellen M. Voorhees. 2001. The trec question answering track. Nat. Lang. Eng., 7:361–378, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Carreras</author>
<author>Lluis Marquez</author>
</authors>
<title>Introduction to the conll-2005 shared task: Semantic role labeling.</title>
<date>2005</date>
<journal>IEEE Signal Processing Magazine,</journal>
<pages>25--50</pages>
<marker>Carreras, Marquez, 2005</marker>
<rawString>X. Carreras and Lluis Marquez. 2005. Introduction to the conll-2005 shared task: Semantic role labeling. R. De Mori, F. Bechet, D. Hakkani-Tur, M. McTear, G. Riccardi, and G. Tur. 2008. Spoken language understanding: A survey. IEEE Signal Processing Magazine, 25:50–58.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sylvain Galliano</author>
<author>Guillaume Gravier</author>
<author>Maura Chaubard</author>
</authors>
<title>The ester 2 evaluation campaign for the rich transcription of french radio broadcasts.</title>
<date>2009</date>
<booktitle>In Proceedings of the International Conference of the Speech Communication Assosiation (Interspeech),</booktitle>
<location>Brighton, U.K.</location>
<marker>Galliano, Gravier, Chaubard, 2009</marker>
<rawString>Sylvain Galliano, Guillaume Gravier, and Maura Chaubard. 2009. The ester 2 evaluation campaign for the rich transcription of french radio broadcasts. In Proceedings of the International Conference of the Speech Communication Assosiation (Interspeech), Brighton, U.K.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Charniak</author>
<author>M Johnson</author>
</authors>
<title>Coarse-to-fine nbest parsing and maxent discriminative reranking.</title>
<date>2005</date>
<booktitle>In Proceedings of the Conference of the Association for Computational Linguistics (ACL),</booktitle>
<pages>363370</pages>
<location>Ann Arbor, MI.</location>
<marker>Charniak, Johnson, 2005</marker>
<rawString>E. Charniak and M. Johnson. 2005. Coarse-to-fine nbest parsing and maxent discriminative reranking. In Proceedings of the Conference of the Association for Computational Linguistics (ACL), page 363370, Ann Arbor, MI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Terry Koo</author>
</authors>
<title>Discriminative reranking for natural language parsing.</title>
<date>2005</date>
<booktitle>Computational Linguistic (CL),</booktitle>
<pages>31--1</pages>
<contexts>
<context position="20834" citStr="Collins and Koo, 2005" startWordPosition="3399" endWordPosition="3402">elect hypotheses generated by the baseline model; second, a strategy to decide, after the reranking phase, if it is more likely that the baseline best hypothesis is more accurate than the best reranked hypothesis and allowing to recover the mistake. Similar ideas have been proposed in (Dinarelli et al., 2010), here we propose a significant evolution and we give a much wider description and evaluation. 4.1 Hypotheses Selection via Attribute Value Extraction (AVE) In previous reranking approaches (Collins, 2000; Collins and Duffy, 2002; Shen et al., 2003a; Shen et al., 2003b; Shen et al., 2004; Collins and Koo, 2005; Kudo et al., 2005; Dinarelli et al., 2009b), few hypotheses are generated with the baseline model, ranked by the model probability. These are then used for the reranking model. An interesting strategy to improve reranking performance is the selection of the best set of hypotheses to be reranked. In this work we propose a semantic inconsistency metric (SIM) based on the attribute-value extraction phase that allows to select better n-best hypotheses. We combine the scores provided by the rule based approach and the CRF approach for AVE, computing a confidence measure. The rule-based approach f</context>
</contexts>
<marker>Collins, Koo, 2005</marker>
<rawString>Michael Collins and Terry Koo. 2005. Discriminative reranking for natural language parsing. Computational Linguistic (CL), 31(1):25–70.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lafferty</author>
<author>A McCallum</author>
<author>F Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<booktitle>In Proceedings of the Eighteenth International Conference on Machine Learning (ICML),</booktitle>
<pages>282--289</pages>
<location>Williamstown, MA, USA,</location>
<contexts>
<context position="7403" citStr="Lafferty et al., 2001" startWordPosition="1136" endWordPosition="1140">ith respect to the application domain. reservation, hotel and London are the normalized attribute values, defined also in the application ontology. This representation is usually called attribute-value representation. In the last decade several probabilistic models have been proposed for the Automatic Concept Labeling step: in (Raymond et al., 2006) a conceptual language model encoded in Stochastic Finite State Transducers (SFST) is proposed. In (Raymond and Riccardi, 2007), the SFST-based model is compared with Support Vector Machines (SVM) (Vapnik, 1998) and Conditional Random Fields (CRF) (Lafferty et al., 2001). Moreover, in (Hahn et al., 2008a) two more models are applied to SLU: a Maximum Entropy (EM) model and a model coming from the Statistical Machine Translation (SMT) community (it is actually a log-linear combination of SMT models). Among these models, CRF has shown in general superior performances on sequence labeling tasks like Named Entity Recognition (NER) (Tjong Kim Sang and De Meulder, 2003), Grapheme-toPhoneme transcription (Sejnowski and Rosenberg, 1105 1987) and also Spoken Language Understanding (Hahn et al., 2008a). In addition to individual systems, more recently also some system </context>
<context position="11474" citStr="Lafferty et al., 2001" startWordPosition="1821" endWordPosition="1824">rline that the phases involved in the reranking framewrok are distinguished for a matter of clarity. In principle, the phases from the hypotheses selection to the last, the decision strategy, can be thought of as a whole reranking model. In the next two subsection we describe the two models used for hypotheses generation and for reranking: CRF and SVM with kernel methods. The two improvements proposed in this paper and listed above are presented in a dedicated section (4). 3.1 Conditional Random Fields CRFs have been proposed for the first time for sequence segmentation and labeling tasks in (Lafferty et al., 2001). This model belongs to the family of exponential or log-linear models. Its main characteristics are the possibility to include a huge number 1106 of features, like the Maximum Entropy (ME) model, but computing global conditional probabilities normalized at sentence level, instead of position level like in ME. In particular this last point results very effective since it solves the label bias problem, as pointed out in (Lafferty et al., 2001). Given a sequence of N words W1N = w1, ..., wN and its corresponding sequence of concepts CN1 = c1, ..., cN, CRF trains the conditional probabilities HN </context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>J. Lafferty, A. McCallum, and F. Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In Proceedings of the Eighteenth International Conference on Machine Learning (ICML), pages 282–289, Williamstown, MA, USA, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brigitte Krenn</author>
<author>Christer Samuelsson</author>
</authors>
<title>The linguist’s guide to statistics - don’t panic.</title>
<date>1997</date>
<marker>Krenn, Samuelsson, 1997</marker>
<rawString>Brigitte Krenn and Christer Samuelsson. 1997. The linguist’s guide to statistics - don’t panic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Lavergne</author>
<author>Olivier Capp´e</author>
<author>Franc¸ois Yvon</author>
</authors>
<title>Practical very large scale CRFs.</title>
<date>2010</date>
<booktitle>In Proceedings the 48th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>504--513</pages>
<marker>Lavergne, Capp´e, Yvon, 2010</marker>
<rawString>Thomas Lavergne, Olivier Capp´e, and Franc¸ois Yvon. 2010. Practical very large scale CRFs. In Proceedings the 48th Annual Meeting of the Association for Computational Linguistics (ACL), pages 504–513. Association for Computational Linguistics, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Hahn</author>
<author>Patrick Lehnen</author>
<author>Georg Heigold</author>
<author>Hermann Ney</author>
</authors>
<title>Optimizing crfs for slu tasks in various languages using modified training criteria.</title>
<date>2009</date>
<booktitle>In Proceedings of the International Conference of the Speech Communication Assosiation (Interspeech),</booktitle>
<location>Brighton, U.K.</location>
<contexts>
<context position="12898" citStr="Hahn et al., 2009" startWordPosition="2056" endWordPosition="2059"> factor in order to model well defined probability distribution: H(˜cn−1, ˜cn, wn+2 n−2) (2) here &amp;quot;cn−1 and &amp;quot;cn are the concepts hypothesized for the previous and current words, H(&amp;quot;cn−1, &amp;quot;cn, wn+2 n−2) is an abbreviation for EMm=1 Am · hm(cn−1, cn, wn+2 n−2). The CRF model used for the Attribute-Value Extraction phase learns in the same way the conditional probability P(V1N|CN1 ,W1N). In particular we use attributes-words concatenations on the source side and attribute values on the target side. Two particular effective implementations of CRFs have been recently proposed. One is described in (Hahn et al., 2009) and uses a margin based criterion for probabilities estimation. The other is described in (Lavergne et al., 2010) and has been implemented in the software wapiti1. The latter solution in particular trains the model using two different regularization factors at the same time: Gaussian prior, used as l2 regularization and used in many softwares to avoid overfitting; Laplacian prior, used as l1 regularization (Riezler and Vasserman, 2010), which has the effect to filter out features with very low scores. 1available at http://wapiti.limsi.fr The two regularization parameters are used together in </context>
</contexts>
<marker>Hahn, Lehnen, Heigold, Ney, 2009</marker>
<rawString>Stefan Hahn, Patrick Lehnen, Georg Heigold, and Hermann Ney. 2009. Optimizing crfs for slu tasks in various languages using modified training criteria. In Proceedings of the International Conference of the Speech Communication Assosiation (Interspeech), Brighton, U.K.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Riezler</author>
<author>Alexander Vasserman</author>
</authors>
<title>Incremental feature selection and l1 regularization for relaxed maximum-entropy modeling.</title>
<date>2010</date>
<contexts>
<context position="13338" citStr="Riezler and Vasserman, 2010" startWordPosition="2125" endWordPosition="2128">atenations on the source side and attribute values on the target side. Two particular effective implementations of CRFs have been recently proposed. One is described in (Hahn et al., 2009) and uses a margin based criterion for probabilities estimation. The other is described in (Lavergne et al., 2010) and has been implemented in the software wapiti1. The latter solution in particular trains the model using two different regularization factors at the same time: Gaussian prior, used as l2 regularization and used in many softwares to avoid overfitting; Laplacian prior, used as l1 regularization (Riezler and Vasserman, 2010), which has the effect to filter out features with very low scores. 1available at http://wapiti.limsi.fr The two regularization parameters are used together in the model implementing the so-called elastic net regularization (Zou and Hastie, 2005): l(λ) + ρ1kλk1 + ρ22 kλk2 (3) 2 A is the set of parameters of the model introduced in equation 1, l(A) is the minus-logarithm of equation 1, used as loss function for training CRF. IIAII1 and IIAII2 are the l1 and l2 regularization, respectively, while p1 and p2 are two parameters that can be optimized as usual on development data or with cross valida</context>
</contexts>
<marker>Riezler, Vasserman, 2010</marker>
<rawString>Stefan Riezler and Alexander Vasserman. 2010. Incremental feature selection and l1 regularization for relaxed maximum-entropy modeling.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hui Zou</author>
<author>Trevor Hastie</author>
</authors>
<title>Regularization and variable selection via the Elastic Net.</title>
<date>2005</date>
<journal>Journal of the Royal Statistical Society B,</journal>
<pages>67--301</pages>
<contexts>
<context position="13584" citStr="Zou and Hastie, 2005" startWordPosition="2162" endWordPosition="2165">The other is described in (Lavergne et al., 2010) and has been implemented in the software wapiti1. The latter solution in particular trains the model using two different regularization factors at the same time: Gaussian prior, used as l2 regularization and used in many softwares to avoid overfitting; Laplacian prior, used as l1 regularization (Riezler and Vasserman, 2010), which has the effect to filter out features with very low scores. 1available at http://wapiti.limsi.fr The two regularization parameters are used together in the model implementing the so-called elastic net regularization (Zou and Hastie, 2005): l(λ) + ρ1kλk1 + ρ22 kλk2 (3) 2 A is the set of parameters of the model introduced in equation 1, l(A) is the minus-logarithm of equation 1, used as loss function for training CRF. IIAII1 and IIAII2 are the l1 and l2 regularization, respectively, while p1 and p2 are two parameters that can be optimized as usual on development data or with cross validation. As explained in (Lavergne et al., 2010), using l1 regularization is an effective way for feature selection in CRF at training time. Note that other approaches have been proposed for feature selection, e.g. in (McCallum, 2003). This type of </context>
</contexts>
<marker>Zou, Hastie, 2005</marker>
<rawString>Hui Zou and Trevor Hastie. 2005. Regularization and variable selection via the Elastic Net. Journal of the Royal Statistical Society B, 67:301–320.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew McCallum</author>
</authors>
<title>Efficiently inducing features of conditional random fields.</title>
<date>2003</date>
<booktitle>In 19th Conference on Uncertainty in Artificial Intelligence.</booktitle>
<contexts>
<context position="14169" citStr="McCallum, 2003" startWordPosition="2269" endWordPosition="2270">ization (Zou and Hastie, 2005): l(λ) + ρ1kλk1 + ρ22 kλk2 (3) 2 A is the set of parameters of the model introduced in equation 1, l(A) is the minus-logarithm of equation 1, used as loss function for training CRF. IIAII1 and IIAII2 are the l1 and l2 regularization, respectively, while p1 and p2 are two parameters that can be optimized as usual on development data or with cross validation. As explained in (Lavergne et al., 2010), using l1 regularization is an effective way for feature selection in CRF at training time. Note that other approaches have been proposed for feature selection, e.g. in (McCallum, 2003). This type of features selection, performed directly at training time, yields very accurate models, since only the most meaningful features are kept in the final model, which guarantee a strong robustness on unseen data. In this work we refer in particular to the CRF implementation described in (Lavergne et al., 2010). 3.2 SVM and Kernel Methods Our reranking model is based on SVM (Vapnik, 1998) with the use of the Partial Tree Kernel defined in (Moschitti, 2006). SVMs are well-known machine learning algorithms belonging to the class of maximal-margin linear classifiers (Vapnik, 1998). The mo</context>
</contexts>
<marker>McCallum, 2003</marker>
<rawString>Andrew McCallum. 2003. Efficiently inducing features of conditional random fields. In 19th Conference on Uncertainty in Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lawrence R Rabiner</author>
</authors>
<title>A tutorial on hidden markov models and selected applications in speech recognition.</title>
<date>1989</date>
<booktitle>Proceedings of the IEEE,</booktitle>
<pages>77--2</pages>
<marker>Rabiner, 1989</marker>
<rawString>Lawrence R. Rabiner. 1989. A tutorial on hidden markov models and selected applications in speech recognition. Proceedings of the IEEE, 77(2):257–286.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Johnson</author>
</authors>
<title>Pcfg models of linguistic tree representations.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<pages>24--613</pages>
<marker>Johnson, 1998</marker>
<rawString>Mark Johnson. 1998. Pcfg models of linguistic tree representations. Computational Linguistics, 24:613–632.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Dominique Laurent</author>
</authors>
<title>Named and specific entity detection in varied data: The quro named entity baseline evaluation.</title>
<date>2010</date>
<booktitle>In Nicoletta Calzolari</booktitle>
<editor>Olivier Galibert, Ludovic Quintard, Sophie Rosset, Pierre Zweigenbaum, Claire Ndellec, Sophie Aubin, Laurent Gillard, Jean-Pierre Raysz, Delphine Pois, Xavier Tannier, Louise Delger, and</editor>
<location>Valletta, Malta,</location>
<marker>Laurent, 2010</marker>
<rawString>Olivier Galibert, Ludovic Quintard, Sophie Rosset, Pierre Zweigenbaum, Claire Ndellec, Sophie Aubin, Laurent Gillard, Jean-Pierre Raysz, Delphine Pois, Xavier Tannier, Louise Delger, and Dominique Laurent. 2010. Named and specific entity detection in varied data: The quro named entity baseline evaluation. In Nicoletta Calzolari (Conference Chair), Khalid Choukri, Bente Maegaard, Joseph Mariani, Jan Odijk, Stelios Piperidis, Mike Rosner, and Daniel Tapias, editors, Proceedings of the Seventh conference on International Language Resources and Evaluation (LREC’10), Valletta, Malta, may. European Language Resources Association (ELRA).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Olivier Galibert</author>
</authors>
<title>Approches et m´ethodologies pour la r´eponse automatique a` des questions adapt´ees un cadre interactif en domaine ouvert.</title>
<date>2009</date>
<tech>Ph.D. thesis,</tech>
<institution>Universit Paris Sud,</institution>
<location>Orsay.</location>
<marker>Galibert, 2009</marker>
<rawString>Olivier Galibert. 2009. Approches et m´ethodologies pour la r´eponse automatique a` des questions adapt´ees un cadre interactif en domaine ouvert. Ph.D. thesis, Universit Paris Sud, Orsay.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Doddington</author>
<author>A Mitchell</author>
<author>M Przybocki</author>
<author>L Ramshaw</author>
<author>S Strassel</author>
<author>R Weischedel</author>
</authors>
<title>The Automatic Content Extraction (ACE) Program–Tasks, Data, and Evaluation.</title>
<date>2004</date>
<booktitle>Proceedings of LREC 2004,</booktitle>
<pages>837--840</pages>
<marker>Doddington, Mitchell, Przybocki, Ramshaw, Strassel, Weischedel, 2004</marker>
<rawString>G. Doddington, A. Mitchell, M. Przybocki, L. Ramshaw, S. Strassel, and R. Weischedel. 2004. The Automatic Content Extraction (ACE) Program–Tasks, Data, and Evaluation. Proceedings of LREC 2004, pages 837– 840.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H´el`ene Bonneau-Maynard</author>
<author>Christelle Ayache</author>
<author>F Bechet</author>
<author>A Denis</author>
<author>A Kuhn</author>
<author>Fabrice Lef`evre</author>
<author>D Mostefa</author>
<author>M Qugnard</author>
<author>S Rosset</author>
<author>J Servan</author>
<author>S Vilaneau</author>
</authors>
<title>Results of the french evalda-media evaluation campaign for literal understanding. In</title>
<date>2006</date>
<booktitle>LREC,</booktitle>
<pages>2054--2059</pages>
<location>Genoa, Italy,</location>
<marker>Bonneau-Maynard, Ayache, Bechet, Denis, Kuhn, Lef`evre, Mostefa, Qugnard, Rosset, Servan, Vilaneau, 2006</marker>
<rawString>H´el`ene Bonneau-Maynard, Christelle Ayache, F. Bechet, A Denis, A Kuhn, Fabrice Lef`evre, D. Mostefa, M. Qugnard, S. Rosset, and J. Servan, S. Vilaneau. 2006. Results of the french evalda-media evaluation campaign for literal understanding. In LREC, pages 2054–2059, Genoa, Italy, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Raymond</author>
<author>Frdric Bchet</author>
<author>Renato De Mori</author>
<author>Graldine Damnati</author>
</authors>
<title>On the use of finite state transducers for semantic interpretation.</title>
<date>2006</date>
<journal>Speech Communication,</journal>
<pages>48--3</pages>
<marker>Raymond, Bchet, De Mori, Damnati, 2006</marker>
<rawString>Christian Raymond, Frdric Bchet, Renato De Mori, and Graldine Damnati. 2006. On the use of finite state transducers for semantic interpretation. Speech Communication, 48(3-4):288–304, March-April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Raymond</author>
<author>Giuseppe Riccardi</author>
</authors>
<title>Generative and discriminative algorithms for spoken language understanding.</title>
<date>2007</date>
<booktitle>In Proceedings of the International Conference of the Speech Communication Assosiation (Interspeech),</booktitle>
<pages>1605--1608</pages>
<location>Antwerp, Belgium,</location>
<contexts>
<context position="7259" citStr="Raymond and Riccardi, 2007" startWordPosition="1115" endWordPosition="1118">not associated to any concept. As shown in the example, Null concepts are removed from the final output since they don’t bring any semantic content with respect to the application domain. reservation, hotel and London are the normalized attribute values, defined also in the application ontology. This representation is usually called attribute-value representation. In the last decade several probabilistic models have been proposed for the Automatic Concept Labeling step: in (Raymond et al., 2006) a conceptual language model encoded in Stochastic Finite State Transducers (SFST) is proposed. In (Raymond and Riccardi, 2007), the SFST-based model is compared with Support Vector Machines (SVM) (Vapnik, 1998) and Conditional Random Fields (CRF) (Lafferty et al., 2001). Moreover, in (Hahn et al., 2008a) two more models are applied to SLU: a Maximum Entropy (EM) model and a model coming from the Statistical Machine Translation (SMT) community (it is actually a log-linear combination of SMT models). Among these models, CRF has shown in general superior performances on sequence labeling tasks like Named Entity Recognition (NER) (Tjong Kim Sang and De Meulder, 2003), Grapheme-toPhoneme transcription (Sejnowski and Rosen</context>
</contexts>
<marker>Raymond, Riccardi, 2007</marker>
<rawString>Christian Raymond and Giuseppe Riccardi. 2007. Generative and discriminative algorithms for spoken language understanding. In Proceedings of the International Conference of the Speech Communication Assosiation (Interspeech), pages 1605–1608, Antwerp, Belgium, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vladimir N Vapnik</author>
</authors>
<title>Statistical Learning Theory.</title>
<date>1998</date>
<publisher>John Wiley and Sons.</publisher>
<contexts>
<context position="7343" citStr="Vapnik, 1998" startWordPosition="1129" endWordPosition="1130">utput since they don’t bring any semantic content with respect to the application domain. reservation, hotel and London are the normalized attribute values, defined also in the application ontology. This representation is usually called attribute-value representation. In the last decade several probabilistic models have been proposed for the Automatic Concept Labeling step: in (Raymond et al., 2006) a conceptual language model encoded in Stochastic Finite State Transducers (SFST) is proposed. In (Raymond and Riccardi, 2007), the SFST-based model is compared with Support Vector Machines (SVM) (Vapnik, 1998) and Conditional Random Fields (CRF) (Lafferty et al., 2001). Moreover, in (Hahn et al., 2008a) two more models are applied to SLU: a Maximum Entropy (EM) model and a model coming from the Statistical Machine Translation (SMT) community (it is actually a log-linear combination of SMT models). Among these models, CRF has shown in general superior performances on sequence labeling tasks like Named Entity Recognition (NER) (Tjong Kim Sang and De Meulder, 2003), Grapheme-toPhoneme transcription (Sejnowski and Rosenberg, 1105 1987) and also Spoken Language Understanding (Hahn et al., 2008a). In add</context>
<context position="14568" citStr="Vapnik, 1998" startWordPosition="2338" endWordPosition="2339">d in (Lavergne et al., 2010), using l1 regularization is an effective way for feature selection in CRF at training time. Note that other approaches have been proposed for feature selection, e.g. in (McCallum, 2003). This type of features selection, performed directly at training time, yields very accurate models, since only the most meaningful features are kept in the final model, which guarantee a strong robustness on unseen data. In this work we refer in particular to the CRF implementation described in (Lavergne et al., 2010). 3.2 SVM and Kernel Methods Our reranking model is based on SVM (Vapnik, 1998) with the use of the Partial Tree Kernel defined in (Moschitti, 2006). SVMs are well-known machine learning algorithms belonging to the class of maximal-margin linear classifiers (Vapnik, 1998). The model represents a hyperplane which separates the training examples with a maximum margin. The hyperplane is learned using optimization theory and is represented in the dual form as a linear combination of training examples: i=1..l yiαixix + b = 0, where xi, i E [1,.., l] are training examples representing objects oi and o in any feature space, yi is the label associated with xi and αi are the lagr</context>
<context position="32349" citStr="Vapnik, 1998" startWordPosition="5343" endWordPosition="5344">urprisingly word prefixes of length 2 are the most meaningful features. As expected, CATEGORY features are also very relevant features, since they provide a strong generalization over words. Another expected outcome is the fact that prefixes and suffixes of length 1 are the least relevant features. In figure 2(a), 2(b) and 2(c) we show the curves resulting from optimization of parameters of reranking models. In particular we optimized the M kernel parameter (µ decay factor, see (Moschitti, 2006) for details), and the C SVM parameter, i.e. the scale factor for the soft margin (please refer to (Vapnik, 1998) for SVM details). Figure 2(b) shows the learning time as a function of the C SVM parameter. This gives an idea of how long takes training our reranking models. In table 3 and 4 we report comparative results over the baseline CRF model, the baseline reranking model (CRF+RR) and the reranking models obtained applying the two improvements proposed in this work (CRF+RRSIM and CRF+RRWRR). As we can see, the baseline reranking model does not improve significantly the baseline CRF model. This outcome is expected since we don’t use any other information in the reranking model than the semantic tree s</context>
</contexts>
<marker>Vapnik, 1998</marker>
<rawString>Vladimir N. Vapnik. 1998. Statistical Learning Theory. John Wiley and Sons.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T J Sejnowski</author>
<author>C S Rosenberg</author>
</authors>
<title>Parallel networks that learn to pronounce English text.</title>
<date>1987</date>
<journal>Complex Systems,</journal>
<pages>1--145</pages>
<marker>Sejnowski, Rosenberg, 1987</marker>
<rawString>T. J. Sejnowski and C. S. Rosenberg. 1987. Parallel networks that learn to pronounce English text. Complex Systems, 1:145–168.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Hahn</author>
<author>Marco Dinarelli</author>
<author>Christian Raymond</author>
<author>Fabrice Lef`evre</author>
<author>Patrick Lehen</author>
<author>Renato De Mori</author>
<author>Alessandro Moschitti</author>
<author>Hermann Ney</author>
<author>Giuseppe Riccardi</author>
</authors>
<title>Comparing stochastic approaches to spoken language understanding in multiple languages.</title>
<date>2010</date>
<journal>IEEE Transactions on Audio, Speech and Language Processing (TASLP),</journal>
<volume>99</volume>
<marker>Hahn, Dinarelli, Raymond, Lef`evre, Lehen, De Mori, Moschitti, Ney, Riccardi, 2010</marker>
<rawString>Stefan Hahn, Marco Dinarelli, Christian Raymond, Fabrice Lef`evre, Patrick Lehen, Renato De Mori, Alessandro Moschitti, Hermann Ney, and Giuseppe Riccardi. 2010. Comparing stochastic approaches to spoken language understanding in multiple languages. IEEE Transactions on Audio, Speech and Language Processing (TASLP), 99.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Dinarelli</author>
<author>Alessandro Moschitti</author>
<author>Giuseppe Riccardi</author>
</authors>
<title>Re-ranking models based on small training data for spoken language understanding.</title>
<date>2009</date>
<booktitle>In Conference of Empirical Methods for Natural Language Processing,</booktitle>
<pages>11--18</pages>
<location>Singapore,</location>
<contexts>
<context position="2380" citStr="Dinarelli et al., 2009" startWordPosition="356" endWordPosition="359">ch MEDIA corpus. The results show significant improvements with respect to current state-of-the-art and previous 1104 re-ranking models. 1 Introduction Discriminative reranking is a widely used approach for several Natural Language Processing (NLP) tasks: Syntactic Parsing (Collins, 2000), Named Entity Recognition (Collins, 2000; Collins and Duffy, 2001), Semantic Role Labelling (Moschitti et al., 2008), Machine Translation (Shen et al., 2004), Question Answering (Moschitti et al., 2007). Recently reranking approaches have been successfully applied also to Spoken Language Understanding (SLU) (Dinarelli et al., 2009b). Discriminative Reranking combines two models: a first SLU model is used to generate a ranked list of n-best hypotheses; a reranking model sorts the list based on a different score and the final result is the new top ranked hypothesis. The advantage of reranking approaches is in the possibility to learn directly complex dependencies in the output domain, as this is provided in the hypotheses generated by the baseline model. In previous approaches complex features are extracted from the hypotheses for both training and classification phase, but there are very few studies on approaches that c</context>
<context position="8228" citStr="Dinarelli et al., 2009" startWordPosition="1267" endWordPosition="1270">ar combination of SMT models). Among these models, CRF has shown in general superior performances on sequence labeling tasks like Named Entity Recognition (NER) (Tjong Kim Sang and De Meulder, 2003), Grapheme-toPhoneme transcription (Sejnowski and Rosenberg, 1105 1987) and also Spoken Language Understanding (Hahn et al., 2008a). In addition to individual systems, more recently also some system combination approaches have been tried on SLU. In (Hahn et al., 2010), two such approaches are compared, one based on weighted ROVER (Fiscus, 1997) while the other is the reranking approach proposed in (Dinarelli et al., 2009b). Both system combination approaches are applied on the MEDIA corpus, thus we will refer to (Hahn et al., 2010) for a comparison with our approach. Like the other tasks mentioned above, SLU is usually a supervised learning task, this means that models are learned from annotated data. This is an important aspect to take into account when designing SLU systems. In this respect accurate SLU models can in part alleviate the problem of manually annotating data. The second step of SLU, that is Attribute Value Extraction (from now on AVE) is performed with two approaches: a) Rule-based approaches a</context>
<context position="20877" citStr="Dinarelli et al., 2009" startWordPosition="3407" endWordPosition="3410"> model; second, a strategy to decide, after the reranking phase, if it is more likely that the baseline best hypothesis is more accurate than the best reranked hypothesis and allowing to recover the mistake. Similar ideas have been proposed in (Dinarelli et al., 2010), here we propose a significant evolution and we give a much wider description and evaluation. 4.1 Hypotheses Selection via Attribute Value Extraction (AVE) In previous reranking approaches (Collins, 2000; Collins and Duffy, 2002; Shen et al., 2003a; Shen et al., 2003b; Shen et al., 2004; Collins and Koo, 2005; Kudo et al., 2005; Dinarelli et al., 2009b), few hypotheses are generated with the baseline model, ranked by the model probability. These are then used for the reranking model. An interesting strategy to improve reranking performance is the selection of the best set of hypotheses to be reranked. In this work we propose a semantic inconsistency metric (SIM) based on the attribute-value extraction phase that allows to select better n-best hypotheses. We combine the scores provided by the rule based approach and the CRF approach for AVE, computing a confidence measure. The rule-based approach for AVE is defined by a set of rules that ma</context>
</contexts>
<marker>Dinarelli, Moschitti, Riccardi, 2009</marker>
<rawString>Marco Dinarelli, Alessandro Moschitti, and Giuseppe Riccardi. 2009b. Re-ranking models based on small training data for spoken language understanding. In Conference of Empirical Methods for Natural Language Processing, pages 11–18, Singapore, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Dinarelli</author>
<author>Alessandro Moschitti</author>
<author>Giuseppe Riccardi</author>
</authors>
<title>Hypotheses Selection for Reranking Semantic Annotation.</title>
<date>2010</date>
<booktitle>In IEEE Workshop of Spoken Language Technology (SLT),</booktitle>
<location>Berkeley, USA.</location>
<contexts>
<context position="20523" citStr="Dinarelli et al., 2010" startWordPosition="3350" endWordPosition="3353">Shen et al., 2003b). 1108 Figure 1: An example of semantic tree constructed from an SLU hypothesis from the MEDIA corpus and used in PTK 4 Hypotheses Selection Criteria This section describes the main contribution of our work: first, a semantic inconsistency metric based on the AVE phase of SLU and allowing to select hypotheses generated by the baseline model; second, a strategy to decide, after the reranking phase, if it is more likely that the baseline best hypothesis is more accurate than the best reranked hypothesis and allowing to recover the mistake. Similar ideas have been proposed in (Dinarelli et al., 2010), here we propose a significant evolution and we give a much wider description and evaluation. 4.1 Hypotheses Selection via Attribute Value Extraction (AVE) In previous reranking approaches (Collins, 2000; Collins and Duffy, 2002; Shen et al., 2003a; Shen et al., 2003b; Shen et al., 2004; Collins and Koo, 2005; Kudo et al., 2005; Dinarelli et al., 2009b), few hypotheses are generated with the baseline model, ranked by the model probability. These are then used for the reranking model. An interesting strategy to improve reranking performance is the selection of the best set of hypotheses to be </context>
</contexts>
<marker>Dinarelli, Moschitti, Riccardi, 2010</marker>
<rawString>Marco Dinarelli, Alessandro Moschitti, and Giuseppe Riccardi. 2010. Hypotheses Selection for Reranking Semantic Annotation. In IEEE Workshop of Spoken Language Technology (SLT), Berkeley, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
</authors>
<title>Efficient Convolution Kernels for Dependency and Constituent Syntactic Trees.</title>
<date>2006</date>
<booktitle>In Proceedings ofECML 2006,</booktitle>
<pages>318--329</pages>
<location>Berlin, Germany.</location>
<contexts>
<context position="14637" citStr="Moschitti, 2006" startWordPosition="2350" endWordPosition="2351">ive way for feature selection in CRF at training time. Note that other approaches have been proposed for feature selection, e.g. in (McCallum, 2003). This type of features selection, performed directly at training time, yields very accurate models, since only the most meaningful features are kept in the final model, which guarantee a strong robustness on unseen data. In this work we refer in particular to the CRF implementation described in (Lavergne et al., 2010). 3.2 SVM and Kernel Methods Our reranking model is based on SVM (Vapnik, 1998) with the use of the Partial Tree Kernel defined in (Moschitti, 2006). SVMs are well-known machine learning algorithms belonging to the class of maximal-margin linear classifiers (Vapnik, 1998). The model represents a hyperplane which separates the training examples with a maximum margin. The hyperplane is learned using optimization theory and is represented in the dual form as a linear combination of training examples: i=1..l yiαixix + b = 0, where xi, i E [1,.., l] are training examples representing objects oi and o in any feature space, yi is the label associated with xi and αi are the lagrange multipliers. The dual form of the hyperplane shows that SVM trai</context>
<context position="15950" citStr="Moschitti, 2006" startWordPosition="2575" endWordPosition="2576">ianini, 2004), allows us to substitute the inner product with a so-called kernel function, computing the same result: K(oi, o) = xi · x. n+2 λm · hm (cn−1 cn, wn−2) M exp E m=1 N H n=1 EZ = ˜cN1 1107 The interesting aspect of using such formulation is the possibility to compare objects in arbitrarily complex feature spaces implicitly, i.e. without knowing the features to be used. Since in real world scenarios data cannot be classified using a simple linear classifier, kernel methods can be used to carry out learning in complex feature spaces. In this work we use the Partial Tree Kernel (PTK) (Moschitti, 2006). 3.3 Reranking Model In order to give an effective representation to SLU hypotheses in SVM, since we are using PTK, we need to represent as trees SLU hypotheses like the one described in section 2. This problem is easily solved by transforming the hypotheses into trees like the one depicted in figure 1. Although there may be more formal solutions to represent semantic information of SLU hypotheses as trees, we would like to remark that the tree structure shown in figure 1 contains all the key information needed for our purposes: the first level of the tree represents the concept sequence anno</context>
<context position="32236" citStr="Moschitti, 2006" startWordPosition="5323" endWordPosition="5324">ories (see section 3.3). As we can see from the table, although feature relevance depends of course from the task, surprisingly word prefixes of length 2 are the most meaningful features. As expected, CATEGORY features are also very relevant features, since they provide a strong generalization over words. Another expected outcome is the fact that prefixes and suffixes of length 1 are the least relevant features. In figure 2(a), 2(b) and 2(c) we show the curves resulting from optimization of parameters of reranking models. In particular we optimized the M kernel parameter (µ decay factor, see (Moschitti, 2006) for details), and the C SVM parameter, i.e. the scale factor for the soft margin (please refer to (Vapnik, 1998) for SVM details). Figure 2(b) shows the learning time as a function of the C SVM parameter. This gives an idea of how long takes training our reranking models. In table 3 and 4 we report comparative results over the baseline CRF model, the baseline reranking model (CRF+RR) and the reranking models obtained applying the two improvements proposed in this work (CRF+RRSIM and CRF+RRWRR). As we can see, the baseline reranking model does not improve significantly the baseline CRF model. </context>
</contexts>
<marker>Moschitti, 2006</marker>
<rawString>Alessandro Moschitti. 2006. Efficient Convolution Kernels for Dependency and Constituent Syntactic Trees. In Proceedings ofECML 2006, pages 318–329, Berlin, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
<author>N Duffy</author>
</authors>
<title>New Ranking Algorithms for Parsing and Tagging: Kernels over Discrete structures, and the voted perceptron.</title>
<date>2002</date>
<booktitle>In Proceedings of the Association for Computational Linguistics,</booktitle>
<pages>263--270</pages>
<contexts>
<context position="19316" citStr="Collins and Duffy, 2002" startWordPosition="3154" endWordPosition="3157">the reranker using the following reranking kernel: KR(e1, e2) = PTK(t1,1, t1,2) + PTK(t2,1, t2,2) (4) − PTK(t1,1, t2,2) − PTK(t2,1,t1,2), where e1 and e2 are two pairs of trees to be compared. The reranking kernel in equation 4, consisting in summing four different kernels, has been proposed in (Shen et al., 2003b) for syntactic parsing reranking, where the basic kernel was a Tree Kernel, and the idea was taken in turn from (Heibrich et al., 2000), where pairs where used to learn preference ranking. The same idea appears also, in a slightly different form, in early work about reranking, e.g. (Collins and Duffy, 2002). The same reranking schema has been used also in (Shen et al., 2004) for reranking different candidate hypotheses for machine translation. For classification, observing that the model is symmetric and exploiting kernel properties, we can use, as classification instances, simple hypotheses instead of pairs. More precisely we use pairs where the second hypothesis is empty, i.e. (Hi, 0), for i E [1..n]. This simplification allow a relatively fast classification phase, since only n instances are generated for each sentence, instead of n2. This simplification has been proposed in (Shen et al., 200</context>
<context position="20752" citStr="Collins and Duffy, 2002" startWordPosition="3383" endWordPosition="3386">rst, a semantic inconsistency metric based on the AVE phase of SLU and allowing to select hypotheses generated by the baseline model; second, a strategy to decide, after the reranking phase, if it is more likely that the baseline best hypothesis is more accurate than the best reranked hypothesis and allowing to recover the mistake. Similar ideas have been proposed in (Dinarelli et al., 2010), here we propose a significant evolution and we give a much wider description and evaluation. 4.1 Hypotheses Selection via Attribute Value Extraction (AVE) In previous reranking approaches (Collins, 2000; Collins and Duffy, 2002; Shen et al., 2003a; Shen et al., 2003b; Shen et al., 2004; Collins and Koo, 2005; Kudo et al., 2005; Dinarelli et al., 2009b), few hypotheses are generated with the baseline model, ranked by the model probability. These are then used for the reranking model. An interesting strategy to improve reranking performance is the selection of the best set of hypotheses to be reranked. In this work we propose a semantic inconsistency metric (SIM) based on the attribute-value extraction phase that allows to select better n-best hypotheses. We combine the scores provided by the rule based approach and t</context>
<context position="33029" citStr="Collins and Duffy, 2002" startWordPosition="5458" endWordPosition="5461">s a function of the C SVM parameter. This gives an idea of how long takes training our reranking models. In table 3 and 4 we report comparative results over the baseline CRF model, the baseline reranking model (CRF+RR) and the reranking models obtained applying the two improvements proposed in this work (CRF+RRSIM and CRF+RRWRR). As we can see, the baseline reranking model does not improve significantly the baseline CRF model. This outcome is expected since we don’t use any other information in the reranking model than the semantic tree shown in figure 1. Previous approaches like for example (Collins and Duffy, 2002), use the baseline model score as feature, as that the reranking model cannot do worst than the baseline model. As we pointed out in section 4.2, this solution require a fine tuning of the reranking model, especially when the baseline model is relatively accurate. In our case, the CRF model has a Sentence Error Rate of 25.0% on the MEDIA test set. This means that 75% of the times the best hypothesis of CRF is correct. In turn this implies that the reranking model must not rerank 75% of times and rerank the other 25% of times, someway contrasting the evidence provided by the baseline model scor</context>
</contexts>
<marker>Collins, Duffy, 2002</marker>
<rawString>M. Collins and N. Duffy. 2002. New Ranking Algorithms for Parsing and Tagging: Kernels over Discrete structures, and the voted perceptron. In Proceedings of the Association for Computational Linguistics, pages 263–270.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Libin Shen</author>
<author>Anoop Sarkar</author>
<author>Aravind K Joshi</author>
</authors>
<title>Using LTAG Based Features in Parse Reranking.</title>
<date>2003</date>
<booktitle>In Proceedings of EMNLP’06.</booktitle>
<contexts>
<context position="18470" citStr="Shen et al., 2003" startWordPosition="3006" endWordPosition="3009">iven metric. In particular, we compute the edit distance of each hypothesis in the list, with respect to the manual annotation taken from the corpus. The best hypothesis Hb is used to build positive instances for the reranker as pairs (Hb, Hi) for i E [1..n] and i =� b, negative instances are built as (Hi, Hb), with same constraints on index i. This means that, if n hypotheses are generated for a sentence, 2 · n instances are generated from them. Note that by construction of pairs the model is symmetric, this provides a property that will be exploited at classification phase, as described in (Shen et al., 2003b). Hypotheses are then converted into trees like the one shown in figure 1. Pairs of trees ek = (ti,k, tj,k), for k varying along all the training or classification instances, are given as input to the SVM model to train the reranker using the following reranking kernel: KR(e1, e2) = PTK(t1,1, t1,2) + PTK(t2,1, t2,2) (4) − PTK(t1,1, t2,2) − PTK(t2,1,t1,2), where e1 and e2 are two pairs of trees to be compared. The reranking kernel in equation 4, consisting in summing four different kernels, has been proposed in (Shen et al., 2003b) for syntactic parsing reranking, where the basic kernel was a</context>
<context position="19917" citStr="Shen et al., 2003" startWordPosition="3249" endWordPosition="3252">and Duffy, 2002). The same reranking schema has been used also in (Shen et al., 2004) for reranking different candidate hypotheses for machine translation. For classification, observing that the model is symmetric and exploiting kernel properties, we can use, as classification instances, simple hypotheses instead of pairs. More precisely we use pairs where the second hypothesis is empty, i.e. (Hi, 0), for i E [1..n]. This simplification allow a relatively fast classification phase, since only n instances are generated for each sentence, instead of n2. This simplification has been proposed in (Shen et al., 2003b). 1108 Figure 1: An example of semantic tree constructed from an SLU hypothesis from the MEDIA corpus and used in PTK 4 Hypotheses Selection Criteria This section describes the main contribution of our work: first, a semantic inconsistency metric based on the AVE phase of SLU and allowing to select hypotheses generated by the baseline model; second, a strategy to decide, after the reranking phase, if it is more likely that the baseline best hypothesis is more accurate than the best reranked hypothesis and allowing to recover the mistake. Similar ideas have been proposed in (Dinarelli et al.,</context>
</contexts>
<marker>Shen, Sarkar, Joshi, 2003</marker>
<rawString>Libin Shen, Anoop Sarkar, and Aravind K. Joshi. 2003. Using LTAG Based Features in Parse Reranking. In Proceedings of EMNLP’06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ralf Herbrich</author>
<author>Thore Graepel</author>
<author>Klaus Obermayer</author>
</authors>
<title>Large Margin Rank Boundaries for Ordinal Regression.</title>
<date>2000</date>
<booktitle>In Advances in Large Margin Classifiers.</booktitle>
<marker>Herbrich, Graepel, Obermayer, 2000</marker>
<rawString>Herbrich, Ralf and Graepel, Thore and Obermayer, Klaus. 2000. Large Margin Rank Boundaries for Ordinal Regression. In Advances in Large Margin Classifiers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Libin Shen</author>
<author>Aravind K Joshi</author>
</authors>
<title>An SVM Based Voting Algorithm with Application to Parse Reranking.</title>
<date>2003</date>
<booktitle>In Proceedings of CoNLL</booktitle>
<marker>Shen, Joshi, 2003</marker>
<rawString>Libin Shen, and Aravind K. Joshi. 2003. An SVM Based Voting Algorithm with Application to Parse Reranking. In Proceedings of CoNLL 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Libin Shen</author>
<author>Anoop Sarkar</author>
<author>Franz J Och</author>
</authors>
<title>Discriminative reranking for machine translation. In</title>
<date>2004</date>
<booktitle>HLTNAACL,</booktitle>
<pages>177--184</pages>
<contexts>
<context position="2205" citStr="Shen et al., 2004" startWordPosition="332" endWordPosition="335">se solutions presenting comparative results obtained reranking hypotheses generated by a very accurate Conditional Random Field model. We evaluate our approach on the French MEDIA corpus. The results show significant improvements with respect to current state-of-the-art and previous 1104 re-ranking models. 1 Introduction Discriminative reranking is a widely used approach for several Natural Language Processing (NLP) tasks: Syntactic Parsing (Collins, 2000), Named Entity Recognition (Collins, 2000; Collins and Duffy, 2001), Semantic Role Labelling (Moschitti et al., 2008), Machine Translation (Shen et al., 2004), Question Answering (Moschitti et al., 2007). Recently reranking approaches have been successfully applied also to Spoken Language Understanding (SLU) (Dinarelli et al., 2009b). Discriminative Reranking combines two models: a first SLU model is used to generate a ranked list of n-best hypotheses; a reranking model sorts the list based on a different score and the final result is the new top ranked hypothesis. The advantage of reranking approaches is in the possibility to learn directly complex dependencies in the output domain, as this is provided in the hypotheses generated by the baseline m</context>
<context position="19385" citStr="Shen et al., 2004" startWordPosition="3167" endWordPosition="3170">1,2) + PTK(t2,1, t2,2) (4) − PTK(t1,1, t2,2) − PTK(t2,1,t1,2), where e1 and e2 are two pairs of trees to be compared. The reranking kernel in equation 4, consisting in summing four different kernels, has been proposed in (Shen et al., 2003b) for syntactic parsing reranking, where the basic kernel was a Tree Kernel, and the idea was taken in turn from (Heibrich et al., 2000), where pairs where used to learn preference ranking. The same idea appears also, in a slightly different form, in early work about reranking, e.g. (Collins and Duffy, 2002). The same reranking schema has been used also in (Shen et al., 2004) for reranking different candidate hypotheses for machine translation. For classification, observing that the model is symmetric and exploiting kernel properties, we can use, as classification instances, simple hypotheses instead of pairs. More precisely we use pairs where the second hypothesis is empty, i.e. (Hi, 0), for i E [1..n]. This simplification allow a relatively fast classification phase, since only n instances are generated for each sentence, instead of n2. This simplification has been proposed in (Shen et al., 2003b). 1108 Figure 1: An example of semantic tree constructed from an S</context>
<context position="20811" citStr="Shen et al., 2004" startWordPosition="3395" endWordPosition="3398">U and allowing to select hypotheses generated by the baseline model; second, a strategy to decide, after the reranking phase, if it is more likely that the baseline best hypothesis is more accurate than the best reranked hypothesis and allowing to recover the mistake. Similar ideas have been proposed in (Dinarelli et al., 2010), here we propose a significant evolution and we give a much wider description and evaluation. 4.1 Hypotheses Selection via Attribute Value Extraction (AVE) In previous reranking approaches (Collins, 2000; Collins and Duffy, 2002; Shen et al., 2003a; Shen et al., 2003b; Shen et al., 2004; Collins and Koo, 2005; Kudo et al., 2005; Dinarelli et al., 2009b), few hypotheses are generated with the baseline model, ranked by the model probability. These are then used for the reranking model. An interesting strategy to improve reranking performance is the selection of the best set of hypotheses to be reranked. In this work we propose a semantic inconsistency metric (SIM) based on the attribute-value extraction phase that allows to select better n-best hypotheses. We combine the scores provided by the rule based approach and the CRF approach for AVE, computing a confidence measure. Th</context>
</contexts>
<marker>Shen, Sarkar, Och, 2004</marker>
<rawString>Libin Shen, Anoop Sarkar, and Franz J. Och. 2004. Discriminative reranking for machine translation. In HLTNAACL, pages 177–184.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taku Kudo</author>
<author>Jun Suzuki</author>
<author>Hideki Isozaki</author>
</authors>
<title>Boosting-based parse reranking with subtree features.</title>
<date>2005</date>
<booktitle>In Proceedings ofACL’05.</booktitle>
<contexts>
<context position="20853" citStr="Kudo et al., 2005" startWordPosition="3403" endWordPosition="3406">ted by the baseline model; second, a strategy to decide, after the reranking phase, if it is more likely that the baseline best hypothesis is more accurate than the best reranked hypothesis and allowing to recover the mistake. Similar ideas have been proposed in (Dinarelli et al., 2010), here we propose a significant evolution and we give a much wider description and evaluation. 4.1 Hypotheses Selection via Attribute Value Extraction (AVE) In previous reranking approaches (Collins, 2000; Collins and Duffy, 2002; Shen et al., 2003a; Shen et al., 2003b; Shen et al., 2004; Collins and Koo, 2005; Kudo et al., 2005; Dinarelli et al., 2009b), few hypotheses are generated with the baseline model, ranked by the model probability. These are then used for the reranking model. An interesting strategy to improve reranking performance is the selection of the best set of hypotheses to be reranked. In this work we propose a semantic inconsistency metric (SIM) based on the attribute-value extraction phase that allows to select better n-best hypotheses. We combine the scores provided by the rule based approach and the CRF approach for AVE, computing a confidence measure. The rule-based approach for AVE is defined b</context>
</contexts>
<marker>Kudo, Suzuki, Isozaki, 2005</marker>
<rawString>Taku Kudo, Jun Suzuki, and Hideki Isozaki. 2005. Boosting-based parse reranking with subtree features. In Proceedings ofACL’05.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Hahn</author>
<author>Patrick Lehnen</author>
<author>Hermann Ney</author>
</authors>
<title>System combination for spoken language understanding.</title>
<date>2008</date>
<booktitle>In Proceedings of the International Conference of the Speech Communication Assosiation (Interspeech),</booktitle>
<pages>236--239</pages>
<location>Brisbane, Australia.</location>
<contexts>
<context position="7436" citStr="Hahn et al., 2008" startWordPosition="1143" endWordPosition="1146"> reservation, hotel and London are the normalized attribute values, defined also in the application ontology. This representation is usually called attribute-value representation. In the last decade several probabilistic models have been proposed for the Automatic Concept Labeling step: in (Raymond et al., 2006) a conceptual language model encoded in Stochastic Finite State Transducers (SFST) is proposed. In (Raymond and Riccardi, 2007), the SFST-based model is compared with Support Vector Machines (SVM) (Vapnik, 1998) and Conditional Random Fields (CRF) (Lafferty et al., 2001). Moreover, in (Hahn et al., 2008a) two more models are applied to SLU: a Maximum Entropy (EM) model and a model coming from the Statistical Machine Translation (SMT) community (it is actually a log-linear combination of SMT models). Among these models, CRF has shown in general superior performances on sequence labeling tasks like Named Entity Recognition (NER) (Tjong Kim Sang and De Meulder, 2003), Grapheme-toPhoneme transcription (Sejnowski and Rosenberg, 1105 1987) and also Spoken Language Understanding (Hahn et al., 2008a). In addition to individual systems, more recently also some system combination approaches have been </context>
</contexts>
<marker>Hahn, Lehnen, Ney, 2008</marker>
<rawString>Stefan Hahn, Patrick Lehnen, and Hermann Ney. 2008a. System combination for spoken language understanding. In Proceedings of the International Conference of the Speech Communication Assosiation (Interspeech), pages 236–239, Brisbane, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J G Fiscus</author>
</authors>
<title>A post-processing system to yield reduced word error rates: Recogniser output voting error reduction (ROVER).</title>
<date>1997</date>
<booktitle>In Proceedings</booktitle>
<pages>347--352</pages>
<location>Santa Barbara, CA,</location>
<contexts>
<context position="8150" citStr="Fiscus, 1997" startWordPosition="1255" endWordPosition="1256">stical Machine Translation (SMT) community (it is actually a log-linear combination of SMT models). Among these models, CRF has shown in general superior performances on sequence labeling tasks like Named Entity Recognition (NER) (Tjong Kim Sang and De Meulder, 2003), Grapheme-toPhoneme transcription (Sejnowski and Rosenberg, 1105 1987) and also Spoken Language Understanding (Hahn et al., 2008a). In addition to individual systems, more recently also some system combination approaches have been tried on SLU. In (Hahn et al., 2010), two such approaches are compared, one based on weighted ROVER (Fiscus, 1997) while the other is the reranking approach proposed in (Dinarelli et al., 2009b). Both system combination approaches are applied on the MEDIA corpus, thus we will refer to (Hahn et al., 2010) for a comparison with our approach. Like the other tasks mentioned above, SLU is usually a supervised learning task, this means that models are learned from annotated data. This is an important aspect to take into account when designing SLU systems. In this respect accurate SLU models can in part alleviate the problem of manually annotating data. The second step of SLU, that is Attribute Value Extraction </context>
</contexts>
<marker>Fiscus, 1997</marker>
<rawString>J. G. Fiscus. 1997. A post-processing system to yield reduced word error rates: Recogniser output voting error reduction (ROVER). In Proceedings 1997 IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU), pages 347–352, Santa Barbara, CA, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Shawe-Taylor</author>
<author>Nello Cristianini</author>
</authors>
<title>Kernel Methods for Pattern Analysis.</title>
<date>2004</date>
<publisher>Cambridge University Press.</publisher>
<marker>Shawe-Taylor, Cristianini, 2004</marker>
<rawString>John Shawe-Taylor and Nello Cristianini. 2004. Kernel Methods for Pattern Analysis. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Discriminative reranking for natural language parsing.</title>
<date>2000</date>
<booktitle>In ICML,</booktitle>
<pages>175--182</pages>
<contexts>
<context position="2047" citStr="Collins, 2000" startWordPosition="311" endWordPosition="312">the first ranked hypothesis provided by the baseline SLU model and the first ranked hypothesis provided by the re-ranker. We show the effectiveness of these solutions presenting comparative results obtained reranking hypotheses generated by a very accurate Conditional Random Field model. We evaluate our approach on the French MEDIA corpus. The results show significant improvements with respect to current state-of-the-art and previous 1104 re-ranking models. 1 Introduction Discriminative reranking is a widely used approach for several Natural Language Processing (NLP) tasks: Syntactic Parsing (Collins, 2000), Named Entity Recognition (Collins, 2000; Collins and Duffy, 2001), Semantic Role Labelling (Moschitti et al., 2008), Machine Translation (Shen et al., 2004), Question Answering (Moschitti et al., 2007). Recently reranking approaches have been successfully applied also to Spoken Language Understanding (SLU) (Dinarelli et al., 2009b). Discriminative Reranking combines two models: a first SLU model is used to generate a ranked list of n-best hypotheses; a reranking model sorts the list based on a different score and the final result is the new top ranked hypothesis. The advantage of reranking a</context>
<context position="20727" citStr="Collins, 2000" startWordPosition="3381" endWordPosition="3382">of our work: first, a semantic inconsistency metric based on the AVE phase of SLU and allowing to select hypotheses generated by the baseline model; second, a strategy to decide, after the reranking phase, if it is more likely that the baseline best hypothesis is more accurate than the best reranked hypothesis and allowing to recover the mistake. Similar ideas have been proposed in (Dinarelli et al., 2010), here we propose a significant evolution and we give a much wider description and evaluation. 4.1 Hypotheses Selection via Attribute Value Extraction (AVE) In previous reranking approaches (Collins, 2000; Collins and Duffy, 2002; Shen et al., 2003a; Shen et al., 2003b; Shen et al., 2004; Collins and Koo, 2005; Kudo et al., 2005; Dinarelli et al., 2009b), few hypotheses are generated with the baseline model, ranked by the model probability. These are then used for the reranking model. An interesting strategy to improve reranking performance is the selection of the best set of hypotheses to be reranked. In this work we propose a semantic inconsistency metric (SIM) based on the attribute-value extraction phase that allows to select better n-best hypotheses. We combine the scores provided by the </context>
</contexts>
<marker>Collins, 2000</marker>
<rawString>Michael Collins. 2000. Discriminative reranking for natural language parsing. In ICML, pages 175–182.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Nigel Duffy</author>
</authors>
<title>Convolution kernels for natural language.</title>
<date>2001</date>
<booktitle>In Advances in Neural Information Processing Systems 14,</booktitle>
<pages>625--632</pages>
<publisher>MIT Press.</publisher>
<contexts>
<context position="2114" citStr="Collins and Duffy, 2001" startWordPosition="319" endWordPosition="322">model and the first ranked hypothesis provided by the re-ranker. We show the effectiveness of these solutions presenting comparative results obtained reranking hypotheses generated by a very accurate Conditional Random Field model. We evaluate our approach on the French MEDIA corpus. The results show significant improvements with respect to current state-of-the-art and previous 1104 re-ranking models. 1 Introduction Discriminative reranking is a widely used approach for several Natural Language Processing (NLP) tasks: Syntactic Parsing (Collins, 2000), Named Entity Recognition (Collins, 2000; Collins and Duffy, 2001), Semantic Role Labelling (Moschitti et al., 2008), Machine Translation (Shen et al., 2004), Question Answering (Moschitti et al., 2007). Recently reranking approaches have been successfully applied also to Spoken Language Understanding (SLU) (Dinarelli et al., 2009b). Discriminative Reranking combines two models: a first SLU model is used to generate a ranked list of n-best hypotheses; a reranking model sorts the list based on a different score and the final result is the new top ranked hypothesis. The advantage of reranking approaches is in the possibility to learn directly complex dependenc</context>
</contexts>
<marker>Collins, Duffy, 2001</marker>
<rawString>Michael Collins and Nigel Duffy. 2001. Convolution kernels for natural language. In Advances in Neural Information Processing Systems 14, pages 625–632. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander M Rush</author>
<author>David Sontag</author>
<author>Michael Collins</author>
<author>Tommi Jaakkola</author>
</authors>
<title>On dual decomposition and linear programming relaxations for natural language processing.</title>
<date>2010</date>
<booktitle>In Empirical Methods for Natural Language Processing (EMNLP).</booktitle>
<location>Cambridge, Massachusetts, USA.</location>
<marker>Rush, Sontag, Collins, Jaakkola, 2010</marker>
<rawString>Rush, Alexander M. and Sontag, David and Collins, Michael and Jaakkola, Tommi. 2010. On dual decomposition and linear programming relaxations for natural language processing. In Empirical Methods for Natural Language Processing (EMNLP). Cambridge, Massachusetts, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
<author>Daniele Pighin</author>
<author>Roberto Basili</author>
</authors>
<title>Tree kernels for semantic role labeling.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>2</issue>
<contexts>
<context position="2164" citStr="Moschitti et al., 2008" startWordPosition="326" endWordPosition="329">he re-ranker. We show the effectiveness of these solutions presenting comparative results obtained reranking hypotheses generated by a very accurate Conditional Random Field model. We evaluate our approach on the French MEDIA corpus. The results show significant improvements with respect to current state-of-the-art and previous 1104 re-ranking models. 1 Introduction Discriminative reranking is a widely used approach for several Natural Language Processing (NLP) tasks: Syntactic Parsing (Collins, 2000), Named Entity Recognition (Collins, 2000; Collins and Duffy, 2001), Semantic Role Labelling (Moschitti et al., 2008), Machine Translation (Shen et al., 2004), Question Answering (Moschitti et al., 2007). Recently reranking approaches have been successfully applied also to Spoken Language Understanding (SLU) (Dinarelli et al., 2009b). Discriminative Reranking combines two models: a first SLU model is used to generate a ranked list of n-best hypotheses; a reranking model sorts the list based on a different score and the final result is the new top ranked hypothesis. The advantage of reranking approaches is in the possibility to learn directly complex dependencies in the output domain, as this is provided in t</context>
</contexts>
<marker>Moschitti, Pighin, Basili, 2008</marker>
<rawString>Alessandro Moschitti, Daniele Pighin, and Roberto Basili. 2008. Tree kernels for semantic role labeling. Computational Linguistics, 34(2):193–224.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
<author>Silvia Quarteroni</author>
<author>Roberto Basili</author>
<author>Suresh Manandhar</author>
</authors>
<title>Exploiting syntactic and shallow semantic kernels for question/answer classification.</title>
<date>2007</date>
<booktitle>In Proceedings of ACL’07,</booktitle>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="2250" citStr="Moschitti et al., 2007" startWordPosition="338" endWordPosition="341">lts obtained reranking hypotheses generated by a very accurate Conditional Random Field model. We evaluate our approach on the French MEDIA corpus. The results show significant improvements with respect to current state-of-the-art and previous 1104 re-ranking models. 1 Introduction Discriminative reranking is a widely used approach for several Natural Language Processing (NLP) tasks: Syntactic Parsing (Collins, 2000), Named Entity Recognition (Collins, 2000; Collins and Duffy, 2001), Semantic Role Labelling (Moschitti et al., 2008), Machine Translation (Shen et al., 2004), Question Answering (Moschitti et al., 2007). Recently reranking approaches have been successfully applied also to Spoken Language Understanding (SLU) (Dinarelli et al., 2009b). Discriminative Reranking combines two models: a first SLU model is used to generate a ranked list of n-best hypotheses; a reranking model sorts the list based on a different score and the final result is the new top ranked hypothesis. The advantage of reranking approaches is in the possibility to learn directly complex dependencies in the output domain, as this is provided in the hypotheses generated by the baseline model. In previous approaches complex features</context>
</contexts>
<marker>Moschitti, Quarteroni, Basili, Manandhar, 2007</marker>
<rawString>Alessandro Moschitti, Silvia Quarteroni, Roberto Basili, and Suresh Manandhar. 2007. Exploiting syntactic and shallow semantic kernels for question/answer classification. In Proceedings of ACL’07, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Yeh</author>
<author>Kelmeth Church</author>
</authors>
<title>More accurate tests for the statistical significance of result differences.</title>
<date>2000</date>
<contexts>
<context position="34762" citStr="Yeh and Church, 2000" startWordPosition="5740" endWordPosition="5743">RSIM 7.5 2381/2758 CRF+RRWRR 7.5 2444/2758 Table 5: Analysis over 10-best hypotheses for CRF baseline and the reranking models showing the effect of hypotheses selection MEDIA Text Input DEV TEST Model Pair Attr+Val Attr+Val CRF vs. CRF+RR 0.2235 0.4075 CRF vs. CRF+RRSIM 0.0299 0.065 CRF vs. CRF+RRWRR 0.0044 1.9998E-4 CRF+RR vs. CRF+RRSIM 0.002 5.9994E-4 CRF+RR vs. CRF+RRWRR 4.9995E-4 9.999E-5 CRF+RRSIM vs. CRF+RRWRR 0.1355 0.0031 Table 6: Significance tests on results of models described in this work. The significance test is based on computationally-intensive randomizations as described in (Yeh and Church, 2000). proves in some cases, state-of-the-art performance. This is particularly meaningful since best results reported in (Hahn et al., 2010) are obtained combining 6 different SLU models. In table 5 we report some statistics to show the effect of SIM on the 10-best hypotheses list. It is particularly interesting to see that when hypotheses selection is applied, oracle error rate (OER) drops of 2% points from an already accurate OER of 9.5%. This is reflected also by the number of oracles present in the 10-best list without applying and applying SIM. We pass from 2657 without SIM to 2758 applying o</context>
</contexts>
<marker>Yeh, Church, 2000</marker>
<rawString>Alexander Yeh and Kelmeth Church. 2000. More accurate tests for the statistical significance of result differences.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>