<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000580">
<title confidence="0.992306">
Sentence Diagram Generation Using Dependency Parsing
</title>
<author confidence="0.998007">
Elijah Mayfield
</author>
<affiliation confidence="0.998781">
Division of Science and Mathematics
University of Minnesota, Morris
</affiliation>
<email confidence="0.995817">
mayf0016@morris.umn.edu
</email>
<sectionHeader confidence="0.99384" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999932695652174">
Dependency parsers show syntactic re-
lations between words using a directed
graph, but comparing dependency parsers
is difficult because of differences in the-
oretical models. We describe a system
to convert dependency models to a struc-
tural grammar used in grammar educa-
tion. Doing so highlights features that are
potentially overlooked in the dependency
graph, as well as exposing potential weak-
nesses and limitations in parsing models.
Our system performs automated analysis
of dependency relations and uses them to
populate a data structure we designed to
emulate sentence diagrams. This is done
by mapping dependency relations between
words to the relative positions of those
words in a sentence diagram. Using an
original metric for judging the accuracy of
sentence diagrams, we achieve precision
of 85%. Multiple causes for errors are pre-
sented as potential areas for improvement
in dependency parsers.
</bodyText>
<sectionHeader confidence="0.961118" genericHeader="keywords">
1 Dependency parsing
</sectionHeader>
<bodyText confidence="0.999917">
Dependencies are generally considered a strong
metric of accuracy in parse trees, as described in
(Lin, 1995). In a dependency parse, words are
connected to each other through relations, with a
head word (the governor) being modified by a de-
pendent word. By converting parse trees to de-
pendency representations before judging accuracy,
more detailed syntactic information can be discov-
ered. Recently, however, a number of dependency
parsers have been developed that have very differ-
ent theories of a correct model of dependencies.
Dependency parsers define syntactic relations
between words in a sentence. This can be done
either through spanning tree search as in (McDon-
ald et al., 2005), which is computationally expen-
sive, or through analysis of another modeling sys-
tem, such as a phrase structure parse tree, which
can introduce errors from the long pipeline. To
the best of our knowledge, the first use of de-
pendency relations as an evaluation tool for parse
trees was in (Lin, 1995), which described a pro-
cess for determining heads in phrase structures
and assigning modifiers to those heads appropri-
ately. Because of different ways to describe rela-
tions between negations, conjunctions, and other
grammatical structures, it was immediately clear
that comparing different models would be diffi-
cult. Research into this area of evaluation pro-
duced several new dependency parsers, each us-
ing different theories of what constitutes a cor-
rect parse. In addition, attempts to model multi-
ple parse trees in a single dependency relation sys-
tem were often stymied by problems such as dif-
ferences in tokenization systems. These problems
are discussed by (Lin, 1998) in greater detail. An
attempt to reconcile differences between parsers
was described in (Marneffe et al., 2006). In this
paper, a dependency parser (from herein referred
to as the Stanford parser) was developed and com-
pared to two other systems: MINIPAR, described
in (Lin, 1998), and the Link parser of (Sleator and
Temperley, 1993), which uses a radically differ-
ent approach but produces a similar, if much more
fine-grained, result.
Comparing dependency parsers is difficult. The
main problem is that there is no clear way to com-
pare models which mark dependencies differently.
For instance, when clauses are linked by a con-
junction, the Link parser considers the conjunction
related to the subject of a clause, while the Stan-
ford parser links the conjunction to the verb of a
clause. In (Marneffe et al., 2006), a simple com-
parison was used to alleviate this problem, which
was based only on the presence of dependencies,
without semantic information. This solution loses
</bodyText>
<page confidence="0.993005">
45
</page>
<note confidence="0.997002">
Proceedings of the ACL-IJCNLP 2009 Student Research Workshop, pages 45–53,
Suntec, Singapore, 4 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.999962764705883">
information and is still subject to many problems
in representational differences. Another problem
with this approach is that they only used ten sen-
tences for comparison, randomly selected from the
Brown corpus. This sparse data set is not necessar-
ily congruous with the overall accuracy of these
parsers.
In this paper, we propose a novel solution to
the difficulty of converting between dependency
models. The options that have previously been
presented for comparing dependency models are
either too specific to be accurate (relying on an-
notation schemes that are not adequately parallel
for comparison) or too coarse to be useful (such
as merely checking for the existence of depen-
dencies). By using a model of language which
is not as fine-grained as the models used by de-
pendency parsers, but still contains some semantic
information beyond unlabelled relations, a com-
promise can be made. We show that using linear
diagramming models can do this with acceptable
error rates, and hope that future work can use this
to compare multiple dependency models.
Section 2 describes structural grammar, its his-
tory, and its usefulness as a representation of syn-
tax. Section 3 describes our algorithm for conver-
sion from dependency graphs to a structural rep-
resentation. Section 4 describes the process we
used for developing and testing the accuracy of
this algorithm, and Section 5 discusses our results
and a variety of features, as well as limitations and
weaknesses, that we have found in the dependency
representation of (Marneffe et al., 2006) as a result
of this conversion.
</bodyText>
<sectionHeader confidence="0.986068" genericHeader="introduction">
2 Introduction to structural grammar
</sectionHeader>
<bodyText confidence="0.999577037037037">
Structural grammar is an approach to natural lan-
guage based on the understanding that the major-
ity of sentences in the English language can be
matched to one of ten patterns. Each of these pat-
terns has a set of slots. Two slots are universal
among these patterns: the subject and the predi-
cate. Three additional slots may also occur: the
direct object, the subject complement, and the ob-
ject complement. A head word fills each of these
slots. In addition, any word in a sentence may be
modified by an additional word. Finally, anywhere
that a word could be used, a substitution may be
made, allowing the position of a word to be filled
by a multiple-word phrase or an entire subclause,
with its own pattern and set of slots.
To understand these relationships better, a stan-
dardized system of sentence diagramming has
been developed. With a relatively small number of
rules, a great deal of information about the func-
tion of each word in a sentence can be represented
in a compact form, using orientation and other spa-
tial clues. This provides a simpler and intuitive
means of visualizing relationships between words,
especially when compared to the complexity of di-
rected dependency graphs. For the purposes of this
paper, we use the system of diagramming formal-
ized in (Kolln and Funk, 2002).
</bodyText>
<subsectionHeader confidence="0.954213">
2.1 History
</subsectionHeader>
<bodyText confidence="0.99997016">
First developed in the early 20th century, structural
grammar was a response to the prescriptive gram-
mar approach of the time. Structural grammar de-
scribes how language actually is used, rather than
prescribing how grammar should be used. This
approach allows an emphasis to be placed on the
systematic and formulaic nature of language. A
key change involved the shift to general role-based
description of the usage of a word, whereas the fo-
cus before had been on declaring words to fall into
strict categories (such as the eight parts of speech
found in Latin).
Beginning with the work of Chomsky in the
1950s on transformational grammar, sentence di-
agrams, used in both structural and prescriptive
approaches, slowly lost favor in educational tech-
niques. This is due to the introduction of trans-
formational grammar, based on generative theo-
ries and intrinsic rules of natural language struc-
ture. This generative approach is almost uni-
versally used in natural language processing, as
generative rules are well-suited to computational
representation. Nevertheless, both structural and
transformational grammar are taught at secondary
and undergraduate levels.
</bodyText>
<subsectionHeader confidence="0.999908">
2.2 Applications of structural grammar
</subsectionHeader>
<bodyText confidence="0.999945818181818">
Structural grammar still has a number of advan-
tages over generative transformational grammar.
Because it is designed to emulate the natural usage
of language, it is more intuitive for non-experts to
understand. It also highlights certain features of
sentences, such as dependency relationships be-
tween words and targets of actions. Many facets
of natural language are difficult to describe using
a parse tree or other generative data structure. Us-
ing structural techniques, many of these aspects
are obvious upon basic analysis.
</bodyText>
<page confidence="0.999355">
46
</page>
<figureCaption confidence="0.9952695">
Figure 1: Diagram of “The students are scholars.”
and “The students studied their assignment.”
</figureCaption>
<bodyText confidence="0.999984473684211">
By developing an algorithm to automatically
analyze a sentence using structural grammar, we
hope that the advantages of structural analysis
can improve the performance of natural language
parsers. By assigning roles to words in a sentence,
patterns or structures in natural language that can-
not be easily gleaned from a data structure are
made obvious, highlighting the limitations of that
structure. It is also important to note that while
sentence diagrams are primarily used for English,
they can be adapted to any language which uses
subjects, verbs, and objects (word order is not im-
portant in sentence diagramming). This research
can therefore be expanded into multilingual de-
pendency parser systems in the future.
To test the effectiveness of these approaches, a
system must be developed for structural analysis
of sentences and subsequent conversion to a sen-
tence diagram.
</bodyText>
<sectionHeader confidence="0.918049" genericHeader="method">
3 Sentence diagram generation
algorithm
</sectionHeader>
<bodyText confidence="0.999932428571428">
In order to generate a sentence diagram, we make
use of typed dependency graphs from the Stanford
dependency parser. To understand this process
requires understanding both the underlying data
structure representing a sentence diagram, and the
conversion from a directed graph to this data struc-
ture.
</bodyText>
<subsectionHeader confidence="0.999872">
3.1 Data structure
</subsectionHeader>
<bodyText confidence="0.999636333333333">
In order to algorithmically convert dependency
parses to a structural grammar, we developed an
original model to represent features of sentence
diagrams. A sentence is composed of four slots
(Subject, Predicate, Object, Complement). These
slots are represented1 in two sentences shown in
</bodyText>
<footnote confidence="0.826902">
1All sentence diagram figures were generated by the al-
gorithm described in this paper. Some diagrams have been
</footnote>
<figureCaption confidence="0.9796735">
Figure 2: Diagram of “Running through the woods
is his favorite activity.”
</figureCaption>
<bodyText confidence="0.9790192">
Figure 1 by the words “students,” “are,” “assign-
ment,” and “scholars” respectively. Each slot con-
tains three sets (Heads, Expletives, Conjunctions).
With the exception of the Heads slot in Subject
and Predicate, all sets may be empty. These sets
are populated by words. A word is comprised of
three parts: the string it represents, a set of mod-
ifying words, and information about its orienta-
tion in a diagram. Finally, anywhere that a word
may fill a role, it can be replaced by a phrase or
subclause. These phrases are represented iden-
tically to clauses, but all sets are allowed to be
empty. Phrases and subclauses filling the role of
a word are connected to the slot they are filling by
a pedestal, as in Figure 2.
</bodyText>
<subsectionHeader confidence="0.999324">
3.2 Conversion from dependency graph
</subsectionHeader>
<bodyText confidence="0.990789">
A typed dependency representation of a sentence
contains a root – that is, a dependency relation
in which neither the governor nor the dependent
word in the relation is dependent in any other re-
lation. We use this relation to determine the predi-
cate of a sentence, which is almost always the gov-
ernor of the root dependency. The dependent is
added to the diagram data structure based on its
relation to the governor.
Before analysis of dependency graphs begins,
our algorithm takes in a set of dependency rela-
tions S and a set of actions (possible objects and
methods to call) A. This paper describes an algo-
rithm that takes in the 55 relations from (Marn-
effe et al., 2006) and the actions in Table 1. The
algorithm then takes as input a directed graph G
representing a sentence, composed of a node rep-
edited for spacing and readability concerns. These changes
do not affect their accuracy.
</bodyText>
<page confidence="0.996983">
47
</page>
<bodyText confidence="0.9997558">
resenting each word in the sentence. These nodes
are connected by edges in the form reln(gov,
dep) representing a relation from S between a
word gov and dep. Our algorithm performs the
following steps:
</bodyText>
<listItem confidence="0.99728584">
1. Determining root actions: For each relation
type R E S, create an ordered list of actions
Root &lt; R, A &gt; from A to perform if that re-
lation is the root relation in the graph.
2. Determining regular actions: For each re-
lation type R E S, create an ordered list of
actions Reln &lt; R, A &gt; from A to perform if
R is found anywhere other than the root in G.
3. Determining the root: Using the root-
finding process described in (Marneffe et al.,
2006), find the root relation ˆR( ˆG, ˆD) E G.
4. Initialize a sentence diagram: Find the set
of actions Aˆ from Root &lt; ˆR, A &gt;and perform
those actions.
5. Finding children: Create a set Open and add
to it each relation E G in which Gˆ or Dˆ from
step 3 is a governor.
6. Processing children: For each relation
˜R(˜G, ˜D) in Open,
(a) Populate the sentence diagram: Find
the set of actions A˜ from Reln &lt; ˜R, A &gt;
and perform those actions.
(b) Finding children: Add to Open each
relation R E G in which G˜ or D˜ is a gov-
ernor.
</listItem>
<bodyText confidence="0.999820222222222">
This step continues until all relations have
been found in a breadth-first order.
Our system of conversion makes the assumption
that the governor of a typed dependency will al-
ready have been assigned a position in a diagram.
This is due to the largely tree-like structure of
dependency graphs generated by the dependency
parser. Dependencies in most cases “flow” down-
wards to the root, and in exceptions, such as cy-
cles, the governor will have been discovered by the
time it is reached again. As we are searching for
words breadth-first, we know that the dependent
of any relation will have been discovered already
so long as this tree-like structure holds. The num-
ber of cases where it does not is small compared
to the overall error rate of the dependency parser,
and does not have a large impact on the accuracy
of the resulting diagram.
</bodyText>
<subsectionHeader confidence="0.999781">
3.3 Single-relation analysis
</subsectionHeader>
<bodyText confidence="0.995979319148936">
A strength of this system for conversion is that in-
formation about the overall structure of a sentence
is not necessary for determining the role of each
individual word as it is added to the diagram. As
each word is traversed, it is assigned a role relative
to its parent only. This means that overall structure
will be discovered naturally by tracing dependen-
cies throughout a graph.
There is one exception to this rule: when com-
paring relationships of type cop (copula, a link-
ing verb, usually a variant of “to be”), three words
are involved: the linking verb, the subject, and the
subject complement. However, instead of a tran-
sitive relationship from one word to the next, the
parser assigns the subject and subject complement
as dependent words of the linking verb. An exam-
ple is the sentence “The students are scholars” as
in Figure 1. This sentence contains three relations:
det(students, The)
nsubj(scholars, students)
cop(scholars, are)
A special case exists in our algorithm to check
the governor of a cop relation for another rela-
tion (usually nsubj). This was a necessary ex-
ception to make given the frequency of linking
verbs in the English language. Dependency graphs
from (Marneffe et al., 2006) are defined as a
singly rooted directed acyclic graph with no re-
entrancies; however, they sometimes share nodes
in the tree, with one word being a dependent of
multiple relations. An example of this exists in
the sentence “I saw the man who loves you.” The
word “who” in this sentence is dependent in two
relations:
ref(man, who)
rel(loves, who)
We here refer to this phenomenon as breaking
the tree structure. This is notable because it causes
a significant problem for our approach. While the
correct relation is identified and assigned in most
cases, a duplicated copy of the dependent word
will appear in the resulting diagram. This is be-
cause the dependent word in each relation is added
to the diagram, even if it has already been added.
Modifiers of these words are then assigned to each
copy, which can result in large areas of duplica-
tion. We decided this duplication was acceptable
</bodyText>
<page confidence="0.998847">
48
</page>
<table confidence="0.9356798">
Term Definition Example
Input Output
GOV, DEP, RELN Elements of arelation det(‘‘woods&amp;quot;, ‘‘woods&amp;quot;
‘‘the&amp;quot;).GOV
SBJ, PRD, OBJ, Slots in a clause CLAUSE.PRD HEADS(‘‘is&amp;quot;),
CMP EXPL(),
CONJ()
HEADS, EXPL, Sets of words in a slot CLAUSE.PRD.HEADS() ‘‘is&amp;quot;
CONJ
MODS Set of modifiers of a ‘‘activity&amp;quot;.MODS (‘‘his&amp;quot;,
word ‘‘favorite&amp;quot;)
SEGMENT, CLAUSE Set or clause of word ‘‘is&amp;quot;.SEGMENT() CLAUSE.PRD
NEW[WORD, Slot] New clause constructor NEW(‘‘is&amp;quot;, PRD) CLAUSE(SBJ(),
PRD(‘‘is&amp;quot;),
OBJ(),
CMP())
ADD(WORD[,ORIENT]) Word added to modi- ‘‘activity&amp;quot;.ADD(‘‘his&amp;quot;)
fiers
APP(WORD[,RIGHT?]) Word appended to ‘‘down&amp;quot;.APP(‘‘shut&amp;quot;,
phrasal head false)
SET(ORIENT) Word orientation set ‘‘his&amp;quot;.SET(DIAGONAL)
Periods represent ownership, parentheses represent parameters passed to a method, separated by commas, and brackets repre-
sent optional parameters.
Orientations include HORIZONTAL, DIAGONAL, VERTICAL, GERUND, BENT, DASHED, and CLAUSE as defined in (Kolln
and Funk, 2002) .
</table>
<tableCaption confidence="0.999371">
Table 1: Terms and methods defined in our algorithm.
</tableCaption>
<figureCaption confidence="0.807591333333333">
Figure 3: The sentence “A big crowd turned out
for the parade.” shown as a dependency graph
(top) and a sentence diagram.
</figureCaption>
<bodyText confidence="0.999205571428571">
to maintain the simplicity of single-relation con-
version rules, though remedying this problem is an
avenue for further research. For testing purposes,
if duplicate copies of a word exist, the correct one
is given preference over the incorrect copy, and the
diagram is scored as correct if either copy is cor-
rectly located.
</bodyText>
<subsectionHeader confidence="0.994847">
3.4 An example diagram conversion
</subsectionHeader>
<bodyText confidence="0.951842142857143">
To illustrate the conversion process, consider the
sentence “A big crowd turned out for the parade.”
The dependency graph for this, as generated by the
Stanford dependency parser, is shown in Figure 3.
The following relations are found, with the actions
taken by the conversion algorithm described:
Root: nsubj(turned, crowd)
</bodyText>
<figure confidence="0.530560142857143">
NEW(GOV, PRD);
GOV.CLAUSE.SBJ.ADD(DEP);
Finding Children: det(crowd, A),
amod(crowd, big), prt(turned, out),
prep(turned, for) added to Open.
Relation: det(crowd, A)
GOV.ADD(DEP,DIAGONAL);
Relation: amod(crowd, big)
GOV.ADD(DEP,DIAGONAL);
Relation: prt(turned, out)
GOV.APP(DEP,TRUE);
Relation: prep(turned, for)
Finding Children: pobj(for, parade)
added to Open.
GOV.ADD(DEP,DIAGONAL);
Relation: pobj(for, parade)
Finding Children: det(parade, the)
added to Open.
GOV.ADD(DEP,HORIZONTAL);
Relation: det(parade, the)
GOV.ADD(DEP,DIAGONAL);
</figure>
<sectionHeader confidence="0.994964" genericHeader="method">
4 Experimental setup
</sectionHeader>
<bodyText confidence="0.998411">
In order to test our conversion algorithm, a large
number of sentence diagrams were needed in order
</bodyText>
<page confidence="0.998755">
49
</page>
<bodyText confidence="0.999912981132076">
to ensure a wide range of structures. We decided to
use an undergraduate-level English grammar text-
book that uses diagramming as a teaching tool
for two reasons. The first is a pragmatic matter:
the sentences have already been diagrammed ac-
curately for comparison to algorithm output. Sec-
ond, the breadth of examples necessary to allow
students a thorough understanding of the process
is beneficial in assuring the completeness of the
conversion system. Cases that are especially diffi-
cult for students are also likely to be stressed with
multiple examples, giving more opportunities to
determine the problem if parsers have similar dif-
ficulty.
Therefore, (Kolln and Funk, 2002) was selected
to be used as the source of this testing data. This
textbook contained 292 sentences, 152 from ex-
amples and 140 from solutions to problem sets.
50% of the example sentences (76 in total, chosen
by selecting every other example) were set aside
to use for development. The remaining 216 sen-
tences were used to gauge the accuracy of the con-
version algorithm.
Our implementation of this algorithm was de-
veloped as an extension of the Stanford depen-
dency parser. We developed two metrics of pre-
cision to evaluate the accuracy of a diagram. The
first approach, known as the inheritance metric,
scored the results of the algorithm based on the
parent of each word in the output sentence dia-
gram. Headwords were judged on their placement
in the correct slot, while modifiers were judged
on whether they modified the correct parent word.
The second approach, known as the orientation
metric, judged each word based solely on its ori-
entation. This distinction judges whether a word
was correctly identified as a primary or modifying
element of a sentence.
These scoring systems have various advantages.
By only scoring a word based on its immediate
parent, a single mistake in the diagram does not
severely impact the result of the score, even if it is
at a high level in the diagram. Certain mistakes are
affected by one scoring system but not the other;
for instance, incorrect prepositional phrase attach-
ment will not have an effect on the orientation
score, but will reduce the value of the inheritance
score. Alternatively, a mistake such as failing to
label a modifying word as a participial modifier
will reduce the orientation score, but will not re-
duce the value of the inheritance score. Generally,
orientation scoring is more forgiving than inheri-
tance scoring.
</bodyText>
<sectionHeader confidence="0.995936" genericHeader="method">
5 Results and discussion
</sectionHeader>
<bodyText confidence="0.999968814814815">
The results of testing these accuracy metrics are
given in Figure 4 and Table 2. Overall inheritance
precision was 85% and overall orientation preci-
sion was 92%. Due to the multiple levels of analy-
sis (parsing from tree to phrase structure to depen-
dency graph to diagram), it is sometimes difficult
to assign fault to a specific step of the algorithm.
There is clearly some loss of information when
converting from a dependency graph to a sentence
diagram. For example, fifteen dependency rela-
tions are represented as diagonal modifiers in a
sentence diagram and have identical conversion
rules. Interestingly, these relations are not nec-
essarily grouped together in the hierarchy given
in (Marneffe et al., 2006). This suggests that the
syntactic information represented by these words
may not be as critical as previously thought, given
enough semantic information about the words. In
total, six sets of multiple dependency relations
mapping to the same conversion rule were found,
as shown in Table 3.
The vast majority of mistakes that were made
came from one of two sources: an incorrect con-
version from a correct dependency parse, or a fail-
ure of the dependency parser to correctly identify
a relation between words in a sentence. Both are
examined below.
</bodyText>
<subsectionHeader confidence="0.989663">
5.1 Incorrect conversion rules
</subsectionHeader>
<bodyText confidence="0.999988166666667">
On occasion, a flaw in a diagram was the result of
an incorrect conversion from a correct interpreta-
tion in a dependency parse. In some cases, these
were because of simple changes due to inaccura-
cies not exposed from development data. In some
cases, this was a result of an overly general rela-
tionship, in which one relation correctly describes
two or more possible structural patterns in sen-
tences. This can be improved upon by specializ-
ing dependency relation descriptions in future ver-
sions of the dependency parser.
One frequent failure of the conversion rules is
due to the overly generalized handling of the root
of sentences. It is assumed that the governing
word in the root relation of a dependency graph
is the main verb of a sentence. Our algorithm has
very general rules for root handling. Exceptions
to these general cases are possible, especially in
</bodyText>
<page confidence="0.979253">
50
</page>
<table confidence="0.991701666666667">
Sentence Length Ori Mean Ori Std.Dev. Inh Mean Inh Std.Dev. Count
3-6 96.61 7.42 90.34 15.20 56
7-8 92.37 15.77 86.00 19.34 57
9-10 92.80 8.18 82.73 17.15 45
11-20 89.97 12.54 82.52 15.51 58
3-20 92.91 11.84 85.51 17.05 216
</table>
<tableCaption confidence="0.978294">
Table 2: Precision of diagramming algorithm on testing data.
</tableCaption>
<table confidence="0.99645825">
Relations Rule
abbrev, advmod, amod, dep, det, measure, neg, nn, GOV.ADD(DEP,DIAGONAL)
num, number, poss, predet, prep, quantmod, ref
iobj, parataxis, pobj GOV.ADD(DEP,HORIZONTAL)
appos, possessive, prt GOV.APP(DEP,TRUE)
aux, tmod GOV.APP(DEP,FALSE)
advcl, csubj, pcomp, rcmod GOV.ADD(NEW(DEP,PRD))
complm, expl, mark GOV.SEGMENT.EXPL.ADD(DEP)
</table>
<tableCaption confidence="0.999095">
Table 3: Sets of multiple dependency relations which are converted identically.
</tableCaption>
<figureCaption confidence="0.76877675">
Figure 4: Inheritance (top) and Orientation preci-
sion results of diagramming algorithm on testing
data. Results are separated by sentence length into
quartiles.
</figureCaption>
<bodyText confidence="0.986085653846154">
interrogative sentences, e.g. the root relation of
the sentence “What have you been reading?” is
dob j ( reading, What) . This should be han-
dled by treating “What” as the object of the clause.
This problem can be remedied in the future by cre-
ating specialized conversion rules for any given re-
lation as a root of a dependency graph.
A final issue is the effect of a non-tree struc-
ture on0the conversion algorithm. Because rela-
tionships are evaluated individually, multiple in-
heritance for words can sometimes create dupli-
cate copies of a word which are then modified in
parallel. An example of this is shown in Figure 5,
which is caused due to the dependency graph for
this sentence containing the following relations:
nsubj(is-4, hope-3)
xsubj(beg-6, hope-3)
xcomp(is-4, beg-6)
Because the tree structure is broken, a word
(hope) is dependent on two different governing
words. While the xsubj relation places the phrase
“to beg for mercy” correctly in the diagram, a sec-
ond copy is created because of the xcomp depen-
dency. A more thorough analysis approach that
checks for breaking of the tree structure may be
useful in avoiding this problem in the future.
</bodyText>
<sectionHeader confidence="0.6226115" genericHeader="method">
5.2 Exposed weaknesses of dependency
parsers
</sectionHeader>
<bodyText confidence="0.874609">
A number of consistent patterns are poorly dia-
grammed by this system. This is usually due to
</bodyText>
<figure confidence="0.8868315">
Orientation by Quartiles
Inheritance by Quartiles
</figure>
<page confidence="0.861957">
51
</page>
<figureCaption confidence="0.982718">
Figure 5: Duplication in the sentence diagram for
</figureCaption>
<bodyText confidence="0.984094448275862">
“Our only hope is to beg for mercy.”
limitations in the theoretical model of the depen-
dency parser. These differences between the ac-
tual structure of the sentence and the structure the
parser assigns can lead to a significant difference
in semantic value of phrases. Improving the accu-
racy of this model to account for these situations
(either through more fine-grained separation of re-
lationships or a change in the model) may improve
the quality of meaning extraction from sentences.
One major shortcoming of the dependency
parser is how it handles prepositional phrases.
As described in (Atterer and Schutze, 2007), this
problem has traditionally been framed as involv-
ing four words (v, n1, p, n2) where v is the head of
a verb phrase, n1 is the head of a noun phrase dom-
inated by v, p is the head of a prepositional phrase,
and n2 the head of a noun phrase dominated by
p. Two options have generally been given for at-
tachment, either to the verb v or the noun n1. This
parser struggles to accurately determine which of
these two possibilities should be used. However,
in the structural model of grammar, there is a third
option, treating the prepositional phrase as an ob-
ject complement of n1. This possibility occurs fre-
quently in English, such as in the sentence “We
elected him as our secretary.” or with idiomatic ex-
pressions such as “out of tune.” The current depen-
dency parser cannot represent this at all.
</bodyText>
<subsectionHeader confidence="0.955098">
5.3 Ambiguity
</subsectionHeader>
<bodyText confidence="0.998946571428571">
A final case is when multiple correct structural
analyses exist for a single sentences. In some
cases, this causes the parser to produce a gramati-
cally and semantically correct parse which, due to
ambiguity, does not match the diagram for com-
parison. An example of this can be seen in Fig-
ure 6, in which the dependency parser assigns the
</bodyText>
<figureCaption confidence="0.6464565">
Figure 6: Diagram of “On Saturday night the li-
brary was almost deserted.”
</figureCaption>
<bodyText confidence="0.9965802">
predicate role to “was deserted” when in fact de-
serted is acting as a subject complement. How-
ever, the phrase “was deserted” can accurately act
as a predicate in that sentence, and produces a se-
mantically valid interpretation of the phrase.
</bodyText>
<sectionHeader confidence="0.999703" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.9999825">
We have demonstrated a promising method for
conversion from a dependency graph to a sentence
diagram. However, this approach still has the op-
portunity for a great deal of improvement. There
are two main courses of action for future work to
reap the benefits of this approach: analyzing cur-
rent results, and extending this approach to other
parsers for comparison. First, a more detailed
analysis of current errors should be undertaken to
determine areas for improvement. There are two
broadly defined categories of error (errors made
before a dependency graph is given to the algo-
rithm for conversion, and errors made during con-
version to a diagram). However, we do not know
what percent of mistakes falls into those two cat-
egories. We also do not know what exact gram-
matical idiosyncracy caused each of those errors.
With further examination of current data, this in-
formation can be determined.
Second, it must be determined what level of
conversion error is acceptable to begin making
quantitative comparisons of dependency parsers.
Once the level of noise introduced by the conver-
sion process is lowered to the point that the major-
ity of diagram errors are due to mistakes or short-
falls in the dependency graph itself, this tool will
be much more useful for evaluation. Finally, this
system should be extended to other dependency
parsers so that a comparison can be made between
multiple systems.
</bodyText>
<sectionHeader confidence="0.997734" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.8489925">
Michaela Atterer and Hinrich Schutze. 2007. Preposi-
tional Phrase Attachment without Oracles. In Com-
</reference>
<page confidence="0.97789">
52
</page>
<reference confidence="0.998768375">
putational Linguistics.
John Carroll, Guido Minnen, and Ted Briscoe. 1999.
Corpus annotation for parser evaluation. In Pro-
ceedings of the EACL workshop on Linguistically
Interpreted Corpora.
Dan Klein and Christopher D. Manning. 2003. Ac-
curate Unlexicalized Parsing. In Proceedings of the
41st Meeting of the Association for Computational
Linguistics.
Martha Kolln and Robert Funk. 2002. Understanding
English Grammar, Sixth Edition. Longman Publish-
ers.
Dekang Lin. 1995. A Dependency-based Method
for Evaluating Broad-Coverage Parsers. In Natural
Language Engineering.
Dekang Lin. 1998. Dependency-based evaluation of
MINIPAR. In Workshop on the Evaluation of Pars-
ing Systems
Marie-Catherine de Marneffe, Bill MacCartney and
Christopher D. Manning. 2006. Generating Typed
Dependency Parses from Phrase Structure Parses.
In International Conference on Language Resources
and Evaluation.
Ryan McDonald, Fernando Pereira, Kiril Ribarov, and
Jan Hajiˇc. 2005. Non-projective dependency pars-
ing using spanning tree algorithms. In Proceedings
of the conference on Human Language Technology
and Empirical Methods in Natural Language Pro-
cessing.
Daniel D. Sleator and Davy Temperley. 1993. Parsing
English with a link grammar. In Third International
Conference on Parsing Technologies.
</reference>
<page confidence="0.999347">
53
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.948146">
<title confidence="0.99995">Sentence Diagram Generation Using Dependency Parsing</title>
<author confidence="0.999583">Elijah Mayfield</author>
<affiliation confidence="0.9990165">Division of Science and Mathematics University of Minnesota, Morris</affiliation>
<email confidence="0.99713">mayf0016@morris.umn.edu</email>
<abstract confidence="0.999416905982906">Dependency parsers show syntactic relations between words using a directed graph, but comparing dependency parsers is difficult because of differences in theoretical models. We describe a system to convert dependency models to a structural grammar used in grammar education. Doing so highlights features that are potentially overlooked in the dependency graph, as well as exposing potential weaknesses and limitations in parsing models. Our system performs automated analysis of dependency relations and uses them to populate a data structure we designed to emulate sentence diagrams. This is done by mapping dependency relations between words to the relative positions of those words in a sentence diagram. Using an original metric for judging the accuracy of sentence diagrams, we achieve precision of 85%. Multiple causes for errors are presented as potential areas for improvement in dependency parsers. 1 Dependency parsing Dependencies are generally considered a strong metric of accuracy in parse trees, as described in (Lin, 1995). In a dependency parse, words are connected to each other through relations, with a head word (the governor) being modified by a dependent word. By converting parse trees to dependency representations before judging accuracy, more detailed syntactic information can be discovered. Recently, however, a number of dependency parsers have been developed that have very different theories of a correct model of dependencies. Dependency parsers define syntactic relations between words in a sentence. This can be done either through spanning tree search as in (McDonald et al., 2005), which is computationally expensive, or through analysis of another modeling system, such as a phrase structure parse tree, which can introduce errors from the long pipeline. To the best of our knowledge, the first use of dependency relations as an evaluation tool for parse trees was in (Lin, 1995), which described a process for determining heads in phrase structures and assigning modifiers to those heads appropriately. Because of different ways to describe relations between negations, conjunctions, and other grammatical structures, it was immediately clear that comparing different models would be difficult. Research into this area of evaluation produced several new dependency parsers, each using different theories of what constitutes a correct parse. In addition, attempts to model multiple parse trees in a single dependency relation system were often stymied by problems such as differences in tokenization systems. These problems are discussed by (Lin, 1998) in greater detail. An attempt to reconcile differences between parsers was described in (Marneffe et al., 2006). In this paper, a dependency parser (from herein referred to as the Stanford parser) was developed and compared to two other systems: MINIPAR, described in (Lin, 1998), and the Link parser of (Sleator and Temperley, 1993), which uses a radically different approach but produces a similar, if much more fine-grained, result. Comparing dependency parsers is difficult. The main problem is that there is no clear way to compare models which mark dependencies differently. For instance, when clauses are linked by a conjunction, the Link parser considers the conjunction related to the subject of a clause, while the Stanford parser links the conjunction to the verb of a clause. In (Marneffe et al., 2006), a simple comparison was used to alleviate this problem, which was based only on the presence of dependencies, without semantic information. This solution loses 45 of the ACL-IJCNLP 2009 Student Research pages 45–53, Singapore, 4 August 2009. ACL and AFNLP information and is still subject to many problems in representational differences. Another problem with this approach is that they only used ten sentences for comparison, randomly selected from the Brown corpus. This sparse data set is not necessarily congruous with the overall accuracy of these parsers. In this paper, we propose a novel solution to the difficulty of converting between dependency models. The options that have previously been presented for comparing dependency models are either too specific to be accurate (relying on annotation schemes that are not adequately parallel for comparison) or too coarse to be useful (such as merely checking for the existence of dependencies). By using a model of language which is not as fine-grained as the models used by dependency parsers, but still contains some semantic information beyond unlabelled relations, a compromise can be made. We show that using linear diagramming models can do this with acceptable error rates, and hope that future work can use this to compare multiple dependency models. Section 2 describes structural grammar, its history, and its usefulness as a representation of syntax. Section 3 describes our algorithm for conversion from dependency graphs to a structural representation. Section 4 describes the process we used for developing and testing the accuracy of this algorithm, and Section 5 discusses our results and a variety of features, as well as limitations and weaknesses, that we have found in the dependency representation of (Marneffe et al., 2006) as a result of this conversion.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Michaela Atterer</author>
<author>Hinrich Schutze</author>
</authors>
<title>Prepositional Phrase Attachment without Oracles.</title>
<date>2007</date>
<booktitle>In Computational Linguistics.</booktitle>
<contexts>
<context position="26131" citStr="Atterer and Schutze, 2007" startWordPosition="4230" endWordPosition="4233">gram for “Our only hope is to beg for mercy.” limitations in the theoretical model of the dependency parser. These differences between the actual structure of the sentence and the structure the parser assigns can lead to a significant difference in semantic value of phrases. Improving the accuracy of this model to account for these situations (either through more fine-grained separation of relationships or a change in the model) may improve the quality of meaning extraction from sentences. One major shortcoming of the dependency parser is how it handles prepositional phrases. As described in (Atterer and Schutze, 2007), this problem has traditionally been framed as involving four words (v, n1, p, n2) where v is the head of a verb phrase, n1 is the head of a noun phrase dominated by v, p is the head of a prepositional phrase, and n2 the head of a noun phrase dominated by p. Two options have generally been given for attachment, either to the verb v or the noun n1. This parser struggles to accurately determine which of these two possibilities should be used. However, in the structural model of grammar, there is a third option, treating the prepositional phrase as an object complement of n1. This possibility oc</context>
</contexts>
<marker>Atterer, Schutze, 2007</marker>
<rawString>Michaela Atterer and Hinrich Schutze. 2007. Prepositional Phrase Attachment without Oracles. In Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Carroll</author>
<author>Guido Minnen</author>
<author>Ted Briscoe</author>
</authors>
<title>Corpus annotation for parser evaluation.</title>
<date>1999</date>
<booktitle>In Proceedings of the EACL workshop on Linguistically Interpreted Corpora.</booktitle>
<marker>Carroll, Minnen, Briscoe, 1999</marker>
<rawString>John Carroll, Guido Minnen, and Ted Briscoe. 1999. Corpus annotation for parser evaluation. In Proceedings of the EACL workshop on Linguistically Interpreted Corpora.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Accurate Unlexicalized Parsing.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Meeting of the Association for Computational Linguistics.</booktitle>
<marker>Klein, Manning, 2003</marker>
<rawString>Dan Klein and Christopher D. Manning. 2003. Accurate Unlexicalized Parsing. In Proceedings of the 41st Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martha Kolln</author>
<author>Robert Funk</author>
</authors>
<title>Understanding English Grammar, Sixth Edition.</title>
<date>2002</date>
<publisher>Longman Publishers.</publisher>
<contexts>
<context position="6777" citStr="Kolln and Funk, 2002" startWordPosition="1089" endWordPosition="1092">ire subclause, with its own pattern and set of slots. To understand these relationships better, a standardized system of sentence diagramming has been developed. With a relatively small number of rules, a great deal of information about the function of each word in a sentence can be represented in a compact form, using orientation and other spatial clues. This provides a simpler and intuitive means of visualizing relationships between words, especially when compared to the complexity of directed dependency graphs. For the purposes of this paper, we use the system of diagramming formalized in (Kolln and Funk, 2002). 2.1 History First developed in the early 20th century, structural grammar was a response to the prescriptive grammar approach of the time. Structural grammar describes how language actually is used, rather than prescribing how grammar should be used. This approach allows an emphasis to be placed on the systematic and formulaic nature of language. A key change involved the shift to general role-based description of the usage of a word, whereas the focus before had been on declaring words to fall into strict categories (such as the eight parts of speech found in Latin). Beginning with the work</context>
<context position="17079" citStr="Kolln and Funk, 2002" startWordPosition="2788" endWordPosition="2791"> CLAUSE Set or clause of word ‘‘is&amp;quot;.SEGMENT() CLAUSE.PRD NEW[WORD, Slot] New clause constructor NEW(‘‘is&amp;quot;, PRD) CLAUSE(SBJ(), PRD(‘‘is&amp;quot;), OBJ(), CMP()) ADD(WORD[,ORIENT]) Word added to modi- ‘‘activity&amp;quot;.ADD(‘‘his&amp;quot;) fiers APP(WORD[,RIGHT?]) Word appended to ‘‘down&amp;quot;.APP(‘‘shut&amp;quot;, phrasal head false) SET(ORIENT) Word orientation set ‘‘his&amp;quot;.SET(DIAGONAL) Periods represent ownership, parentheses represent parameters passed to a method, separated by commas, and brackets represent optional parameters. Orientations include HORIZONTAL, DIAGONAL, VERTICAL, GERUND, BENT, DASHED, and CLAUSE as defined in (Kolln and Funk, 2002) . Table 1: Terms and methods defined in our algorithm. Figure 3: The sentence “A big crowd turned out for the parade.” shown as a dependency graph (top) and a sentence diagram. to maintain the simplicity of single-relation conversion rules, though remedying this problem is an avenue for further research. For testing purposes, if duplicate copies of a word exist, the correct one is given preference over the incorrect copy, and the diagram is scored as correct if either copy is correctly located. 3.4 An example diagram conversion To illustrate the conversion process, consider the sentence “A bi</context>
<context position="19282" citStr="Kolln and Funk, 2002" startWordPosition="3110" endWordPosition="3113">n undergraduate-level English grammar textbook that uses diagramming as a teaching tool for two reasons. The first is a pragmatic matter: the sentences have already been diagrammed accurately for comparison to algorithm output. Second, the breadth of examples necessary to allow students a thorough understanding of the process is beneficial in assuring the completeness of the conversion system. Cases that are especially difficult for students are also likely to be stressed with multiple examples, giving more opportunities to determine the problem if parsers have similar difficulty. Therefore, (Kolln and Funk, 2002) was selected to be used as the source of this testing data. This textbook contained 292 sentences, 152 from examples and 140 from solutions to problem sets. 50% of the example sentences (76 in total, chosen by selecting every other example) were set aside to use for development. The remaining 216 sentences were used to gauge the accuracy of the conversion algorithm. Our implementation of this algorithm was developed as an extension of the Stanford dependency parser. We developed two metrics of precision to evaluate the accuracy of a diagram. The first approach, known as the inheritance metric</context>
</contexts>
<marker>Kolln, Funk, 2002</marker>
<rawString>Martha Kolln and Robert Funk. 2002. Understanding English Grammar, Sixth Edition. Longman Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>A Dependency-based Method for Evaluating Broad-Coverage Parsers.</title>
<date>1995</date>
<journal>In Natural Language Engineering.</journal>
<contexts>
<context position="1208" citStr="Lin, 1995" startWordPosition="177" endWordPosition="178"> models. Our system performs automated analysis of dependency relations and uses them to populate a data structure we designed to emulate sentence diagrams. This is done by mapping dependency relations between words to the relative positions of those words in a sentence diagram. Using an original metric for judging the accuracy of sentence diagrams, we achieve precision of 85%. Multiple causes for errors are presented as potential areas for improvement in dependency parsers. 1 Dependency parsing Dependencies are generally considered a strong metric of accuracy in parse trees, as described in (Lin, 1995). In a dependency parse, words are connected to each other through relations, with a head word (the governor) being modified by a dependent word. By converting parse trees to dependency representations before judging accuracy, more detailed syntactic information can be discovered. Recently, however, a number of dependency parsers have been developed that have very different theories of a correct model of dependencies. Dependency parsers define syntactic relations between words in a sentence. This can be done either through spanning tree search as in (McDonald et al., 2005), which is computatio</context>
</contexts>
<marker>Lin, 1995</marker>
<rawString>Dekang Lin. 1995. A Dependency-based Method for Evaluating Broad-Coverage Parsers. In Natural Language Engineering.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Dependency-based evaluation of MINIPAR.</title>
<date>1998</date>
<booktitle>In Workshop on the Evaluation of Parsing Systems</booktitle>
<contexts>
<context position="2760" citStr="Lin, 1998" startWordPosition="426" endWordPosition="427">uctures and assigning modifiers to those heads appropriately. Because of different ways to describe relations between negations, conjunctions, and other grammatical structures, it was immediately clear that comparing different models would be difficult. Research into this area of evaluation produced several new dependency parsers, each using different theories of what constitutes a correct parse. In addition, attempts to model multiple parse trees in a single dependency relation system were often stymied by problems such as differences in tokenization systems. These problems are discussed by (Lin, 1998) in greater detail. An attempt to reconcile differences between parsers was described in (Marneffe et al., 2006). In this paper, a dependency parser (from herein referred to as the Stanford parser) was developed and compared to two other systems: MINIPAR, described in (Lin, 1998), and the Link parser of (Sleator and Temperley, 1993), which uses a radically different approach but produces a similar, if much more fine-grained, result. Comparing dependency parsers is difficult. The main problem is that there is no clear way to compare models which mark dependencies differently. For instance, when</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>Dekang Lin. 1998. Dependency-based evaluation of MINIPAR. In Workshop on the Evaluation of Parsing Systems</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine de Marneffe</author>
<author>Bill MacCartney</author>
<author>Christopher D Manning</author>
</authors>
<title>Generating Typed Dependency Parses from Phrase Structure Parses.</title>
<date>2006</date>
<booktitle>In International Conference on Language Resources and Evaluation.</booktitle>
<marker>de Marneffe, MacCartney, Manning, 2006</marker>
<rawString>Marie-Catherine de Marneffe, Bill MacCartney and Christopher D. Manning. 2006. Generating Typed Dependency Parses from Phrase Structure Parses. In International Conference on Language Resources and Evaluation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Fernando Pereira</author>
<author>Kiril Ribarov</author>
<author>Jan Hajiˇc</author>
</authors>
<title>Non-projective dependency parsing using spanning tree algorithms.</title>
<date>2005</date>
<booktitle>In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing.</booktitle>
<marker>McDonald, Pereira, Ribarov, Hajiˇc, 2005</marker>
<rawString>Ryan McDonald, Fernando Pereira, Kiril Ribarov, and Jan Hajiˇc. 2005. Non-projective dependency parsing using spanning tree algorithms. In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel D Sleator</author>
<author>Davy Temperley</author>
</authors>
<title>Parsing English with a link grammar.</title>
<date>1993</date>
<booktitle>In Third International Conference on Parsing Technologies.</booktitle>
<contexts>
<context position="3094" citStr="Sleator and Temperley, 1993" startWordPosition="478" endWordPosition="481">endency parsers, each using different theories of what constitutes a correct parse. In addition, attempts to model multiple parse trees in a single dependency relation system were often stymied by problems such as differences in tokenization systems. These problems are discussed by (Lin, 1998) in greater detail. An attempt to reconcile differences between parsers was described in (Marneffe et al., 2006). In this paper, a dependency parser (from herein referred to as the Stanford parser) was developed and compared to two other systems: MINIPAR, described in (Lin, 1998), and the Link parser of (Sleator and Temperley, 1993), which uses a radically different approach but produces a similar, if much more fine-grained, result. Comparing dependency parsers is difficult. The main problem is that there is no clear way to compare models which mark dependencies differently. For instance, when clauses are linked by a conjunction, the Link parser considers the conjunction related to the subject of a clause, while the Stanford parser links the conjunction to the verb of a clause. In (Marneffe et al., 2006), a simple comparison was used to alleviate this problem, which was based only on the presence of dependencies, without</context>
</contexts>
<marker>Sleator, Temperley, 1993</marker>
<rawString>Daniel D. Sleator and Davy Temperley. 1993. Parsing English with a link grammar. In Third International Conference on Parsing Technologies.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>