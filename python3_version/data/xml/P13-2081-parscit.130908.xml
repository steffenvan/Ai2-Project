<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000014">
<title confidence="0.978959">
Sentence Level Dialect Identification in Arabic
</title>
<author confidence="0.993097">
Heba Elfardy
</author>
<affiliation confidence="0.996319">
Department of Computer Science
Columbia University
</affiliation>
<email confidence="0.99061">
heba@cs.columbia.edu
</email>
<author confidence="0.995319">
Mona Diab
</author>
<affiliation confidence="0.979689">
Department of Computer Science
The George Washington University
</affiliation>
<email confidence="0.995651">
mtdiab@gwu.edu
</email>
<sectionHeader confidence="0.993827" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999822882352941">
This paper introduces a supervised ap-
proach for performing sentence level di-
alect identification between Modern Stan-
dard Arabic and Egyptian Dialectal Ara-
bic. We use token level labels to de-
rive sentence-level features. These fea-
tures are then used with other core and
meta features to train a generative clas-
sifier that predicts the correct label for
each sentence in the given input text. The
system achieves an accuracy of 85.5%
on an Arabic online-commentary dataset
outperforming a previously proposed ap-
proach achieving 80.9% and reflecting a
significant gain over a majority baseline of
51.9% and two strong baseline systems of
78.5% and 80.4%, respectively.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999866225">
The Arabic language exists in a state of Diglos-
sia (Ferguson, 1959) where the standard form of
the language, Modern Standard Arabic (MSA) and
the regional dialects (DA) live side-by-side and
are closely related. MSA is the language used
in education, scripted speech and official settings
while DA is the native tongue of Arabic speak-
ers. Arabic dialects may be divided into five
main groups: Egyptian (including Libyan and Su-
danese), Levantine (including Lebanese, Syrian,
Palestinian and Jordanian), Gulf, Iraqi and Mo-
roccan (Maghrebi) (Habash, 2010). Even though
these dialects did not originally exist in a written
form, they are pervasively present in social me-
dia text (normally mixed with MSA) nowadays.
DA does not have a standard orthography leading
to many spelling variations and inconsistencies.
Linguistic Code switching (LCS) between MSA
and DA happens both intra-sententially and inter-
sententially. LCS in Arabic poses a serious chal-
lenge for almost all NLP tasks since MSA and DA
differ on all levels of linguistic representation. For
example, MSA trained tools perform very badly
when applied directly to DA or to a code-switched
DA-MSA text. Hence a need for a robust dialect
identification tool as a preprocessing step arises
both on the word and sentence levels.
In this paper, we focus on the problem of dialect
identification on the sentence level. We propose
a supervised approach for identifying whether a
given sentence is prevalently MSA or Egyptian
DA (EDA). The system uses the approach that was
presented in (Elfardy et al., 2013) to perform token
dialect identification. The token level decisions
are then combined with other features to train a
generative classifier that tries to predict the class
of the given sentence. The presented system out-
performs the approach presented by Zaidan and
Callison-Burch (2011) on the same dataset using
10-fold cross validation.
</bodyText>
<sectionHeader confidence="0.999693" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.9989713">
Dialect Identification in Arabic is crucial for al-
most all NLP tasks, yet most of the research in
Arabic NLP, with few exceptions, is targeted to-
wards MSA. Biadsy et al. (2009) present a sys-
tem that identifies dialectal words in speech and
their dialect of origin through the acoustic signals.
Salloum and Habash (2011) tackle the problem of
DA to English Machine Translation (MT) by piv-
oting through MSA. The authors present a system
that applies transfer rules from DA to MSA then
uses state of the art MSA to English MT system.
Habash et al. (2012) present CODA, a Conven-
tional Orthography for Dialectal Arabic that aims
to standardize the orthography of all the variants
of DA while Dasigi and Diab (2011) present an
unsupervised clustering approach to identify or-
thographic variants in DA. Zaidan and Callison-
Burch (2011) crawl a large dataset of MSA-DA
news’ commentaries. The authors annotate part
of the dataset for sentence-level dialectalness on
</bodyText>
<page confidence="0.987785">
456
</page>
<bodyText confidence="0.8583032">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 456–461,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
Amazon Mechanical Turk and try a language mod-
eling (LM) approach to solve the problem. In
Elfardy and Diab (2012a), we present a set of
guidelines for token-level identification of dialec-
talness while in (Elfardy and Diab, 2012b), (El-
fardy et al., 2013) we tackle the problem of token-
level dialect-identification by casting it as a code-
switching problem.
</bodyText>
<sectionHeader confidence="0.9904425" genericHeader="method">
3 Approach to Sentence-Level Dialect
Identification
</sectionHeader>
<bodyText confidence="0.999233">
We present a supervised system that uses a Naive
Bayes classifier trained on gold labeled data with
sentence level binary decisions of either being
MSA or DA.
</bodyText>
<subsectionHeader confidence="0.944435">
3.1 Features
</subsectionHeader>
<bodyText confidence="0.998701">
The proposed supervised system uses two kinds of
features: (1) Core Features, and (2) Meta Features.
</bodyText>
<subsectionHeader confidence="0.895248">
3.1.1 Core Features:
</subsectionHeader>
<bodyText confidence="0.973167791666667">
These features indicate how dialectal (or non di-
alectal) a given sentence is. They are further
divided into: (a) Token-based features and (b)
Perplexity-based features.
3.1.1.1 Token-based Features: We use the
approach that was presented in (Elfardy et al.,
2013) to decide upon the class of each word in
the given sentence. The aforementioned approach
relies on language models (LM) and MSA and
EDA Morphological Analyzer to decide whether
each word is (a) MSA, (b) EDA, (c) Both (MSA
&amp; EDA) or (d) OOV. We use the token-level class
labels to estimate the percentage of EDA words
and the percentage of OOVs for each sentence.
These percentages are then used as features for
the proposed model. The following variants of the
underlying token-level system are built to assess
the effect of varying the level of preprocessing
on the underlying LM on the performance of the
overall sentence level dialect identification pro-
cess: (1) Surface, (2) Tokenized, (3) CODAfied,
and (4) Tokenized-CODA. We use the following
sentence to show the different techniques:
A�JJ�Ê« Qk�-J»ð Ð@Qk èY»kdh HrAm wktyr ElynA
</bodyText>
<listItem confidence="0.9329138">
1. Surface LMs: No significant preprocessing
is applied apart from the regular initial clean
up of the text which includes removal of
URLs, normalization of speech effects such
as reducing all redundant letters in a word to
</listItem>
<footnote confidence="0.8595575">
1We use Buckwalter transliteration scheme
http://www.qamus.org/transliteration.htm
</footnote>
<bodyText confidence="0.9347934">
a standardized form, eg. the elongated form
of the wordQI-J»ktyr1 ‘a lot’ which could be
rendered in the text asQ���J��J��J�----J»kttttyyyyr
is reduced to Q���J��J��J��J��J» ktttyyyr (specifi-
cally three repeated letters instead of an un-
predictable number of repetitions, to main-
tain the signal that there is a speech effect
which could be a DA indicator).
ex. A�JJ�Ê« Qt
.ð Ð@Qk èY»
</bodyText>
<listItem confidence="0.6685618">
kdh HrAm wktyr ElynA
2. Orthography Normalized (CODAfied)
LM: since DA is not originally a written
form of Arabic, no standard orthography
exists for it. Habash et al. (2012) attempt
to solve this problem by presenting CODA,
a conventional orthography for writing DA.
We use the implementation of CODA pre-
sented in CODAfy (Eskander et al., 2013),
to build an orthography-normalized LM.
While CODA and its applied version using
CODAfy solve the spelling inconsistency
problem in DA, special care must be taken
when using it for our task since it removes
valuable dialectalness cues. For example, the
</listItem>
<bodyText confidence="0.9801039">
letter H~ (v in Buckwalter (BW) Translitera-
tion) is converted into the letter H~ (t in BW)
in a DA context. CODA suggests that such
cases get mapped to the original MSA phono-
logical variant which might make the dialect
identification problem more challenging. On
the other hand, CODA solves the sparseness
issue by mapping multiple spelling-variants
to the same orthographic form leading to a
more robust LM.
</bodyText>
<listItem confidence="0.929730545454545">
ex. A�JJ�Ê« Q���J»ð Ð@Qk èY»
kdh HrAm wkvyr ElynA
3. Tokenized LM: D3 tokenization-scheme is
applied to all data using MADA (Habash et
al., 2009) (an MSA Tokenizer) for the MSA
corpora, and MADA-ARZ (Habash et al.,
2013) (an EDA tokenizer) for the EDA cor-
pora. For building the tokenized LM, we
maintain clitics and lexemes. Some clitics
are unique to MSA while others are unique to
EDA so maintaining them in the LM is help-
</listItem>
<bodyText confidence="0.9809115">
ful, eg. the negation enclitic €� $ is only
used in EDA but it could be seen with an
MSA/EDA homograph, maintaining the en-
clitic in the LM facilitates the identification
</bodyText>
<page confidence="0.99312">
457
</page>
<bodyText confidence="0.997431">
of the sequence as being EDA. 5-grams are
used for building the tokenized LMs (as op-
posed to 3-grams for the surface LMs)
</bodyText>
<table confidence="0.678493">
ex. A�K ú
Î« Q���J» ð Ð@Qk èY»
kdh HrAm w+ ktyr Ely +nA
4. Tokenized &amp; Orthography Normalized
LMs: (Tokenized-CODA) The data is tok-
enized as in (3) then orthography normaliza-
tion is applied to the tokenized data.
ex. A�K ú
Î« Q���J» ð Ð@Qk èY»
kdh HrAm w+ kvyr Ely +nA
</table>
<bodyText confidence="0.9790845">
In addition to the underlying token-level system,
we use the following token-level features:
</bodyText>
<listItem confidence="0.989902111111111">
1. Percentage of words in the sentence that is
analyzable by an MSA morphological ana-
lyzer.
2. Percentage of words in the sentence that is
analyzable by an EDA morphological ana-
lyzer.
3. Percentage of words in the sentence that ex-
ists in a precompiled EDA lexicon.
3.1.1.2 Perplexity-based Features: We run
</listItem>
<bodyText confidence="0.995075333333333">
each sentence through each of the MSA and EDA
LMs and record the perplexity for each of them.
The perplexity of a language model on a given test
</bodyText>
<equation confidence="0.874621">
sentence; S(w1, .., wn) is defined as:
perplexity = (2)−(1/N)Ei log2(p(wi|hi)) (1)
</equation>
<bodyText confidence="0.999739666666667">
where N is the number of tokens in the sentence
and hi is the history of token wi.
The perplexity conveys how confused the LM is
about the given sentence so the higher the perplex-
ity value, the less probable that the given sentence
matches the LM.2
</bodyText>
<subsectionHeader confidence="0.817582">
3.1.2 Meta Features.
</subsectionHeader>
<bodyText confidence="0.9777915">
These are the features that do not directly relate
to the dialectalness of words in the given sentence
but rather estimate how informal the sentence is
and include:
</bodyText>
<listItem confidence="0.880794666666667">
• The percentage of punctuation, numbers,
special-characters and words written in Ro-
man script.
</listItem>
<footnote confidence="0.582108">
2We repeat this step for each of the preprocessing schemes
explained in section 3.1.1.1
</footnote>
<listItem confidence="0.9959439">
• The percentage of words having word-
lengthening effects.
• Number of words &amp; average word-length.
• Whether the sentence has consecutive re-
peated punctuation or not. (Binary feature,
yes/no)
• Whether the sentence has an exclamation
mark or not. (Binary feature, yes/no)
• Whether the sentence has emoticons or not.
(Binary feature, yes/no)
</listItem>
<subsectionHeader confidence="0.999769">
3.2 Model Training
</subsectionHeader>
<bodyText confidence="0.99998647368421">
We use the WEKA toolkit (Hall et al., 2009) and
the derived features to train a Naive-Bayes classi-
fier. The classifier is trained and cross-validated
on the gold-training data for each of our different
configurations (Surface, CODAfied, Tokenized &amp;
Tokenized-CODA).
We conduct two sets of experiments. In the first
one, Experiment Set A, we split the data into a
training set and a held-out test set. In the second
set, Experiment Set B, we use the whole dataset
for training without further splitting. For both sets
of experiments, we apply 10-fold cross validation
on the training data. While using a held-out test-
set for evaluation (in the first set of experiments)
is a better indicator of how well our approach per-
forms on unseen data, only the results from the
second set of experiments are directly comparable
to those produced by Zaidan and Callison-Burch
(2011).
</bodyText>
<sectionHeader confidence="0.999578" genericHeader="evaluation">
4 Experiments
</sectionHeader>
<subsectionHeader confidence="0.933052">
4.1 Data
</subsectionHeader>
<bodyText confidence="0.996452">
We use the code-switched EDA-MSA portion of
the crowd source annotated dataset by Zaidan
and Callison-Burch (2011). The dataset consists
of user commentaries on Egyptian news articles.
Table 1 shows the statistics of the data.
</bodyText>
<table confidence="0.902819666666667">
MSA Sent. EDA Sent. MSA Tok. EDA Tok.
Train 12,160 11,274 300,181 292,109
Test 1,352 1,253 32,048 32,648
</table>
<tableCaption confidence="0.89832">
Table 1: Number of EDA and MSA sentences and
</tableCaption>
<figureCaption confidence="0.7178074">
tokens in the training and test datasets. In Experi-
ment Set A only the train-set is used to perform a
10-fold cross-validation and the test-set is used for
evaluation. In experiment Set B, all data is used to
perform the 10-fold cross-validation.
</figureCaption>
<page confidence="0.962135">
458
</page>
<figure confidence="0.997696">
(a) Experiment Set A (Uses 90% of the dataset) (b) Experiment Set B (Uses the whole dataset)
</figure>
<figureCaption confidence="0.996001">
Figure 1: Learning curves for the different configurations (obtained by applying 10-fold cross validation
on the training set.)
</figureCaption>
<subsectionHeader confidence="0.98275">
4.2 Baselines
</subsectionHeader>
<bodyText confidence="0.999967894736842">
We use four baselines. The first of which is a
majority baseline (Maj-BL); that assigns all the
sentences the label of the most frequent class ob-
served in the training data. The second baseline
(Token-BL) assumes that the sentence is EDA if
more than 45% of its tokens are dialectal otherwise
it assumes it is MSA.3 The third baseline (Ppl-BL)
runs each sentence through MSA &amp; EDA LMs and
assigns the sentence the class of the LM yielding
the lower perplexity value. The last baseline (OZ-
CCB-BL) is the result obtained by Zaidan and
Callison-Burch (2011) which uses the same ap-
proach of our third baseline, Ppl-BL.4 For Token-
BL and Ppl-BL, the performance is calculated
for all LM-sizes of the four different configura-
tions: Surface, CODAfied, Tokenized, Tokenized-
CODA and the best performing configuration on
the cross-validation set is used as the baseline sys-
tem.
</bodyText>
<subsectionHeader confidence="0.994591">
4.3 Results &amp; Discussion
</subsectionHeader>
<bodyText confidence="0.999445875">
For each of the different configurations, we build a
learning curve by varying the size of the LMs be-
tween 2M, 4M, 8M, 16M and 28M tokens. Figures
1a and 1b show the learning curves of the different
configurations on the cross-validation set for ex-
periments A &amp; B respectively. In Table 2 we note
that both CODA and Tokenized solve the data-
sparseness issue hence they produce better results
</bodyText>
<footnote confidence="0.974647">
3We experimented with different thresholds (15%, 30%,
45%, 60% and 75%) and the 45% threshold setting yielded
</footnote>
<table confidence="0.999366333333333">
Condition Exp. Set A Exp. Set B
Maj-BL 51.9 51.9
Token-BL 79.1 78.5
Ppl-BL 80.4 80.4
OZ-CCB-BL N/A 80.9
Surface 82.4 82.6
CODA 82.7 82.8
Tokenized 85.3 85.5
Tokenized-CODA 84.9 84.9
</table>
<tableCaption confidence="0.993099">
Table 2: Performance Accuracies of the differ-
</tableCaption>
<bodyText confidence="0.921895823529412">
ent configurations of the 8M LM (best-performing
LM size) using 10-fold cross validation against the
different baselines.
than Surface experimental condition. However, as
mentioned earlier, CODA removes some dialectal-
ness cues so the improvement resulting from using
CODA is much less than that from using tokeniza-
tion. Also when combining CODA with tokeniza-
tion as in the condition Tokenized-CODA, the per-
formance drops since in this case the sparseness
issue has been already resolved by tokenization
so adding CODA only removes dialectalness cues.
For example Q���J»ð wktyr ‘and a lot’ does not oc-
cur frequently in the data so when performing the
tokenization it becomes Qt
:» ð w+ ktyr which
on the contrary is frequent in the data. Adding
</bodyText>
<footnote confidence="0.828007">
the best performance
4This baseline can only be compared to the results of the
second set of experiments.
</footnote>
<page confidence="0.994344">
459
</page>
<table confidence="0.9990712">
Condition Test Set
Maj-BL 51.9
Token-BL 77
Ppl-BL 81.1
Tokenized 83.3
</table>
<tableCaption confidence="0.75969375">
Table 3: Performance Accuracies of the best-
performing configuration (Tokenized) on the held-
out test set against the baselines Maj-BL, Token-
BL and Ppl-BL.
</tableCaption>
<bodyText confidence="0.9922936875">
Orthography-Normalization converts it to .S 9
w+ kvyr which is more MSA-like hence the con-
fusability increases.
All configurations outperform all baselines with
the Tokenized configuration producing the best re-
sults. The performance of all systems drop as
the size of the LM increases beyond 16M tokens.
As indicated in (Elfardy et al., 2013) as the size
of the MSA &amp; EDA LMs increases, the shared
ngrams increase leading to higher confusability
between the classes of tokens in a given sentence.
Table 3 presents the results on the held out dataset
compared against three of the baselines, Maj-BL,
Token-BL and Ppl-BL. We note that the Tokenized
condition, the best performing condition, outper-
forms all baselines with a significant margin.
</bodyText>
<sectionHeader confidence="0.998904" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999985857142857">
We presented a supervised approach for sentence
level dialect identification in Arabic. The ap-
proach uses features from an underlying system
for token-level identification of Egyptian Dialec-
tal Arabic in addition to other core and meta fea-
tures to decide whether a given sentence is MSA or
EDA. We studied the impact of two types of pre-
processing techniques (Tokenization and Orthog-
raphy Normalization) as well as varying the size of
the LM on the performance of our approach. The
presented approach produced significantly better
results than a previous approach in addition to
beating the majority baseline and two other strong
baselines.
</bodyText>
<sectionHeader confidence="0.998453" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.444587666666667">
This work is supported by the Defense Advanced
Research Projects Agency (DARPA) BOLT pro-
gram under contract number HR0011-12-C-0014.
</bodyText>
<sectionHeader confidence="0.956426" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999649054545455">
Fadi Biadsy, Julia Hirschberg, and Nizar Habash.
2009. Spoken arabic dialect identification using
phonotactic modeling. In Proceedings of the Work-
shop on Computational Approaches to Semitic Lan-
guages at the meeting of the European Associa-
tion for Computational Linguistics (EACL), Athens,
Greece.
Pradeep Dasigi and Mona Diab. 2011. Codact: To-
wards identifying orthographic variants in dialec-
tal arabic. In Proceedings of the 5th International
Joint Conference on Natural Language Processing
(ICJNLP), Chiangmai, Thailand.
Heba Elfardy and Mona Diab. 2012a. Simplified
guidelines for the creation of large scale dialectal
arabic annotations. In Proceedings of the 8th In-
ternational Conference on Language Resources and
Evaluation (LREC), Istanbul, Turkey.
Heba Elfardy and Mona Diab. 2012b. Token level
identification of linguistic code switching. In Pro-
ceedings of the 24th International Conference on
Computational Linguistics (COLING),Mumbai, In-
dia.
Heba Elfardy, Mohamed Al-Badrashiny, and Mona
Diab. 2013. Code Switch Point Detection in Arabic.
In Proceedings of the 18th International Conference
on Application of Natural Language to Information
Systems (NLDB2013), MediaCity, UK, June.
Ramy Eskander, Nizar Habash, Owen Rambow, and
Nadi Tomeh. 2013. Processing Spontaneous Or-
thography. In Proceedings of the 2013 Conference
of the North American Chapter of the Association
for Computational Linguistics: Human Language
Technologies (NAACL-HLT), Atlanta, GA.
Ferguson. 1959. Diglossia. Word 15. 325340.
Nizar Habash, Owen Rambow, and Ryan Roth. 2009.
Mada+ tokan: A toolkit for arabic tokenization, dia-
critization, morphological disambiguation, pos tag-
ging, stemming and lemmatization. In Proceedings
of the 2nd International Conference on Arabic Lan-
guage Resources and Tools (MEDAR), Cairo, Egypt,
pages 102–109.
Nizar Habash, Mona Diab, and Owen Rabmow. 2012.
Conventional orthography for dialectal arabic. In
Proceedings of the Language Resources and Eval-
uation Conference (LREC), Istanbul.
Nizar Habash, Ryan Roth, Owen Rambow, Ramy Es-
kander, and Nadi Tomeh. 2013. Morphological
Analysis and Disambiguation for Dialectal Arabic.
In Proceedings of the 2013 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies
(NAACL-HLT), Atlanta, GA.
Nizar Habash. 2010. Introduction to arabic natural
language processing. Advances in neural informa-
tion processing systems.
</reference>
<page confidence="0.989204">
460
</page>
<reference confidence="0.9997444375">
Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard
Pfahringer, Peter Reutemann, and Ian H Witten.
2009. The weka data mining software: an update.
ACM SIGKDD Explorations Newsletter, 11(1):10–
18.
Wael Salloum and Nizar Habash. 2011. Dialectal
to standard arabic paraphrasing to improve arabic-
english statistical machine translation. In Proceed-
ings of the First Workshop on Algorithms and Re-
sources for Modelling of Dialects and Language Va-
rieties, pages 10–21. Association for Computational
Linguistics.
Omar F Zaidan and Chris Callison-Burch. 2011. The
arabic online commentary dataset: an annotated
dataset of informal arabic with high dialectal con-
tent. In Proceedings of ACL, pages 37–41.
</reference>
<page confidence="0.999433">
461
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.593196">
<title confidence="0.999193">Sentence Level Dialect Identification in Arabic</title>
<author confidence="0.918295">Heba</author>
<affiliation confidence="0.8931675">Department of Computer Columbia</affiliation>
<email confidence="0.999256">heba@cs.columbia.edu</email>
<author confidence="0.984953">Mona</author>
<affiliation confidence="0.9596745">Department of Computer The George Washington</affiliation>
<email confidence="0.999744">mtdiab@gwu.edu</email>
<abstract confidence="0.994136555555556">This paper introduces a supervised approach for performing sentence level dialect identification between Modern Standard Arabic and Egyptian Dialectal Arabic. We use token level labels to derive sentence-level features. These features are then used with other core and meta features to train a generative classifier that predicts the correct label for each sentence in the given input text. The system achieves an accuracy of 85.5% on an Arabic online-commentary dataset outperforming a previously proposed approach achieving 80.9% and reflecting a significant gain over a majority baseline of 51.9% and two strong baseline systems of 78.5% and 80.4%, respectively.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Fadi Biadsy</author>
<author>Julia Hirschberg</author>
<author>Nizar Habash</author>
</authors>
<title>Spoken arabic dialect identification using phonotactic modeling.</title>
<date>2009</date>
<booktitle>In Proceedings of the Workshop on Computational Approaches to Semitic Languages at the meeting of the European Association for Computational Linguistics (EACL),</booktitle>
<location>Athens, Greece.</location>
<contexts>
<context position="3000" citStr="Biadsy et al. (2009)" startWordPosition="467" endWordPosition="470">gyptian DA (EDA). The system uses the approach that was presented in (Elfardy et al., 2013) to perform token dialect identification. The token level decisions are then combined with other features to train a generative classifier that tries to predict the class of the given sentence. The presented system outperforms the approach presented by Zaidan and Callison-Burch (2011) on the same dataset using 10-fold cross validation. 2 Related Work Dialect Identification in Arabic is crucial for almost all NLP tasks, yet most of the research in Arabic NLP, with few exceptions, is targeted towards MSA. Biadsy et al. (2009) present a system that identifies dialectal words in speech and their dialect of origin through the acoustic signals. Salloum and Habash (2011) tackle the problem of DA to English Machine Translation (MT) by pivoting through MSA. The authors present a system that applies transfer rules from DA to MSA then uses state of the art MSA to English MT system. Habash et al. (2012) present CODA, a Conventional Orthography for Dialectal Arabic that aims to standardize the orthography of all the variants of DA while Dasigi and Diab (2011) present an unsupervised clustering approach to identify orthograph</context>
</contexts>
<marker>Biadsy, Hirschberg, Habash, 2009</marker>
<rawString>Fadi Biadsy, Julia Hirschberg, and Nizar Habash. 2009. Spoken arabic dialect identification using phonotactic modeling. In Proceedings of the Workshop on Computational Approaches to Semitic Languages at the meeting of the European Association for Computational Linguistics (EACL), Athens, Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pradeep Dasigi</author>
<author>Mona Diab</author>
</authors>
<title>Codact: Towards identifying orthographic variants in dialectal arabic.</title>
<date>2011</date>
<booktitle>In Proceedings of the 5th International Joint Conference on Natural Language Processing (ICJNLP), Chiangmai,</booktitle>
<location>Thailand.</location>
<contexts>
<context position="3533" citStr="Dasigi and Diab (2011)" startWordPosition="559" endWordPosition="562">esearch in Arabic NLP, with few exceptions, is targeted towards MSA. Biadsy et al. (2009) present a system that identifies dialectal words in speech and their dialect of origin through the acoustic signals. Salloum and Habash (2011) tackle the problem of DA to English Machine Translation (MT) by pivoting through MSA. The authors present a system that applies transfer rules from DA to MSA then uses state of the art MSA to English MT system. Habash et al. (2012) present CODA, a Conventional Orthography for Dialectal Arabic that aims to standardize the orthography of all the variants of DA while Dasigi and Diab (2011) present an unsupervised clustering approach to identify orthographic variants in DA. Zaidan and CallisonBurch (2011) crawl a large dataset of MSA-DA news’ commentaries. The authors annotate part of the dataset for sentence-level dialectalness on 456 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 456–461, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics Amazon Mechanical Turk and try a language modeling (LM) approach to solve the problem. In Elfardy and Diab (2012a), we present a set of guidelines for token-level</context>
</contexts>
<marker>Dasigi, Diab, 2011</marker>
<rawString>Pradeep Dasigi and Mona Diab. 2011. Codact: Towards identifying orthographic variants in dialectal arabic. In Proceedings of the 5th International Joint Conference on Natural Language Processing (ICJNLP), Chiangmai, Thailand.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heba Elfardy</author>
<author>Mona Diab</author>
</authors>
<title>Simplified guidelines for the creation of large scale dialectal arabic annotations.</title>
<date>2012</date>
<booktitle>In Proceedings of the 8th International Conference on Language Resources and Evaluation (LREC),</booktitle>
<location>Istanbul, Turkey.</location>
<contexts>
<context position="4083" citStr="Elfardy and Diab (2012" startWordPosition="640" endWordPosition="643">e the orthography of all the variants of DA while Dasigi and Diab (2011) present an unsupervised clustering approach to identify orthographic variants in DA. Zaidan and CallisonBurch (2011) crawl a large dataset of MSA-DA news’ commentaries. The authors annotate part of the dataset for sentence-level dialectalness on 456 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 456–461, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics Amazon Mechanical Turk and try a language modeling (LM) approach to solve the problem. In Elfardy and Diab (2012a), we present a set of guidelines for token-level identification of dialectalness while in (Elfardy and Diab, 2012b), (Elfardy et al., 2013) we tackle the problem of tokenlevel dialect-identification by casting it as a codeswitching problem. 3 Approach to Sentence-Level Dialect Identification We present a supervised system that uses a Naive Bayes classifier trained on gold labeled data with sentence level binary decisions of either being MSA or DA. 3.1 Features The proposed supervised system uses two kinds of features: (1) Core Features, and (2) Meta Features. 3.1.1 Core Features: These featu</context>
</contexts>
<marker>Elfardy, Diab, 2012</marker>
<rawString>Heba Elfardy and Mona Diab. 2012a. Simplified guidelines for the creation of large scale dialectal arabic annotations. In Proceedings of the 8th International Conference on Language Resources and Evaluation (LREC), Istanbul, Turkey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heba Elfardy</author>
<author>Mona Diab</author>
</authors>
<title>Token level identification of linguistic code switching.</title>
<date>2012</date>
<booktitle>In Proceedings of the 24th International Conference on Computational Linguistics (COLING),Mumbai,</booktitle>
<contexts>
<context position="4083" citStr="Elfardy and Diab (2012" startWordPosition="640" endWordPosition="643">e the orthography of all the variants of DA while Dasigi and Diab (2011) present an unsupervised clustering approach to identify orthographic variants in DA. Zaidan and CallisonBurch (2011) crawl a large dataset of MSA-DA news’ commentaries. The authors annotate part of the dataset for sentence-level dialectalness on 456 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 456–461, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics Amazon Mechanical Turk and try a language modeling (LM) approach to solve the problem. In Elfardy and Diab (2012a), we present a set of guidelines for token-level identification of dialectalness while in (Elfardy and Diab, 2012b), (Elfardy et al., 2013) we tackle the problem of tokenlevel dialect-identification by casting it as a codeswitching problem. 3 Approach to Sentence-Level Dialect Identification We present a supervised system that uses a Naive Bayes classifier trained on gold labeled data with sentence level binary decisions of either being MSA or DA. 3.1 Features The proposed supervised system uses two kinds of features: (1) Core Features, and (2) Meta Features. 3.1.1 Core Features: These featu</context>
</contexts>
<marker>Elfardy, Diab, 2012</marker>
<rawString>Heba Elfardy and Mona Diab. 2012b. Token level identification of linguistic code switching. In Proceedings of the 24th International Conference on Computational Linguistics (COLING),Mumbai, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heba Elfardy</author>
<author>Mohamed Al-Badrashiny</author>
<author>Mona Diab</author>
</authors>
<title>Code Switch Point Detection in Arabic.</title>
<date>2013</date>
<booktitle>In Proceedings of the 18th International Conference on Application of Natural Language to Information Systems (NLDB2013),</booktitle>
<location>MediaCity, UK,</location>
<contexts>
<context position="2471" citStr="Elfardy et al., 2013" startWordPosition="381" endWordPosition="384">rious challenge for almost all NLP tasks since MSA and DA differ on all levels of linguistic representation. For example, MSA trained tools perform very badly when applied directly to DA or to a code-switched DA-MSA text. Hence a need for a robust dialect identification tool as a preprocessing step arises both on the word and sentence levels. In this paper, we focus on the problem of dialect identification on the sentence level. We propose a supervised approach for identifying whether a given sentence is prevalently MSA or Egyptian DA (EDA). The system uses the approach that was presented in (Elfardy et al., 2013) to perform token dialect identification. The token level decisions are then combined with other features to train a generative classifier that tries to predict the class of the given sentence. The presented system outperforms the approach presented by Zaidan and Callison-Burch (2011) on the same dataset using 10-fold cross validation. 2 Related Work Dialect Identification in Arabic is crucial for almost all NLP tasks, yet most of the research in Arabic NLP, with few exceptions, is targeted towards MSA. Biadsy et al. (2009) present a system that identifies dialectal words in speech and their d</context>
<context position="4224" citStr="Elfardy et al., 2013" startWordPosition="662" endWordPosition="666">variants in DA. Zaidan and CallisonBurch (2011) crawl a large dataset of MSA-DA news’ commentaries. The authors annotate part of the dataset for sentence-level dialectalness on 456 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 456–461, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics Amazon Mechanical Turk and try a language modeling (LM) approach to solve the problem. In Elfardy and Diab (2012a), we present a set of guidelines for token-level identification of dialectalness while in (Elfardy and Diab, 2012b), (Elfardy et al., 2013) we tackle the problem of tokenlevel dialect-identification by casting it as a codeswitching problem. 3 Approach to Sentence-Level Dialect Identification We present a supervised system that uses a Naive Bayes classifier trained on gold labeled data with sentence level binary decisions of either being MSA or DA. 3.1 Features The proposed supervised system uses two kinds of features: (1) Core Features, and (2) Meta Features. 3.1.1 Core Features: These features indicate how dialectal (or non dialectal) a given sentence is. They are further divided into: (a) Token-based features and (b) Perplexity</context>
<context position="14866" citStr="Elfardy et al., 2013" startWordPosition="2426" endWordPosition="2429">d to the results of the second set of experiments. 459 Condition Test Set Maj-BL 51.9 Token-BL 77 Ppl-BL 81.1 Tokenized 83.3 Table 3: Performance Accuracies of the bestperforming configuration (Tokenized) on the heldout test set against the baselines Maj-BL, TokenBL and Ppl-BL. Orthography-Normalization converts it to .S 9 w+ kvyr which is more MSA-like hence the confusability increases. All configurations outperform all baselines with the Tokenized configuration producing the best results. The performance of all systems drop as the size of the LM increases beyond 16M tokens. As indicated in (Elfardy et al., 2013) as the size of the MSA &amp; EDA LMs increases, the shared ngrams increase leading to higher confusability between the classes of tokens in a given sentence. Table 3 presents the results on the held out dataset compared against three of the baselines, Maj-BL, Token-BL and Ppl-BL. We note that the Tokenized condition, the best performing condition, outperforms all baselines with a significant margin. 5 Conclusion We presented a supervised approach for sentence level dialect identification in Arabic. The approach uses features from an underlying system for token-level identification of Egyptian Dia</context>
</contexts>
<marker>Elfardy, Al-Badrashiny, Diab, 2013</marker>
<rawString>Heba Elfardy, Mohamed Al-Badrashiny, and Mona Diab. 2013. Code Switch Point Detection in Arabic. In Proceedings of the 18th International Conference on Application of Natural Language to Information Systems (NLDB2013), MediaCity, UK, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ramy Eskander</author>
<author>Nizar Habash</author>
<author>Owen Rambow</author>
<author>Nadi Tomeh</author>
</authors>
<title>Processing Spontaneous Orthography.</title>
<date>2013</date>
<journal>Diglossia. Word</journal>
<booktitle>In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT),</booktitle>
<volume>15</volume>
<pages>325340</pages>
<location>Atlanta, GA. Ferguson.</location>
<contexts>
<context position="6808" citStr="Eskander et al., 2013" startWordPosition="1072" endWordPosition="1075">ext asQ���J��J��J�----J»kttttyyyyr is reduced to Q���J��J��J��J��J» ktttyyyr (specifically three repeated letters instead of an unpredictable number of repetitions, to maintain the signal that there is a speech effect which could be a DA indicator). ex. A�JJ�Ê« Qt .ð Ð@Qk èY» kdh HrAm wktyr ElynA 2. Orthography Normalized (CODAfied) LM: since DA is not originally a written form of Arabic, no standard orthography exists for it. Habash et al. (2012) attempt to solve this problem by presenting CODA, a conventional orthography for writing DA. We use the implementation of CODA presented in CODAfy (Eskander et al., 2013), to build an orthography-normalized LM. While CODA and its applied version using CODAfy solve the spelling inconsistency problem in DA, special care must be taken when using it for our task since it removes valuable dialectalness cues. For example, the letter H~ (v in Buckwalter (BW) Transliteration) is converted into the letter H~ (t in BW) in a DA context. CODA suggests that such cases get mapped to the original MSA phonological variant which might make the dialect identification problem more challenging. On the other hand, CODA solves the sparseness issue by mapping multiple spelling-varia</context>
</contexts>
<marker>Eskander, Habash, Rambow, Tomeh, 2013</marker>
<rawString>Ramy Eskander, Nizar Habash, Owen Rambow, and Nadi Tomeh. 2013. Processing Spontaneous Orthography. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT), Atlanta, GA. Ferguson. 1959. Diglossia. Word 15. 325340.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Owen Rambow</author>
<author>Ryan Roth</author>
</authors>
<title>Mada+ tokan: A toolkit for arabic tokenization, diacritization, morphological disambiguation, pos tagging, stemming and lemmatization.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2nd International Conference on Arabic Language Resources and Tools (MEDAR),</booktitle>
<pages>102--109</pages>
<location>Cairo, Egypt,</location>
<contexts>
<context position="7616" citStr="Habash et al., 2009" startWordPosition="1205" endWordPosition="1208">sk since it removes valuable dialectalness cues. For example, the letter H~ (v in Buckwalter (BW) Transliteration) is converted into the letter H~ (t in BW) in a DA context. CODA suggests that such cases get mapped to the original MSA phonological variant which might make the dialect identification problem more challenging. On the other hand, CODA solves the sparseness issue by mapping multiple spelling-variants to the same orthographic form leading to a more robust LM. ex. A�JJ�Ê« Q���J»ð Ð@Qk èY» kdh HrAm wkvyr ElynA 3. Tokenized LM: D3 tokenization-scheme is applied to all data using MADA (Habash et al., 2009) (an MSA Tokenizer) for the MSA corpora, and MADA-ARZ (Habash et al., 2013) (an EDA tokenizer) for the EDA corpora. For building the tokenized LM, we maintain clitics and lexemes. Some clitics are unique to MSA while others are unique to EDA so maintaining them in the LM is helpful, eg. the negation enclitic €� $ is only used in EDA but it could be seen with an MSA/EDA homograph, maintaining the enclitic in the LM facilitates the identification 457 of the sequence as being EDA. 5-grams are used for building the tokenized LMs (as opposed to 3-grams for the surface LMs) ex. A�K ú Î« Q���J» ð Ð@Q</context>
</contexts>
<marker>Habash, Rambow, Roth, 2009</marker>
<rawString>Nizar Habash, Owen Rambow, and Ryan Roth. 2009. Mada+ tokan: A toolkit for arabic tokenization, diacritization, morphological disambiguation, pos tagging, stemming and lemmatization. In Proceedings of the 2nd International Conference on Arabic Language Resources and Tools (MEDAR), Cairo, Egypt, pages 102–109.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Mona Diab</author>
<author>Owen Rabmow</author>
</authors>
<title>Conventional orthography for dialectal arabic.</title>
<date>2012</date>
<booktitle>In Proceedings of the Language Resources and Evaluation Conference (LREC),</booktitle>
<location>Istanbul.</location>
<contexts>
<context position="3375" citStr="Habash et al. (2012)" startWordPosition="533" endWordPosition="536">) on the same dataset using 10-fold cross validation. 2 Related Work Dialect Identification in Arabic is crucial for almost all NLP tasks, yet most of the research in Arabic NLP, with few exceptions, is targeted towards MSA. Biadsy et al. (2009) present a system that identifies dialectal words in speech and their dialect of origin through the acoustic signals. Salloum and Habash (2011) tackle the problem of DA to English Machine Translation (MT) by pivoting through MSA. The authors present a system that applies transfer rules from DA to MSA then uses state of the art MSA to English MT system. Habash et al. (2012) present CODA, a Conventional Orthography for Dialectal Arabic that aims to standardize the orthography of all the variants of DA while Dasigi and Diab (2011) present an unsupervised clustering approach to identify orthographic variants in DA. Zaidan and CallisonBurch (2011) crawl a large dataset of MSA-DA news’ commentaries. The authors annotate part of the dataset for sentence-level dialectalness on 456 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 456–461, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics Amaz</context>
<context position="6637" citStr="Habash et al. (2012)" startWordPosition="1044" endWordPosition="1047">ransliteration scheme http://www.qamus.org/transliteration.htm a standardized form, eg. the elongated form of the wordQI-J»ktyr1 ‘a lot’ which could be rendered in the text asQ���J��J��J�----J»kttttyyyyr is reduced to Q���J��J��J��J��J» ktttyyyr (specifically three repeated letters instead of an unpredictable number of repetitions, to maintain the signal that there is a speech effect which could be a DA indicator). ex. A�JJ�Ê« Qt .ð Ð@Qk èY» kdh HrAm wktyr ElynA 2. Orthography Normalized (CODAfied) LM: since DA is not originally a written form of Arabic, no standard orthography exists for it. Habash et al. (2012) attempt to solve this problem by presenting CODA, a conventional orthography for writing DA. We use the implementation of CODA presented in CODAfy (Eskander et al., 2013), to build an orthography-normalized LM. While CODA and its applied version using CODAfy solve the spelling inconsistency problem in DA, special care must be taken when using it for our task since it removes valuable dialectalness cues. For example, the letter H~ (v in Buckwalter (BW) Transliteration) is converted into the letter H~ (t in BW) in a DA context. CODA suggests that such cases get mapped to the original MSA phonol</context>
</contexts>
<marker>Habash, Diab, Rabmow, 2012</marker>
<rawString>Nizar Habash, Mona Diab, and Owen Rabmow. 2012. Conventional orthography for dialectal arabic. In Proceedings of the Language Resources and Evaluation Conference (LREC), Istanbul.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Ryan Roth</author>
<author>Owen Rambow</author>
<author>Ramy Eskander</author>
<author>Nadi Tomeh</author>
</authors>
<title>Morphological Analysis and Disambiguation for Dialectal Arabic.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT),</booktitle>
<location>Atlanta, GA.</location>
<contexts>
<context position="7691" citStr="Habash et al., 2013" startWordPosition="1218" endWordPosition="1221"> (v in Buckwalter (BW) Transliteration) is converted into the letter H~ (t in BW) in a DA context. CODA suggests that such cases get mapped to the original MSA phonological variant which might make the dialect identification problem more challenging. On the other hand, CODA solves the sparseness issue by mapping multiple spelling-variants to the same orthographic form leading to a more robust LM. ex. A�JJ�Ê« Q���J»ð Ð@Qk èY» kdh HrAm wkvyr ElynA 3. Tokenized LM: D3 tokenization-scheme is applied to all data using MADA (Habash et al., 2009) (an MSA Tokenizer) for the MSA corpora, and MADA-ARZ (Habash et al., 2013) (an EDA tokenizer) for the EDA corpora. For building the tokenized LM, we maintain clitics and lexemes. Some clitics are unique to MSA while others are unique to EDA so maintaining them in the LM is helpful, eg. the negation enclitic €� $ is only used in EDA but it could be seen with an MSA/EDA homograph, maintaining the enclitic in the LM facilitates the identification 457 of the sequence as being EDA. 5-grams are used for building the tokenized LMs (as opposed to 3-grams for the surface LMs) ex. A�K ú Î« Q���J» ð Ð@Qk èY» kdh HrAm w+ ktyr Ely +nA 4. Tokenized &amp; Orthography Normalized LMs: (</context>
</contexts>
<marker>Habash, Roth, Rambow, Eskander, Tomeh, 2013</marker>
<rawString>Nizar Habash, Ryan Roth, Owen Rambow, Ramy Eskander, and Nadi Tomeh. 2013. Morphological Analysis and Disambiguation for Dialectal Arabic. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT), Atlanta, GA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
</authors>
<title>Introduction to arabic natural language processing. Advances in neural information processing systems.</title>
<date>2010</date>
<contexts>
<context position="1464" citStr="Habash, 2010" startWordPosition="219" endWordPosition="220">ine systems of 78.5% and 80.4%, respectively. 1 Introduction The Arabic language exists in a state of Diglossia (Ferguson, 1959) where the standard form of the language, Modern Standard Arabic (MSA) and the regional dialects (DA) live side-by-side and are closely related. MSA is the language used in education, scripted speech and official settings while DA is the native tongue of Arabic speakers. Arabic dialects may be divided into five main groups: Egyptian (including Libyan and Sudanese), Levantine (including Lebanese, Syrian, Palestinian and Jordanian), Gulf, Iraqi and Moroccan (Maghrebi) (Habash, 2010). Even though these dialects did not originally exist in a written form, they are pervasively present in social media text (normally mixed with MSA) nowadays. DA does not have a standard orthography leading to many spelling variations and inconsistencies. Linguistic Code switching (LCS) between MSA and DA happens both intra-sententially and intersententially. LCS in Arabic poses a serious challenge for almost all NLP tasks since MSA and DA differ on all levels of linguistic representation. For example, MSA trained tools perform very badly when applied directly to DA or to a code-switched DA-MS</context>
</contexts>
<marker>Habash, 2010</marker>
<rawString>Nizar Habash. 2010. Introduction to arabic natural language processing. Advances in neural information processing systems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Hall</author>
<author>Eibe Frank</author>
<author>Geoffrey Holmes</author>
<author>Bernhard Pfahringer</author>
<author>Peter Reutemann</author>
<author>Ian H Witten</author>
</authors>
<title>The weka data mining software: an update.</title>
<date>2009</date>
<journal>ACM SIGKDD Explorations Newsletter,</journal>
<volume>11</volume>
<issue>1</issue>
<pages>18</pages>
<contexts>
<context position="10111" citStr="Hall et al., 2009" startWordPosition="1641" endWordPosition="1644"> the sentence is and include: • The percentage of punctuation, numbers, special-characters and words written in Roman script. 2We repeat this step for each of the preprocessing schemes explained in section 3.1.1.1 • The percentage of words having wordlengthening effects. • Number of words &amp; average word-length. • Whether the sentence has consecutive repeated punctuation or not. (Binary feature, yes/no) • Whether the sentence has an exclamation mark or not. (Binary feature, yes/no) • Whether the sentence has emoticons or not. (Binary feature, yes/no) 3.2 Model Training We use the WEKA toolkit (Hall et al., 2009) and the derived features to train a Naive-Bayes classifier. The classifier is trained and cross-validated on the gold-training data for each of our different configurations (Surface, CODAfied, Tokenized &amp; Tokenized-CODA). We conduct two sets of experiments. In the first one, Experiment Set A, we split the data into a training set and a held-out test set. In the second set, Experiment Set B, we use the whole dataset for training without further splitting. For both sets of experiments, we apply 10-fold cross validation on the training data. While using a held-out testset for evaluation (in the </context>
</contexts>
<marker>Hall, Frank, Holmes, Pfahringer, Reutemann, Witten, 2009</marker>
<rawString>Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard Pfahringer, Peter Reutemann, and Ian H Witten. 2009. The weka data mining software: an update. ACM SIGKDD Explorations Newsletter, 11(1):10– 18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wael Salloum</author>
<author>Nizar Habash</author>
</authors>
<title>Dialectal to standard arabic paraphrasing to improve arabicenglish statistical machine translation.</title>
<date>2011</date>
<booktitle>In Proceedings of the First Workshop on Algorithms and Resources for Modelling of Dialects and Language Varieties,</booktitle>
<pages>10--21</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="3143" citStr="Salloum and Habash (2011)" startWordPosition="490" endWordPosition="493">oken level decisions are then combined with other features to train a generative classifier that tries to predict the class of the given sentence. The presented system outperforms the approach presented by Zaidan and Callison-Burch (2011) on the same dataset using 10-fold cross validation. 2 Related Work Dialect Identification in Arabic is crucial for almost all NLP tasks, yet most of the research in Arabic NLP, with few exceptions, is targeted towards MSA. Biadsy et al. (2009) present a system that identifies dialectal words in speech and their dialect of origin through the acoustic signals. Salloum and Habash (2011) tackle the problem of DA to English Machine Translation (MT) by pivoting through MSA. The authors present a system that applies transfer rules from DA to MSA then uses state of the art MSA to English MT system. Habash et al. (2012) present CODA, a Conventional Orthography for Dialectal Arabic that aims to standardize the orthography of all the variants of DA while Dasigi and Diab (2011) present an unsupervised clustering approach to identify orthographic variants in DA. Zaidan and CallisonBurch (2011) crawl a large dataset of MSA-DA news’ commentaries. The authors annotate part of the dataset</context>
</contexts>
<marker>Salloum, Habash, 2011</marker>
<rawString>Wael Salloum and Nizar Habash. 2011. Dialectal to standard arabic paraphrasing to improve arabicenglish statistical machine translation. In Proceedings of the First Workshop on Algorithms and Resources for Modelling of Dialects and Language Varieties, pages 10–21. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Omar F Zaidan</author>
<author>Chris Callison-Burch</author>
</authors>
<title>The arabic online commentary dataset: an annotated dataset of informal arabic with high dialectal content. In</title>
<date>2011</date>
<booktitle>Proceedings of ACL,</booktitle>
<pages>37--41</pages>
<contexts>
<context position="2756" citStr="Zaidan and Callison-Burch (2011)" startWordPosition="424" endWordPosition="427">l as a preprocessing step arises both on the word and sentence levels. In this paper, we focus on the problem of dialect identification on the sentence level. We propose a supervised approach for identifying whether a given sentence is prevalently MSA or Egyptian DA (EDA). The system uses the approach that was presented in (Elfardy et al., 2013) to perform token dialect identification. The token level decisions are then combined with other features to train a generative classifier that tries to predict the class of the given sentence. The presented system outperforms the approach presented by Zaidan and Callison-Burch (2011) on the same dataset using 10-fold cross validation. 2 Related Work Dialect Identification in Arabic is crucial for almost all NLP tasks, yet most of the research in Arabic NLP, with few exceptions, is targeted towards MSA. Biadsy et al. (2009) present a system that identifies dialectal words in speech and their dialect of origin through the acoustic signals. Salloum and Habash (2011) tackle the problem of DA to English Machine Translation (MT) by pivoting through MSA. The authors present a system that applies transfer rules from DA to MSA then uses state of the art MSA to English MT system. H</context>
<context position="10938" citStr="Zaidan and Callison-Burch (2011)" startWordPosition="1777" endWordPosition="1780">okenized &amp; Tokenized-CODA). We conduct two sets of experiments. In the first one, Experiment Set A, we split the data into a training set and a held-out test set. In the second set, Experiment Set B, we use the whole dataset for training without further splitting. For both sets of experiments, we apply 10-fold cross validation on the training data. While using a held-out testset for evaluation (in the first set of experiments) is a better indicator of how well our approach performs on unseen data, only the results from the second set of experiments are directly comparable to those produced by Zaidan and Callison-Burch (2011). 4 Experiments 4.1 Data We use the code-switched EDA-MSA portion of the crowd source annotated dataset by Zaidan and Callison-Burch (2011). The dataset consists of user commentaries on Egyptian news articles. Table 1 shows the statistics of the data. MSA Sent. EDA Sent. MSA Tok. EDA Tok. Train 12,160 11,274 300,181 292,109 Test 1,352 1,253 32,048 32,648 Table 1: Number of EDA and MSA sentences and tokens in the training and test datasets. In Experiment Set A only the train-set is used to perform a 10-fold cross-validation and the test-set is used for evaluation. In experiment Set B, all data </context>
<context position="12380" citStr="Zaidan and Callison-Burch (2011)" startWordPosition="2019" endWordPosition="2022">ined by applying 10-fold cross validation on the training set.) 4.2 Baselines We use four baselines. The first of which is a majority baseline (Maj-BL); that assigns all the sentences the label of the most frequent class observed in the training data. The second baseline (Token-BL) assumes that the sentence is EDA if more than 45% of its tokens are dialectal otherwise it assumes it is MSA.3 The third baseline (Ppl-BL) runs each sentence through MSA &amp; EDA LMs and assigns the sentence the class of the LM yielding the lower perplexity value. The last baseline (OZCCB-BL) is the result obtained by Zaidan and Callison-Burch (2011) which uses the same approach of our third baseline, Ppl-BL.4 For TokenBL and Ppl-BL, the performance is calculated for all LM-sizes of the four different configurations: Surface, CODAfied, Tokenized, TokenizedCODA and the best performing configuration on the cross-validation set is used as the baseline system. 4.3 Results &amp; Discussion For each of the different configurations, we build a learning curve by varying the size of the LMs between 2M, 4M, 8M, 16M and 28M tokens. Figures 1a and 1b show the learning curves of the different configurations on the cross-validation set for experiments A &amp; </context>
</contexts>
<marker>Zaidan, Callison-Burch, 2011</marker>
<rawString>Omar F Zaidan and Chris Callison-Burch. 2011. The arabic online commentary dataset: an annotated dataset of informal arabic with high dialectal content. In Proceedings of ACL, pages 37–41.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>