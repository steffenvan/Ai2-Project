<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001720">
<title confidence="0.993726">
Minimizing the Length of Non-Mixed Initiative Dialogs
</title>
<author confidence="0.991433">
R. Bryce Inouye
</author>
<affiliation confidence="0.9949195">
Department of Computer Science
Duke University
</affiliation>
<address confidence="0.860514">
Durham, NC 27708
</address>
<email confidence="0.999103">
rbi@cs.duke.edu
</email>
<sectionHeader confidence="0.995643" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999982857142857">
Dialog participants in a non-mixed ini-
tiative dialogs, in which one participant
asks questions exclusively and the other
participant responds to those questions
exclusively, can select actions that min-
imize the expected length of the dialog.
The choice of question that minimizes
the expected number of questions to be
asked can be computed in polynomial
time in some cases.
The polynomial-time solutions to spe-
cial cases of the problem suggest a num-
ber of strategies for selecting dialog ac-
tions in the intractable general case. In
a simulation involving 1000 dialog sce-
narios, an approximate solution using
the most probable rule set/least proba-
ble question resulted in expected dialog
length of 3.60 questions per dialog, as
compared to 2.80 for the optimal case,
and 5.05 for a randomly chosen strategy.
</bodyText>
<sectionHeader confidence="0.999336" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999715466666667">
Making optimal choices in unconstrained natural
language dialogs may be impossible. The diffi-
culty of defining consistent, meaningful criteria
for which behavior can be optimized and the infi-
nite number of possible actions that may be taken
at any point in an unconstrained dialog present
generally insurmountable obstacles to optimiza-
tion.
Computing the optimal dialog action may be
intractable even in a simple, highly constrained
model of dialog with narrowly defined measures
of success. This paper presents an analysis of the
optimal behavior of a participant in non-mixed ini-
tiative dialogs, a restricted but important class of
dialogs.
</bodyText>
<sectionHeader confidence="0.720631" genericHeader="introduction">
2 Non-mixed initiative dialogs
</sectionHeader>
<bodyText confidence="0.999827785714286">
In recent years, dialog researchers have focused
much attention on the study of mixed-initiative
behaviors in natural language dialogs. In gen-
eral, mixed initiative refers to the idea that con-
trol over the content and direction of a dialog may
pass from one participant to another. 1 Cohen et
al. (1998) provides a good overview of the vari-
ous definitions of dialog initiative that have been
proposed. Our work adopts a definition similar to
Guinn (1999), who posits that initiative attaches to
specific dialog goals.
This paper considers non-mixed-initiative di-
alogs, which we shall take to mean dialogs with
the following characteristics:
</bodyText>
<listItem confidence="0.911913875">
1. The dialog has two participants, the leader
and the follower, who are working coopera-
tively to achieve some mutually desired dia-
log goal.
2. The leader may request information from the
follower, or may inform the follower that the
dialog has succeeded or failed to achieve the
dialog goal.
</listItem>
<footnote confidence="0.431293">
&apos;There is no generally accepted consensus as to how ini-
tiative should be defined.
</footnote>
<bodyText confidence="0.992367463414634">
3. The follower may only inform the leader of a
fact in direct response to a request for infor-
mation from the leader, or inform the leader
that it cannot fulfill a particular request.
The model assumes the leader knows sets of ques-
tions
.. .
such that if all questions in any one set are
answered successfully by the follower, the dia-
log goal will be satisfied. The sets will be re-
ferred to hereafter as rule sets. The leader’s
task is to find a rule set whose constituent
questions can all be successfully answered. The
method is to choose a sequence of questions
which will lead to its dis-
covery.
For example, in a dialog in a customer service
setting in which the leader attempts to locate the
follower’s account in a database, the leader might
request the follower’s name and account number,
or might request the name and telephone num-
ber. The corresponding rule sets for such a di-
alog would be and
.
One complicating factor in the leader’s task is
that a question in one rule set may occur in
several other rule sets so that choosing to ask
can have ramifications for several sets.
We assume that for every question the leader
knows an associated probability that the fol-
lower has the knowledge necessary to answer .2
These probabilities enable us to compute an ex-
pected length for a dialog, measured by the num-
ber of questions asked by the leader. Our goal in
selecting a sequence of questions will be to mini-
mize the expected length of the dialog.
The probabilities may be estimated by aggregat-
ing the results from all interactions, or a more so-
phisticated individualized model might be main-
tained for each participant. Some examples of
how these probabilities might be estimated can be
</bodyText>
<footnote confidence="0.9501825">
2In addition to modeling the follower’s knowledge, these
probabilities can also model aspects of the dialog system’s
performance, such as the recognition rate of an automatic
speech recognizer.
</footnote>
<bodyText confidence="0.996594367346939">
found in (Conati et al., 2002; Zukerman and Al-
brecht, 2001).
Our model of dialog derives from rule-based
theories of dialog structure, such as (Perrault and
Allen, 1980; Grosz and Kraus, 1996; Lochbaum,
1998). In particular, this form of the problem mod-
els exactly the “missing axiom theory” of Smith
and Hipp (1994; 1995) which proposes that di-
alog is aimed at proving the top-level goal in a
theorem-proving tree and “missing axioms” in the
proof provide motivation for interactions with the
dialog partner. The rule sets are sets of missing
axioms that are sufficient to complete the proof of
the top-level goal.
Our format is quite general and can model other
dialog systems as well. For example, a dialog sys-
tem that is organized as a decision tree with a ques-
tion at the root, with additional questions at suc-
cessor branches, can be modeled by our format.
As an example, suppose we have top-
level goal and these rules to prove it:
( AND ) implies
( OR ) implies .
The corresponding rule sets are
.
If all of the questions in either or are
satisfied, will be proven. If we have values for
the probabilities , and , we can design
an optimum ordering of the questions to minimize
the expected length of dialogs. Thus if is
much smaller than , we would ask before
asking . The reader might try to decide when
should be asked before any other questions in
order to minimize the expected length of dialogs.
The rest of the paper examines how the leader
can select the questions which minimize the over-
all expected length of the dialog, as measured by
the number of questions asked. Each question-
response pair is considered to contribute equally
to the length. Sections 3, 4, and 5 describe
polynomial-time algorithms for finding the opti-
mum order of questions in three special instances
of the question ordering optimization problem.
Section 6 gives a polynomial-time method to ap-
proximate optimum behavior in the general case of
rule sets which may have many common ques-
tions.
=
=
</bodyText>
<sectionHeader confidence="0.840573" genericHeader="method">
3 Case: One rule set
</sectionHeader>
<bodyText confidence="0.994748470588235">
Many dialog tasks can be modeled with a single
rule set . For example, a
leader might ask the follower to supply values for
each field in a form. Here the optimum strategy is
to ask the questions first that have the least proba-
bility of being successfully answered.
Theorem 1. Given a rule set ,
asking the questions in the order of their prob-
ability of success (least first) results in the min-
imum expected dialog length; that is, for
where is the probability
that the follower will answer question success-
fully.
A formal proof is available in a longer version
of this paper. Informally, we have two cases; the
first assumes that all questions are answered
successfully, leading to a dialog length of , since
questions will be asked and then answered.
The second case assumes that some will not
be answered successfully. The expected length
increases as the probabilities of success of the
questions asked increases. However, the expected
length does not depend on the probability of suc-
cess for the last question asked, since no questions
follow it regardless of the outcome. Therefore, the
question with the greatest probability of success
appears at the end of the optimal ordering. Simi-
larly, we can show that given the last question in
the ordering, the expected length does not depend
upon the probability of the second to last question
in the ordering, and so on until all questions have
been placed in the proper position. The optimal or-
dering is in order of increasing probability of suc-
cess.
</bodyText>
<sectionHeader confidence="0.969332" genericHeader="method">
4 Case: Two independent rule sets
</sectionHeader>
<bodyText confidence="0.98544658">
We now consider a dialog scenario in which the
leader has two rule sets for completing the dialog
task.
Definition 4.1. Two rule sets and are inde-
is non-empty,
then the members of are said to be com-
mon to and . A question is unique to rule
set if and for all ,
In a dialog scenario in which the leader has
multiple, mutually independent rule sets for ac-
complishing the dialog goal, the result of asking a
question contained in one rule set has no effect on
the success or failure of the other rule sets known
by the leader. Also, it can be shown that if the
leader makes optimal decisions at each turn in the
dialog, once the leader begins asking questions be-
longing to one rule set, it should continue to ask
questions from the same rule set until the rule set
either succeeds or fails. The problem of select-
ing the question that minimizes the expected dia-
log length becomes the problem of selecting
which rule set should be used first by the leader.
Once the rule set has been selected, Theorem 1
shows how to select a question from the selected
rule set that minimizes .
By expected dialog length, we mean the usual
definition of expectation
Thus, to calculate the expected length of a dialog,
we must be able to enumerate all of the possible
outcomes of that dialog, along with the probability
of that outcome occurring, and the length associ-
ated with that outcome.
Before we show how the leader should decide
which rule set it should use first, we introduce
some notation.
The expected length in case of failure for an
ordering of the questions of a
rule set is the expected length of the dialog that
would result if were the only rule set available to
the leader, the leader asked questions in the order
given by , and one of the questions in failed.
The expected length in case of failure is
The factor is a scaling factor that ac-
counts for the fact that we are counting only cases
in which the dialog fails. We will let represent
the minimum expected length in case of failure for
rule set , obtained by ordering the questions of
by increasing probability of success, as per Theo-
rem 1.
The probability of success of a rule set
</bodyText>
<listItem confidence="0.530075">
is . The definition
pendent if . If
</listItem>
<bodyText confidence="0.9797424">
of probability of success of a rule set assumes that
the probabilities of success for individual ques-
tions are mutually independent.
Theorem 2. Let be the set of mutu-
ally independent rule sets available to the leader
for accomplishing the dialog goal. For a rule set
in , let be the probability of success of ,
be the number ofquestions in , and be the min-
imum expected length in case offailure. To mini-
mize the expected length of the dialog, the leader
should select the question with the least probabil-
ity of success from the rule set with the least
value of .
Proof: If the leader uses questions from first,
the expected dialog length is
The first term, , is the probability of success
for times the length of . The second term,
, is the probability that will
and will succeed times the length of that dialog.
The third term, , is the
probability that both and fail times the asso-
ciated length. We can multiply out and rearrange
terms to get
If the leader uses questions from first, is
Comparing and , and eliminating any
common terms, we find that is the correct
ordering if
Thus, if the above inequality holds, then
, and the leader should ask questions from
first. Otherwise, , and the leader
should ask questions from first.
We conjecture that in the general case of mu-
tually independent rule sets, the proper ordering of
rule sets is obtained by calculating
for each rule set , and sorting the rule sets by
those values. Preliminary experimental evidence
supports this conjecture, but no formal proof has
been derived yet.
Note that calculating and for each rule set
takes polynomial time, as does sorting the rule sets
into their proper order and sorting the questions
within each rule set. Thus the solution can be ob-
tained in polynomial time.
As an example, consider the rule sets
and . Suppose that we
assign and
. In this case, and are
the same for both rule sets. However,
and , so evaluating for
both rule sets, we discover that asking questions
from first results in the minimum expected dia-
log length.
.
In this section, we will use to denote the
minimum expected length of the dialog (computed
using Theorem 1) resulting from the leader using
only to accomplish the dialog task. The notation
will denote the minimum expected length
of the dialog resulting from the leader using only
the rule set to accomplish the dialog task.
For example, a rule set with
and , has and
.
Theorem 3. Given rule sets
and , such that , if the leader asks
questions from until either succeeds or fails
before asking any questions unique to , then the
ordering of questions of that results in the min-
imum expected dialog length is given by ordering
the questions by increasing , where
The proof is in two parts. First we show that
the questions unique to should be ordered by
5 Case: Two rule sets, one common
question
We now examine the simplest case in which the
rule sets are not mutually independent: the leader
has two rule sets and , and
dering if immediately follows in the or-
dering. is the expected length for the or-
dering with at position . We can show that if
</bodyText>
<figure confidence="0.782994">
then
</figure>
<figureCaption confidence="0.87512875">
Figure 1: A general expression for the expected di-
alog length for the dialog scenario described in section
5. The questions of are asked in the arbitrary order
, where is the question common to
</figureCaption>
<bodyText confidence="0.991891357142857">
and . and are defined in Section 5.
increasing probability of success given that the po-
sition of is fixed. Then we show that given
the correct ordering of unique questions of ,
should appear in that ordering at the position
where falls in the correspond-
ing sequence of questions probabilities of success.
Space considerations preclude a complete listing
of the proof, but an outline follows.
Figure 1 shows an expression for the expected
dialog length for a dialog in which the leader
asks questions from until either succeeds
or fails before asking any questions unique to .
The expression assumes an arbitrary ordering
. Note that if a question
occurring before fails, the rest of the dialog has
a minimum expected length . If fails, the
dialog terminates. If a question occurring after
fails, the rest of the dialog has minimum expected
length
by a process similar to that used in the proof of
Theorem 2. Since the unique questions in are
ordered by increasing probability of success, find-
ing the optimal position of the common question
in the ordering of the questions of corre-
sponds to the problem of finding where the value
of falls in the sorted list of proba-
bilities of success of the unique questions of . If
the value immediately precedes the value of in
the list, then the common question should imme-
diately precede in the optimal ordering of ques-
tions of .
Theorem 3 provides a method for obtaining the
optimal ordering of questions in , given that
is selected first by the leader. The leader can use
the same method to determine the optimal order-
ing of the questions of if is selected first. The
two optimal orderings give rise to two different ex-
pected dialog lengths; the leader should select the
rule set and ordering that leads to the minimal ex-
pected dialog length. The calculation can be done
in polynomial time.
</bodyText>
<sectionHeader confidence="0.9310885" genericHeader="method">
6 Approximate solutions in the general
case
</sectionHeader>
<bodyText confidence="0.997332727272727">
Specific instances of the optimization problem can
be solved in polynomial time, but the general case
has worst-case complexity that is exponential in
the number of questions. To approximate the op-
timal solution, we can use some of the insights
gained from the analysis of the special cases to
generate methods for selecting a rule set, and se-
lecting a question from the chosen rule set. Theo-
rem 1 says that if there is only one rule set avail-
able, then the least probable question should be
asked first. We can also observe that if the dialog
succeeds, then in general, we would like to min-
imize the number of rule sets that must be tried
before succeeding. Combining these two observa-
tions produces a policy of selecting the question
with the minimal probability of success from the
rule set with the maximal probability of success.
.
If we fix the position of , we can show that the
questions unique to must be ordered by increas-
ing probability of success in the optimal ordering.
The proof proceeds by showing that switching the
positions of any two unique questions and in
an arbitrary ordering of the questions of , where
occurs before in the original ordering, the
expected length for the new ordering is less than
the expected length for the original ordering if and
only if .
After showing that the unique questions of
must be ordered by increasing probability of suc-
cess in the optimal ordering, we must then show
how to find the position of in the optimal or-
dering. We say that occurs at position in or-
</bodyText>
<table confidence="0.997937833333333">
Method Avg. length
Optimal 2.80
Most prob. rule set/least prob. question 3.60
Most prob. rule set/random question 4.26
Random rule set/most prob. question 4.26
Random rule set/random question 5.05
</table>
<tableCaption confidence="0.94901">
Table 1: Average expected dialog length (measured in num-
ber of leader questions) for the optimal case and several sim-
ple approximation methods over 1000 dialog scenarios. Each
scenario consisted of 6 rule sets of 2 to 5 questions each, cre-
ated from a pool of 9 different questions.
</tableCaption>
<bodyText confidence="0.999656181818182">
We tested this policy by generating 1000 dialog
scenarios. First, a pool of nine questions with ran-
domly assigned probabilities of success was gen-
erated. Six rule sets were created using these nine
questions, each containing between two and five
questions. The number of questions in each rule
set was selected randomly, with each value being
equally probable. We then calculated the expected
length of the dialog that would result if the leader
were to select questions according to the following
five schemes:
</bodyText>
<listItem confidence="0.9984012">
1. Optimal
2. Most probable rule set, least probable question
3. Random rule set, least probable question
4. Most probable rule set, random question
5. Random rule set, random question.
</listItem>
<bodyText confidence="0.976536">
The results are summarized in Table 1.
</bodyText>
<sectionHeader confidence="0.99743" genericHeader="method">
7 Further Research
</sectionHeader>
<bodyText confidence="0.999945636363636">
We intend to discover other special cases for
which polynomial time solutions exist, and inves-
tigate other methods for approximating the opti-
mal solution. With a larger library of studied spe-
cial cases, even if polynomial time solutions do
not exist for such cases, heuristics designed for use
in special cases may provide better performance.
Another extension to this research is to extend
the information model maintained by the leader to
allow the probabilities returned by the model to be
non-independent.
</bodyText>
<sectionHeader confidence="0.999483" genericHeader="conclusions">
8 Conclusions
</sectionHeader>
<bodyText confidence="0.999926">
Optimizing the behavior of dialog participants can
be a complex task even in restricted and special-
ized environments. For the case of non-mixed ini-
tiative dialogs, selecting dialog actions that mini-
mize the overall expected dialog length is a non-
trivial problem, but one which has some solutions
in certain instances. A study of the characteristics
of the problem can yield insights that lead to the
development of methods that allow a dialog par-
ticipant to perform in a principled way in the face
of intractable complexity.
</bodyText>
<sectionHeader confidence="0.998279" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.998019">
This work was supported by a grant from SAIC,
and from the US Defense Advanced Research
Projects Agency.
</bodyText>
<sectionHeader confidence="0.999387" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99896296969697">
Robin Cohen, Coralee Allaby, Christian Cumbaa,
Mark Fitzgerald, Kinson Ho, Bowen Hui, Celine
Latulipe, Fletcher Lu, Nancy Moussa, David Poo-
ley, Alex Qian, and Saheem Siddiqi. 1998. What is
initiative? User Modeling and User-Adapted Inter-
action, 8(3-4):171–214.
C. Conati, A. Gerntner, and K. Vanlehn. 2002. Us-
ing bayesian networks to manage uncertainty in user
modeling. User Modeling and User-Adapted Inter-
action, 12(4):371–417.
Barbara Grosz and Sarit Kraus. 1996. Collaborative
plans for complex group action. Artificial Intelli-
gence, 86(2):269–357.
Curry I. Guinn. 1999. An analysis of initiative
selection in collaborative task-oriented discourse.
User Modeling and User-adapted Interaction, 8(3-
4):255–314.
K. Lochbaum. 1998. A collaborative planning model
of intentional structure. Computational Linguistics,
24(4):525–572.
C. R. Perrault and J. F. Allen. 1980. A plan-based
analysis of indirect speech acts. Computational Lin-
guistics, 6(3-4):167–182.
Ronnie. W. Smith and D. Richard Hipp. 1994. Spo-
ken Natural Language Dialog Systems: A Practical
Approach. Oxford UP, New York.
Ronnie W. Smith and D. Richard Hipp. 1995. An ar-
chitecture for voice dialog systems based on prolog-
style theorem proving. Computational Linguistics,
21(3):281–320.
I. Zukerman and D. Albrecht. 2001. Predictive statis-
tical models for user modeling. User Modeling and
User-Adapted Interaction, 11(1-2):5–18.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.752939">
<title confidence="0.999994">Minimizing the Length of Non-Mixed Initiative Dialogs</title>
<author confidence="0.998948">R Bryce Inouye</author>
<affiliation confidence="0.999913">Department of Computer Science Duke University</affiliation>
<address confidence="0.813734">Durham, NC 27708</address>
<email confidence="0.999791">rbi@cs.duke.edu</email>
<abstract confidence="0.995152590909091">Dialog participants in a non-mixed initiative dialogs, in which one participant asks questions exclusively and the other participant responds to those questions exclusively, can select actions that minimize the expected length of the dialog. The choice of question that minimizes the expected number of questions to be asked can be computed in polynomial time in some cases. The polynomial-time solutions to special cases of the problem suggest a number of strategies for selecting dialog actions in the intractable general case. In a simulation involving 1000 dialog scenarios, an approximate solution using the most probable rule set/least probable question resulted in expected dialog length of 3.60 questions per dialog, as compared to 2.80 for the optimal case, and 5.05 for a randomly chosen strategy.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Robin Cohen</author>
<author>Coralee Allaby</author>
<author>Christian Cumbaa</author>
<author>Mark Fitzgerald</author>
</authors>
<title>What is initiative? User Modeling and User-Adapted Interaction,</title>
<date>1998</date>
<pages>8--3</pages>
<location>Kinson Ho, Bowen Hui, Celine Latulipe, Fletcher Lu, Nancy Moussa, David</location>
<contexts>
<context position="1959" citStr="Cohen et al. (1998)" startWordPosition="302" endWordPosition="305">imal dialog action may be intractable even in a simple, highly constrained model of dialog with narrowly defined measures of success. This paper presents an analysis of the optimal behavior of a participant in non-mixed initiative dialogs, a restricted but important class of dialogs. 2 Non-mixed initiative dialogs In recent years, dialog researchers have focused much attention on the study of mixed-initiative behaviors in natural language dialogs. In general, mixed initiative refers to the idea that control over the content and direction of a dialog may pass from one participant to another. 1 Cohen et al. (1998) provides a good overview of the various definitions of dialog initiative that have been proposed. Our work adopts a definition similar to Guinn (1999), who posits that initiative attaches to specific dialog goals. This paper considers non-mixed-initiative dialogs, which we shall take to mean dialogs with the following characteristics: 1. The dialog has two participants, the leader and the follower, who are working cooperatively to achieve some mutually desired dialog goal. 2. The leader may request information from the follower, or may inform the follower that the dialog has succeeded or fail</context>
</contexts>
<marker>Cohen, Allaby, Cumbaa, Fitzgerald, 1998</marker>
<rawString>Robin Cohen, Coralee Allaby, Christian Cumbaa, Mark Fitzgerald, Kinson Ho, Bowen Hui, Celine Latulipe, Fletcher Lu, Nancy Moussa, David Pooley, Alex Qian, and Saheem Siddiqi. 1998. What is initiative? User Modeling and User-Adapted Interaction, 8(3-4):171–214.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Conati</author>
<author>A Gerntner</author>
<author>K Vanlehn</author>
</authors>
<title>Using bayesian networks to manage uncertainty in user modeling. User Modeling and User-Adapted Interaction,</title>
<date>2002</date>
<contexts>
<context position="4589" citStr="Conati et al., 2002" startWordPosition="755" endWordPosition="758">easured by the number of questions asked by the leader. Our goal in selecting a sequence of questions will be to minimize the expected length of the dialog. The probabilities may be estimated by aggregating the results from all interactions, or a more sophisticated individualized model might be maintained for each participant. Some examples of how these probabilities might be estimated can be 2In addition to modeling the follower’s knowledge, these probabilities can also model aspects of the dialog system’s performance, such as the recognition rate of an automatic speech recognizer. found in (Conati et al., 2002; Zukerman and Albrecht, 2001). Our model of dialog derives from rule-based theories of dialog structure, such as (Perrault and Allen, 1980; Grosz and Kraus, 1996; Lochbaum, 1998). In particular, this form of the problem models exactly the “missing axiom theory” of Smith and Hipp (1994; 1995) which proposes that dialog is aimed at proving the top-level goal in a theorem-proving tree and “missing axioms” in the proof provide motivation for interactions with the dialog partner. The rule sets are sets of missing axioms that are sufficient to complete the proof of the top-level goal. Our format is</context>
</contexts>
<marker>Conati, Gerntner, Vanlehn, 2002</marker>
<rawString>C. Conati, A. Gerntner, and K. Vanlehn. 2002. Using bayesian networks to manage uncertainty in user modeling. User Modeling and User-Adapted Interaction, 12(4):371–417.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara Grosz</author>
<author>Sarit Kraus</author>
</authors>
<title>Collaborative plans for complex group action.</title>
<date>1996</date>
<journal>Artificial Intelligence,</journal>
<volume>86</volume>
<issue>2</issue>
<contexts>
<context position="4751" citStr="Grosz and Kraus, 1996" startWordPosition="781" endWordPosition="784"> probabilities may be estimated by aggregating the results from all interactions, or a more sophisticated individualized model might be maintained for each participant. Some examples of how these probabilities might be estimated can be 2In addition to modeling the follower’s knowledge, these probabilities can also model aspects of the dialog system’s performance, such as the recognition rate of an automatic speech recognizer. found in (Conati et al., 2002; Zukerman and Albrecht, 2001). Our model of dialog derives from rule-based theories of dialog structure, such as (Perrault and Allen, 1980; Grosz and Kraus, 1996; Lochbaum, 1998). In particular, this form of the problem models exactly the “missing axiom theory” of Smith and Hipp (1994; 1995) which proposes that dialog is aimed at proving the top-level goal in a theorem-proving tree and “missing axioms” in the proof provide motivation for interactions with the dialog partner. The rule sets are sets of missing axioms that are sufficient to complete the proof of the top-level goal. Our format is quite general and can model other dialog systems as well. For example, a dialog system that is organized as a decision tree with a question at the root, with add</context>
</contexts>
<marker>Grosz, Kraus, 1996</marker>
<rawString>Barbara Grosz and Sarit Kraus. 1996. Collaborative plans for complex group action. Artificial Intelligence, 86(2):269–357.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Curry I Guinn</author>
</authors>
<title>An analysis of initiative selection in collaborative task-oriented discourse. User Modeling and User-adapted Interaction,</title>
<date>1999</date>
<pages>8--3</pages>
<contexts>
<context position="2110" citStr="Guinn (1999)" startWordPosition="329" endWordPosition="330">nalysis of the optimal behavior of a participant in non-mixed initiative dialogs, a restricted but important class of dialogs. 2 Non-mixed initiative dialogs In recent years, dialog researchers have focused much attention on the study of mixed-initiative behaviors in natural language dialogs. In general, mixed initiative refers to the idea that control over the content and direction of a dialog may pass from one participant to another. 1 Cohen et al. (1998) provides a good overview of the various definitions of dialog initiative that have been proposed. Our work adopts a definition similar to Guinn (1999), who posits that initiative attaches to specific dialog goals. This paper considers non-mixed-initiative dialogs, which we shall take to mean dialogs with the following characteristics: 1. The dialog has two participants, the leader and the follower, who are working cooperatively to achieve some mutually desired dialog goal. 2. The leader may request information from the follower, or may inform the follower that the dialog has succeeded or failed to achieve the dialog goal. &apos;There is no generally accepted consensus as to how initiative should be defined. 3. The follower may only inform the le</context>
</contexts>
<marker>Guinn, 1999</marker>
<rawString>Curry I. Guinn. 1999. An analysis of initiative selection in collaborative task-oriented discourse. User Modeling and User-adapted Interaction, 8(3-4):255–314.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Lochbaum</author>
</authors>
<title>A collaborative planning model of intentional structure.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<volume>24</volume>
<issue>4</issue>
<contexts>
<context position="4768" citStr="Lochbaum, 1998" startWordPosition="785" endWordPosition="786">stimated by aggregating the results from all interactions, or a more sophisticated individualized model might be maintained for each participant. Some examples of how these probabilities might be estimated can be 2In addition to modeling the follower’s knowledge, these probabilities can also model aspects of the dialog system’s performance, such as the recognition rate of an automatic speech recognizer. found in (Conati et al., 2002; Zukerman and Albrecht, 2001). Our model of dialog derives from rule-based theories of dialog structure, such as (Perrault and Allen, 1980; Grosz and Kraus, 1996; Lochbaum, 1998). In particular, this form of the problem models exactly the “missing axiom theory” of Smith and Hipp (1994; 1995) which proposes that dialog is aimed at proving the top-level goal in a theorem-proving tree and “missing axioms” in the proof provide motivation for interactions with the dialog partner. The rule sets are sets of missing axioms that are sufficient to complete the proof of the top-level goal. Our format is quite general and can model other dialog systems as well. For example, a dialog system that is organized as a decision tree with a question at the root, with additional questions</context>
</contexts>
<marker>Lochbaum, 1998</marker>
<rawString>K. Lochbaum. 1998. A collaborative planning model of intentional structure. Computational Linguistics, 24(4):525–572.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C R Perrault</author>
<author>J F Allen</author>
</authors>
<title>A plan-based analysis of indirect speech acts.</title>
<date>1980</date>
<journal>Computational Linguistics,</journal>
<pages>6--3</pages>
<contexts>
<context position="4728" citStr="Perrault and Allen, 1980" startWordPosition="777" endWordPosition="780"> length of the dialog. The probabilities may be estimated by aggregating the results from all interactions, or a more sophisticated individualized model might be maintained for each participant. Some examples of how these probabilities might be estimated can be 2In addition to modeling the follower’s knowledge, these probabilities can also model aspects of the dialog system’s performance, such as the recognition rate of an automatic speech recognizer. found in (Conati et al., 2002; Zukerman and Albrecht, 2001). Our model of dialog derives from rule-based theories of dialog structure, such as (Perrault and Allen, 1980; Grosz and Kraus, 1996; Lochbaum, 1998). In particular, this form of the problem models exactly the “missing axiom theory” of Smith and Hipp (1994; 1995) which proposes that dialog is aimed at proving the top-level goal in a theorem-proving tree and “missing axioms” in the proof provide motivation for interactions with the dialog partner. The rule sets are sets of missing axioms that are sufficient to complete the proof of the top-level goal. Our format is quite general and can model other dialog systems as well. For example, a dialog system that is organized as a decision tree with a questio</context>
</contexts>
<marker>Perrault, Allen, 1980</marker>
<rawString>C. R. Perrault and J. F. Allen. 1980. A plan-based analysis of indirect speech acts. Computational Linguistics, 6(3-4):167–182.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Smith</author>
<author>D Richard Hipp</author>
</authors>
<title>Spoken Natural Language Dialog Systems: A Practical Approach.</title>
<date>1994</date>
<location>Oxford UP, New York.</location>
<contexts>
<context position="4875" citStr="Smith and Hipp (1994" startWordPosition="802" endWordPosition="805">l might be maintained for each participant. Some examples of how these probabilities might be estimated can be 2In addition to modeling the follower’s knowledge, these probabilities can also model aspects of the dialog system’s performance, such as the recognition rate of an automatic speech recognizer. found in (Conati et al., 2002; Zukerman and Albrecht, 2001). Our model of dialog derives from rule-based theories of dialog structure, such as (Perrault and Allen, 1980; Grosz and Kraus, 1996; Lochbaum, 1998). In particular, this form of the problem models exactly the “missing axiom theory” of Smith and Hipp (1994; 1995) which proposes that dialog is aimed at proving the top-level goal in a theorem-proving tree and “missing axioms” in the proof provide motivation for interactions with the dialog partner. The rule sets are sets of missing axioms that are sufficient to complete the proof of the top-level goal. Our format is quite general and can model other dialog systems as well. For example, a dialog system that is organized as a decision tree with a question at the root, with additional questions at successor branches, can be modeled by our format. As an example, suppose we have toplevel goal and thes</context>
</contexts>
<marker>Smith, Hipp, 1994</marker>
<rawString>Ronnie. W. Smith and D. Richard Hipp. 1994. Spoken Natural Language Dialog Systems: A Practical Approach. Oxford UP, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronnie W Smith</author>
<author>D Richard Hipp</author>
</authors>
<title>An architecture for voice dialog systems based on prologstyle theorem proving.</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<volume>21</volume>
<issue>3</issue>
<marker>Smith, Hipp, 1995</marker>
<rawString>Ronnie W. Smith and D. Richard Hipp. 1995. An architecture for voice dialog systems based on prologstyle theorem proving. Computational Linguistics, 21(3):281–320.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Zukerman</author>
<author>D Albrecht</author>
</authors>
<title>Predictive statistical models for user modeling. User Modeling and User-Adapted Interaction,</title>
<date>2001</date>
<pages>11--1</pages>
<contexts>
<context position="4619" citStr="Zukerman and Albrecht, 2001" startWordPosition="759" endWordPosition="763"> of questions asked by the leader. Our goal in selecting a sequence of questions will be to minimize the expected length of the dialog. The probabilities may be estimated by aggregating the results from all interactions, or a more sophisticated individualized model might be maintained for each participant. Some examples of how these probabilities might be estimated can be 2In addition to modeling the follower’s knowledge, these probabilities can also model aspects of the dialog system’s performance, such as the recognition rate of an automatic speech recognizer. found in (Conati et al., 2002; Zukerman and Albrecht, 2001). Our model of dialog derives from rule-based theories of dialog structure, such as (Perrault and Allen, 1980; Grosz and Kraus, 1996; Lochbaum, 1998). In particular, this form of the problem models exactly the “missing axiom theory” of Smith and Hipp (1994; 1995) which proposes that dialog is aimed at proving the top-level goal in a theorem-proving tree and “missing axioms” in the proof provide motivation for interactions with the dialog partner. The rule sets are sets of missing axioms that are sufficient to complete the proof of the top-level goal. Our format is quite general and can model o</context>
</contexts>
<marker>Zukerman, Albrecht, 2001</marker>
<rawString>I. Zukerman and D. Albrecht. 2001. Predictive statistical models for user modeling. User Modeling and User-Adapted Interaction, 11(1-2):5–18.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>