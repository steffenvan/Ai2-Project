<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000226">
<title confidence="0.994354">
UNITOR-CORE TYPED: Combining Text Similarity
and Semantic Filters through SV Regression
</title>
<author confidence="0.998913">
Danilo Croce, Valerio Storch and Roberto Basili
</author>
<affiliation confidence="0.9973815">
Department of Enterprise Engineering
University of Roma, Tor Vergata
</affiliation>
<address confidence="0.646303">
00133 Roma, Italy
</address>
<email confidence="0.997537">
{croce,storch,basili}@info.uniroma2.it
</email>
<sectionHeader confidence="0.993837" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998019647058823">
This paper presents the UNITOR system that
participated in the *SEM 2013 shared task on
Semantic Textual Similarity (STS). The task is
modeled as a Support Vector (SV) regression
problem, where a similarity scoring function
between text pairs is acquired from examples.
The proposed approach has been implemented
in a system that aims at providing high ap-
plicability and robustness, in order to reduce
the risk of over-fitting over a specific datasets.
Moreover, the approach does not require any
manually coded resource (e.g. WordNet), but
mainly exploits distributional analysis of un-
labeled corpora. A good level of accuracy is
achieved over the shared task: in the Typed
STS task the proposed system ranks in 1st and
2nd position.
</bodyText>
<sectionHeader confidence="0.998963" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998417733333333">
Semantic Textual Similarity (STS) measures the de-
gree of semantic equivalence between two phrases
or texts. An effective method to compute similarity
between sentences or semi-structured material has
many applications in Natural Language Processing
(Mihalcea et al., 2006) and related areas such as
Information Retrieval, improving the effectiveness
of semantic search engines (Sahami and Heilman,
2006), or databases, using text similarity in schema
matching to solve semantic heterogeneity (Islam and
Inkpen, 2008).
This paper describes the UNITOR system partic-
ipating in both tasks of the *SEM 2013 shared task
on Semantic Textual Similarity (STS), described in
(Agirre et al., 2013):
</bodyText>
<listItem confidence="0.8319735">
• the Core STS tasks: given two sentences, s1
and s2, participants are asked to provide a score
</listItem>
<bodyText confidence="0.963994083333333">
reflecting the corresponding text similarity. It is
the same task proposed in (Agirre et al., 2012).
• the Typed-similarity STS task: given two
semi-structured records t1 and t2, containing
several typed fields with textual values, partic-
ipants are asked to provide multiple similarity
scores: the types of similarity to be studied in-
clude location, author, people involved, time,
events or actions, subject and description.
In line with several participants of the STS 2012
challenge, such as (Banea et al., 2012; Croce et al.,
2012a; ˇSari´c et al., 2012), STS is here modeled as
a Support Vector (SV) regression problem, where a
SV regressor learns the similarity function over text
pairs. The semantic relatedness between two sen-
tences is first modeled in an unsupervised fashion
by several similarity functions, each describing the
analogy between the two texts according to a spe-
cific semantic perspective. We aim at capturing sep-
arately syntactic and lexical equivalences between
sentences and exploiting either topical relatedness or
paradigmatic similarity between individual words.
Such information is then combined in a supervised
schema through a scoring function y = f(x) over
individual measures from labeled data through SV
regression: y is the gold similarity score (provided
by human annotators), while x is the vector of the
different individual scores, provided by the chosen
similarity functions.
For the Typed STS task, given the specificity of
the involved information and the heterogeneity of
target scores, individual measures are not applied to
entire texts. Specific phrases are filtered according
to linguistic policies, e.g. words characterized by
specific Part-of-Speech (POS), such as nouns and
verbs, or Named Entity (NE) Category, i.e. men-
</bodyText>
<page confidence="0.983578">
59
</page>
<subsubsectionHeader confidence="0.253824">
Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 1: Proceedings of the Main Conference
</subsubsectionHeader>
<bodyText confidence="0.9769328">
and the Shared Task, pages 59–65, Atlanta, Georgia, June 13-14, 2013. c�2013 Association for Computational Linguistics
tions to specific name classes, such as of a PER-
SON, LOCATION or DATE. The former allows to
focus the similarity functions over entities (nouns)
or actions (verbs), while the latter allows to focus on
some aspects connected with the targeted similarity
functions, such as person involved, location or time.
The proposed approach has been implemented in
a system that aims at providing high applicability
and robustness. This objective is pursued by adopt-
ing four similarity measures designed to avoid the
risk of over-fitting over each specific dataset. More-
over, the approach does not require any manually
coded resource (e.g. WordNet), but mainly exploits
distributional analysis of unlabeled corpora. Despite
of its simplicity, a good level of accuracy is achieved
over the 2013 STS challenge: in the Typed STS task
the proposed system ranks 1st and 2nd position (out
of 18); in the Core STS task, it ranks around the 37th
position (out of 90) and a simple refinement to our
model makes it 19th.
In the rest of the paper, in Section 2, the employed
similarity functions are described and the applica-
tion of SV regression is presented. Finally, Section
3 discusses results on the *SEM 2013 shared task.
</bodyText>
<sectionHeader confidence="0.876788" genericHeader="method">
2 Similarity functions, regression and
</sectionHeader>
<subsectionHeader confidence="0.53469">
linguistic filtering
</subsectionHeader>
<bodyText confidence="0.9999306">
This section describes the approach behind the UN-
ITOR system. The basic similarity functions and
their combination via SV regressor are discussed in
Section 2.1, while the linguistic filters are presented
in Section 2.2.
</bodyText>
<subsectionHeader confidence="0.979942">
2.1 STS functions
</subsectionHeader>
<bodyText confidence="0.9979034">
Each STS function depends on a variety of linguistic
aspects in data, e.g. syntactic or lexical information.
While their supervised combination can be derived
through SV regression, different unsupervised esti-
mators of STS exist.
Lexical Overlap. A basic similarity function is
modeled as the Lexical Overlap (LO) between sen-
tences. Given the sets Wa and Wb of words oc-
curring in two generic texts ta and tb, LO is esti-
mated as the Jaccard Similarity between the sets, i.e.
</bodyText>
<equation confidence="0.673123">
LO=|WanWb |WaUWb |In order to reduce data sparseness,
m
|
</equation>
<bodyText confidence="0.987481">
lematization is applied and each word is enriched
with its POS to avoid the confusion between words
from different grammatical classes.
</bodyText>
<subsectionHeader confidence="0.679747">
Compositional Distributional Semantics. Other
</subsectionHeader>
<bodyText confidence="0.99997015">
similarity functions are obtained by accounting for
the syntactic composition of the lexical information
involved in the sentences. Basic lexical information
is obtained by a co-occurrence Word Space that is
built according to (Sahlgren, 2006; Croce and Pre-
vitali, 2010). Every word appearing in a sentence is
then projected in such space. A sentence can be thus
represented neglecting its syntactic structure, by ap-
plying an additive linear combination, i.e. the so-
called SUM operator. The similarity function be-
tween two sentences is then the cosine similarity be-
tween their corresponding vectors.
A second function is obtained by applying a Dis-
tributional Compositional Semantics operator, in
line with the approaches introduced in (Mitchell and
Lapata, 2010), and it is adopted to account for se-
mantic composition. In particular, the approach de-
scribed in (Croce et al., 2012c) has been applied.
It is based on space projection operations over ba-
sic geometric lexical representations: syntactic bi-
grams are projected in the so called Support Sub-
space (Annesi et al., 2012), aimed at emphasiz-
ing the semantic features shared by the compound
words. The aim is to model semantics of syntac-
tic bi-grams as projections in lexically-driven sub-
spaces. In order to extend this approach to handle
entire sentences, we need to convert them in syn-
tactic representations compatible with the compo-
sitional operators proposed. A dependency gram-
mar based formalism captures binary syntactic re-
lations between the words, expressed as nodes in
a dependency graph. Given a sentence, the parse
structure is acquired and different triples (w1, w2, r)
are generated, where w1 is the relation governor, w2
is the dependent and r is the grammatical type. In
(Croce et al., 2012c) a simple approach is defined,
and it is inspired by the notion of Soft Cardinal-
ity, (Jimenez et al., 2012). Given a triple set T =
�t1, . . . ,tn} extracted from a sentence S and a sim-
ilarity sim(ti,tj), the Soft Cardinality is estimated
</bodyText>
<equation confidence="0.955136">
t� (�|T |
</equation>
<bodyText confidence="0.9064192">
as |S|� sim = �|T  |t� sim(ti, tj)p)−1, where pa-
rameter p controls the “softness” of the cardinality:
with p = 1 element similarities are unchanged while
higher value will tend to the Classical Cardinality
measure. Notice that differently from the previous
</bodyText>
<page confidence="0.991162">
60
</page>
<bodyText confidence="0.9990554375">
usage of the Soft Cardinality notion, we did not ap-
ply it to sets of individual words, but to the sets of
dependencies (i.e. triples) derived from the two sen-
tences. The sim function here can be thus replaced
by any compositional operator among the ones dis-
cussed in (Annesi et al., 2012). Given two sen-
tences, higher Soft Cardinality values mean that the
elements in both sentences (i.e. triples) are different,
while the lower values mean that common triples are
identical or very similar, suggesting that sentences
contain the same kind of information. Given the sets
of triples A and B extracted from the two candidate
sentences, our approach estimates a syntactically re-
stricted soft cardinality operator, the Syntactic Soft
Cardinality (SSC) as SSC(A, B — A|I+|B&apos;I, as
a “soft approximation” of Dice’s ) coefficient
</bodyText>
<equation confidence="0.42789">
calcu-
latedon both sets1.
capture::v
marine::n ROOT VBN
mexico::n PREP-BY NNS
NN
</equation>
<page confidence="0.815293">
61
</page>
<table confidence="0.627433777777778">
dcTitle dcSubject dcDescription dcCreator dcDate dcSource
author - - PER � - -
people inv. PER PER PER - - -
time DATE DATE DATE - � -
location LOC LOC LOC - - -
event N,V,NUV N,V,NUV N,V,NUV - - -
subject N,V,J,NUJUV N,V,J,NUJUV - - - -
description - - N, V , J, N U J U V - - -
general + + + � � �
</table>
<tableCaption confidence="0.99754">
Table 1: Filtering Schema adopted for the Typed STS task.
</tableCaption>
<bodyText confidence="0.999799941176471">
Notice how some kernels loose significance in the
typed STS task. Syntactic information is no useful
so that no tree kernel and compositional kernel is
applied here. Most of the fields are non-sentential2.
Moreover, not all morpho-syntactic information are
extracted as feature from some fields. Filters usu-
ally specify some syntactic categories or Named En-
tities (NEs): they are textual mentions to specific
real-world categories, such as of PERSONS (PER),
LOCATIONS (LOC) or DATES. They are detected
in a field and made available as feature to the cor-
responding kernel: this introduces a bias on typed
measures and emphasizes specific semantic aspects
(e.g. places LOC or persons PER, in location or au-
thor measures, respectively). For example, in the
sentence “The chemist R.S. Hudson began manufac-
turing soap in the back of his small shop in West
Bomich in 1837”, when POS tag filters are applied,
only verbs (V), nouns (N) or adjectives (J) can be
selected as features. This allows to focus on spe-
cific actions, e.g. the verb “manufacture”, entities,
e.g. nouns “soap” and “shop”, or some properties,
e.g. the adjective “small”. When Named Entity cat-
egories are used, a mention to a person like “R.S.
Hudson” or to a location, e.g. “West Bomich’, or
date, e.g. “1837”, can be useful to model the the
person involved, the location or time similarity mea-
sures, respectively.
The Semantic Modeling and the Learning Con-
straints system adopted to model the Typed STS
task are defined in Table 1. There rows are the
different target similarities, while columns indicate
document fields, such as dcTitle, dcSubject,
dcDescription, dcCreator, dcDate and
</bodyText>
<footnote confidence="0.729076666666667">
2The dcDescription is also made of multiple sen-
tences and it reduces the applicability of SPTK and SSC: parse
trees have no clear alignment.
</footnote>
<bodyText confidence="0.999912793103448">
dcSource, as described in the *SEM 2013 shared
task description. Each entry in the Table represents
the feature set for that fields, i.e. POS tags (i.e. V ,
N, J) or Named Entity classes. The “*” symbol
corresponds to all features, i.e. no restriction is
applied to any POS tag or NE class. Finally, the
general similarity function makes use of every NE
class and POS tags adopted for that field in any
measure, as expressed by the special notation +, i.e.
“all of the above features”.
Every feature set denoted in the Table 1 sup-
ports the application of a lexical kernel, such as
the LO described in Section 2.1. When different
POS tags are requested (such as N and V ) mul-
tiple feature sets and kernels are made available.
The “-” symbol means that the source field is fully
neglected from the SV regression. As an exam-
ple, the SV regressor for the location similarity
has been acquired considering the fields dcTitle,
dcSubject, dcDescription. Only features used
for the kernel correspond to LOCATIONs (LOC). For
each of the three feature, the LO and SUM simi-
larity function has been applied, giving rise to an
input 6-dimensional feature space for the regressor.
Differently, in the subject similarity, nouns, adjec-
tives and verbs are the only features adopted from
the fields dcSubject, dcTitle, so that 8 feature
sets are used to model these fields, giving rise to a
16-dimensional feature space.
</bodyText>
<sectionHeader confidence="0.999642" genericHeader="evaluation">
3 Results and discussion
</sectionHeader>
<bodyText confidence="0.9997334">
This section describes results obtained in the *SEM
2013 shared task. The experimental setup of differ-
ent similarity functions is described in Section 3.1.
Results obtained over the Core STS task and Typed
STS task are described in Section 3.2 and 3.3.
</bodyText>
<page confidence="0.997982">
62
</page>
<subsectionHeader confidence="0.983457">
3.1 Experimental setup
</subsectionHeader>
<bodyText confidence="0.941869941176471">
In all experiments, sentences are processed with the
Stanford CoreNLP3 system, for Part-of-Speech tag-
ging, lemmatization, named entity recognition4 and
dependency parsing.
In order to estimate the basic lexical similarity
function employed in the SUM, SSC and SPTK
operators, a co-occurrence Word Space is acquired
through the distributional analysis of the UkWaC
corpus (Baroni et al., 2009), a Web document col-
lection made of about 2 billion tokens. The same
setting of (Croce et al., 2012a) has been adopted
for the space acquisition. The same setup described
in (Croce et al., 2012c) is applied to estimate the
SSC function. The similarity between pairs of syn-
tactically restricted word compound is evaluated
through a Symmetric model: it selects the best 200
dimensions of the space, selected by maximizing the
component-wise product of each compound as in
(Annesi et al., 2012), and combines the similarity
scores measured in each couple subspace with the
product function. The similarity score in each sub-
space is obtained by summing the cosine similarity
of the corresponding projected words. The “soft car-
dinality” is estimated with the parameter p = 2.
The estimation of the semantically Smoothed Par-
tial Tree Kernel (SPTK) is made available by an ex-
tended version of SVM-LightTK software5 (Mos-
chitti, 2006) implementing the smooth matching
between tree nodes. Similarity between lexical
nodes is estimated as the cosine similarity in the
co-occurrence Word Space described above, as in
(Croce et al., 2011). Finally, SVM-LightTK is em-
ployed for the SV regression learning to combine
specific similarity functions.
</bodyText>
<subsectionHeader confidence="0.994088">
3.2 Results over the Core STS
</subsectionHeader>
<bodyText confidence="0.999603833333333">
In the Core STS task, the resulting text similarity
score is measured by the regressor: each sentence
pair from all datasets is modeled according to a 13
dimensional feature space derived from the different
functions introduced in Section 2.1, as follows.
The first 5 dimensions are derived by applying
</bodyText>
<footnote confidence="0.9940458">
3http://nlp.stanford.edu/software/corenlp.shtml
4The TIME and DURATION classes are collapsed with
DATE, while the PERSON and LOCATION classes are consid-
ered without any modification.
5http://disi.unitn.it/moschitti/Tree-Kernel.htm
</footnote>
<table confidence="0.999625333333333">
Runl Rune Runs Run*,
headlines .635 (50) .651 (39) .603 (58) .671 (30)
OnWN .574 (33) .561 (36) .549 (40) .637 (25)
FNWN .352 (35) .358 (32) .327 (44) .459 (7)
SMT .328 (39) .310 (49) .319 (44) .348 (21)
Mean .494 (37) .490 (42) .472 (52) .537 (19)
</table>
<tableCaption confidence="0.999779">
Table 2: Results over the Core STS task
</tableCaption>
<bodyText confidence="0.999954025641025">
the LO operator over lemmatized words in the noun,
verb, adjective and adverb POS categories: 4 ker-
nels look at individual categories, while a fifth ker-
nel insists on the union of all POS. A second set of
5 dimensions is derived by the same application of
the SUM operator to the same syntactic selection of
features. The SPTK is then applied to estimate the
similarity between the LCT structures derived from
the dependency parse trees of sentences. Then, the
SPTK is applied to derive an additional score with-
out considering any specific similarity function be-
tween lexical nodes; in this setting, the SPTK can be
considered as a traditional Partial Tree Kernel (Mos-
chitti, 2006), in order to capture a more strict syn-
tactical similarity between texts. The last score is
generated by applying the SSC operator.
We participated in the *SEM challenge with three
different runs. The main difference between each
run is the dataset employed in the training phase
and the employed kernel within the regressor. With-
out any specific information about the test datasets,
a strategy to prevent the regressor to over-fit train-
ing material has been applied. We decided to use
a training dataset that achieved the best results over
datasets radically different from the training material
in the STS challenge of Semeval 2012. In particular,
for the FNWN and OnWN datasets, we arbitrarily
selected the training material achieving best results
over the 2012 surprise.OnWN; for the headlines and
SMT datasets we maximized performance training
over surprise.SMTnews. In Run1 the SVM regres-
sor is trained using dataset combinations providing
best results according to the above criteria: MSR-
par, MSRvid, SMTeuroparl and surprise.OnWN are
employed against FNWN and OnWN; MSRpar,
SMTeuroparl and surprise.SMTnews are employed
against headline and SMT. A linear kernel is ap-
plied when training the regressor. In Run2, differ-
ently from the previous one, the SVM regressor is
</bodyText>
<page confidence="0.997949">
63
</page>
<table confidence="0.982968">
rank general author people inv. time location event subject description mean
Run, 1 .7981 .8158 .6922 .7471 .7723 .6835 .7875 .7996 .7620
Rune 2 .7564 .8076 .6758 .7090 .7351 .6623 .7520 .7745 .7341
</table>
<tableCaption confidence="0.999926">
Table 3: Results over the Typed STS task
</tableCaption>
<bodyText confidence="0.99988246875">
trained using all examples from the training datasets.
A linear kernel is applied when training the regres-
sor. Finally, in Run3 the same training dataset selec-
tion schema of Run, is applied and a gaussian kernel
is employed in the regressor.
Table 2 reports the general outcome for the UN-
ITOR systems in term of Pearson Correlation. The
best system, based on the linear kernel, ranks around
the 35th position (out of 90 systems), that reflects
the mean rank of all the systems in the ranking of
the different datasets. The gaussian kernel, em-
ployed for the Run3 does not provide any contri-
bution, as it ranks 50th. We think that the main
reason of these results is due to the intrinsic dif-
ferences between training and testing datasets that
have been heuristically coupled. This is first mo-
tivated by lower rank achieved by Rune. More-
over, it is in line with the experimental findings of
(Croce et al., 2012a), where a performance drop is
shown when the regressor is trained over data that
is not constrained over the corresponding source.
In Run* we thus optimized the system by manu-
ally selecting the training material that does provides
best performance on the test dataset: MSRvid, SM-
Teuroparl and surprise.OnWN are employed against
OnWN; surprise.OnWN against FNWN, SMTeu-
roparl against headlines; SMTeuroparl and sur-
prise.SMTnews against SMT. A linear kernel within
the regressor allow to reach the 19th position, even
reducing the complexity of the representation to a
five dimensional feature space: LO and SUM with-
out any specific filter, SPTK, PTK and SSC.
</bodyText>
<subsectionHeader confidence="0.996258">
3.3 Results over the Typed STS
</subsectionHeader>
<bodyText confidence="0.98829106122449">
SV regression has been also applied to the Typed
STS task through seven type-specific regressors plus
a general one. Each SV regressor insists on the LO
and SUM kernel as applied to the features in Table
1. Notice that it was mainly due to the lack of rich
syntactic structures in almost all fields.
As described in Section 2.2, a specific modeling
strategy has been applied to derive the feature space
of each target similarity. For example, the regres-
sor associated with the event similarity score is fed
with 18 scores. Each of the 3 fields, , i.e. dcTitle,
dcSubject and dcDescription, provides the 2
kernels (LO and SUM) with 3 feature sets (i.e. N,
V and N U V ). In particular, the general simi-
larity function considers all extracted features for
each field, giving rise to a space of 51 dimensions.
We participated in the task with two different runs,
whose main difference is the adopted kernel within
the SV regressor. In Run1, a linear kernel is used,
while in Run2 a RBF kernel is applied.
Table 3 reports the general outcome for the UN-
ITOR system. The adopted semantic modeling, as
well as the selection of the proper information, e.g.
the proper named entity, allows the system to rank
in the 1st and 2nd positions (out of 18 systems). The
proposed selection schema in Table 1 is very effec-
tive, as confirmed by the results for almost all typed
similarity scores. Again, the RBF kernel does not
improve result over the linear kernel. The impact
of the proposed approach can be noticed for very
specific scores, such as time and location, especially
for text pairs where structured information is absent,
such as in the dcDate field. Moreover, the regres-
sor is not affected by the differences between train-
ing and test dataset as for the previous Core STS
task. A deep result analysis showed that some simi-
larity scores are not correctly estimated within pairs
showing partial similarities. For example, the events
or actions typed similarity is overestimated for the
texts pairs “The Octagon and Pavilions, Pavilion
Garden, Buxton, c 1875” and “The Beatles, The Oc-
tagon, Pavillion Gardens, St John’s Road, Buxton,
1963” because they mention the same location (i.e.
“Pavillion Gardens”).
Acknowledgements This work has been partially
supported by the Regione Lazio under the project
PROGRESS-IT (FILAS-CR-2011-1089) and the
Italian Ministry of Industry within the “Industria
2015” Framework, project DIVINO (MI01 00234).
</bodyText>
<page confidence="0.999148">
64
</page>
<sectionHeader confidence="0.989625" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999579586206897">
Eneko Agirre, Daniel Cer, Mona Diab, and Aitor
Gonzalez-Agirre. 2012. Semeval-2012 task 6: A pilot
on semantic textual similarity. In *SEM 2012, pages
385–393, Montr´eal, Canada, 7-8 June.
Eneko Agirre, Daniel Cer, Mona Diab, Aitor Gonzalez-
Agirre, and Weiwei Guo. 2013. *sem 2013 shared
task: Semantic textual similarity, including a pilot on
typed-similarity. In *SEM 2013: The Second Joint
Conference on Lexical and Computational Semantics.
Association for Computational Linguistics.
Paolo Annesi, Valerio Storch, and Roberto Basili. 2012.
Space projections as distributional models for seman-
tic composition. In CICLing (1), Lecture Notes in
Computer Science, pages 323–335. Springer.
Carmen Banea, Samer Hassan, Michael Mohler, and
Rada Mihalcea. 2012. Unt: A supervised synergistic
approach to semantic text similarity. In *SEM 2012,
pages 635–642, Montr´eal, Canada, 7-8 June. Associa-
tion for Computational Linguistics.
Marco Baroni, Silvia Bernardini, Adriano Ferraresi, and
Eros Zanchetta. 2009. The wacky wide web: a
collection of very large linguistically processed web-
crawled corpora. Language Resources and Evalua-
tion, 43(3):209–226.
Danilo Croce and Daniele Previtali. 2010. Manifold
learning for the semi-supervised induction of framenet
predicates: An empirical investigation. In Proceed-
ings of the GEMS 2010 Workshop, pages 7–16, Upp-
sala, Sweden.
Danilo Croce, Alessandro Moschitti, and Roberto Basili.
2011. Structured lexical similarity via convolution
kernels on dependency trees. In Proceedings of
EMNLP, Edinburgh, Scotland, UK.
Danilo Croce, Paolo Annesi, Valerio Storch, and Roberto
Basili. 2012a. Unitor: Combining semantic text simi-
larity functions through sv regression. In *SEM 2012,
pages 597–602, Montr´eal, Canada, 7-8 June.
Danilo Croce, Alessandro Moschitti, Roberto Basili, and
Martha Palmer. 2012b. Verb classification using dis-
tributional similarity in syntactic and semantic struc-
tures. In Proceedings of the 50th Annual Meeting
of the Association for Computational Linguistics (Vol-
ume 1: Long Papers), pages 263–272, Jeju Island, Ko-
rea, July.
Danilo Croce, Valerio Storch, Paolo Annesi, and Roberto
Basili. 2012c. Distributional compositional seman-
tics and text similarity. 2012 IEEE Sixth International
Conference on Semantic Computing, 0:242–249.
David Haussler. 1999. Convolution kernels on discrete
structures. Technical report, University of Santa Cruz.
Aminul Islam and Diana Inkpen. 2008. Semantic
text similarity using corpus-based word similarity and
string similarity. ACM Trans. Knowl. Discov. Data,
2:10:1–10:25, July.
Sergio Jimenez, Claudia Becerra, and Alexander Gel-
bukh. 2012. Soft cardinality: A parameterized sim-
ilarity function for text comparison. In *SEM 2012,
pages 449–453, Montr´eal, Canada, 7-8 June. Associa-
tion for Computational Linguistics.
Rada Mihalcea, Courtney Corley, and Carlo Strapparava.
2006. Corpus-based and knowledge-based measures
of text semantic similarity. In In AAAI06.
Jeff Mitchell and Mirella Lapata. 2010. Composition in
distributional models of semantics. Cognitive Science,
34(8):1388–1429.
Alessandro Moschitti. 2006. Efficient convolution ker-
nels for dependency and constituent syntactic trees. In
ECML, pages 318–329, Berlin, Germany, September.
Machine Learning: ECML 2006, 17th European Con-
ference on Machine Learning, Proceedings.
Mehran Sahami and Timothy D. Heilman. 2006. A web-
based kernel function for measuring the similarity of
short text snippets. In Proceedings of the 15th inter-
national conference on World Wide Web, WWW ’06,
pages 377–386, New York, NY, USA. ACM.
Magnus Sahlgren. 2006. The Word-Space Model. Ph.D.
thesis, Stockholm University.
John Shawe-Taylor and Nello Cristianini. 2004. Kernel
Methods for Pattern Analysis. Cambridge University
Press, New York, NY, USA.
Alex J. Smola and Bernhard Sch¨olkopf. 2004. A tutorial
on support vector regression. Statistics and Comput-
ing, 14(3):199–222, August.
Frane ˇSari´c, Goran Glavaˇs, Mladen Karan, Jan ˇSnajder,
and Bojana Dalbelo Baˇsi´c. 2012. Takelab: Systems
for measuring semantic text similarity. In *SEM 2012,
pages 441–448, Montr´eal, Canada, 7-8 June.
</reference>
<page confidence="0.999611">
65
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.666030">
<title confidence="0.99615">UNITOR-CORE TYPED: Combining Text and Semantic Filters through SV Regression</title>
<author confidence="0.996289">Danilo Croce</author>
<author confidence="0.996289">Valerio Storch</author>
<author confidence="0.996289">Roberto</author>
<affiliation confidence="0.9171965">Department of Enterprise University of Roma, Tor</affiliation>
<address confidence="0.999875">00133 Roma, Italy</address>
<abstract confidence="0.984345555555556">This paper presents the UNITOR system that participated in the *SEM 2013 shared task on Semantic Textual Similarity (STS). The task is modeled as a Support Vector (SV) regression problem, where a similarity scoring function between text pairs is acquired from examples. The proposed approach has been implemented in a system that aims at providing high applicability and robustness, in order to reduce the risk of over-fitting over a specific datasets. Moreover, the approach does not require any manually coded resource (e.g. WordNet), but mainly exploits distributional analysis of unlabeled corpora. A good level of accuracy is achieved over the shared task: in the Typed STS task the proposed system ranks in 1st and 2nd position.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eneko Agirre</author>
<author>Daniel Cer</author>
<author>Mona Diab</author>
<author>Aitor Gonzalez-Agirre</author>
</authors>
<title>Semeval-2012 task 6: A pilot on semantic textual similarity.</title>
<date>2012</date>
<booktitle>In *SEM 2012,</booktitle>
<pages>385--393</pages>
<location>Montr´eal,</location>
<contexts>
<context position="1904" citStr="Agirre et al., 2012" startWordPosition="282" endWordPosition="285">l., 2006) and related areas such as Information Retrieval, improving the effectiveness of semantic search engines (Sahami and Heilman, 2006), or databases, using text similarity in schema matching to solve semantic heterogeneity (Islam and Inkpen, 2008). This paper describes the UNITOR system participating in both tasks of the *SEM 2013 shared task on Semantic Textual Similarity (STS), described in (Agirre et al., 2013): • the Core STS tasks: given two sentences, s1 and s2, participants are asked to provide a score reflecting the corresponding text similarity. It is the same task proposed in (Agirre et al., 2012). • the Typed-similarity STS task: given two semi-structured records t1 and t2, containing several typed fields with textual values, participants are asked to provide multiple similarity scores: the types of similarity to be studied include location, author, people involved, time, events or actions, subject and description. In line with several participants of the STS 2012 challenge, such as (Banea et al., 2012; Croce et al., 2012a; ˇSari´c et al., 2012), STS is here modeled as a Support Vector (SV) regression problem, where a SV regressor learns the similarity function over text pairs. The se</context>
</contexts>
<marker>Agirre, Cer, Diab, Gonzalez-Agirre, 2012</marker>
<rawString>Eneko Agirre, Daniel Cer, Mona Diab, and Aitor Gonzalez-Agirre. 2012. Semeval-2012 task 6: A pilot on semantic textual similarity. In *SEM 2012, pages 385–393, Montr´eal, Canada, 7-8 June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eneko Agirre</author>
<author>Daniel Cer</author>
<author>Mona Diab</author>
<author>Aitor GonzalezAgirre</author>
<author>Weiwei Guo</author>
</authors>
<title>sem 2013 shared task: Semantic textual similarity, including a pilot on typed-similarity.</title>
<date>2013</date>
<booktitle>In *SEM 2013: The Second Joint Conference on Lexical and Computational Semantics. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="1707" citStr="Agirre et al., 2013" startWordPosition="248" endWordPosition="251">equivalence between two phrases or texts. An effective method to compute similarity between sentences or semi-structured material has many applications in Natural Language Processing (Mihalcea et al., 2006) and related areas such as Information Retrieval, improving the effectiveness of semantic search engines (Sahami and Heilman, 2006), or databases, using text similarity in schema matching to solve semantic heterogeneity (Islam and Inkpen, 2008). This paper describes the UNITOR system participating in both tasks of the *SEM 2013 shared task on Semantic Textual Similarity (STS), described in (Agirre et al., 2013): • the Core STS tasks: given two sentences, s1 and s2, participants are asked to provide a score reflecting the corresponding text similarity. It is the same task proposed in (Agirre et al., 2012). • the Typed-similarity STS task: given two semi-structured records t1 and t2, containing several typed fields with textual values, participants are asked to provide multiple similarity scores: the types of similarity to be studied include location, author, people involved, time, events or actions, subject and description. In line with several participants of the STS 2012 challenge, such as (Banea e</context>
</contexts>
<marker>Agirre, Cer, Diab, GonzalezAgirre, Guo, 2013</marker>
<rawString>Eneko Agirre, Daniel Cer, Mona Diab, Aitor GonzalezAgirre, and Weiwei Guo. 2013. *sem 2013 shared task: Semantic textual similarity, including a pilot on typed-similarity. In *SEM 2013: The Second Joint Conference on Lexical and Computational Semantics. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paolo Annesi</author>
<author>Valerio Storch</author>
<author>Roberto Basili</author>
</authors>
<title>Space projections as distributional models for semantic composition.</title>
<date>2012</date>
<booktitle>In CICLing (1), Lecture Notes in Computer Science,</booktitle>
<pages>323--335</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="7108" citStr="Annesi et al., 2012" startWordPosition="1096" endWordPosition="1099">.e. the socalled SUM operator. The similarity function between two sentences is then the cosine similarity between their corresponding vectors. A second function is obtained by applying a Distributional Compositional Semantics operator, in line with the approaches introduced in (Mitchell and Lapata, 2010), and it is adopted to account for semantic composition. In particular, the approach described in (Croce et al., 2012c) has been applied. It is based on space projection operations over basic geometric lexical representations: syntactic bigrams are projected in the so called Support Subspace (Annesi et al., 2012), aimed at emphasizing the semantic features shared by the compound words. The aim is to model semantics of syntactic bi-grams as projections in lexically-driven subspaces. In order to extend this approach to handle entire sentences, we need to convert them in syntactic representations compatible with the compositional operators proposed. A dependency grammar based formalism captures binary syntactic relations between the words, expressed as nodes in a dependency graph. Given a sentence, the parse structure is acquired and different triples (w1, w2, r) are generated, where w1 is the relation g</context>
<context position="8588" citStr="Annesi et al., 2012" startWordPosition="1353" endWordPosition="1356">and a similarity sim(ti,tj), the Soft Cardinality is estimated t� (�|T | as |S|� sim = �|T |t� sim(ti, tj)p)−1, where parameter p controls the “softness” of the cardinality: with p = 1 element similarities are unchanged while higher value will tend to the Classical Cardinality measure. Notice that differently from the previous 60 usage of the Soft Cardinality notion, we did not apply it to sets of individual words, but to the sets of dependencies (i.e. triples) derived from the two sentences. The sim function here can be thus replaced by any compositional operator among the ones discussed in (Annesi et al., 2012). Given two sentences, higher Soft Cardinality values mean that the elements in both sentences (i.e. triples) are different, while the lower values mean that common triples are identical or very similar, suggesting that sentences contain the same kind of information. Given the sets of triples A and B extracted from the two candidate sentences, our approach estimates a syntactically restricted soft cardinality operator, the Syntactic Soft Cardinality (SSC) as SSC(A, B — A|I+|B&apos;I, as a “soft approximation” of Dice’s ) coefficient calculatedon both sets1. capture::v marine::n ROOT VBN mexico::n P</context>
<context position="13945" citStr="Annesi et al., 2012" startWordPosition="2253" endWordPosition="2256">K operators, a co-occurrence Word Space is acquired through the distributional analysis of the UkWaC corpus (Baroni et al., 2009), a Web document collection made of about 2 billion tokens. The same setting of (Croce et al., 2012a) has been adopted for the space acquisition. The same setup described in (Croce et al., 2012c) is applied to estimate the SSC function. The similarity between pairs of syntactically restricted word compound is evaluated through a Symmetric model: it selects the best 200 dimensions of the space, selected by maximizing the component-wise product of each compound as in (Annesi et al., 2012), and combines the similarity scores measured in each couple subspace with the product function. The similarity score in each subspace is obtained by summing the cosine similarity of the corresponding projected words. The “soft cardinality” is estimated with the parameter p = 2. The estimation of the semantically Smoothed Partial Tree Kernel (SPTK) is made available by an extended version of SVM-LightTK software5 (Moschitti, 2006) implementing the smooth matching between tree nodes. Similarity between lexical nodes is estimated as the cosine similarity in the co-occurrence Word Space described</context>
</contexts>
<marker>Annesi, Storch, Basili, 2012</marker>
<rawString>Paolo Annesi, Valerio Storch, and Roberto Basili. 2012. Space projections as distributional models for semantic composition. In CICLing (1), Lecture Notes in Computer Science, pages 323–335. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carmen Banea</author>
<author>Samer Hassan</author>
<author>Michael Mohler</author>
<author>Rada Mihalcea</author>
</authors>
<title>Unt: A supervised synergistic approach to semantic text similarity.</title>
<date>2012</date>
<booktitle>In *SEM 2012,</booktitle>
<pages>635--642</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Montr´eal,</location>
<contexts>
<context position="2318" citStr="Banea et al., 2012" startWordPosition="346" endWordPosition="349">, 2013): • the Core STS tasks: given two sentences, s1 and s2, participants are asked to provide a score reflecting the corresponding text similarity. It is the same task proposed in (Agirre et al., 2012). • the Typed-similarity STS task: given two semi-structured records t1 and t2, containing several typed fields with textual values, participants are asked to provide multiple similarity scores: the types of similarity to be studied include location, author, people involved, time, events or actions, subject and description. In line with several participants of the STS 2012 challenge, such as (Banea et al., 2012; Croce et al., 2012a; ˇSari´c et al., 2012), STS is here modeled as a Support Vector (SV) regression problem, where a SV regressor learns the similarity function over text pairs. The semantic relatedness between two sentences is first modeled in an unsupervised fashion by several similarity functions, each describing the analogy between the two texts according to a specific semantic perspective. We aim at capturing separately syntactic and lexical equivalences between sentences and exploiting either topical relatedness or paradigmatic similarity between individual words. Such information is t</context>
</contexts>
<marker>Banea, Hassan, Mohler, Mihalcea, 2012</marker>
<rawString>Carmen Banea, Samer Hassan, Michael Mohler, and Rada Mihalcea. 2012. Unt: A supervised synergistic approach to semantic text similarity. In *SEM 2012, pages 635–642, Montr´eal, Canada, 7-8 June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Baroni</author>
<author>Silvia Bernardini</author>
<author>Adriano Ferraresi</author>
<author>Eros Zanchetta</author>
</authors>
<title>The wacky wide web: a collection of very large linguistically processed webcrawled corpora. Language Resources and Evaluation,</title>
<date>2009</date>
<pages>43--3</pages>
<contexts>
<context position="13454" citStr="Baroni et al., 2009" startWordPosition="2171" endWordPosition="2174"> 2013 shared task. The experimental setup of different similarity functions is described in Section 3.1. Results obtained over the Core STS task and Typed STS task are described in Section 3.2 and 3.3. 62 3.1 Experimental setup In all experiments, sentences are processed with the Stanford CoreNLP3 system, for Part-of-Speech tagging, lemmatization, named entity recognition4 and dependency parsing. In order to estimate the basic lexical similarity function employed in the SUM, SSC and SPTK operators, a co-occurrence Word Space is acquired through the distributional analysis of the UkWaC corpus (Baroni et al., 2009), a Web document collection made of about 2 billion tokens. The same setting of (Croce et al., 2012a) has been adopted for the space acquisition. The same setup described in (Croce et al., 2012c) is applied to estimate the SSC function. The similarity between pairs of syntactically restricted word compound is evaluated through a Symmetric model: it selects the best 200 dimensions of the space, selected by maximizing the component-wise product of each compound as in (Annesi et al., 2012), and combines the similarity scores measured in each couple subspace with the product function. The similari</context>
</contexts>
<marker>Baroni, Bernardini, Ferraresi, Zanchetta, 2009</marker>
<rawString>Marco Baroni, Silvia Bernardini, Adriano Ferraresi, and Eros Zanchetta. 2009. The wacky wide web: a collection of very large linguistically processed webcrawled corpora. Language Resources and Evaluation, 43(3):209–226.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Danilo Croce</author>
<author>Daniele Previtali</author>
</authors>
<title>Manifold learning for the semi-supervised induction of framenet predicates: An empirical investigation.</title>
<date>2010</date>
<booktitle>In Proceedings of the GEMS 2010 Workshop,</booktitle>
<pages>7--16</pages>
<location>Uppsala,</location>
<contexts>
<context position="6302" citStr="Croce and Previtali, 2010" startWordPosition="966" endWordPosition="970">of words occurring in two generic texts ta and tb, LO is estimated as the Jaccard Similarity between the sets, i.e. LO=|WanWb |WaUWb |In order to reduce data sparseness, m | lematization is applied and each word is enriched with its POS to avoid the confusion between words from different grammatical classes. Compositional Distributional Semantics. Other similarity functions are obtained by accounting for the syntactic composition of the lexical information involved in the sentences. Basic lexical information is obtained by a co-occurrence Word Space that is built according to (Sahlgren, 2006; Croce and Previtali, 2010). Every word appearing in a sentence is then projected in such space. A sentence can be thus represented neglecting its syntactic structure, by applying an additive linear combination, i.e. the socalled SUM operator. The similarity function between two sentences is then the cosine similarity between their corresponding vectors. A second function is obtained by applying a Distributional Compositional Semantics operator, in line with the approaches introduced in (Mitchell and Lapata, 2010), and it is adopted to account for semantic composition. In particular, the approach described in (Croce et </context>
</contexts>
<marker>Croce, Previtali, 2010</marker>
<rawString>Danilo Croce and Daniele Previtali. 2010. Manifold learning for the semi-supervised induction of framenet predicates: An empirical investigation. In Proceedings of the GEMS 2010 Workshop, pages 7–16, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Danilo Croce</author>
<author>Alessandro Moschitti</author>
<author>Roberto Basili</author>
</authors>
<title>Structured lexical similarity via convolution kernels on dependency trees.</title>
<date>2011</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<location>Edinburgh, Scotland, UK.</location>
<contexts>
<context position="14579" citStr="Croce et al., 2011" startWordPosition="2353" endWordPosition="2356">the similarity scores measured in each couple subspace with the product function. The similarity score in each subspace is obtained by summing the cosine similarity of the corresponding projected words. The “soft cardinality” is estimated with the parameter p = 2. The estimation of the semantically Smoothed Partial Tree Kernel (SPTK) is made available by an extended version of SVM-LightTK software5 (Moschitti, 2006) implementing the smooth matching between tree nodes. Similarity between lexical nodes is estimated as the cosine similarity in the co-occurrence Word Space described above, as in (Croce et al., 2011). Finally, SVM-LightTK is employed for the SV regression learning to combine specific similarity functions. 3.2 Results over the Core STS In the Core STS task, the resulting text similarity score is measured by the regressor: each sentence pair from all datasets is modeled according to a 13 dimensional feature space derived from the different functions introduced in Section 2.1, as follows. The first 5 dimensions are derived by applying 3http://nlp.stanford.edu/software/corenlp.shtml 4The TIME and DURATION classes are collapsed with DATE, while the PERSON and LOCATION classes are considered wi</context>
</contexts>
<marker>Croce, Moschitti, Basili, 2011</marker>
<rawString>Danilo Croce, Alessandro Moschitti, and Roberto Basili. 2011. Structured lexical similarity via convolution kernels on dependency trees. In Proceedings of EMNLP, Edinburgh, Scotland, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Danilo Croce</author>
<author>Paolo Annesi</author>
<author>Valerio Storch</author>
<author>Roberto Basili</author>
</authors>
<title>Unitor: Combining semantic text similarity functions through sv regression.</title>
<date>2012</date>
<booktitle>In *SEM 2012,</booktitle>
<pages>597--602</pages>
<location>Montr´eal,</location>
<contexts>
<context position="2338" citStr="Croce et al., 2012" startWordPosition="350" endWordPosition="353">STS tasks: given two sentences, s1 and s2, participants are asked to provide a score reflecting the corresponding text similarity. It is the same task proposed in (Agirre et al., 2012). • the Typed-similarity STS task: given two semi-structured records t1 and t2, containing several typed fields with textual values, participants are asked to provide multiple similarity scores: the types of similarity to be studied include location, author, people involved, time, events or actions, subject and description. In line with several participants of the STS 2012 challenge, such as (Banea et al., 2012; Croce et al., 2012a; ˇSari´c et al., 2012), STS is here modeled as a Support Vector (SV) regression problem, where a SV regressor learns the similarity function over text pairs. The semantic relatedness between two sentences is first modeled in an unsupervised fashion by several similarity functions, each describing the analogy between the two texts according to a specific semantic perspective. We aim at capturing separately syntactic and lexical equivalences between sentences and exploiting either topical relatedness or paradigmatic similarity between individual words. Such information is then combined in a su</context>
<context position="6911" citStr="Croce et al., 2012" startWordPosition="1064" endWordPosition="1067">li, 2010). Every word appearing in a sentence is then projected in such space. A sentence can be thus represented neglecting its syntactic structure, by applying an additive linear combination, i.e. the socalled SUM operator. The similarity function between two sentences is then the cosine similarity between their corresponding vectors. A second function is obtained by applying a Distributional Compositional Semantics operator, in line with the approaches introduced in (Mitchell and Lapata, 2010), and it is adopted to account for semantic composition. In particular, the approach described in (Croce et al., 2012c) has been applied. It is based on space projection operations over basic geometric lexical representations: syntactic bigrams are projected in the so called Support Subspace (Annesi et al., 2012), aimed at emphasizing the semantic features shared by the compound words. The aim is to model semantics of syntactic bi-grams as projections in lexically-driven subspaces. In order to extend this approach to handle entire sentences, we need to convert them in syntactic representations compatible with the compositional operators proposed. A dependency grammar based formalism captures binary syntactic</context>
<context position="13553" citStr="Croce et al., 2012" startWordPosition="2190" endWordPosition="2193">.1. Results obtained over the Core STS task and Typed STS task are described in Section 3.2 and 3.3. 62 3.1 Experimental setup In all experiments, sentences are processed with the Stanford CoreNLP3 system, for Part-of-Speech tagging, lemmatization, named entity recognition4 and dependency parsing. In order to estimate the basic lexical similarity function employed in the SUM, SSC and SPTK operators, a co-occurrence Word Space is acquired through the distributional analysis of the UkWaC corpus (Baroni et al., 2009), a Web document collection made of about 2 billion tokens. The same setting of (Croce et al., 2012a) has been adopted for the space acquisition. The same setup described in (Croce et al., 2012c) is applied to estimate the SSC function. The similarity between pairs of syntactically restricted word compound is evaluated through a Symmetric model: it selects the best 200 dimensions of the space, selected by maximizing the component-wise product of each compound as in (Annesi et al., 2012), and combines the similarity scores measured in each couple subspace with the product function. The similarity score in each subspace is obtained by summing the cosine similarity of the corresponding project</context>
<context position="18646" citStr="Croce et al., 2012" startWordPosition="3020" endWordPosition="3023">TOR systems in term of Pearson Correlation. The best system, based on the linear kernel, ranks around the 35th position (out of 90 systems), that reflects the mean rank of all the systems in the ranking of the different datasets. The gaussian kernel, employed for the Run3 does not provide any contribution, as it ranks 50th. We think that the main reason of these results is due to the intrinsic differences between training and testing datasets that have been heuristically coupled. This is first motivated by lower rank achieved by Rune. Moreover, it is in line with the experimental findings of (Croce et al., 2012a), where a performance drop is shown when the regressor is trained over data that is not constrained over the corresponding source. In Run* we thus optimized the system by manually selecting the training material that does provides best performance on the test dataset: MSRvid, SMTeuroparl and surprise.OnWN are employed against OnWN; surprise.OnWN against FNWN, SMTeuroparl against headlines; SMTeuroparl and surprise.SMTnews against SMT. A linear kernel within the regressor allow to reach the 19th position, even reducing the complexity of the representation to a five dimensional feature space: </context>
</contexts>
<marker>Croce, Annesi, Storch, Basili, 2012</marker>
<rawString>Danilo Croce, Paolo Annesi, Valerio Storch, and Roberto Basili. 2012a. Unitor: Combining semantic text similarity functions through sv regression. In *SEM 2012, pages 597–602, Montr´eal, Canada, 7-8 June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Danilo Croce</author>
<author>Alessandro Moschitti</author>
<author>Roberto Basili</author>
<author>Martha Palmer</author>
</authors>
<title>Verb classification using distributional similarity in syntactic and semantic structures.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),</booktitle>
<pages>263--272</pages>
<location>Jeju Island, Korea,</location>
<contexts>
<context position="2338" citStr="Croce et al., 2012" startWordPosition="350" endWordPosition="353">STS tasks: given two sentences, s1 and s2, participants are asked to provide a score reflecting the corresponding text similarity. It is the same task proposed in (Agirre et al., 2012). • the Typed-similarity STS task: given two semi-structured records t1 and t2, containing several typed fields with textual values, participants are asked to provide multiple similarity scores: the types of similarity to be studied include location, author, people involved, time, events or actions, subject and description. In line with several participants of the STS 2012 challenge, such as (Banea et al., 2012; Croce et al., 2012a; ˇSari´c et al., 2012), STS is here modeled as a Support Vector (SV) regression problem, where a SV regressor learns the similarity function over text pairs. The semantic relatedness between two sentences is first modeled in an unsupervised fashion by several similarity functions, each describing the analogy between the two texts according to a specific semantic perspective. We aim at capturing separately syntactic and lexical equivalences between sentences and exploiting either topical relatedness or paradigmatic similarity between individual words. Such information is then combined in a su</context>
<context position="6911" citStr="Croce et al., 2012" startWordPosition="1064" endWordPosition="1067">li, 2010). Every word appearing in a sentence is then projected in such space. A sentence can be thus represented neglecting its syntactic structure, by applying an additive linear combination, i.e. the socalled SUM operator. The similarity function between two sentences is then the cosine similarity between their corresponding vectors. A second function is obtained by applying a Distributional Compositional Semantics operator, in line with the approaches introduced in (Mitchell and Lapata, 2010), and it is adopted to account for semantic composition. In particular, the approach described in (Croce et al., 2012c) has been applied. It is based on space projection operations over basic geometric lexical representations: syntactic bigrams are projected in the so called Support Subspace (Annesi et al., 2012), aimed at emphasizing the semantic features shared by the compound words. The aim is to model semantics of syntactic bi-grams as projections in lexically-driven subspaces. In order to extend this approach to handle entire sentences, we need to convert them in syntactic representations compatible with the compositional operators proposed. A dependency grammar based formalism captures binary syntactic</context>
<context position="13553" citStr="Croce et al., 2012" startWordPosition="2190" endWordPosition="2193">.1. Results obtained over the Core STS task and Typed STS task are described in Section 3.2 and 3.3. 62 3.1 Experimental setup In all experiments, sentences are processed with the Stanford CoreNLP3 system, for Part-of-Speech tagging, lemmatization, named entity recognition4 and dependency parsing. In order to estimate the basic lexical similarity function employed in the SUM, SSC and SPTK operators, a co-occurrence Word Space is acquired through the distributional analysis of the UkWaC corpus (Baroni et al., 2009), a Web document collection made of about 2 billion tokens. The same setting of (Croce et al., 2012a) has been adopted for the space acquisition. The same setup described in (Croce et al., 2012c) is applied to estimate the SSC function. The similarity between pairs of syntactically restricted word compound is evaluated through a Symmetric model: it selects the best 200 dimensions of the space, selected by maximizing the component-wise product of each compound as in (Annesi et al., 2012), and combines the similarity scores measured in each couple subspace with the product function. The similarity score in each subspace is obtained by summing the cosine similarity of the corresponding project</context>
<context position="18646" citStr="Croce et al., 2012" startWordPosition="3020" endWordPosition="3023">TOR systems in term of Pearson Correlation. The best system, based on the linear kernel, ranks around the 35th position (out of 90 systems), that reflects the mean rank of all the systems in the ranking of the different datasets. The gaussian kernel, employed for the Run3 does not provide any contribution, as it ranks 50th. We think that the main reason of these results is due to the intrinsic differences between training and testing datasets that have been heuristically coupled. This is first motivated by lower rank achieved by Rune. Moreover, it is in line with the experimental findings of (Croce et al., 2012a), where a performance drop is shown when the regressor is trained over data that is not constrained over the corresponding source. In Run* we thus optimized the system by manually selecting the training material that does provides best performance on the test dataset: MSRvid, SMTeuroparl and surprise.OnWN are employed against OnWN; surprise.OnWN against FNWN, SMTeuroparl against headlines; SMTeuroparl and surprise.SMTnews against SMT. A linear kernel within the regressor allow to reach the 19th position, even reducing the complexity of the representation to a five dimensional feature space: </context>
</contexts>
<marker>Croce, Moschitti, Basili, Palmer, 2012</marker>
<rawString>Danilo Croce, Alessandro Moschitti, Roberto Basili, and Martha Palmer. 2012b. Verb classification using distributional similarity in syntactic and semantic structures. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 263–272, Jeju Island, Korea, July.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Danilo Croce</author>
<author>Valerio Storch</author>
<author>Paolo Annesi</author>
<author>Roberto Basili</author>
</authors>
<booktitle>2012c. Distributional compositional semantics and text similarity. 2012 IEEE Sixth International Conference on Semantic Computing,</booktitle>
<pages>0--242</pages>
<marker>Croce, Storch, Annesi, Basili, </marker>
<rawString>Danilo Croce, Valerio Storch, Paolo Annesi, and Roberto Basili. 2012c. Distributional compositional semantics and text similarity. 2012 IEEE Sixth International Conference on Semantic Computing, 0:242–249.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Haussler</author>
</authors>
<title>Convolution kernels on discrete structures.</title>
<date>1999</date>
<tech>Technical report,</tech>
<institution>University of Santa Cruz.</institution>
<marker>Haussler, 1999</marker>
<rawString>David Haussler. 1999. Convolution kernels on discrete structures. Technical report, University of Santa Cruz.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aminul Islam</author>
<author>Diana Inkpen</author>
</authors>
<title>Semantic text similarity using corpus-based word similarity and string similarity.</title>
<date>2008</date>
<journal>ACM Trans. Knowl. Discov. Data,</journal>
<pages>2--10</pages>
<contexts>
<context position="1537" citStr="Islam and Inkpen, 2008" startWordPosition="220" endWordPosition="223">r the shared task: in the Typed STS task the proposed system ranks in 1st and 2nd position. 1 Introduction Semantic Textual Similarity (STS) measures the degree of semantic equivalence between two phrases or texts. An effective method to compute similarity between sentences or semi-structured material has many applications in Natural Language Processing (Mihalcea et al., 2006) and related areas such as Information Retrieval, improving the effectiveness of semantic search engines (Sahami and Heilman, 2006), or databases, using text similarity in schema matching to solve semantic heterogeneity (Islam and Inkpen, 2008). This paper describes the UNITOR system participating in both tasks of the *SEM 2013 shared task on Semantic Textual Similarity (STS), described in (Agirre et al., 2013): • the Core STS tasks: given two sentences, s1 and s2, participants are asked to provide a score reflecting the corresponding text similarity. It is the same task proposed in (Agirre et al., 2012). • the Typed-similarity STS task: given two semi-structured records t1 and t2, containing several typed fields with textual values, participants are asked to provide multiple similarity scores: the types of similarity to be studied </context>
</contexts>
<marker>Islam, Inkpen, 2008</marker>
<rawString>Aminul Islam and Diana Inkpen. 2008. Semantic text similarity using corpus-based word similarity and string similarity. ACM Trans. Knowl. Discov. Data, 2:10:1–10:25, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sergio Jimenez</author>
<author>Claudia Becerra</author>
<author>Alexander Gelbukh</author>
</authors>
<title>Soft cardinality: A parameterized similarity function for text comparison.</title>
<date>2012</date>
<booktitle>In *SEM 2012,</booktitle>
<pages>449--453</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Montr´eal,</location>
<contexts>
<context position="7899" citStr="Jimenez et al., 2012" startWordPosition="1228" endWordPosition="1231">s. In order to extend this approach to handle entire sentences, we need to convert them in syntactic representations compatible with the compositional operators proposed. A dependency grammar based formalism captures binary syntactic relations between the words, expressed as nodes in a dependency graph. Given a sentence, the parse structure is acquired and different triples (w1, w2, r) are generated, where w1 is the relation governor, w2 is the dependent and r is the grammatical type. In (Croce et al., 2012c) a simple approach is defined, and it is inspired by the notion of Soft Cardinality, (Jimenez et al., 2012). Given a triple set T = �t1, . . . ,tn} extracted from a sentence S and a similarity sim(ti,tj), the Soft Cardinality is estimated t� (�|T | as |S|� sim = �|T |t� sim(ti, tj)p)−1, where parameter p controls the “softness” of the cardinality: with p = 1 element similarities are unchanged while higher value will tend to the Classical Cardinality measure. Notice that differently from the previous 60 usage of the Soft Cardinality notion, we did not apply it to sets of individual words, but to the sets of dependencies (i.e. triples) derived from the two sentences. The sim function here can be thus</context>
</contexts>
<marker>Jimenez, Becerra, Gelbukh, 2012</marker>
<rawString>Sergio Jimenez, Claudia Becerra, and Alexander Gelbukh. 2012. Soft cardinality: A parameterized similarity function for text comparison. In *SEM 2012, pages 449–453, Montr´eal, Canada, 7-8 June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
<author>Courtney Corley</author>
<author>Carlo Strapparava</author>
</authors>
<title>Corpus-based and knowledge-based measures of text semantic similarity. In</title>
<date>2006</date>
<booktitle>In AAAI06.</booktitle>
<contexts>
<context position="1293" citStr="Mihalcea et al., 2006" startWordPosition="186" endWordPosition="189">e the risk of over-fitting over a specific datasets. Moreover, the approach does not require any manually coded resource (e.g. WordNet), but mainly exploits distributional analysis of unlabeled corpora. A good level of accuracy is achieved over the shared task: in the Typed STS task the proposed system ranks in 1st and 2nd position. 1 Introduction Semantic Textual Similarity (STS) measures the degree of semantic equivalence between two phrases or texts. An effective method to compute similarity between sentences or semi-structured material has many applications in Natural Language Processing (Mihalcea et al., 2006) and related areas such as Information Retrieval, improving the effectiveness of semantic search engines (Sahami and Heilman, 2006), or databases, using text similarity in schema matching to solve semantic heterogeneity (Islam and Inkpen, 2008). This paper describes the UNITOR system participating in both tasks of the *SEM 2013 shared task on Semantic Textual Similarity (STS), described in (Agirre et al., 2013): • the Core STS tasks: given two sentences, s1 and s2, participants are asked to provide a score reflecting the corresponding text similarity. It is the same task proposed in (Agirre et</context>
</contexts>
<marker>Mihalcea, Corley, Strapparava, 2006</marker>
<rawString>Rada Mihalcea, Courtney Corley, and Carlo Strapparava. 2006. Corpus-based and knowledge-based measures of text semantic similarity. In In AAAI06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeff Mitchell</author>
<author>Mirella Lapata</author>
</authors>
<title>Composition in distributional models of semantics.</title>
<date>2010</date>
<journal>Cognitive Science,</journal>
<volume>34</volume>
<issue>8</issue>
<contexts>
<context position="6794" citStr="Mitchell and Lapata, 2010" startWordPosition="1043" endWordPosition="1046">c lexical information is obtained by a co-occurrence Word Space that is built according to (Sahlgren, 2006; Croce and Previtali, 2010). Every word appearing in a sentence is then projected in such space. A sentence can be thus represented neglecting its syntactic structure, by applying an additive linear combination, i.e. the socalled SUM operator. The similarity function between two sentences is then the cosine similarity between their corresponding vectors. A second function is obtained by applying a Distributional Compositional Semantics operator, in line with the approaches introduced in (Mitchell and Lapata, 2010), and it is adopted to account for semantic composition. In particular, the approach described in (Croce et al., 2012c) has been applied. It is based on space projection operations over basic geometric lexical representations: syntactic bigrams are projected in the so called Support Subspace (Annesi et al., 2012), aimed at emphasizing the semantic features shared by the compound words. The aim is to model semantics of syntactic bi-grams as projections in lexically-driven subspaces. In order to extend this approach to handle entire sentences, we need to convert them in syntactic representations</context>
</contexts>
<marker>Mitchell, Lapata, 2010</marker>
<rawString>Jeff Mitchell and Mirella Lapata. 2010. Composition in distributional models of semantics. Cognitive Science, 34(8):1388–1429.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
</authors>
<title>Efficient convolution kernels for dependency and constituent syntactic trees.</title>
<date>2006</date>
<booktitle>In ECML,</booktitle>
<pages>318--329</pages>
<location>Berlin, Germany,</location>
<contexts>
<context position="14379" citStr="Moschitti, 2006" startWordPosition="2324" endWordPosition="2326">s evaluated through a Symmetric model: it selects the best 200 dimensions of the space, selected by maximizing the component-wise product of each compound as in (Annesi et al., 2012), and combines the similarity scores measured in each couple subspace with the product function. The similarity score in each subspace is obtained by summing the cosine similarity of the corresponding projected words. The “soft cardinality” is estimated with the parameter p = 2. The estimation of the semantically Smoothed Partial Tree Kernel (SPTK) is made available by an extended version of SVM-LightTK software5 (Moschitti, 2006) implementing the smooth matching between tree nodes. Similarity between lexical nodes is estimated as the cosine similarity in the co-occurrence Word Space described above, as in (Croce et al., 2011). Finally, SVM-LightTK is employed for the SV regression learning to combine specific similarity functions. 3.2 Results over the Core STS In the Core STS task, the resulting text similarity score is measured by the regressor: each sentence pair from all datasets is modeled according to a 13 dimensional feature space derived from the different functions introduced in Section 2.1, as follows. The fi</context>
<context position="16221" citStr="Moschitti, 2006" startWordPosition="2620" endWordPosition="2622">e and adverb POS categories: 4 kernels look at individual categories, while a fifth kernel insists on the union of all POS. A second set of 5 dimensions is derived by the same application of the SUM operator to the same syntactic selection of features. The SPTK is then applied to estimate the similarity between the LCT structures derived from the dependency parse trees of sentences. Then, the SPTK is applied to derive an additional score without considering any specific similarity function between lexical nodes; in this setting, the SPTK can be considered as a traditional Partial Tree Kernel (Moschitti, 2006), in order to capture a more strict syntactical similarity between texts. The last score is generated by applying the SSC operator. We participated in the *SEM challenge with three different runs. The main difference between each run is the dataset employed in the training phase and the employed kernel within the regressor. Without any specific information about the test datasets, a strategy to prevent the regressor to over-fit training material has been applied. We decided to use a training dataset that achieved the best results over datasets radically different from the training material in </context>
</contexts>
<marker>Moschitti, 2006</marker>
<rawString>Alessandro Moschitti. 2006. Efficient convolution kernels for dependency and constituent syntactic trees. In ECML, pages 318–329, Berlin, Germany, September. Machine Learning: ECML 2006, 17th European Conference on Machine Learning, Proceedings.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mehran Sahami</author>
<author>Timothy D Heilman</author>
</authors>
<title>A webbased kernel function for measuring the similarity of short text snippets.</title>
<date>2006</date>
<booktitle>In Proceedings of the 15th international conference on World Wide Web, WWW ’06,</booktitle>
<pages>377--386</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="1424" citStr="Sahami and Heilman, 2006" startWordPosition="204" endWordPosition="207">ordNet), but mainly exploits distributional analysis of unlabeled corpora. A good level of accuracy is achieved over the shared task: in the Typed STS task the proposed system ranks in 1st and 2nd position. 1 Introduction Semantic Textual Similarity (STS) measures the degree of semantic equivalence between two phrases or texts. An effective method to compute similarity between sentences or semi-structured material has many applications in Natural Language Processing (Mihalcea et al., 2006) and related areas such as Information Retrieval, improving the effectiveness of semantic search engines (Sahami and Heilman, 2006), or databases, using text similarity in schema matching to solve semantic heterogeneity (Islam and Inkpen, 2008). This paper describes the UNITOR system participating in both tasks of the *SEM 2013 shared task on Semantic Textual Similarity (STS), described in (Agirre et al., 2013): • the Core STS tasks: given two sentences, s1 and s2, participants are asked to provide a score reflecting the corresponding text similarity. It is the same task proposed in (Agirre et al., 2012). • the Typed-similarity STS task: given two semi-structured records t1 and t2, containing several typed fields with tex</context>
</contexts>
<marker>Sahami, Heilman, 2006</marker>
<rawString>Mehran Sahami and Timothy D. Heilman. 2006. A webbased kernel function for measuring the similarity of short text snippets. In Proceedings of the 15th international conference on World Wide Web, WWW ’06, pages 377–386, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Magnus Sahlgren</author>
</authors>
<title>The Word-Space Model.</title>
<date>2006</date>
<tech>Ph.D. thesis,</tech>
<institution>Stockholm University.</institution>
<contexts>
<context position="6274" citStr="Sahlgren, 2006" startWordPosition="964" endWordPosition="965"> sets Wa and Wb of words occurring in two generic texts ta and tb, LO is estimated as the Jaccard Similarity between the sets, i.e. LO=|WanWb |WaUWb |In order to reduce data sparseness, m | lematization is applied and each word is enriched with its POS to avoid the confusion between words from different grammatical classes. Compositional Distributional Semantics. Other similarity functions are obtained by accounting for the syntactic composition of the lexical information involved in the sentences. Basic lexical information is obtained by a co-occurrence Word Space that is built according to (Sahlgren, 2006; Croce and Previtali, 2010). Every word appearing in a sentence is then projected in such space. A sentence can be thus represented neglecting its syntactic structure, by applying an additive linear combination, i.e. the socalled SUM operator. The similarity function between two sentences is then the cosine similarity between their corresponding vectors. A second function is obtained by applying a Distributional Compositional Semantics operator, in line with the approaches introduced in (Mitchell and Lapata, 2010), and it is adopted to account for semantic composition. In particular, the appr</context>
</contexts>
<marker>Sahlgren, 2006</marker>
<rawString>Magnus Sahlgren. 2006. The Word-Space Model. Ph.D. thesis, Stockholm University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Shawe-Taylor</author>
<author>Nello Cristianini</author>
</authors>
<title>Kernel Methods for Pattern Analysis.</title>
<date>2004</date>
<publisher>Cambridge University Press,</publisher>
<location>New York, NY, USA.</location>
<marker>Shawe-Taylor, Cristianini, 2004</marker>
<rawString>John Shawe-Taylor and Nello Cristianini. 2004. Kernel Methods for Pattern Analysis. Cambridge University Press, New York, NY, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alex J Smola</author>
<author>Bernhard Sch¨olkopf</author>
</authors>
<title>A tutorial on support vector regression.</title>
<date>2004</date>
<journal>Statistics and Computing,</journal>
<volume>14</volume>
<issue>3</issue>
<marker>Smola, Sch¨olkopf, 2004</marker>
<rawString>Alex J. Smola and Bernhard Sch¨olkopf. 2004. A tutorial on support vector regression. Statistics and Computing, 14(3):199–222, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frane ˇSari´c</author>
<author>Goran Glavaˇs</author>
<author>Mladen Karan</author>
</authors>
<title>Snajder, and Bojana Dalbelo Baˇsi´c.</title>
<date></date>
<booktitle>In *SEM 2012,</booktitle>
<pages>441--448</pages>
<location>Montr´eal,</location>
<marker>ˇSari´c, Glavaˇs, Karan, </marker>
<rawString>Frane ˇSari´c, Goran Glavaˇs, Mladen Karan, Jan ˇSnajder, and Bojana Dalbelo Baˇsi´c. 2012. Takelab: Systems for measuring semantic text similarity. In *SEM 2012, pages 441–448, Montr´eal, Canada, 7-8 June.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>