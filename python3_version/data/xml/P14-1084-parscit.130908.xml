<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000003">
<title confidence="0.998893">
Modelling Events through Memory-based, Open-IE Patterns
for Abstractive Summarization
</title>
<author confidence="0.997179">
Daniele Pighin Marco Cornolti∗ Enrique Alfonseca Katja Filippova
</author>
<affiliation confidence="0.997879">
Google Inc. University of Pisa, Italy Google Inc. Google Inc.
</affiliation>
<email confidence="0.987414">
biondo@google.com cornolti@di.unipi.it ealfonseca@google.com katjaf@google.com
</email>
<sectionHeader confidence="0.993606" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999460291666667">
Abstractive text summarization of news
requires a way of representing events, such
as a collection of pattern clusters in which
every cluster represents an event (e.g.,
marriage) and every pattern in the clus-
ter is a way of expressing the event (e.g.,
X married Y, X and Y tied the knot). We
compare three ways of extracting event
patterns: heuristics-based, compression-
based and memory-based. While the for-
mer has been used previously in multi-
document abstraction, the latter two have
never been used for this task. Compared
with the first two techniques, the memory-
based method allows for generating sig-
nificantly more grammatical and informa-
tive sentences, at the cost of searching a
vast space of hundreds of millions of parse
trees of known grammatical utterances. To
this end, we introduce a data structure and
a search method that make it possible to
efficiently extrapolate from every sentence
the parse sub-trees that match against any
of the stored utterances.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.961928909090909">
Text summarization beyond extraction requires a
semantic representation that abstracts away from
words and phrases and from which a summary can
be generated (Mani, 2001; Sp¨arck-Jones, 2007).
Following and extending recent work in semantic
parsing, information extraction (IE), paraphrase
generation and summarization (Titov and Klemen-
tiev, 2011; Alfonseca et al., 2013; Zhang and
Weld, 2013; Mehdad et al., 2013), the represen-
tation we consider in this paper is a large collec-
∗Work done during an internship at Google Zurich.
</bodyText>
<figureCaption confidence="0.978415666666667">
Figure 1: An example of abstracting from input
sentences to an event representation and genera-
tion from that representation.
</figureCaption>
<bodyText confidence="0.99985348">
tion of clusters of event patterns. An abstractive
summarization system relying on such a represen-
tation proceeds by (1) detecting the most relevant
event cluster for a given sentence or sentence col-
lection, and (2) using the most representative pat-
tern from the cluster to generate a concise sum-
mary sentence. Figure 1 illustrates the summa-
rization architecture we are assuming in this pa-
per. Given input text(s) with resolved and typed
entity mentions, event mentions and the most rele-
vant event cluster are detected (first arrow). Then,
a summary sentence is generated from the event
and entity representations (second arrow).
However, the utility of such a representation for
summarization depends on the quality of pattern
clusters. In particular, event patterns must cor-
respond to grammatically correct sentences. In-
troducing an incomplete or incomprehensible pat-
tern (e.g., PER said PER) may negatively affect
both event detection and sentence generation. Re-
lated work on paraphrase detection and relation
extraction is mostly heuristics-based and has re-
lied on hand-crafted rules to collect such patterns
(see Sec. 2). A standard approach is to focus
on binary relations between entities and extract
</bodyText>
<figure confidence="0.982052882352941">
#21: death
[John Smith] and
[Mary Brown] wed
in [Baltimore]...
#22: divorce
[Smith] tied the
knot with [Brown]
this Monday...
John Smith married Mary Brown
e1: J. Smith (PER)
e2: M. Brown (PER)
e3: Baltimore, MD (LOC)
#23: marriage
PER married PER
PER and PER wed
PER tied the knot with PER
PER has married PER
</figure>
<page confidence="0.972401">
892
</page>
<note confidence="0.918337">
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 892–901,
Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics
</note>
<figureCaption confidence="0.873511">
Figure 2: A generic pipeline for event-driven ab-
stractive headline generation.
</figureCaption>
<bodyText confidence="0.998109704545454">
the dependency path between the two entities as
an event representation. An obvious limitation
of this approach is there is no guarantee that the
extracted pattern corresponds to a grammatically
correct sentence, e.g., that an essential preposi-
tional phrase is retained like in file for a divorce.
In this paper we explore two novel, data-driven
methods for event pattern extraction. The first,
compression-based method uses a robust sentence
compressor with an aggressive compression rate
to get to the core of the sentence (Sec. 3). The
second, memory-based method relies on a vast
collection of human-written headlines and sen-
tences to find a substructure which is known to
be grammatically correct (Sec. 4). While the lat-
ter method comes closer to ensuring perfect gram-
maticality, it introduces a problem of efficiently
searching the vast space of known well-formed
patterns. Since standard iterative approaches com-
paring every pattern with every sentence are pro-
hibitive here, we present a search strategy which
scales well to huge collections (hundreds of mil-
lions) of sentences.
In order to evaluate the three methods, we con-
sider an abstractive summarization task where the
goal is to get the gist of single sentences by recog-
nizing the underlying event and generating a short
summary sentence. To the best of our knowledge,
this is the first time that this task has been pro-
posed; it can be considered as abstractive sentence
compression, in contrast to most existing sentence
compression systems which are based on selecting
words from the original sentence or rewriting with
simpler paraphrase tables. An extensive evalua-
tion with human raters demonstrates the utility of
the new pattern extraction techniques. Our analy-
sis highlights advantages and disadvantages of the
three methods.
To better isolate the qualities of the three ex-
traction methodologies, all three methods use the
same training data and share components of the
Algorithm 1 HEURISTICEXTRACTOR(T, E): heuristi-
cally extract relational patterns for the dependency parse T
and the set of entities E.
</bodyText>
<listItem confidence="0.9318361">
1: /* Global constants /*
2: global Vp, Vc, Np, Nc
3: Vc ← {subj, nsubj, nsubjpass, dobj, iobj, xcomp,
4: acomp, expl, neg, aux, attr, prt}
5: Vp ← {xcomp}
6: Nc ← {det, predet, num, ps, poss, nc, conj}
7: Np ← {ps, poss, subj, nsubj, nsubjpass, dobj, iobj}
8: /* Entry point/*
9: P ← ∅
10: for all C ∈ COMBINATIONS(E) do
</listItem>
<figure confidence="0.924964611111111">
11: N ← MENTIONNODES(T, C)
12: N0 ← APPLYHEURISTICS(T, BUILDMST(T, N))
13: P ← P ∪ {BUILDPATTERN(T, N0)}
14: return P
15: /* Procedures /*
16: procedure APPLYHEURISTICS(T, N)
17: N0 ← N
18: while |N0 |&gt; 0 do
19: N00 ← ∅
20: for all n ∈ N0 do
21: if n.ISVERB() then
22: N00 ← N00 ∪ INCLUDECHILDREN(n, Vc)
23: N00 ← N00 ∪ INCLUDEPARENT(n, Vp)
24: else if n.ISNOUN() then
25: N00 ← N00 ∪ INCLUDECHILDREN(n, Nc)
26: N00 ← N00 ∪ INCLUDEPARENT(n, Np)
27: N0 ← N00 \ N0
28: procedure INCLUDECHILDREN(n, L)
</figure>
<listItem confidence="0.789379333333333">
29: R ← ∅
30: for all c ∈ n.CHILDREN() do
31: if c.PARENTEDGELABEL() ∈ L then
32: R ← R ∪ {c}
33: return R
34: procedure INCLUDEPARENT(n, L)
35: if n.PARENTEDGELABEL() ∈ L then
36: return {n}
37: else return ∅
</listItem>
<bodyText confidence="0.9995513">
very same summarization architecture, as shown
in Figure 2: an event model is constructed by clus-
tering the patterns extracted according to the se-
lected extraction method. Then, the same extrac-
tion method is used to collect patterns from sen-
tences in never-seen-before news articles. Finally,
the patterns are used to query the event model and
generate an abstractive summary. The three differ-
ent pattern extractors are detailed in the next three
sections.
</bodyText>
<sectionHeader confidence="0.728829" genericHeader="method">
2 Heuristics-based pattern extraction
</sectionHeader>
<bodyText confidence="0.999971142857143">
In order to be able to work in an Open-IE man-
ner, applicable to different domains, most existing
pattern extraction systems are based on linguisti-
cally motivated heuristics. Zhang and Weld (2013)
is based on REVERB (Fader et al., 2011), which
uses a regular expression on part-of-speech tags
to produce the extractions. An alternative system,
</bodyText>
<figure confidence="0.994406066666667">
News
article
Pattern
extraction
Pattern
extraction
Abstractive
summary
Inference
News
clusters
Pattern
clustering
Event
model
</figure>
<page confidence="0.998825">
893
</page>
<bodyText confidence="0.999503724137931">
OLLIE (Schmitz et al., 2012), uses syntactic de-
pendency templates to guide the pattern extraction
process.
The heuristics used in this paper are inspired by
Alfonseca et al. (2013), who built well formed re-
lational patterns by extending minimum spanning
trees (MST) which connect entity mentions in a
dependency parse. Algorithm 1 details our re-
implementation of their method and the specific
set of rules that we rely on to enforce pattern gram-
maticality. We use the standard Stanford-style set
of dependency labels (de Marneffe et al., 2006).
The input to the algorithm are a parse tree T and
a set of target entities E. We first generate com-
binations of 1-3 elements of E (line 10), then for
each combination C we identify all the nodes in
T that mention any of the entities in C. We con-
tinue by constructing the MST of these nodes, and
finally apply our heuristics to the nodes in the
MST. The procedure APPLYHEURISTICS (:16) re-
cursively grows a nodeset N&apos; by including chil-
dren and parents of noun and verb nodes in N&apos;
based on dependency labels. For example, we in-
clude all children of verbs in N&apos; whose label is
listed in Vc (:3), e.g., active or passive subjects,
direct or indirect objects, particles and auxiliary
verbs. Similarly, we include the parent of a noun
in N&apos; if the dependency relation between the node
and its parent is listed in Np.
</bodyText>
<sectionHeader confidence="0.996518" genericHeader="method">
3 Pattern extraction by sentence
compression
</sectionHeader>
<bodyText confidence="0.99947512">
Sentence compression is a summarization tech-
nique that shortens input sentences preserving the
most important content (Grefenstette, 1998; Mc-
Donald, 2006; Clarke and Lapata, 2008, inter
alia). While first attempts at integrating a com-
pression module into an extractive summarization
system were not particularly successful (Daum´e
III and Marcu, 2004, inter alia), recent work
has been very promising (Berg-Kirkpatrick et al.,
2011; Wang et al., 2013). It has shown that drop-
ping constituents of secondary importance from
selected sentences – e.g., temporal modifiers or
relative clauses – results in readable and more in-
formative summaries. Unlike this related work,
our goal here is to compress sentences to obtain
an event pattern – the minimal grammatical struc-
ture expressing an event. To our knowledge, this
application of sentence compressors is novel. As
in Section 2, we only consider sentences mention-
ing entities and require the compression (pattern)
to retain at least one such mention.
Sentence compression methods are abundant
but very few can be configured to produce out-
put satisfying certain constraints. For example,
most compression algorithms do not accept com-
pression rate as an argument. In our case, sen-
tence compressors which formulate the compres-
sion task as an optimization problem and solve it
with integer linear programming (ILP) tools un-
der a number of constraints are particularly attrac-
tive (Clarke and Lapata, 2008; Filippova and Al-
tun, 2013). They can be extended relatively easily
with both the length constraint and the constraint
on retaining certain words. The method of Clarke
and Lapata (2008) uses a trigram language model
(LM) to score compressions. Since we are inter-
ested in very short outputs, a LM trained on stan-
dard, uncompressed text would not be suitable. In-
stead, we chose to modify the method of Filippova
and Altun (2013) because it relies on dependency
parse trees and does not use any LM scoring.
Like other syntax-based compressors, the sys-
tem of Filippova and Altun (2013) prunes depen-
dency structures to obtain compression trees and
hence sentences. The objective function to maxi-
mize in an ILP problem (Eq. 1) is formulated over
weighted edges in a transformed dependency tree
and is subject to a number of constraints. Edge
weight is defined as a linear function over a fea-
ture set: w(e) = w · f(e).
</bodyText>
<equation confidence="0.976083">
F(X) = � xe × w(e) (1)
eEE
</equation>
<bodyText confidence="0.997886583333333">
In our reimplementation we followed the algo-
rithm as described by Filippova and Altun (2013).
The compression tree is obtained in two steps.
First, the input tree is transformed with determin-
istic rules, most of which aim at collapsing indis-
pensable modifiers with their heads (determiners,
auxiliary verbs, negation, multi-word expressions,
etc.). Then a sub-tree maximizing the objective
function is found under a number of constraints.
Apart from the structural constrains from the
original system which ensure that the output is a
valid tree, the constraints we add state that:
</bodyText>
<listItem confidence="0.9804094">
1. tree size in edges must be in [3, 6],
2. entity mentions must be retained,
3. subject of the clause must be retained,
4. the sub-tree must be covered by a single
clause – exactly one finite verb must used.
</listItem>
<page confidence="0.995299">
894
</page>
<bodyText confidence="0.999958909090909">
Since we consider compressions with different
lengths as candidates, from this set we select the
one with the maximum averaged edge weight as
the final compression. Figure 3 illustrates the
use of the compressor for obtaining event pat-
terns. Dashed edges are dropped as a result of
constrained compression so that the output is John
Smith married Mary Brown and the event pattern
is PER married PER. Note that the root of a sub-
clause is allowed to be the top-level node in the
extracted compression.
Compared with patterns obtaines with heuris-
tics, compression patterns should retain preposi-
tional verb arguments whose removal would ren-
der the pattern ungrammatical. As an example
consider [C. Zeta-Jones] and [M. Douglas] filed
for divorce. The heuristics-based pattern is PER
and PER filed which is incomplete. Unlike it,
the compression-based method keeps the essential
prepositional phrase for divorce in the pattern be-
cause the average edge weight is greater for the
tree with the prepositional phrase.
</bodyText>
<sectionHeader confidence="0.896809" genericHeader="method">
4 Memory-based pattern extraction
</sectionHeader>
<bodyText confidence="0.999989375">
Neither heuristics-based, nor compression-based
methods provide a guarantee that the extracted
pattern is grammatically correct. In this sec-
tion we introduce an extraction technique which
makes it considerably more likely because it only
extracts patterns which have been observed as
full sentences in a human-written text (Sec. 4.1).
However, this memory-based method also poses
a problem not encountered by the two previous
methods: how to search over the vast space of ob-
served headlines and sentences to extract a pattern
from a given sentence? Our trie-based solution,
which we present in the remainder of this sec-
tion, makes it possible to compare a dependency
graph against millions of observed grammatical
utterances in a fraction of a second.
</bodyText>
<subsectionHeader confidence="0.997999">
4.1 A tree-trie to store them all...
</subsectionHeader>
<bodyText confidence="0.999952888888889">
Our objective is to construct a compact representa-
tion of hundreds of millions of observed sentences
that can fit in the memory of a standard worksta-
tion. This data structure should make it possible
to efficiently identify the sub-trees of a sentence
that match any complete utterance previously ob-
served. To this end, we build a trie of depen-
dency trees (which we call a tree-trie) by scan-
ning all the dependency parses in the news training
</bodyText>
<construct confidence="0.537213">
Algorithm 2 STORE(T, I): store the dependency tree T
in the tree-trie I.
</construct>
<listItem confidence="0.696541692307692">
1: /* Entry point/*
2: L ← T.LINEARIZE()
3: STORERECURSION(I.ROOT(), L, 0)
4: return M
5: /* Procedures /*
6: procedure STORERECURSION(n, L, o)
7: if o == L.LENGTH() then
8: n.ADDTREESTRUCTURE(L.STRUCTURE())
9: return
10: if not n.HASCHILD(L.TOKEN(o)) then
11: n.ADDCHILD(L.TOKEN(o))
12: n� ← n.GETCHILD(L.TOKEN(o))
13: STORERECURSION(n�, L, o + 1)
</listItem>
<bodyText confidence="0.997046052631579">
data, and index each tree in the tree-trie accord-
ing to Algorithm 2. For better clarity, the process
is also described graphically in Figure 4. First,
each dependency tree (a) is linearized, resulting
in a data structure that consists of two aligned se-
quences (b). The first sequence (tokens) encodes
word/parent-relation pairs, while the second se-
quence (structure) encodes the offsets of parent
nodes in the linearized tree. As an example, the
first word “The” is a determiner (“det”) for the sec-
ond node (offset 1) in the sequence, which is “cat”.
In turn, “cat” is the subject (“nsubj”) of the node
in position 2, i.e., “sleeps”. As described in Algo-
rithm 2, we recursively store the token sequence
in the trie, each word/relation pair being stored in
a node. When the token sequence is completely
consumed, we store in the current trie node the
structure of the linearized tree. Combining struc-
tural information with the sequential information
encoded by each path in the trie makes it possi-
ble to rebuild a complete dependency graph. Fig-
ure 4(c) shows an example trie encoding 4 differ-
ent sentences. We highlighted in bold the path cor-
responding to the linearized form (b) of the exam-
ple parse tree (a).
The figure shows that the tree contains two
kinds of nodes: end-of-sentence (EOS) nodes
(red) and non-terminal nodes (in blue). EOS nodes
do not necessarily coincide with trie leaves, as it
is possible to observe complete sentences embed-
ded in longer ones. EOS nodes differ from non-
terminal nodes in that they store one or more struc-
tural sequences corresponding to different syntac-
tic representations of observed sentences with the
same tokens.
Space-complexity and generalization. Storing
all the observed sentences in a single trie requires
huge amounts of memory. To make it possible to
</bodyText>
<page confidence="0.997348">
895
</page>
<figureCaption confidence="0.999988">
Figure 3: Transformed dependency tree with a sub-tree expressing an event pattern.
Figure 4: A dependency tree (a), its linearized form (b) and the resulting path in a trie (c), in bold.
</figureCaption>
<figure confidence="0.999171196428571">
root
Our sources
root
subj
report
root
subj
John Smith
married
in
obj
Mary Brown
in Baltimore
yesterday
tmod
nsubj
cat
sleeps
ROOT
1,2, 1
advmod
soundly
under
prep
the
det
1,2, 1,2,5,3
table
pobj
1,2, 1,2
root
prep
det nsubj
The cat sleeps under the table
pobj
det
1 2 -1 2 5 3
The
det
cat
nsubj
sleeps
ROOT
the
table
under
prep
det
pobj
The
det
nsubj
dog
barked
ROOT
1,2, 1
</figure>
<bodyText confidence="0.9997121875">
store a complete tree-trie in memory, we adopt the
following strategy. We replace the surface form of
entity nodes with the coarse entity type (e.g., PER,
LOC, ORG) of the entity. Similarly, we replace
proper nouns with the placeholder “[P]”, thus sig-
nificantly reducing lexical sparsity. Then, we en-
code each distinct word/relation pair as a 32-bit
unsigned integer. Assuming a maximum tree size
of 255 nodes, we represent structure sequences as
vectors of type unsigned char (8 bit per element).
Finally, we store trie-node children as sorted vec-
tors instead of hash maps to reduce memory foot-
print. As a result, we are able to load a trie encod-
ing 400M input dependency parses, 170M distinct
nodes and 48M distinct sentence structures in un-
der 10GB of RAM.
</bodyText>
<subsectionHeader confidence="0.994738">
4.2 ... and in the vastness match them
</subsectionHeader>
<bodyText confidence="0.986147333333333">
At lookup time, we want to use the tree-trie to
identify all sub-graphs of an input dependency tree
T that match at least a complete observed sen-
tence. To do so, we need to identify all paths in
the trie that match any sub-sequence s of the lin-
earized sequence of T nodes. Whenever we en-
counter an EOS node e, we verify if any of the
structures stored at e matches the sub-tree gener-
ated by s. If so, then we have a positive match.
As a sentence might embed many shorter utter-
ances, each input T will generally yield multiple
matches. For example, querying the tree-trie in
Figure 4(c) with the input tree shown in (a) would
yield two results, as both The cat sleeps and The
cat sleeps under the table are complete utterances
stored in the trie.
Algorithm 3 LOOKUP(T, I): Lookup for matches of sub-
set of tree T in the trie index I.
</bodyText>
<listItem confidence="0.993895466666667">
1: /* Entry point/*
2: L +— T.LINEARIZE()
3: M +— 0
4: LOOKUPRECURSIVE(T, L, 0, I.ROOT(), 0, M)
5: return M
6: /* Procedures /*
7: procedure LOOKUPRECURSIVE(T, L, o, n, P, M)
8: for all i E [o, L.LENGTH()) do
9: if n.HASCHILD(L.TOKEN(i)) then
10: n0 +— n.GETCHILD(L.TOKEN(i))
11: P0 +— P U {i}
12: for all S E n0.TREESTRUCTURES() do
13: if L.ISCOMPATIBLE(S, P0) then
14: M +— M U {T.GETNODES(P0)}
15: LOOKUPRECURSIVE(L, i, o + 1, n0, P0, M)
</listItem>
<bodyText confidence="0.999911411764706">
Algorithm 3 describes the lookup process in
more detail. The first step consists in the lineariza-
tion of the input tree T. Then, we recursively tra-
verse the trie calling LOOKUPRECURSIVE. The
inputs of this procedure are: the input tree T, its
linearization L and an offset o (starting at 0), the
trie node currently being traversed n (starting with
the root), the set of offsets in L that constitute a
partial match P (initially empty) and the set of
complete matches found M. We recursively tra-
verse all the nodes in the trie that yield a partial
match with any sub-sequence of the linearized to-
kens of T. At each step, we scan all the tokens
in L in the range [o, L.LENGTH()) looking for to-
kens matching any of the children of n. If a match-
ing node is found, a new partial match P&apos; is con-
structed by extending P with the matching token
</bodyText>
<page confidence="0.995702">
896
</page>
<figure confidence="0.981249">
10 20 30 40 50 60 70 80 90
</figure>
<figureCaption confidence="0.9883455">
Figure 5: Time complexity of lookup operations
for inputs of different sizes.
</figureCaption>
<bodyText confidence="0.999792906976744">
offset i (line 11), and the recursion continues from
the matching trie node n&apos; and offset i (line 15).
Every time a partial match is found, we verify if
the partial match is compatible with any of the
tree structures stored in the matching node. If that
is the case, we identify the corresponding set of
matching nodes in T and add it to the result M
(lines 12-14). A pattern is generated from each
complete match returned by LOOKUP after apply-
ing a simple heuristic: for each verb node v in the
match, we enforce that negations and auxiliaries in
T depending from x are also included in the pat-
tern.
Time complexity of lookups. Let k be the max-
imum fan-out of trie nodes, d be the depth of
the trie and n be the size of an input tree (num-
ber of nodes). If trie node children are hashed
(which has a negative effect on space complex-
ity), then worst case complexity of LOOKUP() is
O(nk)d−1. If they are stored as sorted lists, as in
our memory-efficient implementation, theoretical
complexity becomes O(nk log(k))d−1. It should
be noted that worst case complexity can only be
observed under extremely unlikely circumstances,
i.e., that at every step of the recursion all the nodes
in the tail of the linearized tree match a child of
the current node. Also, in the actual trie used in
our experiments the average branching factor k is
very small. We observed that a trie storing 400M
sentences (170M nodes) has an average branching
factor of 1.02. While the root of the trie has unsur-
prisingly many children (210K, all the observed
first sentence words), already at depth 2 the aver-
age fan-out is 13.7, and at level 3 it is 4.9.
For an empirical analysis of lookup complexity,
Figure 5 plots, in black, wall-clock lookup time
as a function of tree size n for a random sample
of 1,600 inputs. As shown by the polynomial re-
gression curve (red), observed lookup complexity
is approximately cubic with a very small constant
factor. In general, we can see that for sentences of
common length (20-50 words) a lookup operation
can be completed in well under one second.
</bodyText>
<sectionHeader confidence="0.999545" genericHeader="evaluation">
5 Evaluation
</sectionHeader>
<subsectionHeader confidence="0.997726">
5.1 Experimental settings
</subsectionHeader>
<bodyText confidence="0.996195526315789">
All the models for the experiments that we present
have been trained using the same corpus of
news crawled from the web between 2008 and
2013. The news have been processed with a to-
kenizer, a sentence splitter (Gillick and Favre,
2009), a part-of-speech tagger and dependency
parser (Nivre, 2006), a co-reference resolution
module (Haghighi and Klein, 2009) and an entity
linker based on Wikipedia and Freebase (Milne
and Witten, 2008). We use Freebase types as fine-
grained named entity types, so we are also able to
label e.g. instances of sports teams as such instead
of the coarser label ORG.
Next, the news have been grouped based on
temporal closeness (Zhang and Weld, 2013) and
cosine similarity (using tf·idf weights). For each
of the three pattern extraction methods we used the
same summarization pipeline (as shown above in
Figure 2):
</bodyText>
<listItem confidence="0.997696142857143">
1. Run pattern extraction on the news.
2. For every news collection Coll and entity set
E, generate a set containing all the extracted
patterns from news in Coll mentioning all
the entities in E. These are patterns that are
likely to be paraphrasing each other.
3. Run a clustering algorithm to group together
</listItem>
<bodyText confidence="0.895587785714286">
patterns that typically co-occur in the sets
generated in the previous step. There are
many choices for clustering algorithms (Al-
fonseca et al., 2013; Zhang and Weld, 2013).
Following Alfonseca et al. (2013) we use in
this work a Noisy-OR Bayesian Network be-
cause it has already been applied for abstrac-
tive summarization (albeit multi-document),
it provides an easily interpretable probabilis-
tic clustering, and training can be easily par-
allelized to be able to handle large training
sets. The hidden events in the Bayesian net-
work represent pattern clusters. When train-
ing is done, for each extraction pattern pj
</bodyText>
<figure confidence="0.9979472">
Time (seconds)
f(x) = 1.9E-07 x^3.3E+00
Tree size (number of nodes)
1.0E+01
1.0E+00
1.0E-01
1.0E-02
1.0E-03
1.0E-04
1.0E-05
</figure>
<page confidence="0.968248">
897
</page>
<table confidence="0.924692066666667">
Original sentence Abstractive summary (method)
Two-time defending overall World Cup champion Marcel Hirscher won the Marcel Hirscher has won the giant
challenging giant slalom on the Gran Risa course with two solid runs Sunday slalom. (C)
and attributed his victory to a fixed screw in his equipment setup.
Zodiac Aerospace posted a 7.9 percent rise in first-quarter revenue, below mar- Zodiac Aerospace has reported a rise in
ket expectations, but reaffirmed its full-year financial targets. profits. (C)
Australian free-agent closer Grant Balfour has agreed to terms with the Balti- Balfour will join the Baltimore Orioles.
more Orioles on a two-year deal, the Baltimore Sun reported on Tuesday citing (H)
multiple industry sources.
Paul Rudd is ’Ant-Man’: 5 reasons he needs an ’Agents of SHIELD’ appear- Paul Rudd to play Ant-Man. (H)
ance.
Millwall defender Karleigh Osborne has joined Bristol City on a two-and-a-half Bristol City have signed Karleigh Os-
year deal after a successful loan spell. borne. (M)
Simon Hoggart, one of the Spectator’s best-loved columnists, died yesterday Simon Hoggart passed away yesterday.
after fighting pancreatic cancer for over three years. (M)
</table>
<tableCaption confidence="0.99786">
Table 1: Abstraction examples from compression (C), heuristic (H) and memory-based (M) patterns.
</tableCaption>
<table confidence="0.99931225">
Method Extractions Abstractions
HEURISTIC 24,630 956
COMPRESSION 15,687 657
MEMORY-BASED 11,459 967
</table>
<tableCaption confidence="0.971613">
Table 2: Patterns extracted in each method, before
Noisy-OR inference.
</tableCaption>
<bodyText confidence="0.931522285714286">
and pattern cluster ci, the network provides
p(pj|ci) —the probability that ci will gener-
ate pj— and p(ci|pj) —the probability that,
given a pattern pj, ci was the hidden event
that generated it.
At generation time we proceed in the following
way:
</bodyText>
<listItem confidence="0.992918444444444">
1. Given the title or first sentence of a news ar-
ticle, run the same pattern extraction method
that was used in training and, if possible, ob-
tain a pattern p involving some entities.
2. Find the model clusters that contain this pat-
tern, Cp = {ci such that p(ci|p) &gt; 01.
3. Return a ranked list of model patterns
output= {(pj, score(pj))1, scored as fol-
lows:
</listItem>
<equation confidence="0.881457">
�score(pj) = p(pj|ci)p(ci|p)
ci∈Cp
</equation>
<bodyText confidence="0.999202">
where p was the input pattern.
</bodyText>
<listItem confidence="0.979662666666667">
4. Replace the entity placeholders in the top-
scored patterns pj with the entities that were
actually mentioned in the input news article.
</listItem>
<bodyText confidence="0.997935545454545">
In all cases the parameters of the network were
predefined as 20,000 nodes in the hidden layer
(model clusters) and 40 Expectation Maximization
(EM) training iterations. Training was distributed
across 20 machines with 10 GB of memory each.
For testing we used 37,584 news crawled dur-
ing December 2013, which had not been used for
training the models. Table 3 shows one pattern
cluster example from each of the three trained
models. The table shows only the surface form
of the pattern for simplicity.
</bodyText>
<table confidence="0.3930539">
Pattern cluster (MEMORY-BASED)
organization1 gets organization0 nod for drug
organization1 gets organization0 nod for tablets
organization0 approves organization1 drug
organizations0 approves organization1 ’s drug
organization1 gets organization0 nod for capsules
Pattern cluster (HEURISTIC)
organization0 to buy organization1
organization0 to acquire organization1
organization0 buys organization1
organization0 acquires organization1
organization0 to acquire organizations1
organization0 buys organizations1
organization0 acquires organizations1
organization0 agrees to buy organization1
organization0 snaps up organization1
organization0 to purchase organizations1
organization0 is to acquire organization1
organization0 has agreed to buy organization1
organization0 announces acquisition of organizations1
organization0 may bid for organization1
organization1 sold to organization0
organization1 acquired by organization0
Pattern cluster (COMPRESSION)
the sports team1 have acquired person0 from the sports team2
the sports team1 acquired person0 from the sports team2
the sports team2 have traded person0 to the sports team1
sports team1 acquired the rights to person0 from sports team2
sports team2 acquired from sports team1 in exchange for person0
sports team2 have acquired from the sports team1 in exchange for person0
</table>
<tableCaption confidence="0.9939735">
Table 3: Examples of pattern clusters. In each
cluster ci, patterns are sorted by p(pj|ci).
</tableCaption>
<page confidence="0.996499">
898
</page>
<subsectionHeader confidence="0.787114">
5.2 Results
</subsectionHeader>
<bodyText confidence="0.999914307692308">
Table 2 shows the number of extracted patterns
from the test set, and the number of abstractive
event descriptions produced.
As expected, the number of extracted patterns
using the memory-based model is smaller than
with the two other models, which are based on
generic rules and are less restricted in what they
can generate. As mentioned, the memory-based
model can only extract previously-seen structures.
Compared to this model, with heuristics we can
obtain patterns for more than twice more news ar-
ticles. At the same time, looking at the number
of summary sentences generated they are com-
parable, meaning that a larger proportion of the
memory-based patterns actually appeared in the
pattern clusters and could be used to produce sum-
maries. This is also consistent with the fact that us-
ing heuristics the space of extracted patterns is ba-
sically unbounded and many new patterns can be
generated that were previously unseen –and these
cannot generate abstractions. A positive outcome
is that restricting the syntactic structure of the ex-
tracted patterns to what has been observed in past
news does not negatively affect end-to-end cover-
age when generating the abstractive summaries.
Table 1 shows some of the abstractive sum-
maries generated with the different methods. For
manually evaluating their quality, a random sam-
ple of 100 original sentences was selected for each
method. The top ranked summary for each origi-
nal sentence was sent to human raters for evalua-
tion, and received three different ratings. None of
the raters had any involvement in the development
of the work or the writing of the paper, and a con-
straint was added that no rater could rate more than
50 abstractions. Raters were presented with the
original sentence and the compressed abstraction,
and were asked to rate it along two dimensions, in
both cases using a 5-point Likert scale:
</bodyText>
<listItem confidence="0.998612">
• Readability: whether the abstracted com-
pression is grammatically correct.
• Informativeness: whether the abstracted
</listItem>
<bodyText confidence="0.970070333333333">
compression conveys the most important in-
formation from the original sentence.
Inter-judge agreement was measured using the
Intra-Class Correlation (ICC) (Shrout and Fleiss,
1979; Cicchetti, 1994). The ICC for readability
was 0.37 (95% confidence interval [0.32, 0.41]),
</bodyText>
<table confidence="0.991109">
Method Readability Informativeness
HEURISTIC 3.95 3.07
COMPRESSION 3.98 2.35
MEMORY-BASED 4.20 3.70
</table>
<tableCaption confidence="0.957747">
Table 4: Results for the three methods when rating
</tableCaption>
<bodyText confidence="0.989508795454546">
the top-ranked abstraction.
and for informativeness it was 0.64 (95% confi-
dence interval [0,60, 0.67]), representing fair and
substantial reliability.
Table 4 shows the results when rating the top
ranked abstraction using either of the three dif-
ferent models for pattern extraction. The abstrac-
tions produced with the memory-based method are
more readable than those produced with the other
two methods (statistically significant with 95%
confidence).
Regarding informativeness, the differences be-
tween the methods are bigger, because the first two
methods have a proportionally larger number of
items with a high readability but a low informa-
tiveness score. For each method, we have man-
ually reviewed the 25 items where the difference
between readability and informativeness was the
largest, to understand in which cases grammatical,
yet irrelevant compressions are produced. The re-
sults are shown in Table 5. Be+adjective includes
examples where the pattern is of the form Entity is
Adjective, which the compression-based systems
extracts often represents an incomplete extraction.
Wrong inference contains the cases where patterns
that are related but not equivalent are clustered,
e.g. Person arrived in Country and Person arrived
in Country for talks. Info. missing represents cases
where very relevant information has been dropped
and the summary sentence is not complete. Pos-
sibility contains cases where the original sentence
described a possibility and the compression states
it as a fact, or vice versa. Disambiguation are en-
tity disambiguations errors, and Opposite contains
cases of patterns clustered together that are op-
posite along some dimension, e.g. Person quits
TV Program and Person to return to TV Program.
The method with the largest drop between the
readability and informativeness scores is COM-
PRESSION. As can be seen, many of these mis-
takes are due to relevant information being miss-
ing in the summary sentence. This is also the
largest source of errors for the HEURISTIC system.
For the MEMORY-BASED system, the drop in read-
</bodyText>
<page confidence="0.995884">
899
</page>
<table confidence="0.999177">
Method Be+adjective Wrong inference Info. missing Possibility Disambiguation Opposite
HEURISTIC 0 7 14 3 1 0
COMPRESSION 3 10 10 0 0 2
MEMORY-BASED 0 17 4 2 0 2
</table>
<tableCaption confidence="0.857869">
Table 5: Sources of errors for the top 25 items with high readability and low informativeness.
Table 6: Examples of compression (C), heuristic (H) and memory-based (M) patterns that led to abstrac-
tions with high readability but a low informativeness score. Both incomplete summary sentences and
wrong inferences can be observed.
</tableCaption>
<table confidence="0.721287357142857">
Original sentence Pattern extracted (method) Abstraction
David Moyes is happy to use tough love on Adnan Januzaj
to ensure the Manchester United youngster fulfils his mas-
sive potential.
David Moyes is happy. (C) Fortune will start to favour
David Moyes.
The Democratic People’s Republic of Korea will “achieve The United States said Fri- United States officials said
nothing by making threats or provocation,” the United day. (C, H) Friday.
States said Friday.
EU targets Real Madrid. EU is going after Real
EU targets Real and Barca over illegal state aid.
(H) Madrid.
EU says Israel needs re-
EU warns Israel over settlement construction EU warns Israel. (M) forms.
</table>
<bodyText confidence="0.999658466666667">
ability score is much smaller, so there were less of
these examples. And most of these examples be-
long to the class of wrong inferences (patterns that
are related but not equivalent, so we should not
abstract one of them from the other, but they were
clustered together in the model). Our conclusion
is that the examples with missing information are
not such a big problem with the MEMORY-BASED
system, as using the trie is an additional safeguard
that the generated titles are complete statements,
but the method is not preventing the wrong infer-
ence errors so this class of errors become the dom-
inant class by a large margin.
Some examples with high readability but low
informativeness are shown in Table 6.
</bodyText>
<sectionHeader confidence="0.999499" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.99995115">
Most Open-IE systems are based on linguistically-
motivated heuristics for learning patterns that ex-
press relations between entities or events. How-
ever, it is common for these patterns to be incom-
plete or ungrammatical, and therefore they are not
suitable for abstractive summary generation of the
relation or event mentioned in the text.
In this paper, we describe a memory-based ap-
proach in which we use a corpus of past news
to learn valid syntactic sentence structures. We
discuss the theoretical time complexity of look-
ing up extraction patterns in a large corpus of
syntactic structures stored as a trie and demon-
strate empirically that this method is effective in
practice. Finally, the evaluation shows that sum-
mary sentences produced by this method outper-
form heuristics and compression-based ones both
in terms of readability and informativeness. The
problem of generating incomplete summary sen-
tences, which was the main source of informative-
ness errors for the alternative methods, becomes a
minor problem with the memory-based approach.
Yet, there are some cases in which also the mem-
ory based approach extracts correct but misleading
utterances, e.g., a pattern like PER passed away
from the sentence PER passed the ball away. To
solve this class of problems, a possible research
direction would be the inclusion of more complex
linguistic features in the tree-trie, such as verb sub-
categorization frames.
As another direction for future work, more ef-
fort is needed in making sure that no incorrect in-
ferences are made with this model. These happen
when a more specific pattern is clustered together
with a less specific pattern, or when two non-
equivalent patterns often co-occur in news as two
events are somewhat correlated in real life, but it is
generally incorrect to infer one from the other. Im-
provements in the pattern-clustering model, out-
side the scope of this paper, will be required.
</bodyText>
<page confidence="0.992963">
900
</page>
<sectionHeader confidence="0.995842" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999887175925926">
Enrique Alfonseca, Daniele Pighin, and Guillermo
Garrido. 2013. HEADY: News headline abstraction
through event pattern clustering. In Proceedings of
the 51st Annual Meeting of the Association for Com-
putational Linguistics, Sofia, Bulgaria, 4–9 August
2013, pages 1243–1253.
Taylor Berg-Kirkpatrick, Dan Gillick, and Dan Klein.
2011. Jointly learning to extract and compress. In
Proceedings of the 49th Annual Meeting of the As-
sociation for Computational Linguistics, Portland,
OR, 19–24 June 2011.
Domenic V Cicchetti. 1994. Guidelines, criteria, and
rules of thumb for evaluating normed and standard-
ized assessment instruments in psychology. Psycho-
logical Assessment, 6(4):284.
James Clarke and Mirella Lapata. 2008. Global in-
ference for sentence compression: An integer linear
programming approach. Journal ofArtificialIntelli-
gence Research, 31:399–429.
Hal Daum´e III and Daniel Marcu. 2004. A tree-
position kernel for document compression. In Pro-
ceedings of the 2004 Document Understanding Con-
ference held at the Human Language Technology
Conference of the North American Chapter of the
Association for Computational Linguistics,, Boston,
Mass., 6–7 May 2004.
Marie-Catherine de Marneffe, Bill MacCartney, and
Christopher D. Manning. 2006. Generating typed
dependency parses from phrase structure parses. In
Proceedings of the 5th International Conference on
Language Resources and Evaluation, Genoa, Italy,
22–28 May 2006, pages 449–454.
Anthony Fader, Stephen Soderland, and Oren Etzioni.
2011. Identifying relations for open information ex-
traction. In Proceedings of the 2011 Conference on
Empirical Methods in Natural Language Process-
ing, Edinburgh, UK, 27–29 July 2011, pages 1535–
1545.
Katja Filippova and Yasemin Altun. 2013. Overcom-
ing the lack of parallel data in sentence compression.
In Proceedings of the 2013 Conference on Empirical
Methods in Natural Language Processing, Seattle,
WA, USA, 18–21 October 2013, pages 1481–1491.
Dan Gillick and Benoit Favre. 2009. A scalable global
model for summarization. In Proceedings of the ILP
for NLP Workshop, Boulder, CO, June 4 2009, pages
10–18.
Gregory Grefenstette. 1998. Producing intelligent
telegraphic text reduction to provide an audio scan-
ning service for the blind. In Working Notes of the
Workshop on Intelligent Text Summarization, Palo
Alto, Cal., 23 March 1998, pages 111–117.
Aria Haghighi and Dan Klein. 2009. Simple coref-
erence resolution with rich syntactic and semantic
features. In Proceedings of the 2009 Conference on
Empirical Methods in Natural Language Process-
ing, Singapore, 6-7 August 2009, pages 1152–1161.
Inderjeet Mani. 2001. Automatic Summarization.
John Benjamins, Amsterdam, Philadelphia.
Ryan McDonald. 2006. Discriminative sentence com-
pression with soft syntactic evidence. In Proceed-
ings of the 11th Conference of the European Chap-
ter of the Association for Computational Linguistics,
Trento, Italy, 3–7 April 2006, pages 297–304.
Yashar Mehdad, Giuseppe Carenini, and Frank W.
Tompa. 2013. Abstractive meeting summariza-
tion with entailment and fusion. In Proceedings
of the 14th European Workshop on Natural Lan-
guage Generation, Sofia, Bulgaria, 8–9 August,
2013, pages 136–146.
David Milne and Ian H. Witten. 2008. An effective,
low-cost measure of semantic relatedness obtained
from Wikipedia links. In Proceedings of the AAAI
2008 Workshop on Wikipedia and Artificial Intelli-
gence, Chicago, IL, 13-14 July, 2008.
Joakim Nivre. 2006. Inductive Dependency Parsing.
Springer.
Michael Schmitz, Robert Bart, Stephen Soderland,
Oren Etzioni, et al. 2012. Open language learn-
ing for information extraction. In Proceedings of
the 2012 Conference on Empirical Methods in Natu-
ral Language Processing, Jeju Island, Korea, 12–14
July 2012, pages 523–534.
Patrick E Shrout and Joseph L Fleiss. 1979. Intraclass
correlations: uses in assessing rater reliability. Psy-
chological bulletin, 86(2):420.
Karen Sp¨arck-Jones. 2007. Automatic summaris-
ing: A review and discussion of the state of the art.
Technical Report UCAM-CL-TR-679, University of
Cambridge, Computer Laboratory, Cambridge, U.K.
Ivan Titov and Alexandre Klementiev. 2011. A
Bayesian model for unsupervised semantic parsing.
In Proceedings of the 49th Annual Meeting of the As-
sociation for Computational Linguistics, Portland,
OR, 19–24 June 2011, pages 1445–1455.
Lu Wang, Hema Raghavan, Vittorio Castelli, Radu Flo-
rian, and Claire Cardie. 2013. A sentence com-
pression based framework to query-focused multi-
document summarization. In Proceedings of the
51st Annual Meeting of the Association for Com-
putational Linguistics, Sofia, Bulgaria, 4–9 August
2013, pages 1384–1394.
Congle Zhang and Daniel S. Weld. 2013. Harvest-
ing parallel news streams to generate paraphrases of
event relations. In Proceedings of the 2013 Con-
ference on Empirical Methods in Natural Language
Processing, Seattle, WA, USA, 18–21 October 2013,
pages 1776–1786.
</reference>
<page confidence="0.99813">
901
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.980905">
<title confidence="0.9997845">Modelling Events through Memory-based, Open-IE for Abstractive Summarization</title>
<author confidence="0.988278">Pighin Marco Alfonseca Katja Filippova</author>
<affiliation confidence="0.998344">Google Inc. University of Pisa, Italy Google Inc. Google Inc.</affiliation>
<email confidence="0.996702">biondo@google.comcornolti@di.unipi.itealfonseca@google.comkatjaf@google.com</email>
<abstract confidence="0.999889">Abstractive text summarization of news requires a way of representing events, such as a collection of pattern clusters in which every cluster represents an event (e.g., and every pattern in the cluster is a way of expressing the event (e.g., married Y, X and Y tied the We compare three ways of extracting event patterns: heuristics-based, compressionbased and memory-based. While the former has been used previously in multidocument abstraction, the latter two have never been used for this task. Compared with the first two techniques, the memorybased method allows for generating significantly more grammatical and informative sentences, at the cost of searching a vast space of hundreds of millions of parse trees of known grammatical utterances. To this end, we introduce a data structure and a search method that make it possible to efficiently extrapolate from every sentence the parse sub-trees that match against any of the stored utterances.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Enrique Alfonseca</author>
<author>Daniele Pighin</author>
<author>Guillermo Garrido</author>
</authors>
<title>HEADY: News headline abstraction through event pattern clustering.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1243--1253</pages>
<location>Sofia, Bulgaria, 4–9</location>
<contexts>
<context position="1656" citStr="Alfonseca et al., 2013" startWordPosition="240" endWordPosition="243">ees of known grammatical utterances. To this end, we introduce a data structure and a search method that make it possible to efficiently extrapolate from every sentence the parse sub-trees that match against any of the stored utterances. 1 Introduction Text summarization beyond extraction requires a semantic representation that abstracts away from words and phrases and from which a summary can be generated (Mani, 2001; Sp¨arck-Jones, 2007). Following and extending recent work in semantic parsing, information extraction (IE), paraphrase generation and summarization (Titov and Klementiev, 2011; Alfonseca et al., 2013; Zhang and Weld, 2013; Mehdad et al., 2013), the representation we consider in this paper is a large collec∗Work done during an internship at Google Zurich. Figure 1: An example of abstracting from input sentences to an event representation and generation from that representation. tion of clusters of event patterns. An abstractive summarization system relying on such a representation proceeds by (1) detecting the most relevant event cluster for a given sentence or sentence collection, and (2) using the most representative pattern from the cluster to generate a concise summary sentence. Figure</context>
<context position="7991" citStr="Alfonseca et al. (2013)" startWordPosition="1279" endWordPosition="1282"> an Open-IE manner, applicable to different domains, most existing pattern extraction systems are based on linguistically motivated heuristics. Zhang and Weld (2013) is based on REVERB (Fader et al., 2011), which uses a regular expression on part-of-speech tags to produce the extractions. An alternative system, News article Pattern extraction Pattern extraction Abstractive summary Inference News clusters Pattern clustering Event model 893 OLLIE (Schmitz et al., 2012), uses syntactic dependency templates to guide the pattern extraction process. The heuristics used in this paper are inspired by Alfonseca et al. (2013), who built well formed relational patterns by extending minimum spanning trees (MST) which connect entity mentions in a dependency parse. Algorithm 1 details our reimplementation of their method and the specific set of rules that we rely on to enforce pattern grammaticality. We use the standard Stanford-style set of dependency labels (de Marneffe et al., 2006). The input to the algorithm are a parse tree T and a set of target entities E. We first generate combinations of 1-3 elements of E (line 10), then for each combination C we identify all the nodes in T that mention any of the entities in</context>
<context position="23879" citStr="Alfonseca et al., 2013" startWordPosition="4009" endWordPosition="4013">d cosine similarity (using tf·idf weights). For each of the three pattern extraction methods we used the same summarization pipeline (as shown above in Figure 2): 1. Run pattern extraction on the news. 2. For every news collection Coll and entity set E, generate a set containing all the extracted patterns from news in Coll mentioning all the entities in E. These are patterns that are likely to be paraphrasing each other. 3. Run a clustering algorithm to group together patterns that typically co-occur in the sets generated in the previous step. There are many choices for clustering algorithms (Alfonseca et al., 2013; Zhang and Weld, 2013). Following Alfonseca et al. (2013) we use in this work a Noisy-OR Bayesian Network because it has already been applied for abstractive summarization (albeit multi-document), it provides an easily interpretable probabilistic clustering, and training can be easily parallelized to be able to handle large training sets. The hidden events in the Bayesian network represent pattern clusters. When training is done, for each extraction pattern pj Time (seconds) f(x) = 1.9E-07 x^3.3E+00 Tree size (number of nodes) 1.0E+01 1.0E+00 1.0E-01 1.0E-02 1.0E-03 1.0E-04 1.0E-05 897 Origin</context>
</contexts>
<marker>Alfonseca, Pighin, Garrido, 2013</marker>
<rawString>Enrique Alfonseca, Daniele Pighin, and Guillermo Garrido. 2013. HEADY: News headline abstraction through event pattern clustering. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, Sofia, Bulgaria, 4–9 August 2013, pages 1243–1253.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taylor Berg-Kirkpatrick</author>
<author>Dan Gillick</author>
<author>Dan Klein</author>
</authors>
<title>Jointly learning to extract and compress.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>Portland, OR,</location>
<contexts>
<context position="9643" citStr="Berg-Kirkpatrick et al., 2011" startWordPosition="1558" endWordPosition="1561">ticles and auxiliary verbs. Similarly, we include the parent of a noun in N&apos; if the dependency relation between the node and its parent is listed in Np. 3 Pattern extraction by sentence compression Sentence compression is a summarization technique that shortens input sentences preserving the most important content (Grefenstette, 1998; McDonald, 2006; Clarke and Lapata, 2008, inter alia). While first attempts at integrating a compression module into an extractive summarization system were not particularly successful (Daum´e III and Marcu, 2004, inter alia), recent work has been very promising (Berg-Kirkpatrick et al., 2011; Wang et al., 2013). It has shown that dropping constituents of secondary importance from selected sentences – e.g., temporal modifiers or relative clauses – results in readable and more informative summaries. Unlike this related work, our goal here is to compress sentences to obtain an event pattern – the minimal grammatical structure expressing an event. To our knowledge, this application of sentence compressors is novel. As in Section 2, we only consider sentences mentioning entities and require the compression (pattern) to retain at least one such mention. Sentence compression methods are</context>
</contexts>
<marker>Berg-Kirkpatrick, Gillick, Klein, 2011</marker>
<rawString>Taylor Berg-Kirkpatrick, Dan Gillick, and Dan Klein. 2011. Jointly learning to extract and compress. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, Portland, OR, 19–24 June 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Domenic V Cicchetti</author>
</authors>
<title>Guidelines, criteria, and rules of thumb for evaluating normed and standardized assessment instruments in psychology.</title>
<date>1994</date>
<journal>Psychological Assessment,</journal>
<volume>6</volume>
<issue>4</issue>
<contexts>
<context position="30854" citStr="Cicchetti, 1994" startWordPosition="5078" endWordPosition="5079">elopment of the work or the writing of the paper, and a constraint was added that no rater could rate more than 50 abstractions. Raters were presented with the original sentence and the compressed abstraction, and were asked to rate it along two dimensions, in both cases using a 5-point Likert scale: • Readability: whether the abstracted compression is grammatically correct. • Informativeness: whether the abstracted compression conveys the most important information from the original sentence. Inter-judge agreement was measured using the Intra-Class Correlation (ICC) (Shrout and Fleiss, 1979; Cicchetti, 1994). The ICC for readability was 0.37 (95% confidence interval [0.32, 0.41]), Method Readability Informativeness HEURISTIC 3.95 3.07 COMPRESSION 3.98 2.35 MEMORY-BASED 4.20 3.70 Table 4: Results for the three methods when rating the top-ranked abstraction. and for informativeness it was 0.64 (95% confidence interval [0,60, 0.67]), representing fair and substantial reliability. Table 4 shows the results when rating the top ranked abstraction using either of the three different models for pattern extraction. The abstractions produced with the memory-based method are more readable than those produce</context>
</contexts>
<marker>Cicchetti, 1994</marker>
<rawString>Domenic V Cicchetti. 1994. Guidelines, criteria, and rules of thumb for evaluating normed and standardized assessment instruments in psychology. Psychological Assessment, 6(4):284.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Clarke</author>
<author>Mirella Lapata</author>
</authors>
<title>Global inference for sentence compression: An integer linear programming approach.</title>
<date>2008</date>
<journal>Journal ofArtificialIntelligence Research,</journal>
<pages>31--399</pages>
<contexts>
<context position="9390" citStr="Clarke and Lapata, 2008" startWordPosition="1521" endWordPosition="1524">t N&apos; by including children and parents of noun and verb nodes in N&apos; based on dependency labels. For example, we include all children of verbs in N&apos; whose label is listed in Vc (:3), e.g., active or passive subjects, direct or indirect objects, particles and auxiliary verbs. Similarly, we include the parent of a noun in N&apos; if the dependency relation between the node and its parent is listed in Np. 3 Pattern extraction by sentence compression Sentence compression is a summarization technique that shortens input sentences preserving the most important content (Grefenstette, 1998; McDonald, 2006; Clarke and Lapata, 2008, inter alia). While first attempts at integrating a compression module into an extractive summarization system were not particularly successful (Daum´e III and Marcu, 2004, inter alia), recent work has been very promising (Berg-Kirkpatrick et al., 2011; Wang et al., 2013). It has shown that dropping constituents of secondary importance from selected sentences – e.g., temporal modifiers or relative clauses – results in readable and more informative summaries. Unlike this related work, our goal here is to compress sentences to obtain an event pattern – the minimal grammatical structure expressi</context>
<context position="10659" citStr="Clarke and Lapata, 2008" startWordPosition="1720" endWordPosition="1723">n of sentence compressors is novel. As in Section 2, we only consider sentences mentioning entities and require the compression (pattern) to retain at least one such mention. Sentence compression methods are abundant but very few can be configured to produce output satisfying certain constraints. For example, most compression algorithms do not accept compression rate as an argument. In our case, sentence compressors which formulate the compression task as an optimization problem and solve it with integer linear programming (ILP) tools under a number of constraints are particularly attractive (Clarke and Lapata, 2008; Filippova and Altun, 2013). They can be extended relatively easily with both the length constraint and the constraint on retaining certain words. The method of Clarke and Lapata (2008) uses a trigram language model (LM) to score compressions. Since we are interested in very short outputs, a LM trained on standard, uncompressed text would not be suitable. Instead, we chose to modify the method of Filippova and Altun (2013) because it relies on dependency parse trees and does not use any LM scoring. Like other syntax-based compressors, the system of Filippova and Altun (2013) prunes dependency</context>
</contexts>
<marker>Clarke, Lapata, 2008</marker>
<rawString>James Clarke and Mirella Lapata. 2008. Global inference for sentence compression: An integer linear programming approach. Journal ofArtificialIntelligence Research, 31:399–429.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hal Daum´e</author>
<author>Daniel Marcu</author>
</authors>
<title>A treeposition kernel for document compression.</title>
<date>2004</date>
<booktitle>In Proceedings of the 2004 Document Understanding Conference held at the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics,,</booktitle>
<location>Boston, Mass., 6–7</location>
<marker>Daum´e, Marcu, 2004</marker>
<rawString>Hal Daum´e III and Daniel Marcu. 2004. A treeposition kernel for document compression. In Proceedings of the 2004 Document Understanding Conference held at the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics,, Boston, Mass., 6–7 May 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine de Marneffe</author>
<author>Bill MacCartney</author>
<author>Christopher D Manning</author>
</authors>
<title>Generating typed dependency parses from phrase structure parses.</title>
<date>2006</date>
<booktitle>In Proceedings of the 5th International Conference on Language Resources and Evaluation,</booktitle>
<pages>449--454</pages>
<location>Genoa, Italy,</location>
<marker>de Marneffe, MacCartney, Manning, 2006</marker>
<rawString>Marie-Catherine de Marneffe, Bill MacCartney, and Christopher D. Manning. 2006. Generating typed dependency parses from phrase structure parses. In Proceedings of the 5th International Conference on Language Resources and Evaluation, Genoa, Italy, 22–28 May 2006, pages 449–454.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anthony Fader</author>
<author>Stephen Soderland</author>
<author>Oren Etzioni</author>
</authors>
<title>Identifying relations for open information extraction.</title>
<date>2011</date>
<booktitle>In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1535--1545</pages>
<location>Edinburgh, UK,</location>
<contexts>
<context position="7573" citStr="Fader et al., 2011" startWordPosition="1219" endWordPosition="1222">terns extracted according to the selected extraction method. Then, the same extraction method is used to collect patterns from sentences in never-seen-before news articles. Finally, the patterns are used to query the event model and generate an abstractive summary. The three different pattern extractors are detailed in the next three sections. 2 Heuristics-based pattern extraction In order to be able to work in an Open-IE manner, applicable to different domains, most existing pattern extraction systems are based on linguistically motivated heuristics. Zhang and Weld (2013) is based on REVERB (Fader et al., 2011), which uses a regular expression on part-of-speech tags to produce the extractions. An alternative system, News article Pattern extraction Pattern extraction Abstractive summary Inference News clusters Pattern clustering Event model 893 OLLIE (Schmitz et al., 2012), uses syntactic dependency templates to guide the pattern extraction process. The heuristics used in this paper are inspired by Alfonseca et al. (2013), who built well formed relational patterns by extending minimum spanning trees (MST) which connect entity mentions in a dependency parse. Algorithm 1 details our reimplementation of</context>
</contexts>
<marker>Fader, Soderland, Etzioni, 2011</marker>
<rawString>Anthony Fader, Stephen Soderland, and Oren Etzioni. 2011. Identifying relations for open information extraction. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, Edinburgh, UK, 27–29 July 2011, pages 1535– 1545.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katja Filippova</author>
<author>Yasemin Altun</author>
</authors>
<title>Overcoming the lack of parallel data in sentence compression.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1481--1491</pages>
<location>Seattle, WA, USA,</location>
<contexts>
<context position="10687" citStr="Filippova and Altun, 2013" startWordPosition="1724" endWordPosition="1728"> is novel. As in Section 2, we only consider sentences mentioning entities and require the compression (pattern) to retain at least one such mention. Sentence compression methods are abundant but very few can be configured to produce output satisfying certain constraints. For example, most compression algorithms do not accept compression rate as an argument. In our case, sentence compressors which formulate the compression task as an optimization problem and solve it with integer linear programming (ILP) tools under a number of constraints are particularly attractive (Clarke and Lapata, 2008; Filippova and Altun, 2013). They can be extended relatively easily with both the length constraint and the constraint on retaining certain words. The method of Clarke and Lapata (2008) uses a trigram language model (LM) to score compressions. Since we are interested in very short outputs, a LM trained on standard, uncompressed text would not be suitable. Instead, we chose to modify the method of Filippova and Altun (2013) because it relies on dependency parse trees and does not use any LM scoring. Like other syntax-based compressors, the system of Filippova and Altun (2013) prunes dependency structures to obtain compre</context>
</contexts>
<marker>Filippova, Altun, 2013</marker>
<rawString>Katja Filippova and Yasemin Altun. 2013. Overcoming the lack of parallel data in sentence compression. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, Seattle, WA, USA, 18–21 October 2013, pages 1481–1491.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Gillick</author>
<author>Benoit Favre</author>
</authors>
<title>A scalable global model for summarization.</title>
<date>2009</date>
<booktitle>In Proceedings of the ILP for NLP Workshop,</booktitle>
<volume>4</volume>
<pages>10--18</pages>
<location>Boulder, CO,</location>
<contexts>
<context position="22810" citStr="Gillick and Favre, 2009" startWordPosition="3833" endWordPosition="3836"> lookup time as a function of tree size n for a random sample of 1,600 inputs. As shown by the polynomial regression curve (red), observed lookup complexity is approximately cubic with a very small constant factor. In general, we can see that for sentences of common length (20-50 words) a lookup operation can be completed in well under one second. 5 Evaluation 5.1 Experimental settings All the models for the experiments that we present have been trained using the same corpus of news crawled from the web between 2008 and 2013. The news have been processed with a tokenizer, a sentence splitter (Gillick and Favre, 2009), a part-of-speech tagger and dependency parser (Nivre, 2006), a co-reference resolution module (Haghighi and Klein, 2009) and an entity linker based on Wikipedia and Freebase (Milne and Witten, 2008). We use Freebase types as finegrained named entity types, so we are also able to label e.g. instances of sports teams as such instead of the coarser label ORG. Next, the news have been grouped based on temporal closeness (Zhang and Weld, 2013) and cosine similarity (using tf·idf weights). For each of the three pattern extraction methods we used the same summarization pipeline (as shown above in F</context>
</contexts>
<marker>Gillick, Favre, 2009</marker>
<rawString>Dan Gillick and Benoit Favre. 2009. A scalable global model for summarization. In Proceedings of the ILP for NLP Workshop, Boulder, CO, June 4 2009, pages 10–18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gregory Grefenstette</author>
</authors>
<title>Producing intelligent telegraphic text reduction to provide an audio scanning service for the blind.</title>
<date>1998</date>
<booktitle>In Working Notes of the Workshop on Intelligent Text Summarization,</booktitle>
<pages>111--117</pages>
<location>Palo Alto, Cal., 23</location>
<contexts>
<context position="9349" citStr="Grefenstette, 1998" startWordPosition="1516" endWordPosition="1517">ICS (:16) recursively grows a nodeset N&apos; by including children and parents of noun and verb nodes in N&apos; based on dependency labels. For example, we include all children of verbs in N&apos; whose label is listed in Vc (:3), e.g., active or passive subjects, direct or indirect objects, particles and auxiliary verbs. Similarly, we include the parent of a noun in N&apos; if the dependency relation between the node and its parent is listed in Np. 3 Pattern extraction by sentence compression Sentence compression is a summarization technique that shortens input sentences preserving the most important content (Grefenstette, 1998; McDonald, 2006; Clarke and Lapata, 2008, inter alia). While first attempts at integrating a compression module into an extractive summarization system were not particularly successful (Daum´e III and Marcu, 2004, inter alia), recent work has been very promising (Berg-Kirkpatrick et al., 2011; Wang et al., 2013). It has shown that dropping constituents of secondary importance from selected sentences – e.g., temporal modifiers or relative clauses – results in readable and more informative summaries. Unlike this related work, our goal here is to compress sentences to obtain an event pattern – t</context>
</contexts>
<marker>Grefenstette, 1998</marker>
<rawString>Gregory Grefenstette. 1998. Producing intelligent telegraphic text reduction to provide an audio scanning service for the blind. In Working Notes of the Workshop on Intelligent Text Summarization, Palo Alto, Cal., 23 March 1998, pages 111–117.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aria Haghighi</author>
<author>Dan Klein</author>
</authors>
<title>Simple coreference resolution with rich syntactic and semantic features.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1152--1161</pages>
<contexts>
<context position="22932" citStr="Haghighi and Klein, 2009" startWordPosition="3849" endWordPosition="3852">e (red), observed lookup complexity is approximately cubic with a very small constant factor. In general, we can see that for sentences of common length (20-50 words) a lookup operation can be completed in well under one second. 5 Evaluation 5.1 Experimental settings All the models for the experiments that we present have been trained using the same corpus of news crawled from the web between 2008 and 2013. The news have been processed with a tokenizer, a sentence splitter (Gillick and Favre, 2009), a part-of-speech tagger and dependency parser (Nivre, 2006), a co-reference resolution module (Haghighi and Klein, 2009) and an entity linker based on Wikipedia and Freebase (Milne and Witten, 2008). We use Freebase types as finegrained named entity types, so we are also able to label e.g. instances of sports teams as such instead of the coarser label ORG. Next, the news have been grouped based on temporal closeness (Zhang and Weld, 2013) and cosine similarity (using tf·idf weights). For each of the three pattern extraction methods we used the same summarization pipeline (as shown above in Figure 2): 1. Run pattern extraction on the news. 2. For every news collection Coll and entity set E, generate a set contai</context>
</contexts>
<marker>Haghighi, Klein, 2009</marker>
<rawString>Aria Haghighi and Dan Klein. 2009. Simple coreference resolution with rich syntactic and semantic features. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, Singapore, 6-7 August 2009, pages 1152–1161.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Inderjeet Mani</author>
</authors>
<title>Automatic Summarization. John Benjamins,</title>
<date>2001</date>
<location>Amsterdam, Philadelphia.</location>
<contexts>
<context position="1455" citStr="Mani, 2001" startWordPosition="216" endWordPosition="217"> techniques, the memorybased method allows for generating significantly more grammatical and informative sentences, at the cost of searching a vast space of hundreds of millions of parse trees of known grammatical utterances. To this end, we introduce a data structure and a search method that make it possible to efficiently extrapolate from every sentence the parse sub-trees that match against any of the stored utterances. 1 Introduction Text summarization beyond extraction requires a semantic representation that abstracts away from words and phrases and from which a summary can be generated (Mani, 2001; Sp¨arck-Jones, 2007). Following and extending recent work in semantic parsing, information extraction (IE), paraphrase generation and summarization (Titov and Klementiev, 2011; Alfonseca et al., 2013; Zhang and Weld, 2013; Mehdad et al., 2013), the representation we consider in this paper is a large collec∗Work done during an internship at Google Zurich. Figure 1: An example of abstracting from input sentences to an event representation and generation from that representation. tion of clusters of event patterns. An abstractive summarization system relying on such a representation proceeds by</context>
</contexts>
<marker>Mani, 2001</marker>
<rawString>Inderjeet Mani. 2001. Automatic Summarization. John Benjamins, Amsterdam, Philadelphia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
</authors>
<title>Discriminative sentence compression with soft syntactic evidence.</title>
<date>2006</date>
<booktitle>In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>297--304</pages>
<location>Trento,</location>
<contexts>
<context position="9365" citStr="McDonald, 2006" startWordPosition="1518" endWordPosition="1520">y grows a nodeset N&apos; by including children and parents of noun and verb nodes in N&apos; based on dependency labels. For example, we include all children of verbs in N&apos; whose label is listed in Vc (:3), e.g., active or passive subjects, direct or indirect objects, particles and auxiliary verbs. Similarly, we include the parent of a noun in N&apos; if the dependency relation between the node and its parent is listed in Np. 3 Pattern extraction by sentence compression Sentence compression is a summarization technique that shortens input sentences preserving the most important content (Grefenstette, 1998; McDonald, 2006; Clarke and Lapata, 2008, inter alia). While first attempts at integrating a compression module into an extractive summarization system were not particularly successful (Daum´e III and Marcu, 2004, inter alia), recent work has been very promising (Berg-Kirkpatrick et al., 2011; Wang et al., 2013). It has shown that dropping constituents of secondary importance from selected sentences – e.g., temporal modifiers or relative clauses – results in readable and more informative summaries. Unlike this related work, our goal here is to compress sentences to obtain an event pattern – the minimal gramm</context>
</contexts>
<marker>McDonald, 2006</marker>
<rawString>Ryan McDonald. 2006. Discriminative sentence compression with soft syntactic evidence. In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics, Trento, Italy, 3–7 April 2006, pages 297–304.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yashar Mehdad</author>
<author>Giuseppe Carenini</author>
<author>Frank W Tompa</author>
</authors>
<title>Abstractive meeting summarization with entailment and fusion.</title>
<date>2013</date>
<booktitle>In Proceedings of the 14th European Workshop on Natural Language Generation,</booktitle>
<pages>136--146</pages>
<location>Sofia, Bulgaria, 8–9</location>
<contexts>
<context position="1700" citStr="Mehdad et al., 2013" startWordPosition="248" endWordPosition="251">nd, we introduce a data structure and a search method that make it possible to efficiently extrapolate from every sentence the parse sub-trees that match against any of the stored utterances. 1 Introduction Text summarization beyond extraction requires a semantic representation that abstracts away from words and phrases and from which a summary can be generated (Mani, 2001; Sp¨arck-Jones, 2007). Following and extending recent work in semantic parsing, information extraction (IE), paraphrase generation and summarization (Titov and Klementiev, 2011; Alfonseca et al., 2013; Zhang and Weld, 2013; Mehdad et al., 2013), the representation we consider in this paper is a large collec∗Work done during an internship at Google Zurich. Figure 1: An example of abstracting from input sentences to an event representation and generation from that representation. tion of clusters of event patterns. An abstractive summarization system relying on such a representation proceeds by (1) detecting the most relevant event cluster for a given sentence or sentence collection, and (2) using the most representative pattern from the cluster to generate a concise summary sentence. Figure 1 illustrates the summarization architectur</context>
</contexts>
<marker>Mehdad, Carenini, Tompa, 2013</marker>
<rawString>Yashar Mehdad, Giuseppe Carenini, and Frank W. Tompa. 2013. Abstractive meeting summarization with entailment and fusion. In Proceedings of the 14th European Workshop on Natural Language Generation, Sofia, Bulgaria, 8–9 August, 2013, pages 136–146.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Milne</author>
<author>Ian H Witten</author>
</authors>
<title>An effective, low-cost measure of semantic relatedness obtained from Wikipedia links.</title>
<date>2008</date>
<booktitle>In Proceedings of the AAAI 2008 Workshop on Wikipedia and Artificial Intelligence,</booktitle>
<pages>13--14</pages>
<location>Chicago, IL,</location>
<contexts>
<context position="23010" citStr="Milne and Witten, 2008" startWordPosition="3862" endWordPosition="3865">stant factor. In general, we can see that for sentences of common length (20-50 words) a lookup operation can be completed in well under one second. 5 Evaluation 5.1 Experimental settings All the models for the experiments that we present have been trained using the same corpus of news crawled from the web between 2008 and 2013. The news have been processed with a tokenizer, a sentence splitter (Gillick and Favre, 2009), a part-of-speech tagger and dependency parser (Nivre, 2006), a co-reference resolution module (Haghighi and Klein, 2009) and an entity linker based on Wikipedia and Freebase (Milne and Witten, 2008). We use Freebase types as finegrained named entity types, so we are also able to label e.g. instances of sports teams as such instead of the coarser label ORG. Next, the news have been grouped based on temporal closeness (Zhang and Weld, 2013) and cosine similarity (using tf·idf weights). For each of the three pattern extraction methods we used the same summarization pipeline (as shown above in Figure 2): 1. Run pattern extraction on the news. 2. For every news collection Coll and entity set E, generate a set containing all the extracted patterns from news in Coll mentioning all the entities </context>
</contexts>
<marker>Milne, Witten, 2008</marker>
<rawString>David Milne and Ian H. Witten. 2008. An effective, low-cost measure of semantic relatedness obtained from Wikipedia links. In Proceedings of the AAAI 2008 Workshop on Wikipedia and Artificial Intelligence, Chicago, IL, 13-14 July, 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
</authors>
<title>Inductive Dependency Parsing.</title>
<date>2006</date>
<publisher>Springer.</publisher>
<contexts>
<context position="22871" citStr="Nivre, 2006" startWordPosition="3843" endWordPosition="3844">puts. As shown by the polynomial regression curve (red), observed lookup complexity is approximately cubic with a very small constant factor. In general, we can see that for sentences of common length (20-50 words) a lookup operation can be completed in well under one second. 5 Evaluation 5.1 Experimental settings All the models for the experiments that we present have been trained using the same corpus of news crawled from the web between 2008 and 2013. The news have been processed with a tokenizer, a sentence splitter (Gillick and Favre, 2009), a part-of-speech tagger and dependency parser (Nivre, 2006), a co-reference resolution module (Haghighi and Klein, 2009) and an entity linker based on Wikipedia and Freebase (Milne and Witten, 2008). We use Freebase types as finegrained named entity types, so we are also able to label e.g. instances of sports teams as such instead of the coarser label ORG. Next, the news have been grouped based on temporal closeness (Zhang and Weld, 2013) and cosine similarity (using tf·idf weights). For each of the three pattern extraction methods we used the same summarization pipeline (as shown above in Figure 2): 1. Run pattern extraction on the news. 2. For every</context>
</contexts>
<marker>Nivre, 2006</marker>
<rawString>Joakim Nivre. 2006. Inductive Dependency Parsing. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Schmitz</author>
<author>Robert Bart</author>
<author>Stephen Soderland</author>
<author>Oren Etzioni</author>
</authors>
<title>Open language learning for information extraction.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>523--534</pages>
<location>Jeju Island,</location>
<contexts>
<context position="7839" citStr="Schmitz et al., 2012" startWordPosition="1255" endWordPosition="1258">. The three different pattern extractors are detailed in the next three sections. 2 Heuristics-based pattern extraction In order to be able to work in an Open-IE manner, applicable to different domains, most existing pattern extraction systems are based on linguistically motivated heuristics. Zhang and Weld (2013) is based on REVERB (Fader et al., 2011), which uses a regular expression on part-of-speech tags to produce the extractions. An alternative system, News article Pattern extraction Pattern extraction Abstractive summary Inference News clusters Pattern clustering Event model 893 OLLIE (Schmitz et al., 2012), uses syntactic dependency templates to guide the pattern extraction process. The heuristics used in this paper are inspired by Alfonseca et al. (2013), who built well formed relational patterns by extending minimum spanning trees (MST) which connect entity mentions in a dependency parse. Algorithm 1 details our reimplementation of their method and the specific set of rules that we rely on to enforce pattern grammaticality. We use the standard Stanford-style set of dependency labels (de Marneffe et al., 2006). The input to the algorithm are a parse tree T and a set of target entities E. We fi</context>
</contexts>
<marker>Schmitz, Bart, Soderland, Etzioni, 2012</marker>
<rawString>Michael Schmitz, Robert Bart, Stephen Soderland, Oren Etzioni, et al. 2012. Open language learning for information extraction. In Proceedings of the 2012 Conference on Empirical Methods in Natural Language Processing, Jeju Island, Korea, 12–14 July 2012, pages 523–534.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick E Shrout</author>
<author>Joseph L Fleiss</author>
</authors>
<title>Intraclass correlations: uses in assessing rater reliability.</title>
<date>1979</date>
<journal>Psychological bulletin,</journal>
<volume>86</volume>
<issue>2</issue>
<contexts>
<context position="30836" citStr="Shrout and Fleiss, 1979" startWordPosition="5074" endWordPosition="5077">ny involvement in the development of the work or the writing of the paper, and a constraint was added that no rater could rate more than 50 abstractions. Raters were presented with the original sentence and the compressed abstraction, and were asked to rate it along two dimensions, in both cases using a 5-point Likert scale: • Readability: whether the abstracted compression is grammatically correct. • Informativeness: whether the abstracted compression conveys the most important information from the original sentence. Inter-judge agreement was measured using the Intra-Class Correlation (ICC) (Shrout and Fleiss, 1979; Cicchetti, 1994). The ICC for readability was 0.37 (95% confidence interval [0.32, 0.41]), Method Readability Informativeness HEURISTIC 3.95 3.07 COMPRESSION 3.98 2.35 MEMORY-BASED 4.20 3.70 Table 4: Results for the three methods when rating the top-ranked abstraction. and for informativeness it was 0.64 (95% confidence interval [0,60, 0.67]), representing fair and substantial reliability. Table 4 shows the results when rating the top ranked abstraction using either of the three different models for pattern extraction. The abstractions produced with the memory-based method are more readable </context>
</contexts>
<marker>Shrout, Fleiss, 1979</marker>
<rawString>Patrick E Shrout and Joseph L Fleiss. 1979. Intraclass correlations: uses in assessing rater reliability. Psychological bulletin, 86(2):420.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karen Sp¨arck-Jones</author>
</authors>
<title>Automatic summarising: A review and discussion of the state of the art.</title>
<date>2007</date>
<tech>Technical Report UCAM-CL-TR-679,</tech>
<institution>University of Cambridge, Computer Laboratory,</institution>
<location>Cambridge, U.K.</location>
<marker>Sp¨arck-Jones, 2007</marker>
<rawString>Karen Sp¨arck-Jones. 2007. Automatic summarising: A review and discussion of the state of the art. Technical Report UCAM-CL-TR-679, University of Cambridge, Computer Laboratory, Cambridge, U.K.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Titov</author>
<author>Alexandre Klementiev</author>
</authors>
<title>A Bayesian model for unsupervised semantic parsing.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1445--1455</pages>
<location>Portland, OR,</location>
<contexts>
<context position="1632" citStr="Titov and Klementiev, 2011" startWordPosition="235" endWordPosition="239">reds of millions of parse trees of known grammatical utterances. To this end, we introduce a data structure and a search method that make it possible to efficiently extrapolate from every sentence the parse sub-trees that match against any of the stored utterances. 1 Introduction Text summarization beyond extraction requires a semantic representation that abstracts away from words and phrases and from which a summary can be generated (Mani, 2001; Sp¨arck-Jones, 2007). Following and extending recent work in semantic parsing, information extraction (IE), paraphrase generation and summarization (Titov and Klementiev, 2011; Alfonseca et al., 2013; Zhang and Weld, 2013; Mehdad et al., 2013), the representation we consider in this paper is a large collec∗Work done during an internship at Google Zurich. Figure 1: An example of abstracting from input sentences to an event representation and generation from that representation. tion of clusters of event patterns. An abstractive summarization system relying on such a representation proceeds by (1) detecting the most relevant event cluster for a given sentence or sentence collection, and (2) using the most representative pattern from the cluster to generate a concise </context>
</contexts>
<marker>Titov, Klementiev, 2011</marker>
<rawString>Ivan Titov and Alexandre Klementiev. 2011. A Bayesian model for unsupervised semantic parsing. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, Portland, OR, 19–24 June 2011, pages 1445–1455.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lu Wang</author>
<author>Hema Raghavan</author>
<author>Vittorio Castelli</author>
<author>Radu Florian</author>
<author>Claire Cardie</author>
</authors>
<title>A sentence compression based framework to query-focused multidocument summarization.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1384--1394</pages>
<location>Sofia, Bulgaria, 4–9</location>
<contexts>
<context position="9663" citStr="Wang et al., 2013" startWordPosition="1562" endWordPosition="1565">ilarly, we include the parent of a noun in N&apos; if the dependency relation between the node and its parent is listed in Np. 3 Pattern extraction by sentence compression Sentence compression is a summarization technique that shortens input sentences preserving the most important content (Grefenstette, 1998; McDonald, 2006; Clarke and Lapata, 2008, inter alia). While first attempts at integrating a compression module into an extractive summarization system were not particularly successful (Daum´e III and Marcu, 2004, inter alia), recent work has been very promising (Berg-Kirkpatrick et al., 2011; Wang et al., 2013). It has shown that dropping constituents of secondary importance from selected sentences – e.g., temporal modifiers or relative clauses – results in readable and more informative summaries. Unlike this related work, our goal here is to compress sentences to obtain an event pattern – the minimal grammatical structure expressing an event. To our knowledge, this application of sentence compressors is novel. As in Section 2, we only consider sentences mentioning entities and require the compression (pattern) to retain at least one such mention. Sentence compression methods are abundant but very f</context>
</contexts>
<marker>Wang, Raghavan, Castelli, Florian, Cardie, 2013</marker>
<rawString>Lu Wang, Hema Raghavan, Vittorio Castelli, Radu Florian, and Claire Cardie. 2013. A sentence compression based framework to query-focused multidocument summarization. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, Sofia, Bulgaria, 4–9 August 2013, pages 1384–1394.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Congle Zhang</author>
<author>Daniel S Weld</author>
</authors>
<title>Harvesting parallel news streams to generate paraphrases of event relations.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1776--1786</pages>
<location>Seattle, WA, USA,</location>
<contexts>
<context position="1678" citStr="Zhang and Weld, 2013" startWordPosition="244" endWordPosition="247"> utterances. To this end, we introduce a data structure and a search method that make it possible to efficiently extrapolate from every sentence the parse sub-trees that match against any of the stored utterances. 1 Introduction Text summarization beyond extraction requires a semantic representation that abstracts away from words and phrases and from which a summary can be generated (Mani, 2001; Sp¨arck-Jones, 2007). Following and extending recent work in semantic parsing, information extraction (IE), paraphrase generation and summarization (Titov and Klementiev, 2011; Alfonseca et al., 2013; Zhang and Weld, 2013; Mehdad et al., 2013), the representation we consider in this paper is a large collec∗Work done during an internship at Google Zurich. Figure 1: An example of abstracting from input sentences to an event representation and generation from that representation. tion of clusters of event patterns. An abstractive summarization system relying on such a representation proceeds by (1) detecting the most relevant event cluster for a given sentence or sentence collection, and (2) using the most representative pattern from the cluster to generate a concise summary sentence. Figure 1 illustrates the sum</context>
<context position="7533" citStr="Zhang and Weld (2013)" startWordPosition="1211" endWordPosition="1214">model is constructed by clustering the patterns extracted according to the selected extraction method. Then, the same extraction method is used to collect patterns from sentences in never-seen-before news articles. Finally, the patterns are used to query the event model and generate an abstractive summary. The three different pattern extractors are detailed in the next three sections. 2 Heuristics-based pattern extraction In order to be able to work in an Open-IE manner, applicable to different domains, most existing pattern extraction systems are based on linguistically motivated heuristics. Zhang and Weld (2013) is based on REVERB (Fader et al., 2011), which uses a regular expression on part-of-speech tags to produce the extractions. An alternative system, News article Pattern extraction Pattern extraction Abstractive summary Inference News clusters Pattern clustering Event model 893 OLLIE (Schmitz et al., 2012), uses syntactic dependency templates to guide the pattern extraction process. The heuristics used in this paper are inspired by Alfonseca et al. (2013), who built well formed relational patterns by extending minimum spanning trees (MST) which connect entity mentions in a dependency parse. Alg</context>
<context position="23254" citStr="Zhang and Weld, 2013" startWordPosition="3906" endWordPosition="3909">en trained using the same corpus of news crawled from the web between 2008 and 2013. The news have been processed with a tokenizer, a sentence splitter (Gillick and Favre, 2009), a part-of-speech tagger and dependency parser (Nivre, 2006), a co-reference resolution module (Haghighi and Klein, 2009) and an entity linker based on Wikipedia and Freebase (Milne and Witten, 2008). We use Freebase types as finegrained named entity types, so we are also able to label e.g. instances of sports teams as such instead of the coarser label ORG. Next, the news have been grouped based on temporal closeness (Zhang and Weld, 2013) and cosine similarity (using tf·idf weights). For each of the three pattern extraction methods we used the same summarization pipeline (as shown above in Figure 2): 1. Run pattern extraction on the news. 2. For every news collection Coll and entity set E, generate a set containing all the extracted patterns from news in Coll mentioning all the entities in E. These are patterns that are likely to be paraphrasing each other. 3. Run a clustering algorithm to group together patterns that typically co-occur in the sets generated in the previous step. There are many choices for clustering algorithm</context>
</contexts>
<marker>Zhang, Weld, 2013</marker>
<rawString>Congle Zhang and Daniel S. Weld. 2013. Harvesting parallel news streams to generate paraphrases of event relations. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, Seattle, WA, USA, 18–21 October 2013, pages 1776–1786.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>