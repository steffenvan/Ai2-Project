<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000419">
<title confidence="0.9976895">
Enriching Morphologically Poor Languages
for Statistical Machine Translation
</title>
<author confidence="0.44391">
Eleftherios Avramidis Philipp Koehn
</author>
<email confidence="0.595467">
e.avramidis@sms.ed.ac.uk pkoehn@inf.ed.ac.uk
</email>
<affiliation confidence="0.9937685">
School of Informatics
University of Edinburgh
</affiliation>
<address confidence="0.720442">
2 Baccleuch Place
Edinburgh, EH8 9LW, UK
</address>
<sectionHeader confidence="0.969311" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.985779076923077">
We address the problem of translating from
morphologically poor to morphologically rich
languages by adding per-word linguistic in-
formation to the source language. We use
the syntax of the source sentence to extract
information for noun cases and verb persons
and annotate the corresponding words accord-
ingly. In experiments, we show improved
performance for translating from English into
Greek and Czech. For English–Greek, we re-
duce the error on the verb conjugation from
19% to 5.4% and noun case agreement from
9% to 6%.
</bodyText>
<sectionHeader confidence="0.998899" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999481425">
Traditional statistical machine translation methods
are based on mapping on the lexical level, which
takes place in a local window of a few words. Hence,
they fail to produce adequate output in many cases
where more complex linguistic phenomena play a
role. Take the example of morphology. Predicting
the correct morphological variant for a target word
may not depend solely on the source words, but re-
quire additional information about its role in the sen-
tence.
Recent research on handling rich morphology has
largely focused on translating from rich morphology
languages, such as Arabic, into English (Habash and
Sadat, 2006). There has been less work on the op-
posite case, translating from English into morpho-
logically richer languages. In a study of translation
quality for languages in the Europarl corpus, Koehn
(2005) reports that translating into morphologically
richer languages is more difficult than translating
from them.
There are intuitive reasons why generating richer
morphology from morphologically poor languages
is harder. Take the example of translating noun
phrases from English to Greek (or German, Czech,
etc.). In English, a noun phrase is rendered the same
if it is the subject or the object. However, Greek
words in noun phrases are inflected based on their
role in the sentence. A purely lexical mapping of
English noun phrases to Greek noun phrases suffers
from the lack of information about its role in the sen-
tence, making it hard to choose the right inflected
forms.
Our method is based on factored phrase-based
statistical machine translation models. We focused
on preprocessing the source data to acquire the
needed information and then use it within the mod-
els. We mainly carried out experiments on English
to Greek translation, a language pair that exemplifies
the problems of translating from a morphologically
poor to a morphologically rich language.
</bodyText>
<subsectionHeader confidence="0.994448">
1.1 Morphology in Phrase-based SMT
</subsectionHeader>
<bodyText confidence="0.9999476">
When examining parallel sentences of such lan-
guage pairs, it is apparent that for many English
words and phrases which appear usually in the same
form, the corresponding terms of the richer target
language appear inflected in many different ways.
On a single word-based probabilistic level, it is then
obvious that for one specific English word e the
probability p(f|e) of it being translated into a word
f decreases as the number of translation candidates
increase, making the decisions more uncertain.
</bodyText>
<page confidence="0.981671">
763
</page>
<note confidence="0.700398">
Proceedings of ACL-08: HLT, pages 763–770,
</note>
<page confidence="0.389684">
Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics
</page>
<sectionHeader confidence="0.888196" genericHeader="related work">
1.2 Related Work
</sectionHeader>
<listItem confidence="0.974414769230769">
• English: The president, after reading the
press review and the announcements, left
his office
• Greek-1: The president[nominative], after
reading[3rdsing] the press
review[accusative,sing] and the
announcements[accusative,plur],
left[3rdsing] his office[accusative,sing]
• Greek-2: The president[nominative], after
reading[3rdsing] the press
review[accusative,sing] and the
announcements[nominative,plur],
left[3rdplur] his office[accusative,sing]
</listItem>
<figureCaption confidence="0.998997">
Figure 1: Example of missing agreement information, af-
fecting the meaning of the second sentence
</figureCaption>
<bodyText confidence="0.999197875">
One of the main aspects required for the flu-
ency of a sentence is agreement. Certain words
have to match in gender, case, number, person etc.
within a sentence. The exact rules of agreement
are language-dependent and are closely linked to the
morphological structure of the language.
Traditional statistical machine translation models
deal with this problems in two ways:
</bodyText>
<listItem confidence="0.887201428571429">
• The basic SMT approach uses the target lan-
guage model as a feature in the argument
maximisation function. This language model
is trained on grammatically correct text, and
would therefore give a good probability for
word sequences that are likely to occur in a sen-
tence, while it would penalise ungrammatical
or badly ordered formations.
• Meanwhile, in phrase-based SMT models,
words are mapped in chunks. This can resolve
phenomena where the English side uses more
than one words to describe what is denoted on
the target side by one morphologically inflected
term.
</listItem>
<bodyText confidence="0.999985846153846">
Thus, with respect to these methods, there is a prob-
lem when agreement needs to be applied on part of
a sentence whose length exceeds the order of the of
the target n-gram language model and the size of the
chunks that are translated (see Figure 1 for an exam-
ple).
In one of the first efforts to enrich the source in
word-based SMT, Ueffing and Ney (2003) used part-
of-speech (POS) tags, in order to deal with the verb
conjugation of Spanish and Catalan; so, POS tags
were used to identify the pronoun+verb sequence
and splice these two words into one term. The ap-
proach was clearly motivated by the problems oc-
curring by a single-word-based SMT and have been
solved by adopting a phrase-based model. Mean-
while, there is no handling of the case when the pro-
noun stays in distance with the related verb.
Minkov et al. (2007) suggested a post-processing
system which uses morphological and syntactic fea-
tures, in order to ensure grammatical agreement on
the output. The method, using various grammatical
source-side features, achieved higher accuracy when
applied directly to the reference translations but it
was not tested as a part of an MT system. Similarly,
translating English into Turkish (Durgar El-Kahlout
and Oflazer, 2006) uses POS and morph stems in
the input along with rich Turkish morph tags on the
target side, but improvement was gained only after
augmenting the generation process with morphotac-
tical knowledge. Habash et al. (2007) also inves-
tigated case determination in Arabic. Carpuat and
Wu (2007) approached the issue as a Word Sense
Disambiguation problem.
In their presentation of the factored SMT mod-
els, Koehn and Hoang (2007) describe experiments
for translating from English to German, Spanish and
Czech, using morphology tags added on the mor-
phologically rich side, along with POS tags. The
morphological factors are added on the morpholog-
ically rich side and scored with a 7-gram sequence
model. Probabilistic models for using only source
tags were investigated by Birch et al. (2007), who
attached syntax hints in factored SMT models by
having Combinatorial Categorial Grammar (CCG)
supertags as factors on the input words, but in this
case English was the target language.
This paper reports work that strictly focuses on
translation from English to a morphologically richer
language. We go one step further than just using eas-
ily acquired information (e.g. English POS or lem-
mata) and extract target-specific information from
the source sentence context. We use syntax, not in
</bodyText>
<page confidence="0.995878">
764
</page>
<figureCaption confidence="0.994728666666667">
Figure 2: Classification of the errors on our English-
Greek baseline system (ch. 4.1), as suggested by Vilar
et al. (2006)
</figureCaption>
<bodyText confidence="0.999723833333333">
order to aid reordering (Yamada and Knight, 2001;
Collins et al., 2005; Huang et al., 2006), but as a
means for getting the “missing” morphology infor-
mation, depending on the syntactic position of the
words of interest. Then, contrary to the methods
that added only output features or altered the gen-
eration procedure, we used this information in order
to augment only the source side of a factored transla-
tion model, assuming that we do not have resources
allowing factors or specialized generation in the tar-
get language (a common problem, when translating
from English into under-resourced languages).
</bodyText>
<sectionHeader confidence="0.98481" genericHeader="method">
2 Methods for enriching input
</sectionHeader>
<bodyText confidence="0.999966714285714">
We selected to focus on noun cases agreement
and verb person conjugation, since they were the
most frequent grammatical errors of our baseline
SMT system (see full error analysis in Figure 2).
Moreover, these types of inflection signify the con-
stituents of every phrase, tightly linked to the mean-
ing of the sentence.
</bodyText>
<subsectionHeader confidence="0.998677">
2.1 Case agreement
</subsectionHeader>
<bodyText confidence="0.999883392857143">
The case agreement for nouns, adjectives and arti-
cles is mainly defined by the syntactic role that each
noun phrase has. Nominative case is used to define
the nouns which are the subject of the sentence, ac-
cusative shows usually the direct object of the verbs
and dative case refers to the indirect object of bi-
transitive verbs.
Therefore, the followed approach takes advantage
of syntax, following a method similar to Semantic
Role Labelling (Carreras and Marquez, 2005; Sur-
deanu and Turmo, 2005). English, as morpholog-
ically poor language, usually follows a fixed word
order (subject-verb-object), so that a syntax parser
can be easily used for identifying the subject and the
object of most sentences. Considering such annota-
tion, a factored translation model is trained to map
the word-case pair to the correct inflection of the tar-
get noun. Given the agreement restriction, all words
that accompany the noun (adjectives, articles, deter-
miners) must follow the case of the noun, so their
likely case needs to be identified as well.
For this purpose we use a syntax parser to acquire
the syntax tree for each English sentence. The trees
are parsed depth-first and the cases are identified
within particular “sub-tree patterns” which are man-
ually specified. We use the sequence of the nodes
in the tree to identify the syntactic role of each noun
phrase.
</bodyText>
<figureCaption confidence="0.9863315">
Figure 3: Case tags are assigned on depth-first parse of
the English syntax tree, based on sub-tree patterns
</figureCaption>
<bodyText confidence="0.998715538461538">
To make things more clear, an example can be
seen in figure 3. At first, the algorithm identifies
the subtree “S-(NPB-VP)” and the nominative tag is
applied on the NPB node, so that it is assigned to the
word “we” (since a pronoun can have a case). The
example of accusative shows how cases get trans-
ferred to nested subtrees. In practice, they are recur-
sively transferred to every underlying noun phrase
(NP) but not to clauses that do not need this infor-
mation (e.g. prepositional phrases). Similar rules
are applied for covering a wide range of node se-
quence patterns.
Also note that this method had to be target-
</bodyText>
<page confidence="0.988463">
765
</page>
<bodyText confidence="0.999926666666667">
oriented in some sense: we considered the target
language rules for choosing the noun case in ev-
ery prepositional phrase, depending on the leading
preposition. This way, almost all nouns were tagged
and therefore the number of the factored words was
increased, in an effort to decrease sparsity. Simi-
larly, cases which do not actively affect morphology
(e.g. dative in Greek) were not tagged during factor-
ization.
</bodyText>
<subsectionHeader confidence="0.997887">
2.2 Verb person conjugation
</subsectionHeader>
<bodyText confidence="0.971770692307692">
For resolving the verb conjugation, we needed to
identify the person of a verb and add this piece of
linguistic information as a tag. As we parse the
tree top-down, on every level, we look for two dis-
crete nodes which, somewhere in their children, in-
clude the verb and the corresponding subject. Con-
sequently, the node which contains the subject is
searched recursively until a subject is found. Then,
the person is identified and the tag is assigned to the
node which contains the verb, which recursively be-
queaths this tag to the nested subtree.
For the subject selection, the following rules were
applied:
</bodyText>
<listItem confidence="0.917698947368421">
• The verb person is directly connected to the
subject of the sentence and in most cases it is
directly inferred by a personal pronoun (I, you
etc). Therefore, since this is usually the case,
when a pronoun existed, it was directly used as
a tag.
• All pronouns in a different case (e.g. them, my-
self) were were converted into nominative case
before being used as a tag.
• When the subject of the sentence is not a pro-
noun, but a single noun, then it is in third per-
son. The POS tag of this noun is then used to
identify if it is plural or singular. This was se-
lectively modified for nouns which despite be-
ing in singular, take a verb in plural.
• The gender of the subject does not affect the
inflection of the verb in Greek. Therefore, all
three genders that are given by the third person
pronouns were reduced to one.
</listItem>
<bodyText confidence="0.9733525">
In Figure 4 we can see an example of how the
person tag is extracted from the subject of the sen-
</bodyText>
<figureCaption confidence="0.996872">
Figure 4: Applying person tags on an English syntax tree
</figureCaption>
<bodyText confidence="0.9999839">
tence and gets passed to the relative clause. In par-
ticular, as the algorithm parses the syntax tree, it
identifies the sub-tree which has NP-A as a head
and includes the WHNP node. Consequently, it re-
cursively browses the preceding NPB so as to get
the subject of the sentence. The word “aspects” is
found, which has a POS tag that shows it is a plural
noun. Therefore, we consider the subject to be of
the third person in plural (tagged by they) which is
recursively passed to the children of the head node.
</bodyText>
<sectionHeader confidence="0.99962" genericHeader="method">
3 Factored Model
</sectionHeader>
<bodyText confidence="0.999947333333333">
The factored statistical machine translation model
uses a log-linear approach, in order to combine the
several components, including the language model,
the reordering model, the translation models and the
generation models. The model is defined mathemat-
ically (Koehn and Hoang, 2007) as following:
</bodyText>
<equation confidence="0.997241">
�n aihi(f, e) (1)
1
p(f|e) = Z exp
i=1
</equation>
<bodyText confidence="0.999201">
where
is a vector of weights determined during a
tuning process, and hi is the feature function. The
feature function for a translation probability distri
</bodyText>
<equation confidence="0.805414166666667">
Ai
-
bution is
hT(f|e) = � ) (2)
j
T(ej, fj
</equation>
<bodyText confidence="0.99356175">
While factored models may use a generation step to
combine the several tran
slation components based
on the output factors, we use only source factors;
</bodyText>
<page confidence="0.990186">
766
</page>
<bodyText confidence="0.999970857142857">
therefore we don’t need a generation step to combine
the probabilities of the several components.
Instead, factors are added so that both words and
its factor(s) are assigned the same probability. Of
course, when there is not 1-1 mapping between the
word+factor splice on the source and the inflected
word on the target, the well-known issue of sparse
data arises. In order to reduce these problems, de-
coding needed to consider alternative paths to trans-
lation tables trained with less or no factors (as Birch
et al. (2007) suggested), so as to cover instances
where a word appears with a factor which it has not
been trained with. This is similar to back-off. The
alternative paths are combined as following (fig. 5):
</bodyText>
<equation confidence="0.9871285">
hT (f|e) = � hTt(j)(ej, fj) (3)
j
</equation>
<bodyText confidence="0.999125333333333">
where each phrase j is translated by one translation
table t(j) and each table i has a feature function hTa.
as shown in eq. (2).
</bodyText>
<figureCaption confidence="0.9928805">
Figure 5: Decoding using an alternative path with differ-
ent factorization
</figureCaption>
<bodyText confidence="0.9996610625">
News Commentary respectively, following the spec-
ifications made by the ACL 2007 2nd Workshop
on SMT1. A Czech model was trained on 57,464
aligned sentences, tuned over 1057 sentences of the
News Commentary corpus and and tested on two
sets of 964 sentences and 2000 sentences respec-
tively.
The training sentences were trimmed to a length
of 60 words for reducing perplexity and a standard
lexicalised reordering, with distortion limit set to
6. For getting the syntax trees, the latest version
of Collins’ parser (Collins, 1997) was used. When
needed, part-of-speech (POS) tags were acquired by
using Brill’s tagger (Brill, 1992) on v1.14. Results
were evaluated with both BLEU (Papineni et al.,
2001) and NIST metrics (NIST, 2002).
</bodyText>
<sectionHeader confidence="0.933694" genericHeader="evaluation">
4.2 Results
</sectionHeader>
<table confidence="0.995812285714286">
BLEU NIST
set devtest test07 devtest test07
baseline 18.13 18.05 5.218 5.279
person 18.16 18.17 5.224 5.316
pos+person 18.14 18.16 5.259 5.316
person+case 18.08 18.24 5.258 5.340
altpath:POS 18.21 18.20 5.285 5.340
</table>
<tableCaption confidence="0.891163">
Table 1: Translating English to Greek: Using a single
translation table may cause sparse data problems, which
are addressed using an alternative path to a second trans-
lation table
</tableCaption>
<sectionHeader confidence="0.998801" genericHeader="evaluation">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999724333333333">
This preprocessing led to annotated source data,
which were given as an input to a factored SMT sys-
tem.
</bodyText>
<subsectionHeader confidence="0.992806">
4.1 Experiment setup
</subsectionHeader>
<bodyText confidence="0.99998825">
For testing the factored translation systems, we used
Moses (Koehn et al., 2007), along with a 5-gram
SRILM language model (Stolcke, 2002). A Greek
model was trained on 440,082 aligned sentences of
Europarl v.3, tuned with Minimum Error Training
(Och, 2003). It was tuned over a development set
of 2,000 Europarl sentences and tested on two sets
of 2,000 sentences each, from the Europarl and a
We tested several various combinations of tags,
while using a single translation component. Some
combinations seem to be affected by sparse data
problems and the best score is achieved by using
both person and case tags. Our full method, using
both factors, was more effective on the second test-
set, but the best score in average was succeeded by
using an alternative path to a POS-factored transla-
tion table (table 1). The NIST metric clearly shows
a significant improvement, because it mostly mea-
sures difficult n-gram matches (e.g. due to the long-
distance rules we have been dealing with).
</bodyText>
<footnote confidence="0.9778495">
1see http://www.statmt.org/wmt07 referring to sets dev2006
(tuning) and devtest2006, test2007 (testing)
</footnote>
<page confidence="0.990686">
767
</page>
<subsectionHeader confidence="0.993728">
4.3 Error analysis
</subsectionHeader>
<bodyText confidence="0.999673636363636">
In n-gram based metrics, the scores for all words are
equally weighted, so mistakes on crucial sentence
constituents may be penalized the same as errors
on redundant or meaningless words (Callison-Burch
et al., 2006). We consider agreement on verbs and
nouns an important factor for the adequacy of the re-
sult, since they adhere more to the semantics of the
sentence. Since we targeted these problems, we con-
ducted a manual error analysis focused on the suc-
cess of the improved system regarding those specific
phenomena.
</bodyText>
<table confidence="0.997093">
system verbs errors missing
baseline 311 19.0% 7.4%
single 295 4.7% 5.4%
alt.path 294 5.4% 2.7%
</table>
<tableCaption confidence="0.955395">
Table 2: Error analysis of 100 test sentences, focused on
</tableCaption>
<table confidence="0.869598666666667">
verb person conjugation, for using both person and case
tags
system NPs errors missing
baseline 469 9.0% 4.9%
single 465 6.2% 4.5%
alt. path 452 6.0% 4.0%
</table>
<tableCaption confidence="0.9964255">
Table 3: Error analysis of 100 test sentences, focused on
noun cases, for using both person and case tags
</tableCaption>
<bodyText confidence="0.999864285714286">
The analysis shows that using a system with only
one phrase translation table caused a high percent-
age of missing or untranslated words. When a word
appears with a tag with which it has not been trained,
that would be considered an unseen event and re-
main untranslated. The use of the alternative path
seems to be a good solution.
</bodyText>
<table confidence="0.92598325">
step parsing tagging decoding
VPs 16.7% 25% 58.3%
NPs 39.2% 21.7% 39.1%
avg 31.4% 22.9% 45.7 %
</table>
<tableCaption confidence="0.932629">
Table 4: Analysis on which step of the translation pro-
cess the agreement errors derive from, based on manual
resolution on the errors of table 3
</tableCaption>
<bodyText confidence="0.987576">
The impact of the preprocessing stage to the er-
rors may be seen in table 4, where errors are tracked
back to the stage they derived from. Apart from the
decoding errors, which may be attributed to sparse
data or other statistical factors, a large part of the
errors derive from the preprocessing step; either the
syntax tree of the sentence was incorrectly or par-
tially resolved, or our labelling process did not cor-
rectly match all possible sub-trees.
</bodyText>
<subsectionHeader confidence="0.972774">
4.4 Investigating applicability to other inflected
languages
</subsectionHeader>
<bodyText confidence="0.999961769230769">
The grammatical phenomena of noun cases and verb
persons are quite common among many human lan-
guages. While the method was tested in Greek, there
was an effort to investigate whether it is useful for
other languages with similar characteristics. For this
reason, the method was adapted for Czech, which
needs agreement on both verb conjugation and 9
noun cases. Dative case was included for the indi-
rect object and the rules of the prepositional phrases
were adapted to tag all three cases that can be verb
phrase constituents. The Czech noun cases which
appear only in prepositional phrases were ignored,
since they are covered by the phrase-based model.
</bodyText>
<table confidence="0.989972444444444">
BLUE NIST
set devtest test devtest test
baseline 12.08 12.34 4.634 4.865
person+case 11.98 11.99 4.584 4.801
altpath:POS
person 12.23 12.11 4.647 4.846
altpath:word
case 12.54 12.51 4.758 4.957
altpath:word
</table>
<tableCaption confidence="0.71039125">
Table 5: Enriching source data can be useful when trans-
lating from English to Czech, since it is a morpholog-
ically rich language. Experiments shown improvement
when using factors on noun-cases with an alternative path
</tableCaption>
<bodyText confidence="0.999113857142857">
In Czech, due to the small size of the corpus, it
was possible to improve metric scores only by using
an alternative path to a bare word-to-word transla-
tion table. Combining case and verb tags worsened
the results, which suggests that, while applying the
method to more languages, a different use of the at-
tributes may be beneficial for each of them.
</bodyText>
<page confidence="0.996977">
768
</page>
<sectionHeader confidence="0.994265" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999785">
In this paper we have shown how SMT performance
can be improved, when translating from English
into morphologically richer languages, by adding
linguistic information on the source. Although the
source language misses morphology attributes re-
quired by the target language, the needed infor-
mation is inherent in the syntactic structure of the
source sentence. Therefore, we have shown that
this information can be easily be included in a SMT
model by preprocessing the source text.
Our method focuses on two linguistic phenomena
which produce common errors on the output and are
important constituents of the sentence. In partic-
ular, noun cases and verb persons are required by
the target language, but not directly inferred by the
source. For each of the sub-problems, our algorithm
used heuristic syntax-based rules on the statistically
generated syntax tree of each sentence, in order to
address the missing information, which was conse-
quently tagged in by means of word factors. This
information was proven to improve the outcome of
a factored SMT model, by reducing the grammatical
agreement errors on the generated sentences.
An initial system using one translation table with
additional source side factors caused sparse data
problems, due to the increased number of unseen
word-factor combinations. Therefore, the decoding
process is given an alternative path towards a trans-
lation table with less or no factors.
The method was tested on translating from En-
glish into two morphologically rich languages. Note
that this may be easily expanded for translating from
English into many morphologically richer languages
with similar attributes. Opposed to other factored
translation model approaches that require target lan-
guage factors, that are not easily obtainable for many
languages, our approach only requires English syn-
tax trees, which are acquired with widely avail-
able automatic parsers. The preprocessing scripts
were adapted so that they provide the morphology
attributes required by the target language and the
best combination of factors and alternative paths was
chosen.
</bodyText>
<sectionHeader confidence="0.99549" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9998945">
This work was supported in part under the Euro-
Matrix project funded by the European Commission
(6th Framework Programme). Many thanks to Josh
Schroeder for preparing the training, development
and test data for Greek, in accordance to the stan-
dards of ACL 2007 2nd Workshop on SMT; to Hieu
Hoang, Alexandra Birch and all the members of
the Edinburgh University SMT group for answering
questions, making suggestions and providing sup-
port.
</bodyText>
<sectionHeader confidence="0.998951" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998685714285714">
Birch, A., Osborne, M., and Koehn, P. 2007. CCG
Supertags in factored Statistical Machine Translation.
In Proceedings of the Second Workshop on Statistical
Machine Translation, pages 9–16, Prague, Czech Re-
public. Association for Computational Linguistics.
Brill, E. 1992. A simple rule-based part of speech tag-
ger. Proceedings of the Third Conference on Applied
Natural Language Processing, pages 152–155.
Callison-Burch, C., Osborne, M., and Koehn, P. 2006.
Re-evaluation the role of bleu in machine translation
research. In Proceedings of the 11th Conference of
the European Chapter of the Association for Computa-
tional Linguistics. The Association for Computer Lin-
guistics.
Carpuat, M. and Wu, D. 2007. Improving Statistical Ma-
chine Translation using Word Sense Disambiguation.
In Proceedings of the Joint Conference on Empirical
Methods in Natural Language Processing and Compu-
tational Natural Language Learning (EMNLP-CoNLL
2007), pages 61–72, Prague, Czech Republic.
Carreras, X. and Marquez, L. 2005. Introduction to the
CoNLL-2005 Shared Task: Semantic Role Labeling.
In Proceedings of 9th Conference on Computational
Natural Language Learning (CoNLL), pages 169–172,
Ann Arbor, Michigan, USA.
Collins, M. 1997. Three generative, lexicalised models
for statistical parsing. Proceedings of the 35th con-
ference on Association for Computational Linguistics,
pages 16–23.
Collins, M., Koehn, P., and Kuˇcerová, I. 2005. Clause re-
structuring for statistical machine translation. In ACL
’05: Proceedings of the 43rd Annual Meeting on Asso-
ciation for Computational Linguistics, pages 531–540,
Morristown, NJ, USA. Association for Computational
Linguistics.
</reference>
<page confidence="0.991151">
769
</page>
<reference confidence="0.999264629629629">
Durgar El-Kahlout, i. and Oflazer, K. 2006. Initial explo-
rations in english to turkish statistical machine trans-
lation. In Proceedings on the Workshop on Statistical
Machine Translation, pages 7–14, New York City. As-
sociation for Computational Linguistics.
Habash, N., Gabbard, R., Rambow, O., Kulick, S., and
Marcus, M. 2007. Determining case in Arabic: Learn-
ing complex linguistic behavior requires complex lin-
guistic features. In Proceedings of the 2007 Joint
Conference on Empirical Methods in Natural Lan-
guage Processing and Computational Natural Lan-
guage Learning (EMNLP-CoNLL), pages 1084–1092.
Habash, N. and Sadat, F. 2006. Arabic preprocessing
schemes for statistical machine translation. In Pro-
ceedings of the Human Language Technology Confer-
ence of the NAAC L, Companion Volume: Short Pa-
pers, pages 49–52, New York City, USA. Association
for Computational Linguistics.
Huang, L., Knight, K., and Joshi, A. 2006. Statistical
syntax-directed translation with extended domain of
locality. Proc. AMTA, pages 66–73.
Koehn, P. 2005. Europarl: A parallel corpus for statistical
machine translation. MT Summit, 5.
Koehn, P. and Hoang, H. 2007. Factored translation
models. In Proceedings of the 2007 Joint Conference
on Empirical Methods in Natural Language Process-
ing and Computational Natural Language Learning
(EMNLP-CoNLL), pages 868–876.
Koehn, P., Hoang, H., Birch, A., Callison-Burch, C., Fed-
erico, M., Bertoldi, N., Cowan, B., Shen, W., Moran,
C., Zens, R., Dyer, C., Bojar, O., Constantin, A.,
and Herbst, E. 2007. Moses: Open source toolkit
for statistical machine translation. In Proceedings of
the 45th Annual Meeting of the Association for Com-
putational Linguistics Companion Volume Proceed-
ings of the Demo and Poster Sessions, pages 177–
180, Prague, Czech Republic. Association for Com-
putational Linguistics.
Minkov, E., Toutanova, K., and Suzuki, H. 2007. Gen-
erating complex morphology for machine translation.
In ACL 07: Proceedings of the 45th Annual Meet-
ing of the Association of Computational linguistics,
pages 128–135, Prague, Czech Republic. Association
for Computational Linguistics.
NIST 2002. Automatic evaluation of machine translation
quality using n-gram co-occurrence statistics.
Och, F. J. 2003. Minimum error rate training in statisti-
cal machine translation. In ACL ’03: Proceedings of
the 41st Annual Meeting on Association for Compu-
tational Linguistics, pages 160–167, Morristown, NJ,
USA. Association for Computational Linguistics.
Papineni, K., Roukos, S., Ward, T., and Zhu, W.-J. 2001.
BLEU: a method for automatic evaluation of machine
translation. In ACL ’02: Proceedings of the 40th An-
nual Meeting on Association for Computational Lin-
guistics, pages 311–318, Morristown, NJ, USA. Asso-
ciation for Computational Linguistics.
Stolcke, A. 2002. SRILM-an extensible language model-
ing toolkit. Proc. ICSLP, 2:901–904.
Surdeanu, M. and Turmo, J. 2005. Semantic Role Label-
ing Using Complete Syntactic Analysis. In Proceed-
ings of 9th Conference on Computational Natural Lan-
guage Learning (CoNLL), pages 221–224, Ann Arbor,
Michigan, USA.
Ueffing, N. and Ney, H. 2003. Using pos information
for statistical machine translation into morphologically
rich languages. In EACL ’03: Proceedings of the
tenth conference on European chapter of the Associ-
ation for Computational Linguistics, pages 347–354,
Morristown, NJ, USA. Association for Computational
Linguistics.
Vilar, D., Xu, J., D’Haro, L. F., and Ney, H. 2006. Error
Analysis of Machine Translation Output. In Proceed-
ings of the 5th Internation Conference on Language
Resources and Evaluation (LREC’06), pages 697–702,
Genoa, Italy.
Yamada, K. and Knight, K. 2001. A syntax-based statis-
tical translation model. In ACL ’01: Proceedings of
the 39th Annual Meeting on Association for Compu-
tational Linguistics, pages 523–530, Morristown, NJ,
USA. Association for Computational Linguistics.
</reference>
<page confidence="0.997114">
770
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.364751">
<title confidence="0.999741">Enriching Morphologically Poor Languages for Statistical Machine Translation</title>
<author confidence="0.982827">Eleftherios Avramidis Philipp Koehn</author>
<email confidence="0.880057">e.avramidis@sms.ed.ac.ukpkoehn@inf.ed.ac.uk</email>
<affiliation confidence="0.887992333333333">School of Informatics University of Edinburgh 2 Baccleuch Place</affiliation>
<address confidence="0.995957">Edinburgh, EH8 9LW, UK</address>
<abstract confidence="0.988970583333333">We address the problem of translating from morphologically poor to morphologically rich languages by adding per-word linguistic information to the source language. We use the syntax of the source sentence to extract information for noun cases and verb persons and annotate the corresponding words accordingly. In experiments, we show improved performance for translating from English into Greek and Czech. For English–Greek, we reduce the error on the verb conjugation from</abstract>
<note confidence="0.802401">19% to 5.4% and noun case agreement from 9% to 6%.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Birch</author>
<author>M Osborne</author>
<author>P Koehn</author>
</authors>
<title>CCG Supertags in factored Statistical Machine Translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the Second Workshop on Statistical Machine Translation,</booktitle>
<pages>9--16</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="6868" citStr="Birch et al. (2007)" startWordPosition="1065" endWordPosition="1068">s with morphotactical knowledge. Habash et al. (2007) also investigated case determination in Arabic. Carpuat and Wu (2007) approached the issue as a Word Sense Disambiguation problem. In their presentation of the factored SMT models, Koehn and Hoang (2007) describe experiments for translating from English to German, Spanish and Czech, using morphology tags added on the morphologically rich side, along with POS tags. The morphological factors are added on the morphologically rich side and scored with a 7-gram sequence model. Probabilistic models for using only source tags were investigated by Birch et al. (2007), who attached syntax hints in factored SMT models by having Combinatorial Categorial Grammar (CCG) supertags as factors on the input words, but in this case English was the target language. This paper reports work that strictly focuses on translation from English to a morphologically richer language. We go one step further than just using easily acquired information (e.g. English POS or lemmata) and extract target-specific information from the source sentence context. We use syntax, not in 764 Figure 2: Classification of the errors on our EnglishGreek baseline system (ch. 4.1), as suggested b</context>
<context position="14315" citStr="Birch et al. (2007)" startWordPosition="2345" endWordPosition="2348">he several tran slation components based on the output factors, we use only source factors; 766 therefore we don’t need a generation step to combine the probabilities of the several components. Instead, factors are added so that both words and its factor(s) are assigned the same probability. Of course, when there is not 1-1 mapping between the word+factor splice on the source and the inflected word on the target, the well-known issue of sparse data arises. In order to reduce these problems, decoding needed to consider alternative paths to translation tables trained with less or no factors (as Birch et al. (2007) suggested), so as to cover instances where a word appears with a factor which it has not been trained with. This is similar to back-off. The alternative paths are combined as following (fig. 5): hT (f|e) = � hTt(j)(ej, fj) (3) j where each phrase j is translated by one translation table t(j) and each table i has a feature function hTa. as shown in eq. (2). Figure 5: Decoding using an alternative path with different factorization News Commentary respectively, following the specifications made by the ACL 2007 2nd Workshop on SMT1. A Czech model was trained on 57,464 aligned sentences, tuned ove</context>
</contexts>
<marker>Birch, Osborne, Koehn, 2007</marker>
<rawString>Birch, A., Osborne, M., and Koehn, P. 2007. CCG Supertags in factored Statistical Machine Translation. In Proceedings of the Second Workshop on Statistical Machine Translation, pages 9–16, Prague, Czech Republic. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Brill</author>
</authors>
<title>A simple rule-based part of speech tagger.</title>
<date>1992</date>
<booktitle>Proceedings of the Third Conference on Applied Natural Language Processing,</booktitle>
<pages>152--155</pages>
<contexts>
<context position="15378" citStr="Brill, 1992" startWordPosition="2526" endWordPosition="2527">espectively, following the specifications made by the ACL 2007 2nd Workshop on SMT1. A Czech model was trained on 57,464 aligned sentences, tuned over 1057 sentences of the News Commentary corpus and and tested on two sets of 964 sentences and 2000 sentences respectively. The training sentences were trimmed to a length of 60 words for reducing perplexity and a standard lexicalised reordering, with distortion limit set to 6. For getting the syntax trees, the latest version of Collins’ parser (Collins, 1997) was used. When needed, part-of-speech (POS) tags were acquired by using Brill’s tagger (Brill, 1992) on v1.14. Results were evaluated with both BLEU (Papineni et al., 2001) and NIST metrics (NIST, 2002). 4.2 Results BLEU NIST set devtest test07 devtest test07 baseline 18.13 18.05 5.218 5.279 person 18.16 18.17 5.224 5.316 pos+person 18.14 18.16 5.259 5.316 person+case 18.08 18.24 5.258 5.340 altpath:POS 18.21 18.20 5.285 5.340 Table 1: Translating English to Greek: Using a single translation table may cause sparse data problems, which are addressed using an alternative path to a second translation table 4 Experiments This preprocessing led to annotated source data, which were given as an inp</context>
</contexts>
<marker>Brill, 1992</marker>
<rawString>Brill, E. 1992. A simple rule-based part of speech tagger. Proceedings of the Third Conference on Applied Natural Language Processing, pages 152–155.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Callison-Burch</author>
<author>M Osborne</author>
<author>P Koehn</author>
</authors>
<title>Re-evaluation the role of bleu in machine translation research.</title>
<date>2006</date>
<booktitle>In Proceedings of the 11th Conference of the European Chapter of the Association</booktitle>
<institution>for Computational Linguistics. The Association for Computer Linguistics.</institution>
<contexts>
<context position="17359" citStr="Callison-Burch et al., 2006" startWordPosition="2842" endWordPosition="2845">best score in average was succeeded by using an alternative path to a POS-factored translation table (table 1). The NIST metric clearly shows a significant improvement, because it mostly measures difficult n-gram matches (e.g. due to the longdistance rules we have been dealing with). 1see http://www.statmt.org/wmt07 referring to sets dev2006 (tuning) and devtest2006, test2007 (testing) 767 4.3 Error analysis In n-gram based metrics, the scores for all words are equally weighted, so mistakes on crucial sentence constituents may be penalized the same as errors on redundant or meaningless words (Callison-Burch et al., 2006). We consider agreement on verbs and nouns an important factor for the adequacy of the result, since they adhere more to the semantics of the sentence. Since we targeted these problems, we conducted a manual error analysis focused on the success of the improved system regarding those specific phenomena. system verbs errors missing baseline 311 19.0% 7.4% single 295 4.7% 5.4% alt.path 294 5.4% 2.7% Table 2: Error analysis of 100 test sentences, focused on verb person conjugation, for using both person and case tags system NPs errors missing baseline 469 9.0% 4.9% single 465 6.2% 4.5% alt. path </context>
</contexts>
<marker>Callison-Burch, Osborne, Koehn, 2006</marker>
<rawString>Callison-Burch, C., Osborne, M., and Koehn, P. 2006. Re-evaluation the role of bleu in machine translation research. In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics. The Association for Computer Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Carpuat</author>
<author>D Wu</author>
</authors>
<title>Improving Statistical Machine Translation using Word Sense Disambiguation.</title>
<date>2007</date>
<booktitle>In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</booktitle>
<pages>61--72</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="6372" citStr="Carpuat and Wu (2007)" startWordPosition="986" endWordPosition="989"> features, in order to ensure grammatical agreement on the output. The method, using various grammatical source-side features, achieved higher accuracy when applied directly to the reference translations but it was not tested as a part of an MT system. Similarly, translating English into Turkish (Durgar El-Kahlout and Oflazer, 2006) uses POS and morph stems in the input along with rich Turkish morph tags on the target side, but improvement was gained only after augmenting the generation process with morphotactical knowledge. Habash et al. (2007) also investigated case determination in Arabic. Carpuat and Wu (2007) approached the issue as a Word Sense Disambiguation problem. In their presentation of the factored SMT models, Koehn and Hoang (2007) describe experiments for translating from English to German, Spanish and Czech, using morphology tags added on the morphologically rich side, along with POS tags. The morphological factors are added on the morphologically rich side and scored with a 7-gram sequence model. Probabilistic models for using only source tags were investigated by Birch et al. (2007), who attached syntax hints in factored SMT models by having Combinatorial Categorial Grammar (CCG) supe</context>
</contexts>
<marker>Carpuat, Wu, 2007</marker>
<rawString>Carpuat, M. and Wu, D. 2007. Improving Statistical Machine Translation using Word Sense Disambiguation. In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL 2007), pages 61–72, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Carreras</author>
<author>L Marquez</author>
</authors>
<title>Introduction to the CoNLL-2005 Shared Task: Semantic Role Labeling.</title>
<date>2005</date>
<booktitle>In Proceedings of 9th Conference on Computational Natural Language Learning (CoNLL),</booktitle>
<pages>169--172</pages>
<location>Ann Arbor, Michigan, USA.</location>
<contexts>
<context position="8932" citStr="Carreras and Marquez, 2005" startWordPosition="1402" endWordPosition="1405"> Figure 2). Moreover, these types of inflection signify the constituents of every phrase, tightly linked to the meaning of the sentence. 2.1 Case agreement The case agreement for nouns, adjectives and articles is mainly defined by the syntactic role that each noun phrase has. Nominative case is used to define the nouns which are the subject of the sentence, accusative shows usually the direct object of the verbs and dative case refers to the indirect object of bitransitive verbs. Therefore, the followed approach takes advantage of syntax, following a method similar to Semantic Role Labelling (Carreras and Marquez, 2005; Surdeanu and Turmo, 2005). English, as morphologically poor language, usually follows a fixed word order (subject-verb-object), so that a syntax parser can be easily used for identifying the subject and the object of most sentences. Considering such annotation, a factored translation model is trained to map the word-case pair to the correct inflection of the target noun. Given the agreement restriction, all words that accompany the noun (adjectives, articles, determiners) must follow the case of the noun, so their likely case needs to be identified as well. For this purpose we use a syntax p</context>
</contexts>
<marker>Carreras, Marquez, 2005</marker>
<rawString>Carreras, X. and Marquez, L. 2005. Introduction to the CoNLL-2005 Shared Task: Semantic Role Labeling. In Proceedings of 9th Conference on Computational Natural Language Learning (CoNLL), pages 169–172, Ann Arbor, Michigan, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
</authors>
<title>Three generative, lexicalised models for statistical parsing.</title>
<date>1997</date>
<booktitle>Proceedings of the 35th conference on Association for Computational Linguistics,</booktitle>
<pages>16--23</pages>
<contexts>
<context position="15277" citStr="Collins, 1997" startWordPosition="2511" endWordPosition="2512">in eq. (2). Figure 5: Decoding using an alternative path with different factorization News Commentary respectively, following the specifications made by the ACL 2007 2nd Workshop on SMT1. A Czech model was trained on 57,464 aligned sentences, tuned over 1057 sentences of the News Commentary corpus and and tested on two sets of 964 sentences and 2000 sentences respectively. The training sentences were trimmed to a length of 60 words for reducing perplexity and a standard lexicalised reordering, with distortion limit set to 6. For getting the syntax trees, the latest version of Collins’ parser (Collins, 1997) was used. When needed, part-of-speech (POS) tags were acquired by using Brill’s tagger (Brill, 1992) on v1.14. Results were evaluated with both BLEU (Papineni et al., 2001) and NIST metrics (NIST, 2002). 4.2 Results BLEU NIST set devtest test07 devtest test07 baseline 18.13 18.05 5.218 5.279 person 18.16 18.17 5.224 5.316 pos+person 18.14 18.16 5.259 5.316 person+case 18.08 18.24 5.258 5.340 altpath:POS 18.21 18.20 5.285 5.340 Table 1: Translating English to Greek: Using a single translation table may cause sparse data problems, which are addressed using an alternative path to a second transl</context>
</contexts>
<marker>Collins, 1997</marker>
<rawString>Collins, M. 1997. Three generative, lexicalised models for statistical parsing. Proceedings of the 35th conference on Association for Computational Linguistics, pages 16–23.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
<author>P Koehn</author>
<author>I Kuˇcerová</author>
</authors>
<title>Clause restructuring for statistical machine translation.</title>
<date>2005</date>
<booktitle>In ACL ’05: Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>531--540</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<marker>Collins, Koehn, Kuˇcerová, 2005</marker>
<rawString>Collins, M., Koehn, P., and Kuˇcerová, I. 2005. Clause restructuring for statistical machine translation. In ACL ’05: Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, pages 531–540, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Durgar El-Kahlout</author>
<author>i</author>
<author>K Oflazer</author>
</authors>
<title>Initial explorations in english to turkish statistical machine translation.</title>
<date>2006</date>
<booktitle>In Proceedings on the Workshop on Statistical Machine Translation,</booktitle>
<pages>7--14</pages>
<institution>City. Association for Computational Linguistics.</institution>
<location>New York</location>
<marker>El-Kahlout, i, Oflazer, 2006</marker>
<rawString>Durgar El-Kahlout, i. and Oflazer, K. 2006. Initial explorations in english to turkish statistical machine translation. In Proceedings on the Workshop on Statistical Machine Translation, pages 7–14, New York City. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Habash</author>
<author>R Gabbard</author>
<author>O Rambow</author>
<author>S Kulick</author>
<author>M Marcus</author>
</authors>
<title>Determining case in Arabic: Learning complex linguistic behavior requires complex linguistic features.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL),</booktitle>
<pages>1084--1092</pages>
<contexts>
<context position="6302" citStr="Habash et al. (2007)" startWordPosition="975" endWordPosition="978">ested a post-processing system which uses morphological and syntactic features, in order to ensure grammatical agreement on the output. The method, using various grammatical source-side features, achieved higher accuracy when applied directly to the reference translations but it was not tested as a part of an MT system. Similarly, translating English into Turkish (Durgar El-Kahlout and Oflazer, 2006) uses POS and morph stems in the input along with rich Turkish morph tags on the target side, but improvement was gained only after augmenting the generation process with morphotactical knowledge. Habash et al. (2007) also investigated case determination in Arabic. Carpuat and Wu (2007) approached the issue as a Word Sense Disambiguation problem. In their presentation of the factored SMT models, Koehn and Hoang (2007) describe experiments for translating from English to German, Spanish and Czech, using morphology tags added on the morphologically rich side, along with POS tags. The morphological factors are added on the morphologically rich side and scored with a 7-gram sequence model. Probabilistic models for using only source tags were investigated by Birch et al. (2007), who attached syntax hints in fac</context>
</contexts>
<marker>Habash, Gabbard, Rambow, Kulick, Marcus, 2007</marker>
<rawString>Habash, N., Gabbard, R., Rambow, O., Kulick, S., and Marcus, M. 2007. Determining case in Arabic: Learning complex linguistic behavior requires complex linguistic features. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), pages 1084–1092.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Habash</author>
<author>F Sadat</author>
</authors>
<title>Arabic preprocessing schemes for statistical machine translation.</title>
<date>2006</date>
<booktitle>In Proceedings of the Human Language Technology Conference of the NAAC L, Companion Volume: Short Papers,</booktitle>
<pages>49--52</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>New York City, USA.</location>
<contexts>
<context position="1421" citStr="Habash and Sadat, 2006" startWordPosition="210" endWordPosition="213">itional statistical machine translation methods are based on mapping on the lexical level, which takes place in a local window of a few words. Hence, they fail to produce adequate output in many cases where more complex linguistic phenomena play a role. Take the example of morphology. Predicting the correct morphological variant for a target word may not depend solely on the source words, but require additional information about its role in the sentence. Recent research on handling rich morphology has largely focused on translating from rich morphology languages, such as Arabic, into English (Habash and Sadat, 2006). There has been less work on the opposite case, translating from English into morphologically richer languages. In a study of translation quality for languages in the Europarl corpus, Koehn (2005) reports that translating into morphologically richer languages is more difficult than translating from them. There are intuitive reasons why generating richer morphology from morphologically poor languages is harder. Take the example of translating noun phrases from English to Greek (or German, Czech, etc.). In English, a noun phrase is rendered the same if it is the subject or the object. However, </context>
</contexts>
<marker>Habash, Sadat, 2006</marker>
<rawString>Habash, N. and Sadat, F. 2006. Arabic preprocessing schemes for statistical machine translation. In Proceedings of the Human Language Technology Conference of the NAAC L, Companion Volume: Short Papers, pages 49–52, New York City, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Huang</author>
<author>K Knight</author>
<author>A Joshi</author>
</authors>
<title>Statistical syntax-directed translation with extended domain of locality.</title>
<date>2006</date>
<booktitle>Proc. AMTA,</booktitle>
<pages>66--73</pages>
<contexts>
<context position="7581" citStr="Huang et al., 2006" startWordPosition="1181" endWordPosition="1184">(CCG) supertags as factors on the input words, but in this case English was the target language. This paper reports work that strictly focuses on translation from English to a morphologically richer language. We go one step further than just using easily acquired information (e.g. English POS or lemmata) and extract target-specific information from the source sentence context. We use syntax, not in 764 Figure 2: Classification of the errors on our EnglishGreek baseline system (ch. 4.1), as suggested by Vilar et al. (2006) order to aid reordering (Yamada and Knight, 2001; Collins et al., 2005; Huang et al., 2006), but as a means for getting the “missing” morphology information, depending on the syntactic position of the words of interest. Then, contrary to the methods that added only output features or altered the generation procedure, we used this information in order to augment only the source side of a factored translation model, assuming that we do not have resources allowing factors or specialized generation in the target language (a common problem, when translating from English into under-resourced languages). 2 Methods for enriching input We selected to focus on noun cases agreement and verb pe</context>
</contexts>
<marker>Huang, Knight, Joshi, 2006</marker>
<rawString>Huang, L., Knight, K., and Joshi, A. 2006. Statistical syntax-directed translation with extended domain of locality. Proc. AMTA, pages 66–73.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
</authors>
<title>Europarl: A parallel corpus for statistical machine translation.</title>
<date>2005</date>
<journal>MT Summit,</journal>
<volume>5</volume>
<contexts>
<context position="1618" citStr="Koehn (2005)" startWordPosition="244" endWordPosition="245">ore complex linguistic phenomena play a role. Take the example of morphology. Predicting the correct morphological variant for a target word may not depend solely on the source words, but require additional information about its role in the sentence. Recent research on handling rich morphology has largely focused on translating from rich morphology languages, such as Arabic, into English (Habash and Sadat, 2006). There has been less work on the opposite case, translating from English into morphologically richer languages. In a study of translation quality for languages in the Europarl corpus, Koehn (2005) reports that translating into morphologically richer languages is more difficult than translating from them. There are intuitive reasons why generating richer morphology from morphologically poor languages is harder. Take the example of translating noun phrases from English to Greek (or German, Czech, etc.). In English, a noun phrase is rendered the same if it is the subject or the object. However, Greek words in noun phrases are inflected based on their role in the sentence. A purely lexical mapping of English noun phrases to Greek noun phrases suffers from the lack of information about its </context>
</contexts>
<marker>Koehn, 2005</marker>
<rawString>Koehn, P. 2005. Europarl: A parallel corpus for statistical machine translation. MT Summit, 5.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>H Hoang</author>
</authors>
<title>Factored translation models.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL),</booktitle>
<pages>868--876</pages>
<contexts>
<context position="6506" citStr="Koehn and Hoang (2007)" startWordPosition="1008" endWordPosition="1011">ed higher accuracy when applied directly to the reference translations but it was not tested as a part of an MT system. Similarly, translating English into Turkish (Durgar El-Kahlout and Oflazer, 2006) uses POS and morph stems in the input along with rich Turkish morph tags on the target side, but improvement was gained only after augmenting the generation process with morphotactical knowledge. Habash et al. (2007) also investigated case determination in Arabic. Carpuat and Wu (2007) approached the issue as a Word Sense Disambiguation problem. In their presentation of the factored SMT models, Koehn and Hoang (2007) describe experiments for translating from English to German, Spanish and Czech, using morphology tags added on the morphologically rich side, along with POS tags. The morphological factors are added on the morphologically rich side and scored with a 7-gram sequence model. Probabilistic models for using only source tags were investigated by Birch et al. (2007), who attached syntax hints in factored SMT models by having Combinatorial Categorial Grammar (CCG) supertags as factors on the input words, but in this case English was the target language. This paper reports work that strictly focuses o</context>
<context position="13383" citStr="Koehn and Hoang, 2007" startWordPosition="2182" endWordPosition="2185">ently, it recursively browses the preceding NPB so as to get the subject of the sentence. The word “aspects” is found, which has a POS tag that shows it is a plural noun. Therefore, we consider the subject to be of the third person in plural (tagged by they) which is recursively passed to the children of the head node. 3 Factored Model The factored statistical machine translation model uses a log-linear approach, in order to combine the several components, including the language model, the reordering model, the translation models and the generation models. The model is defined mathematically (Koehn and Hoang, 2007) as following: �n aihi(f, e) (1) 1 p(f|e) = Z exp i=1 where is a vector of weights determined during a tuning process, and hi is the feature function. The feature function for a translation probability distri Ai - bution is hT(f|e) = � ) (2) j T(ej, fj While factored models may use a generation step to combine the several tran slation components based on the output factors, we use only source factors; 766 therefore we don’t need a generation step to combine the probabilities of the several components. Instead, factors are added so that both words and its factor(s) are assigned the same probabi</context>
</contexts>
<marker>Koehn, Hoang, 2007</marker>
<rawString>Koehn, P. and Hoang, H. 2007. Factored translation models. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), pages 868–876.</rawString>
</citation>
<citation valid="false">
<authors>
<author>P Koehn</author>
<author>H Hoang</author>
<author>A Birch</author>
<author>C Callison-Burch</author>
<author>M Federico</author>
<author>N Bertoldi</author>
<author>B Cowan</author>
<author>W Shen</author>
<author>C Moran</author>
<author>R Zens</author>
<author>C Dyer</author>
<author>O Bojar</author>
<author>A Constantin</author>
<author>E Herbst</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions,</booktitle>
<pages>177--180</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="16108" citStr="Koehn et al., 2007" startWordPosition="2641" endWordPosition="2644">ults BLEU NIST set devtest test07 devtest test07 baseline 18.13 18.05 5.218 5.279 person 18.16 18.17 5.224 5.316 pos+person 18.14 18.16 5.259 5.316 person+case 18.08 18.24 5.258 5.340 altpath:POS 18.21 18.20 5.285 5.340 Table 1: Translating English to Greek: Using a single translation table may cause sparse data problems, which are addressed using an alternative path to a second translation table 4 Experiments This preprocessing led to annotated source data, which were given as an input to a factored SMT system. 4.1 Experiment setup For testing the factored translation systems, we used Moses (Koehn et al., 2007), along with a 5-gram SRILM language model (Stolcke, 2002). A Greek model was trained on 440,082 aligned sentences of Europarl v.3, tuned with Minimum Error Training (Och, 2003). It was tuned over a development set of 2,000 Europarl sentences and tested on two sets of 2,000 sentences each, from the Europarl and a We tested several various combinations of tags, while using a single translation component. Some combinations seem to be affected by sparse data problems and the best score is achieved by using both person and case tags. Our full method, using both factors, was more effective on the s</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, Dyer, Bojar, Constantin, Herbst, 2007</marker>
<rawString>Koehn, P., Hoang, H., Birch, A., Callison-Burch, C., Federico, M., Bertoldi, N., Cowan, B., Shen, W., Moran, C., Zens, R., Dyer, C., Bojar, O., Constantin, A., and Herbst, E. 2007. Moses: Open source toolkit for statistical machine translation. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions, pages 177– 180, Prague, Czech Republic. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Minkov</author>
<author>K Toutanova</author>
<author>H Suzuki</author>
</authors>
<title>Generating complex morphology for machine translation.</title>
<date>2007</date>
<booktitle>In ACL 07: Proceedings of the 45th Annual Meeting of the Association of Computational linguistics,</booktitle>
<pages>128--135</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="5677" citStr="Minkov et al. (2007)" startWordPosition="880" endWordPosition="883"> the chunks that are translated (see Figure 1 for an example). In one of the first efforts to enrich the source in word-based SMT, Ueffing and Ney (2003) used partof-speech (POS) tags, in order to deal with the verb conjugation of Spanish and Catalan; so, POS tags were used to identify the pronoun+verb sequence and splice these two words into one term. The approach was clearly motivated by the problems occurring by a single-word-based SMT and have been solved by adopting a phrase-based model. Meanwhile, there is no handling of the case when the pronoun stays in distance with the related verb. Minkov et al. (2007) suggested a post-processing system which uses morphological and syntactic features, in order to ensure grammatical agreement on the output. The method, using various grammatical source-side features, achieved higher accuracy when applied directly to the reference translations but it was not tested as a part of an MT system. Similarly, translating English into Turkish (Durgar El-Kahlout and Oflazer, 2006) uses POS and morph stems in the input along with rich Turkish morph tags on the target side, but improvement was gained only after augmenting the generation process with morphotactical knowle</context>
</contexts>
<marker>Minkov, Toutanova, Suzuki, 2007</marker>
<rawString>Minkov, E., Toutanova, K., and Suzuki, H. 2007. Generating complex morphology for machine translation. In ACL 07: Proceedings of the 45th Annual Meeting of the Association of Computational linguistics, pages 128–135, Prague, Czech Republic. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>NIST</author>
</authors>
<title>Automatic evaluation of machine translation quality using n-gram co-occurrence statistics.</title>
<date>2002</date>
<contexts>
<context position="15480" citStr="NIST, 2002" startWordPosition="2543" endWordPosition="2544">trained on 57,464 aligned sentences, tuned over 1057 sentences of the News Commentary corpus and and tested on two sets of 964 sentences and 2000 sentences respectively. The training sentences were trimmed to a length of 60 words for reducing perplexity and a standard lexicalised reordering, with distortion limit set to 6. For getting the syntax trees, the latest version of Collins’ parser (Collins, 1997) was used. When needed, part-of-speech (POS) tags were acquired by using Brill’s tagger (Brill, 1992) on v1.14. Results were evaluated with both BLEU (Papineni et al., 2001) and NIST metrics (NIST, 2002). 4.2 Results BLEU NIST set devtest test07 devtest test07 baseline 18.13 18.05 5.218 5.279 person 18.16 18.17 5.224 5.316 pos+person 18.14 18.16 5.259 5.316 person+case 18.08 18.24 5.258 5.340 altpath:POS 18.21 18.20 5.285 5.340 Table 1: Translating English to Greek: Using a single translation table may cause sparse data problems, which are addressed using an alternative path to a second translation table 4 Experiments This preprocessing led to annotated source data, which were given as an input to a factored SMT system. 4.1 Experiment setup For testing the factored translation systems, we use</context>
</contexts>
<marker>NIST, 2002</marker>
<rawString>NIST 2002. Automatic evaluation of machine translation quality using n-gram co-occurrence statistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
</authors>
<title>Minimum error rate training in statistical machine translation.</title>
<date>2003</date>
<booktitle>In ACL ’03: Proceedings of the 41st Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>160--167</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="16285" citStr="Och, 2003" startWordPosition="2671" endWordPosition="2672">tpath:POS 18.21 18.20 5.285 5.340 Table 1: Translating English to Greek: Using a single translation table may cause sparse data problems, which are addressed using an alternative path to a second translation table 4 Experiments This preprocessing led to annotated source data, which were given as an input to a factored SMT system. 4.1 Experiment setup For testing the factored translation systems, we used Moses (Koehn et al., 2007), along with a 5-gram SRILM language model (Stolcke, 2002). A Greek model was trained on 440,082 aligned sentences of Europarl v.3, tuned with Minimum Error Training (Och, 2003). It was tuned over a development set of 2,000 Europarl sentences and tested on two sets of 2,000 sentences each, from the Europarl and a We tested several various combinations of tags, while using a single translation component. Some combinations seem to be affected by sparse data problems and the best score is achieved by using both person and case tags. Our full method, using both factors, was more effective on the second testset, but the best score in average was succeeded by using an alternative path to a POS-factored translation table (table 1). The NIST metric clearly shows a significan</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Och, F. J. 2003. Minimum error rate training in statistical machine translation. In ACL ’03: Proceedings of the 41st Annual Meeting on Association for Computational Linguistics, pages 160–167, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Papineni</author>
<author>S Roukos</author>
<author>T Ward</author>
<author>W-J Zhu</author>
</authors>
<title>BLEU: a method for automatic evaluation of machine translation.</title>
<date>2001</date>
<booktitle>In ACL ’02: Proceedings of the 40th Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>311--318</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="15450" citStr="Papineni et al., 2001" startWordPosition="2536" endWordPosition="2539"> 2nd Workshop on SMT1. A Czech model was trained on 57,464 aligned sentences, tuned over 1057 sentences of the News Commentary corpus and and tested on two sets of 964 sentences and 2000 sentences respectively. The training sentences were trimmed to a length of 60 words for reducing perplexity and a standard lexicalised reordering, with distortion limit set to 6. For getting the syntax trees, the latest version of Collins’ parser (Collins, 1997) was used. When needed, part-of-speech (POS) tags were acquired by using Brill’s tagger (Brill, 1992) on v1.14. Results were evaluated with both BLEU (Papineni et al., 2001) and NIST metrics (NIST, 2002). 4.2 Results BLEU NIST set devtest test07 devtest test07 baseline 18.13 18.05 5.218 5.279 person 18.16 18.17 5.224 5.316 pos+person 18.14 18.16 5.259 5.316 person+case 18.08 18.24 5.258 5.340 altpath:POS 18.21 18.20 5.285 5.340 Table 1: Translating English to Greek: Using a single translation table may cause sparse data problems, which are addressed using an alternative path to a second translation table 4 Experiments This preprocessing led to annotated source data, which were given as an input to a factored SMT system. 4.1 Experiment setup For testing the factor</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2001</marker>
<rawString>Papineni, K., Roukos, S., Ward, T., and Zhu, W.-J. 2001. BLEU: a method for automatic evaluation of machine translation. In ACL ’02: Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, pages 311–318, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Stolcke</author>
</authors>
<title>SRILM-an extensible language modeling toolkit.</title>
<date>2002</date>
<booktitle>Proc. ICSLP,</booktitle>
<pages>2--901</pages>
<contexts>
<context position="16166" citStr="Stolcke, 2002" startWordPosition="2652" endWordPosition="2653"> 18.05 5.218 5.279 person 18.16 18.17 5.224 5.316 pos+person 18.14 18.16 5.259 5.316 person+case 18.08 18.24 5.258 5.340 altpath:POS 18.21 18.20 5.285 5.340 Table 1: Translating English to Greek: Using a single translation table may cause sparse data problems, which are addressed using an alternative path to a second translation table 4 Experiments This preprocessing led to annotated source data, which were given as an input to a factored SMT system. 4.1 Experiment setup For testing the factored translation systems, we used Moses (Koehn et al., 2007), along with a 5-gram SRILM language model (Stolcke, 2002). A Greek model was trained on 440,082 aligned sentences of Europarl v.3, tuned with Minimum Error Training (Och, 2003). It was tuned over a development set of 2,000 Europarl sentences and tested on two sets of 2,000 sentences each, from the Europarl and a We tested several various combinations of tags, while using a single translation component. Some combinations seem to be affected by sparse data problems and the best score is achieved by using both person and case tags. Our full method, using both factors, was more effective on the second testset, but the best score in average was succeeded</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Stolcke, A. 2002. SRILM-an extensible language modeling toolkit. Proc. ICSLP, 2:901–904.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Surdeanu</author>
<author>J Turmo</author>
</authors>
<title>Semantic Role Labeling Using Complete Syntactic Analysis.</title>
<date>2005</date>
<booktitle>In Proceedings of 9th Conference on Computational Natural Language Learning (CoNLL),</booktitle>
<pages>221--224</pages>
<location>Ann Arbor, Michigan, USA.</location>
<contexts>
<context position="8959" citStr="Surdeanu and Turmo, 2005" startWordPosition="1406" endWordPosition="1410">types of inflection signify the constituents of every phrase, tightly linked to the meaning of the sentence. 2.1 Case agreement The case agreement for nouns, adjectives and articles is mainly defined by the syntactic role that each noun phrase has. Nominative case is used to define the nouns which are the subject of the sentence, accusative shows usually the direct object of the verbs and dative case refers to the indirect object of bitransitive verbs. Therefore, the followed approach takes advantage of syntax, following a method similar to Semantic Role Labelling (Carreras and Marquez, 2005; Surdeanu and Turmo, 2005). English, as morphologically poor language, usually follows a fixed word order (subject-verb-object), so that a syntax parser can be easily used for identifying the subject and the object of most sentences. Considering such annotation, a factored translation model is trained to map the word-case pair to the correct inflection of the target noun. Given the agreement restriction, all words that accompany the noun (adjectives, articles, determiners) must follow the case of the noun, so their likely case needs to be identified as well. For this purpose we use a syntax parser to acquire the syntax</context>
</contexts>
<marker>Surdeanu, Turmo, 2005</marker>
<rawString>Surdeanu, M. and Turmo, J. 2005. Semantic Role Labeling Using Complete Syntactic Analysis. In Proceedings of 9th Conference on Computational Natural Language Learning (CoNLL), pages 221–224, Ann Arbor, Michigan, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Ueffing</author>
<author>H Ney</author>
</authors>
<title>Using pos information for statistical machine translation into morphologically rich languages. In</title>
<date>2003</date>
<booktitle>EACL ’03: Proceedings of the tenth conference on European chapter of the Association for Computational Linguistics,</booktitle>
<pages>347--354</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="5210" citStr="Ueffing and Ney (2003)" startWordPosition="797" endWordPosition="800">matical or badly ordered formations. • Meanwhile, in phrase-based SMT models, words are mapped in chunks. This can resolve phenomena where the English side uses more than one words to describe what is denoted on the target side by one morphologically inflected term. Thus, with respect to these methods, there is a problem when agreement needs to be applied on part of a sentence whose length exceeds the order of the of the target n-gram language model and the size of the chunks that are translated (see Figure 1 for an example). In one of the first efforts to enrich the source in word-based SMT, Ueffing and Ney (2003) used partof-speech (POS) tags, in order to deal with the verb conjugation of Spanish and Catalan; so, POS tags were used to identify the pronoun+verb sequence and splice these two words into one term. The approach was clearly motivated by the problems occurring by a single-word-based SMT and have been solved by adopting a phrase-based model. Meanwhile, there is no handling of the case when the pronoun stays in distance with the related verb. Minkov et al. (2007) suggested a post-processing system which uses morphological and syntactic features, in order to ensure grammatical agreement on the </context>
</contexts>
<marker>Ueffing, Ney, 2003</marker>
<rawString>Ueffing, N. and Ney, H. 2003. Using pos information for statistical machine translation into morphologically rich languages. In EACL ’03: Proceedings of the tenth conference on European chapter of the Association for Computational Linguistics, pages 347–354, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Vilar</author>
<author>J Xu</author>
<author>L F D’Haro</author>
<author>H Ney</author>
</authors>
<title>Error Analysis of Machine Translation Output.</title>
<date>2006</date>
<booktitle>In Proceedings of the 5th Internation Conference on Language Resources and Evaluation (LREC’06),</booktitle>
<pages>697--702</pages>
<location>Genoa, Italy.</location>
<marker>Vilar, Xu, D’Haro, Ney, 2006</marker>
<rawString>Vilar, D., Xu, J., D’Haro, L. F., and Ney, H. 2006. Error Analysis of Machine Translation Output. In Proceedings of the 5th Internation Conference on Language Resources and Evaluation (LREC’06), pages 697–702, Genoa, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Yamada</author>
<author>K Knight</author>
</authors>
<title>A syntax-based statistical translation model.</title>
<date>2001</date>
<booktitle>In ACL ’01: Proceedings of the 39th Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>523--530</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="7538" citStr="Yamada and Knight, 2001" startWordPosition="1173" endWordPosition="1176">els by having Combinatorial Categorial Grammar (CCG) supertags as factors on the input words, but in this case English was the target language. This paper reports work that strictly focuses on translation from English to a morphologically richer language. We go one step further than just using easily acquired information (e.g. English POS or lemmata) and extract target-specific information from the source sentence context. We use syntax, not in 764 Figure 2: Classification of the errors on our EnglishGreek baseline system (ch. 4.1), as suggested by Vilar et al. (2006) order to aid reordering (Yamada and Knight, 2001; Collins et al., 2005; Huang et al., 2006), but as a means for getting the “missing” morphology information, depending on the syntactic position of the words of interest. Then, contrary to the methods that added only output features or altered the generation procedure, we used this information in order to augment only the source side of a factored translation model, assuming that we do not have resources allowing factors or specialized generation in the target language (a common problem, when translating from English into under-resourced languages). 2 Methods for enriching input We selected t</context>
</contexts>
<marker>Yamada, Knight, 2001</marker>
<rawString>Yamada, K. and Knight, K. 2001. A syntax-based statistical translation model. In ACL ’01: Proceedings of the 39th Annual Meeting on Association for Computational Linguistics, pages 523–530, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>