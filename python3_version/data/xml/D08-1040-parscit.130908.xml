<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000208">
<title confidence="0.9972265">
A Casual Conversation System Using Modality and Word Associations
Retrieved from the Web
</title>
<author confidence="0.992725">
Shinsuke Higuchi Rafal Rzepka Kenji Araki
</author>
<affiliation confidence="0.993628">
Graduate School of Information Science and Technology
Hokkaido University, Sapporo Japan 060-0814
</affiliation>
<email confidence="0.996078">
{shin h,kabura,araki}@media.eng.hokudai.ac.jp
</email>
<sectionHeader confidence="0.995767" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.996363047619048">
In this paper we present a textual dialogue
system that uses word associations retrieved
from the Web to create propositions. We also
show experiment results for the role of modal-
ity generation. The proposed system automat-
ically extracts sets of words related to a con-
versation topic set freely by a user. After the
extraction process, it generates an utterance,
adds a modality and verifies the semantic re-
liability of the proposed sentence. We evalu-
ate word associations extracted form the Web,
and the results of adding modality. Over 80%
of the extracted word associations were evalu-
ated as correct. Adding modality improved the
system significantly for all evaluation criteria.
We also show how our system can be used as
a simple and expandable platform for almost
any kind of experiment with human-computer
textual conversation in Japanese. Two exam-
ples with affect analysis and humor generation
are given.
</bodyText>
<sectionHeader confidence="0.999131" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999948325">
Many task-oriented dialogue systems (Liu et al.,
2003; Reitter et al., 2006) have been developped.
Research on non-task-oriented dialogue systems like
casual conversation dialogue systems (”chatbots”) is
on the other hand not very common, perhaps due to
the many amateurs who try to build naturally talking
systems using sometimes very clever, but rather un-
scientific methods although there are systems with
chatting abilities as (Bickmore and Cassell, 2001)
but concentrate on applying strategies to casual con-
versation rather than their automatic generation of
those conversations. However, we believe that the
main reason is that an unrestricted domain is dispro-
portionately difficult compared to the possible use
such a system could have. It is for example very hard
to predict the contents and topics of user utterances,
and therefore it is almost impossible to prepare con-
versational scenarios. Furthermore, scenarios need
more or less specific goals to be useful. However
in our opinion, sooner or later non-task-oriented di-
alogue systems will have to be combined with task
oriented systems and used after recognizing that the
user’s utterance does not belong to a given task. This
would lead to more natural interfaces for e.g. infor-
mation kiosks or automatic guides placed in public
places where anyone can talk to them about anything
(Gustafson and Bell, 2000; Kopp et al., 2005) re-
gardless of the role the developers intended. For this
reason we have also started implementing emotive-
ness recognition and joke generation modules that
are presented later in the paper.
Well-known examples of non-task-oriented dia-
logue systems are ELIZA (Weizenbaum, 1966) and
A.L.I.C.E 1, though the former was built to parody a
Rogerian therapist which can be regarded as a task.
Both systems and their countless imitators 2 use a
lot of rules coded by hand. ELIZA is able to make
a response to any input, but these responses are only
information requests without providing any new in-
formation to the user. In the case of A.L.I.C.E,
</bodyText>
<footnote confidence="0.880236833333333">
1Wallace, R. The Anatomy of A.L.I.C.E.
http://www.alicebot.org/anatomy.html.
2Many of them have been quite successful in the Loeb-
ner Prize and the Chatterbox Challenge (competitions only for
English-speaking bots) but explanations of their algorithms are
not available.
</footnote>
<page confidence="0.908102">
382
</page>
<note confidence="0.962487">
Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 382–390,
Honolulu, October 2008.c�2008 Association for Computational Linguistics
</note>
<bodyText confidence="0.999971814814815">
the knowledge resource is limited to the existing
database. Creating such databases is costly and
a programmer must learn the AIML mark-up lan-
guage to build it. Although there have been attempts
at updating AIML databases automatically (Pietro et
al., 2005), the scale was rather limited.
As mentioned above, these examples and many
other ”chatbots” need hand-crafted rules, and are
thus often ignored by computer scientists and rarely
become a research topic. However, they have proved
to be useful for e-learning (Pietro et al., 2005) and
machine learning (Araki and Kuroda, 2006) support.
Building a system using automatic methods, like
we do, seems to be the most realistic way for unre-
stricted domains. Considering the large cost of de-
veloping a program that can talk about any topic, it
is appealing to turn to the huge and cheap textual
source that is the Internet.
In this very moment millions of people (Kumar et
al, 2003) are updating their blogs and writing articles
on every possible topic. These are available on the
Web which we can access any time, and in a faster
and faster manner, the search engines grow more and
more efficient. Thus, the Web is well suited to ex-
tracting word associations triggered by words from
user utterances made in a topic-free dialogue sys-
tem.. We present a system making use of this type
of information. It automatically extracts word asso-
ciation lists using all keywords in a given utterance
without choosing a specific one (which most other
systems that ignore the context do) then generates a
reply using the only one strongest association from
the nouns, verbs and adjectives association groups.
Modality is then added to the reply, and then it is
output.
Our system is built upon the idea that human utter-
ances consist of a proposition and a modality (Nitta
et al., 1989). In this paper we present an algorithm
for extracting word associations from the Web and
a method for adding modality to statements. We
evaluate both the word associations and the use of
modality. We also suggest some future possible ex-
tensions of the system and show a small experiment
with adding humor to the system.
In this paper, the system described works for
Japanese and uses text as input and output. Though
the final goal of our research is to help developing
freely talking car navigation systems that by their
chatting abilities can help to avoid drowsiness while
driving and so on. in this part of the development we
concentrate on proposition generation and modality
processing. Therefore, we work only with text now.
We plan to combine this project with research on in
car voice recognition and generation.
</bodyText>
<sectionHeader confidence="0.898604" genericHeader="method">
2 Extracting Word Associations
</sectionHeader>
<bodyText confidence="0.9998925">
In this chapter, we present a method for automatic
extraction of word associations based on keywords
from user utterances. We use the Google3 search
engine snippets to extract word associations in real
time without using earlier prepared resources, such
as off-line databases.
</bodyText>
<subsectionHeader confidence="0.9782835">
2.1 Extracting Word Associations from the
Web
</subsectionHeader>
<bodyText confidence="0.99998936">
In the first step, the system analyzed user utterances
using the morphological analyzer MeCab4 in order
to spot query keywords for extracting word associ-
ations lists. We define nouns, verbs, adjectives, and
unknown words as query keywords. The reason we
chose these word classes is that these word classes
can be treated as important and, to some extent, de-
scribe the context. We define a noun as the longest
set of nouns in a compound noun. For example,
the compound noun shizen gengo shori5 (natural
language processing) is treated by MeCab as three
words: (shizen - natural), (gengo - language) and
(shori - processing). Our system, however, threats
it as one noun.
In the next step, the system uses these keywords
as query words for the Google search engine. The
system extracts the nouns from the search results and
sorts them in frequency order. This process is based
on the idea that words which co-occur frequently
with the input words are of high relevance to them.
The number of extracted snippets is 500. This value
was set experimentally, taking the processing time
and output quality into account. The top ten words
of a list are treated as word associations, see Table 1
for an example.
</bodyText>
<footnote confidence="0.99672375">
3Google, http://www.google.co.jp/
4MeCab: Yet Another Part-of-Speech and Morphological
Analyzer, http://mecab.sourceforge.jp/
5All Japanese transcriptions will be written in italics.
</footnote>
<page confidence="0.999533">
383
</page>
<tableCaption confidence="0.9343845">
Table 1: Examples of noun associations triggered by a
user utterance
</tableCaption>
<bodyText confidence="0.365841">
Sapporo wa samui. (Sapporo city is cold.)
</bodyText>
<figure confidence="0.861383333333333">
Association frequency ranking:
1 yuki (snow) 52
2 fuyu (winter) 50
3 kion (temperature) 16
4 jiki (season) 12
5 Tokyo (Tokyo) 12
6 tenki (weather) 11
7 chiiki (area) 10
8 heya (room) 10
</figure>
<subsectionHeader confidence="0.96839">
2.2 Evaluation
</subsectionHeader>
<bodyText confidence="0.999606090909091">
We asked volunteers to use our system and to eval-
uate the correctness of word lists generated by the
system. First, a participant freely inputs an utter-
ance, for which the system retrieves ten association
words. Next, a participant rated these words using a
scale of one to three with 3 meaning ”perfectly cor-
rect”, 2 -”partially correct” and 1 - ”incorrect”. In
this experiment we consider words that receive a 2
or 3 as usable. The reason associations rated 2 or 3
are considered as usable is that the definition of what
makes a good word association here is difficult to
specify. When it comes to topic-free conversations
we have observed that associations have an effect
on a certain context. Three volunteers repeated the
experiment ten times, so the final amount of evalu-
ated words was 300. Table 2 shows the results of the
top 10 words, sorted by the frequency of appearance.
Table 3 shows the results of the top 5 words.
What constitutes a correct word association was
left to each volunteer to decide subjectively since in
a casual conversation setting associations are hard to
define strictly.
</bodyText>
<tableCaption confidence="0.995999">
Table 2: Top 10 word associations
</tableCaption>
<table confidence="0.9919514">
score participant(A B C) total
3 40 52 57 149
2 37 17 27 81
1 23 31 16 70
usability (%) 77 69 84 77
</table>
<bodyText confidence="0.3860125">
As shown in Table 2 approximately 77% of the
word associations were judged as usable but there
</bodyText>
<tableCaption confidence="0.997247">
Table 3: Top 5 word associations
</tableCaption>
<table confidence="0.9895404">
score participant A B C total
3 20 29 36 85
2 17 9 10 36
1 13 12 4 29
usability (%) 74 76 92 81
</table>
<bodyText confidence="0.999735944444444">
were individual differences between the evaluators.
This shows that the definition of word associations
is different for each participant. Table 3 shows that
approximately 80% of the word associations were
judged as usable. It is thus highly likely that the top
words from the frequency lists are correct associa-
tions. The results show that automatic extracting of
word associations using a Web search engine is fea-
sible. The main reason for extracting word associa-
tions from the Web is that thanks to this method, the
system can handle new information, proper names,
technical terms and so on. by using only the snip-
pets from the search engine. The word association
extraction takes no more than few seconds. For the
evaluation we used only nouns but we expect al-
though verbs and adjectives are often more abstract
than nouns, the word associations for them will im-
prove the results.
</bodyText>
<sectionHeader confidence="0.988811" genericHeader="method">
3 General Description of the System
</sectionHeader>
<bodyText confidence="0.996485">
The system generates replies in the following way:
</bodyText>
<listItem confidence="0.995291">
• extraction of keywords from user utterance
• extraction of word associations from the Web
• generation of sentence proposition using the
extracted associations
• addition of modality to the sentence proposi-
tion
</listItem>
<subsectionHeader confidence="0.9971885">
3.1 Extraction of Keywords from User
Utterances
</subsectionHeader>
<bodyText confidence="0.99987">
The system applies morphological analysis to the
use utterances in the same way as described in sec-
tion 2.1 and extracts keywords based on part of
speech.
</bodyText>
<page confidence="0.997907">
384
</page>
<figureCaption confidence="0.999715">
Figure 1: System flow
</figureCaption>
<subsectionHeader confidence="0.9822895">
3.2 Extraction of Words Association from the
Web
</subsectionHeader>
<bodyText confidence="0.999992625">
The system performs a Google search using the ex-
tracted keywords as a query. The system sorts the
results obtained from the query by their frequency
as in section 2.1. In section 2.1 only nouns were
extracted but here we also extract verbs and adjec-
tives. After sorting all words in adjective, verb and
noun lists the system uses the ones with the highest
frequency as word associations.
</bodyText>
<subsectionHeader confidence="0.978413">
3.3 Generation of Proposition Using Word
Associations
</subsectionHeader>
<bodyText confidence="0.99990975">
Using the associations, the system generates the
proposition of a sentence to be used as a reply to
the user input. A proposition is an expression rep-
resenting an objective statement. The proposition is
generated by applying associations to a proposition
template like [(noun) (topic indicating particle wa)
(adjective)]. We prepared 8 proposition templates
manually (see Table 4). The templates were cho-
sen subjectively after examining statistics from IRC
6 chat logs. Our criteria for choosing templates from
the chat logs was that they should belong to the 20
most frequent modality patterns and to be flexible
enough to fit a range of grammatical constructions,
for example in English, ”isn’t it” cannot follow verbs
while ”I guess” can follow nouns, adjectives, and
verbs. The proposition templates are applied in a
</bodyText>
<footnote confidence="0.9897">
6Internet Relay Chat Protocol,
http://www.irchelp.org/irchelp/rfc/rfc.html
</footnote>
<bodyText confidence="0.99955472">
predetermined order: for example, first a template
”(noun) (wa) (adjective)” is used; next a template
”(noun) (ga) (adjective)” is used. However, since the
generated proposition is not always a natural state-
ment, the system uses exact matching searches of
the whole phrases in a search engine to check the
naturalness of each proposition. If the frequency of
occurrence of the proposition is low, it is defined
as unnatural and deleted. This processing is based
on the idea that the phrases existing on the Web in
large numbers are most probably correct grammat-
ically and semantically. If an unnatural proposition
is generated, the system generates another proposi-
tion in the same way. In this experiment the sys-
tem used propositions for which the hit number ex-
ceeded 1,000 hits using Google. Thus, the process-
ing proceeds as follows. The system first selects the
top noun, top verb, and top adjective word associa-
tions. These are applied to the templates in a prede-
termined order. If a generated proposition is judged
as valid (using Google, occurrence on the web indi-
cates validity), it is used. If not, another template is
tried until a valid proposition is found. The reason
for not trying every possible combination of associ-
ated words is prohibitively long processing time.
</bodyText>
<tableCaption confidence="0.979673">
Table 4: Proposition templates
</tableCaption>
<listItem confidence="0.998773625">
(noun) (wa) (adjective)
(noun) (ga) (adjective)
(noun) (ga) (verb)
(noun) (wa) (verb)
(so-re) (wa) (verb)
(noun)
(adjective)
(verb)
</listItem>
<subsectionHeader confidence="0.988079">
3.4 Adding Modality to the Propositions
</subsectionHeader>
<bodyText confidence="0.999386375">
Finally, the system adds modality to the generated
proposition. By modality we mean a set of grammat-
ical and pragmatic rules to express subjective judg-
ments and attitudes. In our system, modality is real-
ized through adverbs at the end of a sentence which
is common in Japanese (Nitta et al., 1989). In our
system, a pair of sentence head and sentence end
auxiliary verb are defined as ”modality”.
</bodyText>
<page confidence="0.995086">
385
</page>
<subsectionHeader confidence="0.722597">
3.4.1 Extracting Modality
</subsectionHeader>
<bodyText confidence="0.9963148">
There is no standard definition of what consti-
tutes modality in Japanese. In this paper modality of
casual conversation is classified into questions and
informative expressions. Questions are expressions
that request information from the user. Informative
expressions are expressions that transmit informa-
tion to the user. Patterns for these modalities are ex-
tracted automatically from IRC chat logs (100,000
utterances) in advance. Modality patterns are ex-
tracted in these ways:
</bodyText>
<listItem confidence="0.9981175">
• pairs of grammatical particles and an auxiliary
verbs placed at the end of sentences are defined
as ending patterns
• sentences with question marks are defined as
questions
• adverbs, emotive words, and connectives at the
beginning of sentences are defined as informa-
tive expressions
• candidate patterns thus obtained are sorted by
frequency
</listItem>
<bodyText confidence="0.999744928571429">
First the system extracts sentence ending patterns
from IRC chat logs. If an expression contains ques-
tion marks, it is classified as a question. Next, the
system extracts adverbs, emotive words, and con-
nectives from the beginning and end of sentences
from the IRC logs. These pairs (beginning and end)
of expressions are classified as ”informative expres-
sions”. For example question expression ”desu-ka?”
is extracted from a human utterance like ”Kyou-wa
samui desu-ka?” (Is it cold today?). An informative
expression ”maa *** kedo” is extracted from a hu-
man utterance as ”Maa sore-wa ureshii kedo” (Well,
I’m glad, but you know...).
685 patterns were obtained for informative ex-
pressions. 550 of these informative expression pat-
terns were considered by authors as correct (80%).
For questions 396 patterns were obtained, and 292
patterns (73%) were evaluated as correct. We sorted
these candidates in frequency order. The words
appearing at the top of the list were correct, but
even the ones appearing only once were still deemed
as usable. For example, the question expression
”janakatta deshita-kke?” is a correct expression,
but appeared only once in the 100,000 utterances.
Hence, we confirmed that chat logs include various
modality expressions, and only a few of them are
incorrect. Tables 5 and 6 show some examples of
modality patterns.
</bodyText>
<tableCaption confidence="0.981796">
Table 5: Examples of informative expression modality
</tableCaption>
<bodyText confidence="0.869795909090909">
informative expression frequency
maa - kedo 21
(Well , it can be said - but -)
maa - dana 16
(Well , it can be said -)
maa - desu-ga 16
(Well , it appears that -)
soko-de - desu-yo 15
(Here , it is said that -)
maa - da-ga 14
(Well , it can be said - but -)
</bodyText>
<equation confidence="0.90709775">
maa - desu-yo 12
(Well , it is that -)
Table 6: Examples of question modality sentence endings
question freqency
...desuka? 232
(Is it that ... ?)
...kana? 90
(Maybe ... ?)
...da-kke? 87
(Is it right that ... ?)
...masu-ka? 69
(Is it that ... ?)
...nano? 68
(Is it that ... ?)
...toka? 55
( ... , isn’t it ?)
</equation>
<subsectionHeader confidence="0.899209">
3.4.2 Adding Modality
</subsectionHeader>
<bodyText confidence="0.999972875">
The system adds the modality from section 3.4.1
to the proposition from section 3.3 to generate the
system output. This process is based on the idea that
human utterance consists of proposition and modal-
ity. A modality pattern is selected randomly. For ex-
ample, if the system generates the proposition ”fuyu
wa samui (Winter is cold.)” and selects the modal-
ity ”iyaa ... desu-yo (Ooh ... isn’t it?)”, the gen-
</bodyText>
<page confidence="0.9978">
386
</page>
<bodyText confidence="0.999971357142857">
erated output will be ”iyaa, fuyu-wa samui desu-yo
(Winter is cold, you know)”. However, there is a
possibility that the system generates unnatural out-
put like ”fuyu-wa samui dayo-ne (Winter is cold,
arent’t it?)”, depending on the pair of proposition
and modality. To this problem, the system uses the
Google search engine to filter out unnatural output.
The system performs a phrase search on the end of
the sentence. If the number of search hits is higher
than threshold, the output is judged as correct. If the
number of a search hits is lower than the threshold,
the output is judged as incorrect and discarded, and
a new reply is generated. Here, we experimentally
set the threshold to 100 hits.
</bodyText>
<sectionHeader confidence="0.998751" genericHeader="method">
4 Experimental Results
</sectionHeader>
<bodyText confidence="0.999994210526316">
We used system α, generating only the proposi-
tion, and system Q, generating both proposition and
modality. 5 participants used each systems for con-
versations of 10 turns and evaluated the conversa-
tions on a 5-point scale. Evaluation criteria were
”will to continue the conversation” (A), ”grammati-
cal naturalness of dialogues” (B), ”semantical nat-
uralness of dialogues” (C), ”vocabulary richness”
(D), ”knowledge richness” (E), and ”humanity of
the system” (F). Table 7 shows average scores for
the evaluations of each system. System Q that uses
modality scored much higher than system α. Table
8 shows examples of actual dialogue. In the eval-
uation, the participants expressed the opinion that
an utterance like (xx ha yy) is unnatural and using
a modality like (maa)(”well”), (moo)(”anyway”) is
very natural. Thus we can say that the modality ex-
pressions make the utterances of the system seem
more natural.
</bodyText>
<sectionHeader confidence="0.777259" genericHeader="method">
5 The System as a Platform
</sectionHeader>
<bodyText confidence="0.9995063">
The simplicity, real-time processing capabilities and
promising results showing that users do not get
bored so quickly encouraged us to perform trials
with other ongoing projects and experiment with the
system working as a platform for adding various
modules and algorithms. By using our system it is
possible to perform tests to see if a new idea will
support or improve human-computer interaction or
not. Here we will briefly describe two such trials
- one on guessing emotive values of utterances and
</bodyText>
<tableCaption confidence="0.994869">
Table 8: Examples of dialogues with system β
</tableCaption>
<figure confidence="0.941683137931034">
user: Nanika suki-na tabemono aru?
(What food do you like ?)
system: Maa, tabemono-wa oishii desu.
(Well, food tastes good.)
user: Saikin-wa osake-mo
suki-ni natte-kita-n-da.
(Recently, I begin to like alcohol, too.)
system: Demo, sake-wa yowai-no-yo-ne.
(But, I can’t drink much.)
user: Yowai-n-da... Sugu yochau-no?
(Really...?
Do you get drunk
quickly?)
system: Maa, sore-wa sugoi-wa-ne.
(Whow, that’s amazing.)
user: Boku-wa wari-to osake-wa
tsuyoi hou-nan-da.
(I have a rather high
tolerance for alcohol.)
system: Iya, sore-wa tsuyoi-n-de.
(Well, it is strong, I can say.)
user: Kyou-wa sukoshi hadazamui-yo-ne.
Natsu-nanoni.
(It is a little cold today.
Even though it is summer.)
system: Asa-wa hadazamui-toka ?
(Isn’t it chilly in morning?)
user: Asa-kara hadazamukatta-ne.
(It was chilly since morning.)
</figure>
<figureCaption confidence="0.281487">
system: Aa kyou-wa hayai-na.
</figureCaption>
<bodyText confidence="0.854101666666667">
(Ah, it’s early. )
one on improving the system’s overall evaluation by
adding a pun generator.
</bodyText>
<subsectionHeader confidence="0.999022">
5.1 Testing Affect Analysis
</subsectionHeader>
<bodyText confidence="0.999912625">
Ptaszynski et al.(Ptaszynski et al., 2008) have devel-
oped a method for affect analysis of Japanese text.
Their method is based on cross-referencing lexical
emotive elements with emotive expressions appear-
ing in text. In the process of analysis first a gen-
eral emotive context is determined and then the spe-
cific types of emotional states conveyed in an utter-
ance are extracted. They support this method with a
</bodyText>
<page confidence="0.998459">
387
</page>
<tableCaption confidence="0.998761">
Table 7: Evaluation Results
</tableCaption>
<table confidence="0.99898125">
System α proposition system β proposition + modality
Evaluation criteria A B C D E F A B C D E F
Participant a 1 3 2 2 4 2 4 4 3 4 3 5
Participant b 1 3 1 2 1 1 4 4 4 5 4 3
Participant c 1 2 1 2 1 1 1 2 1 2 1 1
Participant d 1 3 1 3 1 2 4 3 1 3 3 4
Oarticipant e 1 4 1 1 2 1 3 2 2 4 5 4
Average 1.0 3.0 1.2 2.0 1.8 1.4 3.2 3.0 2.2 3.6 3.2 3.4
</table>
<bodyText confidence="0.999916785714286">
Web-mining technique to improve the performance
of the emotional state type extraction. A system
constructed on the basis of their method achieved
human level performance in determining the emo-
tiveness of utterances, and 65% of human level per-
formance in extracting the specific types of emo-
tions. Also, the supporting Web mining technique
improved the performance of the emotional state
type extraction to 85% of the human level (Shi et al,
2008). As these are very promising figures we are
currently in the phase of implementing their ideas
in our system and testing how emotion recognition
can influence speech act analysis and the automatic
choice of proper modality.
</bodyText>
<subsectionHeader confidence="0.999919">
5.2 Improving the System Using Humor
</subsectionHeader>
<bodyText confidence="0.999729666666667">
In this trial, an experiment showing that humor can
improve a non-task oriented conversational system’s
overall performance was conducted.
</bodyText>
<subsectionHeader confidence="0.971247">
5.2.1 Implementing PUNDA system
</subsectionHeader>
<bodyText confidence="0.999984391304348">
By using a simplified version of Dybala’s
PUNDA system (Dybala et al., 2008), a pun-
generation was added to our baseline system. The
PUNDA algorithm consists of two parts: A Can-
didate Selection Algorithm and a Sentence Integra-
tion Engine. The former generates a candidate for a
pun analyzing an input utterance and selects words
or phrases that could be transformed into a pun by
one of four generation patterns: homophony, ini-
tial mora addition, internal mora addition or final
mora addition. The latter part generates a sentence
including the candidate extracted in the previous
step. To make the system’s response more related
to the user’s input, each sentence that included a
joke started with the pattern ”[base phrase] to ieba”
(”Speaking of [base phrase]”). The remaining part
of the sentence was extracted from the Web and the
candidate was used as a query word and the list of
sentences including this word was retrieved. Then
the shortest sentence with an exclamation mark is se-
lected as most jokes convey some emotions. When
the candidate list was empty, the system selected one
random pun from a pun database.
</bodyText>
<subsectionHeader confidence="0.715969">
5.2.2 Experiment results
</subsectionHeader>
<bodyText confidence="0.999955846153846">
In the first experiment, 5 participants were asked
to perform a 10-turn dialogue with two systems.
After using both systems (baseline and humor-
equipped), users were asked to evaluate both sys-
tems’s performances by answering the following
questions: A) Do you want to continue the dia-
logue?; B) Was the system’s utterances grammati-
cally natural?; C) Was the system’s utterances se-
mantically natural?; D) Was the system’s vocabu-
lary rich?; E) Did you get an impression that the
system possesses any knowledge?; F) Did you get
an impression that the system was human-like?; G)
Do you think the system tried to make the dialogue
more funny and interesting? and H) Did you find
the system’s utterances interesting and funny? An-
swers were given on a 5-point scale and the results
are shown in Table 9.
A third-person evaluation experiment was also
performed and again the humor-equipped system
scored higher than the non-humor one. The ques-
tion asked in this evaluation was: ”Which dialogue
do you find most interesting and funny?”. Evalu-
ators could choose between 3 options: Dialogue 1
(Baseline system first 3 turns), Dialogue 2 (Humor-
equipped system, first 3 turns with system’s third re-
sponse replaced by pun generator’s output) and Dia-
</bodyText>
<page confidence="0.998904">
388
</page>
<tableCaption confidence="0.999602">
Table 9: Results of humor experiments
</tableCaption>
<table confidence="0.975894666666667">
Evaluation Criteria A B C D E F G H
Baseline System 3.0 2.2 2.4 2.4 2.0 2.8 2.2 2.8
With pun generator 3.2 3.0 2.8 2.8 2.2 3.0 3.4 3.6
</table>
<bodyText confidence="0.99960675">
logue 3 (the first 3 turns of the baseline system with
joking ability). Dialogue 1 and Dialogue 2 have the
same input. Among 25 evaluators, only 5 (20%) re-
sponded that Dialogue 1 was most interesting and
funny. 10 chose Dialogue 2 and the other 10 chose
Dialogue 3 (40% respectively). This means that
each of humor equipped dialogues received evalu-
ations two times higher than non-humor dialogue.
</bodyText>
<subsectionHeader confidence="0.5707765">
5.3 A Toolkit for Conversation-Related
Experiments
</subsectionHeader>
<bodyText confidence="0.999984416666667">
Our system can be also disassembled into a set of
flexible tools which help students to experiment with
dialogue processing. By using simple web-mining
techniques we described, this dialogue engine is ca-
pable of automatic retrieval of associations which
can be used to produce a whole range of utterances
- for example by using the bottom, not the top of the
associations list, one can examine how interesting
or provocative the dialogue becomes. As the sys-
tem has a cgi interface, the experiments are easy and
any new feature (for instance a speech act choice
menu) can be easily added. Such toolkit gives stu-
dents an opportunity to experiment on a given aspect
of dialogue processing without the need of build-
ing a conversation system from the scratch. There
is also no need of laborious knowledge input and,
as such open-domain oriented system generates new
”on topic” utterances, experiment subjects do not get
bored quickly, which is always a problem while col-
lecting conversation logs of human-machine inter-
action. A programmer also can freely choose be-
tween thousands of IRC logs utterances and Internet
resources for the statistical trials, grammar patterns
retrieval, speech acts analysis.
</bodyText>
<sectionHeader confidence="0.997623" genericHeader="conclusions">
6 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999979511111111">
In this research we investigated if word associations
extracted automatically from the Web are reasonable
(semantically on topic) and if they can be success-
fully used in non-task-oriented dialogue systems.
We also implemented such a system extraction mod-
ule. It is able to automatically generate in real-time
responses to user utterances by generating a propo-
sition and adding modality retrieved from IRC chat
logs. We conducted evaluation experiments on the
overall influence of the modality usage and it im-
proved the system. Therefore we showed that it
is possible to construct a dialogue system that au-
tomatically generates understandable on-topic utter-
ances without the need of creating vast amounts of
rules and data beforehand. We also confirmed that
our system can be used as a experimental platform
which can be easily used by other researchers to test
their algorithms with a more unpredictible (and less
boring) ”chatbot”, an important factor for long tir-
ing sessions of human-computer conversation. Cur-
rently there are several projects which use the sys-
tem described here as a platform for experiments and
we introduced two of them - on joke generation and
affect analysis.
There is still a lot of work left to be done. It is
necessary for a non-task-oriented dialogue system to
obtain not only word associations, but also different
kinds of knowledge - of user’s preferences or of di-
alogue itself - for example conversational strategies.
At this moment the system generates utterances by
applying word associations to the proposition tem-
plates and adding modality. We also need to more
deeply consider semantics, speech acts and context
to create a more advanced system. Finally, the sys-
tem needs to recognize not only keywords, but also
user’s modality. We assume that the affect recog-
nition mentioned above will help us to achieve this
goal in near future and this is our next step. By
opening the system’s code and giving others the op-
portunity of adding their own modules and changes
we hope to solve remaining problems. In this pa-
per we focus on the impact of adding modality to a
system. Comparing the system to Japanese versions
of ELIZA (already available) and ALICE (not avail-
able in Japanese yet) is also one of our next steps.
</bodyText>
<page confidence="0.99871">
389
</page>
<sectionHeader confidence="0.998392" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9996975">
This work was partially supported by the Research
Grant from the Nissan Science Foundation.
</bodyText>
<sectionHeader confidence="0.996244" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999715120689655">
Bei Liu, Limin Du, Shuiyuan Yu. 2003 The method
of building expectation model in task-oriented dia-
logue systems and its realization algorithms. Proceed-
ings of Natural Language Processing and Knowledge
Engineering:174-179
David Reitter, Johanna D. Moore, and Frank Keller.
2006. Priming of syntactic rules in task-oriented di-
alogue and spontaneous conversation. In Proc. 28th
Annual Conference of the Cognitive Science Society
(CogSci), Vancouver, Canada.
Timothy Bickmore and Justine Cassell. 2001 Relational
Agents: A Model and Implementation of Building
User Trust. Proceedings of Human Factors Computing
Systems (SIGCHI’01): 396–403.
Joakim Gustafson and Linda Bell. 2000. Speech technol-
ogy on trial: Experiences from the August system. In
Natural Language Engineering, 1(1):1-15.
Stefan Kopp, Lars Gesellensetter, Nicole C. Kramer, and
Ipke Wachsmuth. 2005. A Conversational Agent as
Museum Guide– Design and Evaluation of a Real-
World Application. Intelligent Virtual Agents, LNAI
3661:329-343.
Joseph Weizenbaum. 1966. ELIZA - computer pro-
gram for the study of natural language communica-
tion between man and machine. Commun. ACM, vol.9,
no.1:36-45.
Orlando De Pietro, Maurizio De Rose, and Giovanni
Frontera. 2005. Automatic Update of AIML Knowl-
edge Base in E-Learning Environment. In Proceedings
of Computers and Advanced Technology in Education.
, Oranjestad, Aruba, August:29-31.
Kenji Araki and Michitomo Kuroda. 2006. Gener-
ality of a Spoken Dialogue System Using SeGA-
IL for Different Languages, Proceedings of the
IASTED International Conference COMPUTER
INTELLIGENCE:70-75.
Ravi Kumar, Jasmine Novak, Prabhakar Raghavan, and
Andrew Tomkins. 2003. On the Bursty Evolution of
Blogspace. Proceedings of The Twelfth International
World Wide Web Conference:568-257
Yoshio Nitta and Takashi Masuoka, Japanese modal-
ity(Nihongo no modality) Kuroshio.
Michal Ptaszynski, Pawel Dybala, Rafal Rzepka, and
Kenji Araki. 2008. Double Standpoint Evaluation
Method for Affect Analysis System. The 22nd Annual
Conference of Japanese Society for Artificial Intelli-
gence (JSAI 2008).
Wenhan Shi, Rafal Rzepka and Kenji Araki. 2008. Emo-
tive Information Discovery from User Textual In-
put Using Causal Associations from the Internet (in
Japanese)”, Proceedings of the 7th Forum of Informa-
tion Technology(Vol2):267-268
Pawel Dybala, Michal Ptaszynski, Rafal Rzepka and
Kenji Araki. 2008. Extracting Dajare Candidates from
the Web - Japanese Puns Generating System as a
Part of Humor Processing Research. Proceedings of
LIBM’08 First International Workshop on Laughter in
Interaction and Body Movement:46-51.
</reference>
<page confidence="0.998275">
390
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.437658">
<title confidence="0.9585505">A Casual Conversation System Using Modality and Word Retrieved from the Web</title>
<author confidence="0.999046">Shinsuke Higuchi Rafal Rzepka Kenji Araki</author>
<affiliation confidence="0.998434">Graduate School of Information Science and</affiliation>
<address confidence="0.476652">Hokkaido University, Sapporo Japan 060-0814</address>
<abstract confidence="0.999615454545454">In this paper we present a textual dialogue system that uses word associations retrieved from the Web to create propositions. We also show experiment results for the role of modality generation. The proposed system automatically extracts sets of words related to a conversation topic set freely by a user. After the extraction process, it generates an utterance, adds a modality and verifies the semantic reliability of the proposed sentence. We evaluate word associations extracted form the Web, and the results of adding modality. Over 80% of the extracted word associations were evaluated as correct. Adding modality improved the system significantly for all evaluation criteria. We also show how our system can be used as a simple and expandable platform for almost any kind of experiment with human-computer textual conversation in Japanese. Two examples with affect analysis and humor generation are given.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Bei Liu</author>
<author>Limin Du</author>
<author>Shuiyuan Yu</author>
</authors>
<title>The method of building expectation model in task-oriented dialogue systems and its realization algorithms.</title>
<date>2003</date>
<booktitle>Proceedings of Natural Language Processing and Knowledge Engineering:174-179</booktitle>
<contexts>
<context position="1265" citStr="Liu et al., 2003" startWordPosition="188" endWordPosition="191">ds a modality and verifies the semantic reliability of the proposed sentence. We evaluate word associations extracted form the Web, and the results of adding modality. Over 80% of the extracted word associations were evaluated as correct. Adding modality improved the system significantly for all evaluation criteria. We also show how our system can be used as a simple and expandable platform for almost any kind of experiment with human-computer textual conversation in Japanese. Two examples with affect analysis and humor generation are given. 1 Introduction Many task-oriented dialogue systems (Liu et al., 2003; Reitter et al., 2006) have been developped. Research on non-task-oriented dialogue systems like casual conversation dialogue systems (”chatbots”) is on the other hand not very common, perhaps due to the many amateurs who try to build naturally talking systems using sometimes very clever, but rather unscientific methods although there are systems with chatting abilities as (Bickmore and Cassell, 2001) but concentrate on applying strategies to casual conversation rather than their automatic generation of those conversations. However, we believe that the main reason is that an unrestricted doma</context>
</contexts>
<marker>Liu, Du, Yu, 2003</marker>
<rawString>Bei Liu, Limin Du, Shuiyuan Yu. 2003 The method of building expectation model in task-oriented dialogue systems and its realization algorithms. Proceedings of Natural Language Processing and Knowledge Engineering:174-179</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Reitter</author>
<author>Johanna D Moore</author>
<author>Frank Keller</author>
</authors>
<title>Priming of syntactic rules in task-oriented dialogue and spontaneous conversation.</title>
<date>2006</date>
<booktitle>In Proc. 28th Annual Conference of the Cognitive Science Society (CogSci),</booktitle>
<location>Vancouver, Canada.</location>
<contexts>
<context position="1288" citStr="Reitter et al., 2006" startWordPosition="192" endWordPosition="195">verifies the semantic reliability of the proposed sentence. We evaluate word associations extracted form the Web, and the results of adding modality. Over 80% of the extracted word associations were evaluated as correct. Adding modality improved the system significantly for all evaluation criteria. We also show how our system can be used as a simple and expandable platform for almost any kind of experiment with human-computer textual conversation in Japanese. Two examples with affect analysis and humor generation are given. 1 Introduction Many task-oriented dialogue systems (Liu et al., 2003; Reitter et al., 2006) have been developped. Research on non-task-oriented dialogue systems like casual conversation dialogue systems (”chatbots”) is on the other hand not very common, perhaps due to the many amateurs who try to build naturally talking systems using sometimes very clever, but rather unscientific methods although there are systems with chatting abilities as (Bickmore and Cassell, 2001) but concentrate on applying strategies to casual conversation rather than their automatic generation of those conversations. However, we believe that the main reason is that an unrestricted domain is disproportionatel</context>
</contexts>
<marker>Reitter, Moore, Keller, 2006</marker>
<rawString>David Reitter, Johanna D. Moore, and Frank Keller. 2006. Priming of syntactic rules in task-oriented dialogue and spontaneous conversation. In Proc. 28th Annual Conference of the Cognitive Science Society (CogSci), Vancouver, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothy Bickmore</author>
<author>Justine Cassell</author>
</authors>
<title>Relational Agents: A Model and Implementation of Building User Trust.</title>
<date>2001</date>
<booktitle>Proceedings of Human Factors Computing Systems (SIGCHI’01):</booktitle>
<pages>396--403</pages>
<contexts>
<context position="1670" citStr="Bickmore and Cassell, 2001" startWordPosition="248" endWordPosition="251">for almost any kind of experiment with human-computer textual conversation in Japanese. Two examples with affect analysis and humor generation are given. 1 Introduction Many task-oriented dialogue systems (Liu et al., 2003; Reitter et al., 2006) have been developped. Research on non-task-oriented dialogue systems like casual conversation dialogue systems (”chatbots”) is on the other hand not very common, perhaps due to the many amateurs who try to build naturally talking systems using sometimes very clever, but rather unscientific methods although there are systems with chatting abilities as (Bickmore and Cassell, 2001) but concentrate on applying strategies to casual conversation rather than their automatic generation of those conversations. However, we believe that the main reason is that an unrestricted domain is disproportionately difficult compared to the possible use such a system could have. It is for example very hard to predict the contents and topics of user utterances, and therefore it is almost impossible to prepare conversational scenarios. Furthermore, scenarios need more or less specific goals to be useful. However in our opinion, sooner or later non-task-oriented dialogue systems will have to</context>
</contexts>
<marker>Bickmore, Cassell, 2001</marker>
<rawString>Timothy Bickmore and Justine Cassell. 2001 Relational Agents: A Model and Implementation of Building User Trust. Proceedings of Human Factors Computing Systems (SIGCHI’01): 396–403.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Gustafson</author>
<author>Linda Bell</author>
</authors>
<title>Speech technology on trial: Experiences from the August system.</title>
<date>2000</date>
<booktitle>In Natural Language Engineering,</booktitle>
<pages>1--1</pages>
<contexts>
<context position="2581" citStr="Gustafson and Bell, 2000" startWordPosition="394" endWordPosition="397"> is for example very hard to predict the contents and topics of user utterances, and therefore it is almost impossible to prepare conversational scenarios. Furthermore, scenarios need more or less specific goals to be useful. However in our opinion, sooner or later non-task-oriented dialogue systems will have to be combined with task oriented systems and used after recognizing that the user’s utterance does not belong to a given task. This would lead to more natural interfaces for e.g. information kiosks or automatic guides placed in public places where anyone can talk to them about anything (Gustafson and Bell, 2000; Kopp et al., 2005) regardless of the role the developers intended. For this reason we have also started implementing emotiveness recognition and joke generation modules that are presented later in the paper. Well-known examples of non-task-oriented dialogue systems are ELIZA (Weizenbaum, 1966) and A.L.I.C.E 1, though the former was built to parody a Rogerian therapist which can be regarded as a task. Both systems and their countless imitators 2 use a lot of rules coded by hand. ELIZA is able to make a response to any input, but these responses are only information requests without providing </context>
</contexts>
<marker>Gustafson, Bell, 2000</marker>
<rawString>Joakim Gustafson and Linda Bell. 2000. Speech technology on trial: Experiences from the August system. In Natural Language Engineering, 1(1):1-15.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Kopp</author>
<author>Lars Gesellensetter</author>
<author>Nicole C Kramer</author>
<author>Ipke Wachsmuth</author>
</authors>
<title>A Conversational Agent as Museum Guide– Design and Evaluation of a RealWorld Application. Intelligent Virtual Agents,</title>
<date>2005</date>
<journal>LNAI</journal>
<pages>3661--329</pages>
<contexts>
<context position="2601" citStr="Kopp et al., 2005" startWordPosition="398" endWordPosition="401">to predict the contents and topics of user utterances, and therefore it is almost impossible to prepare conversational scenarios. Furthermore, scenarios need more or less specific goals to be useful. However in our opinion, sooner or later non-task-oriented dialogue systems will have to be combined with task oriented systems and used after recognizing that the user’s utterance does not belong to a given task. This would lead to more natural interfaces for e.g. information kiosks or automatic guides placed in public places where anyone can talk to them about anything (Gustafson and Bell, 2000; Kopp et al., 2005) regardless of the role the developers intended. For this reason we have also started implementing emotiveness recognition and joke generation modules that are presented later in the paper. Well-known examples of non-task-oriented dialogue systems are ELIZA (Weizenbaum, 1966) and A.L.I.C.E 1, though the former was built to parody a Rogerian therapist which can be regarded as a task. Both systems and their countless imitators 2 use a lot of rules coded by hand. ELIZA is able to make a response to any input, but these responses are only information requests without providing any new information </context>
</contexts>
<marker>Kopp, Gesellensetter, Kramer, Wachsmuth, 2005</marker>
<rawString>Stefan Kopp, Lars Gesellensetter, Nicole C. Kramer, and Ipke Wachsmuth. 2005. A Conversational Agent as Museum Guide– Design and Evaluation of a RealWorld Application. Intelligent Virtual Agents, LNAI 3661:329-343.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph Weizenbaum</author>
</authors>
<title>ELIZA - computer program for the study of natural language communication between man and machine.</title>
<date>1966</date>
<journal>Commun. ACM,</journal>
<volume>9</volume>
<pages>1--36</pages>
<contexts>
<context position="2877" citStr="Weizenbaum, 1966" startWordPosition="441" endWordPosition="442">ll have to be combined with task oriented systems and used after recognizing that the user’s utterance does not belong to a given task. This would lead to more natural interfaces for e.g. information kiosks or automatic guides placed in public places where anyone can talk to them about anything (Gustafson and Bell, 2000; Kopp et al., 2005) regardless of the role the developers intended. For this reason we have also started implementing emotiveness recognition and joke generation modules that are presented later in the paper. Well-known examples of non-task-oriented dialogue systems are ELIZA (Weizenbaum, 1966) and A.L.I.C.E 1, though the former was built to parody a Rogerian therapist which can be regarded as a task. Both systems and their countless imitators 2 use a lot of rules coded by hand. ELIZA is able to make a response to any input, but these responses are only information requests without providing any new information to the user. In the case of A.L.I.C.E, 1Wallace, R. The Anatomy of A.L.I.C.E. http://www.alicebot.org/anatomy.html. 2Many of them have been quite successful in the Loebner Prize and the Chatterbox Challenge (competitions only for English-speaking bots) but explanations of the</context>
</contexts>
<marker>Weizenbaum, 1966</marker>
<rawString>Joseph Weizenbaum. 1966. ELIZA - computer program for the study of natural language communication between man and machine. Commun. ACM, vol.9, no.1:36-45.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Orlando De Pietro</author>
<author>Maurizio De Rose</author>
<author>Giovanni Frontera</author>
</authors>
<title>Automatic Update of AIML Knowledge Base in E-Learning Environment.</title>
<date>2005</date>
<booktitle>In Proceedings of Computers and Advanced Technology in Education. ,</booktitle>
<location>Oranjestad, Aruba, August:29-31.</location>
<marker>De Pietro, De Rose, Frontera, 2005</marker>
<rawString>Orlando De Pietro, Maurizio De Rose, and Giovanni Frontera. 2005. Automatic Update of AIML Knowledge Base in E-Learning Environment. In Proceedings of Computers and Advanced Technology in Education. , Oranjestad, Aruba, August:29-31.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenji Araki</author>
<author>Michitomo Kuroda</author>
</authors>
<title>Generality of a Spoken Dialogue System Using SeGAIL for Different Languages,</title>
<date>2006</date>
<booktitle>Proceedings of the IASTED International Conference COMPUTER</booktitle>
<pages>70--75</pages>
<contexts>
<context position="4271" citStr="Araki and Kuroda, 2006" startWordPosition="655" endWordPosition="658">ssociation for Computational Linguistics the knowledge resource is limited to the existing database. Creating such databases is costly and a programmer must learn the AIML mark-up language to build it. Although there have been attempts at updating AIML databases automatically (Pietro et al., 2005), the scale was rather limited. As mentioned above, these examples and many other ”chatbots” need hand-crafted rules, and are thus often ignored by computer scientists and rarely become a research topic. However, they have proved to be useful for e-learning (Pietro et al., 2005) and machine learning (Araki and Kuroda, 2006) support. Building a system using automatic methods, like we do, seems to be the most realistic way for unrestricted domains. Considering the large cost of developing a program that can talk about any topic, it is appealing to turn to the huge and cheap textual source that is the Internet. In this very moment millions of people (Kumar et al, 2003) are updating their blogs and writing articles on every possible topic. These are available on the Web which we can access any time, and in a faster and faster manner, the search engines grow more and more efficient. Thus, the Web is well suited to ex</context>
</contexts>
<marker>Araki, Kuroda, 2006</marker>
<rawString>Kenji Araki and Michitomo Kuroda. 2006. Generality of a Spoken Dialogue System Using SeGAIL for Different Languages, Proceedings of the IASTED International Conference COMPUTER INTELLIGENCE:70-75.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ravi Kumar</author>
<author>Jasmine Novak</author>
<author>Prabhakar Raghavan</author>
<author>Andrew Tomkins</author>
</authors>
<title>On the Bursty Evolution of Blogspace.</title>
<date>2003</date>
<booktitle>Proceedings of The Twelfth International World Wide Web Conference:568-257</booktitle>
<contexts>
<context position="4620" citStr="Kumar et al, 2003" startWordPosition="718" endWordPosition="721">e examples and many other ”chatbots” need hand-crafted rules, and are thus often ignored by computer scientists and rarely become a research topic. However, they have proved to be useful for e-learning (Pietro et al., 2005) and machine learning (Araki and Kuroda, 2006) support. Building a system using automatic methods, like we do, seems to be the most realistic way for unrestricted domains. Considering the large cost of developing a program that can talk about any topic, it is appealing to turn to the huge and cheap textual source that is the Internet. In this very moment millions of people (Kumar et al, 2003) are updating their blogs and writing articles on every possible topic. These are available on the Web which we can access any time, and in a faster and faster manner, the search engines grow more and more efficient. Thus, the Web is well suited to extracting word associations triggered by words from user utterances made in a topic-free dialogue system.. We present a system making use of this type of information. It automatically extracts word association lists using all keywords in a given utterance without choosing a specific one (which most other systems that ignore the context do) then gen</context>
</contexts>
<marker>Kumar, Novak, Raghavan, Tomkins, 2003</marker>
<rawString>Ravi Kumar, Jasmine Novak, Prabhakar Raghavan, and Andrew Tomkins. 2003. On the Bursty Evolution of Blogspace. Proceedings of The Twelfth International World Wide Web Conference:568-257</rawString>
</citation>
<citation valid="false">
<authors>
<author>Yoshio Nitta</author>
<author>Takashi Masuoka</author>
</authors>
<note>Japanese modality(Nihongo no modality) Kuroshio.</note>
<marker>Nitta, Masuoka, </marker>
<rawString>Yoshio Nitta and Takashi Masuoka, Japanese modality(Nihongo no modality) Kuroshio.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michal Ptaszynski</author>
<author>Pawel Dybala</author>
<author>Rafal Rzepka</author>
<author>Kenji Araki</author>
</authors>
<title>Double Standpoint Evaluation Method for Affect Analysis System.</title>
<date>2008</date>
<booktitle>The 22nd Annual Conference of Japanese Society for Artificial Intelligence (JSAI</booktitle>
<contexts>
<context position="21002" citStr="Ptaszynski et al., 2008" startWordPosition="3431" endWordPosition="3434">i-wa-ne. (Whow, that’s amazing.) user: Boku-wa wari-to osake-wa tsuyoi hou-nan-da. (I have a rather high tolerance for alcohol.) system: Iya, sore-wa tsuyoi-n-de. (Well, it is strong, I can say.) user: Kyou-wa sukoshi hadazamui-yo-ne. Natsu-nanoni. (It is a little cold today. Even though it is summer.) system: Asa-wa hadazamui-toka ? (Isn’t it chilly in morning?) user: Asa-kara hadazamukatta-ne. (It was chilly since morning.) system: Aa kyou-wa hayai-na. (Ah, it’s early. ) one on improving the system’s overall evaluation by adding a pun generator. 5.1 Testing Affect Analysis Ptaszynski et al.(Ptaszynski et al., 2008) have developed a method for affect analysis of Japanese text. Their method is based on cross-referencing lexical emotive elements with emotive expressions appearing in text. In the process of analysis first a general emotive context is determined and then the specific types of emotional states conveyed in an utterance are extracted. They support this method with a 387 Table 7: Evaluation Results System α proposition system β proposition + modality Evaluation criteria A B C D E F A B C D E F Participant a 1 3 2 2 4 2 4 4 3 4 3 5 Participant b 1 3 1 2 1 1 4 4 4 5 4 3 Participant c 1 2 1 2 1 1 1</context>
</contexts>
<marker>Ptaszynski, Dybala, Rzepka, Araki, 2008</marker>
<rawString>Michal Ptaszynski, Pawel Dybala, Rafal Rzepka, and Kenji Araki. 2008. Double Standpoint Evaluation Method for Affect Analysis System. The 22nd Annual Conference of Japanese Society for Artificial Intelligence (JSAI 2008).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wenhan Shi</author>
<author>Rafal Rzepka</author>
<author>Kenji Araki</author>
</authors>
<title>Emotive Information Discovery from User Textual Input Using Causal Associations from the Internet (in</title>
<date>2008</date>
<booktitle>Japanese)”, Proceedings of the 7th Forum of Information Technology(Vol2):267-268</booktitle>
<contexts>
<context position="22192" citStr="Shi et al, 2008" startWordPosition="3675" endWordPosition="3678">articipant c 1 2 1 2 1 1 1 2 1 2 1 1 Participant d 1 3 1 3 1 2 4 3 1 3 3 4 Oarticipant e 1 4 1 1 2 1 3 2 2 4 5 4 Average 1.0 3.0 1.2 2.0 1.8 1.4 3.2 3.0 2.2 3.6 3.2 3.4 Web-mining technique to improve the performance of the emotional state type extraction. A system constructed on the basis of their method achieved human level performance in determining the emotiveness of utterances, and 65% of human level performance in extracting the specific types of emotions. Also, the supporting Web mining technique improved the performance of the emotional state type extraction to 85% of the human level (Shi et al, 2008). As these are very promising figures we are currently in the phase of implementing their ideas in our system and testing how emotion recognition can influence speech act analysis and the automatic choice of proper modality. 5.2 Improving the System Using Humor In this trial, an experiment showing that humor can improve a non-task oriented conversational system’s overall performance was conducted. 5.2.1 Implementing PUNDA system By using a simplified version of Dybala’s PUNDA system (Dybala et al., 2008), a pungeneration was added to our baseline system. The PUNDA algorithm consists of two par</context>
</contexts>
<marker>Shi, Rzepka, Araki, 2008</marker>
<rawString>Wenhan Shi, Rafal Rzepka and Kenji Araki. 2008. Emotive Information Discovery from User Textual Input Using Causal Associations from the Internet (in Japanese)”, Proceedings of the 7th Forum of Information Technology(Vol2):267-268</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pawel Dybala</author>
<author>Michal Ptaszynski</author>
<author>Rafal Rzepka</author>
<author>Kenji Araki</author>
</authors>
<title>Extracting Dajare Candidates from the Web - Japanese Puns Generating System as a Part of Humor Processing Research.</title>
<date>2008</date>
<booktitle>Proceedings of LIBM’08 First International Workshop on Laughter in Interaction and Body Movement:46-51.</booktitle>
<contexts>
<context position="22701" citStr="Dybala et al., 2008" startWordPosition="3753" endWordPosition="3756">que improved the performance of the emotional state type extraction to 85% of the human level (Shi et al, 2008). As these are very promising figures we are currently in the phase of implementing their ideas in our system and testing how emotion recognition can influence speech act analysis and the automatic choice of proper modality. 5.2 Improving the System Using Humor In this trial, an experiment showing that humor can improve a non-task oriented conversational system’s overall performance was conducted. 5.2.1 Implementing PUNDA system By using a simplified version of Dybala’s PUNDA system (Dybala et al., 2008), a pungeneration was added to our baseline system. The PUNDA algorithm consists of two parts: A Candidate Selection Algorithm and a Sentence Integration Engine. The former generates a candidate for a pun analyzing an input utterance and selects words or phrases that could be transformed into a pun by one of four generation patterns: homophony, initial mora addition, internal mora addition or final mora addition. The latter part generates a sentence including the candidate extracted in the previous step. To make the system’s response more related to the user’s input, each sentence that include</context>
</contexts>
<marker>Dybala, Ptaszynski, Rzepka, Araki, 2008</marker>
<rawString>Pawel Dybala, Michal Ptaszynski, Rafal Rzepka and Kenji Araki. 2008. Extracting Dajare Candidates from the Web - Japanese Puns Generating System as a Part of Humor Processing Research. Proceedings of LIBM’08 First International Workshop on Laughter in Interaction and Body Movement:46-51.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>