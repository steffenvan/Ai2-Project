<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001235">
<title confidence="0.975987">
Data Driven Language Transfer Hypotheses
</title>
<author confidence="0.999134">
Ben Swanson Eugene Charniak
</author>
<affiliation confidence="0.999322">
Brown University Brown University
</affiliation>
<address confidence="0.901274">
Providence, RI Providence, RI
</address>
<email confidence="0.999537">
chonger@cs.brown.edu ec@cs.brown.edu
</email>
<sectionHeader confidence="0.993912" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999919705882353">
Language transfer, the preferential second
language behavior caused by similarities
to the speaker’s native language, requires
considerable expertise to be detected by
humans alone. Our goal in this work is to
replace expert intervention by data-driven
methods wherever possible. We define a
computational methodology that produces
a concise list of lexicalized syntactic pat-
terns that are controlled for redundancy
and ranked by relevancy to language trans-
fer. We demonstrate the ability of our
methodology to detect hundreds of such
candidate patterns from currently available
data sources, and validate the quality of
the proposed patterns through classifica-
tion experiments.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999788036363636">
The fact that students with different native lan-
guage backgrounds express themselves differ-
ently in second language writing samples has
been established experimentally many times over
(Tetreault et al., 2013), and is intuitive to most
people with experience learning a new language.
The exposure and understanding of this process
could potentially enable the creation of second
language (L2) instruction that is tailored to the na-
tive language (L1) of students.
The detectable connection between L1 and L2
text comes from a range of sources. On one end of
the spectrum are factors such as geographic or cul-
tural preference in word choice, which are a pow-
erful L1 indicator. On the other end lie linguistic
phenomena such as language transfer, in which the
preferential over-use or under-use of structures in
the L1 is reflected in the use of corresponding pat-
terns in the L2. We focus on language transfer in
this work, based on our opinion that such effects
are more deeply connected to and effectively uti-
lized in language education.
The inherent challenge is that viable language
transfer hypotheses are naturally difficult to con-
struct. By the requirement of contrasting different
L1 groups, hypothesis formulation requires deep
knowledge of multiple languages, an ability re-
served primarily for highly trained academic lin-
guists. Furthermore, the sparsity of any particular
language pattern in a large corpus makes it diffi-
cult even for a capable multilingual scholar to de-
tect the few patterns that evidence language trans-
fer. This motivates data driven methods for hy-
pothesis formulation.
We approach this as a representational problem,
requiring the careful definition of a class of lin-
guistic features whose usage frequency can be de-
termined for each L1 background in both L1 and
L2 text (e.g. both German and English written
by Germans). We claim that a feature exhibiting
a sufficiently non-uniform usage histogram in L1
that is mirrored in L2 data is a strong language
transfer candidate, and provide a quantified mea-
sure of this property.
We represent both L1 and L2 sentences in a
universal constituent-style syntactic format and
model language transfer hypotheses with con-
tiguous syntax sub-structures commonly known
as Tree Substitution Grammar (TSG) fragments
(Post and Gildea, 2009)(Cohn and Blunsom,
2010). With these features we produce a concise
ranked list of candidate language transfer hypothe-
ses and their usage statistics that can be automati-
cally augmented as increasing amounts of data be-
come available.
</bodyText>
<page confidence="0.98447">
169
</page>
<note confidence="0.899101">
Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 169–173,
Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics
</note>
<sectionHeader confidence="0.998893" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999967393939394">
This work leverages several recently released data
sets and analysis techniques, with the primary
contribution being the transformations necessary
to combine these disparate efforts. Our analy-
sis methods are closely tied to those described
in Swanson and Charniak (2013), which con-
trasts techniques for the discovery of discrimina-
tive TSG fragments in L2 text. We modify and
extend these methods to apply to the universal de-
pendency treebanks of McDonald et al. (2013),
which we will refer to below to as the UTB. Bilin-
gual lexicon construction (Haghighi et al., 2008)
is also a key component, although previous work
has focused primarily on nouns while we focus on
stopwords. We also transform the UTB into con-
stituent format, in a manner inspired by Carroll
and Charniak (1992).
There is a large amount of related research in
Native Language Identification (NLI), the task of
predicting L1 given L2 text. This work has culmi-
nated in a well attended shared task (Tetreault et
al., 2013), whose cited report contains an excellent
survey of the history of this task. In NLI, however,
L1 data is not traditionally used, and patterns are
learned directly from L2 text that has been anno-
tated with L1 labels. One notable outlier is Brooke
and Hirst (2012), which attempts NLI using only
L1 data for training using large online dictionar-
ies to tie L2 English bigrams and collocations to
possible direct translations from native languages.
Jarvis and Crossley (2012) presents another set of
studies that use NLI as a method to form language
transfer hypotheses.
</bodyText>
<sectionHeader confidence="0.99781" genericHeader="method">
3 Methodology
</sectionHeader>
<bodyText confidence="0.999782">
The first of the four basic requirements of our pro-
posed method is the definition of a class of features
F such that a single feature F E F is capable
of capturing language transfer phenomenon. The
second is a universal representation of both L1 and
L2 data that allows us to count the occurrences of
any F in an arbitrary sentence. Third, as any suf-
ficiently expressive F is likely to be very large, a
method is required to propose an initial candidate
list C C F. Finally, we refine C into a ranked list
H of language transfer hypotheses, where H has
also been filtered to remove redundancy.
In this work we define F to be the set of Tree
Substitution Grammar (TSG) fragments in our
data, which allows any connected syntactic struc-
ture to be used as a feature. As such, our universal
representation of L1/L2 data must be a constituent
tree structure of the general form used in syntactic
parsing experiments on the Penn Treebank. The
UTB gets us most of the way to our goal, defining
a dependency grammar with a universal set of part
of speech (POS) tags and dependency arc labels.
Two barriers remain to the use of standard TSG
induction algorithms. The first is to define a map-
ping from the dependency tree format to con-
stituency format. We use the following depen-
dency tree to illustrate our transformation.
</bodyText>
<figure confidence="0.497870076923077">
root
ROOT DT NN VBZ PRP
The poodle chews it
Under our transformation, the above dependency
parse becomes
ROOT
root
VBZ-L
nsubj
NN-L
det
DT
the
</figure>
<bodyText confidence="0.999902588235294">
We also require a multilingual lexicon in the form
of a function ML(w) for each language L that
maps words to clusters representing their meaning.
In order to avoid cultural cues and reduce noise
in our mapping, we restrict ourselves to clusters
that correspond to a list of L2 stopwords. Any L2
words that do not appear on this list are mapped
to the unknown “UNK” symbol, as are all for-
eign words that are not good translations of any
L2 stopword. Multiple words from a single lan-
guage can map to the same cluster, and it is worth
noting that this is true for L2 stopwords as well.
To determine the mapping functions ML we
train IBM translation models in both directions be-
tween the L2 and each L1. We create a graph in
which nodes are words, either the L2 stopwords or
any L1 word with some translation probability to
</bodyText>
<figure confidence="0.930428714285714">
det nsubj dobj
poodle
NN
VBZ VBZ-R
chews dobj
PRP
it
</figure>
<page confidence="0.970717">
170
</page>
<bodyText confidence="0.99973025">
or from one of the L2 stopwords. The edges in this
graph exist only between L2 and L1 words, and
are directed with weight equal to the IBM model’s
translation probability of the edge’s target given
its source. We construct ML by removing edges
with weight below some threshold and calculating
the connected components of the resulting graph.
We then discard any cluster that does not contain
at least one word from each L1 and at least one L2
stopword.
To propose a candidate list C, we use the TSG
induction technique described in Swanson and
Charniak (2013), which simultaneously induces
multiple TSGs from data that has been partitioned
into labeled types. This method permits linguisti-
cally motivated constraints as to which grammars
produce each type of data. For an experimental
setup that considers n different L1s, we use 2n+1
data types; Figure 1 shows the exact layout used
in our experiments. Besides the necessary n data
types for each L1 in its actual native language form
and n in L2 form, we also include L2 data from
L2 native speakers. We also define 2n + 1 gram-
mars. We begin with n grammars that can each
be used exclusively by one native language data
type, representing behavior that is unique to each
native language (grammars A-C in Figure 1) . This
is done for the L2 as well (grammar G). Finally,
we create an interlanguage grammar for each of
our L1 types that can be used in derivation of both
L1 and L2 data produced by speakers of that L1
(grammars D-F).
The final step is to filter and rank the TSG frag-
ments produced in C, where filtering removes re-
dundant features and ranking provides some quan-
tification of our confidence in a feature as a lan-
guage transfer hypothesis. Swanson and Char-
niak (2013) provides a similar method for pure L2
data, which we modify for our purposes. For re-
dundancy filtering no change is necessary, and we
use their recommended Symmetric Uncertainty
method. For a ranking metric of how well a frag-
ment fits the profile of language transfer we adopt
the expected per feature loss (or risk) also de-
scribed in their work. For an arbitrary feature F,
this is defined as
where TF is the subset of the test data that contains
the feature F, and L∗t is the gold label of test da-
</bodyText>
<figureCaption confidence="0.889503">
Figure 1: The multi-grammar induction setup used
</figureCaption>
<bodyText confidence="0.9467794">
in our experiments. Squares indicate data types,
and circles indicate grammars. Data type labels
indicate the native language of the speaker, and all
L2 data is in English.
tum t. While in their work the predictive distribu-
tion PF(L) is determined by the observed counts
of F in L2 training data, we take our estimates
directly from the L1 data of the languages under
study. This metric captures the extent to which the
knowledge of a feature F’s L1 usage can be used
to predict its usage in L2.
The final result is a ranked and filtered list of hy-
potheses H. The elements of H can be subjected
to further investigation by experts and the accom-
panying histogram of counts contains the relevant
empirical evidence. As more data is added, the
uncertainty in the relative proportions of these his-
tograms and their corresponding R is decreased.
One additional benefit of our method is that TSG
induction is a random process, and repeated runs
of the sampling algorithm can produce different
features. Since redundancy is filtered automati-
cally, these different feature lists can be combined
and processed to potentially find additional fea-
tures given more computing time.
</bodyText>
<sectionHeader confidence="0.999966" genericHeader="evaluation">
4 Results
</sectionHeader>
<bodyText confidence="0.999592111111111">
Limited by the intersection of languages across
data sets, we take French, Spanish, and German
as our set of L1s with English as the L2. We use
the UTB for our native language data, which pro-
vides around 4000 sentences of human annotated
text for each L1. For our L2 data we use the ETS
Corpus of Non-Native English (Blanchard et al.,
2013), which consists of over 10K sentences per
L1 label drawn from TOEFLO exam essays. Fi-
</bodyText>
<figure confidence="0.999141523809524">
A
B
C
L1
Data
DE
FR
ES
D
E
F
L2
Data
EN
DE
FR
ES
G
1 R(F) = |TF |1:PF(L 7� L∗t)
t∈T
F
</figure>
<page confidence="0.994472">
171
</page>
<bodyText confidence="0.999970375">
nally, we use the Penn Treebank as our source of
native English data, for a total of seven data types;
four in English, and one in each L1.
When calculating metrics such as redundancy
and R(F) we use all available data. For TSG
sampling, we balance our data sets to 4000 sen-
tences from each data type and sample using the
Enbuske sampler that was released with Swanson
and Charniak (2013). To construct word clusters,
we use Giza++ (Och and Ney, 2003) and train on
the Europarl data set (Koehn, 2005), using .25 as
a threshold for construction on connected compo-
nents.
We encourage the reader to peruse the full list
of results1, in which each item contains the infor-
mation in the following example.
</bodyText>
<equation confidence="0.902639833333333">
advcl
VERB-L VERB VERB-R
mark 110
ES DE FR
L1 4.2 0.0 0.0
L2 2.3 0.3 0.3
</equation>
<bodyText confidence="0.997957">
This fragment corresponds to an adverbial
clause whose head is a verb in the cluster 110,
which contains the English word “is” and its vari-
ous translations. This verb has a single left depen-
dent, a clause marker such as “because”, and at
least one right dependent. Its prevalence in Span-
ish can explained by examining the translations of
the English sentence “I like it because it is red”.
ES Me gusta porque es rojo.
DE Ich mag es, weil es rot ist.
FR Je l’aime parce qu’il est rouge.
Only in the Spanish sentence is the last pronoun
dropped, as in “I like it because is red”. This
observation, along with the L1/L2 profile which
shows the count per thousand sentences in each
language provides a strong argument that this pat-
tern is indeed a form of language transfer.
Given our setup of three native languages, a fea-
ture with R(F) &lt; .66 is a candidate for language
transfer. However, several members of our filtered
list have R(F) &gt; .66, which is to say that their
</bodyText>
<figure confidence="0.961410666666667">
1bllip.cs.brown.edu/download/interlanguage corpus.pdf
0.44
0.42
0.4
0.38
0.36
0.34
0 10 20 30 40 50 60 70 80 90
Sentences Per Test Case
</figure>
<figureCaption confidence="0.998582">
Figure 2: Creating test cases that consist of sev-
</figureCaption>
<bodyText confidence="0.969570075">
eral sentences mediates feature sparsity, providing
clear evidence for the discriminative power of the
chosen feature set.
L2 usage does not mirror L1 usage. This is to be
expected in some cases due to noise, but it raises
the concern that our features with R(F) &lt; .66 are
also the result of noise in the data. To address this,
we apply our features to the task of cross language
NLI using only L1 data for training. If the varia-
tion of R(F) around chance is simply due to noise
then we would expect near chance (33%) classifi-
cation accuracy. The leftmost point in Figure 2
shows the initial result, using boolean features in
a log-linear classification model, where a test case
involves guessing an L1 label for each individual
sentence in the L2 corpus. While the accuracy
does exceed chance, the margin is not very large.
One possible explanation for this small margin
is that the language transfer signal is sparse, as it
is likely that language transfer can only be used to
correctly label a subset of L2 data. We test this by
combining randomly sampled L2 sentences with
the same L1 label, as shown along the horizontal
axis of Figure 2. As the number of sentences used
to create each test case is increased, we see an in-
crease in accuracy that supports the argument for
sparsity; if the features were simply weak predic-
tors, this curve would be flat. The resulting margin
is much larger, providing evidence that a signifi-
cant portion of our features with R(F) &lt; .66 are
not selected due to random noise in R and are in-
deed connected to language transfer.
The number and strength of these hypotheses is
easily augmented with more data, as is the number
of languages under consideration. Our results also
motivate future work towards automatic genera-
tion of L1 targeted language education exercises,
and the fact that TSG fragments are a component
of a well studied generative language model makes
them well suited to such generation tasks.
</bodyText>
<figure confidence="0.467814">
Classification Accuracy (%)
</figure>
<page confidence="0.937755">
172
</page>
<note confidence="0.629492727272727">
Joel Tetreault, Daniel Blanchard, and Aoife Cahill.
2013. A report on the first native language identi-
fication shared task. In Proceedings of the Eighth
Workshop on Innovative Use of NLP for Building
Educational Applications, Atlanta, GA, USA, June.
Association for Computational Linguistics.
References
Daniel Blanchard, Joel Tetreault, Derrick Higgins,
Aoife Cahill, and Martin Chodorow. 2013. Toefl11:
A corpus of non-native english. Technical report,
Educational Testing Service.
</note>
<reference confidence="0.999790234042553">
Julian Brooke and Graeme Hirst. 2012. Measur-
ing Interlanguage: Native Language Identification
with L1-influence Metrics. In Proceedings of the
Eighth International Conference on Language Re-
sources and Evaluation (LREC-2012), pages 779–
784, Istanbul, Turkey, May. European Language Re-
sources Association (ELRA). ACL Anthology Iden-
tifier: L12-1016.
Glenn Carroll and Eugene Charniak. 1992. Two exper-
iments on learning probabilistic dependency gram-
mars from corpora. Technical Report CS-92-16,
Brown University, Providence, RI, USA.
Trevor Cohn and Phil Blunsom. 2010. Blocked infer-
ence in bayesian tree substitution grammars. pages
225–230. Association for Computational Linguis-
tics.
Aria Haghighi, Percy Liang, Taylor Berg-Kirkpatrick,
and Dan Klein. 2008. Learning bilingual lexicons
from monolingual corpora. In ACL, pages 771–779.
Scott Jarvis and Scott Crossley, editors. 2012. Ap-
proaching Language Transfer Through Text Classi-
fication: Explorations in the Detection-based Ap-
proach, volume 64. Multilingual Matters Limited,
Bristol, UK.
Philipp Koehn. 2005. Europarl: A parallel corpus for
statistical machine translation. MT Summit.
Ryan T. McDonald, Joakim Nivre, Yvonne
Quirmbach-Brundage, Yoav Goldberg, Dipan-
jan Das, Kuzman Ganchev, Keith Hall, Slav Petrov,
Hao Zhang, Oscar T¨ackstr¨om, Claudia Bedini,
N´uria Bertomeu Castell´o, and Jungmee Lee. 2013.
Universal dependency annotation for multilingual
parsing. In ACL (2), pages 92–97.
Franz Josef Och and Hermann Ney. 2003. A sys-
tematic comparison of various statistical alignment
models. Comput. Linguist., 29(1):19–51, March.
Matt Post and Daniel Gildea. 2009. Bayesian learning
of a tree substitution grammar. In Proceedings of the
ACL-IJCNLP 2009 Conference Short Papers, pages
45–48. Association for Computational Linguistics.
Ben Swanson and Eugene Charniak. 2013. Extracting
the native language signal for second language ac-
quisition. In Proceedings of the 2013 Conference of
the North American Chapter of the Association for
Computational Linguistics: Human Language Tech-
nologies, pages 85–94, Atlanta, Georgia, June. As-
sociation for Computational Linguistics.
</reference>
<page confidence="0.999106">
173
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.931715">
<title confidence="0.999873">Data Driven Language Transfer Hypotheses</title>
<author confidence="0.999772">Ben Swanson Eugene Charniak</author>
<affiliation confidence="0.999994">Brown University Brown University</affiliation>
<address confidence="0.958108">Providence, RI Providence, RI</address>
<email confidence="0.99846">chonger@cs.brown.eduec@cs.brown.edu</email>
<abstract confidence="0.998561555555556">Language transfer, the preferential second language behavior caused by similarities to the speaker’s native language, requires considerable expertise to be detected by humans alone. Our goal in this work is to replace expert intervention by data-driven methods wherever possible. We define a computational methodology that produces a concise list of lexicalized syntactic patterns that are controlled for redundancy and ranked by relevancy to language transfer. We demonstrate the ability of our methodology to detect hundreds of such candidate patterns from currently available data sources, and validate the quality of the proposed patterns through classification experiments.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Julian Brooke</author>
<author>Graeme Hirst</author>
</authors>
<title>Measuring Interlanguage: Native Language Identification with L1-influence Metrics.</title>
<date>2012</date>
<booktitle>In Proceedings of the Eighth International Conference on Language Resources and Evaluation (LREC-2012),</booktitle>
<pages>779--784</pages>
<location>Istanbul, Turkey,</location>
<contexts>
<context position="4886" citStr="Brooke and Hirst (2012)" startWordPosition="759" endWordPosition="762"> primarily on nouns while we focus on stopwords. We also transform the UTB into constituent format, in a manner inspired by Carroll and Charniak (1992). There is a large amount of related research in Native Language Identification (NLI), the task of predicting L1 given L2 text. This work has culminated in a well attended shared task (Tetreault et al., 2013), whose cited report contains an excellent survey of the history of this task. In NLI, however, L1 data is not traditionally used, and patterns are learned directly from L2 text that has been annotated with L1 labels. One notable outlier is Brooke and Hirst (2012), which attempts NLI using only L1 data for training using large online dictionaries to tie L2 English bigrams and collocations to possible direct translations from native languages. Jarvis and Crossley (2012) presents another set of studies that use NLI as a method to form language transfer hypotheses. 3 Methodology The first of the four basic requirements of our proposed method is the definition of a class of features F such that a single feature F E F is capable of capturing language transfer phenomenon. The second is a universal representation of both L1 and L2 data that allows us to count</context>
</contexts>
<marker>Brooke, Hirst, 2012</marker>
<rawString>Julian Brooke and Graeme Hirst. 2012. Measuring Interlanguage: Native Language Identification with L1-influence Metrics. In Proceedings of the Eighth International Conference on Language Resources and Evaluation (LREC-2012), pages 779– 784, Istanbul, Turkey, May. European Language Resources Association (ELRA). ACL Anthology Identifier: L12-1016.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Glenn Carroll</author>
<author>Eugene Charniak</author>
</authors>
<title>Two experiments on learning probabilistic dependency grammars from corpora.</title>
<date>1992</date>
<tech>Technical Report CS-92-16,</tech>
<institution>Brown University,</institution>
<location>Providence, RI, USA.</location>
<contexts>
<context position="4414" citStr="Carroll and Charniak (1992)" startWordPosition="677" endWordPosition="680">mbine these disparate efforts. Our analysis methods are closely tied to those described in Swanson and Charniak (2013), which contrasts techniques for the discovery of discriminative TSG fragments in L2 text. We modify and extend these methods to apply to the universal dependency treebanks of McDonald et al. (2013), which we will refer to below to as the UTB. Bilingual lexicon construction (Haghighi et al., 2008) is also a key component, although previous work has focused primarily on nouns while we focus on stopwords. We also transform the UTB into constituent format, in a manner inspired by Carroll and Charniak (1992). There is a large amount of related research in Native Language Identification (NLI), the task of predicting L1 given L2 text. This work has culminated in a well attended shared task (Tetreault et al., 2013), whose cited report contains an excellent survey of the history of this task. In NLI, however, L1 data is not traditionally used, and patterns are learned directly from L2 text that has been annotated with L1 labels. One notable outlier is Brooke and Hirst (2012), which attempts NLI using only L1 data for training using large online dictionaries to tie L2 English bigrams and collocations </context>
</contexts>
<marker>Carroll, Charniak, 1992</marker>
<rawString>Glenn Carroll and Eugene Charniak. 1992. Two experiments on learning probabilistic dependency grammars from corpora. Technical Report CS-92-16, Brown University, Providence, RI, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Trevor Cohn</author>
<author>Phil Blunsom</author>
</authors>
<title>Blocked inference in bayesian tree substitution grammars.</title>
<date>2010</date>
<pages>225--230</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="3197" citStr="Cohn and Blunsom, 2010" startWordPosition="486" endWordPosition="489"> features whose usage frequency can be determined for each L1 background in both L1 and L2 text (e.g. both German and English written by Germans). We claim that a feature exhibiting a sufficiently non-uniform usage histogram in L1 that is mirrored in L2 data is a strong language transfer candidate, and provide a quantified measure of this property. We represent both L1 and L2 sentences in a universal constituent-style syntactic format and model language transfer hypotheses with contiguous syntax sub-structures commonly known as Tree Substitution Grammar (TSG) fragments (Post and Gildea, 2009)(Cohn and Blunsom, 2010). With these features we produce a concise ranked list of candidate language transfer hypotheses and their usage statistics that can be automatically augmented as increasing amounts of data become available. 169 Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 169–173, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics 2 Related Work This work leverages several recently released data sets and analysis techniques, with the primary contribution being the transformations necessary to combine thes</context>
</contexts>
<marker>Cohn, Blunsom, 2010</marker>
<rawString>Trevor Cohn and Phil Blunsom. 2010. Blocked inference in bayesian tree substitution grammars. pages 225–230. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aria Haghighi</author>
<author>Percy Liang</author>
<author>Taylor Berg-Kirkpatrick</author>
<author>Dan Klein</author>
</authors>
<title>Learning bilingual lexicons from monolingual corpora.</title>
<date>2008</date>
<booktitle>In ACL,</booktitle>
<pages>771--779</pages>
<contexts>
<context position="4203" citStr="Haghighi et al., 2008" startWordPosition="641" endWordPosition="644">ociation for Computational Linguistics 2 Related Work This work leverages several recently released data sets and analysis techniques, with the primary contribution being the transformations necessary to combine these disparate efforts. Our analysis methods are closely tied to those described in Swanson and Charniak (2013), which contrasts techniques for the discovery of discriminative TSG fragments in L2 text. We modify and extend these methods to apply to the universal dependency treebanks of McDonald et al. (2013), which we will refer to below to as the UTB. Bilingual lexicon construction (Haghighi et al., 2008) is also a key component, although previous work has focused primarily on nouns while we focus on stopwords. We also transform the UTB into constituent format, in a manner inspired by Carroll and Charniak (1992). There is a large amount of related research in Native Language Identification (NLI), the task of predicting L1 given L2 text. This work has culminated in a well attended shared task (Tetreault et al., 2013), whose cited report contains an excellent survey of the history of this task. In NLI, however, L1 data is not traditionally used, and patterns are learned directly from L2 text tha</context>
</contexts>
<marker>Haghighi, Liang, Berg-Kirkpatrick, Klein, 2008</marker>
<rawString>Aria Haghighi, Percy Liang, Taylor Berg-Kirkpatrick, and Dan Klein. 2008. Learning bilingual lexicons from monolingual corpora. In ACL, pages 771–779.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott Jarvis</author>
<author>Scott Crossley</author>
<author>editors</author>
</authors>
<title>Approaching Language Transfer Through Text Classification: Explorations in the Detection-based Approach, volume 64. Multilingual Matters Limited,</title>
<date>2012</date>
<location>Bristol, UK.</location>
<marker>Jarvis, Crossley, editors, 2012</marker>
<rawString>Scott Jarvis and Scott Crossley, editors. 2012. Approaching Language Transfer Through Text Classification: Explorations in the Detection-based Approach, volume 64. Multilingual Matters Limited, Bristol, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Europarl: A parallel corpus for statistical machine translation.</title>
<date>2005</date>
<publisher>MT Summit.</publisher>
<contexts>
<context position="12012" citStr="Koehn, 2005" startWordPosition="2041" endWordPosition="2042">TOEFLO exam essays. FiA B C L1 Data DE FR ES D E F L2 Data EN DE FR ES G 1 R(F) = |TF |1:PF(L 7� L∗t) t∈T F 171 nally, we use the Penn Treebank as our source of native English data, for a total of seven data types; four in English, and one in each L1. When calculating metrics such as redundancy and R(F) we use all available data. For TSG sampling, we balance our data sets to 4000 sentences from each data type and sample using the Enbuske sampler that was released with Swanson and Charniak (2013). To construct word clusters, we use Giza++ (Och and Ney, 2003) and train on the Europarl data set (Koehn, 2005), using .25 as a threshold for construction on connected components. We encourage the reader to peruse the full list of results1, in which each item contains the information in the following example. advcl VERB-L VERB VERB-R mark 110 ES DE FR L1 4.2 0.0 0.0 L2 2.3 0.3 0.3 This fragment corresponds to an adverbial clause whose head is a verb in the cluster 110, which contains the English word “is” and its various translations. This verb has a single left dependent, a clause marker such as “because”, and at least one right dependent. Its prevalence in Spanish can explained by examining the trans</context>
</contexts>
<marker>Koehn, 2005</marker>
<rawString>Philipp Koehn. 2005. Europarl: A parallel corpus for statistical machine translation. MT Summit.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan T McDonald</author>
<author>Joakim Nivre</author>
</authors>
<title>Yvonne Quirmbach-Brundage, Yoav Goldberg, Dipanjan Das, Kuzman Ganchev, Keith Hall, Slav Petrov, Hao Zhang, Oscar T¨ackstr¨om,</title>
<date>2013</date>
<journal>Claudia Bedini, N´uria Bertomeu Castell´o, and</journal>
<volume>2</volume>
<pages>92--97</pages>
<marker>McDonald, Nivre, 2013</marker>
<rawString>Ryan T. McDonald, Joakim Nivre, Yvonne Quirmbach-Brundage, Yoav Goldberg, Dipanjan Das, Kuzman Ganchev, Keith Hall, Slav Petrov, Hao Zhang, Oscar T¨ackstr¨om, Claudia Bedini, N´uria Bertomeu Castell´o, and Jungmee Lee. 2013. Universal dependency annotation for multilingual parsing. In ACL (2), pages 92–97.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Comput. Linguist.,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="11963" citStr="Och and Ney, 2003" startWordPosition="2030" endWordPosition="2033">consists of over 10K sentences per L1 label drawn from TOEFLO exam essays. FiA B C L1 Data DE FR ES D E F L2 Data EN DE FR ES G 1 R(F) = |TF |1:PF(L 7� L∗t) t∈T F 171 nally, we use the Penn Treebank as our source of native English data, for a total of seven data types; four in English, and one in each L1. When calculating metrics such as redundancy and R(F) we use all available data. For TSG sampling, we balance our data sets to 4000 sentences from each data type and sample using the Enbuske sampler that was released with Swanson and Charniak (2013). To construct word clusters, we use Giza++ (Och and Ney, 2003) and train on the Europarl data set (Koehn, 2005), using .25 as a threshold for construction on connected components. We encourage the reader to peruse the full list of results1, in which each item contains the information in the following example. advcl VERB-L VERB VERB-R mark 110 ES DE FR L1 4.2 0.0 0.0 L2 2.3 0.3 0.3 This fragment corresponds to an adverbial clause whose head is a verb in the cluster 110, which contains the English word “is” and its various translations. This verb has a single left dependent, a clause marker such as “because”, and at least one right dependent. Its prevalenc</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Comput. Linguist., 29(1):19–51, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matt Post</author>
<author>Daniel Gildea</author>
</authors>
<title>Bayesian learning of a tree substitution grammar.</title>
<date>2009</date>
<booktitle>In Proceedings of the ACL-IJCNLP 2009 Conference Short Papers,</booktitle>
<pages>45--48</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="3173" citStr="Post and Gildea, 2009" startWordPosition="483" endWordPosition="486">f a class of linguistic features whose usage frequency can be determined for each L1 background in both L1 and L2 text (e.g. both German and English written by Germans). We claim that a feature exhibiting a sufficiently non-uniform usage histogram in L1 that is mirrored in L2 data is a strong language transfer candidate, and provide a quantified measure of this property. We represent both L1 and L2 sentences in a universal constituent-style syntactic format and model language transfer hypotheses with contiguous syntax sub-structures commonly known as Tree Substitution Grammar (TSG) fragments (Post and Gildea, 2009)(Cohn and Blunsom, 2010). With these features we produce a concise ranked list of candidate language transfer hypotheses and their usage statistics that can be automatically augmented as increasing amounts of data become available. 169 Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 169–173, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics 2 Related Work This work leverages several recently released data sets and analysis techniques, with the primary contribution being the transformations n</context>
</contexts>
<marker>Post, Gildea, 2009</marker>
<rawString>Matt Post and Daniel Gildea. 2009. Bayesian learning of a tree substitution grammar. In Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 45–48. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ben Swanson</author>
<author>Eugene Charniak</author>
</authors>
<title>Extracting the native language signal for second language acquisition.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>85--94</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Atlanta, Georgia,</location>
<contexts>
<context position="3905" citStr="Swanson and Charniak (2013)" startWordPosition="589" endWordPosition="592">sfer hypotheses and their usage statistics that can be automatically augmented as increasing amounts of data become available. 169 Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 169–173, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics 2 Related Work This work leverages several recently released data sets and analysis techniques, with the primary contribution being the transformations necessary to combine these disparate efforts. Our analysis methods are closely tied to those described in Swanson and Charniak (2013), which contrasts techniques for the discovery of discriminative TSG fragments in L2 text. We modify and extend these methods to apply to the universal dependency treebanks of McDonald et al. (2013), which we will refer to below to as the UTB. Bilingual lexicon construction (Haghighi et al., 2008) is also a key component, although previous work has focused primarily on nouns while we focus on stopwords. We also transform the UTB into constituent format, in a manner inspired by Carroll and Charniak (1992). There is a large amount of related research in Native Language Identification (NLI), the </context>
<context position="8098" citStr="Swanson and Charniak (2013)" startWordPosition="1334" endWordPosition="1337">ability to det nsubj dobj poodle NN VBZ VBZ-R chews dobj PRP it 170 or from one of the L2 stopwords. The edges in this graph exist only between L2 and L1 words, and are directed with weight equal to the IBM model’s translation probability of the edge’s target given its source. We construct ML by removing edges with weight below some threshold and calculating the connected components of the resulting graph. We then discard any cluster that does not contain at least one word from each L1 and at least one L2 stopword. To propose a candidate list C, we use the TSG induction technique described in Swanson and Charniak (2013), which simultaneously induces multiple TSGs from data that has been partitioned into labeled types. This method permits linguistically motivated constraints as to which grammars produce each type of data. For an experimental setup that considers n different L1s, we use 2n+1 data types; Figure 1 shows the exact layout used in our experiments. Besides the necessary n data types for each L1 in its actual native language form and n in L2 form, we also include L2 data from L2 native speakers. We also define 2n + 1 grammars. We begin with n grammars that can each be used exclusively by one native l</context>
<context position="11900" citStr="Swanson and Charniak (2013)" startWordPosition="2019" endWordPosition="2022">se the ETS Corpus of Non-Native English (Blanchard et al., 2013), which consists of over 10K sentences per L1 label drawn from TOEFLO exam essays. FiA B C L1 Data DE FR ES D E F L2 Data EN DE FR ES G 1 R(F) = |TF |1:PF(L 7� L∗t) t∈T F 171 nally, we use the Penn Treebank as our source of native English data, for a total of seven data types; four in English, and one in each L1. When calculating metrics such as redundancy and R(F) we use all available data. For TSG sampling, we balance our data sets to 4000 sentences from each data type and sample using the Enbuske sampler that was released with Swanson and Charniak (2013). To construct word clusters, we use Giza++ (Och and Ney, 2003) and train on the Europarl data set (Koehn, 2005), using .25 as a threshold for construction on connected components. We encourage the reader to peruse the full list of results1, in which each item contains the information in the following example. advcl VERB-L VERB VERB-R mark 110 ES DE FR L1 4.2 0.0 0.0 L2 2.3 0.3 0.3 This fragment corresponds to an adverbial clause whose head is a verb in the cluster 110, which contains the English word “is” and its various translations. This verb has a single left dependent, a clause marker suc</context>
</contexts>
<marker>Swanson, Charniak, 2013</marker>
<rawString>Ben Swanson and Eugene Charniak. 2013. Extracting the native language signal for second language acquisition. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 85–94, Atlanta, Georgia, June. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>