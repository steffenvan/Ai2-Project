<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000004">
<title confidence="0.9950095">
Multilingual Summary Generation in a Speech—To—Speech
Translation System for Multilingual Dialogues*
</title>
<author confidence="0.973322">
Jan Alexandersson, Peter PoIler, Michael Kipp, Ralf Engel
</author>
<sectionHeader confidence="0.6258094" genericHeader="abstract">
DFKI GmbH
Stublsatzenhausweg 3
66123 Saarbriicken
falexandersson,poller ,engel ,kipplOdfki .de
Abstract
</sectionHeader>
<bodyText confidence="0.999986416666667">
This paper describes a novel functionality of the
VERBMOBIL system, a large scale translation sys-
tem designed for spontaneously spoken multilingual
negotiation dialogues. The task is the on-demand
generation of dialogue scripts and result summaries
of dialogues. We focus on summary generation and
show how the relevant data are selected from the
dialogue memory and how they are packed into
an appropriate abstract representation. Finally, we
demonstrate how the existing generation module of
VERBMoniL was extended to produce multilingual
and result summaries from these representations.
</bodyText>
<sectionHeader confidence="0.96919" genericHeader="method">
I Introduction
</sectionHeader>
<bodyText confidence="0.999506292682927">
In the last couple of years different methods for
summarization have been developed. In this pa-
per we report on a new system functionality within
the scope of VErteMoBiL (Bub et al., 1997), a fully
implemented speech-to-speech translation system,
that generates German or English dialogue scripts
(Alexandersson and Poller, 1998) as well as Ger-
man or English summaries of a multilingual nego-
tiation dialogue held with assistance of the system.
By a script we mean a document that reflects the
domain-specific propositional contents of the indi-
vidual turns of a dialogue as a whole, while a sum-
mary gives a compact summarization of all negotia-
tions the dialogue participants agreed on.
The key idea behind our approach is to utilize
as many existing resources as possible. Conceptu-
ally we have added one module (although techni-
cally realized in different already existing modules
of the overall VEnuMonii., system) - the summary
generator. Besides formatting, our new module gen-
erates sequences of language specific (i.e., German).
semantic representations for the generation of s&apos;Unir-
maries/scripts based on the content of the dialogue
memory (Kipp et al., 1999). These descriptions are
&apos; The research within VERDMODIL presented here is funded
by the German Ministry of Research and Technology under
grant. O1IVIO11{/l. The authors would like to thank Tilman
Becker for comments on earlier drafts on this paper, and
Stephan Leech for invaluable help with programming.
realized into text by the existing VERBMOBIL gen-
erator (Becker et al., 1998). To produce multilingual
summaries we utilize the transfer module of VERB-
MOBIL (Dorna and Emele, 1996).
The next section gives an overview of the VERB-
MOBIL system focusing on the modules central for
the production of summaries/scripts. It is followed
by a section describing the extraction and mainte-
nance of summary relevant data. We then describe
the functionality of the summary generator in detail.
An excerpt of the sample dialogue we refer to in the
paper is given at the end of the paper.
</bodyText>
<sectionHeader confidence="0.988486" genericHeader="method">
2 Prerequisites
</sectionHeader>
<bodyText confidence="0.99993825">
VERBMOBIL is a speech-to-speech translation
project, which at present is approaching its end and
in which over 100 researchers&apos; at academic and in-
dustrial sites are developing a translation system
for multilingual negotiation dialogues (held face to
face or via telephone) using English, German, and
Japanese. The main difference between VEREIMO-
BIL and, c.f., man-machine dialogue systems is that
VERBMOBIL mediates the dialogue instead of con-
trolling it. Consequently, the complete dialogue
structure as well as almost the complete macro-
planning is out of the system&apos;s control.
The running system of today is complex, consist-
ing of inure than 75 separate modules. About one
third of them concerns linguistic processing and the
rest serves technical purposes. (For more informa-
tion see for instance (Bub et al., 1997)). For the sake
of this paper we concentrate on a small part of the
system as shown in figure 1.
A user contribution is called a turn which is di-
vided into segments. A segment ideally resembles
a complete sentence as we know it from traditional
grammars: However, because of the spontaneity of
the user input and because the turn is chunked by
a statistical process, the input segments for the lin-
guistic components are sometimes merely pieces of
linguistic material. For the dialogue memory and
one of the shallow translation components the din-
</bodyText>
<footnote confidence="0.952955">
&apos;See http://verbmobil.dfki.de for the list of project
partners.
</footnote>
<page confidence="0.991497">
148
</page>
<figure confidence="0.985988857142857">
Deep translation track:
Deep
AnalYsis
A
oGemeratioa
Recognition Selection
Dialog and --C.-
Prosody Synthesis
A
Context and
Control Information
Shallow
Analysis/
Data Translation
</figure>
<figureCaption confidence="0.999893">
Figure I: Part of the VERBMOB1L system
</figureCaption>
<bodyText confidence="0.99954672972973">
logue act (Alexandersson et al., 1998) plays an im-
portant role. The dialogue act represents the com-
municative function of an utterance, which is an im-
portant information for the translation as well as the
modeling of the dialogue as a whole. Examples of il-
locutionary acts are REQUEST and GREET. Other
acts can carry propositional content, like SUGGEST
and INFORM_FEATURE.
To obtain a good translation and enhance the
robustness of the overall system the translation is
based on several competing translation tracks, each
based on different paradigms. The deep translation
track consists of an HPSO based analysis, semantic
transfer and finally a TAG-based generator (VM-
GECO). The linguistic information within this track
is encoded in a so-called VIT2 (Bos et al., 1996;
Dorna, 1996) which is a formalism following DRT.
It consists of a set of semantic conditions (i.e. predi-
cates, roles, operators and quantifiers) and allows for
underspecification with respect to scope and subor-
dination or inherent underspecification. A graphical
representation of the VIT for the English sentence
They will meet at the station&amp;quot; is shown in figure 2.
Besides the deep translation track several shallow
tracks have been developed. The main source of
input for the generation of summaries comes from
one of these shallow analysis components (described
in section 3) which produces dialogue acts, topic
suggestions and expressions in a new knowledge
representation language called DIREX3. These ex-
pressions represent domain related information like
source and destination cities, dates,. important hotel
related data, and meeting points. This input is pro-
cessed by the dialogue module which computes the
relevant (accepted) objects of the negotiation (each
consisting of dialogue act, topic, and a DIREx)
Figure 3 shows the conceptual architecture, where
</bodyText>
<footnote confidence="0.9970195">
2Verbmobil Interface Term
3DomaIn Represeniat on EXpression
</footnote>
<figure confidence="0.327324">
index(lhijn3A2)
</figure>
<figureCaption confidence="0.922259">
Figure 2: Graphical representation of VIT for &amp;quot;They
will meet at the station&amp;quot;
</figureCaption>
<bodyText confidence="0.828967666666667">
the summary generation process as a whole is indi-
cated with thicker lines. It consists of the following
steps:
</bodyText>
<listItem confidence="0.9944078">
o Content Selection: The relevant structures are
selected from the dialogue memory.
* Summary Generation: These structures are
converted into sequences of semantic descriptions
(VITs) of full sentences for German (see section 4).
o Transfer: Depending on the target language, the
German sentence VITs are sent through the transfer
module.
o Sentence Generation: The VITs are generated
by the existing V ERBMOBil. generator (Becker et al..
</listItem>
<page confidence="0.991806">
149
</page>
<figure confidence="0.9989239">
E
&amp;quot;DIRIK&amp;quot;
Seq,s of
Gen,.
VITu
Forentting
nIxectIves
Transfer
VOT1V10116Z
TEXT
</figure>
<figureCaption confidence="0.999667">
Figure 3: Conceptual Architecture of the Summary Generation Process
</figureCaption>
<bodyText confidence="0.879974">
2000).
</bodyText>
<listItem confidence="0.7866225">
* Presentation: The sentences are incorporated
into the final, e.g., HTML document.
</listItem>
<bodyText confidence="0.996244285714286">
Throughout the paper we will refer to a German-
English dialogue (see appendix for an excerpt).
The information presented there is the spoken sen-
tence(s) together with the information extracted as
described in section 3. To save space we only present
parts of it, namely those which give rise to the struc-
tures in figure 4.
</bodyText>
<sectionHeader confidence="0.876431" genericHeader="method">
3 Extraction and Maintenance of
Protocol Relevant Data
</sectionHeader>
<bodyText confidence="0.9916108">
The dialogue memory gets its input from one of
the shallow translation components, which bases
its translation on the dialogue act and DIREX-
expression extracted from the segment. The input
is a triple consisting of:
</bodyText>
<listItem confidence="0.855660833333333">
▪ Dialogue Act representing the intention of the
segment.
• Topic is one of the four topics scheduling, travel-
ing, accommodation and entertainment.
* Direx representing the propositional content of
the segment.
</listItem>
<bodyText confidence="0.978655379310345">
For the extraction of propositional content and in-
tention we use a combination of knowledge based
and statistical methods. To compute the propo-
sitional content finite state transducers (FSTs)
(Appelt et al., 1993) with built-in functions are
used (Kipp et al.. 1999). The intention (represented
by a dialogue act) is computed statistically us-
ing language models (Reithing,er and Klesen, 1997).
Both methods were chosen because of their robust-
ness - since the speech recognizers have a word error
rate of about 20%, we cannot expect sound input
for the analysis. Also the segmentation of turns in
utterances is stochastic and therefore sometimes de-
livers suboptimal segments. Consider the input to
be processed:
I would so we were to leave Hamburg on the
first
where the speech recognize,&apos; replaced &amp;quot;good so we
will&amp;quot; with &apos;&apos;I would so we were to-. The result of
the extraction module looks like:
&apos; [INF ORM -,-trav eling-, has _move : [move ,
has_source_locat ion : [city , has_name=-
&apos; hamburg &apos; ] ,has_departure_t ime :
[date , t ime= [day : 1] ] ] I
The result consists of the dialogue act INFORM,
the topic suggestion traveling, and and a DIREX.
The top object is a move with two roles: A source
location (which is a city - Hanover), and a departure
time (which is a date - day I).
</bodyText>
<subsectionHeader confidence="0.888976">
Dialog processing
</subsectionHeader>
<bodyText confidence="0.999727314285714">
For each utterance, and hence each DIREX the di-
alogue manager (1) estimates its relevance, and (2)
enriches it with context. For summary generation,
we are solely interested in the most specific, accepted
objects. Therefore, we also (3) compute more spe-
cific/general relations between objects:
Relevance detection. Depending on the dialogue act
of the current utterance different courses of action
are taken. SUGGEST dialogue acts trigger the stor-
age, completion, focusing and inter-object relation
(see below) computation for the current structure.
ACCEPT and REJECT acts let the system [[lark the
focused object accepted/rejected.
Object Completion. Suggestions in negotiation dia-
logues are incomplete most of the time. E.g., the
utterance &amp;quot;I would prefer to leave at five&amp;quot; is a sug-
gestion referring to the departure time for a trip
from Munich to Hanover on the 19. Jan. 2000 (see
turn 1005 in the appendix). Most of the complete
data has been mentioned in the preceding dialogue.
Our completion algorithm uses the focused object
(itself a completed suggestion) to complete the cur-
rent structure. All non-conflicting information of the
focused object is copied onto the new object. In our
example the current temporal information &amp;quot;I would
prefer to leave at five&amp;quot; would be completed with date
(i.e., &amp;quot;19. Jan. 2000&amp;quot;) and other travel data (&amp;quot;trip
from Munich to Hanover&amp;quot;). Afterwards, it will be
put to focus.
Object Relations. The processing results in a number
of accepted and rejected objects. Normally, a nego-
tiation produces a series of suggestions that become
more specific over time. For each new object we cal-
culate the relation to all other suggestions in terms
of more .specific/general or equal. A final inference
</bodyText>
<page confidence="0.987595">
150
</page>
<bodyText confidence="0.999827666666667">
procedure then filters redundant objects and pro-
duces a list of accepted objects with highest speci-
ficity. Figure 4 shows two such objects extracted
from the sample dialogue. Both structures have been
completed from context data including situational
data, i.e., current time and place of the negotiation.
</bodyText>
<equation confidence="0.9442228">
Topic SCHEDULING
relations:
((MORE_SPECIFIC_THAN .&apos;#&lt;APPOINTNENT P2*&gt;))
APPOINTMENT (P5*-0-0)
HAS_LOCATION --&gt; CITY (P4*)
HAS_NAME=&amp;quot;hannover&amp;quot;
HAS_MEETING --&gt; MEETING (P3**)
HAS_NAME=&amp;quot;geschaeftstreffen&amp;quot;
HAS_DATE --&gt; DATE (P5*)
TEMPEX=[year:2000,
month:jan,
day:20,
part: am,
time:11:0]
relations:
((MORE_SPECIFIC_THAN . #&lt;APPOINTMENT P26*&gt;)
(MORE_SPECIFIC_THAN . #&lt;APPOINTMENT P30**+0&gt;))
APPOINTMENT (P29*4-0)
HAS_LOCATION --&gt; NONGEO_LOCATION (P30***)
HAS_NAME=&amp;quot;bahnhof&amp;quot;
HAS_DATE --&gt; DATE (P29*)
TEMPEX=ryear:2000,
month: Jan,
day: 19,
time: 9:301
</equation>
<figureCaption confidence="0.9452305">
Figure 4: The scheduling part of the thematic struc-
ture
</figureCaption>
<sectionHeader confidence="0.971554" genericHeader="method">
4 Generating Summaries
</sectionHeader>
<bodyText confidence="0.80015319047619">
Our system uses many of the existing components
of VERB MOBIL. However, we had to develop a new
component, the summary generator, which is de-
scribed below. It salves the task of mapping the
DIFtEX structures selected in the dialogue memory
into sequences of full fledged semantic sentence de-
scriptions (VITs), thereby performing the following
steps:
o Document Planning: Extracting, preparing
and dividing the content of the dialogue memory into
a predefined format. -This includes, c.f., time/place
of negotiation, participants, result of the negotia-
tion.
O Sentence Planning: Splitting the input into
chunks suitable for a sentence. This process in-
volves choosing an appropriate verb and arranging
the parts of the chunk as arguments and/or ad-
juncts. The final step is the mapping of this internal
representation onto a semantic description (VIT) for
each sentence (suitable for further .processing by the
existing VERBMOBIL components).
</bodyText>
<listItem confidence="0.974927">
• Generation: Verbalizing the VITs by the exist-
ing multilingual generator of VERBMOBIL.
• Presentation: Formatting of the complete doc-
</listItem>
<bodyText confidence="0.986345769230769">
ument content to an, e.g., HTML—page. Finally, the
document is displayed by an appropriate browser.
Our approach has been mostly guided by robust-
ness: our representation language (DirtEx) was co-
developed during the course of the project. More-
over, as the extraction. component increased its vo-:
cabulary, we wanted to be able to generate new in-
formation which had not been seen before. Hence
we needed an approach which is fault tolerant. In-
stead of failing when the representation changes or
new type of objects were introduced we degrade in
precision. Our two step approach has proven its use-
fulness for this.
</bodyText>
<subsectionHeader confidence="0.962601">
4.1 Document Planning
</subsectionHeader>
<bodyText confidence="0.997270272727273">
The document itself contains two main parts. The
top of the document includes general informa-
tion about the dialogue (place, date, participants,
theme). The body of the document contains the
summary part which is divided into four paragraphs,
each of them verbalizing the agreements for one ne-
gotiation topic: scheduling, accommodation, travel-
ing and entertainment. Therefore, our document
planning is very straightforward. The four elements
of the top document are processed in the following
manner:
</bodyText>
<listItem confidence="0.970444909090909">
* Place and Date: For place and date the informa-
tion is simply retrieved from the dialogue memory.
• Participants: The participants information are
transformed into a VIT by the plan processor de-
scribed below. In the absence of name/title infor-
mation, a character, e.g., A, B, ... is used.
o Theme: By a shallow examination of the result of
the content extraction, a semantic description corre-
sponding to a noun phrase mirroring the content of
the document as a whole is construed. An example
is Business trip with accommodation.
</listItem>
<bodyText confidence="0.946142818181818">
O The summary: Finally, the summary relevant Di-
REX objects are retrieved from the dialogue mem-
ory: First we compute the most specific suggestions
by using the most specific/general and equal rela-
tions. The remaining suggestions are partitioned
into equivalence classes which are filtered by com-
puting the degree of acceptance. In case of conflict
the most recent one is taken. The resulting set is par-
titioned into the above mentioned topics they belong
to. Finally these are processed by the plan processor
as described below.
</bodyText>
<subsectionHeader confidence="0.942418">
4.2 Sentence Planning
</subsectionHeader>
<bodyText confidence="0.9996585">
We now turn into the process of mapping the inter-
esting part of the dialogue memory onto sequences
</bodyText>
<page confidence="0.99348">
151
</page>
<bodyText confidence="0.999678538461538">
of VITs. An example of the content of one topic -
scheduling - was shown in figure 4. 0.ur two step
approach consists of:
* A plan processor whose task it is to split the
objects selected into chunks suitable for a sentence.
Possibly it contributes to the selection of verbs.
a A semantic constructor whose task it is to con-
vert the output of the plan processor into full fledged
semantic descriptions (VITs) for the sentences of the
document. This second step can be viewed as a ro-
bust fall-back: If the plan processor does not succeed
in obtaining full specifications of all sentence parts,
this step secures a valid and complete specification.
</bodyText>
<subsubsectionHeader confidence="0.786163">
4.2.1 The plan processor
</subsubsectionHeader>
<bodyText confidence="0.999952181818182">
Input to the plan processor (Alexandersson and Rei-
thinger, 1997) is the thematic structure partly shown
in figure 4. The plan processor interprets (currently
about 150) plan operators which are expanded in a
top-down left to right fashion.
For the overall structure of the text, the imposed
topic structure of the thematic structure is kept.
Within a topic we use a set of operators which are ca-
pable of realizing (parts of) the structures to NPs,
PPs and possibly verb information forming a high
level specification of a sentence.
</bodyText>
<subsectionHeader confidence="0.836882">
Plan operators
</subsectionHeader>
<bodyText confidence="0.926009371428571">
A plan operator consists of a goal which is option-
ally divided into subgoal(s). Its syntax contains the
keywords constraints and :actions which can
be any Lisp expression. Variables are indicated with
question/exclamation marks (see figures 5 and 6).
The goal of the operators uses an interface based
on a triple with the following usage:
4. &lt;description&gt; This is the input position of the
operator. It describes and binds the object which
will be processed by this operator.
o &lt;context&gt; This is the context - input/output.
The context contains a stack for objects in focus,
handled as described in (Grosz and Sidner, 1986).
Additionally we put the generated information on a
history list (Dale, 1995). The context supports the
generation of, e.g., pronouns (see below). At present
the context is only used local to each topic.
O &lt;output&gt; The result of the operator. The possible
output types are NP, PP and sentetice(s).
We the distinguish two types of operators; COT7ip1f:1;
operators, responsible for complex objects, which
can contain several roles, and simple operators,
which can process simple objects (carrying only one
role). The general design of a complex operator - see
figure 5 for an operator responsible for appointment
objects - consists of three subgoals:
o (find-roles ) Retrieve the content of the
object. The operators responsible for solving the
f ind-roles goal optionally allow for an enumera-
tion of the roles we want to use.
e (split-roles ...) These roles (and values) will
be .partitioned.into chunks (which we, call a .split)
suitable for generating one sentence.
O (generate-splits ...) Finally the output - a
sentence description - will be constructed.
</bodyText>
<figure confidence="0.997754166666667">
(defplan appointment
:goal ((class (?app scheduling))
(?in-context ?out-context)
?sentence)
:constraints (appointment-p !app)
:subgoals (:sequence
(find-roles ?app ?rels)
(split-roles ?rels
appointment 71-of-splits)
(generate-splits 71-of-splits
(?in-context ?out-context)
appointment ?sentence)))
</figure>
<figureCaption confidence="0.993131">
Figure 5: An example of an operator for a &amp;quot;complex&amp;quot;
object
</figureCaption>
<bodyText confidence="0.9993065">
Behind the functionality of the split-roles goal
we use pairs of operators (figure 6), where the first is
a fact describing the roles of the split, and the second
is a description for how to realize the sentence. In
this example the selection of an appropriate verb is
not performed by this operator but by the semantic
constructor.
The second type of operators are simple operators
like the one for the generation of time expressions
(tempex) or cities (see figure 4).
</bodyText>
<figureCaption confidence="0.7174475">
Figure 7 shows a simplified plan processor output
(building block) for one sentence.
</figureCaption>
<subsubsectionHeader confidence="0.833152">
4.2.2 The Semantic Constructor
</subsubsectionHeader>
<bodyText confidence="0.999952347826087">
The task of the semantic constructor is to map the
information about sentences computed by the plan
processor to full semantic representations (VITs).
The knowledge source for this computational step
is a declarative set of about 160 different semanti-
cally oriented sentence patterns which are encoded
in an easily extendable semantic/syntactic descrip-
tion language.
To obtain a. complete semantic representation for
a sentence we first select a sentence pattern. This
pattern is then, together with the output of the plan
processor, interpreted to produce the VIT. The se-
lection criteria for a sent ence pattern are:
All patterns are ordered topic-wise because
the appropriateness of sentence patterns is topic-
-dependent (e.g., the insertion of topic-specific NPs
or PPs into a sentence).
The intentional state of the information to
be verbalized highly restricts the set of appropriate
verbs.
Depending on the propositional content de-
scribed within a DIRE:\ -VIT - i.e., a VIT repre-
senting one sentence part in a building block of the
</bodyText>
<page confidence="0.985159">
152
</page>
<figure confidence="0.994022034482758">
- Das &lt;Treffen&gt; findet in &lt;City&gt;
am &lt;temper.&gt; statt
The &lt;Meetine-takes place
in &lt;City&gt; on the &lt;temper&gt;
(deffact sentence-split
:goal (sentence-split
((has_meeting ?has_name)
(has_location ?has_location)
(has_date ?has_date))
?_topic))
(defplan generate-split
:goal (generate-split
((has_meeting ?name) - ;;.&apos;meeting
(has_location ?location) ;; city
(has_date ?date)) ; ; temper
(?in-context ?out-context)
?topic
?s)
:subgoals
(:seq ((class (?location ?scheduling pp))
?topic ?loc-pp)
((class (?name ?scheduling))
?topic ?s-topic)
(generate-full-temper ?date ?tempex)
(((generate-sentence decl)
(subj ?topic has_topic)
Cob] ?l-pp has_location)
(obj-add ?tempex has_date))
?in-context ?out-context ?s)))
</figure>
<figureCaption confidence="0.896217">
Figure 6: Example of sentence definition and gener-
ation
</figureCaption>
<equation confidence="0.5452356">
(ACCOMMODATION
(ACCEPTED
(HAS_SIZE VIT:&lt;Einzelzimmer&gt;)
(HAS_PRICE VIT:&lt;80-Euro-pro-Nacht&gt;)
))
</equation>
<figureCaption confidence="0.999886">
Figure 7: Example of a plan processor output
</figureCaption>
<bodyText confidence="0.999412363636364">
plan processor output - it has to play different se-
mantic roles in the sentence (e.g., ‘.erb-argument vs.
verb-complement)
Additionally, the number of DtaEx-VITs given
within a building block for a sentence, influences the
distribution of them to appropriate semantic roles.
Figure 8 shows a simplified sentence pattern that
is selected for the building block in figure 7 to con-
struct a VIT for, e.g., the German sentence Das
Einzelzimmer kostet SO Euro pro Nacht. (&amp;quot;The sin-
gle room costs 80 euro per night.&amp;quot;). According
</bodyText>
<equation confidence="0.66040575">
(( :verb kosten_v)
(:subj HAS_SIZE)
(:obj HAS_PRICE)
(irest. DIREX_PPS))
</equation>
<figureCaption confidence="0.959778">
Figure 8: Example of a sentence pattern
to the above mentioned selection criteria, this pat-
</figureCaption>
<bodyText confidence="0.9913326">
tern is selected only for building blocks within
the, accommo.dationtopic,that_contain at least val-
ues for the roles HAS_SIZE and HAS_PRIZE, respec-
tively. The sentence pattern contains the following
&amp;quot;building instructions&amp;quot;: The semantic verb predi-
cate ( : verb) is kostenAr (to cost), its subject ar-
gument (:subj) is to be filled by the DiftEx-VIT
associated to the DiRex-role HAS_SIZE while :obj
means a similar instruction for the direct object.
The robustness fallback ( :rest DIHEX_PPS) means
that,all_other DIREXVITs are attached to the verb
is-PP complements. It is paft &apos;di all &apos;senteriCe pat-
terns to ensure that even erroneous building blocks
or erroneously selected sentence patterns produce a
sentence VIT.
Finally, the VIT is constructed by interpreting the
sentence pattern. The interpreter walks through the
sentence pattern and performs different actions de-
pending on the keywords, e.g., :verb, :subj and
their values.
</bodyText>
<subsubsectionHeader confidence="0.828769">
4.2.3 Utilizing Context
</subsubsectionHeader>
<bodyText confidence="0.993333387096774">
Duringthe course of the generation, the plan proces-
sor incrementally constructs a context (Dale, 1995),
which allows for the generation of, c.f., anaphora or
demonstratives for making the text fluent or con-
trasting purposes.
* Anaphora If, e.g., a meeting is split into
more than one sentence, the plan processor uses an
anaphora to the meeting in the second sentence.
* Discourse Markers In case of multiple, e.g.,
meetings we introduce the second with a discourse
marker, e.g., &amp;quot;also&amp;quot;.
tt, Demonstratives In case of multiple meetings, we
use a demonstrative to refer to the second meeting.
In addition to the plan processor, the seman-
tic constructor also takes care of coherence within
the paragraphs produced for the individual topics
hereby focusing on the generation of anaphora and
adverbial discourse markers. While the local con-
text of the plan processor is based on the proposi-
tional content at hand, the semantic constructor uses
postprocessing module that is based on the output
VITs of the plan processor (Di itEx-VITs) using its
own semantically oriented local context nienior.
Anaphorization and insertion of discourse mark-
ers within the semantic constructor are based on a
comparison of plan processor output VITs occur-
ring within consecutive sentences of a paragraph.
Identical verb arguments (NPs) in consecutive sen-
tences are replaced by Appropriate anaphoric pro-
nouns while identical verbs themselves lead to the in-
sertion of an appropriate adverbial discourse marker_
</bodyText>
<sectionHeader confidence="0.988077" genericHeader="method">
5 Multilinguality
</sectionHeader>
<bodyText confidence="0.998183666666667">
The generation of dialogue scripts and result SUM-
maries is fully implemented in VEittalomt, for Ger-
man and English. For the English summaries we
</bodyText>
<page confidence="0.998175">
153
</page>
<bodyText confidence="0.997819">
make use of the transfer component as follows. All
VITs from the German document representation are
extracted, then the transfer module produces equiv-
alent English VITs which are finally sent to the En-
glish generation component for producing the En-
glish text.
</bodyText>
<figureCaption confidence="0.884666666666667">
Figure 9 shows the English result summary of the
dialogue shown in the appendix.
Figure 9: Example of an English result summary
</figureCaption>
<sectionHeader confidence="0.985409" genericHeader="evaluation">
6 Evaluation
</sectionHeader>
<bodyText confidence="0.980523428571429">
We have performed a small evaluation of the overall
system as described in this paper. Basis for the eval-
uation were the transcripts of four German-English
negotiation dialogues. For each dialogue the result-
ing features of the negotiation (maximally 47, e.g.,
location, date for a meeting, speakers name and title,
book agent) were annotated by a human, and theii
compared with the result of running the dialogues
through the system and generating the summaries.
The features in the summary were compared using
the following classifications:
a Corr The feature approximately corresponds to
the human annotation. This means that the feature
is either (1) a 100% match; (2) it was not sufficiently
specified or (2) too specific. An example of (2) is
when the correct date included a time, which was
not captured. An example of (3) is when a date
with time was annotated but the feature contained
just a date_
ct Miss A feature is not included in the summary.
tt, False A feature was erroneously included in the
summary, meaning that the feature was not part of
the dialogue or it received a wrong value.
o TN A feature was not part of the dialogue, and
not inclu.ded in, the. summary.
The evaluation result is shown in figure 10. It uses
the standard precision, recall and fallout as defined
in (Mani et. al., 1998).
</bodyText>
<table confidence="0.999821888888889">
Dialogue 1 2 3 4 aver
Turns 33 33 31 32 32.25
Corr 6 13 9 11 9.75
Miss 6 3 5 4 4.5
False 3 3 3 0 2.25
TN 32 28 30 32 30.5
Recall 0.50 0.81 0.64 0.73 0.67
Prec. 0.67 0.81 0.75 1.0 0.81
Fallout 0.09 0.10 0.09 0.00 0.07
</table>
<figureCaption confidence="0.972042">
Figure 10: Evaluation Results
</figureCaption>
<bodyText confidence="0.999900111111111">
Obviously, our approach tries to be on the safe
side; the summary contains only those features that
the system thinks both partners agreed on. The
main reasons for not getting higher numbers is
twofold. The recognition of dialogue acts, and thus
the recognition of the intension behind the utter-
ances reaches a 70% recall (Reithinger and Klesen,
1997). We also still make errors during the content
extraction.
</bodyText>
<sectionHeader confidence="0.998412" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999956454545454">
We have presented an extension to existing modules
allowing for the generation of summaries within the
VERBMOBIL system. To our knowledge our system
is the only one that uses semantic representation as
basis for summarizing. Other approaches use, e.,g.,
statistical techniques or rhetorical parsing (Waibel
et al., 1998; Hovy and Marcu, 1998) to obtain the
summaries. Moreover, although our module is re-
stricted to language specific processing, the use of
semantics and the transfer module allow for the gen-
eration of multilingual documents in a very straight-
forward fashion.
In the near future we will extend the system with
respect to:
I, Sentence Split At present the first found sen-
tence split is chosen. This is not necessarily the op-
timal one. We are currently in the process of devel-
oping criteria for ranking competing results.
e Japanese The \-.TERBMOBIL system currently in-
cludes German, English and Japanese. We intend
to apply the same technique as for the English sum-
maries to generate Japanese ones.
</bodyText>
<sectionHeader confidence="0.998817" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9711425">
1. Alexandersson and P. Poller. 1998. Towards multilin-
gual protocol generation for spontaneous speech dia-
16,0-ues. In Proceedings of INI,G-98, Niagara-On-The-
Lake. Ontario. Canada.
</reference>
<page confidence="0.998948">
154
</page>
<reference confidence="0.996366970588236">
J. Alexandersson and N. Reithinger. 1997. Learning di-
alogue structures from a corpus. In Proceedings of
-Speech-97; pages. 2231-2235,. Rhodes,
Jan Alexandersson, Bianka Buschbeck-Wolf, Tsutomu
Pujinami, Michael Kipp, Stephan Koch, Elisa-
beth Maier, Norbert Reithinger, Birte Schmitz,
and Melanie Siegel. 1998. Dialogue Acts in
VERBMOBIL-2 - Second Edition. Verbmobil-Re_port
226, DFKI Saarbriicken, Universitat Stuttgart, Tech-
niche Universitat Berlin, Universitat des Saarlandes.
D. A_ppelt, J. Hobbs, J. Bear, and M. Tyson. 1993. FAS-
TUS: A. finite-state processor for information extrac-
tion from real-world text. In LICAI-93.
T. Becker, W. Pinkler, A. Kilger, and P. Potter, 1998. An
efficient kernel for multilingual generation in speech-
-to-speech dialogue tLanslation. In -Proceedings of
COLING/ACL-98, Montreal, Quebec, Canada.
T. Becker, A. Kfiger, P. Lopez, and P. Potter. 2000. Mul-
tilingual generation for translation in speech-to-speech
dialogues and its realization in verbmdbil. In Proceed-
ings of RCA 14W00, Berlin, Germany.
J. Bos B. Gamback, C. Lieske, Y. Mori, M. Pinkal, and
K. Worm. 1996. Compositional semantics in verbmo-
bil. In Proceedings of Coling &apos;96, Copenhagen, Den-
mark.
T. Bub, W. Wahlster, and A. Waibel. 1997. Verbmo-
bil: The combination of deep and shallow processing
for spontaneous speech translation. In Proceedings of
ICASSP-97, pages 71-74, Munich.
R. Dale, 1995. An introduction to natural lan-
guage generation. Technical report, Microsoft
Research Institute (MRI), Macquarie Univer-
sity. Presented at the 1995 European Summer
School on Logic, Language and Information, Avail-
able from http://ww-w.mri.mq.edu.aurrdale/nlg-
textbook/ESSLL195/.
M. Dorna and M. Emele. 1996. Efficient Implementation
of a Semantic-Based Transfer Approach. In Proceed-
ings of ECAI-96, pages 567-571, Budapest, Hungary,
August.
M. Dorna. 1996. The ADT-Package for the VERBMOBIL
Interface Term. Verbmobil Report 104, IMS, Univer-
sitat Stuttgart, Germany,
B. Grosz and C. Sidner. 1986. Attention., Intentions and
the Structure of Discourse. Journal of Computational
Linguistics, 12(3).
E. Hovy and D. :Aaron. 1998. Coling/act-98 tu-
torial on automated text summarization. Avail-
able from http://www.isi.edu/
M. Kipp, J. Alexandersson, and N. Reithinger. 1999.
Understanding Spontaneous Negotiation Dialogue. In
Workshop Proceedings &apos;Knowledge And Reasoning in
Practical Dialogue Systems&apos; of LICA&apos; &apos;99, pages 57-
64.
L Mani, D. House, G. Klein, L. Hirschman, L.
Obrist, T. Firmin, M. Chrzanowski, and R.
Sundheina. 1998. Thc tipster summa.e text sum-
marization evaluation - final report. Technical
report, The Mitre Corp. Available from http://www-
24.nist.govirelated_projects/tipster_summacifinal_rpt-
htrul.
N. Reithinger and M. Klesen. 1997. Dialogue Act Clas-
sification Using Language Models. In Proceedings of
EaroSpeech-97, pages 2235-2238, Rhodes.
A. Waibel, M. Bett, M. Fluke, and RStiefelhagen. 1998.
Meeting Browser: Racking and Summarizing Meet-
ings. In Proceedings of the DARPA Broadcast News
Workshop.
</reference>
<sectionHeader confidence="0.96409" genericHeader="conclusions">
Appendix
</sectionHeader>
<bodyText confidence="0.867341">
Excerpt from our sample dialogue.
</bodyText>
<sectionHeader confidence="0.786306" genericHeader="references">
C
</sectionHeader>
<page confidence="0.561083">
1002
</page>
<reference confidence="0.993872773584906">
- ja es geht um das Ceschftstreffen in
Hannover Yes it is about the business
meeting in Hanover)
EINIT,scheduling,has_appointment:
(appointment,has_meeting:[meeting,
has_name=&amp;quot;geschaeftstreffen&apos;],
has_location:Lcity,has_name=&apos;hannover&apos;.
has_loc_spec=in,has_det.unknownil3
- das ist ja am zwanzigsten Januar um elf
Uhr vormittags
ESUGGEST,uncertain_scheduling,has_date:
.1date.tempex=&apos;.(ge_2920_0, [from:
[dom:20,month:jan,tod:11:0,
podmorning_ger2]7)1]
1003
- so we have to leave Munich at six o&apos;clock
CSUGGEST, traveling , has_move : [move,
has_sonrce_location: [city, has_name
=&apos;muenchen&apos;] ,has_departure_time: [date,
temper.&apos; (en_2920_0 , [from: tod :6 : 0]) &apos;13]
1004
- vielleicht fahren wir lieber den Tag davor
(lit.: maybe we better leave the day before)
[SUGGEST,traveling,has_move:Cmove,
has_departure_time:[date,tempex=
1(ge_2920_1,(from:
neg_shift(dur(1,days),ana_point)])&apos;]]]
- da gibt es einen Zug um zwei Uhr
(lit.: there is a train at two o&apos;clock)
[SUCGEST,traveliug,has_move:Emove,has-
_transportation:[rail],has_departure_time:
[date,tempex=&apos;(ge_2920_2,[from:tod:2:01)Ill
1005
- I would prefer to leave at five
[SUGGEST,traveling,has_move:[move,
has_agent:[speaker].has_departure_time:
Edate,tempex=&apos;(en_2920_1,1Lfrom:tod:5:0W1]]
E...]
1011
- let us meet at the station on Wednesday
CSUGGEST,scheduling,has_appointment:
Lnppointment,has_location:[nongeo_location,
has_name=&apos;bahnhof&apos;,has_loc_spec=at,
has_det=def] ,has_date:[date,tempex=
&apos;(en_2920_2,[from:dow:wed])111
1012
- halb zehn am Bahnhof
(lit.: at half past nine at the station)
[ACCEPT,uncertain_scheduling,has_date:[date,
tempex=&apos;(ge_2920_3,Efrom:tod:9:30])&apos;],
has_location:[nongeo_location,has_name=
&apos;bahnhof&apos;]]
C...]
</reference>
<page confidence="0.998768">
155
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.395454">
<title confidence="0.997356">Multilingual Summary Generation in a Multilingual Dialogues*</title>
<author confidence="0.999732">Jan Alexandersson</author>
<author confidence="0.999732">Peter PoIler</author>
<author confidence="0.999732">Michael Kipp</author>
<author confidence="0.999732">Ralf</author>
<affiliation confidence="0.68832">DFKI Stublsatzenhausweg</affiliation>
<address confidence="0.873325">66123</address>
<email confidence="0.795614">falexandersson,poller,engel,kipplOdfki.de</email>
<abstract confidence="0.999926923076923">This paper describes a novel functionality of the a large scale translation system designed for spontaneously spoken multilingual negotiation dialogues. The task is the on-demand generation of dialogue scripts and result summaries dialogues. We focus on summary show how the relevant data are selected from the dialogue memory and how they are packed into an appropriate abstract representation. Finally, we demonstrate how the existing generation module of VERBMoniL was extended to produce multilingual and result summaries from these representations.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Alexandersson</author>
<author>P Poller</author>
</authors>
<title>Towards multilingual protocol generation for spontaneous speech dia16,0-ues.</title>
<date>1998</date>
<booktitle>In Proceedings of INI,G-98,</booktitle>
<location>Niagara-On-TheLake. Ontario. Canada.</location>
<contexts>
<context position="1197" citStr="Alexandersson and Poller, 1998" startWordPosition="163" endWordPosition="166">how the relevant data are selected from the dialogue memory and how they are packed into an appropriate abstract representation. Finally, we demonstrate how the existing generation module of VERBMoniL was extended to produce multilingual and result summaries from these representations. I Introduction In the last couple of years different methods for summarization have been developed. In this paper we report on a new system functionality within the scope of VErteMoBiL (Bub et al., 1997), a fully implemented speech-to-speech translation system, that generates German or English dialogue scripts (Alexandersson and Poller, 1998) as well as German or English summaries of a multilingual negotiation dialogue held with assistance of the system. By a script we mean a document that reflects the domain-specific propositional contents of the individual turns of a dialogue as a whole, while a summary gives a compact summarization of all negotiations the dialogue participants agreed on. The key idea behind our approach is to utilize as many existing resources as possible. Conceptually we have added one module (although technically realized in different already existing modules of the overall VEnuMonii., system) - the summary g</context>
</contexts>
<marker>Alexandersson, Poller, 1998</marker>
<rawString>1. Alexandersson and P. Poller. 1998. Towards multilingual protocol generation for spontaneous speech dia16,0-ues. In Proceedings of INI,G-98, Niagara-On-TheLake. Ontario. Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Alexandersson</author>
<author>N Reithinger</author>
</authors>
<title>Learning dialogue structures from a corpus.</title>
<date>1997</date>
<booktitle>In Proceedings of -Speech-97;</booktitle>
<pages>2231--2235</pages>
<publisher>Rhodes,</publisher>
<contexts>
<context position="16256" citStr="Alexandersson and Reithinger, 1997" startWordPosition="2545" endWordPosition="2549">pproach consists of: * A plan processor whose task it is to split the objects selected into chunks suitable for a sentence. Possibly it contributes to the selection of verbs. a A semantic constructor whose task it is to convert the output of the plan processor into full fledged semantic descriptions (VITs) for the sentences of the document. This second step can be viewed as a robust fall-back: If the plan processor does not succeed in obtaining full specifications of all sentence parts, this step secures a valid and complete specification. 4.2.1 The plan processor Input to the plan processor (Alexandersson and Reithinger, 1997) is the thematic structure partly shown in figure 4. The plan processor interprets (currently about 150) plan operators which are expanded in a top-down left to right fashion. For the overall structure of the text, the imposed topic structure of the thematic structure is kept. Within a topic we use a set of operators which are capable of realizing (parts of) the structures to NPs, PPs and possibly verb information forming a high level specification of a sentence. Plan operators A plan operator consists of a goal which is optionally divided into subgoal(s). Its syntax contains the keywords cons</context>
</contexts>
<marker>Alexandersson, Reithinger, 1997</marker>
<rawString>J. Alexandersson and N. Reithinger. 1997. Learning dialogue structures from a corpus. In Proceedings of -Speech-97; pages. 2231-2235,. Rhodes,</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Alexandersson</author>
<author>Bianka Buschbeck-Wolf</author>
<author>Tsutomu Pujinami</author>
<author>Michael Kipp</author>
<author>Stephan Koch</author>
<author>Elisabeth Maier</author>
<author>Norbert Reithinger</author>
<author>Birte Schmitz</author>
<author>Melanie Siegel</author>
</authors>
<date>1998</date>
<booktitle>Dialogue Acts in VERBMOBIL-2 - Second Edition. Verbmobil-Re_port 226, DFKI Saarbriicken,</booktitle>
<institution>Universitat Stuttgart, Techniche Universitat Berlin, Universitat des Saarlandes.</institution>
<contexts>
<context position="4610" citStr="Alexandersson et al., 1998" startWordPosition="709" endWordPosition="712">nal grammars: However, because of the spontaneity of the user input and because the turn is chunked by a statistical process, the input segments for the linguistic components are sometimes merely pieces of linguistic material. For the dialogue memory and one of the shallow translation components the din&apos;See http://verbmobil.dfki.de for the list of project partners. 148 Deep translation track: Deep AnalYsis A oGemeratioa Recognition Selection Dialog and --C.- Prosody Synthesis A Context and Control Information Shallow Analysis/ Data Translation Figure I: Part of the VERBMOB1L system logue act (Alexandersson et al., 1998) plays an important role. The dialogue act represents the communicative function of an utterance, which is an important information for the translation as well as the modeling of the dialogue as a whole. Examples of illocutionary acts are REQUEST and GREET. Other acts can carry propositional content, like SUGGEST and INFORM_FEATURE. To obtain a good translation and enhance the robustness of the overall system the translation is based on several competing translation tracks, each based on different paradigms. The deep translation track consists of an HPSO based analysis, semantic transfer and f</context>
</contexts>
<marker>Alexandersson, Buschbeck-Wolf, Pujinami, Kipp, Koch, Maier, Reithinger, Schmitz, Siegel, 1998</marker>
<rawString>Jan Alexandersson, Bianka Buschbeck-Wolf, Tsutomu Pujinami, Michael Kipp, Stephan Koch, Elisabeth Maier, Norbert Reithinger, Birte Schmitz, and Melanie Siegel. 1998. Dialogue Acts in VERBMOBIL-2 - Second Edition. Verbmobil-Re_port 226, DFKI Saarbriicken, Universitat Stuttgart, Techniche Universitat Berlin, Universitat des Saarlandes.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Appelt</author>
<author>J Hobbs</author>
<author>J Bear</author>
<author>M Tyson</author>
</authors>
<title>FASTUS: A. finite-state processor for information extraction from real-world text.</title>
<date>1993</date>
<booktitle>In LICAI-93.</booktitle>
<contexts>
<context position="8374" citStr="Appelt et al., 1993" startWordPosition="1291" endWordPosition="1294">gets its input from one of the shallow translation components, which bases its translation on the dialogue act and DIREXexpression extracted from the segment. The input is a triple consisting of: ▪ Dialogue Act representing the intention of the segment. • Topic is one of the four topics scheduling, traveling, accommodation and entertainment. * Direx representing the propositional content of the segment. For the extraction of propositional content and intention we use a combination of knowledge based and statistical methods. To compute the propositional content finite state transducers (FSTs) (Appelt et al., 1993) with built-in functions are used (Kipp et al.. 1999). The intention (represented by a dialogue act) is computed statistically using language models (Reithing,er and Klesen, 1997). Both methods were chosen because of their robustness - since the speech recognizers have a word error rate of about 20%, we cannot expect sound input for the analysis. Also the segmentation of turns in utterances is stochastic and therefore sometimes delivers suboptimal segments. Consider the input to be processed: I would so we were to leave Hamburg on the first where the speech recognize,&apos; replaced &amp;quot;good so we wil</context>
</contexts>
<marker>Appelt, Hobbs, Bear, Tyson, 1993</marker>
<rawString>D. A_ppelt, J. Hobbs, J. Bear, and M. Tyson. 1993. FASTUS: A. finite-state processor for information extraction from real-world text. In LICAI-93.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Becker</author>
<author>W Pinkler</author>
<author>A Kilger</author>
<author>P Potter</author>
</authors>
<title>An efficient kernel for multilingual generation in speech-to-speech dialogue tLanslation.</title>
<date>1998</date>
<booktitle>In -Proceedings of COLING/ACL-98,</booktitle>
<location>Montreal, Quebec, Canada.</location>
<contexts>
<context position="2412" citStr="Becker et al., 1998" startWordPosition="357" endWordPosition="360">ary generator. Besides formatting, our new module generates sequences of language specific (i.e., German). semantic representations for the generation of s&apos;Unirmaries/scripts based on the content of the dialogue memory (Kipp et al., 1999). These descriptions are &apos; The research within VERDMODIL presented here is funded by the German Ministry of Research and Technology under grant. O1IVIO11{/l. The authors would like to thank Tilman Becker for comments on earlier drafts on this paper, and Stephan Leech for invaluable help with programming. realized into text by the existing VERBMOBIL generator (Becker et al., 1998). To produce multilingual summaries we utilize the transfer module of VERBMOBIL (Dorna and Emele, 1996). The next section gives an overview of the VERBMOBIL system focusing on the modules central for the production of summaries/scripts. It is followed by a section describing the extraction and maintenance of summary relevant data. We then describe the functionality of the summary generator in detail. An excerpt of the sample dialogue we refer to in the paper is given at the end of the paper. 2 Prerequisites VERBMOBIL is a speech-to-speech translation project, which at present is approaching it</context>
</contexts>
<marker>Becker, Pinkler, Kilger, Potter, 1998</marker>
<rawString>T. Becker, W. Pinkler, A. Kilger, and P. Potter, 1998. An efficient kernel for multilingual generation in speech-to-speech dialogue tLanslation. In -Proceedings of COLING/ACL-98, Montreal, Quebec, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Becker</author>
<author>A Kfiger</author>
<author>P Lopez</author>
<author>P Potter</author>
</authors>
<title>Multilingual generation for translation in speech-to-speech dialogues and its realization in verbmdbil.</title>
<date>2000</date>
<booktitle>In Proceedings of RCA 14W00,</booktitle>
<location>Berlin, Germany.</location>
<marker>Becker, Kfiger, Lopez, Potter, 2000</marker>
<rawString>T. Becker, A. Kfiger, P. Lopez, and P. Potter. 2000. Multilingual generation for translation in speech-to-speech dialogues and its realization in verbmdbil. In Proceedings of RCA 14W00, Berlin, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Bos B Gamback</author>
<author>C Lieske</author>
<author>Y Mori</author>
<author>M Pinkal</author>
<author>K Worm</author>
</authors>
<title>Compositional semantics in verbmobil.</title>
<date>1996</date>
<booktitle>In Proceedings of Coling &apos;96,</booktitle>
<location>Copenhagen, Denmark.</location>
<marker>Gamback, Lieske, Mori, Pinkal, Worm, 1996</marker>
<rawString>J. Bos B. Gamback, C. Lieske, Y. Mori, M. Pinkal, and K. Worm. 1996. Compositional semantics in verbmobil. In Proceedings of Coling &apos;96, Copenhagen, Denmark.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Bub</author>
<author>W Wahlster</author>
<author>A Waibel</author>
</authors>
<title>Verbmobil: The combination of deep and shallow processing for spontaneous speech translation.</title>
<date>1997</date>
<booktitle>In Proceedings of ICASSP-97,</booktitle>
<pages>71--74</pages>
<location>Munich.</location>
<contexts>
<context position="1056" citStr="Bub et al., 1997" startWordPosition="146" endWordPosition="149">ask is the on-demand generation of dialogue scripts and result summaries of dialogues. We focus on summary generation and show how the relevant data are selected from the dialogue memory and how they are packed into an appropriate abstract representation. Finally, we demonstrate how the existing generation module of VERBMoniL was extended to produce multilingual and result summaries from these representations. I Introduction In the last couple of years different methods for summarization have been developed. In this paper we report on a new system functionality within the scope of VErteMoBiL (Bub et al., 1997), a fully implemented speech-to-speech translation system, that generates German or English dialogue scripts (Alexandersson and Poller, 1998) as well as German or English summaries of a multilingual negotiation dialogue held with assistance of the system. By a script we mean a document that reflects the domain-specific propositional contents of the individual turns of a dialogue as a whole, while a summary gives a compact summarization of all negotiations the dialogue participants agreed on. The key idea behind our approach is to utilize as many existing resources as possible. Conceptually we </context>
<context position="3742" citStr="Bub et al., 1997" startWordPosition="570" endWordPosition="573"> multilingual negotiation dialogues (held face to face or via telephone) using English, German, and Japanese. The main difference between VEREIMOBIL and, c.f., man-machine dialogue systems is that VERBMOBIL mediates the dialogue instead of controlling it. Consequently, the complete dialogue structure as well as almost the complete macroplanning is out of the system&apos;s control. The running system of today is complex, consisting of inure than 75 separate modules. About one third of them concerns linguistic processing and the rest serves technical purposes. (For more information see for instance (Bub et al., 1997)). For the sake of this paper we concentrate on a small part of the system as shown in figure 1. A user contribution is called a turn which is divided into segments. A segment ideally resembles a complete sentence as we know it from traditional grammars: However, because of the spontaneity of the user input and because the turn is chunked by a statistical process, the input segments for the linguistic components are sometimes merely pieces of linguistic material. For the dialogue memory and one of the shallow translation components the din&apos;See http://verbmobil.dfki.de for the list of project p</context>
</contexts>
<marker>Bub, Wahlster, Waibel, 1997</marker>
<rawString>T. Bub, W. Wahlster, and A. Waibel. 1997. Verbmobil: The combination of deep and shallow processing for spontaneous speech translation. In Proceedings of ICASSP-97, pages 71-74, Munich.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Dale</author>
</authors>
<title>An introduction to natural language generation.</title>
<date>1995</date>
<booktitle>European Summer School on Logic, Language and Information, Available from http://ww-w.mri.mq.edu.aurrdale/nlgtextbook/ESSLL195/.</booktitle>
<tech>Technical report,</tech>
<institution>Microsoft Research Institute (MRI), Macquarie University.</institution>
<note>Presented at the</note>
<contexts>
<context position="17440" citStr="Dale, 1995" startWordPosition="2744" endWordPosition="2745"> contains the keywords constraints and :actions which can be any Lisp expression. Variables are indicated with question/exclamation marks (see figures 5 and 6). The goal of the operators uses an interface based on a triple with the following usage: 4. &lt;description&gt; This is the input position of the operator. It describes and binds the object which will be processed by this operator. o &lt;context&gt; This is the context - input/output. The context contains a stack for objects in focus, handled as described in (Grosz and Sidner, 1986). Additionally we put the generated information on a history list (Dale, 1995). The context supports the generation of, e.g., pronouns (see below). At present the context is only used local to each topic. O &lt;output&gt; The result of the operator. The possible output types are NP, PP and sentetice(s). We the distinguish two types of operators; COT7ip1f:1; operators, responsible for complex objects, which can contain several roles, and simple operators, which can process simple objects (carrying only one role). The general design of a complex operator - see figure 5 for an operator responsible for appointment objects - consists of three subgoals: o (find-roles ) Retrieve the</context>
<context position="23046" citStr="Dale, 1995" startWordPosition="3571" endWordPosition="3572">The robustness fallback ( :rest DIHEX_PPS) means that,all_other DIREXVITs are attached to the verb is-PP complements. It is paft &apos;di all &apos;senteriCe patterns to ensure that even erroneous building blocks or erroneously selected sentence patterns produce a sentence VIT. Finally, the VIT is constructed by interpreting the sentence pattern. The interpreter walks through the sentence pattern and performs different actions depending on the keywords, e.g., :verb, :subj and their values. 4.2.3 Utilizing Context Duringthe course of the generation, the plan processor incrementally constructs a context (Dale, 1995), which allows for the generation of, c.f., anaphora or demonstratives for making the text fluent or contrasting purposes. * Anaphora If, e.g., a meeting is split into more than one sentence, the plan processor uses an anaphora to the meeting in the second sentence. * Discourse Markers In case of multiple, e.g., meetings we introduce the second with a discourse marker, e.g., &amp;quot;also&amp;quot;. tt, Demonstratives In case of multiple meetings, we use a demonstrative to refer to the second meeting. In addition to the plan processor, the semantic constructor also takes care of coherence within the paragraphs</context>
</contexts>
<marker>Dale, 1995</marker>
<rawString>R. Dale, 1995. An introduction to natural language generation. Technical report, Microsoft Research Institute (MRI), Macquarie University. Presented at the 1995 European Summer School on Logic, Language and Information, Available from http://ww-w.mri.mq.edu.aurrdale/nlgtextbook/ESSLL195/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Dorna</author>
<author>M Emele</author>
</authors>
<title>Efficient Implementation of a Semantic-Based Transfer Approach.</title>
<date>1996</date>
<booktitle>In Proceedings of ECAI-96,</booktitle>
<pages>567--571</pages>
<location>Budapest, Hungary,</location>
<contexts>
<context position="2515" citStr="Dorna and Emele, 1996" startWordPosition="373" endWordPosition="376">man). semantic representations for the generation of s&apos;Unirmaries/scripts based on the content of the dialogue memory (Kipp et al., 1999). These descriptions are &apos; The research within VERDMODIL presented here is funded by the German Ministry of Research and Technology under grant. O1IVIO11{/l. The authors would like to thank Tilman Becker for comments on earlier drafts on this paper, and Stephan Leech for invaluable help with programming. realized into text by the existing VERBMOBIL generator (Becker et al., 1998). To produce multilingual summaries we utilize the transfer module of VERBMOBIL (Dorna and Emele, 1996). The next section gives an overview of the VERBMOBIL system focusing on the modules central for the production of summaries/scripts. It is followed by a section describing the extraction and maintenance of summary relevant data. We then describe the functionality of the summary generator in detail. An excerpt of the sample dialogue we refer to in the paper is given at the end of the paper. 2 Prerequisites VERBMOBIL is a speech-to-speech translation project, which at present is approaching its end and in which over 100 researchers&apos; at academic and industrial sites are developing a translation </context>
</contexts>
<marker>Dorna, Emele, 1996</marker>
<rawString>M. Dorna and M. Emele. 1996. Efficient Implementation of a Semantic-Based Transfer Approach. In Proceedings of ECAI-96, pages 567-571, Budapest, Hungary, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Dorna</author>
</authors>
<title>The ADT-Package for the VERBMOBIL Interface Term.</title>
<date>1996</date>
<tech>Verbmobil Report 104, IMS,</tech>
<institution>Universitat</institution>
<location>Stuttgart, Germany,</location>
<contexts>
<context position="5356" citStr="Dorna, 1996" startWordPosition="830" endWordPosition="831">r the translation as well as the modeling of the dialogue as a whole. Examples of illocutionary acts are REQUEST and GREET. Other acts can carry propositional content, like SUGGEST and INFORM_FEATURE. To obtain a good translation and enhance the robustness of the overall system the translation is based on several competing translation tracks, each based on different paradigms. The deep translation track consists of an HPSO based analysis, semantic transfer and finally a TAG-based generator (VMGECO). The linguistic information within this track is encoded in a so-called VIT2 (Bos et al., 1996; Dorna, 1996) which is a formalism following DRT. It consists of a set of semantic conditions (i.e. predicates, roles, operators and quantifiers) and allows for underspecification with respect to scope and subordination or inherent underspecification. A graphical representation of the VIT for the English sentence They will meet at the station&amp;quot; is shown in figure 2. Besides the deep translation track several shallow tracks have been developed. The main source of input for the generation of summaries comes from one of these shallow analysis components (described in section 3) which produces dialogue acts, to</context>
</contexts>
<marker>Dorna, 1996</marker>
<rawString>M. Dorna. 1996. The ADT-Package for the VERBMOBIL Interface Term. Verbmobil Report 104, IMS, Universitat Stuttgart, Germany,</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Grosz</author>
<author>C Sidner</author>
</authors>
<title>Attention., Intentions and the Structure of Discourse.</title>
<date>1986</date>
<journal>Journal of Computational Linguistics,</journal>
<volume>12</volume>
<issue>3</issue>
<contexts>
<context position="17362" citStr="Grosz and Sidner, 1986" startWordPosition="2730" endWordPosition="2733">A plan operator consists of a goal which is optionally divided into subgoal(s). Its syntax contains the keywords constraints and :actions which can be any Lisp expression. Variables are indicated with question/exclamation marks (see figures 5 and 6). The goal of the operators uses an interface based on a triple with the following usage: 4. &lt;description&gt; This is the input position of the operator. It describes and binds the object which will be processed by this operator. o &lt;context&gt; This is the context - input/output. The context contains a stack for objects in focus, handled as described in (Grosz and Sidner, 1986). Additionally we put the generated information on a history list (Dale, 1995). The context supports the generation of, e.g., pronouns (see below). At present the context is only used local to each topic. O &lt;output&gt; The result of the operator. The possible output types are NP, PP and sentetice(s). We the distinguish two types of operators; COT7ip1f:1; operators, responsible for complex objects, which can contain several roles, and simple operators, which can process simple objects (carrying only one role). The general design of a complex operator - see figure 5 for an operator responsible for </context>
</contexts>
<marker>Grosz, Sidner, 1986</marker>
<rawString>B. Grosz and C. Sidner. 1986. Attention., Intentions and the Structure of Discourse. Journal of Computational Linguistics, 12(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Hovy</author>
<author>D Aaron</author>
</authors>
<date>1998</date>
<note>Coling/act-98 tutorial on automated text summarization. Available from http://www.isi.edu/</note>
<marker>Hovy, Aaron, 1998</marker>
<rawString>E. Hovy and D. :Aaron. 1998. Coling/act-98 tutorial on automated text summarization. Available from http://www.isi.edu/</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kipp</author>
<author>J Alexandersson</author>
<author>N Reithinger</author>
</authors>
<title>Understanding Spontaneous Negotiation Dialogue.</title>
<date>1999</date>
<booktitle>In Workshop Proceedings &apos;Knowledge And Reasoning in Practical Dialogue Systems&apos; of LICA&apos; &apos;99,</booktitle>
<pages>57--64</pages>
<contexts>
<context position="2030" citStr="Kipp et al., 1999" startWordPosition="297" endWordPosition="300">idual turns of a dialogue as a whole, while a summary gives a compact summarization of all negotiations the dialogue participants agreed on. The key idea behind our approach is to utilize as many existing resources as possible. Conceptually we have added one module (although technically realized in different already existing modules of the overall VEnuMonii., system) - the summary generator. Besides formatting, our new module generates sequences of language specific (i.e., German). semantic representations for the generation of s&apos;Unirmaries/scripts based on the content of the dialogue memory (Kipp et al., 1999). These descriptions are &apos; The research within VERDMODIL presented here is funded by the German Ministry of Research and Technology under grant. O1IVIO11{/l. The authors would like to thank Tilman Becker for comments on earlier drafts on this paper, and Stephan Leech for invaluable help with programming. realized into text by the existing VERBMOBIL generator (Becker et al., 1998). To produce multilingual summaries we utilize the transfer module of VERBMOBIL (Dorna and Emele, 1996). The next section gives an overview of the VERBMOBIL system focusing on the modules central for the production of </context>
</contexts>
<marker>Kipp, Alexandersson, Reithinger, 1999</marker>
<rawString>M. Kipp, J. Alexandersson, and N. Reithinger. 1999. Understanding Spontaneous Negotiation Dialogue. In Workshop Proceedings &apos;Knowledge And Reasoning in Practical Dialogue Systems&apos; of LICA&apos; &apos;99, pages 57-64.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Mani</author>
<author>D House</author>
<author>G Klein</author>
<author>L Hirschman</author>
<author>L Obrist</author>
<author>T Firmin</author>
<author>M Chrzanowski</author>
<author>R Sundheina</author>
</authors>
<title>Thc tipster summa.e text summarization evaluation - final report. Technical report, The Mitre Corp. Available from http://www24.nist.govirelated_projects/tipster_summacifinal_rpthtrul.</title>
<date>1998</date>
<marker>Mani, House, Klein, Hirschman, Obrist, Firmin, Chrzanowski, Sundheina, 1998</marker>
<rawString>L Mani, D. House, G. Klein, L. Hirschman, L. Obrist, T. Firmin, M. Chrzanowski, and R. Sundheina. 1998. Thc tipster summa.e text summarization evaluation - final report. Technical report, The Mitre Corp. Available from http://www24.nist.govirelated_projects/tipster_summacifinal_rpthtrul.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Reithinger</author>
<author>M Klesen</author>
</authors>
<title>Dialogue Act Classification Using Language Models.</title>
<date>1997</date>
<booktitle>In Proceedings of EaroSpeech-97,</booktitle>
<pages>2235--2238</pages>
<location>Rhodes.</location>
<contexts>
<context position="26913" citStr="Reithinger and Klesen, 1997" startWordPosition="4223" endWordPosition="4226">ined in (Mani et. al., 1998). Dialogue 1 2 3 4 aver Turns 33 33 31 32 32.25 Corr 6 13 9 11 9.75 Miss 6 3 5 4 4.5 False 3 3 3 0 2.25 TN 32 28 30 32 30.5 Recall 0.50 0.81 0.64 0.73 0.67 Prec. 0.67 0.81 0.75 1.0 0.81 Fallout 0.09 0.10 0.09 0.00 0.07 Figure 10: Evaluation Results Obviously, our approach tries to be on the safe side; the summary contains only those features that the system thinks both partners agreed on. The main reasons for not getting higher numbers is twofold. The recognition of dialogue acts, and thus the recognition of the intension behind the utterances reaches a 70% recall (Reithinger and Klesen, 1997). We also still make errors during the content extraction. 7 Conclusion We have presented an extension to existing modules allowing for the generation of summaries within the VERBMOBIL system. To our knowledge our system is the only one that uses semantic representation as basis for summarizing. Other approaches use, e.,g., statistical techniques or rhetorical parsing (Waibel et al., 1998; Hovy and Marcu, 1998) to obtain the summaries. Moreover, although our module is restricted to language specific processing, the use of semantics and the transfer module allow for the generation of multilingu</context>
</contexts>
<marker>Reithinger, Klesen, 1997</marker>
<rawString>N. Reithinger and M. Klesen. 1997. Dialogue Act Classification Using Language Models. In Proceedings of EaroSpeech-97, pages 2235-2238, Rhodes.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Waibel</author>
<author>M Bett</author>
<author>M Fluke</author>
<author>RStiefelhagen</author>
</authors>
<title>Meeting Browser: Racking and Summarizing Meetings.</title>
<date>1998</date>
<booktitle>In Proceedings of the DARPA Broadcast News Workshop.</booktitle>
<contexts>
<context position="27304" citStr="Waibel et al., 1998" startWordPosition="4282" endWordPosition="4285">partners agreed on. The main reasons for not getting higher numbers is twofold. The recognition of dialogue acts, and thus the recognition of the intension behind the utterances reaches a 70% recall (Reithinger and Klesen, 1997). We also still make errors during the content extraction. 7 Conclusion We have presented an extension to existing modules allowing for the generation of summaries within the VERBMOBIL system. To our knowledge our system is the only one that uses semantic representation as basis for summarizing. Other approaches use, e.,g., statistical techniques or rhetorical parsing (Waibel et al., 1998; Hovy and Marcu, 1998) to obtain the summaries. Moreover, although our module is restricted to language specific processing, the use of semantics and the transfer module allow for the generation of multilingual documents in a very straightforward fashion. In the near future we will extend the system with respect to: I, Sentence Split At present the first found sentence split is chosen. This is not necessarily the optimal one. We are currently in the process of developing criteria for ranking competing results. e Japanese The \-.TERBMOBIL system currently includes German, English and Japanese.</context>
</contexts>
<marker>Waibel, Bett, Fluke, RStiefelhagen, 1998</marker>
<rawString>A. Waibel, M. Bett, M. Fluke, and RStiefelhagen. 1998. Meeting Browser: Racking and Summarizing Meetings. In Proceedings of the DARPA Broadcast News Workshop.</rawString>
</citation>
<citation valid="false">
<title>ja es geht um das Ceschftstreffen in Hannover Yes it is about the business meeting in Hanover) EINIT,scheduling,has_appointment: (appointment,has_meeting:[meeting, has_name=&amp;quot;geschaeftstreffen&apos;], has_location:Lcity,has_name=&apos;hannover&apos;.</title>
<pages>3</pages>
<marker></marker>
<rawString>- ja es geht um das Ceschftstreffen in Hannover Yes it is about the business meeting in Hanover) EINIT,scheduling,has_appointment: (appointment,has_meeting:[meeting, has_name=&amp;quot;geschaeftstreffen&apos;], has_location:Lcity,has_name=&apos;hannover&apos;. has_loc_spec=in,has_det.unknownil3</rawString>
</citation>
<citation valid="false">
<authors>
<author>das</author>
</authors>
<title>ist ja am zwanzigsten Januar um elf Uhr vormittags ESUGGEST,uncertain_scheduling,has_date:</title>
<note>1date.tempex=&apos;.(ge_2920_0, [from: [dom:20,month:jan,tod:11:0, podmorning_ger2]7)1</note>
<marker>das, </marker>
<rawString>- das ist ja am zwanzigsten Januar um elf Uhr vormittags ESUGGEST,uncertain_scheduling,has_date: .1date.tempex=&apos;.(ge_2920_0, [from: [dom:20,month:jan,tod:11:0, podmorning_ger2]7)1]</rawString>
</citation>
<citation valid="false">
<authors>
<author>so</author>
</authors>
<title>we have to leave Munich at six o&apos;clock CSUGGEST, traveling , has_move : [move, has_sonrce_location: [city, has_name =&apos;muenchen&apos;] ,has_departure_time: [date, temper.&apos;</title>
<booktitle>en_2920_0 , [from: tod :6 : 0]) &apos;13</booktitle>
<pages>1004</pages>
<marker>so, </marker>
<rawString>- so we have to leave Munich at six o&apos;clock CSUGGEST, traveling , has_move : [move, has_sonrce_location: [city, has_name =&apos;muenchen&apos;] ,has_departure_time: [date, temper.&apos; (en_2920_0 , [from: tod :6 : 0]) &apos;13] 1004</rawString>
</citation>
<citation valid="false">
<title>vielleicht fahren wir lieber den Tag davor (lit.: maybe we better leave the day before) [SUGGEST,traveling,has_move:Cmove, has_departure_time:[date,tempex= 1(ge_2920_1,(from: neg_shift(dur(1,days),ana_point)])&apos;</title>
<marker></marker>
<rawString>- vielleicht fahren wir lieber den Tag davor (lit.: maybe we better leave the day before) [SUGGEST,traveling,has_move:Cmove, has_departure_time:[date,tempex= 1(ge_2920_1,(from: neg_shift(dur(1,days),ana_point)])&apos;]]]</rawString>
</citation>
<citation valid="false">
<authors>
<author>da</author>
</authors>
<title>gibt es einen Zug um zwei Uhr (lit.: there is a train at two o&apos;clock) [SUCGEST,traveliug,has_move:Emove,has_transportation:[rail],has_departure_time: [date,tempex=&apos;(ge_2920_2,[from:tod:2:01)Ill</title>
<marker>da, </marker>
<rawString>- da gibt es einen Zug um zwei Uhr (lit.: there is a train at two o&apos;clock) [SUCGEST,traveliug,has_move:Emove,has_transportation:[rail],has_departure_time: [date,tempex=&apos;(ge_2920_2,[from:tod:2:01)Ill</rawString>
</citation>
<citation valid="false">
<title>I would prefer to leave at five [SUGGEST,traveling,has_move:[move, has_agent:[speaker].has_departure_time: Edate,tempex=&apos;(en_2920_1,1Lfrom:tod:5:0W1</title>
<marker></marker>
<rawString>- I would prefer to leave at five [SUGGEST,traveling,has_move:[move, has_agent:[speaker].has_departure_time: Edate,tempex=&apos;(en_2920_1,1Lfrom:tod:5:0W1]]</rawString>
</citation>
<citation valid="false">
<pages>1011</pages>
<publisher>E...</publisher>
<marker></marker>
<rawString>E...] 1011</rawString>
</citation>
<citation valid="false">
<title>let us meet at the station on Wednesday CSUGGEST,scheduling,has_appointment: Lnppointment,has_location:[nongeo_location, has_name=&apos;bahnhof&apos;,has_loc_spec=at, has_det=def] ,has_date:[date,tempex= &apos;(en_2920_2,[from:dow:wed])111 - halb zehn am Bahnhof (lit.: at half past nine at the station) [ACCEPT,uncertain_scheduling,has_date:[date, tempex=&apos;(ge_2920_3,Efrom:tod:9:30])&apos;], has_location:[nongeo_location,has_name= &apos;bahnhof&apos;</title>
<marker></marker>
<rawString>- let us meet at the station on Wednesday CSUGGEST,scheduling,has_appointment: Lnppointment,has_location:[nongeo_location, has_name=&apos;bahnhof&apos;,has_loc_spec=at, has_det=def] ,has_date:[date,tempex= &apos;(en_2920_2,[from:dow:wed])111 - halb zehn am Bahnhof (lit.: at half past nine at the station) [ACCEPT,uncertain_scheduling,has_date:[date, tempex=&apos;(ge_2920_3,Efrom:tod:9:30])&apos;], has_location:[nongeo_location,has_name= &apos;bahnhof&apos;]]</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>