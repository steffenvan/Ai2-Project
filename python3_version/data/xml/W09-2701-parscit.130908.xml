<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.009823">
<title confidence="0.977628">
Knowledge and Reasoning for Medical Question-Answering
</title>
<author confidence="0.776581">
Pierre Zweigenbaum
</author>
<affiliation confidence="0.455401">
CNRS, LIMSI
</affiliation>
<address confidence="0.53599">
Orsay, F-91403 France
</address>
<email confidence="0.970961">
pz@limsi.fr
</email>
<sectionHeader confidence="0.992589" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.983812037037037">
Restricted domains such as medicine set
a context where question-answering is
more likely expected to be associated
with knowledge and reasoning (Mollá and
Vicedo, 2007; Ferret and Zweigenbaum,
2007). On the one hand, knowledge and
reasoning may be more necessary than
in open-domain question-answering be-
cause of more specific or more difficult
questions. On the other hand, it may
also be more manageable, since by def-
inition restricted-domain QA should not
have to face the same breadth of ques-
tions as open-domain QA. It is therefore
interesting to study the role of knowl-
edge and reasoning in restricted-domain
question-answering systems. We shall do
so in the case of the (bio-)medical domain,
which has a long tradition of investigat-
ing knowledge representation and reason-
ing and, more generally, artificial intel-
ligence methods (Shortliffe et al., 1975),
and which has seen a growing interest
in question-answering systems (Zweigen-
baum, 2003; Yu et al., 2005; Demner-
Fushman and Lin, 2007; Zweigenbaum et
al., 2007).
</bodyText>
<sectionHeader confidence="0.7331915" genericHeader="categories and subject descriptors">
1 Knowledge and Reasoning for
Processing Medical Questions
</sectionHeader>
<construct confidence="0.915599857142857">
Medical question-answering has to address ques-
tions other than the usual factual questions of most
QA evaluations. This calls for different question
classifications (Ely et al., 2000; Yu et al., 2005),
especially to determine whether a given ques-
tion can be answered using medical knowledge
backed with a sufficient level of evidence (Lin and
Demner-Fushman, 2005; Kilicoglu et al., 2009).
This can also lead to a different representation of
questions, for instance using a structured represen-
tation such as PICO (Niu et al., 2003; Huang et al.,
2006; Demner-Fushman and Lin, 2007) or simple
concepts and relations (Lin, 2001; Jacquemart and
Zweigenbaum, 2003).
</construct>
<sectionHeader confidence="0.755986" genericHeader="conclusions">
2 Knowledge and Reasoning for Finding
</sectionHeader>
<subsectionHeader confidence="0.930621">
Medical Answers
</subsectionHeader>
<bodyText confidence="0.978426">
Answers to medical questions should be searched
in the most reliable data available. When data exist
in structured knowledge bases (e.g. a drug com-
pendium), it may be more appropriate to query
such knowledge bases directly. Therefore an ap-
proach akin to that of Start/Omnibase (Lin and
Katz, 2003) may be indicated. When answers are
to be found in a collection of documents, as is the
case in traditional question-answering systems,
a representation of the information contained in
these documents can be built, offline (Fleischman
et al., 2003; Sang et al., 2005; Delbecque et al.,
2005) or dynamically.
In medical QA systems, both document anal-
ysis and question analysis nearly always rely on
extensive knowledge of domain concepts and re-
lations, e.g. as provided by the UMLS knowl-
edge sources (McCray and Nelson, 1995). More
than named entities, systems need to detect men-
tions of concepts (Aronson, 2001) and their rela-
tions (Rindflesch et al., 2005). Besides, taking into
account the structure of documents such as sci-
entific articles or encyclopedia entries may help
focus on more relevant sections (Niu and Hirst,
2004; Sang et al., 2005). Finally, answers to com-
plex medical questions often need to span more
than one sentence. Extractive summarization is
performed both from single documents (Demner-
Fushman and Lin, 2007) and from multiple docu-
ments (Fiszman et al., 2008).
</bodyText>
<page confidence="0.86438">
1
</page>
<note confidence="0.9994185">
Proceedings of the 2009 Workshop on Knowledge and Reasoning for Answering Questions, ACL-IJCNLP 2009, pages 1–2,
Suntec, Singapore, 6 August 2009. c�2009 ACL and AFNLP
</note>
<sectionHeader confidence="0.936959" genericHeader="references">
References
</sectionHeader>
<bodyText confidence="0.965792073529412">
Alan R. Aronson. 2001. Effective mapping of biomed-
ical text to the UMLS Metathesaurus: The MetaMap
program. Journal of the American Medical Infor-
matics Association, 8(suppl):17–21.
Thierry Delbecque, Pierre Jacquemart, and Pierre
Zweigenbaum. 2005. Indexing UMLS semantic
types for medical question-answering. In Rolf En-
gelbrecht, Antoine Geissbuhler, Christian Lovis, and
G. Mihalas, editors, Proceedings Medical Informat-
ics Europe, volume 116 of Studies in Health Tech-
nology and Informatics, pages 805–810, Amster-
dam. IOS Press.
Dina Demner-Fushman and Jimmy Lin. 2007. An-
swering clinical questions with knowledge-based
and statistical techniques. Computational Linguis-
tics, 33(1):63–103.
John W. Ely, Jerome A. Osheroff, Paul N. Gor-
man, Mark H. Ebell, M. Lee Chambliss, Eric A.
Pifer, and P. Zoe Stavri. 2000. A taxonomy
of generic clinical questions: classification study.
BMJ, 321:429–432. Available at http://bmj.
com/cgi/content/full/321/7258/429.
Olivier Ferret and Pierre Zweigenbaum. 2007.
Représentation des connaissances pour les sys-
tèmes de question-réponse. In Brigitte Grau
and Jean-Pierre Chevallet, editors, La recherche
d’informations précises : traitement automatique de
la langue, apprentissage et connaissances pour les
systèmes de question-réponse, chapter 4, pages 133–
169. Hermès-Lavoisier, Paris.
Marcelo Fiszman, Dina Demner-Fushman, Halil Kil-
icoglu, and Thomas C Rindflesch. 2008. Automatic
summarization of MEDLINE citations for evidence-
based medical treatment: A topic-oriented evalua-
tion. J Biomed Inform, November.
Michael Fleischman, Abdessamad Echihabi, and Ed-
uard Hovy. 2003. Offline strategies for online ques-
tion answering: Answering questions before they
are asked. In Proceedings of the ACL Conference,
pages 1–7, Sapporo, Japan.
Xiaoli Huang, Jimmy Lin, and Dina Demner-Fushman.
2006. Evaluation of PICO as a knowledge represen-
tation for clinical questions. In AMIA Annu Symp
Proc, page 359–63.
Pierre Jacquemart and Pierre Zweigenbaum. 2003. To-
wards a medical question-answering system: a feasi-
bility study. In Robert Baud, Marius Fieschi, Pierre
Le Beux, and Patrick Ruch, editors, Proceedings
Medical Informatics Europe, volume 95 of Studies
in Health Technology and Informatics, pages 463–
468, Amsterdam. IOS Press.
Halil Kilicoglu, Dina Demner-Fushman, Thomas C
Rindflesch, Nancy L Wilczynski, and R Brian
Haynes. 2009. Towards automatic recognition of
scientifically rigorous clinical research evidence. J
Am Med Inform Assoc, 16(1):25–31.
Jimmy Lin and Dina Demner-Fushman. 2005. “Bag of
words” is not enough for strength of evidence clas-
sification. In AMIA Annu Symp Proc, page 1031.
Jimmy Lin and Boris Katz. 2003. Question answering
techniques for the World Wide Web. In Tutorial at
EACL 2003, Budapest. ACL.
Jimmy Lin. 2001. Indexing and retrieving natural lan-
guage using ternary expressions. Master’s thesis,
Massachusetts Institute of Technology.
Alexa T. McCray and Stuart J. Nelson. 1995. The se-
mantics of the UMLS knowledge sources. Methods
of Information in Medicine, 34(1/2).
</bodyText>
<reference confidence="0.870987348837209">
Diego Mollá and José Luis Vicedo. 2007. Question an-
swering in restricted domains: An overview. Com-
putational Linguistics, 33(1):41–61.
Yun Niu and Graeme Hirst. 2004. Analysis of seman-
tic classes in medical text for question answering. In
Proceedings ACL 2004 Workshop on Question An-
swering in Restricted Domains. ACL.
Yun Niu, Graeme Hirst, Gregory McArthur, and Patri-
cia Rodriguez-Gianolli. 2003. Answering clinical
questions with role identification. In ACL Workshop
Natural Language Processing in Biomedicine, pages
73–80. ACL.
Thomas C. Rindflesch, Marcelo Fiszman, and B. Lib-
bus. 2005. Semantic interpretation for the biomed-
ical literature. In H Chen, S Fuller, WR Hersh,
and C Friedman, editors, Medical informatics: Ad-
vances in knowledge management and data mining
in biomedicine, pages 399–422, Berlin / Heidelberg.
Springer.
Erik Tjong Kim Sang, Gosse Bouma, and Maarten
de Rijke. 2005. Developing offline strategies for an-
swering medical questions. In Proceedings AAAI-05
workshop on Question Answering in restricted do-
mains, pages 41–45. AAAI.
E H Shortliffe, R Davis, S G Axline, B G Buchanan,
C C Green, and S N Cohen. 1975. Computer-based
consultations in clinical therapeutics: explanation
and rule acquisition capabilities of the MYCIN sys-
tem. Comput Biomed Res, 8(4):303–20, August.
Hong Yu, Carl Sable, and Hai Ran Zhu. 2005. Classi-
fying medical questions based on an evidence taxon-
omy. In Proceedings AAAI 2005 Workshop on Ques-
tion Answering in Restricted Domains. AAAI.
Pierre Zweigenbaum, Dina Demner-Fushman, Hong
Yu, and K. Bretonnel Cohen. 2007. Fron-
tiers of biomedical text mining: current progress.
Briefings in Bioinformatics, 8:358–375, October.
doi:10.1093/bib/bbm045.
Pierre Zweigenbaum. 2003. Question answering in
biomedicine. In Maarten de Rijke and Bonnie Web-
ber, editors, Proceedings Workshop on Natural Lan-
guage Processing for Question Answering, EACL
2003, pages 1–4, Budapest. ACL. Keynote speech.
</reference>
<page confidence="0.996726">
2
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000006">
<title confidence="0.999704">Knowledge and Reasoning for Medical Question-Answering</title>
<author confidence="0.997032">Pierre Zweigenbaum</author>
<affiliation confidence="0.922591">CNRS, LIMSI</affiliation>
<address confidence="0.985323">Orsay, F-91403 France</address>
<email confidence="0.996407">pz@limsi.fr</email>
<abstract confidence="0.970949892857143">Restricted domains such as medicine set a context where question-answering is more likely expected to be associated with knowledge and reasoning (Mollá and Vicedo, 2007; Ferret and Zweigenbaum, 2007). On the one hand, knowledge and reasoning may be more necessary than in open-domain question-answering because of more specific or more difficult questions. On the other hand, it may also be more manageable, since by definition restricted-domain QA should not have to face the same breadth of questions as open-domain QA. It is therefore interesting to study the role of knowledge and reasoning in restricted-domain question-answering systems. We shall do so in the case of the (bio-)medical domain, which has a long tradition of investigating knowledge representation and reasoning and, more generally, artificial intelligence methods (Shortliffe et al., 1975), and which has seen a growing interest in question-answering systems (Zweigenbaum, 2003; Yu et al., 2005; Demner- Fushman and Lin, 2007; Zweigenbaum et al., 2007).</abstract>
<title confidence="0.76491">1 Knowledge and Reasoning for Processing Medical Questions</title>
<abstract confidence="0.894474943181818">Medical question-answering has to address questions other than the usual factual questions of most QA evaluations. This calls for different question classifications (Ely et al., 2000; Yu et al., 2005), especially to determine whether a given question can be answered using medical knowledge backed with a sufficient level of evidence (Lin and Demner-Fushman, 2005; Kilicoglu et al., 2009). This can also lead to a different representation of questions, for instance using a structured representation such as PICO (Niu et al., 2003; Huang et al., 2006; Demner-Fushman and Lin, 2007) or simple concepts and relations (Lin, 2001; Jacquemart and Zweigenbaum, 2003). 2 Knowledge and Reasoning for Finding Medical Answers Answers to medical questions should be searched in the most reliable data available. When data exist structured knowledge bases drug compendium), it may be more appropriate to query such knowledge bases directly. Therefore an approach akin to that of Start/Omnibase (Lin and Katz, 2003) may be indicated. When answers are to be found in a collection of documents, as is the case in traditional question-answering systems, a representation of the information contained in these documents can be built, offline (Fleischman et al., 2003; Sang et al., 2005; Delbecque et al., 2005) or dynamically. In medical QA systems, both document analysis and question analysis nearly always rely on extensive knowledge of domain concepts and reprovided by the UMLS knowledge sources (McCray and Nelson, 1995). More than named entities, systems need to detect mentions of concepts (Aronson, 2001) and their relations (Rindflesch et al., 2005). Besides, taking into account the structure of documents such as scientific articles or encyclopedia entries may help focus on more relevant sections (Niu and Hirst, 2004; Sang et al., 2005). Finally, answers to complex medical questions often need to span more than one sentence. Extractive summarization is performed both from single documents (Demner- Fushman and Lin, 2007) and from multiple documents (Fiszman et al., 2008). 1 of the 2009 Workshop on Knowledge and Reasoning for Answering Questions, ACL-IJCNLP pages 1–2, Singapore, 6 August 2009. ACL and AFNLP References Alan R. Aronson. 2001. Effective mapping of biomedical text to the UMLS Metathesaurus: The MetaMap of the American Medical Infor- 8(suppl):17–21. Thierry Delbecque, Pierre Jacquemart, and Pierre Zweigenbaum. 2005. Indexing UMLS semantic types for medical question-answering. In Rolf Engelbrecht, Antoine Geissbuhler, Christian Lovis, and Mihalas, editors, Medical Informatvolume 116 of in Health Techand pages 805–810, Amsterdam. IOS Press. Dina Demner-Fushman and Jimmy Lin. 2007. Answering clinical questions with knowledge-based statistical techniques. Linguis- 33(1):63–103. John W. Ely, Jerome A. Osheroff, Paul N. Gorman, Mark H. Ebell, M. Lee Chambliss, Eric A. Pifer, and P. Zoe Stavri. 2000. A taxonomy of generic clinical questions: classification study. 321:429–432. Available athttp://bmj. Olivier Ferret and Pierre Zweigenbaum. 2007. des connaissances pour les systèmes de question-réponse. In Brigitte Jean-Pierre Chevallet, editors, recherche d’informations précises : traitement automatique de la langue, apprentissage et connaissances pour les de chapter 4, pages 133– 169. Hermès-Lavoisier, Paris. Marcelo Fiszman, Dina Demner-Fushman, Halil Kilicoglu, and Thomas C Rindflesch. 2008. Automatic summarization of MEDLINE citations for evidencebased medical treatment: A topic-oriented evalua- Biomed November. Michael Fleischman, Abdessamad Echihabi, and Eduard Hovy. 2003. Offline strategies for online question answering: Answering questions before they asked. In of the ACL</abstract>
<note confidence="0.712827565217391">pages 1–7, Sapporo, Japan. Xiaoli Huang, Jimmy Lin, and Dina Demner-Fushman. 2006. Evaluation of PICO as a knowledge represenfor clinical questions. In Annu Symp page 359–63. Pierre Jacquemart and Pierre Zweigenbaum. 2003. Towards a medical question-answering system: a feasibility study. In Robert Baud, Marius Fieschi, Pierre Beux, and Patrick Ruch, editors, Informatics volume 95 of Health Technology and pages 463– 468, Amsterdam. IOS Press. Halil Kilicoglu, Dina Demner-Fushman, Thomas C Rindflesch, Nancy L Wilczynski, and R Brian Haynes. 2009. Towards automatic recognition of rigorous clinical research evidence. Med Inform 16(1):25–31. Jimmy Lin and Dina Demner-Fushman. 2005. “Bag of words” is not enough for strength of evidence clas- In Annu Symp page 1031. Jimmy Lin and Boris Katz. 2003. Question answering for the World Wide Web. In at Budapest. ACL.</note>
<author confidence="0.7175">Indexing</author>
<author confidence="0.7175">retrieving natural lan-</author>
<affiliation confidence="0.740645">guage using ternary expressions. Master’s thesis, Massachusetts Institute of Technology.</affiliation>
<address confidence="0.340596">Alexa T. McCray and Stuart J. Nelson. 1995. The se-</address>
<abstract confidence="0.639956230769231">of the UMLS knowledge sources. Information in 34(1/2). Diego Mollá and José Luis Vicedo. 2007. Question anin restricted domains: An overview. Com- 33(1):41–61. Yun Niu and Graeme Hirst. 2004. Analysis of semantic classes in medical text for question answering. In Proceedings ACL 2004 Workshop on Question Anin Restricted ACL. Yun Niu, Graeme Hirst, Gregory McArthur, and Patricia Rodriguez-Gianolli. 2003. Answering clinical with role identification. In Workshop Language Processing in pages 73–80. ACL. Thomas C. Rindflesch, Marcelo Fiszman, and B. Libbus. 2005. Semantic interpretation for the biomedical literature. In H Chen, S Fuller, WR Hersh, C Friedman, editors, informatics: Advances in knowledge management and data mining pages 399–422, Berlin / Heidelberg. Springer. Erik Tjong Kim Sang, Gosse Bouma, and Maarten de Rijke. 2005. Developing offline strategies for anmedical questions. In AAAI-05 workshop on Question Answering in restricted dopages 41–45. AAAI.</abstract>
<note confidence="0.7116582">E H Shortliffe, R Davis, S G Axline, B G Buchanan, C C Green, and S N Cohen. 1975. Computer-based consultations in clinical therapeutics: explanation and rule acquisition capabilities of the MYCIN sys- Biomed 8(4):303–20, August. Hong Yu, Carl Sable, and Hai Ran Zhu. 2005. Classifying medical questions based on an evidence taxon- In AAAI 2005 Workshop on Ques- Answering in Restricted AAAI. Pierre Zweigenbaum, Dina Demner-Fushman, Hong Yu, and K. Bretonnel Cohen. 2007. Frontiers of biomedical text mining: current progress. in 8:358–375, October. doi:10.1093/bib/bbm045. Pierre Zweigenbaum. 2003. Question answering in biomedicine. In Maarten de Rijke and Bonnie Webeditors, Workshop on Natural Language Processing for Question Answering, EACL pages 1–4, Budapest. ACL. Keynote speech. 2</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Diego Mollá</author>
<author>José Luis Vicedo</author>
</authors>
<title>Question answering in restricted domains: An overview.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>1</issue>
<marker>Mollá, Vicedo, 2007</marker>
<rawString>Diego Mollá and José Luis Vicedo. 2007. Question answering in restricted domains: An overview. Computational Linguistics, 33(1):41–61.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yun Niu</author>
<author>Graeme Hirst</author>
</authors>
<title>Analysis of semantic classes in medical text for question answering.</title>
<date>2004</date>
<booktitle>In Proceedings ACL 2004 Workshop on Question Answering in Restricted Domains.</booktitle>
<publisher>ACL.</publisher>
<contexts>
<context position="3053" citStr="Niu and Hirst, 2004" startWordPosition="474" endWordPosition="477">uilt, offline (Fleischman et al., 2003; Sang et al., 2005; Delbecque et al., 2005) or dynamically. In medical QA systems, both document analysis and question analysis nearly always rely on extensive knowledge of domain concepts and relations, e.g. as provided by the UMLS knowledge sources (McCray and Nelson, 1995). More than named entities, systems need to detect mentions of concepts (Aronson, 2001) and their relations (Rindflesch et al., 2005). Besides, taking into account the structure of documents such as scientific articles or encyclopedia entries may help focus on more relevant sections (Niu and Hirst, 2004; Sang et al., 2005). Finally, answers to complex medical questions often need to span more than one sentence. Extractive summarization is performed both from single documents (DemnerFushman and Lin, 2007) and from multiple documents (Fiszman et al., 2008). 1 Proceedings of the 2009 Workshop on Knowledge and Reasoning for Answering Questions, ACL-IJCNLP 2009, pages 1–2, Suntec, Singapore, 6 August 2009. c�2009 ACL and AFNLP References Alan R. Aronson. 2001. Effective mapping of biomedical text to the UMLS Metathesaurus: The MetaMap program. Journal of the American Medical Informatics Associati</context>
</contexts>
<marker>Niu, Hirst, 2004</marker>
<rawString>Yun Niu and Graeme Hirst. 2004. Analysis of semantic classes in medical text for question answering. In Proceedings ACL 2004 Workshop on Question Answering in Restricted Domains. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yun Niu</author>
<author>Graeme Hirst</author>
<author>Gregory McArthur</author>
<author>Patricia Rodriguez-Gianolli</author>
</authors>
<title>Answering clinical questions with role identification.</title>
<date>2003</date>
<booktitle>In ACL Workshop Natural Language Processing in Biomedicine,</booktitle>
<pages>73--80</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="1742" citStr="Niu et al., 2003" startWordPosition="264" endWordPosition="267">Zweigenbaum et al., 2007). 1 Knowledge and Reasoning for Processing Medical Questions Medical question-answering has to address questions other than the usual factual questions of most QA evaluations. This calls for different question classifications (Ely et al., 2000; Yu et al., 2005), especially to determine whether a given question can be answered using medical knowledge backed with a sufficient level of evidence (Lin and Demner-Fushman, 2005; Kilicoglu et al., 2009). This can also lead to a different representation of questions, for instance using a structured representation such as PICO (Niu et al., 2003; Huang et al., 2006; Demner-Fushman and Lin, 2007) or simple concepts and relations (Lin, 2001; Jacquemart and Zweigenbaum, 2003). 2 Knowledge and Reasoning for Finding Medical Answers Answers to medical questions should be searched in the most reliable data available. When data exist in structured knowledge bases (e.g. a drug compendium), it may be more appropriate to query such knowledge bases directly. Therefore an approach akin to that of Start/Omnibase (Lin and Katz, 2003) may be indicated. When answers are to be found in a collection of documents, as is the case in traditional question-</context>
</contexts>
<marker>Niu, Hirst, McArthur, Rodriguez-Gianolli, 2003</marker>
<rawString>Yun Niu, Graeme Hirst, Gregory McArthur, and Patricia Rodriguez-Gianolli. 2003. Answering clinical questions with role identification. In ACL Workshop Natural Language Processing in Biomedicine, pages 73–80. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas C Rindflesch</author>
<author>Marcelo Fiszman</author>
<author>B Libbus</author>
</authors>
<title>Semantic interpretation for the biomedical literature.</title>
<date>2005</date>
<booktitle>Medical informatics: Advances in knowledge management and data mining in biomedicine,</booktitle>
<pages>399--422</pages>
<editor>In H Chen, S Fuller, WR Hersh, and C Friedman, editors,</editor>
<publisher>Springer.</publisher>
<location>Berlin / Heidelberg.</location>
<contexts>
<context position="2882" citStr="Rindflesch et al., 2005" startWordPosition="447" endWordPosition="450">re to be found in a collection of documents, as is the case in traditional question-answering systems, a representation of the information contained in these documents can be built, offline (Fleischman et al., 2003; Sang et al., 2005; Delbecque et al., 2005) or dynamically. In medical QA systems, both document analysis and question analysis nearly always rely on extensive knowledge of domain concepts and relations, e.g. as provided by the UMLS knowledge sources (McCray and Nelson, 1995). More than named entities, systems need to detect mentions of concepts (Aronson, 2001) and their relations (Rindflesch et al., 2005). Besides, taking into account the structure of documents such as scientific articles or encyclopedia entries may help focus on more relevant sections (Niu and Hirst, 2004; Sang et al., 2005). Finally, answers to complex medical questions often need to span more than one sentence. Extractive summarization is performed both from single documents (DemnerFushman and Lin, 2007) and from multiple documents (Fiszman et al., 2008). 1 Proceedings of the 2009 Workshop on Knowledge and Reasoning for Answering Questions, ACL-IJCNLP 2009, pages 1–2, Suntec, Singapore, 6 August 2009. c�2009 ACL and AFNLP R</context>
</contexts>
<marker>Rindflesch, Fiszman, Libbus, 2005</marker>
<rawString>Thomas C. Rindflesch, Marcelo Fiszman, and B. Libbus. 2005. Semantic interpretation for the biomedical literature. In H Chen, S Fuller, WR Hersh, and C Friedman, editors, Medical informatics: Advances in knowledge management and data mining in biomedicine, pages 399–422, Berlin / Heidelberg. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erik Tjong Kim Sang</author>
<author>Gosse Bouma</author>
<author>Maarten de Rijke</author>
</authors>
<title>Developing offline strategies for answering medical questions.</title>
<date>2005</date>
<booktitle>In Proceedings AAAI-05 workshop on Question Answering in restricted domains,</booktitle>
<pages>41--45</pages>
<publisher>AAAI.</publisher>
<marker>Sang, Bouma, de Rijke, 2005</marker>
<rawString>Erik Tjong Kim Sang, Gosse Bouma, and Maarten de Rijke. 2005. Developing offline strategies for answering medical questions. In Proceedings AAAI-05 workshop on Question Answering in restricted domains, pages 41–45. AAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E H Shortliffe</author>
<author>R Davis</author>
<author>S G Axline</author>
<author>B G Buchanan</author>
<author>C C Green</author>
<author>S N Cohen</author>
</authors>
<title>Computer-based consultations in clinical therapeutics: explanation and rule acquisition capabilities of the MYCIN system.</title>
<date>1975</date>
<journal>Comput Biomed Res,</journal>
<volume>8</volume>
<issue>4</issue>
<contexts>
<context position="990" citStr="Shortliffe et al., 1975" startWordPosition="146" endWordPosition="149">ning may be more necessary than in open-domain question-answering because of more specific or more difficult questions. On the other hand, it may also be more manageable, since by definition restricted-domain QA should not have to face the same breadth of questions as open-domain QA. It is therefore interesting to study the role of knowledge and reasoning in restricted-domain question-answering systems. We shall do so in the case of the (bio-)medical domain, which has a long tradition of investigating knowledge representation and reasoning and, more generally, artificial intelligence methods (Shortliffe et al., 1975), and which has seen a growing interest in question-answering systems (Zweigenbaum, 2003; Yu et al., 2005; DemnerFushman and Lin, 2007; Zweigenbaum et al., 2007). 1 Knowledge and Reasoning for Processing Medical Questions Medical question-answering has to address questions other than the usual factual questions of most QA evaluations. This calls for different question classifications (Ely et al., 2000; Yu et al., 2005), especially to determine whether a given question can be answered using medical knowledge backed with a sufficient level of evidence (Lin and Demner-Fushman, 2005; Kilicoglu et </context>
</contexts>
<marker>Shortliffe, Davis, Axline, Buchanan, Green, Cohen, 1975</marker>
<rawString>E H Shortliffe, R Davis, S G Axline, B G Buchanan, C C Green, and S N Cohen. 1975. Computer-based consultations in clinical therapeutics: explanation and rule acquisition capabilities of the MYCIN system. Comput Biomed Res, 8(4):303–20, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hong Yu</author>
<author>Carl Sable</author>
<author>Hai Ran Zhu</author>
</authors>
<title>Classifying medical questions based on an evidence taxonomy.</title>
<date>2005</date>
<booktitle>In Proceedings AAAI 2005 Workshop on Question Answering in Restricted Domains.</booktitle>
<publisher>AAAI.</publisher>
<contexts>
<context position="1095" citStr="Yu et al., 2005" startWordPosition="163" endWordPosition="166">ions. On the other hand, it may also be more manageable, since by definition restricted-domain QA should not have to face the same breadth of questions as open-domain QA. It is therefore interesting to study the role of knowledge and reasoning in restricted-domain question-answering systems. We shall do so in the case of the (bio-)medical domain, which has a long tradition of investigating knowledge representation and reasoning and, more generally, artificial intelligence methods (Shortliffe et al., 1975), and which has seen a growing interest in question-answering systems (Zweigenbaum, 2003; Yu et al., 2005; DemnerFushman and Lin, 2007; Zweigenbaum et al., 2007). 1 Knowledge and Reasoning for Processing Medical Questions Medical question-answering has to address questions other than the usual factual questions of most QA evaluations. This calls for different question classifications (Ely et al., 2000; Yu et al., 2005), especially to determine whether a given question can be answered using medical knowledge backed with a sufficient level of evidence (Lin and Demner-Fushman, 2005; Kilicoglu et al., 2009). This can also lead to a different representation of questions, for instance using a structure</context>
</contexts>
<marker>Yu, Sable, Zhu, 2005</marker>
<rawString>Hong Yu, Carl Sable, and Hai Ran Zhu. 2005. Classifying medical questions based on an evidence taxonomy. In Proceedings AAAI 2005 Workshop on Question Answering in Restricted Domains. AAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pierre Zweigenbaum</author>
<author>Dina Demner-Fushman</author>
<author>Hong Yu</author>
<author>K Bretonnel Cohen</author>
</authors>
<title>Frontiers of biomedical text mining: current progress.</title>
<date>2007</date>
<booktitle>Briefings in Bioinformatics,</booktitle>
<pages>8--358</pages>
<contexts>
<context position="1151" citStr="Zweigenbaum et al., 2007" startWordPosition="172" endWordPosition="175">anageable, since by definition restricted-domain QA should not have to face the same breadth of questions as open-domain QA. It is therefore interesting to study the role of knowledge and reasoning in restricted-domain question-answering systems. We shall do so in the case of the (bio-)medical domain, which has a long tradition of investigating knowledge representation and reasoning and, more generally, artificial intelligence methods (Shortliffe et al., 1975), and which has seen a growing interest in question-answering systems (Zweigenbaum, 2003; Yu et al., 2005; DemnerFushman and Lin, 2007; Zweigenbaum et al., 2007). 1 Knowledge and Reasoning for Processing Medical Questions Medical question-answering has to address questions other than the usual factual questions of most QA evaluations. This calls for different question classifications (Ely et al., 2000; Yu et al., 2005), especially to determine whether a given question can be answered using medical knowledge backed with a sufficient level of evidence (Lin and Demner-Fushman, 2005; Kilicoglu et al., 2009). This can also lead to a different representation of questions, for instance using a structured representation such as PICO (Niu et al., 2003; Huang e</context>
</contexts>
<marker>Zweigenbaum, Demner-Fushman, Yu, Cohen, 2007</marker>
<rawString>Pierre Zweigenbaum, Dina Demner-Fushman, Hong Yu, and K. Bretonnel Cohen. 2007. Frontiers of biomedical text mining: current progress. Briefings in Bioinformatics, 8:358–375, October. doi:10.1093/bib/bbm045.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pierre Zweigenbaum</author>
</authors>
<title>Question answering in biomedicine.</title>
<date>2003</date>
<booktitle>In Maarten de Rijke</booktitle>
<pages>1--4</pages>
<editor>and Bonnie Webber, editors,</editor>
<contexts>
<context position="1078" citStr="Zweigenbaum, 2003" startWordPosition="160" endWordPosition="162">ore difficult questions. On the other hand, it may also be more manageable, since by definition restricted-domain QA should not have to face the same breadth of questions as open-domain QA. It is therefore interesting to study the role of knowledge and reasoning in restricted-domain question-answering systems. We shall do so in the case of the (bio-)medical domain, which has a long tradition of investigating knowledge representation and reasoning and, more generally, artificial intelligence methods (Shortliffe et al., 1975), and which has seen a growing interest in question-answering systems (Zweigenbaum, 2003; Yu et al., 2005; DemnerFushman and Lin, 2007; Zweigenbaum et al., 2007). 1 Knowledge and Reasoning for Processing Medical Questions Medical question-answering has to address questions other than the usual factual questions of most QA evaluations. This calls for different question classifications (Ely et al., 2000; Yu et al., 2005), especially to determine whether a given question can be answered using medical knowledge backed with a sufficient level of evidence (Lin and Demner-Fushman, 2005; Kilicoglu et al., 2009). This can also lead to a different representation of questions, for instance </context>
</contexts>
<marker>Zweigenbaum, 2003</marker>
<rawString>Pierre Zweigenbaum. 2003. Question answering in biomedicine. In Maarten de Rijke and Bonnie Webber, editors, Proceedings Workshop on Natural Language Processing for Question Answering, EACL 2003, pages 1–4, Budapest. ACL. Keynote speech.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>