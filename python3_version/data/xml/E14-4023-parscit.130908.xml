<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000002">
<title confidence="0.995123">
Comparing methods for deriving intensity scores for adjectives
</title>
<author confidence="0.998599">
Josef Ruppenhofer*, Michael Wiegand†, Jasper Brandes*
</author>
<affiliation confidence="0.984058">
*Hildesheim University
</affiliation>
<address confidence="0.405257">
Hildesheim, Germany
</address>
<email confidence="0.337377">
{ruppenho|brandesj}@uni-hildesheim.de
</email>
<affiliation confidence="0.895575">
†Saarland University
</affiliation>
<address confidence="0.49365">
Saarbr¨ucken, Germany
</address>
<email confidence="0.98712">
michael.wiegand@lsv.uni-saarland.de
</email>
<sectionHeader confidence="0.993469" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999989466666667">
We compare several different corpus-
based and lexicon-based methods for the
scalar ordering of adjectives. Among
them, we examine for the first time a low-
resource approach based on distinctive-
collexeme analysis that just requires a
small predefined set of adverbial modi-
fiers. While previous work on adjective in-
tensity mostly assumes one single scale for
all adjectives, we group adjectives into dif-
ferent scales which is more faithful to hu-
man perception. We also apply the meth-
ods to both polar and non-polar adjectives,
showing that not all methods are equally
suitable for both types of adjectives.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999728">
Ordering adjectives by strength (e.g. good &lt; great
&lt; excellent) is a task that has recently received
much attention due to the central role of intensity
classification in sentiment analysis. However, the
need to assess the relative strength of adjectives
also applies to non-polar adjectives. We are thus
interested in establishing prior or lexical intensity
scores and rankings for arbitrary sets of adjectives
that evoke the same scale.1 We do not address con-
textualized intensity, i.e. the fact that e.g. negation
and adverbs such as very or slightly impact the per-
ceived intensity of adjectives.
We work with four scales of adjectives (cf. Ta-
ble 1). Our polar adjectives include 29 adjectives
referring to quality and 18 adjectives relating to
intelligence. Our non-polar adjectives include 8
dimensional adjectives denoting size and 22 de-
noting duration. The adjectives are taken, in part,
from FrameNet’s (Baker et al., 1998) frames for
</bodyText>
<footnote confidence="0.979039333333333">
1As there has been previous work on how to group adjec-
tives into scales (Hatzivassiloglou and McKeown, 1993), we
consider this grouping as given.
</footnote>
<bodyText confidence="0.938346">
DESIRABILITY, MENTAL PROPERTY, SIZE and
DURATION DESCRIPTION. These scales are used
because they are prototypical and have multiple
members on the positive and negative half-scales.
We evaluate several corpus- and resource-based
methods that have been used to assign intensity
scores to adjectives. We compare them to a new
corpus-based method that is robust and of low
complexity, and which directly uses information
related to degree modification of the adjectives to
be orderered. It rests on the observation that ad-
jectives with different types of intensities co-occur
with different types of adverbial modifiers.2
</bodyText>
<note confidence="0.3570355">
POLAR ADJECTIVES
Intelligence Adjs. Intensity Level
</note>
<tableCaption confidence="0.913512">
Table 1: Adjectives used grouped by human gold
standard intensity classes
</tableCaption>
<footnote confidence="0.931657666666667">
2The ratings we collected and our scripts are avail-
able at www.uni-hildesheim.de/ruppenhofer/
data/DISA_data.zip.
</footnote>
<figure confidence="0.84934037037037">
brilliant very high positive
ingenious high positive
brainy, intelligent medium positive
smart low positive bright very lowpositive
daft very low negative
foolish low negative
inane lower medium negative
dim upper medium negative
dim-witted, dumb, mindless high negative
brainless, idiotic, imbecillic, moronic, stupid very high negative
Quality Adjs. Intensity Level
excellent, extraordinary, first-rate, great, outstand- very high positive
ing, super, superb, superlative, tip-top, top-notch
good high positive
decent upper medium positive
fine, fair lower medium positive
okay, average low positive
so-so very low positive
mediocre very low negative
second-rate, substandard low negative
inferior lower medium negative
bad, crappy, lousy, poor, third-rate medium negative
rotten upper medium negative
awful high negative
shitty very high negative
DIMENSIONAL ADJECTIVES
Size Adjs. Intensity Level
</figure>
<bodyText confidence="0.978775933333333">
colossal, enormous, gargantuan, giant, gigantic, gi-
normous, humongous
big, huge, immense, large, oversize, oversized, vast medium positive
outsize, outsized low positive
diminutive, little, puny, small low negative
tiny medium negative
microscopic high negative
Duration Adjs. Intensity Level
long high positive
lengthy medium positive
extended low positive
momentaneous low negative
brief, fleeting, momentary medium negative
short high negative
high positive
</bodyText>
<page confidence="0.972942">
117
</page>
<note confidence="0.684299">
Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 117–122,
Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics
2 Data and resources
</note>
<tableCaption confidence="0.8893388">
Table 2 gives an overview of the different corpora
and resources that we use to produce the different
scores and rankings that we want to compare. The
corpora and ratings will be discussed alongside the
associated experimental methods in §4.1 and §4.2.
</tableCaption>
<table confidence="0.999642625">
Corpora Tokens Reference
BNC —112 M (Burnard, 2007)
LIU reviews —1.06 B (Jindal and Liu, 2008)
ukWaC —2.25 B (Baroni et al., 2009)
Resources Entries Reference
Affective norms —14 K (Warriner et al., 2013)
SoCAL — 6.5 K (Taboada et al., 2011)
SentiStrength — 2.5 K (Thelwall et al., 2010)
</table>
<tableCaption confidence="0.998516">
Table 2: Corpora and resources used
</tableCaption>
<sectionHeader confidence="0.968198" genericHeader="method">
3 Gold standard
</sectionHeader>
<bodyText confidence="0.999968230769231">
We collected human ratings for our four sets of ad-
jectives. All items were rated individually, in ran-
domized order, under conditions that minimized
bias. Participants were asked to use a horizontal
slider, dragging it in the desired direction, repre-
senting polarity, and releasing the mouse at the de-
sired intensity, ranging from −100 to +100 .
Through Amazon Mechanical Turk (AMT), we
recruited subjects with the following qualifica-
tions: US residency, a HIT-approval rate of at least
96% (following Akkaya et al. (2010)), and 500
prior completed HITs. We collected 20 ratings for
each item but had to exclude some participants’
answers as unusable, which reduced our sample to
17 subjects for some items. In the raw data, all ad-
jectives had different mean ratings and their stan-
dard deviations overlapped. We therefore trans-
formed the data into sets of equally strong adjec-
tives as follows. For a given pair of adjectives of
identical polarity, we counted how many partici-
pants rated adjective A more intense than adjective
B; B more intense than A; or A as intense as B.
Whenever a simple majority existed for one of the
two unequal relations, we adopted that as our rela-
tive ranking for the two adjectives.3 The resulting
rankings (intensity levels) are shown in Table 1.
</bodyText>
<sectionHeader confidence="0.998579" genericHeader="method">
4 Methods
</sectionHeader>
<bodyText confidence="0.86626875">
Our methods to determine the intensity of adjec-
tives are either corpus- or lexicon-based.
3In our data, there was no need to break circular rankings,
so we do not consider this issue here.
</bodyText>
<sectionHeader confidence="0.561196" genericHeader="method">
4.1 Corpus-based methods
</sectionHeader>
<bodyText confidence="0.984461323529412">
Our first method, distinctive-collexeme analysis
(Collex) (Gries and Stefanowitsch, 2004) assumes
that adjectives with different types of intensities
co-occur with different types of adverbial modi-
fiers (Table 3). End-of-scale modifiers such as ex-
tremely or absolutely target adjectives with a par-
tially or fully closed scale, such as brilliant or out-
standing, which occupy extreme positions on the
intensity scale. “Normal” degree modifiers such
as very or rather target adjectives with an open
scale structure (in the sense of Kennedy and Mc-
Nally (2005)), such as good or decent, which oc-
cupy non-extreme positions.
To determine an adjective’s preference for one
of the two constructions, the Fisher exact test
(Pedersen, 1996) is used. It makes no distribu-
tional assumptions and does not require a min-
imum sample size. The direction in which ob-
served values differ from expected ones indicates a
preference for one construction over the other and
the p-values are taken as a measure of the prefer-
ence strength. Our hypothesis is that e.g. an adjec-
tive A with greater preference for the end-of-scale
construction than adjective B has a greater inher-
ent intensity than B. We ran distinctive-collexeme
analysis on both the ukWaC and the BNC. We re-
fer to the output as CollexukWaC and CollexBNC.
Note that this kind of method has not yet been ex-
amined for automatic intensity classification.
end-of-scale “normal”
all, as, awfully, enough, extremely,
fairly, highly, how, least, less, much,
pretty, quite, rather, so, somewhat,
sort of, terribly, too, very, well
</bodyText>
<tableCaption confidence="0.632406">
Table 3: Domain independent degree modifiers (3
</tableCaption>
<bodyText confidence="0.936625095238095">
most freq. terms in the BIC; 3 most freq. terms
in the ukWaC)
Another corpus-based method we consider em-
ploys Mean star ratings (MeanStar) from prod-
uct reviews as described by Rill et al. (2012). Un-
like Collex, this method uses no linguistic prop-
erties of the adjectives themselves. Instead, it de-
rives intensity from the star rating scores that re-
viewers (manually) assign to reviews. We count
how many instances of each adjective i (of the set
of adjectives to classify) occur in review titles with
a given star rating (score) 5j within a review cor-
pus. The intensity score is defined as the weighted
n i
mean of the star ratings 5 Ej=1 Sj .
g— n
Horn (1976) proposes pattern-based diagnos-
100%, fully, totally, absolutely,
completely, perfectly, entirely,
utterly, almost, partially, half,
mostly
</bodyText>
<page confidence="0.981384">
118
</page>
<table confidence="0.999870285714285">
Data set Polar Dimensional
Intelligence Quality Duration Size
MeanStar 0.886 0.935 0.148 -0.058
SoCAL 0.848 0.953 NA 0.776
SentiStrength 0.874 0.880 NA NA
CollexukW aC 0.837 0.806 0.732 0.808
CollexukW aC∗ 0.845 0.753 0.732 0.940
CollexBNC 0.834 0.790 0.732 0.733
CollexBNC∗ 0.705 0.643 0.834 0.700
WarV al 0.779 0.916 -0.632 -0.031
WarAro 0.504 -0.452 0.316 0.717
Warpom 0.790 0.891 0.632 0.285
Pattern
X or even Y
X if not Y
be X but not Y
not only X but Y
X and in fact Y
not X, let alone Y
not Y, not even X
Any Int. Qual. Size Dur.
4118 1 34 9 3
3115 1 0 29 0
2815 0 74 3 1
1114 0 3 0 0
45 0 0 0 0
4 0 0 0 0
4 0 1 0 0
</table>
<tableCaption confidence="0.978822">
Table 4: Phrasal patterns in the ukWaC
</tableCaption>
<bodyText confidence="0.999697157894737">
tics for acquiring information about the scalar
structure of adjectives. This was validated on ac-
tual data by Sheinman and Tokunaga (2009). A
pattern such as not just/only X but Y implies that
[Y] must always be stronger than [X] (as in It’s
not just good but great.).
The pattern-based approach has a severe cover-
age problem. Table 4 shows the results for 7 com-
mon phrasal patterns in the larger of our two cor-
pora, the ukWaC. The slots in the patterns are typ-
ically not filled by adjectives from the same scale.
For example, the most frequent pattern X or even
Y has 4118 instances in the ukWaC. Only 34 of
these have quality adjectives in both slots. Though
de Melo and Bansal (2013) have shown that the
coverage problems can be overcome and state-of-
the-art results obtained using web scale data in the
form of Google n-grams, we still set aside this
method here because of its great resource need.
</bodyText>
<subsectionHeader confidence="0.992486">
4.2 Manually compiled lexical resources
</subsectionHeader>
<bodyText confidence="0.988183444444445">
In addition to the corpus methods, we also con-
sider some manually compiled resources. We want
to know if the polarity and intensity information in
them can be used for ordering polar adjectives.
One resource we consider are the affective rat-
ings (elicited with AMT) for almost 14,000 En-
glish words collected by Warriner et al. (2013).
They include scores of valence (unhappy to
happy), arousal (calm to aroused) and dominance
(in control to controlled) for each word in the list.
This scoring system follows the dimensional the-
ory of emotion by Osgood et al. (1957). We will
interpret each of these dimensions as a separate in-
tensity score, i.e. WarV al, WarAro and WarDom.
Beyond Warriner’s ratings, we consider the two
polarity lexicons SentiStrength (Thelwall et al.,
2010) and SoCAL (Taboada et al., 2011) which
also assign intensity scores to polar expressions.
</bodyText>
<sectionHeader confidence="0.998886" genericHeader="method">
5 Experiments
</sectionHeader>
<bodyText confidence="0.490437">
For our evaluation, we compute the similarity be-
tween the gold standard and every other ranking
we are interested in in terms of Spearman’s rank
correlation coefficient (Spearman’s ρ).
Table 5: Spearman rank correlations with the hu-
man gold standard (∗: only the 3 most frequent
modifiers are used (see Table 3))
</bodyText>
<subsectionHeader confidence="0.988743">
5.1 Data transformation
</subsectionHeader>
<bodyText confidence="0.999979923076923">
For the word lists with numeric scores (MeanStar
(§4.1); SentiStrength, SoCAL, WarV al, WarAro
and WarDom (§4.2)) we did as follows: Adjectives
not covered by the word lists were ignored. Ad-
jectives with equal scores were given tied ranks.
For the experiments involving distinctive
collexeme analysis in our two corpora (§4.1) we
proceeded as follows: The adjectives classified
as distinctive for the end-of-scale modification
constructions were put at the top and bottom of
the ranking according to polarity; the greater the
collostructional strength for the adjective as de-
noted by the p-value, the nearer it is placed to the
top or bottom of the ranking. The adjectives that
are distinctive for the normal degree modification
construction are placed between those adjectives
distinctive for the end-of-scale modification
construction, again taking polarity and collostruc-
tional strength into account. This time, the least
distinctive lemmas for the normal modification
construction come to directly join up with the
least distinctive lemmas for the end-of-scale
construction. In between the normal modifiers,
we place adjectives that have no preference for
one or the other construction, which may result
from non-occurrence in small data sets (see §5.2).
</bodyText>
<subsectionHeader confidence="0.77991">
5.2 Results
</subsectionHeader>
<bodyText confidence="0.999996363636364">
The results of the pairwise correlations between
the human-elicited gold standard and the rankings
derived from various methods and resources are
shown in Table 5. For polar adjectives, most rank-
ings correlate fairly well with human judgments.
Warriner’s arousal list, however, performs poorly
on quality adjectives, whereas MeanStar and War-
riner’s dominance and valence lists perform bet-
ter on quality than on intelligence adjectives. For
MeanStar, this does not come as a surprise as qual-
ity adjectives are much more frequent in prod-
</bodyText>
<page confidence="0.998119">
119
</page>
<bodyText confidence="0.99995754">
uct reviews than intelligence adjectives. Overall,
it seems that MeanStar most closely matches the
human judgments that we elicited for the intel-
ligence adjectives. SentiStrength also produces
high scores. However, we do not have full confi-
dence in that result since SentiStrength lacks many
of our adjectives, thus leading to a possibly higher
correlation than would have been achieved if ranks
(scores) had been available for all adjectives.
The picture is very different for the dimensional
(non-polar) adjectives. While Collex still gives
very good results, especially on the ukWaC, the
MeanStar method and most Warriner lists produce
very low positive or even negative correlations.
This shows that estimating the intensity of non-
polar adjectives from metadata or ratings elicited
in terms of affect is not useful. It is much better to
consider their actual linguistic behavior in degree
constructions, which Collex does. SentiStrength
has no coverage for size or duration adjectives.
SoCAL covers 14 of the 22 size adjectives.
Although it never gives the best result, Collex
produces stable results across both corpora and
the four scales. It also requires the least human
effort by far. While all other rankings are pro-
duced with the help of heavy human annotation
(even MeanStar is completely dependent on manu-
ally assigned review scores), one has only to spec-
ify some domain-independent degree and end-of-
scale modifiers. Table 5 also shows that normally
a larger set of modifiers is necessary: only consid-
ering the 3 most frequent terms (Table 3) results in
a notably reduced correlation. As there is no con-
sistent significant difference between CollexBNC
and CollexukWaC even though the ukWaC is 20
times larger than the BNC (Table 2), we may
conclude that the smaller size of the BNC is al-
ready sufficient. This, however, raises the question
whether even smaller amounts of data than the full
BNC could already produce a reasonable intensity
ranking. Figure 1 plots the Spearman correlation
for our adjectives using various sizes of the BNC
corpus.4 It shows that further reducing the size of
the corpus causes some deterioration, most signifi-
cantly on the intelligence adjectives. The counter-
intuitive curve for duration adjectives is explained
as follows. Collex produces ties in the middle of
the scale when data is lacking (see §5.1). Because
the smallest corpus slices contain no or very few
instances and because the gold standard does in-
</bodyText>
<footnote confidence="0.97112">
4For each size, we average across 10 samples.
</footnote>
<figure confidence="0.914365">
0 20 40 60 80 100
% Size of BNC
</figure>
<figureCaption confidence="0.999972">
Figure 1: Reducing the size of the BNC
</figureCaption>
<bodyText confidence="0.9527365">
clude several ties, the results for duration adjec-
tives are inflated initially, when data is lacking.
</bodyText>
<sectionHeader confidence="0.999836" genericHeader="method">
6 Related work
</sectionHeader>
<bodyText confidence="0.9959786875">
Sentiment analysis on adjectives has been exten-
sively explored in previous work, however, most
work focussed on the extraction of subjective ad-
jectives (Wiebe, 2000; Vegnaduzzo, 2004; Wie-
gand et al., 2013) or on the detection of polar ori-
entation (Hatzivassiloglou and McKeown, 1997;
Kamps et al., 2004; Fahrni and Klenner, 2008).
Intensity can be considered in two ways, as a
contextual strength analysis (Wilson et al., 2004)
or as an out-of-context analysis, as in this paper.
Our main contribution is that we compare sev-
eral classification methods that include a new
effective method based on distinctive-collexeme
analysis requiring hardly any human guidance and
which moreover can solve the problem of intensity
assignment for all, not only polar adjectives.
</bodyText>
<sectionHeader confidence="0.990771" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999989">
We compared diverse corpus-based and lexicon-
based methods for the intensity classification of
adjectives. Among them, we examined for the first
time an approach based on distinctive-collexeme
analysis. It requires only a small predefined set
of adverbial modifiers and relies only on infor-
mation about individual adjectives rather than co-
occurrences of adjectives within patterns. As a re-
sult, it can be used with far less data than e.g. the
Google n-grams provide. Unlike the mean star ap-
proach, it needs no extrinsic meta-data and it can
handle both polar and non-polar adjectives. Ac-
cordingly, it appears to be very promising for cases
where only few resources are available and as a
source of evidence to be used in hybrid methods.
</bodyText>
<figure confidence="0.998874454545455">
Intelligence
Quality
Size
Duration
Spearman’s rho 0.9
0.85
0.8
0.75
0.7
0.65
0.6
</figure>
<page confidence="0.959246">
120
</page>
<sectionHeader confidence="0.997871" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999904">
Michael Wiegand was funded by the German Fed-
eral Ministry of Education and Research (BMBF)
under grant no. 01IC12SO1X. The authors would
like to thank Maite Taboada for providing her sen-
timent lexicon (SoCAL) to be used for the experi-
ments presented in this paper.
</bodyText>
<sectionHeader confidence="0.998485" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999709138613861">
Cem Akkaya, Alexander Conrad, Janyce Wiebe, and
Rada Mihalcea. 2010. Amazon Mechanical Turk
for Subjectivity Word Sense Disambiguation. In
NAACL-HLT 2010 Workshop on Creating Speech
and Language Data With Amazon’s Mechanical
Turk, pages 195–203, Los Angeles, CA, USA.
Collin F. Baker, Charles J. Fillmore, and John B.
Lowe. 1998. The Berkeley Framenet Project.
In Proceedings of the International Conference
on Computational Linguistics and Annual Meeting
of the Association for Computational Linguistics
(COLING/ACL), pages 86–90, Montr´eal, Quebec,
Canada.
Marco Baroni, Silvia Bernardini, Adriano Ferraresi,
and Eros Zanchetti. 2009. The WaCky Wide Web:
A Collection of Very Large Linguistically Processed
Web-Crawled Corpora. Language Resources and
Evaluation, 43(3):209–226.
Lou Burnard, 2007. Reference Guide for the British
National Corpus. Research Technologies Service
at Oxford University Computing Services, Oxford,
UK.
Gerard de Melo and Mohit Bansal. 2013. Good, Great,
Excellent: Global Inference of Semantic Intensities.
Transactions of the Association for Computational
Linguistics, 1:279–290.
Angela Fahrni and Manfred Klenner. 2008. Old Wine
or Warm Beer: Target Specific Sentiment Analysis
of Adjectives. In Proceedings of the Symposium on
Affective Language in Human and Machine, pages
60–63, Aberdeen, Scotland, UK.
Stefan Th. Gries and Anatol Stefanowitsch. 2004.
Extending collostructional analysis: a corpus-based
perspective on ‘alternations’. International Journal
of Corpus Linguistics, 9(1):97–129.
Vasileios Hatzivassiloglou and Kathleen McKeown.
1993. Towards the Automatic Identification of Ad-
jectival Scales: Clustering Adjectives According to
Meaning. In Proceedings of the Annual Meeting
of the Association for Computational Linguistics
(ACL), pages 172–182, Columbus, OH, USA.
Vasileios Hatzivassiloglou and Kathleen R. McKeown.
1997. Predicting the Semantic Orientation of Ad-
jectives. In Proceedings of the Conference on Euro-
pean Chapter of the Association for Computational
Linguistics (EACL), pages 174–181, Madrid, Spain.
Laurence Robert Horn. 1976. On the Semantic Prop-
erties ofLogical Operators in English. Indiana Uni-
versity Linguistics Club.
Nitin Jindal and Bing Liu. 2008. Opinion Spam
and Analysis. In Proceedings of the international
conference on Web search and web data mining
(WSDM), pages 219–230, Palo Alto, USA.
Jaap Kamps, M.J. Marx, Robert J. Mokken, and
Maarten De Rijke. 2004. Using Wordnet to Mea-
sure Semantic Orientations of Adjectives. In Pro-
ceedings of the Conference on Language Resources
and Evaluation (LREC), pages 1115–1118, Lisbon,
Portugal.
Christopher Kennedy and Louise McNally. 2005.
Scale Structure, Degree Modification, and the
Semantics of Gradable Predicates. Language,
81(2):345–338.
Charles E. Osgood, George Suci, and Percy Tannen-
baum. 1957. The Measurement of Meaning. Uni-
versity of Illinois Press.
Ted Pedersen. 1996. Fishing for exactness. In
Proceedings of the South-Central SAS Users Group
Conference, Austin, TX, USA.
Sven Rill, Johannes Drescher, Dirk Reinel, Joerg
Scheidt, Oliver Schuetz, Florian Wogenstein, and
Daniel Simon. 2012. A Generic Approach to Gen-
erate Opinion Lists of Phrases for Opinion Mining
Applications. In Proceedings of the KDD-Workshop
on Issues of Sentiment Discovery and Opinion Min-
ing (WISDOM), Beijing, China.
Vera Sheinman and Takenobu Tokunaga. 2009. Ad-
jScales: Differentiating between Similar Adjectives
for Language Learners. CSEDU, 1:229–235.
Maite Taboada, Julian Brooke, Milan Tofiloski, Kim-
berly Voll, and Manfred Stede. 2011. Lexicon-
Based Methods for Sentiment Analysis. Computa-
tional Linguistics, 37(2):267 – 307.
Mike Thelwall, Kevan Buckley, Georgios Paltoglou,
and Di Cai. 2010. Sentiment Strength Detec-
tion in Short Informal Text. Journal of the Ameri-
can Societyfor Information Science and Technology,
61(12):2544–2558.
Stefano Vegnaduzzo. 2004. Acquisition of Subjective
Adjectives with Limited Resources. In Proceedings
of the AAAI Spring Symposium on Exploring Atti-
tude and Affect in Text: Theories and Applications,
Stanford, CA, USA.
Amy Warriner, Victor Kuperman, and Marc Brysbaert.
2013. Norms of valence, arousal, and dominance for
13,915 english lemmas. Behavior Research Meth-
ods, Online First:1–17.
Janyce M. Wiebe. 2000. Learning Subjective Adjec-
tives from Corpora. In Proceedings of the National
Conference on Artificial Intelligence (AAAI), pages
735–740, Austin, TX, USA.
</reference>
<page confidence="0.972731">
121
</page>
<reference confidence="0.999181333333333">
Michael Wiegand, Josef Ruppenhofer, and Dietrich
Klakow. 2013. Predicative Adjectives: An Unsu-
pervised Criterion to Extract Subjective Adjectives.
In Proceedings of the Human Language Technology
Conference of the North American Chapter of the
ACL (HLT/NAACL), pages 534–539, Atlanta, GA,
USA.
Theresa Wilson, Janyce Wiebe, and Rebecca Hwa.
2004. Just how mad are you? Finding strong and
weak opinion clauses. In Proceedings of the Na-
tional Conference on Artificial Intelligence (AAAI),
pages 761–767, San Jose, CA, USA.
</reference>
<page confidence="0.997472">
122
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.307351">
<title confidence="0.999859">Comparing methods for deriving intensity scores for adjectives</title>
<author confidence="0.999878">Michael Jasper</author>
<affiliation confidence="0.768375">Hildesheim,</affiliation>
<address confidence="0.365649">Saarbr¨ucken,</address>
<email confidence="0.995314">michael.wiegand@lsv.uni-saarland.de</email>
<abstract confidence="0.9991868125">We compare several different corpusbased and lexicon-based methods for the scalar ordering of adjectives. Among them, we examine for the first time a lowresource approach based on distinctivecollexeme analysis that just requires a small predefined set of adverbial modifiers. While previous work on adjective intensity mostly assumes one single scale for all adjectives, we group adjectives into different scales which is more faithful to human perception. We also apply the methods to both polar and non-polar adjectives, showing that not all methods are equally suitable for both types of adjectives.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Cem Akkaya</author>
<author>Alexander Conrad</author>
<author>Janyce Wiebe</author>
<author>Rada Mihalcea</author>
</authors>
<title>Amazon Mechanical Turk for Subjectivity Word Sense Disambiguation.</title>
<date>2010</date>
<booktitle>In NAACL-HLT 2010 Workshop on Creating Speech and Language Data With Amazon’s Mechanical Turk,</booktitle>
<pages>195--203</pages>
<location>Los Angeles, CA, USA.</location>
<contexts>
<context position="5563" citStr="Akkaya et al. (2010)" startWordPosition="811" endWordPosition="814"> SentiStrength — 2.5 K (Thelwall et al., 2010) Table 2: Corpora and resources used 3 Gold standard We collected human ratings for our four sets of adjectives. All items were rated individually, in randomized order, under conditions that minimized bias. Participants were asked to use a horizontal slider, dragging it in the desired direction, representing polarity, and releasing the mouse at the desired intensity, ranging from −100 to +100 . Through Amazon Mechanical Turk (AMT), we recruited subjects with the following qualifications: US residency, a HIT-approval rate of at least 96% (following Akkaya et al. (2010)), and 500 prior completed HITs. We collected 20 ratings for each item but had to exclude some participants’ answers as unusable, which reduced our sample to 17 subjects for some items. In the raw data, all adjectives had different mean ratings and their standard deviations overlapped. We therefore transformed the data into sets of equally strong adjectives as follows. For a given pair of adjectives of identical polarity, we counted how many participants rated adjective A more intense than adjective B; B more intense than A; or A as intense as B. Whenever a simple majority existed for one of t</context>
</contexts>
<marker>Akkaya, Conrad, Wiebe, Mihalcea, 2010</marker>
<rawString>Cem Akkaya, Alexander Conrad, Janyce Wiebe, and Rada Mihalcea. 2010. Amazon Mechanical Turk for Subjectivity Word Sense Disambiguation. In NAACL-HLT 2010 Workshop on Creating Speech and Language Data With Amazon’s Mechanical Turk, pages 195–203, Los Angeles, CA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Collin F Baker</author>
<author>Charles J Fillmore</author>
<author>John B Lowe</author>
</authors>
<title>The Berkeley Framenet Project.</title>
<date>1998</date>
<booktitle>In Proceedings of the International Conference on Computational Linguistics and Annual Meeting of the Association for Computational Linguistics (COLING/ACL),</booktitle>
<pages>86--90</pages>
<location>Montr´eal, Quebec, Canada.</location>
<contexts>
<context position="1835" citStr="Baker et al., 1998" startWordPosition="268" endWordPosition="271">ted in establishing prior or lexical intensity scores and rankings for arbitrary sets of adjectives that evoke the same scale.1 We do not address contextualized intensity, i.e. the fact that e.g. negation and adverbs such as very or slightly impact the perceived intensity of adjectives. We work with four scales of adjectives (cf. Table 1). Our polar adjectives include 29 adjectives referring to quality and 18 adjectives relating to intelligence. Our non-polar adjectives include 8 dimensional adjectives denoting size and 22 denoting duration. The adjectives are taken, in part, from FrameNet’s (Baker et al., 1998) frames for 1As there has been previous work on how to group adjectives into scales (Hatzivassiloglou and McKeown, 1993), we consider this grouping as given. DESIRABILITY, MENTAL PROPERTY, SIZE and DURATION DESCRIPTION. These scales are used because they are prototypical and have multiple members on the positive and negative half-scales. We evaluate several corpus- and resource-based methods that have been used to assign intensity scores to adjectives. We compare them to a new corpus-based method that is robust and of low complexity, and which directly uses information related to degree modifi</context>
</contexts>
<marker>Baker, Fillmore, Lowe, 1998</marker>
<rawString>Collin F. Baker, Charles J. Fillmore, and John B. Lowe. 1998. The Berkeley Framenet Project. In Proceedings of the International Conference on Computational Linguistics and Annual Meeting of the Association for Computational Linguistics (COLING/ACL), pages 86–90, Montr´eal, Quebec, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Baroni</author>
<author>Silvia Bernardini</author>
<author>Adriano Ferraresi</author>
<author>Eros Zanchetti</author>
</authors>
<title>The WaCky Wide Web: A Collection of Very Large Linguistically Processed Web-Crawled Corpora. Language Resources and Evaluation,</title>
<date>2009</date>
<pages>43--3</pages>
<contexts>
<context position="4832" citStr="Baroni et al., 2009" startWordPosition="691" endWordPosition="694"> 117 Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 117–122, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics 2 Data and resources Table 2 gives an overview of the different corpora and resources that we use to produce the different scores and rankings that we want to compare. The corpora and ratings will be discussed alongside the associated experimental methods in §4.1 and §4.2. Corpora Tokens Reference BNC —112 M (Burnard, 2007) LIU reviews —1.06 B (Jindal and Liu, 2008) ukWaC —2.25 B (Baroni et al., 2009) Resources Entries Reference Affective norms —14 K (Warriner et al., 2013) SoCAL — 6.5 K (Taboada et al., 2011) SentiStrength — 2.5 K (Thelwall et al., 2010) Table 2: Corpora and resources used 3 Gold standard We collected human ratings for our four sets of adjectives. All items were rated individually, in randomized order, under conditions that minimized bias. Participants were asked to use a horizontal slider, dragging it in the desired direction, representing polarity, and releasing the mouse at the desired intensity, ranging from −100 to +100 . Through Amazon Mechanical Turk (AMT), we recr</context>
</contexts>
<marker>Baroni, Bernardini, Ferraresi, Zanchetti, 2009</marker>
<rawString>Marco Baroni, Silvia Bernardini, Adriano Ferraresi, and Eros Zanchetti. 2009. The WaCky Wide Web: A Collection of Very Large Linguistically Processed Web-Crawled Corpora. Language Resources and Evaluation, 43(3):209–226.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lou Burnard</author>
</authors>
<title>Reference Guide for the British National Corpus. Research Technologies Service at Oxford University Computing Services,</title>
<date>2007</date>
<location>Oxford, UK.</location>
<contexts>
<context position="4753" citStr="Burnard, 2007" startWordPosition="678" endWordPosition="679">ef, fleeting, momentary medium negative short high negative high positive 117 Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 117–122, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics 2 Data and resources Table 2 gives an overview of the different corpora and resources that we use to produce the different scores and rankings that we want to compare. The corpora and ratings will be discussed alongside the associated experimental methods in §4.1 and §4.2. Corpora Tokens Reference BNC —112 M (Burnard, 2007) LIU reviews —1.06 B (Jindal and Liu, 2008) ukWaC —2.25 B (Baroni et al., 2009) Resources Entries Reference Affective norms —14 K (Warriner et al., 2013) SoCAL — 6.5 K (Taboada et al., 2011) SentiStrength — 2.5 K (Thelwall et al., 2010) Table 2: Corpora and resources used 3 Gold standard We collected human ratings for our four sets of adjectives. All items were rated individually, in randomized order, under conditions that minimized bias. Participants were asked to use a horizontal slider, dragging it in the desired direction, representing polarity, and releasing the mouse at the desired inten</context>
</contexts>
<marker>Burnard, 2007</marker>
<rawString>Lou Burnard, 2007. Reference Guide for the British National Corpus. Research Technologies Service at Oxford University Computing Services, Oxford, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerard de Melo</author>
<author>Mohit Bansal</author>
</authors>
<title>Good, Great, Excellent: Global Inference of Semantic Intensities.</title>
<date>2013</date>
<journal>Transactions of the Association for Computational Linguistics,</journal>
<pages>1--279</pages>
<marker>de Melo, Bansal, 2013</marker>
<rawString>Gerard de Melo and Mohit Bansal. 2013. Good, Great, Excellent: Global Inference of Semantic Intensities. Transactions of the Association for Computational Linguistics, 1:279–290.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Angela Fahrni</author>
<author>Manfred Klenner</author>
</authors>
<title>Old Wine or Warm Beer: Target Specific Sentiment Analysis of Adjectives.</title>
<date>2008</date>
<booktitle>In Proceedings of the Symposium on Affective Language in Human and Machine,</booktitle>
<pages>60--63</pages>
<location>Aberdeen, Scotland, UK.</location>
<contexts>
<context position="16605" citStr="Fahrni and Klenner, 2008" startWordPosition="2650" endWordPosition="2653">no or very few instances and because the gold standard does in4For each size, we average across 10 samples. 0 20 40 60 80 100 % Size of BNC Figure 1: Reducing the size of the BNC clude several ties, the results for duration adjectives are inflated initially, when data is lacking. 6 Related work Sentiment analysis on adjectives has been extensively explored in previous work, however, most work focussed on the extraction of subjective adjectives (Wiebe, 2000; Vegnaduzzo, 2004; Wiegand et al., 2013) or on the detection of polar orientation (Hatzivassiloglou and McKeown, 1997; Kamps et al., 2004; Fahrni and Klenner, 2008). Intensity can be considered in two ways, as a contextual strength analysis (Wilson et al., 2004) or as an out-of-context analysis, as in this paper. Our main contribution is that we compare several classification methods that include a new effective method based on distinctive-collexeme analysis requiring hardly any human guidance and which moreover can solve the problem of intensity assignment for all, not only polar adjectives. 7 Conclusion We compared diverse corpus-based and lexiconbased methods for the intensity classification of adjectives. Among them, we examined for the first time an</context>
</contexts>
<marker>Fahrni, Klenner, 2008</marker>
<rawString>Angela Fahrni and Manfred Klenner. 2008. Old Wine or Warm Beer: Target Specific Sentiment Analysis of Adjectives. In Proceedings of the Symposium on Affective Language in Human and Machine, pages 60–63, Aberdeen, Scotland, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gries</author>
<author>Anatol Stefanowitsch</author>
</authors>
<title>Extending collostructional analysis: a corpus-based perspective on ‘alternations’.</title>
<date>2004</date>
<journal>International Journal of Corpus Linguistics,</journal>
<volume>9</volume>
<issue>1</issue>
<contexts>
<context position="6631" citStr="Gries and Stefanowitsch, 2004" startWordPosition="990" endWordPosition="993">ow many participants rated adjective A more intense than adjective B; B more intense than A; or A as intense as B. Whenever a simple majority existed for one of the two unequal relations, we adopted that as our relative ranking for the two adjectives.3 The resulting rankings (intensity levels) are shown in Table 1. 4 Methods Our methods to determine the intensity of adjectives are either corpus- or lexicon-based. 3In our data, there was no need to break circular rankings, so we do not consider this issue here. 4.1 Corpus-based methods Our first method, distinctive-collexeme analysis (Collex) (Gries and Stefanowitsch, 2004) assumes that adjectives with different types of intensities co-occur with different types of adverbial modifiers (Table 3). End-of-scale modifiers such as extremely or absolutely target adjectives with a partially or fully closed scale, such as brilliant or outstanding, which occupy extreme positions on the intensity scale. “Normal” degree modifiers such as very or rather target adjectives with an open scale structure (in the sense of Kennedy and McNally (2005)), such as good or decent, which occupy non-extreme positions. To determine an adjective’s preference for one of the two constructions</context>
</contexts>
<marker>Gries, Stefanowitsch, 2004</marker>
<rawString>Stefan Th. Gries and Anatol Stefanowitsch. 2004. Extending collostructional analysis: a corpus-based perspective on ‘alternations’. International Journal of Corpus Linguistics, 9(1):97–129.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vasileios Hatzivassiloglou</author>
<author>Kathleen McKeown</author>
</authors>
<title>Towards the Automatic Identification of Adjectival Scales: Clustering Adjectives According to Meaning.</title>
<date>1993</date>
<booktitle>In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>172--182</pages>
<location>Columbus, OH, USA.</location>
<contexts>
<context position="1955" citStr="Hatzivassiloglou and McKeown, 1993" startWordPosition="288" endWordPosition="291"> evoke the same scale.1 We do not address contextualized intensity, i.e. the fact that e.g. negation and adverbs such as very or slightly impact the perceived intensity of adjectives. We work with four scales of adjectives (cf. Table 1). Our polar adjectives include 29 adjectives referring to quality and 18 adjectives relating to intelligence. Our non-polar adjectives include 8 dimensional adjectives denoting size and 22 denoting duration. The adjectives are taken, in part, from FrameNet’s (Baker et al., 1998) frames for 1As there has been previous work on how to group adjectives into scales (Hatzivassiloglou and McKeown, 1993), we consider this grouping as given. DESIRABILITY, MENTAL PROPERTY, SIZE and DURATION DESCRIPTION. These scales are used because they are prototypical and have multiple members on the positive and negative half-scales. We evaluate several corpus- and resource-based methods that have been used to assign intensity scores to adjectives. We compare them to a new corpus-based method that is robust and of low complexity, and which directly uses information related to degree modification of the adjectives to be orderered. It rests on the observation that adjectives with different types of intensitie</context>
</contexts>
<marker>Hatzivassiloglou, McKeown, 1993</marker>
<rawString>Vasileios Hatzivassiloglou and Kathleen McKeown. 1993. Towards the Automatic Identification of Adjectival Scales: Clustering Adjectives According to Meaning. In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL), pages 172–182, Columbus, OH, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vasileios Hatzivassiloglou</author>
<author>Kathleen R McKeown</author>
</authors>
<title>Predicting the Semantic Orientation of Adjectives.</title>
<date>1997</date>
<booktitle>In Proceedings of the Conference on European Chapter of the Association for Computational Linguistics (EACL),</booktitle>
<pages>174--181</pages>
<location>Madrid,</location>
<contexts>
<context position="16558" citStr="Hatzivassiloglou and McKeown, 1997" startWordPosition="2642" endWordPosition="2645"> (see §5.1). Because the smallest corpus slices contain no or very few instances and because the gold standard does in4For each size, we average across 10 samples. 0 20 40 60 80 100 % Size of BNC Figure 1: Reducing the size of the BNC clude several ties, the results for duration adjectives are inflated initially, when data is lacking. 6 Related work Sentiment analysis on adjectives has been extensively explored in previous work, however, most work focussed on the extraction of subjective adjectives (Wiebe, 2000; Vegnaduzzo, 2004; Wiegand et al., 2013) or on the detection of polar orientation (Hatzivassiloglou and McKeown, 1997; Kamps et al., 2004; Fahrni and Klenner, 2008). Intensity can be considered in two ways, as a contextual strength analysis (Wilson et al., 2004) or as an out-of-context analysis, as in this paper. Our main contribution is that we compare several classification methods that include a new effective method based on distinctive-collexeme analysis requiring hardly any human guidance and which moreover can solve the problem of intensity assignment for all, not only polar adjectives. 7 Conclusion We compared diverse corpus-based and lexiconbased methods for the intensity classification of adjectives</context>
</contexts>
<marker>Hatzivassiloglou, McKeown, 1997</marker>
<rawString>Vasileios Hatzivassiloglou and Kathleen R. McKeown. 1997. Predicting the Semantic Orientation of Adjectives. In Proceedings of the Conference on European Chapter of the Association for Computational Linguistics (EACL), pages 174–181, Madrid, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Laurence Robert Horn</author>
</authors>
<date>1976</date>
<booktitle>On the Semantic Properties ofLogical Operators in</booktitle>
<institution>English. Indiana University Linguistics Club.</institution>
<contexts>
<context position="8812" citStr="Horn (1976)" startWordPosition="1359" endWordPosition="1360">n the ukWaC) Another corpus-based method we consider employs Mean star ratings (MeanStar) from product reviews as described by Rill et al. (2012). Unlike Collex, this method uses no linguistic properties of the adjectives themselves. Instead, it derives intensity from the star rating scores that reviewers (manually) assign to reviews. We count how many instances of each adjective i (of the set of adjectives to classify) occur in review titles with a given star rating (score) 5j within a review corpus. The intensity score is defined as the weighted n i mean of the star ratings 5 Ej=1 Sj . g— n Horn (1976) proposes pattern-based diagnos100%, fully, totally, absolutely, completely, perfectly, entirely, utterly, almost, partially, half, mostly 118 Data set Polar Dimensional Intelligence Quality Duration Size MeanStar 0.886 0.935 0.148 -0.058 SoCAL 0.848 0.953 NA 0.776 SentiStrength 0.874 0.880 NA NA CollexukW aC 0.837 0.806 0.732 0.808 CollexukW aC∗ 0.845 0.753 0.732 0.940 CollexBNC 0.834 0.790 0.732 0.733 CollexBNC∗ 0.705 0.643 0.834 0.700 WarV al 0.779 0.916 -0.632 -0.031 WarAro 0.504 -0.452 0.316 0.717 Warpom 0.790 0.891 0.632 0.285 Pattern X or even Y X if not Y be X but not Y not only X but </context>
</contexts>
<marker>Horn, 1976</marker>
<rawString>Laurence Robert Horn. 1976. On the Semantic Properties ofLogical Operators in English. Indiana University Linguistics Club.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nitin Jindal</author>
<author>Bing Liu</author>
</authors>
<title>Opinion Spam and Analysis.</title>
<date>2008</date>
<booktitle>In Proceedings of the international conference on Web search and web data mining (WSDM),</booktitle>
<pages>219--230</pages>
<location>Palo Alto, USA.</location>
<contexts>
<context position="4796" citStr="Jindal and Liu, 2008" startWordPosition="684" endWordPosition="687">ive short high negative high positive 117 Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 117–122, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics 2 Data and resources Table 2 gives an overview of the different corpora and resources that we use to produce the different scores and rankings that we want to compare. The corpora and ratings will be discussed alongside the associated experimental methods in §4.1 and §4.2. Corpora Tokens Reference BNC —112 M (Burnard, 2007) LIU reviews —1.06 B (Jindal and Liu, 2008) ukWaC —2.25 B (Baroni et al., 2009) Resources Entries Reference Affective norms —14 K (Warriner et al., 2013) SoCAL — 6.5 K (Taboada et al., 2011) SentiStrength — 2.5 K (Thelwall et al., 2010) Table 2: Corpora and resources used 3 Gold standard We collected human ratings for our four sets of adjectives. All items were rated individually, in randomized order, under conditions that minimized bias. Participants were asked to use a horizontal slider, dragging it in the desired direction, representing polarity, and releasing the mouse at the desired intensity, ranging from −100 to +100 . Through A</context>
</contexts>
<marker>Jindal, Liu, 2008</marker>
<rawString>Nitin Jindal and Bing Liu. 2008. Opinion Spam and Analysis. In Proceedings of the international conference on Web search and web data mining (WSDM), pages 219–230, Palo Alto, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jaap Kamps</author>
<author>M J Marx</author>
<author>Robert J Mokken</author>
<author>Maarten De Rijke</author>
</authors>
<title>Using Wordnet to Measure Semantic Orientations of Adjectives.</title>
<date>2004</date>
<booktitle>In Proceedings of the Conference on Language Resources and Evaluation (LREC),</booktitle>
<pages>1115--1118</pages>
<location>Lisbon, Portugal.</location>
<marker>Kamps, Marx, Mokken, De Rijke, 2004</marker>
<rawString>Jaap Kamps, M.J. Marx, Robert J. Mokken, and Maarten De Rijke. 2004. Using Wordnet to Measure Semantic Orientations of Adjectives. In Proceedings of the Conference on Language Resources and Evaluation (LREC), pages 1115–1118, Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher Kennedy</author>
<author>Louise McNally</author>
</authors>
<title>Scale Structure, Degree Modification, and the Semantics of Gradable Predicates.</title>
<date>2005</date>
<journal>Language,</journal>
<volume>81</volume>
<issue>2</issue>
<contexts>
<context position="7097" citStr="Kennedy and McNally (2005)" startWordPosition="1063" endWordPosition="1067">kings, so we do not consider this issue here. 4.1 Corpus-based methods Our first method, distinctive-collexeme analysis (Collex) (Gries and Stefanowitsch, 2004) assumes that adjectives with different types of intensities co-occur with different types of adverbial modifiers (Table 3). End-of-scale modifiers such as extremely or absolutely target adjectives with a partially or fully closed scale, such as brilliant or outstanding, which occupy extreme positions on the intensity scale. “Normal” degree modifiers such as very or rather target adjectives with an open scale structure (in the sense of Kennedy and McNally (2005)), such as good or decent, which occupy non-extreme positions. To determine an adjective’s preference for one of the two constructions, the Fisher exact test (Pedersen, 1996) is used. It makes no distributional assumptions and does not require a minimum sample size. The direction in which observed values differ from expected ones indicates a preference for one construction over the other and the p-values are taken as a measure of the preference strength. Our hypothesis is that e.g. an adjective A with greater preference for the end-of-scale construction than adjective B has a greater inherent </context>
</contexts>
<marker>Kennedy, McNally, 2005</marker>
<rawString>Christopher Kennedy and Louise McNally. 2005. Scale Structure, Degree Modification, and the Semantics of Gradable Predicates. Language, 81(2):345–338.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles E Osgood</author>
<author>George Suci</author>
<author>Percy Tannenbaum</author>
</authors>
<title>The Measurement of Meaning.</title>
<date>1957</date>
<publisher>University of Illinois Press.</publisher>
<contexts>
<context position="11124" citStr="Osgood et al. (1957)" startWordPosition="1779" endWordPosition="1782">resource need. 4.2 Manually compiled lexical resources In addition to the corpus methods, we also consider some manually compiled resources. We want to know if the polarity and intensity information in them can be used for ordering polar adjectives. One resource we consider are the affective ratings (elicited with AMT) for almost 14,000 English words collected by Warriner et al. (2013). They include scores of valence (unhappy to happy), arousal (calm to aroused) and dominance (in control to controlled) for each word in the list. This scoring system follows the dimensional theory of emotion by Osgood et al. (1957). We will interpret each of these dimensions as a separate intensity score, i.e. WarV al, WarAro and WarDom. Beyond Warriner’s ratings, we consider the two polarity lexicons SentiStrength (Thelwall et al., 2010) and SoCAL (Taboada et al., 2011) which also assign intensity scores to polar expressions. 5 Experiments For our evaluation, we compute the similarity between the gold standard and every other ranking we are interested in in terms of Spearman’s rank correlation coefficient (Spearman’s ρ). Table 5: Spearman rank correlations with the human gold standard (∗: only the 3 most frequent modif</context>
</contexts>
<marker>Osgood, Suci, Tannenbaum, 1957</marker>
<rawString>Charles E. Osgood, George Suci, and Percy Tannenbaum. 1957. The Measurement of Meaning. University of Illinois Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Pedersen</author>
</authors>
<title>Fishing for exactness.</title>
<date>1996</date>
<booktitle>In Proceedings of the South-Central SAS Users Group Conference,</booktitle>
<location>Austin, TX, USA.</location>
<contexts>
<context position="7271" citStr="Pedersen, 1996" startWordPosition="1093" endWordPosition="1094">with different types of intensities co-occur with different types of adverbial modifiers (Table 3). End-of-scale modifiers such as extremely or absolutely target adjectives with a partially or fully closed scale, such as brilliant or outstanding, which occupy extreme positions on the intensity scale. “Normal” degree modifiers such as very or rather target adjectives with an open scale structure (in the sense of Kennedy and McNally (2005)), such as good or decent, which occupy non-extreme positions. To determine an adjective’s preference for one of the two constructions, the Fisher exact test (Pedersen, 1996) is used. It makes no distributional assumptions and does not require a minimum sample size. The direction in which observed values differ from expected ones indicates a preference for one construction over the other and the p-values are taken as a measure of the preference strength. Our hypothesis is that e.g. an adjective A with greater preference for the end-of-scale construction than adjective B has a greater inherent intensity than B. We ran distinctive-collexeme analysis on both the ukWaC and the BNC. We refer to the output as CollexukWaC and CollexBNC. Note that this kind of method has </context>
</contexts>
<marker>Pedersen, 1996</marker>
<rawString>Ted Pedersen. 1996. Fishing for exactness. In Proceedings of the South-Central SAS Users Group Conference, Austin, TX, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sven Rill</author>
<author>Johannes Drescher</author>
<author>Dirk Reinel</author>
<author>Joerg Scheidt</author>
<author>Oliver Schuetz</author>
<author>Florian Wogenstein</author>
<author>Daniel Simon</author>
</authors>
<title>A Generic Approach to Generate Opinion Lists of Phrases for Opinion Mining Applications.</title>
<date>2012</date>
<booktitle>In Proceedings of the KDD-Workshop on Issues of Sentiment Discovery and Opinion Mining</booktitle>
<location>(WISDOM), Beijing, China.</location>
<contexts>
<context position="8346" citStr="Rill et al. (2012)" startWordPosition="1271" endWordPosition="1274">ctive-collexeme analysis on both the ukWaC and the BNC. We refer to the output as CollexukWaC and CollexBNC. Note that this kind of method has not yet been examined for automatic intensity classification. end-of-scale “normal” all, as, awfully, enough, extremely, fairly, highly, how, least, less, much, pretty, quite, rather, so, somewhat, sort of, terribly, too, very, well Table 3: Domain independent degree modifiers (3 most freq. terms in the BIC; 3 most freq. terms in the ukWaC) Another corpus-based method we consider employs Mean star ratings (MeanStar) from product reviews as described by Rill et al. (2012). Unlike Collex, this method uses no linguistic properties of the adjectives themselves. Instead, it derives intensity from the star rating scores that reviewers (manually) assign to reviews. We count how many instances of each adjective i (of the set of adjectives to classify) occur in review titles with a given star rating (score) 5j within a review corpus. The intensity score is defined as the weighted n i mean of the star ratings 5 Ej=1 Sj . g— n Horn (1976) proposes pattern-based diagnos100%, fully, totally, absolutely, completely, perfectly, entirely, utterly, almost, partially, half, mo</context>
</contexts>
<marker>Rill, Drescher, Reinel, Scheidt, Schuetz, Wogenstein, Simon, 2012</marker>
<rawString>Sven Rill, Johannes Drescher, Dirk Reinel, Joerg Scheidt, Oliver Schuetz, Florian Wogenstein, and Daniel Simon. 2012. A Generic Approach to Generate Opinion Lists of Phrases for Opinion Mining Applications. In Proceedings of the KDD-Workshop on Issues of Sentiment Discovery and Opinion Mining (WISDOM), Beijing, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vera Sheinman</author>
<author>Takenobu Tokunaga</author>
</authors>
<title>AdjScales: Differentiating between Similar Adjectives for Language Learners.</title>
<date>2009</date>
<tech>CSEDU,</tech>
<pages>1--229</pages>
<contexts>
<context position="9755" citStr="Sheinman and Tokunaga (2009)" startWordPosition="1537" endWordPosition="1540">7 0.806 0.732 0.808 CollexukW aC∗ 0.845 0.753 0.732 0.940 CollexBNC 0.834 0.790 0.732 0.733 CollexBNC∗ 0.705 0.643 0.834 0.700 WarV al 0.779 0.916 -0.632 -0.031 WarAro 0.504 -0.452 0.316 0.717 Warpom 0.790 0.891 0.632 0.285 Pattern X or even Y X if not Y be X but not Y not only X but Y X and in fact Y not X, let alone Y not Y, not even X Any Int. Qual. Size Dur. 4118 1 34 9 3 3115 1 0 29 0 2815 0 74 3 1 1114 0 3 0 0 45 0 0 0 0 4 0 0 0 0 4 0 1 0 0 Table 4: Phrasal patterns in the ukWaC tics for acquiring information about the scalar structure of adjectives. This was validated on actual data by Sheinman and Tokunaga (2009). A pattern such as not just/only X but Y implies that [Y] must always be stronger than [X] (as in It’s not just good but great.). The pattern-based approach has a severe coverage problem. Table 4 shows the results for 7 common phrasal patterns in the larger of our two corpora, the ukWaC. The slots in the patterns are typically not filled by adjectives from the same scale. For example, the most frequent pattern X or even Y has 4118 instances in the ukWaC. Only 34 of these have quality adjectives in both slots. Though de Melo and Bansal (2013) have shown that the coverage problems can be overco</context>
</contexts>
<marker>Sheinman, Tokunaga, 2009</marker>
<rawString>Vera Sheinman and Takenobu Tokunaga. 2009. AdjScales: Differentiating between Similar Adjectives for Language Learners. CSEDU, 1:229–235.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maite Taboada</author>
<author>Julian Brooke</author>
<author>Milan Tofiloski</author>
<author>Kimberly Voll</author>
<author>Manfred Stede</author>
</authors>
<title>LexiconBased Methods for Sentiment Analysis.</title>
<date>2011</date>
<journal>Computational Linguistics,</journal>
<volume>37</volume>
<issue>2</issue>
<pages>307</pages>
<contexts>
<context position="4943" citStr="Taboada et al., 2011" startWordPosition="710" endWordPosition="713">cs, pages 117–122, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics 2 Data and resources Table 2 gives an overview of the different corpora and resources that we use to produce the different scores and rankings that we want to compare. The corpora and ratings will be discussed alongside the associated experimental methods in §4.1 and §4.2. Corpora Tokens Reference BNC —112 M (Burnard, 2007) LIU reviews —1.06 B (Jindal and Liu, 2008) ukWaC —2.25 B (Baroni et al., 2009) Resources Entries Reference Affective norms —14 K (Warriner et al., 2013) SoCAL — 6.5 K (Taboada et al., 2011) SentiStrength — 2.5 K (Thelwall et al., 2010) Table 2: Corpora and resources used 3 Gold standard We collected human ratings for our four sets of adjectives. All items were rated individually, in randomized order, under conditions that minimized bias. Participants were asked to use a horizontal slider, dragging it in the desired direction, representing polarity, and releasing the mouse at the desired intensity, ranging from −100 to +100 . Through Amazon Mechanical Turk (AMT), we recruited subjects with the following qualifications: US residency, a HIT-approval rate of at least 96% (following </context>
<context position="11368" citStr="Taboada et al., 2011" startWordPosition="1818" endWordPosition="1821">tives. One resource we consider are the affective ratings (elicited with AMT) for almost 14,000 English words collected by Warriner et al. (2013). They include scores of valence (unhappy to happy), arousal (calm to aroused) and dominance (in control to controlled) for each word in the list. This scoring system follows the dimensional theory of emotion by Osgood et al. (1957). We will interpret each of these dimensions as a separate intensity score, i.e. WarV al, WarAro and WarDom. Beyond Warriner’s ratings, we consider the two polarity lexicons SentiStrength (Thelwall et al., 2010) and SoCAL (Taboada et al., 2011) which also assign intensity scores to polar expressions. 5 Experiments For our evaluation, we compute the similarity between the gold standard and every other ranking we are interested in in terms of Spearman’s rank correlation coefficient (Spearman’s ρ). Table 5: Spearman rank correlations with the human gold standard (∗: only the 3 most frequent modifiers are used (see Table 3)) 5.1 Data transformation For the word lists with numeric scores (MeanStar (§4.1); SentiStrength, SoCAL, WarV al, WarAro and WarDom (§4.2)) we did as follows: Adjectives not covered by the word lists were ignored. Adj</context>
</contexts>
<marker>Taboada, Brooke, Tofiloski, Voll, Stede, 2011</marker>
<rawString>Maite Taboada, Julian Brooke, Milan Tofiloski, Kimberly Voll, and Manfred Stede. 2011. LexiconBased Methods for Sentiment Analysis. Computational Linguistics, 37(2):267 – 307.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mike Thelwall</author>
<author>Kevan Buckley</author>
<author>Georgios Paltoglou</author>
<author>Di Cai</author>
</authors>
<title>Sentiment Strength Detection in Short Informal Text.</title>
<date>2010</date>
<journal>Journal of the American Societyfor Information Science and Technology,</journal>
<volume>61</volume>
<issue>12</issue>
<marker>Thelwall, Buckley, Paltoglou, Di Cai, 2010</marker>
<rawString>Mike Thelwall, Kevan Buckley, Georgios Paltoglou, and Di Cai. 2010. Sentiment Strength Detection in Short Informal Text. Journal of the American Societyfor Information Science and Technology, 61(12):2544–2558.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefano Vegnaduzzo</author>
</authors>
<title>Acquisition of Subjective Adjectives with Limited Resources.</title>
<date>2004</date>
<booktitle>In Proceedings of the AAAI Spring Symposium on Exploring Attitude and Affect in Text: Theories and Applications,</booktitle>
<location>Stanford, CA, USA.</location>
<contexts>
<context position="16458" citStr="Vegnaduzzo, 2004" startWordPosition="2627" endWordPosition="2628">d as follows. Collex produces ties in the middle of the scale when data is lacking (see §5.1). Because the smallest corpus slices contain no or very few instances and because the gold standard does in4For each size, we average across 10 samples. 0 20 40 60 80 100 % Size of BNC Figure 1: Reducing the size of the BNC clude several ties, the results for duration adjectives are inflated initially, when data is lacking. 6 Related work Sentiment analysis on adjectives has been extensively explored in previous work, however, most work focussed on the extraction of subjective adjectives (Wiebe, 2000; Vegnaduzzo, 2004; Wiegand et al., 2013) or on the detection of polar orientation (Hatzivassiloglou and McKeown, 1997; Kamps et al., 2004; Fahrni and Klenner, 2008). Intensity can be considered in two ways, as a contextual strength analysis (Wilson et al., 2004) or as an out-of-context analysis, as in this paper. Our main contribution is that we compare several classification methods that include a new effective method based on distinctive-collexeme analysis requiring hardly any human guidance and which moreover can solve the problem of intensity assignment for all, not only polar adjectives. 7 Conclusion We c</context>
</contexts>
<marker>Vegnaduzzo, 2004</marker>
<rawString>Stefano Vegnaduzzo. 2004. Acquisition of Subjective Adjectives with Limited Resources. In Proceedings of the AAAI Spring Symposium on Exploring Attitude and Affect in Text: Theories and Applications, Stanford, CA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amy Warriner</author>
<author>Victor Kuperman</author>
<author>Marc Brysbaert</author>
</authors>
<title>Norms of valence, arousal, and dominance for 13,915 english lemmas. Behavior Research Methods, Online First:1–17.</title>
<date>2013</date>
<contexts>
<context position="4906" citStr="Warriner et al., 2013" startWordPosition="702" endWordPosition="705">ssociation for Computational Linguistics, pages 117–122, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics 2 Data and resources Table 2 gives an overview of the different corpora and resources that we use to produce the different scores and rankings that we want to compare. The corpora and ratings will be discussed alongside the associated experimental methods in §4.1 and §4.2. Corpora Tokens Reference BNC —112 M (Burnard, 2007) LIU reviews —1.06 B (Jindal and Liu, 2008) ukWaC —2.25 B (Baroni et al., 2009) Resources Entries Reference Affective norms —14 K (Warriner et al., 2013) SoCAL — 6.5 K (Taboada et al., 2011) SentiStrength — 2.5 K (Thelwall et al., 2010) Table 2: Corpora and resources used 3 Gold standard We collected human ratings for our four sets of adjectives. All items were rated individually, in randomized order, under conditions that minimized bias. Participants were asked to use a horizontal slider, dragging it in the desired direction, representing polarity, and releasing the mouse at the desired intensity, ranging from −100 to +100 . Through Amazon Mechanical Turk (AMT), we recruited subjects with the following qualifications: US residency, a HIT-appr</context>
<context position="10892" citStr="Warriner et al. (2013)" startWordPosition="1740" endWordPosition="1743"> Though de Melo and Bansal (2013) have shown that the coverage problems can be overcome and state-ofthe-art results obtained using web scale data in the form of Google n-grams, we still set aside this method here because of its great resource need. 4.2 Manually compiled lexical resources In addition to the corpus methods, we also consider some manually compiled resources. We want to know if the polarity and intensity information in them can be used for ordering polar adjectives. One resource we consider are the affective ratings (elicited with AMT) for almost 14,000 English words collected by Warriner et al. (2013). They include scores of valence (unhappy to happy), arousal (calm to aroused) and dominance (in control to controlled) for each word in the list. This scoring system follows the dimensional theory of emotion by Osgood et al. (1957). We will interpret each of these dimensions as a separate intensity score, i.e. WarV al, WarAro and WarDom. Beyond Warriner’s ratings, we consider the two polarity lexicons SentiStrength (Thelwall et al., 2010) and SoCAL (Taboada et al., 2011) which also assign intensity scores to polar expressions. 5 Experiments For our evaluation, we compute the similarity betwee</context>
</contexts>
<marker>Warriner, Kuperman, Brysbaert, 2013</marker>
<rawString>Amy Warriner, Victor Kuperman, and Marc Brysbaert. 2013. Norms of valence, arousal, and dominance for 13,915 english lemmas. Behavior Research Methods, Online First:1–17.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janyce M Wiebe</author>
</authors>
<title>Learning Subjective Adjectives from Corpora.</title>
<date>2000</date>
<booktitle>In Proceedings of the National Conference on Artificial Intelligence (AAAI),</booktitle>
<pages>735--740</pages>
<location>Austin, TX, USA.</location>
<contexts>
<context position="16440" citStr="Wiebe, 2000" startWordPosition="2625" endWordPosition="2626">s is explained as follows. Collex produces ties in the middle of the scale when data is lacking (see §5.1). Because the smallest corpus slices contain no or very few instances and because the gold standard does in4For each size, we average across 10 samples. 0 20 40 60 80 100 % Size of BNC Figure 1: Reducing the size of the BNC clude several ties, the results for duration adjectives are inflated initially, when data is lacking. 6 Related work Sentiment analysis on adjectives has been extensively explored in previous work, however, most work focussed on the extraction of subjective adjectives (Wiebe, 2000; Vegnaduzzo, 2004; Wiegand et al., 2013) or on the detection of polar orientation (Hatzivassiloglou and McKeown, 1997; Kamps et al., 2004; Fahrni and Klenner, 2008). Intensity can be considered in two ways, as a contextual strength analysis (Wilson et al., 2004) or as an out-of-context analysis, as in this paper. Our main contribution is that we compare several classification methods that include a new effective method based on distinctive-collexeme analysis requiring hardly any human guidance and which moreover can solve the problem of intensity assignment for all, not only polar adjectives.</context>
</contexts>
<marker>Wiebe, 2000</marker>
<rawString>Janyce M. Wiebe. 2000. Learning Subjective Adjectives from Corpora. In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 735–740, Austin, TX, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Wiegand</author>
<author>Josef Ruppenhofer</author>
<author>Dietrich Klakow</author>
</authors>
<title>Predicative Adjectives: An Unsupervised Criterion to Extract Subjective Adjectives.</title>
<date>2013</date>
<booktitle>In Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL (HLT/NAACL),</booktitle>
<pages>534--539</pages>
<location>Atlanta, GA, USA.</location>
<contexts>
<context position="16481" citStr="Wiegand et al., 2013" startWordPosition="2629" endWordPosition="2633">ex produces ties in the middle of the scale when data is lacking (see §5.1). Because the smallest corpus slices contain no or very few instances and because the gold standard does in4For each size, we average across 10 samples. 0 20 40 60 80 100 % Size of BNC Figure 1: Reducing the size of the BNC clude several ties, the results for duration adjectives are inflated initially, when data is lacking. 6 Related work Sentiment analysis on adjectives has been extensively explored in previous work, however, most work focussed on the extraction of subjective adjectives (Wiebe, 2000; Vegnaduzzo, 2004; Wiegand et al., 2013) or on the detection of polar orientation (Hatzivassiloglou and McKeown, 1997; Kamps et al., 2004; Fahrni and Klenner, 2008). Intensity can be considered in two ways, as a contextual strength analysis (Wilson et al., 2004) or as an out-of-context analysis, as in this paper. Our main contribution is that we compare several classification methods that include a new effective method based on distinctive-collexeme analysis requiring hardly any human guidance and which moreover can solve the problem of intensity assignment for all, not only polar adjectives. 7 Conclusion We compared diverse corpus-</context>
</contexts>
<marker>Wiegand, Ruppenhofer, Klakow, 2013</marker>
<rawString>Michael Wiegand, Josef Ruppenhofer, and Dietrich Klakow. 2013. Predicative Adjectives: An Unsupervised Criterion to Extract Subjective Adjectives. In Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL (HLT/NAACL), pages 534–539, Atlanta, GA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Wilson</author>
<author>Janyce Wiebe</author>
<author>Rebecca Hwa</author>
</authors>
<title>Just how mad are you? Finding strong and weak opinion clauses.</title>
<date>2004</date>
<booktitle>In Proceedings of the National Conference on Artificial Intelligence (AAAI),</booktitle>
<pages>761--767</pages>
<location>San Jose, CA, USA.</location>
<contexts>
<context position="16703" citStr="Wilson et al., 2004" startWordPosition="2666" endWordPosition="2669">les. 0 20 40 60 80 100 % Size of BNC Figure 1: Reducing the size of the BNC clude several ties, the results for duration adjectives are inflated initially, when data is lacking. 6 Related work Sentiment analysis on adjectives has been extensively explored in previous work, however, most work focussed on the extraction of subjective adjectives (Wiebe, 2000; Vegnaduzzo, 2004; Wiegand et al., 2013) or on the detection of polar orientation (Hatzivassiloglou and McKeown, 1997; Kamps et al., 2004; Fahrni and Klenner, 2008). Intensity can be considered in two ways, as a contextual strength analysis (Wilson et al., 2004) or as an out-of-context analysis, as in this paper. Our main contribution is that we compare several classification methods that include a new effective method based on distinctive-collexeme analysis requiring hardly any human guidance and which moreover can solve the problem of intensity assignment for all, not only polar adjectives. 7 Conclusion We compared diverse corpus-based and lexiconbased methods for the intensity classification of adjectives. Among them, we examined for the first time an approach based on distinctive-collexeme analysis. It requires only a small predefined set of adve</context>
</contexts>
<marker>Wilson, Wiebe, Hwa, 2004</marker>
<rawString>Theresa Wilson, Janyce Wiebe, and Rebecca Hwa. 2004. Just how mad are you? Finding strong and weak opinion clauses. In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 761–767, San Jose, CA, USA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>