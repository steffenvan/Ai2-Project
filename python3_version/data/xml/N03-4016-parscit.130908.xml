<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.433399">
<note confidence="0.974657666666667">
Proceedings of HLT-NAACL 2003
Demonstrations , pp. 31-32
Edmonton, May-June 2003
</note>
<title confidence="0.969863">
Monolingual and Bilingual Concept Visualization from Corpora
</title>
<author confidence="0.992435">
Dominic Widdows Scott Cederberg
</author>
<affiliation confidence="0.781307">
Center for the Study of Language and Information, Stanford University
</affiliation>
<email confidence="0.962973">
{dwiddows,cederber}@csli.stanford.edu
</email>
<bodyText confidence="0.999915146666667">
As well as identifying relevant information, a suc-
cessful information management system must be able to
present its findings in terms which are familiar to the user,
which is especially challenging when the incoming in-
formation is in a foreign language (Levow et al., 2001).
We demonstrate techniques which attempt to address this
challenge by placing terms in an abstract ‘information
space’ based on their occurrences in text corpora, and
then allowing a user to visualize local regions of this in-
formation space. Words are plotted in a 2-dimensional
picture so that related words are close together and whole
classes of similar words occur in recognizable clusters
which sometimes clearly signify a particular meaning. As
well as giving a clear view of which concepts are related
in a particular document collection, this technique also
helps a user to interpret unknown words.
The main technique we will demonstrate is planar pro-
jection of word-vectors from a vector space built using
Latent Semantic Analysis (LSA) (Landauer and Dumais,
1997; Sch¨utze, 1998), a method which can be applied
multilingually if translated corpora are available for train-
ing. Following the method of Sch¨utze (1998), we assign
each word 1000 coordinates based on the number of times
that word occurs in a 15 word window with one of 1000
‘content-bearing words’, chosen by frequency, and the
number of coordinates is reduced to 100 ‘latent dimen-
sions’ using LSA.
This is still far too many words and too many dimen-
sions to be visualized at once. To produce a meaningful
diagram of results related to a particular word or query,
we perform two extra steps. Firstly, we restrict atten-
tion to a given number of closely related words (deter-
mined by cosine similarity of word vectors), selecting a
local group of up to 100 words and their word vectors
for deeper analysis. A second round of Latent Seman-
tic Analysis is then performed on this restricted set, giv-
ing the most significant directions to describe this local
information. The 2 most significant axes determine the
plane which best represents the data. (This process can
be regarded as a higher-dimensional analogue of finding
the line of best-fit for a normal 2-dimensional graph.) The
resulting diagrams give an summary of the areas of mean-
ing in which a word is actually used in a particular docu-
ment collection.
This is particularly effective for visualizing words in
more than one language. This can be achieved by build-
ing a single latent semantic vector space incorporat-
ing words from two languages using a parallel corpus
(Littman et al., 1998; Widdows et al., 2002b). We will
demonstrate a system which does this for English and
German terms in the medical domain. The system is
trained on a corpus of 10,000 abstracts from German
medical documents available with their English transla-
tions 1. In the demonstration, users submit a query state-
ment consisting of any combination of words in English
or German, and are then able to visualize the words most
closely related to this query in a 2-dimensional plot of the
latent semantic space.
An example output for the English query word drug is
shown in Figure below. 2. Such words are of special
interest because the English word drug has two mean-
ings which are represented by different words in German
(medikament = prescription drug and drogen = narcotic).
The 2-dimensional plot clearly distinguishes these two
areas of meaning, with the English word drug being in
between. Such techniques can enable users to recognize
and understand translational ambiguities.
As well as the Springer abstracts corpus, the system
has been trained to work with the parallel English/French
Canadian Hansard corpus and several large monolingual
corpora. Other functionalities of this system include au-
tomatic thesaurus generation, clustering of terms to deter-
mine different context areas, query refinement and docu-
ment retrieval.
As well as LSA, which only uses broad ‘bag of words’
</bodyText>
<footnote confidence="0.9978912">
1Available from the Springer Link website,
http://link.springer.de/
2In the actual demonstration, English results appear in red
and German results in blue: for the description here we have
used different fonts instead.
</footnote>
<figureCaption confidence="0.999968">
Figure 1: ENGLISH and German terms related to the English word drug in the Springer medical abstracts.
</figureCaption>
<figure confidence="0.998970272727273">
antiepileptika ANTIEPILEPTIC
NEUROTRANSMISSION
gc COCAINE
THC
CANNABINOIDS
drogen ABUSE roirksamer substan3en
methadon DRUGS
METHADONE
FORENSIC
ar3neimittel medikament¨ose
FATALITIES DRUG
drogentodesf¨alle
roirksame
drogenabh¨angigen medikamente
bet¨aubungsmittel
medikamenten
opiate
OPIATES
heroin
HEROIN
kokain
URINE
SEROTONERGIC
PIGMENTATION
DEPENDENCEp
harmaka
substan3
ANTIARRHYTHMIC
HAIR
pigmentierung
ANTICONVULSANT
antiarrhythmika
DOSAGE
</figure>
<bodyText confidence="0.999772875">
coocurrence to define similarities, mathematical models
can be built using local coordination of terms based on
syntactic properties. For example, list of nouns such as
“apples, pears and oranges” can be used as information
that these words are all linked, and these links can be
recorded in a database which can also be analyzed using
visualization techniques (Widdows et al., 2002a) and will
be included in the demonstration.
</bodyText>
<subsectionHeader confidence="0.643451">
Demonstration website
</subsectionHeader>
<bodyText confidence="0.999806">
Versions of these demonstrations are publicly avail-
able through the CSLI Infomap project website,
(http://infomap.stanford.edu/).
</bodyText>
<sectionHeader confidence="0.998319" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9997652">
This research was supported in part by the Research
Collaboration between the NTT Communication Science
Laboratories, Nippon Telegraph and Telephone Corpora-
tion and CSLI, Stanford University, and by EC/NSF grant
IST-1999-11438 for the MUCHMORE project.
</bodyText>
<sectionHeader confidence="0.998983" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99724292">
T. Landauer and S. Dumais. 1997. A solution to plato’s
problem: The latent semantic analysis theory of acqui-
sition. Psychological Review, 104(2):211–240.
Gina-Anne Levow, Douglas W. Oard, and Philip Resnik.
2001. Rapidly retargetable interactive translingual re-
trieval. In Human Language Technology Conference
(HLT 2001), San Diego, CA.
Michael L. Littman, Susan T. Dumais, and Thomas K.
Landauer. 1998. Automatic cross-language informa-
tion retrieval using latent semantic indexing. In Gre-
gory Grefenstette, editor, Cross-language information
retrieval, chapter 4. Kluwer, Boston.
Hinrich Sch¨utze. 1998. Automatic word sense discrimi-
nation. Computational Linguistics, 24(1):97–124.
Dominic Widdows, Scott Cederberg, and Beate Dorow.
2002a. Visualisation techniques for analysing mean-
ing. In Fifth International Conference on Text, Speech
and Dialogue, Lecture Notes in Artificial Intelligence
2448, pages 107–115, Brno, Czech Republic, Septem-
ber. Springer.
Dominic Widdows, Beate Dorow, and Chiu-Ki Chan.
2002b. Using parallel corpora to enrich multilingual
lexical resources. In Third International Conference
on Language Resources and Evaluation, pages 240–
245, Las Palmas, Spain, May.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.094040">
<note confidence="0.974980333333333">Proceedings of HLT-NAACL 2003 Demonstrations , pp. 31-32 Edmonton, May-June 2003</note>
<title confidence="0.992741">Monolingual and Bilingual Concept Visualization from Corpora</title>
<author confidence="0.999319">Dominic Widdows Scott Cederberg</author>
<affiliation confidence="0.999763">Center for the Study of Language and Information, Stanford University</affiliation>
<abstract confidence="0.990045449152542">As well as identifying relevant information, a successful information management system must be able to present its findings in terms which are familiar to the user, which is especially challenging when the incoming information is in a foreign language (Levow et al., 2001). We demonstrate techniques which attempt to address this challenge by placing terms in an abstract ‘information space’ based on their occurrences in text corpora, and then allowing a user to visualize local regions of this information space. Words are plotted in a 2-dimensional picture so that related words are close together and whole classes of similar words occur in recognizable clusters which sometimes clearly signify a particular meaning. As well as giving a clear view of which concepts are related in a particular document collection, this technique also helps a user to interpret unknown words. The main technique we will demonstrate is planar projection of word-vectors from a vector space built using Latent Semantic Analysis (LSA) (Landauer and Dumais, 1997; Sch¨utze, 1998), a method which can be applied multilingually if translated corpora are available for training. Following the method of Sch¨utze (1998), we assign each word 1000 coordinates based on the number of times that word occurs in a 15 word window with one of 1000 ‘content-bearing words’, chosen by frequency, and the number of coordinates is reduced to 100 ‘latent dimensions’ using LSA. This is still far too many words and too many dimensions to be visualized at once. To produce a meaningful diagram of results related to a particular word or query, we perform two extra steps. Firstly, we restrict attention to a given number of closely related words (determined by cosine similarity of word vectors), selecting a local group of up to 100 words and their word vectors for deeper analysis. A second round of Latent Semantic Analysis is then performed on this restricted set, giving the most significant directions to describe this local information. The 2 most significant axes determine the plane which best represents the data. (This process can be regarded as a higher-dimensional analogue of finding the line of best-fit for a normal 2-dimensional graph.) The resulting diagrams give an summary of the areas of meaning in which a word is actually used in a particular document collection. This is particularly effective for visualizing words in more than one language. This can be achieved by building a single latent semantic vector space incorporating words from two languages using a parallel corpus (Littman et al., 1998; Widdows et al., 2002b). We will demonstrate a system which does this for English and German terms in the medical domain. The system is trained on a corpus of 10,000 abstracts from German medical documents available with their English transla- In the demonstration, users submit a query statement consisting of any combination of words in English or German, and are then able to visualize the words most closely related to this query in a 2-dimensional plot of the latent semantic space. example output for the English query word in Figure below. Such words are of special because the English word two meanings which are represented by different words in German prescription drug and narcotic). The 2-dimensional plot clearly distinguishes these two of meaning, with the English word in between. Such techniques can enable users to recognize and understand translational ambiguities. As well as the Springer abstracts corpus, the system has been trained to work with the parallel English/French Canadian Hansard corpus and several large monolingual corpora. Other functionalities of this system include automatic thesaurus generation, clustering of terms to determine different context areas, query refinement and document retrieval. As well as LSA, which only uses broad ‘bag of words’ from the Springer Link website, http://link.springer.de/ the actual demonstration, English results appear in red and German results in blue: for the description here we have used different fonts instead. 1: related to the English word the Springer medical abstracts. NEUROTRANSMISSION THC CANNABINOIDS drogen methadon ABUSE roirksamer substan3en METHADONE FORENSIC DRUGS FATALITIES DRUG roirksame medikamente medikamenten opiate OPIATES heroin HEROIN kokain URINE SEROTONERGIC PIGMENTATION harmaka substan3 ANTIARRHYTHMIC HAIR pigmentierung ANTICONVULSANT antiarrhythmika DOSAGE coocurrence to define similarities, mathematical models can be built using local coordination of terms based on syntactic properties. For example, list of nouns such as “apples, pears and oranges” can be used as information that these words are all linked, and these links can be recorded in a database which can also be analyzed using visualization techniques (Widdows et al., 2002a) and will be included in the demonstration. Demonstration website Versions of these demonstrations are publicly available through the CSLI Infomap project website, Acknowledgments</abstract>
<note confidence="0.918518161290322">This research was supported in part by the Research Collaboration between the NTT Communication Science Laboratories, Nippon Telegraph and Telephone Corporation and CSLI, Stanford University, and by EC/NSF grant IST-1999-11438 for the MUCHMORE project. References T. Landauer and S. Dumais. 1997. A solution to plato’s The latent semantic analysis theory of acqui- 104(2):211–240. Gina-Anne Levow, Douglas W. Oard, and Philip Resnik. 2001. Rapidly retargetable interactive translingual re- In Language Technology Conference 2001), San Diego, Michael L. Littman, Susan T. Dumais, and Thomas K. Landauer. 1998. Automatic cross-language information retrieval using latent semantic indexing. In Gre- Grefenstette, editor, information chapter 4. Kluwer, Boston. Hinrich Sch¨utze. 1998. Automatic word sense discrimi- 24(1):97–124. Dominic Widdows, Scott Cederberg, and Beate Dorow. 2002a. Visualisation techniques for analysing mean- In International Conference on Text, Speech Lecture Notes in Artificial Intelligence 2448, pages 107–115, Brno, Czech Republic, September. Springer. Dominic Widdows, Beate Dorow, and Chiu-Ki Chan. 2002b. Using parallel corpora to enrich multilingual resources. In International Conference Language Resources and pages 240– 245, Las Palmas, Spain, May.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>T Landauer</author>
<author>S Dumais</author>
</authors>
<title>A solution to plato’s problem: The latent semantic analysis theory of acquisition.</title>
<date>1997</date>
<journal>Psychological Review,</journal>
<volume>104</volume>
<issue>2</issue>
<contexts>
<context position="1328" citStr="Landauer and Dumais, 1997" startWordPosition="196" endWordPosition="199">n text corpora, and then allowing a user to visualize local regions of this information space. Words are plotted in a 2-dimensional picture so that related words are close together and whole classes of similar words occur in recognizable clusters which sometimes clearly signify a particular meaning. As well as giving a clear view of which concepts are related in a particular document collection, this technique also helps a user to interpret unknown words. The main technique we will demonstrate is planar projection of word-vectors from a vector space built using Latent Semantic Analysis (LSA) (Landauer and Dumais, 1997; Sch¨utze, 1998), a method which can be applied multilingually if translated corpora are available for training. Following the method of Sch¨utze (1998), we assign each word 1000 coordinates based on the number of times that word occurs in a 15 word window with one of 1000 ‘content-bearing words’, chosen by frequency, and the number of coordinates is reduced to 100 ‘latent dimensions’ using LSA. This is still far too many words and too many dimensions to be visualized at once. To produce a meaningful diagram of results related to a particular word or query, we perform two extra steps. Firstly</context>
</contexts>
<marker>Landauer, Dumais, 1997</marker>
<rawString>T. Landauer and S. Dumais. 1997. A solution to plato’s problem: The latent semantic analysis theory of acquisition. Psychological Review, 104(2):211–240.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gina-Anne Levow</author>
<author>Douglas W Oard</author>
<author>Philip Resnik</author>
</authors>
<title>Rapidly retargetable interactive translingual retrieval.</title>
<date>2001</date>
<booktitle>In Human Language Technology Conference (HLT 2001),</booktitle>
<location>San Diego, CA.</location>
<marker>Levow, Oard, Resnik, 2001</marker>
<rawString>Gina-Anne Levow, Douglas W. Oard, and Philip Resnik. 2001. Rapidly retargetable interactive translingual retrieval. In Human Language Technology Conference (HLT 2001), San Diego, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael L Littman</author>
<author>Susan T Dumais</author>
<author>Thomas K Landauer</author>
</authors>
<title>Automatic cross-language information retrieval using latent semantic indexing.</title>
<date>1998</date>
<booktitle>Cross-language information retrieval, chapter 4.</booktitle>
<editor>In Gregory Grefenstette, editor,</editor>
<publisher>Kluwer,</publisher>
<location>Boston.</location>
<contexts>
<context position="2871" citStr="Littman et al., 1998" startWordPosition="458" endWordPosition="461">tions to describe this local information. The 2 most significant axes determine the plane which best represents the data. (This process can be regarded as a higher-dimensional analogue of finding the line of best-fit for a normal 2-dimensional graph.) The resulting diagrams give an summary of the areas of meaning in which a word is actually used in a particular document collection. This is particularly effective for visualizing words in more than one language. This can be achieved by building a single latent semantic vector space incorporating words from two languages using a parallel corpus (Littman et al., 1998; Widdows et al., 2002b). We will demonstrate a system which does this for English and German terms in the medical domain. The system is trained on a corpus of 10,000 abstracts from German medical documents available with their English translations 1. In the demonstration, users submit a query statement consisting of any combination of words in English or German, and are then able to visualize the words most closely related to this query in a 2-dimensional plot of the latent semantic space. An example output for the English query word drug is shown in Figure below. 2. Such words are of special</context>
</contexts>
<marker>Littman, Dumais, Landauer, 1998</marker>
<rawString>Michael L. Littman, Susan T. Dumais, and Thomas K. Landauer. 1998. Automatic cross-language information retrieval using latent semantic indexing. In Gregory Grefenstette, editor, Cross-language information retrieval, chapter 4. Kluwer, Boston.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hinrich Sch¨utze</author>
</authors>
<title>Automatic word sense discrimination.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<volume>24</volume>
<issue>1</issue>
<marker>Sch¨utze, 1998</marker>
<rawString>Hinrich Sch¨utze. 1998. Automatic word sense discrimination. Computational Linguistics, 24(1):97–124.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dominic Widdows</author>
<author>Scott Cederberg</author>
<author>Beate Dorow</author>
</authors>
<title>Visualisation techniques for analysing meaning. In</title>
<date>2002</date>
<booktitle>Fifth International Conference on Text, Speech and Dialogue, Lecture Notes in Artificial Intelligence 2448,</booktitle>
<pages>107--115</pages>
<publisher>Springer.</publisher>
<location>Brno, Czech Republic,</location>
<contexts>
<context position="2893" citStr="Widdows et al., 2002" startWordPosition="462" endWordPosition="465"> local information. The 2 most significant axes determine the plane which best represents the data. (This process can be regarded as a higher-dimensional analogue of finding the line of best-fit for a normal 2-dimensional graph.) The resulting diagrams give an summary of the areas of meaning in which a word is actually used in a particular document collection. This is particularly effective for visualizing words in more than one language. This can be achieved by building a single latent semantic vector space incorporating words from two languages using a parallel corpus (Littman et al., 1998; Widdows et al., 2002b). We will demonstrate a system which does this for English and German terms in the medical domain. The system is trained on a corpus of 10,000 abstracts from German medical documents available with their English translations 1. In the demonstration, users submit a query statement consisting of any combination of words in English or German, and are then able to visualize the words most closely related to this query in a 2-dimensional plot of the latent semantic space. An example output for the English query word drug is shown in Figure below. 2. Such words are of special interest because the </context>
</contexts>
<marker>Widdows, Cederberg, Dorow, 2002</marker>
<rawString>Dominic Widdows, Scott Cederberg, and Beate Dorow. 2002a. Visualisation techniques for analysing meaning. In Fifth International Conference on Text, Speech and Dialogue, Lecture Notes in Artificial Intelligence 2448, pages 107–115, Brno, Czech Republic, September. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dominic Widdows</author>
<author>Beate Dorow</author>
<author>Chiu-Ki Chan</author>
</authors>
<title>Using parallel corpora to enrich multilingual lexical resources.</title>
<date>2002</date>
<booktitle>In Third International Conference on Language Resources and Evaluation,</booktitle>
<pages>240--245</pages>
<location>Las Palmas, Spain,</location>
<contexts>
<context position="2893" citStr="Widdows et al., 2002" startWordPosition="462" endWordPosition="465"> local information. The 2 most significant axes determine the plane which best represents the data. (This process can be regarded as a higher-dimensional analogue of finding the line of best-fit for a normal 2-dimensional graph.) The resulting diagrams give an summary of the areas of meaning in which a word is actually used in a particular document collection. This is particularly effective for visualizing words in more than one language. This can be achieved by building a single latent semantic vector space incorporating words from two languages using a parallel corpus (Littman et al., 1998; Widdows et al., 2002b). We will demonstrate a system which does this for English and German terms in the medical domain. The system is trained on a corpus of 10,000 abstracts from German medical documents available with their English translations 1. In the demonstration, users submit a query statement consisting of any combination of words in English or German, and are then able to visualize the words most closely related to this query in a 2-dimensional plot of the latent semantic space. An example output for the English query word drug is shown in Figure below. 2. Such words are of special interest because the </context>
</contexts>
<marker>Widdows, Dorow, Chan, 2002</marker>
<rawString>Dominic Widdows, Beate Dorow, and Chiu-Ki Chan. 2002b. Using parallel corpora to enrich multilingual lexical resources. In Third International Conference on Language Resources and Evaluation, pages 240– 245, Las Palmas, Spain, May.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>