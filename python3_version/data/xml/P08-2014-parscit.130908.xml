<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000681">
<title confidence="0.995543">
Active Sample Selection for Named Entity Transliteration
</title>
<author confidence="0.998992">
Dan Goldwasser Dan Roth
</author>
<affiliation confidence="0.9990865">
Department of Computer Science
University of Illinois
</affiliation>
<address confidence="0.814244">
Urbana, IL 61801
</address>
<email confidence="0.998943">
{goldwas1,danr}@uiuc.edu
</email>
<sectionHeader confidence="0.995638" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998739866666667">
This paper introduces a new method for
identifying named-entity (NE) transliterations
within bilingual corpora. Current state-of-the-
art approaches usually require annotated data
and relevant linguistic knowledge which may
not be available for all languages. We show
how to effectively train an accurate transliter-
ation classifier using very little data, obtained
automatically. To perform this task, we intro-
duce a new active sampling paradigm for guid-
ing and adapting the sample selection process.
We also investigate how to improve the clas-
sifier by identifying repeated patterns in the
training data. We evaluated our approach us-
ing English, Russian and Hebrew corpora.
</bodyText>
<sectionHeader confidence="0.998988" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9999703125">
This paper presents a new approach for constructing
a discriminative transliteration model.
Our approach is fully automated and requires little
knowledge of the source and target languages.
Named entity (NE) transliteration is the process of
transcribing a NE from a source language to a target
language based on phonetic similarity between the
entities. Figure 1 provides examples of NE translit-
erations in English Russian and Hebrew.
Identifying transliteration pairs is an important
component in many linguistic applications such as
machine translation and information retrieval, which
require identifying out-of-vocabulary words.
In our settings, we have access to source language
NE and the ability to label the data upon request.
We introduce a new active sampling paradigm that
</bodyText>
<page confidence="0.99582">
53
</page>
<figureCaption confidence="0.999702">
Figure 1: NE in English, Russian and Hebrew.
</figureCaption>
<bodyText confidence="0.999603217391304">
aims to guide the learner toward informative sam-
ples, allowing learning from a small number of rep-
resentative examples. After the data is obtained it is
analyzed to identify repeating patterns which can be
used to focus the training process of the model.
Previous works usually take a generative approach,
(Knight and Graehl, 1997). Other approaches ex-
ploit similarities in aligned bilingual corpora; for ex-
ample, (Tao et al., 2006) combine two unsupervised
methods. (Klementiev and Roth, 2006) bootstrap
with a classifier used interchangeably with an un-
supervised temporal alignment method. Although
these approaches alleviate the problem of obtain-
ing annotated data, other resources are still required,
such as a large aligned bilingual corpus.
The idea of selectively sampling training samples
has been wildly discussed in machine learning the-
ory (Seung et al., 1992) and has been applied suc-
cessfully to several NLP applications (McCallum
and Nigam, 1998). Unlike other approaches,our ap-
proach is based on minimizing the distance between
the feature distribution of a comprehensive reference
set and the sampled set.
</bodyText>
<sectionHeader confidence="0.713048" genericHeader="method">
2 Training a Transliteration Model
</sectionHeader>
<bodyText confidence="0.8578965">
Our framework works in several stages, as summa-
rized in Algorithm 1. First, a training set consisting
</bodyText>
<subsubsectionHeader confidence="0.313133">
Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pages 53–56,
</subsubsectionHeader>
<page confidence="0.479289">
Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics
</page>
<bodyText confidence="0.95917916">
of NE transliteration pairs (ws, wt) is automatically
generated using an active sample selection scheme.
The sample selection process is guided by the Suf-
ficient Spanning Features criterion (SSF) introduced
in section 2.2, to identify informative samples in the
source language.An oracle capable of pairing a NE
in the source language with its counterpart in the tar-
get language is then used. Negative training samples
are generated by reshuffling the terms in these pairs.
Once the training data has been collected, the data
is analyzed to identify repeating patterns in the data
which are used to focus the training process by as-
signing weights to features corresponding to the ob-
served patterns. Finally, a linear model is trained us-
ing a variation of the averaged perceptron (Freund
and Schapire, 1998) algorithm. The remainder of
this section provides details about these stages; the
basic formulation of the transliteration model and
the feature extraction scheme is described in section
2.1, in section 2.2 the selective sampling process is
described and finally section 2.3 explains how learn-
ing is focused by using feature weights.
Input: Bilingual, comparable corpus (S, T), set of
named entities NES from S, Reference
Corpus RS, Transliteration Oracle O,
</bodyText>
<figure confidence="0.909794153846154">
Training Corpora D=DS,DT
Output: Transliteration model M
1 Guiding the Sampling Process
2 repeat
3 select a set C C NES randomly
4 ws = argmin,,,ECdistance(R, DS U {ws})
5 D = D U {Ws, O(Ws)}
6 until distance(R,DS U {Ws}) &gt; distance(R,DS) ;
7 Determining Features Activation Strength
8 Define W:f → R s.t. foreach feature f ={fs, ft}
9 W = 0(fs,ft) X 0(fs,ft)
Ws) Wt)
10 Use D to train M;
</figure>
<construct confidence="0.680735">
Algorithm 1: Constructing a transliteration
model.
</construct>
<subsectionHeader confidence="0.856306">
2.1 Transliteration Model
</subsectionHeader>
<bodyText confidence="0.9988475">
Our transliteration model takes a discriminative ap-
proach; the classifier is presented with a word pair
(ws, wt) , where ws is a named entity and it is
asked to determine whether wt is a transliteration
</bodyText>
<figureCaption confidence="0.978393">
Figure 2: Features extraction process
</figureCaption>
<bodyText confidence="0.999970882352941">
of the NE in the target language. We use a linear
classifier trained with a regularized perceptron up-
date rule (Grove and Roth, 2001) as implemented
in SNoW, (Roth, 1998). The classifier’s confi-
dence score is used for ranking of positively tagged
transliteration candidates. Our initial feature extrac-
tion scheme follows the one presented in (Klemen-
tiev and Roth, 2006), in which the feature space con-
sists of n-gram pairs from the two languages. Given
a sample, each word is decomposed into a set of sub-
strings of up to a given length (including the empty
string). Features are generated by pairing substrings
from the two sets whose relative positions in the
original words differ by one or less places; first each
word is decomposed into a set of substrings then
substrings from the two sets are coupled to complete
the pair representation. Figure 2 depicts this process.
</bodyText>
<subsectionHeader confidence="0.996966">
2.2 Guiding the Sampling Process with SSF
</subsectionHeader>
<bodyText confidence="0.9999775">
The initial step in our framework is to generate a
training set of transliteration pairs; this is done by
pairing highly informative source language candi-
date NEs with target language counterparts. We de-
veloped a criterion for adding new samples, Suffi-
ciently Spanning Features (SSF), which quantifies
the sampled set ability to span the feature space.
This is done by evaluating the L-1 distance be-
tween the frequency distributions of source language
word fragments in the current sampled set and in
a comprehensive set of source language NEs, serv-
ing as reference. We argue that since the features
used for learning are n-gram features, once these
two distributions are close enough, our examples
space provides a good and concise characterization
of all named entities we will ever need to con-
sider. A special care should be given to choos-
ing an appropriate reference; as a general guide-
line the reference set should be representative of
the testing data. We collected a set R, consisting
</bodyText>
<page confidence="0.991956">
54
</page>
<bodyText confidence="0.99467125">
of 50,000 NE by crawling through Wikipedia’s arti-
cles and using an English NER system available at
- http://L2R.cs.uiuc.edu/ cogcomp. The frequency
distribution was generated over all character level
bi-grams appearing in the text, as bi-grams best cor-
relate with the way features are extracted. Given a
reference text R, the n-grams distribution of R can be
defined as follows -DR(ngi) =]nyyg�i ,where ng
</bodyText>
<subsectionHeader confidence="0.67836">
Ej Nngj
</subsectionHeader>
<bodyText confidence="0.969246285714286">
is an n-gram in R. Given a sample set S, we measure
the L1 distance between the distributions:
distance (R,S) = EngER  |DR(ng)−DS(ng)  |Sam-
ples decreasing the distance between the distribu-
tions were added to the training data. Given a set
C of candidates for annotation, a sample ws E C
was added to the training set, if -
</bodyText>
<equation confidence="0.949135">
ws = argminwECdistance(R, DS U {ws}).
</equation>
<bodyText confidence="0.999396">
A sample set is said to have SSF, if the distance re-
mains constant as more samples are added.
</bodyText>
<subsectionHeader confidence="0.663478">
2.2.1 Transliteration Oracle Implementation
</subsectionHeader>
<bodyText confidence="0.999979666666667">
The transliteration oracle is essentially a mapping
between the named entities, i.e. given an NE in the
source language it provides the matching NE in the
target language. An automatic oracle was imple-
mented by crawling through Wikipedia topic aligned
document pairs. Given a pair of topic aligned doc-
uments in the two languages, the topic can be iden-
tified either by identifying the top ranking terms or
by simply identifying the title of the documents. By
choosing documents in Wikipedia‘s biography cate-
gory we ensured that the topic of the documents is
person NE.
</bodyText>
<subsectionHeader confidence="0.999384">
2.3 Training the transliteration model
</subsectionHeader>
<bodyText confidence="0.9999805">
The feature extraction scheme we use generates fea-
tures by coupling substrings from the two terms.
Ideally, given a positive sample, it is desirable that
paired substrings would encode phonetically simi-
lar or a distinctive context in which the two scripts
correlate. Given enough positive samples, such fea-
tures will appear with distinctive frequency. Tak-
ing this idea further, these features were recognized
by measuring the co-occurrence frequency of sub-
strings of up to two characters in both languages.
Each feature f=(fs, ft) composed of two substrings
taken from English and Hebrew words was associ-
</bodyText>
<equation confidence="0.827936">
ated with weight. W(f) = ](fs,ft)x ](fs,ft) where
](fs) 0(ft)
</equation>
<table confidence="0.999355">
Data Set Method Rus Heb
1 SSF 0.68 NA
1 KR’06 0.63 NA
2 SSF 0.71 0.52
</table>
<tableCaption confidence="0.755115">
Table 1: Results summary. The numbers are the pro-
portion of NE recognized in the target language. Lines 1
</tableCaption>
<figureCaption confidence="0.622145333333333">
and 2 compare the results of SSF directed approach with
the baseline system on the first dataset. Line 3 summa-
rizes the results on the second dataset.
</figureCaption>
<bodyText confidence="0.999620133333334">
�(fs, ft) is the number of occurrences of that feature
in the positive sample set, and #(fL) is the number of
occurrences of an individual substring, in any of the
features extracted from positive samples in the train-
ing set. The result of this process is a weight table,
in which, as we empirically tested, the highest rank-
ing weights were assigned to features that preserve
the phonetic correlation between the two languages.
To improve the classifier’s learning rate, the learn-
ing process is focused around these features. Given
a sample, the learner is presented with a real-valued
feature vector instead of a binary vector, in which
each value indicates both that the feature is active
and its activation strength - i.e. the weight assigned
to it.
</bodyText>
<sectionHeader confidence="0.997179" genericHeader="evaluation">
3 Evaluation
</sectionHeader>
<bodyText confidence="0.999616263157895">
We evaluated our approach in two settings; first, we
compared our system to a baseline system described
in (Klementiev and Roth, 2006). Given a bilingual
corpus with the English NE annotated, the system
had to discover the NE in target language text. We
used the English-Russian news corpus used in the
baseline system. NEs were grouped into equiva-
lence classes, each containing different variations of
the same NE. We randomly sampled 500 documents
from the corpus. Transliteration pairs were mapped
into 97 equivalence classes, identified by an expert.
In a second experiment, different learning parame-
ters such as selective sampling efficiency and feature
weights were checked. 300 English-Russian and
English-Hebrew NE pairs were used; negative sam-
ples were generated by coupling every English NE
with all other target language NEs. Table 1 presents
the key results of these experiments and compared
with the baseline system.
</bodyText>
<page confidence="0.994852">
55
</page>
<table confidence="0.999942">
Extraction Number Recall Recall
method of Top one Top two
samples
Directed 200 0.68 0.74
Random 200 0.57 0.65
Random 400 0.63 0.71
</table>
<tableCaption confidence="0.904278857142857">
Table 2: Comparison of correctly identified English-
Russian transliteration pairs in news corpus. The model
trained using selective sampling outperforms models
trained using random sampling, even when trained with
twice the data. The top one and top two results
columns describe the proportion of correctly identified
pairs ranked in the first and top two places, respectively.
</tableCaption>
<table confidence="0.999422833333333">
Learning Russian Hebrew
Train- Feature Top Top Top Top
ing weights one five one five
+ + 0.71 0.89 0.52 0.88
- + 0.63 0.82 0.33 0.59
+ - 0.64 0.79 0.37 0.68
</table>
<tableCaption confidence="0.932261857142857">
Table 3: The proportion of correctly identified transliter-
ation pairs with/out using weights and training. The top
one and top five results columns describe the proportion
of correctly identified pairs ranked in the first place and
in any of the top five places, respectively. The results
demonstrate that using feature weights improves perfor-
mance for both target languages.
</tableCaption>
<subsectionHeader confidence="0.997092">
3.1 Using SSF directed sampling
</subsectionHeader>
<bodyText confidence="0.9999902">
Table 2 describes the effect of directed sampling
in the English-Russian news corpora NE discovery
task. Results show that models trained using selec-
tive sampling can outperform models trained with
more than twice the amount of data.
</bodyText>
<subsectionHeader confidence="0.999401">
3.2 Training using feature weights
</subsectionHeader>
<bodyText confidence="0.999981181818182">
Table 3 describes the effect training the model with
weights.The training set consisted of 150 samples
extracted using SSF directed sampling. Three varia-
tions were tested - training without feature weights,
using the feature weights as the initial network
weights without training and training with weights.
The results clearly show that using weights for train-
ing improve the classifier’s performance for both
Russian and Hebrew. It can also be observed that
in many cases the correct pair was ranked in any of
the top five places.
</bodyText>
<sectionHeader confidence="0.996608" genericHeader="conclusions">
4 Conclusions and future work
</sectionHeader>
<bodyText confidence="0.9992345">
In this paper we presented a new approach for con-
structing a transliteration model automatically and
efficiently by selectively extracting transliteration
samples covering relevant parts of the feature space
and focusing the learning process on these features.
We show that our approach can outperform sys-
tems requiring supervision, manual intervention and
a considerable amount of data. We propose a new
measure for selective sample selection which can be
used independently. We currently investigate apply-
ing it in other domains with potentially larger feature
space than used in this work. Another aspect inves-
tigated is using our selective sampling for adapting
the learning process for data originating from dif-
ferent sources; using the a reference set representa-
tive of the testing data, training samples, originating
from a different source , can be biased towards the
testing data.
</bodyText>
<sectionHeader confidence="0.999442" genericHeader="acknowledgments">
5 Acknowledgments
</sectionHeader>
<bodyText confidence="0.999296333333333">
Partly supported by NSF grant ITR IIS-0428472 and
DARPA funding under the Bootstrap Learning Pro-
gram.
</bodyText>
<sectionHeader confidence="0.999119" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998468210526316">
Y. Freund and R. E. Schapire. 1998. Large margin clas-
sification using the perceptron algorithm. In COLT.
A. Grove and D. Roth. 2001. Linear concepts and hidden
variables. ML, 42.
A. Klementiev and D. Roth. 2006. Weakly supervised
named entity transliteration and discovery from multi-
lingual comparable corpora. In ACL.
K. Knight and J. Graehl. 1997. Machine transliteration.
In EACL.
D. K. McCallum and K. Nigam. 1998. Employing EM
in pool-based active learning for text classification. In
ICML.
D. Roth. 1998. Learning to resolve natural language am-
biguities: A unified approach. In AAAI.
H. S. Seung, M. Opper, and H. Sompolinsky. 1992.
Query by committee. In COLT.
T. Tao, S. Yoon, A. Fister, R. Sproat, and C. Zhai. 2006.
Unsupervised named entity transliteration using tem-
poral and phonetic correlation. In EMNLP.
</reference>
<page confidence="0.998415">
56
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.677607">
<title confidence="0.999963">Active Sample Selection for Named Entity Transliteration</title>
<author confidence="0.999988">Dan Goldwasser Dan Roth</author>
<affiliation confidence="0.9999595">Department of Computer Science University of Illinois</affiliation>
<address confidence="0.99926">Urbana, IL 61801</address>
<abstract confidence="0.9798413125">This paper introduces a new method for identifying named-entity (NE) transliterations within bilingual corpora. Current state-of-theart approaches usually require annotated data and relevant linguistic knowledge which may not be available for all languages. We show how to effectively train an accurate transliteration classifier using very little data, obtained automatically. To perform this task, we introduce a new active sampling paradigm for guiding and adapting the sample selection process. We also investigate how to improve the classifier by identifying repeated patterns in the training data. We evaluated our approach using English, Russian and Hebrew corpora.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Y Freund</author>
<author>R E Schapire</author>
</authors>
<title>Large margin classification using the perceptron algorithm.</title>
<date>1998</date>
<booktitle>In COLT.</booktitle>
<contexts>
<context position="3926" citStr="Freund and Schapire, 1998" startWordPosition="590" endWordPosition="593">criterion (SSF) introduced in section 2.2, to identify informative samples in the source language.An oracle capable of pairing a NE in the source language with its counterpart in the target language is then used. Negative training samples are generated by reshuffling the terms in these pairs. Once the training data has been collected, the data is analyzed to identify repeating patterns in the data which are used to focus the training process by assigning weights to features corresponding to the observed patterns. Finally, a linear model is trained using a variation of the averaged perceptron (Freund and Schapire, 1998) algorithm. The remainder of this section provides details about these stages; the basic formulation of the transliteration model and the feature extraction scheme is described in section 2.1, in section 2.2 the selective sampling process is described and finally section 2.3 explains how learning is focused by using feature weights. Input: Bilingual, comparable corpus (S, T), set of named entities NES from S, Reference Corpus RS, Transliteration Oracle O, Training Corpora D=DS,DT Output: Transliteration model M 1 Guiding the Sampling Process 2 repeat 3 select a set C C NES randomly 4 ws = argm</context>
</contexts>
<marker>Freund, Schapire, 1998</marker>
<rawString>Y. Freund and R. E. Schapire. 1998. Large margin classification using the perceptron algorithm. In COLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Grove</author>
<author>D Roth</author>
</authors>
<title>Linear concepts and hidden variables.</title>
<date>2001</date>
<journal>ML,</journal>
<volume>42</volume>
<contexts>
<context position="5226" citStr="Grove and Roth, 2001" startWordPosition="808" endWordPosition="811">}) &gt; distance(R,DS) ; 7 Determining Features Activation Strength 8 Define W:f → R s.t. foreach feature f ={fs, ft} 9 W = 0(fs,ft) X 0(fs,ft) Ws) Wt) 10 Use D to train M; Algorithm 1: Constructing a transliteration model. 2.1 Transliteration Model Our transliteration model takes a discriminative approach; the classifier is presented with a word pair (ws, wt) , where ws is a named entity and it is asked to determine whether wt is a transliteration Figure 2: Features extraction process of the NE in the target language. We use a linear classifier trained with a regularized perceptron update rule (Grove and Roth, 2001) as implemented in SNoW, (Roth, 1998). The classifier’s confidence score is used for ranking of positively tagged transliteration candidates. Our initial feature extraction scheme follows the one presented in (Klementiev and Roth, 2006), in which the feature space consists of n-gram pairs from the two languages. Given a sample, each word is decomposed into a set of substrings of up to a given length (including the empty string). Features are generated by pairing substrings from the two sets whose relative positions in the original words differ by one or less places; first each word is decompos</context>
</contexts>
<marker>Grove, Roth, 2001</marker>
<rawString>A. Grove and D. Roth. 2001. Linear concepts and hidden variables. ML, 42.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Klementiev</author>
<author>D Roth</author>
</authors>
<title>Weakly supervised named entity transliteration and discovery from multilingual comparable corpora.</title>
<date>2006</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="2201" citStr="Klementiev and Roth, 2006" startWordPosition="324" endWordPosition="327">ty to label the data upon request. We introduce a new active sampling paradigm that 53 Figure 1: NE in English, Russian and Hebrew. aims to guide the learner toward informative samples, allowing learning from a small number of representative examples. After the data is obtained it is analyzed to identify repeating patterns which can be used to focus the training process of the model. Previous works usually take a generative approach, (Knight and Graehl, 1997). Other approaches exploit similarities in aligned bilingual corpora; for example, (Tao et al., 2006) combine two unsupervised methods. (Klementiev and Roth, 2006) bootstrap with a classifier used interchangeably with an unsupervised temporal alignment method. Although these approaches alleviate the problem of obtaining annotated data, other resources are still required, such as a large aligned bilingual corpus. The idea of selectively sampling training samples has been wildly discussed in machine learning theory (Seung et al., 1992) and has been applied successfully to several NLP applications (McCallum and Nigam, 1998). Unlike other approaches,our approach is based on minimizing the distance between the feature distribution of a comprehensive referenc</context>
<context position="5462" citStr="Klementiev and Roth, 2006" startWordPosition="843" endWordPosition="847">iteration Model Our transliteration model takes a discriminative approach; the classifier is presented with a word pair (ws, wt) , where ws is a named entity and it is asked to determine whether wt is a transliteration Figure 2: Features extraction process of the NE in the target language. We use a linear classifier trained with a regularized perceptron update rule (Grove and Roth, 2001) as implemented in SNoW, (Roth, 1998). The classifier’s confidence score is used for ranking of positively tagged transliteration candidates. Our initial feature extraction scheme follows the one presented in (Klementiev and Roth, 2006), in which the feature space consists of n-gram pairs from the two languages. Given a sample, each word is decomposed into a set of substrings of up to a given length (including the empty string). Features are generated by pairing substrings from the two sets whose relative positions in the original words differ by one or less places; first each word is decomposed into a set of substrings then substrings from the two sets are coupled to complete the pair representation. Figure 2 depicts this process. 2.2 Guiding the Sampling Process with SSF The initial step in our framework is to generate a t</context>
<context position="10416" citStr="Klementiev and Roth, 2006" startWordPosition="1677" endWordPosition="1680"> which, as we empirically tested, the highest ranking weights were assigned to features that preserve the phonetic correlation between the two languages. To improve the classifier’s learning rate, the learning process is focused around these features. Given a sample, the learner is presented with a real-valued feature vector instead of a binary vector, in which each value indicates both that the feature is active and its activation strength - i.e. the weight assigned to it. 3 Evaluation We evaluated our approach in two settings; first, we compared our system to a baseline system described in (Klementiev and Roth, 2006). Given a bilingual corpus with the English NE annotated, the system had to discover the NE in target language text. We used the English-Russian news corpus used in the baseline system. NEs were grouped into equivalence classes, each containing different variations of the same NE. We randomly sampled 500 documents from the corpus. Transliteration pairs were mapped into 97 equivalence classes, identified by an expert. In a second experiment, different learning parameters such as selective sampling efficiency and feature weights were checked. 300 English-Russian and English-Hebrew NE pairs were </context>
</contexts>
<marker>Klementiev, Roth, 2006</marker>
<rawString>A. Klementiev and D. Roth. 2006. Weakly supervised named entity transliteration and discovery from multilingual comparable corpora. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Knight</author>
<author>J Graehl</author>
</authors>
<title>Machine transliteration.</title>
<date>1997</date>
<booktitle>In EACL.</booktitle>
<contexts>
<context position="2038" citStr="Knight and Graehl, 1997" startWordPosition="300" endWordPosition="303">ine translation and information retrieval, which require identifying out-of-vocabulary words. In our settings, we have access to source language NE and the ability to label the data upon request. We introduce a new active sampling paradigm that 53 Figure 1: NE in English, Russian and Hebrew. aims to guide the learner toward informative samples, allowing learning from a small number of representative examples. After the data is obtained it is analyzed to identify repeating patterns which can be used to focus the training process of the model. Previous works usually take a generative approach, (Knight and Graehl, 1997). Other approaches exploit similarities in aligned bilingual corpora; for example, (Tao et al., 2006) combine two unsupervised methods. (Klementiev and Roth, 2006) bootstrap with a classifier used interchangeably with an unsupervised temporal alignment method. Although these approaches alleviate the problem of obtaining annotated data, other resources are still required, such as a large aligned bilingual corpus. The idea of selectively sampling training samples has been wildly discussed in machine learning theory (Seung et al., 1992) and has been applied successfully to several NLP application</context>
</contexts>
<marker>Knight, Graehl, 1997</marker>
<rawString>K. Knight and J. Graehl. 1997. Machine transliteration. In EACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D K McCallum</author>
<author>K Nigam</author>
</authors>
<title>Employing EM in pool-based active learning for text classification.</title>
<date>1998</date>
<booktitle>In ICML.</booktitle>
<contexts>
<context position="2666" citStr="McCallum and Nigam, 1998" startWordPosition="394" endWordPosition="397">ther approaches exploit similarities in aligned bilingual corpora; for example, (Tao et al., 2006) combine two unsupervised methods. (Klementiev and Roth, 2006) bootstrap with a classifier used interchangeably with an unsupervised temporal alignment method. Although these approaches alleviate the problem of obtaining annotated data, other resources are still required, such as a large aligned bilingual corpus. The idea of selectively sampling training samples has been wildly discussed in machine learning theory (Seung et al., 1992) and has been applied successfully to several NLP applications (McCallum and Nigam, 1998). Unlike other approaches,our approach is based on minimizing the distance between the feature distribution of a comprehensive reference set and the sampled set. 2 Training a Transliteration Model Our framework works in several stages, as summarized in Algorithm 1. First, a training set consisting Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pages 53–56, Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics of NE transliteration pairs (ws, wt) is automatically generated using an active sample selection scheme. The sample selection process is guided by</context>
</contexts>
<marker>McCallum, Nigam, 1998</marker>
<rawString>D. K. McCallum and K. Nigam. 1998. Employing EM in pool-based active learning for text classification. In ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Roth</author>
</authors>
<title>Learning to resolve natural language ambiguities: A unified approach. In</title>
<date>1998</date>
<booktitle>In COLT.</booktitle>
<contexts>
<context position="5263" citStr="Roth, 1998" startWordPosition="816" endWordPosition="817">tivation Strength 8 Define W:f → R s.t. foreach feature f ={fs, ft} 9 W = 0(fs,ft) X 0(fs,ft) Ws) Wt) 10 Use D to train M; Algorithm 1: Constructing a transliteration model. 2.1 Transliteration Model Our transliteration model takes a discriminative approach; the classifier is presented with a word pair (ws, wt) , where ws is a named entity and it is asked to determine whether wt is a transliteration Figure 2: Features extraction process of the NE in the target language. We use a linear classifier trained with a regularized perceptron update rule (Grove and Roth, 2001) as implemented in SNoW, (Roth, 1998). The classifier’s confidence score is used for ranking of positively tagged transliteration candidates. Our initial feature extraction scheme follows the one presented in (Klementiev and Roth, 2006), in which the feature space consists of n-gram pairs from the two languages. Given a sample, each word is decomposed into a set of substrings of up to a given length (including the empty string). Features are generated by pairing substrings from the two sets whose relative positions in the original words differ by one or less places; first each word is decomposed into a set of substrings then subs</context>
</contexts>
<marker>Roth, 1998</marker>
<rawString>D. Roth. 1998. Learning to resolve natural language ambiguities: A unified approach. In AAAI. H. S. Seung, M. Opper, and H. Sompolinsky. 1992. Query by committee. In COLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Tao</author>
<author>S Yoon</author>
<author>A Fister</author>
<author>R Sproat</author>
<author>C Zhai</author>
</authors>
<title>Unsupervised named entity transliteration using temporal and phonetic correlation.</title>
<date>2006</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="2139" citStr="Tao et al., 2006" startWordPosition="316" endWordPosition="319">s, we have access to source language NE and the ability to label the data upon request. We introduce a new active sampling paradigm that 53 Figure 1: NE in English, Russian and Hebrew. aims to guide the learner toward informative samples, allowing learning from a small number of representative examples. After the data is obtained it is analyzed to identify repeating patterns which can be used to focus the training process of the model. Previous works usually take a generative approach, (Knight and Graehl, 1997). Other approaches exploit similarities in aligned bilingual corpora; for example, (Tao et al., 2006) combine two unsupervised methods. (Klementiev and Roth, 2006) bootstrap with a classifier used interchangeably with an unsupervised temporal alignment method. Although these approaches alleviate the problem of obtaining annotated data, other resources are still required, such as a large aligned bilingual corpus. The idea of selectively sampling training samples has been wildly discussed in machine learning theory (Seung et al., 1992) and has been applied successfully to several NLP applications (McCallum and Nigam, 1998). Unlike other approaches,our approach is based on minimizing the distanc</context>
</contexts>
<marker>Tao, Yoon, Fister, Sproat, Zhai, 2006</marker>
<rawString>T. Tao, S. Yoon, A. Fister, R. Sproat, and C. Zhai. 2006. Unsupervised named entity transliteration using temporal and phonetic correlation. In EMNLP.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>