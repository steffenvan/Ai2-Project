<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.012825">
<title confidence="0.995289">
WSD-games: a Game-Theoretic Algorithm for Unsupervised Word Sense
Disambiguation
</title>
<author confidence="0.996789">
Rocco Tripodi Marcello Pelillo
</author>
<affiliation confidence="0.986327">
Ca’ Foscari University of Venice
</affiliation>
<address confidence="0.944001">
Via Torino 155
30172 Venezia, Italy
</address>
<email confidence="0.998641">
{rocco.tripodi, pelillo}@unive.it
</email>
<sectionHeader confidence="0.995844" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.995400533333333">
In this paper we present an unsupervised ap-
proach to word sense disambiguation based on
evolutionary game theory. In our algorithm
each word to be disambiguated is represented
as a node on a graph and each sense as a class.
The algorithm performs a consistent class as-
signment of senses according to the similarity
information of each word with the others, so
that similar words are constrained to similar
classes. The dynamics of the system are for-
mulated in terms of a non-cooperative multi-
player game, where the players are the data
points to decide their class memberships and
equilibria correspond to consistent labeling of
the data.
</bodyText>
<sectionHeader confidence="0.99899" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9999071">
Word sense disambiguation (WSD) is the task to
identify the intended sense of a word in a compu-
tational manner based on the context in which it
appears (Navigli, 2009). It has been studied since
the beginning of NLP (Weaver, 1955) and also to-
day it is a central topic of this discipline. Many
algorithms have been proposed during the years,
based on supervised (Zhong and Ng, 2010; Tratz
et al., 2007), semi-supervised (Pham et al., 2005)
and unsupervised (Mihalcea, 2005; McCarthy et al.,
2007) learning models. Nowadays, even if super-
vised methods perform better in general domains,
unsupervised and semi-supervised models are gain-
ing attention from the research community with per-
formances close to the state of the art (Ponzetto and
Navigli, 2010). In particular Knowledge-based and
graph based algorithms are emerging as interesting
ways to face the problem (Agirre et al., 2009; Sinha
and Mihalcea, 2007). The peculiarities of those al-
gorithms are that they do not require any corpus evi-
dence and use only the structural properties of a lex-
ical database to perform the disambiguation task.
An unsupervised algorithm which has been im-
plemented in different ways by the community (Mi-
halcea et al., 2004; Haveliwala, 2002; Agirre et al.,
2014; De Cao et al., 2010) is the PageRank (Page
et al., 1999). This algorithm is similar in spirit to
ours but we instead of using the graph to compute
the most important nodes (senses) in it, we use the
network to model the geometry of the data and the
interactions among the data points. In our system
the nodes of the graph are interpreted as players, in
the game theoretic sense (see Section 2), which play
a game in order to maximize their utility. The con-
cept of utility has been used in different ways in the
game theory (GT) literature and in general it refers
to the satisfaction that a player derives from the out-
come of a game (Szab´o and Fath, 2007). From our
point of view increasing the utility of a word means
increasing the textual coherence, in a distributional
semantics perspective (Firth, 1957). In fact, in our
framework a word always tries to chose a sense close
to the senses which the other words in the text are
likely to choose.
The starting point of our research is based on the
assumption that the meaning of a sentence emerges
from the interaction of the components which are in-
volved in it. In our study we tried to model this inter-
action and to develop a system in which it is possible
to map lexical items onto concepts. For this reason
</bodyText>
<page confidence="0.988912">
329
</page>
<bodyText confidence="0.930715470588235">
Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 329–334,
Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics
we decided to use a powerful tool, derived from Evo-
lutionary Game Theory (EGT): the non-cooperative
games (see Section 2). EGT and GT have been used
in different ways to study the language use (Pietari-
nen, 2007; Skyrms, 2010) and evolution (Nowak et
al., 2001) but as far as we know, our is the first at-
tempt to use it in a specific NLP task. This choice
is motivated by the fact that GT models are able
to perform a consistent labeling of the data (Hum-
mel and Zucker, 1983; Pelillo, 1997), taking into ac-
count the contextual information. These features are
of great importance for an unsupervised algorithm
which tries to perform a WSD task, because them
can be obtained without any supervision and help
the system to adapt to different contextual domains.
</bodyText>
<sectionHeader confidence="0.957172" genericHeader="method">
2 Game Theory
</sectionHeader>
<bodyText confidence="0.999865071428571">
In this section we briefly introduce some concepts
of GT and EGT, for detailed analysis of these top-
ics we refer to (Weibull, 1997; Leyton-Brown and
Shoham, 2008; Sandholm, 2010).
GT provides predictive power in interactive deci-
sion situations. It has been introduced by Von Neu-
mann and Morgenstern (1944) and in its normal
form representation (which is the one we will use
in our algorithm) it consists in: a finite set of play-
ers I = (1, .., n), a set of pure strategies for each
player Si = (s1, ..., sn) and an utility function ui :
S1x...xSn —* R which associates strategies to pay-
offs. The utility function depends on the combina-
tion of two strategies played together, not just on the
strategy of a single player. An important assumption
in GT is that the players are rational and try to maxi-
mize the value of ui; furthermore in non-cooperative
games the players choose their strategies indepen-
dently. A strategy sz is said to be dominant if and
only if ui(sz, s_i) &gt; ui(si, s_i),bs_i E S_i. As
an example we can consider the famous Prisoner’s
Dilemma (in Table 1) where the strategy confess is
a dominant strategy for both players and this strategy
combination is the Nash equilibrium of the game.
Nash equilibria are those strategy profiles which are
best response to the strategy of the co-player and no
player has the incentive to unilaterally deviate from
his strategy, because there is no way to do better.
</bodyText>
<figure confidence="0.757764">
1 \ 2 confess don’t confess
-5,-5 0,-6
-6,0 -1,-1
</figure>
<tableCaption confidence="0.988279">
Table 1: The Prisoner’s Dilemma.
</tableCaption>
<subsectionHeader confidence="0.957681">
2.1 Evolutionary Game Theory
</subsectionHeader>
<bodyText confidence="0.999967958333333">
EGT has been introduce by Smith and Price (1973)
overcoming some limitations of traditional GT such
as the hyper-rationality imposed on the players, in
fact in real life situations the players choose a strat-
egy according to heuristics or social norms (Szab´o
and Fath, 2007). Another important aspect of EGT
is the introduction of an inductive learning process,
in which the agents play the game repeatedly with
their neighborhood, updating their believes on the
state of the game and choosing their strategy accord-
ingly. The strategy space of each player is defined
as a probability distribution over its pure strategies.
It is represented as a vector xi = (xi1, . . . , xim)
where m is the number of pure strategies and each
component xih denotes the probability that player i
choose its hth pure strategy. The strategy space lies
on the m-dimensional standard simplex Am where:
Emh=1 xih = 1 and xih &gt; 0 for all h. The ex-
pected payoff of a pure strategy eh in a single game
is u(eh, x) = eh · Ax where A is the m x m payoff
matrix. The average payoff of all the player strate-
gies is u(x, x) = EhES xhu(eh, x). In order to find
the Nash equilibria of the game it is used the repli-
cator dynamic equation (Taylor and Jonker, 1978)
</bodyText>
<equation confidence="0.992658">
x˙ = [u(eh, x) − u(x, x)] · xh bh E S (1)
</equation>
<bodyText confidence="0.98253425">
which allows better than average strategies (best
replies) to grow. As in (Erdem and Pelillo, 2012)
we used the discrete time version of the replicator
dynamic equation:
</bodyText>
<equation confidence="0.9985005">
xh(t + 1) = xh(t)u(eh,x)
u(x, x) bh E S (2)
</equation>
<bodyText confidence="0.999935333333333">
where at each time step t the players update their
strategies until the system converges and the Nash
equilibria are found.
</bodyText>
<sectionHeader confidence="0.997493" genericHeader="method">
3 WSD Games
</sectionHeader>
<bodyText confidence="0.999294">
In this section we will show how we created the data
necessary for our framework and how the games are
played.
</bodyText>
<figure confidence="0.543843">
confess
don’t confess
</figure>
<page confidence="0.917872">
330
</page>
<subsectionHeader confidence="0.994761">
3.1 Graph Construction
</subsectionHeader>
<bodyText confidence="0.9978753125">
We model the geometry of the data as a graph,
with nodes corresponding to the words to be disam-
biguated, denoted by I = {ijjN j=1, where ij corre-
sponds to the j-th word and N is the number of tar-
get words in a specific text. From I we construct a
N x N similarity matrix W where each element wij
is the similarity value assigned for the words i and
j. W can be exploited as an useful tool for graph-
based algorithms since it is treatable as weighted ad-
jacency matrix of a weighted graph.
A crucial factor for the graph construction is the
choice of the similarity measure, sim(·, ·) —* R
to weights the edges of the graph. For our ex-
periments we used similarity measures which com-
pute the strength of co-occurrence between any two
words ii and ij
</bodyText>
<equation confidence="0.980376">
wij = sim(ii, ij) Vi, j E I : i =� j (3)
</equation>
<bodyText confidence="0.999934666666667">
Specifically we used the modified Dice coheffi-
cient (mDice) (Dice, 1945), the pointwise mu-
tual information (PMI) (Church and Hanks, 1990)
and the log likelihood ratio (D2) (Dunning, 1993)
These measure have been calculate using the Google
Web1T corpus (Brants and Franz, 2006), a large col-
lection of n-grams (with a window of max 5 words)
occurring in one terabyte of Web documents as col-
lected by Google.
At this point we have the similarity graph W,
we recall that we will use this matrix in order to
allow the words to play the games only with sim-
ilar words. The higher the similarity among two
words, the higher the reciprocal influence and the
possibility that they belong to a similar class. For
this reason, at first we smooth the data in W and
then choose only the most significant js for each
j E W. The first point is solved using a gaussian
</bodyText>
<equation confidence="0.96674">
w.� = ex 2a&apos;
kernel on W
Z p (— 2 ), where Q is the
</equation>
<bodyText confidence="0.997107">
kernel width parameter; the second point is solved
applying a k − nearest neighbor algorithm to W,
which allows us to remove the edges which are less
significant for each i E I. In our experiments we
used Q = 0.5 and k = 25. Moreover, this opera-
tion reduces the computational cost of the algorithm,
which will focus only on relevant similarities.
</bodyText>
<subsectionHeader confidence="0.9994">
3.2 The Strategy Space
</subsectionHeader>
<bodyText confidence="0.998700875">
In order to create the strategy space of the game,
we first use WordNet (Mallery, 1995) to collect the
sense inventories Mi = 1, ... , m of each word,
where m is the number of synsets associated to word
i. Then we set all the sense inventories and obtain
the list of all possible senses, C = 1, ... , c.
We can now define the strategy space S of the
game in matrix form as:
</bodyText>
<equation confidence="0.995105666666667">
si1 si2 ··· sic
... ... · · · ...
sn1 sn2 ··· snc
</equation>
<bodyText confidence="0.948657222222222">
where each row corresponds to the strategy space of
a player and each column corresponds to a sense.
Formally it is a c-dimensional space Ac and each
mixed strategy profile lives in the mixed strategy
space of the game, given by the Cartesian product
Θ = xi∈IAi.
At this point the strategy space can be initialized
with the following formula in order to follow the
constraints described in Section 2.1
</bodyText>
<equation confidence="0.838717666666667">
�Mi�−1, if sense j is in Mi.
sij = (4)
SI0, otherwise.
</equation>
<bodyText confidence="0.815751">
for all i E I and j E S.
</bodyText>
<subsectionHeader confidence="0.988531">
3.3 The Payoff Matrix
</subsectionHeader>
<bodyText confidence="0.999718375">
We encoded the payoff matrix of a WSD game as
a sense similarity matrix among all the senses in
the strategy spaces of the game. In this way the
higher the similarity among two sense candidates,
the higher the incentive for a player to chose that
sense, and play the strategy associated to it.
The c x c sense similarity matrix Z is defined as
follows:
</bodyText>
<equation confidence="0.941936">
zij = ssim(si, sj) Vi, j E C : i =� j (5)
</equation>
<bodyText confidence="0.9998385">
In our experiments we used the GlossVector mea-
sure (Patwardhan and Pedersen, 2006) in order to
compute the semantic relatedness ssim(·, ·). This
measure calculates the cosine similarity among two
second order context vectors. Each vector is ob-
tained from a WordNet super-glosse, which is the
gloss of a synset plus the glosses of the synsets re-
lated to it.
</bodyText>
<page confidence="0.996681">
331
</page>
<table confidence="0.9990565">
run sim P R F1 math med. gen.
1 PMI 57.4 48.9 52.8 47.4 56.3 53.5
2 mDice 58.8 50.0 54.1 48.5 58.4 53.5
3 D2 53.5 45.4 49.1 43.4 54.4 46.7
</table>
<tableCaption confidence="0.993925333333333">
Table 2: The results of the WSD-games team at SemEval-
2015 task 13. Precision, Recall and F1 in all domains and
F1 in specific domains.
</tableCaption>
<bodyText confidence="0.999898555555556">
From Z we can obtain the partial semantic simi-
larity matrix for each pair of player, Zij = m × n,
where m and n are the senses of i and j in Z.
In a previous work (Tripodi et al., 2015) we did
not use this information, instead we used labeled
data points to propagate the class membership in-
formation over the graph. In this new version the
use of the semantic information made the algorithm
completely unsupervised.
</bodyText>
<subsectionHeader confidence="0.946164">
3.4 System Dynamics
</subsectionHeader>
<bodyText confidence="0.999989625">
Now that we have the topology of the data W, the
strategy space of the game S and the payoff matrix
Z we can compute the Nash equilibria of the game
according to equation (2). So in each iteration of
the system each player gain its payoffs according to
equation (6) which allows each payoff to be propor-
tional to the similarity (wij) and to the affinity that
player j has to the hs strategy of player i.
</bodyText>
<equation confidence="0.9884195">
�ui(eh, x) = ((wijZij)xj)h (6)
j∈Ni
</equation>
<bodyText confidence="0.999224">
When the system converges each player chooses the
strategy with the highest value.
</bodyText>
<sectionHeader confidence="0.999521" genericHeader="evaluation">
4 Results and Analysis
</sectionHeader>
<bodyText confidence="0.99998772972973">
The dataset proposed by the organizers of SemEval-
2015 Task 13 (Moro and Navigli, 2015) consists of
five texts from three different domains: math and
computer, biomedical and general. The english cor-
pus is composed of 1426 instances to disambiguate
and 1262 of them have been used in the evalua-
tion. For our experiments we used only the instances
whose lemma has an entry in WordNet 3.0 without
looking up multi-words or trying to link the enti-
ties to other sources such as Wikipedia or BabelNet
(Navigli and Ponzetto, 2012)
We submitted three runs for our system with 1227
single words disambiguated for each run. The only
difference for each run is the similarity measure that
we used to construct the graph W. For run-1 we
used the PMI measure, for run-2 the mDice coef-
ficient and for run-3 the D2. As we expected from
previous experiments on similar datasets, the best
results have been achieved using the mDice coef-
ficient (see Table 2). We obtained low recall values
for all our runs and this because we did not search
multi-words and did not use other sources of infor-
mation for the named entities, in fact the number of
named entities is limited in WordNet.
Looking more closely at the results, we noticed
that we obtained a very low precision (48.5%) in the
math and computer domain and this because even if
the lexical entry of certain instances (eg. in text2:
tab, dialog, script) have an entry in WordNet, their
intended meaning is not present; it can only be ac-
cessible to those systems which use BabelNet to col-
lect the sense inventories. This unexpected problem
affects the performances of the system because even
if those instances will not be considered in the eval-
uation, they have been used by other instances in our
system to play the disambiguation games, compro-
mising the dynamics of the system.
</bodyText>
<sectionHeader confidence="0.989312" genericHeader="conclusions">
5 Conclusions and Future Works
</sectionHeader>
<bodyText confidence="0.999937105263158">
We have presented an unsupervised system for WSD
based on EGT which takes into account contextual
similarity and semantic similarity information in or-
der to perform a consistent labeling of the data. Its
performances are below those of supervised systems
and are comparable with unsupervised and semi-
supervised systems even if on the Semeval-2015
task 13 dataset we did not use other source of infor-
mation except WordNet, did not search multi-words
and did not aspect that the intended meaning of some
instances is not present in WordNet.
As future work we are planning to do a detailed
evaluation of the system in order to find the most
appropriate measures to use and to incorporate in
the framework other sources of information like Ba-
belNet. Furthermore we are also thinking to test
the system as supervised and semi-supervised, im-
plementing a new initialization of the strategy space
and to test new graph construction techniques.
</bodyText>
<page confidence="0.996678">
332
</page>
<sectionHeader confidence="0.929413" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.996952971153846">
Eneko Agirre, Oier Lopez De Lacalle, Aitor Soroa, and
Informatika Fakultatea. 2009. Knowledge-based
WSD and Specific Domains: Performing Better than
Generic Supervised WSD. In IJCAI, pages 1501–
1506.
Eneko Agirre, Oier Lopez de Lacalle, and Aitor Soroa.
2014. Random Walks for Knowledge-Based Word
Sense Disambiguation. Computational Linguistics,
40(1):57–84.
Thorsten Brants and Alex Franz. 2006. {Web 1T 5-gram
Version 1}.
Kenneth Ward Church and Patrick Hanks. 1990. Word
Association Norms, Mutual Information, and Lexicog-
raphy. Computational linguistics, 16(1):22–29.
Diego De Cao, Roberto Basili, Matteo Luciani,
Francesco Mesiano, and Riccardo Rossi. 2010. Ro-
bust and Efficient PageRank for Word Sense Disam-
biguation. In Proceedings of the 2010 Workshop on
Graph-based Methods for Natural Language Process-
ing, pages 24–32.
Lee R. Dice. 1945. Measures of the amount of ecologic
association between species. Ecology, 26(3):297–302.
Ted Dunning. 1993. Accurate Methods for the Statistics
of Surprise and Coincidence. Computational linguis-
tics, 19(1):61–74.
Aykut Erdem and Marcello Pelillo. 2012. Graph Trans-
duction as a Noncooperative Game. Neural Computa-
tion, 24(3):700-723.
John R. Firth. 1957. A Synopsis of Linguistic The-
ory 1930-1955. Studies in linguistic analysis. Oxford:
Blackwell.
Taher H. Haveliwala. 2002. Topic-Sensitive PageRank.
In Proceedings of the 11th international conference on
World Wide Web, pages 517–526.
Robert A. Hummel and Steven W. Zucker. 1983. On the
Foundations of Relaxation Labeling Processes. Pat-
tern Analysis and Machine Intelligence, IEEE Trans-
actions on, (3):267–287.
Kevin Leyton-Brown and Yoav Shoham. 2008. Essen-
tials of Game Theory: A Concise Multidisciplinary
Introduction. Synthesis Lectures on Artificial Intelli-
gence and Machine Learning, 2(1):1–88.
John C. Mallery. 1995. WordNet: a Lexical Database for
English. Communications of the ACM, 38(11):39-41.
Diana McCarthy, Rob Koeling, Julie Weeds, and John
Carroll. 2007. Unsupervised Acquisition of Pre-
dominant Word Senses. Computational Linguistics,
33(4):553–590.
Rada Mihalcea, Paul Tarau, and Elizabeth Figa. 2004.
PageRank on Semantic Networks, with Application to
Word Sense Disambiguation. In Proceedings of the
20th international conference on Computational Lin-
guistics, page 1126.
Rada Mihalcea. 2005. Unsupervised Large-Vocabulary
Word Sense Disambiguation with Graph-Based Algo-
rithms for Sequence Data Labeling. In Proceedings of
the conference on Human Language Technology and
Empirical Methods in Natural Language Processing,
pages 411–418.
Andrea Moro and Roberto Navigli. 2015. SemEval-2015
Task 13: Multilingual All-Words Sense Disambigua-
tion and Entity Linking. In Proceedings of SemEval-
2015.
Roberto Navigli and Simone Paolo Ponzetto. 2012. Ba-
belNet: The Automatic Construction, Evaluation and
Application of a Wide-Coverage Multilingual Seman-
tic Network. Artificial Intelligence, 193:217–250.
Roberto Navigli. 2009. Word Sense Disambiguation: A
Survey. ACM Computing Surveys (CSUR), 41(2):10.
Martin A. Nowak, Natalia L. Komarova, and Partha
Niyogi. 2001. Evolution of Universal Grammar. Sci-
ence, 291(5501):114–118.
Lawrence Page, Sergey Brin, Rajeev Motwani, and Terry
Winograd. 1999. The PageRank Citation Ranking:
Bringing Order to the Web.
Siddharth Patwardhan and Ted Pedersen. 2006. Us-
ing WordNet-Based Context Vectors to Estimate the
Semantic Relatedness of Concepts. In Proceedings
of the EACL 2006 Workshop Making Sense of Sense-
Bringing Computational Linguistics and Psycholin-
guistics Together, volume 1501, pages 1–8.
Marcello Pelillo. 1997. The Dynamics of Nonlinear Re-
laxation Labeling Processes. Journal of Mathematical
Imaging and Vision, 7(4):309–323.
Thanh Phong Pham, Hwee Tou Ng, and Wee Sun
Lee. 2005. Word Sense Disambiguation with Semi-
Supervised Learning. In Proceedings of the National
Conference on Artificial Intelligence, volume 20, page
1093.
Ahti-Veikko Pietarinen. 2007. Game theory and linguis-
tic meaning.
Simone Paolo Ponzetto and Roberto Navigli. 2010.
Knowledge-Rich Word Sense Disambiguation Rival-
ing Supervised Systems. In Proceedings of the 48th
annual meeting of the association for computational
linguistics, pages 1522–1531.
William H. Sandholm. 2010. Population games and evo-
lutionary dynamics.
Ravi Som Sinha and Rada Mihalcea. 2007. Unsuper-
vised Graph-based Word Sense Disambiguation Using
Measures of Word Semantic Similarity. In ICSC, vol-
ume 7, pages 363–369.
Brian Skyrms. 2010. Signals: Evolution, learning, and
information.
</reference>
<page confidence="0.991137">
333
</page>
<reference confidence="0.999832185185185">
John M. Smith and George R. Price. 1973. The Logic of
Animal Conflict. Nature, 246:15.
Gy¨orgy Szab´o and Gabor Fath. 2007. Evolutionary
Games on Graphs. Physics Reports, 446(4):97-216.
Peter D. Taylor and Leo B. Jonker. 1978. Evolutionary
Stable Strategies and Game Dynamics. Mathematical
biosciences, 40(1):145–156.
Stephen Tratz, Antonio Sanfilippo, Michelle Gregory,
Alan Chappell, Christian Posse, and Paul Whitney.
2007. PNNL: A Supervised Maximum Entropy Ap-
proach to Word Sense Disambiguation. In Proceed-
ings of the 4th International Workshop on Semantic
Evaluations, pages 264–267.
Rocco Tripodi, Marcello Pelillo, and Rodolfo Delmonte.
2015. An Evolutionary Game Theoretic Approach
to Word Sense Disambiguation. In Proceedings of
NLPCS 2014.
John Von Neumann and Oskar Morgenstern. 1944. The-
ory of Games and Economic Behavior (60th Anniver-
sary Commemorative Edition).
Warren Weaver. 1955. Translation. Machine translation
of languages, 14:15-23.
J¨orgen W. Weibull. 1997. Evolutionary game theory.
Zhi Zhong and Hwee Tou Ng. 2010. It Makes Sense: A
Wide-Coverage Word Sense Disambiguation System
for Free Text. In Proceedings of the ACL 2010 System
Demonstrations, pages 78–83.
</reference>
<page confidence="0.99906">
334
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.477084">
<title confidence="0.9991635">WSD-games: a Game-Theoretic Algorithm for Unsupervised Word Disambiguation</title>
<author confidence="0.993862">Rocco Tripodi Marcello Pelillo</author>
<affiliation confidence="0.7226155">Ca’ Foscari University of Via Torino</affiliation>
<address confidence="0.961376">30172 Venezia,</address>
<abstract confidence="0.99918075">In this paper we present an unsupervised approach to word sense disambiguation based on evolutionary game theory. In our algorithm each word to be disambiguated is represented as a node on a graph and each sense as a class. The algorithm performs a consistent class assignment of senses according to the similarity information of each word with the others, so that similar words are constrained to similar classes. The dynamics of the system are formulated in terms of a non-cooperative multiplayer game, where the players are the data points to decide their class memberships and equilibria correspond to consistent labeling of the data.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eneko Agirre</author>
</authors>
<title>Oier Lopez De Lacalle, Aitor Soroa, and Informatika Fakultatea.</title>
<date>2009</date>
<booktitle>IJCAI,</booktitle>
<pages>1501--1506</pages>
<marker>Agirre, 2009</marker>
<rawString>Eneko Agirre, Oier Lopez De Lacalle, Aitor Soroa, and Informatika Fakultatea. 2009. Knowledge-based WSD and Specific Domains: Performing Better than Generic Supervised WSD. In IJCAI, pages 1501– 1506.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eneko Agirre</author>
</authors>
<title>Oier Lopez de Lacalle, and Aitor Soroa.</title>
<date>2014</date>
<journal>Computational Linguistics,</journal>
<volume>40</volume>
<issue>1</issue>
<marker>Agirre, 2014</marker>
<rawString>Eneko Agirre, Oier Lopez de Lacalle, and Aitor Soroa. 2014. Random Walks for Knowledge-Based Word Sense Disambiguation. Computational Linguistics, 40(1):57–84.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Brants</author>
<author>Alex Franz</author>
</authors>
<date>2006</date>
<booktitle>{Web 1T 5-gram Version 1}.</booktitle>
<contexts>
<context position="8725" citStr="Brants and Franz, 2006" startWordPosition="1532" endWordPosition="1535">weighted adjacency matrix of a weighted graph. A crucial factor for the graph construction is the choice of the similarity measure, sim(·, ·) —* R to weights the edges of the graph. For our experiments we used similarity measures which compute the strength of co-occurrence between any two words ii and ij wij = sim(ii, ij) Vi, j E I : i =� j (3) Specifically we used the modified Dice cohefficient (mDice) (Dice, 1945), the pointwise mutual information (PMI) (Church and Hanks, 1990) and the log likelihood ratio (D2) (Dunning, 1993) These measure have been calculate using the Google Web1T corpus (Brants and Franz, 2006), a large collection of n-grams (with a window of max 5 words) occurring in one terabyte of Web documents as collected by Google. At this point we have the similarity graph W, we recall that we will use this matrix in order to allow the words to play the games only with similar words. The higher the similarity among two words, the higher the reciprocal influence and the possibility that they belong to a similar class. For this reason, at first we smooth the data in W and then choose only the most significant js for each j E W. The first point is solved using a gaussian w.� = ex 2a&apos; kernel on W</context>
</contexts>
<marker>Brants, Franz, 2006</marker>
<rawString>Thorsten Brants and Alex Franz. 2006. {Web 1T 5-gram Version 1}.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Ward Church</author>
<author>Patrick Hanks</author>
</authors>
<date>1990</date>
<booktitle>Word Association Norms, Mutual Information, and Lexicography. Computational linguistics,</booktitle>
<pages>16--1</pages>
<contexts>
<context position="8586" citStr="Church and Hanks, 1990" startWordPosition="1510" endWordPosition="1513">e similarity value assigned for the words i and j. W can be exploited as an useful tool for graphbased algorithms since it is treatable as weighted adjacency matrix of a weighted graph. A crucial factor for the graph construction is the choice of the similarity measure, sim(·, ·) —* R to weights the edges of the graph. For our experiments we used similarity measures which compute the strength of co-occurrence between any two words ii and ij wij = sim(ii, ij) Vi, j E I : i =� j (3) Specifically we used the modified Dice cohefficient (mDice) (Dice, 1945), the pointwise mutual information (PMI) (Church and Hanks, 1990) and the log likelihood ratio (D2) (Dunning, 1993) These measure have been calculate using the Google Web1T corpus (Brants and Franz, 2006), a large collection of n-grams (with a window of max 5 words) occurring in one terabyte of Web documents as collected by Google. At this point we have the similarity graph W, we recall that we will use this matrix in order to allow the words to play the games only with similar words. The higher the similarity among two words, the higher the reciprocal influence and the possibility that they belong to a similar class. For this reason, at first we smooth the</context>
</contexts>
<marker>Church, Hanks, 1990</marker>
<rawString>Kenneth Ward Church and Patrick Hanks. 1990. Word Association Norms, Mutual Information, and Lexicography. Computational linguistics, 16(1):22–29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diego De Cao</author>
<author>Roberto Basili</author>
<author>Matteo Luciani</author>
<author>Francesco Mesiano</author>
<author>Riccardo Rossi</author>
</authors>
<title>Robust and Efficient PageRank for Word Sense Disambiguation.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Workshop on Graph-based Methods for Natural Language Processing,</booktitle>
<pages>24--32</pages>
<marker>De Cao, Basili, Luciani, Mesiano, Rossi, 2010</marker>
<rawString>Diego De Cao, Roberto Basili, Matteo Luciani, Francesco Mesiano, and Riccardo Rossi. 2010. Robust and Efficient PageRank for Word Sense Disambiguation. In Proceedings of the 2010 Workshop on Graph-based Methods for Natural Language Processing, pages 24–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lee R Dice</author>
</authors>
<title>Measures of the amount of ecologic association between species.</title>
<date>1945</date>
<journal>Ecology,</journal>
<volume>26</volume>
<issue>3</issue>
<contexts>
<context position="8521" citStr="Dice, 1945" startWordPosition="1502" endWordPosition="1503"> x N similarity matrix W where each element wij is the similarity value assigned for the words i and j. W can be exploited as an useful tool for graphbased algorithms since it is treatable as weighted adjacency matrix of a weighted graph. A crucial factor for the graph construction is the choice of the similarity measure, sim(·, ·) —* R to weights the edges of the graph. For our experiments we used similarity measures which compute the strength of co-occurrence between any two words ii and ij wij = sim(ii, ij) Vi, j E I : i =� j (3) Specifically we used the modified Dice cohefficient (mDice) (Dice, 1945), the pointwise mutual information (PMI) (Church and Hanks, 1990) and the log likelihood ratio (D2) (Dunning, 1993) These measure have been calculate using the Google Web1T corpus (Brants and Franz, 2006), a large collection of n-grams (with a window of max 5 words) occurring in one terabyte of Web documents as collected by Google. At this point we have the similarity graph W, we recall that we will use this matrix in order to allow the words to play the games only with similar words. The higher the similarity among two words, the higher the reciprocal influence and the possibility that they b</context>
</contexts>
<marker>Dice, 1945</marker>
<rawString>Lee R. Dice. 1945. Measures of the amount of ecologic association between species. Ecology, 26(3):297–302.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Dunning</author>
</authors>
<date>1993</date>
<booktitle>Accurate Methods for the Statistics of Surprise and Coincidence. Computational linguistics,</booktitle>
<pages>19--1</pages>
<contexts>
<context position="8636" citStr="Dunning, 1993" startWordPosition="1520" endWordPosition="1521"> exploited as an useful tool for graphbased algorithms since it is treatable as weighted adjacency matrix of a weighted graph. A crucial factor for the graph construction is the choice of the similarity measure, sim(·, ·) —* R to weights the edges of the graph. For our experiments we used similarity measures which compute the strength of co-occurrence between any two words ii and ij wij = sim(ii, ij) Vi, j E I : i =� j (3) Specifically we used the modified Dice cohefficient (mDice) (Dice, 1945), the pointwise mutual information (PMI) (Church and Hanks, 1990) and the log likelihood ratio (D2) (Dunning, 1993) These measure have been calculate using the Google Web1T corpus (Brants and Franz, 2006), a large collection of n-grams (with a window of max 5 words) occurring in one terabyte of Web documents as collected by Google. At this point we have the similarity graph W, we recall that we will use this matrix in order to allow the words to play the games only with similar words. The higher the similarity among two words, the higher the reciprocal influence and the possibility that they belong to a similar class. For this reason, at first we smooth the data in W and then choose only the most significa</context>
</contexts>
<marker>Dunning, 1993</marker>
<rawString>Ted Dunning. 1993. Accurate Methods for the Statistics of Surprise and Coincidence. Computational linguistics, 19(1):61–74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aykut Erdem</author>
<author>Marcello Pelillo</author>
</authors>
<title>Graph Transduction as a Noncooperative Game.</title>
<date>2012</date>
<journal>Neural Computation,</journal>
<pages>24--3</pages>
<contexts>
<context position="7251" citStr="Erdem and Pelillo, 2012" startWordPosition="1257" endWordPosition="1260"> the probability that player i choose its hth pure strategy. The strategy space lies on the m-dimensional standard simplex Am where: Emh=1 xih = 1 and xih &gt; 0 for all h. The expected payoff of a pure strategy eh in a single game is u(eh, x) = eh · Ax where A is the m x m payoff matrix. The average payoff of all the player strategies is u(x, x) = EhES xhu(eh, x). In order to find the Nash equilibria of the game it is used the replicator dynamic equation (Taylor and Jonker, 1978) x˙ = [u(eh, x) − u(x, x)] · xh bh E S (1) which allows better than average strategies (best replies) to grow. As in (Erdem and Pelillo, 2012) we used the discrete time version of the replicator dynamic equation: xh(t + 1) = xh(t)u(eh,x) u(x, x) bh E S (2) where at each time step t the players update their strategies until the system converges and the Nash equilibria are found. 3 WSD Games In this section we will show how we created the data necessary for our framework and how the games are played. confess don’t confess 330 3.1 Graph Construction We model the geometry of the data as a graph, with nodes corresponding to the words to be disambiguated, denoted by I = {ijjN j=1, where ij corresponds to the j-th word and N is the number </context>
</contexts>
<marker>Erdem, Pelillo, 2012</marker>
<rawString>Aykut Erdem and Marcello Pelillo. 2012. Graph Transduction as a Noncooperative Game. Neural Computation, 24(3):700-723.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John R Firth</author>
</authors>
<title>A Synopsis of Linguistic Theory 1930-1955. Studies in linguistic analysis.</title>
<date>1957</date>
<publisher>Blackwell.</publisher>
<location>Oxford:</location>
<contexts>
<context position="2934" citStr="Firth, 1957" startWordPosition="486" endWordPosition="487">e network to model the geometry of the data and the interactions among the data points. In our system the nodes of the graph are interpreted as players, in the game theoretic sense (see Section 2), which play a game in order to maximize their utility. The concept of utility has been used in different ways in the game theory (GT) literature and in general it refers to the satisfaction that a player derives from the outcome of a game (Szab´o and Fath, 2007). From our point of view increasing the utility of a word means increasing the textual coherence, in a distributional semantics perspective (Firth, 1957). In fact, in our framework a word always tries to chose a sense close to the senses which the other words in the text are likely to choose. The starting point of our research is based on the assumption that the meaning of a sentence emerges from the interaction of the components which are involved in it. In our study we tried to model this interaction and to develop a system in which it is possible to map lexical items onto concepts. For this reason 329 Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 329–334, Denver, Colorado, June 4-5, 2015. c�2015 </context>
</contexts>
<marker>Firth, 1957</marker>
<rawString>John R. Firth. 1957. A Synopsis of Linguistic Theory 1930-1955. Studies in linguistic analysis. Oxford: Blackwell.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taher H Haveliwala</author>
</authors>
<title>Topic-Sensitive PageRank.</title>
<date>2002</date>
<booktitle>In Proceedings of the 11th international conference on World Wide Web,</booktitle>
<pages>517--526</pages>
<contexts>
<context position="2102" citStr="Haveliwala, 2002" startWordPosition="335" endWordPosition="336">upervised models are gaining attention from the research community with performances close to the state of the art (Ponzetto and Navigli, 2010). In particular Knowledge-based and graph based algorithms are emerging as interesting ways to face the problem (Agirre et al., 2009; Sinha and Mihalcea, 2007). The peculiarities of those algorithms are that they do not require any corpus evidence and use only the structural properties of a lexical database to perform the disambiguation task. An unsupervised algorithm which has been implemented in different ways by the community (Mihalcea et al., 2004; Haveliwala, 2002; Agirre et al., 2014; De Cao et al., 2010) is the PageRank (Page et al., 1999). This algorithm is similar in spirit to ours but we instead of using the graph to compute the most important nodes (senses) in it, we use the network to model the geometry of the data and the interactions among the data points. In our system the nodes of the graph are interpreted as players, in the game theoretic sense (see Section 2), which play a game in order to maximize their utility. The concept of utility has been used in different ways in the game theory (GT) literature and in general it refers to the satisf</context>
</contexts>
<marker>Haveliwala, 2002</marker>
<rawString>Taher H. Haveliwala. 2002. Topic-Sensitive PageRank. In Proceedings of the 11th international conference on World Wide Web, pages 517–526.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert A Hummel</author>
<author>Steven W Zucker</author>
</authors>
<title>On the Foundations of Relaxation Labeling Processes. Pattern Analysis and Machine Intelligence,</title>
<date>1983</date>
<journal>IEEE Transactions on,</journal>
<pages>3--267</pages>
<contexts>
<context position="4049" citStr="Hummel and Zucker, 1983" startWordPosition="684" endWordPosition="688">nal Workshop on Semantic Evaluation (SemEval 2015), pages 329–334, Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics we decided to use a powerful tool, derived from Evolutionary Game Theory (EGT): the non-cooperative games (see Section 2). EGT and GT have been used in different ways to study the language use (Pietarinen, 2007; Skyrms, 2010) and evolution (Nowak et al., 2001) but as far as we know, our is the first attempt to use it in a specific NLP task. This choice is motivated by the fact that GT models are able to perform a consistent labeling of the data (Hummel and Zucker, 1983; Pelillo, 1997), taking into account the contextual information. These features are of great importance for an unsupervised algorithm which tries to perform a WSD task, because them can be obtained without any supervision and help the system to adapt to different contextual domains. 2 Game Theory In this section we briefly introduce some concepts of GT and EGT, for detailed analysis of these topics we refer to (Weibull, 1997; Leyton-Brown and Shoham, 2008; Sandholm, 2010). GT provides predictive power in interactive decision situations. It has been introduced by Von Neumann and Morgenstern (1</context>
</contexts>
<marker>Hummel, Zucker, 1983</marker>
<rawString>Robert A. Hummel and Steven W. Zucker. 1983. On the Foundations of Relaxation Labeling Processes. Pattern Analysis and Machine Intelligence, IEEE Transactions on, (3):267–287.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Leyton-Brown</author>
<author>Yoav Shoham</author>
</authors>
<date>2008</date>
<booktitle>Essentials of Game Theory: A Concise Multidisciplinary Introduction. Synthesis Lectures on Artificial Intelligence and Machine Learning,</booktitle>
<volume>2</volume>
<issue>1</issue>
<contexts>
<context position="4509" citStr="Leyton-Brown and Shoham, 2008" startWordPosition="760" endWordPosition="763">empt to use it in a specific NLP task. This choice is motivated by the fact that GT models are able to perform a consistent labeling of the data (Hummel and Zucker, 1983; Pelillo, 1997), taking into account the contextual information. These features are of great importance for an unsupervised algorithm which tries to perform a WSD task, because them can be obtained without any supervision and help the system to adapt to different contextual domains. 2 Game Theory In this section we briefly introduce some concepts of GT and EGT, for detailed analysis of these topics we refer to (Weibull, 1997; Leyton-Brown and Shoham, 2008; Sandholm, 2010). GT provides predictive power in interactive decision situations. It has been introduced by Von Neumann and Morgenstern (1944) and in its normal form representation (which is the one we will use in our algorithm) it consists in: a finite set of players I = (1, .., n), a set of pure strategies for each player Si = (s1, ..., sn) and an utility function ui : S1x...xSn —* R which associates strategies to payoffs. The utility function depends on the combination of two strategies played together, not just on the strategy of a single player. An important assumption in GT is that the</context>
</contexts>
<marker>Leyton-Brown, Shoham, 2008</marker>
<rawString>Kevin Leyton-Brown and Yoav Shoham. 2008. Essentials of Game Theory: A Concise Multidisciplinary Introduction. Synthesis Lectures on Artificial Intelligence and Machine Learning, 2(1):1–88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John C Mallery</author>
</authors>
<title>WordNet: a Lexical Database for English.</title>
<date>1995</date>
<journal>Communications of the ACM,</journal>
<pages>38--11</pages>
<contexts>
<context position="9810" citStr="Mallery, 1995" startWordPosition="1744" endWordPosition="1745"> and then choose only the most significant js for each j E W. The first point is solved using a gaussian w.� = ex 2a&apos; kernel on W Z p (— 2 ), where Q is the kernel width parameter; the second point is solved applying a k − nearest neighbor algorithm to W, which allows us to remove the edges which are less significant for each i E I. In our experiments we used Q = 0.5 and k = 25. Moreover, this operation reduces the computational cost of the algorithm, which will focus only on relevant similarities. 3.2 The Strategy Space In order to create the strategy space of the game, we first use WordNet (Mallery, 1995) to collect the sense inventories Mi = 1, ... , m of each word, where m is the number of synsets associated to word i. Then we set all the sense inventories and obtain the list of all possible senses, C = 1, ... , c. We can now define the strategy space S of the game in matrix form as: si1 si2 ··· sic ... ... · · · ... sn1 sn2 ··· snc where each row corresponds to the strategy space of a player and each column corresponds to a sense. Formally it is a c-dimensional space Ac and each mixed strategy profile lives in the mixed strategy space of the game, given by the Cartesian product Θ = xi∈IAi. </context>
</contexts>
<marker>Mallery, 1995</marker>
<rawString>John C. Mallery. 1995. WordNet: a Lexical Database for English. Communications of the ACM, 38(11):39-41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana McCarthy</author>
<author>Rob Koeling</author>
<author>Julie Weeds</author>
<author>John Carroll</author>
</authors>
<title>Unsupervised Acquisition of Predominant Word Senses.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>4</issue>
<contexts>
<context position="1373" citStr="McCarthy et al., 2007" startWordPosition="217" endWordPosition="220">the data points to decide their class memberships and equilibria correspond to consistent labeling of the data. 1 Introduction Word sense disambiguation (WSD) is the task to identify the intended sense of a word in a computational manner based on the context in which it appears (Navigli, 2009). It has been studied since the beginning of NLP (Weaver, 1955) and also today it is a central topic of this discipline. Many algorithms have been proposed during the years, based on supervised (Zhong and Ng, 2010; Tratz et al., 2007), semi-supervised (Pham et al., 2005) and unsupervised (Mihalcea, 2005; McCarthy et al., 2007) learning models. Nowadays, even if supervised methods perform better in general domains, unsupervised and semi-supervised models are gaining attention from the research community with performances close to the state of the art (Ponzetto and Navigli, 2010). In particular Knowledge-based and graph based algorithms are emerging as interesting ways to face the problem (Agirre et al., 2009; Sinha and Mihalcea, 2007). The peculiarities of those algorithms are that they do not require any corpus evidence and use only the structural properties of a lexical database to perform the disambiguation task.</context>
</contexts>
<marker>McCarthy, Koeling, Weeds, Carroll, 2007</marker>
<rawString>Diana McCarthy, Rob Koeling, Julie Weeds, and John Carroll. 2007. Unsupervised Acquisition of Predominant Word Senses. Computational Linguistics, 33(4):553–590.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
<author>Paul Tarau</author>
<author>Elizabeth Figa</author>
</authors>
<title>PageRank on Semantic Networks, with Application to Word Sense Disambiguation.</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th international conference on Computational Linguistics,</booktitle>
<pages>1126</pages>
<contexts>
<context position="2084" citStr="Mihalcea et al., 2004" startWordPosition="330" endWordPosition="334">unsupervised and semi-supervised models are gaining attention from the research community with performances close to the state of the art (Ponzetto and Navigli, 2010). In particular Knowledge-based and graph based algorithms are emerging as interesting ways to face the problem (Agirre et al., 2009; Sinha and Mihalcea, 2007). The peculiarities of those algorithms are that they do not require any corpus evidence and use only the structural properties of a lexical database to perform the disambiguation task. An unsupervised algorithm which has been implemented in different ways by the community (Mihalcea et al., 2004; Haveliwala, 2002; Agirre et al., 2014; De Cao et al., 2010) is the PageRank (Page et al., 1999). This algorithm is similar in spirit to ours but we instead of using the graph to compute the most important nodes (senses) in it, we use the network to model the geometry of the data and the interactions among the data points. In our system the nodes of the graph are interpreted as players, in the game theoretic sense (see Section 2), which play a game in order to maximize their utility. The concept of utility has been used in different ways in the game theory (GT) literature and in general it re</context>
</contexts>
<marker>Mihalcea, Tarau, Figa, 2004</marker>
<rawString>Rada Mihalcea, Paul Tarau, and Elizabeth Figa. 2004. PageRank on Semantic Networks, with Application to Word Sense Disambiguation. In Proceedings of the 20th international conference on Computational Linguistics, page 1126.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
</authors>
<title>Unsupervised Large-Vocabulary Word Sense Disambiguation with Graph-Based Algorithms for Sequence Data Labeling.</title>
<date>2005</date>
<booktitle>In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing,</booktitle>
<pages>411--418</pages>
<contexts>
<context position="1349" citStr="Mihalcea, 2005" startWordPosition="215" endWordPosition="216">the players are the data points to decide their class memberships and equilibria correspond to consistent labeling of the data. 1 Introduction Word sense disambiguation (WSD) is the task to identify the intended sense of a word in a computational manner based on the context in which it appears (Navigli, 2009). It has been studied since the beginning of NLP (Weaver, 1955) and also today it is a central topic of this discipline. Many algorithms have been proposed during the years, based on supervised (Zhong and Ng, 2010; Tratz et al., 2007), semi-supervised (Pham et al., 2005) and unsupervised (Mihalcea, 2005; McCarthy et al., 2007) learning models. Nowadays, even if supervised methods perform better in general domains, unsupervised and semi-supervised models are gaining attention from the research community with performances close to the state of the art (Ponzetto and Navigli, 2010). In particular Knowledge-based and graph based algorithms are emerging as interesting ways to face the problem (Agirre et al., 2009; Sinha and Mihalcea, 2007). The peculiarities of those algorithms are that they do not require any corpus evidence and use only the structural properties of a lexical database to perform </context>
</contexts>
<marker>Mihalcea, 2005</marker>
<rawString>Rada Mihalcea. 2005. Unsupervised Large-Vocabulary Word Sense Disambiguation with Graph-Based Algorithms for Sequence Data Labeling. In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing, pages 411–418.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Moro</author>
<author>Roberto Navigli</author>
</authors>
<date>2015</date>
<booktitle>SemEval-2015 Task 13: Multilingual All-Words Sense Disambiguation and Entity Linking. In Proceedings of SemEval2015.</booktitle>
<contexts>
<context position="12750" citStr="Moro and Navigli, 2015" startWordPosition="2307" endWordPosition="2310">we have the topology of the data W, the strategy space of the game S and the payoff matrix Z we can compute the Nash equilibria of the game according to equation (2). So in each iteration of the system each player gain its payoffs according to equation (6) which allows each payoff to be proportional to the similarity (wij) and to the affinity that player j has to the hs strategy of player i. �ui(eh, x) = ((wijZij)xj)h (6) j∈Ni When the system converges each player chooses the strategy with the highest value. 4 Results and Analysis The dataset proposed by the organizers of SemEval2015 Task 13 (Moro and Navigli, 2015) consists of five texts from three different domains: math and computer, biomedical and general. The english corpus is composed of 1426 instances to disambiguate and 1262 of them have been used in the evaluation. For our experiments we used only the instances whose lemma has an entry in WordNet 3.0 without looking up multi-words or trying to link the entities to other sources such as Wikipedia or BabelNet (Navigli and Ponzetto, 2012) We submitted three runs for our system with 1227 single words disambiguated for each run. The only difference for each run is the similarity measure that we used </context>
</contexts>
<marker>Moro, Navigli, 2015</marker>
<rawString>Andrea Moro and Roberto Navigli. 2015. SemEval-2015 Task 13: Multilingual All-Words Sense Disambiguation and Entity Linking. In Proceedings of SemEval2015.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
<author>Simone Paolo Ponzetto</author>
</authors>
<title>BabelNet: The Automatic Construction, Evaluation and Application of a Wide-Coverage Multilingual Semantic Network.</title>
<date>2012</date>
<journal>Artificial Intelligence,</journal>
<pages>193--217</pages>
<contexts>
<context position="13187" citStr="Navigli and Ponzetto, 2012" startWordPosition="2382" endWordPosition="2385">en the system converges each player chooses the strategy with the highest value. 4 Results and Analysis The dataset proposed by the organizers of SemEval2015 Task 13 (Moro and Navigli, 2015) consists of five texts from three different domains: math and computer, biomedical and general. The english corpus is composed of 1426 instances to disambiguate and 1262 of them have been used in the evaluation. For our experiments we used only the instances whose lemma has an entry in WordNet 3.0 without looking up multi-words or trying to link the entities to other sources such as Wikipedia or BabelNet (Navigli and Ponzetto, 2012) We submitted three runs for our system with 1227 single words disambiguated for each run. The only difference for each run is the similarity measure that we used to construct the graph W. For run-1 we used the PMI measure, for run-2 the mDice coefficient and for run-3 the D2. As we expected from previous experiments on similar datasets, the best results have been achieved using the mDice coefficient (see Table 2). We obtained low recall values for all our runs and this because we did not search multi-words and did not use other sources of information for the named entities, in fact the number</context>
</contexts>
<marker>Navigli, Ponzetto, 2012</marker>
<rawString>Roberto Navigli and Simone Paolo Ponzetto. 2012. BabelNet: The Automatic Construction, Evaluation and Application of a Wide-Coverage Multilingual Semantic Network. Artificial Intelligence, 193:217–250.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
</authors>
<title>Word Sense Disambiguation: A Survey.</title>
<date>2009</date>
<journal>ACM Computing Surveys (CSUR),</journal>
<volume>41</volume>
<issue>2</issue>
<contexts>
<context position="1045" citStr="Navigli, 2009" startWordPosition="164" endWordPosition="165">ense as a class. The algorithm performs a consistent class assignment of senses according to the similarity information of each word with the others, so that similar words are constrained to similar classes. The dynamics of the system are formulated in terms of a non-cooperative multiplayer game, where the players are the data points to decide their class memberships and equilibria correspond to consistent labeling of the data. 1 Introduction Word sense disambiguation (WSD) is the task to identify the intended sense of a word in a computational manner based on the context in which it appears (Navigli, 2009). It has been studied since the beginning of NLP (Weaver, 1955) and also today it is a central topic of this discipline. Many algorithms have been proposed during the years, based on supervised (Zhong and Ng, 2010; Tratz et al., 2007), semi-supervised (Pham et al., 2005) and unsupervised (Mihalcea, 2005; McCarthy et al., 2007) learning models. Nowadays, even if supervised methods perform better in general domains, unsupervised and semi-supervised models are gaining attention from the research community with performances close to the state of the art (Ponzetto and Navigli, 2010). In particular </context>
</contexts>
<marker>Navigli, 2009</marker>
<rawString>Roberto Navigli. 2009. Word Sense Disambiguation: A Survey. ACM Computing Surveys (CSUR), 41(2):10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin A Nowak</author>
<author>Natalia L Komarova</author>
<author>Partha Niyogi</author>
</authors>
<date>2001</date>
<journal>Evolution of Universal Grammar. Science,</journal>
<volume>291</volume>
<issue>5501</issue>
<contexts>
<context position="3836" citStr="Nowak et al., 2001" startWordPosition="640" endWordPosition="643">ich are involved in it. In our study we tried to model this interaction and to develop a system in which it is possible to map lexical items onto concepts. For this reason 329 Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 329–334, Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics we decided to use a powerful tool, derived from Evolutionary Game Theory (EGT): the non-cooperative games (see Section 2). EGT and GT have been used in different ways to study the language use (Pietarinen, 2007; Skyrms, 2010) and evolution (Nowak et al., 2001) but as far as we know, our is the first attempt to use it in a specific NLP task. This choice is motivated by the fact that GT models are able to perform a consistent labeling of the data (Hummel and Zucker, 1983; Pelillo, 1997), taking into account the contextual information. These features are of great importance for an unsupervised algorithm which tries to perform a WSD task, because them can be obtained without any supervision and help the system to adapt to different contextual domains. 2 Game Theory In this section we briefly introduce some concepts of GT and EGT, for detailed analysis </context>
</contexts>
<marker>Nowak, Komarova, Niyogi, 2001</marker>
<rawString>Martin A. Nowak, Natalia L. Komarova, and Partha Niyogi. 2001. Evolution of Universal Grammar. Science, 291(5501):114–118.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lawrence Page</author>
<author>Sergey Brin</author>
<author>Rajeev Motwani</author>
<author>Terry Winograd</author>
</authors>
<title>The PageRank Citation Ranking: Bringing Order to the Web.</title>
<date>1999</date>
<contexts>
<context position="2181" citStr="Page et al., 1999" startWordPosition="349" endWordPosition="352">rmances close to the state of the art (Ponzetto and Navigli, 2010). In particular Knowledge-based and graph based algorithms are emerging as interesting ways to face the problem (Agirre et al., 2009; Sinha and Mihalcea, 2007). The peculiarities of those algorithms are that they do not require any corpus evidence and use only the structural properties of a lexical database to perform the disambiguation task. An unsupervised algorithm which has been implemented in different ways by the community (Mihalcea et al., 2004; Haveliwala, 2002; Agirre et al., 2014; De Cao et al., 2010) is the PageRank (Page et al., 1999). This algorithm is similar in spirit to ours but we instead of using the graph to compute the most important nodes (senses) in it, we use the network to model the geometry of the data and the interactions among the data points. In our system the nodes of the graph are interpreted as players, in the game theoretic sense (see Section 2), which play a game in order to maximize their utility. The concept of utility has been used in different ways in the game theory (GT) literature and in general it refers to the satisfaction that a player derives from the outcome of a game (Szab´o and Fath, 2007)</context>
</contexts>
<marker>Page, Brin, Motwani, Winograd, 1999</marker>
<rawString>Lawrence Page, Sergey Brin, Rajeev Motwani, and Terry Winograd. 1999. The PageRank Citation Ranking: Bringing Order to the Web.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Siddharth Patwardhan</author>
<author>Ted Pedersen</author>
</authors>
<title>Using WordNet-Based Context Vectors to Estimate the Semantic Relatedness of Concepts.</title>
<date>2006</date>
<booktitle>In Proceedings of the EACL 2006 Workshop Making Sense of SenseBringing Computational Linguistics and Psycholinguistics Together,</booktitle>
<volume>1501</volume>
<pages>1--8</pages>
<contexts>
<context position="11128" citStr="Patwardhan and Pedersen, 2006" startWordPosition="2004" endWordPosition="2007">to follow the constraints described in Section 2.1 �Mi�−1, if sense j is in Mi. sij = (4) SI0, otherwise. for all i E I and j E S. 3.3 The Payoff Matrix We encoded the payoff matrix of a WSD game as a sense similarity matrix among all the senses in the strategy spaces of the game. In this way the higher the similarity among two sense candidates, the higher the incentive for a player to chose that sense, and play the strategy associated to it. The c x c sense similarity matrix Z is defined as follows: zij = ssim(si, sj) Vi, j E C : i =� j (5) In our experiments we used the GlossVector measure (Patwardhan and Pedersen, 2006) in order to compute the semantic relatedness ssim(·, ·). This measure calculates the cosine similarity among two second order context vectors. Each vector is obtained from a WordNet super-glosse, which is the gloss of a synset plus the glosses of the synsets related to it. 331 run sim P R F1 math med. gen. 1 PMI 57.4 48.9 52.8 47.4 56.3 53.5 2 mDice 58.8 50.0 54.1 48.5 58.4 53.5 3 D2 53.5 45.4 49.1 43.4 54.4 46.7 Table 2: The results of the WSD-games team at SemEval2015 task 13. Precision, Recall and F1 in all domains and F1 in specific domains. From Z we can obtain the partial semantic simil</context>
</contexts>
<marker>Patwardhan, Pedersen, 2006</marker>
<rawString>Siddharth Patwardhan and Ted Pedersen. 2006. Using WordNet-Based Context Vectors to Estimate the Semantic Relatedness of Concepts. In Proceedings of the EACL 2006 Workshop Making Sense of SenseBringing Computational Linguistics and Psycholinguistics Together, volume 1501, pages 1–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marcello Pelillo</author>
</authors>
<title>The Dynamics of Nonlinear Relaxation Labeling Processes.</title>
<date>1997</date>
<journal>Journal of Mathematical Imaging and Vision,</journal>
<volume>7</volume>
<issue>4</issue>
<contexts>
<context position="4065" citStr="Pelillo, 1997" startWordPosition="689" endWordPosition="690">Evaluation (SemEval 2015), pages 329–334, Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics we decided to use a powerful tool, derived from Evolutionary Game Theory (EGT): the non-cooperative games (see Section 2). EGT and GT have been used in different ways to study the language use (Pietarinen, 2007; Skyrms, 2010) and evolution (Nowak et al., 2001) but as far as we know, our is the first attempt to use it in a specific NLP task. This choice is motivated by the fact that GT models are able to perform a consistent labeling of the data (Hummel and Zucker, 1983; Pelillo, 1997), taking into account the contextual information. These features are of great importance for an unsupervised algorithm which tries to perform a WSD task, because them can be obtained without any supervision and help the system to adapt to different contextual domains. 2 Game Theory In this section we briefly introduce some concepts of GT and EGT, for detailed analysis of these topics we refer to (Weibull, 1997; Leyton-Brown and Shoham, 2008; Sandholm, 2010). GT provides predictive power in interactive decision situations. It has been introduced by Von Neumann and Morgenstern (1944) and in its </context>
</contexts>
<marker>Pelillo, 1997</marker>
<rawString>Marcello Pelillo. 1997. The Dynamics of Nonlinear Relaxation Labeling Processes. Journal of Mathematical Imaging and Vision, 7(4):309–323.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thanh Phong Pham</author>
<author>Hwee Tou Ng</author>
<author>Wee Sun Lee</author>
</authors>
<title>Word Sense Disambiguation with SemiSupervised Learning.</title>
<date>2005</date>
<booktitle>In Proceedings of the National Conference on Artificial Intelligence,</booktitle>
<volume>20</volume>
<pages>1093</pages>
<contexts>
<context position="1316" citStr="Pham et al., 2005" startWordPosition="209" endWordPosition="212">-cooperative multiplayer game, where the players are the data points to decide their class memberships and equilibria correspond to consistent labeling of the data. 1 Introduction Word sense disambiguation (WSD) is the task to identify the intended sense of a word in a computational manner based on the context in which it appears (Navigli, 2009). It has been studied since the beginning of NLP (Weaver, 1955) and also today it is a central topic of this discipline. Many algorithms have been proposed during the years, based on supervised (Zhong and Ng, 2010; Tratz et al., 2007), semi-supervised (Pham et al., 2005) and unsupervised (Mihalcea, 2005; McCarthy et al., 2007) learning models. Nowadays, even if supervised methods perform better in general domains, unsupervised and semi-supervised models are gaining attention from the research community with performances close to the state of the art (Ponzetto and Navigli, 2010). In particular Knowledge-based and graph based algorithms are emerging as interesting ways to face the problem (Agirre et al., 2009; Sinha and Mihalcea, 2007). The peculiarities of those algorithms are that they do not require any corpus evidence and use only the structural properties </context>
</contexts>
<marker>Pham, Ng, Lee, 2005</marker>
<rawString>Thanh Phong Pham, Hwee Tou Ng, and Wee Sun Lee. 2005. Word Sense Disambiguation with SemiSupervised Learning. In Proceedings of the National Conference on Artificial Intelligence, volume 20, page 1093.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ahti-Veikko Pietarinen</author>
</authors>
<title>Game theory and linguistic meaning.</title>
<date>2007</date>
<contexts>
<context position="3786" citStr="Pietarinen, 2007" startWordPosition="633" endWordPosition="635">erges from the interaction of the components which are involved in it. In our study we tried to model this interaction and to develop a system in which it is possible to map lexical items onto concepts. For this reason 329 Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 329–334, Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics we decided to use a powerful tool, derived from Evolutionary Game Theory (EGT): the non-cooperative games (see Section 2). EGT and GT have been used in different ways to study the language use (Pietarinen, 2007; Skyrms, 2010) and evolution (Nowak et al., 2001) but as far as we know, our is the first attempt to use it in a specific NLP task. This choice is motivated by the fact that GT models are able to perform a consistent labeling of the data (Hummel and Zucker, 1983; Pelillo, 1997), taking into account the contextual information. These features are of great importance for an unsupervised algorithm which tries to perform a WSD task, because them can be obtained without any supervision and help the system to adapt to different contextual domains. 2 Game Theory In this section we briefly introduce s</context>
</contexts>
<marker>Pietarinen, 2007</marker>
<rawString>Ahti-Veikko Pietarinen. 2007. Game theory and linguistic meaning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Simone Paolo Ponzetto</author>
<author>Roberto Navigli</author>
</authors>
<title>Knowledge-Rich Word Sense Disambiguation Rivaling Supervised Systems.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th annual meeting of the</booktitle>
<pages>1522--1531</pages>
<contexts>
<context position="1629" citStr="Ponzetto and Navigli, 2010" startWordPosition="256" endWordPosition="259">context in which it appears (Navigli, 2009). It has been studied since the beginning of NLP (Weaver, 1955) and also today it is a central topic of this discipline. Many algorithms have been proposed during the years, based on supervised (Zhong and Ng, 2010; Tratz et al., 2007), semi-supervised (Pham et al., 2005) and unsupervised (Mihalcea, 2005; McCarthy et al., 2007) learning models. Nowadays, even if supervised methods perform better in general domains, unsupervised and semi-supervised models are gaining attention from the research community with performances close to the state of the art (Ponzetto and Navigli, 2010). In particular Knowledge-based and graph based algorithms are emerging as interesting ways to face the problem (Agirre et al., 2009; Sinha and Mihalcea, 2007). The peculiarities of those algorithms are that they do not require any corpus evidence and use only the structural properties of a lexical database to perform the disambiguation task. An unsupervised algorithm which has been implemented in different ways by the community (Mihalcea et al., 2004; Haveliwala, 2002; Agirre et al., 2014; De Cao et al., 2010) is the PageRank (Page et al., 1999). This algorithm is similar in spirit to ours bu</context>
</contexts>
<marker>Ponzetto, Navigli, 2010</marker>
<rawString>Simone Paolo Ponzetto and Roberto Navigli. 2010. Knowledge-Rich Word Sense Disambiguation Rivaling Supervised Systems. In Proceedings of the 48th annual meeting of the association for computational linguistics, pages 1522–1531.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William H Sandholm</author>
</authors>
<title>Population games and evolutionary dynamics.</title>
<date>2010</date>
<contexts>
<context position="4526" citStr="Sandholm, 2010" startWordPosition="764" endWordPosition="765">P task. This choice is motivated by the fact that GT models are able to perform a consistent labeling of the data (Hummel and Zucker, 1983; Pelillo, 1997), taking into account the contextual information. These features are of great importance for an unsupervised algorithm which tries to perform a WSD task, because them can be obtained without any supervision and help the system to adapt to different contextual domains. 2 Game Theory In this section we briefly introduce some concepts of GT and EGT, for detailed analysis of these topics we refer to (Weibull, 1997; Leyton-Brown and Shoham, 2008; Sandholm, 2010). GT provides predictive power in interactive decision situations. It has been introduced by Von Neumann and Morgenstern (1944) and in its normal form representation (which is the one we will use in our algorithm) it consists in: a finite set of players I = (1, .., n), a set of pure strategies for each player Si = (s1, ..., sn) and an utility function ui : S1x...xSn —* R which associates strategies to payoffs. The utility function depends on the combination of two strategies played together, not just on the strategy of a single player. An important assumption in GT is that the players are rati</context>
</contexts>
<marker>Sandholm, 2010</marker>
<rawString>William H. Sandholm. 2010. Population games and evolutionary dynamics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ravi Som Sinha</author>
<author>Rada Mihalcea</author>
</authors>
<title>Unsupervised Graph-based Word Sense Disambiguation Using Measures of Word Semantic Similarity.</title>
<date>2007</date>
<booktitle>In ICSC,</booktitle>
<volume>7</volume>
<pages>363--369</pages>
<contexts>
<context position="1788" citStr="Sinha and Mihalcea, 2007" startWordPosition="280" endWordPosition="283">e. Many algorithms have been proposed during the years, based on supervised (Zhong and Ng, 2010; Tratz et al., 2007), semi-supervised (Pham et al., 2005) and unsupervised (Mihalcea, 2005; McCarthy et al., 2007) learning models. Nowadays, even if supervised methods perform better in general domains, unsupervised and semi-supervised models are gaining attention from the research community with performances close to the state of the art (Ponzetto and Navigli, 2010). In particular Knowledge-based and graph based algorithms are emerging as interesting ways to face the problem (Agirre et al., 2009; Sinha and Mihalcea, 2007). The peculiarities of those algorithms are that they do not require any corpus evidence and use only the structural properties of a lexical database to perform the disambiguation task. An unsupervised algorithm which has been implemented in different ways by the community (Mihalcea et al., 2004; Haveliwala, 2002; Agirre et al., 2014; De Cao et al., 2010) is the PageRank (Page et al., 1999). This algorithm is similar in spirit to ours but we instead of using the graph to compute the most important nodes (senses) in it, we use the network to model the geometry of the data and the interactions a</context>
</contexts>
<marker>Sinha, Mihalcea, 2007</marker>
<rawString>Ravi Som Sinha and Rada Mihalcea. 2007. Unsupervised Graph-based Word Sense Disambiguation Using Measures of Word Semantic Similarity. In ICSC, volume 7, pages 363–369.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brian Skyrms</author>
</authors>
<title>Signals: Evolution, learning, and information.</title>
<date>2010</date>
<contexts>
<context position="3801" citStr="Skyrms, 2010" startWordPosition="636" endWordPosition="637">eraction of the components which are involved in it. In our study we tried to model this interaction and to develop a system in which it is possible to map lexical items onto concepts. For this reason 329 Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 329–334, Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics we decided to use a powerful tool, derived from Evolutionary Game Theory (EGT): the non-cooperative games (see Section 2). EGT and GT have been used in different ways to study the language use (Pietarinen, 2007; Skyrms, 2010) and evolution (Nowak et al., 2001) but as far as we know, our is the first attempt to use it in a specific NLP task. This choice is motivated by the fact that GT models are able to perform a consistent labeling of the data (Hummel and Zucker, 1983; Pelillo, 1997), taking into account the contextual information. These features are of great importance for an unsupervised algorithm which tries to perform a WSD task, because them can be obtained without any supervision and help the system to adapt to different contextual domains. 2 Game Theory In this section we briefly introduce some concepts of</context>
</contexts>
<marker>Skyrms, 2010</marker>
<rawString>Brian Skyrms. 2010. Signals: Evolution, learning, and information.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John M Smith</author>
<author>George R Price</author>
</authors>
<date>1973</date>
<booktitle>The Logic of Animal Conflict. Nature,</booktitle>
<pages>246--15</pages>
<contexts>
<context position="5927" citStr="Smith and Price (1973)" startWordPosition="1011" endWordPosition="1014">if ui(sz, s_i) &gt; ui(si, s_i),bs_i E S_i. As an example we can consider the famous Prisoner’s Dilemma (in Table 1) where the strategy confess is a dominant strategy for both players and this strategy combination is the Nash equilibrium of the game. Nash equilibria are those strategy profiles which are best response to the strategy of the co-player and no player has the incentive to unilaterally deviate from his strategy, because there is no way to do better. 1 \ 2 confess don’t confess -5,-5 0,-6 -6,0 -1,-1 Table 1: The Prisoner’s Dilemma. 2.1 Evolutionary Game Theory EGT has been introduce by Smith and Price (1973) overcoming some limitations of traditional GT such as the hyper-rationality imposed on the players, in fact in real life situations the players choose a strategy according to heuristics or social norms (Szab´o and Fath, 2007). Another important aspect of EGT is the introduction of an inductive learning process, in which the agents play the game repeatedly with their neighborhood, updating their believes on the state of the game and choosing their strategy accordingly. The strategy space of each player is defined as a probability distribution over its pure strategies. It is represented as a ve</context>
</contexts>
<marker>Smith, Price, 1973</marker>
<rawString>John M. Smith and George R. Price. 1973. The Logic of Animal Conflict. Nature, 246:15.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gy¨orgy Szab´o</author>
<author>Gabor Fath</author>
</authors>
<date>2007</date>
<journal>Evolutionary Games on Graphs. Physics Reports,</journal>
<pages>446--4</pages>
<marker>Szab´o, Fath, 2007</marker>
<rawString>Gy¨orgy Szab´o and Gabor Fath. 2007. Evolutionary Games on Graphs. Physics Reports, 446(4):97-216.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Taylor</author>
<author>Leo B Jonker</author>
</authors>
<date>1978</date>
<booktitle>Evolutionary Stable Strategies and Game Dynamics. Mathematical biosciences,</booktitle>
<pages>40--1</pages>
<contexts>
<context position="7109" citStr="Taylor and Jonker, 1978" startWordPosition="1228" endWordPosition="1231">pure strategies. It is represented as a vector xi = (xi1, . . . , xim) where m is the number of pure strategies and each component xih denotes the probability that player i choose its hth pure strategy. The strategy space lies on the m-dimensional standard simplex Am where: Emh=1 xih = 1 and xih &gt; 0 for all h. The expected payoff of a pure strategy eh in a single game is u(eh, x) = eh · Ax where A is the m x m payoff matrix. The average payoff of all the player strategies is u(x, x) = EhES xhu(eh, x). In order to find the Nash equilibria of the game it is used the replicator dynamic equation (Taylor and Jonker, 1978) x˙ = [u(eh, x) − u(x, x)] · xh bh E S (1) which allows better than average strategies (best replies) to grow. As in (Erdem and Pelillo, 2012) we used the discrete time version of the replicator dynamic equation: xh(t + 1) = xh(t)u(eh,x) u(x, x) bh E S (2) where at each time step t the players update their strategies until the system converges and the Nash equilibria are found. 3 WSD Games In this section we will show how we created the data necessary for our framework and how the games are played. confess don’t confess 330 3.1 Graph Construction We model the geometry of the data as a graph, w</context>
</contexts>
<marker>Taylor, Jonker, 1978</marker>
<rawString>Peter D. Taylor and Leo B. Jonker. 1978. Evolutionary Stable Strategies and Game Dynamics. Mathematical biosciences, 40(1):145–156.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Tratz</author>
<author>Antonio Sanfilippo</author>
<author>Michelle Gregory</author>
<author>Alan Chappell</author>
<author>Christian Posse</author>
<author>Paul Whitney</author>
</authors>
<title>PNNL: A Supervised Maximum Entropy Approach to Word Sense Disambiguation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 4th International Workshop on Semantic Evaluations,</booktitle>
<pages>264--267</pages>
<contexts>
<context position="1279" citStr="Tratz et al., 2007" startWordPosition="204" endWordPosition="207">ystem are formulated in terms of a non-cooperative multiplayer game, where the players are the data points to decide their class memberships and equilibria correspond to consistent labeling of the data. 1 Introduction Word sense disambiguation (WSD) is the task to identify the intended sense of a word in a computational manner based on the context in which it appears (Navigli, 2009). It has been studied since the beginning of NLP (Weaver, 1955) and also today it is a central topic of this discipline. Many algorithms have been proposed during the years, based on supervised (Zhong and Ng, 2010; Tratz et al., 2007), semi-supervised (Pham et al., 2005) and unsupervised (Mihalcea, 2005; McCarthy et al., 2007) learning models. Nowadays, even if supervised methods perform better in general domains, unsupervised and semi-supervised models are gaining attention from the research community with performances close to the state of the art (Ponzetto and Navigli, 2010). In particular Knowledge-based and graph based algorithms are emerging as interesting ways to face the problem (Agirre et al., 2009; Sinha and Mihalcea, 2007). The peculiarities of those algorithms are that they do not require any corpus evidence an</context>
</contexts>
<marker>Tratz, Sanfilippo, Gregory, Chappell, Posse, Whitney, 2007</marker>
<rawString>Stephen Tratz, Antonio Sanfilippo, Michelle Gregory, Alan Chappell, Christian Posse, and Paul Whitney. 2007. PNNL: A Supervised Maximum Entropy Approach to Word Sense Disambiguation. In Proceedings of the 4th International Workshop on Semantic Evaluations, pages 264–267.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rocco Tripodi</author>
<author>Marcello Pelillo</author>
<author>Rodolfo Delmonte</author>
</authors>
<title>An Evolutionary Game Theoretic Approach to Word Sense Disambiguation.</title>
<date>2015</date>
<booktitle>In Proceedings of NLPCS</booktitle>
<contexts>
<context position="11866" citStr="Tripodi et al., 2015" startWordPosition="2151" endWordPosition="2154">ond order context vectors. Each vector is obtained from a WordNet super-glosse, which is the gloss of a synset plus the glosses of the synsets related to it. 331 run sim P R F1 math med. gen. 1 PMI 57.4 48.9 52.8 47.4 56.3 53.5 2 mDice 58.8 50.0 54.1 48.5 58.4 53.5 3 D2 53.5 45.4 49.1 43.4 54.4 46.7 Table 2: The results of the WSD-games team at SemEval2015 task 13. Precision, Recall and F1 in all domains and F1 in specific domains. From Z we can obtain the partial semantic similarity matrix for each pair of player, Zij = m × n, where m and n are the senses of i and j in Z. In a previous work (Tripodi et al., 2015) we did not use this information, instead we used labeled data points to propagate the class membership information over the graph. In this new version the use of the semantic information made the algorithm completely unsupervised. 3.4 System Dynamics Now that we have the topology of the data W, the strategy space of the game S and the payoff matrix Z we can compute the Nash equilibria of the game according to equation (2). So in each iteration of the system each player gain its payoffs according to equation (6) which allows each payoff to be proportional to the similarity (wij) and to the aff</context>
</contexts>
<marker>Tripodi, Pelillo, Delmonte, 2015</marker>
<rawString>Rocco Tripodi, Marcello Pelillo, and Rodolfo Delmonte. 2015. An Evolutionary Game Theoretic Approach to Word Sense Disambiguation. In Proceedings of NLPCS 2014.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Von Neumann</author>
<author>Oskar Morgenstern</author>
</authors>
<date>1944</date>
<booktitle>Theory of Games and Economic Behavior (60th Anniversary Commemorative Edition).</booktitle>
<marker>Von Neumann, Morgenstern, 1944</marker>
<rawString>John Von Neumann and Oskar Morgenstern. 1944. Theory of Games and Economic Behavior (60th Anniversary Commemorative Edition).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Warren Weaver</author>
</authors>
<date>1955</date>
<booktitle>Translation. Machine translation of languages,</booktitle>
<pages>14--15</pages>
<contexts>
<context position="1108" citStr="Weaver, 1955" startWordPosition="175" endWordPosition="176">nment of senses according to the similarity information of each word with the others, so that similar words are constrained to similar classes. The dynamics of the system are formulated in terms of a non-cooperative multiplayer game, where the players are the data points to decide their class memberships and equilibria correspond to consistent labeling of the data. 1 Introduction Word sense disambiguation (WSD) is the task to identify the intended sense of a word in a computational manner based on the context in which it appears (Navigli, 2009). It has been studied since the beginning of NLP (Weaver, 1955) and also today it is a central topic of this discipline. Many algorithms have been proposed during the years, based on supervised (Zhong and Ng, 2010; Tratz et al., 2007), semi-supervised (Pham et al., 2005) and unsupervised (Mihalcea, 2005; McCarthy et al., 2007) learning models. Nowadays, even if supervised methods perform better in general domains, unsupervised and semi-supervised models are gaining attention from the research community with performances close to the state of the art (Ponzetto and Navigli, 2010). In particular Knowledge-based and graph based algorithms are emerging as inte</context>
</contexts>
<marker>Weaver, 1955</marker>
<rawString>Warren Weaver. 1955. Translation. Machine translation of languages, 14:15-23.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J¨orgen W Weibull</author>
</authors>
<date>1997</date>
<note>Evolutionary game theory.</note>
<contexts>
<context position="4478" citStr="Weibull, 1997" startWordPosition="758" endWordPosition="759">s the first attempt to use it in a specific NLP task. This choice is motivated by the fact that GT models are able to perform a consistent labeling of the data (Hummel and Zucker, 1983; Pelillo, 1997), taking into account the contextual information. These features are of great importance for an unsupervised algorithm which tries to perform a WSD task, because them can be obtained without any supervision and help the system to adapt to different contextual domains. 2 Game Theory In this section we briefly introduce some concepts of GT and EGT, for detailed analysis of these topics we refer to (Weibull, 1997; Leyton-Brown and Shoham, 2008; Sandholm, 2010). GT provides predictive power in interactive decision situations. It has been introduced by Von Neumann and Morgenstern (1944) and in its normal form representation (which is the one we will use in our algorithm) it consists in: a finite set of players I = (1, .., n), a set of pure strategies for each player Si = (s1, ..., sn) and an utility function ui : S1x...xSn —* R which associates strategies to payoffs. The utility function depends on the combination of two strategies played together, not just on the strategy of a single player. An importa</context>
</contexts>
<marker>Weibull, 1997</marker>
<rawString>J¨orgen W. Weibull. 1997. Evolutionary game theory.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhi Zhong</author>
<author>Hwee Tou Ng</author>
</authors>
<title>It Makes Sense: A Wide-Coverage Word Sense Disambiguation System for Free Text.</title>
<date>2010</date>
<booktitle>In Proceedings of the ACL 2010 System Demonstrations,</booktitle>
<pages>78--83</pages>
<contexts>
<context position="1258" citStr="Zhong and Ng, 2010" startWordPosition="200" endWordPosition="203">he dynamics of the system are formulated in terms of a non-cooperative multiplayer game, where the players are the data points to decide their class memberships and equilibria correspond to consistent labeling of the data. 1 Introduction Word sense disambiguation (WSD) is the task to identify the intended sense of a word in a computational manner based on the context in which it appears (Navigli, 2009). It has been studied since the beginning of NLP (Weaver, 1955) and also today it is a central topic of this discipline. Many algorithms have been proposed during the years, based on supervised (Zhong and Ng, 2010; Tratz et al., 2007), semi-supervised (Pham et al., 2005) and unsupervised (Mihalcea, 2005; McCarthy et al., 2007) learning models. Nowadays, even if supervised methods perform better in general domains, unsupervised and semi-supervised models are gaining attention from the research community with performances close to the state of the art (Ponzetto and Navigli, 2010). In particular Knowledge-based and graph based algorithms are emerging as interesting ways to face the problem (Agirre et al., 2009; Sinha and Mihalcea, 2007). The peculiarities of those algorithms are that they do not require a</context>
</contexts>
<marker>Zhong, Ng, 2010</marker>
<rawString>Zhi Zhong and Hwee Tou Ng. 2010. It Makes Sense: A Wide-Coverage Word Sense Disambiguation System for Free Text. In Proceedings of the ACL 2010 System Demonstrations, pages 78–83.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>