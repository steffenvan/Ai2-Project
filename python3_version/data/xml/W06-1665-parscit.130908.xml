<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.992252">
Context-Dependent Term Relations for Information Retrieval
</title>
<author confidence="0.947806">
Jing Bai Jian-Yun Nie Guihong Cao
</author>
<affiliation confidence="0.933896">
DIRO, University of Montreal
</affiliation>
<address confidence="0.842089">
CP. 6128, succ. Centre-ville, Montreal,
Quebec H3C 3J7, Canada
</address>
<email confidence="0.998255">
{baijing,nie,caogui}@iro.umontreal.ca
</email>
<sectionHeader confidence="0.99738" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999814863636364">
Co-occurrence analysis has been used to
determine related words or terms in many
NLP-related applications such as query
expansion in Information Retrieval (IR).
However, related words are usually
determined with respect to a single word,
without relevant information for its
application context. For example, the word
“programming” may be considered to be
strongly related to “Java”, and applied
inappropriately to expand a query on “Java
travel”. To solve this problem, we propose
to add another context word in the relation
to specify the appropriate context of the
relation, leading to term relations of the
form “(Java, travel) → Indonesia”. The
extracted relations are used for query
expansion in IR. Our experiments on
several TREC collections show that this
new type of context-dependent relations
performs much better than the traditional
co-occurrence relations.
</bodyText>
<sectionHeader confidence="0.999014" genericHeader="keywords">
1. Introduction
</sectionHeader>
<bodyText confidence="0.999969086206897">
A query usually is a poor expression of an
information need. This is not only due to its short
length (usually a few words), but also due to the
inability of users to provide the best terms to
describe their information need. At best, one can
expect that some, but not all, relevant terms are
used in the query. Query expansion thus aims to
improve query expression by adding related
terms to the query. However, the effect of query
expansion is strongly determined by the term
relations used (Peat and Willett, 1991). For
example, even if “programming” is strongly
related to “Java”, if this relation is used to
expand a query on “Java travel”, the retrieval
result will likely deteriorate because the
irrelevant term “programming” is introduced,
leading to the retrieval of irrelevant documents
about “programming”.
A number of attempts have been made to deal
with the problem of selecting appropriate
expansion terms. For example, Wordnet has been
used in (Voorhees, 1994) to determine the
expansion terms. However, the experiments did
not show improvement on retrieval effectiveness.
Many experiments have been carried out using
associative relations extracted from term co-
occurrences; but they showed variable results
(Peat and Willett, 1991). In (Qiu and Frei, 1993),
it is observed that one of the reasons is that one
tried to determine expansion terms according to
each original query term separately, which may
introduce much noise. Therefore, they proposed
to determine the expansion terms by summing up
the relations of a candidate expansion term to
each of the query terms. In so doing, a candidate
expansion term is preferred if it has a strong
relationship with many of the query terms.
However, it is still difficult to prevent the
expansion process from adding “programming”
to a query on “Java travel” because of its very
strong relation with “Java”.
The approach used in (Qiu and Frei, 1993)
indeed tries to correct a handicap inherent in the
relations: as term relations are created between
two single words such as “Java →
programming”, no information is available to
help determine the appropriate context to apply
it. The approach used in (Qiu and Frei, 1993) can
simply alleviate the problem without solving it
radically.
In this paper, we argue that the solution lies in
the relations themselves. They have to contain
more information to help determine the
appropriate context to apply them. We thus
propose a way to add some context information
into the relations: we introduce an additional
word into the condition part of the relation, such
as “(Java, computer) → programming”, which
</bodyText>
<page confidence="0.989752">
551
</page>
<note confidence="0.8631135">
Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP 2006), pages 551–559,
Sydney, July 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.992264952380952">
means “programming” is related to “(Java,
computer)” together. In so doing, we would be
able to prevent from extracting and applying a
relation such as “(Java, travel) →
programming”.
In this paper, we will test the extracted
relations in query expansion for IR. We choose to
implement query expansion within the language
modeling (LM) framework because of its
flexibility and high performance. The
experiments on several TREC collections will
show that our query expansion approach can
bring large improvements in retrieval
effectiveness.
In the following sections, we will first review
some of the relevant approaches on query
expansion and term relation extraction. Then we
will describe our general IR models and the
extraction of term relations. The experimental
results will be reported and finally some
conclusions will be drawn.
</bodyText>
<sectionHeader confidence="0.832387" genericHeader="introduction">
2. Query Expansion and Term Relations
</sectionHeader>
<bodyText confidence="0.999893811764706">
It has been found that a key factor that
determines the effect of query expansion is the
selection of appropriate expansion terms (Peat
and Willett, 1991). To determine expansion
terms, one possible resource is thesauri
constructed manually, such as Wordnet. Thesauri
contain manually validated relations between
terms, which can be used to suggest related
terms. (Voorhees, 1994) carried out a series of
experiments on selecting related terms (e.g.
synonyms, hyonyms, etc.) from Wordnet.
However, the experiments did not show that this
can improve retrieval effectiveness. Some of the
reasons are as follows: Although Wordnet
contains many relations validated by human
experts, the coverage is far from complete for the
purposes of IR: not only linguistically motivated
relations, but also association relations, are useful
in IR. Another problem is the lack of information
about the appropriate context to apply relations.
For example, Wordnet contains two synsets for
“computer”, one for the sense of “machine” and
another for “human expert”. It is difficult to
automatically select the correct synset to expand
the word “computer” even if we know that the
query’s area is computer science.
Another often used resource is associative
relations extracted from co-occurrences: two
terms that co-occur frequently are thought to be
associated to each other (Jing and Croft, 1994).
However, co-occurrence relations are noisy:
Frequently co-occurring terms are not necessarily
related. On the other hand, they can also miss
true relations. The most important problem is still
that of ambiguity: when one term is associated
with another, it may be related for one sense and
not for other possible senses. It is then difficult to
determine when the relation applies.
In most of the previous studies, relations
extracted are restricted between one word and
another. This limitation makes the relations
ambiguous, and their utilization in query
expansion often introduces undesired terms. We
believe that the key to make a relation less
ambiguous is to add some contextual
information.
In an attempt to select better expansion terms,
(Qiu and Frei, 1993) proposed the following
approach to select expansion terms: terms are
selected according to their relation to the whole
query, which is calculated as the sum of their
relations to each of the query terms. Therefore, a
term that is related to several query terms will be
favored. In a similar vein, (Bai et al. 2005) also
try to determine the relationship of a word to a
group of words by combining its relationships to
each of the words in the group. This can indeed
select better expansion terms. The consideration
of other query terms produces a weak contextual
effect. However, this effect is limited due to the
nature of the relations extracted, in which a term
depends on only one other term. Much of the
noise in the sets will remain after selection.
For a query composed of several words, what
we would really like to have is a set of terms that
are related to all the words taken together (and
not separately). By combining words in the
condition part such as “(Java, travel)” or “(base,
bat)”, each word will serve as a context to the
other in order to constrain the related terms. In
these cases, we would expect that “hotel”,
“island” or “Indonesia” would co-occur much
more often with “(Java, travel)” than
“programming”, and “ball”, “catcher” etc. co-
occur much more often with “(base, bat)” than
“animal” or “foundation”.
One naturally would suggest that compound
terms can be used for this purpose. However, for
many queries, it is difficult to form a legitimate
compound term. Even if we can detect one
occurrence of a compound, we may miss others
that use its variants. For example, if “Java travel”
is used as a query, we will likely be able to
consider it as a compound term. The same
compound (or its variant) would be difficult to
</bodyText>
<page confidence="0.995797">
552
</page>
<bodyText confidence="0.999552179104478">
detect in a document talking about traveling to
Java: the two words may appear at some distance
or not in some specific syntactic structure as
required in (Lin, 1997). This will lead to the
problem of mismatching between document and
query.
In fact, compound terms are not the only way
to add contextual information to a word. By
putting two words together (without forming a
compound term), we usually obtain a more
precise sense for each word. For example, from
“Java travel”, we can guess that the intended
meaning is likely related to “traveling to Java
Island”. People will not interpret this
combination in the sense of “Java
programming”. In the same way, people would
not consider “animal” to be a related term to
“base, bat”. These examples show that in a
combination of words, each word indeed serves
to specify a context to interpret another word. It
then suggests the following approach: we can
adjunct some additional word(s) in the condition
part of a relation, such as “(Java, travel) →
Indonesia”, which means “Indonesia” is related
to “(Java, travel)” together. It is expected that
one would not obtain “(Java, travel) →
programming”.
Owing to the context effect explained above,
we will call the relations with multiple words in
the condition part context-dependent relations. In
order to limit the computation complexity, we
will only consider adding one additional word
into relations.
The proposed approach follows the same
principle as (Yarowsky, 1995), which tried to
determine the appropriate word sense according
to one relevant context word. However, the
requirement for query expansion is less than
word sense disambiguation: we do not need to
know the exact word sense to make expansion.
We only need to determine the relevant
expansion terms. Therefore, there is no need to
determine manually a set of seeds before the
learning process takes place.
To some extent, the proposed approach is also
related to (Schütze and Pedersen, 1997), which
calculate term similarity according to the words
appearing in the same context, or to second-order
co-occurrences. However, a key difference is that
(Schütze and Pedersen, 1997) consider only
separate context words, while we consider
multiple context words together.
Once term relations are determined, they will
be used in query expansion. The basic IR process
will be implemented in a language modeling
framework. This framework is chosen for its
flexibility to integrate term relations. Indeed, the
LM framework has proven to be capable of
integrating term relations and query expansion
(Bai et al., 2005; Berger and Lafferty, 1999; Zhai
and Lafferty, 2001). However, none of the above
studies has investigated the extraction of strong
context-dependent relations from text collections.
In the next section, we will describe the
general LM framework and our query expansion
models. Then the extraction of term relation will
be explained.
</bodyText>
<sectionHeader confidence="0.8307475" genericHeader="method">
3. Context-Dependent Query Expansion
in Language Models
</sectionHeader>
<bodyText confidence="0.9998666">
The basic IR approach based on LM (Ponte and
Croft, 1998) determines the score of relevance of
a document D by its probability to generate the
query Q. By assuming independence between
query terms, we have:
</bodyText>
<equation confidence="0.6654425">
score D Q
( , )=∑ PML (wi  |Q) log P(wi  |D)
w Q
i∈
</equation>
<bodyText confidence="0.96501325">
where P(wi  |D) denotes the probability of a word
in the language model of the document D. As no
ambiguity will arise, we will use D to mean both
the language model of the document and the
document itself (similarly for a query model and
a query Q).
Another score function is based on KL-
divergence or cross entropy between the
document model and the query model:
score (D, Q)
where
the vocabulary. Although we have
both document and query models in the above
formulation, usually only the document model is
smoothed, while the query model uses Maximum
Likeli
</bodyText>
<equation confidence="0.936728">
V is
hood Estimation (MLE) PML(wi  |Q) . Then
we have:
</equation>
<bodyText confidence="0.9994672">
However, it is obvious that a distance (KL-
divergence) measured between a short query of a
few words and a document cannot be precise. A
better expression would contain all the related
terms. The construction of a better query
expression is the very motivation for query
expansion in traditional IR systems. It is the same
in LM for IR: to create a better query expression
(model) to be able to measure the distan
ce to a
</bodyText>
<equation confidence="0.939380066666667">
P Q D
(  |) = P(wi  |D) ∝ log P(wi  |D)
∏
∑
=∑ P(wi  |Q) log P(wi  |D)
w V
i∈
∈
∈
w
i
i
Q
Q
w
</equation>
<page confidence="0.978735">
553
</page>
<bodyText confidence="0.999830333333333">
document in a more precise way. The key to
creating the new model is the integration of term
relations.
</bodyText>
<subsectionHeader confidence="0.96832">
3.1 LM for Query Expansion
</subsectionHeader>
<bodyText confidence="0.99974425">
Term relations have been used in several recent
language models in IR. (Berger and Lafferty,
1999) proposed a translation model that expands
the document model. The same approach can also
be used to expand the query model. Following
(Berger and Lafferty, 1999), we arrive at the first
expansion model as follows, which has also been
used in (Bai et al., 2005):
</bodyText>
<sectionHeader confidence="0.4708845" genericHeader="method">
Model 1: Context-independent query
expansion model (CIQE)
</sectionHeader>
<subsectionHeader confidence="0.290198">
PR (wi|Q)= ∑PR(wi,qj |Q)=∑PR(wi  |qj)PML(qj |Q)
</subsectionHeader>
<bodyText confidence="0.970135153846154">
q j ∈ V q j ∈ Q
In this model, each original query term qj is
expanded by related terms wi. The relations
between them are determined by PR (wi  |qj) . We
will explain how this probability is defined in
Section 3.2. However, we can already see here
that wi is determined solely by one of the query
term qj. So, we call this model “context-
independent query expansion model” (CIQE).
The above expanded query model enables us
to obtain new related expansion terms, to which
we also have to add the original query. This can
be obtained through the following smoothing:
</bodyText>
<equation confidence="0.914802">
P(wi  |Q) = λ1 PML (wi  |Q) +
(1 − λ1 ) R wi  |qj)PML(qj |Q) (1)
∑ P (
qj
</equation>
<bodyText confidence="0.9986542">
where λ1 is a smoothing parameter.
However, if the query model is expanded on
all the vocabulary (V), the query evaluation will
be very time consuming because the query and
the document have to be compared on every word
(dimension). In practice, we observe that only a
small number of terms have strong relations with
a given term, and the terms having weak relations
usually are not truly related. So we can limit the
expansion terms only to the strongly related ones.
By doing this, we can also expect to filter out
some noise and considerably reduce the retrieval
time.
Suppose that we have selected a set E of
strong expansion terms. Then we have:
</bodyText>
<subsectionHeader confidence="0.336309">
score D Q
</subsectionHeader>
<bodyText confidence="0.951071029411765">
( , )
This query expansion method uses the same
principle as (Qiu and Frei, 1993), but in a LM
setting: the selected expansion terms are those
that are strongly related to all the query terms
(this is what the summation means). The
approach used in (Bai et al., 2005) is slightly
different: A context vector is first built for each
word; then a context vector for a group of words
(e.g. a multi-word query) is composed from the
context vectors of the words of the group; finally
related terms to the group of words are
determined according to the similarity of their
context vectors to that of the group. This last step
uses second-order co-occurrences similarly to
(Schütze and Pedersen, 1997). In both (Qiu and
Frei, 1993) and (Bai et al., 2005), the terms
related to a group of words are determined from
their relations to each of the words in the group,
while the latter relations are extracted separately.
Irrelevant expansion terms can be retained.
As we showed earlier, in many cases, when
one additional word is used with another word,
the sense of each of them can usually be better
determined. This additional word may be
sufficient to interpret correctly many multi-word
user queries. Therefore, our goal is to extract
stronger context-dependent relations of the form
(qj qk) → wi, or to build a probability
functionPR(wi  |qjqk). Once this function is
determined, it can be integrated into a new
language model as follows.
Model 2: Context-dependent query expansion
model (CDQE)
</bodyText>
<equation confidence="0.9829948">
PR(wi  |Q) = ∑PR(wi  |qjqk
P(qjqk  |Q)
q j
,q Q
k∈
</equation>
<bodyText confidence="0.985990727272727">
As PR(wi  |qjqk) is a relation with two terms as
condition, we will also call it a biterm relation.
The name “biterm” is due to (Srikanth and
Srihari, 2002), which means two terms co-
occurring within some distance. Similarly,
PR (wi  |qj) will be called unigram relation. The
corresponding query models will be called biterm
relation model and unigram relation model.
As in general LM, the biterm relation model
can be smoothed with a unigram model. Then we
have the following score function:
</bodyText>
<equation confidence="0.914002944444444">
) ∑ PR (
qj,
+
PR
(wi  |Q
)=λ2PML(wi  |Q)
∈
Q
∑
=
wi∈V
≈ ∑ P(wi  |Q) log P(wi  |D)
w E Q
i∈ ∪
P(wi
|
Q) log P(wi  |D)
) P(qjqk  |Q)
</equation>
<figure confidence="0.88887776">
∈
V
qj,qk
)
≈
qk
(wi
PR
∑
 |qj
(
−
1
λ2
(2)
qk|Q)
i
P
)
w
qk
(q j
|qj
q Q
k ∈
</figure>
<page confidence="0.992437">
554
</page>
<bodyText confidence="0.987095">
where A2 is another smoothing parameter.
</bodyText>
<subsectionHeader confidence="0.997587">
3.2 Extraction of Term Relations
</subsectionHeader>
<bodyText confidence="0.994117944444445">
The key problem now is to obtain the relations
we need: PR (wi  |wj) and PR (wi  |wjwk) . For the first
probability, as in many previous studies, we
exploit term co-occurrences. PR(wi |wj) could be
built as a traditional bigram model. However, this
is not a good approach for IR because two related
terms do not necessarily co-occur side by side.
They often appear at some distance. Therefore,
this model is indeed a biterm model (Srikanth
and Srihari, 2002), i.e., we allow two terms be
separated within some distance. We use the
following formula to determine this probability:
where c(wi,wj) is the frequency of co-occurrence
of the biterm (wi , w j) , i.e. two terms in the same
window of fixed size across the collection. In our
case, we set the window size at 10 (because this
size turned out to be reasonable in our pilot
experiments).
</bodyText>
<subsectionHeader confidence="0.884586">
For P(wi |wjwk), we further extend the biterm
</subsectionHeader>
<bodyText confidence="0.974230666666667">
to triterm, and we use the frequency of co-
occurrences of three terms c(wi , wj , wk) within the
same windows in the document collection:
</bodyText>
<subsubsectionHeader confidence="0.496301">
PR(wi  |wjwO
</subsubsectionHeader>
<bodyText confidence="0.963591444444444">
The number of relations determined in this
way can be very large. The upper bound for
P(wi  |wj) and P(wi  |wj wk ) are respectively
O(|V|2) and O(|V|3). However, many relations
have very low probabilities and are often noise.
As we only consider a subset of strong expansion
terms, the relations with low probability are
almost never used. Therefore, we set two filtering
criteria:
</bodyText>
<listItem confidence="0.865227">
• The biterm in the condition of a relation should
be higher than a threshold (10 in our case);
• The probability of a relation should be higher
than another threshold (0.0001 in our case).
• One more filtering criterion is mutual
information (MI), which reflects the
relatedness of two terms in their combination
(w j, wk) . To keep a relation P(wi  |w j wk) , we
</listItem>
<bodyText confidence="0.972268363636364">
require (w j , wk) be a meaningful combination.
We use the following pointwise MI (Church
and Hanks 1989):
We only keep meaningful combinations such
that MI(wj,wk)&gt;0.
By these filtering criteria, we are able to
reduce considerably the number of biterms and
triterms. For example, on a collection of about
200MB, with a vocabulary size of about 148K,
we selected only about 2.7M useful biterms and
about 137M triterms, which remain tractable.
</bodyText>
<subsectionHeader confidence="0.999864">
3.3 Probability of Biterms
</subsectionHeader>
<bodyText confidence="0.943962375">
In LM used in IR, each query term is attributed
the same weight. This is equivalent to a uniform
probability distribution, i.e.:
i|Q)=|Q
where |Q|U is the number of unigrams in the
query. In CIQE model, we use the same method.
In CDQE, we also need to attribute a
probability P(q jqk  |Q) , to the biterm (q j, qk) .
</bodyText>
<subsectionHeader confidence="0.601908">
Several options are possible.
Uniform probability
</subsectionHeader>
<bodyText confidence="0.9870165">
This simple approach distributes the probability
uniformly among all biterms in the query, i.e.:
</bodyText>
<figure confidence="0.511897333333333">
P(q jqk|Q)=|Q
1
|B
</figure>
<bodyText confidence="0.990787769230769">
where  |Q |B is the number of biterms in Q.
According to mutual information
In a query, if two words are strongly associated,
this also means that their association is more
meaningful to the query, thus should be weighted
higher. Therefore, a natural way to assign a
probability to a biterm in the query is to use
mutual information, which denotes the strength
of association between two words. We use again
the pointwise mutual information MI(qj, qk). If it
is negative, we consider that the biterm is not
meaningful, and is ignored. Therefore, we arrive
at the following probability function:
</bodyText>
<subsectionHeader confidence="0.847175">
P(q jqk  |Q)
</subsectionHeader>
<bodyText confidence="0.9964915">
where (qlqm) E Q means all the meaningful
biterms in the query.
</bodyText>
<figure confidence="0.977403957446808">
)
c(wi,wj
)
c(wl , w j
∑
wl
MI(wj,wk)=log
P(wj)P(wk)
,
)
wk
P(wj
)
=
PR
(wi  |w j
,
,
)
wk
c(wi
=
wj
,
,
)
wj
wk
∑ ( l
c w
wl
P(q
1
|U
,
MI
)
qk
=
(qj
,
MI
)
qm
(ql
∑
(qlqm)EQ
</figure>
<page confidence="0.98661">
555
</page>
<subsectionHeader confidence="0.944805">
Statistical parsing
</subsectionHeader>
<bodyText confidence="0.999980933333333">
In (Gao et al., 2002), a statistical parsing
approach is used to determine the best
combination of translation words for a query. The
approach is similar to building a minimal
spanning tree, which is also used in (Smeaton and
Van Rijsbergen, 1983), to select the strongest
term relations that cover the whole query. This
approach can also be used in our model to
determine the minimal set of the strongest
biterms that cover the query.
In our experiments, we tested all the three
weighting schemas. It turns out that the best
weighting is the one with MI. Therefore, in the
next section, we will only report the results with
the second option.
</bodyText>
<sectionHeader confidence="0.996039" genericHeader="method">
4. Experimental Evaluation
</sectionHeader>
<bodyText confidence="0.999437285714286">
We evaluate query expansion with different
relations on four TREC collections, which are
described in Table 1. All documents have been
processed in a standard manner: terms are
stemmed using Porter stemmer and stopwords are
removed. We only use titles of topics as queries,
which contain 3.58 words per query on average.
</bodyText>
<tableCaption confidence="0.998194">
Table 1. TREC collection statistics
</tableCaption>
<table confidence="0.9874889">
Coll. Description Size Vocab. # Doc. Query
(Mb)
AP Associated 491 196,933 164,597 51-100
Press (1988-89)
SJM San Jose 286 146,514 90,257 101-150
Mercury News
(1991)
WSJ Wall Street 242 121,946 74,520 51-100
Journal (1990-
92)
</table>
<bodyText confidence="0.99945825">
In our experiments, the document model
remains the same while the query model changes.
The document model uses the following Dirichlet
smoothing:
</bodyText>
<equation confidence="0.915266">
P(wi  |D) =
|D
|
</equation>
<bodyText confidence="0.996222428571428">
where tf (wi, D) is the term frequency of wi in D,
PML(wi  |C) is the collection model and µ is the
Dirichlet prior, which is set at 1000 following
(Zhai and Lafferty, 2001).
There are two other smoothing parameters λ1 ,
and λ2 to be determined. In our experiments, we
use a simple method to set them: the parameters
are tuned empirically using a training collection
containing AP1989 documents and queries 101-
150. These preliminary tests suggest that the best
value of
and
(in Equations 1-2) are
relatively stable (we will show this later). In the
</bodyText>
<equation confidence="0.99202425">
λ1
λ2
λ1
λ2 = 0.3 .
</equation>
<subsectionHeader confidence="0.99641">
4.1 Experimental Results
</subsectionHeader>
<bodyText confidence="0.999502666666667">
The main experimental results are described in
Table 2, which reports average precision with
different methods as well as the number of
relevant documents retrieved. UM is the basic
unigram model without query expansion (i.e. we
use MLE for the query model, while the
document model is smoothed with Dirichlet
method). CIQE is the context-independent query
expansion model using unigram relations (Model
</bodyText>
<listItem confidence="0.8724566">
1). CDQE is the context-dependent query
expansion model using biterm relations (Model
2). In the table, we also indicate whether the
improvement in average precision obtained is
statistically significant (t-test).
</listItem>
<tableCaption confidence="0.8360885">
Table 2. Avg. precision and Recall
* and ** indicate that the difference is statistically
</tableCaption>
<sectionHeader confidence="0.500256" genericHeader="method">
CIQE and CDQE vs. UM
</sectionHeader>
<bodyText confidence="0.978422375">
It is interesting to observe that query expansion,
either by CIQE or CDQE, consistently
outperforms the basic unigram model on all the
collections. In all the cases except CIQE for
WSJ, the improvements in average precision are
statistically significant. At the same time, the
increases in the number of relevant documents
retrieved are also consistent with those in average
precision.
The improvement scales obtained with CIQE
are relatively small: from 1% to
These
correspond to the typical figure using this
method.
Comparing CIQE and CDQE, we can see that
context-dependent query expan
</bodyText>
<figure confidence="0.42797788">
10%.
sion (CDQE)
tf(wi,D
) +µPML (wi  |C)
U
and experiments reported below, we will use = 0.4,
Coll. UM CIQE CDQE
#Rel.
AP 0.2767 0.2902 (+5%*) 0.3383 (+22%**)
6101 [+17%**]
3677 3897 4029
SJM 0.2017 0.2225 (+10%**) 0.2448 (+21%**)
2559 [+10%*]
1641 1761 1873
WSJ 0.2373 0.2393 (+1%) 0.2710 (+14%**)
2172 [+13%*]
1588 1626 1737
significant according to t-test:
p&lt;0.05, **
indicates p&lt;0.01;
is compared to UM an
* indicates
(.)
d [.] is
compared to CIQE.
</figure>
<page confidence="0.995989">
556
</page>
<bodyText confidence="0.998478666666667">
always produces better effectiveness than
context-independent expansion (CIQE). The
improvements range between 10% and 17%. All
the improvements obtained by CDQE are
statistically significant. This result strongly
suggests that in general, the context-dependent
term relations identify better expansion terms
than context-independent unigram relations. This
confirms our earlier hypothesis.
Indeed, when we look at the expansion
results, we see that the expansion terms
suggested by biterm relations are usually better.
For example, the (stemmed) expansion terms for
the query “insider trading” suggested
respectively by CIQE and CDQE are as follows:
</bodyText>
<table confidence="0.936232">
CIQE: stock:0.0141 market:0.0113 US:0.0112
year:0.0102 exchang:0.0101 trade:0.0092
report:0.0082 price:0.0076 dollar:0.0071
1:0.0069 govern:0.0066 state:0.0065
futur:0.0061 million:0.0061 dai:0.0060
offici:0.0059 peopl:0.0059 york:0.0057
issu:0.0057 ...
CDQE: secur:0.0161 charg:0.0158 stock:0.0137
scandal:0.0128 boeski:0.0125 inform:0.0119
street:0.0113 wall:0.0112 case:0.0106
year:0.0090 million:0.0086 investig:0.0082
exchang:0.0080 govern:0.0077 sec:0.0077
drexel:0.0075 fraud:0.0071 law:0.0063
ivan:0.0060 ...
</table>
<bodyText confidence="0.998946954545454">
We can see that in general, the terms suggested
by CDQE are much more relevant. In particular,
it has been able to suggest “boeski” (Boesky)
who is involved in an insider trading scandal.
Several other terms are also highly relevant, such
as scandal, investing, sec, drexel, fraud, etc.
The addition of these new terms does not only
improve recall. Precision of top-ranked
documents is also improved. This can be seen in
Figure 1 where we compare the full precision-
recall curve for the AP collection for the three
models. We can see that at all the recall levels,
the precision values always follow the following
order: CDQE &gt; UM. The same observation is
also made on the other collections. This shows
that the CDQE method does not increase recall to
the detriment of precision, but both of them. In
contrast, CIQE increases precision at all but 0.0
recall points: the precision at the 0.0 recall point
is 0.6565 for CIQE and 0.6699 for UM. This
shows that CIQE can slightly deteriorate the top-
ranked few documents.
</bodyText>
<figureCaption confidence="0.9199995">
Figure 1. Comparison of three models on AP
CDQE vs. Pseudo-relevance feedback
</figureCaption>
<bodyText confidence="0.998070484848484">
Pseudo-relevance feedback is widely considered
to be an effective query expansion method. In
many previous experiments, it produced very
good results. The mixture model (Zhai and
Lafferty, 2001) is a representative and effective
method to implement pseudo-relevance feedback:
It uses a set of feedback documents to smooth the
original query model. Compared to the mixture
model, our CDQE method is also more effective:
By manually tuning the parameters of the mixture
model to their best, we obtained the average
precisions of 0.3171, 0.2393 and 0.2565
respectively for AP, SJM and WSJ collections.
These values are lower than those obtained with
CDQE, which has not been heavily tuned.
For the same query “insider trading”, the mixture
model determines the following expansion terms:
Mixture: stock:0.0259256 secur:0.0229553
market:0.0157057 sec:0.013992
inform:0.011658 firm:0.0110419
exchang:0.0100346 law:0.00827076
bill:0.007996 case:0.00764544
profit:0.00672575 investor:0.00662856
japan:0.00625859 compani:0.00609675
commiss:0.0059618 foreign:0.00582441
bank:0.00572947 investig:0.00572276
We can see that some of these terms overlap with
those suggested by biterm relations. However,
interesting words such as boeski, drexel and
scandal are not suggested.
The above comparison shows that our method
outperforms the state-of-the-art methods of query
expansion developed so far.
</bodyText>
<subsectionHeader confidence="0.997807">
4.2 Effect of the Smoothing Parameter
</subsectionHeader>
<bodyText confidence="0.9997975">
In the previous experiments, we have fixed the
smoothing parameters. In this series of tests, we
</bodyText>
<figure confidence="0.9986218">
Precision
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
Recall
CDQE
CIQE
UM
</figure>
<page confidence="0.984382">
557
</page>
<bodyText confidence="0.9980624">
analyze the effect of this smoothing parameter on
retrieval effectiveness. The following figure
shows the change of average precision (AvgP)
using CDQE (Model 2) along with the change of
the parameter λ2 (UM is equivalent to λ2 =1).
</bodyText>
<figureCaption confidence="0.996256">
Figure 2. Effectiveness w.r.t. λ2
</figureCaption>
<bodyText confidence="0.997317333333333">
We can see that for all the three collections,
the effectiveness is good when the parameter is
set in the range of 0.1-0.5. The best value for
different collections remains stable: 0.2-0.3.
The effect of λ1 on Model 1 is slightly
different, but we observe the same trend.
</bodyText>
<subsectionHeader confidence="0.997596">
4.3 Number of Expansion Terms
</subsectionHeader>
<bodyText confidence="0.999752333333333">
In the previous tests, we limit the number of
expansion terms to 80. When different numbers
of expansion terms are used, we obtain different
effectiveness measures. The following figure
shows the variation of average precision (AvgP)
with different numbers of expansion terms, using
</bodyText>
<sectionHeader confidence="0.636978" genericHeader="method">
CDQE method.
</sectionHeader>
<figureCaption confidence="0.993215">
Figure 3. Effectiveness w.r.t. #expansion terms
</figureCaption>
<bodyText confidence="0.999965">
We can see that when more expansion terms
are added, the effectiveness does not always
increase. In general, a number around 80 will
produce good results. In some cases, even if
better effectiveness can be obtained with more
expansion terms, the retrieval time is also longer.
The number 80 seems to produce a good
compromise between effectiveness and retrieval
speed: the retrieval time remains less than 1 sec.
per query.
</bodyText>
<subsectionHeader confidence="0.9014925">
4.4 Suitability of Relations Across
Collections
</subsectionHeader>
<bodyText confidence="0.999104928571429">
In many real applications (e.g. Web search), we
do not have a static document collection from
which relations can be extracted. The question is
whether it is possible and beneficial to extract
relations from one text collection and use them to
retrieve documents in another text collection. Our
intuition is that this is possible because the
relations (especially context-dependent relations)
encode general knowledge, which can be applied
to a different collection. In order to show this, we
extracted term relations from each collection, and
applied them on other collections. The following
tables show the effectiveness produced using
respectively unigram and bi-term relations.
</bodyText>
<tableCaption confidence="0.998042">
Table 3. Cross-utilization of relations
</tableCaption>
<table confidence="0.998547833333333">
Rel. Unigram relation Biterm relation
Coll.
AP SJM WSJ AP SJM WSJ
AP 0.2902 0.2803 0.2793 0.3383 0.3057 0.2987
SJM 0.2271 0.2225 0.2267 0.2424 0.2448 0.2453
WSJ 0.2541 0.2445 0.2393 0.2816 0.2636 0.2710
</table>
<bodyText confidence="0.998965357142857">
From this table, we can observe that relations
extracted from any collection are useful to some
degree: they all outperform UM (see Table 2). In
particular, the relations extracted from AP are the
best for almost all the collections. This can be
explained by the larger size and wider coverage
of the AP collection. This suggests that we do not
necessarily need to extract term relations from
the same text collection on which retrieval is
performed. It is possible to extract relations from
a large text collection, and apply them to other
collections. This opens the door to the possibility
of constructing a general relation base for various
document collections.
</bodyText>
<sectionHeader confidence="0.999949" genericHeader="related work">
5. Related Work
</sectionHeader>
<bodyText confidence="0.999910846153846">
Co-occurrence analysis is a common method to
determine term relations. The previous studies
have been limited to relations between two
words, which we called unigram relations. This
expansion approach has been integrated both in
traditional retrieval models (Jing and Croft,
1994) and in LM (Berger and Lafferty 1999). As
we observed, this type of relation will introduce
much noise into the query, leading to unstable
effectiveness.
Several other studies tried to filter out noise
expansion (or translation) terms by considering
the relations between them (Gao et al., 2002;
</bodyText>
<figure confidence="0.997210772727272">
Avg.P
0.35
0.25
0.15
0.3
0.2
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
Lambda
AP
WSJ
SJM
Avg.P
0.35
0.30
0.25
0.20
0.15
10 20 40 80 150 300
No. expansion terms
AP
WSJ
SJM
</figure>
<page confidence="0.990623">
558
</page>
<bodyText confidence="0.99986176">
Jang et al. 1999; Qiu and Frei, 1993; Bai et al.
2005). However, this is insufficient to detect all
the noise. The key issue is the ambiguity of
relations due to the lack of context information in
the relations. In this paper, we proposed a method
to add some context information into relations.
(Lin, 1997) also tries to solve word ambiguity
by adding syntactic dependency as context.
However, our approach does not require
determining syntactic dependency. The principle
of our approach is more similar to (Yarowsky,
1995). Compared to this latter, our approach is
less demanding: we do not need to identify
manually the exact word senses and seed context
words. The process is fully automatic. This
simplification is made possible due to the
requirement for IR: only in-context related words
are required, but not the exact senses.
Our work is also related to (Smadja and
McKeown, 1996), which tries to determine the
translation of collocations. Term combinations or
biterms we used can be viewed as collocations.
Again, there is much less constraint for our
related terms than translations in (Smadja and
McKeown, 1996).
</bodyText>
<sectionHeader confidence="0.999368" genericHeader="conclusions">
6. Conclusions
</sectionHeader>
<bodyText confidence="0.999978678571429">
In many NLP applications such as IR, we need to
determine relations between terms. In most
previous studies, one tries to determine the
related terms to one single term (word). This
makes the resulting relations ambiguous.
Although several approaches have been proposed
to remove afterwards some of the inappropriate
terms, this only affects part of the noise, and
much still remains. In this paper, we argue that
the solution to this problem lies in the addition of
context information in the relations between
terms. We proposed to add another word in the
condition of the relations so as to help constrain
the context of application. Our experiments
confirm that this addition of limited context
information can indeed improve the quality of
term relations and query expansion in IR.
In this paper, we only compared biterm
relations and unigram relations, the general
method can be extended to triterm relations or
more complex relations, provided that they can
be extracted efficiently.
This paper only investigated the utilization of
context-dependent relations in IR. These relations
can be applied in many other tasks, such as
machine translation, word sense disambiguation /
discrimination, and so on. These are some
interesting research work in the future.
</bodyText>
<sectionHeader confidence="0.996457" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999445622641509">
Bai, J., Song, D., Bruza, P., Nie, J. Y. and Cao, G.
2005. Query expansion using term relationships in
language models for information retrieval, ACM
CIKM, pp. 688-695.
Berger, A. and Lafferty, J. 1999. Information retrieval
as statistical translation. ACM SIGIR, pp. 222-229.
Church, K. W. and Hanks, P. 1989. Word association
norms, mutual information, and lexicography. ACL,
Vol. 16, pp. 22-29.
Gao, J., Nie, J.Y., He, H, Chen, W., Zhou, M. 2002.
Resolving query translation ambiguity using a
decaying co-occurrence model and syntactic
dependency relations. ACM SIGIR, pp. 11-15.
Jang, M. G., Myaeng, S. H., and Park, S. Y. 1999.
Using mutual information to resolve query
translation ambiguities and query term weighting.
ACL, pp. 223-229.
Jing, Y. and Croft, W.B. 1994. An association
thesaurus for information retrieval. RIAO, pp. 146-
160.
Lin, D. 1997. Using syntactic dependency as local
context to resolve word sense ambiguity, ACL, pp.
64-71.
Peat, H.J. and Willett, P. 1991. The limitations of term
co-occurrence data for query expansion in document
retrieval systems. JASIS, 42(5): 378-383.
Ponte, J. and Croft, W.B. 1998. A language modeling
approach to information retrieval. ACM SIGIR, pp.
275-281.
Qiu, Y. and Frei, H.P. 1993. Concept based query
expansion. ACM SIGIR, pp.160-169.
Schütze, H. and Pedersen J.O. 1997. A cooccurrence-
based thesaurus and two applications to information
retrieval, Information Processing and Management,
33(3): 307-318.
Smeaton, A. F. and Van Rijsbergen, C. J. 1983. The
retrieval effects of query expansion on a feedback
document retrieval system. Computer Journal, 26(3):
239-246.
Smadja, F., McKeown, K.R., 1996. Translating
collocations for bilingual lexicons: A statistical
approach, Computational Linguistics, 22(1): 1-38.
Srikanth, M. and Srihari, R. 2002. Biterm language
models for document retrieval. ACM SIGIR, pp. 425-
426
Voorhees, E. 1994. Query expansion using lexical-
semantic relations. ACM SIGIR, pp. 61-69.
Yarowsky, D. 1995. Unsupervised word sense
disambiguation rivaling supervised methods. ACL,
pp. 189-196.
Zhai, C. and Lafferty, J. 2001. Model-based feedback
in the language modeling approach to information
retrieval. ACM SIGIR, pp. 403-410.
</reference>
<page confidence="0.998623">
559
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.820759">
<title confidence="0.994273">Context-Dependent Term Relations for Information Retrieval</title>
<author confidence="0.994147">Jing Bai Jian-Yun Nie Guihong</author>
<affiliation confidence="0.9285365">DIRO, University of CP. 6128, succ. Centre-ville,</affiliation>
<address confidence="0.951513">Quebec H3C 3J7,</address>
<email confidence="0.995587">baijing@iro.umontreal.ca</email>
<email confidence="0.995587">nie@iro.umontreal.ca</email>
<email confidence="0.995587">caogui@iro.umontreal.ca</email>
<abstract confidence="0.999451391304348">Co-occurrence analysis has been used to determine related words or terms in many NLP-related applications such as query expansion in Information Retrieval (IR). However, related words are usually determined with respect to a single word, without relevant information for its application context. For example, the word may be considered to be related to and applied to expand a query on To solve this problem, we propose to add another context word in the relation to specify the appropriate context of the relation, leading to term relations of the The extracted relations are used for query expansion in IR. Our experiments on several TREC collections show that this new type of context-dependent relations performs much better than the traditional co-occurrence relations.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Bai</author>
<author>D Song</author>
<author>P Bruza</author>
<author>J Y Nie</author>
<author>G Cao</author>
</authors>
<title>Query expansion using term relationships in language models for information retrieval,</title>
<date>2005</date>
<journal>ACM CIKM,</journal>
<pages>688--695</pages>
<contexts>
<context position="7256" citStr="Bai et al. 2005" startWordPosition="1129" endWordPosition="1132"> and another. This limitation makes the relations ambiguous, and their utilization in query expansion often introduces undesired terms. We believe that the key to make a relation less ambiguous is to add some contextual information. In an attempt to select better expansion terms, (Qiu and Frei, 1993) proposed the following approach to select expansion terms: terms are selected according to their relation to the whole query, which is calculated as the sum of their relations to each of the query terms. Therefore, a term that is related to several query terms will be favored. In a similar vein, (Bai et al. 2005) also try to determine the relationship of a word to a group of words by combining its relationships to each of the words in the group. This can indeed select better expansion terms. The consideration of other query terms produces a weak contextual effect. However, this effect is limited due to the nature of the relations extracted, in which a term depends on only one other term. Much of the noise in the sets will remain after selection. For a query composed of several words, what we would really like to have is a set of terms that are related to all the words taken together (and not separatel</context>
<context position="11274" citStr="Bai et al., 2005" startWordPosition="1798" endWordPosition="1801">), which calculate term similarity according to the words appearing in the same context, or to second-order co-occurrences. However, a key difference is that (Schütze and Pedersen, 1997) consider only separate context words, while we consider multiple context words together. Once term relations are determined, they will be used in query expansion. The basic IR process will be implemented in a language modeling framework. This framework is chosen for its flexibility to integrate term relations. Indeed, the LM framework has proven to be capable of integrating term relations and query expansion (Bai et al., 2005; Berger and Lafferty, 1999; Zhai and Lafferty, 2001). However, none of the above studies has investigated the extraction of strong context-dependent relations from text collections. In the next section, we will describe the general LM framework and our query expansion models. Then the extraction of term relation will be explained. 3. Context-Dependent Query Expansion in Language Models The basic IR approach based on LM (Ponte and Croft, 1998) determines the score of relevance of a document D by its probability to generate the query Q. By assuming independence between query terms, we have: sco</context>
<context position="13537" citStr="Bai et al., 2005" startWordPosition="2209" endWordPosition="2212">ble to measure the distan ce to a P Q D ( |) = P(wi |D) ∝ log P(wi |D) ∏ ∑ =∑ P(wi |Q) log P(wi |D) w V i∈ ∈ ∈ w i i Q Q w 553 document in a more precise way. The key to creating the new model is the integration of term relations. 3.1 LM for Query Expansion Term relations have been used in several recent language models in IR. (Berger and Lafferty, 1999) proposed a translation model that expands the document model. The same approach can also be used to expand the query model. Following (Berger and Lafferty, 1999), we arrive at the first expansion model as follows, which has also been used in (Bai et al., 2005): Model 1: Context-independent query expansion model (CIQE) PR (wi|Q)= ∑PR(wi,qj |Q)=∑PR(wi |qj)PML(qj |Q) q j ∈ V q j ∈ Q In this model, each original query term qj is expanded by related terms wi. The relations between them are determined by PR (wi |qj) . We will explain how this probability is defined in Section 3.2. However, we can already see here that wi is determined solely by one of the query term qj. So, we call this model “contextindependent query expansion model” (CIQE). The above expanded query model enables us to obtain new related expansion terms, to which we also have to add the</context>
<context position="15208" citStr="Bai et al., 2005" startWordPosition="2515" endWordPosition="2518"> with a given term, and the terms having weak relations usually are not truly related. So we can limit the expansion terms only to the strongly related ones. By doing this, we can also expect to filter out some noise and considerably reduce the retrieval time. Suppose that we have selected a set E of strong expansion terms. Then we have: score D Q ( , ) This query expansion method uses the same principle as (Qiu and Frei, 1993), but in a LM setting: the selected expansion terms are those that are strongly related to all the query terms (this is what the summation means). The approach used in (Bai et al., 2005) is slightly different: A context vector is first built for each word; then a context vector for a group of words (e.g. a multi-word query) is composed from the context vectors of the words of the group; finally related terms to the group of words are determined according to the similarity of their context vectors to that of the group. This last step uses second-order co-occurrences similarly to (Schütze and Pedersen, 1997). In both (Qiu and Frei, 1993) and (Bai et al., 2005), the terms related to a group of words are determined from their relations to each of the words in the group, while the</context>
<context position="32322" citStr="Bai et al. 2005" startWordPosition="5332" endWordPosition="5335">ansion approach has been integrated both in traditional retrieval models (Jing and Croft, 1994) and in LM (Berger and Lafferty 1999). As we observed, this type of relation will introduce much noise into the query, leading to unstable effectiveness. Several other studies tried to filter out noise expansion (or translation) terms by considering the relations between them (Gao et al., 2002; Avg.P 0.35 0.25 0.15 0.3 0.2 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Lambda AP WSJ SJM Avg.P 0.35 0.30 0.25 0.20 0.15 10 20 40 80 150 300 No. expansion terms AP WSJ SJM 558 Jang et al. 1999; Qiu and Frei, 1993; Bai et al. 2005). However, this is insufficient to detect all the noise. The key issue is the ambiguity of relations due to the lack of context information in the relations. In this paper, we proposed a method to add some context information into relations. (Lin, 1997) also tries to solve word ambiguity by adding syntactic dependency as context. However, our approach does not require determining syntactic dependency. The principle of our approach is more similar to (Yarowsky, 1995). Compared to this latter, our approach is less demanding: we do not need to identify manually the exact word senses and seed cont</context>
</contexts>
<marker>Bai, Song, Bruza, Nie, Cao, 2005</marker>
<rawString>Bai, J., Song, D., Bruza, P., Nie, J. Y. and Cao, G. 2005. Query expansion using term relationships in language models for information retrieval, ACM CIKM, pp. 688-695.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Berger</author>
<author>J Lafferty</author>
</authors>
<title>Information retrieval as statistical translation.</title>
<date>1999</date>
<journal>ACM SIGIR,</journal>
<pages>222--229</pages>
<contexts>
<context position="11301" citStr="Berger and Lafferty, 1999" startWordPosition="1802" endWordPosition="1805"> term similarity according to the words appearing in the same context, or to second-order co-occurrences. However, a key difference is that (Schütze and Pedersen, 1997) consider only separate context words, while we consider multiple context words together. Once term relations are determined, they will be used in query expansion. The basic IR process will be implemented in a language modeling framework. This framework is chosen for its flexibility to integrate term relations. Indeed, the LM framework has proven to be capable of integrating term relations and query expansion (Bai et al., 2005; Berger and Lafferty, 1999; Zhai and Lafferty, 2001). However, none of the above studies has investigated the extraction of strong context-dependent relations from text collections. In the next section, we will describe the general LM framework and our query expansion models. Then the extraction of term relation will be explained. 3. Context-Dependent Query Expansion in Language Models The basic IR approach based on LM (Ponte and Croft, 1998) determines the score of relevance of a document D by its probability to generate the query Q. By assuming independence between query terms, we have: score D Q ( , )=∑ PML (wi |Q) </context>
<context position="13276" citStr="Berger and Lafferty, 1999" startWordPosition="2164" endWordPosition="2167">nnot be precise. A better expression would contain all the related terms. The construction of a better query expression is the very motivation for query expansion in traditional IR systems. It is the same in LM for IR: to create a better query expression (model) to be able to measure the distan ce to a P Q D ( |) = P(wi |D) ∝ log P(wi |D) ∏ ∑ =∑ P(wi |Q) log P(wi |D) w V i∈ ∈ ∈ w i i Q Q w 553 document in a more precise way. The key to creating the new model is the integration of term relations. 3.1 LM for Query Expansion Term relations have been used in several recent language models in IR. (Berger and Lafferty, 1999) proposed a translation model that expands the document model. The same approach can also be used to expand the query model. Following (Berger and Lafferty, 1999), we arrive at the first expansion model as follows, which has also been used in (Bai et al., 2005): Model 1: Context-independent query expansion model (CIQE) PR (wi|Q)= ∑PR(wi,qj |Q)=∑PR(wi |qj)PML(qj |Q) q j ∈ V q j ∈ Q In this model, each original query term qj is expanded by related terms wi. The relations between them are determined by PR (wi |qj) . We will explain how this probability is defined in Section 3.2. However, we can a</context>
<context position="31838" citStr="Berger and Lafferty 1999" startWordPosition="5241" endWordPosition="5244">rm relations from the same text collection on which retrieval is performed. It is possible to extract relations from a large text collection, and apply them to other collections. This opens the door to the possibility of constructing a general relation base for various document collections. 5. Related Work Co-occurrence analysis is a common method to determine term relations. The previous studies have been limited to relations between two words, which we called unigram relations. This expansion approach has been integrated both in traditional retrieval models (Jing and Croft, 1994) and in LM (Berger and Lafferty 1999). As we observed, this type of relation will introduce much noise into the query, leading to unstable effectiveness. Several other studies tried to filter out noise expansion (or translation) terms by considering the relations between them (Gao et al., 2002; Avg.P 0.35 0.25 0.15 0.3 0.2 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Lambda AP WSJ SJM Avg.P 0.35 0.30 0.25 0.20 0.15 10 20 40 80 150 300 No. expansion terms AP WSJ SJM 558 Jang et al. 1999; Qiu and Frei, 1993; Bai et al. 2005). However, this is insufficient to detect all the noise. The key issue is the ambiguity of relations due to the lack</context>
</contexts>
<marker>Berger, Lafferty, 1999</marker>
<rawString>Berger, A. and Lafferty, J. 1999. Information retrieval as statistical translation. ACM SIGIR, pp. 222-229.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K W Church</author>
<author>P Hanks</author>
</authors>
<title>Word association norms, mutual information, and lexicography.</title>
<date>1989</date>
<journal>ACL,</journal>
<volume>16</volume>
<pages>22--29</pages>
<contexts>
<context position="19136" citStr="Church and Hanks 1989" startWordPosition="3226" endWordPosition="3229">we only consider a subset of strong expansion terms, the relations with low probability are almost never used. Therefore, we set two filtering criteria: • The biterm in the condition of a relation should be higher than a threshold (10 in our case); • The probability of a relation should be higher than another threshold (0.0001 in our case). • One more filtering criterion is mutual information (MI), which reflects the relatedness of two terms in their combination (w j, wk) . To keep a relation P(wi |w j wk) , we require (w j , wk) be a meaningful combination. We use the following pointwise MI (Church and Hanks 1989): We only keep meaningful combinations such that MI(wj,wk)&gt;0. By these filtering criteria, we are able to reduce considerably the number of biterms and triterms. For example, on a collection of about 200MB, with a vocabulary size of about 148K, we selected only about 2.7M useful biterms and about 137M triterms, which remain tractable. 3.3 Probability of Biterms In LM used in IR, each query term is attributed the same weight. This is equivalent to a uniform probability distribution, i.e.: i|Q)=|Q where |Q|U is the number of unigrams in the query. In CIQE model, we use the same method. In CDQE, </context>
</contexts>
<marker>Church, Hanks, 1989</marker>
<rawString>Church, K. W. and Hanks, P. 1989. Word association norms, mutual information, and lexicography. ACL, Vol. 16, pp. 22-29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Gao</author>
<author>J Y Nie</author>
<author>H He</author>
<author>W Chen</author>
<author>M Zhou</author>
</authors>
<title>Resolving query translation ambiguity using a decaying co-occurrence model and syntactic dependency relations.</title>
<date>2002</date>
<journal>ACM SIGIR,</journal>
<pages>11--15</pages>
<contexts>
<context position="20872" citStr="Gao et al., 2002" startWordPosition="3546" endWordPosition="3549">lity to a biterm in the query is to use mutual information, which denotes the strength of association between two words. We use again the pointwise mutual information MI(qj, qk). If it is negative, we consider that the biterm is not meaningful, and is ignored. Therefore, we arrive at the following probability function: P(q jqk |Q) where (qlqm) E Q means all the meaningful biterms in the query. ) c(wi,wj ) c(wl , w j ∑ wl MI(wj,wk)=log P(wj)P(wk) , ) wk P(wj ) = PR (wi |w j , , ) wk c(wi = wj , , ) wj wk ∑ ( l c w wl P(q 1 |U , MI ) qk = (qj , MI ) qm (ql ∑ (qlqm)EQ 555 Statistical parsing In (Gao et al., 2002), a statistical parsing approach is used to determine the best combination of translation words for a query. The approach is similar to building a minimal spanning tree, which is also used in (Smeaton and Van Rijsbergen, 1983), to select the strongest term relations that cover the whole query. This approach can also be used in our model to determine the minimal set of the strongest biterms that cover the query. In our experiments, we tested all the three weighting schemas. It turns out that the best weighting is the one with MI. Therefore, in the next section, we will only report the results w</context>
<context position="32095" citStr="Gao et al., 2002" startWordPosition="5281" endWordPosition="5284">ous document collections. 5. Related Work Co-occurrence analysis is a common method to determine term relations. The previous studies have been limited to relations between two words, which we called unigram relations. This expansion approach has been integrated both in traditional retrieval models (Jing and Croft, 1994) and in LM (Berger and Lafferty 1999). As we observed, this type of relation will introduce much noise into the query, leading to unstable effectiveness. Several other studies tried to filter out noise expansion (or translation) terms by considering the relations between them (Gao et al., 2002; Avg.P 0.35 0.25 0.15 0.3 0.2 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Lambda AP WSJ SJM Avg.P 0.35 0.30 0.25 0.20 0.15 10 20 40 80 150 300 No. expansion terms AP WSJ SJM 558 Jang et al. 1999; Qiu and Frei, 1993; Bai et al. 2005). However, this is insufficient to detect all the noise. The key issue is the ambiguity of relations due to the lack of context information in the relations. In this paper, we proposed a method to add some context information into relations. (Lin, 1997) also tries to solve word ambiguity by adding syntactic dependency as context. However, our approach does not require de</context>
</contexts>
<marker>Gao, Nie, He, Chen, Zhou, 2002</marker>
<rawString>Gao, J., Nie, J.Y., He, H, Chen, W., Zhou, M. 2002. Resolving query translation ambiguity using a decaying co-occurrence model and syntactic dependency relations. ACM SIGIR, pp. 11-15.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M G Jang</author>
<author>S H Myaeng</author>
<author>S Y Park</author>
</authors>
<title>Using mutual information to resolve query translation ambiguities and query term weighting.</title>
<date>1999</date>
<pages>223--229</pages>
<publisher>ACL,</publisher>
<contexts>
<context position="32284" citStr="Jang et al. 1999" startWordPosition="5324" endWordPosition="5327"> we called unigram relations. This expansion approach has been integrated both in traditional retrieval models (Jing and Croft, 1994) and in LM (Berger and Lafferty 1999). As we observed, this type of relation will introduce much noise into the query, leading to unstable effectiveness. Several other studies tried to filter out noise expansion (or translation) terms by considering the relations between them (Gao et al., 2002; Avg.P 0.35 0.25 0.15 0.3 0.2 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Lambda AP WSJ SJM Avg.P 0.35 0.30 0.25 0.20 0.15 10 20 40 80 150 300 No. expansion terms AP WSJ SJM 558 Jang et al. 1999; Qiu and Frei, 1993; Bai et al. 2005). However, this is insufficient to detect all the noise. The key issue is the ambiguity of relations due to the lack of context information in the relations. In this paper, we proposed a method to add some context information into relations. (Lin, 1997) also tries to solve word ambiguity by adding syntactic dependency as context. However, our approach does not require determining syntactic dependency. The principle of our approach is more similar to (Yarowsky, 1995). Compared to this latter, our approach is less demanding: we do not need to identify manual</context>
</contexts>
<marker>Jang, Myaeng, Park, 1999</marker>
<rawString>Jang, M. G., Myaeng, S. H., and Park, S. Y. 1999. Using mutual information to resolve query translation ambiguities and query term weighting. ACL, pp. 223-229.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Jing</author>
<author>W B Croft</author>
</authors>
<title>An association thesaurus for information retrieval. RIAO,</title>
<date>1994</date>
<pages>146--160</pages>
<contexts>
<context position="6172" citStr="Jing and Croft, 1994" startWordPosition="953" endWordPosition="956">lly motivated relations, but also association relations, are useful in IR. Another problem is the lack of information about the appropriate context to apply relations. For example, Wordnet contains two synsets for “computer”, one for the sense of “machine” and another for “human expert”. It is difficult to automatically select the correct synset to expand the word “computer” even if we know that the query’s area is computer science. Another often used resource is associative relations extracted from co-occurrences: two terms that co-occur frequently are thought to be associated to each other (Jing and Croft, 1994). However, co-occurrence relations are noisy: Frequently co-occurring terms are not necessarily related. On the other hand, they can also miss true relations. The most important problem is still that of ambiguity: when one term is associated with another, it may be related for one sense and not for other possible senses. It is then difficult to determine when the relation applies. In most of the previous studies, relations extracted are restricted between one word and another. This limitation makes the relations ambiguous, and their utilization in query expansion often introduces undesired ter</context>
<context position="31801" citStr="Jing and Croft, 1994" startWordPosition="5234" endWordPosition="5237">ot necessarily need to extract term relations from the same text collection on which retrieval is performed. It is possible to extract relations from a large text collection, and apply them to other collections. This opens the door to the possibility of constructing a general relation base for various document collections. 5. Related Work Co-occurrence analysis is a common method to determine term relations. The previous studies have been limited to relations between two words, which we called unigram relations. This expansion approach has been integrated both in traditional retrieval models (Jing and Croft, 1994) and in LM (Berger and Lafferty 1999). As we observed, this type of relation will introduce much noise into the query, leading to unstable effectiveness. Several other studies tried to filter out noise expansion (or translation) terms by considering the relations between them (Gao et al., 2002; Avg.P 0.35 0.25 0.15 0.3 0.2 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Lambda AP WSJ SJM Avg.P 0.35 0.30 0.25 0.20 0.15 10 20 40 80 150 300 No. expansion terms AP WSJ SJM 558 Jang et al. 1999; Qiu and Frei, 1993; Bai et al. 2005). However, this is insufficient to detect all the noise. The key issue is the a</context>
</contexts>
<marker>Jing, Croft, 1994</marker>
<rawString>Jing, Y. and Croft, W.B. 1994. An association thesaurus for information retrieval. RIAO, pp. 146-160.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lin</author>
</authors>
<title>Using syntactic dependency as local context to resolve word sense ambiguity, ACL,</title>
<date>1997</date>
<pages>64--71</pages>
<contexts>
<context position="8862" citStr="Lin, 1997" startWordPosition="1414" endWordPosition="1415">nimal” or “foundation”. One naturally would suggest that compound terms can be used for this purpose. However, for many queries, it is difficult to form a legitimate compound term. Even if we can detect one occurrence of a compound, we may miss others that use its variants. For example, if “Java travel” is used as a query, we will likely be able to consider it as a compound term. The same compound (or its variant) would be difficult to 552 detect in a document talking about traveling to Java: the two words may appear at some distance or not in some specific syntactic structure as required in (Lin, 1997). This will lead to the problem of mismatching between document and query. In fact, compound terms are not the only way to add contextual information to a word. By putting two words together (without forming a compound term), we usually obtain a more precise sense for each word. For example, from “Java travel”, we can guess that the intended meaning is likely related to “traveling to Java Island”. People will not interpret this combination in the sense of “Java programming”. In the same way, people would not consider “animal” to be a related term to “base, bat”. These examples show that in a c</context>
<context position="32575" citStr="Lin, 1997" startWordPosition="5377" endWordPosition="5378">her studies tried to filter out noise expansion (or translation) terms by considering the relations between them (Gao et al., 2002; Avg.P 0.35 0.25 0.15 0.3 0.2 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Lambda AP WSJ SJM Avg.P 0.35 0.30 0.25 0.20 0.15 10 20 40 80 150 300 No. expansion terms AP WSJ SJM 558 Jang et al. 1999; Qiu and Frei, 1993; Bai et al. 2005). However, this is insufficient to detect all the noise. The key issue is the ambiguity of relations due to the lack of context information in the relations. In this paper, we proposed a method to add some context information into relations. (Lin, 1997) also tries to solve word ambiguity by adding syntactic dependency as context. However, our approach does not require determining syntactic dependency. The principle of our approach is more similar to (Yarowsky, 1995). Compared to this latter, our approach is less demanding: we do not need to identify manually the exact word senses and seed context words. The process is fully automatic. This simplification is made possible due to the requirement for IR: only in-context related words are required, but not the exact senses. Our work is also related to (Smadja and McKeown, 1996), which tries to d</context>
</contexts>
<marker>Lin, 1997</marker>
<rawString>Lin, D. 1997. Using syntactic dependency as local context to resolve word sense ambiguity, ACL, pp. 64-71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H J Peat</author>
<author>P Willett</author>
</authors>
<title>The limitations of term co-occurrence data for query expansion in document retrieval systems.</title>
<date>1991</date>
<journal>JASIS,</journal>
<volume>42</volume>
<issue>5</issue>
<pages>378--383</pages>
<contexts>
<context position="1637" citStr="Peat and Willett, 1991" startWordPosition="248" endWordPosition="251">xt-dependent relations performs much better than the traditional co-occurrence relations. 1. Introduction A query usually is a poor expression of an information need. This is not only due to its short length (usually a few words), but also due to the inability of users to provide the best terms to describe their information need. At best, one can expect that some, but not all, relevant terms are used in the query. Query expansion thus aims to improve query expression by adding related terms to the query. However, the effect of query expansion is strongly determined by the term relations used (Peat and Willett, 1991). For example, even if “programming” is strongly related to “Java”, if this relation is used to expand a query on “Java travel”, the retrieval result will likely deteriorate because the irrelevant term “programming” is introduced, leading to the retrieval of irrelevant documents about “programming”. A number of attempts have been made to deal with the problem of selecting appropriate expansion terms. For example, Wordnet has been used in (Voorhees, 1994) to determine the expansion terms. However, the experiments did not show improvement on retrieval effectiveness. Many experiments have been ca</context>
<context position="4948" citStr="Peat and Willett, 1991" startWordPosition="769" endWordPosition="772">ents on several TREC collections will show that our query expansion approach can bring large improvements in retrieval effectiveness. In the following sections, we will first review some of the relevant approaches on query expansion and term relation extraction. Then we will describe our general IR models and the extraction of term relations. The experimental results will be reported and finally some conclusions will be drawn. 2. Query Expansion and Term Relations It has been found that a key factor that determines the effect of query expansion is the selection of appropriate expansion terms (Peat and Willett, 1991). To determine expansion terms, one possible resource is thesauri constructed manually, such as Wordnet. Thesauri contain manually validated relations between terms, which can be used to suggest related terms. (Voorhees, 1994) carried out a series of experiments on selecting related terms (e.g. synonyms, hyonyms, etc.) from Wordnet. However, the experiments did not show that this can improve retrieval effectiveness. Some of the reasons are as follows: Although Wordnet contains many relations validated by human experts, the coverage is far from complete for the purposes of IR: not only linguist</context>
</contexts>
<marker>Peat, Willett, 1991</marker>
<rawString>Peat, H.J. and Willett, P. 1991. The limitations of term co-occurrence data for query expansion in document retrieval systems. JASIS, 42(5): 378-383.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Ponte</author>
<author>W B Croft</author>
</authors>
<title>A language modeling approach to information retrieval.</title>
<date>1998</date>
<journal>ACM SIGIR,</journal>
<pages>275--281</pages>
<contexts>
<context position="11721" citStr="Ponte and Croft, 1998" startWordPosition="1866" endWordPosition="1869">s chosen for its flexibility to integrate term relations. Indeed, the LM framework has proven to be capable of integrating term relations and query expansion (Bai et al., 2005; Berger and Lafferty, 1999; Zhai and Lafferty, 2001). However, none of the above studies has investigated the extraction of strong context-dependent relations from text collections. In the next section, we will describe the general LM framework and our query expansion models. Then the extraction of term relation will be explained. 3. Context-Dependent Query Expansion in Language Models The basic IR approach based on LM (Ponte and Croft, 1998) determines the score of relevance of a document D by its probability to generate the query Q. By assuming independence between query terms, we have: score D Q ( , )=∑ PML (wi |Q) log P(wi |D) w Q i∈ where P(wi |D) denotes the probability of a word in the language model of the document D. As no ambiguity will arise, we will use D to mean both the language model of the document and the document itself (similarly for a query model and a query Q). Another score function is based on KLdivergence or cross entropy between the document model and the query model: score (D, Q) where the vocabulary. Alt</context>
</contexts>
<marker>Ponte, Croft, 1998</marker>
<rawString>Ponte, J. and Croft, W.B. 1998. A language modeling approach to information retrieval. ACM SIGIR, pp. 275-281.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Qiu</author>
<author>H P Frei</author>
</authors>
<title>Concept based query expansion.</title>
<date>1993</date>
<journal>ACM SIGIR,</journal>
<pages>160--169</pages>
<contexts>
<context position="2392" citStr="Qiu and Frei, 1993" startWordPosition="361" endWordPosition="364">rieval result will likely deteriorate because the irrelevant term “programming” is introduced, leading to the retrieval of irrelevant documents about “programming”. A number of attempts have been made to deal with the problem of selecting appropriate expansion terms. For example, Wordnet has been used in (Voorhees, 1994) to determine the expansion terms. However, the experiments did not show improvement on retrieval effectiveness. Many experiments have been carried out using associative relations extracted from term cooccurrences; but they showed variable results (Peat and Willett, 1991). In (Qiu and Frei, 1993), it is observed that one of the reasons is that one tried to determine expansion terms according to each original query term separately, which may introduce much noise. Therefore, they proposed to determine the expansion terms by summing up the relations of a candidate expansion term to each of the query terms. In so doing, a candidate expansion term is preferred if it has a strong relationship with many of the query terms. However, it is still difficult to prevent the expansion process from adding “programming” to a query on “Java travel” because of its very strong relation with “Java”. The </context>
<context position="6941" citStr="Qiu and Frei, 1993" startWordPosition="1074" endWordPosition="1077">lations. The most important problem is still that of ambiguity: when one term is associated with another, it may be related for one sense and not for other possible senses. It is then difficult to determine when the relation applies. In most of the previous studies, relations extracted are restricted between one word and another. This limitation makes the relations ambiguous, and their utilization in query expansion often introduces undesired terms. We believe that the key to make a relation less ambiguous is to add some contextual information. In an attempt to select better expansion terms, (Qiu and Frei, 1993) proposed the following approach to select expansion terms: terms are selected according to their relation to the whole query, which is calculated as the sum of their relations to each of the query terms. Therefore, a term that is related to several query terms will be favored. In a similar vein, (Bai et al. 2005) also try to determine the relationship of a word to a group of words by combining its relationships to each of the words in the group. This can indeed select better expansion terms. The consideration of other query terms produces a weak contextual effect. However, this effect is limi</context>
<context position="15022" citStr="Qiu and Frei, 1993" startWordPosition="2481" endWordPosition="2484">ill be very time consuming because the query and the document have to be compared on every word (dimension). In practice, we observe that only a small number of terms have strong relations with a given term, and the terms having weak relations usually are not truly related. So we can limit the expansion terms only to the strongly related ones. By doing this, we can also expect to filter out some noise and considerably reduce the retrieval time. Suppose that we have selected a set E of strong expansion terms. Then we have: score D Q ( , ) This query expansion method uses the same principle as (Qiu and Frei, 1993), but in a LM setting: the selected expansion terms are those that are strongly related to all the query terms (this is what the summation means). The approach used in (Bai et al., 2005) is slightly different: A context vector is first built for each word; then a context vector for a group of words (e.g. a multi-word query) is composed from the context vectors of the words of the group; finally related terms to the group of words are determined according to the similarity of their context vectors to that of the group. This last step uses second-order co-occurrences similarly to (Schütze and Pe</context>
<context position="32304" citStr="Qiu and Frei, 1993" startWordPosition="5328" endWordPosition="5331"> relations. This expansion approach has been integrated both in traditional retrieval models (Jing and Croft, 1994) and in LM (Berger and Lafferty 1999). As we observed, this type of relation will introduce much noise into the query, leading to unstable effectiveness. Several other studies tried to filter out noise expansion (or translation) terms by considering the relations between them (Gao et al., 2002; Avg.P 0.35 0.25 0.15 0.3 0.2 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Lambda AP WSJ SJM Avg.P 0.35 0.30 0.25 0.20 0.15 10 20 40 80 150 300 No. expansion terms AP WSJ SJM 558 Jang et al. 1999; Qiu and Frei, 1993; Bai et al. 2005). However, this is insufficient to detect all the noise. The key issue is the ambiguity of relations due to the lack of context information in the relations. In this paper, we proposed a method to add some context information into relations. (Lin, 1997) also tries to solve word ambiguity by adding syntactic dependency as context. However, our approach does not require determining syntactic dependency. The principle of our approach is more similar to (Yarowsky, 1995). Compared to this latter, our approach is less demanding: we do not need to identify manually the exact word se</context>
</contexts>
<marker>Qiu, Frei, 1993</marker>
<rawString>Qiu, Y. and Frei, H.P. 1993. Concept based query expansion. ACM SIGIR, pp.160-169.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Schütze</author>
<author>J O Pedersen</author>
</authors>
<title>A cooccurrencebased thesaurus and two applications to information retrieval,</title>
<date>1997</date>
<booktitle>Information Processing and Management,</booktitle>
<volume>33</volume>
<issue>3</issue>
<pages>307--318</pages>
<contexts>
<context position="10659" citStr="Schütze and Pedersen, 1997" startWordPosition="1704" endWordPosition="1707">ity, we will only consider adding one additional word into relations. The proposed approach follows the same principle as (Yarowsky, 1995), which tried to determine the appropriate word sense according to one relevant context word. However, the requirement for query expansion is less than word sense disambiguation: we do not need to know the exact word sense to make expansion. We only need to determine the relevant expansion terms. Therefore, there is no need to determine manually a set of seeds before the learning process takes place. To some extent, the proposed approach is also related to (Schütze and Pedersen, 1997), which calculate term similarity according to the words appearing in the same context, or to second-order co-occurrences. However, a key difference is that (Schütze and Pedersen, 1997) consider only separate context words, while we consider multiple context words together. Once term relations are determined, they will be used in query expansion. The basic IR process will be implemented in a language modeling framework. This framework is chosen for its flexibility to integrate term relations. Indeed, the LM framework has proven to be capable of integrating term relations and query expansion (B</context>
<context position="15635" citStr="Schütze and Pedersen, 1997" startWordPosition="2587" endWordPosition="2590">nd Frei, 1993), but in a LM setting: the selected expansion terms are those that are strongly related to all the query terms (this is what the summation means). The approach used in (Bai et al., 2005) is slightly different: A context vector is first built for each word; then a context vector for a group of words (e.g. a multi-word query) is composed from the context vectors of the words of the group; finally related terms to the group of words are determined according to the similarity of their context vectors to that of the group. This last step uses second-order co-occurrences similarly to (Schütze and Pedersen, 1997). In both (Qiu and Frei, 1993) and (Bai et al., 2005), the terms related to a group of words are determined from their relations to each of the words in the group, while the latter relations are extracted separately. Irrelevant expansion terms can be retained. As we showed earlier, in many cases, when one additional word is used with another word, the sense of each of them can usually be better determined. This additional word may be sufficient to interpret correctly many multi-word user queries. Therefore, our goal is to extract stronger context-dependent relations of the form (qj qk) → wi, o</context>
</contexts>
<marker>Schütze, Pedersen, 1997</marker>
<rawString>Schütze, H. and Pedersen J.O. 1997. A cooccurrencebased thesaurus and two applications to information retrieval, Information Processing and Management, 33(3): 307-318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A F Smeaton</author>
<author>C J Van Rijsbergen</author>
</authors>
<title>The retrieval effects of query expansion on a feedback document retrieval system.</title>
<date>1983</date>
<journal>Computer Journal,</journal>
<volume>26</volume>
<issue>3</issue>
<pages>239--246</pages>
<marker>Smeaton, Van Rijsbergen, 1983</marker>
<rawString>Smeaton, A. F. and Van Rijsbergen, C. J. 1983. The retrieval effects of query expansion on a feedback document retrieval system. Computer Journal, 26(3): 239-246.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Smadja</author>
<author>K R McKeown</author>
</authors>
<title>Translating collocations for bilingual lexicons: A statistical approach,</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<volume>22</volume>
<issue>1</issue>
<pages>1--38</pages>
<contexts>
<context position="33157" citStr="Smadja and McKeown, 1996" startWordPosition="5468" endWordPosition="5471">ext information into relations. (Lin, 1997) also tries to solve word ambiguity by adding syntactic dependency as context. However, our approach does not require determining syntactic dependency. The principle of our approach is more similar to (Yarowsky, 1995). Compared to this latter, our approach is less demanding: we do not need to identify manually the exact word senses and seed context words. The process is fully automatic. This simplification is made possible due to the requirement for IR: only in-context related words are required, but not the exact senses. Our work is also related to (Smadja and McKeown, 1996), which tries to determine the translation of collocations. Term combinations or biterms we used can be viewed as collocations. Again, there is much less constraint for our related terms than translations in (Smadja and McKeown, 1996). 6. Conclusions In many NLP applications such as IR, we need to determine relations between terms. In most previous studies, one tries to determine the related terms to one single term (word). This makes the resulting relations ambiguous. Although several approaches have been proposed to remove afterwards some of the inappropriate terms, this only affects part of</context>
</contexts>
<marker>Smadja, McKeown, 1996</marker>
<rawString>Smadja, F., McKeown, K.R., 1996. Translating collocations for bilingual lexicons: A statistical approach, Computational Linguistics, 22(1): 1-38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Srikanth</author>
<author>R Srihari</author>
</authors>
<title>Biterm language models for document retrieval.</title>
<date>2002</date>
<journal>ACM SIGIR,</journal>
<pages>425--426</pages>
<contexts>
<context position="16634" citStr="Srikanth and Srihari, 2002" startWordPosition="2759" endWordPosition="2762">hem can usually be better determined. This additional word may be sufficient to interpret correctly many multi-word user queries. Therefore, our goal is to extract stronger context-dependent relations of the form (qj qk) → wi, or to build a probability functionPR(wi |qjqk). Once this function is determined, it can be integrated into a new language model as follows. Model 2: Context-dependent query expansion model (CDQE) PR(wi |Q) = ∑PR(wi |qjqk P(qjqk |Q) q j ,q Q k∈ As PR(wi |qjqk) is a relation with two terms as condition, we will also call it a biterm relation. The name “biterm” is due to (Srikanth and Srihari, 2002), which means two terms cooccurring within some distance. Similarly, PR (wi |qj) will be called unigram relation. The corresponding query models will be called biterm relation model and unigram relation model. As in general LM, the biterm relation model can be smoothed with a unigram model. Then we have the following score function: ) ∑ PR ( qj, + PR (wi |Q )=λ2PML(wi |Q) ∈ Q ∑ = wi∈V ≈ ∑ P(wi |Q) log P(wi |D) w E Q i∈ ∪ P(wi | Q) log P(wi |D) ) P(qjqk |Q) ∈ V qj,qk ) ≈ qk (wi PR ∑ |qj ( − 1 λ2 (2) qk|Q) i P ) w qk (q j |qj q Q k ∈ 554 where A2 is another smoothing parameter. 3.2 Extraction of</context>
</contexts>
<marker>Srikanth, Srihari, 2002</marker>
<rawString>Srikanth, M. and Srihari, R. 2002. Biterm language models for document retrieval. ACM SIGIR, pp. 425-426</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Voorhees</author>
</authors>
<title>Query expansion using lexicalsemantic relations.</title>
<date>1994</date>
<journal>ACM SIGIR,</journal>
<pages>61--69</pages>
<contexts>
<context position="2095" citStr="Voorhees, 1994" startWordPosition="320" endWordPosition="321">ssion by adding related terms to the query. However, the effect of query expansion is strongly determined by the term relations used (Peat and Willett, 1991). For example, even if “programming” is strongly related to “Java”, if this relation is used to expand a query on “Java travel”, the retrieval result will likely deteriorate because the irrelevant term “programming” is introduced, leading to the retrieval of irrelevant documents about “programming”. A number of attempts have been made to deal with the problem of selecting appropriate expansion terms. For example, Wordnet has been used in (Voorhees, 1994) to determine the expansion terms. However, the experiments did not show improvement on retrieval effectiveness. Many experiments have been carried out using associative relations extracted from term cooccurrences; but they showed variable results (Peat and Willett, 1991). In (Qiu and Frei, 1993), it is observed that one of the reasons is that one tried to determine expansion terms according to each original query term separately, which may introduce much noise. Therefore, they proposed to determine the expansion terms by summing up the relations of a candidate expansion term to each of the qu</context>
<context position="5174" citStr="Voorhees, 1994" startWordPosition="802" endWordPosition="803">nd term relation extraction. Then we will describe our general IR models and the extraction of term relations. The experimental results will be reported and finally some conclusions will be drawn. 2. Query Expansion and Term Relations It has been found that a key factor that determines the effect of query expansion is the selection of appropriate expansion terms (Peat and Willett, 1991). To determine expansion terms, one possible resource is thesauri constructed manually, such as Wordnet. Thesauri contain manually validated relations between terms, which can be used to suggest related terms. (Voorhees, 1994) carried out a series of experiments on selecting related terms (e.g. synonyms, hyonyms, etc.) from Wordnet. However, the experiments did not show that this can improve retrieval effectiveness. Some of the reasons are as follows: Although Wordnet contains many relations validated by human experts, the coverage is far from complete for the purposes of IR: not only linguistically motivated relations, but also association relations, are useful in IR. Another problem is the lack of information about the appropriate context to apply relations. For example, Wordnet contains two synsets for “computer</context>
</contexts>
<marker>Voorhees, 1994</marker>
<rawString>Voorhees, E. 1994. Query expansion using lexicalsemantic relations. ACM SIGIR, pp. 61-69.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Yarowsky</author>
</authors>
<title>Unsupervised word sense disambiguation rivaling supervised methods.</title>
<date>1995</date>
<pages>189--196</pages>
<publisher>ACL,</publisher>
<contexts>
<context position="10170" citStr="Yarowsky, 1995" startWordPosition="1626" endWordPosition="1627">It then suggests the following approach: we can adjunct some additional word(s) in the condition part of a relation, such as “(Java, travel) → Indonesia”, which means “Indonesia” is related to “(Java, travel)” together. It is expected that one would not obtain “(Java, travel) → programming”. Owing to the context effect explained above, we will call the relations with multiple words in the condition part context-dependent relations. In order to limit the computation complexity, we will only consider adding one additional word into relations. The proposed approach follows the same principle as (Yarowsky, 1995), which tried to determine the appropriate word sense according to one relevant context word. However, the requirement for query expansion is less than word sense disambiguation: we do not need to know the exact word sense to make expansion. We only need to determine the relevant expansion terms. Therefore, there is no need to determine manually a set of seeds before the learning process takes place. To some extent, the proposed approach is also related to (Schütze and Pedersen, 1997), which calculate term similarity according to the words appearing in the same context, or to second-order co-o</context>
<context position="32792" citStr="Yarowsky, 1995" startWordPosition="5409" endWordPosition="5410"> SJM Avg.P 0.35 0.30 0.25 0.20 0.15 10 20 40 80 150 300 No. expansion terms AP WSJ SJM 558 Jang et al. 1999; Qiu and Frei, 1993; Bai et al. 2005). However, this is insufficient to detect all the noise. The key issue is the ambiguity of relations due to the lack of context information in the relations. In this paper, we proposed a method to add some context information into relations. (Lin, 1997) also tries to solve word ambiguity by adding syntactic dependency as context. However, our approach does not require determining syntactic dependency. The principle of our approach is more similar to (Yarowsky, 1995). Compared to this latter, our approach is less demanding: we do not need to identify manually the exact word senses and seed context words. The process is fully automatic. This simplification is made possible due to the requirement for IR: only in-context related words are required, but not the exact senses. Our work is also related to (Smadja and McKeown, 1996), which tries to determine the translation of collocations. Term combinations or biterms we used can be viewed as collocations. Again, there is much less constraint for our related terms than translations in (Smadja and McKeown, 1996).</context>
</contexts>
<marker>Yarowsky, 1995</marker>
<rawString>Yarowsky, D. 1995. Unsupervised word sense disambiguation rivaling supervised methods. ACL, pp. 189-196.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Zhai</author>
<author>J Lafferty</author>
</authors>
<title>Model-based feedback in the language modeling approach to information retrieval.</title>
<date>2001</date>
<journal>ACM SIGIR,</journal>
<pages>403--410</pages>
<contexts>
<context position="11327" citStr="Zhai and Lafferty, 2001" startWordPosition="1806" endWordPosition="1809">to the words appearing in the same context, or to second-order co-occurrences. However, a key difference is that (Schütze and Pedersen, 1997) consider only separate context words, while we consider multiple context words together. Once term relations are determined, they will be used in query expansion. The basic IR process will be implemented in a language modeling framework. This framework is chosen for its flexibility to integrate term relations. Indeed, the LM framework has proven to be capable of integrating term relations and query expansion (Bai et al., 2005; Berger and Lafferty, 1999; Zhai and Lafferty, 2001). However, none of the above studies has investigated the extraction of strong context-dependent relations from text collections. In the next section, we will describe the general LM framework and our query expansion models. Then the extraction of term relation will be explained. 3. Context-Dependent Query Expansion in Language Models The basic IR approach based on LM (Ponte and Croft, 1998) determines the score of relevance of a document D by its probability to generate the query Q. By assuming independence between query terms, we have: score D Q ( , )=∑ PML (wi |Q) log P(wi |D) w Q i∈ where </context>
<context position="22439" citStr="Zhai and Lafferty, 2001" startWordPosition="3810" endWordPosition="3813">words per query on average. Table 1. TREC collection statistics Coll. Description Size Vocab. # Doc. Query (Mb) AP Associated 491 196,933 164,597 51-100 Press (1988-89) SJM San Jose 286 146,514 90,257 101-150 Mercury News (1991) WSJ Wall Street 242 121,946 74,520 51-100 Journal (1990- 92) In our experiments, the document model remains the same while the query model changes. The document model uses the following Dirichlet smoothing: P(wi |D) = |D | where tf (wi, D) is the term frequency of wi in D, PML(wi |C) is the collection model and µ is the Dirichlet prior, which is set at 1000 following (Zhai and Lafferty, 2001). There are two other smoothing parameters λ1 , and λ2 to be determined. In our experiments, we use a simple method to set them: the parameters are tuned empirically using a training collection containing AP1989 documents and queries 101- 150. These preliminary tests suggest that the best value of and (in Equations 1-2) are relatively stable (we will show this later). In the λ1 λ2 λ1 λ2 = 0.3 . 4.1 Experimental Results The main experimental results are described in Table 2, which reports average precision with different methods as well as the number of relevant documents retrieved. UM is the b</context>
<context position="27094" citStr="Zhai and Lafferty, 2001" startWordPosition="4513" endWordPosition="4516"> on the other collections. This shows that the CDQE method does not increase recall to the detriment of precision, but both of them. In contrast, CIQE increases precision at all but 0.0 recall points: the precision at the 0.0 recall point is 0.6565 for CIQE and 0.6699 for UM. This shows that CIQE can slightly deteriorate the topranked few documents. Figure 1. Comparison of three models on AP CDQE vs. Pseudo-relevance feedback Pseudo-relevance feedback is widely considered to be an effective query expansion method. In many previous experiments, it produced very good results. The mixture model (Zhai and Lafferty, 2001) is a representative and effective method to implement pseudo-relevance feedback: It uses a set of feedback documents to smooth the original query model. Compared to the mixture model, our CDQE method is also more effective: By manually tuning the parameters of the mixture model to their best, we obtained the average precisions of 0.3171, 0.2393 and 0.2565 respectively for AP, SJM and WSJ collections. These values are lower than those obtained with CDQE, which has not been heavily tuned. For the same query “insider trading”, the mixture model determines the following expansion terms: Mixture: </context>
</contexts>
<marker>Zhai, Lafferty, 2001</marker>
<rawString>Zhai, C. and Lafferty, J. 2001. Model-based feedback in the language modeling approach to information retrieval. ACM SIGIR, pp. 403-410.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>