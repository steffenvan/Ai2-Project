<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.997745">
Combination of an Automatic and an Interactive
Disambiguation Method
</title>
<author confidence="0.988357">
Masaya Yamaguchi, Takeyuki Kojima,
Nobuo Inui, Yoshiyuki Kotani and Hirohiko Nisimura
</author>
<affiliation confidence="0.997841">
Department of Computer Science, Tokyo University of Agriculture and Technology,
</affiliation>
<address confidence="0.323698">
Nisimura, Kotani unit, 2-24-16 Naka-cho, Koganei, Tokyo, Japan
</address>
<sectionHeader confidence="0.984503" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999992578947369">
In natural language processing, many methods have
been proposed to solve the ambiguity problems. In
this paper, we propose a. technique to combine a
method of interactive disambiguation and automatic
one for ambiguous words. The characteristic of our
method is that the accuracy of the interactive dis-
ambiguation is considered. The method solves the
two following problems when combining those dis-
ambiguation methods: (1) when should the inter-
active disambiguation be executed? (2) which am-
biguous word should be disambiguated when more
than one ambiguous words exist in a sentence? Our
method defines the condition of executing the inter-
action with users and the order of disambiguation
based on the strategy where the accuracy of the re-
sult is maximized, considering the accuracy of the
interactive disambiguation and automatic one. Us-
ing this method, user interaction can be controlled
while holding the accuracy of results.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999973130434783">
In natural language processing, many methods
have been proposed to solve the ambiguity prob-
lems(Na.gao and Maruyama, 1992). One of those
technique uses interactions with users, because it is
difficult, to make all the knowledge for disambigua-
tion beforehand. That technique is classified into
two types according to the condition of executing
user interaction. One type(TypeA) is that the dis-
ambiguation system executes interactions(Blanchon
et al., 1995), (Maruyama and Watanabe, 1990),
(Ya.maguchi et al., 1995). Another type(TypeB) is
that users executes interactions(D.Brawn and Niren-
burg, 1990), (Muraki et al., 1994). In this paper, Ty-
peA will be adopted because TypeB gives users more
trouble than TypeA does. • For example, in TypeB,
a user may have to find where is wrongly analyzed
in input sentences.
In TypeA, the two following conditions must be
determined: (1) when should interactive disam-
biguation be executed? (2) which ambiguous words
should be disambiguated when more than one am-
biguous word exist in a sentence? Considering the
accuracy of the analyzed result, they should be de-
cided by both the accuracy of the interactive dis-
ambiguation and that of the automatic disambigua-
tion. The traditional methods did not. considered
the accuracy of the interactive disambiguation. For
instance, the accuracy of the analyzed result may
decrease in spite of executing the user interaction
if the accuracy of the interactive disambiguation is
low.
In this paper, we propose the method to com-
bine the interactive disambiguation and the auto-
matic one, considering each accuracy. The method
allows the disambiguation system to maximize the
accuracy of the analyzed result. This paper focuses
on the ambiguity caused by ambiguous words that,
have more than one meaning. Section 2 represents
preconditions for disambiguation. In Section 3, we
describe the condition of executing the interactive
disambiguation. Section 4 shows the procedure that.
decides the order of disambiguation. The perfor-
mance of the method is discussed by the result of
the simulation under assuming the both accuracy
of the interactive disambiguation and the automatic
one.
</bodyText>
<sectionHeader confidence="0.997031" genericHeader="introduction">
2 Preconditions for Disambiguation
</sectionHeader>
<bodyText confidence="0.999430428571428">
This section describes preconditions for disambigua-
tion and methods of the disambiguation.
In this paper, the disambiguation for ambiguous
words means that all ambiguous ones in an input.
sentence are disambiguated. Describing it. formally,
the disambiguation is to decide one element of the
following MS.
</bodyText>
<equation confidence="0.787245">
MS = x M2 X . . . X Ali ,
</equation>
<bodyText confidence="0.9997362">
where an input sentence contains / ambiguous
words. Mj means the set of meanings in the am-
biguous word w.
Each disambiguation method has preconditions as
follows:
</bodyText>
<subsectionHeader confidence="0.498734">
Interactive Disambiguation
</subsectionHeader>
<listItem confidence="0.840585666666667">
• In the interaction, the system shows explana-
tions for each meaning of an ambiguous word to
a user, who selects one explanation from them.
</listItem>
<page confidence="0.660278">
1423
</page>
<listItem confidence="0.839092">
• The system can calculate the probability where
• a user selects the right explanation.
Automatic Disambiguation
• The occurrence probabilities for each candidate
can be calculated for preference.
• The result is the candidate with the maximum
occurrence probability.
</listItem>
<bodyText confidence="0.9958156">
To show the information mentioned above, candi-
dates are expressed by the tree in Figure 1. This tree
is an example in the case that an input sentence is &amp;quot;I
saw a star.&amp;quot;, which contains two ambiguous words
&apos;see&apos; and &apos;star&apos; and each word has two meanings.
</bodyText>
<equation confidence="0.861980666666667">
root
71111 111.12
Pd l, P1 Pd2, P2
</equation>
<figureCaption confidence="0.748375">
Figure 2: An example of the tree of candidates for
one ambiguous word in an input sentence
</figureCaption>
<bodyText confidence="0.977028666666667">
The accuracy of the interactive disambiguation
Pint, and that of the automatic disambiguation Panto
are defined as follows:
</bodyText>
<equation confidence="0.753025142857143">
mm
Pdn ,p,,
root
see_1 see_2
Pd!! Pd12
star_l star_2 star_l star_2
Pd21 Pu Pd22, P12 Pd21, P21 Pd22, P22
</equation>
<figureCaption confidence="0.998417">
Figure 1: An example of the tree of candidates
</figureCaption>
<bodyText confidence="0.999936071428572">
The depth of the tree expresses the order of dis-
ambiguation. In Figure 1, the ambiguities are re-
solved in the order from &apos;see&apos; to &apos;star&apos;. The occur-
rence probability is calculated at each leaf node by
the automatic disambiguation method. For exam-
ple, pll expresses the probability for the candidate
star_11. Furthermore, the accuracy of in-
teraction is also calculated at the leaf node by the
interactive disambiguation method. pd21 is the prob-
ability where the meaning of &apos;star&apos; is `star_1&apos; and
the system shows explanations of `star_1&apos;, `star_2&apos;
for &apos;star&apos; to a user and (s)he selects the explanation
of `star_2&apos;. At Nodes besides leaf ones, only the
accuracy of interaction is calculated.
</bodyText>
<sectionHeader confidence="0.9919155" genericHeader="method">
3 The Condition of Executing the
Interactive Disambiguation
</sectionHeader>
<subsectionHeader confidence="0.999819">
3.1 Basic Idea
</subsectionHeader>
<bodyText confidence="0.9993875">
At each node besides leaf ones, the disambigua-
tion system decides which disambiguation method
is used. Basically, the interactive disambiguation is
executed when its accuracy is higher than the ac-
curacy of the automatic disambiguation. First of
all, let us consider the case where an input sentence
contains one ambiguous word that has n. meanings.
Figure 2 shows the tree of candidates for this case.
</bodyText>
<equation confidence="0.8323085">
Pintr Epthp,
Panto = max pi
</equation>
<bodyText confidence="0.9901025">
The interactive disambiguation is executed, when
the following condition is satisfied.
</bodyText>
<subsectionHeader confidence="0.553221">
Pintr &gt; Panto
</subsectionHeader>
<bodyText confidence="0.999994923076923">
Considering the condition more carefully, the ac-
curacy of the interactive disambiguation is influ-
enced by the explanations that. are shown to users.
Thus the accuracy may be improved by limiting to
show some explanations to users. For example, this
may be caused when the accuracy of mi i is very low
and a. user may select. mil wrongly by the higher
similarity of the explanation for /nil to other expla-
nations. The automatic disambiguation corresponds
to showing only one explanation to users in the in-
teractive disambiguation. Therefore the condition
of executing the interactive disambiguation can be
defined as the exceptional case of the limitation.
</bodyText>
<subsectionHeader confidence="0.99837">
3.2 The Accuracy at a Node
</subsectionHeader>
<bodyText confidence="0.9999683125">
In the case that, the number of ambiguous words is
one as Figure 2, the accuracy of the deeper nodes be-
low the root node needs not to be decided because
they are leaf nodes. When more than two ambiguous
words exist in an input sentence, a node may often
have one that is not a leaf one. To calculate the ac-
curacy of such a node, it is necessary to determine
what kind of disambiguation will be executed at the
deeper nodes. For instance, the disambiguation sys-
tem has to fix each accuracy of node `see_1&apos; and
`see_2&apos; in Figure 1 to calculate the accuracy of the
root node. Therefore, the definition of the accuracy
at any node i is the recursive one. The accuracy of
the interactive disambiguation Pintr(i) and that of
the automatic disambiguation Pauto(0 at node i is
defined as follows:
</bodyText>
<page confidence="0.701928">
1424
</page>
<equation confidence="0.96363475">
Pmtr(i) E pd(inim) x Pr(m)
mem
Pauto(0 me Al
max (Pr(m))
</equation>
<bodyText confidence="0.982561142857143">
where M is the set of the node directly under node
pd(mIM) is the accuracy of the interactive disam-
biguation at node in, that is, the probability that a
user selects 771 provided that the system shows ex-
planations for all the elements of Al to him(her).
Pr(m) is the accuracy at node in and the definition
is as follows:
</bodyText>
<equation confidence="0.846919428571428">
Pintr(m)
(if the interactive disambiguation is
executed at node in)
Pauto(m)
(if the automatic disambiguation is ex-
ecuted at node m)
Poccur(m) (if in is a leaf node)
</equation>
<bodyText confidence="0.9985526">
where pc,„„r(m) is the occurrence probability of
the candidate that includes nodes between the root
node and node m.
When the following condition is satisfied, the in-
teractive disambiguation is executed at node i.
</bodyText>
<equation confidence="0.990686">
Pintr(i) &gt; Pauto(i) (3)
</equation>
<subsectionHeader confidence="0.996508">
3.3 The Limitation of Explanations
</subsectionHeader>
<bodyText confidence="0.9992972">
In user interaction, the presentation of many expla-
nations gives users trouble to select one explanation.
So it is desirable that the disambiguation system
shows fewer explanation to users, if possible. In this
section, we describe the condition where the number
of explanations is limited without losing the accu-
racy of the analyzed result.
By formula (1), the accuracy of the interactive
disambiguation in the case of limiting the set
of explanations AP is defined as follows:
</bodyText>
<equation confidence="0.9802095">
E pd(7nim — Ali)Pr( in)
E M
Ptr(i) = if 1M — /1/1 &gt; 1
Pr(t) if IM — Mil = 1
If formula (4) is satisfied, the set of the explana-
tion M&apos; is not shown to users in the interaction a.t
node i.
Pintr(i) &lt; P„(i) (4)
</equation>
<bodyText confidence="0.738503">
Furthermore, if IM — API = 1, then the automatic
disambiguation is executed at node i. Therefore,
formula (4) implies formula (3).
</bodyText>
<sectionHeader confidence="0.9506035" genericHeader="method">
4 Determination of the Order of
Disambiguation
</sectionHeader>
<subsectionHeader confidence="0.99886">
4.1 Procedure
</subsectionHeader>
<bodyText confidence="0.999820916666667">
UP to here, we have discussed Pintr and Pauto under
a certain order of disambiguation. In this section,
we describe a procedure to decide the order of dis-
ambiguation where the accuracy is maximum.
The accuracy of the analyzed result may be differ-
ent in each order of disambiguation. This is the rea-
son that the disambiguation of one ambiguous word
leads to constrain the meaning of other ambiguous
ones. Therefore, the contents of the interaction may
differ from each order of disambiguation. The or-
der with the maximum accuracy is obtained in the
following procedure:
</bodyText>
<listItem confidence="0.995643">
1. Calculating each occurrence probability of can-
didate for the analyzed result by the automatic
disambiguation method.
2. Obtaining the accuracy in each order of disam-
biguation based on the method described in the
previous sections.
3. Disambiguating by the order with the maximum
accuracy.
</listItem>
<subsectionHeader confidence="0.84568">
4.2 Example
</subsectionHeader>
<figureCaption confidence="0.9091505">
In this section, we illustrate the determination of ex-
ecuting the interactive disambiguation and the order
of disambiguation. The values at leaf nodes are the
occurrence probabilities. The accuracy of the inter-
active disambiguation is 0.9 at the any nodes. Since
the number of ambiguous words is two, the num-
ber of the order of disambiguation is 2! as shown in
Figure 3, 4.
</figureCaption>
<figure confidence="0.9573925">
root
see_l see_2
star_l star_2 star_l star_2
0.10 0.10 0.05 0.75
</figure>
<figureCaption confidence="0.912286">
Figure 3: An example of the order of disambigua-
tion(1)
</figureCaption>
<bodyText confidence="0.9798378">
To begin with, we intend to calculate what kind
of disambiguation is executed at node `star_1&apos;
and star_2&apos;, in Figure 3. By formula (1), (2),
Pi„tr(see_1) and Paut.o(see_l) are as follows (since
both ambiguous words have two meanings,
</bodyText>
<equation confidence="0.724203166666667">
= n: PL„tr(i)
Pauto(i
Pr(m) =
1425
root
Therefore, Pintr(root) &gt; Pauto(root), and
</equation>
<bodyText confidence="0.8591218">
Pr (root ) becomes 0.81. Comparing with Pr (root )
of each order, Pr(roof) of Figure 3 is greater than
that of Figure 4. Thus the system interacts with
users against &apos;see&apos; in the first place.
star_l star_2
</bodyText>
<figureCaption confidence="0.936836">
Figure 4: An example of the order of disambigua-
</figureCaption>
<equation confidence="0.9678866">
tion(2)
Pi.„47.(see_1) = 0.9 x (0.75 + 0.05)
= 0.72
Paut0(see_1) = max(0.75, 0.05)
= 0.75
</equation>
<bodyText confidence="0.71676575">
Because of Pi„tr(see_1) &lt; P0„t0(see_1), the au-
tomatic disambiguation is executed at node see_1.
On the other hand, at node see_2, P1„tr(see_2) and
Pa„to(see_2) are as follows:
</bodyText>
<equation confidence="0.851168909090909">
Pi„tr(see_2) = 0.18
P23t0(see_2) = 0.10
Pio1.(see_2) &gt; P„„t0(see_2) is satisfied. So the
system interacts with users at this node.
By the result. of the above, Pior(root) and
Pa„to(root) are as follows:
P1„1,.(root) = 0.9(Pr(see_1) Pr(see_2))
0.9(Pa„to(see_1) Pi„tr(see_2))
= 0.9(0.75 + 0.18) = 0.837
Panto( root) = max(Pr(see_1),Pr(see_2))
max(0.75, 0.18) = 0.75
</equation>
<bodyText confidence="0.976763428571429">
Therefore, the interactive disambiguation is ex-
ecuted at. the root node because of tr(root) &gt;
Pauto(root), and Pr(root) = 0.837.
Next, let us explain the case of Figure 4. Cal-
culating the same way as Figure 3, the. interactive
disambiguation is executed in any node besides leaf
ones, and Pintr(root.), Pa„to(root) are as follows:
</bodyText>
<equation confidence="0.918816">
Pin tr (r00i) = 0.9(Pr(star_1)-F Pr(star-2))
• 0.9(Pintr(st ar-1) + Pi n tr (Star _2))
• 0.9(0.765 + 0.135) = 0.81
Pauto(root) = max(Pr(star_1), Pr (star_2))
max(0.10, 0.75) = 0.75
</equation>
<sectionHeader confidence="0.916643" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<bodyText confidence="0.999721571428571">
We applied the proposed method (abbreviated as
MP) to the disambiguation of trees of candidates
that are made for experiments, and compared it with
the method (abbreviated as MA) that executes in-
teraction in all nodes.
We set the following properties to the tree of can-
didates.
</bodyText>
<listItem confidence="0.9961185">
• the number of ambiguous words included in an
input sentence
• the number of meanings in an ambiguous word
• the occurrence probability of candidates
</listItem>
<bodyText confidence="0.999388272727273">
To assign an occurrence probability to each can-
didate, a random value is given to each candidate
above all, and each value is divided by the sum of
values given to all candidates.
Figure 5, 6 show the accuracy at the root node
and the number of interaction, respectively. In these
figures, a mark &apos;+&apos; indicates results of MP. Each of
them is the average of 300 trees. A mark &apos;*&apos; indicates
results of MA. Because MA does not prescribe the
order of disambiguation, the result. of each tree is
the average of all the orders.
</bodyText>
<figure confidence="0.996974666666667">
0 9
085
08
.1 0 75
0 7
0 65
06
83. A 34 A4, 133. 834 134. 134. Ca. C3. CO. CS, 03. 034 DA. 06. (6. 89. £12- 812. 16. 26.
Pcoperly Cl IMO
</figure>
<figureCaption confidence="0.999986">
Figure 5: The accuracy of MP, MA
</figureCaption>
<bodyText confidence="0.919478">
The horizontal axis means the property of the tree.
Each Alphabet in the value of the horizontal axis
stands for the number of ambiguous words in a tree
and the number of meanings of a word as follows:
A: 2 x 4 D: 2 x 4 x 4
B: 2 x 2 x 4 E: 2 x 2 x 4 x 4
C: 2 x 2 x 2 x 4 F: 2x2x2x4x4
</bodyText>
<figure confidence="0.6560718">
see_i see_2 see_l see_2
0.10 0.05 0.10 0.75
1426
33- 43, 34. 34, 133. 834 84. 844 C3. C34 CO. CO. 03. 03 136. 864 E6- ES, E12 .E12. 06 064
Propwly S 1.4
</figure>
<figureCaption confidence="0.999952">
Figure 6: The number of interaction of MP, MA
</figureCaption>
<bodyText confidence="0.999808142857143">
For instance, &apos;2 x 4&apos; shows that there are two am-
biguous words in a tree and one ambiguous word has
two meanings and another word has four meanings.
The number in the value of the x-axis represents
the number of the candidate whose occurrence prob-
ability is not zero. Two marks, &apos;+&apos; and &apos;-&apos; mean that
the accuracy of interaction is 0.9, 0.85 respectively.
</bodyText>
<sectionHeader confidence="0.999849" genericHeader="discussions">
6 Discussion
</sectionHeader>
<subsectionHeader confidence="0.999215">
6.1 The Accuracy of Disambiguation
</subsectionHeader>
<bodyText confidence="0.99999625">
The effect of the proposed method on the accuracy
is expressed by the difference of distributions of two
marks, &apos;+&apos; and in Figure 5. This shows that. the
accuracy of the proposed method is better than that,
of MA in any property of tree. Table 1 (the line of
&apos;Accuracy&apos;) shows the minimum, maximum, and av-
erage values of the ratio of improved accuracy (RIA).
The definition of RIA is shown a.s follows:
</bodyText>
<equation confidence="0.972003">
RIA = C - aca
1.0 - aca
</equation>
<bodyText confidence="0.9988515">
where (ter, (Ica is the accuracy the result by MP
and MA respectively.
</bodyText>
<tableCaption confidence="0.999306">
Table 1: Summary of the results
</tableCaption>
<table confidence="0.974635333333333">
II inimum Maximum Average
Accuracy 0.14 0.23 0.18
Interaction -0.06 0.12 0.03
</table>
<subsectionHeader confidence="0.998154">
6.2 The Number of Interaction
</subsectionHeader>
<bodyText confidence="0.999282166666667">
The number of interaction rnay increase on the con-
dition that the accuracy of the analyzed result is
maximized. In this section, the degree of the in-
crease will be estimated by comparing the number
of interaction of MP with that of MA. For this
purpose, &apos;RH&apos; is defined as follows:
</bodyText>
<equation confidence="0.8704365">
RII =nr-na
w
</equation>
<bodyText confidence="0.964170666666666">
where np, lla is the number of interaction by MP
and MA respectively, nu, is the number of ambigu-
ous words in an input sentence. Rh represents the
ratio of the increase in the number of interaction per
ambiguous word. Table 1(the line of &apos;Interaction&apos;)
shows the minimum, maximum, and average of RI!.
To reduce the number of interaction, the auto-
matic disambiguation is executed instead of execut-
ing the interactive disambiguation, estimating the
loss of the accuracy L(i) in node i. L(i) is defined
as follows:
= 132.(0- Patao(i)
The proposed method will allow the system to re-
duce the number of interaction, by considering L(i)
in each node.
</bodyText>
<sectionHeader confidence="0.999124" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.9999402">
NW have proposed the method of combining the
interactive disambiguation and the automatic one.
The characteristic of our method is that it considers
the accuracy of the interactive disambiguation. This
method makes three following things possible:
</bodyText>
<listItem confidence="0.947646">
• selecting the disambiguation method that ob-
tains higher accuracy
• limiting explanations shown to users
• obtaining the order of disambiguation where the
accuracy of the analyzed results is maximized.
</listItem>
<sectionHeader confidence="0.998022" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.994728545454545">
Herve&apos; Blanchon, K. Loken-Kim, and T. Morimoto.
1995. An interactive disambiguation module for
English natural language utteracances. In Pro-
ceedings of NLPRS-95, pages 550-555.
Ralf D.Brawn and Sergei Nirenburg. 1990. Human-
computer interaction for semantic disambigua-
tion. In Proceedings of COLING-90, pages 42-47.
11. Maruyama and H. Watanabe. 1990. An interac-
tive Japanese parser for ma-chine translation. In
Proceedings of COLING-90, pages 257-262.
K. Muraki, S. Akamine, K. Satoh, and S. Ando.
1994. TWP: How to assist English production
on Japanese word processor. In Proceedings of
COLING-94, pages 847-852.
K. Nagao and H. Maruyama. 1992. Ambiguities and
their resolution in natural language processing.
Journal of IPSJ, 33(7):741-745.
M. Yamaguchi, N. Inui, Y. Kotani, and H. Nisimura.
1995. The design and experiment of an evaluation
function for user interaction cost in the interac-
tive semantic disambiguation. In Proceedings of
HCP95, pages 285-290.
</reference>
<figure confidence="0.99833525">
3 5
3
1 2
1 5
</figure>
<page confidence="0.94228">
1427
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.466732">
<title confidence="0.9863275">Combination of an Automatic and an Interactive Disambiguation Method</title>
<author confidence="0.987217">Masaya Yamaguchi</author>
<author confidence="0.987217">Takeyuki Kojima</author>
<affiliation confidence="0.742692">Inui, Yoshiyuki Kotani Nisimura Department of Computer Science, Tokyo University of Agriculture and Technology,</affiliation>
<address confidence="0.998933">Nisimura, Kotani unit, 2-24-16 Naka-cho, Koganei, Tokyo, Japan</address>
<abstract confidence="0.9996658">In natural language processing, many methods have been proposed to solve the ambiguity problems. In this paper, we propose a. technique to combine a method of interactive disambiguation and automatic one for ambiguous words. The characteristic of our method is that the accuracy of the interactive disambiguation is considered. The method solves the two following problems when combining those disambiguation methods: (1) when should the interactive disambiguation be executed? (2) which ambiguous word should be disambiguated when more than one ambiguous words exist in a sentence? Our method defines the condition of executing the interaction with users and the order of disambiguation based on the strategy where the accuracy of the result is maximized, considering the accuracy of the interactive disambiguation and automatic one. Using this method, user interaction can be controlled while holding the accuracy of results.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>Herve&apos; Blanchon</author>
<author>K Loken-Kim</author>
<author>T Morimoto</author>
</authors>
<marker>Blanchon, Loken-Kim, Morimoto, </marker>
<rawString> Herve&apos; Blanchon, K. Loken-Kim, and T. Morimoto.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sergei Nirenburg</author>
</authors>
<title>An interactive disambiguation module for English natural language utteracances.</title>
<date>1990</date>
<booktitle>In Proceedings of NLPRS-95,</booktitle>
<pages>550--555</pages>
<note>Ralf D.Brawn</note>
<marker>1995.</marker>
<rawString>An interactive disambiguation module for English natural language utteracances. In Proceedings of NLPRS-95, pages 550-555. Ralf D.Brawn and Sergei Nirenburg. 1990. Humancomputer interaction for semantic disambiguation. In Proceedings of COLING-90, pages 42-47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maruyama</author>
<author>H Watanabe</author>
</authors>
<title>An interactive Japanese parser for ma-chine translation.</title>
<date>1990</date>
<booktitle>In Proceedings of COLING-90,</booktitle>
<pages>257--262</pages>
<marker>11.</marker>
<rawString>Maruyama and H. Watanabe. 1990. An interactive Japanese parser for ma-chine translation. In Proceedings of COLING-90, pages 257-262. K. Muraki, S. Akamine, K. Satoh, and S. Ando.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Nagao</author>
<author>H Maruyama</author>
</authors>
<title>TWP: How to assist English production on Japanese word processor.</title>
<date>1992</date>
<journal>Journal of IPSJ,</journal>
<booktitle>In Proceedings of COLING-94,</booktitle>
<pages>847--852</pages>
<marker>1994.</marker>
<rawString>TWP: How to assist English production on Japanese word processor. In Proceedings of COLING-94, pages 847-852. K. Nagao and H. Maruyama. 1992. Ambiguities and their resolution in natural language processing. Journal of IPSJ, 33(7):741-745. M. Yamaguchi, N. Inui, Y. Kotani, and H. Nisimura.</rawString>
</citation>
<citation valid="false">
<title>The design and experiment of an evaluation function for user interaction cost in the interactive semantic disambiguation.</title>
<booktitle>In Proceedings of HCP95,</booktitle>
<pages>285--290</pages>
<marker>1995.</marker>
<rawString>The design and experiment of an evaluation function for user interaction cost in the interactive semantic disambiguation. In Proceedings of HCP95, pages 285-290.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>