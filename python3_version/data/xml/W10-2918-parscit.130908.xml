<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000189">
<title confidence="0.9984425">
A Comparative Study of Bayesian Models for Unsupervised Sentiment
Detection
</title>
<author confidence="0.993228">
Chenghua Lin
</author>
<affiliation confidence="0.99131">
School of Engineering,
Computing and Mathematics
University of Exeter
</affiliation>
<address confidence="0.900312">
Exeter, EX4 4QF, UK.
</address>
<email confidence="0.996061">
cl322@exeter.ac.uk
</email>
<sectionHeader confidence="0.994697" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999635">
This paper presents a comparative study
of three closely related Bayesian mod-
els for unsupervised document level senti-
ment classification, namely, the latent sen-
timent model (LSM), the joint sentiment-
topic (JST) model, and the Reverse-JST
model. Extensive experiments have been
conducted on two corpora, the movie re-
view dataset and the multi-domain senti-
ment dataset. It has been found that while
all the three models achieve either bet-
ter or comparable performance on these
two corpora when compared to the exist-
ing unsupervised sentiment classification
approaches, both JST and Reverse-JST are
able to extract sentiment-oriented topics.
In addition, Reverse-JST always performs
worse than JST suggesting that the JST
model is more appropriate for joint senti-
ment topic detection.
</bodyText>
<sectionHeader confidence="0.998784" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999766944444445">
With the explosion of web 2.0, various types of
social media such as blogs, discussion forums and
peer-to-peer networks present a wealth of infor-
mation that can be very helpful in assessing the
general public’s sentiments and opinions towards
products and services. Recent surveys have re-
vealed that opinion-rich resources like online re-
views are having greater economic impact on both
consumers and companies compared to the tradi-
tional media (Pang and Lee, 2008). Driven by
the demand of gleaning insights of such great
amounts of user-generated data, work on new
methodologies for automated sentiment analysis
has bloomed splendidly.
Compared to the traditional topic-based text
classification, sentiment classification is deemed
to be more challenging as sentiment is often em-
bodied in subtle linguistic mechanisms such as
</bodyText>
<note confidence="0.5363974">
Richard Everson
School of Engineering,
Computing and Mathematics
University of Exeter
Exeter, EX4 4QF, UK.
</note>
<email confidence="0.959215">
R.E.Everson@exeter.ac.uk
</email>
<bodyText confidence="0.999923926829268">
the use of sarcasm or incorporated with highly
domain-specific information. Although the task
of identifying the overall sentiment polarity of
a document has been well studied, most of the
work is highly domain dependent and favoured
in supervised learning (Pang et al., 2002; Pang
and Lee, 2004; Whitelaw et al., 2005; Kennedy
and Inkpen, 2006; McDonald et al., 2007), re-
quiring annotated corpora for every possible do-
main of interest, which is impractical for real
applications. Also, it is well-known that senti-
ment classifiers trained on one domain often fail
to produce satisfactory results when shifted to an-
other domain, since sentiment expression can be
quite different in different domains (Aue and Ga-
mon, 2005). Moreover, aside from the diversity
of genres and large-scale size of Web corpora,
user-generated contents evolve rapidly over time,
which demands much more efficient algorithms
for sentiment analysis than the current approaches
can offer. These observations have thus motivated
the problem of using unsupervised approaches for
domain-independent joint sentiment topic detec-
tion.
Some recent research efforts have been made to
adapt sentiment classifiers trained on one domain
to another domain (Aue and Gamon, 2005; Blitzer
et al., 2007; Li and Zong, 2008; Andreevskaia
and Bergler, 2008). However, the adaption perfor-
mance of these lines of work pretty much depends
on the distribution similarity between the source
and target domain, and considerable effort is still
required to obtain labelled data for training.
Intuitively, sentiment polarities are dependent
on contextual information, such as topics or do-
mains. In this regard, some recent work (Mei et
al., 2007; Titov and McDonald, 2008a) has tried to
model both sentiment and topics. However, these
two models either require postprocessing to calcu-
late the positive/negative coverage in a document
for polarity identification (Mei et al., 2007) or re-
</bodyText>
<note confidence="0.9565608">
Yulan He
Knowledge Media Institute
The Open University
Milton Keynes
MK7 6AA, UK
</note>
<email confidence="0.846161">
Y.He@open.ac.uk
</email>
<page confidence="0.972932">
144
</page>
<note confidence="0.764825">
Proceedings of the Fourteenth Conference on Computational Natural Language Learning, pages 144–152,
Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.9999288125">
quire some kind of supervised setting in which
review text should contain ratings for aspects of
interest (Titov and McDonald, 2008a). More re-
cently, Dasgupta and Ng (2009) proposed an unsu-
pervised sentiment classification algorithm by in-
tegrating user feedbacks into a spectral clustering
algorithm. Features induced for each dimension of
spectral clustering can be considered as sentiment-
oriented topics. Nevertheless, human judgement
of identifying the most important dimensions dur-
ing spectral clustering is required.
Lin and He (2009) proposed a joint sentiment-
topic (JST) model for unsupervised joint senti-
ment topic detection. They assumed that top-
ics are generated dependent on sentiment distri-
butions and then words are generated conditioned
on sentiment-topic pairs. While this is a reason-
able design choice, one may argue that the re-
verse is also true that sentiments may vary ac-
cording to topics. Thus in this paper, we studied
the reverse dependence of the JST model called
Reverse-JST, in which sentiments are generated
dependent on topic distributions in the modelling
process. We also note that, when the topic num-
ber is set to 1, both JST and reversed-JST es-
sentially become a simple latent Dirichlet alloca-
tion (LDA) model with only 5 (number of sen-
timent label) topics, each of which corresponds
to a sentiment label. We called it latent senti-
ment model (LSM) in this paper. Extensive ex-
periments have been conducted on the movie re-
view (MR)1 (Pang et al., 2002) and multi-domain
sentiment (MDS)2 (Blitzer et al., 2007) datasets
to compare the performance of LSM, JST and
Reverse-JST. Results show that all these three
models are able to give either better or compara-
ble performance compared to the existing unsu-
pervised sentiment classification approaches. In
addition, both JST and reverse-JST are able to ex-
tract sentiment-oriented topics. Furthermore, the
fact that reverse-JST always performs worse than
JST suggests that the JST model is more appropri-
ate for joint sentiment topic detection.
The rest of the paper is organized as follows.
Section 2 presents related work. Section 3 de-
scribes the LSM, JST and Reserver-JST models.
Experimental setup and results on the MR and
MDS datasets are discussed in Section 4 and 5 re-
</bodyText>
<footnote confidence="0.9972105">
1http://www.cs.cornell.edu/people/
pabo/movie-review-data
2http://www.cs.jhu.edu/˜mdredze/
datasets/sentiment/index2.html
</footnote>
<bodyText confidence="0.997632">
spectively. Finally, Section 6 concludes the paper
and outlines the future work.
</bodyText>
<sectionHeader confidence="0.999441" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999990212765958">
As opposed to the work (Pang et al., 2002; Pang
and Lee, 2004; Whitelaw et al., 2005; Kennedy
and Inkpen, 2006) that only focused on senti-
ment classification in one particular domain, re-
cent research attempts have been made to address
the problem of sentiment classification across do-
mains. Aue and Gamon (2005) explored vari-
ous strategies for customizing sentiment classifiers
to new domains, where the training is based on
a small number of labelled examples and large
amounts of unlabelled in-domain data. However,
their experiments achieved only limited success,
with most of the classification accuracy below
80%. In the same vein, some more recent work
focused on domain adaption for sentiment classi-
fiers. Blitzer et al. (2007) used the structural corre-
spondence learning (SCL) algorithm with mutual
information. Li and Zong (2008) combined multi-
ple single classifiers trained on individual domains
using SVMs. However, the adaption performance
in (Blitzer et al., 2007) depends on the selection of
pivot features that used to link the source and tar-
get domains; whereas the approach of Li and Zong
(2008) heavily relies on labelled data from all the
domains to train the integrated classifier and thus
lack the flexibility to adapt the trained classifier to
domains where label information is not available.
Recent years have also seen increasing interests
in modelling both sentiment and topics simultane-
ously. The topic-sentiment mixture (TSM) model
(Mei et al., 2007) can jointly model sentiment and
topics by constructing an extra background com-
ponent and two additional sentiment subtopics on
top of the probabilistic latent semantic indexing
(pLSI) (Hofmann, 1999). However, TSM may
suffer from the problem of overfitting the data
which is known as a deficiency of pLSI, and post-
processing is also required in order to calculate
the sentiment prediction for a document. The
multi-aspect sentiment (MAS) model (Titov and
McDonald, 2008a), which is extended from the
multi-grain latent Dirichlet allocation (MG-LDA)
model (Titov and McDonald, 2008b), allows sen-
timent text aggregation for sentiment summary of
each rating aspect extracted from MG-LDA. One
drawback of MAS is that it requires that every as-
pect is rated at least in some documents, which
</bodyText>
<page confidence="0.994523">
145
</page>
<bodyText confidence="0.999984277777778">
is practically infeasible. More recently, Dasgupta
and Ng (2009) proposed an unsupervised sen-
timent classification algorithm where user feed-
backs are provided on the spectral clustering pro-
cess in an interactive manner to ensure that text are
clustered along the sentiment dimension. Features
induced for each dimension of spectral cluster-
ing can be considered as sentiment-oriented top-
ics. Nevertheless, human judgement of identify-
ing the most important dimensions during spectral
clustering is required.
Among various efforts for improving senti-
ment detection accuracy, one direction is to in-
corporate prior information or subjectivity lexi-
con (i.e., words bearing positive or negative sen-
timent) into the sentiment model. Such sen-
timent lexicons can be acquired from domain-
independent sources in many different ways, from
manually built appraisal groups (Whitelaw et
al., 2005), to semi-automatically (Abbasi et al.,
2008) and fully automatically (Kaji and Kitsure-
gawa, 2006) constructed lexicons. When incor-
porating lexical knowledge as prior information
into a sentiment-topic model, Andreevskaia and
Bergler (2008) integrated the lexicon-based and
corpus-based approaches for sentence-level sen-
timent annotation across different domains; Li et
al. (2009) employed lexical prior knowledge for
semi-supervised sentiment classification based on
non-negative matrix tri-factorization, where the
domain-independent prior knowledge was incor-
porated in conjunction with domain-dependent un-
labelled data and a few labelled documents. How-
ever, this approach performed worse than the JST
model on the movie review data even with 40%
labelled documents as will be shown in Section 5.
</bodyText>
<sectionHeader confidence="0.875882" genericHeader="method">
3 Latent Sentiment-Topic Models
</sectionHeader>
<bodyText confidence="0.999129428571429">
This section describes three closely related
Bayesian models for unsupervised sentiment clas-
sification, the latent sentiment model (LSM), the
joint sentiment-topic (JST) model, and the joint
topic sentiment model by reversing the generative
process of sentiment and topics in the JST model,
called Reverse-JST.
</bodyText>
<subsectionHeader confidence="0.997733">
3.1 Latent Sentiment Model (LSM)
</subsectionHeader>
<bodyText confidence="0.999513523809524">
The LSM model, as shown in Figure 1(a), can be
treated as a special case of LDA where a mixture
of only three sentiment labels are modelled, i.e.
positive, negative and neutral.
Assuming that we have a total number of S sen-
timent labels3; a corpus with a collection of D
documents is denoted by C = {d1, d2, ..., dD};
each document in the corpus is a sequence of Nd
words denoted by d = (w1, w2,..., wNd), and
each word in the document is an item from a vo-
cabulary index with V distinct terms denoted by
{1, 2,..., V }. The procedure of generating a word
in LSM starts by firstly choosing a distribution
over three sentiment labels for a document. Fol-
lowing that, one picks up a sentiment label from
the sentiment label distribution and finally draws a
word according to the sentiment label-word distri-
bution.
The joint probability of words and sentiment la-
bel assignment in LSM can be factored into two
terms:
</bodyText>
<equation confidence="0.992024">
P(w, l) = P(w|l)P(l|d). (1)
</equation>
<bodyText confidence="0.9992735">
Letting the superscript −t denote a quantity that
excludes data from the tth position, the conditional
posterior for lt by marginalizing out the random
variables ϕ and π is
</bodyText>
<equation confidence="0.9960305">
P (lt = k|w,l�t, β, �) ∝
N�t
k,d + γk
Nit + Ek γk,
</equation>
<bodyText confidence="0.999988727272727">
where Nwt,k is the number of times word wt has
associated with sentiment label k; Nk is the the
number of times words in the corpus assigned to
sentiment label k; Nk,d is the number of times
sentiment label k has been assigned to some word
tokens in document d; Nd is the total number of
words in the document collection.
Gibbs sampling is used to estimate the poste-
rior distribution of LSM, as well as the JST and
Reverse-JST models that will be discussed in the
following two sections.
</bodyText>
<subsectionHeader confidence="0.999165">
3.2 Joint Sentiment-Topic Model (JST)
</subsectionHeader>
<bodyText confidence="0.908272909090909">
In contrast to LSM that only models document
sentiment, the JST model (Lin and He, 2009)
can detect sentiment and topic simultaneously, by
modelling each document with S (number of sen-
timent labels) topic-document distributions. It
should be noted that when the topic number is
set to 1, JST effectively becomes the LSM model
with only three topics corresponding to each of the
3For all the three models, i.e., LSM, JST and Reverse-
JST, we set the sentiment label number S to 3 representing
the positive, negative and neutral polarities, respectively.
</bodyText>
<equation confidence="0.8305348">
N�t
wt�� + β ·
N�t
k + V β
(2)
</equation>
<page confidence="0.861268">
146
</page>
<figure confidence="0.997243">
(a) (b) (c)
</figure>
<figureCaption confidence="0.999972">
Figure 1: (a) LSM model; (b) JST model; (c) Reverse-JST model.
</figureCaption>
<bodyText confidence="0.98088025">
three sentiment labels. Let T be the total num-
ber of topics, the procedure of generating a word
wi according to the graphical model shown in Fig-
ure 1(b) is:
</bodyText>
<listItem confidence="0.839596222222222">
• For each document d, choose a distribution
πd N Dir(γ).
• For each sentiment label l of document d,
choose a distribution θd,l N Dir(α).
• For each word wi in document d
– choose a sentiment label li N
Multinomial(πd),
– choose a topic zi N Multinomial(θd,li),
– choose a word wi from ϕli , a Multi-
</listItem>
<bodyText confidence="0.973047">
zi
nomial distribution over words condi-
tioned on topic zi and sentiment label li.
In JST, the joint probability of words and topic-
sentiment label assignments can be factored into
three terms:
</bodyText>
<equation confidence="0.998484">
P(w, z, l) = P(w|z,l)P(z|l, d)P(l|d). (3)
</equation>
<bodyText confidence="0.991826">
The conditional posterior for zt and lt can be ob-
tained by marginalizing out the random variables
ϕ, θ, and π:
</bodyText>
<equation confidence="0.9952102">
P(zt = j, lt = k|w, z−t, l−t, α, β,&apos;Y) a
N−t
wt,j,k + β �
N−t
j,k + V β
</equation>
<bodyText confidence="0.99994525">
where Nwt,j,k is the number of times word wt ap-
peared in topic j and with sentiment label k; Nj,k
is the number of times words assigned to topic
j and sentiment label k, Nk,j,d is the number of
times a word from document d has been associ-
ated with topic j and sentiment label k; Nk,d is
the number of times sentiment label k has been
assigned to some word tokens in document d.
</bodyText>
<subsectionHeader confidence="0.87309">
3.3 Reverse Joint Sentiment-Topic Model
</subsectionHeader>
<bodyText confidence="0.958400538461538">
(Reverse-JST)
We also studied a variant of the JST model,
called Reverse-JST. As opposed to JST in which
topic generation is conditioned on sentiment la-
bels, sentiment label generation in Reverse-JST is
dependent on topics. As shown in Figure 1(c),
Reverse-JST is effectively a four-layer hierarchi-
cal Bayesian model, where topics are associated
with documents, under which sentiment labels are
associated with topics and words are associated
with both topics and sentiment labels.
The procedure of generating a word wi in
Reverse-JST is shown below:
</bodyText>
<listItem confidence="0.963657777777778">
• For each document d, choose a distribution
θd N Dir(α).
• For each topic z of document d, choose a dis-
tribution πd,z N Dir(γ).
• For each word wi in document d
– choose a topic zi N Multinomial(θd),
– choose a sentiment label li N
Multinomial(πd,zi),
– choose a word wi from ϕli , a multi-
</listItem>
<bodyText confidence="0.964879375">
zi
nomial distribution over words condi-
tioned on the topic zi and sentiment la-
bel li.
Analogy to JST, in Reverse-JST the joint prob-
ability of words and the topic-sentiment label as-
signments can be factored into the following three
terms:
</bodyText>
<equation confidence="0.981002">
P(w,l, z) = P(w|l, z)P(l|z, d)P(z|d), (5)
</equation>
<bodyText confidence="0.961965">
and the conditional posterior for zt and lt can be
derived by integrating out the random variables ϕ,
</bodyText>
<equation confidence="0.905416642857143">
N−t
j,k,d + α �
N−t
k,d + Tα
N−t
k,d + γk ,(4)
N−t
d + Ek γk
147
0, and 7r, yielding
P(zt = j, lt = k|w, z−t, l−t, α, Q,&apos;Y) ∝
N−t
j,d + α
· N−t
</equation>
<bodyText confidence="0.971678111111111">
d + Tα� (6)
It it noted that most of the terms in the Reverse-
JST posterior is identical to the posterior of JST in
Equation 4, except that Nj,d is the number of times
topic j has been assigned to some word tokens in
document d.
As we do not have a direct sentiment label-
document distribution in Reverse-JST, a distribu-
tion over sentiment label for document P(l|d) is
calculated as P(l|d) = Ez P(l|z, d)P(z|d). For
all the three models, the probability P(l|d) will
be used to determine document sentiment polar-
ity. We define that a document d is classified
as a positive-sentiment document if its probabil-
ity of positive sentiment label given document
P(lpos|d), is greater than its probability of neg-
ative sentiment label given document P(lneg|d),
and vice versa.
</bodyText>
<sectionHeader confidence="0.999724" genericHeader="method">
4 Experimental Setup
</sectionHeader>
<subsectionHeader confidence="0.996859">
4.1 Dataset Description
</subsectionHeader>
<bodyText confidence="0.997791696969697">
Two publicly available datasets, the MR and MDS
datasets, were used in our experiments. The MR
dataset (also known as the polarity dataset) has
become a benchmark for many studies since the
work of Pang et al. (2002). The version 2.0 used in
our experiment consists of 1000 positive and 1000
negative movie reviews drawn from the IMDB
movie archive, with an average of 30 sentences in
each document. We also experimented with an-
other dataset, namely subjective MR, by removing
the sentences that do not bear opinion information
from the MR dataset, following the approach of
Pang and Lee (2004). The resulting dataset still
contains 2000 documents with a total of 334,336
words and 18,013 distinct terms, about half the
size of the original MR dataset without perform-
ing subjectivity detection.
First used by Blitzer et al. (2007), the MDS
dataset contains 4 different types of product re-
views taken from Amazon.com including books,
DVDs, electronics and kitchen appliances, with
1000 positive and 1000 negative examples for each
domain4.
4We did not perform subjectivity detection on the MDS
dataset since its average document length is much shorter
Preprocessing was performed on both of the
datasets. Firstly, punctuation, numbers, non-
alphabet characters and stop words were removed.
Secondly, standard stemming was performed in
order to reduce the vocabulary size and address the
issue of data sparseness. Summary statistics of the
datasets before and after preprocessing are shown
in Table 1.
</bodyText>
<subsectionHeader confidence="0.943084">
4.2 Defining Model Priors
</subsectionHeader>
<bodyText confidence="0.981970473684211">
In the experiments, two subjectivity lexicons,
namely the MPQA5 and the appraisal lexicon6,
were combined and incorporated as prior infor-
mation into the model learning. These two lexi-
cons contain lexical words whose polarity orien-
tation have been fully specified. We extracted the
words with strong positive and negative orienta-
tion and performed stemming in the preprocess-
ing. In addition, words whose polarity changed af-
ter stemming were removed automatically, result-
ing in 1584 positive and 2612 negative words, re-
spectively. It is worth noting that the lexicons used
here are fully domain-independent and do not bear
any supervised information specifically to the MR,
subjMR and MDS datasets. Finally, the prior in-
formation was produced by retaining all words in
the MPQA and appraisal lexicons that occurred in
the experimental datasets. The prior information
statistics for each dataset is listed in the last row of
Table 1.
In contrast to Lin and He (2009) that only uti-
lized prior information during the initialization of
the posterior distributions, we use the prior infor-
mation in the Gibbs sampling inference step and
argue that this is a more appropriate experimental
setting. For the Gibbs sampling step of JST and
Reverse-JST, if the currently observed word token
matches a word in the sentiment lexicon, a cor-
responding sentiment label will be assigned and
only a new topic will be sampled. Otherwise, a
new sentiment-topic pair will be sampled for that
word token. For LSM, if the current word token
matches a word in the sentiment lexicon, a corre-
sponding sentiment label will be assigned and skip
the Gibbs sampling procedure. Otherwise, a new
sentiment label will be sampled.
than that of the MR dataset, with some documents even hav-
ing one sentence only.
</bodyText>
<footnote confidence="0.960145666666667">
5http://www.cs.pitt.edu/mpqa/
6http://lingcog.iit.edu/arc/appraisal_
lexicon_2007b.tar.gz
</footnote>
<equation confidence="0.927542">
N−t
w�,j,k + Q ·
N−t
j,k + V Q
N−t
k,j,d + &apos;Yk
N−t
j,d + Ek&apos;Yk
</equation>
<page confidence="0.998175">
148
</page>
<tableCaption confidence="0.981876">
Table 1: Dataset and sentiment lexicon statistics. (Note:†denotes before preprocessing and * denotes
after preprocessing.)
</tableCaption>
<table confidence="0.999777111111111">
Dataset # of words
MR subjMR MDS
Book DVD Electronic Kitchen
Corpus size† 1,331,252 812,250 352,020 341,234 221,331 186,122
Corpus size* 627,317 334,336 157,441 153,422 95,441 79,654
Vocabulary† 38,906 34,559 22,028 21,424 10,669 9,525
Vocabulary* 25,166 18,013 14,459 14,806 7,063 6,252
# of lexicon 1248/1877 1150/1667 1000/1352 979/1307 574/552 582/504
(pos./neg.)*
</table>
<tableCaption confidence="0.979264">
Table 2: LSM sentiment classification results.
</tableCaption>
<table confidence="0.995305777777778">
Aaccuracy (%)
MR subjMR MDS
Book DVD Electronic Kitchen MDS overall
LSM (without prior info.) 61.7 57.9 51.6 53.5 58.4 56.8 55.1
LSM (with prior info.) 74.1 76.1 64.2 66.3 72.5 74.1 69.3
Dasgupta and Ng (2009) 70.9 N/A 69.5 70.8 65.8 69.7 68.9
Li et al.(2009) with 10% doc. label 60 N/A 62
Li et al.(2009) with 40% doc. label 73.5 N/A 73
N/A
</table>
<sectionHeader confidence="0.996425" genericHeader="evaluation">
5 Experimental Results
</sectionHeader>
<subsectionHeader confidence="0.998108">
5.1 LSM Sentiment Classification Results
</subsectionHeader>
<bodyText confidence="0.999987258064516">
In this section, we discuss the sentiment classifica-
tion results of LSM at document level by incorpo-
rating prior information extracted from the MPQA
and appraisal lexicon. The symmetry Dirichlet
prior Q was set to 0.01, and the asymmetric Dirich-
let sentiment prior -y was set to 0.01 and 0.9 for
the positive and negative sentiment label, respec-
tively. Classification accuracies were averaged
over 5 runs for each dataset with 2000 Gibbs sam-
pling iterations.
As can be observed from Table 2, the perfor-
mance of LSM is only mediocre for all the 6
datasets when no prior information was incorpo-
rated. A significant improvement, with an aver-
age of more than 13%, is observed after incor-
porating prior information, especially notable for
subjMR and kitchen with 18.2% and 17.3% im-
provement, respectively. It is also noted that LSM
with subjMR dataset achieved 2% improvement
over the original MR dataset, implying that the
subjMR dataset has better representation of sub-
jective information than the original dataset by fil-
tering out the objective contents. For the MDS
dataset, LSM achieved 72.5% and 74.1% accu-
racy on electronic and kitchen domain respec-
tively, which is much better than the book and
DVD domain with only around 65% accuracy.
Manually analysing the MDS dataset reveals that
the book and DVD reviews often contain a lot
of descriptions of book contents or movie plots,
which make the reviews from these two domains
difficult to classify; whereas in the electronic and
kitchen domain, comments on the product are of-
ten expressed in a straightforward manner.
When compared to the recently proposed un-
supervised approach based on a spectral cluster-
ing algorithm (Dasgupta and Ng, 2009), except
for the book and DVD domain, LSM achieved
better performance in all the other domains with
more than 5% overall improvement. Neverthe-
less, the approach proposed by Dasgupta and Ng
(2009) requires users to specify which dimensions
(defined by the eigenvectors in spectral cluster-
ing) are most closely related to sentiment by in-
specting a set of features derived from the re-
views for each dimension, and clustering is per-
formed again on the data to derive the final re-
sults. In all the Bayesian models studied here, no
human judgement is required. Another recently
proposed non-negative matrix tri-factorization ap-
proach (Li et al., 2009) also employed lexical prior
knowledge for semi-supervised sentiment classi-
fication. However, when incorporating 10% of
labelled documents for training, the non-negative
matrix tri-factorization approach performed much
worse than LSM, with only around 60% accu-
racy achieved for all the datasets. Even with 40%
labelled documents, it still performs worse than
LSM on the MR dataset and slightly outperforms
LSM on the MDS dataset. It is worth noting that
no labelled documents were used in the LSM re-
sults reported here.
</bodyText>
<page confidence="0.99849">
149
</page>
<figureCaption confidence="0.999026">
Figure 2: JST and Reverse-JST sentiment classification results with multiple topics.
</figureCaption>
<subsectionHeader confidence="0.996316">
5.2 JST and Reverse-JST Results with
Multiple Topics
</subsectionHeader>
<bodyText confidence="0.999971063492064">
As both JST and Reverse-JST model document
level sentiment and mixture of topic simulta-
neously, it is worth to explore how the senti-
ment classification and topic extraction tasks af-
fect/benifit each other. With this in mind, we
conducted a set of experiments on both JST and
Reverse-JST, with topic number varying from 30,
50 to 100. The symmetry Dirichlet prior α and Q
were set to 50/T and 0.01 respectively for both
models. The asymmetry sentiment prior -y was
empirically set to (0.01, 1.8) for JST and (0.01,
0.012) for Reverse-JST, corresponding to positive
and negative sentiment prior, respectively. Results
were averaged over 5 runs with 2000 Gibbs sam-
pling iterations.
As can be seen from Figure 2 that, for both mod-
els, the sentiment classification accuracy based on
the subjMR dataset still outperformed the results
based on the original MR dataset, where an over-
all improvement of 3% is observed for JST and
about 2% for Reverse-JST. When comparing JST
and Reverse-JST, it can be observed that Reverse-
JST performed slightly worse than JST for all sets
of experiments with about 1% to 2% drop in ac-
curacy. By closely examining the posterior of JST
and Reverse-JST (c.f. Equation 4 and 6), we no-
ticed that the count Nj�d (number of times topic j
associated with some word tokens in document d)
in the Reverse-JST posterior would be relatively
small due to the factor of large topic number set-
ting. On the contrary, the count Nk�d (number of
times sentiment label k assigned to some word to-
kens in document d) in the JST posterior would be
relatively large as k is only defined over 3 differ-
ent sentiment labels. This essentially makes JST
less sensitive to the data sparseness problem and
the perturbation of hyperparameter setting. In ad-
dition, JST encodes an assumption that there is ap-
proximately a single sentiment for the entire docu-
ment, i.e. the documents are usually either mostly
positive or mostly negative. This assumption is
important as it allows the model to cluster different
terms which share similar sentiment. In Reverse-
JST, this assumption is not enforced unless only
one topic for each sentiment is defined. Therefore,
JST appears to be a more appropriate model de-
sign for joint sentiment topic detection.
In addition, it is observed that the sentiment
classification accuracy of both JST and Reverse-
JST drops slightly when the topic number in-
creases from 30 to 100, with the changes of 2%
(MR) and 1.5% (subjMR and MDS overall re-
sult) being observed for both models. This is
likely due to the fact that when the topic number
increases, the probability mass attracted under a
sentiment-topic pair would become smaller, which
essentially creates data sparseness problem. When
comparing with LSM, we notice that the differ-
ence in sentiment classification accuracy is only
marginal by additionally modelling a mixture of
topics. But both JST and Reverse-JST are able to
extract sentiment-oriented topics apart from docu-
ment level sentiment detection.
</bodyText>
<page confidence="0.998986">
150
</page>
<tableCaption confidence="0.999341">
Table 3: Topic examples extracted by JST under different sentiment labels.
</tableCaption>
<bodyText confidence="0.959010823529412">
Book DVD Electronic Kitchen
pos. neg. pos. neg. pos. neg. pos. neg.
recip war action murder mous drive color fan
food militari good killer hand fail beauti room
cook armi fight crime logitech data plate cool
cookbook soldier right cop comfort complet durabl air
beauti govern scene crime scroll manufactur qualiti loud
simpl thing chase case wheel failur fiestawar nois
eat evid hit prison smooth lose blue live
famili led art detect feel backup finger annoi
ic iraq martial investig accur poorli white blow
kitchen polici stunt mysteri track error dinnerwar vornado
varieti destruct chan commit touch storag bright bedroom
good critic brilliant thriller click gb purpl inferior
pictur inspect hero attornei conveni flash scarlet window
tast invas style suspect month disast dark vibrat
cream court chines shock mice recogn eleg power
</bodyText>
<subsectionHeader confidence="0.980801">
5.3 Topic Extraction
</subsectionHeader>
<bodyText confidence="0.999854964285714">
We also evaluated the effectiveness of topic sen-
timent captured. In contrast to LDA in which a
word is drawn from the topic-word distribution,
in JST or Reverse-JST, a word is drawn from the
distribution over words conditioned on both topic
and sentiment label. As an illustration, Table 3
shows eight topic examples extracted from the
MDS dataset by JST, where each topic was drawn
from a particular product domain under positive or
negative sentiment label.
As can be seen from Table 3, the eight extracted
topics are quite informative and coherent, and each
of the topics represents a certain product review
from the corresponding domain. For example,
the positive book topic probably discusses a good
cookbook; the positive DVD topic is apparently
about a popular action movie by Jackie Chan; the
negative electronic topic is likely to be complains
regarding data lose due to the flash drive failure,
and the negative kitchen topic is probably the dis-
satisfaction of the high noise level of the Vornado
brand fan. In terms of topic sentiment, by examin-
ing through the topics in the table, it is evident that
topics under the positive and negative sentiment
label indeed bear positive and negative sentiment
respectively. The above analysis reveals the effec-
tiveness of JST in extracting topics and capturing
topic sentiment from text.
</bodyText>
<sectionHeader confidence="0.998596" genericHeader="conclusions">
6 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999972928571429">
In this paper, we studied three closed related
Bayesian models for unsupervised sentiment de-
tection, namely LSM, JST and Reverse-JST. As
opposing to most of the existing approaches to
sentiment classification which favour in super-
vised learning, these three models detect senti-
ment in a fully unsupervised manner. While all the
three models gives either better or comparable per-
formance compared to the existing approaches on
unsupervised sentiment classification on the MR
and MDS datasets, JST and Reverse-JST can also
model a mixture of topics and the sentiment as-
sociated with each topic. Moreover, extensive ex-
periments conducted on the datasets from differ-
ent domains reveal that JST always outperformed
Reverse-JST, suggesting JST being a more appro-
priate model design for joint sentiment topic de-
tection.
There are several directions we plan to inves-
tigate in the future. One is incremental learn-
ing of the JST parameters when facing with new
data. Another one is semi-supervised learning
of the JST model with some supervised informa-
tion being incorporating into the model parameter
estimation procedure such as some known topic
knowledge for certain product reviews or the doc-
ument labels derived automatically from the user-
supplied review ratings.
</bodyText>
<sectionHeader confidence="0.999271" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999520444444444">
Ahmed Abbasi, Hsinchun Chen, and Arab Salem.
2008. Sentiment analysis in multiple languages:
Feature selection for opinion classification in web
forums. ACM Trans. Inf. Syst., 26(3):1–34.
Alina Andreevskaia and Sabine Bergler. 2008. When
specialists and generalists work together: Overcom-
ing domain dependence in sentiment tagging. In
Proceedings of (ACL-HLT), pages 290–298.
A. Aue and M. Gamon. 2005. Customizing sentiment
</reference>
<page confidence="0.98054">
151
</page>
<reference confidence="0.997975538461538">
classifiers to new domains: a case study. In Pro-
ceedings of Recent Advances in Natural Language
Processing (RANLP).
John Blitzer, Mark Dredze, and Fernando Pereira.
2007. Biographies, bollywood, boom-boxes and
blenders: Domain adaptation for sentiment classi-
fication. In Proceedings of the Association for Com-
putational Linguistics (ACL), pages 440–447.
S. Dasgupta and V. Ng. 2009. Topic-wise, Sentiment-
wise, or Otherwise? Identifying the Hidden Dimen-
sion for Unsupervised Text Classification. In Pro-
ceedings of the 2009 Conference on Empirical Meth-
ods in Natural Language Processing, pages 580–
589.
Thomas Hofmann. 1999. Probabilistic latent semantic
indexing. In Proceedings of the ACM Special Inter-
est Group on Information Retrieval (SIGIR), pages
50–57.
Nobuhiro Kaji and Masaru Kitsuregawa. 2006. Au-
tomatic construction of polarity-tagged corpus from
html documents. In Proceedings of the COL-
ING/ACL on Main conference poster sessions, pages
452–459.
A. Kennedy and D. Inkpen. 2006. Sentiment classi-
fication of movie reviews using contextual valence
shifters. Computational Intelligence, 22(2):110–
125.
Shoushan Li and Chengqing Zong. 2008. Multi-
domain sentiment classification. In Proceedings of
the Association for Computational Linguistics and
the Human Language Technology Conference (ACL-
HLT), Short Papers, pages 257–260.
Tao Li, Yi Zhang, and Vikas Sindhwani. 2009. A non-
negative matrix tri-factorization approach to senti-
ment classification with lexical prior knowledge. In
Proceedings of (ACL-IJCNLP), pages 244–252.
Chenghua Lin and Yulan He. 2009. Joint senti-
ment/topic model for sentiment analysis. In Pro-
ceedings of the ACM international conference on In-
formation and knowledge management (CIKM).
Ryan McDonald, Kerry Hannan, Tyler Neylon, Mike
Wells, and Jeff Reynar. 2007. Structured models for
fine-to-coarse sentiment analysis. In Proceedings of
the Annual Meeting of the Association of Computa-
tional Linguistics (ACL), pages 432–439.
Qiaozhu Mei, Xu Ling, Matthew Wondra, Hang Su,
and ChengXiang Zhai. 2007. Topic sentiment mix-
ture: modeling facets and opinions in weblogs. In
Proceedings of the conference on World Wide Web
(WWW), pages 171–180.
Bo Pang and Lillian Lee. 2004. A sentimental ed-
ucation: sentiment analysis using subjectivity sum-
marization based on minimum cuts. In Proceedings
of the Annual Meeting on Association for Computa-
tional Linguistics (ACL), page 271.
Bo Pang and Lillian Lee. 2008. Opinion mining and
sentiment analysis. Found. Trends Inf. Retr., 2(1-
2):1–135.
Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.
2002. Thumbs up?: sentiment classification using
machine learning techniques. In Proceedings of the
Conference on Empirical Methods in Natural Lan-
guage Processing (EMNLP), pages 79–86.
Ivan Titov and Ryan McDonald. 2008a. A joint model
of text and aspect ratings for sentiment summariza-
tion. In Proceedings of the Aunal Meeting on Asso-
ciation for Computational Linguistics and the Hu-
man Language Technology Conference (ACL-HLT),
pages 308–316.
Ivan Titov and Ryan McDonald. 2008b. Modeling on-
line reviews with multi-grain topic models. In Pro-
ceeding of the International Conference on World
Wide Web (WWW 08’), pages 111–120.
Casey Whitelaw, Navendu Garg, and Shlomo Arga-
mon. 2005. Using appraisal groups for sentiment
analysis. In Proceedings of the ACM international
conference on Information and Knowledge Manage-
ment (CIKM), pages 625–631.
</reference>
<page confidence="0.998117">
152
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.484404">
<title confidence="0.9986505">A Comparative Study of Bayesian Models for Unsupervised Sentiment Detection</title>
<author confidence="0.921261">Chenghua</author>
<affiliation confidence="0.997872666666667">School of Computing and University of</affiliation>
<address confidence="0.548177">Exeter, EX4 4QF,</address>
<email confidence="0.991459">cl322@exeter.ac.uk</email>
<abstract confidence="0.998355">This paper presents a comparative study of three closely related Bayesian models for unsupervised document level sentiment classification, namely, the latent sentiment model (LSM), the joint sentimenttopic (JST) model, and the Reverse-JST model. Extensive experiments have been conducted on two corpora, the movie review dataset and the multi-domain sentiment dataset. It has been found that while all the three models achieve either better or comparable performance on these two corpora when compared to the existing unsupervised sentiment classification approaches, both JST and Reverse-JST are able to extract sentiment-oriented topics. In addition, Reverse-JST always performs worse than JST suggesting that the JST model is more appropriate for joint sentiment topic detection.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Ahmed Abbasi</author>
<author>Hsinchun Chen</author>
<author>Arab Salem</author>
</authors>
<title>Sentiment analysis in multiple languages: Feature selection for opinion classification in web forums.</title>
<date>2008</date>
<journal>ACM Trans. Inf. Syst.,</journal>
<volume>26</volume>
<issue>3</issue>
<contexts>
<context position="9840" citStr="Abbasi et al., 2008" startWordPosition="1496" endWordPosition="1499">each dimension of spectral clustering can be considered as sentiment-oriented topics. Nevertheless, human judgement of identifying the most important dimensions during spectral clustering is required. Among various efforts for improving sentiment detection accuracy, one direction is to incorporate prior information or subjectivity lexicon (i.e., words bearing positive or negative sentiment) into the sentiment model. Such sentiment lexicons can be acquired from domainindependent sources in many different ways, from manually built appraisal groups (Whitelaw et al., 2005), to semi-automatically (Abbasi et al., 2008) and fully automatically (Kaji and Kitsuregawa, 2006) constructed lexicons. When incorporating lexical knowledge as prior information into a sentiment-topic model, Andreevskaia and Bergler (2008) integrated the lexicon-based and corpus-based approaches for sentence-level sentiment annotation across different domains; Li et al. (2009) employed lexical prior knowledge for semi-supervised sentiment classification based on non-negative matrix tri-factorization, where the domain-independent prior knowledge was incorporated in conjunction with domain-dependent unlabelled data and a few labelled docu</context>
</contexts>
<marker>Abbasi, Chen, Salem, 2008</marker>
<rawString>Ahmed Abbasi, Hsinchun Chen, and Arab Salem. 2008. Sentiment analysis in multiple languages: Feature selection for opinion classification in web forums. ACM Trans. Inf. Syst., 26(3):1–34.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alina Andreevskaia</author>
<author>Sabine Bergler</author>
</authors>
<title>When specialists and generalists work together: Overcoming domain dependence in sentiment tagging.</title>
<date>2008</date>
<booktitle>In Proceedings of (ACL-HLT),</booktitle>
<pages>290--298</pages>
<contexts>
<context position="3275" citStr="Andreevskaia and Bergler, 2008" startWordPosition="487" endWordPosition="490">n different domains (Aue and Gamon, 2005). Moreover, aside from the diversity of genres and large-scale size of Web corpora, user-generated contents evolve rapidly over time, which demands much more efficient algorithms for sentiment analysis than the current approaches can offer. These observations have thus motivated the problem of using unsupervised approaches for domain-independent joint sentiment topic detection. Some recent research efforts have been made to adapt sentiment classifiers trained on one domain to another domain (Aue and Gamon, 2005; Blitzer et al., 2007; Li and Zong, 2008; Andreevskaia and Bergler, 2008). However, the adaption performance of these lines of work pretty much depends on the distribution similarity between the source and target domain, and considerable effort is still required to obtain labelled data for training. Intuitively, sentiment polarities are dependent on contextual information, such as topics or domains. In this regard, some recent work (Mei et al., 2007; Titov and McDonald, 2008a) has tried to model both sentiment and topics. However, these two models either require postprocessing to calculate the positive/negative coverage in a document for polarity identification (Me</context>
<context position="10035" citStr="Andreevskaia and Bergler (2008)" startWordPosition="1522" endWordPosition="1525">ing is required. Among various efforts for improving sentiment detection accuracy, one direction is to incorporate prior information or subjectivity lexicon (i.e., words bearing positive or negative sentiment) into the sentiment model. Such sentiment lexicons can be acquired from domainindependent sources in many different ways, from manually built appraisal groups (Whitelaw et al., 2005), to semi-automatically (Abbasi et al., 2008) and fully automatically (Kaji and Kitsuregawa, 2006) constructed lexicons. When incorporating lexical knowledge as prior information into a sentiment-topic model, Andreevskaia and Bergler (2008) integrated the lexicon-based and corpus-based approaches for sentence-level sentiment annotation across different domains; Li et al. (2009) employed lexical prior knowledge for semi-supervised sentiment classification based on non-negative matrix tri-factorization, where the domain-independent prior knowledge was incorporated in conjunction with domain-dependent unlabelled data and a few labelled documents. However, this approach performed worse than the JST model on the movie review data even with 40% labelled documents as will be shown in Section 5. 3 Latent Sentiment-Topic Models This sect</context>
</contexts>
<marker>Andreevskaia, Bergler, 2008</marker>
<rawString>Alina Andreevskaia and Sabine Bergler. 2008. When specialists and generalists work together: Overcoming domain dependence in sentiment tagging. In Proceedings of (ACL-HLT), pages 290–298.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Aue</author>
<author>M Gamon</author>
</authors>
<title>Customizing sentiment classifiers to new domains: a case study.</title>
<date>2005</date>
<booktitle>In Proceedings of Recent Advances in Natural Language Processing (RANLP).</booktitle>
<contexts>
<context position="2685" citStr="Aue and Gamon, 2005" startWordPosition="400" endWordPosition="404">ntifying the overall sentiment polarity of a document has been well studied, most of the work is highly domain dependent and favoured in supervised learning (Pang et al., 2002; Pang and Lee, 2004; Whitelaw et al., 2005; Kennedy and Inkpen, 2006; McDonald et al., 2007), requiring annotated corpora for every possible domain of interest, which is impractical for real applications. Also, it is well-known that sentiment classifiers trained on one domain often fail to produce satisfactory results when shifted to another domain, since sentiment expression can be quite different in different domains (Aue and Gamon, 2005). Moreover, aside from the diversity of genres and large-scale size of Web corpora, user-generated contents evolve rapidly over time, which demands much more efficient algorithms for sentiment analysis than the current approaches can offer. These observations have thus motivated the problem of using unsupervised approaches for domain-independent joint sentiment topic detection. Some recent research efforts have been made to adapt sentiment classifiers trained on one domain to another domain (Aue and Gamon, 2005; Blitzer et al., 2007; Li and Zong, 2008; Andreevskaia and Bergler, 2008). However,</context>
<context position="6957" citStr="Aue and Gamon (2005)" startWordPosition="1055" endWordPosition="1058">perimental setup and results on the MR and MDS datasets are discussed in Section 4 and 5 re1http://www.cs.cornell.edu/people/ pabo/movie-review-data 2http://www.cs.jhu.edu/˜mdredze/ datasets/sentiment/index2.html spectively. Finally, Section 6 concludes the paper and outlines the future work. 2 Related Work As opposed to the work (Pang et al., 2002; Pang and Lee, 2004; Whitelaw et al., 2005; Kennedy and Inkpen, 2006) that only focused on sentiment classification in one particular domain, recent research attempts have been made to address the problem of sentiment classification across domains. Aue and Gamon (2005) explored various strategies for customizing sentiment classifiers to new domains, where the training is based on a small number of labelled examples and large amounts of unlabelled in-domain data. However, their experiments achieved only limited success, with most of the classification accuracy below 80%. In the same vein, some more recent work focused on domain adaption for sentiment classifiers. Blitzer et al. (2007) used the structural correspondence learning (SCL) algorithm with mutual information. Li and Zong (2008) combined multiple single classifiers trained on individual domains using</context>
</contexts>
<marker>Aue, Gamon, 2005</marker>
<rawString>A. Aue and M. Gamon. 2005. Customizing sentiment classifiers to new domains: a case study. In Proceedings of Recent Advances in Natural Language Processing (RANLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Blitzer</author>
<author>Mark Dredze</author>
<author>Fernando Pereira</author>
</authors>
<title>Biographies, bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification.</title>
<date>2007</date>
<booktitle>In Proceedings of the Association for Computational Linguistics (ACL),</booktitle>
<pages>440--447</pages>
<contexts>
<context position="3223" citStr="Blitzer et al., 2007" startWordPosition="479" endWordPosition="482">iment expression can be quite different in different domains (Aue and Gamon, 2005). Moreover, aside from the diversity of genres and large-scale size of Web corpora, user-generated contents evolve rapidly over time, which demands much more efficient algorithms for sentiment analysis than the current approaches can offer. These observations have thus motivated the problem of using unsupervised approaches for domain-independent joint sentiment topic detection. Some recent research efforts have been made to adapt sentiment classifiers trained on one domain to another domain (Aue and Gamon, 2005; Blitzer et al., 2007; Li and Zong, 2008; Andreevskaia and Bergler, 2008). However, the adaption performance of these lines of work pretty much depends on the distribution similarity between the source and target domain, and considerable effort is still required to obtain labelled data for training. Intuitively, sentiment polarities are dependent on contextual information, such as topics or domains. In this regard, some recent work (Mei et al., 2007; Titov and McDonald, 2008a) has tried to model both sentiment and topics. However, these two models either require postprocessing to calculate the positive/negative co</context>
<context position="5718" citStr="Blitzer et al., 2007" startWordPosition="868" endWordPosition="871">this paper, we studied the reverse dependence of the JST model called Reverse-JST, in which sentiments are generated dependent on topic distributions in the modelling process. We also note that, when the topic number is set to 1, both JST and reversed-JST essentially become a simple latent Dirichlet allocation (LDA) model with only 5 (number of sentiment label) topics, each of which corresponds to a sentiment label. We called it latent sentiment model (LSM) in this paper. Extensive experiments have been conducted on the movie review (MR)1 (Pang et al., 2002) and multi-domain sentiment (MDS)2 (Blitzer et al., 2007) datasets to compare the performance of LSM, JST and Reverse-JST. Results show that all these three models are able to give either better or comparable performance compared to the existing unsupervised sentiment classification approaches. In addition, both JST and reverse-JST are able to extract sentiment-oriented topics. Furthermore, the fact that reverse-JST always performs worse than JST suggests that the JST model is more appropriate for joint sentiment topic detection. The rest of the paper is organized as follows. Section 2 presents related work. Section 3 describes the LSM, JST and Rese</context>
<context position="7380" citStr="Blitzer et al. (2007)" startWordPosition="1120" endWordPosition="1123">hat only focused on sentiment classification in one particular domain, recent research attempts have been made to address the problem of sentiment classification across domains. Aue and Gamon (2005) explored various strategies for customizing sentiment classifiers to new domains, where the training is based on a small number of labelled examples and large amounts of unlabelled in-domain data. However, their experiments achieved only limited success, with most of the classification accuracy below 80%. In the same vein, some more recent work focused on domain adaption for sentiment classifiers. Blitzer et al. (2007) used the structural correspondence learning (SCL) algorithm with mutual information. Li and Zong (2008) combined multiple single classifiers trained on individual domains using SVMs. However, the adaption performance in (Blitzer et al., 2007) depends on the selection of pivot features that used to link the source and target domains; whereas the approach of Li and Zong (2008) heavily relies on labelled data from all the domains to train the integrated classifier and thus lack the flexibility to adapt the trained classifier to domains where label information is not available. Recent years have </context>
<context position="17618" citStr="Blitzer et al. (2007)" startWordPosition="2861" endWordPosition="2864"> (2002). The version 2.0 used in our experiment consists of 1000 positive and 1000 negative movie reviews drawn from the IMDB movie archive, with an average of 30 sentences in each document. We also experimented with another dataset, namely subjective MR, by removing the sentences that do not bear opinion information from the MR dataset, following the approach of Pang and Lee (2004). The resulting dataset still contains 2000 documents with a total of 334,336 words and 18,013 distinct terms, about half the size of the original MR dataset without performing subjectivity detection. First used by Blitzer et al. (2007), the MDS dataset contains 4 different types of product reviews taken from Amazon.com including books, DVDs, electronics and kitchen appliances, with 1000 positive and 1000 negative examples for each domain4. 4We did not perform subjectivity detection on the MDS dataset since its average document length is much shorter Preprocessing was performed on both of the datasets. Firstly, punctuation, numbers, nonalphabet characters and stop words were removed. Secondly, standard stemming was performed in order to reduce the vocabulary size and address the issue of data sparseness. Summary statistics o</context>
</contexts>
<marker>Blitzer, Dredze, Pereira, 2007</marker>
<rawString>John Blitzer, Mark Dredze, and Fernando Pereira. 2007. Biographies, bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification. In Proceedings of the Association for Computational Linguistics (ACL), pages 440–447.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Dasgupta</author>
<author>V Ng</author>
</authors>
<title>Topic-wise, Sentimentwise, or Otherwise? Identifying the Hidden Dimension for Unsupervised Text Classification.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>580--589</pages>
<contexts>
<context position="4352" citStr="Dasgupta and Ng (2009)" startWordPosition="648" endWordPosition="651">However, these two models either require postprocessing to calculate the positive/negative coverage in a document for polarity identification (Mei et al., 2007) or reYulan He Knowledge Media Institute The Open University Milton Keynes MK7 6AA, UK Y.He@open.ac.uk 144 Proceedings of the Fourteenth Conference on Computational Natural Language Learning, pages 144–152, Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics quire some kind of supervised setting in which review text should contain ratings for aspects of interest (Titov and McDonald, 2008a). More recently, Dasgupta and Ng (2009) proposed an unsupervised sentiment classification algorithm by integrating user feedbacks into a spectral clustering algorithm. Features induced for each dimension of spectral clustering can be considered as sentimentoriented topics. Nevertheless, human judgement of identifying the most important dimensions during spectral clustering is required. Lin and He (2009) proposed a joint sentimenttopic (JST) model for unsupervised joint sentiment topic detection. They assumed that topics are generated dependent on sentiment distributions and then words are generated conditioned on sentiment-topic pa</context>
<context position="8979" citStr="Dasgupta and Ng (2009)" startWordPosition="1369" endWordPosition="1372">e problem of overfitting the data which is known as a deficiency of pLSI, and postprocessing is also required in order to calculate the sentiment prediction for a document. The multi-aspect sentiment (MAS) model (Titov and McDonald, 2008a), which is extended from the multi-grain latent Dirichlet allocation (MG-LDA) model (Titov and McDonald, 2008b), allows sentiment text aggregation for sentiment summary of each rating aspect extracted from MG-LDA. One drawback of MAS is that it requires that every aspect is rated at least in some documents, which 145 is practically infeasible. More recently, Dasgupta and Ng (2009) proposed an unsupervised sentiment classification algorithm where user feedbacks are provided on the spectral clustering process in an interactive manner to ensure that text are clustered along the sentiment dimension. Features induced for each dimension of spectral clustering can be considered as sentiment-oriented topics. Nevertheless, human judgement of identifying the most important dimensions during spectral clustering is required. Among various efforts for improving sentiment detection accuracy, one direction is to incorporate prior information or subjectivity lexicon (i.e., words beari</context>
<context position="20992" citStr="Dasgupta and Ng (2009)" startWordPosition="3387" endWordPosition="3390">aset # of words MR subjMR MDS Book DVD Electronic Kitchen Corpus size† 1,331,252 812,250 352,020 341,234 221,331 186,122 Corpus size* 627,317 334,336 157,441 153,422 95,441 79,654 Vocabulary† 38,906 34,559 22,028 21,424 10,669 9,525 Vocabulary* 25,166 18,013 14,459 14,806 7,063 6,252 # of lexicon 1248/1877 1150/1667 1000/1352 979/1307 574/552 582/504 (pos./neg.)* Table 2: LSM sentiment classification results. Aaccuracy (%) MR subjMR MDS Book DVD Electronic Kitchen MDS overall LSM (without prior info.) 61.7 57.9 51.6 53.5 58.4 56.8 55.1 LSM (with prior info.) 74.1 76.1 64.2 66.3 72.5 74.1 69.3 Dasgupta and Ng (2009) 70.9 N/A 69.5 70.8 65.8 69.7 68.9 Li et al.(2009) with 10% doc. label 60 N/A 62 Li et al.(2009) with 40% doc. label 73.5 N/A 73 N/A 5 Experimental Results 5.1 LSM Sentiment Classification Results In this section, we discuss the sentiment classification results of LSM at document level by incorporating prior information extracted from the MPQA and appraisal lexicon. The symmetry Dirichlet prior Q was set to 0.01, and the asymmetric Dirichlet sentiment prior -y was set to 0.01 and 0.9 for the positive and negative sentiment label, respectively. Classification accuracies were averaged over 5 run</context>
<context position="22884" citStr="Dasgupta and Ng, 2009" startWordPosition="3703" endWordPosition="3706"> LSM achieved 72.5% and 74.1% accuracy on electronic and kitchen domain respectively, which is much better than the book and DVD domain with only around 65% accuracy. Manually analysing the MDS dataset reveals that the book and DVD reviews often contain a lot of descriptions of book contents or movie plots, which make the reviews from these two domains difficult to classify; whereas in the electronic and kitchen domain, comments on the product are often expressed in a straightforward manner. When compared to the recently proposed unsupervised approach based on a spectral clustering algorithm (Dasgupta and Ng, 2009), except for the book and DVD domain, LSM achieved better performance in all the other domains with more than 5% overall improvement. Nevertheless, the approach proposed by Dasgupta and Ng (2009) requires users to specify which dimensions (defined by the eigenvectors in spectral clustering) are most closely related to sentiment by inspecting a set of features derived from the reviews for each dimension, and clustering is performed again on the data to derive the final results. In all the Bayesian models studied here, no human judgement is required. Another recently proposed non-negative matrix</context>
</contexts>
<marker>Dasgupta, Ng, 2009</marker>
<rawString>S. Dasgupta and V. Ng. 2009. Topic-wise, Sentimentwise, or Otherwise? Identifying the Hidden Dimension for Unsupervised Text Classification. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 580– 589.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Hofmann</author>
</authors>
<title>Probabilistic latent semantic indexing.</title>
<date>1999</date>
<booktitle>In Proceedings of the ACM Special Interest Group on Information Retrieval (SIGIR),</booktitle>
<pages>50--57</pages>
<contexts>
<context position="8324" citStr="Hofmann, 1999" startWordPosition="1267" endWordPosition="1268">ains; whereas the approach of Li and Zong (2008) heavily relies on labelled data from all the domains to train the integrated classifier and thus lack the flexibility to adapt the trained classifier to domains where label information is not available. Recent years have also seen increasing interests in modelling both sentiment and topics simultaneously. The topic-sentiment mixture (TSM) model (Mei et al., 2007) can jointly model sentiment and topics by constructing an extra background component and two additional sentiment subtopics on top of the probabilistic latent semantic indexing (pLSI) (Hofmann, 1999). However, TSM may suffer from the problem of overfitting the data which is known as a deficiency of pLSI, and postprocessing is also required in order to calculate the sentiment prediction for a document. The multi-aspect sentiment (MAS) model (Titov and McDonald, 2008a), which is extended from the multi-grain latent Dirichlet allocation (MG-LDA) model (Titov and McDonald, 2008b), allows sentiment text aggregation for sentiment summary of each rating aspect extracted from MG-LDA. One drawback of MAS is that it requires that every aspect is rated at least in some documents, which 145 is practi</context>
</contexts>
<marker>Hofmann, 1999</marker>
<rawString>Thomas Hofmann. 1999. Probabilistic latent semantic indexing. In Proceedings of the ACM Special Interest Group on Information Retrieval (SIGIR), pages 50–57.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nobuhiro Kaji</author>
<author>Masaru Kitsuregawa</author>
</authors>
<title>Automatic construction of polarity-tagged corpus from html documents.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL on Main conference poster sessions,</booktitle>
<pages>452--459</pages>
<contexts>
<context position="9893" citStr="Kaji and Kitsuregawa, 2006" startWordPosition="1503" endWordPosition="1507">onsidered as sentiment-oriented topics. Nevertheless, human judgement of identifying the most important dimensions during spectral clustering is required. Among various efforts for improving sentiment detection accuracy, one direction is to incorporate prior information or subjectivity lexicon (i.e., words bearing positive or negative sentiment) into the sentiment model. Such sentiment lexicons can be acquired from domainindependent sources in many different ways, from manually built appraisal groups (Whitelaw et al., 2005), to semi-automatically (Abbasi et al., 2008) and fully automatically (Kaji and Kitsuregawa, 2006) constructed lexicons. When incorporating lexical knowledge as prior information into a sentiment-topic model, Andreevskaia and Bergler (2008) integrated the lexicon-based and corpus-based approaches for sentence-level sentiment annotation across different domains; Li et al. (2009) employed lexical prior knowledge for semi-supervised sentiment classification based on non-negative matrix tri-factorization, where the domain-independent prior knowledge was incorporated in conjunction with domain-dependent unlabelled data and a few labelled documents. However, this approach performed worse than th</context>
</contexts>
<marker>Kaji, Kitsuregawa, 2006</marker>
<rawString>Nobuhiro Kaji and Masaru Kitsuregawa. 2006. Automatic construction of polarity-tagged corpus from html documents. In Proceedings of the COLING/ACL on Main conference poster sessions, pages 452–459.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kennedy</author>
<author>D Inkpen</author>
</authors>
<title>Sentiment classification of movie reviews using contextual valence shifters.</title>
<date>2006</date>
<journal>Computational Intelligence,</journal>
<volume>22</volume>
<issue>2</issue>
<pages>125</pages>
<contexts>
<context position="2309" citStr="Kennedy and Inkpen, 2006" startWordPosition="341" endWordPosition="344">xt classification, sentiment classification is deemed to be more challenging as sentiment is often embodied in subtle linguistic mechanisms such as Richard Everson School of Engineering, Computing and Mathematics University of Exeter Exeter, EX4 4QF, UK. R.E.Everson@exeter.ac.uk the use of sarcasm or incorporated with highly domain-specific information. Although the task of identifying the overall sentiment polarity of a document has been well studied, most of the work is highly domain dependent and favoured in supervised learning (Pang et al., 2002; Pang and Lee, 2004; Whitelaw et al., 2005; Kennedy and Inkpen, 2006; McDonald et al., 2007), requiring annotated corpora for every possible domain of interest, which is impractical for real applications. Also, it is well-known that sentiment classifiers trained on one domain often fail to produce satisfactory results when shifted to another domain, since sentiment expression can be quite different in different domains (Aue and Gamon, 2005). Moreover, aside from the diversity of genres and large-scale size of Web corpora, user-generated contents evolve rapidly over time, which demands much more efficient algorithms for sentiment analysis than the current appro</context>
<context position="6757" citStr="Kennedy and Inkpen, 2006" startWordPosition="1023" endWordPosition="1026">T model is more appropriate for joint sentiment topic detection. The rest of the paper is organized as follows. Section 2 presents related work. Section 3 describes the LSM, JST and Reserver-JST models. Experimental setup and results on the MR and MDS datasets are discussed in Section 4 and 5 re1http://www.cs.cornell.edu/people/ pabo/movie-review-data 2http://www.cs.jhu.edu/˜mdredze/ datasets/sentiment/index2.html spectively. Finally, Section 6 concludes the paper and outlines the future work. 2 Related Work As opposed to the work (Pang et al., 2002; Pang and Lee, 2004; Whitelaw et al., 2005; Kennedy and Inkpen, 2006) that only focused on sentiment classification in one particular domain, recent research attempts have been made to address the problem of sentiment classification across domains. Aue and Gamon (2005) explored various strategies for customizing sentiment classifiers to new domains, where the training is based on a small number of labelled examples and large amounts of unlabelled in-domain data. However, their experiments achieved only limited success, with most of the classification accuracy below 80%. In the same vein, some more recent work focused on domain adaption for sentiment classifiers</context>
</contexts>
<marker>Kennedy, Inkpen, 2006</marker>
<rawString>A. Kennedy and D. Inkpen. 2006. Sentiment classification of movie reviews using contextual valence shifters. Computational Intelligence, 22(2):110– 125.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shoushan Li</author>
<author>Chengqing Zong</author>
</authors>
<title>Multidomain sentiment classification.</title>
<date>2008</date>
<booktitle>In Proceedings of the Association for Computational Linguistics and the Human Language Technology Conference (ACLHLT), Short Papers,</booktitle>
<pages>257--260</pages>
<contexts>
<context position="3242" citStr="Li and Zong, 2008" startWordPosition="483" endWordPosition="486">e quite different in different domains (Aue and Gamon, 2005). Moreover, aside from the diversity of genres and large-scale size of Web corpora, user-generated contents evolve rapidly over time, which demands much more efficient algorithms for sentiment analysis than the current approaches can offer. These observations have thus motivated the problem of using unsupervised approaches for domain-independent joint sentiment topic detection. Some recent research efforts have been made to adapt sentiment classifiers trained on one domain to another domain (Aue and Gamon, 2005; Blitzer et al., 2007; Li and Zong, 2008; Andreevskaia and Bergler, 2008). However, the adaption performance of these lines of work pretty much depends on the distribution similarity between the source and target domain, and considerable effort is still required to obtain labelled data for training. Intuitively, sentiment polarities are dependent on contextual information, such as topics or domains. In this regard, some recent work (Mei et al., 2007; Titov and McDonald, 2008a) has tried to model both sentiment and topics. However, these two models either require postprocessing to calculate the positive/negative coverage in a documen</context>
<context position="7484" citStr="Li and Zong (2008)" startWordPosition="1135" endWordPosition="1138">ade to address the problem of sentiment classification across domains. Aue and Gamon (2005) explored various strategies for customizing sentiment classifiers to new domains, where the training is based on a small number of labelled examples and large amounts of unlabelled in-domain data. However, their experiments achieved only limited success, with most of the classification accuracy below 80%. In the same vein, some more recent work focused on domain adaption for sentiment classifiers. Blitzer et al. (2007) used the structural correspondence learning (SCL) algorithm with mutual information. Li and Zong (2008) combined multiple single classifiers trained on individual domains using SVMs. However, the adaption performance in (Blitzer et al., 2007) depends on the selection of pivot features that used to link the source and target domains; whereas the approach of Li and Zong (2008) heavily relies on labelled data from all the domains to train the integrated classifier and thus lack the flexibility to adapt the trained classifier to domains where label information is not available. Recent years have also seen increasing interests in modelling both sentiment and topics simultaneously. The topic-sentimen</context>
</contexts>
<marker>Li, Zong, 2008</marker>
<rawString>Shoushan Li and Chengqing Zong. 2008. Multidomain sentiment classification. In Proceedings of the Association for Computational Linguistics and the Human Language Technology Conference (ACLHLT), Short Papers, pages 257–260.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tao Li</author>
<author>Yi Zhang</author>
<author>Vikas Sindhwani</author>
</authors>
<title>A nonnegative matrix tri-factorization approach to sentiment classification with lexical prior knowledge.</title>
<date>2009</date>
<booktitle>In Proceedings of (ACL-IJCNLP),</booktitle>
<pages>244--252</pages>
<contexts>
<context position="10175" citStr="Li et al. (2009)" startWordPosition="1540" endWordPosition="1543">n (i.e., words bearing positive or negative sentiment) into the sentiment model. Such sentiment lexicons can be acquired from domainindependent sources in many different ways, from manually built appraisal groups (Whitelaw et al., 2005), to semi-automatically (Abbasi et al., 2008) and fully automatically (Kaji and Kitsuregawa, 2006) constructed lexicons. When incorporating lexical knowledge as prior information into a sentiment-topic model, Andreevskaia and Bergler (2008) integrated the lexicon-based and corpus-based approaches for sentence-level sentiment annotation across different domains; Li et al. (2009) employed lexical prior knowledge for semi-supervised sentiment classification based on non-negative matrix tri-factorization, where the domain-independent prior knowledge was incorporated in conjunction with domain-dependent unlabelled data and a few labelled documents. However, this approach performed worse than the JST model on the movie review data even with 40% labelled documents as will be shown in Section 5. 3 Latent Sentiment-Topic Models This section describes three closely related Bayesian models for unsupervised sentiment classification, the latent sentiment model (LSM), the joint s</context>
<context position="23529" citStr="Li et al., 2009" startWordPosition="3809" endWordPosition="3812"> domain, LSM achieved better performance in all the other domains with more than 5% overall improvement. Nevertheless, the approach proposed by Dasgupta and Ng (2009) requires users to specify which dimensions (defined by the eigenvectors in spectral clustering) are most closely related to sentiment by inspecting a set of features derived from the reviews for each dimension, and clustering is performed again on the data to derive the final results. In all the Bayesian models studied here, no human judgement is required. Another recently proposed non-negative matrix tri-factorization approach (Li et al., 2009) also employed lexical prior knowledge for semi-supervised sentiment classification. However, when incorporating 10% of labelled documents for training, the non-negative matrix tri-factorization approach performed much worse than LSM, with only around 60% accuracy achieved for all the datasets. Even with 40% labelled documents, it still performs worse than LSM on the MR dataset and slightly outperforms LSM on the MDS dataset. It is worth noting that no labelled documents were used in the LSM results reported here. 149 Figure 2: JST and Reverse-JST sentiment classification results with multiple</context>
</contexts>
<marker>Li, Zhang, Sindhwani, 2009</marker>
<rawString>Tao Li, Yi Zhang, and Vikas Sindhwani. 2009. A nonnegative matrix tri-factorization approach to sentiment classification with lexical prior knowledge. In Proceedings of (ACL-IJCNLP), pages 244–252.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chenghua Lin</author>
<author>Yulan He</author>
</authors>
<title>Joint sentiment/topic model for sentiment analysis.</title>
<date>2009</date>
<booktitle>In Proceedings of the ACM international conference on Information and knowledge management (CIKM).</booktitle>
<contexts>
<context position="4719" citStr="Lin and He (2009)" startWordPosition="699" endWordPosition="702">la, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics quire some kind of supervised setting in which review text should contain ratings for aspects of interest (Titov and McDonald, 2008a). More recently, Dasgupta and Ng (2009) proposed an unsupervised sentiment classification algorithm by integrating user feedbacks into a spectral clustering algorithm. Features induced for each dimension of spectral clustering can be considered as sentimentoriented topics. Nevertheless, human judgement of identifying the most important dimensions during spectral clustering is required. Lin and He (2009) proposed a joint sentimenttopic (JST) model for unsupervised joint sentiment topic detection. They assumed that topics are generated dependent on sentiment distributions and then words are generated conditioned on sentiment-topic pairs. While this is a reasonable design choice, one may argue that the reverse is also true that sentiments may vary according to topics. Thus in this paper, we studied the reverse dependence of the JST model called Reverse-JST, in which sentiments are generated dependent on topic distributions in the modelling process. We also note that, when the topic number is se</context>
<context position="12747" citStr="Lin and He, 2009" startWordPosition="1981" endWordPosition="1984">k, where Nwt,k is the number of times word wt has associated with sentiment label k; Nk is the the number of times words in the corpus assigned to sentiment label k; Nk,d is the number of times sentiment label k has been assigned to some word tokens in document d; Nd is the total number of words in the document collection. Gibbs sampling is used to estimate the posterior distribution of LSM, as well as the JST and Reverse-JST models that will be discussed in the following two sections. 3.2 Joint Sentiment-Topic Model (JST) In contrast to LSM that only models document sentiment, the JST model (Lin and He, 2009) can detect sentiment and topic simultaneously, by modelling each document with S (number of sentiment labels) topic-document distributions. It should be noted that when the topic number is set to 1, JST effectively becomes the LSM model with only three topics corresponding to each of the 3For all the three models, i.e., LSM, JST and ReverseJST, we set the sentiment label number S to 3 representing the positive, negative and neutral polarities, respectively. N�t wt�� + β · N�t k + V β (2) 146 (a) (b) (c) Figure 1: (a) LSM model; (b) JST model; (c) Reverse-JST model. three sentiment labels. Let</context>
<context position="19275" citStr="Lin and He (2009)" startWordPosition="3120" endWordPosition="3123"> stemming in the preprocessing. In addition, words whose polarity changed after stemming were removed automatically, resulting in 1584 positive and 2612 negative words, respectively. It is worth noting that the lexicons used here are fully domain-independent and do not bear any supervised information specifically to the MR, subjMR and MDS datasets. Finally, the prior information was produced by retaining all words in the MPQA and appraisal lexicons that occurred in the experimental datasets. The prior information statistics for each dataset is listed in the last row of Table 1. In contrast to Lin and He (2009) that only utilized prior information during the initialization of the posterior distributions, we use the prior information in the Gibbs sampling inference step and argue that this is a more appropriate experimental setting. For the Gibbs sampling step of JST and Reverse-JST, if the currently observed word token matches a word in the sentiment lexicon, a corresponding sentiment label will be assigned and only a new topic will be sampled. Otherwise, a new sentiment-topic pair will be sampled for that word token. For LSM, if the current word token matches a word in the sentiment lexicon, a corr</context>
</contexts>
<marker>Lin, He, 2009</marker>
<rawString>Chenghua Lin and Yulan He. 2009. Joint sentiment/topic model for sentiment analysis. In Proceedings of the ACM international conference on Information and knowledge management (CIKM).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Kerry Hannan</author>
<author>Tyler Neylon</author>
<author>Mike Wells</author>
<author>Jeff Reynar</author>
</authors>
<title>Structured models for fine-to-coarse sentiment analysis.</title>
<date>2007</date>
<booktitle>In Proceedings of the Annual Meeting of the Association of Computational Linguistics (ACL),</booktitle>
<pages>432--439</pages>
<contexts>
<context position="2333" citStr="McDonald et al., 2007" startWordPosition="345" endWordPosition="348">nt classification is deemed to be more challenging as sentiment is often embodied in subtle linguistic mechanisms such as Richard Everson School of Engineering, Computing and Mathematics University of Exeter Exeter, EX4 4QF, UK. R.E.Everson@exeter.ac.uk the use of sarcasm or incorporated with highly domain-specific information. Although the task of identifying the overall sentiment polarity of a document has been well studied, most of the work is highly domain dependent and favoured in supervised learning (Pang et al., 2002; Pang and Lee, 2004; Whitelaw et al., 2005; Kennedy and Inkpen, 2006; McDonald et al., 2007), requiring annotated corpora for every possible domain of interest, which is impractical for real applications. Also, it is well-known that sentiment classifiers trained on one domain often fail to produce satisfactory results when shifted to another domain, since sentiment expression can be quite different in different domains (Aue and Gamon, 2005). Moreover, aside from the diversity of genres and large-scale size of Web corpora, user-generated contents evolve rapidly over time, which demands much more efficient algorithms for sentiment analysis than the current approaches can offer. These o</context>
</contexts>
<marker>McDonald, Hannan, Neylon, Wells, Reynar, 2007</marker>
<rawString>Ryan McDonald, Kerry Hannan, Tyler Neylon, Mike Wells, and Jeff Reynar. 2007. Structured models for fine-to-coarse sentiment analysis. In Proceedings of the Annual Meeting of the Association of Computational Linguistics (ACL), pages 432–439.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qiaozhu Mei</author>
<author>Xu Ling</author>
<author>Matthew Wondra</author>
<author>Hang Su</author>
<author>ChengXiang Zhai</author>
</authors>
<title>Topic sentiment mixture: modeling facets and opinions in weblogs.</title>
<date>2007</date>
<booktitle>In Proceedings of the conference on World Wide Web (WWW),</booktitle>
<pages>171--180</pages>
<contexts>
<context position="3655" citStr="Mei et al., 2007" startWordPosition="546" endWordPosition="549">sentiment topic detection. Some recent research efforts have been made to adapt sentiment classifiers trained on one domain to another domain (Aue and Gamon, 2005; Blitzer et al., 2007; Li and Zong, 2008; Andreevskaia and Bergler, 2008). However, the adaption performance of these lines of work pretty much depends on the distribution similarity between the source and target domain, and considerable effort is still required to obtain labelled data for training. Intuitively, sentiment polarities are dependent on contextual information, such as topics or domains. In this regard, some recent work (Mei et al., 2007; Titov and McDonald, 2008a) has tried to model both sentiment and topics. However, these two models either require postprocessing to calculate the positive/negative coverage in a document for polarity identification (Mei et al., 2007) or reYulan He Knowledge Media Institute The Open University Milton Keynes MK7 6AA, UK Y.He@open.ac.uk 144 Proceedings of the Fourteenth Conference on Computational Natural Language Learning, pages 144–152, Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics quire some kind of supervised setting in which review text should contain r</context>
<context position="8124" citStr="Mei et al., 2007" startWordPosition="1236" endWordPosition="1239">le classifiers trained on individual domains using SVMs. However, the adaption performance in (Blitzer et al., 2007) depends on the selection of pivot features that used to link the source and target domains; whereas the approach of Li and Zong (2008) heavily relies on labelled data from all the domains to train the integrated classifier and thus lack the flexibility to adapt the trained classifier to domains where label information is not available. Recent years have also seen increasing interests in modelling both sentiment and topics simultaneously. The topic-sentiment mixture (TSM) model (Mei et al., 2007) can jointly model sentiment and topics by constructing an extra background component and two additional sentiment subtopics on top of the probabilistic latent semantic indexing (pLSI) (Hofmann, 1999). However, TSM may suffer from the problem of overfitting the data which is known as a deficiency of pLSI, and postprocessing is also required in order to calculate the sentiment prediction for a document. The multi-aspect sentiment (MAS) model (Titov and McDonald, 2008a), which is extended from the multi-grain latent Dirichlet allocation (MG-LDA) model (Titov and McDonald, 2008b), allows sentimen</context>
</contexts>
<marker>Mei, Ling, Wondra, Su, Zhai, 2007</marker>
<rawString>Qiaozhu Mei, Xu Ling, Matthew Wondra, Hang Su, and ChengXiang Zhai. 2007. Topic sentiment mixture: modeling facets and opinions in weblogs. In Proceedings of the conference on World Wide Web (WWW), pages 171–180.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>A sentimental education: sentiment analysis using subjectivity summarization based on minimum cuts.</title>
<date>2004</date>
<booktitle>In Proceedings of the Annual Meeting on Association for Computational Linguistics (ACL),</booktitle>
<pages>271</pages>
<contexts>
<context position="2260" citStr="Pang and Lee, 2004" startWordPosition="333" endWordPosition="336"> Compared to the traditional topic-based text classification, sentiment classification is deemed to be more challenging as sentiment is often embodied in subtle linguistic mechanisms such as Richard Everson School of Engineering, Computing and Mathematics University of Exeter Exeter, EX4 4QF, UK. R.E.Everson@exeter.ac.uk the use of sarcasm or incorporated with highly domain-specific information. Although the task of identifying the overall sentiment polarity of a document has been well studied, most of the work is highly domain dependent and favoured in supervised learning (Pang et al., 2002; Pang and Lee, 2004; Whitelaw et al., 2005; Kennedy and Inkpen, 2006; McDonald et al., 2007), requiring annotated corpora for every possible domain of interest, which is impractical for real applications. Also, it is well-known that sentiment classifiers trained on one domain often fail to produce satisfactory results when shifted to another domain, since sentiment expression can be quite different in different domains (Aue and Gamon, 2005). Moreover, aside from the diversity of genres and large-scale size of Web corpora, user-generated contents evolve rapidly over time, which demands much more efficient algorit</context>
<context position="6707" citStr="Pang and Lee, 2004" startWordPosition="1015" endWordPosition="1018">erforms worse than JST suggests that the JST model is more appropriate for joint sentiment topic detection. The rest of the paper is organized as follows. Section 2 presents related work. Section 3 describes the LSM, JST and Reserver-JST models. Experimental setup and results on the MR and MDS datasets are discussed in Section 4 and 5 re1http://www.cs.cornell.edu/people/ pabo/movie-review-data 2http://www.cs.jhu.edu/˜mdredze/ datasets/sentiment/index2.html spectively. Finally, Section 6 concludes the paper and outlines the future work. 2 Related Work As opposed to the work (Pang et al., 2002; Pang and Lee, 2004; Whitelaw et al., 2005; Kennedy and Inkpen, 2006) that only focused on sentiment classification in one particular domain, recent research attempts have been made to address the problem of sentiment classification across domains. Aue and Gamon (2005) explored various strategies for customizing sentiment classifiers to new domains, where the training is based on a small number of labelled examples and large amounts of unlabelled in-domain data. However, their experiments achieved only limited success, with most of the classification accuracy below 80%. In the same vein, some more recent work fo</context>
<context position="17382" citStr="Pang and Lee (2004)" startWordPosition="2823" endWordPosition="2826"> 4.1 Dataset Description Two publicly available datasets, the MR and MDS datasets, were used in our experiments. The MR dataset (also known as the polarity dataset) has become a benchmark for many studies since the work of Pang et al. (2002). The version 2.0 used in our experiment consists of 1000 positive and 1000 negative movie reviews drawn from the IMDB movie archive, with an average of 30 sentences in each document. We also experimented with another dataset, namely subjective MR, by removing the sentences that do not bear opinion information from the MR dataset, following the approach of Pang and Lee (2004). The resulting dataset still contains 2000 documents with a total of 334,336 words and 18,013 distinct terms, about half the size of the original MR dataset without performing subjectivity detection. First used by Blitzer et al. (2007), the MDS dataset contains 4 different types of product reviews taken from Amazon.com including books, DVDs, electronics and kitchen appliances, with 1000 positive and 1000 negative examples for each domain4. 4We did not perform subjectivity detection on the MDS dataset since its average document length is much shorter Preprocessing was performed on both of the </context>
</contexts>
<marker>Pang, Lee, 2004</marker>
<rawString>Bo Pang and Lillian Lee. 2004. A sentimental education: sentiment analysis using subjectivity summarization based on minimum cuts. In Proceedings of the Annual Meeting on Association for Computational Linguistics (ACL), page 271.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>Opinion mining and sentiment analysis.</title>
<date>2008</date>
<journal>Found. Trends Inf. Retr.,</journal>
<pages>2--1</pages>
<contexts>
<context position="1470" citStr="Pang and Lee, 2008" startWordPosition="218" endWordPosition="221">addition, Reverse-JST always performs worse than JST suggesting that the JST model is more appropriate for joint sentiment topic detection. 1 Introduction With the explosion of web 2.0, various types of social media such as blogs, discussion forums and peer-to-peer networks present a wealth of information that can be very helpful in assessing the general public’s sentiments and opinions towards products and services. Recent surveys have revealed that opinion-rich resources like online reviews are having greater economic impact on both consumers and companies compared to the traditional media (Pang and Lee, 2008). Driven by the demand of gleaning insights of such great amounts of user-generated data, work on new methodologies for automated sentiment analysis has bloomed splendidly. Compared to the traditional topic-based text classification, sentiment classification is deemed to be more challenging as sentiment is often embodied in subtle linguistic mechanisms such as Richard Everson School of Engineering, Computing and Mathematics University of Exeter Exeter, EX4 4QF, UK. R.E.Everson@exeter.ac.uk the use of sarcasm or incorporated with highly domain-specific information. Although the task of identify</context>
</contexts>
<marker>Pang, Lee, 2008</marker>
<rawString>Bo Pang and Lillian Lee. 2008. Opinion mining and sentiment analysis. Found. Trends Inf. Retr., 2(1-2):1–135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
<author>Shivakumar Vaithyanathan</author>
</authors>
<title>Thumbs up?: sentiment classification using machine learning techniques.</title>
<date>2002</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>79--86</pages>
<contexts>
<context position="2240" citStr="Pang et al., 2002" startWordPosition="329" endWordPosition="332">bloomed splendidly. Compared to the traditional topic-based text classification, sentiment classification is deemed to be more challenging as sentiment is often embodied in subtle linguistic mechanisms such as Richard Everson School of Engineering, Computing and Mathematics University of Exeter Exeter, EX4 4QF, UK. R.E.Everson@exeter.ac.uk the use of sarcasm or incorporated with highly domain-specific information. Although the task of identifying the overall sentiment polarity of a document has been well studied, most of the work is highly domain dependent and favoured in supervised learning (Pang et al., 2002; Pang and Lee, 2004; Whitelaw et al., 2005; Kennedy and Inkpen, 2006; McDonald et al., 2007), requiring annotated corpora for every possible domain of interest, which is impractical for real applications. Also, it is well-known that sentiment classifiers trained on one domain often fail to produce satisfactory results when shifted to another domain, since sentiment expression can be quite different in different domains (Aue and Gamon, 2005). Moreover, aside from the diversity of genres and large-scale size of Web corpora, user-generated contents evolve rapidly over time, which demands much mo</context>
<context position="5661" citStr="Pang et al., 2002" startWordPosition="860" endWordPosition="863">that sentiments may vary according to topics. Thus in this paper, we studied the reverse dependence of the JST model called Reverse-JST, in which sentiments are generated dependent on topic distributions in the modelling process. We also note that, when the topic number is set to 1, both JST and reversed-JST essentially become a simple latent Dirichlet allocation (LDA) model with only 5 (number of sentiment label) topics, each of which corresponds to a sentiment label. We called it latent sentiment model (LSM) in this paper. Extensive experiments have been conducted on the movie review (MR)1 (Pang et al., 2002) and multi-domain sentiment (MDS)2 (Blitzer et al., 2007) datasets to compare the performance of LSM, JST and Reverse-JST. Results show that all these three models are able to give either better or comparable performance compared to the existing unsupervised sentiment classification approaches. In addition, both JST and reverse-JST are able to extract sentiment-oriented topics. Furthermore, the fact that reverse-JST always performs worse than JST suggests that the JST model is more appropriate for joint sentiment topic detection. The rest of the paper is organized as follows. Section 2 present</context>
<context position="17004" citStr="Pang et al. (2002)" startWordPosition="2760" endWordPosition="2763">). For all the three models, the probability P(l|d) will be used to determine document sentiment polarity. We define that a document d is classified as a positive-sentiment document if its probability of positive sentiment label given document P(lpos|d), is greater than its probability of negative sentiment label given document P(lneg|d), and vice versa. 4 Experimental Setup 4.1 Dataset Description Two publicly available datasets, the MR and MDS datasets, were used in our experiments. The MR dataset (also known as the polarity dataset) has become a benchmark for many studies since the work of Pang et al. (2002). The version 2.0 used in our experiment consists of 1000 positive and 1000 negative movie reviews drawn from the IMDB movie archive, with an average of 30 sentences in each document. We also experimented with another dataset, namely subjective MR, by removing the sentences that do not bear opinion information from the MR dataset, following the approach of Pang and Lee (2004). The resulting dataset still contains 2000 documents with a total of 334,336 words and 18,013 distinct terms, about half the size of the original MR dataset without performing subjectivity detection. First used by Blitzer</context>
</contexts>
<marker>Pang, Lee, Vaithyanathan, 2002</marker>
<rawString>Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan. 2002. Thumbs up?: sentiment classification using machine learning techniques. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 79–86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Titov</author>
<author>Ryan McDonald</author>
</authors>
<title>A joint model of text and aspect ratings for sentiment summarization.</title>
<date>2008</date>
<booktitle>In Proceedings of the Aunal Meeting on Association for Computational Linguistics and the Human Language Technology Conference (ACL-HLT),</booktitle>
<pages>308--316</pages>
<contexts>
<context position="3681" citStr="Titov and McDonald, 2008" startWordPosition="550" endWordPosition="553">tection. Some recent research efforts have been made to adapt sentiment classifiers trained on one domain to another domain (Aue and Gamon, 2005; Blitzer et al., 2007; Li and Zong, 2008; Andreevskaia and Bergler, 2008). However, the adaption performance of these lines of work pretty much depends on the distribution similarity between the source and target domain, and considerable effort is still required to obtain labelled data for training. Intuitively, sentiment polarities are dependent on contextual information, such as topics or domains. In this regard, some recent work (Mei et al., 2007; Titov and McDonald, 2008a) has tried to model both sentiment and topics. However, these two models either require postprocessing to calculate the positive/negative coverage in a document for polarity identification (Mei et al., 2007) or reYulan He Knowledge Media Institute The Open University Milton Keynes MK7 6AA, UK Y.He@open.ac.uk 144 Proceedings of the Fourteenth Conference on Computational Natural Language Learning, pages 144–152, Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics quire some kind of supervised setting in which review text should contain ratings for aspects of inte</context>
<context position="8594" citStr="Titov and McDonald, 2008" startWordPosition="1309" endWordPosition="1312">ears have also seen increasing interests in modelling both sentiment and topics simultaneously. The topic-sentiment mixture (TSM) model (Mei et al., 2007) can jointly model sentiment and topics by constructing an extra background component and two additional sentiment subtopics on top of the probabilistic latent semantic indexing (pLSI) (Hofmann, 1999). However, TSM may suffer from the problem of overfitting the data which is known as a deficiency of pLSI, and postprocessing is also required in order to calculate the sentiment prediction for a document. The multi-aspect sentiment (MAS) model (Titov and McDonald, 2008a), which is extended from the multi-grain latent Dirichlet allocation (MG-LDA) model (Titov and McDonald, 2008b), allows sentiment text aggregation for sentiment summary of each rating aspect extracted from MG-LDA. One drawback of MAS is that it requires that every aspect is rated at least in some documents, which 145 is practically infeasible. More recently, Dasgupta and Ng (2009) proposed an unsupervised sentiment classification algorithm where user feedbacks are provided on the spectral clustering process in an interactive manner to ensure that text are clustered along the sentiment dimens</context>
</contexts>
<marker>Titov, McDonald, 2008</marker>
<rawString>Ivan Titov and Ryan McDonald. 2008a. A joint model of text and aspect ratings for sentiment summarization. In Proceedings of the Aunal Meeting on Association for Computational Linguistics and the Human Language Technology Conference (ACL-HLT), pages 308–316.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Titov</author>
<author>Ryan McDonald</author>
</authors>
<title>Modeling online reviews with multi-grain topic models.</title>
<date>2008</date>
<booktitle>In Proceeding of the International Conference on World Wide Web (WWW 08’),</booktitle>
<pages>111--120</pages>
<contexts>
<context position="3681" citStr="Titov and McDonald, 2008" startWordPosition="550" endWordPosition="553">tection. Some recent research efforts have been made to adapt sentiment classifiers trained on one domain to another domain (Aue and Gamon, 2005; Blitzer et al., 2007; Li and Zong, 2008; Andreevskaia and Bergler, 2008). However, the adaption performance of these lines of work pretty much depends on the distribution similarity between the source and target domain, and considerable effort is still required to obtain labelled data for training. Intuitively, sentiment polarities are dependent on contextual information, such as topics or domains. In this regard, some recent work (Mei et al., 2007; Titov and McDonald, 2008a) has tried to model both sentiment and topics. However, these two models either require postprocessing to calculate the positive/negative coverage in a document for polarity identification (Mei et al., 2007) or reYulan He Knowledge Media Institute The Open University Milton Keynes MK7 6AA, UK Y.He@open.ac.uk 144 Proceedings of the Fourteenth Conference on Computational Natural Language Learning, pages 144–152, Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics quire some kind of supervised setting in which review text should contain ratings for aspects of inte</context>
<context position="8594" citStr="Titov and McDonald, 2008" startWordPosition="1309" endWordPosition="1312">ears have also seen increasing interests in modelling both sentiment and topics simultaneously. The topic-sentiment mixture (TSM) model (Mei et al., 2007) can jointly model sentiment and topics by constructing an extra background component and two additional sentiment subtopics on top of the probabilistic latent semantic indexing (pLSI) (Hofmann, 1999). However, TSM may suffer from the problem of overfitting the data which is known as a deficiency of pLSI, and postprocessing is also required in order to calculate the sentiment prediction for a document. The multi-aspect sentiment (MAS) model (Titov and McDonald, 2008a), which is extended from the multi-grain latent Dirichlet allocation (MG-LDA) model (Titov and McDonald, 2008b), allows sentiment text aggregation for sentiment summary of each rating aspect extracted from MG-LDA. One drawback of MAS is that it requires that every aspect is rated at least in some documents, which 145 is practically infeasible. More recently, Dasgupta and Ng (2009) proposed an unsupervised sentiment classification algorithm where user feedbacks are provided on the spectral clustering process in an interactive manner to ensure that text are clustered along the sentiment dimens</context>
</contexts>
<marker>Titov, McDonald, 2008</marker>
<rawString>Ivan Titov and Ryan McDonald. 2008b. Modeling online reviews with multi-grain topic models. In Proceeding of the International Conference on World Wide Web (WWW 08’), pages 111–120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Casey Whitelaw</author>
<author>Navendu Garg</author>
<author>Shlomo Argamon</author>
</authors>
<title>Using appraisal groups for sentiment analysis.</title>
<date>2005</date>
<booktitle>In Proceedings of the ACM international conference on Information and Knowledge Management (CIKM),</booktitle>
<pages>625--631</pages>
<contexts>
<context position="2283" citStr="Whitelaw et al., 2005" startWordPosition="337" endWordPosition="340">ditional topic-based text classification, sentiment classification is deemed to be more challenging as sentiment is often embodied in subtle linguistic mechanisms such as Richard Everson School of Engineering, Computing and Mathematics University of Exeter Exeter, EX4 4QF, UK. R.E.Everson@exeter.ac.uk the use of sarcasm or incorporated with highly domain-specific information. Although the task of identifying the overall sentiment polarity of a document has been well studied, most of the work is highly domain dependent and favoured in supervised learning (Pang et al., 2002; Pang and Lee, 2004; Whitelaw et al., 2005; Kennedy and Inkpen, 2006; McDonald et al., 2007), requiring annotated corpora for every possible domain of interest, which is impractical for real applications. Also, it is well-known that sentiment classifiers trained on one domain often fail to produce satisfactory results when shifted to another domain, since sentiment expression can be quite different in different domains (Aue and Gamon, 2005). Moreover, aside from the diversity of genres and large-scale size of Web corpora, user-generated contents evolve rapidly over time, which demands much more efficient algorithms for sentiment analy</context>
<context position="6730" citStr="Whitelaw et al., 2005" startWordPosition="1019" endWordPosition="1022">ST suggests that the JST model is more appropriate for joint sentiment topic detection. The rest of the paper is organized as follows. Section 2 presents related work. Section 3 describes the LSM, JST and Reserver-JST models. Experimental setup and results on the MR and MDS datasets are discussed in Section 4 and 5 re1http://www.cs.cornell.edu/people/ pabo/movie-review-data 2http://www.cs.jhu.edu/˜mdredze/ datasets/sentiment/index2.html spectively. Finally, Section 6 concludes the paper and outlines the future work. 2 Related Work As opposed to the work (Pang et al., 2002; Pang and Lee, 2004; Whitelaw et al., 2005; Kennedy and Inkpen, 2006) that only focused on sentiment classification in one particular domain, recent research attempts have been made to address the problem of sentiment classification across domains. Aue and Gamon (2005) explored various strategies for customizing sentiment classifiers to new domains, where the training is based on a small number of labelled examples and large amounts of unlabelled in-domain data. However, their experiments achieved only limited success, with most of the classification accuracy below 80%. In the same vein, some more recent work focused on domain adaptio</context>
<context position="9795" citStr="Whitelaw et al., 2005" startWordPosition="1490" endWordPosition="1493"> the sentiment dimension. Features induced for each dimension of spectral clustering can be considered as sentiment-oriented topics. Nevertheless, human judgement of identifying the most important dimensions during spectral clustering is required. Among various efforts for improving sentiment detection accuracy, one direction is to incorporate prior information or subjectivity lexicon (i.e., words bearing positive or negative sentiment) into the sentiment model. Such sentiment lexicons can be acquired from domainindependent sources in many different ways, from manually built appraisal groups (Whitelaw et al., 2005), to semi-automatically (Abbasi et al., 2008) and fully automatically (Kaji and Kitsuregawa, 2006) constructed lexicons. When incorporating lexical knowledge as prior information into a sentiment-topic model, Andreevskaia and Bergler (2008) integrated the lexicon-based and corpus-based approaches for sentence-level sentiment annotation across different domains; Li et al. (2009) employed lexical prior knowledge for semi-supervised sentiment classification based on non-negative matrix tri-factorization, where the domain-independent prior knowledge was incorporated in conjunction with domain-depe</context>
</contexts>
<marker>Whitelaw, Garg, Argamon, 2005</marker>
<rawString>Casey Whitelaw, Navendu Garg, and Shlomo Argamon. 2005. Using appraisal groups for sentiment analysis. In Proceedings of the ACM international conference on Information and Knowledge Management (CIKM), pages 625–631.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>