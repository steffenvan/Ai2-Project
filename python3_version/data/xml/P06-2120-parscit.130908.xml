<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000056">
<title confidence="0.9981275">
Stochastic Discourse Modeling in Spoken Dialogue Systems
Using Semantic Dependency Graphs
</title>
<author confidence="0.998906">
Jui-Feng Yeh, Chung-Hsien Wu and Mao-Zhu Yang
</author>
<affiliation confidence="0.9910155">
Department of Computer Science and Information Engineering
National Cheng Kung University
</affiliation>
<address confidence="0.965431">
No. 1, Ta-Hsueh Road, Tainan, Taiwan, R.O.C.
</address>
<email confidence="0.982773">
{jfyeh, chwu, mzyang}@csie.ncku.edu.tw
</email>
<sectionHeader confidence="0.998581" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99993896">
This investigation proposes an approach
to modeling the discourse of spoken dia-
logue using semantic dependency graphs.
By characterizing the discourse as a se-
quence of speech acts, discourse modeling
becomes the identification of the speech
act sequence. A statistical approach is
adopted to model the relations between
words in the user’s utterance using the
semantic dependency graphs. Dependency
relation between the headword and other
words in a sentence is detected using the
semantic dependency grammar. In order
to evaluate the proposed method, a dia-
logue system for medical service is devel-
oped. Experimental results show that the
rates for speech act detection and task-
completion are 95.6% and 85.24%, re-
spectively, and the average number of
turns of each dialogue is 8.3. Compared
with the Bayes’ classifier and the Partial-
Pattern Tree based approaches, we obtain
14.9% and 12.47% improvements in ac-
curacy for speech act identification, re-
spectively.
</bodyText>
<sectionHeader confidence="0.99963" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9999882">
It is a very tremendous vision of the computer
technology to communicate with the machine us-
ing spoken language (Huang et al., 2001; Allen at
al., 2001). Understanding of spontaneous language
is arguably the core technology of the spoken dia-
logue systems, since the more accurate information
obtained by the machine (Higashinaka et al., 2004),
the more possibility to finish the dialogue task.
Practical use of speech act theories in spoken lan-
guage processing (Stolcke et al. 2000; Walker and
Passonneau 2001; Wu et al., 2004) have given both
insight and deeper understanding of verbal com-
munication. Therefore, when considering the
whole discourse, the relationship between the
speech acts of the dialogue turns becomes ex-
tremely important. In the last decade, several prac-
ticable dialogue systems (McTEAR, 2002), such as
air travel information service system, weather
forecast system, automatic banking system, auto-
matic train timetable information system, and the
Circuit-Fix-it shop system, have been developed to
extract the user’s semantic entities using the se-
mantic frames/slots and conceptual graphs. The
dialogue management in these systems is able to
handle the dialogue flow efficaciously. However, it
is not applicable to the more complex applications
such as “Type 5: the natural language conversa-
tional applications” defined by IBM (Rajesh and
Linda, 2004). In Type 5 dialog systems, it is possi-
ble for the users to switch directly from one ongo-
ing task to another. In the traditional approaches,
the absence of precise speech act identification
without discourse analysis will result in the failure
in task switching. The capability for identifying the
speech act and extracting the semantic objects by
reasoning plays a more important role for the dia-
log systems. This research proposes a semantic
dependency-based discourse model to capture and
share the semantic objects among tasks that switch
during a dialog for semantic resolution. Besides
</bodyText>
<page confidence="0.913975">
937
</page>
<note confidence="0.731317">
Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 937–944,
Sydney, July 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.999981285714286">
acoustic speech recognition, natural language un-
derstanding is one of the most important research
issues, since understanding and application restric-
tion on the small scope is related to the data struc-
tures that are used to capture and store the
meaningful items. Wang et al. (Wang et al., 2003)
applied the object-oriented concept to provide a
new semantic representation including semantic
class and the learning algorithm for the combina-
tion of context free grammar and N-gram.
Among these approaches, there are two essential
issues about dialogue management in natural lan-
guage processing. The first one is how to obtain
the semantic object from the user’s utterances. The
second is a more effective speech act identification
approach for semantic understanding is needed.
Since speech act plays an important role in the de-
velopment of dialogue management for dealing
with complex applications, speech act identifica-
tion with semantic interpretation will be the most
important topic with respect to the methods used to
control the dialogue with the users. This paper
proposes an approach integrating semantic de-
pendency graph and history/discourse information
to model the dialogue discourse (Kudo and Ma-
tsumoto, 2000; Hacioglu et al., 2003; Gao and Su-
zuki, 2003). Three major components, such as
semantic relation, semantic class and semantic role
are adopted in the semantic dependency graph
(Gildea and Jurasfky, 2002; Hacioglu and Ward,
2003). The semantic relations constrain the word
sense and provide the method for disambiguation.
Semantic roles are assigned when the relation es-
tablished among semantic objects. Both semantic
relations and roles are defined in many knowledge
resources or ontologies, such as FrameNet (Baker
et al., 2004) and HowNet with 65,000 concepts in
Chinese and close to 75,000 English equivalents, is
a bilingual knowledge-base describing relations
between concepts and relations between the attrib-
utes of concepts with ontological view (Dong and
Dong 2006). Generally speaking, semantic class is
defined as a set with the elements that are usually
the words with the same semantic interpretation.
Hypernyms that are superordinate concepts of the
words are usually used as the semantic classes just
like the Hypernyms of synsets in WordNet
(http://www.cogsci.princeton.edu/~wn/) or defini-
tions of words’ primary features in HowNet. Be-
sides, the approach for understanding tries to find
the implicit semantic dependency between the con-
cepts and the dependency structure between con-
cepts in the utterance are also taken into
consideration. Instead of semantic frame/slot, se-
mantic dependency graph can keep more informa-
tion for dialogue understanding.
</bodyText>
<sectionHeader confidence="0.926134" genericHeader="method">
2 Semantic Dependency Graph
</sectionHeader>
<bodyText confidence="0.9986625">
Since speech act theory is developed to extract the
functional meaning of an utterance in the dialogue
(Searle, 1979), discourse or history can be defined
as a sequence of speech acts,
</bodyText>
<equation confidence="0.952136">
H SA SA SA SA
t 1 2 t −1
= { , ,.... , }
t , and accordingly the
</equation>
<bodyText confidence="0.9997715">
speech act theory can be adopted for discourse
modeling. Based on this definition, the discourse
analysis in semantics using the dependency graphs
tries to identify the speech act sequence of the dis-
course. Therefore, discourse modeling by means of
speech act identification considering the history is
shown in Equation (1). By introducing the hidden
variable Di, representing the i-th possible depend-
ency graph derived from the word sequence W.
The dependency relation, rk , between word wk and
headword wkh is extracted using HowNet and de-
noted as DR(wk, wkh) ≡ rk . The dependency graph
which is composed of a set of dependency relations
in the word sequence W is defined as
</bodyText>
<equation confidence="0.9859212">
i i
i 1( 1 , ( 1) )} .
D W = DR w
( ) { 1 ( 1, 1 ), 2 ( 2 , 2 ),...,
i w h DR w w h DRm− wm− w m− h
</equation>
<bodyText confidence="0.989662">
The probability of hypothesis SAt given word se-
quence W and history Ht-1 can be described in
Equation (1). According to the Bayes’ rule, the
speech act identification model can be decomposed
into two components, P(SAt |Di,W,Ht−1) and
</bodyText>
<equation confidence="0.998915">
P(Di  |W, Ht−1) , described in the following.
( SAt |W,Ht−1)
( SAt,Di |W,Ht−1) (1)
( SAt  |Di,W,Ht−1)× P(Di  |W,Ht−1)
</equation>
<bodyText confidence="0.999740833333333">
where SA* and SAt are the most probable speech
act and the potential speech act at the t-th dialogue
turn, respectively. W={w1,w2,w3,...,wm} denotes the
word sequence extracted from the user’s utteance
without considering the stop words. Ht-1 is the his-
tory representing the previous t-1 turns.
</bodyText>
<equation confidence="0.998480384615385">
SA* =
argmaxP
SA t
=arg ax
m ∑P
SA D
t
i
=arg ax
m ∑ P
SA D
t
i
</equation>
<page confidence="0.990208">
938
</page>
<subsectionHeader confidence="0.993577">
2.1 Speech act identification using semantic
dependency with discourse analysis
</subsectionHeader>
<bodyText confidence="0.999919333333333">
In this analysis, we apply the semantic dependency,
word sequence, and discourse analysis to the iden-
tification of speech act. Since Di is the i-th possible
dependency graph derived from word sequence W,
speech act identification with semantic dependency
can be simplified as Equation (2).
</bodyText>
<equation confidence="0.993011666666667">
t 1 t t−1
P SA D W H t −
(  |, , ) (
P SA Di H
≅  |, ) (2)
i
According to Bayes’ rule, the probability
P SA D i H − can be rewritten as:
t t 1
(  |, )
P(Di Ht −1  |SAt )P(SAt)
) P SA D H
(  |, = i
∑P(Di,Ht−1  |SAl)P(SAl)
SAl
</equation>
<bodyText confidence="0.882148875">
As the history is defined as the speech act se-
quence, the joint probability of Di and Ht-1 given
the speech act SAt can be expressed as Equation (4).
For the problem of data sparseness in the training
corpus, the probability,
P (Di , SA1, SA2 , ..., SAt− 1  |SAt) , is hard to obtain and
the speech act bi-gram model is adopted for ap-
proximation.
</bodyText>
<equation confidence="0.999764666666667">
P(Di,Ht−1  |SAt)
=P(Di,SA1,SA2,...,SAt−1  |SAt) (4)
P(Di,SAt −1  |SAt)
</equation>
<bodyText confidence="0.999689">
For the combination of the semantic and syntactic
structures, the relations defined in HowNet are
employed as the dependency relations, and the hy-
pernym is adopted as the semantic concept accord-
ing to the primary features of the words defined in
HowNet. The headwords are decided by the algo-
rithm based on the part of speech (POS) proposed
by Academia Sinica in Taiwan. The probabilities
of the headwords are estimated according to the
probabilistic context free grammar (PCFG) trained
on the Treebank developed by Sinica (Chen et al.,
2001). That is to say, the headwords are extracted
according to the syntactic structure and the de-
pendency graphs are constructed by the semantic
relations defined in HowNet. According to previ-
ous definition with independent assumption and
the bigram smoothing of the speech act model us-
ing the back-off procedure, we can rewrite Equa-
tion (4) into Equation (5).
</bodyText>
<equation confidence="0.999341733333333">
P(Di,SAt−1  |SAt)
m
1
= ( ( , ),  |)
i t t
α ∏ P DR w w SA SA
− +
k k kh
k
m
(1 ) ( ( , )  |)
i t
− α k k kh
∏ P DR w w SA
k
</equation>
<bodyText confidence="0.999704666666667">
where α is the mixture factor for normalization.
According to the conceptual representation of the
word, the transformation function, f (⋅) , trans-
forms the word into its hypernym defined as the
semantic class using HowNet. The dependency
relation between the semantic classes of two words
will be mapped to the conceptual space. Also the
semantic roles among the dependency relations are
obtained. On condition that t
</bodyText>
<equation confidence="0.9491391">
SA , t 1
SA − and the re-
lations are independent, the equation becomes
P(DRki (wk , wkh ), SA t −1 (6)
 |SAt )
P DR f w f w SA SA
( ( ( ), ( )),  |)
i t − 1 t
≅ k k kh
( ( ( ), ( ))  |) (  |)
i t t − 1 t
= P DR f w f w SA P SA SA
k k kh
The conditional probability,
P DRk f w k f wkh SA and
( ( ( ), ( ))  |)
i −
t P SA SA
(  |)
t 1 t , are
</equation>
<bodyText confidence="0.990845">
estimated according to Equations (7) and (8), re-
spectively.
</bodyText>
<equation confidence="0.992619307692308">
P DR f w f w SA
( ( ( ), ( ))  |)
i t
k k kh
(7)
= C(f(wk),f(wkh),rk,SAt)
C(SAt )
P SA SA
(  |)
t − 1 t = C SA SA
( , )
C(SAt )
t − 1 t
</equation>
<bodyText confidence="0.99139625">
where C(⋅ ) represents the number of events in the
training corpus. According to the definitions in
Equations (7) and (8), Equation (6) becomes prac-
ticable.
</bodyText>
<figure confidence="0.983707181818182">
(3)
1
−
(5)
1
=
1
−
1
=
(8)
</figure>
<page confidence="0.852168">
939
</page>
<bodyText confidence="0.765427">
=
</bodyText>
<subsectionHeader confidence="0.971383">
2.2 Semantic dependency analysis using
word sequence and discourse
</subsectionHeader>
<bodyText confidence="0.996100625">
Although the discourse can be expressed as the
speech act sequence Ht = {SA1, SA2 ,....SAt −1 , SAt} ,
the dependency graph Di is determined mainly by
W, but not t 1
H − . The probability that defines se-
mantic dependency analysis using the words se-
quence and discourse can be rewritten in the
following:
</bodyText>
<equation confidence="0.995353357142857">
P(Di |W,Ht−1)
P(Di  |W, SAt− 1, SAt−2 , ..., SA1)
≅ P(Di  |W)
and
P (D , W)
P(Di  |W) = i
P ( W)
m
P D W
( , ) =∏ P DR w w
( ( , ))
i
i k k kh
k
</equation>
<bodyText confidence="0.968482333333333">
The probability of the dependency relation be-
tween words is defined as that between the con-
cepts defined as the hypernyms of the words, and
then the dependency rules are introduced. The
probability P(rk  |f (wk ), f (wkh )) is estimated from
Equation (13).
</bodyText>
<equation confidence="0.948389">
P DR w w
( ( , ))
i
k k kh
P DR f w f w
( ( ( ), ( )))
i
≡ k k kh
= P(rk  |f (wk ), f (wkh ))
C(rk,f(wk),f(wkh))
C(f (wk ), f (wkh ))
According to Equations (11), (12) and (13), Equa-
tion (10) is rewritten as the following equation.
`
1
−
(12)
1
=
(13)
</equation>
<bodyText confidence="0.9330054">
Seeing that several dependency graphs can be gen-
erated from the word sequence W, by introducing
the hidden factor Di, the probability P(W) can be
the sum of the probabilities P(Di , W) as Equation
(11).
</bodyText>
<equation confidence="0.999578648648649">
P (W ) = ∑ P(Di, W) (11)
Di: yield (Di)=W
P DR w w
( ( , ))
i
k k kh
∏
1
k
−
m
=1
=
P
(Di W)
∑ ∏
P DR w w
( ( , ))
i
k k kh
1
: ( )
yield D W k
= = 1
i
C(rk , f (wk ), f (wkh ))
C(f (wk ), f (wkh ))
Di
=
−
m
1
−
m
∏
k = 1
(14)
</equation>
<bodyText confidence="0.982096090909091">
Because Di is generated from W, Di is the suffi-
cient to represent W in semantics. We can estimate
the joint probability P(Di,W) only from the de-
pendency relations Di. Further, the dependency
relations are assumed to be independent with each
other and therefore simplified as
C(rk, f (wk ), f (wkh ))
C(f (wk ), f (wkh ))
where function, f (⋅) , denotes the transformation
from the words to the corresponding semantic
classes.
</bodyText>
<equation confidence="0.846008333333333">
1
m
∑ ∏
D yield D W k
: ( ) = =1
i i
</equation>
<figureCaption confidence="0.990967">
Figure 1. Speech acts corresponding to multiple services in the medical domain
</figureCaption>
<page confidence="0.995789">
940
</page>
<sectionHeader confidence="0.999571" genericHeader="method">
3 Experiments
</sectionHeader>
<bodyText confidence="0.999727333333333">
In order to evaluate the proposed method, a spoken
dialogue system for medical domain with multiple
services was investigated. Three main services:
registration information service, clinic information
service, and FAQ information service are used.
This system mainly provides the function of on-
line registration. For this goal, the health education
documents are provided as the FAQ files. And the
inference engine about the clinic information ac-
cording to the patients’ syndromes is constructed
according to a medical encyclopedia. An example
is illustrated as figure 2:
</bodyText>
<figure confidence="0.992584">
System:午安。需要服務嗎?
Good Afternoon. May I help you?
User:是的,我要看醫生。
Yes, I should be diagnosed by doctor.
System:請問您要掛哪一科?
Which department would you like to make an appoint-
ment for?
User:我不知道。
I do not know.
System:請問你有那些症狀?
What symptoms are with you?
User:我喉嚨痛又發燒。而且全身酸痛。
I am with a sore throat and a fever. I ached all over, too.
System:好的,這些症狀多久了?
Well, how long have you had these symptoms?
User:好幾天了。
For several days.
System:建議您掛內科醫師。
My suggestion is that you may visit the Internal Medi-
cine.
User:請問內科何時有門診?
What’s the visiting schedule of the Internal Medicine?
System:您可以參考醫院門診表,決定您的時間,我們的時
間有...。
</figure>
<figureCaption confidence="0.747636666666667">
You can check the Services Schedule and decide a con-
venient time for you. The Available time for now is....
Figure 2 An example of dialog
</figureCaption>
<bodyText confidence="0.998023166666667">
12 Speech acts are defined and shown in Figure 1.
Every service corresponds to the 12 speech acts
with different probabilities.
The acoustic speech recognition engine embed-
ded in dialog system based on Hidden Markov
Models (HMMs) was constructed. The feature vec-
tor is parameterized on 26 MFCC coefficients. The
decoding strategy is based on a classical Viterbi
algorithm. The evaluation results by the character
error rate (CER) for a Chinese speech recognition
system is 18.3 percent and the vocabulary size of
the language is 25,132.
</bodyText>
<subsectionHeader confidence="0.999961">
3.1 Analysis of corpus
</subsectionHeader>
<bodyText confidence="0.999893428571428">
The training corpus was collected using the on-line
recording from National Cheng Kung University
Hospital in the first phase and the Wizard-of-Oz
method in the second phase. Totally, there are
1,862 dialogues with 13,986 sentences in the cor-
pus. The frequencies of the speech acts used in the
system are shown in Figure 3.
</bodyText>
<figure confidence="0.998100307692308">
Cancel registration
Confirmation (clinic)
Confirmatin (others)
Dr. and Clinic
FAQ
Registration
Clinic information
Greeting
Time
Dr.&apos;s inforamtion
Registration revision
Others
0 2 4 6 8 10 12 14
</figure>
<figureCaption confidence="0.983013">
Figure 3 Frequencies for each speech act
</figureCaption>
<bodyText confidence="0.9999221">
The number of dialogue turns is also important to
the success of the dialogue task. According to the
observation of the corpus, we can find that the dia-
logues with more than 15 turns usually failed to
complete the dialogue, that is to say, the common
ground cannot be achieved. These failed dialogues
were filtered out from the training corpus before
conducting the following experiments. The distri-
bution of the number of turns per dialogue is
shown in Figure 4.
</bodyText>
<figure confidence="0.391552">
Length (Turns)
</figure>
<figureCaption confidence="0.6780575">
Figure 4. The distribution of the number of turns
per dialogue
</figureCaption>
<subsectionHeader confidence="0.93507">
3.2 Precision of speech act identification re-
lated to the corpus size
</subsectionHeader>
<figure confidence="0.988594272727273">
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16
Frequency
350
300
250
200
150
100
50
0
2.70
2.75
4.10
4.35
4.70
9.11
9.76
10.71
11.56
12.81
13.46
13.96
</figure>
<page confidence="0.995902">
941
</page>
<bodyText confidence="0.999980272727273">
The size of the training corpus is crucial to the
practicability of the proposed method. In this ex-
periment, we analyze the effect of the number of
sentences according to the precision rate of the
speech act using the semantic dependency graphs
with and without the discourse information. From
the results, the precision rates for speech act identi-
fication achieved 95.6 and 92.4 percentages for the
training corpus containing 10,036 and 7,012 sen-
tences using semantic dependency graphs with and
without history, respectively. This means that se-
mantic dependency graph with discourse outper-
forms that without discourse, but more training
data are needed to include the discourse for speech
act identification. Fig. 5 shows the relationship
between the speech act identification rate and the
size of the training corpus. From this figure, we
can find that more training sentences for the se-
mantic dependency graph with discourse analysis
are needed than that without discourse. This im-
plies discourse analysis plays an important role in
the identification of the speech act.
</bodyText>
<subsectionHeader confidence="0.994143">
3.3 Performance analysis of semantic depend-
ency graph
</subsectionHeader>
<bodyText confidence="0.999797">
To evaluate the performance, two systems were
developed for comparison. One is based on the
Bayes’ classifier (Walker et al., 1997), and the
other is the use of the partial pattern tree (Wu et al.,
2004) to identify the speech act of the user’s utter-
ances. Since the dialogue discourse is defined as a
sequence of speech acts. The prediction of speech
act of the new input utterance becomes the core
issue for discourse modeling. The accuracy for
speech act identification is shown in Table 1.
According to the observation of the results, se-
mantic dependency graphs obtain obvious
</bodyText>
<figure confidence="0.923192666666667">
1 2 3 4 5 6 7 8 9 10 11 12 13 14
Size of corpus
(the number of sentence, in thousands)
</figure>
<figureCaption confidence="0.9437395">
Figure 5. The relation between the speech act iden-
tification rate and the size of training corpus
</figureCaption>
<bodyText confidence="0.999845583333333">
improvement compared to other approaches. The
reason is that not only the meanings of the words
or concepts but also the structural information and
the implicit semantic relation defined in the knowl-
edge base are needed to identify the speech
act.Besides, taking the discourse into consideration
will improve the prediction about the speech act of
the new or next utterance. This means the dis-
course model can improve the accuracy of the
speech act identification, that is to say, discourse
modeling can help understand the user’s desired
intension especially when the answer is very short.
</bodyText>
<table confidence="0.84721978125">
Speech act identification rate (%J
87.5
62.5
100
75
50
semantic dependency graph with
discourse analysis
semantic dependency graph
without discourse analysis
Speech act Semantic dependency graph PPT Bayes’
Classifier
With discourse analysis Without discourse analysis
Clinic information 100 96.1 88 92
(26 sentences) (26) (25) (23) (24)
Dr.’s information 97 92.8 66.6 92.8
(42 sentences) (41) (39) (28) (39)
Confirmation(others) 95 95 95 95
(42 sentences) (40) (40) (40) (40)
Others 57.1 50 43 38
(14 sentences) (8) (6) (5)
FAQ 70 53.8 61.5 46
(13 sentences) (9) (7) (6)
Clinic information 98.5 96.2 91.1 93.3
(135 sentences) (133) (130) (123) (126)
Time 94.7 89.4 97.3 92.1
(38) (36) (34) (37) (35)
Registration 100 100 86.6 86.6
(75) (75) (75) (65) (65)
Cancel registration 90 80 60 80
(10) (9) (8) (6) (8)
Average Precision 95.6 92.4 85 88.1
</table>
<tableCaption confidence="0.999543">
Table 1 The accuracy for speech act identification
</tableCaption>
<page confidence="0.993648">
942
</page>
<bodyText confidence="0.999826038461538">
For example, the user may only say “yes” or “no”
for confirmation. The misclassification in speech
act will happen due to the limited information.
However, it can obtain better interpretation by
introducing the semantic dependency relations as
well as the discourse information.
To obtain the single measurement, the average
accuracy for speech act identification is shown in
Table 1. The best approach is the semantic de-
pendency graphs with the discourse. This means
the information of the discourse can help speech
act identification. And the semantic dependency
graph outperforms the traditional approach due to
the semantic analysis of words with their corre-
sponding relations.
The success of the dialog lies on the achievement
of the common ground between users and ma-
chine which is the most important issue in dia-
logue management. To compare the semantic
dependency graph with previous approaches, 150
individuals who were not involved in the devel-
opment of this project were asked to use the dia-
logue system to measure the task success rate. To
filter out the incomplete tasks, 131 dialogs were
employed as the analysis data in this experiment.
The results are listed in Table 2.
</bodyText>
<table confidence="0.798552">
SDG&apos; SDG2 PPT Bayes’
Task 87.2 85.5 79.4 80.2
completion
rate
Number of 8.3 8.7 10.4 10.5
turns on
average
</table>
<bodyText confidence="0.966627103448276">
SDG&apos; :With discourse analysis, SDG2 :Without discourse
Table 2 Comparisons on the Task completion rate
and the number of dialogue turns between differ-
ent approaches
We found that the dialogue completion rate and
the average length of the dialogs using the de-
pendency graph are better than those using the
Bayes’ classifier and partial pattern tree approach.
Two main reasons are concluded: First, depend-
ency graph can keep the most important informa-
tion in the user’s utterance, while in semantic
slot/frame approach, the semantic objects not
matching the semantic slot/frame are generally
filtered out. This approach is able to skip the repe
tition or similar utterances to fill the same infor-
mation in different semantic slots. Second, the
dependency graph-based approach can provide the
inference to help the interpretation of the user’s
intension.
For semantic understanding, correct interpretation
of the information from the user’s utterances be-
comes inevitable. Correct speech act identification
and correct extraction of the semantic objects are
both important issues for semantic understanding
in the spoken dialogue systems. Five main catego-
ries about medical application, clinic information,
Dr.’s information, confirmation for the clinic in-
formation, registration time and clinic inference,
are analyzed in this experiment.
</bodyText>
<table confidence="0.991133">
SDG PPT Bayes’
Clinic infor- 95.0 89.5 90.3
mation
Dr.’s infor- 94.3 71.7 92.4
mation
Confirmation 98.0 98.0 98.0
(Clinic)
Clinic 97.3 74.6 78.6
Time 97.6 97.8 95.5
SDG:With discourse analysis
</table>
<tableCaption confidence="0.969746">
Table 3 Correction rates for semantic object ex-
</tableCaption>
<bodyText confidence="0.972829666666667">
traction
According to the results shown in Table 3, the
worst condition happened in the query for the
Dr.’s information using the partial pattern tree.
The mis-identification of speech act results in the
un-matched semantic slots/frames. This condition
will not happen in semantic dependency graph,
since the semantic dependency graph always
keeps the most important semantic objects accord-
ing to the dependency relations in the semantic
dependency graph instead of the semantic slots.
Rather than filtering out the unmatched semantic
objects, the semantic dependency graph is con-
structed to keep the semantic relations in the ut-
terance. This means that the system can preserve
most of the user’s information via the semantic
dependency graphs. We can observe the identifi-
cation rate of the speech act is higher for the se-
mantic dependency graph than that for the partial
pattern tree and Bayes’ classifier as shown in Ta-
ble 3.
</bodyText>
<page confidence="0.998626">
943
</page>
<sectionHeader confidence="0.999683" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999982764705883">
This paper has presented a semantic depend-
ency graph that robustly and effectively deals with
a variety of conversational discourse information
in the spoken dialogue systems. By modeling the
dialogue discourse as the speech act sequence, the
predictive method for speech act identification is
proposed based on discourse analysis instead of
keywords only. According to the corpus analysis,
we can find the model proposed in this paper is
practicable and effective. The results of the ex-
periments show the semantic dependency graph
outperforms those based on the Bayes’ rule and
partial pattern trees. By integrating discourse
analysis this result also shows the improvement
obtained not only in the identification rate of
speech act but also in the performance for seman-
tic object extraction.
</bodyText>
<sectionHeader confidence="0.99903" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.99317325">
The authors would like to thank the National
Science Council, Republic of China, for its finan-
cial support of this work, under Contract No. NSC
94-2213-E-006-018.
</bodyText>
<sectionHeader confidence="0.999199" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999950585714286">
J. F. Allen, D. K. Byron, D. M. Ferguson, L. Galescu,
and A. Stent. 2001. Towards Conversational Hu-
man-Computer Interaction. AI Magazine.
C. F. Baker, C. J. Fillmore, and J. B. Lowe. 1998. The
Berkeley FrameNet Project. In Proceedings of
COLING/ACL. 86-90
K. J. Chen, C. R. Huang, F.Y. Chen, C. C. Luo, M. C.
Chang, and C.J. Chen. 2001. Sinica Treebank: De-
sign Criteria, representational issues and immple-
mentation. In Anne Abeille, editor, Building and
Using Syntactically Annotated Corpora. Kluwer. 29-
37
Z. Dong and Q. Dong. 2006. HowNet and the computa-
tion of meaning. World Scientific Publishing Co Inc.
J. Gao, and H. Suzuki. 2003. Unsupervised learning of
dependency structure for language modeling. In
Proceedings of ACL 2003, 521-528.
D. Gildea and D. Jurafsky. 2002. Automatic labeling of
semantic roles. Computational Linguistics, 28(3).
245–288.
K. Hacioglu, S. Pradhan, W. Ward, J. Martin, and D.
Jurafsky. 2003. Shallow semantic parsing using
support vector machines. Technical Report TR-
CSLR-2003-1, Center for Spoken Language Re-
search, Boulder, Colorado.
K. Hacioglu and W. Ward. 2003. Target word detection
and semantic role chunking using support vector
machines. In HLT-03.
R. Higashinaka, N. Miyazaki, M. Nakano, and K. Ai-
kawa. 2004. Evaluating Discourse Understanding in
Spoken Dialogue Systems. ACM Transactions on
Speech and Language Processing (TSLP), Volume 1,
1-20.
X. Huang, A. Acero, and H.-W. Hon. 2001. Spoken
Language Proceeding. Prentice-Hall,Inc.
T. Kudo and Y. Matsumoto. 2000. Japanese Depend-
ency Structure Analysis Based on Support Vector
Machines. In Proceedings of the EMLNP. 18–25
M. F. McTEAR. 2002. Spoken Dialogue Technology:
Enabling the Conversational User Interface. ACM
Computer Surveys, Vol 34, No. 1, 90-169..
B. Rajesh, and B. Linda. 2004. Taxonomy of speech-
enabled applications (http://www106.ibm.com/de-
veloperworks/wireless/library/wi-tax/)
J. Searle. 1979. Expression and Meaning: Studies in the
Theory of Speech Acts. New York, Cambridge Uni-
versity Press.
A. Stolcke, K. Ries, N. Coccaro, E. Shriberg, R. Bates,
D. Jurafsky, P. Taylor, R. Martin, C. Van Ess-
Dykema, and M. Meteer. 2000. Dialogue act model-
ing for automatic tagging and recognition of conver-
sational speech. Computational Linguistics 26(3),
339--373.
M. A. Walker, D. Litman, C. Kamm, and A. Abella,
1997. PARADISE: a general framework for evaluat-
ing spoken dialogue agents. In Proceedings of the
ACL, 271–280
M. Walker and R. Passonneau. 2001. DATE: a dia-
logue act tagging scheme for evaluation of spoken
dialogue systems. In Proceedings of the first inter-
national conference on Human language technology
research. 1-8.
Y.-Y. Wang and A. Acero. 2003. Combination of CFG
and N-gram Modeling in Semantic Grammar Learn-
ing, In Proceedings of the Eurospeech Conference.
Geneva, Switzerland. September 2003.
C.-H. Wu, J.-F. Yeh, and M.-J. Chen. 2004. Speech
Act Identification using an Ontology-Based Partial
Pattern Tree. in Proceedings of ICSLP 2004, Jeju,
Korea, 2004.
</reference>
<page confidence="0.998643">
944
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.826701">
<title confidence="0.9997175">Stochastic Discourse Modeling in Spoken Dialogue Systems Using Semantic Dependency Graphs</title>
<author confidence="0.999198">Jui-Feng Yeh</author>
<author confidence="0.999198">Chung-Hsien Wu</author>
<author confidence="0.999198">Mao-Zhu Yang</author>
<affiliation confidence="0.999345">Department of Computer Science and Information Engineering National Cheng Kung University</affiliation>
<address confidence="0.98526">No. 1, Ta-Hsueh Road, Tainan, Taiwan, R.O.C.</address>
<email confidence="0.974963">jfyeh@csie.ncku.edu.tw</email>
<email confidence="0.974963">chwu@csie.ncku.edu.tw</email>
<email confidence="0.974963">mzyang@csie.ncku.edu.tw</email>
<abstract confidence="0.99427173076923">This investigation proposes an approach to modeling the discourse of spoken dialogue using semantic dependency graphs. By characterizing the discourse as a sequence of speech acts, discourse modeling becomes the identification of the speech act sequence. A statistical approach is adopted to model the relations between words in the user’s utterance using the semantic dependency graphs. Dependency relation between the headword and other words in a sentence is detected using the semantic dependency grammar. In order to evaluate the proposed method, a dialogue system for medical service is developed. Experimental results show that the rates for speech act detection and taskcompletion are 95.6% and 85.24%, respectively, and the average number of turns of each dialogue is 8.3. Compared with the Bayes’ classifier and the Partial- Pattern Tree based approaches, we obtain 14.9% and 12.47% improvements in accuracy for speech act identification, respectively.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J F Allen</author>
<author>D K Byron</author>
<author>D M Ferguson</author>
<author>L Galescu</author>
<author>A Stent</author>
</authors>
<title>Towards Conversational Human-Computer Interaction.</title>
<date>2001</date>
<publisher>AI Magazine.</publisher>
<marker>Allen, Byron, Ferguson, Galescu, Stent, 2001</marker>
<rawString>J. F. Allen, D. K. Byron, D. M. Ferguson, L. Galescu, and A. Stent. 2001. Towards Conversational Human-Computer Interaction. AI Magazine.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C F Baker</author>
<author>C J Fillmore</author>
<author>J B Lowe</author>
</authors>
<title>The Berkeley FrameNet Project.</title>
<date>1998</date>
<booktitle>In Proceedings of COLING/ACL.</booktitle>
<pages>86--90</pages>
<marker>Baker, Fillmore, Lowe, 1998</marker>
<rawString>C. F. Baker, C. J. Fillmore, and J. B. Lowe. 1998. The Berkeley FrameNet Project. In Proceedings of COLING/ACL. 86-90</rawString>
</citation>
<citation valid="true">
<authors>
<author>K J Chen</author>
<author>C R Huang</author>
<author>F Y Chen</author>
<author>C C Luo</author>
<author>M C Chang</author>
<author>C J Chen</author>
</authors>
<title>Sinica Treebank: Design Criteria, representational issues and immplementation.</title>
<date>2001</date>
<booktitle>In Anne Abeille, editor, Building and Using Syntactically Annotated Corpora. Kluwer.</booktitle>
<pages>29--37</pages>
<contexts>
<context position="9414" citStr="Chen et al., 2001" startWordPosition="1541" endWordPosition="1544">imation. P(Di,Ht−1 |SAt) =P(Di,SA1,SA2,...,SAt−1 |SAt) (4) P(Di,SAt −1 |SAt) For the combination of the semantic and syntactic structures, the relations defined in HowNet are employed as the dependency relations, and the hypernym is adopted as the semantic concept according to the primary features of the words defined in HowNet. The headwords are decided by the algorithm based on the part of speech (POS) proposed by Academia Sinica in Taiwan. The probabilities of the headwords are estimated according to the probabilistic context free grammar (PCFG) trained on the Treebank developed by Sinica (Chen et al., 2001). That is to say, the headwords are extracted according to the syntactic structure and the dependency graphs are constructed by the semantic relations defined in HowNet. According to previous definition with independent assumption and the bigram smoothing of the speech act model using the back-off procedure, we can rewrite Equation (4) into Equation (5). P(Di,SAt−1 |SAt) m 1 = ( ( , ), |) i t t α ∏ P DR w w SA SA − + k k kh k m (1 ) ( ( , ) |) i t − α k k kh ∏ P DR w w SA k where α is the mixture factor for normalization. According to the conceptual representation of the word, the transformati</context>
</contexts>
<marker>Chen, Huang, Chen, Luo, Chang, Chen, 2001</marker>
<rawString>K. J. Chen, C. R. Huang, F.Y. Chen, C. C. Luo, M. C. Chang, and C.J. Chen. 2001. Sinica Treebank: Design Criteria, representational issues and immplementation. In Anne Abeille, editor, Building and Using Syntactically Annotated Corpora. Kluwer. 29-37</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Dong</author>
<author>Q Dong</author>
</authors>
<title>HowNet and the computation of meaning.</title>
<date>2006</date>
<publisher>World Scientific Publishing Co Inc.</publisher>
<contexts>
<context position="5409" citStr="Dong and Dong 2006" startWordPosition="818" endWordPosition="821">ntic dependency graph (Gildea and Jurasfky, 2002; Hacioglu and Ward, 2003). The semantic relations constrain the word sense and provide the method for disambiguation. Semantic roles are assigned when the relation established among semantic objects. Both semantic relations and roles are defined in many knowledge resources or ontologies, such as FrameNet (Baker et al., 2004) and HowNet with 65,000 concepts in Chinese and close to 75,000 English equivalents, is a bilingual knowledge-base describing relations between concepts and relations between the attributes of concepts with ontological view (Dong and Dong 2006). Generally speaking, semantic class is defined as a set with the elements that are usually the words with the same semantic interpretation. Hypernyms that are superordinate concepts of the words are usually used as the semantic classes just like the Hypernyms of synsets in WordNet (http://www.cogsci.princeton.edu/~wn/) or definitions of words’ primary features in HowNet. Besides, the approach for understanding tries to find the implicit semantic dependency between the concepts and the dependency structure between concepts in the utterance are also taken into consideration. Instead of semantic</context>
</contexts>
<marker>Dong, Dong, 2006</marker>
<rawString>Z. Dong and Q. Dong. 2006. HowNet and the computation of meaning. World Scientific Publishing Co Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Gao</author>
<author>H Suzuki</author>
</authors>
<title>Unsupervised learning of dependency structure for language modeling.</title>
<date>2003</date>
<booktitle>In Proceedings of ACL 2003,</booktitle>
<pages>521--528</pages>
<contexts>
<context position="4681" citStr="Gao and Suzuki, 2003" startWordPosition="709" endWordPosition="713">rom the user’s utterances. The second is a more effective speech act identification approach for semantic understanding is needed. Since speech act plays an important role in the development of dialogue management for dealing with complex applications, speech act identification with semantic interpretation will be the most important topic with respect to the methods used to control the dialogue with the users. This paper proposes an approach integrating semantic dependency graph and history/discourse information to model the dialogue discourse (Kudo and Matsumoto, 2000; Hacioglu et al., 2003; Gao and Suzuki, 2003). Three major components, such as semantic relation, semantic class and semantic role are adopted in the semantic dependency graph (Gildea and Jurasfky, 2002; Hacioglu and Ward, 2003). The semantic relations constrain the word sense and provide the method for disambiguation. Semantic roles are assigned when the relation established among semantic objects. Both semantic relations and roles are defined in many knowledge resources or ontologies, such as FrameNet (Baker et al., 2004) and HowNet with 65,000 concepts in Chinese and close to 75,000 English equivalents, is a bilingual knowledge-base d</context>
</contexts>
<marker>Gao, Suzuki, 2003</marker>
<rawString>J. Gao, and H. Suzuki. 2003. Unsupervised learning of dependency structure for language modeling. In Proceedings of ACL 2003, 521-528.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Gildea</author>
<author>D Jurafsky</author>
</authors>
<title>Automatic labeling of semantic roles.</title>
<date>2002</date>
<journal>Computational Linguistics,</journal>
<volume>28</volume>
<issue>3</issue>
<pages>245--288</pages>
<marker>Gildea, Jurafsky, 2002</marker>
<rawString>D. Gildea and D. Jurafsky. 2002. Automatic labeling of semantic roles. Computational Linguistics, 28(3). 245–288.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Hacioglu</author>
<author>S Pradhan</author>
<author>W Ward</author>
<author>J Martin</author>
<author>D Jurafsky</author>
</authors>
<title>Shallow semantic parsing using support vector machines.</title>
<date>2003</date>
<tech>Technical Report TRCSLR-2003-1,</tech>
<institution>Center for Spoken Language Research,</institution>
<location>Boulder, Colorado.</location>
<contexts>
<context position="4658" citStr="Hacioglu et al., 2003" startWordPosition="705" endWordPosition="708">n the semantic object from the user’s utterances. The second is a more effective speech act identification approach for semantic understanding is needed. Since speech act plays an important role in the development of dialogue management for dealing with complex applications, speech act identification with semantic interpretation will be the most important topic with respect to the methods used to control the dialogue with the users. This paper proposes an approach integrating semantic dependency graph and history/discourse information to model the dialogue discourse (Kudo and Matsumoto, 2000; Hacioglu et al., 2003; Gao and Suzuki, 2003). Three major components, such as semantic relation, semantic class and semantic role are adopted in the semantic dependency graph (Gildea and Jurasfky, 2002; Hacioglu and Ward, 2003). The semantic relations constrain the word sense and provide the method for disambiguation. Semantic roles are assigned when the relation established among semantic objects. Both semantic relations and roles are defined in many knowledge resources or ontologies, such as FrameNet (Baker et al., 2004) and HowNet with 65,000 concepts in Chinese and close to 75,000 English equivalents, is a bil</context>
</contexts>
<marker>Hacioglu, Pradhan, Ward, Martin, Jurafsky, 2003</marker>
<rawString>K. Hacioglu, S. Pradhan, W. Ward, J. Martin, and D. Jurafsky. 2003. Shallow semantic parsing using support vector machines. Technical Report TRCSLR-2003-1, Center for Spoken Language Research, Boulder, Colorado.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Hacioglu</author>
<author>W Ward</author>
</authors>
<title>Target word detection and semantic role chunking using support vector machines.</title>
<date>2003</date>
<booktitle>In HLT-03.</booktitle>
<contexts>
<context position="4864" citStr="Hacioglu and Ward, 2003" startWordPosition="737" endWordPosition="740">evelopment of dialogue management for dealing with complex applications, speech act identification with semantic interpretation will be the most important topic with respect to the methods used to control the dialogue with the users. This paper proposes an approach integrating semantic dependency graph and history/discourse information to model the dialogue discourse (Kudo and Matsumoto, 2000; Hacioglu et al., 2003; Gao and Suzuki, 2003). Three major components, such as semantic relation, semantic class and semantic role are adopted in the semantic dependency graph (Gildea and Jurasfky, 2002; Hacioglu and Ward, 2003). The semantic relations constrain the word sense and provide the method for disambiguation. Semantic roles are assigned when the relation established among semantic objects. Both semantic relations and roles are defined in many knowledge resources or ontologies, such as FrameNet (Baker et al., 2004) and HowNet with 65,000 concepts in Chinese and close to 75,000 English equivalents, is a bilingual knowledge-base describing relations between concepts and relations between the attributes of concepts with ontological view (Dong and Dong 2006). Generally speaking, semantic class is defined as a se</context>
</contexts>
<marker>Hacioglu, Ward, 2003</marker>
<rawString>K. Hacioglu and W. Ward. 2003. Target word detection and semantic role chunking using support vector machines. In HLT-03.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Higashinaka</author>
<author>N Miyazaki</author>
<author>M Nakano</author>
<author>K Aikawa</author>
</authors>
<title>Evaluating Discourse Understanding in Spoken Dialogue Systems.</title>
<date>2004</date>
<journal>ACM Transactions on Speech and Language Processing (TSLP),</journal>
<volume>1</volume>
<pages>1--20</pages>
<contexts>
<context position="1637" citStr="Higashinaka et al., 2004" startWordPosition="243" endWordPosition="246">95.6% and 85.24%, respectively, and the average number of turns of each dialogue is 8.3. Compared with the Bayes’ classifier and the PartialPattern Tree based approaches, we obtain 14.9% and 12.47% improvements in accuracy for speech act identification, respectively. 1 Introduction It is a very tremendous vision of the computer technology to communicate with the machine using spoken language (Huang et al., 2001; Allen at al., 2001). Understanding of spontaneous language is arguably the core technology of the spoken dialogue systems, since the more accurate information obtained by the machine (Higashinaka et al., 2004), the more possibility to finish the dialogue task. Practical use of speech act theories in spoken language processing (Stolcke et al. 2000; Walker and Passonneau 2001; Wu et al., 2004) have given both insight and deeper understanding of verbal communication. Therefore, when considering the whole discourse, the relationship between the speech acts of the dialogue turns becomes extremely important. In the last decade, several practicable dialogue systems (McTEAR, 2002), such as air travel information service system, weather forecast system, automatic banking system, automatic train timetable in</context>
</contexts>
<marker>Higashinaka, Miyazaki, Nakano, Aikawa, 2004</marker>
<rawString>R. Higashinaka, N. Miyazaki, M. Nakano, and K. Aikawa. 2004. Evaluating Discourse Understanding in Spoken Dialogue Systems. ACM Transactions on Speech and Language Processing (TSLP), Volume 1, 1-20.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Huang</author>
<author>A Acero</author>
<author>H-W Hon</author>
</authors>
<title>Spoken Language Proceeding.</title>
<date>2001</date>
<publisher>Prentice-Hall,Inc.</publisher>
<contexts>
<context position="1426" citStr="Huang et al., 2001" startWordPosition="211" endWordPosition="214"> dependency grammar. In order to evaluate the proposed method, a dialogue system for medical service is developed. Experimental results show that the rates for speech act detection and taskcompletion are 95.6% and 85.24%, respectively, and the average number of turns of each dialogue is 8.3. Compared with the Bayes’ classifier and the PartialPattern Tree based approaches, we obtain 14.9% and 12.47% improvements in accuracy for speech act identification, respectively. 1 Introduction It is a very tremendous vision of the computer technology to communicate with the machine using spoken language (Huang et al., 2001; Allen at al., 2001). Understanding of spontaneous language is arguably the core technology of the spoken dialogue systems, since the more accurate information obtained by the machine (Higashinaka et al., 2004), the more possibility to finish the dialogue task. Practical use of speech act theories in spoken language processing (Stolcke et al. 2000; Walker and Passonneau 2001; Wu et al., 2004) have given both insight and deeper understanding of verbal communication. Therefore, when considering the whole discourse, the relationship between the speech acts of the dialogue turns becomes extremely</context>
</contexts>
<marker>Huang, Acero, Hon, 2001</marker>
<rawString>X. Huang, A. Acero, and H.-W. Hon. 2001. Spoken Language Proceeding. Prentice-Hall,Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Kudo</author>
<author>Y Matsumoto</author>
</authors>
<title>Japanese Dependency Structure Analysis Based on Support Vector Machines.</title>
<date>2000</date>
<booktitle>In Proceedings of the EMLNP.</booktitle>
<pages>18--25</pages>
<contexts>
<context position="4635" citStr="Kudo and Matsumoto, 2000" startWordPosition="700" endWordPosition="704"> first one is how to obtain the semantic object from the user’s utterances. The second is a more effective speech act identification approach for semantic understanding is needed. Since speech act plays an important role in the development of dialogue management for dealing with complex applications, speech act identification with semantic interpretation will be the most important topic with respect to the methods used to control the dialogue with the users. This paper proposes an approach integrating semantic dependency graph and history/discourse information to model the dialogue discourse (Kudo and Matsumoto, 2000; Hacioglu et al., 2003; Gao and Suzuki, 2003). Three major components, such as semantic relation, semantic class and semantic role are adopted in the semantic dependency graph (Gildea and Jurasfky, 2002; Hacioglu and Ward, 2003). The semantic relations constrain the word sense and provide the method for disambiguation. Semantic roles are assigned when the relation established among semantic objects. Both semantic relations and roles are defined in many knowledge resources or ontologies, such as FrameNet (Baker et al., 2004) and HowNet with 65,000 concepts in Chinese and close to 75,000 Englis</context>
</contexts>
<marker>Kudo, Matsumoto, 2000</marker>
<rawString>T. Kudo and Y. Matsumoto. 2000. Japanese Dependency Structure Analysis Based on Support Vector Machines. In Proceedings of the EMLNP. 18–25</rawString>
</citation>
<citation valid="true">
<authors>
<author>M F McTEAR</author>
</authors>
<title>Spoken Dialogue Technology: Enabling the Conversational User Interface.</title>
<date>2002</date>
<journal>ACM Computer Surveys,</journal>
<volume>34</volume>
<pages>90--169</pages>
<contexts>
<context position="2109" citStr="McTEAR, 2002" startWordPosition="318" endWordPosition="319">ly the core technology of the spoken dialogue systems, since the more accurate information obtained by the machine (Higashinaka et al., 2004), the more possibility to finish the dialogue task. Practical use of speech act theories in spoken language processing (Stolcke et al. 2000; Walker and Passonneau 2001; Wu et al., 2004) have given both insight and deeper understanding of verbal communication. Therefore, when considering the whole discourse, the relationship between the speech acts of the dialogue turns becomes extremely important. In the last decade, several practicable dialogue systems (McTEAR, 2002), such as air travel information service system, weather forecast system, automatic banking system, automatic train timetable information system, and the Circuit-Fix-it shop system, have been developed to extract the user’s semantic entities using the semantic frames/slots and conceptual graphs. The dialogue management in these systems is able to handle the dialogue flow efficaciously. However, it is not applicable to the more complex applications such as “Type 5: the natural language conversational applications” defined by IBM (Rajesh and Linda, 2004). In Type 5 dialog systems, it is possible</context>
</contexts>
<marker>McTEAR, 2002</marker>
<rawString>M. F. McTEAR. 2002. Spoken Dialogue Technology: Enabling the Conversational User Interface. ACM Computer Surveys, Vol 34, No. 1, 90-169..</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Rajesh</author>
<author>B Linda</author>
</authors>
<date>2004</date>
<note>Taxonomy of speechenabled applications (http://www106.ibm.com/developerworks/wireless/library/wi-tax/)</note>
<contexts>
<context position="2667" citStr="Rajesh and Linda, 2004" startWordPosition="398" endWordPosition="401"> last decade, several practicable dialogue systems (McTEAR, 2002), such as air travel information service system, weather forecast system, automatic banking system, automatic train timetable information system, and the Circuit-Fix-it shop system, have been developed to extract the user’s semantic entities using the semantic frames/slots and conceptual graphs. The dialogue management in these systems is able to handle the dialogue flow efficaciously. However, it is not applicable to the more complex applications such as “Type 5: the natural language conversational applications” defined by IBM (Rajesh and Linda, 2004). In Type 5 dialog systems, it is possible for the users to switch directly from one ongoing task to another. In the traditional approaches, the absence of precise speech act identification without discourse analysis will result in the failure in task switching. The capability for identifying the speech act and extracting the semantic objects by reasoning plays a more important role for the dialog systems. This research proposes a semantic dependency-based discourse model to capture and share the semantic objects among tasks that switch during a dialog for semantic resolution. Besides 937 Proc</context>
</contexts>
<marker>Rajesh, Linda, 2004</marker>
<rawString>B. Rajesh, and B. Linda. 2004. Taxonomy of speechenabled applications (http://www106.ibm.com/developerworks/wireless/library/wi-tax/)</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Searle</author>
</authors>
<title>Expression and Meaning: Studies in the Theory of Speech Acts.</title>
<date>1979</date>
<publisher>University Press.</publisher>
<location>New York, Cambridge</location>
<contexts>
<context position="6247" citStr="Searle, 1979" startWordPosition="946" endWordPosition="947">tic classes just like the Hypernyms of synsets in WordNet (http://www.cogsci.princeton.edu/~wn/) or definitions of words’ primary features in HowNet. Besides, the approach for understanding tries to find the implicit semantic dependency between the concepts and the dependency structure between concepts in the utterance are also taken into consideration. Instead of semantic frame/slot, semantic dependency graph can keep more information for dialogue understanding. 2 Semantic Dependency Graph Since speech act theory is developed to extract the functional meaning of an utterance in the dialogue (Searle, 1979), discourse or history can be defined as a sequence of speech acts, H SA SA SA SA t 1 2 t −1 = { , ,.... , } t , and accordingly the speech act theory can be adopted for discourse modeling. Based on this definition, the discourse analysis in semantics using the dependency graphs tries to identify the speech act sequence of the discourse. Therefore, discourse modeling by means of speech act identification considering the history is shown in Equation (1). By introducing the hidden variable Di, representing the i-th possible dependency graph derived from the word sequence W. The dependency relati</context>
</contexts>
<marker>Searle, 1979</marker>
<rawString>J. Searle. 1979. Expression and Meaning: Studies in the Theory of Speech Acts. New York, Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Stolcke</author>
<author>K Ries</author>
<author>N Coccaro</author>
<author>E Shriberg</author>
<author>R Bates</author>
<author>D Jurafsky</author>
<author>P Taylor</author>
<author>R Martin</author>
<author>C Van EssDykema</author>
<author>M Meteer</author>
</authors>
<title>Dialogue act modeling for automatic tagging and recognition of conversational speech.</title>
<date>2000</date>
<journal>Computational Linguistics</journal>
<volume>26</volume>
<issue>3</issue>
<pages>339--373</pages>
<marker>Stolcke, Ries, Coccaro, Shriberg, Bates, Jurafsky, Taylor, Martin, Van EssDykema, Meteer, 2000</marker>
<rawString>A. Stolcke, K. Ries, N. Coccaro, E. Shriberg, R. Bates, D. Jurafsky, P. Taylor, R. Martin, C. Van EssDykema, and M. Meteer. 2000. Dialogue act modeling for automatic tagging and recognition of conversational speech. Computational Linguistics 26(3), 339--373.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A Walker</author>
<author>D Litman</author>
<author>C Kamm</author>
<author>A Abella</author>
</authors>
<title>PARADISE: a general framework for evaluating spoken dialogue agents.</title>
<date>1997</date>
<booktitle>In Proceedings of the ACL,</booktitle>
<pages>271--280</pages>
<contexts>
<context position="17495" citStr="Walker et al., 1997" startWordPosition="3093" endWordPosition="3096">ata are needed to include the discourse for speech act identification. Fig. 5 shows the relationship between the speech act identification rate and the size of the training corpus. From this figure, we can find that more training sentences for the semantic dependency graph with discourse analysis are needed than that without discourse. This implies discourse analysis plays an important role in the identification of the speech act. 3.3 Performance analysis of semantic dependency graph To evaluate the performance, two systems were developed for comparison. One is based on the Bayes’ classifier (Walker et al., 1997), and the other is the use of the partial pattern tree (Wu et al., 2004) to identify the speech act of the user’s utterances. Since the dialogue discourse is defined as a sequence of speech acts. The prediction of speech act of the new input utterance becomes the core issue for discourse modeling. The accuracy for speech act identification is shown in Table 1. According to the observation of the results, semantic dependency graphs obtain obvious 1 2 3 4 5 6 7 8 9 10 11 12 13 14 Size of corpus (the number of sentence, in thousands) Figure 5. The relation between the speech act identification ra</context>
</contexts>
<marker>Walker, Litman, Kamm, Abella, 1997</marker>
<rawString>M. A. Walker, D. Litman, C. Kamm, and A. Abella, 1997. PARADISE: a general framework for evaluating spoken dialogue agents. In Proceedings of the ACL, 271–280</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Walker</author>
<author>R Passonneau</author>
</authors>
<title>DATE: a dialogue act tagging scheme for evaluation of spoken dialogue systems.</title>
<date>2001</date>
<booktitle>In Proceedings of the first international conference on Human language technology research.</booktitle>
<pages>1--8</pages>
<contexts>
<context position="1804" citStr="Walker and Passonneau 2001" startWordPosition="270" endWordPosition="273">hes, we obtain 14.9% and 12.47% improvements in accuracy for speech act identification, respectively. 1 Introduction It is a very tremendous vision of the computer technology to communicate with the machine using spoken language (Huang et al., 2001; Allen at al., 2001). Understanding of spontaneous language is arguably the core technology of the spoken dialogue systems, since the more accurate information obtained by the machine (Higashinaka et al., 2004), the more possibility to finish the dialogue task. Practical use of speech act theories in spoken language processing (Stolcke et al. 2000; Walker and Passonneau 2001; Wu et al., 2004) have given both insight and deeper understanding of verbal communication. Therefore, when considering the whole discourse, the relationship between the speech acts of the dialogue turns becomes extremely important. In the last decade, several practicable dialogue systems (McTEAR, 2002), such as air travel information service system, weather forecast system, automatic banking system, automatic train timetable information system, and the Circuit-Fix-it shop system, have been developed to extract the user’s semantic entities using the semantic frames/slots and conceptual graphs</context>
</contexts>
<marker>Walker, Passonneau, 2001</marker>
<rawString>M. Walker and R. Passonneau. 2001. DATE: a dialogue act tagging scheme for evaluation of spoken dialogue systems. In Proceedings of the first international conference on Human language technology research. 1-8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y-Y Wang</author>
<author>A Acero</author>
</authors>
<date>2003</date>
<booktitle>Combination of CFG and N-gram Modeling in Semantic Grammar Learning, In Proceedings of the Eurospeech Conference.</booktitle>
<location>Geneva, Switzerland.</location>
<marker>Wang, Acero, 2003</marker>
<rawString>Y.-Y. Wang and A. Acero. 2003. Combination of CFG and N-gram Modeling in Semantic Grammar Learning, In Proceedings of the Eurospeech Conference. Geneva, Switzerland. September 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C-H Wu</author>
<author>J-F Yeh</author>
<author>M-J Chen</author>
</authors>
<title>Speech Act Identification using an Ontology-Based Partial Pattern Tree.</title>
<date>2004</date>
<booktitle>in Proceedings of ICSLP 2004,</booktitle>
<location>Jeju,</location>
<contexts>
<context position="1822" citStr="Wu et al., 2004" startWordPosition="274" endWordPosition="277">47% improvements in accuracy for speech act identification, respectively. 1 Introduction It is a very tremendous vision of the computer technology to communicate with the machine using spoken language (Huang et al., 2001; Allen at al., 2001). Understanding of spontaneous language is arguably the core technology of the spoken dialogue systems, since the more accurate information obtained by the machine (Higashinaka et al., 2004), the more possibility to finish the dialogue task. Practical use of speech act theories in spoken language processing (Stolcke et al. 2000; Walker and Passonneau 2001; Wu et al., 2004) have given both insight and deeper understanding of verbal communication. Therefore, when considering the whole discourse, the relationship between the speech acts of the dialogue turns becomes extremely important. In the last decade, several practicable dialogue systems (McTEAR, 2002), such as air travel information service system, weather forecast system, automatic banking system, automatic train timetable information system, and the Circuit-Fix-it shop system, have been developed to extract the user’s semantic entities using the semantic frames/slots and conceptual graphs. The dialogue man</context>
<context position="17567" citStr="Wu et al., 2004" startWordPosition="3108" endWordPosition="3111">5 shows the relationship between the speech act identification rate and the size of the training corpus. From this figure, we can find that more training sentences for the semantic dependency graph with discourse analysis are needed than that without discourse. This implies discourse analysis plays an important role in the identification of the speech act. 3.3 Performance analysis of semantic dependency graph To evaluate the performance, two systems were developed for comparison. One is based on the Bayes’ classifier (Walker et al., 1997), and the other is the use of the partial pattern tree (Wu et al., 2004) to identify the speech act of the user’s utterances. Since the dialogue discourse is defined as a sequence of speech acts. The prediction of speech act of the new input utterance becomes the core issue for discourse modeling. The accuracy for speech act identification is shown in Table 1. According to the observation of the results, semantic dependency graphs obtain obvious 1 2 3 4 5 6 7 8 9 10 11 12 13 14 Size of corpus (the number of sentence, in thousands) Figure 5. The relation between the speech act identification rate and the size of training corpus improvement compared to other approac</context>
</contexts>
<marker>Wu, Yeh, Chen, 2004</marker>
<rawString>C.-H. Wu, J.-F. Yeh, and M.-J. Chen. 2004. Speech Act Identification using an Ontology-Based Partial Pattern Tree. in Proceedings of ICSLP 2004, Jeju, Korea, 2004.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>