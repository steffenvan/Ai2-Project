<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001546">
<title confidence="0.998513">
Improving the Scalability of Semi-Markov Conditional
Random Fields for Named Entity Recognition
</title>
<author confidence="0.920753">
Daisuke Okanoharat Yusuke Miyaot Yoshimasa Tsuruoka t Jun’ichi Tsujiitt§
</author>
<affiliation confidence="0.96973">
tDepartment of Computer Science, University of Tokyo
Hongo 7-3-1, Bunkyo-ku, Tokyo, Japan
$School of Informatics, University of Manchester
</affiliation>
<address confidence="0.612064333333333">
POBox 88, Sackville St, MANCHESTER M60 1QD, UK
§SORST, Solution Oriented Research for Science and Technology
Honcho 4-1-8, Kawaguchi-shi, Saitama, Japan
</address>
<email confidence="0.999641">
{hillbig,yusuke,tsuruoka,tsujii}@is.s.u-tokyo.ac.jp
</email>
<sectionHeader confidence="0.9974" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999973083333333">
This paper presents techniques to apply
semi-CRFs to Named Entity Recognition
tasks with a tractable computational cost.
Our framework can handle an NER task
that has long named entities and many
labels which increase the computational
cost. To reduce the computational cost,
we propose two techniques: the first is the
use of feature forests, which enables us to
pack feature-equivalent states, and the sec-
ond is the introduction of a filtering pro-
cess which significantly reduces the num-
ber of candidate states. This framework
allows us to use a rich set of features ex-
tracted from the chunk-based representa-
tion that can capture informative charac-
teristics of entities. We also introduce a
simple trick to transfer information about
distant entities by embedding label infor-
mation into non-entity labels. Experimen-
tal results show that our model achieves an
F-score of 71.48% on the JNLPBA 2004
shared task without using any external re-
sources or post-processing techniques.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999899372093023">
The rapid increase of information in the biomedi-
cal domain has emphasized the need for automated
information extraction techniques. In this paper
we focus on the Named Entity Recognition (NER)
task, which is the first step in tackling more com-
plex tasks such as relation extraction and knowl-
edge mining.
Biomedical NER (Bio-NER) tasks are, in gen-
eral, more difficult than ones in the news domain.
For example, the best F-score in the shared task of
Bio-NER in COLING 2004 JNLPBA (Kim et al.,
2004) was 72.55% (Zhou and Su, 2004) 1, whereas
the best performance at MUC-6, in which systems
tried to identify general named entities such as
person or organization names, was an accuracy of
95% (Sundheim, 1995).
Many of the previous studies of Bio-NER tasks
have been based on machine learning techniques
including Hidden Markov Models (HMMs) (Bikel
et al., 1997), the dictionary HMM model (Kou et
al., 2005) and Maximum Entropy Markov Mod-
els (MEMMs) (Finkel et al., 2004). Among these
methods, conditional random fields (CRFs) (Laf-
ferty et al., 2001) have achieved good results (Kim
et al., 2005; Settles, 2004), presumably because
they are free from the so-called label bias problem
by using a global normalization.
Sarawagi and Cohen (2004) have recently in-
troduced semi-Markov conditional random fields
(semi-CRFs). They are defined on semi-Markov
chains and attach labels to the subsequences of a
sentence, rather than to the tokens2. The semi-
Markov formulation allows one to easily construct
entity-level features. Since the features can cap-
ture all the characteristics of a subsequence, we
can use, for example, a dictionary feature which
measures the similarity between a candidate seg-
ment and the closest element in the dictionary.
Kou et al. (2005) have recently showed that semi-
CRFs perform better than CRFs in the task of
recognition of protein entities.
The main difficulty of applying semi-CRFs to
Bio-NER lies in the computational cost at training
</bodyText>
<footnote confidence="0.999001166666667">
1Krauthammer (2004) reported that the inter-annotator
agreement rate of human experts was 77.6% for bio-NLP,
which suggests that the upper bound of the F-score in a Bio-
NER task may be around 80%.
2Assuming that non-entity words are placed in unit-length
segments.
</footnote>
<page confidence="0.988015">
465
</page>
<bodyText confidence="0.5940285">
Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 465–472,
Sydney, July 2006. c�2006 Association for Computational Linguistics
</bodyText>
<tableCaption confidence="0.994363">
Table 1: Length distribution of entities in the train-
ing set of the shared task in 2004 JNLPBA
</tableCaption>
<table confidence="0.786466363636364">
Length # entity Ratio
1 21646 42.19
2 15442 30.10
3 7530 14.68
4 3505 6.83
5 1379 2.69
6 732 1.43
7 409 0.80
8 252 0.49
&gt;8 406 0.79
total 51301 100.00
</table>
<bodyText confidence="0.998788612903226">
because the number of named entity classes tends
to be large, and the training data typically contain
many long entities, which makes it difficult to enu-
merate all the entity candidates in training. Table
1 shows the length distribution of entities in the
training set of the shared task in 2004 JNLPBA.
Formally, the computational cost of training semi-
CRFs is O(KLN), where L is the upper bound
length of entities, N is the length of sentence and
K is the size of label set. And that of training in
first order semi-CRFs is O(K2LN). The increase
of the cost is used to transfer non-adjacent entity
information.
To improve the scalability of semi-CRFs, we
propose two techniques: the first is to intro-
duce a filtering process that significantly re-
duces the number of candidate entities by using
a “lightweight” classifier, and the second is to
use feature forest (Miyao and Tsujii, 2002), with
which we pack the feature equivalent states. These
enable us to construct semi-CRF models for the
tasks where entity names may be long and many
class-labels exist at the same time. We also present
an extended version of semi-CRFs in which we
can make use of information about a preceding
named entity in defining features within the frame-
work of first order semi-CRFs. Since the preced-
ing entity is not necessarily adjacent to the current
entity, we achieve this by embedding the informa-
tion on preceding labels for named entities into the
labels for non-named entities.
</bodyText>
<sectionHeader confidence="0.865798" genericHeader="introduction">
2 CRFs and Semi-CRFs
</sectionHeader>
<bodyText confidence="0.991518875">
CRFs are undirected graphical models that encode
a conditional probability distribution using a given
set of features. CRFs allow both discriminative
training and bi-directional flow of probabilistic in-
formation along the sequence. In NER, we of-
ten use linear-chain CRFs, which define the con-
ditional probability of a state sequence y = y1, ...,
yn given the observed sequence x = x1,...,xn by:
</bodyText>
<equation confidence="0.981851">
p(y|x, A) = Z1 exp (EZ 1ΣjAjfj(yi−1, yi, x, i)),
(1)
</equation>
<bodyText confidence="0.903700238095238">
where fj(yi−1, yi, x, i) is a feature function and
Z(x) is the normalization factor over all the state
sequences for the sequence x. The model parame-
ters are a set of real-valued weights A = {Aj}, each
of which represents the weight of a feature. All the
feature functions are real-valued and can use adja-
cent label information.
Semi-CRFs are actually a restricted version of
order-L CRFs in which all the labels in a chunk are
the same. We follow the definitions in (Sarawagi
and Cohen, 2004). Let s = (s1, ..., sp) denote a
segmentation of x, where a segment sj = (tj, uj,
yj) consists of a start position tj, an end position
uj, and a label yj. We assume that segments have a
positive length bounded above by the pre-defined
upper bound L (tj &lt; uj, uj − tj + 1 &lt; L) and
completely cover the sequence x without overlap-
ping, that is, s satisfies t1 = 1, up = |x|, and
tj+1 = uj + 1 for j = 1, ..., p − 1. Semi-CRFs
define a conditional probability of a state sequence
y given an observed sequence x by:
</bodyText>
<equation confidence="0.997065">
1
p(y|x, A) = Z(x) exp(ΣjΣiAifi(sj)), (2)
</equation>
<bodyText confidence="0.9952213">
where fi(sj) := fi(yj−1, yj, x, tj, uj) is a fea-
ture function and Z(x) is the normalization factor
as defined for CRFs. The inference problem for
semi-CRFs can be solved by using a semi-Markov
analog of the usual Viterbi algorithm. The com-
putational cost for semi-CRFs is O(KLN) where
L is the upper bound length of entities, N is the
length of sentence and K is the number of label
set. If we use previous label information, the cost
becomes O(K2LN).
</bodyText>
<sectionHeader confidence="0.760747" genericHeader="method">
3 Using Non-Local Information in
</sectionHeader>
<subsectionHeader confidence="0.693999">
Semi-CRFs
</subsectionHeader>
<bodyText confidence="0.9999668">
In conventional CRFs and semi-CRFs, one can
only use the information on the adjacent previ-
ous label when defining the features on a certain
state or entity. In NER tasks, however, informa-
tion about a distant entity is often more useful than
</bodyText>
<page confidence="0.999453">
466
</page>
<figureCaption confidence="0.9179105">
Figure 1: Modification of “O” (other labels) to
transfer information on a preceding named entity.
</figureCaption>
<bodyText confidence="0.999983903846154">
information about the previous state (Finkel et al.,
2005). For example, consider the sentence “... in-
cluding Sp1 and CP1.” where the correct labels of
“Sp1” and “CP1” are both “protein”. It would be
useful if the model could utilize the (non-adjacent)
information about “Sp1” being “protein” to clas-
sify “CP1” as “protein”. On the other hand, in-
formation about adjacent labels does not necessar-
ily provide useful information because, in many
cases, the previous label of a named entity is “O”,
which indicates a non-named entity. For 98.0% of
the named entities in the training data of the shared
task in the 2004 JNLPBA, the label of the preced-
ing entity was “O”.
In order to incorporate such non-local informa-
tion into semi-CRFs, we take a simple approach.
We divide the label of “O” into “O-protein” and
“O” so that they convey the information on the
preceding named entity. Figure 1 shows an ex-
ample of this conversion, in which the two labels
for the third and fourth states are converted from
“O” to “O-protein”. When we define the fea-
tures for the fifth state, we can use the informa-
tion on the preceding entity “protein” by look-
ing at the fourth state. Since this modification
changes only the label set, we can do this within
the framework of semi-CRF models. This idea is
originally proposed in (Peshkin and Pfeffer, 2003).
However, they used a dynamic Bayesian network
(DBNs) rather than a semi-CRF, and semi-CRFs
are likely to have significantly better performance
than DBNs.
In previous work, such non-local information
has usually been employed at a post-processing
stage. This is because the use of long distance
dependency violates the locality of the model and
prevents us from using dynamic programming
techniques in training and inference. Skip-CRFs
(Sutton and McCallum, 2004) are a direct imple-
mentation of long distance effects to the model.
However, they need to determine the structure
for propagating non-local information in advance.
In a recent study by Finkel et al., (2005), non-
local information is encoded using an indepen-
dence model, and the inference is performed by
Gibbs sampling, which enables us to use a state-
of-the-art factored model and carry out training ef-
ficiently, but inference still incurs a considerable
computational cost. Since our model handles lim-
ited type of non-local information, i.e. the label
of the preceding entity, the model can be solved
without approximation.
</bodyText>
<sectionHeader confidence="0.958303" genericHeader="method">
4 Reduction of Training/Inference Cost
</sectionHeader>
<bodyText confidence="0.999994740740741">
The straightforward implementation of this mod-
eling in semi-CRFs often results in a prohibitive
computational cost.
In biomedical documents, there are quite a few
entity names which consist of many words (names
of 8 words in length are not rare). This makes
it difficult for us to use semi-CRFs for biomedi-
cal NER, because we have to set L to be eight or
larger, where L is the upper bound of the length of
possible chunks in semi-CRFs. Moreover, in or-
der to take into account the dependency between
named entities of different classes appearing in a
sentence, we need to incorporate multiple labels
into a single probabilistic model. For example, in
the shared task in COLING 2004 JNLPBA (Kim
et al., 2004) the number of labels is six (“pro-
tein”, “DNA”, “RNA”, “cell line”, “cell type”
and “other”). This also increases the computa-
tional cost of a semi-CRF model.
To reduce the computational cost, we propose
two methods (see Figure 2). The first is employing
a filtering process using a lightweight classifier to
remove unnecessary state candidates beforehand
(Figure 2 (2)), and the second is the using the fea-
ture forest model (Miyao and Tsujii, 2002) (Fig-
ure 2 (3)), which employs dynamic programming
at training “as much as possible”.
</bodyText>
<subsectionHeader confidence="0.999166">
4.1 Filtering with a naive Bayes classifier
</subsectionHeader>
<bodyText confidence="0.999954">
We introduce a filtering process to remove low
probability candidate states. This is the first step
of our NER system. After this filtering step, we
construct semi-CRFs on the remaining candidate
states using a feature forest. Therefore the aim of
this filtering is to reduce the number of candidate
states, without removing correct entities. This idea
</bodyText>
<page confidence="0.998375">
467
</page>
<figureCaption confidence="0.988638">
Figure 2: The framework of our system. We first enumerate all possible candidate states, and then filter
out low probability states by using a light-weight classifier, and represent them by using feature forest.
</figureCaption>
<table confidence="0.999547142857143">
Feature Name Example of Features
Start/End Word ws, we
Inside Word ws, ws+1, ... , we
Context Word ws_1, we+1
Start/End SP sps, spe
Inside SP sps, sps+1, ..., spe
Context SP sps_1, spe+1
</table>
<tableCaption confidence="0.903412">
Table 2: Features used in the naive Bayes Classi-
</tableCaption>
<bodyText confidence="0.994193166666667">
fier for the entity candidate: ws, ws+1, ..., we. spz
is the result of shallow parsing at wz.
is similar to the method proposed by Tsuruoka and
Tsujii (2005) for chunk parsing, in which implau-
sible phrase candidates are removed beforehand.
We construct a binary naive Bayes classifier us-
ing the same training data as those for semi-CRFs.
In training and inference, we enumerate all possi-
ble chunks (the max length of a chunk is L as for
semi-CRFs) and then classify those into “entity”
or “other”. Table 2 lists the features used in the
naive Bayes classifier. This process can be per-
formed independently of semi-CRFs
Since the purpose of the filtering is to reduce the
computational cost, rather than to achieve a good
F-score by itself, we chose the threshold probabil-
ity of filtering so that the recall of filtering results
would be near 100 %.
</bodyText>
<subsectionHeader confidence="0.915387">
4.2 Feature Forest
</subsectionHeader>
<bodyText confidence="0.992319142857143">
In estimating semi-CRFs, we can use an efficient
dynamic programming algorithm, which is simi-
lar to the forward-backward algorithm (Sarawagi
and Cohen, 2004). The proposal here is a more
general framework for estimating sequential con-
ditional random fields.
This framework is based on the feature forest
</bodyText>
<figureCaption confidence="0.999569">
Figure 3: Example of feature forest representation
of linear chain CRFs. Feature functions are as-
signed to “and” nodes.
Figure 4: Example of packed representation of
</figureCaption>
<bodyText confidence="0.925238777777778">
semi-CRFs. The states that have the same end po-
sition and prev-entity label are packed.
model, which was originally proposed for disam-
biguation models for parsing (Miyao and Tsujii,
2002). A feature forest model is a maximum en-
tropy model defined overfeature forests, which are
abstract representations of an exponential number
of sequence/tree structures. A feature forest is
an “and/or” graph: in Figure 3, circles represent
</bodyText>
<page confidence="0.997829">
468
</page>
<bodyText confidence="0.999708346153846">
“and” nodes (conjunctive nodes), while boxes de-
note “or” nodes (disjunctive nodes). Feature func-
tions are assigned to “and” nodes. We can use
the information of the previous “and” node for de-
signing the feature functions through the previous
“or” node. Each sequence in a feature forest is
obtained by choosing a conjunctive node for each
disjunctive node. For example, Figure 3 represents
3 x 3 = 9 sequences, since each disjunctive node
has three candidates. It should be noted that fea-
ture forests can represent an exponential number
of sequences with a polynomial number of con-
junctive/disjunctive nodes.
One can estimate a maximum entropy model for
the whole sequence with dynamic programming
by representing the probabilistic events, i.e. se-
quence of named entity tags, by feature forests
(Miyao and Tsujii, 2002).
In the previous work (Lafferty et al., 2001;
Sarawagi and Cohen, 2004), “or” nodes are con-
sidered implicitly in the dynamic programming
framework. In feature forest models, “or” nodes
are packed when they have same conditions. For
example, “or” nodes are packed when they have
same end positions and same labels in the first or-
der semi-CRFs,
In general, we can pack different “or” nodes that
yield equivalent feature functions in the follow-
ing nodes. In other words, “or” nodes are packed
when the following states use partial information
on the preceding states. Consider the task of tag-
ging entity and O-entity, where the latter tag is ac-
tually O tags that distinguish the preceding named
entity tags. When we simply apply first-order
semi-CRFs, we must distinguish states that have
different previous states. However, when we want
to distinguish only the preceding named entity tags
rather than the immediate previous states, feature
forests can represent these events more compactly
(Figure 4). We can implement this as follows. In
each “or” node, we generate the following “and”
nodes and their feature functions. Then we check
whether there exist “or” node which has same con-
ditions by using its information about “end posi-
tion” and “previous entity”. If so, we connect the
“and” node to the corresponding “or” node. If not,
we generate a new “or” node and continue the pro-
cess.
Since the states with label O-entity and entity
are packed, the computational cost of training in
our model (First order semi-CRFs) becomes the
half of the original one.
</bodyText>
<sectionHeader confidence="0.999777" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<subsectionHeader confidence="0.997592">
5.1 Experimental Setting
</subsectionHeader>
<bodyText confidence="0.999927315789474">
Our experiments were performed on the training
and evaluation set provided by the shared task in
COLING 2004 JNLPBA (Kim et al., 2004). The
training data used in this shared task came from
the GENIA version 3.02 corpus. In the task there
are five semantic labels: protein, DNA, RNA,
cell line and cell type. The training set consists
of 2000 abstracts from MEDLINE, and the evalu-
ation set consists of 404 abstracts. We divided the
original training set into 1800 abstracts and 200
abstracts, and the former was used as the training
data and the latter as the development data. For
semi-CRFs, we used amis3 for training the semi-
CRF with feature-forest. We used GENIA taggar4
for POS-tagging and shallow parsing.
We set L = 10 for training and evaluation when
we do not state L explicitly, where L is the upper
bound of the length of possible chunks in semi-
CRFs.
</bodyText>
<subsectionHeader confidence="0.941859">
5.2 Features
</subsectionHeader>
<bodyText confidence="0.999977">
Table 3 lists the features used in our semi-CRFs.
We describe the chunk-dependent features in de-
tail, which cannot be encoded in token-level fea-
tures.
“Whole chunk” is the normalized names at-
tached to a chunk, which performs like the closed
dictionary. “Length” and “Length and End-
Word” capture the tendency of the length of a
named entity. “Count feature” captures the ten-
dency for named entities to appear repeatedly in
the same sentence.
“Preceding Entity and Prev Word” are fea-
tures that capture specifically words for conjunc-
tions such as “and” or “, (comma)”, e.g., for the
phrase “OCIM1 and K562”, both “OCIM1” and
“K562” are assigned cell line labels. Even if
the model can determine only that “OCIM1” is a
cell line , this feature helps “K562” to be assigned
the label cell line.
</bodyText>
<subsectionHeader confidence="0.800641">
5.3 Results
</subsectionHeader>
<bodyText confidence="0.9738135">
We first evaluated the filtering performance. Table
4 shows the result of the filtering on the training
</bodyText>
<footnote confidence="0.903129">
3http://www-tsujii.is.s.u-tokyo.ac.jp/auris/
4http://www-tsujii.is.s.u-tokyo.ac.jp/GENIA/tagger/
Note that the evaluation data are not used for training the GE-
NIA tagger.
</footnote>
<page confidence="0.999487">
469
</page>
<tableCaption confidence="0.858744">
Table 3: Feature templates used for the chunk s := ws ws+1 ... we where ws and we represent the words
at the beginning and ending of the target chunk respectively. pi is the part of speech tag of wi and sci is
the shallow parse result of wi.
</tableCaption>
<table confidence="0.999939153846154">
Feature Name description of features
Non-Chunk Features
Word/POS/SC with Position BEGIN + ws, END + we, IN + ws+1, ..., IN + we−1, BEGIN + ps,...
Context Uni-gram/Bi-gram ws−1, we+1, ws−2 + ws−1, we+1 + we+2, ws−1 + we+1
Prefix/Suffix of Chunk 2/3-gram character prefix of ws, 2/3/4-gram character suffix of we
Orthography capitalization and word formation of ws...we
Chunk Features
Whole chunk ws + ws+1 + ... + we
Word/POS/SC End Bi-grams we−1 + we, pe−1 + pe, sce−1 + sce
Length, Length and End Word |s|, Isl+we
Count Feature the frequency of wsws+1..we in a sentence is greater than one
Preceding Entity Features
Preceding Entity /and Prev Word PrevState, PrevState + ws−1
</table>
<tableCaption confidence="0.984753">
Table 4: Filtering results using the naive Bayes
</tableCaption>
<bodyText confidence="0.792891333333333">
classifier. The number of entity candidates for the
training set was 4179662, and that of the develop-
ment set was 418628.
</bodyText>
<table confidence="0.992332125">
Training set
Threshold probability reduction ratio recall
1.0 x 10−12 0.14 0.984
1.0 x 10−15 0.20 0.993
Development set
Threshold probability reduction ratio recall
1.0 x 10−12 0.14 0.985
1.0 x 10−15 0.20 0.994
</table>
<bodyText confidence="0.999936166666667">
and evaluation data. The naive Bayes classifiers
effectively reduced the number of candidate states
with very few falsely removed correct entities.
We then examined the effect of filtering on the
final performance. In this experiment, we could
not examine the performance without filtering us-
ing all the training data, because training on all
the training data without filtering required much
larger memory resources (estimated to be about
80G Byte) than was possible for our experimental
setup. We thus compared the result of the recog-
nizers with and without filtering using only 2000
sentences as the training data. Table 5 shows the
result of the total system with different filtering
thresholds. The result indicates that the filtering
method achieved very well without decreasing the
overall performance.
We next evaluate the effect of filtering, chunk
information and non-local information on final
performance. Table 6 shows the performance re-
sult for the recognition task. L means the upper
bound of the length of possible chunks in semi-
CRFs. We note that we cannot examine the re-
sult of L = 10 without filtering because of the in-
tractable computational cost. The row “w/o Chunk
Feature” shows the result of the system which does
not employ Chunk-Features in Table 3 at training
and inference. The row “Preceding Entity” shows
the result of a system which uses Preceding En-
tity and Preceding Entity and Prev Word fea-
tures. The results indicate that the chunk features
contributed to the performance, and the filtering
process enables us to use full chunk representation
(L = 10). The results of McNemar’s test suggest
that the system with chunk features is significantly
better than the system without it (the p-value is
less than 1.0 &lt; 10−4). The result of the preceding
entity information improves the performance. On
the other hand, the system with preceding infor-
mation is not significantly better than the system
without its. Other non-local information may im-
prove performance with our framework and this is
a topic for future work.
Table 7 shows the result of the overall perfor-
mance in our best setting, which uses the infor-
mation about the preceding entity and 1.0 x 10−15
threshold probability for filtering. We note that the
result of our system is similar to those of other sys-
</bodyText>
<footnote confidence="0.823563666666667">
5The result of the classifier on development data is 74.64
(without preceding information) and 75.14 (with preceding
information).
</footnote>
<page confidence="0.997906">
470
</page>
<tableCaption confidence="0.979634">
Table 5: Performance with filtering on the development data. (&lt; 1.0 x 10−12) means the threshold
probability of the filtering is 1.0 x 10−12.
</tableCaption>
<table confidence="0.999885222222222">
Recall Precision F-score Memory Usage (MB) Training Time (s)
Small Training Data = 2000 sentences
Without filtering 65.77 72.80 69.10 4238 7463
Filtering (&lt; 1.0 x 10.0−12) 64.22 70.62 67.27 600 1080
Filtering (&lt; 1.0 x 10.0−15) 65.34 72.52 68.74 870 2154
All Training Data = 16713 sentences
Without filtering Not available Not available
Filtering (&lt; 1.0 x 10.0−12) 70.05 76.06 72.93 10444 14661
Filtering (&lt; 1.0 x 10.0−15) 72.09 78.47 75.14 15257 31636
</table>
<tableCaption confidence="0.99453">
Table 6: Overall performance on the evaluation set. L is the upper bound of the length of possible chunks
in semi-CRFs.
</tableCaption>
<table confidence="0.988465">
Recall Precision F-score
L &lt; 5 64.33 65.51 64.92
L = 10 + Filtering (&lt; 1.0 x 10.0−12) 70.87 68.33 69.58
L = 10 + Filtering (&lt; 1.0 x 10.0−15) 72.59 70.16 71.36
w/o Chunk Feature 70.53 69.92 70.22
+ Preceding Entity 72.65 70.35 71.48
</table>
<bodyText confidence="0.99920452">
tems in several respects, that is, the performance of
cell line is not good, and the performance of the
right boundary identification (78.91% in F-score)
is better than that of the left boundary identifica-
tion (75.19% in F-score).
Table 8 shows a comparison between our sys-
tem and other state-of-the-art systems. Our sys-
tem has achieved a comparable performance to
these systems and would be still improved by us-
ing external resources or conducting pre/post pro-
cessing. For example, Zhou et. al (2004) used
post processing, abbreviation resolution and exter-
nal dictionary, and reported that they improved F-
score by 3.1%, 2.1% and 1.2% respectively. Kim
et. al (2005) used the original GENIA corpus
to employ the information about other semantic
classes for identifying term boundaries. Finkel
et. al (2004) used gazetteers, web-querying, sur-
rounding abstracts, and frequency counts from
the BNC corpus. Settles (2004) used seman-
tic domain knowledge of 17 types of lexicon.
Since our approach and the use of external re-
sources/knowledge do not conflict but are com-
plementary, examining the combination of those
techniques should be an interesting research topic.
</bodyText>
<tableCaption confidence="0.976625">
Table 7: Performance of our system on the evalu-
ation set
</tableCaption>
<table confidence="0.999778857142857">
Class Recall Precision F-score
protein 77.74 68.92 73.07
DNA 69.03 70.16 69.59
RNA 69.49 67.21 68.33
cell type 65.33 82.19 72.80
cell line 57.60 53.14 55.28
overall 72.65 70.35 71.48
</table>
<tableCaption confidence="0.999498">
Table 8: Comparison with other systems
</tableCaption>
<table confidence="0.999592333333333">
System Recall Precision F-score
Zhou et. al (2004) 75.99 69.42 72.55
Our system 72.65 70.35 71.48
Kim et.al (2005) 72.77 69.68 71.19
Finkel et. al (2004) 68.56 71.62 70.06
Settles (2004) 70.3 69.3 69.8
</table>
<page confidence="0.996493">
471
</page>
<sectionHeader confidence="0.999366" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999978222222222">
In this paper, we have proposed a single proba-
bilistic model that can capture important charac-
teristics of biomedical named entities. To over-
come the prohibitive computational cost, we have
presented an efficient training framework and a fil-
tering method which enabled us to apply first or-
der semi-CRF models to sentences having many
labels and entities with long names. Our results
showed that our filtering method works very well
without decreasing the overall performance. Our
system achieved an F-score of 71.48% without the
use of gazetteers, post-processing or external re-
sources. The performance of our system came
close to that of the current best performing system
which makes extensive use of external resources
and rule based post-processing.
The contribution of the non-local information
introduced by our method was not significant in
the experiments. However, other types of non-
local information have also been shown to be ef-
fective (Finkel et al., 2005) and we will examine
the effectiveness of other non-local information
which can be embedded into label information.
As the next stage of our research, we hope to ap-
ply our method to shallow parsing, in which seg-
ments tend to be long and non-local information is
important.
</bodyText>
<sectionHeader confidence="0.999551" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99994101754386">
Daniel M. Bikel, Richard Schwartz, and Ralph
Weischedel. 1997. Nymble: a high-performance
learning name-finder. In Proc. of the Fifth Confer-
ence on Applied Natural Language Processing.
Jenny Finkel, Shipra Dingare, Huy Nguyen, Malv-
ina Nissim, Gail Sinclair, and Christopher Man-
ning. 2004. Exploiting context for biomedical en-
tity recognition: From syntax to the web. In Proc. of
JNLPBA-04.
Jenny Rose Finkel, Trond Grenager, and Christopher
Manning. 2005. Incorporating non-local informa-
tion into information extraction systems by Gibbs
sampling. In Proc. ofACL 2005, pages 363–370.
Jin-Dong Kim, Tomoko Ohta, Yoshimasa Tsuruoka,
Yuka Tateisi, and Nigel Collier. 2004. Introduc-
tion to the bio-entity recognition task at JNLPBA.
In Proc. ofJNLPBA-04, pages 70–75.
Seonho Kim, Juntae Yoon, Kyung-Mi Park, and Hae-
Chang Rim. 2005. Two-phase biomedical named
entity recognition using a hybrid method. In Proc. of
the Second International Joint Conference on Natu-
ral Language Processing (IJCNLP-05).
Zhenzhen Kou, William W. Cohen, and Robert F. Mur-
phy. 2005. High-recall protein entity recognition
using a dictionary. Bioinformatics 2005 21.
Micahel Krauthammer and Goran Nenadic. 2004.
Term identification in the biomedical literature. Jor-
nal ofBiomedical Informatics.
John Lafferty, Andrew McCallum, and Fernando
Pereira. 2001. Conditional random fields: Prob-
abilistic models for segmenting and labeling se-
quence data. In Proc. ofICML 2001.
Yusuke Miyao and Jun’ichi Tsujii. 2002. Maximum
entropy estimation for feature forests. In Proc. of
HLT 2002.
Peshkin and Pfeffer. 2003. Bayesian information ex-
traction network. In IJCAI.
Sunita Sarawagi and William W. Cohen. 2004. Semi-
markov conditional random fields for information
extraction. In NIPS 2004.
Burr Settles. 2004. Biomedical named entity recogni-
tion using conditional random fields and rich feature
sets. In Proc. ofJNLPBA-04.
Beth M. Sundheim. 1995. Overview of results of the
MUC-6 evaluation. In Sixth Message Understand-
ing Conference (MUC-6), pages 13–32.
Charles Sutton and Andrew McCallum. 2004. Collec-
tive segmentation and labeling of distant entities in
information extraction. In ICML workshop on Sta-
tistical Relational Learning.
Yoshimasa Tsuruoka and Jun’ichi Tsujii. 2005. Chunk
parsing revisited. In Proceedings of the 9th Inter-
national Workshop on Parsing Technologies (IWPT
2005).
GuoDong Zhou and Jian Su. 2004. Exploring deep
knowledge resources in biomedical name recogni-
tion. In Proc. ofJNLPBA-04.
</reference>
<page confidence="0.998501">
472
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.556615">
<title confidence="0.9858035">Improving the Scalability of Semi-Markov Conditional Random Fields for Named Entity Recognition</title>
<author confidence="0.927831">Tsuruoka</author>
<affiliation confidence="0.981507">of Computer Science, University of Tokyo</affiliation>
<address confidence="0.926484">Hongo 7-3-1, Bunkyo-ku, Tokyo, Japan</address>
<affiliation confidence="0.950333">of Informatics, University of Manchester</affiliation>
<address confidence="0.964278">POBox 88, Sackville St, MANCHESTER M60 1QD, UK</address>
<affiliation confidence="0.782422">Solution Oriented Research for Science and Technology</affiliation>
<address confidence="0.850293">Honcho 4-1-8, Kawaguchi-shi, Saitama, Japan</address>
<abstract confidence="0.991045909090909">This paper presents techniques to apply semi-CRFs to Named Entity Recognition tasks with a tractable computational cost. Our framework can handle an NER task that has long named entities and many labels which increase the computational cost. To reduce the computational cost, we propose two techniques: the first is the use of feature forests, which enables us to pack feature-equivalent states, and the sec-</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Daniel M Bikel</author>
<author>Richard Schwartz</author>
<author>Ralph Weischedel</author>
</authors>
<title>Nymble: a high-performance learning name-finder.</title>
<date>1997</date>
<booktitle>In Proc. of the Fifth Conference on Applied Natural Language Processing.</booktitle>
<contexts>
<context position="2374" citStr="Bikel et al., 1997" startWordPosition="359" endWordPosition="362">complex tasks such as relation extraction and knowledge mining. Biomedical NER (Bio-NER) tasks are, in general, more difficult than ones in the news domain. For example, the best F-score in the shared task of Bio-NER in COLING 2004 JNLPBA (Kim et al., 2004) was 72.55% (Zhou and Su, 2004) 1, whereas the best performance at MUC-6, in which systems tried to identify general named entities such as person or organization names, was an accuracy of 95% (Sundheim, 1995). Many of the previous studies of Bio-NER tasks have been based on machine learning techniques including Hidden Markov Models (HMMs) (Bikel et al., 1997), the dictionary HMM model (Kou et al., 2005) and Maximum Entropy Markov Models (MEMMs) (Finkel et al., 2004). Among these methods, conditional random fields (CRFs) (Lafferty et al., 2001) have achieved good results (Kim et al., 2005; Settles, 2004), presumably because they are free from the so-called label bias problem by using a global normalization. Sarawagi and Cohen (2004) have recently introduced semi-Markov conditional random fields (semi-CRFs). They are defined on semi-Markov chains and attach labels to the subsequences of a sentence, rather than to the tokens2. The semiMarkov formulat</context>
</contexts>
<marker>Bikel, Schwartz, Weischedel, 1997</marker>
<rawString>Daniel M. Bikel, Richard Schwartz, and Ralph Weischedel. 1997. Nymble: a high-performance learning name-finder. In Proc. of the Fifth Conference on Applied Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny Finkel</author>
<author>Shipra Dingare</author>
<author>Huy Nguyen</author>
<author>Malvina Nissim</author>
<author>Gail Sinclair</author>
<author>Christopher Manning</author>
</authors>
<title>Exploiting context for biomedical entity recognition: From syntax to the web. In</title>
<date>2004</date>
<booktitle>Proc. of JNLPBA-04.</booktitle>
<contexts>
<context position="2483" citStr="Finkel et al., 2004" startWordPosition="378" endWordPosition="381">al, more difficult than ones in the news domain. For example, the best F-score in the shared task of Bio-NER in COLING 2004 JNLPBA (Kim et al., 2004) was 72.55% (Zhou and Su, 2004) 1, whereas the best performance at MUC-6, in which systems tried to identify general named entities such as person or organization names, was an accuracy of 95% (Sundheim, 1995). Many of the previous studies of Bio-NER tasks have been based on machine learning techniques including Hidden Markov Models (HMMs) (Bikel et al., 1997), the dictionary HMM model (Kou et al., 2005) and Maximum Entropy Markov Models (MEMMs) (Finkel et al., 2004). Among these methods, conditional random fields (CRFs) (Lafferty et al., 2001) have achieved good results (Kim et al., 2005; Settles, 2004), presumably because they are free from the so-called label bias problem by using a global normalization. Sarawagi and Cohen (2004) have recently introduced semi-Markov conditional random fields (semi-CRFs). They are defined on semi-Markov chains and attach labels to the subsequences of a sentence, rather than to the tokens2. The semiMarkov formulation allows one to easily construct entity-level features. Since the features can capture all the characterist</context>
</contexts>
<marker>Finkel, Dingare, Nguyen, Nissim, Sinclair, Manning, 2004</marker>
<rawString>Jenny Finkel, Shipra Dingare, Huy Nguyen, Malvina Nissim, Gail Sinclair, and Christopher Manning. 2004. Exploiting context for biomedical entity recognition: From syntax to the web. In Proc. of JNLPBA-04.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny Rose Finkel</author>
<author>Trond Grenager</author>
<author>Christopher Manning</author>
</authors>
<title>Incorporating non-local information into information extraction systems by Gibbs sampling.</title>
<date>2005</date>
<booktitle>In Proc. ofACL</booktitle>
<pages>363--370</pages>
<contexts>
<context position="8061" citStr="Finkel et al., 2005" startWordPosition="1339" endWordPosition="1342">N) where L is the upper bound length of entities, N is the length of sentence and K is the number of label set. If we use previous label information, the cost becomes O(K2LN). 3 Using Non-Local Information in Semi-CRFs In conventional CRFs and semi-CRFs, one can only use the information on the adjacent previous label when defining the features on a certain state or entity. In NER tasks, however, information about a distant entity is often more useful than 466 Figure 1: Modification of “O” (other labels) to transfer information on a preceding named entity. information about the previous state (Finkel et al., 2005). For example, consider the sentence “... including Sp1 and CP1.” where the correct labels of “Sp1” and “CP1” are both “protein”. It would be useful if the model could utilize the (non-adjacent) information about “Sp1” being “protein” to classify “CP1” as “protein”. On the other hand, information about adjacent labels does not necessarily provide useful information because, in many cases, the previous label of a named entity is “O”, which indicates a non-named entity. For 98.0% of the named entities in the training data of the shared task in the 2004 JNLPBA, the label of the preceding entity w</context>
<context position="10006" citStr="Finkel et al., (2005)" startWordPosition="1665" endWordPosition="1668">DBNs) rather than a semi-CRF, and semi-CRFs are likely to have significantly better performance than DBNs. In previous work, such non-local information has usually been employed at a post-processing stage. This is because the use of long distance dependency violates the locality of the model and prevents us from using dynamic programming techniques in training and inference. Skip-CRFs (Sutton and McCallum, 2004) are a direct implementation of long distance effects to the model. However, they need to determine the structure for propagating non-local information in advance. In a recent study by Finkel et al., (2005), nonlocal information is encoded using an independence model, and the inference is performed by Gibbs sampling, which enables us to use a stateof-the-art factored model and carry out training efficiently, but inference still incurs a considerable computational cost. Since our model handles limited type of non-local information, i.e. the label of the preceding entity, the model can be solved without approximation. 4 Reduction of Training/Inference Cost The straightforward implementation of this modeling in semi-CRFs often results in a prohibitive computational cost. In biomedical documents, th</context>
</contexts>
<marker>Finkel, Grenager, Manning, 2005</marker>
<rawString>Jenny Rose Finkel, Trond Grenager, and Christopher Manning. 2005. Incorporating non-local information into information extraction systems by Gibbs sampling. In Proc. ofACL 2005, pages 363–370.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jin-Dong Kim</author>
<author>Tomoko Ohta</author>
<author>Yoshimasa Tsuruoka</author>
<author>Yuka Tateisi</author>
<author>Nigel Collier</author>
</authors>
<title>Introduction to the bio-entity recognition task at JNLPBA.</title>
<date>2004</date>
<booktitle>In Proc. ofJNLPBA-04,</booktitle>
<pages>70--75</pages>
<contexts>
<context position="2012" citStr="Kim et al., 2004" startWordPosition="300" endWordPosition="303">1.48% on the JNLPBA 2004 shared task without using any external resources or post-processing techniques. 1 Introduction The rapid increase of information in the biomedical domain has emphasized the need for automated information extraction techniques. In this paper we focus on the Named Entity Recognition (NER) task, which is the first step in tackling more complex tasks such as relation extraction and knowledge mining. Biomedical NER (Bio-NER) tasks are, in general, more difficult than ones in the news domain. For example, the best F-score in the shared task of Bio-NER in COLING 2004 JNLPBA (Kim et al., 2004) was 72.55% (Zhou and Su, 2004) 1, whereas the best performance at MUC-6, in which systems tried to identify general named entities such as person or organization names, was an accuracy of 95% (Sundheim, 1995). Many of the previous studies of Bio-NER tasks have been based on machine learning techniques including Hidden Markov Models (HMMs) (Bikel et al., 1997), the dictionary HMM model (Kou et al., 2005) and Maximum Entropy Markov Models (MEMMs) (Finkel et al., 2004). Among these methods, conditional random fields (CRFs) (Lafferty et al., 2001) have achieved good results (Kim et al., 2005; Set</context>
<context position="11170" citStr="Kim et al., 2004" startWordPosition="1859" endWordPosition="1862">itive computational cost. In biomedical documents, there are quite a few entity names which consist of many words (names of 8 words in length are not rare). This makes it difficult for us to use semi-CRFs for biomedical NER, because we have to set L to be eight or larger, where L is the upper bound of the length of possible chunks in semi-CRFs. Moreover, in order to take into account the dependency between named entities of different classes appearing in a sentence, we need to incorporate multiple labels into a single probabilistic model. For example, in the shared task in COLING 2004 JNLPBA (Kim et al., 2004) the number of labels is six (“protein”, “DNA”, “RNA”, “cell line”, “cell type” and “other”). This also increases the computational cost of a semi-CRF model. To reduce the computational cost, we propose two methods (see Figure 2). The first is employing a filtering process using a lightweight classifier to remove unnecessary state candidates beforehand (Figure 2 (2)), and the second is the using the feature forest model (Miyao and Tsujii, 2002) (Figure 2 (3)), which employs dynamic programming at training “as much as possible”. 4.1 Filtering with a naive Bayes classifier We introduce a filteri</context>
<context position="16869" citStr="Kim et al., 2004" startWordPosition="2795" endWordPosition="2798">ctions. Then we check whether there exist “or” node which has same conditions by using its information about “end position” and “previous entity”. If so, we connect the “and” node to the corresponding “or” node. If not, we generate a new “or” node and continue the process. Since the states with label O-entity and entity are packed, the computational cost of training in our model (First order semi-CRFs) becomes the half of the original one. 5 Experiments 5.1 Experimental Setting Our experiments were performed on the training and evaluation set provided by the shared task in COLING 2004 JNLPBA (Kim et al., 2004). The training data used in this shared task came from the GENIA version 3.02 corpus. In the task there are five semantic labels: protein, DNA, RNA, cell line and cell type. The training set consists of 2000 abstracts from MEDLINE, and the evaluation set consists of 404 abstracts. We divided the original training set into 1800 abstracts and 200 abstracts, and the former was used as the training data and the latter as the development data. For semi-CRFs, we used amis3 for training the semiCRF with feature-forest. We used GENIA taggar4 for POS-tagging and shallow parsing. We set L = 10 for train</context>
</contexts>
<marker>Kim, Ohta, Tsuruoka, Tateisi, Collier, 2004</marker>
<rawString>Jin-Dong Kim, Tomoko Ohta, Yoshimasa Tsuruoka, Yuka Tateisi, and Nigel Collier. 2004. Introduction to the bio-entity recognition task at JNLPBA. In Proc. ofJNLPBA-04, pages 70–75.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Seonho Kim</author>
<author>Juntae Yoon</author>
<author>Kyung-Mi Park</author>
<author>HaeChang Rim</author>
</authors>
<title>Two-phase biomedical named entity recognition using a hybrid method.</title>
<date>2005</date>
<booktitle>In Proc. of the Second International Joint Conference on Natural Language Processing (IJCNLP-05).</booktitle>
<contexts>
<context position="2607" citStr="Kim et al., 2005" startWordPosition="398" endWordPosition="401">BA (Kim et al., 2004) was 72.55% (Zhou and Su, 2004) 1, whereas the best performance at MUC-6, in which systems tried to identify general named entities such as person or organization names, was an accuracy of 95% (Sundheim, 1995). Many of the previous studies of Bio-NER tasks have been based on machine learning techniques including Hidden Markov Models (HMMs) (Bikel et al., 1997), the dictionary HMM model (Kou et al., 2005) and Maximum Entropy Markov Models (MEMMs) (Finkel et al., 2004). Among these methods, conditional random fields (CRFs) (Lafferty et al., 2001) have achieved good results (Kim et al., 2005; Settles, 2004), presumably because they are free from the so-called label bias problem by using a global normalization. Sarawagi and Cohen (2004) have recently introduced semi-Markov conditional random fields (semi-CRFs). They are defined on semi-Markov chains and attach labels to the subsequences of a sentence, rather than to the tokens2. The semiMarkov formulation allows one to easily construct entity-level features. Since the features can capture all the characteristics of a subsequence, we can use, for example, a dictionary feature which measures the similarity between a candidate segmen</context>
</contexts>
<marker>Kim, Yoon, Park, Rim, 2005</marker>
<rawString>Seonho Kim, Juntae Yoon, Kyung-Mi Park, and HaeChang Rim. 2005. Two-phase biomedical named entity recognition using a hybrid method. In Proc. of the Second International Joint Conference on Natural Language Processing (IJCNLP-05).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhenzhen Kou</author>
<author>William W Cohen</author>
<author>Robert F Murphy</author>
</authors>
<title>High-recall protein entity recognition using a dictionary. Bioinformatics</title>
<date>2005</date>
<pages>21</pages>
<contexts>
<context position="2419" citStr="Kou et al., 2005" startWordPosition="367" endWordPosition="370">nowledge mining. Biomedical NER (Bio-NER) tasks are, in general, more difficult than ones in the news domain. For example, the best F-score in the shared task of Bio-NER in COLING 2004 JNLPBA (Kim et al., 2004) was 72.55% (Zhou and Su, 2004) 1, whereas the best performance at MUC-6, in which systems tried to identify general named entities such as person or organization names, was an accuracy of 95% (Sundheim, 1995). Many of the previous studies of Bio-NER tasks have been based on machine learning techniques including Hidden Markov Models (HMMs) (Bikel et al., 1997), the dictionary HMM model (Kou et al., 2005) and Maximum Entropy Markov Models (MEMMs) (Finkel et al., 2004). Among these methods, conditional random fields (CRFs) (Lafferty et al., 2001) have achieved good results (Kim et al., 2005; Settles, 2004), presumably because they are free from the so-called label bias problem by using a global normalization. Sarawagi and Cohen (2004) have recently introduced semi-Markov conditional random fields (semi-CRFs). They are defined on semi-Markov chains and attach labels to the subsequences of a sentence, rather than to the tokens2. The semiMarkov formulation allows one to easily construct entity-lev</context>
</contexts>
<marker>Kou, Cohen, Murphy, 2005</marker>
<rawString>Zhenzhen Kou, William W. Cohen, and Robert F. Murphy. 2005. High-recall protein entity recognition using a dictionary. Bioinformatics 2005 21.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Micahel Krauthammer</author>
<author>Goran Nenadic</author>
</authors>
<date>2004</date>
<booktitle>Term identification in the biomedical literature. Jornal ofBiomedical Informatics.</booktitle>
<marker>Krauthammer, Nenadic, 2004</marker>
<rawString>Micahel Krauthammer and Goran Nenadic. 2004. Term identification in the biomedical literature. Jornal ofBiomedical Informatics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In</title>
<date>2001</date>
<booktitle>Proc. ofICML</booktitle>
<contexts>
<context position="2562" citStr="Lafferty et al., 2001" startWordPosition="389" endWordPosition="393">e in the shared task of Bio-NER in COLING 2004 JNLPBA (Kim et al., 2004) was 72.55% (Zhou and Su, 2004) 1, whereas the best performance at MUC-6, in which systems tried to identify general named entities such as person or organization names, was an accuracy of 95% (Sundheim, 1995). Many of the previous studies of Bio-NER tasks have been based on machine learning techniques including Hidden Markov Models (HMMs) (Bikel et al., 1997), the dictionary HMM model (Kou et al., 2005) and Maximum Entropy Markov Models (MEMMs) (Finkel et al., 2004). Among these methods, conditional random fields (CRFs) (Lafferty et al., 2001) have achieved good results (Kim et al., 2005; Settles, 2004), presumably because they are free from the so-called label bias problem by using a global normalization. Sarawagi and Cohen (2004) have recently introduced semi-Markov conditional random fields (semi-CRFs). They are defined on semi-Markov chains and attach labels to the subsequences of a sentence, rather than to the tokens2. The semiMarkov formulation allows one to easily construct entity-level features. Since the features can capture all the characteristics of a subsequence, we can use, for example, a dictionary feature which measu</context>
<context position="15184" citStr="Lafferty et al., 2001" startWordPosition="2517" endWordPosition="2520">or” node. Each sequence in a feature forest is obtained by choosing a conjunctive node for each disjunctive node. For example, Figure 3 represents 3 x 3 = 9 sequences, since each disjunctive node has three candidates. It should be noted that feature forests can represent an exponential number of sequences with a polynomial number of conjunctive/disjunctive nodes. One can estimate a maximum entropy model for the whole sequence with dynamic programming by representing the probabilistic events, i.e. sequence of named entity tags, by feature forests (Miyao and Tsujii, 2002). In the previous work (Lafferty et al., 2001; Sarawagi and Cohen, 2004), “or” nodes are considered implicitly in the dynamic programming framework. In feature forest models, “or” nodes are packed when they have same conditions. For example, “or” nodes are packed when they have same end positions and same labels in the first order semi-CRFs, In general, we can pack different “or” nodes that yield equivalent feature functions in the following nodes. In other words, “or” nodes are packed when the following states use partial information on the preceding states. Consider the task of tagging entity and O-entity, where the latter tag is actua</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John Lafferty, Andrew McCallum, and Fernando Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In Proc. ofICML 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yusuke Miyao</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Maximum entropy estimation for feature forests.</title>
<date>2002</date>
<booktitle>In Proc. of HLT</booktitle>
<contexts>
<context position="5072" citStr="Miyao and Tsujii, 2002" startWordPosition="806" endWordPosition="809"> set of the shared task in 2004 JNLPBA. Formally, the computational cost of training semiCRFs is O(KLN), where L is the upper bound length of entities, N is the length of sentence and K is the size of label set. And that of training in first order semi-CRFs is O(K2LN). The increase of the cost is used to transfer non-adjacent entity information. To improve the scalability of semi-CRFs, we propose two techniques: the first is to introduce a filtering process that significantly reduces the number of candidate entities by using a “lightweight” classifier, and the second is to use feature forest (Miyao and Tsujii, 2002), with which we pack the feature equivalent states. These enable us to construct semi-CRF models for the tasks where entity names may be long and many class-labels exist at the same time. We also present an extended version of semi-CRFs in which we can make use of information about a preceding named entity in defining features within the framework of first order semi-CRFs. Since the preceding entity is not necessarily adjacent to the current entity, we achieve this by embedding the information on preceding labels for named entities into the labels for non-named entities. 2 CRFs and Semi-CRFs C</context>
<context position="11618" citStr="Miyao and Tsujii, 2002" startWordPosition="1933" endWordPosition="1936">ses appearing in a sentence, we need to incorporate multiple labels into a single probabilistic model. For example, in the shared task in COLING 2004 JNLPBA (Kim et al., 2004) the number of labels is six (“protein”, “DNA”, “RNA”, “cell line”, “cell type” and “other”). This also increases the computational cost of a semi-CRF model. To reduce the computational cost, we propose two methods (see Figure 2). The first is employing a filtering process using a lightweight classifier to remove unnecessary state candidates beforehand (Figure 2 (2)), and the second is the using the feature forest model (Miyao and Tsujii, 2002) (Figure 2 (3)), which employs dynamic programming at training “as much as possible”. 4.1 Filtering with a naive Bayes classifier We introduce a filtering process to remove low probability candidate states. This is the first step of our NER system. After this filtering step, we construct semi-CRFs on the remaining candidate states using a feature forest. Therefore the aim of this filtering is to reduce the number of candidate states, without removing correct entities. This idea 467 Figure 2: The framework of our system. We first enumerate all possible candidate states, and then filter out low </context>
<context position="14076" citStr="Miyao and Tsujii, 2002" startWordPosition="2340" endWordPosition="2343">e an efficient dynamic programming algorithm, which is similar to the forward-backward algorithm (Sarawagi and Cohen, 2004). The proposal here is a more general framework for estimating sequential conditional random fields. This framework is based on the feature forest Figure 3: Example of feature forest representation of linear chain CRFs. Feature functions are assigned to “and” nodes. Figure 4: Example of packed representation of semi-CRFs. The states that have the same end position and prev-entity label are packed. model, which was originally proposed for disambiguation models for parsing (Miyao and Tsujii, 2002). A feature forest model is a maximum entropy model defined overfeature forests, which are abstract representations of an exponential number of sequence/tree structures. A feature forest is an “and/or” graph: in Figure 3, circles represent 468 “and” nodes (conjunctive nodes), while boxes denote “or” nodes (disjunctive nodes). Feature functions are assigned to “and” nodes. We can use the information of the previous “and” node for designing the feature functions through the previous “or” node. Each sequence in a feature forest is obtained by choosing a conjunctive node for each disjunctive node.</context>
</contexts>
<marker>Miyao, Tsujii, 2002</marker>
<rawString>Yusuke Miyao and Jun’ichi Tsujii. 2002. Maximum entropy estimation for feature forests. In Proc. of HLT 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peshkin</author>
<author>Pfeffer</author>
</authors>
<title>Bayesian information extraction network.</title>
<date>2003</date>
<booktitle>In IJCAI.</booktitle>
<contexts>
<context position="9336" citStr="Peshkin and Pfeffer, 2003" startWordPosition="1562" endWordPosition="1565">formation into semi-CRFs, we take a simple approach. We divide the label of “O” into “O-protein” and “O” so that they convey the information on the preceding named entity. Figure 1 shows an example of this conversion, in which the two labels for the third and fourth states are converted from “O” to “O-protein”. When we define the features for the fifth state, we can use the information on the preceding entity “protein” by looking at the fourth state. Since this modification changes only the label set, we can do this within the framework of semi-CRF models. This idea is originally proposed in (Peshkin and Pfeffer, 2003). However, they used a dynamic Bayesian network (DBNs) rather than a semi-CRF, and semi-CRFs are likely to have significantly better performance than DBNs. In previous work, such non-local information has usually been employed at a post-processing stage. This is because the use of long distance dependency violates the locality of the model and prevents us from using dynamic programming techniques in training and inference. Skip-CRFs (Sutton and McCallum, 2004) are a direct implementation of long distance effects to the model. However, they need to determine the structure for propagating non-lo</context>
</contexts>
<marker>Peshkin, Pfeffer, 2003</marker>
<rawString>Peshkin and Pfeffer. 2003. Bayesian information extraction network. In IJCAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sunita Sarawagi</author>
<author>William W Cohen</author>
</authors>
<title>Semimarkov conditional random fields for information extraction.</title>
<date>2004</date>
<booktitle>In NIPS</booktitle>
<contexts>
<context position="2754" citStr="Sarawagi and Cohen (2004)" startWordPosition="420" endWordPosition="423">named entities such as person or organization names, was an accuracy of 95% (Sundheim, 1995). Many of the previous studies of Bio-NER tasks have been based on machine learning techniques including Hidden Markov Models (HMMs) (Bikel et al., 1997), the dictionary HMM model (Kou et al., 2005) and Maximum Entropy Markov Models (MEMMs) (Finkel et al., 2004). Among these methods, conditional random fields (CRFs) (Lafferty et al., 2001) have achieved good results (Kim et al., 2005; Settles, 2004), presumably because they are free from the so-called label bias problem by using a global normalization. Sarawagi and Cohen (2004) have recently introduced semi-Markov conditional random fields (semi-CRFs). They are defined on semi-Markov chains and attach labels to the subsequences of a sentence, rather than to the tokens2. The semiMarkov formulation allows one to easily construct entity-level features. Since the features can capture all the characteristics of a subsequence, we can use, for example, a dictionary feature which measures the similarity between a candidate segment and the closest element in the dictionary. Kou et al. (2005) have recently showed that semiCRFs perform better than CRFs in the task of recogniti</context>
<context position="6612" citStr="Sarawagi and Cohen, 2004" startWordPosition="1069" endWordPosition="1072">a state sequence y = y1, ..., yn given the observed sequence x = x1,...,xn by: p(y|x, A) = Z1 exp (EZ 1ΣjAjfj(yi−1, yi, x, i)), (1) where fj(yi−1, yi, x, i) is a feature function and Z(x) is the normalization factor over all the state sequences for the sequence x. The model parameters are a set of real-valued weights A = {Aj}, each of which represents the weight of a feature. All the feature functions are real-valued and can use adjacent label information. Semi-CRFs are actually a restricted version of order-L CRFs in which all the labels in a chunk are the same. We follow the definitions in (Sarawagi and Cohen, 2004). Let s = (s1, ..., sp) denote a segmentation of x, where a segment sj = (tj, uj, yj) consists of a start position tj, an end position uj, and a label yj. We assume that segments have a positive length bounded above by the pre-defined upper bound L (tj &lt; uj, uj − tj + 1 &lt; L) and completely cover the sequence x without overlapping, that is, s satisfies t1 = 1, up = |x|, and tj+1 = uj + 1 for j = 1, ..., p − 1. Semi-CRFs define a conditional probability of a state sequence y given an observed sequence x by: 1 p(y|x, A) = Z(x) exp(ΣjΣiAifi(sj)), (2) where fi(sj) := fi(yj−1, yj, x, tj, uj) is a fe</context>
<context position="13576" citStr="Sarawagi and Cohen, 2004" startWordPosition="2261" endWordPosition="2264">the max length of a chunk is L as for semi-CRFs) and then classify those into “entity” or “other”. Table 2 lists the features used in the naive Bayes classifier. This process can be performed independently of semi-CRFs Since the purpose of the filtering is to reduce the computational cost, rather than to achieve a good F-score by itself, we chose the threshold probability of filtering so that the recall of filtering results would be near 100 %. 4.2 Feature Forest In estimating semi-CRFs, we can use an efficient dynamic programming algorithm, which is similar to the forward-backward algorithm (Sarawagi and Cohen, 2004). The proposal here is a more general framework for estimating sequential conditional random fields. This framework is based on the feature forest Figure 3: Example of feature forest representation of linear chain CRFs. Feature functions are assigned to “and” nodes. Figure 4: Example of packed representation of semi-CRFs. The states that have the same end position and prev-entity label are packed. model, which was originally proposed for disambiguation models for parsing (Miyao and Tsujii, 2002). A feature forest model is a maximum entropy model defined overfeature forests, which are abstract </context>
<context position="15211" citStr="Sarawagi and Cohen, 2004" startWordPosition="2521" endWordPosition="2524"> in a feature forest is obtained by choosing a conjunctive node for each disjunctive node. For example, Figure 3 represents 3 x 3 = 9 sequences, since each disjunctive node has three candidates. It should be noted that feature forests can represent an exponential number of sequences with a polynomial number of conjunctive/disjunctive nodes. One can estimate a maximum entropy model for the whole sequence with dynamic programming by representing the probabilistic events, i.e. sequence of named entity tags, by feature forests (Miyao and Tsujii, 2002). In the previous work (Lafferty et al., 2001; Sarawagi and Cohen, 2004), “or” nodes are considered implicitly in the dynamic programming framework. In feature forest models, “or” nodes are packed when they have same conditions. For example, “or” nodes are packed when they have same end positions and same labels in the first order semi-CRFs, In general, we can pack different “or” nodes that yield equivalent feature functions in the following nodes. In other words, “or” nodes are packed when the following states use partial information on the preceding states. Consider the task of tagging entity and O-entity, where the latter tag is actually O tags that distinguish</context>
</contexts>
<marker>Sarawagi, Cohen, 2004</marker>
<rawString>Sunita Sarawagi and William W. Cohen. 2004. Semimarkov conditional random fields for information extraction. In NIPS 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Burr Settles</author>
</authors>
<title>Biomedical named entity recognition using conditional random fields and rich feature sets.</title>
<date>2004</date>
<booktitle>In Proc. ofJNLPBA-04.</booktitle>
<contexts>
<context position="2623" citStr="Settles, 2004" startWordPosition="402" endWordPosition="403">04) was 72.55% (Zhou and Su, 2004) 1, whereas the best performance at MUC-6, in which systems tried to identify general named entities such as person or organization names, was an accuracy of 95% (Sundheim, 1995). Many of the previous studies of Bio-NER tasks have been based on machine learning techniques including Hidden Markov Models (HMMs) (Bikel et al., 1997), the dictionary HMM model (Kou et al., 2005) and Maximum Entropy Markov Models (MEMMs) (Finkel et al., 2004). Among these methods, conditional random fields (CRFs) (Lafferty et al., 2001) have achieved good results (Kim et al., 2005; Settles, 2004), presumably because they are free from the so-called label bias problem by using a global normalization. Sarawagi and Cohen (2004) have recently introduced semi-Markov conditional random fields (semi-CRFs). They are defined on semi-Markov chains and attach labels to the subsequences of a sentence, rather than to the tokens2. The semiMarkov formulation allows one to easily construct entity-level features. Since the features can capture all the characteristics of a subsequence, we can use, for example, a dictionary feature which measures the similarity between a candidate segment and the closes</context>
<context position="24285" citStr="Settles (2004)" startWordPosition="4033" endWordPosition="4034"> systems. Our system has achieved a comparable performance to these systems and would be still improved by using external resources or conducting pre/post processing. For example, Zhou et. al (2004) used post processing, abbreviation resolution and external dictionary, and reported that they improved Fscore by 3.1%, 2.1% and 1.2% respectively. Kim et. al (2005) used the original GENIA corpus to employ the information about other semantic classes for identifying term boundaries. Finkel et. al (2004) used gazetteers, web-querying, surrounding abstracts, and frequency counts from the BNC corpus. Settles (2004) used semantic domain knowledge of 17 types of lexicon. Since our approach and the use of external resources/knowledge do not conflict but are complementary, examining the combination of those techniques should be an interesting research topic. Table 7: Performance of our system on the evaluation set Class Recall Precision F-score protein 77.74 68.92 73.07 DNA 69.03 70.16 69.59 RNA 69.49 67.21 68.33 cell type 65.33 82.19 72.80 cell line 57.60 53.14 55.28 overall 72.65 70.35 71.48 Table 8: Comparison with other systems System Recall Precision F-score Zhou et. al (2004) 75.99 69.42 72.55 Our sys</context>
</contexts>
<marker>Settles, 2004</marker>
<rawString>Burr Settles. 2004. Biomedical named entity recognition using conditional random fields and rich feature sets. In Proc. ofJNLPBA-04.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beth M Sundheim</author>
</authors>
<title>Overview of results of the MUC-6 evaluation.</title>
<date>1995</date>
<booktitle>In Sixth Message Understanding Conference (MUC-6),</booktitle>
<pages>13--32</pages>
<contexts>
<context position="2221" citStr="Sundheim, 1995" startWordPosition="337" endWordPosition="338">mated information extraction techniques. In this paper we focus on the Named Entity Recognition (NER) task, which is the first step in tackling more complex tasks such as relation extraction and knowledge mining. Biomedical NER (Bio-NER) tasks are, in general, more difficult than ones in the news domain. For example, the best F-score in the shared task of Bio-NER in COLING 2004 JNLPBA (Kim et al., 2004) was 72.55% (Zhou and Su, 2004) 1, whereas the best performance at MUC-6, in which systems tried to identify general named entities such as person or organization names, was an accuracy of 95% (Sundheim, 1995). Many of the previous studies of Bio-NER tasks have been based on machine learning techniques including Hidden Markov Models (HMMs) (Bikel et al., 1997), the dictionary HMM model (Kou et al., 2005) and Maximum Entropy Markov Models (MEMMs) (Finkel et al., 2004). Among these methods, conditional random fields (CRFs) (Lafferty et al., 2001) have achieved good results (Kim et al., 2005; Settles, 2004), presumably because they are free from the so-called label bias problem by using a global normalization. Sarawagi and Cohen (2004) have recently introduced semi-Markov conditional random fields (se</context>
</contexts>
<marker>Sundheim, 1995</marker>
<rawString>Beth M. Sundheim. 1995. Overview of results of the MUC-6 evaluation. In Sixth Message Understanding Conference (MUC-6), pages 13–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles Sutton</author>
<author>Andrew McCallum</author>
</authors>
<title>Collective segmentation and labeling of distant entities in information extraction.</title>
<date>2004</date>
<booktitle>In ICML workshop on Statistical Relational Learning.</booktitle>
<contexts>
<context position="9800" citStr="Sutton and McCallum, 2004" startWordPosition="1631" endWordPosition="1634">s modification changes only the label set, we can do this within the framework of semi-CRF models. This idea is originally proposed in (Peshkin and Pfeffer, 2003). However, they used a dynamic Bayesian network (DBNs) rather than a semi-CRF, and semi-CRFs are likely to have significantly better performance than DBNs. In previous work, such non-local information has usually been employed at a post-processing stage. This is because the use of long distance dependency violates the locality of the model and prevents us from using dynamic programming techniques in training and inference. Skip-CRFs (Sutton and McCallum, 2004) are a direct implementation of long distance effects to the model. However, they need to determine the structure for propagating non-local information in advance. In a recent study by Finkel et al., (2005), nonlocal information is encoded using an independence model, and the inference is performed by Gibbs sampling, which enables us to use a stateof-the-art factored model and carry out training efficiently, but inference still incurs a considerable computational cost. Since our model handles limited type of non-local information, i.e. the label of the preceding entity, the model can be solved</context>
</contexts>
<marker>Sutton, McCallum, 2004</marker>
<rawString>Charles Sutton and Andrew McCallum. 2004. Collective segmentation and labeling of distant entities in information extraction. In ICML workshop on Statistical Relational Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoshimasa Tsuruoka</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Chunk parsing revisited.</title>
<date>2005</date>
<booktitle>In Proceedings of the 9th International Workshop on Parsing Technologies (IWPT</booktitle>
<contexts>
<context position="12709" citStr="Tsuruoka and Tsujii (2005)" startWordPosition="2116" endWordPosition="2119">tities. This idea 467 Figure 2: The framework of our system. We first enumerate all possible candidate states, and then filter out low probability states by using a light-weight classifier, and represent them by using feature forest. Feature Name Example of Features Start/End Word ws, we Inside Word ws, ws+1, ... , we Context Word ws_1, we+1 Start/End SP sps, spe Inside SP sps, sps+1, ..., spe Context SP sps_1, spe+1 Table 2: Features used in the naive Bayes Classifier for the entity candidate: ws, ws+1, ..., we. spz is the result of shallow parsing at wz. is similar to the method proposed by Tsuruoka and Tsujii (2005) for chunk parsing, in which implausible phrase candidates are removed beforehand. We construct a binary naive Bayes classifier using the same training data as those for semi-CRFs. In training and inference, we enumerate all possible chunks (the max length of a chunk is L as for semi-CRFs) and then classify those into “entity” or “other”. Table 2 lists the features used in the naive Bayes classifier. This process can be performed independently of semi-CRFs Since the purpose of the filtering is to reduce the computational cost, rather than to achieve a good F-score by itself, we chose the thres</context>
</contexts>
<marker>Tsuruoka, Tsujii, 2005</marker>
<rawString>Yoshimasa Tsuruoka and Jun’ichi Tsujii. 2005. Chunk parsing revisited. In Proceedings of the 9th International Workshop on Parsing Technologies (IWPT 2005).</rawString>
</citation>
<citation valid="true">
<authors>
<author>GuoDong Zhou</author>
<author>Jian Su</author>
</authors>
<title>Exploring deep knowledge resources in biomedical name recognition.</title>
<date>2004</date>
<booktitle>In Proc. ofJNLPBA-04.</booktitle>
<contexts>
<context position="2043" citStr="Zhou and Su, 2004" startWordPosition="306" endWordPosition="309">d task without using any external resources or post-processing techniques. 1 Introduction The rapid increase of information in the biomedical domain has emphasized the need for automated information extraction techniques. In this paper we focus on the Named Entity Recognition (NER) task, which is the first step in tackling more complex tasks such as relation extraction and knowledge mining. Biomedical NER (Bio-NER) tasks are, in general, more difficult than ones in the news domain. For example, the best F-score in the shared task of Bio-NER in COLING 2004 JNLPBA (Kim et al., 2004) was 72.55% (Zhou and Su, 2004) 1, whereas the best performance at MUC-6, in which systems tried to identify general named entities such as person or organization names, was an accuracy of 95% (Sundheim, 1995). Many of the previous studies of Bio-NER tasks have been based on machine learning techniques including Hidden Markov Models (HMMs) (Bikel et al., 1997), the dictionary HMM model (Kou et al., 2005) and Maximum Entropy Markov Models (MEMMs) (Finkel et al., 2004). Among these methods, conditional random fields (CRFs) (Lafferty et al., 2001) have achieved good results (Kim et al., 2005; Settles, 2004), presumably because</context>
</contexts>
<marker>Zhou, Su, 2004</marker>
<rawString>GuoDong Zhou and Jian Su. 2004. Exploring deep knowledge resources in biomedical name recognition. In Proc. ofJNLPBA-04.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>