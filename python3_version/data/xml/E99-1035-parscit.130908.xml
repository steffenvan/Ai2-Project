<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000473">
<note confidence="0.713198">
Proceedings of EACL &apos;99
</note>
<title confidence="0.999096">
A Cascaded Finite-State Parser
for Syntactic Analysis of Swedish
</title>
<author confidence="0.985397">
Dimitrios Kokkinakis and Sofie Johansson Kokkinakis
</author>
<affiliation confidence="0.990879">
Department of Swedish/Spradata
</affiliation>
<address confidence="0.779779666666667">
Box 200, SE-405 30
Goteborg University, Goteborg
SWEDEN
</address>
<email confidence="0.94337">
fsvedk,svesjI@svenska.gu. se
</email>
<sectionHeader confidence="0.976642" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999359555555556">
This report describes the development
of a parsing system for written Swedish
and is focused on a grammar, the
main component of the system, semi-
automatically extracted from corpora. A
cascaded, finite-state algorithm is ap-
plied to the grammar in which the input
contains coarse-grained semantic class
information, and the output produced
reflects not only the syntactic structure
of the input, but grammatical functions
as well. The grammar has been tested
on a variety of random samples of dif-
ferent text genres, achieving precision
and recall of 94.62% and 91.92% respec-
tively, and average crossing rate of 0.04,
when evaluated against manually disam-
biguated, annotated texts.
</bodyText>
<sectionHeader confidence="0.996325" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999945714285714">
This report describes a parsing system for fast
and accurate analysis of large bodies of written
Swedish. The grammar has been implemented
in a modular fashion as finite-state, cascaded
machines, henceforth called Cass-SWE, a name
adopted from the parser used, Cascaded analy-
sis of syntactic structure, (Abney, 1996). Cass-
SWE operates on part-of-speech annotated texts
and is coupled with a pre-processing mechanism,
which distinguishes thousands of phrasal verbs,
idioms, and multi-word expressions. Cass-SWE
is designed in such a way that semantic informa-
tion, inherited by named-entity (NE) identifica-
tion software, is taken under consideration; and
grammatical functions are extracted heuristically
using finite-state transducers. The grammar has
been manually acquired from open-source texts
by observing legitimately adjacent, part-of-speech
chains, and how and which function words sig-
nal boundaries between phrasal constituents and
clauses.
</bodyText>
<sectionHeader confidence="0.98397" genericHeader="introduction">
2 Background
</sectionHeader>
<subsectionHeader confidence="0.997804">
2.1 Cascaded Finite-State Automata
</subsectionHeader>
<bodyText confidence="0.99988288">
Finite-state technology has had a great impact on
a variety of Natural Language Processing applica-
tions, as well as in industrial and academic Lan-
guage Engineering. Attractive properties, such as
conceptual simplicity, flexibility, and space and
time efficiency, have motivated researchers to cre-
ate grammars for natural language using finite-
state methods: Koskenniemi et al. (1992); Ap-
pelt et at. (1993); Roche (1996); Roche &amp; Schabes
(1997). The cascaded, finite-state mechanism we
use in this work is described in Abney (1997):
&amp;quot;...a finite-state cascade consists of a se-
quence of strata, each stratum being de-
fined by a set of regular-expression pat-
terns for recognizing phrases. [..] The
output of stratum 0 consists of parts of
speech. The patterns at level l are applied
to the output of level l-1 in the manner
of a lexical analyzer [...] longest match
is selected (ties being resolved in favour
of the first pattern listed), the matched
input symbols are consumed from the in-
put, the category of the matched pattern
is produced as output, and the cycle re-
peats...&amp;quot;, (p. 130).
</bodyText>
<subsectionHeader confidence="0.999129">
2.2 Swedish Finite-State Grammars
</subsectionHeader>
<bodyText confidence="0.999851142857143">
There have been few attempts in the past to model
Swedish grammars using finite-state methods. K.
Church at MIT implemented a Swedish, regular-
expression grammar, inspired by ideas from Ejer-
hed &amp; Church (1983). Unfortunately, the lexicon
and the rules were designed to parse a very lim-
ited set of sentences. In Ejerhed (1985), a very
</bodyText>
<page confidence="0.99656">
245
</page>
<bodyText confidence="0.9810425">
Proceedings of EACL &apos;99
general description of Swedish grammar was pre-
sented. Its algorithmic details were unclear, and
we are unaware of any descriptions in the liter-
ature of large scale applications or implementa-
tions of the models presented. It seems to us
that Swedish language researchers are satisfied
with the description and, apparently, the imple-
mentation on a small scale of finite-state meth-
ods for noun phrases only, (Cooper, 1984; Rauch,
1993). However, large scale grammars for Swedish
do exist, employing other approaches to parsing,
either radically different, such as the Swedish Core
Language Engine, (Gamback &amp; Rayner, 1992), or
slightly different, such as the Swedish Constraint
Grammar, (Birn, 1998).
</bodyText>
<subsectionHeader confidence="0.998477">
2.3 Pre-Processing
</subsectionHeader>
<bodyText confidence="0.997520909090909">
By pre-processing we mean: (i) the recognition of
multi-word tokens, phrasal verbs and idioms; (ii)
sentence segmentation; (iii) part-of-speech tag-
ging using Brill&apos;s (1994) part-of-speech tagger,
and the EAGLES tagset for Swedish, (Johansson-
Kokkinakis &amp; Kokkinakis, 1996). The general ac-
curacy of the tagger is at the 96% level, (98,7%
for the evaluation presented in table (1)). Tagging
errors do not influence critically the performance
of Cass-SWE1 (cf. Voutilainen, 1998); (iv) se-
mantic inheritance in the form of NE labels: time
sequences, locations, persons, organizations, com-
munication and transportation means, money ex-
pressions and body-part. The recognition is per-
formed using finite-state recognizers based on trig-
ger words, typical contexts, and typical predicates
associated with the entities. The performance of
the NE recognition for Swedish is 97.4% preci-
sion, and 93.5% recall, tested within the AVENTI-
NUS2 domain. Cass-SWE has been integrated
in the General Architecture for Text Engineering
(GATE), Cunningham et al. (1996).
</bodyText>
<sectionHeader confidence="0.972537" genericHeader="method">
3 The Grammar Framework
</sectionHeader>
<bodyText confidence="0.9999502">
The Swedish grammar has been semi-
automatically extracted from written text
corpora by observing two phenomena: (i) which
part-of-speech n-grams, are not allowed to be
adjacent to each other in a constituent, and (ii)
</bodyText>
<footnote confidence="0.762770333333333">
1The parser can be tolerant of the erroneous anno-
tation returned by the tagger, e.g. in the distinction
between Swedish adjective-participles in (-t). This is
accomplished by constructing rules that contain either
adjective or participle in the following manner:
np ARTICLE(ADJECTIVEIPARTICIPLE) NOUN
2 AVENTINUS (LE-2238), Advanced Informa-
tion System for Multilingual Drug Enforcement.
(http: / /svenska.gu .se/aventinus)
</footnote>
<bodyText confidence="0.998905071428571">
how and which function words signal bound-
aries between phrases and clauses. (i) uses
the Mutual Information, statistics, based on
the n-grams. Low n-gram frequencies, such
as verb/noun-determiner, gave reliable cues
for clause boundary, while high values such as
numeral-noun did not, and thus rejected. Obser-
vation (i) is related to the notion of distituent
grammars, &amp;quot; ...a distituent grammar is a list
of tag pairs which cannot be adjacent within a
constituent...&amp;quot;, Magerman &amp; Marcus (1990); (ii)
is a supplement of (i), which recognizes formal
indicators of subordination/co-ordination, such
as conjunctions, subjunctions, and punctuation.
</bodyText>
<subsectionHeader confidence="0.9965785">
3.1 Syntactic Labelling and the
Underlying Corpus
</subsectionHeader>
<bodyText confidence="0.99862784">
The syntactic analysis is completed through the
recognition of a variety of phrasal constituents,
sentential clauses, and subclauses. We follow
the proposal defined by the EAGLES (1996),
Syntactic Annotation Group, which recognizes
a number of syntactic, metasymbolic categories
that are subsumed in most current categories of
constituency-based syntactic annotation. The la-
belled bracketing consists of the syntactic cate-
gory of the phrasal constituent enclosed between
brackets. Unlabelled bracketing is only adopted
in cases of unrecognized syntactic constructions.
The corpora we used consisted of a variety of
different sources, about 200,000 tokens, collected
in AVENTINUS. The rules are divided into lev-
els, with each level consisting of groups of pat-
terns ordered according to their internal complex-
ity and length. A pattern consists of a category
and a regular expression. The regular expressions
are translated into finite-state automata, and the
union of the automata yields a single, determin-
istic, finite-state, level recognizer, (Abney, 1996).
Moreover, there is also the possibility of grouping
words and/or part-of-speech tags using morpho-
logical and semantic criteria.
</bodyText>
<subsectionHeader confidence="0.996595">
3.2 Grammar Rules
</subsectionHeader>
<bodyText confidence="0.995505">
Some of the most important groups include:
</bodyText>
<listItem confidence="0.9995402">
• Noun Phrases, Grammaro: the number
of patterns in grammar° is 180, divided in six
different groups, depending on the length and
complexity of the patterns. A large number
of (parallel) coordination rules are also imple-
mented at this level, depending on the simi-
larity of the conjuncts with respect to several
different characteristics, (cf. Nagao, 1992).
• Prepositional Phrases, Grammari: the
majority of prepositional phrases are noun
</listItem>
<page confidence="0.993127">
246
</page>
<bodyText confidence="0.948509833333333">
Proceedings of EACL &apos;99
phrases preceded by a preposition. Trapped
adverbials, belonging to the noun phrase and
not identified while applying grammar°, are
merged within the up. Both simple and multi-
word prepositions are used.
</bodyText>
<listItem confidence="0.99923725">
• Verbal Groups, Grammar2: identifies and
labels phrasal, non-phrasal, and complex ver-
bal formations. The rules allow for any num-
ber of auxiliary verbs, possible intervening
adverbs, and end with a main verb or particle.
A distinction is made between finite/infinite
active/passive verbal groups.
• Clauses, Grammar3 and Grammar4: the
</listItem>
<bodyText confidence="0.967125571428571">
clause resolution is based on surface crite-
ria, outlined at the beginning of this chapter,
and the rather fixed word order of Swedish.
Grammar3 distinguishes different types of
subordinate clauses; while Grammar4 recog-
nizes main clauses. A unique level is desig-
nated for each type of clause
</bodyText>
<subsectionHeader confidence="0.998057">
3.3 Grammatical Functions
</subsectionHeader>
<bodyText confidence="0.9999752">
Grammatical functions are heuristically recog-
nized using the topographical scheme, originally
developed for Danish, in which the relative po-
sition of all functional elements in the clause is
mapped in the sentence, (Diderichsen, 1966).
</bodyText>
<subsectionHeader confidence="0.994337">
3.4 An Example
</subsectionHeader>
<bodyText confidence="0.8877615">
The following short example illustrates the input
and output to Cass-SWE:
&apos;Under 1998 gick 8 799 foretag i konkurs i
Sverige.&apos;, i.e. &apos;During 1998, 8 799 companies
</bodyText>
<subsubsectionHeader confidence="0.326397">
went bankrupt in Sweden.&apos;
</subsubsectionHeader>
<bodyText confidence="0.9779945">
The input to Cass-SWE is an annotated version
of the text:
</bodyText>
<equation confidence="0.828212777777778">
&apos;Under/S 1998/MC/tim gick/VMISA 8_799/MC
foretag/NCN(SP)NI/org i/S konkurs/NCUSNI
i/S Sverige/NP/icg./r.
Output:
[main_clause
TIME=[rop head=Under sem=tim
[S head=Under sem=n/a tinder]
[np head=1998 sem=tim
[MC head=1998 sem=tim 1998]]]
</equation>
<bodyText confidence="0.619691">
[vg-active-finite head=gick sem=n/a
</bodyText>
<figure confidence="0.643028153846154">
[VMISA head=gick sem=n/a gick]]
SUBJ--grip head=fiiretag sem=org
[MC head=8_799 sem=n/a 8_799]
[NCN(SP)NI head=foretag sem=org foretag]]
P-OBJ=Epp head=i sem=n/a
[S head=i sem=n/a
[up head=konkurs sem=n/a
[NCUSNI head=konkurs sem=n/a konkurs]3]
[pp head=i sem=lcg
[S head=i sem=n/a
[up head=Sverige sem=lcg
[NP head=Sverige sem=lcg Sverige]]]
[F .])
</figure>
<bodyText confidence="0.846945222222222">
Here s: preposition; Mc: numeral; VMISA: finite,
active verb; NCUSNI/NCN(SP)NI: common nouns; NP:
proper noun and F: punctuation; while tin: time
sequence; org: organization and lcg: geograph-
ical location. The output produced reflects the
coarse-grained semantics and part-of-speech used
in the input, as well as the head of each phrase
and the grammatical functions: TIME, SUBJ(ect)
and P-OBJ(ect).
</bodyText>
<sectionHeader confidence="0.994513" genericHeader="evaluation">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.9996825">
The performance of the parser partly depends on
the output of the tagger and the rest of the pre-
processing software. Our way of dealing with how
&amp;quot;correct&amp;quot; the performance of the parser is, follows
a practical, pragmatic approach, based on consul-
tation of modern Swedish syntax literature. We
use the metrics: precision (P), recall (R), F-value
(F) and cross-bracketed rate. F = (02+1) PR/02
P+R, where 13 is a parameter encoding the rela-
tive importance of (R) and (P); here 0=1. Eval-
uation is performed automatically using the evalb
evaluation software, (Sekine &amp; Collins, 1997).
</bodyText>
<subsectionHeader confidence="0.998156">
4.1 &apos;Gold Standard&apos; and Error Analysis
</subsectionHeader>
<bodyText confidence="0.999962416666667">
For the evaluation of Cass-SWE we use three
types of texts: (i) a sample taken from a man-
ually annotated Swedish corpus of 100,000 words
with grammatical information (SynTag, Jarborg,
1990); (ii)- newspaper material; and (iii) a test
suite, for non-common constructions, by consult-
ing Swedish syntax literature. Texts (ii) and (iii)
were annotated manually. The total number of
tokens was 1,500 and sentences 117.
The evaluation results are given in Table (1), for
both noun phrases (NPs), and full chunk parsing
(All). The errors found can be divided into: (i)
</bodyText>
<tableCaption confidence="0.997034">
Table 1: Cass-SWE, Performance
</tableCaption>
<table confidence="0.994381">
P R F Cross
NPs 97.82% 94.52% 96.17% 0.03
All 94.62% 91.92% 93.2%7 0.04
</table>
<bodyText confidence="0.999511285714286">
errors in the texts themselves, which we cannot
control and are difficult to discover if the texts
are not proofread prior to processing; (ii) errors
produced by the tagger; and (iii) grammatical er-
rors produced by the parser, caused mainly by the
lack of an appropriate pattern in the rules, and
almost exclusively in higher order clauses due to
</bodyText>
<page confidence="0.993358">
247
</page>
<bodyText confidence="0.945892333333333">
Proceedings of EACL &apos;99
structural ambiguity and coordination problems.
None of the errors in (i) and (ii) have been man-
ually corrected. This was a conscious choice, so
that the evaluation of the parsing will be based
on unrestricted data.
</bodyText>
<sectionHeader confidence="0.9973" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999979">
We have described the implementation of a large
coverage parser for Swedish, following the cas-
caded finite-state approach. Our main guidance
towards the grammar development was the obser-
vation of how and which function words behave
as delimiters between different phrases, as well as
which other part-of-speech tags are not allowed
to be adjacent within a constituent. Cass-SWE
operates on part-of-speech annotated texts us-
ing coarse-grained semantic information, and pro-
duces output that reflects this information as well
as grammatical functions in the output. A corpus,
annotated syntactically, is a rich source of infor-
mation which we intend to use for a number of
applications, e.g. information extraction; an inter-
mediate step in the extraction of lexical semantic
information; making valency lexicons more com-
prehensive by extracting sub-categorization infor-
mation, and syntactic relations.
</bodyText>
<sectionHeader confidence="0.996747" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999699618421053">
Abney, S. 1996. Partial Parsing via Finite-State
Cascades. In Proceedings of the ESSLLI &apos;96 Ro-
bust Parsing Workshop, Prague, Czech Rep.
Abney, S. 1997. Part-of-Speech Tagging and Par-
tial Parsing, In Corpus-Based Methods in Lan-
guage and Speech Processing, Young S. and
Bloothooft G., editors, Kluwer Acad. Publish-
ers, Chap. 4, pp. 118-136.
Appelt, D.E., J. Hobbs, J. Bear, D. Israel, and M.
Tyson. 1993. FASTUS: A Finite-State Proces-
sor for Information Extraction from Real-World
Text, In Proceedings of the IJCAI &apos;93, France.
Birn, J. 1998. Swedish Constraint Grammar, Ling-
soft Inc., Finland, forthcoming.
Brill, E. 1994. Some Advances In Rule-Based Part
of Speech Tagging, In Proceedings of the 12th
AAAI &apos;94, Seattle, Washington.
Cooper, R. 1984. Svenska nominalfraser och
kontext-fri grammatik, In Nordic Journal of
Linguistics, Vol. 7:115-144, (in Swedish).
Cunningham, H., R. Gaizauskas, and Y. Wilks.
1995. A General Architecture for Text Engineer-
ing (GATE) - A New Approach to Language
Engineering R&amp;D, Technical report CS-95-21,
University of Sheffield, UK.
Diderichsen, P. 1966. Helhed og Struktur, G.E.C.
GADS Forlag, (in Danish).
EAGLES. 1996. Expert Advisory Group for Lan-
guage Engineering Standards, EAG-TCWG-
SASG/1.8 , http://www.ilc.pi.cnr.it/EAGLES/
home.html. Visited 01/08/1998.
Ejerhed, E. and Church, K. 1983. Finite State
Parsing, In Papers from the 7th Scandinavian
Conference of Linguistics, Karlsson P., editor,
University of Helsinki, Publ. No. 10(2):410-431.
Ejerhed, E. 1985. En ytstruktur grammatik for
svenska, In Svenskans Beskrivning 15, Allen, S.,
L-G. Andersson, J. Lofstrom, K. Nordenstam,
and B. Ralph, editors, G8teborg, (in Swedish).
Gamback, B. and Rayner, M. 1992. The
Swedish Core Language Engine, CRC-025,
http://www.cam.sri.com. Visited 01/10/1998.
Johansson-Kokkinakis, S. and Kokkinakis, D.
1996. Rule-Based Tagging in Sprcikbanken,
Research Reports from the Department of
Swedish, Goteborg University, GU-ISS-96-5.
Jarborg, J. 1990. Anvandning av Syn Tag, Re-
search Reports from the Department of
Swedish, Goteborg University, (in Swedish).
Koskenniemi, K., P. Tapanainen, and A. Vouti-
lainen. 1992. Compiling and Using Finite -State
Syntactic Rules, In Proceedings of COLING &apos;92,
Nantes, France, Vol. 1:156-162.
Magerman, D.M. and Marcus, M.P. 1990. Parsing
a Natural Language Using Mutual Information
Statistics, In Proceedings of AAAI &apos;90, Boston,
Massachusetts.
Nagao, M. 1992. Are the Grammars so far Devel-
oped Appropriate to Recognize the Real Struc-
ture of a Sentence?, In Proceedings of 4th TMI,
Montréal, Canada, pp. 127-137.
Rauch, B. 1993. Automatisk igenkanning av nom-
inalfraser i lopande text, In Proceedings of the
9th NODALIDA, Eklund, R., editor, pp. 207-
215, (in Swedish).
Roche, E. 1996. Parsing with Finite-State Trans-
ducers, http://www.merl-com/reports/TR96-
30. Visited 12/03/99.
Roche, E. and Schabes, Y., editors, 1997. Finite-
State Language Processing, MIT Press.
Sekine, S. and Collins, M.J. 1997. The evalb Soft-
ware, http://cs.nyu.edu/cs/projects/proteus/
evalb. Visited 14/12/97.
Voutilainen, A. 1998. Does Tagging Help Parsing?
A Case Study on Finite State Parsing, In Pro-
ceedings of the FSMNLP &apos;98, Ankara, Turkey.
</reference>
<page confidence="0.996986">
248
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.119280">
<note confidence="0.508985">Proceedings of EACL &apos;99</note>
<title confidence="0.9942965">A Cascaded Finite-State Parser for Syntactic Analysis of Swedish</title>
<author confidence="0.981112">Dimitrios Kokkinakis</author>
<author confidence="0.981112">Sofie Johansson Kokkinakis</author>
<affiliation confidence="0.999732">Department of Swedish/Spradata</affiliation>
<address confidence="0.985122">Box 200, SE-405 30</address>
<affiliation confidence="0.863122">Goteborg University, Goteborg</affiliation>
<address confidence="0.673234">SWEDEN</address>
<author confidence="0.381578">se</author>
<abstract confidence="0.996514210526316">This report describes the development of a parsing system for written Swedish and is focused on a grammar, the main component of the system, semiautomatically extracted from corpora. A cascaded, finite-state algorithm is applied to the grammar in which the input contains coarse-grained semantic class information, and the output produced reflects not only the syntactic structure of the input, but grammatical functions as well. The grammar has been tested on a variety of random samples of different text genres, achieving precision and recall of 94.62% and 91.92% respectively, and average crossing rate of 0.04, when evaluated against manually disambiguated, annotated texts.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Abney</author>
</authors>
<title>Partial Parsing via Finite-State Cascades.</title>
<date>1996</date>
<booktitle>In Proceedings of the ESSLLI &apos;96 Robust Parsing Workshop,</booktitle>
<location>Prague, Czech Rep.</location>
<contexts>
<context position="1277" citStr="Abney, 1996" startWordPosition="187" endWordPosition="188">grammatical functions as well. The grammar has been tested on a variety of random samples of different text genres, achieving precision and recall of 94.62% and 91.92% respectively, and average crossing rate of 0.04, when evaluated against manually disambiguated, annotated texts. 1 Introduction This report describes a parsing system for fast and accurate analysis of large bodies of written Swedish. The grammar has been implemented in a modular fashion as finite-state, cascaded machines, henceforth called Cass-SWE, a name adopted from the parser used, Cascaded analysis of syntactic structure, (Abney, 1996). CassSWE operates on part-of-speech annotated texts and is coupled with a pre-processing mechanism, which distinguishes thousands of phrasal verbs, idioms, and multi-word expressions. Cass-SWE is designed in such a way that semantic information, inherited by named-entity (NE) identification software, is taken under consideration; and grammatical functions are extracted heuristically using finite-state transducers. The grammar has been manually acquired from open-source texts by observing legitimately adjacent, part-of-speech chains, and how and which function words signal boundaries between p</context>
<context position="7614" citStr="Abney, 1996" startWordPosition="1134" endWordPosition="1135">nstituent enclosed between brackets. Unlabelled bracketing is only adopted in cases of unrecognized syntactic constructions. The corpora we used consisted of a variety of different sources, about 200,000 tokens, collected in AVENTINUS. The rules are divided into levels, with each level consisting of groups of patterns ordered according to their internal complexity and length. A pattern consists of a category and a regular expression. The regular expressions are translated into finite-state automata, and the union of the automata yields a single, deterministic, finite-state, level recognizer, (Abney, 1996). Moreover, there is also the possibility of grouping words and/or part-of-speech tags using morphological and semantic criteria. 3.2 Grammar Rules Some of the most important groups include: • Noun Phrases, Grammaro: the number of patterns in grammar° is 180, divided in six different groups, depending on the length and complexity of the patterns. A large number of (parallel) coordination rules are also implemented at this level, depending on the similarity of the conjuncts with respect to several different characteristics, (cf. Nagao, 1992). • Prepositional Phrases, Grammari: the majority of p</context>
</contexts>
<marker>Abney, 1996</marker>
<rawString>Abney, S. 1996. Partial Parsing via Finite-State Cascades. In Proceedings of the ESSLLI &apos;96 Robust Parsing Workshop, Prague, Czech Rep.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Abney</author>
</authors>
<title>Part-of-Speech Tagging and Partial Parsing,</title>
<date>1997</date>
<booktitle>In Corpus-Based Methods in Language and Speech Processing,</booktitle>
<volume>4</volume>
<pages>118--136</pages>
<editor>S. and Bloothooft G., editors, Kluwer Acad. Publishers,</editor>
<location>Young</location>
<contexts>
<context position="2487" citStr="Abney (1997)" startWordPosition="358" endWordPosition="359"> phrasal constituents and clauses. 2 Background 2.1 Cascaded Finite-State Automata Finite-state technology has had a great impact on a variety of Natural Language Processing applications, as well as in industrial and academic Language Engineering. Attractive properties, such as conceptual simplicity, flexibility, and space and time efficiency, have motivated researchers to create grammars for natural language using finitestate methods: Koskenniemi et al. (1992); Appelt et at. (1993); Roche (1996); Roche &amp; Schabes (1997). The cascaded, finite-state mechanism we use in this work is described in Abney (1997): &amp;quot;...a finite-state cascade consists of a sequence of strata, each stratum being defined by a set of regular-expression patterns for recognizing phrases. [..] The output of stratum 0 consists of parts of speech. The patterns at level l are applied to the output of level l-1 in the manner of a lexical analyzer [...] longest match is selected (ties being resolved in favour of the first pattern listed), the matched input symbols are consumed from the input, the category of the matched pattern is produced as output, and the cycle repeats...&amp;quot;, (p. 130). 2.2 Swedish Finite-State Grammars There have</context>
</contexts>
<marker>Abney, 1997</marker>
<rawString>Abney, S. 1997. Part-of-Speech Tagging and Partial Parsing, In Corpus-Based Methods in Language and Speech Processing, Young S. and Bloothooft G., editors, Kluwer Acad. Publishers, Chap. 4, pp. 118-136.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D E Appelt</author>
<author>J Hobbs</author>
<author>J Bear</author>
<author>D Israel</author>
<author>M Tyson</author>
</authors>
<title>FASTUS: A Finite-State Processor for Information Extraction from Real-World Text,</title>
<date>1993</date>
<booktitle>In Proceedings of the IJCAI &apos;93,</booktitle>
<marker>Appelt, Hobbs, Bear, Israel, Tyson, 1993</marker>
<rawString>Appelt, D.E., J. Hobbs, J. Bear, D. Israel, and M. Tyson. 1993. FASTUS: A Finite-State Processor for Information Extraction from Real-World Text, In Proceedings of the IJCAI &apos;93, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Birn</author>
</authors>
<date>1998</date>
<institution>Swedish Constraint Grammar, Lingsoft Inc.,</institution>
<location>Finland, forthcoming.</location>
<contexts>
<context position="4134" citStr="Birn, 1998" startWordPosition="628" endWordPosition="629">clear, and we are unaware of any descriptions in the literature of large scale applications or implementations of the models presented. It seems to us that Swedish language researchers are satisfied with the description and, apparently, the implementation on a small scale of finite-state methods for noun phrases only, (Cooper, 1984; Rauch, 1993). However, large scale grammars for Swedish do exist, employing other approaches to parsing, either radically different, such as the Swedish Core Language Engine, (Gamback &amp; Rayner, 1992), or slightly different, such as the Swedish Constraint Grammar, (Birn, 1998). 2.3 Pre-Processing By pre-processing we mean: (i) the recognition of multi-word tokens, phrasal verbs and idioms; (ii) sentence segmentation; (iii) part-of-speech tagging using Brill&apos;s (1994) part-of-speech tagger, and the EAGLES tagset for Swedish, (JohanssonKokkinakis &amp; Kokkinakis, 1996). The general accuracy of the tagger is at the 96% level, (98,7% for the evaluation presented in table (1)). Tagging errors do not influence critically the performance of Cass-SWE1 (cf. Voutilainen, 1998); (iv) semantic inheritance in the form of NE labels: time sequences, locations, persons, organizations,</context>
</contexts>
<marker>Birn, 1998</marker>
<rawString>Birn, J. 1998. Swedish Constraint Grammar, Lingsoft Inc., Finland, forthcoming.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Brill</author>
</authors>
<title>Some Advances In Rule-Based Part of Speech Tagging,</title>
<date>1994</date>
<booktitle>In Proceedings of the 12th AAAI &apos;94,</booktitle>
<location>Seattle, Washington.</location>
<marker>Brill, 1994</marker>
<rawString>Brill, E. 1994. Some Advances In Rule-Based Part of Speech Tagging, In Proceedings of the 12th AAAI &apos;94, Seattle, Washington.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Cooper</author>
</authors>
<title>Svenska nominalfraser och kontext-fri grammatik,</title>
<date>1984</date>
<journal>In Nordic Journal of Linguistics,</journal>
<volume>7</volume>
<note>(in Swedish).</note>
<contexts>
<context position="3856" citStr="Cooper, 1984" startWordPosition="588" endWordPosition="589">red by ideas from Ejerhed &amp; Church (1983). Unfortunately, the lexicon and the rules were designed to parse a very limited set of sentences. In Ejerhed (1985), a very 245 Proceedings of EACL &apos;99 general description of Swedish grammar was presented. Its algorithmic details were unclear, and we are unaware of any descriptions in the literature of large scale applications or implementations of the models presented. It seems to us that Swedish language researchers are satisfied with the description and, apparently, the implementation on a small scale of finite-state methods for noun phrases only, (Cooper, 1984; Rauch, 1993). However, large scale grammars for Swedish do exist, employing other approaches to parsing, either radically different, such as the Swedish Core Language Engine, (Gamback &amp; Rayner, 1992), or slightly different, such as the Swedish Constraint Grammar, (Birn, 1998). 2.3 Pre-Processing By pre-processing we mean: (i) the recognition of multi-word tokens, phrasal verbs and idioms; (ii) sentence segmentation; (iii) part-of-speech tagging using Brill&apos;s (1994) part-of-speech tagger, and the EAGLES tagset for Swedish, (JohanssonKokkinakis &amp; Kokkinakis, 1996). The general accuracy of the </context>
</contexts>
<marker>Cooper, 1984</marker>
<rawString>Cooper, R. 1984. Svenska nominalfraser och kontext-fri grammatik, In Nordic Journal of Linguistics, Vol. 7:115-144, (in Swedish).</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Cunningham</author>
<author>R Gaizauskas</author>
<author>Y Wilks</author>
</authors>
<title>A General Architecture for Text Engineering (GATE) - A New Approach to Language Engineering R&amp;D,</title>
<date>1995</date>
<tech>Technical report CS-95-21,</tech>
<institution>University of Sheffield, UK.</institution>
<marker>Cunningham, Gaizauskas, Wilks, 1995</marker>
<rawString>Cunningham, H., R. Gaizauskas, and Y. Wilks. 1995. A General Architecture for Text Engineering (GATE) - A New Approach to Language Engineering R&amp;D, Technical report CS-95-21, University of Sheffield, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Diderichsen</author>
</authors>
<title>Helhed og Struktur, G.E.C. GADS Forlag,</title>
<date>1966</date>
<location>(in Danish).</location>
<contexts>
<context position="9361" citStr="Diderichsen, 1966" startWordPosition="1400" endWordPosition="1401">ctive/passive verbal groups. • Clauses, Grammar3 and Grammar4: the clause resolution is based on surface criteria, outlined at the beginning of this chapter, and the rather fixed word order of Swedish. Grammar3 distinguishes different types of subordinate clauses; while Grammar4 recognizes main clauses. A unique level is designated for each type of clause 3.3 Grammatical Functions Grammatical functions are heuristically recognized using the topographical scheme, originally developed for Danish, in which the relative position of all functional elements in the clause is mapped in the sentence, (Diderichsen, 1966). 3.4 An Example The following short example illustrates the input and output to Cass-SWE: &apos;Under 1998 gick 8 799 foretag i konkurs i Sverige.&apos;, i.e. &apos;During 1998, 8 799 companies went bankrupt in Sweden.&apos; The input to Cass-SWE is an annotated version of the text: &apos;Under/S 1998/MC/tim gick/VMISA 8_799/MC foretag/NCN(SP)NI/org i/S konkurs/NCUSNI i/S Sverige/NP/icg./r. Output: [main_clause TIME=[rop head=Under sem=tim [S head=Under sem=n/a tinder] [np head=1998 sem=tim [MC head=1998 sem=tim 1998]]] [vg-active-finite head=gick sem=n/a [VMISA head=gick sem=n/a gick]] SUBJ--grip head=fiiretag sem=o</context>
</contexts>
<marker>Diderichsen, 1966</marker>
<rawString>Diderichsen, P. 1966. Helhed og Struktur, G.E.C. GADS Forlag, (in Danish).</rawString>
</citation>
<citation valid="true">
<authors>
<author>EAGLES</author>
</authors>
<title>Expert Advisory Group for Language Engineering Standards,</title>
<date>1996</date>
<note>http://www.ilc.pi.cnr.it/EAGLES/ home.html. Visited 01/08/1998.</note>
<contexts>
<context position="6743" citStr="EAGLES (1996)" startWordPosition="1008" endWordPosition="1009">eral-noun did not, and thus rejected. Observation (i) is related to the notion of distituent grammars, &amp;quot; ...a distituent grammar is a list of tag pairs which cannot be adjacent within a constituent...&amp;quot;, Magerman &amp; Marcus (1990); (ii) is a supplement of (i), which recognizes formal indicators of subordination/co-ordination, such as conjunctions, subjunctions, and punctuation. 3.1 Syntactic Labelling and the Underlying Corpus The syntactic analysis is completed through the recognition of a variety of phrasal constituents, sentential clauses, and subclauses. We follow the proposal defined by the EAGLES (1996), Syntactic Annotation Group, which recognizes a number of syntactic, metasymbolic categories that are subsumed in most current categories of constituency-based syntactic annotation. The labelled bracketing consists of the syntactic category of the phrasal constituent enclosed between brackets. Unlabelled bracketing is only adopted in cases of unrecognized syntactic constructions. The corpora we used consisted of a variety of different sources, about 200,000 tokens, collected in AVENTINUS. The rules are divided into levels, with each level consisting of groups of patterns ordered according to </context>
</contexts>
<marker>EAGLES, 1996</marker>
<rawString>EAGLES. 1996. Expert Advisory Group for Language Engineering Standards, EAG-TCWGSASG/1.8 , http://www.ilc.pi.cnr.it/EAGLES/ home.html. Visited 01/08/1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Ejerhed</author>
<author>K Church</author>
</authors>
<title>Finite State Parsing,</title>
<date>1983</date>
<booktitle>In Papers from the 7th Scandinavian Conference of Linguistics,</booktitle>
<pages>10--2</pages>
<editor>Karlsson P., editor,</editor>
<publisher>Publ. No.</publisher>
<institution>University of Helsinki,</institution>
<contexts>
<context position="3285" citStr="Ejerhed &amp; Church (1983)" startWordPosition="491" endWordPosition="495">tratum 0 consists of parts of speech. The patterns at level l are applied to the output of level l-1 in the manner of a lexical analyzer [...] longest match is selected (ties being resolved in favour of the first pattern listed), the matched input symbols are consumed from the input, the category of the matched pattern is produced as output, and the cycle repeats...&amp;quot;, (p. 130). 2.2 Swedish Finite-State Grammars There have been few attempts in the past to model Swedish grammars using finite-state methods. K. Church at MIT implemented a Swedish, regularexpression grammar, inspired by ideas from Ejerhed &amp; Church (1983). Unfortunately, the lexicon and the rules were designed to parse a very limited set of sentences. In Ejerhed (1985), a very 245 Proceedings of EACL &apos;99 general description of Swedish grammar was presented. Its algorithmic details were unclear, and we are unaware of any descriptions in the literature of large scale applications or implementations of the models presented. It seems to us that Swedish language researchers are satisfied with the description and, apparently, the implementation on a small scale of finite-state methods for noun phrases only, (Cooper, 1984; Rauch, 1993). However, larg</context>
</contexts>
<marker>Ejerhed, Church, 1983</marker>
<rawString>Ejerhed, E. and Church, K. 1983. Finite State Parsing, In Papers from the 7th Scandinavian Conference of Linguistics, Karlsson P., editor, University of Helsinki, Publ. No. 10(2):410-431.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Ejerhed</author>
</authors>
<title>En ytstruktur grammatik for svenska,</title>
<date>1985</date>
<booktitle>In Svenskans Beskrivning 15,</booktitle>
<editor>Allen, S., L-G. Andersson, J. Lofstrom, K. Nordenstam, and B. Ralph, editors, G8teborg, (in Swedish).</editor>
<contexts>
<context position="3401" citStr="Ejerhed (1985)" startWordPosition="514" endWordPosition="515">al analyzer [...] longest match is selected (ties being resolved in favour of the first pattern listed), the matched input symbols are consumed from the input, the category of the matched pattern is produced as output, and the cycle repeats...&amp;quot;, (p. 130). 2.2 Swedish Finite-State Grammars There have been few attempts in the past to model Swedish grammars using finite-state methods. K. Church at MIT implemented a Swedish, regularexpression grammar, inspired by ideas from Ejerhed &amp; Church (1983). Unfortunately, the lexicon and the rules were designed to parse a very limited set of sentences. In Ejerhed (1985), a very 245 Proceedings of EACL &apos;99 general description of Swedish grammar was presented. Its algorithmic details were unclear, and we are unaware of any descriptions in the literature of large scale applications or implementations of the models presented. It seems to us that Swedish language researchers are satisfied with the description and, apparently, the implementation on a small scale of finite-state methods for noun phrases only, (Cooper, 1984; Rauch, 1993). However, large scale grammars for Swedish do exist, employing other approaches to parsing, either radically different, such as th</context>
</contexts>
<marker>Ejerhed, 1985</marker>
<rawString>Ejerhed, E. 1985. En ytstruktur grammatik for svenska, In Svenskans Beskrivning 15, Allen, S., L-G. Andersson, J. Lofstrom, K. Nordenstam, and B. Ralph, editors, G8teborg, (in Swedish).</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Gamback</author>
<author>M Rayner</author>
</authors>
<date>1992</date>
<booktitle>The Swedish Core Language Engine, CRC-025, http://www.cam.sri.com. Visited</booktitle>
<pages>01--10</pages>
<contexts>
<context position="4057" citStr="Gamback &amp; Rayner, 1992" startWordPosition="615" endWordPosition="618">&apos;99 general description of Swedish grammar was presented. Its algorithmic details were unclear, and we are unaware of any descriptions in the literature of large scale applications or implementations of the models presented. It seems to us that Swedish language researchers are satisfied with the description and, apparently, the implementation on a small scale of finite-state methods for noun phrases only, (Cooper, 1984; Rauch, 1993). However, large scale grammars for Swedish do exist, employing other approaches to parsing, either radically different, such as the Swedish Core Language Engine, (Gamback &amp; Rayner, 1992), or slightly different, such as the Swedish Constraint Grammar, (Birn, 1998). 2.3 Pre-Processing By pre-processing we mean: (i) the recognition of multi-word tokens, phrasal verbs and idioms; (ii) sentence segmentation; (iii) part-of-speech tagging using Brill&apos;s (1994) part-of-speech tagger, and the EAGLES tagset for Swedish, (JohanssonKokkinakis &amp; Kokkinakis, 1996). The general accuracy of the tagger is at the 96% level, (98,7% for the evaluation presented in table (1)). Tagging errors do not influence critically the performance of Cass-SWE1 (cf. Voutilainen, 1998); (iv) semantic inheritance</context>
</contexts>
<marker>Gamback, Rayner, 1992</marker>
<rawString>Gamback, B. and Rayner, M. 1992. The Swedish Core Language Engine, CRC-025, http://www.cam.sri.com. Visited 01/10/1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Johansson-Kokkinakis</author>
<author>D Kokkinakis</author>
</authors>
<title>Rule-Based Tagging</title>
<date>1996</date>
<booktitle>in Sprcikbanken, Research Reports from the</booktitle>
<pages>96--5</pages>
<institution>Department of Swedish, Goteborg University,</institution>
<marker>Johansson-Kokkinakis, Kokkinakis, 1996</marker>
<rawString>Johansson-Kokkinakis, S. and Kokkinakis, D. 1996. Rule-Based Tagging in Sprcikbanken, Research Reports from the Department of Swedish, Goteborg University, GU-ISS-96-5.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Jarborg</author>
</authors>
<title>Anvandning av Syn Tag, Research Reports from the</title>
<date>1990</date>
<institution>Department of Swedish, Goteborg University, (in Swedish).</institution>
<contexts>
<context position="11470" citStr="Jarborg, 1990" startWordPosition="1709" endWordPosition="1710">ws a practical, pragmatic approach, based on consultation of modern Swedish syntax literature. We use the metrics: precision (P), recall (R), F-value (F) and cross-bracketed rate. F = (02+1) PR/02 P+R, where 13 is a parameter encoding the relative importance of (R) and (P); here 0=1. Evaluation is performed automatically using the evalb evaluation software, (Sekine &amp; Collins, 1997). 4.1 &apos;Gold Standard&apos; and Error Analysis For the evaluation of Cass-SWE we use three types of texts: (i) a sample taken from a manually annotated Swedish corpus of 100,000 words with grammatical information (SynTag, Jarborg, 1990); (ii)- newspaper material; and (iii) a test suite, for non-common constructions, by consulting Swedish syntax literature. Texts (ii) and (iii) were annotated manually. The total number of tokens was 1,500 and sentences 117. The evaluation results are given in Table (1), for both noun phrases (NPs), and full chunk parsing (All). The errors found can be divided into: (i) Table 1: Cass-SWE, Performance P R F Cross NPs 97.82% 94.52% 96.17% 0.03 All 94.62% 91.92% 93.2%7 0.04 errors in the texts themselves, which we cannot control and are difficult to discover if the texts are not proofread prior t</context>
</contexts>
<marker>Jarborg, 1990</marker>
<rawString>Jarborg, J. 1990. Anvandning av Syn Tag, Research Reports from the Department of Swedish, Goteborg University, (in Swedish).</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Koskenniemi</author>
<author>P Tapanainen</author>
<author>A Voutilainen</author>
</authors>
<title>Compiling and Using Finite -State Syntactic Rules,</title>
<date>1992</date>
<booktitle>In Proceedings of COLING &apos;92,</booktitle>
<volume>Vol.</volume>
<pages>1--156</pages>
<location>Nantes, France,</location>
<contexts>
<context position="2340" citStr="Koskenniemi et al. (1992)" startWordPosition="331" endWordPosition="334">n manually acquired from open-source texts by observing legitimately adjacent, part-of-speech chains, and how and which function words signal boundaries between phrasal constituents and clauses. 2 Background 2.1 Cascaded Finite-State Automata Finite-state technology has had a great impact on a variety of Natural Language Processing applications, as well as in industrial and academic Language Engineering. Attractive properties, such as conceptual simplicity, flexibility, and space and time efficiency, have motivated researchers to create grammars for natural language using finitestate methods: Koskenniemi et al. (1992); Appelt et at. (1993); Roche (1996); Roche &amp; Schabes (1997). The cascaded, finite-state mechanism we use in this work is described in Abney (1997): &amp;quot;...a finite-state cascade consists of a sequence of strata, each stratum being defined by a set of regular-expression patterns for recognizing phrases. [..] The output of stratum 0 consists of parts of speech. The patterns at level l are applied to the output of level l-1 in the manner of a lexical analyzer [...] longest match is selected (ties being resolved in favour of the first pattern listed), the matched input symbols are consumed from the </context>
</contexts>
<marker>Koskenniemi, Tapanainen, Voutilainen, 1992</marker>
<rawString>Koskenniemi, K., P. Tapanainen, and A. Voutilainen. 1992. Compiling and Using Finite -State Syntactic Rules, In Proceedings of COLING &apos;92, Nantes, France, Vol. 1:156-162.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D M Magerman</author>
<author>M P Marcus</author>
</authors>
<title>Parsing a Natural Language Using Mutual Information Statistics,</title>
<date>1990</date>
<booktitle>In Proceedings of AAAI &apos;90,</booktitle>
<location>Boston, Massachusetts.</location>
<contexts>
<context position="6357" citStr="Magerman &amp; Marcus (1990)" startWordPosition="954" endWordPosition="957">LE) NOUN 2 AVENTINUS (LE-2238), Advanced Information System for Multilingual Drug Enforcement. (http: / /svenska.gu .se/aventinus) how and which function words signal boundaries between phrases and clauses. (i) uses the Mutual Information, statistics, based on the n-grams. Low n-gram frequencies, such as verb/noun-determiner, gave reliable cues for clause boundary, while high values such as numeral-noun did not, and thus rejected. Observation (i) is related to the notion of distituent grammars, &amp;quot; ...a distituent grammar is a list of tag pairs which cannot be adjacent within a constituent...&amp;quot;, Magerman &amp; Marcus (1990); (ii) is a supplement of (i), which recognizes formal indicators of subordination/co-ordination, such as conjunctions, subjunctions, and punctuation. 3.1 Syntactic Labelling and the Underlying Corpus The syntactic analysis is completed through the recognition of a variety of phrasal constituents, sentential clauses, and subclauses. We follow the proposal defined by the EAGLES (1996), Syntactic Annotation Group, which recognizes a number of syntactic, metasymbolic categories that are subsumed in most current categories of constituency-based syntactic annotation. The labelled bracketing consist</context>
</contexts>
<marker>Magerman, Marcus, 1990</marker>
<rawString>Magerman, D.M. and Marcus, M.P. 1990. Parsing a Natural Language Using Mutual Information Statistics, In Proceedings of AAAI &apos;90, Boston, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Nagao</author>
</authors>
<title>Are the Grammars so far Developed Appropriate to Recognize the Real Structure of a Sentence?,</title>
<date>1992</date>
<booktitle>In Proceedings of 4th TMI,</booktitle>
<pages>127--137</pages>
<location>Montréal, Canada,</location>
<contexts>
<context position="8160" citStr="Nagao, 1992" startWordPosition="1219" endWordPosition="1220">ngle, deterministic, finite-state, level recognizer, (Abney, 1996). Moreover, there is also the possibility of grouping words and/or part-of-speech tags using morphological and semantic criteria. 3.2 Grammar Rules Some of the most important groups include: • Noun Phrases, Grammaro: the number of patterns in grammar° is 180, divided in six different groups, depending on the length and complexity of the patterns. A large number of (parallel) coordination rules are also implemented at this level, depending on the similarity of the conjuncts with respect to several different characteristics, (cf. Nagao, 1992). • Prepositional Phrases, Grammari: the majority of prepositional phrases are noun 246 Proceedings of EACL &apos;99 phrases preceded by a preposition. Trapped adverbials, belonging to the noun phrase and not identified while applying grammar°, are merged within the up. Both simple and multiword prepositions are used. • Verbal Groups, Grammar2: identifies and labels phrasal, non-phrasal, and complex verbal formations. The rules allow for any number of auxiliary verbs, possible intervening adverbs, and end with a main verb or particle. A distinction is made between finite/infinite active/passive ver</context>
</contexts>
<marker>Nagao, 1992</marker>
<rawString>Nagao, M. 1992. Are the Grammars so far Developed Appropriate to Recognize the Real Structure of a Sentence?, In Proceedings of 4th TMI, Montréal, Canada, pp. 127-137.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Rauch</author>
</authors>
<title>Automatisk igenkanning av nominalfraser i lopande text,</title>
<date>1993</date>
<booktitle>In Proceedings of the 9th</booktitle>
<pages>207--215</pages>
<editor>NODALIDA, Eklund, R., editor,</editor>
<note>(in Swedish).</note>
<contexts>
<context position="3870" citStr="Rauch, 1993" startWordPosition="590" endWordPosition="591">rom Ejerhed &amp; Church (1983). Unfortunately, the lexicon and the rules were designed to parse a very limited set of sentences. In Ejerhed (1985), a very 245 Proceedings of EACL &apos;99 general description of Swedish grammar was presented. Its algorithmic details were unclear, and we are unaware of any descriptions in the literature of large scale applications or implementations of the models presented. It seems to us that Swedish language researchers are satisfied with the description and, apparently, the implementation on a small scale of finite-state methods for noun phrases only, (Cooper, 1984; Rauch, 1993). However, large scale grammars for Swedish do exist, employing other approaches to parsing, either radically different, such as the Swedish Core Language Engine, (Gamback &amp; Rayner, 1992), or slightly different, such as the Swedish Constraint Grammar, (Birn, 1998). 2.3 Pre-Processing By pre-processing we mean: (i) the recognition of multi-word tokens, phrasal verbs and idioms; (ii) sentence segmentation; (iii) part-of-speech tagging using Brill&apos;s (1994) part-of-speech tagger, and the EAGLES tagset for Swedish, (JohanssonKokkinakis &amp; Kokkinakis, 1996). The general accuracy of the tagger is at t</context>
</contexts>
<marker>Rauch, 1993</marker>
<rawString>Rauch, B. 1993. Automatisk igenkanning av nominalfraser i lopande text, In Proceedings of the 9th NODALIDA, Eklund, R., editor, pp. 207-215, (in Swedish).</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Roche</author>
</authors>
<title>Parsing with Finite-State Transducers,</title>
<date>1996</date>
<pages>96--30</pages>
<contexts>
<context position="2376" citStr="Roche (1996)" startWordPosition="340" endWordPosition="341">erving legitimately adjacent, part-of-speech chains, and how and which function words signal boundaries between phrasal constituents and clauses. 2 Background 2.1 Cascaded Finite-State Automata Finite-state technology has had a great impact on a variety of Natural Language Processing applications, as well as in industrial and academic Language Engineering. Attractive properties, such as conceptual simplicity, flexibility, and space and time efficiency, have motivated researchers to create grammars for natural language using finitestate methods: Koskenniemi et al. (1992); Appelt et at. (1993); Roche (1996); Roche &amp; Schabes (1997). The cascaded, finite-state mechanism we use in this work is described in Abney (1997): &amp;quot;...a finite-state cascade consists of a sequence of strata, each stratum being defined by a set of regular-expression patterns for recognizing phrases. [..] The output of stratum 0 consists of parts of speech. The patterns at level l are applied to the output of level l-1 in the manner of a lexical analyzer [...] longest match is selected (ties being resolved in favour of the first pattern listed), the matched input symbols are consumed from the input, the category of the matched p</context>
</contexts>
<marker>Roche, 1996</marker>
<rawString>Roche, E. 1996. Parsing with Finite-State Transducers, http://www.merl-com/reports/TR96-30. Visited 12/03/99.</rawString>
</citation>
<citation valid="true">
<date>1997</date>
<booktitle>FiniteState Language Processing,</booktitle>
<editor>Roche, E. and Schabes, Y., editors,</editor>
<publisher>MIT Press.</publisher>
<contexts>
<context position="2400" citStr="(1997)" startWordPosition="345" endWordPosition="345">part-of-speech chains, and how and which function words signal boundaries between phrasal constituents and clauses. 2 Background 2.1 Cascaded Finite-State Automata Finite-state technology has had a great impact on a variety of Natural Language Processing applications, as well as in industrial and academic Language Engineering. Attractive properties, such as conceptual simplicity, flexibility, and space and time efficiency, have motivated researchers to create grammars for natural language using finitestate methods: Koskenniemi et al. (1992); Appelt et at. (1993); Roche (1996); Roche &amp; Schabes (1997). The cascaded, finite-state mechanism we use in this work is described in Abney (1997): &amp;quot;...a finite-state cascade consists of a sequence of strata, each stratum being defined by a set of regular-expression patterns for recognizing phrases. [..] The output of stratum 0 consists of parts of speech. The patterns at level l are applied to the output of level l-1 in the manner of a lexical analyzer [...] longest match is selected (ties being resolved in favour of the first pattern listed), the matched input symbols are consumed from the input, the category of the matched pattern is produced as ou</context>
</contexts>
<marker>1997</marker>
<rawString>Roche, E. and Schabes, Y., editors, 1997. FiniteState Language Processing, MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Sekine</author>
<author>M J Collins</author>
</authors>
<date>1997</date>
<booktitle>The evalb Software, http://cs.nyu.edu/cs/projects/proteus/ evalb. Visited</booktitle>
<pages>14--12</pages>
<contexts>
<context position="11240" citStr="Sekine &amp; Collins, 1997" startWordPosition="1670" endWordPosition="1673">TIME, SUBJ(ect) and P-OBJ(ect). 4 Evaluation The performance of the parser partly depends on the output of the tagger and the rest of the preprocessing software. Our way of dealing with how &amp;quot;correct&amp;quot; the performance of the parser is, follows a practical, pragmatic approach, based on consultation of modern Swedish syntax literature. We use the metrics: precision (P), recall (R), F-value (F) and cross-bracketed rate. F = (02+1) PR/02 P+R, where 13 is a parameter encoding the relative importance of (R) and (P); here 0=1. Evaluation is performed automatically using the evalb evaluation software, (Sekine &amp; Collins, 1997). 4.1 &apos;Gold Standard&apos; and Error Analysis For the evaluation of Cass-SWE we use three types of texts: (i) a sample taken from a manually annotated Swedish corpus of 100,000 words with grammatical information (SynTag, Jarborg, 1990); (ii)- newspaper material; and (iii) a test suite, for non-common constructions, by consulting Swedish syntax literature. Texts (ii) and (iii) were annotated manually. The total number of tokens was 1,500 and sentences 117. The evaluation results are given in Table (1), for both noun phrases (NPs), and full chunk parsing (All). The errors found can be divided into: (</context>
</contexts>
<marker>Sekine, Collins, 1997</marker>
<rawString>Sekine, S. and Collins, M.J. 1997. The evalb Software, http://cs.nyu.edu/cs/projects/proteus/ evalb. Visited 14/12/97.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Voutilainen</author>
</authors>
<title>Does Tagging Help Parsing? A Case Study on Finite State Parsing,</title>
<date>1998</date>
<booktitle>In Proceedings of the FSMNLP &apos;98,</booktitle>
<location>Ankara, Turkey.</location>
<contexts>
<context position="4630" citStr="Voutilainen, 1998" startWordPosition="700" endWordPosition="701">ore Language Engine, (Gamback &amp; Rayner, 1992), or slightly different, such as the Swedish Constraint Grammar, (Birn, 1998). 2.3 Pre-Processing By pre-processing we mean: (i) the recognition of multi-word tokens, phrasal verbs and idioms; (ii) sentence segmentation; (iii) part-of-speech tagging using Brill&apos;s (1994) part-of-speech tagger, and the EAGLES tagset for Swedish, (JohanssonKokkinakis &amp; Kokkinakis, 1996). The general accuracy of the tagger is at the 96% level, (98,7% for the evaluation presented in table (1)). Tagging errors do not influence critically the performance of Cass-SWE1 (cf. Voutilainen, 1998); (iv) semantic inheritance in the form of NE labels: time sequences, locations, persons, organizations, communication and transportation means, money expressions and body-part. The recognition is performed using finite-state recognizers based on trigger words, typical contexts, and typical predicates associated with the entities. The performance of the NE recognition for Swedish is 97.4% precision, and 93.5% recall, tested within the AVENTINUS2 domain. Cass-SWE has been integrated in the General Architecture for Text Engineering (GATE), Cunningham et al. (1996). 3 The Grammar Framework The Sw</context>
</contexts>
<marker>Voutilainen, 1998</marker>
<rawString>Voutilainen, A. 1998. Does Tagging Help Parsing? A Case Study on Finite State Parsing, In Proceedings of the FSMNLP &apos;98, Ankara, Turkey.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>