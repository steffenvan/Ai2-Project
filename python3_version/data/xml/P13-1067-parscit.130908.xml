<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000479">
<title confidence="0.9735635">
Multilingual Affect Polarity and Valence Prediction in Metaphor-Rich
Texts
</title>
<author confidence="0.95926">
Zornitsa Kozareva
</author>
<affiliation confidence="0.91441">
USC Information Sciences Institute
</affiliation>
<address confidence="0.8787865">
4676 Admiralty Way
Marina del Rey, CA 90292-6695
</address>
<email confidence="0.99935">
kozareva@isi.edu
</email>
<sectionHeader confidence="0.99391" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999916392857143">
Metaphor is an important way of convey-
ing the affect of people, hence understand-
ing how people use metaphors to convey
affect is important for the communication
between individuals and increases cohe-
sion if the perceived affect of the con-
crete example is the same for the two in-
dividuals. Therefore, building computa-
tional models that can automatically iden-
tify the affect in metaphor-rich texts like
“The team captain is a rock.”, “Time is
money.”, “My lawyer is a shark.” is an
important challenging problem, which has
been of great interest to the research com-
munity.
To solve this task, we have collected
and manually annotated the affect of
metaphor-rich texts for four languages.
We present novel algorithms that integrate
triggers for cognitive, affective, perceptual
and social processes with stylistic and lex-
ical information. By running evaluations
on datasets in English, Spanish, Russian
and Farsi, we show that the developed af-
fect polarity and valence prediction tech-
nology of metaphor-rich texts is portable
and works equally well for different lan-
guages.
</bodyText>
<sectionHeader confidence="0.999329" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99270096875">
Metaphor is a figure of speech in which a word
or phrase that ordinarily designates one thing is
used to designate another, thus making an implicit
comparison (Lakoff and Johnson, 1980; Martin,
1988; Wilks, 2007). For instance, in
“My lawyer is a shark”
the speaker may want to communicate that his/her
lawyer is strong and aggressive, and that he will
attack in court and persist until the goals are
achieved. By using the metaphor, the speaker ac-
tually conveys positive affect because having an
aggressive lawyer is good if one is being sued.
There has been a substantial body of work on
metaphor identification and interpretation (Wilks,
2007; Shutova et al., 2010). However, in this
paper we focus on an equally interesting, chal-
lenging and important problem, which concerns
the automatic identification of affect carried by
metaphors. Building such computational mod-
els is important to understand how people use
metaphors to convey affect and how affect is ex-
pressed using metaphors. The existence of such
models can be also used to improve the communi-
cation between individuals and to make sure that
the speakers perceived the affect of the concrete
metaphor example in the same way.
The questions we address in this paper are:
“How can we build computational models that can
identify the polarity and valence associated with
metaphor-rich texts?” and “Is it possible to build
such automatic models for multiple languages?”.
Our main contributions are:
</bodyText>
<listItem confidence="0.999512533333333">
• We have developed multilingual metaphor-
rich datasets in English, Spanish, Russian and
Farsi that contain annotations of the Positive
and Negative polarity and the valence (from
−3 to +3 scale) corresponding to the inten-
sity of the affect conveyed in the metaphor.
• We have proposed and developed automated
methods for solving the polarity and valence
tasks for all four languages. We model
the polarity task as a classification problem,
while the valence task as a regression prob-
lem.
• We have studied the influence of different in-
formation sources like the metaphor itself,
the context in which it resides, the source and
</listItem>
<page confidence="0.966872">
682
</page>
<note confidence="0.9136945">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 682–691,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.972688058823529">
target domains of the metaphor, in addition to
contextual features and trigger word lists de-
veloped by psychologists (Tausczik and Pen-
nebaker, 2010).
• We have conducted in depth experimental
evaluation and showed that the developed
methods significantly outperform baseline
methods.
The rest of the paper is organized as follows.
Section 2 describes related work, Section 3 briefly
talks about metaphors. Sections 4 and 5 describe
the polarity classification and valence prediction
tasks for affect of metaphor-rich texts. Both sec-
tions have information on the collected data for
English, Spanish, Russian and Farsi, the con-
ducted experiments and obtained results. Finally,
we conclude in Section 6.
</bodyText>
<sectionHeader confidence="0.999812" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999953195121951">
A substantial body of work has been done on de-
termining the affect (sentiment analysis) of texts
(Kim and Hovy, 2004; Strapparava and Mihalcea,
2007; Wiebe and Cardie, 2005; Yessenalina and
Cardie, 2011; Breck et al., 2007). Various tasks
have been solved among which polarity and va-
lence identification are the most common. While
polarity identification aims at finding the Positive
and Negative affect, valence is more challenging
as it has to map the affect on a [−3,+3] scale
depending on its intensity (Polanyi and Zaenen,
2004; Strapparava and Mihalcea, 2007).
Over the years researchers have developed vari-
ous approaches to identify polarity of words (Esuli
and Sebastiani, 2006), phrases (Turney, 2002; Wil-
son et al., 2005), sentences (Choi and Cardie,
2009) even documents (Pang and Lee, 2008).
Multiple techniques have been employed, from
various machine learning classifiers, to clustering
and topic models. Various domains and textual
sources have been analyzed such as Twitter, Blogs,
Web documents, movie and product reviews (Tur-
ney, 2002; Kennedy and Inkpen, 2005; Niu et al.,
2005; Pang and Lee, 2008), but yet what is miss-
ing is affect analyzer for metaphor-rich texts.
While the affect of metaphors is well stud-
ied from its linguistic and psychological aspects
(Blanchette et al., 2001; Tomlinson and Love,
2006; Crawdord, 2009), to our knowledge the
building of computational models for polarity and
valence identification in metaphor-rich texts is still
a novel task (Smith et al., 2007; Veale, 2012; Veale
and Li, 2012; Reyes and Rosso, 2012; Reyes et
al., 2013). Little (almost no) effort has been put
into multilingual computational affect models of
metaphor-rich texts. Our research specifically tar-
gets the resolution of these problems and shows
that it is possible to build such computational mod-
els. The experimental result provide valuable con-
tributions and fundings, which could be used by
the research community to build upon.
</bodyText>
<sectionHeader confidence="0.995564" genericHeader="method">
3 Metaphors
</sectionHeader>
<bodyText confidence="0.999941594594594">
Although there are different views on metaphor in
linguistics and philosophy (Black, 1962; Lakoff
and Johnson, 1980; Gentner, 1983; Wilks, 2007),
the common among all approaches is the idea of
an interconceptual mapping that underlies the pro-
duction of metaphorical expressions. There are
two concepts or conceptual domains: the target
(also called topic in the linguistics literature) and
the source (or vehicle), and the existence of a link
between them gives rise to metaphors.
The texts “Your claims are indefensible.” and
“He attacked every weak point in my argument.”
do not directly talk about argument as a war, how-
ever the winning or losing of arguments, the attack
or defense of positions are structured by the con-
cept of war. There is no physical battle, but there
is a verbal battle and the structure of an argument
(attack, defense) reflects this (Lakoff and Johnson,
1980).
As we mentioned before, there has been a lot of
work on the automatic identification of metaphors
(Wilks, 2007; Shutova et al., 2010) and their
mapping into conceptual space (Shutova, 2010a;
Shutova, 2010b), however these are beyond the
scope of this paper. Instead we focus on an equally
interesting, challenging and important problem,
which concerns the automatic identification of af-
fect carried by metaphors. To conduct our study,
we use human annotators to collect metaphor-rich
texts (Shutova and Teufel, 2010) and tag each
metaphor with its corresponding polarity (Posi-
tive/Negative) and valence [−3,+3] scores. The
next sections describe the affect polarity and va-
lence tasks we have defined, the collected and an-
notated metaphor-rich data for each one of the En-
glish, Spanish, Russian and Farsi languages, the
conducted experiments and obtained results.
</bodyText>
<page confidence="0.999502">
683
</page>
<sectionHeader confidence="0.976971" genericHeader="method">
4 Task A: Polarity Classification
</sectionHeader>
<subsectionHeader confidence="0.994978">
4.1 Problem Formulation
</subsectionHeader>
<bodyText confidence="0.956602076923077">
Task Definition: Given metaphor-rich texts annotated with
Positive and Negative polarity labels, the goal is to build an
automated computational affect model, which can assign to
previously unseen metaphors one of the two polarity classes.
Thirty percent of our mortgages are
underwater.
a tough pill to
swallow
values that gave our
nation birth
The administration, in fact, could go
further with the budget knife by
eliminating the V-22 Osprey aircraft
</bodyText>
<figureCaption confidence="0.999179">
Figure 1: Polarity Classification
</figureCaption>
<bodyText confidence="0.963733625">
Figure 1 illustrates the polarity task in which the
metaphors were classified into Positive or Nega-
tive. For instance, the metaphor “tough pill to
swallow” has Negative polarity as it stands for
something being hard to digest or comprehend,
while the metaphor “values that gave our nation
birth” has a Positive polarity as giving birth is like
starting a new beginning.
</bodyText>
<subsectionHeader confidence="0.993653">
4.2 Classification Algorithms
</subsectionHeader>
<bodyText confidence="0.999778764705882">
We model the metaphor polarity task as a classifi-
cation problem in which, for a given collection of
N training examples, where mi is a metaphor and
ci is the polarity of mi, the objective is to learn
a classification function f : mi → ci in which 1
stands for positive polarity and 0 stands for neg-
ative polarity. We tested five different machine
learning algorithms such as Nave Bayes, SVM
with polynomial kernel, SVM with RBF kernel,
AdaBoost and Stacking, out of which AdaBoost
performed the best. In our experimental study, we
use the freely available implementations in Weka
(Witten and Frank, 2005).
Evaluation Measures: To evaluate the goodness
of the polarity classification algorithms, we cal-
culate the f-score and accuracy on 10-fold cross
validation.
</bodyText>
<subsectionHeader confidence="0.998752">
4.3 Data Annotation
</subsectionHeader>
<bodyText confidence="0.992794333333333">
To conduct our experimental study, we have used
annotated data provided by the Language Com-
puter Corporation (LCC)1, which developed anno-
</bodyText>
<footnote confidence="0.941201">
1http://www.languagecomputer.com/
</footnote>
<bodyText confidence="0.998493232142858">
tation toolkit specifically for the task of metaphor
detection, interpretation and affect assignment.
They hired annotators to collect and annotate data
for the English, Spanish, Russian and Farsi lan-
guages. The domain for which the metaphors were
collected was Governance. It encompasses elec-
toral politics, the setting of economic policy, the
creation, application and enforcement of rules and
laws. The metaphors were collected from polit-
ical speeches, political websites, online newspa-
pers among others (Mohler et al., 2013).
The annotation toolkit allowed annotators to
provide for each metaphor the following infor-
mation: the metaphor, the context in which the
metaphor was found, the meaning of the metaphor
in the source and target domains from the per-
spective of a native speaker. For example, in the
Context: And to all nations, we will speak for the
values that gave our nation birth.; the annotators
tagged the Metaphor: values that gave our nation
birth; and listed as Source: mother gave birth to
baby; and Target: values of freedom and equal-
ity motivated the creation of America. The same
annotators also provided the affect associated with
the metaphor. The agreements of the annotators as
measured by LCC are: .83, .87, .80 and .61 for the
English, Spanish, Russian and Farsi languages.
In our study, the maximum length of a metaphor
is a sentence, but typically it has the span of a
phrase. The maximum length of a context is three
sentences before and after the metaphor, but typ-
ically it has the span of one sentence before and
after. In our study, the source and target domains
are provided by the human annotators who agree
on these definitions, however the source and target
can be also automatically generated by an inter-
pretation system or a concept mapper. The gen-
eration of source and target information is beyond
the scope of this paper, but studying their impact
on affect is important. At the same time, we want
to show that if the technology for source/target de-
tection and interpretation is not yet available, then
how far can one reach by using the metaphor itself
and the context around it. Later depending on the
availability of the information sources and toolkits
one can decide whether to integrate such informa-
tion or to ignore it. In the experimental sections,
we show how the individual information sources
and their combination affects the resolution of the
metaphor polarity and valence prediction tasks.
Table 1 shows the positive and negative class
Clinton also came into office hoping
to bridge Washington’s partisan
divide.
the &apos;things&apos; are going to make
sure their ox doesn&apos;t get gored
</bodyText>
<page confidence="0.996102">
684
</page>
<bodyText confidence="0.509838">
distribution for each one of the four languages.
</bodyText>
<table confidence="0.9959674">
Negative Positive
ENGLISH 2086 1443
SPANISH 196 434
RUSSIAN 468 418
FARSI 384 252
</table>
<tableCaption confidence="0.9238485">
Table 1: Polarity Class Distribution for Four Lan-
guages
</tableCaption>
<bodyText confidence="0.9984124">
The majority of the the annotated examples are
for English. However, given the difficulty of find-
ing bilingual speakers, we still managed to collect
around 600 examples for Spanish and Farsi, and
886 examples for Russian.
</bodyText>
<subsectionHeader confidence="0.998989">
4.4 N-gram Evaluation and Results
</subsectionHeader>
<bodyText confidence="0.999938416666667">
N-gram features are widely used in a variety of
classification tasks, therefore we also use them in
our polarity classification task. We studied the in-
fluence of unigrams, bigrams and a combination
of the two, and saw that the best performing fea-
ture set consists of the combination of unigrams
and bigrams. In this paper, we will refer from now
on to n-grams as the combination of unigrams and
bigrams.
Figure 2 shows a study of the influence of the
different information sources and their combina-
tion with n-gram features for English.
</bodyText>
<figure confidence="0.9981731">
1
.90
.80
.70
.60
.50
.40
.30
.70
.10
</figure>
<figureCaption confidence="0.996197">
Figure 2: Influence of Information Sources for
Metaphor Polarity Classification of English Texts
</figureCaption>
<bodyText confidence="0.9997058">
For each information source (metaphor, context,
source, target and their combinations), we built a
separate n-gram feature set and model, which was
evaluated on 10-fold cross validation. The results
from this study show that for English, the more
information sources one combines, the higher the
classification accuracy becomes.
Table 2 shows the influence of the information
sources for Spanish, Russian and Farsi with the n-
gram features. The best f-scores for each language
are shown in bold. For Farsi and Russian high per-
formances are obtained both with the context and
with the combination of the context, source and
target information. While for Spanish they reach
similar performance.
</bodyText>
<table confidence="0.99603725">
SPANISH RUSSIAN FARSI
Metaphor 71.6 71.0 62.4
Source 67.1 62.4 55.4
Target 68.9 67.2 62.4
Context 73.5 77.1 67.4
S+T 76.6 68.7 62.4
M+S+T 76.0 75.4 64.2
C+S+T 76.5 76.5 68.4
</table>
<tableCaption confidence="0.988433">
Table 2: N-gram features, F-scores on 10-fold val-
idation for Spanish, Russian and Farsi
</tableCaption>
<subsectionHeader confidence="0.931547">
4.5 LIWC as a Proxy for Metaphor Polarity
</subsectionHeader>
<bodyText confidence="0.999595903225807">
LIWC Repository: In addition to the n-gram
features, we also used the Linguistic Inquiry and
Word Count (LIWC) repository (Tausczik and
Pennebaker, 2010), which has 64 word categories
corresponding to different classes like emotional
states, psychological processes, personal concerns
among other. Each category contains a list of
words characterizing it. For instance, the LIWC
category discrepancy contains words like should,
could among others, while the LIWC category in-
hibition contains words like block, stop, constrain.
Previously LIWC was successfully used to ana-
lyze the emotional state of bloggers and tweeters
(Quercia et al., 2011) and to identify deception and
sarcasm in texts (Ott et al., 2011; Gonz´alez-Ib´a˜nez
et al., 2011). When LIWC analyzes texts it gener-
ates statistics like number of words found in cat-
egory Ci divided by the total number of words in
the text. For our metaphor polarity task, we use
LIWC’s statistics of all 64 categories and feed this
information as features for the machine learning
classifiers. LIWC repository contains conceptual
categories (dictionaries) both for the English and
Spanish languages.
LIWC Evaluation and Results: In our experi-
ments LIWC is applied to English and Spanish
metaphor-rich texts since the LIWC category dic-
tionaries are available for both languages. Table 3
shows the obtained accuracy and f-score results in
English and Spanish for each one of the informa-
tion sources.
</bodyText>
<page confidence="0.990226">
685
</page>
<table confidence="0.968434461538462">
present tense
persona/ pronouns
fami/y category
socia/ presence
ENGLISH SPANISH
Acc Fscore Acc Fscore
Metaphor 98.8 98.8 87.9 87.2
Source 98.6 98.6 97.3 97.3
Target 98.2 98.2 97.9 97.9
Context 91.4 91.4 93.3 93.2
S+T 98.0 98.0 76.3 75.5
M+S+T 95.8 95.7 86.8 86.0
C+S+T 87.9 88.0 79.2 78.5
</table>
<tableCaption confidence="0.78067">
Table 3: LIWC features, Accuracy and F-scores
on 10-fold validation for English and Spanish
</tableCaption>
<bodyText confidence="0.997086782608696">
The best performances are reached with indi-
vidual information sources like metaphor, context,
source or target instead of their combinations. The
classifiers obtain similar performance for both lan-
guages.
LIWC Category Relevance to Metaphor Polar-
ity: We also study the importance and relevance
of the LIWC categories for the metaphor polar-
ity task. We use information gain (IG) to mea-
sure the amount of information in bits about the
polarity class prediction, if the only information
available is the presence of a given LIWC cate-
gory (feature) and the corresponding polarity class
distribution. IG measures the expected reduction
in entropy (uncertainty associated with a random
feature) (Mitchell, 1997).
Figure 3 illustrates how certain categories occur
more with the positive (in red color) vs negative
(in green color) class. With the positive metaphors
we observe the LIWC categories for present tense,
social, affect and family, while for the negative
metaphors we see LIWC categories for past tense,
inhibition and anger.
</bodyText>
<figure confidence="0.920935">
1
0
_1
</figure>
<figureCaption confidence="0.95307">
Figure 3: LIWC category relevance to Metaphor
Polarity
</figureCaption>
<bodyText confidence="0.949131333333333">
In addition, we show in Figure 4 examples of
the top LIWC categories according to IG ranking
for each one of the information sources.
</bodyText>
<figureCaption confidence="0.9623915">
Figure 4: Example of LIWC Categories and
Words
</figureCaption>
<bodyText confidence="0.999944375">
For metaphor texts, these categories are I, con-
juntion, anger, discrepancy, swear words among
others; for contexts the categories are pronouns
like I, you, past tense, friends, affect and so on.
Our study shows that some of the LIWC categories
are important across all information sources, but
overall different triggers activate depending on the
information source and the length of the text used.
</bodyText>
<subsectionHeader confidence="0.986664">
4.6 Comparative study
</subsectionHeader>
<bodyText confidence="0.999907214285714">
Figure 5 shows a comparison of the accuracy of
our best performing approach for each language.
For English and Spanish these are the LIWC mod-
els, while for Russian and Farsi these are the n-
gram models. We compare the performance of the
algorithms with a majority baseline, which assigns
the majority class to each example. For instance,
in English there are 3529 annotated examples, of
which 2086 are positive and 1443 are negative.
Since the positive class is the predominant one
for this language and dataset, a majority classifier
would have .59 accuracy in returning the positive
class as an answer. Similarly, we compute the ma-
jority baseline for the rest of the languages.
</bodyText>
<table confidence="0.9483564">
Accuracy Maj*rity Baseline Difference
English 98.80 59.11 +39.69
Spanish 97.90 68.88 +29.02
Russian 77.00 52.82 +24.18
Farsi 72.20 60.30 +11.90
</table>
<figureCaption confidence="0.864541">
Figure 5: Best Accuracy Model and Comparison
against a Majority Baseline for Metaphor Polarity
Classification
</figureCaption>
<bodyText confidence="0.9915915">
As we can see from Figure 5 that all classi-
fiers significantly outperform the majority base-
</bodyText>
<figure confidence="0.997734348837209">
6=&amp;quot;$( =&apos;(?6 =&apos;.7?
6=&amp;quot;$( 6
6&amp;&apos;.7?
+,(-.&amp;quot;/01-% /&apos;.7?
/0(2 &amp;&apos;&lt;&amp;quot;
!&amp;quot;#$%&amp;&apos;(
5+&amp;5@58&apos;+
(&amp;quot;7$895#:
5+1&amp;quot;6#
$+1&amp;quot;(
&amp;&apos;&lt;&amp;quot;
=&apos;(&gt;
/&apos;+34
4&amp;+%
2
5+&amp;5@58&apos;+
*&apos;+#&amp;quot;,#
!.,&amp;quot;1+
5+1&amp;quot;6#
$;&amp;quot;/#
=&apos;(&gt;
%&amp;&apos;
(0+
2
@7&apos;/&gt;
/&apos;+6#($5+
6#&apos;%
6=&amp;quot;$( =&apos;(?6
&amp;$#&amp;quot;
&gt;577
(895#:
$++&apos;:&amp;quot;?
.&amp;quot;#,3,&amp;1
-&apos;.(/&amp;quot;
(/0-&amp;quot;
0$(1&amp;quot;#
$+1&amp;quot;(
$;&amp;quot;/#
=&apos;(&gt;
/&apos;+34
past tense
3rd person
anger category
</figure>
<page confidence="0.996352">
686
</page>
<bodyText confidence="0.99970375">
line. For Farsi the increment is +11.90, while for
English the increment is +39.69. This means that
the built classifiers perform much better than a ran-
dom classifier.
</bodyText>
<subsectionHeader confidence="0.996779">
4.7 Lessons Learned
</subsectionHeader>
<bodyText confidence="0.999923190476191">
To summarize, in this section we have defined the
task of polarity classification and we have pre-
sented a machine learning solution. We have used
different feature sets and information sources to
solve the task. We have conducted exhaustive
evaluations for four different languages namely
English, Spanish, Russian and Farsi. The learned
lessons from this study are: (1) for n-gram us-
age, the larger the context of the metaphor, the
better the classification accuracy becomes; (2) if
present source and target information can further
boost the performance of the classifiers; (3) LIWC
is a useful resource for polarity identification in
metaphor-rich texts; (4) analyzing the usages of
tense like past vs. present and pronouns are im-
portant triggers for positive and negative polarity
of metaphors; (5) some categories like family, so-
cial presence indicate positive polarity, while oth-
ers like inhibition, anger and swear words are in-
dicative of negative affect; (6) the built models sig-
nificantly outperform majority baselines.
</bodyText>
<sectionHeader confidence="0.979094" genericHeader="method">
5 Task B: Valence Prediction
</sectionHeader>
<subsectionHeader confidence="0.973805">
5.1 Problem Formulation
</subsectionHeader>
<bodyText confidence="0.99544348">
Task Definition: Given metaphor-rich texts annotated
with valence score (from −3 to +3), where −3 indicates
strong negativity, +3 indicates strong positivity, 0 indi-
cates neural, the goal is to build a model that can predict
without human supervision the valence scores of new pre-
viously unseen metaphors.
Figure 6 shows an example of the valence pre-
diction task in which the metaphor-rich texts must
be arranged by the intensity of the emotional
state provoked by the texts. For instance, −3
corresponds to very strong negativity, −2 strong
negativity, −1 weak negativity (similarly for the
positive classes). In this task we also consider
metaphors with neutral affect. They are annotated
with the 0 label and the prediction model should be
able to predict such intensity as well. For instance,
the metaphor “values that gave our nation birth”,
is considered by American people that giving birth
sets new beginning and has a positive score +1,
but “budget knife” is more positive +3 since tax
cut is more important. As any sentiment analysis
task, affect assignment of metaphors is also a sub-
jective task and the produced annotations express
the values, believes and understanding of the an-
notators.
</bodyText>
<subsectionHeader confidence="0.897943">
5.2 Regression Model
</subsectionHeader>
<bodyText confidence="0.999166214285714">
We model the valence task a regression prob-
lem, in which for a given metaphor m, we seek
to predict the valence v of m. We do this via
a parametrized function f:ˆv = f(m; w), where
w E Rd are the weights. The objective is to
learn w from a collection of N training examples
{&lt; mi, vi &gt;}Ni_1, where mi are the metaphor ex-
amples and vi E R is the valence score of mi.
Support vector regression (Drucker et al., 1996)
is a well-known method for training a regression
model by solving the following optimization prob-
lem:
where C is a regularization constant and E controls
the training error. The training algorithm finds
weights w that define a function f minimizing the
empirical risk. Let h be a function from seeds into
some vector-space representation C_ Rd, then the
function f takes the form: f(m; w) = h(m)Tw =
ENi_1 αiK(m, mi), where f is re-parameterized
in terms of a polynomial kernel function K with
dual weights αi. K measures the similarity be-
tween two metaphoric texts. Full details of the
regression model and its implementation are be-
yond the scope of this paper; for more details see
(Sch¨olkopf and Smola, 2001; Smola et al., 2003).
In our experimental study, we use the freely avail-
able implementation of SVM in Weka (Witten and
Frank, 2005).
</bodyText>
<page confidence="0.790024">
-2
</page>
<bodyText confidence="0.985155571428572">
the &apos;things&apos; are going to make
sure their ox doesn&apos;t get gored
a tough pill to
swallow
The administration, in fact, could go
further with the budget knife by
eliminating the V-22 Osprey aircraft
</bodyText>
<figure confidence="0.712062583333333">
Clinton also came into office hoping
to bridge Washington’s partisan
divide.
values that gave our
nation birth
-3
-1
+3
+2
+1
Thirty percent of our mortgages are
underwater.
</figure>
<figureCaption confidence="0.998821">
Figure 6: Valence Prediction
</figureCaption>
<table confidence="0.84927">
min 2||w||2 + N N max(0, |vi − f(mi; w) |− E)
w∈Rs i=1 � N11 �
E-insensitive loss function
</table>
<page confidence="0.996694">
687
</page>
<bodyText confidence="0.994860625">
Evaluation Measures: To evaluate the quality of
the valence prediction model, we compare the ac-
tual valence score of the metaphor given by human
annotators denoted with y against those valence
scores predicted by the regression model denoted
with x. We estimate the goodness of the regres-
sion model calculating both the correlation coef-
ficientn P xiyi−P xi P yi
</bodyText>
<equation confidence="0.9543335">
ccx,y =
√
</equation>
<bodyText confidence="0.997497">
.
The two evaluation measures should be interpreted
in the following manner. Intuitively the higher the
correlation score is, the better the correlation be-
tween the actual and the predicted valence scores
will be. Similarly the smaller the mean squared
error rate, the better the regression model fits the
valence predictions to the actual score.
</bodyText>
<subsectionHeader confidence="0.994981">
5.3 Data Annotation
</subsectionHeader>
<bodyText confidence="0.9992272">
To conduct our valence prediction study, we used
the same human annotators from the polarity clas-
sification task for each one of the English, Span-
ish, Russian and Farsi languages. We asked the
annotators to map each metaphor on a [−3,+3]
scale depending on the intensity of the affect asso-
ciated with the metaphor.
Table 4 shows the distribution (number of ex-
amples) for each valence class and for each lan-
guage.
</bodyText>
<table confidence="0.9563194">
-3 -2 -1 0 +1 +2 +3
ENGLISH 1057 817 212 582 157 746 540
SPANISH 106 65 27 17 40 132 262
RUSSIAN 118 42 308 13 202 149 67
FARSI 147 117 120 49 91 63 98
</table>
<tableCaption confidence="0.9426245">
Table 4: Valence Score Distribution for Each Lan-
guage
</tableCaption>
<subsectionHeader confidence="0.999149">
5.4 Empirical Evaluation and Results
</subsectionHeader>
<bodyText confidence="0.999883928571428">
For each language and information source we built
separate valence prediction regression models. We
used the same features for the regression task as
we have used in the classification task. Those in-
clude n-grams (unigrams, bigrams and combina-
tion of the two), LIWC scores. Table 5 shows
the obtained correlation coefficient (CC) and mean
squared error (MSE) results for each one of the
four languages (English, Spanish, Russian and
Farsi) using the dataset described in Table 4.
The Farsi and Russian regression models are
based only on n-gram features, while the English
and Spanish regression models have both n-gram
and LIWC features. Overall, the CC for English
and Spanish is higher when LIWC features are
used. This means that the LIWC based valence re-
gression model approximates the predicted values
better to those of the human annotators. The better
valence prediction happens when the metaphor it-
self is used by LIWC. The MSE for English and
Spanish is the lowest, meaning that the predic-
tion is the closest to those of the human annota-
tors. In Russian and Farsi the lowest MSE is when
the combined metaphor, source and target infor-
mation sources are used. For English and Spanish
the smallest MSE or so called prediction error is
1.52 and 1.30 respectively, while for Russian and
Farsi is 1.62 and 2.13 respectively.
</bodyText>
<subsectionHeader confidence="0.996838">
5.5 Lessons Learned
</subsectionHeader>
<bodyText confidence="0.999958647058824">
To summarize, in this section we have defined
the task of valence prediction of metaphor-rich
texts and we have described a regression model
for its solution. We have studied different fea-
ture sets and information sources to solve the task.
We have conducted exhaustive evaluations in all
four languages namely English, Spanish, Russian
and Farsi. The learned lessons from this study
are: (1) valence prediction is a much harder task
than polarity classification both for human annota-
tion and for the machine learning algorithms; (2)
the obtained results showed that despite its dif-
ficulty this is still a plausible problem; (3) sim-
ilarly to the polarity classification task, valence
prediction with LIWC is improved when shorter
contexts (the metaphor/source/target information
source) are considered.
</bodyText>
<sectionHeader confidence="0.996154" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.9999658125">
People use metaphor-rich language to express af-
fect and often affect is expressed through the usage
of metaphors. Therefore, understanding that the
metaphor “I was boiling inside when I saw him.”
has Negative polarity as it conveys feeling of anger
is very important for interpersonal or multicultural
communications.
In this paper, we have introduced a novel corpus
of metaphor-rich texts for the English, Spanish,
Russian and Farsi languages, which was manu-
ally annotated with the polarity and valence scores
of the affect conveyed by the metaphors. We
have studied the impact of different information
sources such as the metaphor in isolation, the con-
text in which the metaphor was used, the source
and target domain meanings of the metaphor and
</bodyText>
<equation confidence="0.705317">
nP x2i −(P xi)2√nP y2i −(P yi)2
Pn
i=i(x−ˆx)
</equation>
<bodyText confidence="0.491527">
and the mean squared error msex,y = n
</bodyText>
<page confidence="0.973531">
688
</page>
<table confidence="0.999702444444444">
RUSSIAN N-gram FARSI N-gram ENGLISH N-gram SPANISH N-gram ENGLISH LIWC SPANISH LIWC
CC MSE CC MSE CC MSE CC MSE CC MSE CC MSE
Metaphor .45 1.71 .25 2.25 .36 2.50 .37 2.54 .74 1.52 .87 1.20
Source .22 1.89 .11 2.42 .40 2.27 .22 2.43 .81 1.30 .85 1.28
Target .25 1.91 .15 2.47 .37 2.41 .32 2.36 .72 1.56 .85 1.29
Context .43 1.83 .32 2.38 .37 2.59 .40 2.37 .40 2.16 .67 1.92
S+T .29 1.83 .18 2.38 .40 2.40 .41 2.19 .70 1.60 .78 1.53
M+S+T .45 1.62 .29 2.13 .43 2.34 .43 2.14 .67 1.67 .78 1.53
C+S+T .42 1.85 .26 2.61 .43 2.52 .39 2.41 .44 2.08 .64 1.96
</table>
<tableCaption confidence="0.959063">
Table 5: Valence Prediction, Correlation Coefficient and Mean Squared Error for English, Spanish, Rus-
sian and Farsi
</tableCaption>
<bodyText confidence="0.999479333333333">
their combination in order to understand how such
information helps and impacts the interpretation
of the affect associated with the metaphor. We
have conducted exhaustive evaluation with multi-
ple machine learning classifiers and different fea-
tures sets spanning from lexical information to
psychological categories developed by (Tausczik
and Pennebaker, 2010). Through experiments car-
ried out on the developed datasets, we showed that
the proposed polarity classification and valence
regression models significantly improve baselines
(from 11.90% to 39.69% depending on the lan-
guage) and work well for all four languages. From
the two tasks, the valence prediction problem was
more challenging both for the human annotators
and the automated system. The mean squared er-
ror in valence prediction in the range [−3,+3],
where −3 indicates strong negative and +3 indi-
cates strong positive affect for English, Spanish
and Russian was around 1.5, while for Farsi was
around 2.
The current findings and learned lessons reflect
the properties of the collected data and its anno-
tations. In the future we are interested in study-
ing the affect of metaphors for domains differ-
ent than Governance. We want to conduct stud-
ies with the help of social sciences who would re-
search whether the tagging of affect in metaphors
depends on the political affiliation, age, gender or
culture of the annotators. Not on a last place, we
would like to improve the built valence prediction
models and to collect more data for Spanish, Rus-
sian and Farsi.
</bodyText>
<sectionHeader confidence="0.998292" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99961275">
The author would like to thank the reviewers for
their helpful comments as well as the LCC anno-
tators who have prepared the data and made this
work possible. This research is supported by the
Intelligence Advanced Research Projects Activ-
ity (IARPA) via Department of Defense US Army
Research Laboratory contract number W911NF-
12-C-0025. The U.S. Government is authorized to
reproduce and distribute reprints for Governmen-
tal purposes notwithstanding any copyright anno-
tation thereon. Disclaimer: The views and con-
clusions contained herein are those of the authors
and should not be interpreted as necessarily rep-
resenting the official policies or endorsements, ei-
ther expressed or implied, of IARPA, DoD/ARL,
or the U.S. Government.
</bodyText>
<sectionHeader confidence="0.998877" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9985428">
Max Black. 1962. Models and Metaphors.
Isabelle Blanchette, Kevin Dunbar, John Hummel, and
Richard Marsh. 2001. Analogy use in naturalis-
tic settings: The influence of audience, emotion and
goals. Memory and Cognition, pages 730–735.
Eric Breck, Yejin Choi, and Claire Cardie. 2007. Iden-
tifying expressions of opinion in context. In Pro-
ceedings of the 20th international joint conference
on Artifical intelligence, IJCAI’07, pages 2683–
2688. Morgan Kaufmann Publishers Inc.
Yejin Choi and Claire Cardie. 2009. Adapting a po-
larity lexicon using integer linear programming for
domain-specific sentiment classification. In Pro-
ceedings of the 2009 Conference on Empirical Meth-
ods in Natural Language Processing: Volume 2 -
Volume 2, EMNLP ’09, pages 590–598.
Elizabeth Crawdord. 2009. Conceptual metaphors of
affect. Emotion Review, pages 129–139.
Harris Drucker, Chris J.C. Burges, Linda Kaufman,
Alex Smola, and Vladimir Vapnik. 1996. Support
vector regression machines. In Advances in NIPS,
pages 155–161.
Andrea Esuli and Fabrizio Sebastiani. 2006. Sen-
tiwordnet: A publicly available lexical resource
for opinion mining. In In Proceedings of the 5th
Conference on Language Resources and Evaluation
(LREC06, pages 417–422.
Dedre Gentner. 1983. Structure-mapping: A theo-
retical framework for analogy. Cognitive Science,
7(2):155–170.
</reference>
<page confidence="0.994523">
689
</page>
<reference confidence="0.999462846846847">
Roberto Gonz´alez-Ib´a˜nez, Smaranda Muresa n, and
Nina Wacholder. 2011. Identifying sarcasm in twit-
ter: a closer look. In Proceedings of the 49th An-
nual Meeting of the Association for Computational
Linguistics: Human Language Technologies: short
papers - Volume 2, HLT ’11, pages 581–586.
Alistair Kennedy and Diana Inkpen. 2005. Sentiment
classification of movie and product reviews using
contextual valence shifters. Computational Intelli-
gence, pages 110–125.
Soo-Min Kim and Eduard Hovy. 2004. Determin-
ing the sentiment of opinions. In Proceedings of
the 20th international conference on Computational
Linguistics, COLING ’04.
George Lakoff and Mark Johnson. 1980. Metaphors
We Live By. University of Chicago Press, Chicago.
James H. Martin. 1988. Representing regularities in
the metaphoric lexicon. In Proceedings of the 12th
conference on Computational linguistics - Volume 1,
COLING ’88, pages 396–401.
Thomas M. Mitchell. 1997. Machine Learning.
McGraw-Hill, Inc., 1 edition.
Michael Mohler, David Bracewell, David Hinote, and
Marc Tomlinson. 2013. Semantic signatures for
example-based linguistic metaphor detection. In
The Proceedings of the First Workshop on Metaphor
in NLP, (NAACL), pages 46–54.
Yun Niu, Xiaodan Zhu, Jianhua Li, and Graeme Hirst.
2005. Analysis of polarity information in medical
text. In In: Proceedings of the American Medical
Informatics Association 2005 Annual Symposium,
pages 570–574.
Myle Ott, Yejin Choi, Claire Cardie, and Jeffrey T.
Hancock. 2011. Finding deceptive opinion spam
by any stretch of the imagination. In Proceedings
of the 49th Annual Meeting of the Association for
Computational Linguistics: Human Language Tech-
nologies - Volume 1, HLT ’11, pages 309–319.
Bo Pang and Lillian Lee. 2008. Opinion mining and
sentiment analysis. Found. Trends Inf. Retr., 2(1-
2):1–135, January.
Livia Polanyi and Annie Zaenen. 2004. Contextual
lexical valence shifters. In Yan Qu, James Shana-
han, and Janyce Wiebe, editors, Proceedings of the
AAAI Spring Symposium on Exploring Attitude and
Affect in Text: Theories and Applications. AAAI
Press. AAAI technical report SS-04-07.
Daniele Quercia, Jonathan Ellis, Licia Capra, and Jon
Crowcroft. 2011. In the mood for being influential
on twitter. In the 3rd IEEE International Conference
on Social Computing.
Antonio Reyes and Paolo Rosso. 2012. Making ob-
jective decisions from subjective data: Detecting
irony in customer reviews. Decis. Support Syst.,
53(4):754–760, November.
Antonio Reyes, Paolo Rosso, and Tony Veale. 2013.
A multidimensional approach for detecting irony in
twitter. Lang. Resour. Eval., 47(1):239–268, March.
Bernhard Sch¨olkopf and Alexander J. Smola. 2001.
Learning with Kernels: Support Vector Machines,
Regularization, Optimization, and Beyond (Adap-
tive Computation and Machine Learning). The MIT
Press.
Ekaterina Shutova and Simone Teufel. 2010.
Metaphor corpus annotated for source - target do-
main mappings. In International Conference on
Language Resources and Evaluation.
Ekaterina Shutova, Lin Sun, and Anna Korhonen.
2010. Metaphor identification using verb and noun
clustering. In Proceedings of the 23rd International
Conference on Computational Linguistics, COLING
’10, pages 1002–1010.
Ekaterina Shutova. 2010a. Automatic metaphor in-
terpretation as a paraphrasing task. In Human Lan-
guage Technologies: The 2010 Annual Conference
of the North American Chapter of the Associa-
tion for Computational Linguistics, HLT ’10, pages
1029–1037.
Ekaterina Shutova. 2010b. Models of metaphor in nlp.
In Proceedings of the 48th Annual Meeting of the As-
sociation for Computational Linguistics, ACL ’10,
pages 688–697.
Catherine Smith, Tim Rumbell, John Barnden, Bob
Hendley, Mark Lee, and Alan Wallington. 2007.
Don’t worry about metaphor: affect extraction for
conversational agents. In Proceedings of the 45th
Annual Meeting of the ACL on Interactive Poster
and Demonstration Sessions, ACL ’07, pages 37–
40. Association for Computational Linguistics.
Alex J. Smola, Bernhard Schlkopf, and Bernhard Sch
Olkopf. 2003. A tutorial on support vector regres-
sion. Technical report, Statistics and Computing.
Carlo Strapparava and Rada Mihalcea. 2007. Semeval-
2007 task 14: Affective text. In Proceedings of the
Fourth International Workshop on Semantic Evalua-
tions (SemEval-2007), pages 70–74. Association for
Computational Linguistics, June.
Yla R. Tausczik and James W. Pennebaker. 2010. The
Psychological Meaning of Words: LIWC and Com-
puterized Text Analysis Methods. Journal of Lan-
guage and Social Psychology, 29(1):24–54, March.
Marc T. Tomlinson and Bradley C. Love. 2006. From
pigeons to humans: grounding relational learning in
concrete examples. In Proceedings of the 21st na-
tional conference on Artificial intelligence - Volume
1, AAAI’06, pages 199–204. AAAI Press.
Peter D. Turney. 2002. Thumbs up or thumbs down?:
semantic orientation applied to unsupervised classi-
fication of reviews. In Proceedings of the 40th An-
nual Meeting on Association for Computational Lin-
guistics, ACL ’02, pages 417–424.
</reference>
<page confidence="0.975085">
690
</page>
<reference confidence="0.986016676470589">
Tony Veale and Guofu Li. 2012. Specifying viewpoint
and information need with affective metaphors: a
system demonstration of the metaphor magnet web
app/service. In Proceedings of the ACL 2012 System
Demonstrations, ACL ’12, pages 7–12.
Tony Veale. 2012. A context-sensitive, multi-faceted
model of lexico-conceptual affect. In The 50th An-
nual Meeting of the Association for Computational
Linguistics, Proceedings of the Conference, pages
75–79.
Janyce Wiebe and Claire Cardie. 2005. Annotating
expressions of opinions and emotions in language.
language resources and evaluation. In Language
Resources and Evaluation (formerly Computers and
the Humanities.
Yorick Wilks. 2007. A preferential, pattern-seeking,
semantics for natural language inference. In Words
and Intelligence I, volume 35 of Text, Speech
and Language Technology, pages 83–102. Springer
Netherlands.
Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.
2005. Recognizing contextual polarity in phrase-
level sentiment analysis. In Proceedings of the con-
ference on Human Language Technology and Em-
pirical Methods in Natural Language Processing,
HLT ’05, pages 347–354.
Ian H. Witten and Eibe Frank. 2005. Data Mining:
Practical Machine Learning Tools and Techniques.
Morgan Kaufmann, second edition.
Ainur Yessenalina and Claire Cardie. 2011. Com-
positional matrix-space models for sentiment analy-
sis. In Proceedings of the Conference on Empirical
Methods in Natural Language Processing, EMNLP
’11, pages 172–182.
</reference>
<page confidence="0.998261">
691
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.746852">
<title confidence="0.994765">Multilingual Affect Polarity and Valence Prediction in Metaphor-Rich Texts</title>
<author confidence="0.940202">Zornitsa</author>
<affiliation confidence="0.990156">USC Information Sciences</affiliation>
<address confidence="0.985304">4676 Admiralty</address>
<author confidence="0.944973">Marina del Rey</author>
<author confidence="0.944973">CA</author>
<email confidence="0.99925">kozareva@isi.edu</email>
<abstract confidence="0.994924103448276">Metaphor is an important way of conveying the affect of people, hence understanding how people use metaphors to convey affect is important for the communication between individuals and increases cohesion if the perceived affect of the concrete example is the same for the two individuals. Therefore, building computational models that can automatically identify the affect in metaphor-rich texts like team captain is a is lawyer is a is an important challenging problem, which has been of great interest to the research community. To solve this task, we have collected and manually annotated the affect of metaphor-rich texts for four languages. We present novel algorithms that integrate triggers for cognitive, affective, perceptual and social processes with stylistic and lexical information. By running evaluations on datasets in English, Spanish, Russian and Farsi, we show that the developed affect polarity and valence prediction technology of metaphor-rich texts is portable and works equally well for different languages.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Max Black</author>
</authors>
<title>Models and Metaphors.</title>
<date>1962</date>
<contexts>
<context position="6340" citStr="Black, 1962" startWordPosition="995" endWordPosition="996">taphor-rich texts is still a novel task (Smith et al., 2007; Veale, 2012; Veale and Li, 2012; Reyes and Rosso, 2012; Reyes et al., 2013). Little (almost no) effort has been put into multilingual computational affect models of metaphor-rich texts. Our research specifically targets the resolution of these problems and shows that it is possible to build such computational models. The experimental result provide valuable contributions and fundings, which could be used by the research community to build upon. 3 Metaphors Although there are different views on metaphor in linguistics and philosophy (Black, 1962; Lakoff and Johnson, 1980; Gentner, 1983; Wilks, 2007), the common among all approaches is the idea of an interconceptual mapping that underlies the production of metaphorical expressions. There are two concepts or conceptual domains: the target (also called topic in the linguistics literature) and the source (or vehicle), and the existence of a link between them gives rise to metaphors. The texts “Your claims are indefensible.” and “He attacked every weak point in my argument.” do not directly talk about argument as a war, however the winning or losing of arguments, the attack or defense of </context>
</contexts>
<marker>Black, 1962</marker>
<rawString>Max Black. 1962. Models and Metaphors.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Isabelle Blanchette</author>
<author>Kevin Dunbar</author>
<author>John Hummel</author>
<author>Richard Marsh</author>
</authors>
<title>Analogy use in naturalistic settings: The influence of audience, emotion and goals. Memory and Cognition,</title>
<date>2001</date>
<pages>730--735</pages>
<contexts>
<context position="5585" citStr="Blanchette et al., 2001" startWordPosition="876" endWordPosition="879"> 2006), phrases (Turney, 2002; Wilson et al., 2005), sentences (Choi and Cardie, 2009) even documents (Pang and Lee, 2008). Multiple techniques have been employed, from various machine learning classifiers, to clustering and topic models. Various domains and textual sources have been analyzed such as Twitter, Blogs, Web documents, movie and product reviews (Turney, 2002; Kennedy and Inkpen, 2005; Niu et al., 2005; Pang and Lee, 2008), but yet what is missing is affect analyzer for metaphor-rich texts. While the affect of metaphors is well studied from its linguistic and psychological aspects (Blanchette et al., 2001; Tomlinson and Love, 2006; Crawdord, 2009), to our knowledge the building of computational models for polarity and valence identification in metaphor-rich texts is still a novel task (Smith et al., 2007; Veale, 2012; Veale and Li, 2012; Reyes and Rosso, 2012; Reyes et al., 2013). Little (almost no) effort has been put into multilingual computational affect models of metaphor-rich texts. Our research specifically targets the resolution of these problems and shows that it is possible to build such computational models. The experimental result provide valuable contributions and fundings, which c</context>
</contexts>
<marker>Blanchette, Dunbar, Hummel, Marsh, 2001</marker>
<rawString>Isabelle Blanchette, Kevin Dunbar, John Hummel, and Richard Marsh. 2001. Analogy use in naturalistic settings: The influence of audience, emotion and goals. Memory and Cognition, pages 730–735.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Breck</author>
<author>Yejin Choi</author>
<author>Claire Cardie</author>
</authors>
<title>Identifying expressions of opinion in context.</title>
<date>2007</date>
<booktitle>In Proceedings of the 20th international joint conference on Artifical intelligence, IJCAI’07,</booktitle>
<pages>2683--2688</pages>
<publisher>Morgan Kaufmann Publishers Inc.</publisher>
<contexts>
<context position="4505" citStr="Breck et al., 2007" startWordPosition="706" endWordPosition="709">s follows. Section 2 describes related work, Section 3 briefly talks about metaphors. Sections 4 and 5 describe the polarity classification and valence prediction tasks for affect of metaphor-rich texts. Both sections have information on the collected data for English, Spanish, Russian and Farsi, the conducted experiments and obtained results. Finally, we conclude in Section 6. 2 Related Work A substantial body of work has been done on determining the affect (sentiment analysis) of texts (Kim and Hovy, 2004; Strapparava and Mihalcea, 2007; Wiebe and Cardie, 2005; Yessenalina and Cardie, 2011; Breck et al., 2007). Various tasks have been solved among which polarity and valence identification are the most common. While polarity identification aims at finding the Positive and Negative affect, valence is more challenging as it has to map the affect on a [−3,+3] scale depending on its intensity (Polanyi and Zaenen, 2004; Strapparava and Mihalcea, 2007). Over the years researchers have developed various approaches to identify polarity of words (Esuli and Sebastiani, 2006), phrases (Turney, 2002; Wilson et al., 2005), sentences (Choi and Cardie, 2009) even documents (Pang and Lee, 2008). Multiple techniques</context>
</contexts>
<marker>Breck, Choi, Cardie, 2007</marker>
<rawString>Eric Breck, Yejin Choi, and Claire Cardie. 2007. Identifying expressions of opinion in context. In Proceedings of the 20th international joint conference on Artifical intelligence, IJCAI’07, pages 2683– 2688. Morgan Kaufmann Publishers Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yejin Choi</author>
<author>Claire Cardie</author>
</authors>
<title>Adapting a polarity lexicon using integer linear programming for domain-specific sentiment classification.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume</booktitle>
<volume>2</volume>
<pages>590--598</pages>
<contexts>
<context position="5048" citStr="Choi and Cardie, 2009" startWordPosition="791" endWordPosition="794">2007; Wiebe and Cardie, 2005; Yessenalina and Cardie, 2011; Breck et al., 2007). Various tasks have been solved among which polarity and valence identification are the most common. While polarity identification aims at finding the Positive and Negative affect, valence is more challenging as it has to map the affect on a [−3,+3] scale depending on its intensity (Polanyi and Zaenen, 2004; Strapparava and Mihalcea, 2007). Over the years researchers have developed various approaches to identify polarity of words (Esuli and Sebastiani, 2006), phrases (Turney, 2002; Wilson et al., 2005), sentences (Choi and Cardie, 2009) even documents (Pang and Lee, 2008). Multiple techniques have been employed, from various machine learning classifiers, to clustering and topic models. Various domains and textual sources have been analyzed such as Twitter, Blogs, Web documents, movie and product reviews (Turney, 2002; Kennedy and Inkpen, 2005; Niu et al., 2005; Pang and Lee, 2008), but yet what is missing is affect analyzer for metaphor-rich texts. While the affect of metaphors is well studied from its linguistic and psychological aspects (Blanchette et al., 2001; Tomlinson and Love, 2006; Crawdord, 2009), to our knowledge t</context>
</contexts>
<marker>Choi, Cardie, 2009</marker>
<rawString>Yejin Choi and Claire Cardie. 2009. Adapting a polarity lexicon using integer linear programming for domain-specific sentiment classification. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 2 -Volume 2, EMNLP ’09, pages 590–598.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elizabeth Crawdord</author>
</authors>
<title>Conceptual metaphors of affect. Emotion Review,</title>
<date>2009</date>
<pages>129--139</pages>
<contexts>
<context position="5628" citStr="Crawdord, 2009" startWordPosition="884" endWordPosition="885">, sentences (Choi and Cardie, 2009) even documents (Pang and Lee, 2008). Multiple techniques have been employed, from various machine learning classifiers, to clustering and topic models. Various domains and textual sources have been analyzed such as Twitter, Blogs, Web documents, movie and product reviews (Turney, 2002; Kennedy and Inkpen, 2005; Niu et al., 2005; Pang and Lee, 2008), but yet what is missing is affect analyzer for metaphor-rich texts. While the affect of metaphors is well studied from its linguistic and psychological aspects (Blanchette et al., 2001; Tomlinson and Love, 2006; Crawdord, 2009), to our knowledge the building of computational models for polarity and valence identification in metaphor-rich texts is still a novel task (Smith et al., 2007; Veale, 2012; Veale and Li, 2012; Reyes and Rosso, 2012; Reyes et al., 2013). Little (almost no) effort has been put into multilingual computational affect models of metaphor-rich texts. Our research specifically targets the resolution of these problems and shows that it is possible to build such computational models. The experimental result provide valuable contributions and fundings, which could be used by the research community to b</context>
</contexts>
<marker>Crawdord, 2009</marker>
<rawString>Elizabeth Crawdord. 2009. Conceptual metaphors of affect. Emotion Review, pages 129–139.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Harris Drucker</author>
<author>Chris J C Burges</author>
<author>Linda Kaufman</author>
<author>Alex Smola</author>
<author>Vladimir Vapnik</author>
</authors>
<title>Support vector regression machines.</title>
<date>1996</date>
<booktitle>In Advances in NIPS,</booktitle>
<pages>155--161</pages>
<contexts>
<context position="22437" citStr="Drucker et al., 1996" startWordPosition="3597" endWordPosition="3600">. As any sentiment analysis task, affect assignment of metaphors is also a subjective task and the produced annotations express the values, believes and understanding of the annotators. 5.2 Regression Model We model the valence task a regression problem, in which for a given metaphor m, we seek to predict the valence v of m. We do this via a parametrized function f:ˆv = f(m; w), where w E Rd are the weights. The objective is to learn w from a collection of N training examples {&lt; mi, vi &gt;}Ni_1, where mi are the metaphor examples and vi E R is the valence score of mi. Support vector regression (Drucker et al., 1996) is a well-known method for training a regression model by solving the following optimization problem: where C is a regularization constant and E controls the training error. The training algorithm finds weights w that define a function f minimizing the empirical risk. Let h be a function from seeds into some vector-space representation C_ Rd, then the function f takes the form: f(m; w) = h(m)Tw = ENi_1 αiK(m, mi), where f is re-parameterized in terms of a polynomial kernel function K with dual weights αi. K measures the similarity between two metaphoric texts. Full details of the regression m</context>
</contexts>
<marker>Drucker, Burges, Kaufman, Smola, Vapnik, 1996</marker>
<rawString>Harris Drucker, Chris J.C. Burges, Linda Kaufman, Alex Smola, and Vladimir Vapnik. 1996. Support vector regression machines. In Advances in NIPS, pages 155–161.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Esuli</author>
<author>Fabrizio Sebastiani</author>
</authors>
<title>Sentiwordnet: A publicly available lexical resource for opinion mining. In</title>
<date>2006</date>
<booktitle>In Proceedings of the 5th Conference on Language Resources and Evaluation (LREC06,</booktitle>
<pages>417--422</pages>
<contexts>
<context position="4968" citStr="Esuli and Sebastiani, 2006" startWordPosition="778" endWordPosition="781"> affect (sentiment analysis) of texts (Kim and Hovy, 2004; Strapparava and Mihalcea, 2007; Wiebe and Cardie, 2005; Yessenalina and Cardie, 2011; Breck et al., 2007). Various tasks have been solved among which polarity and valence identification are the most common. While polarity identification aims at finding the Positive and Negative affect, valence is more challenging as it has to map the affect on a [−3,+3] scale depending on its intensity (Polanyi and Zaenen, 2004; Strapparava and Mihalcea, 2007). Over the years researchers have developed various approaches to identify polarity of words (Esuli and Sebastiani, 2006), phrases (Turney, 2002; Wilson et al., 2005), sentences (Choi and Cardie, 2009) even documents (Pang and Lee, 2008). Multiple techniques have been employed, from various machine learning classifiers, to clustering and topic models. Various domains and textual sources have been analyzed such as Twitter, Blogs, Web documents, movie and product reviews (Turney, 2002; Kennedy and Inkpen, 2005; Niu et al., 2005; Pang and Lee, 2008), but yet what is missing is affect analyzer for metaphor-rich texts. While the affect of metaphors is well studied from its linguistic and psychological aspects (Blanch</context>
</contexts>
<marker>Esuli, Sebastiani, 2006</marker>
<rawString>Andrea Esuli and Fabrizio Sebastiani. 2006. Sentiwordnet: A publicly available lexical resource for opinion mining. In In Proceedings of the 5th Conference on Language Resources and Evaluation (LREC06, pages 417–422.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dedre Gentner</author>
</authors>
<title>Structure-mapping: A theoretical framework for analogy.</title>
<date>1983</date>
<journal>Cognitive Science,</journal>
<volume>7</volume>
<issue>2</issue>
<contexts>
<context position="6381" citStr="Gentner, 1983" startWordPosition="1001" endWordPosition="1002"> (Smith et al., 2007; Veale, 2012; Veale and Li, 2012; Reyes and Rosso, 2012; Reyes et al., 2013). Little (almost no) effort has been put into multilingual computational affect models of metaphor-rich texts. Our research specifically targets the resolution of these problems and shows that it is possible to build such computational models. The experimental result provide valuable contributions and fundings, which could be used by the research community to build upon. 3 Metaphors Although there are different views on metaphor in linguistics and philosophy (Black, 1962; Lakoff and Johnson, 1980; Gentner, 1983; Wilks, 2007), the common among all approaches is the idea of an interconceptual mapping that underlies the production of metaphorical expressions. There are two concepts or conceptual domains: the target (also called topic in the linguistics literature) and the source (or vehicle), and the existence of a link between them gives rise to metaphors. The texts “Your claims are indefensible.” and “He attacked every weak point in my argument.” do not directly talk about argument as a war, however the winning or losing of arguments, the attack or defense of positions are structured by the concept o</context>
</contexts>
<marker>Gentner, 1983</marker>
<rawString>Dedre Gentner. 1983. Structure-mapping: A theoretical framework for analogy. Cognitive Science, 7(2):155–170.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Gonz´alez-Ib´a˜nez</author>
<author>Smaranda Muresa n</author>
<author>Nina Wacholder</author>
</authors>
<title>Identifying sarcasm in twitter: a closer look.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers - Volume 2, HLT ’11,</booktitle>
<pages>581--586</pages>
<marker>Gonz´alez-Ib´a˜nez, n, Wacholder, 2011</marker>
<rawString>Roberto Gonz´alez-Ib´a˜nez, Smaranda Muresa n, and Nina Wacholder. 2011. Identifying sarcasm in twitter: a closer look. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers - Volume 2, HLT ’11, pages 581–586.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alistair Kennedy</author>
<author>Diana Inkpen</author>
</authors>
<title>Sentiment classification of movie and product reviews using contextual valence shifters.</title>
<date>2005</date>
<journal>Computational Intelligence,</journal>
<pages>110--125</pages>
<contexts>
<context position="5360" citStr="Kennedy and Inkpen, 2005" startWordPosition="837" endWordPosition="840">affect on a [−3,+3] scale depending on its intensity (Polanyi and Zaenen, 2004; Strapparava and Mihalcea, 2007). Over the years researchers have developed various approaches to identify polarity of words (Esuli and Sebastiani, 2006), phrases (Turney, 2002; Wilson et al., 2005), sentences (Choi and Cardie, 2009) even documents (Pang and Lee, 2008). Multiple techniques have been employed, from various machine learning classifiers, to clustering and topic models. Various domains and textual sources have been analyzed such as Twitter, Blogs, Web documents, movie and product reviews (Turney, 2002; Kennedy and Inkpen, 2005; Niu et al., 2005; Pang and Lee, 2008), but yet what is missing is affect analyzer for metaphor-rich texts. While the affect of metaphors is well studied from its linguistic and psychological aspects (Blanchette et al., 2001; Tomlinson and Love, 2006; Crawdord, 2009), to our knowledge the building of computational models for polarity and valence identification in metaphor-rich texts is still a novel task (Smith et al., 2007; Veale, 2012; Veale and Li, 2012; Reyes and Rosso, 2012; Reyes et al., 2013). Little (almost no) effort has been put into multilingual computational affect models of metap</context>
</contexts>
<marker>Kennedy, Inkpen, 2005</marker>
<rawString>Alistair Kennedy and Diana Inkpen. 2005. Sentiment classification of movie and product reviews using contextual valence shifters. Computational Intelligence, pages 110–125.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Soo-Min Kim</author>
<author>Eduard Hovy</author>
</authors>
<title>Determining the sentiment of opinions.</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th international conference on Computational Linguistics, COLING ’04.</booktitle>
<contexts>
<context position="4398" citStr="Kim and Hovy, 2004" startWordPosition="690" endWordPosition="693">that the developed methods significantly outperform baseline methods. The rest of the paper is organized as follows. Section 2 describes related work, Section 3 briefly talks about metaphors. Sections 4 and 5 describe the polarity classification and valence prediction tasks for affect of metaphor-rich texts. Both sections have information on the collected data for English, Spanish, Russian and Farsi, the conducted experiments and obtained results. Finally, we conclude in Section 6. 2 Related Work A substantial body of work has been done on determining the affect (sentiment analysis) of texts (Kim and Hovy, 2004; Strapparava and Mihalcea, 2007; Wiebe and Cardie, 2005; Yessenalina and Cardie, 2011; Breck et al., 2007). Various tasks have been solved among which polarity and valence identification are the most common. While polarity identification aims at finding the Positive and Negative affect, valence is more challenging as it has to map the affect on a [−3,+3] scale depending on its intensity (Polanyi and Zaenen, 2004; Strapparava and Mihalcea, 2007). Over the years researchers have developed various approaches to identify polarity of words (Esuli and Sebastiani, 2006), phrases (Turney, 2002; Wilso</context>
</contexts>
<marker>Kim, Hovy, 2004</marker>
<rawString>Soo-Min Kim and Eduard Hovy. 2004. Determining the sentiment of opinions. In Proceedings of the 20th international conference on Computational Linguistics, COLING ’04.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Lakoff</author>
<author>Mark Johnson</author>
</authors>
<title>Metaphors We Live By.</title>
<date>1980</date>
<publisher>University of Chicago Press,</publisher>
<location>Chicago.</location>
<contexts>
<context position="1473" citStr="Lakoff and Johnson, 1980" startWordPosition="225" endWordPosition="228">metaphor-rich texts for four languages. We present novel algorithms that integrate triggers for cognitive, affective, perceptual and social processes with stylistic and lexical information. By running evaluations on datasets in English, Spanish, Russian and Farsi, we show that the developed affect polarity and valence prediction technology of metaphor-rich texts is portable and works equally well for different languages. 1 Introduction Metaphor is a figure of speech in which a word or phrase that ordinarily designates one thing is used to designate another, thus making an implicit comparison (Lakoff and Johnson, 1980; Martin, 1988; Wilks, 2007). For instance, in “My lawyer is a shark” the speaker may want to communicate that his/her lawyer is strong and aggressive, and that he will attack in court and persist until the goals are achieved. By using the metaphor, the speaker actually conveys positive affect because having an aggressive lawyer is good if one is being sued. There has been a substantial body of work on metaphor identification and interpretation (Wilks, 2007; Shutova et al., 2010). However, in this paper we focus on an equally interesting, challenging and important problem, which concerns the a</context>
<context position="6366" citStr="Lakoff and Johnson, 1980" startWordPosition="997" endWordPosition="1000">exts is still a novel task (Smith et al., 2007; Veale, 2012; Veale and Li, 2012; Reyes and Rosso, 2012; Reyes et al., 2013). Little (almost no) effort has been put into multilingual computational affect models of metaphor-rich texts. Our research specifically targets the resolution of these problems and shows that it is possible to build such computational models. The experimental result provide valuable contributions and fundings, which could be used by the research community to build upon. 3 Metaphors Although there are different views on metaphor in linguistics and philosophy (Black, 1962; Lakoff and Johnson, 1980; Gentner, 1983; Wilks, 2007), the common among all approaches is the idea of an interconceptual mapping that underlies the production of metaphorical expressions. There are two concepts or conceptual domains: the target (also called topic in the linguistics literature) and the source (or vehicle), and the existence of a link between them gives rise to metaphors. The texts “Your claims are indefensible.” and “He attacked every weak point in my argument.” do not directly talk about argument as a war, however the winning or losing of arguments, the attack or defense of positions are structured b</context>
</contexts>
<marker>Lakoff, Johnson, 1980</marker>
<rawString>George Lakoff and Mark Johnson. 1980. Metaphors We Live By. University of Chicago Press, Chicago.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James H Martin</author>
</authors>
<title>Representing regularities in the metaphoric lexicon.</title>
<date>1988</date>
<booktitle>In Proceedings of the 12th conference on Computational linguistics - Volume 1, COLING ’88,</booktitle>
<pages>396--401</pages>
<contexts>
<context position="1487" citStr="Martin, 1988" startWordPosition="229" endWordPosition="230">ur languages. We present novel algorithms that integrate triggers for cognitive, affective, perceptual and social processes with stylistic and lexical information. By running evaluations on datasets in English, Spanish, Russian and Farsi, we show that the developed affect polarity and valence prediction technology of metaphor-rich texts is portable and works equally well for different languages. 1 Introduction Metaphor is a figure of speech in which a word or phrase that ordinarily designates one thing is used to designate another, thus making an implicit comparison (Lakoff and Johnson, 1980; Martin, 1988; Wilks, 2007). For instance, in “My lawyer is a shark” the speaker may want to communicate that his/her lawyer is strong and aggressive, and that he will attack in court and persist until the goals are achieved. By using the metaphor, the speaker actually conveys positive affect because having an aggressive lawyer is good if one is being sued. There has been a substantial body of work on metaphor identification and interpretation (Wilks, 2007; Shutova et al., 2010). However, in this paper we focus on an equally interesting, challenging and important problem, which concerns the automatic ident</context>
</contexts>
<marker>Martin, 1988</marker>
<rawString>James H. Martin. 1988. Representing regularities in the metaphoric lexicon. In Proceedings of the 12th conference on Computational linguistics - Volume 1, COLING ’88, pages 396–401.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas M Mitchell</author>
</authors>
<date>1997</date>
<journal>Machine Learning. McGraw-Hill, Inc.,</journal>
<volume>1</volume>
<pages>edition.</pages>
<contexts>
<context position="17187" citStr="Mitchell, 1997" startWordPosition="2738" endWordPosition="2739">xt, source or target instead of their combinations. The classifiers obtain similar performance for both languages. LIWC Category Relevance to Metaphor Polarity: We also study the importance and relevance of the LIWC categories for the metaphor polarity task. We use information gain (IG) to measure the amount of information in bits about the polarity class prediction, if the only information available is the presence of a given LIWC category (feature) and the corresponding polarity class distribution. IG measures the expected reduction in entropy (uncertainty associated with a random feature) (Mitchell, 1997). Figure 3 illustrates how certain categories occur more with the positive (in red color) vs negative (in green color) class. With the positive metaphors we observe the LIWC categories for present tense, social, affect and family, while for the negative metaphors we see LIWC categories for past tense, inhibition and anger. 1 0 _1 Figure 3: LIWC category relevance to Metaphor Polarity In addition, we show in Figure 4 examples of the top LIWC categories according to IG ranking for each one of the information sources. Figure 4: Example of LIWC Categories and Words For metaphor texts, these catego</context>
</contexts>
<marker>Mitchell, 1997</marker>
<rawString>Thomas M. Mitchell. 1997. Machine Learning. McGraw-Hill, Inc., 1 edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Mohler</author>
<author>David Bracewell</author>
<author>David Hinote</author>
<author>Marc Tomlinson</author>
</authors>
<title>Semantic signatures for example-based linguistic metaphor detection.</title>
<date>2013</date>
<booktitle>In The Proceedings of the First Workshop on Metaphor in NLP, (NAACL),</booktitle>
<pages>46--54</pages>
<contexts>
<context position="10433" citStr="Mohler et al., 2013" startWordPosition="1635" endWordPosition="1638">Language Computer Corporation (LCC)1, which developed anno1http://www.languagecomputer.com/ tation toolkit specifically for the task of metaphor detection, interpretation and affect assignment. They hired annotators to collect and annotate data for the English, Spanish, Russian and Farsi languages. The domain for which the metaphors were collected was Governance. It encompasses electoral politics, the setting of economic policy, the creation, application and enforcement of rules and laws. The metaphors were collected from political speeches, political websites, online newspapers among others (Mohler et al., 2013). The annotation toolkit allowed annotators to provide for each metaphor the following information: the metaphor, the context in which the metaphor was found, the meaning of the metaphor in the source and target domains from the perspective of a native speaker. For example, in the Context: And to all nations, we will speak for the values that gave our nation birth.; the annotators tagged the Metaphor: values that gave our nation birth; and listed as Source: mother gave birth to baby; and Target: values of freedom and equality motivated the creation of America. The same annotators also provided</context>
</contexts>
<marker>Mohler, Bracewell, Hinote, Tomlinson, 2013</marker>
<rawString>Michael Mohler, David Bracewell, David Hinote, and Marc Tomlinson. 2013. Semantic signatures for example-based linguistic metaphor detection. In The Proceedings of the First Workshop on Metaphor in NLP, (NAACL), pages 46–54.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yun Niu</author>
<author>Xiaodan Zhu</author>
<author>Jianhua Li</author>
<author>Graeme Hirst</author>
</authors>
<title>Analysis of polarity information in medical text.</title>
<date>2005</date>
<booktitle>In In: Proceedings of the American Medical Informatics Association 2005 Annual Symposium,</booktitle>
<pages>570--574</pages>
<contexts>
<context position="5378" citStr="Niu et al., 2005" startWordPosition="841" endWordPosition="844">depending on its intensity (Polanyi and Zaenen, 2004; Strapparava and Mihalcea, 2007). Over the years researchers have developed various approaches to identify polarity of words (Esuli and Sebastiani, 2006), phrases (Turney, 2002; Wilson et al., 2005), sentences (Choi and Cardie, 2009) even documents (Pang and Lee, 2008). Multiple techniques have been employed, from various machine learning classifiers, to clustering and topic models. Various domains and textual sources have been analyzed such as Twitter, Blogs, Web documents, movie and product reviews (Turney, 2002; Kennedy and Inkpen, 2005; Niu et al., 2005; Pang and Lee, 2008), but yet what is missing is affect analyzer for metaphor-rich texts. While the affect of metaphors is well studied from its linguistic and psychological aspects (Blanchette et al., 2001; Tomlinson and Love, 2006; Crawdord, 2009), to our knowledge the building of computational models for polarity and valence identification in metaphor-rich texts is still a novel task (Smith et al., 2007; Veale, 2012; Veale and Li, 2012; Reyes and Rosso, 2012; Reyes et al., 2013). Little (almost no) effort has been put into multilingual computational affect models of metaphor-rich texts. Ou</context>
</contexts>
<marker>Niu, Zhu, Li, Hirst, 2005</marker>
<rawString>Yun Niu, Xiaodan Zhu, Jianhua Li, and Graeme Hirst. 2005. Analysis of polarity information in medical text. In In: Proceedings of the American Medical Informatics Association 2005 Annual Symposium, pages 570–574.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Myle Ott</author>
<author>Yejin Choi</author>
<author>Claire Cardie</author>
<author>Jeffrey T Hancock</author>
</authors>
<title>Finding deceptive opinion spam by any stretch of the imagination.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1, HLT ’11,</booktitle>
<pages>309--319</pages>
<contexts>
<context position="15362" citStr="Ott et al., 2011" startWordPosition="2447" endWordPosition="2450"> Word Count (LIWC) repository (Tausczik and Pennebaker, 2010), which has 64 word categories corresponding to different classes like emotional states, psychological processes, personal concerns among other. Each category contains a list of words characterizing it. For instance, the LIWC category discrepancy contains words like should, could among others, while the LIWC category inhibition contains words like block, stop, constrain. Previously LIWC was successfully used to analyze the emotional state of bloggers and tweeters (Quercia et al., 2011) and to identify deception and sarcasm in texts (Ott et al., 2011; Gonz´alez-Ib´a˜nez et al., 2011). When LIWC analyzes texts it generates statistics like number of words found in category Ci divided by the total number of words in the text. For our metaphor polarity task, we use LIWC’s statistics of all 64 categories and feed this information as features for the machine learning classifiers. LIWC repository contains conceptual categories (dictionaries) both for the English and Spanish languages. LIWC Evaluation and Results: In our experiments LIWC is applied to English and Spanish metaphor-rich texts since the LIWC category dictionaries are available for b</context>
</contexts>
<marker>Ott, Choi, Cardie, Hancock, 2011</marker>
<rawString>Myle Ott, Yejin Choi, Claire Cardie, and Jeffrey T. Hancock. 2011. Finding deceptive opinion spam by any stretch of the imagination. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1, HLT ’11, pages 309–319.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>Opinion mining and sentiment analysis.</title>
<date>2008</date>
<journal>Found. Trends Inf. Retr.,</journal>
<pages>2--1</pages>
<contexts>
<context position="5084" citStr="Pang and Lee, 2008" startWordPosition="797" endWordPosition="800">na and Cardie, 2011; Breck et al., 2007). Various tasks have been solved among which polarity and valence identification are the most common. While polarity identification aims at finding the Positive and Negative affect, valence is more challenging as it has to map the affect on a [−3,+3] scale depending on its intensity (Polanyi and Zaenen, 2004; Strapparava and Mihalcea, 2007). Over the years researchers have developed various approaches to identify polarity of words (Esuli and Sebastiani, 2006), phrases (Turney, 2002; Wilson et al., 2005), sentences (Choi and Cardie, 2009) even documents (Pang and Lee, 2008). Multiple techniques have been employed, from various machine learning classifiers, to clustering and topic models. Various domains and textual sources have been analyzed such as Twitter, Blogs, Web documents, movie and product reviews (Turney, 2002; Kennedy and Inkpen, 2005; Niu et al., 2005; Pang and Lee, 2008), but yet what is missing is affect analyzer for metaphor-rich texts. While the affect of metaphors is well studied from its linguistic and psychological aspects (Blanchette et al., 2001; Tomlinson and Love, 2006; Crawdord, 2009), to our knowledge the building of computational models </context>
</contexts>
<marker>Pang, Lee, 2008</marker>
<rawString>Bo Pang and Lillian Lee. 2008. Opinion mining and sentiment analysis. Found. Trends Inf. Retr., 2(1-2):1–135, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Livia Polanyi</author>
<author>Annie Zaenen</author>
</authors>
<title>Contextual lexical valence shifters. In</title>
<date>2004</date>
<booktitle>Proceedings of the AAAI Spring Symposium on Exploring Attitude and Affect in Text: Theories and Applications. AAAI Press. AAAI technical report</booktitle>
<pages>04--07</pages>
<editor>Yan Qu, James Shanahan, and Janyce Wiebe, editors,</editor>
<contexts>
<context position="4814" citStr="Polanyi and Zaenen, 2004" startWordPosition="756" endWordPosition="759">nducted experiments and obtained results. Finally, we conclude in Section 6. 2 Related Work A substantial body of work has been done on determining the affect (sentiment analysis) of texts (Kim and Hovy, 2004; Strapparava and Mihalcea, 2007; Wiebe and Cardie, 2005; Yessenalina and Cardie, 2011; Breck et al., 2007). Various tasks have been solved among which polarity and valence identification are the most common. While polarity identification aims at finding the Positive and Negative affect, valence is more challenging as it has to map the affect on a [−3,+3] scale depending on its intensity (Polanyi and Zaenen, 2004; Strapparava and Mihalcea, 2007). Over the years researchers have developed various approaches to identify polarity of words (Esuli and Sebastiani, 2006), phrases (Turney, 2002; Wilson et al., 2005), sentences (Choi and Cardie, 2009) even documents (Pang and Lee, 2008). Multiple techniques have been employed, from various machine learning classifiers, to clustering and topic models. Various domains and textual sources have been analyzed such as Twitter, Blogs, Web documents, movie and product reviews (Turney, 2002; Kennedy and Inkpen, 2005; Niu et al., 2005; Pang and Lee, 2008), but yet what </context>
</contexts>
<marker>Polanyi, Zaenen, 2004</marker>
<rawString>Livia Polanyi and Annie Zaenen. 2004. Contextual lexical valence shifters. In Yan Qu, James Shanahan, and Janyce Wiebe, editors, Proceedings of the AAAI Spring Symposium on Exploring Attitude and Affect in Text: Theories and Applications. AAAI Press. AAAI technical report SS-04-07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniele Quercia</author>
<author>Jonathan Ellis</author>
<author>Licia Capra</author>
<author>Jon Crowcroft</author>
</authors>
<title>In the mood for being influential on twitter.</title>
<date>2011</date>
<booktitle>In the 3rd IEEE International Conference on Social Computing.</booktitle>
<contexts>
<context position="15297" citStr="Quercia et al., 2011" startWordPosition="2435" endWordPosition="2438">dition to the n-gram features, we also used the Linguistic Inquiry and Word Count (LIWC) repository (Tausczik and Pennebaker, 2010), which has 64 word categories corresponding to different classes like emotional states, psychological processes, personal concerns among other. Each category contains a list of words characterizing it. For instance, the LIWC category discrepancy contains words like should, could among others, while the LIWC category inhibition contains words like block, stop, constrain. Previously LIWC was successfully used to analyze the emotional state of bloggers and tweeters (Quercia et al., 2011) and to identify deception and sarcasm in texts (Ott et al., 2011; Gonz´alez-Ib´a˜nez et al., 2011). When LIWC analyzes texts it generates statistics like number of words found in category Ci divided by the total number of words in the text. For our metaphor polarity task, we use LIWC’s statistics of all 64 categories and feed this information as features for the machine learning classifiers. LIWC repository contains conceptual categories (dictionaries) both for the English and Spanish languages. LIWC Evaluation and Results: In our experiments LIWC is applied to English and Spanish metaphor-ri</context>
</contexts>
<marker>Quercia, Ellis, Capra, Crowcroft, 2011</marker>
<rawString>Daniele Quercia, Jonathan Ellis, Licia Capra, and Jon Crowcroft. 2011. In the mood for being influential on twitter. In the 3rd IEEE International Conference on Social Computing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antonio Reyes</author>
<author>Paolo Rosso</author>
</authors>
<title>Making objective decisions from subjective data: Detecting irony in customer reviews.</title>
<date>2012</date>
<journal>Decis. Support Syst.,</journal>
<volume>53</volume>
<issue>4</issue>
<contexts>
<context position="5844" citStr="Reyes and Rosso, 2012" startWordPosition="917" endWordPosition="920">xtual sources have been analyzed such as Twitter, Blogs, Web documents, movie and product reviews (Turney, 2002; Kennedy and Inkpen, 2005; Niu et al., 2005; Pang and Lee, 2008), but yet what is missing is affect analyzer for metaphor-rich texts. While the affect of metaphors is well studied from its linguistic and psychological aspects (Blanchette et al., 2001; Tomlinson and Love, 2006; Crawdord, 2009), to our knowledge the building of computational models for polarity and valence identification in metaphor-rich texts is still a novel task (Smith et al., 2007; Veale, 2012; Veale and Li, 2012; Reyes and Rosso, 2012; Reyes et al., 2013). Little (almost no) effort has been put into multilingual computational affect models of metaphor-rich texts. Our research specifically targets the resolution of these problems and shows that it is possible to build such computational models. The experimental result provide valuable contributions and fundings, which could be used by the research community to build upon. 3 Metaphors Although there are different views on metaphor in linguistics and philosophy (Black, 1962; Lakoff and Johnson, 1980; Gentner, 1983; Wilks, 2007), the common among all approaches is the idea of </context>
</contexts>
<marker>Reyes, Rosso, 2012</marker>
<rawString>Antonio Reyes and Paolo Rosso. 2012. Making objective decisions from subjective data: Detecting irony in customer reviews. Decis. Support Syst., 53(4):754–760, November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antonio Reyes</author>
<author>Paolo Rosso</author>
<author>Tony Veale</author>
</authors>
<title>A multidimensional approach for detecting irony in twitter.</title>
<date>2013</date>
<journal>Lang. Resour. Eval.,</journal>
<volume>47</volume>
<issue>1</issue>
<contexts>
<context position="5865" citStr="Reyes et al., 2013" startWordPosition="921" endWordPosition="924"> analyzed such as Twitter, Blogs, Web documents, movie and product reviews (Turney, 2002; Kennedy and Inkpen, 2005; Niu et al., 2005; Pang and Lee, 2008), but yet what is missing is affect analyzer for metaphor-rich texts. While the affect of metaphors is well studied from its linguistic and psychological aspects (Blanchette et al., 2001; Tomlinson and Love, 2006; Crawdord, 2009), to our knowledge the building of computational models for polarity and valence identification in metaphor-rich texts is still a novel task (Smith et al., 2007; Veale, 2012; Veale and Li, 2012; Reyes and Rosso, 2012; Reyes et al., 2013). Little (almost no) effort has been put into multilingual computational affect models of metaphor-rich texts. Our research specifically targets the resolution of these problems and shows that it is possible to build such computational models. The experimental result provide valuable contributions and fundings, which could be used by the research community to build upon. 3 Metaphors Although there are different views on metaphor in linguistics and philosophy (Black, 1962; Lakoff and Johnson, 1980; Gentner, 1983; Wilks, 2007), the common among all approaches is the idea of an interconceptual ma</context>
</contexts>
<marker>Reyes, Rosso, Veale, 2013</marker>
<rawString>Antonio Reyes, Paolo Rosso, and Tony Veale. 2013. A multidimensional approach for detecting irony in twitter. Lang. Resour. Eval., 47(1):239–268, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernhard Sch¨olkopf</author>
<author>Alexander J Smola</author>
</authors>
<date>2001</date>
<booktitle>Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond (Adaptive Computation and Machine Learning).</booktitle>
<publisher>The MIT Press.</publisher>
<marker>Sch¨olkopf, Smola, 2001</marker>
<rawString>Bernhard Sch¨olkopf and Alexander J. Smola. 2001. Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond (Adaptive Computation and Machine Learning). The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ekaterina Shutova</author>
<author>Simone Teufel</author>
</authors>
<title>Metaphor corpus annotated for source - target domain mappings.</title>
<date>2010</date>
<booktitle>In International Conference on Language Resources and Evaluation.</booktitle>
<contexts>
<context position="7655" citStr="Shutova and Teufel, 2010" startWordPosition="1205" endWordPosition="1208">a verbal battle and the structure of an argument (attack, defense) reflects this (Lakoff and Johnson, 1980). As we mentioned before, there has been a lot of work on the automatic identification of metaphors (Wilks, 2007; Shutova et al., 2010) and their mapping into conceptual space (Shutova, 2010a; Shutova, 2010b), however these are beyond the scope of this paper. Instead we focus on an equally interesting, challenging and important problem, which concerns the automatic identification of affect carried by metaphors. To conduct our study, we use human annotators to collect metaphor-rich texts (Shutova and Teufel, 2010) and tag each metaphor with its corresponding polarity (Positive/Negative) and valence [−3,+3] scores. The next sections describe the affect polarity and valence tasks we have defined, the collected and annotated metaphor-rich data for each one of the English, Spanish, Russian and Farsi languages, the conducted experiments and obtained results. 683 4 Task A: Polarity Classification 4.1 Problem Formulation Task Definition: Given metaphor-rich texts annotated with Positive and Negative polarity labels, the goal is to build an automated computational affect model, which can assign to previously u</context>
</contexts>
<marker>Shutova, Teufel, 2010</marker>
<rawString>Ekaterina Shutova and Simone Teufel. 2010. Metaphor corpus annotated for source - target domain mappings. In International Conference on Language Resources and Evaluation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ekaterina Shutova</author>
<author>Lin Sun</author>
<author>Anna Korhonen</author>
</authors>
<title>Metaphor identification using verb and noun clustering.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics, COLING ’10,</booktitle>
<pages>1002--1010</pages>
<contexts>
<context position="1957" citStr="Shutova et al., 2010" startWordPosition="306" endWordPosition="309">or phrase that ordinarily designates one thing is used to designate another, thus making an implicit comparison (Lakoff and Johnson, 1980; Martin, 1988; Wilks, 2007). For instance, in “My lawyer is a shark” the speaker may want to communicate that his/her lawyer is strong and aggressive, and that he will attack in court and persist until the goals are achieved. By using the metaphor, the speaker actually conveys positive affect because having an aggressive lawyer is good if one is being sued. There has been a substantial body of work on metaphor identification and interpretation (Wilks, 2007; Shutova et al., 2010). However, in this paper we focus on an equally interesting, challenging and important problem, which concerns the automatic identification of affect carried by metaphors. Building such computational models is important to understand how people use metaphors to convey affect and how affect is expressed using metaphors. The existence of such models can be also used to improve the communication between individuals and to make sure that the speakers perceived the affect of the concrete metaphor example in the same way. The questions we address in this paper are: “How can we build computational mo</context>
<context position="7272" citStr="Shutova et al., 2010" startWordPosition="1148" endWordPosition="1151"> (or vehicle), and the existence of a link between them gives rise to metaphors. The texts “Your claims are indefensible.” and “He attacked every weak point in my argument.” do not directly talk about argument as a war, however the winning or losing of arguments, the attack or defense of positions are structured by the concept of war. There is no physical battle, but there is a verbal battle and the structure of an argument (attack, defense) reflects this (Lakoff and Johnson, 1980). As we mentioned before, there has been a lot of work on the automatic identification of metaphors (Wilks, 2007; Shutova et al., 2010) and their mapping into conceptual space (Shutova, 2010a; Shutova, 2010b), however these are beyond the scope of this paper. Instead we focus on an equally interesting, challenging and important problem, which concerns the automatic identification of affect carried by metaphors. To conduct our study, we use human annotators to collect metaphor-rich texts (Shutova and Teufel, 2010) and tag each metaphor with its corresponding polarity (Positive/Negative) and valence [−3,+3] scores. The next sections describe the affect polarity and valence tasks we have defined, the collected and annotated meta</context>
</contexts>
<marker>Shutova, Sun, Korhonen, 2010</marker>
<rawString>Ekaterina Shutova, Lin Sun, and Anna Korhonen. 2010. Metaphor identification using verb and noun clustering. In Proceedings of the 23rd International Conference on Computational Linguistics, COLING ’10, pages 1002–1010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ekaterina Shutova</author>
</authors>
<title>Automatic metaphor interpretation as a paraphrasing task. In Human Language Technologies: The</title>
<date>2010</date>
<booktitle>Annual Conference of the North American Chapter of the Association for Computational Linguistics, HLT ’10,</booktitle>
<pages>1029--1037</pages>
<contexts>
<context position="7327" citStr="Shutova, 2010" startWordPosition="1158" endWordPosition="1159">ise to metaphors. The texts “Your claims are indefensible.” and “He attacked every weak point in my argument.” do not directly talk about argument as a war, however the winning or losing of arguments, the attack or defense of positions are structured by the concept of war. There is no physical battle, but there is a verbal battle and the structure of an argument (attack, defense) reflects this (Lakoff and Johnson, 1980). As we mentioned before, there has been a lot of work on the automatic identification of metaphors (Wilks, 2007; Shutova et al., 2010) and their mapping into conceptual space (Shutova, 2010a; Shutova, 2010b), however these are beyond the scope of this paper. Instead we focus on an equally interesting, challenging and important problem, which concerns the automatic identification of affect carried by metaphors. To conduct our study, we use human annotators to collect metaphor-rich texts (Shutova and Teufel, 2010) and tag each metaphor with its corresponding polarity (Positive/Negative) and valence [−3,+3] scores. The next sections describe the affect polarity and valence tasks we have defined, the collected and annotated metaphor-rich data for each one of the English, Spanish, Ru</context>
</contexts>
<marker>Shutova, 2010</marker>
<rawString>Ekaterina Shutova. 2010a. Automatic metaphor interpretation as a paraphrasing task. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, HLT ’10, pages 1029–1037.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ekaterina Shutova</author>
</authors>
<title>Models of metaphor in nlp.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL ’10,</booktitle>
<pages>688--697</pages>
<contexts>
<context position="7327" citStr="Shutova, 2010" startWordPosition="1158" endWordPosition="1159">ise to metaphors. The texts “Your claims are indefensible.” and “He attacked every weak point in my argument.” do not directly talk about argument as a war, however the winning or losing of arguments, the attack or defense of positions are structured by the concept of war. There is no physical battle, but there is a verbal battle and the structure of an argument (attack, defense) reflects this (Lakoff and Johnson, 1980). As we mentioned before, there has been a lot of work on the automatic identification of metaphors (Wilks, 2007; Shutova et al., 2010) and their mapping into conceptual space (Shutova, 2010a; Shutova, 2010b), however these are beyond the scope of this paper. Instead we focus on an equally interesting, challenging and important problem, which concerns the automatic identification of affect carried by metaphors. To conduct our study, we use human annotators to collect metaphor-rich texts (Shutova and Teufel, 2010) and tag each metaphor with its corresponding polarity (Positive/Negative) and valence [−3,+3] scores. The next sections describe the affect polarity and valence tasks we have defined, the collected and annotated metaphor-rich data for each one of the English, Spanish, Ru</context>
</contexts>
<marker>Shutova, 2010</marker>
<rawString>Ekaterina Shutova. 2010b. Models of metaphor in nlp. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL ’10, pages 688–697.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Catherine Smith</author>
<author>Tim Rumbell</author>
<author>John Barnden</author>
<author>Bob Hendley</author>
<author>Mark Lee</author>
<author>Alan Wallington</author>
</authors>
<title>Don’t worry about metaphor: affect extraction for conversational agents.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions, ACL ’07,</booktitle>
<pages>pages</pages>
<contexts>
<context position="5788" citStr="Smith et al., 2007" startWordPosition="907" endWordPosition="910">o clustering and topic models. Various domains and textual sources have been analyzed such as Twitter, Blogs, Web documents, movie and product reviews (Turney, 2002; Kennedy and Inkpen, 2005; Niu et al., 2005; Pang and Lee, 2008), but yet what is missing is affect analyzer for metaphor-rich texts. While the affect of metaphors is well studied from its linguistic and psychological aspects (Blanchette et al., 2001; Tomlinson and Love, 2006; Crawdord, 2009), to our knowledge the building of computational models for polarity and valence identification in metaphor-rich texts is still a novel task (Smith et al., 2007; Veale, 2012; Veale and Li, 2012; Reyes and Rosso, 2012; Reyes et al., 2013). Little (almost no) effort has been put into multilingual computational affect models of metaphor-rich texts. Our research specifically targets the resolution of these problems and shows that it is possible to build such computational models. The experimental result provide valuable contributions and fundings, which could be used by the research community to build upon. 3 Metaphors Although there are different views on metaphor in linguistics and philosophy (Black, 1962; Lakoff and Johnson, 1980; Gentner, 1983; Wilks</context>
</contexts>
<marker>Smith, Rumbell, Barnden, Hendley, Lee, Wallington, 2007</marker>
<rawString>Catherine Smith, Tim Rumbell, John Barnden, Bob Hendley, Mark Lee, and Alan Wallington. 2007. Don’t worry about metaphor: affect extraction for conversational agents. In Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions, ACL ’07, pages 37– 40. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alex J Smola</author>
<author>Bernhard Schlkopf</author>
<author>Bernhard Sch Olkopf</author>
</authors>
<title>A tutorial on support vector regression.</title>
<date>2003</date>
<tech>Technical report, Statistics and Computing.</tech>
<contexts>
<context position="23170" citStr="Smola et al., 2003" startWordPosition="3722" endWordPosition="3725">a regularization constant and E controls the training error. The training algorithm finds weights w that define a function f minimizing the empirical risk. Let h be a function from seeds into some vector-space representation C_ Rd, then the function f takes the form: f(m; w) = h(m)Tw = ENi_1 αiK(m, mi), where f is re-parameterized in terms of a polynomial kernel function K with dual weights αi. K measures the similarity between two metaphoric texts. Full details of the regression model and its implementation are beyond the scope of this paper; for more details see (Sch¨olkopf and Smola, 2001; Smola et al., 2003). In our experimental study, we use the freely available implementation of SVM in Weka (Witten and Frank, 2005). -2 the &apos;things&apos; are going to make sure their ox doesn&apos;t get gored a tough pill to swallow The administration, in fact, could go further with the budget knife by eliminating the V-22 Osprey aircraft Clinton also came into office hoping to bridge Washington’s partisan divide. values that gave our nation birth -3 -1 +3 +2 +1 Thirty percent of our mortgages are underwater. Figure 6: Valence Prediction min 2||w||2 + N N max(0, |vi − f(mi; w) |− E) w∈Rs i=1 � N11 � E-insensitive loss func</context>
</contexts>
<marker>Smola, Schlkopf, Olkopf, 2003</marker>
<rawString>Alex J. Smola, Bernhard Schlkopf, and Bernhard Sch Olkopf. 2003. A tutorial on support vector regression. Technical report, Statistics and Computing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carlo Strapparava</author>
<author>Rada Mihalcea</author>
</authors>
<title>Semeval2007 task 14: Affective text.</title>
<date>2007</date>
<booktitle>In Proceedings of the Fourth International Workshop on Semantic Evaluations (SemEval-2007),</booktitle>
<pages>70--74</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics,</institution>
<contexts>
<context position="4430" citStr="Strapparava and Mihalcea, 2007" startWordPosition="694" endWordPosition="697">ethods significantly outperform baseline methods. The rest of the paper is organized as follows. Section 2 describes related work, Section 3 briefly talks about metaphors. Sections 4 and 5 describe the polarity classification and valence prediction tasks for affect of metaphor-rich texts. Both sections have information on the collected data for English, Spanish, Russian and Farsi, the conducted experiments and obtained results. Finally, we conclude in Section 6. 2 Related Work A substantial body of work has been done on determining the affect (sentiment analysis) of texts (Kim and Hovy, 2004; Strapparava and Mihalcea, 2007; Wiebe and Cardie, 2005; Yessenalina and Cardie, 2011; Breck et al., 2007). Various tasks have been solved among which polarity and valence identification are the most common. While polarity identification aims at finding the Positive and Negative affect, valence is more challenging as it has to map the affect on a [−3,+3] scale depending on its intensity (Polanyi and Zaenen, 2004; Strapparava and Mihalcea, 2007). Over the years researchers have developed various approaches to identify polarity of words (Esuli and Sebastiani, 2006), phrases (Turney, 2002; Wilson et al., 2005), sentences (Choi</context>
</contexts>
<marker>Strapparava, Mihalcea, 2007</marker>
<rawString>Carlo Strapparava and Rada Mihalcea. 2007. Semeval2007 task 14: Affective text. In Proceedings of the Fourth International Workshop on Semantic Evaluations (SemEval-2007), pages 70–74. Association for Computational Linguistics, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yla R Tausczik</author>
<author>James W Pennebaker</author>
</authors>
<title>The Psychological Meaning of Words: LIWC and Computerized Text Analysis Methods.</title>
<date>2010</date>
<journal>Journal of Language and Social Psychology,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="3714" citStr="Tausczik and Pennebaker, 2010" startWordPosition="582" endWordPosition="586">arity and valence tasks for all four languages. We model the polarity task as a classification problem, while the valence task as a regression problem. • We have studied the influence of different information sources like the metaphor itself, the context in which it resides, the source and 682 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 682–691, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics target domains of the metaphor, in addition to contextual features and trigger word lists developed by psychologists (Tausczik and Pennebaker, 2010). • We have conducted in depth experimental evaluation and showed that the developed methods significantly outperform baseline methods. The rest of the paper is organized as follows. Section 2 describes related work, Section 3 briefly talks about metaphors. Sections 4 and 5 describe the polarity classification and valence prediction tasks for affect of metaphor-rich texts. Both sections have information on the collected data for English, Spanish, Russian and Farsi, the conducted experiments and obtained results. Finally, we conclude in Section 6. 2 Related Work A substantial body of work has b</context>
<context position="14807" citStr="Tausczik and Pennebaker, 2010" startWordPosition="2364" endWordPosition="2367">gh performances are obtained both with the context and with the combination of the context, source and target information. While for Spanish they reach similar performance. SPANISH RUSSIAN FARSI Metaphor 71.6 71.0 62.4 Source 67.1 62.4 55.4 Target 68.9 67.2 62.4 Context 73.5 77.1 67.4 S+T 76.6 68.7 62.4 M+S+T 76.0 75.4 64.2 C+S+T 76.5 76.5 68.4 Table 2: N-gram features, F-scores on 10-fold validation for Spanish, Russian and Farsi 4.5 LIWC as a Proxy for Metaphor Polarity LIWC Repository: In addition to the n-gram features, we also used the Linguistic Inquiry and Word Count (LIWC) repository (Tausczik and Pennebaker, 2010), which has 64 word categories corresponding to different classes like emotional states, psychological processes, personal concerns among other. Each category contains a list of words characterizing it. For instance, the LIWC category discrepancy contains words like should, could among others, while the LIWC category inhibition contains words like block, stop, constrain. Previously LIWC was successfully used to analyze the emotional state of bloggers and tweeters (Quercia et al., 2011) and to identify deception and sarcasm in texts (Ott et al., 2011; Gonz´alez-Ib´a˜nez et al., 2011). When LIWC</context>
<context position="29202" citStr="Tausczik and Pennebaker, 2010" startWordPosition="4746" endWordPosition="4749">0 2.40 .41 2.19 .70 1.60 .78 1.53 M+S+T .45 1.62 .29 2.13 .43 2.34 .43 2.14 .67 1.67 .78 1.53 C+S+T .42 1.85 .26 2.61 .43 2.52 .39 2.41 .44 2.08 .64 1.96 Table 5: Valence Prediction, Correlation Coefficient and Mean Squared Error for English, Spanish, Russian and Farsi their combination in order to understand how such information helps and impacts the interpretation of the affect associated with the metaphor. We have conducted exhaustive evaluation with multiple machine learning classifiers and different features sets spanning from lexical information to psychological categories developed by (Tausczik and Pennebaker, 2010). Through experiments carried out on the developed datasets, we showed that the proposed polarity classification and valence regression models significantly improve baselines (from 11.90% to 39.69% depending on the language) and work well for all four languages. From the two tasks, the valence prediction problem was more challenging both for the human annotators and the automated system. The mean squared error in valence prediction in the range [−3,+3], where −3 indicates strong negative and +3 indicates strong positive affect for English, Spanish and Russian was around 1.5, while for Farsi wa</context>
</contexts>
<marker>Tausczik, Pennebaker, 2010</marker>
<rawString>Yla R. Tausczik and James W. Pennebaker. 2010. The Psychological Meaning of Words: LIWC and Computerized Text Analysis Methods. Journal of Language and Social Psychology, 29(1):24–54, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc T Tomlinson</author>
<author>Bradley C Love</author>
</authors>
<title>From pigeons to humans: grounding relational learning in concrete examples.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st national conference on Artificial intelligence -</booktitle>
<volume>1</volume>
<pages>199--204</pages>
<publisher>AAAI Press.</publisher>
<contexts>
<context position="5611" citStr="Tomlinson and Love, 2006" startWordPosition="880" endWordPosition="883">2002; Wilson et al., 2005), sentences (Choi and Cardie, 2009) even documents (Pang and Lee, 2008). Multiple techniques have been employed, from various machine learning classifiers, to clustering and topic models. Various domains and textual sources have been analyzed such as Twitter, Blogs, Web documents, movie and product reviews (Turney, 2002; Kennedy and Inkpen, 2005; Niu et al., 2005; Pang and Lee, 2008), but yet what is missing is affect analyzer for metaphor-rich texts. While the affect of metaphors is well studied from its linguistic and psychological aspects (Blanchette et al., 2001; Tomlinson and Love, 2006; Crawdord, 2009), to our knowledge the building of computational models for polarity and valence identification in metaphor-rich texts is still a novel task (Smith et al., 2007; Veale, 2012; Veale and Li, 2012; Reyes and Rosso, 2012; Reyes et al., 2013). Little (almost no) effort has been put into multilingual computational affect models of metaphor-rich texts. Our research specifically targets the resolution of these problems and shows that it is possible to build such computational models. The experimental result provide valuable contributions and fundings, which could be used by the resear</context>
</contexts>
<marker>Tomlinson, Love, 2006</marker>
<rawString>Marc T. Tomlinson and Bradley C. Love. 2006. From pigeons to humans: grounding relational learning in concrete examples. In Proceedings of the 21st national conference on Artificial intelligence - Volume 1, AAAI’06, pages 199–204. AAAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
</authors>
<title>Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of reviews.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ACL ’02,</booktitle>
<pages>417--424</pages>
<contexts>
<context position="4991" citStr="Turney, 2002" startWordPosition="783" endWordPosition="784">(Kim and Hovy, 2004; Strapparava and Mihalcea, 2007; Wiebe and Cardie, 2005; Yessenalina and Cardie, 2011; Breck et al., 2007). Various tasks have been solved among which polarity and valence identification are the most common. While polarity identification aims at finding the Positive and Negative affect, valence is more challenging as it has to map the affect on a [−3,+3] scale depending on its intensity (Polanyi and Zaenen, 2004; Strapparava and Mihalcea, 2007). Over the years researchers have developed various approaches to identify polarity of words (Esuli and Sebastiani, 2006), phrases (Turney, 2002; Wilson et al., 2005), sentences (Choi and Cardie, 2009) even documents (Pang and Lee, 2008). Multiple techniques have been employed, from various machine learning classifiers, to clustering and topic models. Various domains and textual sources have been analyzed such as Twitter, Blogs, Web documents, movie and product reviews (Turney, 2002; Kennedy and Inkpen, 2005; Niu et al., 2005; Pang and Lee, 2008), but yet what is missing is affect analyzer for metaphor-rich texts. While the affect of metaphors is well studied from its linguistic and psychological aspects (Blanchette et al., 2001; Toml</context>
</contexts>
<marker>Turney, 2002</marker>
<rawString>Peter D. Turney. 2002. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of reviews. In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ACL ’02, pages 417–424.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tony Veale</author>
<author>Guofu Li</author>
</authors>
<title>Specifying viewpoint and information need with affective metaphors: a system demonstration of the metaphor magnet web app/service.</title>
<date>2012</date>
<booktitle>In Proceedings of the ACL 2012 System Demonstrations, ACL ’12,</booktitle>
<pages>7--12</pages>
<contexts>
<context position="5821" citStr="Veale and Li, 2012" startWordPosition="913" endWordPosition="916">rious domains and textual sources have been analyzed such as Twitter, Blogs, Web documents, movie and product reviews (Turney, 2002; Kennedy and Inkpen, 2005; Niu et al., 2005; Pang and Lee, 2008), but yet what is missing is affect analyzer for metaphor-rich texts. While the affect of metaphors is well studied from its linguistic and psychological aspects (Blanchette et al., 2001; Tomlinson and Love, 2006; Crawdord, 2009), to our knowledge the building of computational models for polarity and valence identification in metaphor-rich texts is still a novel task (Smith et al., 2007; Veale, 2012; Veale and Li, 2012; Reyes and Rosso, 2012; Reyes et al., 2013). Little (almost no) effort has been put into multilingual computational affect models of metaphor-rich texts. Our research specifically targets the resolution of these problems and shows that it is possible to build such computational models. The experimental result provide valuable contributions and fundings, which could be used by the research community to build upon. 3 Metaphors Although there are different views on metaphor in linguistics and philosophy (Black, 1962; Lakoff and Johnson, 1980; Gentner, 1983; Wilks, 2007), the common among all app</context>
</contexts>
<marker>Veale, Li, 2012</marker>
<rawString>Tony Veale and Guofu Li. 2012. Specifying viewpoint and information need with affective metaphors: a system demonstration of the metaphor magnet web app/service. In Proceedings of the ACL 2012 System Demonstrations, ACL ’12, pages 7–12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tony Veale</author>
</authors>
<title>A context-sensitive, multi-faceted model of lexico-conceptual affect.</title>
<date>2012</date>
<booktitle>In The 50th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference,</booktitle>
<pages>75--79</pages>
<contexts>
<context position="5801" citStr="Veale, 2012" startWordPosition="911" endWordPosition="912">ic models. Various domains and textual sources have been analyzed such as Twitter, Blogs, Web documents, movie and product reviews (Turney, 2002; Kennedy and Inkpen, 2005; Niu et al., 2005; Pang and Lee, 2008), but yet what is missing is affect analyzer for metaphor-rich texts. While the affect of metaphors is well studied from its linguistic and psychological aspects (Blanchette et al., 2001; Tomlinson and Love, 2006; Crawdord, 2009), to our knowledge the building of computational models for polarity and valence identification in metaphor-rich texts is still a novel task (Smith et al., 2007; Veale, 2012; Veale and Li, 2012; Reyes and Rosso, 2012; Reyes et al., 2013). Little (almost no) effort has been put into multilingual computational affect models of metaphor-rich texts. Our research specifically targets the resolution of these problems and shows that it is possible to build such computational models. The experimental result provide valuable contributions and fundings, which could be used by the research community to build upon. 3 Metaphors Although there are different views on metaphor in linguistics and philosophy (Black, 1962; Lakoff and Johnson, 1980; Gentner, 1983; Wilks, 2007), the </context>
</contexts>
<marker>Veale, 2012</marker>
<rawString>Tony Veale. 2012. A context-sensitive, multi-faceted model of lexico-conceptual affect. In The 50th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference, pages 75–79.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janyce Wiebe</author>
<author>Claire Cardie</author>
</authors>
<title>Annotating expressions of opinions and emotions in language. language resources and evaluation.</title>
<date>2005</date>
<booktitle>In Language Resources and Evaluation (formerly Computers and the Humanities.</booktitle>
<contexts>
<context position="4454" citStr="Wiebe and Cardie, 2005" startWordPosition="698" endWordPosition="701">baseline methods. The rest of the paper is organized as follows. Section 2 describes related work, Section 3 briefly talks about metaphors. Sections 4 and 5 describe the polarity classification and valence prediction tasks for affect of metaphor-rich texts. Both sections have information on the collected data for English, Spanish, Russian and Farsi, the conducted experiments and obtained results. Finally, we conclude in Section 6. 2 Related Work A substantial body of work has been done on determining the affect (sentiment analysis) of texts (Kim and Hovy, 2004; Strapparava and Mihalcea, 2007; Wiebe and Cardie, 2005; Yessenalina and Cardie, 2011; Breck et al., 2007). Various tasks have been solved among which polarity and valence identification are the most common. While polarity identification aims at finding the Positive and Negative affect, valence is more challenging as it has to map the affect on a [−3,+3] scale depending on its intensity (Polanyi and Zaenen, 2004; Strapparava and Mihalcea, 2007). Over the years researchers have developed various approaches to identify polarity of words (Esuli and Sebastiani, 2006), phrases (Turney, 2002; Wilson et al., 2005), sentences (Choi and Cardie, 2009) even </context>
</contexts>
<marker>Wiebe, Cardie, 2005</marker>
<rawString>Janyce Wiebe and Claire Cardie. 2005. Annotating expressions of opinions and emotions in language. language resources and evaluation. In Language Resources and Evaluation (formerly Computers and the Humanities.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yorick Wilks</author>
</authors>
<title>A preferential, pattern-seeking, semantics for natural language inference.</title>
<date>2007</date>
<booktitle>In Words and Intelligence I,</booktitle>
<volume>35</volume>
<pages>83--102</pages>
<publisher>Springer</publisher>
<contexts>
<context position="1501" citStr="Wilks, 2007" startWordPosition="231" endWordPosition="232">We present novel algorithms that integrate triggers for cognitive, affective, perceptual and social processes with stylistic and lexical information. By running evaluations on datasets in English, Spanish, Russian and Farsi, we show that the developed affect polarity and valence prediction technology of metaphor-rich texts is portable and works equally well for different languages. 1 Introduction Metaphor is a figure of speech in which a word or phrase that ordinarily designates one thing is used to designate another, thus making an implicit comparison (Lakoff and Johnson, 1980; Martin, 1988; Wilks, 2007). For instance, in “My lawyer is a shark” the speaker may want to communicate that his/her lawyer is strong and aggressive, and that he will attack in court and persist until the goals are achieved. By using the metaphor, the speaker actually conveys positive affect because having an aggressive lawyer is good if one is being sued. There has been a substantial body of work on metaphor identification and interpretation (Wilks, 2007; Shutova et al., 2010). However, in this paper we focus on an equally interesting, challenging and important problem, which concerns the automatic identification of a</context>
<context position="6395" citStr="Wilks, 2007" startWordPosition="1003" endWordPosition="1004"> 2007; Veale, 2012; Veale and Li, 2012; Reyes and Rosso, 2012; Reyes et al., 2013). Little (almost no) effort has been put into multilingual computational affect models of metaphor-rich texts. Our research specifically targets the resolution of these problems and shows that it is possible to build such computational models. The experimental result provide valuable contributions and fundings, which could be used by the research community to build upon. 3 Metaphors Although there are different views on metaphor in linguistics and philosophy (Black, 1962; Lakoff and Johnson, 1980; Gentner, 1983; Wilks, 2007), the common among all approaches is the idea of an interconceptual mapping that underlies the production of metaphorical expressions. There are two concepts or conceptual domains: the target (also called topic in the linguistics literature) and the source (or vehicle), and the existence of a link between them gives rise to metaphors. The texts “Your claims are indefensible.” and “He attacked every weak point in my argument.” do not directly talk about argument as a war, however the winning or losing of arguments, the attack or defense of positions are structured by the concept of war. There i</context>
</contexts>
<marker>Wilks, 2007</marker>
<rawString>Yorick Wilks. 2007. A preferential, pattern-seeking, semantics for natural language inference. In Words and Intelligence I, volume 35 of Text, Speech and Language Technology, pages 83–102. Springer Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Wilson</author>
<author>Janyce Wiebe</author>
<author>Paul Hoffmann</author>
</authors>
<title>Recognizing contextual polarity in phraselevel sentiment analysis.</title>
<date>2005</date>
<booktitle>In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing, HLT ’05,</booktitle>
<pages>347--354</pages>
<contexts>
<context position="5013" citStr="Wilson et al., 2005" startWordPosition="785" endWordPosition="789"> 2004; Strapparava and Mihalcea, 2007; Wiebe and Cardie, 2005; Yessenalina and Cardie, 2011; Breck et al., 2007). Various tasks have been solved among which polarity and valence identification are the most common. While polarity identification aims at finding the Positive and Negative affect, valence is more challenging as it has to map the affect on a [−3,+3] scale depending on its intensity (Polanyi and Zaenen, 2004; Strapparava and Mihalcea, 2007). Over the years researchers have developed various approaches to identify polarity of words (Esuli and Sebastiani, 2006), phrases (Turney, 2002; Wilson et al., 2005), sentences (Choi and Cardie, 2009) even documents (Pang and Lee, 2008). Multiple techniques have been employed, from various machine learning classifiers, to clustering and topic models. Various domains and textual sources have been analyzed such as Twitter, Blogs, Web documents, movie and product reviews (Turney, 2002; Kennedy and Inkpen, 2005; Niu et al., 2005; Pang and Lee, 2008), but yet what is missing is affect analyzer for metaphor-rich texts. While the affect of metaphors is well studied from its linguistic and psychological aspects (Blanchette et al., 2001; Tomlinson and Love, 2006; </context>
</contexts>
<marker>Wilson, Wiebe, Hoffmann, 2005</marker>
<rawString>Theresa Wilson, Janyce Wiebe, and Paul Hoffmann. 2005. Recognizing contextual polarity in phraselevel sentiment analysis. In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing, HLT ’05, pages 347–354.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ian H Witten</author>
<author>Eibe Frank</author>
</authors>
<date>2005</date>
<booktitle>Data Mining: Practical Machine Learning Tools and Techniques.</booktitle>
<publisher>Morgan Kaufmann,</publisher>
<note>second edition.</note>
<contexts>
<context position="9556" citStr="Witten and Frank, 2005" startWordPosition="1510" endWordPosition="1513">ication Algorithms We model the metaphor polarity task as a classification problem in which, for a given collection of N training examples, where mi is a metaphor and ci is the polarity of mi, the objective is to learn a classification function f : mi → ci in which 1 stands for positive polarity and 0 stands for negative polarity. We tested five different machine learning algorithms such as Nave Bayes, SVM with polynomial kernel, SVM with RBF kernel, AdaBoost and Stacking, out of which AdaBoost performed the best. In our experimental study, we use the freely available implementations in Weka (Witten and Frank, 2005). Evaluation Measures: To evaluate the goodness of the polarity classification algorithms, we calculate the f-score and accuracy on 10-fold cross validation. 4.3 Data Annotation To conduct our experimental study, we have used annotated data provided by the Language Computer Corporation (LCC)1, which developed anno1http://www.languagecomputer.com/ tation toolkit specifically for the task of metaphor detection, interpretation and affect assignment. They hired annotators to collect and annotate data for the English, Spanish, Russian and Farsi languages. The domain for which the metaphors were col</context>
<context position="23281" citStr="Witten and Frank, 2005" startWordPosition="3741" endWordPosition="3744">fine a function f minimizing the empirical risk. Let h be a function from seeds into some vector-space representation C_ Rd, then the function f takes the form: f(m; w) = h(m)Tw = ENi_1 αiK(m, mi), where f is re-parameterized in terms of a polynomial kernel function K with dual weights αi. K measures the similarity between two metaphoric texts. Full details of the regression model and its implementation are beyond the scope of this paper; for more details see (Sch¨olkopf and Smola, 2001; Smola et al., 2003). In our experimental study, we use the freely available implementation of SVM in Weka (Witten and Frank, 2005). -2 the &apos;things&apos; are going to make sure their ox doesn&apos;t get gored a tough pill to swallow The administration, in fact, could go further with the budget knife by eliminating the V-22 Osprey aircraft Clinton also came into office hoping to bridge Washington’s partisan divide. values that gave our nation birth -3 -1 +3 +2 +1 Thirty percent of our mortgages are underwater. Figure 6: Valence Prediction min 2||w||2 + N N max(0, |vi − f(mi; w) |− E) w∈Rs i=1 � N11 � E-insensitive loss function 687 Evaluation Measures: To evaluate the quality of the valence prediction model, we compare the actual va</context>
</contexts>
<marker>Witten, Frank, 2005</marker>
<rawString>Ian H. Witten and Eibe Frank. 2005. Data Mining: Practical Machine Learning Tools and Techniques. Morgan Kaufmann, second edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ainur Yessenalina</author>
<author>Claire Cardie</author>
</authors>
<title>Compositional matrix-space models for sentiment analysis.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’11,</booktitle>
<pages>172--182</pages>
<contexts>
<context position="4484" citStr="Yessenalina and Cardie, 2011" startWordPosition="702" endWordPosition="705">st of the paper is organized as follows. Section 2 describes related work, Section 3 briefly talks about metaphors. Sections 4 and 5 describe the polarity classification and valence prediction tasks for affect of metaphor-rich texts. Both sections have information on the collected data for English, Spanish, Russian and Farsi, the conducted experiments and obtained results. Finally, we conclude in Section 6. 2 Related Work A substantial body of work has been done on determining the affect (sentiment analysis) of texts (Kim and Hovy, 2004; Strapparava and Mihalcea, 2007; Wiebe and Cardie, 2005; Yessenalina and Cardie, 2011; Breck et al., 2007). Various tasks have been solved among which polarity and valence identification are the most common. While polarity identification aims at finding the Positive and Negative affect, valence is more challenging as it has to map the affect on a [−3,+3] scale depending on its intensity (Polanyi and Zaenen, 2004; Strapparava and Mihalcea, 2007). Over the years researchers have developed various approaches to identify polarity of words (Esuli and Sebastiani, 2006), phrases (Turney, 2002; Wilson et al., 2005), sentences (Choi and Cardie, 2009) even documents (Pang and Lee, 2008)</context>
</contexts>
<marker>Yessenalina, Cardie, 2011</marker>
<rawString>Ainur Yessenalina and Claire Cardie. 2011. Compositional matrix-space models for sentiment analysis. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’11, pages 172–182.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>